{
  "title": "Leveraging molecular structure and bioactivity with chemical language models for de novo drug design",
  "url": "https://openalex.org/W4313703391",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2900235939",
      "name": "Michael Moret",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A3011089556",
      "name": "Irene Pachón-Angona",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2310462495",
      "name": "Leandro Cotos",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2058924233",
      "name": "Shen Yan",
      "affiliations": [
        "University Children's Hospital Zurich",
        "University of Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2989930169",
      "name": "Kenneth Atz",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2234153035",
      "name": "Cyrill Brunner",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2123014785",
      "name": "Martin Baumgartner",
      "affiliations": [
        "University of Zurich",
        "University Children's Hospital Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A1854816946",
      "name": "Francesca Grisoni",
      "affiliations": [
        "Utrecht University",
        "ETH Zurich",
        "Eindhoven University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2222109823",
      "name": "Gisbert Schneider",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2900235939",
      "name": "Michael Moret",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A3011089556",
      "name": "Irene Pachón-Angona",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2310462495",
      "name": "Leandro Cotos",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2058924233",
      "name": "Shen Yan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2989930169",
      "name": "Kenneth Atz",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2234153035",
      "name": "Cyrill Brunner",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2123014785",
      "name": "Martin Baumgartner",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1854816946",
      "name": "Francesca Grisoni",
      "affiliations": [
        "Utrecht University",
        "ETH Zurich",
        "Eindhoven University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2222109823",
      "name": "Gisbert Schneider",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2901719664",
    "https://openalex.org/W2889555425",
    "https://openalex.org/W1988111902",
    "https://openalex.org/W2041686943",
    "https://openalex.org/W2578240541",
    "https://openalex.org/W2773987374",
    "https://openalex.org/W2594328795",
    "https://openalex.org/W2114704115",
    "https://openalex.org/W6604009900",
    "https://openalex.org/W2592262780",
    "https://openalex.org/W2914635984",
    "https://openalex.org/W2529996553",
    "https://openalex.org/W2883583109",
    "https://openalex.org/W3185456481",
    "https://openalex.org/W3133523400",
    "https://openalex.org/W1975147762",
    "https://openalex.org/W2784270883",
    "https://openalex.org/W3127493072",
    "https://openalex.org/W3174777205",
    "https://openalex.org/W2897337442",
    "https://openalex.org/W2970352191",
    "https://openalex.org/W2610148085",
    "https://openalex.org/W2923057410",
    "https://openalex.org/W2520601585",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2953798723",
    "https://openalex.org/W2765224015",
    "https://openalex.org/W2558999090",
    "https://openalex.org/W3011286504",
    "https://openalex.org/W2890507936",
    "https://openalex.org/W2887447356",
    "https://openalex.org/W2982209755",
    "https://openalex.org/W2128186735",
    "https://openalex.org/W2059912458",
    "https://openalex.org/W2963026768",
    "https://openalex.org/W2963459876",
    "https://openalex.org/W3044724994",
    "https://openalex.org/W2099071242",
    "https://openalex.org/W2309693750",
    "https://openalex.org/W2328672918",
    "https://openalex.org/W3006953393",
    "https://openalex.org/W1997176810",
    "https://openalex.org/W2060531713",
    "https://openalex.org/W1988037271",
    "https://openalex.org/W1973552820",
    "https://openalex.org/W2103445331",
    "https://openalex.org/W3010145447",
    "https://openalex.org/W2052030759",
    "https://openalex.org/W2129191085",
    "https://openalex.org/W4238567307",
    "https://openalex.org/W2169450835",
    "https://openalex.org/W3185391990",
    "https://openalex.org/W6748645487",
    "https://openalex.org/W2775714759",
    "https://openalex.org/W2325811289",
    "https://openalex.org/W2050066735",
    "https://openalex.org/W2014582878",
    "https://openalex.org/W2256578114",
    "https://openalex.org/W2037389769",
    "https://openalex.org/W2167279371",
    "https://openalex.org/W2900420896",
    "https://openalex.org/W2061937956",
    "https://openalex.org/W3100751385",
    "https://openalex.org/W3098269892"
  ],
  "abstract": null,
  "full_text": "Article https://doi.org/10.1038/s41467-022-35692-6\nLeveraging molecular structure and bioac-\ntivity with chemical language models for de\nnovo drug design\nMichael Moret 1, Irene Pachon Angona1,L e a n d r oC o t o s1,S h e nY a n2,\nKenneth Atz 1, Cyrill Brunner1, Martin Baumgartner2,\nFrancesca Grisoni 1,3,4 & Gisbert Schneider1,5\nGenerative chemical language models (CLMs) can be used for de novo mole-\ncular structure generation by learningfrom a textual representation of mole-\ncules. Here, we show that hybrid CLMs can additionally leverage the bioactivity\ninformation available for the training compounds. To computationally design\nligands of phosphoinositide 3-kinase gamma (PI3Kγ), a collection of virtual\nmolecules was created with a generative CLM. This virtual compound library\nwas reﬁned using a CLM-based classiﬁer for bioactivity prediction. This second\nhybrid CLM was pretrained with patented molecular structures andﬁne-tuned\nwith known PI3Kγ ligands. Several of the computer-generated molecular\ndesigns were commercially available, enabling fast prescreening and pre-\nliminary experimental validation. A new PI3Kγ ligand with sub-micromolar\nactivity was identiﬁed, highlighting the method’s scaffold-hopping potential.\nChemical synthesis and biochemical testing of two of the top-ranked de novo\ndesigned molecules and their derivatives corroborated the model’s ability to\ngenerate PI3Kγ ligands with medium to low nanomolar activity for hit-to-lead\ne x p a n s i o n .T h em o s tp o t e n tc o m p o u n d sled to pronounced inhibition of PI3K-\ndependent Akt phosphorylation in a medulloblastoma cell model, demon-\nstrating efﬁcacy of PI3Kγ ligands in PI3K/Akt pathway repression in human\ntumor cells. The results positively advocate hybrid CLMs for virtual compound\nscreening and activity-focused molecular design.\nComputational methods have become key players in hit and lead dis-\ncovery in pharmaceutical research, complementing experimental\nhigh-throughput screening\n1. Bespoke virtual compound libraries pro-\nvide access to untapped regions of the chemical space2,t h e r e b y\nextending the diversity of potential drug candidates. However, owing\nto the potentially unlimited size of virtual chemical libraries, concerns\nhave been raised over the pragmatism of successfully screening\nbillions of molecules virtually with a potentially high risk of false\npositives\n2,3. To mitigate some of these challenges, researchers have\nemployed generative deep learning models to construct compounds\non demand by de novo design and to obtain small, focused virtual\ncompound libraries\n4,5. A variety of data-driven approaches can be used\nto generate focused virtual chemical libraries and create molecules\nwith the desired properties\n5– 18. Chemical language models (CLMs) are\nReceived: 26 October 2021\nAccepted: 19 December 2022\nCheck for updates\n1ETH Zurich, Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, 8093 Zurich, Switzerland.2University of Zurich, University Children’s\nHospital, Children’s Research Center, Pediatric Molecular Neuro-Oncology Research, Lengghalde 5, 8008 Zurich, Switzerland.3Eindhoven University of\nTechnology, Institute for Complex Molecular Systems and Eindhoven Artiﬁcial Intelligence Systems Institute, Department of Biomedical Engineering, Groene\nLoper 7, 5612AZ Eindhoven, The Netherlands.4Center for 393 Living Technologies, Alliance TU/e, WUR, UU, UMC 394 Utrecht, Utrecht 3584 CB, The\nNetherlands.5ETH Singapore SEC Ltd, 1 CREATE Way, #06-01 CREATE Tower, Singapore 138602, Singapore.e-mail: f.grisoni@tue.nl; gisbert@ethz.ch\nNature Communications|          (2023) 14:114 1\n1234567890():,;\n1234567890():,;\nbased on neural networks for processing string representations of\nmolecules (e.g., simpliﬁed molecular input line entry system [SMILES]\nstrings; Fig.1a)5,7,19. CLMs have already been successfully employed to\ngenerate focused virtual chemical libraries. Examples of de novo-\ndesigned bioactive molecules include inhibitors of vascular endothe-\nlial growth factor receptor 2 (VEGFR-2) pathway\n7,a sw e l la sn u c l e a r\nhormone receptor modulators20– 23.\nThe creation of a focused virtual chemical library with a CLM\ngenerally includes three basic steps: (i) model pretraining with a large\nset of molecules to learn the SMILES grammar and the feature dis-\ntribution of the pretraining data, (ii) transfer learning with a smaller set\nof molecules (ﬁne-tuning set) to bias the molecule generation by the\nCLM toward the chemical space of interest, and (iii) sampling of new\nmolecules from the data distributions modeled in steps (i) and (ii)\n5,24.\nThere are alternative approaches for CLM development, e.g., model\nﬁne-tuning (step ii) by reinforcement learning\n6,25.\nIn this study, we developed a data-driven molecular design pipe-\nline that leverages both the structural and bioactivity information of\nknown ligands to generate bespoke molecules by learning from a\ntextual representation of molecules. We pretrained two CLMs, each\nwith a distinct pretraining strategy, on a large set of patented com-\npound structures (one for molecular generation and one for classiﬁ-\ncation). Both CLMs wereﬁne-tuned on inhibitors of phosphoinositide\n3-kinase gamma (PI3Kγ), which is an anticancer, anti-inﬂammatory, and\nimmunomodulatory drug target\n26,27. For rapid validation, commer-\ncially available compounds from the set of de novo-generated mole-\ncules were testedﬁrst, as opposed to synthesizing them, revealing a\nnew ligand of phosphoinositide 3-kinase gamma (PI3Kγ) with sub-\nmicromolar activity. This result conﬁrmed the scaffold-hopping cap-\nability of the de novo molecular design pipeline. In addition, two of the\ntop-ranked de novo-generated molecular designs and several deriva-\ntives were synthesized. These compounds potently inhibited PI3Kγ\nactivity, corroborating the applicability of the computational\napproach to hit-to-lead optimization.\nResults and discussion\nMolecular design and scoring were performed in two steps, each of\nwhich was executed by a distinct CLM: (i) molecular de novo design\nand (ii) reﬁnement of the generated virtual molecule library using the\navailable ligand bioactivity data for the target of interest (PI3Kγ).\nFocused library generation\nChemical language model. A CLM based on a long short-term\nmemory (LSTM) neural network and SMILES strings as input was\ndeveloped for the de novo generation of a focused virtual chemical\nlibrary for PI3Kγ\n28. To learn from unlabeled data, CLMs leverage“self-\nsupervised” learning29.S p e c iﬁcally, the CLM was trained with an\nautoregressive approach, i.e., the process of iteratively predicting the\nnext character in a SMILES string given all the previous characters in\nthe string (Fig.2a)\n30. In previous studies, CLMs were pretrained on\nmolecules with known biological activity (IC50,E C50, Kd,a n dKi)< 1µM\nretrieved from the ChEMBL database20,23,31– 33. Although the training set\ncan capture the general features ofbioactive compounds, it does not\nnecessarily represent the physicochemical properties of approved\ndrugs. Here, to enable the CLM to capture features related to approved\ndrugs, we used 839,674 molecules from the US patent database for\npretraining\n34. We hypothesized that patented compounds are more\nlikely to become marketed drugs than the bioactive molecules\ndeposited in ChEMBL. Transfer learning was performed to properly\nfocus the pretrained CLM toward the target space of PI3Kγ ligands. For\ntransfer learning, 46 PI3Kγ inhibitors with IC\n50 ≤ 100 nM were selected\nfrom the Drug Target Commons (DTC) database35.\nNucleus sampling for molecule generation. CLMs generate new\nmolecules by extending strings from a“start” character until the“stop”\ncharacter is sampled or when reaching a preset maximum string length.\nString characters are iterativelyadded by weighted random sampling\nfrom the probability distribution learned by the CLM during training.\nThe more likely a given character is at a given step according to the\nFig. 1 | De novo molecular generation with the CLM. aSMILES string repre-\nsentation of a molecule.b Example of the effect of the temperature parameter on\nthe probability distribution learnt by the CLM.c Example of the effect of the\nnucleus sampling threshold. Only the characters N and C can be sampled here.\nd Fréchet ChemNet Distance (FCD) comparison between temperature and nucleus\nsampling after the pretraining (reported as the mean with standard deviation over\n10 repeats with 5000 molecules sampled per repeat).e Comparison of the novelty\nof the generated SMILES strings during the transfer learning between temperature\nsampling (temperature = 0.7) and nucleus sampling (threshold = 0.85). Mean values\n(lines) and standard deviations (shaded areas) are shown for ten repeats (1000\nSMILES strings were sampled every second epoch over 40 epochs). Novelty is\nexpressed as the percentage of SMILES strings generated that were valid and not\nincluded in either the training or theﬁne-tuning data.\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 2\nprobabilities learned by the CLM, the more often it will be sampled, and\nvice versa. Narrowing the probabilities learned by the CLM with a\nparameter (the so-called temperature; Fig.1b) generally improves the\nsampling process\n31. This improvement occurs in terms of (i) the quality\nof the SMILES strings generated, as reﬂected by their validity (gram-\nmatically valid SMILES strings), uniqueness (nonrepetitive molecules),\nand novelty (molecules not present in the pretraining andﬁne-tuning\ndata) and (ii) the similarity of the sampled virtual chemical libraries to\nthe reference data in terms of their chemical structures and predicted\nbioactivities, as measured by the Fréchet ChemNet Distance (FCD)\n36.\nHowever, with this“temperature sampling” approach, unlikely SMILES\ncharacters can be sampled, which could result in the construction of\nmolecules that do not match the design objectives. Here, aiming to\nprevent the CLM from picking unlikely SMILES characters by tempera-\nture sampling, we employed“nucleus sampling”\n37.T h i sm e t h o dr eﬂects\nthe conﬁdence of the model in its predictions by allowing only the most\nprobable character(s) to be sampled using a probability threshold\nbased on the cumulative probabilities of the SMILES characters (Fig.1c).\nNucleus sampling improved upon temperature sampling in terms\nof lower FCD values (Fig.1d), indicating a greater overall similarity of\nthe de novo-generated molecules to the pretraining set in terms of\nstructural and bioactivity properties. During transfer learning, nucleus\nsampling generally improved the quality of the sampled molecules in\nterms of the novelty of the SMILES strings compared to the best\ntemperature sampling data obtained (Fig.1e)\n33. The results were stable\nover a range of sampling threshold values (Supplementary Table 1).\nHowever, nucleus sampling did not outperform temperature sampling\nin terms of the uniqueness, validity, and novelty of the SMILES strings\ngenerated after the pretraining (Supplementary Table 2). To create a\nPI3Kγ focused chemical library during transfer learning, we used\nnucleus sampling with a threshold of 0.85. A total of 5000 SMILES\nstrings were sampled over 50 transfer learning epochs with ten repe-\ntitions (5000 × 50 × 10). A total of 2,500,000 SMILES strings were\ngenerated, of which 1,121,735 were valid, unique, and novel (non-\nidentical) compared to both the training andﬁne-tuning compounds.\nBioactivity prediction with a hybrid chemical language model\nLeveraging bioactivity data for molecule selection.T h ea v a i l a b i l i t y\nof bioactivity data for theﬁne-tuning molecules permitted the training\nof a bioactivity prediction model to select the most promising de novo\ndesigns38. Chemoinformatics methods often rely on precomputed\nfeatures (molecular descriptors), combined with a machine learning\nalgorithm for molecular property prediction. In this study, we aimed to\nexplore the potential of a SMILES string-based hybrid CLM to predict\nbioactivity. This neural network model combines a generative CLM\nwith a classi ﬁer network. Given that (i) inactive molecules\non PI3Kγ were annotated with pIC\n50 = 4.0 (Fig.2c) and (ii) there is a\nnatural ordering of the PI3Kγ ligands according to their pIC50 values,\nthe bioactivity prediction task was framed as an ordinal classiﬁcation\ntask, i.e., classiﬁcation with a class order39.S u c ham o d e lc o n s i d e r s\nboth the active and inactive compounds for training and preserves\nboth the class labels and the class order. For model training, we\ndeﬁned three class labels: “inactive” (pIC50 ≤ 4.0, 34 molecules),\n“moderately active” (4.0 < pIC50 ≤ 6.5, 121 molecules), and “highly\nactive” (pIC50 > 6.5, 43 molecules). The CLM generated a focused vir-\ntual chemical library by leveraging the structural information of the\nmolecules used forﬁne-tuning, while the classiﬁer layer factored their\nactivity labels into the model (Fig.2d).\nWe explored two different pretraining strategies for feature\nlearning with a large amount of unlabeled data.\n1. Autoregressive pretraining (Fig.2a). This strategy is analogous to\nthe one performed for the generative CLM.\n2. ELECTRA (efﬁciently learning an encoder that classiﬁes token\nreplacements accurately) pretraining (Fig.2b)\n40. The ELECTRA\napproach is based on training a model to distinguish between\n“real” input characters and“corrupt” ones, which was previously\nshown to be useful for contextual representation of natural\nlanguage\n40. We adapted ELECTRA for the CLM training with an\nLSTM model and SMILES strings as input28. The training data\ncontained corrupted input SMILES strings generated by randomly\nsubstituting multiple characters with other characters of the\nab\n...\nCorruption\nCN1CC=CC1=O\nCLMC N\nCN 1\nCN1CC=CC1= O\nCN1CC=CC1=O\nELECTRA\nReplaced\nOriginal\nC  C    1  C  C  =  C  C  1  =  F\nCLM\nCLM ROO O O O O O O O R\nc d\nCLM\nE-CLM\nGeneration\n99 votes\n1 vote\nPredictive ensemble \n(100 models)\nRefined chemical space\ninactive moderately active highly active\nFig. 2 | Bioactivity prediction. aA CLM for molecule generation iteratively pre-\ndicts the next character in a SMILES string given the preceding characters (“auto-\nregressive” approach).b An E-CLM (a CLM pretrained with the ELECTRA method) is\ntrained on corrupted SMILES strings aiming to predict, for each string character,\nwhether it is the original (correct) or a corrupted (substituted) character.c Activity\ndistribution of the PI3Kγ ligands. Compounds with annotated pIC50 ≤ 4.0 were\nconsidered“inactive”,a n dap I C50 value of 6.5 was used to separate the“moderately\nactive” from the“highly active” compounds.d The molecular structures (in the\nform of a SMILES string) of theﬁne-tuning set were used to focus the CLM (pre-\ntrained on the US patent database) on the chemical space of the target of interest\n(PI3Kγ). To account for the uncertainty in the predictions, we employed an\nensemble of 100 models to rank the generated molecules by the number of“votes”.\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 3\nSMILES language. The CLM was trained to spot these corrupted\ncharacters.\nWe hypothesized that, compared to autoregressive pretraining,\nELECTRA pretraining has amore appropriate inductive bias (i.e., the set\nof algorithmic assumptions to solve a given task) to extract useful fea-\ntures for ordinal classiﬁcation. The inductive bias of autoregressive\npretraining is particularly suited for generating SMILES strings because\nthe training and generative tasks are the same, namely, adding char-\nacters iteratively. However, ligands of the same macromolecular target\ntend to have similar chemical substructures, and, therefore, the ability\nof a model to distinguish small structural changes was deemed relevant.\nAt the same time, small structural changes might lead to a drastic var-\niation in biological activity (the so-called activity cliffs\n41). Hereinafter,\nthe model that was pretrained with the ELECTRA method is referred to\nas “E-CLM”.\nTo probe the effect of the pretraining scheme on the predictions,\nwe added only a single feedforward layer to the pretrained CLM and\nE-CLM for bioactivity prediction. This additional network layer con-\nsisted of three neurons, one for each of the three bioactivity classes. It\nwas added to ﬁne-tune the entire network for bioactivity\nprediction\n42,43. To mitigate the class data imbalance, we applied over-\nsampling to the classes with fewer data (i.e., the“inactive” and “highly\nactive” classes)44.\nOverall, we found that the E-CLM performed better than the\nstandard CLM for the task of identifying the most active molecules,\nwhile minimizing the number of inactive molecules misclassiﬁed as\n“highly active”. For the chosen threshold (0.4), the E-CLM had a false\npositive rate of 10.0% compared to 46.7% for the CLM for the same true\npositive rate (71.3%) (Supplementary Figs. 2a, 3a). Fine-tuning of all\nneural network weights performed better than keeping the weights of\none of the two layers constant (Supplementary Fig. 2a, c, d). These\nresults highlight the importance of choosing an appropriate pretrain-\ning method for cheminformatic applications, depending on the\ndownstream task, e.g., data generation or classiﬁcation.\nIncreasing the prediction conﬁdence using deep ensemble learn-\ning. Deep learning models suffer from a decrease in performance when\napplied to out-of-domain data\n45, a well-known issue in quantitative\nstructure-activity relationship modeling46,47.T oi n c r e a s et h ec o n -\nﬁdence in the bioactivity predictions, we used a deep ensemble model\nby combining the predictions of multiple models with a majority vot-\ning approach\n48,49. Owing to the nondeterministic optimization process,\nrepeats of the same CLM training procedure will lead to different\nmodels. Deep ensemble learning has been shown to perform well\nacross different domains to account for the predictive uncertainty of\nthe models, while having the beneﬁt of being straightforward to\nimplement\n50. Accordingly, 100 different E-CLM classiﬁers were trained\non the bioactivity prediction task. The level of conﬁdence in a pre-\ndiction was deﬁned as the number of models that classiﬁed a given\ninput molecule as“highly active”.\nWith increasing conﬁdence levels, the number of molecules pre-\ndicted as“highly active” decreased (Fig.3a), a documented effect of\nensemble voting51. None of the molecules from the focused virtual\nlibrary was predicted as“highly active” with all 100 votes. Forty-seven\nde novo designs were predicted as highly active, with 99 votes (Sup-\nplementary Figs. 4, 5). Among these top-ranked molecules, 64% fea-\nt u r e dan e wa t o ms c a f f o l da n d6 2 %f e a t u r e dan e wg r a p hs c a f f o l dw i t h\nrespect to theﬁne-tuning set (see Supplementary Fig. 6 for exemplary\nmolecule decompositions into graph and atom scaffolds)\n52,53.H i g h e r\nconﬁdence was reﬂected in the increased substructure similarity of the\npredicted actives to the molecules of theﬁne-tuning set, as captured\nby the Tanimoto index computed on Morganﬁngerprints (Fig.3b)54.I n\nline with the chemical similarity principle55, this observation suggests\nthat there is a greater chance of identifying active molecules when the\nn u m b e ro fv o t e si sh i g h .T h eﬁve most dissimilar molecules among the\ntop-ranked molecules had a similarity to their respective nearest\nneighbors of theﬁne-tuning set, ranging from 53 to 58% (Fig.3c). The\nclosest molecules of the ﬁne-tuning set have a similarity ranging\nbetween 77 and 100%, meaning that one molecule of theﬁne-tuning\ns e tw a sr e - c r e a t e db yt h eC L M ,a l t h o u g hw i t had i f f e r e n ts t e r e o -\nchemistry (Fig.3d), a structural feature that is not captured by Morgan\nﬁngerprints. This result highlights the potential of the approach to\nexplore both closely related molecules to known bioactives, e.g., for\nstructure-activity relationship studies or hit-to-lead expansion, as well\nas more structurally innovative compounds for“scaffold hopping”.\nIn vitro bioactivity of commercially available compounds\nFor a proof of concept, some of the molecules generated by the CLM\nwere tested for PI3Kγ binding in vitro. To optimize the efﬁciency in\nterms of both time and resources, we selected the test molecules from\nthe reﬁned virtual chemical libraries that could be purchased from\ncommercial suppliers, as opposed to synthesizing the de novo designs.\nIn total, 16 computer-generated molecules were commercially avail-\nable. Their predictive conﬁdence ranged from 80/100 votes for com-\npound 1 to 24/100 votes for compound16 (Fig. 4).\nAlthough none of the ordered molecules was part of the top-\nranked set (i.e., receiving 99/100 votes), compound1, the molecule\nwith the highest number of votes (80/100), was a hit, withK\nd ranging\nbetween 0.6 and 0.7µM( N = 2; 670 nM; 620 nM) (Figs.4, 5 and Sup-\nplementary Table 3). None of the lower-ranking compounds inhibited\nPI3Kγ in the biochemical assay (Fig.4). The conﬁdence level of our\nensemble correctly prioritized compound1 (active in vitro) over\ncompounds 2 and 4 (inactive in vitro), despite all of them having the\nsame scaffold but with different substituents (Fig.4). We hypothesize\nthat this might be due to the positive effect of the ELECTRA pretrain-\ning, which was aimed at recognizing the effect of small structural\nchanges.\nCompound 1 has a new atom scaffold compared to all molecules\nin the ChEMBL database (version 28) annotated with“pActivity” ≥ 5.0\non PI3Kγ (pActivity: −log(molar IC\n50,X C50,E C50,A C50, Ki, Kd,o r\n“potency”)). It constitutes a“scaffold hop” from known inhibitors. The\nmost similar molecule among these has a Tanimoto similarity of 34% to\nthat of compound 1 (Supplementary Fig. 7). When screening the\ncommercial library with the ensemble of predictive models, com-\npound1 (80/100 votes) would have appeared in the top 52, showcasing\nthe effect of combining de novo design with scoring. It should be\nnoted that no commercially available molecule received more than 89\nvotes. The presence of a top-ranking de novo design with 99 out of 100\nvotes highlights the ability of generative molecular design to explore\nthe chemical space beyond commercially available compounds.\nAiming to benchmark these results, similarity-based virtual\nscreening using the commercial compound library was carried out\nusing Morgan ﬁngerprints (Tanimoto index) and the ﬁne-tuning\nm o l e c u l e sa sq u e r i e s\n56.C o m p o u n d1 ranked in position 25,693, high-\nlighting the ability of our pipeline to uncover a hit that would likely not\nhave been found by chemical structure-based similarity searching. The\nin vitro validation advocates the E-CLM ensemble prediction approach\nfor ranking the computer-generated molecular designs, aiming to\nidentify bioactive molecules with new scaffolds (core structures).\nSynthesis and bioactivity testing generated molecules\nMotivated by the positive results of the scaffold-hopping exercise\nfor hitﬁnding, we synthesized two of the computer-generated top-\nranked molecules (17, 20; 99/100 votes) and derivatives thereof (18,\n19, 21, 22). De novo designs 17 and 20 were selected from all\ncomputer-generated molecules receiving 99/100 votes by the\nE-CLM ensemble model. Aiming to distinguish between these top-\nscoring molecules we used TIGER software (v19.7, inSili.com LLC)\nfor target prediction and grouped the molecules according to their\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 4\nscaffolds. Scaffold S1 (Fig. 5) was the most frequently generated\ncore of the de novo designs, for which PI3K binding or inhibition\nwas predicted by TIGER. De novo compounds17 and 20 received\nfavorable TIGER scores (1.8 and 2.1). They are structurally closely\nrelated to the known dual Bruton’s tyrosine kinase (Btk) and PI3Kδ\ninhibitor 23 and PI3Kγ/δ inhibitor 24 (Fig. 5)\n57,58.I ti sn o t e w o r t h y\nthat molecules 17, 20, 23, and 24 were not contained in the CLM\ntraining or ﬁne-tuning data. The highest similarity of17 and 20 to\ncompounds from the CLM ﬁne-tuning set were 57 and 63%,\nrespectively. These compounds feature the same pyrazolopyr-\nimidine kinase hinge binding motif, but the de novo-generated\nmolecules structurally differ in sidechain positions R\n1-4 (Fig. 5). The\ngenerative molecule construction method re-created the known\ngeneric scaffold S1 with new sidechain variations. However,\nensemble E-CLM scoring alone could not differentiate between\ncompounds 17 and 20. Both received equally conﬁdent votes. We\nchose this particular example to investigate the applicability of the\ngenerative approach to hit expansion rather than hitﬁnding. Such a\nsituation emulates hit-to-lead development in medicinal chemistry.\nMolecules17 and20 could not be obtained via the preferred retro-\nsynthetic routes suggested by IBM RXN (www.rxn.res.ibm.com)\n59.W e ,\ntherefore, devised suitable synthesis paths manually. The compounds\nwere afforded in seven and four steps, respectively (Supplementary\nInformation: Chemical Synthesis and Analytics). Puriﬁed compounds\nwere tested for direct PI3Kγ binding. The results of this assay revealed\npotent activity in the nanomolar range (K\nd values, expressed as the\naverage ofN = 2 independent experiments:17,6 3 n M ;18,5 2 n M ;19,\n160 nM;20,1 2 0n M ;21, 290 nM;22, 13 nM; Supplementary Figs. 8– 10).\nCompounds 17 and 20 were considerably more active than hit com-\npound 1,w h i c hw a sa p p r o p r i a t e l yr eﬂected in the more conﬁdent\nE-CLM voting (99/100 for17 and 20;8 0 / 1 0 0v o t e sf o r1). The most\npotent compound22 was devised manually, motivated by the original\nde novo designs.\nAiming to rationalize the difference in activity between com-\npound 1 and the 4-amino-pyrazolopyrimidine derivatives 17– 22,\nautomated ligand docking was performed using GOLD software60.\nPlausible ligand binding poses in the modeled active site of human\nPI3Kγ (PDB ID: 3ENE)\n57 were obtained for all molecules (Fig. 6).\nba\nN\nN\nF\nOH\nNH2\nN\nN\nd\nNH2\nN\nN\nI\nOH\nN\nN\nNH2\nN\nN\nBr\nOH\nN\nN\nF\nNH2\nN\nN\nCl\nOH\nN\nN\nF\nN\nN\nCl\nOH\nNH2\nN\nN\nc\nN N\nNF\nN\nO\nN\nNH2N\nN\nN\nN\nO NH2\nO\nOH\nNH2\nN\nN N\nN\nHO OH\nNH2\nO\nOH\nNH2\nN\nN N\nN\nCl OH\nN\nCl\nNH2\nN\nN\nAtom scaffold: Yes \nGraph scaffold:  Yes\nMost similar: 53%\nAtom scaffold: Yes  \nGraph scaffold: Yes \nMost similar: 55%\nAtom scaffold: No \nGraph scaffold: No\nMost similar: 56% \nAtom scaffold: No\nGraph scaffold: No\nMost similar: 57% \nAtom scaffold: No\nGraph scaffold: No\nMost similar: 58%\nAtom scaffold: No \nGraph scaffold: No \nMost similar: 100% \nAtom scaffold: No\nGraph scaffold: No \nMost similar: 82% \nAtom scaffold: No \nGraph scaffold: No \nMost similar: 81% \nAtom scaffold: No \nGraph scaffold: No\nMost similar: 81% \nAtom scaffold: No\nGraph scaffold: No\nMost similar: 77% \nN\nN\nN\nNH2\nO OH\nCl\nCl\nN\n/ 105\nFig. 3 | Molecule ranking with a deep ensemble model. aNumber of molecules in\nthe reﬁned virtual chemical library that were predicted as“highly active” as a\nfunction of the number of votes (conﬁdence level).b Average structural similarity\n(Tanimoto similarity index computed on Morganﬁngerprints) of each de novo\ndesign to theﬁne-tuning set as a function of the number of votes. The solid line\nrepresents the mean value, with the shaded area representing the standard\ndeviation.c Top-ranked designs (99/100 votes) selected with the most distant\nnearest neighbor, whose similarity is indicated below the structure (“Most similar”)\nin theﬁne-tuning set. The atom (“Atom scaffold”) and graph (“Graph scaffold”)\nscaffold novelty of the structure with respect to theﬁne-tuning set is indicated\nbelow each structure (“Yes”:n e w ,“No”: not new).d Top-ranked designs (99/100\nvotes) selected with the closest nearest neighbor in theﬁne-tuning set.\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 5\nInduced-ﬁt docking of molecules17– 22 suggested the aromatic and\nexocyclic nitrogens forming key hydrogen bridges to the kinase hinge\nresidues Glu880 and Val882. Free energies of binding were estimated\nto range from −29.8 to −34.7 kJ mol\n−1 for compounds 1 and 17,\nrespectively (Supplementary Table 4). These values are generally in\nagreement with the experimental bioactivities, reﬂecting the relatively\nweaker kinase binding of compound 1.T h e4 - a m i n o -\npyrazolopyrimidine derivatives 17– 22 achieved lower estimated\nbinding energies than compound1, highlighting the importance of the\nhydrogen bridges to the kinase hinge residues Glu880 and Val882. At\nthe same time, the docking results also reveal shortcomings of the\nquantitative estimation of free energies, which, for this given an\nN\nN N\nO\nO\nF F\n1\nN\nN N\nN\nNH2\nCl\nOH\n17\nN\nN N\nN\nNH2\nCl\nOH\n18\nN\nN N\nN\nNH2\nBr\nO\n19\nO OO\nNN\nN N\nCl\nOH\nNH2\n23\nN\nN N\nN\nNH2\nOH\n20 21 22\nCl\nN\nN N\nN\nNH2\nOH\nN\nN N\nN\nNH2\nOH\nCl\nCl\nN\nN N\nN\nNH2\nR1\nR2-4\nS1\n68%\n59%\nNN\nN N\nOO\nNH2\n24\n76%\n83%\nFig. 5 | Chemical structures of bioactive ligands.Computer-generated molecule1\nis a commercially available PI3Kγ ligand identiﬁed by the chemical language model.\nPercent values (Tanimoto coefﬁcient) reﬂect the similarity of the synthesized\ncomputer-generated molecules17 and 20 to the known PI3K inhibitors23 and 24.\nCompounds 18, 19 and 21, 22 are analogs of molecules17 and 20, respectively.\nO\nFF\nN N\nNO\n1 | 80/100 | 640 nM \nO\nNF\nF\nNH\nOH\n9 | 41/100 | -\nO\nNN\nS O\n5 | 53/100 | -\nO\nNO\nHO N O\n13 | 29/100 | -\nO\nFFF\nN N\nN\nNO\n2 | 79/100 | -\nO\nN\nH2N\nO\n6 | 45/100 | -\nO\nN\nCl O\nO\n14 | 28/100 | -\nO\nNH\nN\nBr\nN\nO\n10 | 40/100 | -\nO\nCl N O\nO\n7 | 42/100 | -\nO\nNF\nN O\nO\n3 | 72/100 | -\nO\nNNCl\nO O\n11 | 34/100 | -\nO\nN\nH\nN\nN+\nOO -\nO\n15 | 27/100 | -\nO\nFF\nN N\nN\nNO\n4 | 66/100 | -\nO\nN\nH2N N O\nO\n12 | 33/100 | -\nO\nO\nH\nN O\n8 | 41/100 | -\n16 | 24/100 | -\nO\nN\nO\nO\nO\nO\nOH\nFig. 4 | Commercially available compounds tested for PI3Kγ inhibition.Com-\npounds 1– 16 are shown, together with the number of votes from the ensemble of\nthe maximum number of 100 possible votes and the experimentally determined\nbinding constantKd.T h ea b s e n c eo fav a l u e(−) indicates no observed binding of\nthe compound to the target.\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 6\nexample, failed to correctly rank the 4-amino-pyrazolopyrimidine\nderivatives 17– 22 according to their experimentalKd values (Supple-\nmentary Table 4).\nTaken together, the results indicate that the molecular design\napproach presented here could identify both new scaffolds and\nstructural analogs of bioactive compounds for computer-assisted hit\nﬁnding and expansion. E-CLM ensemble scoring proved applicable to\nvirtual ligand screening but could not differentiate between structu-\nrally closely related potent ligands. Using an external scoring function\n(TIGER software) for target prediction proved useful in this study,\ncomplementing the twin-CLM approach.\nTo conﬁrm the biological activities of the most potent com-\npounds 18 (K\nd = 52 nM) and22 (Kd = 13 nM) in cells, we tested com-\npound effects on epidermal growth factor receptor (EGFR)-induced\nactivation of AKT/protein kinase B (PKB), a well-established effector\ndownstream of EGFR-PI3K signaling in cancer61.I nr e s p o n s et og r o w t h\nfactor receptor and PI3K activation, AKT is phosphorylated on Ser473\nby the Rictor-mTOR complex\n62. Thus, the phosphorylation of AKT on\nSer473 can be used as a surrogate read-out for PI3K activity in cells.\nTreatment of the serum-starved human brain tumor cell line HD-MB03\nwith epidermal growth factor (EGF), the physiological ligand of the\nEGFR, leads to the phosphorylation of AKTS473 (Fig.7a and Supple-\nmentary Fig. 11). Pre-treatment of the cells with18 or 22 at 100 nM\nconcentration prevents AKTS473 phosphorylation (Fig.7a) and causes\nan ~70– 90% reduction in AKT phosphorylation levels (Fig.7b). The\nreduction in EGF-induced AKT phosphorylation by compounds18 and\n22 is comparable to the inhibition caused by an equimolar con-\ncentration of the pan-PI3Kα/β/γ/δ inhibitor copanlisib (BAY 80-6946)\nEGF\na\nb\n-        +       +      +      +-        +       +      +      +\nDMSO 18 22 Cop.\np-AKT (S473)\n70\n55\nkDa\nAKT\n70\n55\nGAPDH\n40\n35\nc\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100% relative pAKT(S473)\nEGF-\nDMSO 18 22 Cop.\n+ + + +\nIC50: \n18: 171.5 nM \n22: 187.7 nM \nCop.: 19.35 nM \n0 50 100 150 200 250\n0\n25\n50\n75\n100\n125\n150\nConc. (nM)\nCell viability (%)\n18\n22\nCop.\nFig. 6 | Compounds 18 and 22 repress PI3K-AKT signaling in tumor cells.\na Representative immunoblot analysis p-AKT (S473), AKT, and GAPDH (loading\ncontrol) using total lysates of human HD-MB03 tumor cells stimulated with\n10 ng ml−1 EGF for 15 min in the absence or presence of compounds18 or 22,o r\ncopanlisib (Cop.). Compounds and copanlisib were used at 100 nM concentration.\nDMSO was used as solvent control.b Quantiﬁcation of p-AKT levels relative to EGF-\nstimulated DMSO control.N = 2 from two independent experiments.c CellTiter-Glo\nassay to monitor the viability of cells after 72 h of exposure to increasing con-\ncentrations of18, 22, or copanlisib in a medium supplemented with FBS. A non-\nlinear ﬁt of inhibitor versus normalized response is shown. Means (dots) and SD\n(error bars) ofN = 4 (copanlisib) orN = 7 (compounds18 or 22) measurements\ncombined from two independent experiments are shown.\nFig. 7 | Docking poses of novel PI3Kγ inhibitors. aGlobal view of PI3Kγ (PDB ID:\n3ENE) with stick models of molecules21 (blue) and22 (magenta) docked into the\nactive site of PI3Kγ. b Close-up view of the suggested binding poses of molecules21\n(blue) and22 (magenta).c Close-up view of the binding poses of molecules17\n(magenta) and18 (blue). d Close-up view of the computed binding pose of mole-\ncule 1 (in blue).\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 7\nwith reported sub-nanomolar inhibitory activity against PI3Kα and\nPI3Kδ (PI3Kγ IC50 =6 . 5n M )63. In our medulloblastoma cell-based assay,\ncompounds 18, 22, and copanlisib had IC50 values of ~172, 188, and\n19 nM, respectively. To exclude the possibility that reduced AKT\nphosphorylation caused by compound18 and 22 treatments is the\nresult of reduced viability or cell death, we monitored the viability of\ncompound-treated cells using the CellTiter-Glo assay. We found that\nneither 18 nor 22 caused a signiﬁcant reduction in viability at 100 nM\nconcentration (Fig. 7c), thus excluding an indirect effect on AKT\nfunction due to toxicity. The predicted best-ﬁtI C\n50 values in the\nCellTiter-Glo assay for compounds18, 22, and copanlisib are ~172, 188,\nand 19 nM, respectively. In conclusion, both compounds18 and 22\nrepress the activation of the PI3K effector kinase AKT under physio-\nlogically relevant conditions in human tumor cells at a low nanomolar\nconcentration.\nDe novo drug design aims to generate new molecular scaffolds\nwith desired properties and, at the same time, suggest more subtle\nstructural modiﬁcations for hit-to-lead optimization. The results of this\nstudy positively advocate the CLM approach for both design tasks.\nMethodological improvements in CLM training advanced the sampling\nof target-focused virtual molecule libraries. The hybrid CLM classiﬁer\nincluded both structural and bioactivity information of theﬁne-tuning\nmolecules for the design of a virtual chemical library, thereby com-\nplementing the available method ological repertoire for virtual\nscreening. It remains to be determined in more detail to what extent\nthe CLM pretraining method affects model performance in the\ndownstream task, i.e., molecular generation or ordinal classiﬁcation.\nImportantly, CLM training was performed without data augmentation\nto study the positive effect of nucleus sampling on the generation of a\nSMILES string. Future improvement might be possible by combining\nnucleus sampling with data augmentation for CLM transfer\nlearning\n33,64– 66. Given the setup of the present study, it was not possible\nto determine whether our hypothesis regarding the beneﬁcial effect of\nmodel pretraining on patented chemical structures holds true. The\nlong time required for hit-to-lead expansion and preclinical and clinical\ndrug development until a marketed drug is obtained will likely pre-\nclude such an analysis. Irrespectively, three de novo designs were\nsuccessfully tested for bioactivity. Hit compounds1 (80/100 votes),17,\nand 20 (99/100 votes) were correctly predicted to be active by CLM\nensemble scoring. The difference in votes is reﬂected in the high\nnanomolar and low nanomolar dissociation constants, respectively.\nObtaining rapid experimental validation of a set of readily available de\nnovo-designed molecules prior to embarking on de novo synthesis\nmight help assess the value of computationally generated activity-\nfocused chemical libraries. Future prospective studies will also have to\nassess the general applicability of this approach to other drug targets\nfrom different target families, and improve the prediction accuracy of\nthe CLM classiﬁer for structurally closely related molecules. Further-\nmore, although in this study we only considered in vitro bioactivity\n(direct binding and cellular activity), the workﬂow could be further\nextended to consider the multi-dimensional nature of drug discovery\nprojects (e.g., membrane permeability, aqueous solubility, and off-\ntarget activity) in a data-driven manner. Drawing any conclusions as to\nits superiority to other methods or broad applicability would be pre-\nmature. Additional prospective studies will be necessary to help\nanswer this question. Whether a particular de novo design method\nmay be considered“better” than another one critically depends on the\nspeciﬁc task, rendering any general method evaluation challenging.\nWe consider practical application the best judge and a way forward.\nThis study highlights the versatility of generative deep learning\nfor hit and leadﬁnding in drug discovery. The computational pipeline\ncan be used to both create new molecules and screen libraries of\nexisting compounds. We envision future projects in which de novo\ndesign methods areﬁrst validated for physically available molecules\nfrom a compound repository or commercial suppliers before investing\nin more expensive and time-consuming syntheses of computer-\ngenerated molecules. This strategy could potentially help accelerate\nthe design-make-test-analyze cycle of drug discovery\n67.\nMethods\nTarget selection\nThe protein target PI3Kγ26 was selected on the basis of the data avail-\nable in the DTC35 database. We selected one of the targets with the\nhighest number of annotated data points. Molecules with activity\nentries satisfying each of the following conditions were kept (standard\nrelation:“=”,s t a n d a r du n i t :“nM”,s u b s t r a t ev a l u e :“10”, substrate unit:\n“μM”, test inhibitor type: “competitive inhibitor”, compound con-\ncentration value:“0.001– 50”, test assay format:“biochemical”,t e s t\nassay type:“functional”, test assay subtype:“enzyme activity”). This\nﬁltering step resulted in a dataset containing 198 molecules. Duplicate\nentries of small molecules with orders of magnitude difference in their\nreported activity were deleted (Supplementary Fig. 1).\nTraining data\nThe training molecules were represented as canonical SMILES strings\nusing the RDKit package (v. 2019.03.2,https://www.rdkit.org). SMILES\nstrings with a length of up to 90 characters were retained and stan-\ndardized in Python (v. 3.6.5) by removing salts and duplicates. The\nCLM was pretrained on the pharmaceutical subset of the US patent\ndatabase\n34,68. After the processing, 839,674 unique molecules encoded\nas canonical SMILES strings constituted the pretraining data. PI3Kγ\ninhibitors with reported bioactivity≤100 nM in the DTC database were\nused for the CLM transfer learning (“ﬁne-tuning set”). This criterion\nresulted in aﬁne-tuning set containing 43 molecules.\nCLM pretraining andﬁne-tuning for the generation of SMILES\nstrings\nThe CLM model was implemented in Python (v. 3.6.5) using Keras (v.\n2.2.0, https://keras.io/) with the TensorFlow GPU backend (v. 1.9.0,\nhttps://www.tensorﬂow.org). The model was implemented as a recur-\nrent neural network with LSTM cells. The neural network was com-\nposed of four layers with a total of 5,820,515 parameters (layer 1:\nBatchNormalization, layer 2: 1024 LSTM cells, layer 3: 256 LSTM cells,\nand layer 4: BatchNormalization) and trained with SMILES data enco-\nded as one-hot vectors. The CLM was trained using the Adam opti-\nmizer (learning rate = 10\n−3) and the categorical cross-entropy loss\nfunction. The training was performed over 40 epochs, where one\nepoch was deﬁned as one pass over all the training data. Transfer\nlearning was performed by keeping the parameters of theﬁrst network\nlayer constant and training the second layer with a learning rate of 10\n−4.\nELECTRA pretraining\nThe E-CLM model was implemented in Python (v. 3.6.5) using Keras (v.\n2.2.0, https://keras.io/) with the TensorFlow GPU backend (v. 1.9.0,\nhttps://www.tensorﬂow.org). The ELECTRA model was implemented\nwith the same architecture as that of the generative CLM, i.e., as a\nrecurrent neural network with LSTM cells. Model training was per-\nformed with the Adam optimizer (learning rate = 10\n−3, 50 epochs) and\nthe binary cross-entropy loss function.\nOrdinal classiﬁer training\nThe hybrid CLM network contained the weights of the pretrained\nE-CLM plus an additional feedforward layer with three sigmoidal\nneurons. The model was trained to solve an ordinal classiﬁcation task,\nwhere each of the three output neurons corresponded to one class.k-\nMeans clustering (k =5 , S c i k i t - l e a r n ;https://scikit-learn.org/stable/)\nwas performed to group theﬁne-tuning molecules according to their\nsimilarity based on Morganﬁngerprints. Four groups were used for\ncross-validation and one for classiﬁer testing. The output threshold\nvalues, the number of transfer learning epochs, and the oversampling\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 8\nvalues of the less represented classes were deﬁned by cross-validation.\nThe best settings were selected based on the performance on the test\nset, which was used once (oversampling: +40 molecules for the two\nless represented classes, sigmoid threshold: 0.4, number of transfer\nlearning epochs: 200). Each of the 100 CLM models of theﬁnal\nensemble was trained with the best settings on all available data. The\nneural network architecture was composed of six layers with a total of\n5,646,982 parameters (layer 1: BatchNormalization, layer 2: 1024 LSTM\ncells, layer 3: 256 LSTM cells, layer 4: BatchNormalization, layer 5:\nDropout, and layer 6: Dense, with three units, each with a sigmoid\nactivation function) and was trained with SMILES encoded as one-hot\nv e c t o r s .T h em o d e l sw e r et r a i n e dw i t ht h eA d a mo p t i m i z e ra n dt h e\nbinary cross-entropy loss function (learning rate = 10\n−4,2 0 0e p o c h s ) .\nTemperature sampling\nSMILES characters were sampled using the softmax function para-\nmeterized by the sampling temperature. The probability of thei-th\ncharacter being sampled from the CLM predictions was computed as\n(Eq. 1)\nq\ni =e x pðzi=TÞ\n/C14 X\nj expðzj=TÞ, ð1Þ\nwhere zi is the CLM prediction for characteri, T is the temperature,\nand qi is the sampling probability of characteri.\nNucleus sampling\nSMILES characters were sampled with a temperature value equal to 1\n(Eq. 2), considering only characters whose cumulative probability was\ngreater than the nucleus parameter (“top vocabulary”):\nX\nx2VðpÞ\nPðx ∣ x1:i/C0 1Þ > p, ð2Þ\nwhereVðpÞ is the top vocabulary,x is an element of the vocabulary, and\np is the nucleus parameter.\nCommercial compound library screening\nMolecules were ranked based on their similarity (Tanimoto index,\nMorganﬁngerprints) to the molecules used toﬁne-tune the generative\nCLM. As a fusion rule, the reciprocal sum of ranks was calculated to\nobtain a score value,S, for each molecule (Eq.3)56:\nS =\nXN\ni =1\n1\nrank xi\n/C0/C1 , ð3Þ\nwhere i runs over allN ﬁne-tuning molecules, andrank(xi)i st h er a n k\nobtained from the similarity between the considered design and thei-\nth molecule of theﬁne-tuning set (the higher the similarity, the higher\nthe rank). GreaterS values correspond to better rank positions in the\nfused list of molecules.\nAutomated ligand docking\nThe crystal structure of human PI3Kγ (PDB ID: 3ENE) was retrieved\nfrom the Protein Data Bank (https://www.rcsb.org/) and prepared with\nMOE v.2019.0102 (Chemical Computing Group, Montreal, Canada)\nwith the following settings: QuickPrep module:“Preserve Sequence\nand Neutralize”; “Use Protonate 3D for Protonation’ =T r u e ;‘Allow\nASN/GLN/HIS“Flips” in Protonate 3D’=T r u e ;‘Delete Water Molecules\nFarther than 4.5 Å from Ligand or Receptor” = True, Tether Receptor:\nStrength = 10, Buffer = 0.25; Fix:“Atoms Farther than 8 Å from\nLigands”, hydrogens close to ligands notﬁxed; Reﬁne: “to RMS Gra-\ndient of 0.1 kcal/mol/Å ”; “Retain QuickPrep Minimization\nRestraints” = True. Ligand molecules were docked with GOLD v.5.2.2\nwithin MOE v.2019.0102 (Chemical Computing Group, Montreal,\nCanada): Ef ﬁciency = default, Score ef ﬁciency = 100; Early\nTermination = [number:3, RMS = 1.5], GOLD scoring, Induced Fit, 80\nposes per compound. Poses were reﬁned with MOE GBVI/WSA dG (40\nreﬁnement poses)\n69, and the top-scoring pose of each compound was\nselected for further analysis. The applied GoldScore function GBVI/\nWSA dG estimated free binding energies based on four components: (i)\nprotein– ligand hydrogen bond energy, (ii) protein– ligand van der\nWaals energy, (iii) ligand internal van der Waals energy, and (iv) ligand\ntorsional strain energy. Redocking of the crystalized small molecule\nligand (PDB ID: 3ENE, 1-methyl-3-naphthalen-2-yl-1H-pyrazolo[3,4-d]\npyrimidin-4-amine) yielded a root mean square deviation of 0.448 Å\nand an estimated binding energy of−33.93 kJ mol\n−1.\nBiochemical kinase binding assay\nPI3Kγ binding assays were performed by Euroﬁns Discovery (https://\nwww.euroﬁnsdiscoveryservices.com) on a fee-for-service basis. KINO-\nMEscan™ was used to determine the dissociation constantKd.T h e\nassay was based on the ability of a test compound to compete with an\nimmobilized active site-directed ligand. Competition of the test com-\npound with the immobilized ligand was measured via quantitative PCR\n(qPCR) of the DNA tag of DNA-tagged kinase\n70. An 11-point three-fold\nserial dilution of each test compound was prepared in 100% DMSO at\n100× ﬁnal test concentration and subsequently diluted to 1× in the\nassay (ﬁnal DMSO concentration = 1%). Dissociation constants were\nestimated with a standard dose-response curve using the Hill equation\n(Eq. 4)\n71:\nResponse = Background + Signal /C0 Background\n1+ KHill slope\nd =DoseHillSlope\n/C16/C17 , ð4Þ\nwhere the Hill slope was set to−1. Curves wereﬁtted using a nonlinear\nleast squareﬁt with the Levenberg– Marquardt algorithm72,73.\nCells and cell culture for in-cell activity analysis\nHD-MBO3 Group 3 medulloblastoma cells were cultured in RPMI\nmedium supplemented with 10% fetal bovine serum (FBS, both from\nSigma-Aldrich, St. Louis, USA), 1% Penicillin-Streptomycin, and 1%\nGlutaMAX (both from Gibco/Thermo Fisher Scientiﬁc, Waltham, USA).\nThe cells were maintained at 37 °C in a humidiﬁed atmosphere con-\ntaining 5% CO\n2. Chemicals: Copanlisib (BAY 80-6946, Selleckchem,\nMunich, Germany) and other compounds were dissolved in 100%\ndimethyl sulfoxide (DMSO) at a stock concentration of 10 to 100 mM\na n ds t o r e da t−20 °C. DMSO was used as solvent control in all assays.\nImmunoblotting\nThe cells were seeded in six-well plates and starved in a serum-free\nmedium for 48 h before treatment. Cells were pretreated with either\nDMSO (solvent control), 100 nM copanlisib (positive control) or\ncompounds for 3 h, and then treated for 15 min with 10 ng ml\n−1\nrecombinant human EGF protein (PeproTech, London, UK, Cat.100-\n15). Cells were then lysed using RIPA buffer (30 mM HEPES, pH 7.4,\n150 mM NaCl, 1% Nonidet P-40, 0.5% sodium deoxycholate, 0.1%\nsodium dodecyl sulfate, 5 mM EDTA) supplemented with protease\n(Complete Mini) and phosphataseinhibitors (PhosSTOP, both from\nRoche, Basel, Switzerland) and cleared by centrifugation for 5 min.\nProtein concentration was measured using the Pierce BCA Protein\nAssay Kit according to the manufacturer’s( T h e r m oF i s h e rS c i e n t iﬁc,\nWaltham, USA) instructions. Protein separation was performed on\nMini-Protean TGX (4– 20%) SDS-PAGE gel and transferred to PVDF\nmembranes (both from Bio-Rad, Hercules, USA). After 1 h of blocking\nwith 5% non-fat dry milk, membranes were probed with primary anti-\nAKT (#9272), anti-phospho-AKT (p-AktSer473) (#4060), and anti-\nGAPDH antibodies (#2118, all from Cell Signaling Technology, Danvers,\nUSA,). HRP-linked secondary antibodies were used to detect the pri-\nmary antibodies. Chemiluminescence detection was carried out using\nChemiDoc Touch Gel and Western Blot imaging system (Bio-Rad,\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 9\nHercules, USA). Integrated densities of protein bands from two inde-\npendent IB experiments were determined using Fiji software74.B a c k -\nground signal was subtracted from all measurements. p-AKT signal was\nnormalized to total AKT.\nCell viability/proliferation (Cell TiterGlo) assay\nCell viability was determined using CellTiter-Glo® 2.0 Cell Viability\nAssay (G9242, Promega, Madison, USA). About 500 cells per 20μlw e r e\nseeded in a ﬂat bottom 384-well plate (781098, Greiner bio-one,\nKremsmünster, Austria). Increasing concentrations of compounds\nwere deposited on cells using an HP Digital Drug Dispenser (Hewlett-\nPackard, Palo Alto, USA) with DMSO total volume normalization. After\n72 h, the CellTiter-Glo reagent was added (volume/volume) following\nthe manufacturer’s instructions. Luminescence representing the\nnumber of viable cells was quantiﬁed with a Cytation 3 imaging reader\n(BioTek, Winooski, USA). Measurements from a total ofN =4( c o p a n -\nlisib) or 7 (compounds18 or 22) technical replicas were combined\nfrom two independent experiments. Prism 9 software (GraphPad\nSoftware, San Diego, CA, USA) was used to calculate best-ﬁt values of\ninhibitor vs. normalized response and to predict IC\n50.\nChemical synthesis and analytics\nFor a full description of the chemical synthesis and compound analy-\ntics, see the Supplementary Material.\nTIGER target prediction\nTIGER software (version 19.7, inSili.com GmbH, Zurich, Switzerland)\nw a su s e da sd e s c r i b e di nr e f .75. Molecules were represented in terms\nof CopyCATS (version 3.2) topological pharmacophore descriptor\nvectors for input to TIGER\n76. Any predictions of PI3K subtypes were\nconsidered correct predictions.\nReporting summary\nFurther information on research design is available in the Nature\nPortfolio Reporting Summary linked to this article.\nData availability\nThe training data used in this study are available from Zenodo at\nhttps://zenodo.org/record/7370858 (https://doi.org/10.5281/zenodo.\n7370858).\nCode availability\nThe computational framework presented in this study and the pre-\ntrained neural network weights are available from Zenodo athttps://\nzenodo.org/record/7370858(https://doi.org/10.5281/zenodo.7370858).\nReferences\n1. Neves, B. J. et al. QSAR-based virtual screening: advances and\napplications in drug discovery.Front. Pharmacol.9,1 2 7 5\n(2018).\n2. Walters, W. P. Virtual chemical libraries.J. Med. Chem.62,\n1116–1124 (2019).\n3. Jain, A. N. Scoring noncovalent protein-ligand interactions: a con-\ntinuous differentiable function tuned to compute binding afﬁnities.\nJ. Comput. Aided Mol. Des.10,4 2 7–440 (1996).\n4. Schneider, G. & Fechner, U. Generating focused molecule libraries\nfor drug discovery with recurrent neural networks.Nat. Rev. Drug\nDiscov. 4, 649–663 (2005).\n5 . S e g l e r ,M .H .S . ,K o g e j ,T . ,T y r c h a n ,C .&W a l l e r ,M .P .G e n e r a t i n g\nfocused molecule libraries for drugd i s c o v e r yw i t hrecurrent neural\nnetworks.ACS Cent. Sci.4,1 2 0–131 (2018).\n6. Popova, M., Isayev, O. & Tropsha, A. Deep reinforcement learning\nfor de novo drug design.Sci. Adv.4, eaap7885 (2018).\n7. Yuan, W. et al. Chemical space mimicry for drug discovery.J. Chem.\nInf. Model.57,8 7 5–882 (2017).\n8. Ruddigkeit, L., van Deursen, R., Blum, L. C. & Reymond, J.-L. Enu-\nmeration of 166 billion organic small molecules in the chemical\nuniverse database GDB-17.J. Chem. Inf. Model.52,\n2864–2875 (2012).\n9. Liu, Q., Allamanis, M., Brockschmidt, M. & Gaunt, A. Constrained\ngraph variational autoencoders for molecule design. inThe Thirty-\nsecond Conference on Neural Information Processing Systems\n7795–7804 (Curran Associates Inc., 2018).\n1 0 . Y o u ,J . ,L i u ,B . ,Y i n g ,R . ,P a n d e ,V .&L e s k o v e c ,J .G r a p hc o n v o l u t i o n a l\npolicy network for goal-directed molecular graph generation. Pre-\nprint athttp://arxiv.org/abs/1806.02473(2018).\n11. Ikebata, H., Hongo, K., Isomura, T., Maezono, R. & Yoshida, R.\nBayesian molecular design with a chemical language model.J.\nComput. Aided Mol. Des.31,3 7 9–391 (2017).\n12. Nigam, A., Friederich, P., Krenn, M. & Aspuru-Guzik, A. Augmenting\ngenetic algorithms with deep neural networks for exploring the\nchemical space. Preprint athttp://arxiv.org/abs/1909.11655(2019).\n13. Skalic, M., Jiménez, J. & Sabbadin, D. & De Fabritiis, G. Shape-based\ngenerative modeling for de novo drug design.J .C h e m .I n f .M o d e l.\n59,1 2 0 5–1214 (2019).\n1 4 . W a l l a c h ,I . ,D z a m b a ,M .&H e i f e ts, A. AtomNet: A deep convolutional\nneural network for bioactivity prediction in structure-based drug\ndiscovery. Preprint athttp://arxiv.org/abs/1510.02855(2015).\n15. Gómez-Bombarelli, R. et al. Automatic chemical design using a\ndata-driven continuous representation of molecules.ACS Cent. Sci.\n4,2 6 8–276 (2018).\n16. Sanchez-Lengeling, B. & Aspuru-Guzik, A. Inverse molecular design\nusing machine learning: Generative models for matter engineering.\nScience 361,3 6 0–365 (2018).\n17. Soleimany, A. P. et al. Evidential deep learning for guided molecular\nproperty prediction and discovery.ACS Cent. Sci.7,\n1356–1367 (2021).\n18. Born, J. et al. PaccMannRL: de novo generation of hit-like anticancer\nmolecules from transcriptomic data via reinforcement learning.\niScience24, 102269 (2021).\n19. Weininger, D. SMILES, a chemical language and information sys-\ntem. 1. Introduction to methodology and encoding rules.J. Chem.\nInf. Comput. Sci.28,3 1–36 (1988).\n20. Merk, D., Friedrich, L., Grisoni, F. & Schneider, G. De novo design of\nbioactive small molecules by artiﬁcial intelligence.Mol. Inf.37,\n1700153 (2018).\n2 1 . G r i s o n i ,F .e ta l .C o m b i n i n gg e n e r a t i v ea r t iﬁcial intelligence and on-\nchip synthesis for de novo drug design.Sci. Adv.7,\neabg3338 (2021).\n2 2 . M o r e t ,M . ,H e l m s t ä d t e r ,M . ,G r i s o n i ,F . ,S c h n e i d e r ,G .&M e r k ,D .\nBeam search for automated design and scoring of novel ROR\nligands with machine intelligence.A n g e w .C h e m .I n t .E d. Engl. 60,\n19477–19482 (2021).\n23. Merk, D., Grisoni, F., Friedrich, L. & Schneider, G. Tuning artiﬁcial\nintelligence on the de novo design of natural-product-inspired\nretinoid X receptor modulators.Commun. Chem.1,6 8( 2 0 1 8 ) .\n24. Peters, M., Ruder, S. & Smith, N. A. To tune or not to tune? Adapting\npretrained representations to diverse tasks. Preprint athttp://arxiv.\norg/abs/1903.05987(2019).\n2 5 . O l i v e c r o n a ,M . ,B l a s c h k e ,T . ,E n g k v i s t ,O .&C h e n ,H .M o l e c u l a rd e -\nnovo design through deep reinforcement learning.J. Cheminform.\n9,4 8( 2 0 1 7 ) .\n26. Yang, J. et al. Targeting PI3K in cancer: mechanisms and advances\nin clinical trials.Mol. Cancer18,2 6( 2 0 1 9 ) .\n27. Kaneda, M. M. et al. PI3Kγ is a molecular switch that controls\nimmune suppression.Nature 539,4 3 7–442 (2016).\n28. Hochreiter, S. & Schmidhuber, J. Long short-term memory.Neural\nComput. 9,1 7 3 5–1780 (1997).\n2 9 . W a n i ,M .A . ,B h a t ,F .A . ,A f z a l ,S .&K h a n ,A .I .Advances in Deep\nLearning(Springer, 2020).\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 10\n30. Bengio, Y., Ducharme, R., Vincent, P. & Jauvin, C. A neural prob-\nabilistic language model.J. Mach. Learn. Res.3,1 1 3 7–1155 (2003).\n31. Gupta, A. et al. Generative recurrent networks for de novo drug\ndesign. Mol. Inf. 37, 1700111 (2018).\n32. Gaulton, A. et al. The ChEMBL database in 2017.Nucleic Acids Res.\n45, D945–D954 (2017).\n33. Moret, M., Friedrich, L., Grisoni, F., Merk, D. & Schneider, G. Gen-\nerative molecular design in low data regimes.Nat. Mach. Intell.2,\n171–180 (2020).\n34. Lowe, D. Chemical reactions from US patents (1976-Sep2016).ﬁg-\nshare https://ﬁgshare.com/articles/ChemicalreactionsfromUS\npatents1976-Sep2016/5104873( 2 0 1 7 ) .\n35. Tanoli, Z. et al. Drug target commons 2.0: a community platform for\nsystematic analysis of drug-target interaction proﬁles. Database\n2018,1 –13 (2018).\n36. Preuer, K., Renz, P., Unterthiner, T., Hochreiter, S. & Klambauer, G.\nFréchet ChemNet distance: a metric for generative models for\nmolecules in drug discovery.J .C h e m .I n f .M o d e l .58,\n1736–1741 (2018).\n37. Holtzman, A., Buys, J., Forbes, M. & Choi, Y. The curious case of\nneural text degeneration. Preprint athttp://arxiv.org/abs/1904.\n09751 (2019).\n38. David, L. et al. Applications of deep-learning in exploiting large-\nscale and heterogeneous compound data in industrial pharma-\nceutical research.Front. Pharmacol.10,1 3 0 3( 2 0 1 9 ) .\n39. Li, L. & Lin, H. Ordinal regression by extended binary classiﬁcation.\nin Advances in Neural Information Processing Systems 19865–872\n(MIT Press, 2007).\n40. Clark, K., Luong, M.-T., Le, Q. V. & Manning, C. D. ELECTRA: Pre-\ntraining text encoders as discriminators rather than generators.\nPreprint athttp://arxiv.org/abs/2003.10555(2020).\n41. Dimova, D., Stumpfe, D. & Bajorath, J. Systematic assessment of\ncoordinated activity cliffs formed by kinase inhibitors and detailed\ncharacterization of activity cliff clusters and associated SAR infor-\nmation. Eur. J. Med. Chem.90,4 1 4–427 (2015).\n42. Devlin, J., Chang, M.-W., Lee, K. & Toutanova, K. BERT: Pre-training\nof deep bidirectional transformers for language understanding.\nPreprint athttp://arxiv.org/abs/1810.04805(2018).\n43. Howard, J. & Ruder, S. Universal language modelﬁne-tuning for text\nclassiﬁcation. Preprint athttp://arxiv.org/abs/1801.06146(2018).\n44. Japkowicz, N. Learning from imbalanced data sets: a comparison of\nvarious strategies.AAAI Workshop Learn. Imbalanced Data Sets68,\n10–15 (2000).\n4 5 . H i r s c h f e l d ,L . ,S w a n s o n ,K . ,Y a n g ,K . ,B a r z i l a y ,R .&C o l e y ,C .W .\nUncertainty quantiﬁcation using neural networks for molecular\nproperty prediction.J. Chem. Inf. Model.60,3 7 7 0–3780 (2020).\n46. Sahigara, F. et al. Comparison of different approaches to deﬁne the\napplicability domain of QSAR models.Molecules17,\n4791–4810 (2012).\n47. Gadaleta, D., Mangiatordi, G. F., Catto, M., Carotti, A. & Nicolotti, O.\nApplicability domain for QSAR models: where theory meets reality.\nIJQSPR 1,4 5–63 (2016).\n48. Lam, L. & Suen, S. Y. Application of majority voting to pattern\nrecognition: an analysis of its behavior and performance.IEEE Trans.\nSyst. Man Cybern. Syst. Hum.27,5 5 3–568 (1997).\n49. Koch, C. P. et al. Exhaustive proteome mining for functional MHC-I\nligands.ACS Chem. Biol.8, 1876–1881 (2013).\n50. Lakshminarayanan, B., Pritzel, A., & Blundell, C. Simple and scalable\npredictive uncertainty estimation using deep ensembles. InProc.\n31st Conference on Neural Information Processing System\n6402–6413 (Curran Associates Inc., 2017).\n51. Valsecchi, C., Grisoni, F., Consonni, V. & Ballabio, D. Consensus\nversus individual QSARs in classiﬁc a t i o n :c o m p a r i s o no nal a r g e -\nscale case study.J. Chem. Inf. Model.60,1 2 1 5–1223 (2020).\n52. Xu, Y. & Johnson, M. Algorithm for naming molecular equivalence\nclasses represented by labeled pseudographs.J .C h e m .I n f .C o m -\nput. Sci.41,1 8 1–185 (2001).\n5 3 . B e m i s ,G .W .&M u r c k o ,M .A .T h ep r o p e r t i e so fk n o w nd r u g s .1 .\nMolecular frameworks.J. Med. Chem.39, 2887–2893 (1996).\n54. Rogers, D. & Hahn, M. Extended-connectivityﬁngerprints.J. Chem.\nInf. Model.50,7 4 2–754 (2010).\n55. Johnson, M. A. & Maggiora, G. M.Concepts and Applications of\nMolecular Similarity(Wiley, 1990).\n5 6 . C h e n ,B . ,M u e l l e r ,C .&W i l l e t t ,P .C o m b i n a t i o nr u l e sf o rg r o u pf u s i o n\nin similarity‐based virtual screening.Mol. Inf. 29,5 3 3–541 (2010).\n57. Apsel, B. et al. Targeted polypharmacology: discovery of dual\ninhibitors of tyrosine and phosphoinositide kinases.Nat. Chem. Biol.\n4, 691–699 (2008).\n58. Chakravarty, S. et al. Heterocyclic compounds and methods of use.\nWorld Patent (2015).\n59. Schwaller, P. et al. Predicting retrosynthetic pathways using\ntransformer-based models and a hyper-graph exploration strategy.\nChem. Sci.11,3 3 1 6–3325 (2020).\n6 0 . V e r d o n k ,M .L . ,C o l e ,J .C . ,H a r t s h o r n ,M .J . ,M u r r a y ,C .W .&T a y l o r ,R .\nD. Improved protein-ligand docking using GOLD.Proteins52,\n609–623 (2003).\n6 1 . B u s s i n k ,J . ,v a nd e rK o g e l ,A .J .&K a a n d e r s ,J .H .A .M .A c t i v a t i o no f\nthe PI3-K/AKT pathway and implications for radioresistance\nmechanisms in head and neck cancer.Lancet Oncol.9,\n288–296 (2008).\n6 2 . S a r b a s s o v ,D .D . ,G u e r t i n ,D .A . ,A l i ,S .M .&S a b a t i n i ,D .M .P h o s -\nphorylation and regulation of Akt/PKB by the rictor-mTOR complex.\nScience 307,1 0 9 8–1101 (2005).\n63. Liu, N. et al. BAY 80-6946 is a highly selective intravenous PI3K\ninhibitor with potent p110α and p110δ activities in tumor cell lines\nand xenograft models.Mol. Cancer Ther.12,2 3 1 9–2330 (2013).\n64. Skinnider, M. A., Greg Stacey, R., Wishart, D. S. & Foster, L. J. Che-\nmical language models enable navigation in sparsely populated\nchemical space.Nat. Mach. Intell.3,7 5 9–770 (2021).\n65. Bjerrum, E. J. SMILES enumeration as data augmentation for neural\nnetwork modeling of molecules. Preprint athttps://arxiv.org/abs/\n1703.07076(2017).\n66. Dao, T. et al. A kernel theory of modern data augmentation.Proc.\nMach. Learn. Res.97,1 5 2 8–1537 (2019).\n67. Schneider, G. Automating drug discovery.Nat. Rev. Drug Discov.17,\n97–113 (2018).\n6 8 . S c h n e i d e r ,N . ,L o w e ,D .M . ,S a y l e ,R .A . ,T a r s e l l i ,M .A .&L a n d r u m ,G .\nA. Big data from pharmaceutical patents: a computational analysis\nof medicinal chemists’ bread and butter.J. Med. Chem.59,\n4385–4402 (2016).\n69. Labute, P. The generalized Born/volume integral implicit solvent\nmodel: estimation of the free energy of hydration using London\ndispersion instead of atomic surface area.J. Comput. Chem.29,\n1693–1698 (2008).\n70. Fabian, M. A. et al. A small molecule-kinase interaction map for\nclinical kinase inhibitors.Nat. Biotechnol.23,3 2 9–336 (2005).\n71. Hill, A. V. The possible effects of the aggregation of the molecules\nof haemoglobin on its dissociation curves.J. Physiol.40,4 –7 (1910).\n72. Levenberg, K. A method for the solution of certain non-linear pro-\nblems in least squares.Quart. Appl. Math.2,1 6 4–168 (1944).\n73. Milde, T. et al. HD-MB03 is a novel Group 3 medulloblastoma model\ndemonstrating sensitivity to histone deacetylase inhibitor treat-\nment. J. Neurooncol.110, 335–348 (2012).\n74. Schindelin, J. et al. Fiji: an open-source platform for biological-\nimage analysis.Nat. Methods9,6 7 6–682 (2012).\n75. Schneider, P. & Schneider, G. Acomputational method for unveil-\ning the target promiscuity of pharmacologically active compounds\nin silico.Angew. Chem. Int. Ed.56, 11520–11524 (2017).\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 11\n76. Reutlinger, M. et al. Chemically advanced template search (CATS)\nfor scaffold-hopping and prospective target prediction for‘orphan’\nmolecules.Mol. Inf.32,1 3 3–138 (2013).\nAcknowledgements\nThis work wasﬁnancially supported by the Swiss National Science\nFoundation (grants no. 205321_182176 to G.S. and no. CRSII5_202245/1\nRaSMID to G.S. and M.B.) and by the RETHINK initiative at ETH Zurich. The\nauthors thank Alexander Button, Damian Gautschi, and Jonas Bossart for\nhelpful discussions. Daniel Lowe and Lukas Friedrich are thanked for\ntheir technical assistance with the US patent database.\nAuthor contributions\nM.M., F.G., and G.S. conceived the study. M.M. implemented the soft-\nware. C.B. curated the data. K.A. and I.P.A. performed the docking study.\nI.P.A. and L.C. synthesized the compounds. S.Y. and M.B. designed the\ncell-based assays. S.Y. performed the cell-based assays. G.S. supervised\nthe study. All authors analyzed the data and results and contributed to\nthe writing of the manuscript.\nCompeting interests\nG.S. declares a potentialﬁnancial conﬂict of interest as a consultant to\nthe pharmaceutical industry and co-founder of inSili.com GmbH, Zurich,\nSwitzerland. The authors declare no other competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41467-022-35692-6.\nCorrespondenceand requests for materials should be addressed to\nFrancesca Grisoni or Gisbert Schneider.\nPeer review informationNature Communicationsthanks Alexander\nTropsha and the other, anonymous, reviewer(s) for their contribution to\nthe peer review of this work.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to jur-\nisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons license, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article’s Creative Commons license, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons license and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this license, visithttp://creativecommons.org/\nlicenses/by/4.0/.\n© The Author(s) 2023\nArticle https://doi.org/10.1038/s41467-022-35692-6\nNature Communications|          (2023) 14:114 12",
  "topic": "Drug",
  "concepts": [
    {
      "name": "Drug",
      "score": 0.5234886407852173
    },
    {
      "name": "Computational biology",
      "score": 0.4943976402282715
    },
    {
      "name": "Drug discovery",
      "score": 0.47903624176979065
    },
    {
      "name": "Computer science",
      "score": 0.44563838839530945
    },
    {
      "name": "Chemistry",
      "score": 0.3146219551563263
    },
    {
      "name": "Biology",
      "score": 0.26653027534484863
    },
    {
      "name": "Pharmacology",
      "score": 0.19950392842292786
    },
    {
      "name": "Biochemistry",
      "score": 0.1773558259010315
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I35440088",
      "name": "ETH Zurich",
      "country": "CH"
    },
    {
      "id": "https://openalex.org/I4210128593",
      "name": "University Children's Hospital Zurich",
      "country": "CH"
    },
    {
      "id": "https://openalex.org/I202697423",
      "name": "University of Zurich",
      "country": "CH"
    }
  ]
}