{
    "title": "Accelerating Pre-trained Language Models via Calibrated Cascade.",
    "url": "https://openalex.org/W3115348206",
    "year": 2020,
    "authors": [
        {
            "id": "https://openalex.org/A2098784551",
            "name": "Lei Li",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2131512363",
            "name": "Yankai Lin",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2304534086",
            "name": "Shuhuai Ren",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2100821712",
            "name": "Deli Chen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2671201830",
            "name": "Xuancheng Ren",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1906085637",
            "name": "Peng Li",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2093278426",
            "name": "Jie Zhou",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2107643647",
            "name": "Xu Sun",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W3034292689",
        "https://openalex.org/W3035038672",
        "https://openalex.org/W2946417913",
        "https://openalex.org/W2963846996",
        "https://openalex.org/W2964212410",
        "https://openalex.org/W2970454332",
        "https://openalex.org/W2130158090",
        "https://openalex.org/W3101163004",
        "https://openalex.org/W2251939518",
        "https://openalex.org/W2998183051",
        "https://openalex.org/W2963310665",
        "https://openalex.org/W2970565456",
        "https://openalex.org/W2978017171",
        "https://openalex.org/W2951244744",
        "https://openalex.org/W131533222"
    ],
    "abstract": "Dynamic early exiting aims to accelerate pre-trained language models' (PLMs) inference by exiting in shallow layer without passing through the entire model. In this paper, we analyze the working mechanism of dynamic early exiting and find it cannot achieve a satisfying trade-off between inference speed and performance. On one hand, the PLMs' representations in shallow layers are not sufficient for accurate prediction. One the other hand, the internal off-ramps cannot provide reliable exiting decisions. To remedy this, we instead propose CascadeBERT, which dynamically selects a proper-sized, complete model in a cascading manner. To obtain more reliable model selection, we further devise a difficulty-aware objective, encouraging the model output class probability to reflect the real difficulty of each instance. Extensive experimental results demonstrate the superiority of our proposal over strong baseline models of PLMs' acceleration including both dynamic early exiting and knowledge distillation methods.",
    "full_text": null
}