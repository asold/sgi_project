{
  "title": "Large Language Models in equity markets: applications, techniques, and insights",
  "url": "https://openalex.org/W4413745906",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A4321127253",
      "name": "Aakanksha   Jadhav",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2565041535",
      "name": "Vishal Mirza",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4321127253",
      "name": "Aakanksha   Jadhav",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2565041535",
      "name": "Vishal Mirza",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4404039641",
    "https://openalex.org/W4392859372",
    "https://openalex.org/W4394990140",
    "https://openalex.org/W4404208640",
    "https://openalex.org/W4404208572",
    "https://openalex.org/W4401691580",
    "https://openalex.org/W4404350209",
    "https://openalex.org/W4388929300",
    "https://openalex.org/W4401545735",
    "https://openalex.org/W4407692022",
    "https://openalex.org/W4404369585",
    "https://openalex.org/W4396757543",
    "https://openalex.org/W4404369452",
    "https://openalex.org/W4404783297",
    "https://openalex.org/W4401413611",
    "https://openalex.org/W4393027410",
    "https://openalex.org/W4393027165",
    "https://openalex.org/W4400037577",
    "https://openalex.org/W4400037165",
    "https://openalex.org/W4367318783"
  ],
  "abstract": "Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector.",
  "full_text": "Frontiers in Artificial Intelligence 01 frontiersin.org\nLarge Language Models in equity \nmarkets: applications, techniques, \nand insights\nAakanksha Jadhav  and Vishal Mirza *\nIndependent Researcher, New York, NY, United States\nRecent breakthroughs in Large Language Models (LLMs) have the potential to \ndisrupt equity investing by enabling sophisticated data analysis, market prediction, \nand automated trading. This paper presents a comprehensive review of 84 research \nstudies conducted between 2022 and early 2025, synthesizing the state of LLM \napplications in stock investing. We provide a dual-layered categorization: first, by \nfinancial applications such as stock price forecasting, sentiment analysis, portfolio \nmanagement, and algorithmic trading; second, by technical methodologies, \nincluding prompting, fine-tuning, multi-agent frameworks, reinforcement \nlearning, and custom architectures. Additionally, we consolidate findings on the \ndatasets used, ranging from financial statements to multimodal data (news, market \ntrends, earnings transcripts, social media), and systematically compare general-\npurpose vs. finance-specialized LLMs used in research. Our analysis identifies key \nresearch trends, commonalities, and divergences across studies, evaluating both \ntheir empirical contributions and methodological innovations. We highlight the \nstrengths of existing research, such as improved sentiment extraction and the use \nof reinforcement learning to factor market feedback, alongside critical gaps in \nscalability, interpretability, and real-world validation. Finally, we propose directions \nfor future research, emphasizing hybrid modeling approaches, architectures that \nfactor reasoning and large context windows, and robust evaluation frameworks \nto advance AI-driven financial strategies. By mapping the intersection of LLMs \nand equity markets, this review provides a foundation and roadmap for future \nresearch and practical implementation in the financial sector.\nKEYWORDS\nLarge Language Models, LLMS, finance, NLP, stock, equity, investing, algorithmic \ntrading\n1 Introduction\nHistorically, investment strategies largely relied on structured data, fundamental and \ntechnical analysis, and human interpretation of financial reports, often resulting in slow \ndecision-making and limited market adaptability. The advent of Large Language Models \n(LLMs) marks a transformative era in equity investing, shifting the paradigm from traditional, \nmanual analysis to automated, real-time insights. LLMs now enable the rapid processing and \nintegration of vast datasets, combining structured financial metrics with unstructured sources \nlike news, earnings call transcripts, and social media sentiment. This integration uncovers \nmarket trends and signals with unprecedented precision, converting previously overlooked \ntextual data into actionable trading signals. Moreover, LLMs are facilitating the evolution from \nstatic, rule-based models to dynamic, self-learning systems powered by reinforcement learning \nand multi-agent frameworks. This evolution enhances market responsiveness, improves risk \nmanagement, and boosts alpha generation by identifying complex market narratives and \nemerging shifts. However, the integration of LLMs into equity investing is not without its \nOPEN ACCESS\nEDITED BY\nAparna Gupta,  \nRensselaer Polytechnic Institute, United States\nREVIEWED BY\nDragos Bozdog,  \nStevens Institute of Technology, United States\nSotiris Kotsiantis,  \nUniversity of Patras, Greece\nPeggy Lindner,  \nUniversity of Houston, United States\n*CORRESPONDENCE\nVishal Mirza  \n vishal.mirza@nyu.edu\nRECEIVED 08 April 2025\nACCEPTED 18 July 2025\nPUBLISHED 27 August 2025\nCITATION\nJadhav A and Mirza V (2025) Large Language \nModels in equity markets: applications, \ntechniques, and insights.\nFront. Artif. Intell. 8:1608365.\ndoi: 10.3389/frai.2025.1608365\nCOPYRIGHT\n© 2025 Jadhav and Mirza. This is an \nopen-access article distributed under the \nterms of the Creative Commons Attribution \nLicense (CC BY). The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that the \noriginal publication in this journal is cited, in \naccordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.\nTYPE Review\nPUBLISHED 27 August 2025\nDOI 10.3389/frai.2025.1608365\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 02 frontiersin.org\nchallenges, including data reliability, potential biases, regulatory \nconsiderations, and the interpretability of AI-driven recommendations.\nThis review paper analyzes current research on the application of \nLarge Language Models (LLMs) in equity markets. It focuses on the \nfollowing research questions: (1) What are the major trends in how \nLLMs are being applied within equity markets? (2) What are the primary \ntechnical innovations and methodological approaches employed in \nLLM-driven equity research? (3) What are the significant limitations, \nchallenges, and research gaps that have been identified in the literature?\n1.1 Key considerations for LLM usage in \nstock investing\n1.1.1 Data complexity\nMultimodal data: The financial stock investing landscape is \ncharacterized by an increasingly complex and voluminous collection \nof multi-modal data, presenting significant analytical challenges. \nInvestors must process both structured and unstructured data sets, \neach requiring distinct computational approaches. Structured data, \nincluding financial statements, earnings reports, and quantitative \nmarket metrics demands rigorous statistical and analytical modeling. \nIn contrast, unstructured data, such as financial news, social media \nsentiment, and analyst reports, necessitates advanced natural language \nprocessing (NLP) techniques to extract meaningful insights. \nAdditionally, the integration of visual elements such as price charts, \ntechnical indicators, and graphical financial summaries, along with \naudio or text data from earnings calls and investor briefings, further \ncomplicates the analytical landscape.\nLarge datasets: The size of datasets used to analyze a single stock, \nor a portfolio is large and complex with inclusion of multimodal data- \nmultiple unstructured and structured datasets and real-time data \nstreams. Additionally, the size of financial earning reports (quarterly, \nannual, 10Q, 10 K) and industry report pdf files usually spans 100+ \npages, while earning transcripts contains large audio/text files.\nWhy LLMs can address data complexity in large datasets: Large \nLanguage Models (LLMs) are uniquely suited to handle the data \ncomplexity inherent in financial stock investing due to their ability to \nprocess and synthesize large volumes of heterogeneous data. Unlike \ntraditional models that require separate preprocessing pipelines for \neach data type, LLMs are trained on vast corpora of multimodal \ninformation, enabling them to natively handle unstructured data such \nas text from earnings reports, analyst notes, and news articles. Their \ncontextual understanding allows them to extract relevant insights \nfrom lengthy documents (e.g., 100+ page 10-Ks), and their ability to \nsummarize, infer sentiment, and answer questions from natural \nlanguage inputs makes them ideal for navigating and distilling large, \ncomplex datasets. Moreover, LLMs can be extended or paired with \nvision and speech models (e.g., via multimodal architectures like \nGPT-4V or Gemini) to interpret visual data (charts, tables) and audio \ntranscripts (earnings calls), thereby providing a unified framework for \nholistic financial analysis.\n1.1.2 Time sensitivity and real time analysis\nFinancial markets are inherently time-sensitive, with investment \ndecisions often hinging on the rapid processing and analysis of \ninformation. Latency and response times play a pivotal role, \nparticularly in short-term trading strategies such as day trading. \nThe ability to react swiftly to market fluctuations can significantly \nimpact investment outcomes, emphasizing the need for real-time \nor near-real-time analytical capabilities. This consideration is \nespecially pertinent when evaluating the suitability of Large \nLanguage Models (LLMs) for equity investing, as their effectiveness \ndepends on their ability to process vast amounts of financial data \nwith minimal delay.\n1.1.3 Diverse investment strategies and asset \nclasses\nInvestment strategies in equity markets vary widely, from long-\nterm value and growth investing to short-term momentum and high-\nfrequency trading, each requiring distinct analytical methods. \nAdditionally, this complexity extends across asset classes, including \nstocks, ETFs, and derivatives like options and futures, each with \nunique characteristics and risk factors. While LLMs hold promise for \nfinancial investing, effectively adapting them to diverse asset classes \nand investment styles remains a critical challenge. Additionally, \nfinancial analysis encompasses a wide range of approaches, including \nfundamental and technical analysis. Fundamental analysis focuses on \nthe intrinsic value of assets, while technical analysis examines \nhistorical price and volume data.\n1.2 Review scope\nThe application of LLMs to stock and equity investing has seen a \nsignificant surge in research, particularly in the 2 years following the late \n2022 launch of ChatGPT, during which we identified approximately 84 \nrelevant studies. Despite the growing interest in applying LLMs to \nfinance and stock investment, the rapid proliferation of research in this \ndomain has created a fragmented landscape. Some studies focus on \nmulti-agent trading frameworks, others explore time series forecasting, \nwhile still others develop domain-specific LLM architectures. This review \naims to consolidate these disparate efforts by synthesizing findings from \n84 recent studies. Our goal is to provide a comprehensive overview of the \nresearch on how LLMs are being applied to transform stock and equity \ninvesting, while also highlighting key challenges and gaps in the field.\nWe selected 84 research papers from a comprehensive set of 100+ \nresearch papers sourced from Google Scholar and arXiv. The selection \nprocess involved applying keyword filters such as “LLM for Stock \nInvesting” and “Large Language Models for Equity Investing. Papers \nthat primarily focused on macroeconomic analysis or general financial \nrisk modeling, broader finance topics without explicit application of \nLLMs to equity markets, were excluded.\nTo provide a holistic analysis, we  adopt a two-fold \nclassification approach:\n 1 Applications of LLMs in Finance-Equity Investing (Section 2): \nThis section categorizes the practical goals (why) and real-\nworld relevance (what) of LLM applications in equity investing.\n 2 LLM Technical Innovations and Approaches (Section 3): This \nsection examines the method (how)—detailing the specific \ntechniques and methodologies used in LLM applications.\nThis dual approach enables a comprehensive evaluation of both \nthe “why, what” and “how” aspects of research on LLM usage in \nequity investing. By exploring the key observations and insights \nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 03 frontiersin.org\ngained from existing research, we  seek to highlight both the \npotential and the limitations of LLMs in this dynamic and \nchallenging field. As investors increasingly integrate LLMs and other \nreinforcement learning AI techniques into their decision-making \nprocesses, understanding the potential and limitations of \nLLM-driven strategies becomes crucial. This paper serves as both a \nroadmap and a call to action for researchers and practitioners, \npaving the way toward more transparent, efficient, and reliable \napplications of LLMs in stock and equity investing. For simplicity, \nbrevity, and readability we refer to each research paper by ‘Paper No. ’ \nas indexed in the References section and avoid the use of complete \npaper title and author names unlike the format of traditional \nliterature reviews.\n2 Applications of LLMs in \nfinance-equity investing\nAn effective method for categorizing the research landscape of \nLLM applications in stock investing is by end use or financial \napplication, as it reflects how both practitioners and researchers \ntypically frame their objectives. By grouping the 84 papers into \ncategories such as stock trend prediction, sentiment analysis, portfolio \nmanagement, and others we highlight each study’s practical goals and \nreal-world relevance (Figure 1). This application-centric perspective \nnot only spotlights potential synergies among similar works but also \nreveals gaps in coverage—for example, relatively few studies address \nrisk management tasks. Consequently, categorizing by end use \nprovides a clear, pragmatic lens through which to assess the collective \nimpact and future directions of LLM research in equity and \nstock investing.\n2.1 Stock price forecasting and market \ntrends\nA substantial body of research on LLMs in equity investing centers \non forecasting stock prices, predicting market returns, and analyzing \nbroader market trends. Typically, these studies combine textual data \n(e.g., news, press releases, earnings reports, analyst reports, social \nmedia content, etc.) with quantitative time-series data to enhance \npredictive accuracy beyond traditional methods.\n2.1.1 Integration of qualitative data in forecasting\nLeveraging language models to extract and interpret market \nsignals from unstructured data has proven effective in complementing \nnumerical datasets for forecasting models. This subcategory explores \nhow LLMs integrate unstructured textual data with structured \nFIGURE 1\nCategorization of research by financial application for stock investing.\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 04 frontiersin.org\nfinancial indicators to improve stock prediction models and generate \nactionable market signals.\n2.1.1.1 Stock prediction using multiple data sets\n • Shi and Hollifield (2024)  compares GPT-4 and BERT for stock \nreturn prediction using historical economic indicators, \nshowing the strength of LLMs in processing structured \neconomic data.\n • Ni et al. (2024)  forecasts post-earnings stock performance by \ncombining textual earnings reports and transcripts with key \nfinancial metrics.\n • Lee et  al. (n.d.)  transforms qualitative textual insights into \nquantitative market signals, offering a direct mapping approach \nfor LLM-based forecasting.\n • Ding et  al. (2023)  fuses LLMs with time-series modeling to \nimprove stock return predictions in the Chinese market, \nillustrating LLM adaptability to local market contexts.\n • Swamy et al. (n.d.) blends LLM-generated “priority indices” with \ntraditional quantitative factors to enhance market trend prediction.\n • Tong et al. (2024) introduces Ploutos, which integrates textual \nand numerical data to generate interpretable forecasts of price \nmovements, focusing on explainability.\n • Cheng and Tang (2023) demonstrates GPT-4’s ability to design \nhigh-performing investment factors with strong returns and \nSharpe ratios.\n • Fatemi and Hu (2024)  proposes a multi-agent, multimodal \nsystem for stock prediction, emphasizing complex agent-based \nmodeling over single-model forecasting.\n • Deng et al. (2024) introduces a “denoising-then-voting” method \nto improve few-shot stock forecasting in noisy and data-\nscarce environments.\n • Di et al. (2024) and Guo and Shum (2024) extend forecasting to \nbroader market indices using LLMs combined with multi-source \ndatasets and knowledge graphs, respectively.\n2.1.1.2 Stock prediction using news data sets\n • Tandon (2024)  compares BERT and FinBERT for general \nsentiment extraction from news headlines, establishing baseline \nmodel differences.\n • Bhat (n.d.) focuses on extracting emotional tone from news \nheadlines to forecast stock movements, highlighting finer-\ngrained sentiment modeling.\n • Liang et al. (2024)  introduces FinGPT, which incorporates \ncontextual nuances from financial news to improve \nprediction accuracy.\n • Chen et al. (2022) shows that complex linguistic features captured \nby LLMs outperform traditional models in global stock \nreturn forecasting.\n • Guo and Hauptmann (2024)  fine-tunes LLMs using Mistral \nembeddings on financial news, demonstrating performance gains \nin portfolio returns from domain-specific training.\n • Vidal (2024) reports mixed results with certain LLMs, cautioning \nagainst overreliance without robust evaluation.\n • Lopez-Lira and Tang (2023) evaluates ChatGPT’s raw capability \nto predict stock prices from headlines without financial fine-\ntuning, benchmarking general-purpose LLMs against domain-\ntrained ones.\nThese studies collectively demonstrate the value of combining \nLLMs with structured and unstructured data for market prediction, \nshowcasing methodological diversity and a trend toward \ninterpretability and domain adaptation.\n2.1.2 Time series specialization\nThis subcategory focuses on adapting LLMs to handle temporal \ndependencies and structured price signals for enhanced time-series \nforecasting in financial markets.\n • Valeyre and Aboura (2024) evaluates LLMs on a dataset of major \nU.S. equities, demonstrating their alpha-generating potential in \ntraditional time-series forecasting tasks.\n • Wang et al. (2024) proposes a novel architecture that fuses textual \ninputs with time-series signals to improve predictive accuracy in \nstock price movements.\n • Chen et  al. (2024)  investigates the role of historical return \npatterns in informing future price predictions, using LLMs to \nextract and model temporal patterns.\n • Voigt et  al. (2024)  explores the methodological \nconvergence  between NLP and time-series analysis, \napplying  LLMs to structured forecasting problems in \nquantitative finance.\n • Wang et al. (2024) introduces Stock time—a bespoke architecture \nspecifically designed for financial time-series prediction, \noptimizing LLM capabilities for sequential modeling tasks.\nThese studies highlight how LLMs are being repurposed or \narchitecturally enhanced to address the unique demands of time-\ndependent financial data.\n2.2 Sentiment analysis and market \nintelligence\nResearch in this domain focuses on extracting, quantifying, and \ninterpreting sentiment from diverse textual sources—such as news \narticles, social media posts, analyst reports, and press releases—to \ngenerate actionable intelligence for market analysis. The key \nthemes include.\n2.2.1 Text mining and natural language \nprocessing\nThis category focuses on extracting insights from financial text \ndata using LLMs, with a strong emphasis on sentiment analysis across \nvarious domains and data types.\n • Deng et al. (2022) applies LLMs to Reddit data to extract investor \nsentiment, showcasing the utility of social media as an alternative \nsentiment source.\n • Das et  al. (2024)  evaluates LLMs for single-stock trading, \nintegrating news sentiment and price movement signals to \ninform trading decisions.\n • Wu (2024)  investigates the relationship between market \nsentiment from news sources and resulting stock \nprice fluctuations.\n • Zhao and Welsch (2024) introduces an adaptive LLM framework \nfor sentiment analysis, integrating instruction tuning and real-\ntime market feedback to improve adaptability.\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 05 frontiersin.org\n • Aparicio et al. (2024) presents BioFinBERT, a domain-specific \nLLM fine-tuned for biotechnology stock sentiment, highlighting \nthe value of industry-specific modeling.\n • Liu et  al. (2024)  explores the correlation between news \nsentiment and Bitcoin prices, extending sentiment analysis to \ncryptocurrency markets.\n • Xing (2024) proposes a multi-agent LLM system that enhances \nsentiment classification accuracy through collaborative \nagent dynamics.\n • Dolphin et al. (2024) develops an LLM-driven system to process \nunstructured financial news and tickers, converting them into \nstructured data formats for sentiment tracking.\n • Yu (2023) conducts a case study on US equity market news, \nexamining the variability and reliability of LLM-generated \nsentiment labels.\n • Kirtac and Germano (2024) compares general-purpose and fine-\ntuned LLMs for financial sentiment analysis, analyzing \nperformance differences across model types.\nThese studies reflect a broad spectrum of sentiment analysis \ntechniques using LLMs—from basic extraction to adaptive and agent-\nbased frameworks—demonstrating their growing sophistication and \nimportance in financial modeling.\n2.2.2 Sentiment scoring\nThis subcategory focuses on converting qualitative sentiment \nfrom financial text into quantitative scores that can directly inform \ntrading and investment strategies.\n • Bond et al. (2023) uses ChatGPT to generate a sentiment-based \nmarket indicator from daily news summaries, demonstrating \nsuperior performance compared to traditional sentiment \nanalysis methods.\n • Lefort et al. (2024) applies ChatGPT to financial news headlines \nto derive sentiment scores for NASDAQ index predictions, \nintegrating these scores into an NLP-driven investment strategy.\nBoth studies illustrate how LLMs can translate textual \nsentiment into actionable numeric signals, with Paper 31 \nemphasizing broader market trends and Paper 61 focusing on \nNASDAQ-specific movements.\n2.3 Automated trading and decision \nsystems\nThis category highlights research dedicated to building systems \ncapable of autonomously making trading decisions or crafting \nstrategies based on LLM outputs. These approaches range from multi-\nagent frameworks to fully functional trading bots, operating in both \nsimulated and real-world environments.\n2.3.1 Algorithmic trading/automated trading \ndecision systems (AI agents)\n • Yu et  al. (2024) introduces a multi-agent framework FinCon \ndesigned to handle complex financial tasks, including trading \nand portfolio management.\n • Kou et  al. (2024)  presents a multi-agent methodology for \nquantitative stock investing, combining LLMs with \nestablished quantitative techniques to enhance performance \nand stability.\n • Zhang et  al. (2024)  simulates investor behavior through an \nLLM-driven multi-agent system (Stock Agent) that adapts to live \nmarket conditions.\n • Xiao et al. (2024) deploys specialized LLM-based agents (Trading \nAgents) within a structure modeled on real-world trading firms, \ndemonstrating improved performance against \nstandard benchmarks.\n • Li et al. (2023) introduces TradingGPT, a multi-agent framework \nwith layered memories and distinct agent characters, aiming to \nemulate human cognitive processes for improved trading \nefficiency and accuracy, emphasizing the hierarchical nature of \nhuman memory.\n • Yu et al. (2023), FinMem, addresses the need for a novel LLM \nagent architecture to effectively transition from question-\nanswering to purpose-driven financial trading, focusing on \nmulti-source information processing, reasoning chains, and \ntask prioritization.\n • Wang et  al. (2024) investigates LLM reasoning processes for \ntrading decisions based on trend observations in crypto trading, \nrevealing that less sophisticated LLMs can outperform more \nsophisticated LLMs, offering a contrast to the trend of increasing \nmodel complexity.\n • Li et  al. (2024)  develops an LLM-based trading agent, \nCryptoTrade, that integrates diverse data (on chain and off-chain \ndata) for cryptocurrency trading, showcasing LLM versatility \nbeyond traditional stock markets.\n2.3.2 Sentiment analysis for trading/portfolio \nmanagement\n • Konstantinidis et  al. (2024)  proposes a sentiment-analysis \nframework (FinLlama) for algorithmic trading that elevates \nportfolio returns, even in volatile markets.\n • Chen et al. (2024)  explores social media sentiment to inform \ntrading strategies, linking shifts in investor sentiment to returns \nand herding behavior within AI-driven trading ecosystems. This \nstudy demonstrates the potential of factoring investor sentiment \nto inform trading decisions.\n2.3.3 Adaptive trading/reinforcement learning\n • Saqur and Rudzicz (2024) introduces Reinforcement Learning \nfrom Market Feedback (RLMF), enabling LLMs to adapt \ncontinuously to evolving market dynamics.\n2.3.4 AI agent platforms\n • Y ang et al. (2024) provides an open-source AI agent platform, \nFinRobot, broadening access to specialized LLM-driven tools for \nboth researchers and practitioners.\nIntegrating sentiment analysis (2.3.2) into algorithmic systems \n(2.3.1) combines quantitative and qualitative data. Reinforcement \nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 06 frontiersin.org\nlearning (2.3.3) enhances agent adaptability. Open-source platforms \n(2.3.4) broaden access. These advances demonstrate LLMs’ \ntransformative potential in automated trading.\n2.4 Investment analysis, valuation and \nequity research\nLarge Language Models (LLMs) offer considerable potential for \nstreamlining and enhancing traditional equity research. By \nautomating tasks such as stock ratings, identifying new investment \nopportunities, and assisting in the interpretation of complex financial \ndocuments, LLMs can significantly improve analysts’ efficiency and \ninsights. Research in this domain can be  grouped into several \nkey themes.\n2.4.1 Equity research automation\n • Papasotiriou et al. (2024) presents a method for automating and \nimproving equity stock ratings by combining GPT-4 with \nmultimodal financial data.\n • Li et al. (2023) leverages generative AI (Llama2 and GPT-3.5) to \nautomate fundamental investment research, with a focus on data \nsummarization and ideation.\n • Zhou et al. (2024) introduces FinRobot, an open-source AI agent \ndesigned for sell-side analysts seeking to automate equity \nresearch processes.\n • Yue and Au (2023)  describes GPTQuant, a conversational \nchatbot that simplifies investment research by generating and \nexecuting Python code.\nWhile all papers focus on automation, they differ in their \napproach. (Papasotiriou et  al., 2024) focuses on ratings, ( Li et  al., \n2023) on idea generation, (Zhou et al., 2024) on open-source tools, \nand (Yue and Au, 2023) on user interaction, highlighting the diversity \nof automation strategies.\n2.4.2 Investment research/analysis\n • Kim and Oh (n.d.)  presents a novel approach that combines \nLLMs, NLP , and dynamic data retrieval for in-depth stock \nmarket analysis.\n2.4.3 Stock selection/portfolio management\n • Fatouros et al. (2024) proposes MarketSenseAI, a GPT-4–based \nframework that supports stock selection.\n • Fatouros et al. (2025) extends this approach with MarketSenseAI \n2.0, an enhanced LLM-driven system that integrates various \nfinancial datasets and Retrieval-Augmented Generation to \noptimize portfolio performance.\nBoth papers focus on stock selection, but Paper 47 expands on \nPaper 8 by incorporating more diverse data and advanced generation \ntechniques to improve portfolio optimization.\n2.4.4 Executive/corporate communication \nanalysis\n • Chiang et  al. (2025)  explores how LLMs can evaluate Q&A \nsegments in earnings calls to assess the transparency and \nresponsiveness of corporate executives, providing valuable \ninsights for investment decision-making.\n2.4.5 Modeling\n • Wang et al. (2023) introduces a new paradigm for alpha mining \nin quantitative investment, addressing the challenge of translating \nquant researchers’ ideas into effective trading strategies.\n • Wang et  al. (2024) focuses on using Large Language Models \n(LLMs) to help understand and model investor decision-making, \nespecially when investors are influenced by “herd behavior” \n(following the crowd).\nWang et al. (2023) focuses on modeling quant researcher ideas, \nwhile (Wang et  al., 2024) model’s investor behavior, showing two \ndifferent modeling approaches. Building upon the modeling of \nfinancial data, researchers are also looking at how to improve the \nexplainability of LLM models.\n2.4.6 Explainability/interpretability\nThe focus on explainability is important for the real-world \napplication of the models.\n • Koa et al. (2024) develops a self-learning framework to enhance \nthe interpretability of stock predictions by generating human-\nreadable explanations, addressing a critical challenge for both \ntraditional models and LLMs.\n • Additionally, Lopez-Lira and Tang (2023), Tong et al. (2024), \nAbdelsamie and Wang (2024) , Zhao (2024)  cover model \ninterpretability. Tong et  al. (2024) and Lopez-Lira and Tang \n(2023), introduce novel frameworks and Zhao (2024) introduces \na novel algorithm for enhancing interpretability for equity \napplication of LLMs, while ( Abdelsamie and Wang, 2024 ) \ncompares interpretability across general purpose LLMs.\n2.5 Portfolio management and investment \nadvisory\nResearch in this domain applies Large Language Models (LLMs) to \nportfolio construction, wealth management, and personalized financial \nadvice. The overarching aim is to optimize asset allocations and provide \nactionable recommendations for investors. Key themes include:\n2.5.1 Portfolio construction/optimization\n • Lu et al. (2023) demonstrates high-alpha portfolio generation by \nincorporating insights from news and policy announcements.\n • Romanko et al. (2023) uses ChatGPT for stock selection in portfolio \nconstruction, integrating it with traditional optimization methods.\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 07 frontiersin.org\n • Ko and Lee (2024) explores how ChatGPT can assist in asset class \nselection and enhance portfolio diversification.\n • Gu et  al. (2024) proposes an adaptive portfolio management \nframework that leverages LLMs and Reinforcement Learning for \ndynamic long–short positions.\n • Huang et al. (2024) introduces a novel LLM-based, algorithm-\ndriven system for stock selection and portfolio optimization.\n • Zhao (2024)  to revolutionize portfolio management by \novercoming limitations in traditional approaches, this research \ndevelops a framework integrating advanced NLP , LLMs, and \nDRL (Deep Reinforcement learning) for enhanced return \npredictions, sentiment extraction, and optimized \ntrading strategies.\n • Perlin et al. (n.d.)  evaluates Google’s Gemini 1.5 Flash LLM’s \ninvestment performance using extensive U.S. market data, \nfinding it does not consistently outperform basic benchmarks, \nand its risk-adjusted returns decline with longer investment \nhorizons. It covers a large-scale simulation of investment \ndecisions using different data inputs and time horizons.\nWhile (Lu et al., 2023; Romanko et al., 2023; Ko and Lee, 2024; \nGu et al., 2024; Huang et al., 2024; Zhao, 2024) provide frameworks \nfor portfolio construction, Perlin et al. (n.d.) differentiates itself by \nevaluating an existing and widely utilized LLM, showing the \ndifference between theoretical implementations and real-world \nevaluation. Also, the complexity of frameworks increases for ( Gu \net al., 2024; Huang et al., 2024; Zhao, 2024) including a reinforcement \nlearning approach. Some papers utilize hybrid approaches, while \nother papers rely solely on LLMs.\nWhile the research conducted within the sphere of portfolio \nconstruction and optimization can, lead to, and improve the quality \nof Robo-advisory platforms, we  cover that in as separate \nsection below.\n2.5.2 Robo-advisory/investor education\n • Fieberg et al. (2024): Illustrates how LLMs can generate financial \nadvice tailored to individual investor profiles.\n • Lu (2025): Examines the impact of varying levels of financial \nliteracy (alpha/beta) on investor behavior within robo-\nadvisory platforms.\n2.6 Risk management and anomaly \ndetection\nWhile much of the literature focuses on improving predictive \naccuracy, few studies address the robustness and reliability of LLMs in \nequity investing. Three key themes emerge:\n2.6.1 Bias assessment\n • Glasserman and Lin (2023) investigates two potential biases that \ncan arise when LLMs use news sentiment for stock predictions: \nLook-Ahead Bias—when models inadvertently incorporate \nfuture returns into current forecasts. Distraction Effect—where \nextraneous company information skews the sentiment assessment.\n2.6.2 Anomaly detection\nThis category of research examines methods for identifying \nunusual market conditions or portfolio crashes.\n • Park (2024) introduces an LLM-driven multi-agent framework \ndesigned to automate anomaly detection in financial markets, \nreducing the burden of manual alert validation. Similarly,\n • Koa et  al. (2024)  proposes a framework called “Temporal \nRelational Reasoning (TRR), ” which utilizes LLMs to detect \nportfolio crashes by applying human-like temporal reasoning.\n • Y ang et al. (2025) proposes TwinMarket, a multi-agent framework \nthat simulates complex human behavior. Simulated stock market \nexperiments show how individual actions lead to emergent group \nbehaviors, including financial bubbles and recessions.\nPark (2024)  and Y ang et  al. (2025) both utilize multi-agent \nframeworks, but (Park, 2024) focuses on automating alert validation, \nwhereas ( Y ang et  al., 2025) simulates human behavior to model \nemergent market phenomena. Koa et  al. (2024)  takes a different \napproach by focusing on temporal relational reasoning, which \nemulates human-like temporal analysis. Therefore, the papers vary in \ntheir approach, from multi-agent systems to temporal reasoning.\nThe early detection of anomalies is a critical step in risk mitigation, \nallowing for proactive measures to be taken before significant market \ndisruptions occur.\n2.6.3 Risk mitigation\nCurrently, there are no papers found that directly fit this category.\n2.7 Financial content generation and data \nintegration\nThis section covers research that utilizes LLMs for generating \nfinancial content or integrating large-scale datasets. The overarching \naim is to synthesize information from diverse sources into coherent, \nactionable outputs that aid in decision-making and provide market \ninsights. Key areas of focus include:\n2.7.1 Report generation/automation\n • Nishida and Utsuro (2025) demonstrates automated production \nof financial news articles covering stock price fluctuations.\n • Pop et al. (2024) discusses how LLMs streamline equity research \nreporting by automating significant portions of the \nwriting process.\nWhile both papers focus on automating financial content, Nishida \nand Utsuro (2025) is geared toward generating news articles with a \nfocus on timeliness, whereas ( Pop et  al., 2024 ) focuses on the \nautomation of more in-depth equity research reports.\n2.7.2 Financial LLM development and \ndemocratization\n • Liu et al. (2023) introduces an open-source framework (FinGPT) \ndesigned to democratize financial LLMs. It covers data collection, \nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 08 frontiersin.org\nfine-tuning, and various adaptation strategies, supporting a wide \nrange of downstream applications.\n2.8 Benchmarking, surveys, evaluation and \ndatasets\nThis final category highlights studies that assess and benchmark the \nperformance of LLMs in financial contexts. These works often involve \nsurveys, comparative analyses, or the introduction of new evaluation \nframeworks—serving as foundational references for future research.\n • Surveys and reviews: Several papers (Zhao et al., 2024; Nie et al., \n2024; Kong et al., 2024; Ding et al., 2024; Kong et al., 2024) offer \nbroad overviews of LLM applications, ranging from automating \nfinancial reports to deploying trading agents.\n • Benchmarks: Papers (Li et al., 2024; Mateega et al., 2025; Krause, \n2023) focus on the development of new benchmarks (e.g., \nInvestorBench, FinanceQA), enabling more systematic \ncomparisons of LLM performance. Li et al. (2024)  focuses on \ncreate a benchmark/standardized way to evaluate how well LLMs \nperform in financial analysis tasks.\n • Comparisons: Abdelsamie and Wang (2024)  benchmarks \nspecialized financial LLMs, like Quantum, against human \nanalysts and general-purpose LLMs to evaluate their market \nprediction accuracy and efficiency.\n • Limitations: Papers ( Bi et al., 2024 ; Chiang et al., 2025 ) delve \ninto the practical potential and limitations of LLMs for \nfinancial forecasting and strategic decision-making, \nunderscoring the need for ongoing evaluation in this rapidly \nevolving field.\n3 LLM technical innovations, \napproaches\nThis section presents the key technical innovations \nunderpinning recent research in the application of Large Language \nModels (LLMs) to Financial Stock Investing. We  offer a \ncomprehensive overview of the methodologies employed across \nthese studies, highlighting the diverse techniques and nuanced \napproaches that drive progress in this field. Figure  2 provides a \nsummary of the categorization of recent research by different \napproaches for LLMs.\nFIGURE 2\nCategorization of research by LLM technique/methodology.\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 09 frontiersin.org\n3.1 Surveys and benchmarks\nThis category includes research that systematically evaluates the \nperformance of LLM-based financial applications through \nbenchmarks, surveys, and evaluation frameworks, providing critical \ninsights into both the capabilities and limitations of \ncurrent approaches.\n3.1.1 Broad overview\n • Zhao et  al. (2024)  and Kong et  al. (2024)  provides a \ncomprehensive overview of how LLMs are being applied \nin finance.\n • Bi et  al. (2024)  surveys how AI—especially ChatGPT—can \ntransform financial forecasting, addressing key challenges such \nas privacy and ethics.\n • Kong et al. (2024) reviews the transformation of finance by LLMs, \ncategorizing applications and presenting datasets, benchmarks, \nand methodologies for future research.\nWhile all three papers provide broad overviews, Zhao et al. (2024) \nand Kong et al. (2024) offer a general view, Bi et al. (2024) focuses on \nthe potential of a specific LLM, and Kong et al. (2024)  provides a \nstructured categorization of the field.\nNote that the categorization is not completely mutually \nexclusive, some papers that fit in two categories are represented in \nthe one category and by an asterisk in the next most \nrelevant category.\n3.1.2 Application-specific overviews\n • Sentiment analysis: Liu et al. (2024) provides a deep dive into the \napplication of LLMs for financial sentiment analysis, using \ndetailed datasets and case studies.\n • Trading agents: Ding et  al. (2024)  reviews the landscape of \nLLM-based trading agents.\nThe application-specific overviews provide a foundation for more \ndetailed technical evaluation.\n3.1.3 Technical overview\n • Nie et al. (2024) offers an in-depth review of various approaches, \ndetailing progress, prospects, and challenges while classifying \napplications into linguistic, sentiment, financial, and agent-\nbased tasks.\n3.1.4 Benchmarking and bias evaluation\n • Li et  al. (2024)  introduces InvestorBench, a standardized \nbenchmark for evaluating LLM-based agents in financial \ndecision-making across equities, cryptocurrencies, and ETFs, \nassessing their reasoning and decision-making capabilities using \n13 different LLM backbones.\n • Glasserman and Lin (2023) evaluates both “Look Ahead Bias” \nand the “distraction effect” by comparing sentiment-driven \ntrading strategies based on original versus anonymized news \nheadlines, using in-sample and out-of-sample tests to isolate and \nmeasure these biases.\n • Yu (2023) presents a case study on US equity market news \nsentiment analysis revealing significant variability in LLM \nsentiment classification, highlighting inherent output \nvolatility. This could act as a benchmark reference for \nfuture research.\nLi et  al. (2024)  provides a broad benchmark for financial \nagents, while ( Glasserman and Lin, 2023 ; Yu, 2023 ) focus on \nspecific aspects of LLM performance, such as bias and output \nvolatility. Glasserman and Lin (2023)  and Yu (2023) both use real \nworld data to evaluate LLMs, whereas ( Li et  al., 2024 ) builds \na benchmark.\nThe findings from these benchmarking and bias evaluations \ninform the broader overviews and technical analyses.\n3.2 Prompting techniques\nPrompting techniques are pivotal in harnessing the capabilities of \nLLMs for financial applications, enabling precise control over model \noutputs and facilitating complex reasoning. This section explores \nvarious prompting methodologies, demonstrating their impact across \ndiverse financial equity investing tasks, from forecasting to \nportfolio management.\n3.2.1 Zero-shot and few-shot prompting for \nfinancial analysis and forecasting\nPaper 5: Uses GPT-4-32k with a diverse set of financial datasets \n(covering fundamental, market, and news data) and a Retrieval \nAugmented Generation (RAG)-like strategy to generate multi-horizon \nequity stock ratings. It employs both zero-shot and few-shot \nprompting for effective data integration.\n • Nishida and Utsuro (2025) generates explanatory financial news \narticles about stock price movements by implementing few-shot \nlearning and contrasting its performance with zero-shot methods.\n • Pop et al. (2024) enhances stock trend prediction by applying a \n“denoising-then-voting” technique that combines few-shot \nlearning with in-context prompt engineering.\n • Mateega et al. (2025) automates the extraction of key elements \nfrom equity research reports by combining zero-shot/few-shot \nprompting with information retrieval.\n • Chen et al. (2024) investigates ChatGPT’s forecasting tendencies \nby analyzing its extrapolation behavior, calibration, and inherent \nbiases in predicting historical stock returns using a prompt-\nbased approach.\n • Lee et  al. (n.d.)  converts qualitative textual insights into \nquantitative market prediction scores by leveraging crafted \nprompts with dynamic few-shot examples.\n • Swamy et al. (n.d.) extracts quantitative signals from qualitative \ndata—such as moving averages and options volume—using \ninnovative prompting strategies and integrates these signals with \ntraditional quantitative features.\n • Lefort et  al. (2024)  classifies financial news sentiment and \nde-noises aggregated outputs through zero-shot and few-shot \nprompting, supporting trading decisions on the NASDAQ.\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 10 frontiersin.org\n • Chen et al. (2024) applies zero-shot classification to analyze over \n77 million investor social-media posts, categorizing them into \ntechnical versus fundamental analysis and bullish versus \nbearish sentiment.\n • Romanko et  al. (2023) implements a two-step process where \nprompting (via zero-shot/few-shot methods) gathers stock \nsuggestions, which are then refined using traditional portfolio \noptimization techniques (e.g., Markowitz mean–\nvariance optimization).\nThese papers showcase the versatility of zero-shot and few-shot \nprompting, varying in their complexity and application. Papasotiriou \net al. (2024) and Romanko et al. (2023) utilize RAG and optimization \ntechniques, respectively, to enhance the prompting process, while \nother papers focus on direct application to sentiment analysis, \nforecasting, and data extraction.\nThe effectiveness of these prompting techniques extends to \nportfolio management, where tailored prompts can guide LLMs in \ngenerating and evaluating investment strategies.\n3.2.2 Prompting techniques in portfolio \nmanagement\n • Li et  al. (2024)  leverages zero-shot prompting to generate \nportfolios and assess asset diversification, comparing the \nperformance of these portfolios against randomly selected ones.\n • Ko and Lee (2024)  uses ChatGPT in a zero-shot setting to \nproduce asset class selections, which are quantitatively evaluated \nfor diversity and performance.\n • Fieberg et  al. (2024)  employs structured prompts across 32 \ndifferent LLMs, each reflecting diverse investor profiles, to \ngenerate financial advice that is then evaluated for suitability, \nperformance, and potential bias.\n • Lu (2025) integrates a ChatGPT-based system—utilizing both \nzero-shot and few-shot prompting—into a robo-advisor \nframework to enhance investor understanding of alpha and beta, \nleading to improved portfolio choices.\n • Bond et al. (2023) utilizes ChatGPT’s zero-shot NLP capabilities \nto analyze daily U.S. news summaries and generate a market \nsentiment indicator for short-term stock return forecasting.\n • Wang et al. (2023) also covers the development of Alpha-GPT, an \ninteractive system that uses prompt engineering and LLMs to \ngenerate creative trading signals, validated through alpha \nmining experiments.\nThese papers demonstrate the application of prompting for \nportfolio management, with variations in the use of zero-shot versus \nfew-shot prompting, as well as the use of LLMs to generate investment \nadvice, and trading signals. Fieberg et  al. (2024)  and Lu (2025)  \nincorporate the analysis of investor profiles, and educational aspects, \nwhereas the rest of the papers focus on pure portfolio creation \nand analysis.\n3.2.3 Chain of thought prompting\n • Fatouros et al. (2024) uses GPT-4 as both a predictor and signal \nevaluator for stock selection by analyzing diverse financial data. \nIt employs chain-of-thought and in-context learning techniques \nto enhance signal accuracy.\n • Deng et  al. (2022)  adopts a semi-supervised approach by \nprompting an LLM with chain-of-thought techniques to generate \nweak sentiment labels from Reddit posts, which are then distilled \ninto a smaller model using regression loss—achieving \nperformance comparable to supervised methods.\nThese papers show how chain of thought prompting allows LLMs \nto create better outputs, by improving the reasoning process. Fatouros \net al. (2024) uses it to improve signal accuracy, whereas (Deng et al., \n2022) uses it to create better sentiment labels.\n3.2.4 Instruction prompting and context \nprompting\n • Perlin et al. (n.d.) evaluates Google’s Gemini 1.5 Flash LLM for \ninvestment decision-making using anonymized U.S. market data. \nIt queries the LLM with prompts that specify investment horizons \nand relevant financial inputs.\n • Huang et al. (2024) implements scenario-based iterative prompt \nengineering to generate stock suggestions. These suggestions are \nsubsequently screened using additional financial algorithms \n(NBESOA) for optimized portfolio construction.\n • Lu et al. (2023) uses a prompt-based approach with data feeds \nfrom the Wall Street Journal and China State policy datasets to \nassess the efficacy of ChatGPT in providing financial stock \ninvesting recommendations.\n • Dolphin et al. (2024) by combining LLM generative capabilities \nwith advanced prompting and a validation framework using \nstring similarity, the system extracts granular, per-company \ninsights from news articles, demonstrating high accuracy and \nproviding a live API and dataset for further research.\nThese papers showcase the use of instruction and context \nprompting across various applications, from evaluating LLM \nperformance to generating stock suggestions and extracting market \ninsights. Perlin et al. (n.d.) and Lu et al. (2023) focus on evaluation, \nwhereas (Huang et al., 2024; Dolphin et al., 2024) focus on the creation \nof outputs.\n3.2.5 Knowledge generation prompting\n • Cheng and Tang (2023)  leverages GPT-4 to autonomously \ngenerate equity investment factors through knowledge \ninference without direct data input. It employs prompting \nstrategies that guide GPT-4  in reasoning and generating \nthese factors.\n3.3 Comparison across LLM models\nComparative analysis of LLMs is crucial for understanding their \nrelative strengths and weaknesses in financial equity applications. This \nsection explores studies that benchmark different models across various \ntasks, highlighting the nuances in their performance and capabilities.\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 11 frontiersin.org\n • Krause (2023) compares the performance of ChatGPT, Bard, and \nBing on various financial tasks—including report/text generation, \ndecision support, summarization, and general NLP—to assess \ntheir suitability for financial analysis.\n • Wu (2024) evaluates and contrasts multiple LLMs (e.g., ChatGPT, \nTongyi Qianwen, and Baichuan Intelligence) in generating news-\nbased stock scores and predicting stock market returns.\n • Shi and Hollifield (2024) assesses the predictive capabilities of \nGPT against traditional transformer models like BERT using \neconomic data from the Federal Reserve Beige Book, to \ndetermine their effectiveness in financial market prediction.\n • Tandon (2024) systematically reviews and compares various LLM \ntechniques (including BERT and FinBERT) for stock market \nprediction by analyzing financial news headlines using historical \ndatasets from Kaggle and Y ahoo Finance.\n • Voigt et  al. (2024)  adapts NLP-centric, Transformer-based \narchitectures for stock price forecasting by leveraging the \nstructural parallels between text sequences and time-series data, \nwith the expectation that models excelling in language processing \ncan capture temporal dependencies in financial markets.\n • Abdelsamie and Wang (2024) Compares the performance of \nQuantum, an advanced LLM specialized for financial forecasting, \nwith other general purpose LLMs—GPT-3, GPT-4, FinGPT, and \nFinBERT and human analysts. Employing a dataset of historical \nfinancial data, news headlines, and social media sentiment, the \nresearch systematically assesses predictive accuracy, response \nefficiency, and interpretability across models.\n • Lopez-Lira and Tang (2023)  compares the performance of \nvarious GPT models, BERT and Finbert to confirm accuracy and \nreliability in predicting stock prices based on new headlines while \nalso suggesting an interpretability framework\n • Kirtac and Germano (2024)  covers a comparative analysis of \nLLMs, including GPT-3-based OPT model, BERT, and FinBERT, \nalongside traditional methods for financial news sentiment \nanalysis, demonstrating that OPT significantly outperforms \nothers in predicting stock market returns and generating \nsubstantial trading profits.\nThese papers vary in their scope and focus, from comparing \ngeneral-purpose LLMs across diverse tasks (Krause, 2023; Wu, 2024) \nto evaluating specialized financial LLMs against human analysts and \ntraditional models (Abdelsamie and Wang, 2024; Kirtac and Germano, \n2024). Shi and Hollifield (2024), Tandon (2024) and Voigt et al. (2024) \nfocus on comparing LLMs against traditional transformer models. \nLopez-Lira and Tang (2023) adds the dimension of interpretability. \nThe evaluations vary in the data used, and the metrics used.\nThe findings from these comparative studies inform the \ndevelopment of more effective prompting techniques and the selection \nof appropriate models for specific financial investing tasks.\n3.4 Finetuning\nFinetuning plays a critical role in adapting Large Language Models \n(LLMs) to the specific demands of financial stock investing tasks, \nenabling them to capture nuanced patterns and generate accurate \npredictions. This section reviews various finetuning methods used to \nadapt Large Language Models to financial tasks, ranging from \ninstruction tuning to parameter-efficient finetuning and \nknowledge distillation.\n3.4.1 Finetuning/domain adaptation\n • Guo and Hauptmann (2024) fine-tunes LLMs for stock return \nforecasting, integrating and comparing token-level embeddings \nfrom different LLM architectures.\n • Valeyre and Aboura (2024) evaluates the Chronos model for time \nseries prediction in financial markets by testing both its pre-trained \nand fine-tuned configurations using supervised forecasting.\n • Aparicio et al. (2024) adapts BioBERT to the financial domain by \nfine-tuning it on curated financial textual databases, enabling \nsentiment analysis of press releases and financial texts around key \nbiotech stock inflection points.\n • Wang et al. (2024) this research developed InvestAlign, a method \nthat constructs supervised fine-tuning training datasets for LLMs \nusing theoretical solutions from simplified investment problems, \nrather than costly and privacy-sensitive real-user data, to better \nalign LLM investment decisions with human investor behavior.\nThese papers demonstrate various approaches to domain \nadaptation, ranging from fine-tuning for specific prediction tasks \n(Guo and Hauptmann, 2024; Valeyre and Aboura, 2024) to adapting \nmodels from other domains ( Aparicio et  al., 2024 ) and creating \nsynthetic datasets for finetuning (Wang et al., 2024). The data used, \nand the model architectures adapted vary significantly.\nInstruction finetuning builds upon domain adaptation by \nincorporating specific instructions to guide the model’s learning.\n3.4.2 Instruction finetuning and instruction \nprompting\n • Liang et al. (2024)  constructs an instruction tuning dataset \nusing a multi-step process—clustering company-related news \nto capture dissemination influence, enriching prompts with \ncontext and explicit instructions, and then fine-tuning the \nLLM—to enhance sentiment-based stock movement prediction.\n3.4.3 Parameter efficient finetuning (PEFT)\nPEFT aims to reduce the computational and memory costs \nassociated with finetuning large models\n • Konstantinidis et al. (2024) implements LoRA fine-tuning on \nLlama 2 7B within a generator-classifier architecture for efficient \nfinancial sentiment analysis. [Custom Architecture]\n • Liu et al. (2023) introduces FinGPT, an open-sourced framework \nthat automates real-time financial data collection and adapts \ngeneral-purpose LLMs for applications like robo-advising and \nsentiment analysis using LoRA/QLoRA fine-tuning, coupled \nwith reinforcement learning (RLSP). [Reinforcement Learning]\nKonstantinidis et al. (2024) and Liu et al. (2023) both utilize LoRA \nfinetuning, but they differ in their architectures and applications. \nKonstantinidis et al. (2024) uses LoRA within a custom architecture, \nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 12 frontiersin.org\nwhereas (Liu et al., 2023) uses LoRA within its open-source framework, \nand also in conjunction with reinforcement learning.\n3.4.4 Combined instruction and parameter \nefficient finetuning\nCombining instruction finetuning with parameter-efficient \ntechniques allows for both task-specific adaptation and \ncomputational efficiency.\n • Ni et al. (2024) employs a QLoRA-enhanced instruction fine-\ntuning strategy that combines base and external factors for \nimproved stock prediction following earnings reports.\n • Li et al. (2023) leverages both unsupervised and supervised LoRA \non Llama2 alongside instruction fine-tuning on GPT3.5 to \nautomate summarization and idea generation from diverse financial \ntexts, thereby enhancing fundamental investment research.\n3.4.5 Instruction tuning with reinforcement \nlearning\nReinforcement learning can be  integrated with instruction \nfinetuning to further refine model performance based on real-\nworld feedback\n • Zhao and Welsch (2024) includes finetuning of LLaMA 2 model \nwith instruction tuning to incorporate human instructions. \nAdditionally, reinforcement learning (RL) is used to incorporate \nstock market feedback by dynamically adjusting knowledge \nsource weights within a RAG module, improving financial \nsentiment analysis and stock price movement prediction.\nFinetuning can also be used to enhance embedding generation for \npredictive modeling.\n3.4.6 Fine tuning for embedding generation and \npredictive modeling\n • Chen et al. (2022) utilizes LLMs (e.g., ChatGPT and LLaMA) to \nextract contextualized representations from news text for \npredicting expected stock returns. The study demonstrates that \nLLM-based predictions, which capture broader article context \nand complex narratives, significantly outperform traditional \ntechnical signals across multiple global equity markets.\n3.4.7 Finetuning and knowledge transfer\n • Das et  al. (2024)  combines financial textual data (news and \nsentiment) with price signals by leveraging large pretrained \nmodels (e.g., LLaMA-2-13B, Mistral, Gemma). These models are \nfurther fine-tuned or prompted in a zero−/few-shot manner to \ngenerate automated trading actions, facilitating effective \nknowledge transfer.\n3.5 Agentic frameworks\nAgent-based systems have the potential to transform financial \nstock and equity investing by automating complex decision-making \nprocesses. This section reviews various agentic applications, from \nsingle-agent solutions to sophisticated multi-agent frameworks, \nhighlighting their diverse approaches and impacts. Research on agent-\nbased frameworks in financial stock and equity investing is still \nemerging, with only 20 of the 84 reviewed papers focusing on agent \nsystems. (Note: Ding et al. (2024) is a survey and is covered in Section \n3.1.1.).\n3.5.1 Single-agent applications\n • Yue and Au (2023)  GPTQuant uses prompt templates and \nLangChain to create a conversational AI agent that generates \nPython code for investment research, streamlining the \nanalysis process.\n • Koa et  al. (2024)  covers the development of a Summarize-\nExplain-Predict (SEP) framework, which utilizes a self-reflective \nagent and Proximal Policy Optimization (PPO) to train an LLM \nto autonomously generate explainable stock predictions, \nachieving superior performance in both prediction accuracy and \nportfolio construction.\n3.5.2 Multi-agent systems using chain-of-thought \n(CoT)\nMulti-agent systems expand on these single-agent capabilities by \ncoordinating multiple agents to perform complex tasks\n • Zhou et al. (2024) utilizes a multi-agent CoT system to automate \nequity research and valuation by combining quantitative and \nqualitative analysis. It dynamically updates its data using three \nspecialized agents (Data CoT, Concept CoT, and Thesis CoT) that \nemulate human analyst reasoning, resulting in high-quality, \ntimely research.\n • Wang et al. (2024) to understand LLM’s reasoning approach for \ntrading decision, study introduce FS-ReasoningAgent, a multi-\nagent framework that separates reasoning into factual and \nsubjective components, demonstrating enhanced LLM trading \nperformance and showing that subjective news drives returns in \nbull markets, while factual data performs better in bear markets.\nZhou et al. (2024) and Wang et al. (2024) both employ multi-agent \nCoT systems, but they focus on different aspects of financial investing. \nZhou et al. (2024) automates equity research, while (Wang et al., 2024) \nanalyzes the impact of factual versus subjective news on \ntrading decisions.\n3.5.3 Multi-agent systems with coordinated \nnetworks\nCoordinated networks further enhance multi-agent systems by \nenabling complex interactions and adaptive decision-making.\n • Kou et al. (2024) proposes a multi-step framework where LLMs \nextract alpha factors from multimodal financial data. These \nfactors are integrated into a multi-agent system with dynamic \nweight-gating to produce an adaptive composite alpha formula \nfor enhanced portfolio management.\n • Zhang et al. (2024) introduces a multi-agent system, “StockAgent, ” \nwhich simulates investor trading behavior in a realistic market \nenvironment. Agents make trading decisions based on various \nexternal factors.\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 13 frontiersin.org\n • Park (2024)  presents a multi-agent framework for anomaly \ndetection in financial markets. It employs specialized agents for \ndata conversion, expert web analysis, institutional knowledge \napplication, cross-checking, and report consolidation, thereby \nautomating anomaly alert validation in the S&P 500, reducing \nmanual verification.\n • Xiao et  al. (2024)  deploys a multi-agent framework \n(TradingAgents) that simulates a trading firm by assigning \nroles such as fundamental, sentiment, and technical analysts, \nalong with risk management agents. These agents \ncollaboratively debate and synthesize diverse analyses and \nhistorical data to inform trading decisions, outperforming \nbaseline models on key metrics\n • Fatemi and Hu (2024) develops a multi-agent system (FinVision) \nthat analyzes diverse multimodal financial data (including text \nand charts) using a “reflection module” that reviews past trading \nsignals—especially visual cues—to improve stock \nmarket predictions.\n • Xing (2024) proposes a heterogeneous LLM agent framework for \nfinancial sentiment analysis, where specialized agents \ncollaboratively discuss identified error types to improve accuracy \nwithout additional fine-tuning.\n • Y ang et al. (2024) presents an open-source multi-agent platform \n(FinRobot) for financial tasks that employs a layered architecture. \nIt leverages Financial Chain-of-Thought to decompose complex \nproblems, dynamically selects LLM strategies, and integrates \ndiverse models through LLMOps and DataOps.\n • Y ang et al. (2025) presents TwinMarket (a multi agent framework) \nthat simulates individual behaviors and interactions to \ndemonstrate how they lead to collective dynamics and emergent \nphenomena, such as financial bubbles and recessions, within a \nsimulated stock market.\n • Li et  al. (2023) TradingGPT (single and multi-agent system) \nutilizes three memory layers with custom decay mechanisms, \ninter-agent debate, and individualized trading traits to enable \nagents to effectively integrate historical data and real-time market \nsignals for enhanced trading decisions. Note the layered memory \nalso fits in custom architecture\nThese papers showcase diverse approaches to multi-agent \nsystems with coordinated networks, ranging from alpha factor \nextraction (Kou et al., 2024) to anomaly detection (Park, 2024) and \ntrading simulation (Zhang et al., 2024; Xiao et al., 2024; Fatemi and \nHu, 2024; Y ang et al., 2025; Li et al., 2023 ). The complexity of the \nsystems, and the tasks performed vary significantly. Xing (2024) and \nY ang et  al. (2024) focus on frameworks, whereas the rest focus \non applications.\n3.5.4 Multi-agent systems with reinforcement \nlearning\nReinforcement learning can further enhance multi-agent systems \nby enabling agents to learn from experience and adapt to changing \nmarket conditions.\n • Yu et al. (2024) introduces FinCon, a hierarchical multi-agent \nsystem modeled after real-world investment firms. It employs a \n“conceptual verbal reinforcement” mechanism where agents self-\ncritique and update their investment beliefs to guide future \nactions, thereby improving performance and reducing \nunnecessary communication.\n • Yu et al. (2023) presents FinMem a multi-agent architecture that \nincorporates three core modules: Profiling for agent \ncustomization, a layered Memory module that emulates human \ntrader cognition for efficient hierarchical data assimilation, and \nDecision-making to translate insights into investment actions; \nthis design allows the agent to self-evolve, adapt to market cues, \nand surpass human perceptual limits, resulting in improved \ntrading performance.\n • Li et al. (2024) CryptoTrade, incorporates a reflective mechanism \nto analyze prior trading outcomes and refine daily decisions, \ndemonstrating superior performance compared to traditional \nstrategies and time-series baselines across various \ncryptocurrencies and market conditions.\nThese papers demonstrate the use of reinforcement learning in \nmulti-agent systems, with variations in the reinforcement mechanisms \nand applications. Yu et  al. (2024)  uses a conceptual verbal \nreinforcement mechanism, whereas (Yu et al., 2023) focuses on a multi \nmodule architecture, and (Li et al., 2024) uses a reflective mechanism.\n3.6 Custom architecture\nCustom architectures are pivotal in pushing the boundaries of \nLLM applications in finance, enabling the development of specialized \nmodels that address unique challenges. This section explores a variety \nof innovative architectural approaches, from knowledge distillation to \nhybrid and multi-modal frameworks. Please note multi-agent \narchitectures are covered explicitly in the section 3.5—\nAgentic Applications.\n3.6.1 Knowledge distillations\nKnowledge distillation includes the transfer knowledge from a \nlarge “teacher” model to a smaller “student” model.\n • Bhat (n.d.) employs a computationally efficient distilled LLM to \nextract emotional tone and intensity from financial news \nheadlines. The distilled model’s outputs are fed into classification \nalgorithms for predicting stock price direction, demonstrating \nthat emotion analysis alone can rival the performance of \ntraditional financial data methods.\n3.6.2 Transfer learning and foundation models\nTransfer learning and foundation models extend this concept by \nleveraging pre-trained knowledge for broader applications. Guo and \nShum (2024)  demonstrates the power of transfer learning and \nfoundation models in capturing universal market patterns.\n • Guo and Shum (2024) utilizes a novel LLM structure designed \nfor large-scale investment applications. The model, termed Large \nInvestment Model (LIM), employs a “foundation model” \napproach by training on vast financial datasets to learn universal \nmarket patterns, which are then transferred via transfer learning \nto develop specialized and efficient investment strategies for \nvarious financial tasks.\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 14 frontiersin.org\n3.6.3 Retrieval-augmented and agent-based \narchitectures\nRetrieval-augmented and agent-based architectures further \nenhance LLM capabilities by integrating external knowledge and \ndynamic interactions.\n • Fatouros et  al. (2025)  introduces MarketSenseAI 2.0, which \ncombines Retrieval-Augmented Generation (RAG) with LLM \nagents for comprehensive stock analysis and selection. This \nframework processes diverse data types—including financial \nnews, historical prices, company fundamentals, and \nmacroeconomic indicators—with RAG handling SEC filings, \nearnings calls, and institutional reports. Empirical results on \nS&P  100 stocks (2023–2024) indicate cumulative returns of \n125.9% versus an index return of 73.5%.\n • Kim and Oh (n.d.) presents an integrated system that fuses RAG \nwith LangChain to dynamically retrieve and synthesize external \nfinancial data, producing real-time, contextually enriched stock \nanalysis reports.\nFatouros et al. (2025) and Kim and Oh (n.d.) both use RAG, but \n(Fatouros et al., 2025) uses RAG in combination with LLM agents.\n3.6.4 Time series and temporal reasoning \narchitectures\nTime series and temporal reasoning architectures complement \nother forms by focusing on the temporal dynamics of financial data.\n • Wang et  al. (2024)  proposes StockTime, a specialized LLM \narchitecture designed explicitly for stock price time series data. \nBy treating stock prices as consecutive tokens, StockTime extracts \ntextual information (e.g., correlations, trends, timestamps) and \nintegrates this with time series data into an embedding space. \nThis multimodal fusion yields more accurate predictions while \nreducing memory usage and runtime costs.\n • Koa et  al. (2024)  introduces Temporal Relational Reasoning \n(TRR), a framework that combines LLM-based zero-shot text \ninterpretation with cognitively inspired components (memory, \nattention, reasoning) to track and aggregate news impacts over \ntime. This structured approach improves detection of impending \nportfolio crashes by modeling temporal relationships among \nevents and stocks.\nWang et al. (2024) and Koa et al. (2024) both address temporal \nreasoning, but they differ in their approaches. Wang et  al. (2024) \nfocuses on treating time series data as tokens, while (Koa et al., 2024) \nintegrates cognitive components.\n3.6.5 Hybrid and multi-modal frameworks\nHybrid and multi-modal frameworks integrate diverse data types \nand models to capture complex market relationships.\n • Di et  al. (2024) proposes a custom architecture for securities \nindex prediction that integrates LLM-driven knowledge \nextraction with a heterogeneous graph and a Graph Neural \nNetwork (GNN) to capture complex market relationships.\n • Tong et  al. (2024)  presents a novel, integrated two-part \nframework (Ploutos) that combines specialized experts for \nmulti-modal data analysis with tailored prompting and dynamic \ntoken weighting to enhance interpretability in stock \nmovement prediction.\n • Ding et al. (2023) introduces a novel framework that combines a \nLocal–Global model for integrating stock features with \nLLM-derived semantic information and employs self-correlated \nreinforcement learning to align these embeddings within a \nshared semantic space.\nThese papers showcase diverse hybrid and multi-modal \nframeworks, combining various techniques to capture complex \nmarket relationships. Di et al. (2024), Tong et al. (2024) and Ding et al. \n(2023) all use different methods to combine different data types \nand models.\n3.7 Retrieval-augmented generation (RAG)\nRetrieval-Augmented Generation (RAG) in stock investing \nenables LLMs to provide more accurate and contextually relevant \nfinancial insights by dynamically retrieving and incorporating up-to-\ndate information from diverse sources like news articles, financial \nreports, and market data.\nWe observe that only a few papers out of the 84 research papers \nincorporate RAG in some form, with just two using it as the \nprimary technique.\n • Li et  al. (2024)  introduces AlphaFin, a data set combining \ntraditional research datasets, real-time financial data, and \nhandwritten chain-of-thought (CoT) data to address the \nlimitation of limited financial training dataset availability. Further \nthey introduce a RAG based, two phased framework \n(StockChain) for financial analysis.\nSeveral papers incorporate RAG with diverse techniques. Papers \n(Papasotiriou et al., 2024; Romanko et al., 2023) combine RAG with \nzero-shot and few-shot prompting; Papers (Kim and Oh, n.d.; Fatouros \net al., 2025) utilize RAG with agents and (Zhao, 2024) integrates RAG \nwith reinforcement learning while (Zhao and Welsch, 2024) uses RAG \nin combination with reinforcement learning and instruction tuning.\n3.8 Reinforcement learning\nThis section examines the integration of Reinforcement Learning \n(RL) with Large Language Models (LLMs) to advance financial \ntrading. Recent studies demonstrate RL ’s efficacy in enabling \nLLM-driven adaptive strategies, particularly in achieving regime-\nadaptive execution, enhancing the explainability of trading decisions, \nand improving portfolio performance across volatile market conditions.\n3.8.1 Regime adaptation via reinforcement \nlearning\n • Saqur and Rudzicz (2024) Leverages Reinforcement Learning \nfrom Market Feedback (RLMF), a regime-adaptive market \nexecution method, to dynamically adjust LLM behavior in real-\ntime. This model-agnostic approach, demonstrated with Llama-2 \nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 15 frontiersin.org\n7B, utilizes intrinsic market rewards and a teacher-student dual-\nphase pipeline (iterative train and execute cycles) to improve \npredictive accuracy by 15% over models like GPT-4o, effectively \ncircumventing the need for human-labeled data. This highlights \na trend in utilizing RL to reduce reliance on extensive human-\nlabeled datasets.\n3.8.2 Adaptive and explainable trading systems\n • Gu et  al. (2024) presents a framework that fuses LLMs with \nReinforcement Learning for margin trading. The LLM system \nanalyzes diverse financial data to produce market forecasts with \nexplainable reasoning, which are then integrated with RL to \ndynamically adjust trading positions, significantly boosting \nreturns and Sharpe ratios while enhancing transparency in \nportfolio management.\n • Zhao (2024)  introduces the Hierarchical Reinforced Trader \n(HRT), an adaptive Retrieval-Augmented Generation (RAG) \nframework for LLMs, employing bi-level Deep Reinforcement \nLearning (DRL) and an enhanced Univariate Flagging Algorithm \n(UFA) for model interpretability. This framework demonstrates \nsignificant improvements in portfolio performance and risk \nmanagement across diverse market conditions. Portfolio \ncomparisons to the S&P 500 reveal favorable results in both bull \nand bear/volatile market scenarios.\n3.9 Embedding based methods\nEmbedding-based methods leverage the semantic understanding \ncapabilities of Large Language Models (LLMs) to transform textual \nfinancial data into dense vector representations. This section explores \nrecent applications of LLM embeddings in financial analysis, focusing \non their use in stock prediction and communication evaluation.\n • Chen et al. (2022) utilizes state-of-the-art LLMs (e.g., ChatGPT, \nLLaMA) to extract contextualized embeddings from news \narticles. These embeddings capture nuanced language features—\nsuch as negation and complex narratives—and are used as input \nfeatures to predict stock returns, outperforming traditional \ntechnical signals and simpler NLP methods across diverse global \nequity markets.\n • Chiang et al. (2025)  leverages LLM-based vector embeddings \nderived from 192,000 earnings call transcripts to quantify the \nsemantic alignment and relevance of Q&A segments, providing \na novel metric for evaluating investor communication \neffectiveness. This method allows for a deeper understanding of \nthe relationship between the questions asked, and the answers \ngiven, in earnings calls.\n4 Data sets and models\nFor a comprehensive view on data sets used across the 84 different \nresearch is presented Figure 3.\nMajority of the datasets used in the 84 research studies are public \ndata sets available through SEC, Edgar, Y ahoo Finance, News, \nCompany websites, Social media. Only a few limited studies use \nspecialized datasets—Simulated Trading Environment Dataset (Zhang \net al., 2024; Xiao et al., 2024), Anonymized Portfolio Dataset (Perlin \net al., n.d. ), INVESTORBENCH Dataset (Li et al., 2024 ), FinLLM \nChallenge Dataset ( Das et  al., 2024 ), Boardroom Q&A Dataset \n(Chiang et  al., 2025 ), FinanceQA Dataset (for question–answer \nevaluation) (Mateega et al., 2025).\nA central theme across the 84 reviewed papers is the diversity of \nLLMs employed for financial tasks. Some studies leverage generic \ntransformer models (e.g., GPT, LLaMA) with minimal modifications, \nwhile others adopt domain-specific architectures fine-tuned on large \ncorpora of financial text. Figure 4 provides the distribution of LLMs \nused in research so far. Out of the 84 research papers evaluated, 50 \npapers provide specific reference to LLM names with a majority \naround 49 papers mentioning the use of general purpose LLMs such \nas GPT, Llama, BERT, others. A few studies present domain specific \nLLMs. Table  1 provides an overview of financial LLMs, including \ndetails on base models, parameters and key focus areas.\nOverall, the proliferation of finance-specific LLMs underscores a \nbroader industry trend toward domain adaptation, multi-agent \nframeworks, and hybrid modeling approaches that harness the unique \nstrengths of LLMs and insights from financial data.\n5 Discussion\n5.1 Strengths of existing research\nThe reviewed literature highlights several strengths in using LLMs \nfor stock investing:\n • Comprehensive Data Integration: Many studies successfully \nintegrate structured (e.g., financial statements, historical prices) \nand unstructured (e.g., news articles, earnings call transcripts, \nsocial media) data to enhance predictive accuracy.\n • Breadth of Coverage (Application & LLM Techniques):  \nResearch on use of LLMs in stock investing so far covers a broad \nset of financial end-use case applications (sentiment analysis, \nequity research, stock prediction, portfolio management, \nalgorithmic trading, others) and diverse set of LLM techniques \nranging from simple prompt based methods, to fine tuning, the \nuse of LLM agents for automated workflows and decisions and \nthe proposals of novel custom architectures.\n • Usage of General Purpose and Domain Specific LLM Models: \nMajority of the research studies conducted so far use general \npurpose LLMs such as GPT 3, 4, LlaMA, BERT and others. Only \na few studies use or present fine-tuned versions of general \npurpose LLMs such as (FinGPT, FinLlama, BioFinBERT) for \nimproved performance on financial investing tasks.\n • Advancements in Model Architectures:  Several studies \nintroduce novel frameworks such as Ploutos (for integrating \nnumerical and textual data) and using a combination of generator \nand classifier model, StockTime (for time-series adaptation), and \nMarketSenseAI (for multi-modal analysis using RAG). These \ninnovations improve LLM adaptability to financial markets.\n • Validation of potential to disrupt Sentiment Analysis and \nInvestment Research: Several research studies demonstrated \nsuperior performance of LLMs when used in sentiment analysis \nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 16 frontiersin.org\nto capture signals from large data sets (news, analyst reports and \nsocial media) compared to traditional methods. Similarly, \nresearch confirmed LLMs streamlining equity research (e.g., \nGPTQuant for report generation, FinRobot for sell-side research \nautomation) and support algorithmic trading through real-time \nprocessing and decision-making.\n • Emerging Multi-Agent and Reinforcement Learning Systems: \nResearch in AI-driven trading strategies has progressed beyond \nrule-based models to reinforcement learning and multi-agent \nframeworks that dynamically adjust to market conditions, \nimproving adaptability and efficacy of predictions, \nrisk management.\nCommon Data Types\n/g120Historical stock \nprices\n/g120Market indices (e.g., \nS&P 500, NASDAQ)\n/g120Trading volumes and \nreturns\n/g120Financial ratios and \ntechnical indicators\n/g120Portfolio \nperformance metrics\n/g120News articles and \nheadlines\n/g120Earnings reports \nand SEC filings\n/g120Press releases\n/g120Equity research \nreports and analyst \nopinions\n/g120Social media posts \n(e.g., Reddit, \nTwitter)\n/g120Transcripts of \nboardroom Q&A \nor advisory \nsessions\n/g120A blend of \nhistorical market \ndata and financial \nnews/earnings text\n/g120Portfolio \nperformance data \npaired with \nsentiment scores\n/g120Equity \nfundamentals \nmerged with \nqualitative analysis \nfrom reports\n/g120Synthetic or \nsimulated trading \nenvironments\n/g120Anonymized or \nproprietary portfolio \nperformance data\n/g120Custom-curated \nbenchmarks for \ndecision-making or \nboardroom \nsimulations\n/g120Composite \ndatasets \ncombining \nmultiple \nmodalities\n/g120Standardized \nQA pairs for \nfinancial \nanalysis\n/g120Aggregated \nbenchmark \ncollections for \nevaluating \ntrading agents \nor decision-\nmaking systems\nTypical Dataset Names and Sources\n/g120Yahoo Finance \nHistorical Prices \n(frequently used for \nstock prices and \nvolumes)\n/g120CRSP and \nCompustat( for \nhistorical returns, \nfundamentals, and \nfactor data)\n/g120WRDS/SEC \nEDGAR (for \nintegrating filings or \nnumeric performance \ndata)\n/g120Proprietary \nInstitutional/Portfolio \nDatasets (for studies \non portfolio \nperformance or risk \nmanagement)\n/g120Reuters News \nArchivea nd \nBloomberg News \nArchive\n/g120SEC EDGAR \nEarnings Reports \nand Filings\n/g120Thomson Reuters \nEquity Research \nDataseto r similar \nvendor-provided \ncorpora\n/g120Custom Financial \nSentiment \nCorpora( e.g., \nFinSent Corpus, \nReddit Finance \nDataset)\n/g120Boardroom Q&A \nDataset(transcript \ndata)\n/g120Yahoo \nFinance/CRSP data \ncombined with \nReuters/Bloomberg \nnews\n/g120SEC Filings plus \ntextual analysis \n(e.g., earnings \nreports processed \nfor sentiment)\n/g120Custom-curated \ndatasets that fuse \nmarket data with \nsocial media or \nnews sentiment \n(often created by \nthe research team)\n/g120Synthetic Multi-\nAgent Financial \nSimulation Dataset\n/g120Simulated Trading \nEnvironment \nDataset\n/g120Anonymized \nPortfolio Dataset\n/g120INVESTORBENCH \nDataset\n/g120FinLLM Challenge \nDataset\n/g120Boardroom Q&A \nDataset\n/g120FinanceQA \nDataset (for \nquestion–\nanswer \nevaluation)\n/g120Generative AI \nFinance \nBenchmark \nDataset (for \ncomparing \nChatGPT, Bard, \nBing AI, etc.)\n/g120Aggregated \nbenchmarks \nreferenced in \nsurvey papers\nDatasets used in \nResearch\nTime Series and \nNumerical Market \nData\nTextual and \nUnstructured \nFinancial Data\nCombined / Hybrid \nMulti-Modal \nDatasets\nSimulated, \nProprietary, and \nCustom-Curated \nDatasets\nBenchmark and \nEvaluation-\nSpecific Datasets\nFIGURE 3\nDatasets used across 84 different research papers.\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 17 frontiersin.org\n • Benchmarking and Standardization:  Studies such as \nInvestorBench and FinanceQA offer benchmarking frameworks \nto systematically evaluate LLM performance in finance, providing \na foundation for more structured comparisons.\n • Research Delivery in Constrained environments:  Access to \ncomputational resources—such as GPUs for model fine-tuning \ncould be  a limitation. Similarly, lack of transparency and \ndocumentation on closed source models is another limitation for \n12\n9\n333\n5 4 3\n11111111\n3\n1 2 111111\nFIGURE 4\nGeneral purpose (blue) and fine-tuned (orange) LLMs used in research.\nTABLE 1 Overview of financial LLMs for equity investing.\nModel name Base model Parameters Specialization Key features\nBloombergGPT BLOOM ~50B Financial text (news, reports, press)\nTrained on combined general \n+ financial corpus; strong \nperformance on news-based \ntasks\nFinGPT Various Varies Financial datasets\nFine-tuned with Low-Rank \nAdaptation (LoRA); \ndissemination-aware and \ncontext-enriched\nInvestLM LLaMA-65B 65B Financial investment tasks\nFine-tuned with a curated \ndataset for investment-related \napplications; focuses on \nadvanced RL integration\nFinLLaMA LLaMA-2 52B tokens\nFinancial sentiment classification, \ntrading simulations\nPre-trained on financial \ncorpus; instruction fine-tuned \nwith 573 K financial \ninstructions\nFinLlama LLaMA-2 (7B) 7B Sentiment analysis for algorithmic \ntrading\nFine-tuned for sentiment \nvalence and strength \nclassification; optimized using \nLoRA\nFinLLaV A FinLLaMA N/A\nMultimodal financial data (text, \ntables, charts)\nTrained with 1.43 M image-\ntext instructions to handle \ncomplex financial data types\nFinMA (PIXIU) LLaMA (7B & 70B) 7B, 70B\nFinancial sentiment analysis and \nNLP tasks\nFine-tuned on financial \ndatasets\nFinBERT BERT N/A Financial NLP tasks Pre-trained on general and \nfinancial corpora; uses multi-\ntask learning\nFLANG Custom N/A Financial corpus Domain-specific model\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 18 frontiersin.org\nexperimentation and Model interpretability. However, the \nbreadth of research so far despite these limitations is notable.\n5.2 Limitations of existing research studies\nDespite these strengths, several limitations remain:\n • Limited Real-World Testing: While many studies demonstrate \npromising results in controlled environments, few have tested \nLLM-driven investment strategies in real-world trading \nconditions. Challenges such as execution slippage, transaction \ncosts, and market impact are often overlooked.\n • Data Quality and Bias: LLMs are highly sensitive to the quality \nof the training data and the data used for inference. Many \nLLM-driven models depend on real-time market data and \nunstructured text sources, making them vulnerable to biased, \nmanipulated, or misleading information, leading to potential \noverfitting and poor generalization. There is a potential risk for \nbad actors and attackers to manipulate data to distort investing \noutcomes and money flow. Out of the 84 research papers, only \nfew research studies cover the data quality limitations and some \nfactor bias considerations.\n • Interpretability and Explainability Challenges: The black-box \nnature of many LLM-based models limits transparency, making \nit difficult for investors and regulators to understand, trust, and \njustify AI-driven investment decisions. This lack of \ninterpretability hinders broader adoption and raises regulatory \nconcerns in financial markets. GPT based models used in many \nresearch paper so far are closed-source and do not provide \nvisibility on the model specifications, limiting explainability.\n • Context window Limitations: All existing research studies focus \non data sets with limited sizes and scope. None of the studies \nhave elaborated or found a scalable solution for the high context \nwindow of inputs required for stock investing use cases- examples \ninclude PDF files with 100 + pages. Evaluating and\n • Challenges in Back-Testing and Validation: The risk of data \nleakage in back-testing remains a critical concern. Most studies \nfail to rigorously test against out-of-sample data or consider \nsurvivorship bias, which can inflate performance metrics.—\nmention few studies that account for this\n • Regional Coverage: Most research studies are focused on the US \nand China markets with one study covering data from the Japan \nmarket. Scalability of the findings and frameworks to data from \nmarkets in other regions remains an open question.\n • Coverage across Investment types:  Majority of the research \nconducted so far focusses on broader stock investing in the \nconstruct of long term/value investing. Research focus on \nday trading use cases or High frequency trading \nis unexplored.\n • Limited Exploration of Non-Equity Asset Classes:  Most \nresearch focuses on stock investing, with limited exploration of \nLLM applications in commodities, fixed income, or options \nmarkets, which require different risk assessment models.\nBy addressing these gaps, future research can refine LLM \napplications in financial investing, making them more accurate, \nscalable, and aligned with industry needs.\n5.3 Research gaps and future directions\nTo overcome current limitations and further enhance the utility \nof LLMs in stock investing, future research should focus on:\n • Hybrid Modeling Approaches:  Integrating LLMs with \ntraditional quantitative and AI models (e.g., econometric, factor \nmodels) and can leverage the strengths of both methodologies, \ncould improve predictive performance and decision-\nmaking reliability.\n • Reasoning Models: Most general purpose and generic LLMs \nused in the research so far are derived from GPT, BERT and \nLlama. There is limited to none reference to usage of reasoning \nmodels such as GPT o1, GPT o1mini, Deep Seek R1, others.\n • Efficiency Improvements- Solving for Computational \nOverhead and Latency: The large size and complexity of LLMs \noften result in high computational costs and latency issues, \nmaking real-time trading applications challenging. \nAdvancements in model optimization—such as distillation, \nquantization, and efficient fine-tuning techniques like LoRA—\ncould reduce computational overhead and latency, making real-\ntime applications more feasible. There is a huge potential for \nmodel architectural and algorithmic advances to meet unique \nneeds of stock investing use cases.\n • Scalability of Multi-Agent AI Systems: While multi-agent LLM \nframeworks have shown initial promise in controlled setups, \ntheir scalability, coordination mechanisms and reliability in high-\nstakes financial environments remain an open challenge.\n • Enhanced Explainability and Interpretability: Developing new \ninterpretability frameworks tailored to LLMs in financial/stock \ninvesting applications will be crucial for building stakeholder trust \nand ensuring regulatory compliance. Research into techniques \nthat demystify LLM outputs is needed. Future work must address \nthe ethical implications of automated decision-making\n • Ethical & Regulatory considerations: The ethical and regulatory \nimplications of deploying LLMs in equity markets require more \ncomprehensive investigation to ensure responsible adoption and \ncompliance with financial regulations. Current research, while \nacknowledging issues such as data biases and model \ninterpretability, often overlooks the broader ethical concerns, \nincluding the potential for LLMs to amplify market manipulations \nthrough biased or misleading data inputs, such as orchestrated \nsocial media campaigns or falsified financial reports. Additionally, \nthe lack of transparency in closed-source models (e.g., GPT-based \nsystems) raises concerns about accountability, particularly when \nthese models influence high-stakes investment decisions. \nRegulatory frameworks, such as those enforced by the SEC or \nESMA, demand rigorous validation and explainability of \nAI-driven strategies, yet few studies address compliance with \nthese standards or the ethical risks of over-reliance on automated \nsystems. Future research should prioritize developing frameworks \nfor ethical AI governance, including robust auditing mechanisms \nto detect and mitigate biases, transparent reporting protocols for \nLLM-driven decisions, and alignment with global financial \nregulations to foster trust and ensure equitable \nmarket participation.\n • Solving for Large Context Window: To ensure true scalability \nof use in financial applications, the context window limitations \nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 19 frontiersin.org\nof LLMs will need to be solved. Research on this topic will be vital \nfor true scalability.\n • Maintenance and Domain Adaptation: Domain-specific LLMs \nrequire continuous fine-tuning and updates to remain effective \nas market conditions evolve. This can be resource-intensive and \nmay limit scalability.\n • Addressing Bias and Data Manipulation Risks: Future research \nshould develop more robust techniques to detect and mitigate \nbiases in financial datasets, including adversarial attacks on \nAI-generated trading signals.\n • Adaptive Learning and Market Feedback Integration:  \nReinforcement learning from real market interactions should \nbe further explored to enable self-improving models that adapt \ndynamically to changing market conditions\n • Expansion to Broader Financial Instruments:  While most \nstudies concentrate on equities, LLM applications should \nbe extended to alternative asset classes, such as bonds, derivatives, \nand crypto markets, to assess their predictive power across \ndifferent financial products.\n • Cross-Regional and Cross-Market Evaluations:  LLM-based \ninvestment models should be tested across different geographic \nmarkets and economic conditions to assess their generalizability \nand robustness.\nAuthor contributions\nAJ: Conceptualization, Data curation, Formal analysis, \nInvestigation, Methodology, Project administration, Resources, \nSupervision, Validation, Visualization, Writing  – original draft, \nWriting  – review & editing. VM: Formal analysis, Investigation, \nMethodology, Supervision, Validation, Writing  – original draft, \nWriting – review & editing.\nFunding\nThe author(s) declare that no financial support was received for \nthe research and/or publication of this article.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe construed as a potential conflict of interest.\nGenerative AI statement\nThe authors declare that Gen AI was used in the creation of this \nmanuscript. We used for literature review and re-writing some of the \ntext concisely.\nPublisher’s note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be evaluated in this article, or claim that may be made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\nAbdelsamie, M., and Wang, H. (2024). Comparative analysis of LLM-based market \nprediction and human expertise with sentiment analysis and machine learning \nintegration. In Proceedings of the 2024 7th international conference on data science and \ninformation technology (DSIT) (pp. 1–6). IEEE.\nAparicio, V ., Gordon, D., Huayamares, S. G., and Luo, Y . (2024). BioFinBERT: \nfinetuning large language models (llms) to analyze sentiment of press releases and \nfinancial text around inflection points of biotech stocks. ArXiv. Available online at: \nhttps://arxiv.org/abs/2401.11011\nBhat, Rithesh H. Stock price trend prediction using emotion analysis of financial \nheadlines with distilled LLM model. PETRA '24: Proceedings of the 17th \ninternational conference on pervasive technologies related to assistive environments. \npp. 67–73.\nBi, S., Deng, T., and Xiao, J. (2024). The role of AI in financial forecasting: \nChatGPT's potential and challenges. ArXiv. Available online at: https://arxiv.org/\nabs/2411.13562\nBond, S. A., Klok, H., and Zhu, M. (2023). Large language models and financial \nmarket sentiment. Available online at: https://ssrn.com/abstract=4584928\nChen, S., Green, T. C., Gulen, H., and Zhou, D. (2024). What does ChatGPT make of \nhistorical stock returns? Extrapolation and miscalibration in LLM stock return forecasts. \nAvailable online at: https://ssrn.com/abstract=4941906\nChen, Y ., Kelly, B. T., and Xiu, D. (2022). Expected returns and large language models. \nAvailable online at: https://ssrn.com/abstract=4416687\nChen, S., Peng, L., and Zhou, D. (2024).Wisdom or whims? Decoding investor trading \nstrategies with large language models. Available online at: https://ssrn.com/\nabstract=4867401\nCheng, Y ., and Tang, K. (2023). GPT's idea of stock factors. Available online at: https://\nssrn.com/abstract=4560216\nChiang, H., Hynes, L., and Sandberg, D. (2025). Questioning the answers: LLMs enter \nthe boardroom. S&P global market intelligence quantamental report. Available online \nat: https://ssrn.com/abstract=5109196\nDas, S., Zera, R. E., Lyngkhoi, M., Saha, S., and Maurya, A. (2024). Wealth guide: a \nsophisticated language model solution for financial trading decisions. In Proceedings of \nthe eighth financial technology and natural language processing and the 1st agent AI for \nscenario planning, pp. 133–140, Jeju, South Korea.\nDeng, X., Bashlovkina, V ., Han, F ., Baumgartner, S., and Bendersky, M. (2022). What \ndo LLMs know about financial markets? A case study on Reddit market sentiment \nanalysis. WWW '23 companion: companion proceedings of the ACM web conference \n2023, pp. 107–110\nDeng, Y ., He, X., Hu, J., and Yiu, S. (2024). Enhancing few-shot stock trend \npredictionswith large language models. ArXiv. Available online at: https://arxiv.org/\nabs/2407.09003s\nDi, Z., Chen, J., Y ang, Y ., Ding, L., and Xiang, Y . (2024). LLM-driven knowledge \nenhancement for securities index prediction, In proceedings of the first international \nOpenKG workshop: large knowledge-enhanced models. Jeju Island, South Korea: CEUR \nWorkshop Proceedings, 3818, 71–82.\nDing, Y ., Jia, S., Ma, T., Mao, B., Zhou, X., Li, L., et al. (2023). Integrating stock features \nand global information via large language models for enhanced stock return prediction. \nArXiv. Available online at: https://arxiv.org/abs/2310.05627\nDing, H., Li, Y ., Wang, J., and Chen, H. (2024). Large language model agent in \nfinancial trading: a survey. ArXiv. Available online at: https://arxiv.org/abs/2408.06361\nDolphin, R., Dursun, J., Chow, J., Blankenship, J., Adams, K., and Pike, Q. (2024). \nExtracting structured insights from financial news: An augmented LLM driven \napproach [ArXiv preprint]. ArXiv. Available online at: https://arxiv.org/\nabs/2407.15788\nFatemi, S., and Hu, Y . (2024). FinVision: a multi-agent framework for stock market \nprediction. ICAIF '24: Proceedings of the 5th ACM international conference on AI in \nfinance, pp. 582–590.\nFatouros, G., Metaxas, K., Soldatos, J., and Karathanassis, M. (2025). MarketSenseAI \n2.0: enhancing stock analysis through LLM agents. ArXiv. Available online at: https://\narxiv.org/abs/2502.00415\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 20 frontiersin.org\nFatouros, G., Metaxas, K., Soldatos, J., and Kyriazis, D. (2024). Can large language \nmodels beat wall street? Unveiling the potential of AI in stock selection. ArXiv. Available \nonline at: https://doi.org/10.1007/s00521-024-10613-4\nFieberg, C., Hornuf, L., Streich, D., and Meiler, M. (2024). Using large language \nmodels for financial advice. Available online at: https://ssrn.com/abstract=4850039\nGlasserman, P ., and Lin, C. (2023). Assessing look-ahead bias in stock return \npredictions generated by GPT sentiment analysis. ArXiv. Available online at: https://\narxiv.org/abs/2309.17322\nGu, J., Y e, J., Wang, G., and Yin, W . (2024). Adaptive and explainable margin trading \nvia large language models on portfolio management. ICAIF '24: Proceedings of the 5th \nACM international conference on AI in finance, pp. 248–256.\nGuo, T., and Hauptmann, E. (2024). Fine-tuning large language models for stock \nreturn prediction using newsflow. In Proceedings of the 2024 conference on empirical \nmethods in natural language processing: industry track, pp. 1028–1045, Miami, \nFlorida, US. Association for Computational Linguistics.\nGuo, J., and Shum, H. (2024). Large investment model. ArXiv. Available online at: \nhttps://arxiv.org/abs/2408.10255\nHuang, Z., Zhang, Z., Hua, C., Liao, B., and Li, S. (2024). Leveraging enhanced egret \nswarm optimization algorithm and artificial intelligence-driven prompt strategies for \nportfolio selection. Sci. Rep. 14:26681. doi: 10.1038/s41598-024-77925-2\nKim, H., and Oh, H. Llm analyst: what stocks do you recommend today. Available at \nSSRN. Available online at: https://ssrn.com/abstract=4899957\nKirtac, K., and Germano, G. (2024). Sentiment trading with large language models. \nFinanc. Res. Lett. 62:105227. doi: 10.1016/j.frl.2024.105227\nKo, H., and Lee, J. (2024). Can ChatGPT improve investment decisions? From a \nportfolio management perspective. Financ. Res. Lett.  64:105433. doi: \n10.1016/j.frl.2024.105433\nKoa, K. J., Ma, Y ., Ng, R., and Chua, T. (2024). Learning to generate explainable stock \npredictions using self-reflective large language models. In Proceedings of the ACM web \nconference 2024 (WWW '24) (pp. 4304–4315).\nKoa, K. J., Ma, Y ., Ng, R., Zheng, H., and Chua, T. (2024). Temporal relational \nreasoning of large language models for detecting stock portfolio crashes. Arxiv. Available \nonline at: https://arxiv.org/abs/2410.17266\nKong, Y ., Nie, Y ., Dong, X., Mulvey, J., Poor, V ., Wen, W ., et al. (2024). Large language \nmodels for financial and investment management: applications and benchmarks. J. \nPortfolio Manag. Quant. Tools 51, 162–210. doi: 10.3905/jpm.2024.1.645\nKong, Y ., Nie, Y ., Dong, X., Mulvey, J. M., Poor, H. V ., Wen, Q., et al. (2024). Large \nlanguage models for financial and investment management: models, opportunities, and \nchallenges. J. Portfolio Manag. 51, 211–231. doi: 10.3905/jpm.2024.1.646\nKonstantinidis, T., Iacovides, G., Xu, M., Constantinides, T. G., and Mandic, D. (2024). \nFinLlama: financial sentiment classification for algorithmic trading applications. ICAIF \n'24: Proceedings of the 5th ACM international conference on AI in finance, pp. 134–141.\nKou, Z., Yu, H., Peng, J., and Chen, L. (2024). Automate strategy finding with LLM in \nquant investment [ArXiv preprint]. ArXiv. Available online at: https://arxiv.org/\nabs/2409.06289\nKrause, D. (2023). Large language models and generative AI in finance: an analysis of \nChatGPT, Bard, and Bing AI. Available online at: https://ssrn.com/abstract=4511540\nLee, H., Choi, Y ., and Kwon, Y ., Quantifying qualitative insights: leveraging LLMS to \nmarket predict. Available online at: https://ssrn.com/abstract=5093626\nLefort, B., Benhamou, E., Ohana, J. -J., Saltiel, D., Guez, B., and Jacquot, T. (2024). \nSentiment analysis of bloomberg markets wrap using ChatGPT: application to the \nNASDAQ. Available online at: https://ssrn.com/abstract=4780150\nLi, H., Cao, Y ., Yu, Y ., Javaji, S. R., Deng, Z., He, Y ., et al. (2024). INVESTORBENCH: \na benchmark for financial decision-making tasks with LLM-based agent. ArXiv. \nAvailable online at: https://arxiv.org/abs/2412.18174\nLi, L., Chang, T., and Wang, H. (2023). Multimodal Gen-AI for fundamental \ninvestment research. ArXiv. Available online at: https://arxiv.org/abs/2401.06164\nLi, X., Li, Z., Shi, C., Xu, Y ., Du, Q., Tan, M., et al. (2024). AlphaFin: Benchmarking \nfinancial analysis with retrieval-augmented stock-chain framework. In Proceedings of \nthe 2024 joint international conference on computational linguistics, language resources \nand evaluation (LREC-COLING 2024) (pp. 773–783). ELRA and ICCL.\nLi, Y ., Luo, B., Wang, Q., Chen, N., Liu, X., and He, B. (2024). CryptoTrade: A reflective \nLLM-based agent to guide zero-shot cryptocurrency trading. In Proceedings of \nEMNLP 2024 (pp. 1094–1106). Association for Computational Linguistics.\nLi, Y ., Yu, Y ., Li, H., Chen, Z., and Khashanah, K. (2023). TradingGPT: Multi-agent \nsystem with layered memory and distinct characters for enhanced financial trading \nperformance [ArXiv preprint]. ArXiv. Available online at: https://arxiv.org/abs/2309.03736\nLiang, Y ., Liu, Y ., Zhang, B., Wang, C. D., and Y ang, H. (2024). FinGPT: enhancing \nsentiment-based stock movement prediction with dissemination-aware and context-\nenriched LLMs. ArXiv. Available online at: https://arxiv.org/abs/2412.10823\nLiu, C., Arulappan, A., Naha, R., Mahanti, A., Kamruzzaman, J., and Ra, I. H. \n(2024). Large language models and sentiment analysis in financial markets: a \nreview, datasets, and case study. IEEE Access  12, 134041–134061. doi: \n10.1109/ACCESS.2024.3445413\nLiu, X., Wang, G., Y ang, H., and Zha, D. (2023). FinGPT: democratizing internet-scale \ndata for financial large language models. ArXiv. Available online at: https://arxiv.org/\nabs/2307.10485\nLopez-Lira, A., and Tang, Y . (2023). Can ChatGPT forecast stock price movements? \nReturn predictability and large language models [Working paper]. Available online at: \nhttps://doi.org/10.2139/ssrn.4412788\nLu, F . (2025). Robo-advising meets large language models: educating investors on \nalpha and beta of mutual funds and stocks. Available online at: https://ssrn.com/\nabstract=5083305\nLu, F ., Huang, L., and Li, S. (2023). ChatGPT, generative AI, and investment advisory. \nAvailable online at: https://ssrn.com/abstract=4519182\nMateega, S., Georgescu, C., and Tang, D. (2025). FinanceQA: a benchmark for \nevaluating financial analysis capabilities of large language models. ArXiv. Available \nonline at: https://arxiv.org/abs/2501.18062\nNi, H., Meng, S., Chen, X., Zhao, Z., Chen, A., Li, P ., et al. (2024). Harnessing earnings \nreports for stock predictions: a QLoRA-enhanced LLM approach. ArXiv. Available \nonline at: https://doi.org/10.1109/DOCS63458.2024.10704454\nNie, Y ., Kong, Y ., Dong, X., Mulvey, J. M., Poor, H. V ., Wen, Q., et al. (2024). A survey \nof large language models for financial applications: progress, prospects and challenges. \nArXiv. Available online at: https://arxiv.org/abs/2406.11903\nNishida, S., and Utsuro, T. (2025). Generating financial news articles from factors of \nstock price rise / decline by LLMs. Proceedings of the joint workshop of the 9th financial \ntechnology and natural language processing (FinNLP), the 6th Financial Narrative \nProcessing (FNP), and the 1st Workshop on Large Language Models for Finance and \nLegal (LLMFinLegal), pp. 184–195, Abu Dhabi, UAE, Association for Computational \nLinguistics.\nPapasotiriou, K., Sood, S., Reynolds, S., and Balch, T. (2024). “ AI in investment \nanalysis: LLMs for equity stock ratings” in ICAIF '24: Proceedings of the 5th ACM \ninternational conference on AI in finance (ACM), 419–427.\nPark, T. (2024). Enhancing anomaly detection in financial markets with an LLM-\nbased multi-agent framework. ArXiv. Available online at: https://arxiv.org/\nabs/2403.19735\nPerlin, M., Foguesatto, C., Muller, F . M., and Righi, M. Can AI beat a naive portfolio? An \nexperiment with anonymized data. Available online at: https://ssrn.com/abstract=4954881\nPop, A., Spörer, J., and Handschuh, S. (2024). The structure of financial equity research \nreports -- identification of the most frequently asked questions in financial analyst \nreports to automate equity research using Llama 3 and GPT-4. ArXiv. Available online \nat: https://arxiv.org/abs/2407.18327\nRomanko, O., Narayan, A., and Kwon, R. H. (2023). ChatGPT-based investment \nportfolio selection. Oper. Res. Forum 4:91. doi: 10.1007/s43069-023-00277-6\nSaqur, R., and Rudzicz, F . (2024). Stock price trend prediction using emotion analysis \nof financial headlines with distilled LLM model. Open Review. Available online at: \nhttps://openreview.net/forum?id=y3W1TVuJii&referrer=%5Bthe%20profile%20of%20\nRaeid%20Saqur%5D(%2Fprofile%3Fid%3D~Raeid_Saqur1)\nShi, J., and Hollifield, B. (2024). Predictive power of LLMs in financial markets. ArXiv. \nAvailable online at: https://arxiv.org/abs/2411.16569\nSwamy, M., Shukla, A., and Purtilo, J. LLM-based stock market trend prediction. Open \nReview. Available online at: https://openreview.net/forum?id=ICwdNpmu2d\nTandon, R. (2024). Prediction of stock market trends based on large language models. \nITEGAM J. Eng. Technol. Ind. Appl. (ITEGAM-JETIA)  11, a615–a622. Available at: \nhttps://www.jetir.org/view?paper=JETIR2409071\nTong, H., Li, J., Wu, N., Gong, M., Zhang, D., and Zhang, Q. (2024). Ploutos: towards \ninterpretable stock movement prediction with financial large language model. ArXiv. \nAvailable online at: https://arxiv.org/abs/2403.00782\nValeyre, S., and Aboura, S. (2024). LLMs for time series: an application for single stocks \nand statistical arbitrage. ArXiv. Available online at: https://arxiv.org/abs/2412.09394\nVidal, J. (2024). Efficacy of AI and other large language models in predicting stock \nprices. Available online at: https://ssrn.com/abstract=4947135\nVoigt, F ., von Luck, K., and Stelldinger, P . (2024). Assessment of the applicability of \nlarge language models for quantitative stock price prediction. PETRA '24: Proceedings \nof the 17th international conference on pervasive technologies related to assistive \nenvironments, pp. 293–302.\nWang, Q., Gao, Y ., Tang, Z., Luo, B., and He, B. (2024). Enhancing LLM trading \nperformance with fact-subjectivity aware reasoning [ArXiv preprint]. ArXiv. Available \nonline at: https://arxiv.org/abs/2410.12464\nWang, S., Ji, T., Wang, L., Sun, Y ., Liu, S., Kumar, A., et al. (2024). StockTime: a time \nseries specialized large language model architecture for stock price prediction. ArXiv. \nAvailable online at: https://arxiv.org/abs/2409.08281\nWang, H., Pan, Z., Zhang, H., Liu, M., Lin, Y ., and Zhao, H. V . (2024). InvestAlign: \nAlign LLMs with investor decision-making under herd behavior. In Adaptive foundation \nmodels: evolving AI for personalized and efficient learning, NeurIPS 2024.\nWang, S., Yuan, H., Zhou, L., Ni, L. M., Shum, H., and Guo, J. (2023). Alpha-GPT: \nHuman-AI interactive alpha mining for quantitative investment [ArXiv preprint]. \nArXiv. Available online at: https://arxiv.org/abs/2308.00016\nJadhav and Mirza 10.3389/frai.2025.1608365\nFrontiers in Artificial Intelligence 21 frontiersin.org\nWu, R. (2024). Portfolio performance based on LLM news scores and related \neconomical analysis [Working paper]. Available online at: https://ssrn.com/\nabstract=4709617\nXiao, Y ., Sun, E., Luo, D., and Wang, W . (2024). TradingAgents: multi-agents LLM \nfinancial trading framework. ArXiv. Available online at: https://arxiv.org/\nabs/2412.20138\nXing, F . (2024). Designing heterogeneous LLM Agents for financial sentiment analysis. \nACM Trans. Manag. Inf. Syst. 16, 1–24. doi: 10.1145/3688399\nY ang, H., Zhang, B., Wang, N., Guo, C., Zhang, X., Lin, L., et al. (2024). FinRobot: an \nopen-source AI agent platform for financial applications using large language models. \nArXiv. Available online at: https://arxiv.org/abs/2405.14767\nY ang, Y ., Zhang, Y ., Wu, M., Zhang, K., Zhang, Y ., Yu, H., et al (2025). TwinMarket: A \nscalable behavioral and social simulation for financial markets [ArXiv preprint]. ArXiv. \nAvailable online at: https://arxiv.org/abs/2502.01506\nYu, B. (2023). Benchmarking large language model volatility [ArXiv preprint]. ArXiv. \nAvailable online at: https://arxiv.org/abs/2311.15180\nYu, Y ., Li, H., Chen, Z., Jiang, Y ., Li, Y ., Zhang, D., et al. (2023). FinMem: a \nperformance-enhanced LLM trading agent with layered memory and character design \n[ArXiv preprint]. ArXiv. Available online at: https://arxiv.org/abs/2311.13743\nYu, Y ., Y ao, Z., Li, H., Deng, Z., Cao, Y ., Chen, Z., et al. (2024). FinCon: A synthesized \nLLM multi-agent system with conceptual verbal reinforcement for enhanced financial \ndecision making. Advances in Neural Information Processing Systems 37 (NeurIPS \n2024). [Conference proceedings]. Available online at: https://proceedings.neurips.cc/\npaper_files/paper/2024/hash/f7ae4fe91d96f50abc2211f09b6a7e49-Abstract-\nConference.html\nYue, T., and Au, D. (2023). GPTQuant's conversational AI: simplifying investment \nresearch for all. Available online at: https://ssrn.com/abstract=4380516\nZhang, C., Liu, X., Zhang, Z., Jin, M., Li, L., Wang, Z., et al. (2024). When AI \nMeets Finance (StockAgent): large language model-based stock trading in simulated \nreal-world environments. ArXiv. Available online at: https://arxiv.org/\nabs/2407.18957\nZhao, Z. (2024). Next-generation intelligent portfolio management [Institutional \nreport]: DSpace@MIT. Cambridge, MA:   Massachusetts Institute of Technology.  Available  at:   \nhttps://dspace.mit.edu/handle/1721.1/156635\nZhao, H., Liu, Z., Wu, Z., Li, Y ., Y ang, T., Shu, P ., et al. (2024). Revolutionizing finance \nwith LLMs: an overview of applications and insights [ArXiv preprint]. ArXiv. Available \nonline at: https://arxiv.org/abs/2401.11641\nZhao, Z., and Welsch, R. E. (2024). Aligning LLMs with human instructions and stock \nmarket feedback in financial sentiment analysis. ArXiv. Available online at: https://arxiv.\norg/abs/2410.14926\nZhou, T., Wang, P ., Wu, Y ., and Y ang, H. (2024). FinRobot: AI agent for equity research \nand valuation with large language models. ArXiv. Available online at: https://arxiv.org/\nabs/2411.08804",
  "topic": "Equity (law)",
  "concepts": [
    {
      "name": "Equity (law)",
      "score": 0.5683664083480835
    },
    {
      "name": "Computer science",
      "score": 0.4437717795372009
    },
    {
      "name": "Economics",
      "score": 0.3366581201553345
    },
    {
      "name": "Political science",
      "score": 0.17278572916984558
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": []
}