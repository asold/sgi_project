{
  "title": "The Social Data Foundation model: Facilitating health and social care transformation through<i>datatrust services</i>",
  "url": "https://openalex.org/W3170813427",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2193437618",
      "name": "Michael Boniface",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2116610443",
      "name": "Laura Carmichael",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2036531771",
      "name": "Wendy Hall",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2099571073",
      "name": "Brian Pickering",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2022487549",
      "name": "Sophie Stalla Bourdillon",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2045080173",
      "name": "Steve Taylor",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2193437618",
      "name": "Michael Boniface",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2116610443",
      "name": "Laura Carmichael",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2036531771",
      "name": "Wendy Hall",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2099571073",
      "name": "Brian Pickering",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2022487549",
      "name": "Sophie Stalla Bourdillon",
      "affiliations": [
        "University of Southampton"
      ]
    },
    {
      "id": "https://openalex.org/A2045080173",
      "name": "Steve Taylor",
      "affiliations": [
        "University of Southampton"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3084037070",
    "https://openalex.org/W2911160483",
    "https://openalex.org/W2034561306",
    "https://openalex.org/W2155445226",
    "https://openalex.org/W2049255625",
    "https://openalex.org/W3170813427",
    "https://openalex.org/W2055684807",
    "https://openalex.org/W2132039067",
    "https://openalex.org/W2924814302",
    "https://openalex.org/W2905735277",
    "https://openalex.org/W3188471205",
    "https://openalex.org/W6605377519",
    "https://openalex.org/W2791881027",
    "https://openalex.org/W2164572080",
    "https://openalex.org/W3024722698",
    "https://openalex.org/W3193989929",
    "https://openalex.org/W2887440581",
    "https://openalex.org/W3036911563",
    "https://openalex.org/W3012501605",
    "https://openalex.org/W2785980092",
    "https://openalex.org/W2323290108",
    "https://openalex.org/W2135569169",
    "https://openalex.org/W3040880499",
    "https://openalex.org/W6757160636",
    "https://openalex.org/W207633926",
    "https://openalex.org/W2177662450",
    "https://openalex.org/W2907164391",
    "https://openalex.org/W3025752617",
    "https://openalex.org/W3128180766",
    "https://openalex.org/W2134266749",
    "https://openalex.org/W2963300406",
    "https://openalex.org/W2887709387",
    "https://openalex.org/W2129397798",
    "https://openalex.org/W2909729565",
    "https://openalex.org/W2971484212",
    "https://openalex.org/W3035739642",
    "https://openalex.org/W4248588746",
    "https://openalex.org/W3093987936",
    "https://openalex.org/W2142175015",
    "https://openalex.org/W2980956924",
    "https://openalex.org/W3008881689",
    "https://openalex.org/W132440809",
    "https://openalex.org/W1498816769",
    "https://openalex.org/W2184587911",
    "https://openalex.org/W3086590218",
    "https://openalex.org/W2906567312",
    "https://openalex.org/W3122324498"
  ],
  "abstract": "Abstract Turning the wealth of health and social data into insights to promote better public health, while enabling more effective personalized care, is critically important for society. In particular, social determinants of health have a significant impact on individual health, well-being, and inequalities in health. However, concerns around accessing and processing such sensitive data, and linking different datasets, involve significant challenges, not least to demonstrate trustworthiness to all stakeholders. Emerging datatrust services provide an opportunity to address key barriers to health and social care data linkage schemes, specifically a loss of control experienced by data providers, including the difficulty to maintain a remote reidentification risk over time, and the challenge of establishing and maintaining a social license. Datatrust services are a sociotechnical evolution that advances databases and data management systems, and brings together stakeholder-sensitive data governance mechanisms with data services to create a trusted research environment. In this article, we explore the requirements for datatrust services , a proposed implementation—the Social Data Foundation, and an illustrative test case. Moving forward, such an approach would help incentivize, accelerate, and join up the sharing of regulated data, and the use of generated outputs safely amongst stakeholders, including healthcare providers, social care providers, researchers, public health authorities, and citizens.",
  "full_text": "RESEARCH ARTICLE\nThe Social Data Foundation model: Facilitating health and\nsocial care transformation throughdatatrust services\nMichael Boniface1, Laura Carmichael1,* , Wendy Hall1 , Brian Pickering1,\nSophie Stalla-Bourdillon2 and Steve Taylor1\n1Electronics & Computer Science, University of Southampton, Southampton, United Kingdom\n2Law, University of Southampton, Southampton, United Kingdom\n*Corresponding author. E-mail:L.E.Carmichael@soton.ac.uk\nReceived: 16 June 2021;Revised: 17 December 2021;Accepted: 10 January 2022\nKey words:data governance models; data institutions; data stewardship;datatrust services; healthcare and social care\nAbbreviations: AI, artificial intelligence; API, application programming interface; CHIA, Care and Health Information Exchange\nAnalytics; DARS, Data Access Request Service; DLT, distributed ledger technology; DPIA, data protection impact assessment;\nDPO, data protection officer; DSAP, data sharing and analysis project; GDPR, General Data Protection Regulation; HL7 FHIR,\nHealth Level 7 Fast Healthcare Interoperability Resources; HRA, Health Research Authority; ICO, Information Commissioner’s\nOffice; ICS, integrated care system; ISO, International Organization for Standardization; MELD, Multidisciplinary Ecosystem to\nstudy Lifecourse Determinants of Complex Mid-life Multimorbidity using Artificial Intelligence; ML, machine learning; MLTC-M,\nmultiple long term conditions— multimorbidity; NHS, National Health Service (UK); NHS REC, NHS Research Ethics Committee;\nNIHR, National Institute for Health Research (UK); ONS, Office for National Statistics; OWASP, Open Web Application Security\nProject; PETs, privacy enhancing-technologies; PI, principal investigator; RDA, Research Data Alliance; SDF, Social Data\nFoundation; SD-WANS, software-defined wide area networks; TRE, trusted research environment; UK, United Kingdom; UKDS,\nUK Data Service; UKHDRA, UK Health Data Research Alliance; WSI, Web Science Institute\nAbstract\nTurning the wealth of health and social data into insights to promote better public health, while enabling more effective\npersonalized care, is critically important for society. In particular, social determinants of health have a significant\nimpact on individual health, well-being, and inequalities in health. However, concerns around accessing and\nprocessing such sensitive data, and linking different datasets, involve significant challenges, not least to demonstrate\ntrustworthiness to all stakeholders. Emergingdatatrust servicesprovide an opportunity to address key barriers to\nhealth and social care data linkage schemes, specifically a loss of control experienced by data providers, including the\ndifficulty to maintain a remote reidentification risk over time, and the challenge of establishing and maintaining a\nsocial license. Datatrust services are a sociotechnical evolution that advances databases and data management\nsystems, and brings together stakeholder-sensitive data governance mechanisms with data services to create a trusted\nresearch environment. In this article, we explore the requirements fordatatrust services, a proposed implementation—\nthe Social Data Foundation, and an illustrative test case. Moving forward, such an approach would help incentivize,\naccelerate, and join up the sharing of regulated data, and the use of generated outputs safely amongst stakeholders,\nincluding healthcare providers, social care providers, researchers, public health authorities, and citizens.\nPolicy Significance Statement\nTurning the wealth of health and social data into insights for better public health and personalized care is critically\nimportant for society. Yet data access and insights are hampered by manual governance processes that can be time\nconsuming, error-prone, and not easy to repeat. With increasing data volumes, complexity, and need for ever-faster\n© The Author(s), 2022. Published by Cambridge University Press. This is an Open Access article, distributed under the terms of the Creative Commons\nAttribution licence (http://creativecommons.org/licenses/by/4.0), which permits unrestricted re-use, distribution and reproduction, provided the\noriginal article is properly cited.\nData & Policy(2022), 4: e6\ndoi:10.1017/dap.2022.1\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nsolutions, new approaches to data governance must be found that are secure, rights-respecting, and endorsed by\ncommunities. The Social Data Foundation combines governance withdatatrust servicesto allow citizens, service\nproviders, and researchers to work together to transform systems. By bridging the gap between data and trust\nservices, new progressive models of data governance can be established offering high levels of data stewardship and\ncitizen participation.\n1. Introduction\nSocial determinants of health significantly affect individual well-being and health inequalities (Sadana\nand Harper,2011; Public Health England,2017; Marmot et al.,2020). The World Health Organization\n(n.d.) describes“social determinants of health” as “nonmedical factors that influence health outcomes”\nsuch as“education,”“ working life conditions,”“ early childhood development,” and “social-inclusion\nand nondiscrimination.” The global COVID-19 pandemic highlights how“disparities in social deter-\nminants of health” (Burström and Tao,2020) give rise to poorer health outcomes for some groups in\nsociety. For instance, disadvantaged economic groups appear to be at greater risk of exposure to COVID-\n19, and are more susceptible to severe disease or death (e.g., Abrams and Szefler,2020; Burström and Tao,\n2020; Triggle,2021).\nSocial determinants of health can be acquired from diverse data sources— for example, wearables, digital\nhealth platforms, social media, and environment monitoring— many beyond the conventional boundaries of\nhealth and social care (e.g., Sharon and Lucivero,2019). The“safe” linkage (UK Data Service,n.d.;U K\nHealth Data Research Alliance,2020) of good quality data is therefore vital for the generation of insights\nsupporting positive health and social care transformation.1 Specifically, newer forms of social determinants\nof health data (e.g., from wearables) need to bring together with other more conventional data types (e.g.,\nelectronic healthcare records, public health statistics, and birth cohorts datasets) for analysis by multidis-\nciplinary researchers and practitioners, including the application and development of new and existing\nhealth data science methods and tools. Such data-driven insights can be used to“improve decision-making at\nthe individual and community level”(Galea et al.,2020) thus promoting better public health,\n2 enabling more\neffective personalized care,3 and ultimately helping address inequalities in health.\nAlthough the need for sustainable and positive health and social care transformation is widely accepted\nin principle, more needs to be done in practice to derive benefit from available data. This includes\nincentivizing and accelerating sharing of regulated data and any associated outputs across relevant\nstakeholders (e.g., healthcare or social care providers, researchers, public health authorities, and citizens).\nMany health and social care datasets remain in silos under the control of individual groups or institutions\n(Kariotis et al.,2020), giving rise to data monopolies or oligopolies. Slow, disjointed, manual governance\nprocesses— often error-prone, time consuming, and difficult to repeat— hamper data access and insights.\n4\nThis has been accentuated by the extraordinary situation of the global COVID-19 pandemic (e.g.,\nResearch Data Alliance (RDA) COVID-19 Working Group,2020). Trustworthy data governance is\nessential not only to ensure data providers and data users can fulfill their regulatory obligations, but also to\nmaintain public confidence and engagement (Geissbuhler et al.,2013; Stalla-Bourdillon et al.,2021).\n1 Note that a key theme for positive health and social care transformation is the design and implementation of“integrated care\nsystems” (ICSs) for seamless care delivery across the health and social care pathways (NHS,2019)— also referred to as“hospitals\nwithout walls” (Hawkes, 2013; Spinney,2021).\n2 For example, via public interventions, targeted health, and well-being campaigns.\n3 For example, through personalized medicine, increased patient and/or service user empowerment, and better operational\nefficiency for health and care service providers.\n4 In the UK, the NHS remains a key provider of clinical and administrative data for research and innovation (i.e., secondary use of\ndata for nonclinical purposes) related to health and social care systems transformation. Data users can request access to data, for\nexample, via applications to Data Access Request Service (DARS) (NHS Digital,n.d.) provided by NHS Digital, individual NHS\ntrusts and foundations, and local health and care records programmes (e.g., Wessex Care Records (2021)).\ne6-2 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nAdvanced data governance5 models are therefore required that can foster a“social license” (Carter et al.,\n2015; Jones and Ford, 2018;O ’Hara, 2019) and which can handle increasing data volumes and\ncomplexity safely (e.g., Sohail et al.,2018; Winter and Davidson,2019).\nTo enable fast, collaborative, and trustworthy data sharing that meets these needs, we propose a Social\nData Foundation for Health and Social Care (“the SDF”) (Boniface et al.,2020), as a new form of data\ninstitution.6 Based on the“Five Safes Plus One,” and the concept of the“trusted research environment\n(TRE)” (The UK Health Data Research Alliance,2020), the SDF proposesdatatrust services as a\nsociotechnical model for good data governance, sensitive to the needs of all stakeholders, and allied\nwith advances in dynamic and secure federated research environments.\nThis article considers how health and social care transformation can be facilitated throughdatatrust\nservices— and is divided into four main parts.7 First, inSection 2, we explore the conceptual basis for\nTREs within the health and social care domain. Second, inSection 3, we demonstrate why the SDF model\nis well equipped to support health and social care transformation for individual and community benefit,8\nboost open science, and generate insights for multiple stakeholders— by providing an overview of the\nSDF governance structure and an implementation ofdatatrust services.Third, inSection 4, we validate\nour SDF model through its application to a test case centered on social determinants of health research: the\n“Multidisciplinary Ecosystem to study Lifecourse Determinants of Complex Mid-life Multimorbidity\nusing Artificial Intelligence” (MELD) project (MELD,2021). Finally, inSection 5, we summarize the key\npoints raised and outline next steps for the SDF model.\n2. “TREs” in Health and Social Care: Motivation and Key Requirements\nBest practice for health and social care research and innovation— specified by the UK Health Data\nResearch Alliance (UKHDRA) (2020)— necessitates that data sharing and linkage occurs within TREs,\nproviding:\na secure space for researchers to access sensitive data. Commonly referred to as‘data safe havens,’\nTREs are based on the idea that researchers should access and use data within a single secure\nenvironment (Harrison,2020).\nThis section examines the concept of a“TRE” when used for linking data held by different parties for\nthe purpose of health and social care transformation.\n2.1. Challenges with the“data release model”\nDespite the long-established notion of the“data safe haven” (Burton et al.,2015),9 health and social data\nlinkage typically uses a“data release model”: data are made available to approved users in their own data\nenvironments (UKHDRA,2020).\n5 While there is no universal definition of the term“data governance,” Janssen et al. (2020) provide a useful description of this\nterm in a multiorganizational context:“Organizations and their personnel defining, applying, and monitoring the patterns of rules\nand authorities for directing the proper functioning of, and ensuring the accountability for, the entire life-cycle of data and algorithms\nwithin and across organizations.” Note that Smart Dubai and Nesta (2020) describe collaborative data governance innovation as\n“fairly embryonic” in practice.\n6 The phrase“data institution” is used by the Open Data Institute (ODI) as an umbrella term to describe:“organizations whose\npurpose involves stewarding data on behalf of others, often towards public, educational or charitable aims” (Dodds et al.,2020).\n7 A glossary of key terms is provided after the main text of this article.\n8 For example, alignment with the CARE principles (2018).\n9 Trusted third party intermediaries continue to play a crucial role in facilitating data linkage for public health research and\ninnovation— such as, SAIL (2021; Jones et al.,2014) for linkage of specified anonymized datasets, and UKHDRA (n.d.) for\ndiscoverability of particular UK health datasets held by members through its Innovation Gateway. For further discussion of this\npoint, the Public Health Research Data Forum (2015) provides 11 case studies of data linkage projects from across the world, and\noutlines barriers and key lessons to be learnt. For further examples of health data sharing initiatives also see: ICES, Canada (2021);\nand Data Linkage Western Australia (2021).\nData & Policy e6-3\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nThe data release model can be problematic. Firstly, health and social care data are often rich and large-\nscale requiring“diverse tooling” (UKHDRA, 2020). However, data safe havens were“until recently”\nonly able to provide limited tools for data analysis (UKHDRA,2020) as well as“secure remote working\nsolutions, real-time anonymisation, and synthetic data” (Desai et al.,2016). Further, once data are shared,\ndata providers often experience a loss of control over their data. They have reduced oversight over how\ndata are accessed, linked, and reused. Generated outputs from any data linkage activities (e.g., containers,\nderived data, images, notebooks, publications, and software) are often not adequately disclosed\n(UKHDRA, 2020), making it more difficult to effectively mitigate the risk of reidentification, and\nincreasing potential“mosaic effects” (Pozen, 2005).\nIn some cases, this loss of control and visibility may act as disincentives to sharing data with higher\nlevels of utility\n10 (e.g., data providers may share only aggregated data where deidentified data at the\nindividual level may offer greater societal benefit), or sharing any data whatsoever. A lack of control,\ntransparency, and measurement of benefit may also prevent, weaken, or nullify a social license (defined\nbelow) for specific health and social care research and innovation activities.\n2.2. Upholding a social license\nFulfilling legal obligations alone is not enough to secure social legitimacy for health and social care\nresearch and innovation (Carter et al.,2015)— TREs require a“social license” defined by Muller et al.\n(2021) as follows:\nA social licence in the context of data-intensive health research refers to the non-tangible societal\npermission or approval that is granted to either public or private researchers and research organisa-\ntions. This allows them to collect, use, and share health data for the purpose of health research by\nvirtue of those activities being trustworthy, by which is meant trusted to be in line with the values\nand expectations of the data subject communities, stakeholders, and the public.\nA social license, therefore, is dependent on perceptions by the main stakeholders that what is being\ndone is acceptable and beneficial (Rooney et al.,2014). Applied to the TRE, its social license is supported\nby its perceived trustworthiness (which can be expressed in terms of benevolence, integrity, and ability\n[Mayer et al.,1995]) toward the communities it intends to serve. For instance, aligning ethical oversight\nwith the CARE Principles for Indigenous Data Governance (2018)— that is, “collective benefit,”\n“authority to control,”“responsibility,” and “ethics”— brings to center stage the need to ensure equanimity\nacross the data lifecycle. The UKHDRA (2020) describes the principal rationale for TREs as follows:\n[to] protect— by design— the privacy of individuals whose health data they hold, while facilitating\nlarge scale data analysis using High Performance Computing that increases understanding of\ndisease and improvements in health and care.\nAlong similar lines, the Research Data Alliance (RDA) outlines TRUST principles for data infra-\nstructures— that is,“Transparency,”“ Responsibility,”“ User Focus,”“ Sustainability,” and “Technology”\n(Lin et al.,2020). However, changes in technology, especially within data science, introduce other issues.\nGiven the availability of ever-increasing volumes of people-centric data, the Toronto Declaration (2018)\nhighlights the fundamental human rights of data subjects, especially for those felt to be particularly\n10 While strong deidentification of data is vital to protect the rights of (groups of) individuals, deidentification can lower the utility\nof data. The definition of anonymized data is provided by GDPR (2016) Recital 26, namely“information which does not relate to an\nidentified or identifiable natural person or to personal data rendered anonymous in such a manner that the data subject is not or no\nlonger identifiable.” Although strictly speaking, Recital 26 is not binding it has been used by the Court of Justice of the European\nUnion and other national courts to interpret the concept of anonymized data. As a matter of principle, two different processes can lead\nto anonymized data: a risk-based approach to aggregation (i.e., data is aggregated, e.g., to produce counts, average sums) or a risk-\nbased approach to deidentification (i.e., data remains at the individual-level). In both cases, data and context controls should be\ncombined to guarantee that reidentification risk is“remote” over time (ICO,2012).\ne6-4 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nvulnerable. Similarly, the UK Data Ethics Framework (Central Digital and Data Office,2020) champions\nthe overarching principles of transparency, accountability, and fairness. As well as compliance with\nrelevant law and constant review of individual rights, the framework seeks to balance community needs\nagainst those rights. Governance must include all relevant, possibly cross-disciplinary expertise, and\nongoing training, of course. In a similar vein with artificial intelligence (AI) technologies, the European\nCommission (2019) and the UK Department of Health and Social Care (2021) both emphasize respect for\nindividual rights within the context of potential community benefit, accountability, and transparency.\nBeyond this, though, for stakeholders to agree on a social license, it must be clear that the rights and\nexpectations of individuals and the communities they represent should be upheld.\n2.3. Bringing citizens back to center stage\nTo promote social license and public trust, collaborative data-sharing initiatives need to (re)connect data\ncitizens with data about them and its utility. This is particularly pertinent as health and social care research\nand innovation becomes increasingly data-driven (Aitken et al.,2020) with national and international data\naggregators aiming to increase the power of AI through collection of ever-larger population and disease-\nspecific datasets. In such circumstances provenance, transparency of (re)use, and benefits suffer the risk of\nopacity; citizen inclusion must be embedded in the design and operation of such processes.\nFurther, the secondary use of data continues to increase (Jones and Ford,2018), yet is often less understood\nby citizens (CurvedThinking,2019). While such citizen engagement and participation is not new within the\nhealth and social care domain, more needs to be done to empower citizens and ensure greater inclusivity in\npractice (Ocloo and Matthews,2016)— especially where healthcare data are (re)used by third parties\n(Understanding Patient Data and Ada Lovelace Institute,2020). Precedence must be given to meaningful\ncitizen engagement and participation (Davidson et al.,2013;F o r de ta l . ,2019), which remain“inclusive and\naccessible to broad publics” (Aitken et al.,2020). Of course, given citizens are the focus of public health\npromotion, recipients of care, and data subjects, it is important they not only have access to information about\nhow data are being (re)used, but also have a voice in the transformation of health and social care systems.\nIn a world of data-driven policies and technologies, citizen voice and agency will increasingly be\ndetermined by participation in datasets themselves. Unless minority representation in datasets is\naddressed, bias and health inequalities will continue to be propagated. As such, citizen engagement,\nparticipation, and empowerment should be viewed as core to health and social care data governance (e.g.,\nHripcsak et al.,2014; Miller et al.,2018). In particular, there needs to be inclusion of appropriately\nrepresentative citizens— along with other stakeholders— in the codesign and coevaluation of digital\nhealth and social care solutions— to ensure that the benefits derived from“safe outputs” are “measured\nand evidenced” (Centre for Data Ethics and Innovation,2020) for communities and individuals.\n2.4. Maintaining cohesion and the“diameter of trust”\nExisting data-sharing relationships between stakeholder communities (e.g., a specific university, local\ncouncil, and hospital) can be replicated and strengthened through a TRE. To maintain the cohesiveness of\nsuch a community, extensions to membership and engagement need careful consideration as they relate to\nnotions of community-building around TRE interactions. A“diameter of trust” (Ainsworth and Buchan,\n2015; Ford et al.,2019; Northern Health Science Alliance,2020) provides a means to:\ngauge the size and characteristics of a learning, sustainable and trustworthy system\n(MedConfidential, 2017).\nA diameter of trust may be defined for a data institution by examining:\n(i) “The level at which engagement with the citizen can be established [… ]”\n(ii) “The extent of patient flows within the health economy, between organisations [… ]”\n(iii) “The scale of a data platform being of sufficientsize to enable effective population analyses [… ]” and\nData & Policy e6-5\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\n(iv) “The ability to bring data together from the wider determinants of health and care relevant for that\npopulation in near real-time [… ]” (MedConfidential, 2017).\nAs such, mechanisms need to be in place for a TRE, therefore, to expand while appreciating potential\nimpacts of community size. A diameter of trust cannot be predicated solely on demographics (e.g.,\ngeographic scope and community), and trustworthiness must be demonstrated through the operation of a\ndata institution and its proven outcomes, which will in turn encourage trust responses from its stake-\nholders (e.g., O’Hara, 2019).\n2.5. Progressive governance\nTo remain effective and appropriate, a data governance model for a TRE must be progressive, learning\niteratively, integrating new best practices without undue delay, as well as remaining compliant with the\nchanging legal landscape. Best practice may be both organizational (e.g., the adoption of codes of conduct\nand ethical frameworks) and technical (e.g., application of advanced security and privacy-enhancing\ntechnologies [PETs]) in nature. To maintain trustworthiness, crucially, it must adapt to the experience and\nconcerns of all key stakeholders (data subjects, data providers, service providers, researchers, etc.). For\ninstance, Understanding Patient Data (Banner, 2020) has provided a first iteration of a high-level\n“learning data governance model” that aims to meaningfully integrate citizen views within the deci-\nsion-making lifecycle.\nLessons may be learned not only from the day-to-day practicalities of supporting individual research\nprojects, through the outputs of citizen engagement and participation activities, but also externally via\nauthoritative national and international guidance. As Varshney (2020) asserts:\nprogressive data governance encourages fluid implementation using scalable tools and programs.\nTherefore, progressive data governance is essential, and contingent on greater automation of data\ngovernance processes and tooling to accelerate trustworthy and collaborative data linkage (Sohail et al.,\n2018; Moses and Desai,2020).\n2.6. Adhering to the“Five Safes Plus One”\nBest practice for TREs is centered on the“Five Safes Framework” (UKHDRA,2020). The framework was\ndevised in 2003 for the Office for National Statistics (ONS), and is used“for designing, describing, and\nevaluating access systems for data” (Desai et al.,2016). An additional safe—“ Safe Return”— has been added\nby UKHDRA (2020), which is described below. The“F i v eS a f e sP l u sO n e” approach identifies the key\n“dimensions”(Arbuckle and Ritchie,2019) that influence the risk and trustworthiness of health and social care\nresearch projects— and are provided as“adjustable controls rather than binary settings” (UKHDRA,2020).\nFor our purposes, based on the interpretation of the UKHDRA (2020), the six dimensions are as\nfollows:\n“ Safe people”: only trusted and authorized individuals (e.g., vetted researchers working on ethically\napproved projects in the interests of the public good) shall have access to the data within the TRE.\n“ Safe projects”: only approved projects shall be carried out via the TRE that are legally and ethically\ncompliant and have“potential public benefit.”\n“ Safe setting”: the TRE shall provide a trust-enhancing technical (“safe computing”) and organiza-\ntional infrastructure to ensure all data-related activities are undertaken securely and safely.\n“ Safe data”: all other“safes” are adhered to; data are deidentified appropriately before reusage via\nthe TRE, and remain appropriately deidentified across the life-cycle of an approved project.\n“ Safe outputs”: all outputs generated from data analysis activities, undertaken via the TRE, must not\nbe exported without authorization.\ne6-6 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\n“ Safe return”: to ensure that recombination of TRE outputs with other data at“the clinical setting that\noriginated the data”— which may reidentify data subjects— is only undertaken if permitted and\nconsented by the data subjects concerned. (UKHDRA,2020).11\nA collaborative health and social care data-sharing scheme must also fulfill essential data governance\nrequirements for ethics (e.g., institutional approval,Integrated Research Application System (IRAS)\n[2021] approval), legal-compliance (e.g., data protection, confidentiality, contracts, and intellectual\nproperty), and cyber-security (e.g., UK Cyber Essentials Plus [National Cyber Security Centre,n.d.],\nISO27001 [ISO,2013], NHS Data Security and Protection Toolkit,2021).12\n3. The SDF Model\nModels of safe and high-quality data linkage from multiple agencies necessitate a high level of inter-\ndisciplinarity (Jacobs and Popma,2019) wider than the conventional boundaries of medicine and social\ncare (Ford et al.,2019; Sharon and Lucivero,2019). To address this, the SDF model has adopted a\nsociotechnical approach13 to governing data (e.g., Young et al.,2019) where the multidisciplinary aspects\n(including, ethical, healthcare, legal, social care, social–cultural, and technical issues) of safe linkage for\nhealth and social care transformation are considered collectively and holistically from the outset.\nA key objective of the SDF is to accommodate different stakeholder communities and maintain their\napproval at a level sufficient for engagement and participation. Since multistakeholder health and social\ncare data needs to be aggregated at various levels (e.g., locally, regionally, and nationally), the SDF offers\na localized hub for data-intensive research and innovation facilitating multiparty data sharing through a\ncommunity of vetted stakeholders— including healthcare providers, social care providers, researchers,\nand public health authorities. Consequently, stakeholders can work together on projects facilitated by the\nSDF to discover solutions to health and social care transformation, promote greater collaboration, address\nkey local priorities and rapidly respond to new and emerging health data-related challenges, while\noffering national exemplars of health system solutions.\nIn order for the SDF to acquire and maintain a social license, any community and individual benefits arising\nfrom the SDF must be“measured and evidenced” (Centre for Data Ethics and Innovation,2020)a sw e l la s\npotential risks and constraints— and disseminated to communities and stakeholders in a transparent manner.\n14\nThe SDF model therefore includes a standard process to identify, monitor, and measure project outputs for\ndifferent stakeholders. Metrics here include: the alignment between project strategy and its generated outputs;\nresource allocation compared with action recommendations from generated project outputs; and, demon-\nstrated positive health and social care transformation impacts for certain stakeholder groups.\nWhile the“Five Safes Plus One” approach provides a useful guide by which to design, describe, and\nevaluate TREs, it does not specify how to implement governance and technology to enable these six safes.\nTo address this, our SDF model interlinks two key threads: governance and technology. We first describe\nthe SDF governance model, then the SDFdatatrust servicessupporting the management of data services\nthrough functional anonymization, risk management, ownership/rights management, and audit.\nA concluding section describes how the combined governance and technical approach addresses the\nrequirements identified inSection 2.\n11 It is worthwhile to note that pursuant to section 171(1) of the Data Protection Act (2018) (UK):“It is an offence for a person\nknowingly or recklessly to reidentify information that is deidentified personal data without the consent of the controller responsible\nfor deidentifying the personal data.”\n12 For a nonexhaustive list of data governance requirements, see Boniface et al. (2020).\n13 Note that the SDF initiative brings together a multidisciplinary team of clinical and social care practitioners with data\ngovernance, health data science, and security experts from ethics, law, technology and innovation, web science, and digital health.\n14 As a benchmark for best practice, see the five-point framework for evaluating whether a potential data sharing activity can be\nconsidered to be of public benefit outlined by Scott (2018).\nData & Policy e6-7\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\n3.1. SDF governance\nThe overall purpose of SDF governance model is to facilitate the safe (re)usage of data through“well-\ndefined data governance roles and processes” that builds“prompt and on-going risk assessment and risk\nmitigation into the whole data lifecycle” (Stalla-Bourdillon et al., 2019)— ultimately to ensure SDF\nactivities deliver positive health and social care transformation for stakeholders. Effective governance\ntherefore must enable the SDF Platform and its Facilitator (defined below) to exercise best practice and\nprogressive governance in support of“Data Sharing and Analysis Projects” (DSAPs) that are legally\ncompliant, respect ethical considerations, and maintain a social license.\nGovernance needs to take into account the requirements, sensitivities, and vulnerabilities of stake-\nholders (especially those of stakeholders who are not directly involved in decision-making), so that SDF\ngovernance must adopt the key fiduciary ethical virtues of loyalty and care (O’Hara, 2021).\n15 However,\nthe relationship isnot a fiduciary one in the fulllegal sense,16 because the purpose of the SDF is not to\nserve a narrow range of stakeholders’interests exclusively, but to deliver positive outcomes across the full\nrange of stakeholders (including service providers and data controllers themselves) while behaving in a\ntrustworthy manner and retaining trust (O’Hara, 2021). SDF governance is not intended to constrain\ndecision-makers’abilities to make the best decisions for their own organizations, but rather to include, and\nbe seen to include, the full range of relevant legitimate interests (O’Hara, 2019).\n3.1.1. SDF governance structure\nThe SDF Governance model builds on the“Data Foundations Framework” (Stalla-Bourdillon et al.,2019,\n2021) developed by the Web Science Institute (WSI) at the University of Southampton (UK) and Lapin\nLtd (Jersey). The Data Foundations Framework advocates and provides guidance on robust governance\nmechanisms for collective-centric decision-making, citizen representation, and data stewardship, so is a\nsuitable basis for the SDF Governance, whose structure is shown inFigure 1.\nThe main bodies, roles, and stakeholders that form the“SDF Governance Structure” are as follows:\n Advisory Committee: A group of individuals external to the SDF— with a wide range of expertise\nrelated to health and social care transformation (e.g., health and social care services, cyber-security,\ndata governance, health data science, ethics, and law)— that provides advice to the SDF Board on\nmatters related to data sharing (as necessary).\n Citizen Representatives: Experts in patient/service user voice, who are mandatory members of the\nSDF Board (see below), and oversee the administration of citizen participation and engagement\nactivities to ensure that the SDF maintains a social license. In particular, Citizen Representatives\nshall create, implement and manage a framework for citizen participation and engagement activities,\nwhere citizens can cocreate and participate in health and social care systems transformation as well\nas exercise their data-related rights.\n17\n Data Provider: An entity is the owner or rights holder of data that is either discoverable via the\nPlatform, hosted by the Platform, or utilized in DSAPs. The Data Provider is typically an organ-\nizational role, represented by a senior person, who has authority to share the data. A representative of\na Data Provider could act as a member of the SDF Board.\n Data User: An entity that discovers, uses, and/or reuses shared data made accessible via the SDF, or\nmanages DSAPs that are facilitated by the SDF Platform. The Data User role is subdivided into:\n15 The authors are grateful for discussions with Prof. Kieron O’Hara on an earlier version of this article— specifically on the\nnotion of fiduciary ethical virtues in relation todatatrust services.\n16 For instance, in the legal sense a fiduciary is“[a] person to whom power or property is entrusted for the benefit of another”—\nwhere “[d]uties [are] owed by a fiduciary to a beneficiary”— for example,“a duty of confidentiality,”“a duty of no conflict,” and “a\nduty not to profit from his position” (Thompson Reuters: Practical law,n.d.).\n17 Note that the SDF appeared as a case study in a report on“Exploring legal mechanisms for data stewardship” published by Ada\nLovelace and the AI Council (2021).\ne6-8 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\no Citizen— an interested member of the public wanting to understand dataset use and measurable\noutcomes;\no Project Manager— a person responsible for DSAPs and ensuring legal compliance, policy\ncompliance, and“safe people”; and\no Data Analyst— a person working on a DSAP analyzing datasets.\n Data Protection Officer (DPO): A standard role (whose appointment in some instances is mandatory\nunder the General Data Protection Regulation (GDPR,2016) for organizations that process personal\ndata to oversee the processing to ensure that it is compliant with GDPR obligations and respects data\nsubjects’rights. For the SDF, the DPO is responsible for overseeing the processing of any personal\ndata within the SDF and advising on compliance with the GDPR, in particular the identification and\nimplementation of controls to address the risk of reidentification when different Data Providers’data\nare linked in response to Data Users’ queries, thus contributing to“safe data.” The DPO’s advice\nextends to the special case of“safe return” where in some cases the outputs of projects are permitted\nto be returned to the Data Provider for reintegration with their source data. Here, the DPO can work\nwith project staff and the Data Providers themselves to determine the potential for reidentification\nwhen project results are reintegrated with source data, whether reidentification is permissible, or\nhow it can be prevented. The DPO works closely with the Independent Guardian who is responsible\nfor overseeing the processing of all types of data.\n External Auditor: A body independent to the SDF who is responsible for auditing or certifying its\nperformance, conformance to standards and/or compliance to regulations.\n Independent Guardian: A team of experts in data governance, who are independent from the SDF\nBoard and oversee the administration of the SDF to ensure that all data-related activities within the\nSDF realize the highest standards of excellence for data governance in accordance with applicable\nData Provider Sa/g415sfac/g415on Data User Sa/g415sfac/g415on\nInforma/g415on Governance & Ethical Oversight\nPla/g414orm \nOpera/g415on\nData Analysis \nProject Support\nData \nManagement\nSDF Rulebook: \nOpera/g415ng Policy \n& Procedures\nAdvisory Commi/g425ee\nExternal\nAuditor\nAims & Values\nPla/g414orm Facilitator\nCi/g415zen Representa/g415ve\nSecurity, Ethics \n& Privacy\nCi/g415zen Involvement & Social Licence\nData \nProvider\nData \nUser\nAudit & Standards \nConformance\nViability & \nValue Proposi/g415on\nRegulatory \nCompliance\nAudit Feedback\nData Protec/g415on Oﬃcer\nSDF Pla/g414orm\nAccoun/g415ng & \nBusiness Analysis\nMonitoring Monitoring\nIndependent Guardian\nMul/g415disciplinary Advice, User Feedback\nStrategy & Policies\nSDF Board\nPersonal Data Processing Oversight\nData Sharing and Analysis Project (DSAP)\nProvisions & Hosts\nDiscover Data, Set up DSAPRegister Data for Discovery\nOperates & Manages\nSocial Data Founda/g415on\nManage DSAP,\nLink & Analyse DataProvide Data\nFigure 1.Social Data Foundation Governance Structure.\nData & Policy e6-9\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\npolicies and processes that govern the operation of the SDF Platform. In particular, the Independent\nGuardian shall: (a) help set up a risk management framework for data sharing; (b) assess the\nproposed data use cases in accordance with this risk management framework; and (c) audit and\nmonitor all day-to-day data-related activities, including data access, citizen participation and\nengagement. These responsibilities contribute to “safe projects,” trustworthy governance, and\nsupport SDF transparency and best practice.\n Platform Facilitator: An executing officer, usually supported by a team, who oversees the technical\nday-to-day operation of the SDF Platform, including the provision of infrastructure and functional\nservices for Data Providers and Data Users, the implementation of governance policies, and support\nservices for other roles where required.\n The SDF Board: The inclusive decision-making body whose appointed members represent the\ninterests of the SDF’s key stakeholders: Data Providers, Data Users, and Citizens. Feedback from\nData Providers and Data Users is obtained via the Advisory Board, and citizen engagement is\nprovided by the presence of Citizen Representatives as board members. The principal respon-\nsibility of its members is to administer the SDF’s assets and carry out its purpose, including the\ndetermination of objectives, scope and guiding principles as well as progressive operating\npolicies, processes and regulations through maintenance of the SDF Rulebook. The SDF Board\ntherefore consumes multidisciplinary input from other roles and bodies— and consolidates this\nknowledge into the policies and processes expressed in the SDF Rulebook.\n3.1.2. Examples of SDF governance processes for DSAPs\nThe SDF provides a“safe setting” for “safe projects”— that is, DSAPs. The following table of standard\ngovernance processes is by no means exhaustive, but provides an illustration of the types of processes that\nmust be in place for all DSAPs (Table 1).\nTable 1. Examples of key standardized processes for all data sharing and analysis projects (DSAPs)\nKey standardized process for all“DSAPs”\nRelation to the“five safes\nplus one”\n(a) The SDF DSAP approval process\nDSAPs must successfully complete a SDF pre-approval process\nbefore access is granted to the SDF Platform. A DSAP must have a\nProject Manager who is responsible for overseeing and\nadministering the project, and is pre-approved by the SDF via\nbackground checks. The Project Manager must apply to the SDF\nand provide evidence that their project has satisfied relevant legal\nand ethical requirements. This evidence will be checked by the SDF\ngovernance body in accordance with the SDF Rulebook, and only if\nsatisfactory will the SDF support the project and grant access to any\nspecified datasets\n“Safe people”; “Safe\nprojects”\n(b) The SDF DSAP container process\nDSAPs must be secure and isolated from other projects and data“Safe setting”\n(c) The SDF DSAP default access policy\nThere must be a default access policy that prevents unauthorized data\nexport or download from the secure environment\n“Safe outputs”\n(d) The SDF DSAP audit trail process\nDSAPs must have their activities recorded for audit purposes in a\nnonrepudiable way; a project audit record is shared between the\nProject Manager, the relevant Data Provider(s), and the SDF\nPlatform\n“Safe setting”\n(Continued)\ne6-10 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\n3.2. Datatrust services\nDatatrust servicesare a sociotechnical evolution that advances databases and data management systems\ntoward a network of trusted stakeholders— who are connected through linked data by closely integrating\nmechanisms of governance with data management and access services.Datatrust services can offer a\nmultisided service platform (the SDF Platform), which creates value through linked data interactions\nbetween Data Providers and Data Users, while implementing the necessary management and governance\narrangements. We now describe the specific functionalities of ourdatatrust service platformrecognizing\nthat the features and design choices represent a specific implementation. We expect multiple implemen-\ntations of datatrust services to emerge, each with particular characteristics, but designed to flexibly\nsupport a range of governance models and values.\n3.2.1. Overview: Datatrust service platform\nFor illustration, Figure 2 depicts a datatrust service platform embedded into the “SDF Governance\nModel” (Section 3.1).\nSome key features of thisdatatrust service platform(as depicted byFigure 2) are as follows:\nTable 1. Continued\nKey standardized process for all“DSAPs”\nRelation to the“five safes\nplus one”\n(e) The SDF DSAP functional anonymization process\nDSAPs must process data legally, ethically, and securely— in\naccordance with all applicable data-sharing licenses and/or\nagreements, ethics approvals, and all other necessary requirements.\nThe SDF must practise“functional anonymization,” which is\ndefined by Elliot et al. (2018)a s“the practice of reducing the risk of\nre-identification through controls on the data and its environment so\nthat it is at an acceptably low level”\n“Safe data”; “Safe projects”;\n“Safe setting”\nTrusted Runtime Data Environment\nEthical and SocialData ServicesControl \nServices\nDSAP\nControl \nServices\nRegistry\nData \nServices\nRegistry\nFunctional \nAnonymisation\nOrchestrator\nDSAP\nTemplate\nData Source\nService Function\nSecurity Control \nService Function\nDSAP\nSpecification\nDSAP Pipeline\nContainers\nData\nConfiguration Purpose\nAnalysis & \nDevelopment\nReconfiguring \nData  & \nEnvironment \nSecure Virtual Infrastructure\nContainer Management\nEthics\nApproval\nArtefact\nRelease\nData Service Pipeline &\nQuery Specification Re-orchestration\nOrchestration API\nFunction API\nRisk\nManagement\nData Processing\nService Function\nDiscovery API\nControl API\nOwnership & \nRights\nManagement\nSocial\nLicence\nValue &\nProportionality\nEnvironment\nConfiguration\nQuality\nManagement\nRelease API\nImages, \nModels, \nNotebooks \nDatasets, \nPublications\nData science is \nan interactive \nprocess \nrequiring \nreorchestration \nProgrammable \ngovernance with \ndataflows as \ncode\nQuality \ncontrolled and \ntrusted functions\nDynamic \nFunctional \nAnonymisation\nSafe Outputs \nneed quality \nassurance\nDistributed runtime \nenvironment including \nhierarchical data centres \n(edge, etc)\nFigure 2.A datatrust service platform.\nData & Policy e6-11\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nA. Datatrust services related to “ensuring value and proportionality”: Such datatrust services are\nnecessitated to provide oversight for the lifecycle of DSAPs— through stages of request, orchestration,\nknowledge discovery, and artifact release— in order to ensure“value and proportionality” within the\ndefined remit of the SDF for stakeholder approval (i.e., maintaining a social license) and ethical\noversight.\nB. Datatrust servicesrelated to“purpose specification”: Suchdatatrust servicesare required to make\nsure the purpose of DSAPs are specified in templates that combine both human and machine-readable\nelements for consistency— and allow for human approval and automated deployment. Templates support\nprogrammable governance where dataflows are defined as code, and are used to orchestrate quality-\ncontrolled data services within functional anonymization environments dynamically with repeatability.\nC. Datatrust servicesrelated to“configuration of data and environment”: Suchdatatrust servicesfor\n“data configuration” and “environment configuration” are essential to give rise to the important property\nof functional anonymization, which is concerned with addressing risk of reidentification by controlling\ndata and their environment:\nA data environment usually consists of four key elements, and a description of a data environment\nthat includes these four elements is usually adequate for discussing, planning or evaluating the\nfunctional anonymisation of the original dataset. These elements are: other data [/] data users [/]\ngovernance processes [/] infrastructure (Elliot et al.,2018).\nInterpreting these four key elements of the“data environment” for a DSAP:\na. “Other data” are further datasets within the DSAP that may be combined with the dataset in\nquestion. Each DSAP is assessed for risk of reidentification on a case-by-case basis where the\nspecific combination of datasets and rights asserted in smart contracts are considered.\nb. “Data users” are vetted Data Analysts (“safe people”).\nc. “Governance processes” comprise the SDF governance processes— for example, for ethical\napproval, stakeholder acceptance, policy enforcement through contracts, licenses, and data usage\npolicies associated with data service functions.\nd. “Infrastructure” is provided by secure cloud resources todatatrust servicesthat may be federated\nthrough software-defined wide area networks (SD-WANs) allowing flexible configuration of\nnetworking elements— including potential for distributed runtime environment and hierarchical\ndata centers (e.g., public cloud, private cloud, and edge).Datatrust servicesare deployed as a cloud\ntenant, and utilize standard cloud services APIs in order to package containers and provision secure\npipelines of containers and resources dedicated to each DSAP, which are isolated from other DSAP\ninstances.\nTo enable a\n“safe setting” and support for“safe projects,” datatrust servicescomply with applicable\ncyber security certification (e.g., UK Cyber Essentials Plus) and industry-specific certification security\nstandards (e.g., NHS Data Security and Protection Toolkit,2021 to enable NHS health data process-\ning). In addition,datatrust servicesare operated within a cybersecurity risk assessment and mitigation\nprocess to guard against cyber threats and attacks— guided by ISO 27005 (ISO,2018), and compliant\nwith ISO 27001 (ISO,2013) risk management.\nOnce a DSAP is deployed, Data Users can access data services that operate on the datasets within the\nDSAP to produce artifacts including publications, new datasets, models, notebooks, and images. All\noutputs undergo quality assurance before release to academic, policy, or operational channels, including\nmeasurable evidence for social license, and updated data services available for deployment in new\nDSAPs.\ne6-12 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\n3.2.2. Datatrust service functionality\nDatatrust services govern a wide range of data service functions to collect, curate, discover, access\nand process health, and social care data. The development and packaging of data service functions is\nconducted outside of thedatatrust service platform by developers and then packaged as images for\ndeployment by the platform. Such data service functions are typically quality controlled software\nlibraries deployed by the platform depending on the requirements of Data Providers and Data Users.\nIn general, Data Providers are required to select cohorts and prepare data at source for sharing and\nlinking through tasks not limited to: (a) data deidentification; (b) data cleaning; (c) data quality\nassurance; (d) data consistency assurance (e.g., ensuring pseudonymized identifiers are consistent\nacross datasets); and (e) data harmonization and compatibility assurance (e.g., normalizing data\nfields across heterogeneous data sets generated by different software). The use of standardized\nmetadata, including provenance records, is important to make it possible to interpret and link\ndatasets. “Health Level 7 Fast Healthcare Interoperability Resources ”— known as HL7 FHIR—\n(Bender and Sartipi, 2013) is the predominant standard for discovery and exchange of electronic\nhealth care records and research databases, although routine datasets and those related to wider\nsocial determinants of health are vastly heterogeneous, with harmonization remaining a topic of\nsignificant research.\nData Users may (re)use a single source, or multiple sources, of data. The connection of multiple data\nsources is referred to as“data linking”— which is defined by the Public Health Research Data Forum\n(2015) as:\nbringing together two or more sources of information which relate to the same individual, event,\ninstitution or place. By combining information, it may be possible to identify relationships between\nfactors which are not evident from the single sources.\nDifferent data linking processes exist to combine datasets. For example, deterministic and probabilistic\ntechniques can be used to identify the same individuals in two datasets, and then processed using\ncryptographic algorithms to provide tokenized link identifiers (Jones et al.,2014), while federated\nlearning pipelines offer the opportunity to build AI (Machine Learning) models that can learn from\nmultiple datasets without exchanging the data itself (Rieke et al.,2020).\nThe capability to flexibly specify, provision and monitor secure dataflow pipelines within the context\nof ethical oversight, social license, and risk management are key characteristics ofdatatrust services.In\nthe following subsections, we describe four important aspects ofdatatrust servicefunctionality in more\ndetail: functional anonymization, specification of data and dataflows, compliance decision support, and\nownership and rights management.\n3.2.3. Functional anonymization\nWhat is the“Functional Anonymization Orchestrator”? As its name suggests, the“Functional Anon-\nymization Orchestrator” is thedatatrust servicefor functional anonymization— and performs an auto-\nmated process for deployment of data services, security controls/permissions, and allocation of compute\nstorage and network resources.\nHow does it work? The Functional Anonymization Orchestrator interfaces with a registry of pre-\napproved, trusted data service functions and environment controls, as well as the Risk Management\ncomponent responsible for assessment of risks related to compliance, privacy, and cybersecurity. The\noutcome of orchestration is an isolated and secure virtual environment for each DSAP, thus imple-\nmenting “safe projects.” This combination of data configuration, environment configuration, and risk\nmanagement ensures that datatrust services offer the property of functional anonymization— and\ntherefore works to address its key elements, as cited by Elliot et al. (2018) (see Section 3.2.1 for\nfurther information).\nData & Policy e6-13\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\n3.2.4. Specification of data and dataflows\nWhat is the“DSAP template”? The “DSAP Template” is thedatatrust servicefor the specification of\ndata and dataflows that are subsequently used as part of ethical approvals, data-sharing agreements, and\ndata protection impact assessments.\nHow does it work?The Functional Anonymization Orchestrator allows Data Users to express DSAP\nrequirements through declarative templates using cloud-native orchestration languages (e.g., Kuber-\nnetes). Such declarative languages provide ways to construct machine-readable DSAP templates that\ncan be tailored using properties and used to provision and configure virtual instances offering the\nrequired data services. The templates include data service configuration specifying queries that define\ncohort inclusion and exclusion criteria, and retention policies. The standardization of templates and\nAPIs will be essential for interoperation between datatrust services governing health and social\ncare data.\nTemplates are technical in nature and therefore a predefined set of baseline templates are defined for\ndifferent project types, as outlined inTable 2. These templates support data distribution patterns for\nhosting, caching, and accessing datasets— and offer the flexibility required for variability in risk of loss of\ncontrol associated with different types of datasets and Data Providers’appetite for such risks. In addition,\nthe flexibility in data distribution models allows for replication, retention, and associated cost implications\nto be considered.\n3.2.5. Compliance decision support\nWhat is the “risk management” component? The “Risk Management” component is the datatrust\nservice for regulatory compliance decision support for DSAP pipelines— and utilizes an asset-based risk\nmodeling approach following ISO 27001 (ISO,2013); initially based on cyber security.\nHow does it work?Risk is explicitly defined in relation tothreats upon assets. Assets are tangible and\nnontangible items of value— while datasets are core assets of interest, other assets include software, data,\nmachinery, services, people, and reputation. Assets may be attacked by threats, which causemisbehavior\nin the asset (i.e., unwanted, erroneous, or dangerous behavior). Therisk to the asset is the severity of the\nmisbehavior combined with the likelihood of the threat.Controls may be applied to the asset to reduce the\nlikelihood of the threat occurring.\nTable 2. Data sharing and analysis project template types\nDSAP baseline template Description\nPlatform hosted Data are uploaded to the Platform from a Data Provider and then\nsubsequently imported and linked within a DSAP\nApplies to situations where data are hosted by the Platform only\nProject hosted Data are uploaded and linked within a DSAP from one or more Data\nProviders\nApplies to situations where data are made discoverable via the Platform,\nbut are not hosted by the Platform\nFederated query Data are hosted by a Data Provider and access is limited to analysis by\npredefined distributed queries executed at Data Providers and\nsubsequent linking of results\nApplies to situations where Data Providers wish to maximize control\nover their datasets\nHybrid hosted and query Data is linked in some combination of Platform Hosted, Project Hosted\nand Federated Query\ne6-14 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nA semi-automated approach for risk identification and analysis based on a security risk analysis tool—\nthe “System Security Modeller”— has been developed in previous work; and, applied to trust in\ncommunication network situations (Surridge et al.,2018) as well as health care applications and data\nprotection compliance (Surridge et al.,2019). This work has been further extended into the realm of\nregulatory compliance requirements in Taylor et al. (2020). Threat types supported by the Risk Manage-\nment approach therefore include cyber security, such as those associated with the“Open Web Application\nSecurity Project” (OWASP) Top Ten (2021), or compliance threats due to failures in regulatory or\nlicensing compliance.\nThe Risk Management component therefore detects cyber security or regulatory compliance threats—\nbased on a specified DSAP template— and provide recommendations for controls (mitigating strategies)\nto block a compliance threat sufficiently to satisfy a regulatory requirement. While further work is\nrequired on the specifics of the compliance requirements themselves, the methodology for encoding\ncompliance requirements into a risk management approach has been proven.\nExample of potential risk: Reidentification.A key risk to be mitigated is the potential for reidentification\nthat can arise through data sharing, usage and reusage in DSAPs. Oswald (2013) defines the risk of\nreidentification as:\nthe likelihood of someone being able to re-identify an individual, and the harm or impact if that re-\nidentification occurred.\nData linking,“singling out” individuals, and“inference”— that is, deducing some information about an\nindividual (Article 29 Data Protection Working Party,2014) are data vulnerabilities that may result in\npotential harms to data subjects, as well as compliance threats and potential harms to Data Providers. The\nRisk Management component ensures that the SDF can“mitigate the risk of identification until it is\nremote” (Information Commissioner’s Office,2012) using control strategies (e.g., source pseudonymiza-\ntion andk-anonymization) that are assessed according to the DSAP template risk model, and monitored\nthrough risk assessment points on DSAP deployment and data service functions (e.g., upload, query, and\naggregation). The Risk Management component provides risk assessment to the Functional Anonymiza-\ntion Orchestrator— and only if an acceptable, low level of risk is found will the services provide data to\nData Users. Where an unacceptable level of risk is found, data access is denied pending further checking\nand additional measures to deidentify data.\nExample of risk assessment points: Federated query scenario.As an example,Figure 3shows the risk\nassessment points for the“Federated Query DSAP Template” (as denoted by four numbered green\ndiamonds):\nSDF Pla/g414orm Trusted Research Environment\nShared Project Audit\nSecure Project EnvironmentProject\nAnalyst\nQuery & \nAnalysis\nProject\nManager\nPseudonymised \nData\nPseudonymised \nData\nQuery Distribu/g415on\nmanage\nQuery Results \nLinking\nQuery\nQuery\nResult\nResult\nData Provider\nData\nProvider\n1\n2\nquery\nresults 34\nFigure 3.Reidentification risk assessment for distributed query.\nData & Policy e6-15\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nIn the Federated Query scenario (one of four predefined baseline DSAP templates outlined inTable 2),\npolicy enforcement is dynamic with risk assessment points (1) and (2) placed at each Data Provider upon\nreceipt and processing of a query fragment; here the results of the query fragment are checked. Risk\nassessment point (3) occurs after the result fragments are linked, and risk assessment point (4) occurs after\nany analysis of the linked result.\nNote that a key difference between the Platform Hosted and Federated Query scenarios (seeTable 2)i s\nwhere reidentification risk assessment takes place. While, in the Federated Query scenario, some of the\nreidentification risk checking is distributed to Data Providers; in the Platform Hosted scenario, all such\nchecking is undertaken by the operator of the Platform. The ability to check for reidentification risk on a\nper-query basis at Data Provider premises (in the Federated Query scenario) therefore strengthens the Data\nProvider’s control over their data for circumstances where data cannot be exchanged.\n3.2.6. Ownership and rights management\nWhat is the“ownership and rights management” service? SDF Governance requires that each DSAP\nhave its activities recorded for audit purposes in a nonrepudiable way. Thisdatatrust servicetherefore\nensures that all permitted stakeholders for a specified DSAP— for example, Project Manager, Data\nProvider(s)— have access to a“Shared Project Audit Distributed Ledger” where all transactions for a\nDSAP are recorded.\nHow does it work?\nDistributed ledger technology. To provide such Shared Project Audit Distributed Ledgers, the SDF\nemploys distributed ledger technology (based on blockchain technology):\nA distributed ledger is essentially an asset database that can be shared across a network of multiple\nsites, geographies or institutions (UK Government Chief Scientific Adviser,2016).\nDistributed ledger technology has appropriate properties for“DSAP audit” in that it is immutable\n(i.e., records cannot be altered or deleted), and it is inherently shared and distributed (i.e., each permitted\nstakeholder has their own copy of the audit record). All transactions within the DSAP (e.g., analysis\nactivities of data analysts) are automatically recorded onto the audit ledger. Audit logs are irreversible and\nincontrovertible, thus providing a robust audit trail, as well as encouraging compliant behavior.\nSmart contracts. To ensure compliance with all specified data-sharing agreements and/or licenses\napplicable to a DSAP, the Ownership and Rights Management service also employs smart contracts\ntechnology. Smart contracts are related to distributed ledger technology— as programs are run on a\nblockchain, which\ndefine rules, like a regular contract, and automatically enforce them via the code (Ethereum,2021).\nSmart contracts have several useful properties for the purposes of“license terms enforcement” in the\nSDF Platform:\n Smart contracts are programs that provide user functionality: Data browsing, analysis, access,\nlinking, and query functions can be written within smart contracts, and used by Data Analysts in\nDSAPs.\nFor example, a smart contract can implement data linking using pseudonymized identifiers, or\nqueries on datasets at Data Providers.\n Smart contracts provide means to automate enforcement of agreement terms: Each invocation of\nfunctionality provided by smart contract programs can be evaluated at runtime— based on the\ncombined data input, function, and parameters of the invocation— for compliance with the license\nterms of the Data Providers whose datasets are used in a DSAP. Smart contracts implementing data-\noriented functions should be the entry point for all data analysis activity, and license terms therefore can\ne6-16 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nbe enforced at the point of execution by the Data Analyst. This automated enforcement prevents Data\nAnalysts from executing operations that are inconsistent with the license terms of Data Providers.\nFor example, if one Data Provider prohibits pseudonymized linking, their dataset will not be\navailable to a smart contract implementing pseudonymized linking; whereas for other Data\nProviders who do permit linking, their datasets can be available to the“linking” smart contract.\n The transactions executed for smart contracts are recorded automatically on“Shared Project Audit\nDistributed Ledgers”: Given smart contracts are implemented on blockchain (i.e., the underlying\ntechnology shared with distributed ledger technology), a key link between the functionality\navailable to data-centric functions executed by Data Analysts and the Shared Project Audit\nDistributed Ledger is provided.\nIt is important to highlight that further work is required to establish specific smart contract dataset\nfunctions and license terms to be enforced. While it is expected that there will be highly specific\nrequirements for individual DSAPs, it also remains likely that there will be some common functionality\nand license terms frequently used across many types of DSAPs.\n4. Validation of the SDF Model\nTo validate the SDF model, we now analyze a real-world project exploring the social determinants of\nhealth: the“Multidisciplinary Ecosystem to study Lifecourse Determinants of Complex Mid-life Multi-\nmorbidity using Artificial Intelligence”— MELD project (MELD,2021). This test case seeks to answer\nthe question:if the MELD project were to be supported by the SDF (as a DSAP), to what extent would the\nfeatures of the SDF model improve the safety, execution and impact of the project?\n4.1. Test case overview: National Institute for Health Research— MELD project\nMELD focuses on the“lifecourse causes of early onset complex” multimorbidity; “early onset” is\nwhere a person has two or more long-term conditions before the age of 50 years old, and“complex”\nwhere a person has four or more long-term conditions (MELD,2021). Multimorbidity is one of\nseveral key focus areas for health and social care transformation. A substantial number of people\n(30% all ages, 54% > 65 years of age and 83% > 85 years) suffer from two or more long-term\nconditions (Cassell et al., 2018), with those from more disadvantaged backgrounds more likely to\ndevelop multimorbidity earlier. Multimorbidity affects quality of life, leads to poorer health out-\ncomes and experiences of care, and accounts for disproportionate healthcare workload and costs.\nSolutions are needed to understand disease trajectories over the life-course (start well, live well, age\nwell) at population levels, and to develop e ffective personalize d interventions.\nFurthermore, complex and heterogeneou s longitudinal and routine linked data— including social\ndeterminants of health from datasets beyond electronic healthcare systems— are needed to study the\nclusters and trajectory of disease.\nMELD is selected for validation of the SDF model as it is closely aligned with the purpose of the SDF.\nSpecifically, MELD is seeking to develop novel public health interventions by analyzing the social\ndeterminants of health using complex linked social and health datasets. MELD is part of a multidis-\nciplinary ecosystem for data linkage and analysis together with citizen participation and engagement.\nAs such, MELD helps unpack different data requirements required for DSAPs— and can drive the\ndevelopment of DSAP templates. MELD also highlights that data linkage can take many forms, such as\ntransfer learning, and demonstrates the variety of generated outputs that would need to be managed— for\nexample, derived data, artificial intelligence/machine learning models, and tooling.\n4.2. MELD 1.0: Initial project\nThe first phase of MELD brings together a multidisciplinary team— including researchers from medicine,\nsocial science, and computer science— and patient and public involvement (PPI) representatives to\nData & Policy e6-17\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nexplore life-course determinants of multiple long-term conditions. MELD is supported by a National\nInstitute for Health Research (NIHR) and considers two datasets:\n The 1970 British Cohort Study (BCS70) dataset: The BCS70 is a well-established, longitudinal birth\ncohort dataset that“follows the lives of more than 17,000 people born in England, Scotland and\nWales in a single week of 1970.” (UK Data Service,1970) This dataset is available for secondary use\nvia the UK Data Service. The MELD project has access to all BCS70 data collected as part of data\nsweeps.\n The Care and Health Information Exchange Analytics (CHIA) dataset: The CHIA (Care and Health\nInformation Exchange,n.d.) is a clinical dataset provided by the NHS and includes 700,000 patients\nin Hampshire and the Isle of Wight. The dataset is available for secondary use via the South, Central,\nand West Commissioning Support Unit on behalf of health and social care organizations in\nHampshire, Farnham, and the Isle of Wight.\nThe two datasets provided must only be accessible to the research team for the purposes of the project. The\ndevelopment phase has received institutional-level (the appropriate Research Ethics Committee [REC]),\nand national-level ethics approval (NHS REC). As part of the ethics review process, the project team has\ncarried out a data protection impact assessment.\nMELD will develop AI pipelines to:\n(1) Curate the datasets to assess and ensure readiness;\n(2) Develop clustering algorithms to identify early onset complex and burdensome multiple long term\nconditions;\n(3) Explore if sentinel conditions and long-term condition accrual sequence can be identified and\ncharacterized; and\n(4) Devise AI transfer learning methods that allow extrapolation of inferences from BCS70 to CHIA\n— and vice versa.\nThe intention is for MELD to link together more datasets, in particular those related to other birth cohorts\nand larger routine datasets requiring“the necessary environment, principles, systems, methods and team\nin which to use AI techniques” in order to“identify optimal timepoints for public health interventions”\n(IT Innovation Centre,n.d.).\nThe exploratory work undertaken will be used as a proof of concept for a larger research collaboration\napplication:\nto scale the MELD ecosystem to‘combine’ other birth cohorts and larger routine datasets giving\nmuch greater power to fully explore the lifecourse relationship between sequence of exposure to\nwider determinants, sentinel and subsequent clinical events, and development of early other\ncomplex MLTC-M clusters (MELD,2020).\nIt is therefore vital that MELD is able to handle more complex types of data linkage activities than the\nremit of its current study— for example, combinations of multiple types of diverse data from additional\ndata providers with different licensing arrangements, provenance, and quality. As part of these future\nwork plans, MELD requires a data governance model that is scalable and adaptive to its growing needs.\n4.3. Hypothetical MELD 2.0: Scaling up data linking facilitated by the SDF\nThe SDFdatatrust serviceswill support the MELD project team in the delivery of research outcomes\nwhile helping stakeholders manage associated risks efficiently. The stakeholders include: the NHS Health\nResearch Authority (HRA); the two data providers (NHS for CHIA and the UK Data Service for BCS70);\nthe principal investigator for MELD— who takes the role of project manager; and the data analysts\nworking on the project.\ne6-18 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\n4.3.1. Project approvals, data access and resources\nThe principal investigator for MELD must first establish the required research ethics approvals (e.g., at\ninstitutional and national levels), data access rights, and resources to undertake research— all of which are\nnecessary to delegate rights to Data Analysts as part of the MELD project team. For instance, NHS HRA\napproval “applies to all project-based research taking place in the NHS in England and Wales” (NHS\nHRA, 2021). NHS HRA approval requires researchers to submit a research application form through the\nIRAS— which includes detailed study information along with supporting documents (NHS HRA,2019,\n2021)— such as,“Organization Information Document,”“Schedule of Events” and “Sponsors Insurance”\nprovided by the principal investigator’s host organization following local approval.\nWhile institutional and national governance processes for approval requests require similar informa-\ntion, there is little standardization between processes and document structures. Consistency between\ndescribed dataflows, data scope, policies, and environments is entirely disconnected from system\nimplementation. By starting with a project template configured with human and machine-readable data\nrequirements, dataflows, and environment controls (e.g., the DSAP template as described inSection\n3.2.4), risk management can be directly embedded into research processes— and thus greater agility in\nsuch processes can be achieved. The project specification is then used and adapted to authority requests.\nIdeally, authorities need to transform governance web forms to programmable APIs and business\nprocesses; collaboration through standardization will be required.\n4.3.2. Example: Setup and operation of a MELD 2.0 DSAP\nWe now outline the main steps to be taken by the principal investigator for MELD and the SDF in order to\nset up a DSAP for MELD 2.0.\nFigure 4shows the secure project environment for the MELD 2.0 project within the SDF platform.\nDuring setup, the following steps occur:\nMELD\nShared \nAudit\nRecords\nSDF Pla/g414orm Trusted Research Environment\nMELD Secure Project Environment\nExplore\nData\nAnalysis Query \nDistribu/g415onQuery\nQuery Results, ML \nAnalysis \n& Reden/g415ﬁca/g415on \nRisk Assessment\nData \nExamina/g415on\nData\nAnalyst\nMetadata\nAnalysis \nResults\nMeld PI\n1\nCHIA \nResult\nFragment\nCHIA Query\nFragment\nBCS70 \nQuery\nFragment\nBCS70 Result\nFragment\n2\n4\n4\n4\nMetadata\n4 1\n4 2\n1 2\nUKDS\nNHS\nML ToolsUse of ML\nTools 4\nProject Agreement Audit Checkpoint41 2 3\nAdminister\nProject\n3\nRe-iden/g415ﬁca/g415on Risk Assessment Checkpoint\nBCS70 \n(pseudonymous)\nCHIA \n(pseudonymous)\nCHIA Data \nContainer\nBCS70 \nData \nContainer\nQuery I/FQuery I/F\n1\n2\n1\n2\nFigure 4.MELD within thedatatrust service platform.\nData & Policy e6-19\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\n(1) The principal investigator for MELD (“MELD PI”) requests a DSAP— and then completes a\nDSAP template with data configuration (inclusion, exclusion, and retention) along with sup-\nporting information regarding satisfaction of compliance requirements, ethical soundness and\nsocial benefit.\n(2) The SDF’s governing body performs background checks on the principal investigator for MELD\n— and if approved assesses the project application.\n(3) The SDF’s governing body assesses the application and if the evidence regarding compliance,\nethics, and social benefit is satisfactory, the SDF agrees to support MELD.\n(4) The principal investigator for MELD makes an agreement with the SDF for a DSAP (as denoted\nby the“green circle 3” in Figure 4).\n(5) The SDF creates a DSAP for MELD. The MELD DSAP (represented by the“pink box” in\nFigure 4) is a secure environment— isolated from DSAPs for other projects. Access to the MELD\nDSAP for data analysts is specified by principal investigator for MELD and enforced by the\nplatform.\n(6) The principal investigator for MELD acquires agreements and/or licenses from specified data\nproviders, which will come with terms of use that must be respected (indicated by the“green\ncircles 1 and 2,” respectively inFigure 4). The MELD principal investigator names the SDF as\ntheir TRE in agreement with these specified data providers.\n(7) The datasets are acquired from the Data Providers by the SDF (as the named delegate by the\nprincipal investigator)— and are loaded into the MELD DSAP.\n(8) The principal investigator for MELD authors the“MELD Data Usage Policy” (as denoted by\n“green circle 4” in Figure 4), which must be consistent with the licenses and/or agreements\nbetween the principal investigator for MELD and the two data providers (“green circles 1 and 2”\nin Figure 4).\n(9) The principal investigator for MELD appoints Data Analysts, who must agree to the“MELD\nData Usage Policy.”\n(10) The principal investigator for MELD grants access to the“MELD DSAP” for each approved\nData Analyst.\nDuring operation, the following steps are performed, most likely iteratively. All MELD analyst operations\nare via datatrust services that perform data functions encoded within smart contracts that provide\nfunctionality constrained to agreements and policies for MELD, which are denoted by the“green\ncircles” in Figure 4.\n(1) One or more specified Data Analysts for MELD explore dataset metadata limited by those defined\nin the DSAP specification.\n(2) One or more specified Data Analysts for MELD formulate queries, which may be on an individual\ndataset or inferences between datasets. These queries must be consistent with:\na. Specified data usage terms for the DSAP; and\nb. Approvals (IRAS for CHIA dataset; UK Data Service End User Agreement for BCS70\ndataset).\n(3) One or more specified Data Analysts for MELD run queries and use machine learning tools to\nanalyze the resultant data. Depending on the query from the Data Analyst(s), the results may be\nfrom one dataset or both datasets linked by common attributes. Data Analysts are not able to\ndownload the datasets from the DSAP.\n(4) Results are returned after internal checking for consistency with the appropriate agreements. Audit\nrecords (the“large shared green box” in Figure 4) are maintained and shared between the key\nstakeholders to encourage transparency and promote trustworthiness.\ne6-20 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\n4.4. Validation\nThe SDF model aims to improve and accelerate data flows for health and social care transformation in five\nways (Boniface et al.,2020), through:“empowerment of citizens”; “greater assurances to stakeholders”;\n“faster ethical oversight and information governance”; “better discoverability of data and generated\noutcomes”; and “facilitation of localized solutions with national leadership.” We now explore each\nproposed benefit— and how it can be realized for the MELD project.\n4.4.1. Empowerment of citizens\nGiven the depth of data required to understand lifestyle behaviors, socioeconomic factors, and health, the\ndevelopment of AI-based interventions addressing multimorbidity over the life-course necessitates a\ntrusted partnership with citizens: access to such data is contingent on trust building.\nThe SDF model is governed through the principles and values of open science, ethics, integrity, and\nfairness in full consideration of digital inclusion (i.e., literacy and innovation opportunities), social\ninclusion, and gender equality. It further considersthe structures required to support multidisciplinary\nand multimotivational teams. Through Citizen Representatives, patient/service user voice is repre-\nsented at board level. Citizen empowerment is further addressed through collaborations with local\ninitiatives, such as the Southampton Social Impact Lab (2021), which allows for novel ways of\ncodesign and coevaluation, including hard-to-reach groups. The SDF model therefore goes beyond\nrepresentation in governance — and further facilitates participation in the design of solutions for\ncommunities.\nThe SDF is positioned in Southampton (UK)— a region serving a 1.8 million population (3.7\nmillion including specialist care) with a large network of distributed health and social care providers.\nThe geographic region and environmental conditions are highly diverse— including urban, maritime,\nand rural economic activities as well as large permanent/transient populations presenting a diverse\npopulation with a wide range of health and care needs. This population diversity helps to ensure civil\nand citizen engagement activities (e.g., patient/s ervice user voice, codesign, and coevaluation),\nrelated to the discovery and evaluation of new interventions, as inclusive and connected to local\nneeds. The SDF is therefore well positioned t o make sure that research results are publicized\nappropriately, and that community and individual benefits are realized— with evidence provided of\nproven potential.\n4.4.2. Greater assurances for stakeholders\nThe design, testing, and generalization of interventions from MELDrequire the incremental explor-\nation of the datasets required to develop new clustering and prediction algorithms. The methodology\nrequires an iterative process of data discovery, curation, and linking to assess the readiness of datasets\nfor the required analysis. The quality of routine health and social care data, and birth cohort data is\nunknown, as is the performance of AI pipelines applied to such data. As such, data needs to be carefully\nassembled, incrementally, in accordance with governance requirements for data minimization and\nmitigation of risk.\nThe approach of the SDF todynamic functional anonymization, risk management, and auditable\nprocesses is ideally designed to efficiently support projects such as MELD and provide assurances for\nstakeholders. Both the CHIA and BCS70 datasets are pseudonymized, and therefore present a risk of\nreidentification when analyzed or linked, with newly identified datasets introducing further risks. The\nSDF provides checkpoints for such risks within data pipelines from source to insight, and data analysis\nfunctionality constrained to compliance with license terms of Data Providers. Further, given that the SDF\nsupports Federated Query project types, data are not linked until the purpose is known (i.e., to meet the\nprinciple of purpose limitation), the prior knowledge of the project purposes, usage context and dataset\nstructures involved can inform the reidentification risk assessment. The use of transparent, shared,\nnonrepudiable audit records encourages compliant behaviors. Audit checkpoints for recording access\nto datasets can be verified against their respective license agreements. In some cases, multiple agreements\nData & Policy e6-21\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nare audited at the same point— for example, when the Data Analyst receives query results, the two license\nagreements plus data usage policy terms are audited. With all datasets stored within an isolated and secure\nproject environment, Data Analysts are not able to download them. The datasets therefore cannot be\npropagated further, thus reducing the risk of unauthorized access, and potential loss of control experienced\nby Data Providers.\n4.4.3. Faster ethical oversight and information governance\nThe initial MELD project is a form of“data release” where datasets (CHIA and BSC70) are defined in\nadvance at the start of the project— and a single ethics approval is provided. In many ways, the datasets\nand governance of the MELD 1.0 project are simple— however, this initial approach does not scale when\nthe complexity of data linkage increases (i.e., MELD 2.0) raising challenges for capturing the data\nrequirements, but also providing the information to those responsible for ethical oversight, such as the\nNHS HRA and research sponsors.\nThe SDF model addresses the sociotechnical interface between humans responsible for ethics\ndecisions and the machines used by analysts to undertake the research. By establishing the concept of\nDSAP templates— as a sociotechnical integration mechanism driving oversight, risk management, and\nprovisioning— processes can be semi-automated in ways that ensure the human-in-the-loop is retained.\nThe automation of processes will deliver efficiencies in approvals, risk assessment (e.g., deidentification\nstandards) and dataflows, and such efficiencies will allow for the potential for iterative ways of working\nand reorchestration of DSAP projects when new requirements are discovered. Given the SDF model is\npredicated on strong oversight and monitoring of approved projects through the Independent Guardian,\nthe SDF is able to help to support and present the exploratory work undertaken during a proof of concept.\nThis is because the SDF is able to provide assurances to data providers that licensing arrangements were\ncomplied with, and best practice was followed.\n4.4.4. Better discoverability of data and generated outcomes\nMELD is part of a wider National Institute for Health Research (NIHR) AI programme, which itself\nis part of a vibrant research community seeking ways by which AI solutions can deliver better\ncare. Collaboration and sharing outcomes therefore will be an essential part of MELD success and\nimpact.\nThe SDF supports an ecosystem for data-driven research and innovation in health and social care. As a\nhub, the SDF provides opportunities for MELD to connect with a community of stakeholders sharing\ncommon interests (including local social and healthcare data providers), and experts from a wide range of\ndisciplines, such as ethics, law, psychology, sociology, and technology. By joining the SDF community,\nMELD will be enriched through increased citizen engagement and participation, and feedback from the\nresearch and innovation community can uncover new associations between projects (including projects\nthat are already part of the SDF and from elsewhere), and lead to new opportunities for collaborations and\nimpact. More general outcomes — such as new datasets, data usage metrics, reusable\nmethodologies, tools , and models— are all possible benefits to the community that can increase MELD\nimpact. For example, as a progressive data governance model, the SDF would aim to iteratively learn and\nintegrate best practices from the MELD project to influence policy, benefit the SDF community, and\nprovide evidence for a social license.\n4.4.5. Facilitation of localized solutions with national leadership\nMELD aims to provide community and individual benefits to those living with multimorbidity— and must\ndevelop interventions in ways that both connect with the local needs of citizens and can be generalized and\nscaled nationally.\nThe SDF recognizes that disruptive research and innovation often happens between trusted local\npartners working in placed-based systems who address identified challenges together (NHS,n.d.).\ne6-22 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nProjects are undertaken in the context of supportive national policies— where engagement in scale-up\nprograms turns federated place-based transformation into national assets. This contrasts with approaches\nto build single solutions nationally, which expect place-based systems to accept and adopt them. The SDF\ntherefore supports projects where experimentation is needed to explore unknown solutions, and retain\npluralism of research, while developing leaders that have influence on the national stage.\n4.5. Limitations\nAlthough the MELD project has provided an initial validation of the SDF platform as a real-life\nimplementation for a TRE, there are some limitations. First, since one of the MELD project\ncoinvestigators also coleads the SDF project, it is possible that data governance constructs may have\ninfluenced each project implicitly. However, we maintain that such overlap demonstrates that the SDF\nis based on experience and not just a literature review. Secondly, focusing on one test case does not\ncover the breadth of challenges related to data linkage for health and social care transformation. For\ninstance, the management of multiple long-term conditions is only one area of the much larger field of\nhealth and social care transformation, the data users are only from one academic institution, and there\nare no transnational data-sharing activities. However, notwithstanding these limitations and for the\npurposes of this article, we consider that as a“thought-exercise” the MELD test case provides a useful\ncontribution to the much wider and on-going effort of the SDF initiative to test and validate the SDF\nmodel.\n5. Conclusion\nThe SDF model provides one example of a TRE, which offers a new approach to data-driven transform-\nation of health and social care systems that is secure, rights respecting, and endorsed by communities.\nThrough datatrust services— a sociotechnical evolution of databases and data management systems—\nstakeholder-sensitive data governance mechanisms are combined with data services to create TREs that\nadhere to the“Five Safes Plus One.” In an age of increasing data complexity and scale, such TREs can\naccelerate research and innovation that depends on multistakeholder linked data (e.g., social determinants\nof health research) while providing a trust-enhancing and well-regulated structure offering assurances to\ndata subjects and data providers. The ability ofdatatrust services to dynamically orchestrate secure\ndataflows with properties of functional anonymization and monitor risks at runtime— allows for pro-\ngressive governance models, and more iterative knowledge discovery processes. The means to iterate\ncreates new ways to incorporate collective ethical oversight and citizen participation (i.e., representation,\ncodesign, and evaluation) more naturally into phases of research.\nWe further outlined the“SDF Governance Model,” including the institutional structure, processes, and\nroles with consideration of the full range of relevant legitimate interests and the fiduciary ethical virtues of\nloyalty and care. We then described howdatatrust services can support DSAPs using capabilities of\nfunctional anonymization orchestration, risk management, and auditable data ownership and rights\nmanagement. We then validated the approach against a representative project“MELD” exploring the\nsocial determinants of multimorbidity over the life-course— as an exemplar DSAP— in order to highlight\nhow MELD can benefit from the SDF model when scaling the research to more complex datasets.\nIn this article, we have presented our version ofdatatrust serviceswithin the specific context of the\nSDF. However, we recognize that there is no-one-size-fits-all approach, and there may be simpler and\nmore complex forms ofdatatrust services better suited to other data-sharing initiatives with different\ngovernance arrangements to the SDF (e.g., with other data-sharing purposes, contexts, diameters of trust,\nand stakeholder expectations). While we must remain cognizant of the types of values embedded in the\ndesign ofdatatrust services, and the extent to which these could act as constraints if redeployed in other\nmultiparty sharing scenarios, elements of the SDF model could be used as primitives fordatatrust services\nas part of other TREs. The design and development of thesedatatrust servicestherefore must be suitably\nData & Policy e6-23\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nflexible so that they can be generalized to deliver different governance arrangements and facilitate safe\ndata sharing within other settings and domains.\nFollowing agreement of the three principal partners, we now move into a phase of establishing a SDF in\nSouthampton working with citizens to attain social license, and other stakeholders to provision infra-\nstructure anddatatrust services.A set of transformation projects have been identified beyond the initial\nMELD project that aim to deliver a wide range of benefits to citizens, healthcare providers, and social care\nproviders, but are also being used to drive forward approaches to governance. This interplay between\n“progressive digitalisation” and “progressive governance” is at the heart of the SDF model, which aims to\nensure that governance reflects the values and priorities of the community, in order to accelerate projects\nso that outcomes benefit citizens as soon as possible.\nGlossary\nFor the purposes of this article, we define the following terms:\nData governance mechanisms Well-defined roles and processes for ensuring the safe and secure sharing, usage and\nreusage of health and social care data as part of a TRE, such as in relation to collective-\ncentric decision-making, citizen representation, and data stewardship.\nData sharing and analysis project\n(“DSAP”)\nA health and social care research project that is approved by the SDF Governance\nBoard for facilitation via the SDF Platform.\nDatatrust services A sociotechnical evolution that advances databases and data management systems,\nand brings together stakeholder-sensitive data governance mechanisms with data\nservices to create a TRE.\nFiduciary ethical virtues of loyalty and\ncare\nBehavior seen to be trustworthy, that retains trust and, in so doing, delivers positive\noutcomes across the full range of stakeholders in relation to a data institution (such as\nthe SDF).\nFunctional anonymization The practice of mitigating the risk of reidentification to a remote level by\nimplementing “controls on data and its environment” (Elliot et al.,2018).\nHealth and social care transformation The progressive digitalization of health and social care services in response to societal\ndemands and advances in clinical practice, medicine, and technology.\nMultimorbidity The cooccurrence of two or more long-term health conditions.\nSocial Data Foundation for Health and\nSocial Care (“the SDF”)\nA new data institution for multiparty data sharing to enable positive health and social\ncare transformation via a TRE, which is based on a specific implementation of\ndatatrust services.\nSocial determinants of health Nonmedical factors that significantly affect individual well-being and health\ninequalities— for example, education and employment.\nSocial license A high degree of social legitimacy; stakeholder approvals for health and social care\nresearch, innovation and transformation given to data institutions (which are under\nconstant reevaluation)— on the basis that the main stakeholders perceive that what is\nbeing done is acceptable, trustworthy, and beneficial toward the communities it\nintends to serve.\nTrusted research environment A safe and secure data platform for approved DSAPs that can be accessed (remotely)\nby authorized persons (e.g., data analysts); and, which abides by the“Five Safes Plus\nOne” approach: “safe people,”“ safe projects,”“ safe data,”“ safe setting,”“ safe\noutputs,” and (where necessary)“safe return” (The UK Health Data Research\nAlliance, 2020).\nAcknowledgments. This article expands and extends the concepts in our Web Science Institute (WSI) white paper (Boniface et al.,\n2020). We therefore give special thanks to all those that supported and contributed to this white paper. This includes Rachel Bailey\n(University Hospital Southampton NHS Foundation Trust), Tom Barnett (Web Science Institute, University of Southampton), Prof.\nSally Brailsford (CORMSIS, University of Southampton), Guy Cohen and Marcus Grazette (Privitar), Paul Copping (Sightline\nInnovation), Christine Currie (CORMSIS, University of Southampton), Jo Dixon (Research and Innovation Services, University of\nSouthampton), Dan King (Southampton City Council), Alison Knight (Research and Innovation Services, University of South-\nampton), Prof. Kieron O’Hara (Electronics and Computer Science, University of Southampton), Alistair Sackley (Web Science\nInstitute, University of Southampton), Prof. Mike Surridge (IT Innovation Centre, University of Southampton), Neil Tape\n(University Hospital Southampton NHS Foundation Trust), Gary Todd (Famiio Ltd.), and Wally Trenholm (Sightline Innovation).\nWe also greatly acknowledge the valuable discussions and feedback from Privitar on an earlier draft of the white paper, and the\ne6-24 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nsupport of Pinsent Mason lawyers in the development of legal arrangements. We again thank Prof. Kieron O’Hara for the discussions\nand valuable input on the notion of fiduciary ethical virtues in relation todatatrust services.Finally, but by no means least, we extend\nour special thanks to NIHR MELD lead investigators, Dr. Simon Fraser and Dr. Nisreen Alwan at the University of Southampton for\nthe contribution to the validation case. Please note that all views and opinions expressed in this article are those of the authors, and do\nnot necessarily represent those named above. A pre-print version of this article is available via EPrints Soton— Boniface et al.\n(2021). Prof. Dame Wendy Hall also delivered a keynote speech, which is available via the Sixth International Data for\nPolicy Conference playlist (Hall,2021).\nFunding Statement. The Social Data Foundation (SDF) project is partly funded and supported by the University of Southampton’s\nWeb Science Institute (WSI) and Southampton Connect. This research article has also been supported in part by the“Multidiscip-\nlinary Ecosystem to Study Lifecourse Determinants of Complex Mid-life Multimorbidity using Artificial Intelligence” (MELD)\nproject funded by the National Institute for Health Research (Award ID: NIHR202644).\nCompeting Interests. The authors declare no competing interests exist.\nAuthor Contributions. Conceptualization: M.B., L.C., B.P., S.S.-B, S.T.; Methodology: M.B., S.S.-B.; Writing— original draft:\nM.B., L.C., B.P., S.S.-B, S.T.; Writing— review and editing: M.B., L.C., W.H., B.P., S.S.-B., S.T. These author contributions are\nbased on the CRedit Taxonomy— available at:https://casrai.org/credit/. All authors approved the final submitted draft.\nData Availability Statement.As part of the MELD test case, the two following datasets are discussed: the 1970 British Cohort\nStudy (BCS70) dataset available from the UK Data Service (beta.ukdataservice.ac.uk/datacatalogue/series/series?id=200001); and,\nthe Care and Health Information Exchange Analytics (CHIA) dataset available from the South, Central and West Commissioning\nSupport Unit on behalf of health and social care organizations in Hampshire, Farnham, and the Isle of Wight (https://\ncareandhealthinformationexchange.org.uk/). Restrictions apply to the availability of these data.\nReferences\nAbrams EM and Szefler SJ(2020) COVID-19 and the impact of social determinants of health.The Lancet Respiratory Medicine 8\n(7), 659–661. https://doi.org/10.1016/S2213-2600(20)30234-4\nAda Lovelace and the AI Council (2021) Exploring legal mechanisms for data stewardship. Available at https://www.\nadalovelaceinstitute.org/report/legal-mechanisms-data-stewardship/ (accessed 20 May 2021).\nAinsworth J and Buchan I(2015) Combining health data uses to ignite health system learning.Methods of Information in Medicine\n54(6), 479–487. Available at https://www.thieme-connect.de/products/ejournals/pdf/10.3414/ME15-01-0064.pdf (accessed\n20 May 2021).\nAitken M, Tully MP, Porteous C, Denegri S, Cunningham-Burley S, Banner N, Black C, Burgess M, Cross L, van Delden J,\nFord E, Fox S, Fitzpatrick N, Gallacher K, Goddard C, Hassan L, Jamieson R, Jones KH, Kaarakainen M, Lugg-Widger\nF, McGrail K, McKenzie A, Moran R, Murtagh MJ, Oswald M, Paprica A, Perrin N, Richards EV, Rouse J, Webb J and\nWillison DJ(2020) Consensus statement on public involvement and engagement with data-intensive health research.Inter-\nnational Journal of Population Data Science 4(1), 586.https://doi.org/10.23889/ijpds.v4i1.586\nArbuckle L and Ritchie F(2019) The five safes of risk-based anonymization.IEEE Security & Privacy 17(5), 84–89. https://\ndoi.org/10.1109/MSEC.2019.2929282\nArticle 29 Data Protection Working Party(2014) Opinion 05/2014 on anonymisation techniques. WP216 adopted on 10 April\n2014. Available at https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp216_en.pdf\n(accessed 21 May 2020).\nBanner N (2020) A new approach to decisions about data. Understanding patient data. Available at https://\nunderstandingpatientdata.org.uk/news/new-approach-decisions-about-data (accessed 20 May 2021).\nBender D and Sartipi K(2013) HL7 FHIR: An Agile and RESTful approach to healthcare information exchange. In Pereira\nRodrigues P, Pechenizkiy M, Gama J, Cruz Correia R, Liu J, Traina A, Lucas P and Soda P (eds),Proceedings of the 26th IEEE\nInternational Symposium on Computer-based Medical Systems, University of Porto, Portugal. Institute of Electrical and\nElectronics Engineers, Inc. (IEEE), pp. 326–331. https://doi.org/10.1109/CBMS.2013.6627810\nBoniface M, Carmichael L, Hall W, Pickering B, Stalla-Bourdillon S and Taylor S(2020) A blueprint for a social data\nfoundation: Accelerating trustworthy and collaborative data sharing for health and social care transformation. Web Science\nInstitute (WSI) White Paper #4. Available atwww.socialdatafoundation.org/ (accessed 20 May 2021).\nBoniface M, Carmichael L, Hall W, Pickering B, Stalla-Bourdillon S and Taylor S(2021) The social data foundation model:\nFacilitating health and social care transformation throughdatatrust services. [Preprint]. Local EPrints ID: 449699. Available at\nhttp://eprints.soton.ac.uk/id/eprint/449699 (accessed 15 June 2021).\nBurström B and Tao W(2020) Social determinants of health and inequalities in COVID-19.European Journal of Public Health 30\n(4), 617–618. https://doi.org/10.1093/eurpub/ckaa095\nBurton PR, Murtagh MJ, Boyd A, Williams JB, Dove ES, Wallace SE, Tassé A-M, Little J, Chisholm RL, Gaye A, Hveem K,\nBrookes AJ, Goodwin P, Fistein J, Bobrow M and Knoppers BM(2015) Data safe havens in health research and healthcare.\nBioinformatics 31(20), 3241–3248. https://doi.org/10.1093/bioinformatics/btv279\nData & Policy e6-25\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nCare and Health Information Exchange (CHIE)(n.d.) Available athttps://careandhealthinformationexchange.org.uk/ (accessed\n20 May 2021).\nCARE Principles for Indigenous Data Governance(2018) International data week and research data alliance plenary co-hosted\nevent. Indigenous Data Sovereignty Principles for the Governance of Indigenous Data Workshop, Gaborone, Botswana.\nAvailable athttps://www.gida-global.org/care (accessed 20 May 2021).\nCarter P, Laurie GT and Dixon-Woods M(2015) The social licence for research: whycare.data ran into trouble.Journal of\nMedical Ethics 41(5), 404–409. Available athttps://jme.bmj.com/content/41/5/404 (accessed 20 May 2021).\nCassell A, Edwards D, Harshfield A, Rhodes K, Brimicombe J, Payne R and Griffin S(2018) The epidemiology of\nmultimorbidity in primary care: A retrospective cohort study.British Journal of General Practice 68(669), e245–51. https://\ndoi.org/10.3399/bjgp18X695465\nCentral Digital and Data Office(2020) Data ethics framework. UK Government Digital Services. Available athttps://www.gov.\nuk/government/publications/data-ethics-framework/data-ethics-framework-2020 (accessed 20 May 2021).\nCentre for Data Ethics and Innovation(2020) Addressing public trust in public sector data use. Available athttps://www.gov.uk/\ngovernment/publications/cdei-publishes-its-first-report-on-public-sector-data-sharing/addressing-trust-in-public-sector-data-\nuse (accessed 20 May 2021).\nCurvedThinking (2019) Understanding public expectations of the use of health and care data. Developed in consultation with:\nUnderstanding Patient Data, Commissioned by One London. Available athttps://understandingpatientdata.org.uk/sites/default/\nfiles/2019-07/Understanding%20public%20expectations%20of%20the%20use%20of%20health%20and%20care%20data.pdf\n(accessed 20 May 2021).\nData Linkage Western Australia(2021) Available athttps://www.datalinkage-wa.org.au/ (accessed 19 March 2021).\nData Protection Act(2018) (UK) Available athttps://www.legislation.gov.uk/ukpga/2018/12/contents/enacted(accessed 24 May\n2021).\nDavidson S, McLean C, Treanor S, Aitken M, Cunningham-Burley S, Laurie G, Pagliari C and Sethi N(2013) Public\nacceptability of data sharing between the public, private and third sectors for research purposes. Scottish Government Social\nResearch, Ipsos MORI Scotland and University of Edinburgh, Research Commissioned by the Scottish Government. Available at\nhttps://www.webarchive.org.uk/wayback/archive/3000/ and https://www.gov.scot/resource/0043/00435458.pdf (accessed\n14 December 2021).\nDesai Y, Ritchie F and Welpton R(2016) Five safes: Designing data access for research.UWE, Economics Working Paper Series\n1601. Available athttps://www2.uwe.ac.uk/faculties/bbs/Documents/1601.pdf (accessed 21 May 2021).\nDodds L, Szász D Keller JR, Snaith B and Duarte S\n(2020) Designing sustainable data institutions. Open Data Institute (ODI)\nreport. Contributions from Hardinges J and Tennison J. Available athttps://theodi.org/article/designing-sustainable-data-\ninstitutions-paper/ (accessed 20 May 2021).\nElliot M, O’Hara K, Raab C, O’Keefe CM, Mackey E, Dibben C, Gowans H, Purdam K and McCullagh K(2018) Functional\nanonymisation: Personal data and the data environment.Computer Law & Security Review 34(2), 204–221. https://doi.org/\n10.1016/j.clsr.2018.02.001\nEthereum (2021) Introduction to smart contracts. Available athttps://ethereum.org/en/developers/docs/smart-contracts/ (accessed\n21 May 2021).\nEuropean Commission(2019) Building trust in human-centric artificial intelligence. Communication from the Commission to the\nEuropean parliament, the Council, the European Economic and Social Committee and the Committee of the Regions. COM\n(2019) 168 final. Available athttps://digital-strategy.ec.europa.eu/en/library/communication-building-trust-human-centric-arti\nficial-intelligence (accessed 21 May 2021).\nFord E, Boyd A, Bowles JKF, Havard A, Aldridge RW, Curcin V, Greiver M, Harron K, Katikireddi V, Rodgers SE and\nSperrin M(2019) Our data, our society, our health: A vision for inclusive and transparent health data science in the United\nKingdom and beyond.Learning Health Systems 3(3), e10191.https://doi.org/10.1002/lrh2.10191\nGalea S, Abdalla SM and Sturchio JL(2020) Social determinants of health, data science, and decision-making: Forging a\ntransdisciplinary synthesis.PLoS Medicine 17(6), e1003174.https://doi.org/10.1371/journal.pmed.1003174\nGeissbuhler A, Safran C, Buchan I, Bellazzi R, Labkoff S, Eilenberg K, Leese A, Richardson C, Mantas J, Murray P and De\nMoor G(2013) Trustworthy reuse of health data: A transnational perspective.International Journal of Medical Informatics 82\n(1), 1–9.\nhttps://doi.org/10.1016/j.ijmedinf.2012.11.003\nGeneral Data Protection Regulation (GDPR)(2016) Regulation (EU) 2016/679 of the European Parliament and of the Council of\n27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such\ndata, and repealing Directive 95/46/EC (General Data Protection Regulation) European Commission. Available athttps://eur-\nlex.europa.eu/eli/reg/2016/679/oj (accessed 21 May 2021).\nHall W (2021). A Blueprint for a Data Foundation. Keynote Speech at Sixth International Data for Policy Conference 2021.\nRecording available athttps://dataforpolicy.org/global-discussion-on-the-future-of-policy-data-interactions-at-data-for-policys-\nsixth-edition/ (accessed 17 December 2021).\nHarrison T (2020) Putting the trust in trusted research environments. Understanding patient data. Available at https://\nunderstandingpatientdata.org.uk/news/putting-trust-trusted-research-environments (accessed 21 May 2021).\nHawkes N(2013) Hospitals without walls.BMJ 34, f5479.https://doi.org/10.1136/bmj.f5479\nHripcsak G, Bloomrosen M, FlatelyBrennan P, Chute CG, Cimino J, Detmer DE, Edmunds M, Embi PJ, Goldstein MM,\nHammond WE, Keenan GM, Labkoff S, Murphy S, Safran C, Speedie S, Strasberg H, Temple F and Wilcox AB(2014)\ne6-26 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nHealth data use, stewardship, and governance: Ongoing gaps and challenges: A report from AMIA’s 2012 Health Policy Meeting.\nJournal of the American Medical Informatics Association 21(2), 204–211. https://doi.org/10.1136/amiajnl-2013-002117\nICES (2021) Available athttps://www.ices.on.ca/ (accessed 20 May 2021).\nInformation Commissioner’s Office (ICO)(2012) Anonymisation: Managing data protection risk code of practice. Available at\nhttps://ico.org.uk/media/1061/anonymisation-code.pdf (accessed 20 May 2021).\nIntegrated Research Application System (IRAS)(2021) Available athttps://www.myresearchproject.org.uk/ (accessed 20 May\n2021).\nISO (2013) ISO/IEC 27001:2013. Information technology— Security Techniques— Information security management systems—\nRequirements, International Organization for Standardization, 2013. Available athttps://www.iso.org/ (accessed 20 May 2021).\nISO (2018) ISO 27005 Information Technology— Security techniques— Information security risk management. Available athttps://\nwww.iso.org/ (accessed 20 May 2021).\nIT Innovation Centre(n.d.) MELD. University of Southampton. Available athttp://www.it-innovation.soton.ac.uk/projects/ai-\nmeld (accessed 4 June 2021).\nJacobs B and Popma J(2019) Medical research, big data and the need for privacy by design.Big Data & Society 6,1 –5. https://\ndoi.org/10.1177/2053951718824352\nJanssen M, Brous P, Estevez E, Barbosa LS and Janowski T(2020) Data governance: Organizing data for trustworthy artificial\nintelligence. Government Information Quarterly 37(3), 101493.https://doi.org/10.1016/j.giq.2020.101493\nJones KH and Ford DV(2018) Population data science: Advancing the safe use of population data for public benefit.Epidemiology\nand Health 40, e2018061.https://doi.org/10.4178/epih.e2018061\nJones KH, Ford DV, Jones C, Dsilva R, Thompson S, Brooks CJ, Heaven ML, Thayer DS, McNerney C and Lyons RA(2014)\nA case study of the Secure Anonymous Information Linkage (SAIL) gateway: A privacy-protecting remote access system for\nhealth-related research and evaluation. Journal of Biomedical Informatics 50 , 196 –204. https://doi.org/10.1016/\nj.jbi.2014.01.003\nKariotis T, Ball M\n, Greshake Tzovaras B, Dennis S, Sahama T, Johnston C, Almond H and Borda A(2020). Emerging health\ndata platforms: From individual control to collective data governance. Data & Policy 2, E13. https://doi.org/10.1017/\ndap.2020.14\nLin D, Crabtree J, Dillo I, Downs RR, Edmunds R, Giaretta D, De Giusti M, L’Hours H, Hugo W, Jenkyns R, Khodiyar V,\nMartone ME, Mokrane M, Navale V, Petters J, Sierman B, Sokolova DV, Stockhause M and Westbrook J(2020) The\nTRUST principles for digital repositories.Scientific Data 7, 144.https://doi.org/10.1038/s41597-020-0486-7\nMarmot M, Allen J, Boyce T, Goldblatt P and Morrison J(2020) Health Equity in England: The Marmot Review 10 Years on.\nLondon: Institute of Health Equity. Available athttp://www.instituteofhealthequity.org/resources-reports/marmot-review-10-\nyears-on/the-marmot-review-10-years-on-full-report.pdf (accessed 21 May 2021).\nMayer RC, Davis JH and Schoorman FD(1995) An integrative model of organizational trust.The Academy of Management\nReview 20(3), 709–734. Available athttps://www.jstor.org/stable/258792 (accessed 21 May 2021).\nMedConfidential (2017) Enabling evidence based continuous improvement: The target architecture– Connected care settings and\nimproving patient experience. Available at https://medconfidential.org/wp-content/uploads/2017/09/2017-07-13-Target-\nArchitecture.pdf (accessed 21 May 2021).\nMELD, University of Southampton(2021) Research project: Developing a multidisciplinary ecosystem to study lifecourse\ndeterminants of complex mid-life multimorbidity using artificial intelligence (MELD). Faculty of Medicine. Available athttps://\nwww.southampton.ac.uk/medicine/academic_units/projects/meld.page (accessed 21 May 2021).\nMiller FA, Patton SJ, Dobrow M and Berta W(2018) Public involvement in health research systems: A governance framework.\nHealth Research Policy and Systems 16, 79.https://doi.org/10.1186/s12961-018-0352-7\nMoses B and Desai K(2020). Data governance is broken. Information Week. Available athttps://informationweek.com/big-data/\ndata-governance-is-broken-/a/d-id/1339635 (accessed 21 May 2021).\nMuller SHA, Kalkman S, van Thiel GJMW, Mostert M and van Delden JJM(2021) The social licence for data-intensive health\nresearch: Towards co-creation, public value and trust.BMC Medical Ethics 22, 110.https://doi.org/10.1186/s12910-021-00677-5\nMultidisciplinary Ecosystem to study Lifecourse Determinants of Complex Mid-life Multimorbidity using Artificial\nIntelligence (MELD)(2020) Project proposal. University of Southampton. Internal document.\nNational Cyber Security Centre(n.d.) UK Cyber Essentials Plus. Available athttps://www.ncsc.gov.uk/cyberessentials/overview\n(accessed 20 May 2021).\nNHS (2019) The NHS long term plan. V1.2. Available athttps://www.longtermplan.nhs.uk/wp-content/uploads/2019/08/nhs-long-\nterm-plan-version-1.2.pdf (accessed 21 May 2021).\nNHS (n.d.) Placed based approaches to reducing health inequalities. Available athttps://www.england.nhs.uk/ltphimenu/placed-\nbased-approaches-to-reducing-health-inequalities/ (accessed 21 May 2021).\nNHS Data Security and Protection Toolkit(2021) Available athttps://www.dsptoolkit.nhs.uk/ (accessed 21 May 2021).\nNHS Digital(n.d.) Data Access Request Service (DARS). Available athttps://digital.nhs.uk/services/data-access-request-service-\ndars (accessed 20 May 2021).\nNHS Health Research Authority (HRA)(2019) Prepare study documentation. Last updated: 17 July 2019. Available athttps://\nwww.hra.nhs.uk/planning-and-improving-research/research-planning/prepare-study-documentation/ (accessed 14 December\n2021).\nData & Policy e6-27\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nNHS Health Research Authority (HRA)(2021) HRA approval. Last updated: 22 November 2021. Available athttps://www.\nhra.nhs.uk/approvals-amendments/what-approvals-do-i-need/hra-approval/ (accessed 14 December 2021).\nNorthern Health Science Alliance (NSHA)(2020) Connected health cities: Impact report 2016–2020. Available athttps://\nwww.thenhsa.co.uk/app/uploads/2020/10/CHC-full-impact-report.pdf (accessed 21 May 2021).\nO’Hara K(2019) Data trusts: Ethics, architecture and governance for trustworthy data stewardship. Web Science Institute (WSI)\nWhite Paper #1. Available athttps://www.southampton.ac.uk/wsi/enterprise-and-impact/white-papers.page (accessed 20 May\n2021).\nO’Hara K(2021) From internal discussions with authors on the notion of fiduciary ethical virtues anddatatrust services.\nOcloo J and Matthews R(2016) From tokenism to empowerment: Progressing patient and public involvement in healthcare\nimprovement. BMJ Quality & Safety 25(8), 626–632. http://doi.org/10.1136/bmjqs-2015-004839\nOswald M(2013) Something bad might happen: Lawyers, anonymization and risk.XRDS 20(1), 22–26. https://doi.org/10.1145/\n2508970.\nOWASP (2021) OWASP top ten. Available athttps://owasp.org/www-project-top-ten/ (accessed 20 May 2021).\nPozen DE (2005) The Mosaic theory, national security, and the freedom of information act.Yale Law Journal 115, 628–679.\nAvailable at SSRNhttps://ssrn.com/abstract=820326 (accessed 20 May 2021).\nPublic Health England(2017) Reducing health inequalities: System, scale and sustainability. Available athttps://assets.publishing.\nservice.gov.uk/government/uploads/system/uploads/attachment_data/file/731682/Reducing_health_inequalities_system_\nscale_and_sustainability.pdf (accessed 21 May 2021).\nPublic Health Research Data Forum(2015). Enabling data linkage to maximise the value of public health research data: Full\nreport. Available at https://cms.wellcome.org/sites/default/files/enabling-data-linkage-to-maximise-value-of-public-health-\nresearch-data-phrdf-mar15.pdf (accessed 21 May 2021).\nResearch Data Alliance (RDA) COVID-19 Working Group(2020) RDA COVID-19; Recommendations and guidelines on data\nsharing, final release 30 June 2020.https://doi.org/10.15497/rda00052.\nRieke N, Hancox J, Li W, Milletari F, Roth HR, Albarqouni S, Bakas S, Galtier MN, Landman BA, Maier-Hein K, Ourselin\nS, Sheller M, Summers RM, Trask A, Xu D, Baust M and Cardoso MJ(2020) The future of digital health with federated\nlearning. NPJ Digital Medicine 3, 119.https://doi.org/10.1038/s41746-020-00323-1\nRooney D, Leach J and Ashworth P(2014) Doing the social in social licence.Social Epistemology 28(3–4), 209–218. https://\ndoi.org/10.1080/02691728.2014.922644\nSadana R and Harper S(2011) Data systems linking social determinants of health with health outcomes: Advancing public goods\nto support research and evidence-based policy and programs.Public Health Reports 126(3), 6–13. https://doi.org/10.1177/\n00333549111260S302\nSAIL (2021) Databank. Available athttps://saildatabank.com/ (accessed 21 May 2021).\nScott K(2018). Data for Public Benefit: Balancing the risks and benefits of data sharing. Report Co-authored by Understanding\nPatient Data, Involve and Carnegie UK Trust. Contributors: Burall S, Perrin N, Shelton P, White D, Irvine G and Grant\nA. Available athttps://www.involve.org.uk/sites/default/files/field/attachemnt/Data%20for%20Public%20Benefit%20Report_\n0.pdf (accessed 24 May 2021).\nSharon T and Lucivero F(2019) Introduction to the special theme: the expansion of the health data ecosystem— Rethinking data\nethics and governance.Big Data & Society 6,1 –5. https://doi.org/10.1177/2053951719852969\nSmart Dubai and Nesta(2020) Data sharing toolkit: Approaches, guidance and resources to unlock the value of data. Available at\nhttps://www.nesta.org.uk/toolkit/data-sharing-toolkit/ (accessed 4 June 2021).\nSohail O, Sharma P and Ciric B(2018) Data governance for next-generation platforms. Deloitte. Available athttps://www2.\ndeloitte.com/us/en/pages/technology/articles/data-governance-next-gen-platforms.html (accessed 20 May 2021).\nSpinney L(2021). Hospitals without walls: The future of healthcare. The Guardian. Available athttps://www.theguardian.com/\nsociety/2021/jan/02/hospitals-without-walls-the-future-of-digital-healthcare (accessed 21 May 2021).\nStalla-Bourdillon S, Carmichael L and Wintour A(2021) Fostering trustworthy data sharing: Establishing data foundations in\npractice. Data & Policy 3, e4.https://doi.org/10.1017/dap.2020.24\nStalla-Bourdillon S, Wintour A and Carmichael L(2019) Building Trust through Data Foundations: A Call for a Data\nGovernance Model to Support Trustworthy Data Sharing. Web Science Institute (WSI) White Paper #2. Available athttps://\nwww.southampton.ac.uk/wsi/enterprise-andimpact/white-papers.page (accessed 21 May 2021).\nSurridge M, Correndo G, Meacham K, Papay J, Phillips SC, Wiegand S and Wilkinson T(2018) Trust modelling in 5G mobile\nnetworks. InProceedings of the 2018 Workshop on Security in Softwarized Networks: Prospects and Challenges (SecSoN’18).\nWorkshop Co-Chairs: Benson T, Bisson P, Pries R and Zinner T. New York, NY: ACM, pp. 14–19. https://doi.org/10.1145/\n3229616.3229621\nSurridge M, Meacham K, Papay J, Phillips SC, Pickering JB, Shafiee A and Wilkinson T(2019) Modelling compliance threats\nand security analysis of cross border health data exchange. In Attiogbé C, Ferrarotti F and Maabout S (eds),New Trends in Model\nand Data Engineering. MEDI 2019. Communications in Computer and Information Science, Vol.1085. Cham: Springer.https://\ndoi.org/10.1007/978-3-030-32213-7_14\nTaylor S, Surridge M and Pickering B(2020) Regulatory compliance modelling using risk management techniques. Available at\nSSRN http://doi.org/10.2139/ssrn.3716778\ne6-28 Michael Boniface et al.\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press\nThe Toronto Declaration(2018) Protecting the right to equality and non-discrimination in machine learning systems. Amnesty\nInternational and AccessNow (eds). Available athttps://www.torontodeclaration.org/wp-content/uploads/2019/12/Toronto_\nDeclaration_English.pdf (accessed 21 May 2021).\nThompson Reuters: Practical Law (n.d.) Fiduciary duties and fiduciary. Glossary. Available at https://uk.practicallaw.\nthomsonreuters.com/1-107-5744?transitionType=Default&contextData=(sc.Default)&firstPage=true (accessed 30 November\n2021).\nTriggle N(2021). Is COVID at risk of becoming a disease of the poor?BBC News,February 2021. Available athttps://www.bbc.\nco.uk/news/health-56162075 (accessed 21 May 2021).\nUK Data Service(1970) 1970 British Cohort Study (BCS70). Available atbeta.ukdataservice.ac.uk/datacatalogue/series/series?\nid=200001 (accessed 20 May 2021).\nUK Data Service(n.d.) Regulating access to data: 5 Safes. Available athttps://www.ukdataservice.ac.uk/manage-data/legal-\nethical/access-control/five-safes (accessed 20 May 2021).\nUK Department of Health and Social Care(2021) A guide to good practice for digital and data-driven health technologies.\nAvailable athttps://www.gov.uk/government/publications/code-of-conduct-for-data-driven-health-and-care-technology/initial-\ncode-of-conduct-for-data-driven-health-and-care-technology (accessed 21 May 2021).\nUK Government Chief Scientific Adviser(2016) Distributed ledger technology: Beyond block chain. Government Office for\nScience. Available at https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/\n492972/gs-16-1-distributed-ledger-technology.pdf (accessed 21 May 2021).\nUK Health Data Research Alliance (UKHDRA)(2020) Trusted Research Environments (TRE): A strategy to build public trust\nand meet changing health data science needs. Green Paper v2.0 dated 21 July 2020. Available athttps://ukhealthdata.org/wp-\ncontent/uploads/2020/07/200723-Alliance-Board_Paper-E_TRE-Green-Paper.pdf (accessed 21 May 2021).\nUK Health Data Research Alliance (UKHDRA)(n.d.) Innovation Gateway. Available athttps://www.healthdatagateway.org/\n(accessed 21 May 2021).\nUnderstanding Patient Data and Ada Lovelace Institute(2020) Foundations of fairness: Where next for NHS health data\npartnerships. Available athttps://understandingpatientdata.org.uk/sites/default/files/2020-03/Foundations%20of%20Fairness%\n20-%20Summary%20and%20Analysis.pdf (accessed 21 May 2021).\nUniversity of Southampton(2021) Social impact lab. Available athttps://www.southampton.ac.uk/silab/index.page (accessed\n20 May 2021).\nVarshney S(2020). A progressive approach to data governance.Forbes. Available athttps://www.forbes.com/sites/forbestech\ncouncil/2020/11/03/a-progressive-approach-to-data-governance/ (accessed 20 May 2021).\nWessex Care Records(2021) Available athttps://www.wessexcarerecords.org.uk/ (accessed 20 May 2021).\nWinter JS and Davidson E(2019) Big data governance of personal health information and challenges to contextual integrity.The\nInformation Society 35(1), 36–51. https://doi.org/10.1080/01972243.2018.1542648\nWorld Health Organization(n.d.) social determinants of health. Available athttps://www.who.int/health-topics/social-determin\nants-of-health (accessed 20 May 2021).\nYoung M, Rodriguez L, Keller E, Sun F, Sa B, Whittington J and Howe B(2019) Beyond open vs. closed: Balancing individual\nprivacy and public accountability in data sharing. InProceedings of the Conference on Fairness, Accountability, and Trans-\nparency (F AT*’19). General Co-Chairs: Boyd, D and Morgenstern J. Program Co-Chairs: Chouldechova A and Diaz F.\nNew York: Association for Computing Machinery (ACM), pp. 191–200. https://doi.org/10.1145/3287560.3287577\nCite this article: Boniface M, Carmichael L, Hall W, Pickering B, Stalla-Bourdillon S and Taylor S(2022). The Social Data\nFoundation model: Facilitating health and social care transformation throughdatatrust services. Data & Policy, 4: e6. doi:10.1017/\ndap.2022.1\nData & Policy e6-29\nhttps://doi.org/10.1017/dap.2022.1 Published online by Cambridge University Press",
  "topic": "Data governance",
  "concepts": [
    {
      "name": "Data governance",
      "score": 0.6192286610603333
    },
    {
      "name": "Health care",
      "score": 0.5908854603767395
    },
    {
      "name": "License",
      "score": 0.5219383239746094
    },
    {
      "name": "Stakeholder",
      "score": 0.5212088823318481
    },
    {
      "name": "Knowledge management",
      "score": 0.4922155439853668
    },
    {
      "name": "Business",
      "score": 0.49109673500061035
    },
    {
      "name": "Sociotechnical system",
      "score": 0.48421168327331543
    },
    {
      "name": "Data sharing",
      "score": 0.475027859210968
    },
    {
      "name": "Corporate governance",
      "score": 0.46653300523757935
    },
    {
      "name": "Public relations",
      "score": 0.44303134083747864
    },
    {
      "name": "Internet privacy",
      "score": 0.39405977725982666
    },
    {
      "name": "Process management",
      "score": 0.33097803592681885
    },
    {
      "name": "Computer science",
      "score": 0.3156737685203552
    },
    {
      "name": "Data quality",
      "score": 0.1928749680519104
    },
    {
      "name": "Medicine",
      "score": 0.17861005663871765
    },
    {
      "name": "Political science",
      "score": 0.1700679063796997
    },
    {
      "name": "Marketing",
      "score": 0.15340358018875122
    },
    {
      "name": "Alternative medicine",
      "score": 0.0
    },
    {
      "name": "Pathology",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Metric (unit)",
      "score": 0.0
    },
    {
      "name": "Finance",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I43439940",
      "name": "University of Southampton",
      "country": "GB"
    }
  ],
  "cited_by": 8
}