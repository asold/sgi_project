{
  "title": "Crawling The Internal Knowledge-Base of Language Models",
  "url": "https://openalex.org/W4386566424",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2182941915",
      "name": "Roi Cohen",
      "affiliations": [
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A2736090994",
      "name": "Mor Geva",
      "affiliations": [
        "Allen Institute"
      ]
    },
    {
      "id": "https://openalex.org/A86633810",
      "name": "Jonathan Berant",
      "affiliations": [
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A1484279603",
      "name": "Amir Globerson",
      "affiliations": [
        "Tel Aviv University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4293060592",
    "https://openalex.org/W4281748205",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4285429195",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W2038721957",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3199958362",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2963318887",
    "https://openalex.org/W4221166196",
    "https://openalex.org/W4303441863",
    "https://openalex.org/W4298187912",
    "https://openalex.org/W4285298351",
    "https://openalex.org/W3104939451",
    "https://openalex.org/W4223974161",
    "https://openalex.org/W4283765342",
    "https://openalex.org/W2251913848",
    "https://openalex.org/W2167187514",
    "https://openalex.org/W3118781290",
    "https://openalex.org/W3206959854",
    "https://openalex.org/W2561529111"
  ],
  "abstract": "Language models are trained on large volumes of text, and as a result their parameters might contain a significant body of factual knowledge. Any downstream task performed by these models implicitly builds on these facts, and thus it is highly desirable to have means for representing this body of knowledge in an interpretable way. However, there is currently no mechanism for such a representation.Here, we propose to address this goal by extracting a knowledge-graph of facts from a given language model. We describe a procedure for \"crawling\" the internal knowledge-base of a language model. Specifically, given a seed entity, we expand a knowledge-graph around it. The crawling procedure is decomposed into sub-tasks, realized through specially designed prompts that control for both precision (i.e., that no wrong facts are generated) and recall (i.e., the number of facts generated). We evaluate our approach on graphs crawled starting from dozens of seed entities, and show it yields high precision graphs (82-92%), while emitting a reasonable number of facts per entity.",
  "full_text": "Findings of the Association for Computational Linguistics: EACL 2023, pages 1856–1869\nMay 2-6, 2023 ©2023 Association for Computational Linguistics\nCrawling The Internal Knowledge-Base of Language Models\nRoi Cohen1 Mor Geva2∗ Jonathan Berant1 Amir Globerson1\n1Blavatnik School of Computer Science, Tel Aviv University 2Allen Institute for AI\nroi1@mail.tau.ac.il, pipek@google.com, joberant@cs.tau.ac.il, gamir@tauex.tau.ac.il\nAbstract\nLanguage models are trained on large volumes\nof text, and as a result their parameters might\ncontain a significant body of factual knowledge.\nAny downstream task performed by these mod-\nels implicitly builds on these facts, and thus it\nis highly desirable to have means for represent-\ning this body of knowledge in an interpretable\nway. However, there is currently no mechanism\nfor such a representation. Here, we propose to\naddress this goal by extracting a knowledge-\ngraph of facts from a given language model.\nWe describe a procedure for “crawling” the\ninternal knowledge-base of a language model.\nSpecifically, given a seed entity, we expand a\nknowledge-graph around it. The crawling pro-\ncedure is decomposed into sub-tasks, realized\nthrough specially designed prompts that con-\ntrol for both precision (i.e., that no wrong facts\nare generated) and recall (i.e., the number of\nfacts generated). We evaluate our approach on\ngraphs crawled starting from dozens of seed en-\ntities, and show it yields high precision graphs\n(82-92%), while emitting a reasonable number\nof facts per entity.\n1 Introduction\nModern language models (LMs) (Raffel et al.,\n2020; Brown et al., 2020) are trained on vast\namounts of text that captures much of human\nknowledge, including scientific articles, Wikipedia,\nbooks, and other sources of information (Gao et al.,\n2020). Consequently, such models encode world\nknowledge in their parameters, allowing them to\ngenerate rich and coherent outputs.\nPast work has illustrated LMs can be viewed\nas knowledge-bases (Petroni et al., 2019) as well\nas analyzed the encoded knowledge (e.g., see\nAlKhamissi et al., 2022) and leveraged it for\napplications such as closed-book QA (Roberts\net al., 2020; Brown et al., 2020) and search (Tay\net al., 2022), illustrating LMs can be viewed as\n∗ Now at Google Research.\nknowledge-bases (Petroni et al., 2019). But what\nare the facts stored in the internal knowledge bases\nof modern LMs, and how can these be represented\nexplicitly? This is the challenge we address in this\nwork. Our motivation is to obtain an interpretable\nand transparent representation that will allow hu-\nmans to inspect what the LM knows, what it does\nnot know, why it makes certain mistakes, and what\nare the biases it encodes. Moreover, with such a\nrepresentation, one can leverage general-purpose\ntools, such as query languages, for interacting with\nthis knowledge.\nThe first question in this endeavour is what is\na suitable explicit knowledge representation. A\nnatural candidate structure is a knowledge graph\n(KG). Namely, a graph whose nodes are entities\nand whose edges represent relations between enti-\nties. KGs are appealing since information can be\nreadily “read-off” from the graph, they can be reli-\nably queried, and different KGs can be easily com-\npared. KGs have been extensively used to represent\nknowledge (Bollacker et al., 2008; Vrandeˇci´c and\nKrötzsch, 2014), but a key limitation is their low\ncoverage, as they usually require manual curation\nand depend on a closed schema. Conversely, LMs\nmight have very high coverage as they are trained\non a vast body of knowledge represented as raw\ntext. We thus ask if it is possible to convert an LM\nto a KG, such that we enjoy its advantages while\nachieving high coverage.\nAs the full KG encoded in an LM can be large,\nwe reduce the problem to the task of constructing\na KG around a given seed entity. For example,\nFig. 1 shows a KG extracted by our method for the\nseed entity Alan Turing. This can be viewed as a\ncrawling procedure which starts from the seed en-\ntity and recursively expands it to expose additional\nfacts. This crawling problem introduces several\nnew challenges. First, unlike prior work (Petroni\net al., 2019; Alivanistos et al., 2022; Hao et al.,\n2022), we are given only an entity, without know-\n1856\nAlan \nTuring\nUnited \nKingdom\nCountry of \ncitizenship\ncapital\nOfficial \nlanguageSummer \ndstTime \nzone\nMember of\nLondon\nEnglishYesGMT \n(UTC+0)\nEuropean \nUnion\ncurrency\nGovernment \ntype\nInternet ltdISO 3166 \ncode Calling \ncode\nPound \nSterling\nConstitutional \nMonarchy\n.uk\nGB +44\nBritish\nNationality\nOfficial \nlanguage of\ncapital\ncountry\nGiven \nname\nFamily \nname\nEducated at\nEducated at\nPlace of birth\nField of work\nAlan Turing King’s \nCollege\nSherborne \nSchool\nPaddington, \nLondon\nCryptanalysis\nSuicide\nManner \nof death\noccupation\noccupation\nField of \nworkSex or \ngender\nField of work\nMathematician\nComputer \nScienceLogicianMale\nMathematics Named \nafter\nIndustry Information \nTechnology\nNotable \nsubfields\nNotable \nsubfields\nNotable \nsubfields\nNotable \nsubfields\nTopology\nAlgebra\nAnalysis\nGeometry\nFigure 1: An example of a generated depth-2 knowledge graph around the seed entity ALAN TURING , applying\nLMCRAWL (see Sec. 3-Sec. 4). Additional graphs are in Sec. E.\ning what relations are associated with it. Thus, we\nhave to extract those relations and then find the ob-\njects for each relation. Second, KGs are expected to\nexhibit very high precision, and thus it is necessary\nto generate as many relevant facts as possible while\nmaintaining almost perfect factual correctness.1\nWe address the above challenges by decom-\nposing crawling into multiple sub-tasks, and han-\ndle each task using few-shot in-context learning\n(Brown et al., 2020). Explicitly, we do not fine-tune\na model, but instead manually design a prompt and\na few examples for each task, an approach recently-\nproven successful (Wei et al., 2022; Drozdov et al.,\n2022; Chowdhery et al., 2022; Khot et al., 2022).\nWe use the following sub-tasks (see Tab. 1 for the\nfull list and examples). First, given an entitye (e.g.,\nALAN TURING ), we generate the relations relevant\nfor e (e.g., EDUCATED AT , PLACE OF BIRTH ). Sec-\nond, for each entity e and relation r, we generate\nthe corresponding set of objects O and add to the\nKG triplets (e, r, o) for each o ∈O. For example,\nfor ALAN TURING and EDUCATED AT , we gener-\n1We note that there is a deeper philosophical aspect to\nthis issue, which is at the core of the field of epistemology.\nNamely, what does it mean for a model to “believe” a fact,\nas opposed to the model “knowing” a fact. Here we adopt a\n“dispositional” view of belief, whereby a belief corresponds\nto a statement by the model, and knowledge is a belief that is\ntrue in the world.\nate triplets with the objects KING ’S COLLEGE and\nSHERBORNE SCHOOL . To maintain high precision,\nwe prompt the model to emit “Don’t know”when-\never it is not confident about the target objects. All\nthe above outputs are generated through in-context\nlearning, where we use the WIKI DATA KG (Vran-\ndeˇci´c and Krötzsch, 2014) to construct in-context\nexamples. Don’t knowexamples are constructed by\nfinding true facts in WIKI DATA that are unknown\nto the LM. Finally, we increase recall by prompt-\ning the LM to generate paraphrases for entities and\nrelations, and use those to obtain additional triplets.\nWe test our approach with GPT-3\n(text-davinci-002) on 140 seed entities,\nand show that we can extract accurate KGs\n(∼82-92% precision) that contain a plausible\nnumber of facts per entity. Importantly, large LMs\nare not constrained to a predefined schema, and\nindeed our procedure with GPT-3 generates facts\noutside the schema of WIKI DATA, e.g., (B OSTON\nCELTICS , CHAMPIONSHIPS , 17).\nTo conclude, our contributions are: 1) Formulat-\ning the problem of crawling a KG from an LM, 2)\nPresenting a prompt-based approach that decom-\nposes the problem into multiple sub-tasks, and 3)\nEvaluating the approach with GPT-3, which leads\nto high-precision graphs.\n1857\n2 Problem Setup\nOur goal is to uncover the knowledge-base of a\ngiven LM. We represent a knowledge-base via a\nKG, which is a collection of triplets. Formally,\na KG is a graph G = (N, R, E), where N is a\nset of entities, R is a set of relations, and E is a\nset of subject-relation-object triplets (s, r, o) where\ns, o∈N and r ∈R.\nTo simplify the setup, we assume we are given\na “seed entity” around which we will expand the\ngraph (for example Fig. 1). Conceptually, we can\nalso let the LM generate seed entities, but we argue\nseed expansion is a more realistic scenario, where\na user is interested in a graph about a certain entity.\nEntities and relations are represented via strings\nand are not constrained to a given vocabulary (simi-\nlar to open information extraction. e.g., see V o and\nBagheri, 2017).\n3 Crawling KGs via Prompting\nThe core component of our approach is a proce-\ndure that takes an entity e, and extracts all relations\nassociated with it, and the corresponding objects.\nNamely, we expand the KG around this entity. We\ncan then recursively apply this procedure to further\nexpand the KG. We refer to this as ‘entity expan-\nsion’, and break it into two high-level steps:\n• Relation generation(Sec. 3.1): For an entity\ne, generate a set of relations R, where e is the\nsubject.\n• Object generation(Sec. 3.3-Sec. 3.4): Given\nthe entity e and the relation set R, find the corre-\nsponding objects. Namely, for each r ∈R, find\na list of entities O such that (e, r, o) is in the KG\nfor o ∈O. We consider lists since many rela-\ntions (e.g., CHILDREN ) potentially have multiple\ncorrect objects. Furthermore, we also consider\nthe case where the object corresponding to (e, r)\nis unknown to the model (e.g., the model does\nnot know who is the daughter of a given entity\ne). In this case we take O to be empty, and the\nedge is not added to the KG. This is crucial for\nmaintaining a high-precision KG.\nBoth steps are achieved via few-shot in-context\nlearning. Namely, we construct prompts with in-\ncontext examples (stay fixed throughout the pro-\ncess) that exhibit the desired behaviour (Tab. 1).\nTo improve recall, we employ an additional para-\nphrasing procedure (Sec. 3.2 and Sec. 3.5), which\ngenerates alternative strings for a given entity or re-\nlation. For example, the entityWILLIAM CLINTON\ncan be referred to as WILLIAM JEFFERSON CLIN -\nTON or BILL CLINTON , and the relation OCCU -\nPATION may be expressed as PROFESSION . Thus,\nwe run object and relation generation for all these\nvariants, and pool the results to construct the final\ngraph. Paraphrases are also obtained through the\nLM, without use of external knowledge. The entire\nflow is illustrated in Fig. 2, and we next elaborate\non each of the components.\n3.1 Relation Generation\nOur task is to generate a set of relations R for a\ngiven subject entity e. To achieve this, we lever-\nage WIKI DATA to construct in-context examples.\nSpecifically, we pick a list of WIKI DATA entities\ne1, . . . , eKr and for each entity ei, extract its set of\nWIKI DATA relations. This results in Kr in-context\nexamples for relation generation. We concatenate\nthe target entity to the in-context examples, feed\nthis prompt to the LM and use its output as the set\nR for e. Tab. 1 shows an example prompt. We note\nthat this generation process can produce relations\nthat are not included in the prompt, and are not part\nof WIKI DATA at all.2 Full prompt with in-context\nexamples is presented in Sec. B.1.\n3.2 Relation Paraphrasing\nA relation r may be described in multiple ways,\nand the LM might work better with some of these\nparaphrases (Jiang et al., 2021). Thus, we use a\nprocedure to obtain a set of paraphrases of r, de-\nnoted by P(r), and run all downstream crawling\ntasks for all strings in P(r).\nFor relation paraphrasing we find that in-context\nexamples are not necessary and an instruction\nprompt is sufficient. Tab. 1 shows a specific ex-\nample under the sub-task “Relation Paraphrasing”.\nSee Sec. A.1 for the three prompts and more tech-\nnical details.\n3.3 Object Generation\nOur next goal is, for each r ∈R, to generate a\nset of objects O such that (e, r, o) is in the KG\nfor all o ∈O. Importantly, we should also let the\nLM declare it does not know the object, and thus\nO would be empty. In this case, no edge will be\nadded to the output KG.\n2For example, when the subject is a sports team, the\nmodel repeatedly generated a relation regarding its MASCOT\nor LARGEST WIN , which are facts outside of WIKI DATA.\n1858\nSub-task Query Prompt Expected Output\nRelation\nGeneration\nPhilippines Q: René Magritte A: ethnic group, place of birth, place\nof death, sex or gender, spouse, country of citizenship,\nmember of political party, native language, place of\nburial, cause of death, residence, family name, given\nname, manner of death, educated at, field of work, work\nlocation, represented by Q: Stryn A: significant event,\nhead of government, country, capital, separated from\nQ: Philippines A:\nleader name #\ncctld # capital\n# calling code\nPure Object\nGeneration\nBarack Obama\n# child\nQ: Monte Cremasco # country A: Italy Q: Johnny Depp #\nchildren A: Jack Depp # Lily-Rose DeppQ: Wolfgang Sauseng\n# employer A: University of Music and Performing Arts\nVienna Q: Barack Obama # child A:\nSasha Obama #\nMalia Obama\nDK Object\nGeneration\nQueen\nElizabeth\nII # date of\ndeath\nQ: Heinrich Peters # occupation A: Don’t know Q: Monte\nCremasco # country A: Italy Q: Ferydoon Zandi # place of\nbirth A: Don’t know Q: Hans Ertl # sportA: mountaineering\nQ: Queen Elizabeth II # date of death A:\nDon’t know\nSubject\nParaphrasing\nAlan Turing Alan Turing is also known as: The father of\ncomputing\nRelation\nParaphrasing\nnotable work ’notable work’ may be described as a work of ’great\nvalue’ or a work\nof ’importance’\nTable 1: The full list of sub-tasks in our approach, where for each sub-task we provide its name, a query, a\ncorresponding prompt, and the expected output. In ‘DK Object Generation’ the prompt declares in one of the\nin-context examples that the model does not know the place of birth of Ferydoon Zandi, since querying for it leads\nto a wrong answer (the query with the wrong answer isn’t shown).\nWe first explain prompt construction without\nthe use of “Don’t Know”output, and refer to this\nas “Pure Object Genration”. We take Ko entities\ne1, . . . , eKo from WIKI DATA. For each entity ei,\nwe choose one of its relations ri, and all the objects\nOi for this entity-relation pair in WIKI DATA. This\ncreates Ko examples for object generation. Similar\nto relation generation, the target entity-relation pair\nis concatenated to the Ko examples, and the list\nof objects is parsed from the generated LM out-\nput (see exact format in Tab. 1, under the sub-task\n“Pure Object Generation”, and the full prompt with\nin-context examples in Sec. B.2). Recall that for\neach relation, we have multiple paraphrases. To\nmaintain high precision, we only accept objects\nthat were generated by at least two realizations of\nthe relation.\n3.4 Learning to Output“Don’t Know”\nA key desideratum for KGs is high precision,\nnamely the facts in the graph should be correct\nwith high probability. Towards this end, we want\nto prompt the LM to output “Don’t Know”(DK)\nfor facts where it is likely to make an error.3\n3A model might make an error because it is not confident\nabout the answer, or because its training data contains false\nfacts. In this work, we are agnostic to this distinction and our\nBut how do we know what the model does not\nknow? To capture this, we find cases where the\nLM outputs erroneous facts, and use these to con-\nstruct in-context examples with a DK target. For\nexample, suppose we run ‘Pure Object Generation’\nwith e = BILL CLINTON and r = CHILDREN and\nthe model outputs O = KLAY THOMPSON . We\ndeduce that the model does not know who Clin-\nton’s children are, and therefore, can add the exam-\nple ei = BILL CLINTON , ri = CHILDREN , oi =\nDon’t knowto the prompt. In other words, we find\nexamples where oi is Don’t knowthrough cases\nwhere the model errs on its predicted objects. We\nthen construct a prompt with a total of Kdk exam-\nples, half of which are failure cases where with\noi = Don’t knowand the other half are correct\npredictions. We refer to this as “DK Object Gener-\nation”. See the corresponding row in Tab. 1 and the\nfull prompt with in-context examples in Sec. B.3.\n3.5 Subject Paraphrasing\nSimilar to relations, an entity e may have several\nnames, and it may be easier for the LM to complete\nthe triplet (e, r,?) with one of these. Thus, we\ntake a paraphrasing approach to extend an entity\nname e into a set P(e). The procedure is identical\nprompt’s goal is to encourage generation of correct outputs.\n1859\nSubject \nParaphrasing\nRelation \nGeneration\n…\nRelation \nParaphrasing\nDK Object \nGeneration\nBarack Obama \n# a person’s \nhusband or wife\nFigure 2: An illustration of the full method for crawling a subgraph (LMCRAWL ), starting from BARACK OBAMA\nas the subject, until obtaining the triplet (BARACK OBAMA , SPOUSE , MICHELLE OBAMA ).\nto relation paraphrasing (Sec. 3.2), except we use\na single prompt instructing the LM to complete\nthe sentence “s is also known as”, where s is the\nsubject. To increase the number of paraphrases, we\nsample from the model three times, resulting in up\nto three paraphrases.\nBoth here and in Relation Paraphrasing\n(Sec. 3.2), the LM occasionally generates nonsen-\nsical paraphrases. Nevertheless, the DK method\nhandles those cases well, outputting \"Don’t know\"\nfor most of them. Thus, we argue that paraphras-\ning combined with DK emission is an effective\napproach for controlling recall and precision.\n3.6 LMCRAWL\nFig. 2 shows the application of the complete\npipeline (which we refer to as LMCRAWL ) for\nthe entity BARACK OBAMA . First, we obtain all\nparaphrases for e (Sec. 3.5). Then, we extract all\nrelations for these (Sec. 3.1). Next, we paraphrase\nrelations (Sec. 3.2). Finally, we extract the known\nobjects for these relations (Sec. 3.3-Sec. 3.4).\n4 Experimental Setup\nAs mentioned in Sec. 3, we use WIKI DATA\n(publicly available) in constructing the in-context\nprompts. The number of in-context examples is\nKr = 7, Ko = 8, Kdk = 10.\nAdditionally, we use WIKI DATA to select seed\nentities for evaluating our approach. For these\nseeds, we consider the task of constructing KGs\naround the corresponding entities.\nWe split the seed entities into a validation set\n(20 entities), which is used to make design choices\n(e.g., choosing prompt format), and a test set (120\nentities), which is used only for the final evaluation.\nFor the development set, we manually chose 20\nentities from WIKI DATA. These included women\nand men with various professions, cities, countries,\nand various cultural entities such as movies and\nbooks. We also aimed to reprsent both head and\ntail entities in this list.\nTo construct our test set, we defined 25 specific\nworld-entities related categories, which we refer to\nas the test categories. Some of these were more\nspecific, such as AI Researchers, and some are\nmore general, such as Scientists (see Table.6 for\nthe full list). We chose 4 seeds out of each cate-\ngory as follows. We first sorted the set of entities\nof each group based on the number of WIKI DATA\nfacts associated with them (we view this count as\nan approximate measure of popularity). Then, we\nrandomly sampled two entities out of the full list,\nand an additional two out of the first 1000. Intu-\nitively, the first two represent tail entities, while the\nother two represents head ones. Thus we ended\nup with 100 seed entities (i.e., 4 different entities\nout of each of the 25 different subgroups). We re-\nfer to these as the main test set(see Tab. 6). We\ncreated an additional test set of 20 entities that is\nmeant to contain very popular entities. Its entities\nwere randomly sampled out of a set of size 1000,\nwhich was manually constructed by choosing 40\nvery well-known entities (i.e., that all people would\nknow) from each of the 25 test categories.\nAll 140 entities were not used in the construction\nof any of the prompts in Sec. 3. Tab. 2 shows the\nfull list of validation and head test entities.\nEvaluation metrics Given an entity s, our entity\nexpansion process returns a knowledge graph G,\nthat contains the entity s, other entities and rela-\ntions between them.\n1860\nDev Seeds Head Test Seeds\nABBA Aristotle\nAlan Turing Canada\nAngela Merkel Celine Dion\nAugustin-Louis Cauchy China\nBarack Obama Emanuel Macron\nBob Dylan Franz Kafka\nBoston Celtics Grease\nDavid Bowie Hamlet\nDiana, Princess of Wales Jacinda Ardern\nEike von Repgow Lionel Messi\nInglourious Basterds Little Women\nMarble Arch Manchester United F.C.\nMarie Curie Margaret Hamilton\nMikhail Bulgakov Michelangelo\nMoby-Dick Mike Tyson\nPablo Picasso Oprah Winfrey\nParis Rosalind Franklin\nPhilippines Steven Spielberg\nRachel Carson Serena Williams\nShahar Pe’er The Rolling Stones\nTable 2: List of all validation and head test seeds.\nIdeally, we want to compare G to a ground\ntruth graph that results from expanding the entity\ns. Given such a graph, we could measure preci-\nsion and recall over the gold and predicted sets\nof triplets. However, using large LMs to generate\ngraphs leads to several challenges. First, there is\nno ground-truth graph. While we could presum-\nably use the WIKI DATA graph, we found that it is\nmissing many correct facts predicted by the LM. In\nfact, improving coverage is a key motivation for our\nwork! Second, facts may be reworded in several\nequivalent ways, rendering comparison between\nWIKI DATA graphs and predicted graphs difficult.\nTo circumvent these challenges, we use the fol-\nlowing notions of precision and recall.\n• Precision: To estimate precision we conducted\nboth manual and automatic evaluations (the au-\ntomatic approach was more scalable). For the\nmanual evaluation we simply tried to validate\neach of the generated facts by manually browsing\nhighly trustful web sources (Google, Wikipedia,\netc.) to check if the fact is true. The automatic\nevaluation approach was implemented as follows.\nIn order to check the correctness of a given pre-\ndicted triplet (e, r, o), we issue a query contain-\ning (e, r) to Google search, and search whether\no appears in the result. We limit the result to first\n40 words which are not HTML labels or URL\nlinks. If it does, we assume the triplet is correct.\n4 See Sec. 5.3 for an accuracy estimation of the\n4This paragraph typically contains either an “answer box”\nor some summary of the first result page, in case there is no\nanswer box.\nautomatic method.\nManual evaluation was done for all the head test\nset graphs, as well as all the 1-hop graphs of\nthe main test set. Additionally, we performed\nmanual evaluation for 20% randomly sampled\ntriplets from the 2-hop graphs (altogether, the\ntotal portion of manually labeled facts from each\ngraph was ∼30%). The rest of the triplets were\nautomatically evaluated.\n• Recall: Estimating recall is not possible since\nwe do not have access to the true ground truth\ngraph. Moreover, using WIKI DATA graph size as\nan estimate for the number of true facts will be\nmisleading since it has low coverage in general,\nand high variancein terms of coverage for differ-\nent entities. Thus, we simply report the number\nof verified triplets in our KG. In other words,\nwe report recall without the denominator. We\nrefer to this as # of facts. This practice is similar\nto open information extraction (V o and Bagheri,\n2017), where it is impossible to know the set of\nall true facts and thus the convention is to report\nthe number of generated facts only.\nImplementation details As the LM in our exper-\niments, we used the OpenAI text-davinci-002\nmodel. We experiment with both greedy decoding\nand sampling 3 outputs per query (temperature 0.8).\nWe generate graphs with either a single expansion\nstep or two expansion steps, recursively expanding\nentities found in the first step. After a graph is gen-\nerated, we remove duplicates by iterating through\nthe facts and removing a fact if the token-wise F1\nbetween it and another fact is higher than 0.85.\nBase Model and AblationsThe simplest version\nof our model includes only ’Relation Generation’\n(Sec. 3.1) and ’Pure Object Generation’ (Sec. 3.3),\nwithout the “Don’t Know”and paraphrasing com-\nponents. We refer to this version as Pure-Greedy\nand Pure-Sampling, depending on the decoding\nused (see Sec. 4). In other model variants, we use\nDK to refer to using ‘DK Object Generation’ in-\nstead of ‘Pure Object Generation’. Additionally,\nSP and RP refer to adding ‘Subject Paraphrasing’\nand ‘Relation Paraphrasing’ respectively.\n5 Results\nWe next report results showing that our expansion\nmethod is able to generate meaningful knowledge\nsubgraphs, when expanding seed entities.\n1861\nMain Test Set Head Test Set\none-hop two-hop one-hop two-hop\nPrecision # of Facts Precision # of Facts Precision # of Facts Precision # of Facts\nPure-Greedy 54.6 ± 8.2 6 .2 ± 2.8 43.4 ± 6.1 26 .1 ± 5.5 80.3 ± 8.4 14 .4 ± 3.9 62.1 ± 7.3 82 .3 ± 15.4\nLMCRAWL 83.3 ± 7.9 5 .4 ± 1.1 82.0 ± 7.5 21 .4 ± 4.7 91.5 ± 11.4 11 .0 ± 4.6 90.9 ± 4.9 61 .2 ± 25.1\nTable 3: Averaged results across all 100 main testseeds (left), as well as all the 20 head testones (right).\nExample graph: We begin with an illustrative\nexample for the graph of the seed entity ALAN\nTURING . Fig. 1 shows a subset of the two-hop\nextracted graph in this case. It can be seen that all\nfacts are sensible, except for the fact that the field\nof Computer Science is named after Alan Turing\n(although he is certainly one of its fathers). See\nalso Figs. 4 and 5 for additional example graphs.\nResults on the Main Test set:Tab. 3 reports\naveraged results of the Pure-Greedy base model\nand LMCRAWL across the 100 main test seeds.\nWe observe that precision of Pure-Greedy is too\nlow to be useful for a KG – 54.6% for 1-hop graphs\nand 43.4% for 2-hop graphs. Conversely, precision\nwith LMCRAWL is much higher: 83.3% for 1-\nhop graphs and 82.0% for 2-hop graphs. While we\nsuffer a small hit in ‘# of facts’, the sizes of KGs\noutput by our approach are quite reasonable.\nResults on the Head Test set:Tab. 3 reports\naveraged results of the Pure-Greedy base model\nand LMCRAWL across the 20 head test seeds.\nSpecifically, we achieve precision of 91.5% while\napplying LMCRAWL for 1-hop graphs, and for\n2-hop we have 90.9%. It can be seen that both\nprecision and number of facts in this case are higher\nthan in the main test set. This suggests that either it\nis easier to extract facts from the LM about popular\nentities, or that the LM indeed encodes more facts\nfor these (see Sec. 5.2 for further analysis).\n5.1 Ablations\nNext, we examine the contribution of each compo-\nnent in our final approach on the validation set.\nThe Effect of Don’t Know Generation:The\ngoal of allowing the model to output “Don’t Know”\nis to improve precision. Tab. 4 and 5 show results\nfor the model without using DK prompting (inPure\nrows) as well as with (DK rows) for both sampling\nand greedy decoding. In both cases, the DK op-\ntion leads to much higher precision, but reduces\nthe number of generated facts. However, we later\nrecover some of these lost facts using subject and\nrelation paraphrasing.\nMethod Precision # of Facts\nPure-Sampling 64.9 ± 20.2 22 .2 ± 9.7\nPure-Greedy 77.5 ± 17.4 12 .5 ± 6.0\nDK-Sampling 71.4 ± 19.9 17 .7 ± 9.4\nDK-Greedy 82.9 ± 16.0 10 .2 ± 5.9\n+RP 80.9 ± 17.0 12 .7 ± 5.4\n+SP 80.6 ± 17.0 12 .2 ± 7.0\nLMCRAWL 88.3 ± 8.2 13 .0 ± 5.9\nTable 4: Averaged results over the 20 validation seed\n(one-hop). DK: “Don’t know”. SP: Subject Paraphras-\ning. RP: Relation Paraphrasing.\nMethod Precision # of Facts\nPure-Sampling 40.0 ± 9.5 224 .0 ± 81.1\nPure-Greedy 55.9 ± 9.7 87 .8 ± 39.7\nDK-Sampling 54.7 ± 8.6 144 .0 ± 83.5\nDK-Greedy 72.4 ± 7.5 45 .8 ± 30.3\nLMCRAWL 86.4 ± 6.1 69 .8 ± 52.9\nTable 5: Averaged results across all 20 validation seeds\n(two-hop). DK: “Don’t know”. SP: Subject Paraphras-\ning. RP: Relation Paraphrasing.\nThe Effect of Paraphrasing: Tab. 4 shows re-\nsults without the paraphrasing component in the\nDK-Greedy row. Both paraphrasing techniques,\nRP and SP, separately increase coverage, while\ncausing a minimal hit to precision. Interestingly,\ncombining RP and SP leads to improvements in\nboth precision and coverage for 1-hop and 2-hop\ngraphs (Tab. 4, 5).\n5.2 Coverage vs. Entity Frequency\nThe frequency of entities on the Web is highly\nskewed. That is, some entities appear many times,\nwhile others are rare. We expect this will be re-\nflected in the number of facts extracted for these\nentities. Indeed, on WIKI DATA, head entities usu-\nally have many more facts compared to tail entities.\nHere, we ask whether a similar phenomenon exists\nin our predicted KGs.\nFig. 3 shows the number of facts generated for\na depth-1 graph by LMCRAWL for all entities of\ntype PERSON , as a function of the number of facts\nthat appear in the corresponding depth-1 WIKI -\n1862\nDATA graph of the same seed. Clearly, there is high\ncorrelation (correlation coefficient is 0.61) between\nthe number of extracted facts and entity frequency\non WIKI DATA. This is rather surprising and en-\ncouraging since our procedure does not make any\nuse of entity frequency, and head and tail entities\nare expanded in exactly the same way.\nFigure 3: The # of tripletsextracted by LMCRAWL as\na function of the # of tripletsin WIKI DATA, for the set\nof validation entities of type PERSON .\n5.3 Precision is Possibly Underestimated\nOur automatic approach for evaluating precision\nuses Google search (see Sec. 4). We view this\nas a conservative estimate of precision, since a\nfact judged as true via this mechanism is highly\nlikely to be true. Conversely, a true fact might\nnot be verified due to search or string matching\nissues. To quantify this, we sampled 500 generated\nfacts from Pure-Greedyand LMCRAWL that were\njudged to be incorrect through Google search, as\nwell as 500 that were judged to be correct. We\nmanually inspected them and found that 4.1% of\nthe triplets that the automatic approach has labeled\nas correct, are actually wrong, while 22% of the\ntriplets that the automatic approach has labeled\nto be incorrect, are true (few demonstrations are\npresented in Sec. D). Exact estimation of precision\nwould require full manual annotation, which we\navoided to minimize costs.\n6 Related Work\nPretrained LMs are at the heart of recent NLP\nresearch and applications. As mentioned earlier,\nPetroni et al. (2019) and other works have observed\nthat LMs contain rich factual knowledge. We elab-\norate on other relevant works below.\nKnowledge-base construction. KG construc-\ntion typically involves both manual and automated\naspects. For example, popular KBs such as Word-\nNet (Fellbaum, 2020), ConceptNet (Speer et al.,\n2017) and WIKI DATA (Vrandeˇci´c and Krötzsch,\n2014) were constructed by heavily relying on man-\nual effort, gathering knowledge from humans. To\nreduce such manual labor, automated information\nextraction (IE) methods have been extensively de-\nveloped (Yates et al., 2007; Fader et al., 2011; An-\ngeli et al., 2015; V o and Bagheri, 2017). Knowl-\nedge in LMs is a fairly recent topic of interest, and\nhas mostly focused on probing for specific facts\n(Petroni et al., 2019; Razniewski et al., 2021).\nMost similar to our work are Hao et al. (2022),\nwho also extract KGs from LMs, However, they\nrequire defining the relations of interest through\nexamples before crawling, while our specific goal\nis to start with a seed entity and allow the LM\nto determine the relevant relations. Another rele-\nvant recent work is Alivanistos et al. (2022) who\nalso use in-context learning to extract a KG from\nGPT3. But they also assume relations are provided,\nwhereas a key aspect of our approach is generating\nthe relations.\nTo the best of our knowledge, ours is the first\nwork to construct a knowledge graph via extracting\nknowledge directly from LMs, using only one seed\nentity (and no other given relations or entities).\nQuantifying Uncertainty in LMs.Factual cor-\nrectness in LMs has attracted recent interest, be-\ncause it is a crucial requirement for LM applica-\nbility. In this context, some works have studied\nselective question answering, where LMs avoid an-\nswering particular questions (Varshney et al., 2022).\nOther works have considered calibration in LMs\n(Jiang et al., 2021; Desai and Durrett, 2020),\nFinally, recent works have investigated whether\nmodels can express their certainty on output facts,\neither in words or by producing the probability of\ncertainty (Lin et al., 2022; Kadavath et al., 2022).\nA key aspect of our approach is the use of a “Don’t\nknow” mechanism, which is related to this line of\nwork since it lets the LM declare its certainty as\npart of the output. Unlike Kadavath et al. (2022),\nwe do so in the context of crawling a KG and via\nin-context learning (as opposed to fine-tuning).\n7 Conclusion\nUnderstanding large LMs is a key part of modern\nNLP, as they are used across the board in NLP\napplications. In particular, it is important to under-\n1863\nstand the body of knowledge these models possess,\nso it can be used and revised as needed, thereby\navoiding factual errors and biases. In this work\nwe present an important step towards this goal by\nextracting a structured KB from an LM.\nThere are many possible exciting extensions for\nour work. The first is to expand it to a larger graph\ncorresponding to more expansion hops. This would\nrequire many more calls to an API, which at present\nis also costly, and it would be important to develop\nmore cost-effective approaches. Second, we have\nintroduced several approaches to controlling the\nprecision and recall of the proposed model, but\ncertainly more can be envisioned. For example,\nwe can introduce various consistency constraints to\nincrease precision (e.g., check that FATHER OF and\nCHILD OF are consistent in the generated graph).\nFinally, once a larger KG has been extracted, one\ncan query it to see how well it serves as a question\nanswering mechanism.\nOverall, we find the possibility of seamlessly\nconverting LMs to KGs for better interaction and\ncontrol to be an exciting and fruitful direction for\nfuture research.\nLimitations\nProducing the full internal KG out of an LM is still\na significant challenge. One challenge is cost (as\nnoted above). The other is error propagation issues.\nOnce the model makes a generation mistake in a\nparticular node of the generated graph, it may lead\nto an increasing number of mistakes during the\nnext generation steps, expanding from that node.\nThat is one of our main rationales for creating and\nevaluating only two-hop graphs, and not additional\nhops (although ideally, the real goal is to uncover\nthe full internal KG).\nOur automatic way of evaluating precision is\nonly approximate, which means our reported accu-\nracy numbers for 2-hop are an approximation of\ntrue precision (although we believe the true preci-\nsion is in fact higher, as discussed in the text).\nAnother challenge we do not address is under-\nstanding the source of knowledge inaccuracies. Are\nthey due to limitations of our model in extracting\nthe knowledge, or due to the LM not containing\nthese facts at all. This is certainly important to\nunderstand in order to improve knowledge repre-\nsentation in LMs. We are also aware to the fact\nthat since the generated graphs are not perfectly ac-\ncurate, they might contain disinformation and mis-\nleading facts. That would hopefully be improved\nby future research.\nFinally, the question whether we could have\ncome up with a better-reflecting “recall” metric\nthan the one we suggested is yet to be solved, as in\ngeneral it is still unclear how to measure knowledge\ncoverage.\nReferences\nDimitrios Alivanistos, Selene Báez Santamaría, Michael\nCochez, Jan-Christoph Kalo, Emile van Krieken,\nand Thiviyan Thanapalasingam. 2022. Prompting\nas probing: Using language models for knowledge\nbase construction. arXiv preprint arXiv:2208.11057.\nBadr AlKhamissi, Millicent Li, Asli Celikyilmaz, Mona\nDiab, and Marjan Ghazvininejad. 2022. A review on\nlanguage models as knowledge bases. arXiv preprint\narXiv:2204.06031.\nGabor Angeli, Melvin Jose Johnson Premkumar, and\nChristopher D Manning. 2015. Leveraging linguis-\ntic structure for open domain information extraction.\npages 344–354.\nKurt Bollacker, Colin Evans, Praveen Paritosh, Tim\nSturge, and Jamie Taylor. 2008. Freebase: a collabo-\nratively created graph database for structuring human\nknowledge. In Proceedings of the 2008 ACM SIG-\nMOD international conference on Management of\ndata, pages 1247–1250.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, et al. 2022. Palm: Scaling\nlanguage modeling with pathways. arXiv preprint\narXiv:2204.02311.\nShrey Desai and Greg Durrett. 2020. Calibra-\ntion of pre-trained transformers. arXiv preprint\narXiv:2003.07892.\nAndrew Drozdov, Nathanael Schärli, Ekin Akyürek,\nNathan Scales, Xinying Song, Xinyun Chen, Olivier\nBousquet, and Denny Zhou. 2022. Compositional\n1864\nsemantic parsing with large language models. arXiv\npreprint arXiv:2209.15003.\nAnthony Fader, Stephen Soderland, and Oren Etzioni.\n2011. Identifying relations for open information ex-\ntraction. In Proceedings of the 2011 conference on\nempirical methods in natural language processing,\npages 1535–1545.\nChristiane Fellbaum. 2020. WordNet: An Electronic\nLexical Database. MIT Press.\nLeo Gao, Stella Biderman, Sid Black, Laurence Gold-\ning, Travis Hoppe, Charles Foster, Jason Phang,\nHorace He, Anish Thite, Noa Nabeshima, Shawn\nPresser, and Connor Leahy. 2020. The Pile: An\n800gb dataset of diverse text for language modeling.\narXiv preprint arXiv:2101.00027.\nShibo Hao, Bowen Tan, Kaiwen Tang, Hengzhe Zhang,\nEric P Xing, and Zhiting Hu. 2022. Bertnet: Har-\nvesting knowledge graphs from pretrained language\nmodels. arXiv preprint arXiv:2206.14268.\nZhengbao Jiang, Jun Araki, Haibo Ding, and Graham\nNeubig. 2021. How can we know when language\nmodels know? on the calibration of language models\nfor question answering. Transactions of the Associa-\ntion for Computational Linguistics, 9:962–977.\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom\nHenighan, Dawn Drain, Ethan Perez, Nicholas\nSchiefer, Zac Hatfield Dodds, Nova DasSarma,\nEli Tran-Johnson, et al. 2022. Language models\n(mostly) know what they know. arXiv preprint\narXiv:2207.05221.\nTushar Khot, Harsh Trivedi, Matthew Finlayson, Yao\nFu, Kyle Richardson, Peter Clark, and Ashish Sab-\nharwal. 2022. Decomposed prompting: A modular\napproach for solving complex tasks. arXiv preprint\narXiv:2210.02406.\nStephanie Lin, Jacob Hilton, and Owain Evans. 2022.\nTeaching models to express their uncertainty in\nwords. arXiv preprint arXiv:2205.14334.\nFabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton\nBakhtin, Yuxiang Wu, and Sebastian Miller, Alexan-\nder H. Riedel. 2019. Language models as knowledge\nbases? EMNLP.\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring the\nlimits of transfer learning with a unified text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1–67.\nSimon Razniewski, Andrew Yates, Nora Kassner, and\nGerhard Weikum. 2021. Language models as or for\nknowledge bases. arXiv preprint arXiv:2110.04888.\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\nHow much knowledge can you pack into the parame-\nters of a language model? EMNLP.\nRobyn Speer, Joshua Chin, and Catherine Havasi. 2017.\nConceptnet 5.5: An open multilingual graph of gen-\neral knowledge. 31(1).\nYi Tay, Vinh Q Tran, Mostafa Dehghani, Jianmo Ni,\nDara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe\nZhao, Jai Gupta, et al. 2022. Transformer mem-\nory as a differentiable search index. arXiv preprint\narXiv:2202.06991.\nNeeraj Varshney, Swaroop Mishra, and Chitta Baral.\n2022. Investigating selective prediction approaches\nacross several tasks in iid, ood, and adversarial set-\ntings. arXiv preprint arXiv:2203.00211.\nDuc-Thuan V o and Ebrahim Bagheri. 2017. Open in-\nformation extraction. Encyclopedia with semantic\ncomputing and Robotic intelligence, 1(01):1630003.\nDenny Vrandeˇci´c and Markus Krötzsch. 2014. Wiki-\ndata: a free collaborative knowledgebase. Communi-\ncations of the ACM, 57(10):78–85.\nDenny Vrandeˇci´c and Markus Krötzsch. 2014. Wiki-\ndata: A free collaborative knowledge base. Commu-\nnications of the ACM, 57:78–85.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.\nChain of thought prompting elicits reasoning in large\nlanguage models. arXiv preprint arXiv:2201.11903.\nAlexander Yates, Michele Banko, Matthew Broadhead,\nMichael J Cafarella, Oren Etzioni, and Stephen Soder-\nland. 2007. Textrunner: open information extraction\non the web. In Proceedings of Human Language\nTechnologies: The Annual Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics (NAACL-HLT), pages 25–26.\nA Technical Details\nA.1 Relation-Paraphrasing\nWe use 3 different instructions that have been man-\nually constructed. If we denote a specific relation\nby r, then they are:\n• \"‘r’ may be described as\"\n• \"‘r’ refers to\"\n• \"please describe ‘r’ in a few\nwords:\"\nThat is, for every original relation which has been\ngenerated by the model, we perform additional\nthree different model calls, one with each of those\ninstruction prompts, resulting in three paraphrases.\nIf needed, we eliminate overlapping paraphrases.\n1865\nB Full Prompts\nB.1 Relation Generation\nQ: Javier Culson\nA: participant of # place of\nbirth # sex or gender # coun-\ntry of citizenship # occupation\n# family name # given name # edu-\ncated at # sport # sports disci-\npline competed in\nQ: René Magritte\nA: ethnic group # place of birth\n# place of death # sex or gender\n# spouse # country of citizenship\n# member of political party # na-\ntive language # place of burial\n# cause of death # residence #\nfamily name # given name # manner\nof death # educated at # field\nof work # work location # repre-\nsented by\nQ: Nadym\nA: country # capital of # coordi-\nnate location # population # area\n# elevation above sea level\nQ: Stryn\nA: significant event # head of\ngovernment # country # capital #\nseparated from\nQ: 1585\nA: said to be the same as # fol-\nlows\nQ: Bornheim\nA: head of government # country #\nmember of # coordinate location\n# population # area # elevation\nabove sea level\nQ: Aló Presidente\nA: genre # country of origin #\ncast member # original network\nB.2 Pure Object Generation\nQ: Kristin von der Goltz #\nmother\nA: Kirsti Hjort\nQ: Monte Cremasco # country\nA: Italy\nQ: Johnny Depp # children\nA: Jack Depp # Lily-Rose Depp\nQ: Theodor Inama von Sternegg\n# place of birth\nA: Augsburg\nQ: Wolfgang Sauseng # employer\nA: University of Music and Per-\nforming Arts Vienna\nQ: Hans Ertl # sport\nA: mountaineering\nQ: Nicolas Cage # sibling\nA: Christopher Coppola # Marc\nCoppola\nQ: Manfred Müller # occupation\nA: Catholic priest\nB.3 DK Object Generation\nQ: Heinrich Peters # occupation\nA: Don’t know\nQ: Monte Cremasco # country\nA: Italy\nQ: Nicolas Cage # sibling\nA: Christopher Coppola # Marc\nCoppola\nQ: Hans Ertl # sport\nA: mountaineering\nQ: Klaus Baumgartner # work lo-\ncation\nA: Don’t know\nQ: Ruth Bader Ginsburg # educated\nat\nA: Cornell University # Harvard\nLaw School # Columbia Law School\nQ: Ferydoon Zandi # place of\nbirth\nA: Don’t know\n1866\nQ: Wolfgang Sauseng # employer\nA: University of Music and Per-\nforming Arts Vienna\nQ: Apayao # head of government\nA: Don’t know\nQ: Kristin von der Goltz #\nmother\nA: Don’t know\nC Main Test Set\nTable 6 provides our main test, which includes 100\ndifferent seeds - 4 from each of our predefined\nentity group categories.\nD Automatic Precision Evaluation\nAs noted in the main text, the automatic precision\nevaluation method (i.e., the one based on Google\nsearch) may sometimes fail. Some of the failure\ncases are: (a) Inexact string matching. For example\n(BOSTON CELTICS , LEAGUE , N ATIONAL BAS-\nKETBALL ASSOCIATION (NBA)) is not verified,\nbut dropping (NBA) from the object would result\nin a successful verification. b) Paraphrases: For\nexample (MARBLE ARCH , COUNTRY , U NITED\nKINGDOM ) is not verified but changing the object\nto ENGLAND does succeed.\nE Additional Generated Graphs\nFigs. 4, 5 show additional example graphs (to the\none shown in Fig. 1), generated around the seed\nentities ANGELA MERKEL and BOSTON CELTICS\nrespectively.\n1867\nAngela \nMerkelPhD in quantum \nchemistry\nAngela Dorothea \nKasner\nChristian \nDemocratic Union\nJoachim \nSauer\nUniversity of \nLeipzig\nGerman \nAcademy\nChancellor \nof Germany\nHamburg\nJuly 17, \n1954\nGerman\nHumb\npolitics\nfemaleGermany\nBerlin\nEuropean \nPeople's Party\nKonrad \nAdenauer\nAnnegret \nKramp-Karren\nblack\nyellow\nFederal \nChairman\nJunge \nUnion\nChemistry\nOrder of Merit of \nthe Federal Republic\nUniversity of \nHamburg\nHumboldt \nUniversity of Berlin\nchemist\nJoachim\nspouse\ncountry of \ncitizenship\nnationality\nSauer\neducation\nofficial \nlanguage\n1409\ncountry\nLeipzig\nhttps://www.\nuni-leip\nheadquarters\nlearned \nsociety official \nlanguage\nwww.akadem\nienunion.de\ncapital of\nlocated in \nadministrative \nterritorial entity\ncountry\nFirst Mayor\ndate\nChristianity\ncapital\nleader \nname\nChancellor\n.de\nwww.bundesr\negierung\nPresident\nofficial \nlanguages\ndd.mm.yyyy\nDE\n+49\nThe European \nUnion\nhead of \ngovernment\nfederal parliamentary \nrepublic\nacademic \ndegree\nGiven \nname\npolitical \nparty\nspouse\nalma mater\noccupation\nplace of birth\nnationality\ndate of \nbirth\nField of \nwork\nsex or \ngender\ncountry of \ncitizenship\nnationality\neducated at\neducated at\neuropean \nparliament \ngroupfounded by\nheadquarters \nlocation deputy \nchairperson \nname\ncolours\ncolours\nleader \ntitle\nyouth \nwing\nfield of \nstudyawards \nreceived\nalma mater\nemployer\noccupation\ngiven \nname\neducated at\nfamily \nname\nindustry\nestablished in\narea \nserved\nwebsite\ntype of \ninstitution\nwebsite\nleader title\ntype\nreligionleader \ntitle 1\ninternet \ntld\ncctld\nwebsite\nleader \ntitle 1\ndate \nformat\niso 3166 \ncode\ncalling \ncode\nmembership \nin european \nunion\ngovernment \ntype\nFigure 4: An example of a generated depth-2 knowledge graph around the seed entity ANGELA MERKEL , using\nLMCRAWL(see Sec. 3). For readability, back edges from 2-depth nodes to 1-depth nodes are omitted.\nFigure 5: An example of a generated depth-2 knowledge graph around the seed entity BOSTON CELTICS , using\nLMCRAWL (see Sec. 3).\n1868\nCategories Sampled Seeds Categories Sampled Seeds\nPoliticians\nWang Zhi\nCathy Rogers\nKate Wilkinson\nCarles Campuzano\nProducers\nAlyssa Milano\nLenny Kravitz\nCarter Harman\nNancy Meyers\nScientists\nPavel Krotov\nMirra Moiseevna Gukhman\nAxel Delorme\nJesús Caballero Mellado\nActors\nJon V oight\nBoris Savchenko\nTolga Tekin\nVirginia Keiley\nBasketball\nTom McMillen\nPat Kelly\nSteve Moundou-Missi\nAllen Phillips\nSingers\nFreddie Mercury\nAngélique Kidjo\nCamille Thurman\nGiorgio Ronconi\nSports\nPeteca\nmotorcycle racing\nBasque pelota\nmountain bike trials\nBands\nSteve Miller Band\nHypocrisy\nAfro Kolektyw\nFrailty\nArtists\nBoˇrek Šípek\nLoriot\nGeorge William Wakefield\nGeorge Trosley\nTV Shows\nSecrets and Lies\nSpirited Away\nSuper Friends\nThe Life and Legend of Wyatt Earp\nPaintings\nPortrait of a Man\nLandscape\nThe foot washing\nThe King’s rival\nFoods/Restaurants\nTahu petis\nKandil simidi\nJim Block\nkubang boyo\nWriters\nAleksandr V olkov\nOsamu Tezuka\nElizaveta Sergeevna Danilova\nHenry Saint Clair Wilkins\nAnimals\ndonkey\njaguar\nmustang\nwhale\nBooks\nThe Green Berets\nAlfred de Musset\nDemain le capitalisme\nThe labyrinth\nPlants\nmaple\nrose\ncatmint\nconflower\nLandmarks\nTrafalgar Square\nMount Everest\nYosemite National Park\nMatterhorn\nArchitects\nLouis Kahn\nChristopher Wren\nMichael Graves\nDomenico Fontana\nCities\nVatican City\nCherdyn\nToulon\nMiljøXpressen\nDrummers\nAlan Montagu-Stuart-Wortley-Mackenzie\nMihály Deák\nJoey Kramer\nStephanie Eulinberg\nCountries\nNiger\nSweden\nEngland\nSingapore\nBiologists\nWangari Muta Maathai\nJames Rothman\nJoanna Siódmiak\nBarbara Bajd\nPhilosophy\nEvgeny Torchinov\nNikolay Umov\nMonica Giorgi\nLarysa Tsitarenka\nAI Researchers\nWilliam T. Freeman\nStephen Falken\nJoseph Weizenbaum\nRobby Garner\nMovies\nSpider-Man: Far from Home\nSonic the Hedgehog\nUnearthed\nAnother Man’s Poison\nTable 6: List of all main test set seeds\n1869",
  "topic": "Crawling",
  "concepts": [
    {
      "name": "Crawling",
      "score": 0.8385412693023682
    },
    {
      "name": "Computer science",
      "score": 0.8301191329956055
    },
    {
      "name": "Knowledge base",
      "score": 0.7495847940444946
    },
    {
      "name": "Knowledge graph",
      "score": 0.6107466220855713
    },
    {
      "name": "Natural language processing",
      "score": 0.5914117097854614
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5453429222106934
    },
    {
      "name": "Task (project management)",
      "score": 0.5047386884689331
    },
    {
      "name": "Precision and recall",
      "score": 0.4902632534503937
    },
    {
      "name": "Graph",
      "score": 0.47802433371543884
    },
    {
      "name": "Language model",
      "score": 0.4732190668582916
    },
    {
      "name": "Representation (politics)",
      "score": 0.46734315156936646
    },
    {
      "name": "Knowledge representation and reasoning",
      "score": 0.4499564468860626
    },
    {
      "name": "Recall",
      "score": 0.4300639033317566
    },
    {
      "name": "Entity linking",
      "score": 0.4105379581451416
    },
    {
      "name": "Information retrieval",
      "score": 0.36530277132987976
    },
    {
      "name": "Theoretical computer science",
      "score": 0.21179422736167908
    },
    {
      "name": "Linguistics",
      "score": 0.08449253439903259
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Anatomy",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    }
  ]
}