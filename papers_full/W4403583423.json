{
  "title": "Large Language Models and Empathy: Systematic Review",
  "url": "https://openalex.org/W4403583423",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2809724045",
      "name": "Vera Sorin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5092734868",
      "name": "Dana Brin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2572125234",
      "name": "Yiftach Barash",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2155772135",
      "name": "Eli Konen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4212339766",
      "name": "Alexander Charney",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2419298921",
      "name": "Girish Nadkarni",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2325035506",
    "https://openalex.org/W2890009290",
    "https://openalex.org/W1969676322",
    "https://openalex.org/W3003968294",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4378783467",
    "https://openalex.org/W4383501093",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W4399737726",
    "https://openalex.org/W4393867901",
    "https://openalex.org/W4401820448",
    "https://openalex.org/W4402350853",
    "https://openalex.org/W4386565997",
    "https://openalex.org/W4377024131",
    "https://openalex.org/W4383909162",
    "https://openalex.org/W4375859913",
    "https://openalex.org/W4364377826",
    "https://openalex.org/W4385572854",
    "https://openalex.org/W4380291947",
    "https://openalex.org/W4398765892",
    "https://openalex.org/W4389519275",
    "https://openalex.org/W4367310920",
    "https://openalex.org/W4378470708",
    "https://openalex.org/W4353016766",
    "https://openalex.org/W4384455669",
    "https://openalex.org/W4387232979",
    "https://openalex.org/W4388666107",
    "https://openalex.org/W4389518904",
    "https://openalex.org/W3195074401",
    "https://openalex.org/W4378908072",
    "https://openalex.org/W2168222508",
    "https://openalex.org/W2169547194",
    "https://openalex.org/W4376122030",
    "https://openalex.org/W2482116652",
    "https://openalex.org/W2027508313",
    "https://openalex.org/W2809745250",
    "https://openalex.org/W2801150160",
    "https://openalex.org/W4210702936"
  ],
  "abstract": "Background Empathy, a fundamental aspect of human interaction, is characterized as the ability to experience another being’s emotions within oneself. In health care, empathy is a fundamental for health care professionals and patients’ interaction. It is a unique quality to humans that large language models (LLMs) are believed to lack. Objective We aimed to review the literature on the capacity of LLMs in demonstrating empathy. Methods We conducted a literature search on MEDLINE, Google Scholar, PsyArXiv, medRxiv, and arXiv between December 2022 and February 2024. We included English-language full-length publications that evaluated empathy in LLMs’ outputs. We excluded papers evaluating other topics related to emotional intelligence that were not specifically empathy. The included studies’ results, including the LLMs used, performance in empathy tasks, and limitations of the models, along with studies’ metadata were summarized. Results A total of 12 studies published in 2023 met the inclusion criteria. ChatGPT-3.5 (OpenAI) was evaluated in all studies, with 6 studies comparing it with other LLMs such GPT-4, LLaMA (Meta), and fine-tuned chatbots. Seven studies focused on empathy within a medical context. The studies reported LLMs to exhibit elements of empathy, including emotions recognition and emotional support in diverse contexts. Evaluation metric included automatic metrics such as Recall-Oriented Understudy for Gisting Evaluation and Bilingual Evaluation Understudy, and human subjective evaluation. Some studies compared performance on empathy with humans, while others compared between different models. In some cases, LLMs were observed to outperform humans in empathy-related tasks. For example, ChatGPT-3.5 was evaluated for its responses to patients’ questions from social media, where ChatGPT’s responses were preferred over those of humans in 78.6% of cases. Other studies used subjective readers’ assigned scores. One study reported a mean empathy score of 1.84-1.9 (scale 0-2) for their fine-tuned LLM, while a different study evaluating ChatGPT-based chatbots reported a mean human rating of 3.43 out of 4 for empathetic responses. Other evaluations were based on the level of the emotional awareness scale, which was reported to be higher for ChatGPT-3.5 than for humans. Another study evaluated ChatGPT and GPT-4 on soft-skills questions in the United States Medical Licensing Examination, where GPT-4 answered 90% of questions correctly. Limitations were noted, including repetitive use of empathic phrases, difficulty following initial instructions, overly lengthy responses, sensitivity to prompts, and overall subjective evaluation metrics influenced by the evaluator’s background. Conclusions LLMs exhibit elements of cognitive empathy, recognizing emotions and providing emotionally supportive responses in various contexts. Since social skills are an integral part of intelligence, these advancements bring LLMs closer to human-like interactions and expand their potential use in applications requiring emotional intelligence. However, there remains room for improvement in both the performance of these models and the evaluation strategies used for assessing soft skills.",
  "full_text": null,
  "topic": "Preprint",
  "concepts": [
    {
      "name": "Preprint",
      "score": 0.8771522045135498
    },
    {
      "name": "Empathy",
      "score": 0.5417521595954895
    },
    {
      "name": "Psychology",
      "score": 0.45354169607162476
    },
    {
      "name": "Computer science",
      "score": 0.36029165983200073
    },
    {
      "name": "World Wide Web",
      "score": 0.2902657985687256
    },
    {
      "name": "Social psychology",
      "score": 0.1981998085975647
    }
  ]
}