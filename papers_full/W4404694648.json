{
  "title": "Adaptive Control of Retrieval-Augmented Generation for Large Language Models Through Reflective Tags",
  "url": "https://openalex.org/W4404694648",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2606389340",
      "name": "Chengyuan Yao",
      "affiliations": [
        "Hiroshima University"
      ]
    },
    {
      "id": "https://openalex.org/A2027194343",
      "name": "Satoshi Fujita",
      "affiliations": [
        "Hiroshima University"
      ]
    },
    {
      "id": "https://openalex.org/A2606389340",
      "name": "Chengyuan Yao",
      "affiliations": [
        "Hiroshima University"
      ]
    },
    {
      "id": "https://openalex.org/A2027194343",
      "name": "Satoshi Fujita",
      "affiliations": [
        "Hiroshima University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6779857854",
    "https://openalex.org/W6777615688",
    "https://openalex.org/W4393235306",
    "https://openalex.org/W4388994228",
    "https://openalex.org/W4386556635",
    "https://openalex.org/W4388778348",
    "https://openalex.org/W6845404407",
    "https://openalex.org/W4389518901",
    "https://openalex.org/W4385570777",
    "https://openalex.org/W4389519118",
    "https://openalex.org/W3094217983",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W3034156543",
    "https://openalex.org/W6885172986",
    "https://openalex.org/W4402671236",
    "https://openalex.org/W6809646742",
    "https://openalex.org/W6838865847",
    "https://openalex.org/W4319049323",
    "https://openalex.org/W4386365737",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W4301243929"
  ],
  "abstract": "While retrieval-augmented generation (RAG) enhances large language models (LLMs), it also introduces challenges that can impact accuracy and performance. In practice, RAG can obscure the intrinsic strengths of LLMs. Firstly, LLMs may become too reliant on external retrieval, underutilizing their own knowledge and reasoning, which can diminish responsiveness. Secondly, RAG may introduce irrelevant or low-quality data, adding noise that disrupts generation, especially with complex tasks. This paper proposes an RAG framework that uses reflective tags to manage retrieval, evaluating documents in parallel and applying the chain-of-thought (CoT) technique for step-by-step generation. The model selects the highest quality content for final output. The key contributions are as follows: (1) reducing hallucinations by focusing on high-scoring documents; (2) improving real-time performance through efficient retrieval; and (3) mitigating negative effects by filtering out irrelevant information using parallel generation and reflective tagging. These innovations aim to optimize RAG for more reliable, high-quality results.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6084929704666138
    },
    {
      "name": "Control (management)",
      "score": 0.49354708194732666
    },
    {
      "name": "Augmented reality",
      "score": 0.4165585935115814
    },
    {
      "name": "Information retrieval",
      "score": 0.3748128414154053
    },
    {
      "name": "Natural language processing",
      "score": 0.35162603855133057
    },
    {
      "name": "Artificial intelligence",
      "score": 0.29064592719078064
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I113306721",
      "name": "Hiroshima University",
      "country": "JP"
    }
  ],
  "cited_by": 6
}