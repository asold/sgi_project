{
    "title": "Graph transformer network with temporal kernel attention for skeleton-based action recognition",
    "url": "https://openalex.org/W4205947138",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A220594498",
            "name": "Yanan Liu",
            "affiliations": [
                "Yunnan University"
            ]
        },
        {
            "id": "https://openalex.org/A2095945326",
            "name": "Hao Zhang",
            "affiliations": [
                "Yunnan University"
            ]
        },
        {
            "id": "https://openalex.org/A2097891866",
            "name": "Dan Xu",
            "affiliations": [
                "Yunnan University"
            ]
        },
        {
            "id": "https://openalex.org/A2248357839",
            "name": "Kangjian He",
            "affiliations": [
                "Yunnan University"
            ]
        },
        {
            "id": "https://openalex.org/A220594498",
            "name": "Yanan Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2095945326",
            "name": "Hao Zhang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2097891866",
            "name": "Dan Xu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2248357839",
            "name": "Kangjian He",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W3128461539",
        "https://openalex.org/W3003375623",
        "https://openalex.org/W3109355347",
        "https://openalex.org/W2017049184",
        "https://openalex.org/W2583941031",
        "https://openalex.org/W3164569956",
        "https://openalex.org/W3134090706",
        "https://openalex.org/W2965970896",
        "https://openalex.org/W6677055838",
        "https://openalex.org/W2039051707",
        "https://openalex.org/W6785253800",
        "https://openalex.org/W6791951655",
        "https://openalex.org/W6684499055",
        "https://openalex.org/W6775780680",
        "https://openalex.org/W6800709229",
        "https://openalex.org/W6762621715",
        "https://openalex.org/W2963282966",
        "https://openalex.org/W6750290883",
        "https://openalex.org/W6779113007",
        "https://openalex.org/W3129366157",
        "https://openalex.org/W6662688328",
        "https://openalex.org/W6655757585",
        "https://openalex.org/W6681199532",
        "https://openalex.org/W6726569863",
        "https://openalex.org/W2143004591",
        "https://openalex.org/W4240042586",
        "https://openalex.org/W6743401523",
        "https://openalex.org/W6766113013",
        "https://openalex.org/W2792345332",
        "https://openalex.org/W6759373541",
        "https://openalex.org/W6746803634",
        "https://openalex.org/W6725062358",
        "https://openalex.org/W6740961951",
        "https://openalex.org/W6763223085",
        "https://openalex.org/W3135202376",
        "https://openalex.org/W6750401302",
        "https://openalex.org/W2026498605",
        "https://openalex.org/W6704520437",
        "https://openalex.org/W6730277886",
        "https://openalex.org/W6748947987",
        "https://openalex.org/W4200412139",
        "https://openalex.org/W6743928348",
        "https://openalex.org/W2966210862",
        "https://openalex.org/W6778983983",
        "https://openalex.org/W6768529555",
        "https://openalex.org/W6766161741",
        "https://openalex.org/W3113177135",
        "https://openalex.org/W4247924304",
        "https://openalex.org/W2962555132",
        "https://openalex.org/W2342662179",
        "https://openalex.org/W4302310419",
        "https://openalex.org/W3049455300",
        "https://openalex.org/W2981341885",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2963076818",
        "https://openalex.org/W2608982575",
        "https://openalex.org/W4255556797",
        "https://openalex.org/W2606294640",
        "https://openalex.org/W2803865273",
        "https://openalex.org/W2996835428",
        "https://openalex.org/W4312245820",
        "https://openalex.org/W2978927732",
        "https://openalex.org/W4292905395",
        "https://openalex.org/W4249914127",
        "https://openalex.org/W4230566620",
        "https://openalex.org/W3209485964",
        "https://openalex.org/W3148714641",
        "https://openalex.org/W4205445494",
        "https://openalex.org/W3138679477",
        "https://openalex.org/W2956928039",
        "https://openalex.org/W2619947201",
        "https://openalex.org/W3215030504",
        "https://openalex.org/W3009946848",
        "https://openalex.org/W3034999503",
        "https://openalex.org/W4247092244",
        "https://openalex.org/W3093441220",
        "https://openalex.org/W2944006115",
        "https://openalex.org/W3197400233",
        "https://openalex.org/W3006529527",
        "https://openalex.org/W3092336341",
        "https://openalex.org/W3094502228",
        "https://openalex.org/W3039153384",
        "https://openalex.org/W1924770834",
        "https://openalex.org/W2802577319"
    ],
    "abstract": "Skeleton-based human action recognition has caused wide concern, as skeleton data can robustly adapt to dynamic circumstances such as camera view changes and background interference thus allowing recognition methods to focus on robust features. In recent studies, the human body is modeled as a topological graph, and the graph convolution network (GCN) is used to extract features of actions. Although GCN has a strong ability to learn spatial modes, it ignores the varying degrees of higher-order dependencies that are captured by message passing. Moreover, the joints represented by vertices are interdependent, and hence incorporating an attention mechanism to weigh dependencies is beneficial. In this work, we propose a kernel attention adaptive graph transformer network (KA-AGTN), which models the higher-order spatial dependencies between joints by the graph transformer operator based on multihead self-attention. In addition, the Temporal Kernel Attention (TKA) block in KA-AGTN generates a channel-level attention score using temporal features, which can enhance temporal motion correlation. After combining the two-stream framework and adaptive graph strategy, KA-AGTN outperforms the baseline 2s-AGCN by 1.9% and by 1% under X-Sub and X-View on the NTU-RGBD 60 dataset, by 3.2% and 3.1% under X-Sub and X-Set on the NTU-RGBD 120 dataset, and by 2% and 2.3% under Top-1 and Top-5 and achieves the state-of-the-art performance on the Kinetics-Skeleton 400 dataset.",
    "full_text": null
}