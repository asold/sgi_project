{
    "title": "Leveraging a Large Language Model to Assess Quality-of-Care: Monitoring ADHD Medication Side Effects",
    "url": "https://openalex.org/W4395066886",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5065959135",
            "name": "Yair Bannett",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A5014625545",
            "name": "Fatma Güntürkün",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A5063020021",
            "name": "Malvika Pillai",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A5033407891",
            "name": "Jessica E. Herrmann",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A5095852039",
            "name": "Ingrid Luo",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A5076336163",
            "name": "Lynne C. Huffman",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A5052105714",
            "name": "Heidi M. Feldman",
            "affiliations": [
                "Stanford University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2111758455",
        "https://openalex.org/W2044837527",
        "https://openalex.org/W1966976587",
        "https://openalex.org/W2753059860",
        "https://openalex.org/W4387327155",
        "https://openalex.org/W2023582980",
        "https://openalex.org/W2780265295",
        "https://openalex.org/W2285134444",
        "https://openalex.org/W2162012775",
        "https://openalex.org/W4213383170",
        "https://openalex.org/W3022158429",
        "https://openalex.org/W2055180595",
        "https://openalex.org/W2401054881",
        "https://openalex.org/W1965751712",
        "https://openalex.org/W2055218182",
        "https://openalex.org/W2605144596",
        "https://openalex.org/W3037405958",
        "https://openalex.org/W2116810060",
        "https://openalex.org/W2769851464",
        "https://openalex.org/W4207057807",
        "https://openalex.org/W3217152367",
        "https://openalex.org/W3049243480",
        "https://openalex.org/W4285681477",
        "https://openalex.org/W2105501846",
        "https://openalex.org/W4391057582",
        "https://openalex.org/W4391755461",
        "https://openalex.org/W4239301040",
        "https://openalex.org/W4294214983"
    ],
    "abstract": "Objective: To assess the accuracy of a large language model (LLM) in measuring clinician adherence to practice guidelines for monitoring side effects after prescribing medications for children with attention-deficit/hyperactivity disorder (ADHD). Methods: Retrospective population-based cohort study of electronic health records. Cohort included children aged 6-11 years with ADHD diagnosis and ≥2 ADHD medication encounters (stimulants or non-stimulants prescribed) between 2015-2022 in a community-based primary healthcare network (n=1247). To identify documentation of side effects inquiry, we trained, tested, and deployed an open-source LLM (LLaMA) on all clinical notes from ADHD-related encounters (ADHD diagnosis or ADHD medication prescription), including in-clinic/telehealth and telephone encounters (n=15,593 notes). Model performance was assessed using holdout and deployment test sets, compared to manual chart review. Results: The LLaMA model achieved excellent performance in classifying notes that contain side effects inquiry (sensitivity= 87.2%, specificity=86.3/90.3%, area under curve (AUC)=0.93/0.92 on holdout/deployment test sets). Analyses revealed no model bias in relation to patient age, sex, or insurance. Mean age (SD) at first prescription was 8.8 (1.6) years; patient characteristics were similar across patients with and without documented side effects inquiry. Rates of documented side effects inquiry were lower in telephone encounters than in-clinic/telehealth encounters (51.9% vs. 73.0%, p&lt;0.01). Side effects inquiry was documented in 61% of encounters following stimulant prescriptions and 48% of encounters following non-stimulant prescriptions (p&lt;0.01). Conclusions: Deploying an LLM on a variable set of clinical notes, including telephone notes, offered scalable measurement of quality-of-care and uncovered opportunities to improve psychopharmacological medication management in primary care.",
    "full_text": " 1\nLeveraging a Large Language Model to Assess Quality-of-Care: Monitoring ADHD \nMedication Side Effects \nYair Bannett, MD, MS a; Fatma Gunturkun, PhD b; Malvika Pillai, PhD c,d; Jessica E. Herrmann, MS e; \nIngrid Luo, MSb; Lynne C. Huffman, MDa; Heidi M. Feldman, MD, PhDa \n \nAffiliations: aDivision of Developmental-Behavioral Pediatrics, Stanford University School of \nMedicine, Stanford, CA, USA; bStanford Quantitative Sciences Unit, Stanford, CA, USA;  \ncVeterans Affairs Palo Alto Health Care System, Palo Alto, California, USA; dBiomedical \nInformatics Research Center, Stanford University School of Medicine, Stanford, California, \nUSA; eStanford University School of Medicine, Stanford, California, USA. \nAddress correspondence to: Yair Bannett, Developmental-Behavioral Pediatrics, Stanford \nUniversity School of Medicine, 3145 Porter Drive, Palo Alto, CA, 94304 \n(ybannett@stanford.edu), phone: 650-725-8995, fax: 650-725-8351. \nShort Title: Large language model for quality of ADHD care \nConflict of Interest Disclosures (includes financial disclosures): The authors have no conflicts \nof interest to disclose. \nFunding/Support: This work was supported by the Stanford Maternal and Child Health \nResearch Institute and by the National Institute of Mental Health of the National Institutes of \nHealth under grant number K23MH128455 (Dr. Bannett).  \nRole of Funder/Sponsor: The content is solely the responsibility of the authors and does not \nnecessarily represent the official views of the National Institutes of Health. Funders did not have \nany part in design and conduct of the study; collection, management, analysis, and interpretation \nof the data; preparation, review, or approval of the manuscript; and decision to submit the \nmanuscript for publication. \nData Availability statement: The entire code for the pipeline and training of the large language \nmodel, which can be used to reproduce our study in other settings, is available in the GitHub \nrepository at https://github.com/ybannett/NLP_ADHD_SEI. The datasets generated and analyzed \nin the current study contain protected patient health information and are therefore not publicly \navailable; the data will be shared on reasonable request to the corresponding author. \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n 2\nContributors Statement: \n \nDr. Yair Bannett conceptualized and designed the study, defined and coordinated data extraction, \nparticipated in chart reviews and annotation, participated in data analyses and drafting the \nmanuscript, and reviewed and revised the manuscript. \nDrs. Fatma Gunturkun and Malvika Pillai participated in study design, carried out the data \nanalyses and model training, participated in drafting the manuscript, and reviewed and revised \nthe manuscript. \nMs. Jessica Herrmann participated in development of annotation guidelines, manual chart \nreviews and annotation of clinical notes, interpretation of the data, and critically reviewed and \nrevised the manuscript. \nMs. Ingrid Luo participated in data analyses and model training, and critically reviewed and \nrevised the manuscript. \nDrs. Lynne Huffman and Heidi Feldman participated in conceptualization of the study, \ninterpretation of the data, and critically reviewed and revised the manuscript. \nAll authors approved the final manuscript as submitted and agree to be accountable for all \naspects of the work.  \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 3\nABSTRACT  \n \nObjective: To assess the accuracy of a large language model (LLM) in measuring clinician \nadherence to practice guidelines for monitoring side effects after prescribing medications for \nchildren with attention-deficit/hyperactivity disorder (ADHD). \nMethods: Retrospective population-based cohort study of electronic health records. Cohort \nincluded children aged 6-11 years with ADHD diagnosis and >2 ADHD medication encounters \n(stimulants or non-stimulants prescribed) between 2015-2022 in a community-based primary \nhealthcare network (n=1247). To identify documentation of side effects inquiry, we trained, \ntested, and deployed an open-source LLM (LLaMA) on all clinical notes from ADHD-related \nencounters (ADHD diagnosis or ADHD medication prescription), including in-clinic/telehealth \nand telephone encounters (n=15,593 notes). Model performance was assessed using holdout and \ndeployment test sets, compared to manual chart review. \nResults: The LLaMA model achieved excellent performance in classifying notes that contain \nside effects inquiry (sensitivity= 87.2%, specificity=86.3/90.3%, area under curve \n(AUC)=0.93/0.92 on holdout/deployment test sets). Analyses revealed no model bias in relation \nto patient age, sex, or insurance. Mean age (SD) at first prescription was 8.8 (1.6) years; patient \ncharacteristics were similar across patients with and without documented side effects inquiry. \nRates of documented side effects inquiry were lower in telephone encounters than in-\nclinic/telehealth encounters (51.9% vs. 73.0%, p<0.01). Side effects inquiry was documented in \n61% of encounters following stimulant prescriptions and 48% of encounters following non-\nstimulant prescriptions (p<0.01).   \nConclusions: Deploying an LLM on a variable set of clinical notes, including telephone notes, \noffered scalable measurement of quality-of-care and uncovered opportunities to improve \npsychopharmacological medication management in primary care.\n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 4\nINTRODUCTION \n \nAccurate measurement of clinical practice is a necessary and critical component of \nimproving healthcare quality and health outcomes in a learning health system.1 However, \ntraditional methods for capturing clinical practice, such as chart reviews, are time consuming, \nlabor intensive, and unconducive to real-time improvement efforts.2,3 Large language models are \na type of artificial intelligence that offers opportunities to capture clinical practice at scale by \nautomatically analyzing free-text information from clinical notes in the electronic health records \n(EHR). Here, we focus on a highly prevalent childhood condition – Attention \nDeficit/Hyperactivity Disorder (ADHD) - which has long-standing clinical practice guidelines, \nas a test case for leveraging a large language model to assess quality-of-care. \nADHD is a prevalent neurodevelopmental disorder, estimated to affect 10% of US children.\n4 \nMost children with ADHD are treated by their primary care pediatrician (PCP).5,6 PCPs \nfrequently prescribe medications, including stimulants and non-stimulants, as part of the \nmanagement of ADHD. Evidence-based clinical practice guidelines for primary care \nmanagement of ADHD, published and distributed by the American Academy of Pediatrics \n(AAP), encourage PCPs to monitor benefits and side effects when prescribing medications.\n7-9 \nThe few studies that have assessed PCP adherence to AAP practice guidelines for ADHD \nmedication management analyzed available EHR structured data (e.g., prescriptions, encounter \ndates) to assess medication prescription patterns and timely follow-up of patients.10,11 Studies \nthat aimed to gather more detailed information, such as evidence in the EHR narrative text that \nclinicians monitored medication benefits and side effects, have been limited in scope due to the \nneed for labor-intensive chart reviews.11,12  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 5\nThe current national quality metrics that aim to capture high-quality ADHD medication \nmanagement – Healthcare Effectiveness Data and Information Set (HEDIS) measures - are \nclaims-based metrics that are readily available for analysis and reporting at scale.13 However, \nthese metrics only capture the frequency of in-office follow up of children prescribed ADHD \nmedications. The HEDIS metrics have no evidence base (i.e., guidelines do not include a \nrecommended frequency of follow-up) and they do not capture any guideline-based treatment \nrecommendations, such as monitoring for medication side effects.14 Furthermore, a focus on \ninformation abstracted only from in-office visits may significantly underestimate the frequency \nof encounters. Current medication management in primary care takes place in multiple \ncommunication routes with families, including through virtual (telehealth) encounters, telephone \nencounters, and secure messaging systems. Indeed, one study assessing primary care medication \nmanagement of ADHD found that the frequency of any type of follow-up, including \ncommunication with patients over the phone or email – not in-person follow-up alone – was \nassociated with improved ADHD symptoms.\n15  \nIn this study, we aimed to assess the accuracy of an open-source large language model in \nmeasuring the extent to which primary care clinicians document inquiring about ADHD \nmedication side effects in clinical notes from in-clinic/telehealth and telephone encounters. If \nsuccessful, such a model can become an integral part of robust quality measurement, \nhighlighting avenues for near real-time improvement efforts leading to improved patient \noutcomes. \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 6\nMETHODS \n \nWe present our study in accordance with the MINimum Information for Medical AI \nReporting (MINIMAR) framework and the Strengthening the Reporting of Observational Studies \nin Epidemiology (STROBE) reporting guidelines.16,17 This study was approved by the Stanford \nUniversity School of Medicine Institutional Review Board. \nSetting and population \nPackard Children’s Health Alliance (PCHA) is a community-based pediatric healthcare \nnetwork in the Northern California, affiliated with Stanford Children’s Health and Lucile \nPackard Children’s Hospital. PCHA has 25 pediatrics primary care clinics, grouped into 11 \npractices.  \nStudy design, data sources, and cohort selection \nThis was a retrospective population-based cohort study. We extracted structured and \nunstructured (free text) EHR data (2015-2022) from 11 community primary care practices of all \nclinic/telehealth/telephone ADHD-related encounters for patients 6-11 years. We defined an \nADHD-related encounter as an encounter with an ADHD visit diagnosis or with an ADHD \nmedication prescribed, including stimulants (methylphenidate and amphetamines) and non-\nstimulants (alpha-agonists and atomoxetine). ADHD diagnoses and prescriptions for ADHD \nmedications were identified based on codes and concepts from the Observational Medical \nOutcomes Partnership Common Data Model (OMOP CDM), an approach that allows for \ncommon format and nomenclature across databases (see e-supplement for list of codes). \nSince we focused on documentation of medication side effects, the study cohort included \npatients with >\n2 ADHD medication encounters (i.e., encounters in which the PCP prescribed \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 7\nstimulants or non-stimulants). The final study cohort comprised 1247 patients (see \nsupplementary Figure 1 for the study flowchart). \nStructured EHR data variables \nWe used structured data in the EHR to describe the following patient characteristics: patient \nage (at encounter of interest), sex, race/ethnicity (Asian/Non-Hispanic, Black/Non-Hispanic, \nHispanic, White/Non-Hispanic, Other/Non-Hispanic, Unknown), and medical insurance at first \nADHD medication encounter (private/public). In our analyses, we separated patients into two \nage groups (6-7 or 8-11 years at the time of the first prescription) based on our clinical \nexperience that patients under 8 years have a higher rate of ADHD medication side effects than \nthose who are 8 years and older. \nManual chart review and annotation of clinical notes  \nThe primary outcome of interest was the rate of documentation inquiring about medication \nside effects in clinical notes of ADHD-related encounters occurring within 3 months of an \nADHD medication prescription, starting from the second medication encounter onwards per \npatient, when monitoring of medication side effects is expected. Side effects inquiry included \ndocumentation of either absence of side effects (e.g., “no weight loss”) or presence of side \neffects (e.g., “reduced appetite”). We included clinical notes from all in-clinic, telehealth, and \ntelephone ADHD-related encounters conducted after an ADHD medication was first prescribed \n(4369 in-clinic/telehealth notes and 11,224 telephone notes; total notes n=15,593).  \nTo create a “ground truth” for documentation of side effects inquiry, we developed \nannotation guidelines used by two clinicians (YB, JH) who performed independent chart review \nand annotation of a sample of clinical notes using the CLAMP software.\n18 We sampled and \nannotated 2-26 clinical notes per patient from medication encounters (including in-\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 8\nclinic/telehealth and telephone encounters) for a sample of 119 patients (n=501 notes). Inter-\nannotator agreement (IAA) was assessed using the Cohen’s kappa statistic.19 After confirming \nIAA=0.86 for the first 84 notes, the annotators divided the annotation of the remaining notes \n(n=417).  \nLarge language model development and train/test split \nWe developed a binary classification pipeline based on the open-source Large Language \nModel Meta AI, trained on 13 billion parameters (LLaMA13B), to classify notes as containing or \nnot containing documentation of side effects inquiry (see e-methods supplement describing \nmodel architecture and optimization). Figure 1 illustrates the model training and deployment \nworkflow. The annotated set of 501 notes was subdivided with an 80-20 split into train (n=411) \nand holdout test (n=90) sets. The train set was used for model development and hyperparameter \ntuning while the holdout test set was set aside to evaluate model performance compared to \nground truth labels using various metrics including sensitivity, specificity, and area under the \nreceiver operating characteristic curve (AUC). Model thresholds were selected to maximize \nsensitivity and minimize the false negative rate on the training set because we wanted to avoid \nwrongly classifying notes to suggest clinicians as not adhering to practice guidelines when they \nactually did. We report 95% confidence intervals (CI) for AUC, which captures the \ndiscrimination power of the model and is not influenced by threshold selection. After confirming \nacceptable model performance on the holdout test set, we deployed the model on the remaining \nunannotated notes from all ADHD-related encounters for the study cohort (deployment test set, \nn=15,184). We then sampled and annotated 366 notes (IAA=0.93) to assess model performance \nin the deployment test set. The code is available via Github at \nhttps://github.com/ybannett/NLP_ADHD_SEI\n.  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 9\nError and fairness analysis \nFor the error analysis, the misclassified notes in the holdout and deployment test sets \nwere reviewed to understand model errors and potential reasoning behind misclassifications. For \nthe fairness analysis, we utilized the classification parity approach to assess whether model \noutcomes are roughly equal across several patient subgroups divided by patient attributes that \nincluded insurance type, sex, and age at first prescription.\n20 The fairness analysis was completed \nto rule out model bias that may perpetuate disparities in care, if such disparities exist.21,22 We did \nnot examine race/ethnicity data in the fairness analysis due to a large percentage of missing data \nand co-linearity between insurance type and race/ethnicity in our data.\n23 \nStatistical analysis \nContinuous variables were summarized by the mean and standard deviation, and \ncategorical variables were presented as counts and percentages. The balance of demographic \ncharacteristics between the groups was assessed using the absolute standardized differences \n(ASD). ASD values of 0.2, 0.5, and 0.8 correspond to small, medium, and large differences \nbetween the groups, respectively. A two-sided proportion test with a significance level of 0.05 \nwas used to compare the proportion of encounters with side effect inquiries between 1) telephone \nencounters and in-clinic/telehealth encounters, and 2) encounters associated with stimulant \nprescriptions, non-stimulant prescriptions, or both. Only race/ethnicity had missing data (29.5%). \nAll analyses were conducted using Python version 3.11.5. \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 10\nRESULTS \nModel performance \nThe LLaMA model achieved excellent performance in classifying notes that contain side \neffects inquiry, as compared to ground truth labels. In the holdout test set (n=90 notes), the \nmodel achieved sensitivity of 87.2%, specificity of 86.3%, and an AUC of 0.93 (CI\n95%: 0.88-\n0.99). In the deployment test set (n=366 notes), the model achieved sensitivity of 87.2%, \nspecificity of 90.3%, and an AUC of 0.92 (CI\n95%: 0.89-0.94). \nError analysis \nIn an error analysis, we investigated potential reasons for model misclassifications. False \npositive classifications included documentations that were not clearly related to the prescribed \nADHD medication (e.g., review of systems) or documented side effects from other prescribed \nmedications (e.g., medication for acne). False negative classifications included abbreviated \ndocumentation (e.g., “follow up add meds weight loss”) or documentation of non-specific \nsymptoms (e.g., “giggly and disruptive on new med”). \nFairness analysis \nAs illustrated in Figure 2, the model exhibited similar AUC values (presented with 95% \nCI) across different patient subgroups, including patient age group, sex, and insurance type.  \nModel findings and study cohort \nThe study cohort included 1247 patients aged 6-11 years who had at least two primary \ncare visits in which an ADHD medication was prescribed by the PCP. Cohort characteristics by \ndocumentation of side effects inquiry (yes/no), based on model classifications, are displayed in \nTable 1. Of 1247 patients, 72.6% (n=917) were first prescribed medications when they were 8-\n11 years of age and 73.9% (n=922) were male. The cohort primarily consisted of White/Non-\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 11\nHispanic patients (n=549, 44.0%) or Unknown race/ethnicity patients (n=365, 29.3%). Most \npatients were privately insured (n=929, 74.5%). Based on model classification, in 85.6% of \npatients (n=1067) the PCP documented inquiring about medication side effects in at least one \nADHD-related encounter (starting at the second medication encounter per patient). Rates of \ndocumented side effect inquiries were higher for patients with public insurance compared to \nthose with private insurance (90.6% vs 83.9%, absolute standardized difference=0.24), while no \ndifferences were observed with regard to age group, sex, or race/ethnicity. \nModel findings by primary care practice, encounter modality, and medication type \nOverall, side effects inquiry was documented in 59.8% (n=5884) of ADHD-related \nencounters and was highly variable across primary care practices (range 14-74% of encounters, \nFigure 3). More than 50% of ADHD-related encounters were completed by telephone in 7 out of \n11 practices. However, the proportion of telephone encounters with documented side effects \ninquiry was significantly lower at 52.0% compared to 72.9% for in-clinic/telehealth encounters \n(p<0.01), with high inquiry rates by telephone observed in only two practices. When examining \nencounters by the type of ADHD medication prescribed, side effects inquiry was documented in \n61.1% (n= 5440) of ADHD-related encounters within three months after stimulants were \nprescribed and in 48.2% (n=197) of encounters after non-stimulants were prescribed (p<0.01, \nFigure 4). Side effects inquiry was documented in 46.8% (n=247) of encounters after both \nstimulants and non-stimulants were prescribed. \n \nDISCUSSION \nIn this study, we have shown that deploying a large language model (LLM) on different \ntypes of clinical notes can effectively assess adherence to AAP practice guidelines for \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 12\nmedication management of children with ADHD, a highly prevalent condition. Fairness analysis \ndid not indicate any evidence of model bias. By deploying this model, we uncovered specific \ntargets for improvement in PCP medication management, including under-utilization of \ntelephone encounters to monitor medication side effects, and low rates of side effects \nmanagement when prescribing non-stimulants. \nThe high LLM performance rates established in this study demonstrate that LLMs offer \nan accurate and reliable method of analyzing the vast amount of unstructured EHR data that \nrepresents the documentation trail of current pediatric care, which includes significant between-\nvisit management of chronic conditions (e.g., telephone encounters, secure messaging). Our \nfindings are promising in that LLMs allow efficient data mining and interpretation of large \nvolumes of clinical data that, thus far, have been inaccessible through existing chart extraction \nmethodologies. Additionally, the automaticity and speed of LLMs offers the opportunity to \ndevelop near real-time feedback through dashboards for clinicians and health organizations on \ntheir current care – an effective method to improve clinical practice.\n24 \nWhen applying a large language model to assess documentation of clinical care, it is \ncritical to assess AI model bias given its potential to perpetuate health disparities.21,22 We \ntherefore incorporated a fairness analysis into our study. In this case, we confirmed that the \nmodel performance did not differ significantly across patient subgroups, including patient age \ngroup, sex, and insurance type.  \nSeveral targets for quality improvement were uncovered by deploying the LLM on all \nclinical notes. While all practices had a high utilization of telephone visits for ADHD medication \nmanagement, only two of the 11 practices used telephone visits to regularly inquire about \nmedication side effects. This finding serves as a learning opportunity for other practices. A \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 13\nsimple intervention that adopts a standardized medication refill form, currently used in the two \npractices that documented side effects inquiry in most telephone encounters, can have a \nsignificant positive effect on the quality of medication management. Another finding was the \nlower rates of side-effects inquiry in children prescribed non-stimulants, as compared to \nstimulants. Here too, an intervention that targets potential knowledge gaps related to side effects \nprofile of these less frequently prescribed medications can promote high quality care.  \nThis study complements our previous study that focused on clinician adherence to AAP \nguidelines in recommending non-pharmacological behavioral treatment for young children with \nADHD, in which we demonstrated the use of large language models in the evaluation of quality-\nof-care for children with ADHD.\n25 These two studies are the first, to our knowledge, that provide \nobjective support for the successful use of artificial intelligence (AI) to provide a comprehensive \nevaluation of ADHD management, a prevalent neurobehavioral condition that is predominantly \nmanaged in primary care. Future implementation of such algorithms, could allow primary care \nclinicians to receive feedback on between-visit management (e.g., telephone encounters for \nmedication management) and to receive real-time decision support (e.g., prompts for inquiring \nabout specific side effects) – two areas of need in primary care that have been recently identified \nas areas that could benefit from AI.\n26 \nLimitations \nOur cohort identification relied on multiple medication prescriptions with a primary \nindication for ADHD. Although this approach facilitates standardized implementation in any \nhealthcare system, it introduces some level of misclassification error. Our assessment of quality-\nof-care in this study relies on clinician documentation in the EHR. It is possible that, in some \ncases, clinicians inquired about side effects without documenting their inquiries in the EHR. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 14\nFurthermore, our study focused on medication management of ADHD by PCPs, and we did not \nhave information on prescriptions provided to children outside of the examined network (e.g., by \nchild psychiatrists). Because we were interested in measuring clinician adherence to guidelines, \nour outcome included any mention of side effects inquiry; we did not have information on rates \nof side effects presence and absence. We are currently examining the use of another model to \nanswer this separate research question and use case. Finally, although the study was conducted in \na large network of primary care practices with a diverse population (including 15% Hispanic, \nsimilar to the US census), its generalizability and the accuracy of model classifications needs to \nbe assessed in other healthcare networks.  \n \nCONCLUSION \nGiven the high prevalence of ADHD and the potential harm that can be caused to \nchildren and adolescents if psychopharmacological medication side effects are not considered \nand documented as part of clinical care, this study carries significant implications. By leveraging \nrecent advances in the ability of large language models to accurately classify large bodies of text, \nour novel approach offers an efficient way to assess the quality of ADHD medication \nmanagement. The rapid transformation of clinical data into knowledge can provide clinicians and \nhealthcare organizations with timely and actionable feedback. We are currently working to \nexpand this approach to include patient vitals data (i.e., weight, blood pressure, pulse) and \ndocumentation of patient care through the EHR secure messaging system, which were not \navailable in the dataset created for this study, representing an additional step towards a \ncomprehensive assessment of care for a large population of patients. Following replication of this \napproach in other healthcare systems, implementation of LLMs can contribute to enhancing \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 15\nevidence-based and equitable healthcare delivery for children with ADHD, ultimately improving \npatient outcomes.   \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 16\nAcknowledgments:  \nThis research used data and services provided by STARR, “STAnford medicine Research data \nRepository,” a clinical data warehouse containing live Epic data from Stanford Health Care \n(SHC), the Stanford Children’s Hospital (SCH), the University Healthcare Alliance (UHA) and \nPackard Children's Health Alliance (PCHA) clinics and other auxiliary data from Hospital \napplications such as radiology PACS. STARR platform is developed and operated by Stanford \nMedicine Research IT team and is made possible by Stanford School of Medicine Research \nOffice. We thank Packard Children’s Health Alliance and Stanford Research Information \nTechnology for their support and assistance in data acquisition and extraction.  \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 17\nReferences: \n1. Etheredge LM. A rapid-learning health system. Health Aff (Millwood). Mar-Apr \n2007;26(2):w107-18. doi:10.1377/hlthaff.26.2.w107 \n2. Zima BT, Mangione-Smith R. Gaps in quality measures for child mental health care: an \nopportunity for a collaborative agenda. Journal of the American Academy of Child and \nAdolescent Psychiatry. Aug 2011;50(8):735-7. doi:10.1016/j.jaac.2011.05.006 \n3. Schuster MA, Onorato SE, Meltzer DO. Measuring the Cost of Quality Measurement: A \nMissing Link in Quality Strategy. Jama. Oct 3 2017;318(13):1219-1220. \ndoi:10.1001/jama.2017.11525 \n4. Li Y, Yan X, Li Q, et al. Prevalence and Trends in Diagnosed ADHD Among US \nChildren and Adolescents, 2017-2022. JAMA Netw Open. Oct 2 2023;6(10):e2336872. \ndoi:10.1001/jamanetworkopen.2023.36872 \n5. Visser SN, Bitsko RH, Danielson ML, et al. Treatment of Attention Deficit/Hyperactivity \nDisorder among Children with Special Health Care Needs. J Pediatr. Jun 2015;166(6):1423-\n30.e1-2. doi:10.1016/j.jpeds.2015.02.018 \n6. Albert M, Rui P, Ashman JJ. Physician Office Visits for Attention-deficit/Hyperactivity \nDisorder in Children and Adolescents Aged 4-17 Years: United States, 2012-2013. NCHS data \nbrief. Jan 2017;(269):1-8.  \n7. Clinical practice guideline: treatment of the school-aged child with attention-\ndeficit/hyperactivity disorder. Pediatrics. Oct 2001;108(4):1033-44.  \n8. Wolraich M, Brown L, Brown RT, et al. ADHD: clinical practice guideline for the \ndiagnosis, evaluation, and treatment of attention-deficit/hyperactivity disorder in children and \nadolescents. Pediatrics. Nov 2011;128(5):1007-22. doi:10.1542/peds.2011-2654 \n9. Wolraich ML, Hagan JF, Jr., Allan C, et al. Clinical Practice Guideline for the Diagnosis, \nEvaluation, and Treatment of Attention-Deficit/Hyperactivity Disorder in Children and \nAdolescents. Pediatrics. Oct 2019;144(4)doi:10.1542/peds.2019-2528 \n10. Bannett Y, Feldman HM, Gardner RM, et al. Attention-Deficit/Hyperactivity Disorder in \n2- to 5-Year-Olds: A Primary Care Network Experience. Acad Pediatr. Apr 28 \n2020;doi:10.1016/j.acap.2020.04.009 \n11. Epstein JN, Kelleher KJ, Baum R, et al. Variability in ADHD care in community-based \npediatrics. Pediatrics. Dec 2014;134(6):1136-43. doi:10.1542/peds.2014-1500 \n12. Gordon MK, Baum RA, Gardner W, et al. Comparison of Performance on ADHD \nQuality of Care Indicators: Practitioner Self-Report Versus Chart Review. Journal of attention \ndisorders. Aug 2020;24(10):1457-1461. doi:10.1177/1087054715624227 \n13. National Committee for Quality Assurance. Follow-up care for children prescribed \nADHD medication. Accessed October 24, 2019, Available at: http://www.ncqa.org\n.  \n14. Zima BT, Murphy JM, Scholle SH, et al. National quality measures for child mental \nhealth care: background, progress, and next steps. Pediatrics. Mar 2013;131 Suppl 1:S38-49. \ndoi:10.1542/peds.2012-1427e \n15. Epstein JN, Kelleher KJ, Baum R, et al. Specific Components of Pediatricians' \nMedication-Related Care Predict Attention-Deficit/Hyperactivity Disorder Symptom \nImprovement. Journal of the American Academy of Child and Adolescent Psychiatry. Jun \n2017;56(6):483-490.e1. doi:10.1016/j.jaac.2017.03.014 \n16. Hernandez-Boussard T, Bozkurt S, Ioannidis JPA, et al. MINIMAR (MINimum \nInformation for Medical AI Reporting): Developing reporting standards for artificial intelligence \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 18\nin health care. Journal of the American Medical Informatics Association : JAMIA. Dec 9 \n2020;27(12):2011-2015. doi:10.1093/jamia/ocaa088 \n17. Vandenbroucke JP, von Elm E, Altman DG, et al. Strengthening the Reporting of \nObservational Studies in Epidemiology (STROBE): explanation and elaboration. PLoS Med. Oct \n16 2007;4(10):e297. doi:10.1371/journal.pmed.0040297 \n18. Soysal E, Wang J, Jiang M, et al. CLAMP – a toolkit for efficiently building customized \nclinical natural language processing pipelines. Journal of the American Medical Informatics \nAssociation. 2017;25(3):331-336. doi:10.1093/jamia/ocx132 \n19. McHugh ML. Interrater reliability: the kappa statistic. Biochemia medica. \n2012;22(3):276-282.  \n20. Röösli E, Bozkurt S, Hernandez-Boussard T. Peeking into a black box, the fairness and \ngeneralizability of a MIMIC-III benchmarking model. Sci Data. Jan 24 2022;9(1):24. \ndoi:10.1038/s41597-021-01110-7 \n21. Czarnowska P, Vyas Y, Shah K. Quantifying Social Biases in NLP: A Generalization and \nEmpirical Comparison of Extrinsic Fairness Metrics. Transactions of the Association for \nComputational Linguistics. 2021;9:1249-1267. doi:10.1162/tacl_a_00425 \n22. Röösli E, Rice B, Hernandez-Boussard T. Bias at warp speed: how AI may contribute to \nthe disparities gap in the time of COVID-19. Journal of the American Medical Informatics \nAssociation. 2020;28(1):190-192. doi:10.1093/jamia/ocaa210 \n23. Bannett Y, Gardner RM, Huffman LC, et al. Continuity of Care in Primary Care for \nYoung Children With Chronic Conditions. Academic Pediatrics. 2023;23(2):314-321.  \n24. Ivers N, Jamtvedt G, Flottorp S, et al. Audit and feedback: effects on professional \npractice and healthcare outcomes. Cochrane Database Syst Rev. Jun 13 2012;(6):Cd000259. \ndoi:10.1002/14651858.CD000259.pub3 \n25. Pillai M, Posada J, Gardner RM, et al. Measuring quality-of-care in treatment of young \nchildren with attention-deficit/hyperactivity disorder using pre-trained language models. Journal \nof the American Medical Informatics Association. 2024;doi:10.1093/jamia/ocae001 \n26. Sarkar U, Bates DW. Using Artificial Intelligence to Improve Primary Care for Patients \nand Clinicians. JAMA Internal Medicine. 2024;doi:10.1001/jamainternmed.2023.7965 \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 19\nTables and Figures: \n \nTable 1. Characteristics of study cohort: Patients ages 6-11 years prescribed medications for \nADHD by a primary care pediatrician. \n  Overall  \n   \nN=1247  \nNo Side Effects \nInquiry  \nN=180  \nSide Effects \nInquiryb  \nN=1067  \nAbsolute \nStandardized \nDifferencec  \nAge at diagnosis, N (%)a          \n  6-7 years  342 (27.4) 37 (20.6) 305 (28.6) 0.18   8-11 years  905 (72.6) 143 (79.4) 762 (71.4) \nAge at 1st prescription, N (%)          \n  6-7 years  293 (23.5) 30 (16.7) 263 (24.6) 0.19   8-11 years  954 (76.5) 150 (83.3) 804 (75.4) \nSex (Male), N (%)  922 (73.9) 131 (73.6) 791 (74.1) 0.01 \nRace/Ethnicity, N (%)              \n  Asian /Non-Hispanic  74 (5.9) 9 (5.0) 65 (6.1) 0.05 \n  Black /Non-Hispanic  60 (4.8) 3 (1.7) 57 (5.3) 0.17 \n  Hispanic  190 (15.2) 30 (16.7) 160 (15.0) 0.05 \n  Other /Non-Hispanic   9 (0.7) 0 (0.0)   9 (0.8) 0.10 \n  White /Non-Hispanic  549 (44.0) 71 (39.4) 478 (44.8) 0.11 \n  Unknown  365 (29.3) 67 (37.2) 298 (27.9) 0.20 \nInsurance, N (%)        \n  Private  929 (74.5) 150 (83.3) 779 (73.0) 0.24   Public  318 (25.5)  30 (16.7) 288 (27.0) \naAge at first encounter with an ADHD diagnosis within the patient age range. \nbDocumented inquiry of side effects, as classified by the LLaMA model, in at least one ADHD-related \nencounter starting at the second time an ADHD medication was prescribed. \ncAbsolute Standardized Difference values of 0.2, 0.5, and 0.8 correspond to small, moderate, and large \ndifferences, respectively.  \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 20\nFigure 1. Model training, testing, and deployment. \n \nIAA = Inter-annotator agreement \n \n  \nA nnotations  by two \nclinicians (IA A: 0.86) for \nrandom sample of patients\n(n=120 patients; 527 notes)\nLLaMA\nTrain (80%) \n(n=419 notes)\n①\nHoldout Test (20%)\n(n=108 notes)\n②\nDeployment Notes\n(n=1143 patients; \n17319 notes)\n③\nDeployment Test\n(IAA: 0.93)\n(sample of n=400 notes)\n④\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 2 1\nFigure 2. Fairness analysis results. \n \nSE = side effects \n \n \n \n  \n1\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 2 2\nFigure 3. ADHD-related encounters with and without side effects (SE) inquiry by primary care \npractice.  \nSE = side effects; 'A' to 'K' represent 11 primary care practices sorted by number of ADHD-\nrelated encounters. \n \n \n \n  \n2\n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint \n 2 3\nFigure 4. ADHD-related encounters with and without side effects (SE) inquiry by medication \ntype.\nSE = side effects \n \n3\n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 24, 2024. ; https://doi.org/10.1101/2024.04.23.24306225doi: medRxiv preprint "
}