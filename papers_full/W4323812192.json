{
  "title": "Writing medical papers using large-scale language models: a perspective from the Japanese Journal of Radiology",
  "url": "https://openalex.org/W4323812192",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A48082429",
      "name": "Takeshi Nakaura",
      "affiliations": [
        "Kumamoto University"
      ]
    },
    {
      "id": "https://openalex.org/A1920219464",
      "name": "Shinji Naganawa",
      "affiliations": [
        "Nagoya University"
      ]
    },
    {
      "id": "https://openalex.org/A48082429",
      "name": "Takeshi Nakaura",
      "affiliations": [
        "Kumamoto University"
      ]
    },
    {
      "id": "https://openalex.org/A1920219464",
      "name": "Shinji Naganawa",
      "affiliations": [
        "Nagoya University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4315784554",
    "https://openalex.org/W4319083882",
    "https://openalex.org/W4317607715",
    "https://openalex.org/W4317390716",
    "https://openalex.org/W4318263917",
    "https://openalex.org/W4317853296"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)1 3\nJapanese Journal of Radiology (2023) 41:457–458 \nhttps://doi.org/10.1007/s11604-023-01408-z\nEDITORIAL\nWriting medical papers using large‑scale language models: \na perspective from the Japanese Journal of Radiology\nTakeshi Nakaura1 · Shinji Naganawa2\nPublished online: 10 March 2023 \n© The Author(s) under exclusive licence to Japan Radiological Society 2023\nAbbreviations\nLLM  Large-scale language model\nGPT  Generative pre-trained transformer\nIntroduction\nRecently, large-scale language models (LLMs) such as Gen-\nerative Pre-trained Transformer (GPT) have been attracting \nmuch attention due to their ability to achieve human-like \nperformance in tasks such as translation, text editing, and \narticle generation. However, there are mixed opinions on the \nuse of this technology in scientific writing. This is an Edito-\nrial comment on the development of LLM and its application \nto the writing of scientific papers, its problems, and whether \nit should be mentioned as the author.\nDevelopment of LLM\nThe current rapid development of LLMs began with a neural \nnetwork architecture called Transformer, published in 2017, \nwhich can capture relationships between words in a sentence \nby learning based on a scoring system called “Attention” [1]. \nGPT is a language model that extends Transformer and is \npre-trained on large text data sets and is capable of generat-\ning more human-like text as the scale increases from GPT-1, \nGPT-2, to GPT-3. ChatGPT is a chat application combin-\ning GPT-3 with reinforcement learning that was released \nby OpenAI in November 2022 and has now become such \na hot topic that it has been featured in various mainstream \nnews programs.\nLLM's ability to write scientific papers \nand the problems it faces\nRecently, ChatGPT was used to generate abstracts for \nresearch articles in leading medical journals and examined \nwhether researchers could distinguish them, and found \nthat 32% of the abstracts generated by ChatGPT were real \nabstracts, whereas 14% of real abstracts were mistakenly \nidentified as ChatGPT-generated abstracts [2]. At this point, \nChatGPT's paper writing ability seems to have reached a \nlevel close to that of humans. However, on the other hand, \nLLMs such as ChatGPT learn from a large amount of data \non the Internet including information that has not undergone \nscrutiny for accuracy, so there is a high possibility that it \nlearns scientifically incorrect information. Therefore, there \nis no guarantee that the correct content will be output by \nsuch LLMs. The following five issues have been identified as \npriorities for future research using such LLMs; maintaining \nhuman verification, creating rules for accountability, invest-\ning in truly open LLMs, reaping the benefits of LLMs for \nthe scientific paper writing, and broadening the discussion \n[3]. Specifically, there is an urgent need to establish rules for \nclarification of the use of LLM, evaluation of the text quality \nwritten by LLM, and establishment of copyright and ethical \nrules; however, these remain largely unfulfilled at this time.\nDescription of LLM use\nIn spite of the above problems, some papers have appeared \nin which ChatGPT is listed as an author, and it is said that \nthe establishment of rules for the use of LLMs is urgently \nneeded [4]. Currently, many argue that papers authored by \nLLMs do not meet authorship requirements because they \ncannot be held accountable as authors and LLMs cannot \n * Takeshi Nakaura \n kff00712@nifty.com\n1 Department of Diagnostic Radiology, Kumamoto University \nGraduate School of Medicine, 1-1-1 Honjo Chuo-ku, \nKumamoto 860-8556, Japan\n2 Department of Radiology, Nagoya University Graduate \nSchool of Medicine, Nagoya, Japan\n458 Japanese Journal of Radiology (2023) 41:457–458\n1 3\nagree to terms of use or content distribution rights for soft-\nware tools [5], and we also support this.\nAt this time, no firm conclusion has been reached as to \nthe extent to which the use of LLMs is acceptable. The Sci-\nence plans to change its editorial policies to prohibit the \nsubmission of English text produced by ChatGPT [6 ]. On \nthe other hand, the Nature does not completely prohibit the \nuse of LLMs, but strongly recommends that researchers \nusing LLM tools should document this use in the methods \nor acknowledgements sections [7 ]. We follow the Nature's \npolicy and recommend that if authors use the text as it is out-\nput by a large language model such as ChatGPT, it should be \ncarefully noted in the acknowledgements session. For exam-\nples, “ChatGPT was used for the English translation, which \nwas validated in detail by the authors. Or “ChatGPT was \nused to survey previous reports and to summarize them, the \nvalidity of which has been verified by the authors through \ncareful research of each original article.”\nConclusion\nThis paper has described the Japanese Journal of Radiol-\nogy editors' current opinions on writing papers using LLMs. \nPlease note that this field is in an evolving state of develop-\nment and that guidelines and legislation have not yet caught \nup with the area, so these opinions may change significantly \nin the future.\nDeclarations \nConflict of interest The authors declare that they have no conflict of \ninterest.\nReferences\n 1. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez \nAN, et al. Attention Is All You Need [Internet]. arXiv [cs.CL]. \n2017. http:// arxiv. org/ abs/ 1706. 03762.\n 2. Else H. Abstracts written by ChatGPT fool scientists. Nature. \n2023;20:423–423.\n 3. Eva AM, Bollen J, Zuidema W, Bockting CL. ChatGPT: five pri-\norities for research. Nature. 2023;614:224–6.\n 4. The AI writing on the wall. Nature machine intelligence. Nature \nPublishing Group; 2023;5:1.\n 5. Stokel-Walker C. ChatGPT listed as author on research papers: \nmany scientists disapprove. Nature. 2023;613:620–1.\n 6. Thorp HH. ChatGPT is fun, but not an author. Science. \n2023;379:313.\n 7. Tools such as ChatGPT threaten transparent science; here are our \nground rules for their use. Nature. 2023;613:612–612.\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Perspective (graphical)",
  "concepts": [
    {
      "name": "Perspective (graphical)",
      "score": 0.7030971050262451
    },
    {
      "name": "Computer science",
      "score": 0.49050062894821167
    },
    {
      "name": "Scale (ratio)",
      "score": 0.4683842957019806
    },
    {
      "name": "Medical physics",
      "score": 0.3767429292201996
    },
    {
      "name": "Data science",
      "score": 0.3731869161128998
    },
    {
      "name": "Medicine",
      "score": 0.2985175549983978
    },
    {
      "name": "Artificial intelligence",
      "score": 0.15872281789779663
    },
    {
      "name": "Cartography",
      "score": 0.075691819190979
    },
    {
      "name": "Geography",
      "score": 0.05932101607322693
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I96036126",
      "name": "Kumamoto University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I60134161",
      "name": "Nagoya University",
      "country": "JP"
    }
  ]
}