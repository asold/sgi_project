{
    "title": "Artificial Intelligence to Automate Health Economic Modelling: A Case Study to Evaluate the Potential Application of Large Language Models",
    "url": "https://openalex.org/W4391723611",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2486523368",
            "name": "Tim Reason",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1983992187",
            "name": "William Rawlinson",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2046090370",
            "name": "Julia Langham",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1986744770",
            "name": "Andy Gimblett",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2138684868",
            "name": "Bill Malcolm",
            "affiliations": [
                "Bristol-Myers Squibb (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A4214151112",
            "name": "Sven Klijn",
            "affiliations": [
                "Bristol-Myers Squibb (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2486523368",
            "name": "Tim Reason",
            "affiliations": [
                "European Framework Program Consulting (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A1983992187",
            "name": "William Rawlinson",
            "affiliations": [
                "European Framework Program Consulting (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A2046090370",
            "name": "Julia Langham",
            "affiliations": [
                "European Framework Program Consulting (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A1986744770",
            "name": "Andy Gimblett",
            "affiliations": [
                "European Framework Program Consulting (United Kingdom)"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3151002452",
        "https://openalex.org/W2170239385",
        "https://openalex.org/W2037809152",
        "https://openalex.org/W3039365472",
        "https://openalex.org/W4362597819",
        "https://openalex.org/W3197513570",
        "https://openalex.org/W4319656910",
        "https://openalex.org/W4324373918",
        "https://openalex.org/W4281483047",
        "https://openalex.org/W4293998609",
        "https://openalex.org/W4281250694",
        "https://openalex.org/W4221161695",
        "https://openalex.org/W4221143046",
        "https://openalex.org/W6855844941",
        "https://openalex.org/W1982967337",
        "https://openalex.org/W2596664472",
        "https://openalex.org/W4378803794",
        "https://openalex.org/W4282982239",
        "https://openalex.org/W2547303135",
        "https://openalex.org/W6925793365",
        "https://openalex.org/W4226102934",
        "https://openalex.org/W3048857296",
        "https://openalex.org/W4283703423",
        "https://openalex.org/W2953532875",
        "https://openalex.org/W4322621757",
        "https://openalex.org/W3206003576",
        "https://openalex.org/W4220902548",
        "https://openalex.org/W3198064442",
        "https://openalex.org/W3210293336",
        "https://openalex.org/W4382310450",
        "https://openalex.org/W4213127247",
        "https://openalex.org/W4226444494",
        "https://openalex.org/W4200234798",
        "https://openalex.org/W4366603405",
        "https://openalex.org/W4220970940",
        "https://openalex.org/W4225906434",
        "https://openalex.org/W2242464395"
    ],
    "abstract": null,
    "full_text": "Vol.:(0123456789)\nPharmacoEconomics - Open (2024) 8:191–203 \nhttps://doi.org/10.1007/s41669-024-00477-8\nORIGINAL RESEARCH ARTICLE\nArtificial Intelligence to Automate Health Economic Modelling: A Case \nStudy to Evaluate the Potential Application of Large Language Models\nTim Reason1 · William Rawlinson1 · Julia Langham1  · Andy Gimblett1 · Bill Malcolm2 · Sven Klijn3 \nAccepted: 1 February 2024 / Published online: 10 February 2024 \n© The Author(s) 2024\nAbstract\nBackground Current generation large language models (LLMs) such as Generative Pre-Trained Transformer 4 (GPT-4) have \nachieved human-level performance on many tasks including the generation of computer code based on textual input. This \nstudy aimed to assess whether GPT-4 could be used to automatically programme two published health economic analyses.\nMethods The two analyses were partitioned survival models evaluating interventions in non-small cell lung cancer (NSCLC) \nand renal cell carcinoma (RCC). We developed prompts which instructed GPT-4 to programme the NSCLC and RCC mod-\nels in R, and which provided descriptions of each model’s methods, assumptions and parameter values. The results of the \ngenerated scripts were compared to the published values from the original, human-programmed models. The models were \nreplicated 15 times to capture variability in GPT-4’s output.\nResults GPT-4 fully replicated the NSCLC model with high accuracy: 100% (15/15) of the artificial intelligence (AI)-generated \nNSCLC models were error-free or contained a single minor error, and 93% (14/15) were completely error-free. GPT-4 closely rep-\nlicated the RCC model, although human intervention was required to simplify an element of the model design (one of the model’s \nfifteen input calculations) because it used too many sequential steps to be implemented in a single prompt. With this simplification, \n87% (13/15) of the AI-generated RCC models were error-free or contained a single minor error, and 60% (9/15) were completely \nerror-free. Error-free model scripts replicated the published incremental cost-effectiveness ratios to within 1%.\nConclusion This study provides a promising indication that GPT-4 can have practical applications in the automation of health eco-\nnomic model construction. Potential benefits include accelerated model development timelines and reduced costs of development. \nFurther research is necessary to explore the generalisability of LLM-based automation across a larger sample of models.\nKey Points for Decision Makers \nGPT-4, a current generation large language model \n(LLM), automatically replicated two published health \neconomic models with high accuracy, based on instruc-\ntions about how the models should be designed and what \ninput values should be used.\nThis is a promising early indication that LLMs could \nbe used to automate building health economic models, \nwhich could reduce the costs of health economic analy-\nsis, accelerate model development timelines and reduce \nthe risk of error in modelling.\n* Tim Reason \n tim.reason@estima-sci.com\n1 Estima Scientific, Mediaworks, 191 Wood Ln, \nLondon W12 7FP, UK\n2 Bristol Myers Squibb, Uxbridge, UK\n3 Bristol Myers Squibb, Princeton, NJ, USA\n1 Introduction\nWe are living through a golden age of innovations and the \ndevelopment of new treatments for many diseases. How -\never, this is occurring at a time of increasing demand, \nprimarily due to an ageing population with complex health \nneeds, together with constrained healthcare resources and \nbudgets. Health economic models, which provide evidence \nof the relative costs and benefits of new health technolo-\ngies compared with existing technologies [1 ], are vital \ntools for informing health decision making, particularly \nhealth technology assessments that inform national deci-\nsions for market access and reimbursement [2 ].\n192 T. Reason et al.\nTo ensure prompt market access to medicines, there is \na demand for timely and reliable health economic analy -\nsis. However, existing methods for model development \nare expensive, time-consuming and prone to human-error \n[3]. There is therefore a need for research to enhance the \nefficiency and quality of health economic modelling. Auto-\nmation of some aspects of economic modelling using arti-\nficial intelligence (AI) could accelerate development time-\nlines, reduce costs and reduce the risk of technical errors, \nwhich are present in virtually all human-built models [4 ], \nultimately improving access to medicines and outcomes \nfor patients.\nThe development of a health economic model typically \ninvolves four phases: conceptualisation of the model, estimat-\ning parameter values, constructing the model and validating the \nmodel, as shown in Fig. 1 [2]. During the model construction \nphase, a health economist programmes the model in a software \nsuch as R or Excel [5], based on a previously specified design. \nLarge language models (LLMs), such as Generative Pre-\nTrained Transformer 4 (GPT-4), are mathematical models that \nwork by repeatedly predicting the next word [7, 8]. LLMs enable \nautomated generation of text content, including computer code, \nbased on input (prompts) [8]. Therefore, LLMs offer a potential \nroute to automating health economic model construction. Theo-\nretically, we could provide an LLM with a series of text-based \nprompts describing a models’ design, and ask it to generate code \nto programme the model in a software such as R. However, the \npotential of LLMs in automating model construction has not \nyet been explored.\nLLM-based model construction is a promising idea for \nseveral reasons. Firstly, health economists usually produce \na text-based summary of a model’s design prior to model \nconstruction (a specification document). Secondly, several \naspects of model construction are suited to automation: \nmodel construction involves programming a large number \nof simple formulae, which is time consuming, repetitive \nand prone to human error; health economic models are \ntypically based on a limited set of well-established meth-\nodologies, and there are objectively correct and incorrect \nways of programming a model provided the model is con-\nceptualised (designed) in sufficient detail [3 ].\nIn this paper, we report a case study that aimed to assess \nwhether an LLM, GPT-4, could be used to automatically \nconstruct and replicate the results of two published health \neconomic analyses based on text prompts describing the \nmodel’s assumptions, methods and parameter values.\nFig. 1  The four phases of devel-\noping a health economic model\n2  Methods\n2.1  Economic Models used in the Case Study\nThe two published health economic analyses were cho-\nsen because we had access to complete information on the \nmethodology used, and both models were three-state par -\ntitioned survival models, which is a very commonly used \nmodel type in oncology modelling. Both published models \nwere built in Microsoft Excel. One model assessed the cost-\neffectiveness of nivolumab versus docetaxel in patients with \nnon-small cell lung cancer (NSCLC) previously treated with \nplatinum-based chemotherapy from a US payer perspective \n(the NSCLC model), and the other assessed the cost effec-\ntiveness of nivolumab plus ipilimumab versus both sunitinib \nand pazopanib for the first-line treatment of unresectable \nadvanced renal cell carcinoma (RCC) in Switzerland (the \nRCC model) [10, 11]. Key characteristics of each model are \npresented in Table 1.\nFor this study, we did not have access to individual \npatient data that were used in the published models to fit \noverall survival, progression-free survival and time-to-dis-\ncontinuation curves. Therefore, these extrapolated curves \nwere used directly as parameters in the AI-generated models. \nTo constrain the scope of our case study, we generated only \nthe base case analyses, and sensitivity and scenario analyses \nwere not included.\n2.2  Overview of the LLM‑Based Automation \nof Model Construction\nAn overview of the LLM-based automation of model con-\nstruction, including the prompt development process, is \nshown in Fig. 2.\n2.2.1  Prompt Development Process\nLLMs generate text content based on inputs known as \n‘prompts’. Text-based prompts can use any text-based form, \nincluding questions or instructions in natural language, and \nshould convey the nature of the output that the user wishes to \nelicit from the LLM. An example of a prompt is, ‘write me \nan essay on Hamlet’. The output of an LLM can vary signifi-\ncantly depending on the style and quality of a prompt [11]. \nNumerous studies have investigated ‘effective’ prompting, \nwhere ‘effective’ prompts are those most likely to produce \n193\nLarge Language Models for Automating Economic Modelling\nTable 1  Models replicated in the case study\nNSCLC non-small cell lung cancer, PSM partitioned survival model, RCC  renal cell carcinoma\nSpecification Model\nNSCLC RCC \nModel type Three-state PSM Three-state PSM\nTreatments Nivolumab, docetaxel Nivolumab + ipilimumab, pazopanib, sunitinib\nHealth states Progression-free, progressed disease, death Progression-free, progressed disease, death\nTime horizon and \ncycle length\n20 years/1 week 40 years/1 week\nCost categories Drug acquisition Drug acquisition\nDrug administration Drug administration\nDrug monitoring Treatment initiation (upon starting treatment)\nSubsequent therapy drug acquisition, drug administration and drug \nmonitoring (upon death or progression for nivolumab, upon finishing \nfirst-line treatment for docetaxel)\nDisease management\nSubsequent therapy drug acquisition, drug \nadministration (upon finishing first-line \ntreatment)\nEnd-of-life care (upon death)\nDisease management\nAdverse events (upon starting treatment)\nEnd-of-life care (upon death)\nUtility categories Adverse events utility decrement Treatment-specific health-state utilities\nHealth-state utilities\nFig. 2  Diagram showing (a) the top-level process used to construct health economic models using an LLM and (b) the iterative prompt develop-\nment process used in this study. API application programming interface, GPT-4 generative pre-trained transformer 4, LLM large language model\n194 T. Reason et al.\nan output of the desired form and quality, and this is a highly \nactive area of research that is rapidly progressing [13– 16]. \nA scientific process is required for best outcomes. Numer -\nous strategies such as ‘chain of thought’ prompting and the \ninclusion of key phrases (e.g. ‘let’s think step by step’) have \nbeen assessed on benchmark problem sets and have been \ndemonstrated to significantly improve performance [16, 17]. \nIterative optimisation methods have also been shown to pro-\nduce improvements in outcomes for given task sets [18].\nGiven the impact of prompting strategies on perfor -\nmance, it was important that we developed effective \nprompts for our case study to fairly assess GPT-4’s capa-\nbilities in model construction. As no existing studies had \ninvestigated how to effectively prompt LLMs to construct \nhealth economic models, we opted to use an iterative \nmethod to develop the prompts. It should be noted that \nan alternative prompting strategy may yield superior out-\ncomes; however, the iterative method provided satisfactory \noutcomes for this study. This functioned as follows (Fig \n2b): for each model initial prompts were developed; these \nwere submitted to GPT-4 and the generated models were \nevaluated and based on these insights the prompts were \nadjusted. The adjusted prompts were then submitted back \ninto GPT-4 for further testing and evaluation; the process \ncontinued until no further improvements could be made \nthrough reasonable adjustments to the content and style \nof the prompts, and final prompts were reached for each \nmodel.\nThe prompts we developed instructed GPT-4 to code the \nNSCLC and RCC models in R, and provided descriptions of \neach model’s methods, assumptions and parameter values as \nsupporting information.\n2.2.2  LLM Interaction\nThere are a variety of methods to submit prompts to an \nLLM and receive an output. ChatGPT is a web application \nthat allows prompts to be submitted to an LLM online, in \na dialogue format [19], a method that is readily accessible \nand popular. However, it is not suited to automation, as it \nrequires manual entry of prompts into the web application, \nand manual extraction of the response.\nFor this study, we used application programming inter -\nface (API) calls to submit prompts to GPT-4 and receive \noutput. API calls transmit a request to a server (in this case, \ntransmitting a prompt to the GPT-4 servers) and return a \nresponse (in this case, returning the text output from GPT-4). \nImportantly, API calls can be embedded into code, such as a \nPython script. This enables automation of complex, multi-\nstep interactions with LLMs. For example, a computer pro-\ngramme can be written to automate a series of prompt–out-\nput interactions with an LLM, and subsequently manipulate \nthe LLM’s outputs.\n2.3  Prompting Methods and Key Learnings\nSeveral key insights were uncovered through iterative \nprompt development, which shaped the form of the final \nprompts, as described below.\n2.3.1  Using Multiple Prompts\nA token is a unit of text that can be processed and gener -\nated by an LLM. GPT-4 had a token limit of 8192 at the \ntime of the study. This restricted the quantity of text in a \nprompt–response pair to roughly 4000 words. The base case \nanalyses of the models were found to require more than \n15,000 tokens to specify in R. Therefore, the models could \nnot be generated using a single prompt. In addition, GPT-4 \nwas observed to have significantly better performance when \ninstructed to build a single element of the models (such as a \nparticular input calculation, or survival analysis) than when \ninstructed to build a full model in one go.\nTherefore, we developed multiple prompts for each \nmodel, each instructing GPT-4 to generate a separate section \nof the R script. We split the scripts into sections as follows:\n• Parameter definition sections—each of these sections \ndefined a set of model parameters.\n• Input calculation sections—each of these sections calcu-\nlated a cost or utility from the model parameters, which \nwas later applied in the model trace.\n• Model trace sections—each of these sections defined a \npart of the model trace, using functions from the Heemod \nR package [20].\n• Other sections—these sections contained routine code, \nsuch as code to run the model or load R packages.\nGenerating the scripts in sections posed challenges. When \ngenerating a section of the R script, GPT-4 only had access \nto information contained in the prompt for that section. \nHowever, the separate script sections had to work together \nwhen combined. In particular, later sections needed to use \nvariables defined in earlier sections. Therefore, we devel-\noped a fully automated process in Python to pass informa-\ntion on earlier sections of the model script into prompts used \nfor later sections [21]. This worked as follows (Fig. 3):\n1. The prompts were loaded into Python as strings. A sepa-\nrate prompt was developed for each model section.\n2. Alongside each prompt, a ‘section tag’ was added which \nindicated what part of the model the prompt referred to. \nFor example, there were six section tags available for \nprompts for input calculation sections, which covered \ngeneral categories of input calculation. These were: drug \nacquisition cost calculation, transition cost calculation, \nhealth state cost calculation, other cost calculation, util-\n195\nLarge Language Models for Automating Economic Modelling\nity decrement calculation and health state utility calcula-\ntion. These options were sufficient to construct both the \nRCC and NSCLC models.\n3. For each prompt, the user could provide a further ‘data \ntag’. These tags linked the prompt to one or more of the \nparameter definition prompts.\n4. When the process was initiated, the prompts were passed \nautomatically to GPT-4 using API calls. The order was \ndetermined by the section tags.\n5. The parameter definition sections of the scripts were \nautomatically appended to the prompts for calculation \nsections based on the data tags. This ensured that GPT-4 \nhad information on the variable names of model param-\neters required for the calculation sections.\n6. Once all prompts had been passed to GPT-4 and all the \nscript sections had been generated, these were automati-\ncally combined into a complete model script through \nconcatenation. Again, the order was determined by the \nsection tags. The final output could be copied into R and \nrun without any human edits.\nAs well as passing the variable names of model param-\neters into prompts, it was also necessary to pass some \nintermediate variable names. An intermediate variable stores \nthe result of a calculation for use in a later section of the \nmodel script. For example, models commonly calculate per \ncycle costs which are applied later in the trace calculations.\nThis posed a separate problem as the user cannot know \nin advance what intermediate variables will be generated by \nGPT-4 and how these variables will be named. Therefore, a \nsolution analogous to the tagging approach was not feasible. \nInstead, we developed automated ‘summary calls’ that were \nAPI calls prompting GPT-4 to list the intermediate variables \ndefined in a section of the model script. Summary calls were \nadded into specific stages of the automated process to pass \nintermediate variable names from earlier script sections into \nthe prompts used to generate later script sections (Fig.  3). \nThe automated process was able to handle both model cases \nand was not changed between constructing the NSCLC and \nRCC models.\n2.3.2  Contextual Information\nWe observed that GPT-4 made far more errors when using \nfunctions from health economic modelling packages than \nwhen implementing base functions in R. GPT-4 also \nFig. 3  Diagram showing the structure of the automated process used to construct each replica model in Python. API application programming \ninterface, GPT-4 generative pre-trained transformer 4\n196 T. Reason et al.\nincorrectly implemented certain common health economic \nassumptions, such as vial wastage, when prompted. Fur -\nther, intermediate variables were stored in an inconsistent \nmanner (scalars, vectors and arrays) which caused errors \nwhen these variables were used in later script sections. It \ntherefore became clear that we needed to provide GPT-4 \nwith contextual information on top of information specify -\ning the model assumptions, methods and parameter values. \nThis information needed to describe how to use functions \nfrom health economic modelling packages, explain common \nhealth economics assumptions, and provide instructions on \nthe desired structure of the model code (for example, speci-\nfying how to store intermediate variables). To this end, we \ndrafted contextual information relevant to each model sec-\ntion, and integrated this into the Python process. The infor -\nmation was automatically prepended to the calculation and \ndata prompts, based on the section tags, as shown in Fig. 3.\nAn example of contextual information is provided in \nFig.  4. We included worked examples, as this has been \nshown to improve the performance of LLMs in multi-step \nreasoning tasks [16]. The contextual information was devel-\noped iteratively in the same manner as the prompts. The final \nset of contextual information was generic and applicable \nto both models. It formed part of the back-end structure of \nthe Python process and was not changed when we used the \nprocess to construct the RCC and NSCLC models.\n2.3.3  Prompt content\nThrough the process of iterative development, we reached a \nfinal prompt set of 33 prompts to specify the NSCLC model. \nA total of 17 of these prompts contained only parameter val-\nues (‘data prompts’), with the remaining 16 prompts describ-\ning methodology and assumptions (‘method prompts’). The \nfinal prompt set for the RCC model used 21 data prompts \nand 16 method prompts. All final prompts are provided in \nthe Online Resource.\nThe method prompts differed in length depending on the \ncomplexity of the methods described. Figure  5a provides \nan example of a simple method prompt for the RCC model \nand the data prompts to which it was linked, and Fig.  5b \nprovides an example of a complex method prompt for the \nNSCLC model.\nFig. 4  Example of contextual information. This contextual information was automatically appended to prompts tagged as ‘discounting’ prompts. \nGPT-4 generative pre-trained transformer 4\n197\nLarge Language Models for Automating Economic Modelling\nFor sections of the models that required multi-step meth-\nodology, performance was generally improved by explicitly \nsetting out the methodological steps in order. We noted that \non occasion, the performance of prompts could depend on \nphrasing and word choice.\nTo avoid submitting sensitive data to GPT-4, dummy \nvalues were used in data prompts, which required human \nintervention to replace dummy values with the correct \nvalues in the output scripts. However, this step could be \navoided through the use of a private LLM that ensures the \nconfidentiality of sensitive information (see Discussion).\n2.4  Output Generation and Assessment\nThe final set of prompts for each model were loaded into \nPython and the automated process was initiated. This pro-\nduced a text string with AI-generated R code for each model. \nThe string was copied into R and run without human edits. \nNo change was made to the automated process (including \nthe contextual information) between generating the NSCLC \nand RCC models. The results of the generated scripts were \ncompared with the published values and a health economist \nperformed line-by-line technical quality assurance to iden-\ntify any errors.\nMetrics collected were the base case incremental cost-\neffectiveness ratio (ICER) result as well as the number and \ncategory of errors in the generated models. Errors were cat-\negorised into minor, intermediate and major errors. Classi-\nfication was based on the time it took for a health economist \nto correct the errors once they had been identified. Minor \nerrors took less than 2 min to rectify, intermediate errors \ntook less than 10 min, and major errors took more than 10 \nmin. As this measure could vary from health economist to \nhealth economist, a description of all errors is provided in \nthe appendices.\nDespite setting the temperature of GPT-4 to 0, (‘tempera-\nture’ controls the randomness of the text generated by GPT-\n4) outputs were observed to vary when the same prompt set \nwas used on multiple occasions. Therefore, we generated 15 \nscripts for each model to capture variation in performance.\n3  Results\nExample AI-generated scripts for each model are provided \nin the Online Resource. The accuracy of the NSCLC and \nRCC models is shown in Fig.  6. The NSCLC model was \nfully replicated with high accuracy. Overall, 100% (15/15) \nof the AI-generated NSCLC models were error free or \ncontained only a single minor error, and 93% (14/15) of \nthe AI-generated NSCLC models were completely error \nfree. Only one minor error was observed across the 15 \ntest runs.\nThe RCC model was also closely replicated. However, \nhuman intervention was required to simplify one element \nof the model design (one of the model’s fifteen input cal-\nculations). This is because it used too many sequential \nsteps to be implemented in a single prompt. This had only \na minor impact on model results. The original calcula-\ntion used an elaborate approach to calculate weight-based \ndrug dosing. A simplification was applied by providing \nthe proportion of patients in each weight category and the \nmidpoint weights directly, as well as limiting the set of \navailable vial sizes.\nThis was performed manually at the prompting stage, \nso that GPT-4 was instructed to build the simplified ver -\nsion of the model. With the simplification, 87% (13/15) \nof the AI-generated RCC models were error free or con-\ntained only a single minor error, while 60% (9/15) of the \nAI-generated RCC models were completely error free. In \ntotal, six minor errors and one intermediate error were \nobserved across the 15 test runs.\nAll error-free scripts for both models replicated the pub-\nlished ICERs to within 1%. For the NSCLC model, the error-\nfree AI-generated ICERs all evaluated to USD$117,600/\nquality per quality-adjusted life-year (QALY), compared \nwith the published value of USD$117,739/QALY. For the \nRCC model, the error-free AI-generated ICERs all evaluated \nto CHF107,284/QALY versus sunitinib and CHF105,965/\nQALY versuss pazopanib, compared with the published val-\nues of CHF108,326/QALY and CHF106,996/QALY. Devia-\ntion was explained by minor differences in the calculation \nengine of the Heemod R package versus the Excel models. \nFor example, the AI-generated models applied discounting \non a per-cycle basis, whilst the Excel models applied this \non a year-by-year basis. Similarly, the R models assumed \nprogression-free survival state occupancy was 100% in the \nfirst model cycle, whereas half-cycle correction was applied \nin the first model cycle for one of the Excel models.\nOf the 30 AI-generated models, none required more \nthan 10 min of edits to rectify errors following human \nquality assurance. The average time taken by GPT-4 to \ngenerate the NSCLC model was 715 s (standard deviation \n29 s) and the average time taken by GPT-4 to generate the \nRCC model was 956 s (standard deviation 52 s).\n4  Discussion\nIn this case study we aimed to assess whether GPT-4 could be \nused to automatically construct two health economic analyses \nbased on descriptions of the model’s assumptions, methods \n198 T. Reason et al.\nshould be distinguished from model conceptualisation, estima-\ntion of parameter values and model validation (technical and \nexternal) that were not automated during this study.\nFig. 5  A Example of a specification prompt for a simple model com-\nponent. Dummy values are underlined. 1We found that including \na definition of the cost category in snake case would lead to shorter \nand more precise variable names in the resulting R script. This is why \n“the cost category is ‘drug_aq’” was included in the method prompt. \nCHF Swiss franc, RDI relative dose intensity. B Example of a speci-\nfication prompt for a more complex model component. Dummy val-\nues are underlined. 1We found that including a definition of the cost \ncategory in snake case would lead to shorter and more precise vari-\nable names in the resulting R script. This is why “the cost category is \n‘sub_therapy_drug_admin’” was included in the method prompt\nand parameter values. Model construction is the third phase of \nmodel development, in which the model is programmed in a \nsoftware such as R or Excel on the basis of a prior design, and \n199\nLarge Language Models for Automating Economic Modelling\nIn response to this question and through iterative prompt \ndevelopment we reached a novel process for automating health \neconomic model construction in R using an LLM. In addition \nto prompts describing the model’s methods, assumptions and \nparameter values, the process required contextual information. \nHowever, this information was generalisable across the two \nmodels we generated and described how to use health econom-\nics R packages, how to interpret common health economic \nassumptions and how to structure code.\nUsing this novel process, we automatically constructed ver-\nsions of the two published models. No human intervention was \nrequired between writing the prompts describing the model \ndesigns and receiving back the fully programmed model R \nscripts. Across 15 runs for each model, most of the runs were \nerror free or contained only a single minor error. These results \nare promising given that these are health technology assess-\nment (HTA)-ready models and that virtually all human built \nhealth economic models contain technical errors prior to qual-\nity assurance [4]. None of the AI-generated models required \nmore than 10 min of human edits to correct errors following \nfull technical quality control, which demonstrates the minor \nnature of errors observed in our study.\nIt should be noted that one calculation in the published \nRCC model had to be simplified for the AI-generated model, \nas it used too many sequential steps for a single prompt. To \nfully replicate the published RCC model this section of the \nAI-generated script would require human editing, indicating \nthat with current generation LLMs human intervention may \nbe required for atypical and complex model sections. How-\never, simplification was required for only one section of the \n28 calculation sections across the two models. The need for \noccasional human intervention does not greatly undermine the \npotential benefits achievable through LLM-based automation \nof model construction.\n4.1  Study Limitations\nThere were a number of limitations in our case study. \nFirstly, sensitive data in the prompts we developed had to be \nredacted using dummy values and manually added back in to \nthe AI-generated models. This is because prompts submitted \nto LLMs may be retained by the LLM provider and become \nvulnerable to data breaches. Also, LLMs may be trained on \nsubmitted prompts, which could result in data leaks. Data \nsecurity is of great importance in HEOR and should not \nFig. 6  Accuracy of the AI-gen-\nerated replica models. NSCLC \nnon-small cell lung cancer, RCC  \nrenal cell carcinoma\n\n200 T. Reason et al.\nbe jeopardised as we take advantage of the opportunities \noffered by LLMs. Since this research was performed, several \noptions for the secure use of LLMs have emerged, such as \ndedicated hosting of private instances of LLMs, downloada-\nble instances of open-source models and API services where \nprompts are not stored or used to train models. This would \nenable inclusion of sensitive data in model design prompts.\nSecondly, to constrain the scope of our study, we repli-\ncated only the base case analyses of the published models. \nThe ability of LLMs to programme sensitivity analyses, \nwhich are important components of health economic analy-\nses, was not evaluated and is an area for future research. \nAdditionally, the AI-generated models were both three-\nstate partitioned survival models (PSMs) in late-stage anti-\ncancer treatment. It remains to be demonstrated whether \nLLMs can accurately programme a range of model types \nwith varying levels of sophistication, such as decision-tree \nanalysis, Markov models and individual patient simulation \napproaches, and whether this can be achieved across a wider \nrange of disease areas.\nThirdly, following technical quality control of the AI-\ngenerated scripts, errors were corrected by the same health \neconomist who had developed the prompts. Due to the nature \nof the iterative development process, the health economist \nhad some familiarity with the type of errors likely to be \nmade, which may have reduced the time taken to correct \nthem. More time may be required to correct errors without \nthe prior knowledge gained through developing prompts \nusing an iterative process.\n4.2  Implications for Future Policy and Research\nThe implications of our research are many fold. We rep-\nlicated published models in this study to demonstrate the \naccuracy of the LLM-generated models by comparing \nresults against established values. However, the same pro-\ncesses could be used to automatically construct a de novo \nmodel, where model conceptualisation, estimation of param-\neter values and model validation (technical and external) \nare performed manually as for human-built models. When \ndeveloping a de novo model, it is common practice to spec-\nify the model in detail prior to starting any programming (for \nexample, in a model specification document). This informa-\ntion could be used to develop model design prompts and \nperform LLM-based model construction for de novo models.\nWith this in mind, there are numerous potential appli-\ncations for LLM-based model construction. As a first use \ncase, AI-generated models could be used to rapidly perform \ndouble-programming technical validation of human-built \nmodels. This is a method in which the same model is built \nindependently by two health economists, and differences \nin the results are investigated to reveal technical errors. In \nthis use case, the LLM could take on the role of one of the \ntwo health economists to save time and potentially increase \naccuracy. Secondly, LLM-based model construction could \nenable rapid production of additional models to perform \nassessments of structural uncertainty. For example, rapidly \nconstructing a PSM in parallel to a Markov model, which \nmay otherwise not be possible due to time and resource \nconstraints. Thirdly, it may be possible to quickly adapt \nLLM-generated models through editing of the model design \nprompts (for example, adding a new comparator) which \nwould be of particular use at an early modelling stage.\nIn addition to this, many countries have HTA agencies \nto robustly assess the costs and effectiveness of new tech-\nnologies [22, 23]. However, the process can be lengthy and \nthereby delay patients’ access to medicines [24– 26], which \nin turn can affect patient outcomes [27, 28]. In the longer \nterm, using LLMs to automate model construction could \nresult in a reduction in the person hours required for model \ndevelopment, which could accelerate timelines for HTA pro-\ncesses and reduce costs. As AI is implemented into other \naspects of clinical development and health economics and \noutcomes research (HEOR) it may increase the complexity \nas well as demand for HTAs [29, 30]. Therefore, it may be \nnecessary to automate some aspects of the economic model-\nling to free up time for tasks that cannot be automated. AI \nis also being assessed in other processes that are relevant to \nHTAs and HEOR such as conducting systematic literature \nreviews [36, 37] and the use of large amounts of clinical data \n(real-world and “big data”) [38].\nFinally, LLM-based model construction could open the \ndoor to deploying economic modelling more widely in \nhealthcare decision making, if significant reductions in costs \nand resource requirements can be achieved.\nThe above applications primarily derive from the poten-\ntial of LLM-based model construction to reduce the time \nand resource required to construct models, and therefore to \naccelerate timelines for model construction. As our study \nwas the first (to the authors’ knowledge) to investigate using \nLLMs to produce health economic models, a high upfront \ntime investment was required to experiment with and iden-\ntify successful prompting strategies through iterative prompt \ndevelopment. However, prompting strategies may prove gen-\neralisable across different decision problems, and this asser-\ntion is supported by the similarity between the successful \nprompt sets we developed for the NSCLC and RCC models \n(particularly the contextual information, which was reused \nwithout edits). If this is the case, the process of developing \nprompts would shift from experimental, iterative develop-\nment to adapting prompts from published exemplars based \non the specifics of the decision problem in question. Such \na streamlined process could enable significant reductions in \nthe time and cost required to programme health economic \nmodels. Therefore, a key next research step will be to inves-\ntigate the generalisability of prompting strategies across a \n201\nLarge Language Models for Automating Economic Modelling\nwider pool of models. In particular, further research should \nbe conducted to assess the accuracy that can be achieved \nthrough using prompts transferred from one decision prob-\nlem to another without iterative optimisation.\nThere are a number of challenges that must be overcome \nto integrate LLM-based automation into existing model \ndevelopment workflows. Our case study suggests that AI-\ngenerated scripts may contain errors. It is important that \nthese errors are placed in the context of human performance \nin model construction, which is the relevant comparison, and \nare not used to discount AI-generated models out of hand \n[4]. It should also be emphasised that full technical quality \nassurance should be performed for AI-generated scripts as \nit is for human-built models.\nAdditionally, an expanded skillset is required to perform \nLLM-based model construction in comparison with manu-\nally developing health economic models. Firstly, knowl-\nedge of how to programme health economic models in R \nis required, both to perform technical quality control of AI-\ngenerated scripts, and to perform manual edits of atypical or \ncomplex sections. These skills are not ubiquitous amongst \nhealth economists. Although, it is worth noting that LLMs \ncan be used to edit Microsoft Excel files (and therefore \nExcel-based models), which may become an important use-\ncase in the future. Secondly, basic working knowledge of \nPython is an advantage (although, if prompting strategies \nprove generalisable the Python components may not require \nediting in many cases). Finally, users must understand how \nto develop effective prompts to specify a model. Educating \nhealth economists in these areas is likely to require dedicated \ntraining. However, if LLM-based model construction is sig-\nnificantly time saving this should not be a barrier to use.\nFurthermore, HTA agencies and evidence assessment \ngroups (EAGs) may be reluctant to accept the use of LLM-\nbased processes in generating evidence. This is because the \ntechnologies involved are not yet widely understood, and \nthere is not currently a gold standard for applying LLM-\nbased methods in the field of HEOR. However, it should \nbe noted that the output produced by LLM-based model \nconstruction (an R script) is scrutable in the same way as a \nhuman generated output, since all working is provided in the \ncode. Therefore, an LLM-generated model could be robustly \nchecked, which is a prerequisite of HEOR methods in an \nHTA document.\nWhilst it is important to consider the above challenges, \nthe results of our study should also be placed in the context \nof the rapid improvements that have recently been made \nin the field of generative AI. It is highly likely that next-\ngeneration LLMs will allow for the methods described in \nour case study to be adapted and improved. For example, \nnext-generation LLMs may enhance the accuracy of gener -\nated code. Furthermore, models with improved token limits \nhave been released since this study was conducted (GPT-4 \nturbo with a limit of 128,000 tokens, and Claude 2.1 with a \nlimit of 200,000 tokens. The version of GPT-4 used in this \nstudy had a token limit of 8192). Increases to token-limits \n(which restrict the quantity of text that can be included in \nprompts and outputs) can simplify the processes described \nin this paper.\n5  Conclusion\nUsing a novel LLM-based process, we constructed the base \ncase analyses of published three-state partitioned survival \nanalyses in R to a high degree of accuracy, demonstrating \nthe feasibility of using GPT-4 to automate health economic \nmodel construction. Potential benefits of automating health \neconomic model construction include accelerated time-\nlines and reduced costs for model development, reduction \nin human error and novel methods for model validation \nand exploring structural uncertainty. Potential challenges \ninclude managing the perception of AI-generated models, \nthe requirement for an expanded skillset in comparison with \nmanual model construction, and barriers to acceptance of \nLLM-based methods by HTA bodies. Further research \nshould be conducted to explore the generalisability of LLM-\nbased model construction across a wider range of model \ntypes and disease areas, the accuracy that could be achieved \nthrough prompts that are reusable across multiple decision \nproblems and the potential to construct Excel-based health \neconomic models using LLMs.\nSupplementary Information The online version contains supplemen-\ntary material available at https:// doi. org/ 10. 1007/ s41669- 024- 00477-8.\nDeclarations \nFunding This study was funded by Bristol Myers Squibb. The study \nsponsor was involved in several aspects of the research, including the \nstudy design, interpretation of data, writing of the manuscript and deci-\nsion to submit the manuscript for publication.\nConflict of Interest This study was supported by Bristol Myers Squibb. \nEstima authors (Tim Reason, William Rawlinson, Julia Langham, \nAndy Gimblett) are consultants and have worked on behalf of Bill \nMalcolm and Sven Klijn, who are employees and shareholders of Bris-\ntol Myers Squibb.\nAvailability of Data and Material All data generated or analysed during \nthis study are included in this published article (and its supplementary \ninformation files).\nEthics Approval No human participants, their data or biological mate-\nrial were used in this study.\nConsent for Publication This article does not contain identifiable pho-\ntos or patient data.\nConsent to Participate No human participants took part in this study.\n202 T. Reason et al.\nCode Availability All AI-generated R code has been provided in the \nOnline Resource, in addition to the prompts that were used to describe \nthe designs and inputs of each replicated model, and the user-defined \nR functions that were used by GPT-4.\nAuthor Contributions All authors (TR, WR, JL, AG, BM and SK) con-\ntributed to the study conception and design. Material preparation, data \ncollection and analysis were performed by TR and WR. The first draft \nof the manuscript was written by WR and all authors (TR, WR, JL, \nAG, BM and SK) commented on previous versions of the manuscript. \nAll authors (TR, WR, JL, AG, BM and SK) read and approved the \nfinal manuscript.\nOpen Access  This article is licensed under a Creative Commons Attri-\nbution-NonCommercial 4.0 International License, which permits any \nnon-commercial use, sharing, adaptation, distribution and reproduction \nin any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Com-\nmons licence, and indicate if changes were made. The images or other \nthird party material in this article are included in the article's Creative \nCommons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article's Creative Commons \nlicence and your intended use is not permitted by statutory regula-\ntion or exceeds the permitted use, you will need to obtain permission \ndirectly from the copyright holder. To view a copy of this licence, visit \nhttp:// creat iveco mmons. org/ licen ses/ by- nc/4. 0/.\nReferences\n 1. Drummond MF, Sculpher MJ, Torrance GW, O’Brien BJ, Stoddart \nGL. Methods for the Economic Evaluation of Health Care Pro-\ngrammes [Internet]. Oxford University Press; 2005. https:// EconP \napers. repec. org/ RePEc: oxp: obooks: 97801 98529 453. Accessed on \n01 Sep 2023.\n 2. Caro JJ, Briggs AH, Siebert U, Kuntz KM. Modeling good \nresearch practices—overview: a report of the ISPOR-SMDM \nModeling Good Research Practices Task Force-1. Value Health. \n2012;15:796–803.\n 3. (M. Eddy) D. Model transparency and validation: a report of the \nISPOR-SMDM modeling good research practices task force-7. \nValue Health. 2012;15.\n 4. Radeva D, Hopkin G, Mossialos E, Borrill J, Osipenko L, Naci H. \nAssessment of technical errors and validation processes in eco-\nnomic models submitted by the company for NICE technology \nappraisals. Int J Technol Assess Health Care. 2020;36:311–6.\n 5. R Core Team. R: A Language and Environment for Statistical \nComputing [Internet]. Vienna, Austria: R Foundation for Statisti-\ncal Computing; 2023. https:// www.R- proje ct. org/. Accessed on 01 \nSep 2023.\n 6. OpenAI. GPT-4 Technical Report. 2023.\n 7. S. R. Bowman. Eight things to know about large language mod-\nels. ArXiv [Internet]. 2023. https:// doi. org/ 10. 48550/ arXiv. 2304. \n00612. Accessed on 01 Sep 2023.\n 8. Poldrack RA, Lu T, Begu\\vs G. AI-assisted coding: experiments \nwith GPT-4. ArXiv [Internet]. 2023;abs/2304.13187. https:// api. \nseman ticsc holar. org/ Corpu sID: 25833 1866. Accessed on 01 Sep \n2023.\n 9. Chaudhary MA, Lubinga SJ, Smare C, Hertel N, Penrod JR. Cost-\neffectiveness of nivolumab in patients with NSCLC in the United \nStates. Am J Manag Care. 2021;27:e254–60.\n 10. Çakar E, Oniangue-Ndza C, Schneider RP, Klijn SL, Vogl UM, \nRothermundt C, et al. Cost-effectiveness of nivolumab plus \nipilimumab for the first-line treatment of intermediate/poor-risk \nadvanced and/or metastatic renal cell carcinoma in Switzerland. \nPharmacoecon Open. 2023;7:567–77.\n 11. Harrer S. Attention is not all you need: the complicated case of \nethically using large language models in healthcare and medi-\ncine. EBioMedicine. 2023;90: 104512.\n 12. Zhou D, Schärli N, Hou L, Wei J, Scales N, Wang X, et al. \nLeast-to-most prompting enables complex reasoning in large \nlanguage models. ArXiv [Internet]. 2023.  https:// doi. org/ 10.  \n48550/ arXiv. 2205. 10625. Accessed on 01 Sep 2023.\n 13. Creswell A, Shanahan M. Faithful reasoning using large lan -\nguage models. ArXiv [Internet]. 2022. https:// doi. org/ 10. 48550/ \narXiv. 2208. 14271. Accessed on 01 Sep 2023.\n 14. Creswell A, Shanahan M, Higgins I. Selection-inference: \nexploiting large language models for interpretable logical rea-\nsoning. ArXiv [Internet]. 2022. https:// doi. org/ 10. 48550/ arXiv. \n2205. 09712. Accessed on 01 Sep 2023.\n 15. Wang X, Wei J, Schuurmans D, Le Q, Chi E, Narang S, et al. \nSelf-consistency improves chain of thought reasoning in lan-\nguage models. ArXiv [Internet]. 2023. https:// doi. org/ 10. 48550/ \narXiv. 2203. 11171. Accessed on 01 Sep 2023.\n 16. Wei J, Wang X, Schuurmans D, Bosma M, Chi EH, Le Q, et al. \nChain of thought prompting elicits reasoning in large language \nmodels. CoRR [Internet]. 2022;abs/2201.11903. https:// arxiv.  \norg/ abs/ 2201. 11903. Accessed on 01 Sep 2023.\n 17. Kojima T, Gu SS, Reid M, Matsuo Y, Iwasawa Y. Large lan-\nguage models are zero-shot reasoners. ArXiv [Internet]. \n2022;abs/2205.11916. https:// api. seman ticsc holar. org/ Corpu \nsID: 24901 7743. Accessed on 01 Sep 2023.\n 18. Yang C, Wang X, Lu Y, Liu H, Le QV, Zhou D, et al. Large \nlanguage models as optimizers. 2023. Accessed on 01 Sep 2023.\n 19. ChatGPT (Oct 12 version) [Internet]. L.L.C., San Francisco: \nOpenAI; 2023. https:// beta. openai. com/ docs/ models.\n 20. Guyot P, Ades A, Ouwens MJ, Welton NJ. Enhanced second-\nary analysis of survival data: reconstructing the data from pub-\nlished Kaplan-Meier survival curves. BMC Med Res Methodol. \n2012;12:9.\n 21. Van Rossum G, Drake FL Jr. Python reference manual. Centrum \nvoor Wiskunde en Informatica Amsterdam; 1995.\n 22. Angelis A, Lange A, Kanavos P. Using health technology \nassessment to assess the value of new medicines: results of a \nsystematic review and expert consultation across eight European \ncountries. Eur J Health Econ. 2018;19:123–52.\n 23. Jenei K, Raymakers AJN, Bayle A, Berger-Thürmel K, Cherla \nA, Honda K, et al. Health technology assessment for cancer \nmedicines across the G7 countries and Oceania: an interna-\ntional, cross-sectional study. Lancet Oncol. 2023;24:624–35.\n 24. Büssgen M, Stargardt T. Does health technology assessment \ncompromise access to pharmaceuticals? Eur J Health Econ. \n2023;24:437–51.\n 25. Akehurst RL, Abadie E, Renaudin N, Sarkozy F. Variation in \nhealth technology assessment and reimbursement processes in \nEurope. Value Health J Int Soc Pharmacoecon Outcomes Res. \n2017;20:67–76.\n 26. Kamphuis B. Access to medicines in Europe: delays and chal-\nlenges for access [Internet]. London School of Economics; \n2021. https:// doi. org/ 10. 21953/ 0zaz- k994.\n 27. Incze A, Kaló Z, Espín J, Kiss É, Kessabi S, Garrison LP. \nAssessing the consequences of external reference pricing for \nglobal access to medicines and innovation: economic analysis \nand policy implications. Front Pharmacol. 2022;13: 815029.\n 28. Zhu X, Liu B. Launch delay of new drugs in China and effect \non patients’ health. Clin Ther. 2020;42:1750-1761.e7.\n 29. Padula WV, Kreif N, Vanness DJ, Adamson B, Rueda J-D, \nFelizzi F, et al. Machine learning methods in health econom-\nics and outcomes research-The PALISADE checklist: A good \n203\nLarge Language Models for Automating Economic Modelling\npractices report of an ISPOR Task Force. Value Health J Int Soc \nPharmacoecon Outcomes Res. 2022;25:1063–80.\n 30. Davenport T, Kalakota R. The potential for artificial intelligence \nin healthcare. Future Healthc J. 2019;6:94–8.\n 31. Askin S, Burkhalter D, Calado G, El Dakrouni S. Artificial intel-\nligence applied to clinical trials: opportunities and challenges. \nHealth Technol. 2023;13:203–13.\n 32. Hendrix N, Veenstra DL, Cheng M, Anderson NC, Verguet S. \nAssessing the economic value of clinical artificial intelligence: \nchallenges and opportunities. Value Health J Int Soc Pharmaco-\necon Outcomes Res. 2022;25:331–9.\n 33. Unsworth H, Wolfram V, Dillon B, Salmon M, Greaves F, Liu \nX, et al. Building an evidence standards framework for artificial \nintelligence-enabled digital health technologies. Lancet Digit \nHealth. 2022;4:e216–7.\n 34. Vervoort D, Tam DY, Wijeysundera HC. Health technol-\nogy assessment for cardiovascular digital health technologies \nand artificial intelligence: why is it different? Can J Cardiol. \n2022;38:259–66.\n 35. Bélisle-Pipon J-C, Couture V, Roy M-C, Ganache I, Goetghebeur \nM, Cohen IG. What makes artificial intelligence exceptional in \nhealth technology assessment? Front Artif Intell. 2021;4: 736697.\n 36. de la Torre-López J, Ramírez A, Romero JR. Artificial intelligence \nto automate the systematic review of scientific literature. Comput-\ning. 2023;105:2171–94.\n 37. Blaizot A, Veettil SK, Saidoung P, Moreno-Garcia CF, Wiratunga \nN, Aceves-Martins M, et al. Using artificial intelligence methods \nfor systematic review in health sciences: a systematic review. Res \nSynth Methods. 2022;13:353–62.\n 38. Kang J. Real-world data in health technology assessment: do we \nknow it well enough? In: Bremer A, Strand R, editors. Precis \noncol cancer biomark issues stake matters concern [Internet]. \nCham: Springer International Publishing; 2022. p. 187–203. \nhttps:// doi. org/ 10. 1007/ 978-3- 030- 92612-0_ 12.\n 39. Hogervorst MA, Vreman RA, Mantel-Teeuwisse AK, Goettsch \nWG. Reported challenges in health technology assessment of \ncomplex health technologies. Value Health J Int Soc Pharmaco -\necon Outcomes Res. 2022;25:992–1001.\n 40. Breeze PR, Squires H, Ennis K, Meier P, Hayes K, Lomax N, \net al. Guidance on the use of complex systems models for eco-\nnomic evaluations of public health interventions. Health Econ. \n2023;32:1603–25."
}