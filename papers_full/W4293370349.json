{
  "title": "Low Level Source Code Vulnerability Detection Using Advanced BERT Language Model",
  "url": "https://openalex.org/W4293370349",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4293370386",
      "name": "Mansour Alqarni",
      "affiliations": [
        "University of Ontario Institute of Technology",
        "First Technical University"
      ]
    },
    {
      "id": "https://openalex.org/A2101752247",
      "name": "Akramul Azim",
      "affiliations": [
        "University of Ontario Institute of Technology",
        "First Technical University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2804659066",
    "https://openalex.org/W3030390060",
    "https://openalex.org/W1512847993",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6739811675",
    "https://openalex.org/W2953333557",
    "https://openalex.org/W2487816900",
    "https://openalex.org/W47648955",
    "https://openalex.org/W2043277155",
    "https://openalex.org/W2032021788",
    "https://openalex.org/W2962960733",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2979771119",
    "https://openalex.org/W2988673764",
    "https://openalex.org/W3165830952",
    "https://openalex.org/W3097933861",
    "https://openalex.org/W2095705004",
    "https://openalex.org/W1665214252",
    "https://openalex.org/W3166740962",
    "https://openalex.org/W2626792426",
    "https://openalex.org/W4301430471",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2585582603",
    "https://openalex.org/W3182842347"
  ],
  "abstract": "In software security and reliability, automated vulnerability detection is an essential and compulsory task.Software needs to be tested and checked before it goes to the client for production.As technology changes rapidly, source code is also becoming massive.Thus the adequate accuracy of automated vulnerability detection has become very important to produce secure software and remove security concerns.According to previous research, a deep and recurrent neural network model can not satisfactorily test accuracy to detect all vulnerabilities.In this paper, we introduce experimental research on Bidirectional Encoder Representations Transformers (BERT), a state-of-the-art natural language processing model aimed to improve test accuracy, contributing to updates to the development of deep layers of the BERT model.As well, we balance and fine-tune the dataset of the model with improved parameters.This combination of changes achieves new levels of accuracy for the BERT model, with 99.30% test accuracy in detecting source code vulnerabilities.We have made our balanced dataset and advanced model publicly available for any research purposes.",
  "full_text": "The 35th Canadian Conference on Artificial Intelligence\nDOI: 0\nLow Level Source Code Vulnerability Detection Using Advanced\nBERT Language Model\nMansour Alqarni†*, Akramul Azim†\n† Ontario Tech University\n*Mansour.Alqarni@ontariotechu.net\nAbstract\nIn software security and reliability, automated vulnerability detection is an essential\nand compulsory task. Software needs to be tested and checked before it goes to the client\nfor production. As technology changes rapidly, source code is also becoming massive.\nThus the adequate accuracy of automated vulnerability detection has become very im-\nportant to produce secure software and remove security concerns. According to previous\nresearch, a deep and recurrent neural network model can not satisfactorily test accu-\nracy to detect all vulnerabilities. In this paper, we introduce experimental research on\nBidirectional Encoder Representations Transformers (BERT), a state-of-the-art natural\nlanguage processing model aimed to improve test accuracy, contributing to updates to\nthe development of deep layers of the BERT model. As well, we balance and fine-tune the\ndataset of the model with improved parameters. This combination of changes achieves\nnew levels of accuracy for the BERT model, with 99.30% test accuracy in detecting\nsource code vulnerabilities. We have made our balanced dataset and advanced model\npublicly available for any research purposes.\nKeywords: Machine Learning, Neural Network, Advance Deep Learning, Program\nAnalysis, Software Security, Balanced Dataset.\nThis article is© 2022 by author(s) as listed above. The article is licensed under a Creative Commons\nAttribution (CC BY 4.0) International license (https://creativecommons.org/licenses/by/4.0/legalcode),\nexcept where otherwise indicated with respect to particular material included in the article. The article\nshould be attributed to the author(s) identified above.\n1. Introduction\nRecently, production using Continuous Integration (CI) and Continuous Delivery\n(CD) pipelines have been prioritized in the software development industry. This pipeline\nalso includes automated tests. Static analyzer software like SonarQube [1] and Brake-\nmen [2] are used to detect software vulnerabilities. Still, these automated processes can-\nnot accurately detect vulnerabilities due to a preponderance of false-positive and false-\nnegative results. As security vulnerability detection is a sensitive task, the software’s\naccuracy needs to be paramount; otherwise, they can be hacked, cracked, or stopped\ndue to security bugs, breaches, unhandled exceptions, memory leaks, buffer overflow,\netc. Previously, researchers used traditional algorithms to detect vulnerabilities [3], but\nwith the increased availability of computing resources, machine learning [4] and deep\nlearning [5] have been used to improve the accuracy of vulnerability detection. Even so,\naccuracy has not reached the level at which it needs to be. Recently, advanced models of\nNatural Language Processing (NLP) have been introduced, which are called transform-\ners [6] [7] [8], able to extract all important features that were not possible previously\nwith common machine learning algorithms. Transformers use a sequence architecture\ngenerated from layers to offer state-of-the-art accuracy.\nThough these transformer models are being used for human language taxonomy clas-\nsification, translation, answering questions, grammar correction etc. In this paper, we\nhave used the transformers for vulnerability detection within programming languages.We\nhave proposed a bi-modal model that can understand the difference between natural lan-\nguage and programming language. Low level programming languages in the past have\nmulti vulnerabilities causing Cyber Hijacking, Buffer Overflow, Firewall system, Memory\ncorruption attacks and more [9] which can not be detected during the coding process. To\nimprove the security and integrity of the application and embedded software we propose\nour advanced BERT model with a higher accuracy for detection weakness during the\ncoding process. Our main contributions are listed below:\n2\nWe have balanced the existing dataset using sampling algorithms as previous results\nfrom existing research papers were biased due to data imbalances.\nWe have proposed to use pre-trained Bidirectional Encoder Representations Trans-\nformers (BERT), and have updated the BERT model by adding additional scope for\nvulnerability detection. Also developed an architecture for deep layers so that our up-\ndated model can outperform machine learning and deep learning models from previous\nresearchers’ work.\nFinally, we have fine-tuned the model by finding the most effective parameters for\nstate-of-the-art accuracy.\nThe remainder of the paper is organized in the following way. In section II, previous\nrelated works of researchers are highlighted. In section III, the dataset of vulnerability\ndetection is described, as well as the techniques we use to remove data imbalance prob-\nlems. In section IV, we discuss methods, transformer model architectures, and model\nparameters. Experimental results and performance comparison are offered in section V,\nfollowed by a conclusion in section VI.\n2. Related Works\nMany researchers have contributed to source code vulnerability detection as the num-\nber of security issues has increased rapidly in the software industry. In the early stages\nof this effort, static analyzer techniques were used to detect vulnerabilities [10] and tools\nlike Clang were developed [11]. But after the evolution of highly configured cloud com-\nputing resources, machine learning and deep learning models have been used to detect\nvulnerabilities by researchers in recent years. Using machine learning algorithms smaller\nto naive-bayes and support vector machine (SVM) [12] and tokenization to use bags of\nwords [13] have been used. Tools like CppCheck [14] and Flawfinder [15] have been cre-\nated. But these algorithms have failed to provide high levels of accuracy. After the deep\nlearning evolution, some researchers have applied convolutional neural network (CNN),\nrecurrent network (RNN), and long short term memory (LSTM) options to detect differ-\nent kinds of vulnerabilities [16] [17]. These deep learning models can provide an advanced\nperformance than common machine learning algorithms and the accuracy of experimen-\ntal results are also better than previous traditional machine learning algorithms. But\nthe memorization techniques of deep learning models have some drawbacks as impor-\ntant features and information can be missed. To solve these problems, Google introduced\nBERT[18]asanaturallanguageprocessingtransformermodeltoincreasepositiveresults\non natural language processing tasks. But this model was mainly designed for human\nlanguage related tasks like sentiment analysis [19], question-answering [20], and named\nentity recognition. Using similar techniques that has been used by other researchers [21]\non the other hand we used an advanced ML model to attain better results. Our research\naims to make the BERT model compatible with programming languages and achieve\nnew levels of accuracy.\n3. Dataset\nDatasets are the main raw materials for natural language processing models. Ex-\nperimental results are not only dependent on best models but also dependent on pre-\nprocessed and unbiased datasets. We have selected the latest and updated code repos-\nitory Github [22] where developers push source code from different parts of the world.\nThe Github dataset is comparatively the most unbiased, real-world dataset as it is a\nworldwide code repository expanded and updated every day. It is assumed that using\nthis dataset, experimental results will be as reliable as possible and detect new vul-\nnerabilities. This dataset has 119 different kinds of Common Weakness Enumeration\n(CWE) for vulnerability detection. Table 1, below, shows the Github dataset overview\nand Figure 1 shows primary dataset visualization.\nTable 1. Overview of Github Dataset\nTotal Code 127419\nVulnerable Source Code 7%\nNon Vulnerable Source Code 93%\n3\nFigure 1. Visualization of Github Dataset\nTo understand more about the dataset, we compared a vulnerable source code and\nnon-vulnerable source code from this dataset. The source code reveals a vulnerability\nfor strlen() built in function used inmemcpy() function, revealed in Figure 2. In Figure\n3 the correct functionsizeof() is used to remove the vulnerability.\nFigure 2. vulnerable source code\n1 Void vulnerable ( char * S)\n2 {\n3 char text [256];\n4 memcpy (text ,s, strlen (s));\n5 Printf (\"%s\\n\",text );\n6\n7 }\nFigure 3. non-vulnerable source code\n1 Void nonvulnerable ( char * S)\n2 {\n3 char text [256];\n4 memcpy (text ,s, sizof (s));\n5 Printf (\"%s\\n\",text );\n6\n7 }\nThedatasethastwocolumns. Thefirstcolumnisthesourcecodeofdifferentfunctions\nand the second column is the vulnerability status (CWE). Figure 4, below, shows the\ndataset contents.\nTable 2 shows the statics of vulnerability types which are present in this dataset.\nTable 2. Vulnerability type statistics\nDescription Total\nBuffer Overflow Problems 38.2%\nMemory Leaks 18.9%\nNULL Pointers 9.5%\nPointer Subtraction Problems 2.0%\nIncorrect Length of Buffer Access 31.4%\nImprovement of Dataset:After observing the dataset, we found that it was not\nbalanced. As an imbalanced dataset can give wrong experimental results, we used over-\nsampling algorithms via the Synthetic Minority Oversampling Technique (SMOTE) to\n4\nFigure 4. Github Dataset Contents\nbalance the existing dataset, randomly duplicating minority class samples. The SMOTE\ntechnique selects close samples from the feature space, and this technique will calculate\nthe distances between two corresponding samples. After selecting the close samples,\nmore related samples are duplicated to balance the dataset.\nTable 3 shows the updated dataset overview and Figure 5 shows the balanced dataset\nvisualization.\nTable 3. Overview of balanced Github dataset\nTotal Code 247858\nVulnerable Source Code 123929\nNon Vulnerable Source Code 123929\nFigure 5. Balanced Dataset Visualization\n4. Proposed Methods\nBERT is a language model that is based on transformers. The speciality of BERT is\nthat it is fully bidirectional. Traditional models scan texts from left to right or right to\nleft. But BERT can scan the text from both sides at the same time [18]. For example,\nprevious models might assume \"bank deposit\" and \"riverbank\" as linked to the word\n\"bank.\" But due to the bidirectional property of BERT, it is now possible to derive\ndeeper meanings from cognates such as these. BERT is a pre-trained model that has\nbeen previously trained from unlabelled Wikipedia (2500M Words) and Book corpus\n5\n(800M Words) [23]. We can use transfer learning [24] to train the BERT model with our\nvulnerability detection dataset for programming language. To do this, we have used some\npre-processing techniques to convert the source code into specific formats and then added\ndeep layers to develop the deep transition architecture of the BERT training model. The\npre-processing and feature extraction techniques are described below.\nTokenization: Computers do not understand any language. It mainly understands\nthe numbers. To convert the language into numbers, the first step is tokenization. To-\nkenization mainly split the sentences into meaningful words. So we have proposed to\ntokenize the source code according to BERT specific format. As BERT is biredictional,\nit marks the beginning by [CLS] token and ending by [SEP] token. Then it starts tok-\nenization. As an example, a simple source code is shown below that can be tokenized.\nNormal Code:\nchar text [256]; gets (text );\nTokenized code:\n[ ’char ’ , ’ text ’ , ’##[’ , ’##25’ , ’##6’ , ’##]’ , ’##;’ , ’ gets ’ , ’##(’ ,\n’##text ’ , ’##)’ , ’##;’ ]\nPadding: Paddingmustbecompletedbeforetraininganydatasettoaspecificmodel.\nBERT only allows fixed length sentences as input. If the length of source code from the\ndataset is shorter than the fixed-length, some paddings will be added to fit in the fixed\nlength. BERT provides an artificial token [PAD] to add necessary padding.\nEncoding: The final step of pre-processing is token encoding. In this step, all the\ntokens will be converted into numbers. Every token will be converted into their corre-\nsponding unique id.\nHere is the final encoding output of thetokenization example:\n[25869 , 3793, 29634, 17788, 2575, 29636, 29628,\n4152, 29619, 18209, 29620, 29628]\n4.1. Architecture of the BERT model and our additional model:\nBERT is not trained on a vulnerability detection using the best appropriate dataset,\nwe have proposed to update the model by adding an additional model with some layers\nand train the whole model with vulnerability detection GitHub dataset. At first, we\ndiscussed the main BERT architecture and after that we presented our additional models\nwith updated layers and features.\nExisting BERT Architecture:BERT has mainly two different models. These are:\nBERT Base and BERT Large. BERT Base has 12 transformer blocks and BERT Large\nhas 24 transformer blocks. These transformer blocks are called encoders. Under the\nhood, these encoders have large feed-forward networks (768 and 1024), respectively [25].\nFigure 6 shows the BERT model architecture.\nIn BERT, the input sentences are the sum of the token, segment, and position embed-\ndings. After separating the sentences with a special token, learned embeddings indicated\nby E are added to check the belongings of the sentences. Figure 7 shows the input em-\nbeddings of the BERT model.\nBERT uses transformer which is an advanced attention mechanism used to learns\ncontextual comparison between words or sub-words in a text. Transformer has two dif-\nferent mechanisms in its basic form: an encoder that reads the text input and a decoder\nthat generates a job prediction. However, encoder technique is required because BERT’s\npurpose is to construct a model language [25].\nThe Transformer encoder is described in detail in Figure 6. The input is a sequence of\ntokens that are embedded into multi-vectors at the beginning of the neural network pro-\ncessor. The result is a sequence of H-dimensional into multi-vectors, each of the vectors\nhas a corresponding index linked to that input.\nTo train a BERT model, randomly, some percentage of the tokens are masked. This\nis called masked LM. Approximately about 15% there is a sequence in each word that\nis substituted with a [MASK token] before it is being processed into BERT. Based on\n6\nFigure 6. BERT model architecture [23]\nFigure 7. All Embeddings of BERT\nthe context that it is been provided by different studies, where most the sequence of\nwords are non-masked and during each process the model will attempts to predict the\noriginal value of the masked words. The output of the encoder has a classification layer\nwill be added to Transform the outcome vectors into the vocabulary dimension by using\nmultiplying them into embedding matrix. Soft-max also been used for calculating the\nprobability of each word [18]. Figure 8 shows the masked LM of BERT.\nFigure 8. Masked LM of BERT Model [25]\n4.2. Proposed advanced model architecture:\nWe have proposed adding some additional layers combined with a pre-trained BERT\nmodel. In the final updated model, there are three input layers.\nThese are: inputwordids, inputmask, andsegmentids.\n7\nIn the next position, there is a pre-trained BERT layer. Then we have added three\ndense layers. The first dense layer has 64 filters with a dropout [26] technique to reduce\nthe overfitting problem. The middle dense layer has 32 filters with dropouts. The final\ndense layer has 2 filters for two classes with a dropout technique. We have used the\nRectified linear unit (ReLu) [27] as an activation function for the first two layers. But\nfor final classification, the softmax function has been used. Equation 4.1 shows the\nprobability distribution of the class labels. Here P is the probability, C is the context\nvector that is the final hidden state corresponding to the first token [CLS]. W is the\nweight and T is the numerical tokens.\nP = softmax(CW T ) (4.1)\nWe have used the categorical cross-entropy formula to calculate the loss of our pro-\nposed model. Figure 7 shows our proposed updated model architecture for vulnerability\ndetection. After adding our proposed additional layers, we have successfully trained the\nsource code vulnerability dataset and improved accuracy. Our updated model can be\nexpressed by a summary of architecture also. Figure 9 shows the model summary.\nFigure 9. Advanced Vulnerability detection model architecture\nFinally, we have fine-tuned our updated model by finding optimal parameters, re-\nvealed in Table 4 below.\nTable 4. The parameters for training our advanced model\nParameters Name Values\nLearning Rate 2e-5\nBatch Size 64\nEpoch 10\n8\nFigure 10. Advanced Model Summary\n5. Experimental Setup and Result Analysis\nExperimental environment: Training a BERT-based model is a very resource-\nconsuming task, and it takes much time. The experimental environment has an Intel\nCore i9 processor, a Tesla k80 GPU, and 12 GB of RAM. As a result of this experimental\nenvironment, training time has been reduced while performance has improved.\nTraining, validation, and testing experiment: We have splitted the whole\ndataset to three types of experiment. These are: training, validation, and testing. Train-\ning dataset is for training the model; validation dataset mainly validates the accuracy\nbefore final testing, and testing dataset is used for testing the model accuracy. Test\ndataset is 0.2% of the whole dataset and the validation dataset is 0.2% of the training\ndataset. Thus we have updated the BERT model and fine tuned the model for better\nperformance. Table 5 shows the distribution of training, validation,and testing dataset\nnumbers.\nTable 5. Training, validation, and testing dataset\nDataset Training Validation Testing\nGithub 158629 39657 49572\nExperimental Result Analysis:After 4 hours of training our proposed model, we\nachieved the new state-of-the-art accuracy for source code vulnerability detection. Table\n6 shows the final result of our experiment for training, validation, and testing.\nTable 6. Final accuracy for training, validation, and testing\nTraining Validation Testing\n99.80% 99.34% 99.30%\nFigure 11, below, shows the training versus validation accuracy curve and Figure 10\nshows the training versus validation loss curve.\n9\nFigure 11. Training Vs Validation Accuracy Curve\nFigure 12. Training Vs Validation Loss Curve\nAfter getting the result, we compared our result with previous researcher results. It\nis important to match the dataset also while comparing the result with previous research\nexperiments. We have found two research papers for comparison. Table 7 shows the\ncomparison of test results with previous experiments.\nTable 7. Test result comparison\nRNN+LSTM [17] Bi-LSTM [28] BERT + Proposed Model\n81.4% 94.3% 99.30%\nFrom table 7, we can easily understand that a pre-trained BERT based customized\nNLP model can outperform previous deep learning models like RNN, LSTM, and Bi-\nLSTM . As BERT is already pre trained using millions of texts and can understand the\nmeaning of different kinds of sentences, thus BERT has achieved the state of the art\naccuracy than other models.\n6. Conclusion\nIn our research, we balanced the Github dataset and successfully developed a new\nBERT-based source code vulnerability detection model. BERT was not designed for pro-\ngramming language related tasks rather it was designed for human language related tasks\npreviously but we have added an additional model with BERT and train the updated\nmodel again for vulnerability detection. As a result, we have achieved the new state of\nthe art result which is 99.30% for some vulnerability detection. But due to some limi-\ntation of powerful computing resources, we have not added all vulnerabilities. In future,\nwe are working on more vulnerabilities and programming languages also. Our updated\nmodel can be also used by other researchers and engineers for developing vulnerability\ndetection software or further improvement.\nReferences\n[1] “SonarQube Vulnerability Detection”. inAccessed: 2021-06-12:url: https:\n//www.sonarqube.org.\n[2] “Brakemen Vulnerability Checker”. inAccessed: 2021-06-12: url: https :\n//brakemanscanner.org/.\n10\n[3] R. Mahmood and Q. Mahmoud. “Evaluation of Static Analysis Tools for\nFindingVulnerabilitiesinJavaandC/C++SourceCode”. inArXiv:abs/1805.09040\n(2018).\n[4] X. Yang, J. Chen, R. Yedida, Z. Yu and T. Menzies. “How to Recog-\nnize Actionable Static Code Warnings (Using Linear SVMs)”. inArXiv:\nabs/2006.00444 (2020).\n[5] L. Mou, G. Li, Z. Jin, L. Zhangand T. Wang. “TBCNN: A Tree-Based Con-\nvolutionalNeuralNetworkforProgrammingLanguageProcessing”. inArXiv:\nabs/1409.5718 (2014).\n[6] A. Vaswani, N. M. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, L. Kaiserand I. Polosukhin. “Attention is All you Need”.inArXiv:\nabs/1706.03762 (2017).\n[7] L. Kaiser, A. N. Gomez, N. M. Shazeer, A. Vaswani, N. Parmar, L. Jones\nand J.Uszkoreit.“OneModelToLearnThemAll”. inArXiv:abs/1706.05137\n(2017).\n[8] L. Kaiser, A. N. Gomezand F. Chollet. “Depthwise Separable Convolutions\nfor Neural Machine Translation”.inArXiv: abs/1706.03059 (2018).\n[9] J. N. D. Guptaand S. Sushil. “Threat Modeling and Secure Software Engi-\nneeringProcess”. inInformation Security and Assurance:2008, pages 415–422.\ndoi: 10.4018/978-1-59904-855-0.ch009 .\n[10] S. A. Mokhov, J. Paquetand M. Debbabi. “The Use of NLP Techniques in\nStaticCodeAnalysistoDetectWeaknessesandVulnerabilities”. inCanadian\nConference on AI: 2014.\n[11] M. Arroyo, F. Chiotta and F. Bavera. “An user configurable clang static\nanalyzertaintchecker”. in2016 35th International Conference of the Chilean\nComputer Science Society (SCCC): 2016,pages 1–12. doi: 10.1109/SCCC.\n2016.7835996.\n[12] S.-X. Lu, J. Meng and G.-E. Cao. “Support vector machine based on a\nnew reduced samples method”. in2010 International Conference on Ma-\nchine Learning and Cybernetics: volume 3. 2010, pages 1510–1514. doi:\n10.1109/ICMLC.2010.5580828.\n[13] A. Alahmadi, A. Joorabchi and A. E. Mahdi. “A new text representation\nscheme combining Bag-of-Words and Bag-of-Concepts approaches for auto-\nmatic text classification”.in2013 7th IEEE GCC Conference and Exhibition\n(GCC): 2013,pages 108–113. doi: 10.1109/IEEEGCC.2013.6705759.\n[14] Cppcheck. inAccessed: 2021-04-12:url: http://cppcheck.sourceforge.\nnet.\n[15] “WheeleFlawfinder”. inAccessed:2021-04-12: url:https://www.dwheeler.\ncom/flawfinder/.\n[16] R. Russell, L. Kim, L. Hamilton, T. Lazovich, J. Harer, O. Ozdemir, P.\nEllingwood and M.McConley.“AutomatedVulnerabilityDetectioninSource\nCode Using Deep Representation Learning”. in2018 17th IEEE Interna-\ntional Conference on Machine Learning and Applications (ICMLA): 2018,\npages 757–762. doi: 10.1109/ICMLA.2018.00120.\n[17] W. Z. L. H. Guo J. “Detecting vulnerability in source code using CNN and\nLSTM network. Soft Comput”.in2021: doi: 10.1007/s00500-021-05994-\nw.\n[18] J. Devlin, M.-W. Chang, K. Leeand K. Toutanova.BERT: Pre-training of\nDeep Bidirectional Transformers for Language Understanding. 2019. arXiv:\n1810.04805 [cs.CL].\n[19] M. Munikar, S. Shakyaand A. Shrestha. “Fine-grained Sentiment Classifi-\ncation using BERT”.in2019 Artificial Intelligence for Transforming Busi-\nness and Society (AITB): 1 (2019),pages 1–5.\n[20] Y.-H. Chan and Y.-C. Fan. “A Recurrent BERT-based Model for Question\nGeneration”. inMRQA@EMNLP: 2019.\n11\n[21] M. Alqarni and A. Azim. “Software Source Code Vulnerability Detection\nUsing Advanced Deep Convolutional Neural Network”.inProceedings of the\n31st Annual International Conference on Computer Science and Software\nEngineering: CASCON ’21. Toronto, Canada: IBM Corp., 2021, 226–231.\n[22] Github. “Github”. inurl: https://github.com.\n[23] D.Deepa.“BidirectionalEncoderRepresentationsfromTransformers”. in2021:\ndoi: 10.17762/turcomat.v12i7.3055.\n[24] S. Bozinovski. “Reminder of the First Paper on Transfer Learning in Neural\nNetworks, 1976”.inInformatica (Slovenia): 44 (2020).\n[25] “TheIllustratedBERT,ELMo,andco.” inAccessed:2021-06-22: url:http:\n//jalammar.github.io/illustrated-bert/.\n[26] N. Srivastava, G. E. Hinton, A. Krizhevsky, I. Sutskeverand R. Salakhut-\ndinov. “Dropout: a simple way to prevent neural networks from overfitting”.\ninJ. Mach. Learn. Res.: 15 (2014),pages 1929–1958.\n[27] V. Nair and G. E. Hinton. “Rectified Linear Units Improve Restricted\nBoltzmann Machines”.inICML: 2010.\n[28] G. Tang, L. Yang, S. Ren, L. Meng, F. Yangand H. Wang. “An Auto-\nmatic Source Code Vulnerability Detection Approach Based on KELM”.\ninSecurity and Communication Networks: 2021 (2021).",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.597582221031189
    },
    {
      "name": "Code (set theory)",
      "score": 0.596462070941925
    },
    {
      "name": "Vulnerability (computing)",
      "score": 0.5627418756484985
    },
    {
      "name": "Programming language",
      "score": 0.35172000527381897
    },
    {
      "name": "Computer security",
      "score": 0.26538580656051636
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I39470171",
      "name": "Ontario Tech University",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I4210161785",
      "name": "First Technical University",
      "country": "NG"
    }
  ],
  "cited_by": 9
}