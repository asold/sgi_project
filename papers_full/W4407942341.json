{
    "title": "How the Choice of LLM and Prompt Engineering Affects Chatbot Effectiveness",
    "url": "https://openalex.org/W4407942341",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A3007714585",
            "name": "Lukasz Pawlik",
            "affiliations": [
                "Kielce University of Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4378909214",
        "https://openalex.org/W4361750421",
        "https://openalex.org/W4396513350",
        "https://openalex.org/W3166797128",
        "https://openalex.org/W3200957432",
        "https://openalex.org/W4400397477",
        "https://openalex.org/W4390639297",
        "https://openalex.org/W4402683797",
        "https://openalex.org/W4399450079",
        "https://openalex.org/W4404782999",
        "https://openalex.org/W3188212375",
        "https://openalex.org/W4285678515",
        "https://openalex.org/W4385195647"
    ],
    "abstract": "Modern businesses increasingly rely on chatbots to enhance customer communication and automate routine tasks. The research aimed to determine the optimal configurations of a telecommunications chatbot on the Rasa Pro platform, including the selection of large language models (LLMs), prompt formats, and command structures. The impact of various LLMs, prompt formats, and command precision on response quality was analyzed. Smaller models, like Gemini-1.5-Flash-8B and Gemma2-9B-IT, can achieve results comparable to larger models, offering a cost-effective solution. Specifically, the Gemini-1.5-Flash-8B model achieved an accuracy improvement of 21.62 points when using the JSON prompt format. This emphasizes the importance of prompt engineering techniques, like using structured formats (YAML, JSON) and precise commands. The study utilized a dataset of 400 sample test phrases created based on real customer service conversations with a mobile phone operatorâ€™s customers. Results suggest optimizing chatbot performance does not always require the most powerful models. Proper prompt preparation and data format choice are crucial. The theoretical framework focuses on the interaction between model size, prompt format, and command precision. Findings provide insights for chatbot designers to optimize performance through LLM selection and prompt construction. These findings have practical implications for businesses seeking cost-effective and efficient chatbot solutions.",
    "full_text": null
}