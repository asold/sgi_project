{
  "title": "Comparison of Large Language Models in Answering Immuno-Oncology Questions: A Cross-Sectional Study",
  "url": "https://openalex.org/W4388139918",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2665416131",
      "name": "Giovanni Maria Iannantuono",
      "affiliations": [
        "National Institutes of Health",
        "Center for Cancer Research",
        "National Cancer Institute"
      ]
    },
    {
      "id": "https://openalex.org/A4223093048",
      "name": "Dara Bracken-Clarke",
      "affiliations": [
        "National Institutes of Health",
        "Center for Cancer Research",
        "National Cancer Institute"
      ]
    },
    {
      "id": "https://openalex.org/A1694753115",
      "name": "Fatima Karzai",
      "affiliations": [
        "National Cancer Institute",
        "Center for Cancer Research",
        "National Institutes of Health"
      ]
    },
    {
      "id": "https://openalex.org/A801900682",
      "name": "Hyoyoung Choo-Wosoba",
      "affiliations": [
        "National Institutes of Health",
        "National Cancer Institute",
        "Center for Cancer Research"
      ]
    },
    {
      "id": "https://openalex.org/A1767924676",
      "name": "James L. Gulley",
      "affiliations": [
        "Center for Cancer Research",
        "National Institutes of Health",
        "National Cancer Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2420358557",
      "name": "Charalampos S. Floudas",
      "affiliations": [
        "National Cancer Institute",
        "Center for Cancer Research",
        "National Institutes of Health"
      ]
    },
    {
      "id": "https://openalex.org/A2665416131",
      "name": "Giovanni Maria Iannantuono",
      "affiliations": [
        "Center for Cancer Research",
        "National Institutes of Health",
        "National Cancer Institute"
      ]
    },
    {
      "id": "https://openalex.org/A4223093048",
      "name": "Dara Bracken-Clarke",
      "affiliations": [
        "National Institutes of Health",
        "National Cancer Institute",
        "Center for Cancer Research"
      ]
    },
    {
      "id": "https://openalex.org/A1694753115",
      "name": "Fatima Karzai",
      "affiliations": [
        "Center for Cancer Research",
        "National Cancer Institute",
        "National Institutes of Health"
      ]
    },
    {
      "id": "https://openalex.org/A801900682",
      "name": "Hyoyoung Choo-Wosoba",
      "affiliations": [
        "Data Management (Italy)",
        "National Institutes of Health",
        "Center for Cancer Research",
        "Cancer Institute (WIA)"
      ]
    },
    {
      "id": "https://openalex.org/A1767924676",
      "name": "James L. Gulley",
      "affiliations": [
        "National Cancer Institute",
        "National Institutes of Health",
        "Center for Cancer Research"
      ]
    },
    {
      "id": "https://openalex.org/A2420358557",
      "name": "Charalampos S. Floudas",
      "affiliations": [
        "National Cancer Institute",
        "Center for Cancer Research",
        "National Institutes of Health"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4367310920",
    "https://openalex.org/W2000471193",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4386423073",
    "https://openalex.org/W4210370153",
    "https://openalex.org/W2883210621",
    "https://openalex.org/W1966976587",
    "https://openalex.org/W4294214983",
    "https://openalex.org/W4292229870",
    "https://openalex.org/W4361298490",
    "https://openalex.org/W4318263917",
    "https://openalex.org/W4380423243",
    "https://openalex.org/W4386730959",
    "https://openalex.org/W4386827842",
    "https://openalex.org/W4386894187",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4319083882",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W4385647263",
    "https://openalex.org/W4386033569",
    "https://openalex.org/W4386110374",
    "https://openalex.org/W4387393234",
    "https://openalex.org/W4387326101",
    "https://openalex.org/W4387128076",
    "https://openalex.org/W4385900159",
    "https://openalex.org/W2599076725",
    "https://openalex.org/W2903686952"
  ],
  "abstract": "ABSTRACT Background The capability of large language models (LLMs) to understand and generate human-readable text has prompted the investigation of their potential as educational and management tools for cancer patients and healthcare providers. Materials and Methods We conducted a cross-sectional study aimed at evaluating the ability of ChatGPT-4, ChatGPT-3.5, and Google Bard to answer questions related to four domains of immuno-oncology (Mechanisms, Indications, Toxicities, and Prognosis). We generated 60 open-ended questions (15 for each section). Questions were manually submitted to LLMs, and responses were collected on June 30th, 2023. Two reviewers evaluated the answers independently. Results ChatGPT-4 and ChatGPT-3.5 answered all questions, whereas Google Bard answered only 53.3% (p &lt;0.0001). The number of questions with reproducible answers was higher for ChatGPT-4 (95%) and ChatGPT3.5 (88.3%) than for Google Bard (50%) (p &lt;0.0001). In terms of accuracy, the number of answers deemed fully correct were 75.4%, 58.5%, and 43.8% for ChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (p = 0.03). Furthermore, the number of responses deemed highly relevant was 71.9%, 77.4%, and 43.8% for ChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (p = 0.04). Regarding readability, the number of highly readable was higher for ChatGPT-4 and ChatGPT-3.5 (98.1%) and (100%) compared to Google Bard (87.5%) (p = 0.02). Conclusion ChatGPT-4 and ChatGPT-3.5 are potentially powerful tools in immuno-oncology, whereas Google Bard demonstrated relatively poorer performance. However, the risk of inaccuracy or incompleteness in the responses was evident in all three LLMs, highlighting the importance of expert-driven verification of the outputs returned by these technologies. IMPLICATIONS FOR PRACTICE Several studies have recently evaluated whether large language models may be feasible tools for providing educational and management information for cancer patients and healthcare providers. In this cross-sectional study, we assessed the ability of ChatGPT-4, ChatGPT-3.5, and Google Bard to answer questions related to immuno-oncology. ChatGPT-4 and ChatGPT-3.5 returned a higher proportion of responses, which were more accurate and comprehensive, than those returned by Google Bard, yielding highly reproducible and readable outputs. These data support ChatGPT-4 and ChatGPT-3.5 as powerful tools in providing information on immuno-oncology; however, accuracy remains a concern, with expert assessment of the output still indicated.",
  "full_text": "1 \n \nComparison of Large Language Models in Answering 1 \nImmuno-Oncology Questions: A Cross-Sectional Study 2 \n 3 \n 4 \nGiovanni Maria Iannantuono, MD1†, Dara Bracken-Clarke, MD2†, Fatima Karzai, MD1, 5 \nHyoyoung Choo-Wosoba, PhD3, James L. Gulley, MD, PhD2,  6 \nCharalampos S. Floudas, MD, DMSc, MS2. 7 \n 8 \n 9 \n1Genitourinary Malignancies Branch, Center for Cancer Research, National Cancer Institute, National 10 \nInstitutes of Health, Bethesda, MD, United States. 11 \n 12 \n2Center for Immuno-Oncology, Center for Cancer Research, National Cancer Institute, National Institutes 13 \nof Health, Bethesda, MD, United States. 14 \n 15 \n3Biostatistics and Data Management Section, Center for Cancer Research, National Cancer Institute, 16 \nNational Institutes of Health, Bethesda, MD, United States. 17 \n 18 \n 19 \n†These authors contributed equally to this work 20 \n 21 \n 22 \nCorresponding Author: 23 \n 24 \nCharalampos S. Floudas, MD, DMSc, MS 25 \nCenter for Immuno-Oncology, Center for Cancer Research, National Cancer Institute 26 \n10 Center Drive, Bethesda, MD, 20892. 27 \nBuilding 10, Room 7N240A 28 \nTel: 240-858-3032 - Email: charalampos.floudas@nih.gov 29 \n 30 \nRunning Head Title: LARGE LANGUAGE MODELS IN IMMUNO-ONCOLOGY 31 \n 32 \nKeywords: Large language models; Artificial intelligence; Immuno-oncology; ChatGPT; 33 \nGoogle Bard. 34 \n 35 \nAuthor Contributions 36 \nIannantuono GM: Conception/Design; Provision of study material; Collection and/or assembly 37 \nof data; Data analysis and interpretation; Manuscript writing; Final approval of manuscript. 38 \nBracken-Clarke D: Conception/Design; Provision of study material; Collection and/or assembly 39 \nof data; Data analysis and interpretation; Manuscript writing; Final approval of manuscript. 40 \nKarzai F: Manuscript writing; Final approval of manuscript. 41 \nChoo-Wosoba H: Data analysis and interpretation; Manuscript writing; Final approval of 42 \nmanuscript. 43 \nGulley JL: Manuscript writing; Final approval of manuscript. 44 \nFloudas CS: Conception/Design; Data analysis and interpretation; Manuscript writing; Final 45 \napproval of manuscript. 46 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n2 \n \nABSTRACT 47 \n 48 \nBackground: The capability of large language models (LLMs) to understand and generate human-49 \nreadable text has prompted the investigation of their potential as educational and management 50 \ntools for cancer patients and healthcare providers.  51 \nMaterials and Methods: We conducted a cross-sectional study aimed at evaluating the ability of 52 \nChatGPT-4, ChatGPT -3.5, and Google Bard  to answer questions related to four domains of 53 \nimmuno-oncology (Mechanisms, Indications, Toxicities, and Prognosis). We generated 60 open -54 \nended questions (15 for each section). Questions were manually submitted to LLMs, and responses 55 \nwere collected on June 30th, 2023. Two reviewers evaluated the answers independently.  56 \nResults: ChatGPT-4 and ChatGPT -3.5 answered all questions, whereas Google Bard  answered 57 \nonly 53.3% (p <0.0001). The number of questions with reproducible answers was higher for 58 \nChatGPT-4 (95%) and ChatGPT3.5 (88.3%) than for Google Bard (50%) (p <0.0001). In terms of 59 \naccuracy, the number of answers deemed fully correct were 75.4%, 58.5%, and 43.8% for 60 \nChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (p = 0.03). Furthermore, the number of 61 \nresponses deemed highly relevant was 71.9%, 77.4%, and 43.8% for ChatGPT -4, ChatGPT-3.5, 62 \nand Google Bard, respectively (p = 0.04). Regarding readability, the number of highly readable 63 \nwas higher for ChatGPT -4 and ChatGPT -3.5 (98.1% ) and (100%) compared to Google Bard 64 \n(87.5%) (p = 0.02). 65 \nConclusion: ChatGPT-4 and ChatGPT -3.5 are potentially powerful tools in immuno-oncology, 66 \nwhereas Google Bard demonstrated  relatively poorer performance. However,  the risk of 67 \ninaccuracy or incompleteness in the responses was evident in all three LLMs, highlighting the 68 \nimportance of expert-driven verification of the outputs returned by these technologies.  69 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n3 \n \nIMPLICATIONS FOR PRACTICE 70 \nSeveral studies have recently evaluated whether large language models may be feasible tools for 71 \nproviding educational and management information for cancer patients and healthcare providers.  72 \nIn this cross -sectional study, we assessed the ability of ChatGPT -4, ChatGPT-3.5, and Google 73 \nBard to answer questions related to immuno-oncology. ChatGPT-4 and ChatGPT-3.5 returned a 74 \nhigher proportion of responses, which were more accurate and comprehensive, than those returned 75 \nby Google Bard, yielding highly reproducible and readable outputs. These data support ChatGPT-76 \n4 and ChatGPT -3.5 as powerful tools in providing information on immuno-oncology; however, 77 \naccuracy remains a concern, with expert assessment of the output still indicated. 78 \n 79 \n 80 \n 81 \n 82 \n 83 \n 84 \n 85 \n 86 \n 87 \n 88 \n 89 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n4 \n \n1. INTRODUCTION 90 \nLarge language models (LLMs) are a recent breakthrough in the domain of generative artificial 91 \nintelligence (AI) (1).  Generative AI includes technologies based on “natural language processing” 92 \n(NLP) which uses computational linguistics and deep learning  (DL) algorithms to enable 93 \ncomputers to interpret and generate human -like text  (2). Large language models are complex 94 \nsystems trained on large quantities of text data which are able to create new content in response to 95 \nprompts such as text, images, or other media  (3). This versatility has led to the investigation of 96 \ntheir potential application s in the field of medicine and healthcare  in light of its self -evident 97 \npotential benefits in these domains  (4). Indeed, the availability of user -friendly tools able to 98 \nprovide detailed, accurate and current  information would be  crucial in promoting patient  and 99 \nhealthcare providers’  education and awareness, particularly in the case of complex health 100 \nconditions like cancer (5). 101 \n 102 \nThus far, many studies have assessed the potential of ChatGPT, an advanced LLM based on a 103 \ngenerative pre-trained transformer (GPT) architecture, for providing screening and/or management 104 \ninformation in solid tumors (6). Following the rollout of ChatGPT, more LLMs trained on different 105 \ndata were released, expanding the selection of these new AI -based tools.  Consequently, a n 106 \nincreasing number of studies are investigating and comparing the potential ability of ChatGPT 107 \nwith other LLMs as easy-to-use interfaces to gather information related to a specific cancer-related 108 \ntopic (7). So far,  initial evidence suggests a possible role of these  technologies as “virtual 109 \nassistants” for healthcare professionals and patients  in providing information about cancer, 110 \nunfortunately counterbalanced by a significant error rate. Therefore, further studies are needed to 111 \ninvestigate the potential applicability of these tools in other fields (7). 112 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n5 \n \nThe past several years have seen profound  changes in the field of immuno -oncology (IO). The 113 \nadvent of immune-checkpoint inhibitors (ICIs) has paved the way  towards a new era in cancer 114 \ntreatment, enhancing the chance of long -term survival in patients with metastatic disease, and 115 \nproviding new treatment options in earlier-stage settings (8). Presently, an increasing number of 116 \ncancer patients are either candidates for or already receiving ICIs or other immunotherapies, 117 \nsubject to both the enormous potential benefits but also the immune-related adverse events that 118 \nmay be caused by these treatments  (9). In this context, LLMs may represent a valid tool for 119 \nhealthcare professionals and patients (and their caregivers) receiving these treatments.  Therefore, 120 \nwe sought to assess and compare the ability of three prominent LLMs to provide educational and 121 \nmanagement information in the IO field.  122 \n 123 \n 124 \n 125 \n 126 \n 127 \n 128 \n 129 \n 130 \n 131 \n 132 \n 133 \n 134 \n 135 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n6 \n \n2. MATERIALS AND METHODS 136 \n2.1 Large language models 137 \nIn this cross -sectional study we compared the performance of three LLMs : ChatGPT-3.5 (10), 138 \nChatGPT-4 (10), and Google Bard (11). ChatGPT is an LLM based on the GPT architecture and 139 \ndeveloped by OpenAI, a company based in San Francisco  (USA). ChatGPT is built upon either 140 \nGPT-3.5 and GPT-4; the former is freely available to all the users, whereas the latter is an advanced 141 \nversion with additional features and provided under the name “ChatGPT Plus” to paid subscribers 142 \n(10). Google Bard is based on the Pathways Language Model (PaLM) family of LLMs, developed 143 \nby GoogleAI (11).  144 \n 145 \n2.2 Questions and responses’ generation 146 \nWe generated 60 open-ended questions based on our clinical experience covering four different 147 \ndomains of IO  including “mechanisms” (of action) , “indications” (for use) , “toxicities”, and 148 \n“prognosis” (Suppl. Mat. A). In order to standardize assessment, particularly of “relevance” and 149 \n“accuracy”, and to reduce bias, a sample answer for each question was generated a priori prior to 150 \nquestion submission. Questions were manually and directly submitted to the web chat interfaces 151 \nof the three above-mentioned LLMs on June 30th 2023 and responses were collected (Suppl. Mat. 152 \nB). We assessed the reproducibility, accuracy, relevance, and readability (Table 1) of responses 153 \nprovided by each LLM. Two reviewers (GMI and DBC) rated the answers independently. During 154 \nthe rating process, reviewers were blinded to the LLM being assessed. Inconsistencies between the 155 \nreviewers were discussed with an additional reviewer (CSF) and resolved by consensus.  Cohen's 156 \nkappa coefficient was calculated to evaluate inter-rater reliability during the rating process (12). 157 \n 158 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n7 \n \nFirst, we assessed the ability of each LLM to provide reproducible responses . Therefore, each 159 \nindividual question was submitted three times  on each LLM . In the case of non-reproducible 160 \nanswers, questions were not considered for further analysis. Subsequently, the accuracy, relevance, 161 \nand readability of responses deemed reproducible were assessed using a 3 -point scale ( Table 2) 162 \n(Figure 1). Reviewers graded the accuracy of answers according to available information as of 163 \n2021, as the training datasets of ChatGPT are updated to September 2021 . Finally, word- and 164 \ncharacter-counts were calculated for each answer. 165 \n 166 \n2.3 Statistical analyses  167 \nCategorical variables were presented with proportions and numeric variables as measures of 168 \ncentral tendency . Comparisons between categorical variables were performed with two -sided 169 \ngeneralized Fisher's exact tests for testing any potential differences in these three LLMs. In the 170 \ncase of numeric continuous variables, a Kruskal-Wallis test was utilized. Statistical tests were not 171 \nperformed within each of the four domains, but  rather were performed only to evaluate overall 172 \nperformance by combining those four domains , due to insufficient sample sizes within each 173 \ndomain (i.e., only up to 15 available observations). All statistical results should be interpreted as 174 \nexploratory; all statistical analyses were performed and all plots generated using R version 4.2.2 175 \n(The R Foundation for Statistical Computing, 2022). This study was conducted in accordance with 176 \nStrengthening the  Reporting of Observational Studies in Epidemiology (STROBE) reporting 177 \nguidelines (13). 178 \n 179 \n 180 \n 181 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n8 \n \n3. RESULTS 182 \nAssessment of inter -rater reliability with Cohen’s kappa during the rating process  demonstrated 183 \n“strong” to “near perfect ” agreement between reviewers (Suppl. Mat . C). ChatGPT-3.5 and 184 \nChatGPT-4 provided at least one response to all questions  (60 [100%]) , while Google Bard 185 \nresponded only to 32 (53.3%) queries (p <0.0001) . Specifically, t he percentages of responses 186 \nprovided by Google Bard were different across the four domains, with better performances in the 187 \n\"mechanisms” (14 [93.3%]) and “prognosis” domains (13 [86.7%]) compared to the “indications” 188 \n(5 [33.3%] ), and “toxicities” (0 [0%]) domains. Regarding reproducibility, t he numbers of 189 \nquestions with reproducible answers were similar between ChatGPT-3.5 and ChatGPT-4 (53 190 \n[88.3%] and 57 [95%], respectively), while it was lower (16 [50%]) for Google Bard (p <0.0001). 191 \nAlthough ChatGPT-3.5 and ChatGPT-4 performed similarly across all domains, ChatGPT-4 192 \nachieved 100% reproducible responses in two domains (“mechanisms” and “indications”) in which 193 \nChatGPT-3.5 achieved only 86.7%. Google Bard was variably capable and accurate across the 194 \ndifferent sections . Despite a significant number of answers deemed reproducible in the 195 \n“mechanisms” (6 [40%]) and “prognosis” (9 [60%]) sections, a poor performance was observed 196 \nin the “indications” (1 [6.7%]) and “toxicities” (0 [0%]) domains (Figure 2). In terms of accuracy, 197 \nthe numbers of answers deemed fully correct were 31 (58.5%), 43 (75.4%), and 7 (43.8%) for 198 \nChatGPT-3.5, ChatGPT-4 and Google Bard, respectively ( p = 0.03 ). Furthermore, regarding 199 \nrelevancy, the numbers of responses deemed highly relevant were 41 (77.4%), 41 (71.9%), and 7 200 \n(43.8%) for ChatGPT-3.5, ChatGPT-4 and Google Bard, respectively (p = 0.04). Readability was 201 \ndeemed optimal across all three LLMs. However, the number s of highly readable answers were 202 \ngreater for ChatGPT-3.5 and ChatGPT-4 (52 [98.1%] and 57 [100%]) compared to Google Bard 203 \n(14 [87.5%]) (p = 0.02) (Figure 3). The median numbers of words and their corresponding ranges 204 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n9 \n \nfor the responses provided by ChatGPT-3.5, ChatGPT-4, and Google Bard were 297 (197 - 404), 205 \n276 (139 - 395), and 290.5 (12 - 424), respectively (p = 0.06). Finally, the median number s of 206 \ncharacters and their corresponding ranges were 1829 (1119 - 2470), 1589 (854 - 2233), and 1532 207 \n(75 - 2070), respectively (p <0.0001). 208 \n 209 \n 210 \n 211 \n 212 \n 213 \n 214 \n 215 \n 216 \n 217 \n 218 \n 219 \n 220 \n 221 \n 222 \n 223 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n10 \n \n4. DISCUSSION 224 \nIn recent decades, significant effort has been made to harness the potential of AI in medicine and 225 \nhealthcare (14). Artificial intelligence can be defined as “the science and engineering of making 226 \nintelligent machines, especially intelligent computer program s” (15). It is composed of  multiple 227 \nsubfields, based on different algorithms and principles, including knowledge representation, 228 \nmachine learning (ML), DL, and NLP (2,16). Specifically, NLP uses computational language and 229 \nDL to enable computers to understand text in the same way as humans (2). Recent progress in NLP 230 \nhas led to major breakthroughs in the field of generative AI, as evidenced by the advent of LLMs 231 \n(3). The se can recognize,  summarize and generate novel content using statistical connections 232 \nbetween letters and words. Indeed, LLMs can also be considered  as “few shot learners” due to 233 \ntheir ability to readily adapt to new domains with few information after being trained (17). 234 \n 235 \nOver the last year, the release of ChatGPT (10) has attracted considerable attention, which only 236 \nincreased following the release of other LLMs such as  Google B ard (11), Bing AI  (18) and, 237 \nPerplexity (19). The remarkable adaptability of these AI -based technologies  to a broad and  238 \nextensive range of disciplines was immediately apparent following their introduction (20). This is 239 \nalso evidenced by the rapid publication of large numbers of studies designed to investigate their 240 \nrole in multiple and diffuse fields , including medicine and healthcare. Initial data have 241 \ndemonstrated LLMs to be highly applicable to  the field of cancer care, especially in providing 242 \ninformation about the screening and/or management of specific solid tumors (7). However, to the 243 \nauthors’ knowledge, their potential role in the field of IO has not yet been investigated, despite the 244 \nrapidly expanding knowledge in all the aspects of IO ( basic, translational, and clinical research ) 245 \nand the large number of cancer patients currently receiving immunotherapy (8,9). 246 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n11 \n \nTherefore, we performed a cross-sectional study aimed for the first time at assessing the potential 247 \nof three prominent LLMs in answering questions about the field of IO. Our res ults demonstrated 248 \nthat ChatGPT -4 and ChatGPT -3.5 were able to answer most of the  IO-related questions with 249 \nexcellent accuracy and relevance. In contrast, the performance of Google Bard was comparatively 250 \npoorer, as shown by a lower number of both answered questions and the reproducibility/accuracy 251 \nof these responses, compared to the other two LLMs. All three LLMs were able to provide highly 252 \nreadable responses, highlighting the power of these generative AI technologies in providing 253 \nhuman-readable text. ChatGPT (both v3.5 and v4) clearly demonstrated their potential as a “virtual 254 \nassistant” for both clinicians and patients or caregivers. ChatGPT (both v3.5 and, especially, v4)  255 \nhas also demonstrated remarkable acumen in both  diagnosing and providing management plans 256 \nfor IO toxicities . It has also proved highly effective  in suggesting evidence -based and licensed 257 \nindications for IO therapy, either alone or in combination . Additionally, it has demonstrable 258 \nefficacy in providing background information on IO drug mechanisms and disease prognoses in 259 \ngenerally comprehensible text without excess jargon, albeit often with a lack of sources and broken 260 \nor inaccurate references. 261 \n 262 \nHowever, the results of this study also highlight the differing performance of various LLMs across 263 \ntopics and specific tasks (Table 3) , as this demonstrate s significant variability . In our study,  264 \nChatGPT is demonstrated to be a powerful tool  when applied to  the field of IO , particularly in 265 \ncomparison to Google Bard. Similar results were also reported in another recently published study 266 \nassessing these three LLMs in a different cancer-related topic. Specifically, Rahsepar et al . 267 \nreported the results of a study investigating the ability of ChatGPT-3.5, ChatGPT-4 and Google 268 \nBard in answering questions related to lung cancer screening and prevention (21). As in our study, 269 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n12 \n \nChatGPT achieved a superior  performance to Google Bard . However,  the available evidence 270 \nsuggests that the LLM developed by OpenAI is not always accurate , as shown by the  results of 271 \nother studies investigating medical/healthcare topics other than cancer (Table 3). In the studies 272 \npublished by Seth et al., Zúñiga Salazar et al. and Dhanvijay et al., Google Bard performed better 273 \nin comparison to ChatGPT in non-cancer domains, likely clarifying a potential role for this LLM 274 \n(22–24). Furthermore, the results of the study by Al-Ashwal et al. showed a better performance 275 \nfor Bing AI in answering questions related to drug -drug interactions in comparison to the other 276 \nLLMs (25). Therefore, it is essential to compare the performance of different LLMs since their 277 \nabilities may vary based on both task and domain. 278 \n 279 \nIn addition, despite the promising results of our study and its unequivocal efficacy in synthesizing 280 \nand evaluating textual data, the potential of ChatGPT for error and hallucination remains (26). The 281 \noccurrence of “hallucinations” is one of the greatest obstacles to the routine clinical application of 282 \nLLMs.  While potentially tolerable in other domains, this is  a critical issue in medicine and the 283 \nbiomedical sciences due to its potential to directly impact patient care. In addition, it must be noted 284 \nthat the datasets on which these models were trained were: (i) confidential and proprietary (thus 285 \nimpossible to assess for data quality or bias), (ii) not specifically selected ab initio for addressing 286 \nbiomedical issues  and (iii) only valid up to September 2021 (thus lacking up to date information 287 \n– a major issue in so rapidly evolving a field as medicine in general and IO in particular) (10,27). 288 \nTherefore, expert assessment of LLMs’ output remains a prerequisite for their clinical use.  289 \n 290 \nOpen-source LLMs trained on specific biomedical datasets in order to accomplish pre -specified 291 \ntasks offer a potential solution and alternative paradigm. BioGPT, a cutting-edge LLM with a user-292 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n13 \n \nfriendly interface developed for the biomedical field, represents an excellent example of this (28). 293 \nBioGPT shares the same architecture as OpenAI’s GPT models but was trained on information 294 \nderived from the biomedical literature. It has demonstrated excellent performance in several tasks, 295 \nincluding text generation and categorization, due to  its extensive pre -training on massive 296 \nbiomedical datasets  (28). Further studies to investigate the utility and performance  of LLMs 297 \ndeveloped on biomedical data , with comparison to those LLMs presently available, are, thus, 298 \nrequired. 299 \n 300 \n4.1 Limitations 301 \nOur study has some limitations that need to be mentioned. Firstly, we have focused only on three 302 \nprominent LLMs, excluding other LLMs including BingAI and Perplexity . At the time of the 303 \ndesign of this study, ChatGPT and Google Bard were the most investigated LLMs  and, thus, we 304 \nelected to fo cus on them. However, recent evidence has shown the potential of BingAI in the 305 \nbiomedical field. Therefore, our results do  not represent the entire spectrum of LLMs available  306 \nand further assessment of other LLMs in the field of IO is essential . Secondly, the rating process 307 \nof the answers was made by only two reviewers. However, while a third reviewer was available to 308 \nresolve any conflicts which arose, this proved unnecessary as a strong to near perfect agreement 309 \nwas demonstrated between the two reviewers  Finally, the number of open-ended questions 310 \nincluded was relatively small, which may have impacted the analysis, particularly for domain-311 \nspecific performance. 312 \n 313 \n 314 \n 315 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n14 \n \n5. CONCLUSION 316 \nChatGPT-3.5 and ChatGPT -4 have demonstrated significant and clinically meaningful utility as 317 \ndecision- and research-aids in various subfields of IO, while Google Bard demonstrated significant 318 \nlimitations, especially in comparison to ChatGPT . However, the risk of inaccurate or incomplete 319 \nresponses was evident in all LLMs, highlighting the importance of an expert-driven verification of 320 \nthe information provided by these technologies. Finally, despite their potential to positively impact 321 \nthe field of medicine and healthcare, this study reinforced the significance of a human evaluation 322 \nof LLMs in order to create reliable tools for clinical use. 323 \n 324 \n 325 \n 326 \n 327 \n 328 \n 329 \n 330 \n 331 \n 332 \n 333 \n 334 \n 335 \n 336 \n 337 \n 338 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n15 \n \n Conflicts of Interest 339 \nAuthors declare no conflict of interest. 340 \n 341 \nCRediT Roles 342 \nConceptualization (GMI, DBC, CSF); Formal analysis (GMI and HCW); Investigation (GMI and 343 \nDBC); Methodology (GMI and DBC); Visualization (GMI and CSF); Writing - Original Draft 344 \n(GMI, DBC, HCW); Writing - Review & Editing (FK, JG, CSF); Supervision (CSF). All authors 345 \naccepted the final draft of the manuscript. 346 \n 347 \nData Availability Statement 348 \nThe data underlying this article are available in the article and in its online supplementary material. 349 \n 350 \nFunding 351 \nThis work was supported by the Intramural Research Program, National Institutes of Health, 352 \nNational Cancer Institute, Center for Cancer Research. The interpretation and reporting of these 353 \ndata are the sole responsibility of the authors. 354 \n 355 \n 356 \n 357 \n 358 \n 359 \n 360 \n 361 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n16 \n \nREFERENCES 362 \n 363 \n1. IBM. What is generative AI? [Internet]. 2021 [cited 2023 Oct 13]. Available from: 364 \nhttps://research.ibm.com/blog/what-is-generative-AI 365 \n2. IBM. What is Natural Language Processing? | IBM [Internet]. [cited 2023 Oct 15]. Available 366 \nfrom: https://www.ibm.com/topics/natural-language-processing 367 \n3. Birhane A, Kasirzadeh A, Leslie D, Wachter S. Science in the age of large language models. 368 \nNat Rev Phys [Internet]. 2023 [cited 2023 Oct 13];5(5). Available from: 369 \nhttps://ora.ox.ac.uk/objects/uuid:9eac0305-0a9a-4e44-95f2-c67ee9eae15c 370 \n4. Ayers JW, Poliak A, Dredze M, Leas EC, Zhu Z, Kelley JB, et al. Comparing Physician and 371 \nArtificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social 372 \nMedia Forum. JAMA Intern Med. 2023 Jun 1;183(6):589–96.  373 \n5. Risk A, Petersen C. Health information on the internet: quality issues and international 374 \ninitiatives. JAMA. 2002 May 22;287(20):2713–5.  375 \n6. Sallam M. ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic 376 \nReview on the Promising Perspectives and Valid Concerns. Healthc Basel Switz. 2023 Mar 377 \n19;11(6):887.  378 \n7. Iannantuono GM, Bracken-Clarke D, Floudas CS, Roselli M, Gulley JL, Karzai F. 379 \nApplications of large language models in cancer care: current evidence and future 380 \nperspectives. Front Oncol. 2023 Sep 4;13:1268915.  381 \n8. Johnson DB, Nebhan CA, Moslehi JJ, Balko JM. Immune-checkpoint inhibitors: long-term 382 \nimplications of toxicity. Nat Rev Clin Oncol. 2022 Apr;19(4):254–67.  383 \n9. Darvin P, Toor SM, Sasidharan Nair V, Elkord E. Immune checkpoint inhibitors: recent 384 \nprogress and potential biomarkers. Exp Mol Med. 2018 Dec 13;50(12):1–11.  385 \n10. OpenAI. What is ChatGPT? [Internet]. [cited 2023 Oct 13]. Available from: 386 \nhttps://help.openai.com/en/articles/6783457-what-is-chatgpt 387 \n11. Google. Try Bard, an AI experiment by Google [Internet]. [cited 2023 Oct 13]. Available 388 \nfrom: https://bard.google.com 389 \n12. McHugh ML. Interrater reliability: the kappa statistic. Biochem Medica. 2012;22(3):276–82.  390 \n13. von Elm E, Altman DG, Egger M, Pocock SJ, Gøtzsche PC, Vandenbroucke JP, et al. The 391 \nStrengthening the Reporting of Observational Studies in Epidemiology (STROBE) 392 \nstatement: guidelines for reporting observational studies. J Clin Epidemiol. 2008 393 \nApr;61(4):344–9.  394 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n17 \n \n14. Haug CJ, Drazen JM. Artificial Intelligence and Machine Learning in Clinical Medicine, 395 \n2023. N Engl J Med. 2023 Mar 30;388(13):1201–8.  396 \n15. McCarthy J. What Is Artificial Intelligence?  397 \n16. IBM. AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What’s the 398 \ndifference? [Internet]. 2023 [cited 2023 Oct 16]. Available from: 399 \nhttps://www.ibm.com/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks/ 400 \n17. Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P, et al. Language Models are 401 \nFew-Shot Learners [Internet]. arXiv; 2020 [cited 2023 Oct 16]. Available from: 402 \nhttp://arxiv.org/abs/2005.14165 403 \n18. Microsoft. Bing AI [Internet]. [cited 2023 Oct 17]. Available from: 404 \nhttps://www.bing.com:9943/search?showconv=1&q=bing AI&sf=codex3p&form=MA13FV 405 \n19. Perplexity AI. Perplexity [Internet]. [cited 2023 Oct 17]. Available from: 406 \nhttps://www.perplexity.ai/ 407 \n20. Thorp HH. ChatGPT is fun, but not an author. Science. 2023 Jan 27;379(6630):313.  408 \n21. Rahsepar AA, Tavakoli N, Kim GHJ, Hassani C, Abtin F, Bedayat A. How AI Responds to 409 \nCommon Lung Cancer Questions: ChatGPT vs Google Bard. Radiology. 2023 410 \nJun;307(5):e230922.  411 \n22. Seth I, Lim B, Xie Y, Cevik J, Rozen WM, Ross RJ, et al. Comparing the Efficacy of Large 412 \nLanguage Models ChatGPT, BARD, and Bing AI in Providing Information on Rhinoplasty: 413 \nAn Observational Study. Aesthetic Surg J Open Forum. 2023;5:ojad084.  414 \n23. Zúñiga Salazar G, Zúñiga D, Vindel CL, Yoong AM, Hincapie S, Zúñiga AB, et al. Efficacy 415 \nof AI Chats to Determine an Emergency: A Comparison Between OpenAI’s ChatGPT, 416 \nGoogle Bard, and Microsoft Bing AI Chat. Cureus. 2023 Sep;15(9):e45473.  417 \n24. Dhanvijay AKD, Pinjar MJ, Dhokane N, Sorte SR, Kumari A, Mondal H. Performance of 418 \nLarge Language Models (ChatGPT, Bing Search, and Google Bard) in Solving Case 419 \nVignettes in Physiology. Cureus. 2023 Aug;15(8):e42972.  420 \n25. Al-Ashwal FY, Zawiah M, Gharaibeh L, Abu-Farha R, Bitar AN. Evaluating the Sensitivity, 421 \nSpecificity, and Accuracy of ChatGPT-3.5, ChatGPT-4, Bing AI, and Bard Against 422 \nConventional Drug-Drug Interactions Clinical Tools. Drug Healthc Patient Saf. 423 \n2023;15:137–47.  424 \n26. Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, et al. Large language models 425 \nencode clinical knowledge. Nature. 2023 Aug;620(7972):172–80.  426 \n27. van Dis EAM, Bollen J, Zuidema W, van Rooij R, Bockting CL. ChatGPT: five priorities for 427 \nresearch. Nature. 2023 Feb;614(7947):224–6.  428 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n18 \n \n28. Luo R, Sun L, Xia Y, Qin T, Zhang S, Poon H, et al. BioGPT: generative pre-trained 429 \ntransformer for biomedical text generation and mining. Brief Bioinform. 2022 Nov 430 \n19;23(6):bbac409.  431 \n29. Koga S, Martin NB, Dickson DW. Evaluating the performance of large language models: 432 \nChatGPT and Google Bard in generating differential diagnoses in clinicopathological 433 \nconferences of neurodegenerative disorders. Brain Pathol Zurich Switz. 2023 Aug 8;e13207.  434 \n30. Kumari A, Kumari A, Singh A, Singh SK, Juhi A, Dhanvijay AKD, et al. Large Language 435 \nModels in Hematology Case Solving: A Comparative Study of ChatGPT-3.5, Google Bard, 436 \nand Microsoft Bing. Cureus. 2023 Aug;15(8):e43861.  437 \n31. Lim ZW, Pushpanathan K, Yew SME, Lai Y, Sun CH, Lam JSH, et al. Benchmarking large 438 \nlanguage models’ performances for myopia care: a comparative analysis of ChatGPT-3.5, 439 \nChatGPT-4.0, and Google Bard. EBioMedicine. 2023 Sep;95:104770.  440 \n32. Meo SA, Al-Khlaiwi T, AbuKhalaf AA, Meo AS, Klonoff DC. The Scientific Knowledge of 441 \nBard and ChatGPT in Endocrinology, Diabetes, and Diabetes Technology: Multiple-Choice 442 \nQuestions Examination-Based Performance. J Diabetes Sci Technol. 2023 Oct 443 \n5;19322968231203987.  444 \n33. Toyama Y, Harigai A, Abe M, Nagano M, Kawabata M, Seki Y, et al. Performance 445 \nevaluation of ChatGPT, GPT-4, and Bard on the official board examination of the Japan 446 \nRadiology Society. Jpn J Radiol. 2023 Oct 4;  447 \n34. Waisberg E, Ong J, Masalkhi M, Zaman N, Sarker P, Lee AG, et al. Google’s AI chatbot 448 \n“Bard”: a side-by-side comparison with ChatGPT and its utilization in ophthalmology. Eye 449 \nLond Engl. 2023 Sep 28;  450 \n 451 \n 452 \n 453 \n 454 \n 455 \n 456 \n 457 \n 458 \n 459 \n 460 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n19 \n \nFIGURE LEGENDS 461 \nFigure 1: Flowchart of the rating process for each triplet of responses. 462 \n 463 \nFigure 2: Spot matrix of the percentages of the answered questions [Blue] and reproducible 464 \nresponses [Orange] for each LLM . Color volume is directly proportional to percentage  with the 465 \nouter black circle representing 100%. Corresponding numeric data are available in Suppl. Mat. D. 466 \n 467 \nFigure 3: Bar plot of the results (accuracy, readability, and relevance) for all three LLMs. This 468 \nplot was based only on the questions evaluable for accuracy, readability, and relevance. 469 \nCorresponding numeric data are available in Suppl. Mat. D.470 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n20 \n \nTable 1. Definitions of the outcomes \n \nOutcomes Definitions Score \nAnswer Returned \nThe ability of LLM to return a meaningful answer to each instance of the \nquestion submitted, rather than returning an error or declining to return an \nanswer, independent of the accuracy of this response. \nRecorded as Boolean \nTrue/False \nReproducibility \nThe ability of LLM to return a generally similar series of answers across \nthe three separate queries with no fundamental differences or \ninconsistencies between these three answers. \nRecorded as Boolean \nTrue/False \nAccuracy \nThe ability of LLM to provide accurate and correct information addressing \nthe question asked and returning all major or critical points required in \nsuch an answer. Response not adversely marked for extraneous or \nirrelevant information here – as long as this information was correct. \nRecorded numerically \nfrom 1 to 3 \nReadability \nThe ability of LLM to return comprehensible and coherent natural language \ntext in English, including appropriate syntax, formatting, and punctuation, \nindependent of the accuracy of this response. \nRecorded numerically \nfrom 1 to 3 \nRelevance \nThe ability of LLM to return information that was relevant and specific to \nthe question asked or immediately adjacent topics without extraneous, \nunrequested, or tangential information. Accuracy was not specifically \nassessed here, though the result was adversely marked if the response \nincluded immaterial information while neglecting to address the specific \nquestion asked. \nRecorded numerically \nfrom 1 to 3 \nNote: for scoring of Relevance, the answer returned was not adversely marked for any included disclaimers to the effect that the LLM cannot \nprovide medical advice and any such advice should be sought from a clinician or that anyone with a cancer diagnosis and/or receiving systemic \ntherapy with potential toxicity should contact their treating clinician/s. This was deemed to represent appropriate and medically sound advice and \nnot to be irrelevant or extraneous material. \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n21 \n \nTable 2. Definitions of the scoring system \n \n     Score \n1 2 3 \nAccuracy \nFundamentally inaccurate or \nincorrect information, including \ncritical errors, omissions and/or \nentirely incorrect treatment advice. \nPartially correct and accurate \ninformation, including non-critical \nerrors and/or omitting relevant \ninformation or failing to provide \nspecific guideline advice. \nFully accurate and correct \ninformation, answering the \nspecific question asked with no \nsignificant errors or omissions. \nRelevance* \nIrrelevant and/or entirely tangential \nmaterial, not addressing the \nspecific question asked. \nGenerally relevant material though \nincluding significant extraneous \nand/or tangential information. \nRelevant and focused \ninformation directly addressing \nthe question asked, including \nan appropriate expansion on \nthe relevant topic. \nReadability \nIncoherent, unintelligible and/or \ngarbled text, +/- severely \nmisformatted and/or oxymoronic \nmaterial resulting in compromised \nlegibility. \nGenerally coherent and intelligible \nmaterial with significant formatting \nand/or parsing errors. \nFully coherent, well-parsed \nand constructed material, \neasily and clearly intelligible. \n*Note: Inclusion of a disclaimer that the answer was provided by an AI/LLM and cannot be taken as medical advice and/or that any \ninformation or questions should also be addressed to a qualified medical practitioner was not scored negatively – as this represents a \nlegitimate and appropriate legal disclaimer. \n \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n22 \n \nTable 3. List of studies investigating the utility of ChatGPT and Google Bard across various contexts of medicine and healthcare. \nFirst Author Year of \nPublication LLMs Domain Questions \n(n) \nReviewers \n(n) \nAl-Ashwal FY (25) 2023 ChatGPT - Google \nBard - Bing AI Drug-drug interactions 225 [OE] NA \nDhanvijay AK (24) 2023 ChatGPT - Google \nBard - Bing AI Physiology 77 [OE] 2 \nSeth I (22) 2023 ChatGPT - Google \nBard - Bing AI Rhinoplasty 6 [OE] 3 \nKoga S (29) 2023 ChatGPT - Google \nBard \nNeurodegenerative \ndisorder 25 [OE] NA \nKumari A (30) 2023 ChatGPT - Google \nBard Hematology 50 [OE] 3 \nLim ZW (31) 2023 ChatGPT - Google \nBard Myopia 31 [OE] 3 \nMeo SA (32) 2023 ChatGPT - Google \nBard \nEndocrinology, diabetes, \nand diabetes technology 100 [MC] - \nToyama Y (33) 2023 ChatGPT - Google \nBard Radiology 103 [MC] 3 \nWaisberg E (34) 2023 ChatGPT - Google \nBard Ophthalmology NA 4 \nZuniga Salazar G (23) 2023 ChatGPT - Google \nBard - Bing AI Emergency 176 [OE] NA \nAbbreviations: Multiple choice (MC); Not available (NA); Open-ended (OE). \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n23 \n \nFigure 1  \n \n \n \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n24 \n \nFigure 2  \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint \n25 \n \nFigure 3  \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted October 31, 2023. ; https://doi.org/10.1101/2023.10.31.23297825doi: medRxiv preprint ",
  "topic": "Oncology",
  "concepts": [
    {
      "name": "Oncology",
      "score": 0.42952659726142883
    },
    {
      "name": "Medicine",
      "score": 0.4263097047805786
    },
    {
      "name": "Computer science",
      "score": 0.375852108001709
    },
    {
      "name": "Internal medicine",
      "score": 0.3449660539627075
    },
    {
      "name": "Medical physics",
      "score": 0.3300493359565735
    },
    {
      "name": "Psychology",
      "score": 0.32667428255081177
    }
  ]
}