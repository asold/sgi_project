{
  "title": "CVXPY: A Python-Embedded Modeling Language for Convex Optimization",
  "url": "https://openalex.org/W2949979136",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2744636337",
      "name": "Diamond, Steven",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2743083542",
      "name": "Boyd, Stephen",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2536620281",
    "https://openalex.org/W2129516068",
    "https://openalex.org/W2288174618",
    "https://openalex.org/W2786741601",
    "https://openalex.org/W2001728872",
    "https://openalex.org/W1530724886",
    "https://openalex.org/W2113642685",
    "https://openalex.org/W2026483567",
    "https://openalex.org/W2296319761",
    "https://openalex.org/W2117402460",
    "https://openalex.org/W2407287065",
    "https://openalex.org/W2178935672"
  ],
  "abstract": "CVXPY is a domain-specific language for convex optimization embedded in Python. It allows the user to express convex optimization problems in a natural syntax that follows the math, rather than in the restrictive standard form required by solvers. CVXPY makes it easy to combine convex optimization with high-level features of Python such as parallelism and object-oriented design. CVXPY is available at http://www.cvxpy.org/ under the GPL license, along with documentation and examples.",
  "full_text": "arXiv:1603.00943v2  [math.OC]  1 Jun 2016\nJournal of Machine Learning Research 17 (2016) 1-5 Submitte d 8/15; Published 4/16\nCVXPY: A Python-Embedded Modeling Language for\nConvex Optimization\nSteven Diamond diamond@cs.stanford.edu\nStephen Boyd boyd@stanford.edu\nDepartments of Computer Science and Electrical Engineerin g\nStanford University\nStanford, CA 94305, USA\nEditor: Antti Honkela\nAbstract\nCVXPY is a domain-speciﬁc language for convex optimization embedde d in Python. It\nallows the user to express convex optimization problems in a natural syntax that follows\nthe math, rather than in the restrictive standard form required b y solvers. CVXPY makes it\neasy to combine convex optimization with high-level features of Pyt hon such as parallelism\nand object-oriented design. CVXPY is available at http://www.cvxpy.org/ under the\nGPL license, along with documentation and examples.\nKeywords: convex optimization, domain-speciﬁc languages, Python, conic pro gramming,\nconvexity veriﬁcation\n1. Introduction\nConvex optimization has many applications to ﬁelds as diver se as machine learning, control,\nﬁnance, and signal and image processing (Boyd and Vandenber ghe, 2004). Using convex\noptimization in an application requires either developing a custom solver or converting\nthe problem into a standard form. Both of these tasks require expertise, and are time-\nconsuming and error prone. An alternative is to use a domain- speciﬁc language (DSL)\nfor convex optimization, which allows the user to specify th e problem in a natural way\nthat follows the math; this speciﬁcation is then automatica lly converted into the standard\nform required by generic solvers. CVX (Grant and Boyd, 2014) , YALMIP (Lofberg, 2004),\nQCML (Chu et al., 2013), PICOS (Sagnol, 2015), and Convex.jl (Udell et al., 2014) are\nexamples of such DSLs for convex optimization.\nCVXPY is a new DSL for convex optimization. It is based on CVX ( Grant and Boyd,\n2014), but introduces new features such as signed disciplin ed convex programming analysis\nand parameters. CVXPY is an ordinary Python library, which m akes it easy to combine\nconvex optimization with high-level features of Python suc h as parallelism and object-\noriented design.\nCVXPY has been downloaded by thousands of users and used to te ach multiple courses\n(Boyd, 2015). Many tools have been built on top of CVXPY, such as an extension for\nstochastic optimization (Ali et al., 2015).\nc⃝ 2016 Steven Diamond and Stephen Boyd.\nDiamond and Boyd\n2. CVXPY Syntax\nCVXPY has a simple, readable syntax inspired by CVX (Grant an d Boyd, 2014). The\nfollowing code constructs and solves a least squares proble m where the variable’s entries\nare constrained to be between 0 and 1. The problem data A ∈ Rm×n and b ∈ Rm could\nbe encoded as NumPy ndarrays or one of several other common ma trix representations in\nPython.\n# Construct the problem.\nx = Variable(n)\nobjective = Minimize(sum_squares(A*x - b))\nconstraints = [0 <= x, x <= 1]\nprob = Problem(objective, constraints)\n# The optimal objective is returned by prob.solve().\nresult = prob.solve()\n# The optimal value for x is stored in x.value.\nprint x.value\nThe variable, objective, and constraints are each construc ted separately and combined\nin the ﬁnal problem. In CVX, by contrast, these objects are cr eated within the scope of a\nparticular problem. Allowing variables and other objects t o be created in isolation makes\nit easier to write high-level code that constructs problems (see §6).\n3. Solvers\nCVXPY converts problems into a standard form known as conic f orm (Nesterov and Nemirovsky,\n1992), a generalization of a linear program. The conversion is done using graph implementa-\ntions of convex functions (Grant and Boyd, 2008). The result ing cone program is equivalent\nto the original problem, so by solving it we obtain a solution of the original problem.\nSolvers that handle conic form are known as cone solvers; eac h one can handle combina-\ntions of several types of cones. CVXPY interfaces with the op en-source cone solvers CVX-\nOPT (Andersen et al., 2015), ECOS (Domahidi et al., 2013), an d SCS (O’Donoghue et al.,\n2016), which are implemented in combinations of Python and C . These solvers have diﬀer-\nent characteristics, such as the types of cones they can hand le and the type of algorithms\nemployed. CVXOPT and ECOS are interior-point solvers, whic h reliably attain high accu-\nracy for small and medium scale problems; SCS is a ﬁrst-order solver, which uses OpenMP\nto target multiple cores and scales to large problems with mo dest accuracy.\n4. Signed DCP\nLike CVX, CVXPY uses disciplined convex programming (DCP) t o verify problem convexity\n(Grant et al., 2006). In DCP, problems are constructed from a ﬁxed library of functions\nwith known curvature and monotonicity properties. Functio ns must be composed according\nto a simple set of rules such that the composition’s curvatur e is known. For a visualization\nof the DCP rules, visit dcp.stanford.edu.\n2\nCVXPY: A Python-Embedded Modeling Language for Convex Optimization\nCVXPY extends the DCP rules used in CVX by keeping track of the signs of expres-\nsions. The monotonicity of many functions depends on the sig n of their argument, so\nkeeping track of signs allows more compositions to be veriﬁe d as convex. For example,\nthe composition square(square(x)) would not be veriﬁed as convex under standard DCP\nbecause the square function is nonmonotonic. But the composition is veriﬁed as convex\nunder signed DCP because square is increasing for nonnegative arguments and square(x)\nis nonnegative.\n5. Parameters\nAnother improvement in CVXPY is the introduction of paramet ers. Parameters are con-\nstants whose symbolic properties ( e.g., dimensions and sign) are ﬁxed but whose numeric\nvalue can change. A problem involving parameters can be solv ed repeatedly for diﬀerent\nvalues of the parameters without redoing computations that do not depend on the param-\neter values. Parameters are an old idea in DSLs for optimizat ion, appearing in AMPL\n(Fourer et al., 2002).\nA common use case for parameters is computing a trade-oﬀ curv e. The following code\nconstructs a LASSO problem (Boyd and Vandenberghe, 2004) wh ere the positive parameter\nγ trades oﬀ the sum of squares error and the regularization ter m. The problem data are\nA∈ Rm×n and b∈ Rm.\nx = Variable(n)\ngamma = Parameter(sign=\"positive\") # Must be positive due to DCP rules.\nerror = sum_squares(A*x - b)\nregularization = norm(x, 1)\nprob = Problem(Minimize(error + gamma*regularization))\nComputing a trade-oﬀ curve is trivially parallelizable, si nce each problem can be solved\nindependently. CVXPY can be combined with Python multiproc essing (or any other par-\nallelism library) to distribute the trade-oﬀ curve computa tion across many processes.\n# Assign a value to gamma and find the optimal x.\ndef get_x(gamma_value):\ngamma.value = gamma_value\nresult = prob.solve()\nreturn x.value\n# Get a range of gamma values with NumPy.\ngamma_vals = numpy.logspace(-4, 6)\n# Do parallel computation with multiprocessing.\npool = multiprocessing.Pool(processes = N)\nx_values = pool.map(get_x, gamma_vals)\n6. Object-Oriented Convex Optimization\nCVXPY enables an object-oriented approach to constructing optimization problems. As\nan example, consider an optimal ﬂow problem on a directed gra ph G= ( V,E ) with vertex\n3\nDiamond and Boyd\nset V and (directed) edge set E. Each edge e ∈ E carries a ﬂow fe ∈ R, and each vertex\nv ∈ V has an internal source that generates sv ∈ R ﬂow. (Negative values correspond to\nﬂow in the opposite direction, or a sink at a vertex.) The (sin gle commodity) ﬂow problem\nis (with variables fe and sv)\nminimize ∑\ne∈E φe(fe) + ∑\nv∈V ψv(sv),\nsubject to sv + ∑\ne∈I(v) fe = ∑\ne∈O(v) fe, for all v∈ V,\nwhere the φe and ψv are convex cost functions and I(v) and O(v) give vertex v’s incoming\nand outgoing edges, respectively.\nTo express the problem in CVXPY, we construct vertex and edge objects, which store\nlocal information such as optimization variables, constra ints, and an associated objective\nterm. These are exported as a CVXPY problem for each vertex an d each edge.\nclass Vertex(object):\ndef __init__(self, cost):\nself.source = Variable()\nself.cost = cost(self.source)\nself.edge_flows = []\ndef prob(self):\nnet_flow = sum(self.edge_flows) + self.source\nreturn Problem(Minimize(self.cost), [net_flow == 0])\nclass Edge(object):\ndef __init__(self, cost):\nself.flow = Variable()\nself.cost = cost(self.flow)\ndef connect(self, in_vertex, out_vertex):\nin_vertex.edge_flows.append(-self.flow)\nout_vertex.edge_flows.append(self.flow)\ndef prob(self):\nreturn Problem(Minimize(self.cost))\nThe vertex and edge objects are composed into a graph using th e edges’connect method.\nTo construct the single commodity ﬂow problem, we sum the ver tices and edges’ local\nproblems. (Addition of problems is overloaded in CVXPY to ad d the objectives together\nand concatenate the constraints.)\nprob = sum([object.prob() for object in vertices + edges])\nprob.solve() # Solve the single commodity flow problem.\nAcknowledgments\nWe thank the many contributors to CVXPY. This work was suppor ted by DARPA XDATA.\n4\nCVXPY: A Python-Embedded Modeling Language for Convex Optimization\nReferences\nA. Ali, Z. Kolter, S. Diamond, and S. Boyd. Disciplined conve x stochastic programming:\nA new framework for stochastic optimization. In Proceedings of the Conference on Un-\ncertainty in Artiﬁcial Intelligence , pages 62–71, 2015.\nM. Andersen, J. Dahl, and L. Vandenberghe. CVXOPT: Python so ftware for convex opti-\nmization, version 1.1. http://cvxopt.org/, May 2015.\nS. Boyd. EE364a: Convex optimization I. http://stanford.edu/class/ee364a/, Decem-\nber 2015.\nS. Boyd and L. Vandenberghe. Convex Optimization . Cambridge University Press, 2004.\nE. Chu, N. Parikh, A. Domahidi, and S. Boyd. Code generation f or embedded second-order\ncone programming. In Proceedings of the European Control Conference , pages 1547–1552,\n2013.\nA. Domahidi, E. Chu, and S. Boyd. ECOS: An SOCP solver for embe dded systems. In\nProceedings of the European Control Conference , pages 3071–3076, 2013.\nR. Fourer, D. Gay, and B. Kernighan. AMPL: A Modeling Language for Mathematical\nProgramming. Cengage Learning, 2002.\nM. Grant and S. Boyd. Graph implementations for nonsmooth co nvex programs. In V. Blon-\ndel, S. Boyd, and H. Kimura, editors, Recent Advances in Learning and Control , Lecture\nNotes in Control and Information Sciences, pages 95–110. Sp ringer, 2008.\nM. Grant and S. Boyd. CVX: MATLAB software for disciplined co nvex programming,\nversion 2.1. http://cvxr.com/cvx, March 2014.\nM. Grant, S. Boyd, and Y. Ye. Disciplined convex programming . In L. Liberti and N. Mac-\nulan, editors, Global Optimization: From Theory to Implementation , Nonconvex Opti-\nmization and its Applications, pages 155–210. Springer, 20 06.\nJ. Lofberg. YALMIP: A toolbox for modeling and optimization in MATLAB. In Proceedings\nof the IEEE International Symposium on Computed Aided Control Sy stems Design , pages\n294–289, 2004.\nY. Nesterov and A. Nemirovsky. Conic formulation of a convex programming problem and\nduality. Optimization Methods and Software , 1(2):95–115, 1992.\nB. O’Donoghue, E. Chu, N. Parikh, and S. Boyd. Conic optimiza tion via operator splitting\nand homogeneous self-dual embedding. Journal of Optimization Theory and Applications ,\npages 1–27, 2016.\nG. Sagnol. PICOS: A Python interface for conic optimization solvers, version 1.1.\nhttp://picos.zib.de/index.html, April 2015.\nM. Udell, K. Mohan, D. Zeng, J. Hong, S. Diamond, and S. Boyd. C onvex optimization\nin Julia. In Proceedings of the Workshop for High Performance Technical Computing in\nDynamic Languages , pages 18–28, 2014.\n5",
  "topic": "Python (programming language)",
  "concepts": [
    {
      "name": "Python (programming language)",
      "score": 0.9147195816040039
    },
    {
      "name": "Programming language",
      "score": 0.7190403938293457
    },
    {
      "name": "Computer science",
      "score": 0.6669403314590454
    },
    {
      "name": "Regular polygon",
      "score": 0.5722895860671997
    },
    {
      "name": "Syntax",
      "score": 0.5094159245491028
    },
    {
      "name": "Scripting language",
      "score": 0.4182564318180084
    },
    {
      "name": "Theoretical computer science",
      "score": 0.33122581243515015
    },
    {
      "name": "Mathematics",
      "score": 0.2144758701324463
    },
    {
      "name": "Artificial intelligence",
      "score": 0.14912819862365723
    },
    {
      "name": "Geometry",
      "score": 0.0783628523349762
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I97018004",
      "name": "Stanford University",
      "country": "US"
    }
  ],
  "cited_by": 475
}