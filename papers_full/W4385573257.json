{
    "title": "Prompt-and-Rerank: A Method for Zero-Shot and Few-Shot Arbitrary Textual Style Transfer with Small Language Models",
    "url": "https://openalex.org/W4385573257",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2898659512",
            "name": "Mirac Suzgun",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4314641062",
            "name": "Luke Melas-Kyriazi",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2089131864",
            "name": "Dan Jurafsky",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2963667126",
        "https://openalex.org/W2170240176",
        "https://openalex.org/W2617566453",
        "https://openalex.org/W2965033324",
        "https://openalex.org/W2970785793",
        "https://openalex.org/W3100727892",
        "https://openalex.org/W3212496002",
        "https://openalex.org/W2970562804",
        "https://openalex.org/W2963034998",
        "https://openalex.org/W3173777717",
        "https://openalex.org/W2970597249",
        "https://openalex.org/W2964008635",
        "https://openalex.org/W3175978877",
        "https://openalex.org/W2964222296",
        "https://openalex.org/W2963631950",
        "https://openalex.org/W3197754201",
        "https://openalex.org/W3099852471",
        "https://openalex.org/W2970476646",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W2952335829",
        "https://openalex.org/W3034319502",
        "https://openalex.org/W2949980515",
        "https://openalex.org/W2936695845",
        "https://openalex.org/W3207322569",
        "https://openalex.org/W4205635927",
        "https://openalex.org/W3035252911",
        "https://openalex.org/W2589277916",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4225959163",
        "https://openalex.org/W2914442349",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2964321064",
        "https://openalex.org/W3176456866",
        "https://openalex.org/W2964529779",
        "https://openalex.org/W2986893290",
        "https://openalex.org/W3115113481",
        "https://openalex.org/W2927085091",
        "https://openalex.org/W2963532001"
    ],
    "abstract": "We propose a method for arbitrary textual style transfer (TST)—the task of transforming a text into any given style—utilizing general-purpose pre-trained language models. Our method, Prompt-and-Rerank, is based on a mathematical formulation of the TST task, decomposing it into three constituent components: textual similarity, target style strength, and fluency. Our method uses zero-shot or few-shot prompting to obtain a set of candidate generations in the target style, and then re-ranks them according to the three components. Our method enables small pre-trained language models to perform on par with state-of-the-art large-scale models while using two orders of magnitude less compute and memory. We also investigate the effect of model size and prompt design (e.g., prompt paraphrasing and delimiter-pair choice) on style transfer quality across seven diverse textual style transfer datasets, finding, among other things, that delimiter-pair choice has a large impact on performance, and that models have biases on the direction of style transfer.",
    "full_text": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 2195–2222\nDecember 7-11, 2022 ©2022 Association for Computational Linguistics\nPrompt-and-Rerank: A Method for Zero-Shot and Few-Shot\nArbitrary Textual Style Transfer with Small Language Models\nMirac Suzgun*\nStanford University\nmsuzgun@cs.stanford.edu\nLuke Melas-Kyriazi*\nOxford University\nlukemk@robots.ox.ac.uk\nDan Jurafsky\nStanford University\njurafsky@cs.stanford.edu\nAbstract\nWe propose a method for arbitrary textual style\ntransfer (TST)—the task of transforming a text\ninto any given style—utilizing general-purpose\npre-trained language models. Our method,\nPrompt-and-Rerank, is based on a mathemati-\ncal formulation of the TST task, decomposing it\ninto three constituent components: textual sim-\nilarity, target style strength, and fluency. Our\nmethod uses zero-shot or few-shot prompting\nto obtain a set of candidate generations in the\ntarget style, and then re-ranks them according\nto the three components. Our method enables\nsmall pre-trained language models to perform\non par with state-of-the-art large-scale mod-\nels while using two orders of magnitude less\ncompute and memory. We also investigate the\neffect of model size and prompt design (e.g.,\nprompt paraphrasing and delimiter-pair choice)\non style transfer quality across seven diverse\ntextual style transfer datasets, finding, among\nother things, that delimiter-pair choice has a\nlarge impact on performance, and that models\nhave biases on the direction of style transfer.1\n1 Introduction\nTextual style transfer (TST) refers to the task of\ntransferring one stylistic aspect of a piece of text\n(e.g., sentiment polarity, formality, politeness, etc.)\nwithout changing its main semantic content, struc-\nture, or other attributes. Traditionally, the natu-\nral language generation (NLG) community has ap-\nproached each instantiation of style transfer as a\ndistinct task, designing and training specialized\nmodels on style-specific training corpora. For ex-\nample, sentiment transfer has been studied exten-\nsively (Li et al. (2018); Sudhakar et al. (2019);\nLuo et al. (2019a), inter alia). This paradigm has\nrestricted TST research to a limited, simple set of\nstyle choices with parallel corpora, which can often\nbe solved adequately by word replacement (e.g., re-\n1Our code, data, and results are available at https://\ngithub.com/suzgunmirac/prompt-and-rerank\nSentiment Transfer\nInput the food was low quality and thrown together quickly with little flavor.\nGPT-J-6Bthe food was delicious and prepared with a lot of care!\nInput the staff is awesome and location is right in the heart of old town!\nGPT-J-6Bthe staff is terrible and location is in the middle of nowhere!\nElizabethan→Modern English Translation\nInput thou hast quar rell’d with a man for coughing in the street, because he hathwakened thy dog that hath lain asleep in the sun.\nGPT-J-6Byou have cursed a man because he’s coughed in the street, because he haswoken your dog, which has been sleeping in the sun.\nInput if thou art fickle, what dost thou with him that is renown’d for faith?\nGPT-J-6Bif you are fickle, then what are you doing with that person who is knownfor being reliable?\nFluency and Grammar Correction\nInput Forexample, My cousin is 12years old.\nGPT-J-6BFor example, My cousin is twelve years old.\nFormality Transfer\nInput r u talking about ur avatar?\nGPT-J-6Bare you talking about your avatar?\nTable 1:Qualitative examples of few-shot style transfer\non the YELP , SHAKESPEARE , JFLEG , and GYAFC\ndatasets. Coupling off-the-shelf “small” language mod-\nels with our prompt-and-reranking method enables us\nto perform arbitrary textual style transfer without any\nmodel training or prompt-tuning. Compared to the ex-\ntremely large language models (viz., ones with more\nthan 100 billion parameters) used by Reif et al. (2022),\nour models obtain similar performance using almost\ntwo orders of magnitude less compute and memory.\nplacing negative words with corresponding positive\nwords for sentiment transfer).\nWith the recent success of general-purpose lan-\nguage modeling (LM), it is, however, natural to ask\nwhether one can tackle a more general formulation\nof style transfer: arbitrary TST, in which one aims\nto transform a reference text into an arbitrary style\nspecified by the user at inference-time.\nInspired by the success of natural-language\nprompting in other domains (Radford et al., 2019;\nPetroni et al., 2019; Brown et al., 2020; Gao et al.,\n2021), we consider a prompting-based zero- and\nfew-shot approach to arbitrary TST. Under this\nsetup, we specify the desired type of style transfer\nproblem using a natural-language prompt contain-\ning the source text (and optionally a few examples,\nin the few-shot case), and then use a pre-trained LM\n2195\nto generate the stylized target text. Thus, the source\ntext may be transformed into any user-specified\nstyle without additional training or fine-tuning.\nRecent work (Reif et al., 2022) has found that ex-\ntremely large language models (LLMs), namely the\n175 billion-parameter GPT-3 (Brown et al., 2020)\nmodel and the proprietary 137 billion-parameter\nLLM model, are capable of sentiment and formality\ntransfer. However, language models at this scale\nare not accessible to most researchers and practi-\ntioners, even in inference-only settings, due to their\nlarge memory consumption and slow generation\ntimes. Thus far, to the best of our knowledge, there\nhas not been any research on the capabilities of\nreasonably-sized models for style transfer domain,\nnor any systematic study of how the precise con-\nstruction of the prompt affects model performance.\nHere we take a first-principles approach to arbi-\ntrary TST using pretrained language models. We\nfirst mathematically formalize the task, showing\nhow it can be formulated as the combination of\ntextual similarity, target style strength, and fluency.\nThis framework naturally leads us to propose a new\nmethod for arbitrary TST, which we call “Prompt-\nand-Rerank.” Using this method, we demonstrate,\nfor the first time, that it is possible to perform arbi-\ntrary TST using reasonably-sized language models;\nprior work indicated that only enormous (i.e., GPT-\n3-scale) language models were capable of this task.\nWe summarize the main contributions and in-\nsights of this paper as follows: (i) We provide the\nfirst mathematical formalization of the arbitrary\nTST task. (ii) We propose Prompt-and-Rerank, a\nnovel prompting-based method for arbitrary TST\nwhich follows naturally from our mathematical for-\nmulation. (iii) Our method matches and sometimes\neven exceeds state-of-the-art performance on arbi-\ntrary TST while using reasonably-sized language\nmodels such as GPT-2, which consume two orders\nof magnitude less memory and compute than prior\nwork. (iv) We conduct a nuanced investigation of\nthe influence of prompt design, such as task phras-\ning and delimiter-pair choice, on the quality of style\ntransfer generations. (v) In order to encourage and\nfacilitate further research in the area, we establish\na set of benchmarks for arbitrary TST (including\ncleaned versions of the popular sentiment transfer\ndatasets AMAZON and YELP ) along with accom-\npanying automatic evaluation metrics.\n2 Background and Related Work\nBackground. TST is a long-standing problem in\nNLP which encompasses many popular sub-tasks,\nsuch as sentiment and formality transfer. Prior\nto the advent of large-scale pre-training in recent\nyears, it was common practice to consider each\nof these sub-tasks separately, and to train sepa-\nrate models on different supervised datasets for\neach task. These models generally performed well\nwithin the limited scope of their task, but failed to\ngeneralize to new tasks or to texts outside of their\ntraining distribution. Here we show that the mod-\nern paradigm of pre-training large models and then\nprompting (or fine-tuning) them can be applied to\nmany sub-tasks of TST in a unified, zero-shot man-\nner, even with relatively small Transformers.\nRelated Work.Traditional approaches to TST\ncan be broadly categorized into two families. The\nfirst family involves identifying and replacing dis-\ntinctive style-related phrases (Li et al. (2018); Sud-\nhakar et al. (2019); Wu et al. (2019); Madaan\net al. (2020); Malmi et al. (2020); Reid and Zhong\n(2021), inter alia). For example, Madaan et al.\n(2020) perform the task of politeness transfer by\nfirst identifying words with stylistic attributes us-\ning TF-IDF and then training a model to replace\nor augment these stylistic words with ones asso-\nciated with the target attribute. In general, these\napproaches perform well for very simple style edits\n(e.g., negating a sentence by adding the word not),\nbut they struggle in scenarios that require more\ncomplex syntactic and semantic changes.\nThe second family of approaches involves dis-\nentangling latent representations of style and con-\ntent, such that a text can be encoded into a style-\ninvariant representation and then decoded in a de-\nsired style (Hu et al., 2017; Shen et al., 2017; Fu\net al., 2018; Luo et al., 2019a). For example, Hu\net al. (2017) encodes into and decodes from a style-\nagnostic latent space using a V AE alongside at-\ntribute discriminators. These approaches are often\ntheoretically well-grounded, but they generally re-\nquire large quantities of labeled data and struggle\nto scale beyond a small number of styles.\nDifferently from these two families, one recent\nwork (Reif et al., 2022) uses enormous pre-trained\nlanguage models to tackle TST, an idea motivated\nby the remarkable performance of pre-trained LMs\nin other areas of NLP (Radford et al., 2019; Devlin\net al., 2019; Yang et al., 2019; Liu et al., 2019).\nSpecifically, they use LLM, LLM-Dialog, and GPT-\n2196\n3, each of which has over 100 billion parameters,\nto rewrite texts in a variety of styles. However, they\nperform minimal analysis of their prompting setup,\ndeferring such analysis to future work, and they\nsuggest that this prompting-based approach is only\nfeasible with LLMs.2\nWhile drawing on many intuitions from Reif\net al. (2022) and these earlier studies, this paper\npresents a novel prompt-and-rerank approach to\nthe general task of TST using pre-trained language\nmodels. Alongside our method, we present the first\nsystematic study of prompt formulation and model\nsize for the task of textual style transfer. Contrary\nto expectations, using our method we find that even\nsmall LMs are able to effectively perform arbitrary\nstyle transfer. In fact, we match the performance\nof Reif et al. (2022) on multiple datasets using two\norders of magnitude less memory and compute.\n3 Method: Prompt-Based Arbitrary TST\nThis section begins with a mathematical formal-\nization of the task of textual style transfer. 3 Our\nformalization elucidates the three underlying com-\nponents of the task, namely text similarity, target\nstyle strength, and fluency, and naturally leads us to\nPrompt-and-Rerank, our prompt-based re-ranking\nalgorithm for solving TST.\n3.1 Problem Formulation\nLet x ∈Σ∗ denote a text over a vocabulary Σ, and\nSthe set of all possible text style choices. Let us\nfurther use x(s1) ∈Σ∗ to denote a text x written\nin the style s1 ∈S. Informally speaking, the goal\nof TST is to transfer the style of a text x(s1) (usu-\nally, a sentence) from s1 to s2 without changing\nthe main semantic content of the text. We can for-\nmally express this transformation via a function\nf : Σ∗ ×S×S→ Σ∗, which takes an input text\n(say x(s1)) and its corresponding style (s1), as well\nas a target style ( s2), and outputs a modified ver-\nsion of the input written in the style of s2 (namely,\n˜x(s2)).4 Ideally, we would want the generated out-\n2A note on terminology: We shall refer to GPT-3 (Brown\net al., 2020) and similar models with 100+ billion model\nparameters as large or enormous language models, as they are\ntwo-to-three orders of magnitude larger than previous models\n(e.g. the GPT-2 series with 117M-to-6B parameters).\n3Despite its important role in NLG, we are not aware of\nany prior formal statement of the style transfer problem. Here,\nwe hope to solidify the problem formulation and illustrate\nthe a connection between this problem formulation and the\nautomatic metrics used in the field to evaluate TST models.\n4In cases where the original style of the input text might\nnot be known a priori, one can either estimate the style of the\nx s2s1\n˜x(s2)x(s1)\nx s2s1\n˜x(s2)x(s1)\nFigure 1: Two different but equally meaningful and\nvalid interpretations of the textual style transfer task.\nHere x can be thought as the universal (abstract) mean-\ning of a text, x(s1) a rewrite of x in the style of s1.\nDepending on which graphical model one adheres to,\nx(s2) can be said to generated by x and s2 (left model)\nor by x(s1) and s2 (right model). In this paper, we fol-\nlow the second interpretation.\nput ˜x(s2) = f(x(s1),s1,s2) to be “close” (both\nsemantically and syntactically) to the ground-truth\nx(s2) as much as possible.\nThe graphical models depicted in Figure 1 pro-\nvide two different ways of formulating the task of\nTST (and of machine translation for that matter).\nBoth models have valid and meaningful implica-\ntions and interpretations; the main generative differ-\nence between them is that the parents of ˜x(s2) are\nx and s2 in the former (left), whereas the parents\nof ˜x(s2) are x(s1) and s2 in the latter (right).\nDue to the inherent difficulty of collecting di-\nverse supervised data for arbitrary TST, most prior\nstudies considered a simplified version of the task,\nwherein the source (s1) and target (s2) style choices\nare fixed beforehand. In this work, we consider a\nbroad formulation of the task, make no assump-\ntions about the source and target style choices a\npriori, and explain how one can leverage the power\nof off-the-shelf LMs to perform arbitrary TST.\nGiven an input text x(s1) written in the style\nof s1 and the target style s2, we decompose the\nconditional likelihood of a generated output ˜x(s2)\ninto three terms:5\np(˜x(s2) |[x(s1),s1],s2) (1)\n= p(˜x(s2),[x(s1),s1],s2)\np([x(s1),s1],s2)\n∝p([x(s1),s1],[˜x(s2),s2])\n= p([˜x(s2),s2]) p([x(s1),s1] |[˜x(s2),s2])\n= p(˜x(s2))  \nfluency\np(s2 |˜x(s2))  \ntransfer strength\np([x(s1),s1] |[˜x(s2),s2])  \ntextual similarity\ninput using a statistical classifier or assume that the input is\nwritten in a neutral style.\n5We make use of the brackets “[·]” only to group relevant\nterms (e.g., x(s1),s1) together; they do not have any statistical\nsignificance in this context.\n2197\nOutput-1\nOutput-2\nOutput-3\nOutput-4\nOutput-5\nPrompt LM\n(GPT-2)\nBERTScore\nTextual Similarity\nMLM (RoBERTa)\nStyle Classiﬁer\nGPT-2-Large\nFluency\nx x\nx x\nx x\nx x\nx x\nRe-score and re-rank the outputs.\nPick the highest scoring output.\nGiven the input text, source style, and\ntarget style, write a proper prompt.\nGenerate multiple outputs\nusing beam search.\nOutput-3\nInput Source Style Target Style\nFigure 2: An illustration of our Prompt-and-Rerank method. Given an input text and a target style, we first\ncompose a prompt and feed it to a pretrained language model to generate multiple output texts—conditioned on the\nprompt—using beam search. We then re-score each candidate output along the three axes from Eq. (1): textual\nsimilarity, style transfer strength, and fluency. We choose the candidate with the highest score as our final output.\nThe first term, p(˜x(s2)), measures the overall flu-\nency of the output. The second term, p(s2 |˜x(s2)),\nmeasures the transfer strength of the output (i.e.,\ndetermines whether the output is written in the tar-\nget style). The last term, p([x(s1),s1] |[˜x(s2),s2]),\ncan be thought of as a proxy for textual similarity\nin the context of textual style transfer—it captures\nthe correspondence between the input and output\ntexts written in their respective styles.\n3.2 Prompt-and-Rerank for Arbitrary TST\nThe problem formulation above naturally leads us\nto a method for (textual) style transfer, which we\ndenote Prompt-and-Rerank (P&R).\nThe foundation of our method is use of prompt\ntemplates to convert TST into a natural-language\ngeneration problem. Formally, we use a predefined\ntemplate τ ∈T to convert an input text x(s1) and\nthe desired style transformation (i.e., s1 →s2) into\na natural-language prefix τ(x,s1,s2). The tem-\nplate τ serves to not only contextualize the task for\nthe model but also incorporate all the necessary con-\nditional information (that is, input sentence, source\nstyle, and target style) in the input context. The\nprecise design and composition of the templates is\nthe topic of the following section (§4.2).6\nNext, we feed the prompt into a pre-trained LM\n(e.g., GPT-2) and use the model to generatekdiffer-\nent outputs ˜x(s2)\nk conditioned on the prompt, each\nsampled independently without updating any pa-\nrameters of the model. These outputs are taken to\nbe our candidate outputs for re-ranking. We then\nre-rank our k candidate outputs according to the\n6Additionally, in the few-shot case, where we have a num-\nber of few-shot exemplars, we convert these exemplars into\nmeaningful prompts using the same template structure τ and\nprepend them to the main prompt.\ndecomposition in Equation 1:\npreranking(˜x(s2)\ni |[x(s1),s1],s2) (2)\n∝p(˜x(s2)\ni )p(s2|˜x(s2)\ni )p([x(s1),s1]|[˜x(s2)\ni ,s2]).\nFinally, we pick the output ˜x(s2)\ni ∈ ˜Xwith the\nhighest re-ranking score. Figure 2 provides an il-\nlustration of the method.\nAll that remains is to describe how to calculate\neach term in the re-ranking pass:\n(i) To calculate the first (fluency) term, we use\nGPT-2-Large (774M) to determine the overall like-\nlihood of each candidate text.7\n(ii) For the second (transfer strength) term, we\ndeliberately turn a masked language model (MLM),\nin our case a pre-trained RoBERTa model, into a\nstyle classifier as follows: Given ˜x(s2)\ni ∈ ˜X(s2)\nand S= {s1,s2}, we convert ˜x(s2)\ni into a “fill-in-\nthe-blank” cloze statement via a pre-defined cloze\ntemplate, that is, we rewrite it as “The following\ntext is <mask>: [˜x(s2)\ni ].” We then query the MLM\nto predict the masked token,8 but instead of look-\ning at the probability distribution over the original\nmodel vocabulary, we restrict our attention to the\nelements in Sand thus consider the likelihood of\nthe missing token being s1 or s2. We then normal-\nize these probabilities by l1-normalization and get\na proper probability distribution for p(s2|˜x(s2)).9\n(iii) Finally, for the third (textual similar-\nity) term, we use BERTScore (Zhang et al.,\n2020), which utilizes pre-trained contextual\nembeddings from BERT to measure the co-\n7Given a text x:= x1:t of length t, we calculate its proba-\nbility under a model θas pθ(x) =∏t\ni=1 pθ(xi |x<i)\n8One limitation of this framework is that it assumes the\nstyles are associated with distinct tokens in the vocabulary.\n9Of course, a more sophisticated normalization technique\ncan be employed in this setup, but this basic normalization\nmethod seemed to be sufficient in our experiments.\n2198\nsine similarity between two texts. 10 Specif-\nically, we approximate p([x(s1),s1]|[˜x(s2),s2])\nwith BERTScore(x(s1),x(s2)).11\nAfterwards, we compute the score for each can-\ndidate by multiplying (i), (ii), and (iii) accordingly;\nre-rank all the candidates; and pick the one with\nthe highest score as the final output.12\nOverall, our approach is model-agnostic, allow-\ning pre-trained LMs to be used out-of-the-box. Fur-\nthermore, our experiments show that with well-\ndesigned prompts, one does not need a massive\nlanguage model for this approach to be successful.\n4 Prompt Construction\nIn practice, we found the specific syntax and se-\nmantics of the prompt template significantly impact\nmodel performance. Thus, we conducted a system-\natic investigation of the impact of different prompt\ndesign choices on the quality of TST generations.\n4.1 Delimiter-Pairs\nWe experimented with ten different text bound-\nary markers (delimiter pairs), which may be di-\nvided into two categories: those whose opening\nand closing markers are identical (known as indis-\ntinguishable delimiters), and those whose markers\nare different (known as complementary delimiters).\nSpecifically, we considered two indistinguishable\npairs (viz., quotes and dashes) and eight comple-\nmentary pairs: (1) curly brackets {·}, (2) square\nbrackets [·], (3) angle brackets ⟨·⟩, (4) parentheses\n(·), (5) quotes \" ·\", (6) dashes – ·–, (7) triple angle\nbrackets ⟨⟨⟨·⟩⟩⟩, (8) bracket quotes ⟩\" ·\", (9) as-\nterisk quotes * \" ·\", and (10) double curly bracket\n{{·}}.13 In their experiments, Reif et al. (2022)\nuse only curly brackets.14\n10Our choice of BERTScore comes with some approxi-\nmations. It is symmetric, i.e., BERTScore(x(s1),x(s2)) =\nBERTScore(x(s2),x(s1)), and BERTScore also does not\nexplicitly include style information. We believe these are\nreasonable simplifications (and it is possible that pre-trained\nBERT implicitly incorporates style information).\n11One can alternatively use MoverScore (Zhao et al., 2019),\nBARTScore (Yuan et al., 2021), or BLEURT (Sellam et al.,\n2020) for approximating textual similarity in (iii).\n12Since the calculation of (iii) penalizes long sequences\nor sequences involving rare words, we also consider the re-\nranking method in which we ignore the fluency factor, assum-\ning that the sentences generated by the models are always\nfluent, which, we are aware that, is a faulty assumption.\n13We use (8), (9), and (10) to emulate blockquotes, bullet\npoints, and liquid tags in Markdown, respectively.\n14We hypothesized that the complementary delimiter-pairs\nmight yield better results than the indistinguishable ones, since\nit is categorically easier for models to distinguish and under-\nstand where sentences start and end. We also speculated\n4.2 Prompt Phrasing\nWe considered four manually-written template for-\nmats t∈T for our discrete prompts:\n(a) Vanilla: “Here is a text: [d1][x(s1)][d2] Here\nis a rewrite of the text, which is [s2]: [d1]”,\n(b) Contrastive: “Here is a text, which is [s1]:\n[d1][x(s1)][d2] Here is a rewrite of the text, which\nis [s2]: [d1]”,\n(c) Negation-v1: “Here is a text, which is [s1]:\n[d1][x(s1)][d2] Here is a rewrite of the text, which\nis not [s1]: [d1]”, and\n(d) Negation-v2: “Here is a text, which is not\n[s2]: [d1][x(s1)][d2] Here is a rewrite of the text,\nwhich is [s2]: [d1]”.\nNote that [d1] and [d2] denote the opening and\nclosing elements of the chosen delimiter-pair, re-\nspectively. In their experiments, Reif et al. (2022)\nexclusively made use of the vanilla setting, which\nonly specifies the target style ( s2) in the second\nhalf of the prompt; however, we initially specu-\nlated that providing useful information about the\nsource style (s1) and creating a clear contrast be-\ntween the source and target styles in the prompt\nsemantics might help pre-trained LMs to have a\nbetter understanding of the underlying nature of\nthe task and improve their performance; hence, we\ndecided to look at the contrastive setting as well.\nAs for the other two negation templates, we wanted\nto test how specifying the source style as the nega-\ntion of the target style (viz., s1:=“not s2”) and vice\nversa might affect the model performance.15\nExample. Finally, to make our prompting setup\nmore concrete, let us give a concrete and brief ex-\nample of how we formulate a prompt. We consider\nthe contrastive template with curly brackets as our\ndelimiter. If we have an input sentence x(s1)=“I\nlove The Sound of Music; it is the best movie ever!!”\nwith s1=positive and s2=negative, then the prompt\nunder this template would be “Here is a text, which\nis positive: {I love The Sound of Music ; it is the\nbest movie ever!!} Here is a rewrite of the text,\nwhich is negative: {” The language model would\nthen generate an output by autoregressively decod-\ning after the last delimiter, to produce a sentence\nsuch as: “I hate The Sound of Music; it is the worst\nmovie ever!!}.”16\nthat delimiter-pairs that were more likely to be used as text-\nseparators in the training data in various contexts (e.g., in code\nsnippets) might yield better results.\n15The last two formats might be useful especially when we\ndo not have access to either the source or the target style.\n16Table 9 in the Appendix provides a complete set of exam-\n2199\nDataset Styles Example Sentence-Pairs Test Set Size\nYelp Restaurant Reviews Negative ever since joes has changed hands it’s just gotten worse and worse. 1000(Zhang et al., 2015) Positive ever since joes has changed hands it’s gotten better and better.\nAmazon Product Reviews Negative if your bike had a kickstand on the plate it won’t lock down. 1000(He and McAuley, 2016) Positive if your bike had a kickstand on the plate it would lock down.\nGY AFC Formality Dataset Informal and so what if it is a rebound relationship for both of you? 1000(Rao and Tetreault, 2018) Formal what if it is a rebound relationship for both of you?\nShakespearean English Dataset Elizabethan is rosaline, whom thou didst love so dear, so soon forsaken? 599(Xu et al., 2012) Modern have you given up so quickly on rosaline, whom you loved so much?\nJFLEG Corpus Ungrammatical Forexample, My cousin is 12years old. 747(Napoles et al., 2017) Grammatical For example, my cousin is 12 years old.\nSymbolic Manipulation Symbolic olive >cat 1000(Ours) English olive is greater than cat\nTable 2:Overview of the textual style transfer datasets used in this paper.\n4.3 Zero-Shot vs. Few-Shot Settings\nIn recent years, LLMs, such as GPT-3, have proven\nthemselves to be resourceful few-shot learners. In\na few-shot learning setting, a model is presented\nwith a small set of illustrative examples, oftentimes\nalong with a natural-language prompt describing\nthe task, and expected to understand the underlying\ntask and make accurate predictions without per-\nforming any gradient updates to the weights of the\nmodel at inference time. We wanted to explore\nhow the number of demonstrations affects the per-\nformance of our models. To that end, we also tested\nthe performances of our models under the zero-shot\nand four-shot settings.\n5 Experiments and Results\n5.1 Datasets\nDifferently from most previous work, which fo-\ncused on single TST subtasks or datasets, we\npresent experiments on a wide range of TST sub-\ntasks (also described in Table 2):\n• YELP : Sentiment transfer for Yelp reviews\n(Zhang et al., 2015).\n• AMAZON : Sentiment transfer for Amazon re-\nviews (Li et al., 2018).\n• SHAKESPEARE : Elizabethan-to-modern trans-\nlation for Shakespeare (Xu et al., 2012).\n• GYAFC: Formality transfer for Yahoo An-\nswers responses (Rao and Tetreault, 2018).\n• JFLEG : Grammar error correction for student\nessays (Napoles et al., 2017).\n• SYM: Symbol-to-natural-language translation\non a new custom synthetic dataset.\nIn the initial stages of our research, we noticed\nthat all of these datasets, with the exception of\nSYM (which is synthetic), contain various tokeniza-\ntion issues (e.g., sentences sometimes contain ex-\nples of prompts used in each task.\ntra white-space or have their punctuation marks\nseparated out by spaces). We did not wish these\ntokenization artifacts to diminish the quality of our\ngenerations from general-purpose LMs—neither\ndid we want this issue to negatively impact our\nevaluation scheme. To that end, we used a simple\ntext-cleaning procedure to clean the texts.17\n5.2 Evaluation Metrics\nPrior studies on style and sentiment transfer have\ntypically evaluated models across three dimensions:\ncontent/meaning preservation (textual similarity),\nstyle transfer strength, and fluency (Mir et al., 2019;\nBriakou et al., 2021). We note that these dimen-\nsions correspond exactly to the criteria that appear\nin Equation 1 in §3.1 (Krishna et al., 2020).\nContent Preservation.BLEU (Papineni et al.,\n2002) is the standard metric for measuring seman-\ntic content preservation. We use the SacreBLEU\n(sBLEU) implementation (Post, 2018) to compute\nboth reference-BLEU (r-sBLEU) and self -sBLEU\n(s-sBLEU) scores. Whereas r-sBLEU helps mea-\nsure the distance of generated sentences from the\nground-truth references, s-sBLEU indicates the de-\ngree to which the model directly copies the source.\nTransfer Strength. In order to determine\nwhether outputs generated by a TST model have\nthe attributes of their target styles, we follow the\nstandard classifier-based approach: we train a (bi-\nnary) style classifier on the corpus of interest and\nuse it to estimate the fraction of generated outputs\nwhose styles match their target styles.\nFluency. To measure the fluency of generated\ntexts, we compute their average token-level per-\nplexity (PPL) using a pre-trained LM (in our case,\n17We release both the original and cleaned versions of the\ndatasets alongside this paper to help facilitate future research.\nIn the Appendix, we also present results for both the original\nand cleaned datasets.\n2200\nModel Acc r-sBLEU s-sBLEU PPL\nSUPERVISED\n[1] CrossAlignment 0.73 7.8 18.3 217\n[2] BackTrans 0.95 2.0 46.5 158\n[3] MultiDecoder 0.46 13.0 39.4 373\n[4] DeleteOnly 0.85 13.4 33.9 182\n[4] DeleteAndRetrieve 0.90 14.7 36.4 180\n[5] UnpairedRL 0.49 16.8 45.7 385\n[6] DualRL 0.88 25.9 58.9 133\n[7] ST (Multi-Class) 0.86 26.4 63.0 175\n[7] ST (Conditional) 0.93 22.9 52.8 223\n[8] B-GST 0.81 21.6 46.5 158\nZERO- OR FEW-SHOT INFERENCEONLY\n[9] LLMAug-0S-FirstChoice 0.85 5.3 9.2 33\n[9] LLM5S-FirstChoice 0.93 6.7 11.2 43\n[9] LLMAug-0S-Best-sBLEU† 0.63 19.8 45.1 55\n[9] LLM5S-Best-sBLEU† 0.78 23.2 48.3 77\nOurs(GPT-2-XL) 0.87 14.8 28.7 65\nOurs(GPT-J-6B) 0.87 23.0 47.7 80\nTable 3:A comparison of our Prompt-and-Rerank ap-\nproach with supervised sentiment transfer methods and\nthe ultra-large-scale prompting-based method of Reif\net al. (2022) on YELP -clean. In order to compare fairly\nagainst previous studies, we applied our data-cleaning\ncode to their publicly-available outputs and re-computed\nall evaluation metrics. References: [1] (Shen et al.,\n2017), [2] (Prabhumoye et al., 2018), [3] (Fu et al.,\n2018), [4] (Li et al., 2018), [5] (Xu et al., 2018), [6] (Luo\net al., 2019b), [7] (Dai et al., 2019), [8] (Sudhakar et al.,\n2019), [9] (Reif et al., 2022). Note on †: We used\nsBLEU to choose the best candidate, as opposed to\nBLEU that was used originally by Reif et al. (2022).\nGPT-2-Large). We note that, whilst this PPL-driven\napproach has the advantage of being automated and\npractical, it still contains considerable drawbacks,\nincluding biases towards shorter texts.\n5.3 Model Choices.\nWe used four GPT-2 models (Radford et al., 2019)\nof varying sizes (viz., GPT-2-Small (117M params),\nGPT-2-Medium (345M), GPT-2-Large (774M),\nand GPT-2-XL (1.6B)), GPT-Neo-1.3B Black et al.\n(2021), GPT-Neo-2.7B, and GPT-J-6B (Wang and\nKomatsuzaki, 2021). We highlight that none of\nthese models were fine-tuned or prompt-tuned.\n5.4 Results\nHere, we present a summary of our key findings.\nFor our complete results, we encourage the reader\nto see the Appendix (especially, Tables 11-20).\nTable 3 juxtaposes our results on YELP with\nthose of prior studies. Despite not training or fine-\ntuning, our method is competitive with prior mod-\nels that were designed and trained specifically for\nthese tasks. In fact, compared to supervised meth-\nods, our models almost always generate more flu-\nent outputs, as measured by perplexity. Compared\nDataset Model Acc∗ r-sBLEU s-sBLEU PPL\nAMAZON GPT-2-XL 0.70 11.5 17.2 77\nP→N GPT-J-6B 0.65 21.5 31.4 70\nAMAZON GPT-2-XL 0.56 13.2 19.9 50\nN→P GPT-J-6B 0.52 19.3 29.3 58\nYELP GPT-2-XL 0.87 14.8 28.7 65\nP→N GPT-J-6B 0.87 23.0 47.7 80\nYELP GPT-2-XL 0.72 12.0 25.3 55\nN→P GPT-J-6B 0.65 20.2 44.6 58\nSHAKE- GPT-2-XL 0.39 18.9 38.4 90\nSPEARE GPT-J-6B 0.78 21.9 31.8 81\nJFLEG GPT-2-XL 35.9 74.8 91.5 76\nGPT-J-6B 40.0 64.8 59.1 48\nGYAFC GPT-2-XL 0.82 32.7 41.9 58\nGPT-Neo-1.3B0.85 36.4 49.6 68\nSYM GPT-2-XL 0.56 68.5 - -\nGPT-J-6B 0.74 81.9 - -\nTable 4: Four-shot performances of GPT-2-XL and\nGPT-J across all style transfer tasks, using curly brackets\nas delimiters. Full results with all models and delimiter\npairs are shown in the appendix. P→N stands for the\npositive →negative direction, and vice-versa for N→P.\n∗ for JFLEG , GLEU score is used in place of accuracy\nto measure grammar correction performance. Note that\nthe r-sBLEU column is not bolded because it is not\nnecessarily desirable to have a higher r-sBLEU.\nto Reif et al. (2022), who utilize the proprietary\n137-billion-parameter LLM (LaMDA), we compare\non-par or favorably despite using much smaller\nmodels; we obtain better sBLEU scores than their\n“FirstChoice” setting (which uses a single output)\nand better accuracy scores than their “BestBLEU”\noracle setting (which takes the best of 16 outputs,\nas measured by sBLEU score).\nTable 4 presents a summary of our results across\nall seven TST datasets for GPT-2-XL and GPT-J.\nFor full results including all models (GPT-2-Small\nto GPT-J), please refer to the Appendix. Broadly,\nwe find that all models are capable of TST to a\nreasonable degree—with the larger models (e.g.,\nGPT-2-XL, GPT-Neo-2.7B, GPT-J) often perform-\ning better than the smaller models. The only model\nthat consistently performs poorly is GPT-2-Small:\nIts high s-sBLEU and low accuracy indicate that it\ncopies long sections of the input (without changing\nits style) more often than the other models.\nLooking at individual tasks, we recognize that\nthere remains substantial room for improvement on\nthe JFLEG task: Most models underperformed a\nsimple baseline that copied the input text without\nmaking any changes. The baseline achieved 37.2\nGLEU, better than all models except GPT-J (which\nobtained 40.0). Finally, on our new synthetic task\nSYM, we found that GPT-J performed significantly\n2201\nSetting Target Style Textual Similarity Fluency\nGround Truth 3.60 (0.07) 3.34 (0.09) 3.78 (0.05)\nDeleteAndRetrieve (Li et al., 2018) 2.31 (0.14) 2.10 (0.13) 1.97 (0.17)\nStyle Transformer (Dai et al., 2019) 2.43 (0.17) 2.94 (0.13) 2.18 (0.18)\nLLM (Reif et al., 2022) 2.90 (0.13) 1.98 (0.14) 3.73 (0.05)\nOurs (Prompt-and-Rerank) 3.32 (0.13) 3.51 (0.10) 3.67 (0.08)\nTable 5:Human evaluation results on YELP -clean. Each score in the table represents the mean of 250 ratings (with\nstandard errors shown in parentheses): 5 ratings per example across 50 examples, of which 25 were positive-to-\nnegative and 25 were negative-to-positive. Raters scored examples on a scale of 1-to-5 (with 5 being best) across\nthree dimensions: target style, textual similarity, and fluency. We find that Prompt-and-Rerank performs well across\nall dimensions; it scores highest on Target Styleand Textual Similarity and scores only slightly lower than LLM (a\n137-billion parameter language model) on Fluency.\nSetting Acc r-sBLEU s-sBLEU PPL\nVanilla 78.0 14.7 31.0 58.5\nContrastive 79.5 13.4 27.0 59.5\nNegation-v1 66.5 13.4 28.1 67.5\nNegation-v2 52.0 18.0 40.6 69.0\nTable 6: Four-shot performances of GPT-2-XL on\nYELP -clean under different prompting protocols. We\nshow the average of scores from P→N and N→P direc-\ntions. A full table with all models is in the Appendix.\nAcross all models, the vanilla and contrastive prompting\nprotocols tend to yield the most favourable results.\nDelimiter Acc r-sBLEU s-sBLEU PPL\n⟨·⟩ 49.5 17.4 40.8 45\n* \" ·\" 55.0 12.0 29.8 37\n⟩\" ·\" 53.0 10.7 25.4 35\n{·} 59.5 10.0 23.6 35\n– ·– 54.5 6.4 16.5 24\n{{·}} 50.5 18.3 43.9 65\n(·) 55.5 12.4 28.1 43\n\" ·\" 60.5 8.8 20.4 31\n[·] 58.0 11.4 27.4 41\nTable 7: Zero-shot performances of GPT-2-XL on\nYELP -clean using different delimiter pairs. Full tables\nwith all models for all datasets are in the Appendix.\nbetter than the rest: It achieved 74% accuracy18\nwhereas no other model exceeded 60% accuracy.19\n5.5 Human Evaluation\nTo evaluate the efficacy of our proposed Prompt-\nand-Rerank method, we also conducted a human-\nsubject study. Our goals were (1) to assess how\nour proposed method fares against the previously\nproposed methods for style transfer, and (2) to un-\nderstand how correct and well-written both the gen-\nerations and ground-truth references are.\nOur human evaluation followed the procedure\nfrom Reif et al. (2022), in which six human-\n18Accuracy is measured via exact-string-matching.\n19When the models failed to generate the correct output,\nwe found that a common failure case was copying the input\nwords correctly but using the wrong logic (e.g., generating\n“less than” instead of “greater than”).\nraters were to asked to rank outputs along three\ndimensions—namely target-style strength, textual\nsimilarity, and fluency. Our six (volunteer) raters\nwere all graduate students who were all native or\nfluent English speakers. For our evaluation, we\nfocused only on YELP : We randomly sampled 50\nexamples (25 positive-to-negative and 25 negative-\nto-positive) and selected the corresponding outputs\nfrom DeleteAndRetrieve (Li et al., 2018), Style\nTransformer (Dai et al., 2019), LLM (Reif et al.,\n2022), and our own method “Prompt-and-Rerank”,\nalong with the ground-truth references. Each ex-\nample (and its corresponding set of outputs) was\nrated by five raters.\nTo ensure fair comparison, we presented the\nsame samples to our human-raters but randomized\nthe order of the outputs and references, and we\nasked our raters to rate each output on a scale of 1-\nto-5, where 5 indicates the best and 1 the worst. All\nour participants successfully completed our study,\nand it took about one hour for each rater to com-\nplete our human evaluation study.\nResults. Table 5 includes a summary of our\nhuman-evaluation results. “Prompt-and-Rerank”\nobtained the highest scores along both the target\nstyle and textual similarity dimensions, performing\nsignificantly better than the previously proposed\nmethods. In terms of fluency, Reif et al. (2022)’s\nmethod (3.73) has scored slightly higher than ours\n(3.67), and both methods were close to the average\nground-truth fluency score (3.78). We further note\nthat the low textual (semantic) ranking score of the\nground-truth references suggest that the references\nmight be slightly noisy.\n5.6 Further Analysis and Discussion\nContrastive prompting generally improves style\ntransfer quality. As shown in Table 6 (and Ta-\nble 20 in the Appendix), amongst the four prompt-\n2202\ning protocols considered in this paper, contrastive\nprompting generally yielded the best accuracy, al-\nbeit not always the best sBLEU scores.\nDelimiter-pair choice has a large impact on\nmodel performance.Our systematic analysis of\nten different delimiter-pairs shows that delimiter\nchoice substantially affects the quality of generated\noutputs. Although there is not a single pair which\nperforms best across all setups, certain delimiters,\nsuch as the curly brackets {·}, square brackets [·],\nparentheses (·), and quotes \" ·\", yielded consis-\ntently better results on both AMAZON and YELP\n(see Tables 10-13). We hypothesize that the strong\nperformance of these markers is attributable to the\nfact that they are often used as text separators (or\ndividers) in different textual contexts, such as es-\nsays, dialogues, and code snippets, which compose\npart of the pre-training data of our models.\nRe-ranking improves overall performance.\nWe considered two re-ranking approaches, one in\nwhich we picked the generated output with the\nhighest beam score and one in which we sampled\nthree outputs from the model using beam search\nand then re-scored them according to three criteria\ndiscussed in §3.2. As shown in Tables 15 and 16,\nthe re-ranking method can boost the sentiment ac-\ncuracy by 10-30%. It often, but not always, leads\nto better sBLEU and fluency scores. Also, as Ta-\nble 8 illustrates, if we have access to a classifier\ntrained on paired data, it might be more convenient\nto use it in our style transfer accuracy measure-\nments, instead of an MLM as a proxy-classifier, in\nthe re-ranking process, as it empirically leads to\nhigher accuracy and sBLEU scores.\nAnalysis of bias and transfer performance\nin opposite directions.We find that pre-trained\nmodels have strong directional biases: None of\nthe models performed the same when going in the\nnegative→positive (N→P) and positive→negative\n(P→N) directions on AMAZON and YELP . We\noffer three possible explanations for this phe-\nnomenon: (i) The inherent differences in the lin-\nguistic difficulty of the tasks, (ii) the potential bi-\nases in pre-training dataset(s), and (iii) the poor\nquality of annotations in certain style transfer direc-\ntions. Regarding (i), a qualitative inspection of the\nsentiment transfer datasets illustrates that in some\ncases, good P→N performance can be achieved\nby simply adding a negation (e.g., “not”) into the\ntext. Regarding (ii), it is possible that the web-\nscraped pre-training data of these models contains\nModel Setting Acc r-sBLEU s-sBLEU PPL\nGPT-2-XL\n(1558M)\nTop Choice 0.63 13.7 20.3 65\nP&RRoBERTa 0.87 14.8 28.7 65\nP&ROracle Cl. 0.95 16.8 33.4 63\nGPT-J-6B\n(6B)\nTop Choice 0.81 25.3 50.5 107\nP&RRoBERTa 0.87 23.0 47.7 80\nP&ROracle Cl. 0.95 25.4 52.4 87\nTable 8:Comparison of vanilla four-shot performance\nof GPT-2 XL and GPT-J-6B models on YELP -clean\n(P →N) under three settings: (1) choosing the out-\nput with the highest beam score (TC), (2) Prompt-and-\nRerank with RoBERTa used as a zero-shot style classi-\nfier (P&RRoBERTa), and (3) Prompt-and-Rerank with an\noracle style classifier trained on paired data (P&ROracle).\nFor full results in YELP -clean, see Table 16.\nmore sentences that resemble the task of changing\nthe sentiment from positive to negative than the\nreverse direction during their pre-training periods.\nQualitatively, the GPT-2 models appear adept at\nnegation; therefore, it may not be surprising that\nthese models yield better results in the P→N direc-\ntion. As for (iii), our inspection of the ground-truth\ndata reveals that it contains some noisy labels and\nincorrect input-output pairs.\nLimitations. The primary limitation of our re-\nranking method is that it involves generating mul-\ntiple outputs from an autoregressive LM, which\nrequires multiple forward passes. Additionally, our\napproach relies on having access to a pre-trained\nbi-directional MLM. Compared to a simple zero-\nshot approach, these elements could potentially add\ncomplexity to deploying this model in practice.\n6 Conclusion\nIn this paper, we propose a novel formal frame-\nwork for textual style transfer. This framework nat-\nurally leads us to a new method, which we denote\nPrompt-and-Rerank, that utilizes general-purpose\npretrained language models to transform text into\nin arbitrary styles. In our experiments, we use\nour method to demonstrate that off-the-shelf, pre-\ntrained “small” language models, such as GPT-2,\ncan perform arbitrary textual style transfer, without\nany additional model fine-tuning or prompt-tuning.\nAdditionally, we conduct an extensive investigation\nprompt phrasing and delimiter choice on transfer\nquality. In total, we hope that our work makes fur-\nther research in this area more accessible to a broad\nset of researchers, both by alleviating the compu-\ntational constraints of hundred-billion-parameter\nlanguage models and by establishing a standard set\nof clean datasets for arbitrary text style transfer.\n2203\n7 Ethical Considerations & Limitations\nOur work aims to advance the state of research\non the task of arbitrary textual style transfer. As\nwith many NLP applications, these methods may\nbe used for negative purposes by malicious actors.\nFor example, it would be possible to conceive of\nan instantiation of arbitrary textual style transfer\nwhich converts a non-sensationalist news headline\ninto a sensationalist news headline, or one that con-\nverts a non-offensive piece of text into an offensive\npiece of text, in order to achieve a malicious goal.\nOur work also involves pretrained general-\npurpose language models, which bring up less-\nobvious ethical considerations than those discussed\nabove. Since these language models are trained on\ntext scraped from the web, they have acquired some\nof the biases present in web text. Such biases may\nbe extracted by certain forms of prompting; recent\nwork (Prabhumoye et al., 2021) suggests that few-\nshot prompts can be used to detect social biases in\npretrained language models. A large body of work\nis dedicated to understanding and de-biasing these\nlarge language models, but it is not the subject of\nour present work.\nAcknowledgments\nWe would like to thank Yonatan Belinkov, Fed-\nerico Bianchi, Dora Demszky, Esin Durmus, Tim\nFranzmeyer, Tayfun Gür, Tatsu Hashimoto, John\nHewitt, Laurynas Karazija, Deniz Kele¸ s, Faisal\nLadhak, Percy Liang, Nelson Liu, Shikhar Murty,\nTolúlo. pé. Ògúnrè.mí, Isabel Papadimitriou, Ash-\nwin Paranjape, Stuart M. Shieber, Suny Shtedrit-\nski, Kyle Swanson, Rose Wang, Elliot Wu, Tianyi\nZhang, and Kaitlyn Zhou for their help and sup-\nport. We especially thank Suproteem K. Sarkar for\nproofreading an earlier version of this manuscript\nand providing us with constructive comments and\nvaluable suggestions. We also wish to thank the\nanonymous reviewers for providing us with helpful\nfeedback, Sudha Rao for helping us with the navi-\ngation of the GYAFC dataset, and Yunli Wang for\nsharing their data splits and classifiers for GYAFC\nthat were used in their paper. We gratefully ac-\nknowledge the support of Open Philanthropy, the\nNSF (via award IIS-2128145), and a Google Colab\nResearch Credit Grant, as well as the support of the\nRhodes Trust to Melas-Kyriazi.\nReferences\nSid Black, Leo Gao, Phil Wang, Connor Leahy,\nand Stella Biderman. 2021. GPT-Neo: Large\nScale Autoregressive Language Modeling with Mesh-\nTensorflow.\nEleftheria Briakou, Sweta Agrawal, Joel Tetreault,\nand Marine Carpuat. 2021. Evaluating the Eval-\nuation Metrics for Style Transfer: A Case Study\nin Multilingual Formality Transfer. arXiv preprint\narXiv:2110.10668.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language Models are Few-Shot Learners. In\nAdvances in Neural Information Processing Systems\n33: Annual Conference on Neural Information Pro-\ncessing Systems 2020, NeurIPS 2020, December 6-\n12, 2020, virtual.\nNing Dai, Jianze Liang, Xipeng Qiu, and Xuan-Jing\nHuang. 2019. Style Transformer: Unpaired Text\nStyle Transfer without Disentangled Latent Represen-\ntation. In Proceedings of the 57th Annual Meeting of\nthe Association for Computational Linguistics, pages\n5997–6007.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\nDeep Bidirectional Transformers for Language Un-\nderstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nZhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao,\nand Rui Yan. 2018. Style Transfer in Text: Explo-\nration and Evaluation. In Proceedings of the AAAI\nConference on Artificial Intelligence, volume 32.\nTianyu Gao, Adam Fisch, and Danqi Chen. 2021. Mak-\ning Pre-trained Language Models Better Few-shot\nLearners. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers),\npages 3816–3830.\nRuining He and Julian McAuley. 2016. Ups and Downs:\nModeling the Visual Evolution of Fashion Trends\nwith One-Class Collaborative Filtering. In proceed-\nings of the 25th international conference on world\nwide web, pages 507–517.\n2204\nZhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan\nSalakhutdinov, and Eric P Xing. 2017. Toward Con-\ntrolled Generation of Text. In International confer-\nence on machine learning, pages 1587–1596. PMLR.\nDi Jin, Zhijing Jin, Zhiting Hu, Olga Vechtomova, and\nRada Mihalcea. 2021. Deep Learning for Text Style\nTransfer: A Survey. Computational Linguistics ,\npages 1–51.\nKalpesh Krishna, John Wieting, and Mohit Iyyer. 2020.\nReformulating Unsupervised Style Transfer as Para-\nphrase Generation. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 737–762, Online. Asso-\nciation for Computational Linguistics.\nGuillaume Lample, Sandeep Subramanian, Eric Smith,\nLudovic Denoyer, Marc’Aurelio Ranzato, and Y-Lan\nBoureau. 2019. Multiple-Attribute Text Rewriting.\nIn International Conference on Learning Representa-\ntions.\nJuncen Li, Robin Jia, He He, and Percy Liang. 2018.\nDelete, Retrieve, Generate: a Simple Approach to\nSentiment and Style Transfer. In Proceedings of\nthe 2018 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long Pa-\npers), pages 1865–1874, New Orleans, Louisiana.\nAssociation for Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoBERTa: A Robustly Optimized BERT Pretrain-\ning Approach. CoRR, abs/1907.11692.\nFuli Luo, Peng Li, Pengcheng Yang, Jie Zhou, Yutong\nTan, Baobao Chang, Zhifang Sui, and Xu Sun. 2019a.\nTowards Fine-Grained Text Sentiment Transfer. In\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 2013–\n2022.\nFuli Luo, Peng Li, Jie Zhou, Pengcheng Yang, Baobao\nChang, Zhifang Sui, and Xu Sun. 2019b. A\nDual Reinforcement Learning Framework for Un-\nsupervised Text Style Transfer. arXiv preprint\narXiv:1905.10060.\nAman Madaan, Amrith Setlur, Tanmay Parekh, Barn-\nabás Póczos, Graham Neubig, Yiming Yang, Ruslan\nSalakhutdinov, Alan W Black, and Shrimai Prabhu-\nmoye. 2020. Politeness Transfer: A Tag and Gen-\nerate Approach. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 1869–1881.\nEric Malmi, Aliaksei Severyn, and Sascha Rothe.\n2020. Unsupervised Text Style Transfer with\nPadded Masked Language Models. arXiv preprint\narXiv:2010.01054.\nRemi Mir, Bjarke Felbo, Nick Obradovich, and Iyad\nRahwan. 2019. Evaluating Style Transfer for Text.\narXiv preprint arXiv:1904.02295.\nCourtney Napoles, Keisuke Sakaguchi, Matt Post, and\nJoel Tetreault. 2015. Ground Truth for Grammatical\nError Correction Metrics. In Proceedings of the 53rd\nAnnual Meeting of the Association for Computational\nLinguistics and the 7th International Joint Confer-\nence on Natural Language Processing (Volume 2:\nShort Papers), pages 588–593.\nCourtney Napoles, Keisuke Sakaguchi, and Joel\nTetreault. 2017. JFLEG: A fluency corpus and bench-\nmark for grammatical error correction. In Proceed-\nings of the 15th Conference of the European Chap-\nter of the Association for Computational Linguistics:\nVolume 2, Short Papers, pages 229–234, Valencia,\nSpain. Association for Computational Linguistics.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. BLEU: A method for Automatic\nEvaluation of Machine Translation. In Proceedings\nof the 40th annual meeting of the Association for\nComputational Linguistics, pages 311–318.\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language Models as Knowl-\nedge Bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 2463–2473.\nMatt Post. 2018. A Call for Clarity in Reporting BLEU\nScores. In Proceedings of the Third Conference on\nMachine Translation: Research Papers, pages 186–\n191, Brussels, Belgium. Association for Computa-\ntional Linguistics.\nShrimai Prabhumoye, Rafal Kocielnik, Mohammad\nShoeybi, Anima Anandkumar, and Bryan Catanzaro.\n2021. Few-shot Instruction Prompts for Pretrained\nLanguage Models to Detect Social Biases. arXiv\npreprint arXiv:2112.07868.\nShrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhut-\ndinov, and Alan W Black. 2018. Style Transfer\nThrough Back-Translation. In Proceedings of the\n56th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n866–876.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nModels are Unsupervised Multitask Learners. Ope-\nnAI blog, 1(8):9.\nSudha Rao and Joel Tetreault. 2018. Dear Sir or Madam,\nMay I Introduce the GY AFC Dataset: Corpus, Bench-\nmarks and Metrics for Formality Style Transfer. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 129–140, New Or-\nleans, Louisiana. Association for Computational Lin-\nguistics.\n2205\nMachel Reid and Victor Zhong. 2021. LEWIS: Leven-\nshtein Editing for Unsupervised Text Style Transfer.\narXiv preprint arXiv:2105.08206.\nEmily Reif, Daphne Ippolito, Ann Yuan, Andy Co-\nenen, Chris Callison-Burch, and Jason Wei. 2022. A\nRecipe for Arbitrary Text Style Transfer with Large\nLanguage Models. In Proceedings of the 60th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) , pages 837–\n848, Dublin, Ireland. Association for Computational\nLinguistics.\nThibault Sellam, Dipanjan Das, and Ankur P Parikh.\n2020. Bleurt: Learning robust metrics for text gener-\nation. In Proceedings of ACL.\nTianxiao Shen, Tao Lei, Regina Barzilay, and Tommi\nJaakkola. 2017. Style Transfer from Non-Parallel\nText by Cross-Alignment. Advances in neural infor-\nmation processing systems, 30.\nAkhilesh Sudhakar, Bhargav Upadhyay, and Arjun Ma-\nheswaran. 2019. \"Transforming\" Delete, Retrieve,\nGenerate Approach for Controlled Text Style Trans-\nfer. In Proceedings of the 2019 Conference on Em-\npirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n3269–3279.\nBen Wang and Aran Komatsuzaki. 2021. GPT-\nJ-6B: A 6 Billion Parameter Autoregressive\nLanguage Model. https://github.com/\nkingoflolz/mesh-transformer-jax.\nYunli Wang, Yu Wu, Lili Mou, Zhoujun Li, and Wenhan\nChao. 2019. Harnessing Pre-Trained Neural Net-\nworks with Rules for Formality Style Transfer. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 3573–\n3578, Hong Kong, China. Association for Computa-\ntional Linguistics.\nYunli Wang, Yu Wu, Lili Mou, Zhoujun Li, and Wenhan\nChao. 2020. Formality Style Transfer with Shared\nLatent Space. In Proceedings of the 28th Inter-\nnational Conference on Computational Linguistics,\npages 2236–2249.\nXing Wu, Tao Zhang, Liangjun Zang, Jizhong Han,\nand Songlin Hu. 2019. \"Mask and Infill\": Apply-\ning Masked Language Model to Sentiment Transfer.\narXiv preprint arXiv:1908.08039.\nJingjing Xu, Xu Sun, Qi Zeng, Xiaodong Zhang, Xu-\nancheng Ren, Houfeng Wang, and Wenjie Li. 2018.\nUnpaired Sentiment-to-Sentiment Translation: A Cy-\ncled Reinforcement Learning Approach. In Proceed-\nings of the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 979–988.\nWei Xu, Alan Ritter, Bill Dolan, Ralph Grishman, and\nColin Cherry. 2012. Paraphrasing for Style. In COL-\nING, pages 2899–2914.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXLNet: Generalized Autoregressive Pretraining for\nLanguage Understanding. Advances in neural infor-\nmation processing systems, 32.\nWeizhe Yuan, Graham Neubig, and Pengfei Liu. 2021.\nBartscore: Evaluating generated text as text genera-\ntion. In Advances in Neural Information Processing\nSystems, volume 34, pages 27263–27277. Curran As-\nsociates, Inc.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. BERTScore:\nEvaluating Text Generation with BERT. In Inter-\nnational Conference on Learning Representations.\nXiang Zhang, Junbo Zhao, and Yann LeCun. 2015.\nCharacter-Level Convolutional Networks for Text\nClassification. Advances in neural information pro-\ncessing systems, 28:649–657.\nWei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Chris-\ntian M Meyer, and Steffen Eger. 2019. Moverscore:\nText generation evaluating with contextualized em-\nbeddings and earth mover distance. In Proceedings\nof the 2019 Conference on Empirical Methods in Nat-\nural Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 563–578.\n2206\nA Appendix\nA.1 Additional Details about Datasets\nPrevious TST studies have often chosen to focus on\nparticular subtasks (such as changing the sentiment\nof a text from positive to negative) or particular\ndatasets (such as YELP or AMAZON ). In contrast,\nin our experiments, we decided to focus on a va-\nriety of TST datasets, some of which are known\nand widely used datasets in the field and some of\nwhich are new and synthetic. In the first half of this\nsection, we present and discuss these datasets.20\nYelp Sentiment Dataset. YELP is a subset of the\nYelp Review Polarity Dataset that was first used by\nZhang et al. (2015) for a text classification task. It\nconsists restaurant and other business reviews from\nYelp, along with a label—either positive or nega-\ntive—for each review. We used the version of the\ndataset that was curated by Li et al. (2018) in our\nexperiments. The test set contains 500 positive and\n500 negative samples, with one human reference\n(ground-truth) for each sample.\nAmazon Sentiment Dataset.AMAZON is sim-\nilar to YELP in its nature, but it contains product\nreviews that were obtained from Amazon. Each\nreview is labeled either positive or negative. As\nbefore, we used the version of the dataset that was\nused by Li et al. (2018). The test set contains 500\npositive and 500 negative sentences, with one hu-\nman reference output for each sample.\nShakespearean English Dataset.We addition-\nally used a small subset of the dataset that was used\nby Xu et al. (2012) originally for phrase-based ma-\nchine translation, and experimented with “trans-\nlating” sentences written in Elizabethan English\nto modern English. This small test set, which we\ncall SHAKESPEARE , contains 599 paired sentences\nfrom William Shakespeare’s Romeo and Juliet ,\nwritten in Elizabethan and modern English.21\nGYAFC Formality Dataset.Grammarly’s Ya-\nhoo Answers Formality corpus (GYAFC; Rao and\n20We chose these datasets to broaden the semantic diversity\nof the TST tasks and to establish benchmarks for new TST\nstudies. We share both the original and clean versions of\nsome of the widely-used but poorly-tokenized datasets, such\nas AMAZON and YELP . In doing so, we hope to help address\nthe recent call-to-action on reproducibility in TST from Jin\net al. (2021); they encouraged researchers to share their data\nand evaluation codes in order to establish reliable benchmarks\nand facilitate easier comparison of new studies with existing\nwork. We hope that our efforts will be a constructive step\ntowards this goal.\n21All the input sentences in SHAKESPEARE contain at least\n10 and at most 25 words (inclusive).\nTetreault (2018)) contains paired informal and for-\nmal sentences. Following Luo et al. (2019b), we\nused the samples from the “Family & Relationship”\n(F&R) domain and restricted our focus to the infor-\nmal to formal direction. The test set contains 500\nformal and 500 informal sentences.\nJFLEG Corpus.The JHU FLuency-Extended\nGUG (JFLEG ) Corpus was introduced by Napoles\net al. (2017) to train and evaluate models for au-\ntomatic grammatical error correction. It contains\npaired grammatical and ungrammatical sentences\n(with three error types—namely, awkward, ortho-\ngraphic, and grammatical). In our experiments, we\nfocused on the ungrammatical to grammatical di-\nrection and used the publicly available test set that\ncontains 747 sentences.\nSymbolic Manipulation Task. We designed\nthis small synthetic dataset to investigate how skill-\nful the off-the-shelf language models are at writing\nsymbolic expressions as natural English-language\nsentences. This dataset contains 1,000 example\npairs, in which each input sample is written in a\nsymbolic form (as either “α> β” or “α< β”, where\nαand β are two different single words from the\nanimal color, fruit, and number categories) and its\ncorresponding output is basically the spoken utter-\nance in English.\nRemark. We realized that the original versions of\nall the aforementioned real-world TST datasets con-\ntain various tokenization issues (for instance, sen-\ntences sometimes contain extra whitespaces or have\ntheir puntuation marks separated out by spaces).\nWe did not wish these tokenization artifacts to di-\nminish the quality of our generations. To that end,\nwe used a simple text-cleaning procedure to clean\nthe texts before feeding them to our models.22\nA.2 Additional Evaluation Metrics\nHere, we describe in greater detail the standard au-\ntomatic evaluation metrics used in the assessment\nof the performance of TST models.\nContent Preservation.The standard metric for\nmeasuring semantic content preservation (or tex-\ntual similarity, as we call it) has been BLEU (Pap-\nineni et al., 2002): If reference (ground-truth) sen-\ntences are available, then reference-BLEU scores\nare calculated by comparing model outputs to\nhuman-written ground-truth outputs using n-grams.\nSome recent studies (Lample et al., 2019; Dai et al.,\n22For the AMAZON and YELP datasets, we show the benefit\nof data-cleaning on overall performance. We also publicly\nrelease our text-cleaning code.\n2207\n2019) further look at self -BLEU scores, compar-\ning model outputs to input sentences—this is par-\nticularly done when reference sentences are not\ndirectly available. In our evaluations, we primar-\nily used the SacreBLEU metric (Post, 2018)—as\nSacreBLEU has been shown to be a more reliable\nand accessible metric than BLEU—and considered\nboth reference-SacreBLEU (r-sBLEU) and self -\nSacreBLEU (s-sBLEU) scores.23 When evaluating\nthe performances of models on the JFLEG cor-\npus, we also used the sentence-level GLEU metric\n(Napoles et al., 2015), a variant of BLEU that was\nspecifically designed for evaluating grammatical\nerror correction (GEC) models.\nTransfer Strength.To determine whether out-\nputs generated by a TST model have the attributes\nof their target styles, the most common approach\nhas been to train a (binary) classifier on the training\nset of the corpus of focus, where the sentences are\ntaken as the inputs and their corresponding styles\nas the labels, and then to use this trained classifier\nto predict the percentage of the generated outputs\nfor which the styles predicted by the model match\ntheir target styles.24 In our sentiment transfer exper-\niments, we measured transfer strength (sentiment\naccuracy) by fine-tuning pre-trained RoBERTa clas-\nsifiers (Liu et al., 2019) on the training data in each\ncase. In our experiments on SHAKESPEARE , we\nused the RoBERTa-based Shakespeare classifier of\nKrishna et al. (2020). Finally, in our experiments\non GYAFC, we fine-tuned a pre-trained RoBERTa\nclassifier on a subset of F&R examples.25\nFluency. With the emergence of successful LMs\nat our disposal, most recent TST models measure\nthe fluency of their generated texts by computing\nperplexity (PPL) via a pre-trained LM like GPT-\n2.26 Whilst this PPL-driven approach has the ad-\nvantage of being automated and practical, it still\ncontains considerable drawbacks, among which bi-\nases towards short texts and more frequent tokens\ncan be listed right away. In our evaluations, we\nreported the average token-level PPL of generated\n23We used the SacreBLEU metric implemented in Hug-\nging Face’s Metrics library and lowered all the texts—both\npredictions and references—before calculating the scores.\n24This method of measuring transfer accuracy demands\naccess to either paired data for training a classifier or a pre-\ntrained classier that can accurately estimate the style of an\ninput text. It is, therefore, difficult to measure transfer accu-\nracy for arbitrary or unknown styles, because there may not\nbe any specific data to train a classifier.\n25We release all our fine-tuned classifiers on our codebase.\n26Early work used to measure fluency of sentences using\nan n-gram (typically trigram) Kneser-Ney language model.\ntexts using GPT-2-Large (774M).\nA.3 Full Results\nIn the tables below, we include zero-shot results\nfor the clean versions of AMAZON (Table 11) and\nYELP (Table 13), as well as the original versions\nof AMAZON (Table 10) and YELP (Table 12). We\nalso include four-shot results for the clean versions\nof AMAZON (Table 14), YELP (Table 15), SHAKE -\nSPEARE (Table 16), JFLEG (Table 17), GYAFC\n(Table 18), and SYM (Table 19).\nA.4 Further Discussion\nSentiment Transfer.Table 15 and Table 16 show\nthe results for the clean versions of AMAZON and\nYELP , respectively. In terms of sentiment accu-\nracy, GPT-2-XL yielded the best performance on\nboth datasets, achieving 70% (87%) positive →\nnegative accuracy and 56% (72%) negative →pos-\nitive on AMAZON (YELP ). In both cases, however,\nthe sBLEU scores of GPT-2-XL were relatively\nlower than those of other models, indicating that it\ncopied more from the source text. The GPT-Neo\nmodels had higher r-sBLEU and s-sBLEU scores\nthan GPT-2-XL on both AMAZON and YELP , with\nonly slightly worse accuracy scores. In the case\nof YELP -clean especially, the GPT-Neo/J models\nachieved good balances of sentiment accuracy, tex-\ntual similarity, and fluency.\nShakespeare-to-Modern English Translation.\nAs shown in Table 14, model performance gen-\nerally improves with model size, with GPT-J-6B\nachieving almost 80% accuracy (according to the\nsupervised classifier) and 21.9 r-sBLEU. Also no-\ntable is the difference between GPT-2-Small’s high\ns-sBLEU score and low classifier accuracy, relative\nto the other models. Together, these indicate that\nthe model copies large parts of the input text more\noften than the other GPT models.\nFormality Transfer and Grammatical Error\nCorrection. For GYAFC (Table 18), most models\nachieved accuracy scores above 80%, with increas-\ning model size correlating with BLEU score. No-\ntably, GPT-Neo-2.7B achieved an accuracy score\nof 81% and and a r-sBLEU score of 50 in the infor-\nmal to formal direction. For JFLEG (Table 17), on\nthe other hand, most models failed to outperform a\nsimple baseline, which automatically copied the in-\nput text without making any changes. This baseline\nachieves a GLEU score of 37.2, better than all mod-\nels except GPT-J (which obtains 40.0). Broadly,\n2208\nthere remains substantial room for improvement on\nJFLEG.\nSymbolic Manipulation. Our final task is de-\nsigned to measure the ability of these language\nmodels to copy and manipulate tokens under a re-\nfined synthetic experimental setup. With the excep-\ntion of GPT-J, no model exceeded 60% accuracy on\nthis synthetic dataset. GPT-J, by contrast, achieved\n74% accuracy.\nA.5 Additional Qualitative Examples\nWe provide additional qualitative examples from\nour language models in Tables 22-25.\nA.6 Additional Related Work\nHere, we describe additional related work on dif-\nferent subtasks of textual style transfer that could\nnot be included in the main component of the paper\ndue to space constraints.\nThese works can be broadly categorized into two\nfamilies. The first family of approaches involves\nidentifying and replacing distinctive style-related\nphrases (Li et al. (2018); Sudhakar et al. (2019);\nWu et al. (2019); Madaan et al. (2020); Malmi\net al. (2020); Reid and Zhong (2021), inter alia).\nFor instance, Madaan et al. (2020) tackle the task\nof politeness transfer with a two-step text-editing\napproach, first identifying words with stylistic at-\ntributes using a n-gram TF-IDF method and then\ntraining a model to replace or augment these stylis-\ntic words with ones associated with the target at-\ntribute. Similarly, Li et al. (2018) propose a simple\napproach to sentiment and style transfer based on\nthe idea that these attributes can often be identified\nby certain distinctive phrases. They identify these\nphrases, replace them with phrases associated with\nthe target attribute, and combine them with an RNN\nto improve the fluency of the output text. Recently,\nReid and Zhong (2021) propose to minimize the\nLevenshtein edit-distance between source and tar-\nget texts, using a fine-tuned LM to make targeted\nedits. In general, these approaches perform well\nfor very simple types of style transfer (e.g., nega-\ntion by adding the word not to a sentence), but they\nstruggle in scenarios that require more complex\nsyntactic and semantic changes.\nThe second family of approaches involves disen-\ntangling latent representations of style and content\nHu et al. (2017); Shen et al. (2017); Fu et al. (2018);\nLuo et al. (2019a); Wang et al. (2020) seek to learn\na style-invariant representation for a piece of text,\nsuch that it can then be decoded in an arbitrary style.\nFor example, Hu et al. (2017) encoded sentences\ninto a style-agnostic space and then decode them\nin a style-specific manner using a variational au-\ntoencoder alongside attribute discriminators. Shen\net al. (2017); Fu et al. (2018); Dai et al. (2019);\nWang et al. (2019) improved upon this method-\nology through the use of cross-alignment, style\nembeddings, rule-based systems, and new architec-\ntures. While these approaches are often theoreti-\ncally well-grounded, they generally require large\nquantities of labeled data and struggle with scaling\nbeyond a small number of styles.\nA.7 Computational Details\nThe computational cost of our experiments were\nquite low, as they only involve running inference\non pre-trained models. All experiments were con-\nducted on a single GPU. We usde an NVidia V100\nfor all experiments except those with GPT-J-6B,\nfor which we used an RTX 8000 due to memory\nrequirements. We estimate that all experiments for\nthis paper consumed fewer than 30 GPU-days.\nA.8 License Details\nWe will release all code for this experiment under\nan open-source license (MIT License).\nA.9 Language Details\nAll datasets used for this paper are in English.\n2209\nDataset [Few-Shot Examples] and [Test-Time Input]\nAMAZON\nHere is a text, which is positive: {very small but it works great in the car.} Here is a rewrite of the text, which is negative:\n{very small and it works terribly in the car.} \\n ### \\n Here is a text, which is positive: {i really loved it and will use it alot.}\nHere is a rewrite of the text, which is negative: {i really disliked it and will not use it again.} \\n ### \\n Here is a text, which\nis positive: {it gets the job done and for the price you can t beat it.} Here is a rewrite of the text, which is negative: {it does\nnot work well and it was expensive.} \\n ### \\n Here is a text, which is negative: {i will never buy anything from this brand\nagain.} Here is a rewrite of the text, which is positive: {i will buy from this brand again.} \\n ### \\n Here is a text, which is\nnegative: {if your bike had a kickstand on the plate it won’t lock down. } Here is a rewrite of the text, which is positive: {\nYELP\nHere is a text, which is negative: {this place is awful!} Here is a rewrite of the text, which is positive: {this place is\namazing!} \\n ### \\n Here is a text, which is positive: {definitely will buy another pair of socks from this store–they have\nthe best socks ever} Here is a rewrite of the text, which is negative: {definitely will NOT buy another pair of socks from\nthis store–they have the worst socks ever} \\n ### \\n Here is a text, which is negative: {my wife and i were disappointed by\nthe quality of the service–also, the food was pretty tasteless} Here is a rewrite of the text, which is positive: {my wife\nand i were impressive by the quality of the service–also, the food was pretty delicious} \\n ### \\n Here is a text, which is\npositive: {i loved their black tea and hot chocolate selections!} Here is a rewrite of the text, which is negative: {i hated\ntheir black tea and hot chocolate selections!} \\n ### \\n Here is a text, which is positive: {it’s small yet they make you feel\nright at home.} Here is a rewrite of the text, which is negative: {\nSHAKESPEARE\nHere is a text, which is written in old English: {what hast thou there?} Here is a rewrite of the text, which is written in\nmodern English: {what have you got there?} \\n ### \\n Here is a text, which is written in old English: {what say’st thou,\nmy dear nurse?} Here is a rewrite of the text, which is written in modern English: {what did you say, my dear nurse?} \\n\n### \\n Here is a text, which is written in old English: {and how doth she?} Here is a rewrite of the text, which is written in\nmodern English: {and how is she doing?} \\n ### \\n Here is a text, which is written in old English: {talk not to me, for i’ll\nnot speak a word.} Here is a rewrite of the text, which is written in modern English: {don’t talk to me, because i won’t\nanswer you.} \\n ### \\n Here is a text, which is old English: {as mine on hers, so hers is set on mine, and all combined,\nsave what thou must combine by holy marriage.} Here is a rewrite of the text, which is modern English: {\nGYAFC\n\\n Here is a text, which is informal: {sorry but donnt know if i can do this alone.} Here is a rewrite of the text, which is\nformal: {I am sorry, but I don’t know if I can do this alone.} \\n ### \\n Here is a text, which is formal: {i am going to ask\nhim to come to the concert with me, and i hope he accepts my invitation.} Here is a rewrite of the text, which is informal:\n{gonna ask him to come to the concert with me and hope he says yes :)} \\n ### \\n Here is a text, which is informal: {that\nsucks man but u gotta move on} Here is a rewrite of the text, which is formal: {that is unfortunate, but you need to move\non} \\n ### \\n Here is a text, which is formal: {and i am sorry that you and your girlfriend broke up last week.} Here is a\nrewrite of the text, which is informal: {and im sorry that u and ur girlfriend broke up last week...} \\n ### \\n Here is a text,\nwhich is formal: {i mean that you have to really be her friend.} Here is a rewrite of the text, which is informal: {\nJFLEG\n\\n Here is a text, which is ungrammatical: {There are several reason.} Here is a rewrite of the text, which is grammatical:\n{There are several reasons.} \\n ### \\n Here is a text, which is ungrammatical: {To my surprize nothing happened.} Here\nis a rewrite of the text, which is grammatical: {To my surprise, nothing happened.} \\n ### \\n Here is a text, which is\nungrammatical: {This is important thing.} Here is a rewrite of the text, which is grammatical: {This is an important\nthing.} \\n ### \\n Here is a text, which is ungrammatical: {Water is needed for alive.} Here is a rewrite of the text, which is\ngrammatical: {Water is necessary to live.} \\n ### \\n Here is a text, which is ungrammatical: {New and new technology\nhas been introduced to the society.} Here is a rewrite of the text, which is grammatical: {\nSYM\nHere is a text, which is symbolic: {apple > seven} Here is a rewrite of the text, which is English: {apple is greater than\nseven} \\n ### \\n Here is a text, which is symbolic: {tiger < robin} Here is a rewrite of the text, which is English: {tiger is\nless than robin} \\n ### \\n Here is a text, which is symbolic: {teal > green} Here is a rewrite of the text, which is English:\n{teal is greater than green} \\n ### \\n Here is a text, which is symbolic: {apple < dog} Here is a rewrite of the text, which is\nEnglish: {apple is less than dog} \\n ### \\n Here is a text, which is symbolic: {yellow > gray} Here is a rewrite of the text,\nwhich is English: {\nTable 9:A complete list of example-prompts used in our few-shot experiments. Here, the color gray is used to\nhighlight the examples used in our setups and the color teal an example test-time input in each specific TST task.\n2210\nPositive→Negative Negative→Positive\nModel Delimiter-Pair Acc r-sBLEU s-sBLEU PPL Acc r-sBLEU s-sBLEU PPL\nGPT-2-Small\n(117M)\n⟨·⟩ 0.35 12.4 22.7 34 0.19 11.4 23.6 33\n* \"·\" 0.43 9.0 15.9 42 0.24 7.3 14.5 40\n⟩\" ·\" 0.46 6.6 11.3 29 0.23 6.8 14.1 30\n{·} 0.33 14.1 26.4 35 0.18 15.0 31.3 39\n–·– 0.40 6.8 12.6 29 0.17 6.5 13.8 26\n{{·}} 0.36 27.0 49.7 85 0.20 27.0 56.0 94\n(·) 0.35 18.1 32.7 54 0.18 17.6 38.2 59\n\" ·\" 0.45 8.2 14.2 32 0.21 8.4 16.2 33\n[·] 0.35 18.9 35.5 60 0.21 14.3 29.3 43\n⟨⟨⟨·⟩⟩⟩ 0.42 6.4 12.1 24 0.19 6.7 14.1 26\nGPT-2-Medium\n(345M)\n⟨·⟩ 0.42 21.9 37.9 67 0.27 23.2 45.0 72\n* \"·\" 0.46 11.1 20.0 45 0.31 7.8 15.2 32\n⟩\" ·\" 0.45 13.4 22.4 43 0.29 6.2 13.4 27\n{·} 0.44 21.6 38.2 73 0.26 19.1 37.1 67\n–·– 0.63 4.2 7.0 22 0.31 3.7 7.6 21\n{{·}} 0.45 25.3 43.2 69 0.27 20.2 39.8 67\n(·) 0.49 19.4 32.4 69 0.31 18.1 35.5 69\n\" ·\" 0.47 11.3 19.2 35 0.28 9.2 17.5 34\n[·] 0.54 17.1 28.6 63 0.32 13.1 26.3 52\n⟨⟨⟨·⟩⟩⟩ 0.47 14.2 25.3 43 0.28 10.8 21.1 35\nGPT-2-Large\n(774M)\n⟨·⟩ 0.38 25.5 43.7 52 0.24 27.8 58.0 73\n* \"·\" 0.39 27.1 46.7 72 0.25 22.9 47.0 60\n⟩\" ·\" 0.39 27.1 46.9 66 0.23 26.5 53.7 70\n{·} 0.39 28.7 48.8 77 0.24 28.0 54.8 63\n–·– 0.50 8.8 15.4 22 0.22 6.5 13.3 18\n{{·}} 0.43 27.7 46.5 63 0.25 36.6 69.3 113\n(·) 0.41 22.2 38.9 48 0.26 22.9 45.1 59\n\" ·\" 0.52 19.7 31.4 57 0.30 17.7 34.2 48\n[·] 0.44 22.0 36.8 53 0.26 19.4 38.7 44\n⟨⟨⟨·⟩⟩⟩ 0.47 13.1 21.9 28 0.28 12.2 24.6 25\nGPT-2-XL\n(1558M)\n⟨·⟩ 0.40 26.3 43.0 81 0.31 25.9 48.2 82\n* \"·\" 0.42 22.7 39.3 60 0.29 17.6 33.3 44\n⟩\" ·\" 0.43 20.8 35.1 54 0.29 17.9 34.0 47\n{·} 0.47 23.8 37.6 73 0.31 22.7 42.5 80\n–·– 0.56 5.6 9.0 19 0.28 4.3 7.8 18\n{{·}} 0.42 29.8 49.8 99 0.29 25.7 46.4 80\n(·) 0.45 16.4 28.8 41 0.28 17.8 33.6 53\n\" ·\" 0.47 16.1 26.2 38 0.30 14.6 28.4 41\n[·] 0.46 19.2 30.8 60 0.32 16.4 31.4 52\n⟨⟨⟨·⟩⟩⟩ 0.51 9.0 13.9 25 0.37 7.4 12.7 26\nGPT-Neo-1.3B\n(1.3B)\n⟨·⟩ 0.48 14.9 26.1 48 0.29 11.0 21.5 40\n* \"·\" 0.41 15.1 26.8 36 0.25 13.8 28.5 44\n⟩\" ·\" 0.38 19.7 36.0 60 0.26 18.9 37.4 48\n{·} 0.48 11.0 18.7 32 0.30 8.8 16.6 31\n–·– 0.54 5.0 8.6 18 0.30 4.9 9.6 18\n{{·}} 0.49 15.3 25.0 47 0.31 13.6 24.6 42\n(·) 0.44 14.3 25.3 44 0.27 15.5 29.1 51\n\" ·\" 0.39 19.5 33.4 50 0.25 15.8 31.4 37\n[·] 0.46 15.1 27.0 51.7 0.26 15.1 30.4 47\n⟨⟨⟨·⟩⟩⟩ 0.56 5.9 9.2 28 0.32 4.6 8.1 22\nGPT-Neo-2.7B\n(2.7B)\n⟨·⟩ 0.43 20.0 36.1 53 0.27 22.2 43.8 59\n* \"·\" 0.37 26.2 46.7 65 0.21 26.8 54.1 65\n⟩\" ·\" 0.37 26.1 45.9 68 0.22 23.6 50.7 60\n{·} 0.44 21.6 37.7 61 0.29 27.1 51.4 80\n–·– 0.56 4.4 7.7 15 0.23 4.0 8.2 14\n{{·}} 0.42 23.7 42.0 56 0.24 29.5 58.5 72\n(·) 0.44 19.7 32.9 48 0.27 21.1 40.9 64\n\" ·\" 0.38 26.1 44.5 67 0.22 26.3 52.7 67\n[·] 0.48 20.3 35.6 67 0.25 22.4 42.9 58\n⟨⟨⟨·⟩⟩⟩ 0.45 14.1 24.8 32 0.22 21.0 42.1 55\nGPT-J-6B\n(6B)\n⟨·⟩ 0.40 27.3 47.0 74 0.32 17.0 32.7 51\n* \"·\" 0.38 29.2 49.5 82 0.28 23.4 42.9 61\n⟩\" ·\" 0.36 27.4 47.2 69 0.30 23.1 43.6 64\n{·} 0.41 27.8 47.6 80 0.32 24.9 45.6 78\n–·– 0.43 7.1 12.3 19 0.20 4.8 9.0 17\n{{·}} 0.29 30.4 54.9 72 0.29 26.8 51.1 76\n(·) 0.48 24.9 41.6 80 0.35 22.3 39.3 77\n\" ·\" 0.39 28.6 47.3 69 0.31 23.0 42.4 64\n[·] 0.43 23.3 38.2 63 0.37 20.8 38.3 60\n⟨⟨⟨·⟩⟩⟩ 0.34 30.3 55.6 98 0.31 23.6 44.2 67\nTable 10:Zero-shot performances of the off-the-shelf “small” language models from the GPT-2 and GPT-Neo/J\nfamilies on the original version of the AMAZON dataset. Here, we also experimented with ten different delimiter-\npairs, ranging from curly brackets to asterisk quotes: Overall, curly brackets {·}, square brackets [·], parentheses (·),\nand quotes \" ·\" yielded consistently reliable and high-quality outputs. Most of the models could not go beyond\n60% accuracy in the positive to negative direction and 35% accuracy in the negative to positive direction. As shown\nin Table 11, most models performed marginally better (in terms of their accuracy, BLEU, and PPL scores) on\nthe cleaner version of the dataset, suggesting that the original version might contain some tokenization-related\n(semantic) noises that might be preventing the models from performing well.\n2211\nPositive→Negative Negative→Positive\nModel Delimiter-Pair Acc r-sBLEU s-sBLEU PPL Acc r-sBLEU s-sBLEU PPL\nGPT-2-Small\n(117M)\n⟨·⟩ 0.34 17.9 33.4 47 0.19 13.7 30.5 42\n* \"·\" 0.43 8.1 14.8 38 0.26 7.9 16.3 37\n⟩\" ·\" 0.45 6.3 11.6 29 0.25 7.7 15.4 32\n{·} 0.31 18.9 34.9 49 0.18 17.7 38.1 48\n–·– 0.42 6.6 12.0 24 0.21 6.6 13.7 26\n{{·}} 0.28 30.4 56.7 90 0.19 28.4 60.9 81\n(·) 0.34 22.2 39.1 57 0.21 18.7 40.1 48\n\" ·\" 0.46 8.7 15.9 35 0.27 7.3 14.9 34\n[·] 0.32 19.9 35.4 59 0.20 18.4 39.7 55\n⟨⟨⟨·⟩⟩⟩ 0.39 9.3 17.0 31 0.20 9.0 18.8 28\nGPT-2-Medium\n(345M)\n⟨·⟩ 0.43 19.3 33.7 49 0.28 16.8 33.4 47\n* \"·\" 0.52 10.4 17.2 31 0.33 7.6 15.1 29\n⟩\" ·\" 0.46 10.4 17.6 30 0.32 6.3 12.9 25\n{·} 0.48 21.9 36.7 68 0.32 20.1 38.0 57\n–·– 0.57 3.9 6.8 20 0.29 3.1 5.9 18\n{{·}} 0.45 23.3 40.1 62 0.31 21.2 41.1 64\n(·) 0.45 19.9 33.1 50 0.32 17.6 35.3 58\n\" ·\" 0.49 9.8 16.1 31 0.35 7.0 12.8 25\n[·] 0.50 15.7 25.9 42 0.30 13.2 26.1 46\n⟨⟨⟨·⟩⟩⟩ 0.48 8.8 14.8 26 0.31 10.1 19.2 30\nGPT-2-Large\n(774M)\n⟨·⟩ 0.40 26.3 44.6 68 0.29 22.9 43.4 52\n* \"·\" 0.44 23.5 40.9 54 0.27 18.8 36.9 42\n⟩\" ·\" 0.43 20.8 36.0 44 0.29 19.4 39.2 42\n{·} 0.44 28.6 49.1 70 0.28 26.0 51.2 55\n–·– 0.40 7.3 12.0 17 0.36 7.4 13.8 19\n{{·}} 0.43 31.0 53.1 90 0.29 31.3 60.0 79\n(·) 0.39 23.0 39.1 51 0.26 23.3 45.3 61\n\" ·\" 0.47 18.1 29.8 47 0.31 16.8 32.7 48\n[·] 0.47 20.2 34.3 50 0.26 17.5 34.1 42\n⟨⟨⟨·⟩⟩⟩ 0.49 9.9 16.2 21 0.27 9.4 18.2 22\nGPT-2-XL\n(1558M)\n⟨·⟩ 0.40 25.6 42.0 68 0.29 23.1 43.0 65\n* \"·\" 0.36 22.5 39.4 48 0.31 18.7 37.5 47\n⟩\" ·\" 0.40 18.8 31.5 43 0.27 19.2 37.8 46\n{·} 0.46 21.5 35.4 59 0.32 22.3 41.4 70\n–·– 0.53 7.2 11.7 23 0.32 6.9 11.8 21\n{{·}} 0.45 25.7 43.2 81 0.31 24.8 45.4 72\n(·) 0.48 19.3 30.7 52 0.30 17.8 33.4 53\n\" ·\" 0.45 20.5 33.6 49 0.31 17.9 33.4 51\n[·] 0.47 21.1 33.4 55 0.32 19.2 34.7 55\n⟨⟨⟨·⟩⟩⟩ 0.47 7.8 13.1 24 0.38 6.8 12.5 25\nGPT-Neo-1.3B\n(1.3B)\n⟨·⟩ 0.50 11.4 20.1 38 0.30 10.6 19.7 34\n* \"·\" 0.38 15.0 25.0 37 0.26 11.9 22.4 31\n⟩\" ·\" 0.40 12.6 22.1 35 0.26 11.3 22.2 29\n{·} 0.49 11.8 19.9 34 0.31 10.9 20.5 35\n–·– 0.50 4.1 6.8 18 0.25 4.4 8.5 18\n{{·}} 0.48 13.9 23.9 41 0.35 12.4 22.9 38\n(·) 0.42 16.6 27.8 53 0.28 13.1 25.8 42\n\" ·\" 0.45 13.8 24.8 36 0.30 12.4 24.7 32\n[·] 0.46 16.7 28.1 45 0.26 14.7 28.5 43\n⟨⟨⟨·⟩⟩⟩ 0.57 3.4 5.8 20 0.36 3.1 5.5 18\nGPT-Neo-2.7B\n(2.7B)\n⟨·⟩ 0.44 20.1 34.8 51 0.29 19.5 38.3 46\n* \"·\" 0.40 27.2 47.9 61 0.22 28.9 57.6 58\n⟩\" ·\" 0.37 21.8 39.4 45 0.21 22.5 45.6 41\n{·} 0.48 21.4 36.5 55 0.28 23.7 45.9 57\n–·– 0.56 3.9 6.7 14 0.26 3.8 7.4 13\n{{·}} 0.43 21.2 36.2 44 0.27 28.0 55.7 56\n(·) 0.48 17.0 28.7 42 0.32 19.5 36.8 52\n\" ·\" 0.38 25.6 44.5 58 0.22 28.6 58.2 59\n[·] 0.48 18.7 32.1 47 0.26 23.3 46.2 50\n⟨⟨⟨·⟩⟩⟩ 0.49 14.8 24.9 33 0.32 18.7 37.3 37\nGPT-J-6B\n(6B)\n⟨·⟩ 0.40 25.0 43.4 66 0.35 20.1 35.7 56\n* \"·\" 0.42 26.8 44.8 60 0.33 23.5 41.9 56\n⟩\" ·\" 0.39 29.3 50.3 65 0.31 24.2 44.8 64\n{·} 0.41 26.1 44.6 57 0.33 27.1 47.7 72\n–·– 0.46 5.9 9.7 17 0.23 4.6 8.6 17\n{{·}} 0.30 29.9 53.8 56 0.30 27.5 52.3 73\n(·) 0.44 21.0 34.8 53 0.37 19.5 37.7 64\n\" ·\" 0.41 27.8 45.7 63 0.34 25.3 45.2 62\n[·] 0.45 20.1 34.0 53 0.36 20.8 37.7 65\n⟨⟨⟨·⟩⟩⟩ 0.39 28.3 47.4 66 0.32 25.6 47.2 66\nTable 11:Zero-shot performances of the off-the-shelf “small” language models on the clean version of theAMAZON\ndataset (AMAZON -clean, in short). As before, none of the models could go beyond the 60% accuracy level, but\nmost of them seem to have achieved slightly better perplexity scores in the clean version of the dataset than in the\noriginal version.\n2212\nPositive→Negative Negative→Positive\nModel Delimiter-Pair Acc r-sBLEU s-sBLEU PPL Acc r-sBLEU s-sBLEU PPL\nGPT-2-Small\n(117M)\n⟨·⟩ 0.38 10.1 29.7 49 0.11 13.8 40.6 47\n* \"·\" 0.41 3.1 10.6 31 0.21 4.4 14.0 33\n⟩\" ·\" 0.33 4.8 13.4 31 0.15 6.5 18.6 31\n{·} 0.36 8.4 23.3 35 0.15 7.8 23.5 34\n–·– 0.45 4.5 12.0 28 0.14 6.7 19.3 33\n{{·}} 0.37 13.4 38.9 62 0.11 16.6 49.1 54\n(·) 0.36 8.0 25.2 42 0.13 10.9 32.7 46\n\" ·\" 0.37 4.9 13.7 30 0.18 6.7 20.3 35\n[·] 0.36 6.8 20.7 38 0.12 8.7 25.2 31\n⟨⟨⟨·⟩⟩⟩ 0.43 2.1 5.8 17 0.09 2.1 6.4 17\nGPT-2-Medium\n(345M)\n⟨·⟩ 0.55 9.9 27.0 44 0.31 10.3 28.2 38\n* \"·\" 0.64 7.4 17.5 40 0.38 7.2 16.7 33\n⟩\" ·\" 0.52 5.5 15.3 26 0.31 5.8 14.8 26\n{·} 0.66 7.6 17.6 34 0.35 8.7 24.1 34\n–·– 0.69 4.6 11.3 30 0.36 5.0 12.3 27\n{{·}} 0.68 12.2 30.3 52 0.32 14.8 36.6 58\n(·) 0.63 8.5 22.1 46 0.32 10.5 26.8 48\n\" ·\" 0.66 5.1 13.1 29 0.41 6.3 15.2 30\n[·] 0.66 8.4 22.0 36 0.32 8.1 21.0 33\n⟨⟨⟨·⟩⟩⟩ 0.64 1.8 4.7 16 0.24 2.2 5.9 16\nGPT-2-Large\n(774M)\n⟨·⟩ 0.65 14.5 36.8 54 0.22 17.3 46.7 38\n* \"·\" 0.61 13.8 33.7 43 0.27 15.8 44.4 45\n⟩\" ·\" 0.57 16.2 44.0 59 0.27 18.7 51.4 53\n{·} 0.68 12.8 30.6 41 0.26 13.5 37.5 38\n–·– 0.64 8.9 22.3 31 0.24 9.7 26.3 25\n{{·}} 0.69 18.2 45.9 75 0.24 20.6 58.2 55\n(·) 0.68 10.6 26.0 40 0.28 15.4 40.6 46\n\" ·\" 0.74 12.0 25.9 44 0.34 14.3 34.7 42\n[·] 0.70 8.3 20.2 31 0.28 9.7 26.2 32\n⟨⟨⟨·⟩⟩⟩ 0.73 6.1 14.8 21 0.27 6.9 17.7 19\nGPT-2-XL\n(1558M)\n⟨·⟩ 0.67 15.0 35.3 59 0.41 16.4 40.4 54\n* \"·\" 0.67 10.0 25.0 35 0.37 13.0 31.6 36\n⟩\" ·\" 0.66 10.4 25.8 41 0.34 12.5 30.2 39\n{·} 0.78 9.7 21.1 41 0.41 12.1 30.1 40\n–·– 0.74 6.4 13.9 25 0.37 6.3 14.2 20\n{{·}} 0.67 17.2 38.9 61 0.35 18.8 49.2 66\n(·) 0.72 8.6 18.5 35 0.40 12.4 28.3 42\n\" ·\" 0.72 9.7 23.3 41 0.38 10.3 24.9 34\n[·] 0.72 9.2 22.0 35 0.41 10.1 23.5 31\n⟨⟨⟨·⟩⟩⟩ 0.70 4.0 9.5 18 0.39 4.6 11.0 17\nGPT-Neo-1.3B\n(1.3B)\n⟨·⟩ 0.61 6.5 16.0 28 0.38 6.8 15.7 26\n* \"·\" 0.31 13.3 38.7 33 0.24 13.5 35.4 37\n⟩\" ·\" 0.24 16.9 52.1 54 0.21 15.7 45.8 44\n{·} 0.66 3.2 8.4 19 0.38 5.3 12.2 21\n–·– 0.52 2.9 8.4 17 0.30 4.4 11.2 20\n{{·}} 0.60 9.1 23.6 35 0.39 8.5 21.2 30\n(·) 0.59 6.8 18.6 34 0.27 11.1 31.1 47\n\" ·\" 0.46 14.9 40.2 54 0.23 14.9 40.1 47\n[·] 0.57 8.1 20.8 38 0.36 8.4 22.1 33\n⟨⟨⟨·⟩⟩⟩ 0.68 1.3 3.8 17 0.38 1.9 4.1 16\nGPT-Neo-2.7B\n(2.7B)\n⟨·⟩ 0.68 8.3 21.8 28 0.28 12.5 33.1 31\n* \"·\" 0.56 14.1 39.1 54 0.18 18.1 51.9 51\n⟩\" ·\" 0.54 12.1 34.3 43 0.21 15.9 46.4 42\n{·} 0.63 7.5 19.5 27 0.26 12.4 32.8 32\n–·– 0.63 3.4 8.5 16 0.26 3.7 9.8 14\n{{·}} 0.55 12.0 32.9 40 0.20 16.2 48.1 42\n(·) 0.73 7.3 18.0 38 0.34 13.6 34.2 47\n\" ·\" 0.55 12.6 33.2 42 0.17 15.4 45.9 42\n[·] 0.62 8.0 21.3 33 0.27 13.7 37.0 39\n⟨⟨⟨·⟩⟩⟩ 0.64 4.6 12.6 21 0.27 7.1 18.5 20\nGPT-J-6B\n(6B)\n⟨·⟩ 0.60 14.9 37.6 52 0.44 14.4 33.0 51\n* \"·\" 0.57 16.2 41.0 57 0.36 16.1 37.1 49\n⟩\" ·\" 0.52 16.4 43.3 62 0.32 17.2 42.6 56\n{·} 0.60 13.6 36.1 51 0.46 14.3 32.0 46\n–·– 0.60 4.4 11.4 20 0.27 3.7 8.9 17\n{{·}} 0.44 16.2 44.4 50 0.34 17.8 43.0 56\n(·) 0.64 11.3 29.2 46 0.50 15.8 34.1 57\n\" ·\" 0.57 12.7 34.0 52 0.37 14.8 34.5 43\n[·] 0.58 13.6 35.3 56 0.51 13.1 29.1 44\n⟨⟨⟨·⟩⟩⟩ 0.47 16.1 45.3 58 0.40 13.5 31.7 43\nTable 12:Zero-shot performances of the off-the-shelf “small” language models on the original version of the YELP\ndataset. Amongst all the model architectures, GPT-J-6B had the finest results, both quantitatively and qualitatively.\nWe also note the performance differences between the positive to negative direction and the negative to positive\ndirection across all the experiments. It appears that the former direction is easier for all the models than the latter\ndirection. Furthermore, as in the case of AMAZON , Table 13 illustrates that most models performed slightly better\nin the the clean version of YELP than in the original version.\n2213\nPositive→Negative Negative→Positive\nModel Delimiter-Pair Acc r-sBLEU s-sBLEU PPL Acc r-sBLEU s-sBLEU PPL\nGPT-2-Small\n(117M)\n⟨·⟩ 0.34 13.1 37.9 52 0.14 12.9 38.2 50\n* \"·\" 0.38 3.2 9.2 30 0.23 3.7 11.3 29\n⟩\" ·\" 0.38 3.1 10.4 25 0.16 5.3 14.9 27\n{·} 0.36 6.6 19.3 28 0.12 8.2 25.7 29\n–·– 0.43 4.3 12.4 24 0.12 5.3 16.7 27\n{{·}} 0.37 16.0 45.0 67 0.12 17.2 54.0 59\n(·) 0.42 8.2 22.5 34 0.13 12.1 37.9 37\n\" ·\" 0.35 4.9 15.4 33 0.21 6.1 18.5 30\n[·] 0.42 8.3 23.0 41 0.13 11.3 35.9 39\n⟨⟨⟨·⟩⟩⟩ 0.50 1.5 4.0 14 0.11 1.9 5.9 15\nGPT-2-Medium\n(345M)\n⟨·⟩ 0.57 8.9 23.7 37 0.31 9.4 27.3 39\n* \"·\" 0.64 5.8 14.5 31 0.41 5.4 14.7 29\n⟩\" ·\" 0.52 5.7 16.7 28 0.30 5.6 15.0 26\n{·} 0.65 7.3 19.9 37 0.33 10.5 28.6 41\n–·– 0.66 3.9 9.7 23 0.34 3.0 7.4 20\n{{·}} 0.63 13.1 33.5 52 0.31 12.7 35.5 48\n(·) 0.64 9.4 25.3 44 0.29 11.8 33.8 44\n\" ·\" 0.63 5.2 14.2 29 0.42 6.1 15.9 27\n[·] 0.64 7.0 18.4 35 0.33 8.2 22.4 33\n⟨⟨⟨·⟩⟩⟩ 0.62 1.9 5.0 15 0.24 1.7 4.8 14\nGPT-2-Large\n(774M)\n⟨·⟩ 0.63 14.3 36.3 46 0.27 17.9 48.2 44\n* \"·\" 0.65 13.5 33.3 47 0.35 12.5 34.6 36\n⟩\" ·\" 0.61 13.9 35.9 47 0.32 15.3 42.9 44\n{·} 0.67 12.0 28.8 40 0.30 12.5 33.8 30\n–·– 0.65 5.0 13.7 18 0.26 7.3 19.8 20\n{{·}} 0.75 17.2 39.9 59 0.31 21.3 58.1 62\n(·) 0.69 12.2 29.2 47 0.31 14.6 40.7 46\n\" ·\" 0.77 11.8 27.3 41 0.37 11.7 29.6 34\n[·] 0.75 10.3 24.7 40 0.38 12.9 32.9 38\n⟨⟨⟨·⟩⟩⟩ 0.72 3.6 9.1 16 0.31 4.2 10.7 15\nGPT-2-XL\n(1558M)\n⟨·⟩ 0.64 17.4 40.1 58 0.35 17.3 41.5 53\n* \"·\" 0.69 11.3 28.2 40 0.41 12.6 31.3 33\n⟩\" ·\" 0.71 9.7 22.1 36 0.35 11.6 28.6 34\n{·} 0.73 8.6 21.3 35 0.46 11.4 25.9 35\n–·– 0.70 6.0 15.4 23 0.39 6.8 17.5 25\n{{·}} 0.63 17.4 40.9 70 0.38 19.1 46.8 59\n(·) 0.72 10.8 25.0 45 0.39 14.0 31.1 41\n\" ·\" 0.77 7.6 17.6 31 0.44 9.9 23.1 30\n[·] 0.75 10.8 24.9 38 0.41 12.0 29.9 43\n⟨⟨⟨·⟩⟩⟩ 0.68 2.2 5.4 14 0.32 2.0 5.1 13\nGPT-Neo-1.3B\n(1.3B)\n⟨·⟩ 0.68 6.5 16.7 27 0.42 6.9 17.6 29\n* \"·\" 0.38 12.5 37.0 37 0.22 12.5 36.2 33\n⟩\" ·\" 0.32 13.7 42.3 41 0.19 16.1 47.9 40\n{·} 0.69 4.6 10.5 22 0.37 6.3 15.3 23\n–·– 0.58 3.1 8.1 18 0.33 4.2 11.1 17\n{{·}} 0.69 7.2 17.0 30 0.40 8.9 20.6 27\n(·) 0.63 8.6 21.3 39 0.28 8.3 23.3 28\n\" ·\" 0.47 12.6 35.2 43 0.30 13.8 35.6 36\n[·] 0.68 8.3 21.4 40 0.34 8.6 23.9 30\n⟨⟨⟨·⟩⟩⟩ 0.72 1.2 2.9 15 0.38 1.7 3.6 15\nGPT-Neo-2.7B\n(2.7B)\n⟨·⟩ 0.66 8.8 23.4 31 0.32 13.9 35.3 36\n* \"·\" 0.58 14.5 36.9 42 0.17 17.4 51.1 42\n⟩\" ·\" 0.54 13.8 38.3 43 0.21 13.2 39.9 32\n{·} 0.64 7.0 19.0 24 0.28 11.0 32.6 29\n–·– 0.68 3.4 9.1 17 0.26 5.0 14.3 16\n{{·}} 0.57 11.0 29.3 31 0.24 15.5 46.1 35\n(·) 0.76 10.3 23.1 44 0.41 14.4 33.6 43\n\" ·\" 0.59 12.5 33.6 42 0.21 14.9 43.4 38\n[·] 0.66 9.6 23.7 32 0.29 14.9 42.4 43\n⟨⟨⟨·⟩⟩⟩ 0.64 5.4 14.4 21 0.27 8.1 21.7 23\nGPT-J-6B\n(6B)\n⟨·⟩ 0.62 14.1 35.3 50 0.47 14.7 33.4 44\n* \"·\" 0.55 17.1 43.9 65 0.40 13.2 31.8 41\n⟩\" ·\" 0.61 16.9 41.6 56 0.38 13.3 30.5 37\n{·} 0.61 14.3 34.7 49 0.48 13.5 30.6 43\n–·– 0.54 5.4 14.7 22 0.36 4.8 10.9 19\n{{·}} 0.42 14.7 42.3 38 0.33 17.5 45.0 53\n(·) 0.66 12.9 30.7 50 0.51 11.5 23.4 44\n\" ·\" 0.66 15.7 36.1 55 0.40 16.6 36.2 45\n[·] 0.69 11.8 28.7 45 0.53 13.3 27.3 43\n⟨⟨⟨·⟩⟩⟩ 0.53 10.7 29.8 35 0.43 11.4 25.4 30\nTable 13:Zero-shot performances of the off-the-shelf “small” language models on the clean version of the YELP\ndataset (YELP -clean, in short). In contrast to Table 12, we note that models, overall, achieved better results in\nYELP -clean than in YELP -original. Some models even could go beyond the 75% accuracy level in the positive to\nnegative direction. Consistent with the previous findings, these results also indicate that curly brackets {·}, square\nbrackets [·], parentheses (·), and quotes \" ·\" are favourable delimiter-pairs, leading to better outcomes than many\nother delimiter-pairs.\n2214\nShakespearean→Modern English\nModel Setting Acc r-sBLEU s-sBLEU PPL\nGPT-2-Small(117M) 4-Shot (Top Choice) 0.35 17.1 42.4 65\nGPT-2-Medium(345M) 4-Shot (Top Choice) 0.50 7.1 13.9 65\nGPT-2-Large(774M) 4-Shot (Top Choice) 0.38 14.1 30.9 134\nGPT-2-XL(1558M) 4-Shot (Top Choice) 0.39 18.9 38.4 90\nGPT-Neo-1.3B(1.3B) 4-Shot (Top Choice) 0.39 17.2 37.0 63\nGPT-Neo-2.7B(2.7B) 4-Shot (Top Choice) 0.62 23.9 41.4 106\nGPT-J-6B(6B) 4-Shot (Top Choice) 0.78 21.9 31.8 81\nTable 14: Four-shot performances of the off-the-shelf “small” language models on the clean version of the\nSHAKESPEARE corpus. In this few-shot setup, we included a simple natural-language task description and four\nillustrative examples in the prompt. We note that GPT-J-6B was able to “translate” sentences written in Elizabethan\nEnglish to Modern English successfully, achieving a transfer accuracy score of 78%, reference BLEU score of 21.9,\nand perplexity value of 81.\nPositive→Negative Negative→Positive\nModel Setting Acc r-sBLEU s-sBLEU PPL Acc r-sBLEU s-sBLEU PPL\nStyle-Embedding\nLi et al. (2018)\n0.33 16.2 33.2 265 0.47 13.1 29.0 287\nCrossAligned 0.66 2.2 3.0 93 0.74 1.7 2.4 96\nDeleteAndRetrieve 0.49 33.3 60.3 120 0.51 26.7 53.5 113\nTemplateBased 0.65 38.1 70.5 243 0.56 31.0 65.7 200\nGPT-2-Small\n(117M)\n0-Shot (Top Choice) 0.31 18.9 34.9 49 0.18 17.7 38.1 48\n4-Shot (Top Choice) 0.32 23.8 46.1 94 0.25 27.7 58.2 67\n4-Shot (RC: 3, IF)0.42 21.1 39.2 68 0.32 24.6 51.0 69\n4-Shot (RC: 3, FS) 0.38 23.0 43.5 73 0.30 27.2 52.4 77\nGPT-2-Medium\n(345M)\n0-Shot (Top Choice) 0.48 21.9 36.7 68 0.32 20.1 38.0 57\n4-Shot (Top Choice) 0.44 12.3 17.8 78 0.42 11.5 17.8 72\n4-Shot (RC: 3, IF)0.58 12.6 18.6 66 0.55 10.2 15.0 53\n4-Shot (RC: 3, FS) 0.52 7.2 10.0 59 0.50 5.6 9.0 56\nGPT-2-Large\n(774M)\n0-Shot (Top Choice) 0.44 28.6 49.1 70 0.28 26.0 51.2 55\n4-Shot (Top Choice) 0.47 17.1 27.7 54 0.32 15.0 27.4 101\n4-Shot (RC: 3, IF)0.60 15.4 24.7 62 0.43 15.6 27.7 59\n4-Shot (RC: 3, FS) 0.55 21.6 33.1 55 0.35 20.0 34.7 53\nGPT-2-XL\n(1558M)\n0-Shot (Top Choice) 0.46 21.5 35.4 59 0.32 22.3 41.4 70\n4-Shot (Top Choice) 0.63 13.7 20.3 65 0.44 14.5 22.3 60\n4-Shot (RC: 3, IF)0.70 11.5 17.2 77 0.56 13.2 19.9 50\n4-Shot (RC: 3, FS) 0.66 11.5 16.6 54 0.50 14.8 19.7 58\nGPT-Neo-1.3B\n(1.3B)\n0-Shot (Top Choice) 0.49 11.8 19.9 34 0.31 10.9 20.5 35\n4-Shot (Top Choice) 0.53 22.1 35.8 68 0.34 22.0 39.6 67\n4-Shot (RC: 3, IF)0.60 21.2 33.4 66 0.39 21.6 36.2 65\n4-Shot (RC: 3, FS) 0.56 22.2 33.1 67 0.32 20.9 32.6 63\nGPT-Neo-2.7B\n(2.7B)\n0-Shot (Top Choice) 0.48 21.4 36.5 55 0.28 23.7 45.9 57\n4-Shot (Top Choice) 0.52 22.3 33.7 74 0.35 22.3 39.5 74\n4-Shot (RC: 3, IF)0.60 21.7 32.3 69 0.42 20.6 34.9 66\n4-Shot (RC: 3, FS) 0.55 21.2 30.2 65 0.40 19.2 29.7 60\nGPT-J-6B\n(6B)\n0-Shot (Top Choice) 0.41 26.1 44.6 57 0.33 27.1 47.7 72\n4-Shot (Top Choice) 0.59 20.5 31.9 69 0.46 18.1 28.8 60\n4-Shot (RC: 3, IF)0.65 21.5 31.4 70 0.52 19.3 29.3 58\n4-Shot (RC: 3, FS) 0.64 17.0 24.7 61 0.50 18.6 25.7 59\nTable 15:Four-shot results on AMAZON -clean. We show the average results under (i) the zero-shot setting (0-Shot\n(Top Choice)); (ii) the four-shot setting in which we chose the top beam search result (4-Shot (Top Choice); (iii) the\nfour-shot setting in which we generated three outputs from the model, re-scored and re-ranked them according to\nthe textual similarity and style factors—ignoring the fluency aspect—(4-Shot (RC: 3, IF)); and (iv) the four-shot\nsetting in which we generated three outputs from the model, re-scored and re-ranked them according to the textual\nsimilarity, style, and fluency factors ( 4-Shot (RC: 3, FS) . (Here, “RC” denotes to the re-ranking-and-choosing\nmethod, “IF” ignoring fluency, and “FS” full set (meaning that we consider all the textual similarity, transfer\naccuracy, and fluency criteria). First, we stress that proving few-shot examples in the input resulted in 10-15%\nimprovements in the accuracy scores in most of our models (see 0-shot results vs. 4-shot results). Second, we\nhighlight that some of our off-the-shelf models (e.g., GPT-2-XL and GPT-J-6B) performed on par with, and\neven succeeded the performances of, the specially-tailored models of Li et al. (2018) along certain metrics. (For\ninstance, our off-the-shelf models achieve significantly lower perplexity rates than theirs.) Third, we note that the\nPrompt-and-Rerank method (described in §3.2) seems to boost the models’ performances in almost all the cases.\nFourth, we note that 4-Shot (RC: 3, IF) often performs noticeably better than 4-Shot (RC: 3, FS) across all the\nmodels, suggesting that we may not need to include the fluency factor in our re-scoring calculations after all.\n2215\nPositive→Negative Negative→Positive\nModel Setting Acc r-sBLEU s-sBLEU PPL Acc r-sBLEU s-sBLEU PPL\nBackTranslation (Prabhumoye et al., 2018)0.90 2.0 2.7 120 0.99 1.9 2.6 64\nUnpairedRL (Xu et al., 2018) 0.42 16.1 46.0 408 0.56 17.5 45.3 362\nCrossAlignment (Shen et al., 2017) 0.72 7.3 19.3 244 0.74 8.3 19.3 190\nMultidecoder (Fu et al., 2018) 0.42 13.4 43.2 376 0.49 12.6 35.5 369\nStyleEmbedding 0.08 19.7 71.3 154 0.10 18.9 62.7 197\nStyle-Embedding\nLi et al. (2018)\n0.08 19.7 71.3 154 0.10 18.9 62.7 197\nDelete-Only 0.89 12.7 33.1 195 0.81 14.0 34.7 169\nRetrieve-Only 1.00 1.1 2.1 93 0.98 1.8 2.8 86\nCrossAligned 0.72 7.3 19.3 244 0.74 8.3 19.3 190\nDeleteAndRetrieve 0.90 14.5 36.8 279 0.89 14.8 35.9 100\nTemplateBased 0.84 21.2 55.2 289 0.83 20.9 55.7 190\nDualR (Luo et al., 2019b) 0.91 26.5 58.7 125 0.85 25.3 58.8 141\nB-GST (Sudhakar et al., 2019)0.83 19.8 46.8 153 0.79 23.4 46.1 163\nMulti-Class (StyleTransformer,\nDai et al. (2019))\n0.94 26.3 61.0 177 0.77 26.5 65.0 173\nConditional 0.95 22.6 52.6 211 0.87 23.1 53.0 234\nGPT-2-Small\n(117M)\n0-Shot (Top Choice) 0.36 6.6 19.3 28 0.12 8.2 25.7 29\n4-Shot (Top Choice) 0.08 24.8 75.2 94 0.10 23.1 74.1 81\n4-Shot (RC: 3, IF) 0.14 21.5 71.0 73 0.17 18.5 58.5 99\n4-Shot (RC: 3, FS) 0.06 26.7 84.6 72 0.09 27.9 85.4 68\nGPT-2-Medium\n(345M)\n0-Shot (Top Choice) 0.65 7.3 19.9 37 0.33 10.5 28.6 41\n4-Shot (Top Choice) 0.49 14.5 34.1 72 0.35 13.3 35.2 56\n4-Shot (RC: 3, IF) 0.68 15.0 35.1 69 0.53 12.6 29.8 45\n4-Shot (RC: 3, FS) 0.43 20.4 46.4 74 0.40 17.7 43.5 48\nGPT-2-Large\n(774M)\n0-Shot (Top Choice) 0.67 12.0 28.8 40 0.30 12.5 33.8 30\n4-Shot (Top Choice) 0.79 16.6 32.8 84 0.57 14.5 31.0 74\n4-Shot (RC: 3, IF) 0.79 10.6 24.7 79 0.58 12.1 30.3 53\n4-Shot (RC: 3, FS) 0.58 23.0 56.8 76 0.45 22.1 53.5 64\nGPT-2-XL\n(1558M)\n0-Shot (Top Choice) 0.73 8.6 21.3 35 0.46 11.4 25.9 35\n4-Shot (Top Choice) 0.63 13.7 20.3 65 0.44 14.5 22.3 60\n4-Shot (RC: 3, IF) 0.87 14.8 28.7 65 0.72 12.0 25.3 55\n4-Shot (RC: 3, FS) 0.77 21.1 38.7 85 0.62 18.0 35.2 70\nGPT-Neo-1.3B\n(1.3B)\n0-Shot (Top Choice) 0.69 4.6 10.5 22 0.37 6.3 15.3 23\n4-Shot (Top Choice) 0.78 14.8 30.2 58 0.45 14.5 32.0 56\n4-Shot (RC: 3, IF) 0.85 14.6 30.1 59 0.61 13.1 28.3 42\n4-Shot (RC: 3, FS) 0.77 22.5 46.1 87 0.49 23.5 46.1 72\nGPT-Neo-2.7B\n(2.7B)\n0-Shot (Top Choice) 0.64 7.0 19.0 24 0.28 11.0 32.6 29\n4-Shot (Top Choice) 0.83 22.8 42.7 89 0.42 21.8 47.1 89\n4-Shot (RC: 3, IF) 0.88 23.5 45.8 96 0.52 22.0 48.0 69\n4-Shot (RC: 3, FS) 0.80 24.5 44.5 87 0.48 23.9 48.4 68\nGPT-J-6B\n(6B)\n0-Shot (Top Choice) 0.61 14.3 34.7 49 0.48 13.5 30.6 43\n4-Shot (Top Choice) 0.81 25.3 50.5 107 0.52 21.7 48.7 82\n4-Shot (RC: 3, IF) 0.87 23.0 47.7 80 0.65 20.2 44.6 58\n4-Shot (RC: 3, FS) 0.79 25.9 51.5 78 0.55 26.3 50.0 67\nTable 16:Four-shot results on YELP -clean. As before, we detail the average results under different zero- and\nfew-shot settings: Overall, our few-shot results on YELP -clean are consistent with those on AMAZON -clean, as\nreported in Table 15. GPT-2-XL and GPT-J-6B models, amongst all the models, have achieved the most successful\nperformances, leveling themselves almost with the custom-made (trained) state-of-the-art models. We present some\nof the generated examples from these models in Table 21.\n2216\nUngrammatical→Grammatical\nModel Setup GLEU r-sBLEU s-sBLEU PPL\nGPT-2-Small(117M) 4-Shot (Top Choice) 35.9 74.8 91.5 76\nGPT-2-Medium(345M) 4-Shot (Top Choice) 19.9 38.0 40.6 63\nGPT-2-Large(774M) 4-Shot (Top Choice) 30.0 56.8 64.1 55\nGPT-2-XL(1558M) 4-Shot (Top Choice) 24.8 46.2 47.0 57\nGPT-Neo-1.3B(1.3B) 4-Shot (Top Choice) 26.6 48.4 49.4 54\nGPT-Neo-2.7B(2.7B) 4-Shot (Top Choice) 34.5 57.4 54.1 40\nGPT-J-6B (6B) 4-Shot (Top Choice) 40.0 64.8 59.1 48\nTable 17:Four-shot performances of the off-the-shelf “small” language models on the clean version of the JFLEG\ncorpus. In this task, as a baseline, we consider the model which directly copies its input—we call this model\n“copy-input” model; this model achieves a GLEU score score 37.7. All but GPT-J-6B fail to beat the performance of\nthe baseline “copy-input” model. GPT-J-6B, on the other hand, achieves a GLEU score of 40.0. Small language\nmodels fail, in fact rather miserably, at this grammatical error correction task. There is therefore an open room for\nimprovement. We hope that our results will encourage researchers to come up with more effective ways to utilize\npre-trained language models to solve this challenging problem.\nInformal→Formal\nModel Setup Accuracy r-sBLEU s-sBLEU PPL\nGPT-2-Small(117M) 4-Shot (Top Choice) 0.85 6.1 8.7 41\nGPT-2-Medium(345M) 4-Shot (Top Choice) 0.76 12.9 16.2 39\nGPT-2-Large(774M) 4-Shot (Top Choice) 0.78 23.2 31.3 33\nGPT-2-XL(1558M) 4-Shot (Top Choice) 0.82 32.7 41.9 58\nGPT-Neo-1.3B (1.3B) 4-Shot (Top Choice) 0.85 36.4 49.6 68\nGPT-Neo-2.7B(2.7B) 4-Shot (Top Choice) 0.81 50.0 61.2 64\nGPT-J-6B(6B) 4-Shot (Top Choice) 0.69 47.9 52.3 49\nTable 18: Four-shot results on GYAFC-clean. We highlight that most of the off-the-shelf “small” language\nmodels could obtain at least 80% accuracy in the informal to formal direction. Amongst all the models, GPT-2-XL,\nGPT-Neo-1.3B, and GPT-Neo-2.7B appeared to be most successful, achieving not only high accuracy scores but\nalso high BLEU scores and relatively low perplexity rates.\nModel Correct-Class Accuracy Opposite-Class Accuracy reference-sBLEU\nGPT-2-Small 0.42 0.46 51.9\nGPT-2-Medium 0.46 0.46 60.3\nGPT-2-Large 0.53 0.35 65.6\nGPT-2-XL 0.56 0.38 68.5\nGPT-Neo-1.3B 0.55 0.37 67.3\nGPT-Neo-2.7B 0.57 0.38 69.6\nGPT-J-6B 0.74 0.21 81.9\nTable 19:Four-shot performances of the off-the-shelf “small” language models on the symbolic manipulation task\n(SYM) defined in §5.1. Correct-Class accuracy refers to the accuracy of the model under exact-string matching,\nwhereas Opposite-Class accuracy refers to the fraction of the cases for which the model copied and placed the\nright input words in the output but verbalized the incorrect (opposite) inequality symbol, that is writing “less than”\ninstead of “greater than” or vice versa in between the expressions (for instance, the ground-truth might be “olive is\ngreater than cat”, but the model might have generated “olive is less than cat.”) It was surprising to discover that\nmost models failed to go beyond 60% accuracy on this small dataset. GPT-J-6B, on the other hand, outperformed\nall the other models, achieving an accuracy score of 74% on this task. We also remark that of the cases for which\nthe models failed to generate the correct output, they often were able to copy the appropriate words from the input\nbut failed to write the correct inequality symbol at the end.\n2217\nPositive→Negative Negative→Positive\nModel Setting Acc r-sBLEU s-sBLEU PPL Acc r-sBLEU s-sBLEU PPL\nGPT-2-Small\n(117M)\n4-Shot, Vanilla 0.14 25.3 82.1 79 0.13 24.9 80.6 75\n4-Shot, Contrastive 0.14 21.5 71. 0 73 0.17 18.5 58.5 99\n4-Shot, Negation-v10.05 25.2 83.7 72 0.07 23.1 75.3 68\n4-Shot, Negation-v2 0.06 25.4 84.5 75 0.08 25.3 83.0 74\nGPT-2-Medium\n(345M)\n4-Shot, Vanilla 0.63 19.7 49.4 75 0.38 17.7 49.7 62\n4-Shot, Contrastive 0.68 15.0 35.1 69 0.53 12.6 29.8 45\n4-Shot, Negation-v1 0.34 15.7 41.6 63 0.22 15.4 42.3 55\n4-Shot, Negation-v2 0.36 14.1 39.2 63 0.30 12.6 36.2 51\nGPT-2-Large\n(774M)\n4-Shot, Vanilla 0.75 16.2 38.9 60 0.52 17.2 45.6 55\n4-Shot, Contrastive 0.79 10.6 24.7 79 0.58 12.1 30.3 53\n4-Shot, Negation-v1 0.41 10.8 30.1 79 0.27 13.4 36.7 59\n4-Shot, Negation-v2 0.14 16.9 52.1 57 0.22 12.6 36.3 59\nGPT-2-XL\n(1558M)\n4-Shot, Vanilla 0.86 15.6 32.0 59 0.70 13.8 29.9 58\n4-Shot, Contrastive 0.87 14.8 28.7 65 0.72 12.0 25.3 55\n4-Shot, Negation-v1 0.83 11.8 24.1 81 0.50 14.9 32.0 54\n4-Shot, Negation-v2 0.53 19.0 43.5 77 0.51 16.9 37.7 61\nGPT-Neo-1.3B\n(1.3B)\n4-Shot, Vanilla 0.80 17.2 38.5 80 0.52 14.5 35.6 50\n4-Shot, Contrastive 0.85 14.6 30.1 59 0.61 13.1 28.3 42\n4-Shot, Negation-v1 0.79 16.1 34.7 72 0.00 0.0 0.0 0\n4-Shot, Negation-v2 0.57 16.5 40.6 67 0.00 0.0 0.0 0\nGPT-Neo-2.7B\n(2.7B)\n4-Shot, Vanilla 0.86 24.7 51.2 104 0.43 24.3 54.9 74\n4-Shot, Contrastive 0.88 23.5 45.8 96 0.52 22.0 48.0 69\n4-Shot, Negation-v1 0.80 22.5 47.8 79 0.00 0.0 0.0 0\n4-Shot, Negation-v2 0.76 22.0 48.2 85 0.00 0.0 0.0 0\nGPT-J-6B\n(6B)\n4-Shot, Vanilla 0.90 23.5 51.0 85 0.62 22.8 49.9 63\n4-Shot, Contrastive 0.87 23.0 47.7 80 0.65 20.2 44.6 58\n4-Shot, Negation-v1 0.82 23.6 50.9 85 0.53 24.3 54.7 65\n4-Shot, Negation-v2 0.73 25.1 59.1 95 0.48 25.2 58.1 66\nTable 20:Four-shot performances of the off-the-shelf “small” language models on the YELP -clean dataset under\ndifferent prompting protocols. Rows are bolded according to best accuracy scores. Across all models, the vanilla\nand contrastive prompting protocols appear to yield the most favourable results, though the contrastive prompting\nprotocol typically performs better than the vanilla prompting protocol along the accuracy dimension, but not\nnecessarily along the r-sBLEU dimension. We, however, note that in the case of GPT-J-6B, vanilla prompting\nperforms on par with contrastive prompting overall.\n2218\nModel Text\nInput (P→N) the staff is awesome and location is right in the heart of old town!\nGPT-2-Small the staff is awesome and location is right in the heart of old town!\nGPT-2-Medium the staff was great but the location was an even higher priority.\nGPT-2-Large the staff is awful and location is not in the center of old town!\nGPT-2-XL the staff was kind of awful, location was kind of a shithole\nGPT-Neo-1.3B the staff is awful and location is just a couple minutes away from the city center!\nGPT-Neo-2.7B the staff is terrible and location is just outside of old town!\nGPT-J-6B the staff is terrible and location is in the middle of nowhere!\nInput (P→N) he always looks gorgeous and is so happy when i pick him up!\nGPT-2-Small he always looks gorgeous and is so happy when i pick him up!\nGPT-2-Medium he always looks so sad and upset by the fact that i pick him up!\nGPT-2-Large he always looks ugly and is so sad when i pick him up!\nGPT-2-XL he never looks gorgeous and is so sad when i pick him up!\nGPT-Neo-1.3B he always looks awful and is so sad when i pick him up!\nGPT-Neo-2.7B he always looks horrible and is so unhappy when i pick him up!\nGPT-J-6B he always looks ugly and is so sad when i pick him up!\nInput (N→P) the food was low quality and thrown together quickly with little flavor.\nGPT-2-Small the food was low quality and thrown together quickly with little flavor.\nGPT-2-Medium the food was high quality and thrown together quickly with a great flavor.\nGPT-2-Large the food was excellent and was cooked to perfection by very skilled and professional server-chefs.\nGPT-2-XL the food was high quality and tasted really good.\nGPT-Neo-1.3B the food was high quality and tasted amazing!\nGPT-Neo-2.7B the food was fantastic and presented exceptionally with excellent quality and excellent flavors!\nGPT-J-6B the food was delicious and prepared with a lot of care!\nInput (N→P) we went there on a busy holiday weekend and the service was extremely slow.\nGPT-2-Small we went there on a busy holiday weekend and the service was extremely slow.\nGPT-2-Medium we went there on a busy holiday weekend and the service was exceptional!\nGPT-2-Large we did go there on a busy holiday weekend–it was fast!\nGPT-2-XL we went there on a quiet weekend and the service was very fast.\nGPT-Neo-1.3B we went there on a busy holiday weekend and the service was exceptional!\nGPT-Neo-2.7B we went there on a slow holiday weekend and the service was extremely fast\nGPT-J-6B we went there on a busy holiday weekend and the service was extremely fast.\nInput (P→N) i love the outside seating and the reverse happy hour is incredibly affordable.\nGPT-2-Small i love the outside seating and the reverse happy hour is unbelievably affordable.\nGPT-2-Medium i love everything about this place–the music is great, everyone is super nice, and they have\namazing desserts that are affordable.\nGPT-2-Large i loved the outside seating and the reverse happy hour is insanely expensive.\nGPT-2-XL i hate the outside seating and the reverse happy hour.\nGPT-Neo-1.3B i hate the outside seating and the reverse happy hour is incredibly costly.\nGPT-Neo-2.7B i hate the outside seating and the reverse happy hour is outrageously expensive.\nGPT-J-6B i hate the outside seating and the reverse happy hour is incredibly expensive.\nInput (N→P) the service is mediocre and the restaurant is just average.\nGPT-2-Small i love their black tea and hot chocolate selections!\nGPT-2-Medium i liked their black tea and hot chocolate selections; i was impressed by the quality of the food\nand service\nGPT-2-Large the service is wonderful!\nGPT-2-XL the service is great, and the restaurant is great!\nGPT-Neo-1.3B the service and the restaurant are just average.\nGPT-Neo-2.7B the service and the restaurant are just wonderful!\nGPT-J-6B the service is remarkable and the restaurant is amazing.\nTable 21:Qualitative examples of sentiment transfer on YELP -clean. We manually highlight in blue and red phrases\nthat we find to be associated with the input and target styles, respectively.\n2219\nModel Text\nInput (N→P) it works for maybe a few minutes and wears off quickly.\nGPT-2-Small it does not wear or work well when driving.\nGPT-2-Medium i think that it may have something to do with this brand.\nGPT-2-Large it works well for a while, but it wears off very quickly.\nGPT-2-XL it only does a few minutes’ worth of work and then gives up.\nGPT-Neo-1.3B it can be used for a few minutes, but wears off quickly.\nGPT-Neo-2.7B it lasts a lifetime and wears off after a few hours.\nGPT-J-6B it works for a few hours and wears well.\nInput (N→P) i am only giving this item num_num stars because of the absurd price.\nGPT-2-Small i am only giving this item num_num stars because of the absurd price.\nGPT-2-Medium i will buy some num_num stars and will use them to have an extra day off when i work.\nGPT-2-Large i am only giving this item stars because it got a good review.\nGPT-2-XL i will NOT purchase this item again.\nGPT-Neo-1.3B i really liked it and i will do it more often.\nGPT-Neo-2.7B i am giving this item num_num stars, because of the absurd price.\nGPT-J-6B i am only giving this item 5 stars because it works perfect and the price is reasonable.\nInput (N→P) would have been alot nicer if it simply threaded in with the correct alignment.\nGPT-2-Small would have been alot nicer if it simply threaded in with the correct alignment.\nGPT-2-Medium it works perfectly.\nGPT-2-Large would have been so much better if the plastic was a bit thicker.\nGPT-2-XL would have been great if it just threaded in properly.\nGPT-Neo-1.3B would have been alot nicer if it simply threaded in with the correct alignment.\nGPT-Neo-2.7B it is very nice but it does not fit in properly at all.\nGPT-J-6B it works just fine and there is zero frustration with the way the threading is implemented.\nInput (P→N) it fulfills my modest requirements, and exceeds my expectations in appearance.\nGPT-2-Small it isn’t good enough. I would buy from this brand again.\nGPT-2-Medium it doesn’t fit my needs and falls short in other areas.\nGPT-2-Large it did not fulfill my modest requirements, and did not exceed my expectations in appearance, and\nwould not fit well in the car.\nGPT-2-XL it does not meet my expectations in appearance.\nGPT-Neo-1.3B it does not fit my expectations and it does not fulfill my modest requirements in appearance.\nGPT-Neo-2.7B it doesn t fulfill my modest requirements, and i found it to be unsatisfactory.\nGPT-J-6B it fails to meet my needs, and is disappointing to look at.\nInput (P→N) great headset, solid build quality and blocks out the wind.\nGPT-2-Small i hate it\nGPT-2-Medium lots of dust on here and can be worn.\nGPT-2-Large not worth buying and not worth the price. It’s just too large.\nGPT-2-XL i hate it, it is terrible.\nGPT-Neo-1.3B dreadful headset, terrible quality and wind blocks out the audio quality.\nGPT-Neo-2.7B lousy headset, hard to unblock the wind.\nGPT-J-6B great headset, but it does not work great in the wind.\nInput (P→N) i dropped phone once and the case held up perfectly.\nGPT-2-Small i dropped phone once and the case held up perfectly.\nGPT-2-Medium i dropped phone as a result.\nGPT-2-Large i never dropped my phone once and the case held up fine.\nGPT-2-XL i dropped phone twice and the case was damaged.\nGPT-Neo-1.3B i dropped it and it was very broken.\nGPT-Neo-2.7B i dropped phone as many times as I dropped a brick.\nGPT-J-6B i dropped the phone and the case broke into pieces.\nTable 22:Qualitative examples of sentiment transfer on AMAZON -clean. We manually highlight in blue and red\nphrases that we find to be associated with the input and target styles, respectively.\n2220\nModel Text\nInput follow ur heart... it’s neva wrong\nGPT-2-Small follow my heart.\nGPT-2-Large follow your heart... its nova wrong...\nGPT-2-Medium follow your heart... its nova wrong\nGPT-2-XL follow ur heart and be the man you always wanted to be and never had.\nGPT-J-6B follow your heart... it is never wrong\nGPT-Neo-1.3B follow your heart... its neva wrong\nGPT-Neo-2.7B follow your heart... it’s never wrong\nInput if u you act like dat all da time she might think u desperate.\nGPT-2-Small if u acts like dat all, she might think that u wanna be happy with something and u dont want dat\nto break up with you, you will regret it, and she will become jealous. it is good...\nGPT-2-Medium if u u are always like dat..\nGPT-2-Large if you act like dat all da time she might think you desperate...\nGPT-2-XL if u u act like dat all da time she might think u desperate :)\nGPT-Neo-1.3B if u you act like dat everytime she thinks u desperately searching.\nGPT-Neo-2.7B if u you act like dat all da time she might think u desperate...\nGPT-J-6B if you act like that all the time she might think you desperate\nInput dont do things tht can get you hurt.\nGPT-2-Small but im sorry that u can do it and u can’t leave\nGPT-2-Medium do things which i’m sure u will like.\nGPT-2-Large don’t do things that can get you hurt\nGPT-2-XL dont do things that can end up getting u hurt.\nGPT-Neo-1.3B do things that can get you hurt.\nGPT-Neo-2.7B do not do things that can get you hurt.\nGPT-J-6B dont do things that might hurt you\nTable 23:Qualitative examples of sentiment transfer on GYAFC-clean. We manually highlight in blue and red\nphrases that we find to be associated with the input and target styles, respectively.\nModel Text\nInput Fo example, in this genaration people watch movies and listen to musics more than read books\nand novels.\nGPT-2-Small Fo example, in this genaration people watch movies and listen to musics more than read books\nand novels.\nGPT-2-Medium In this generation people watch movies more than read books and novels.\nGPT-2-Large Fo example, in this genaration people watch movies and listen to musics more than read books\nand novels.\nGPT-2-XL Fo example, in this example people watch movies and listen to music more than read books.\nGPT-Neo-1.3B Example, in this genaration people watch movies and listen to musics more than read books and\nnovels.\nGPT-Neo-2.7B Examples, in this generation, people watch movies and listen to music, whereas, reading books\nand novels is limited.\nGPT-J-6B For example, in this generation, people are watching movies and listening to musics more than\nreading books and novels.\nInput they are the boney and vital part o the society.\nGPT-2-Small They are the most important part of the society.\nGPT-2-Medium they are the vital part of the kingdom.\nGPT-2-Large they are the vital and boney parts of the society.\nGPT-2-XL they are the vital part, the boney part, and the society.\nGPT-Neo-1.3B they are the vital part of society.\nGPT-Neo-2.7B they are the boney and vital part of society.\nGPT-J-6B they are the bone and vital part of the society.\nInput And I am completely disagree with what the auther want to say.\nGPT-2-Small And I am completely disagree with what the auther want to say.\nGPT-2-Medium And I am entirely disagree with what the auther want to say.\nGPT-2-Large And I am completely disagree with what the auther want to say\nGPT-2-XL And I think the auther want to say completely differently.\nGPT-Neo-1.3B And I disagree with what he say.\nGPT-Neo-2.7B And I absolutely disagree with what the author want to say.\nGPT-J-6B I completely disagree with what the author wants to say.\nTable 24:Qualitative examples on JFLEG -clean. We manually highlight in blue and red phrases that we find to be\nassociated with the input and target styles, respectively.\n2221\nModel Text\nInput romeo, doff thy name; and for that name, which is no part of thee, take all myself\nGPT-2-Small speak you, my dear nurse, to me...\nGPT-2-Medium Romeo, Romeo, Romeo.\nGPT-2-Large romo, doff thy name, take all myself, all i’ll say is, you’re a dirty old man.\nGPT-2-XL roome, doff thy name; and for that name, which is no part of thee, take all myself.\nGPT-Neo-1.3B romeo, get out of my sight; get out, i’ll not have it.\nGPT-Neo-2.7B rommy, get rid of your name; and because your name, which is no part of you, needs to get rid of, take all of me.\nGPT-J-6B romeo, take off your name, and for that name, which is not part of you, take all of me.\nInput now art thou sociable, now art thou romeo; now art thou what thou art, by art as well as by nature.\nGPT-2-Small now art thou romeo, now art thou romeo; now art thee what thou art, by art as well as by nature.\nGPT-2-Medium what I have said in thy speech thou hast said enough of me, wherewith to destroy thy soul.\nGPT-2-Large now art thou sociable, now art thou romeo; now art thou what thou art, by art as well as by nature.\nGPT-2-XL now is thou sociable, now is thou Romeo; now is thou what thou art, by nature as well as by nature.\nGPT-Neo-1.3B and now art thou what thou art, by art as well as by nature.\nGPT-Neo-2.7B now are you sociable, now are you romeo; now are you what you are, by nature.\nGPT-J-6B now you are friendly, now you are Romeo; now you are who you are, by nature as well as by art.\nInput the sweetest honey is loathsome in his own deliciousness and in the taste confounds the appetite.\nGPT-2-Small the sweetest honey is loathsome in his own deliciousness and in the taste confounds the appetite.\nGPT-2-Medium sweetest honey, sweetest bread, sweetest wine, sweetest dainties, do them to the soul’s delights.\nGPT-2-Large the sweetest honey is loathsome in his own deliciousness; in the taste confounds the appetite.\nGPT-2-XL the most sweet and clearest honey is loathsome in the taste and in the very smell confounds the appetite.\nGPT-Neo-1.3B the honey is sweeter than ever it was in the honeycomb, and is almost enough to make one lose their senses and\ndie a corpse.\nGPT-Neo-2.7B the sweetest milk is foul and sickly in his own deliciousness and in the taste confounds the appetite.\nGPT-J-6B the sweetest honey is disgusting in its own deliciousness and in its taste it confounds the appetite.\nInput unless philosophy can make a juliet, displant a town, reverse a prince’s doom, it helps not, it prevails not.\nGPT-2-Small what am I thinking of?*\nGPT-2-Medium if philosophy can make a juliet, supplant your King, reverse his doom, reverse a prince’s doom, reverse a king’s\ndoom.\nGPT-2-Large unless philosophy can make a juliet, displant a town, reverse a prince’s doom, it helps not, it prevails not.\nGPT-2-XL unless it can convert a whore into a knight, it does not make it jolly.\nGPT-Neo-1.3B unless philosophy can make a juliet, a town, reverse a prince’s doom, it helps not, it prevails not.\nGPT-Neo-2.7B unless philosophy can make a Juliet, cause a town to explode, reverse a prince’s downfall, it helps not, it prevails\nnot.\nGPT-J-6B unless philosophy can make a Juliet, overturn a town, reverse a prince’s doom, it doesn’t help, it doesn’t work.\nInput night’s candles are burnt out, and jocund day stands tiptoe on the misty mountain tops.\nGPT-2-Small not here\nGPT-2-Medium and when night comes, the sun sets and stars all flicker in the distance.\nGPT-2-Large night’s candles are burnt out, and jocund day stands in a field of snow.\nGPT-2-XL night’s candles are burning out, and jocund day is standing still on the misty mountain tops.\nGPT-Neo-1.3B night’s fires are out and the day stands up above the foggy mountains.\nGPT-Neo-2.7B night’s candles are burnt out; day’s gone to bed and evening’s at hand; the sun is setting on the mountain tops.\nGPT-J-6B day is over, and night is approaching, and it stands on its tiptoes over the misted mountain tops.\nInput nor tears nor prayers shall purchase out abuses, therefore use none.\nGPT-2-Small nor tears nor prayers shall purchase out abuses, therefore use none\nGPT-2-Medium nor tears nor prayers shall purchase out abuses, therefore use none.\nGPT-2-Large use none, for abuse is in the eyes of a man.\nGPT-2-XL no tears nor prayers shall buy out abuses, therefore I will not use any.\nGPT-Neo-1.3B nor tears nor prayers shall have any power, therefore use none.\nGPT-Neo-2.7B nor prayers nor tears will do any good, therefore use none.\nGPT-J-6B and tears and prayers won’t work for you, so don’t use them.\nInput and here stands all your state: either be gone before the watch be set, or by the break of day disguised from hence.\nGPT-2-Small and here stands all your state: either be gone before the watch be set, or by the break of day disguised from hence.\nGPT-2-Medium and this day there is nothing but the city.\nGPT-2-Large but where is the watch?\nGPT-2-XL and here stands all your state: either be gone before the watch, or by the break of day disguised from hence.\nGPT-Neo-1.3B and here stands all your state: either be gone before the watch be set, or by the break of day disguised from hence.\nGPT-Neo-2.7B and this is all you get: either go before the watch is set, or before the break of day dressed like a thief from hence.\nGPT-J-6B and here is all your stuff: either leave now or you’ll have to deal with us when it’s morning.\nTable 25:Qualitative examples on SHAKESPEARE -clean. We manually highlight in blue and red phrases that we\nfind to be associated with the input and target styles, respectively. (Footnote *: Pray tell us, what are you thinking of\nright now?)\n2222"
}