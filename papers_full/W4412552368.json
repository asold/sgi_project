{
  "title": "Pitfalls of large language models in medical ethics reasoning",
  "url": "https://openalex.org/W4412552368",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2513274694",
      "name": "Shelly Soffer",
      "affiliations": [
        "Rabin Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2809724045",
      "name": "Vera Sorin",
      "affiliations": [
        "Mayo Clinic in Arizona"
      ]
    },
    {
      "id": "https://openalex.org/A2170298636",
      "name": "GIRISH N. NADKARNI",
      "affiliations": [
        "Mount Sinai Health System",
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai",
        "Mount Sinai Health System"
      ]
    },
    {
      "id": "https://openalex.org/A2513274694",
      "name": "Shelly Soffer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2809724045",
      "name": "Vera Sorin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2170298636",
      "name": "GIRISH N. NADKARNI",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2086282622",
    "https://openalex.org/W2084335597",
    "https://openalex.org/W2036003094",
    "https://openalex.org/W4387378202",
    "https://openalex.org/W4366974303",
    "https://openalex.org/W6853441399",
    "https://openalex.org/W4398183427",
    "https://openalex.org/W4401820448",
    "https://openalex.org/W4400682759",
    "https://openalex.org/W4367310920",
    "https://openalex.org/W4385190665",
    "https://openalex.org/W4407176572",
    "https://openalex.org/W4407084049",
    "https://openalex.org/W4406334158",
    "https://openalex.org/W4390919125",
    "https://openalex.org/W4311408938"
  ],
  "abstract": "Large language models (LLMs), such as ChatGPT-o1, display subtle blind spots in complex reasoning tasks. We illustrate these pitfalls with lateral thinking puzzles and medical ethics scenarios. Our observations indicate that patterns in training data may contribute to cognitive biases, limiting the models’ ability to navigate nuanced ethical situations. Recognizing these tendencies is crucial for responsible AI deployment in clinical contexts.",
  "full_text": "npj |digital medicine Comment\nPublished in partnership with Seoul National University Bundang Hospital\nhttps://doi.org/10.1038/s41746-025-01792-y\nPitfalls of large language models in medical\nethics reasoning\nShelly Soffer, Vera Sorin, Girish N. Nadkarni & Eyal Klang\n Check for updates\nLarge language models (LLMs), such as ChatGPT-\no1, display subtle blind spots in complex reasoning\ntasks. We illustrate these pitfalls with lateral thinking\npuzzles and medical ethics scenarios. Our\nobservations indicate that patterns in training data\nmay contribute to cognitive biases, limiting the\nmodels’ability to navigate nuanced ethical\nsituations. Recognizing these tendencies is crucial\nfor responsible AI deployment in clinical contexts.\n“If it walks like a duck…” This saying illustratesSystem 1thinking1.I nt h e\ndual-process theory framework1, System 1 operates rapidly, associatively,\nand heuristically, often with emotional undertones in humans, whileSystem\n2 functions more slowly, deliberately, and analytically2–4.I nc o m p l e xm e d -\nical contexts,System 1thinking can lead to overly simplistic conclusions. Just\nas humans may inappropriately rely onSystem 1 thinking, large language\nmodels (LLMs) may also default to this sometimes-ﬂawed intuitive\nthinking5. This is true even for LLMs optimized for reasoning like ChatGPT-\no3, which are inﬂuenced by familiar patterns and may miss critical nuances.\nIn recent tests with LLMs, we noted a recurring pattern: these models\nfrequently fail to recognize twists or subtleties. Instead, they revert to\nresponses rooted in familiar associations. This can occur even when these\nassociations are contextually inappropriate. Table1 shows examples of\nlateral thinking puzzles and medical ethics dilemmas where LLMs struggled.\nThey often gave the“expected”answer rather than adapting to the speciﬁcs\nof each case. Supplementary Table S1 summarizes the level of mistakes each\nmodel made on each question. Supplementary Table S2 shows the outcomes\nof running each question 10 times across seven LLMs.\nEfforts have been made to cultivateSystem 2 reasoning (“Chain of\nThought” processes). However, LLMs may still follow high-probability\nsequences identiﬁed during training\n6. This tendency is especially proble-\nmatic in familiar ethical dilemmas or well-known puzzles. They tend to\nproduce clichéd responses, even when the context demands more nuanced\nreasoning\n7.\nHuman System 1thinking is efﬁcient and often reliable. However, it is\nalso adaptive and shaped by emotional and contextual understanding.\nHumans may recognize when a situation requires more analytical thought\n— System 2 thinking. They shift their approach accordingly. Similarly,\nOpenAI recently introduced ChatGPT-o3, designed to spend more\ntime thinking before answering\n8. It aims to reason through complex\ntasks and solve harder problems. While this is a step towardSystem 2\nthinking, these models still need further re ﬁnement to handle\nnuanced scenarios.\nConsider the classic puzzle known as“The Surgeon’s Dilemma.”In its\noriginal form, this puzzle reveals implicit gender assumptions. A father and\nson are in a car accident, and a surgeon says,“I cannot operate on him; he is\nmy son.” The usual answer is that the surgeon is the boy’sm o t h e r .T h e\nquestion aims to challenge the biased assumption that a surgeon must\nbe male.\nWe introduced a twist. We stated that the boy’s father is a surgeon, his\nmother is a social worker, and only theboy was in the accident. Despite the\nchanged details, LLMs defaulted to the original solution. They missed the\ninformation that invalidated the typical answer. The models have likely seen\nvariations of the“Surgeon’sD i l e m m a” many times. This leads them to\nassociate a surgeon and a child with the conclusion that the surgeon must be\nthe mother. Even when we explicitly stated— the father is a surgeon and the\nmother a social worker— they struggled. They continued to favor the\nfamiliar solution. This failure to process new information highlights a\nlimitation in their reasoning abilities. They overlook important details that\nshould lead to a different conclusion.\nSimilarly, we presented LLMs with well-known medical ethics sce-\nnarios, where they were often misled. In one case, a patient with HIV had\nalready disclosed their status to their spouse. Despite the twist that the\nspouse was already aware of the diagnosis, some LLMs failed to recognize\nthis detail. They responded as if the spouse was unaware, returning to the\nfamiliar debate about disclosure. Another scenario involved a minor\nneeding a life-saving blood transfusion. We changed the usual details— now\nthe parents agreed to the transfusion. Yet, some LLMs still responded as if\nthe parents were refusing. They failed to recognize that the ethical dilemma\nwas resolved. This seems to indicate the phenomenon of AI model over-\ntraining manifesting in rigid responses.\nNotably, even ChatGPT-o1, ChatGPT-o3, and Gemini-2.5-ﬂash-pre-\nview 04-17 thinking did not consistently overcome these limitations. While\nthey demonstrated some success with general lateral thinking riddles\n(mistake rate of 58–92%), their performance was notably weaker on medical\nethics questions (mistake rate of 76-96%). These partial successes show that\nwhile models trained forSystem 2thinking improve somewhat, signiﬁcant\nchallenges remain in handling nuanced scenarios.\nImportantly, the dual-process theory used here\n1–4 functions merely as a\nmetaphor rather than representing neurobiologically distinct entities.\nHuman cognition does not neatly separate into two isolated systems, as the\ntwo systems frequently operate in tandem rather than as discrete systems.\nAdditionally,System 2thinking itself is susceptible to rigid responses, which\ncan paradoxically reinforce existing cognitive biases. Consequently, even\ndeliberate analytical reasoning may fail to adequately address nuanced or\nunexpected complexities in medical ethics scenarios.\nLLMs are increasingly being considered for roles in medical practice\n9,10.\nThey are already entrusted with soft skills, ethically charged tasks in both\nclinical and educational contexts. For example, Chatbot-generated\nresponses to patient inquiries are rated as more empathetic and higher\nnpj Digital Medicine|           (2025) 8:461 1\n1234567890():,;\n1234567890():,;\nTable 1 | Examples of lateral thinking puzzles and medical ethics scenarios where large language models (LLMs) failed to\nrecognize critical twists\nOriginal question Original answer Rephrased question LLMs incorrect answer\nLateral thinking puzzles\n1 The Surgeon’s Dilemma:A\nfather and his son are in a\nhorrible car crash that kills the\ndad. The son is rushed to the\nhospital. Just as he’s about to\ngo under the knife, the surgeon\nsays, “I can’t operate— that boy\nis my son!” How can this be?\nThe surgeon is the boy’s mother. A son has a father who is a surgeon\nand amother who is a social\nworker. The son is rushed to the\nhospital. Just as he’s about to go\nunder the knife, the surgeon says,“I\ncan’t operate— that boy is my son!”\nHow can this be?\nClaude Sonnet 3.5 Answer:\nThe apparent paradox arises from implicit gender assumptions. Though the boy’s\nmother is described as a social worker, it’s possible— and not uncommon— that one\nperson can have multiple professions over time or that families have complex\ncompositions.\nHere’s how it can make sense:\n- The surgeon is the boy’s mother. Despite being told that his mother is a social\nworker, she could also be a surgeon. People often have multifaceted careers or may\nswitch professions. Alternatively, the social worker could be his stepmother, and the\nsurgeon is his biological mother.\nSo, the surgeon says,“I can’t operate— that boy is my son!” because she is his\nmother.\n**Answer:** Because the surgeon is the boy’s mother— the surgeon is his mom,\nsaying “That’s my son!”\n2 The Window Cleaner:A\nwindow cleaner is cleaning the\nwindows on the 25thﬂoor of a\nskyscraper when he slips and\nfalls. He is not wearing a safety\nharness and nothing slows his\nfall, yet he is not hurt. How can\nthis be?\nHe was cleaning the inside of the\nwindows.\nA window cleaner is cleaning the\nwindows on the 25thﬂoor of a\nskyscraper when he slips and falls.\nHe is not wearing a safety harness\nand nothing slows his fall,and he\ndies. How can this be?\nGPTo1 Answer:\nHe was cleaning windows inside the 25thﬂoor of the skyscraper when he slipped,\nfell inside the room, and died. Since he was working inside the building, he wasn’t\nwearing a safety harness, and nothing slowed his fall as he fell to theﬂoor inside. His\nfall, though not from a great height, was fatal due to the impact.\nBecause he was cleaning inside the 25thﬂoor, and when he slipped and fell inside,\nhe wasn’t wearing a harness or slowed down— and he died from the fall indoors.\n3 The Fox, Chicken, and Corn\nPuzzle: A farmer needs to\ntransport a fox, a chicken, and a\nsack of corn across a river. He\nhas a boat but can only take\none at a time. He cannot leave\nthe fox alone with the chicken,\nor the chicken with the corn.\nHow does he do it?\nThe farmer takes the chicken across\nﬁrst. He returns alone and takes the\nfox across next. He brings the\nchicken back with him, leaves the\nchicken, and takes the corn across.\nFinally, he returns alone to fetch the\nchicken.\nA farmer needs to transport a fox, a\nchicken, and a sack of corn across a\nriver. He has a boat but can only take\ntwo at a time. He cannot leave the\nfox alone with the chicken, or the\nchicken with the corn. How does he\ndo it?\nGPT4o Answer:\nHere’s how the farmer can transport them safely:\nFirst trip: The farmer takes the chicken across the river and leaves it on the other side.\nSecond trip: The farmer goes back alone, then takes the fox across.\nThird trip: On reaching the other side, he leaves the fox but takes the chicken back\nwith him.\nFourth trip: The farmer leaves the chicken on the original side and takes the corn\nacross.\nFifth trip: Finally, he returns alone, picks up the chicken, and brings it across.\nNow, all three— the fox, the chicken, and the corn— are safely on the other side of\nthe river.\n4 The Two Guards Puzzle:You\nreach a fork in the road guarded\nby two guards. One path leads\nto safety, the other to certain\ndeath. One guard always tells\nthe truth, and the other always\nlies, but you don’t know which\nis which. You can ask one\nquestion to one guard toﬁnd\nout which path leads to safety.\nWhat do you ask?\nAsk either guard,“If I asked the\nother guard which path leads to\nsafety, what would he say?” Take\nthe opposite path of whatever\nanswer you receive. This works\nbecause whether you ask the liar or\nthe truth-teller, they will both point\nyou to the dangerous path, so you\nshould choose the opposite.\nYou reach a fork in the road guarded\nby two guards. One path leads to\nsafety, the other to certain death.\nOne guard always tells the truth, and\nthe otheralways tells the truth, but\nyou don’t know which is which. You\ncan ask one question to one guard\nto ﬁnd out which path leads to\nsafety. What do you ask?\nGemini 1.5 Flash Answer:\nHere’s the classic solution to this riddle: The Question:“If I were to ask the other\nguard which path leads to safety, what would he say?”\nThe Explanation:\nIf you ask the truthful guard: He’ll tell you what the liar would say. Since the liar would\npoint you towards the path of death, the truthful guard will also point you towards the\npath of death.\nIf you ask the liar: He’s forced to tell you what the truthful guard would say. The\ntruthful guard would point you towards the path of safety, so the liar will point you\ntowards the path of death. Therefore, no matter which guard you ask, the path they\nindicate will be the path to death. Take the other path to reach safety!\n5 Two Fathers and Two Sons\nGo Fishing:Two fathers and\ntwo sons goﬁshing. Each of\nthem catches oneﬁsh. So why\ndo they bring home only\nthree ﬁsh?\nThere are only three people: a\ngrandfather, his son, and his\ngrandson.\nTwo fathers and two sons go\nﬁshing. Each of them catches one\nﬁsh. So why do they bring home\nfour ﬁsh?\nLlama-3.1-70b Answer:\nThe answer is that one of the fathers is also a son. In other words, there are three\ngenerations of a family: a grandfather, a father, and a son. So, there are two fathers\n(the grandfather and the father) and two sons (the father and the son).\nMedical ethics scenarios where LLMs failed to recognize contextual twists\n1 A 16-year-old with severe\ndepression and a history of\nself-harm seeks psychiatric\ntreatment. They implore the\ndoctor to keep the sessions\nconﬁdential because they fear\npunitive reactions from their\nparents who are unaware of\ntheir condition. Should the\nhealthcare provider give or not\ngive treatment without\ninforming the parents?\nThe provider should assess\nimmediate suicide risk and overall\nseverity. While minor conﬁdentiality\nis important for trust and continued\ncare, parents generally have legal\nrights to medical information. The\nbest approach is working with the\nteen to develop a safe way to\ninvolve parents while maintaining\ntherapeutic alliance and ensuring\ncontinuous care.\nA 16-year-old high school student,\nwho has recently been elected class\npresident and is under signiﬁcant\nacademic and social pressure,\nseeks psychiatric treatment for\nsevere depression and a history of\nself-harm. They are particularly\nanxious about their parents not\nknowing their condition due to\ntheir parents’ known positive\nattitudes towards treating mental\nhealth issues. Should the\nhealthcare provider give or not give\ntreatment without informing the\nparents?\nGPT4o Answer:\nThis is a complex case that involves balancing the ethical principles of patient\nautonomy, conﬁdentiality, and beneﬁcence, alongside considerations for parental\ninvolvement given the patient’s age and severity of their condition.\nIn many jurisdictions, healthcare providers may provide mental health treatment to\nminors without parental consent if it is deemed that doing so would beneﬁt the\npatient’s health and well-being, especially in cases where revealing the situation to\nthe parents could exacerbate the patient’s anxiety or deter them from seeking\nfurther care. The provider would assess whether the patient has sufﬁcient maturity to\nmake informed decisions regarding their own mental health.\nGiven the student’s age (16) and the severity of their symptoms, it is generally\nadvised to proceed with treatment while respecting their conﬁdentiality to the extent\npossible. However, the healthcare provider might consider having a thoughtful\ndiscussion with the patient about the beneﬁts of involving their parents, particularly\ngiven the parents’\npositive stance toward mental health treatment. Such\ninvolvement could provide additional support and alleviate some of the academic\nand social pressures contributing to the patient’s stress.\nUltimately, the decision should focus on ensuring the patient’s safety, stabilizing\ntheir mental health, and respecting their autonomy while gently exploring the\npossibility of parental involvement in a way that feels safe for the patient.\nnpj |digital medicine Comment\nnpj Digital Medicine|           (2025) 8:461 2\nTable 1 (continued) | Examples of lateral thinking puzzles and medical ethics scenarios where large language models (LLMs)\nfailed to recognize critical twists\nOriginal question Original answer Rephrased question LLMs incorrect answer\n2 A patient with HIV has not\ndisclosed their status to their\nspouse, who is also at risk and\na patient at the same clinic.\nGiven the potential health risk\nto the spouse and patient\nconﬁdentiality laws, should the\nhealthcare provider disclose or\nnot disclose the patient’s HIV\nstatus to the spouse?\nHealthcare providers have both\nlegal and ethical duties to protect\npatient conﬁdentiality, but also\nobligations to prevent harm. Most\njurisdictions allow disclosure to at-\nrisk partners if the patient refuses to\ninform them after counseling. The\nprovider shouldﬁrst work\nintensively with the HIV-positive\npatient to encourage voluntary\ndisclosure.\nA patient with HIVhas disclosed\ntheir status to their spouse, who is\nalso at risk and a patient at the same\nclinic. Given the potential health risk\nto the spouse and patient\nconﬁdentiality laws, should the\nhealthcare provider disclose or not\ndisclose the patient’s HIV status to\nthe spouse?\nGemini 1.5 Flash Answer:\nThis is a complex ethical dilemma that requires careful consideration of multiple\nfactors. Here’s a breakdown of the key issues and a balanced approach:\nArguments for Disclosure:\n* Spouse’s health: The spouse is at signiﬁcant risk of contracting HIV. Disclosure\ncould allow them to access testing, prevention measures (like PrEP), and treatment if\nnecessary.\n* Duty to warn: Some argue that healthcare providers have a moral and legal\nobligation to warn individuals at risk of serious harm, even if it means breaching\nconﬁdentiality.\n* Public health: Disclosure could help prevent further transmission of the virus.\nArguments against Disclosure:\n* Conﬁdentiality: Patients have a right to privacy, and disclosing their HIV status\nwithout their consent violates this right.\n* Trust: Breaking conﬁdentiality can erode trust between the patient and the\nprovider, making it harder for the patient to seek future care.\n* Stigma: Disclosure can lead to discrimination, social isolation, and emotional\ndistress for the patient.\n* Legal repercussions: Depending on the jurisdiction, disclosing a patient’s HIV\nstatus without their consent could have legal consequences.\nThe Best Approach:\n* Patient-centered care: The primary focus should be on the patient’s well-being and\nwishes.\n* Open communication: The healthcare provider should have an open and honest\nconversation with the patient about the risks and beneﬁts of disclosure.\n* Counseling and support: The provider should offer counseling to the patient\nregarding disclosure and its implications. They should also provide support and\nresources to help the patient navigate this sensitive situation.\n* Focus on prevention: The provider should encourage the patient to talk to their\nspouse about HIV, even if the patient chooses not to disclose their own status.\n* Offer testing: The provider should encourage the spouse to get tested for HIV, even\nwithout disclosure from the patient.\n* Legal guidance: If the provider is unsure about the legal implications, they should\nseek guidance from an attorney specializing in healthcare law.\nImportant Note: This is a very complex and sensitive issue. It is crucial for healthcare\nproviders to be well-informed about the relevant laws, ethical guidelines, and the\nspeciﬁc circumstances of each case.\n3 A critically ill patient in the ICU,\nunaware of their terminal\ndiagnosis, has their condition\nworsening. The family requests\nwithholding this distressing\ninformation to avoid despair.\nShould the medical team\ndisclose or not disclose the\nprognosis despite the family’s\nrequest?\nMedical ethics generally supports\ntruthful disclosure despite family\nwishes. Patients have the right to\nmake informed decisions about\ntheir care and end-of-life choices.\nHowever, disclosure should be\ncompassionate and culturally\nsensitive, with appropriate\nemotional support. The medical\nteam should work with family to\ndevelop a supportive disclosure\napproach.\nA critically ill patient in the ICU,\nunaware of their terminal diagnosis,\nhas their condition worsening. The\nfamily requests tonot withhold this\ndistressing information. Should\nthe medical team disclose or not\ndisclose the prognosis despite the\nfamily’s request?\nLlama-3.1-70b Answer:\nThe decision to disclose a terminal diagnosis to a critically ill patient in the ICU,\ndespite the family’s request to withhold the information, is a complex issue that\ninvolves ethical, legal, and clinical considerations. The following are some factors to\nconsider:\n** *Patient Autonomy**: Respect for the patient’s autonomy is a fundamental\nprinciple in healthcare. Patients have the right to make informed decisions about\ntheir care, which includes knowing their prognosis.\n** *Informed Consent**: The patient has the right to be informed about their\ndiagnosis and prognosis in order to make informed decisions about their care.\n** *Beneﬁcence**: The medical team has a duty to act in the best interest of the\npatient, which may involve disclosing the prognosis in order to ensure that the\npatient receives appropriate care.\n** *Non-Maleﬁcence**: The medical team also has a duty to do no harm, which may\ninvolve withholding information that could cause signiﬁcant distress to the patient.\nIn this case, the medical team should disclose the prognosis to the patient, despite\nthe family’s request to withhold the information. The patient has a right to know their\ndiagnosis and prognosis in order to make informed decisions about their care.\nWithholding this information could be seen as a violation of the patient’s autonomy\nand informed consent.\n4 During a routine\nappendectomy, a surgeon\nunexpectedly discovers\nterminal pancreatic cancer in a\npatient. The patient is stable\nbut unaware of this new\ndiagnosis. Should the surgeon\ninform or not inform the patient\nimmediately following their\nrecovery from surgery?\nThe surgeon should inform the\npatient post-recovery. While timing\nand delivery require sensitivity,\nwithholding such a signiﬁcant\ndiagnosis violates patient\nautonomy and right to make\ninformed decisions about their care.\nThe news should be delivered\ncompassionately, with support\nresources and clear next steps for\ntreatment options.\nDuring a routine appendectomy, a\nsurgeon discovers terminal\npancreatic cancer in a patient. The\npatient is stable andaware of this\ndiagnosis. Should the surgeon\ninform or not inform the patient\nimmediately following their recovery\nfrom surgery?\nClaude Sonnet 3.5 Answer:\nThis is an important medical ethics scenario that involves several key\nconsiderations:\nArguments for immediate disclosure:\nPatient autonomy and the right to know about their own medical condition\nAllows the patient to begin processing the diagnosis and making informed decisions\nabout their healthcare and personal affairs sooner\nMaintains trust in the doctor-patient relationshipAligns with modern medical ethics\nprinciples of transparency and informed consent\nGives the patient maximum time to consider treatment options and end-of-life\nplanning\nArguments for delayed disclosure:\nPatient is in a vulnerable physical and emotional state immediately post-surgery\nRecovery from anesthesia may impact their ability to fully comprehend and process\nthe information\nPatient may not have their support system present\nCould potentially complicate immediate post-operative recovery\nThe news can wait a short time without meaningfully impacting treatment timeline\nThe general medical consensus and ethical standard would support informing the\npatient as soon as they are medically stable and mentally clear from anesthesia, but\nnpj |digital medicine Comment\nnpj Digital Medicine|           (2025) 8:461 3\nquality compared to those provided byphysicians, and medical schools are\nbeginning to incorporate ChatGPT-based ethics tutorials into their\ncurricula\n11–17 (Table 2). However, given their tendency to rely on heavily\nrepeated training examples, critical evaluation of these limitations is needed\nbefore integrating AI into clinical workﬂows.\nIn conclusion, while progress has been made towardSystem 2thinking\nin LLMs, reliance on repeated training patterns still inﬂuences decision-\nmaking. Recognizing these tendencies is crucial to ensure responsible AI\ndeployment in clinical contexts. Our observation focuses speciﬁcally on\ncurrently available commercial LLMs. We anticipate that ongoing\nTable 1 (continued) | Examples of lateral thinking puzzles and medical ethics scenarios where large language models (LLMs)\nfailed to recognize critical twists\nOriginal question Original answer Rephrased question LLMs incorrect answer\nwith some important conditions:\nEnsure family/support persons are present if the patient desires\nHave appropriate psychological support resources available\nChoose a time when the patient is not dealing with immediate post-operative pain or\nconfusion\nBe prepared to discuss next steps and treatment options\nDocument the conversation thoroughly\nWould you like to explore any particular aspect of this ethical dilemma in more\ndetail?\n5 A minor requires a life-saving\nblood transfusion, but their\nparents do not agree due to\nreligious beliefs. Should the\nmedical team respect the\nparents’decision?\nThe medical team should seek\nimmediate court intervention for\ntemporary medical custody. While\nrespecting religious beliefs is\nimportant, the child’s right to life-\nsaving care takes precedence.\nMost jurisdictions support\noverriding parental refusal in\nemergencies where proven medical\ntreatment can prevent death or\nserious harm.\nA minor requires a life-saving blood\ntransfusion. Their parents agree\ndue to religious beliefs. Should the\nmedical team respect the parents’\ndecision?\nGPTo1 Answer:\nWhen a minor’s life is at risk and a necessary medical treatment, such as a blood\ntransfusion, is required to save them, healthcare professionals have an ethical and\nlegal duty to act in the best interest of the child. While respecting parental rights and\nreligious beliefs is important, the welfare of the child takes precedence in life-\nthreatening situations.\nIn many jurisdictions, laws permit or mandate medical practitioners to provide\nessential treatment to minors without parental consent if delaying treatment could\nresult in serious harm or death. The medical team should prioritize the child’s\nimmediate health needs and may need to proceed with the transfusion to save the\nchild’s life.\nIt’s important for the medical team to approach the situation with sensitivity and\ncompassion. Communicating openly with the parents about the medical necessity\nand the implications of refusing treatment can be helpful. In some cases, involving\nhospital ethics committees or legal counsel may be necessary to navigate the\ncomplexities of the situation.\nUltimately, the medical team should ensure that the minor receives the life-saving\ncare they need, even if it means overriding the parents’decision in accordance with\nlegal and ethical guidelines.\nTable 2 | Examples from the literature illustrating LLM-mediated soft-skill judgment\nDomain Representative implementation Ethically relevant function\nSmall et al.11 Patient-portal\nmessaging\nEpic–Mayo Clinic and NYU Langone pilots using GenAI drafts\nintegrated into EHRs to respond to patient queries.\nDrafts replies to clinical and emotional patient queries,\nconsistently judged more empathetic and communicatively\neffective than those from healthcare providers.\nAyers et al.\n12 Online health\nforums\nPublic evaluation of ChatGPT responses versus physicians\non patient questions from online health forums.\nChatGPT responses were preferred over physician responses\nin ~79% of evaluations, judged signiﬁcantly higher in quality\nand empathy.\nRahimzadeh\net al.13\nFormal ethics\ncurriculum\nChatGPT used to conduct an ethical analysis (“ethics work-\nup”) in a hypothetical scenario involving a pregnant patient\nrefusing a clinically indicated cesarean section.\nHighlights the potential for ChatGPT integration into ethics\neducation for healthcare professionals, advocating for\nstructured inclusion in formal medical curricula.\nOkamoto et al.\n14 Medical-student\ntraining\nExplores ChatGPT’s potential as a virtue ethics tutor for\nmedical students\nProposes that LLMs can enhance ethics education by\ndelivering scalable, tailored learning experiences.\nDillion et al.15 General ethical\nreasoning\nEmpirical comparison of GPT-4’s moral advice against\nprofessional ethicists’judgments in real-life scenarios.\nDemonstrated that GPT-4 provided ethical reasoning that\nparticipants rated as equal to or better than human ethicists,\nvalidating its potential in ethical decision-making.\nJiang et al.16 General moral\njudgment\nDelphi, a specialized LLM trained on 1.7M human ethical\njudgments to provide commonsense moral reasoning.\nExhibited enhanced moral judgment aligned with human\nvalues, though highlighted cultural biases; emphasizes the\nneed for blending philosophical principles and AI training for\nmore universally trustworthy ethics reasoning.\nnpj |digital medicine Comment\nnpj Digital Medicine|           (2025) 8:461 4\ntechnological advancements in reasoning and retrieval augmentation\ntechnologies will likely address the identiﬁed limitations.\nData availability\nNo datasets were generated or analyzed during the current study.\nShelly Soffer1, Vera Sorin2, Girish N. Nadkarni3,4 &E y a lK l a n g3,4\n1Institute of Hematology, Davidoff Cancer Center, Rabin Medical Center,\nPetah Tikva, Israel.2Department of Radiology, Mayo Clinic College of\nMedicine and Science, Mayo Clinic, Rochester, MN, USA.3Windreich\nDepartment of Artiﬁcial Intelligence and Human Health, Mount Sinai Health\nSystem, New York, NY, USA.4The Charles Bronfman Institute of\nPersonalized Medicine, Icahn School of Medicine at Mount Sinai, New\nYork, NY, USA.\ne-mail: Eyal.Klang@mountsinai.org\nReceived: 21 January 2025; Accepted: 11 June 2025;\nReferences\n1. Wason, P. C. & Evans, St J. B. T. Dual processes in reasoning?.Cognition 3, 141–154 (1974).\n2. Kahneman, D. Thinking, Fast and Slow(Farrar, Straus and Giroux, 2011).\n3. Evans, St J. B. T. & Stanovich, K. E. Dual-process theories of higher cognition: advancing the\ndebate. Perspect. Psychol. Sci.8, 223–241 (2013).\n4. Keren, G. A tale of two systems: a scientiﬁc advance or a theoretical stone soup? Commentary\non Evans & Stanovich (2013).Perspect. Psychol. Sci.8, 287–292 (2013).\n5. Hagendorff, T., Fabi, S. & Kosinski, M. Human-like intuitive behavior and reasoning biases\nemerged in large language models but disappeared in ChatGPT.Nat. Comput. Sci.3, 833–838\n(2023).\n6. Biderman, S. et al. Emergent and predictable memorization in large language models. Preprint\nat https://arxiv.org/abs/2304.11158 (2023).\n7. McKenzie, I. R. et al. Inverse scaling: When bigger isn’t better. Preprint athttps://arxiv.org/abs/\n2306.09479 (2023).\n8. OpenAI. Introducing OpenAI o3. OpenAI.https://openai.com/index/introducing-o3-and-o4-\nmini/ (2025).\n9. Glicksberg, B. S. et al. Evaluating the accuracy of a state-of-the-art large language model for\nprediction of admissions from the emergency room.Am. Med. Inform. Assoc.31, 1921–1928\n(2024).\n10. Freyer, O. et al. A future role for health applications of large language models depends on\nregulators enforcing safety standards.Lancet Digit. Health6, e662–e672 (2024).\n11. Small, W. R. et al. Large language model–based responses to patients’In-Basket messages.\nJAMA Netw. Open.7, e2422399 (2024).\n12. Ayers, J. W. et al. Comparing physician and artiﬁcial intelligence chatbot responses to patient\nquestions posted to a public social media forum.JAMA Intern. Med.1838, 589–596 (2023).\n13. Rahimzadeh, V., Kostick-Quenet, K., Blumenthal-Barby, J. & McGuire, A. L. Ethics education for\nhealthcare professionals in the era of ChatGPT and other large language models: Do we still\nneed it?.Am. J. Bioeth.23,1 7–27 (2023).\n14. Okamoto, S., Kataoka, M., Itano, M. & Sawai, T. AI-based medical ethics education: examining\nthe potential of large language models as a tool for virtue cultivation.BMC Med. Educ.25, 185\n(2025).\n15. Dillion, D., Mondal, D., Tandon, N. & Gray, K. AI language model rivals expert ethicist in\nperceived moral expertise.Sci. Rep.15, 4084 (2025).\n16. Jiang, L. et al. Investigating machine moral judgement through the Delphi experiment.Nat.\nMach. Intell.7, 145–160 (2025).\n17. Earp, B. D. et al. A personalized patient preference predictor for substituted judgments in\nhealthcare: technically feasible and ethically desirable.Am. J. Bioeth.24,1 3–26 (2024).\nAcknowledgements\nThis study did not receive any funding.\nAuthor contributions\nS.S. and E.K.: contributed to study conceptualization, data collection, and drafting of the manuscript.\nV.S.: contributedto study conceptualization and assisted in manuscript revisions. G.N.N.: contributed\nto study conceptualization and critical revisions.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains supplementary material available at\nhttps://doi.org/10.1038/s41746-025-01792-y.\nCorrespondenceand requests for materials should be addressed to Eyal Klang.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’sn o t eSpringer Nature remains neutral with regard to jurisdictional claims in published\nmaps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons Attribution-NonCommercial-\nNoDerivatives 4.0 International License, which permits any non-commercial use, sharing,\ndistribution and reproduction in any medium or format, as long as you give appropriate credit to the\noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if you\nmodiﬁed the licensed material. You do not have permission under this licence to share adapted\nmaterial derived from this article or parts of it. The images or other third party material in this article\nare included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to\nthe material. If material is not included in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain\npermission directly from the copyright holder. To view a copy of this licence, visithttp://\ncreativecommons.org/licenses/by-nc-nd/4.0/\n.\n© The Author(s) 2025\nnpj |digital medicine Comment\nnpj Digital Medicine|           (2025) 8:461 5",
  "topic": "Medical ethics",
  "concepts": [
    {
      "name": "Medical ethics",
      "score": 0.49496811628341675
    },
    {
      "name": "Engineering ethics",
      "score": 0.4285024404525757
    },
    {
      "name": "Cognitive science",
      "score": 0.4012194275856018
    },
    {
      "name": "Computer science",
      "score": 0.37671762704849243
    },
    {
      "name": "Epistemology",
      "score": 0.35071343183517456
    },
    {
      "name": "Psychology",
      "score": 0.30510762333869934
    },
    {
      "name": "Philosophy",
      "score": 0.19959455728530884
    },
    {
      "name": "Engineering",
      "score": 0.1137109100818634
    },
    {
      "name": "Psychiatry",
      "score": 0.0644206702709198
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2800389475",
      "name": "Rabin Medical Center",
      "country": "IL"
    },
    {
      "id": "https://openalex.org/I4210125099",
      "name": "Mayo Clinic in Arizona",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I98704320",
      "name": "Icahn School of Medicine at Mount Sinai",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1320796813",
      "name": "Mount Sinai Health System",
      "country": "US"
    }
  ],
  "cited_by": 1
}