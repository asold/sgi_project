{
  "title": "LSTTN: A Long-Short Term Transformer-based spatiotemporal neural network for traffic flow forecasting",
  "url": "https://openalex.org/W4392883897",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2138590562",
      "name": "Qinyao Luo",
      "affiliations": [
        "Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2572352381",
      "name": "Silu He",
      "affiliations": [
        "Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2106724710",
      "name": "Xing Han",
      "affiliations": [
        "Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2117947532",
      "name": "Yuhan Wang",
      "affiliations": [
        "Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2097452064",
      "name": "Haifeng Li",
      "affiliations": [
        "Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2138590562",
      "name": "Qinyao Luo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2572352381",
      "name": "Silu He",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2106724710",
      "name": "Xing Han",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2117947532",
      "name": "Yuhan Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097452064",
      "name": "Haifeng Li",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6681133986",
    "https://openalex.org/W2085592822",
    "https://openalex.org/W2528639018",
    "https://openalex.org/W6628877408",
    "https://openalex.org/W2079662306",
    "https://openalex.org/W4388956455",
    "https://openalex.org/W3123909522",
    "https://openalex.org/W2579495707",
    "https://openalex.org/W6747428926",
    "https://openalex.org/W2788919350",
    "https://openalex.org/W4205883350",
    "https://openalex.org/W2907492528",
    "https://openalex.org/W6720006811",
    "https://openalex.org/W6736685754",
    "https://openalex.org/W3179429918",
    "https://openalex.org/W3034749137",
    "https://openalex.org/W3093761440",
    "https://openalex.org/W6794669646",
    "https://openalex.org/W2901504064",
    "https://openalex.org/W3133663379",
    "https://openalex.org/W3109074851",
    "https://openalex.org/W6757242954",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W3177318507",
    "https://openalex.org/W4313156423",
    "https://openalex.org/W6770255733",
    "https://openalex.org/W6845758617",
    "https://openalex.org/W4307171272",
    "https://openalex.org/W4309651348",
    "https://openalex.org/W4283315029",
    "https://openalex.org/W2997848713",
    "https://openalex.org/W3080253043",
    "https://openalex.org/W4310896129",
    "https://openalex.org/W4306317966",
    "https://openalex.org/W6857511798",
    "https://openalex.org/W4385652073",
    "https://openalex.org/W6766978945",
    "https://openalex.org/W3213170289",
    "https://openalex.org/W4323065138",
    "https://openalex.org/W4382240004",
    "https://openalex.org/W2964321699",
    "https://openalex.org/W1485009520",
    "https://openalex.org/W2963840672",
    "https://openalex.org/W3103720336",
    "https://openalex.org/W4376490867",
    "https://openalex.org/W4311001165",
    "https://openalex.org/W1662382123",
    "https://openalex.org/W4297733535",
    "https://openalex.org/W4317940035",
    "https://openalex.org/W3000386982",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4295312788",
    "https://openalex.org/W1539670134",
    "https://openalex.org/W2964015378",
    "https://openalex.org/W4245804068",
    "https://openalex.org/W3103427490",
    "https://openalex.org/W4323250843",
    "https://openalex.org/W4310416691",
    "https://openalex.org/W4382203079",
    "https://openalex.org/W4322614756",
    "https://openalex.org/W4388637518",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2963358464",
    "https://openalex.org/W2965341826"
  ],
  "abstract": null,
  "full_text": "LSTTN: A Long-Short Term Transformer-based Spatio-temporal Neural Network for\nTraffic Flow Forecasting\nQinyao Luoa,b, Silu Hea, Xing Hana, Yuhan Wanga, Haifeng Lia,b,∗∗\naSchool of Geosciences and Info-Physics, Central South University, No.932 South Lushan Road, Changsha, 410083, Hunan, China\nbXiangjiang Laboratory, No. 569, YueLu Avenue, Changsha, 410083, Hunan, China\nAbstract\nAccurate traffic forecasting is a fundamental problem in intelligent transportation systems and learning long-range tra ffic rep-\nresentations with key information through spatiotemporal graph neural networks (STGNNs) is a basic assumption of current traffic\nflow prediction models. However, due to structural limitations, existing STGNNs can only utilize short-range tra ffic flow data;\ntherefore, the models cannot adequately learn the complex trends and periodic features in tra ffic flow. Besides, it is challenging to\nextract the key temporal information from the long historical traffic series and obtain a compact representation. To solve the above\nproblems, we propose a novel LSTTN (Long-Short Term Transformer-based Network) framework comprehensively considering\nthe long- and short-term features in historical tra ffic flow. First, we employ a masked subseries Transformer to infer the content\nof masked subseries from a small portion of unmasked subseries and their temporal context in a pretraining manner, forcing the\nmodel to efficiently learn compressed and contextual subseries temporal representations from long historical series. Then, based on\nthe learned representations, long-term trend is extracted by using stacked 1D dilated convolution layers, and periodic features are\nextracted by dynamic graph convolution layers. For the di fficulties in making time-step level prediction, LSTTN adopts a short-\nterm trend extractor to learn fine-grained short-term temporal features. Finally, LSTTN fuses the long-term trend, periodic features\nand short-term features to obtain the prediction results. Experiments on four real-world datasets show that in 60-minute-ahead\nlong-term forecasting, the LSTTN model achieves a minimum improvement of 5.63% and a maximum improvement of 16.78%\nover baseline models. The source code is available at https://github.com/GeoX-Lab/LSTTN.\nKeywords: Traffic forecasting, spatiotemporal modeling, long-short term forecasting, Transformer, Mask Subseries Strategy.\n1. Introduction\nWith the rapid development of urbanization, intelligent trans-\nportation system (ITS) plays an increasingly important role in\npeople’s daily travel life, and the tra ffic flow forecasting sys-\ntem is also an essential component of ITS. Accurate traffic pre-\ndiction information can help drivers plan their travel routes in\nadvance to minimize the time delay on the road, and also help\nrelated departments to arrange personnel in advance to guide\nthe traffic in congested areas.\nThe task of traffic flow forecasting is challenging due to its\ncomplex spatial dependencies and nonlinear temporal relations.\nTraditional traffic flow prediction methods such as ARIMA [1]\nand V AR [2] require specific assumptions on traffic data. How-\never, real-world data are often too complex to satisfy those as-\nsumptions, limiting the applicability of those methods to a great\nextent. More importantly, they cannot capture the complex non-\nlinear temporal dependencies and do not take the spatial de-\npendencies in the tra ffic network into account. That generates\nadverse impact on their prediction accuracies in practical appli-\n∗Corresponding author: Haifeng Li (lihaifeng@csu.edu.cn)\n∗∗Citation: Q. Luo, S. He, X. Han, Y . Wang, H. Li. LSTTN: A Long-Short\nTerm Transformer-based spatiotemporal neural network for tra ffic flow fore-\ncasting. Knowledge-Based Systems. 2024, 293: 111637\ncations. In the era with well-developed technologies of sens-\ning and data processing, vast amounts of tra ffic data become\navailable to city managers. Along with the rapid advancement\nof deep learning, many methods forecasting tra ffic flow utiliz-\ning deep learning and big data have been proposed and dra-\nmatically improved the forecasting results compared to tradi-\ntional methods. Their performances indicate the great poten-\ntial of deep learning-based, data-driven tra ffic flow forecasting\nmethods. Such methods have become the mainstream forecast-\ning methods today. Early spatiotemporal prediction methods\nadopted CNNs to model the spatial dependecies and achieved\nbetter prediction performance than traditional methods [3, 4].\nSince a traffic network is naturally a non-Euclidean graph struc-\nture, with the proposal of graph neural networks (GNNs), re-\nsearchers have started to employ them to model the spatial de-\npendecies in tra ffic networks, and they have combined GNNs\nwith temporal models such as RNNs and 1-dimensional (1D)\nCNNs to build traffic flow prediction models [5, 6].\nHowever, the vast majority of these models are limited to\nusing short historical series (e.g., 12 time steps or 1 hour of his-\ntorical traffic flow features) as model input, but the information\nin short-term data is often insu fficient to adequately represent\nthe rich temporal features present in historical tra ffic data. Us-\ning the upper figure in Figure 1 as an example, to predict the\ntraffic flow after 06:00, even if we use 6-hour-long historical\nPreprint submitted to Knowledge-Based Systems March 26, 2024\narXiv:2403.16495v1  [cs.LG]  25 Mar 2024\nFigure 1: A snapshot of a historical time series of sensor 400236 and sensor\n400240 in the PEMS-BAY dataset. The sequences in the upper figure corre-\nspond to the green window in the lower figure. The short-term historical trend\nof 00:00-0–6:00 is not sufficient for the model to accurately predict future traf-\nfic flow changes, but considering the long-term trend and periodicity in the long\nhistorical series can help the model better determine future trends.\ndata from 00:00 to 06:00, it is still difficult for the model to ac-\ncurately determine the different trends in traffic flow at different\nlocations by relying only on the short-time trend information\nprovided by this part of the historical data since the trends and\nvalues of the historical series recorded by the two sensors are\nalso very close. The trend and periodicity features in long his-\ntorical series can be of great help to the model in determining\nthe complex trends in tra ffic flow. As shown in the lower fig-\nure in Figure 1, it is easier for the model to infer different future\ntrends based on the different long-term trend features of the two\nseries and the recurring temporal features in the purple circles.\nIn addition, effectively learning the key temporal information in\nlong historical series is also an issue worth considering. It is in-\nefficient to directly input each time step of long historical series\ninto the model; in addition, since traffic flow series have certain\ncontinuity, there is often redundant information in long histor-\nical series, and the model should have the ability to e fficiently\nextract the key representations from long series.\nTo solve the above problems, we introduce long histori-\ncal series into the tra ffic flow forecasting model so that the\nmodel can make a comprehensive judgment about future traffic\nflow fluctuations with the help of long-term trend information.\nWe further propose a novel tra ffic flow forecasting framework\ncalled LSTTN (Long-Short Term Transformer-based Network),\nwhich can take short-term trends into account while obtain-\ning long-term trends and periodic features from long-term key\ntemporal information-rich representations. The contributions of\nthis paper can be summarized as follows:\n1. We propose a tra ffic flow forecasting framework that in-\ntegrates long- and short-term temporal features and can\neffectively utilize the long-term trend and periodic fea-\ntures in long historical series, LSTTN.\n2. Specific long-range dependecies-capturing components\nare designed under the proposed framework. The trans-\nformer model is pretrained by a mask reconstruction task\nto obtain compressed and contextual subseries tempo-\nral representations. Then, long-term trend features are\nextracted from the obtained subseries representations by\nstacked 1D convolutional layers, and a spatial-based graph\nconvolution is adopted to obtain periodic features in long\nhistorical series.\n3. We evaluate the proposed framework on four real-world\ndatasets, and the experimental results show that the LSTTN\nmodel outperforms the baseline models for all predic-\ntion horizons. The visualization of the prediction results\nshows that the LSTTN model is robust to missing data\nand abrupt changes.The source code of this paper is avail-\nable at https://github.com/GeoX-Lab/LSTTN.\nThe rest of this paper is organized as follows. Section 2 re-\nviews previous traffic flow forecasting methods, Section 3 for-\nmally describes the traffic flow forecasting task and presents the\noverall framework and design details, and Section 4 evaluates\nthe method through multiple sets of experiments. Finally, Sec-\ntion 5 concludes the paper and provides possible future research\ndirections.\n2. Related Work\nTraffic flow prediction is a fundamental task in intelligent\ntransportation systems. According to the modeling approach,\nmainstream tra ffic flow prediction methods can be classified\nas statistical-based methods and data-driven spatial-temporal\ngraph neural network methods.\n2.1. Statistical-based Tra ffic Flow Forecasting Methods\nMost early tra ffic flow forecasting methods are based on\nstatistics, such as historical average (HA) [7] models, ARIMA\n[1] models, and Kalman filtering [8]. The historical weighted\naverage model is based on the temporal periodicity of tra ffic\nflow and takes the average value of tra ffic features at the same\ntime-of-day as the prediction result. ARIMA requires input\ntime series to be stationary after di fferencing and captures the\nlinear relationship in the di fferenced time series. The Kalman\nfilter completes the prediction by modeling the state of the dy-\nnamic system.\nMost of the early tra ffic flow forecasting models migrated\nthe methods that were applied to ordinary time series, ignoring\nthe complex interactions between roads in the tra ffic network\nand lacking consideration of spatial dependencies in traffic flow\ndata.\n2.2. STGNN-based Tra ffic Flow Forecasting Methods\n2.2.1. Structural Design of STGNN-based Tra ffic Flow Fore-\ncasting Methods\nIn recent years, the use of neural networks to model the\nspatiotemporal dependecies in traffic flow and train the models\non massive data has become a new trend in the field of tra ffic\nflow prediction, and has achieved better results than previous\nworks [9]. Some methods apply convolutional neural networks\n(CNNs) to model the spatial relationships of tra ffic data orga-\nnized in the form of grids [10, 11]. They consider the Euclidean\n2\ndistance and spatial location relationships between roads, but\nlack a measure of topological relationships. However, road net-\nworks can be naturally expressed in the form of graphs, which\nare more suitable for describing the topological relationships\nbetween roads, and the distance between roads can be repre-\nsented as the weights of the edges. The emergence of graph\nneural networks (GNNs) has solved the problem that previous\ndeep learning methods had difficulty in terms of modeling non-\nEuclidean data structures, and GNNs have been applied to var-\nious different tasks ever since [12, 13, 14].\nGNNs can be classified into two categories, namely spectral-\nbased GNNs and spatial-based GNNs [15]. Bruna et al. first\nproposed the spectral CNN [16], which generalizes CNNs to\nnon-Euclidean space, but the process of spectral decomposi-\ntion of Laplacian matrices suffers from excessive computational\ncomplexity. ChebNet [17] applies Chebyshev polynomials to\napproximate complex spectral convolutions, e ffectively reduc-\ning the complexity of the spectral convolution and reducing the\nnumber of parameters, thus it is less likely to overfit the data.\nGCN [18] can be regarded as a first-order ChebNet with reg-\nularization. It is computationally e fficient and easy to stack\nin multiple layers. Spatial-based GNNs take the perspective\nof local spatial associations between nodes, and describe the\nprocess of graph convolution as an aggregation of information\nfrom the central node and its neighboring nodes. Glimer et\nal. summarized the operations (e.g. aggregation, readout, etc.)\nof the spatial-based GNNs and generalized a class of message\npassing neural networks (MPNN) [19]. The GCN can also be\nregarded as a spatial-based message passing neural network,\nwhere the weight of the messages from neighbor nodes during\naggregation is fixed and determined by the degree of the nodes.\nGAT [20] introduces a multihead self-attention mechanism into\ngraph neural networks to dynamically assign the weight of mes-\nsages from neighboring nodes during aggregation. Thus, com-\npared with GCN, GAT can better focus on the information from\nimportant nodes.\nOn the basis of GNNs, studies further introduced the mod-\neling of temporal dependecies in tra ffic flow and proposed nu-\nmerous spatiotemporal graph neural network models for tra ffic\nforecasting tasks [21, 22, 23, 24, 25, 26]. Depending on the\nmodeling of the temporal dependecies, we classify STGNNs\ninto RNN-based, CNN-based and Transformer-based STGNNs.\n(1) RNN-based STGNNs. DCRNN [5] uses a gated recur-\nrent unit (GRU), a variant of the RNN, to extract temporal fea-\ntures from data, as the GRU achieves similar performance to\nLSTM with fewer parameters. A di ffusion convolution neural\nnetwork (DCNN) is adopted to simulate the e ffect of the spa-\ntiotemporal changes that spread from one node to other nodes\nin a traffic network. T-GCN [26] instead combines GRU with\nGCN, and the results in two common scenarios, namely, on\nhighways and urban roads, show that the performance of T-\nGCN exceeds baseline models. AST-GCN [27] and KST-GCN\n[28] are further proposed to incorporate external factors. How-\never, due to the limitations of the linear chain structure of RNNs,\nthe parameters of RNN-based STGNNs cannot be trained and\nupdated in parallel, so the backpropagation process of these\nmodels is very time-consuming [6]. On the other hand, as the\nfeatures from earlier steps may be forgotten, RNN-based mod-\nels have difficulty in capturing long-range temporal dependen-\ncies in data.\n(2) CNN-based STGNNs. Some works consider 1D convo-\nlutions to model the temporal dependecies. STGCN [6] adopts\na 1D causal convolution and gated linear unit (GLU) to ex-\ntract temporal features from tra ffic data, and combines them\nwith ChebNet to build a spatiotemporal feature extractor. Graph\nWaveNet [29] constructs an adaptive adjacency matrix that cap-\ntures hidden spatial dependencies in traffic data through an end-\nto-end manner without any prior knowledge and utilizes 1D\ndilated causal convolution to enlarge the model’s temporal re-\nceptive field. ASTGCN [30] introduces a spatiotemporal atten-\ntion mechanism to capture long-range temporal dependencies\nand the implied spatial connections in the road network and\ncombines it with spatial graph convolution and temporal 1D\nconvolutions to model the spatiotemporal dynamics in tra ffic\ndata. Overall, CNN-based models no longer su ffer from long\ntraining time and vanishing gradient problems, and 1D convo-\nlutions help CNN-based models learn temporal dependencies\nfrom traffic data.\n(3) Transformer-based STGNNs. Due to structural con-\nstraints, the direct input of long sequences into the models men-\ntioned above may cause the problem of excessive computa-\ntional complexity, so the above methods tend to use short-range\ntraffic flow data (e.g., one-hour historical tra ffic flow informa-\ntion) to predict future traffic flows. However, the inherent peri-\nodicity and the long-term trend information in tra ffic flows are\ndifficult to extract directly from short historical time series. Re-\ncently, with the emergence of Transformer [31], some research\nhas begun to focus on how to use it to fully mine long-range de-\npendencies in historical time series based. While ensuring that\nthe model parameters can be trained in parallel, Transformer\nenables direct connection between the individual time steps of\nthe input sequence independent of the linear chain structure of\nRNNs or the receptive field in CNNs. This approach can help\nTransformer-based models better capture long-range dependen-\ncies in traffic data. Traffic Transformer [23] designs various en-\ncoding strategies for the positional encoding mechanism to help\nTransformer learn day-level and week-level periodicity from\ntraffic flow data. STTN [32] incorporates the graph convolution\nprocess into spatial Transformer, and together with temporal\nTransformer, STTN can capture long-range dependencies from\ntraffic data. Although the above methods take the dependecies\nbetween distant time steps into account, they still only use short\nhistorical time series to make predictions. Other works con-\nsider improving the original Transformer model to make pre-\ndictions based on long sequences. For example, Informer [33]\nproposed ProbSparse attention to reduce the complexity of the\noriginal self-attention mechanism. In addition, a generative de-\ncoder is employed to avoid the error accumulation problem that\narises with increasing time steps. However, these works ignore\nthe spatial dependecies present in tra ffic networks and capture\nmostly trend features while failing to better capture the inherent\nperiodicity in traffic data [34].\n3\n2.2.2. Learning Paradigm of STGNN-based Tra ffic Flow Fore-\ncasting Methods\nIn general, STGNNs mostly adopt a supervised learning\nparadigm and use only tra ffic flow features of future moments\nas supervision signals to guide the model’s training process. In\nrecent years, the rapid development of self-supervised learn-\ning, which learns representations from massive data without\nadditional labels, has led to a large number of applications in\ncomputer vision [35, 36], natural language processing [37, 38],\nand graph representation learning [39, 40, 41]. Additionally,\nSTGNNs can also benefit from additional supervision signals.\nConsidering the relatively small size of most of the publicly\navailable traffic datasets, STGCL [42] designs various data aug-\nmentation methods and uses contrastive learning as an auxiliary\ntask to guide STGNNs to better distinguish different spatiotem-\nporal features in historical data. ST-SSL [43], on the other hand,\nuses the perspective of spatiotemporal heterogeneity and aug-\nments the graph structure and traffic features. STEP [44] passes\nthe long-range representations obtained from Transformer into\na graph structure learning module to learn spatial dependencies\nfrom long historical sequences but does not sufficiently account\nfor the long-term trend and the periodic features that are unique\nto long sequences.\nGiven the above background, in this paper, we consider ex-\nploiting the long-term trend and periodicity from long historical\ntraffic data and expect the model to produce accurate predic-\ntion results based on the long-range and compact representa-\ntions learned from the long-term sequences.\n3. Methodology\n3.1. Problem Definition\nDefinition 1 (Traffic network). A traffic network G can be ex-\npressed as G = (V, E, A). The node set V ( |V|= N) denotes\nsensors or road crossings in the tra ffic network, and the edge\nset E can be obtained according to the spatial distances of sen-\nsors or the topological relations of roads.\nDefinition 2 (Traffic forecasting problem). The traffic forecast-\ning problem can be expressed as predicting the tra ffic features\nF future time steps ahead given the historical features of H time\nsteps and the adjacency matrix A:\n[Xt, Xt+1, . . . ,Xt+F−1] = f (A, [Xt−H, Xt−H+1, . . . ,Xt−1]) (1)\nwhere X ∈RN×T denotes the traffic feature matrix, and T de-\nnotes the total length of the series in the dataset. The vast ma-\njority of current tra ffic forecasting methods f accept a short\nhistorical series, e.g., H = 12. In this paper, we attempt to uti-\nlize the temporal patterns of traffic flow from a longer historical\nseries, which can be expressed as follows:\n[Xt, Xt+1, . . . ,Xt+F−1] = f\n\u0010\nA, Xshort, Xlong\n\u0011\n(2)\nwhere Xshort = [Xt−S , Xt−S +1, . . . ,Xt−1], S denotes the length\nof the short-term historical series given to the model. Xlong =\n[Xt−L, Xt−L+1, . . . ,Xt−1]. L denotes the length of the long his-\ntorical series.\n3.2. LSTTN Framework\nThe overall LSTTN framework is shown in Figure 2. We\nadopt a subseries temporal representation learner to extract subseries-\nlevel temporal representations from long-term series and design\na long-term trend extractor, periodicity extractor and short-term\ntrend extractor to obtain long- and short-term temporal features\nfrom subseries-level representations. Specifically:\n1. Subseries temporal representation learner (STRL). As it\nis inefficient to learn time-step level fine-grained repre-\nsentations for long-term series, we instead learn subseries-\nlevel representations from the temporal context by using\na mask reconstruction task.\n2. Long-term trend extractor. This module expands the model’s\ntemporal receptive field by stacking dilated 1-dimensional\nconvolutional layers to capture long-term trends from sub-\nseries representations.\n3. Periodicity extractor. This module captures the inherent\nperiodicity in traffic flow from the representations of the\nsame period of time from the previous same week-of-day\nand the previous day.\n4. Short-term trend extractor. As the subseries representa-\ntions are coarse-grained, we cannot obtain time-step level\nforecasting results from those representations. The mod-\nule directly utilizes the existing STGNN model to learn\nlocal fine-grained trend features from the short-term his-\ntorical series.\nFigure 2: An overview of the LSTTN framework. The long historical time\nseries Xlong is split into subseries of equal lengths, and the last subseries is\ntaken as the short-term historical time series Xshort. The subseries-level tem-\nporal representation S, which is rich in key temporal information, is learned\nby the subseries temporal representation learner, and then, long-term trend and\nperiodic features are extracted from S. Meanwhile, time-step level short-term\ntrend are extracted directly from Xshort. Finally, the long-term and short-term\nfeatures are fused to obtain the prediction results.\n3.3. Masked Sub-series Transformer\nThe fundamental purpose of the masked subseries Trans-\nformer (MST) is to infer the contents of masked subseries from\na small number of subseries and their temporal context so that\nthe model can efficiently learn compressed, context information-\nrich subseries representations from long time series. The design\n4\nof MST consists of two basic problems: (1) the masking strat-\negy and (2) the model for learning representations.\n(1) Masking strategy\nTwo important elements of the masking strategy of the MST\nneed to be considered: the basic unit for masking and the mask\nratio.\n(a) The basic unit for masking. Existing methods usually\nuse a 5-minute time step as the basic unit of input data, which\nis inefficient for capturing the trend of long time series. Inspired\nby [44, 45, 46], we divide the long series into equal-length\nsubseries containing multiple time steps, and the subseries are\ntaken as the basic unit of the model input.\n(b) Mask ratio. Both BERT [37] and MAE [35] learn the\nessential semantic information in the data by mask reconstruc-\ntion. In natural language, the semantic information of words\nis richer, and sentences rarely have redundant parts and have\nhigh information density, so BERT sets a lower masking ratio\nof 15%. The information density of image data is relatively low,\nand there is spatial continuity of pixel points, so even if MAE\nmasks off 75% of the pixels, the main content of the image can\nstill be inferred. Long-term tra ffic flow data are similar to im-\nages with temporal continuity and low information density, so a\nrelatively high masking ratio is needed. We apply 75% random\nmasking in this paper.\n(2) Model for learning representations\nAnother issue to consider is which model to choose to learn\nthe subseries representations. For time series, one of the differ-\nences between Transformer and temporal models such as RNN\nand 1D CNN is that the inputs to each time step in Transformer\nare directly connected to each other. Regardless of increases\nin time step, Transformer learns representations with previous\ntemporal features being considered. In this paper, the Trans-\nformer encoder is adopted as the STRL.\nFigure 3: The structure of masked subseries Transformer\nAs shown in Figure 3, MST consists of two parts: the STRL\nand the self-supervised task head. The STRL learns the sub-\nseries temporal representation, and the self-supervised task head\nreconstructs the complete long series based on the temporal\nrepresentation of the unmasked subseries and the mask tokens.\nSpecifically, first, Xlong = [Xt−L, Xt−L+1, . . . ,Xt−1], the long his-\ntorical series is divided into nonoverlapping subseries contain-\ning S time steps, so the number of subseries is N = L/S . We\nrandomly mask 75% of the subseries, and the set of masked\nsubseries is denoted as Xmasked. The remaining data are denoted\nas Xunmasked and are used as the input to STRL:\nSunmasked = STRL(Xunmasked) (3)\nwhere Sunmasked denotes the representations of Xunmasked, which\nis the output by STRL. The self-supervised task head consists\nof a Transformer layer and a linear output layer and can recon-\nstruct the complete long series givenSunmasked and the learnable\nmask token S[MASK] as follows:\nh ˆXmasked , ˆXunmasked\ni\n= TaskHead \u0000\u0002Sunmasked , S[MASK]\n\u0003\u0001 (4)\nThe goal of the pretraining stage is to make the error be-\ntween the reconstructed ˆXmasked and the masked truth values as\nsmall as possible, so only the masked subseries are considered\nwhen calculating the loss:\nLpretrain\n\u0010 ˆXmasked , Xmasked ; ΘT\n\u0011\n=\n\r\r\r ˆXmasked −Xmasked\n\r\r\r (5)\nwhere ΘT represents the learnable parameters of the whole Trans-\nformer.\n3.4. Long-term Trend Extractor\nThe relatively small amount of information in a short-term\nhistorical series is not sufficient for the model to infer complex\nfuture changes in tra ffic flow, while the long historical series\ncan help the model determine the fluctuation of tra ffic flow in\nfuture moments. For this reason, we design a long-term trend\nextractor to extract the long-term trend features in tra ffic flow\nfrom the subseries temporal representations.\nFigure 4: A demonstration of the 1-dimensional dilated convolution layer. The\nyellow parallelograms at the bottom represent input data, and the red parallel-\nogram represents the output. Layers in the middle are hidden layers. As the\nnumber of layers increases, the receptive field grows exponentially, enabling\nthe efficient capture of long-range features.\nCommonly adopted basic structures for temporal feature ex-\ntraction include the RNN and 1-dimensional CNN. However,\nas RNNs cannot process the features of each time step in par-\nallel and are prone to the problem of gradient vanishing and\ngradient explosion, RNNs have difficulty handling long series.\nOrdinary 1-dimensional CNNs have a limited receptive field,\nand increasing that field requires stacking multiple CNN layers,\n5\nwhich leads to a large increase in the number of model param-\neters with increasing model depth. As shown in Figure 4, we\nadopt stacked 1-dimensional dilated convolution layers [47] as\nthe long-term trend extractor. The receptive field of the mod-\nule grows exponentially as the number of 1-dimensional dilated\nconvolution layers increases, which can capture trend features\nefficiently while avoiding problems such as gradient vanishing.\nThe dilated convolution operation can be expressed as follows:\nx ∗d C(m) =\nk−1X\nj=0\nC(m)x(m −d ×j) (6)\nwhere m denotes the m-th element in seriesx, C ∈Rk represents\nthe convolution kernel, and d represents the dilation rate. In this\npaper, a convolution layer can be expressed as follows:\nDi = Convi(Di−1) = MaxPool(gelu(Di−1 ∗d Ci)) (7)\nwhere the max pooling operation is adopted to reduce dimen-\nsions. The dilation rate d of the i-th layer is set to 2 i. When\ni = 1, the input to the module is the set of subseries temporal\nrepresentations S, i.e., D1 = S = [S1, S2, . . . ,SN ]. The output of\nthe last convolution layer is taken as the long-term trend feature\nHlong.\n3.5. Periodicity Extractor\nPeriodicity is also an important pattern of traffic flow. Gen-\nerally, there is daily and weekly periodicity in tra ffic flow, and\ntraffic in the same time period from di fferent dates can show\nvery similar spatiotemporal patterns. In this paper, we build\na periodicity extractor to capture periodic spatiotemporal fea-\ntures from the subseries representations of the corresponding\ntime period in the previous week and the previous day. As the\nrepresentations of the subseries already contain temporal infor-\nmation and no longer have temporal dimensions, this module\nmainly considers extracting the spatial dependencies among the\ninput features across different time steps of each node while re-\ntaining the temporal information of the subseries. Let the du-\nration of a day corresponds to a series of l segments; then, the\nrepresentations of the corresponding moments from the previ-\nous week and the previous day can be denoted asSweek = SN−7×l\nand Sday = SN−l, respectively ( N denotes the number of sub-\nseries which equals L/S ). As shown in Figure 5, Sweek and\nSday are passed into a spatial-based graph convolution module\nfor the obtainment of periodic temporal features Hday and Hday.\nThis module is similar to the one proposed in [29]. As Figure\n5 indicates, the graph convolution module combines the spatial\ndependencies defined by the structure of the tra ffic graph and\nthe spatial dependencies hidden in the graph.\nHweek = PK\nk=0 Pk\nf SweekWk1 + Pk\nbSweekWk2 + Ak\nadpSweekWk3 (8)\nHday = PK\nk=0 Pk\nf Sday Wk4 + Pk\nbSday Wk5 + Ak\nadp Sday Wk6 (9)\nwhere Pf = APn\nj=1 Ai j\nand Pb = AT\nPn\nj=1 AT\ni j\ncorrespond to the forward\ndiffusion and backward diffusion of graph signals, respectively,\nand represent corresponding transition matrices. The power of\nthe matrices k represents the number of steps in the di ffusion\nprocess. W denotes the weight matrices. Aadp is a self-adaptive\nneighbor matrix which can be considered as the transition ma-\ntrix of a hidden diffusion process. Aadp = Softmax\n\u0010\nReLU\n\u0010\nE1ET\n2\n\u0011\u0011\n.\nE1 and E2 represent the source node embedding and target node\nembedding, respectively. The spatial dependency weight be-\ntween the source node and target node is derived by multiplying\nE1 and E2. ReLU() is for eliminating weak dependencies, and\nSoftmax() is for normalization.\nFigure 5: A demonstration of the spatial-based graph convolution module. In\nthis module, the spatial dependencies between two nodes are supposed to come\nfrom three diffusions, forward diffusion and backward diffusion that are defined\nby graph structure, as well as the di ffusion hidden in graph. If there is no\navailable graph structure, this module will only capture the dependencies which\nare from hidden diffusion and depicted by the self-adaptive neighbor matrix.\n3.6. Short-term Trend Extractor\nThe granularity of the subseries-level temporal representa-\ntions extracted from long series is coarse, which makes it di ffi-\ncult for the model to accurately predict the fine-grained tra ffic\nflow trends at the time-step level. In addition, there is a strong\ntemporal correlation between the future short-term tra ffic flow\nand the historical short-term traffic flow, so the short-term trend\nneeds to be modeled separately.\nIt has been widely proved that STGNNs excel at capturing\nfine-grained features from short-term series [29, 5, 6]. Basi-\ncally, they complete the feature capture in two steps. First, they\nlearn spatial features and temporal features separately via spa-\ntial learning networks and temporal learning networks. Then\nthey fuse two kinds of features through a certain spatiotempo-\nral fusion neural architecture. Given the acknowledged capa-\nbility of STGNNs, we can directly adopt an existing STGNN\nsuch as Graph WaveNet [29], DCRNN [5] or STGCN [6], as\nthe short-term trend extractor to obtain finer-grained short-term\ntrend Hshort:\nHshort = STGNN (A, Xshort) (10)\n6\nwhere Xshort represents the last subseries in the long series,\ni.e., the subseries closest to the current moment, A represents\nthe neighbor matrix, STGNN() represents the adopted STGNN\nmodel.\n3.7. Feature Fusion\nTo comprehensively consider the long- and short-term fea-\ntures in the long historical series, the previously obtained long-\nterm trend features, periodic features and short-term trend fea-\ntures are fused to obtain the final prediction result ˆY:\nˆY = MLP\n\u0010\nMLP\n\u0010\nHlong∥Hweek∥Hday\n\u0011\n∥Hshort\n\u0011\n(11)\nwhere ∥denotes the concatenation operation. The aim of the\ntraffic flow forecasting task is to make the model output as close\nas possible to the true values, so L1 loss is chosen as the objec-\ntive function. It is expressed as follows:\nLforecast\n\u0010 ˆY, Y; Θ\n\u0011\n=\n\r\r\r ˆY −Y\n\r\r\r (12)\nwhere Y = [Xt, Xt+1, . . . ,Xt+F−1] represents the ground truth\nand Θ denotes the set of learnable parameters in the whole\nmodel.\n4. Experiments\n4.1. Datasets\nFour public real-world tra ffic flow datasets were chosen to\nfully evaluate the performance of our model.\n(1) METR-LA. This dataset contains traffic speed data col-\nlected from 207 sensors on the Los Angeles County freeway\nsystem, ranging from March 1, 2012 to June 30, 2012.\n(2) PEMS-BAY . This dataset consists of traffic flow speeds\ncollected from 325 sensors on highways in bay area, ranging\nfrom Jan 1, 2017 to May 31, 2017.\n(3) PEMS04. This dataset consists of tra ffic flow, occu-\npancy and speed data, collected from 307 sensors on 29 high-\nways in California. The time span of the dataset is from January\nto February 2018.\n(4) PEMS08. This dataset contains tra ffic data collected\nfrom 170 sensors on 8 highways in California. Similar to PEMS04,\nit consists of three features: flow, occupancy and speed. The\ntime span of the dataset is from July to August 2018.\nDetailed statistical information about the four datasets is\nprovided in Table 1. To provide a fair comparison, the dataset\ndivision in this paper is kept consistent with other examples in\nthe literature. For METR-LA and PEMS-BAY , the ratio of the\ntraining, validation and test sets is 7:2:1, and for PEMS04 and\nPEMS08, it is 6:2:2.\n4.2. Experimental Setup\n4.2.1. Evaluation Metrics\nLet the number of samples in the dataset be n. In addition,\nlet Yi = Xt:t+F = [Xt, Xt+1, . . . ,Xt+F−1] denote the ground truth\nof the i-th sample in the dataset and ˆYi denote the prediction\nresult provided by the model. We adopt the following metrics\nto evaluate the performance of our model:\n• Root mean squared error (RMSE):\nRMSE =\nvt\n1\nn\nnX\ni=1\n\u0010 ˆYi −Yi\n\u00112\n(13)\n• Mean absolute error (MAE):\nMAE = 1\nn\nnX\ni=1\n\f\f\f ˆYi −Yi\n\f\f\f (14)\n• Mean absolute percentage error (MAPE):\nMAPE = 1\nn\nnX\ni=1\n\f\f\f\f\f\f\nˆYi −Yi\nYi\n\f\f\f\f\f\f (15)\nFor consistency with previous works and to provide a fair\ncomparison with other baselines, we omit missing data when\ncalculating the metrics above.\n4.2.2. Baseline Models\nWe compare our method with the following nine traffic fore-\ncasting models. The former five are widely adopted baseline\nmodels and the latter four are models proposed in nearly two\nyears. A brief description of each model is provided as below:\n(1) DCRNN [5], a combination of di ffusion convolutional\nneural network and a gated recurrent unit;\n(2) STGCN [6], a spatiotemporal network that stacks 1D\ngated convolution blocks and graph convolution blocks;\n(3) Graph WaveNet [29], a spatiotemporal network that uti-\nlizes adaptive dependency matrix and merges 1D causal convo-\nlution and graph convolution to capture spatiotemporal depen-\ndencies;\n(4) GMAN [48], a multihead attention network that cap-\ntures the spatial relationship between di fferent nodes and the\ntemporal relationship between different time steps;\n(5) MTGNN [49], a model capable of learning multi-scale\nspatio-temporal features without prior knowledge about graph\nstructure via a graph learning layer;\n(6) DDSTGCN [50], a dual dynamic STGCN that utilizes\nedge features to transform traffic flow graphs into hypergraphs;\n(7) STID [51], a model that encodes information based on\nsimple multi-layer perceptrons and makes predictions through\na regression layer;\n(8) DSTET [52], a transformer network which enhances the\ncharacterzation of spatial-temporal features through decoupling\nthe spatial and temporal embedding;\n(9) DAGN [53], a domain adversarial graph neural network\nwhich captures node-pair adjacent relationships to enable dy-\nnamic aggregation of spatial-temporal information.\n4.2.3. Experimental Environment and Hyperparameter Settings\nAll of the experiments are conducted on the Linux platform\nequipped with an Intel Xeon Gold 5218R and a NVIDIA RTX\nA6000 GPU, and the models are implemented with PyTorch\n[54]. The length of the input sequence is set to two weeks,\n7\nTable 1: Stastistics of datasets\nDataset Nodes Edges Time interval Samples\nMETR-LA 207 1722 5mins 34272\nPEMS-BAY 325 2694 5mins 52116\nPEMS04 307 987 5mins 16992\nPEMS08 170 718 5mins 17856\nwhich is equivalent to 4032 time steps for datasets with a 5-\nminute interval between each data point. The batch size is set\nto 32, and the number of training iterations was 100. We use the\nAdam optimizer [55] to train the model, and a multistep learn-\ning rate scheduler is adopted to control how the learning rate\ndecreases as the training process progresses. The hidden dimen-\nsion of the long-term trend extractor and periodicity extractor is\nset to 4. The hyperparameters of the STGNN are set according\nto those provided in the original paper, and the STGNN used in\nthe experimental part of this paper is Graph WaveNet.\n4.3. Experimental Results\n4.3.1. Prediction Accuracy\nWe compare the LSTTN model with the nine baseline mod-\nels on the four real-world traffic datasets. The results are shown\nin Table 2. To provide fair comparisons, for the five widely\nadopted baseline models, we adopt the experimental results from\nthe LibCity [56] benchmark. In the benchmark, the hyperpa-\nrameters of those baseline models have been carefully adjusted,\nand the results are better than those given in the original papers\nin most cases. For the four baseline models proposed in recent\ntwo years, the experimental results are extracted from [52] and\n[53]. The former paper provides the top results of DDSTGCN,\nSTID and DSTET under the same experimental setting, the lat-\nter presents the best performance of DAGN.\nAccording to Table 2, the LSTTN model acquires very high\nprediction accuracy on all four datasets. Though the perfor-\nmance of the LSTTN model on PEMS08 is slightly inferior\nto Graph WaveNet and DSTET, on the other three datasets,\nthe advantage of the LSTTN model over baseline models is\nquite significant. Especially, on METR-LA, the dataset with\nthe largest number of samples, the LSTTN model outperforms\nall nine baseline models in all metrics and for all prediction\nhorizons, On the second largest dataset, PEMS-BAY , in MAPE,\neven compared to the most comparative baseline model, DSTET,\nthe LSTTN model achieves improvements of 0.94%, 4.01% and\n8.47% at 15 min, 30 min and 60 min horizons, respectively.\nIt is also worth nothing that, on the three datasets, as the pre-\ndiction horizon increases, the improvements achieved by the\nLSTTN model in all three metrics become larger. Specifically,\nwhen predicting the next 60 min, the LSTTN model achieves\nimprovements of 9.55% in RMSE, 8.73% in MAE and 12.92%\nin MAPE on METR-LA. Similarly, on PEMS-BAY , improve-\nments of 9.86% in RMSE, 13.38% in MAE and 16.78% in\nMAPE are observed. And on PEMS04, improvements of 5.63%\nin RMSE, 7.05% in MAE and 13.44% in MAPE are achieved\nby the LSTTN model. Those results indicate that the LSTTN\nmodel has stronger long-term prediction capability in compari-\nson.\nAnother thing worth noting is that except the LSTTN model,\nDSTET is the only one predicting tra ffic flow with considera-\ntion into periodicity. The result that DSTET displays the best\nperformance among nine baseline models corroborates the im-\nportance of utilizing periodicity. Since one major difference be-\ntween DSTET and the LSTTN model is that the LSTTN model\nalso captures long-term trend, the advantage of the LSTTN model\nover DSTET may be attributed to its introduction of long-term\ntrend for prediction.\n4.3.2. Ablation Studies\nTo demonstrate that each module in the LSTTN model can\neffectively improve the prediction performance, ablation exper-\niments are conducted on the METR-LA dataset. the experimen-\ntal results are shown in Table 4.3.2, where w/o LT represents the\noriginal the LSTTN model without a long-term trend extractor,\nw/o P represents the original model without a periodicity ex-\ntractor, w/o ST indicates that the short-term trend extractor, i.e.,\nSTGNN, was removed from the original model, and ST only\nindicates that only STGNN was used to generate prediction re-\nsults.\nAs seen from the table, (1) the LSTTN model without the\nlong-term trend module has worse performance than the orig-\ninal the LSTTN model for all prediction horizons, and as the\nhorizon increases, the difference in their performances also in-\ncreases, with a maximum difference of approximately 17% (60\nmin, MAPE metric). This result may have been found because\nthe fluctuation in traffic flow is relatively small in a short hori-\nzon and has a high correlation with short-term historical fea-\ntures. However, as the horizon becomes longer, the short-term\nhistorical features become increasingly insu fficient in terms of\nadequately judging complex future temporal trends, and the\nlong-term trend tends to play a more important role. (2) The\nperformance of the LSTTN model without the periodicity mod-\nule is weaker than that of the original model for all horizons,\nwhich indicates that explicitly modeling the periodicity in traf-\nfic flow helps improve the model’s performance. However, the\ncontribution of periodicity to the performance improvement is\nrelatively small compared to that of the long-term trend. (3)\nThe prediction performance of the LSTTN model without the\nshort-term trend module is significantly worse than that of the\noriginal model, which illustrates the necessity of retaining the\nshort-term trend module. It is worth noting that the metric val-\nues of the LSTTN model without the short-term trend module\nare very close at di fferent forecast lengths, which may happen\nbecause the model that only utilizes coarse subseries represen-\ntations cannot infer the fine-grained time-step level fluctuations.\n8\nTable 2: Prediction performances of traffic forecasting models on multiple datasets. The best results are marked in bold, and the second-best results are underlined.\nMETR-LA PEMS-BAY PEMS04 PEMS08\n15 min 30 min 60 min 15 min 30 min 60 min 15 min 30 min 60 min 15 min 30 min 60 min\nDCRNN\nRMSE 4.61 5.33 6.25 2.18 2.84 3.58 29.50 31.35 34.20 22.08 23.64 25.99\nMAE 2.49 2.74 3.08 1.10 1.33 1.59 18.51 19.70 21.56 14.30 15.22 16.70\nMAPE 6.19% 7.12% 8.44% 2.21% 2.82% 3.58% 12.60% 13.45% 14.87% 9.31% 9.86% 10.79%\nSTGCN\nRMSE 4.80 5.51 6.34 2.46 2.98 3.57 29.53 30.49 31.86 22.87 23.88 25.32\nMAE 2.59 2.82 3.11 1.32 1.50 1.73 18.70 19.28 20.11 14.80 15.33 16.22\nMAPE 6.61% 7.43% 8.53% 2.77% 3.23% 3.86% 13.06% 13.42% 13.98% 9.81% 10.11% 10.64%\nGraph WaveNet\nRMSE 4.84 5.54 6.33 2.20 2.83 3.50 27.70 28.60 29.81 20.70 21.76 23.34\nMAE 2.58 2.83 3.14 1.10 1.32 1.57 17.20 17.76 18.56 13.03 13.55 14.34\nMAPE 6.58% 7.58% 8.89% 2.23% 2.82% 3.51% 12.02% 12.49% 13.35% 8.76% 8.98% 9.76%\nGMAN\nRMSE 4.99 5.51 6.17 2.46 2.99 3.56 28.91 29.66 30.77 22.40 23.23 24.61\nMAE 2.80 3.01 3.31 1.33 1.54 1.78 18.47 18.88 19.59 14.92 15.29 16.11\nMAPE 7.44% 8.21% 9.26% 2.73% 3.26% 3.90% 15.66% 15.78% 16.12% 12.31% 12.52% 13.15%\nMTGNN\nRMSE 4.55 5.19 6.01 2.21 2.85 3.55 27.97 28.92 30.23 21.05 22.10 23.58\nMAE 2.46 2.69 3.00 1.11 1.34 1.59 17.41 17.97 18.73 13.55 14.08 14.96\nMAPE 6.87% 7.00% 8.14% 2.25% 2.86% 3.58% 12.75% 13.31% 13.81% 10.00% 9.99% 10.56%\nDDSTGCN\nRMSE 5.01 6.02 7.13 2.71 3.64 4.37 28.38 29.54 30.69 21.14 22.23 24.12\nMAE 2.64 3.00 3.44 1.29 1.60 1.89 17.69 18.51 19.51 13.54 14.02 14.70\nMAPE 6.76% 8.12% 9.74% 2.69% 3.62% 4.46% 12.34% 12.70% 13.46% 8.82% 9.71% 10.41%\nSTID\nRMSE 5.53 6.60 7.54 2.81 3.72 4.40 28.48 29.86 31.79 21.66 23.57 25.89\nMAE 2.80 3.18 3.55 1.30 1.62 1.89 17.51 18.29 19.58 13.28 14.21 15.58\nMAPE 7.70% 9.40% 10.95% 2.73% 3.68% 4.47% 12.00% 12.46% 13.38% 8.62% 9.24% 10.33%\nDSTET\nRMSE 4.52 5.22 6.08 2.17 2.85 3.60 27.38 28.66 29.77 20.24 21.63 23.53\nMAE 2.46 2.71 3.03 1.06 1.29 1.57 16.90 17.68 18.48 12.25 13.21 14.11\nMAPE 6.05% 6.95% 8.30% 2.13% 2.74% 3.54% 11.59% 12.44% 12.71% 8.03% 8.83% 9.30%\nDAGN\nRMSE 5.03 6.00 7.49 2.58 3.22 4.21 29.68 32.02 38.87 23.56 25.46 31.97\nMAE 2.67 3.03 3.67 1.28 1.49 1.86 19.13 20.53 23.63 15.16 16.68 20.94\nMAPE 6.85% 8.16% 10.55% 2.75% 3.38% 4.50% 13.85% 14.31% 15.55% 10.87% 11.29% 14.30%\nLSTTN\n(Ours)\nRMSE 4.42 5.10 5.92 2.18 2.76 3.41 27.74 28.67 30.00 20.78 21.89 23.47\nMAE 2.42 2.65 2.96 1.06 1.26 1.48 17.06 17.62 18.46 13.17 13.71 14.54\nMAPE 5.94% 6.80% 7.93% 2.11% 2.63% 3.24% 11.34% 11.68% 12.17% 8.63% 9.09% 9.77%\nTable 3: Ablation studies\n15 min 30 min 60 min\nRMSE MAE MAPE RMSE MAE MAPE RMSE MAE MAPE\nOurs 4.42 2.42 5.98% 5.10 2.65 6.80% 5.92 2.96 7.93%\nw/o LT 4.71 2.50 6.43% 5.59 2.81 7.76% 6.74 3.23 9.57%\nw/o P 4.46 2.43 6.02% 5.21 2.69 6.98% 6.15 3.04 8.30%\nw/o ST 8.71 4.07 12.03% 8.72 4.07 12.04% 8.75 4.09 12.11%\nST only 4.84 2.58 6.58% 5.54 2.83 7.58% 6.33 3.14 8.89%\n9\n(a)\n (b)\nFigure 6: Loss values of the Transformer model on the validation set during the\npretraining stage. (a) Change in validation losses as iteration continues, and (b)\nthe lowest validation loss values during iterations with di fferent dimensions of\nsubseries representations.\n4.3.3. Hyperparameter Analysis\n(1) Dimension of subseries representations. The dimension\nof each subseries representation output by Transformer, i.e., the\ndimension of the hidden Transformer layer during the pretrain-\ning stage, is an important hyperparameter of the model. We\nselected the best dimension from [32, 64, 96, 128] and con-\nducted experiments on the METR-LA dataset. To account for\nmodel generalizability while avoiding test set information leak-\nage, the validation loss was used as an evaluation metric. A\nlower loss value indicates a better ability to reconstruct masked\nsubseries from given contexts and to capture the contextual as-\nsociations in long series. As shown in Figure 6(b), with the\nincrease in dimension, the validation loss shows a trend of de-\ncreasing and then increasing, and when the dimension is set to\n32, the subseries representations cannot adequately express the\ncontextual information and their own temporal information in\nthe long-term sequence. When the dimension is set to 96 or\n128, as shown in Figure 6(a), it becomes easy for the model\nto overfit the training set, and the loss value is slightly worse\nthan that when the dimension is set to 64. Therefore, we set the\ndimension of the subseries representations to 64 in this paper.\n(2) Dimension of the hidden layers in the long-term trend\nmodule and periodicity module. We found the optimal hidden\nlayer dimension from [1, 4, 8, 16, 32] and conducted experi-\nments on the METR-LA dataset. From Figure 7, it can be ob-\nserved that when the dimension is set to 4, the value of each\nmetric reaches the optimum, while a larger dimension causes\na performance drop. A small dimension is not su fficient for\nthe model to fully capture the trend and periodic features in\nthe data, while a large dimension may cause the model to over-\nfit the training set and reduce the generalizability, resulting in\npoor model performance on the test set. Therefore, we set the\nhidden layer dimension of the long-term trend module and the\nperiodicity module to 4 to obtain the best performance.\n4.3.4. Visualization\nTo demonstrate the performance and advantages of the LSTTN\nmodel more clearly, we visualize the 15-minute ahead, 30-minute\nahead and 60-minute ahead prediction results of the LSTTN\nmodel and Graph WaveNet on the METR-LA dataset. Figure\nFigure 7: Loss values of the Transformer model on the validation set during the\npretraining stage. (a) Change in validation losses as iteration continues, and (b)\nthe lowest validation loss values during iterations with di fferent dimensions of\nsubseries representations.\n10\nFigure 8: Visualization of 15-minute ahead predictions on a snapshot of the\nMETR-LA test set\nFigure 9: Visualization of 30-minute ahead predictions on a snapshot of the\nMETR-LA test set\n11\nFigure 10: Visualization of 60-minute ahead predictions on a snapshot of the\nMETR-LA test set\n8 ∼10 show the prediction results for sensor 773023 and sen-\nsor 771673 (corresponding to node 91 and node 196, respec-\ntively) from June 10 (Sunday) to June 19, 2012 (Tuesday). The\nzero values in the ground truth indicate missing data. It can\nbe observed that the LSTTN model is able to provide accurate\nprediction results for all prediction horizons. In addition, the\nLSTTN model has two major advantages:\n(1) LSTTN can sense sudden changes in tra ffic flow more\nquickly.\nTo further compare the performance from a smaller scale,\nwe visualize the prediction of sensor 773023 (node 91) on June\n19. It can be found that the accuracy of both the LSTTN model\nand Graph WaveNet decreases as we increase the horizon, and\nthe accuracy drops more significantly in the case of large fluc-\ntuations. However, the deviation in the results provided by the\nLSTTN model is smaller in comparison. For example, when\nthe tra ffic speed rebounded suddenly and significantly at ap-\nproximately 19:00 as the evening travel peak ended, and such\nsudden change is neither a random occurrence nor a short-term\ntrend, but a periodic feature , As seen in Figure 8 ∼10, both\nthe LSTTN model and Graph WaveNet exhibited a certain time\ndelay in predicting the sudden change, and the time delay was\nmore significant when the prediction horizon was larger. How-\never, the time delay for the LSTTN model is relatively smaller,\nand the predicted value is closer to the ground truth. Consid-\nering that Graph WaveNet is designed to learn short-term trend\nonly, the performance di fference between Graph Wavenet and\nthe LSTTN model may be attributed to that Graph WaveNet\nmistakenly regards the sudden change in the short-term sequence\nas a noise instead of a feature, whereas the LSTTN model cap-\ntures this feature by the periodicity extractor and utilizes it for\npredictions.\n(2) LSTTN can make rough predictions even when short-\ntime historical data are missing.\nMissing data often occurs in traffic road network data due to\ncommunication failures, sensor malfunctions or system main-\ntenance. For example, the network-wide level tra ffic data are\nmissing on June 9, 17 and 18, 2012, in the METR-LA dataset.\nthe LSTTN model is able to make rough prediction results based\non the temporal information provided by the long historical\ntime series even when a period of data is missing. From the pre-\ndiction result shown in Figure 10, we can see that since the input\nwindow of the ordinary STGNN (e.g., Graph WaveNet) is short,\nwhen the length of missing data is longer than the STGNN in-\nput window, the input time series will only contain zeros, and\nthe ordinary STGNNs cannot utilize any valid temporal infor-\nmation and can only output an average value without any fluctu-\nation. However, the LSTTN model can still provide meaningful\nprediction results in this case. For instance, the LSTTN model\nsuccessfully predicted the spiky temporal pattern of node 91;\nfor node 196, whose speed changes more smoothly, the LSTTN\nmodel can predict the trend of rapid increase and then slow de-\ncrease during the missing data period. This result indicates that\nthe LSTTN model can e ffectively utilize long-term trends and\nthe periodic information provided by the long historical time\nseries to obtain rough prediction results even when there is a\nlong period of missing data.\n12\n4.3.5. Execution cost analysis\nWe analyse the execution costs of the LSTTN model and the\nthree most comparative baseline models on METR-LA using\nthe same hardware. For a better interpretation of the execution-\ncost comparison (Table 4), a detailed analysis into the traning\ntime of the LSTTN model (Table 5) and a brief comparison\nof model design (Table 6) are provided. According to Table\n4, the LSTTN model requires a larger number of parameters\nand longer training time than the other models. Basically, the\nincreases in execution cost come from three aspects:\n1. Employment of Transformer. For the LSTTN model, over\n96% of its training time is spent on the masked sub-series\nTransformer (Table 5). Compared with graph convolu-\ntion network and graph adjacency matrix, Transformer\nrequires considerably longer training time. That is also\nreflected in the result that besides the LSTTN model,\nDSTET which also employs Transformer demands sig-\nnificantly longer time for training than the other two mod-\nels without Transformer (Table 4). As for the gap be-\ntween the LSTTN model and DSTET, it is mainly a con-\nsequence of di fference in the length of input sequence.\nAs noted in Table 1, the time complexity of Transformer\nis proportional to the length of input sequence (Ls). Since\nDSTET utilizes Transformer to learn the short-term fea-\ntures, while the Transformer employed in the LSTTN\nmodel is for better learning of long-term features, the in-\nput sequence of the latter Transformer (4032 time steps)\nis hundreds of times longer than that of the former Trans-\nformer (12 time steps). That makes training the latter\nTransformer cost much more time than training the latter\none.\n2. Additional learning of long-term features. As Table 6\nindicates, among the four models, the LSTTN model is\nthe only one learning both short-term features (short-term\ntrend) and long-term features (long-term trend and pe-\nriodicity). Two more feature-capture modules, namely\nlong-term extractor and periodicity extractor, are deployed\nin the LSTTN model, compared with the other models.\nTraining the two modules require additional time and pa-\nrameters.\n3. Additional training of feature fusion. As noted earlier,\nthe LSTTN models learns three types of features. To\nbetter utilize the learned features for better forecasting,\na feature-fusion module is also deployed in the LSTTN\nmodel. This deployment brings not only additional pa-\nrameters but also additional stage of training to the model.\n5. Conclusion and Future Work\nIn consideration of the insu fficiency of short-term features\nfor traffic forecasting, this paper proposes a novel framework\nnamed LSTTN that integrates both the long-term features and\nshort-term features present in historical tra ffic data to obtain\nmore accurate prediction results. The proposed LSTTN is plug-\ngable for its compatibility with all STGNN models, indicating\nthe feasibility of packing LSTTN as a plugin to make it easier\nto deploy LSTTN to application platforms.\nUnder the proposed framework, a specific model design is\nalso provided. Apart from extracting short-term features using\nSTGNN, the LSTTN model also learns two additional long-\nterm features, namely long-term trend and periodicity. And for\nvalid extraction of long-term features, the LSTTN model first\nlearns sub-series temporal representations via a masked sub-\nseries Transformer, then based on the learned representations, it\nextracts long-term trend and periodicity utilizing stacked 1D di-\nlated convolution and spatial-based graph convolution, respec-\ntively. Besides, a specific strategy for fusing long-term and\nshort term features is also employed for better prediction. Ex-\nperiments on real-world datasets with different prediction hori-\nzons show that the LSTTN model achieves better performance\nthan other baseline models, which implies the e ffectiveness of\nintegrating long-term and short term features to improve the\nprediction accuracy. The conducted ablation experiments verify\nthe validity of each learning module of the LSTTN model, and\nthe visualization of the prediction results show that the LSTTN\nmodel is capable of perceiving upcoming abrupt changes faster\nand provide prediction results regardless of missing data. Those\nresults also corroborate the role of long-term features, namely\nlong-term trend and periodicity can play in traffic forecasting.\nAlthough LSTTN can effectively utilize the temporal infor-\nmation in long historical series and make more accurate pre-\ndictions, there are still some shortcomings that deserve further\nresearch:\n1. The evaluation of LSTTN mainly concerns the prediction\naccuracy, whereas high prediction accuracy alone may\nnot guarantee its practicability. For example, as stated\nearlier, compared with mainstream STGNNs learning short-\nterm features only such as Graph WaveNet, the LSTTN\nmodel requires longer training time and more parame-\nters, which will influence the adoption of LSTTN in real-\nworld scenarios. Besides solution to the additional train-\ning cost, issues like user-friendliness should also be well\nconsidered in the future.\n2. The design of the subseries temporal representation learner,\nthe long-term trend extractor, the periodicity extractor\nand the short-term trend extractor in the LSTTN frame-\nwork and the strategy used to fuse long- and short-term\nfeatures can all be regarded as feasible concrete imple-\nmentations, and other forms of module design and fusion\nstrategies can be further explored. For example, future\nexploration can be done on learning dynamic spatial de-\npendencies for the extraction of periodic features.\n3. Although ablation studies and visualization analysis are\nperformed to improve the transparency and interpretabil-\nity of the performance of the LSTTN model, there is still\ncertain room for improvement.\nCRediT authorship contribution statement\nQinyao Luo: Conceptualization, Methodology, Writing –\noriginal draft, Writing - Review & Editing.Silu He: Data cura-\ntion, Writing – original draft, Writing - Review & Editing.Xing\n13\nTable 4: Execution costs of models on METR-LA under a NVIDIA RTX A6000 GPU\nModel Time complexity Most time-consuming component Training time (s /epoch) Params (M)\nGraph WaveNet O(no2 + ne) Graph adjacency matrix,\nGraph convolution network 19.6 0.99\nMTGNN O(no2 + ne) Graph adjacency matrix,\nGraph convolution network 22.3 1.61\nDSTET O(Ls2ed) Transformer 48.2 0.72\nLSTTN (ours) O(Ls2ed) Transformer 611.6 2.19\n* For each model, its estimated trainig time is the sum of time used to train its each module.\n** The time complexities of graph adjacency matrix and graph convolution network are O(no2) and O(ne2), no is the number of nodes, ne is the\nnumber of edges, Ls denotes the length of input sequence, ed denotes the dimension of embedding.\n*** The time complexity of Transformer is O(Ls2ed), Ls denotes the length of input sequence, ed denotes the dimension of embedding.\nTable 5: Training time analysis of LSTNN model on METR-LA under a NVIDIA RTX A6000 GPU\nModule Percentage of the overall training time\nMasked Sub-series Transformer 96.50%\nLong-term Trend Extractor 1.20%\nPeriodicity Extractor 0.21%\nShort-term Trend Extractor 2.08%\nFeature Fusion 0.01%\nHan: Software, Validation. Xuhan Wang: Data curation, Writ-\ning – original draft. Haifeng Li: Conceptualization, Method-\nology, Writing – original draft, Writing - Review & Editing,\nSupervision, Funding acquisition.\nDeclaration of competing interest\nThe authors declare that they have no known competing fi-\nnancial interests or personal relationships that could have ap-\npeared to influence the work reported in this paper.\nData availability\nData is available at https://github.com/GeoX-Lab/LSTTN.\nAcknowledgement\nThis work was supported by the National Natural Science\nFoundation of China [grant numbers 41871364, 4227148 1],\nand Hunan Provincial Natural Science Foundation of China [grant\nnumber 2022JJ30698].\nReferences\n[1] G. Yu, C. Zhang, Switching arima model based forecasting for traffic flow,\nin: 2004 IEEE International Conference on Acoustics, Speech, and Signal\nProcessing, V ol. 2, IEEE, 2004, pp. ii–429.\n[2] S. R. Chandra, H. Al-Deek, Predictions of freeway tra ffic speeds and vol-\numes using vector autoregressive models, Journal of Intelligent Trans-\nportation Systems 13 (2) (2009) 53–72.\n[3] J. Zhang, Y . Zheng, D. Qi, Deep spatio-temporal residual networks for\ncitywide crowd flows prediction, in: Proceedings of the AAAI conference\non artificial intelligence, V ol. 31, 2017.\n[4] X. Shi, Z. Chen, H. Wang, D.-Y . Yeung, W.-K. Wong, W.-c. Woo, Con-\nvolutional lstm network: A machine learning approach for precipita-\ntion nowcasting, Advances in neural information processing systems 28\n(2015).\n[5] Y . Li, R. Yu, C. Shahabi, Y . Liu, Di ffusion convolutional recur-\nrent neural network: Data-driven tra ffic forecasting, arXiv preprint\narXiv:1707.01926 (2017).\n[6] B. Yu, H. Yin, Z. Zhu, Spatio-temporal graph convolutional net-\nworks: A deep learning framework for tra ffic forecasting, arXiv preprint\narXiv:1709.04875 (2017).\n[7] B. L. Smith, M. J. Demetsky, Tra ffic flow forecasting: comparison\nof modeling approaches, Journal of transportation engineering 123 (4)\n(1997) 261–266.\n[8] J. W. Gao, Z. W. Leng, B. Zhang, X. Liu, G. Q. Cai, The application of\nadaptive kalman filter in traffic flow forecasting, in: Advanced Materials\nResearch, V ol. 680, Trans Tech Publ, 2013, pp. 495–500.\n[9] W. Jiang, J. Luo, Graph neural network for tra ffic forecasting: A survey,\nExpert Systems with Applications (2022) 117921.\n[10] X. Ma, Z. Dai, Z. He, J. Ma, Y . Wang, Y . Wang, Learning tra ffic as im-\nages: A deep convolutional neural network for large-scale transportation\nnetwork speed prediction, Sensors 17 (4) (2017) 818.\n[11] Y . Liu, H. Zheng, X. Feng, Z. Chen, Short-term tra ffic flow prediction\nwith conv-lstm, in: 2017 9th International Conference on Wireless Com-\nmunications and Signal Processing (WCSP), IEEE, 2017, pp. 1–6.\n[12] T. N. Kipf, M. Welling, Variational graph auto-encoders, arXiv preprint\narXiv:1611.07308 (2016).\n[13] M. Zhang, Z. Cui, M. Neumann, Y . Chen, An end-to-end deep learning\narchitecture for graph classification, in: Proceedings of the AAAI confer-\nence on artificial intelligence, V ol. 32, 2018.\n[14] H. Li, J. Cao, J. Zhu, Y . Liu, Q. Zhu, G. Wu, Curvature graph neural\nnetwork, Information Sciences 592 (2022) 50–66.\n[15] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, S. Y . Philip, A comprehensive\nsurvey on graph neural networks, IEEE transactions on neural networks\nand learning systems 32 (1) (2020) 4–24.\n[16] J. Bruna, W. Zaremba, A. Szlam, Y . LeCun, Spectral networks and locally\nconnected networks on graphs, arXiv preprint arXiv:1312.6203 (2013).\n[17] M. De fferrard, X. Bresson, P. Vandergheynst, Convolutional neural net-\nworks on graphs with fast localized spectral filtering, Advances in neural\ninformation processing systems 29 (2016).\n[18] T. N. Kipf, M. Welling, Semi-supervised classification with graph convo-\nlutional networks, arXiv preprint arXiv:1609.02907 (2016).\n[19] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, G. E. Dahl, Neural\nmessage passing for quantum chemistry, in: International conference on\nmachine learning, PMLR, 2017, pp. 1263–1272.\n[20] P. Veli ˇckovi´c, G. Cucurull, A. Casanova, A. Romero, P. Lio, Y . Bengio,\nGraph attention networks, arXiv preprint arXiv:1710.10903 (2017).\n[21] J. Bai, J. Zhu, Y . Song, L. Zhao, Z. Hou, R. Du, H. Li, A3t-gcn: Atten-\n14\nTable 6: A brief comparison of model design\nComponents Learned features\nGraph adjacency matrix Graph convolution network Transformer Short-term trend Periodicity Long-term trend\nGraph WaveNet ! ! % ! % %\nMTGNN ! ! % ! % %\nDSTET ! % ! ! % %\nLSTTN (ours) ! ! ! ! ! !\ntion temporal graph convolutional network for traffic forecasting, ISPRS\nInternational Journal of Geo-Information 10 (7) (2021) 485.\n[22] S. He, Q. Luo, R. Du, L. Zhao, H. Li, Stgc-gnns: A gnn-based tra ffic pre-\ndiction framework with a spatial-temporal granger causality graph, arXiv\npreprint arXiv:2210.16789 (2022).\n[23] L. Cai, K. Janowicz, G. Mai, B. Yan, R. Zhu, Tra ffic transformer: Cap-\nturing the continuity and periodicity of time series for tra ffic forecasting,\nTransactions in GIS 24 (3) (2020) 736–755.\n[24] C. Park, C. Lee, H. Bahng, Y . Tae, S. Jin, K. Kim, S. Ko, J. Choo, St-\ngrat: A novel spatio-temporal graph attention networks for accurately\nforecasting dynamically changing road speed, in: Proceedings of the\n29th ACM international conference on information & knowledge man-\nagement, 2020, pp. 1215–1224.\n[25] A. Roy, K. K. Roy, A. A. Ali, M. A. Amin, A. M. Rahman, Unified spatio-\ntemporal modeling for traffic forecasting using graph neural network, in:\n2021 International Joint Conference on Neural Networks (IJCNN), IEEE,\n2021, pp. 1–8.\n[26] L. Zhao, Y . Song, C. Zhang, Y . Liu, P. Wang, T. Lin, M. Deng, H. Li, T-\ngcn: A temporal graph convolutional network for traffic prediction, IEEE\ntransactions on intelligent transportation systems 21 (9) (2019) 3848–\n3858.\n[27] J. Zhu, Q. Wang, C. Tao, H. Deng, L. Zhao, H. Li, Ast-gcn: Attribute-\naugmented spatiotemporal graph convolutional network for tra ffic fore-\ncasting, IEEE Access 9 (2021) 35973–35983.\n[28] J. Zhu, X. Han, H. Deng, C. Tao, L. Zhao, P. Wang, T. Lin, H. Li, Kst-\ngcn: A knowledge-driven spatial-temporal graph convolutional network\nfor tra ffic forecasting, IEEE Transactions on Intelligent Transportation\nSystems 23 (9) (2022) 15055–15065.\n[29] Z. Wu, S. Pan, G. Long, J. Jiang, C. Zhang, Graph wavenet for\ndeep spatial-temporal graph modeling, arXiv preprint arXiv:1906.00121\n(2019).\n[30] S. Guo, Y . Lin, N. Feng, C. Song, H. Wan, Attention based spatial-\ntemporal graph convolutional networks for tra ffic flow forecasting, in:\nProceedings of the AAAI conference on artificial intelligence, V ol. 33,\n2019, pp. 922–929.\n[31] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, I. Polosukhin, Attention is all you need, Advances in neural\ninformation processing systems 30 (2017).\n[32] M. Xu, W. Dai, C. Liu, X. Gao, W. Lin, G.-J. Qi, H. Xiong, Spatial-\ntemporal transformer networks for traffic flow forecasting, arXiv preprint\narXiv:2001.02908 (2020).\n[33] H. Zhou, S. Zhang, J. Peng, S. Zhang, J. Li, H. Xiong, W. Zhang, In-\nformer: Beyond efficient transformer for long sequence time-series fore-\ncasting, in: Proceedings of the AAAI conference on artificial intelligence,\nV ol. 35, 2021, pp. 11106–11115.\n[34] A. Zeng, M. Chen, L. Zhang, Q. Xu, Are transformers e ffective for time\nseries forecasting?, arXiv preprint arXiv:2205.13504 (2022).\n[35] K. He, X. Chen, S. Xie, Y . Li, P. Doll ´ar, R. Girshick, Masked autoen-\ncoders are scalable vision learners, in: Proceedings of the IEEE /CVF\nConference on Computer Vision and Pattern Recognition, 2022, pp.\n16000–16009.\n[36] D. Chen, Y . Chen, Y . Li, F. Mao, Y . He, H. Xue, Self-supervised learning\nfor few-shot image classification, in: ICASSP 2021-2021 IEEE Interna-\ntional Conference on Acoustics, Speech and Signal Processing (ICASSP),\nIEEE, 2021, pp. 1745–1749.\n[37] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Bert: Pre-training of deep\nbidirectional transformers for language understanding, arXiv preprint\narXiv:1810.04805 (2018).\n[38] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al.,\nLanguage models are unsupervised multitask learners, OpenAI blog 1 (8)\n(2019) 9.\n[39] H. Li, J. Cao, J. Zhu, Q. Luo, S. He, X. Wang, Augmentation-free graph\ncontrastive learning of invariant-discriminative representations, IEEE\nTransactions on Neural Networks and Learning Systems (2023).\n[40] J. Zhu, B. Li, Z. Zhang, L. Zhao, H. Li, High-order topology-enhanced\ngraph convolutional networks for dynamic graphs, Symmetry 14 (10)\n(2022) 2218.\n[41] J. Zhu, M. Hong, R. Du, H. Li, Alleviating neighbor bias: augmenting\ngraph self-supervise learning with structural equivalent positive samples,\narXiv preprint arXiv:2212.04365 (2022).\n[42] X. Liu, Y . Liang, C. Huang, Y . Zheng, B. Hooi, R. Zimmermann, When\ndo contrastive learning signals help spatio-temporal graph forecasting?,\nin: Proceedings of the 30th International Conference on Advances in Ge-\nographic Information Systems, 2022, pp. 1–12.\n[43] J. Ji, J. Wang, C. Huang, J. Wu, B. Xu, Z. Wu, J. Zhang, Y . Zheng,\nSpatio-temporal self-supervised learning for traffic flow prediction, arXiv\npreprint arXiv:2212.04475 (2022).\n[44] Z. Shao, Z. Zhang, F. Wang, Y . Xu, Pre-training enhanced spatial-\ntemporal graph neural network for multivariate time series forecasting,\nin: Proceedings of the 28th ACM SIGKDD Conference on Knowledge\nDiscovery and Data Mining, 2022, pp. 1567–1577.\n[45] Z. Li, Z. Rao, L. Pan, P. Wang, Z. Xu, Ti-mae: Self-supervised masked\ntime series autoencoders, arXiv preprint arXiv:2301.08871 (2023).\n[46] Y . Nie, N. H. Nguyen, P. Sinthong, J. Kalagnanam, A time series is\nworth 64 words: Long-term forecasting with transformers, arXiv preprint\narXiv:2211.14730 (2022).\n[47] F. Yu, V . Koltun, Multi-scale context aggregation by dilated convolutions,\narXiv preprint arXiv:1511.07122 (2015).\n[48] C. Zheng, X. Fan, C. Wang, J. Qi, Gman: A graph multi-attention network\nfor traffic prediction, in: Proceedings of the AAAI conference on artificial\nintelligence, V ol. 34, 2020, pp. 1234–1241.\n[49] Z. Wu, S. Pan, G. Long, J. Jiang, X. Chang, C. Zhang, Connecting the\ndots: Multivariate time series forecasting with graph neural networks,\nin: Proceedings of the 26th ACM SIGKDD international conference on\nknowledge discovery & data mining, 2020, pp. 753–763.\n[50] Y . Sun, X. Jiang, Y . Hu, F. Duan, K. Guo, B. Wang, J. Gao, B. Yin,\nDual dynamic spatial-temporal graph convolution network for traffic pre-\ndiction, IEEE Transactions on Intelligent Transportation Systems 23 (12)\n(2022) 23680–23693.\n[51] Z. Shao, Z. Zhang, F. Wang, W. Wei, Y . Xu, Spatial-temporal identity: A\nsimple yet e ffective baseline for multivariate time series forecasting, in:\nProceedings of the 31st ACM International Conference on Information &\nKnowledge Management, 2022, pp. 4454–4458.\n[52] W. Sun, R. Cheng, Y . Jiao, J. Gao, Z. Zheng, N. Lu, Transformer network\nwith decoupled spatial–temporal embedding for tra ffic flow forecasting,\nApplied Intelligence (2023) 1–21.\n[53] X. Ouyang, Y . Yang, Y . Zhang, W. Zhou, J. Wan, S. Du, Domain adver-\nsarial graph neural network with cross-city graph structure learning for\ntraffic prediction, Knowledge-Based Systems 278 (2023) 110885.\n[54] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,\nT. Killeen, Z. Lin, N. Gimelshein, L. Antiga, et al., Pytorch: An imper-\native style, high-performance deep learning library, Advances in neural\ninformation processing systems 32 (2019).\n[55] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv\npreprint arXiv:1412.6980 (2014).\n[56] J. Wang, J. Jiang, W. Jiang, C. Li, W. X. Zhao, Libcity: An open library\nfor traffic prediction, in: Proceedings of the 29th International Conference\non Advances in Geographic Information Systems, 2021, pp. 145–148.\n15",
  "topic": "Artificial neural network",
  "concepts": [
    {
      "name": "Artificial neural network",
      "score": 0.6319506168365479
    },
    {
      "name": "Term (time)",
      "score": 0.5717229247093201
    },
    {
      "name": "Transformer",
      "score": 0.5468804240226746
    },
    {
      "name": "Computer science",
      "score": 0.4992246627807617
    },
    {
      "name": "Artificial intelligence",
      "score": 0.30441293120384216
    },
    {
      "name": "Engineering",
      "score": 0.18833771347999573
    },
    {
      "name": "Electrical engineering",
      "score": 0.07527759671211243
    },
    {
      "name": "Voltage",
      "score": 0.06380406022071838
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ]
}