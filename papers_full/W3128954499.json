{
  "title": "Comparative Analysis of Transformer based Language Models",
  "url": "https://openalex.org/W3128954499",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2647751307",
      "name": "Aman Pathak",
      "affiliations": [
        "Medi-Caps University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6676297131",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W1544827683",
    "https://openalex.org/W2799079108",
    "https://openalex.org/W2804897457",
    "https://openalex.org/W2130158090",
    "https://openalex.org/W2963846996",
    "https://openalex.org/W2964086597",
    "https://openalex.org/W2606964149",
    "https://openalex.org/W4288548690",
    "https://openalex.org/W3104033643",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2950613642",
    "https://openalex.org/W2914120296",
    "https://openalex.org/W2978670439",
    "https://openalex.org/W2888302696",
    "https://openalex.org/W4320013936",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2951831170",
    "https://openalex.org/W2964110616",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2963748441",
    "https://openalex.org/W2943552823",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2099471712",
    "https://openalex.org/W3034715004",
    "https://openalex.org/W2108598243",
    "https://openalex.org/W2949615363",
    "https://openalex.org/W2270070752",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2963310665",
    "https://openalex.org/W4287824654",
    "https://openalex.org/W4313908941",
    "https://openalex.org/W3034850762",
    "https://openalex.org/W2963457723",
    "https://openalex.org/W2996264288",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W2889326796",
    "https://openalex.org/W2965373594"
  ],
  "abstract": "Natural language processing (NLP) has witnessed many substantial advancements in the past three years. With the introduction of the Transformer and self-attention mechanism, language models are now able to learn better representations of the natural language. These attentionbased models have achieved exceptional state-of-the-art results on various NLP benchmarks. One of the contributing factors is the growing use of transfer learning. Models are pre-trained on unsupervised objectives using rich datasets that develop fundamental natural language abilities that are fine-tuned further on supervised data for downstream tasks. Surprisingly, current researches have led to a novel era of powerful models that no longer require finetuning. The objective of this paper is to present a comparative analysis of some of the most influential language models. The benchmarks of the study are problem-solving methodologies, model architecture, compute power, standard NLP benchmark accuracies and shortcomings.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8331402540206909
    },
    {
      "name": "Transformer",
      "score": 0.736264705657959
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6978464126586914
    },
    {
      "name": "Language model",
      "score": 0.6348636746406555
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5853363275527954
    },
    {
      "name": "Natural language processing",
      "score": 0.5613287091255188
    },
    {
      "name": "Natural language",
      "score": 0.5564584136009216
    },
    {
      "name": "Machine learning",
      "score": 0.4407294690608978
    },
    {
      "name": "Architecture",
      "score": 0.42178231477737427
    },
    {
      "name": "Natural language understanding",
      "score": 0.4106118083000183
    },
    {
      "name": "Engineering",
      "score": 0.09158128499984741
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Art",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Visual arts",
      "score": 0.0
    }
  ]
}