{
  "title": "Evaluating and Enhancing Japanese Large Language Models for Genetic Counseling Support: Comparative Study of Domain Adaptation and the Development of an Expert-Evaluated Dataset",
  "url": "https://openalex.org/W4405775523",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2138833460",
      "name": "Takuya Fukushima",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3178251112",
      "name": "Masae Manabe",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2341502382",
      "name": "Shuntaro Yada",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2141474645",
      "name": "Shoko Wakamiya",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1969170634",
      "name": "Akiko Yoshida",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2955730999",
      "name": "Yusaku Urakawa",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2108939674",
      "name": "Akiko Maeda",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2148787822",
      "name": "Shigeyuki Kan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098938303",
      "name": "Masayo Takahashi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A220970269",
      "name": "Eiji Aramaki",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4368372302",
    "https://openalex.org/W3123768925",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4380685958",
    "https://openalex.org/W4362511131",
    "https://openalex.org/W4389379994",
    "https://openalex.org/W4387305434",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4377009978",
    "https://openalex.org/W4387724712",
    "https://openalex.org/W4399990891",
    "https://openalex.org/W4385571886",
    "https://openalex.org/W4396822552"
  ],
  "abstract": "Background Advances in genetics have underscored a strong association between genetic factors and health outcomes, leading to an increased demand for genetic counseling services. However, a shortage of qualified genetic counselors poses a significant challenge. Large language models (LLMs) have emerged as a potential solution for augmenting support in genetic counseling tasks. Despite the potential, Japanese genetic counseling LLMs (JGCLLMs) are underexplored. To advance a JGCLLM-based dialogue system for genetic counseling, effective domain adaptation methods require investigation. Objective This study aims to evaluate the current capabilities and identify challenges in developing a JGCLLM-based dialogue system for genetic counseling. The primary focus is to assess the effectiveness of prompt engineering, retrieval-augmented generation (RAG), and instruction tuning within the context of genetic counseling. Furthermore, we will establish an experts-evaluated dataset of responses generated by LLMs adapted to Japanese genetic counseling for the future development of JGCLLMs. Methods Two primary datasets were used in this study: (1) a question-answer (QA) dataset for LLM adaptation and (2) a genetic counseling question dataset for evaluation. The QA dataset included 899 QA pairs covering medical and genetic counseling topics, while the evaluation dataset contained 120 curated questions across 6 genetic counseling categories. Three enhancement techniques of LLMs—instruction tuning, RAG, and prompt engineering—were applied to a lightweight Japanese LLM to enhance its ability for genetic counseling. The performance of the adapted LLM was evaluated on the 120-question dataset by 2 certified genetic counselors and 1 ophthalmologist (SK, YU, and AY). Evaluation focused on four metrics: (1) inappropriateness of information, (2) sufficiency of information, (3) severity of harm, and (4) alignment with medical consensus. Results The evaluation by certified genetic counselors and an ophthalmologist revealed varied outcomes across different methods. RAG showed potential, particularly in enhancing critical aspects of genetic counseling. In contrast, instruction tuning and prompt engineering produced less favorable outcomes. This evaluation process facilitated the creation an expert-evaluated dataset of responses generated by LLMs adapted with different combinations of these methods. Error analysis identified key ethical concerns, including inappropriate promotion of prenatal testing, criticism of relatives, and inaccurate probability statements. Conclusions RAG demonstrated notable improvements across all evaluation metrics, suggesting potential for further enhancement through the expansion of RAG data. The expert-evaluated dataset developed in this study provides valuable insights for future optimization efforts. However, the ethical issues observed in JGCLLM responses underscore the critical need for ongoing refinement and thorough ethical evaluation before these systems can be implemented in health care settings.",
  "full_text": null,
  "topic": "Preprint",
  "concepts": [
    {
      "name": "Preprint",
      "score": 0.659315824508667
    },
    {
      "name": "Adaptation (eye)",
      "score": 0.5588939189910889
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.5088560581207275
    },
    {
      "name": "Computer science",
      "score": 0.3931695222854614
    },
    {
      "name": "Psychology",
      "score": 0.35213977098464966
    },
    {
      "name": "World Wide Web",
      "score": 0.18531301617622375
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    }
  ]
}