{
  "title": "Large Language Models and Generative AI, Oh My!",
  "url": "https://openalex.org/W4392502414",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A357521830",
      "name": "Michael Zyda",
      "affiliations": [
        "University of Southern California"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4382931408"
  ],
  "abstract": "Artificial intelligence (AI) has a miserable reputation regarding promises made and results delivered. Last century, there were many AI winters. The hype surrounding large language models and generative AI could join this trend, we do not hope.",
  "full_text": "INTRODUCTION\nArtificial intelligence (AI) winters are periods of low to no \nfunding by government agencies and the venture com -\nmunity. AI winters usually come when grand promises \nare made by researchers and startup founders to inter -\nest government funding agencies and investors. Grand \npromises are made, funding is pro -\nvided, and results delivered are less \nthan stellar. New funding and in -\nterest dry up and blow away. Rinse \nand repeat at a later date. Figure 1  \nshows the various failures that led to  \nAI winters in the last third of last \ncentury. That material is from Wiki -\npedia1 and redrawn here for your \nedification. The source 1 provides the \nright amount of detail should you \nneed more.\nTHE AI HYPE CYCLE\nThe AI hype cycle is shown in  \nFigure 2. It starts with hype, which is defined as extrav -\nagant or intensive publicity or promotion, according \nto the online Oxford Languages dictionary. In our case, \nwith respect to AI, this starts with big researcher prom -\nises followed by press amplification of those promises. \nFrom industry, this all started with hiring people with \nthe title “Evangelist,” which was the warning sign to us \nall that something was not quite right. Out of this, the \nAI hype cycle has historically ended with unrealistic \nDigital Object Identifier 10.1109/MC.2024.3350290\nDate of current version: 1 March 2024\nLarge Language \nModels and \nGenerative AI, Oh My!\nMichael Zyda  , University of Southern California\nArtificial intelligence (AI) has a miserable \nreputation regarding promises made and \nresults delivered. Last century, there were \nmany AI winters. The hype surrounding large \nlanguage models and generative AI could join \nthis trend, we do not hope. \nGAMES\nEDITOR MICHAEL ZYDA\nUniversity of Southern California;  \nzyda@mikezyda.com\nCOMPUTER  0018-9162/24©2024IEEE  PUBLISHED BY THE IEEE COMPUTER SOCIETY   MARCH 2024 127\n128 COMPUTER    WWW.COMPUTER.ORG/COMPUTER\nGAMES\nexpectations being held and dis -\nappointments to funders (research \nsponsors, venture capitalists, and \ncorporate investments), with all of \nthis resulting in funding cuts and \nresearchers and investors abandon -\ning the area. So, all of us on the side -\nlines are wondering, is there a large \nlanguage model (LLM) or generative \nAI winter roaring toward us, or is \nsomething useful going to come out \nof all the noise?\nWHAT ARE LLMS?\n“Large language models (LLMs) are \ndeep learning models that are pre -\ntrained on massive sets of data, some \nas large as 50 billion web pages. A core \npart of the LLM is a transformer model. \nA transformer model is a set of neural \nnetworks that consist of an encoder \nand decoder with self-attention capa -\nbilities, meaning the models are capa -\nble of unsupervised training from the \nFIGURE 1. Early examples of periods of AI winters. 1\nFIGURE 2. The hype cycle.\n\n MARCH 2024 129\ndata fed them. The transformer models \nlearn to understand the sentence, para -\ngraph, and complete article of the data \npresented. Transformers process entire \nsequences of data in parallel, meaning \ntheir computation can be performed on \na GPU (graphics processing unit) dra -\nmatically reducing the training time \nfor the LLM.” 2,3,4 Note that the above \nparagraph is a rewrite and compression \nof the cited sources.2,3,4\nWHAT IS GENERATIVE AI?\nFully pretrained LLMs are called foun -\ndation models. Foundation models can \nthen be specialized (built on top of) to \ncreate generative AI applications, ap -\nplications that can generate new text, \nnew images, new audio, language \ninterpretations, and other new syn -\nthetic items. 5 The generative AI appli -\ncations, usually shortened to just gen -\nerative AI, that people have been most \nexcited about are ChatGPT, DALL-E, \nand Midjourney.\nChatGPT lets you provide it text, and \nit will give you new text in response. For \nFIGURE 3. A turkey at the beach in Carmel by the Sea.\nFIGURE 4. A turkey cooking dinner.\nFIGURE 5. A turkey playing the accordion.\nFIGURE 6. A turkey wearing a Mickey Mouse hat.\n\n130 CO MPUTER    WWW.COMPUTER.ORG/COMPUTER\nGAMES\nexample, almost all my friends that tried \nChatGPT 3.5 first asked it to write their \npersonal biography . When I did this, it \nwas sort of accurate but had me dead at \nthe end of the written bio. There were \nseveral mistakes in the bio, and there \nis no way anyone could ever really use \nthe generated text. This changed with \nChatGPT 4.0, and I did the same test and \ngot a reasonably excellent generated bio \nback: I only modified one sentence, and \nthat was more for style than anything \nfactual. In a previous “Games” column,\n6 \nI tried to hand ChatGPT 3.5 a full screen-\nplay , which it rejected, and had to settle \nfor just a single scene from my favorite \nnoir film, The Long Goodbye. ChatGPT \n3.5 gave me a new scene that seemed \npretty reasonable for a scene in a noir \nfilm not yet made, but I did not provide \nChatGPT 3.5 any guidance as to how that \nscene fit into the larger story of the com-\nplete future film.\nDALL-E\n7 and Midjourney 8 let you \nprovide their generative AI applica-\ntions text that describes an image \nyou would like created. I haven’t tried \nFIGURE 7. A turkey wearing a space helmet.\nFIGURE 8. A turkey wearing a tool belt.\nFIGURE 9. A turkey wearing running shoes.\nFIGURE 10. A turkey working in a bank.\n\n M ARCH 2024  131\nDALL-E, but I have spent a lot of time \nplaying with Midjourney . Let’s talk about \nthat experience in the next section.\nA MIDJOURNEY \nTHANKSGIVING\nOne of the things to know about me \nis that when my wife decides to have \na large dinner party, I get tasked with \ncreating place cards for each person \nattending. I personalize these cards \nwith respect to each person and with \nrespect to the chosen theme for the \ndinner party. This year’s theme was \n“A Midjourney Thanksgiving.” Here is \nmy list of very short texts provided \nto Midjourney:\n › a t\nurkey at the beach in Carmel \nby the Sea\n › a t\nurkey cooking dinner\n › a t\nurkey playing an accordion\n › a t\nurkey wearing a Mickey \nMouse hat\n › a t\nurkey wearing a space helmet\n › a t\nurkey wearing a tool belt\n › a t\nurkey with running shoes\n › a t\nurkey working in a bank\n › h\nappy Thanksgiving turkey \napocalypse.\nThe pictures Midjourney created \nare shown in Figures 3 –11. \nSo, this is the artwork for each place \ncard, and I would paste that onto a \ncard individualized with the name of \neach person using Photoshop. So, we \nare just talking about Midjourney, so \nthe individuals are not that important \nexcept that the topic chosen for each \nimage was turkey plus something to \ndo with their occupation or life. I did \nnot tell Midjourney to use a particular \nart style, yet it seemed to create each of \nthese with a similar style! Midjourney \ndid not provide me a reference or credit \nfor that art style.\nNow , we know that Midjourney’s \nfoundation model was trained by scrap-\ning imagery and text off of the Internet. \nAnd I did “ a turkey wearing a Mickey \nMouse hat” test to see if it would give \nme an image that would make Disney \nhappy , and the turkey pics seem OK, but \nit gave me two Donald Duck pics: Don-\nald Duck is a cartoon character created \nby the Walt Disney Company! So, we \nhave failed the Walt Disney test. How \ncan we use generative AI without some \nway of assuring us and our attorneys \nthat we are not going to get sued for \ncopyright infringement? This is already \nan issue as the New York Times sues Mi-\ncrosoft and ChatGPT maker OpenAI.\n9 \nApple is taking a different path with ex-\nploring AI training data licensing with a \nvariety of news publishers.\n10\nSo, what maybe really needs to \nbe done is the user of a particular \ngenerative AI architecture doesn’t \njust use a training set built by scrap -\ning the Internet but rather is provided \na tool that can scrape the internal art \narchives of the particular client. This \nmeans if Walt Disney wants to use \ngenerative AI to create new characters, \nthen the training set built for the gener-\native AI tool is made by scraping the art \narchives of Disney’s internal historical \nart productions instead of the Internet. \nI am not sure that is an option offered \nby anyone right now but maybe soon \nas issues of trademark and copyright \nbecome familiar to the tech industry.\nFIGURE 11. Happy Thanksgiving turkey apocalypse.\nOnce we have all of the copyright and trademark \nissues resolved for generative AI, there is then \nthe potential for a bright future in entertainment, \nespecially for the games and film industries.\n132 CO MPUTER    WWW.COMPUTER.ORG/COMPUTER\nGAMES\nGENERATIVE AI AND THE \nGAMES INDUSTRY\nOnce we have all of the copyright and \ntrademark issues resolved for gener -\native AI, there is then the potential \nfor a bright future in entertainment, \nespecially for the games and film \nindustries. In the games and enter -\ntainment industry, there is always \na demand for concept art, and the \ntechnology embedded in generative \nAI looks quite interesting for rap -\nidly producing concepts in near-real \ntime while the development crew is \nstill sitting around the discussion \ntable. With respect to things beyond \n2D concepts, there are generative AI \nstartups focused on creating 3D as -\nsets and worlds rapidly.\n11 Generative \nAI has a great future for game char -\nacters and nonplayer characters as \nwell.\n11 We will see.\nEVERYONE WANTS TO \nINVEST IN A GENERATIVE  \nAI SUPERSTAR STARTUP\nThe number of friends of mine that have \nasked if I know anyone at Anthropic is \nquite large. Everyone seems to want \nto invest in a generative AI startup, \nand the word on the street is that is the \none. Who knows? There is a large list of \ngenerative AI startups here.\n11 If some \nof the fundamental issues of copyright \nand trademark can be rectified, then \nmaybe some of these startups will sail \npast the culling soon to come. And \nmaybe, if all the beans line up, we will \nmostly miss another AI winter…\nACKNOWLEDGMENT\nI acknowledge the contributions of my \nmany friends in the games and com -\nputing industries, especially those \nwho have been in AI since near the \nbeginning…\nREFERENCES\n1. “ AI winter.” Wikipedia. Accessed: \nDec. 25, 2023. [Online]. Available: \nhttps:/ /en.wikipedia.org/wiki/\nAI_winter\n2.\n “\nWhat are large language models \n(LLM)?” Amazon. Accessed: Dec. \n28, 2023. [Online]. Available: \nhttps://aws.amazon.com/what-is/\nlarge-language-model/#:~:text  \n=Large%20language%20models%  \n20(LLM)%20are,decoder%20\nwith%20self%2Dattention%20\ncapabilities\n3.\n “\nGenerative AI exists because of the \ntransformer,” Financial Times, Sep. \n2023. Accessed: Dec. 28, 2023. [On-\nline]. Available: https:/ /ig.ft.com/\ngenerative-ai/#:~:text=Transformers  \n%20process%20an%20entire%20\nsequence,or%20generate%20—%20\ntext%20more%20accurately \n4.\n J\n. Uszkoreit. “Transformer: A novel \nneural network architecture for \nlanguage understanding.” Google \nResearch Blog. Accessed: Dec. 28, \n2023. [Online]. Available: https://\nblog.research.google/2017 /08/\ntransformer-novel-neural-network.\nhtml\n5.\n “\nGenerative AI.” Accenture. Ac-\ncessed: Dec. 28. 2023. [Online]. \nAvailable: https:/ /www.accenture.\ncom/us-en/insights/generative-ai?  \nc=acn_glb_generativeai-lagoogle  \n_13770004&n=psgs_0623&gclid=  \nCj0KCQiA1rSsBhDHARIsANB4EJZ  \ncm1xXZdUjHrcieDnW12YlXwu94k  \n_Veg_fuGeOXLrDiH1z6_LzwwIa  \nAnJIEALw_wcB&gclsrc=aw.ds\n6.\n M\n. Zyda, “Hubris—From the \nmetaverse to ChatGPT to TikTok’s time \nof tribulation,” Computer, vol. 56, no. \n7, pp. 131–136, Jul. 2023, doi: 10.1109/\nMC.2023.3267986.\n7.\n “\nDALL-E.” OpenAI. Accessed: Dec. 28,  \n2023. [Online]. Available: https://\nopenai.com \n8.\n M\nidjourney. Accessed: Dec. 28,  \n2023. [Online]. Available: https:// \nmidjourney.com \n9. R\n. Browne, “New York Times Sues \nMicrosoft, ChatGPT maker OpenAI \nover copyright infringement,” CNBC, \nDec. 2023. Accessed: Dec. 28, 2023. \n[Online]. Available: https:/ /www.cnbc.\ncom/2023/12/27 /new-york-times \n-sues-microsoft-chatgpt-maker \n-openai-over-copyright-infringement.\nhtml?__source=sharebar%7Cfacebook \n&par=sharebar&fbclid=IwAR2mn-\nMxwwNWP02xPsFZ1BEqmfGCx  \nFC0tfJzGlj1_SIMy1fdOF96qbussy1I \n10.\n B\n. Mullin and T. Mickle, “Apple ex-\nplores A.I. deals with news publish-\ners,” NY Times, Dec. 2023. Accessed: \nDec. 28, 2023. [Online]. Available: \nhttps://www.nytimes.com/  \n2023/12/22/technology/\napple-ai-news-publishers.html \n11.\n “\nGenerative AI startups.” Dealroom.\nco. Accessed: Dec. 28, 2023. [Online]. \nAvailable: https:/ /app.dealroom.co/\nlists/33530\nCOMMENTS?\nI\nf you have comments about this \narticle, or topics or references I \nshould have cited or you want to \nrant back to me on why what I say \nis nonsense, I want to hear. Every \ntime we finish one of these col-\numns, and it goes to print, what \nI’m going to do is get it up online \nand maybe point to it at my Face-\nbook (mikezyda) and my LinkedIn \n(mikezyda) pages so that I can re-\nceive comments from you. Maybe \nwe’ll react to some of those com-\nments in future columns or online \nto enlighten you in real time! This \nis the “Games” column. You have \na wonderful day.\nMICHAEL ZYDA is the founding \ndirector of the Computer Science \nGames Program and a professor \nemeritus of engineering practice in \nthe Department of Computer Science, \nUniversity of Southern California, Los \nAngeles, CA 90089 USA. Contact \nhim at zyda@mikezyda.com.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8326501846313477
    },
    {
      "name": "Generative grammar",
      "score": 0.5703105330467224
    },
    {
      "name": "Programming language",
      "score": 0.4471724331378937
    },
    {
      "name": "Artificial intelligence",
      "score": 0.43871286511421204
    },
    {
      "name": "Natural language processing",
      "score": 0.4119020998477936
    },
    {
      "name": "Software engineering",
      "score": 0.38916221261024475
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1174212",
      "name": "University of Southern California",
      "country": "US"
    }
  ]
}