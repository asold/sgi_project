{
    "title": "Streamlining Systematic Reviews: Harnessing Large Language Models for Quality Assessment and Risk-of-Bias Evaluation",
    "url": "https://openalex.org/W4385614921",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2113436608",
            "name": "Abdulqadir J Nashwan",
            "affiliations": [
                "Hamad Medical Corporation",
                "Mutah University"
            ]
        },
        {
            "id": "https://openalex.org/A5092265198",
            "name": "Jaber H. Jaradat",
            "affiliations": [
                "Hamad Medical Corporation"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W1964172790",
        "https://openalex.org/W4376866715",
        "https://openalex.org/W3119142291",
        "https://openalex.org/W4296330923",
        "https://openalex.org/W4377197101"
    ],
    "abstract": "This editorial explores the innovative application of large language Models (LLMs) in conducting systematic reviews, specifically focusing on quality assessment and risk-of-bias evaluation. As integral components of systematic reviews, these tasks traditionally require extensive human effort, subjectivity, and time. Integrating LLMs can revolutionize this process, providing an objective, consistent, and rapid methodology for quality assessment and risk-of-bias evaluation. With their ability to comprehend context, predict semantic relationships, and extract relevant information, LLMs can effectively appraise study quality and risk of bias. However, careful consideration must be given to potential risks and limitations associated with over-reliance on machine learning models and inherent biases in training data. An optimal balance and combination between human expertise and automated LLM evaluation might offer the most effective approach to advance and streamline the field of evidence synthesis.",
    "full_text": "Review began\n 08/01/2023 \nReview ended\n 08/04/2023 \nPublished\n 08/06/2023\nÂ© Copyright \n2023\nNashwan et al. This is an open access\narticle distributed under the terms of the\nCreative Commons Attribution License CC-\nBY 4.0., which permits unrestricted use,\ndistribution, and reproduction in any\nmedium, provided the original author and\nsource are credited.\nStreamlining Systematic Reviews: Harnessing\nLarge Language Models for Quality Assessment\nand Risk-of-Bias Evaluation\nAbdulqadir \nJ. Nashwan \n \n, \nJaber \nH. Jaradat \n1.\n Nursing Department, Hamad Medical Corporation, Doha, QAT \n2.\n School of Medicine, Mutah University, Al Karak, JOR\nCorresponding author: \nAbdulqadir \nJ. Nashwan, \nanashwan@hamad.qa\nAbstract\nThis editorial explores the innovative application of large language Models (LLMs) in conducting systematic\nreviews, specifically focusing on quality assessment and risk-of-bias evaluation. As integral components of\nsystematic reviews, these tasks traditionally require extensive human effort, subjectivity, and time.\nIntegrating LLMs can revolutionize this process, providing an objective, consistent, and rapid methodology\nfor quality assessment and risk-of-bias evaluation. With their ability to comprehend context, predict\nsemantic relationships, and extract relevant information, LLMs can effectively appraise study quality and\nrisk of bias. However, careful consideration must be given to potential risks and limitations associated with\nover-reliance on machine learning models and inherent biases in training data. An optimal balance and\ncombination between human expertise and automated LLM evaluation might offer the most effective\napproach to advance and streamline the field of evidence synthesis.\nCategories:\n Healthcare Technology, Epidemiology/Public Health\nKeywords:\n evidence synthesis, machine learning, artificial intelligence, large language models, risk of bias, quality\nassessment, systematic reviews\nEditorial\nLarge language models (LLMs) present a groundbreaking opportunity to revolutionize the process of\nconducting systematic reviews, particularly in quality assessment (QA) and risk-of-bias (ROB) appraisal.\nThis lies in the potential of LLMs to automate the inherently labor-intensive and often subjective process of\nthese tasks that may lead to inconsistencies among different assessors.\nSystematic reviews conduct rigorous and comprehensive assessments of existing literature on a particular\nmedical topic \n[1]\n. They are an essential part of evidence-based medicine and involve several stages, of which\nthe QA of included studies or the appraisal of ROB is a critical stage to ensure the credibility of the review.\nThese reviews critically analyzed the available evidence, identified potential biases or shortcomings in\nindividual studies, and synthesized the findings \n[1]\n.\nLLMs are advanced artificial intelligence (AI) models, such as Generative Pre-trained Transformer 4 (GPT-4),\nDALL-E, Segment Anything Model (SAM), Large Language Model Meta AI (LLaMA), Language Model for\nDialogue Applications (LaMDA), Vision Transformer, etc., capable of automating various tasks in natural\nlanguage processing, computer vision, etc. GPT-4 is the latest GPT model incorporated in ChatGPT, which is\na multimodal foundation model that excels in generating human-like text and can process text and image\ninputs and beyond \n[2]\n. LLMs are trained on extensive text data, enabling them to understand context,\npredict semantic relationships, and extract relevant information from diverse datasets \n[2]\n. Consequently,\nLLMs can be effectively harnessed to automatically assess the quality of the included studies in a systematic\nreview, streamlining the process and reducing the subjectivity associated with human\nindependent assessors.\nAlthough QA and ROB assessments are considered similar safeguard elements and are sometimes used\ninterchangeably by researchers, their applications and interpretations differ. QA evaluates methodological\nsafeguards within a study to ensure it is well-designed, conducted, analyzed, interpreted, and reported,\nthereby minimizing systematic errors or bias. Conversely, the ROB assessment, also known as critical\nappraisal, aims to understand how these safeguards may influence the study results, involving judgments\nabout the level of bias and delving deeper into the implications of methodological safeguards on the study's\noutcomes. QA entails counting the safeguards present as numerical assessment, whereas a ROB assessment\nemploys an approach to rank studies based on potential bias into low or high-risk studies \n[3,4]\n. There are\nnumerous tools to assess QA and ROB; they differ according to the study design, such as the Joanna Briggs\nInstitute (JBI), Assessing the Methodological Quality of Systematic Reviews (AMSTAR), Critical Appraisal\nSkills Program (CASP), Cochrane Risk of Bias (ROB 1 and 2) tool, Risk Of Bias In Non-randomized Studies -\nof Interventions (ROBINS-I) tool, the Newcastle-Ottawa Scale (NOS), etc. \n[4]\n.\n1\n2\n \n Open Access\nEditorial\n \nDOI:\n 10.7759/cureus.43023\nHow to cite this article\nNashwan A J, Jaradat J H (August 06, 2023) Streamlining Systematic Reviews: Harnessing Large Language Models for Quality Assessment and\nRisk-of-Bias Evaluation. Cureus 15(8): e43023. \nDOI 10.7759/cureus.43023\nLLMs can be trained to identify common sources of bias, such as selection, performance, detection, attrition,\nand reporting, by recognizing specific phrases, language patterns, or missing information; the LLM can\nassign a risk level of bias to each study. This objective, automated assessment can minimize human\nassessors' subjectivity, enhance the systematic review's reliability and capture nuances that may otherwise\nhave been overlooked \n[5]\n. The use of LLMs not only improves the efficiency and consistency of QA and ROB\nevaluations but also expedites the overall systematic review process. By eliminating the need for manual\nappraisal, LLMs enable faster evidence synthesis and knowledge dissemination, crucial in developing\nclinical guidelines and public health emergencies (e.g., pandemics), where timely access to highly-quality\nsynthesized evidence is crucial. However, using LLMs holds many potential risks, limitations, and\nchallenges. Overreliance on LLMs may weaken critical thinking skills in researchers. Risks associated with\ninherent biases in the training data of LLMs might influence the assessment outcomes \n[2,5]\n. Therefore,\ncombining human expertise and automated LLM evaluation might offer the best approach, ensuring both the\nefficiency of automation and the nuanced understanding of human assessors.\nIn conclusion, harnessing LLMs in conducting quality assessments and the risk of bias in systematic reviews\ncan be transformative. With proper caution to ensure appropriate use and mitigate potential risks,\nefficiency, consistency, and objectivity benefits can significantly advance the evidence synthesis field.\nAdditional Information\nDisclosures\nConflicts of interest:\n In compliance with the ICMJE uniform disclosure form, all authors declare the\nfollowing: \nPayment/services info:\n All authors have declared that no financial support was received from\nany organization for the submitted work. \nFinancial relationships:\n All authors have declared that they have\nno financial relationships at present or within the previous three years with any organizations that might\nhave an interest in the submitted work. \nOther relationships:\n All authors have declared that there are no\nother relationships or activities that could appear to have influenced the submitted work.\nReferences\n1\n. \nBurns PB, Rohrich RJ, Chung KC: \nThe levels of evidence and their role in evidence-based medicine\n. Plast\nReconstr Surg. 2011, 128:305-10. \n10.1097/PRS.0b013e318219c171\n2\n. \nAbd-Alrazaq A, AlSaad R, Alhuwail D, et al.: \nLarge language models in medical education: opportunities,\nchallenges, and future directions\n. JMIR Med Educ. 2023, 9:e48291. \n10.2196/48291\n3\n. \nFuruya-Kanamori L, Xu C, Hasan SS, Doi SA: \nQuality versus risk-of-bias assessment in clinical research\n. J\nClin Epidemiol. 2021, 129:172-5. \n10.1016/j.jclinepi.2020.09.044\n4\n. \nBarker TH, Stone JC, Sears K, et al.: \nRevising the JBI quantitative critical appraisal tools to improve their\napplicability: an overview of methods and the development process\n. JBI Evid Synth. 2023, 21:478-93.\n10.11124/JBIES-22-00125\n5\n. \nKarabacak M, Margetis K: \nEmbracing large language models for medical applications: opportunities and\nchallenges\n. Cureus. 2023, 15:e39305. \n10.7759/cureus.39305\n2023 Nashwan et al. Cureus 15(8): e43023. DOI 10.7759/cureus.43023\n2\n of \n2"
}