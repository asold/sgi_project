{
  "title": "Compositional Language Modeling for Icon-Based Augmentative and Alternative Communication",
  "url": "https://openalex.org/W2955925702",
  "year": 2018,
  "authors": [
    {
      "id": "https://openalex.org/A5008165079",
      "name": "Shiran Dudy",
      "affiliations": [
        "Oregon Health & Science University"
      ]
    },
    {
      "id": "https://openalex.org/A5044068445",
      "name": "Steven Bedrick",
      "affiliations": [
        "Oregon Health & Science University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2507974895",
    "https://openalex.org/W2078783730",
    "https://openalex.org/W1533916863",
    "https://openalex.org/W1997161938",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W4252489443",
    "https://openalex.org/W1486649854",
    "https://openalex.org/W2071826481",
    "https://openalex.org/W433714084",
    "https://openalex.org/W2110228239",
    "https://openalex.org/W2132845931",
    "https://openalex.org/W3099138433",
    "https://openalex.org/W2077538051",
    "https://openalex.org/W1562493387",
    "https://openalex.org/W2150251308",
    "https://openalex.org/W2119489362"
  ],
  "abstract": "Icon-based communication systems are widely used in the field of Augmentative and Alternative Communication. Typically, icon-based systems have lagged behind word- and character-based systems in terms of predictive typing functionality, due to the challenges inherent to training icon-based language models. We propose a method for synthesizing training data for use in icon-based language models, and explore two different modeling strategies.",
  "full_text": "Proceedings of the Workshop on Deep Learning Approaches for Low-Resource NLP, pages 25–32\nMelbourne, Australia July 19, 2018.c⃝2018 Association for Computational Linguistics\n25\nCompositional Language Modeling for Icon-Based Augmentative and\nAlternative Communication\nShiran Dudy Steven Bedrick\nCenter for Spoken Language Understanding\nOregon Health & Science University\n3181 S.W. Sam Jackson Park Rd.\nPortland, Oregon, USA\n{dudy,bedricks}@ohsu.edu\nAbstract\nIcon-based communication systems are\nwidely used in the ﬁeld of Augmentative\nand Alternative Communication. Typi-\ncally, icon-based systems have lagged be-\nhind word- and character-based systems\nin terms of predictive typing functionality,\ndue to the challenges inherent to training\nicon-based language models. We propose\na method for synthesizing training data for\nuse in icon-based language models, and\nexplore two different modeling strategies.\n1 Introduction\nIndividuals who experience speech and language\nimpairments often are helped by Augmenta-\ntive and Alternative Communication (AAC) tech-\nniques that facilitate the expression or compre-\nhension of spoken or written language (Beukel-\nman and Mirenda, 2005; American Speech Lan-\nguage Hearing Association et al., 2004; Fossett\nand Mirenda, 2007). Impairments may result from\ndevelopmental disorders affecting speech and lan-\nguage (Cerebral Palsy, Down Syndrome, some\nforms of Autism Spectrum Disorder, etc.), or they\nmay be caused by injury (stroke, traumatic brain\ninjury, neurodegenerative diseases such as ALS,\netc.). AAC interventions can take many forms,\nbut a common goal is to provide users with a way\nto select symbols (words, phrases, etc.) for pur-\nposes of communication. The ﬁeld of AAC groups\ninterventions into \"low-technology\" (i.e., printed)\nor \"high-technology\" (i.e., computerized) devices;\nboth are commonly used, and there are a number\nof factors that go in to the decision of which de-\nvice to use (Iacono et al., 2011; Light and Drager,\n2007). In some cases, devices produce speech\n(or written language) based on those selections,\nwhereas in other cases, the goal of the device is\nto support a user in producing their own speech.\nIn some cases, the unit of selection may be\nicon-based rather than word- or character-based.\nThis is particularly common in devices used by\nchildren or individuals with impaired literacy, but\nis also common in adult use. Icon-based sys-\ntems can have higher selection speeds, and can be\neasier for individuals with neuromuscular impair-\nments to operate; there are a wide variety of sym-\nbol sets and symbol-based communication sys-\ntems used (Patel, 2011).\nComputerized text-based AAC devices often\ninclude some form of word prediction using\na language model (see (Vertanen and Kristens-\nson, 2011; Garay-Vitoria and Abascal, 2006) for\noverviews of this area). Icon-based systems often\ndo not employ predictive features. 1 In part, this\nis because they typically rely on direct-selection\nor other input modalities; another barrier, is a lack\nof relevant linguistic training data. To our knowl-\nedge, there are no corpora of language produced\nusing icon-based AAC systems.\nIn the present work, we apply modern lan-\nguage modeling techniques to a large-vocabulary\nicon set commonly used in AAC applications, but\nfor which we have no in-domain (or even in-\nvocabulary) training data. We are building our\nmodel as support for a brain-computer interface\n(Orhan et al., 2012). In this input modality, the\nuser has very limited control over item selection,\nmaking accurate language modeling critical.\nWe propose a method to generate language\nmodels and evaluate their performance by experi-\nmenting with a process to generate a trainable lan-\nguage modeling corpus. We also share an experi-\n1One notable exception to this trend is the system used in\nSymbolPath (Wiegand and Patel, 2012b), which uses seman-\ntic frames to attempt non-sequential symbol prediction (Wie-\ngand and Patel, 2012a). This work, however, was limited to a\nspeciﬁc and small icon set.\n26\nmental setup for a new language modeling archi-\ntecture. Our contributions in this paper are:\n•A proposed approach to synthesize a pseudo-\ncorpus with which to learn language models\nfrom a corpus-less symbol set\n•An experimental evaluation of the impact\nof various pieces of our corpus synthesis\nmethodology on icon prediction accuracy\n•A preliminary attempt to apply a novel lan-\nguage model architecture suitable for icon-\nbased, open-vocabulary AAC applications\n2 Symbolstix dataset\nThe Symbolstix (Clark, 1997) icon set is used in\nseveral commercial AAC applications. Each icon\nincludes an image, and is associated with metadata\ninformation that textually describes the meaning\nassigned to the icon at hand. An image in this set\ncan represent a single word, a phrase, or a syntac-\ntic modiﬁer (such as “plural”). The images cover\n48 major topics such as actions, technology, nature\netc. They vary in meaning, demonstrating abstract\nconcepts and tangible ones; they also present dif-\nferent levels of complexity and details. The meta-\ndata primarily describe the associated term the im-\nage corresponds to, its synonyms, and its transla-\ntion to different languages.\nThe Symbolstix icon set was designed for use\nby communities who are in need of icon-based\ncommunication, such as children with communi-\ncation disabilities, TBI patients, etc. One commer-\ncial application of the current icon-set is a news-\ncast aimed at adult consumers; another is a com-\nmunications platform for children with Cerebral\nPalsy. The set of 34k icons is in practice broad\nenough to reﬂect those needs. However, the cre-\nators of the system often do add new icons when\nrequested by their user population.\nFigure 1: Example icons: afraid and bite leg\nOn the left side of Figure 1 is an exam-\nple of a single-word icon representing the term\nafraid. This icon’s human-assigned topic category\nis “descriptives-feelings”. Note that many icons\nare mapped to multiple synonyms. Synonyms of\nthis icon are: eerie, fear, feared, fearful, fears,\nfrightened, Halloween, scary, terriﬁed, upset, and\nnervous. As such, an icon’s meaning is highly\ncontext-dependent.\nThe right-hand side icon in Figure 1 is an exam-\nple of a two-word icon representing the concept\nbite leg. This icon’s topic is of “actions”. Syn-\nonyms of this icon are: “bad day” and “dog bite”.\nAs observed in Figure 1, the nature of the Symbol-\nstix leans toward conversational concepts of spo-\nken language, due to their intended use in AAC.\nSymbolstix contains 34, 837 icons. 13, 951 of\nthese icons are of a single word; several of these\nare duplicates 2, only 12, 434 of the single word\nicons are unique terms. In our experiment, to\navoid redundancy, we used this set of unique\nterms. We chose the unique term-icon pair (from\nits non-unique group) that had the richest metadata\nand the highest overlap (within its group) to rep-\nresent a concept. This step was essential to reduce\ncomplexity; however, it did introduce a limitation\nto our approach, which we discuss in section 5.\nNotably, the Symbolstix corpus comes with no\ndataset that demonstrates the intended usage of\nicons to construct a proper sentence. Ideally, we\nwould use a dataset of icon sentences for language\nmodeling, as it would enable learning icon se-\nquences and by that to infer the language rules\nfrom its patterns. In the next section, we describe\nhow we were able to overcome that obstacle.\n3 Experimental Setup\nAs mentioned in Section 2, the Symbolstix data set\nof icons has no sentence-like corpus from which\nicon sequences can be readily learned to form a\nlanguage model of icons. We attempted to syn-\nthesize an icon corpus by beginning with a textual\ncorpus, and “projecting” our icons into the text\nspace using pre-trained word embeddings using\nthe methodology described below. Since each icon\nis accompanied by metadata containing human-\nedited synonym lists, it was natural to represent\nicons as some composition of their synonyms in a\nvector space.\nIn this manner, we embedded our icons in text,\nand created pseudo-sequences (“icon sentences”).\nThis solution is not without problems, ﬁrst among\nthem the issue is that our icon sentences may not\n2A single lexical item may be represented several times;\nfor example, there are several variants of “glue”, with differ-\nent shapes of bottles and patterns of labels.\n27\nrepresent realistic examples of how the Symbol-\nstix icons are meant to be used. Rather, they might\ninstead represent the icons as subjected to the lan-\nguage conventions found in oral or written lan-\nguage. For example comparing a possible icon se-\nquence to the English language might look like:\nIcon: <I> <go> <here> <past>\nEnglish: <I> <went> <here>, or\nEnglish: <the> <dogs> <are> <at> <home>\nIcon: <the> <dog> <plural> [<be> optional]\n<at> <home>\nSome of the terms may disappear in translation,\nwhile others are added.\nAnother question is whether it is possible to\nfully represent an icon as the sum of its synonyms;\nor, put another way, whether the ways in which an\nicon’s synonyms are used in written language can\ncapture the totality of an icon’s meaning. For ex-\nample, the icon in ﬁgure 1 does not precisely mean\n“afraid”, but rather refers to a more general con-\ncept. This is why we chose to explore a composi-\ntional approach to representing icon meaning in a\ncontinuous space. Finally, how should we handle\nsentences in our textual data set that are not fully\nrepresentable using icons from Symbolstix?\nData Preprocessing\nIcon Representation: In order to construct an icon\nlanguage model, we needed to ﬁnd a way to rep-\nresent our icon vocabulary in a continuous em-\nbedding space (following the lead of Kiros et al.\n(2015)). Lacking a corpus that included icons, we\nwere unable to directly train “icon embeddings”\nfrom data. Instead, we attempted to “project” our\nicons into a word embedding space.\nWe experimented with two different approaches\nof word embedding (see section 4), and, for each\nicon, generated icon embeddings by averaging 3\nthe word embeddings of the icon’s synonyms (as\nspeciﬁed by the Symbolstix metadata). Note that a\ndifferent choice of icon set would have resulted in\na different embedding space and language model.\nHowever, this basic approach describes a generic\nprocess to produce models form a corpus-less\nsymbol-set, and should translate to other situtions.\nTextual Datasets: We next took a textual cor-\npus (see section 4), and identiﬁed terms that could\nbe replaced with icon embeddings. In this work,\nwe relied on a relatively simple strategy of me-\nchanically substituting icons for words based on\n3We also experimented with summation, and observed no\nmeaningful difference.\ntheir Symbolstix metadata. In other words, in-\nstances of the word “wetland” in the corpus would\nbe replaced by the icon with “wetland” in its\nlist of synonyms or descriptor terms. Note that\nthis icon’s embedding would contain information\nabout other words associated with that icon (e.g.\n“swamp”). We discuss some practical considera-\ntions around polysemous words and icons in sec-\ntion 4. This step forms a dataset of embedding\nsequences, which we then used as a corpus for\nlearning a language model. The resulting corpus\nwas then fully representable by embeddings (both\nof the words and icons).\nTraining\nFor our language model, we used a standard RNN\narchitecture with two hidden LSTM layers, a lin-\near, and a ﬁnal softmax layer that predicts the\nterm’s index, trained with cross entropy loss func-\ntion (seen in Equation 1). The model’s input is of\nthe generated embeddings and as such contained\nno explicit embedding layer.\nLi =\n∑\njϵJ\nT(i, j) log(P(i, j)). (1)\nThe icons in this project are aimed at patients\nwho would use them as a means to communicate.\nIt is very likely that the icon language that would\nbe formed by these patients would share similar\ncharacteristics with spontaneous speech or infor-\nmal language since this is the type of commu-\nnication we have with a caregiver, family mem-\nber, or a friend. Knowing this, we used the Sub-\ntlexUS (Brysbaert and New, 2009) corpus (made\nup of subtitles from movies and television) as a\nproxy for a corpus of spontaneous speech that con-\ntained 6, 043, 188 sentences.4\nModel Evaluation\nWe evaluated our language model using three dif-\nferent metrics:\n•Mean Reciprocal Rank (MRR) of the “cor-\nrect” predicted icon as seen in Equation 2\nMRR = 1\n|Q|\n∑\niϵQ\n1\nranki\n, (2)\nQ represents the token events of the target.\nThe choice of MRR metric was to internally\n4See (Vertanen and Kristensson, 2011) for an extensive\ndiscussion on issues surrounding corpus selection for AAC\napplications.\n28\nlook at the rank of the target, rather than to bi-\nnary classify it for whether it was accurately\npredicted in the ﬁrst rank.\n•Accuracy@k: The percentage of predictions\nin which the “correct” icon was within the\ntop k predictions. The choice in ACC@k was\nto inform about the quality of the prediction\ngenerated by the models. We have chosen\nACC@1 to crudely understand whether the\nﬁrst choice was correct, and ACC@10 to get\na sense of the prediction quality given that a\nuser may be able to choose from a limited list\n(depending on the user interface), and also\nto model the notion that different users may\nchoose different words in a simialr context\n(and so there is not a single correct word in\nreality).\n4 Experiments\nWe performed three sets of experiments. The\nﬁrst explored the effect of different approaches to\nword embedding, the second explored the effects\nof either including or excluding non-icon terms in\nmodel training, and the third looked at the effects\nof other (non-Subtlex) text corpora. For both ap-\nproaches to word embedding, we used pre-trained\nword vectors. The pretrained set is the source for\ngenerating the icon embeddings.\nBoth the icon and the pretrained embeddings re-\nplace the terms in the textual data with their cor-\nresponding vectors to generate an embedding cor-\npus. All our experiments contained the same num-\nber of pretrained vectors as well as icon vectors. If\nboth vector sets contained the same term, the icon\nembedding was used. The textual dataset was to-\nkenized and punctuation was removed. Each of\nthese experiments was held in a 5 fold cross val-\nidation fashion. The process to generate the cor-\npus from which language models are learned is\ndescribed in Figure 2.\nThis process shows also the three different mod-\nules we experimented with: the pretrained corpus,\nwhich forms the icon embeddings; the icon set that\nforms (with or with out the pretrained set (there-\nfore the ‘switch’ between pretrained embeddings\nto textual dataset)) the textual embedding; and the\ntextual dataset that provides the sequences of sym-\nbols to generate the textual embedding.\nExperiment 1: Pretrained Vectors\nThe Pretrained embeddings in our experiment are\nused both to construct the icon representations and\nBPMN 2.0 shiran    |   February 20, 2018\nTextual Dataset\nPreTrained embeddings\nIcon embeddings Embedding Dataset\nFigure 2: Block diagram to generate training set\nfor language modeling\nto represent the textual corpus. In our setting\nwe have explored the Global Vectors for Word\nRepresentation (Glove) (Pennington et al., 2014)\nset consisting of 400,000 uncased entries and\ntrained on Wikipedia 2014 and Gigaword version\n5 ( ≈6B tokens) with 50 embedding dimensions,\nand compared it to Context2Vec (c2v) (Melamud\net al., 2016) trained on ukWaC corpus and MSCC\n(≈2B + ≈50M tokens) consisting of 160,563 un-\ncased entries, with 600 embedding dimensions.\nTo maintain a controlled environment the textual\ndataset remained ﬁxed, the vocabulary of pre-\ntrained token types was identical ( n=69,840) as\nwell as the icon list (n=6,934 term types) irrespec-\ntive of the dataset used. A term in the dataset was\nprioritized to be replaced with an icon term ﬁrst,\nthen if not found, with an icon synonym, with a\npretrained representation, and ﬁnally, provided no\nalternative, a term was replaced with an <unk>\nvector representation.\nmetric c2v Glove\nMRR 0.85 (0.00) 0.85 (0.00)\nACC@1 (%) 50.99 (0.03) 49.29 (0.04)\nACC@10 (%) 90.51 (0.01) 90.29 (0.01)\nTable 1: Effect of word embedding method\nTable 1 contains the experimental results of\nevaluations run on models trained with Glove and\nc2v vectors, averaged across ﬁve folds of cross-\nvalidation on the SubtlexUS dataset.\nAfter controlling for the number of icon- and\npretrained-term types as well as for the textual\ncorpus, Table 1 shows that there are no meaning-\nful differences resulted from the pretrained vectors\ntype. The dataset the vectors were trained on as\n29\nwell as the method by which the vectors were gen-\nerated had no observable impact on the language\nmodel performance.\nWhile Experiment 1 covers one aspect of com-\nparing differences between different word embed-\ndings, when choosing a pretrained set of vectors\nto use and generate icons from, there may be ad-\nditional considerations. The coverage of the pre-\ntrained set is essential to produce icon represen-\ntations, but also is important for terms in the tex-\ntual dataset that cannot be represented with icons\n(which are then replaced with a pretrained vector\nif found) as described in Experiment 1. The pre-\ntrained set coverage with regards to the icon set\nis measured not only by the total number of icon\nrepresentations that were generated from the pre-\ntrained set, but also by how well each icon cap-\ntures the broad meaning it stands for. Since each\nicon is likely to have its name and synonyms com-\nposed together to represent it (as described in 3 in\nData Preprocessing part), an optimal pretrained set\nwould contain representations for all these terms.\nAs for the textual dataset, an optimal coverage of\nthe text with the pretrained list ideally would con-\nsist of a large number of term types, but also term\nevents that appear in the dataset.\nExperiment 2: Icon Symbols Constraint\nIdeally, the corpus to learn language models from\nwould consist of the icon vocabulary solely since\nthe goal is to construct an Icon language model.\nWe therefore, experimented with transforming\nour synthetic corpus to only include terms rep-\nresentable using icon vectors (“pure”) and com-\npared LM and prediction accuracy with the orig-\ninal, “non-pure” results. We used Glove and c2v\nvectors in our experiment presented in Table 2.\nTable 2 describe an averaged ﬁve fold cross val-\nidation experiment of SubtlexUS with icon only\nembeddings referred by the “pure” experiment.\nmetric c2v Glove\nMRR 0.33 (0.00) 0.33 (0.00)\nACC@1 (%) 46.79 (0.06) 45.72 (0.06)\nACC@10 (%) 54.92 (0.01) 54.29 (0.04)\nTable 2: Effect of Icon embedding representation\non SubtlexUS mean(standard deviation)\nTable 2 describes a similar pattern to Table 1 as\nthere was no meaningful change in the ﬁnal icon\nlanguage models’ performances due to the “pure”\ncondition. We do note that there was a slight ad-\nvantage to c2v embeddings which seemed to be\npredicting more correctly the target.\nThe “pure” condition resulted in a relatively\nsmaller prediction accuracy. On the one hand, this\nmay be surprising evidence, as it is reasonable to\nthink that a smaller and more focused vocabulary\nset would result in an improved language model\nperformance. We assume that the reduction in vo-\ncabulary size caused as a result of employing icons\nsolely created short, sparse, and uncommon pat-\nterns of sequences, which limited the models’ abil-\nity to learn and predict accurately.\nUnder the “pure” condition, the model vocabu-\nlary consists solely of the icon set itself, whereas\nin the “non-pure” condition, the model vocabu-\nlary consists of the icon set as well as the pre-\ntrained embeddings together with <unk> terms.\nWhile we can not directly compare the two ex-\nperiments (1 and 2) we can share our considera-\ntions when choosing to generate language models\npurely based on icons.\nTo support our explanation for Table 2 interpre-\ntation, we conducted a qualitative test and looked\ninto to the actual sentences produced by the icons\nin isolation, asking whether these sentences cre-\nated “meaningful” (or at least useful) messages\nfor LM training.. This might be helpful to get a\ndeeper perspective on the corpus created and assist\nin making design choices. Here is an example:\n“non-pure”: <your> <warning> <did> <not>\n<work>\n“pure”: <your> <warning> <not> <work>\nArguably, the main message was conveyed in this\nsentence, while in the following:\n“non-pure”: <they> <did> <n’t> <use> <mud>\n<they> <used> <sod>\n“pure”: <they> <use> <they>\nthe essence is gone. While it is not feasible to\nqualitatively look at every sentence, one may con-\nsider comparing the amount of tokens prior to\nelimination and post, under the assumption that\nthe greater the loss, the more likely that the quality\nof solely using the icon-set becomes a concern.\nWe would like to note that in Experiment 2 in\nparticular, we used the same simulated “icon lan-\nguage” for both training and evaluation. An ideal\nevaluation of our approach to producing synthetic\nin-domain training data would have been evaluat-\ning the language models trained on simulated icon\nlanguage on “real” text composed using icons. As\n30\nwe did not have such a useful resource, it is impor-\ntant to observe this as a limitation of the current\nexperiment.\nExperiment 3: Textual Corpus\nIn our system, the role of the textual corpus is\nto provide the language model with training data\nregarding patterns of word (“icon”) use. Ideally,\nwe would use a corpus made of symbols that rep-\nresent the type of content and structure an AAC\nuser would produce. Finding an AAC-oriented\ncorpus that would be big enough to train was a\nhurdle, and so for our previously-described exper-\niments, we relied on SubtlexUS. While not ideal,\nthis corpus was closer to spontaneous speech than,\nsay, a newswire corpus would have been, and\nfeatured smaller and more manageable sentences\nthat we hoped would withstand being converted to\npseudo-icon representations.\nThat said, we did wish to investigate the util-\nity of using an existing corpus that was designed\nto be closer to AAC-style speech. Vertanen and\nKristensson (2011) produced such a corpus, con-\nsisting of 6,142 sentences produced by Amazon\nMechanical Turk users who were paid to generate\nplausible sentences and to evaluate the plausibility\nof other sentences generated by other workers.\nThis corpus, while valuable, was too small for\nuse with our language modeling approach. Fol-\nlowing Vertanen and Kristensson’s insight that\n“short text” such as that seen in online media such\nas Twitter, etc. might be a good proxy for true\nAAC-style speech, we therefore mixed the AAC-\nstyle corpus with second corpus, this one con-\nsisting of modiﬁed SMS messages. The second\ncorpus was from Chen and Kan (2013) and con-\nsisted of 18,042 SMS messages, and was origi-\nnally constructed for experiments in text normal-\nization. As such, it includes messages written\nin heavily-abbreviated forms as well as “cleaned\nup” versions of each message, written in some-\nthing approximating “standard” English orthogra-\nphy. We used this subset of the corpus in the hopes\nthat its short, informal, and speech-like sentences\nwould complement the AAC-style corpus. Our\ngoal was to assemble a corpus containing language\nthat is as close as possible to what would be pro-\nduced by actual users of an AAC system. We then\nrepeated the language modeling experiments con-\nducted earlier on this hybrid corpus, using identi-\ncal procedures and evaluation metrics.\nTable 3 and 4 tell a similar story to one an-\nmetric c2v Glove\nMRR 0.38 (0.00) 0.33 (0.01)\nACC@1 (%) 56.41 (0.52) 47.13 (2.81)\nACC@10 (%) 60.44 (0.42) 54.51 (2.37)\nTable 3: Textual corpus (AAC-SMS)\nmean(standard deviation)\nmetric c2v Glove\nMRR 0.37 (0.01) 0.34 (0.00)\nACC@1 (%) 53.25 (2.11) 47.73 (1.46)\nACC@10 (%) 59.06 (1.29) 56.00 (1.40)\nTable 4: Textual corpus (AAC-SMS/pure)\nmean(standard deviation)\nother: the models trained using c2v embeddings\noutperformed the models that used Glove embed-\ndings, which is different from what we observed in\nthe previous experiments— though with this cor-\npus, the overall performance numbers were much\nlower than with the original, larger corpora. The\nreason for overall low performance was probably\ndue to the very small size of the AAC-SMS cor-\npus, and possible overﬁtting as a result. Digging\nmore deeply into our data, we examined the in-\ndividual cross-validation results at the fold level,\nthinking that perhaps the results were unstable due\nto the relatively small data set which indeed seem\nto be the case.\nNevertheless, in an attempt to indirectly evalu-\nate different models, while the AAC experiments\nhad substantially higher variance across folds than\ndid the SubtlexUS experiments, the differences\nbetween the two approaches do appear to be real.\nUltimately, we note that the substantial difference\nin corpus size between SubtlexUS and our AAC-\nSMS corpus make it difﬁcult to draw any ﬁrm con-\nclusions, and investigating this issue further will\nbe a component of our future work in this area.\n5 Conclusions\nThis work is a ﬁrst step towards the development\nof language models for an icon set that has no cor-\nresponding corpus, but there remains much to be\ndone. One limitation of this work is that, even\nafter being projected into an icon space, our syn-\nthetic training data is somewhat different from ac-\ntual icon-based language produced by AAC users.\nThat said, we did try to overcome this limitation by\nexperimenting with a corpus designed to be much\n31\ncloser to actual AAC-style language, though at a\nsubstantial cost in terms of corpus size. This is a\ncommon problem in AAC research in general, and\nour immediate next steps will focus on develop-\ning more naturalistic training corpora (following\nthe lead of Vertanen and Kristensson (2011), who\nfaced similar challenges).\nAnother important limitation is that we have not\nsolved the problem of icons that represent multi-\nword expressions or phrases. This will be a ma-\njor area our future work, for two reasons. First,\nmany important icons fall into this category. Sec-\nond, one of the advantages of icon-based AAC is\nincreased speed of communication, and collapsing\nmulti-word expressions to a single icon would en-\nable substantial improvements.\nA second area of future work will look at ways\nto capture and express morphology. Our icon set\nincludes icons that can be used to indicate tense,\nplurality, etc., but our current approach to cor-\npus processing and term substitution/composition\ndoes not take advantage of such information. We\nintend to explore ways to directly represent mor-\nphological/inﬂectional information in the input\nside of our models, and in doing so make better\nuse of our icon system.\nA ﬁnal limitation of this work is that our ap-\nproach to selecting icons had the unfortunate side\neffect of ignoring polysemy: the set of icons that\nwe worked with here was restricted to a single\nsense of polysemous words. This means that some\npossibly-useful icons were excluded, which could\nhave consequences for anybody actually using our\nsystem for communication. Consider the word\n“cheer”, which can be either a verb or a noun, and\nin both cases has multiple meanings. There are\nseveral icons in Symbolstix that capture different\nusages of the word, but our current approach only\nuses one. This will be another active area of future\nwork, and we expect our solution to this problem\nto tie in with our solution to the issue of multi-\nword expressions.\nOur evaluations thus far have been system-\noriented, and have tried to measure the model’s\nperformance. Our MRR and accuracy results have\nprovided us with an internal view for where our\nmodels were performing as desired as well as\nidentiﬁed areas where they fall short. The next\nstep will be to integrate our language model with\nthe rest of our AAC platform and begin working\nwith real end-users. We anticipate that this will\nguide much of our future work on this problem.\nAcknowledgments\nWe thank the anonymous DeepLo workshop re-\nviewers for their valuable feedback and com-\nments. We also thank our clinical collaborators\nin OHSU’s Institute on Development & Disabil-\nity: Betts Peters, Brandon Eddy, and Dr. Melanie\nFried-Oken, as well as our collaborators at North-\neastern University, in the laboratories of Drs.\nDavid Smith and Deniz Erdogmus. Research re-\nported in this paper was supported by the National\nInstitute on Deafness and Other Communication\nDisorders of the NIH under awards R01DC009834\nand R56DC015999.\nReferences\nAmerican Speech Language Hearing Association et al.\n2004. Roles and Responsibilities of Speech-\nLanguage Pathologists with Respect to Augmenta-\ntive and Alternative Communication: Technical Re-\nport .\nDavid R. Beukelman and Pat Mirenda. 2005. Aug-\nmentative & Alternative Communication: Support-\ning Children & Adults with Complex Communica-\ntion Needs . Paul H. Brookes Publishing Co., 3rd\nedition.\nMarc Brysbaert and Boris New. 2009. Moving Beyond\nKuˇcera and Francis: A Critical Evaluation of Cur-\nrent Word Frequency Norms and the Introduction\nof a New and Improved Word Frequency Measure\nfor American English. Behavior Research Methods\n41(4):977–990.\nTao Chen and Min-Yen Kan. 2013. Creating a\nlive, public short message service corpus: the nus\nsms corpus. Language Resources and Evaluation\n47(2):299–335.\nJacquie Clark. 1997. Symbolstix. News 2 You.\nhttps://www.n2y.com/symbolstix-prime.\nBrenda Fossett and Pat Mirenda. 2007. Augmentative\nand Alternative Communication. Handbook of De-\nvelopmental Disabilities pages 330–348.\nNestor Garay-Vitoria and Julio Abascal. 2006. Text\nprediction systems: a survey. Universal Access in\nthe Information Society 4(3):188–203.\nTeresa Iacono, Katie Lyon, and Denise West. 2011.\nNon-Electronic Communication Aids for People\nwith Complex Communication Needs. Inter-\nnational Journal of Speech-Language Pathology\n13(5):399–410.\n32\nRyan Kiros, Yukun Zhu, Ruslan R Salakhutdinov,\nRichard Zemel, Raquel Urtasun, Antonio Torralba,\nand Sanja Fidler. 2015. Skip-Thought Vectors. In\nAdvances in Neural Information Processing Sys-\ntems. pages 3294–3302.\nJanice Light and Kathryn Drager. 2007. AAC Tech-\nnologies for Young Children with Complex Com-\nmunication Needs: State of the Science and Future\nResearch Directions. Augmentative and Alternative\nCommunication 23(3):204–216.\nOren Melamud, Jacob Goldberger, and Ido Dagan.\n2016. context2vec: Learning Generic Context Em-\nbedding with Bidirectional LSTM. In Proceedings\nof The 20th SIGNLL Conference on Computational\nNatural Language Learning. pages 51–61.\nU. Orhan, K. E. Hild, D. Erdogmus, B. Roark, B. Oken,\nand M. Fried-Oken. 2012. Rsvp Keyboard: An EEG\nBased Typing Interface. In 2012 IEEE International\nConference on Acoustics, Speech and Signal Pro-\ncessing (ICASSP). pages 645–648.\nR. Patel. 2011. Message Formulation, Organization,\nand Navigation Schemes for Icon-Based Communi-\ncation Aids. In 2011 Annual International Confer-\nence of the IEEE Engineering in Medicine and Biol-\nogy Society. pages 5364–5367.\nJeffrey Pennington, Richard Socher, and Christopher\nManning. 2014. Glove: Global Vectors for Word\nRepresentation. In Proceedings of the 2014 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP). pages 1532–1543.\nKeith Vertanen and Per Ola Kristensson. 2011. The\nimagination of crowds: Conversational aac lan-\nguage modeling using crowdsourcing and large data\nsources. In Proceedings of the Conference on Em-\npirical Methods in Natural Language Processing .\nAssociation for Computational Linguistics, Strouds-\nburg, PA, USA, EMNLP ’11, pages 700–711.\nhttp://dl.acm.org/citation.cfm?id=2145432.2145514.\nKarl Wiegand and Rupal Patel. 2012a. Non-\nsyntactic word prediction for aac. In Proceed-\nings of the Third Workshop on Speech and\nLanguage Processing for Assistive Technolo-\ngies. Association for Computational Linguistics,\nStroudsburg, PA, USA, SLPAT ’12, pages 28–36.\nhttp://dl.acm.org/citation.cfm?id=2392855.2392860.\nKarl Wiegand and Rupal Patel. 2012b. Symbol-\npath: A continuous motion overlay module for\nicon-based assistive communication. In Proceed-\nings of the 14th International ACM SIGACCESS\nConference on Computers and Accessibility . ACM,\nNew York, NY , USA, ASSETS ’12, pages 209–210.\nhttps://doi.org/10.1145/2384916.2384957.",
  "topic": "Icon",
  "concepts": [
    {
      "name": "Icon",
      "score": 0.9493159055709839
    },
    {
      "name": "Computer science",
      "score": 0.7998707294464111
    },
    {
      "name": "Language model",
      "score": 0.6677069664001465
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.6182910203933716
    },
    {
      "name": "Symbol (formal)",
      "score": 0.5600042939186096
    },
    {
      "name": "Field (mathematics)",
      "score": 0.513127863407135
    },
    {
      "name": "Natural language processing",
      "score": 0.4763089418411255
    },
    {
      "name": "Artificial intelligence",
      "score": 0.46719714999198914
    },
    {
      "name": "Augmentative and alternative communication",
      "score": 0.46224263310432434
    },
    {
      "name": "Character (mathematics)",
      "score": 0.43085813522338867
    },
    {
      "name": "Word (group theory)",
      "score": 0.4273822605609894
    },
    {
      "name": "Human–computer interaction",
      "score": 0.4244541525840759
    },
    {
      "name": "Speech recognition",
      "score": 0.3702627718448639
    },
    {
      "name": "Programming language",
      "score": 0.17628270387649536
    },
    {
      "name": "Linguistics",
      "score": 0.1082165539264679
    },
    {
      "name": "Geometry",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I165690674",
      "name": "Oregon Health & Science University",
      "country": "US"
    }
  ],
  "cited_by": 11
}