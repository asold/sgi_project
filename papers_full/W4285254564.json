{
  "title": "Transformer based ensemble for emotion detection",
  "url": "https://openalex.org/W4285254564",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4320548338",
      "name": "Aditya Kane",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4320548339",
      "name": "Shantanu Patankar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3156524762",
      "name": "Sahil Khose",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3097539135",
      "name": "Neeraja Kirtane",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2970597249",
    "https://openalex.org/W1966797434",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W3142289085",
    "https://openalex.org/W2805744755",
    "https://openalex.org/W1989777370",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3156371678",
    "https://openalex.org/W3034323190",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4287824654"
  ],
  "abstract": "Detecting emotions in languages is important to accomplish a complete interaction between humans and machines. This paper describes our contribution to the WASSA 2022 shared task which handles this crucial task of emotion detection. We have to identify the following emotions: sadness, surprise, neutral, anger, fear, disgust, joy based on a given essay text. We are using an ensemble of ELECTRA and BERT models to tackle this problem achieving an F1 score of 62.76%. Our codebase (https://bit.ly/WASSA_shared_task) and our WandB project (https://wandb.ai/acl_wassa_pictxmanipal/acl_wassa) is publicly available.",
  "full_text": "Proceedings of the 12th Workshop on Computational Approaches to\nSubjectivity, Sentiment & Social Media Analysis, pages 250 - 254\nMay 26, 2022c⃝2022 Association for Computational Linguistics\nTransformer based ensemble for emotion detection\nAditya Kane∗ and Shantanu Patankar*\nPune Institute of Computer Technology, Pune\n{adityakane1, shantanupatankar2001}@gmail.com\nSahil Khose and Neeraja Kirtane\nManipal Institute of Technology, Manipal\n{sahilkhose18, kirtane.neeraja}@gmail.com\nAbstract\nDetecting emotions in languages is important\nto accomplish a complete interaction between\nhumans and machines. This paper describes\nour contribution to the WASSA 2022 shared\ntask which handles this crucial task of emo-\ntion detection. We have to identify the follow-\ning emotions: sadness, surprise, neutral, anger,\nfear, disgust, joy based on a given essay text.\nWe are using an ensemble of ELECTRA and\nBERT models to tackle this problem achieving\nan F1 score of 62.76%. Our codebase 1 and our\nWandB project2 is publicly available.\n1 Introduction\nEven after engineering a 175B parameter language\nmodel like GPT-3 (Brown et al., 2020) we are far\nfrom artificial general intelligence. Emotion is a\nconcept that is challenging to describe. However,\nas human beings, we understand the emotional ef-\nfect that situations could have on other people. It\nis interesting to see how we can infuse this knowl-\nedge into machines. This work explores whether it\nis possible for machines to map emotions to sit-\nuations consciously. Emotion in text has been\nstudied for a while and has given interesting in-\nsights. The dataset that we are using is an extended\nversion of the (Ekman, 1992) dataset. Our team,\nMPA_ED, participated in the W ASSA 2022 Shared\nTask on Empathy Detection and Emotion Classi-\nfication, Track 2: Emotion Classification (EMO),\nwhich consists of predicting the emotion at the\nessay level. This paper has the following contribu-\ntions:\nWe propose three new datasets generated using\nvarious sampling techniques which overcome the\nclass imbalance. We present our ensemble based so-\nlution consisting of multiple ELECTRA and BERT\n∗First authors\n1https://bit.ly/WASSA_shared_task\n2https://wandb.ai/acl_wassa_\npictxmanipal/acl_wassa\n(Devlin et al., 2018) models to solve the emotion\nclassification task. We provide a detailed analysis\nof the performance of the cluster of models and re-\nflect on the shortcomings of the models as well as\nthe dataset generated that affected the performance.\n2 Related Work\nEmotion detection and sentiment analysis has been\nan extensive research topic since the inception of\nnatural language processing. It has been stud-\nied in great detail by faculties of both computer\nscience and neurobiology (Okon-Singer et al.,\n2015). Murthy and Kumar (2021) presents an\nextensive review of the modern emotion classi-\nfication techniques. The work by Alhuzali and\nAnaniadou (2021) remains the current state-of-the-\nart on emotion classification on the renowned Se-\nmEval dataset (Mohammad et al., 2018). BERT\nremains the best performer on the GoEmotions\ndataset (Demszky et al., 2020)\njoy\n4.4%\ndisgust\n8.0%\nsurprise\n8.8%\nfear\n10.4%\nneutral\n14.8%\nsadness\n34.8%\nanger\n18.8%\nFigure 1: Class distribution in emotions\n3 Data\nThe dataset consists of 1860 data points. Each\ndata point has an essay and its emotion. The emo-\ntions are classified into seven types: anger, disgust,\nfear, joy, neutral, sadness, and surprise. The vali-\ndation and test split has 270 and 525 data points\nrespectively. The classes for the training data ex-\npresses high imbalance, as shown in Fig 1 . Here\n250\nsadness\njoy\njoy\ndisgust\nBERT_AOUS\nELECTRA_AOUS\nELECTRA_AOS\nELECTRA_RSO\nInput essay \nVoting joy\nFigure 2: Ensemble pipeline\nwe see that the emotion \"sadness\" has the max-\nimum number of data points, whereas \"joy\" has\nthe least number of data points. The distribution\nis highly skewed and hence data augmentation is\nrequired to mitigate that. We performed basic pre-\nprocessing like removing punctuation, numbers,\nmultiple spaces, and single line characters.\nTo overcome the class imbalance, GoEmotions\ndataset is used, which is a similar dataset with 27\nemotions. We suggest three data augmentation\ntechniques using the dataset described as follows:\n• Augmented Over-UnderSampling (AOUS):\nIf X denotes the number of data points per\nclass, in this method, if the data points in a\nparticular class are greater than X, we un-\ndersample the data by randomly removing\nthe essays. Otherwise, the data is oversam-\npled by simply adding Reddit comments with\nmaximum lengths from GoEmotions dataset\n(sorted by lengths) (Fig 3). As the average\nlength of comments in GoEmotions dataset is\n12 and average length of essays in WASSA\ndataset is 84, the comments with maximum\nlength are chosen for oversampling. We take\nX as 400 in our experiments.\n• Random synthetic oversampling (RSO): We\nobserve a significant difference in the aver-\nage comment length of GoEmotions dataset\nand the average essay length in the WASSA\ndataset. To avoid disturbing the length distri-\nbution of the WASSA dataset after oversam-\npling, we create synthetic essays by concate-\nnating multiple random comments with same\nemotion (Fig 4). We match the distribution of\nlengths of the synthetically generated essays\nfrom GoEmotions dataset with the distribution\nof the original dataset using “Systematic Sam-\npling.” We eliminate the deficit in each class\nby adding synthetically generated essays.\n• Augmented Oversampling (AOS) : X de-\nnotes the highest number of data points per\nModel Dataset macro F1\nBERTbase AOUS 59.19%\nELECTRAbase AOS 58.94%\nELECTRAbase RSO 59.06%\nELECTRAbase AOUS 59.67%\nEnsemble val 62.76%\ntest 53.41%\nTable 1: Validation metrics\nclass. If the number of data points is less\nthan X, the data is oversampled by adding\ncomments from GoEmotions dataset with the\nhighest lengths. (Fig 3)\nThe data distribution post augmentation is balanced\nwith number of samples in AOS, RSO and AOUS\ndatasets equal to 4528, 4828 and 2800 respectively.\n4 System Description\nBidirectional Encoder Representations from Trans-\nformers (BERT) (Devlin et al., 2018) is a\ntransformer-based (Vaswani et al., 2017) language\nmodel developed by Google.\nELECTRA (Clark et al., 2020) is a variation of\nBERT, having a different pre-training approach. It\nrequires less compute time compared to BERT.\nWe performed ablations with many of the present\nwell-known language models — ALBERT (Lan\net al., 2019), XLNET (Yang et al., 2019), RoBERTa\n(Liu et al., 2019) and found BERT and ELECTRA\nto perform the best.\n5 Ensemble Methods\nWe conducted extensive experimentation and ob-\nserved some models to perform substantially better\nthan others. We shortlisted the models based on the\nvalidation F1-score. We decided to ensemble these\nmodels for better performance. We shortlisted four\nmodels and used majority voting as our ensemble\nmethod: BERT with AOUS, ELECTRA with AOS,\nELECTRA with RSO, ELECTRA with AOUS.\n251\na b\nWASSA Dataset\na b\nGoEmotions Dataset\na b\nOver-Under \nSampling (AOUS)\na b\nOver Sampling \n(AOS)\nFigure 3: AOS and AOUS\nWe used the ensemble of the models in Table\n1. The confusion matrices of each of these models\nare shown in Fig 5. The confusion matrix of the\nresultant ensemble is shown in 6. Note that all con-\nfusion matrices are normalized by the number of\ntrue samples in each class of the evaluation dataset.\nWe deduce the following observations:\n1. When the true label is \"disgust,\" all models\nconfuse the emotions \"anger\" and \"disgust\".\nAll models have below average performance\non \"anger\" and \"disgust\".\n2. Models trained on AOUS dataset (c, d in Fig\n5) are less prone to confusion in multiple close\nclasses like \"disgust\", \"fear\" and \"sadness\" .\n3. The emotions \"anger\" and \"disgust\" do not\nbenefit from the ensemble, whereas \"fear\" suf-\nfers a bit. However we observe, the emotions\n\"neutral\", \"sadness\" and \"surprise\" experience\nsignificant gains from this process.\n6 Experiments and Results\nOur training setup was fairly straightforward. Lan-\nguage model backbone followed by fully connected\nlayer and Softmax is used. CrossEntropy loss was\nused. We employed the Adam optimizer with1e−5\nlearning rate and batch size of 8. We fixed the seed\nfor numpy and torch to 3407.\nSome of the observations made during our ex-\ntensive experimentation is as follows:\n1. Batch size 8 outperforms larger batch sizes:\nWe observed improvements across all models\nand datasets using a batch size of 8 over 32 or\n64. We speculate this is because smaller batch\nsize helps in generalization as the stochasticity\nof individual batches increase.\n2. ELECTRA fine-tuned on the AOUS dataset\noutperforms other models: ELECTRA per-\nforms better than BERT for all our augmented\na b\nWASSA Dataset\na b\nRandom synthetic \nEssays\n a b\nRSO\na b\nGoEmotions Dataset\n=\n=\nComments to Essays\nFigure 4: RSO\ndatasets. We believe models finetuned on\nAOUS dataset perform better because AOUS\ndataset has 400 labels per class, making the\ndataset balanced while limiting the adulter-\nation induced by the GoEmotions dataset.\n3. Multi-task learning has poor performance:\nWe experimented with multi-task learning\nwhere empathy and distress tasks (Track 1)\nand emotion classification task (Track 2) were\ntrained together with a shared backbone. We\nobserved that the training was erratic, and the\ntraining loss did not converge.\n4. Models are sensitive to data imbalance :\nWhen trained on the original dataset with class\nimbalance, the model is biased towards pre-\ndicting classes with more training samples.\nWe used data augmentation techniques men-\ntioned in Section 3 to tackle this issue. After\nhandling the class imbalance with data aug-\nmentation, the macro F1 score of the BERT\nmodel increased from 32.19% to 59.19%.\n5. Emotion \"joy\" vs \"surprise\" : These are\nthe only two positive emotions in the dataset.\nWe expected all of the models to confuse\nthese emotions as they are semantically simi-\nlar. However, to our \"surprise\", we observed\nthe models performed spectacularly on these\ntwo emotions. We think this is because \"sur-\nprise\" and \"joy\" have distinct appearances in\nthe corpus. \"surprise\" examples have some\nsort of exclamation or a questioning tone in\nthem. This leaves us with \"joy\", which hap-\npens to be the only positive emotion along\nwith \"surprise\" in the corpus.\n6. Randomly created synthetic essays provide\nlittle understanding: We observed the model\ntrained on RSO augmented data often predicts\n252\nanger disgust\nfear joy\nneutral sadness surprise\nanger\ndisgust\nfear\njoy\nneutral\nsadness\nsurprise\n0.66 0.11 0.026 0 0.12 0.092 0\n0.42 0.33 0 0 0.083 0.17 0\n0.032 0 0.71 0 0.097 0.16 0\n0.29 0 0 0.36 0.14 0.21 0\n0.2 0.04 0 0 0.6 0.12 0.04\n0.061 0.031 0.02 0 0.14 0.74 0\n0.14 0.071 0 0 0.071 0.14 0.57\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nanger disgust\nfear joy\nneutral sadness surprise\nanger\ndisgust\nfear\njoy\nneutral\nsadness\nsurprise\n0.51 0.026 0.039 0.013 0.13 0.25 0.026\n0.33 0.25 0.083 0 0 0.25 0.083\n0 0 0.68 0.032 0.032 0.19 0.065\n0.071 0 0 0.57 0 0.36 0\n0.08 0 0.08 0.04 0.68 0.12 0\n0.051 0 0.051 0.02 0.071 0.81 0\n0.071 0 0.071 0.071 0 0.14 0.64\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n(a) ELECTRA with AOS (b) ELECTRA with RSO\nanger disgust\nfear joy\nneutral sadness surprise\nanger\ndisgust\nfear\njoy\nneutral\nsadness\nsurprise\n0.64 0.092 0.066 0.026 0.053 0.079 0.039\n0.42 0.33 0 0 0.17 0.083 0\n0.032 0.032 0.65 0.032 0.13 0.097 0.032\n0.21 0 0.071 0.5 0.071 0.14 0\n0.04 0.04 0.04 0 0.76 0.04 0.08\n0.092 0.02 0.02 0.01 0.092 0.72 0.041\n0.14 0 0 0 0.071 0.071 0.71\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nanger disgust\nfear joy\nneutral sadness surprise\nanger\ndisgust\nfear\njoy\nneutral\nsadness\nsurprise\n0.67 0.11 0.013 0.013 0.092 0.079 0.026\n0.42 0.33 0 0 0.083 0.17 0\n0 0.065 0.65 0.032 0.097 0.13 0.032\n0.21 0 0 0.5 0.071 0.14 0.071\n0.2 0.04 0.04 0 0.6 0.08 0.04\n0.082 0.041 0.02 0 0.092 0.77 0\n0.14 0.071 0.071 0 0 0.071 0.64\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n(c) ELECTRA with AOUS (d) BERT with AOUS\nFigure 5: Confusion matrices of our models.\nanger disgust\nfear joy\nneutral sadness surprise\nanger\ndisgust\nfear\njoy\nneutral\nsadness\nsurprise\n0.63 0.092 0.013 0 0.12 0.13 0.013\n0.42 0.33 0 0 0.083 0.17 0\n0 0 0.61 0.032 0.13 0.16 0.065\n0.14 0 0 0.5 0.071 0.29 0\n0.08 0 0 0 0.8 0.08 0.04\n0.061 0.02 0.02 0.01 0.092 0.8 0\n0.071 0 0 0 0.071 0.14 0.71\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nFigure 6: Confusion matrix of our final ensemble.\nother emotions as \"sadness\" (Fig 5 (b)). We\nspeculate this is because there was no addition\nof synthetically generated data for the \"sad-\nness\" class as it is the largest class. We further\nhypothesize the synthetic data in RSO, being\nrandomly concatenated, disrupts the context\nof the entire essay as a whole. However, we\nstill use the model in our final ensemble since\nit performed well amongst the population. We\nthink this occurs due to multiple factors being\nsimultaneously at play. Further investigation\nis a promising future direction.\nThe validation confusion matrix of all the four\nmodels are displayed in Fig 5 and their results in\nTable 1. We present the following statistics. (True\nPositive (TP), standard deviation (σ), mean (µ))\n1. The highest TP µ is for \"sadness\" and\n\"fear\" emotion with 76 and 67.25 values re-\nspectively. Interestingly both of these emo-\ntions also have the least TP σwith 3.92 and\n2.87 values respectively.\n2. The least TP µis for \"disgust\" and \"joy\"\nemotion with 31 and 48.5 values respectively.\n\"joy\" also accounting for the highest TP σ\nwith 8.81 value which infers that all the mod-\nels are agreeing on different datapoints to clas-\nsify as \"joy\". Whereas \"disgust\" has one of the\nleast TP σwith 4.0 just following \"fear\" and\n\"sadness\", this suggests that all the models are\nable to agree on a very small sample space of\nthe class data to be classified as \"disgust\".\n7 Conclusion\nIn this work, we have explored an application of\nBERT and ELECTRA as a means to the task of\nemotion classification. Various data sampling tech-\nniques were used to overcome the large imbalance\nin data. In the end the best metrics were achieved\nby using majority voting of the 4 best models as an\nensemble. We foresee multiple future directions,\nincluding multi-task learning of multiple tasks with\na shared backbone, pretraining on the entire GoE-\nmotions dataset, as well as studying and rectifying\nspurious behaviour of \"anger\" and \"disgust\" labels.\n253\nReferences\nHassan Alhuzali and Sophia Ananiadou. 2021.\nSpanEmo: Casting multi-label emotion classification\nas span-prediction. In Proceedings of the 16th Con-\nference of the European Chapter of the Association\nfor Computational Linguistics: Main Volume, pages\n1573–1584, Online. Association for Computational\nLinguistics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nKevin Clark, Minh-Thang Luong, Quoc V Le, and\nChristopher D Manning. 2020. Electra: Pre-training\ntext encoders as discriminators rather than generators.\narXiv preprint arXiv:2003.10555.\nDorottya Demszky, Dana Movshovitz-Attias, Jeongwoo\nKo, Alan Cowen, Gaurav Nemade, and Sujith Ravi.\n2020. Goemotions: A dataset of fine-grained emo-\ntions. arXiv preprint arXiv:2005.00547.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. BERT: pre-training of\ndeep bidirectional transformers for language under-\nstanding. CoRR, abs/1810.04805.\nPaul Ekman. 1992. An argument for basic emotions.\nCognition and Emotion, 6(3-4):169–200.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Sori-\ncut. 2019. ALBERT: A lite BERT for self-\nsupervised learning of language representations.\nCoRR, abs/1909.11942.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining\napproach. CoRR, abs/1907.11692.\nSaif Mohammad, Felipe Bravo-Marquez, Mohammad\nSalameh, and Svetlana Kiritchenko. 2018. SemEval-\n2018 task 1: Affect in tweets. In Proceedings of The\n12th International Workshop on Semantic Evaluation,\npages 1–17, New Orleans, Louisiana. Association for\nComputational Linguistics.\nAshritha R Murthy and K M Anil Kumar. 2021. A\nreview of different approaches for detecting emotion\nfrom text. IOP Conference Series: Materials Science\nand Engineering, 1110(1):012009.\nHadas Okon-Singer, Talma Hendler, Luiz Pessoa, and\nAlexander J. Shackman. 2015. The neurobiology of\nemotion–cognition interactions: fundamental ques-\ntions and strategies for future research. Frontiers in\nHuman Neuroscience, 9.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. Advances in neural information processing\nsystems, 30.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Car-\nbonell, Ruslan Salakhutdinov, and Quoc V . Le. 2019.\nXlnet: Generalized autoregressive pretraining for lan-\nguage understanding. CoRR, abs/1906.08237.\n254",
  "topic": "Sadness",
  "concepts": [
    {
      "name": "Sadness",
      "score": 0.8458067774772644
    },
    {
      "name": "Disgust",
      "score": 0.7221670150756836
    },
    {
      "name": "Computer science",
      "score": 0.6913913488388062
    },
    {
      "name": "Surprise",
      "score": 0.6649844646453857
    },
    {
      "name": "Anger",
      "score": 0.6334593892097473
    },
    {
      "name": "Codebase",
      "score": 0.6221365332603455
    },
    {
      "name": "Emotion detection",
      "score": 0.5678132772445679
    },
    {
      "name": "Task (project management)",
      "score": 0.5470092296600342
    },
    {
      "name": "Recall",
      "score": 0.5028347373008728
    },
    {
      "name": "Emotion classification",
      "score": 0.49092963337898254
    },
    {
      "name": "Artificial intelligence",
      "score": 0.398910790681839
    },
    {
      "name": "Machine learning",
      "score": 0.38130125403404236
    },
    {
      "name": "Human–computer interaction",
      "score": 0.37786728143692017
    },
    {
      "name": "Natural language processing",
      "score": 0.3437519073486328
    },
    {
      "name": "Cognitive psychology",
      "score": 0.3102903366088867
    },
    {
      "name": "Psychology",
      "score": 0.21956440806388855
    },
    {
      "name": "Social psychology",
      "score": 0.16543805599212646
    },
    {
      "name": "Programming language",
      "score": 0.16437864303588867
    },
    {
      "name": "Source code",
      "score": 0.12492716312408447
    },
    {
      "name": "Emotion recognition",
      "score": 0.12481847405433655
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    }
  ]
}