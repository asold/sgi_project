{
  "title": "Natural Language Processing for Digital Health in the Era of Large Language Models",
  "url": "https://openalex.org/W4409251317",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2165699372",
      "name": "Abeed Sarker",
      "affiliations": [
        "Emory University"
      ]
    },
    {
      "id": "https://openalex.org/A311940369",
      "name": "Rui Zhang",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A2156867267",
      "name": "YanShan Wang",
      "affiliations": [
        "University of Pittsburgh"
      ]
    },
    {
      "id": "https://openalex.org/A2131102361",
      "name": "Yunyu Xiao",
      "affiliations": [
        "Cornell University"
      ]
    },
    {
      "id": "https://openalex.org/A2107407687",
      "name": "Sudeshna Das",
      "affiliations": [
        "Emory University"
      ]
    },
    {
      "id": "https://openalex.org/A3083530330",
      "name": "Dalton Schutte",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A3186262181",
      "name": "David Oniani",
      "affiliations": [
        "University of Pittsburgh"
      ]
    },
    {
      "id": "https://openalex.org/A2126157100",
      "name": "Qianqian Xie",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2105258892",
      "name": "Hua Xu",
      "affiliations": [
        "Yale University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4288400169",
    "https://openalex.org/W4390849687",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W2925863688",
    "https://openalex.org/W4382246105",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W4368367885",
    "https://openalex.org/W4361282369",
    "https://openalex.org/W4385456320",
    "https://openalex.org/W3046375318",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4385567084",
    "https://openalex.org/W6796581206",
    "https://openalex.org/W4385620388",
    "https://openalex.org/W4381930847",
    "https://openalex.org/W4388725043",
    "https://openalex.org/W4308681662",
    "https://openalex.org/W4389520259",
    "https://openalex.org/W6854691855",
    "https://openalex.org/W4386741020",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4312220150",
    "https://openalex.org/W2971258845",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W4386120650",
    "https://openalex.org/W4385476046",
    "https://openalex.org/W3004612364",
    "https://openalex.org/W4233740607",
    "https://openalex.org/W4306798657",
    "https://openalex.org/W4322757661",
    "https://openalex.org/W4292947664",
    "https://openalex.org/W4388759569",
    "https://openalex.org/W4366769280",
    "https://openalex.org/W4386045865",
    "https://openalex.org/W4388116027",
    "https://openalex.org/W4388204324",
    "https://openalex.org/W4367310920",
    "https://openalex.org/W2979186816",
    "https://openalex.org/W4379769651",
    "https://openalex.org/W4226269440",
    "https://openalex.org/W2990571471",
    "https://openalex.org/W4388376534",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W2604410201",
    "https://openalex.org/W2944912855",
    "https://openalex.org/W4225272835",
    "https://openalex.org/W3134460066",
    "https://openalex.org/W2102742655",
    "https://openalex.org/W3104749795",
    "https://openalex.org/W2984843849",
    "https://openalex.org/W4392503764",
    "https://openalex.org/W3155976349",
    "https://openalex.org/W4390992325",
    "https://openalex.org/W4360991106",
    "https://openalex.org/W4389917881",
    "https://openalex.org/W6959429459",
    "https://openalex.org/W4387500346"
  ],
  "abstract": "Summary Objectives: Large language models (LLMs) are revolutionizing the natural language pro-cessing (NLP) landscape within healthcare, prompting the need to synthesize the latest ad-vancements and their diverse medical applications. We attempt to summarize the current state of research in this rapidly evolving space. Methods: We conducted a review of the most recent studies on biomedical NLP facilitated by LLMs, sourcing literature from PubMed, the Association for Computational Linguistics Anthology, IEEE Explore, and Google Scholar (the latter particularly for preprints). Given the ongoing exponential growth in LLM-related publications, our survey was inherently selective. We attempted to abstract key findings in terms of (i) LLMs customized for medical texts, and (ii) the type of medical text being leveraged by LLMs, namely medical literature, electronic health records (EHRs), and social media. In addition to technical details, we touch upon topics such as privacy, bias, interpretability, and equitability. Results: We observed that while general-purpose LLMs (e.g., GPT-4) are most popular, there is a growing trend in training or customizing open-source LLMs for specific biomedi-cal texts and tasks. Several promising open-source LLMs are currently available, and appli-cations involving EHRs and biomedical literature are more prominent relative to noisier data sources such as social media. For supervised classification and named entity recogni-tion tasks, traditional (encoder only) transformer-based models still outperform new-age LLMs, and the latter are typically suited for few-shot settings and generative tasks such as summarization. There is still a paucity of research on evaluation, bias, privacy, reproduci-bility, and equitability of LLMs. Conclusions: LLMs have the potential to transform NLP tasks within the broader medical domain. While technical progress continues, biomedical application focused research must prioritize aspects not necessarily related to performance such as task-oriented evaluation, bias, and equitable use.",
  "full_text": "IMIA Yearbook of Medical Informatics 2024\n229\n \n1. Introduction\nLanguage models encode characteristics \nof a language in a machine-readable form—\nas numeric vectors. Over approximately the \nlast decade, two major advances in language \nmodeling have transformed how they are \nused in natural language processing (NLP) \nresearch and applications:\n• the ability to capture word- or phrase-lev-\nel semantics (meanings) in the form \nof dense vectors (semantically similar \nlexical expressions appear close to each \nother in a vector space) [1]; and, later;\n• the ability to capture contextual varia -\ntions in meanings via transformer-based \nmodels [2].\nThe transition from (1) to (2) was partic-\nularly impactful—pretrained transformer \nmodels enabled systems to advance the state-\nof-the-art in many standardized NLP tasks \n[3,4]. Broadly speaking, current state-of-\nthe-art language models attempt to capture \nprobability distributions over sequences of \nwords in a given language. They do this by \nlearning patterns and relationships between \nwords from large amounts of text-based \ndata. Popular mechanisms for learning such \npatterns include masked language modeling \n(e.g., predicting masked words from their \ncontexts), and autoregressive pretraining \n[5] (e.g., next word prediction). Since such \npretraining methods are self-supervised, and \ntext-based data are abundant, it is possible to \nlearn powerful representations (e.g., BERT \n[2] and GPT-3 [6]). Starting with BERT, the \nability to further train existing pretrained \ntransformer models led to the creation of \nmany models—some customized for texts \nin restricted domains, such as the medical \ndomain [7,8]. Within this period that ob -\nserved unprecedented advances in language \nmodeling, early advances were primarily \nin encoder-only models, and more recent \nadvances have been in encoder-decoder or \ndecoder-only (generative) models [9].\nOver the last five years, the concept of large \nin terms of the size of a language model has \nevolved rapidly (Figure 1). ‘Large’ in large \nlanguage models (LLMs) refers to the size \nof the parameters learned by these language \nmodels, which are typically measured in \nbillions, and often trillions, these days. More \nparameters often allow a model to capture \na broader range of linguistic patterns and \nrelationships within the data it was trained \non, which can enhance its ability to process \nand generate texts. Consequently, larger \nmodels also generally perform better in \nNatural Language Processing for Digital \nHealth in the Era of Large Language Models\nAbeed Sarker1, Rui Zhang2, Yanshan Wang3, Yunyu Xiao4, Sudeshna Das1, Dalton Schutte2, \nDavid Oniani3, Qianqian Xie5, and Hua Xu5\n1 Emory University, A tlanta, GA, USA {abeed.sarker,sudeshna.das}@emory.edu\n2 University of Minnesota, Minneapolis, MN, USA {zhan1386,schut184}@umn.edu\n3 University of Pittsburgh, Pittsburgh, P A, USA {yanshan.wang,davidoniani}@pitt.edu\n4 Cornell University, New Y ork, NY, USA {yux4008@}med.cornell.edu\n5 Y ale University, New Haven, CT, USA {qianqian.xie,hua.xu}@yale.edu\nSummary\nObjectives: Large language models (LLMs) are revolutionizing \nthe natural language pro-cessing (NLP) landscape within health-\ncare, prompting the need to synthesize the latest ad-vancements \nand their diverse medical applications. We attempt to summarize \nthe current state of research in this rapidly evolving space.\nMethods: We conducted a review of the most recent studies \non biomedical NLP facilitated by LLMs, sourcing literature from \nPubMed, the Association for Computational Linguistics Anthology, \nIEEE Explore, and Google Scholar (the latter particularly for \npreprints). Given the ongoing exponential growth in LLM-related \npublications, our survey was inherently selective. We attempted \nto abstract key findings in terms of (i) LLMs customized for med-\nical texts, and (ii) the type of medical text being leveraged by \nLLMs, namely medical literature, electronic health records (EHRs), \nand social media. In addition to technical details, we touch upon \ntopics such as privacy, bias, interpretability, and equitability.\nResults: We observed that while general-purpose LLMs (e.g., \nGPT-4) are most popular, there is a growing trend in training \nor customizing open-source LLMs for specific biomedi-cal texts \nand tasks. Several promising open-source LLMs are currently \navailable, and appli-cations involving EHRs and biomedical \nliterature are more prominent relative to noisier data sources such \nas social media. For supervised classification and named entity \nrecogni-tion tasks, traditional (encoder only) transformer-based \nmodels still outperform new-age LLMs, and the latter are \ntypically suited for few-shot settings and generative tasks such as \nsummarization. There is still a paucity of research on evaluation, \nbias, privacy, reproduci-bility, and equitability of LLMs.\nConclusions: LLMs have the potential to transform NLP tasks \nwithin the broader medical domain. While technical progress \ncontinues, biomedical application focused research must prioritize \naspects not necessarily related to performance such as task-ori-\nented evaluation, bias, and equitable use.\nKeywords \nDeep Learning; Large Language Models; Natural Language Pro-\ncessing; Medical Informatics.\nYearb Med Inform 2023: \nhttp://dx.doi.org/10.1055/s-0044-1800750\nArticle published online: 2025-04-08\n230\nIMIA Yearbook of Medical Informatics 2024\nSarker et al.\nNLP tasks. In 2019, the largest model, to \nthe best of our knowledge, was T5 [10] \nwith up to 11 billion parameters. In com -\nparison, GPT-4 is speculated to have over \na trillion parameters. Among open-source \nalternatives, Meta’s LLaMa2 has 70 billion \nparameters [11]. The utility of LLMs has \nled to their adoption in biomedical research \nand application, and some LLMs have been \ncustomized or tuned specifically for medical \ntext. In the following sections, we provide \nan overview of the development and use of \nLLMs, specifically generative ones, within \nbiomedical NLP. The rest of this chapter is \norganized as follows: in section 2, we outline \nthe training of biomedical LLMs, currently \navailable biomedical LLMs, and their uses; \nin sections 3 to 5, we highlight the use of \nLLMs for distinct types of medical texts—\nliterature, electronic health records (EHRs), \nand social media, respectively; in section 6, \nwe discuss topics such as bias, reproducibili-\nty, and privacy; and we conclude the chapter \nin section 7 by outlining key limitations and \nfuture directions for medical LLMs.\n2. Adapting LLMs for the \nMedical Domain\n2.1. Training Medical LLMs\nAlthough generic LLMs like ChatGPT 1 \nand GPT-4 [12] have demonstrated their \nrobustness in diverse contexts, their perfor-\nmance on medical texts is often suboptimal \n[13,14], perhaps due to insufficient medi -\ncal domain-specific training data [15,16]. \nThis gap has catalyzed the emergence of \nmedical-specific LLMs that leverage med -\nical big data to optimize domain-specific \nperformance. Three strategies are typically \nemployed for creating medical domain-spe-\ncific LLMs [17,18]:\n• Pretraining from scratch [19]: This \napproach requires pretraining a new \nmedical LLM from the ground up using \na vast corpus of medical data, employing \n1  https://openai.com/blog/chatgpt [accessed: \n29 Jan, 2024]\nthe transformer architecture [20]. Tai -\nlor-made for medical applications, these \nmodels can develop a deep and nuanced \nunderstanding of medical language and \ncontexts. However, this strategy requires \nextensive resources in terms of data and \ncomputational power;\n• Continued pretraining [21]: This strategy \ninvolves taking a pre-existing, robust \ngeneral LLM and further training it on \nmedical-specific data. The key is to infuse \nthe general model with enough medical \ndata so that it can effectively represent/\nencode and generate medical information. \nContinued pretraining tasks employ the \nsame strategies as the base models, which \ncan be computationally intensive. Due to \nthe importance and popularity of contin-\nued pretraining, particularly for domain \nadaptation, computationally efficient \nstrategies such as low-rank adaptation \n(e.g., LoRA) have been proposed [22];\n• Instruction tuning [23]: This method \nfine-tunes general LLMs for the medical \ndomain using instruction tuning data, \nimproving model performance for med -\nical tasks by providing specific instruc -\ntions. The training data might include \ntask-based instructions, scenario-based \nqueries, or decision-making processes \nin a medical context. The effectiveness \nof instruction tuning heavily depends \non the quality and variety of the instruc-\ntional data.\n2.2. Emergence of Medical LLMs\nEncoder-only transformer models like \nBERT [2] led the way to the current gen -\nerative models we refer to as LLMs. Early \nadaptation of transformer models to the \nmedical domain came through the release \nof models like BioBERT [7], PubMedBERT \n[38], and ClinicalBERT [39]. BioBERT was \npretrained on the original BERT model using \n18 billion words from PMC and PubMed, \nPubMedBERT was pretrained from a ran -\ndomly initialized BERT model and using the \nentirety of PubMed data, and ClinicalBERT \n[39] was pretrained on a multi-center EHR \ndataset of diabetes patients. Explorations of \nthe scaling effects for BERT and GPT-2-style \nmodels with increasingly large numbers of \nmodel weights, up to 8.3 billion, demon -\nstrated that performance increased for both \nmodel types at extremely large sizes [40]. \nThis work was followed by pretraining \nFigure 1. Emergence of larger large language models (LLMs) over time. The vertical axis (parameter size) is represented in the log scale. For \nmodels with multiple size variants, only the smallest and largest are shown, for visual clarity. LLMs in green depict those pretrained on biomedical \ndatasets. Triangles are used to depict generative models with an encoder-decoder architecture. All other generative models are decoder-only.\n\nIMIA Yearbook of Medical Informatics 2024\n231\nNatural Language Processing for Digital Health in the Era of Large Language Models\nusing PubMed data from newly initialized \nmodels and models pretrained on general \ncorpora [41]. The resulting BioMegatron \n345M parameter model showed stronger \nperformance than PubMedBERT on multiple \nstandardized NLP tasks. These works paved \nthe way for new-age generative LLMs with \nbillions of parameters.\nWe summarize representative LLMs in \nTable 1. Among them, MedPaLM [24], Med-\nPaLM2 [42], ChatDoctor [25], MedAlpaca \n[26], Clinical Camel [28], AlpaCare [34], \nLLaV A-Med [31], MMedLM 2 [37] and \nMed-Flamingo [33] adopted the instruction \ntuning strategy. MedPaLM and MedPaLM2, \nwhich utilize the PaLM architecture with \n540 billion parameters, and PaLM2 as the \nbackbone, have been shown to be particu -\nlarly effective in medical question-answering \n(QA) tasks. AMIE [34] also uses PaLM2 \nas the backbone model, and is specifically \nfine-tuned for clinical applications, based \non medical QA and clinical texts. However, \nits large parameter size and closed-source \nnature make it challenging for widespread \ndeployment, particularly in resource-con -\nstrained settings. Models such as ChatDoctor \nand MedAlpaca, based on the open-sourced \nLLM LLaMA [11, 43], offer a more practical \nbalance. With a focus on QA and conversa-\ntions, they provide versatility while being \nless computationally intensive, making \nthem more accessible for diverse medical \napplications.\nGatorTron [44] and GatorTronGPT [29] \nrepresent the few medical LLMs that have \nbeen trained from scratch. GatorTronGPT is \nbased on the GPT-3 [45] framework, and it \nwas trained using 200 million clinical notes, \nand 124 NVIDIA DGX nodes.\nPMC-LLaMA [15], Clinical-LLaMA \n[28], Meditron [16] and Me LLaMA [36] \nrepresent models using the continued pre -\ntraining, or domain-adaptive pretraining \napproach. These models utilize foundation \nLLMs that are further enhanced with specific \nmedical knowledge. All these models use \nLLaMA2 as their backbone, given its strong \nperformance in general domain tasks and \nopen-source nature. PMC-LLaMA and Me \nLLaMA further combine this approach with \ninstruction tuning, demonstrating an effec -\ntive, hybrid strategy to adapt the LLaMA2 \nmodel to the medical domain.\n2.3. Characteristics of Medical LLMs\nIn the dynamic landscape of medical \nLLMs, a nuanced understanding of their \nvaried characteristics is crucial for effective \napplication. The distinctions between open \nand closed-source models, parameter size, \nand training strategies offer insights into \ntheir adaptability and utility in different \nmedical settings.\nOpen vs. Closed Source.  The contrast \nbetween open-source models such as Chat-\nDoctor and MedAlpaca and closed-source \nmodels like MedPaLM presents a fundamen-\ntal choice in the medical community. Open-\nsource models foster collaboration, enabling \nextensive enhancement and personalization. \nConversely, closed-source models may offer \nbetter professional support, user interfaces, \nand performance, but confine their devel -\nopment within proprietary boundaries, thus \nrestricting their availability and flexibility.\nParameter Size and Computational Com-\nplexity. Parameter size is a pivotal factor in \nthe selection of medical LLMs. Large mod-\nels like MedPaLM (540 billion parameters) \noffer in-depth understanding and complex \nreasoning capabilities. However, their de -\nployment demands substantial resources, \nmaking them less feasible for constrained \nenvironments. Conversely, smaller models \nin the 7B-13B range, such as MedAlpaca \nand AlpaCare, strike a balance between ef-\nficiency and effectiveness, facilitating easier \ndeployment.\nDomains, Modality, Language and \nUsage. In the realm of medical LLMs, the \nmajority of studies focus on published bio-\nmedical literature text, often overlooking \nclinical data and tasks. For example, mod -\nels like PMC-LLaMA and AlpaCare excel \nin the biomedical literature domain with \nrobust instruction-following capabilities. \nMeditron, though high-performing, lacks \nthe instruction-following ability, limiting its \nscope in instruction-driven tasks. Relatively \nfewer models, such as Clinical-LLaMA and \nGatorTronGPT, focus on the clinical domain. \nGatorTronGPT, trained on 82 billion clinical \ntexts and available in 5B and 20B parameter \nmodel sizes, demonstrates potential, yet its \ngeneralization abilities are constrained by its \nsize. Meanwhile, Clinical-LLaMA, primar-\nily trained on MIMIC-IV’s limited clinical \ntexts, concentrates on classification tasks, \nnot fully exploiting the capabilities of LLMs \nin a variety of clinical settings. Most medical \nLLMs focus on textual data, but emerging \nmodels like Med-Flamingo introduce mul -\ntimodal capabilities (e.g., via fine-tuning on \nimage caption data), incorporating image \nanalysis which is invaluable in fields like \nradiology or pathology. The language focus \nis predominantly English, with exceptions \nlike HuatuoGPT, which is tailored for Chi-\nnese, and MMedLM 2, which supports six \nmajor languages: Japanese, Spanish, French, \nRussian, English, and Chinese, indicating \na growing trend towards accommodating \nlinguistic diversity in medical LLMs. The \nchoice between these models should be \nbased on the specific needs of biomedical \nversus clinical applications, data modality, \nand the complexity of tasks involved.\n2.4. Evaluation of LLMs on \nBiomedical Tasks\nThe Biomedical Language Understanding \nEvaluation (BLUE) framework was pro -\nposed to facilitate a biomedical counterpart \nto the popular General Language Under -\nstanding Evaluation (GLUE) framework \n[46]. Comprising five tasks on ten biomed-\nical corpora, resources from BLUE have \nbeen partially adopted by some models as \npart of their evaluation [47,48]. Since the \ntasks on which medical LLMs are trained \nare diverse, the evaluation metrics vary. \nDue to this, there is currently no objective \nmeasure to help select an LLM for a spe -\ncific medical task beyond choosing models \nthat have been specifically pre-trained on \ndomain-specific text. Human evaluation of \nmodel outputs has been used in addition to \ngeneral language model evaluation metrics \nlike BLEU and ROUGE [49,50] for medi -\ncal text summarization. Similarly, concept \nextraction from EHRs has been studied \nthrough qualitative evaluation [51]. Akin \nto the BLUE framework, the MultiMedQA \nframework comprising nine tasks for quan-\ntitative evaluation in addition to additional \n\n232\nIMIA Yearbook of Medical Informatics 2024\nSarker et al.\nTable 1. A detailed comparison of medical LLMs available at the time of writing. This comparative analysis spans multiple dimensions, providing a holistic view of each model’s characteristics and capabilities. Key aspects \nof comparison include: backbone model, model size, training strategy, domain-specific data used and data size, accessibility, language, and release date. IFT : instruction fine-tuning; CPT : continued pretraining; SPT : \npretraining from scratch; RLMF: reinforcement learning with mixed feedback; QA: question answering. For MedPaLM2, there is no information about the data size and model size of its backbone model PaLM2 (the same \nbackbone model for AMIE). Models without explicit license terms that can be accessed are denoted by a checkmark while models without access are denoted by ‘X’. Consumer-Mediated Health Information Exchange: \nAuthorize Direct Transmission. \nModel Backbone Size Strategy Data Data Size Modality License Access Language Release date\nMedPaLM [24] PaLM 540B IFT QA - Text X English 12/26/22\nChatDoctor [25] LLaMA 7B IFT Conversation 100K Text Apache 2.0 English 03/24/23\nMedAlpaca [26] LLaMA 7B, 13B IFT QA 160K Text GNU GPL v3.0 English 04/14/23\nPMC-LLaMA [15] LLaMA, LLaMA2 7B, 13B CPT+IFT Literature, book, conversa-\ntion, QA, knowledge graph 79B, 514K Text Apache 2.0 English 04/25/23\nMedPaLM2 [27] PaLM2 - IFT QA - Text X English 05/16/23\nClinical Camel [28] LLaMA2 13B, 70B IFT Conversation, QA 104K Text GNU Affero GPL\nv3.0 English 05/19/23\nGatorTronGPT\n[29]\nGPT-3 archi-\ntecture 5B, 20B SPT General and clinical text 82B Text Apache 2.0 English 05/24/23\nHuatuoGPT [30] Baichuan, Ziya 7B, 13B IF-\nT+RLMF Conversation, QA - Text Apache 2.0 Chinese 05/25/23\nLLaVA-Med [31] LLaVA 13B IFT biomedical image-text 630K Text, image Microsoft \nResearchLicense English 06/01/23\nClinical-LLaMA \n[32] LLaMA2 7B CPT MIMIC-IV - Text X English 07/12/23\nMed-Flamingo \n[33] Flamingo 9B IFT General and biomedical \nimage-text >0.01B Text, image √ English 07/27/23\nAlpaCare [34] LLaMA2 7B, 13B IFT Biomedical conversation 52K Text Apache 2.0 English 10/23/23\nMeditron [16] LLaMA2 7B, 70B CPT General and biomedical text 48B Text Apache 2.0 English 11/27/23\nAMIE [35] PaLM2 - IFT QA, clinical text 110K Text X English 01/11/24\nMe LLaMA [36] LLaMA2 13B, 70B CPT+IFT QA, clinical text 129B,\n214K Text\nPhysioNet Creden-\ntialed HealthData \nLicense 1.5.0\nEnglish 02/20/24\nMMedLM2 [37] InternLM, \nBLOOM 7B IFT QA, clinical text 25.5B Text cc-by-4.0 Multilingual 02/26/24\n\nIMIA Yearbook of Medical Informatics 2024\n233\nNatural Language Processing for Digital Health in the Era of Large Language Models\ntasks for qualitative evaluation has been \nproposed [52]. The MedEval testbed focuses \non covering a wider variety of human body \nparts, as compared to existing frameworks \nthat prioritize task coverage [53].\nBeyond the English language, MedBench \n[54] and MMedBench [37] have been intro-\nduced as evaluation frameworks for Chinese \nand multilingual medical LLMs, respective-\nly. BioMistral2, a collection of open-source \npretrained biomedical LLMs, also features \na multilingual evaluation framework in \nseven languages, although the drawbacks \nof auto-translation remain as they translate \nan English benchmark into seven languag -\nes. The framework CRAFT-MD 3 focuses \nexclusively on the task of conversational \nreasoning for evaluating medical LLMs. \nSince evaluation of LLMs is an evolving \narea of research, just like LLMs themselves, \nnovel evaluation strategies (such as halluci-\nnation evaluation [55]) are actively being \nproposed, and we anticipate a trend of more \nstandardized and converging benchmarking \nof medical LLMs in the future.\n3. LLMs for Medical \nLiterature\nMost training and application of medical \nLLMs have focused on text from the medical \nliterature. In this section, we briefly review \nkey NLP tasks, highlight some of the most \nimportant models that were trained on the \nbiomedical literature, discuss their applica-\ntions to specific tasks, and address challenges \nassociated with their use.\n3.1. LLM Applications in \nBiomedical Literature\nSeveral NLP tasks have relevance when \napplying LLMs to the biomedical litera -\nture. Named Entity Recognition (NER) is \nthe identification of words that belong to \na class of interest (drugs, symptoms, etc.). \nRelation extraction is identifying relation -\n2 https://arxiv.org/abs/2402.10373\n3 https://www.medrxiv.org/content/10.1101/2\n023.09.12.23295399v2\nships between named entities from the \nliterature (e.g., drug A treats condition Z). \nLiterature-based discovery is the prediction \nof new relationships between entities using \nexisting entities and relationships extracted \nfrom a corpus. Other tasks include question \nanswering (QA) where the model responds \nto a query given some biomedical text as \ninput, information retrieval to identify and \nextract relevant information from text, and \nsummarization to provide a concise descrip-\ntion of larger biomedical text.\n3.1.1. Information Extraction\nLLMs have shown moderate to good, \nthough not state-of-the-art, performance on \nNER. For example, a GPT model augmented \nwith a biomedical knowledge graph was \nable to obtain respectable F1 scores [56]. \nThe same study also showed that LLMs \nwere able to achieve impressive scores for \nzero-shot NER. There is some potential for \nLLMs to be used for drug repurposing, a \nliterature-based discovery task, as recent \nresearch has demonstrated that even the \ngeneric GPT-4 model can perform well on \nthis task [57] by fine-tuning the model with \nprompts that are augmented with knowledge \nfrom a biomedical knowledge graph. Recent-\nly, there have been explorations into using \nLLMs, such as MedLLaMA, for relation \nextraction and knowledge graph construction \n[58]. While LLMs can be used for informa-\ntion extraction, a recent survey found that \nPubMedBERT often outperformed GPT-3.5 \nand GPT-4 on information retrieval-focused \ntasks [59]. These studies demonstrated that \nthere is room for improvement on these tasks \nfor LLMs.\n3.1.2. Question Answering\nLLMs have demonstrated exceptional \nperformance on a wide variety of QA-fo -\ncused tasks. ChatDoctor, PMC-LLaMA, \nMedAlpaca [26] have all demonstrated \nstrong performance on a range of biomedical \nQA datasets. This suggests that these models, \ntuned on the literature, may be useful for in-\nformation retrieval and for reducing the time \nphysicians need to spend looking through \nPubMed to find answers to their questions. \nMedAlpaca, in particular, has achieved \nstate-of-the-art zero-shot performance in \nanswering questions from the three parts of \nthe United States Medical Licensing Exam \nseries [26].\n3.1.3. Information Retrieval\nCombining LLMs with external databas-\nes for information retrieval and response \ngeneration, retrieval augmented generation, \nhas shown promise in improving the speci-\nficity of answers provided to users [60]. As \ndiscussed later in this survey paper, hallu -\ncinations are a problem with any LLM but \ncan be particularly hazardous in a medical \ncontext where a hallucination could lead to \nerroneous advice generation. However, this \ncan be mitigated by the use of knowledge \ngraphs to enhance reasoning and ground \nLLMs to decrease the likelihood of hallu -\ncinations [57].\n3.1.4. Summarization\nRecent work has shown that LLMs can \neffectively be fine-tuned on small amounts of \ndomain-specific data to produce high-quality \nsummarizations of biomedical research ab-\nstracts [61]. A sample of 175 abstracts from \nthe specialized COVID-19 dataset, CORD-\n19 [62], was used with GPT-3.5 and Davinci \n(the initial model of the GPT-3 series) to pro-\nduce a dataset of synthetic prompts that were \nused to successfully fine-tune other LLMs to \nproduce summarizations of abstracts.\n4. LLMs for Electronic \nHealth Records\nLarge-scale data mining from free text \nnotes in EHRs and extracting meaningful \ninformation has been a challenge for NLP \nresearch over the years, and LLMs present \nsubstantial opportunities to move the state-\nof-the-art forward. Consequently, LLMs \nhave found widespread use in the context \nof EHRs. Here, we outline a subset of key \napplications of LLMs for EHR data.\n\n234\nIMIA Yearbook of Medical Informatics 2024\nSarker et al.\n4.1. Clinical Decision Support \nSystems\nClinical Decision Support Systems \n(CDSSs) enhance medical decision-making \nby providing targeted clinical knowledge, \npatient information, and other health infor-\nmation [63,64]. Recently, LLMs have shown \ngreat potential as core CDSS components. \nLLMs trained or fine-tuned on texts from \nEHRs can capture high-quality represen -\ntations of input texts that can be used for \ntasks such as diagnosis prediction [65], \nclinical trial outcome measurement [66], and \nin-hospital mortality prediction [67], to name \na few. In-context learning capabilities [6,68] \nmake generative LLMs inherently interac -\ntive, allowing for direct conversations and \nQA sessions between physicians and LLMs. \nSuch interactive artificial intelligence (AI) \nsystems built on NLP technology was largely \ninfeasible prior to the recent advances in \ngenerative LLMs. Chatbots have become \na common component in new-age CDSS \ndesigns with generative LLM integration \n[69,70]. A number of studies have already \ndemonstrated the effectiveness of using \nsuch chatbots for clinical decision support, \nparticularly illustrating their potential to im-\nprove productivity in healthcare settings and \nfacilitate better health outcomes [29,71,72]. \nWhile research in this space is still early, the \noverwhelmingly promising results suggest \nthat chatbots based on generative LLMs \nand trained on EHR texts will see signifi -\ncant adoption across healthcare systems. In \nterms of specific applications, text-to-text \nLLMs have found use in chest X-ray report \nsummarization [73], summarization and \nclassification of medical dialogues [74], and \ndiagnostic reasoning [75], to name a few. \nDue to the many possible applications of \nLLMs on EHR texts, as mentioned earlier in \nthis article, a number of models have been \nproposed that have been trained or fine-tuned \non EHR-specific data—the most notable of \nthem perhaps being GatorTron [44].\n4.2. Revenue Cycle Optimization\nRevenue Cycle Management (RCM) is a \ncritical process for healthcare organizations \nthat typically consists of pre-encounter, \nintra-encounter, and post-encounter steps \n[76]. Revenue Cycle Optimization (RCO) \nanalyzes each of these steps to identify areas \nthat can increase revenue, reduce expenses, \nand improve cash flow. Therefore, RCO \nhelps streamline RCM, resulting in efficient \nbilling processes, reduced claim denials, and \ntimely reimbursements, which can signifi -\ncantly improve the overall quality of care, \nultimately driving better health outcomes \n[77]. Traditionally, RCO is a manual, highly \ncomplex endeavor with plenty of opportu -\nnities to augment human decision-making \nwith AI.\nGenerative LLM-based chatbots can \nhelp with pre-encounter and inter-encounter \ntasks, including appointment scheduling, \npatient registration, and prior authorization. \nGiven the politeness and empathy that can \nbe infused into these chatbots in simulated \nhealthcare settings [78], their use in patient \ninteractions holds great promise. Accord -\ning to a 2019 report [79], payment errors \namount to hundreds of billions of dollars in \nunnecessary spending annually. To this end, \nNYUTron has shown that EHR-trained gen-\nerative LLMs can predict insurance denials, \nreducing billing complexity and payment \nerrors [80].\n4.3. Translational Research\nTranslational research is defined as “the \nprocess of applying ideas, insights and dis-\ncoveries generated through basic scientific \ninquiry to the treatment or prevention of \nhuman disease” [81]. The application of \nAI-driven methods to translational research \npresents a clear opportunity for multidis -\nciplinary collaborations, with teams com -\nprising diverse domain experts, such as \ncomputer scientists, mathematicians, and \nclinicians. Indeed, many successful transla-\ntional research efforts have had authors with \nwide-ranging research backgrounds [82-84]. \nThis trend is likely to continue in the case \nof LLMs trained on EHRs, with researchers \ndiscovering novel applications to medicine \n[85]. Clinical trials, the gold standard for \nevaluating new treatments, are critical in \ntranslational research. Feasibility studies \nbefore conducting clinical trials leverage \nLLMs to analyze patient records, aiding in \nthe assessment of a trial’s practicality by \nquickly determining if sufficient suitable \nparticipants are available. This accelerates \nthe early stages of research. LLMs can also \nanalyze EHRs to extract and normalize \nmedical concepts to identify potential trial \nparticipants. Systems like EliIE [86] could \nbe enhanced by LLMs, facilitating patient \ncohort definition and even enabling in silico \ntrials. Moreover, LLMs can play a crucial \nrole in patient recruitment, swiftly analyz -\ning clinical documents in EHRs to match \npatients with appropriate trials, thereby \nstreamlining recruitment and ensuring that \ntrial opportunities are maximized. Lastly, \nLLMs can aid in analyzing clinical trial \ncriteria and matching patients with the most \nsuitable trials, offering patients access to \nthe latest treatment options, for example, \nTrialGPT [87].\n5. LLMs for Health-\nrelated Social Media Data\nSocial media chatter contains an abun -\ndance of health-related information as \nsubscribers often discuss such topics with \ntheir peers. A small survey, for example, \nshowed that over 80% of cancer patients \nconducted disease-related communication \nwith others over social media [88]. Often, \nhealth-related information available from \nsocial media are not available from any \nother sources [89]. Knowledge relevant to \nhealth can be acquired from social media in \nclose to real-time [90], at scale, and often \nfrom hard-to-reach populations [91]. NLP \nof health-related social media texts has \nproven difficult (relative to, for example, \ntext from medical literature) over the years \nfor various data-level characteristics, such \nas misspellings and colloquial and evolving \nlanguage [92]. Despite the difficulties asso-\nciated with NLP of social media data, recent \nprogress has demonstrated their utility for \ncomplex tasks, such as targeted public health \nsurveillance [93] and behavior analysis [94].\nLiterature on the application of generative \nLLMs for social media based health-related \ntasks is sparse, with only a handful of pa -\npers published to date. This is unsurprising \n\nIMIA Yearbook of Medical Informatics 2024\n235\nNatural Language Processing for Digital Health in the Era of Large Language Models\nsince applications of new NLP technology \nwithin the health space typically target do -\nmain-specific text from sources other than \nsocial media such as medical literature. Once \nthese methods are mature, they are applied \nand often customized for social media texts, \nwhich represent an array of additional NLP \nchallenges. We outline some important re -\ncent research contributions, noting that most \nlanguage models in application today are still \ntransformer-based encoder models, which \noutperform new-age generative models in \nbenchmarking experiments [95].\n5.1. LLMs for Mental Health\nSocial media sources encapsulate a trove \nof knowledge regarding mental health, \nand, consequently, a substantial chunk \nof health-related NLP research involving \nsocial media data has focused on mental \nhealth-related topics [96]. With the emer -\ngence of new-age LLMs, the trend has \nbeen no different. A very recent contribu -\ntion is the MentaLLaMA model [97]. The \npaper introducing the model also presents \nthe interpretable mental health instruction \ndataset built from social media data. The \nMentalLLaMA model is shown to perform \nclose to supervised state-of-the-art discrim-\ninative models while providing reasonable \nexplanations. Despite less than optimal \nperformance, MentaLLaMA represents an \nexciting branching of open-source LLMs—\nthe first to specifically address health-related \nsocial media text. A similar theme of using \nsocial media data for providing conversa -\ntional text assistance pertaining to mental \nhealth issues is demonstrated by Psy-LLM \n[98]. They use data from the Chinese social \nmedia platforms Tianya, Yixinli, and Zhihu. \nInevitably, many more models customized \nfor targeted health-related topics over social \nmedia data will follow suit.\nXu et al. [99] present a comparative \nevaluation of zero-shot, few-shot (examples \ninserted into the prompt), and instruction \nfine-tuned LLMs on mental health datasets \nobtained from the social media platform \nReddit. Their fine-tuned models Men -\ntal-Alpaca, based on Alpaca [100], and \nMental-FLANT5, based on the T5 frame -\nwork [10], outperform GPT-3.5 and GPT-4. \nThese results demonstrate the promise of \nsubdomain-specific LLMs in digital health.\n5.2. LLMs for Health Surveillance\nIdentifying and monitoring disease out -\nbreaks in real-time with social media has \nbeen useful for health institutions, including \nthe World Health Organization [101]. Al -\nthough the use of LLMs in infoveillance is \nstill nascent, the ability of LLMs to extract \nsymptoms from social media posts has \nalready been explored [102] in the context \nof COVID-19. The study showed that with \nprompt engineering, GPT-3.5-Turbo and \nGPT-4 can achieve high precision and recall. \nThe authors also reported using ChatGPT as \nan aid for prompt engineering to arrive at \nthe final prompt used to compare different \nLLMs, including Google Bard. Such use of \nLLMs to aid in using other LLMs is likely \nto rise in the future.\n5.3. LLMs for Combating Health \nMisinformation\nThe rapid spread of misinformation \nthrough social media is an active topic of \nconcern among the broader healthcare com-\nmunity [101]. With LLMs generating text \nthat is indistinguishable from those written \nby humans, there is notable risk of misuse of \nLLMs to generate misinformation at scale. \nChen et al. [103] point out the dichotomy \nof LLM usage in both promoting as well as \ncombating health-related misinformation on \nsocial media platforms. They highlight the \nuse cases of detecting health-related misin-\nformation by augmenting LLMs with exter-\nnal knowledge bases. With social media plat-\nforms integrating LLMs more closely into \ntheir ecosystem, misinformation intervention \ntechniques such as LLM-generated factual \ncounter-misinformation responses are on \nthe horizon. Xiao et al. [104] take a step in \nthis direction by creating Jennifer, a chatbot \nto provide expert-sourced answers to com -\nmonly asked questions about COVID-19. \nThey deployed their chatbot on Facebook, \nin addition to other websites, and found that \nJennifer was able to help users find more \naccurate answers to COVID-19-related \nqueries. They proposed using LLMs to com-\nplement their expert-sourcing framework \nfor faster deployment in future versions of \ntheir chatbot.\n5.4. LLMs for Health Opinion \nMining\nThe massive amount of opinion gener -\nated on social media platforms makes them \nlucrative for gauging public sentiments \ntoward health policies as well as early de -\ntection of rapidly changing health threats \nlike COVID-19. Tran et al. [105] utilized \nLLMs for COVID-19-related public opinion \nmining using Twitter (X) data from Japan. \nAlthough the LLMs exhibited high perfor -\nmance variability in zero-shot settings with \ndifferent prompt designs, the study showed a \nuseful application of LLMs in digital health.\n6. LLMs: Challenges, \nLimitations, and Risks\n6.1. Privacy and Data Security\nClosed-source LLMs such as ChatGPT \nhave seen substantial rise in popularity ow-\ning to their ease of use. These LLMs invoke \nAPI4 calls to the model hosted off-site with \npossible personally identifiable information \n(PII) being transmitted. Some healthcare \ninstitutions have established internal guide-\nlines to prevent such off-site transmission of \ndata, while some have reached agreements \nwith service providers to securely transfer \nPII. Much like LLMs themselves, privacy \nand data security standards associated with \nLLM use in healthcare settings are evolv -\ning. Mesko and Topol [106] highlight the \nneed for informed patient consent for the \nuse of LLMs in their personal healthcare \nmanagement.\n4  Application Programming Interface; for \ncommunication between a server and the \nclient/user.\n\n236\nIMIA Yearbook of Medical Informatics 2024\nSarker et al.\n6.2. Bias and Fairness\nSeveral studies have found that LLMs \ndo not generalize well across distinct demo-\ngraphics. GPT-4 has been shown to exhibit \nbias when diagnosing people of different \ngenders, races, and ethnicities [107]. Reg -\nulation of LLMs, particularly in healthcare, \nhas been suggested [106] as a means to \nprotect vulnerable populations from harm. \nThe sparsity of multilingual medical LLMs \nis another factor contributing to geographical \nbias in the adoption of medical LLMs. The \nMMedC medical corpus covering five lan -\nguages, CHIMED-GPT for Chinese, and the \nbilingual mixture-of-experts LLM BiMedX \nfor Arabic medical tasks are noteworthy \nattempts to extend the application of LLMs \nin more languages. Perhaps the most impact-\nful stride toward alleviating geographical \ndisparities is demonstrated by Apollo [108]. \nCovering a population of 6 billion through \nsix languages, Apollo is further distinguished \nby being lightweight.\n6.3. Interpretability, Explainability, \nTransparency, and Equitable AI\nA major issue hindering the adoption \nof LLM-based technologies in healthcare \nis the lack of transparency. LLMs may ex -\nhibit opacity across different dimensions: \nclosed-source models, lack of information \non training data and procedures, and limited \ninterpretability and explainability. This lack \nof transparency adds to the issue of account-\nability, which is paramount in medicine. Al-\nthough interventions such as the foundation \nmodel transparency index [109] have been \nproposed, the success of such approaches \nlargely relies on their adoption.\nThe compute-intensive nature of large \nmodels poses challenges to equitable use \nof AI. For large models, it is necessary to \nutilize clusters of GPUs for time-efficient \nfine-tuning and inference. For example, at \nfull precision, LLaMa-v2 70B requires at \nleast 8 A100 NVDIA GPUs for tuning. Not \nall researchers and developers have access \nto the resources necessary to tune or deploy \nthese models, which inevitably leads to in -\nequity in research and application of LLMs \nin medicine. Some techniques in “TinyML” \nhave been proposed to reduce the footprint \nof these large models and include techniques \nsuch as training subsets of weights (LoRA), \nquantization, and precision reduction [110].\n6.4. Evaluation of LLM \nPerformance, Reproducibilty, and \nDeployability\nIn terms of NLP tasks, multiple studies \nhave shown that for tasks such as supervised \nclassification and information extraction, \ntransformer-based models still outperform \nLLMs when large labeled training data is \navailable. LLMs, however, typically per -\nform better for these tasks in low-/zero-shot \nsettings [56,111]. For generative tasks such \nas summarization and QA, LLMs have \ndemonstrated the greatest improvements \ncompared to earlier methods [75, 112]. Xu et \nal. [99] stress, in the context of mental health, \nthat despite the impressive performance of \nLLMs, their deployability for digital health \napplications remains in question. For deploy-\nment in healthcare, LLMs must be evaluated \non aspects beyond accuracy or other intrin-\nsic evaluation metrics. Targeted pre- and \npost-deployment evaluations of fairness, \nbias, and interpretability are essential, along \nwith robust strategies for effective identifica-\ntion and mitigation of ethical concerns [107].\nReproducibility can often be challenging \nto ensure since LLM outputs may be non-de-\nterministic. This may particularly happen \nwith API-based LLMs since the closed-\nsource back-end models may change over \ntime, rendering past outputs irreproducible. \nAdditionally, open-source models may lose \ntheir initial capabilities when further tuned \non new data, a problem known as catastroph-\nic forgetting [21,113,114].\nFinally, LLMs used for generative tasks \npose a risk for hallucinations that can be at \nbest annoying or at worst dangerous in the \ncase of biomedical text generation for QA \nor summarization. Hallucinations can be \nparticularly hard to predict and may remain \nundiscovered if models are not evaluated rig-\norously. The ease of use of API-based mod-\nels like GPT-4 particularly make non-expert \nresearchers (i.e., those without substantial \nexperience in NLP research) susceptible to \ninterpreting coherent responses generated by \nLLMs to be accurate information. Extensive \nintrinsic and extrinsic evaluations, led by \nresearchers with substantial NLP expertise, \nare necessary to mitigate the dangers of \nhallucination.\n7. Concluding Remarks\nNotwithstanding the challenges associ -\nated with the use of LLMs in biomedical \nNLP tasks, there remains vast potential for \nintegrating LLMs in research, education, \nand clinical care [115]. Retrieval augmented \ngeneration has been gaining popularity as a \nmethod to reduce hallucinations [116].\nPrompt modification, integration of exter-\nnal data sources, and leveraging knowledge \ngraphs for reasoning augmentation have \nalso been found to mitigate hallucinations \n[117]. Evaluating general purpose LLMs for \ntrustworthiness across several dimensions \nsuch as reliability, safety, and resistance to \nmisuse has been proposed [118]. Designing \ntrustworthiness criteria specific to healthcare \nsystems can benefit the advancement of \nmedical LLMs. As more effective approach-\nes for mitigating the limitations associated \nwith LLMs are developed, their adoption in \nbiomedical NLP tasks is expected to increase \nfurther. We expect to see a trend of more eq-\nuitable dissemination of LLM infrastructure \nwith smaller, less resource-intensive models \nin the future. Biomedical subdomain-specific \nmodels, similar to MentalLlaMA for the sub-\ndomain of mental health, are also envisaged.\nLLMs have brought about a new par -\nadigm in biomedical NLP research and \napplication, enabling us to make substantial \nprogress on problems that appeared un -\nsolvable even in the recent past (e.g., QA). \nThus, the proliferation of LLM use in digital \nhealth is largely desirable, and the future is \npromising. However, it is critical to estab -\nlish and implement necessary guardrails for \nresponsible usage to mitigate the possibility \nof unintended harm.\n\nIMIA Yearbook of Medical Informatics 2024\n237\nNatural Language Processing for Digital Health in the Era of Large Language Models\nReferences\n1. Mikolov T, Sutskever I, Chen K, Corrado GS, \nDean J. Distributed Represen-tations of Words \nand Phrases and their Compositionality. In: \nBurges CJ, Bottou L, Welling M, Ghahramani \nZ, Weinberger KQ, editors. Advances in Neural \nInformation Processing Systems. vol. 26. Cur -\nran Associates, Inc.; 2013. https://proceedings.\nneurips.cc/paper_files/paper/2013/file/9aa -\n42b31882ec039965f3c4923ce901b-Paper.pdf\n2. Devlin J, Chang M, Lee K, Toutanova K. \nBERT: Pre-training of Deep Bidirectional \nTransformers for Language Understanding. \nCoRR. 2018;abs/1810.04805. http://arxiv.org/\nabs/1810.04805\n3. Mahajan D, Liang JJ, Tsou CH, Ozlem Uzuner. \nOverview of the 2022 n2c2 shared task on con-\ntex-tualized medication event extraction in cli -\nnical notes. Journal of Biomedical Informatics. \n2023;144:104432. https://doi.org/10.1016/j.\njbi.2023.104432\n4. Klein AZ, Banda JM, Guo Y , Schmidt AL, Xu D, \nAmaro IF, et al. Overview of the 8th social media \nmining for health applications (SMM4H) shared \ntasks at the AMIA 2023 annual symposium. \nJournal of the American Medical Informatics \nAssociation. 2024 01:ocae010. https://doi.\norg/10.1093/jamia/ocae010\n5. Yang Z, Dai Z, Yang Y , Carbonell J, Salakhutdi-\nnov RR, Le QV . XLNet: Generalized Autoregres-\nsive Pretraining for Language Understanding. \nIn: Wallach H, Larochelle H, Beygelzimer A, \nd’Alché-Buc F, Fox E, Garnett R, editors. Advan-\nces in Neural Information Processing Systems. \nvol. 32. Curran Associates, Inc.; 2019. https://\nproceedings.neurips.cc/paper_files/paper/2019/\nfile/dc6a7e655d7e5840e66733e9ee67cc69-Pa -\nper.pdf\n6. Brown T, Mann B, Ryder N, Subbiah M, Kaplan \nJD, Dhariwal P, et al. Language Models are Few-\nShot Learners. In: Larochelle H, Ranzato M, \nHadsell R, Balcan MF, Lin H, editors. Advances \nin Neural Information Processing Systems. vol. \n33. Curran Associates, Inc.; 2020. p. 1877-901. \nhttps://proceedings.neurips.cc/paper_files/\npaper/2020/file/1457c0d6bfcb4967418bfb8ac -\n142f64a-Paper.pdf\n7. Lee J, Yoon W, Kim S, Kim D, Kim S, So CH, et \nal. BioBERT: a pre-trained biomedical language \nrep-resentation model for biomedical text mi -\nning. Bioinformatics. 2020 Feb;36(4):1234-40. \nhttp://doi.org/10.1093/bioinformatics/btz682\n8. Alsentzer E, Murphy J, Boag W, Weng WH, Jindi \nD, Naumann T, et al. Publicly Available Clinical \nBERT Embeddings. In: Rumshisky A, Roberts \nK, Bethard S, Naumann T, editors. Proceedings \nof the 2nd Clinical Natural Language Processing \nWorkshop. Minneapolis, Minnesota, USA: Asso-\nciation for Computational Linguistics; 2019. p. \n72-8. https://aclanthology.org/W19-1909\n9. Min B, Ross H, Sulem E, Veyseh APB, Nguyen \nTH, Sainz O, et al. Recent advances in natural \nlan-guage processing via large pre-trained \nlanguage models: A survey. ACM Compu -\nting Surveys. 2023;56(2):1-40. https://doi.\norg/10.1145/3605943\n10. Raffel C, Shazeer N, Roberts A, Lee K, Narang \nS, Matena M, et al. Exploring the Limits of \nTransfer Learning with a Unified Text-to-Text \nTransformer. CoRR. 2019;abs/1910.10683. \nhttp://arxiv.org/abs/1910.10683\n11. Touvron H, Martin L, Stone K, Albert P, \nAlmahairi A, Babaei Y , et al. Llama 2: Open \nfoundation and fine-tuned chat models. arXiv \npreprint arXiv:230709288. 2023. https://arxiv.\norg/abs/2307.09288\n12. OpenAI. GPT-4 Technical Report; 2023. https://\narxiv.org/abs/2303.08774\n13. Dave T, Athaluri SA, Singh S. ChatGPT in \nmedicine: an overview of its applications, advan-\ntages, limitations, future prospects, and ethical \nconsiderations. Frontiers in Artificial Intelligen-\nce. 2023;6:1169595. https://doi.org/10.3389/\nfrai.2023.1169595\n14. Sallam M, Salim N, Barakat M, Al-Tammemi \nA. ChatGPT applications in medical, dental, \npharmacy, and public health education: A de -\nscriptive study highlighting the advantages and \nlimitations. Narra J. 2023;3(1):e103-3. https://\ndoi.org/10.52225/narra.v3i1.103\n15. Wu C, Zhang X, Zhang Y , Wang Y , Xie W. \nPMC-LLaMA: Towards Building Open-source \nLanguage Models for Medicine. arXiv preprint \narXiv:230414454. 2023. https://arxiv.org/\nabs/2304.14454\n16. Chen Z, Cano AH, Romanou A, Bonnet A, Mat-\noba K, Salvi F, et al. MEDITRON-70B: Scaling \nMedical Pretraining for Large Language Models. \narXiv preprint arXiv:231116079. 2023. https://\narxiv.org/abs/2311.16079\n17. Wang B, Xie Q, Pei J, Chen Z, Tiwari P, Li Z, et \nal. Pre-trained language models in biomedical \ndo-main: A systematic survey. ACM Com -\nputing Surveys. 2023;56(3):1-52. https://doi.\norg/10.1145/3611651\n18. Zhao WX, Zhou K, Li J, Tang T, Wang X, Hou Y , \net al. A survey of large language models. arXiv \npre-print arXiv:230318223. 2023. https://arxiv.\norg/abs/2303.18223\n19. Gu Y , Tinn R, Cheng H, Lucas M, Usuyama N, \nLiu X, et al. Domain-specific language model \npre-training for biomedical natural language \nprocessing. ACM Transactions on Computing for \nHealthcare (HEALTH). 2021;3(1):1-23. https://\ndoi.org/10.1145/3458754\n20. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, \nJones L, Gomez AN, et al. Attention is all you \nneed. Advances in neural information proces -\nsing systems. 2017;30. https://papers.nips.cc/\npaper/7181-attention-is-all-you-need\n21. Ke Z, Shao Y , Lin H, Konishi T, Kim G, Liu \nB. Continual Pre-training of Language Models. \nIn: The Eleventh International Conference on \nLearning Representations; 2022. https://doi.\norg/10.18653/v1/2022.emnlp-main.695\n22. Hu EJ, Shen Y , Wallis P, Allen-Zhu Z, Li Y , Wang \nS, et al. LoRA: Low-Rank Adaptation of Large \nLanguage Models. In: International Conference \non Learning Representations; 2022. https://\nopenreview.net/forum?id=nZeVKeeFYf9\n23. Shah NH, Entwistle D, Pfeffer MA. Creation \nand Adoption of Large Language Models in \nMedicine. JAMA. 2023 09;330(9):866-9. https://\ndoi.org/10.1001/jama.2023.14217\n24. Singhal K, Azizi S, Tu T, Mahdavi SS, Wei \nJ, Chung HW, et al. Large language models \nencode clinical knowledge. arXiv preprint \narXiv:221213138. 2022. https://arxiv.org/\nabs/2212.13138\n25. Li Y , Li Z, Zhang K, Dan R, Jiang S, Zhang \nY . ChatDoctor: A Medical Chat Model Fine -\nTuned on a Large Language Model Meta-AI \n(LLaMA) Using Medical Domain Knowledge. \nCureus. 2023;15(6). https://doi.org/10.7759/\ncureus.40895\n26. Han T, Adams LC, Papaioannou JM, Grundmann \nP, Oberhauser T, Löser A, et al. MedAlpaca– An \nOpen-Source Collection of Medical Conver -\nsational AI Models and Training Data. arXiv \npreprint arXiv:230408247. 2023. https://arxiv.\norg/abs/2304.08247\n27. Tu T, Azizi S, Driess D, Schaekermann M, Amin \nM, Chang PC, et al. Towards generalist biomedi-\ncal AI. arXiv preprint arXiv:230714334. 2023. \nhttps://arxiv.org/abs/2307.14334\n28. Toma A, Lawler PR, Ba J, Krishnan RG, Rubin \nBB, Wang B. Clinical Camel: An Open-Source \nExpert-Level Medical Language Model with \nDialogue-Based Knowledge Encoding. arXiv \npreprint arXiv:230512031. 2023. https://arxiv.\norg/abs/2305.12031\n29. Peng C, Yang X, Chen A, Smith KE, PourNeja-\ntian N, Costa AB, et al. A Study of Generative \nLarge Language Model for Medical Research \nand Healthcare. npj Digital Medicine. 2023 \nNov;6(1):210. Available from: https://doi.\norg/10.1038/s41746-023-00958-w\n30. Zhang H, Chen J, Jiang F, Yu F, Chen Z, Chen \nG, et al. HuatuoGPT, Towards Taming Langu -\nage Model to Be a Doctor. In: Findings of the \nAssociation for Computational Linguistics: \nEMNLP 2023; 2023. p. 10859-85. https://doi.\norg/10.18653/v1/2023.findings-emnlp.725\n31. Li C, Wong C, Zhang S, Usuyama N, Liu H, \nYang J, et al. LLaV A-Med: Training a large \nlanguage-and-vision assistant for biomedicine in \none day. arXiv preprint arXiv:230600890. 2023. \nhttps://arxiv.org/abs/2306.00890\n32. Gema A, Daines L, Minervini P, Alex B. Parame-\nter-Efficient Fine-Tuning of LLaMA for the Cli-\nnical Domain. arXiv preprint arXiv:230703042. \n2023. https://arxiv.org/abs/2307.03042\n33. Moor M, Huang Q, Wu S, Yasunaga M, Dalmia \nY , Leskovec J, et al. Med-Flamingo: a multi -\nmodal medical few-shot learner. In: Machine \nLearning for Health (ML4H). PMLR; 2023. \np. 353-67. https://proceedings.mlr.press/v225/\nmoor23a.html\n34. Zhang X, Tian C, Yang X, Chen L, Li Z, Petzold \nLR. AlpaCare: Instruction-tuned Large Lan -\nguage Models for Medical Application. arXiv \npreprint arXiv:231014558. 2023. https://arxiv.\norg/abs/2310.14558\n35. Tu T, Palepu A, Schaekermann M, Saab K, Frey-\nberg J, Tanno R, et al. Towards Conversational \nDiagnostic AI. arXiv preprint arXiv:240105654. \n2024. https://arxiv.org/abs/2401.05654\n36. Xie Q, Chen Q, Chen A, Peng C, Hu Y , Lin F, \net al. Me LLaMA: Foundation Large Language \nModels for Medical Applications. arXiv pre -\nprint arXiv:240212749. 2024. https://arxiv.org/\nabs/2402.12749\n\n238\nIMIA Yearbook of Medical Informatics 2024\nSarker et al.\n37. Qiu P, Wu C, Zhang X, Lin W, Wang H, Zhang \nY , et al. Towards Building Multilingual Lan -\nguage Model for Medicine. arXiv preprint \narXiv:240213963. 2024. https://arxiv.org/\nabs/2402.13963\n38. Gu Y , Tinn R, Cheng H, Lucas M, Usuyama N, \nLiu X, et al. Domain-Specific Language Model \nPre-training for Biomedical Natural Language \nProcessing. ACM Transactions on Computing \nfor Healthcare. 2022 Jan;3(1):1-23. https://doi.\norg/10.1145/3458754\n39. Wang G, Liu X, Ying Z, Yang G, Chen Z, \nLiu Z, et al. Optimized glycemic control of \ntype 2 diabetes with reinforcement learning: \na proof-of-concept trial. Nature Medicine. \n2023;29(10):2633-42. https://doi.org/10.1038/\ns41591-023-02552-9\n40. Shoeybi M, Patwary M, Puri R, LeGresley \nP, Casper J, Catanzaro B. Megatron-LM: \nTraining Multi-Billion Parameter Language \nModels Using Model Parallelism. arXiv; \n2020. ArXiv:1909.08053. http://arxiv.org/\nabs/1909.08053\n41. Shin HC, Zhang Y , Bakhturina E, Puri R, \nPatwary M, Shoeybi M, et al. BioMegatron: \nLarger Bio-medical Domain Language Model. \narXiv; 2020. ArXiv:2010.06060. http://arxiv.org/\nabs/2010.06060\n42. Singhal K, Azizi S, Tu T, Mahdavi SS, Wei \nJ, Chung HW, et al. Large language mo -\ndels encode clinical knowledge. Nature. \n2023;620(7972):172-80. https://doi.org/10.1038/\ns41586-023-06291-2\n43. Touvron H, Lavril T, Izacard G, Martinet X, \nLachaux MA, Lacroix T, et al. Llama: Open \nand efficient foundation language models. arXiv \npreprint arXiv:230213971. 2023. https://arxiv.\norg/abs/2302.13971\n44. Yang X, Chen A, PourNejatian N, Shin HC, \nSmith KE, Parisien C, et al. A large language \nmodel for electronic health records. npj Digital \nMedicine. 2022;5(1). https://doi.org/10.1038/\ns41746-022-00742-2\n45. Brown T, Mann B, Ryder N, Subbiah M, Kaplan \nJD, Dhariwal P, et al. Language models are few-\nshot learners. Advances in neural information \nprocessing systems. 2020;33:1877-901. https://\npapers.nips.cc/paper/2020/hash/1457c0d6bf -\ncb4967418bfb8ac142f64a-Abstract.html\n46. Peng Y , Yan S, Lu Z. Transfer Learning in \nBiomedical Natural Language Processing: \nAn Evaluation of BERT and ELMo on Ten \nBenchmarking Datasets. In: Proceedings of the \n2019 Workshop on Bi-omedical Natural Langua-\nge Processing (BioNLP 2019); 2019. https://doi.\norg/10.18653/v1/W19-5006\n47. Zhang K, Yu J, Yan Z, Liu Y , Adhikarla E, Fu \nS, et al. BiomedGPT: A unified and generalist \nbiomedi-cal generative pre-trained transformer \nfor vision, language, and multimodal tasks. arXiv \npreprint arXiv:230517100. 2023. https://arxiv.\norg/abs/2305.17100\n48. Luo R, Sun L, Xia Y , Qin T, Zhang S, Poon H, \net al. BioGPT: generative pretrained transformer \nfor biomedical text generation and mining. \nBriefings in bioinformatics. 2022;23(6):bbac409. \nhttps://doi.org/10.1093/bib/bbac409\n49. Tang L, Sun Z, Idnay B, Nestor JG, Soroush \nA, Elias PA, et al. Evaluating large language \nmodels on medical evidence summarization. \nnpj Digital Medicine. 2023;6(1):158. https://doi.\norg/10.1038/s41746-023-00896-7\n50. Singh J, Patel T, Singh A. Performance Analysis \nof Large Language Models for Medical Text \nSum-marization. OSF Preprints. https://osf.io/\npreprints/osf/kn5f2\n51. Liu D, Ding C, Bold D, Bouvier M, Lu J, Shickel \nB, et al. Evaluation of General Large Language \nModels in Contextually Assessing Semantic \nConcepts Extracted from Adult Critical Care \nElectronic Health Record Notes. arXiv preprint \narXiv:240113588. 2024. https://arxiv.org/\nabs/2401.13588\n52. Abraham TM, Adams G. Evaluating the Medical \nKnowledge of Open LLMs - Part 1. MedARC \nBlog. 2024 January. https://medarc.ai/blog/\nmedarc-llms-eval-part-1\n53. He Z, Wang Y , Yan A, Liu Y , Chang E, Gentili \nA, et al. MedEval: A Multi-Level, Multi-Task, \nand Multi-Domain Medical Benchmark for \nLanguage Model Evaluation. In: Proceedings \nof the 2023 Con-ference on Empirical Me -\nthods in Natural Language Processing; 2023. \np. 8725-44. https://doi.org/10.18653/v1/2023.\nemnlp-main.540\n54. Cai Y , Wang L, Wang Y , de Melo G, Zhang Y , \nWang Y , et al. Medbench: A large-scale chinese \nbenchmark for evaluating medical large language \nmodels. arXiv preprint arXiv:231212806. 2023. \nhttps://arxiv.org/abs/2312.12806\n55. Zhu Z, Sun Z, Yang Y . HaluEval-Wild: Evalua-\nting Hallucinations of Language Models in the \nWild. arXiv preprint arXiv:240304307. 2024. \nhttps://arxiv.org/abs/2403.04307\n56. Bian J, Zheng J, Zhang Y , Zhu S. Inspire the \nLarge Language Model by External Knowledge \non Bi-oMedical Named Entity Recognition. \narXiv; 2023. ArXiv:2309.12278. http://arxiv.\norg/abs/2309.12278\n57. Soman K, Rose PW, Morris JH, Akbas RE, Smith \nB, Peetoom B, et al. Biomedical knowledge \ngraph-enhanced prompt generation for large lan-\nguage models. arXiv; 2023. ArXiv:2311.17330. \nhttp://arxiv.org/abs/2311.17330\n58. Li M, Chen M, Zhou H, Zhang R. PeTailor: \nImproving Large Language Model by Tailored \nChunk Scorer in Biomedical Triple Extraction. \narXiv; 2023. ArXiv:2310.18463. http://arxiv.org/\nabs/2310.18463\n59. Chen Q, Du J, Hu Y , Keloth VK, Peng X, Raja \nK, et al. Large language models in biomedical \nnatural language processing: benchmarks, \nbaselines, and recommendations. arXiv; \n2024. ArXiv:2305.16326.  http://arxiv.org/\nabs/2305.16326\n60. Wang C, Ong J, Wang C, Ong H, Cheng R, Ong \nD. Potential for GPT Technology to Optimize \nFuture Clinical Decision-Making Using Retrie-\nval-Augmented Generation. Annals of Biomedi-\ncal Engi-neering. 52, 1115–1118 (2024). https://\ndoi.org/10.1007/s10439-023-03327-6\n61. Khan YA, Hokia C, Xu J, Ehlert B. covLLM: Lar-\nge Language Models for COVID-19 Biomedical \nLit-erature. arXiv; 2023. ArXiv:2306.04926. \nhttp://arxiv.org/abs/2306.04926\n62. Wang LL, Lo K, Chandrasekhar Y , Reas R, \nYang J, Burdick D, et al. CORD-19: The \nCOVID-19 Open Research Dataset. arXiv; \n2020. ArXiv:2004.10706. http://arxiv.org/\nabs/2004.10706\n63. Sutton RT, Pincock D, Baumgart DC, Sadowski \nDC, Fedorak RN, Kroeker KI. An overview of \nclinical decision support systems: benefits, risks, \nand strategies for success. npj Digital Medici -\nne. 2020 Feb;3(1):17. https://doi.org/10.1038/\ns41746-020-0221-y\n64. Osheroff J, Teich J, Levick D, Saldana L, Velas-\nco F, Sittig D, et al. Improving outcomes with \nclinical decision support. 2nd ed. HIMSS Book \nSeries. Himss Publishing; 2012. https://doi.\norg/10.4324/9781498757461\n65. van Aken B, Papaioannou JM, Naik M, Eleftheri-\nadis G, Nejdl W, Gers F, et al. This Patient Looks \nLike That Patient: Prototypical Networks for \nInterpretable Diagnosis Prediction from Clinical \nText. In: He Y , Ji H, Li S, Liu Y , Chang CH, \neditors. Proceedings of the 2nd Conference of \nthe Asia-Pacific Chapter of the Association for \nComputational Linguistics and the 12th Inter -\nnational Joint Conference on Natural Language \nProcessing (V olume 1: Long Papers). Online \nonly: Association for Computational Linguistics; \n2022. p. 172-84. https://aclanthology.org/2022.\naacl-main.14\n66. Lee RY , Kross EK, Torrence J, Li KS, Sibley J, \nCohen T, et al. Assessment of Natural Langu -\nage Pro-cessing of Electronic Health Records \nto Measure Goals-of-Care Discussions as a \nClinical Trial Outcome. JAMA Network Open. \n2023 03;6(3):e231204. https://doi.org/10.1001/\njamanetworkopen.2023.1204.\n67. Lyu W, Dong X, Wong R, Zheng S, Abell-Hart K, \nWang F, et al. A Multimodal Transformer: Fusing \nClinical Notes with Structured EHR Data for \nInterpretable In-Hospital Mortality Prediction. \nAMIA Annu Symp Proc. 2022;2022:719-28. \nhttps://www.ncbi.nlm.nih.gov/pmc/articles/\nPMC10148371\n68. Garg S, Tsipras D, Liang P, Valiant G. What Can \nTransformers Learn In-Context? A Case Study \nof Simple Function Classes. In: Oh AH, Agar -\nwal A, Belgrave D, Cho K, editors. Advances \nin Neural In-formation Processing Systems; \n2022. Available from: https://openreview.net/ \nfo-rum?id=flNZJ2eOet.\n69. Benary M, Wang XD, Schmidt M, Soll D, Hil-\nfenhaus G, Nassir M, et al. Leveraging Large \nLanguage Models for Decision Support in Per-\nsonalized Oncology. JAMA Network Open. 2023 \nNov;6(11):e2343689. http://dx.doi.org/10.1001/\njamanetworkopen.2023.43689\n70. Liu S, Wright AP, Patterson BL, Wanderer JP, \nTurer RW, Nelson SD, et al. Using AI-gene -\nrated sug-gestions from ChatGPT to optimize \nclinical decision support. Journal of the Ame -\nrican Medical In-formatics Association. 2023 \n04;30(7):1237-45. https://doi.org/10.1093/\njamia/ocad072\n71. Rao A, Pang M, Kim J, Kamineni M, Lie \nW, Prasad AK, et al. Assessing the Utility of \nChatGPT Throughout the Entire Clinical Work-\nflow: Development and Usability Study. J Med \nInternet Res. 2023 Aug;25:e48659. https://doi.\norg/10.2196/48659\n\nIMIA Yearbook of Medical Informatics 2024\n239\nNatural Language Processing for Digital Health in the Era of Large Language Models\n72. Fawzi S. A Review of the Role of ChatGPT for \nClinical Decision Support Systems. In: 2023 5th \nNovel Intelligent and Leading Emerging Sciences \nConference (NILES); 2023. p. 439-42. https://\ndoi.org/10.1109/NILES59815.2023.10296668. \n73. Wang T, Zhao X, Rios A. UTSA-NLP at Rad -\nSum23: Multi-modal Retrieval-Based Chest \nX-Ray Re-port Summarization. In: Demner-fus-\nhman D, Ananiadou S, Cohen K, editors. The \n22nd Workshop on Biomedical Natural Langu-\nage Processing and BioNLP Shared Tasks. To-\nronto, Canada: Associ-ation for Computational \nLinguistics; 2023. p. 557-66. Available from: \nhttps://aclanthology.org/2023.bionlp-1.58\n74. Ozler KB, Bethard S. clulab at MEDIQA-Chat \n2023: Summarization and classification of me -\ndical dialogues. In: Naumann T, Ben Abacha A, \nBethard S, Roberts K, Rumshisky A, editors. \nProceedings of the 5th Clinical Natural Lan -\nguage Processing Workshop. Toronto, Canada: \nAssociation for Computational Linguistics; \n2023. p. 144-9. https://aclanthology.org/2023.\nclinicalnlp-1.19\n75. Sharma B, Gao Y , Miller T, Churpek M, Afshar \nM, Dligach D. Multi-Task Training with In-Do-\nmain Language Models for Diagnostic Reaso -\nning. In: Naumann T, Ben Abacha A, Bethard S, \nRoberts K, Rumshisky A, editors. Proceedings \nof the 5th Clinical Natural Language Proces -\nsing Workshop. Toronto, Canada: Association \nfor Computational Linguistics; 2023. p.78-85. \nhttps://aclanthology.org/2023.clinicalnlp-1.10\n76. Chin S, Li A, Boulet M, Howse K, Rajaram A. \nResident and family physician perspectives on \nbilling: An exploratory study. Perspect Health \nInf Manag. 2022 Oct;19(4):1g. https://www.\nncbi.nlm.nih.gov/pmc/articles/PMC9635049/\n77. Bhati D, Deogade MS, Kanyal D. Improving \nPatient Outcomes Through Effective Hospital \nAdmin-istration: A Comprehensive Review. \nCureus. 2023 Oct. http://dx.doi.org/10.7759/\ncureus.47731\n78. Ayers JW, Poliak A, Dredze M, Leas EC, Zhu \nZ, Kelley JB, et al. Comparing Physician and \nArtificial Intelligence Chatbot Responses to \nPatient Questions Posted to a Public Social \nMedia Forum. JAMA Internal Medicine. 2023 \n06;183(6):589-96. https://doi.org/10.1001/\njamainternmed.2023.1838\n79. Shrank WH, Rogstad TL, Parekh N. Waste \nin the US Health Care System: Estimated \nCosts and Po-tential for Savings. JAMA. 2019 \n10;322(15):1501-9. https://doi.org/10.1001/\njama.2019.13978\n80. Jiang LY , Liu XC, Nejatian NP, Nasir-Moin M, \nWang D, Abidin A, et al. Health system-scale \nlanguage models are all-purpose prediction \nengines. Nature. 2023 Jun;619(7969):357-62. \nhttp://dx.doi.org/10.1038/s41586-023-06160-y\n81. Lost in clinical translation. Nature Medicine. \n2004 Sep;10(9):879-9. https://doi.org/10.1038/\nnm0904-879\n82. Yala A, Mikhael PG, Lehman C, Lin G, Strand \nF, Wan YL, et al. Optimizing risk-based breast \ncancer screening policies with reinforcement le-\narning. Nature Medicine. 2022 Jan;28(1):136-43. \nhttps://doi.org/10.1038/s41591-021-01599-w\n83. Rehman RZU, Del Din S, Guan Y , Yarnall \nAJ, Shi JQ, Rochester L. Selecting Clinically \nRelevant Gait Characteristics for Classification \nof Early Parkinson’s Disease: A Comprehensive \nMachine Learning Approach. Scientific Reports. \n2019 Nov;9(1):17269. https: //doi.org/10.1038/\ns41598-019-53656-7\n84. Guazzo A, Longato E, Fadini GP, Morieri ML, \nSparacino G, Di Camillo B. Deep-learning-ba -\nsed nat-ural-language-processing models to \nidentify cardiovascular disease hospitalisations \nof patients with diabetes from routine visits’ \ntext. Scientific Reports. 2023 Nov;13(1):19132. \nhttps://doi.org/10.1038/s41598-023-45115-1\n85. Thirunavukarasu AJ, Ting DSJ, Elangovan K, \nGutierrez L, Tan TF, Ting DSW. Large language \nmod-els in medicine. Nature Medicine. 2023 \nAug;29(8):1930-40. https://doi.org/10.1038/\ns41591-023-02448-8\n86. Kang T, Zhang S, Tang Y , Hruby GW, Rusanov \nA, Elhadad N, et al. EliIE: An open-source in -\nfor-mation extraction system for clinical trial eli-\ngibility criteria. Journal of the American Medical \nIn-formatics Association. 2017;24(6):1062-71. \nhttps://doi.org/10.1093/jamia/ocx019\n87. Jin Q, Wang Z, Floudas CS, Sun J, Lu Z. \nMatching patients to clinical trials with large \nlanguage models. ArXiv. 2023. https://arxiv.org/\nabs/2307.15051\n88. Braun LA, Zomorodbakhsch B, Keinki C, \nHuebner J. Information needs, communication \nand usage of social media by cancer patients and \ntheir relatives. Journal of cancer research and \nclinical on-cology. 2019;145:1865-75. https://\ndoi.org/10.1007/s00432-019-02929-9\n89. Spadaro A, Sarker A, Hogg-Bremer W, Love JS, \nO’Donnell N, Nelson LS, et al. Reddit discussi-\nons about buprenorphine associated precipitated \nwithdrawal in the era of fentanyl. Clinical Toxi-\ncol-ogy. 2022;60(6):694-701. https://doi.org/10\n.1080/15563650.2022.2032730\n90. Kogan NE, Clemente L, Liautaud P, Kaashoek \nJ, Link NB, Nguyen AT, et al. An early warning \nap-proach to monitor COVID-19 activity with \nmultiple digital traces in near real time. Science \nAd-vances. 2021;7(10):eabd6989. https://doi.\norg/10.1126/sciadv.abd6989\n91. Bremer W, Sarker A. Recruitment and retention \nin mobile application-based intervention studies: \na critical synopsis of challenges and opportuni-\nties. Informatics for Health and Social Care. \n2023;48(2):139-52. https://doi.org/10.1080/17\n538157.2022.2082297\n92. 92. Sarker A, Ginn R, Nikfarjam A, O’Connor \nK, Smith K, Jayaraman S, et al. Utilizing social \nmedia data for pharmacovigilance: A review. \nJournal of Biomedical Informatics. 2015;54:202-\n12. https://doi.org/10.1016/j.jbi.2015.02.004\n93. Shen C, Chen A, Luo C, Zhang J, Feng B, Liao \nW. Using reports of symptoms and diagnoses \non so-cial media to predict COVID-19 case \ncounts in mainland China: Observational \ninfoveillance study. Journal of medical Inter -\nnet research. 2020;22(5):e19421. https://doi.\norg/10.2196/19421\n94. Zhang H, Wheldon C, Dunn AG, Tao C, Huo \nJ, Zhang R, et al. Mining Twitter to assess the \ndetermi-nants of health behavior toward human \npapillomavirus vaccination in the United States. \nJournal of the American Medical Informatics \nAssociation. 2020;27(2):225-35. https://doi.\norg/10.1093/jamia/ocz191\n95. Guo Y , Ovadje A, Al-Garadi MA, Sarker A. \nEvaluating Large Language Models for Heal -\nthRelated Text Classification Tasks with Public \nSocial Media Data; ArXiv. 2024. https://arxiv.\norg/abs/2403.19031\n96. Correia RB, Wood IB, Bollen J, Rocha LM. Mi-\nning Social Media Data for Biomedical Signals \nand Health-Related Behavior. Annual Review \nof Biomedical Data Science. 2020;3(1):433-\n58. https://doi.org/10.1146/annurev-biodatas -\nci-030320-040844\n97. Yang K, Zhang T, Kuang Z, Xie Q, Ananiadou \nS. MentalLLaMA: Interpretable Mental Health \nAnaly-sis on Social Media with Large Language \nModels. arXiv preprint arXiv:230913567. 2023. \nhttps://arxiv.org/abs/2309.13567\n98. Lai T, Shi Y , Du Z, Wu J, Fu K, Dou Y , et al. \nPsy-llm: Scaling up global mental health psy -\nchological services with ai-based large language \nmodels. arXiv preprint arXiv:230711991. 2023. \nhttps://arxiv.org/abs/2307.11991\n99. Xu X, Yao B, Dong Y , Gabriel S, Yu H, Hendler \nJ, et al. Mental-LLM: Leveraging Large Lan -\nguage Models for Mental Health Prediction via \nOnline Text Data. In: Proceedings of the ACM on \nInterac-tive, Mobile, Wearable and Ubiquitous \nTechnologies. 2023;8(1)31. p. 1-32. https://doi.\norg/10.1145/3643540\n100. Taori R, Gulrajani I, Zhang T, Dubois Y , Li X, \nGuestrin C, et al. Stanford Alpaca: An Instruc -\ntion-following LLaMA model. GitHub; 2023. \nhttps://github.com/tatsu-lab/stanford_alpaca\n101. Chen J, Wang Y . Social media use for health \npurposes: systematic review. Journal of medical \nIn-ternet research. 2021;23(5):e17917. https://\ndoi.org/10.2196/17917\n102. Jiang K, Devendra V , Chavan S, Bernard GR. \nDetection of Day-Based Health Evidence with \nPre-trained Large Language Models: A Case of \nCOVID-19 Symptoms in Social Media Posts. \nIn: 2023 IEEE International Conference on \nBioinformatics and Biomedicine (BIBM). IEEE; \n2023. p. 4208-12. Available from: https://doi.\norg/10.1109/BIBM58861.2023.10385580\n103. Chen C, Shu K. Combating misinformation in \nthe age of llms: Opportunities and challenges. \narXiv preprint arXiv:231105656. 2023. https://\narxiv.org/abs/2311.05656\n104. Xiao Z, Liao QV , Zhou M, Grandison T, Li Y . \nPowering an AI Chatbot with Expert Sourcing \nto Sup-port Credible Health Information Access. \nIn: Proceedings of the 28th International Con -\nference on Intelligent User Interfaces; 2023. p. \n2-18. https://doi.org/10.1145/3581641.3584031\n105. Tran V , Matsui T. Public Opinion Mining Using \nLarge Language Models on COVID-19 Related \nTweets. In: 2023 15th International Conference \non Knowledge and Systems Engineering (KSE). \nIEEE; 2023. p. 1-6. https://doi.org/10.1109/\nKSE59128.2023.10299499\n106. Meskó B, Topol EJ. The imperative for regu -\nlatory oversight of large language models (or \ngenera-tive AI) in healthcare. NPJ digital me -\ndicine. 2023;6(1):120. https://doi.org/10.1038/\ns41746-023-00873-0\n\n240\nIMIA Yearbook of Medical Informatics 2024\nSarker et al.\n107. Zack T, Lehman E, Suzgun M, Rodriguez JA, \nCeli LA, Gichoya J, et al. Assessing the potential \nof GPT-4 to perpetuate racial and gender biases \nin health care: a model evaluation study. The \nLancet Digital Health. 2024;6(1):e12-22. https://\ndoi.org/10.1016/S2589-7500(23)00225-X\n108. Wang X, Chen N, Chen J, Hu Y , Wang Y , Wu X, \net al. Apollo: Lightweight Multilingual Medical \nLLMs towards Democratizing Medical AI to 6B \nPeople. arXiv preprint arXiv:240303640. 2024. \nhttps://arxiv.org/abs/2403.03640\n109. Bommasani R, Klyman K, Longpre S, Kapoor \nS, Maslej N, Xiong B, et al. The foundation \nmodel transparency index. arXiv preprint \narXiv:231012941. 2023. https://arxiv.org/\nabs/2310.12941\n110. Lin J, Zhu L, Chen WM, Wang WC, Han S. \nTiny Machine Learning: Progress and Futures \n[Feature]. IEEE Circuits and Systems Maga -\nzine. 2023;23(3):8-34. https://doi.org/10.1109/\nMCAS.2023.3302182\n111. Chen Q, Du J, Hu Y , Keloth VK, Peng X, Raja \nK, et al. Large language models in biomedical \nnatural language processing: benchmarks, ba -\nselines, and recommendations. arXiv preprint \narXiv:230516326. 2023. https://arxiv.org/\nabs/2305.16326\n112. Wu C, Lin W, Zhang X, Zhang Y , Wang Y , \nXie W. PMC-LLaMA: Towards Building \nOpensource Lan-guage Models for Medicine. \narXiv; 2023. ArXiv:2304.14454. http://arxiv.\norg/abs/2304.14454\n113. French RM. Catastrophic forgetting in connec-\ntionist networks. Trends in cognitive sciences. \n1999;3(4):128-35. https://doi.org/10.1016/\nS1364-6613(99)01294-2.\n114. Gupta K, Thérien B, Ibrahim A, Richter ML, \nAnthony QG, Belilovsky E, et al. Continual \nPre-Training of Large Language Models: How to \nre-warm your model? In: Workshop on Efficient \nSystems for Foundation Models@ ICML2023; \n2023. Available from: https://openreview.net/\nforum?id=pg7PUJe0Tl. \n115. Clusmann J, Kolbinger FR, Muti HS, Carrero \nZI, Eckardt JN, Laleh NG, et al. The future \nlandscape of large language models in medici -\nne. Communications Medicine. 2023;3(1):141. \nhttps://doi.org/10.1038/s43856-023-00370-1\n116. Gao Y , Xiong Y , Gao X, Jia K, Pan J, Bi Y , et \nal. Retrieval-augmented generation for large \nlanguage models: A survey. arXiv preprint \narXiv:231210997. 2023. https://arxiv.org/\nabs/2312.10997\n117. Huang L, Yu W, Ma W, Zhong W, Feng Z, Wang \nH, et al. A Survey on Hallucination in Large \nLan-guage Models: Principles, Taxonomy, Chal-\nlenges, and Open Questions. arXiv; 2023. Ar-\nXiv:2311.05232. http://arxiv.org/abs/2311.05232\n118. Liu Y , Yao Y , Ton JF, Zhang X, Cheng RGH, \nKlochkov Y , et al. Trustworthy LLMs: a \nSurvey and Guideline for Evaluating Large \nLanguage Models’ Alignment. arXiv preprint \narXiv:230805374. 2023. https://arxiv.org/\nabs/2308.05374. \nCopyright\n© 2024. The Author(s). This is an open \naccess article published by Thieme under \nthe terms of the Creative Commons Attri -\nbution License, permitting unrestricted use, \ndistribution, and reproduction so long as \nthe original work is properly cited. https://\ncreativecommons.org/licenses/by/4.0/\n",
  "topic": "Automatic summarization",
  "concepts": [
    {
      "name": "Automatic summarization",
      "score": 0.5453691482543945
    },
    {
      "name": "Interpretability",
      "score": 0.5158385634422302
    },
    {
      "name": "Social media",
      "score": 0.49195024371147156
    },
    {
      "name": "Computer science",
      "score": 0.47955843806266785
    },
    {
      "name": "Data science",
      "score": 0.4249563217163086
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3681105971336365
    },
    {
      "name": "Internet privacy",
      "score": 0.33857113122940063
    },
    {
      "name": "Natural language processing",
      "score": 0.330893337726593
    },
    {
      "name": "World Wide Web",
      "score": 0.2827349007129669
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I150468666",
      "name": "Emory University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I130238516",
      "name": "University of Minnesota",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I170201317",
      "name": "University of Pittsburgh",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I205783295",
      "name": "Cornell University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I32971472",
      "name": "Yale University",
      "country": "US"
    }
  ]
}