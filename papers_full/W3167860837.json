{
  "title": "Signal Transformer: Complex-valued Attention and Meta-Learning for Signal Recognition",
  "url": "https://openalex.org/W3167860837",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5018401644",
      "name": "Yihong Dong",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5101415114",
      "name": "Peng Ying",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5012381843",
      "name": "Muqiao Yang",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5088593720",
      "name": "Songtao Lu",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5059252324",
      "name": "Qingjiang Shi",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2964078140",
    "https://openalex.org/W2970144620",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2970674435",
    "https://openalex.org/W3101844643",
    "https://openalex.org/W2892122929",
    "https://openalex.org/W2951775809",
    "https://openalex.org/W2889965839",
    "https://openalex.org/W2117163577",
    "https://openalex.org/W3103158340",
    "https://openalex.org/W3035791573",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2970433714",
    "https://openalex.org/W2787501667",
    "https://openalex.org/W2971184120",
    "https://openalex.org/W2906424389",
    "https://openalex.org/W2794363191",
    "https://openalex.org/W3098528340",
    "https://openalex.org/W2557283755",
    "https://openalex.org/W2626778328",
    "https://openalex.org/W3035944497",
    "https://openalex.org/W1836465849",
    "https://openalex.org/W2970122980",
    "https://openalex.org/W2618946976",
    "https://openalex.org/W2047515252",
    "https://openalex.org/W2963723981",
    "https://openalex.org/W3016245588",
    "https://openalex.org/W2970697704",
    "https://openalex.org/W1924770834",
    "https://openalex.org/W2970971581",
    "https://openalex.org/W3097892290",
    "https://openalex.org/W2064191652",
    "https://openalex.org/W3015651375",
    "https://openalex.org/W2948168221",
    "https://openalex.org/W3138656191",
    "https://openalex.org/W3094286125",
    "https://openalex.org/W3016147814",
    "https://openalex.org/W2272847350",
    "https://openalex.org/W2990520147",
    "https://openalex.org/W3105253998"
  ],
  "abstract": "Deep neural networks have been shown as a class of useful tools for addressing signal recognition issues in recent years, especially for identifying the nonlinear feature structures of signals. However, this power of most deep learning techniques heavily relies on an abundant amount of training data, so the performance of classic neural nets decreases sharply when the number of training data samples is small or unseen data are presented in the testing phase. This calls for an advanced strategy, i.e., model-agnostic meta-learning (MAML), which is able to capture the invariant representation of the data samples or signals. In this paper, inspired by the special structure of the signal, i.e., real and imaginary parts consisted in practical time-series signals, we propose a Complex-valued Attentional MEta Learner (CAMEL) for the problem of few-shot signal recognition by leveraging attention and meta-learning in the complex domain. To the best of our knowledge, this is also the first complex-valued MAML that can find the first-order stationary points of general nonconvex problems with theoretical convergence guarantees. Extensive experiments results showcase the superiority of the proposed CAMEL compared with the state-of-the-art methods.",
  "full_text": "Signal Transformer: Complex-valued Attention and\nMeta-Learning for Signal Recognition\nYihong Dong\nTongji University\nduh_dyh@tongji.edu.cn\nYing Peng\nTongji University\n1853287@tongji.edu.cn\nMuqiao Yang\nCarnegie Mellon University\nmuqiaoy@cs.cmu.edu\nSongtao Lu\nIBM Thomas J. Watson Research Center\nsongtao@ibm.com\nQingjiang Shi\nTongji University\nshiqj@tongji.edu.cn\nAbstract\nDeep neural networks have been shown as a class of useful tools for addressing\nsignal recognition issues in recent years, especially for identifying the nonlinear\nfeature structures of signals. However, this power of most deep learning techniques\nheavily relies on an abundant amount of training data, so the performance of classic\nneural nets decreases sharply when the number of training data samples is small\nor unseen data are presented in the testing phase. This calls for an advanced\nstrategy, i.e., model-agnostic meta-learning (MAML), which is able to capture\nthe invariant representation of the data samples or signals. In this paper, inspired\nby the special structure of the signal, i.e., real and imaginary parts consisted in\npractical time-series signals, we propose a Complex-valued Attentional MEta\nLearner (CAMEL) for the problem of few-shot signal recognition by leveraging\nattention and meta-learning in the complex domain. To the best of our knowledge,\nthis is also the ﬁrst complex-valued MAML that can ﬁnd the ﬁrst-order stationary\npoints of general nonconvex problems with theoretical convergence guarantees.\nExtensive experiments results showcase the superiority of the proposed CAMEL\ncompared with the state-of-the-art methods.\n1 Introduction\nWith the recent explosion of deep learning, signal recognition has made some remarkable advances\n[1–4]. To achieve these, a large volume of data is required to obtain satisfactory performance.\nHowever, the deep learning models trained with traditional supervised learning methods often\nperform poorly or even fail when only a small amount of data is available or when they need to\nadapt to unseen tasks or time-varying ones. In practical signal recognition tasks, the collection\nand annotation of abundant data are notoriously expensive, especially for some rare but important\nsignals. Another critical challenge is the presence of noise, because the signal data varies for different\nsignal-to-noise ratios (SNRs), and in real-world scenarios, the deep neural networks (DNNs) have to\nadapt to real-time variations in SNRs.\nMeta-learning technique [5 –9] seeks to resolve above challenges by learning how to learn like\nhumans do. We know that humans can effectively utilize prior knowledge and experience to learn\nnew skills rapidly with very few examples. Similarly, the meta-learner is trained on the distribution\nof homogeneous tasks, with the goal of learning internal features that are broadly applicable to all\ntasks, rather than a single individual task. Equipped with these sensitive internal features, the meta-\nlearner is able to produce signiﬁcant improvements of adaptation ability via ﬁne-tuning. Recently,\nmeta-learning has demonstrated promising performance in many ﬁelds [10 –29]. Please see the\nPreprint. Under review.\narXiv:2106.04392v2  [cs.LG]  12 Jun 2021\nFigure 1: The overview of CAMEL.\nsupplementary material for detailed related work in Section G. However, for some particular ﬁelds,\nespecially signal recognition, existing meta-learning methods generally neglect the prior knowledge of\nthe signals, i.e., temporal information and complex domain information. For models with insufﬁcient\ntraining data, it is crucial to incorporate this prior knowledge.\nAs such, we take into account the attention mechanism [30] and the complex-valued neural network\n[31–33] for signal recognition, respectively. Attention mechanisms have been widely adopted in many\ntime series learning tasks, such as natural language processing. It became an integral component of\nRecurrent neural networks (RNNs), long short-term memory [34] and gated recurrent [35] neural\nnetworks, until Transformer [30] was proposed. Since then, self-attention is able to replace RNN\nwith better performance and parallel computation. Therefore, we adapt the attention mechanism to\nthe signal recognition task. Since the signals contain both magnitude and phase, complex numbers\nare used for the representation of signals. Consequently, complex arithmetic operations are the\nessential part of signal processing. Intuitively, complex-valued neural networks should be built to\naddress the signal recognition problem. However, to the best of our knowledge, the meta-learning\nmethod equipped with attention mechanisms in the complex-valued neural networks has not been\ninvestigated.\nIn this paper, we propose a Complex-valued Attentional MEta Learner (CAMEL), for few-shot signal\nrecognition, which generalizes meta-learning and attention to the complex domain. With the help of\nthese novel designs, CAMEL has succeeded in capturing more information from the signal data. The\nprior knowledge assists CAMEL in preventing overﬁtting and improving its performance. For better\nunderstanding the proposed architecture, the overview of CAMEL is illustrated in Figure 1. Notice\nthat CAMEL can be applied to any kind of complex-valued data. By leveraging existing meta-learning\nand few learning methods in extensive experiments, the proposed method shows consistently better\nperformance compared with the state-of-the-art methods. The effectiveness of each novel component\nin CAMEL is veriﬁed via ablation studies. From the convergence analysis of complex-valued MAML,\nit is shown that CAMEL is able to ﬁnd an ϵﬁrst-order stationary point for any positive ϵafter at most\nO\n(\n1/ϵ2)\niterations with second-order information.\nThe code of this paper will be released upon acceptance. Please see the supplementary material for\nnotations, detailed derivation of Lemma, and more experiment results.\n2 Motivation\nMeta-learning is one of the most suited techniques to solve signal recognition problems, because, in\nthe real world, signal annotation is expensive and models need to adapt to changing SNRs, whereas\nmeta-learning has an explicit goal of fast adaptation. To further improve the effectiveness of meta-\nlearning in applications to signal processing, we consider incorporating prior knowledge of signal\n2\ndata to the model by CAMEL that can generalize meta-learning with attention to the complex domain\nso that we are able to extract complex domain and temporal information from signal data.\nHowever, lots of so called complex-valued neural networks treat a complex number as two real\nnumbers, i.e., real and imaginary parts of the complex number, and design special network structures\nto recover complex operations using these real numbers. We refer to these special complex-valued\nneural networks as in-phase/quadrature complex-valued neural networks (IQCVNNs). Although\nIQCVNNs can deal with complex-valued problems, essentially the neural nets are still working with\nreal-valued ones, since IQCVNNs work without deﬁning complex derivatives and the complex chain\nrules in back-propagation. We refer to the complex-valued neural networks that deﬁne complex\nderivatives and the complex chain rules as complex derivatives complex-valued neural networks\n(CDCVNNs). It turns out that compared with IQCVNNs, CDCVNNs can perform complex operations\nwith fewer parameters. To be more speciﬁc, we give the following lemmas to show the signiﬁcance\nof CDVNNs compared with IQCVNNs with respect to time complexity.\nLemma 1 If a function gis complex analytic, the time complexity of the derivative of gin IQCVNNs\nare twice that of the complex derivative of gin CDCVNNs.\nLemma 2 The complex-valued convolutional layer and complex-valued fully connected layer is\ncomplex analytic.\nAs we know, the convolutional and fully connected layers are the most computationally intensive\nparts of a neural network. Therefore, although it has a similar effect to the complex-valued neural\nnetwork, IQCVNNs far exceed the CDCVNNs in terms of the time complexity of back-propagation.\nEspecially, meta-learning requires second-order information of the objective function to guarantee\nconvergence [36], which forces us to implement CDCVNNs. The complex chain rule is a key to\nimplementing CDCVNNs. According to the complex chain rule, we are able to derive the outer-loop\nupdate process of CAMEL, which is different from that of MAML.\nComplex-valued attention is also necessary for CAMEL to obtain the temporal information from\nsignal data. However, in complex-valued attention, it is required to compute the derivative of the\nmapping from complex to real domain since calculating the similarity coefﬁcient between two pairs\nleads to the real numbers in the activation function of the complex-valued neural nets. Given the\nfollowing lemma, we know that the derivative of the function will be non-analytic, since constant\nfunction is useless in identifying the features of data.\nLemma 3 ∀g: C →R, gis analytic if and only if gis a constant function.\nTo the best of our knowledge, attention in the complex domain has rarely been studied. 1. Therefore,\nwe here study complex-valued attention and propose CAMEL as presented in the next section.\n3 CAMEL\nPlease see the supplementary material for the deﬁnitions of complex derivative, analytic function,\nand the Cauchy-Riemann equations in Section D.\n3.1 Algorithm Design\nCAMEL utilizes complex-valued neural networks and attention to provide prior knowledge, i.e.,\ncomplex domain and temporal information, to prevent overﬁtting during training. It resembles its\nnamesake animal, camel, which stores water and nutrients with its hump to ensure its survival in\nextreme conditions.\nCAMEL updates parameters through back-propagation by the chain rule. However, traditional chain\nrule does not work, because CAMEL is non-analytic.\n1A closely related work is [37], which proposed a complex transformer and developed attention and encoder-\ndecoder network operating for complex input. However, they utilized eight attentions to represent complex-valued\nattention without considering the nonlinear components of attention such as softmax and activation functions,\netc.\n3\nThe chain rule for complex variables The chain rule is different when the function is non-analytic.\nFor a non-analytic composite function g(u), where u = h(x), we can apply the following chain rule:\n∂g(u)\n∂x = ∂g(u)\n∂u\n∂u\n∂x + ∂g(u)\n∂u∗\n∂u∗\n∂x (1)\nwhere gis a continuous function and u∗denotes the conjugate vector of u. Note that if the function\nis analytic, the second term equals zero and (1) turns into the normal chain rule. In the case of matrix\nderivatives, the chain rule can be written as:\n∂g(U)\n∂X =\n∂Tr\n((∂g(U)\n∂U\n)T\n∂U\n)\n∂X +\n∂Tr\n((∂g(U)\n∂U∗\n)T\n∂U∗\n)\n∂X (2)\nwhere U = h(X) is non-analytic, U and X are two complex matrices, and (·)T denotes the transpose\nof a matrix.\nUnder (1) and (2), CAMEL is able to update the parameters as expected. Formally, we deﬁne the\nbase model of CAMEL to be a complex-valued attentional neural network with meta-parameters\nθ ∈C. The goal is to learn a sensitive initial θ, for which the network performs well on the ith query\nset Qi after few gradient update steps on the ith support set Si to obtain θ′\ni. Here, Ti = {Si,Qi}is\na task randomly sampled from the task probability distribution p(T). The update steps above are\ntermed as the inner-loop update process, which can be represented as:\nθ′\ni = θ −α∇θLSi (θ) (3)\nwhere αis a learning rate and ∇θLSi (θ) denotes the gradient on the support set of task i. The\nmeta-parameters θ are trained by optimizing the performance of θ′\ni. Consequently, the meta-objective\nis deﬁned as follows:\nmin\nθ\nLmeta(θ) ≜ E{Si,Qi}∼p(T) [LQi (θ′\ni)] (4)\nwhere LQi (θ′\ni) denotes the loss on the query set of task iafter the inner-loop update process. As\nthe underlying p(T) is unknown, evaluation of the expectation in the right hand side of (4) is often\ncomputationally prohibitive. Therefore, we can minimize the function Lmeta(θ) with a batch of tasks\n{Ti}B\ni=1 that are independently drawn from p(T), which can be expressed as:\nLmeta(θ) = 1\nBΣ{Si,Qi}∼p(T) LQi (θ′\ni)\n= 1\nBΣ{Si,Qi}∼p(T) LQi\n(\nθ −αΣj∇θ′\ni\nLSi (θ′\ni)\n)\n.\n(5)\nThe optimization of the meta-objective is referred to as the outer-loop update process, which can be\nexpressed as:\nθ ←θ −β∇θLmeta(θ) (6)\nwhere βdenotes the meta learning rate. Deﬁne\nHi\nθθ ≜\n(∂∇θLSi (θ)\n∂θ\n)∗\n, Hi\nθ∗θ ≜\n(∂∇θ∗LSi (θ)\n∂θ\n)∗\n. (7)\nLemma 4 In response to complex meta-parameters θ, we have\n∇θLmeta(θ) = 1\nBΣ{Si,Qi}∼p(T)\n(\nI −αHi\nθθ\n)\n∇θ′\ni\nLQi (θ′\ni) −αHi\nθ∗θ∇(θ′\ni)∗LQi (θ′\ni). (8)\nThen, according to (8), the outer-loop update process for complex meta-parameters θ is\nθ ←θ −β 1\nBΣ{Si,Qi}∼p(T)\n(\nI −αHi\nθθ\n)\n∇θ′\ni\nLQi (θ′\ni) −αHi\nθ∗θ∇(θ′\ni)∗LQi (θ′\ni). (9)\nThe complete algorithm description of is outlined in Algorithm 1.\n4\nAlgorithm 1 Pseudocode for CAMEL Update\nRequire: The distribution over tasks p(T).\nRequire: The learning rates α,β.\nEnsure: The meta-parameters θ of CAMEL.\nRandomly initialize the meta-parameters θ of CAMEL.\nrepeat\nSample batch of tasks Ti = {Si,Qi}∼ p(T)\nfor each {Si,Qi}do\nEvaluate ∇θi LSi (θi) via the complex chain rule (1) and (2).\nUpdate θ′\ni = θ −α∇θLSi (θ).\nSet Hi\nθθ =\n(∂∇θLSi (θ)\n∂θ\n)∗\nand Hi\nθ∗θ =\n(∂∇θ∗LSi (θ)\n∂θ\n)∗\nEvaluate ∇θ′\ni\nLQi (θ′\ni) and ∇(θ′\ni)∗LQi (θ′\ni) via the complex chain rule (1) and (2).\nend for\nUpdate θ ←θ −β 1\nBΣ{Si,Qi}∼p(T)\n(\nI −αHi\nθθ\n)\n∇θ′\ni\nLQi (θ′\ni) −αHi\nθ∗θ∇(θ′\ni)∗LQi (θ′\ni)\nuntil convergence\n3.2 Complex-valued Attention\nThe attention mechanisms are widely used in various areas of deep learning, but attention for the\ncomplex domain have rarely been addressed. A signiﬁcant reason is that the attention has to utilize\nthe softmax function to calculate the similarity coefﬁcient, which must be real numbers rather than\ncomplex numbers. According to Lemma 3, it is a constant function or a non-analytic function.\nHowever, the constant functions are useless and discardable in neural networks, while non-analytic\nfunctions cannot be derived at arbitrary points in complex domain. As a result, we had to utilize the\ncomplex gradient vector.\nComplex gradient vector If ˆgis the real function of a complex vector x, then the complex gradient\nvector is given by [38]:\n∇ˆg(x) = 2dˆg(x)\ndx∗ = dˆg(x)\n∂ℜ(x∗) + j dˆg(x)\n∂ℑ(x∗). (10)\nComplex-valued softmax functionUnder (10), we are able to deﬁne the generalized complex-valued\nsoftmax function as:\nCsf(x) = Rsf(ˆg(x)) (11)\nwhere Rsf(·) denotes the softmax function in real case and ˆg(·) denotes any function that maps\ncomplex numbers to real numbers, such as abs(·) (i.e., the magnitude of the complex numbers), ℜ(·),\nand ℑ(·), etc.\nGiven a complex matrix X, we can compute the complex matrix Q, K and V using linear trans-\nformations, which are similar to complex-valued fully connected layers. Then the complex-valued\nattention can be written as:\nCa(Q,K,V) = Csf\n(QKT\n√dk\n)\nV\n= Csf\n((ℜ(Q)ℜ(K)T −ℑ(Q)ℑ(K)T) + j(ℜ(Q)ℑ(K)T + ℑ(Q)ℜ(K)T)√dk\n)\nℜ(V)\n+ jCsf\n((ℜ(Q)ℜ(K)T −ℑ(Q)ℑ(K)T) + j(ℜ(Q)ℑ(K)T + ℑ(Q)ℜ(K)T)√dk\n)\nℑ(V)\n(12)\nwhere Csf(·) acts on each row of the matrix and dk denotes the row dimension of K i.e. scaling\nfactor.\nComplex-valued multi-head attention Complex-valued multi-headed attention allows models to\njointly focus on information from different representations.\nCmha(Q,K,V) = Concat({Ca(QWQ\nk ,KWK\nk ,VWV\nk )}n\nk=1)WO (13)\n5\nFigure 2: The architecture of CAMEL. The embedding block contains 1 ×1 complex-valued\nconvolutional layers. The complex-valued convolutional block contains 3 ×1 complex-valued\nconvolutional layer, complex-valued batch normalization, and complex-valued ReLU. The complex-\nvalued attention block contains complex-valued attentions. The complex-valued fully connected\nblock contains complex-valued fully connected layers, complex-valued batch normalization, and\ncomplex-valued ReLU.\nwhere WQ\nk ,WK\nk ,WV\nk , and WO are the projection matrices and Concat(·) denotes the concatena-\ntion of inputs matrices.\nComplex-valued normalization Normalization, such as batch normalization [39] and layer normal-\nization [40], is an important component of neural networks. Especially, the batch normalization is\ncommonly employed. However, for a complex vector x, its variance, which has to be computed\nin normalization, is real. According to Lemma 3, the variance is non-analytic. Therefore, in the\nback-propagation of complex-valued normalization, we have to utilize the complex gradient vec-\ntor (10). Deﬁne γ as the complex scaling parameters and κas the complex shift parameters, the\ncomplex-valued normalization can be expressed as:\nCn(x) = γ(Var[x])−1\n2 (x −E[x]) + κ\nVar[x] = E{[x −E[x]][x −E[x]]H}\n(14)\nwhere E[·] and Var[·] denote the expectation and variance, respectively, and[x]H denotes the conjugate\ntranspose of x.\nComplex-valued activation function The activation function is nonlinear, so that it is scarcely to be\nanalytic. Most of the well-known activation functions are not analytic in the complex domain, such\nas Sigmoid, Tanh, and ReLU [41], etc. Especially, the complex Sigmoid and Tanh is not bounded\nwhile in complex ReLU the complex numbers cannot be compared with zero. To this end, the\ncomplex-valued activation function can be deﬁned as:\nCaf(x) = Raf(ℜ(x)) + jRaf(ℑ(x)) (15)\nwhere Raf(·) denotes the activation function in real case. In this way, the CSigmoid and CTanh are\nbounded because the real and imaginary parts of them are bounded. Meanwhile, the complex CReLU\ncan be compared with zero because the real and imaginary parts of inputs can be compared with zero.\nHowever, since the complex-valued activation functions deﬁned above are non-analytic in most cases,\nthe complex chain rule is required for derivatives.\nPlease see the supplementary material for detailed complex-valued convolutional layer and complex-\nvalued fully connected layer in Section F.\n4 Convergence of CAMEL\nIn this section, we will show the convergence behavior of complex-valued MAML by following\nthe previous work [36] in proving the convergence MAML in the real domain. To prove the\ncomplex-valued MAML, we need to utilize twice continuously differentiable,Li-smooth, ρi-Lipschitz\ncontinuous, and Hessian, etc. in complex domain. Please see the supplementary material for detailed\nAssumptions, Lemma, and proof of Theorem 1 in Section H.\nTheorem 1 Suppose that Assumptions 1-5 hold and α∈(0, 1\n6L]. Consider running complex-valued\nMAML with batch sizes B ≥20 and |Q|≥⌈ 2α2σ2\nH⌉. Following the deﬁnition in Lemma 5, let\nβk = ˜β(θk)/12. Then for any ϵ> 0, complex-valued MAML ﬁnds a solution that\nE[||∇Lmeta(θϵ)||] ≤max\n{√\n61(1 + ρα\nL σ)(σ2\nB + ˜σ2\nB|Q|+ ˜σ2\n|S|),61ρα\nL (σ2\nB + ˜σ2\nB|Q|+ ˜σ2\n|S|),ϵ\n}\n(16)\n6\nafter running for\nO(1)∆ min\n{L+ ρα(σ+ ϵ)\nϵ2 ,LB\nσ2 + L(B|Q|+ |S|)\n˜σ2\n}\n(17)\niterations, where ∆ is deﬁned in Assumption 1 and |S|and |Q|denotes the size of the support set and\nquery set, respectively.\nThe result in Theorem 1 demonstrates that after running CAMEL forO(1+ρ(σ+ϵ)/6\nϵ2 + B\nσ2 + (B|Q|+|S|)\n˜σ2 )\niterations, we are able to ﬁnd a point θ† at which the expected gradient norm E[||∇Lmeta(θ†)||]\nsatisﬁes (16).\n5 Experiments\nWe train the model on 3 datasets: RadioML 2016.10A [1], a dataset with 220,000 total samples,\n20,000 samples for each class and 11,000 samples for each SNR, consists of 2 ×128 dimension\ninput X in 11 classes. The 11 classes correspond to 11 modulation types: 8PSK, AM-DSB, AM-SSB,\nBPSK, CPFSK, GFSK, PAM4, QAM16, QAM64, QPSK, WBFM. And RadioML 2016.04C [1], a\nsynthetic dataset, is generated with GNU Radio, consisting of about 110 thousand signals. These\nsamples are uniformly distributed in SNR from -20dB to +20dB and tagged so that we can evaluate\nperformance on speciﬁc subsets. Actually 2016.10A represents a cleaner and more normalized\nversion of the 2016.04C dataset. The third one is SIGNAL2020.02 [42], whose data is modulated at\na rate of 8 samples per symbol, while 128 samples per frame, with 20 different SNRs, even values\nbetween [2dB, 40dB].\n5.1 Experimental setup\nThe CAMEL is implemented in Pytorch [43] with python on a RTX3090 Graphics Processing Units,\nand trained using the Adam optimizer [44]. In the classiﬁcation experiments of three datasets,\nRadioML 2016.04C, RadioML 2016.10A and SIGNAL 2020.02, the default hyper-parameters are as\nfollows: the training epochs are 400,000; the meta batch size is 2; the meta-level outer learning rate\nis 0.001 and the task-level inner update learning rate is 0.1; the task-level inner update step is 5 and\nthe update step for ﬁne-tuning is 10. All of our experiments use the same hyper-parameter as the\ndefault setting. We change the support set shot number in 1 and 5 to have different results of 5-way\n1-shot case and 5-way 5-shot case.\n5.2 Our Model\nFirst, we study the inﬂuence of adding a multi-head self attention mechanism in this network, which\ncan focus attention on important information. We perform a multi-head attention with 8 heads. Instead\nof performing a single attention function with input dx-dimensional keys, values and queries, it is\nfound beneﬁcial to linearly project the queries, keys and values htimes with different, learned linear\nprojections to dk, dq, dv dimensions, respectively. Then perform the attention function in parallel,\nconcatenate the outputs and do the projection again to get the ﬁnal result [45]. In our experiments, as\nillustrated in Table 1, the performance is much better with the addition of the multi-head attention\nmechanism. As the batch size increases, the performance improves while increasing computation and\ntime-consuming. To make a trade-off, we set the batch size to be 64 when using multi-head attention.\nWe observe that the model with attention mechanism demonstrates a greater ability to increase the\naccuracy owing to various improvements.\nFurther study concerns the inﬂuence of adding a complex-valued neural network, because we\nnotice that complex numbers could have a richer representational capacity. For these signals inputs,\nusing complex number can probably obtain more useful details than real numbers and could also\nfacilitate noise-robust memory retrieval mechanisms [48]. We need to deal with the complex building\nblocks to construct a complex number neural network: representing of complex numbers, Complex\ngradient vectors, complex weight initialization, complex convolutions, complex-valued activation,\ncomplex-valued normalization and complex-valued multi-head attention mechanism. These blocks\nare determined by their own algorithm and the algorithm of complex numbers. We ﬁgure out from\nthe results in Table 1 and Table 2 that this complex features improve the classiﬁcation accuracy in\nboth 5-way 1-shot and 5-way 5-shot cases with different datasets.\n7\nTable 1: CAMEL: compare with other meta-learning models on datasets RADIOML 2016.10A and\nSIGNAL 2020.02. The method ‘MAML+attention’ indicates adding multi-head attention mechanism\non the origin MAML model, ‘MAML+complex’ means constructing complex-valued neural network\nin the MAML model and ‘CT [37]’ represents the Complex Transformer model using 8 attention\nfunctions to represent the complex-valued attention. The ±shows 95% conﬁdence intervals over\ntasks.\nRADIOML 2016.10A SIGNAL2020.02\nMethod 1-shot 5-shot 1-shot 5-shot\nMAML [5] 86.57% 94.50% 43.26% 67.77%\nMAML+attention 95.80% 97.70% 54.44% 63.33%\nMAML+complex 91.40% 96.38% 59.50% 64.00%\nSNAIL [46] 71.18% 78.48% 35.01% 36.34%\nReptilec [47] 69.16% 92.32% 55.01% 69.39%\nMAML+complex+CT [37] 96.40% 97.50% 58.40% 69.80%\nCAMEL (ours) 97.23% ±0.13% 98.22% ±0.08% 64.80% ±0.10% 74.27% ±0.15%\nTable 2: CAMEL: compare with other meta-learning models in detail on the dataset RADIOML\n2016.04C. The ±shows 95% conﬁdence intervals over tasks. CAMEL outperforms all other meta-\nlearning models listed.\nRADIOML 2016.04C\nMethod 1-shot 5-shot\nMAML [5] 88.93% ±0.13% 93.59% ±0.62%\nMAML+attention 92.12% ±0.22% 95.51% ±0.05%\nMAML+complex 91.65% ±0.35% 96.28% ±0.53%\nSNAIL [46] 89.21% ±0.75% 96.90% ±0.19%\nReptile [47] 87.08% ±2.88% 92.07% ±5.65%\nMAML+complex+CT [37] 93.58% ±1.15% 96.52% ±0.08%\nCAMEL (ours) 96.30% ±0.22% 97.51% ±0.15%\nIn the training process, we adjust the number of convolution kernels to 128. For the multi-head\nattention part, we set the source sequence length and output sequence length to 64, number of heads\nto 8. We observe that such complex-valued models are more competitive than their real valued\ncounterparts. These build our ﬁnal model: CAMEL, Model-Agnostic Meta-Learning with features of\nmulti-head attention and complex-valued neural network. Compared with the other meta-learning\nmodels, CAMEL achieves the best classiﬁcation accuracy.\nThe Complex Transformer [37] implements complex attention in another way: It rewrites all complex\nfunctions into two separate real functions and computes the multiplication of queries, keys and values\nto get the complex attention with 8 attention functions having different inputs. We also conduct\nSNAIL [46], which combines a casual attention operation over the context produced by temporal\nconvolutions, and Reptile [47], which uses only ﬁrst-order derivatives for meta-learning updates.\nTo have a comparison, Table 1 and Table 2 list the accuracies of several models based on MAML\napplied on different datasets. Results in thses two tables demonstrate that our model CAMEL have\nthe state-of-the-art performance among all. In particular, some models are not well performed on the\ntask in the dataset SIGNAL2020.02, but our model CAMEL still has a stable and great performance\non this challenging task. Figure 3 indicates that CAMEL could get the highest accuracy at a relatively\nfast convergence speed. The results also show that, on these challenging signal classiﬁcation tasks,\nthe CAMEL model apparently outperforms other meta-learning models in accuracy and stability,\nwhich could be ﬁgured out from the smooth accuracy curves and narrow conﬁdence intervals for\nCAMEL model in both 1 shot and 5 shot cases.\n5.3 Ablation study\nIn this section, we have conducted the ablation studies on CAMEL in three scenarios, as shown in\nTable 3. The ﬁrst scenario uses samples whose SNR ≥0, of which 75% is selected as the training\n8\nFigure 3: CAMEL: compare the convergence curves of accuracy with other meta-learning models\nfor classiﬁcation tasks on the dataset RADIOML 2016.04C. This pair of images shows the accuracy\ncurves at 95% conﬁdence interval over the same classiﬁcation task. Left: 5-way 1-shot learning.\nRight: 5-way 5-shot learning. The results indicate that our model CAMEL reaches the highest\naccuracy at a relatively fast convergence rate.\nTable 3: Ablation study on CAMEL in three scenarios. For the MAML, add multi-head attention\nmechanism and use complex numbers step by step. Our model CAMEL combines MAML, complex-\nvalued neural network and complex-valued multi-head attention component. The total experiment\nconsists of 4 models on 3 training and test sets.\nAccurancy SNR ≥0 SNR = 0 P-O set\nMAML 87.20% 81.64% 89.06%\nMAML+attention 93.00% 87.26% 91.90%\nMAML+complex 91.10% 91.75% 91.30%\nCAMEL (ours) 93.70% 92.10% 96.30%\nset and 25% is selected as the test set. For the second scenario, showed in the column \"SNR = 0\" in\nTable 3, we pick samples with SNR=0 and randomly select 75% of them to form the training set and\n25% of them as the test set. The third scenario forms the (Prediction-Other) P-O set as follow: pick 5\nclasses of signal samples (SNR ≥0) as set P and the rest 5 classes of samples (SNR ≥0) form set\nO. Pick all samples in set O and 5% of samples in set P as the training set. The remaining 95% of\nsamples in set P constitute the test set.\nOn 3 training and testing sets mentioned above, we construct the MAML model ﬁrst, and then add\nsome features on it step by step. We add attention components and complex numbers separately and\ntogether. From the results we observe that in CAMEL, all the features added on the original MAML\nmodel help improve the classiﬁcation accuracy.\n6 Conclusion\nIn this paper, we have proposed a complex domain attentional meta-learning framework for signal\nrecognition named CAMEL. CAMEL utilizes complex-valued neural networks and attention to\nprovide prior knowledge, i.e., complex domain and temporal information, which helps CAMEL\nimprove performance and prevent overﬁtting. As two byproducts of CAMEL, we have designed\nthe complex-valued meta-learning and complex-valued attention, which can be of independent\ninterest. With second-order information, CAMEL is able to ﬁnd ﬁrst-order stationary points of\ngeneral nonconvex problems. Furthermore, CAMEL has achieved the state-of-the-art results on\nextensive datasets. Finally, the ablation studies in three scenarios have demonstrated the effectiveness\nof the components of CAMEL.\n9\nReferences\n[1] T. J. O’Shea, J. Corgan, and T. C. Clancy, “Convolutional radio modulation recognition net-\nworks,” inInternational Conference on Engineering Applications of Neural Networks, pp. 213–\n226, Springer, 2016.\n[2] M. Jas, T. Dupré la Tour, U. Simsekli, and A. Gramfort, “Learning the morphology of brain\nsignals using alpha-stable convolutional sparse coding,” in Advances in Neural Information\nProcessing Systems, vol. 30, 2017.\n[3] X. Song, L. Chai, and J. Zhang, “Graph signal processing approach to qsar/qspr model learning\nof compounds,” IEEE Transactions on Pattern Analysis and Machine Intelligence , pp. 1–1,\n2020.\n[4] Y . Dong, X. Jiang, L. Cheng, and Q. Shi, “SSRCNN: A semi-supervised learning framework for\nsignal recognition,”IEEE Transactions on Cognitive Communications and Networking, pp. 1–1,\n2021.\n[5] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for fast adaptation of deep\nnetworks,” inInternational Conference on Machine Learning, pp. 1126–1135, PMLR, 2017.\n[6] C. Finn, K. Xu, and S. Levine, “Probabilistic model-agnostic meta-learning,” inAdvances in\nNeural Information Processing Systems, vol. 31, 2018.\n[7] J. Yoon, T. Kim, O. Dia, S. Kim, Y . Bengio, and S. Ahn, “Bayesian model-agnostic meta-\nlearning,” inAdvances in Neural Information Processing Systems, pp. 7343–7353, 2018.\n[8] R. Zhang, T. Che, Z. Ghahramani, Y . Bengio, and Y . Song, “Metagan: An adversarial approach\nto few-shot learning.,”Advances in Neural Information Processing Systems, vol. 2, p. 8, 2018.\n[9] Y . Balaji, S. Sankaranarayanan, and R. Chellappa, “Metareg: Towards domain generaliza-\ntion using meta-regularization,”Advances in Neural Information Processing Systems, vol. 31,\npp. 998–1008, 2018.\n[10] S. Liu, A. Davison, and E. Johns, “Self-supervised generalisation with meta auxiliary learning,”\nin Advances in Neural Information Processing Systems, vol. 32, 2019.\n[11] S. Khodadadeh, L. Boloni, and M. Shah, “Unsupervised meta-learning for few-shot image\nclassiﬁcation,” in Advances in Neural Information Processing Systems, vol. 32, 2019.\n[12] Y . Xie, H. Jiang, F. Liu, T. Zhao, and H. Zha, “Meta learning with relational information for\nshort sequences,” inAdvances in Neural Information Processing Systems, vol. 32, 2019.\n[13] F. Alet, E. Weng, T. Lozano-Pérez, and L. P. Kaelbling, “Neural relational inference with fast\nmodular meta-learning,” inAdvances in Neural Information Processing Systems, vol. 32, 2019.\n[14] G. Jerfel, E. Grant, T. Grifﬁths, and K. A. Heller, “Reconciling meta-learning and continual\nlearning with online mixtures of tasks,” in Advances in Neural Information Processing Systems,\nvol. 32, 2019.\n[15] M. Khodak, M.-F. F. Balcan, and A. S. Talwalkar, “Adaptive gradient-based meta-learning\nmethods,” inAdvances in Neural Information Processing Systems, vol. 32, 2019.\n[16] P. Zhou, X. Yuan, H. Xu, S. Yan, and J. Feng, “Efﬁcient meta learning via minibatch proximal\nupdate,” inAdvances in Neural Information Processing Systems, vol. 32, 2019.\n[17] A. Rajeswaran, C. Finn, S. M. Kakade, and S. Levine, “Meta-learning with implicit gradients,”\nin Advances in Neural Information Processing Systems, vol. 32, 2019.\n[18] Z. Zhuang, Y . Wang, K. Yu, and S. Lu, “No-regret non-convex online meta-learning,” in\nICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing\n(ICASSP), pp. 3942–3946, IEEE, 2020.\n[19] W. Kong, R. Somani, S. Kakade, and S. Oh, “Robust meta-learning for mixed linear regression\nwith small batches,” inAdvances in Neural Information Processing Systems, vol. 33, pp. 4683–\n4696, 2020.\n[20] G. Denevi, M. Pontil, and C. Ciliberto, “The advantage of conditional meta-learning for biased\nregularization and ﬁne tuning,” in Advances in Neural Information Processing Systems, vol. 33,\npp. 964–974, 2020.\n10\n[21] Y . Chen, A. L. Friesen, F. Behbahani, A. Doucet, D. Budden, M. Hoffman, and N. de Freitas,\n“Modular meta-learning with shrinkage,” inAdvances in Neural Information Processing Systems,\nvol. 33, pp. 2858–2869, 2020.\n[22] H. Yao, Y . Zhou, M. Mahdavi, Z. J. Li, R. Socher, and C. Xiong, “Online structured meta-\nlearning,” in Advances in Neural Information Processing Systems , vol. 33, pp. 6779–6790,\n2020.\n[23] S. Baik, M. Choi, J. Choi, H. Kim, and K. M. Lee, “Meta-learning with adaptive hyperpa-\nrameters,” inAdvances in Neural Information Processing Systems, vol. 33, pp. 20755–20765,\n2020.\n[24] V . Sitzmann, E. Chan, R. Tucker, N. Snavely, and G. Wetzstein, “Metasdf: Meta-learning\nsigned distance functions,” in Advances in Neural Information Processing Systems , vol. 33,\npp. 10136–10147, 2020.\n[25] J. Harrison, A. Sharma, C. Finn, and M. Pavone, “Continuous meta-learning without tasks,” in\nAdvances in Neural Information Processing Systems, vol. 33, pp. 17571–17581, 2020.\n[26] K. Ji, J. D. Lee, Y . Liang, and H. V . Poor, “Convergence of meta-learning with task-speciﬁc\nadaptation over partial parameters,” in Advances in Neural Information Processing Systems,\nvol. 33, pp. 11490–11500, 2020.\n[27] C. Boutilier, C.-w. Hsu, B. Kveton, M. Mladenov, C. Szepesvari, and M. Zaheer, “Differentiable\nmeta-learning of bandit policies,” in Advances in Neural Information Processing Systems ,\nvol. 33, pp. 2122–2134, 2020.\n[28] B. Confavreux, F. Zenke, E. Agnes, T. Lillicrap, and T. V ogels, “A meta-learning approach to\n(re)discover plasticity rules that carve a desired function into a neural network,” inAdvances in\nNeural Information Processing Systems, vol. 33, pp. 16398–16408, 2020.\n[29] M. Goldblum, L. Fowl, and T. Goldstein, “Adversarially robust few-shot learning: A meta-\nlearning approach,” in Advances in Neural Information Processing Systems, vol. 33, pp. 17886–\n17895, 2020.\n[30] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and\nI. Polosukhin, “Attention is all you need,” in Advances in Neural Information Processing\nSystems, vol. 30, 2017.\n[31] C. Trabelsi, O. Bilaniuk, Y . Zhang, D. Serdyuk, S. Subramanian, J. F. Santos, S. Mehri,\nN. Rostamzadeh, Y . Bengio, and C. J. Pal, “Deep complex networks,” in 6th International\nConference on Learning Representations (ICLR), OpenReview.net, 2018.\n[32] A. Hirose, Complex-valued neural networks, vol. 400. Springer Science & Business Media,\n2012.\n[33] Y . Tu, Y . Lin, C. Hou, and S. Mao, “Complex-valued networks for automatic modulation\nclassiﬁcation,” IEEE Transactions on Vehicular Technology, vol. 69, no. 9, pp. 10085–10089,\n2020.\n[34] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural Computation, vol. 9,\nno. 8, pp. 1735–1780, 1997.\n[35] J. Chung, C. Gulcehre, K. Cho, and Y . Bengio, “Empirical evaluation of gated recurrent neural\nnetworks on sequence modeling,”arXiv preprint arXiv:1412.3555, 2014.\n[36] A. Fallah, A. Mokhtari, and A. Ozdaglar, “On the convergence theory of gradient-based model-\nagnostic meta-learning algorithms,” inInternational Conference on Artiﬁcial Intelligence and\nStatistics, pp. 1082–1092, PMLR, 2020.\n[37] M. Yang, M. Q. Ma, D. Li, Y .-H. H. Tsai, and R. Salakhutdinov, “Complex transformer: A\nframework for modeling complex-valued sequence,” in IEEE International Conference on\nAcoustics, Speech and Signal Processing (ICASSP), pp. 4232–4236, IEEE, 2020.\n[38] A. Hjørungnes, Complex-valued matrix derivatives: with applications in signal processing and\ncommunications. Cambridge University Press, 2011.\n[39] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep network training by reducing\ninternal covariate shift,” inInternational Conference on Machine Learning, pp. 448–456, PMLR,\n2015.\n11\n[40] J. L. Ba, J. R. Kiros, and G. E. Hinton, “Layer normalization,”arXiv preprint arXiv:1607.06450,\n2016.\n[41] I. Goodfellow, Y . Bengio, A. Courville, and Y . Bengio, Deep learning, vol. 1. MIT press\nCambridge, 2016.\n[42] Y . Dong, X. Jiang, H. Zhou, Y . Lin, and Q. Shi, “SR2CNN: Zero-shot learning for signal\nrecognition,”IEEE Transactions on Signal Processing, vol. 69, pp. 2316–2329, 2021.\n[43] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin,\nN. Gimelshein, L. Antiga, et al., “Pytorch: An imperative style, high-performance deep learning\nlibrary,”arXiv preprint arXiv:1912.01703, 2019.\n[44] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” arXiv preprint\narXiv:1412.6980, 2014.\n[45] Y . N. Dauphin and S. Schoenholz, “Metainit: Initializing learning by learning to initialize,” in\nAdvances in Neural Information Processing Systems(H. Wallach, H. Larochelle, A. Beygelzimer,\nF. d'Alché-Buc, E. Fox, and R. Garnett, eds.), vol. 32, Curran Associates, Inc., 2019.\n[46] N. Mishra, M. Rohaninejad, X. Chen, and P. Abbeel, “A simple neural attentive meta-learner,”\nin International Conference on Learning Representations, 2018.\n[47] A. Nichol, J. Achiam, and J. Schulman, “On ﬁrst-order meta-learning algorithms,” arXiv\npreprint arXiv:1803.02999, 2018.\n[48] C. Trabelsi, O. Bilaniuk, Y . Zhang, D. Serdyuk, S. Subramanian, J. F. Santos, S. Mehri, N. Ros-\ntamzadeh, Y . Bengio, and C. J. Pal, “Deep complex networks,” inInternational Conference on\nLearning Representations, 2018.\n[49] S. Zhang, Y . Xia, and J. Wang, “A complex-valued projection neural network for constrained\noptimization of real functions in complex variables,”IEEE Transactions on Neural Networks\nand Learning Systems, vol. 26, no. 12, pp. 3227–3238, 2015.\n[50] H. Zhang, X. Liu, D. Xu, and Y . Zhang, “Convergence analysis of fully complex backpropaga-\ntion algorithm based on wirtinger calculus,”Cognitive Neurodynamics, vol. 8, no. 3, pp. 261–\n266, 2014.\n12\nTable 4: Deﬁnition of mathematical symbols\nθ Meta-parameters of model\nα Learning rate\nTi Task ii.e. {Si,Qi}\np(T) Task probability distribution\nβ Meta learning rate\nL maxiLi\nρ maxiρi\nB Batch size\nσ2 The variance of gradient ∇fi(θ)\n˜σ2 The variance of gradient ∇fi(θ,d)\nd Random minibatch drawn from the dataset of task i\nβk The k-th step meta learning rate\nLi Lipschitz constant of ∇fi\nρi Lipschitz constant of ∇2fi\nfi Loss function for task i\nFi The loss after the update of gradient descent\nI The set of all tasks\nx Complex-valued input vector\nb Complex-valued bias vector\nLSi (θ) The loss on the support set of task i\nLmeta(θ) Meta-objective\nA Proof of Lemma 1\nLemma 1 If a function gis complex analytic, the time complexity of the derivative of gin IQCVNNs\nare twice that of the complex derivative of gin CDCVNNs.\nProof 1 We consider two scenarios, the derivative of simple analytic function and composite analytic\nfunction.\n1. For a simple analytic function g(z), in CDCVNNs, the complex derivative of g with respect\nto a complex vector z is equal to ∂g(z)\n∂z = ∂ℜ(g(z))\n∂ℜ(z) + j∂ℑ(g(z))\n∂ℜ(z) . While IQCVNNs considers\nz =\n[\nℜ(z)\nℑ(z)\n]\nand g(z) =\n[\nℜ(g(z))\nℑ(g(z))\n]\n, therefore\n∂g(z)\n∂z = ∂\n∂\n[\nℜ(z)\nℑ(z)\n]\n[\nℜ(g(z))\nℑ(g(z))\n]T\n=\n\n\n∂ℜ(g(z))\n∂ℜ(z)\n∂ℑ(g(z))\n∂ℜ(z)\n∂ℜ(g(z))\n∂ℑ(z)\n∂ℑ(g(z))\n∂ℑ(z)\n\n.\n(18)\nThus, in this scenario, the time complexity of the derivative of gin IQCVNNs are twice that of the\ncomplex derivative of gin CDCVNNs.\n2. For a composite analytic function g(h(z)) where u = h(z) is also complex analytic, in CDCVNNs,\nthe complex derivative of gwith respect to a complex vector z ∈Cm can be computed according to\nthe complex chain rule.\n∂g(u)\n∂z = ∂g(u)\n∂u\n∂u\n∂z + ∂g(u)\n∂u∗\n∂u∗\n∂z (19)\nOwing to the fact that u = h(z) is complex analytic, ∂u∗\n∂z is equal to zero. So, (19) can be simpliﬁed\nto\n∂g(u)\n∂z = ∂g(u)\n∂u\n∂u\n∂z (20)\n13\nwhere ∂g(u)\n∂u and ∂u\n∂z ∈Cm. Hence, the time complexity of the complex derivative ofgin CDCVNNs\nis O(2 ∗2 ∗m) = O(4m). However, in IQCVNNs, we have\n∂g(u)\n∂z = ∂\n∂\n[\nℜ(u)\nℑ(u)\n]\n[\nℜ(g(u))\nℑ(g(u))\n]T ∂\n∂\n[\nℜ(z)\nℑ(z)\n]\n[\nℜ(u)\nℑ(u)\n]T\n=\n\n\n∂ℜ(g(u))\n∂ℜ(u)\n∂ℑ(g(u))\n∂ℜ(u)\n∂ℜ(g(u))\n∂ℑ(u)\n∂ℑ(g(u))\n∂ℑ(u)\n\n\n\n\n∂ℜ(u)\n∂ℜ(z)\n∂ℑ(u)\n∂ℜ(z)\n∂ℜ(u)\n∂ℑ(z)\n∂ℑ(u)\n∂ℑ(z)\n\n\n(21)\nwhere the size of each above tensor in (21) is (2,2,m). Hence, the time complexity of the derivative\nof gin IQCVNNs is O(2 ∗2 ∗2 ∗m) = O(8m). Note that the composite function of N layers, which\ncan be seen as N−1 composite functions of two layers calculated serially. As a result, in CDCVNNs,\nthe time complexity of the complex derivative of gis O(4m(N −1)), while in IQCVNNs, the time\ncomplexity of the derivative of gis O(8m(N −1)). Hence, the Lemma holds in the scenario of the\nderivative of composite analytic function.\nTo sum up, the Lemma 1 is established in both two scenarios. This completes the proof.\nB Proof of Lemma 2\nLemma 2 The complex-valued convolutional layer and complex-valued fully connected layer is\ncomplex analytic.\nProof 2 It is obviously that the complex-valued convolution layer and complex-valued fully connected\nlayer are linear and continuous. Assume that a linear function g(x) = ATx + b is continuous with\nrespect to a complex vector x, then we can obtain\n∂ℜ(g(x))\n∂ℜ(x) = ∂ℜ(A)Tℜ(x) −ℑ(A)Tℑ(x) + ℜ(b)\n∂ℜ(x) = ℜ(A),\n∂ℑ(g(x))\n∂ℑ(x) = ∂ℑ(A)Tℜ(x) + ℜ(A)Tℑ(x) + ℑ(b)\n∂ℑ(x) = ℜ(A).\nIn a similar way,\n∂ℜ(g(x))\n∂ℑ(x) = −ℑ(A), ∂ℑ(g(x))\n∂ℜ(x) = ℑ(A).\nTherefore, \n\n\n∂ℜ(g(x))\n∂ℜ(x) = ∂ℑ(g(x))\n∂ℑ(x)\n∂ℜ(g(x))\n∂ℑ(x) = −∂ℑ(g(x))\n∂ℜ(x) .\nAccording to the function g(x) is continuous and satisﬁes the Cauchy-Riemann equations, the linear\nfunction is complex analytic. Hence, the complex-valued convolution layer and complex-valued fully\nconnected layer are complex analytic. This completes the proof.\nC Proof of Lemma 3\nLemma 3 ∀g: C →R, gis analytic if and only if gis a constant function.\nProof 3 Assume a function g ∈{C →R}is analytic. Then ghas to satisfy the Cauchy-Riemann\nequations: \n\n\n∂ℜ(g(x))\n∂ℜ(x) = ∂ℑ(g(x))\n∂ℑ(x) = ∂0\n∂ℑ(x) = 0\n∂ℜ(g(x))\n∂ℑ(x) = −∂ℑ(g(x))\n∂ℜ(x) = − ∂0\n∂ℜ(x) = 0\nwhere x is the complex input vector. Since the partial derivatives of g are all equal to 0, g is a\nconstant function. This completes the proof.\n14\nD Deﬁnition Recall\nIn this section, we recall the deﬁnitions of complex derivative, analytic function, and the Cauchy-\nRiemann equations.\nComplex derivative Let g(z) ∈C, where z∈C. If g(z) is continuous at a point z0, we can deﬁne\nits complex derivative as:\ng′(z0) = dg\ndz\n⏐⏐⏐⏐\nz=z0\n= lim\n∆z→0\ng(z0 + ∆z) −g(z0)\n∆z . (22)\nThis is similar to the deﬁnition of the derivative for the function of a real variable. In the real case,\nthe existence of the derivative implies that the limits of dg\ndz both exist and are equal when the point\nz0 + ∆zconverges to z0 from both the left (∆ <0) and right (∆ >0) directions. However, in the\ncomplex case, it means that the limits of dg\ndz exist and are equal when the point z0 + ∆zconverges to\nz0 from any directions in the complex plane. If a function satisﬁes this property at a point z0, we say\nthat the function is complex-differentiable at z0.\nAnalytic function If a function g(z) is complex-differentiable for all points z in some domain\nD ⊂C , then g(z) is said to be analytic, i.e., g(z) is a complex analytic function also known as\nholomorphic function, in D.\nThe Cauchy-Riemann equations The Cauchy-Riemann equations are a pair of real partial differen-\ntial equations, and their complex analytic function needs to satisfy:\n\n\n\n∂ℜ(g(z))\n∂ℜ(z) = ∂ℑ(g(z))\n∂ℑ(z)\n∂ℜ(g(z))\n∂ℑ(z) = −∂ℑ(g(z))\n∂ℜ(z)\n(23)\nwhere ℜ(·) and ℑ(·) denote the real and imaginary parts of the complex number, respectively. The\nnecessary and sufﬁcient condition for g(z) to be complex analytic function in Dis that the function\ng(z) is continuous and satisﬁes the Cauchy-Riemann equations in D.\nE Proof of Lemma 4\nLemma 4 In response to complex meta-parameters θ, we have\n∇θLmeta(θ) = 1\nBΣ{Si,Qi}∼p(T)\n(\nI −αHi\nθθ\n)\n∇θ′\ni\nLQi (θ′\ni) −αHi\nθ∗θ∇(θ′\ni)∗LQi (θ′\ni). (11)\nProof 4 According to (5), it is obviously that\n∇θLmeta(θ) = 1\nBΣ{Si,Qi}∼p(T)∇θLQi (θ′\ni). (24)\nNote that, since LQi : C →R, following the deﬁnition of complex gradient vector (10), we have\n∇θLQi (θ′\ni) = 2∂LQi (θ′\ni)\n∂θ∗\n= 2\n(∂LQi (θ′\ni)\n∂θ\n)∗\n= 2\n(∂LQi (θ′\ni)\n∂θ′\ni\n∂θ′\ni\n∂θ + ∂LQi (θ′\ni)\n∂(θ′\ni)∗\n∂(θ′\ni)∗\n∂θ\n)∗\n= 2\n(\n∂LQi (θ′\ni)\n∂(θ′\ni)∗\n(∂θ′\ni\n∂θ\n)∗\n+ ∂LQi (θ′\ni)\n∂(θ′\ni)∗∗\n(∂(θ′\ni)∗\n∂θ\n)∗)\n= ∇θ′\ni\nLQi (θ′\ni)\n(∂θ′\ni\n∂θ\n)∗\n+ ∇(θ′\ni)∗LQi (θ′\ni)\n(∂(θ′\ni)∗\n∂θ\n)∗\n(25)\n15\nwhere the second equality is because the output of LQi is real, the third equality follows the complex\nchain rule, and the last equality is given by the deﬁnition of complex gradient vector. Next, according\nto inner-loop update process (3), we have(∂θ′\ni\n∂θ\n)∗\n=\n(∂(θ −α∇θLSi (θ))\n∂θ\n)∗\n=\n(\nI −α∂∇θLSi (θ)\n∂θ\n)∗\n= I −α\n(∂∇θLSi (θ)\n∂θ\n)∗\n.\n(26)\nSimilarly, (∂(θ′\ni)∗\n∂θ\n)∗\n=\n(∂(θ −α∇θLSi (θ))∗\n∂θ\n)∗\n=\n(∂θ∗−α∇θ∗LSi (θ)\n∂θ\n)∗\n= −α\n(∂∇θ∗LSi (θ)\n∂θ\n)∗\n.\n(27)\nNow, using (7), we can write (25) as\n∇θLQi (θ′\ni) =\n(\nI −αHi\nθθ\n)\n∇θ′\ni\nLQi (θ′\ni) −αHi\nθ∗θ∇(θ′\ni)∗LQi (θ′\ni). (28)\nPlugging (28) in (24) yields\n∇θLmeta(θ) = 1\nBΣ{Si,Qi}∼p(T)\n(\nI −αHi\nθθ\n)\n∇θ′\ni\nLQi (θ′\ni) −αHi\nθ∗θ∇(θ′\ni)∗LQi (θ′\ni). (29)\nThis completes the proof.\nF Complex-valued Neural Networks\nNeural networks require back-propagation to update their parameters via ﬁrst-order derivatives, as do\ncomplex-valued neural networks. We would prefer the functions in complex-valued neural networks\nto be analytic. Deﬁne x and b as the complex input vector and complex bias vector for each function,\nrespectively.\nComplex-valued convolutional layer The complex-valued convolutional layer implements the\nconvolution operation on complex input signals. Deﬁne A as the complex convolution kernel. Given\nx, A, and b, since the complex-valued convolutional layer is linear, we are able to compute the real\nand imaginary parts of its outputs separately as the following\nℜ(Cconv(x,A,b) = ℜ(A) ⊗ℜ(x) −ℑ(A) ⊗ℑ(x) + ℜ(b), (30a)\nℑ(Cconv(x,A,b) = ℜ(A) ⊗ℑ(x) + ℑ(A) ⊗ℜ(x) + ℑ(b). (30b)\nThen, according to the (30a) and (30b), the complex-valued convolutional layer can be represented as\nfollows:\nCconv(x,A,b) = ℜ(Cconv(x,A,b) + jℑ(Cconv(x,A,b)\n=(ℜ(A) ⊗ℜ(x) −ℑ(A) ⊗ℑ(x) + ℜ(b)) + j(ℜ(A) ⊗ℑ(x) + ℑ(A) ⊗ℜ(x) + ℑ(b))\nwhere ⊗denotes the convolution operation in real case.\nComplex-valued fully connected layer The complex-valued fully connected layer achieves the\nlinear transformation of complex inputs. Deﬁne W as the complex weight matrix. Given x, W,\nand b, the real and imaginary parts of the outputs of complex-valued fully connected layer can be\ncomputed as:\nℜ(Cfc(x,W,b)) = ℜ(W)Tℜ(x) −ℑ(W)Tℑ(x) + ℜ(b), (31a)\nℑ(Cfc(x,W,b)) = ℑ(W)Tℜ(x) + ℜ(W)Tℑ(x) + ℑ(b). (31b)\nSimilarly, the complex-valued fully connected layer can be expressed as:\nCfc(x,W,b) = ℜ(Cfc(x,W,b)) + jℑ(Cfc(x,W,b))\n= ℜ(W)Tℜ(x) −ℑ(W)Tℑ(x) + ℜ(b)\n+ jℑ(W)Tℜ(x) + ℜ(W)Tℑ(x) + ℑ(b).\n(32)\n16\nG Related work\nRecently, meta-learning has demonstrated promising performance in many ﬁelds. Khodadadeh et\nal. [11] proposed an unsupervised algorithm for model-independent meta-learning for classiﬁcation\ntasks. The work [10] proposed a new method that automatically learns appropriate labels for auxiliary\ntasks. The work [12] proposed a new meta-learning method to learn heterogeneous point process\nmodels from short event sequence data and relational networks. In addition, the work [14] proposed a\nDirichlet process mixture for hierarchical Bayesian models with the parameters of arbitrary parametric\nmodels. Khodak et al. [15] built a theoretical framework for the design and understanding of practical\nmeta-learning methods. The authors in [16] proposed a meta-learning method based on minibatch\nproximal update for learning effective hypothesis transfer.\nMoreover, the work [17] proposed an implicit MAML algorithm which relies only on the solution\nto the inner level optimization. The work [21] a meta-learning approach that avoids the need for\nthis often sub-optimal hand-selection. The work [22] proposed an online structured meta-learning\nframework. Additionally, the authors in [23] proposed a new weight update rule that greatly enhances\nthe fast adaptation process. The work [25] proposed a meta-learning approach via online changepoint\nanalysis to augment with a differentiable Bayesian changepoint detection scheme. The work [29]\nproposed an adversarial querying algorithm for generating adversarially robust meta-learners and\nthoroughly investigated the causes for adversarial vulnerability.\nH Convergence Analysis\nFor ease of writing and derivation, in our notation, fi(θ) = LSi (θ) represents the loss function on\nthe task i, Fi(θ) = fi(θ −α∇fi(θ)) = fi(θ′\ni) = LQi (θ′\ni) represents the loss on the task iafter the\ninner-loop update process, and F(θ) = Lmeta(θ) represents the meta-objective. By drawing task i\nfrom task probability distribution p(Ti), our optimization problem can be rewritten as\nmin\nθ\nF(θ) = Ei∼p[Fi(θ)] = Ei∼p[fi(θ −α∇fi(θ))]. (33)\nDeﬁnition 1 A random vector θϵ ∈Cm is called an ϵ-approximate ﬁrst order stationary point for\nproblem 33 if it satisﬁes E[||∇F(θϵ)||] ≤ϵ.\nThen, we formally state our assumptions as below.\nAssumption 1 F is bounded below, min F(θ) > −∞and ∆ ≜ (F(θ0) −minθ∈C F(θ)) is\nbounded.\nAssumption 2 Suppose Idenotes the set of all tasks. ∀i∈I, fi is twice continuously differentiable\nwith respect to z and z∗(the second-order Wirtinger derivatives [38] of fi exist and are continuous)\nand Li-smooth [32, 49], i.e.,\n∀θ,µ ∈Cm,||∇fi(θ) −∇fi(µ)||≤ Li||θ −µ|| (34)\nwhere norm ||z||denotes\n√\nz1z∗\n1 + ...+ zmz∗m.\nAssumption 3 ∀i ∈ I, the Hessian ∇2fi = ∂2fi\n∂v∗∂v⊤ is ρi-Lipschitz continuous where v =\n(z,z∗)⊤∈C2m [3,5], i.e.,\n∀θ,µ ∈Cm,||∇2fi(θ) −∇2fi(µ)||≤ ρi||θ −µ||. (35)\nNote that we have one Li and ρi for each fi, so in this paper we will use L = max iLi and\nρ = maxiρi to represent the Lipschitz constant of the gradients and Hessians for all i ∈I. We\nfollow the deﬁnition of Lipschitz continuous in the complex domain from [49, 50].\nAssumption 4 The variance of gradient ∇fi(θ) is bounded, i.e., for some real-valued parameter\nσ >0, we have Ei∼p[||∇f(θ) −∇fi(θ)||2] ≤σ2.\n17\nAssumption 5 Suppose d∼Ti denotes a random minibatch drawn from the dataset of task i. Then\n∀i∈I and ∀θ,µ ∈Cm, the stochastic gradients ∇fi(θ,d) and Hessians ∇2fi(θ,d) have bounded\nvariance, i.e.,\nEd∼Ti [||∇fi(θ,d) −∇fi(θ)||2] ≤˜σ2, (36a)\nEd∼Ti [||∇2fi(θ,d) −∇2fi(θ)||2] ≤σ2\nH. (36b)\nwhere ˜σand σH are non-negative real-valued constants.\nLemma 5 [36] Suppose that Assumptions 2-5 hold and α∈[0, 1\nL]. Then consider the deﬁnition\n˜β(θ) = 1\n4L+ 2ρα∑\ni∈B′||˜∇fi(θ,Di\nβ)||/B′\nwhere B′is a batch of tasks with size B′which are independently drawn with probability distribution\np(Ti), and for i∈B′, Di\nβ is a dataset corresponding to task iwith size Dβ. If\nB′≥⌈0.5(ρασ/L)2⌉, Dβ ≥⌈2(ρα˜σ/L)2⌉\nare satisﬁed, then\nE[ ˜β(θ)] ≥ 0.8\nL(θ), E[ ˜β(θ)2] ≥ 3.125\nL(θ2)\nwhere L(θ) ≜ 4L+ 2ραEi∼p||∇fi(θ)||.\nTheorem 1 Suppose that Assumptions 1-5 hold and α∈(0, 1\n6L]. Consider running complex-valued\nMAML with batch sizes B ≥20 and |Q|≥⌈ 2α2σ2\nH⌉. Following the deﬁnition in Lemma 5, let\nβk = ˜β(θk)/12. Then for any ϵ> 0, complex-valued MAML ﬁnds a solution that\nE[||∇Lmeta(θϵ)||] ≤max\n{√\n61(1 + ρα\nL σ)(σ2\nB + ˜σ2\nB|Q|+ ˜σ2\n|S|),61ρα\nL (σ2\nB + ˜σ2\nB|Q|+ ˜σ2\n|S|),ϵ\n}\n(37)\nafter running for\nO(1)∆ min\n{L+ ρα(σ+ ϵ)\nϵ2 ,LB\nσ2 + L(B|Q|+ |S|)\n˜σ2\n}\n(38)\niterations, where ∆ is deﬁned in Assumption 1 and |S|and |Q|denotes the size of the support set and\nquery set, respectively.\nProof 5 Deﬁne Gi(θ) ≜ ∇θFi(θ). Gi(θ) can be written as\nGi(θ) =\n(\nI −αHi\nθθ\n)\n∇θ′\ni\nfi(θ′\ni) −αHi\nθ∗θ∇(θ′\ni)∗fi(θ′\ni)\n= ∇θ′\ni\nfi(θ′\ni) −α\n(\nHi\nθθ∇θ′\ni\nfi(θ′\ni) + Hi\nθ∗θ∇(θ′\ni)∗fi(θ′\ni)\n)\n.\n(39)\nThen, Gi(θ∗) can be expressed as\nGi(θ∗) = (Gi(θ))∗\n=\n(\n∇θ′\ni\nfi(θ′\ni) −α\n(\nHi\nθθ∇θ′\ni\nfi(θ′\ni) + Hi\nθ∗θ∇(θ′\ni)∗fi(θ′\ni)\n))∗\n= ∇(θ′\ni)∗fi(θ′\ni) −α\n(\nHi\nθθ∗∇θ′\ni\nfi(θ′\ni) + Hi\nθ∗θ∗∇(θ′\ni)∗fi(θ′\ni)\n)\n(40)\n18\nwhere the ﬁrst and second equalities are because the loss function is real numbers. According to\nWirtinger derivatives [38], deﬁne conjugate coordinates φ=\n[\nθ\nθ∗\n]\n, and we have\nGi(φ) =\n[\nGi(θ)\nGi(θ∗)\n]\n=\n\n ∇θ′\ni\nfi(θ′\ni) −α\n(\nHi\nθθ∇θ′\ni\nfi(θ′\ni) + Hi\nθ∗θ∇(θ′\ni)∗fi(θ′\ni)\n)\n∇(θ′\ni)∗fi(θ′\ni) −α\n(\nHi\nθθ∗∇θ′\ni\nfi(θ′\ni) + Hi\nθ∗θ∗∇(θ′\ni)∗fi(θ′\ni)\n)\n\n\n=\n[ ∇θ′\ni\nfi(θ′\ni)\n∇(θ′\ni)∗fi(θ′\ni)\n]\n−α\n[\nHi\nθθ Hi\nθ∗θ\nHi\nθθ∗ Hi\nθ∗θ∗\n][ ∇θ′\ni\nfi(θ′\ni)\n∇(θ′\ni)∗fi(θ′\ni)\n]\n= ∇φ′\ni\nfi(θ′\ni) −α∇2\nφLSi (θ)∇φ′\ni\nfi(θ′\ni)\n=\n(\nI −α∇2\nφfi(θ)\n)\n∇φ′\ni\nfi(θ′\ni)\n=\n(\nI −α∇2\nφfi(φ)\n)\n∇φ′\ni\nfi(φ′\ni)\n(41)\nwhere the second equality follows (40) and (41), the fourth equality is given by the deﬁnition of\ncomplex gradient and hessian, and the last equality follows Wirtinger derivatives. Obviously, Gi(φ)\nhas the same form with the outer-loop update gradient in MAML. Thus, with the Assumptions 2-5\nwhich extend the Assumptions in [36] to complex domain, we have similar derivation and conclusion\nas [36]. Since θ = (θ∗)∗and Gi(θ) = ( Gi(θ∗))∗, updating meta-parameter θ is equivalent to\nupdating φ. Hence, Theorem 1 holds. This completes the proof.\nI Toy Experiment of the Chain Rule\nThe complex chain rule is signiﬁcant for the back-propagation of CDCVNN, especially in the\npresence of non-analytic functions, and we conduct a toy experiment to verify it. The toy network is\ndeﬁned as J = h3(h2(h1(x))), where h1(x) = x∗, h2(x) = x2, and h3(x) = |exp −x|. Figure 4\ndemonstrates that the complex chain rule is succeed in optimizing J while the naive chain rule fail\ndue to ∂h1(x)\n∂x = ∂x∗\n∂x = 0.\nFigure 4: The comparison of back-propagation of the toy network J via the complex chain rule and\nnaive chain rule.\nJ Confusion Matrices\nThe class-confusion matrices for MAML and CAMEL are showed in Figure 5 and Figure 6 for 1 shot\nand 5 shot case, respectively. These tell the actual labels and predict labels of the testing samples.\nFrom the images we can ﬁnd out that we will have better classiﬁcation performance in 5 shot case\n19\nthan 1 shot case, and better performance with model CAMEL than MAML. The results also indicate\nthat two models both perform well for the class ’CPFSK’ and are easy to get confused for the other 4\nclasses. Additionally, CAMEL has much better performance for these remaining 4 classes.\nFigure 5: Confusion Matrix: compare our model CAMEL with MAML in 1-shot case for classiﬁcation\ntasks on the dataset RADIOML 2016.10A. The y axis shows the actual label of samples and the x axis\nshows the predict label. The data is presented in percentage. Left: Model-Agnostic Meta-Learning\nmodel. Right: Complex-valued Attentional MEta Learner. The results tell that two models both\nperform well for the class ’CPFSK’ and CAMEL has much better performance for other classes.\nFigure 6: Confusion Matrix: compare our model CAMEL with MAML in 5-shot case for classiﬁcation\ntasks on the dataset RADIOML 2016.10A. The data is presented in percentage. Left: MAML. Right:\nCAMEL. From the result, two models are both able to fulﬁl the classiﬁcation task well, and CAMEL\ndoes a better job.\n20",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7391210794448853
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6519504189491272
    },
    {
      "name": "Machine learning",
      "score": 0.5182356834411621
    },
    {
      "name": "Artificial neural network",
      "score": 0.5097431540489197
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.5064395666122437
    },
    {
      "name": "Feature learning",
      "score": 0.461561381816864
    },
    {
      "name": "Deep learning",
      "score": 0.4609900116920471
    },
    {
      "name": "SIGNAL (programming language)",
      "score": 0.44977423548698425
    },
    {
      "name": "Transformer",
      "score": 0.41114065051078796
    },
    {
      "name": "Invariant (physics)",
      "score": 0.4108165502548218
    },
    {
      "name": "Feature vector",
      "score": 0.4101662039756775
    },
    {
      "name": "Mathematics",
      "score": 0.11232033371925354
    },
    {
      "name": "Engineering",
      "score": 0.07085675001144409
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Mathematical physics",
      "score": 0.0
    }
  ],
  "institutions": []
}