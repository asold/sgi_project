{
  "title": "Large language models as decision aids in neuro-oncology: a review of shared decision-making applications",
  "url": "https://openalex.org/W4392939056",
  "year": 2024,
  "authors": [
    {
      "id": null,
      "name": "Lawson McLean, Aaron",
      "affiliations": [
        "Comprehensive Cancer Center Mainfranken",
        "Friedrich Schiller University Jena",
        "Jena University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A1993644842",
      "name": "Wu, Yonghui",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": null,
      "name": "Lawson McLean, Anna C.",
      "affiliations": [
        "Friedrich Schiller University Jena",
        "Comprehensive Cancer Center Mainfranken",
        "Jena University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2750035444",
      "name": "Hristidis Vagelis",
      "affiliations": [
        "University of California, Riverside"
      ]
    },
    {
      "id": "https://openalex.org/A1993644842",
      "name": "Wu, Yonghui",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2750035444",
      "name": "Hristidis Vagelis",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4376866715",
    "https://openalex.org/W4385620011",
    "https://openalex.org/W3086667591",
    "https://openalex.org/W4378189609",
    "https://openalex.org/W4386826322",
    "https://openalex.org/W4312194635",
    "https://openalex.org/W4323050332",
    "https://openalex.org/W4319016959",
    "https://openalex.org/W2972256702",
    "https://openalex.org/W3158188155",
    "https://openalex.org/W1980058248",
    "https://openalex.org/W2802884616",
    "https://openalex.org/W3013269156",
    "https://openalex.org/W4384277274",
    "https://openalex.org/W4384519236",
    "https://openalex.org/W2059175649",
    "https://openalex.org/W3108469678",
    "https://openalex.org/W4324373918",
    "https://openalex.org/W4391472194",
    "https://openalex.org/W2400879687",
    "https://openalex.org/W2943759166",
    "https://openalex.org/W2212298497",
    "https://openalex.org/W6603684260",
    "https://openalex.org/W6600060591",
    "https://openalex.org/W3162922479",
    "https://openalex.org/W2045831130",
    "https://openalex.org/W2022630572",
    "https://openalex.org/W2968956882",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W2884603128",
    "https://openalex.org/W4312215529",
    "https://openalex.org/W4391069573",
    "https://openalex.org/W4392297945",
    "https://openalex.org/W2783032848",
    "https://openalex.org/W2070578512",
    "https://openalex.org/W4383346782",
    "https://openalex.org/W2898411150",
    "https://openalex.org/W4388824189",
    "https://openalex.org/W4381572755",
    "https://openalex.org/W3196986269",
    "https://openalex.org/W4390498094",
    "https://openalex.org/W3043247093",
    "https://openalex.org/W4210287787",
    "https://openalex.org/W3151748448",
    "https://openalex.org/W4365512576",
    "https://openalex.org/W2793130520",
    "https://openalex.org/W2940419730",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4316672966",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4283072634",
    "https://openalex.org/W4388909126",
    "https://openalex.org/W2908201961",
    "https://openalex.org/W1865339649",
    "https://openalex.org/W3192977992",
    "https://openalex.org/W4385476046",
    "https://openalex.org/W2789303506",
    "https://openalex.org/W4385227045",
    "https://openalex.org/W2996459254",
    "https://openalex.org/W4391221150",
    "https://openalex.org/W4285154716",
    "https://openalex.org/W4283079383",
    "https://openalex.org/W2507169601"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)\nJournal of Cancer Research and Clinical Oncology (2024) 150:139 \nhttps://doi.org/10.1007/s00432-024-05673-x\nREVIEW\nLarge language models as decision aids in neuro‑oncology: a review \nof shared decision‑making applications\nAaron Lawson McLean1,2  · Yonghui Wu3  · Anna C. Lawson McLean1,2  · Vagelis Hristidis4 \nReceived: 21 July 2023 / Accepted: 29 February 2024 / Published online: 19 March 2024 \n© The Author(s) 2024\nAbstract\nShared decision-making (SDM) is crucial in neuro-oncology, fostering collaborations between patients and healthcare pro-\nfessionals to navigate treatment options. However, the complexity of neuro-oncological conditions and the cognitive and \nemotional burdens on patients present significant barriers to achieving effective SDM. This discussion explores the potential \nof large language models (LLMs) such as OpenAI's ChatGPT and Google's Bard to overcome these barriers, offering a means \nto enhance patient understanding and engagement in their care. LLMs, by providing accessible, personalized information, \ncould support but not supplant the critical insights of healthcare professionals. The hypothesis suggests that patients, better \ninformed through LLMs, may participate more actively in their treatment choices. Integrating LLMs into neuro-oncology \nrequires navigating ethical considerations, including safeguarding patient data and ensuring informed consent, alongside the \njudicious use of AI technologies. Future efforts should focus on establishing ethical guidelines, adapting healthcare work -\nflows, promoting patient-oriented research, and developing training programs for clinicians on the use of LLMs. Continuous \nevaluation of LLM applications will be vital to maintain their effectiveness and alignment with patient needs. Ultimately, \nthis exploration contends that the thoughtful integration of LLMs into SDM processes could significantly enhance patient \ninvolvement and strengthen the patient-physician relationship in neuro-oncology care.\nKeywords Shared decision making · Large language models · Neuro-oncology care · Patient engagement · Ethical \nconsiderations  · Healthcare integration\nIntroduction\nRecent years have witnessed a significant shift in the \napproach to surgical consent and treatment planning, moving \naway from traditional medical paternalism towards shared \ndecision-making (SDM) (Edwards et al. 2023). SDM is an \nethical and professional approach that fosters a collabora-\ntive patient-physician relationship, emphasizing the impor -\ntance of informed consent based on mutual understanding \nand consideration of the best available evidence (Légaré \net al. 2018). This dynamic process of SDM aims to improve \nhealth outcomes and enhance patient satisfaction by involv-\ning patients in decision-making processes (Mik et al. 2018; \nElwyn et al. 2016).\n * Aaron Lawson McLean \n aaron.lawsonmclean@med.uni-jena.de\n Yonghui Wu \n yonghui.wu@ufl.edu\n Anna C. Lawson McLean \n anna.lawsonmclean@med.uni-jena.de\n Vagelis Hristidis \n vagelis@cs.ucr.edu\n1 Department of Neurosurgery, Jena University Hospital–\nFriedrich Schiller University Jena, Am Klinikum 1, \n07747 Jena, Germany\n2 Comprehensive Cancer Center Central Germany, Jena, \nGermany\n3 Department of Health Outcomes and Biomedical Informatics, \nCollege of Medicine, University of Florida, Gainesville, FL, \nUSA\n4 Computer Science and Engineering, University of California, \nRiverside, Riverside, CA, USA\n Journal of Cancer Research and Clinical Oncology (2024) 150:139\n139 Page 2 of 10\nImplementation of SDM in neuro‑oncology\nIn neuro-oncology, SDM is recognized as a crucial compo-\nnent in treatment decisions, aiming to involve patients and \nphysicians in collaborative discussions about treatment \nand goals of care (Corell et al. 2021; Musella et al. 2021). \nUnique to neuro-oncology, compared to other healthcare \ndomains, are the specific challenges of SDM, such as the \ncomplex nature of the disease, the urgency of treatment \ndecisions, cognitive challenges faced by patients, and the \nmultifaceted treatment options available (Díaz et al. 2009; \nShepherd et al. 2023). These distinct challenges, coupled \nwith barriers on both the patient and physician sides, can \nhinder the effective implementation of SDM in neuro-\noncology care (Leu et al. 2023). Addressing these barriers \nis crucial to ensure that SDM interventions truly achieve \ntheir intended goals of equitable education and emotional \nsupport for all stakeholders involved (Waddell et al. 2021).\nIn this article, we examine challenges impeding the \nimplementation of SDM in neuro-oncology and explore \nthe potential of conversational artificial intelligence \n(AI), exemplified by large language models (LLMs) such \nas OpenAI’s ChatGPT and Google's Bard, to overcome \nthese challenges. We argue that LLMs, sophisticated com-\nputational tools that generate coherent and contextually \nappropriate text responses from extensive datasets, may \nhold distinctive benefits in addressing these challenges. To \nexamine this perspective, we undertook a thematic anal-\nysis, drawing insights from a diverse range of literature \nspanning academic databases, tech-centric repositories \nsuch as arXiv and IEEE Xplore, preprint platforms such \nas bioRxiv and medRxiv, and other research aggregators \n(Roberts et al. 2019). Our multifaceted approach sought \nto provide a comprehensive and nuanced view of SDM's \nintricacies in the neuro-oncology landscape and the poten-\ntial role of LLMs in overcoming these hurdles.\nBarriers on the patient side\nPatients diagnosed with neuro-oncological conditions \noften face numerous challenges in understanding and \ndecision-making. Foremost among these is limited health \nliteracy (Chieffo et al. 2023 ; Porter et al. 2021 ; Reinert \net al. 2018). The medical world, laden with its complex \nterminology and detailed information, can be intimidating \n(Koch-Weser et al. 2009 ). Many neuro-oncology patients, \ndespite earnest efforts, find themselves overwhelmed and \nunable to fully understand their treatment options, hinder -\ning their capacity to make informed decisions (Sorensen \nVon Essen et al. 2022b). There is an urgent need for new \ncommunications strategies that effectively bridge this gap \nin health literacy and patient self-efficacy.\nIn addition, the profound emotional impact of a neuro-\noncological diagnosis can overshadow a patient's ability to \ncommunicate and make clear informed decisions. Emotions \nsuch as fear, anxiety, and overwhelming uncertainty can pre-\nvent them from actively participating in SDM discussions \n(Hermann et al. 2016). Recent studies by Leu et al. 2023; \nSorensen Von Essen et al. 2022 underscore the importance \nof not only medical guidance but also emotional support in \nthe neuro-oncology context (Leu et al. 2023; Sorensen Von \nEssen et al. 2022a). Creating a safe environment for patients \nto voice their fears and concerns is vital in alleviating the \nburden of these emotional obstacles (Heyhoe et al. 2015).\nFurthermore, conditions such as brain tumors often result \nin cognitive impairments. These mental alterations hinder \nthe patient's capacity to process complex medical informa-\ntion and engage actively in SDM (Coomans et al. 2019; \nGerstenecker et al. 2014; Gosselt et al. 2021). Evaluating \ncognitive functions in such a situation becomes essential. \nInvolving caregivers or relatives in the decision-making pro-\ncess is also crucial (Pace et al. 2020). It is worth highlight-\ning that the caregivers or close family members must also \nnavigate a turbulent emotional landscape, often mirroring \nthe confusion, fear, and lack of understanding experienced \nby the patients themselves (Hewins et al. 2019; CaC and \nBroekman 2022).\nIn today's information-rich age, there is another preva-\nlent challenge: information overload. Patients and caregiv -\ners are often swamped by the sheer volume of information \navailable, especially on the internet (Sorensen Von Essen \net al. 2022b). This information overload can lead to decision \nparalysis, making it hard for them to discern and understand \ntreatment options and potential outcomes. It is crucial for \nhealthcare providers and patients to be aware of these barri-\ners and identify strategies to address them together.\nBarriers on the physician side\nPhysicians, in their commitment to deliver the best neuro-\noncology care, face a set of distinct challenges, which may \naffect the implementation of SDM.\nOne of the most pervasive challenges is time constraints. \nWith busy schedules and ever-increasing patient loads, \nphysicians often find themselves pressed for time and even \nburned out (Downing et al. 2018; Kroth et al. 2019). Unfor-\ntunately, these limited windows for consultation can hinder \nthe depth and quality of discussions and SDM. Elwyn et al. \nstress the implications of this limited engagement, highlight-\ning the need for allocating adequate time to ensure enrich-\ning patient-physician interactions, fundamental for a holistic \nSDM approach in neuro-oncology care (Elwyn et al. 2016).\nJournal of Cancer Research and Clinical Oncology (2024) 150:139 \n Page 3 of 10 139\nWithin the challenges of SDM in neuro-oncology, one \ncannot overlook the profound emotional toll and associated \nburnout that physicians often grapple with. In a survey of \nEuropean and North American neuro-oncology providers \nconducted in 2016–2017, it was observed that professional \nburnout is a significant issue among those dedicated to the \ncare of patients with brain tumors (Yust-Katz and O’brien \nB et al. 2020). This syndrome, characterized by emotional \nexhaustion, depersonalization, and a sense of diminished \npersonal achievement, underscores a silent crisis among \nhealthcare providers in the realm of neuro-oncologist (Dun-\nbar and Kumthekar 2020). The implications of such burn-\nout cannot be understated, especially when deliberating on \nSDM's effectiveness in neuro-oncology. An emotionally \ndrained physician, grappling with burnout, might not opti-\nmally engage in shared decision-making, potentially sidelin-\ning the patient's perspective (West et al. 2018). Addressing \nphysician burnout, therefore, becomes key not just for the \nwell-being of healthcare providers but also for the overarch-\ning efficacy of the SDM paradigm in neuro-oncology care.\nNext comes the challenge of staying updated in a rapidly \nevolving field. The swift pace of advancements in neuro-\noncological research and treatment modalities can make it \ndifficult for physicians to keep up to date (Lukas et al. 2018). \nAny knowledge gaps, however, slight, could compromise \ntheir ability to provide the most recent and comprehensive \ninformation to patients, thereby affecting the SDM process. \nThis demonstrates the importance of continuous medical \neducation and easy access to trustworthy resources, which \ncan help physicians provide a consistently high standard of \ncare.\nHistorically, the physician–patient relationship has often \nbeen asymmetrical, with the former assuming a more domi-\nnant role (Kaba and Sooriakumaran 2007). This imbalance, \ncoupled with ingrained biases, can sometimes tilt the scales \naway from effective SDM (Makoul and Clayman 2006). A \ntendency towards paternalistic decision-making can lead to \ndecisions being made without fully integrating the patient's \nperspective. Edwards et al. 2023 identified the significance \nof recognizing and addressing these biases in the context of \nSDM involving patients with advanced cancer deciding on \npalliative treatments and care (Edwards et al. 2023). A tran-\nsition towards truly patient-centered care, where the patient's \nvoice is equally resonant, becomes crucial for the effective \nimplementation of SDM.\nFinally, even with the best intentions, effective commu-\nnication remains an elusive skill for some. While medical \nknowledge is vast, conveying it without resorting to jar -\ngon or overly complex language is vital. Any misunder -\nstanding in communication can create barriers to patients’ \nunderstanding, depriving them of a meaningful role in the \ndecision-making process (Vermeir et al. 2015). Therefore, \nmastering clear and accessible communication techniques is \nessential. By ensuring that complex information is relayed \nin an understandable manner, physicians empower patients \nto become active participants in their own care journey. In \nsum, while the challenges faced by physicians in the realm \nof SDM are multifaceted, acknowledging and proactively \naddressing them can pave the way for more collaborative \nand informed neuro-oncology care.\nBridging the gap with LLMs\nLLMs might offer some assistance in enhancing patient \neducation, counseling, and SDM within the complex field \nof neuro-oncology care. It is necessary to approach their \npotential with measured optimism, recognizing their limita-\ntions while considering their potential advantages for dis-\nseminating information and bolstering patient engagement \n(Ray 2023).\nLLMs have the capability to provide informative \nresponses tailored to one-off or conversational interactions \nwith users, based on the knowledge that the LLMs have \nacquired through analyzing millions of documents, a process \nknown as “training”. LLMs can potentially aid in clarifying \nmedical notions, laying out and explaining treatment options, \nand conversing about possible pros and cons in a compre-\nhensible way (Singhal et al. 2023). With a potential basis \nin clinical evidence, LLMs might offer patients a clearer \nlens through which to view their care choices, and how \nthese align with their personal objectives (Jin et al. 2021). \nAlthough they generally do not have access real-time patient \nspecifics, the immense computational power of LLMs can \nstill be looked at as a resource for broad knowledge sharing, \npossibly making medical concepts more understandable for \npatients (Harrer 2023).\nIn relation to SDM, LLMs could potentially be utilized \nas decision-support tools, presenting patients with overarch-\ning views of treatment alternatives (Yang et al. 2023). By \ntapping into an expansive knowledge sourced from neuro-\noncology cases, clinical standards, scientific findings, and \nclinical trial data, LLMs might address patient queries, miti-\ngate apprehensions, and generally improve understanding. \nLLMs might also help patients prepare for their next physi-\ncian visit, by jointly creating a small set of questions to ask \ntheir healthcare provider. With the right kind of information, \npatients might find themselves in a better position to partake \nin decision-making processes.\nOne significant advantage of LLMs over conventional \nweb search engines, such as Google, is their capacity to \nalleviate the issue of information overload. Rather than pre-\nsenting users with an overwhelming array of web pages, \nLLMs synthesize information into concise, coherent par -\nagraphs that respond directly to the user's query, thereby \nfacilitating patient education and setting the stage for more \n Journal of Cancer Research and Clinical Oncology (2024) 150:139\n139 Page 4 of 10\nsubstantive discussions within the framework of SDM For \nLLMs to effectively contribute to SDM, it is imperative \nthat the information they provide is accessible to patients, \nnecessitating a literacy level commensurate with that of the \nintended audience. Recent analyses have indicated that out-\nputs from models like ChatGPT often demand high literacy \nlevels for comprehension, posing challenges in the context \nof patient education on complex medical topics (Dash et al. \n2023; Haver et al. 2024; Onder et al. 2024; Temel et al. \n2024). However, this limitation can be addressed through \nstrategic prompting—the method by which a query is for -\nmulated by the user (Gao 2023). For instance, a user might \nspecify, “Explain low-grade glioma as if to a 10th-grader,” \nthus tailoring the complexity of the LLM’s response to suit \nthe patient's needs.\nIt is critical to emphasize that current LLMs do not pos-\nsess the requisite maturity for direct healthcare applications, \nand thus, should not be considered replacements for health-\ncare professionals (Dinan et al. 2021). Rather, they func-\ntion as supplementary informational aids that can enhance \npatient education and facilitate more comprehensive discus-\nsions. A principal limitation preventing LLMs from acting as \nsubstitutes for physicians is the lack of guaranteed scientific \naccuracy in their responses (Mittelstadt et al. 2023). This \ninaccuracy arises not only from potential misinformation \npresent in the training datasets but also from the phenom-\nenon known as “hallucination,” where an LLM generates \ncontent that is not verifiably sourced from its training data \n(Huang et al. 2023). Addressing this issue of hallucination \nrepresents a significant focus of ongoing research.\nFurthermore, LLMs may not deliver the most current \nor advanced information due to delays in retraining cycles, \nwhich occur infrequently due to high computational costs \n(Ling et al. 2023). For instance, updates to models such as \nChatGPT are not continuous, resulting in responses that may \nlack the latest scientific findings or treatment advancements. \nThis temporal gap in knowledge underscores the models' \nlimitations in providing real-time, state-of-the-art medical \nadvice. Despite these constraints, the application of LLMs in \npatient education offers the potential to alleviate the burden \nof information overload on healthcare practitioners, thereby \nenabling them to dedicate more attention to patient-centered \ncare, consider the clinical implications of medical informa-\ntion, and offer personalized advice. This strategic utilization \nof LLMs could play a crucial role in enhancing the quality \nof healthcare delivery by supporting the informational needs \nof patients and practitioners alike.\nThe integration of LLMs for SDM in neuro-oncology is \ndetailed in the workflow show in Table  1, beginning with \npatient input and concluding with the process's evaluation \nand refinement. Illustrating this approach with a young \npatient diagnosed with a low-grade glioma highlights the \ncapability of LLMs to enrich each stage of care. While this \noffers guide for incorporating LLMs into neuro-oncology \nSDM, practical implementations may vary to suit distinct \nhealthcare environments and resource availability.\nEthical considerations\nThe burgeoning integration of LLMs in healthcare, particu-\nlarly in the domain of neuro-oncology, brings with it a host \nof ethical challenges. As these AI-driven tools increasingly \ninfluence patient education, counseling, and SDM, we must \ncarefully examine a series of ethical considerations to chart \na responsible and effective future for this technology.\nFirst, ensuring patient privacy and informed consent is \nparamount when integrating LLMs into healthcare. LLMs \nprocess individual patient data to generate personalized \nresponses, necessitating rigorous data protection measures, \nanonymization techniques, and comprehensive informed \nconsent frameworks to safeguard patient confidentiality \nwhile leveraging LLM capabilities (Meskó and Topol 2023). \nRecent incidents, such as ChatGPT’s inadvertent leakage of \nsensitive business information belonging to a private com-\npany, underscore the imperative for scrutinizing the security \nand potential risks associated with LLM use (Borger et al. \n2023; Nasr et al. 2023).\nThe feasibility of patients using public LLM platforms \nto discuss health conditions without compromising privacy \nremains problematic. Even without disclosing identifiable \ninformation, research has demonstrated the potential for \ndeducing user identities through aggregated web search que-\nries (Hussien et al. 2013; Zhang et al. 2022). One proposed \nsolution is the deployment of private, locally hosted LLMs, \nwhich, while addressing privacy concerns, introduces sig-\nnificant costs associated with maintaining the necessary \ncomputational infrastructure (Hong et al. 2023). Addition-\nally, such private models may lag behind the continuous \nadvancements achieved by publicly available LLM technolo-\ngies, presenting a trade-off between privacy protection and \naccess to cutting-edge capabilities.\nThe responsible use of these AI-driven tools stands \nas another cardinal consideration. As they become more \nentrenched in our clinical workflows, it's vital to anchor \ntheir deployment in established clinical guidelines, evi-\ndence-based approaches, and professional standards (Ben-\njamens et al. 2020; Topol 2019). This necessitates that \nLLM-informed chatbots and decision aids are not just tech-\nnologically sophisticated but are also grounded in rigorous \nscientific scrutiny (Li et al. 2024; Sallam 2023b). For profes-\nsionals to have faith in the outputs of LLMs, there must be \ntransparent documentation detailing the algorithms’ inner \nworkings and the data on which they were trained (Liao and \nWortman Vaughan 2023).\nMoreover, the journey with LLMs doesn’t end at their \nintegration; it demands continual evaluation and refinement \nJournal of Cancer Research and Clinical Oncology (2024) 150:139 \n Page 5 of 10 139\n(Mökander et al. 2023). Ensuring these tools serve the \npatient optimally requires vigilance against potential biases \nand a commitment to enhancing their efficacy. By regu-\nlarly analyzing their outputs and absorbing user feedback, \nwe can sharpen their utility (Lee et al. 2023). For example, \nthe recently developed concept of retrieval-augmented gen-\neration (RAG) has emerged as an avenue to enhance the \nspecificity and relevance of LLM responses. By embed-\nding updated clinical data and trusted medical sources, the \nRAG approach promises to provide more tailored prompt \nresponses and guidance (Zakka et al. 2024; Wang et al. \n2023). The endeavor to refine LLMs in neuro-oncology care \nmust be a collaborative one, pooling insights from clinicians, \nresearchers, and, crucially, the patients themselves.\nFinally, while LLMs stand as a testament to technologi-\ncal prowess, it's vital to delineate their role clearly. They are \ninstruments of information and guidance, not replacements \nfor the nuanced care of healthcare professionals (Baum-\ngartner and Baumgartner 2023; Bommasani et al. 2023). \nPhysicians, with their depth of training and experience, \nremain indispensable in interpreting LLM-generated con-\ntent, molding it to the unique contours of each patient's clini-\ncal situation. In weaving LLMs into the fabric of healthcare, \nthe aim should be to augment the patient-physician relation-\nship, fortifying the principle of informed decision-making \nand ensuring that patients continue to be at the center of \ntheir care trajectory.\nTable 2 presents both the potential benefits and crucial \nconsiderations when incorporating LLMs into SDM. It \nemphasizes the need to weigh advantages against ethical \nand practical concerns.\nFuture directions\nThe field of neuro-oncology, characterized by its significant \nemotional and cognitive demands on patients, presents a dis-\ntinctive context for decision-making processes (Pertz et al. \n2022). This context positions neuro-oncology at the intersec-\ntion of clinical challenges and technological opportunities, \nparticularly regarding the implementation of LLMs within \nSDM frameworks. The future trajectory of LLMs in SDM \nis both promising and complex, necessitating strategic plan-\nning for their integration.\nCentral to this integration is the imperative for ethical \nconsiderations. Developing clear ethical guidelines and \nTable 1  Workflow for utilizing LLMs in shared decision-making for neuro-oncology care\nThis table presents an advanced framework for incorporating LLMs into the treatment decision-making process for patients with low-grade \ngliomas. It delineates a sequential, nine-step pathway that begins with the patient's initial input about their condition and concludes with the \nfollow-up and evaluation of the chosen treatment. The structure emphasizes the integration of AI tools in healthcare, aiming to enhance patient \nengagement, satisfaction, and outcomes by providing tailored, accessible information throughout the decision-making journey. The specific \nimplementation may vary depending on the context and available resources\nAI artificial intelligence, LLM large language model\nStep Description\nStep 1: Patient input Patient provides information, concerns, and preferences regarding their condition and treatment options\nExamples from the case of a young patient diagnosed with a low-grade glioma following a brain biopsy:\nWhat is a low-grade glioma?\nWhat are my treatment options for a low-grade glioma?\nWhat are the potential risks and benefits associated with each treatment option?\nHow will treatment for a low-grade glioma affect my daily life and long-term outcomes?\nStep 2: LLM interaction LLM interacts with the patient, generating tailored responses to address patient queries and provide \nrelevant information\nStep 3: Information dissemination LLM presents evidence-based information about treatment options, including risks, benefits, and poten-\ntial outcomes\nStep 4: Patient consideration Patient reviews the information provided by the LLM, considers their preferences and priorities, and \nexplores treatment possibilities\nStep 5: Patient-physician discussion Patient engages in a discussion with the physician, sharing insights gained from the LLM interaction \nand discussing treatment options in more detail\nStep 6: Physician interpretation Physician analyzes patient-specific data, interprets clinical implications, and provides personalized \nadvice and recommendations\nStep 7: Post-discussion LLM interactio After the patient-physician discussion, the patient interacts again with the LLM to clarify any remaining \nquestions or concerns regarding the physician's recommendations. This step aims to reinforce under-\nstanding and ensure the patient feels fully informed\nStep 8: Collaborative decision-making Patient and physician collaborate in making informed decisions, taking into account the patient's values, \npreferences, and clinical expertise\nStep 9: Follow-up and evaluation Treatment decisions are implemented, and the patient’s progress is monitored. The effectiveness of \nLLM-based SDM is evaluated and refined for future improvements\n Journal of Cancer Research and Clinical Oncology (2024) 150:139\n139 Page 6 of 10\nTable 2  Overview of implementing LLMs in SDM for healthcare\nCategory Sub-category Details Implications/strategies\nBenefits of LLMs Accessible information Provides tailored information, addressing patient \nconcerns and queries, enhancing understanding and \nengagement\nEnsures information is aligned with patient needs and \npreferences, complementing clinical expertise\nPersonalized care LLMs can analyze vast datasets to offer personalized \ninsights and recommendations for patient care\nTailor healthcare strategies to individual patient profiles, \nimproving outcomes and patient satisfaction\nSupport for clinical decision-making Augments clinician knowledge with evidence-based \nsuggestions, reducing diagnostic and therapeutic \nerrors\nEnhance the accuracy of clinical decisions, support com-\nplex case analysis, and complement clinician expertise\nPatient education and empowerment Facilitates deeper patient understanding of their health \nconditions and treatment options\nEmpower patients to actively participate in their care, \nleading to better health outcomes and satisfaction\nClinical training and education Offers a dynamic, interactive platform for medical \neducation and professional development\nImprove the training of healthcare professionals with up-\nto-date, scenario-based learning tools\nResearch and development Accelerates medical research by analyzing patterns and \ngenerating hypotheses from large datasets\nDrive innovation in treatment methods, diagnostic tools, \nand healthcare delivery models\nEfficiency in healthcare operations Streamlines administrative tasks, patient triage, and \nresource allocation\nOptimize healthcare delivery, reduce wait times, and \nimprove overall operational efficiency\nConsiderations for LLM use Ethical and privacy concerns Ethical considerations for patient data privacy and \nconsent\nIntegration with healthcare workflows, responsible AI \nuse, ongoing evaluation, and literacy level adjustments \nin responses\nIntegration and workflow alignment Integration with existing healthcare workflows and \npractices\nAlign tools with patient and clinical needs, facilitating \nseamless engagement and complementing expertise\nChallenges in SDM Accuracy and reliability AI-generated information may not always be accurate \nor up-to-date\nDecision-making may rely on outdated information, \nnecessitating continuous updates and accuracy checks\nInterpretability Complexity in AI outputs can hinder patient and clini-\ncian understanding\nDevelop intuitive interfaces and present information in \nlay terms for effective communication\nBias and equity Perpetuation of biases affects fairness in recommenda-\ntions\nImplement diverse datasets and continuous auditing to \nmitigate biases and ensure equitable care\nData privacy Concerns over data security and patient privacy Enhance data protection measures and communicate \npractices transparently to build trust\nTechnical requirements Computational resources Necessity for high-performance computing for LLM \noperations\nEnsure availability of resources to support large-scale \ndata processing and AI computations\nData infrastructure Secure, compliant infrastructure for patient data man-\nagement\nRobust data protection and privacy measures are crucial \nfor secure and efficient data handling\nIntegration capabilities Compatibility with EHRs and clinical decision support \nsystems\nFacilitate seamless integration to leverage existing digital \nhealth infrastructures\nUser interface and training Development of user-friendly interfaces and ongoing \nprofessional education\nEnhance interaction with LLM outputs and ensure effec-\ntive use and interpretation in clinical settings\nJournal of Cancer Research and Clinical Oncology (2024) 150:139 \n Page 7 of 10 139\nTable 2  (continued)\nCategory Sub-category Details Implications/strategies\nStrategies for overcoming limitations Algorithmic bias Bias leading to unequal care outcomes Diverse training datasets and continuous auditing to \nidentify and address biases\nData privacy concerns Impacts patient trust and data sharing willingness Strengthen data protection and communicate handling \npractices clearly\nReal-time updates AI recommendations may not reflect the latest research Incorporate mechanisms for continuous learning and \nupdates based on new data and studies\nInterdisciplinary collaboration Essential but often lacking for effective implementation Foster teams of clinicians, AI experts, ethicists to guide \ndevelopment and deployment\nRegulatory and ethical considerations Navigating the complex regulatory landscape and ethi-\ncal dilemmas\nDevelop guidelines and ethical frameworks, engaging \nwith regulatory bodies and ethicists early in the process\nThis table delineates the multifaceted considerations associated with the implementation and utilization of LLMs within the context of SDM in healthcare settings. It systematically categorizes \ncritical aspects into five main areas: the benefits of employing LLMs for enhancing patient engagement and understanding; the considerations necessary for ethical deployment and integration \ninto existing clinical workflows; the challenges faced in ensuring the accuracy, interpretability, and equity of AI-generated information; the technical and infrastructural requirements for effec-\ntive LLM implementation; and strategic approaches for overcoming potential limitations such as algorithmic bias, privacy concerns, and the need for real-time updates. Each category and sub-\ncategory is elaborated with details on the specific issue or benefit, alongside implications or strategies aimed at addressing these aspects to optimize patient care outcomes and support healthcare \nprofessionals\nAI artificial intelligence, LLM large language model, SDM shared decision-making, EHR electronic health record\n Journal of Cancer Research and Clinical Oncology (2024) 150:139\n139 Page 8 of 10\nregulatory frameworks for LLM technologies in health-\ncare is critical. Such frameworks must address a range of \nconcerns, including patient data privacy, transparency, and \ninformed consent, alongside efforts to mitigate biases and \npromote responsible use (Meskó and Topol 2023). These \nelements are essential for establishing a strong ethical foun-\ndation for the application of LLMs in neuro-oncology.\nThe utility of ethically designed LLM tools is contingent \nupon their compatibility with clinical workflows. Future \ndevelopments should focus on integrating LLM tools seam-\nlessly into clinical practices, which can be facilitated by \ndesigning intuitive user interfaces, ensuring compatibility \nwith existing electronic health records, and creating syner -\ngies with current decision-support systems (Sallam 2023a). \nEffective integration is key to optimizing the utility of LLMs \nand securing their acceptance within the medical community \n(Sallam 2023b). Moreover, the focus on patient-centric out-\ncomes is vital. Investigating the effects of LLMs on patient \nsatisfaction, decision quality, treatment adherence, and long-\nterm health outcomes is crucial for assessing the real-world \nimpact of LLMs in SDM.\nFurthermore, the education and training of healthcare \nprofessionals regarding LLM technologies are of paramount \nimportance. Ensuring that clinicians are knowledgeable \nabout the capabilities, limitations, and potential biases of \nLLMs is necessary for informed clinical decision-making \nand maintaining trust between healthcare providers and \npatients.\nFinally, equipping the current and next generation of \nhealthcare professionals is paramount (Abd-Alrazaq et al. \n2023). The integration of LLMs in neuro-oncology neces-\nsitates specialized education and training endeavors. By \nensuring clinicians are well-versed in the strengths, pitfalls, \nand nuanced biases of LLM technologies, we can pave the \nway for more informed clinical decisions and reinforce the \nmutual trust between healthcare providers and their patients \n(Cascella et al. 2023).\nConclusion\nSDM appears to offer significant potential in neuro-oncol-\nogy care. As efforts are made to foster a more collaborative \nenvironment between patients and healthcare profession-\nals, LLMs might be considered as tools to support patient \neducation, counseling, and initial dialogues. They might aid \nin delivering information, addressing patient queries, and \nenhancing clarity regarding treatment choices, which could, \nin turn, help patients feel more involved, possibly improve \npatient-doctor interactions, and alleviate some disease and \ntreatment-related anxiety and apprehensions.\nIntegrating LLMs with SDM practices offers the oppor -\ntunity to increase patient engagement, potentially improve \ntreatment outcomes, and foster a more supportive relation-\nship between patients and doctors in neuro-oncology care. \nHowever, it is essential to recognize that LLMs are supple-\nments, not substitutes, for clinical expertise. Their potential \nto enhance the decision-making process with accessible and \npersonalized information must therefore be approached with \ncareful consideration of ethical standards, data protection, \nand continuous evaluation.\nAuthor contributions All named authors meet ICMJE authorship \ncriteria. ALM led the project's conceptualization, methodology, data \nanalysis, and initial manuscript draft. ACLM, YW, and VH provided \ncritical revisions and intellectual content. All authors approved the \nfinal manuscript.\nFunding Open Access funding enabled and organized by Pro-\njekt DEAL. YW received funding from the Patient-Centered \nOutcomes Research Institute (PCORI) under award number ME-\n2018C3-14754 and from the National Institute on Aging (NIA) via \ngrant R56AG069880. No additional external funding, grants, or rel-\nevant financial support was provided for this research.\nData availability statement All datasets generated and analyzed during \nthe current study are included in this published article. No additional \ndata are available.\nDeclarations \nConflict of interest The authors declare no potential conflicts of in-\nterest concerning the research, authorship, and/or publication of this \narticle.\nEthical approval Formal ethical approval was not required according \nto applicable legislation and institutional guidance.\nOpen Access  This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article's Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article's Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nReferences\nAbd-Alrazaq A, Alsaad R, Alhuwail D et al (2023) Large language \nmodels in medical education: opportunities, challenges, and future \ndirections. JMIR Med Educ. https:// doi. org/ 10. 2196/ 48291\nBaumgartner C, Baumgartner D (2023) A regulatory challenge for \nnatural language processing (NLP)-based tools such as ChatGPT \nto be legally used for healthcare decisions. where are we now? \nClin Transl Med. https:// doi. org/ 10. 1002/ ctm2. 1362\nBenjamens S, Dhunnoo P, Meskó B (2020) The state of artificial intel-\nligence-based FDA-approved medical devices and algorithms: \nJournal of Cancer Research and Clinical Oncology (2024) 150:139 \n Page 9 of 10 139\nan online database. Npj Digit Med. https:// doi. org/ 10. 1038/  \ns41746- 020- 00324-0\nBommasani R, Liang P, Lee T (2023) Holistic evaluation of language \nmodels. Ann N Y Acad Sci 1525:140–146\nBorger JG, Ng AP, Anderton H et al (2023) Artificial intelligence \ntakes center stage: exploring the capabilities and implications \nof ChatGPT and other AI-assisted technologies in scientific \nresearch and education. Immunol Cell Biol 101:923–935\nJesserun CAC, Broekman MLD (2022) True shared decision-making \nin neurosurgical oncology: does it really exist? Acta Neurochir \n165:11–13\nCascella M, Montomoli J, Bellini V et al (2023) Evaluating the fea-\nsibility of ChatGPT in healthcare: an analysis of multiple clini-\ncal and research scenarios. J Med Syst. https:// doi. org/ 10. 1007/ \ns10916- 023- 01925-4\nChieffo DPR, Lino F, Ferrarese D et al (2023) Brain tumor at diagno-\nsis: from cognition and behavior to quality of life. Diagnostics. \nhttps:// doi. org/ 10. 3390/ diagn ostic s1303 0541\nCoomans MB, Van Der Linden SD, Gehring K et al (2019) Treat-\nment of cognitive deficits in brain tumour patients: current sta-\ntus and future directions. Curr Opin Oncol 31:540–547\nCorell A, Guo A, Vecchio TG et al (2021) Shared decision-making in \nneurosurgery: a scoping review. Acta Neurochir 163:2371–2382\nDash D, Thapa R, Banda JM et al. (2023) Evaluation of GPT-3.5 and \nGPT-4 for supporting real-world information needs in health-\ncare delivery. In, p arXiv: 2304. 13714\nDíaz JL, Barreto P, Gallego JM et al (2009) Proper information dur -\ning the surgical decision-making process lowers the anxiety of \npatients with high-grade gliomas. Acta Neurochir 151:357–362\nDinan E, Abercrombie G, Stevie Bergman A et al. (2021) Antici-\npating safety issues in E2E conversational AI: framework and \ntooling. In, p arXiv: 2107. 03451\nDowning NL, Bates DW, Longhurst CA (2018) Physician burnout in \nthe electronic health record era: are we ignoring the real cause? \nAnn Int Med. https:// doi. org/ 10. 7326/ M18- 0139\nDunbar EM, Kumthekar PU (2020) In pursuit of a perpetually burn-\ning flame: preventing burnout in neuro-oncology. Neuro Oncol \n22:750–751\nEdwards M, Holland-Hart D, Mann M et al (2023) Understanding \nhow shared decision-making approaches and patient aids influ-\nence patients with advanced cancer when deciding on palliative \ntreatments and care: a realist review. Health Expect. https:// doi.  \norg/ 10. 1111/ hex. 13822\nElwyn G, Frosch DL, Kobrin S (2016) Implementing shared deci-\nsion-making: consider all the consequences. Implement Sci \n11:1–10\nGao A (2023) Prompt engineering for large language models. SSRN \nElectr J. https:// doi. org/ 10. 2139/ ssrn. 45043 03\nGerstenecker A, Nabors LB, Meneses K et al (2014) Cognition in \npatients with newly diagnosed brain metastasis: profiles and impli-\ncations. J Neurooncol 120:179–185\nGosselt IK, Scheepers VPM, Spreij LA et al (2021) Cognitive com-\nplaints in brain tumor patients and their relatives’ perspectives. \nNeuro-Oncol Pract 8:160–170\nHarrer S (2023) Attention is not all you need: the complicated case of \nethically using large language models in healthcare and medicine. \nEBioMedicine. https:// doi. org/ 10. 1016/j. ebiom. 2023. 104512\nHaver HL, Gupta AK, Ambinder EB et al (2024) Evaluating the use \nof ChatGPT to accurately simplify patient-centered information \nabout breast cancer prevention and screening. Radiol Imag Can-\ncer. https:// doi. org/ 10. 1148/ rycan. 230086\nHermann H, Trachsel M, Elger BS et al (2016) Emotion and value in \nthe evaluation of medical decision-making capacity: a narrative \nreview of arguments. Front Psychol. https:// doi. org/ 10. 3389/ fpsyg. \n2016. 00765\nHewins W, Zienius K, Rogers JL et al (2019) The effects of brain \ntumours upon medical decision-making capacity. Curr Oncol Rep \n21:55\nHeyhoe J, Birks Y, Harrison R et al (2015) The role of emotion in \npatient safety: are we brave enough to scratch beneath the sur -\nface? J R Soc Med 109:52–58\nHong J, Wang JT, Zhang C et al. (2023) DP-OPT: make large lan-\nguage model your privacy-preserving prompt engineer. in, p \narXiv: 2312. 03724\nHuang L, Yu W, Ma W et al. (2023) A survey on hallucination in \nlarge language models: principles, taxonomy, challenges, and \nopen questions. in, p arXiv: 2311. 05232\nHussien A-E-EA, Hamza N, Hefny HA (2013) Attacks on anonymi-\nzation-based privacy-preserving: a survey for data mining and \ndata publishing. J Inf Secur 04:101–112\nJin D, Pan E, Oufattole N et al (2021) What disease does this patient \nhave? a large-scale open domain question answering dataset \nfrom medical exams. Appl Sci. https:// doi. org/ 10. 3390/ app11  \n146421\nKaba R, Sooriakumaran P (2007) The evolution of the doctor-patient \nrelationship. Int J Surg 5:57–65\nKoch-Weser S, Dejong W, Rudd RE (2009) Medical word use in \nclinical encounters. Health Expect 12:371–382\nKroth PJ, Morioka-Douglas N, Veres S et al (2019) Association of \nelectronic health record design and use factors with clinician \nstress and burnout. JAMA Netw Open 2:e199609\nLee P, Bubeck S, Petro J (2023) Benefits, limits, and risks of GPT-4 \nas an AI chatbot for medicine. N Engl J Med 388:1233–1239\nLégaré F, Adekpedjou R, Stacey D et al (2018) Interventions for \nincreasing the use of shared decision making by healthcare pro-\nfessionals 2018. Cochrane Datab Syst Rev. https:// doi. org/ 10.  \n1002/ 14651 858. CD006 732. pub4\nLeu S, Cahill J, Grundy PL (2023) A prospective study of shared \ndecision-making in brain tumor surgery. Acta Neurochir \n165:15–25\nLi J, Dada A, Puladi B, Kleesiek J, Egger J (2024) ChatGPT in health-\ncare: a taxonomy and systematic review. Comput Methods Pro-\ngrams Biomed 245:108013. https:// doi. org/ 10. 1016/j. cmpb. 2024. \n108013\nLiao QV, Wortman Vaughan J (2023) AI Transparency in the Age \nof LLMs: A Human-Centered Research Roadmap. In, p arXiv:  \n2306. 01941\nLing C, Zhao X, Lu J et al. (2023) Domain specialization as the key to \nmake large language models disruptive: a comprehensive survey. \nIn, p arXiv: 2305. 18703\nLukas RV, Wu J, Dey M et al (2018) A survey of the neuro-oncology \nlandscape. J Clin Neurol. https:// doi. org/ 10. 3988/ jcn. 2018. 14.1.8\nMakoul G, Clayman ML (2006) An integrative model of shared \ndecision making in medical encounters. Patient Educ Couns \n60:301–312\nMeskó B, Topol EJ (2023) The imperative for regulatory oversight of \nlarge language models (or generative AI) in healthcare. Npj Digit \nMed. https:// doi. org/ 10. 1038/ s41746- 023- 00873-0\nDe Mik SML, Stubenrouch FE, Balm R et al (2018) Systematic review \nof shared decision-making in surgery. Br J Surg 105:1721–1730\nMittelstadt B, Wachter S, Russell C (2023) To protect science, we must \nuse LLMs as zero-shot translators. Nat Hum Behav 7:1830–1832\nMökander J, Schuett J, Kirk HR et al (2023) Auditing large language \nmodels: a three-layered approach. AI Eth. https:// doi. org/ 10. 1007/ \ns43681- 023- 00289-2\nMusella A, Devitto R, Anthony M et al (2021) The Importance of \nshared decision-making for patients with glioblastoma. Patient \nPrefer Adher 15:2009–2016\nNasr M, Carlini N, Hayase J et al. (2023) Scalable extraction of training \ndata from (production) language Models. In, p arXiv: 2311. 17035\n Journal of Cancer Research and Clinical Oncology (2024) 150:139\n139 Page 10 of 10\nOnder CE, Koc G, Gokbulut P et al (2024) Evaluation of the reli-\nability and readability of ChatGPT-4 responses regarding hypo-\nthyroidism during pregnancy. Sci Rep. https://  doi. org/ 10. 1038/ \ns41598- 023- 50884-w\nPace A, JaF K, Van Den Bent MJ et al (2020) Determining medical \ndecision-making capacity in brain tumor patients: why and how? \nNeuro-Oncol Pract 7:599–612\nPertz M, Schlegel U, Thoma P (2022) Sociocognitive functioning \nand psychosocial burden in patients with brain tumors. Cancers. \nhttps:// doi. org/ 10. 3390/ cance rs140 30767\nPorter AB, Chukwueke UN, Mammoser AG et al (2021) Delivering \nequitable care to underserved neuro-oncology populations. Am \nSoc Clin Oncol Educ B. https:// doi. org/ 10. 1200/ EDBK_ 320803\nRay PP (2023) ChatGPT: a comprehensive review on background, \napplications, key challenges, bias, ethics, limitations and future \nscope. Intern Th Cyber-Phys Syst 3:121–154\nReinert C, Rathberger K, Klinkhammer-Schalke M et al (2018) Infor-\nmation needs and requirements in patients with brain tumours and \ntheir relatives. J Neurooncol 138:407–415\nRoberts K, Dowell A, Nie JB (2019) Attempting rigour and replicabil-\nity in thematic analysis of qualitative research data; a case study \nof codebook development. BMC Med Res Methodol. https:// doi. \norg/ 10. 1186/ s12874- 019- 0707-y\nSallam M (2023) ChatGPT utility in healthcare education, research, \nand practice: systematic review on the promising perspectives \nand valid concerns. Healthcare. https:// doi. org/ 10. 3390/ healt  \nhcare 11060 887\nShepherd SC, Hacking B, Wallace LM et al (2023) Feeling known and \ninformed: Serial qualitative interviews evaluating a consultation \nsupport intervention for patients with high-grade glioma. Cancer \nMed 12:8652–8661\nSinghal K, Azizi S, Tu T et al (2023) Large language models encode \nclinical knowledge. Nature 620:172–180\nSorensen Von Essen H, Poulsen FR, Dahlrot RH et al (2022a) Develop-\nment of a patient decision aid to support shared decision making \nfor patients with recurrent high-grade glioma. Int J Environ Res \nPub Health. https:// doi. org/ 10. 3390/ ijerp h1912 7396\nSorensen Von Essen H, Stacey D, Dahl Steffensen K et al (2022b) \nDecisional needs of patients with recurrent high-grade glioma \nand their families. Neurooncol Pract 9:402–410\nTemel MH, Erden Y, Bağcıer F (2024) Information quality and read-\nability: ChatGPT’s responses to the most common questions about \nspinal cord injury. W Neurosurg 181:e1138–e1144\nTopol EJ (2019) High-performance medicine: the convergence of \nhuman and artificial intelligence. Nat Med 25:44–56\nVermeir P, Vandijck D, Degroote S et al (2015) Communication in \nhealthcare: a narrative review of the literature and practical rec-\nommendations. Int J Clin Pract 69:1257–1267\nWaddell A, Lennox A, Spassova G et al (2021) Barriers and facilita-\ntors to shared decision-making in hospitals from policy to prac-\ntice: a systematic review. Implement Sci. https:// doi. org/ 10. 1186/ \ns13012- 021- 01142-y\nWang C, Ong J, Wang C et al (2023) Potential for GPT technology \nto optimize future clinical decision-making using retrieval-\naugmented generation. Ann Biom Eng. https:// doi. org/ 10. 1007/ \ns10439- 023- 03327-6\nWest CP, Dyrbye LN, Shanafelt TD (2018) Physician burnout: con-\ntributors, consequences and solutions. J Intern Med 283:516–529\nYang R, Tan TF, Lu W et al (2023) Large language models in health \ncare: development, applications, and challenges. Health Care Sci. \nhttps:// doi. org/ 10. 1002/ hcs2. 61\nYust-Katz S, O’brienVera BE et al (2020) Burnout and career satisfac-\ntion in neuro-oncology: a survey of the society for neuro-oncology \nand the european association of neuro-oncology memberships. \nNeuro Oncol 22:838–850\nZakka C, Shad R, Chaurasia A, Dalal AR, Kim JL, Moor M, Fong \nR, Phillips C, Alexander K, Ashley E, Boyd J, Boyd K, Hirsch \nK, Langlotz C, Lee R, Melia J, Nelson J, Sallam K, Tullis S, \nVogelsong MA, Cunningham JP, Hiesinger W (2024) Almanac - \nretrieval-augmented language models for clinical medicine. NEJM \nAI 1(2). https:// doi. org/ 10. 1056/ aioa2 300068\nZhang S, Ray S, Lu R et al (2022) Toward privacy-preserving aggre-\ngate reverse skyline query with strong security. IEEE Trans Inf \nForens Secur 17:2538–2552\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Safeguarding",
  "concepts": [
    {
      "name": "Safeguarding",
      "score": 0.7991219758987427
    },
    {
      "name": "Health care",
      "score": 0.5159974098205566
    },
    {
      "name": "Informed consent",
      "score": 0.4683356285095215
    },
    {
      "name": "Workflow",
      "score": 0.4482632875442505
    },
    {
      "name": "Medicine",
      "score": 0.38825058937072754
    },
    {
      "name": "Psychology",
      "score": 0.36929842829704285
    },
    {
      "name": "Oncology",
      "score": 0.36019977927207947
    },
    {
      "name": "Nursing",
      "score": 0.20553624629974365
    },
    {
      "name": "Alternative medicine",
      "score": 0.1920909583568573
    },
    {
      "name": "Political science",
      "score": 0.18391403555870056
    },
    {
      "name": "Computer science",
      "score": 0.09871304035186768
    },
    {
      "name": "Pathology",
      "score": 0.08710840344429016
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Database",
      "score": 0.0
    }
  ]
}