{
  "title": "Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education",
  "url": "https://openalex.org/W4386574312",
  "year": 2023,
  "authors": [
    {
      "id": null,
      "name": "Abedi, Mahyar",
      "affiliations": [
        "Michigan State University"
      ]
    },
    {
      "id": null,
      "name": "Alshybani, Ibrahem",
      "affiliations": [
        "Michigan State University"
      ]
    },
    {
      "id": null,
      "name": "Shahadat, Muhammad Rubayat Bin",
      "affiliations": [
        "Michigan State University"
      ]
    },
    {
      "id": "https://openalex.org/A4271755977",
      "name": "Murillo, Michael S.",
      "affiliations": [
        "Michigan State University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W153048087",
    "https://openalex.org/W3022090634",
    "https://openalex.org/W2767562582",
    "https://openalex.org/W2313534146",
    "https://openalex.org/W2104120631",
    "https://openalex.org/W2336531398",
    "https://openalex.org/W3206964026",
    "https://openalex.org/W2916822684",
    "https://openalex.org/W2766386833",
    "https://openalex.org/W3011104729",
    "https://openalex.org/W4221031608",
    "https://openalex.org/W1163071855",
    "https://openalex.org/W114156697",
    "https://openalex.org/W2143959207",
    "https://openalex.org/W2911379327",
    "https://openalex.org/W4327518725",
    "https://openalex.org/W2985278156",
    "https://openalex.org/W4319773014",
    "https://openalex.org/W4385565281",
    "https://openalex.org/W4366989878",
    "https://openalex.org/W4205201623",
    "https://openalex.org/W3032230397",
    "https://openalex.org/W4323812846",
    "https://openalex.org/W1982643343",
    "https://openalex.org/W3147517805",
    "https://openalex.org/W4321847712",
    "https://openalex.org/W2944987391",
    "https://openalex.org/W4376866715",
    "https://openalex.org/W2020073413",
    "https://openalex.org/W3204788409",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W4221159132",
    "https://openalex.org/W2983962589",
    "https://openalex.org/W2098441518",
    "https://openalex.org/W1981276685",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W3201856225",
    "https://openalex.org/W2914767245",
    "https://openalex.org/W4291900964",
    "https://openalex.org/W4367360137",
    "https://openalex.org/W4296772911",
    "https://openalex.org/W3204998121",
    "https://openalex.org/W4385570209",
    "https://openalex.org/W4365511667",
    "https://openalex.org/W4322766882",
    "https://openalex.org/W4225716729",
    "https://openalex.org/W4389523832",
    "https://openalex.org/W4389520749",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4385573488",
    "https://openalex.org/W3046764764",
    "https://openalex.org/W3176353699",
    "https://openalex.org/W3048763337",
    "https://openalex.org/W6739651123",
    "https://openalex.org/W2508728158",
    "https://openalex.org/W2888010645",
    "https://openalex.org/W3101684541",
    "https://openalex.org/W3105936375",
    "https://openalex.org/W4236521339",
    "https://openalex.org/W2788897568",
    "https://openalex.org/W2964309167",
    "https://openalex.org/W4239187549",
    "https://openalex.org/W4236728252",
    "https://openalex.org/W2914475543",
    "https://openalex.org/W3005364219",
    "https://openalex.org/W2883376713",
    "https://openalex.org/W188088074",
    "https://openalex.org/W3164112679",
    "https://openalex.org/W4297103095",
    "https://openalex.org/W3028999579",
    "https://openalex.org/W3185181255",
    "https://openalex.org/W3130639100",
    "https://openalex.org/W4362575155",
    "https://openalex.org/W4360615722",
    "https://openalex.org/W3033776495",
    "https://openalex.org/W2899856450",
    "https://openalex.org/W2794297522",
    "https://openalex.org/W2963606273",
    "https://openalex.org/W3116538722",
    "https://openalex.org/W2792106437",
    "https://openalex.org/W3108615578",
    "https://openalex.org/W2904596937",
    "https://openalex.org/W2752868187",
    "https://openalex.org/W3049748707",
    "https://openalex.org/W2713640100",
    "https://openalex.org/W2908350269",
    "https://openalex.org/W3100449273",
    "https://openalex.org/W2929028679",
    "https://openalex.org/W2342299174",
    "https://openalex.org/W3011633192",
    "https://openalex.org/W2973112377",
    "https://openalex.org/W2981606406",
    "https://openalex.org/W2996141440",
    "https://openalex.org/W4385988359",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W4383551192",
    "https://openalex.org/W4292819600",
    "https://openalex.org/W3125770638",
    "https://openalex.org/W3009936362",
    "https://openalex.org/W4312204748",
    "https://openalex.org/W4304614231",
    "https://openalex.org/W4365795311",
    "https://openalex.org/W4320186815",
    "https://openalex.org/W4319779057",
    "https://openalex.org/W4362582720",
    "https://openalex.org/W3009335665",
    "https://openalex.org/W3111275476",
    "https://openalex.org/W3205211246",
    "https://openalex.org/W4308947461",
    "https://openalex.org/W3092848027",
    "https://openalex.org/W6743117384",
    "https://openalex.org/W4200531362",
    "https://openalex.org/W7053510832",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4321601639",
    "https://openalex.org/W3202285719",
    "https://openalex.org/W3176849078",
    "https://openalex.org/W4284991798",
    "https://openalex.org/W4361241770",
    "https://openalex.org/W2981863007",
    "https://openalex.org/W3017131514",
    "https://openalex.org/W3184900232",
    "https://openalex.org/W3204718649",
    "https://openalex.org/W4361204578",
    "https://openalex.org/W3170233936",
    "https://openalex.org/W2042517954",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W4301393026",
    "https://openalex.org/W3198377975",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W4385572867",
    "https://openalex.org/W4318257512",
    "https://openalex.org/W4365813047",
    "https://openalex.org/W4375949262",
    "https://openalex.org/W4392681182",
    "https://openalex.org/W4317910584",
    "https://openalex.org/W3119553947",
    "https://openalex.org/W3085789143"
  ],
  "abstract": "In the rapidly evolving landscape of education, digital technologies have repeatedly disrupted traditional pedagogical methods. This paper explores the latest of these disruptions: the potential integration of large language models (LLMs) and chatbots into graduate engineering education. We begin by tracing historical and technological disruptions to provide context and then introduce key terms such as machine learning and deep learning and the underlying mechanisms of recent advancements, namely attention/transformer models and graphics processing units. The heart of our investigation lies in the application of an LLM-based chatbot in a graduate fluid mechanics course. We developed a question bank from the course material and assessed the chatbot's ability to provide accurate, insightful responses. The results are encouraging, demonstrating not only the bot's ability to effectively answer complex questions but also the potential advantages of chatbot usage in the classroom, such as the promotion of self-paced learning, the provision of instantaneous feedback, and the reduction of instructors' workload. The study also examines the transformative effect of intelligent prompting on enhancing the chatbot's performance. Furthermore, we demonstrate how powerful plugins like Wolfram Alpha for mathematical problem-solving and code interpretation can significantly extend the chatbot's capabilities, transforming it into a comprehensive educational tool. While acknowledging the challenges and ethical implications surrounding the use of such AI models in education, we advocate for a balanced approach. The use of LLMs and chatbots in graduate education can be greatly beneficial but requires ongoing evaluation and adaptation to ensure ethical and efficient use. This paper invites further research and dialogue in this emerging field, with the goal of responsibly harnessing these technologies to advance higher education.",
  "full_text": "Mahyar Abedi, Ibrahem Alshybani, Muhammad Rubayat Bin Shahadat, Michael S. Murillo\nBeyond Traditional Teaching: The Potential of Large \nLanguage Models and Chatbots in Graduate Engineering \nEducation\nCopyright: 2023 © the Author(s). Text is available under a Creative Commons Attribution 4.0 International license. More information in our Publishing Policy.\nhttps://doi.org/10.32388/MD04B0\nSep 9, 2023\nPreprint v1\nBeyond Traditional Teaching: The Potential of Large\nLanguage Models and Chatbots in Graduate Engineering\nEducation\nMahyar Abedi1‡, Ibrahem Alshybani1‡*, Muhammad Rubayat Bin Shahadat1‡, Michael\nS. Murillo2,\n1 Department of Mechanical Engineering, Michigan State University, East Lansing,\nMichigan, USA\n2 Department of Computational Mathematics, Science and Engineering, Michigan State\nUniversity, East Lansing, Michigan, USA\n‡These authors contributed equally to this work.\n* alshyban@msu.edu\nAbstract\nIn the rapidly evolving landscape of education, digital technologies have repeatedly\ndisrupted traditional pedagogical methods. This paper explores the latest of these\ndisruptions: the potential integration of large language models (LLMs) and chatbots\ninto graduate engineering education. We begin by tracing historical and technological\ndisruptions to provide context and then introduce key terms such as machine learning\nand deep learning and the underlying mechanisms of recent advancements, namely\nattention/transformer models and graphics processing units. The heart of our\ninvestigation lies in the application of an LLM-based chatbot in a graduate fluid\nmechanics course. We developed a question bank from the course material and assessed\nthe chatbot’s ability to provide accurate, insightful responses. The results are\nencouraging, demonstrating not only the bot’s ability to effectively answer complex\nquestions but also the potential advantages of chatbot usage in the classroom, such as\nthe promotion of self-paced learning, the provision of instantaneous feedback, and the\nreduction of instructors’ workload. The study also examines the transformative effect of\nintelligent prompting on enhancing the chatbot’s performance. Furthermore, we\ndemonstrate how powerful plugins like Wolfram Alpha for mathematical problem-solving\nand code interpretation can significantly extend the chatbot’s capabilities, transforming\nit into a comprehensive educational tool. While acknowledging the challenges and\nethical implications surrounding the use of such AI models in education, we advocate\nfor a balanced approach. The use of LLMs and chatbots in graduate education can be\ngreatly beneficial but requires ongoing evaluation and adaptation to ensure ethical and\nefficient use. This paper invites further research and dialogue in this emerging field,\nwith the goal of responsibly harnessing these technologies to advance higher education.\n1 Introduction 1\nThroughout history, education has been continually shaped by technological disruptions.2\nThe advent of the printing press in the 15th century democratized access to knowledge,3\ntransforming how information was disseminated [1]. The 19th-century introduction of 4\nthe blackboard revolutionized classroom dynamics, fostering interactive learning [2]. In5\nSeptember 8, 2023 1/42\nGlossary\nartificial intelligence (AI): ability of machines to perform tasks that are\nusually associated with human intelligencemachine learning (ML): subset of\nAI that allows computers to learn from data without being explicitly programmed\ndeep learning (DL): subset ofML that uses advanced layer approach with large\nnumber of parameters\ncorpus: text used for training a language model; corpora refers to multiple texts\nnatural language processing (NLP): algorithms that give computers the abil-\nity to understand and process human language\nprompting: user input to the chatbot\ninput/output prompt (I/O): model computes a single output based\non input\nchain of thought prompt (CoT): model breaks the problem in\nsequential and interconnected thoughts to arrive at a specific output\ntree of thought prompt (ToT): model branches out the input problem\ninto several thoughts and generates multiple potential outputs\nlarge language model (LLM): integrated DL/NLP model trained on huge cor-\npora to perform complex tasks\nchatbot: application interface designed to simulate human conversation\nstochastic parrot: random process of generating text based on training from\npre-existing texts\nconversational AI: technology that enables computers to engage in natural\nand human-like conversations\nplugins: powerful software tools designed to enhance the capabilities of a chatbot\nsycophancy: tendency of chatbots for unnecessary complementing and agreeing\nwith user input\nhallucination: phenomenon where chatbots produce irrelevant, nonsensical, or\nincoherent responses\ngenerative pre-trained transformer (GPT): DL model that generates text,\nvideo, or audio\ntransformer architecture: neural network architecture that uses focus to\nbetter capture sequences like text\nthe subsequent era, we saw the impact of innovations like radio [3, 4] and calculators [5].6\nThe late 20th century marked the dawn of digital learning, with the internet enabling7\nonline resources, coding platforms, and interactive applications as integral components8\nof modern education [6]. In the current phase, computational software has further 9\nenhanced learning, enabling the exploration of complex concepts and intricate 10\nproblem-solving with ease [7–12]. Despite initial resistance, each disruption has led to11\nfundamental shifts in educational methods, highlighting the transformative potential of12\ntechnology in education. 13\nSeptember 8, 2023 2/42\nThe dawn of the 21st century marked the rise of AI as a transformative force in14\neducation. Intelligent tutoring systems have personalized learning by tailoring content15\nto individual needs [13, 14]. Automated grading has freed instructors to focus on 16\nteaching rather than administrative tasks [14]. Course management systems have 17\nenhanced the efficiency of content organization and delivery [15]. Immersive learning 18\nenvironments have been created through virtual and augmented reality, making abstract19\nconcepts tangible [16–18]. Tools for performance intervention and emotional state 20\ndetection have enabled real-time responses to learning difficulties and student 21\nengagement, fostering a more responsive educational environment [19–21]. Virtual 22\nassistants have facilitated self-directed learning, while AI-powered content creation and23\nplagiarism detection software have enriched materials and ensured integrity [22–24]. 24\nAmong the diverse AI technologies shaping education, chatbots have emerged as 25\nparticularly transformative. Evolving from simple rule-based systems, they have become26\nsophisticated conversational agents through advancements in natural language 27\nprocessing (NLP), transformer architectures, and attention mechanisms [25, 26]. This28\nremarkable transformation, fueled by high-performance computing and extensive 29\ndatasets, enabled the training of LLMs [27]. Since 2020, the role of LLMs in education30\nhas been a point of exploration and debate. Questions about their impact on learning31\nobjectives, student workload, assignments, and academic integrity have arisen, along 32\nwith considerations of how they might enhance learning experiences [28]. In this 33\ncontext, tools like Elicit, Claude, Poe, and ChatGPT have found specific roles: Elicit34\nand Claude in content optimization and personalization; Poe in fostering creativity; and35\nChatGPT, an OpenAI product, in aiding content understanding and brainstorming. 36\nThe addition of plugins and tools like Bard further extends the capabilities of these AI37\nsystems, offering instructors a tailored suite of resources for various educational needs.38\nIn this paper, we advocate for incorporating Large Language Models (LLMs) into39\ngraduate-level STEM instruction, using a fluid mechanics course as a case study. We40\nexamine the multifaceted capabilities of LLMs, including answering specialized 41\nquestions, solving equations, enabling visualization, and even interpreting PDFs. 42\nEffective prompting and third-party enhancements like the Wolfram plugin are key to43\nunlocking these capabilities. Importantly, instructors need to grasp the underlying 44\ntechnology behind LLMs, especially when interfacing with chatbots, to mitigate 45\npotential drawbacks such as inaccuracies and nonsensical outputs. Beyond the 46\ntechnological considerations, we explore the ethical dimensions of deploying LLMs, 47\nemphasizing equity, transparency, and data privacy. The integration of LLMs offers a48\ntransformative approach to STEM education, addressing its challenges while 49\nmaximizing its educational promise. 50\n2 The Building Blocks of Educational Chatbots: An51\nIntroduction to Large Language Models 52\nAs we shift our focus from the overarching benefits of LLMs to their technical intricacies,53\nit becomes imperative for instructors to understand what makes these models tick. This54\nis crucial not just for academic curiosity but for practical classroom application. In 55\nsection 3, we will go a step further by examining how LLMs become the beating heart56\nof chatbots, revolutionizing the educational space in diverse and innovative ways. 57\nLLMs, at their core, are an extension of Natural Language Processing (NLP) 58\ntechnologies. These models are trained on vast datasets and have the capability to 59\nperform a wide range of tasks, from summarizing articles to conversing in 60\nreal-time [29–32]. In educational settings, understanding LLMs is becoming increasingly61\nSeptember 8, 2023 3/42\nessential. They form the technological backbone of various educational chatbots and 62\nvirtual assistants that instructors will likely encounter, both today and in the near 63\nfuture [33, 34]. 64\nBefore we delve into practical applications, it is worth exploring the evolutionary65\njourney of LLMs. These models have transitioned from basic statistical language 66\nprocessors to intricate systems leveraging neural networks and pre-training 67\ntechniques [29, 35–43]. This development has expanded the toolkit that instructors can68\ntap into, enriching the classroom experience. 69\nHowever, LLMs are not just limited to powering chatbots. They can be aligned with70\nethical considerations and fine-tuned to offer targeted feedback and improved learning71\noutcomes [44–48]. To further illuminate the distinctions between LLMs and chatbots,72\nFigure 1 offers a comparative visual overview. 73\nFig 1. LLM Training and Applications: LLMs are trained on a corpus (large volume of\ntext data) using NLP combined with ML methods. The LLMs can be used for a variety\nof tasks (shown on the right side) or developed into a type of chatbot that can answer\nquestions, carry on a conversation or operate plugins.\nWhen considering the advancement of LLMs, two key innovations emerge: 74\nLLM Architecture: The advent of transformer architecture [49] has revolutionized75\nthe field by introducing attention mechanisms. These mechanisms enable LLMs to 76\ngrasp the context within sentences or even across paragraphs, improving their utility in77\ntasks like translation, summarization, and question-answering [50–52]. 78\nComputational Power: The efficacy of LLMs is closely tied to computational 79\nresources. The usage of advanced GPUs and TPUs has made it possible to train models80\nwith more parameters, enabling a level of performance that was previously 81\nunattainable [53–57]. 82\nAs we wrap up our discussion on the innovations driving the efficacy of LLMs, it is83\ncrucial to recognize that these advancements in architecture or computational power are84\ntightly coupled with the complexities of training these models. For instructors aiming to85\nimplement or understand LLMs in educational settings, grasping the underlying 86\ntraining procedures becomes pivotal. 87\nSeptember 8, 2023 4/42\n2.1 State-of-the-Art Large Language Model Training 88\nAs we move deeper into the intricacies of LLM training, we begin with the foundational89\naspect: data preparation. Instructors keen on harnessing the power of LLMs should 90\nnote that the efficacy of these models starts with clean data. Preprocessing tasks like91\ntext sanitization and removing irrelevant symbols are critical first steps to ensure the92\nquality of training. Once the data is prepared, the next pivotal step involves 93\nestablishing the architecture—most often, the transformer architecture, as seen in 94\nmodels like GPT. Initial values for weights and biases are set during this phase, laying95\nthe groundwork for the model to develop a comprehensive understanding of language.96\nAt this juncture, it is crucial to understand that the training of LLMs is not a 97\none-time process but occurs in distinct stages, pretraining and fine-tuning. The 98\npretraining stage is a broad learning phase that employs a self-supervised approach, 99\nwhere the model absorbs the intricacies of language from vast volumes of unlabeled100\ndata. This is akin to a student engaging in broad academic study before specializing.101\nAs the model transitions into the fine-tuning stage, it is as if the student moves into102\nspecialized coursework: the model learns from smaller, task-specific labeled 103\ndatasets [58–60]. This specialization allows the model to apply its generalized 104\nknowledge to perform specific tasks, enhancing its utility in educational settings [30].105\n2.2 Challenges and Caveats of Large Language Model 106\nIntegration for Education 107\nAs LLMs increasingly find applications in higher education, it is crucial for instructors108\nand students to comprehend their inner workings, ethical implications, alignment with109\nhuman values, and the importance of model training and dataset quality [61–63]. While 110\nchatbots offer various benefits, they also introduce challenges such as hallucination, 111\nprivacy, and overreliance. 112\nHallucination: Researchers have sometimes observed that LLMs provide incorrect113\nor misleading information [64, 65]. Although the text produced by LLMs might exhibit114\ngrammatical accuracy and logical structure, it can sometimes suffer from semantic 115\ninaccuracy, misdirection, conflicts, or misalignment with the given context or 116\nestablished facts. Researchers and developers can tackle this challenge by furnishing 117\nmodels with superior-quality data or incorporating human feedback. 118\nOutdated knowledge: LLMs might experience difficulty in resolving problems 119\nthat demand the latest information. However, researchers are actively working on 120\nstrategies to ensure that these models are consistently supplied with the latest insights,121\npotentially mitigating this concern [66, 67]. 122\nHarmful content: LLMs possess the capability to produce content that could be123\nharmful, potentially amplifying societal problems and nurturing hostility [68, 69]. 124\nDeliberate examination of initial GPT-4 iterations unveiled this risk, prompting model125\nrejections as a measure to alleviate potential harm. The released version of GPT-4 126\ndemonstrates significant improvements in reducing harmful content generation. 127\nPrivacy: LLMs are trained on diverse datasets, have the capacity to synthesize 128\ninformation, and can potentially discern individuals while paired with external data [70].129\nActions such as expunging personal information from datasets and employing 130\nautomated assessments are put into effect to mitigate risks to privacy. Subsequent 131\nimprovements are directed at curbing privacy hazards by concentrating on information132\nprovided by users [71, 72]. 133\nOverreliance: A growing concern with increasing model capability can lead to 134\nSeptember 8, 2023 5/42\nunnoticed errors, inadequate oversight, and potential skill loss [73]. Mitigation strategies135\ninclude providing comprehensive documentation, refining the model’s refusal behavior,136\nand encouraging critical evaluation of model outputs. However, challenges persist, such137\nas the model’s tendency to hedge responses, which may inadvertently foster overreliance,138\nand users potentially becoming less attentive to refusal cues over time. 139\nUnderstanding how to manage these challenges often involves a deep dive into the140\nmodel’s inner mechanisms, including its stochastic behavior. One way to gain more141\ncontrol over model outputs and mitigate some of these challenges is through a concept142\nknown as temperature scaling. 143\n2.3 The Stochastic Nature of LLMs: The Concept of 144\nTemperature 145\nControlling LLM responses is a fundamental concern for instructors aiming to maximize146\nthe utility of these models in academic settings. Temperature scaling provides a nuanced147\napproach to balancing the model’s certainty and creativity, helping to address some of148\nthe aforementioned challenges, such as generating hallucinated or overly rigid content.149\nTemperature scaling assumes a pivotal methodological role in governing distribution150\nsmoothness, carrying significant implications for augmenting the performance of 151\nintricate models involved in NLP tasks [74]. By employing lower temperature 152\nparameters, the models demonstrate heightened certainty and consistency, attributes 153\ncrucial for precision-demanding tasks. Nonetheless, this can result in outputs perceived154\nas excessively rigid or repetitive [75]. 155\nIn contrast, applying higher temperature parameters infuses the models with an 156\nelement of stochasticity, fostering a more diverse and creative output and facilitating the157\nexploration of unconventional solutions and novel ideas. On the other hand, excessively158\nhigh temperatures may result in incoherent responses unrelated to the original query.159\nThe methods of implementing temperature scaling are multifaceted, encompassing 160\nconstant temperature applications [76, 77], dynamic adjustments over training 161\niterations [78], or variations based on the specific word position within a sentence [74].162\nThe practical significance of temperature scaling in LLMs is particularly salient 163\nwhen these models are adapted into real-world applications such as automated chat164\nsystems or chatbots. By calibrating the temperature, instructors can tailor the chatbot165\nresponses to be either more precise or more creative, depending on the educational 166\ncontext. With this foundational understanding of LLMs and their stochastic behavior,167\nwe are better equipped to explore their most interactive form: chatbots. 168\n3 Chatbots: Interfacing with Humans 169\nBuilding on the foundations of Large Language Models (LLMs), chatbots have rapidly170\nbecome a pivotal component of human-computer interaction [79,80]. Their unique blend171\nof algorithmic complexity and linguistic proficiency enables real-time dialogue with 172\nusers, adding a layer of interactivity that holds significant implications for higher 173\neducation. These advanced capabilities are the culmination of decades of research and174\ninnovation in Artificial Intelligence and computational linguistics. This section will 175\nexplore the historical roots of chatbots, delve into their evolution over the years, 176\nexamine their applications in academia, and discuss the tools and methodologies that177\nfacilitate their effective integration into educational settings. 178\nSeptember 8, 2023 6/42\n3.1 History and Evolution of Chatbots and Conversational AIs179\nFor instructors interested in understanding the roots of chatbots, the story starts with180\nthe Turing Test, introduced in 1950 by Alan Turing [81–83] (as shown by the blue node181\nin Figure 2). The Turing Test aimed to determine if a machine could exhibit behavior182\nindistinguishable from human intelligence. This intellectual query led to the creation of183\nELIZA in the 1960s by Joseph Weizenbaum [84–86] (the first purple node on the upper184\nlayer in Figure 2). Serving as a rudimentary psychotherapist, ELIZA used 185\npattern-matching techniques to simulate conversation. 186\nFig 2. Choronological Development, Evolution, and Progression of LLMs and\nChatbots: Advanced language models, capable of processing vast amounts of data,\nchatbots, and conversational AI agents have evolved and interacted with each other,\nleading to advancements in natural language understanding, human-computer\ninteractions, and AI-driven products. In the Figure, the orange objects refer to LLMs,\npurple objects refer to conversational AI or chatbots, green objects refer to AI-based\nvirtual assistants and pink objects refer to AI-driven objects.\nIn the 1970s, rule-based chatbot systems became prevalent, where predefined rules187\ndetermined the responses to user inputs. Richard Wallace’s A.L.I.C.E. (Artificial 188\nLinguistic Internet Computer Entity) was a notable example that engaged users in 189\nopen-ended conversations using an extensive set of predefined rules [87, 88]. A.L.I.C.E.190\nincorporated context awareness through short-term memory and refined its responses by191\nstoring previous inputs and corresponding responses [89, 90], which led to the 192\ndevelopment of other chatbot systems like MegaHAL [91, 92] and Jabberwacky [93–95].193\nThe twenty-first century has witnessed remarkable advancements in AI and NLP194\ntechniques, leading to the development of sophisticated and innovative chatbots [96–98]. 195\nThese chatbots can understand user queries and provide meaningful responses, making196\nthem invaluable for various applications such as customer service, personalized support,197\nand product recommendations [99, 100]. Additionally, they excel at automating 198\nmundane tasks and extracting valuable insights from vast datasets [101, 102]. For 199\ninstance, SmarterChild, an instant messaging chatbot initially developed by 200\nActiveBuddy and later acquired by Microsoft, delivers various services ranging from 201\nweather reports to general information [103] (the purple node on the right side of the202\nupper layer in Figure 2). One pivotal milestone in the chatbot landscape was the 203\nSeptember 8, 2023 7/42\nintroduction of Siri (Speech Interpretation and Recognition Interface) by 204\nApple [104, 105] (the green node at the beginning of the middle layer in Figure 2 as the205\nfirst intelligent virtual assistant). Siri, an intelligent virtual assistant, revolutionized 206\nhow humans interact with technology and chatbots [106]. Its success has not only 207\ntransformed user expectations but also paved the way for the development of other208\nnotable virtual assistants such as Alexa by Amazon [107–109], Cortana by 209\nMicrosoft [110–113], and Google Assistant by Google [114–117]. 210\nRecent years have witnessed the emergence of conversational AI, driven by advances211\nin ML, DL, and NLP. Platforms such as IBM Watson [118–120] and Google 212\nDialogflow [121–124] have been instrumental in the development of conversational AI213\nand the enhancement of the understanding and implementation of NLP techniques. One214\nof the most notable achievements in the field of conversational AI is the development of215\npowerful language models such as GPT (the orange node near the end of the middle216\nlayer in Figure 2 represents the onset of chatbots and artificial intelligence), which have217\nsignificantly improved the understanding and generation capabilities of 218\nchatbots [125–128]. Developed by OpenAI, these models are trained on vast amounts of219\ntext data using advanced DL architectures to generate coherent and contextual 220\nhuman-like responses [129]. With each iteration, these models become more complex,221\nintroducing new functionalities to the corresponding chatbot, including conditional text222\ngeneration (GPT 2); translation and summarization (GPT 3); faster outputs and text223\ncompletion (GPT 3.5); multilanguage functions, logical reasoning, and robust API 224\nplugins (such as Wolfram Alpha and ScholarAI) (GPT 4) [125, 127, 130]. Figure 3 225\nillustrates the performance enhancement and additional functionalities in different 226\nversions of GPT models as the number of input parameters in the DL model increases.227\nFig 3. The Highlighted Road Map of GPT Evolution: From the early inception of GPT\nto its progressive iterations, this roadmap showcases the rapid development of powerful\nlanguage generation models based on transformer architecture. It also depicts the major\nbreakthroughs and refinements leading to more sophisticated and capable GPT variants\nthat have significantly impacted various NLP tasks.\nThe release of ChatGPT as a chatbot based on GPT models by OpenAI marks a228\npivotal milestone in the development of chatbots and conversational AIs. After that,229\nInflection released the Pi chatbot [131], designed to be a kind and supportive 230\nSeptember 8, 2023 8/42\ncompanion offering conversations, friendly advice, and concise information in a 231\nhuman-like and coherent style. Replika is another companion chatbot programmed to232\nlearn and mimic people’s writing style, offering an unprecedented sense of comfort and233\nwell-being [132–135]. Similar to other technological giants, Google has also contributed234\nto fields of LLMs through the development of several models, including 235\nLaMDA [136–138] and PaLM [139–141]. Despite many obstacles in the development236\nand implementation procedure, such as sentinent behavior, LaMDA, and PaLM are 237\nutilized to develop Bard chatbot [142, 143]. Bard is an AI-powered chatbot designed to238\nbe more conversational and generate more diverse and prolonged responses than GPT239\nmodels [144, 145]. Claude and Claude 2.0 are two of the other powerful chatbots 240\nreleased recently, with superior performance to generate longer responses and nuanced241\nreasoning [146, 147]. Claude 2.0 has made significant strides in multiple fields, including242\nlaw and mathematics. It scored 76.5% in the Bar exam’s multiple-choice section and243\nachieved a score higher than 90% of graduate school applicants in GRE reading and244\nwriting exams [148]. Figure 2 provides a comprehensive overview of the evolution 245\ntimeline of chatbots, LLMs, conversational AIs, and AI-based products. 246\n3.2 Higher-Education Implication of Chatbots 247\nChatbots, powered by advancements in conversational AI and sophisticated language248\nmodels like GPT, PaLM, and LaMDA have revolutionized various domains, including249\neducation. These models have significantly enhanced the natural language 250\nunderstanding and generation capabilities of chatbots, allowing them to generate 251\ncoherent and contextually appropriate responses [96, 129, 149, 150]. In education, these252\nadvancements offer numerous advantages to researchers [151], students [152], and 253\ninstructors [153]. Chatbots can provide personalized and adaptive learning experiences254\nby tailoring content and resources to individual student needs and learning styles, 255\nleading to improved engagement and knowledge retention [154, 155]. They can offer256\nimmediate and accurate responses to student inquiries, providing timely support and257\nguidance that enhances the learning process [156–158]. Additionally, chatbots facilitate 258\ncontinuous assessment and feedback, allowing students to receive prompt evaluations259\nand insights into their progress, enabling them to identify areas for 260\nimprovement [159, 160]. They can also assist in delivering educational materials and261\nresources, offering on-demand access to information, and promoting self-directed 262\nlearning [161]. Moreover, chatbots foster collaborative learning experiences by 263\nfacilitating group discussions and providing opportunities for peer interaction [162]. By264\nautomating administrative tasks, such as grading and scheduling, chatbots support 265\ninstructors by freeing up their time to focus on instructional activities [159, 163]. These266\nadvantages of chatbots in education encompass personalized learning, timely support,267\ncontinuous assessment, resource delivery, collaboration, and administrative 268\nassistance [164–166]. Figure 4 illustrates some of the merits of chatbot implementation269\nfor student and education purposes. 270\nIn addition to educational benefits, researchers could also benefit from utilizing 271\nchatbots. Chatbots have substantially enhanced the present state of information 272\nretrieval, providing a notable improvement in the accessibility of information compared273\nto basic Google searches. Furthermore, these chatbots, augmented with powerful 274\nplugins, open up new gateways to access the internet’s vast repository of knowledge,275\ne.g., OpenAI has introduced plugins as an added feature in its latest versions of 276\nChatGPT, where users can select and utilize up to three plugins at a time for their277\nspecific tasks, with the option to change their selection as needed, providing valuable278\nassistance to both students and researchers in higher education, enabling them to 279\nstreamline their tasks and achieve their objectives with reduced effort. Table 1 outlines280\nSeptember 8, 2023 9/42\nFig 4. Chatbots in Education: A transformative tool offering students instant access,\ntailored learning experiences through topical threads, rapid responses, and unparalleled\npersonalization for an optimized learning journey.\nseveral plugins integrated into ChatGPT, offering higher education and research 281\napplications. Apart from plugins, chatbots have also tapped into specialized AIs that282\nfocus on discovering academic papers, exemplified by Elicit, Semantic Scholar, and 283\nScholarAI. These advancements encompass the critical stages of research, ranging from284\nwriting and editing to a meticulous review of papers. Additionally, chatbots have 285\nevolved to excel at summarizing complex research papers, rendering them invaluable286\naids for researchers and learners seeking to distill intricate knowledge efficiently. 287\nWhile chatbots bring numerous benefits to education and research, they also face288\ndrawbacks and limitations. One limitation is their inability to fully replace the human289\nelement of interaction and personalized instruction [26]. Despite being able to provide290\nimmediate responses and support, chatbots lack the empathy and nuanced 291\nunderstanding that human instructors possess, which can be particularly challenging for292\nstudents requiring individualized attention or those with complex learning needs. 293\nAdditionally, chatbots may need help to accurately assess subjective assignments or 294\nprovide in-depth feedback beyond essential evaluation criteria [167]. Technological 295\nbarriers and disparities pose another limitation due to students’ unequal access to the296\nnecessary devices, stable internet connections, or technological literacy, hindering their297\nengagement with chatbot-driven educational experiences. Moreover, there is a risk of298\nchatbots inadvertently reinforcing a transactional approach to learning, prioritizing 299\ncorrect answers over critical thinking, creativity, and problem-solving skills [168], 300\nlimiting opportunities for comprehensive learning experiences, exploration, and 301\nintellectual growth. Furthermore, one concern regarding chatbots is their potential to302\nperpetuate biases and reinforce stereotypes in their training data [162, 169]. If the 303\ntraining data are biased or lack diversity, the chatbot’s responses may unintentionally304\nexhibit biases or engage in discriminatory behavior. Privacy and data security concerns305\nalso arise when utilizing chatbots, requiring careful data handling to comply with 306\nprivacy regulations and safeguard sensitive information [170, 171]. Additionally, 307\ntechnical glitches, system failures, or programming errors can disrupt the learning 308\nprocess and lead to frustration among researchers, students, and instructors [172]. It is309\nessential to address these limitations thoughtfully and consider chatbots as 310\ncomplementary tools that work alongside human instructors to create a comprehensive311\nSeptember 8, 2023 10/42\nPlugins/Features Description\nBrowsing Browsing Alpha integrates the Bing search API, enabling ChatGPT to\nbrowse and retrieve web content directly from the internet.\nRetrieval\nThe Retrieval feature grants ChatGPT the ability to access authorized\npersonal or organizational information sources. By leveraging natural\nlanguage queries, users can retrieve pertinent document snippets from\nvarious data sources, including files, emails, notes, and public documents.\nCode\nEnhances the capabilities of ChatGPT by enabling it to perform a variety\nInterpreter\nof tasks. These tasks include numerically solving mathematical problems\nconducting data analysis and visualization on your dataset file, and\nconverting file formats using Python.\nWolfram\nEmpowers ChatGPT users with advanced computational capabilities,\nenabling them to solve various types of queries, including mathematical\nproblems and computations.\nAskYourPDF Generate summaries of file content in response to user inquiries.\nScholarAI It searches millions of peer-reviewed articles based on the user prompt. It\nalso obtains the DOI and provides a short summary of the article.\nCustom Allows the users to specify or customize their preferences or requirements\nInstructions about the responses way they want to receive from the chatbot.\nTable 1. Shows the description of some available plugins and features that can be used\nin higher education.\nand effective educational environment. 312\nAs we have explored the diverse merits and potential pitfalls of chatbot 313\nimplementation in educational settings, an important conclusion emerges: successful 314\nadoption is not a plug-and-play endeavor. Instead, it necessitates systematic adaptations315\nin curriculum design, instructional techniques, and communication protocols [152]. 316\nInstructors, therefore, should not just be passive consumers of this technology; they 317\nshould actively engage in restructuring course objectives, designing chatbot-centric 318\nassignments, and establishing guidelines for effective chatbot utilization. Instructor 319\ntraining programs, too, must evolve, equipping instructors with the skills to weave 320\nchatbots seamlessly into their pedagogical toolkit [163]. By proactively embracing these321\nadjustments, we pave the way for a more dynamic and enriched educational experience.322\n4 Chatbots: Strategies and Tools 323\nBuilding upon the discussed chronological evolution and real-world implications of 324\nchatbots, we will examine the key methods and tools used in chatbots, highlighting325\nfrom prompt techniques to customizing interactions and providing an in-depth review326\nuseful for graduate students and instructors. 327\n4.1 Basic Prompting 328\nPrompting serves as the bedrock for enhancing the utility of chatbots, particularly those329\nemploying advanced language models like ChatGPT. In essence, a prompt is a set of330\nSeptember 8, 2023 11/42\ninstructions that directs the chatbot toward generating a specific kind of 331\nresponse [173–175]. It acts as the steering wheel for the chatbot, guiding it to produce332\noutcomes that align with the desired objectives [176–178]. Therefore, crafting clear and 333\nstructured prompts becomes indispensable for optimizing the accuracy and relevance of334\nthe chatbot’s generated responses [176]. 335\nFor instance, while searching for the momentum equation for a steady, inviscid, and336\nincompressible flow, an improper prompt like ‘provide the momentum equation’ may337\nproduce a more generalized answer. However, a more specific prompt like ‘provide the338\nmomentum equation for a steady, inviscid, and incompressible flow’ ensures an accurate339\nresponse. 340\nUnderstanding the intricacies of prompt engineering is not merely a technical 341\nendeavor but a practical one for instructors. This understanding allows instructors to342\nleverage tools like ChatGPT in versatile ways, from crafting dynamic quizzes to 343\ndesigning comprehensive course plans. Thanks to the adaptability of prompt 344\nconfigurations, ChatGPT can be fine-tuned to offer a multitude of prompt suggestions,345\ngathering diverse and relevant educational data [176, 179]. 346\n4.2 Prompt Strategies 347\nBefore diving into the advanced prompting methods, it is essential to understand the348\nfoundational principles that govern effective prompting. These can be broadly 349\ncategorized into specific words, context provision, and mechanisms for eliciting more350\ndetailed information [180]. ChatGPT utilizes various advanced prompting strategies to351\nsolve distinct challenges, yielding the desired outputs. Specifically, three principal 352\nmethods stand out: the Input-Output (I/O) method, the Chain of Thought (CoT), and353\nthe Tree of Thoughts (ToT) prompts [181]. 354\nIn I/O prompting, the model is provided with various input samples alongside their355\nrespective outputs which guides the model in producing the desired output for a given356\ninput [181]. Figure 5 shows an example of I/O prompting using ChatGPT 4.0. In this357\nscenario, we posed a query ‘What is the continuum hypothesis in fluid mechanics’ to358\nChatGPT 4.0., which in turn resulted in the corresponding response. 359\nFig 5. I/O Prompting Mechanism: Inputs are fed into the system, and based on\ninternal processing, corresponding outputs are generated, showcasing the dynamic\ninteraction and response mechanism\nCoT breaks the input problem into a series of logical thoughts and reaches the final360\nSeptember 8, 2023 12/42\ndesired output based on previous thoughts. This approach is useful for intricate 361\nmathematical or reasoning tasks that require step-by-step breakdowns. It clarifies the362\nmodel’s actions and its reasoning, making error detection more 363\nstraightforward. [181–184]. 364\nFig 6. CoT Prompting Mechanism: CoT breaks the problem into multiple sequential\nand interconnected steps, and each step gives a clear idea of how the model reaches the\nfinal output.\nFigure 6 shows the example of CoT prompting using ChatGPT 4.0. We used the365\nCoT prompting technique in this scenario to pose the same question. ChatGPT 366\ndeconstructed the query into several thoughts, each directing the model toward the final367\nanswer. 368\nToT is a strategy for structuring the model’s output to branch out into different369\nrelated thoughts. This approach can be beneficial for complicated questions that involve370\nmultiple related ideas. By structuring the response as a tree of thoughts, the model can371\ncover a wide range of related ideas in a structured and organized manner. ToT solves a372\nproblem by searching over a tree where each node represents a partial solution based on373\ninput and previous thought sequences [181]. Figure 7 shows the example of ToT 374\nprompting. We attempted to utilize ToT in a more straightforward manner without any375\ncoding. Yet, the prompt illustrated in Figure 7 may not genuinely respond to queries376\nusing the tree of thoughts. Hence, we believe there’s a pressing need for an improved377\nmethodology to draft prompts for ToT. 378\nWithin the rest of this study, to instruct ChatGPT to induce the ToT prompt, we379\nhave utilized the following command provided by Dave Hulbert [185]. This prompt 380\ninitiates a discussion that investigates several logical paths, possibly leading to the 381\ndesired outcome of the question. From a discussion standpoint, this prompt may 382\neffectively provide distinct paths to answer conceptual questions, but it might be less383\nefficient in addressing analytical or mathematical problems, as discussed in section 5.2.384\nSeptember 8, 2023 13/42\nFig 7. ToT Prompting Mechanism: ToT branches out the input into different related\nthoughts, which help the model reach the final outputs.\nImagine three different experts are answering this question.\nAll experts will write down 1 step of their thinking, then\nshare it with the group. Then, all experts will go on to the\nnext step. If any expert realizes they’re wrong at any point,\nthen they leave.[The question is ...]\n4.3 How to use a prompt properly? 385\nChatGPT is a valuable resource for both students and instructors at graduate, 386\nundergraduate, and professional levels. It can craft course syllabi, design projects, 387\nsupply fundamental formulas, offer research articles, and even design and assess student388\nquizzes. The best possible results can be achieved by supplying context and employing389\nplugins. Below are some illustrations showcasing the advantages of using ChatGPT in a390\ngraduate fluid mechanics course. 391\nExample provided by the instructor:We are learning the fundamentals of 392\nturbulence for a graduate-level fluid mechanics class. Today we are focused on the 393\nNavier-Stokes equation and its application. Please generate a summary of this topic 394\nfollowed by a quiz with five multiple-choice questions. We will attempt to answer the395\nquestions next, and then we will ask you to check our results and provide reasons for the396\ncorrect answers. 397\nChatGPT 4.0 provided a concise overview of the Navier-Stokes equation and its 398\npractical uses in the given scenario, accompanied by a quiz of 5 multiple-choice 399\nquestions. When prompted on the preferred answer format for students, ChatGPT 400\nemphasized clarity, suggesting any method that distinctly matches answers to their 401\ncorresponding questions. Using a streamlined format—listing answers like 1A, 2B, 3C,402\n4D, and 5B, it assessed the responses, highlighted correct and incorrect answers, and403\nelucidated the reasoning behind each question. 404\nExample provided by the instructor:We are learning about the fundamentals 405\nof turbulence in today’s class. Using ScholarAI, find the most recently published papers406\nSeptember 8, 2023 14/42\non direct numerical simulation (DNS) focusing on the flow over an airfoil. Based on407\nwhat you find, provide three short-answer questions I can try to answer, and you can408\ncheck. 409\nIn response to this example, ChatGPT 4.0 presented us with some of the latest 410\npapers via the ScholarAI plugin and posed three brief questions based on the content of411\nthose papers. After submitting our responses, it assessed and provided explanations for412\neach question. 413\nExample provided by the instructor:We are learning about the fundamentals 414\nof shock waves in today’s class. Our learning goal is to understand shock waves’ 415\nformation, propagation, and impact. Please provide five real-life examples of shock 416\nwaves. Based on the examples, provide five short-answer questions I can try to answer,417\nand you can check. 418\nChatGPT 4.0 presented five practical instances of shock waves based on the given419\nscenario. Following that, it posed five questions based on these examples. After we 420\nsubmitted our responses, it analyzed them and offered detailed explanations for each421\nquestion. 422\nExample provided by the instructor:We are learning about the fundamentals 423\nof shock waves in today’s class. Our goal is to learn about shock tubes. Please give me a424\ndetailed theory of shock tubes with the necessary equations and design a project for me425\nwith proper initial conditions so that I can analytically calculate the change of pressure,426\nvelocity, temperature, and density across the shock wave in the tube and you can check427\nthe final answers. 428\nIn response to the above example, ChatGPT 4.0 provided details about the shock429\ntubes, including the equations representing how various properties alter across the shock430\nwave. Subsequently, it outlined a project with the necessary initial conditions. We 431\nanalytically calculated the change of different properties like pressure, velocity, 432\ntemperature, and density across the shock wave. After sharing our results with 433\nChatGPT, it evaluated our responses. 434\nExample provided by the instructor:We are learning about vortex generation 435\nand shedding fundamentals. Please give me a detailed theory on these topics with the436\nnecessary mathematical formulations. Give me a few real-life examples of vortex 437\nshedding, followed by a quiz with three short answer questions based on applications of438\nvortex shedding in Engineering. We will attempt to answer the questions, and you will439\nevaluate our responses. 440\nIn response to the above example, ChatGPT 4.0 provided details about the vortex441\ngeneration and shedding with necessary equations, followed by a few real-life examples.442\nIt then posed three questions concerning the application of vortex shedding in 443\nengineering. After we submitted our responses, it evaluated them and explained each444\nquestion. 445\nExample provided by the instructor:In today’s class, we are learning about the446\nflow around a circular cylinder. We are particularly interested in the pressure 447\ndistribution around the cylinder. I have sent you all a paper. Now using Ask Your PDF,448\ntell ChatGPT to summarize this paper and find out the most important points. Also, ask449\nany question to GPT if you need help understanding anything from the pdf. 450\nIn the provided scenario, theAsk Your PDFtool prompted us with a link to upload451\nour document. Once the paper was uploaded and its URL was shared with ChatGPT,452\nthe system could provide summaries and address queries originating from the content of453\nthe PDF. 454\nSeptember 8, 2023 15/42\nThe conversational learning feature of ChatGPT allows students to learn through455\ndialogue and interactions [180, 186]. Rather than traditional Google searches, students456\ncan directly ask GPT for recent papers or specific answers. Integrations with plugins457\nlike Wolfram, ScholarAI, code interpreter, and custom instructions enhance the learning458\nexperience. Furthermore, ChatGPT can recall previous conversations until a new chat459\nbegins. Students and instructors can engage in back-and-forth discussions, seek more460\nprofound understanding, and verify any information. Due to its training on diverse 461\ntopics, ChatGPT can identify interdisciplinary connections. With the help of code 462\ninterpreter and custom instructions, many previously impossible tasks have become 463\nstraightforward. Thus, we will delve deeper into these tools to demonstrate their 464\napplication in graduate-level fluid mechanics courses. 465\n4.4 Code Interpreter 466\nThe code interpreter, an experimental ChatGPT model, is designed to execute Python467\ncode, manage file uploads, and facilitate downloads within a well-structured 468\nenvironment. This innovative feature operates with persistence and security, 469\nmaintaining a session that remains active throughout a chat conversation, albeit with470\nan upper-bound timeout. This continuity enables subsequent code executions to build471\nupon each other, fostering a dynamic and interactive experience. Additionally, the 472\nenvironment is equipped with ephemeral disk space and supports an array of 473\nwidely-used Python packages. The system allows for the uploading of files to the 474\ncurrent conversation workspace and the downloading of the results, thereby 475\nsubstantially enhancing the functionalities of ChatGPT. This advancement represents a476\nsignificant leap in capabilities, allowing for many sophisticated tasks and applications to477\nbe adeptly performed within the confines of the conversation. 478\n• The code interpreter can process data from user-uploaded files. It can detail the479\ndataset, execute statistical evaluations, craft visual representations like graphs, 480\nidentify data trends, and forecast outcomes. 481\n• It can execute image processing tasks, alter the image’s color scheme, and modify482\nits form while preserving the original aspect ratio. 483\n• Another excellent feature of the code interpreter is its file conversion function. It484\ncan convert one format of the file to another format based on the user’s preference.485\n• The code interpreter can create, analyze, and optimize codes. Additionally, it can486\nidentify coding errors and offer corrective suggestions. 487\n• In addition to powerful Python visualization libraries, code interpreter allows 488\nusers to develop interactive visualizations and interfaces through Streamlit. 489\nStreamlit helps users quickly and easily build data-driven apps, dashboards, and490\nreports with minimal code. It also allows developers to create complex 491\nvisualizations and interfaces. Additionally, Streamlit offers a wide range of 492\nfeatures to make it easier for developers to build high-quality applications. 493\nThe course instructors and students can gain significant advantages from code 494\ninterpreters. Below, some instances are highlighted demonstrating the effective 495\nutilization of a code interpreter. 496\nExample 1: We are learning the fundamentals of streamlines, stream functions, 497\nand vortex shedding for a graduate-level fluid mechanics class. Today we are particularly498\ninterested in how streamlines behave when there is a flow passing over a spherical body.499\nWrite a Python code that will generate multiple streamlines over a circular body. Do not500\nSeptember 8, 2023 16/42\nshow any streamlines inside the circular body. Save the visualization in a high-resolution501\nimage. 502\nChatGPT executed the Python code in response to this example and generated the503\nfollowing high-quality image (Figure 8). However, it included a caveat, noting that the504\nplot is rudimentary. For a more precise visualization, more robust computational 505\nmethods such as DNS (Direct Numerical Simulation) or LES (Large Eddy Simulation)506\nare recommended. 507\nFig 8. Flow Over a Circular Body Generated by Code Interpreter: Code interpreter\ngenerated multiple streamlines, showing the flow direction from left to right, around the\ncircular body.\nExample 2: Today, we are particularly interested in the drag force and drag 508\ncoefficient measurement. We have experimental data for measuring the drag force over a509\nstreamlined hemisphere. The drag force was measured by a force transducer, and the510\ndrag coefficient was measured by the empirical equation. Now, read the experimental511\ndata file. Consider the 1st row and 1st column as the headers. Show the correlation 512\nmatrix in a heat map. Now save the visualization in high-resolution images. 513\nThe ChatGPT read and described the data file in response to this example. 514\nSubsequently, a correlation matrix was presented in Figure 9, depicting the 515\ninterrelationships between each variable. The correlation values span from -1 to 1, 516\nwhere 1 signifies a perfectly positive correlation, -1 denotes a perfectly negative 517\ncorrelation, and 0 suggests no correlation. 518\nExample 3: We are learning the fundamentals of streamlines, stream functions, 519\nand vortex shedding for a graduate-level fluid mechanics class. I have uploaded an image520\nthat is from a very classic fluid mechanics problem. The image is in greyscale but we521\nneed a colored version of it. Make it a colored image. Put greyscaled and colored image522\nside by side and generate very high-resolution images which I can use in a report. 523\nIn response to this example, ChatGPT transformed a grayscale image into a 524\ncolorized version, adeptly preserving the intensity levels, as displayed in Figure 10. 525\nExample 4: We are learning the fundamentals of shock waves and are particularly526\nSeptember 8, 2023 17/42\nFig 9. Correlation Heatmap: The correlation matrix shows the correlation between\nevery pair of variables. The values range from -1 to 1, where 1 indicates a perfect\npositive correlation, -1 indicates a perfect negative correlation, and 0 indicates no\ncorrelation.\nFig 10. Transformed Colored Image: The code interpreter converted the grayscale\nimage into a colored image keeping the intensity level the same.\ninterested in oblique shock waves. I have uploaded a data file which is basically an 527\noblique shock table [187]. Consider the first row as a header. Now, describe the data file528\nin brief and create a few important plots. Also, tell me what should be the value of\u0000 at 529\n✓=5 and M1=1 and 1.5. 530\nIn response to this example, ChatGPT described the data file nicely in short and531\ngenerated Figure 11. Within the dataset, certain conditions exhibited detached shock532\nwaves, which were adeptly represented in the visualizations by the code interpreter.533\nSeptember 8, 2023 18/42\nFig 11. Generated Visualizations from Uploaded Datafile: The code interpreter\ngenerated the line plots from the uploaded shock table. The discontinuity in the lines\nindicates the detached shock conditions.\nAdditionally, ChatGPT provided precise values for\u0000 at ✓=5 andM1=1 and 1.5, 534\nindicating its capability to interact with specific rows and columns effectively. 535\n4.5 Custom Instructions 536\nIn a recent development, OpenAI unveiled an innovative feature for its advanced 537\nconversational AI, ChatGPT, on July 2023. This feature, known as Custom 538\nInstructions, allows students in higher education, researchers, and graduate students to539\nspecify their preferences or requirements, which the AI system takes into account while540\nformulating responses. This enhancement is particularly beneficial for instructors and541\ngraduate students, as it allows them to tailor the AI’s responses to their specific needs.542\nFor instance, an instructor involved in higher education sciences can leverage this543\nfeature to craft detailed lesson plans without repeatedly specifying their teaching 544\ncontext. Similarly, researchers and graduate students can customize the AI’s responses545\nbased on their field of study, enhancing the relevance and applicability of the 546\ninformation provided. Moreover, those with advanced knowledge in a particular domain547\ncan instruct the AI to generate code without accompanying explanations, thereby 548\nstreamlining the output for those already familiar with the subject matter. 549\nIntroducing custom instructions optimizes the output of ChatGPT, leading to more550\ntargeted and valuable responses, enhancing the educational process, and making the tool551\nmore effective and efficient for learning and teaching purposes. The feature represents a552\nsignificant stride in the evolution of AI, demonstrating its potential to adapt to 553\nindividual needs and contribute positively to various educational contexts. Here is an554\nexample of a graduate-level fluid mechanics course from the student’s perspective. 555\nExample provided by student:I am working on a problem related to the 556\nNavier-Stokes equations, which describe the motion of fluid substances. I understand the557\ntheory but I need help with implementing a numerical solution, specifically using the 558\nfinite difference method in Python. Generate Python code for a finite difference solution559\nto the 2D incompressible Navier-Stokes equations. Assume a uniform grid and a simple560\nboundary condition where the velocity is zero at the boundaries. As I understand the561\ntheory, generate just the code. 562\nIn response to this example, ChatGPT would generate the Python code for finite563\ndifference solutions to the Navier-Stokes equations without explaining the theory behind564\nthe equations. 565\nSeptember 8, 2023 19/42\n5 Chatbot Implementation: Case Study and 566\nEvaluation of a Graduate STEM Course 567\nIncorporated with ChatGPT 568\nAfter we explored ChatGPT and its integration with powerful plugins, features, and569\nstrategies for educational purposes, in our next step, we will examine the full scope of570\nits accuracy and capabilities within the educational realm. Among the many available571\ncourses, we have selected graduate fluid mechanics as our case study due to its 572\nmultifaceted nature, incorporating conceptual, analytical, and mathematical elements,573\nas well as computationally intensive problems that often require advanced solvers and574\npost-processing techniques. 575\n5.1 Case Study: Graduate Fluid Mechanics 576\nAs a case study for this paper, we examined the graduate-level fluid mechanics course to577\ndetermine how the instructors and the students could benefit from a chatbot. This 578\nadvanced-level course offers an in-depth exploration of fluid mechanics, encompassing a579\ncomprehensive understanding of fluid behavior, flow phenomena, and the mathematical580\nmodels utilized to analyze fluid flows. The curriculum explores conservation laws, 581\nviscous flows, boundary layer theory, turbulence, compressibility, and multiphase flows.582\nStudents gain the necessary skills to analyze complex fluid systems and develop 583\nsolutions to practical engineering problems through theoretical lectures, computational584\nexercises, and experimental investigations. It enhances students’ theoretical knowledge585\nand equips them with the analytical and problem-solving abilities essential for success in586\nvarious fields, including aerospace engineering, chemical engineering, civil engineering,587\nand environmental engineering. 588\nThis course also encompasses a unique combination of analytical, conceptual, and589\ncomputational problems, making it an ideal subject to harness the potential benefits of590\na chatbot. With its diverse problem-solving requirements, fluid mechanics presents a591\ncomplex learning landscape for students. Introducing a chatbot into this educational592\ncontext allows students to receive personalized guidance, instant feedback, and 593\ninteractive support tailored to their specific needs, enhancing their understanding and594\nproficiency in this challenging subject. 595\nFurthermore, by incorporating chatbots into the curriculum, instructors could cover596\nmore material on novel and relevant topics, introducing large-scale course projects to597\nenhance students’ understanding and application of concepts. Chatbots offer a unique598\nopportunity to provide automated guidance and support throughout project 599\ndevelopment. Students can engage with chatbots to receive step-by-step instructions,600\naccess relevant resources, and receive instant feedback on their progress. This 601\nintegration enables instructors to introduce complex and cutting-edge topics that may602\nhave been previously challenging to address due to time constraints or limited resources.603\nAdditionally, chatbots can facilitate student collaboration by creating virtual spaces for604\ndiscussion, peer evaluation, and knowledge sharing. By leveraging chatbots’ capabilities,605\ninstructors can create a dynamic learning environment that fosters creativity, 606\nproblem-solving skills, and teamwork. Incorporating chatbots into the curriculum 607\nexpands the possibilities for experimental learning. It equips students with the 608\nnecessary skills to tackle real-world challenges in their field of study and prepares them609\nfor the responsibilities of engineering jobs. 610\nSeptember 8, 2023 20/42\n5.2 Result and Analysis of the Question Bank 611\nEvaluating ChatGPT’s accuracy against a well-structured question bank serves several612\npivotal purposes of this study. It allows a clear assessment of the tool’s proficiency in a613\ngraduate-level fluid mechanics course. This assessment is vital for instructors 614\ncontemplating integrating such AI-driven tools, as it provides insights into their 615\nreliability and potential limitations. Moreover, by finding the areas of strength and 616\nweakness, instructors can strategically guide students on when and how to utilize 617\nChatGPT, ensuring it complements traditional learning methods. This section provides618\nthe evaluation methodology and results for our designed experimental framework. In619\nthis study, we randomly selected 75 graduate-level fluid mechanics questions. The 620\nselected questions include 25 conceptual, 25 analytical, and 25 mathematical questions.621\nSample questions for each category are provided in Appendix B. A deep understanding622\nof turbulence, incompressible, and compressible flow is required to answer these 623\nquestions. Our framework employs ChatGPT 3.5, ChatGPT 4.0, and ChatGPT 4.0 624\nwith the Wolfram plugin. Two prompts were utilized for analytical and mathematical625\nquestions: I/O and CoT. As mentioned before, the ToT prompt suggested by 626\nHulbert [185] did not give correct responses for a lot of analytical and mathematical627\nquestions, and there is a need for a better way to write the ToT prompt; we used the628\nToT prompt only for conceptual questions. The following protocols were maintained629\nwhile asking questions to the ChatGPT: 630\n• For I/O, we asked the questions directly to ChatGPT. For CoT, we asked 631\nquestions in the following way: “Question. Think carefully and logically, 632\nexplaining your answer.” 633\n• Our evaluation criteria only considered whether the response was right or wrong.634\nAny partially correct response was classified as an incorrect response. 635\n• Each question is posted on a separate thread with no chat history or prior 636\nfeedback. 637\nBased on our analysis and the data depicted in Figures 12 and 13, we have 638\ndetermined that ChatGPT 3.5, 4.0, and 4.0 with Wolfram exhibit better performance in639\nFig 12. % of Correct Answers to Mathematical Questions: It is evident that ChatGPT\n4.0 with Wolfram offers the most accurate results for answering mathematical questions.\nFurthermore, it is seen that the accuracy of CoT> I/O prompts for all GPT models.\nSeptember 8, 2023 21/42\nFig 13. % of Correct Answers to Analytical Questions: It is inferred that all ChatGPT\nmodels worked well with analytical questions. In addition, CoT showed 100%\ncorrectness for all the ChatGPT models.\naddressing conceptual and analytical questions compared to the mathematical ones. 640\nBoth ChatGPT 3.5 and 4.0 adeptly handled all selected conceptual questions and 641\nproduced 100% accurate responses. Furthermore, when employing the CoT prompt, all642\nanalytical responses were correct using ChatGPT 3.5, 4.0, and 4.0 with Wolfram. 643\nHowever, in mathematical inquiries, the highest accuracy achieved was 84%, using CoT644\nprompt and ChatGPT 4.0 with Wolfram. The primary reasons for GPT’s inability to645\neffectively address mathematical questions can be classified into two broad categories.646\nIncorrect mathematical reasoning: The domain of graduate-level fluid mechanics 647\ndemands profound comprehension and intricate mathematical reasoning, often 648\nsurpassing the capabilities of a language model. Insufficient grasp of scientific principles,649\nmethodologies, and terminology can lead to erroneous responses [188]. ChatGPT 650\nsometimes makes flawed assumptions and employs incorrect mathematical equations,651\nresulting in inaccurate responses. 652\nIncorrect calculations: There are situations where ChatGPT makes accurate 653\nassumptions and applies correct mathematical equations but falters during the 654\nexecution of mathematical operations, resulting in erroneous answers. This type of error655\nis more frequently observed in ChatGPT 3.5, while leveraging ChatGPT 4.0 with 656\nWolfram substantially mitigates such errors. 657\nThere are a few other types of errors found in the literature. ChatGPT can lack658\nspatial perception, manifesting as an inability to visualize atoms, molecules, and 659\nforces [188]. Deficiencies in causal and logical reasoning can also lead to incorrect 660\nresponses [188–190]. Additionally, there can be areas for improvement in spatial and661\ntemporal reasoning, which pertains to comprehending relationships among objects, 662\nindividuals, space, and chronological order [191]. 663\nAs evidenced in Figures 12 and 13, the CoT prompt outperforms the I/O prompts.664\nThis trend is particularly pronounced in mathematical responses. Furthermore, 665\nincorporating Wolfram plugins with ChatGPT 4.0 substantially reduces 666\ncomputation-related errors, enhancing the overall accuracy of responses. 667\nOur investigation into ChatGPT’s effectiveness in addressing graduate-level fluid 668\nSeptember 8, 2023 22/42\nmechanics questions has unveiled several implications for instructors. When ChatGPT669\ndemonstrates high accuracy rates in analytical and conceptual questions, it emerges as a670\nreliable supplementary resource, providing students with rapid clarifications beyond 671\ntraditional resources. However, given its moderate accuracy in mathematical questions,672\nit is advisable to cross-reference with primary academic sources to ensure conceptual673\ncorrectness. Instructors can harness ChatGPT’s interactive potential regardless of 674\naccuracy by incorporating it into lectures for real-time discussions. Furthermore, 675\ninstructors can strategically design assignments to foster critical thinking and 676\nproblem-solving skills, avoiding direct reliance on ChatGPT for solutions. This 677\napproach maintains academic integrity and encourages independent learning. While 678\nChatGPT can augment educational experiences, instructors should position it as a 679\nsupplement rather than a replacement for conventional teaching methodologies. 680\n5.3 Considerations for Responsible LLM and Chatbot 681\nIntegration in Education 682\nThe outputs generated by chatbots are not static but can evolve and change over time683\nfor several reasons. First, chatbots employ stochastic language models, so their 684\nresponses contain an element of randomness and will naturally vary (refer to Appendix685\nA for a comprehensive explanation of the stochastic nature of LLMs and chatbots).686\nAdditionally, the underlying large language models powering chatbots are often updated687\nor replaced with more advanced versions, altering the knowledge and conversational688\ncapabilities. For safety and ethical reasons, chatbot creators may also modify the 689\nsystem to constrain certain types of problematic outputs that previously occurred. 690\nMoreover, different chatbots leverage unique architectures, training datasets, and 691\nplugins, so outputs will understandably differ across chatbot applications and versions.692\nIn our case study, this implies that the results, prompts, strategies, and examples 693\nproposed in section 4 could potentially yield responses that deviate from the 694\nillustrations in Figures 5 to 11, given a different timeframe. We observed a similar 695\nphenomenon when attempting to reproduce the findings presented by Hulbert [185] 696\n(Figure 14 represents the question that we investigated to identify the changes in the697\naccuracy of ChatGPT 3.5, Figure 15 illustrates the wrong response provided by 698\nChatGPT 3.5 March 2023 version [185], Figure 16 shows the correct response we 699\nobtained by using ChatGPT 3.5 July 2023 version). All the analyses and results 700\npresented in this study were conducted using the ChatGPT July 2023 version. 701\nFig 14. The representative problem used by [185]: The question provided in the\naforementioned study measures the logic and reasoning capability of ChatGPT.\nFinally, as illustrated in Figure 1, human feedback is a pivotal facet in enhancing702\nchatbot learning. Human input aids chatbots in learning from their errors. However,703\nwithout effective monitoring and refinement, the reliability of chatbots might 704\ndecline [192]. There have been reports indicating a reduction in ChatGPT’s accuracy in705\npredicting prime numbers and its reliability in generating computer code between 706\nMarch 2023 and June 2023 [193]. In summary, we cannot expect consistent identical707\nresponses from chatbots, as their outputs are subject to stochasticity, evolving language708\nmodels, safety interventions, and distinctive system designs. The nature of chatbot 709\nSeptember 8, 2023 23/42\nFig 15. Response from ChatGPT 3.5 using CoT prompt [185]: In their study,\nChatGPT 3.5 generated the wrong answer for the problem illustrated in Figure 14.\nFig 16. Response from ChatGPT 3.5 using CoT prompt suggested by [185]: Using the\nsuggested prompt, ChatGPT 3.5 gives the correct response for the problem presented in\nFigure 14, which is contrary to the response provided in Figure 15\noutputs is dynamic rather than static over time. 710\nSeptember 8, 2023 24/42\n6 Chatbots: Assessment and Recommendations for 711\nEducation 712\nWhen the calculator was invented, everyone was concerned it would take away our 713\nnumeracy skills. Nevertheless, it has become an integral part of our day-to-day life.714\nCurrently, we have a similar concern: chatbots would replace conventional teaching and715\nlearning methods. Therefore, it is essential to watch and track the fast improvements of716\nchatbots and decide on their use in teaching, learning, and assessment in higher 717\neducation. Currently, there are opinions from the two extremes- banning the use of718\nchatbots and AI software or including them in the curriculum. We suggest universities719\nand instructors go against any policing approach rather than using chatbots as a 720\npowerful supplementary tool to enhance student’s learning process. So, the next big721\nquestion is, “What should be the assessment process if the students use chatbots?” A722\nsimple solution to this problem might be to use physical closed-book or online 723\nexaminations where students are prohibited from using any chatbots or AI 724\nsoftware [194]. However, such an approach has been criticized long before since it is not725\ncontemporary, and students memorize much unnecessary information to pass the 726\nexamination, which they forget shortly after the examinations [195]. Instead of the 727\nclosed book examinations, the instructors can take open book examinations and 728\nprohibit using any software, which is very common in grad-level fluid mechanics courses.729\nAnother idea of assessment is to design the assignments that ChatGPTs are not730\ngood at handling. In this context, our study is very beneficial. We found that current731\nChatGPT models can accurately answer conceptual and analytical questions. However,732\nit still struggles to answer mathematical questions in graduate-level fluid mechanics.733\nTherefore, based on our study, it is suggested that the instructors design their 734\nassignments based on mathematical questions. It is also suggested that the instructors735\nshould set questions using different visuals, images, or charts, which the current models736\nof ChatGPTs struggle to answer. However, this approach may be a short-term solution737\nas the ChatGPT models are improving very fast, and future models would be able to738\nhandle more complex mathematical questions of fluid mechanics. Another form of 739\nassessment could be submitting assignments that include personal experiences on fluid740\nmechanics perspectives. Uploading audio or video files explaining the assignments [195]741\nor in-person presentations [196] can be another form of assessment. 742\nOverall, our suggestions for the instructors, in terms of teaching, is to go through the743\neasy concept and analytical parts very quickly and spend more time on the 744\nmathematical and very complicated real-life problems. The students should use 745\nchatbots to improve their writing skills and generate ideas rather than copying and746\npasting answers. It is high time the universities realized that the digital form of 747\neducation is critical and included AI tools in the curriculum as a supplement, not as a748\nreplacement for conventional teaching and learning. The universities should provide 749\ntraining on chatbots and AI ethics and update academic integrity policies that include750\nchatbots and AI tools. 751\n7 Conclusion 752\nThis paper set out to explore the transformative potential of Language Learning Models753\n(LLMs), particularly advanced chatbots like ChatGPT 4.0, in higher education with a754\nfocus on specialized subjects such as fluid mechanics. We initiated our study with a755\nreview of the disruptions in education, defining what LLMs and chatbots are, and 756\nassessing their applicability in teaching graduate-level fluid mechanics. 757\nSeptember 8, 2023 25/42\nOur meticulous evaluation of a question bank tailored for a fluid mechanics course758\nrevealed that ChatGPT’s latest versions show remarkable proficiency in tackling 759\nanalytical and conceptual questions. Specifically, ChatGPT 3.5 and 4.0 yielded 100%760\naccurate responses for all the selected conceptual queries. Moreover, when CoT (Chain761\nof Thought) prompting strategies were employed, these versions also demonstrated 762\nflawless performance in responding to analytical questions. 763\nHowever, the performance dropped when it came to mathematical questions, with764\nthe highest accuracy level being 84%—achieved by ChatGPT 4.0 integrated with 765\nWolfram Alpha. Our analysis suggests that the limitations primarily stem from either766\nincorrect mathematical reasoning or computational errors. These limitations can be 767\nsomewhat mitigated by using plugins like Wolfram Alpha, which significantly improve768\nthe reliability of mathematical answers. 769\nOur research also underscored the importance of effective prompting strategies. CoT770\n(Chain of Thought) prompting consistently outperformed I/O (Input/Output) 771\nprompting, particularly in the realm of mathematical questions. Beyond prompting, we772\ndiscussed the enhancement of chatbot capabilities through plugins like Wolfram Alpha773\nand Code Interpreter. These plugins not only improve the accuracy but also expand the774\nrange of tasks that can be automated, including code generation and debugging, 775\nstatistical analysis, and data visualization. 776\nWhile the rapid advancements in LLMs hold promise for revolutionizing educational777\npractices, caution is advised. Custom instructions, although powerful, may sometimes778\nresult in misleading or irrelevant outputs. Instructors and students are urged to 779\ncritically assess the generated content rather than accepting it unquestioningly. 780\nGiven the accelerating development in the field of LLMs, we anticipate that 781\nupcoming versions will be even more powerful, provided that ethical considerations are782\nadequately addressed. The widespread use of chatbots by numerous organizations 783\nhighlights the urgent requirement for higher education institutions to incorporate these784\ntools into their academic landscape [197–199]. However, the onus is on educational 785\ninstitutions to stay updated and adapt these technologies responsibly. Integration of786\nsuch tools into academic environments is not merely an option but a necessity for 787\nfostering innovation and nurturing independent, critical thinking among graduate 788\nstudents. 789\nIn summary, our study strongly advocates for the integration of advanced chatbots790\nlike ChatGPT into the educational ecosystem, especially for automating labor-intensive791\ntasks such as literature reviews, code writing, and conceptual explanations. This will792\nenable instructors and students to concentrate more on the essence of higher education:793\ndeveloping innovative solutions to complex global challenges. 794\nA Details of the Stochastic Nature of LLMs 795\nAs highlighted earlier, the output generated by chatbots, or more formally, Language796\nLearning Models (LLMs) like GPT (Generative Pretrained Transformer), is stochastic797\nin nature. This means that the output is probabilistic and may vary from one instance798\nto another. While this variability can be an asset in some contexts, such as creative799\nwriting or brainstorming, it raises certain questions when these tools are applied in 800\neducational settings. 801\nEducational tools like calculators or search engines usually provide consistent, 802\npredictable outcomes—a critical requirement for objective learning and assessment. 803\nSeptember 8, 2023 26/42\nImagine a calculator that gave different answers each time you input the same equation;804\nit would be unreliable for educational purposes. 805\nSome chatbots, including Claude and ChatGPT, offer features like “Retry” or 806\n“Regenerate” that allow users to request new outputs. instructors should be aware of807\nthis stochastic element and are advised to explore the range of possible responses to808\nensure they align with educational objectives. 809\nIn this appendix, we delve into the mathematical foundations that underlie these810\nstochastic behaviors to provide instructors with a deeper understanding of what 811\nchatbots are actually doing when generating responses. 812\nA.1 Markov Chains and Autoregressive Models: The 813\nUnderlying Mechanics 814\nTo understand why chatbots produce variable outputs, it is helpful to consider the 815\nconcept of a Markov Chain. In its simplest form, a Markov Chain is a sequence of816\nevents where the probability of each event occurring depends solely on the state of the817\nprevious event. When applied to language, this means that the likelihood of the next818\nword appearing in a sentence depends only on the current word. 819\nHowever, modern chatbots use more advanced versions of this concept, known as820\nautoregressive models. In these, the probability of the next word appearing depends on821\nthe lastp words rather than just the current word. This allows the model to generate822\nmore coherent and contextually relevant text. 823\nA.2 A Bayesian Perspective: Updating Probabilities 824\nOn-The-Fly 825\nFrom a Bayesian point of view, the chatbot constantly updates its ’beliefs’—in this case,826\nthe probabilities of potential next words—based on the new words it encounters. These827\nupdates are mathematically represented by Bayes’ theorem: 828\nP(next word|context) =P(context|next word)⇥ P(next word)\nP(context) (1)\nHere, P(next word|context) is the probability of the next word given the current 829\ncontext, whileP(context|next word) andP(next word) are the likelihood of the context830\ngiven the next word and the prior probability of the next word, respectively. The term831\nP(context) is a normalizing constant that ensures all probabilities sum to one. By 832\ncontinuously updating these probabilities, the chatbot can produce text that is coherent833\nand contextually appropriate, albeit with a degree of stochastic variability. 834\nA.3 Connecting Autoregressive Models with Probabilities: The835\nPredictive Nature of Chatbots 836\nIn the realm of language models, autoregressive models predict the next word based on837\nprobabilities tied to the preceding words or context. This is crucial to understand 838\nbecause it means that the chatbot isn’t just picking words randomly; it is making 839\neducated guesses based on what it has “learned” during its training phase. 840\nFor a simple first-order autoregressive model, abbreviated as AR(1), the probability841\nof the upcoming word, given the current word, can be expressed as: 842\nP(Wt+1 = w|Wt)= f(Wt; ✓) (2)\nSeptember 8, 2023 27/42\nIn this formula,f represents a function parameterized by✓, which gives the probability 843\nof the next wordw occurring, given the current wordWt. 844\nA.4 Temperature Scaling: Fine-Tuning the Randomness 845\nAfter calculating these probabilities using an autoregressive model (which you can think846\nof as our “educated guesses” influenced by the context), we can further refine them with847\na technique known as temperature scaling. The formula for this is: 848\nP0(wi)= P(wi)\n1\nT\nP\nj P(wj )\n1\nT\n(3)\nHere, T is the temperature parameter. A high temperature will make the output more849\nrandom: the probabilities raised to the 0-th power are nearly constant. Conversely, a850\nlow temperature will make it more deterministic because the largest probability will be851\nselected as smaller probabilities are driven to zero. This is particularly useful in 852\neducational settings where you might want to control the level of creativity or 853\nrandomness in the chatbot’s responses. 854\nA.5 Summary: Understanding the Stochastic Nature of 855\nLanguage Learning Models 856\nIn summary, when an autoregressive model generates probabilities for the next word, it857\nuses a well-defined probabilistic framework. This framework takes into account the 858\ncontext (previous words) to determine the probabilities of potential next words. Various859\nmethods like Markov Chains, Bayesian updating, or neural networks trained in an 860\nautoregressive manner are employed to derive these probabilities. Once the raw 861\nprobabilities are obtained, they can be fine-tuned using temperature scaling to control862\nthe level of randomness in the model’s output. 863\nB Fluid Mechanics Question Banks Used in this 864\nStudy 865\nThe following appendix provides representative examples from the test bank of fluid866\nmechanics questions utilized in assessing chatbot performance. The test bank contains867\nquestions spanning the breadth of fluid mechanics, categorized as conceptual, analytical,868\nor mathematical problems. 869\nConceptual questions test qualitative understanding of fluid behavior and 870\nphenomena without requiring calculations. Analytical questions involve setting up and871\nsolving equations describing fluid systems using principles of fluid mechanics. 872\nMathematical questions pose quantitative scenarios that must be solved through the873\napplication of fluid equations and math operations. 874\nTo offer insight into the nature and difficulty of problems within each category, we875\nhave included five sample questions from the test bank for each type - conceptual, 876\nanalytical, and mathematical. Though limited in number, these examples aim to 877\nillustrate the progression in complexity and needed fluency with fluid mechanics theory,878\napproximations, and calculations required in analyzing situations across the question879\nbank. Readers are encouraged to review these samples to gain an appreciation of the880\nrigorous assessment undertaken through this compiled set of fluid mechanics problems.881\nSeptember 8, 2023 28/42\nB.1 Class I- Conceptual Problems 882\n• What are the characteristics of subsonic, transonic, and supersonic flow regimes,883\nand how are they analyzed? 884\n• Consider the vectorw = n ⇥ (v ⇥ n), wherev is arbitrary andn is a unit vector. 885\nIn which direction doesw point, and what is its magnitude? 886\n• Discuss the principles and applications of the lattice Boltzmann method in 887\nsimulating fluid flows. 888\n• How does the Boussinesq approximation extend the Navier-Stokes equation to 889\ninclude buoyancy effects? 890\n• If the entropyS is considered as the dependent variable in the fundamental 891\ndifferential equation, what are the proper definitions forT, P, andµ? 892\nB.2 Class II- Analytical Problems 893\n• Prove that the productSij Tji is zero ifSij is symmetric andTji is anti-symmetric. 894\n• For 2D flow, prove that the vortex stretching in the vorticity equation is zero.895\n• Write the vorticity equation and the physical meaning of each term. 896\n• Prove that potential flows are irrotational and irrotational flows are potential. 897\n• Show that the dissipation term in the energy equation is positive. 898\nB.3 Class III- Mathematical Problems 899\n• Consider the flow through a convergent-divergent duct with an exit-to-throat area900\nratio of 2. The reservoir pressure is 1 atm, and the exit pressure is 0.95 atm.901\nCalculate the Mach numbers at the exit. 902\n• A supersonic wind tunnel is designed to produce Mach 2.5 flow in the test section903\nwith standard sea level conditions. Calculate the exit area ratio and reservoir 904\nconditions necessary to achieve these design conditions. 905\n• A very long tube 3 cm in diameter carries water at an average velocity of 5 m/s.906\nA short nozzle attached to the end accelerates the flow with a 5:1 area reduction.907\nFind the force between the pipe and the nozzle when the exit pressure (P2)i s 908\natmospheric (100 kPa), and the pipe pressure (P1) is 325 kPa. 909\n• A normal shock wave is standing in the test section of a supersonic wind tunnel.910\nUpstream of the wave, Mach numberM1 = 3, pressureP1= 0.5 atm, and 911\ntemperature T1 = 200 K. FindM2, P2 and T2 downstream of the wave. 912\n• Consider the isentropic subsonic-supersonic flow through a convergent-divergent913\nnozzle. The reservoir pressure and temperature are 10 atm and 300 K, 914\nrespectively. There are two locations in the nozzle whereA/(A⇤) = 6:1, one in the 915\nconvergent section and the other in the divergent section. Assume the values for916\nsubsonic section: M = 0.097,P0/P = 1.006,T0/T = 1.002; while for the 917\nsupersonic section M = 3.368,P0/P = 63.13,T0/T = 3.269. At each location, 918\ncalculate M, P, T, andu. 919\nSeptember 8, 2023 29/42\nReferences\n1. Eisenstein EL. The printing press as an agent of change. vol. 1. Cambridge\nUniversity Press; 1980.\n2. Kolb AY, Kolb D. Experiential Learning Theory as a Guide for Experiential\nEducators in Higher Education. ELTHE: Experiential Learning in Higher\nEducation. 2022;1(1). doi:10.46787/elthe.v1i1.3362.\n3. Cain VEM. From Sesame Street to Prime Time School Television: Educational\nMedia in the Wake of the Coleman Report. History of Education Quarterly.\n2017;57(4):590–615. doi:10.1017/heq.2017.34.\n4. Gercek G, Saleem N, Steel DJ. Implementing Cloud Based Virtual Computer\nNetwork Labs for Online Education: Experiences from a Phased Approach.\nInternational Journal of Online Engineering (iJOE). 2016;12(03):4–10.\ndoi:10.3991/IJOE.V12I03.5564.\n5. Banks S. A Historical Analysis of Attitudes toward the Use of Calculators in\nJunior High and High School Math Classrooms in the United States since 1975.\nCedarville University. 2011;doi:10.15385/TMED.2011.1.\n6. Wegerif R. Applying dialogic theory to illuminate the relationship between\nliteracy education and teaching thinking in the context of the Internet Age.\nL1-Educational Studies in Language and Literature. 2016;16:1–21.\ndoi:10.17239/L1ESLL-2016.16.02.07.\n7. Gayoso Mart´ ınez V, Hern´ andez Encinas L, Mart´ ın Mu˜ noz A, Queiruga Dios A.\nUsingFree Mathematical Software in Engineering Classes. axioms.\n2021;doi:10.3390/axioms10040253.\n8. Velychko V, Stopkin A, Fedorenko O. USE OF COMPUTER ALGEBRA\nSYSTEM MAXIMA IN THE PROCESS OF TEACHING FUTURE\nMATHEMATICS TEACHERS. Information Technologies and Learning Tools.\n2019;doi:10.33407/ITLT.V69I1.2284.\n9. Kaw A, Hess M. Assessing Teaching Methods for a Course in Numerical\nMethods. Cedarville University. 2006;doi:10.18260/1-2–547.\n10. Lee Y, Cho J. The Influence of Python Programming Education for Raising\nComputational Thinking. International Journal of u- and e- Service, Science and\nTechnology. 2017;10(8):63–72. doi:10.14257/IJUNESST.2017.10.8.06.\n11. Prokopyev MS, Vlasova EZ, Tretyakova T, Sorochinsky M, Solovyeva RA.\nDevelopment of a Programming Course for Students of a Teacher Training\nHigher Education Institution Using the Programming Language Python.\nAxioms. 2020;9(3):253. doi:10.20511/PYR2020.V8N3.484.\n12. Cheon M, Lee O, Mun C, Ha H. A Study on the Factors Affecting Intention of\nLearning Python Programming: For Non-majors in University. International\nJournal of Information and Education Technology. 2022;12(5):1635.\ndoi:10.18178/ijiet.2022.12.5.1635.\n13. Woolf BP. Building Intelligent Interactive Tutors: Student-centered Strategies\nfor Revolutionizing E-learning. Morgan Kaufmann. 2009;.\n14. Anderson JR, Corbett AT, Koedinger KR, Pelletier R. Lessons learned from the\ndesign and implementation of intelligent tutoring systems. Intelligent tutoring\nsystems: Lessons learned. 1995; p. 227–250.\nSeptember 8, 2023 30/42\n15. Siemens G, Long P. Learning analytics: The emergence of a discipline.\nAmerican Behavioral Scientist. 2013;57(10):1380–1400.\n16. Billinghurst M. Augmented reality in education. New horizons for learning.\n2002;12(5):1–5.\n17. Boyles B. Virtual reality and augmented reality in education. Center For\nTeaching Excellence, United States Military Academy, West Point, Ny. 2017;67.\n18. Elmqaddem N. Augmented reality and virtual reality in education. Myth or\nreality? International journal of emerging technologies in learning. 2019;14(3).\n19. Sukiman SA, Aziz NA. ARTIFICIAL INTELLIGENCE AS THE KEY\nPLAYER IN LEARNING INTERVENTIONS: A MINI REVIEW AMONG\nSTUDENTS WITH LEARNING DIFFICULTIES. International Journal of\nTechnology Management and Information System. 2021;3(2):1–14.\n20. Holmes W, Bialik M, Fadel C. Artificial intelligence in education. In: Data\nethics : building trust : how digital technologies can serve humanity. Globethics\nPublications; 2023. p. 621–653.\n21. Ayzeren YB, Erbilek M, C ¸ elebi E. Emotional state prediction from online\nhandwriting and signature biometrics. IEEE Access. 2019;7:164759–164774.\n22. Khalil M, Er E. Will ChatGPT get you caught? Rethinking of plagiarism\ndetection. arXiv preprint arXiv:230204335. 2023;.\n23. Sahu M. Plagiarism detection using artificial intelligence technique in multiple\nfiles. International Journal 0f Scientific and Technology Research. 2016;5(4).\n24. Quidwai MA, Li C, Dube P. Beyond Black Box AI-Generated Plagiarism\nDetection: From Sentence to Document Level. arXiv preprint arXiv:230608122.\n2023;.\n25. D P. War of the chatbots: Bard, Bing Chat, ChatGPT, Ernie and beyond. The\nnew AI gold rush and its impact on higher education. Journal of AI and\nLearning. 2023;6(1):23–33.\n26. Caldarini G, Jaf S, McGarry K. A literature survey of recent advances in\nchatbots. Information. 2022;13(1):41.\n27. Talib MA, Majzoub S, Nasir Q, Jamal D. A systematic literature review on\nhardware implementation of artificial intelligence algorithms. The Journal of\nSupercomputing. 2021;77:1897–1938.\n28. Berdejo-Espinola V, Amano T. AI tools can improve equity in science. Science.\n2023;379(6636):991–991.\n29. Collins-Thompson K, Callan J. Predicting reading difficulty with statistical\nlanguage models. Journal of the american society for information science and\ntechnology. 2005;56(13):1448–1462.\n30. Korteling JH, van de Boer-Visschedijk G, Blankendaal RA, Boonekamp R,\nEikelboom A. Human-versus artificial intelligence. Frontiers in artificial\nintelligence. 2021;4:622364.\n31. Fernoag˘ a V, Stelea GA, Gavril˘ a C, Sandu F. Intelligent Education Assistant\nPowered by Chatbots. eLearning & Software for Education. 2018;2.\nSeptember 8, 2023 31/42\n32. Colace F, De Santo M, Lombardi M, Pascale F, Pietrosanto A, Lemma S.\nChatbot for e-learning: A case of study. International Journal of Mechanical\nEngineering and Robotics Research. 2018;7(5):528–533.\n33. Ghayyur S, Averitt J, Mugunthan V, Wallace E, Deshpande A. Panel: Privacy\nChallenges and Opportunities in{LLM-Based} Chatbot Applications. In:\nProceedings of 2023 USENIX Conference on Privacy Engineering Practice and\nRespect; 2023.\n34. Abd-Alrazaq A, AlSaad R, Alhuwail D, Ahmed A, Healy PM, Latifi S, et al.\nLarge Language Models in Medical Education: Opportunities, Challenges, and\nFuture Directions. JMIR Medical Education. 2023;9(1):e48291.\n35. Renals S, Grefenstette G. Text-and Speech-Triggered Information Access: 8th\nELSNET Summer School, Chios Island, Greece, July 15-30, 2000, Revised\nLectures. vol. 2705. Springer; 2003.\n36. Bellegarda JR. Statistical language model adaptation: review and perspectives.\nSpeech communication. 2004;42(1):93–108.\n37. Bellegarda JR. An overview of statistical language model adaptation. In: ISCA\nTutorial and Research Workshop (ITRW) on Adaptation Methods for Speech\nRecognition; 2001. p. 165–174.\n38. Melis G, Dyer C, Blunsom P. On the state of the art of evaluation in neural\nlanguage models. arXiv preprint arXiv:170705589. 2017;.\n39. Carlini N, Ippolito D, Jagielski M, Lee K, Tramer F, Zhang C. Quantifying\nmemorization across neural language models. arXiv preprint arXiv:220207646.\n2022;.\n40. Hosseini K, Beelen K, Colavizza G, Ardanuy MC. Neural language models for\nnineteenth-century english. arXiv preprint arXiv:210511321. 2021;.\n41. Petroni F, Rockt¨ aschel T, Lewis P, Bakhtin A, Wu Y, Miller AH, et al.\nLanguage models as knowledge bases? arXiv preprint arXiv:190901066. 2019;.\n42. Li S, Puig X, Paxton C, Du Y, Wang C, Fan L, et al. Pre-trained language\nmodels for interactive decision-making. Advances in Neural Information\nProcessing Systems. 2022;35:31199–31212.\n43. See A, Pappu A, Saxena R, Yerukola A, Manning CD. Do massively pretrained\nlanguage models make better storytellers? arXiv preprint arXiv:190910705.\n2019;.\n44. Griffith S, Subramanian K, Scholz J, Isbell CL, Thomaz AL. Policy shaping:\nIntegrating human feedback with reinforcement learning. Advances in neural\ninformation processing systems. 2013;26.\n45. Christiano PF, Leike J, Brown T, Martic M, Legg S, Amodei D. Deep\nreinforcement learning from human preferences. Advances in neural information\nprocessing systems. 2017;30.\n46. Hendrycks D, Burns C, Basart S, Critch A, Li J, Song D, et al. Aligning ai with\nshared human values. arXiv preprint arXiv:200802275. 2020;.\n47. Ouyang L, Wu J, Jiang X, Almeida D, Wainwright C, Mishkin P, et al. Training\nlanguage models to follow instructions with human feedback. Advances in\nNeural Information Processing Systems. 2022;35:27730–27744.\nSeptember 8, 2023 32/42\n48. Song F, Yu B, Li M, Yu H, Huang F, Li Y, et al. Preference ranking\noptimization for human alignment. arXiv preprint arXiv:230617492. 2023;.\n49. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, et al.\nAttention is all you need. Advances in neural information processing systems.\n2017;30.\n50. Qiu D, Yang B. Text summarization based on multi-head self-attention\nmechanism and pointer network. Complex & Intelligent Systems. 2022; p. 1–13.\n51. Liu G, Guo J. Bidirectional LSTM with attention mechanism and convolutional\nlayer for text classification. Neurocomputing. 2019;337:325–338.\n52. Chen C, Han D, Chang CC. CAAN: Context-Aware attention network for visual\nquestion answering. Pattern Recognition. 2022;132:108980.\n53. K¨ unas CA, Padoin EL, Navaux PO. Accelerating Deep Learning Model Training\non Cloud Tensor Processing Unit. In: CLOSER; 2023. p. 316–323.\n54. ARD V, GR J. Five ways deep learning has transformed image analysis. Nature.\n2022;609.\n55. Narayanan D, Shoeybi M, Casper J, LeGresley P, Patwary M, Korthikanti V,\net al. Efficient large-scale language model training on gpu clusters using\nmegatron-lm. In: Proceedings of the International Conference for High\nPerformance Computing, Networking, Storage and Analysis; 2021. p. 1–15.\n56. de Jong M, Zemlyanskiy Y, Ainslie J, FitzGerald N, Sanghai S, Sha F, et al.\nFiDO: Fusion-in-Decoder optimized for stronger performance and faster\ninference. arXiv preprint arXiv:221208153. 2022;.\n57. Babaeizadeh M, Frosio I, Tyree S, Clemons J, Kautz J. Reinforcement learning\nthrough asynchronous advantage actor-critic on a gpu. arXiv preprint\narXiv:161106256. 2016;.\n58. Tinn R, Cheng H, Gu Y, Usuyama N, Liu X, Naumann T, et al. Fine-tuning\nlarge neural language models for biomedical natural language processing.\nPatterns. 2023;4(4).\n59. Aghajanyan A, Okhonko D, Lewis M, Joshi M, Xu H, Ghosh G, et al. Htlm:\nHyper-text pre-training and prompting of language models. arXiv preprint\narXiv:210706955. 2021;.\n60. Ding N, Qin Y, Yang G, Wei F, Yang Z, Su Y, et al. Parameter-efficient\nfine-tuning of large-scale pre-trained language models. Nature Machine\nIntelligence. 2023;5(3):220–235.\n61. Sarker IH. Ai-based modeling: Techniques, applications and research issues\ntowards automation, intelligent and smart systems. SN Computer Science.\n2022;3(2):158.\n62. Singh G, Mallik A, Iqbal Z, Revalla H, Chao S, Nagasamy V. Systems and\nmethods for detecting deep neural network inference quality using image/data\nmanipulation without ground truth information; 2023.\n63. Singh G. Measuring confidence in deep neural networks; 2023.\n64. Li Y, Du Y, Zhou K, Wang J, Zhao WX, Wen JR. Evaluating object\nhallucination in large vision-language models. arXiv preprint arXiv:230510355.\n2023;.\nSeptember 8, 2023 33/42\n65. Manakul P, Liusie A, Gales MJ. Selfcheckgpt: Zero-resource black-box\nhallucination detection for generative large language models. arXiv preprint\narXiv:230308896. 2023;.\n66. Yu P, Ji H. Self Information Update for Large Language Models through\nMitigating Exposure Bias. arXiv preprint arXiv:230518582. 2023;.\n67. Lewis P, Perez E, Piktus A, Petroni F, Karpukhin V, Goyal N, et al.\nRetrieval-augmented generation for knowledge-intensive nlp tasks. Advances in\nNeural Information Processing Systems. 2020;33:9459–9474.\n68. Weidinger L, Mellor J, Rauh M, Griffin C, Uesato J, Huang PS, et al. Ethical\nand social risks of harm from language models. arXiv preprint arXiv:211204359.\n2021;.\n69. Touileb S, Nozza D. Measuring harmful representations in Scandinavian\nlanguage models. arXiv preprint arXiv:221111678. 2022;.\n70. Pan X, Zhang M, Ji S, Yang M. Privacy risks of general-purpose language\nmodels. In: 2020 IEEE Symposium on Security and Privacy (SP). IEEE; 2020.\np. 1314–1331.\n71. Curzon J, Kosa TA, Akalu R, El-Khatib K. Privacy and artificial intelligence.\nIEEE Transactions on Artificial Intelligence. 2021;2(2):96–108.\n72. Bartneck C, L¨ utge C, Wagner A, Welsh S, Bartneck C, L¨ utge C, et al. Privacy\nissues of AI. An introduction to ethics in robotics and AI. 2021; p. 61–70.\n73. Passi S, Vorvoreanu M. Overreliance on AI Literature Review. Microsoft\nResearch. 2022;.\n74. Guo C, Pleiss G, Sun Y, Weinberger KQ. On calibration of modern neural\nnetworks. In: International conference on machine learning. PMLR; 2017. p.\n1321–1330.\n75. Zhang H, Duckworth D, Ippolito D, Neelakantan A. Trading off diversity and\nquality in natural language generation. arXiv preprint arXiv:200410450. 2020;.\n76. Norouzi M, Bengio S, Jaitly N, Schuster M, Wu Y, Schuurmans D, et al.\nReward augmented maximum likelihood for neural structured prediction.\nAdvances In Neural Information Processing Systems. 2016;29.\n77. Caccia M, Caccia L, Fedus W, Larochelle H, Pineau J, Charlin L. Language\ngans falling short. arXiv preprint arXiv:181102549. 2018;.\n78. Lin J, Sun X, Ren X, Li M, Su Q. Learning when to concentrate or divert\nattention: Self-adaptive attention temperature for neural machine translation.\narXiv preprint arXiv:180807374. 2018;.\n79. Wei J, Tay Y, Bommasani R, Raffel C, Zoph B, Borgeaud S, et al. Emergent\nabilities of large language models. arXiv preprint arXiv:220607682. 2022;.\n80. Bowman SR. Eight things to know about large language models. arXiv preprint\narXiv:230400612. 2023;.\n81. Turing AM. Computing machinery and intelligence. Springer; 2009.\n82. Turing A. Intelligent machinery (1948). B Jack Copeland. 2004; p. 395.\n83. Turing A. Intelligent machinery, a heretical theory (c. 1951). B Jack Copeland.\n2004; p. 465.\nSeptember 8, 2023 34/42\n84. Weizenbaum J. ELIZA—a computer program for the study of natural language\ncommunication between man and machine. Communications of the ACM.\n1966;9(1):36–45.\n85. Bassett C. The computational therapeutic: exploring Weizenbaum’s ELIZA as a\nhistory of the present. AI & SOCIETY. 2019;34:803–812.\n86. Shum HY, He Xd, Li D. From Eliza to XiaoIce: challenges and opportunities\nwith social chatbots. Frontiers of Information Technology & Electronic\nEngineering. 2018;19:10–26.\n87. Wallace RS. The anatomy of ALICE. Springer; 2009.\n88. Bani BS, Singh AP. College enquiry Chatbot using ALICE. International\nJournal of New Technology and Research. 2017;3(1):263368.\n89. McTear MF, Callejas Z, Griol D. The conversational interface. 94. Springer;\n2016.\n90. Sharma V, Goyal M, Malik D. An intelligent behaviour shown by chatbot\nsystem. International Journal of New Technology and Research.\n2017;3(4):263312.\n91. Hutchens JL, Alder MD. Introducing megahal. In: New Methods in Language\nProcessing and Computational Natural Language Learning; 1998. p. 271–274.\n92. Siswadi AAP, Tarigan A. Ugleo: a Web Based Intelligence Chatbot for Student\nAdmission Portal Using Megahal Style. Jurnal Ilmiah Informatika Komputer.\n2020;23(3):175–191.\n93. Fryer L, Carpenter R. Bots as language learning tools. Language Learning &\nTechnology. 2006;.\n94. Boiano S, Borda A, Gaia G, Rossi S, Cuomo P. Chatbots and new audience\nopportunities for museums and heritage organisations. Electronic visualisation\nand the arts. 2018; p. 164–171.\n95. De Angeli A, Carpenter R, et al. Stupid computer! Abuse and social identities.\nIn: Proc. INTERACT 2005 workshop Abuse: The darker side of\nHuman-Computer Interaction. 4. Citeseer; 2005. p. 19–25.\n96. Chao MH, Trappey AJ, Wu CT. Emerging technologies of natural\nlanguage-enabled chatbots: a review and trend forecast using intelligent\nontology extraction and patent analytics. Complexity. 2021;2021:1–26.\n97. Bilquise G, Ibrahim S, Shaalan K, et al. Emotionally Intelligent Chatbots: A\nSystematic Literature Review. Human Behavior and Emerging Technologies.\n2022;2022.\n98. Adamopoulou E, Moussiades L. An overview of chatbot technology. In: IFIP\ninternational conference on artificial intelligence applications and innovations.\nSpringer; 2020. p. 373–383.\n99. Wollny S, Schneider J, Di Mitri D, Weidlich J, Rittberger M, Drachsler H. Are\nwe there yet?-a systematic literature review on chatbots in education. Frontiers\nin artificial intelligence. 2021;4:654924.\n100. Nawaz N, Saldeen MA. Artificial intelligence chatbots for library reference\nservices. Journal of Management Information & Decision Sciences. 2020;23.\nSeptember 8, 2023 35/42\n101. Liu L, Duffy VG. Exploring the Future Development of Artificial Intelligence\n(AI) Applications in Chatbots: A Bibliometric Analysis. International Journal of\nSocial Robotics. 2023;15(5):703–716.\n102. Kooli C. Chatbots in education and research: A critical examination of ethical\nimplications and solutions. Sustainability. 2023;15(7):5614.\n103. Ask JA, Facemire M, Hogan A, Conversations H. The state of chatbots.\nForrester com report. 2016;20:1–16.\n104. Coheur L. From Eliza to Siri and beyond. In: Information Processing and\nManagement of Uncertainty in Knowledge-Based Systems: 18th International\nConference, IPMU 2020, Lisbon, Portugal, June 15–19, 2020, Proceedings, Part\nI 18. Springer; 2020. p. 29–41.\n105. IO HN, LEE CBP, LIAN Z. Comments About the Siri chatbot: a Sentiment\nAnalysis of the Postings at a Microblogging Site. Journal of Information\nTechnology Management. 2019;30(4).\n106. Kaplan A, Haenlein M. Siri, Siri, in my hand: Who’s the fairest in the land? On\nthe interpretations, illustrations, and implications of artificial intelligence.\nBusiness horizons. 2019;62(1):15–25.\n107. Lopatovska I, Rink K, Knight I, Raines K, Cosenza K, Williams H, et al. Talk\nto me: Exploring user interactions with the Amazon Alexa. Journal of\nLibrarianship and Information Science. 2019;51(4):984–997.\n108. Chung H, Park J, Lee S. Digital forensic approaches for Amazon Alexa\necosystem. Digital investigation. 2017;22:S15–S25.\n109. Ramadan Z, F Farah M, El Essrawi L. From Amazon. com to Amazon. love:\nHow Alexa is redefining companionship and interdependence for people with\nspecial needs. Psychology & Marketing. 2021;38(4):596–609.\n110. Kepuska V, Bohouta G. Next-generation of virtual personal assistants\n(microsoft cortana, apple siri, amazon alexa and google home). In: 2018 IEEE\n8th annual computing and communication workshop and conference (CCWC).\nIEEE; 2018. p. 99–103.\n111. Yang S, Lee J, Sezgin E, Bridge J, Lin S, et al. Clinical advice by voice\nassistants on postpartum depression: cross-sectional investigation using Apple\nSiri, Amazon Alexa, Google Assistant, and Microsoft Cortana. JMIR mHealth\nand uHealth. 2021;9(1):e24045.\n112. Reis A, Paulino D, Paredes H, Barroso I, Monteiro MJ, Rodrigues V, et al.\nUsing intelligent personal assistants to assist the elderlies An evaluation of\nAmazon Alexa, Google Assistant, Microsoft Cortana, and Apple Siri. In: 2018\n2nd International Conference on Technology and Innovation in Sports, Health\nand Wellbeing (TISHW). IEEE; 2018. p. 1–5.\n113. Bhat HR, Lone TA, Paul ZM. Cortana-intelligent personal digital assistant: A\nreview. International Journal of Advanced Research in Computer Science.\n2017;8(7):55–57.\n114. Akinbi A, Berry T. Forensic investigation of google assistant. SN Computer\nScience. 2020;1(5):272.\n115. L´ opez G, Quesada L, Guerrero LA. Alexa vs. Siri vs. Cortana vs. Google\nAssistant: a comparison of speech-based natural user interfaces. In: Advances in\nSeptember 8, 2023 36/42\nHuman Factors and Systems Interaction: Proceedings of the AHFE 2017\nInternational Conference on Human Factors and Systems Interaction, July 17-\n21, 2017, The Westin Bonaventure Hotel, Los Angeles, California, USA 8.\nSpringer; 2018. p. 241–250.\n116. Tulshan AS, Dhage SN. Survey on virtual assistant: Google assistant, siri,\ncortana, alexa. In: Advances in Signal Processing and Intelligent Recognition\nSystems: 4th International Symposium SIRS 2018, Bangalore, India, September\n19–22, 2018, Revised Selected Papers 4. Springer; 2019. p. 190–201.\n117. Tai TY, Chen HHJ. The impact of Google Assistant on adolescent EFL learners’\nwillingness to communicate. Interactive Learning Environments.\n2023;31(3):1485–1502.\n118. High R. The era of cognitive systems: An inside look at IBM Watson and how it\nworks. IBM Corporation, Redbooks. 2012;1:16.\n119. Strickland E. IBM Watson, heal thyself: How IBM overpromised and\nunderdelivered on AI health care. IEEE Spectrum. 2019;56(4):24–31.\n120. Chen Y, Argentinis JE, Weber G. IBM Watson: how cognitive computing can\nbe applied to big data challenges in life sciences research. Clinical therapeutics.\n2016;38(4):688–701.\n121. Sabharwal N, Agrawal A, Sabharwal N, Agrawal A. Introduction to Google\ndialogflow. Cognitive Virtual Assistants Using Google Dialogflow: Develop\nComplex Cognitive Bots Using the Google Dialogflow Platform. 2020; p. 13–54.\n122. Singh A, Ramasubramanian K, Shivam S, Singh A, Ramasubramanian K,\nShivam S. Introduction to microsoft Bot, RASA, and google dialogflow.\nBuilding an enterprise chatbot: Work with protected enterprise data using open\nsource frameworks. 2019; p. 281–302.\n123. Reyes R, Garza D, Garrido L, De la Cueva V, Ramirez J. Methodology for the\nimplementation of virtual assistants for education using Google dialogflow. In:\nAdvances in Soft Computing: 18th Mexican International Conference on\nArtificial Intelligence, MICAI 2019, Xalapa, Mexico, October 27–November 2,\n2019, Proceedings 18. Springer; 2019. p. 440–451.\n124. Salvi S, Geetha V, Kamath SS. Jamura: a conversational smart home assistant\nbuilt on Telegram and Google Dialogflow. In: TENCON 2019-2019 IEEE\nRegion 10 Conference (TENCON). IEEE; 2019. p. 1564–1571.\n125. Liu Y, Han T, Ma S, Zhang J, Yang Y, Tian J, et al. Summary of chatgpt/gpt-4\nresearch and perspective towards the future of large language models. arXiv\npreprint arXiv:230401852. 2023;.\n126. Cucchiara R. What large language models like GPT can do for finance; 2023.\n127. OpenAI. GPT-4 Technical Report; 2023.\n128. Gong T, Lyu C, Zhang S, Wang Y, Zheng M, Zhao Q, et al. Multimodal-gpt: A\nvision and language model for dialogue with humans. arXiv preprint\narXiv:230504790. 2023;.\n129. Floridi L, Chiriatti M. GPT-3: Its nature, scope, limits, and consequences.\nMinds and Machines. 2020;30:681–694.\n130. Conroy G. Scientists used ChatGPT to generate an entire paper from\nscratch-but is it any good? Nature. 2023;619(7970):443–444.\nSeptember 8, 2023 37/42\n131. Inflection. Press release: Inflection AI Introduces Pi, Your Personal AI —\ninflection.ai; 2023. Available from:https://inflection.ai/press.\n132. Depounti I, Saukko P, Natale S. Ideal technologies, ideal women: AI and gender\nimaginaries in Redditors’ discussions on the Replika bot girlfriend. Media,\nCulture & Society. 2023;45(4):720–736.\n133. Skjuve M, Følstad A, Fostervold KI, Brandtzaeg PB. My chatbot companion-a\nstudy of human-chatbot relationships. International Journal of\nHuman-Computer Studies. 2021;149:102601.\n134. Ta V, Griffith C, Boatfield C, Wang X, Civitello M, Bader H, et al. User\nexperiences of social support from companion chatbots in everyday contexts:\nthematic analysis. Journal of medical Internet research. 2020;22(3):e16235.\n135. Pentina I, Hancock T, Xie T. Exploring relationship development with social\nchatbots: A mixed-method study of replika. Computers in Human Behavior.\n2023;140:107600.\n136. Griffiths M. Is LaMDA sentient? AI & SOCIETY. 2022; p. 1–2.\n137. Le T, Nguyen T, Ho N, Bui H, Phung D. Lamda: Label matching deep domain\nadaptation. In: International Conference on Machine Learning. PMLR; 2021. p.\n6043–6054.\n138. Lemoine B. Is LaMDA Sentient?—an Interview. Medium. 2022;.\n139. Chowdhery A, Narang S, Devlin J, Bosma M, Mishra G, Roberts A, et al. Palm:\nScaling language modeling with pathways. arXiv preprint arXiv:220402311.\n2022;.\n140. Driess D, Xia F, Sajjadi MS, Lynch C, Chowdhery A, Ichter B, et al. Palm-e:\nAn embodied multimodal language model. arXiv preprint arXiv:230303378.\n2023;.\n141. Anil R, Dai AM, Firat O, Johnson M, Lepikhin D, Passos A, et al. Palm 2\ntechnical report. arXiv preprint arXiv:230510403. 2023;.\n142. Campello de Souza B, Serrano de Andrade Neto A, Roazzi A. Are the new ais\nsmart enough to steal your job? iq scores for chatgpt, microsoft bing, google\nbard and quora poe. IQ Scores for ChatGPT, Microsoft Bing, Google Bard and\nQuora Poe (April 7, 2023). 2023;.\n143. Ram B, Pratima Verma PV. Artificial intelligence AI-based Chatbot study of\nChatGPT, Google AI Bard and Baidu AI. World Journal of Advanced\nEngineering Technology and Sciences. 2023;8(01):258–261.\n144. Rahaman MS, Ahsan M, Anjum N, Rahman MM, Rahman MN. The AI race is\non! Google’s Bard and OpenAI’s ChatGPT head to head: an opinion article.\nMizanur and Rahman, Md Nafizur, The AI Race is on. 2023;.\n145. King MR. Can Bard, Google’s Experimental Chatbot Based on the LaMDA\nLarge Language Model, Help to Analyze the Gender and Racial Diversity of\nAuthors in Your Cited Scientific References? Cellular and Molecular\nBioengineering. 2023;16(2):175–179.\n146. Roth E. Google-backed Anthropic launches Claude, an AI chatbot that’s easier\nto talk to; 2023. Available from:https://www.theverge.com/2023/3/14/\n23640056/anthropic-ai-chatbot-claude-google-launch .\nSeptember 8, 2023 38/42\n147. Smutny P, Schreiberova P. Chatbots for learning: A review of educational\nchatbots for the Facebook Messenger. Computers & Education. 2020;151:103862.\n148. Anthropic. Claude 2 — anthropic.com; 2023. Available from:\nhttps://www.anthropic.com/index/claude-2.\n149. Santhanam S, Shaikh S. A survey of natural language generation techniques\nwith a focus on dialogue systems-past, present and future directions. arXiv\npreprint arXiv:190600500. 2019;.\n150. Abdellatif A, Badran K, Costa DE, Shihab E. A Comparison of Natural\nLanguage Understanding Platforms for Chatbots in Software Engineering. IEEE\nTransactions on Software Engineering. 2022;48(8):3087–3102.\ndoi:10.1109/TSE.2021.3078384.\n151. Følstad A, Araujo T, Law ELC, Brandtzaeg PB, Papadopoulos S, Reis L, et al.\nFuture directions for chatbot research: an interdisciplinary research agenda.\nComputing. 2021;103(12):2915–2942.\n152. Essel HB, Vlachopoulos D, Tachie-Menson A, Johnson EE, Baah PK. The\nimpact of a virtual teaching assistant (chatbot) on students’ learning in\nGhanaian higher education. International Journal of Educational Technology in\nHigher Education. 2022;19(1):1–19.\n153. Chen X, Xie H, Hwang GJ. A multi-perspective study on artificial intelligence\nin education: Grants, conferences, journals, software tools, institutions, and\nresearchers. Computers and Education: Artificial Intelligence. 2020;1:100005.\n154. Luckin R, Holmes W, Griffiths M, Forcier LB. Intelligence unleashed: An\nargument for AI in education. Open Research Online. 2016;.\n155. Kumar JA. Educational chatbots for project-based learning: investigating\nlearning outcomes for a team-based design course. International journal of\neducational technology in higher education. 2021;18(1):1–28.\n156. Barrett M, Branson L, Carter S, DeLeon F, Ellis J, Gundlach C, et al. Using\nartificial intelligence to enhance educational opportunities and student services\nin higher education. Inquiry: The Journal of the Virginia Community Colleges.\n2019;22(1):11.\n157. Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, Elepa˜ no C, et al.\nPerformance of ChatGPT on USMLE: Potential for AI-assisted medical\neducation using large language models. PLoS digital health. 2023;2(2):e0000198.\n158. Lin CC, Huang AY, Yang SJ. A review of ai-driven conversational chatbots\nimplementation methodologies and challenges (1999–2022). Sustainability.\n2023;15(5):4012.\n159. Okonkwo CW, Ade-Ibijola A. Chatbots applications in education: A systematic\nreview. Computers and Education: Artificial Intelligence. 2021;2:100033.\n160. V´ azquez-Cano E, Mengual-Andr´ es S, L´ opez-Meneses E. Chatbot to improve\nlearning punctuation in Spanish and to enhance open and flexible learning\nenvironments. International Journal of Educational Technology in Higher\nEducation. 2021;18(1):1–20.\n161. Kuhail MA, Alturki N, Alramlawi S, Alhejori K. Interacting with educational\nchatbots: A systematic review. Education and Information Technologies.\n2023;28(1):973–1018.\nSeptember 8, 2023 39/42\n162. Baskara FR. Chatbots and Flipped Learning: Enhancing Student Engagement\nand Learning Outcomes through Personalised Support and Collaboration.\nIJORER: International Journal of Recent Educational Research.\n2023;4(2):223–238.\n163. Zawacki-Richter O, Mar´ ın VI, Bond M, Gouverneur F. Systematic review of\nresearch on artificial intelligence applications in higher education–where are the\neducators? International Journal of Educational Technology in Higher\nEducation. 2019;16(1):1–27.\n164. Chen L, Chen P, Lin Z. Artificial intelligence in education: A review. Ieee\nAccess. 2020;8:75264–75278.\n165. Cardona MA, Rodr´ ıguez RJ, Ishmael K, et al. Artificial Intelligence and the\nFuture of Teaching and Learning: Insights and Recommendations. US\nDepartment of Education, Office of Educational Technology. 2023;.\n166. Miao F, Holmes W. Artificial Intelligence and Education. Guidance for\nPolicy-makers. United Nations Educational, Scientific and Cultural\nOrganization (UNESCO). 2021;.\n167. Hwang GJ, Chang CY. A review of opportunities and challenges of chatbots in\neducation. Interactive Learning Environments. 2021; p. 1–14.\n168. Huang W, Hew KF, Fryer LK. Chatbots for language learning—Are they really\nuseful? A systematic review of chatbot-supported language learning. Journal of\nComputer Assisted Learning. 2022;38(1):237–257.\n169. Farrokhnia M, Banihashem SK, Noroozi O, Wals A. A SWOT analysis of\nChatGPT: Implications for educational practice and research. Innovations in\nEducation and Teaching International. 2023; p. 1–15.\n170. Hasal M, Nowakov´ a J, Ahmed Saghair K, Abdulla H, Sn´ aˇ sel V, Ogiela L.\nChatbots: Security, privacy, data protection, and social aspects. Concurrency\nand Computation: Practice and Experience. 2021;33(19):e6426.\n171. Faguy A. Google warns employees about chatbots-including its own bard-out of\nprivacy concerns, report says; 2023. Available from:\nhttps://www.forbes.com/sites/anafaguy/2023/06/15/\ngoogle-warns-employees-about-chatbots-including-its-own-bard-out-of-privacy-concerns-report-says/\n?sh=6a9976bfb613.\n172. Sitzmann T, Ely K, Bell BS, Bauer KN. The effects of technical difficulties on\nlearning and attrition during online training. Journal of Experimental\nPsychology: Applied. 2010;16(3):281.\n173. Reynolds L, McDonell K. Prompt programming for large language models:\nBeyond the few-shot paradigm. In: Extended Abstracts of the 2021 CHI\nConference on Human Factors in Computing Systems; 2021. p. 1–7.\n174. Strobelt H, Webson A, Sanh V, Hoover B, Beyer J, Pfister H, et al. Interactive\nand visual prompt engineering for ad-hoc task adaptation with large language\nmodels. IEEE transactions on visualization and computer graphics.\n2022;29(1):1146–1156.\n175. Zhou K, Yang J, Loy CC, Liu Z. Learning to prompt for vision-language models.\nInternational Journal of Computer Vision. 2022;130(9):2337–2348.\nSeptember 8, 2023 40/42\n176. White J, Fu Q, Hays S, Sandborn M, Olea C, Gilbert H, et al. A prompt\npattern catalog to enhance prompt engineering with chatgpt. arXiv preprint\narXiv:230211382. 2023;.\n177. Liu P, Yuan W, Fu J, Jiang Z, Hayashi H, Neubig G. Pre-train, prompt, and\npredict: A systematic survey of prompting methods in natural language\nprocessing. ACM Computing Surveys. 2023;55(9):1–35.\n178. Yang Z, Li L, Wang J, Lin K, Azarnasab E, Ahmed F, et al. Mm-react:\nPrompting chatgpt for multimodal reasoning and action. arXiv preprint\narXiv:230311381. 2023;.\n179. Zhou D, Sch¨ arli N, Hou L, Wei J, Scales N, Wang X, et al. Least-to-most\nprompting enables complex reasoning in large language models. arXiv preprint\narXiv:220510625. 2022;.\n180. Atlas S. ChatGPT for higher education and professional development: A guide\nto conversational AI. Digital Commons. 2023;.\n181. Yao S, Yu D, Zhao J, Shafran I, Griffiths TL, Cao Y, et al. Tree of thoughts:\nDeliberate problem solving with large language models. arXiv preprint\narXiv:230510601. 2023;.\n182. Wei J, Wang X, Schuurmans D, Bosma M, Chi E, Le Q, et al. Chain of thought\nprompting elicits reasoning in large language models. arXiv preprint\narXiv:220111903. 2022;.\n183. Wang X, Wei J, Schuurmans D, Le Q, Chi E, Narang S, et al. Self-consistency\nimproves chain of thought reasoning in language models. arXiv preprint\narXiv:220311171. 2022;.\n184. Wang B, Deng X, Sun H. Iteratively prompt pre-trained language models for\nchain of thought. In: Proceedings of the 2022 Conference on Empirical Methods\nin Natural Language Processing; 2022. p. 2714–2730.\n185. Hulbert D. Tree of Knowledge: ToK aka Tree of Knowledge dataset for Large\nLanguage Models LLM; 2023.\nhttps://github.com/dave1010/tree-of-thought-prompting .\n186. Baidoo-Anu D, Owusu Ansah L. Education in the era of generative artificial\nintelligence (AI): Understanding the potential benefits of ChatGPT in\npromoting teaching and learning. Available at SSRN 4337484. 2023;.\n187. Oblique Shock Waves Table; 2023. Available from:\nhttp://www.aerodynamics4students.com/\ngas-dynamics-and-supersonic-flow/table8.php .\n188. Wang X, Hu Z, Lu P, Zhu Y, Zhang J, Subramaniam S, et al. SciBench:\nEvaluating College-Level Scientific Problem-Solving Abilities of Large Language\nModels. arXiv preprint arXiv:230710635. 2023;.\n189. Han R, Peng T, Yang C, Wang B, Liu L, Wan X. Is Information Extraction\nSolved by ChatGPT? An Analysis of Performance, Evaluation Criteria,\nRobustness and Errors. arXiv preprint arXiv:230514450. 2023;.\n190. Metze K, Morandin-Reis RC, Lorand-Metze I, Florindo JB. The Amount of\nErrors in ChatGPT’s Responses is Indirectly Correlated with the Number of\nPublications Related to the Topic Under Investigation. Annals of Biomedical\nEngineering. 2023; p. 1–2.\nSeptember 8, 2023 41/42\n191. Borji A. A categorical archive of chatgpt failures. arXiv preprint\narXiv:230203494. 2023;.\n192. Chen L, Zaharia M, Zou J. How is ChatGPT’s behavior changing over time?\narXiv preprint arXiv:230709009. 2023;.\n193. Paul A. CHATGPT’s accuracy has gotten worse, study shows; 2023. Available\nfrom: https://www.popsci.com/technology/chatgpt-human-inaccurate/.\n194. Cassidy C. Australian universities to return to ‘pen and paper’exams after\nstudents caught using AI to write essays. The Guardian. 2023;10.\n195. Rudolph J, Tan S, Tan S. ChatGPT: Bullshit spewer or the end of traditional\nassessments in higher education? Journal of Applied Learning and Teaching.\n2023;6(1).\n196. Lim V. ChatGPT raises uncomfortable questions about teaching and classroom\nlearning. The Straits Times. 2022; p. B3.\n197. Abdulquadri A, Mogaji E, Kieu TA, Nguyen NP. Digital transformation in\nfinancial services provision: A Nigerian perspective to the adoption of chatbot.\nJournal of Enterprising Communities: People and Places in the Global Economy.\n2021;15(2):258–281.\n198. Pillai R, Sivathanu B. Adoption of AI-based chatbots for hospitality and\ntourism. International Journal of Contemporary Hospitality Management.\n2020;32(10):3199–3226.\n199. Lewandowski T, Delling J, Grotherr C, B¨ ohmann T. State-of-the-Art Analysis\nof Adopting AI-based Conversational Agents in Organizations: A Systematic\nLiterature Review. PACIS. 2021; p. 167.\nSeptember 8, 2023 42/42",
  "topic": "Chatbot",
  "concepts": [
    {
      "name": "Chatbot",
      "score": 0.8219817280769348
    },
    {
      "name": "Computer science",
      "score": 0.5854238271713257
    },
    {
      "name": "Context (archaeology)",
      "score": 0.4100393056869507
    },
    {
      "name": "Engineering ethics",
      "score": 0.3848266005516052
    },
    {
      "name": "World Wide Web",
      "score": 0.2455313503742218
    },
    {
      "name": "Engineering",
      "score": 0.24510109424591064
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I87216513",
      "name": "Michigan State University",
      "country": "US"
    }
  ]
}