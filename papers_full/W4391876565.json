{
    "title": "Red Teaming Language Model Detectors with Language Models",
    "url": "https://openalex.org/W4391876565",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2996502104",
            "name": "Zhouxing Shi",
            "affiliations": [
                "University of California, Los Angeles"
            ]
        },
        {
            "id": "https://openalex.org/A2136156804",
            "name": "Yihan Wang",
            "affiliations": [
                "University of California, Los Angeles"
            ]
        },
        {
            "id": "https://openalex.org/A2100642826",
            "name": "Fan Yin",
            "affiliations": [
                "University of California, Los Angeles"
            ]
        },
        {
            "id": "https://openalex.org/A2108776058",
            "name": "Xiangning Chen",
            "affiliations": [
                "University of California, Los Angeles"
            ]
        },
        {
            "id": "https://openalex.org/A2208999240",
            "name": "Kai-Wei Chang",
            "affiliations": [
                "University of California, Los Angeles"
            ]
        },
        {
            "id": "https://openalex.org/A4213488976",
            "name": "Cho-Jui Hsieh",
            "affiliations": [
                "University of California, Los Angeles"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2962718684",
        "https://openalex.org/W4385573699",
        "https://openalex.org/W2917779306",
        "https://openalex.org/W4285225959",
        "https://openalex.org/W6787335730",
        "https://openalex.org/W6851601001",
        "https://openalex.org/W6810081322",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2950681488",
        "https://openalex.org/W3104423855",
        "https://openalex.org/W6801783160",
        "https://openalex.org/W6757615711",
        "https://openalex.org/W6761551260",
        "https://openalex.org/W2963126845",
        "https://openalex.org/W6851071894",
        "https://openalex.org/W2996851481",
        "https://openalex.org/W6848955896",
        "https://openalex.org/W6850824531",
        "https://openalex.org/W3101449015",
        "https://openalex.org/W3155332104",
        "https://openalex.org/W6776811381",
        "https://openalex.org/W4318351452",
        "https://openalex.org/W2888482885",
        "https://openalex.org/W4385894687",
        "https://openalex.org/W6769627184",
        "https://openalex.org/W2949128310",
        "https://openalex.org/W2799007037",
        "https://openalex.org/W6851663954",
        "https://openalex.org/W3103491646",
        "https://openalex.org/W6767101625",
        "https://openalex.org/W6850625674",
        "https://openalex.org/W2982756474",
        "https://openalex.org/W3099729825",
        "https://openalex.org/W3170572542",
        "https://openalex.org/W3035183289",
        "https://openalex.org/W6763240421",
        "https://openalex.org/W6849393593",
        "https://openalex.org/W3173343821",
        "https://openalex.org/W6846556436",
        "https://openalex.org/W4224308101",
        "https://openalex.org/W1583837637",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W3203534993",
        "https://openalex.org/W4299567010",
        "https://openalex.org/W4353007481",
        "https://openalex.org/W4364387756",
        "https://openalex.org/W4322718191",
        "https://openalex.org/W4323650348",
        "https://openalex.org/W2969958763",
        "https://openalex.org/W4360891421"
    ],
    "abstract": "Abstract The prevalence and strong capability of large language models (LLMs) present significant safety and ethical risks if exploited by malicious users. To prevent the potentially deceptive usage of LLMs, recent work has proposed algorithms to detect LLM-generated text and protect LLMs. In this paper, we investigate the robustness and reliability of these LLM detectors under adversarial attacks. We study two types of attack strategies: 1) replacing certain words in an LLMâ€™s output with their synonyms given the context; 2) automatically searching for an instructional prompt to alter the writing style of the generation. In both strategies, we leverage an auxiliary LLM to generate the word replacements or the instructional prompt. Different from previous works, we consider a challenging setting where the auxiliary LLM can also be protected by a detector. Experiments reveal that our attacks effectively compromise the performance of all detectors in the study with plausible generations, underscoring the urgent need to improve the robustness of LLM-generated text detection systems. Code is available at https://github.com/shizhouxing/LLM-Detector-Robustness.",
    "full_text": null
}