{
  "title": "Observe, Ask, Intervene: Designing AI Agents for More Inclusive Meetings",
  "url": "https://openalex.org/W4406692394",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5024314064",
      "name": "Mo Houtti",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A5009414108",
      "name": "Moyan Zhou",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A5058856783",
      "name": "Loren Terveen",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A5046479021",
      "name": "Stevie Chancellor",
      "affiliations": [
        "University of Minnesota"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4220844519",
    "https://openalex.org/W1969569185",
    "https://openalex.org/W2916904544",
    "https://openalex.org/W2076205377",
    "https://openalex.org/W2063597719",
    "https://openalex.org/W3130610582",
    "https://openalex.org/W2017748193",
    "https://openalex.org/W2158544074",
    "https://openalex.org/W1977519940",
    "https://openalex.org/W3019615756",
    "https://openalex.org/W2277431815",
    "https://openalex.org/W2011100419",
    "https://openalex.org/W2125439844",
    "https://openalex.org/W4400781109",
    "https://openalex.org/W4386012970",
    "https://openalex.org/W2144969491",
    "https://openalex.org/W2786763812",
    "https://openalex.org/W2622468367",
    "https://openalex.org/W1994750264",
    "https://openalex.org/W3130426944",
    "https://openalex.org/W2092795326",
    "https://openalex.org/W2133626900",
    "https://openalex.org/W1586509775",
    "https://openalex.org/W1982709543",
    "https://openalex.org/W2170383941",
    "https://openalex.org/W1988611129",
    "https://openalex.org/W2005219594",
    "https://openalex.org/W2623779865",
    "https://openalex.org/W3201195645",
    "https://openalex.org/W2330277600",
    "https://openalex.org/W2055406076",
    "https://openalex.org/W4289637608",
    "https://openalex.org/W2133535394",
    "https://openalex.org/W4318718195",
    "https://openalex.org/W4225113883",
    "https://openalex.org/W4319878704",
    "https://openalex.org/W2921959179",
    "https://openalex.org/W2885379826",
    "https://openalex.org/W4225001143",
    "https://openalex.org/W2808264290",
    "https://openalex.org/W4224105048",
    "https://openalex.org/W2078512233",
    "https://openalex.org/W4224940987",
    "https://openalex.org/W4225102718",
    "https://openalex.org/W2746377532",
    "https://openalex.org/W3159940288",
    "https://openalex.org/W2413523787",
    "https://openalex.org/W2093562055",
    "https://openalex.org/W2099386544",
    "https://openalex.org/W2065772465",
    "https://openalex.org/W2885050103",
    "https://openalex.org/W4292289324",
    "https://openalex.org/W3126860501",
    "https://openalex.org/W2156897926",
    "https://openalex.org/W2131801294",
    "https://openalex.org/W2911311425",
    "https://openalex.org/W2063419487",
    "https://openalex.org/W3128611391",
    "https://openalex.org/W1970906454",
    "https://openalex.org/W3090234790",
    "https://openalex.org/W2748823229",
    "https://openalex.org/W2811058660",
    "https://openalex.org/W2793354676",
    "https://openalex.org/W2140182371",
    "https://openalex.org/W2998862821",
    "https://openalex.org/W3040894905",
    "https://openalex.org/W2769305543",
    "https://openalex.org/W2886664698",
    "https://openalex.org/W3155290920",
    "https://openalex.org/W3192495122",
    "https://openalex.org/W2766005220",
    "https://openalex.org/W3105435131",
    "https://openalex.org/W592490675",
    "https://openalex.org/W2798473720",
    "https://openalex.org/W3159799903",
    "https://openalex.org/W3163667512"
  ],
  "abstract": "Video conferencing meetings are more effective when they are inclusive, but inclusion often hinges on meeting leaders' and/or co-facilitators' practices. AI systems can be designed to improve meeting inclusion at scale by moderating negative meeting behaviors and supporting meeting leaders. We explored this design space by conducting $9$ user-centered ideation sessions, instantiating design insights in a prototype ``virtual co-host'' system, and testing the system in a formative exploratory lab study ($n=68$ across $12$ groups, $18$ interviews). We found that ideation session participants wanted AI agents to ask questions before intervening, which we formalized as the ``Observe, Ask, Intervene'' (OAI) framework. Participants who used our prototype preferred OAI over fully autonomous intervention, but rationalized away the virtual co-host's critical feedback. From these findings, we derive guidelines for designing AI agents to influence behavior and mediate group work. We also contribute methodological and design guidelines specific to mitigating inequitable meeting participation.",
  "full_text": "Observe, Ask, Intervene: Designing AI Agents for More Inclusive Meetings\nMO HOUTTI, Department of Computer Science & Engineering, University of Minnesota, USA\nMOYAN ZHOU,Department of Computer Science & Engineering, University of Minnesota, USA\nLOREN TERVEEN, Department of Computer Science & Engineering, University of Minnesota, USA\nSTEVIE CHANCELLOR, Department of Computer Science & Engineering, University of Minnesota, USA\nVideo conferencing meetings are more effective when they are inclusive, but inclusion often hinges on meeting leaders‚Äô and/or\nco-facilitators‚Äô practices. AI systems can be designed to improve meeting inclusion at scale by moderating negative meeting behaviors\nand supporting meeting leaders. We explored this design space by conducting 9 user-centered ideation sessions, instantiating design\ninsights in a prototype ‚Äúvirtual co-host‚Äù system, and testing the system in a formative exploratory lab study ( ùëõ = 68 across 12\ngroups, 18 interviews). We found that ideation session participants wanted AI agents to ask questions before intervening, which\nwe formalized as the ‚ÄúObserve, Ask, Intervene‚Äù (OAI) framework. Participants who used our prototype preferred OAI over fully\nautonomous intervention, but rationalized away the virtual co-host‚Äôs critical feedback. From these findings, we derive guidelines for\ndesigning AI agents to influence behavior and mediate group work. We also contribute methodological and design guidelines specific\nto mitigating inequitable meeting participation.\nCCS Concepts: ‚Ä¢ Human-centered computing ‚ÜíEmpirical studies in HCI ; Computer supported cooperative work .\nAdditional Key Words and Phrases: Video Conferencing, Group Work, Meetings, Inclusion, AI\nACM Reference Format:\nMo Houtti, Moyan Zhou, Loren Terveen, and Stevie Chancellor. 2025. Observe, Ask, Intervene: Designing AI Agents for More Inclusive\nMeetings. In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI ‚Äô25), April 26 - May 1, 2025, Yokohama,\nJapan. ACM, New York, NY, USA, 29 pages. https://doi.org/10.1145/3706598.3713838\n1 INTRODUCTION\nVideo conferencing (VC) platform adoption has exploded in recent years [46, 84]. Today, platforms like Zoom support\nlarge and ever-increasing amounts of group work across schools [82], workplaces [18], and government agencies [1].\nThis shift to VC-mediated group work has renewed interest in HCI to innovate in and improve virtual meetings\n(e.g., [23, 42, 64, 71]).\nAn important yet challenging dimension for improving meetings is making them inclusive‚Äîenabling all attendees to\nparticipate to the extent they desire. Inclusion in organizations is important for many reasons‚Äîit improves satisfac-\ntion [17], performance [20], and creativity [56]. However, making meetings inclusive is hard work for meeting leaders\nand participants, so they often turn to co-facilitators for assistance [42]. This is a good solution, consistent with prior\nwork finding that facilitators enhance meeting outcomes [4, 7, 11]. But facilitation also is hard work and many teams\ndo not have the requisite training or funding to hire a facilitator [38].\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components\nof this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to\nredistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n¬© 2025 Association for Computing Machinery.\nManuscript submitted to ACM\n1\narXiv:2501.10553v1  [cs.HC]  17 Jan 2025\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\nWe know from decades of research on group work that technology mediates our ability to do work well [67]‚Äîand we\nargue that technology mediates some of the challenges of making VC meetings more inclusive. The benefits of inclusion\ntranslate to the VC meeting context [23], but making VC meetings inclusive is challenging because of sociotechnical\nbarriers [42]. Recently, Houtti et al. [42] found that the burden of facilitation falls on VC meeting leaders, who are often\nill-equipped to run meetings equitably and do not have technical affordances to let them delegate their responsibilities.\nTaken together, we see a gap in the technology design of VC meetings, the pragmatic way they are managed, and the\npotential of technology to serve as a facilitator to make meetings more inclusive. This suggests a role for systems to act\nas a facilitator for inclusion to overcome issues of scalability and burden on attendees.\nTo explore this design space, we adopted the metaphor of a ‚Äúvirtual co-host‚Äù to facilitate more inclusive meetings,\nbuilding on aforementioned work showing that better facilitation can improve meeting inclusion [ 42] and other\noutcomes [4, 7, 11]. We synthesize these insights in the VC space with ongoing work that uses AI as a tool for assisting\nin meetings [71] and as an agent for delegation. Using this metaphor as a starting point, we conducted ideation sessions\nto solicit feature ideas for an agent that could engage with meeting participants. Participants designed co-hosts to\nseek explicit feedback from meeting participants before deciding to intervene on their behalf. We formalized this as an\nAI framework called ‚ÄúObserve, Ask, Intervene‚Äù (OAI). Participants also designed co-hosts to give negative feedback\nprivately, revealing an exciting opportunity for AI systems‚Äîto mitigate the social discomfort that occurs when humans\ncommunicate negative feedback to each other [2, 16, 31, 39, 48, 83].\nWe tested these insights by prototyping a rule-based AI virtual co-host and conducting a formative evaluation through\nan exploratory lab study. The lab study included 68 participants across 12 groups of size 4-7. All groups completed a\nstructured task through the same VC platform, with our virtual co-host present in 7 of the 12 groups. We collected\nin-depth qualitative feedback by interviewing 18 participants who interacted with the co-host, and quantitatively\nanalyzed post-study questionnaires on meeting quality. We found that asking questions prior to interventions gave\nparticipants feelings of agency, was preferred over fully autonomous intervention, and was minimally distracting,\nbut that hosts and over-participators rationalized away the virtual co-host‚Äôs critical feedback. Despite the feedback‚Äôs\nineffectiveness, we also found that subjective assessments of meeting quality were better with the virtual co-host\npresent.\nOur findings inform the design of AI systems that seek to influence human behavior and/or mediate synchronous\ngroup work. We contribute:\n‚Ä¢details and operationalization of the ‚ÄúObserve, Ask, Intervene‚Äù (OAI) framework. By enlisting user judgment,\nOAI lets AI systems intervene without concerns about inaccuracy seen in prior work [71]. We show that OAI\nimproves user agency, discuss how it follows from broader principles in human-AI interaction, and provide\ndetailed design recommendations for OAI-based systems.\n‚Ä¢evidence of a key limitation and benefit of AIs as social actors [65]: they exert little normative pressure. Based on\nthis we discuss implications for designingeffective interventions, providing examples of how our system‚Äôs chosen\ninterventions could be altered to have the desired effects. We further highlight opportunities for leveraging AI to\npromote otherwise difficult feedback exchange in group contexts.\n‚Ä¢methodological and design guidelines for future work on using AI systems to make meetings more inclusive. For\nexample, we highlight key shortcomings of user-centered methods when designing such systems.\n2\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\nWe present our work in two parts. We first focus on the ideation sessions and the prototype that emerged from them.\nWe then cover our exploratory evaluation of the virtual co-host, including follow-up interviews with participants. We\nconclude by discussing implications for designing AI systems in and beyond the virtual meeting context.\n2 RELATED WORK\nIn this section, we outline the current state of sociotechnical solutions for VC meetings, other work informing the\ndesign of AI agents, and prior research on human-AI interaction.\n2.1 Sociotechnical Solutions for VC Meetings\nVideo conferencing (VC) is understood to be limited in key ways compared to in-person interaction. For example, VC\nlimits nonverbal communication [10, 40, 42, 87], which can reduce social cohesion [15] and meeting satisfaction [40],\nand increase psychological fatigue [9].\nScholars and practitioners in and beyond CHI have explored social and sociotechnical solutions to many of VC‚Äôs\nproblems, often taking translucence-based [ 30] approaches that make social information more visible to meeting\nattendees. In a series of experiments, Hills et al. [40], found that training students to employ ‚Äúvideo meeting signals‚Äù‚Äî\na simple set of gestures used to communicate common feelings‚Äîincreased meeting satisfaction. In an empirical\nstudy, Nguyen and Canny [66] found that non-traditional VC setups that preserve the ability for spatial referencing\nimproved the formation of intragroup trust. Langner et al. [54] found that employing a joint attention eye-tracking\nsystem improved meeting participants‚Äô focus. Other solutions have leveraged AI. Murali et al . [64] implemented\nAffectiveSpotlight, which overcomes the difficulty of gauging audience mood by identifying and spotlighting the most\nexpressive person in the meeting at intervals. Samrose et al. ‚Äôs MeetingCoach [71] uses AI to detect various behavioral\ncues in meetings, and consolidates them into a post-meeting dashboard that was shown to improve understanding of\nmeeting dynamics. Many commercial systems (e.g., [5, 32, 70]) use AI to perform difficult and helpful administrative\ntasks such as transcription, note-taking, topic tracking, and/or summarization.\nPrior research suggests that, while useful, translucence-based approaches are inherently limited. For example,\n‚Äúnudging‚Äù‚Äîinfluencing humans‚Äô behavior by altering how information is presented‚Äîhas been shown to encourage\nprosocial behavior in a range of contexts [ 60, 75, 85], but Hummel and Maedche [45] find in a quantitative review\nthat nudges have small effect sizes. Informational approaches rely on meeting attendees to decide appropriate actions\nbased on the information presented, but they do not attend to strong non-informational (often social) incentives that\ncan influence behavior in counter-productive directions‚Äîe.g., structural inertia [36], peer pressure [22], or cognitive\ndissonance [37]. AI agent-based approaches could overcome these limitations by taking a more active role in meetings,\nbut existing work on designing AI agents for behavior change has mostly been limited to single-user contexts‚Äîe.g.,\nencouraging regular breaks [69] and self-reflection [50]. We extend this work by exploring unique challenges (e.g.,\nmanaging peer social pressure) that arise when designing AI agents to mediate synchronous group work.\nWe specifically explore how AI agent-based systems could address a common VC problem surfaced by Houtti et al.\n[42], who found in an interview study that VC meetings rely too much on meeting leaders to make meetings more\ninclusive. They suggest two mechanisms for mitigating this issue in VC meetings: ‚Äútransferring control from meeting\nleaders to technical systems or other attendees and helping meeting leaders better exercise the control they do wield. ‚Äù We used\nthe virtual co-host metaphor to explore the design space of the former recommendation, by mirroring the social role of\na person to whom meeting leaders often transfer control [4, 7, 42]. Our virtual co-host assumes joint responsibility over\n3\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\nmeeting inclusion by reminding hosts to facilitate more inclusively when needed, giving them information to help\nthem do so, and giving other meeting participants direction on how to be more inclusive.\n2.2 Designing Automated Agents\nExtensive research has explored the design and use of automated (AI and non-AI) agents for various purposes. Liao\net al. [57] prototyped a personal assistant to help employees find work-related information and evaluated it in a\nfield study. They found, among other things, that interrupting users with proactive interaction is risky, especially\nfor those with busy work schedules. Kocielnik et al . [50] explored the use of a conversational agent for workplace\nself-reflection, highlighting user preferences and trade-offs between voice- and chat-based interaction. Fitzpatrick et al.\n[33] employed a conversational agent to administer cognitive behavioral therapy and found that it reduced feelings of\ndepression. Schroeder et al. [76] did the same for dialectical behavioral therapy with positive results. D‚ÄôMello et al. [28]\ndemonstrated that a conversational AI could tutor students.\nOther work has shown how automated agents can influence behavior, delineating both their capabilities and\nlimitations. Vollmer et al. [86], for example, found that humanoid robots‚Äô answers to a question did not affect how\nadult humans answered, though other humans‚Äô answers did. This suggests that, unlike humans, automated agents\ncannot exercise subtle peer pressure. Conversely, Bickmore et al . [12] found that a conversational agent was more\neffective than a pedometer in encouraging people to walk more, demonstrating the ability of automated agents to\nchange behavior more effectively than passive informational approaches. Like Bickmore et al., we explore the use of\na proactive automated agent to change behavior, this time in the group work context of meetings. Virtual meeting\ninclusion often falls on meeting hosts [42], so we use the ‚Äúco-host‚Äù metaphor to solicit designs for an automated agent\nthat assumes some of this responsibility.\n2.3 Human-AI Interaction\nAI systems are commonly implemented to be responsive to user interaction. For example, the popular ‚Äúhuman-in-the-\nloop‚Äù paradigm involves users to iteratively improve algorithmic decision-making. Interaction can take many forms:\ncontrolling the learning process [63], providing training data [88], annotating and labeling raw data [62], fact-checking\nagainst misinformation [26], and much more [35, 89].\nAs the number of user-facing AI applications has increased, a growing body of work has looked to inform how we\nshould design human-AI interaction at the interface level. Amershi et al. [6], for example, propose 18 general design\nguidelines for human-facing AI technologies. Among them is ‚ÄúEnabl[ing] the user to provide feedback indicating their\npreferences during regular interaction with the AI system. ‚Äù Schmidt [73] similarly focuses on the importance of control in\nhuman-AI interaction, arguing that ‚Äúbeing able to determine what should happen is strongly related to self-determination\nand freedom of choice, and is ultimately a basis for feeling safe. ‚Äù Schmidt and Herrmann [74] propose ‚Äúintervention user\ninterfaces‚Äù allowing humans to intervene in AI processes with immediate effect. Lai et al . [53] propose a paradigm\nwhere users circumscribe ‚Äútrustworthy regions‚Äù of action that can be conditionally delegated to AI systems.\nOur work builds on this. Prior work and our ideation sessions led us to test a system that defers to user judgment\nwhen deciding how and whether to intervene. Therefore, our exploratory evaluation of the system let us test claims\nmade by Schmidt and Herrmann and others about the importance of agency in designing interactive AI systems.\n4\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\nID Gender Race and Ethnicity Age Job Level\nD1 Male Asian 40-44 First-level management\nD2 Female White (non-Hispanic) 20-24 Intermediate level\nD3 Male Asian 20-24 Entry level\nD4 Female Asian (Korean) 25-29 First-level management\nD5 Male Asian 20-24 Entry level\nD6 Female White 25-29 Intermediate level\nD7 Male Asian (Indian) 25-29 Intermediate level\nD8 Female Korean-American 25-29 Entry level\nD9 Male Asian 25-29 Intermediate level\nTable 1. Ideation session participants‚Äô basic demographic information. All questions (except job level) were free response.\n3 PART 1: USER-CENTERED IDEATION\nRecall that our work is split into two parts: user-centered ideation sessions and an exploratory lab study. We begin with\nthe former, outlining the methods, findings, and the system they led us to prototype.\n3.1 Ideation Session Methods\nWe conducted 9 ideation sessions over Zoom (Figure 1) with a semi-structured design activity. (Basic demographic\ninformation is reported in Table 1). Participants had all engaged in group work via VC platforms through their\nemployment or other means. We received approval for our study from our institution‚Äôs IRB. All participants were\ninvited to participate by a research team member through email, either because they were direct personal connections\nor because they had participated in a previous study in our lab and had consented to be contacted for follow-up research\nstudies. Participants were compensated with $20 Amazon gift cards.\nThe ideation sessions let us explore design possibilities and needs in detail. Recall that in the prior work (e.g., [4, 7, 42],\nsee Related Work for more), better facilitation improves meeting outcomes. Therefore, we began each session by\npresenting the virtual co-host metaphor, explaining that its goal was to reduce inequitable barriers to participation. To\ndo this, it could behave like any other (human) participant in the meeting‚Äîi.e., it could interact with other attendees\nFig. 1. Summary of ideation session methods, analysis objects, and outputs.\n5\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\nthrough text, audio, or any of the platform‚Äôs other affordances like screen-sharing, but could not modify the platform‚Äôs\nUI. We set these constraints to ensure participants focused their ideation on the agent rather than improvements to\nvideo conferencing platform UIs, in accordance with our research goals as informed by prior work. The rest of the\nsession was then split into two parts:\n‚Ä¢Design activity: We asked each participant to design a virtual co-host that could intervene to mitigate inequitable\nbarriers to participation in their workplace meetings. We asked each participant contextual questions to keep them\nmoving towards a final design (e.g., ‚Äúwhich of the two approaches you proposed do you think is more compelling?‚Äù )\nor to clarify the reasoning behind design decisions (e.g., ‚Äúhow do you see this feature reducing inequity?‚Äù or ‚Äúwhy\nshould the co-host send this information privately instead of publicly?‚Äù ). (‚àº30 min)\n‚Ä¢Presentation: We gave participants time to sketch their final idea on a Google Jamboard. They then presented\ntheir idea to us, and we asked follow-up questions as needed to understand the motivations behind specific\ndesign decisions. (‚àº15 min)\nTwo of the authors conducted the ideation sessions. Sessions were recorded and transcribed for future reference.\nWe adopted a collaborative design thinking [61] approach to analyze artifacts and develop a final design. From the\nJamboard artifacts, the two authors identified key design insights, described in the following subsection. Building\ndirectly on features designed by participants, they collaboratively brainstormed how to design feasible iterations that\nwould instantiate the key design insights, could plausibly alter meeting behavior, would be measurable in simulated\nlab study meetings, and could give us useful information about designing AI agents for improving meeting inclusion.\nThese considerations were balanced by synthesizing participant ideas, design insights, and insights from prior research.\n3.2 Ideation Session Findings\nFrom our ideation sessions, we gleaned several insights about when and how a virtual co-host should intervene in\nmeetings. We outline these design insights next and, where relevant, we highlight how prior work shaped our thinking\non them.\n3.2.1 When? After asking for explicit user input. There was a ubiquitous preference for interactive over fully autonomous\nAI. Users‚Äô co-host ideas demonstrated a desire to retain some human control over the co-host‚Äôs behavior. For example,\nD6 designed a co-host to ask people ‚Äúwhat is the purpose of this meeting?‚Äù before deciding whether to intervene on\ntheir behalf. D7 designed a co-host to provide nudges based on behaviors the user says they want help with. Other\nexamples include transcribing meeting content when asked (D1), pinging the host when asked (D9), delivering questions\nanonymously when asked (D4), and nudging the current speaker when someone indicates they would like to speak (D3,\nD5).\nInteractivity could plausibly reduce mistrust in the system‚Äôs inferences. Participants in Samrose et al . [71] were\nskeptical about AI‚Äôs ability to accurately assess their internal states based on external cues: ( ‚ÄúI don‚Äôt feel that AI is\ngood enough at sentiment. ‚Äù ‚ÄúI have some doubts on whether this can be done accurately, given how subjective some of this\ninformation would be. ‚Äù [71]) Deferring to humans has been used as a solution in other, high-stakes domains where users\nare worried about AI system accuracy [14, 49, 81]. Making our co-host rely on user input would let us test whether\nsimilar solutions can improve trust in AI systems for VC meetings.\nThe co-host should be proactive in soliciting user input. D6 designed a co-host that followed what they called the\n‚Äútrigger, message, call to action‚Äù cycle, as shown in Figure 2‚Äîa process where the virtual co-host is triggered into\naction by automated inferences, messages affected attendees to verify its inferences, then provides a targeted call to\n6\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\naction based on feedback. Prior work suggests many VC features are underused because meeting participants must\nknow of them and seek them out [42]. We reasoned that the onus should not be on users to always prompt the virtual\nco-host‚Äôs actions or it would be an underused feature. We therefore adopted D6‚Äôs approach, and renamed it ‚ÄúObserve,\nAsk, Intervene‚Äù (OAI).\n3.2.2 How? Non-intrusively and gently. Ideation participants imagined lightweight, non-intrusive, and friendly in-\nterventions. D6, for example, proposed a feature that communicates whether anyone is struggling with the meeting\ncontent (Figure 2). D7 proposed a virtual co-host that alerts the host when they move to a new topic without letting\nothers chime in. D8 noted that feedback messages should be ‚Äúsomething friendly‚Äù . D2 and D6 suggested speaking time\nas a useful baseline metric for understanding whether everyone can participate, and noted that visualizations could\nmake feedback easier to digest.\n3.2.3 How? Privately. Implicit in participants‚Äô preferences for ‚Äúfriendly‚Äù interventions was a desire to avoid creating\nsocial discomfort. This manifested more explicitly when they articulated why the co-host should intervene privately.\nWhen asked to whom speaking time visualizations should be displayed, D6 said:\n‚ÄúIt‚Äôs better just to have it for the facilitator, or maybe just for the person who‚Äôs speaking too much... I wouldn‚Äôt\nshare it with the whole group, I would just share it with the people whose behavior you‚Äôre trying to change,\nwhich in this case sounds like those who are speaking too much. ‚Äù\nShe predicted that public interventions would make over-participators ‚Äúanxious, and counting the seconds as they‚Äôre\nspeaking‚Äù and wanted to avoid creating discomfort. D3, who designed a co-host to deliver text-based nudges to the\ncurrent speaker, also indicated that feedback should be targeted at the person whose behavior we are trying to change.\nD2 expressed that public interventions might even make under-participators uncomfortable by highlighting that ‚Äúthis\nperson hasn‚Äôt spoken for a little while. ‚Äù\nFig. 2. Partial screenshot of a participant‚Äôs Jamboard, explaining their preferred virtual co-host features. Sticky notes 3-5 describe the\n‚Äútrigger, message, call to action‚Äù cycle, which we adapted to ‚ÄúObserve, Ask, Intervene‚Äù.\n7\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\nThis was valuable given that receiving negative feedback fromhuman peers is a frequent source of social discomfort [2,\n16, 31, 39, 48, 83] even when the feedback is given privately.Combining prior work with our participants‚Äô requests\nrevealed an exciting opportunity: to deliver critical feedback without social discomfort by having an AI\nagent deliver feedback instead of a human. Prior work has shown that publicly shared speaking time visualizations\nduring meetings lead over-participators to speak less [27]. Supplementing visualizations with private feedback and\nsuggestions from an automated agent‚Äîas opposed to displaying impersonal labeled visualizations to the group‚Äîcould\nmake their already demonstrated effects stronger and more effective, while letting us retain the social comfort of private\ninterventions that participants valued.\n4 PART 2: VIRTUAL CO-HOST IMPLEMENTATION AND EXPLORATORY LAB STUDY\nWe extracted two major design insights from the ideation sessions. A virtual co-host should (1) proactively solicit\nfeedback from select meeting participants to inform its interventions and (2) intervene with non-intrusive, gentle,\nprivate feedback. Participants suggested concrete ways in which these insights could be instantiated in a system.\nGuided by their suggestions, we implemented a prototype rule-based virtual co-host system and evaluated it in an\nexploratory lab study. To satisfy the first design insight, we organized the virtual co-host‚Äôs design around the ‚ÄúObserve,\nAsk, Intervene‚Äù (OAI) framework adapted from D6‚Äôs ‚Äútrigger, message, call-to-action‚Äù idea. To satisfy the second design\ninsight, we selected interventions for the ‚ÄúIntervene‚Äù phase that were non-intrusive, gentle, and private.\nOur evaluation focused on whether key premises justifying our design insights would be borne out empirically at\neach stage of the virtual co-host‚Äôs behavior in OAI. Specifically, we sought to determine whether each phase of OAI\nwould be acceptable to users and effective at helping the system achieve its functional purpose. (We only considered\nacceptability for ‚ÄúObserve‚Äù given that AI inference‚Äôs effectiveness is already well studied [64, 71].)\nThe first design insight‚Äôs feasibility relied on user reactions in the ‚ÄúObserve‚Äù and ‚ÄúAsk‚Äù phases. To proactively solicit\nfeedback, we must be able to observe for signals of a non-inclusive meeting, and react to those signals by asking\nquestions mid-meeting. Users should provide honest information in response. The second design insight‚Äôs feasibility\nrelied on user reactions in the ‚ÄúIntervene‚Äù phase. To be worthwhile, private and gentle interventions should lead to\nchanges in behavior that improve the meeting. Each stage in this process must independently be acceptable to users as\nwell, if not preferable. In Figure 3, we provide a complete summary of OAI, key premises about each phase we sought\nto elucidate, and their relation to our two major design insights.\nOur design insights encompass an expansive design space‚Äîe.g., we could think of many plausible interventions that\nwould be non-intrusive, gentle, and private. We therefore opted for a primarily qualitative exploration, supplemented by\ndescriptive quantitative data. This let us go beyond simply understanding the effects of our particular implementation.\nKnowing both if and why key premises underlying OAI are (not) correct would let us develop a rich understanding of\nthe overall design space, which is preferable for this kind of formative study.\nOur implementation instantiated design insights only as needed to adequately evaluate them. Similar to a ‚ÄúWizard of\nOz‚Äù experiment [24], we selectively withheld information about how the system really works to understand how users\nmight react to a robust version of the system. We note these decisions throughout the system description, which is\norganized around OAI‚Äôs three phases.\n4.1 Virtual Co-host Implementation\n4.1.1 Observe.\nThe virtual co-host begins each meeting by introducing itself and letting everyone know who the host is. It tells users it\n8\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\nFig. 3. The ‚ÄúObserve, Ask, Intervene‚Äù (OAI) framework around which we designed our system, and the corresponding key premises\nabout users we sought to test in each phase of the framework. These premises bear on the feasibility of our two major design insights:\nproactively soliciting feedback and intervening gently/privately.\nwill be ‚Äúobserving conversational dynamics‚Äù and may reach out later in the meeting (Figure 4). To inform its Ask and\nIntervene phases, the virtual co-host observes and records each participant‚Äôs cumulative speaking time at 1-second\nintervals. While the virtual co-host only observes speaking times, we chose to not have it tell meeting participants what\ninformation it collected. We left the phrase ‚Äúobserve conversational dynamics‚Äù vague because we wanted to understand\nwhether participants would feel a ‚Äúwatching-eye‚Äù effect [44] when being observed by the co-host if they did not know\nwhat info it was collecting (e.g., tone, sentiment, interruption patterns, etc.), and whether adding the Ask phase would\nmitigate or exacerbate those concerns.\nFor the purposes of our study, we used over-inclusive rule-based triggers for the Ask phase. We were most interested\nin the efficacy of the Ask and Intervene phases and did not want the Observe phase to act as a bottleneck. The goal\nwas to ensure the virtual co-host would wait for some minimal level of inequality to manifest but always proceed to\nthe Ask phase even if no substantial inequality was detected. Future iterations could use more advanced AI to select\neffective Observe rules; however, we did not see this as necessary for testing the concept in a controlled lab environment.\nTherefore, the virtual co-host moves to the Ask phase if:\n(1) at least 8 minutes have elapsed, and a non-host participant has spoken more than twice the average or less than\nhalf the average, or\n(2) half the meeting time has elapsed.\nThe latter rule ensured that the Ask phase would always be triggered by minute 15 of each 30-minute lab study\nmeeting. This would ensure that under-participators had a chance to answer the virtual co-host‚Äôs questions and that\nenough time would be left for interventions to affect the meeting.\n4.1.2 Ask.\nThe virtual co-host identified anyone with below-average speaking time as an under-participator. We, again, used\n9\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\nFig. 4. Screenshot of the co-host‚Äôs intro message (sent to all participants shortly before start of the meeting) and first meeting\nassessment question (sent to under-participators several minutes later). Participants could respond to questions directly in text-based\nchat.\nover-inclusive criteria so more participants would receive the virtual co-host‚Äôs questions (Figure 4), letting us understand\nuser reactions to being asked for feedback by an AI co-host. Under-participators were then asked:\n(1) Have you felt able to express yourself, put forward your own ideas, and contradict others when necessary?\n(2) Have you felt inhibited from participating in the discussion because of the behavior of other meeting members\n(other than the host)?\n(3) Is there any feedback or advice you‚Äôd like me to anonymously pass on to the host?\nQuestions 1 and 2 were adapted from Davison‚Äôs revalidated meeting assessment instrument [ 25] to ensure they\ncaptured common meeting problems, selecting the questions that closely matched our outcomes. Participants could\nrespond to the virtual co-host by typing their answers in a direct chat message. The first two questions required a yes\nor no answer. For the third, participants could either type a free-response message or reply with ‚Äúno‚Äù. When given\nunsupported input, the virtual co-host would reply that it did not understand, prompting participants to try again.\nA ‚Äúno‚Äù answer to Question 1 activated the host intervention. A ‚Äúyes‚Äù answer to Question 2 activated both the host\nand over-participator interventions. Note that we decided to include the host intervention if any behavioral change\nwas needed since the host is central to how a meeting runs [ 47, 55, 72, 77, 78]. In some meetings, multiple people\nreceived the questions from the virtual co-host, in which case any single negative response activated the corresponding\nintervention(s).\nTo minimize distraction, we made the virtual co-host easy to ignore in the Ask stage; if the user does not reply, it does\nnothing. The co-host also provides minimal detail about its interventions; after receiving a negative assessment, it lets\nthe user know it will intervene but does not tell them how. We reasoned that an OAI system for meetings would need to\nbe minimally distracting, and should therefore operate with minimal oversight (like a human co-host would). Aligning\nour system‚Äôs design with this principle let us understand whether a realistic level of user interaction‚Äîquickly soliciting\n10\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\nusers‚Äô perspectives, rather than giving them full insight into and control over the virtual co-host‚Äôs behavior‚Äîwould\ngive us the expected benefits of interactivity and be acceptable to users.\n4.1.3 Intervene.\nIf the host intervention was activated, the virtual co-host sent the host a message indicating a meeting problem and\nrecommended strategies for facilitating more inclusively. The message varied based on which question prompted the\nintervention, but always contained a bar chart with information about each member‚Äôs time spoken, in accordance\nwith D2 and D6‚Äôs ideas. Houtti et al. [42] found that under-participators often become ‚Äúinvisible‚Äù in virtual meetings,\nthereby favoring over-participators being engaged in conversation. We therefore designed this visualization to make\nunder-participators the most visible to the meeting host (Figure 5a). Hosts occupy a special role that often requires\nthem to speak more than the average person in the meeting. Therefore, the visualization did not include their speaking\ntime, as we did not want to encourage the facilitator to step back from their responsibilities.\nThe virtual co-host considered the person who spoke the most an over-participator. This meant an over-participator\nmight be identified even in a highly equal meeting; we once again selected over-inclusive criteria that were appropriate\nfor our study objectives (understanding reactions to the virtual co-host‚Äôs interventions). We also reasoned that an over-\ninclusive system would trigger on potential false positives (over-participation identified in a good meeting), allowing\nus to explore the acceptability of soliciting feedback when a meeting is going well. To catch situations with multiple\nover-participators, any other person who spoke more than twice the average was also considered an over-participator.\nThis rule was never triggered, so each meeting had a single over-participator designated.\nIf the over-participator intervention was activated, the virtual co-host told over-participators they should let others\ncontribute more and gave suggestions for improving their behavior. Unlike hosts, over-participators received different\ninformation and visualizations, about their speaking time relative to the average of all other non-host meeting\nparticipants (Figure 5b). We reasoned that users frustrated with an over-participator were unlikely to feel comfortable\nwith them having privileged access to every participant‚Äôs exact speaking time. Doing so might also give them information\nwith which to criticize under-participators for not contributing‚Äîa dynamic we would not want any system to encourage.\nTargets of the virtual co-host‚Äôs interventions received an updated visualization every 4 minutes to encourage\ncontinued awareness of their (non-)compliance with the norms it expressed. We extensively piloted the visualizations\nto make sure they were visually salient and easy to understand. Unlike under-participators in the Ask stage‚Äîwho\nwould stop receiving messages if they ignored the virtual co-host‚Äîthose receiving interventions had to tell the co-host\nto ‚Äústop‚Äù if they wanted to stop receiving messages from it. To prevent interruptions and ensure receivers did not miss\nthe virtual co-host‚Äôs messages, messages were queued and sent after the receiver‚Äôs microphone had been inactive for at\nleast 5 seconds.\n4.2 Technical Details\nThe virtual co-host was implemented as a Discord bot using Discord.py. Discord is a free video chat system with over a\nhundred million users [1]. It is often used for student project teams, course spaces, and gaming. The virtual co-host\nused Selenium and custom Javascript to track participants‚Äô speaking times in real-time by monitoring elements in\nDiscord‚Äôs web browser interface. It communicated with participants through direct messages. 1 In addition to text,\nmessages contained visualizations generated with R/ggplot2. Images are sent in their full dimensions through Discord\n1Discord displays direct message notifications through a pop-up bubble on a sidebar, showing who sent the message and how many messages were sent.\nThe user can click the bubble to open a direct message interface with the sender. This is similar to clicking to open chat in other VC software. When\nfinished, they can go back to the meeting interface by clicking the meeting server‚Äôs bubble in the same sidebar.\n11\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\n(a) Host message example\n(b) Over-participator message example\nFig. 5. Examples of intervention messages from the virtual co-host. The virtual co-host notified participants of issues in the meeting,\nprovided suggested actions, and included speaking time visualizations. Host-targeted visualizations made under-participators more\nvisible by placing those who spoke least at the top and scaling name size inversely with speaking time.\n12\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\n(not as thumbnails or downloads like in other VC software). Participants in a pilot study meeting reported no difficulty\nnoticing and seeing the co-host‚Äôs visualizations.\n4.3 Exploratory Lab Study Methods\nStudents at several US-based institutions were invited to sign up to participate in our study, alone or in groups of up to 3.\nOur institution‚Äôs IRB reviewed and approved this study. Recruitment was done through in-person class announcements,\na departmental research pool, and emails to institutional/departmental mailing lists. Experiment sessions had 4 to 7\nparticipants. Each participant was compensated $20 for completing the study. If participants signed up in a group, they\nwere guaranteed to be in the same session. This setup ensured that in every session, most participants knew at least\nsome participants, but no participant knew everyone‚Äîbetter approximating many group work dynamics.\nOur study used a between-subjects design [19], which satisfied our research objectives while minimizing demand on\nparticipants‚Äô time. This approach let us reliably recruit enough participants to obtain deep qualitative insights (our\nprimary objective) and quantitative data to supplement those insights.\nWe assigned groups to conditions randomly, except in cases where we needed to maintain balance between conditions.\nFor example, we manually assigned two groups to the treatment condition following three random assignments to\nthe control condition in a row. We started with 5 control group sessions ( ùëõ = 28) and 5 treatment group sessions\n(ùëõ = 29). The virtual co-host was only present in treatment groups; control groups had no exposure to the system\nwhatsoever. In the 5 treatment sessions, the virtual co-host‚Äôs visualization- and feedback-based interventions were\nonly triggered twice. (One intervention was correctly triggered, while the other resulted from a participant input\nerror.) In another meeting, the host received positive free-form feedback passed anonymously from another participant,\nbut no visualizations or guidance from the virtual co-host. It became apparent that gathering sufficient data on the\nsystem‚Äôs interventions would not be feasible without a significantly larger sample size. Therefore, in two additional\ntreatment groups, researchers manually triggered the interventions (minus the free-form feedback) regardless of\nunder-participators‚Äô meeting assessments (ùëõ = 11, bringing the total treatment group to ùëõ = 40). This gave us more data\nwith which to develop a rich understanding of user reactions to the ‚ÄúIntervene‚Äù phase.\nEach session was structured as follows:\nFig. 6. Summary of exploratory lab study methods, analysis objects, and outputs.\n13\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\n‚Ä¢Icebreaker: Two researchers facilitated a short icebreaker activity. Participants were asked to share their names\nand one thing they enjoy doing.\n‚Ä¢Solo Activity: Participants were given a worksheet to complete the Lost at Sea activity [13], a group work task\nused in prior work (e.g. [21, 29, 43, 58]). In this activity, participants are given a hypothetical scenario where they\nare on a lifeboat in the sea and asked to rank 15 items in order of importance for survival. We selected this task\nin part because it does not require equal participation (and could be completed alone). Participants completed\nthis activity solo for 10 minutes to allow everyone adequate time to come up with their own ideas. (Timed, 10\nminutes.)\n‚Ä¢Group Activity: A meeting host was selected at random and was instructed to lead the process of producing a\ngroup answer for the Lost At Sea activity. In treatment groups : the virtual co-host joined the meeting and\nintroduced itself (Figure 4). The facilitating researcher alerted participants to the co-host‚Äôs presence to ensure\nthey were aware of it and how it communicated. We wanted to see how participants would react to the virtual\nco-host, so we did not give any instructions on how they should respond to its messages. (Timed, 30 minutes.)\n‚Ä¢Post-study Questionnaire: Participants were given a Qualtrics survey containing Davison‚Äôs meeting assessment\ninstrument [25, Section A.1], which assesses meetings on five constructs: Communication, Discussion Quality,\nStatus Effects, Teamwork, and Efficiency 2. People in treatment groups assessed how distracting the virtual\nco-host was on a 5-point Likert scale.\n‚Ä¢Semi-structured Interviews: A subset of participants who experienced the co-host‚Äôs Ask or Intervene phases\nwere invited for follow-up interviews (10 under-participators, 3 over-participators, and 5 hosts; ùëõ = 18), where\nwe solicited in-depth reactions to the virtual co-host. Interviews lasted on average about 13 minutes.\nAnalysis: We analyzed follow-up interviews using inductive thematic analysis. We generated open codes for each\nunique participant statement, conducted axial coding to group-related codes, and concluded with selective coding\nto identify major themes and outcomes. We recorded audio and video of the group activities to assist in analysis.\nParticipants were notified in the consent form and before the icebreaker that parts of the study would be recorded. To\nsupplement the qualitative analysis, we conducted statistical tests on questionnaire responses. We report descriptive\nstatistics where appropriate.\n4.4 Exploratory Lab Study Results\nWe organize our findings by OAI‚Äôs three steps. Recall that we wanted to understand whether and how a virtual co-host\ncould be designed to be both acceptable (i.e., users like the system) and effective (i.e., it works as intended). Therefore,\nwe articulate how our findings relate to acceptability and effectiveness. We address only acceptability for ‚ÄúObserve‚Äù\nsince the effectiveness of AI inference in VC meetings is already demonstrated by prior work (e.g., [64, 71]).\nEach interview participant‚Äôs anonymous ID consists of a letter‚ÄîH, U, or O indicating they were a host, under-\nparticipator, or over-participator. For example, H1 was a host and U1 was an under-participator, though they may not\nhave been in the same meeting. When relevant, we specify in text that participants were in the same meeting. We\nlightly edited participant quotes for brevity and clarity.\n4.4.1 Observe .\n2Our survey erroneously omitted the last two items in the instrument (E1 and E4), both of which pertain to the Efficiency construct. We, therefore, omit\nthe Efficiency construct from our statistical results. Excluding this construct does not change the overall interpretation of our findings. Our analysis of\nquestions E2 and E3 further supports this interpretation and is included in a Supplemental table S1.\n14\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\nAcceptability:\nNo negative effects of being observed by the co-host.\nIn interviews, participants reported no negative feelings about the virtual co-host‚Äôs presence. The virtual co-host\njoined the meeting as a participant‚Äîit had its own user tile just like other meeting participants‚Äîand it sent an\nintroductory message telling participants it would ‚Äúobserve conversational dynamics. ‚Äù U10, for example, recalled feeling\nthat ‚Äúit was just kind of there‚Äù and that they did not think about it until it messaged them. U6 said ‚Äúmy focus wasn‚Äôt\nentirely on it. ‚Äù Our results connect to prior work that the experience of a ‚Äúwatching-eye‚Äù effect is context-dependent [44],\nand show that AI agents may not have this negative effect in virtual meetings even if they are visually presented as\nattendees with their own user tiles.\n4.4.2 Ask .\nAcceptability:\nEngaging with the virtual co-host was generally positive.\nParticipants indicated that receiving questions from the virtual co-host was a generally positive experience. U5\nappreciated that the co-host‚Äôs questions helped validate their negative feelings about the meeting. ‚ÄúI was already feeling\nfrustrated, so it was good to validate that. ‚ÄùKnowing that the co-host would share the feedback did not change things.\nU6 guessed that giving the virtual co-host a negative response would cause it to message the host, but recalled that this\nmade them ‚Äúnot particularly uneasy; maybe 10%. ‚Äú\nEngaging with the virtual co-host was minimally distracting.\nParticipants‚Äô subjective evaluations of distraction also showed a willingness to engage, and some participants were\nnot bothered by the co-host. However, a few participants found the virtual co-host distracting and worried that if they\nresponded negatively, ‚Äúit‚Äôs going to talk to me more. ‚Äù (U3) In the post-study questionnaire, participants in meetings\nwith the virtual co-host were asked if ‚Äúthe virtual co-host was distracting‚Äù on a 5-point Likert scale. For the 17 under-\nparticipators who were asked questions by the virtual co-host, only 4 participants ‚ÄúAgreed‚Äù (3 participants) or ‚ÄùStrongly\nAgreed‚Äù (1) with that statement. Conversely, 10 said they ‚ÄúStrongly Disagreed‚Äù (5) and ‚ÄúDisagreed‚Äù (5) with the co-host\nbeing distracting (see Figure 7). This suggests that most did not find the virtual co-host distracting, but the variation\nsupported our decision to make the virtual co-host‚Äôs questions unobtrusive.\nAsking mitigated concerns about accuracy.\nAlmost all interviewees said they preferred being asked before interventions. We asked under-participators their\nopinions on having the virtual co-host ask before intervening. U8 responded that ‚ÄúI would still prefer [the co-host] to ask\nquestions... sometimes expressions just aren‚Äôt communicating what you‚Äôre actually feeling. ‚Äù U2 similarly worried that if\nthe system intervened without asking first, it ‚Äúmight be wrong, and then it negatively impacts the person‚Äù on behalf of\nwhom it is intervening. Participants worried that the AI might inaccurately infer meeting issues where there are none\nand intervene inappropriately. Asking mitigated this concern, confirming our design intuitions and aligning with other\nhuman-AI studies [14, 49, 81].\n15\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\nAsking let participants retain agency.\nWe wondered if asking might have other advantages, so we asked participants to assume the virtual co-host\ncould perfectly assess their internal states. Participants still preferred for the virtual co-host to solicit explicit\nmeeting assessments. U8 said ‚ÄúI like retaining agency, so I would still prefer it to ask questions than try to analyze my face. ‚Äù\nU9 echoed this, saying ‚Äúthere‚Äôs that part of autonomy that needs to be maintained, so I wouldn‚Äôt like the virtual co-host\nto notify the host without checking in with me first. ‚Äù We conclude that OAI is useful for designing AI-based meeting\ninterventions because it improves interventions based on imprecise proxy signals and preserves human preferences for\nagency over AI systems (consistent with Schmidt [73]). We return to this in the Discussion section.\nEffectiveness:\nParticipants gave the virtual co-host accurate information.\nParticipants reported being honest in their answers to the virtual co-host. U10 even remarked that ‚Äúbecause it‚Äôs\nan inanimate being, I‚Äôd probably be more likely to give it a very honest answer. ‚Äù This is consistent with prior work\nshowing that people are more likely to disclose difficult information to virtual humans than real humans [59]. It also\ncorroborates our ideation participants‚Äô intuitions that AI agents can receive critical feedback with minimal discomfort\nto users, which may make them more effective than humans at gathering information about meeting issues.\nThere was a drop-off in engagement with the co-host‚Äôs questions.\nRecall that participants reported minimal distraction from the virtual co-host‚Äôs questions. However, we saw a drop-off\nin response rate as more feedback was requested. Of the 17 under-participators who received questions from the\nvirtual co-host, 14 answered at least one of the questions, 11 answered the first two, and only 7 answered all three.\nFurther, the virtual co-host‚Äôs third question was free-form - of the 7 that answered it, only 1 provided unstructured\nFig. 7. Agreement with the statement ‚Äúthe virtual co-host was distracting‚Äù by participants to whom the virtual co-host asked\nquestions.\n16\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\nConstruct M (control) SD (control) M (treatment) SD (treatment) df t p\nCommunication 8.45 3.37 6.18 2.96 55.90 2.89 **0.005\nDiscussion Quality 17.24 2.18 17.10 2.62 65.11 0.24 0.81\nStatus Effects 7.83 3.75 6.05 2.84 50.19 2.14 *0.04\nTeamwork 12.38 1.86 12.90 1.79 59.15 -1.15 0.25\nTable 2. Welch‚Äôs two sample ùë°-tests of user assessments on four of the five meeting quality constructs in Davison [25]. Participants\nwho had the co-host present rated meetings better on all but one construct. 5-point Likert scale responses were summed within each\nconstruct to derive a corresponding value for each participant. Note that some of the constructs are worded positively while others\nare worded negatively [25, see A.1], so the ‚Äúbetter‚Äù mean value for each row is indicated in bold.\nfeedback to the host. The 6 other participants just said ‚Äúno‚Äù to provide no feedback. On the one hand, this was surprising\nbecause multiple ideation session participants said they wanted to provide anonymous feedback to the host. However,\nparticipants may not be willing to take on more cognitive load during a meeting to avoid distraction.\n4.4.3 Intervene .\nAcceptability:\nParticipants appreciated socially comfortable interventions.\nAs expected from ideation sessions, participants‚Äîboth over- and under-participators‚Äîpreferred that visualizations\nremain private because public visualizations would create social discomfort. O1 worried that visualizations ‚Äúcould\nlead to feelings of embarrassment if it‚Äôs broadcasted to everybody. ‚Äù This may seem self-interested coming from an\nover-participator, but under-participators shared this concern:\n‚ÄúThat puts people on the spot of like, shoot, I‚Äôve been talking too much or too little. If it‚Äôs just to the host, they\ncan make space for the person without calling them out. ‚Äù (U6)\nU2 similarly said: ‚Äúwhen you give it to everyone, everyone will just speak less and then no one is talking. ‚Äù Even when\nfrustrated with an uninclusive meeting, U5 worried that ‚Äúif it‚Äôs a shared display, it might make some folks feel uneasy. ‚Äù\nThe host has a special mandate.\nRecall that we selected the host for each meeting at random. Despite this, participants were comfortable with the\nhost having privileged information about everyone‚Äôs exact speaking times:\nGiving it to the host makes it feel like it‚Äôs a tool for the host to care for everyone, whereas when it‚Äôs presented\nto everyone it feels like a monitoring device of your performance. (H3)\nNon-hosts echoed this. U2 reasoned that the host has ‚Äúa mandate to make sure everyone has the room to speak. ‚Äù O1\nexpressed that the host should receive private feedback and visualizations ‚Äúbecause they have responsibilities over other\npeople. ‚ÄùImportantly, U3 cautioned that ‚Äúif you have a boss who doesn‚Äôt like you, they can use it against you, ‚Äù indicating\nthat users‚Äô comfort might depend on the meeting host demonstrating positive intentions.\n17\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\nEffectiveness:\nGroups with the virtual co-host rated meetings better.\nParticipants in treatment groups rated meetings better overall (Table 2). While we would expect this to mean meeting\noutcomes were improved by the virtual co-host‚Äôs interventions, our findings on effectiveness paint a different picture.\nParticipants paid less attention to interventions than to questions.\nEven though the virtual co-host‚Äôs interventions did not require active interaction (unlike the co-host‚Äôs questions),\nparticipants who received interventions varied much more in their desire to redirect attention to its messages. H5 said\n‚Äúit was just another thing to look at when there were a lot of things going on. ‚Äù H4 did not read the messages ‚Äúto make sure I\nwas staying focused‚Äù , but did look at the visualizations and could recall the information in them. The other two hosts, H1\nand H2, reported paying close attention to the information in the virtual co-host‚Äôs messages. H2, for example,‚Äúskimmed\nthrough the suggestions‚Äù , which served as a ‚Äúquick reminder that I need to actively pull people into this conversation‚Äù .\nH1 read the co-host‚Äôs instructions for how to stop its messages, but ‚Äúchose not to stop it just because I still think they‚Äôre\nhelpful. ‚Äù\nOnly 1 of 3 over-participators reported looking at the virtual co-host‚Äôs messages, compared to 4 of 4 hosts. Despite\ngetting reminders from the virtual co-host every 4 minutes, 2 of 3 over-participators missed all its messages. This is\nlikely because they were singularly focused on the meeting goals, or perhaps, not focused on the overall tenor of the\nmeeting and goals of inclusion. This suggests that over-participator interventions may need to be more prominent,\nharder to ignore, or tailored to their contexts.\nParticipants rationalized away the virtual co-host‚Äôs feedback.\nDespite finding co-host messages helpful, hosts did not feel compelled to act on the recommendations. H1 explained\nthat the virtual co-host emphasized the value of running meetings inclusively, but that they were already being inclusive\nanyway:\nIt wasn‚Äôt a huge change for me. When you‚Äôre leading a meeting, one of the most important parts is getting\neverybody to speak, so I‚Äôve always emphasized that.\nIn this case, H1‚Äôs positive evaluation of the meeting may have been accurate; in their meeting, U4 was the largest\nunder-participator and did express that they thought the meeting was going well, saying ‚ÄúI did not need to add my\nvoice‚Äù in our follow-up interview. However, it is not clear that H1 could intuitively know U4‚Äôs meeting experience,\ngiven that U4 had only spoken for 10 seconds at the time of intervention (over 8 minutes into the meeting). That H1\nmaintained a positive self-assessment despite the virtual co-host‚Äôs assertion that ‚Äúsome people have not felt comfortable\nexpressing themselves‚Äù is consistent with what we observed across participants.\nDuring another session, the facilitating researcher noticed that H4 was moving quickly through the activity items\nwithout allowing time for others to interject‚ÄîH4‚Äôs session was shortest by far (approximately 13 minutes, compared\nto the median meeting length of 28 minutes). H4 also spoke the largest percentage of the meeting compared to other\nhosts (68.7%). When asked about the value of including an under-participator in the meeting as the virtual co-host\nrecommended, H4 responded that ‚ÄúI feel like, in that scenario, if [person] had something to say, [they] would have said it. ‚Äù\nIndeed, H4 argued that they were doing a good job consulting other meeting participants:\n18\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\n‚ÄúEvery time I was trying to make a decision in the meeting I would ask people what they thought. I didn‚Äôt feel\nthat anybody was hogging the talking time. ‚Äù\nThe one over-participator who did see the virtual co-host‚Äôs messages exemplifies how outside perceptions of under-\nparticipators‚Äô meeting experiences are often inaccurate in self-serving ways. O1 rationalized away the virtual co-host‚Äôs\nfeedback:\n‚ÄúSo when I got the messages saying I might be speaking a little bit more, I was like... I feel like I‚Äôm being fair\nto people and asking for input. I‚Äôm talking, but I‚Äôm also conceding some of my opinions to other people. ‚Äù\nMeanwhile, U5 expressed frustration with O1:\n‚ÄúPeople were being very rapid-fire, and they weren‚Äôt leaving a lot of time for discussion. It just kind of seemed\nlike, is everyone fine with this?‚Äù\nDespite reminders from the virtual co-host indicating problems in the meeting, participants mostly ignored its\nconstructive feedback and suggestions. This can be explained by the psychological literature on cognitive dissonance [37],\nwhich shows that humans may re-orient their beliefs to maintain psychological comfort. That participants so consistently\nengaged in cognitive dissonance here was somewhat surprising given ideation session participants‚Äô intuitions and prior\nresearch where awareness feedback successfully changed over-participators‚Äô behaviors [27]. We return to this in the\nDiscussion section for additional analysis.\nLow social pressure from AI is the most plausible cause of our interventions‚Äô failures, consistent with recent work\nby Vollmer et al. [86] finding that robots could not subtly peer pressure adults as effectively as other adults could. Recall\nthat some of our interventions were artificially triggered by researchers. Could hosts and over-participators have simply\nignored the feedback because they (correctly) intuited its disconnect from real meeting conditions? The example of O1\ncomplicates this interpretation; O1 rationalized away feedback even when it was informed by U5‚Äôs deep frustration.\nSuch lack of insight into others‚Äô experiences is consistent with recent work by Houtti et al. [42], who note that meeting\nleaders are often completely unaware when their meeting facilitation decisions make others feel excluded. Further, it is\ndifficult to imagine the same feedback from a human peer failing to override O1‚Äôs mistaken assumption in this case‚Äîor\neven accurate assumptions in other participants‚Äô cases. Indeed, the famous Asch conformity experiments [8] showed\nthat people can even be influenced to give an obviously incorrect answer to a question if it conforms to others‚Äô answers.\nIn light of the virtual co-host‚Äôs ineffectiveness, our finding that it improved meeting assessments suggests that its mere\npresence, and perhaps its questions3, primed participants to rate meetings better, even if no gains were seen in meeting\nquality. Our conclusion here follows from recent work noting the presence of a robust AI ‚Äúplacebo effect‚Äù [51]. This\nhighlights an important issue, which we also return to in the Discussion: deploying AI systems can make participants\nfeel better about meetings even if they have no meaningful effects on meeting behaviors.\n4.5 Summary\nMost of the key premises underlying our design insights were borne out in the evaluation. AI systems can (and the virtual\nco-host did) proactively solicit feedback during meetings. Gentle and private interventions showed more mixed results;\nthe specific interventions we employed were acceptable for the reasons we anticipated (maintaining anonymity and\n3Our quantitative results do not meaningfully change when we compare control groups against treatment groups where the co-host was present but did\nnot intervene with visualizations and feedback. (See Table S2.) Alongside the fact that most participants did not receive interventions in the first place,\nthis supports our assertion that the co-host‚Äôs presence or questions, not its interventions, improved meeting perceptions.\n19\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\nsocial comfort), but did not improve participants‚Äô meeting behaviors. Our qualitative findings shed light on underlying\nreasons, which we now discuss alongside other takeaways.\n5 DISCUSSION\nOur findings demonstrate the OAI framework‚Äôs potential in helping us design acceptable and effective AI systems\nfor meeting facilitation. We highlight contributions of the OAI framework as a whole and takeaways from the mixed\nresults of our specific intervention strategy. We synthesize our findings alongside prior work to suggest ways in which\nfuture interventions could be more effective, while retaining the features of our specific interventions that made them\nacceptable to participants.\nWhile our ideation sessions focused on a system to make VC meetings more inclusive, we believe our findings can\nprovide more general guidance. Therefore, the first two Discussion subsections consider the general design implications\nof findings on the Ask and Intervene steps in OAI. (We do not focus on Observe given the extensive and high-quality\nprior work on AI observation and inference‚Äîe.g. [44, 54, 64, 71].) We then highlight implications for design to mitigate\ninequities in meetings.\n5.1 Ask\n5.1.1 Asking makes AI inferences more acceptable and more accurate. Designing the virtual co-host to ask questions\nmid-meeting conflicted with our intuition to minimize distractions. Indeed, Liao et al . [57] found that users dislike\nunsolicited proactive interaction from an automated agent, especially if they have busy work schedules. However, we\nreasoned this aversion may not apply in the VC context where users already expect synchronous engagement with\nothers verbally and through text-based chat. Enacting this user preference in our implementation let us test whether\nsimilar barriers would materialize in such contexts.\nOur results suggest proactive ‚Äúasking‚Äù during synchronous group work actually makes AI systems more acceptable.\nWhen asked to choose between a virtual co-host that asks questions and one that simply intervenes autonomously, all\nbut one under-participator preferred the former‚Äîeven after having just experienced a meeting in which they had the\nburden of answering its questions. Preferences were driven by improved sense of agency and reduced concerns about\naccuracy.\nAccuracy was a major concern for users in prior work, and asking provides a means of overcoming it. A user‚Äôs\nsubjective impression of their inclusion in a meeting is more reliable than what an algorithm could produce by analyzing\ntheir face or speech. This could be used to augment AI inferences. For example, MeetingCoach‚Äôs post-meeting dashboard\nshows a breakdown of a user‚Äôs tone throughout the meeting [71]. What if MeetingCoach were designed to ask assessment\nquestions when a speaker had a negative tone? This would enable the system to confirm AI inferences before acting\non them, overcoming a key limitation of AI systems and making it more acceptable. Explicit responses could also be\ndisplayed to users alongside inferential data to substantiate inferences.\n5.1.2 Design guidelines for asking. Our results suggest several design guidelines for systems that ask questions during\nmeetings:\n‚Ä¢Systems should distribute the burden of answering across multiple users, rather than just a single one. When\npossible, interventions should not be contingent on getting answers to all questions.\n20\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\n‚Ä¢As expected, it was easier to get the attention of under-participators than over-participators through text-based\nchat. Systems that target middle- or over-participators will have to do more work to make questions\nvisually prominent and difficult to miss.\n‚Ä¢Despite ideation session participants wanting the ability to give free-form feedback, participants in our meetings\nrarely gave feedback mid-meeting. Questions should be yes-or-no, to minimize cognitive burden. We\nhypothesize that Likert scale questions can be considered if the granularity justifies the likely reduction in\nresponse rate.\n5.2 Intervene\n5.2.1 Effective interventions should make social pressure more salient. By observing the effects of speaking time\nvisualizations in meetings, DiMicco et al. [27] concluded that group awareness feedback will cause individuals to self-\nregulate and conform with the feedback‚Äôsimplied norms. Our virtual co-host made normative expectations moreexplicit;\nit directly messaged over-participators and hosts to indicate when they were not meeting normative expectations. Yet\nits constructive criticism and suggestions fell mostly on deaf ears. Importantly, DiMicco et al. ‚Äôs meeting visualizations\ndiffered in that they were shared among all meeting participants .\nWe conclude that awareness feedback in meetings likely achieves most of its effects by augmenting perceived\nnormative pressure. Individuals inherently understand that over-participating can lead others to judge them negatively.\nMaking the judgment more salient (by having a public speaking display) is more effective than making the over-\nparticipation more salient (in our case, by having an AI agent provideprivate feedback and visualizations). We speculate\nthat highlighting normative pressure from others reduces the risk of cognitive dissonance [ 37] because it does not\nrequire users to accept that critical information about themselves is accurate‚Äîonly that others may perceive it as\naccurate. Awareness feedback interventions that seek to influence meeting participants‚Äô behavior should therefore be\ndesigned to emphasize the possibility of judgment from peers.\nThere is a fundamental tension here: users prefer systems thatminimize social pressure, but social pressure is needed\nto prompt behavior change. This tension is at the heart of why our interventions failed to change participants‚Äô behavior.\nHowever, future systems can be creative in balancing these concerns. For example, we could take a phased approach\nthat relies on the threat of public interventions‚Äîe.g., where participants are told that private interventions will become\npublic only if not acted on. This would maintain social comfort, while incentivizing users to change their behavior to\ncontinue maintaining social comfort. Alternatively, making participants aware that the co-host is acting on behalf of\nanother meeting participant could reduce the risk of cognitive dissonance. AI feedback would be understood to reflect a\nreal human‚Äôs assessment, prompting behavior change, while still minimizing social pressure because the feedback is\ndelivered indirectly. These interventions have potential in theory, and should be empirically tested in future work.\n5.2.2 Computers are social actors with less social pressure. Our findings build further on Nass et al. ‚Äôs seminal work\ndemonstrating that humans subconsciously interact with machines as if they were social beings [ 65]. Our results\nsuggest that AI agents cannot apply normative pressure to the same degree as humans situated in a similar social role,\nmaking it more difficult for them to overcome psychological biases like cognitive dissonance [37].\nIn cases where normative pressure is needed, we should design AI systems to communicate desired norms more\naggressively. For example, our virtual co-host could have been more effective if it prompted participants to explicitly\nacknowledge the norm violations‚Äîe.g., by preventing them from un-muting until they acknowledged the feedback and\ntheir intention to act on it. Alternatively, AI systems could rely on other humans to give their interventions normative\n21\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\nweight. Our results suggest, for example, that an AI fitness accountability coach might not be as effective as a human\ncoach even if it competently performed all the same functions. This system could rely on normative pressure from\nother humans by, e.g., sharing the user‚Äôs progress with their friends (just as many modern fitness apps do).\nWhile low normative pressure is a limitation of AI agents in the intervention use-case, it also could be an advantage\nwhen we want to minimize normative pressure. Soliciting meeting assessments is one case‚Äîrecall that one of our\nparticipants said it was easier to give the virtual co-host negative feedbackbecause it was virtual . This strength can be\nleveraged in other domains where giving feedback is difficult. For example, Google‚Äôs Q&A tool for all-hands meetings,\nwhich combines and summarizes employee questions, reportedly doubled the number of employees contributing\nfeedback [68].4 Future work could explore other applications of AI as a means of facilitating the exchange of feedback\nin groups.\n5.2.3 Positive priming can make ineffective interventions seem effective. The virtual co-host‚Äôs positive priming effects\ndemonstrate the imperative to measure systems‚Äô effects on meetings based on tangible outcomes, self-reported subjective\ndata, and in-depth qualitative inquiry. In its current form, we expect our system would marginally improve real workers‚Äô\nsubjective meeting experiences despite not truly improving meeting behaviors in any meaningful way.\nResearchers and practitioners should be mindful of priming when users are involved in the design process‚Äîe.g.,\nthrough value-sensitive design [34], user-centered design [3], participatory design [79], or other methods‚Äîespecially\nwhen evaluating systems that seek to challenge users or alter their behavior. Recall that following participants‚Äô\npreferences to intervene privately made our system both more acceptable and less effective. It is not entirely surprising\nthat participants designed a system they liked, and that did not sufficiently constrain their negative behaviors. We\nhypothesize that systems designed with user involvement are more likely to see positive subjective outcomes alongside\nnegative/neutral objective outcomes, though more work is needed to confirm or reject this hypothesis.\nImportantly, it may not be sufficient to consult more (or more diverse) stakeholders. Recall thateven under-participators\npreferred interventions to minimize others‚Äô social discomfort. This may have been caused by vicarious embarrass-\nment [52]‚Äîi.e., under-participators may feel uncomfortable with someone else being ‚Äúcalled out‚Äù in their presence. Said\nanother way, consulting the stakeholders who stood to benefit the most did not suggest different design conclusions.\nWhile this may be a limitation of user-centered methods (and should be investigated more), it should not deter us from\ninvolving users in the design process. Our systems should be both effective and acceptable, so subjective outcomes are\nstill important to assess.\n5.3 Implications for Future Work on VC Meeting Inclusion\nSo far, our discussion has centered around the significance of our findings for designing AI-based meeting systems in\ngeneral. We believe this will be valuable to researchers in CHI; however, our findings also include important takeaways\nabout the specific problem of inclusion in meetings. We conclude by connecting our implications to this context. We\noffer these as methodological and design guidelines for future work on designing AI systems to make meetings more\ninclusive.\n5.3.1 High risk of cognitive dissonance. Recall that participants engaged in cognitive dissonance because our system\ncould not apply sufficient social pressure. Future researchers should anticipate and design for this risk. Prior work in\npsychology extensively documents the self-serving bias‚Äî‚Äúa tendency for people to take personal responsibility for their\n4We should note that the tool has been criticized for ‚Äúsoftening‚Äù questions to leadership. As evidenced by our findings, however, friendliness can be\nvalued over directness in other organizational contexts.\n22\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\ndesirable outcomes yet externalize responsibility for their undesirable outcomes. ‚Äù [80] Similarly, we expect that users will\ntend to externalize responsibility for adverse meeting outcomes, increasing the risk of cognitive dissonance when we\nseek to change behavior by surfacing their roles in making the meeting less inclusive.\n5.3.2 Surreptitiously perpetuating inequity. Our findings demonstrate the imperative for researchers and designers to\nevaluate systems‚Äô effects holistically. In its current form, we imagine our virtual co-host would marginally improve real\nworkers‚Äô subjective perceptions of meeting inclusion and, in doing so, unintentionally exacerbate inequities by\nmaking people complacent. Why worry about meeting inclusion when we have an AI tool that mitigates it? (Except, of\ncourse, it did not.) Given how contextual, multi-faceted, and difficult-to-measure inclusion is, these conflicting effects\ncan be difficult to identify unless we are looking for them. Thus, narrow evaluations risk leading us to design systems\nthat surreptitiously perpetuate the very harms we intend to mitigate.\n6 LIMITATIONS\nOur chosen methods, while appropriate for the questions we sought to investigate, have several inherent limitations.\n6.1 Controlled Environment\nA lab study enabled us to compare the experiences of groups in a somewhat controlled environment, but real meetings\nare far from controlled and are therefore impossible to emulate perfectly. For example, we could expect that meeting\nleaders who feel a strong sense of responsibility over their team meetings might be more receptive to a virtual co-host‚Äôs\nnegative feedback (and therefore less likely to rationalize its feedback away).\nFurther, a lab study precluded us from examining use over time. In organizational settings, we might see hosts\nrationalize away feedback in the meeting itself, but then seek out feedback from under-participators after the meeting.\nThis might in turn affect how they react to subsequent feedback from the virtual co-host. These limitations suggest\navenues for further research, ideally in the form of field studies where AI-based systems that employ OAI are tested in\nreal meetings over time.\n6.2 Between-Subjects and Inter-Group Differences\nDue to our between-subjects design, differences in meeting assessments could simply reflect inherent differences\nbetween groups, rather than effects of the treatment. While random assignment accounts for this issue in theory,\nrecall that we assigned participants pseudo-randomly‚Äîto ensure balance between conditions, then to create additional\ntreatment groups with researcher-triggered interventions. While we see no obvious reasons this group assignment\nstrategy could have systematically biased group composition, this possibility cannot be ruled out entirely.\n6.3 Interactions Between OAI Phases\nInteractions between phases of OAI were beyond the scope of our study. When designing an OAI-based system, we\nshould be mindful of how implementation decisions in one phase could affect reactions to an entirely different phase.\nFor example, if Ask were timed to overtly follow specific behavioral cues, this could make Observe more salient to\nusers such that they do experience the ‚Äúwatching-eye‚Äù [44] effect contra our findings. And as already mentioned, the\ngenuineness of responses in Ask could change how people react to Intervene, especially if they intuit a disconnect\nbetween the AI‚Äôs interventions and real meeting conditions. Ideally, these and other interactions could be tested via 2x2\nfactorial studies‚Äîbut at the very least, they should be considered when designing other OAI-based systems.\n23\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\n6.4 Other Cultural Contexts\nOur participants were all US-based English-speakers. Many of our findings may not transfer to other cultural contexts.\nFor example, the ‚ÄúAsk‚Äù phase could plausibly fail to get honest responses in cultures with high power distance [41].\nFuture work should consider this possibility when employing or studying OAI-based systems in cultural contexts that\nare substantially different from the one we focused on here.\n7 CONCLUSION\nThrough user-centered ideation sessions and an exploratory lab study, this work contributes details and operational-\nization of a new framework, ‚ÄúObserve, Ask, Intervene‚Äù (OAI), for designing AI tools to mediate synchronous group\ninteractions. Our work provides guidelines for designing proactive AI agents to support group work, especially in the\ncontext of improving meeting inclusion.\n24\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\nREFERENCES\n[1] [n. d.]. About Discord | Our Mission and Values. https://discord.com/company\n[2] Nicole Abi-Esber, Jennifer E. Abel, Juliana Schroeder, and Francesca Gino. 2022. ‚ÄúJust letting you know . . . ‚Äù Underestimating others‚Äô desire for\nconstructive feedback. Journal of Personality and Social Psychology 123, 6 (2022), 1362‚Äì1385. https://doi.org/10.1037/pspi0000393 Place: US Publisher:\nAmerican Psychological Association.\n[3] Chadia Abras, Diane Maloney-Krichmar, and Jenny Preece. 2004. User-Centered Design. Encyclopedia of Human-Computer Interaction (2004).\n[4] Mark Adkins, Michael Burgoon, and Jay F. Nunamaker. 2003. Using group support systems for strategic planning with the United States Air Force.\nDecision Support Systems 34, 3 (Feb. 2003), 315‚Äì337. https://doi.org/10.1016/S0167-9236(02)00124-0\n[5] Airgram.io. [n. d.]. Airgram | AI Assistant for Automated Meeting Notes & Summary. https://www.airgram.io/\n[6] Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N. Bennett, Kori\nInkpen, Jaime Teevan, Ruth Kikin-Gil, and Eric Horvitz. 2019. Guidelines for Human-AI Interaction. InProceedings of the 2019 CHI Conference on Human\nFactors in Computing Systems (CHI ‚Äô19) . Association for Computing Machinery, New York, NY, USA, 1‚Äì13. https://doi.org/10.1145/3290605.3300233\n[7] Robert Anson, Robert Bostrom, and Bayard Wynne. 1995. An Experiment Assessing Group Support System and Facilitator Effects on Meeting\nOutcomes. Management Science 41, 2 (Feb. 1995), 189‚Äì208. https://doi.org/10.1287/mnsc.41.2.189 Publisher: INFORMS.\n[8] Solomon E Asch. 1956. Studies of independence and conformity: I. A minority of one against a unanimous majority. Psychological monographs:\nGeneral and applied 70, 9 (1956), 1. https://doi.org/10.1037/h0093718\n[9] Jeremy N. Bailenson. 2021. Nonverbal Overload: A Theoretical Argument for the Causes of Zoom Fatigue. Technology, Mind, and Behavior 2, 1 (Feb.\n2021). https://doi.org/10.1037/tmb0000030\n[10] Steve Benford, Chris Brown, Gail Reynard, and Chris Greenhalgh. 1996. Shared spaces: transportation, artificiality, and spatiality. In Proceedings of\nthe 1996 ACM conference on Computer supported cooperative work (CSCW ‚Äô96) . Association for Computing Machinery, New York, NY, USA, 77‚Äì86.\nhttps://doi.org/10.1145/240080.240196\n[11] Margaret Beranek, Catherine Beise, and Fred Niederman. 1993. Facilitation and group support systems . https://doi.org/10.1109/HICSS.1993.284182\nPages: 207 vol.4.\n[12] Timothy W. Bickmore, Rebecca A. Silliman, Kerrie Nelson, Debbie M. Cheng, Michael Winter, Lori Henault, and Michael K. Paasche-Orlow. 2013. A\nRandomized Controlled Trial of an Automated Exercise Coach for Older Adults. Journal of the American Geriatrics Society 61, 10 (2013), 1676‚Äì1683.\nhttps://doi.org/10.1111/jgs.12449 _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jgs.12449.\n[13] Elaine Biech. 2007. The Pfeiffer Book of Successful Team-Building Tools: Best of the Annuals . John Wiley & Sons. Google-Books-ID: _rKAA_FrtusC.\n[14] Reuben Binns. 2022. Human Judgment in algorithmic loops: Individual justice and automated decision-making. Regulation & Governance 16, 1\n(2022), 197‚Äì211. https://doi.org/10.1111/rego.12358 _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/rego.12358.\n[15] Silvia Bonaccio, Jane O‚ÄôReilly, Sharon L. O‚ÄôSullivan, and Fran√ßois Chiocchio. 2016. Nonverbal Behavior and Communication in the Workplace: A\nReview and an Agenda for Research. Journal of Management 42, 5 (July 2016), 1044‚Äì1074. https://doi.org/10.1177/0149206315621146 Publisher:\nSAGE Publications Inc.\n[16] Charles F Bond and Evan L Anderson. 1987. The reluctance to transmit bad news: Private discomfort or public display? Journal of Experimental\nSocial Psychology 23, 2 (March 1987), 176‚Äì187. https://doi.org/10.1016/0022-1031(87)90030-8\n[17] Kim C. Brimhall, Erica Leeanne Lizano, and Mich√†lle E. Mor Barak. 2014. The mediating role of inclusion: A longitudinal study of the effects of\nleader‚Äìmember exchange and diversity climate on job satisfaction and intention to leave among child welfare workers. Children and Youth Services\nReview 40 (May 2014), 79‚Äì88. https://doi.org/10.1016/j.childyouth.2014.03.003\n[18] Stephen Carradini, Kristen Getchell, Peter Cardon, Carolin Fleischmann, Jolanta Aritz, and James Stapp. 2024. Evidence-based recommendations for\nrecorded-meetings policies. Business Horizons 67, 1 (2024), 83‚Äì92. https://doi.org/10.1016/j.bushor.2023.08.003\n[19] Gary Charness, Uri Gneezy, and Michael A. Kuhn. 2012. Experimental methods: Between-subject and within-subject design. Journal of Economic\nBehavior & Organization 81, 1 (2012), 1‚Äì8. https://doi.org/10.1016/j.jebo.2011.08.009\n[20] Chiyin Chen and Ningyu Tang. 2018. Does perceived inclusion matter in the workplace? Journal of Managerial Psychology 33, 1 (Jan. 2018), 43‚Äì57.\nhttps://doi.org/10.1108/JMP-02-2017-0078 Publisher: Emerald Publishing Limited.\n[21] Zenglo Chen, Robert B. Lawson, Lawrence R. Gordon, and Barbara McIntosh. 1996. Groupthink: Deciding with the Leader and The Devil. The\nPsychological Record 46, 4 (Oct. 1996), 581‚Äì590. https://doi.org/10.1007/BF03395186\n[22] M. J. Connor. 1994. Peer Relations and Peer Pressure. Educational Psychology in Practice 9, 4 (Jan. 1994), 207‚Äì215. https://doi.org/10.1080/\n0266736940090403 Publisher: Routledge _eprint: https://doi.org/10.1080/0266736940090403.\n[23] Ross Cutler, Yasaman Hosseinkashi, Jamie Pool, Senja Filipi, Robert Aichner, Yuan Tu, and Johannes Gehrke. 2021. Meeting Effectiveness\nand Inclusiveness in Remote Collaboration. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1 (April 2021), 1‚Äì29. https:\n//doi.org/10.1145/3449247\n[24] Nils Dahlb√§ck, Arne J√∂nsson, and Lars Ahrenberg. 1993. Wizard of Oz studies: why and how. In Proceedings of the 1st international conference on\nIntelligent user interfaces . 193‚Äì200. https://doi.org/10.1145/169891.169968\n[25] Robert Davison. 1999. An instrument for measuring meeting success: revalidation and modification. Information & Management 36, 6 (Dec. 1999),\n321‚Äì328. https://doi.org/10.1016/S0378-7206(99)00026-9\n25\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\n[26] Gianluca Demartini, Stefano Mizzaro, and Damiano Spina. 2020. Human-in-the-loop Artificial Intelligence for Fighting Online Misinformation:\nChallenges and Opportunities. IEEE Data Eng. Bull. 43, 3 (2020), 65‚Äì74.\n[27] Joan Morris DiMicco, Katherine J. Hollenbach, Anna Pandolfo, and Walter Bender. 2007. The Impact of Increased Awareness While Face-to-\nFace. Human‚ÄìComputer Interaction 22, 1-2 (May 2007), 47‚Äì96. https://doi.org/10.1080/07370020701307781 Publisher: Taylor & Francis _eprint:\nhttps://www.tandfonline.com/doi/pdf/10.1080/07370020701307781.\n[28] Sidney D‚ÄôMello, Rosalind W. Picard, and Arthur Graesser. 2007. Toward an Affect-Sensitive AutoTutor.IEEE Intelligent Systems 22, 4 (July 2007),\n53‚Äì61. https://doi.org/10.1109/MIS.2007.79 Conference Name: IEEE Intelligent Systems.\n[29] B. Dugan and E. Glinert. 2002. Task division in collaborative simulations. In Proceedings of the 35th Annual Hawaii International Conference on\nSystem Sciences . 10 pp.‚Äì. https://doi.org/10.1109/HICSS.2002.994541\n[30] Thomas Erickson and Wendy A Kellogg. 2000. Social translucence: an approach to designing systems that support social processes.ACM transactions\non computer-human interaction (TOCHI) 7, 1 (2000), 59‚Äì83.\n[31] Tasha Eurich. 2018. The Right Way to Respond to Negative Feedback. Harvard Business Review (May 2018). https://hbr.org/2018/05/the-right-way-\nto-respond-to-negative-feedback Section: Difficult conversations.\n[32] Fireflies.ai. [n. d.]. Fireflies.ai | AI notetaker to transcribe, summarize, analyze meetings. https://fireflies.ai\n[33] Kathleen Kara Fitzpatrick, Alison Darcy, and Molly Vierhile. 2017. Delivering Cognitive Behavior Therapy to Young Adults With Symptoms of\nDepression and Anxiety Using a Fully Automated Conversational Agent (Woebot): A Randomized Controlled Trial. JMIR Mental Health 4, 2 (June\n2017), e7785. https://doi.org/10.2196/mental.7785 Company: JMIR Mental Health Distributor: JMIR Mental Health Institution: JMIR Mental Health\nLabel: JMIR Mental Health Publisher: JMIR Publications Inc., Toronto, Canada.\n[34] Batya Friedman, Peter H Kahn, and Alan Borning. 2001. Value Sensitive Design: Theory and Methods. (Dec. 2001).\n[35] Andreas F√ºgener, J√∂rn Grahl, Alok Gupta, and Wolfgang Ketter. 2021. Will humans-in-the-loop become borgs? Merits and pitfalls of working with\nAI. Management Information Systems Quarterly (MISQ)-Vol 45 (2021).\n[36] Michael T. Hannan and John Freeman. 1984. Structural Inertia and Organizational Change. American Sociological Review 49, 2 (1984), 149‚Äì164.\nhttps://doi.org/10.2307/2095567 Publisher: [American Sociological Association, Sage Publications, Inc.].\n[37] Eddie Harmon-Jones and Judson Mills. 2019. An introduction to cognitive dissonance theory and an overview of current perspectives on the theory.\nIn Cognitive dissonance: Reexamining a pivotal theory in psychology (2nd ed.). , Eddie Harmon-Jones (Ed.). American Psychological Association,\nWashington, 3‚Äì24. https://doi.org/10.1037/0000135-001\n[38] Stephen C. Hayne. 1999. The facilitators perspective on meetings and implications for group support systems design. ACM SIGMIS Database: the\nDATABASE for Advances in Information Systems 30, 3-4 (Sept. 1999), 72‚Äì91. https://doi.org/10.1145/344241.344246\n[39] Tim Herrera. 2018. Why It‚Äôs So Hard to Hear Negative Feedback. The New York Times (March 2018). https://www.nytimes.com/2018/03/26/smarter-\nliving/why-its-so-hard-to-hear-negative-feedback.html\n[40] Paul D. Hills, Mackenzie V. Q. Clavin, Miles R. A. Tufft, Matthias S. Gobel, and Daniel C. Richardson. 2022. Video meeting signals: Experimental\nevidence for a technique to improve the experience of video conferencing. PLOS ONE 17, 8 (Aug. 2022), e0270399. https://doi.org/10.1371/journal.\npone.0270399 Publisher: Public Library of Science.\n[41] Geert Hofstede. 2011. Dimensionalizing cultures: The Hofstede model in context. Online readings in psychology and culture 2, 1 (2011), 8.\nhttps://doi.org/10.9707/2307-0919.1014\n[42] Mo Houtti, Moyan Zhou, Loren Terveen, and Stevie Chancellor. 2023. \"All of the White People Went First\": How Video Conferencing Consolidates\nControl and Exacerbates Workplace Bias. Proceedings of the ACM on Human-Computer Interaction 7, CSCW1 (April 2023), 1‚Äì25. https://doi.org/10.\n1145/3579597\n[43] Erzhen Hu, Md Aashikur Rahman Azim, and Seongkook Heo. 2022. FluidMeet: Enabling Frictionless Transitions Between In-Group, Between-Group,\nand Private Conversations During Virtual Breakout Meetings. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems\n(CHI ‚Äô22) . Association for Computing Machinery, New York, NY, USA, 1‚Äì17. https://doi.org/10.1145/3491102.3517558\n[44] Yaou Hu and Hyounae (Kelly) Min. 2023. The dark side of artificial intelligence in service: The ‚Äúwatching-eye‚Äù effect and privacy concerns.\nInternational Journal of Hospitality Management 110 (April 2023), 103437. https://doi.org/10.1016/j.ijhm.2023.103437\n[45] Dennis Hummel and Alexander Maedche. 2019. How effective is nudging? A quantitative review on the effect sizes and limits of empirical nudging\nstudies. Journal of Behavioral and Experimental Economics 80 (June 2019), 47‚Äì58. https://doi.org/10.1016/j.socec.2019.03.005\n[46] Rishi Iyengar. 2020. Zoom‚Äôs revenue soars 169% as people flock to service during pandemic | CNN Business. https://www.cnn.com/2020/06/02/tech/\nzoom-earnings-coronavirus/index.html\n[47] Ingrid Bronken Jakobsson and Tucker Woodham Brock. 2021. Energizing the ‚ÄúZoom-bie‚Äù Experience: Understanding virtual meetings through the\ninfluence of speaking times on perceived meeting satisfaction . Master‚Äôs thesis. Handelsh√∏yskolen BI.\n[48] Rachel Jug, Xiaoyin ‚ÄúSara‚Äù Jiang, and Sarah M. Bean. 2018. Giving and Receiving Effective Feedback: A Review Article and How-To Guide. Archives\nof Pathology & Laboratory Medicine 143, 2 (Aug. 2018), 244‚Äì250. https://doi.org/10.5858/arpa.2018-0058-RA\n[49] Anna Kawakami, Venkatesh Sivaraman, Hao-Fei Cheng, Logan Stapleton, Yanghuidi Cheng, Diana Qing, Adam Perer, Zhiwei Steven Wu, Haiyi\nZhu, and Kenneth Holstein. 2022. Improving Human-AI Partnerships in Child Welfare: Understanding Worker Practices, Challenges, and Desires\nfor Algorithmic Decision Support. In CHI Conference on Human Factors in Computing Systems . ACM, New Orleans LA USA, 1‚Äì18. https:\n//doi.org/10.1145/3491102.3517439\n26\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\n[50] Rafal Kocielnik, Daniel Avrahami, Jennifer Marlow, Di Lu, and Gary Hsieh. 2018. Designing for Workplace Reflection: A Chat and Voice-Based\nConversational Agent. In Proceedings of the 2018 Designing Interactive Systems Conference (DIS ‚Äô18) . Association for Computing Machinery, New\nYork, NY, USA, 881‚Äì894. https://doi.org/10.1145/3196709.3196784\n[51] Thomas Kosch, Robin Welsch, Lewis Chuang, and Albrecht Schmidt. 2023. The Placebo Effect of Artificial Intelligence in Human‚ÄìComputer\nInteraction. ACM Trans. Comput.-Hum. Interact. 29, 6 (Jan. 2023), 56:1‚Äì56:32. https://doi.org/10.1145/3529225\n[52] S√∂ren Krach, Jan Christopher Cohrs, Nicole Cruz de Echeverr√≠a Loebell, Tilo Kircher, Jens Sommer, Andreas Jansen, and Frieder Michel Paulus. 2011.\nYour Flaws Are My Pain: Linking Empathy To Vicarious Embarrassment. PLOS ONE 6, 4 (April 2011), e18675. https://doi.org/10.1371/journal.pone.\n0018675 Publisher: Public Library of Science.\n[53] Vivian Lai, Samuel Carton, Rajat Bhatnagar, Q. Vera Liao, Yunfeng Zhang, and Chenhao Tan. 2022. Human-AI Collaboration via Conditional\nDelegation: A Case Study of Content Moderation. In CHI Conference on Human Factors in Computing Systems . ACM, New Orleans LA USA, 1‚Äì18.\nhttps://doi.org/10.1145/3491102.3501999\n[54] Moritz Langner, Peyman Toreini, and Alexander Maedche. 2022. EyeMeet: A Joint Attention Support System for Remote Meetings. In Extended\nAbstracts of the 2022 CHI Conference on Human Factors in Computing Systems (CHI EA ‚Äô22) . Association for Computing Machinery, New York, NY,\nUSA, 1‚Äì7. https://doi.org/10.1145/3491101.3519792\n[55] Nale Lehmann-Willenbrock, Steven G Rogelberg, Joseph A Allen, and John E Kello. 2017. The critical importance of meetings to leader and\norganizational success: Evidence-based insights and implications for key stakeholders. Organizational Dynamics 47, 1 (2017), 32.\n[56] Hannes Leroy, Claudia Buengeler, Marlies Veestraeten, Meir Shemla, and Inga J. Hoever. 2022. Fostering Team Creativity Through Team-Focused\nInclusion: The Role of Leader Harvesting the Benefits of Diversity and Cultivating Value-In-Diversity Beliefs. Group & Organization Management\n47, 4 (Aug. 2022), 798‚Äì839. https://doi.org/10.1177/10596011211009683 Publisher: SAGE Publications Inc.\n[57] Q. Vera Liao, Matthew Davis, Werner Geyer, Michael Muller, and N. Sadat Shami. 2016. What Can You Do? Studying Social-Agent Orientation and\nAgent Proactive Interactions with an Agent for Employees. In Proceedings of the 2016 ACM Conference on Designing Interactive Systems (DIS ‚Äô16) .\nAssociation for Computing Machinery, New York, NY, USA, 264‚Äì275. https://doi.org/10.1145/2901790.2901842\n[58] Glenn Littlepage, William Robison, and Kelly Reddington. 1997. Effects of Task Experience and Group Experience on Group Performance, Member\nAbility, and Recognition of Expertise. Organizational Behavior and Human Decision Processes 69, 2 (Feb. 1997), 133‚Äì147. https://doi.org/10.1006/\nobhd.1997.2677\n[59] Gale M. Lucas, Jonathan Gratch, Aisha King, and Louis-Philippe Morency. 2014. It‚Äôs only a computer: Virtual humans increase willingness to\ndisclose. Computers in Human Behavior 37 (Aug. 2014), 94‚Äì100. https://doi.org/10.1016/j.chb.2014.04.043\n[60] Theresa M. Marteau, David Ogilvie, Martin Roland, Marc Suhrcke, and Michael P. Kelly. 2011. Judging nudging: can nudging improve population\nhealth? BMJ 342 (Jan. 2011), d228. https://doi.org/10.1136/bmj.d228 Publisher: British Medical Journal Publishing Group Section: Analysis.\n[61] Pietro Micheli, Sarah J. S. Wilner, Sabeen Hussain Bhatti, Matteo Mura, and Michael B. Beverland. 2019. Doing Design Thinking: Conceptual Review,\nSynthesis, and Research Agenda. Journal of Product Innovation Management 36, 2 (2019), 124‚Äì148. https://doi.org/10.1111/jpim.12466 _eprint:\nhttps://onlinelibrary.wiley.com/doi/pdf/10.1111/jpim.12466.\n[62] Robert Munro Monarch. 2021. Human-in-the-Loop Machine Learning: Active learning and annotation for human-centered AI . Simon and Schuster.\n[63] Eduardo Mosqueira-Rey, Elena Hern√°ndez-Pereira, David Alonso-R√≠os, Jos√© Bobes-Bascar√°n, and √Ångel Fern√°ndez-Leal. 2023. Human-in-the-loop\nmachine learning: A state of the art. Artificial Intelligence Review 56, 4 (2023), 3005‚Äì3054.\n[64] Prasanth Murali, Javier Hernandez, Daniel McDuff, Kael Rowan, Jina Suh, and Mary Czerwinski. 2021. AffectiveSpotlight: Facilitating the\nCommunication of Affective Responses from Audience Members during Online Presentations. In Proceedings of the 2021 CHI Conference on Human\nFactors in Computing Systems (CHI ‚Äô21) . Association for Computing Machinery, New York, NY, USA, 1‚Äì13. https://doi.org/10.1145/3411764.3445235\n[65] Clifford Nass, Jonathan Steuer, and Ellen R. Tauber. 1994. Computers are social actors. In Proceedings of the SIGCHI conference on Human factors in\ncomputing systems celebrating interdependence - CHI ‚Äô94 . ACM Press, Boston, Massachusetts, United States, 72‚Äì78. https://doi.org/10.1145/191666.\n191703\n[66] David T Nguyen and John Canny. 2007. Multiview: improving trust in group video conferencing through spatial faithfulness. In Proceedings of the\nSIGCHI conference on Human factors in computing systems . 1465‚Äì1474.\n[67] Gary M Olson and Judith S Olson. 2000. Distance matters. Human‚Äìcomputer interaction 15, 2-3 (2000), 139‚Äì178.\n[68] Marco Quiroz-Gutierrez. 2024. Google employees say AI meeting tool gives execs softball questions. https://fortune.com/2024/08/28/google-ai-\ntool-softball-questions-tgif-meetings/\n[69] Sarah Reeder, Lorelei Kelly, Bobak Kechavarzi, and Selma Sabanovic. 2010. Breakbot: a social motivator for the workplace. In Proceedings of\nthe 8th ACM Conference on Designing Interactive Systems (DIS ‚Äô10) . Association for Computing Machinery, New York, NY, USA, 61‚Äì64. https:\n//doi.org/10.1145/1858171.1858184\n[70] Rewatch.com. [n. d.]. Rewatch. https://rewatch.com/\n[71] Samiha Samrose, Daniel McDuff, Robert Sim, Jina Suh, Kael Rowan, Javier Hernandez, Sean Rintel, Kevin Moynihan, and Mary Czerwinski. 2021.\nMeetingCoach: An Intelligent Dashboard for Supporting Effective & Inclusive Meetings. In Proceedings of the 2021 CHI Conference on Human Factors\nin Computing Systems . ACM, Yokohama Japan, 1‚Äì13. https://doi.org/10.1145/3411764.3445615\n[72] Nils Christian Sauer and Simone Kauffeld. 2015. The ties of meeting leaders: A social network analysis. Psychology 6, 04 (2015), 415.\n[73] Albrecht Schmidt. 2020. Interactive Human Centered Artificial Intelligence: A Definition and Research Challenges. In Proceedings of the International\nConference on Advanced Visual Interfaces (A VI ‚Äô20) . Association for Computing Machinery, New York, NY, USA, 1‚Äì4. https://doi.org/10.1145/3399715.\n27\nCHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan Mo Houtti, et al.\n3400873\n[74] Albrecht Schmidt and Thomas Herrmann. 2017. Intervention user interfaces: a new interaction paradigm for automated systems. Interactions 24, 5\n(Aug. 2017), 40‚Äì45. https://doi.org/10.1145/3121357\n[75] Christoph Schneider, Markus Weinmann, and Jan Vom Brocke. 2018. Digital nudging: guiding online user choices through interface design.Commun.\nACM 61, 7 (June 2018), 67‚Äì73. https://doi.org/10.1145/3213765\n[76] Jessica Schroeder, Chelsey Wilkes, Kael Rowan, Arturo Toledo, Ann Paradiso, Mary Czerwinski, Gloria Mark, and Marsha M. Linehan. 2018. Pocket\nSkills: A Conversational Mobile Web App To Support Dialectical Behavioral Therapy. In Proceedings of the 2018 CHI Conference on Human Factors in\nComputing Systems (CHI ‚Äô18) . Association for Computing Machinery, New York, NY, USA, 1‚Äì15. https://doi.org/10.1145/3173574.3173972\n[77] Vivien E Schuleigh, John M Malouff, Nicola S Schutte, and Natasha M Loi. 2019. ENHANCING MEETINGS: The Impact of Leader Behavior. Journal\nof Leadership Education 18, 3 (2019).\n[78] Vivien E Schuleigh, John M Malouff, Nicola S Schutte, and Natasha M Loi. 2021. Effects of Meeting Leader Training on Meeting Attendees. Journal\nof Leadership Education 20, 1 (2021).\n[79] Douglas Schuler and Aki Namioka. 1993. Participatory Design: Principles and Practices . CRC Press. Google-Books-ID: pWOEk6Sk4YkC.\n[80] James Shepperd, Wendi Malone, and Kate Sweeny. 2008. Exploring Causes of the Self-serving Bias. Social and Personality Psychology Compass 2, 2\n(2008), 895‚Äì908. https://doi.org/10.1111/j.1751-9004.2008.00078.x _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1751-9004.2008.00078.x.\n[81] C. Estelle Smith, Bowen Yu, Anjali Srivastava, Aaron Halfaker, Loren Terveen, and Haiyi Zhu. 2020. Keeping Community in the Loop: Understanding\nWikipedia Stakeholder Values for Machine Learning-Based Systems. In Proceedings of the 2020 CHI Conference on Human Factors in Computing\nSystems (CHI ‚Äô20) . Association for Computing Machinery, New York, NY, USA, 1‚Äì14. https://doi.org/10.1145/3313831.3376783\n[82] Adam Stefanile. 2020. The transition from classroom to Zoom and how it has changed education. Journal of social science research 16, 7 (2020),\n33‚Äì40. https://doi.org/10.24297/jssr.v16i.8789\n[83] Douglas Stone and Sheila Heen. 2015. Thanks for the Feedback: The Science and Art of Receiving Feedback Well . Penguin. Google-Books-ID:\nN7gBDAAAQBAJ.\n[84] Kate Sukhanova. 2023. Zooming in: Latest Zoom Statistics & Trends for 2023. https://techreport.com/statistics/software-web/zoom-statistics-trends/\n[85] Barnabas Szaszi, Anna Palinkas, Bence Palfi, Aba Szollosi, and Balazs Aczel. 2018. A Systematic Scoping Review of the Choice Architecture Movement:\nToward Understanding When and Why Nudges Work.Journal of Behavioral Decision Making 31, 3 (2018), 355‚Äì366. https://doi.org/10.1002/bdm.2035\n_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bdm.2035.\n[86] Anna-Lisa Vollmer, Robin Read, Dries Trippas, and Tony Belpaeme. 2018. Children conform, adults resist: A robot group induced peer pressure\non normative social conformity. Science Robotics 3, 21 (Aug. 2018), eaat7111. https://doi.org/10.1126/scirobotics.aat7111 Publisher: American\nAssociation for the Advancement of Science.\n[87] Nerys Williams. 2021. Working through COVID-19: ‚ÄòZoom‚Äô gloom and ‚ÄòZoom‚Äô fatigue. Occupational Medicine 71, 3 (April 2021), 164. https:\n//doi.org/10.1093/occmed/kqab041\n[88] Xingjiao Wu, Luwei Xiao, Yixuan Sun, Junhang Zhang, Tianlong Ma, and Liang He. 2022. A survey of human-in-the-loop for machine learning.\nFuture Generation Computer Systems 135 (2022), 364‚Äì381.\n[89] Fabio Massimo Zanzotto. 2019. Human-in-the-loop artificial intelligence. Journal of Artificial Intelligence Research 64 (2019), 243‚Äì252.\n28\nObserve, Ask, Intervene CHI ‚Äô25, April 26 - May 1, 2025, Yokohama, Japan\nA APPENDIX\nConstruct M (control) SD (control) M (treatment) SD (treatment) df t p\nCommunication 8.45 3.37 6.18 2.96 55.90 2.89 **0.005\nDiscussion Quality 17.24 2.18 17.10 2.62 65.11 0.24 0.81\nStatus Effects 7.83 3.75 6.05 2.84 50.19 2.14 *0.04\nTeamwork 12.38 1.86 12.90 1.79 59.15 -1.15 0.25\nEfficiency 7.69 1.39 8.92 1.26 57.09 -3.76 ***0.0004\nTable S1. Same as Table 2, but with the modified Efficiency construct (using only questions E2 and E3) included. Welch‚Äôs two sample\nùë°-tests of user assessments on the five meeting quality constructs in Davison [25]. Participants who had the co-host present rated\nmeetings better on all but one construct. 5-point Likert scale responses were summed within each construct to derive a corresponding\nvalue for each participant. Note that some of the constructs are worded positively while others are worded negatively [25, see A.1], so\nthe ‚Äúbetter‚Äù mean value for each row is indicated in bold.\nConstruct M (control) SD (control) M (treatment) SD (treatment) df t p\nCommunication 8.45 3.37 5.71 2.52 41.22 3.14 **0.003\nDiscussion Quality 17.24 2.18 17.05 2.30 32.17 0.26 0.79\nStatus Effects 7.83 3.75 5.47 1.62 41.37 2.94 **0.005\nTeamwork 12.38 1.86 13.35 1.58 38.18 -1.89 0.07\nEfficiency 7.69 1.39 9.06 1.03 41.46 -3.81 ***0.0005\nTable S2. Same as Table 2, but with the modified Efficiency construct (using only questions E2 and E3) included and excluding\ntreatment groups where the virtual co-host intervened. Welch‚Äôs two sample ùë°-tests of user assessments on the five meeting quality\nconstructs in Davison [25]. Participants who had the co-host present rated meetings better on all but one construct, even if we\nonly look at meetings where the co-host did not intervene. 5-point Likert scale responses were summed within each construct to\nderive a corresponding value for each participant. Note that some of the constructs are worded positively while others are worded\nnegatively [25, see A.1], so the ‚Äúbetter‚Äù mean value for each row is indicated in bold.\nReceived 12 September 2024; revised 10 December 2024; accepted 16 January 2025\n29",
  "topic": "Ask price",
  "concepts": [
    {
      "name": "Ask price",
      "score": 0.7632699608802795
    },
    {
      "name": "Formative assessment",
      "score": 0.7285937070846558
    },
    {
      "name": "Inclusion (mineral)",
      "score": 0.6353391408920288
    },
    {
      "name": "Session (web analytics)",
      "score": 0.627098798751831
    },
    {
      "name": "Computer science",
      "score": 0.5207421779632568
    },
    {
      "name": "Exploratory research",
      "score": 0.4466113746166229
    },
    {
      "name": "Intervention (counseling)",
      "score": 0.4456496834754944
    },
    {
      "name": "Ideation",
      "score": 0.43220263719558716
    },
    {
      "name": "Psychology",
      "score": 0.4065375328063965
    },
    {
      "name": "Human‚Äìcomputer interaction",
      "score": 0.3414287567138672
    },
    {
      "name": "Medical education",
      "score": 0.3249460458755493
    },
    {
      "name": "World Wide Web",
      "score": 0.20431244373321533
    },
    {
      "name": "Social psychology",
      "score": 0.19765865802764893
    },
    {
      "name": "Pedagogy",
      "score": 0.18230921030044556
    },
    {
      "name": "Sociology",
      "score": 0.1351507604122162
    },
    {
      "name": "Medicine",
      "score": 0.0
    },
    {
      "name": "Psychiatry",
      "score": 0.0
    },
    {
      "name": "Economy",
      "score": 0.0
    },
    {
      "name": "Cognitive science",
      "score": 0.0
    },
    {
      "name": "Anthropology",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I130238516",
      "name": "University of Minnesota",
      "country": "US"
    }
  ],
  "cited_by": 2
}