{
  "title": "GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models",
  "url": "https://openalex.org/W4395101324",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4315181820",
      "name": "Pawan Rajpoot",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2490046946",
      "name": "Ankur Parikh",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2970771982",
    "https://openalex.org/W4287891464",
    "https://openalex.org/W4385571076",
    "https://openalex.org/W4320839455",
    "https://openalex.org/W4308900200",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W3118781290",
    "https://openalex.org/W3156012351",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4389523710",
    "https://openalex.org/W4385567149",
    "https://openalex.org/W2998702515",
    "https://openalex.org/W3192478068",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W4323697341",
    "https://openalex.org/W4385571645",
    "https://openalex.org/W4378942219",
    "https://openalex.org/W4292779060"
  ],
  "abstract": "Relation extraction (RE) is a crucial task in natural language processing (NLP) that aims to identify and classify relationships between entities mentioned in text. In the financial domain, relation extraction plays a vital role in extracting valuable information from financial documents, such as news articles, earnings reports, and company filings. This paper describes our solution to relation extraction on one such dataset REFinD. The dataset was released along with shared task as a part of the Fourth Workshop on Knowledge Discovery from Unstructured Data in Financial Services, co-located with SIGIR 2023. In this paper, we employed OpenAI models under the framework of in-context learning (ICL). We utilized two retrieval strategies to find top K relevant in-context learning demonstrations / examples from training data for a given test example. The first retrieval mechanism, we employed, is a learning-free dense retriever and the other system is a learning-based retriever. We were able to achieve 3rd rank overall. Our best F1-score is 0.718.",
  "full_text": "Proceedings of the Sixth Workshop on Financial Technology and Natural Language Processing, pages 42–45\nNovember 1, 2023. ©2023 Association for Computational Linguistics\n42\nGPT-FinRE: In-context Learning for Financial\nRelation Extraction using Large Language Models\nPawan Kumar Rajpoot∗∗\npawan.rajpoot2411@gmail.com\nMUST Research\nBangalore, Karnataka, India\nAnkur Parikh\nankur.parikh85@gmail.com\nUtilizeAI Research\nBangalore, Karnataka, India\nAbstract\nRelation extraction (RE) is a crucial task in natural lan-\nguage processing (NLP) that aims to identify and classify\nrelationships between entities mentioned in text. In the\nfinancial domain, relation extraction plays a vital role in\nextracting valuable information from financial documents,\nsuch as news articles, earnings reports, and company fil-\nings. This paper describes our solution to relation extrac-\ntion on one such dataset REFinD. The dataset was released\nalong with shared task as a part of the Fourth Workshop\non Knowledge Discovery from Unstructured Data in Fi-\nnancial Services, co-located with SIGIR 2023. In this paper,\nwe employed OpenAI models under the framework of in-\ncontext learning (ICL). We utilized two retrieval strategies\nto find top K relevant in-context learning demonstrations /\nexamples from training data for a given test example. The\nfirst retrieval mechanism, we employed, is a learning-free\ndense retriever and the other system is a learning-based\nretriever. We were able to achieve 3rd rank overall (model\nperformance and report). Our best F1-score is 0.718.\nKeywords: relationship extraction, gpt, in context learn-\ning, text tagging, REFinD, KDF, SIGIR, CEIL, ICL, In Con-\ntext Learning, GPT NEO, Finance, Large Language Model\nACM Reference Format:\nPawan Kumar Rajpoot and Ankur Parikh. 2023. GPT-FinRE: In-\ncontext Learning for Financial Relation Extraction using Large\nLanguage Models. In Proceedings of The 4th Workshop on Knowl-\nedge Discovery from Unstructured Data in Financial Services (KDF\n@SIGIR ’23).ACM, New York, NY, USA, 4 pages.https://doi.org/\n10.1145/nnnnnnn.nnnnnnn\n1 Introduction\nThe emergence of large language models (LLMs) such as\nGPT-3 [6][12] represents a significant advancement in nat-\nural language processing (NLP). These models have ex-\npertise in variety of domains and hence they can be used\n∗Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies\nare not made or distributed for profit or commercial advantage and that\ncopies bear this notice and the full citation on the first page. Copyrights\nfor components of this work owned by others than ACM must be honored.\nAbstracting with credit is permitted. To copy otherwise, or republish, to\npost on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nKDF @SIGIR ’23, July 27, 2023, Taipei, Taiwan\n© 2023 Association for Computing Machinery.\nACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\nFigure 1. Relation Extraction example, here both organi-\nzations are connected with \"acquired by\" relation.\nas it is in multiple NLP tasks. Traditionaly language mod-\nels use separate pre-training-and fine-tuning pipelines [1]\n[3] [5] [4] [9] where fine-tune stage follows pre-training.\nModels are fine-tuned on a task-specific dataset in a fully-\nsupervised manner. More recently a new paradigm known\nas in-context learning (ICL) [6][14] is being used which\nformulates an NLP task such that LLMs make predictions\nby learning from demonstrations. These demonstrations\nare presented to the LLMs in the context prompt itself.\nUnder the framework of ICL, LLMs achieve remarkable\nperformance rivaling previous fully-supervised methods\neven with only a limited number of demonstrations pro-\nvided in the prompt in various tasks such as solving math\nproblems, commonsense reasoning, text classification, fact\nretrieval, natural language inference, and semantic parsing\n[6] [14] [8]. Recently, ICL based approach[16] is utilized for\nRelation Extraction (RE) task. RE seeks to identify a seman-\ntic relationship between a given entity pair mentioned in a\nsentence, which is the central task for knowledge retrieval\nrequiring a deep understanding of natural language. The\napproach achieves improvements over not only existing\nGPT-3 baselines, but also on fully-supervised baselines.\nSpecifically, it achieves SOTA performances on the Se-\nmeval and SciERC datasets, and competitive performances\non the TACRED and ACE05 datasets.\nRetrieval of examples to demonstrate is a key factor\nin the overall performance on these pipelines. LLMs can\nrelate to the presented \"to be predicted\" data point more if\nthe contextual examples predicted are similar to it. More\nrelevant examples help us to leverage more out from LLMs\nboth in terms of improvement in performance and less\nhallucination as examples can demonstrate model not to\nhallucinate in some cases.\nIn this paper, we employed GPT-3.5 Turbo and GPT-4\nunder the framework of ICL for the relation extraction task\non REFinD dataset. We utilized two retrieval strategies to\nfind top K relevant in-context learning demonstrations\n/ examples from training data for a given test example.\nThe first mechanism we have employed is a learning-free\ndense retriever. The other system we have utilized is a\nlearning-based retriever [13].\n43\nKDF @SIGIR ’23, July 27, 2023, Taipei, Taiwan Pawan Kumar Rajpoot and Ankur Parikh\nFigure 2. REFinD dataset relation and entity types.\n2 Preliminary Background\n2.1 Task Definition\nAs per the challenge \"Relation Extraction is the task of\nautomatically identifying and classifying the semantic re-\nlationships that exist between different entities in a given\ntext. \" This shared task is a part of \"Knowledge Discov-\nery from Unstructured Data in Financial Services\" (KDF)\nworkshop which is collocated with SIGIR 2023.\nLet C denote the input context and e1 in C, e2 in C\ndenote the pair of entity pairs. Given a set of predefined\nrelation classes R, relation extraction aims to predict the\nrelation y in R between the pair of entities (e1, e2) within\nthe context C, or if there is no predefined relation between\nthem, predict y=\"no relation\".\n2.2 Data\nThe dataset [18] released with this task is the largest re-\nlation extraction dataset for financial documents to date.\nOverall REFinD contains around 29K instances and 22 rela-\ntions among 8 types of entity pairs. REFinD is created using\nraw text from various 10-X reports (including 10-K, 10-Q,\netc. broadly known as 10-X) of publicly traded companies\nobtained from US Securities and Exchange Commission.\nFigure-2 shows different entity types and relations exist\nbetween them.\n2.3 In Context Learning\nIn-context learning (ICL) refers to one of the core emergent\nabilities [17] that infers new tasks from context. We use\nthe terms ’in-weights learning’ and ’in-context learning’\nfrom prior work on sequence models [6] to distinguish be-\ntween gradient-based learning with parameter updates and\ngradient-free learning from context, respectively. Formally,\neach training instance is first linearized into an input text x\n= (x1...xn ) and an output text y = (y1...yn), where for all to-\nkens x1...xn, y1...yn in V and V is the vocabulary set of the\nLM. Given a new test input text x-test, in-context learning\ndefines the generation of output y as y-test ∼ PLM(y-test |\nx1,y1,...,xk,yk, x-test), where ∼ refers to decoding strate-\ngies (e.g., greedy decoding and nuclear sampling [11]), and\neach in-context example ei= (xi,yi) is sampled from a train-\ning set D. The generation procedure is especially attractive\nas it eliminates the need for updating the parameters of the\nlanguage model when encountering a new task, which is\noften expensive and impractical. Notably, the performance\nof ICL on downstream tasks can vary from almost random\nto comparable with state-of-the-art systems, depending\non the quality of the retrieved in-context examples [ 13]\n[10] [19].\n3 GPT-FinRE\nGPT-RE is formalized under the ICL framework, using GPT\nmodels as shown in Figure-3.\n3.1 Prompt Construction\nWe construct a prompt for each given test example,which\nis fed to the GPT models. Each prompt consists of the\nfollowing components.\nTask Description and Predefined Classes : We provide\na succinct overview of the RE task description and the\nsubset of predefined classes R, denoted by O. This subset is\nall possible relations exist between entity types of e1 and\ne2. The model is explicitly asked to output the relation,\nwhich belongs to the O. Otherwise, the model will output\n\"no relation\".\nK-shot Demonstrations : In the demonstration part, we\nreformulate each example by first showing the input prompt\nx-demo = Prompt(C, e1, e2) and the relation label y-demo.\nTest Input : Similar to the demonstrations, we offer the\ntest input prompt x-test, and GPT models are expected to\ngenerate the corresponding relation y-test.\n3.2 Retrieval Systems\nWe have employed two retrieval strategies to find top K\nrelevant in-context learning demonstrations / examples\nfrom training data for a given test example.\n3.2.1 KNN with OpenAI Embeddings. Since ICL demon-\nstrations closer to the test sample in the embedding space\nresult in more consistent and robust performance [10]. We\nutilized the KNN to retrieve the most similar examples in\nthe training set as the few-shot demonstrations for each\ntest example. As this learning-free dense retriever relies\non the choice of the embedding space, we used OpenAI\nembeddings (text-embedding-ada-002) to obtain example\nrepresentations. For similarity search, we used FAISS tool\n[2].\n3.2.2 EPR (Efficient Prompt Retrieval). This learning-\nbased dense retriever is trained to retrieve a better single-\nton in-context example [13] , and Top-K most similar ex-\namples are selected in the inference stage. This method for\nretrieving prompts for in-context learning uses annotated\ndata and a LM. Given an input-output pair, it estimates\n44\nGPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models KDF @SIGIR ’23, July 27, 2023, Taipei, Taiwan\nRetriever LLM F1-Score\nKNN with openAI embeddings GPT 3.5 Turbo (Examples: 5 retrieved\n+ 5 random per possible relation)\n0.643\nKNN with openAI embeddings GPT 4 (Examples: 5 retrieved + 5 ran-\ndom per possible relation)\n0.697\nEPR with GPT-Neo-2.7B GPT 4 (Examples: 2 retrieved + 3 ran-\ndom per possible relation)\n0.703\nEPR with GPT-Neo-2.7B GPT 4 (Examples: 5 retrieved + 4 ran-\ndom per possible relation)\n0.718\nTable 1. Our performance on test data with different combinations of retriever and LLM\nthe probability of the output given the input and a candi-\ndate training example as the prompt, and labels training\nexamples as positive or negative based on this probability.\nIt then trains an efficient dense retriever from this data,\nwhich is used to retrieve training examples as prompts at\ntest time. Due to limited access to OpenAI, we have used\nthe gpt-neo-2.7B model [7] as our choice of LM.\n3.2.3 Random Class Examples. Along with KNN /\nEPR based examples, we also added K examples randomly\nfor each possible class between two entity types to add\nmore variety in the final prompt.\n4 Experiments\nDue to limited access and cost associated with OpenAI,\nWe performed 4 primary experiments on the test dataset.\nWe tried various rule based heuristics to improve the F1-\nscore, but it didn’t work as expected. We used retriever\nimplementations from 1 .\n5 Results\nThe results are shown in Table-1. Our best F1-Score is 0.718.\nWe got 4th position in the shared-task. We find that GPT\n4 performs better than GPT 3.5 Turbo. We also find that\nlearning based retriever (EPR) outperforms learning-free\nretriever (KNN with OpenAI embeddigs).\n6 Future Work\nIn future we want to utilize GPT 4 for EPR. We also want to\nuse different retrieval approaches such as Compositional\nExemplars for In-context Learning (CEIL)[15].\n7 Conclusion\nThis work explores the potential of GPT + ICL on Finan-\ncial Relation Extraction (REFinD dataset). We used two\nretrieval mechanisms to find similar examples: (1) KNN\nwith OpenAI Embeddings (2) EPR. We tried two different\nGPT models: (1) GPT 3.5 Turbo and GPT 4. The experimen-\ntal results show that GPT 4 with learning based retriever\nEPR is giving the best F1-Score of 0.718.\nReferences\n[1] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.\n2019. BERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding. In Proceedings of the 2019 Conference of the\n1https://github.com/HKUNLP/icl-ceil\nNorth American Chapter of the Association for Computational Linguis-\ntics: Human Language Technologies, Volume 1 (Long and Short Papers).\nAssociation for Computational Linguistics, Minneapolis, Minnesota,\n4171–4186. https://doi.org/10.18653/v1/N19-1423\n[2] Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019. Billion-scale\nsimilarity search with GPUs. IEEE Transactions on Big Data7, 3\n(2019), 535–547.\n[3] Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: A Pretrained\nLanguage Model for Scientific Text. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language Processing and the\n9th International Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP). Association for Computational Linguistics, Hong\nKong, China, 3615–3620. https://doi.org/10.18653/v1/D19-1371\n[4] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gim-\npel, Piyush Sharma, and Radu Soricut. 2020. ALBERT: A Lite\nBERT for Self-supervised Learning of Language Representations.\narXiv:1909.11942 [cs.CL]\n[5] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\nNarang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020.\nExploring the Limits of Transfer Learning with a Unified Text-to-Text\nTransformer. arXiv:1910.10683 [cs.LG]\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D\nKaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam,\nGirish Sastry, Amanda Askell, et al . 2020. Language models are\nfew-shot learners. Advances in neural information processing systems\n33 (2020), 1877–1901.\n[7] Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe,\nCharles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima,\net al. 2020. The Pile: An 800GB Dataset of Diverse Text for Language\nModeling. arXiv preprint arXiv:2101.00027(2020).\n[8] Richard Shin, Christopher H. Lin, Sam Thomson, Charles Chen,\nSubhro Roy, Emmanouil Antonios Platanios, Adam Pauls, Dan Klein,\nJason Eisner, and Benjamin Van Durme. 2021. Constrained Language\nModels Yield Few-Shot Semantic Parsers.CoRR abs/2104.08768 (2021).\narXiv:2104.08768 https://arxiv.org/abs/2104.08768\n[9] Liu Zhuang, Lin Wayne, Shi Ya, and Zhao Jun. 2021. A Robustly Opti-\nmized BERT Pre-training Approach with Post-training. InProceedings\nof the 20th Chinese National Conference on Computational Linguistics.\nChinese Information Processing Society of China, Huhhot, China,\n1218–1227. https://aclanthology.org/2021.ccl-1.108\n[10] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence\nCarin, and Weizhu Chen. 2021. What Makes Good In-Context Ex-\namples for GPT-3? CoRR abs/2101.06804 (2021). arXiv:2101.06804\nhttps://arxiv.org/abs/2101.06804\n[11] Xiang Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eis-\nner, Tatsunori Hashimoto, Luke Zettlemoyer, and Mike Lewis. 2022.\nContrastive decoding: Open-ended text generation as optimization.\narXiv preprint arXiv:2210.15097(2022).\n[12] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer,\nApoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie\nBaker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin\nGhafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry\nLepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen,\nAdam Roberts, Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-\nChing Chang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh\n45\nKDF @SIGIR ’23, July 27, 2023, Taipei, Taiwan Pawan Kumar Rajpoot and Ankur Parikh\nFigure 3. GPT-FinRE pipeline flow\nSrinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel\nMorris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny So-\nraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben\nHutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John,\nJosh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew\nLamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bern-\nstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak,\nEd Chi, and Quoc Le. 2022. LaMDA: Language Models for Dialog\nApplications. arXiv:2201.08239 [cs.CL]\n[13] Ohad Rubin, Jonathan Herzig, and Jonathan Berant. 2022. Learning\nTo Retrieve Prompts for In-Context Learning. In Proceedings of the\n2022 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies. Associa-\ntion for Computational Linguistics, Seattle, United States, 2655–2671.\nhttps://doi.org/10.18653/v1/2022.naacl-main.191\n[14] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis,\nHannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Rethinking the\nRole of Demonstrations: What Makes In-Context Learning Work?\narXiv preprint arXiv:2202.12837(2022).\n[15] Jiacheng Ye, Zhiyong Wu, Jiangtao Feng, Tao Yu, and Lingpeng\nKong. 2023. Compositional Exemplars for In-context Learning. (2023).\narXiv:2302.05698 [cs.CL]\n[16] Zhen Wan, Fei Cheng, Zhuoyuan Mao, Qianying Liu, Haiyue Song,\nJiwei Li, and Sadao Kurohashi. 2023. Gpt-re: In-context learning\nfor relation extraction using large language models. arXiv preprint\narXiv:2305.02105 (2023).\n[17] Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng\nLu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, et al. 2023.\nLarger language models do in-context learning differently. arXiv\npreprint arXiv:2303.03846(2023).\n[18] Simerjot Kaur, Charese Smiley, Akshat Gupta, Joy Sain, Dongsheng\nWang, Suchetha Siddagangappa, Toyin Aguda, and Sameena Shah.\n2023. REFinD: Relation Extraction Financial Dataset. arXiv preprint\narXiv:2305.18322 (2023).\n[19] Zhiyong Wu, Yaoxiang Wang, Jiacheng Ye, and Lingpeng Kong.\n2023. Self-Adaptive In-Context Learning: An Information Compres-\nsion Perspective for In-Context Example Selection and Ordering.\narXiv:2212.10375 [cs.CL]",
  "topic": "Relationship extraction",
  "concepts": [
    {
      "name": "Relationship extraction",
      "score": 0.8301825523376465
    },
    {
      "name": "Computer science",
      "score": 0.7801542282104492
    },
    {
      "name": "Relation (database)",
      "score": 0.6971526145935059
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6684997081756592
    },
    {
      "name": "Task (project management)",
      "score": 0.6111428737640381
    },
    {
      "name": "Named-entity recognition",
      "score": 0.6082757115364075
    },
    {
      "name": "Information extraction",
      "score": 0.5719767212867737
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5703698992729187
    },
    {
      "name": "Natural language processing",
      "score": 0.5504404902458191
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.5436782240867615
    },
    {
      "name": "Rank (graph theory)",
      "score": 0.5219354629516602
    },
    {
      "name": "Machine learning",
      "score": 0.4768061339855194
    },
    {
      "name": "Information retrieval",
      "score": 0.46386948227882385
    },
    {
      "name": "Data mining",
      "score": 0.20493099093437195
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Combinatorics",
      "score": 0.0
    }
  ]
}