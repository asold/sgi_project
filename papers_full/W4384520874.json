{
  "title": "Harnessing Large Language Models for Cognitive Assistants in Factories",
  "url": "https://openalex.org/W4384520874",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4295965247",
      "name": "Samuel Kernan Freire",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3114474685",
      "name": "Mina Foosherian",
      "affiliations": [
        "Bremer Institut für Produktion und Logistik GmbH"
      ]
    },
    {
      "id": "https://openalex.org/A2108208485",
      "name": "Chaofan Wang",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2226758187",
      "name": "Evangelos Niforatos",
      "affiliations": [
        "Delft University of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3080659561",
    "https://openalex.org/W4319985185",
    "https://openalex.org/W2920473980",
    "https://openalex.org/W2748768308",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2604683081",
    "https://openalex.org/W4220681241",
    "https://openalex.org/W2091382943",
    "https://openalex.org/W4294786243",
    "https://openalex.org/W4387356888",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W2924494197",
    "https://openalex.org/W4295955345",
    "https://openalex.org/W4312969523",
    "https://openalex.org/W2996625406",
    "https://openalex.org/W2791936859",
    "https://openalex.org/W3217604899",
    "https://openalex.org/W3210314098",
    "https://openalex.org/W4317840265",
    "https://openalex.org/W2972387096",
    "https://openalex.org/W2278942097",
    "https://openalex.org/W2956009611",
    "https://openalex.org/W2967595425",
    "https://openalex.org/W4296064756",
    "https://openalex.org/W3198679462",
    "https://openalex.org/W3205172848",
    "https://openalex.org/W4225163310",
    "https://openalex.org/W4382652828"
  ],
  "abstract": "&lt;p&gt;As agile manufacturing expands and workforce mobility increases, the importance of efficient knowledge transfer among factory workers grows. Cognitive Assistants (CAs) with Large Language Models (LLMs), like GPT-3.5, can bridge knowledge gaps and improve worker performance in manufacturing settings. This study investigates the opportunities, risks, and user acceptance of LLM-powered CAs in two factory contexts: textile and detergent production. Several opportunities and risks are identified through a literature review, proof-of-concept implementation, and focus group sessions. Factory representatives raise concerns regarding data security, privacy, and the reliability of LLMs in high-stake environments. By following design guidelines regarding persistent memory, real-time data integration, security, privacy, and ethical concerns, LLM-powered CAs can become valuable assets in manufacturing settings and other industries. &lt;/p&gt;",
  "full_text": "  \nDelft University of Technology\nHarnessing Large Language Models for Cognitive Assistants in Factories\nKernan Freire, Samuel; Foosherian, Mina; Wang, Chaofan; Niforatos, Evangelos\nDOI\n10.1145/3571884.3604313\nPublication date\n2023\nDocument Version\nFinal published version\nPublished in\nProceedings of the 5th International Conference on Conversational User Interfaces, CUI 2023\nCitation (APA)\nKernan Freire, S., Foosherian, M., Wang, C., & Niforatos, E. (2023). Harnessing Large Language Models\nfor Cognitive Assistants in Factories. In Proceedings of the 5th International Conference on Conversational\nUser Interfaces, CUI 2023 Article 44 (Proceedings of the 5th International Conference on Conversational\nUser Interfaces, CUI 2023). ACM. https://doi.org/10.1145/3571884.3604313\nImportant note\nTo cite this publication, please use the final published version (if applicable).\nPlease check the document version above.\nCopyright\nOther than for strictly personal use, it is not permitted to download, forward or distribute the text or part of it, without the consent\nof the author(s) and/or copyright holder(s), unless the work is under an open content license such as Creative Commons.\nTakedown policy\nPlease contact us and provide details if you believe this document breaches copyrights.\nWe will remove access to the work immediately and investigate your claim.\nThis work is downloaded from Delft University of Technology.\nFor technical reasons the number of authors shown on this cover page is limited to a maximum of 10.\nHarnessing Large Language Models for Cognitive Assistants in \nFactories \nS. Kernan Freire \nDelft University of Technology \nDelft, The Netherlands \ns.kernanfreire@tudelft.nl \nMina Foosherian \nBIBA - Bremer Institut für Produktion und Logistik GmbH \nBremen, Germany \nfos@biba.uni-bremen.de \nC. Wang \nDelft University of Technology \nDelft, The Netherlands \nc.wang-16@tudelft.nl \nE. Niforatos \nDelft University of Technology \nDelft, Netherlands \ne.niforatos@tudelft.nl \nABSTRACT \nAs agile manufacturing expands and workforce mobility increases, \nthe importance of efficient knowledge transfer among factory work-\ners grows. Cognitive Assistants (CAs) with Large Language Mod-\nels (LLMs), like GPT-3.5, can bridge knowledge gaps and improve \nworker performance in manufacturing settings. This study investi-\ngates the opportunities, risks, and user acceptance of LLM-powered \nCAs in two factory contexts: textile and detergent production. Sev-\neral opportunities and risks are identified through a literature re-\nview, proof-of-concept implementation, and focus group sessions. \nFactory representatives raise concerns regarding data security, pri-\nvacy, and the reliability of LLMs in high-stake environments. By \nfollowing design guidelines regarding persistent memory, real-\ntime data integration, security, privacy, and ethical concerns, LLM-\npowered CAs can become valuable assets in manufacturing settings \nand other industries. \nCCS CONCEPTS \n• Human-centered computing → Human computer interac-\ntion (HCI); Natural language interfaces; • Computing method-\nologies → Natural language generation; • Information sys-\ntems → Users and interactive retrieval; • Applied computing \n→ Industry and manufacturing. \nKEYWORDS \ncognitive assistant, conversational user interfaces, knowledge man-\nagement, industry 5.0, human-centered AI, knowledge sharing \nACM Reference Format: \nS. Kernan Freire, Mina Foosherian, C. Wang, and E. Niforatos. 2023. Har-\nnessing Large Language Models for Cognitive Assistants in Factories. In \nACM conference on Conversational User Interfaces (CUI ’23), July 19–21, \n2023, Eindhoven, Netherlands. ACM, New York, NY, USA, 6 pages. https: \n//doi.org/10.1145/3571884.3604313 \nPermission to make digital or hard copies of part or all of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed \nfor profit or commercial advantage and that copies bear this notice and the full citation \non the first page. Copyrights for third-party components of this work must be honored. \nFor all other uses, contact the owner/author(s). \nCUI ’23, July 19–21, 2023, Eindhoven, Netherlands \n© 2023 Copyright held by the owner/author(s). \nACM ISBN 979-8-4007-0014-9/23/07. \nhttps://doi.org/10.1145/3571884.3604313 \n1 INTRODUCTION \nIn the era of Industry 5.0 [38], the complexities of agile production \nlines and a highly mobile workforce have emphasized the need for \nefficient knowledge sharing among factory workers. Knowledge \nmanagement has become a critical aspect of modern manufacturing \nenvironments, and leveraging technology to facilitate this process \nis paramount. One emerging solution is using Cognitive Assistants \n(CAs), which can empower productivity and bridge knowledge \ngaps by learning from experienced workers and sharing relevant \ninformation within the workplace [1, 2, 20]. \nEnhancing CAs with Large Language Models (LLMs), such as \nGPT-3.5, offers numerous opportunities to improve their abilities in \nknowledge sharing and support across various domains. This paper \nexplores the opportunities, barriers, and user acceptance of CAs \npowered by GPT-3.5 in manufacturing settings. We conducted a lit-\nerature review, designed, developed, and tested a proof-of-concept \nfor two factory contexts, and collaborated with factory representa-\ntives through focus group sessions to gain insights into the percep-\ntions and expectations of LLM-empowered CAs in manufacturing. \n2 LITERATURE REVIEW \n2.1 Cognitive Assistants and Their Applications \nCognitive assistants, unlike systems designed to replace humans \nin specific tasks (e.g., industrial robots), aim to augment human \ncapabilities in complex tasks, such as supporting lifelong educa-\ntion and machine operation [1, 2, 20]. These assistants often excel \nin efficient communication, reliably and consistently interacting \nwith multiple users simultaneously [1, 2]. To achieve these goals, \ncognitive assistants should facilitate efficient human-machine inter-\naction through natural language processing, gesture interpretation, \nperception, vision, sound recognition, augmented reality, and other \ntechniques [1, 2]. \nAmong these methods, conversational agent-based natural lan-\nguage communication is the most prevalent interaction technique \nfor cognitive assistants, encompassing natural language under-\nstanding, generation, and dialogue [1]. Conversational agents en-\ngage users in natural language and can efficiently perform labor-\nintensive tasks across various industries, such as customer service, \nhealthcare, education, e-banking, and personal assistance [7, 19, 23, \n40]. \n\nCUI ’23, July 19–21, 2023, Eindhoven, Netherlands Kernan Freire \nIndustrial applications of cognitive assistants, akin to Alexa, \nGoogle Assistant, or Siri, are an emerging research area. These \nprototypes have appeared under various names, such as intelligent \n(virtual/personal) assistants, digital assistants, software robots, or \nsimply chatbots. Cognitive assistants in manufacturing offer sig-\nnificant advantages, including centralized access to heterogeneous \ninformation systems, task delegation, and hands- and gaze-free \ninteractions during work [37]. Moreover, cognitive assistants can \nbe employed for on-the-job worker training [18] and for adjusting \nmachine parameters in simulations [22]. \n2.2 Leveraging Cognitive Assistants for \nKnowledge Sharing in Manufacturing \nSettings \nMuch of the literature concerning cognitive assistants in manu-\nfacturing emphasizes knowledge and information delivery. Exam-\nples include context-aware assistance [12], predictive maintenance \nrecommendations [36], and decision support based on shop-floor \ndata analytics [3, 27]. For instance, Rodriguez et al. [29] present a \nmixed reality assistance system for real-time assembly operations. \nThe system evaluates the operation context using a recognition \nsystem that identifies the completion of each assembly step to \ngenerate the subsequent instruction. Belkadi et al. [6] propose a \ncontext-aware, knowledge-based system to support manufacturing \noperators by integrating knowledge management, context man-\nagement, and simulation management modules, aiding real-time \nworker decision-making. Similar to Rodriguez et al. [29], context \nmanagement obtains contextual information to comprehend the \nuser’s situation and implements simulation techniques to anticipate \nthe effects of worker decisions. Büttner et al. [9] employ a hand-\ntracking algorithm to detect incorrect picking actions and assembly \nprocess errors. Tao et al. [33] utilize wearable and environmental \nsensing devices to capture worker activity, guiding task execution. \nJosifovska et al. [16] incorporate a context manager module, includ-\ning a human digital twin, to simulate specific human abilities and \npreferences. \nThe literature has also explored knowledge acquisition from \nworkers, albeit to a significantly lesser degree. However, we be-\nlieve that it is crucial for cognitive assistants’ long-term success on \nthe shop floor. Technological probes have shown that supporting \nworkers to think aloud can result in the creation of high-quality \nreports from which knowledge can be extracted [17]. Fenoglio et al. \n[11] suggest a system for capturing explicit and tacit knowledge \n(through best practices) from experienced industrial workers, em-\nploying a role-playing game where a virtual agent interacts with \nhuman experts and knowledge engineers to iteratively extract and \nrepresent knowledge. Although the system can capture tacit knowl-\nedge, it requires human intervention. Fully capturing tacit knowl-\nedge (typically nonverbal and unexpressed) with a purely algorith-\nmic approach is deemed impossible by Fenoglio et al. [11]. Similarly, \nSoliman and Vanharanta [30] propose a knowledge creation and \nretention model using artificial intelligence, but no practical applica-\ntion has been reported in the literature. Hoerner et al. [13] suggest \na digital assistance system to support operator troubleshooting \nprocesses on the shop floor, developing a method for capturing and \nstructuring expert tacit knowledge. However, this method is not \napplied by the digital assistant but by human knowledge managers \nresponsible for extracting, representing, and delivering the acquired \nknowledge as the system input. Interestingly, state-of-the-art nat-\nural language processing (NLP) techniques, such as recent large \nmodel Models (LLM), may be powerful enough to (partially) fulfil \nthe role of knowledge manager. \n2.3 Large Language Models \nLarge language models have recently garnered substantial interest \nin the field of natural language processing and beyond. Scaling up \nLLMs, for instance, by augmenting model parameters, enhances per-\nformance and sample efficiency across diverse NLP tasks [35]. More-\nover, bigger LLMs exhibit emergent capabilities absent in smaller \ncounterparts [35]. One notable ability is zero-shot prompting, in \nwhich a pre-trained language model can tackle tasks using natural \nlanguage instructions as prompts without additional training or \nparameter adjustments [8, 35]. LLMs also demonstrate remarkable \nfew-shot prompting or in-context learning skills, where the model \nimproves performance on a downstream task by conditioning on a \nprompt containing input-output examples [35]. Leveraging zero-\nshot/few-shot prompting, companies can craft custom prompts to \ngenerate responses tailored to their requirements. Furthermore, \nseveral LLMs can integrate other NLP tasks, such as text translation \nand simplification, to better address user needs. \nLLMs’ pre-training on large-scale, mixed-source corpora enables \nthem to capture extensive knowledge from the data [39]. As a \nresult, recent research has focused on utilizing LLMs for domain-\nspecific tasks and assessing their adaptability [39]. Various studies \nhave investigated the application of GPT-3.5 and other LLMs in \nthe medical field, encompassing areas such as biological informa-\ntion extraction [32], medical consultation advice [25], and report \nsimplification [14, 39]. Concurrently, multiple empirical studies \nhave shown LLMs to be effective writing or reading assistants in \neducational contexts [5, 24, 39]. Furthermore, several studies have \nemployed LLMs to address diverse legal tasks, including legal docu-\nment analysis, judgment prediction, and document writing [34, 39]. \nHowever, LLMs may generate text that is semantically plausi-\nble and syntactically correct but factually wrong, a phenomenon, \nknown as “hallucination” [4]. The suitability of the term hallucina-\ntion is questionable as it might imply changes in one’s perceptual \nexperience, which LLMs do not have. However, considering its \nwidespread adoption, we will continue to use this term in this \npaper for clarity. Ji et al. [15] differentiate intrinsic and extrinsic \nhallucinations in natural language generation. The former term \nrefers to contradictions between source material (e.g., training data \nand prompts), whereas extrinsic hallucinations refer to information \nthat cannot be verified by the source material. Whereas intrinsic \nhallucinations are clearly erroneous, extrinsic hallucinations can \nstill be an issue in high-stake contexts where all outputs should be \nverifiable. \n2.4 Exploring Large Language Models for \nDomain-Specific Knowledge Sharing \nIn order to augment an LLM with domain-specific or custom knowl-\nedge, two main strategies exist. The first method, fine-tuning, in-\nvolves training the model further using a custom data set [28]. \nHarnessing Large Language Models for Cognitive Assistants in Factories CUI ’23, July 19–21, 2023, Eindhoven, Netherlands \nHowever, such models might struggle to effectively use the con-\ntext surrounding entities, resulting in limitations when fine-tuning \non smaller domain-specific data sets [10]. Moreover, while fine-\ntuning can achieve high accuracy and comprehensiveness, it re-\nquires significant time and resources for both training and hosting \nthe custom model. Alternatively, in-context learning offers relevant \ninformation from the custom data set in connection with the user \nquery during the query process, thus improving the model’s per-\nformance [21]. Lewis et al. [21] presented the retrieval-augmented \ngeneration (RAG) architecture, which operates similarly to a con-\nventional seq2seq model by taking a single sequence as input and \nproducing a corresponding output sequence. RAG enhances its per-\nformance by using the input to retrieve a set of pertinent documents \nfrom Wikipedia rather than directly passing the input directly to \nthe generator. \nIn addition to retrieving information from domain-specific or \ncustom databases, LLM-driven systems can create implicit data to \nenhance these databases further. Such a system powered by an LLM \ncould allow users to select question-and-answer pairs for inclusion \nor to submit questions that the assistants are unable to answer to \nthese databases [31]. Over time, LLM-driven systems will amass a \nconsiderable collection of answers and become increasingly adept \nas primary knowledge specialists. \nTo the best of our knowledge, no cognitive assistant currently \nexists that leverages an LLM and is specifically designed to tackle \ninherent weaknesses of LLMs, such as hallucinations, by learning \nfrom skilled workers and disseminating pertinent knowledge in \nmanufacturing settings. Consequently, we aim to investigate the \npossibilities, obstacles, and user receptiveness of cognitive assis-\ntants employing LLMs in the context of manufacturing. \n3 SYSTEM DESCRIPTION \nTo explore the potential of using LLMs to augment cognitive assis-\ntants in manufacturing, we built LLM-powered features for existing \ncognitive assistants. The assistants originate from two different \nmanufacturing contexts, namely textile and detergent production, \ncommunicating in Italian and Dutch, respectively. Both assistants \ncan be accessed in a smartphone application and feature a conver-\nsational user interface with speech and text capabilities for flexible \nuser interaction. In this section, we describe the architecture, com-\nponents, and user interaction related to the new LLM-powered \nfeatures. \n3.1 Manufacturing context \nThe assistant for the textile production context is designed to sup-\nport novice workers with basic tasks, for example, by answering \nFAQs about how to operate the looms or perform tasks such as knot-\nting. As such, the knowledge base upon which the assistant relies \nis relatively static. In contrast, the assistant for the detergent pro-\nduction context aims to share more complex knowledge between \nthe workers, for example, how to solve emergent issues with the \nproduction line. This type of knowledge is more likely to change \nover time as it is affected by raw ingredient quality, machine wear, \nand product characteristics. As such, it is important to continu-\nously incorporate newly discovered knowledge. The LLM-powered \nfeatures replace existing capabilities in the aforementioned assis-\ntants. Specifically, capabilities that originally provided issue support \nderived from past issue reports, and answering frequently asked \nquestions. \n3.2 Architecture and user interaction \nThe LLM-powered features are used to construct a multi-part prompt \nwhich is sent to the GPT-3.5 API1 . The prompts consist of a prede-\nfined system instruction, existing domain-specific texts, the user’s \nrequest, and query results from a knowledge graph (only for the \ndetergent production assistant, see Figure 1). \nPrompt \nSystem instructions \nDomain speciﬁc knowledge \nUser input \nResponse from Knowledge \nGraph Query* \nGPT3.5 API Query \nResponse presented to the user \nFigure 1: Prompt Engineering \nThe 150-word system instruction contains statements such as \n“You are a helpful assistant for factory workers”, “you provide concise \nanswers in a maximum of 50 words”, a general description of the \ninvolved machines and process. This is followed by the factory and \ndomain-specific information. In the case of the detergent factory, \nthis is 2,000 words of previously collected issue descriptions, ac-\ncounting for about 30 different issues. For the textile production \nassistant, we included the text from seven learning modules and \nten FAQ pairs. Then, we include the user’s input. For the detergent \nproduction assistant, the user is asked to provide a description of \nthe symptoms they observed, including the main machine compo-\nnent involved and the error code. This information is used to query \na knowledge graph for any previously recorded issue solutions. \nAny result is appended to the prompt. For the textile production \nassistant, we simply include the user’s question since a knowledge \ngraph is not available. \n1https://platform.openai.com/docs/guides/chat/introduction—last accessed June 8, \n2023 \nCUI ’23, July 19–21, 2023, Eindhoven, Netherlands Kernan Freire \nCA: Each weft thread passes \nthrough an eyelet of the \ndevice and under any \nalignment rods \nUser: How do   you pass \nthe weft threads through \nthe weft guard? \nFigure 2: A dialogue showing a user asking for task instruc-\ntions from the cognitive assistant (CA) \nUser: I need help with an \nissue. \nCA: Please provide a \ndescription of the symptoms \nyou've observed \nUser: The label machine is \nplacing crooked labels and \nreporting error 12 \nCA: I suggest resetting the \nlabel machine and tightening \nthe small bolt holding for the \nlabel tensioner. If this \ndoesn't solve the problem, \nplease contact technical \nservices for support. \nFigure 3: A dialogue showing a user requesting help with a \nmachine issue from the cognitive assistant (CA) \n4 EVALUATION METHOD \n4.1 User Study with Factory Representatives \nDuring the evaluation’s initial phase, we assessed the accuracy of \nthe LLM-powered features’ responses. We enlisted three represen-\ntatives from a detergent factory and two from a textile factory. In \nindividual sessions, participants posed various questions related to \ntheir production lines using the LLM-powered features and evalu-\nated the accuracy of the responses. The participants were free to \npose any questions they deemed fit, for example, how to solve a \nspecific issue at the production line or how to conduct a standard \noperating procedure. All participants had prior experience using \nnon-LLM-powered cognitive assistants. \n4.2 Feature Demonstration and Focus Group \nIn the evaluation’s second phase, we showcased the LLM-powered \nfeatures to 22 individuals, comprising representatives from three \ndifferent factories, developers, and researchers, including three \nparticipants from the first phase. Subsequently, we explored the \npotential advantages, drawbacks, and constraints of employing \nLLM-powered assistants in the targeted factories and the broader \nmanufacturing sector. All participants were familiar with cognitive \nassistants and the manufacturing context. \n5 RESULTS AND DISCUSSION \nOverall, the factory representatives were impressed by the accu-\nracy of the responses. Furthermore, they were satisfied with the \nrobustness of the system’s ability to interpret some of their (poorly \nphrased) questions, a common issue with non-LLM-powered cogni-\ntive assistants. However, they noted that they sometimes received \na generic response that was not useful. This usually occurred when \nthere was insufficient information provided in the prompt for that \nparticular topic. \nThe factory representatives expressed several concerns related \nto the use of such technology in manufacturing environments. One \nsignificant apprehension is the possibility of confidential infor-\nmation and proprietary knowledge being exposed to competitors \nthrough the LLM’s API and training corpus. This risk can jeopar-\ndize the competitive advantage of manufacturing companies and \ncompromise intellectual property. Furthermore, they did not want \nto have their company’s name or IP address associated with all \nprompts made by their employees, especially if it may somehow \nnegatively impact their company’s brand image. \nHowever, it should be noted that most of the participants initially \nbelieved that all the data sent to the API was being used by OpenAI \nto improve their model. After all, this is the case for the consumer-\nfacing, browser-based interface commonly known as chatGPT, al-\nbeit with an opt-out option2 . Conversely, the API follows an opt-in \nprotocol and does not use prompts for training purposes by default3 . \nDespite knowing this, many of the factory representatives were \ncautious of trusting another corporation with their data. As such, \nthey were more welcoming to using open-source, locally-hosted \nLLMs. These solutions could offer more control and privacy while \nmitigating potential risks and exposure to competitors. Although \nopen-source LLMs are available, such as LLaMa and its derivatives \nsuch as Alpaca, they pale in comparison to the abilities of GPT-\n3.5 and GPT-4. However, some experimentation with ChatGLM \nappears to be more promising. \nOne researcher pinpointed issues such as (artificial) hallucina-\ntions, elementary reasoning errors, privacy invasion, guarantees on \nrecommendations or correctness of explanations, and the danger of \nemploying LLMs where lives or money are on the line. For example, \nin the detergent factory where volatile chemicals are mixed. These \nconcerns further highlight the need for cautious and responsible \nimplementation of LLM-powered CAs in manufacturing settings to \nkeep potential risks and drawbacks in check. These points echo the \n2https://help.openai.com/en/articles/7039943-data-usage-for-consumer-services-\nfaq—last accessed June 8, 2023 \n3https://openai.com/policies/api-data-usage-policies—last accessed June 8, 2023 \nHarnessing Large Language Models for Cognitive Assistants in Factories CUI ’23, July 19–21, 2023, Eindhoven, Netherlands \nmain limitations that OpenAI [26] have outlined in their technical \nreport: \n(1) does not learn from experience \n(2) not fully reliable \n(3) limited context window \n(4) risks: bias, misinformation, over-reliance, privacy, cyber se-\ncurity, and more \nAll of these limitations are (partially) mitigated by providing \nthe assistant with persistent memory, for example, in the form of a \nknowledge graph as we demonstrated for the detergent business \ncase. This enables the assistant to access knowledge specifically for \nits context of use (e.g., a factory), learn from its users, and maxi-\nmize the potential of its context window by querying knowledge \nrelevant to the situation at hand. Ultimately, this will also improve \nthe reliability of its responses. Furthermore, if the user suspects \nthat the LLM is hallucinating, the cognitive assistant could bypass \nit and retrieve the raw data from the knowledge base for the user \nto check. \nFrom the perspective of the designers and developers of con-\nversational systems, using LLMs can greatly reduce the resources \nneeded for the development and maintenance of assistants as their \nfeatures do not have to be programmed in as much detail as it was \npreviously necessary (e.g., intent-based systems). \n6 DESIGN GUIDELINES \nTo maximize the effectiveness of LLM-powered CAs, the following \ndesign guidelines should be considered: \n• Integrate dynamic domain knowledge. Integrate per-\nsistent memory of domain knowledge for the assistant, for \nexample, in the form of a continuously expanding knowledge \nbase. Once the knowledge base becomes too large to fit in \none query, techniques such as semantic search can be used \nto select relevant documents. Documents can be indexed in \na vector form to facilitate semantic search. Additionally, the \noutcomes from prior queries can be saved to reduce both the \ncomputational and time expense by repeatedly prompting \nthe large language model (LLM) for the same question. \n• Supply real-time data. Seamless integration with exist-\ning factory systems and machine data can help the LLM \nmake contextual connections between the user’s question, \nthe current situation, and knowledge stored in its persis-\ntent memory (e.g., in a knowledge graph). Furthermore, this \nwould enable it to calculate production statistics and visual-\nize insights into graphs. \n• Provide transparency where possible and when requested. \nAlthough the output of the LLM cannot (yet) be explained, \nit is possible to report and explain the (hidden) contents of \nthe prompts. For example, responses from a knowledge base \nthat are included in the prompt could be exposed to the user \nto improve explainability. \n• Design for security and privacy. Addressing concerns \nabout data security and privacy is critical for user acceptance \nand trust in such systems. Solutions such as locally hosted \nLLMs can help alleviate these concerns. \n• Ethics Adopting LLM-powered cognitive assistants in man-\nufacturing settings raises ethical concerns, including the \npotential for hallucinations, lack of reliable explanations, \nand loss of intellectual property. These can have negative \nconsequences when applied in high-stake business environ-\nments. Therefore, it is imperative to maintain transparency \nregarding potential risks and limitations associated with \nLLM-powered CAs to mitigate these issues, allowing end-\nusers to make informed decisions on their use. \n• Collect feedback and evaluate. Regular evaluation and \nuser feedback should be incorporated into the system de-\nvelopment process to continuously refine and improve the \nLLM-powered feature of the cognitive assistant. \n7 CONCLUSION \nLLM-powered CAs hold promise for improving knowledge sharing \nand supporting various aspects of manufacturing processes. By ad-\ndressing challenges related to technical limitations, and ethical con-\ncerns, for example, by enabling persistent memory, LLM-powered \nCAs can become valuable assets in modern manufacturing environ-\nments and other industries. Nevertheless, considering the substan-\ntial potential of LLMs and the ongoing discovery of their extensive \nimpact, both favorable and unfavorable, it is imperative to engage \nin critical reflection prior to deployment. The aforementioned de-\nsign guidelines can serve as “reflection prompts” to facilitate this \nprocess. \nACKNOWLEDGMENTS \nThis work was supported by the European Union’s Horizon 2020 \nresearch and innovation program via the project COALA “COgni-\ntive Assisted agile manufacturing for a LAbor force supported by \ntrustworthy Artificial Intelligence” (Grant agreement 957296). \nREFERENCES \n[1] 2016. Intelligent Cognitive Assistants: Workshop Summary and Recommenda-\ntions. https://www.nsf.gov/crssprgm/nano/reports/2016-1003_ICA_Workshop_ \nFinal_Report_2016.pdf \n[2] 2018. Intelligent Cognitive Assistants: Workshop Summary and Research \nNeeds. https://www.nsf.gov/crssprgm/nano/reports/ICA2_Workshop_Report_ \n2018.pdf \n[3] Brunno Abner, Ricardo J. Rabelo, Saulo P. Zambiasi, and David Romero. 2020. \nProduction Management as-a-Service: A Softbot Approach. In Advances in \nProduction Management Systems. Towards Smart and Digital Manufacturing, Bojan \nLalic, Vidosav Majstorovic, Ugljesa Marjanovic, Gregor von Cieminski, and David \nRomero (Eds.). IFIP Advances in Information and Communication Technology, \nVol. 592. Springer International Publishing, Cham, 19–30. https://doi.org/10. \n1007/978-3-030-57997-5{_}3 \n[4] Hussam Alkaissi and Samy I McFarlane. 2023. Artificial hallucinations in Chat-\nGPT: implications in scientific writing. Cureus 15, 2 (2023). \n[5] Zeljana Basic, Ana Banovac, Ivana Kruzic, and Ivan Jerkovic. 2023. Better \nby you, better than me, chatgpt3 as writing assistance in students essays. \narXiv:2302.04536 [cs.AI] \n[6] Farouk Belkadi, Mohamed Anis Dhuieb, José Vicente Aguado, Florent Laroche, \nAlain Bernard, and Francisco Chinesta. 2020. Intelligent assistant system as a \ncontext-aware decision-making support for the workers of the future. Computers \n& Industrial Engineering 139 (Jan. 2020), 105732. https://doi.org/10.1016/j.cie. \n2019.02.046 \n[7] Luka Bradeško, Michael Witbrock, Janez Starc, Zala Herga, Marko Grobelnik, \nand Dunja Mladenić. 2017. Curious Cat–Mobile, Context-Aware Conversational \nCrowdsourcing Knowledge Acquisition. ACM Trans. Inf. Syst. 35, 4, Article 33 \n(aug 2017), 46 pages. https://doi.org/10.1145/3086686 \n[8] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, \nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda \nAskell, et al. 2020. Language models are few-shot learners. Advances in neural \ninformation processing systems 33 (2020), 1877–1901. \n[9] Sebastian Büttner, Oliver Sand, and Carsten Röcker. 2017. Exploring De-\nsign Opportunities for Intelligent Worker Assistance: A New Approach Using \nCUI ’23, July 19–21, 2023, Eindhoven, Netherlands Kernan Freire \nProjetion-Based AR and a Novel Hand-Tracking Algorithm. In Ambient Intel-\nligence (Lecture Notes in Computer Science), Andreas Braun, Reiner Wichert, \nand Antonio Maña (Eds.). Springer International Publishing, Cham, 33–45. \nhttps://doi.org/10.1007/978-3-319-56997-0_3 \n[10] Keyur Faldu, Amit Sheth, Prashant Kikani, and Hemang Akbari. 2021. KI-BERT: \nInfusing knowledge context for better language and domain understanding. arXiv \npreprint arXiv:2104.08145 (2021). \n[11] Enzo Fenoglio, Emre Kazim, Hugo Latapie, and Adriano Koshiyama. 2022. Tacit \nknowledge elicitation process for industry 4.0. Discover Artificial Intelligence 2, 1 \n(March 2022), 6. https://doi.org/10.1007/s44163-022-00020-w \n[12] Markus Funk, Tilman Dingler, Jennifer Cooper, and Albrecht Schmidt. 2015. \nStop Helping Me - I’m Bored! Why Assembly Assistance Needs to Be Adap-\ntive. In Adjunct Proceedings of the 2015 ACM International Joint Conference on \nPervasive and Ubiquitous Computing and Proceedings of the 2015 ACM Interna-\ntional Symposium on Wearable Computers (Osaka, Japan) (UbiComp/ISWC’15 \nAdjunct). Association for Computing Machinery, New York, NY, USA, 1269–1273. \nhttps://doi.org/10.1145/2800835.2807942 \n[13] Lorenz Hoerner, Markus Schamberger, and Freimut Bodendorf. 2022. Using Tacit \nExpert Knowledge to Support Shop-floor Operators Through a Knowledge-based \nAssistance System. Computer Supported Cooperative Work (CSCW) (Sept. 2022). \nhttps://doi.org/10.1007/s10606-022-09445-4 \n[14] Katharina Jeblick, Balthasar Schachtner, Jakob Dexl, Andreas Mittermeier, \nAnna Theresa Stüber, Johanna Topalis, Tobias Weber, Philipp Wesp, Bastian \nSabel, Jens Ricke, and Michael Ingrisch. 2022. ChatGPT Makes Medicine \nEasy to Swallow: An Exploratory Case Study on Simplified Radiology Reports. \narXiv:2212.14882 [cs.CL] \n[15] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, \nYe Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of Hallucination in \nNatural Language Generation. ACM Comput. Surv. 55, 12, Article 248 (mar 2023), \n38 pages. https://doi.org/10.1145/3571730 \n[16] Klementina Josifovska, Enes Yigitbas, and Gregor Engels. 2019. A Digital Twin-\nBased Multi-modal UI Adaptation Framework for Assistance Systems in Industry \n4.0. In Human-Computer Interaction. Design Practice in Contemporary Societies \n(Lecture Notes in Computer Science), Masaaki Kurosu (Ed.). Springer International \nPublishing, Cham, 398–409. https://doi.org/10.1007/978-3-030-22636-7_30 \n[17] Samuel Kernan Freire, Evangelos Niforatos, Zoltan Rusak, Doris Aschenbrenner, \nand Alessandro Bozzon. 2022. A Conversational User Interface for Instructional \nMaintenance Reports. In Proceedings of the 4th Conference on Conversational \nUser Interfaces (Glasgow, United Kingdom) (CUI ’22). Association for Computing \nMachinery, New York, NY, USA, Article 5, 6 pages. https://doi.org/10.1145/ \n3543829.3544516 \n[18] Samuel Kernan Freire, Sarath Surendranadha Panicker, Santiago Ruiz-Arenas, \nZoltán Rusák, and Evangelos Niforatos. 2022. A Cognitive Assistant for Operators: \nAI-Powered Knowledge Sharing on Complex Systems. IEEE Pervasive Computing \n(2022), 1–9. https://doi.org/10.1109/MPRV.2022.3218600 \n[19] Everlyne Kimani, Kael Rowan, Daniel McDuff, Mary Czerwinski, and Gloria \nMark. 2019. A conversational agent in support of productivity and wellbeing at \nwork. In 2019 8th international conference on affective computing and intelligent \ninteraction (ACII). IEEE, 1–7. \n[20] Nguyen-Thinh Le and Laura Wartschinski. 2018. A cognitive assistant for improv-\ning human reasoning skills. International Journal of Human-Computer Studies \n117 (2018), 45–54. \n[21] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, \nNaman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, \nSebastian Riedel, and Douwe Kiela. 2021. Retrieval-Augmented Generation for \nKnowledge-Intensive NLP Tasks. arXiv:2005.11401 [cs.CL] \n[22] Franz Georg Listl, Jan Fischer, and Michael Weyrich. 2021. Towards a Simulation-\nbased Conversational Assistant for the Operation and Engineering of Production \nPlants. In 2021 26th IEEE International Conference on Emerging Technologies and \nFactory Automation (ETFA ). IEEE, 1–4. https://doi.org/10.1109/ETFA45728.2021. \n9613681 \n[23] Bei Luo, Raymond YK Lau, Chunping Li, and Yain-Whar Si. 2022. A critical \nreview of state-of-the-art chatbot designs and applications. Wiley Interdisciplinary \nReviews: Data Mining and Knowledge Discovery 12, 1 (2022), e1434. \n[24] Kamil Malinka, Martin Perešíni, Anton Firc, Ondřej Hujňák, and Filip Januš. 2023. \nOn the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain \na University Degree? arXiv:2303.11146 [cs.CY] \n[25] Oded Nov, Nina Singh, and Devin Mann. 2023. Putting ChatGPT’s Medical Advice \nto the (Turing) Test. arXiv:2301.10035 [cs.HC] \n[26] OpenAI. 2023. GPT-4 Technical Report. Technical Report. OpenAI. https: \n//cdn.openai.com/papers/gpt-4.pdf \n[27] Ricardo J. Rabelo, Saulo Popov Zambiasi, and David Romero. 2019. Collaborative \nSoftbots: Enhancing Operational Excellence in Systems of Cyber-Physical Sys-\ntems. In Collaborative Networks and Digital Transformation, Luis M. Camarinha-\nMatos, Hamideh Afsarmanesh, and Dario Antonelli (Eds.). IFIP Advances in \nInformation and Communication Technology, Vol. 568. SPRINGER NATURE, \n55–68. https://doi.org/10.1007/978-3-030-28464-0{_}6 \n[28] Alexander Rietzler, Sebastian Stabinger, Paul Opitz, and Stefan Engl. 2019. Adapt \nor get left behind: Domain adaptation through bert language model finetuning \nfor aspect-target sentiment classification. arXiv preprint arXiv:1908.11860 (2019). \n[29] Leonardo Rodriguez, Fabian Quint, Dominic Gorecky, David Romero, and Héc-\ntor R. Siller. 2015. Developing a Mixed Reality Assistance System Based on \nProjection Mapping Technology for Manual Operations at Assembly Worksta-\ntions. Procedia Computer Science 75 (Jan. 2015), 327–333. https://doi.org/10.1016/ \nj.procs.2015.12.254 \n[30] Yehya Soliman and Hannu Vanharanta. 2020. A Model for Capturing Tacit \nKnowledge in Enterprises. In Advances in Human Factors, Business Management \nand Leadership (Advances in Intelligent Systems and Computing), Jussi Ilari Kantola \nand Salman Nazir (Eds.). Springer International Publishing, Cham, 141–148. \nhttps://doi.org/10.1007/978-3-030-20154-8_14 \n[31] Quy Tang. 2023. Integrating ChatGPT with internal knowledge base and question-\nanswer platform. https://medium.com/singapore-gds/integrating-chatgpt-with-\ninternal-knowledge-base-and-question-answer-platform-36a3283d6334 \n[32] Ruixiang Tang, Xiaotian Han, Xiaoqian Jiang, and Xia Hu. 2023. Does Synthetic \nData Generation of LLMs Help Clinical Text Mining? arXiv:2303.04360 [cs.CL] \n[33] Wenjin Tao, Ze-Hao Lai, Ming C. Leu, Zhaozheng Yin, and Ruwen Qin. 2019. A \nself-aware and active-guiding training & assistant system for worker-centered \nintelligent manufacturing. Manufacturing Letters 21 (Aug. 2019), 45–49. https: \n//doi.org/10.1016/j.mfglet.2019.08.003 \n[34] Dietrich Trautmann, Alina Petrova, and Frank Schilder. 2022. Legal Prompt En-\ngineering for Multilingual Legal Judgement Prediction. arXiv:2212.02199 [cs.CL] \n[35] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian \nBorgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. \n2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682 \n(2022). \n[36] Stefan Wellsandt, Mina Foosherian, Katerina Lepenioti, Mattheos Fikardos, Gre-\ngoris Mentzas, and Klaus-Dieter Thoben. 2022. Supporting Data Analytics in \nManufacturing with a Digital Assistant. In Advances in Production Management \nSystems. Smart Manufacturing and Logistics Systems: Turning Ideas into Action, \nDuck Young Kim, Gregor von Cieminski, and David Romero (Eds.). IFIP Ad-\nvances in Information and Communication Technology, Vol. 664. Springer Nature \nSwitzerland, Cham, 511–518. https://doi.org/10.1007/978-3-031-16411-8{_}59 \n[37] Stefan Wellsandt, Karl Hribernik, and Klaus-Dieter Thoben. 2021. Anatomy of \na Digital Assistant. In Advances in Production Management Systems. Artificial \nIntelligence for Sustainable and Resilient Production Systems, Alexandre Dolgui, \nAlain Bernard, David Lemoine, Gregor von Cieminski, and David Romero (Eds.). \nIFIP Advances in Information and Communication Technology, Vol. 633. Springer \nInternational Publishing, Cham, 321–330. https://doi.org/10.1007/978-3-030-\n85910-7{_}34 \n[38] Xun Xu, Yuqian Lu, Birgit Vogel-Heuser, and Lihui Wang. 2021. Industry 4.0 and \nIndustry 5.0—Inception, conception and perception. Journal of Manufacturing \nSystems 61 (2021), 530–535. https://doi.org/10.1016/j.jmsy.2021.10.006 \n[39] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, \nYingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, \nYushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, \nZikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A Survey of Large \nLanguage Models. arXiv:2303.18223 [cs.CL] \n[40] Shuo Zhou and Timothy Bickmore. 2022. A Virtual Counselor for Breast Cancer \nGenetic Counseling: Adaptive Pedagogy Leads to Greater Knowledge Gain (CHI \n’22). Association for Computing Machinery, New York, NY, USA, Article 436, \n17 pages. https://doi.org/10.1145/3491102.3517553 ",
  "topic": "Factory (object-oriented programming)",
  "concepts": [
    {
      "name": "Factory (object-oriented programming)",
      "score": 0.7370890378952026
    },
    {
      "name": "Workforce",
      "score": 0.5155255794525146
    },
    {
      "name": "Cognition",
      "score": 0.5154879689216614
    },
    {
      "name": "Agile software development",
      "score": 0.5104891061782837
    },
    {
      "name": "Bridge (graph theory)",
      "score": 0.4292253851890564
    },
    {
      "name": "Knowledge management",
      "score": 0.39881864190101624
    },
    {
      "name": "Computer science",
      "score": 0.39600294828414917
    },
    {
      "name": "Business",
      "score": 0.36047521233558655
    },
    {
      "name": "Psychology",
      "score": 0.1979506015777588
    },
    {
      "name": "Software engineering",
      "score": 0.10158699750900269
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    },
    {
      "name": "Economic growth",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Internal medicine",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98358874",
      "name": "Delft University of Technology",
      "country": "NL"
    },
    {
      "id": "https://openalex.org/I4387156409",
      "name": "Bremer Institut für Produktion und Logistik GmbH",
      "country": null
    }
  ]
}