{
  "title": "Towards New Robotic Design Tools: Using Collaborative Robots within the Creative Industry",
  "url": "https://openalex.org/W2611291505",
  "year": 2016,
  "authors": [
    {
      "id": "https://openalex.org/A2085647910",
      "name": "Johannes Braumann",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2417671844",
      "name": "Sven Stumm",
      "affiliations": [
        "RWTH Aachen University"
      ]
    },
    {
      "id": "https://openalex.org/A2787820969",
      "name": "Sigrid Brell-Cokcan",
      "affiliations": [
        "RWTH Aachen University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2066202893",
    "https://openalex.org/W2745497417",
    "https://openalex.org/W1891870154",
    "https://openalex.org/W4290741322",
    "https://openalex.org/W6604959750",
    "https://openalex.org/W2557623044",
    "https://openalex.org/W4300846586"
  ],
  "abstract": "This research documents our initial experiences of using a new type of collaborative, industrial robot in the area of architecture, design, and construction.The KUKA LBR-iiwa differs from common robotic configurations in that it uses seven axes with integrated force-torque sensors and can be programmed in the Java programming language.Its force-sensitivity makes it safe to interact with, but also enables entirely new applications that use hand-guiding and utilize the force-sensors to compensate for high tolerances on building sites, similar to how we manually approach assembly tasks.Especially for the creative industry, the Java programming opens up completely new applications that would have previously required complex bus systems or industrial data interfaces.We will present a series of realized projects that showcase some of the potential of this new type of collaborative, safe robot, and discuss the advantages and limitations of the robotic system.",
  "full_text": "164\nTowards New Robotic Design Tools  \n1 Sensitive robotic assembly informed \nthrough haptic programming. \nShowcased at the Hannover Fair \n2016.\nJohannes Braumann\nRobots in Architecture \nUfG Linz\nSven Stumm\nIP RWTH Aachen\nSigrid Brell-Cokcan\nRobots in Architecture \nIP RWTH Aachen\nUsing Collaborative Robots within the Creative Industry\n1\nABSTRACT\nThis research documents our initial experiences of using a new type of collaborative, industrial robot \nin the area of architecture, design, and construction. The KUKA LBR-iiwa differs from common \nrobotic configurations in that it uses seven axes with integrated force-torque sensors and can be \nprogrammed in the Java programming language. Its force-sensitivity makes it safe to interact with, but \nalso enables entirely new applications that use hand-guiding and utilize the force-sensors to compen-\nsate for high tolerances on building sites, similar to how we manually approach assembly tasks.\nEspecially for the creative industry, the Java programming opens up completely new applications \nthat would have previously required complex bus systems or industrial data interfaces. We will \npresent a series of realized projects that showcase some of the potential of this new type of collab-\norative, safe robot, and discuss the advantages and limitations of the robotic system.\n165\n GENERATIVE ROBOTICS\nINTRODUCTION\nTen years ago, the use of industrial robots within architectural \nresearch was considered to be high-end, often depending on \nrobotic engineers that worked with designers to realize projects. \nToday, these robots have turned into well-researched tools that \ncan be found at many larger universities, and are also starting \nto leave the field of research towards full-scale applications, as \ndemonstrated in the work of Gramazio & Kohler, Achim Menges, \nand others (Figure 2).\nCompanies such as Branch Technology are now basing their \ninnovative applications on reliable robotic platforms, thus \nallowing them to focus on their construction-specific tasks, rather \nthan having to develop an entire robotic system.\nWhereas robots are often used to perform tasks similar to \nexisting CNC machines, our main research interest lies in the \ncore of construction strategies and how we can advance robotic \nsoftware technology to assist in assembling tasks (refer to the \nproject section and Stumm et al. 2016).\nCurrently, significant development in the area of software can \nbe observed in our field, enabling tablet-like interaction with \nthe control panel and new networked devices to act as a robot \ncontroller through software options like KUKA mxAutomation \n(Munz et al. 2016, Braumann and Brell-Cokan 2015). Within the \ncontext of architecture and design, the community of creative \nrobot users itself has become the main enabling factor to greatly \nlower the entry bar for new users of robotics by exchanging \nideas on the same level and providing accessible but powerful \ntools such as KUKA|prc, HAL, and others.\nRecently, we can observe changes happening within the robot \nindustry as well, as companies are moving their focus away from \ntraditional robot installations within safety fences towards safe \nhuman-robot collaboration, while also investigating new applica-\ntions beyond the automotive sector.\nINTELLIGENT WORK ASSISTANT\nFor this purpose, a number of robotics companies have devel-\noped a new generation of lightweight robotic arms such as \nKUKA’s LBR iiwa (intelligent industrial work assistant), with similar \n“safe” machines being available from ABB (YuMi), UR, and a range \nof smaller robotic startups, building upon research such as by \nthe DLR (Albu-Schäffer et al, 2007). The iiwa (Figure 3) differs \nfrom the common robotic-arm template. Immediately visible is \nits design, which is optimized to reduce the potential of harming \nthe user by minimizing the amount of sharp edges and reducing \ncrushing hazards, thus making it possible to safely interact with \nthe robot in a haptic way.\n2a\n2c\n2b\nFurthermore, the LBR iiwa employs seven axes, enabling the \nrobot to move the kinematic chain behind its tool, without \nmoving the tool itself. The additional redundant axis greatly \nincreases the robot’s kinematic flexibility, offering mathematically \ninfinite possibilities to move to a defined point in space, which \ncan be used to avoid obstacles, and to offset the comparably \nlimited axis range. The force-torque sensors within every axis \nconstitute another step-change in robotic technologies, enabling \nthe robot to feel and react to contact and pressure. Previously, \n3b\n3a\n2 Architectural robotic projects: ICD/\nITKE Research Pavilion 2015–16 \n(a), Branch Technologies (b), Echord \nETH Zurich (c).\n3 Save interaction with a collabo-\nrative robot: Compliant mode (a), \ncollision detection (b).\n166\nforce-torque sensors for industrial robots were mostly mounted \ndirectly between the tool and the flange, or the drive currents for \nindividual axes were used to provide only a rather coarse feed-\nback. Adding these sensors to every axis does not just enable \nforce-sensitive applications, but makes the robot potentially safe \nto work with, as it can now feel collisions at every joint, rather \nthan just at the tool tip.\nThe sensors are not limited to a Boolean yes/no collision, but \nprovide fine-grained data that can be used for many different \napplications—e.g., those that require information about contact \nstate or process force. Additionally, the robot can be moved \naround manually in compliant mode, which does not simply \nrelease the brakes of the motors, but compensates gravity \nand measures the force applied at each joint to support any \nuser-given movement. Even the weight of workpieces can be \ncompensated in a similar fashion, so objects mounted onto the \nrobot can be moved as if they weighed nearly nothing.\nWithin the scope of architecture and design, we see a special \npotential for interactive design parametrization and force-guided \nassembly, which is further discussed in the project section.\nRobot as an App\nWhile similar applications have been possible before, the iiwa’s \nnew programming provides accessible libraries that allows the \ncreative user to utilize these features at a high level without \nneeding external data processing or specialized software.\nUnlike previous LBR iterations such as the LBR4, which relied \non the regular KUKA Robot Language (KRL), the iiwa introduced \nSunriseOS, which uses Java as the robot’s programming language. \nThis allows us to use state-of-the-art programming strategies, \nsuch as object-oriented programming, and most importantly, to \nimplement external libraries that range from geometric functions \nto image processing and cloud networking. As an integrated \ndevelopment environment (IDE), KUKA provides the Sunrise \nWorkbench, a modified version of the open-source software \nEclipse. In addition to making complex tasks easier to program, \nit also greatly opens up the scope of robot programming. Rather \nthan being limited to certain interfaces and tech packages, we \ncan define custom ways of communication and interaction, e.g., \nusing high-performance technologies developed by the game \nindustry for Android, which also uses Java for its apps.\nAn exemplary programming workflow via Sunrise Workbench \n(Figure 4) starts with the user creating a new Java project and \nwriting the logic using the provided KUKA-specific libraries \nfor movements, force conditions, etc. Tools and coordinate \nsystems are also created within the Sunrise Workbench and can \nbe intelligently nested, so that, for example,multiple tool-tip \ncoordinate systems are assigned to a single tool. Finally, safe-\nty-specific properties are set in the Safety Configuration and the \nIO configuration is loaded from WorkVisual, as with regular KRC4 \nrobots. The project can now be synced with the robot, replacing \nthe previous program. On the robot, the previously set-up tools \nand coordinate system now show up and can be calibrated, thus \nmatching the digital environment with the actual physical space. \nThe next synchronization between robot and IDE then pushes \nthese changes back into the Workbench. A simulation in advance \nis not possible, only syntax errors are checked and highlighted.\nInitial Experiences\nAs the iiwa robot has only recently been introduced and is priced \ncomparatively high, we could not build upon the knowledge of \nmany other, creative robot users. For example, applications in the \ncreative industry are robotic scale model testing at the BRG/ETH \nZurich (2016) and camera motion control for movies at CMOCOS \n(Shepherd and Buchstab 2014). The findings below represent \nour initial conclusions and subjective evaluation after slightly less \nthan a year of using iiwa robots.\n• Acceptance: While negative connotations for robotic arms \nare common, the design of the iiwa seemed to greatly \nT owards New Robotic Design T ools Braumann, Brell-Cokcan, Stumm\n4  SunriseWorkbench: Defining robot topology, safety and program within the IDE and synchronizing it directly to the LBR iiwa robot.\n167\n GENERATIVE ROBOTICS\nincrease public acceptance as it distanced itself from regular \nindustrial robots, while also not too directly emulating human \narms. People were quick to interact with the iiwa without \nhesitations or safety concerns, while students were curious to \nwork with a new machine.\n• Mechanics: Immediately noticeable is the iiwa’s low weight \nof less than 30 kg, which makes it significantly easier to \nmove and set up than, for example, 50 kg Agilus robots. At \nthe same time, the larger iiwa can manipulate up to 14 kg, \nwhile the Agilus series currently tops out at 10 kg, resulting \nin a very favorable weight to payload ratio. The relatively low \naxis-speed of 57–144°/sec can be limiting for some appli-\ncations, but most collaborative setups require significantly \nlower speeds for safety reasons. The iiwa’s main drawback \ncompared to other robots is the very limited range of its axes \n(e.g. +-140 at A1 and +-152.5 at A7), which is most likely the \nresult of the effort to reduce crushing hazards, while also \nleading internal wiring and tubing up to the flange. Even with \npresumably easy movements, it has been very common for \nus to hit the axis limits of the machine, usually requiring fine-\ntuning of the posture as well as the redundant, seventh axis.\n \n• General Programming: The idea of adapting an established \nIDE for robot programming definitely shows merit, as does \nthe choice of Java as a well-documented language that many \nstudents have been exposed to as early as in secondary \nschool. The KUKA libraries are well integrated and come \nwith a certain amount of documentation, making it possible \nto quickly create an initial program. A significant challenge \narises from the decision to only allow a single active project \non the robot (though it can contain multiple sub-programs). \nThis leads to particular challenges when multiple users are \ncollaborating on a project, as the current system lacks any \nkind of version control, which gives users the choice between \nsynchronizing the project to their local machines (thus \noverwriting the local project) or moving data the other way \naround. Therefore, any versioning has to happen before the \nproject is uploaded to the robot.\n• Motion Programming: While Java offers many advantages for \nthe efficient programming of tasks, thus allowing us to work \nwith parallel threads and asynchronous tasks, the physical \nrobot itself can only do a single operation at once. This leads \nto problems with blended movements, as the robot has to \nknow the next position in order to create a smooth trajectory \nwithout stopping at every programmed position. The user can \neither put multiple commands into a MotionBatch, or execute \nmotiontasks asynchronously, both of which caused problems \nwith very large, complex toolpaths. Troubleshooting is further \ncomplicated by the fact that the only feedback provided \non the robot control panel are console messages as well as \nexceptions. While the older KRC4 controller presents the user \na pointer at the currently active line, SunriseOS only allows \nthe user to step through a program if a debugging process is \nstarted through the Sunrise Workbench from a remote PC. \nAny kind of “block selection” has to be programmed in Java, \ne.g., through a custom debugging interface.\n• Expandability: Through additional libraries, it was quickly \npossible to integrate additional features such as a custom \nGUI based on the Java.Swing toolkit, as well as geometric \noperations that allow a similar interaction with geometry as in \nCAD software. See the project section for more details.\n• Safety: For applications that involve direct interaction between \nthe user and robot, such as collaborative assembly, but also for \nthe initial programming of robotic tasks, especially in educa-\ntion, the integrated safety features of the iiwa offer significant \nadvantages over conventional robots. With the relevant safety \npackage, it is possible to set a global collision stop that will \nbe applied irrespective of the particular program that is being \nused, and to protect that setting with a password. While these \nfeatures do not make any application automatically safe—e.g., \nwhen sharp tools are involved—many applications do not \nrequire any further, external safety equipment.\nNEW PROGRAMMING INTERFACES FOR \nCOLLABORATIVE ROBOTS\nIn previous research we have developed KUKA|prc (parametric \nrobot control – Braumann and Brell-Cokcan 2011), allowing \ncreative users to quickly and intuitively program and simulate \nrobotic arms within a visual programming environment. For many \nusers, this environment proved essential towards rapidly proto-\ntyping new fabrication strategies, but also for quickly engaging \nstudents. In our own teaching we have experienced it to be highly \nbeneficial to provide students with an accessible interface that \nallows them to explore the capabilities and constraints of robotic \narms in both a virtual environment, immediately followed by actual, \nphysical experiments. Depending on their skills and interests, \nstudents can then either work very “deep” within the programming \nof the robot, or at a higher level through the visual programming \nenvironment—and of course in any combination of these two.\n168\n5\n6\n5 KUKA LBR iiwa simulation within \nKUKA|prc—in parallel optimizing \nthe reachability of several robotic \nprocesses, based on parametric 3D \ngeometry.\n6 Schematic display of KUKA|prc-\nbased SunriseOS workflow. Initial \nsetuo is done in the Sunrise \nWorkbench. Toolpaths are gener-\nated in KUKA|prc and saved as .xml \nfiles. The Java program streams the \ninformation to the robot.\nT owards New Robotic Design T ools Braumann, Brell-Cokcan, Stumm\n169\n GENERATIVE ROBOTICS\nWe were unable to find any suitable offline programming environ-\nment capable of simulating and controlling an iiwa arm;the KUKA \nSimPro software was only capable of simulating the robot, but \nunable to output code, and a direct link for ROS would require \nvery deep changes to the controller, as well as software that is not \ncommon outside of the core-robotics sector. Thus, we decided to \nintegrate the iiwa robot into the KUKA|prc environment (Figure 5).\nThe first challenge was the definition of a new kinematic model \nthat supports a single kinematic chain of seven rotary axes, \nas opposed, for example, to a six-axis robot with an external \nturntable. This step was taken in preparation of the iiwa’s arrival, \nbuilding upon our experience with the iiwa’s predecessor. As \nliterature did not provide any fully formulated solution, we \nexperimented with using an evolutionary solver towards creating \nseries of axis movements with the same toolframe but different \nposition of the redundant axis. Using this empirical data, we \nwere able to formulate and test geometric hypotheses within \nGrasshopper that finally resulted in a fast and reliable inverse \nkinematic model of the iiwa robot.\nNext, we had to consider on how to transfer data from \nGrasshopper to the visual programming environment. We first \nevaluated “hacking” the synchronization process of the Sunrise \nWorkbench to directly sync projects to the robot, but ultimately \nsaw too many practical as well as safety issues. Therefore, \nwe chose to use a “Firmata” by creating a standardized, base \nprogram that is capable of communicating with outside sources \nthrough defined means. A similar approach has been chosen by \nAndy Payne and Jason Kelly Johnson for their Firefly (2016) envi-\nronment, where a firmata is uplloaded onto an Arduino controller \nwhich can then communicate with Grasshopper.\nFor the transfer of data between the offline programming \nsystem and the iiwa robot, we decided to utilize a human-read-\nable format to allow quick and easy changes to the file, finally \nchoosing XML due to the availability of powerful libraries both \non the .NET side as well as for Java.\nAs discussed above, the blending of complex toolpaths is \ncomparatively complicated for the iiwa, as it has to put the \nmovement commands either into a MotionBatch, or process \nthem asynchronously, which can lead the program to terminate \nearly, despite several asynchronous movements commands \nstill awaiting processing. Similar to our work with mxAutoma-\ntion, which deals with several similar limitations, we therefore \nimplemented a custom buffering system that would not process \nall commands in advance, but selectively group them into \nMotionBatches when needed and watch over the execution of \nasynchronous movements (Figure 6).\nRather than uploading a new project for each element, users are \nnow simply confronted with a filebrowser that allows them to \nselect XML files from all sources accessible to the Windows site \nof the controller, from network shares to USB drives. This allows \nus to very quickly deploy new projects to the iiwa robot, as well \nas effectively share a single robot between multiple groups of \nstudents.\nINITIAL PROJECTS\nIn the past years, we have used the KUKA LBR iiwa collaborative \nrobot in a series of research and teaching activities. The following \nprojects were chosen to showcase some of the iiwa/Sunrise \nspecific features that set the robotic system apart from other \nindustrial robots.\nRobotic Calligraphy was developed as a showcase installation \nfor KUKA Robotics and the Ars Electronica Center (AEC), a \ndigital media museum in Europe. It builds upon the concept of \ngenerating different greyscale values by rotating an asymmetric \ncalligraphy pen that produces pure black when its wide side is \nnormal to the toolpath, and a lighter shade the more it deviates \nfrom the normal. In previous projects and workshops (Brell-\nCokcan and Braumann 2014), we have implemented the strategy \nwithin the Grasshopper environment and were therefore able to \nimmediately test it with the iiwa by changing the code generation \nfrom KRL to Sunrise/XML. Building upon this proof of concept, \nit was our goal to create a completely integrated program that \nruns entirely on the Sunrise controller, with its own graphical user \ninterface and without requiring an external PC (Figure 7).\nThe first step was to create a simple geometric library—based on \nthe default javax.vecmath library—that allows us to work with \ngeometric objects such as planes in a similar way as within the \nRhinoCommon framework. It was then very easy to layout the \ntoolpaths and apply the rotation based on the brightness of a \nraster image. The comparison with the CAD output enabled an \nimmediate error checking of the results.\nOnce the pathplanning was finished, we looked into the capturing \nof photos through a camera. Instead of depending on an industrial \ncamera, we were able to simply attach a Logitech C920 consumer \nwebcam to the Sunrise controller and install the accompanying \ndriver software. We then captured an image through OpenCV, \nused Haar feature-based cascade classifiers (Viola and Jones \n2001) to recognize faces, and cropped the image to ideally fit the \nface within the aspect ratio of the paper. Finally, we implemented \na graphical user interface based on javax.swing that allowed the \nuser to fine-tune the brightness and contrast of the captured image.\nBoth calligraphy pen as well as the webcam were then mounted \n170\n7b\n7c\n7a\n7 Image capturing with a regular webcam (a), image processing through a  \ncustom made GUI running on the smartPAD for easy interaction (b),  \ncalligraphy process (c).\n8 LBR iiwa “cell” at the Ars Electronica Museum, without requiring additional \nsafety (a). Calligraphy result (b).\non the iiwa through a 3D-printed endeffector. The process was \nlaid out in a way that someone could manually position the iiwa \nthrough hand-guiding, have their “selfie” taken by the robot, \nwhich the operator could then fine-tune on the control panel \nbefore starting the drawing process.\nThe developed system was active for more than a month at the \nArs Electronica Center, operated exclusively by non-expert staff \nwithout any previous robot experience (Figure 8).\nDIANA: In previous research, we have experimented with the \nfabrication of ruled surfaces through wooden rods, with the goal \nof using a small-scale robot to create a large-scale installation. \nUntil recently, a KUKA Agilus robot only performed the cutting \nand multi-axis drilling of the support structure, while the rods \nwould have to be cut and placed manually (Figure 9). The reason \nfor that can be found in the fact that wooden rods are a natural \nmaterial with very high tolerances. These tolerances can be due \nto improper storage and humidity, or simply because of the used \nwood type, and may amount to more than 10 mm on a 1000 \nmm rod. DIANA, the dynamic interactive assistant for novel \napplications, is a robot installation developed by teams from \nRWTH Aachen University (Chair for Individualized Production in \nArchitecture and the Cybernetic-Cluster IMA/ZLW & IfU) and \nRobots in Architecture as part of the KUKA Innovation Award for \nthe Hannover Fair 2016 that showcases the challenges of using \nrobots in the construction industry, demonstrating concepts \nsuch as mass customization and strategies towards dealing with \nenvironments with high tolerances.\nFor this project, we digitally designed and built a rod-structure \nout of 45 x 45 mm wooden slabs and 12mm diameter birch \nrods. The robot setup provided by KUKA consisted of a iiwa \n14 R820 robot mounted onto a flexFELLOW platform—a robot \nbase that integrates the controller and can be quickly relocated. \nAn important design tool from the very beginning was our iiwa \nsimulation through KUKA|prc that allowed us to optimize the \ngeometry in regards to reachability and collisions. While we \n8a\n8b\nT owards New Robotic Design T ools Braumann, Brell-Cokcan, Stumm\n171\n GENERATIVE ROBOTICS\nwere able to incorporate the position and orientation of each \nmounting point into the Java program, these values assume an \nideal, digital environment and take neither production tolerances, \nnor an imprecise placement of the robot itself into account. \nFirst of all, the user takes the iiwa robot and manually guides it \nfrom one side of the base structure to the other side, a process \nwe refer to as “haptic programming” (Stumm et al. 2016). By \ncapturing the movement, a curve is parametrized that informs \nthe fabrication process, making every generated structure \nunique. Based on this data, the robot generates a list of tasks \nfor that fabrication process: First of all, the robot takes a rod out \nof the supply station, which groups rods within a range of 50 \nmm. In order to calculate the exact length of the rod, the robot \nmoves each tip of the rod onto the flexFELLOW platform until a \ncontact is established. This contact is established solely through \nthe force-torque sensors, without requiring additional sensory \nequipment. The robot records the distance between the gripper \nfingers and the measuring position, thus being able to calculate \nthe length in each direction. Using a common circular saw, the \nrod is then cut according to the previously generated curve. For \nthe actual assembly, the robot moves the rod into the approx-\nimate position of each mounting position as known from the \ndesign. Due to the high material tolerances, it then searches for \nthe exact position via the force sensors. Once it feels a significant \ndrop in the force values, it concludes that the rod has slipped \ninto mounting position and continues the assembly process by \nretrieving the next rod (Figure 10).\nIn the past, such systems have mostly relied on external \nmeasuring equipment that calculates the offset between the \nideal and the actual toolframe. However, such systems are \ncomplicated to use and not ideally suited to the rough, changing \nenvironments of a construction site. The force-sensitivity of the \niiwa provides a well-integrated way towards implementing such \nfunctionality into an assembly process, without requiring external \nequipment or special software.\nCONCLUSION AND OUTLOOK\nThe KUKA LBR iiwa represents a significant step change not \nonly for the robotics industry, but also for the construction \nindustry, as it enables completely new ways of interacting with \nrobots;both in regards to physical and digital interaction. Even \nmore than previous machines, the robot becomes a universal \nplatform that can be adapted through software for specific \ntasks and implemented into existing systems, from the cloud to \nBuilding Information Modeling.\nUsing the prepared “firmata” allows users to quickly prototype \nprocesses and check reachability through the KUKA|prc and \nthe visual programming environment, where toolpath layouts \ncan be more easily constrained to geometries. Within Sunrise \nWorkbench, the user can continue working with the automati-\ncally generated XML file, adding, for example,additional safety \nand interaction features around it.\nAt the moment, the iiwa’s working range limits larger-scale appli-\ncations within a construction context. However, the transfer of \n9b\n9a\n9c\n9 Robotically fabricating the supporting structure with a regular, non-complaint \nrobot (a). Previous, manual assembly of rods (b). New, senstitive assembly \ninformed through haptic programming presented at the Hannover Fair 2016 (c).\n172\nthe robotic system onto a mobile platform (KMR iiwa, Figure 11), \nwill allow us to navigate autonomously within a workspace that is \nlimited only by the capacity of its batteries.\nACKNOWLEDGEMENTS\nThis research was performed as part of the “Robotic Woodcraft” \nresearch project (FWF-PEEK AR238) and the KUKA Innovation \nAward. The DIANA team consisted of Sven Stumm, Martin von \nHilchen, Elisa Lublasser and Prof. Sigrid Brell-Cokcan (IP-RWTH \nAachen), Philipp Ennen and Prof. Sabina Jeschke (IMA/ZLW & IfU \nRWTH Aachen) and Johannes Braumann (Robots in Architecture).\nREFERENCES\nAlbu-Schäffer Albin, Sami Haddadin, Christian Ott, Andreas Stemmer, \nThomas Wimböck, and Gerd Hirzinger. 2007. “The DLR Lightweight \nRobot: Design and Control Concepts for Robots in Human Environments.” \nIndustrial Robot: An International Journal 34 (5): 376–385.\nBraumann, Johannes and Sigrid Brell-Cokcan. 2011. “Parametric Robot \nControl: Integrated CAD/CAM for Architectural Design.” In Proceedings of \nthe 31st Annual Conference of the Association for Computer Aided Design in \nArchitecture (ACADIA). Banff, Alberta, Canada: ACADIA. 242–251. \nBraumann, Johannes, and Sigrid Brell-Cokcan. 2015. “Adaptive Robot \nControl - New Parametric Workflows Directly from Design to KUKA \nRobots.” In Real Time: Proceedings of the 33rd eCAADe Conference, \nvol. 2, edited by B. Martens, G. Wurzer, T. Grasl, W. E. Lorenz, and R. \nSchaffranek. Vienna, Austria: eCAADe. 243–250.\nBrell-Cokcan, Sigrid and Johannes Braumann. 2014. “Robotic Production \nImmanent Design: Creative Toolpath Design in Micro and Macro Scale.” In \nACADIA 14: Design Agency—Proceedings of the 34th Annual Conference of \nthe Association for Computer Aided Design in Architecture, edited by David \nGerber, Alvin Huang, and Jose Sanchez. Los Angeles: ACADIA. 579–588.\nETH Zurich. “Robotic Scale-Model Testing”. Accessed May 5th 2016. \nhttp:/ /www.block.arch.ethz.ch/brg/research/robotic-scale-model-testing\nMunz, Heinrich, Johannes Braumann, and Sigrid Brell-Cokcan. 2016. \n“Direct Robot Control with mxAutomation.” In Rob | Arch 2016: Robotic \nFabrication in Architecture, Art and Design 2016, edited by Dagmar \nReinhardt, Rob Saunders, and Jane Burry. Vienna: Springer. 440–447.\nPayne, Andy and Jason Kelly Johnson. “Firefly.” Accessed May 5th 2016. \nhttp:/ /www.fireflyexperiments.com\nShepherd, Stuart and Alois Buchstab. 2014. “KUKA Robots On-Site.” In \nRob | Arch 2014: Robotic Fabrication in Architecture, Art and Design, edited \nby Wes McGee and Monica Ponce de Leon. Vienna: Springer. 373–380.\nStumm, Sven, Johannes Braumann, Martin von Hilchen, and Sigrid \nBrell-Cokcan. 2016. “On-Site Robotic Construction Assistance for \nAssembly Using A-Priori Knowledge and Human-Robot Collaboration.” \nIn Proceedings of the International Conference on Robotics in Alpe-Adria-\nDanube Region. Belgrade, Serbia: RAAD.\nT owards New Robotic Design T ools Braumann, Brell-Cokcan, Stumm\n10\n173\n GENERATIVE ROBOTICS\nViola, Paul, and Michael Jones. 2001. “Rapid Object Detection using a \nBoosted Cascade of Simple Features.” In Proceedings of the 2001 IEEE \nComputer Society Conference on Computer Vision and Pattern Recognition, \nvol. 1. Kauai, HI: CVPR. 551–560.\nIMAGE CREDITS\nFigure 2a: © University of Stuttgart\nFigure 2b: © Branch Technologies\nFigure 2c: © ETH Zurich\nAll other figures: © Robots in Architecture and RWTH Aachen University\nSigrid Brell-Cokcan and Johannes Braumann founded the Association \nfor Robots in Architecture in 2010 with the goal of making indus-\ntrial robots accessible to the creative industry. Towards that goal, the \nAssociation is developing innovative software tools such as KUKA|prc \n(parametric robot control) and initialized the Rob|Arch conference series \non robotic fabrication in architecture, art, and design which–following \nVienna in 2012, Ann Arbor in 2014, and Sydney in 2016 – will be held \n2018 in Zurich. Robots in Architecture is a KUKA System Partner and has \nbeen validated as a research institutions by national and international \nresearch agencies such as the European Union’s FP7 program. Recently, \nSigrid founded the new chair for Individualized Production in Architecture \nat RWTH Aachen University. Johannes is heading the robotics lab at \nUfG Linz and leading the development of KUKA|prc. Their work has \nbeen widely published in peer reviewed scientific journals, international \nproceedings, and books, as well as being featured in formats such as \nWired, Gizmodo, FAZ, and RBR.\nSven Stumm is a computer scientist at the Chair of Individualized \nProduction in Architecture (IP) at RWTH Aachen University with a \nfocus on intelligent systems and backgrounds in humanoid, mobile \nand stationary industrial robotics. His core competences are in robot \ncontroller development, sensor data processing, probabilistic modelling  \nas well as software development for programming and simulation of \nrobotic applications. At IP he researches assembly and production \nprocesses within construction, and novel interactive interfaces for  \nrobot programming.\n10  DIANA: Capturing geometry \nthrough manual guiding (1), \nmeasuring exact length (2), cutting \n(3), force-sensitive assembly (4).\n11  KMR iiwa platform at the Chair \nfor Individualized Production in \nArchitecture at RWTH Aachen.\n11",
  "topic": "Java",
  "concepts": [
    {
      "name": "Java",
      "score": 0.7021899223327637
    },
    {
      "name": "Robot",
      "score": 0.6881531476974487
    },
    {
      "name": "Computer science",
      "score": 0.6474802494049072
    },
    {
      "name": "Industrial robot",
      "score": 0.5368369817733765
    },
    {
      "name": "Human–computer interaction",
      "score": 0.4408641755580902
    },
    {
      "name": "Architecture",
      "score": 0.43168947100639343
    },
    {
      "name": "Software engineering",
      "score": 0.3902457058429718
    },
    {
      "name": "Systems engineering",
      "score": 0.3762056231498718
    },
    {
      "name": "Engineering",
      "score": 0.2655394375324249
    },
    {
      "name": "Artificial intelligence",
      "score": 0.22135546803474426
    },
    {
      "name": "Programming language",
      "score": 0.1470564901828766
    },
    {
      "name": "Art",
      "score": 0.0
    },
    {
      "name": "Visual arts",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I887968799",
      "name": "RWTH Aachen University",
      "country": "DE"
    }
  ],
  "cited_by": 7
}