{
  "title": "Multi-agent systems powered by large language models: applications in swarm intelligence",
  "url": "https://openalex.org/W4410551457",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A4221741194",
      "name": "Jimenez-Romero, Cristian",
      "affiliations": [
        "CY Cergy Paris Université",
        "Centre National de la Recherche Scientifique"
      ]
    },
    {
      "id": "https://openalex.org/A4221735791",
      "name": "Yegenoglu, Alper",
      "affiliations": [
        "Forschungszentrum Jülich"
      ]
    },
    {
      "id": "https://openalex.org/A3180404321",
      "name": "Blum, Christian",
      "affiliations": [
        "Artificial Intelligence Research Institute"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2202146474",
    "https://openalex.org/W1926550788",
    "https://openalex.org/W4391136507",
    "https://openalex.org/W2098387795",
    "https://openalex.org/W6848967537",
    "https://openalex.org/W2773535824",
    "https://openalex.org/W4403573463",
    "https://openalex.org/W4402901320",
    "https://openalex.org/W4388744821",
    "https://openalex.org/W1960510011",
    "https://openalex.org/W2077935068",
    "https://openalex.org/W4389363348",
    "https://openalex.org/W4389742501",
    "https://openalex.org/W4385889839",
    "https://openalex.org/W4405787555",
    "https://openalex.org/W4403203873",
    "https://openalex.org/W4385381809",
    "https://openalex.org/W6875730949",
    "https://openalex.org/W4403589070",
    "https://openalex.org/W3140951851",
    "https://openalex.org/W4391919254",
    "https://openalex.org/W4387835442",
    "https://openalex.org/W4394867994",
    "https://openalex.org/W4399759101",
    "https://openalex.org/W2150312211",
    "https://openalex.org/W4403576716",
    "https://openalex.org/W4379919478",
    "https://openalex.org/W6763765333",
    "https://openalex.org/W4378768661",
    "https://openalex.org/W3194103514",
    "https://openalex.org/W4401039466",
    "https://openalex.org/W1903683453",
    "https://openalex.org/W4319165647"
  ],
  "abstract": "This work examines the integration of large language models (LLMs) into multi-agent simulations by replacing the hard-coded programs of agents with LLM-driven prompts. The proposed approach is showcased in the context of two examples of complex systems from the field of swarm intelligence: ant colony foraging and bird flocking. Central to this study is a toolchain that integrates LLMs with the NetLogo simulation platform, leveraging its Python extension to enable communication with GPT-4o via the OpenAI API. This toolchain facilitates prompt-driven behavior generation, allowing agents to respond adaptively to environmental data. For both example applications mentioned above, we employ both structured, rule-based prompts and autonomous, knowledge-driven prompts. Our work demonstrates how this toolchain enables LLMs to study self-organizing processes and induce emergent behaviors within multi-agent environments, paving the way for new approaches to exploring intelligent systems and modeling swarm intelligence inspired by natural phenomena. We provide the code, including simulation files and data at https://github.com/crjimene/swarm_gpt .",
  "full_text": "TYPE Original Research\nPUBLISHED /two.tnum/one.tnum May /two.tnum/zero.tnum/two.tnum/five.tnum\nDOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nOPEN ACCESS\nEDITED BY\nGeorgios Leontidis,\nUniversity of Aberdeen, United Kingdom\nREVIEWED BY\nKonstantinos Liagkouras,\nUniversity of Piraeus, Greece\nWei Li,\nCity University of Hong Kong,\nHong Kong SAR, China\n*CORRESPONDENCE\nCristian Jimenez-Romero\ncristian.jimenez-romero@cyu.fr\nRECEIVED /one.tnum/three.tnum March /two.tnum/zero.tnum/two.tnum/five.tnum\nACCEPTED /two.tnum/three.tnum April /two.tnum/zero.tnum/two.tnum/five.tnum\nPUBLISHED /two.tnum/one.tnum May /two.tnum/zero.tnum/two.tnum/five.tnum\nCITATION\nJimenez-Romero C, Yegenoglu A and Blum C\n(/two.tnum/zero.tnum/two.tnum/five.tnum) Multi-agent systems powered by large\nlanguage models: applications in swarm\nintelligence. Front. Artif. Intell./eight.tnum:/one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum.\ndoi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nCOPYRIGHT\n© /two.tnum/zero.tnum/two.tnum/five.tnum Jimenez-Romero, Yegenoglu and\nBlum. This is an open-access article\ndistributed under the terms of the\nCreative\nCommons Attribution License (CC BY) . The\nuse, distribution or reproduction in other\nforums is permitted, provided the original\nauthor(s) and the copyright owner(s) are\ncredited and that the original publication in\nthis journal is cited, in accordance with\naccepted academic practice. No use,\ndistribution or reproduction is permitted\nwhich does not comply with these terms.\nMulti-agent systems powered by\nlarge language models:\napplications in swarm\nintelligence\nCristian Jimenez-Romero/one.tnum*, Alper Yegenoglu /two.tnumand\nChristian Blum /three.tnum\n/one.tnumETIS Laboratory, ENSEA, CNRS, UMR/eight.tnum/zero.tnum/five.tnum/one.tnum, CY Cergy-Paris University, Cergy, France, /two.tnumIndependent\nResearcher, Jülich, Germany, /three.tnumArtiﬁcial Intelligence Research Institute (IIIA-CSIC), Be llaterra, Spain\nThis work examines the integration of large language models ( LLMs) into\nmulti-agent simulations by replacing the hard-coded program s of agents with\nLLM-driven prompts. The proposed approach is showcased in the con text of two\nexamples of complex systems from the ﬁeld of swarm intelligence: ant colony\nforaging and bird ﬂocking. Central to this study is a toolchain that integrates\nLLMs with the NetLogo simulation platform, leveraging its Pyt hon extension\nto enable communication with GPT-/four.tnumo via the OpenAI API. This toolchain\nfacilitates prompt-driven behavior generation, allowing agen ts to respond\nadaptively to environmental data. For both example applicatio ns mentioned\nabove, we employ both structured, rule-based prompts and autonom ous,\nknowledge-driven prompts. Our work demonstrates how this too lchain enables\nLLMs to study self-organizing processes and induce emergent be haviors\nwithin multi-agent environments, paving the way for new approache s to\nexploring intelligent systems and modeling swarm intelligen ce inspired by\nnatural phenomena. We provide the code, including simulation ﬁles and data at\nhttps://github.com/crjimene/swarm_gpt.\nKEYWORDS\nagent-based modeling, large language models, LLM-guided ag ents, simulation, swarm\nintelligence\n/one.tnum Introduction\n/one.tnum./one.tnum From rule-based to LLM-driven agents: a new\nparadigm in ABMS\nIn this study, we use the terms “agent” and “multi-agent” based on their foundational\nmeanings in agent-based modeling and simulation (ABMS,\nMacal and North, 2009 ), while\nextending them through the integration of large language models (LLMs, Chang et al.,\n2024). Traditionally, an agent in ABMS is an autonomous entity with localized decision-\nmaking abilities, interacting with its environment and other agents according to predeﬁned\nrules or principles. A multi-agent system (MAS,\nWooldridge, 2009) refers to a collection of\nsuch agents operating within a shared environment, where global behaviors emerge from\ntheir local interactions. Examples of ABMS include simulations of ecosystem dynamics,\nurban development, and social interactions (\nHeckbert et al., 2010 ; Chen, 2012; Bianchi and\nSquazzoni, 2015).\nBeyond rule-based agents, ABMS literature also explores agents controlled by neural\nnetworks, especially in applications that require adaptability or learning. Techniques\nFrontiers in Artiﬁcial Intelligence /zero.tnum/one.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nlike reinforcement learning and evolutionary strategies are\ncommonly used to optimize agent behaviors in dynamic\nenvironments (\nHecker and Moses, 2015 ; Ning and Xie, 2024 ;\nLiu et al., 2024a ). Other research investigates the application of\nbiologically inspired architectures, particularly spiking neural\nnetworks, to develop solutions that are both energy-eﬃcient\nand computationally eﬀective (\nFang and Dickerson, 2017 ; Putra\net al., 2024 ). Within these systems, emergent behavior plays\na pivotal role, facilitating the eﬀective handling of complex\ntasks (\nJimenez Romero et al., 2024 ).\nRecently, these terms have been introduced in a diﬀerent\ncontext within artiﬁcial intelligence. Here, AI agents often represent\ntask-oriented entities designed to autonomously achieve speciﬁc\ngoals, such as generating dialogues or managing workﬂows. These\nagents typically focus on individual task execution rather than the\nemergent dynamics central to ABMS (\nTalebirad and Nadiri, 2023 ;\nKannan et al., 2024 ; Li et al., 2024 ).\nIn our work, we employ the terms “agent” and “multi-agent”\nin the context of ABMS while integrating LLMs to guide agent\nbehaviors. An agent in our simulations can be either LLM-\nsteered or rule-based. We incorporate LLMs to guide agent\nbehaviors in two ways: (1) simulations consisting entirely of LLM-\nsteered agents, and (2) hybrid simulations where LLM-steered\nagents interact with traditional rule-based agents. This means our\nsimulations can have populations of agents that are completely\nLLM-based or a mix of LLM-based and rule-based agents within\nthe same environment.\nWe aim to explore the potential advantages of leveraging the\ndecision-making and pattern-generation capabilities of LLMs to\naugment ABMS. Speciﬁcally, we are interested in investigating\nwhether integrating LLMs can help us model emergent behavior\nusing the language processing capabilities and the knowledge base\nof LLMs.\nFrom this point forward, when we refer to “agents, ” we mean\nagents within the ABMS framework that may incorporate LLM\nintelligence.\n/one.tnum./two.tnum Motivation\nThe ﬁeld of agent-based simulations has rapidly evolved, driven\nby advances in artiﬁcial intelligence (AI) and computational power.\nThese simulations, which model the interactions of autonomous\nagents within a deﬁned environment, are increasingly being\nenhanced by the integration of generative AI, particularly LLMs.\nIn this context, LLMs—with their capacity to process and generate\nhuman-like text—oﬀer a novel means of guiding and inﬂuencing\nagent behaviors in real-time. A critical aspect of this integration is\nprompt engineering, which is the careful design of prompts that\nserve as instructions for the agents, dictating how they should\nrespond to their environment.\nThe motivation and contribution of this work are found in the\npresentation of a toolchain that integrates LLMs with agent-based\nsimulations within the NetLogo environment (\nTisue and Wilensky,\n2004; Amblard et al., 2015 ), a platform widely recognized in the\ncomplexity science community for its robustness and versatility.\nNetLogo’s value as an educational tool spanning various academic\nlevels further underscores its importance, making it an ideal choice\nfor demonstrating the integration of advanced AI methods into\nmulti-agent simulations.\nOur study investigates two distinct approaches to utilizing\nLLMs within multi-agent environments, focusing on the role\nof prompt engineering in shaping agent behavior. The ﬁrst\napproach employs detailed, structured prompts within an ant\ncolony simulation. These prompts are designed to specify behaviors\nunder clearly deﬁned conditions, such as following pheromone\ntrails or retrieving food. This method allows for precise control\nover agent actions, enabling a rule-based system where each agent’s\nbehavior is explicitly dictated by the LLM-generated instructions.\nIn contrast, the second approach explores the use of less\nstructured, principle-based prompts in a bird ﬂocking simulation.\nHere, the prompts rely on the LLM’s inherent understanding of\ncomplex concepts such as ﬂocking dynamics and self-organization.\nInstead of requiring explicit, rule-based instructions, these prompts\nallow the LLM to handle the intricate behavioral patterns that\nwould otherwise need numerous rules to deﬁne. This approach\nleverages the LLM’s capacity to intuitively model these dynamics,\nenabling behaviors that emerge naturally from agents’ interactions\nwith each other and their environment. As we will show, the LLM\ncan produce adequate and adaptive agent behaviors that realistically\nreﬂect complex, emergent patterns within the simulation.\n/one.tnum./three.tnum Research objectives\nThe following are the main objectives of our research:\n• To assess the eﬃcacy of structured prompts in the context\nof the rule-based ant colony foraging simulation of NetLogo,\nwhich is a classic MAS model that demonstrates swarm\nintelligence principles based on how real ants ﬁnd food and\ncommunicate via pheromones. It is widely used in artiﬁcial\nintelligence, complexity science, and optimization research.\n• To assess the eﬃcacy of structured prompts in NetLogo’s\nknowledge-driven bird ﬂocking simulation, which is also a\nclassic model demonstrating self-organizing behavior in MAS.\nIt is inspired by Craig Reynolds’ “Boids” model (\nReynolds,\n1987), which simulates how birds, ﬁsh, or other animals move\nin cohesive groups without a central leader.\n• To present a comprehensive toolchain that combines LLMs\nwith multi-agent simulation environments, oﬀering a new\nmethod for modeling and analyzing swarm behavior in\ncomplex systems.\nThis investigation aims to explore how LLMs, through eﬀective\nprompt engineering, can be integrated into multi-agent systems to\nmodel and guide emergent, self-organizing behaviors in simulated\nenvironments.\n/one.tnum./four.tnum Background and related work\nThe integration of generative AI into multi-agent systems\nrepresents a burgeoning ﬁeld that seeks to enhance the autonomy,\nFrontiers in Artiﬁcial Intelligence /zero.tnum/two.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nadaptability, and realism of agent behaviors in simulations. This\napproach leverages the vast knowledge embedded within LLMs to\ninﬂuence agent interactions in ways that were previously unfeasible\nwith traditional rule-based systems. The use of generative AI in\nmulti-agent simulations has opened new avenues for exploring\ncomplex behaviors, emergent dynamics, and adaptive systems.\nIn particular, the integration of LLMs with agent-based\nsimulations represents a signiﬁcant convergence of natural\nlanguage processing (NLP) and complex systems modeling. LLMs,\nwith their ability to generate human-like text and understand\ncomplex linguistic patterns, have transformed various ﬁelds within\nartiﬁcial intelligence, particularly in automating and interpreting\nlanguage-based tasks. Agent-based simulations are a robust\nframework for modeling complex systems where individual agents\ninteract with each other and their environment, potentially leading\nto emergent behaviors. The use of LLMs in simulations may\nhereby vary widely, from highly structured, rule-based prompts\nthat delineate speciﬁc actions to more generalized prompts that rely\non the LLM’s broader knowledge base. This study highlights two\ndistinct methodologies in applying LLM capabilities to simulate\nemergent, multi-agent behaviors with varying degrees of prompt\nspeciﬁcity and autonomy.\nIntegrating LLMs with agent-based simulations presents\ntransformative opportunities across various domains, enhancing\nthe realism and complexity of simulations. This integration can\nsigniﬁcantly improve the modeling of social systems, industrial\nautomation, and multi-agent interactions.\nPark et al. (2023) introduce an LLM-driven agent that can\nengage and converse with both humans and other AI agents.\nThe agent has the capability to generate text that can be\ncomprehended and interpreted by other agents. This facilitates\nclear communication between them, fostering eﬀective interactions\nand collaboration. The simulated environment functions as a\nsandbox composed of text, allowing the agent to perceive and\ninterpret the surrounding context eﬀectively. This setting enables\nthe agent to navigate and interact with the provided information.\nInspired by the work of\nPark et al. (2023) , Junprung (2023) presents\ntwo LLM-driven experiments, two-agent negotiation, and a six-\nagent murder mystery game to simulate human behavior. The\nauthor describes the behavior of three categorical diﬀerent LLM-\ndriven simulations and discusses the limitations of large-scale\nlanguage models.\nGao et al. (2023) create a framework for social network\nsimulation called S3. They simulate motion, attitude, and\ninteractive behaviors to emulate social behavior. Due to the\nchanging environment, the agents have to adapt and retain a\nmemory to utilize past experiences and adjust their behavior. They\nobserve the emergence of collective behavior among the agents and\nconclude their environment holds potential for further exploration\nin the ﬁelds of social sciences and informed decision-making. This\ninsight suggests that the dynamics observed could provide valuable\nperspectives on group interactions and collaborative processes.\nThe research of\nDasgupta et al. (2023) investigates the use of\nLLMs to improve the decision-making abilities of AI agents that\ninteract with their environment. The proposed system consists of\nthree parts: a Planner that uses a pre-trained LLM to generate\ninstructions, a reinforcement-learning agent, the Actor, that carries\nout these instructions, and a Reporter that provides environmental\nfeedback to the Planner. The Planner reads a description of the\ntask and breaks it down into simple instructions for the Actor,\nwho was trained to understand simple instructions and operates\nupon them. The Reporter observes the eﬀects of the Actor’s actions\non the environment and communicates this information in a\ntext-based form back to the Planner. The system is tested on\ncomplex tasks that require reasoning and gathering information,\nand the results show that it outperforms traditional reinforcement\nlearning methods, especially when using larger language models.\nThe researchers demonstrate that Large language models (70 billion\nparameters) consistently outperformed smaller language models\n(7 billion parameters) in the experiments, indicating that larger\nmodels have resilience against noisy or irrelevant information\nand greater capacity for the complex reasoning required to solve\nthese tasks.\nZhu et al. (2023) present Ghost in the Minecraft\n(GITM), a framework for developing general capable agents\nin the Minecraft world. In contrast to previous approaches,\nespecially reinforcement learning algorithms, GITM uses large\nlanguage models to achieve high success rates, e.g. in the \"Obtain\nDiamond\" task. Typical reinforcement learning-based agents often\nstruggle with the complexity of Minecraft due to the long time\nhorizon of the task, which can lead to diﬃculties in learning and\nadapting. In contrast,\nZhu et al. (2023) leverages LLMs to enable\na hierarchical decomposition of complex tasks into manageable\nsub-goals and structured actions. This approach yields signiﬁcantly\nhigher eﬃciency and robustness, allowing agents to better navigate\nand interact with the Minecraft environment. GITM integrates the\nlogical reasoning and knowledge base of LLMs with text-based\nknowledge and memory, enabling eﬀective interaction with the\nenvironment and the pursuit of intricate, long-term objectives. The\narticle demonstrates the potential of LLMs for the development of\ngenerally capable agents in open, complex environments.\nRecently, researchers incorporated LLM into swarm systems\nto leverage the reasoning and knowledge capabilities of these\nmodels (\nGao et al., 2024 ; Qu, 2024 ). Strobel et al. (2024)\nintegrate LLMs into robot swarms to enhance their reasoning,\nplanning, and collaboration abilities. They exchange the robot\nprogramming controller by proposing two changes: (1) An indirect\nintegration uses LLMs to generate and validate the programming\nof the controller before or during the deployment. This approach\nimproves eﬃciency and reduces human error by automating the\ndesign process. (2) A direct integration implements a separate LLM\nfor each robot during deployment, enabling the robot to plan,\nreason, and collaborate using natural language. The LLM-driven\nrobots can detect and respond to unexpected behaviors and are\nmore resilient in dynamic environments without prior information.\nFeng et al. (2024) present an algorithm aimed at adapting\nLLM experts using collaborative search techniques inspired by\nswarm intelligence. This method allows several LLMs to collaborate\nin exploring the weight space to optimize a speciﬁc utility\nfunction without the need for extensive ﬁne-tuning data or strong\nassumptions about the models involved. In their work, each LLM\ncan be treated as a particle within a swarm navigating within the\nweight space and adjusting its position based on its best or worst-\nfound solutions. The algorithm demonstrates ﬂexibility in diﬀerent\nsingle or multi-task objectives. Due to their collaborative search\nFrontiers in Artiﬁcial Intelligence /zero.tnum/three.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\napproach the LLM experts can discover unseen capabilities, which\nenables the transition from weak to strong performance levels.\nIn their work, called Swarm-GPT,\nJiao et al. (2023) integrate\nLLMs with motion-based planning to automate Unmanned Aerial\nVehicle (UAVs) swarm choreography. Users are able to generate\nsynchronized drone performance via language commands. Swarm-\nGPT is able to utilize LLMs to create UAVs formations and\nmovements which are synchronized to music. The system includes\na trajectory planner that utilizes waypoints generated by the LLM,\nguaranteeing that the drone movements are both collision-free\nand feasible. Swarm-GPT has been eﬀectively demonstrated at live\nevents, highlighting its practical application and ability to perform\nin real time.\nLiu et al. (2024c) explore the application of multimodal\nLLMs to control the formation of UAVs using image and text\ninputs. The researchers ﬁrst pre-trained an LLM on a single\nUAV , demonstrating the LLM’s potential to interpret and execute\ncommands eﬀectively. Then they expanded their approach to\ncoordinate multiple UAVs in formation. The multimodal LLM\nrecognizes environmental signals from the images captured by the\nprimary drone (via a camera). Then, the pre-trained LLM analyzes\nthe data and generates instructions for managing the UAV to attain\na speciﬁed formation.\nAnother application in language-guided formation control is\npresented by\nLiu et al. (2024b) . The authors propose a framework\ncalled Language-Guided Pattern Formation (LGPF) for swarm\nrobotics. Their system employs an LLM to translate a high-level\npattern description into speciﬁc actions for a swarm of robots,\nintegrating multi-agent reinforcement learning for detailed control.\nThe LGPF framework allows for intuitive and ﬂexible control\nof robot swarms, enabling them to achieve complex formations\nguided by natural language instructions.\nMost existing MAS and swarm intelligence simulations rely\non explicitly programmed, rule-based behaviors that are often\ndomain-speciﬁc and lack ﬂexibility. While several recent works\nhave explored LLMs for planning or social agent interactions, such\nas role-playing agents or virtual societies, these typically focus on\nhuman-like reasoning, not swarm intelligence or nature-inspired\ncollective behavior. In contrast to existing literature, our paper\nmakes the following contributions. (1) We investigate how LLMs\ncan be integrated into swarm intelligence. This is one of the\nﬁrst works to use LLMs as decentralized behavioral engines for\nnon-human and non-verbal, swarm-like agents. We demonstrate\nour framework on two classical swarm intelligence scenarios–ant\ncolony foraging and bird ﬂocking–each involving diﬀerent sensory\ninputs and emergent outcomes. In both cases, agents receive\nlocalized information about their environment and act based\non LLM-generated decisions. (2) We introduce a generalizable\ntoolchain for integrating LLMs with OpenAI’s GPT models\nvia Python, enabling agents to act based on prompt-generated\ndecisions rather than ﬁxed procedural logic. This framework\ndecouples agent logic from hardcoded rules, enabling behavior to\nbe modiﬁed or extended via natural language prompts. (3) Our\nwork compares two categories of LLM prompt - structured rule-\nbased and autonomous knowledge-driven - to show how diﬀerent\nprompt designs aﬀect emergent behavior in collective systems.\nWhile the structured prompts encode rule-based logic in natural\nlanguage, the autonomous prompts rely on the LLM’s internal\nknowledge and general reasoning. This comparison provides\ninsight into the design space of LLM-based agent prompts and their\neﬀect on emergent system dynamics.\n/two.tnum Materials and methods\nIn this study, we employed two distinct simulations of the\nbehavior of social insects to explore the integration of LLMs\nin guiding agent behaviors within multi-agent systems. The\nexperiments were designed to investigate the eﬀectiveness of\nstructured, rule-based prompts in one scenario and principle-\nbased, knowledge-driven prompts in the other one. Both\nsimulations utilize the LLM to process environmental inputs and\ngenerate agent actions, providing insights into how LLMs can\nbe leveraged to model complex behaviors such as foraging and\nﬂocking.\nStructured rule-based prompts are designed with explicit,\npredeﬁned instructions that guide the LLM to generate\ndeterministic agent actions. These prompts specify exact conditions\nand responses, ensuring consistent and predictable agent behaviors.\nFor example, in a foraging scenario, structured prompts might\ninclude direct rules for following pheromone trails or picking up\nfood when encountered.\nKnowledge-driven prompts, on the other hand, rely on the\nLLM’s inherent understanding of broader behavioral concepts\nand principles. These prompts are less rigid and provide the\nTABLE /one.tnum Comparative analysis of structured, rule-based prompts versus\nknowledge-driven prompts, highlighting their distinctive design crit eria,\noperational characteristics, and intended use within agent-based\nsimulations.\nCriterion Structured,\nrule-based\nprompts\nKnowledge-\ndriven\nprompts\nPrompt design Clearly deﬁned rules,\nexplicit instructions\nFlexible guidelines,\nopen-ended knowledge\nrequests\nNature of guidance Deterministic,\nprescriptive\nNon-deterministic,\nexplorative\nTask scope Narrowly deﬁned,\nspeciﬁc tasks\nBroadly deﬁned, general\nobjectives\nOutput variability Limited, predictable\noutputs\nHigh variability, adaptive\noutputs\nAgent autonomy Low autonomy; actions\nexplicitly guided by rules\nHigh autonomy; agents\nindependently reason\nand adapt\nDependency on\npredeﬁned rules\nHigh; relies strictly on\npre-speciﬁed\ninstructions\nLow; leverages intrinsic\nknowledge of the model\nAdaptability to new\nscenarios\nLimited; requires manual\nadjustment of rules\nHigh; readily adapts\nusing implicit knowledge\nComplexity of\nprompt structure\nStructured, ﬁxed\ntemplates\nDynamic, context-driven\nstructures\nUse case examples Speciﬁc simulations,\ncontrolled experiments\nExplorative tasks, novel\nscenario discoveryFrontiers in Artiﬁcial Intelligence /zero.tnum/four.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nLLM with general guidelines, enabling more adaptive and ﬂexible\nagent behaviors. In the context of a bird ﬂocking simulation,\nsuch prompts might encourage behaviors based on principles\nlike alignment, cohesion, and separation without specifying exact\nactions, allowing the LLM to synthesize responses that foster\nemergent, self-organizing dynamics.\nTo clearly illustrate the conceptual diﬀerences between the\ntwo types of prompts employed in this study: structured, rule-\nbased prompts and knowledge-driven prompts,\nTable 1 presents\na comparative analysis outlining their deﬁning criteria and\ncharacteristics.\n/two.tnum./one.tnum Toolchain for LLM-driven multi-agent\nsimulations with NetLogo\nFigure 1 illustrates the toolchain for LLM-driven multi-agent\nsimulations with NetLogo, showing the integration between\nNetLogo, GPT-4o, and the Python extension. The following\nenumeration describes each step of the workﬂow:\n1. Environment encoding: The simulation toolchain leverages\nNetLogo to capture real-time environmental states, including\nagent positions, inter-agent interactions, and other relevant\nenvironmental variables depending on the simulation (e.g.\npheromone concentrations). These data are encoded into\nstructured prompts that convey a comprehensive environmental\ncontext to the LLM. This encoding ensures that the LLM receives\ntimely, accurate input representing dynamic changes in the\nenvironment.\n2. Python extension integration: NetLogo uses its Python\nextension to facilitate communication with GPT-4o via the\nOpenAI API. This extension allows NetLogo to send encoded\nenvironmental data as prompts to the LLM and receive\nstructured responses, enabling the interaction between the\nsimulation platform and the LLM.\n3. LLM processing:The structured prompts are processed by GPT-\n4o, which interprets the input data and generates agent behavior\nsuggestions based on encoded environmental information. The\nLLM’s ability to process complex, context-rich data allows it to\ninfer and propose actions that adhere to predeﬁned rules (for\nstructured prompts) or leverage general behavioral principles\n(in principle-based prompts). This stage ensures that agent\nresponses align with the overall objectives of the simulation, be\nit foraging success or cohesive ﬂocking.\n4. Decoding LLM output: The LLM output, formatted as a\nstructured JSON or Python dictionary, is translated into\nexecutable actions predeﬁned within the NetLogo simulation.\nThis step converts the structured actions generated by the\nLLM into precise instructions for agents, such as movement\nvectors, state transitions, or pheromone release behaviors. The\nPython extension facilitates this process by receiving the LLM\nresponses from the OpenAI API and converting them into a\nNetLogo-compatible data structure. This translation mechanism\nensures both syntactic and semantic alignment between the\nLLM’s output and the data format required by the simulation.\n5. Agent action execution and iterative process:The decoded\ncommands are executed by the agents in NetLogo, updating\ntheir states and behaviors in response to the LLM’s instructions.\nThis action directly modiﬁes the simulation environment,\nforming a closed-loop system where each action feeds back into\nthe environmental context for the next iteration. The iterative\nprocess ensures that agent behaviors continuously respond to\nevolving environmental conditions and LLM feedback, fostering\nemergent behaviors and adaptive responses.\nThe following sections detail the setup, LLM integration, and\nprocedures used in each experiment.\n/three.tnum Experiment /one.tnum: ant colony foraging\nsimulation\nAs mentioned above, this experiment is based on the ant\nforaging model implemented in the NetLogo library (see https://\nccl.northwestern.edu/netlogo/models/Ants). It takes place in a two-\ndimensional foraging area consisting of designated food sources\nscattered throughout the environment and a central nest where the\nants must return to deposit the food they collect. The environment\nis designed to mimic natural foraging conditions, where agents\n(ants) must navigate to ﬁnd food and return it to the nest while\ninteracting with environmental cues such as pheromone trails and\nnest scents; see\nFigure 2.\n• Agents: The simulation features stateless ants, each operating\nas an independent agent without memory of past actions.\nThese ants rely entirely on real-time environmental inputs and\nLLM-generated prompts to determine their behaviors. The\nagents are designed to follow explicit, rule-based instructions\nderived from the LLM, ensuring that their actions are\npredictable and consistent with predeﬁned conditions.\n• LLM integration: OpenAI GPT-4o is employed to process\nstructured prompts that deﬁne the ants’ behaviors. The\ndefault API parameters are used, with the exception of the\ntemperature, which is set to 0.0 to ensure deterministic results\nbased on the provided inputs. The LLM receives real-time\nenvironmental information and generates actions according\nto a predeﬁned set of rules. These structured prompts ensure\nthat the ants’ responses are clearly deﬁned and predictable,\nenabling systematic analysis of their behavior. Nevertheless,\nthere is still a small chance that the LLM may occasionally\ngenerate responses that deviate from the speciﬁed rules.\n/three.tnum./one.tnum Procedure\n/three.tnum./one.tnum./one.tnum Prompt design\nThe prompt is structured as a zero-shot prompt, requiring\nthe LLM to generate accurate responses without relying on\nprior examples or contextual memory from previous interactions.\nThis intentional design maintains stateless prompts to control\nthe agents. We employed an API function that does not retain\nconversation context between prompts, making each interaction\nindependent and requiring the LLM to interpret and respond\nsolely based on the current input. The ﬁnal prompt used in\nFrontiers in Artiﬁcial Intelligence /zero.tnum/five.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nFIGURE /one.tnum\nDiagram illustrating the toolchain for LLM-driven multi-agent s imulations, integrating NetLogo and GPT-/four.tnumo via the Python extension and OpenAI API.\nThe workﬂow showcases a closed-loop process where environmental stat es are encoded into structured prompts, processed by GPT-/four.tnumo to\ngenerate behavior suggestions, decoded into executable actions, a nd iteratively executed by agents within the NetLogo simulation environment.\nFIGURE /two.tnum\nAnt foraging simulation in NetLogo. The central circle depicts the nest area, while the three blue circles nearby indicate food sou rces.\nour experiments resulted from several iterations in a trial-and-\nerror process to ensure the LLM could eﬀectively understand the\nenvironment and rules and execute the expected tasks accordingly.\nFor this experiment, precise behavioral rules were provided for\nthe ants within the simulation, including instructions such as\nfollowing pheromone trails when searching for food, picking\nup food when encountered, and releasing pheromones to mark\nfood sources.\nFrontiers in Artiﬁcial Intelligence /zero.tnum/six.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\n/three.tnum./one.tnum./two.tnum Tuning process\nOur initial approach utilized minimal instructions, providing\na general description of the foraging task to assess how eﬀectively\nants could perform without speciﬁc guidance: ﬁnding food,\nmarking paths to food sources using pheromones, and utilizing nest\nscent to navigate back to the nest when carrying food. This minimal\ninstruction set was intentionally selected based on fundamental\nbiological principles described in ecological literature related to\nant foraging behavior, particularly focusing on pheromone-based\ncommunication and nest-scent navigation. The primary rationale\nwas to evaluate the inherent capacity of LLM-driven agents to\nmanifest realistic collective foraging behavior without extensive,\nexplicitly detailed instructions. Through this initial generalization\nattempt, we aimed to determine whether the LLM required\nmore detailed or structured instructions to accurately reproduce\nemergent ant colony behaviors.\nFollowing the initial evaluation, it became clear that more\nexplicit rules were essential for consistent and realistic ant\nbehavior. Throughout this iterative process, the language model\noﬀered valuable feedback by highlighting misunderstandings or\nambiguities in the prompts. This feedback was instrumental in\nreﬁning the prompts to enhance the ants’ performance. Below, we\npresent an analysis of how these prompts evolved, focusing on\nspeciﬁc improvements and the reasoning behind each iteration.\nIteration 1\n• Prompt Text\n1 You a r e an a n t i n a 2D s i m u l a t i o n t a s k e d w i t h\nf i n d i n g food , marking t h e p a t h t o food\nw i t h t r a i l s o f pheromones , and u s i n g n e s t\ns c e n t t o n a v i g a t e back t o t h e n e s t when\nc a r r y i n g food .\n2\n3 Format your a c t i o n s a s a Python d i c t i o n a r y\nw i t h t h e s e k e y s and o p t i o n s :\n4 ‘ ‘ move−forward ’ ’ : True or F a l s e ,\n5 ‘ ‘ r o t a t e ’ ’ : ‘ ‘ l e f t ’ ’ , ‘ ‘ r i g h t ’ ’ , or ‘ ‘ none\n’ ’,\n6 ‘ ‘ pick −up−food ’ ’ : True or F a l s e ,\n7 ‘ ‘ drop−pheromone ’ ’ : True or F a l s e ,\n8 ‘ ‘ drop−food ’ ’ : True or F a l s e .\n9\n10 You w i l l be p r o v i d e d w i t h environment\ni n f o r m a t i o n . Keep your r e s p o n s e c o n c i s e ,\nunder 3 5 t o k e n s .\n11\n12 C u r r e n t environment :\n13 −Pheromone c o n c e n t r a t i o n ( L e f t : 0 , F r o n t :\n0 , R i g h t : 0 ) ,\n14 −Nest p r e s e n c e : True ,\n15 −Nest s c e n t ( L e f t : 1 9 6 . 8 4 , F r o n t : 1 9 6 . 3 9 ,\nR i g h t : 1 9 5 . 7 6 ) ,\n16 −Food c o n c e n t r a t i o n a t your l o c a t i o n : 0 ,\n17 −C a r r y i n g food s t a t u s : True\n• Observed behavior\nIn this ﬁrst attempt, we provided general instructions\nto establish a baseline for ant behavior. The ants were\ntasked with ﬁnding food, marking paths with pheromones,\nand using nest scent to return home when carrying\nfood. However, simulations revealed inconsistencies.\nAnts often failed to follow pheromone and nest scent\ngradients eﬀectively, sometimes moving away from stronger\ncues. Some ants released pheromones unexpectedly,\nwhile others exhibited random movement patterns. This\ninconsistency prevented the colony from displaying an\norganized foraging behavior, indicating that clearer rules\nwere needed for actions such as pheromone release and\ngradient follow-up.\n• Analysis\nWhile this prompt established the basic framework for\nthe simulation, it lacked speciﬁc guidance on how ants\nshould interpret and prioritize environmental cues or resolve\nconﬂicting signals. The absence of detailed instructions led to\nambiguous behaviors, including inconsistencies in following\npheromone and nest scent gradients. This highlighted the\nneed for more explicit rules to ensure consistent and organized\nswarm behavior.\nIteration 2\n• Prompt text\nWe add an instruction to the prompt to prioritize nest\nscent over pheromone trails when carrying food.\n1 You a r e an a n t i n a 2D s i m u l a t i o n t a s k e d w i t h\nf i n d i n g food , marking t h e p a t h t o food w i t h\npheromone t r a i l s , and u s i n g n e s t s c e n t t o\nn a v i g a t e back t o t h e n e s t when c a r r y i n g food .\nP r i o r i t i z e n e s t s c e n t o v e r pheromone t r a i l s\nwhen c a r r y i n g food .\n2 . . .\n• Observed behavior\nTo address the issues from the ﬁrst prompt, we added\na directive for ants to prioritize nest scent over pheromone\ntrails when carrying food, aiming to better mimic foraging\nant behavior. Despite this improvement, ants still exhibited\ninconsistencies in following pheromone and nest scent\ngradients. When nest scent and pheromone trails had similar\nstrengths, ants demonstrated conﬂicting actions. Additionally,\nthe prompt did not specify behaviors for ants not carrying\nfood, leading to ineﬃcient exploration. Ants tended to\nrotate aimlessly near the nest and were slow to venture\noutward, showing the need for clearer guidance to improve\nexploration eﬃciency.\n• Analysis\nIntroducing prioritization helped align the ants’ actions\nwhen carrying food, but inconsistencies in following scent\ngradients persisted. Ants not carrying food and not sensing\nany pheromones tended to remain near the nest without\neﬀectively exploring the environment. This emphasized\nthe necessity for comprehensive guidance covering all\npossible states and clearer instructions on responding to\nenvironmental cues to enhance exploration eﬃciency.\nIteration 3\n• Prompt text\nFrontiers in Artiﬁcial Intelligence /zero.tnum/seven.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nAs before, with added clariﬁcations in the current\nenvironment:\n1 . . .\n2 −Nest p r e s e n c e : True ( You a r e c u r r e n t l y a t\nt h e n e s t ) ,\n3 −C a r r y i n g food s t a t u s : True ( You a r e\nc u r r e n t l y c a r r y i n g food )\n4 . . .\n• Observed behavior\nWe observed that ants sometimes failed to pick up food\nor drop it at the nest, possibly due to a lack of awareness of\ntheir current state. To rectify this, we explicitly stated their\nstatus in the prompt, such as whether they were at the nest or\ncarrying food. This redundancy ensured that ants performed\ncorrect actions in these situations. However, inconsistencies\nin following pheromone and nest scent gradients remained.\nAnts continued to exhibit limited exploration when not\ncarrying food, tending to stay near the nest rather\nthan venturing into new areas or eﬀectively following\npheromone trails.\n• Analysis\nExplicitly stating the ants’ status improved decision-\nmaking by providing clear context, leading to better execution\nof actions like picking up and dropping food. Yet, the lack of\nspeciﬁc instructions on following scent gradients meant ants\nstill showed inconsistencies in navigating toward pheromone\ntrails or nest scent. Their ineﬃcient exploration highlighted\nthe need for clearer guidance to enhance movement away from\nthe nest.\nIteration 4\n• Prompt text\nWe add an instruction to the prompt to use the highest\npheromone scent to navigate to food when not carrying any.\n1 You a r e an a n t i n a 2D s i m u l a t i o n . Your t a s k\ni s t o p i c k up food and r e l e a s e i t a t t h e\nn e s t . Use n e s t s c e n t t o n a v i g a t e back t o\nt h e n e s t when c a r r y i n g food , p r i o r i t i z i n g\nn e s t s c e n t o v e r pheromones . Use h i g h e s t\npheromone s c e n t t o n a v i g a t e t o food when\nnot c a r r y i n g any .\n2 . . .\n• Observed behavior\nTo guide ants not carrying food, we speciﬁed that\nthey should navigate toward food using the highest\npheromone concentration. Their ability to ﬁnd food\nsources when pheromone trails were present was\nclearly improved in this way. However, inconsistencies\nin following pheromone gradients persisted. In\nthe absence of pheromones or nest scents, ants\ntended to remain near the nest, exhibiting ineﬃcient\nexploration behaviors.\n• Analysis\nBy distinguishing between the states of carrying and\nnot carrying food, we enhanced the ants’ foraging eﬃciency\nwhen environmental cues were available. Nonetheless,\ninconsistencies in following pheromone gradients indicated\nthat ants needed clearer instructions on interpreting and\nacting upon varying scent intensities. The lack of an eﬀective\nexploration strategy, when cues were absent, remained\na challenge.\nIteration 5\n• Prompt text\nEnvironmental information about pheromone\nconcentration and nest scent presented with directional\ncues instead of quantities:\n1 . . .\n2 C u r r e n t environment :\n3 −Higher Pheromone C o n c e n t r a t i o n : F r o n t ,\n4 −Nest P r e s e n c e : F a l s e ( You a r e not\nc u r r e n t l y a t t h e n e s t ) ,\n5 −S t r o n g e r Nest S c e n t : L e f t ,\n6 −Food C o n c e n t r a t i o n a t your l o c a t i o n : 0 ,\n7 −C a r r y i n g Food S t a t u s : True ( You a r e\nc u r r e n t l y c a r r y i n g food ) }\n• Observed behavior\nRecognizing the need for better interpretation of\nenvironmental cues, we modiﬁed how information was\npresented by using directional descriptions instead of\nnumerical values—e.g., “Higher Pheromone Concentration:\nFront” and “Stronger Nest Scent: Left.” This adjustment\nsigniﬁcantly improved the ants’ ability to follow pheromone\nand nest scent gradients. Ants became more consistent in\nmoving toward stronger cues, enhancing their navigation and\nforaging eﬃciency.\nHowever, when no scents were detected, ants still\nshowed limited exploration, often remaining near the\nnest rather than actively searching new areas. This\nindicated that while gradient following had improved,\nthe exploration strategy was still ineﬃcient in the absence of\nsensory cues.\n• Analysis\nUsing directional cues provided clearer guidance\non responding to environmental gradients, resolving\nmany inconsistencies observed in previous prompts.\nFrom Prompt 5 onward, ants became more adept\nat following pheromone and nest scent gradients,\nleading to a more organized foraging behavior. Despite\nthese improvements, ants’ exploration remained\nineﬃcient when no sensory cues were present,\nindicating a need for further instructions to promote\neﬀective exploration.\nIteration 6\n• Prompt text\nWe add an instruction to the prompt to\nrelease pheromones on food sources and while\ncarrying food.\nFrontiers in Artiﬁcial Intelligence /zero.tnum/eight.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\n1 You a r e an a n t i n a 2D s i m u l a t i o n . Your t a s k i s t o\np i c k up food and r e l e a s e i t a t t h e n e s t .\nR e l e a s e pheromone on food s o u r c e and w h i l e you\na r e c a r r y i n g food . Use n e s t s c e n t t o n a v i g a t e\nback t o t h e n e s t when c a r r y i n g food ,\np r i o r i t i z i n g n e s t s c e n t o v e r pheromones . Use\nh i g h e s t pheromone s c e n t t o n a v i g a t e t o food\nwhen not c a r r y i n g any .\n2 . . .\n• Observed behavior\nTo encourage trail formation back to the nest, we\ninstructed ants to release pheromones while carrying food.\nThis led to stronger trails and improved the eﬃciency of other\nants in locating food sources. With the improved gradient-\nfollowing ability from Prompt 5, ants were more consistent\nin navigation.\nNevertheless, in the absence of pheromones and nest\nscents, ants still exhibited limited exploration behaviors,\ntending to stay near the nest. This indicated that their\nexploration strategy was still ineﬃcient and required\nreﬁnement.\n• Analysis\nBy enhancing pheromone deposition during food\ntransport and improving gradient following, we boosted\ncolony cooperation and foraging success. However,\nthe persistent issue of limited exploration in scent-\nfree areas indicated that additional instructions were\nnecessary to promote outward movement and enhance\nexploration eﬃciency.\nIteration 7\n• Prompt text\nWe added the word “only” in the prompt as follows:\n1 You a r e an a n t i n a 2D s i m u l a t i o n . Your t a s k\ni s t o p i c k up food and r e l e a s e i t a t t h e\nn e s t . R e l e a s e pheromone on food s o u r c e and\nw h i l e you a r e c a r r y i n g food . Use n e s t\ns c e n t t o n a v i g a t e back t o t h e n e s t o n l y\nwhen c a r r y i n g food , p r i o r i t i z i n g n e s t\ns c e n t o v e r pheromones . Use h i g h e s t\npheromone s c e n t t o n a v i g a t e t o food when\nnot c a r r y i n g any .\n2 . . .\n• Observed behavior\nIn earlier iterations, ants sometimes prioritized\nnest scent over pheromones even when not carrying\nfood, leading them to return to the nest unnecessarily.\nWith this clariﬁcation, the ants began to prioritize the\nnest scent appropriately, using it only when they were\ncarrying food. However, ants still exhibited limited\nexploration when no sensory cues were present, tending\nto remain near the nest rather than actively searching\nnew areas.\n• Analysis\nAdding “only” to the instruction text was crucial\nto ensure that the ants did not prioritize the scent\nof the nest when they were looking for food. This\neliminated unnecessary returns and improved foraging\neﬃciency.\nIteration 8\n• Prompt text\nWe added an instruction to the prompt to move away from\nthe nest and rotate randomly if not carrying any food and not\nsensing any pheromone.\n1 You a r e an a n t i n a 2D s i m u l a t i o n . Your t a s k\ni s t o p i c k up food and r e l e a s e i t a t t h e\nn e s t . R e l e a s e pheromone on food s o u r c e and\nw h i l e you a r e c a r r y i n g food . Use n e s t\ns c e n t t o n a v i g a t e back t o t h e n e s t o n l y\nwhen c a r r y i n g food , p r i o r i t i z i n g n e s t\ns c e n t o v e r pheromones . Use h i g h e s t\npheromone s c e n t t o n a v i g a t e t o food when\nnot c a r r y i n g any . Move away from n e s t and\nr o t a t e randomly i f you a r e not c a r r y i n g\nany food and you a r e not s e n s i n g any\npheromone .\n2 . . .\n• Observed behavior\nIn previous iterations, we observed limited exploratory\nbehavior of the ants in areas without scents. To address\nthis, we introduced a directive for proactive exploration. This\napproach improved exploration, with ants venturing further\nfrom the nest and discovering food sources in fewer simulation\nsteps. However, a noticeable bias concerning the rotation\nremained, particularly around the nest, indicating that the\nrandomness was not functioning as eﬃciently as intended.\n• Analysis\nBy instructing ants to move away from the nest and\nrotate randomly when not carrying food and not sensing\npheromones, we encouraged them to explore new areas more\neﬀectively. This change increased the likelihood of ants ﬁnding\nfood, as they ventured further from the nest rather than\nlingering nearby.\nIteration 9\n• Prompt text\nWe expanded the rotation options to include “random”:\n1 . . .\n2 ‘ ‘ r o t a t e ’ ’ : ‘ ‘ l e f t ’ ’ , ‘ ‘ r i g h t ’ ’ \" , ‘ ‘ none ’ ’ ,\nor ‘ ‘ random ’ ’\n3 . . .\n• Observed behavior\nWith this adjustment, ants demonstrated more varied and\nunpredictable movement patterns during exploration. They\neﬀectively moved away from the nest and searched a wider\narea, increasing their chances of encountering food sources\nmore quickly and eﬃciently.\n• Analysis\nTo enhance the randomness of the ants’ exploration, we\nexpanded their rotation options to include “random.” This\nmeant that when the LLM selected “random” as the rotation\nFrontiers in Artiﬁcial Intelligence /zero.tnum/nine.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\naction, it was making a high-level decision to delegate the\nchoice of direction to chance. In the simulation, this “random’\n’ option was implemented at a programming level in NetLogo\nto randomly choose the direction of rotation either left or\nright.\nThrough iterative tuning, we signiﬁcantly enhanced the\nsimulated ants’ behavior, making it more consistent with the ant\nforaging dynamics observed in the rule-based NetLogo model. Each\nprompt iteration addressed speciﬁc issues identiﬁed in simulations,\nwith language model feedback guiding some of the adjustments.\n/three.tnum./one.tnum./three.tnum Prompt deployment\nThe prompts are presented in a format that the LLM\ncan process and output as a series of actionable commands.\nCommunication with the LLM is facilitated through the OpenAI\nAPI, speciﬁcally using the chat.completions mechanism,\nwhich allows context-free messages to be passed at each step. This\nsetup involves sending a system prompt that outlines the overall\ntask and rules, followed by user prompts that provide real-time\nenvironmental information.\nAt each simulation step, NetLogo translates the agent’s\nperception of its environment into the input variables described in\nthe prompt. This ensures that the LLM has an accurate and up-to-\ndate representation of the environment on which its decisions can\nbe based. The LLM then generates a response formatted as a Python\ndictionary, containing speciﬁc actions the agent should take. The\nfollowing example prompt illustrates the process:\n• System prompt\n1 You a r e an a n t i n a 2D s i m u l a t i o n . Your t a s k\ni s t o p i c k up food and r e l e a s e i t a t t h e\nn e s t . R e l e a s e pheromone on food s o u r c e and\nw h i l e you a r e c a r r y i n g food . Use n e s t\ns c e n t t o n a v i g a t e back t o t h e n e s t o n l y\nwhen c a r r y i n g food , p r i o r i t i z i n g n e s t\ns c e n t o v e r pheromones . Use h i g h e s t\npheromone s c e n t t o n a v i g a t e t o food when\nnot c a r r y i n g any . Move away from n e s t and\nr o t a t e randomly i f you a r e not c a r r y i n g\nany food and you a r e not s e n s i n g any\npheromone . Format your a c t i o n s a s a Python\nd i c t i o n a r y w i t h t h e s e k e y s and o p t i o n s :\n2\n3 ‘ ‘ move−forward ’ ’ ( o p t i o n s : True , F a l s e )\n4 ‘ ‘ r o t a t e ’ ’ ( o p t i o n s : ‘ ‘ l e f t ’ ’ , ‘ ‘ r i g h t ’ ’ ,\n‘ ‘ none ’ ’ , ‘ ‘ random ’ ’ )\n5 ‘ ‘ pick −up−food ’ ’ ( o p t i o n s : True , F a l s e )\n6 ‘ ‘ drop−pheromone ’ ’ ( o p t i o n s : True , F a l s e )\n7 ‘ ‘ drop−food ’ ’ ( o p t i o n s : True , F a l s e ) .\n8\n9 You w i l l be p r o v i d e d w i t h environment\ni n f o r m a t i o n . Keep your r e s p o n s e c o n c i s e ,\nunder 4 5 t o k e n s .\n• Possible user prompt\n1 T h i s i s your c u r r e n t environment :\n2 −H i g h e s t Pheromone C o n c e n t r a t i o n : None ,\n3 −Nest P r e s e n c e : True ( You a r e c u r r e n t l y a t\nt h e n e s t ) ,\n4 −S t r o n g e r Nest S c e n t : F r o n t ,\n5 −Food C o n c e n t r a t i o n a t your\n6 l o c a t i o n : 0 ,\n7 −C a r r y i n g Food S t a t u s : F a l s e ( You a r e not\nc u r r e n t l y c a r r y i n g food ) .\n• Possible response from the LLM\n1 {\n2 ‘‘move-forward’’: True,\n3 ‘‘rotate’’: ‘‘none’’,\n4 ‘‘pick-up-food’’: False,\n5 ‘‘drop-pheromone’’: False,\n6 ‘‘drop-food’’: False\n7 }\n/three.tnum./two.tnum System monitoring\nThe simulation monitors the ants’ eﬃciency in navigating\nthe environment, speciﬁcally their ability to locate food, follow\npheromone trails, and return food to the nest. Key metrics\ninclude the time taken to ﬁnd and return food, the consistency of\npheromone trail usage, and the accuracy of following the nest scent\nwhen carrying food. The observed behaviours and performance\nanalysis are documented in the result section.\n/four.tnum Experiment /two.tnum: bird ﬂocking\nsimulation\nAs mentioned before, the bird ﬂocking model of NetLogo\n(see https://ccl.northwestern.edu/netlogo/models/Flocking) is an\nimplementation of the famous Boids model from Reynolds (1987).\nThe simulation takes place in two-dimensional airspace. Although\nthis environment is relatively simple, it eﬀectively replicates key\nﬂocking behaviors like group cohesion, allowing for the observation\nof ﬂocking dynamics under varying conditions. By adjusting\nspeciﬁc parameters, the simulation provides insights into how\nchanges in the environment inﬂuence ﬂocking behavior.\n• Agents: The agents in this simulation are modeled as birds,\neach operating under principle-based prompts. Unlike rule-\nbased systems, these birds are guided by general principles\nof ﬂocking dynamics, that is, by alignment, separation, and\ncohesion (\nReynolds, 1987 ). These principles help the birds\nnavigate their environment by adjusting their headings in\nresponse to the positions and headings of neighboring birds.\n• LLM integration: The prompts provided to the LLM leverage\nits inherent knowledge of ﬂocking dynamics, requiring it to\napply these general principles to guide the behavior of each\nbird. The LLM is responsible for interpreting environmental\ndata and generating responses that ensure the birds align with\ntheir ﬂockmates, maintain an appropriate distance to avoid\ncollisions, and stay cohesive as a group.\nFrontiers in Artiﬁcial Intelligence /one.tnum/zero.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\n/four.tnum./one.tnum Procedure\n/four.tnum./one.tnum./one.tnum Prompt design\nSimilar to the setup in the case of ant foraging, prompts\nfor the ﬂocking task are structured as zero-shot prompts,\nmeaning they operate without prior examples or contextual\nmemory from previous interactions. The ﬁnal prompt was\ntuned through several iterations (see\nsubsubsection 4.1.2) in\na trial-and-error process to ensure the LLM could eﬀectively\ninterpret the environment and calculate heading directions\naccording to ﬂocking principles. Each prompt guiding a bird\nis designed to determine its heading based on the three core\nprinciples of ﬂocking dynamics as implemented in the NetLogo\nlibrary: Separation (steering to avoid crowding neighbors),\nAlignment (steering towards the average heading of nearby\nbirds), and Cohesion (steering towards the average position of\nnearby ﬂockmates).\n/four.tnum./one.tnum./two.tnum Tuning process\nThe initial rules were inspired by well established principles\nfrom ﬂocking theory, notably the classical alignment, cohesion, and\nseparation behaviors introduced in\nReynolds (1987) Boids model.\nThese basic principles were intended to produce generalized\nﬂocking patterns that could be broadly applicable across\nscenarios. However, as will be shown below, it was crucial to\nexplicitly state in the prompt that the compass convention is\nused in the simulation. This alignment with NetLogo’s world\nrepresentation, where headings are measured in degrees—0\ndegrees pointing north, 90 degrees east, 180 degrees south,\nand 270 degrees west—was essential. Clearly deﬁning this\nconvention ensured that the LLM could accurately compute\nand adjust the birds’ headings according to ﬂocking dynamics,\nmaintaining consistency in the agents’ behavior within NetLogo’s\nsimulation environment.\nIteration 1\n• Prompt Text\n1\n2 You a r e an a g e n t i n a 2D s i m u l a t i o n . Your t a s k\ni s t o d e t e r m i n e your new h e a d i n g b a s e d on\nt h e f l o c k i n g p r i n c i p l e s o f s e p a r a t i o n\nt u r n , a l i g n m e n t t u r n ( a v e r a g e h e a d i n g o f\nn e i g h b o r s ) , and c o h e r e n c e t u r n ( a v e r a g e\nh e a d i n g t o w a r d s f l o c k m a t e s ) . The\np a r a m e t e r s f o r t h e s e p r i n c i p l e s a r e :\nmaximum−s e p a r a t e −t u r n , maximum−a l i g n −t u r n ,\nmaximum−cohere −t u r n , minimum−s e p a r a t i o n −\nd i s t a n c e . The s i m u l a t i o n p r o v i d e s t h e\nf o l l o w i n g i n f o r m a t i o n : C u r r e n t h e a d i n g ,\nN e i g h b o r s i n v i s i o n r a d i u s .\n3\n4 P r o v i d e your f i n a l new h e a d i n g a f t e r a p p l y i n g\nt h e s e r u l e s , e x p r e s s e d a s an a n g l e i n\nd e g r e e s . The r e s u l t s h o u l d be i n JSON\nf o r m a t , w i t h t h e key and v a l u e : \" new−\nh e a d i n g \" ( v a l u e : h e a d i n g i n d e g r e e s ) .\nSummarize your answer i n no more than 1 2 0\nwords .\n5\n6 These a r e t h e f l o c k i n g p a r a m e t e r s :\n7\n8 Maximum s e p a r a t e t u r n : 1 . 5\n9 Maximum a l i g n t u r n : 5\n10 Maximum c o h e r e t u r n : 3\n11 Minimum s e p a r a t i o n : 1\n12\n13 T h i s i s your c u r r e n t environment :\n14\n15 C u r r e n t h e a d i n g : 1 3 8 deg\n16 N e i g h b o r s i n v i s i o n r a d i u s : n e i g h b o r _ 1 : x :\n0 . 5 3 , y : −3 . 6 9 , h e a d i n g : 2 4 8 deg\n• Observed behavior\nIn this initial attempt, we provided general instructions\nto establish a baseline for ﬂocking behavior. The agents were\ninstructed to determine their heading based on the principles\nof separation, alignment, and coherence. However, most of\nthe LLM-generated responses were not interpretable by the\nsimulation, as they did not adhere to the expected format.\nAdditionally, even when successfully parsed, inconsistencies\nin the agents’ behavior were observed, preventing the\nemergence of ﬂocking.\n• Analysis\nWhile this prompt deﬁned the basic framework for the\nsimulation, it lacked constraints to enforce a structured\nresponse. In many cases, the LLM’s output included extended\ntextual and mathematical explanations before or alongside the\nJSON object, which interfered with proper parsing.\nIteration 2\n• Prompt text\nAn explicit instruction was added to limit the response to\nthe JSON object only.\n1 . . .\n2 P r o v i d e your f i n a l new h e a d i n g a f t e r a p p l y i n g\nt h e s e r u l e s , e x p r e s s e d a s an a n g l e i n\nd e g r e e s . The r e s u l t s h o u l d be i n JSON\nf o r m a t o n l y , w i t h t h e key and v a l u e : \" new−\nh e a d i n g \" ( v a l u e : h e a d i n g i n d e g r e e s ) .\nSummarize your answer i n no more than 1 2 0\nwords .\n3 . . .\n• Observed behavior\nTo address the issues from the ﬁrst iteration, we added a\ndirective restricting the response format to a JSON object only.\nThis modiﬁcation successfully constrained the output, making\nit more reliable and compatible with the simulation. However,\nwhile some ﬂocking behavior emerged, it was inconsistent.\nSmall clusters formed brieﬂy, but overall alignment and\ncoherence were weaker than expected.\n• Analysis\nWe compared the resulting headings with those produced\nby a rule-based model. While some calculated headings were\nnumerically similar, they often pointed in opposite directions.\nThis suggested ambiguity in the LLM’s coordinate system.\nSince NetLogo employs a compass convention for heading\ncalculations, we decided to explicitly specify this convention\nin the next iteration.\nFrontiers in Artiﬁcial Intelligence /one.tnum/one.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nIteration 3\n• Prompt text\nAn instruction was added to specify that the compass\nconvention should be used.\n1 You a r e an a g e n t i n a 2D s i m u l a t i o n . F o l l o w i n g\nt h e compass c o n v e n t i o n , your t a s k i s t o\nd e t e r m i n e your new h e a d i n g b a s e d on t h e\nf l o c k i n g p r i n c i p l e s o f s e p a r a t i o n t u r n ,\na l i g n m e n t t u r n ( a v e r a g e h e a d i n g o f\nn e i g h b o r s ) , and c o h e r e n c e t u r n ( a v e r a g e\nh e a d i n g t o w a r d s f l o c k m a t e s )\n2 . . .\n• Observed behavior\nBy explicitly specifying the compass convention for\nheading calculations, ﬂocking behavior improved. Larger\nclusters formed compared to previous iterations. However,\nﬂocking remained inconsistent, as some agents moved in\nseemingly random directions.\n• Analysis\nExamining the erratic headings, we requested the\nLLM to explain its calculations. When generating a\nreasoning process before outputting the ﬁnal heading,\nthe LLM produced correct answers. However, errors\noccurred when providing only the numerical result.\nThis highlighted the need for a structured reasoning\nprocess, or “chain of thought, ” to ensure accurate\nheading calculations.\nIteration 4\n• Prompt text\nA new key, “rationale”, was added to the JSON\noutput to encourage reasoning before determining the\nﬁnal heading.\n1 . . .\n2 P r o v i d e your f i n a l new h e a d i n g a f t e r a p p l y i n g\nt h e s e r u l e s , e x p r e s s e d a s an a n g l e i n\nd e g r e e s . The r e s u l t s h o u l d be i n JSON\nf o r m a t o n l y , w i t h t h e k e y s and v a l u e s : \"\nr a t i o n a l e \" ( v a l u e : your e x p l a n a t i o n ) and \"\nnew−h e a d i n g \" ( v a l u e : h e a d i n g i n d e g r e e s ) .\n3 . . .\n• Observed behavior\nIntroducing the “rationale” key signiﬁcantly improved\nﬂocking behavior. The agents demonstrated more consistent\nheading adjustments, enhancing the emergence of ﬂocking\ndynamics. However, occasional errors persisted, particularly\nwhen agents needed to turn counterclockwise to reach a\nnearby target heading.\n• Analysis\nThe “rationale” key enabled the LLM to engage\nin a structured thought process, substantially\nimproving ﬂocking behavior. However, some agents\nstill moved in the opposite direction when making\nsmall adjustments, particularly for counterclockwise\nturns. This suggested that additional guidance was\nnecessary to ensure agents always chose the shortest\nrotation path.\nIteration 5\n• Prompt text\nAn explicit instruction was added to ensure\nthe shortest rotational path (clockwise or\ncounterclockwise) was always chosen when adjusting\nthe heading.\n1 You a r e an a g e n t i n a 2D s i m u l a t i o n . F o l l o w i n g\nt h e compass c o n v e n t i o n , your t a s k i s t o\nd e t e r m i n e your new h e a d i n g b a s e d on t h e\nf l o c k i n g p r i n c i p l e s o f s e p a r a t i o n t u r n ,\na l i g n m e n t t u r n ( a v e r a g e h e a d i n g o f\nn e i g h b o r s ) , and c o h e r e n c e t u r n ( a v e r a g e\nh e a d i n g t o w a r d s f l o c k m a t e s ) . The\np a r a m e t e r s f o r t h e s e p r i n c i p l e s a r e :\nmaximum−s e p a r a t e −t u r n , maximum−a l i g n −t u r n ,\nmaximum−cohere −t u r n , minimum−s e p a r a t i o n −\nd i s t a n c e . The s i m u l a t i o n p r o v i d e s t h e\nf o l l o w i n g i n f o r m a t i o n : C u r r e n t h e a d i n g ,\nN e i g h b o r s i n v i s i o n r a d i u s . When\nc a l c u l a t i n g t h e a l i g n m e n t t u r n , a l w a y s\nc ho o se t h e s h o r t e s t p a t h ( c l o c k w i s e or\nc o u n t e r c l o c k w i s e ) t o a l i g n w i t h t h e\na v e r a g e h e a d i n g o f n e i g h b o r s .\n2 . . .\n• Observed behavior\nBy explicitly instructing the model to select the\nshortest path to the target heading, ﬂocking behavior\nimproved signiﬁcantly. The LLM-driven agents\nformed larger, more stable ﬂocking clusters, achieving\nperformance comparable to the original, rule-based\nNetLogo model.\n• Analysis\nIncluding the shortest-path directive ensured that\nLLM-based agents correctly aligned their heading\nadjustments with both LLM-based and rule-based\nagents. This modiﬁcation resolved the previously\nobserved issues, leading to a more coherent and emergent\nﬂocking behavior.\n/four.tnum./one.tnum./three.tnum Prompt deployment\nThis task uses the same prompt deployment\nmechanism as Experiment 1. Communication with\nthe LLM is handled via the OpenAI API using the\nchat.completions mechanism, which supports context-\nfree messaging. A system prompt deﬁnes the task and\nrules, followed by a user prompt providing real-time\nenvironmental data.\nAt each simulation step, NetLogo translates the agent’s\nperception into the input variables in the prompt, including the\nheading and position of other agents within its vision radius, into\nthe input variables used in the prompt. This ensures the LLM\nhas an accurate, up-to-date view of the environment. The LLM\nthen generates a response formatted in JSON, specifying the agent’s\nactions. The following example prompt illustrates this process:\nFrontiers in Artiﬁcial Intelligence /one.tnum/two.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\n• System prompt\n1 You a r e an a g e n t i n a 2D s i m u l a t i o n . F o l l o w i n g\nt h e compass c o n v e n t i o n , your t a s k i s t o\nd e t e r m i n e your new h e a d i n g b a s e d on t h e\nf l o c k i n g p r i n c i p l e s o f s e p a r a t i o n t u r n ,\na l i g n m e n t t u r n ( a v e r a g e h e a d i n g o f\nn e i g h b o r s ) , and c o h e r e n c e t u r n ( a v e r a g e\nh e a d i n g t o w a r d s f l o c k m a t e s ) . The\np a r a m e t e r s f o r t h e s e p r i n c i p l e s a r e :\nmaximum−s e p a r a t e −t u r n , maximum−a l i g n −t u r n ,\nmaximum−cohere −t u r n , minimum−s e p a r a t i o n −\nd i s t a n c e . The s i m u l a t i o n p r o v i d e s t h e\nf o l l o w i n g i n f o r m a t i o n : C u r r e n t h e a d i n g ,\nN e i g h b o r s i n v i s i o n r a d i u s . When\nc a l c u l a t i n g t h e a l i g n m e n t t u r n , a l w a y s\nc ho o se t h e s h o r t e s t p a t h ( c l o c k w i s e or\nc o u n t e r c l o c k w i s e ) t o a l i g n w i t h t h e\na v e r a g e h e a d i n g o f n e i g h b o r s .\n2\n3 P r o v i d e your f i n a l new h e a d i n g a f t e r a p p l y i n g\nt h e s e r u l e s , e x p r e s s e d a s an a n g l e i n\nd e g r e e s . The r e s u l t s h o u l d be i n JSON\nf o r m a t o n l y , w i t h t h e k e y s and v a l u e s : ’\nr a t i o n a l e ’ ( v a l u e : your e x p l a n a t i o n ) and ’\nnew−heading ’ ( v a l u e : h e a d i n g i n d e g r e e s ) .\n• Possible user prompt\n1 These a r e t h e f l o c k i n g p a r a m e t e r s :\n2 −Maximum s e p a r a t e t u r n : 1 . 5 ,\n3 −Maximum a l i g n t u r n : 5 ,\n4 −Maximum c o h e r e t u r n : 3 ,\n5 −Minimum s e p a r a t i o n : 1 . 5 ;\n6\n7 T h i s i s your c u r r e n t environment :\n8 −C u r r e n t h e a d i n g : 1 3 8 deg ,\n9 −N e i g h b o r s i n v i s i o n r a d i u s : n e i g h b o r _ 1 : x :\n0 . 5 3 , y : −3 . 6 9 , h e a d i n g : 2 4 8 deg ;\n• Possible Response of the LLM\n1 {\n2 \" r a t i o n a l e \" : Given t h e c u r r e n t h e a d i n g o f 1 3\n8 d e g r e e s and one n e i g h b o r a t ( 0 . 5 3 , −3 .\n6 9 ) w i t h a h e a d i n g o f 2 4 8 d e g r e e s , we\nf i r s t c a l c u l a t e t h e s e p a r a t i o n t u r n . The\nd i s t a n c e t o t h e n e i g h b o r i s s q r t ( 0 . 5 3^2\n+ ( −3 . 6 9 ) ^2 ) = 3 . 7 3 , which i s g r e a t e r\nthan t h e minimum s e p a r a t i o n d i s t a n c e o f\n1 . 5 , so no s e p a r a t i o n t u r n i s needed .\nFor a l i g n m e n t , t h e a v e r a g e h e a d i n g o f\nt h e n e i g h b o r i s 2 4 8 d e g r e e s . The\ns h o r t e s t p a t h t o a l i g n w i t h 2 4 8 d e g r e e s\nfrom 1 3 8 d e g r e e s i s c l o c k w i s e , which i s\na t u r n o f 1 1 0 d e g r e e s . However , t h e\nmaximum a l i g n t u r n i s 5 d e g r e e s , so we\nt u r n 5 d e g r e e s c l o c k w i s e t o 1 4 3 d e g r e e s .\nFor c o h e r e n c e , s i n c e t h e r e i s o n l y one\nn e i g h b o r , t h e a v e r a g e h e a d i n g t o w a r d s\nt h e n e i g h b o r i s t h e same a s t h e neighbor\n’ s h e a d i n g , 2 4 8 d e g r e e s . The s h o r t e s t\n3 p a t h t o a l i g n w i t h 2 4 8 d e g r e e s from 1 4 3\nd e g r e e s i s c l o c k w i s e , which i s a t u r n\no f 1 0 5 d e g r e e s . However , t h e maximum\nc o h e r e t u r n i s 3 d e g r e e s , so we t u r n 3\nd e g r e e s c l o c k w i s e t o 1 4 6 d e g r e e s . The\nf i n a l new h e a d i n g i s 1 4 6 d e g r e e s . ,\n4 \" new−h e a d i n g \" : 1 4 6\n5 }\n/four.tnum./two.tnum Monitoring Behavior\nKey metrics include the degree of separation maintained\nbetween agents, the consistency of alignment with the average\nheading of nearby birds, and the eﬀectiveness of cohesion in\nmoving toward the ﬂock’s center of mass. The observed behaviors\nand performance analyses are documented in the results section.\n/five.tnum Results\n/five.tnum./one.tnum Experiment /one.tnum: ant foraging with\nstructured rule-based prompting\nThe following three variants of the ants foraging simulation\nwere applied:\n1. The original NetLogo model (henceforth simply called\n“NetLogo”).\n2. The model in which the rule-governed ants of the original model\nare replaced by LLM-governed ants (henceforth called “LLM”).\n3. A hybrid model in which half of the ants are rule-governed and\nthe other half are LLM-governed (henceforth called “Hybrid”).\nIn all simulations, we used a colony of 10 ants, three food\npatches to be exploited, and a stopping criterion of 1000 simulation\nsteps. Moreover, each experiment was repeated ﬁve times (with\ndiﬀerent seeds). The eﬃcacy of each model was assessed by\nquantifying the total amount of food gathered within these 1000\nsimulation steps.\n/five.tnum./one.tnum./one.tnum Food collection behavior\nFigure 3 shows the total amount of food collected over 1,000\nsimulation steps for the three diﬀerent model variants. NetLogo and\nLLM perform similarly in terms of the ants’ success in bringing food\nback to the nest, with both models accumulating approximately 85\nunits of food by the end of the simulation. However, the standard\ndeviation for NetLogo is around 20, whereas LLM displays a much\nlower standard deviation of about 7.\nIn contrast, the Hybrid model outperforms the other two\nvariants, collecting an average of approximately 95 units of\nfood with a standard deviation of about 12. This superior\nperformance is due to the combination of the behavioural\ndiﬀerences between LLM-guided ants and rule-based ants. The\nzoomed inset in\nFigure 3, for example, shows that Hybrid starts\nreturning food to the nest at around 20 simulation steps, whereas\nLLM and NetLogo begin this process at about 40 steps. This means\nthat, for some reason, the Hybrid variant is more eﬃcient in quickly\nﬁnding food sources.\nTo better understand the signiﬁcance of the observed\nperformance diﬀerences in the food collection, we analyzed the\nvariations in standard deviations between the models utilizing\nvarious tests. These tests are depicted in\nFigure 4 as groups\ncorresponding to the models. The Levene and Brown-Forsythe\ntests assess the homogeneity of variances between the groups,\nwith the Levene test utilizing the mean and the Brown-Forsythe\ntest employing the median. Cohen’s d quantiﬁes the eﬀect size,\nindicating the magnitude of the diﬀerence between two groups.\nFrontiers in Artiﬁcial Intelligence /one.tnum/three.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nFIGURE /three.tnum\nComparison of the total food collected across the three tested models : NetLogo (represented by the orange line), LLM (green line), and H ybrid (blue\nline). This visualization highlights the food collection performan ce diﬀerences among the diﬀerent models over ﬁve runs with diﬀer ent seeds. The\nlines represent the means, while the shaded areas indicate t he standard deviations.\nFIGURE /four.tnum\nComparison of performance metrics of the food collection among LLM, N etLogo, and Hybrid. The Levene, Brown-Forsythe, and Kruskal-Wal lis tests\nindicate signiﬁcant diﬀerences between Hybrid and the other m odels, while the LLM and NetLogo show no meaningful shifts in central tendency or\noverall distribution. For details, see the text.\nThe Kurskal-Wallis test (referred to as Kruskal in the plot)\nassesses whether there are statistically signiﬁcant diﬀerences in the\ndistributions, serving as a non-parametric test for medians.\nThe Levene and Brown-Forsythe tests for the LLM vs. NetLogo\ngroup yielded p-values around 0.0045, indicating a signiﬁcant\ndiﬀerence in variance and suggesting that the groups have an\nunequal spread. In contrast, the Cohen’s d value of 0.006 reﬂects\na small eﬀect size, suggesting nearly identical group means. The\nKruskal-Wallis test produces a high value of 0.99 (truncated in the\nﬁgure for improved visibility) indicating no statistical diﬀerence in\nthe distributions. In summary, there are no practical or statistical\ndiﬀerences observed between the LLM and NetLogo groups\nregarding the outcome. While the variances diﬀer slightly, there\nis no meaningful shift in central tendency or overall distribution.\nThe Levene, Brown-Forsythe, and Kruskal p-values for the LLM vs.\nHybrid group are all close to zero, indicating statistically signiﬁcant\ndiﬀerences. Additionally, Cohen’s d eﬀect size is approximately 0.2,\nsuggesting a small yet meaningful eﬀect. This analysis reveals a\nstatistically signiﬁcant and practically noticeable diﬀerence between\nthe LLM and Hybrid groups. While the eﬀect size is small, it is\nstill meaningful, indicating that Hybrid performs diﬀerently from\nLLM, albeit not drastically. The diﬀering variances further support\nthe notion that their behaviors are not merely a shift in location.\nThe NetLogo vs. Hybrid group shows a notable and statistically\nsupported diﬀerence between the two models. The variances diﬀer\nsigniﬁcantly, and although the eﬀect size is modest at 0.23, it\nremains consistent across analyses. This suggests that there is\na meaningful distinction in performance between NetLogo and\nHybrid.\nWe were also interested in evaluating the eﬀectiveness of the\nthree model variants regarding individual ants.\nFigure 5 depicts the\naverage number of simulation steps taken by an ant to return to\nits nest after picking up food, presented as boxplots. Generally,\nants in NetLogo (rule-governed ants) require fewer steps than\nthose controlled by the LLM. The LLM-guided ants demonstrate\nconsistent foraging behavior across the diﬀerent experiments,\nFrontiers in Artiﬁcial Intelligence /one.tnum/four.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nFIGURE /five.tnum\nThe average number of steps taken by an ant to return to its nest after picking up food (for food patches /one.tnum–/three.tnum). The green boxplots represent the\nsimulations of LLM, the orange boxplots those of NetLogo, while the bl ue boxplots show the results of Hybrid. Each boxplot spans from the ﬁrst to\nthe third quartile, with the vertical line within the box ind icating the median. The whiskers extend to represent the min imum and maximum number\nof steps taken, while the circles denote outliers.\nTABLE /two.tnum Statistics concerning the average amount of steps taken by an ant to return food to the nest.\nFood patch Model variant Mean Std Min /two.tnum/zero.tnum%/five.tnum/zero.tnum%/seven.tnum/five.tnum%Max\nLLM 23.04 3.34 16.0 21.0 23.0 25.0 48.0\n1 NetLogo 21.0 5.3 13.0 17.0 20.0 24.0 46.0\nHybrid 21.98 4.32 13.0 19.0 22.0 25.00 48.0\nLLM 32.3 3.41 25.0 31.0 32.0 34.0 49.0\n2 NetLogo 30.16 4.93 22.0 27.0 29.0 32.0 45.0\nHybrid 29.46 3.90 24.0 26.0 29.0 31.00 41.0\nLLM 39.29 2.36 36.0 37.5 40.0 41.0 42.0\n3 NetLogo 38.11 2.02 35.0 37.0 38.0 39.0 42.0\nHybrid 38.75 0.96 38.0 38.0 38.5 39.25 40.0\nparticularly for food patches 1 and 2. Notably, food patch 1 is\nthe closest to the nest, while food patch 3 is the farthest away.\nDetailed statistics, including the three quartiles, mean, standard\ndeviation, and minimum and maximum amounts of food collected,\nare provided in\nTable 2.\nFurthermore, we investigated the average number of steps taken\nby an ant from leaving the nest until ﬁnding a food source, which\nis represented in\nFigure 6. We speciﬁcally track and count ants\nthat are not carrying food and are exploring their environment\nuntil they start to carry the food. Hybrid demonstrates consistent\nperformance in ﬁnding food patches 1 and 2. In contrast, LLM and\nNetLogo display a more variable behavior during food searches.\nNotably, concerning food patch 1, the models exhibit a higher\nnumber of outliers, which can be attributed to the ants’ initial\nexploration of the environment before encountering the food. A\nnotable outlier is observed in the context of NetLogo and food\npatch 2, where an ant required 720 steps to ﬁnd food. Detailed\nstatistics are listed in\nTable 3.\n/five.tnum./two.tnum Experiment /two.tnum: bird ﬂocking simulation\nwith knowledge-driven prompts\nThe following two model variants were experimentally tested\nand evaluated:\n1. The original NetLogo model (henceforth simply called\n“NetLogo”, like in the ant foraging case).\n2. The model in which some of the rule-governed birds of the\noriginal model are replaced by LLM-governed birds (henceforth\ncalled “Hybrid”).\nIn all simulations, we used a ﬂock of 30 birds and a simulation\nlength of 800 steps. In the case of Hybrid, ﬁve of 30 rule-based birds\nare replaced by LLM-guided birds. Moreover, each experiment\nwas repeated ﬁve times (with diﬀerent seeds). The eﬀectiveness\nof the ﬂocking behavior is evaluated by measuring the distances\nand angular disparities between birds across the entire simulation.\nFigure 7 depicts the ﬂocking simulation executed in the NetLogo\nFrontiers in Artiﬁcial Intelligence /one.tnum/five.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nFIGURE /six.tnum\nAverage number of steps taken by an ant from leaving the nest to ﬁn ding a food source. Each boxplot spans from the ﬁrst to the third quar tile, with\nthe vertical line within the box indicating the median. The w hiskers extend to represent the minimum and maximum number o f steps taken, while the\ncircles denote outliers.\nTABLE /three.tnum Statistics for the average amount of steps taken by an ant to ﬁnd and collect food.\nFood patch Model variant Mean Std Min /two.tnum/zero.tnum%/five.tnum/zero.tnum%/seven.tnum/five.tnum%Max\nLLM 79.65 63.25 25.0 43.0 53.0 92.0 342.0\n1 NetLogo 71.48 72.77 12.0 22.0 39.0 99.0 464.0\nHybrid 71.42 68.88 12.0 31.0 47.0 86.0 466.0\nLLM 79.44 50.04 36.0 51.0 60.0 83.0 299.0\n2 NetLogo 93.74 102.09 21.0 33.0 56.0 116.50 720.0\nHybrid 73.81 74.81 22.00 32.75 42.00 78.50 326.0\nLLM 92.29 36.53 39.0 66.50 105.0 112.50 144.0\n3 NetLogo 123.33 142.92 37.0 41.0 47.0 86.0 432.0\nHybrid 61.25 6.18 53.0 58.25 63.0 66.0 66.0\nenvironment, featuring a heterogeneous population of 25 rule-\nbased and 5 LLM-guided birds.\n/five.tnum./two.tnum./one.tnum Flocking behavior\nFigure 8 compares the diﬀerences in the birds’ heading\ndirections between two model variants, as outlined above. However,\nnote that the heading diﬀerences between the rule-based birds and\nall other birds in model variant Hybrid (orange line) are separated\nfrom the heading diﬀerences between the LLM-guided birds and all\nother birds of Hybrid (green line).\nThe results shown in\nFigure 8 allow to make the following\nobservations. While the two bird types of Hybrid show a similar\nevolution of the heading diﬀerences, the rule-based birds of the\noriginal NetLogo model show somewhat lower heading diﬀerences.\nWe anticipate that with longer simulation runs, the heading\ndiﬀerences of the two model variants would converge to similar\nvalues. We also observed that the LLM-guided birds tend to\ncongregate at the outer peripheries of the ﬂocks, positioning\nthemselves further away from the ﬂocks’ center. An example of this\nbehavior is visualized in\nFigure 7 (see the ﬂock on the right) and\nalso illustrated in Figure 9 which indicates the average distances\nbetween birds. We hypothesize that this rather “conservative”\nbehavior of the LLM-guided birds contributes to greater heading\ndiﬀerences among the rule-based birds of Hybrid, as this behavior\nintroduces slight perturbations in the ﬂocking dynamics. Another\npossible interpretation involves the internal representation of\ndistance within the LLM. Although we deﬁne distance in Euclidean\nspace and provide these distances as ﬂoat values to the language\nmodel, it may interpret and represent distances in a diﬀerent\nmanner.\nFigure 10 illustrates the statistical analysis of the heading\ndiﬀerences between Hybrid (LLM and rule-driven birds) and\nNetLogo, which reveals disparities in the distributional properties\nof the experiments. Although the observed mean diﬀerence is\nrelatively small, as indicated by a Cohen’s d of 0.16–suggesting\nFrontiers in Artiﬁcial Intelligence /one.tnum/six.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nFIGURE /seven.tnum\nBird ﬂocking simulation in the NetLogo environment: yellow birds fol low rule-based behavior, while red birds are guided by the LLM.\nFIGURE /eight.tnum\nComparison of bird ﬂocking heading diﬀerences across two simulat ion approaches: original NetLogo (blue line) and Hybrid (orange and gr een lines).\nIn fact, the orange line shows the behavior of the /two.tnum/five.tnum rule-based birds of Hybrid, while the green line presents the behavior of the /five.tnumLLM-guided birds\nof Hybrid. The lines represent the means, while the shaded ar eas indicate the standard deviations.\na minor eﬀect size, the variance-based tests provide strong\nevidence of heterogeneity. Speciﬁcally, both Levene’s test and the\nBrown-Forsythe test return extremely low p-values, indicating\nthat the assumption of homogeneity of variances is violated.\nFurthermore, the Kruskal-Wallis test yields a p-value close to zero\nas well, signifying statistically signiﬁcant diﬀerences in the overall\ndistributions of the groups. In summary, these results suggest\nthat although central tendencies may be similar, the variance and\ndistributional shape diﬀer, indicating that the underlying behavior\nof the models diverges substantially.\nWe further investigated the behavior of rather staying at\nthe border of ﬂocks by examining collisions between birds,\nwhich are deﬁned as occasions in which the Euclidean distance\nbetween two birds is smaller than one. In fact, it turns out\nthat, throughout a simulation, the LLM-guided birds try to avoid\ncollisions; see\nFigure 11. In contrast, the rule-based birds from\nHybrid and those from NetLogo, exhibit a much higher number\nof collisions.\nFurthermore, triggered by our earlier observations, we\nexamined the average number of neighbors of a bird, as shown\nFrontiers in Artiﬁcial Intelligence /one.tnum/seven.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nFIGURE /nine.tnum\nComparison of average bird distances across the two tested model v ariants.\nFIGURE /one.tnum/zero.tnum\nBoxplot comparing diﬀerent test metrics of heading diﬀerence s between Hybrid and NetLogo. Despite a small eﬀect size, signiﬁc ant diﬀerences in\nvariance and distribution are evident. For details, see the te xt.\nTABLE /four.tnum Statistics for the average number of ﬂocking neighbors. The values are aggregated over all steps and experiments.\nModel\nvariant\nMean Median Std Min /two.tnum/zero.tnum%/five.tnum/zero.tnum%/seven.tnum/five.tnum%Max\nHybrid (LLM) 6.27 5.40 4.23 1.00 2.75 5.40 8.63 17.80\nHybrid\n(NetLogo)\n9.23 9.44 4.30 1.04 6.44 9.44 12.25 16.76\nNetLogo 11.42 11.24 6.27 1.04 6.02 11.24 16.87 22.56\nin Figure 12. Hereby, we deﬁne two birds as neighbors if they are\nat a distance greater than one (no collision) and within a distance\nd of at most ﬁve (that is, 1 < d ≤ 5). Moreover, we require a\nheading diﬀerence of h ≤ 15. As expected, rule-based birds exhibit\nthe highest number of neighbors, while the LLM-guided birds\ndisplay the lowest number, a result of their conservative behavior.\nStatistics on the average number of ﬂocking neighbors can be found\nin\nTable 4.\n/five.tnum./three.tnum Simulation length and experimental\nruns\nIn the bird ﬂock simulation, we empirically observed that\ncollective behaviors stabilized after approximately 500 steps, with\ncluster formations remaining relatively unchanged in subsequent\nsimulation steps. Therefore, extending the simulations beyond\nthe chosen limit of 800 steps would likely have provided\nFrontiers in Artiﬁcial Intelligence /one.tnum/eight.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nFIGURE /one.tnum/one.tnum\nCollisions between birds. A collision occurs when the distance d between birds is at most one (that is, d ≤ /one.tnum).\nFIGURE /one.tnum/two.tnum\nAverage number of neighbors: A neighbor is deﬁned as any entity wit hin a distance d such that /one.tnum≤ d ≤ /five.tnum, thereby excluding collisions. Furthermore,\nwe establish a heading diﬀerence criterion of h ≤ /one.tnum/five.tnum.\nminimal additional information on emergent dynamics or\nsystem stability.\nIn contrast, for the ant foraging scenario, we acknowledge\nthat a longer simulation would have been beneﬁcial to\ncomprehensively explore long-term emergent behaviors,\nparticularly since complete depletion of food resources\ntypically occurs around 2000 steps. Our choice to limit\nthe simulations to 1000 steps was primarily motivated\nby computational costs and practical time constraints.\nThus, we strongly recommend that future studies consider\nlonger simulation durations to more fully capture and\ncharacterize long-term emergent behaviors and overall\nsystem stability.\n/six.tnum Discussion\n/six.tnum./one.tnum Prompt strategies\nWe explored two complementary strategies for integrating\nLarge Language Models (LLMs) into multi-agent simulations: (i)\na structured, rule-based approach in an ant foraging context, and\n(ii) a principle-based, knowledge-driven approach in a bird ﬂocking\nscenario. In both cases, our experiments demonstrated how LLMs\ncan support swarm-like behaviors: guiding ants to locate and\nretrieve food by following pheromone trails, and prompting “birds”\nto coordinate alignment according to core ﬂocking principles.\nOverall, the LLM-driven agents performed comparably to their\nFrontiers in Artiﬁcial Intelligence /one.tnum/nine.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nfully rule-based counterparts, but they sometimes displayed notable\ndiﬀerences in how they interpreted and prioritized local cues when\nrelying on text-based decision-making.\nA key theme across both simulations was the importance\nof iterative prompt-tuning, which proved essential for producing\nconsistent and context-appropriate responses. In the ant foraging\nsimulations, early prompts did not specify what ants should do if\nno pheromone or nest scent was present, leading to confusion or\ninaction. Through multiple rounds of tuning, we added directives,\nsuch as “move away from the nest when no pheromone signals\nare detected” that encouraged exploration. Similarly, clarifying that\nnest scent should take precedence over pheromone while carrying\nfood helped ants more reliably locate and deposit resources.\nFollowing these reﬁnements, the foraging performance of the LLM-\ndriven ants nearly matched that of the standard NetLogo model.\nA new insight arose from the hybrid simulations, in which\na portion of the ant colony was rule-based while the rest\nwas LLM-driven. These mixed colonies often outperformed\nboth purely rule-based and purely LLM-based groups. One\npossible explanation is that deterministic if-then logic eﬃciently\nmanages well-understood aspects of foraging, while LLM-driven\nexploration provides adaptability in more uncertain situations.\nThus, combining traditional rules with text-based reasoning can\nyield more robust foraging strategies. However, this seemingly\nbetter performance of the hybrid populations warrants further\ninvestigation. We recommend running the simulations for longer\ndurations so that the colony has enough time to collect any\nremaining pieces of food, which may help clarify the mechanisms\ndriving this performance advantage.\nIn the bird ﬂocking simulations, using longer prompts that\nhighlighted alignment, separation, and cohesion improved stability.\nEarly prompts did not deﬁne heading conventions (e.g., 0 ◦ = north,\n90◦ = east), causing erratic turns and reversals. After establishing\nthe conventions and clarifying the short-turn logic (which favored\nminimal angular adjustments), the ﬂocks became more cohesive.\nHowever, LLM-driven birds generally stayed slightly farther from\nthe ﬂock center and experienced fewer collisions than their rule-\nbased counterparts, indicating that LLMs can interpret spatial cues\nin subtly diﬀerent ways while still maintaining coherent swarm\nbehavior.\nIn both scenarios, we observed that LLM decision-making\ncan function eﬀectively in a “stateless” manner, relying on\ncomplete contextual details at every step. This guarantees that\nthe model consistently acts on relevant information but also\nnecessitates highly detailed prompts. Failing to include key\ndetails—like pheromone intensity or heading conventions—\ncan result in ambiguous or incorrect actions. Expanding this\napproach to incorporate short-term memory or more sophisticated\nenvironmental representations could enable LLM-driven agents\nto maintain internal states that more closely resemble those in\ntraditional agent-based models.\nTogether, these results conﬁrm that LLMs can serve as ﬂexible\nengines for agent behaviors that align with swarm principles,\noﬀering adaptive, context-driven responses. They also highlight\nhow prompt design and iterative reﬁnement are central to achieving\nthe desired outcomes. Even small changes in the prompts, such as\nspecifying the angle to rotate or how to handle conﬂicting signals,\ncan signiﬁcantly inﬂuence emergent group-level patterns. This\nunderscores both the potential and the complexity of integrating\nLLMs into agent-based simulations, where subtle details of agent\nlogic can greatly aﬀect collective behavior.\n/six.tnum./two.tnum Challenges\nFinally, regarding potential drawbacks of our approach, two key\nissues must be noted, computation time and cost:\nFirst, the interaction between an agent (such as an ant or bird)\nand the remote LLM at each iteration of a simulation requires\nsigniﬁcantly more computation time compared to executing\nsimple rules within NetLogo. This increase primarily stems\nfrom API latency, the computational complexity of large-scale\nlanguage model inference, and the associated natural language\nprocessing operations. It is important to clarify, however, that\nwhen using an external API (such as the OpenAI API), much\nof this computational burden is oﬄoaded to the AI service\nprovider, thereby alleviating the direct computational cost from the\nsimulation user’s perspective.\nIn our speciﬁc experiments, we observed that each step\ninvolving an LLM-driven agent interaction typically required\nprocessing times on the order of seconds due to network latency\nand model response times, whereas conventional rule-based\nsimulations executed agent interactions within milliseconds\nor less per simulation step. Thus, although signiﬁcantly\nmore computationally intensive per agent-step, the method\nremains practically feasible for smaller-scale exploratory\nsimulations and conceptual validations, as demonstrated in\nthis paper.\nSecond, utilizing GPT-4o through the OpenAI API inherently\nintroduces token-based costs and dependencies associated with\nexternal model access, which may aﬀect simulation scalability,\ncost-eﬃciency, and reliability. To mitigate these potential issues,\nthe computational overhead could be signiﬁcantly reduced by\ndeploying smaller, locally hosted LLMs, particularly after targeted\nﬁne-tuning tailored to speciﬁc simulation tasks.\nAt the outset of this research (prior to June 2024), we\nexperimented with multiple LLMs. Among those evaluated, GPT-\n4o emerged as the most eﬃcient and successful in handling tasks,\nconsistently achieving the expected behavior. Other tested models\noften exhibited unreliable and erratic behavior, including ants\nrandomly dropping food and failing to demonstrate expected self-\norganizing capabilities.\nHowever, it is crucial to emphasize that our framework is\nnot inherently tied to GPT-4o or the OpenAI API. Rather,\nwe explicitly designed our methodological framework to ensure\nadaptability and generality, allowing straightforward integration\nwith alternative LLMs, including open-source and locally deployed\nsolutions. Although the experiments presented in this study utilized\na single external model, our methodological approach is fully\nextendable and compatible with a variety of language models.\nGiven the rapid progress in performance and resource eﬃciency of\nLLMs, we anticipate future developments will further enhance the\nfeasibility and eﬀectiveness of locally deployed language models for\nthe simulation of swarm behaviors.\nFrontiers in Artiﬁcial Intelligence /two.tnum/zero.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nTABLE /five.tnum Summary of strengths and weaknesses of the proposed\nLLM-driven multi-agent simulation approach across relevant e valuation\ncriteria.\nCriterion Strengths Weaknesses\nAdaptability High ﬂexibility; agents\nquickly adapt to novel\nscenarios without\nexplicit reprogramming.\nIncreased variability may\nlead to unpredictability\nin agent behaviors,\nrequiring careful\nmonitoring.\nCognitive\ncomplexity\nEnhanced reasoning\ncapabilities, enabling\nnuanced,\nprinciple-driven\ndecision-making in\nagents.\nReduced transparency\nand limited\nexplainability of agent\ndecision-making\nprocesses.\nPrompt design Allows intuitive,\nnatural-language\ninstructions, simplifying\nagent interaction and\ntask speciﬁcation.\nHigh sensitivity to\nprompt wording; subtle\nchanges can signiﬁcantly\naﬀect outcomes.\nGeneralization Strong potential for\ntransfer learning due to\nextensive knowledge\nbase, enabling\napplicability across\ndiverse scenarios.\nDependence on external\nAI services constrains\nscalability and incurs\nhigher latency and usage\ncosts.\nComputational cost Computational burden\nshifted to external\nservice provider; low\nlocal computational\ndemands.\nHigher total\ncomputational overhead,\nlatency, and API\ndependency compared to\nconventional rule-based\nmethods.\nScalability Conceptually scalable for\ncognitively complex\ntasks, exploiting\ngeneral-purpose\nknowledge.\nPractically limited\nscalability due to\nexternal API call\nconstraints, latency, and\nassociated costs.\n/seven.tnum Conclusion\nBy applying LLMs to two classic multiagent models, ant\nforaging and bird ﬂocking, this study shows that LLMs can serve\nas a viable alternative or complement to traditional rule-based logic\nin achieving eﬀective swarm-like dynamics.\nIn ant foraging simulations, LLM-guided ants gathered food\nat rates comparable to ants of the standard NetLogo model, as\nlong as their instructions were meticulously designed. Moreover,\nhybrid colonies that integrated LLM-driven and rule-based ants\nshowed a promising trend of improved performance compared to\nuniform groups, suggesting that the combination of deterministic\neﬃciency and text-based reasoning can be mutually beneﬁcial and\nwarrants further investigation. In bird ﬂocking, LLM-driven agents\nadhered to the separation, alignment, and cohesion principles to\nform cohesive ﬂocks. While heading convergence sometimes lagged\nbehind purely rule-based simulations, the resulting formations\nremained visually coherent. In particular, LLM-based birds\nadopted slightly more peripheral positions, indicating that nuanced\ndiﬀerences in textual instructions, such as how distance and turning\nare interpreted, can shape global ﬂock patterns.\nThese two experimental cases were used to explore our\nmain research objectives: to demonstrate how structured, rule-\nbased prompts and knowledge-driven prompts could be eﬀectively\nincorporated into simulations of collective emergent behavior.\nAlthough our results show promise even in these relatively simple\nswarm contexts, we believe that the true potential and comparative\nadvantage of integrating LLMs into agent-based systems would\nbe most pronounced in scenarios requiring agents with higher\nlevels of cognitive complexity or sophisticated principle-driven\ndecision making. In such contexts, whether modeling complex\nsocial systems, strategic economic behavior, or adaptive ecological\ninteractions, the ﬂexible knowledge representation, contextual\nunderstanding, and general reasoning capabilities of LLMs could\nsigniﬁcantly outweigh the additional computational costs. We\nsummarize the strengths and weaknesses of our approach\nin\nTable 5.\nThese advantages manifest particularly in enabling agents\nto autonomously adapt to novel, dynamic, and cognitively\ndemanding scenarios without requiring extensive reprogramming\nor domain-speciﬁc rule engineering, a persistent challenge with\ntraditional hard-coded systems. Furthermore, LLMs’ ability to\nintegrate multiple knowledge domains and leverage implicit world\nknowledge oﬀers the potential for more nuanced and contextually\nappropriate agent behaviors that would otherwise require more\ncomplex rule systems.\nAdditionally, in line with our research objectives, the toolchain\nwe present, integrating NetLogo simulations with LLM interactions\nvia Python extension and the OpenAI API, oﬀers a practical\ncontribution in terms of accessibility and pedagogical potential.\nNetLogo, widely recognized for its educational utility and intuitive\ninterface, provides a suitable platform for exploring complex\nmulti-agent systems. By incorporating LLMs into this familiar\nand user-friendly environment, our approach facilitates the study\nof cognitively richer and more adaptive agent behaviors, while\nalso lowering the barrier to entry for researchers, educators, and\nstudents interested in experimenting with advanced AI techniques\nin agent-based modeling. We believe that this integration can\nsupport broader engagement with simulation-based research and\nteaching, especially in interdisciplinary contexts where accessibility\nand interpretability are essential.\nIt is important to acknowledge certain practical considerations\nthat accompany our LLM-based approach to multi-agent systems.\nThe integration of LLMs into agent-based simulations introduces\nsigniﬁcant computational overhead compared to traditional rule-\nbased implementations, with each agent-LLM interaction requiring\nnetwork communication and remote inference that substantially\nincreases simulation time. Additionally, accessing commercial\nLLM APIs like GPT-4o incurs token-based costs that scale with\nsimulation complexity, agent population, and runtime duration.\nThese resource implications must be weighed against the beneﬁts\nof enhanced agent capabilities and behavioral sophistication.\nFuture implementations might mitigate computational costs\nthrough optimizations such as local model deployment, periodic\nrather than continuous LLM consultation, or the distillation of\nLLM-derived insights into more eﬃcient specialized models that\nmaintain key behavioral characteristics while reducing inference\nrequirements.\nTaken together, these considerations not only illustrate the\npotential of LLMs in agent-based systems, but also remind us\nof the importance of thoughtful design when bringing these\ntechnologies into simulation contexts. Our ﬁndings highlight the\nFrontiers in Artiﬁcial Intelligence /two.tnum/one.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\ncentral role of iterative prompt tuning in shaping how LLMs\nbehave within multi-agent environments. Careful attention to the\nlength, structure, and clarity of the prompts is essential to achieve\nconsistent, context-aware responses. At the same time, this need\nfor well-crafted prompts opens up exciting possibilities for future\nwork. More complex simulations could beneﬁt from increased\nLLM adaptability, especially if supported by mechanisms such as\npartial memory, contextual awareness, or reinforcement signals\nthat allow agents to go beyond stateless behavior and respond in\nmore nuanced, dynamic ways.\nUltimately, this work underscores the potential for advanced\nlanguage models, guided by carefully designed prompts, to\nenrich or even extend the capabilities of traditional agent-based\nmodels, oﬀering new perspectives on swarm intelligence, self-\norganization, and emergent behaviors. Beyond simulation, these\ninsights could also inform real-world applications, particularly in\nswarm robotics, where the ability to generate ﬂexible, context-\naware behavior on the ﬂy may open new possibilities for\nautonomous coordination, exploration, and collective problem\nsolving in dynamic environments.\nData availability statement\nThe datasets presented in this study can be found in\nonline repositories. The names of the repository/repositories and\naccession number(s) can be found below:\nhttps://github.com/\ncrjimene/swarm_gpt.\nAuthor contributions\nCJ-R: Methodology, Data curation, Writing – review & editing,\nInvestigation, Writing – original draft, Conceptualization, Funding\nacquisition, Formal analysis, Software, Resources. AY: Writing\n– original draft, Visualization, Methodology, Writing – review\n& editing, Software, Formal analysis, Investigation. CB: Funding\nacquisition, Validation, Supervision, Writing – review & editing,\nWriting – original draft, Investigation.\nFunding\nThe author(s) declare that ﬁnancial support was received\nfor the research and/or publication of this article. Christian\nBlum was supported by grant PID2022-136787NB-I00 funded by\nMCIN/AEI/10.13039/501100011033.This research was supported\nby the EUTOPIA Science and Innovation Fellowship Programme\nand funded by the European Union Horizon 2020 programme\nunder the Marie Sklodowska-Curie grant agreement No 945380.\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could be\nconstrued as a potential conﬂict of interest.\nGenerative AI statement\nThe author(s) declare that no Gen AI was used in the creation\nof this manuscript.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their aﬃliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nAuthor disclaimer\nThis article reﬂects only the author’s view and the EU Research\nExecutive Agency is not responsible for any use that may be made\nof the information it contains.\nReferences\nAmblard, F., Daudé, E., Gaudou, B., Grignard, A., Hutzler, G., La ng, C., et al. (2015).\n“Introduction to NetLogo, ” in Agent-Based Spatial Simulation with Netlogo(London:\nElsevier), 75–123. doi: 10.1016/B978-1-78548-055-3.5000 3-4\nBianchi, F., and Squazzoni, F. (2015). Agent-based models in\nsociology. Wiley Interdiscip. Rev. Comput. Stat . 7, 284–306. doi: 10.1002/\nwics.1356\nChang, Y., Wang, X., Wang, J., Wu, Y., Yang, L., Zhu, K., et al. ( 2024). A survey\non evaluation of large language models. ACM Trans. Intellig. Syst. Technol. 15:1289.\ndoi: 10.1145/3641289\nChen, L. (2012). Agent-based modeling in urban and architect ural research: a brief\nliterature review. Front. Architect. Res. 1, 166–177. doi: 10.1016/j.foar.2012.03.003\nDasgupta, I., Kaeser-Chen, C., Marino, K., Ahuja, A., Babaya n, S., Hill, F., et al.\n(2023). Collaborating with language models for embodied reason ing. arXiv [preprint]\narXiv:2302.00763.\nFang, Y., and Dickerson, S. J. (2017). “Achieving swarm inte lligence with spiking\nneural oscillators, ” in 2017 IEEE International Conference on Rebooting Computing\n(ICRC) (Washington, DC: IEEE), 1–4.\nFeng, S., Wang, Z., Wang, Y., Ebrahimi, S., Palangi, H., Miculi cich, L., et al. (2024).\nModel swarms: Collaborative search to adapt llm experts via swarm i ntelligence. arXiv\n[preprint] arXiv:2410.11163. doi: 10.48550/arXiv.2410.11 163\nGao, C., Lan, X., Li, N., Yuan, Y., Ding, J., Zhou, Z., et al. (20 24). Large language\nmodels empowered agent-based modeling and simulation: a survey and perspectives.\nHumanit. Soc. Sci. Commun. 11, 1–24. doi: 10.1057/s41599-024-03611-3\nGao, C., Lan, X., Lu, Z., Mao, J., Piao, J., Wang, H., et al. (202 3). s3: Social-network\nsimulation system with large language model-empowered agents. arXiv [preprint]\narXiv:2307.14984. doi: 10.2139/ssrn.4607026\nHeckbert, S., Baynes, T., and Reeson, A. (2010). Agent-base d modeling in ecological\neconomics. Ann. N. Y. Acad. Sci. 1185, 39–53. doi: 10.1111/j.1749-6632.2009.05286.x\nHecker, J. P., and Moses, M. E. (2015). Beyond pheromones: evo lving error-\ntolerant, ﬂexible, and scalable ant-inspired robot swarms. Swarm Intellig. 9, 43–70.\ndoi: 10.1007/s11721-015-0104-z\nJiao, A., Patel, T. P., Khurana, S., Korol, A.-M., Brunke, L., A dajania, V.\nK., et al. (2023). Swarm-GPT: combining large language models wit h safe\nmotion planning for robot choreography design. arXiv [preprint] arXiv:2312.01059.\ndoi: 10.48550/arXiv.2312.01059\nFrontiers in Artiﬁcial Intelligence /two.tnum/two.tnum frontiersin.org\nJimenez-Romero et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/three.tnum/zero.tnum/one.tnum/seven.tnum\nJimenez Romero, C., Yegenoglu, A., Pérez Martín, A., Diaz-Pi er, S., and\nMorrison, A. (2024). Emergent communication enhances fora ging behavior in\nevolved swarms controlled by spiking neural networks. Swarm Intellig. 18, 1–29.\ndoi: 10.1007/s11721-023-00231-6\nJunprung, E. (2023). Exploring the intersection of large languag e models and\nagent-based modeling via prompt engineering. arXiv [preprint] arXiv:2308.07411.\ndoi: 10.48550/arXiv.2308.07411\nKannan, S. S., Venkatesh, V. L., and Min, B.-C. (2024). “Smar t-LLM: Smart multi-\nagent robot task planning using large language models, ” in 2024 IEEE/RSJ International\nConference on Intelligent Robots and Systems (IROS)(Abu Dhabi: IEEE), 12140-12147.\nLi, X., Wang, S., Zeng, S., Wu, Y., and Yang, Y. (2024). A surve y on llm-\nbased multi-agent systems: workﬂow, infrastructure, and cha llenges. Vicinagearth 1:9.\ndoi: 10.1007/s44336-024-00009-2\nLiu, H., Li, Z., Huang, K., Wang, R., Cheng, G., and Li, T. (2024 a).\nEvolutionary reinforcement learning algorithm for large-scale multi-agent\ncooperation and confrontation applications. J. Supercomput . 80, 2319–2346.\ndoi: 10.1007/s11227-023-05551-2\nLiu, H.-S., Kuroki, S., Kozuno, T., Sun, W.-F., and Lee, C.-Y . (2024b). “Language-\nguided pattern formation for swarm robotics with multi-agent reinforcement learning, ”\nin 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n(Abu Dhabi: IEEE), 8998–9005.\nLiu, Y., Zhou, Z., Liu, J., Chen, L., and Wang, J. (2024c). Mult i-\nagent formation control using large language models. TechRxiv.\ndoi: 10.36227/techrxiv.172954477.70259514/v1\nMacal, C. M., and North, M. J. (2009). “Agent-based modeling an d simulation, ”\nin Proceedings of the 2009 Winter Simulation Conference (WSC)(Austin, TX: IEEE),\n86–98.\nNing, Z., and Xie, L. (2024). A survey on multi-agent reinforc ement learning and its\napplication. J. Automat. Intellig. 3, 73–91. doi: 10.1016/j.jai.2024.02.003\nPark, J. S., O’Brien, J. C., Cai, C., Morris, M. R., Liang, P., and Bernstein,\nM. (2023). “Generative agents: Interactive simulacra of huma n behavior, ” in\nProceedings of the 36th Annual ACM Symposium on User Interface Software and\nTechnology (New York, NY: Association for Computing Machinery).\nPutra, R. V. W., Marchisio, A., and Shaﬁque, M. (2024). SNN4Ag ents: a\nframework for developing energy-eﬃcient embodied spiking neu ral networks for\nautonomous agents. arXiv [preprint] arXiv:2404.09331. doi: 10.3389/frobt.2024.\n1401677\nQu, Y. (2024). Federated learning driven large language models\nfor swarm intelligence: a survey. arXiv [preprint] arXiv:2406.09831.\ndoi: 10.48550/arXiv.2406.09831\nReynolds, C. W. (1987). “Flocks, herds and schools: a distribut ed behavioral model, ”\nin Proceedings of the 14th Annual Conference on Computer Graphics and Interactive\nTechniques, 25–34.\nStrobel, V., Dorigo, M., and Fritz, M. (2024). LLM2Swarm: rob ot\nswarms that responsively reason, plan, and collaborate through\nLLMS. arXiv [preprint] arXiv:2410.11387. doi: 10.48550/arXiv.2410.\n11387\nTalebirad, Y., and Nadiri, A. (2023). Multi-agent collaboratio n: harnessing\nthe power of intelligent LLM agents. arXiv [preprint] arXiv:2306.03314.\ndoi: 10.48550/arXiv.2306.03314\nTisue, S., and Wilensky, U. (2004). “Netlogo: a simple environme nt for modeling\ncomplexity, ” inInternational Conference on Complex Systems(Boston, MA), 16–21.\nWooldridge, M. (2009). An Introduction to Multiagent Systems. Hoboken, NJ: John\nWiley & Sons.\nZhu, X., Chen, Y., Tian, H., Tao, C., Su, W., Yang, C., et al. (20 23). Ghost in the\nminecraft: Generally capable agents for open-world environments v ia large language\nmodels with text-based knowledge and memory. arXiv [preprint] arXiv:2305.17144.\ndoi: 10.48550/arXiv.2305.17144\nFrontiers in Artiﬁcial Intelligence /two.tnum/three.tnum frontiersin.org",
  "topic": "Swarm intelligence",
  "concepts": [
    {
      "name": "Swarm intelligence",
      "score": 0.5510056614875793
    },
    {
      "name": "Computer science",
      "score": 0.5430923700332642
    },
    {
      "name": "Swarm behaviour",
      "score": 0.5409482717514038
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3596886992454529
    },
    {
      "name": "Machine learning",
      "score": 0.15969595313072205
    },
    {
      "name": "Particle swarm optimization",
      "score": 0.12509781122207642
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210142324",
      "name": "CY Cergy Paris Université",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I1294671590",
      "name": "Centre National de la Recherche Scientifique",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I86175216",
      "name": "École Nationale Supérieure de l'Électronique et de ses Applications",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I4210131846",
      "name": "Artificial Intelligence Research Institute",
      "country": "ES"
    }
  ],
  "cited_by": 5
}