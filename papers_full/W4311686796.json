{
  "title": "Six-Center Assessment of CNN-Transformer with Belief Matching Loss for Patient-Independent Seizure Detection in EEG",
  "url": "https://openalex.org/W4311686796",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2804348443",
      "name": "Wei Yan Peh",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2760049312",
      "name": "Prasanth Thangavel",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2111069917",
      "name": "Yuanyuan Yao",
      "affiliations": [
        "KU Leuven"
      ]
    },
    {
      "id": "https://openalex.org/A2053258426",
      "name": "John Thomas",
      "affiliations": [
        "McGill University",
        "Montreal Neurological Institute and Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2500951292",
      "name": "Yee-Leng Tan",
      "affiliations": [
        "National Neuroscience Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2076007607",
      "name": "Justin Dauwels",
      "affiliations": [
        "Delft University of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2052394872",
    "https://openalex.org/W2080289801",
    "https://openalex.org/W2088786840",
    "https://openalex.org/W1545825327",
    "https://openalex.org/W2088222765",
    "https://openalex.org/W2742056141",
    "https://openalex.org/W3015375075",
    "https://openalex.org/W3137363251",
    "https://openalex.org/W1964875525",
    "https://openalex.org/W2969795856",
    "https://openalex.org/W3111670203",
    "https://openalex.org/W2043596210",
    "https://openalex.org/W2119234283",
    "https://openalex.org/W2113894235",
    "https://openalex.org/W3043250973",
    "https://openalex.org/W2795691199",
    "https://openalex.org/W3045153122",
    "https://openalex.org/W3003074332",
    "https://openalex.org/W3016911444",
    "https://openalex.org/W2914314600",
    "https://openalex.org/W3118794207",
    "https://openalex.org/W2087568562",
    "https://openalex.org/W2962782417",
    "https://openalex.org/W2894170005",
    "https://openalex.org/W2799604831",
    "https://openalex.org/W2759483166",
    "https://openalex.org/W3211727810",
    "https://openalex.org/W2295614256",
    "https://openalex.org/W2779032883",
    "https://openalex.org/W4205767588",
    "https://openalex.org/W3124539869",
    "https://openalex.org/W2963290013",
    "https://openalex.org/W2052466231",
    "https://openalex.org/W2918225995",
    "https://openalex.org/W2947657751",
    "https://openalex.org/W2137818765",
    "https://openalex.org/W3193174973",
    "https://openalex.org/W3120626054",
    "https://openalex.org/W3183266704",
    "https://openalex.org/W3140426200",
    "https://openalex.org/W3078711533",
    "https://openalex.org/W2082548472",
    "https://openalex.org/W2120853742",
    "https://openalex.org/W2990430870",
    "https://openalex.org/W2317674142",
    "https://openalex.org/W2089513838",
    "https://openalex.org/W2802911621",
    "https://openalex.org/W3126317075",
    "https://openalex.org/W2904559787",
    "https://openalex.org/W2913668833",
    "https://openalex.org/W4225472780",
    "https://openalex.org/W4207042075",
    "https://openalex.org/W4244405836"
  ],
  "abstract": "Neurologists typically identify epileptic seizures from electroencephalograms (EEGs) by visual inspection. This process is often time-consuming, especially for EEG recordings that last hours or days. To expedite the process, a reliable, automated, and patient-independent seizure detector is essential. However, developing a patient-independent seizure detector is challenging as seizures exhibit diverse characteristics across patients and recording devices. In this study, we propose a patient-independent seizure detector to automatically detect seizures in both scalp EEG and intracranial EEG (iEEG). First, we deploy a convolutional neural network with transformers and belief matching loss to detect seizures in single-channel EEG segments. Next, we extract regional features from the channel-level outputs to detect seizures in multi-channel EEG segments. At last, we apply post-processing filters to the segment-level outputs to determine seizures’ start and end points in multi-channel EEGs. Finally, we introduce the minimum overlap evaluation scoring as an evaluation metric that accounts for minimum overlap between the detection and seizure, improving upon existing assessment metrics. We trained the seizure detector on the Temple University Hospital Seizure (TUH-SZ) dataset and evaluated it on five independent EEG datasets. We evaluate the systems with the following metrics: sensitivity (SEN), precision (PRE), and average and median false positive rate per hour (aFPR/h and mFPR/h). Across four adult scalp EEG and iEEG datasets, we obtained SEN of 0.617–1.00, PRE of 0.534–1.00, aFPR/h of 0.425–2.002, and mFPR/h of 0–1.003. The proposed seizure detector can detect seizures in adult EEGs and takes less than 15[Formula: see text]s for a 30[Formula: see text]min EEG. Hence, this system could aid clinicians in reliably identifying seizures expeditiously, allocating more time for devising proper treatment.",
  "full_text": "  \nDelft University of Technology\nSix-Center Assessment of CNN-Transformer with Belief Matching Loss for Patient-\nIndependent Seizure Detection in EEG\nPeh, Wei Yan; Thangavel, Prasanth; Yao, Yuanyuan ; Thomas, John; Tan, Yee Leng; Dauwels, Justin\nDOI\n10.1142/S0129065723500120\nPublication date\n2023\nDocument Version\nFinal published version\nPublished in\nInternational Journal of Neural Systems\nCitation (APA)\nPeh, W. Y., Thangavel, P., Yao, Y., Thomas, J., Tan, Y. L., & Dauwels, J. (2023). Six-Center Assessment of\nCNN-Transformer with Belief Matching Loss for Patient-Independent Seizure Detection in EEG.\nInternational Journal of Neural Systems, 33(3), Article 2350012.\nhttps://doi.org/10.1142/S0129065723500120\nImportant note\nTo cite this publication, please use the final published version (if applicable).\nPlease check the document version above.\nCopyright\nOther than for strictly personal use, it is not permitted to download, forward or distribute the text or part of it, without the consent\nof the author(s) and/or copyright holder(s), unless the work is under an open content license such as Creative Commons.\nTakedown policy\nPlease contact us and provide details if you believe this document breaches copyrights.\nWe will remove access to the work immediately and investigate your claim.\nThis work is downloaded from Delft University of Technology.\nFor technical reasons the number of authors shown on this cover page is limited to a maximum of 10.\nGreen Open Access added to TU Delft Institutional Repository 'You share, we take care!' - Taverne project   \nhttps://www.openaccess.nl/en/you-share-we-take-care \nOtherwise as indicated in the copyright section: the publisher is the copyright holder of this work and the author uses the Dutch legislation to make this work public.   \nFebruary 25, 2023 11:1 2350012\nInternational Journal of Neural Systems, Vol. 33, No. 3 (2023) 2350012 (17 pages)\nc⃝ World Scientiﬁc Publishing Company\nDOI: 10.1142/S0129065723500120\nSix-Center Assessment of CNN-Transformer with Belief Matching\nLoss for Patient-Independent Seizure Detection in EEG*\nWei Yan Peh†, Prasanth Thangavel†, Yuanyuan Yao‡,J o h nT h o m a s§,\nYee-Leng Tan¶ a n dJ u s t i nD a u w e l s∥,∗∗\n†Interdisciplinary Graduate School(IGS)\nNanyang Technological University, Singapore 639798\n‡Katholieke Universiteit Leuven, Oude Markt 13, 3000 Leuven, Belgium\n§Montreal Neurological Institute, McGill University, Montreal QC H3A 2B4, Canada\n¶National Neuroscience Institute, Singapore 308433\n∥Department of Microelectronics, Delft, University of Technology\n2628 CD Delft, Netherlands\n∗∗j.h.g.dauwels@tudelft.nl\nAccepted 15 December 2022\nPublished Online 22 February 2023\nNeurologists typically identify epileptic seizures fromelectroencephalograms (EEGs) by visual inspection.\nThis process is often time-consuming, especially for EEG recordings that last hours or days. To expe-\ndite the process, a reliable, automated, and patient-independent seizure detector is essential. However,\ndeveloping a patient-independent seizure detector is challenging as seizures exhibit diverse characteristics\nacross patients and recording devices. In this study, we propose a patient-independent seizure detector to\nautomatically detect seizures in both scalp EEG and intracranial EEG (iEEG). First, we deploy a con-\nvolutional neural network with transformers and belief matching loss to detect seizures in single-channel\nEEG segments. Next, we extract regional features from the channel-level outputs to detect seizures in\nmulti-channel EEG segments. At last, we apply post-processing ﬁlters to the segment-level outputs to\ndetermine seizures’ start and end points in multi-channel EEGs. Finally, we introduce the minimum over-\nlap evaluation scoring as an evaluation metric that accounts for minimum overlap between the detection\nand seizure, improving upon existing assessment metrics. We trained the seizure detector on the Temple\nUniversity Hospital Seizure (TUH-SZ) dataset and evaluated it on ﬁve independent EEG datasets. We\nevaluate the systems with the following metrics: sensitivity (SEN), precision (PRE), and average and\nmedian false positive rate per hour (aFPR/h and mFPR/h). Across four adult scalp EEG and iEEG\ndatasets, we obtained SEN of 0.617–1.00, PRE of 0.534–1.00, aFPR/h of 0.425–2.002, and mFPR/h\nof 0–1.003. The proposed seizure detector can detect seizures in adult EEGs and takes less than 15 s\nfor a 30 min EEG. Hence, this system could aid clinicians in reliably identifying seizures expeditiously,\nallocating more time for devising proper treatment.\nKeywords: Transformer; belief matching; electroencephalogram; patient-independent seizure detection.\n∗An extended version of this paper can be found in https:/ /arXiv.org/abs/2208.00025.\n∗∗Corresponding author.\n2350012-1\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nW. Y. Peh et al.\n1. Introduction\nEpilepsy is a brain disorder characterized by the\nmanifestations of sudden unprovoked seizures. 1\nSeizures are diverse and vary signiﬁcantly across\npatients in etiology, severity, and symptoms.\n2 Most\nelectrographic seizures las tf rom30st o2m i n ,w h e re\na seizure lasting longer than 5 min is a medical emer-\ngency.3 Epilepsy is diagnosed when a patient expe-\nriences two or more recurring seizures.4 Around 1%\nof the world population is diagnosed with epilepsy.5\nMoreover, approximately 10% of the population will\nexperience a seizure within their lifetime.\n6 Over-\nall, provoked and unprovoked seizures occur in\nabout 3.5 and 4.2 per 10,000 individuals annually,\nrespectively.\n5 After a seizure episode, the likelihood\nof encountering another seizure event increases to\nabout 50%, bringing the individual to a much greater\nrisk of relapsing.\n7\nTo detect seizures, an e lectroencephalogram\n(EEG) can be utilized to measure the electri-\ncal activity in the brain.\n5 Scalp EEG records the\nbrain activity with surface electrodes, while intracra-\nnial EEG (iEEG) measures the signals directly via\nimplanted electrodes.\n8 However, visual inspection of\nEEGs can be time-consuming. 9 There is a need for\nautomated detectors that c an detect seizures reli-\nably and quickly. Most progress has been made\ntoward patient-speciﬁc detectors, as seizure mor-\nphologies vary across patients. Consequently, design-\ning a seizure detector thatcan detect seizures in any\npatient can be challenging but tremendously helpful\nfor clinicians.\nIn recent studies on automated seizure detection\nfrom EEG, the detectors are validated mainly on two\npublic seizure datasets: the Temple University Hospi-\ntal seizure (TUH-SZ) dataset\n10–12 and the Children’s\nHospital Boston Massachusetts Institute of Tech-\nnology (CHB-MIT) dataset.\n11,13–15 In many stud-\nies, diﬀerent models are proposed, including wavelet\nanalysis,16–18 machine learning models, 19 convolu-\ntional neural networks (CNNs),10,12,13,15,20 recurrent\nneural networks (RNNs), 10 long short-term mem-\nory (LSTM),21 transformer,22 transfer learning,23–26\nquickest detection,27 and temporal graph convolu-\ntional networks (TGCNs).28\nThe seizure detectors p roposed in these stud-\nies are similar in architecture and/or implemen-\ntation. The detectors ﬁrst divide the EEGs into\nshort multi-channel segments (segment-level), before\nclassifying each segment as normal against seizure.\nThen, using the segment-level outputs, they deter-\nmine the start and end points of the seizures in full\nEEGs. The main innovation in these studies lies in\nthe design of the segment-level detector, where most\nstudies propose increasingly deep and complex neu-\nral networks with millions of parameters.\n22,28\nUnfortunately, computationally intensive mod-\nels may not necessarily improve patient-independent\nseizure detection due to the increased risk of\noverﬁtting.\n28,29 Furthermore, detectors trained on\nlarger datasets had reported similar results to\nthose trained on smaller datasets.\n28,30 For instance,\nCovert et al.28 had used a vastly larger dataset\nthan Yuan et al.30 (18741 EEGs versus 686 EEGs,\nrespectively); yet, they obtained similar if not poorer\nresults than Yuan et al.(AUC of 0.935 versus 0.967,\nrespectively). While we acknowledge possible diﬀer-\nences between the quality and type of EEG used in\nboth studies, using more data does not seem to help\nimprove the seizure detection problem.\nTo resolve the bottleneck, we require a fresh per-\nspective on this problem. As we will explain in the\nfollowing, we address certain drawbacks of existing\nseizure detectors and resolve some of their weak-\nnesses in this study.\nFirst, most modern seizure detectors identify\nseizures at the segment-level directly. Since these\ndetectors are trained on multi-channel EEG seg-\nments, they can only handle a ﬁxed number of EEG\nelectrodes (e.g. 21). To apply those models to EEGs\nwith a diﬀerent number of electrodes (32), the mod-\nels need to be retrained. In practice, the number of\nelectrodes may vary, and this limitation is a severe\nimpediment to clinical applications.\nTo overcome this, we proposed a seizure detec-\ntor that starts by detect ing seizures in single-\nchannel segments (channel-level detection). We eval-\nuate three variations of CNN for the channel-level\ndetector: CNN with softmax loss (CNN-SM), CNN\nwith belief matching (BM) loss (CNN-BM), and\na CNN cascaded with a transformer and BM loss\n(CNN-TRF-BM). The BM loss is used to improve\ncalibration performan ce. It does so by trying to\nmodel the distribution and behavior of the proba-\nbility predicted to be similar to the distribution and\nbehavior of probability observed in training data.\n31\n2350012-2\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nSix-Center Assessment of Seizure Detection in EEG\nHence, calibration improves the probability estimate\nof a data point belonging to a class. Meanwhile, the\ntransformer is deployed to extract long-range pat-\nterns across the signals via self-attention, which the\nCNNs cannot. Several existing studies have proposed\nsystems to detect seizures at the channel-level.\n32–34\nHowever, some of these only analyzed single-channel\nEEGs instead of multi-channel EEGs.\n32 Conse-\nquently, they do not consider segment-level detec-\ntion, in contrast to the study at hand.\nTo resolve the restriction on the ﬁxed number of\nchannels, we aggregate the channel-level outputs and\ngroup them into ﬁve distinct brain regions. Then, we\ncompute statistical features from each region, which\ncan be done for an arbitrary number of electrodes.\nThis approach allows us to apply the detectors to\nEEGs with any number of electrodes and both scalp\nEEG and iEEGs. In this study, we trained the pro-\nposed seizure detector on a large scalp EEG dataset\n(TUH-SZ dataset) and evaluated it on ﬁve indepen-\ndent scalp EEG and iEEG datasets. In contrast,\nfew research studies investigate both scalp EEG and\niEEG together. Moreover, for seizure detectors eval-\nu a t e do nb o t hs c a l pE E Ga n di E E G ,t h o s ed e t e c t o r s\nare often trained and analyzed separately.\n22,35\nFinally, a good evaluation metric to measure the\neﬀectiveness of seizure de tectors is necessary. Such\nmetrics score a detection from the automated system\nbased on how much it overlaps with a manually anno-\ntated seizure(s). For channel- or segment-level EEG\nseizure detection, the problem is binary: ictal versus\nnonictal. Consequently, standard metrics for binary\nclassiﬁcation are applied in the literature for channel-\nor segment-level EEG seizure detection. However,\nEEG-level seizure detection,particularly event-based\nseizure detection, is more complicated. In this sce-\nnario, the problem is no longer a binary classiﬁca-\ntion problem. Instead, the problem is to determine\nwhether a detection had correctly detected a seizure\nbased on the overlap between the detection and the\nseizure(s). Unfortunately, most studies use diﬀerent\nevaluation approaches to assess the detectors, mak-\ning comparison studies challenging. Several evalua-\ntion metrics have been proposed, including epoch-\nbased sampling (EBS),\n36 any-overlap (OVLP), 36\ntime-aligned event scoring (TAES),36 and increased\nmargin scoring (IMS).37 However, these metrics do\nnot reﬂect real-world clinical requirements.\nFor instance, Reus et al.37 only reported IMS,\nwhich considers a detect ion correct as long as\nthe detection is within 30 s before the start or\nafter the end of the seizure, respectively. Simi-\nlarly, Koren et al.38 reported IMS, and increased\nthe time margin to 120s. Allowing this signiﬁcant\nerror margin could lead to huge uncertainty and\nlow precision (PRE) during detection. Meanwhile,\nF¨urbass et al.\n13 determine that a seizure is detected\nas long as a detection app ears within a seizure\nevent. These approaches ignored the amount of over-\nlap required, making their measurement approach\nextremely lenient. Either way, it is inappropriate in\nclinical practice.\nTherefore, we introduce the minimum over-\nlap evaluation scoring (MOES), which requires the\ndetection from the automated system to have a mini-\nmum overlap duration of 10s and a minimum overlap\nof 30% with a ground truth seizure for it to be consid-\nered correct. In contrast, OVLP and TAES require\na nonzero (e.g. 0.1%) and perfect (100%) overlap,\nrespectively, which tends to under- or over-penalize\nthe detector. By requiring a nontrivial overlap, albeit\nnot necessarily a perfect overlap, the MOES metric\nhas an adequate tolerance for clinical practice.\nIn summary, this paper performs the following:\n(1) We developed a patient-independent seizure\ndetector that can be a pplied to scalp EEG and\niEEG, regardless of the number of electrodes.\n(2) We utilize a BM loss to improve the calibra-\ntion performance, which i s critical for decision-\nmaking. However, such approaches are rarely\napplied in EEG analysis, as most studies favor\nsoftmax (SM) loss. Unfortunately, many existing\nclassiﬁcation algorithms are not optimized for\nobtaining accurate probabilities, and their pre-\ndictions may be miscalibrated.\n(3) We apply CNN with transformers as a trans-\nformer can extract long-range patterns, which a\nCNN cannot. Transformers had been explored\nfor seizure detection (see Ref. 22) but have yet\nto be applied at the channel-level.\n(4) We train the proposed detector on one scalp\nEEG dataset and test it on ﬁve independent\nscalp EEG and iEEG datasets. Seizure detectors\nare usually not assessed simultaneously on mul-\ntiple datasets and not on scalp EEGs and iEEGs.\n2350012-3\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nW. Y. Peh et al.\n(5) We introduce the MOES to assess the perfor-\nmance of seizure detectors. In contrast to exist-\ning metrics, the MOES metric requires a nontriv-\nial but not necessarily pe rfect overlap between\nthe detection and ground truth seizure(s) for the\ndetection to be considered correct. Existing met-\nrics are too lenient or strict on the overlap crite-\nria, resulting in inaccurate results.\n2. Materials and Methods\n2.1. Dataset\nWe analyze six public EEG datasets in this study:\n(1) Temple University Hospital Seizure (TUH-SZ)\ndataset\n39\n(2) Children’s Hospital Boston Massachusetts Insti-\ntute of Technology (CHB-MIT) dataset40\n(3) Helsinki University Hospital (HUH) dataset41\n(4) Sleep Wake Epilepsy Center at ETH Zurich\n(SWEC-ETHZ) dataset42\n(5) International Epilepsy Electrophysiology Portal\n(IEEGP) dataset43\n(6) Epilepsy iEEG Multicenter (EIM) dataset.44\nInformation about the six datasets is summarized\nin Table 1. The TUH-SZ dataset is the largest among\nthose six datasets, with the most annotated seizure\nevents. Hence, we utilized the TUH-SZ dataset as the\nprimary source to train th e entire seizure detector\npipeline.\nFirst, the seizure detector is trained and evalu-\nated with the TUH-SZ dataset via four-fold cross-\nvalidation (CV). We assign approximately the same\nnumber of patients and seizures to each fold. Next,\nusing the trained detector, we further assess it on\nﬁve other independent EEG datasets. In this way, we\nexamine the generalizability of the detector on dif-\nferent EEG datasets with diﬀerent EEG types and\npatient age groups.\nFor all the EEGs, a fourth-order Butterworth\nnotch ﬁlter at 60 Hz (USA) and 50 Hz (EU) is applied\nto remove electrical interference.\n45 Next, a 1 Hz high-\npass ﬁlter (fourth order) is implemented to reject\nDC shifts and baseline ﬂuctuations.\n46 Finally, all the\nEEGs are downsampled to a sampling frequency Fs\nof 128 Hz. At last, we convert all scalp EEGs to bipo-\nlar montage, as the TUH-SZ dataset is annotated in\nthe bipolar montage. As the montage for the iEEGs\nis incompatible with the bipolar montage, we keep\nthe montage of the iEEGs at monopolar.\n2.2. Seizure detector pipeline\nWe perform seizure detection ﬁrst at individual chan-\nnels (channel-level detection), followed by multi-\nchannel segments (segment-level detection). At last,\nwe detect the start and end points of the seizures\nin the entire multi-channel EEG (EEG-level detec-\ntion)\n45–47 (see Fig. 1). The proposed seizure detec-\ntor is displayed in Fig. 2. The pipeline consists of a\nchannel-level deep learning classiﬁer, a segment-level\nmachine learning classiﬁer, and multiple EEG-level\npost-processing modules. The seizure detectors are\nTable 1. Information on the six scalp EEG and iEEG datasets analyzed in the study.\nInformation Details TUH-SZ CHB-MIT HUH SWEC-ETHZ IEEGP EIM\nEEG\nDetails\nPatient Type Human Human Human Human Human/Dog Human\nPatient Age Group Adult Paediatric Neonatal Adult Adult Adult\nEEG Type scalp EEG scalp EEG scalp EEG iEEG iEEG iEEG\nF\ns (Hz) 250-1000 256 256 512 400-5000 250-1000\nChannel Name Available Available Available Unavailable Unavailable Unavailable\nChannel-level Annotation Yes No No No No No\nSeizure Label, Type Yes, 8 No No No No No\nNo of Channels 19,21 23,24,26 21 36–100 16–72 53–216\nNumber of\nPatients and EEGs\nPatients 637 24 75 16 12 31\nAll EEGs 5,610 683 75 100 12 102\nNon-Seizure EEGs 4,450 545 22 0 0 0\nSeizure EEGs 1,150 138 54 100 12 102\nSeizure Events 3,050 185 517 100 12 102\nDuration\nAll EEGs (in hours) 922 980 114 13.5 7.20 7.96\nNon-SZ EEGs (in hours) 681 792 35.0 0 0 0\nSZ EEGs (in hours) 242 188 78.6 13.5 7.20 7.96\nAverage (All) (in minutes) 9.84 86.1 89.64 8.1 36 4.68\nAverage SZ (in seconds) 54.3 54.4 90.5 95.9 37.3 103.7\n2350012-4\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nSix-Center Assessment of Seizure Detection in EEG\nChannel-level Segment-level\nEEG-level\nW\nFig. 1. The three EEG scales: channel-, segment-, and\nEEG-level detection.\nimplemented on NVIDIA GeForce GTX1080 GPUs\nin Keras 2.2.0 and TensorFlow 2.6.0.\n2.3. Channel-level seizure detector\nThe channel-level seizure detector computes the\nseizure probability for single-channel EEG segments.\nThe window length W adopted in the literature\nranges between 1 s to 30 s. However, W =1 si s\ntoo short to capture long-range seizure morphol-\nogy, while W = 30s is too long to capture short\nseizures. Therefore, we tested window lengths W ∈\n{3, 5, 10, 20}s. In this study, we deploy three channel-\nlevel seizure detectors based on CNNs:\n(1) CNN with softmax (SM) loss: CNN-SM.\n(2) CNN with belief matching (BM) loss: CNN-BM.\n(3) CNN-transformer with BM loss: CNN-TRF-BM.\n2.3.1. CNN-SM model\nThe CNN-SM model is a CNN with a SM loss func-\ntion. The input is the raw single-channel signal of\nlength W × F\ns. The architecture contains ﬁve con-\nvolutional layers with 8, 16, 32, 64, and 128 ﬁlters,\nrespectively, with two fully connected layers. To min-\nimize the loss, we applied the Adam optimizer with\nan initial learning rate equal to 10\n−4. The batch size\nduring training is set to 1000. Also, we implemented\nclass weights that are inversely proportional to the\nclass frequency in the training data during training.\nThis allows us to optimize the loss function on an\nimbalanced dataset without overﬁtting.\n47 Finally, we\noptimized parameters within the CNN via nested CV\n0.2\n0.2\n0.2\n0.2\n0.7\n0.7\n0.7\n0.2\n0.2\n0.2\n0.2\n0.7\n0.7\n0.2\n0.2\n0.2\n0.2\n0.2\n0.7\n0.2\n0.2\nMul/g415-channel \nSegment Single-channel \nSegment\nChannel-level \nScore\nSegment-level \nScore\nMul/g415-channel \nSegment Single-channel \nSegment\nChannel-level \nScore\nSegment-level \nScore\nMul/g415-channel \nSegment Single-channel \nSegment\nChannel-level \nScore\nSegment-level \nScore\n⋮ ⋮⋮ ⋮\n⋮ ⋮⋮ ⋮\n0.2\n0.2\n0.2\n0.7\n0.7\n0.7\n0.7\n0.7\n0.2\n0.2\n0.7\n0.7\n0.7\n0.7\n0.2\n0.2\n0.2\n0.7\n0.7\n0.7\n0.2\n0\n0\n0\n1\n1\n1\n1\n1\n0\n0\n1\n1\n1\n1\n0\n0\n0\n1\n1\n1\n0\n0\n0\n0\n1\n1\n1\n1\n1\n0\n0\n1\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\nThresholdSmoothening Consecu/g415ve \ndetec/g415onCombina/g415on\nSeizure \nDetec/g415on\nWindows\nChannel-level \nPredic/g415on\nSegment-level \nPredic/g415on\nChannel- and Segment-level Predic/g415on EEG-level Postprocessing\nFull \nMul/g415-channel \nEEG\nFig. 2. The proposed seizure detector pipeline consists of multiple stages of seizure detection at three EEG scales. The\nEEG is divided into overlapping epochs where we performed channel- and segment-level detection to get a series of\nsegment-level outputs. Next, we applied four post-processing steps for EEG-level detection. First, we apply smoothening\nwindow (e.g. max smoothen window of length 3) to the segment-level output. Second, we implement thresholds (e.g. 0.5)\nto obtain a series of 0 s and 1 s. Third, we locate chains of consecutive 1 s and replace them with 0 s if the chain is less\nthan N\nc (e.g. Nc = 4) in length. Finally, suppose any two chains of consecutive 1 s are within proximity (e.g. 3 epochs).\nIn that case, we combine them into a single detection to prevent many fractured detection windows.\n2350012-5\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nW. Y. Peh et al.\non the training data, with an 80:20% split for train-\ning and validation.\n2.3.2. CNN-BM model\nT h eC N N - B Mm o d e lh a st h es a m ea r c h i t e c t u r e\nas the CNN-SM model, except that the BM loss\nreplaces the SM loss. The BM loss is shown to yield\nbetter uncertainty estimates and generalization per-\nformance than the SM loss, an important property\nrequired for seizure detection.\n48 The BM framework\nis formulated from a Bayesian perspective that views\nbinary classiﬁcation as distribution matching. The\nBM loss is deﬁned as\nL(W) ≈− 1\nm\nm∑\ni=1\nℓEB(y(i),αW(x(i))), (1)\nwhere x(i) and y(i) is the ith training data and its\nlabel, respectively, m is the total number of sam-\nples, and αW =e x p (W), where W are the weights\nof the neural network classiﬁer. ℓEB(y,α W(x))\nis the evidence lower bound (ELBO) 48 and is\ndeﬁned as ℓEB(y,α W(x)) = EqW\nz | x\n[logp(y|x, z)] −\nKL(qW\nz|x ∥pz|x), where z is the categorical probability\nabout the label, pz|x is the target distribution, qW\nz|x\nis the approximate distribution, and KL is the KL-\ndivergence. We refer to Ref. 48 for more information\non the BM loss.\n2.3.3. CNN-TRF-BM model\nThe CNN-TRF-BM model contains the CNN and\nthe transformer. The architecture is the same as\nin the CNN-BM model, but we insert an addi-\ntional transformer encoder between the ﬁnal convo-\nlutional layer and the ﬂattening layer (see Ref. 49).\nWe implemented a transformer in tandem with the\nCNN, as the CNN alone cannot model correlations\nbetween distant data points, such as seizure mor-\nphologies. The transformer can compensate for this\nlimitation by extracting long-range information from\nthe CNN features. The transformer encoder contains\neight heads, and the number of hidden layer neu-\nrons in the forward feed network (FFN) is 1024. As\ninput to the transformer, we extract 1 s segments\nwith 25% overlap from the W-second single-channel\nsegment.\n2.4. Segment-level seizure detector\nNext, we rely on the outputs of the channel-level\ndetectors to detect seizur es in multi-channel seg-\nments. The channel-level detectors yield seizure\nprobabilities for each EEG channel, which we arrange\ninto regions according to the scalp topology: frontal,\ncentral, occipital, and parietal. Besides those four\nlocal regions, we also deﬁne a “global” region con-\ntaining all channels. From each region, we extract\nseven statistical features: mean, median, standard\ndeviation, maximum value, minimum value, and\nvalue at 25% and 75% percentile. As there are ﬁve\nregions, we extract 5 × 7 = 35 features. From all\nchannel-level outputs, we compute the normalized\nhistogram features (5 bins, range [0, 1]) and include\nthem into the feature set, bringing the total features\nto 40.\nIn the iEEGs, the channel locations are unavail-\nable; hence we cannot group the iEEG channels\ninto local regions. Instead, we replace the four local\nregions with the global region. In this scenario, only\n12 features are unique, and the remaining ones are\nduplicates. In any case, the number of segment-\nlevel features is 40, regardless of the number of\nchannels or the availability of the channel locations.\nThis approach ensures that the number of features\nis consistent during the training and evaluation of\nany dataset. The features will be the inputs to an\nXGBoost model for training and validation, and we\ndetermined the hyperparameters via grid search CV.\nWe selected the XGBoost model, as it is a state-\nof-the-art machine learning model that outperforms\nmost classical models such as the support vector\nmachine (SVM) and random forest.\n50\n2.5. Channel- and segment-level\nevaluation metric\nWe assess the channel- and segment-level seizure\nclassiﬁers through the following metrics: accuracy\n(ACC), balanced accuracy (BAC), sensitivity (SEN),\nspeciﬁcity (SPE), F1 score (F1), and expected cal-\nibration error (ECE).\n31 As the seizure and non-\nseizure classes are imbalanced, we evaluate the\nresults mainly in BAC.\n47\n2.6. EEG-level seizure detector\nFinally, we perform seizure detection on full EEGs by\ndetermining the start and end time of the seizures,\n2350012-6\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nSix-Center Assessment of Seizure Detection in EEG\nif any. First, we apply a sliding window of length\nW with a shift duration To to the multi-channel\nEEG, extracting n multi-channel segments. Here, n\ndepends on the duration of the EEG recording. If the\nEEG recording lasts only 20s, n = 1. However, if the\nEEG recording is 3600s, n = 3600−20\n1 +1 = 3581.\nThe overlap duration To is set to 1 s. Next, we\nperform segment-level detection on each segment,\nresulting in n seizure probabilities P =[ p\n1,...,p n].\nFinally, we conduct three post-processing steps to\nthe seizure probability sequence P:\n(1) We apply 1D smoothing ﬁlters with an overlap\nof 1 sample. We tested various ﬁlter lengths K\nf\n( 3 ,5 ,o r7 s )a n dﬁ l t e rt y p e s( m e a n ,m e d i a n ,\nor max). The smoothing ﬁlter removes isolated\nseizure detections (usually false positives (FPs)\nsuch as artifacts) and smoothens regions with\nsigniﬁcant conﬁdence variations to stabilize the\ndetections.\n(2) Next, we perform thresholding to the seizure\nprobabilities to round them to zeros (seizure-\nfree) or ones (seizure). We tested threshold val-\nues θ ∈{ 0.1, 0.2,..., 0.8, 0.9}.\n(3) Then, we identify co nsecutive ones of length\nsmaller than N\nc, and replace the 1 s with 0 s.\nSelecting a large Nc removes many short detec-\ntions, leading to fewer FPs and more FNs, as\nthe system may miss short seizures. We tested\nN\nc ∈{ 1, 2,..., 19, 20}.\nFinally, we identify the remaining sequences of\nconsecutive 1 s, and determine their start and end\ntime. The ﬁnal output of the EEG-level seizure detec-\ntor is the start and end timesof the detected seizures.\n2.7. EEG-level seizure detection\nevaluation metric\nWe assess the ACC of the detections via EEG-level\nseizure detection evaluation metric. There are several\nwell-established evaluation metrics, such as EBS, 36\nany-overlap (OVLP),36 TAES,36 and IMS.37 How-\never, these metrics do not accurately reﬂect the clin-\nical requirement of a se izure detector. Hence, we\ndeﬁne a new metric, the MOES. In this metric, there\nneeds to be a nontrivial overlap between the detec-\ntion and the seizure, while it does not need to be\nperfect.\n2.8. Minimum overlap evaluation\nscoring (MOES )\nThe MOES determines the overlap duration T\noverlap\nbetween the detection (Tdetection =[ dstart,dend]) and\nseizure ( Tseizure =[ sstart,s end]) window, and vice\nversa, before deciding if the detection is correct or\nthe seizure is captured. B ased on existing litera-\nture, only seizures of at least 10 s are annotated\ntypically.\n51 Therefore, the min imum overlap dura-\ntion of the detection (s) wi th the seizure should be\n10s. However, these criteria do not account for the\nduration of the seizure or the detection. Therefore,\neven if the detection corr ectly detected over 10 s\nof a seizure, the system should be penalized if the\nmajority of the detection didnot capture any seizure.\nTo resolve this, we compute the detection overlap\n(DOL) and the seizure overlap (SOL), which mea-\nsures the fraction of the detection that overlaps with\nany seizures, and vice versa, as\nDOL\ni =\n∑\ns Toverlap,s,i\ndend,i − dstart,i\n, (2)\nSOLj =\n∑\nd Toverlap,d,j\nsend,j − sstart,j\n, (3)\nwhere i and j are the index of a detection and a\nseizure, respectively, ∑Toverlap,s,i is the sum of all\nthe overlaps with any seizures with detection i,a n d∑Toverlap,d,j is the sum of all the overlaps with any\nseizures with seizure j.\nIn this study, we set a minimum DOL and SOL\nof 0.3 (30%) to ensure that a signiﬁcant portion of\nthe DOLs with the seizures and vice versa. In OVLP\nmetric, the DOL is set to be 0+%, while in TAES it\nis 100%. The ﬁrst option is too lenient in practice,\nwhile the latter is too strict.\nA high DOL implies that the DOLs well with\nthe seizure(s). Meanwhile, a high SOL indicates that\nthe seizure is well captur ed by the detection(s). If\nthe DOL is low, the detection should be discarded\nand treated as a FP. Similarly, if the SOL is low,\nthe seizure should be treated as a false negative\n(FN). More details on how MOES approaches dif-\nferent detection cases are elaborated in the extended\nversion of the paper.\nFinally, the detection may start earlier or later\nthan the annotated seizure. We compute the detec-\ntion oﬀset as\nT\noﬀset = dstart − sstart + W, (4)\n2350012-7\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nW. Y. Peh et al.\nwhere W is the duration of the window length,dstart\nis the start time of the detection, sstart is the start\ntime of the annotated seizure. We addedW in the oﬀ-\nset as we require a minimum window of lengthW to\ndetect seizures. To more accurately detect the onset\nof a seizure, one may slide the window in smaller\nsteps around the onset of a detection. However, this\ngoes beyond the scope of this work, as we are mainly\ninterested in detecting seizures, irrespective of their\nonset times.\n2.9. EEG-level seizure detection\nperformance metrics\nWe measure the performance of EEG-level seizure\ndetection with SEN, PRE, false positive per hour\n(FPR/h), and the oﬀset. All these metrics are essen-\ntial to provide a fair assessment of the proposed\npipeline as an assistive tool for clinical applica-\ntions. We compute the SEN, PRE, and FPR/h per\nEEG, before computing their mean values across\neach dataset. Meanwhile, for FPR/h, we compute the\naverage FPR/h (aFPR/h) and the median FPR/h\n(mFPR/h).\n3. Results\n3.1. Channel-level seizure detection\nWe performed channel-level seizure detection with\nthree channel-level detectors: CNN-SM, CNN-BM,\nand CNN-TRF-BM. We summarized the results in\nTable 2. In addition, all th e precision-recall (PR)\ncurves can be found in Fig. 3.\nOn the TUH-SZ dataset, the proposed channel-\nlevel detectors achieve high BAC, SEN, and SPE\nacross all window lengths. Moreover, the ECE\nimproved for all window lengths (except for 3 s) when\nthe SM loss is replaced with the BM loss (CNN-\nSM against CNN-BM). However, the ECE is slightly\nlarger for the CNN-TRF-BM model. The perfor-\nmance peaks at W =2 0 sf o ra l lt h r e em o d e l s .\nOverall, the CNN-TRF-BM model attained the best\nresults, followed by the CNN-BM and the CNN-SM\nmodel. As the channel-level detector attains good\nresults on the TUH-SZ dataset, using it as the pri-\nmary training dataset seems promising.\nNext, we assessed the channel-level detector,\ntrained on the TUH-SZ dataset, on the ﬁve EEG\ndatasets. The detectors achieve high BACs on the\nCHB-MIT, SWEC-ETHZ, and EIM datasets, but\nyield poor BACs on the HUH and IEEGP datasets.\nFor those datasets, seizures have only been anno-\ntated on the level of segments instead of channels;\ntherefore, it is impossibleto assess the channel detec-\ntor reliably. Without channel-level annotations, we\nmust assume that all channels within a multi-channel\nsegment contain seizures. However, this is unlikely\nas seizures sometimes only occur in certain regions.\nIn particular, focal seizures occur only in one hemi-\nsphere or at a few electrodes. Consequently, channels\nthat do not exhibit seizures may be mislabeled as\n“seizures”, leading to errors during training and test-\ning. However, segment-level and EEG-level detection\nresults are reliable for those datasets.\n3.2. Segment-level seizure detection\nNext, we performed segment- level seizure detection\nusing the outputs from the three channel-level detec-\ntors. The segment-level detection results on the six\nEEG datasets are displayed in Table 3.\nOn the TUH-SZ dataset, the proposed segment-\nlevel detectors achieve high BAC, SEN, and SPE\nacross all window lengths, similarly to the channel-\nlevel results. However, the ECE reported at the\nsegment-level is much greater than the channel-level\ncounterparts, as the segment-level detector model\ndoes not minimize ECE. Similarly, the performance\npeaks at W = 20 s. Again, the CNN-TRF-BM model\noutshines the other two models.\nNext, we evaluated the segment-level seizure\ndetector on the other ﬁve datasets. We obtained\nexcellent performance on all the datasets at vari-\nous window lengths, except for the HUH dataset.\nThe segment-level detectors obtain high BACs on the\nIEEGP dataset, even when the channel-level results\non this dataset are not satisfactory.\nOverall, the performance peaks at diﬀerent win-\ndow lengths across the six datasets. This might be\ndue to the discrepancy in seizure types, patient types,\nand patient age groups across the diﬀerent datasets.\nFor instance, for datasets with many short seizures,\none should deploy a window length of 3 s as it can\ncapture shorter seizures, while a window length of\n20s would be suboptimal.\n3.3. EEG-level seizure detection\nNext, we performed EEG-l evel seizure detection\nbased on the outputs of the segment-level detector.\n2350012-8\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nSix-Center Assessment of Seizure Detection in EEG\nTable 2. Channel-level seizure detection results for diﬀerent CNN models across six EEG datasets.\nDataset\n W\n CNN-SM\n CNN-BM\n CNN-TRF-BM\nECE ACC BAC SEN SPE F1\n ECE ACC BAC SEN SPE F1\n ECE ACC BAC SEN SPE F1\nTUH-SZ\nScalp EEG\nAdult\n3\n 0.043 0.824 0.832 0.808 0.855 0.827\n 0.046 0.837 0.842 0.827 0.856 0.839\n 0.052 0.824 0.832 0.773 0.89 0.826\n5\n 0.043 0.84 0.836 0.769 0.902 0.84\n 0.035 0.845 0.842 0.862 0.821 0.848\n 0.03 0.85 0.83 0.767 0.892 0.849\n10\n 0.044 0.815 0.826 0.809 0.844 0.821\n 0.021 0.848 0.844 0.78 0.908 0.848\n 0.056 0.772 0.76 0.868 0.653 0.758\n20\n 0.044 0.836 0.845 0.812 0.877 0.837\n 0.027 0.845 0.851 0.834 0.868 0.846\n 0.033 0.852 0.858 0.828 0.889 0.853\nHUH\nScalp EEG\nNeonatal\n3\n 0.259 0.506 0.491 0.187 0.794 0.454\n 0.399 0.403 0.403 0.249 0.903 0.496\n 0.408 0.4 0.4 0.245 0.902 0.492\n5\n 0.28 0.532 0.511 0.12 0.902 0.445\n 0.481 0.354 0.354 0.168 0.957 0.423\n 0.377 0.427 0.427 0.289 0.879 0.526\n10\n 0.228 0.527 0.507 0.217 0.796 0.482\n 0.403 0.417 0.417 0.264 0.912 0.511\n 0.508 0.358 0.358 0.168 0.974 0.423\n20\n 0.271 0.574 0.534 0.131 0.937 0.485\n 0.457 0.385 0.385 0.211 0.952 0.464\n 0.527 0.343 0.343 0.145 0.986 0.403\nCHB-MIT\nScalp EEG\nPaediatric\n3\n 0.259 0.617 0.756 0.569 0.942 0.649\n 0.269 0.568 0.74 0.51 0.97 0.601\n 0.25 0.582 0.747 0.528 0.966 0.617\n5\n 0.181 0.669 0.763 0.56 0.966 0.668\n 0.205 0.62 0.739 0.494 0.984 0.616\n 0.095 0.742 0.808 0.666 0.95 0.755\n10\n 0.126 0.786 0.816 0.743 0.889 0.79\n 0.137 0.724 0.782 0.635 0.928 0.733\n 0.205 0.663 0.748 0.515 0.981 0.649\n20\n 0.129 0.777 0.78 0.592 0.969 0.758\n 0.141 0.777 0.782 0.606 0.959 0.765\n 0.153 0.755 0.756 0.534 0.978 0.733\nSWEC-ETHZ\niEEG\nAdult\n3\n 0.069 0.803 0.721 0.56 0.882 0.804\n 0.127 0.814 0.725 0.557 0.892 0.813\n 0.107 0.814 0.726 0.56 0.891 0.814\n5\n 0.066 0.828 0.718 0.502 0.935 0.819\n 0.108 0.834 0.723 0.514 0.933 0.826\n 0.097 0.798 0.73 0.614 0.847 0.805\n10\n 0.084 0.772 0.726 0.648 0.805 0.785\n 0.112 0.805 0.74 0.628 0.853 0.812\n 0.094 0.844 0.737 0.535 0.939 0.837\n20\n 0.074 0.837 0.781 0.615 0.914 0.836\n 0.099 0.827 0.777 0.635 0.89 0.83\n 0.12 0.863 0.79 0.594 0.953 0.857\nIEEGP\niEEG\nAdult\n3\n 0.358 0.536 0.536 0.453 0.952 0.613\n 0.346 0.533 0.533 0.444 0.975 0.608\n 0.351 0.532 0.532 0.445 0.968 0.606\n5\n 0.417 0.512 0.512 0.416 0.991 0.578\n 0.398 0.502 0.502 0.404 0.993 0.567\n 0.317 0.553 0.553 0.473 0.95 0.626\n10\n 0.317 0.574 0.574 0.508 0.9 0.651\n 0.352 0.562 0.562 0.479 0.976 0.631\n 0.386 0.523 0.523 0.428 0.998 0.59\n20\n 0.465 0.531 0.531 0.438 0.995 0.592\n 0.406 0.546 0.546 0.458 0.985 0.614\n 0.433 0.505 0.505 0.407 0.999 0.561\nEIM\niEEG\nAdult\n3\n 0.201 0.653 0.662 0.583 0.741 0.643\n 0.128 0.658 0.669 0.579 0.759 0.649\n 0.144 0.659 0.666 0.588 0.745 0.651\n5\n 0.205 0.65 0.684 0.52 0.848 0.633\n 0.135 0.652 0.687 0.518 0.855 0.638\n 0.154 0.66 0.653 0.626 0.679 0.653\n10\n 0.207 0.659 0.641 0.658 0.624 0.65\n 0.154 0.666 0.663 0.622 0.704 0.66\n 0.155 0.665 0.701 0.536 0.866 0.653\n20\n 0.221 0.671 0.703 0.57 0.835 0.662\n 0.15 0.674 0.695 0.594 0.796 0.669\n 0.139 0.667 0.716 0.541 0.89 0.658\nFig. 3. The precision-recall (PR) curves of the channel-, segment-, and EEG-level seizure detection computed with the\nCNN-TRF-BM-based seizure detector across diﬀerent datasets. The EEG-level PR curves are generated by varying the\nthreshold θ in the EEG-level postprocessing step and computing the PRE and recall (REC) at each threshold with MOES.\nWe summarized the results for the six datasets in\nTable 4. The EEG-level performance is computed\naccording to MOES, as it is more suitable for clinical\npractice than existing metrics.\nOn the TUH-SZ dataset, the CNN-TRF-BM\nmodel leads to the most promising results, followed\nby the CNN-BM and the CNN-SM model. The\nCNN-TRF-BM EEG-level seizure detector attained\na respectable SEN, PRE, aFPR/h, mFPR/h, and\nmedian oﬀset of 0.772, 0.429, 0.425, 0, and−2.125 s,\nrespectively. While the aFPR/h is high, the mFPR/h\nis extremely low. This implies that the aFPR/h\nis skewed by a small number of EEGs containing\nan exceptionally huge amount of false detection.\nWhile the SEN is similar across all three models, the\nCNN-TRF-BM model reported the best PRE, which\nis critical for clinical deployment.\nSimilarly, we evaluated the EEG-level seizure\ndetectors on the ﬁve scalp EEG and iEEG datasets.\nThe CNN models yield high SEN, decent PRE,\nand low aFPR/h and mFPR/h on the CHB-MIT,\nSWEC-ETHZ, and EIM datasets. Meanwhile, on\nthe HUH and IEEGP datasets, the model achieves\nlow SEN (0.254 and 0.450, respectively), high PRE\n(0.841 and 0.917, respectively), and low mFPR/h\n(0.347 and 0, respectivel y). The poorer results on\n2350012-9\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nW. Y. Peh et al.\nTable 3. Segment-level seizure detection results for diﬀerent CNN models across six EEG datasets.\nDataset\n W\n CNN-SM\n CNN-BM\n CNN-TRF-BM\nECE ACC BAC SEN SPE F1\n ECE ACC BAC SEN SPE F1\n ECE ACC BAC SEN SPE F1\nTUH-SZ\nScalp EEG\nAdult\n3\n 0.051 0.818 0.736 0.888 0.584 0.817\n 0.027 0.820 0.733 0.901 0.565 0.816\n 0.262 0.823 0.751 0.885 0.616 0.824\n5\n 0.036 0.804 0.779 0.856 0.702 0.804\n 0.033 0.810 0.789 0.856 0.722 0.811\n 0.248 0.814 0.794 0.856 0.732 0.815\n10\n 0.039 0.815 0.817 0.783 0.850 0.815\n 0.031 0.833 0.833 0.815 0.852 0.833\n 0.027 0.832 0.831 0.800 0.862 0.831\n20\n 0.268 0.833 0.823 0.766 0.881 0.833\n 0.031 0.841 0.829 0.771 0.888 0.841\n 0.251 0.856 0.846 0.795 0.897 0.855\nHUH\nScalp EEG\nNeonatal\n3\n 0.193 0.514 0.510 0.514 0.507 0.534\n 0.130 0.776 0.776 0.746 0.926 0.803\n 0.259 0.614 0.614 0.577 0.735 0.710\n5\n 0.200 0.470 0.545 0.376 0.714 0.471\n 0.232 0.746 0.746 0.709 0.932 0.784\n 0.303 0.533 0.533 0.429 0.869 0.618\n10\n 0.353 0.407 0.575 0.192 0.957 0.349\n 0.366 0.651 0.651 0.581 1 0.695\n 0.467 0.455 0.455 0.292 0.984 0.514\n20\n 0.357 0.413 0.575 0.183 0.968 0.349\n 0.414 0.628 0.628 0.533 0.817 0.691\n 0.444 0.426 0.426 0.251 0.994 0.483\nCHB-MIT\nScalp EEG\nPaediatric\n3\n 0.122 0.789 0.801 0.804 0.798 0.789\n 0.117 0.798 0.811 0.819 0.804 0.801\n 0.258 0.833 0.847 0.808 0.886 0.837\n5\n 0.105 0.814 0.824 0.762 0.887 0.808\n 0.126 0.811 0.816 0.700 0.932 0.808\n 0.256 0.822 0.824 0.715 0.932 0.819\n10\n 0.118 0.874 0.841 0.745 0.936 0.867\n 0.100 0.875 0.831 0.686 0.976 0.862\n 0.104 0.879 0.837 0.698 0.976 0.866\n20\n 0.362 0.921 0.838 0.699 0.976 0.910\n 0.104 0.918 0.815 0.650 0.979 0.906\n 0.334 0.929 0.847 0.711 0.982 0.920\nSWEC-ETHZ\niEEG\nAdult\n3\n 0.585 0.335 0.546 0.981 0.110 0.267\n 0.532 0.769 0.776 0.808 0.680 0.821\n 0.278 0.415 0.579 0.959 0.199 0.358\n5\n 0.487 0.417 0.600 0.980 0.220 0.380\n 0.355 0.584 0.601 0.514 0.886 0.659\n 0.234 0.541 0.649 0.917 0.381 0.529\n10\n 0.231 0.717 0.763 0.871 0.655 0.731\n 0.131 0.455 0.472 0.311 0.992 0.509\n 0.196 0.751 0.768 0.841 0.695 0.766\n20\n 0.226 0.806 0.832 0.881 0.773 0.819\n 0.151 0.449 0.463 0.296 0.996 0.493\n 0.261 0.877 0.872 0.858 0.874 0.883\nIEEGP\niEEG\nAdult\n3\n 0.289 0.753 0.753 0.727 0.884 0.787\n 0.308 0.636 0.535 0.952 0.118 0.542\n 0.376 0.720 0.720 0.769 0.474 0.760\n5\n 0.311 0.722 0.722 0.779 0.439 0.759\n 0.278 0.658 0.555 0.968 0.143 0.559\n 0.325 0.737 0.737 0.706 0.892 0.778\n10\n 0.306 0.692 0.692 0.631 1 0.738\n 0.326 0.726 0.679 0.808 0.551 0.697\n 0.334 0.670 0.670 0.604 1 0.712\n20\n 0.290 0.621 0.621 0.571 0.720 0.690\n 0.345 0.757 0.705 0.883 0.528 0.733\n 0.398 0.616 0.616 0.429 0.991 0.648\nEIM\niEEG\nAdult\n3\n 0.292 0.650 0.553 0.953 0.152 0.556\n 0.180 0.372 0.545 0.939 0.150 0.310\n 0.201 0.631 0.505 0.999 0.010 0.495\n5\n 0.279 0.568 0.459 0.893 0.025 0.468\n 0.280 0.577 0.670 0.904 0.436 0.575\n 0.203 0.654 0.538 0.989 0.087 0.543\n10\n 0.262 0.654 0.568 0.909 0.227 0.586\n 0.224 0.841 0.809 0.785 0.832 0.849\n 0.218 0.715 0.646 0.926 0.366 0.655\n20\n 0.204 0.648 0.644 0.603 0.685 0.611\n 0.246 0.833 0.850 0.886 0.808 0.846\n 0.224 0.780 0.745 0.881 0.609 0.749\nthe HUH dataset align with our expectations since\nit is a neonatal dataset. The morphology of neonatal\nseizures diﬀers vastly from adult seizures. Since the\nmodel has been trained on adult scalp EEG, it\nstruggles to detect seizures in neonatal scalp EEGs.\nMeanwhile, the IEEGP dataset contains some dog\niEEGs, which could have diﬀerent seizure patterns\nfrom adult humans. However, we observed that the\ndetection performance is comparable for human and\ndog EEGs. Hence, the proposed detector can detect\nsome neonate and dog seizures with high PRE, which\ncan be tremendously valuable.\nWe also determined the detection oﬀset, deﬁned\nas the average duration between the start time of the\nseizure and the start time of its corresponding detec-\ntion (see Table 4), which can be negative. A negative\noﬀset does not imply forecasting, as the EEG data is\nanalyzed oﬄine.\n52 Therefore, data from future time\nintervals are being considered to decide whether an\nEEG segment is ictal.\nFinally, to determine the eﬀectiveness of the\nCNN-TRF-BM-based EEG-l evel seizure detector\n(Fig. 4), we plot the normalized histograms of the\nTP and FN of seizures det ected sorted by event\nduration, together with the normalized histogram of\nSEN, PRE, and FPR/h computed from individual\nEEGs across the datasets. From Fig. 4(a), it can be\nseen that it is easier to detect a long seizure than\na short event. Figures 4(b) and 4(c) reveal that the\nSEN and PRE are high for most EEGs, with only\na minority of the ﬁles having a poor detection rate.\nLast, Fig. 4(d) conﬁrms that the system does not\nmake false detections in most EEGs, as mFPR/h\nis 0. Taken together, these ﬁgures suggest that the\nproposed detector performs well across most EEGs.\nThe proposed seizure det ectors, speciﬁcally the\nCNN-TRF-BM-based mode l, can detect patient-\nindependent seizures at the channel-, segment-, and\nEEG-level across various scalp EEG and iEEG\ndatasets without retraining. It takes less than 15 s\ncomputation time to detect seizures in a 30 min\nEEG. Hence, the proposed d etector can help auto-\nmate EEG annotations clinically. However, while the\nresults are appealing for adult human EEG, there is\nroom for improvement for neonatal EEG. One may\nneed to perform additional tuning or retraining to\nachieve better performance for such cases.\n4. Discussion\n4.1. Comparison with existing\npatient-independent detectors\nTo compare the proposed seizure detector to the\nstate of the art is challenging, as there is a lack of\nstandardized evaluation metrics, datasets, or train-\ning and testing procedures for the problem of seizure\n2350012-10\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nSix-Center Assessment of Seizure Detection in EEG\nTable 4. EEG-level seizure detection results for diﬀerent models evaluated with MOES across six EEG datasets.\nDataset\n W\n CNN-SM\n CNN-BM\n CNN-Transformer-BM\nSEN PRE aFPR/h mFPR/h Oﬀset\n SEN PRE aFPR/h mFPR/h Oﬀset\n SEN PRE aFPR/h mFPR/h Oﬀset\nTUH-SZ\nScalp EEG\nAdult\n3\n 0.70 .457 0 .803 0 −4.125\n 0.713 0 .49 0 .479 0 −4.5\n 0.772 0 .429 0 .425 0 −2.125\n5\n 0.704 0 .48 0 .555 0 −4.5\n 0.701 0 .491 0 .413 0 −1.5\n 0.653 0 .476 0 .411 0 0 .625\n10\n 0.719 0 .495 0 .466 0 −1\n 0.701 0 .512 0 .237 0 1 .5\n 0.671 0 .534 0 .954 0 0 .5\n20\n 0.707 0 .467 0 .679 0 6 .25\n 0.708 0 .49 0 .468 0 6\n 0.655 0 .52 1 .037 0 2 .875\nCHB-MIT\nScalp EEG\nPediatric\n3\n 0.638 0 .112 1 .721 1 .099 0 .711\n 0.613 0 .14 0 .916 0 .539 −2.763\n 0.70 .181 1 .095 0 .616 0 .053\n5\n 0.678 0 .143 1 .514 0 .868 −4.474\n 0.568 0 .235 0 .600 0 .158 2 .947\n 0.571 0 .292 0 .541 0 .224 1 .605\n10\n 0.734 0 .254 1 .041 0 .618 0 .158\n 0.704 0 .411 0 .291 0 .026 4 .737\n 0.678 0 .377 0 .421 0 .118 4 .684\n20\n 0.803 0 .194 1 .224 0 .592 6 .842\n 0.741 0 .244 0 .884 0 .368 5 .237\n 0.769 0 .383 0 .445 0 .145 1 .474\nHUH\nScalp EEG\nNeonatal\n3\n 0.298 0 .334 2 .565 1 .094 6\n 0.623 0 .576 2 .320 2 .276 −3.52\n 0.515 0 .522 2 .874 2 .843 −2.255\n5\n 0.328 0 .372 2 .413 0 .849 4 .25\n 0.314 0 .505 1 .977 1 .933 3 .892\n 0.253 0 .649 0 .678 0 .623 5 .098\n10\n 0.254 0 .397 1 .671 0 .181 11 .5\n 0.214 0 .807 0 .334 0 .303 13 .52\n 0.227 0 .818 0 .253 0 .223 10 .853\n20\n 0.276 0 .473 1 .340 0 .186 14 .25\n 0.283 0 .686 0 .708 0 .674 16 .333\n 0.254 0 .841 0 .374 0 .347 15 .245\nSWEC-ETHZ\niEEG\nAdult\n3\n 0.743 0 .758 2 .316 1 .415 10 .781\n 0.933 0 .865 1 .286 0 .469 −2.156\n 0.938 0 .878 0 .895 0 .559 7 .687\n5\n 0.938 0 .949 0 .362 0 3 .781\n 0.923 0 .752 2 .854 2 .391 0 .312\n 0.933 0 .834 1 .784 1 .127 4 .906\n10\n 0.933 0 .785 2 .223 0 .884 4 .187\n 0.825 0 .695 3 .265 2 .858 15 .719\n 0.857 0 .748 2 .899 1 .648 10 .375\n20\n 0.878 0 .711 3 .897 3 .601 14 .937\n 0.911 0 .744 2 .764 1 .259 16 .531\n 0.849 0 .727 3 .010 2 .205 12 .5\nIEEGP\niEEG\nAdult\n3\n 0.60 .964 0 .523 0 −19\n 0.583 0 .958 0 .500 0 −14.5\n 0.667 0 .82 .200 2 −19\n5\n 0.667 0 .82 .624 2 −17\n 0.583 0 .906 1 .595 0 −17\n 0.617 0 .944 1 .120 0 −17\n10\n 0.592 0 .946 0 .750 0 −12\n 0.45 0 .678 5 .596 7 −12\n 0.50 .753 4 .423 5 −12\n20\n 0.567 0 .805 3 .846 0 −2\n 0.542 0 .906 1 .500 0 −2\n 0.45 0 .917 0 .500 0 −2\nEIM\niEEG\nAdult\n3\n 0.972 1 0 0 −22.083\n 0.792 0 .904 1 .245 1 .286 −7\n 11 1 .523 0 −32.083\n5\n 0.979 0 .938 1 .080 0 −30.083\n 10 .972 0 .484 0 .452 −15.417\n 11 0 .647 0 −23.958\n10\n 11 0 0 −23.417\n 0.931 0 .979 0 .520 0 10 .542\n 0.931 1 0 .830 0 −1.333\n20\n 0.875 0 .964 0 .494 0 .711 5 .208\n 11 0 0 −0.792\n 0.951 1 0 .507 0 −3.125\nFig. 4. EEG-level seizure detection results for the CNN-TRF-BM model across diﬀerent datasets. (a) Normalized his-\ntograms of TPs and FNs sorted by seizure duration; (b-d) Normalized histograms of the SEN, PRE, and false positive\nrate per hour (FPR/h) for individual EEGs, respectively.\n2350012-11\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nW. Y. Peh et al.\ndetection. In addition, the datasets considered in\nthe literature vary in terms of patients (age, type,\ndiversity), clinical settings, EEG type, data quantity\nand quality, and use case (patient-speciﬁc versus\npatient-independent).\nIt is especially critical to specify the use case, as\npatient-speciﬁc detectors may yield much better per-\nformance than a patient-independent detector, but\ncannot be readily deployed. Therefore, comparing\nthese two types of detect ors is meaningless. Con-\nsequently, we consider studies that report patient-\nindependent seizure detection results on the six\ndatasets analyzed in this paper.\n4.1.1. Detection on the TUH-SZ dataset\nNumerous patient-independent seizure detectors\nhave been evaluated on the TUH-SZ dataset.\nRoy et al. utilized diﬀerent machine learning mod-\nels and reported a SEN and FPR/h of 0.916\nand 137.311.\n12 Meanwhile, Shah et al. applied\nan LTSM to detect seizures at the segment-level\nand obtained SEN between 0.33–0.37 and FPR/h\nbetween 1.24–20.8. 10 Ayodele et al. trained a\nVGGNet and evaluated it on 24 EEGs, attaining a\nSEN, FPR/h, and oﬀset of 0.7835, 0.9, and 2.32s,\nrespectively.\n11\nMost results reported are not suitable for clinical\napplication; extremely low SEN or high FPR/h.\nAdditionally, most studies did not report the seizure\nevaluation metrics. When they do, they utilize EBS\nand OVLP metrics, which fail to represent the\nrequirements of a seizure de tector appropriately. In\ncontrast, the proposed CNN-TRF-BM seizure detec-\ntor achieved superior results calculated with MOES\n(SEN, PRE, aFPR/h, and mFPR/h of 0.772, 0.429,\n0.425, and 0, respectively), which is suitable for clini-\ncal applications. However, to the author’s knowledge,\nno existing studies have reported the PRE, although\nit is an essential metric in clinical practice. Moreover,\nonly a few studies reported the oﬀset.\n4.1.2. Detection on the CHB-MIT dataset\nIn the following, we review the results of the\nCHB-MIT dataset reported in the literature. Fur-\nbass et al. deployed epileptiform wave sequence\n(EWS) to classify seizures and obtained a SEN\nand FPR/h of 0.67 and 0.32, respectively.\n13\nG˜A¸smez et al. applied a CNN and achieved a SEN,\nSPE, and FPR/h of 0.531, 0.931, and 7.8, respec-\ntively.15 Ayodele et al.employed the CHB-MIT and\nTUH-SZ dataset and reported a SEN, FPR/h, and\noﬀset of 0.7145, 0.76, and 2.32s, respectively.11 Man-\nsouri et al. trained their detector on the CHB-\nMIT (19 patients) and the TUH-SZ (24 patients)\ndataset and evaluated the detector on the CHB-MIT\ndataset.\n14 They attained a SEN, SPE, and FPR/h\nof 0.83, 0.96, and 8, respectively.\nThe proposed CNN-TRF-BM model achieves\nbetter results on the CHB-MIT dataset, with SEN,\nPRE, aFPR/h, mFPR/h, and oﬀset of 0.678, 0.377,\n0.421, 0.118, and 4.684s, respectively. However,\nwe trained our detector with the TUH-SZ dataset\ninstead of the CHB-MIT dataset. The TUH-SZ\ndataset contains more seizures (3055 events) com-\npared to CHB-MIT (185 events), giving the model\nmore data to learn from. This shows that training\nthe detector on a diﬀeren t but larger dataset may\nhelp improve the performance.\n4.1.3. Detection on the SWEC-ETHZ dataset\nNo existing seizure detectors had been evaluated on\nthe SWEC-ETHZ dataset in a patient-independent\nmanner. Existing studies only performed patient-\nspeciﬁc detection on this dataset.\n42 The current\nstudy can be the baseline for patient-independent\nseizure detection on the SWEC-ETHZ dataset.\n4.1.4. Detection on the HUH dataset\nNo seizure detectors have so far been evaluated\non the HUH dataset in a patient-independent\nmanner. Existing studies only evaluated patient-\nspeciﬁc seizure detection.\n53 This study is the ﬁrst\nto perform patient-independent seizure detection\nat EEG-level on the HUH dataset. Moreover, we\napplied a detector trained on adult EEGs to detect\nseizures in neonatal EEGs and attained promising\nresults. This shows that a detector trained on adult\nseizures may capture neonatal seizures with a high\nPRE, despite the substantial age gap. As the model\nhas been trained on adult scalp EEG, it struggles to\ndetect all seizures in neonatal EEGs.\n4.1.5. Detection on the IEEGP dataset\nFew studies investigated seizure detection on the\nIEEGP dataset. All studies are on patient-speciﬁc\n2350012-12\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nSix-Center Assessment of Seizure Detection in EEG\nseizure detections.54 Similarly, ACC is a poor met-\nric for an imbalanced dataset. Therefore, the current\nstudy can be the baseline for patient-independent\nseizure detection on the IEEGP dataset.\n4.1.6. Detection on the EIM dataset\nNo earlier studies on seizure detection have been con-\nducted on the EIM dataset. The existing studies aim\nto predict surgical outcomes.\n44 This study is the ﬁrst\nto analyze the EIM dataset for patient-independent\nseizure detection.\n4.2. Commercial detectors\nSeveral commercial seizure detectors are available\nin the market, such as Persyst,\n55 Encevis,56 and\nBESA.56 Earlier studies by Reus et al. 37 and\nKoren et al.38 have compared the performance of\nPersyst, Encevis, and BESA. We summarized their\nﬁndings against the performance of the proposed\ndetector in Table 5. Both studies evaluated the\ncommercial detectors on a dult scalp EEG datasets;\nhence, we focus on the TUH-SZ dataset in this\nsection.\nThe proposed model outperforms the three\ncommercial detectors in the study conducted by\nReus et al. by a signiﬁcant margin. Meanwhile, the\nproposed system outperforms Persyst and BESA in\nthe study by Koren et al., with Encevis reporting\nsimilar results to this study. However, we report\nMOES, TAES, OVLP, and IMS metric results. In\ncontrast, Reus et al. and Koren et al. only reported\nIMS, which is more lenient as they consider a detec-\ntion correct as long as th e detection is within 30\ns before the start or after the end of the seizure.\nKoren et al.implemented an altered version of IMS,\nwhere the margin is increased to 120s. These metrics\nintroduced a signiﬁcant margin of error, which is\ninappropriate in clinical practice.\nTable 5. Performance of commercial seizure detec-\ntors against the proposed CNN-TRF-BM detector.\nAuthor No of\nPatients\nNo of\nSeizures\nDuration\n(in hours) Metrics Seizure\nDetector SEN aFPR/h\nReus et al. 37 283 249 8771 IMS\nPersyst 14 0.558 0.071\nEncevis 1.9.2 0.518 0.229\nBESA 2.0 0.430 0.100\nKoren et al. 38 81 790 6900 IMS\nPersyst 13 0.816 0.9\nEncevis 1.7 0.778 0.2\nBESA 2.0 0.676 0.7\nCurrent\nstudy\n637\nTUH-SZ 3055 922\nMOES CNN-TRF-BM 0.772 0.425\nOVLP CNN-TRF-BM 0.775 0.423\nIMS CNN-TRF-BM 0.797 0.412\n4.3. Transformer for seizure detection\nWe identiﬁed two studies that apply transformers\nfor seizure detection. 22 However, these systems did\nnot implement a channel-level detector but headed\ndirectly to the segment-level. Thus, this study is the\nﬁrst to implement a channel-level seizure detector\nthrough transformers.\nBhattacharya et al. utilized a transformer for\npatient-speciﬁc seizure d etection on the CHB-MIT\nand IEEGP dataset.\n22 For the CHB-MIT and\nIEEGP datasets, they attained an average SEN of\n0.985 and 0.948, and FPR/h of 0.124 and 0, respec-\ntively. While they used transformers, there were sig-\nniﬁcant diﬀerences in the study performed by Bhat-\ntacharya et al. as compared to this study. First, we\nfollowed a patient-independent approach while they\ndesigned a patient-speciﬁcdetector. Second, the pro-\nposed system can detect seizures at the channel-level.\nIn contrast, their systems can only detect seizures at\nthe segment-level. Third, we implemented BM loss\nwhile they utilized the SM loss.\n4.4. Complexity of seizure detectors\nMost seizure detectors prop o s e di nt h el i t e r a t u r ed o\nnot perform channel-level detection and proceed to\nsegment-level detection directly. The main innova-\ntion in those studies lies in improving the deep neural\nnetworks used for segment-level classiﬁcation. These\ndeep neural networks typically contain numerous lay-\ners (often 10+) and millions of parameters, which\nrequire substantial computational power for train-\ning. Moreover, such networks tend to overﬁt speciﬁc\ndatasets, leading to poor generalization. We explore\nwhether deeper models lead to better seizure detec-\ntion performance.\nIn Table 6, we list diﬀerent deep learning sys-\ntems and provide information about their design\nand seizure detection performance. These neural net-\nworks for seizure detectors contain many layers,\nranging between 2 and 709, and contain 7600 to\n138 million parameters. The inputs to those models\nalso vary signiﬁcantly, ranging from 5888 to 228,000\ninput data points. In contrast, the three proposed\nseizure detectors only require between 384 to 2560\ninput data points for window lengths varying from\n5 s to 20 s. Moreover, the models contain 7 to 15 lay-\ners, with 0.16 to 3.5 million parameters for the CNN\n2350012-13\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nW. Y. Peh et al.\nand CNN-TRF models. The input size, number of\nlayers, and parameters for the proposed models are\nmuch smaller than for most of the existing models\nlisted in Table 6.\nNext, we examined the correlation between model\nsize and performance. The proposed seizure detector\nmodels reported higher SEN and lower FPR/h than\nmost models with more parameters and layers. The\nAUC, ACC, BAC, and F1 were comparable, while\nthe SPE was poorer in our model. However, SPE is\nonly computed in segment-level classiﬁcation, which\nis not an EEG-level detection metric. Moreover, the\nproposed models obtained better AUPRC, SEN, and\nFPR/h than most existing models with fewer param-\neters and layers.\nOverall, the proposed models outshine models\nwith vastly more parameters, which suggests that\ndesigning ever-bigger neural networks for seizure\ndetection may not be a fruitful avenue for research.\nInstead, alternative pipelines with substantially\nfewer parameters may perform comparably to the\nstate of the art or even better. In this study, we\ndemonstrated that by ﬁrst detecting seizures at indi-\nvidual channels, one could vastly reduce the number\nof parameters while achieving the same or increased\nlevel of performance.\n5. Conclusions and Future work\nThis study proposed patient-independent seizure\ndetectors that identify seizures on three EEG\nscales: channel-, segment- and EEG-level. First,\nthe channel-level detectors detect seizures in single-\nchannel segments through a CNN-based deep learn-\ning model. Next, we perform segment-level detec-\ntion based on statistical features extracted from\nthe channel-level outputs based on diﬀerent scalp\nregions. At last, we apply post-processing ﬁlters to\nthe segment-level outputs to determine any detected\nseizures’ start and end times.\nTable 6. Deep learning models in the literature in terms of complexity and performance.\nParameters Input\nAuthor Model Layers (in millions) size AUC AUPRC ACC BAC SEN SPE PRE F1 FPR/h\nAsif et al. 57 SeizureNet 133 45 .94 150 , 5 2 8 — — ————— 0 . 8 9 6 —\nRaghu et al. 23\nAlexNet 25 62 51 , 5 2 9 — —0 . 7 6 8 ————— —\nVGG16 41 138 50 , 1 7 6 — —0 . 8 3 3 ————— —\nVGG19 47 138 50 , 1 7 6 — —0 . 8 1 8 ————— —\nSqueezeNet 68 1 .25 1 , 529 — — 0.851 — — — — — —\nGoogleNet 144 7 50 , 176 — — 0.745 — — — — — —\nInceptionv3 316 24 89 , 4 0 1 — —0 . 8 8 3 ————— —\nDenseNet201 709 20 50 , 1 7 6 — —0 . 8 5 1 ————— —\nResNet18 72 11 50 , 1 7 6 — —0 . 8 6 2 ————— —\nResNet50 177 23 50 , 176 — — 0.862 — — — — — —\nResNet101 347 29 .45 0 , 1 7 6 — —0 . 8 6 3 ————— —\nCovert et al. 28 TGCN 30 5 .5 415 , 107 0.926 — — 0.809 0.648 0.970 — — —\nYuan et al. 30 CNN 4 0 .04 17 , 664 0.957 0.906 0.944 — — — — 0.853 —\nZhou et al. 58 CNN 3 0 .45 , 888 — — 0.595 0.595 0.618 0.572 — — —\nSaab et al. 24 ChronoNet 10 12 .74 5 , 6 0 0 0 . 9 3 0— ————— 0 . 7 7 0 0 . 1 0 0\nEmami et al. 25 VGG16 41 138 50 , 176 — — — — 0.740 — — — 0.200\nAnsari et al. 20 CNN 23 0 .0076 54 , 000 0.830 — — — 0.770 — — — 0.900\nGomez et al. 15 CNN 12 0 .314 21 , 504 — 0.440 0.929 0.731 0.531 0.931 0.514 0.461 7.800\nCurrent study\nCNN 7 0 .16 384 — — — — 0.713 — 0.490 0.581 0\nCNN 7 0 .26 640 — — — — 0.701 — 0.491 0.578 0\nCNN 7 0 .52 1 , 280 — — — — 0.701 — 0.512 0.592 0\nCNN 7 1 2 , 560 — — — — 0.708 — 0.490 0.579 0\nCurrent study\nCNN-TRF 15 2 .3 384 — — — — 0.772 — 0.429 0.552 0\nCNN-TRF 15 2 .5 640 — — — — 0.653 — 0.476 0.551 0\nCNN-TRF 15 2 .81 , 280 — — — — 0.671 — 0.534 0.595 0\nCNN-TRF 15 3 .52 , 560 — — — — 0.655 — 0.520 0.580 0\n2350012-14\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nSix-Center Assessment of Seizure Detection in EEG\nWe trained and tested the proposed detectors\non the TUH-SZ scalp EEG dataset before evalu-\nating the pretrained detectors on ﬁve independent\nscalp EEG and iEEG datasets. Also, we introduced\nMOES to address some shortcomings of the existing\nEEG-level detection metrics. To the author’s knowl-\nedge, this study is one of the ﬁrst to incorporate\na channel-level detector within the seizure detec-\ntion system.\n32 Moreover, we implemented a pipeline\nthat can detect seizures with any number of elec-\ntrodes and demonstrated that a channel-level detec-\ntor is essential for reliable seizure detection and\nboosting the generalizat ion performance. Finally,\nthe proposed seizure det ector is computationally\neﬃcient, with a computation time of less than 15 s for\na 30 min EEG. Hence, the detector may help acceler-\nate and improve EEG annotation in clinical practice.\nHowever, as the seizure detector is based on deep\nlearning, it is nearly impossible to identify the exact\nfeatures contributing signiﬁcantly to the seizure dis-\ncrimination process. We can perform manual feature\nextraction before deploying the deep learning models\nin future work. For instance, we can decompose the\ntime series into diﬀerent frequency bands via wavelet\nor Fourier transforms. This way, we may understand\nthe contribution and signiﬁcance of each frequency\ncomponent of the EEG signals, yielding signiﬁcantly\nmore information than by just inputting raw time\nseries signals.\nAdditionally, we will address the problem of\ndetecting artifacts be fore seizure detection.\n49 The\nartifact detector will be designed to reduce FPR/h\nand improve the PRE of the seizure detector. Con-\nsequently, it can reject artifacts without eliminating\nimportant cerebral signals, such as slow waves, sharp\nwaves, and seizures in EEGs.\nReferences\n1. V. K. Jirsa, W. C. Stacey, P. P. Quilichini, A. I.\nIvanov and C. Bernard, On the nature of seizure\ndynamics, Brain 137(8) (2014) 2210–2230.\n2 . V .D .N u n e s ,L .S a w y e r ,J .N e i l s o n ,G .S a r r ia n dJ .H .\nCross, Diagnosis and management of the epilepsies\nin adults and children: Summary of updated nice\nguidance, BMJ 344 (2012).\n3. S. Jenssen, E. J. Gracely and M. R. Sperling, How\nlong do most seizures last? A systematic comparison\nof seizures recorded in the epilepsy monitoring unit,\nEpilepsia 47(9) (2006) 1499–1503.\n4. M. M. Goldenberg, Overview of drugs used for\nepilepsy and seizures: Etiology, diagnosis, and treat-\nment, Pharm. Ther. 35(7) (2010) 392.\n5. World Health Organization, Programme for Neu-\nrological Diseases and Neuroscience (World Health\nOrganization), International Bureau for Epilepsy,\nInternational League against Epilepsy, Atlas:\nEpilepsy Care in the World (World Health Organi-\nzation, 2005).\n6. F. F. Ferri, Ferri’s Clinical Advisor 2020 ,E - B o o k :5\nBooks in 1 (Elsevier Health Sciences, 2019).**\n7. A. T. Berg, Risk of recurrence after a ﬁrst unpro-\nvoked seizure, Epilepsia 49 (2008) 13–18.\n8. F. Mormann, R. G. Andrzejak, C. E. Elger and\nK. Lehnertz, Seizure prediction: The long and wind-\ning road, Brain 130(2) (2007) 314–333.\n9. I. Geut, S. Weenink, I. Knottnerus and M. J.\nvan Putten, Detecting interictal discharges in ﬁrst\nseizure patients: Ambulatory EEG or EEG after\nsleep deprivation? Seizure 51 (2017) 52–54.\n10. V. Shah, M. Golmohammadi, S. Ziyabari, E. Von\nWeltin, I. Obeid and J. Picone, Optimizing chan-\nnel selection for seizure detection, in2017 IEEE Sig-\nnal Processing in Medicine and Biology Symposium\n(SPMB ) (IEEE, 2017), pp. 1–5.\n11. K. Ayodele, W. Ikezogwo, M. Komolafe and\nP. Ogunbona, Supervised domain generalization for\nintegration of disparate scalp EEG datasets for auto-\nmatic epileptic seizure detection,Comput. Biol. Med.\n120 (2020) 103757.\n12. S. Roy et al. , Evaluation of artiﬁcial intelligence sys-\ntems for assisting neurologists with fast and accurate\nannotations of scalp electroencephalography data,\nEBioMedicine (2021) 103275.\n13. F. F¨urbass et al. , Prospective multi-center study\nof an automatic online seizure detection system\nfor epilepsy monitoring units, Clin. Neurophysiol.\n126(6) (2015) 1124–1131.\n14. A. Mansouri, S. P. Singh and K. Sayood, Online EEG\nseizure detection and localization, Algorithms 12(9)\n(2019) 176.\n15. C. G´o m e z ,P .A r b e l ´aez, M. Navarrete, C. Alvarado-\nRojas, M. Le Van Quyen and M. Valderrama, Auto-\nmatic seizure detection based on imaged-EEG sig-\nnals through fully convolutional networks, Sci. Rep.\n10(1) (2020) 1–13.\n16. O. Faust, U. R. Acharya, H. Adeli and A. Adeli,\nWavelet-based EEG processing for computer-aided\nseizure detection and epilepsy diagnosis, Seizure 26\n(2015) 56–64.\n17. H. Adeli, Z. Zhou and N. Dadmehr, Analysis of EEG\nrecords in an epileptic patient using wavelet trans-\nform, J. Neurosci. Meth. 123(1) (2003) 69–87.\n18. S. Ghosh-Dastidar, H. Adeli and N. Dadmehr,\nMixed-band wavelet-chaos-neural network method-\nology for epilepsy and epileptic seizure detection,\nIEEE Trans. Biomed. Eng. 54(9) (2007) 1545–1551.\n2350012-15\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nW. Y. Peh et al.\n19. M. Savadkoohi, T. Oladunni and L. Thompson, A\nmachine learning approach to epileptic seizure pre-\ndiction using electroencephalogram (EEG) signal,\nBiocybern. Biomed. Eng. 40(3) (2020) 1328–1341.\n20. A. H. Ansari, P. J. Cherian, A. Caicedo, G. Naulaers,\nM. De Vos and S. Van Huﬀel, Neonatal seizure detec-\ntion using deep convolutional neural networks, Int.\nJ. Neural Syst. 29(4) (2019) 1850011.\n21. X. Hu, S. Yuan, F. Xu, Y. Leng, K. Yuan and\nQ. Yuan, Scalp EEG classiﬁcation using deep Bi-\nLSTM network for seizure detection, Comput. Biol.\nMed. 124 (2020) 103919.\n22. A. Bhattacharya, T. Baweja and S. Karri, Epileptic\nseizure prediction using deep transformer model,Int.\nJ. Neural Syst. (2021) 2150058.\n23. S. Raghu, N. Sriraam, Y. Temel, S. V. Rao and P. L.\nKubben, EEG based multi-class seizure type classiﬁ-\ncation using convolutional neural network and trans-\nfer learning, Neural Netw. 124 (2020) 202–212.\n24. K. Saab, J. Dunnmon, C. R´e, D. Rubin and C. Lee-\nMesser, Weak supervision as an eﬃcient approach for\nautomated seizure detection in electroencephalogra-\nphy, NPJ Digit. Med. 3(1) (2020) 1–12.\n25. A. Emami, N. Kunii, T. Matsuo, T. Shinozaki,\nK. Kawai and H. Takahashi, Seizure detection by\nconvolutional neural network-based analysis of scalp\nelectroencephalography plot images, NeuroImage:\nClin. 22 (2019) 101684.\n26. H. S. Nogay and H. Adeli, Detection of epileptic\nseizure using pretrained deep convolutional neural\nnetwork and transfer learning, Eur. Neurol. 83(6)\n(2020) 602–614.\n2 7 . S .S a n t a n i e l l o ,S .P .B u r n s ,A .J .G o l b y ,J .M .S i n g e r ,\nW. S. Anderson and S. V. Sarma, Quickest detec-\ntion of drug-resistant seizures: An optimal control\napproach, Epilepsy Behav. 22 (2011) S49–S60.\n28. I. C. Covert, B. Krishnan, I. Najm, J. Zhan,\nM. Shore, J. Hixson and M. J. Po, Temporal graph\nconvolutional networks for automatic seizure detec-\ntion, in Proceedings of the 4th Machine Learning for\nHealthcare Conference (Ann Arbor, Michigan, 2019),\npp. 160–180.\n29. S. Roy, I. Kiral-Kornek and S. Harrer, Chrononet:\nA deep recurrent neural network for abnormal\nEEG identiﬁcation, in Conf. Artiﬁcial Intelligence\nin Medicine in Europe (Springer, 2019), pp. 47–56.\n30. Y. Yuan, G. Xun, K. Jia and A. Zhang, A multi-view\ndeep learning framework for EEG seizure detection,\nIEEE J. Biomed. Health Inf. 23(1) (2018) 83–94.\n31. C. Guo, G. Pleiss, Y. Sun and K. Q. Weinberger,\nOn calibration of modern neural networks, in Pro-\nceedings of the 34th International Conference on\nMachine Learning (International Convention Cen-\ntre, Sydney, Australia, 2017), pp. 1321–1330.\n32. Y. Lu, Y. Ma, C. Chen and Y. Wang, Classiﬁcation\nof single-channel EEG signals for epileptic seizures\ndetection based on hybrid features, Technol. Health\nCare 26(S1) (2018) 337–346.\n33. U. R. Acharya, S. L. Oh, Y. Hagiwara, J. H. Tan and\nH. Adeli, Deep convolutional neural network for the\nautomated detection and diagnosis of seizure using\nEEG signals, Comput. Biol. Med. 100 (2018) 270–\n278.\n34. G. Liu, L. Tian and W. Zhou, Patient-independent\nseizure detection based on channel-perturbation con-\nvolutional neural network and bidirectional long\nshort-term memory,Int. J. Neural Syst.\n32(6) (2022)\n2150051.\n35. L. Spyrou, D. Mart´ın-Lopez, A. Valent´ın, G. Alarc´on\nand S. Sanei, Detection of intracranial signatures\nof interictal epileptiform discharges from concurrent\nscalp EEG, Int. J. Neural Syst. 26(4) (2016)\n1650016.\n36. V. Shah, M. Golmohammadi, I. Obeid and J. Picone,\nObjective evaluation metrics for automatic classiﬁca-\ntion of EEG events, Biomed. Signal Process. (2021)\n223–255.\n37. E. Reus, G. Visser, J. van Dijk and F. Cox, Auto-\nmated seizure detection in an EMU setting: Are soft-\nware packages ready for implementation?Seizure 96\n(2022) 13–17.\n38. J. Koren, S. Hafner, M. Feigl and C. Baumgart-\nner, Systematic analysis and comparison of com-\nmercial seizure-detection software, Epilepsia 62(2)\n(2021) 426–438.\n39. V. Shah, E. Von Weltin, S. Lopez, J. R. McHugh,\nL. Veloso, M. Golmohammadi, I. Obeid and\nJ. Picone, The temple university hospital seizure\ndetection corpus, Front. Neuroinform. 12 (2018) 83.\n40. A. Shoeb, H. Edwards, J. Connolly, B. Bourgeois,\nS. T. Treves and J. Guttag, Patient-speciﬁc seizure\nonset detection, Epilepsy Behav. 5(4) (2004) 483–\n498.\n41. N. Stevenson, K. Tapani, L. Lauronen and S. Van-\nhatalo, A dataset of neonatal EEG recordings with\nseizure annotations, Sci. Data 6(1) (2019) 1–8.\n42. A. Burrello, K. Schindler, L. Benini and A. Rahimi,\nHyperdimensional computing with local binary pat-\nterns: One-shot learning of seizure onset and identiﬁ-\ncation of ictogenic brain regions using short-time ieeg\nrecordings, IEEE Trans. Biomed. Eng. 67(2) (2019)\n601–613.\n43. J. B. Wagenaar, B. H. Brinkmann, Z. Ives, G. A.\nWorrell and B. Litt, A multimodal platform for\ncloud-based collaborative research, in 2013 6th\nInt. IEEE/EMBS Conf. Neural Engineering (NER)\n(IEEE, 2013), pp. 1386–1389.\n44. A. Li et al. , Neural fragility as an EEG marker of\nthe seizure onset zone, Nat. Neurosci. 24(10) (2021)\n1465–1474.\n45. J. Thomas et al. , Automated adult epilepsy diagnos-\ntic tool based on interictal scalp electroencephalo-\ngram characteristics: A six-center study,Int. J. Neu-\nral Syst. (2021) 2050074.\n46. P. Thangavel et al. , Time-frequency decomposi-\ntion of scalp electroencephalograms improves deep\n2350012-16\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n\nFebruary 25, 2023 11:1 2350012\nSix-Center Assessment of Seizure Detection in EEG\nlearning-based epilepsy diagnosis, Int. J. Neural\nSyst. (2021) 2150032.\n47. W. Y. Peh et al. , Multi-center validation study of\nautomated classiﬁcation of pathological slowing in\nadult scalp electroencephalograms via frequency fea-\ntures, Int. J. Neural Syst. (2021) 2150016.\n48. T. Joo, U. Chung and M.-G. Seo, Being bayesian\nabout categorical probability, in Proc. 37th Int.\nConf. Machine Learning (Virtual, 2020), pp. 4950–\n4961.\n49. W. Y. Peh, Y. Yao and J. Dauwels, Transformer\nconvolutional neural networks for automated artifact\ndetection in scalp EEG, in 2022 44th Annual Int.\nConf. IEEE Engineering in Medicine and Biology\nSociety (EMBC ) (IEEE, 2022), pp. 3599–3602.\n50. C.-S. Ouyang, R.-C. Yang, R.-C. Wu, C.-T. Chiang\nand L.-C. Lin, Determination of antiepileptic drugs\nwithdrawal through EEG hjorth parameter analysis,\nInt. J. Neural Syst. 30(11) (2020) 2050036.\n51. P. Afra, C. C. Jouny and G. K. Bergey, Duration of\ncomplex partial seizures: An intracranial EEG study,\nEpilepsia 49(4) (2008) 677–684.\n52. M. J. Cook et al. , Prediction of seizure likelihood\nwith a long-term, implanted seizure advisory system\nin patients with drug-resistant epilepsy: A ﬁrst-in-\nman study, Lancet Neurol. 12(6) (2013) 563–571.\n53. A. O’Shea, G. Lightbody, G. Boylan and A. Temko,\nNeonatal seizure detection from raw multi-channel\nEEG using a fully convolutional architecture,Neural\nNetw. 123 (2020) 12–25.\n54. B. H. Brinkmann et al. , Crowdsourcing reproducible\nseizure forecasting in human and canine epilepsy,\nBrain 139(6) (2016) 1713–1722.\n55. A. Sierra-Marcos, M. L. Scheuer and A. O. Rossetti,\nSeizure detection with automated EEG analysis: A\nvalidation study focusing on periodic patterns,Clin.\nNeurophysiol. 126(3) (2015) 456–462.\n56. N. Rommens, E. Geertsema, L. J. Holleboom, F. Cox\nand G. Visser, Improving staﬀ response to seizures\non the epilepsy monitoring unit with online EEG\nseizure detection algorithms, Epilepsy Behav. 84\n(2018) 99–104.\n57. U. Asif, S. Roy, J. Tang and S. Harrer, Seizurenet:\nMulti-spectral deep feature learning for seizure\ntype classiﬁcation, M a c h .L e a r n .C l i n .N e u r o i m a g -\ning Radiogenomics Neurooncology (2020) 77–87.\n5 8 . M .Z h o u ,C .T i a n ,R .C a o ,B .W a n g ,Y .N i u ,T .H u ,\nH. Guo and J. Xiang, Epileptic seizure detection\nbased on EEG signals and CNN, Front. Neuroin-\nform. 12 (2018) 95.\n2350012-17\nInt. J. Neur. Syst. 2023.33. Downloaded from www.worldscientific.com\nby DELFT UNIVERSITY OF TECHNOLOGY on 03/14/23. Re-use and distribution is strictly not permitted, except for Open Access articles.\n",
  "topic": "Electroencephalography",
  "concepts": [
    {
      "name": "Electroencephalography",
      "score": 0.8244873285293579
    },
    {
      "name": "Computer science",
      "score": 0.5925678014755249
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.5183330774307251
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5085188150405884
    },
    {
      "name": "Convolutional neural network",
      "score": 0.4944581985473633
    },
    {
      "name": "Scalp",
      "score": 0.4915202558040619
    },
    {
      "name": "Epilepsy",
      "score": 0.4124765396118164
    },
    {
      "name": "Psychology",
      "score": 0.29907578229904175
    },
    {
      "name": "Medicine",
      "score": 0.2681155204772949
    },
    {
      "name": "Neuroscience",
      "score": 0.2604084014892578
    },
    {
      "name": "Anatomy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I172675005",
      "name": "Nanyang Technological University",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I99464096",
      "name": "KU Leuven",
      "country": "BE"
    },
    {
      "id": "https://openalex.org/I5023651",
      "name": "McGill University",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I1292859797",
      "name": "Montreal Neurological Institute and Hospital",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I4210131313",
      "name": "National Neuroscience Institute",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I98358874",
      "name": "Delft University of Technology",
      "country": "NL"
    }
  ]
}