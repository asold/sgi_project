{
  "title": "How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench",
  "url": "https://openalex.org/W4389518992",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2157516767",
      "name": "Qinyuan Ye",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Harvey Fu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2108009659",
      "name": "Xiang Ren",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2476502706",
      "name": "Robin Jia",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4385573444",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W1840435438",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W3034776473",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W3199241049",
    "https://openalex.org/W2154061444",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4385571157",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W4281690148",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2295598076",
    "https://openalex.org/W3154806625",
    "https://openalex.org/W2943552823",
    "https://openalex.org/W4308049129",
    "https://openalex.org/W4386874839",
    "https://openalex.org/W3212496002"
  ],
  "abstract": "We investigate the predictability of large language model (LLM) capabilities: given records of past experiments using different model families, numbers of parameters, tasks, and numbers of in-context examples, can we accurately predict LLM performance on new experiment configurations? Answering this question has practical implications for LLM users (e.g., deciding which models to try), developers (e.g., prioritizing evaluation on representative tasks), and the research community (e.g., identifying hard-to-predict capabilities that warrant further investigation). We study the performance prediction problem on experiment records from BIG-bench. On a random train-test split, an MLP-based predictor achieves an R2 score greater than 95%, indicating the presence of learnable patterns within the experiment records. We then formulate the problem of searching for “small-bench,” an informative subset of BIG-bench tasks from which the performance on the full set can be maximally recovered. We find a subset as informative as BIG-bench Hard for evaluating new model families, while being 3× smaller. Additionally, we find competitive subsets by clustering task representations learned by our MLP-based predictor and selecting tasks close to cluster centroids, highlighting the importance of task diversity in constructing “small-bench.”",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 7493–7517\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nHow Predictable Are Large Language Model Capabilities?\nA Case Study on BIG-bench\nQinyuan Ye Harvey Yiyun Fu Xiang Ren Robin Jia\nUniversity of Southern California, Los Angeles, CA, USA\n{qinyuany, harveyfu, xiangren, robinjia}@usc.edu\nAbstract\nWe investigate the predictability of large lan-\nguage model (LLM) capabilities: given records\nof past experiments using different model fam-\nilies, numbers of parameters, tasks, and num-\nbers of in-context examples, can we accurately\npredict LLM performance on new experiment\nconfigurations? Answering this question has\npractical implications for LLM users (e.g., de-\nciding which models to try), developers (e.g.,\nprioritizing evaluation on representative tasks),\nand the research community (e.g., identifying\nhard-to-predict capabilities that warrant further\ninvestigation).\nWe study the performance prediction problem\non experiment records from BIG-bench. On\na random train-test split, an MLP-based pre-\ndictor achieves an R2 score greater than 95%,\nindicating the presence of learnable patterns\nwithin the experiment records. We then formu-\nlate the problem of searching for “small-bench,”\nan informative subset of BIG-bench tasks from\nwhich the performance on the full set can be\nmaximally recovered. We find a subset as infor-\nmative as BIG-bench Hard for evaluating new\nmodel families, while being 3×smaller. Addi-\ntionally, we find competitive subsets by cluster-\ning task representations learned by our MLP-\nbased predictor and selecting tasks close to clus-\nter centroids, highlighting the importance of\ntask diversity in constructing “small-bench.”1\n1 Introduction\nLarge language models (LLMs) have revolution-\nized natural language processing (NLP) research.\nTypically, when researchers introduce a new set of\nLLMs, they release them in various sizes and con-\nduct extensive evaluation on different tasks, while\nalso considering different experiment configura-\ntions, such as prompting strategies and the number\nof in-context examples (Black et al., 2021; Zhang\n1Code can be found at https://github.com/INK-USC/\npredicting-big-bench.\nModel Family # param Task # shot\nPerf.\n?\nelementary_math\ncode_line_desc\nstrategy_qa\n3\n2\n0\nGPT-3\n3B\n0.48\nBIG-G \nT=1\n8B\n0.19\nPaLM\n64B\n0.23\nGPT-3\nelementary_math\n6B\n1\nHow \npredictable\n \nare \nLLM \ncapabilities?\nTrain\nBIG-G \nT=1\nPaLM\nGPT-3\nNew \nModel\nTest\nTask \n87\nTask \n6\n....................\nHow \nto \nevaluate \nnew \nmodels \nwithin \nbudget \nconstraints\n?\nTask 214\nTask \n32\nBIG-bench\n\"small-bench\"\nTask \n127\nFigure 1: Overview. We study the problem of (1) pre-\ndicting LLM performance on new experiment configu-\nrations; (2) searching for a subset of tasks which is most\ninformative for predicting performance on remaining\ntasks when evaluating a new model family.\net al., 2022; Touvron et al., 2023). Given the com-\nbinatorially large space of possible experimental\nconfigurations, running all possible experiments\nfor a new set of LLMs is impractical. This begets\na critical question: to what extent can we predict\nthe capabilities of an LLM in a given experimental\nsetting?\nStudying this problem helps address various\npractical issues. For LLM users, a performance\nprediction model could offer guidance for exper-\niment design and decision-making by answering\nquestions such as, “What model scale and how\nmany shots are necessary to attain satisfactory per-\nformance for my task?” For LLM developers and\nthe research community, a performance prediction\nmodel could lead to insights into LLM capabili-\nties by identifying which capabilities are hard-to-\npredict and require further investigation, and which\ncapabilities are highly correlated and may be depri-\noritized during evaluation to save budget.\n7493\nWe investigate the predictability of LLM capa-\nbilities on the BIG-bench (Srivastava et al., 2023)\nevaluation suite, as it includes a vast collection of\nexperiment records. BIG-bench is a collaborative\ninitiative aimed at “prob[ing] large language mod-\nels and extrapolat[ing] their future capabilities.” It\nhas extensively evaluated various state-of-the-art\nLLMs on a diverse set of tasks contributed by the\ncommunity. We gather and carefully filter these\nrecords, yielding a total of 56k+ records which we\nuse as the “dataset” for our analysis.\nWe first formulate the problem of performance\nprediction given experiment configurations such as\nmodel family, model scale, task, and the number\nof in-context examples used. We compare various\nmatrix completion, tree-based, and neural network\nmethods in a random train-test split scenario (§3).\nFurther, we design and experiment with various\ndata splits, representing different types of general-\nization challenges, to simulate practical situations\nresearchers may face (§4).\nWe then consider the problem of searching for\n“small-bench,” a compact and informative subset of\nBIG-bench. This subset should allow for maximum\nrecovery of performance on the complete BIG-\nbench, enabling efficient evaluation of new LLMs\nwhile maintaining evaluation generality. We formu-\nlate this as a subset search problem (§5) and empir-\nically compare various search methods, clustering-\nbased subset construction methods, along with\nwidely-adopted subsets such as BIG-bench Lite\nand BIG-bench Hard (Suzgun et al., 2023).\nOur key findings are summarized as follow:\n1. LLMs’ performance on BIG-bench follows pre-\ndictable patterns. In the default random train-test\nsplit scenario, our best predictor, an MLP model,\nachieves an RMSE lower than 0.05 (i.e., on av-\nerage mis-predict by <0.05 when the range is\n[0,1]) and an R2 greater than 95% (i.e., explains\nmore than 95% variance in the target variable).\n2. The predictor’s performance is dependent on the\nassumptions of the train-test distribution. In a\nmore challenging setting where we hold out the\nCartesian product of complete model families\n(all model scales) and complete tasks (all num-\nbers of shots), the predictor’s performance de-\ncreases (R2 : 95% →86%).\n3. Performance of emergent tasks (Wei et al.,\n2022a) is not entirely unpredictable. In gen-\neral, performance of emergent tasks is harder\nto predict than that of non-emergent tasks. In\nspecific scenarios (e.g., when a related emergent\ntask is present in the training set) our model can\naccurately predict emergent abilities.\n4. BIG-bench Lite and BIG-bench Hard (Suzgun\net al., 2023), two subsets of BIG-bench com-\nmonly used for evaluating new models, are sub-\noptimal if the goal is to recover the performance\non remaining tasks. We are able to find a subset\nthat is as informative as BIG-bench Hard while\nbeing 3×smaller by using randomized search.\n5. Task diversity and task value are critical factors\nin constructing “small-bench.” By clustering\ntask representations learned by the MLP-based\npredictor and selecting tasks close to cluster cen-\ntroids, we obtain competitive “small-bench” can-\ndidates. This strategy is further improved by\nincorporating task value information.\n2 Related Work\nScaling Laws and Emergent Abilities. Pre-\ntraining scale is critical to language model capa-\nbilities. Research on scaling laws (Kaplan et al.,\n2020; Rae et al., 2021; Hoffmann et al., 2022) aims\nto categorize the relationship between pre-training\ncompute, corpus size, model size and the test log-\nlikelihood loss. Our work can be loosely consid-\nered as an extension to scaling laws, with three\nnotable distinctions: (1) we focus on predicting\ndownstream task performance; (2) we use model\nscale along with other experiment configuration in-\nformation; (3) we mainly experiment with machine\nlearning methods instead of explicit power laws. In\nthis same vein, recent work has studied the effect\nof scale in a “pre-train then fine-tune” paradigm\n(Tay et al., 2022) and has explored non-monotonic\nscaling laws for complex scaling behaviors (Ca-\nballero et al., 2023). Another important observa-\ntion about scale is that very large language models\nexhibit emergent abilities (Wei et al., 2022a), which\nare described as “unpredictable.” In this work we\nempirically examine this claim and quantify the\nprediction errors under various assumptions.\nBenchmarking for LLMs. Along with the de-\nvelopment and scaling of LLMs, there are contin-\nuing efforts to create benchmarks that assess the\ncapabilities of these models. One general trend for\nthese benchmarks is transitioning from single-task\n(Bowman et al., 2015; Rajpurkar et al., 2016), to\nmulti-task (Wang et al., 2018, 2019), and finally\nto massively multi-task (Hendrycks et al., 2021;\nSrivastava et al., 2023). However, due to budget or\n7494\nAPI constraints, models are typically evaluated on\nonly a subset of the full range of available bench-\nmarks. The selection is often made arbitrarily by\nthe models’ developers, making it challenging to\ncompare models in a fair and holistic way (see\nLiang et al. 2023, Fig. 4). In response to this issue,\nwe study the “small-bench” problem and hope it\noffers insights on efficient benchmarking of LLMs.\nPerformance Prediction. NLP ERF (Xia et al.,\n2020) is a pilot work on performance prediction\nin NLP, focusing on bilingual and cross-lingual\ntasks. It demonstrates the potential of selecting an\ninformative subset of tasks for evaluation, which\ninspired our work on searching for “small-bench.”\nYe et al. (2021) extend NLP ERF to account for\nfine-grained performance measures, confidence in-\ntervals and calibration. Zhu et al. (2022) study pre-\ndicting a model’s downstream performance (GLUE,\nWang et al. 2018) using probing tasks performance\n(SentEval, Conneau and Kiela 2018), and advocate\nfor incorporating probing during pre-training. Our\nwork aims to add to the discussion by focusing on\nthe performance prediction of LLMs. Given the\nongoing advancements and substantial influence of\nLLMs in the field of NLP, we believe this topic is\nboth timely and relevant, potentially holding impli-\ncations for future development of LLMs.\n3 Performance Prediction on BIG-bench\n3.1 Problem Definition\nIn this section, we focus on the problem of learning\nfrom experiment records of large language models,\nand predict the performance of an unseen combina-\ntion of experiment settings.\nNotations. We use Lto denote the model fami-\nlies in consideration (e.g., PaLM, GPT-3). We use\nT to denote the diverse collection of tasks in con-\nsideration (e.g., 2-digit subtraction, emoji_movie).\nFormally, an experiment record is defined by the\nfollowing values:\n• Model family l∈L\n• Number of model parameters 2 nparam ∈N\n• Task being evaluated on t∈T\n• Number of in-context examples nshot ∈N\n2Here we use nparam as the general representation of\nmodel scale. It is important to acknowledge a limitation:\nnparam does not provide a comprehensive description of\nmodel scale. Pre-training compute and corpus size should\nbe included should such information be available.\n• Normalized performance 3 y∈[0,1]\nOur goal is to learn a regression model f that pre-\ndicts ˆybased on (l,nparam,t,n shot).\nData Splits. We obtain a large set of experiment\nrecords D = {(l,nparam,t,n shot,y)}and split\nthem into three non-overlapping subsets, Dtrain,\nDdev, Dtest. By default, we use random splitting\nand adopt 10-fold cross validation.4 In subsequent\nsections of this paper, we also use other splitting\nstrategies for controlled analysis (§3.4 and §4).\nEvaluation. We report root mean square error\n(RMSE) and coefficient of determination score\n(R2) on the test set Dtest. RMSE is defined as√\n1\nn\n∑n\ni=1(ˆy−y)2. R2 score characterizes the\nproportion of variance explained by the model, i.e.,\nR2 = Explained Variance\nTotal Variance = 1 −\n∑n\ni=1(ˆy−y)2\n∑n\ni=1(¯y−y)2\nwhere ¯y= 1\nn\nn∑\ni=1\ny\nIn the main paper, we focus on RMSE and R2\nscores as they are widely accepted evaluation met-\nrics for regression problems. In Appendix C.1 we\nintroduce two alternative metrics based on rank\ncorrelation and discuss our findings.\n3.2 Data\nWe construct our dataset D from the BIG-bench\nrepository.5 We design a series of filtering crite-\nria (e.g., excluding tasks where all models have\n0 accuracy, excluding tasks with <100 examples),\nwhich are detailed in Appendix A. After filtering,\nour dataset has 56,143 experiment records. We list\nhigh-level statistics about this dataset in Table 1.\nWe would like to highlight that this dataset cov-\ners diverse tasks and models. According to Sri-\nvastava et al. (2023), tasks in BIG-bench cover\n“problems from linguistics, childhood development,\nmath, common-sense reasoning, biology, physics,\nsocial bias, software development, and beyond.”\nWe refer the readers to Fig. 3 and Table App. 3\nin Srivastava et al. (2023) for an overview. We\nalso made our best effort to incorporate all avail-\nable model families in BIG-bench. The six model\n3For tasks metrics in a different range, e.g., [0, 100], we\nnormalize the score to be in [0, 1] for consistency.\n4More specifically, we first split D into 10 disjoint subsets,\nand then rotate on which ones are Ddev and Dtest.\n5https://github.com/google/BIG-bench/\n7495\n# Experiment Records 56,143\n# Model Families 6\nBIG-G T=0, BIG-G T=1,\nBIG-G Sparse, PaLM\nGPT-3, Gopher\n# Models† 51\n# BIG-bench Tasks 134\n# BIG-bench Subtasks‡ 313\n{nshot} { 0,1,2,3,5}\nTable 1: Statistics of BIG-bench experiment records\nafter filtering. †“Model” is defined by model family\nl and nparam, e.g., PaLM 535B. ‡The 313 subtasks\nfall into the 134 tasks. For simplicity we disregard the\ntask-subtask hierarchy in this study. In the remaining of\nthis paper, “tasks” refers to BIG-bench subtasks.\nfamilies included are representative, and offer con-\nsiderable diversity. We provide a brief summary of\nthese model families (release date, company, model\narchitecture choices, etc.) in Table 2.\n3.3 Compared Models\nMatrix Completion. Our problem is analogous\nto recommender systems or 2D matrix completion,\nif “models” (described by land nparam) are con-\nsidered as “users,” and “n-shot tasks” (described\nby t and nshot) are considered as “items.” Each\nn-shot task (item i) is “rated” by each model (user\nu). With such adaptation, we consider the follow-\ning matrix completion methods: (a) Model + Task\nBaseline: ˆy= µ+bu +bi, where µis the global av-\nerage performance, bu represents the effect brought\nby user u, and bi represents the effect brought by\nitem i. These parameters are learned by minimiz-\ning mean square error on Dtrain. (b) Adapted\nSVD: ˆy = µ+ bu + bi + q⊤\nu pi. Compared to (a),\nan additional vector qu is learned for each user u,\nand pi for each item i. The term q⊤\nu pi is expected\nto model the interaction between user uand item i.\n(c) Model-model kNN: First find the top kmodels\nmost similar to u, then aggregate the performance\nof these k models on item i by using weighted\naveraging. (d) Task-task kNN: similar to model-\nmodel kNN, but finds similar tasks and aggregate\nperformance on these tasks instead.\nTrees. We use two common tree-based methods\nthat can directly learn to make predictions ˆyfrom\nthe input (l,nparam,t,n shot): (e) Random Forest\n(Breiman, 2001) and (f) Gradient Boosted Trees\n(Friedman, 2001; Chen and Guestrin, 2016).\n0.6 0.7 0.8 0.9\nTest R2\nModel+T ask Baseline\nAdapted SVD\nModel-model kNN\nT ask-task kNN\nRandom Forest\nGradient Boosted Trees\nMLP\n0.7068\n0.8082\n0.8999\n0.9048\n0.9397\n0.9510\n0.9508\nMatrix Completion Trees Neural Networks\nFigure 2: Model Comparison for Performance Predic-\ntion using Default Data Split. Gradient boosted trees\nand MLP achieve strong performance (RMSE <0.05\nand R2 >0.95).\nNeural Networks. We train simple (g) multi-\nlayer perceptron (MLP) models to predict ˆyfrom\nthe input (l,nparam,t,n shot). Hyperparameters\nsuch as number of layers and hidden dimensions\nare determined based on Ddev performance.\nFeaturization and Hyperparameters. Featur-\nization for trees and MLPs are explained in Ap-\npendix B. Hyperparameters and training details of\nthese methods are discussed in Appendix D.1.\n3.4 Results and Analysis\nTrees and MLPs achieve strong performance.\nWe experiment with the prediction models men-\ntioned above and present their performance in\nFig. 2. (1) Tree-based methods and MLP outper-\nforms matrix completion methods by a large mar-\ngin. We hypothesize that the 2D user-item simplifi-\ncation may cause loss of information on the input\nspace. For example, the value of nparam is merely\nused to distinguish different “users,” and does not\ncontribute to the computation of ˆy directly. (2)\nGradient boosted trees and MLP are the strongest\namong all compared models; both achieving RMSE\n<0.05 (i.e., on average mis-predict by<0.05) and\nR2 > 0.95 (i.e., more than 95% of variance in y\nis explained). This suggests that learnable patterns\nexist in LLM experiment records—LLM perfor-\nmance on unseen configurations can be predicted\nto a considerable extent in the current setting.\nPerformance varies on different test groups\n(Fig. 3 ). To have a more fine-grained under-\nstanding of the predictions, we group Dtest ex-\namples according to the features such as nshot,\nnparam, and model family l, and then compute\n7496\nR2 on each of these test groups.6 We use the MLP\nmodel predictions and present the results in Fig. 3\nusing dark blue bars ( ). In terms of nshot, we\nfind that it is harder to predict zero-shot perfor-\nmance than 2- or 3-shot performance. In terms of\nthe model family l, we believe the three BIG-G\nmodels (T=0, T=1, sparse) are easier to predict be-\ncause their pre-training pipelines are similar. For\nnparam, we group all models into four buckets. For\nexample, bucket 1 contains the smallest 25% mod-\nels. We observe a trend that performance of larger\nmodels are harder to predict.\nWe also group Dtest according to whether the\ntask tis an emergent task (see Appendix E in Wei\net al. 2022a). Our predictor achieves an R2 score\nof 0.94 on the emergent group and 0.95 on the non-\nemergent group. This suggests in general emergent\nabilities are indeed harder to predict.\nMulti-group training is helpful (Fig. 3, / ↔ ).\nWe further conduct a set of controlled experiments\nby only training on examples from the test group\nof interest ( e.g., examples with nshot = 0 ). We\nname them as single-group experiments ( / ), as\nopposed to multi-group experiments ( ) done in\nprevious sections where the predictor is trained on\nall groups. Notably, in all settings, multi-group R2\nis always larger than single-group R2. There are\nlimited observations of Gopher models in the train-\ning set, and they benefit from multi-group learning\nsignificantly (R2 increases from 0.74 to 0.87). This\nreaffirms the claim that LLM performance exhibits\nshared patterns across various settings.\nSome groups benefit more from multi-group\ntraining, some are intrinsically harder to predict.\n(Fig. 3, ↔ / ↔ ) Our controlled experi-\nments also allow us to distinguish between two fac-\ntors: the group is intrinsically harder to predict or\nthe group benefits more from multi-group learning.\nIn Fig. 3(a), results suggest that nshot = 0 group\nis not necessarily harder to predict than nshot = 2\nand nshot = 3 on its own (indicated by / bars),\nbut the latter two benefit more from multi-group\nlearning. Typically, when evaluating LLMs on a\ntask, there is a huge performance boost when going\nfrom zero-shot to one-shot, and the performance\nimproves more stably when more shots become\navailable. It is easier to predict 3-shot performance\nwhen given 0,1,2-shot performance, than to predict\n6Note that the denominator in R2, total variance, will be\ndifferent for each group.\n0.6 0.7 0.8 0.9 1.0\n3\n2\n1\n0\n(a) Group by nshot\nTrained on ...\nSingle-group (1000 Examples)\nSingle-group (All Examples)\nMulti-group (All Examples)\n0.6 0.7 0.8 0.9 1.0\nPaLM\nGopher\nGPT-3\nBIG-G sparse\nBIG-G T=1\nBIG-G T=0\n(b) Group by Model Family l\n0.6 0.7 0.8 0.9 1.0\nTest R2 in Each Group\nBucket 4\nBucket 3\nBucket 2\nBucket 1\n(Largest)\n(Smallest)\n(c) Group by nparam (4 Buckets)\nFigure 3: R2 Score when Grouped with nshot, l, and\nnparam. Example: Multi-group nshot = 0 means\ntraining on the complete Dtrain (containing all nshot\nvalues) and evaluate onnshot = 0 examples in Dtest.\nSingle-group (1000 Examples) nshot = 0 means using\n1000 nshot = 0 examples in Dtrain as the training data.\n0-shot performance when given 1,2,3-shot perfor-\nmance. This partly explains why the 0-shot group\ndoes not benefit much from multi-group training.\nIn Fig. 3(b), BIG-G T=0 and BIG-G T=1 benefit\nfrom multi-group learning more than the GPT-3\nmodel family, resulting in higher R2 scores in the\nmulti-group setting. In Fig. 3(c), we observe that\nlarger models tend to be intrinsically more challeng-\ning to predict. This observation is more significant\nwhen the single-group training set size is controlled\nto be 1000 (represented by bars), where we ob-\nserve a clear trend that groups consisting of larger\nmodels achieve lower R2 score.\nIdentifying most/least “predictable” tasks. We\nfurther experiment with grouping test examples ac-\n7497\n0.7 0.8 0.9 1.0\nma:three_digit_subtraction_control\nqa_wikidata\nlm:sentence_negation_json\nma:two_digit_multiplication_control\nma:three_digit_addition_control\n0.9785\n0.9802\n0.9805\n0.9818\n0.9885\n5 Tasks with Highest R2\n400\n 200\n 0\nauthorship_verification:swapped\nparagraph_segmentation\ngender_inclusive_sentences_german\ncheckmate_in_one\nlinguistics_puzzles\n-1.8346\n-5.9370\n-12.1233\n-38.2871\n-410.7146\n5 Tasks with Lowest R2\nFigure 4: 5 Most and Least “Predictable” Tasks\nBased on R2 Score. ma stands for “modi-\nfied_arithmetic”, lm stands for “linguistic_mapping”.\nFig. 9 and 10 illustrate their scaling behaviors.\ncording to the task tthey belong to, to identify the\nmost and least predictable tasks. The five most\npredictable tasks (Fig. 4 Top) include qa_wikidata\nand linguistic_mappings, which were tasks marked\nas having high linearity7 in their scaling behavior\n(Srivastava et al. 2023, Sec 3.4). This observation\nis reasonable because high linearity typically im-\nplies predictability. However, modified_arithmetic,\na task marked as having high breakthroughness\n(Srivastava et al., 2023) and emergence (Wei et al.,\n2022a), is considered highly predictable in our set-\nting. Our hypothesis is that the predictor is able\nto infer this by learning from experiment records\nwith similar configurations: If breakthroughness\nis observed with other models or other number of\nshots, the trained predictor is able to infer the trend\nfor a new experiment configuration. We believe it\nis still challenging to predict breakthroughness/e-\nmergence in more restricted setting, e.g., based on\ntask meta-data or input text alone.\nFor the five tasks with lowest R2 scores (Fig. 4\nBottom), we manually examined their scaling be-\nhavior (Fig. 10) and indeed find these curves to be\nsurprising. For future work, it will be interesting to\ninvestigate the underlying reasons, and to identify\ncommon characteristics shared among these tasks.\n4 Creating Challenging Train-Test Splits\nPreviously, we randomly split D into Dtrain,\nDdev, and Dtest, i.e., we randomly sampled\n7Linearity measures “the extent to which performance\nimproves reliably with scale;” Breakthroughness measures\n“the extent to which a model is able to learn a task only once\nthe model grows beyond a critical scale.” See Srivastava et al.\n(2023) Appendix B for the formal definition.\n0.6 0.7 0.8 0.9 1.0\nTest R2\nL3 Composition\ntest × test\nL3\n(l, t)\nL2.2\n(l, t, nshot)\nL2.1\n(l, nparam, t)\nL1\n(l, nparam, t, nshot)\nModel + T ask Baseline\nT ask-task kNN\nGradient Boosted Trees\nMLP\nFigure 5: Performance of Different Prediction Mod-\nels on Challenging Train-Test Splits. As the setting\nbecomes more challenging (L1 →L2 →L3 →L3 Com-\nposition), performance gradually drops and variance in-\ncreases. MLP is least sensitive to these changes.\n(l,nparam,t,n shot) combinations. This is a rela-\ntively easy setting; for example, when the model\nfamily l, number of parameters nparam, and task t\nare kept the same, it may be easy for a model to pre-\ndict performance of nshot = 2 when the records of\nnshot = 1 and nshot = 3 appear in Dtrain. A more\nchallenging data split would ensure that the com-\nbinations of (l,nparam,t) in the test set are com-\npletely unseen in Dtrain, and the model is required\nto predict for all possible nshot values. Taking it a\nstep further, one may want make predictions on an\nunseen configuration of (l,t) for all possible values\nof nparam and nshot.\n4.1 Train-Test Split Settings\nTo simulate these use cases, we design and com-\npare model performance on three additional set-\ntings (L2.1, L2.2, L3).\n• L1: Random (l,nparam,t,n shot), used in §3\n• L2.1: Group by (l,nparam,t)\n• L2.2: Group by (l,t,n shot)\n• L3: Group by (l,t)\nFor example, in L3, we first group all experiment\nrecords in Daccording to (l,t), then create Dtrain,\nDdev, and Dtest by random splitting the groups.\n7498\nAdditionally, we make L3 setting even more\nchallenging by holding out one entire subset of\nLtest ×Ttest. Specifically, we first select Ltest, a\nsubset of model families ⊆ L, and Ttest, a sub-\nset of tasks ⊆T . After this, Dtest is defined as\n{(l,nparam,t,n shot,y)|l∈Ltest,t ∈Ttest}. This\ncorresponds to a practical scenario where a new\nmodel family is developed, and researchers want\nto take a “sneak peek” at the full picture of its\ncapabilities—evaluate on a subset of tasks (i.e.,\nTtrain = T\\Ttest), and predict the model’s perfor-\nmance on the remaining tasks (i.e., Ttest). We refer\nto this as the “L3 Composition” setting.8\n4.2 Results and Analysis\nMain Results. Results on four representative\nmodels in these settings are visualized in Fig. 5.\nWe observe that as the settings becomes more chal-\nlenging (L1 →L2 →L3 →L3 Composition), per-\nformance gradually decreases and the standard de-\nviation increases. Another important observation\nis that though MLP and gradient boosted trees are\ncomparable in the L1 setting, MLPs are less sen-\nsitive to the increased difficulty (performance de-\ncrease is smaller and standard deviation is smaller).\nSample Prediction Results in L3. In Fig. 7 we\nvisualize predictions on four sample (l,t) combi-\nnations by the MLP model—two achieving high\nR2 scores and two achieving low R2 scores. We\nhave two high-level observations: (1) Predictions\nare more accurate on (l,t) combinations which has\nobservations on similar tasks t′or similar models\nfamilies l′in Dtrain. (2) Over-estimation is a com-\nmon type of mistake made by our trained prediction\nmodels. We observe several cases of “false posi-\ntives” of emergent abilities. Due to space limit, we\ndefer more discussion in §C.2.\n5 Searching for “small-bench”\nThere has been a recent emphasis on assessing\nthe generality of large language models, which in-\nvolves evaluating these models on numerous tasks\nand scenarios. However, it will be extremely ex-\npensive to conduct all these experiments every time\na new model is developed in the future. Extend-\ning from the holding out Ltest ×Ttest setting in\n§4.1, in this section, we formulate and study the\nproblem of searching for “small-bench:” Can we\nfind a subset of BIG-bench tasks, such that when\n8In §D.2, we describe our efforts to ensure that the perfor-\nmance is as comparable as possible across settings.\na new model family is evaluated on it, the per-\nformance of the remaining tasks can be maximally\nrecovered? In the following we give a formal defini-\ntion of this problem (§5.1), construct “small-bench”\ncandidates using different search algorithms and\nstrategies (§5.2), and present our findings (§5.3).\n5.1 Problem Definition\nOur goal is to find Ttrain, a subset of all tasks T,\nthat are selected and used for evaluating new model\nfamilies Ltest. We use bto represent the evaluation\nbudget, i.e., |Ttrain|= b. We use Ttest = T\\Ttrain\nto denote the tasks whose performance we wish to\nrecover. The problem of finding the optimal T(b)∗\ntrain\ncan be formulated as the following:\narg max\nTtrain\nR2(Ttest ×Ltest)\ns.t. Ttrain ⊆T , |Ttrain|= b\nR2(Ttest×Ltest) represents the R2 score on Ttest×\nLtest when a predictor is trained on the remaining\nexperiment records, as previously done in §4.\nEvaluation. Ideally the optimal Ttrain should al-\nlow us to predict the performance ofany new model\nfamily, without overfitting to a specific held-out\nmodel family. To evaluate this, we adopt nested\ncross-validation on Lduring evaluation of a se-\nlected Ttrain. Specifically, given that |L|= 6, we\ncreate 6 ×5 = 30 different ways to hold out one\nmodel family as Ldev and one model family as\nLtest. We then train 30 prediction models and re-\nport the average of 30 R2(Ttest ×Ltest) scores.\n5.2 Compared Methods\nWe consider different evaluation budget b ∈\n{4,8,16,24,32,42}. We compare the following\nmethods for selecting Ttrain.\nBaselines. (a) BIG-bench Lite (Srivastava et al.,\n2023): A subset of BIG-bench for cheaper evalu-\nation, proposed in the original BIG-bench paper.\n|Ttrain|= 42 for BIG-bench Lite.9 (b) BIG-bench\nHard (Suzgun et al., 2023): A subset of BIG-\nbench containing challenging tasks that cannot be\nsolved with direct in-context learning but can be\nimproved with chain-of-thought prompting (Wei\net al., 2022b). |Ttrain|= 24 for BIG-bench Hard.\n(c) Random: For each b, randomly sample 5 Ttrain\n9Tasks in BIG-bench Lite/Hard are listed in Appendix G.\nTo the best of our knowledge, the selection process for BIG-\nbench Lite is not disclosed.\n7499\nsuch that |Ttrain|= b. We report the mean and\nstandard deviation of these 5 runs.\nSearch Algorithms. (d) Greedy Search : Based\non the search result T(b−1)\ntrain at budget b−1, enumer-\nate all tasks not present in T(b−1)\ntrain , and select the\none task that achieves the highestR2(T(b)\ntest ×Ltest)\nto form the T(b)\ntrain at budget b. (e) Best of 5000 :\nFor each b, randomly select 5000 Ttrain and select\nthe one achieving the highest R2(Ldev ×Ttest).\nNote that these search algorithms optimize\nR2(Ttest ×Ldev) during search, to ensure that\nTtest ×Ltest is held-out for evaluation. Addition-\nally, to make the search computationally tractable,\nwe only use 1 fixed fold from the 30 folds during\nsearch. We discuss the impact of these experimen-\ntal decisions in Appendix C.5.\nClustering-based. We hypothesize that a good\n“small-bench” should be diverse (covering the task\nspace comprehensively while avoiding redundancy\nby excluding similar tasks) and representative\n(each selected task providing informative insights\nfor recovering the performance of other tasks). To\nvalidate this, we use the following methods to con-\nstruct Ttrain. (f) k-means: We extract the task\nrepresentations10 learned by our MLP models in\n§3. We apply k-means clustering to these represen-\ntations, group them into bclusters, and then select\nthe task closest to the centroid of the each cluster.\n(g) k-means + Task Value:We first calculate the\ntask value for each task in T by aggregating their\ncontributions from the Best of 5000 search history.\nFor example, if a task is present in 20 trials out of\nthe 5000, its task value will be the average of the\nR2 scores from those 20 trials. We then incorporate\nthis information into k-means clustering, by select-\ning the task closest to the centroid among tasks that\nare top 25% valuable globally.\n5.3 Results and Discussion\nWe visualize the results of all compared methods\nin Fig. 6. We have the following key observations.\nBIG-bench Hard and Lite are sub-optimal for\nrecovering performance on remaining tasks. A\n8-task subset found by Best of 5000 and randomly-\nsampled 16-task subsets can match the 24-task BIG-\nbench Hard for this goal. We further examine the re-\n10The task t is represented as an one-hot feature in the input\nspace. Thus, for each task, there is a vector corresponding to\neach task in the first layer of the MLP. We refer to these as\n“task representations.”\n4 8 16 24 32 42\nSize of train\n0.60\n0.65\n0.70\n0.75\n0.80\n0.8530-Fold R2( test × test)\nBB-Lite\nBB-Hard\nBaselines\nRandom\nSearch Algorithms\nGreedy Search\nBest of 5000\nClustering-based\nK-means\nK-means + T ask Value\nFigure 6: “Small-bench” Search Results. X-axis: size\nof “small-bench” (Ttrain), i.e., number of tasks selected\nfor evaluating a new model family. Y-axis: R2 score\non recovering performance of remaining tasks. The\ncomplete BIG-bench will be at (313,1.0) in this fig-\nure. Takeaways: (1) BIG-bench Lite and Hard are\nsub-optimal for recovering performance on remaining\ntasks; (2) Task diversity and task value are important for\nconstructing effective “small-bench” candidates.\nsults and find several cases where BIG-bench Hard\nfails to represent the complete BIG-bench. For ex-\nample, according to full BIG-bench performance\nrecovered from BIG-bench Hard, BIG-G T=1 2B\nis better than GPT-3 Large; however, according to\nthe ground-truth BIG-bench performance, GPT-3\nLarge is better than BIG-G T=1 2B, which is cap-\ntured more accurately when a 24-task small-bench\ncandidate is used. See Table 3 for the details.\nIt is important to note that BIG-bench Hard was\nnot specifically designed for our goal, and thus\nis not expected to be competitive in our problem.\nYet it is surprising that it underperforms randomly-\nsampled subsets. As a general recommendation for\nevaluating newly-developed models, we suggest\nusing the Ttrain subsets found by solving the op-\ntimization problem in §5.1. If there is a specific\nevaluation goal in mind (e.g., focus on frontier, as\nin the case of BIG-bench Hard), Ttrain should still\nbe manually selected.\nGreedy search is unstable and finds sub-optimal\nsolutions. Search algorithms consistently out-\nperforms randomly sampled Ttrain sets; however,\ngreedy search appears to be unstable, with occa-\nsional performance drops as the budget increases.\nFurthermore, at b= 42, it underperforms the Best\nof 5000 approach. We include additional results\non other search algorithms, including beam search\n7500\nand simulated annealing, in §C.4, where we ob-\nserve similar instablitiy. One possible explanation\nis the complexity of the search space, where the\ngreedy search algorithm cannot guarantee finding\nthe optimal solution. The gaps between the search\nobjective (Ldev ×Ttest in one fold) and the evalua-\ntion objective (Ltest ×Ttest in 30 folds) could also\ncontribute to this issue (§C.5).\nTask diversity and task value are important fac-\ntors for constructing “small-bench.” Firstly, k-\nmeans is comparable to or surpasses Best of 5000,\ndespite that it is not explicitly optimized for the R2\nobjective. This supports the notion that diversity is\nan important factor in constructing “small-bench.”\nThis finding also suggests that the MLP models\nfor performance prediction produce meaningful\ntask representations as a side product. Secondly,\nk-means + Task Value is comparable to or out-\nperforms k-means, confirming that task value is\nanother important factor for constructing “small-\nbench,” complementing the diversity aspect.\n6 Conclusion and Future Work\nIn this work, we began with the question, “How\npredictable are large language model capabilities?”\nand conducted a detailed case study on BIG-bench.\nWe first formulated the machine learning prob-\nlem of predicting performance given configurations\nsuch as model family, the number of parameters,\ntask, and the number of in-context learning exam-\nples. Our strongest prediction model achieves an\nR2 score greater than 95%, which suggests past\nLLM experiment observations can be used to pre-\ndict the performance of new experiment configura-\ntions. To address the problem of increasing evalua-\ntion cost on massively multi-task benchmarks, we\nintroduced the problem of searching for an infor-\nmative “small-bench.” Results suggest that popular\nsubsets such as BIG-bench Lite and BIG-bench\nHard are not optimal for this purpose. Instead, sub-\nsets characterized by diversity and high task values\noffer competitive “small-bench” candidates, high-\nlighting the importance of these two factors.\nIn closing, while our study primarily focused on\nthe predictability of LLM capabilities, we hope to\ninitiate discussions on the following broader topics.\nRethinking LLM Evaluation. Currently, there\nis a lack of consensus regarding evaluation prac-\ntices for newly developed LLMs. Often times new\nLLMs are evaluated on different set of selected\ntasks, making it hard to compare different models\nand quantify the progress in LLM development.\nMoreover, task selection is often heuristic, follow-\ning past practices, or chosen arbitrarily without\nprincipled justifications. We anticipate more active\ndiscussion on establishing evaluation practices that\nassess LLM capabilities efficiently, reliably and\nrigorously, and we hope our work provides use-\nful insights towards this. Related to our efforts on\nsearching for “small-bench,” Perlitz et al. (2023)\ninvestigate the impact of benchmarking options on\nthe trade-off between computational efficiency and\nreliability, and develop Flash-HELM, an efficient\nalternative to HELM (Liang et al., 2023). Vivek\net al. (2023) propose Anchor Point Selection to\nselect representative examples in the test set and\nreduce evaluation cost at the instance-level.\nBroadening observations on LLM capability\nlandscape. Complementary to BIG-bench, sev-\neral ongoing initiatives, such as HELM (Liang\net al., 2023), Open LLM Leaderboard 11, and\nEleuther AI LM Harness 12 are dedicated to sys-\ntematically evaluating existing LLMs. Integrating\ninsights from these great initiatives into future work\nhas the potential to enhance the accuracy of LLM\nperformance prediction and deepen our understand-\ning of LLM capabilities. Additionally, it would be\nintriguing to take into account recent advances such\nas chain-of-thought prompting (Wei et al., 2022b)\nand instruction tuning (Sanh et al., 2022; Ouyang\net al., 2022), and systematically measure their ef-\nfects on LLM capabilities.\nLimitations\nLimited to BIG-bench results. We choose BIG-\nbench for our study due to its extensive collection\nof experiment records. Though it offers consider-\nable diversity in terms of tasks and models, several\nlimitations exist. (1) Tasks: It’s important to note\nthat BIG-bench tasks are sourced from the research\ncommunity and may not accurately reflect the ac-\ntual distribution of tasks encountered by LLMs in\nreal-world scenarios. Therefore, our study has lim-\nitations in terms of generalizing our conclusions\nto the real-world task distribution. (2) Models:\nThough we have made every effort to incorporate\nas many model families as possible, there are only\n11https://huggingface.co/spaces/HuggingFaceH4/\nopen_llm_leaderboard\n12https://github.com/EleutherAI/\nlm-evaluation-harness\n7501\n6 model families in our experiment record dataset\nderived from BIG-bench. Such scarcity introduces\ninstability and increases the difficulty in investigat-\ning the “small-bench” problem.\nLimited to publicly-available LLM meta-data.\nLLMs capabilities are dependent on many factors,\nbeyond the model family land number of param-\neters nparam used in this study. Factors such as\npre-training stability, convergence, pre-train corpus\ncomposition, etc., all play important roles. How-\never, we often don’t have access to this information.\nIn this work, we assume that the input features\n(l,nparam) can capture such information during\ntraining implicitly. In the future, we believe our\nmethod can be expanded to include additional pre-\ntraining meta-data when they become available.\nLimited to interpolation settings. Our experi-\nments mainly concentrate on interpolation settings,\nwhere the combinations of (l,nparam,t,n shot) are\nnew in the test set, but each of the input element\nis seen at least once in the training set. As LLMs\ncontinue to grow in size, a very important aspect\nis predicting performance of larger models in an\nextrapolation setting. We present some preliminary\nfindings in this setting in §C.3.\nLimitations in evaluation metrics. We use\nRMSE and R2 as they are widely-used metrics for\nregression tasks. However, both metrics have their\nlimitations for our problem, especially in the con-\ntext of conducting group-wise comparison (§3.4).\nRMSE does not account for the variance in the tar-\nget variable. A low RMSE value for a task may\nbe solely due to the fact that the task performance\nis relatively insensitve to different experiment set-\ntings. On the other hand, while R2 score accounts\nfor variance, it creates discrepancies when conduct-\ning group-wise comparison since the denominator\nused to compute R2 differs for each group. To get\na more comprehensive picture of our prediction\nmodel, we introduce task-average Pearson Correla-\ntion and Kendall Rank Correlation for evaluation\nand discuss our findings in Appendix C.1.\nAcknowledgements\nWe thank anonymous reviewers and members of\nUSC NLP for their valuable feedback. QY and XR\nwere supported in part by the Office of the Director\nof National Intelligence (ODNI), Intelligence Ad-\nvanced Research Projects Activity (IARPA), via the\nHIATUS Program contract #2022-22072200006,\nthe DARPA MCS program under Contract No.\nN660011924033, the Defense Advanced Research\nProjects Agency with award W911NF-19-20271,\nNSF IIS 2048211, and gift awards from Google\nand Amazon. HF was supported by a USC Provost\nFellowship Award. RJ was supported by an Open\nPhilanthropy research grant and a Cisco Research\nAward.\nReferences\nSid Black, Leo Gao, Phil Wang, Connor Leahy,\nand Stella Biderman. 2021. GPT-Neo: Large\nScale Autoregressive Language Modeling with Mesh-\nTensorflow. In GPT-Neo.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\nIn Proceedings of the 2015 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n632–642, Lisbon, Portugal. Association for Compu-\ntational Linguistics.\nLeo Breiman. 2001. Random forests. Machine learning,\n45:5–32.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nEthan Caballero, Kshitij Gupta, Irina Rish, and David\nKrueger. 2023. Broken neural scaling laws. In The\nEleventh International Conference on Learning Rep-\nresentations.\nVladimír ˇCern`y. 1985. Thermodynamical approach to\nthe traveling salesman problem: An efficient simula-\ntion algorithm. Journal of optimization theory and\napplications, 45:41–51.\nTianqi Chen and Carlos Guestrin. 2016. Xgboost: A\nscalable tree boosting system. In Proceedings of the\n22nd ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining, KDD ’16,\npage 785–794, New York, NY , USA. Association for\nComputing Machinery.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\n7502\nSebastian Gehrmann, et al. 2022. Palm: Scaling\nlanguage modeling with pathways. arXiv preprint\narXiv:2204.02311.\nAlexis Conneau and Douwe Kiela. 2018. SentEval: An\nevaluation toolkit for universal sentence representa-\ntions. In Proceedings of the Eleventh International\nConference on Language Resources and Evaluation\n(LREC 2018), Miyazaki, Japan. European Language\nResources Association (ELRA).\nJerome H Friedman. 2001. Greedy function approx-\nimation: a gradient boosting machine. Annals of\nstatistics, pages 1189–1232.\nDeep Ganguli, Danny Hernandez, Liane Lovitt,\nAmanda Askell, Yuntao Bai, Anna Chen, Tom Con-\nerly, Nova Dassarma, Dawn Drain, Nelson Elhage,\nSheer El Showk, Stanislav Fort, Zac Hatfield-Dodds,\nTom Henighan, Scott Johnston, Andy Jones, Nicholas\nJoseph, Jackson Kernian, Shauna Kravec, Ben Mann,\nNeel Nanda, Kamal Ndousse, Catherine Olsson,\nDaniela Amodei, Tom Brown, Jared Kaplan, Sam\nMcCandlish, Christopher Olah, Dario Amodei, and\nJack Clark. 2022. Predictability and surprise in large\ngenerative models. In 2022 ACM Conference on Fair-\nness, Accountability, and Transparency, FAccT ’22,\npage 1747–1764, New York, NY , USA. Association\nfor Computing Machinery.\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou,\nMantas Mazeika, Dawn Song, and Jacob Steinhardt.\n2021. Measuring massive multitask language under-\nstanding. In International Conference on Learning\nRepresentations.\nJordan Hoffmann, Sebastian Borgeaud, Arthur Men-\nsch, Elena Buchatskaya, Trevor Cai, Eliza Ruther-\nford, Diego de Las Casas, Lisa Anne Hendricks,\nJohannes Welbl, Aidan Clark, et al. 2022. Train-\ning compute-optimal large language models. arXiv\npreprint arXiv:2203.15556.\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B\nBrown, Benjamin Chess, Rewon Child, Scott Gray,\nAlec Radford, Jeffrey Wu, and Dario Amodei. 2020.\nScaling laws for neural language models. arXiv\npreprint arXiv:2001.08361.\nPercy Liang, Rishi Bommasani, Tony Lee, Dimitris\nTsipras, Dilara Soylu, Michihiro Yasunaga, Yian\nZhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-\nmar, Benjamin Newman, Binhang Yuan, Bobby Yan,\nCe Zhang, Christian Alexander Cosgrove, Christo-\npher D Manning, Christopher Re, Diana Acosta-\nNavas, Drew Arad Hudson, Eric Zelikman, Esin\nDurmus, Faisal Ladhak, Frieda Rong, Hongyu Ren,\nHuaxiu Yao, Jue W ANG, Keshav Santhanam, Laurel\nOrr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun,\nNathan Kim, Neel Guha, Niladri S. Chatterji, Omar\nKhattab, Peter Henderson, Qian Huang, Ryan An-\ndrew Chi, Sang Michael Xie, Shibani Santurkar,\nSurya Ganguli, Tatsunori Hashimoto, Thomas Icard,\nTianyi Zhang, Vishrav Chaudhary, William Wang,\nXuechen Li, Yifan Mai, Yuhui Zhang, and Yuta Ko-\nreeda. 2023. Holistic evaluation of language models.\nTransactions on Machine Learning Research. Fea-\ntured Certification, Expert Certification.\nNelson F. Liu, Tony Lee, Robin Jia, and Percy Liang.\n2023. Do question answering modeling improve-\nments hold across benchmarks? In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 13186–13218, Toronto, Canada. Association\nfor Computational Linguistics.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\nMaddie Simens, Amanda Askell, Peter Welinder,\nPaul F Christiano, Jan Leike, and Ryan Lowe. 2022.\nTraining language models to follow instructions with\nhuman feedback. In Advances in Neural Information\nProcessing Systems, volume 35, pages 27730–27744.\nCurran Associates, Inc.\nYotam Perlitz, Elron Bandel, Ariel Gera, Ofir Arviv,\nLiat Ein-Dor, Eyal Shnarch, Noam Slonim, Michal\nShmueli-Scheuer, and Leshem Choshen. 2023. Ef-\nficient benchmarking (of language models). arXiv\npreprint arXiv:2308.11696.\nJack W Rae, Sebastian Borgeaud, Trevor Cai, Katie\nMillican, Jordan Hoffmann, Francis Song, John\nAslanides, Sarah Henderson, Roman Ring, Susan-\nnah Young, et al. 2021. Scaling language models:\nMethods, analysis & insights from training gopher.\narXiv preprint arXiv:2112.11446.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. SQuAD: 100,000+ questions for\nmachine comprehension of text. In Proceedings of\nthe 2016 Conference on Empirical Methods in Natu-\nral Language Processing, pages 2383–2392, Austin,\nTexas. Association for Computational Linguistics.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Arun Raja, Manan Dey,\nM Saiful Bari, Canwen Xu, Urmish Thakker,\nShanya Sharma Sharma, Eliza Szczechla, Taewoon\nKim, Gunjan Chhablani, Nihal Nayak, Debajyoti\nDatta, Jonathan Chang, Mike Tian-Jian Jiang, Han\nWang, Matteo Manica, Sheng Shen, Zheng Xin Yong,\nHarshit Pandey, Rachel Bawden, Thomas Wang, Tr-\nishala Neeraj, Jos Rozen, Abheesht Sharma, An-\ndrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan\nTeehan, Teven Le Scao, Stella Biderman, Leo Gao,\nThomas Wolf, and Alexander M Rush. 2022. Multi-\ntask prompted training enables zero-shot task gener-\nalization. In International Conference on Learning\nRepresentations.\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao,\nAbu Awal Md Shoeb, Abubakar Abid, Adam Fisch,\nAdam R. Brown, Adam Santoro, Aditya Gupta,\nAdrià Garriga-Alonso, Agnieszka Kluska, Aitor\n7503\nLewkowycz, Akshat Agarwal, Alethea Power, Alex\nRay, Alex Warstadt, Alexander W. Kocurek, Ali\nSafaya, Ali Tazarv, Alice Xiang, Alicia Parrish,\nAllen Nie, Aman Hussain, Amanda Askell, Amanda\nDsouza, Ambrose Slone, Ameet Rahane, Anan-\ntharaman S. Iyer, Anders Johan Andreassen, An-\ndrea Madotto, Andrea Santilli, Andreas Stuhlmüller,\nAndrew M. Dai, Andrew La, Andrew Lampinen,\nAndy Zou, Angela Jiang, Angelica Chen, Anh\nVuong, Animesh Gupta, Anna Gottardi, Antonio\nNorelli, Anu Venkatesh, Arash Gholamidavoodi,\nArfa Tabassum, Arul Menezes, Arun Kirubara-\njan, Asher Mullokandov, Ashish Sabharwal, Austin\nHerrick, Avia Efrat, Aykut Erdem, Ayla Karaka¸ s,\nB. Ryan Roberts, Bao Sheng Loe, Barret Zoph,\nBartłomiej Bojanowski, Batuhan Özyurt, Behnam\nHedayatnia, Behnam Neyshabur, Benjamin Inden,\nBenno Stein, Berk Ekmekci, Bill Yuchen Lin, Blake\nHowald, Bryan Orinion, Cameron Diao, Cameron\nDour, Catherine Stinson, Cedrick Argueta, Cesar\nFerri, Chandan Singh, Charles Rathkopf, Chenlin\nMeng, Chitta Baral, Chiyu Wu, Chris Callison-\nBurch, Christopher Waites, Christian V oigt, Christo-\npher D Manning, Christopher Potts, Cindy Ramirez,\nClara E. Rivera, Clemencia Siro, Colin Raffel, Court-\nney Ashcraft, Cristina Garbacea, Damien Sileo,\nDan Garrette, Dan Hendrycks, Dan Kilman, Dan\nRoth, C. Daniel Freeman, Daniel Khashabi, Daniel\nLevy, Daniel Moseguí González, Danielle Perszyk,\nDanny Hernandez, Danqi Chen, Daphne Ippolito,\nDar Gilboa, David Dohan, David Drakard, David Ju-\nrgens, Debajyoti Datta, Deep Ganguli, Denis Emelin,\nDenis Kleyko, Deniz Yuret, Derek Chen, Derek\nTam, Dieuwke Hupkes, Diganta Misra, Dilyar Buzan,\nDimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee,\nDylan Schrader, Ekaterina Shutova, Ekin Dogus\nCubuk, Elad Segal, Eleanor Hagerman, Elizabeth\nBarnes, Elizabeth Donoway, Ellie Pavlick, Emanuele\nRodolà, Emma Lam, Eric Chu, Eric Tang, Erkut\nErdem, Ernie Chang, Ethan A Chi, Ethan Dyer,\nEthan Jerzak, Ethan Kim, Eunice Engefu Manyasi,\nEvgenii Zheltonozhskii, Fanyue Xia, Fatemeh Siar,\nFernando Martínez-Plumed, Francesca Happé, Fran-\ncois Chollet, Frieda Rong, Gaurav Mishra, Genta In-\ndra Winata, Gerard de Melo, Germán Kruszewski,\nGiambattista Parascandolo, Giorgio Mariani, Glo-\nria Xinyue Wang, Gonzalo Jaimovitch-Lopez, Gregor\nBetz, Guy Gur-Ari, Hana Galijasevic, Hannah Kim,\nHannah Rashkin, Hannaneh Hajishirzi, Harsh Mehta,\nHayden Bogar, Henry Francis Anthony Shevlin, Hin-\nrich Schuetze, Hiromu Yakura, Hongming Zhang,\nHugh Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet,\nJack Geissinger, Jackson Kernion, Jacob Hilton, Jae-\nhoon Lee, Jaime Fernández Fisac, James B Simon,\nJames Koppel, James Zheng, James Zou, Jan Kocon,\nJana Thompson, Janelle Wingfield, Jared Kaplan,\nJarema Radom, Jascha Sohl-Dickstein, Jason Phang,\nJason Wei, Jason Yosinski, Jekaterina Novikova, Jelle\nBosscher, Jennifer Marsh, Jeremy Kim, Jeroen Taal,\nJesse Engel, Jesujoba Alabi, Jiacheng Xu, Jiaming\nSong, Jillian Tang, Joan Waweru, John Burden, John\nMiller, John U. Balis, Jonathan Batchelder, Jonathan\nBerant, Jörg Frohberg, Jos Rozen, Jose Hernandez-\nOrallo, Joseph Boudeman, Joseph Guerr, Joseph\nJones, Joshua B. Tenenbaum, Joshua S. Rule, Joyce\nChua, Kamil Kanclerz, Karen Livescu, Karl Krauth,\nKarthik Gopalakrishnan, Katerina Ignatyeva, Katja\nMarkert, Kaustubh Dhole, Kevin Gimpel, Kevin\nOmondi, Kory Wallace Mathewson, Kristen Chia-\nfullo, Ksenia Shkaruta, Kumar Shridhar, Kyle Mc-\nDonell, Kyle Richardson, Laria Reynolds, Leo Gao,\nLi Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-\nOchando, Louis-Philippe Morency, Luca Moschella,\nLucas Lam, Lucy Noble, Ludwig Schmidt, Luheng\nHe, Luis Oliveros-Colón, Luke Metz, Lütfi Kerem\nSenel, Maarten Bosma, Maarten Sap, Maartje Ter\nHoeve, Maheen Farooqi, Manaal Faruqui, Mantas\nMazeika, Marco Baturan, Marco Marelli, Marco\nMaru, Maria Jose Ramirez-Quintana, Marie Tolkiehn,\nMario Giulianelli, Martha Lewis, Martin Potthast,\nMatthew L Leavitt, Matthias Hagen, Mátyás Schu-\nbert, Medina Orduna Baitemirova, Melody Arnaud,\nMelvin McElrath, Michael Andrew Yee, Michael Co-\nhen, Michael Gu, Michael Ivanitskiy, Michael Star-\nritt, Michael Strube, Michał Sw˛ edrowski, Michele\nBevilacqua, Michihiro Yasunaga, Mihir Kale, Mike\nCain, Mimee Xu, Mirac Suzgun, Mitch Walker,\nMo Tiwari, Mohit Bansal, Moin Aminnaseri, Mor\nGeva, Mozhdeh Gheini, Mukund Varma T, Nanyun\nPeng, Nathan Andrew Chi, Nayeon Lee, Neta Gur-\nAri Krakover, Nicholas Cameron, Nicholas Roberts,\nNick Doiron, Nicole Martinez, Nikita Nangia, Niklas\nDeckers, Niklas Muennighoff, Nitish Shirish Keskar,\nNiveditha S. Iyer, Noah Constant, Noah Fiedel,\nNuan Wen, Oliver Zhang, Omar Agha, Omar El-\nbaghdadi, Omer Levy, Owain Evans, Pablo Anto-\nnio Moreno Casares, Parth Doshi, Pascale Fung,\nPaul Pu Liang, Paul Vicol, Pegah Alipoormolabashi,\nPeiyuan Liao, Percy Liang, Peter W Chang, Pe-\nter Eckersley, Phu Mon Htut, Pinyu Hwang, Piotr\nMiłkowski, Piyush Patil, Pouya Pezeshkpour, Priti\nOli, Qiaozhu Mei, Qing Lyu, Qinlang Chen, Ra-\nbin Banjade, Rachel Etta Rudolph, Raefer Gabriel,\nRahel Habacker, Ramon Risco, Raphaël Millière,\nRhythm Garg, Richard Barnes, Rif A. Saurous, Riku\nArakawa, Robbe Raymaekers, Robert Frank, Ro-\nhan Sikand, Roman Novak, Roman Sitelew, Ro-\nnan Le Bras, Rosanne Liu, Rowan Jacobs, Rui\nZhang, Russ Salakhutdinov, Ryan Andrew Chi,\nSeungjae Ryan Lee, Ryan Stovall, Ryan Teehan,\nRylan Yang, Sahib Singh, Saif M. Mohammad,\nSajant Anand, Sam Dillavou, Sam Shleifer, Sam\nWiseman, Samuel Gruetter, Samuel R. Bowman,\nSamuel Stern Schoenholz, Sanghyun Han, Sanjeev\nKwatra, Sarah A. Rous, Sarik Ghazarian, Sayan\nGhosh, Sean Casey, Sebastian Bischoff, Sebastian\nGehrmann, Sebastian Schuster, Sepideh Sadeghi,\nShadi Hamdan, Sharon Zhou, Shashank Srivastava,\nSherry Shi, Shikhar Singh, Shima Asaadi, Shixi-\nang Shane Gu, Shubh Pachchigar, Shubham Tosh-\nniwal, Shyam Upadhyay, Shyamolima Shammie\nDebnath, Siamak Shakeri, Simon Thormeyer, Si-\nmone Melzi, Siva Reddy, Sneha Priscilla Makini,\nSoo-Hwan Lee, Spencer Torene, Sriharsha Hatwar,\nStanislas Dehaene, Stefan Divic, Stefano Ermon,\nStella Biderman, Stephanie Lin, Stephen Prasad,\n7504\nSteven Piantadosi, Stuart Shieber, Summer Mish-\nerghi, Svetlana Kiritchenko, Swaroop Mishra, Tal\nLinzen, Tal Schuster, Tao Li, Tao Yu, Tariq Ali,\nTatsunori Hashimoto, Te-Lin Wu, Théo Desbor-\ndes, Theodore Rothschild, Thomas Phan, Tianle\nWang, Tiberius Nkinyili, Timo Schick, Timofei Ko-\nrnev, Titus Tunduny, Tobias Gerstenberg, Trenton\nChang, Trishala Neeraj, Tushar Khot, Tyler Shultz,\nUri Shaham, Vedant Misra, Vera Demberg, Victo-\nria Nyamai, Vikas Raunak, Vinay Venkatesh Ra-\nmasesh, vinay uday prabhu, Vishakh Padmakumar,\nVivek Srikumar, William Fedus, William Saunders,\nWilliam Zhang, Wout V ossen, Xiang Ren, Xiaoyu\nTong, Xinran Zhao, Xinyi Wu, Xudong Shen, Yadol-\nlah Yaghoobzadeh, Yair Lakretz, Yangqiu Song,\nYasaman Bahri, Yejin Choi, Yichi Yang, Yiding\nHao, Yifu Chen, Yonatan Belinkov, Yu Hou, Yu-\nfang Hou, Yuntao Bai, Zachary Seid, Zhuoye Zhao,\nZijian Wang, Zijie J. Wang, Zirui Wang, and Ziyi\nWu. 2023. Beyond the imitation game: Quantifying\nand extrapolating the capabilities of language models.\nTransactions on Machine Learning Research.\nMirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\nbastian Gehrmann, Yi Tay, Hyung Won Chung,\nAakanksha Chowdhery, Quoc Le, Ed Chi, Denny\nZhou, and Jason Wei. 2023. Challenging BIG-bench\ntasks and whether chain-of-thought can solve them.\nIn Findings of the Association for Computational Lin-\nguistics: ACL 2023, pages 13003–13051, Toronto,\nCanada. Association for Computational Linguistics.\nYi Tay, Mostafa Dehghani, Jinfeng Rao, William Fedus,\nSamira Abnar, Hyung Won Chung, Sharan Narang,\nDani Yogatama, Ashish Vaswani, and Donald Met-\nzler. 2022. Scale efficiently: Insights from pretrain-\ning and finetuning transformers. In International\nConference on Learning Representations.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al. 2023. Llama: Open and effi-\ncient foundation language models. arXiv preprint\narXiv:2302.13971.\nRajan Vivek, Kawin Ethayarajh, Diyi Yang, and Douwe\nKiela. 2023. Anchor points: Benchmarking mod-\nels with much fewer examples. arXiv preprint\narXiv:2309.08638.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Aman-\npreet Singh, Julian Michael, Felix Hill, Omer Levy,\nand Samuel Bowman. 2019. Superglue: A stickier\nbenchmark for general-purpose language understand-\ning systems. In Advances in Neural Information\nProcessing Systems, volume 32. Curran Associates,\nInc.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel Bowman. 2018. GLUE:\nA multi-task benchmark and analysis platform for nat-\nural language understanding. In Proceedings of the\n2018 EMNLP Workshop BlackboxNLP: Analyzing\nand Interpreting Neural Networks for NLP, pages\n353–355, Brussels, Belgium. Association for Com-\nputational Linguistics.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, Ed H.\nChi, Tatsunori Hashimoto, Oriol Vinyals, Percy\nLiang, Jeff Dean, and William Fedus. 2022a. Emer-\ngent abilities of large language models. Transactions\non Machine Learning Research. Survey Certifica-\ntion.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le,\nand Denny Zhou. 2022b. Chain of thought prompt-\ning elicits reasoning in large language models. In\nAdvances in Neural Information Processing Systems.\nMengzhou Xia, Antonios Anastasopoulos, Ruochen Xu,\nYiming Yang, and Graham Neubig. 2020. Predicting\nperformance for natural language processing tasks.\nIn Proceedings of the 58th Annual Meeting of the As-\nsociation for Computational Linguistics, pages 8625–\n8646, Online. Association for Computational Lin-\nguistics.\nZihuiwen Ye, Pengfei Liu, Jinlan Fu, and Graham Neu-\nbig. 2021. Towards more fine-grained and reliable\nNLP performance prediction. In Proceedings of the\n16th Conference of the European Chapter of the Asso-\nciation for Computational Linguistics: Main Volume,\npages 3703–3714, Online. Association for Computa-\ntional Linguistics.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022.\nOpt: Open pre-trained transformer language models.\narXiv preprint arXiv:2205.01068.\nZining Zhu, Soroosh Shahtalebi, and Frank Rudzicz.\n2022. Predicting fine-tuning performance with prob-\ning. In Proceedings of the 2022 Conference on Em-\npirical Methods in Natural Language Processing,\npages 11534–11547, Abu Dhabi, United Arab Emi-\nrates. Association for Computational Linguistics.\nA Filtering BIG-bench Records\nWe use the following criteria when filtering the\nrecords. After filtering we obtain a dataset with\n56k+ records which is described in Table 1. For\nnow we limit the scope to predicting performance\non the preferred evaluation metric.\n1. Keep json tasks and remove programmatic\ntasks.\n2. Remove T0/T5 models because there are only\n14 records for each of these two. Keep BIG-G,\nPaLM, GPT-3, Gopher models.\n7505\n3. Remove BIG-bench subtasks whose perfor-\nmance on the preferred metric is zero for all\nmodels.\n4. Keep experiments whose preferred\nmetric is in exact_str_match,\nmultiple_choice_grade, rougeLsum.\nThis keeps 93% of all records before this step.\n5. Remove entries of aggregating results from\nmultiple subtasks as the performance of a task.\n6. Remove subtasks with less than 100 examples\nbecause small sample size may lead to large\nvariance during evaluation\nWe present a summary of the 6 model families in\nthese records in Table 2.\nB Featurization\nIn the main body of the paper we use the abstrac-\ntion of (l,nparam,t,n shot) to describe experiment\nconfigurations. In the actual training of tree-based\nmodels and MLP, we modify how these features\nare represented. In particular, the input features\ncontain the following:\n1. l is converted as binary features for each\nmodel family, e.g., is_PaLM.\n2. (l,nparam) is converted as binary features for\neach model, e.g., is_PaLM_535B.\n3. There are 6 numerical features for the num-\nber of parameters: number of total parame-\nters, number of non-embedding parameters,\nnumber of FLOP-matched non-embedding pa-\nrameters; and the natural log of these three\nvalues.\n4. tis converted as binary features for each task,\ne.g., is_code_line_description.\n5. m is a binary feature for the preferred\nmetric associated with the task t, e.g.,\nis_exact_str_match. BIG-bench defines a\npreferred metric for each task, so in the ab-\nstraction it is covered by t.\n6. nshot is directly used as an input feature.\nFor numerical features (6 features for the num-\nber of parameters and 1 feature for the num-\nber of shots), we use StandardScaler in the\nsklearn libarary to normalize them. Addition-\nally, we normalize the performance value y to\nbe in the range of [0,1]. exact_str_match and\nmultiple_choice_grade already satisfy this con-\nstraint. The reported rougeLsum values are in the\nrange of [0,100] and are multiplied by 0.01 to form\nour dataset.\nC Extended Experiment Details and\nResults\nC.1 Additional Evaluation Metrics for\nPerformance Prediction\nIn addition to RMSE and R2 score, two common\nmetrics for evaluating regression models, we in-\ntroduce two new metrics, Task-average Pearson\nCorrelation and Task-average Kendall Rank Cor-\nrelation. The usage of Pearson Correlation and\nKendall Rank Correlation are inspired by Liu et al.\n(2023) and we further adapt them to be averaging\nacross tasks.\nConcretely, we first group the test set Dtest into\n|T| groups, based on the associated task tof each\nexample. Within each group, we compute the Pear-\nson Correlation or Kendall Rank Correlation be-\ntween the predicted performance and the actual\nperformance. Finally, the average of these rank cor-\nrelation values across all tasksTis then reported as\nthe task-average rank correlation. We report these\nnumbers along with RMSE and R2 in Table 6.\nGenerally, prediction models with higher R2\nscores exhibit higher rank correlation. Exceptions\nemerge when closely comparing tree-based models\nand MLP models. While MLP models are compara-\nble or outperform tree-based models in terms ofR2\nscore, tree-based models tend to outperform MLP\nmodels in terms of task-avg (rank) correlation. Our\nfurther investigation reveals that tree-based models\nmake more errors with large absolute errors, which\nare penalized heavily by RMSE and R2 (involv-\ning taking square of these errors), whereas rank\ncorrelation is less sensitive to such errors.\nThroughout our paper, we primarily focus on ex-\nperimentation with MLP models due to their faster\nruntime and the values of the learned representa-\ntions in MLP. In practice, we recommend selecting\nmethods based on the final goal: MLP models for\nmore accurate prediction in terms of exact values;\ntree-based methods for more accurate ranking of\ndifferent experiment settings.\nC.2 Sample Predictions in the L3 setting\nIn Fig. 7 we visualize predictions on four sample\n(l,t) combinations by the MLP model. The left\n7506\nModel Family Company Release Date Pre-train Corpus # Parameters Architecture Choices Infrastructure\nBIG-G (T=0, T=1) Google Jun 2022 2.8T tokens 2M to 137B Gated-GELU, relative attention TPUv3, GSPMDBIG-G Sparse Google Jun 2022 2.8T tokens 51M to 46B BIG-G + Mixture-of-Experts TPUv3, GSPMDPaLM Google Apr 2022 780B tokens 8B, 62B, 540B SwiGLU activation, parallel layers, etc. TPUv4, PathwayGPT-3 OpenAI May 2020 300B tokens 125M to 175B Alternating dense and sparse attention GPUsGopher DeepMind Nov 2021 300B tokens 44M to 280B RMSNorm, relative position encoding TPUv3, model parallelism, etc.\nTable 2: Summary of model families included in this study. These model families offer considerable diversity.\nInformation in this table is aggregated from Srivastava et al. (2023); Chowdhery et al. (2022); Brown et al. (2020);\nRae et al. (2021)\nBIG-G T=1 2B Wins Tie GPT-3 Large WinsConclusion\nPerformance Recovered from BBH (24 subtasks)20.1% 70.1% 9.8% BIG-G T=1 2B is betterPerformance Recovered from small-bench (24 subtasks)19.1% 56.3% 24.6% GPT-3 Large is better\nGround-truth full BIG-bench Performance14.3% 55.3% 30.4% GPT-3 Large is better\nTable 3: Using BIG-bench Hard and “small-bench” to recover performance and compare models. In this\nexample, BBH is less informative in recovering performance on remaining tasks, and thus is the comparison is less\naccurate.\ntwo are cases achieving high R2 scores. The right\ntwo are cases achieving low R2 scores.\nFor (l,t) combinations achieving highR2 scores,\nour observation is that either a combination (l,t′)\nexists in Dtrain such that tand t′are similar (e.g., t\nand t′are two sub-tasks from the same BIG-bench\ntask), or (l′,t) exists in Dtrain such that l′and l\nare similar (e.g., both land l′from the three BIG-\nG model families). Our interpretation is that the\nlearned predictor is capturing model family simi-\nlarities and task similarities and therefore predicts\nmore accurately when lor thas a similar counter-\npart in the training set.\nFor (l,t) combinations achieving low R2 scores,\nwe observe several cases of overestimating perfor-\nmance or predicting “false positives” of emergent\nabilities. The selection of these combinations are\nlargely due to using R2 as selection criteria—they\nhave small total variance as the denominator for\nR2 score, so any overestimation will results in an\nextremely negative R2 score. Nevertheless, these\nqualitative results suggest that overestimation is\na common type of mistake made by our trained\nprediction model.\nC.3 Performance Prediction in Extrapolation\nSettings\nIn the input space of our problem,nshot and nparam\nare numerical features. Thus it is possible to test\nthe extrapolation capabilities on these two inputs.\nWe create three settings for testing the model’s\nextrapolation capabilities:\n• E1: Dtest contains examples with nshot = 3,\nDtrain contains examples withnshot = 0,1,2\n• E2.1: Dtest contains examples with\n(l,nparam) = (GPT-3,200B)\n• E2.2: Dtest contains examples with\n(l,nparam) = (PaLM,535B)\nRelaxing Constraints by leaking 10% Dtest.\nPure extrapolation may be extremely challenging.\nTo better contextualize the results and understand\nlimitations, we compare model performance in\nthree slightly different settings. The first setting\n(S1) is holding 10% Dtrain as dev set for hyperpa-\nrameter selection and early stopping. This corre-\nsponds to the pure extrapolation setting, as no in-\nformation about Dtest is available at training time.\nThe second setting (S2) is holding 10%Dtest as dev\nset. Information about Dtest is indirectly leaked to\nmodel training. The third setting is leaking 10%\nDtest during training. This third setting (S3) is\nmainly for reference.\nMore specifically, we split the original Dtrain\ninto 90% D′\ntrain and 10% Ddev1. Also we split\nthe original Dtest into 90% D′\ntest and 10% Ddev2.\nIn S1, model training, selection and evaluation is\ndone with (D′\ntrain,Ddev1,D′\ntest). In S2, we al-\nlow model selection with Ddev2, so the experi-\nment is done with (D′\ntrain,Ddev2,D′\ntest). In S3,\nwe leak Ddev2 (which is from the test distribution)\nto training time, and the experiment is done with\n(D′\ntrain ∪Ddev2,Ddev1,D′\ntest).\nResults and Findings. We present the results\nin Table 4. (1) Extrapolation in terms of nshot\nis promising, achieving R2 which is greater than\n0.9. However, extrapolation to increased model\nsize remains challenging. This is closely related to\nthe observation that emergent abilities is difficult\nto predict (Ganguli et al., 2022; Wei et al., 2022a).\n7507\n1010 1011\nflop_matched_non_embedding_params\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0performance\nmodel: PaLM\ntask: bbq_lite_json:\nbbq_lite_json_nationality_ambig\n0-shot pred\n0-shot true\n1-shot pred\n1-shot true\n2-shot pred\n2-shot true\n5-shot pred\n5-shot true\n107 108 109 1010 1011\nflop_matched_non_embedding_params\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5performance\nmodel: BIG-G T=0\ntask: modified_arithmetic:\nthree_digit_addition_control\n0-shot pred\n0-shot true\n1-shot pred\n1-shot true\n2-shot pred\n2-shot true\n3-shot pred\n3-shot true\n1010 1011\nflop_matched_non_embedding_params\n0.0\n0.1\n0.2\n0.3\n0.4performance\nmodel: PaLM\ntask: tense\n0-shot pred\n0-shot true\n1-shot pred\n1-shot true\n2-shot pred\n2-shot true\n5-shot pred\n5-shot true\n108 109 1010 1011\nflop_matched_non_embedding_params\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6performance\nmodel: GPT\ntask: modified_arithmetic:\nthree_digit_subtraction_plus_one\n0-shot pred\n0-shot true\n1-shot pred\n1-shot true\n2-shot pred\n2-shot true\n3-shot pred\n3-shot true\nFigure 7: Sample Prediction Results in L3 setting (§C.2). Left 2: (l,t) combinations achieving high R2 score;\nRight 2: (l,t) combinations achieving low R2 score.\n(2) Performance in S2 is consistently better than\nS1. Note that the only difference between these\ntwo setting is the Ddev used to do model selection.\nThis suggests that the model overfits and fails to\nextrapolate well in the strict S1 setting. Leaking\nsome information about the test distribution (as in\nS2 and S3) can greatly help improve prediction\naccuracy.\nC.4 Additional Results on “small-bench”\nsearch\nWe experiment with two additional search algo-\nrithms for “small-bench” search: (1) Randomized\nBeam Search: Similar to regular beam search, ex-\ncept that we maintain a beam size of q= 4 and we\nenumerate 1/qrandomly selected task candidates\nat each timestamp. This ensures the search run-\ntime is equivalent to greedy search. (2) Simulated\nAnnealing ( ˇCern`y, 1985): Initialize with a seed\nTtrain; at time t, iteratively search in the neigh-\nbourhood of the Ttrain at time t−1 and occasion-\nally allowing uphill moves (i.e., moving towards\na worse solution). Results are visualized in Fig. 8.\nSimilar to greedy search, these two search methods\nface optimization challenges discussed in §5.3 and\nmay lead to sub-optimal solutions.\nC.5 Gaps between the “small-bench” search\nobjective and evaluation objective\nIn §5.3, we observe that the performance of greedy\nsearch is unstable and hypothesize that this is partly\ndue to the gaps between the search and evaluation\nobjective.\nGap between Tdev and Ttest. To simulate the\nscenario that the prediction model is expected to\nmake predictions on an unseen model family, we\nmake sure that the search algorithm optimizes on\nTdev ×Ltest, and holds out Ttest ×Ltest for evalua-\ntion. This creates a dev-test shift which may affect\nsearch algorithm results.\n4 8 16 24 32 42\nSize of train\n0.650.65\n0.70\n0.75\n0.80\n0.8530-Fold R2( test × test)\nBB-Lite\nBB-Hard\nBaselines\nRandom\nGreedy Search\nBeam Search (#beam=4)\nSimulated Annealing\nBest of 5000\nFigure 8: Additional “Small-bench” Search Results.\nSee §C.4 for in-depth analysis.\nGap between 1 fold and 30 folds. Due to run-\ntime concerns, we only launch search algorithms\non 1 fold, while at evaluation time we use all 30\nfolds. The 30 folds, derived from 6 distinct model\nfamilies, may exhibit significant variations. Con-\nsequently, the search result on 1 fold may overfit\nto that specific fold and become less optimal on all\n30 folds.\nD Reproducibility\nD.1 Hyperparameters and Training Details\nFor all the following methods and for each data\nsplit setting (L1/L2.1/L2.2/L3/L3 Composition),\nwe select hyperparameters based on the dev perfor-\nmance on the first fold, and select the best set of\nhyperparameters from 100 random combinations\nfrom a pre-defined list.\nFor Random Forest, we use the implementa-\ntion of RandomForestRegressor from sklearn\nlibrary. We use squared_error as optimization crite-\nrion. The hyperparameter candidates are sampled\n7508\nS1:Ddevis 10%Dtrain S2:Ddevis 10%Dtest S3: Leak 10%Dtest\nRMSE (↓) R2 (↑) RMSE (↓) R2 (↑) RMSE (↓) R2 (↑)\nMore shots\nE1: Hold outnshot= 3 0.0618 0.9297 0.0587 0.9367 0.0545 0.9454\nScaling up model size\nE2.1: Hold out GPT-3 200B0.1314 0.6968 0.1017 0.8187 0.0830 0.8791\nE2.2: Hold out PaLM 535B0.2708 0.1535 0.1923 0.5731 0.1668 0.6789\nTable 4: Results of Extrapolation Experiments (§C.3).\nfrom the following:\n1 {\n2 \" n_estimators \": [30, 100, 300],\n3 \" max_depth \": [ None , 16, 32, 64, 128],\n4 \" min_samples_split \": [2, 4, 8],\n5 \" min_samples_leaf \": [1, 2, 4],\n6 \" max_features \": [1.0, 0.9, 0.8, 0.7, 0.6, \"\nsqrt \"],\n7 \" max_samples \": [1.0, 0.9, 0.8, 0.7, 0.6]\n8 }\nFor Gradient Boosted Trees, we use the im-\nplementation of XGBRegressor from XGBoost li-\nbrary (Chen and Guestrin, 2016). We use the\nreg:squarederror as objective. The hyperparam-\neter candidates are sampled from the following:\n1 {\n2 \" n_estimators \": [30, 100, 300, 1000],\n3 \" learning_rate \": [0.1, 0.3, 0.5, 0.8, 1.0],\n4 \" max_depth \": [ None , 16, 32, 64, 128], # None\nindicates no limit\n5 \" gamma \": [0, 0.1, 0.2],\n6 \" subsample \": [0.6, 0.7, 0.8, 0.9, 1.0],\n7 }\nFor MLP, we implement with Pytorch. We use\nAdam optimzier and use MSELoss. The hyperpa-\nrameter candidates are sampled from the following:\n1 {\n2 \"lr\": [1e-3, 3e-4, 1e-4],\n3 \" batch_size \": [32, 64, 128],\n4 \" dropout \": [0.0, 0.05, 0.1, 0.15, 0.2],\n5 \" hidden_dims \": [\n6 (128,64,32,16),(256,128,64,32),\n7 (128,64,32),(256,128,64),\n8 (64,32),(128,64),(256,128),\n9 (128,),(64,)\n10 ],\n11 \" weight_decay \": [0.0, 0.00001, 0.0001, 0.001\n, 0.01],\n12 }\nD.2 Details on Cross Validation\nL1: Random Splitting. We first split Dinto 10\ndisjoint subsets, and then rotate on which ones\nare Ddev and Dtest. To save computation budget,\nhyperparameter selection is done on the Ddev of\nthe first fold.\nL2.1/L2.2/L3: Random Splitting at Different\nGranularity. To ensure that the results are com-\nparable across settings as much as possible, we use\nModel Runtime (second)\nMatrix+Task Baseline 4\nAdapted SVD 2\nModel-model kNN 2\nTask-task kNN 5\nRandom Forest 98\nGradient Boosted Trees 242\nMLP 86\nMLP (optimized for search) 28\nTable 5: Runtime (Training+Evaluation) of Performance\nPrediction Models.\n10-fold cross validation for all these settings, sim-\nilar to the practice in L1. This ensures for every\nfold, the sizes of Dtrain/Ddev/Dtest are consistent\nacross settings, and each example in Dappears in\nDtest exactly once. In this case, the only changing\nvariable is the data splitting strategy.\nL3 Composition: Holding out Ltest ×Ttest. To\nalign with the 10-fold setting in L1-L3 as much as\npossible, we split Linto 3 non-overlapping subsets,\nand split T into 3 non-overlapping subsets. This\ngives 3 ×3 = 9 different Dtest for cross-validation.\nD.3 Hardware and Runtime\nMatrix completion experiments and tree-based ex-\nperiments are done on a server with 56 Intel Xeon\nCPU E5-2690v4 (@ 2.6 GHz). MLP experiments\nare done on one NVIDIA GeForce RTX 2080 Ti.\nThe runtime for training a model for performance\nprediction is listed in Table 5. For small-bench\nsearch, we optimized MLP training by not saving a\ncopy of the best checkpoint in memory, and moving\nDtrain and Ddev to GPU before training to reduce\nGPU I/O. For Greedy Search, the performance pre-\ndiction algorithm is repeated for 12326 times, using\napproximately 5 days. For Best of 5000, the per-\nformance prediction algorithm is repeated for 5000\ntimes, using approximately 2 days.\n(Continued on next page)\n7509\nE Full Results of Performance Prediction\nRMSE R2 Score Task Avg. Pearson Task Avg. Kendall\nL1 Setting: Random(l,nparam,t,nshot), 10 folds\nModel+Task Baseline 0.1220 (±0.0016) 0.7068 (±0.0067) 0.5207 (±0.0078) 0.3617 (±0.0077)\nAdapted SVD 0.0986 ( ±0.0014) 0.8082 (±0.0053) 0.5149 (±0.0089) 0.3443 (±0.0053)\nModel-model kNN 0.0712 (±0.0016) 0.8999 (±0.0041) 0.7046 (±0.0085) 0.5133 (±0.0070)\nTask-task kNN 0.0695 ( ±0.0012) 0.9048 (±0.0035) 0.7006 (±0.0091) 0.5109 (±0.0078)\nRandom Forest 0.0553 ( ±0.0014) 0.9397 (±0.0030) 0.8378 (±0.0062) 0.6590 (±0.0058)\nGradient Boosted Trees 0.0499 (±0.0013) 0.9510 (±0.0025) 0.8566 (±0.0085) 0.6690 (±0.0060)\nMLP 0.0500 ( ±0.0009) 0.9508 (±0.0014) 0.8203 (±0.0097) 0.6128 (±0.0065)\nL2.1 Setting: Random(l,nparam,t), 10 folds\nModel+Task Baseline 0.1221 (±0.0042) 0.7057 (±0.0158) 0.4823 (±0.0172) 0.3629 (±0.0152)\nAdapted SVD 0.1000 ( ±0.0039) 0.8026 (±0.0135) 0.4575 (±0.0115) 0.3229 (±0.0121)\nModel-model kNN 0.0721 (±0.0034) 0.8974 (±0.0085) 0.6669 (±0.0118) 0.5043 (±0.0110)\nTask-task kNN 0.0763 ( ±0.0031) 0.8852 (±0.0078) 0.6102 (±0.0190) 0.4548 (±0.0136)\nRandom Forest 0.0724 ( ±0.0034) 0.8962 (±0.0109) 0.7468 (±0.0152) 0.5830 (±0.0101)\nGradient Boosted Trees 0.0676 (±0.0029) 0.9095 (±0.0084) 0.7458 (±0.0155) 0.5759 (±0.0094)\nMLP 0.0616 ( ±0.0022) 0.9251 (±0.0040) 0.7008 (±0.0163) 0.5244 (±0.0126)\nL2.2 Setting: Random(l,t,nshot), 10 folds\nModel+Task Baseline 0.1315 (±0.0033) 0.6577 (±0.0288) 0.4556 (±0.0327) 0.3373 (±0.0229)\nAdapted SVD 0.1208 ( ±0.0042) 0.7107 (±0.0324) 0.4338 (±0.0229) 0.3095 (±0.0170)\nModel-model kNN 0.0983 (±0.0062) 0.8072 (±0.0339) 0.5885 (±0.0204) 0.4287 (±0.0116)\nTask-task kNN 0.0985 ( ±0.0060) 0.8079 (±0.0231) 0.6059 (±0.0181) 0.4449 (±0.0137)\nRandom Forest 0.0675 ( ±0.0031) 0.9098 (±0.0096) 0.7571 (±0.0144) 0.5862 (±0.0107)\nGradient Boosted Trees 0.0624 (±0.0033) 0.9229 (±0.0092) 0.7819 (±0.0116) 0.6057 (±0.0104)\nMLP 0.0555 ( ±0.0019) 0.9391 (±0.0050) 0.7424 (±0.0210) 0.5520 (±0.0143)\nL3 Setting: Random(l,t), 10 folds\nModel+Task Baseline 0.1321 (±0.0075) 0.6542 (±0.0302) 0.4746 (±0.0288) 0.3575 (±0.0229)\nAdapted SVD 0.1199 ( ±0.0088) 0.7146 (±0.0353) 0.4211 (±0.0291) 0.2979 (±0.0211)\nModel-model kNN 0.1028 (±0.0130) 0.7880 (±0.0531) 0.5954 (±0.0214) 0.4345 (±0.0106)\nTask-task kNN 0.1032 ( ±0.0076) 0.7878 (±0.0308) 0.5667 (±0.0242) 0.4102 (±0.0156)\nRandom Forest 0.1015 ( ±0.0103) 0.7940 (±0.0414) 0.6617 (±0.0234) 0.4961 (±0.0174)\nGradient Boosted Trees 0.0947 (±0.0084) 0.8212 (±0.0315) 0.6589 (±0.0302) 0.4827 (±0.0246)\nMLP 0.0736 ( ±0.0064) 0.8922 (±0.0164) 0.6573 (±0.0156) 0.4680 (±0.0148)\nL3 Composition Setting: Holding outLtest×Ttest, 9 folds\nModel+Task Baseline 0.1383 (±0.0115) 0.6231 (±0.0265) 0.5099 (±0.0763) 0.3709 (±0.0457)\nAdapted SVD 0.1318 ( ±0.0142) 0.6575 (±0.0460) 0.4720 (±0.0767) 0.3365 (±0.0541)\nModel-model kNN 0.1138 (±0.0173) 0.7398 (±0.0731) 0.5342 (±0.1198) 0.3918 (±0.0956)\nTask-task kNN 0.1152 ( ±0.0139) 0.7362 (±0.0530) 0.5692 (±0.0773) 0.4086 (±0.0657)\nRandom Forest 0.1118 ( ±0.0154) 0.7475 (±0.0782) 0.6136 (±0.0781) 0.4347 (±0.0494)\nGradient Boosted Trees 0.1072 (±0.0104) 0.7706 (±0.0451) 0.5970 (±0.0941) 0.4034 (±0.0588)\nMLP 0.0843 ( ±0.0072) 0.8597 (±0.0129) 0.6228 (±0.0991) 0.4236 (±0.0675)\nTable 6: Full Results of Performance Prediction. Matrix Completion Trees Neural Network\n7510\nF Scaling Behavior of Most/Least “Predictable” Tasks (§3.4)\n107\n108\n109\n1010\n1011\nEffective parameter count\n0\n20\n40\n60\n80\n100exact_str_match\nmodified_arithmetic:three_digit_addition_control\nBIG-G (0-shot)\nBIG-G (1-shot)\nBIG-G (2-shot)\nBIG-G (3-shot)\nBIG-G T=1 (0-shot)\nBIG-G T=1 (1-shot)\nBIG-G T=1 (2-shot)\nBIG-G T=1 (3-shot)\nBIG-G sparse (0-shot)\nBIG-G sparse (1-shot)\nBIG-G sparse (2-shot)\nBIG-G sparse (3-shot)\nGPT (0-shot)\nGPT (1-shot)\nGPT (2-shot)\nGPT (3-shot)\nPaLM (0-shot)\nPaLM (1-shot)\nPaLM (2-shot)\nPaLM (3-shot)\n(a) modified_arithmetic:\nthree_digit_addition_control\n107\n108\n109\n1010\n1011\nEffective parameter count\n0\n20\n40\n60\n80exact_str_match\nmodified_arithmetic:two_digit_multiplication_control\nBIG-G (0-shot)\nBIG-G (1-shot)\nBIG-G (2-shot)\nBIG-G (3-shot)\nBIG-G T=1 (0-shot)\nBIG-G T=1 (1-shot)\nBIG-G T=1 (2-shot)\nBIG-G T=1 (3-shot)\nBIG-G sparse (0-shot)\nBIG-G sparse (1-shot)\nBIG-G sparse (2-shot)\nBIG-G sparse (3-shot)\nGPT (0-shot)\nGPT (1-shot)\nGPT (2-shot)\nGPT (3-shot)\nPaLM (0-shot)\nPaLM (1-shot)\nPaLM (2-shot)\nPaLM (3-shot)\n(b) modified_arithmetic:\ntwo_digit_multiplication_control\n107\n108\n109\n1010\n1011\nEffective parameter count\n0\n20\n40\n60\n80\n100exact_str_match\nlinguistic_mappings:sentence_negation_json\nBIG-G (0-shot)\nBIG-G (1-shot)\nBIG-G (2-shot)\nBIG-G (3-shot)\nBIG-G T=1 (0-shot)\nBIG-G T=1 (1-shot)\nBIG-G T=1 (2-shot)\nBIG-G T=1 (3-shot)\nBIG-G sparse (0-shot)\nBIG-G sparse (1-shot)\nBIG-G sparse (2-shot)\nBIG-G sparse (3-shot)\nGPT (0-shot)\nGPT (1-shot)\nGPT (2-shot)\nGPT (3-shot)\nPaLM (0-shot)\nPaLM (1-shot)\nPaLM (2-shot)\nPaLM (3-shot)\n(c) linguistic_mapping:\nsentence_negation_json\n107\n108\n109\n1010\n1011\nEffective parameter count\n0\n20\n40\n60\n80rougeLsum\nqa_wikidata\nBIG-G (0-shot)\nBIG-G (1-shot)\nBIG-G (2-shot)\nBIG-G (3-shot)\nBIG-G T=1 (0-shot)\nBIG-G T=1 (1-shot)\nBIG-G T=1 (2-shot)\nBIG-G T=1 (3-shot)\nBIG-G sparse (0-shot)\nBIG-G sparse (1-shot)\nBIG-G sparse (2-shot)\nBIG-G sparse (3-shot)\nGPT (0-shot)\nGPT (1-shot)\nGPT (2-shot)\nGPT (3-shot)\nPaLM (0-shot)\nPaLM (1-shot)\nPaLM (2-shot)\nPaLM (3-shot)\nBest rater\nAverage rater\n(d) qa_wikidata\n107\n108\n109\n1010\n1011\nEffective parameter count\n0\n20\n40\n60\n80\n100exact_str_match\nmodified_arithmetic:three_digit_subtraction_control\nBIG-G (0-shot)\nBIG-G (1-shot)\nBIG-G (2-shot)\nBIG-G (3-shot)\nBIG-G T=1 (0-shot)\nBIG-G T=1 (1-shot)\nBIG-G T=1 (2-shot)\nBIG-G T=1 (3-shot)\nBIG-G sparse (0-shot)\nBIG-G sparse (1-shot)\nBIG-G sparse (2-shot)\nBIG-G sparse (3-shot)\nGPT (0-shot)\nGPT (1-shot)\nGPT (2-shot)\nGPT (3-shot)\nPaLM (0-shot)\nPaLM (1-shot)\nPaLM (2-shot)\nPaLM (3-shot)\n(e) modified_arithmetic:\nthree_digit_subtraction_control\nFigure 9: Scaling Behavior of Tasks with HighestR2 Score. Figures are obtained from https://github.com/\ngoogle/BIG-bench\n7511\n107\n108\n109\n1010\n1011\nEffective parameter count\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30exact_str_match\nlinguistics_puzzles\nBIG-G (0-shot)\nBIG-G (1-shot)\nBIG-G (2-shot)\nBIG-G (3-shot)\nBIG-G T=1 (0-shot)\nBIG-G T=1 (1-shot)\nBIG-G T=1 (2-shot)\nBIG-G T=1 (3-shot)\nBIG-G sparse (0-shot)\nBIG-G sparse (1-shot)\nBIG-G sparse (2-shot)\nBIG-G sparse (3-shot)\nGPT (0-shot)\nGPT (1-shot)\nGPT (2-shot)\nGPT (3-shot)\nPaLM (0-shot)\nPaLM (1-shot)\nPaLM (2-shot)\nPaLM (3-shot)\nBest rater\nAverage rater\n(a) linguistics_puzzles\n107\n108\n109\n1010\n1011\nEffective parameter count\n0\n10\n20\n30\n40\n50\n60\n70exact_str_match\ncheckmate_in_one\nBIG-G (0-shot)\nBIG-G (1-shot)\nBIG-G (2-shot)\nBIG-G (3-shot)\nBIG-G T=1 (0-shot)\nBIG-G T=1 (1-shot)\nBIG-G T=1 (2-shot)\nBIG-G T=1 (3-shot)\nBIG-G sparse (0-shot)\nBIG-G sparse (1-shot)\nBIG-G sparse (2-shot)\nBIG-G sparse (3-shot)\nGPT (0-shot)\nGPT (1-shot)\nGPT (2-shot)\nGPT (3-shot)\nPaLM (0-shot)\nPaLM (1-shot)\nPaLM (2-shot)\nPaLM (3-shot)\nBest rater\nAverage rater (b) checkmate_in_one\n107\n108\n109\n1010\n1011\nEffective parameter count\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0exact_str_match\ngender_inclusive_sentences_german\nBIG-G (0-shot)\nBIG-G (1-shot)\nBIG-G (2-shot)\nBIG-G (3-shot)\nBIG-G T=1 (0-shot)\nBIG-G T=1 (1-shot)\nBIG-G T=1 (2-shot)\nBIG-G T=1 (3-shot)\nBIG-G sparse (0-shot)\nBIG-G sparse (1-shot)\nBIG-G sparse (2-shot)\nBIG-G sparse (3-shot)\nGPT (0-shot)\nGPT (1-shot)\nGPT (2-shot)\nGPT (3-shot)\nPaLM (0-shot)\nPaLM (1-shot)\nPaLM (2-shot)\nPaLM (3-shot)\nBest rater\nAverage rater\n(c) gender_inclusive\n_sentences_german\n107\n108\n109\n1010\n1011\nEffective parameter count\n0.0\n0.2\n0.4\n0.6\n0.8exact_str_match\nparagraph_segmentation\nBIG-G (0-shot)\nBIG-G (1-shot)\nBIG-G (2-shot)\nBIG-G (3-shot)\nBIG-G T=1 (0-shot)\nBIG-G T=1 (1-shot)\nBIG-G T=1 (2-shot)\nBIG-G T=1 (3-shot)\nBIG-G sparse (0-shot)\nBIG-G sparse (1-shot)\nBIG-G sparse (2-shot)\nBIG-G sparse (3-shot)\nGPT (0-shot)\nGPT (1-shot)\nGPT (2-shot)\nGPT (3-shot)\nBest rater\nAverage rater\n(d) paragraph_segmentation\n107\n108\n109\n1010\n1011\nEffective parameter count\n48.0\n48.5\n49.0\n49.5\n50.0\n50.5\n51.0\n51.5\n52.0multiple_choice_grade\nauthorship_verification:swapped\nBIG-G (0-shot)\nBIG-G (1-shot)\nBIG-G (2-shot)\nBIG-G (3-shot)\nBIG-G T=1 (0-shot)\nBIG-G T=1 (1-shot)\nBIG-G T=1 (2-shot)\nBIG-G T=1 (3-shot)\nBIG-G sparse (0-shot)\nBIG-G sparse (1-shot)\nBIG-G sparse (2-shot)\nBIG-G sparse (3-shot)\nPaLM (0-shot)\nPaLM (1-shot)\nPaLM (2-shot)\nPaLM (3-shot)\nRandom\n(e) authorship_verification:\nswapped\nFigure 10: Scaling Behavior of Tasks with LowestR2 Score. Figures are obtained from https://github.com/\ngoogle/BIG-bench\n7512\nG “Small-bench” Search Results\nG.1 BIG-bench Hard and BIG-bench Lite\nThe two subsets listed below slightly differ from the original subsets, because we filtered out several\nsubtasks as described in §A.\n1 {\n2 \" bblite \": [' bbq_lite_json : bbq_lite_json_age_ambig ', ' bbq_lite_json : bbq_lite_json_age_disambig ', '\nbbq_lite_json : bbq_lite_json_disability_status_ambig ', ' bbq_lite_json :\nbbq_lite_json_disability_status_disambig ', ' bbq_lite_json : bbq_lite_json_gender_identity_ambig ',\n' bbq_lite_json : bbq_lite_json_gender_identity_disambig ', ' bbq_lite_json :\nbbq_lite_json_nationality_ambig ', ' bbq_lite_json : bbq_lite_json_nationality_disambig ', '\nbbq_lite_json : bbq_lite_json_physical_appearance_ambig ', ' bbq_lite_json :\nbbq_lite_json_physical_appearance_disambig ', ' bbq_lite_json : bbq_lite_json_race_ethnicity_ambig '\n, ' bbq_lite_json : bbq_lite_json_race_ethnicity_disambig ', ' bbq_lite_json :\nbbq_lite_json_religion_ambig ', ' bbq_lite_json : bbq_lite_json_religion_disambig ', ' bbq_lite_json :\nbbq_lite_json_ses_ambig ', ' bbq_lite_json : bbq_lite_json_ses_disambig ', ' bbq_lite_json :\nbbq_lite_json_sexual_orientation_ambig ', ' bbq_lite_json :\nbbq_lite_json_sexual_orientation_disambig ', 'code_line_description ', ' conceptual_combinations :\nemergent_properties ', ' formal_fallacies_syllogisms_negation ', 'hindu_knowledge ', '\nlanguage_identification ', 'linguistics_puzzles ', 'logic_grid_puzzle ', ' logical_deduction :\nfive_objects ', ' logical_deduction : seven_objects ', ' logical_deduction : three_objects ', '\nnovel_concepts ', 'operators ', ' parsinlu_reading_comprehension ', ' play_dialog_same_or_different '\n, ' strange_stories : boolean ', ' strange_stories : multiple_choice ', 'strategyqa ', '\nsymbol_interpretation : adversarial ', ' symbol_interpretation : emoji_agnostic ', '\nsymbol_interpretation : name_agnostic ', ' symbol_interpretation : plain ', ' symbol_interpretation :\ntricky ', ' vitaminc_fact_verification ', 'winowhy '],\n3 \" bbhard \": ['causal_judgment ', 'date_understanding ', 'disambiguation_qa ', 'dyck_languages ', '\nformal_fallacies_syllogisms_negation ', 'geometric_shapes ', 'hyperbaton ', ' logical_deduction :\nfive_objects ', ' logical_deduction : seven_objects ', ' logical_deduction : three_objects ', '\nmovie_recommendation ', 'navigate ', 'object_counting ', 'penguins_in_a_table ', '\nreasoning_about_colored_objects ', 'ruin_names ', ' salient_translation_error_detection ', 'snarks '\n, 'sports_understanding ', 'temporal_sequences ', ' tracking_shuffled_objects : five_objects ', '\ntracking_shuffled_objects : seven_objects ', ' tracking_shuffled_objects : three_objects ', '\nword_sorting ']\n4 }\nG.2 Best of 5000\n1 {\n2 4: [ 'arithmetic :5 _digit_subtraction ', ' goal_step_wikihow : goal_inference ', ' linguistic_mappings :\npast_tense_irregular_json ', ' natural_instructions : subtask 027 _drop_answer_type_generation '],\n3 8: [ 'arithmetic :4 _digit_multiplication ', ' chess_state_tracking : real_medium ', ' elementary_math_qa :\nquestion_only ', ' linguistic_mappings : past_tense_regular_json ', ' natural_instructions : subtask 015\n_mctaco_question_generation_frequency ', ' natural_instructions : subtask 034\n_winogrande_question_modification_object ', ' natural_instructions : subtask 038 _qasc_combined_fact '\n, 'physics '],\n4 16: [ 'arithmetic :2 _digit_addition ', 'arithmetic :3 _digit_multiplication ', 'arithmetic :4\n_digit_subtraction ', ' bbq_lite_json : bbq_lite_json_gender_identity_ambig ', ' bbq_lite_json :\nbbq_lite_json_physical_appearance_disambig ', ' cause_and_effect : two_sentences ', '\nchess_state_tracking : real_medium ', ' chess_state_tracking : synthetic_medium ', 'gem : cs_restaurants\n', ' goal_step_wikihow : goal_inference ', ' international_phonetic_alphabet_nli ', '\nlinguistic_mappings : plural_regular_json ', ' natural_instructions : subtask 005\n_mctaco_wrong_answer_generation_event_duration ', ' natural_instructions : subtask 036\n_qasc_topic_word_to_generate_related_fact ', ' natural_instructions : subtask 055\n_multirc_write_incorrect_answer ', 'social_iqa '],\n5 24: [ 'anachronisms ', 'arithmetic :2 _digit_division ', 'arithmetic :3 _digit_division ', 'arithmetic :4\n_digit_subtraction ', ' bbq_lite_json : bbq_lite_json_physical_appearance_ambig ', 'dyck_languages ',\n' elementary_math_qa : question_with_language_hint ', 'gem : asset', 'implicatures ', '\nlinguistic_mappings : plural_json ', ' mathematical_induction ', 'mnist_ascii ', '\nnatural_instructions : subtask 014 _mctaco_wrong_answer_generation_absolute_timepoint ', '\nnatural_instructions : subtask 017 _mctaco_wrong_answer_generation_frequency ', '\nnatural_instructions : subtask 044 _essential_terms_identifying_essential_words ', '\nnatural_instructions : subtask 060 _ropes_question_generation ', ' natural_instructions : subtask 061\n_ropes_answer_generation ', 'navigate ', 'nonsense_words_grammar ', 'persian_idioms ', 'social_iqa '\n, ' strange_stories : multiple_choice ', ' unnatural_in_context_learning : dates ', 'winowhy '],\n6 32: [ ' abstract_narrative_understanding :4 _distractors ', 'arithmetic :2 _digit_division ', 'arithmetic :2\n_digit_subtraction ', 'arithmetic :3 _digit_addition ', 'arithmetic :3 _digit_division ', 'arithmetic :\n4 _digit_division ', 'arithmetic :5 _digit_addition ', ' bbq_lite_json :\nbbq_lite_json_gender_identity_disambig ', ' bridging_anaphora_resolution_barqa ', '\nchess_state_tracking : synthetic_long ', 'common_morpheme ', ' elementary_math_qa :\nquestion_with_mathematical_hint ', 'epistemic_reasoning ', 'gem : cs_restaurants ', '\nidentify_math_theorems ', 'implicatures ', ' intersect_geometry : shapes_ 4 ', 'kannada ', '\nlinguistic_mappings : past_tense_json ', ' linguistic_mappings : plural_json ', ' logical_deduction :\nthree_objects ', ' natural_instructions : subtask 005 _mctaco_wrong_answer_generation_event_duration '\n, ' natural_instructions : subtask 013 _mctaco_answer_generation_absolute_timepoint ', '\nnatural_instructions : subtask 020 _mctaco_span_based_question ', ' natural_instructions : subtask 023\n_cosmosqa_question_generation ', ' natural_instructions : subtask 035\n_winogrande_question_modification_person ', ' natural_instructions : subtask 045\n_miscellaneous_sentence_paraphrasing ', ' natural_instructions : subtask 054\n_multirc_write_correct_answer ', ' natural_instructions : subtask 056\n_multirc_classify_correct_answer ', ' unit_interpretation :lv0 ', ' unnatural_in_context_learning :\ndates_unnatural_content ', ' unnatural_in_context_learning : reverse_to_natural_content '],\n7513\n7 42: [ ' abstract_narrative_understanding :9 _distractors ', 'analogical_similarity ', 'arithmetic :2\n_digit_multiplication ', 'arithmetic :2 _digit_subtraction ', 'arithmetic :3 _digit_division ', '\narithmetic :5 _digit_addition ', ' bbq_lite_json : bbq_lite_json_age_disambig ', ' cause_and_effect :\ntwo_sentences ', 'color :hsl ', ' cs_algorithms :lcs ', ' cs_algorithms : valid_parentheses ', '\nelementary_math_qa : language_hint_only ', ' english_russian_proverbs ', 'fantasy_reasoning ', 'gem :\nwebnlg_en ', 'gem : webnlg_ru ', 'human_organs_senses ', 'intent_recognition ', ' intersect_geometry :\nshapes_ 3 ', ' linguistic_mappings : plural_json ', ' metaphor_understanding : met 2lit ', 'mnist_ascii ',\n' modified_arithmetic : three_digit_addition_control ', 'movie_recommendation ', '\nnatural_instructions : subtask 007 _mctaco_answer_generation_transient_stationary ', '\nnatural_instructions : subtask 016 _mctaco_answer_generation_frequency ', ' natural_instructions :\nsubtask 024 _cosmosqa_answer_generation ', ' natural_instructions : subtask 026\n_drop_question_generation ', ' natural_instructions : subtask 034\n_winogrande_question_modification_object ', ' natural_instructions : subtask 037\n_qasc_generate_related_fact ', ' natural_instructions : subtask 047 _misc_answering_science_questions\n', ' natural_instructions : subtask 049 _multirc_questions_needed_to_answer ', '\nparagraph_segmentation ', 'question_selection ', ' simple_ethical_questions ', 'social_iqa ', '\nstrange_stories : boolean ', ' swedish_to_german_proverbs ', ' symbol_interpretation : tricky ', '\ntracking_shuffled_objects : five_objects ', ' unit_interpretation :lv3 ', '\nunnatural_in_context_learning : unnatural_addition_ 2 _digit '],\n8 }\nG.3 Greedy Search\n1 {\n2 4: [ 'gem : cs_restaurants ', ' unnatural_in_context_learning : dates_unnatural_content ', '\nnatural_instructions : subtask 058 _multirc_question_answering ', ' presuppositions_as_nli '],\n3 8: [ 'gem : cs_restaurants ', ' unnatural_in_context_learning : dates_unnatural_content ', '\nnatural_instructions : subtask 058 _multirc_question_answering ', ' presuppositions_as_nli ', '\narithmetic :5 _digit_division ', ' evaluating_information_essentiality ', ' simp_turing_concept :\nadditional_set_ 2 ', ' linguistic_mappings : plural_regular_json '],\n4 16: [ 'gem : cs_restaurants ', ' unnatural_in_context_learning : dates_unnatural_content ', '\nnatural_instructions : subtask 058 _multirc_question_answering ', ' presuppositions_as_nli ', '\narithmetic :5 _digit_division ', ' evaluating_information_essentiality ', ' simp_turing_concept :\nadditional_set_ 2 ', ' linguistic_mappings : plural_regular_json ', 'gem : wikilingua_en ', 'gem :\ncommon_gen ', 'arithmetic :5 _digit_subtraction ', 'ruin_names ', 'gem : asset', ' unit_interpretation :\nlv2 ', ' bbq_lite_json : bbq_lite_json_disability_status_ambig ', 'physics '],\n5 24: [ 'gem : cs_restaurants ', ' unnatural_in_context_learning : dates_unnatural_content ', '\nnatural_instructions : subtask 058 _multirc_question_answering ', ' presuppositions_as_nli ', '\narithmetic :5 _digit_division ', ' evaluating_information_essentiality ', ' simp_turing_concept :\nadditional_set_ 2 ', ' linguistic_mappings : plural_regular_json ', 'gem : wikilingua_en ', 'gem :\ncommon_gen ', 'arithmetic :5 _digit_subtraction ', 'ruin_names ', 'gem : asset', ' unit_interpretation :\nlv2 ', ' bbq_lite_json : bbq_lite_json_disability_status_ambig ', 'physics ', ' real_or_fake_text :easy\n', ' strange_stories : multiple_choice ', 'penguins_in_a_table ', ' nonsense_words_grammar ', '\nconceptual_combinations : emergent_properties ', 'code_line_description ', 'logical_sequence ', '\nhhh_alignment : Helpfulness '],\n6 32: [ 'gem : cs_restaurants ', ' unnatural_in_context_learning : dates_unnatural_content ', '\nnatural_instructions : subtask 058 _multirc_question_answering ', ' presuppositions_as_nli ', '\narithmetic :5 _digit_division ', ' evaluating_information_essentiality ', ' simp_turing_concept :\nadditional_set_ 2 ', ' linguistic_mappings : plural_regular_json ', 'gem : wikilingua_en ', 'gem :\ncommon_gen ', 'arithmetic :5 _digit_subtraction ', 'ruin_names ', 'gem : asset', ' unit_interpretation :\nlv2 ', ' bbq_lite_json : bbq_lite_json_disability_status_ambig ', 'physics ', ' real_or_fake_text :easy\n', ' strange_stories : multiple_choice ', 'penguins_in_a_table ', ' nonsense_words_grammar ', '\nconceptual_combinations : emergent_properties ', 'code_line_description ', 'logical_sequence ', '\nhhh_alignment : Helpfulness ', ' linguistic_mappings : pronoun_replacement_json ', 'gem :xsum ', '\ncs_algorithms :lcs ', ' chess_state_tracking : real_long ', ' unnatural_in_context_learning : dates ', '\nentailed_polarity_hindi ', ' bbq_lite_json : bbq_lite_json_nationality_ambig ', '\nnatural_instructions : subtask 023 _cosmosqa_question_generation '],\n7 42: [ 'gem : cs_restaurants ', ' unnatural_in_context_learning : dates_unnatural_content ', '\nnatural_instructions : subtask 058 _multirc_question_answering ', ' presuppositions_as_nli ', '\narithmetic :5 _digit_division ', ' evaluating_information_essentiality ', ' simp_turing_concept :\nadditional_set_ 2 ', ' linguistic_mappings : plural_regular_json ', 'gem : wikilingua_en ', 'gem :\ncommon_gen ', 'arithmetic :5 _digit_subtraction ', 'ruin_names ', 'gem : asset', ' unit_interpretation :\nlv2 ', ' bbq_lite_json : bbq_lite_json_disability_status_ambig ', 'physics ', ' real_or_fake_text :easy\n', ' strange_stories : multiple_choice ', 'penguins_in_a_table ', ' nonsense_words_grammar ', '\nconceptual_combinations : emergent_properties ', 'code_line_description ', 'logical_sequence ', '\nhhh_alignment : Helpfulness ', ' linguistic_mappings : pronoun_replacement_json ', 'gem :xsum ', '\ncs_algorithms :lcs ', ' chess_state_tracking : real_long ', ' unnatural_in_context_learning : dates ', '\nentailed_polarity_hindi ', ' bbq_lite_json : bbq_lite_json_nationality_ambig ', '\nnatural_instructions : subtask 023 _cosmosqa_question_generation ', ' natural_instructions : subtask 004\n_mctaco_answer_generation_event_duration ', 'question_selection ', ' simp_turing_concept :\nadditional_set_ 1 ', 'matrixshapes ', ' movie_dialog_same_or_different ', ' natural_instructions :\nsubtask 021 _mctaco_grammatical_logical ', 'arithmetic :4 _digit_division ', ' natural_instructions :\nsubtask 061 _ropes_answer_generation ', ' modified_arithmetic : three_digit_subtraction_control ', '\ndate_understanding ']\n8 }\nG.4 Beam Search (q=4, p=1/4)\n1 {\n2 4: [ 'implicatures ', ' natural_instructions : subtask 049 _multirc_questions_needed_to_answer ', '\nlinguistic_mappings : past_tense_json ', ' natural_instructions : subtask 035\n_winogrande_question_modification_person '],\n7514\n3 8: [ 'implicatures ', ' natural_instructions : subtask 049 _multirc_questions_needed_to_answer ', '\nlinguistic_mappings : past_tense_json ', ' natural_instructions : subtask 057\n_multirc_classify_incorrect_answer ', 'gem :e2 e_nlg', 'arithmetic :5 _digit_subtraction ', '\nlogical_deduction : seven_objects ', ' bbq_lite_json : bbq_lite_json_nationality_ambig '],\n4 16: [ 'implicatures ', ' natural_instructions : subtask 049 _multirc_questions_needed_to_answer ', '\nlinguistic_mappings : past_tense_json ', ' natural_instructions : subtask 057\n_multirc_classify_incorrect_answer ', 'gem :e2 e_nlg', 'arithmetic :5 _digit_subtraction ', '\nlogical_deduction : seven_objects ', 'cryobiology_spanish ', ' vitaminc_fact_verification ', '\nqa_wikidata ', ' abstract_narrative_understanding :4 _distractors ', ' linguistic_mappings :\nplural_json ', ' symbol_interpretation : emoji_agnostic ', ' elementary_math_qa :\nquestion_with_mathematical_hint ', ' simp_turing_concept : additional_set_ 2 ', ' elementary_math_qa :\nquestion_only '],\n5 24: [ 'implicatures ', ' natural_instructions : subtask 049 _multirc_questions_needed_to_answer ', '\nlinguistic_mappings : past_tense_json ', ' natural_instructions : subtask 057\n_multirc_classify_incorrect_answer ', 'gem :e2 e_nlg', 'arithmetic :5 _digit_subtraction ', '\nlogical_deduction : seven_objects ', 'cryobiology_spanish ', ' vitaminc_fact_verification ', '\nqa_wikidata ', ' abstract_narrative_understanding :4 _distractors ', ' linguistic_mappings :\nplural_json ', ' symbol_interpretation : emoji_agnostic ', ' elementary_math_qa :\nquestion_with_mathematical_hint ', ' simp_turing_concept : additional_set_ 2 ', ' elementary_math_qa :\nquestion_only ', ' natural_instructions : subtask 004 _mctaco_answer_generation_event_duration ', '\nempirical_judgments ', ' gre_reading_comprehension ', ' logical_deduction : three_objects ', '\narithmetic :4 _digit_subtraction ', ' hhh_alignment : Harms ', ' bbq_lite_json :\nbbq_lite_json_nationality_ambig ', ' natural_instructions : subtask 025\n_cosmosqa_incorrect_answer_generation '],\n6 32: [ 'implicatures ', ' natural_instructions : subtask 049 _multirc_questions_needed_to_answer ', '\nlinguistic_mappings : past_tense_json ', ' natural_instructions : subtask 057\n_multirc_classify_incorrect_answer ', 'gem :e2 e_nlg', 'arithmetic :5 _digit_subtraction ', '\nlogical_deduction : seven_objects ', 'cryobiology_spanish ', ' vitaminc_fact_verification ', '\nqa_wikidata ', ' abstract_narrative_understanding :4 _distractors ', ' linguistic_mappings :\nplural_json ', ' symbol_interpretation : emoji_agnostic ', ' elementary_math_qa :\nquestion_with_mathematical_hint ', ' simp_turing_concept : additional_set_ 2 ', ' elementary_math_qa :\nquestion_only ', ' natural_instructions : subtask 004 _mctaco_answer_generation_event_duration ', '\nempirical_judgments ', ' gre_reading_comprehension ', ' logical_deduction : three_objects ', '\nelementary_math_qa : language_hint_only ', 'cifar 10 _classification : base 64 ', '\nmathematical_induction ', 'arithmetic :2 _digit_subtraction ', ' unnatural_in_context_learning :\nidentity ', ' natural_instructions : subtask 054 _multirc_write_correct_answer ', 'logical_sequence ',\n'arithmetic :5 _digit_multiplication ', 'persian_idioms ', ' linguistic_mappings :\npast_tense_regular_json ', ' periodic_elements : subtask_ 1 ', ' parsinlu_reading_comprehension '],\n7 42: [ 'implicatures ', ' natural_instructions : subtask 049 _multirc_questions_needed_to_answer ', '\nlinguistic_mappings : past_tense_json ', ' natural_instructions : subtask 057\n_multirc_classify_incorrect_answer ', 'gem :e2 e_nlg', 'arithmetic :5 _digit_subtraction ', '\nlogical_deduction : seven_objects ', 'cryobiology_spanish ', ' vitaminc_fact_verification ', '\nqa_wikidata ', ' abstract_narrative_understanding :4 _distractors ', ' linguistic_mappings :\nplural_json ', ' symbol_interpretation : emoji_agnostic ', ' elementary_math_qa :\nquestion_with_mathematical_hint ', ' simp_turing_concept : additional_set_ 2 ', ' elementary_math_qa :\nquestion_only ', ' natural_instructions : subtask 004 _mctaco_answer_generation_event_duration ', '\nempirical_judgments ', ' gre_reading_comprehension ', ' logical_deduction : three_objects ', '\nelementary_math_qa : language_hint_only ', 'cifar 10 _classification : base 64 ', '\nmathematical_induction ', 'arithmetic :2 _digit_subtraction ', ' unnatural_in_context_learning :\nidentity ', ' natural_instructions : subtask 054 _multirc_write_correct_answer ', 'logical_sequence ',\n'arithmetic :5 _digit_multiplication ', ' natural_instructions : subtask 055\n_multirc_write_incorrect_answer ', ' natural_instructions : subtask 034\n_winogrande_question_modification_object ', 'arithmetic :3 _digit_addition ', ' natural_instructions\n: subtask 016 _mctaco_answer_generation_frequency ', ' language_identification ', 'crass_ai ', '\nnatural_instructions : subtask 050 _multirc_answerability ', 'persian_idioms ', 'disambiguation_qa ',\n'gem : asset', 'dark_humor_detection ', 'arithmetic :4 _digit_addition ', '\ninternational_phonetic_alphabet_nli ', ' natural_instructions : subtask 008\n_mctaco_wrong_answer_generation_transient_stationary ']\n8 }\nG.5 k-means\nThe numbers reported in Fig. 6 is the average of 5 runs. We ran the k-means algorithms with 5 different\nrandom initialization. In the following we list the “small-bench” candidates from 1 run. The same applies\nto “k-means + Task Value” results.\n1 {\n2 4: [ 'anachronisms ', ' natural_instructions : subtask 032 _winogrande_question_generation_person ', '\nlinguistic_mappings : de_past_tense_regular_json ',' natural_instructions : subtask 033\n_winogrande_answer_generation ']\",\n3 8: [ 'anachronisms ', ' natural_instructions : subtask 026 _drop_question_generation ', 'arithmetic :5\n_digit_addition ', ' linguistic_mappings : question_formation_json ', ' natural_instructions : subtask 0\n30 _winogrande_full_person ', ' bbq_lite_json : bbq_lite_json_ses_disambig ', ' natural_instructions :\nsubtask 039 _qasc_find_overlapping_words ', ' linguistic_mappings : de_past_tense_regular_json ']\",\n4 16: [ 'anachronisms ', ' symbol_interpretation : plain ', 'arithmetic :5 _digit_addition ', '\nlinguistic_mappings : past_tense_regular_json ', ' natural_instructions : subtask 031\n_winogrande_question_generation_object ', ' bbq_lite_json : bbq_lite_json_ses_disambig ', '\nnatural_instructions : subtask 039 _qasc_find_overlapping_words ', ' modified_arithmetic :\ntwo_digit_multiplication_plus_one ', ' bbq_lite_json : bbq_lite_json_nationality_ambig ', '\nchess_state_tracking : real_medium ', ' linguistic_mappings : de_past_tense_regular_json ', '\nnatural_instructions : subtask 032 _winogrande_question_generation_person ', ' natural_instructions :\nsubtask 041 _qasc_answer_generation ', 'gem :turk ', ' unnatural_in_context_learning :\ndates_unnatural_content ', ' natural_instructions : subtask 048 _multirc_question_generation ']\",\n7515\n5 24: [ 'anachronisms ', ' real_or_fake_text :easy ', 'arithmetic :5 _digit_addition ', 'gem : webnlg_en ', '\nnatural_instructions : subtask 049 _multirc_questions_needed_to_answer ', ' linguistic_mappings :\npast_tense_regular_json ', ' bbq_lite_json : bbq_lite_json_nationality_ambig ', 'gem :xsum ', '\ntracking_shuffled_objects : seven_objects ', ' natural_instructions : subtask 019\n_mctaco_temporal_reasoning_category ', ' natural_instructions : subtask 024\n_cosmosqa_answer_generation ', ' natural_instructions : subtask 030 _winogrande_full_person ', '\nchess_state_tracking : synthetic_medium ', ' natural_instructions : subtask 045\n_miscellaneous_sentence_paraphrasing ', ' unnatural_in_context_learning :\nreverse_to_natural_content ', ' authorship_verification : swapped ', ' natural_instructions : subtask 03\n9 _qasc_find_overlapping_words ', ' modified_arithmetic : two_digit_multiplication_control ', '\nbbq_lite_json : bbq_lite_json_sexual_orientation_disambig ', ' abstract_narrative_understanding :9\n_distractors ', 'color :hsl ', ' fact_checker : fever ', 'tense ', ' intersect_geometry : shapes_ 4 ']\",\n6 32: [ 'anachronisms ', ' real_or_fake_text :easy ', 'arithmetic :5 _digit_division ', 'gem : webnlg_en ', '\nnatural_instructions : subtask 049 _multirc_questions_needed_to_answer ', ' linguistic_mappings :\npast_tense_json ', ' bbq_lite_json : bbq_lite_json_nationality_ambig ', 'gem :xsum ', '\ntracking_shuffled_objects : seven_objects ', ' natural_instructions : subtask 020\n_mctaco_span_based_question ', ' natural_instructions : subtask 032\n_winogrande_question_generation_person ', ' natural_instructions : subtask 032\n_winogrande_question_generation_person ', ' natural_instructions : subtask 003\n_mctaco_question_generation_event_duration ', ' natural_instructions : subtask 045\n_miscellaneous_sentence_paraphrasing ', ' unnatural_in_context_learning : reverse_natural_content ',\n' authorship_verification : swapped ', ' goal_step_wikihow : goal_inference ', ' modified_arithmetic :\ntwo_digit_multiplication_control ', ' bbq_lite_json : bbq_lite_json_sexual_orientation_disambig ', '\nabstract_narrative_understanding :9 _distractors ', 'color :hsl ', ' fact_checker : fever ', 'tense ', '\nintersect_geometry : shapes_ 4 ', ' unnatural_in_context_learning : dates_unnatural_content ', '\nnatural_instructions : subtask 048 _multirc_question_generation ', 'hyperbaton ', '\nsymbol_interpretation : plain ', 'arithmetic :5 _digit_addition ', ' chess_state_tracking : real_medium '\n, ' simp_turing_concept : additional_set_ 1 ', 'physics ']\",\n7 42: [ 'anachronisms ', ' real_or_fake_text :easy ', 'arithmetic :5 _digit_division ', 'gem : webnlg_en ', '\nnatural_instructions : subtask 039 _qasc_find_overlapping_words ', ' linguistic_mappings :\npast_tense_json ', ' bbq_lite_json : bbq_lite_json_nationality_ambig ', 'gem :xsum ', '\ntracking_shuffled_objects : seven_objects ', ' natural_instructions : subtask 019\n_mctaco_temporal_reasoning_category ', ' natural_instructions : subtask 017\n_mctaco_wrong_answer_generation_frequency ', ' natural_instructions : subtask 030\n_winogrande_full_person ', ' natural_instructions : subtask 003\n_mctaco_question_generation_event_duration ', ' natural_instructions : subtask 045\n_miscellaneous_sentence_paraphrasing ', ' unnatural_in_context_learning : reverse_natural_content ',\n' authorship_verification : swapped ', ' goal_step_wikihow : goal_inference ', ' modified_arithmetic :\ntwo_digit_multiplication_control ', ' bbq_lite_json : bbq_lite_json_physical_appearance_disambig ',\n' abstract_narrative_understanding :9 _distractors ', 'color :hex ', ' fact_checker : fever ', 'tense ', '\nlinguistic_mappings : de_past_tense_regular_json ', ' unnatural_in_context_learning :\ndates_unnatural_content ', ' natural_instructions : subtask 026 _drop_question_generation ', '\nhyperbaton ', ' symbol_interpretation : plain ', 'arithmetic :5 _digit_addition ', '\nchess_state_tracking : real_medium ', ' simp_turing_concept : additional_set_ 1 ', 'physics ', 'cifar 10\n_classification : base 64 ', ' intersect_geometry : shapes_ 4 ', ' elementary_math_qa :\nquestion_with_language_hint ', ' goal_step_wikihow : step_inference ', ' unit_conversion :\nunit_identification ', ' natural_instructions : subtask 056 _multirc_classify_correct_answer ', '\nstrange_stories : multiple_choice ', ' discourse_marker_prediction ', ' bbq_lite_json :\nbbq_lite_json_religion_disambig ', ' natural_instructions : subtask 024 _cosmosqa_answer_generation ']\n\"\n8 }\nG.6 k-means + Task Value\n1 {\n2 4: [ ' bbq_lite_json : bbq_lite_json_sexual_orientation_disambig ', ' natural_instructions : subtask 029\n_winogrande_full_object ', 'gem :xsum ', ' linguistic_mappings : question_formation_json ']\",\n3 8: [ 'hyperbaton ', ' natural_instructions : subtask 026 _drop_question_generation ', 'arithmetic :5\n_digit_addition ', ' linguistic_mappings : question_formation_json ', ' natural_instructions : subtask 0\n29 _winogrande_full_object ', ' bbq_lite_json : bbq_lite_json_sexual_orientation_disambig ', '\nnatural_instructions : subtask 003 _mctaco_question_generation_event_duration ', 'gem :xsum ']\",\n4 16: [ 'hyperbaton ', ' real_or_fake_text : gpt 2_xl ', 'arithmetic :5 _digit_addition ', ' linguistic_mappings :\npast_tense_regular_json ', ' natural_instructions : subtask 029 _winogrande_full_object ', '\nbbq_lite_json : bbq_lite_json_sexual_orientation_disambig ', ' goal_step_wikihow : goal_inference ', '\nperiodic_elements : subtask_ 1 ', ' bbq_lite_json : bbq_lite_json_physical_appearance_ambig ', '\nchess_state_tracking : synthetic_long ', ' intersect_geometry : shapes_ 4 ', ' natural_instructions :\nsubtask 025 _cosmosqa_incorrect_answer_generation ', ' natural_instructions : subtask 002\n_quoref_answer_generation ', 'gem :turk ', ' unnatural_in_context_learning : dates_unnatural_content '\n, ' natural_instructions : subtask 048 _multirc_question_generation ']\",\n5 24: [ 'snarks ', ' real_or_fake_text : gpt 2_xl ', 'arithmetic :5 _digit_addition ', ' simp_turing_concept :\nadditional_set_ 2 ', ' natural_instructions : subtask 048 _multirc_question_generation ', '\nlinguistic_mappings : past_tense_regular_json ', ' bbq_lite_json :\nbbq_lite_json_physical_appearance_ambig ', 'gem :xsum ', 'analogical_similarity ', '\nnatural_instructions : subtask 019 _mctaco_temporal_reasoning_category ', ' natural_instructions :\nsubtask 025 _cosmosqa_incorrect_answer_generation ', ' natural_instructions : subtask 029\n_winogrande_full_object ', ' chess_state_tracking : real_short ', ' natural_instructions : subtask 045\n_miscellaneous_sentence_paraphrasing ', ' unnatural_in_context_learning :\nreverse_to_natural_content ', 'hyperbaton ', ' goal_step_wikihow : goal_inference ', '\nmodified_arithmetic : two_digit_multiplication_control ', ' bbq_lite_json :\nbbq_lite_json_sexual_orientation_disambig ', ' nonsense_words_grammar ', '\ndiscourse_marker_prediction ', 'implicatures ', ' ascii_word_recognition ', ' intersect_geometry :\nshapes_ 4 ']\",\n6 32: [ 'anachronisms ', ' real_or_fake_text : gpt 2_xl ', 'arithmetic :3 _digit_division ', '\nplay_dialog_same_or_different ', ' natural_instructions : subtask 058 _multirc_question_answering ', '\nlinguistic_mappings : past_tense_json ', ' bbq_lite_json : bbq_lite_json_physical_appearance_ambig ',\n7516\n'gem :xsum ', 'analogical_similarity ', ' natural_instructions : subtask 020\n_mctaco_span_based_question ', ' natural_instructions : subtask 025\n_cosmosqa_incorrect_answer_generation ', ' minute_mysteries_qa : multiplechoice ', '\nnatural_instructions : subtask 003 _mctaco_question_generation_event_duration ', '\nnatural_instructions : subtask 045 _miscellaneous_sentence_paraphrasing ', '\nunnatural_in_context_learning : reverse_to_natural_content ', ' authorship_verification : swapped ', '\ngoal_step_wikihow : goal_inference ', ' modified_arithmetic : two_digit_multiplication_control ', '\nbbq_lite_json : bbq_lite_json_sexual_orientation_disambig ', ' figure_of_speech_detection ', '\ndiscourse_marker_prediction ', 'implicatures ', ' ascii_word_recognition ', ' intersect_geometry :\nshapes_ 4 ', ' unnatural_in_context_learning : dates_unnatural_content ', ' natural_instructions :\nsubtask 048 _multirc_question_generation ', 'hyperbaton ', ' symbol_interpretation : plain ', '\narithmetic :5 _digit_addition ', ' chess_state_tracking : synthetic_long ', ' simp_turing_concept :\nadditional_set_ 1 ', 'human_organs_senses ']\",\n7 42: [ 'anachronisms ', ' real_or_fake_text : gpt 2_xl ', 'arithmetic :3 _digit_division ', '\nplay_dialog_same_or_different ', ' natural_instructions : subtask 047\n_misc_answering_science_questions ', ' linguistic_mappings : past_tense_json ', ' bbq_lite_json :\nbbq_lite_json_physical_appearance_ambig ', 'gem :xsum ', ' tracking_shuffled_objects : seven_objects '\n, ' natural_instructions : subtask 019 _mctaco_temporal_reasoning_category ', ' natural_instructions :\nsubtask 017 _mctaco_wrong_answer_generation_frequency ', ' natural_instructions : subtask 029\n_winogrande_full_object ', ' natural_instructions : subtask 003\n_mctaco_question_generation_event_duration ', ' natural_instructions : subtask 045\n_miscellaneous_sentence_paraphrasing ', ' unnatural_in_context_learning :\nreverse_to_natural_content ', ' authorship_verification : swapped ', ' goal_step_wikihow :\ngoal_inference ', ' modified_arithmetic : two_digit_multiplication_control ', ' bbq_lite_json :\nbbq_lite_json_physical_appearance_disambig ', ' figure_of_speech_detection ', 'color :hex ', '\nimplicatures ', ' ascii_word_recognition ', ' linguistic_mappings : de_past_tense_regular_json ', '\nunnatural_in_context_learning : dates_unnatural_content ', ' natural_instructions : subtask 026\n_drop_question_generation ', 'hyperbaton ', ' symbol_interpretation : plain ', 'arithmetic :5\n_digit_addition ', ' chess_state_tracking : synthetic_long ', ' simp_turing_concept : additional_set_ 1 '\n, 'physics ', 'cifar 10 _classification : base 64 ', ' intersect_geometry : shapes_ 4 ', '\nelementary_math_qa : question_with_language_hint ', ' goal_step_wikihow : step_inference ', '\nunit_conversion : unit_identification ', ' natural_instructions : subtask 056\n_multirc_classify_correct_answer ', ' strange_stories : boolean ', ' discourse_marker_prediction ', '\nbbq_lite_json : bbq_lite_json_religion_disambig ', ' natural_instructions : subtask 025\n_cosmosqa_incorrect_answer_generation ']\"\n7517",
  "topic": "Predictability",
  "concepts": [
    {
      "name": "Predictability",
      "score": 0.7367293834686279
    },
    {
      "name": "Computer science",
      "score": 0.735149085521698
    },
    {
      "name": "Cluster analysis",
      "score": 0.6107559204101562
    },
    {
      "name": "Task (project management)",
      "score": 0.6095484495162964
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5880361795425415
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.5784726142883301
    },
    {
      "name": "Big data",
      "score": 0.5768611431121826
    },
    {
      "name": "Machine learning",
      "score": 0.5240141153335571
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5038041472434998
    },
    {
      "name": "Test bench",
      "score": 0.48207026720046997
    },
    {
      "name": "Centroid",
      "score": 0.4689442813396454
    },
    {
      "name": "Language model",
      "score": 0.42087921500205994
    },
    {
      "name": "Data mining",
      "score": 0.3779641389846802
    },
    {
      "name": "Natural language processing",
      "score": 0.33643263578414917
    },
    {
      "name": "Statistics",
      "score": 0.11983513832092285
    },
    {
      "name": "Mathematics",
      "score": 0.1055971086025238
    },
    {
      "name": "Engineering",
      "score": 0.08243873715400696
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Embedded system",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1174212",
      "name": "University of Southern California",
      "country": "US"
    }
  ],
  "cited_by": 7
}