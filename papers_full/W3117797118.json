{
  "title": "GPolS: A Contextual Graph-Based Language Model for Analyzing Parliamentary Debates and Political Cohesion",
  "url": "https://openalex.org/W3117797118",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2809845840",
      "name": "Ramit Sawhney",
      "affiliations": [
        "Netaji Subhas University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3102361898",
      "name": "Arnav Wadhwa",
      "affiliations": [
        "Indian Institute of Technology Delhi",
        "Indraprastha Institute of Information Technology Delhi",
        "Midas Multispeciality Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2325138078",
      "name": "Shivam Agarwal",
      "affiliations": [
        "Manipal Academy of Higher Education"
      ]
    },
    {
      "id": "https://openalex.org/A2117028084",
      "name": "Rajiv Ratn Shah",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2807860467",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2758632539",
    "https://openalex.org/W1593113005",
    "https://openalex.org/W2143398792",
    "https://openalex.org/W2345368148",
    "https://openalex.org/W2954211942",
    "https://openalex.org/W2145958021",
    "https://openalex.org/W2577993056",
    "https://openalex.org/W132082782",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W2980844465",
    "https://openalex.org/W4235264716",
    "https://openalex.org/W2135257872",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2788706835",
    "https://openalex.org/W4295161156",
    "https://openalex.org/W2110450891",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2933100986",
    "https://openalex.org/W2077135037",
    "https://openalex.org/W2126708686",
    "https://openalex.org/W3029204180",
    "https://openalex.org/W2563476909",
    "https://openalex.org/W2251159224",
    "https://openalex.org/W4234782269",
    "https://openalex.org/W2974926830",
    "https://openalex.org/W2807529348",
    "https://openalex.org/W2895021214",
    "https://openalex.org/W2797669327",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2095705004",
    "https://openalex.org/W2953092389",
    "https://openalex.org/W4233415207",
    "https://openalex.org/W2163046677",
    "https://openalex.org/W2474059332",
    "https://openalex.org/W2766453196",
    "https://openalex.org/W4312691474",
    "https://openalex.org/W2003914049",
    "https://openalex.org/W2949537154",
    "https://openalex.org/W1995517447",
    "https://openalex.org/W1605860798",
    "https://openalex.org/W2995896027",
    "https://openalex.org/W1881549354",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2842153692",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W2051434435",
    "https://openalex.org/W2980708516",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W3015468748",
    "https://openalex.org/W3037689348",
    "https://openalex.org/W3034936923",
    "https://openalex.org/W1536205469",
    "https://openalex.org/W1562827282",
    "https://openalex.org/W2131244513",
    "https://openalex.org/W2737923628",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2788605280",
    "https://openalex.org/W3035096916",
    "https://openalex.org/W2974794596",
    "https://openalex.org/W2951592338",
    "https://openalex.org/W2963757738",
    "https://openalex.org/W2740855839",
    "https://openalex.org/W2963716420",
    "https://openalex.org/W2966287263",
    "https://openalex.org/W2960532269",
    "https://openalex.org/W4249993242",
    "https://openalex.org/W2891746463",
    "https://openalex.org/W1591177804",
    "https://openalex.org/W2925863688",
    "https://openalex.org/W2899675781",
    "https://openalex.org/W2807828381",
    "https://openalex.org/W1538750993",
    "https://openalex.org/W560287614",
    "https://openalex.org/W1501467168",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3124530552",
    "https://openalex.org/W4253236115",
    "https://openalex.org/W2964965220",
    "https://openalex.org/W4297733535"
  ],
  "abstract": "Parliamentary debates present a valuable language resource for analyzing comprehensive options in electing representatives under a functional, free society. However, the esoteric nature of political speech coupled with non-linguistic aspects such as political cohesion between party members presents a complex and underexplored task of contextual parliamentary debate analysis. We introduce GPolS, a neural model for political speech sentiment analysis jointly exploiting both semantic language representations and relations between debate transcripts, motions, and political party members. Through experiments on real-world English data and by visualizing attention, we provide a use case of GPolS as a tool for political speech analysis and polarity prediction.",
  "full_text": "Proceedings of the 28th International Conference on Computational Linguistics, pages 4847–4859\nBarcelona, Spain (Online), December 8-13, 2020\n4847\nGPolS: A Contextual Graph-Based Language Model for Analyzing\nParliamentary Debates and Political Cohesion\nRamit Sawhney\nNetaji Subhas Institute of Technology\nramits.co@nsit.net.in\nArnav Wadhwa\nMIDAS, IIIT Delhi\narnavw96@gmail.com\nShivam Agarwal\nManipal Institute of Technology\nshivamag99@gmail.com\nRajiv Ratn Shah\nMIDAS, IIIT Delhi\nrajivratn@iiitd.ac.in\nAbstract\nParliamentary debates present a valuable language resource for analyzing comprehensive op-\ntions in electing representatives under a functional, free society. However, the esoteric nature\nof political speech coupled with non-linguistic aspects such as political cohesion between party\nmembers presents a complex and underexplored task of contextual parliamentary debate analy-\nsis. We introduce GPolS, a neural model for political speech stance analysis jointly exploiting\nboth semantic language representations and relations between debate transcripts, motions, and\npolitical party members. Through experiments on real-world English data, we provide a use case\nof GPolS as a tool for political speech analysis and polarity prediction.\n1 Introduction\nPolitics is broadly deﬁned as the set of activities associated with the governance of a country or a re-\ngion. It involves various aspects that inﬂuence critical decisions having national importance. One such\naspect is the conduct of parliamentary debates between political parties having ruling and opposition\npower. These debates discuss matters affecting the future development of a nation, such as economic\nand societal growth, policy reforms, and budget revisions. Records of such debates act as a valuable lan-\nguage resource as they provide a wealth of information regarding viewpoints of political representatives\nover critical societal factors (Abercrombie and Batista-Navarro, 2020b), and also for assessing political\ncandidates and basing voting decisions (Utych, 2019).\nAnalyzing sentiment in such political discourse is propelled by the developments in ﬁelds like behav-\nioral economics that bring the psychological aspects of parliamentary decision-making to the forefront\n(Rheault, 2016). However, under Parliament’sRules of Behavior,1 the language used in political debates\nis complex, laden with domain-speciﬁc procedural jargon used in the political realm, and obscure (Aber-\ncrombie and Batista-Navarro, 2018a). This esoteric and tedious nature of political debates makes their\nanalysis complex, forming a barrier to ordinary citizen’s insights into political stances and wide-ranging\nconsequences they entail (Edelman, 1985).\nThe good news is that natural language processing (NLP) shows promise for analyzing voluminous\npolitical debates and breaking the understanding barrier towards political ideology to help make informed\nvoting decisions (Davoodi et al., 2020; Eidelman et al., 2018). However, conventional language models\n(Hasan and Ng, 2013) may not generalize well on understanding the obscure linguistic styles of political\ndebates. This complexity arises due to the lack of political context and procedural parliamentary jargon\nin generic corpora over which traditional text representation models are trained (Pennington et al., 2014;\nBojanowski et al., 2017). For instance, in the political context, Red State is a state that primarily votes\nfor Republicans, whereas a Blue State votes primarily for Democrats. Leveraging the success of unsu-\npervised pre-training in NLP (Devlin et al., 2019; Liu et al., 2019), ﬁne-tuning pre-trained models over\nthe voluminous debate transcripts can lead to drastic advances in analyzing political debates.\nThis work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://\ncreativecommons.org/licenses/by/4.0/.\n1https://www.parliament.uk/documents/rules-of-behaviour.pdf\n4848\nU1 U2Peter Aldous Richard DraxConservative Party\nPOLICE GRANT REPORT\nI beg to move, That the Police Grant Report \n(England and Wales) for 2018-19 (HC 745), \nwhich was laid before this House on 31 \nJanuary, be approved.\nU3\nDEFENCE REFORMS\nI beg to move, this House notes concerns about the \nGovernment’s defence reforms in relation to whether \nits proposals for the reserve forces will deliver \nanticipated cost saving savings or defence \ncapability...\nMotion Context\n… I am a former soldie r, and \nholding the land is where we \ngained information and \nintelligence… Those crimes would \nnot be committed if there were a \npolice presence on the ground …I \nbelieve the overseas aid  budget \nwill balloon to some £ 20 billion in \n2020 … I have absolutely no \nobjection to money going to \noverseas aid , but I object … \ncharity starts at home…  I urge the \nGovernment and any right -minded \nperson to consider the target.\n… During my nine years in the \nArmy... Their contributions to \nmany recent operations from \nAfghanistan to Iraq leaves us in no \ndoubt of their valour . Today’s \nconflicts require troops to  hit the \nground running  … Government \nargue that they inherited \nmultibillion pound hole in defence \nbudget ...while starving the \norganisations that defend our \ncountry. I have no problem giving \nmoney to overseas aid , but I \nthink… Charity starts at home , \nespecially in austere times …\nT1 T2 T3 T4… I have seen our reservists in \naction in Iraq and Afghanistan, and \nI think everyone in the House \nwould like to thank them … the \nreason for a gap is previous \nLabour Governments multibillion \nblack hole in the finances … it \nwould go up to £ 36 billion… the \nGovernment reduced the defence \nbudget by 9%… it is not \nacceptable when the defence of our \ncountry is at stake …Unless \nMinisters change tack now , the \ndefence capability of this country \ncould be at dire risk.\nKevan Jones\nLabour Party\n… Setting police presence and \nbudgets for 2018-19 has been a \nreal challenge both for the \nGovernment and for local forces \nsuch as Suffolk constabulary … \nhighest caseload per officer in the \ncountry… yet receives one of the \nlowest funding settlements … has \nto contend with a wide variety of \nmodern pressures … events that \ncan never be predicted will take \nplace… I urge the Government to \ninstigate the funding review \nwithout further delay and as \nquickly as possible.\nIntra-Party Context\nPoliticiansSpeech TranscriptsMotions\nSpeaker-Self Context\nabc\nabc\nText Color What it represents\nSpeaker-Self Context: \nSimilarity in speeches of a \nspeaker across different motions\nMotion Context:\nSimilarity in speeches of different \nspeakers over the same motion\nM1 M2abc Intra-Party Context:\nSimilarity in stance adoption\nFigure 1: Four debate transcripts from the UK Parliament’s House of Commons, over two different\nmotions. The colors indicate similarity between transcripts based across three different contexts.\nThe challenging aspect is that analyzing political debates involves multiple contextual elements be-\nyond language, such as political party afﬁliations and topics of the debates. Consider Figure 1, where\nwe present four speech transcripts over two different motions, from the UK House of Commons. The\nﬁrst two transcripts, T1 and T2 over the ”Police Grant Report” motion, are from members U1 and U2\nof the Conservative Party, who express similar viewpoints and support the motion under debate. Such a\nintra-party context and similarity is often indicative and an example of political cohesion within parties\n(Hug, 2009; Lai et al., 2019). Next, among transcripts T2 and T3, we observe a remarkable similarity\nbetween two different transcripts from the same speakerU2, debating over two different motions. Such a\nspeaker-self context is characteristic of the linguistic styles of individual speakers that reﬂect across their\nspeeches (WIEBE, 1994b; Cottam et al., 2015). Lastly, transcripts T3 and T4 highlight motion context,\nthe similarity of speeches based on the motion under debate. The psychological impact of the topic of\nmotion in debate and the stances adopted by peer-speakers, jointly tend to inﬂuence the stance a speaker\nlikely has towards the motion. The underlying connections between the elements of a debate- such as\nparticipants, motions, and speeches; play an essential role in the outcome of the debate. Identifying\nsuch similarities in the parliamentary ecosystem unfolds the possibility to learn latent patterns among\nspeakers, the speeches they deliver, their political afﬁliations, and how they target various motions.\nBuilding on the interdependent nature of participating elements in parliamentary debates, we propose\nGPolS: Graph Political Sentiment analyzer: a neural framework for speech-level stance analysis of\nmembers of the parliament (MPs). First, we ﬁne-tune BERT (Devlin et al., 2019), on a large corpus\nof debate speeches of the UK Parliament’s House of Commons. Through ﬁne-tuning BERT, we extract\nsemantically meaningful representations of political speeches and motions. We empirically validate\nthe presence of similarities between transcripts across debates, motions, and speakers ( Sec. 3.2). At\nthe heart of GPolS, we model these similarities through relations between elements in a parliamentary\nsetting as a graph. GPolS, through the use of a Graph Attention Network (GAT) ( Sec. 3.3) aggregates\nfeatures across the contextual relations between motions, transcripts, and speakers to hierarchically learn\nsimilarities across transcripts through semantic (token-level attention) and graph based (graph attention)\nrepresentations. Through experiments ( Sec. 4) on more than 33,000 transcripts from the UK House of\nCommons, we demonstrate GPolS’s ability for stance analysis in parliamentary debates (Sec. 5). Lastly,\nwe visualize GPolS’s graph attention mechanism ( Sec. 5.3) and token-level attention ( Sec. 5.4) thus\nproviding a use case for GPolS as a tool for parliamentary debate analysis.\n4849\n2 Related Work\nPolitics and Linguistics Analyzing political data acts as a knowledge source that provides insights into\ncohesion within political parties, stances of MPs towards critical motions for both the general public, and\nacross domains including humanities, and computational linguistics (Vilares and He, 2017; Sim et al.,\n2013; Slembrouck, 1992). A developing body of research at the intersection of Politics and Linguistics\nspans agreement detection (Menini and Tonelli, 2016; M. and M., 2018; Duthie and Budzynska, 2018),\nemotion analysis (Rheault, 2016; Dzieciatko, 2019), topic-opinion analysis (Nguyen et al., 2015; Aber-\ncrombie and Batista-Navarro, 2018b) and, debate stance classiﬁcation (Proksch et al., 2019). Existing\nwork focuses on these tasks through legislative speeches from the US Congress (Chen et al., 2017), the\nUK Parliament (Bhavan et al., 2019), and the EU Parliament (Glava ˇs et al., 2017; Frid-Nielsen, 2018)\nand through social media such as Twitter (Trilling, 2014; Boutyline and Willer, 2017). Recently, some\ntools for extracting and annotating political data have also been developed (Haddadan et al., 2019).\nPolitical Stance and Sentiment Analysis NLP has seen a growth in analyzing and mining opinions\nfrom political discourse (Cabrio and Villata, 2018; Rheault, 2016; Fi ˇser et al., 2020). Word embed-\ndings have shown remarkable progress in analyzing political debates and text (Onyimadu et al., 2013;\nAbercrombie and Batista-Navarro, 2018a; Rheault and Cochrane, 2020). (Rudkowsky et al., 2018) con-\nducted a textual analysis of Austrian parliamentary speeches, demonstrating the effectiveness of using\nword embeddings instead of conventional approaches such as Bag-of-Words. More recent approaches\n(Abercrombie et al., 2019; Abercrombie and Batista-Navarro, 2020a) show the ability of pre-trained\ntransformers such as BERT in capturing domain-speciﬁc jargon better for feature extraction from de-\nbates. A promising new direction at the intersection of Politics and NLP is the inclusion of context such\nas political party afﬁliations and engagement in social circles. (Boutyline and Willer, 2017; Lai et al.,\n2019) study the linguistic patterns of politically engaged users on Twitter by inferring a user’s political\ninclination through the politicians and policy nonproﬁts they follow. They show that more conservative\nusers exhibit a higher level of homophily and often stick to their political stances even when challenged.\nRecent works (Bhavan et al., 2020; Bhavan et al., 2019) have shown the presence of herd mentality in\npolitical stances through graph embeddings by identifying the linguistic similarity between members of\nthe same political party over a set of 1,251 debates. (Davoodi et al., 2020) study the interactions be-\ntween the content of a proposed bill and the legislative context in which it is presented. (Al Khatib et al.,\n2020) models debater characteristics to predict persuasiveness. GPolS builds on and differs from existing\nwork across three pivots: 1) we analyze a substantially larger (34,461) set of parliamentary debates for\na more meaningful analysis, 2) we analyze and empirically demonstrate political cohesion, and correla-\ntions between MP speeches for political stance analysis, and 3) Joint language and contextual modeling\nof parliamentary debates through token-level and graph attention.\n3 Methodology\nWe ﬁrst deﬁne the problem of analyzing parliamentary debates, and then present GPolS. Figure 2 presents\nan overview of GPolS. We ﬁne-tune and use BERT to encode parliamentary debates and motions. We\nthen motivate GPolS by analyzing the similarity across debate transcripts based on three types of context\nand model them through a heterogeneous graph. Lastly, we detail the Graph Attention Network (GAT)\nfor propagating contextual information across debate transcripts, speakers and motions for classiﬁcation.\nProblem Deﬁnition We denote a debate transcript as ti ∈ T = {t1,t2,...,t N }corresponding to\nthe speech made by a MP (speaker) sj ∈S = {s1,s2,...,s Z}on one speciﬁc motion mk ∈M =\n{m1,m2,...,m Q}. Each speaker si is afﬁliated to only one political party pi ∈P = {p1,p2,...,p R}.\nOn a debate motion m, given a transcript tspoken by a MP swith a political party afﬁliation p, the task\nis to classify the stance Y ∈{’Aye’,’No’}of the MP son the motion mbased on the transcript t. ’Aye’\nand ’No’represent a positive and negative stance on the motion, respectively.\n4850\nFigure 2: An overview of the proposed context graph, GPolS model and its components.\n3.1 Encoding Parliamentary Debates and Motions through BERT\nA debate comprises Motions, i.e., expressions over policy positions taken by the government, Members\nof Parliament (MP), etc. The motion is followed by complementary or counter-responses from other\nMPs, often termed as Utterances, which collectively comprise a Speech. We adopt a transformer lan-\nguage model: Bidirectional Encoder Representations from Transformers (BERT) (Devlin et al., 2019) to\nencode debate transcripts tand motion descriptions m. We ﬁne-tune the BERT-Base-Cased (Wolf et al.,\n2019)2 model architecture. Often, ﬁne-tuning BERT on task-speciﬁc corpus yields performance gains on\ndownstream NLP tasks (Alsentzer et al., 2019; Sun et al., 2019). The domain-speciﬁc nature of political\nspeeches and complex political jargon motivate us to ﬁne-tune the pre-trained BERT language model.\nWe ﬁne-tune BERT on the ParlV ote dataset (Abercrombie and Batista-Navarro, 2020a), a corpus of de-\nbates from the UK Parliament’s House of Commons comprising of 33,461 transcripts of debate speeches\nfrom May 7th, 1997 to November 5th, 2019.3 Following (Abercrombie and Batista-Navarro, 2020a), we\nonly consider the ﬁrst 512 tokens of speeches in ParlV ote (18,253 speeches have less than 512 tokens)4.\nAll motions are less than 512 tokens, and describe the topic for a given debate. For each transcriptt∈T\nand, each motion m ∈M, we obtain feature vectors ht = BERT(t) and hm = BERT(m) ∈RF . The\nfeature vector is a one-dimensional vector of size F = 768obtained the output of the [CLS] token from\nthe ﬁnal BERT layer. The pre-processing, training, and hyperparameter tuning are detailed in Section 4.\n3.2 GPolS: Graph Political Stance analyzer: Context Modeling and Graph Creation\nDecision-makers are subtly inﬂuenced by the environment around them (Bode et al., 2014). We identify\nthree major types of contexts in parliamentary debates— intra-party context, speaker-self context and\nmotion context. The ﬁrst, Intra-Party Context, captures the inﬂuence of the same political afﬁliations\nand fellow party members over the speeches of a speaker. During debates, some speakers tend to express\ntheir raw individual opinions, while some may exhibithomophily: the likeliness of associated individuals\nto adopt similar viewpoints (Boucek, 2002). Speaker-Self Context captures the unique linguistic style of\na speaker based on the similarity between the speeches they deliver (Johnstone, 2009). Lastly, we also\npresent a Motion Context, that captures the relationship between a speech and the motion under debate.\nMotivated by (Chen et al., 2019a) we use heterogeneous graphs to model such contextual information.\nHypothesising the presence of contextual information in parliamentary debates We perform an\nexperiment to examine the similarity between debate transcripts that are related based on their motion,\nspeaker, and speaker afﬁliation. For this experiment, we compute the cosine similarity between the ﬁne-\ntuned BERT embeddings of each of the debate transcripts in ParlV ote. We then compare the distributions\n2https://huggingface.co/bert-base-cased\n3Available in XML format at https://www.theyworkforyou.com/ under an Open Parliament License.\n4We also experiment with LongFormer (Beltagy et al., 2020) to reduce the trimming of tokens in long speeches, but empir-\nically observe no statistically signiﬁcant difference in performance between BERT and LongFormer over the ParlV ote corpus.\n4851\nNodes\nSpeaker (1, 346)\nMotion (1, 995)\nTranscript (33, 461)\nLinkages (Contexts)\nSpeaker-Speaker (335, 621)\nMotion-Transcript (33, 461)\nSpeaker-Transcript (33, 461)\nTable 1: Graph statistics\nSame\nSpeaker\nDifferent\nSpeaker\n0\n1\np=0.002\nCosine\nSimilarity\nSame\nParty\nDifferent\nParty\n0\n1\np=6.9e-5\nSame\nMotion\nDifferent\nMotion\n0\n1\np=5.6e-13\nFigure 3: Box plots show the distribution of pairwise cosine similarity be-\ntween transcripts (based on speakers, speaker afﬁliation, and motion) with\ntheir corresponding conﬁdence intervals (notch).\nof cosine similarities between transcript embeddings (BERT) from the same speaker, and those from\ndifferent speakers. Similarly, we compare cosine similarity distributions across transcripts spoken by\nmembers of the same party, and across different parties, as well as across the same motion, and different\nmotions. We present the distribution in Figure 3, and observe that transcripts related to each other(based\non speaker, transcript and motion) are signiﬁcantly ( p <0.005) more similar than that from different\norigins under the Wilcoxon signed-rank test (Woolson, 2007). Based on these empirical similarities\nbetween debates, we model these contexts in the form of a heterogeneous graph, which we describe next.\nGraph Creation for Context Modeling We represent the relations between transcripts, speakers and\nmotions in the form of a graph G = (V,E). V and E represent the nodes and edges in the graph.\nThe nodes V are consisted of the set of debate transcripts T, speakers S and motions M. The edges E\nhave three types: Speaker-Transcript edges Est based on speaker-self context, Speaker-Speaker edges\nEss based on intra-party context, and Transcript-Motion edges Etm based on motion context. G is a\nheterogeneous graph as it has different types of nodes and edges. We now describe these three relations\none by one that capture different contexts based on the similarities observed through Figure 3.\n•Speaker-self context captures the relationship between a speaker and the transcript of their speech\nin a given debate. Each speech is personalized and reﬂects the mentality of a speaker across different\nspeeches, motions and times (Wiebe, 1994a; Layman et al., 2006). Contrastingly, self-speaker\ncontext can also capture the domain expertise of the speakers. Speaker-self context captures the\nsimilarity between speeches by the same speaker. It is formally represented as a Speaker-Transcript\nedge Est between a transcript tand the MP swhose speech that transcript corresponds to.\n•Intra-party context models the relationship between a MP and the party they belong to. We build\non the hypothesis that speakers are inﬂuenced by other party members, and there exists a partisan\nmentality like political cohesion within parties. (Lai et al., 2019; Owens, 2003; Chartash et al.,\n2018). Formally, intra-party context is represented by a Speaker-Speaker edge Ess between two\nMPs (speakers) si,sj ∈Sif both si and sj are afﬁliated to the same political party p∈P.\n•Motion level contextencodes the relation between a transcript and a motion. In debates, a speech is\nbased on the current motion of discussion. Formally, motion context is represented as a Transcript-\nMotion edge Etm between a transcript tand a motion mcorresponding to that debate transcript.\nWe summarize the statistics of the created graph G in Table 1. We now describe the graph attention\nnetwork for context propagation across nodes and the optimization for political stance analysis.\n3.3 Graph Attention Network: Semi-Supervised Node Classiﬁcation for Stance Prediction\nWe treat stance prediction (’Aye’ or ’No’)as a node classiﬁcation problem. As labels are available\nfor a subset of nodes in our graph (i.e., speech nodes (transcripts)), we frame the node classiﬁcation\nproblem in a semi-supervised learning setting, allowing the model to distribute gradient information\nfrom the supervised loss on the labeled transcript nodes. The inclusion of unlabeled motion and speaker\n4852\nnodes allow us to not only capture the structural traits of relations between similar transcripts based\non contextual relations but also the contextual text representation of each motion. As each context has a\ndifferent degree of inﬂuence on a speaker’s speech, it is important that the graph encoding suitably weighs\nmore relevant relations between transcripts, speakers and motions. To this end, we use GATs, that are\ngraph neural networks with node level attention popularly used for node classiﬁcation (Veliˇckovi´c et al.,\n2017).\nWe ﬁrst describe a single graph attention layer (Veliˇckovi´c et al., 2017) which is used throughout\nthe GAT component. The input to this layer is a set of node features h = {x1,x2,...,x |V |},xi ∈RF\nwhere, F is the number of features for each node. For each debate transcript t, we set the node feature\nas the embedding extracted ht from the text transcript using BERT. Similarly, for each motion m, the\nnode feature is set as hm. As there is no text information available for speakers s∈S, we initialize their\nfeature vectors to zero embeddings. 5 The node features are transformed to context dependent features,\nh′ = [q1,q2,...q |V |]; qi ∈ RF′\nbased on the inﬂuence by its neighbors during training. Following\n(Veliˇckovi´c et al., 2017) we ﬁrst apply a shared linear transform parameterized by W ∈RF′×F to all\nthe nodes. Then, we apply a shared self-attention mechanism to each node i in its neighborhood Ni.\nFor each node j ∈Ni, we compute normalized attention coefﬁcients αij which shows the importance of\ncontext between nodes iand j. Formally, αij is given as:\nαij = exp (LeakyReLU(aT\nw[Wxi ⊕Wxj]))∑\nk∈Ni\nexp (LeakyReLU(aTw[Wxi ⊕Wxk])) (1)\nwhere, .T ,⊕represent transpose and concatenation, respectively. We use LeakyReLU as the activa-\ntion function throughout our framework to mitigate vanishing gradients (Maas et al., 2013). Following\n(Veliˇckovi´c et al., 2017) aw ∈R2F′\nis the parameter matrix of a single layer layer feed forward neu-\nral network. The attention coefﬁcients are used to weigh and aggregate contextual information from\nneighboring nodes. Following (Veliˇckovi´c et al., 2017) we use multi-head attention to stabilize training\n(Vaswani et al., 2017). Formally, U independent executors apply the attention mechanism. Their output\nfeatures are concatenated to yield:\nqi =\nU⨁\nk=1\nLeakyReLU\n\n∑\nj∈Ni\nαk\nijWkxj\n\n (2)\nwhere αk\nij and Wk denote the attention coefﬁcients and linear transform weight matrix computed by the\nkth attention head. We apply a 2-layer GAT model, the ﬁrst layer consists of U = 8 attention heads\ncalculating F′= 8features per node. The second layer is used for classiﬁcation with one attention head\nand F′= 2(”Aye” or ”no”) followed by a softmax activation (Nwankpa et al., 2018).\nyi = Softmax\n\n∑\nj∈Ni\nβijW2\n8⨁\nk=1\nLeakyReLU\n\n∑\nj∈Ni\nαk\nijWkxj\n\n\n\n (3)\nwhere, βij and W2 ∈R2×64 denote the attention coefﬁcients and linear transform weight matrix com-\nputed by the second attention layer. The entire framework is trained in an end-to-end fashion to minimise\nthe cross entropy loss of labeled nodes using the Adam optimizer (Kingma and Ba, 2014), as:\nLcse = −\n|V |∑\ni=1\nYi ln(yi) + (1−Yi) ln(1−yi) (4)\nwhere, Yi is the true stance and, yi is the estimated probability of ”Aye” or ”No”. During training, we\nonly have labeled transcript nodes for those transcripts in the graph that are part of the train set. Speaker\nand motion nodes are masked so that losses are propagated only for the labeled nodes.\n5It is possible to initialize user features using external information about the politician, however, this is beyond the scope of\nthis work, and forms our future direction. We follow related literature on user proﬁling (Chen et al., 2019b; Mishra et al., 2019)\nin heterogeneous graph attention network settings and set user features as zero embeddings.\n4853\n4 Experimental setup\n4.1 Dataset and Preprocessing\nWe evaluate GPolS on the ParlV ote dataset consisting of 33,461 debate transcripts. On an average,\na speech in ParlV ote has 760.2 ±901.3 tokens (max 20,730). Following (Abercrombie and Batista-\nNavarro, 2020a), we remove non-speech elements, tokenize motions and transcripts and, preserve the\ntexts’ original casing. The speaker names and party afﬁliations are obtained using TheyWorkForYou.6\nThe dataset is fairly balanced with 53.57/46.43% Aye/No labels. The transcripts are labeled based on\na speaker’s vote to their speech, with votes for ’Aye’ and ’no’ representing positive and negative sen-\ntiment. Following (Abercrombie and Batista-Navarro, 2020a), the dataset is divided into 5 subsets for\nexperimenting with various corpus and debate transcript sizes as: (1)Large is the complete pre-processed\nsubset. (2) Medium-any is a random sample with half (18,253) of the total instances. (3)Medium (≤512)\nconsists of all speeches and motions in medium-any with 512 tokens or fewer. (4) Small-any is a ran-\ndom sample of the same size as the corpus used by (Abercrombie and Batista-Navarro, 2018a)—1,251\nexamples. (5) Small (≤512) contains speeches+motions in small-any with 512 tokens or fewer.\n4.2 Training setup\nAll experiments were performed on an NVIDIA Tesla P100 GPU. For ﬁne-tuning BERT, we explore the\nfollowing hyperparameters: learning rates ∈{2 ·10−5,5 ·10−5,2 ·10−4}, batch sizes ∈{8,16,32},\nepochs ∈{3,4,5,6,7,8,9,10}. The optimal hyperparameters for BERT were selected based on valida-\ntion accuracy, as: learning rate = 5e−5, batch size of 8, with the AdamW (Loshchilov and Hutter, 2019)\noptimizer, for 7 epochs on the ParlV ote dataset. We use the default dropout (Srivastava et al., 2014) rate\n(0.1) on self attention layers but do not use additional dropout at the top linear layer.\nTraining GPolS: We use grid search for hyperaparamter selection for all models over all variants of\nthe dataset individually, and select optimal values based on validation accuracy. All intermediate GAT\nlayers are used with 8 attention heads and an output space of 8 with a dropout=0.6. The Adam optimiser\nis set with default valuesβ1 = 0.9, β2 = 0.999, ϵ= 1e−8, weight-decay = 5e−4 and an initial learning\nrate of 0.001. We use a exponential learning rate scheduler with a decay rate of0.67 (Li and Arora, 2019)\nand early stopping with a patience of 10 epochs. Following (Abercrombie and Batista-Navarro, 2020a),\nwe evaluated all models using the same randomly selected 80/10/10 training-validation-testing split of\nthe data for each subsection of the corpus, and report mean results over 10 different runs.\n4.3 Baselines\nFollowing Abercrombie (2020a), we compare GPolS with baselines on classiﬁcation accuracy.7\nMajority class: The majority class in the training set as the predictions for test set. This baseline does\nnot use any textual or contextual features.\nSupport Vector Machines (SVM): A bag-of-words (BoW) model that uses unigram features as input\nwith term frequency-inverse document frequency feature selection (TF-IDF). We use SVM with a linear\nkernel, L2 regularisation and optimise squared hinge loss (Gentile and Warmuth, 1999).\nMulti-layer Perceptron (MLP): A BoW model that utilises only unigram textual features from tran-\nscripts as input with TF-IDF selection. We use a MLP with1 hidden layer containing 100 units followed\nby ReLU activation. We use L-BFGS optimisation (Liu and Nocedal, 1989) for training 200 epochs\nBERT-MLP: BERT (Devlin et al., 2019) embeddings are used on the ParlV ote dataset followed by a\nMLP with the same settings as described above. It is a text only model with no additional context.\nDeepwalk: Concatenates speaker-speaker graph (speaker-self context) embeddings with a set of lan-\nguage features followed by a MLP (same as above). TF-IDF based BoW features (upto trigrams) were\nconcatenated with subjectivity scores for each speech computed using the Harvard General Inquirer lex-\n6Available at https://github.com/mysociety/\n7We replicated all baselines based on the conﬁgurations given in (Abercrombie and Batista-Navarro, 2020a) for the SVM,\nMLP and BERT-MLP, (Bhavan et al., 2020) for the Deepwalk baseline.\n4854\nSmall - 1,251 transcripts Medium - 18,253 transcripts Large - 33,461 transcriptsModel\nAny speech #Tokens ≤ 512 Any speech #Tokens ≤ 512 All speeches\nMajority class 0.53 ± 1e − 3 0 .53 ± 3e − 3 0.50 ± 2e − 3 0 .52 ± 5e − 3 0.50 ± 4e − 3\nSVM 0.51 ± 4e − 3 0 .57 ± 6e − 4 0.68 ± 1e − 3 0 .63 ± 3e − 3 0.66 ± 2e − 3\nMLP 0.50 ± 2e − 3 0 .56 ± 1e − 3 0.63 ± 4e − 3 0 .63 ± 8e − 4 0.65 ± 3e − 3\nBERT + MLP 0.64 ± 1e − 3 0 .53 ± 2e − 3 0.61 ± 9e − 4 0 .61 ± 4e − 3 0.67 ± 7e − 3\nDeepwalk 0.73 ± 4e − 3 0.73 ± 3e − 3 0.72 ± 9e − 4 0.72 ± 1e − 3 0.72 ± 8e − 4\nGPolS 0.80 ± 5e − 4 0.80 ± 4e − 4 0.77 ± 6e − 4 0.77 ± 5e − 4 0.76 ± 3e − 4\nTable 2: Classiﬁcation accuracy averaged over 10 different runs. Bold denotes the best results.\nFigure 4: Attention coefﬁcients amongst MPs of Con-\nservative Party (left) and Liberal Democrats (right)\nModel Speaker-self\ncontext\nIntra-party\ncontext\nMotion\ncontext Acc\nBERT \u0017 \u0017 \u0017 0.67\nGPolS \u0013 \u0017 \u0013 0.73\nGPolS \u0013 \u0013 \u0017 0.75\nGPolS \u0013 \u0013 \u0013 0.76\nTable 3: Ablation study: We investigate the ef-\nfect of different contexts by removing contexts.\nicon (Roberts, 1997). Deepwalk (Perozzi et al., 2014) was used to obtain speaker embeddings from a\nspeaker graph based on party afﬁliation and concatenated with the text features from transcripts.8\n5 Results and Analysis\n5.1 Performance Comparison with Baselines\nWe compare the performance of GPolS with baseline methods in terms of classiﬁcation accuracy over 10\ndifferent runs in Table 2. We note that BERT+MLP signiﬁcantly (p< 0.05) outperforms Majority class\nand BoW (TF-IDF) based approaches: SVM and MLP. We postulate this to ﬁne-tuning BERT to obtain\nrich embeddings that better capture the context within each debate transcript. We observe that graph-\nbased models (Deepwalk, GPolS) outperform text-only models (SVM, MLP, BERT-MLP), reiterating\nthe presence of similarity between related transcripts. GPolS outperforms all baselines signiﬁcantly\n(p <0.05) under the Wilcoxon signed-rank test, by a large margin greater than 6.5%. We attribute\nthis improvement to two aspects: 1) Fine-tuning BERT for domain-speciﬁc embeddings, and 2) Graph\nattention mechanism in GPolS. First, BERT is able to better model political jargon in debate transcripts\npost ﬁne-tuning. Second, GPolS enhances text features through a context propagation mechanism via\ngraph attention by modeling speaker-self, intra-party, and motion level context. The additional context\nthat GPolS adds by learning the latent patterns between related transcripts, sets GPolS apart from all the\nbaselines. We further analyze these in the following subsections, ﬁrst through an ablation study, and then\nby analyzing BERT’s token-level attention on debates, and GPolS’s graph attention mechanism.\n5.2 Ablation Study: Quantifying the Impact of Context\nWe perform an ablation study over the different kinds of context that GPolS models, in Table 3. All\nperformance differences are statistically signiﬁcant ( p <0.05) under Wilcoxon’s signed rank test. We\nremove the contexts one by one and ﬁnd that the speaker-self context leads to an improvement owing to\nthe similarity in transcripts by the same speaker. We also note that the accuracy drop on removing motion\ncontext is small but statistically signiﬁcant ( p <0.05). The small performance change also shows that\nwhile there is a content-based similarity between transcripts of the same motion, such context may not be\nas relevant from the perspective of stance analysis. We also note that speaker-self and intra-party context\n8We also experiment with node2vec from (Bhavan et al., 2019), however, as reported in their following work (Bhavan et al.,\n2020), there is no signiﬁcant difference between both, so we only report results based on the more recent method for brevity.\n4855\nFigure 5: Attention visualisation using BERT. Intense red denotes higher attention. Arrows represent\nsimilar terms across transcripts. Heatmaps represent BERT heads that encode semantic links in speech.\nare slightly more important as compared to motion-context. This is potentially due to existence of larger\npolitical cohesion and partisan mentality in political parties. We analyze this next.\n5.3 Analyzing Political Cohesion and Partisan Identities: Visualizing GPolS’s Graph Attention\nMultiple studies have highlighted the presence of political cohesion, and a partisan-like herd mentality\nin UK-based political parties (Huddy, 2003; Bowler et al., 1999). To analyze this political cohesion, and\nGPolS’s intra-party context, we ﬁrst calculate the attention scores amongst each member in two well-\nknown UK political parties, as shown in Figure. 4. A higher attention score between a speaker and their\nneighbors indicates a higher degree of peer inﬂuence on the speaker and a similarity in their political\nstances. We ﬁrst analyze the Conservative party, one of the oldest and largest parties in the UK. We\nobserve in Figure 4 (left) that high attention scores exist between speakers and their peers, indicating\na high degree of political cohesion between MPs. High political cohesion in the conservative party is\nfurther consolidated by the age and large size of the party, as goals and decisions are much more common\nbetween members of such large and old parties (Hayton, 2012). On the other end of the spectrum, we\nanalyze the Liberal Democrats, a relatively newer and smaller party as compared to the Conservative\nparty, in Figure 4 (right). We note high attention scores along the diagonal, indicating a large self-\ndependency of speakers or a lower degree of political cohesion. Through these examples, we show that\nGPolS effectively learns and weights such latent patterns through context propagation over the speaker-\nspeaker and speaker-transcript relations. The attention mechanism also provides insights into political\ncohesion across large volumes of transcripts to aid interpretability in ﬁelds such as Digital Humanities.\n5.4 Token-level Attention Visualisation using BERT\nAs a concluding use-case, we analyze token-level attention over political debate transcripts. Our goal\nwith this attention analysis is not to study causation or an explanation of GPolS’s predictions, but rather\nanalyzing the impacvt of ﬁne-tuning BERT on ParlV ote. In Figure 5, we present two snippets of real-\nworld debates over the motion: ’Post Ofﬁce Reinvention Program’. In T1, BERT allots higher attention\nto terms relevant to motion, such aspost ofﬁce account, cash, liquidity, etc. Similarly in T2, BERT allots\nmore attention to the context of senior citizens being very anxious about the new arrangements. BERT\nalso allots high attention to words indicative of stance adoption over motions, such as the arrangement\nbeing very disappointing in T1. We present two such heads and analyse their corresponding self-attention\nheat-maps over an input speech snippet fromT1. Higher attention scores link the ’arrangement’ as being\n’very disappointing’. Notably, the term surgeries in T1 and T2, get assigned a high attention weight. In\nthe political domain, surgeries are held by MPs where they meet people and discuss matters of concern.\n4856\n6 Conclusion\nWe propose GPolS, that enhances linguistic analysis of debates with context for political stance detec-\ntion. Fine-tuning BERT, we encode debates and motions from the UK Parliament’s House of Commons\nto capture semantics in political jargon. We show GPolS practical applicability and interpretability in\nparliamentary debate settings. Through this work, we hope to complement digital humanities, media,\nsocial scientists, political linguistics and any members of the public who wish to scrutinize the activi-\nties of their elected representatives. GPolS makes a step towards facilitating the understanding of MP’s\nopinions through for analyzing latent correlations and sentiments in voluminous parliamentary debates.\nAcknowledgement\nRajiv Ratn Shah is partly supported by the Infosys Center for AI and the Center of Design and New\nMedia at IIIT Delhi.\nReferences\nGavin Abercrombie and Riza Batista-Navarro. 2018a. ‘aye’ or ‘no’? speech-level sentiment analysis of hansard\nUK parliamentary debate transcripts. In Proceedings of the Eleventh International Conference on Language\nResources and Evaluation (LREC 2018) , Miyazaki, Japan, May. European Language Resources Association\n(ELRA).\nGavin Abercrombie and Riza Theresa Batista-Navarro. 2018b. Identifying opinion-topics and polarity of parlia-\nmentary debate motions. In Proceedings of the 9th Workshop on Computational Approaches to Subjectivity,\nSentiment and Social Media Analysis , pages 280–285, Brussels, Belgium, October. Association for Computa-\ntional Linguistics.\nGavin Abercrombie and Riza Batista-Navarro. 2020a. ParlV ote: A corpus for sentiment analysis of political\ndebates. In Proceedings of The 12th Language Resources and Evaluation Conference, pages 5073–5078, Mar-\nseille, France, May. European Language Resources Association.\nGavin Abercrombie and Riza Batista-Navarro. 2020b. Sentiment and position-taking analysis of parliamentary\ndebates: a systematic literature review. Journal of Computational Social Science, 3(1):245–270, Apr.\nGavin Abercrombie, Federico Nanni, Riza Batista-Navarro, and Simone Paolo Ponzetto. 2019. Policy preference\ndetection in parliamentary debate motions. In Proceedings of the 23rd Conference on Computational Natural\nLanguage Learning (CoNLL), pages 249–259, Hong Kong, China, November. Association for Computational\nLinguistics.\nKhalid Al Khatib, Michael V ¨olske, Shahbaz Syed, Nikolay Kolyada, and Benno Stein. 2020. Exploiting per-\nsonal characteristics of debaters for predicting persuasiveness. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages 7067–7072, Online, July. Association for Computational\nLinguistics.\nEmily Alsentzer, John R. Murphy, Willie Boag, Wei-Hung Weng, Di Jin, Tristan Naumann, and Matthew B. A.\nMcDermott. 2019. Publicly available clinical bert embeddings.\nIz Beltagy, Matthew E. Peters, and Arman Cohan. 2020. Longformer: The long-document transformer.\nAnjali Bhavan, Rohan Mishra, Pradyumna Prakhar Sinha, Ramit Sawhney, and Rajiv Ratn Shah. 2019. Inves-\ntigating political herd mentality: A community sentiment based approach. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Linguistics: Student Research Workshop , pages 281–287, Flo-\nrence, Italy, July. Association for Computational Linguistics.\nAnjali Bhavan, Mohit Sharma, Ramit Sawhney, and Rajiv Ratn Shah. 2020. Analysis of parliamentary debate\ntranscripts using community-based graphical approaches (student abstract). In The Thirty-Fourth AAAI Confer-\nence on Artiﬁcial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artiﬁcial Intelligence\nConference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artiﬁcial Intelligence, EAAI\n2020, New York, NY, USA, February 7-12, 2020, pages 13753–13754. AAAI Press.\nStefan Bode, Carsten Murawski, Chun Siong Soon, Philipp Bode, Jutta Stahl, and Philip L. Smith. 2014. Demys-\ntifying “free will”: The role of contextual information and evidence accumulation for predictive brain activity.\nNeuroscience & Biobehavioral Reviews, 47:636–645, November.\n4857\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with\nsubword information. Transactions of the Association for Computational Linguistics, 5:135–146.\nFrancoise Boucek. 2002. The structure and dynamics of intra-party politics in europe. Perspectives on European\nPolitics and Society, 3(3):453–493.\nAndrei Boutyline and Robb Willer. 2017. The social structure of political echo chambers: Variation in ideological\nhomophily in online networks. Political Psychology, 38(3):551–569.\nShaun Bowler, David M Farrell, Richard S Katz, et al. 1999. Party discipline and parliamentary government. The\nOhio State University Press.\nElena Cabrio and Serena Villata. 2018. Five years of argument mining: a data-driven analysis. In Proceedings\nof the Twenty-Seventh International Joint Conference on Artiﬁcial Intelligence, IJCAI-18 , pages 5427–5433.\nInternational Joint Conferences on Artiﬁcial Intelligence Organization, 7.\nDavid Chartash, Nicholas J Caruana, Markus Dickinson, and Laura B Stephenson. 2018. When the team’s jersey\nis what matters. Party Politics, page 135406881879519, August.\nWei Chen, Xiao Zhang, Tengjiao Wang, Bishan Yang, and Yi Li. 2017. Opinion-aware knowledge graph for\npolitical ideology detection. In Proceedings of the Twenty-Sixth International Joint Conference on Artiﬁcial\nIntelligence, IJCAI-17, pages 3647–3653.\nWeijian Chen, Yulong Gu, Zhaochun Ren, Xiangnan He, Hongtao Xie, Tong Guo, Dawei Yin, and Yongdong\nZhang. 2019a. Semi-supervised user proﬁling with heterogeneous graph attention networks. In Proceedings\nof the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence, IJCAI-19 , pages 2116–2122.\nInternational Joint Conferences on Artiﬁcial Intelligence Organization, 7.\nWeijian Chen, Yulong Gu, Zhaochun Ren, Xiangnan He, Hongtao Xie, Tong Guo, Dawei Yin, and Yongdong\nZhang. 2019b. Semi-supervised user proﬁling with heterogeneous graph attention networks. In IJCAI, vol-\nume 19, pages 2116–2122.\nMartha L Cottam, Elena Mastors, Thomas Preston, and Beth Dietz. 2015. Introduction to political psychology.\nRoutledge.\nMaryam Davoodi, Eric Waltenburg, and Dan Goldwasser. 2020. Understanding the language of political agree-\nment and disagreement in legislative texts. In Proceedings of the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 5358–5368, Online, July. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirec-\ntional transformers for language understanding. In Proceedings of the 2019 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and\nShort Papers), pages 4171–4186, Minneapolis, Minnesota, June. Association for Computational Linguistics.\nRory Duthie and Katarzyna Budzynska. 2018. A deep modular rnn approach for ethos mining. In Proceedings\nof the Twenty-Seventh International Joint Conference on Artiﬁcial Intelligence, IJCAI-18 , pages 4041–4047.\nInternational Joint Conferences on Artiﬁcial Intelligence Organization, 7.\nMariusz Dzieciatko. 2019. Application of text analytics to analyze emotions in the speeches. In Ewa Pietka,\nPawel Badura, Jacek Kawa, and Wojciech Wieclawek, editors, Information Technology in Biomedicine, pages\n525–536, Cham. Springer International Publishing.\nMurray Edelman. 1985. Political language and political reality. PS, 18(1):10–19.\nVladimir Eidelman, Anastassia Kornilova, and Daniel Argyle. 2018. How predictable is your state? leveraging\nlexical and contextual information for predicting legislative ﬂoor action at the state level. In Proceedings of\nthe 27th International Conference on Computational Linguistics, pages 145–160, Santa Fe, New Mexico, USA,\nAugust. Association for Computational Linguistics.\nDarja Fi ˇser, Maria Eskevich, and Franciska de Jong, editors. 2020. Proceedings of the Second ParlaCLARIN\nWorkshop, Marseille, France, May. European Language Resources Association.\nSnorre Sylvester Frid-Nielsen. 2018. Human rights or security? positions on asylum in european parliament\nspeeches. European Union Politics, 19(2):344–362.\nClaudio Gentile and Manfred K. K Warmuth. 1999. Linear hinge loss and average margin. In M. J. Kearns, S. A.\nSolla, and D. A. Cohn, editors, Advances in Neural Information Processing Systems 11 , pages 225–231. MIT\nPress.\n4858\nGoran Glavaˇs, Federico Nanni, and Simone Paolo Ponzetto. 2017. Unsupervised cross-lingual scaling of political\ntexts. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational\nLinguistics: Volume 2, Short Papers , pages 688–693, Valencia, Spain, April. Association for Computational\nLinguistics.\nShohreh Haddadan, Elena Cabrio, and Serena Villata. 2019. Disputool – a tool for the argumentative analysis of\npolitical debates. In Proceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence,\nIJCAI-19, pages 6524–6526. International Joint Conferences on Artiﬁcial Intelligence Organization, 7.\nKazi Saidul Hasan and Vincent Ng. 2013. Stance classiﬁcation of ideological debates: Data, models, features, and\nconstraints. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages\n1348–1356, Nagoya, Japan, October. Asian Federation of Natural Language Processing.\nRichard Hayton. 2012. Reconstructing Conservatism?: The Conservative party in opposition, 1997–2010.\nLeonie Huddy. 2003. Group identity and political cohesion.\nSimon Hug. 2009. Selection effects in roll call votes. British Journal of Political Science, 40(1):225–235, October.\nBarbara Johnstone. 2009. Stance, style, and the linguistic individual. Stance: sociolinguistic perspectives, 29:52.\nDiederik P. Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization.\nMirko Lai, Marcella Tambuscio, Viviana Patti, Giancarlo Ruffo, and Paolo Rosso. 2019. Stance polarity in polit-\nical debates: A diachronic perspective of network homophily and conversations on twitter. Data & Knowledge\nEngineering, 124:101738.\nGeoffrey C. Layman, Thomas M. Carsey, and Juliana Menasce Horowitz. 2006. PARTY POLARIZATION\nIN AMERICAN POLITICS: Characteristics, causes, and consequences. Annual Review of Political Science ,\n9(1):83–110, June.\nZhiyuan Li and Sanjeev Arora. 2019. An exponential learning rate schedule for deep learning.\nDong C. Liu and Jorge Nocedal. 1989. On the limited memory BFGS method for large scale optimization.\nMathematical Programming, 45(1-3):503–528, August.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke\nZettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv\npreprint arXiv:1907.11692.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled weight decay regularization. In International Conference on\nLearning Representations.\nAhmadalinezhad M. and Makrehchi M. 2018. Detecting agreement and disagreement in political debates. In:\nThomson R., Dancy C., Hyder A., Bisgin H. (eds) Social, Cultural, and Behavioral Modeling. SBP-BRiMS ,\n2018.\nAndrew L Maas, Awni Y Hannun, and Andrew Y Ng. 2013. Rectiﬁer nonlinearities improve neural network\nacoustic models. In Proc. icml, volume 30, page 3.\nStefano Menini and Sara Tonelli. 2016. Agreement and disagreement: Comparison of points of view in the politi-\ncal domain. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics:\nTechnical Papers, pages 2461–2470, Osaka, Japan, December. The COLING 2016 Organizing Committee.\nPushkar Mishra, Marco Del Tredici, Helen Yannakoudakis, and Ekaterina Shutova. 2019. Abusive language\ndetection with graph convolutional networks. In Proceedings of the 2019 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and\nShort Papers), pages 2145–2150.\nViet-An Nguyen, Jordan Boyd-Graber, Philip Resnik, and Kristina Miler. 2015. Tea party in the house: A hierar-\nchical ideal point topic model and its application to republican legislators in the 112th congress. InProceedings\nof the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint\nConference on Natural Language Processing (Volume 1: Long Papers), pages 1438–1448, Beijing, China, July.\nAssociation for Computational Linguistics.\nChigozie Nwankpa, Winifred Ijomah, Anthony Gachagan, and Stephen Marshall. 2018. Activation functions:\nComparison of trends in practice and research for deep learning.\n4859\nObinna Onyimadu, Keiichi Nakata, Tony Wilson, David Macken, and Kecheng Liu. 2013. Towards sentiment\nanalysis on parliamentary debates in hansard. In Revised Selected Papers of the Third Joint International Con-\nference on Semantic Technology - Volume 8388, JIST 2013, page 48–50, Berlin, Heidelberg. Springer-Verlag.\nJohn E. Owens. 2003. Part 1: Cohesion. The Journal of Legislative Studies, 9(4):12–40, December.\nJeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word represen-\ntation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP),\npages 1532–1543.\nBryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk. Proceedings of the 20th ACM SIGKDD\ninternational conference on Knowledge discovery and data mining - KDD ’14.\nSven-Oliver Proksch, Will Lowe, Jens W ¨ackerle, and Stuart Soroka. 2019. Multilingual sentiment analysis: A\nnew approach to measuring conﬂict in legislative speeches. Legislative Studies Quarterly, 44(1):97–131.\nLudovic Rheault and Christopher Cochrane. 2020. Word embeddings for the analysis of ideological placement in\nparliamentary corpora. Political Analysis, 28(1):112–133.\nLudovic Rheault. 2016. Expressions of anxiety in political texts. In Proceedings of the First Workshop on NLP\nand Computational Social Science , pages 92–101, Austin, Texas, November. Association for Computational\nLinguistics.\nCarl W Roberts. 1997. Text analysis for the social sciences : methods for drawing statistical inferences from texts\nand transcripts. Mahwah NJ. : Erlbaum. Includes bibliographical references and indexes.\nElena Rudkowsky, Martin Haselmayer, Matthias Wastian, Marcelo Jenny, ˇStefan Emrich, and Michael Sedlmair.\n2018. More than bags of words: Sentiment analysis with word embeddings. Communication Methods and\nMeasures, 12(2-3):140–157.\nYanchuan Sim, Brice DL Acree, Justin H Gross, and Noah A Smith. 2013. Measuring ideological proportions\nin political speeches. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language\nProcessing, pages 91–101.\nStef Slembrouck. 1992. The parliamentary hansard ‘verbatim’report: the written construction of spoken discourse.\nLanguage and literature, 1(2):101–119.\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout:\nA simple way to prevent neural networks from overﬁtting. J. Mach. Learn. Res., 15(1):1929–1958, January.\nChi Sun, Xipeng Qiu, Yige Xu, and Xuanjing Huang. 2019. How to ﬁne-tune bert for text classiﬁcation? China\nNational Conference on Chinese Computational Linguistics, pages 194–206.\nDamian Trilling. 2014. Two different debates? investigating the relationship between a political debate on TV and\nsimultaneous comments on twitter. Social Science Computer Review, 33(3):259–276, July.\nStephen M. Utych. 2019. Speaking style and candidate evaluations. Politics, Groups, and Identities, 0(0):1–19.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser,\nand Illia Polosukhin. 2017. Attention is all you need. In I. Guyon, U. V . Luxburg, S. Bengio, H. Wallach,\nR. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30 ,\npages 5998–6008. Curran Associates, Inc.\nPetar Veliˇckovi´c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li `o, and Yoshua Bengio. 2017.\nGraph attention networks.\nDavid Vilares and Yulan He. 2017. Detecting perspectives in political debates. In Proceedings of the 2017\nconference on empirical methods in natural language processing, pages 1573–1582.\nJanyce M. Wiebe. 1994a. Tracking point of view in narrative. Comput. Linguist., 20(2):233–287, June.\nJM WIEBE. 1994b. Tracking point of view in narrative. Computational linguistics-Association for Computational\nLinguistics (Print), 20(2):233–287.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac,\nTim Rault, R’emi Louf, Morgan Funtowicz, and Jamie Brew. 2019. Huggingface’s transformers: State-of-the-\nart natural language processing. ArXiv, abs/1910.03771.\nRF Woolson. 2007. Wilcoxon signed-rank test. Wiley encyclopedia of clinical trials, pages 1–3.",
  "topic": "Cohesion (chemistry)",
  "concepts": [
    {
      "name": "Cohesion (chemistry)",
      "score": 0.789164662361145
    },
    {
      "name": "Politics",
      "score": 0.7266616821289062
    },
    {
      "name": "Computer science",
      "score": 0.6630939245223999
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4960807263851166
    },
    {
      "name": "Sentiment analysis",
      "score": 0.44369834661483765
    },
    {
      "name": "Natural language processing",
      "score": 0.4412020146846771
    },
    {
      "name": "Linguistics",
      "score": 0.4317772388458252
    },
    {
      "name": "Political science",
      "score": 0.3575454354286194
    },
    {
      "name": "Sociology",
      "score": 0.331158846616745
    },
    {
      "name": "Law",
      "score": 0.14166295528411865
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Organic chemistry",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I36090812",
      "name": "Netaji Subhas University of Technology",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I68891433",
      "name": "Indian Institute of Technology Delhi",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I119939252",
      "name": "Indraprastha Institute of Information Technology Delhi",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I4210089172",
      "name": "Midas Multispeciality Hospital",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I164861460",
      "name": "Manipal Academy of Higher Education",
      "country": "IN"
    }
  ]
}