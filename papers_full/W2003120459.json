{
    "title": "An expectation transformer approach to predicate abstraction and data independence for probabilistic programs",
    "url": "https://openalex.org/W2003120459",
    "year": 2010,
    "authors": [
        {
            "id": "https://openalex.org/A5019438409",
            "name": "Ukachukwu Ndukwu",
            "affiliations": [
                "Macquarie University"
            ]
        },
        {
            "id": "https://openalex.org/A5035107880",
            "name": "Annabelle McIver",
            "affiliations": [
                "Macquarie University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2134991157",
        "https://openalex.org/W2768978272",
        "https://openalex.org/W1734364899",
        "https://openalex.org/W2913459036",
        "https://openalex.org/W1516256348",
        "https://openalex.org/W2103953153",
        "https://openalex.org/W2092233450",
        "https://openalex.org/W2115856443",
        "https://openalex.org/W1498004481",
        "https://openalex.org/W2012001501",
        "https://openalex.org/W2074199912",
        "https://openalex.org/W2913788705",
        "https://openalex.org/W2126704329",
        "https://openalex.org/W2169677553",
        "https://openalex.org/W66273859",
        "https://openalex.org/W1996396409",
        "https://openalex.org/W2005998857"
    ],
    "abstract": "In this paper we revisit the well-known technique of predicate abstraction to\\ncharacterise performance attributes of system models incorporating probability.\\nWe recast the theory using expectation transformers, and identify transformer\\nproperties which correspond to abstractions that yield nevertheless exact bound\\non the performance of infinite state probabilistic systems. In addition, we\\nextend the developed technique to the special case of \"data independent\"\\nprograms incorporating probability. Finally, we demonstrate the subtleness of\\nthe extended technique by using the PRISM model checking tool to analyse an\\ninfinite state protocol, obtaining exact bounds on its performance.\\n",
    "full_text": "A. Di Pierro & G. Norman (Eds): 8th Workshop on Quantitative\nAspects of Programming Languages (QAPL 2010)\nEPTCS 28, 2010, pp. 129–143, doi:10.4204/EPTCS.28.9\nc⃝ Uk Ndukwu and AK McIver\nThis work is licensed under the\nCreative Commons Attribution License.\nAn expectation transformer approach to predicate\nabstraction and data independence\nfor probabilistic programs∗\nUkachukwu Ndukwu and AK McIver\nDeptartment of Computing, Macquarie University, NSW 2109 Australia.\n{ukndukwu,anabel}@science.mq.edu.au\nIn this paper we revisit the well-known technique of predicate abstraction to characterise performance\nattributes of system models incorporating probability. Werecast the theory using expectation trans-\nformers [8], and identify transformer properties which correspond to abstractions that yield never-\ntheless exact bound on the performance of inﬁnite state probabilistic systems. In addition, we extend\nthe developed technique to the special case of “data independent” programs [14] incorporating prob-\nability. Finally, we demonstrate the subtleness of the extended technique by using the PRISM model\nchecking tool [1] to analyse an inﬁnite state protocol, obtaining exact bounds on its performance.\n1 Introduction\nAutomated analysis of inﬁnite (very large) state systems often relies on abstractions which summarise the\nessential behaviour as a ﬁnite state “anti-reﬁnement” in such a way as to guarantee the desired properties\n(if indeed they hold). Typically, however, abstractions introduce nondeterminism, and in a probabilistic\nsystem this can lead to a high degree of imprecision in the estimated probabilistic properties. The choice\nof abstraction therefore is critical; some approaches to ﬁnding the right one use “abstraction reﬁnement”,\nsometimes relying on counterexamples of failed attempts toobtain incremental improvements [7].\nIn this paper we revisit the technique of “predicate abstraction” from the perspective of “expectation\ntransformers”.Predicate abstractionrefers to the notion of approximating a system using a given set of\npredicates: states are grouped together according to the predicates they satisfy (in the given set), and the\nsystem is abstracted by tracking only the transformations expressible in the induced equivalence classes.\nExpectation transformers[8] is a generalisation to probabilistic systems of Hoare/Dijkstra-style semantic\nreasoning [20] — predicates are replaced by real-valued functions of the state. The approach is equivalent\nto operational models of programming based on Markov-Decision Processes, but results in a convenient\nproof system for verifying general properties of probabilistic programs.\nIn particular we are able to characterise, using expectation transformers, a simple criterion for when\nan abstraction givesexactquantitative analysis for probabilistic properties. The criterion is sufﬁcient to\nidentify when predicate abstraction introduces no additional nondeterminism. A typical class of programs\nwhere this is effective is the so-called class of “data independent” programs [14]. A program isdata\nindependentwhenever its control structure does not depend on the precise values of the data. Wolper\n[14] ﬁrst identiﬁed this as a class of interesting programs amenable to veriﬁcation via model checking\n[9]. In addition to Wolper’s idea, we consider the notion of probabilistic data independence where the\nprobabilistic choice cannot be dependent on the data. In general, the idea we propose here is aimed\n∗The authors acknowledge support from (I) The Australian Commonwealth Endeavour International Postgraduate Research\nScholarship (E-IPRS) Fund, and (II) The Australian Research Council (ARC) Grant Number DP0879529.\n130 An expectation transformer approach to predicate abstraction\nat constructing abstractions which result in no loss of information especially when probability plays a\ncrucial role in the performance analysis of inﬁnite state system models. Such abstractions are said to be\n“information-preserving” since they sufﬁce as exact representations of their original systems.\nUsing the expectation transformer approach we prove the “folk theorem” (see [4]) for probabilistic\nsystems: that data independent programs can be treated withpredicate abstraction yielding exact results\non threshold properties such as “the probability that a set of states has been reached in at mostk steps”.\nIn particular our contributions in this paper are:\n(i) The development of a technique which permits the application of predicate abstraction to proba-\nbilistic programs using expectation transformers;\n(ii) An establishment of a criterion for identifying abstractions which do not lose information;\n(iii) We show how the developed technique and criterion can be applied to data independent programs\nespecially when probability plays a crucial role;\n(iv) And ﬁnally, a demonstration of the technique on a case study of a system with potential inﬁnite\nstate behaviour.\nThis paper is structured as follows: In Sec. 2 we summarise the expectation transformer semantics\nfor probabilistic programs, Sec. 3 is the development of thetechnique for predicate abstraction using\nexpectation transformers. In Sec. 4 we show how the technique can be applied to identify when predicate\nabstraction yields exact thresholds for inﬁnite state systems; we then explore the special treatment of\ndata independent programs. In Sec. 5 we illustrate the technique by model checking the Rabin’s choice\ncoordination problem (also known as the distributed consensus) [13]; this is a protocol which has the\npotential to require unbounded resources on its performance and therefore cannot be veriﬁed directly\nwith a model-checking approach. However the theory of Sec. 4shows that the results we obtain using its\ninformation-preserving abstraction are nevertheless exact interpretations of its performance.\n1.1 Summary of notation\nFunction application is represented by a dot, as inf·x (rather thanf(x)). We use an abstract state spaceS.\nGiven predicatePred we write[Pred] for thecharacteristicfunction mapping states satisfyingPred to 1\nand to 0 otherwise, punning 1 and 0 with “True” and “False” respectively. Whenevere,e′ are real-valued\nfunctions overS we writee+ e′,e ⊔ e′,e ⊓ e′ for the pointwise addition, maximum and minimum.\nMoreover\nα ×e ise scaled by the realα .\nFor commutative operator⊙, we use(⊙x ∈ X · f·x) for the comprehension which applies⊙ between\nall instancesf· x asx ranges overX . For example,( ⊔ x ∈ [0,1] · x2) gives the maximum value ofx2 as\nx ranges over the closed interval[0,1].\n2 Probabilistic program semantics and expectation transformers\nWhen programs incorporate probability, their properties can no longer be guaranteed “with certainty”,\nbut only “up to some probability”. For example the program\ninc ˆ= x := x/2 1/2⊕ x+1 , (1)\nsets the integer-valued variablex tox/2 (the result of the integer division) only with probability1/2\n— in practice this means that if the statement (1) were executed a large number of times, and the number\nUk Ndukwu and AK McIver 131\nof times thatx was halved or increased tabulated, roughly 1/2 of them would recordx as having been\nhalved (up to well-known statistical conﬁdence [15]).\nThe probabilistic guarded command language pGCL [8] and itsassociatedquantitative logicwere\ndeveloped to express such programs and to derive their probabilistic properties by extending the classical\nassertional style of programming. Programs in the pGCL are modeled (operationally) as functions (or\ntransitions) which mapinitial statesin S to (sets of) probability distributions overﬁnal states— the\nprogram at (1) for instance has a single transition which maps any initial statex = k0 to a (single) ﬁnal\ndistribution; we represent that distribution as a functiond, evaluating to 1/2 when x = k0/2 orx = k0+1.\nSince properties are now quantitative we express them via a logic ofreal-valued functions, orexpec-\ntations. For example, the property “if the initial state satisﬁesx = 0 ∨ x = 2, then the ﬁnal value ofx is\n1 with probability 1/2” can be expressed as theexpected valueof the function[x = 1] with respect tod,\nwhich evaluates to 1/2 × 1 + 1/2 × 0 = 1/2, whenx is initially 2 for example.\nDirect appeal to the operational semantics quickly becomesimpractical for all but the simplest pro-\ngrams — better is the equivalent transformer-style semantics which is obtained by rationalising the above\ncalculation in terms of expected values rather than transitions, and the explanation runs as follows. Writ-\ningE S for the set of all (non-normalised) functions fromS to the interval[0,1], which we call the set of\nexpectations, we say that the expectation[x = 1] has been transformed to the expectation[x = 0∨x= 2]/2\nby the programinc(1) above so that they are in the relation “1/2 is the expected value of[x = 1] with\nrespect toinc’s result distribution wheneverx is initially either 0 or 2”. More generally given a program\nProg, an expectatione inE S and a states∈ S, we deﬁnewp.Prog.e.s to be the expected value ofe with\nrespect to the result distribution of programProg if executed initially from states. We say thatwp.Prog\nis theexpectation transformerrelative toProg. In our example that allows us to write\n[x = 0 ∨ x = 2]/2 = wp.(x := x/2 1/2⊕ x := x+1).[x = 1] .\nIn the case thatnondeterminismis present, execution ofProg results in asetof possible distributions and\nwe modify the deﬁnition ofwp to take account of this — indeed we deﬁnewp.Prog.E .sso that it delivers\ntheleast-expected value with respect to all distributions in the result set. The transformers [8] give rise\nto a complete characterisation of probabilistic programs with nondeterminism, and they are sufﬁcient to\nexpress many performance-style properties, including theprobability that an event occurs, the expected\ntime that it occurs, and long-run average of the number of times it occurs over many repeated executions\nof the system.\nIn Fig. 1 we set out the semantics for the pGCL, a variation of Dijkstra’s GCL with the addition of\nprobabilistic choice. All the programming features have been deﬁned previously elsewhere, and (apart\nfrom probabilistic choice) have interpretations which aremerely adapted to the real-valued context. For\nexample, nondeterminism, as explained above, is interpreted demonicallyand can be thought of as being\nresolved by a “minimal-seeking demon”, providing guarantees on all program behaviour, such as is\nexpected for total correctness.Probabilistic choice, on the other hand, selects the operands at random\nwith weightings determined by the probability parameterp. Iteration is deﬁned by a least ﬁxed point of\na monotone expectation-to-expectation function.1\nWe end this section with a discussion of a simple performanceproperty: a probabilistic analysis of\nthe number of iterations until termination. Given a loopdo G → Prog od which executes the program\nProg untilG becomes false, we can compute the probability that the loop has executed no more thank\n1Well-deﬁnedness is guaranteed by, for example, restricting the expectations to lie in the real interval[0,1] or to complete\nthe reals with∞ . These issues have been discussed elsewhere [8].\n132 An expectation transformer approach to predicate abstraction\nskip wp.skip.E ˆ= E ,\nabort wp.abort.E ˆ= 0 ,\nassignment wp.(x := f).E ˆ= E [x := f] ,\nsequential compositionwp.(ro\n9 r′).E ˆ= wp.r.(wp.r′.E ) ,\nprobabilistic choice wp.(rp⊕ r′).E ˆ= p × wp.r.E + (1−p) × wp.r′.E ,\nnondeterministic choicewp.(r [] r′).E ˆ= wp.r.E ⊓ wp.r′.E ,\nBoolean choice wp.(if G then r else r′).E ˆ= [G ] × wp.r.E + [¬G ] × wp.r′.E ,\nIteration wp.(do G → r od).E ˆ= (µ X • [¬G ]×E + [G ]×wp.r.X ) .\nE is an expectation inE S, andf is a function of the state, and⊓ is pointwise minimum. The realp is restricted\nto lie between 0 and 1, and the term (µ X ...) refers to the least ﬁxed point with respect to≤, which we lift to real-\nvalued functions. Commands are ordered usingreﬁnement, so that more reﬁned programs improve probabilistic\nresults, thusP ⊑ Q iff (∀E ∈ E S · wp.P.E ≤ wp.Q .E ); note also that themonotone property of wp is such that if\nE ≤ E\n′\nthenwp.P.E ≤ wp.P.E\n′\n, whereP,Q are program commands andE ,E\n′\nare expectations.\nFigure 1: Structural deﬁnitions ofwp for the pGCL.\ntimes on termination as:\nwp.do G → Prog;n := n+1 od.[n ≤ k] , (2)\nwhere n is a fresh variable, not occurring inProg. Informally, ifn is initialised to 0 before the execution\nof the loop and is incremented after each execution ofProg, this expresses the (minimum) probability\nthat its value on exiting the loop does not exceedk. When no nondeterminism is present the expression in\n(2) computes an exact bound for expected performance; when it is present it computes the greatest lower\nbound. However upper bounds can be calculated using a maximum interpretation of nondeterminism but\nwe do not discuss that interpretation here.\nIn this section we have summarised an expectation transformer approach to probabilistic semantics.\nIn many cases, especially for performance, the exact analysis of the system in this style is impractical; an\nalternative to calculation is model checking, however thisis not viable for very large or inﬁnite systems.\nPredicate abstraction is a popular approach to approximating such programs, and in the next section we\ndevelop the expectation transformer approach to predicateabstraction for probabilistic programs.\n3 Abstract expectation transformers\nPredicate abstraction is a standard technique for deﬁning abstractions of transition systems. In this section\nwe will show how to deﬁne it for probabilistic programs usingexpectation transformers. The approach is\ninspired by Ball’s formalisation of predicate abstractionfor standard sequential programs using weakest\nprecondition semantics [17].\nLetΦ be a (ﬁnite) set of predicates over the state spaceS. The standard predicate abstraction overΦ\nis induced by the equivalence class:\ns∼Φ s′ iff (∀\nφ ∈ Φ · φ .s= φ .s′) .\nGiven a transition systemT overS, the abstract transition systemT /∼Φ takes the equivalence classes\ngiven byS/ ∼Φ as the state space, and their transitions ˆs → ˆt in T / ∼Φ provided that there exists a\nUk Ndukwu and AK McIver 133\ntransitions → t inT . The probabilistic generalisation is somewhat more complicated to deﬁne. On the\nother hand the expectation transformer semantics characterises operational behaviour, and the approach\nwe take here is to deﬁne the abstract transition system overS/Φ using a generalisation of Ball’s idea.\nLet cubes.Φ be the (ﬁnite) set of (non trivial) minimal predicates formed by taking negations and\nconjunctions of predicates inΦ . The setcubes.Φ corresponds to the (set of) equivalence classesS/∼Φ ,\nand represents the abstract state space of the abstraction induced byΦ . LetcubedΦ :E S → E S be deﬁned\ncubedΦ .e ˆ= ( ⊔ c ∈ cubes.Φ · ( ⊔ λ [c] ≤ e · λ [c])) . (3)\nWe note thatcubedΦ .e is unique and would usually be a linear combination of the elements ofcubes.Φ ,\nhence making it the sum of scaled cubes over the latter. Consequently,cubed.e is the weakest approxi-\nmation ofe with respect to the granularity expressible by conjunctions, negations and disjunctions inΦ .\nWe say thate iscubed relative toΦ exactly whene = cubedΦ .e. Note thatcubed.cubed.e = cubed.e and\nthat sums, maxima and minima of cubed expressions are still cubes, i.e.\n3(a) cubed.(cubed.e+ cubed.e′) = (cubed.e+ cubed.e′) ,\n3(b) cubed.(cubed.e ⊔ cubed.e′) = (cubed.e ⊔ cubed.e′) ,\n3(c) cubed.(cubed.e ⊓ cubed.e′) = (cubed.e ⊓ cubed.e′) .\nDeﬁnition 1.Given a pGCL program Prog, and a set of predicatesΦ , and expectation e over S we deﬁne\nthe abstract weakest expectation relative toΦ as:\nwpΦ .Prog.e ˆ= cubedΦ .wp.Prog.e .\nWe write ProgΦ for the corresponding abstract program operating over the abstract system S/Φ . This\nimplies that ProgΦ is determined bywpΦ .Prog.\nAs an example, consider the programincat (1) operating under arithmetic modulo 4. The underlying\nstate space is deﬁned by 0≤ x < 4; consider now the setΦ consisting of the single predicatex = 0∨x= 2;\nthe set of cubescubes.Φ ˆ= {(x = 0 ∨ x = 2),(x = 1 ∨ x = 3)}, implying that the induced predicate\nabstraction has two states. We can see now that\nwpΦ .inc.[x = 1 ∨ x = 3] = [x = 0 ∨ x = 2]/2 ,\nand wpΦ .inc.[x = 0 ∨ x = 2] = [x = 1 ∨ x = 3]/2 ,\nwhich is consistent with the abstraction in Fig. 2, where each abstract state has a probability of at least\n1/2 of being transformed to the other state, with the remainingprobability being assigned to a nondeter-\nministic update.\nThe next lemma sets out some properties of the abstract expectation transformer.\nLemma 1. Let Prog,Prog′ be programs,Φ ,Φ ′ sets of predicates, and e,e′ expectations andα a real.\nThe following inequalities apply:\n(1) wpΦ .Prog.e ≤ wp.Prog.e\n(2) wpΦ .Prog.e ≤ wpΦ ∪Φ ′ .Prog.e\n(3) wpΦ .Prog.e+ wpΦ .Prog.e′ ≤ wpΦ .Prog.(e+ e′)\n(4) α ×wpΦ .Prog.e = wpΦ .Prog.(α ×e)\n(5) ( wpΦ .Prog.e−1) ⊔ 0) ≤ wpΦ .Prog.((e−1) ⊔ 0)\nProof: The inequalities and equalities all follow from arithmetic and Def. 1.\n134 An expectation transformer approach to predicate abstraction\n0\n1\n2\n3\n1\n3\n0 \n2\nThe transition system on the left represents the programincover the state space deﬁned by 0≤ x < 4, using\narithmetic modulo 4. Each solid black arrow occurs with probability 1/2. The transition system on the right is\nthe abstraction based onΦ = {x = 0 ∨ x = 2}. Here we can see non determinism (indicated by dotted lines)is\nintroduced after any transition which divides the value ofx by 2.\nFigure 2: The transition system forincand an abstraction.\nLem. 1 conﬁrms our intuition that (1) the properties measured with respect to the abstraction are no\nmore than with respect to the original program; (2) ﬁner-grained abstractions give more accurate results\nand (3,4,5)wpΦ .Prog corresponds to a well-deﬁned probabilistic transition system [8].\nFor standard transitions systems (with no probability) an abstract systemProgΦ is determined directly\nfrom the control structure and assignment statements. Thiscorresponds towpΦ distributing through the\nprogram operators. For probabilistic systems this is not the case. For example, the programinc;inc\n(with addition modulo 4) we may compute 3[x = 0 ∨ x = 2]/4 ≤ wpΦ .(inc;inc).[x = 0 ∨ x = 2], whereas\n[x = 0 ∨ x = 2]/4 = wpΦ .inc.(wpΦ .inc).[x = 0 ∨ x = 2], implying that the nondeterminism introduced at\neach abstract transition will increase the inaccuracy. Comparing with Fig. 2 we see that nondeterminism\nis introduced at each abstract transition, and this could beresolved in the abstract system in such a way\nthat there is only 1/4 chance of returning to the initial abstract state.\nThe following lemma shows thatwpΦ only distributes through nondeterminism, and only subdis-\ntributes through sequential composition and probabilistic choice.\nLemma 2. Let Prog,Prog′ be programs,Φ ,Φ ′ sets of predicates, and e,e′ expectations. The following\ninequalities apply:\n(4) wpΦ .(Prog [] Prog′).e = wpΦ .Prog.e ⊓ wpΦ .Prog′.e\n(5) wpΦ .Prog.(wpΦ .Prog′).e ≤ wpΦ .(Prog;Prog′).e\n(6) wpΦ .(Prog) p⊕ wpΦ .Prog′.e ≤ wpΦ .(Prog p⊕ Prog′).e\nProof: The inequalities and equalities all follow from arithmetic and Def. 1.\nLem. 2 implies that whenever nondeterminism is introduced,the analysis of a program abstracted\nat each program statement could be too coarse to verify a desired quantitative threshold. This is not a\nproblem when the abstraction does not introduce nondeterminism. Consider the program\ntwoFlip ˆ= x := 0 p⊕ x := 1;y := 0 q⊕ y := 1 , (4)\nand the set of predicatesΦ ˆ= {x = y,x ̸= y}. The resulting transition system over the state space deﬁned\nby x and y is set out in Fig. 3 together with the abstraction induced by thisΦ .\nUk Ndukwu and AK McIver 135\n0 \n0\n0 \n1\n1 \n1\n1 \n0\npq \np(1-q) \n(1-p)q \n(1-p)(1-q) \nx=y \nx≠y \npq+(1-p)(1-q) \np+q-2pq \np+q-2pq \npq+(1-p)(1-q) \nThe transition system (labelled with probabilities) on theleft represents the programtwoFlipover the state space\ndeﬁned by variablesx and y, each of which can take 0 or 1 value in the states (x,y). Each branch is executed with\nthe probability that it occurs; only the transitions fromx = y = 0 are illustrated, with transitions from the remaining\nstates similarly calculated. The transition system on the right represents the abstraction which only keeps track of\nwhetherx and y are equal or not. Since no nondeterminism is introduced, properties at that level of granularity can\nbe accurately calculated using this abstraction.\nFigure 3: The transition system fortwoFlipand an abstraction.\nObserve how no nondeterminism has been introduced in this abstraction — since indeed\nwpΦ .(twoFlip;twoFlip) =wpΦ .(twoFlip);wpΦ .(twoFlip). Intuitively this tells us that properties which\ncan be stated at the granularity ofΦ can be computed accurately from its corresponding abstraction. In\nthe next section we formalise our intuition using expectation transformers.\n4 Information-preserving abstractions and expected time to terminate\nIn this section we introduce “information-preserving” abstractions and study how they apply to the com-\nputation of exact bounds on performance-style properties of probabilistic programs.\nAs we saw above, an abstraction which does not introduce nondeterminism preserves the exact be-\nhaviour of the program at the granularity of the chosen set ofpredicates. Programs which do not exhibit\nnondeterminism or aborting behaviours satisfy the specialproperties that:\nwpΦ .Prog.(e+ e\n′\n) = wpΦ .Prog.e+ wpΦ .Prog.e\n′\nwpΦ .Prog.(1 − e) = 1 − wpΦ .Prog.e\nfor anydeterministicpGCL program command Prog, set of predicateΦ , and expectationse,e′. The next\ndeﬁnition formalises that idea in terms of expectation transformers.\nDeﬁnition 2.Given a deterministic program Prog and a set of predicatesΦ , we say that the abstraction\ninduced byΦ isinformation-preservingif:\nwpΦ .Prog.[c] = wp.Prog.[c] ,\nfor all c∈ cubes.Φ .\nTo see Def. 2 in action, observe that\n136 An expectation transformer approach to predicate abstraction\nwp.inc.[x = 0 ∨ x = 2]\n= [ x = 0 ∨ x = 3]/2+[x = 1]\n̸= [ x = 1 ∨ x = 3]/2\n= wpΦ .inc.[x = 0 ∨ x = 2] ,\nimplying the introduction of a nondeterministic branch at the abstract state corresponding tox= 1∨x= 3.\nA more efﬁcient way to check for information-preservation is simply to check thatwp.Prog.[φ ] is\ncubed for allφ ∈ Φ ; the next lemma shows that this is sound.\nLemma 3. Let Prog be a deterministic (probabilistic) program, and let Φ be a set of predicates. If\nwp.Prog.[φ ] is cubed for allφ ∈ Φ then the abstraction induced byΦ is information-preserving.\nProof: We need to show thatwp.Prog.[c] =wpΦ .Prog.[c] for all c∈ cubed.Φ . Note that each such c\nis generated from negations and conjunctions, so all we needshow is that for predicatesψ ,ψ ′ such that\nwp.Prog.[ψ ] and wp.Prog.[ψ ′] are cubed, then so too arewp.Prog.(1 − [ψ ]) and wp.Prog.[ψ ∧ ψ ′].\nThe result follows sincewp.Prog.[ψ ∧ψ ′] = (wp.Prog.[ψ ]+ wp.Prog.[ψ ]′ −1) ⊔ 0, andwp.Prog.(1−\n[ψ ]) =1 − wp.Prog.[ψ ], and the fact that sums and inverses of cubed expressions arestill cubed.\nAs mentioned above, a key characterising property of information-preserving abstractions is that\nthey generate no new nondeterminism. A probabilistic program exhibits no (demonic) nondeterminism\nif its expectation transformer semantics distributes addition. The next lemma shows this for information-\npreserving abstractions.\nLemma 4. Let Prog be a deterministic (probabilistic) program, and letΦ be a set of predicates inducing\nan information-preserving abstraction on Prog. The predicate transformerwpΦ .Prog is deterministic on\ncubed expectations.\nProof: The result follows by showing thatwp.Prog = wpΦ .Prog on cubed expressions. Assume ﬁrst\nthat c,c′ ∈ cubes.Φ , and that\nλ ,λ ′ are reals. We reason as follows:\nwpΦ .Prog.(λ [c] +λ ′[c′])\n≤ wp.Prog.(λ [c] +λ ′[c′]) Lem. 1 (1)\n= λ wp.Prog.[c] +λ ′wp.Prog.[c′] Prog is deterministic\n= λ wpΦ .Prog.[c] +λ ′wpΦ .Prog.[c′] Prog is information-preserving\n≤ wpΦ .Prog.(λ [c] +λ ′[c′]) . Lem. 1 (3)\nObserve ﬁnally that the equality generalises for expressions consisting of ﬁnite sums of cubes, and the\nfact that there are only ﬁnitely many distinct cubes whenever Φ is ﬁnite.\nIn particular we can now see that information-preserving abstractions compute exact results for all\ncubed expressions:\nCorollary 1.Let Prog be a deterministic (probabilistic) program, and letΦ be a set of predicates induc-\ning an information-preserving abstraction on Prog. ThenwpΦ .Prog.e = wp.Prog.e whenever e is cubed.\nProof: Follows since if e is cubed then it is a ﬁnite sum of scaled cubes, and by Lem. 4wpΦ .Prog\ndistributes addition.\n4.1 Computing abstractions component-wise\nThe above notions assume that the abstraction is calculatedwholesale on the programProg; in practice it\nmay be more efﬁcient to calculate the abstraction by computing it relative to, and on smaller components\nof the program, however as Lem. 2 (5,6) indicate, additionalinaccuracies can creep in wherever the\nabstraction is computed from program components.\nUk Ndukwu and AK McIver 137\nFortunately this does not occur in the case of information-preserving abstractions: Lem. 4 is key to\nverifying that information-preserving abstractions are determined from their components alone, provided\nthat they themselves are also information-preserving. In practical terms this means that in a transition-\nsystem, provided each transition preserves the information, then so will the abstraction. In our predicate\ntransformer framework, we need to show thatwpΦ distributes sequential composition and probabilistic\nchoice.\nLemma 5. Let Prog,Prog′ be deterministic (probabilistic) programs, and letΦ be a set of predicates\ninducing an information-preserving abstraction on each. The following inequalities apply:\n(5′) wpΦ .Prog.(wpΦ .Prog′) = wpΦ .(Prog;Prog′)\n(6′) wpΦ .Prog p⊕ wpΦ .Prog′ = wpΦ .(Prog p⊕ Prog′) .\nProof: Follows easily from Lem. 4 sincewpΦ .Prog and wpΦ .Prog′ are both cubed expressions.\n4.2 Computing average performance\nSigniﬁcantly, we can now compute expected performance proﬁles exactly from the abstraction.\nLemma 6. Let Prog be a deterministic program, and information-preserving with respect toΦ , and\nsuppose that G,(n ≤ k) ∈ Φ , where k is an integer. The following equalities hold:\nwp.(do G → Prog;n := n+1 od).[n ≤ k] = wp.(do ˆG → ProgΦ ;n := n+1 od).[n ≤ k] ,\nwhere ˆG represents the abstraction of G in S/ ∼Φ .\nProof:\nLet N ˆ= wp.(do G → Prog;n := n+1 od).[n ≤ k], and NΦ ˆ= wp.(do ˆG → ProgΦ ;n := n+1 od).[n ≤ k].\nBy Lem. 1 (1), and monotonicity of the programming language Fig. 1 we see that NΦ ≤ N. To show\nthat N≤ N Φ we note that N and NΦ are both least ﬁxed points of monotone expectation-to-expectation\nfunctions. We use the least ﬁxed point property of functionsover partially-ordered sets, i.e. that if f.x ≤ x\nthen\nµ .f ≤ x [2]. Applied to N and NΦ we establish that NΦ satisﬁes the least ﬁxed point equation for N\nas follows:\n[G ]×[n ≤ k] + [¬G ]×wpΦ .Prog.N\n= [ G ]×[n ≤ k] + [¬G ]×wp.Prog.N Φ cubedΦ .N Φ = N Φ (see below); Lem. 4\n= N Φ . N Φ is a ﬁxed point\nThe result now follows since N is the least ﬁxed point of the function(λ x· [G ]×n + [¬G ]×wp.Prog.x).\nFor the “see below” part, note that NΦ is itself a ﬁxed point, satisfying: NΦ = [G ]×[n ≤ k] +\n[¬G ]×wpΦ .Prog.N Φ . It now follows that NΦ is cubed sincewpΦ .Prog.e is, for any expression e.\nMore generally exact bounds can be computed even when the program exhibits ﬁnitely-branching\nnondeterminism.\nCorollary 2.Let Prog1 ...Progm be deterministic and information-preserving with respectto Φ . Let\nG ∈ Φ , and n a fresh variable. The following equality holds:\nwp.Prog.(do G → (Prog1 [] ...[] Progm od).[n ≤ k]\n= wp.Prog.(do G → (Prog1Φ [] ...[] Progm Φ od).[n ≤ k] .\nProof: The proof is similar to Lem. 6 since nondeterminism distributes by Lem. 1 (4).\nThe signiﬁcance of Cor. 2 is that whenever the abstraction isknown to be information-preserving\ncomponent-wise over a program (or transition system), thenexact performance can be carried out on the\nabstraction. An important class of such programs are the so-called “data independent” systems, to which\nwe turn in the next section.\n138 An expectation transformer approach to predicate abstraction\n4.3 Data independence\nA program is said to bedata independent(with respect to a data typeX ) [14] if it cannot perform\noperations involving speciﬁc values of the type: speciﬁcally it can only input, output, store and make\ncomparisons using any relational operatorΘ ∈ { =,<,≤,>,≥,...}. Wolper points out that many dis-\ntributed protocols fall into this category — he shows that such systems can be model checked accurately.\nIn fact, if we extend this informal deﬁnition to probabilistic programs such that all probabilistic choices\nare constants, then our results above imply that there is an abstraction which can be used to compute\nperformance properties exactly, namely the abstraction induced by predicatesΨ ˆ= {x Θ y | ∀x,y program\nvariables of same type}. We use this intuition to deﬁne a simple characterisation ofdata independent\nprograms: they are the programs which are information-preserving with respect toΨ (with informal\ndeﬁnition above).\nDeﬁnition 3.Let Prog be a deterministic pGCL program with variables x1 ...xm . We say that Prog is\ndata independentwith respect to x1 ...xm provided that Prog is information-preserving with respectto the\nabstraction induced byΨ , whereΨ is the set of predicates containing all expressions of the form xi Θ yj\nfor all1 ≤ i,j,≤ m.\nNote that this characterisation of data independence can begeneralised to programsProg1 [] ...[] Progn\nwhich exhibit nondeterministic behaviour by ensuring thatthe deterministic componentsProgi comply\nwith Def. 3. Note that this deﬁnition shares some similarities with Wolper’s denotational characterisation\n[14], in that Def. 3 captures the idea that properties expressible at the granularity ofΦ are shared by both\nProgΦ and Prog. It does not deal with general types however, as does Lazic [16].\nWith Def. 3 we can now conclude that data independent probabilistic programs have abstractions\nwhich preserve performance bounds.\nLemma 7. Let Prog be a data independent program. Then the expected number of iterationsdo G →\nProg od may be computed exactly using the abstract program ProgΨ whenever G∈ Ψ , whereΨ is deﬁned\nin Def. 3.\nThe practical implication of Lem. 7 (which follows directlyfrom Lem. 6 and Cor. 2) is that perfor-\nmance (and correctness) of data independent programs can beanalysed exactlyusing model checking.\nIn the next section we give an example to illustrate this idea.\n5 Case study: Rabin’s distributed consensus\nWe illustrate the effectiveness of our technique on the Rabin’s choice-coordination problem [13]. The\nstate space generated on execution of the algorithm is potentially inﬁnite hence limiting the scope of\nmodel checking on verifying liveness properties (such as termination conditions) relating to its overall\nperformance. As we will see, even though the algorithm is notquite data independent, there does exist\nan information-preserving abstraction demonstrating that exact numerical analysis is still possible on its\nperformance.\n5.1 Informal description\nA group of tourists are to decide between two meeting places (which are not of interest to us). A major\nconstraint is that they may not communicate as a group; nor isthere a central “authority” (e.g.a tour\nguide) whose decision overrides theirs.\nUk Ndukwu and AK McIver 139\nEach tourist carries a notepad on which he will write variousnumbers; outside each of the two\npotential meeting places is a noticeboard on which various messages will be written. Initially the number\nzero appears on all the notepads and on the two noticeboards.\nEach tourist decides independently (demonically) which meeting place to visit ﬁrst, after which he\nstrictly alternates his visits between them. At each place he looks at the noticeboard, and if it displays\n“here”, he goes inside. If it does not display “here” it will display a number instead, in which case the\ntourist compares that numberK with the numberk on his notepad and does one of the following:\nifk < K — The tourist writesK on his notepad (erasingk), and goes to the other place.\nifk > K — The tourist writes “here” on the noticeboard (erasingK ), and goes inside.\nifk = K — The tourist choosesK\n′\n, the next even number larger thanK , and then ﬂips a coin: if it\ncomes up heads, he increasesK\n′\nby a further one. He then writesK\n′\non the noticeboard and on his\nnotepad (erasingk and K ), and goes to the other place.2\nA key characterisation of the Rabin’s algorithm, which has also been proved elsewhere [8] is that, on\ntermination all the tourists’ will converge at the same meeting place, and that happens with probability\n1. However it is not always the case that an “observer” can witness every state of the program that will\nlead to termination. For example, it is possible thatthe tourists will forever (according to an observer)\nkeep updating their notepads and the noticeboards without deciding on a meeting place.This enforces\nan unbounded state behaviour on the algorithm. Nonetheless, given the unbounded state nature of the\nalgorithm, our theoretical results still permit us to studya suitable performance attribute of the system:\nthe expected number of rounds (or steps) of the protocol until termination (analogous to convergence).\n5.2 A pGCL snapshot of the Rabin’s algorithm\nFig. 4 (on the next page) gives an overview of the Rabin’s choice-coordination problem in the pGCL.\nWe call the two meeting places “left” and “right” as we discuss it and refer to the notations3 accordingly.\nBag lout (rout)is the bag of numbers held by tourists waiting to look at the left (right) noticeboard; bag\nlin (rin)is the bag of numbers held by tourists who have already decided on the left (right) alternative;\nnumber L (R)is the number on the left (right) noticeboard. Initially there areA (B)tourists on the left\n(right), all holding the number zero; no tourist has yet madea decision, and both noticeboards show zero.\nExecution is as follows: if some tourists are still undecided (so thatlout (rout)is not yet empty),\nselect one: the number he holds isl (r). If some tourist has already decided on this alternative (sothatlin\n(rin)is not empty), this tourist does the same; otherwise any of the three possibilities discussed above is\nexecuted.\n5.3 Computing average performance of the Rabin’s algorithm\nIn this section we discuss properties of the Rabin’s algorithm sufﬁcient for an analysis of its average per-\nformance. Since the unbounded state nature of the algorithmlimits the scope of model checking on the\n2For example ifK is 2 or 3, thenK\n′\nbecomes 4 and then possibly 5.\n3[[ ...]] — bag (multiset) brackets;□ —empty bag; [[ n ]]N —bag containingN copies all of valuen;take n from b — a\nprogram command which chooses an element demonically from non-empty bagb, assigns it ton and removes it fromb;add\nn to b —add element n to bagb;n —the “conjugate” ofn, it isn + 1 ifn is even andn − 1 ifn is odd; #b — the number of\nelements in a bag b.\n140 An expectation transformer approach to predicate abstraction\nlout,rout ˆ= [[0 ]]A , [[ 0 ]]B ;\nlin,rin ˆ= □ , □ ;\nL,R ˆ= 0, 0 ;\ndo lout̸= □ →\ntakelfrom lout;\niflin̸= □ then addltolinelse\nl> L → add ltolin\n[] l= L → (L := L + 2 1\n2\n⊕ (L + 2); add L torout\n[] l< L → add L torout\nﬁ\n[] rout̸= □ →\ntaker from rout;\nifrin̸= □ then addr torinelse\nr > R → add r torin\n[] r = R → (R := R + 2 1\n2\n⊕ (R + 2); add R tolout\n[] r < R → add R tolout\nﬁ\nod\nFigure 4: The Rabin’s choice coordination algorithm in the pGCL (adapted from [8]).\noriginal system, we must therefore compute a suitable abstraction prior to performance analysis. Never-\ntheless, with our proposed technique, it is possible to defeat the overhead incurred by model checking\nthe unbounded state system just by model checking its information-preserving abstraction.\nOne performance property of interest is captured by computing the minimum probabilityPmin, that\nwithin a ﬁnite number of stepsT , the tourists eventually converge at the same meeting placeon termina-\ntion. In the logic PCTL [6], directly supported by the PRISM tool, we express this property as\nPmin =?[true U≤T (#lin= N ) | (#rin= N )], (5)\nwhere N represents the total number of tourists who will initially decide on where to meeti.e. N= A + B.\nSimilarly, with the reward structures [12] of the PCTL we compute the expected number of rounds\nof the protocol until termination. Again, this will be done on the protocol’s abstraction using the speciﬁ-\ncation:\nRmin | Rmax =?[F (#lin= N ) | (#rin= N )]. (6)\nThe parametersRmin and Rmax respectively represent the expected minimum and maximum rewards\n(expected number of rounds) until the tourists eventually converge at the same meeting place. We note\nthat states where the tourists have not yet met the convergence condition are worth a reward value of one.\nIn the sections that follow, we explain how we identify essential behaviours of the algorithm that\nwill permit the construction of an information-preservingabstraction upon which the analysis can be\nperformed.\n5.4 An information-preserving abstraction\nAs earlier stated, even though the Rabin’s algorithm has unbounded state behaviour, it is not data in-\ndependent since the probabilistic update increments the variablesL,R etc. However there is still an\nUk Ndukwu and AK McIver 141\nFigure 5: Performance result of Rabin’s algorithm for N = 2, 3.\nNumber of Tourists Rmin Rmax\nN = 2 2 7\nN = 3 2 11\nFigure 6: Expected number of steps\ninformation-preserving abstraction, which we will now describe.\nObserve that although the noticeboard values are incremented, they always maintain|L − R| ≤ 2. In\nterms of the algorithm, the only information that needs to bepreserved is the valueL − R and whether\nL,R are odd or even. Finally, the relative values of the tourists’ numbers toL and R also need to be\nrecorded, as well as their location. This generates an information-preserving abstraction. In practice, we\ncharacterise the relationship between the noticeboard values using a fresh variable we callslot, which\ncan only take values in{0, 1, 2} — since the noticeboard values and hence the notepad values can only\nlie in one of these slots for any given state of the system. We deﬁne the slot variable as follows and\ninterpret transitions in the abstract state with respect tothe slot values:\nslotˆ=\n\n\n\n0 if L = R\n1 if L = R − 2 ∨ R = L − 2\n2 if L =\nR .\nIn the section that follows, we explain the performance results derived from the information-preserving\nabstraction. The results nevertheless give a precise summary of the performance of the original system.\n5.5 Experimental results\nWe model the abstract behaviour discussed above for the basecases of even and odd number of tourists\n(N = 2,3) in the PRISM language, and similarly analyse the performance results as captured by the\nproperties in (5) and (6), using the experimentation facility of the tool. A similar model construction and\nanalysis for larger values ofN is also possible by repeating the same technique although very laborious.\n142 An expectation transformer approach to predicate abstraction\nFig. 5 captures the performance characteristics of the information-preserving abstraction of the Ra-\nbin’s algorithm. It clearly establishes the termination property of the unbounded state system using just\nits abstraction: note that both graphs converge to probability 1. In the original unbounded state system,\nachieving this is practically impossible. See the originalmodel in the compendium of case studies at [1].\nWe also observe (Fig. 6) that the expected minimum and maximum number of rounds until termina-\ntion can be model checked, and hence nevertheless gives an exact bound on the number of steps required\nfor the unbounded state system to terminate. Again, in the unbounded state system, the result of comput-\ningRmax for example isinﬁnity, which in the PRISM tool is interpreted to mean that it is not possible\nfor a terminating (or convergence) condition to be reached.\n6 Discussion\nWhile some probabilistic program logics allow programs to be compared even at abstract levels, for\nexample using the techniques in [5, 3], the underlying logicof the pGCL supports the notion of program\nreﬁnement and hence compositionality. This makes it easy torelate reﬁnement over concrete states to\ntheir abstract counterparts and furthermore with the otherprobabilistic program logics, given any context.\nOther approaches seek to use variations of counterexample guided predicate abstraction [10, 7] to\nautomate ﬁnding sets of predicates which generate ﬁner abstractions. One way to see the relationship\nwith our approach would be to note that when an abstraction isobserved to be information-preserving\n(according to Lem. 3 for example) then further reﬁnement is unnecessary. Kwiatkowska et al. [11]\npropose an approach to estimate the accuracy of the analysisimplied by any abstraction, conﬁrming that\nfor information-preserving abstractions the analysis is exact.\nOn the application level, one way to see the usefulness of ourtechnique is in the recent research\ndirection of linking proof-based veriﬁcation with model checking for probabilistic systems [18, 19].\nSince proof-based veriﬁcation can cope with proofs over inﬁnite state systems, a key challenge with this\ntechnique is then the identiﬁcation and constructing of information-preserving abstractions upon which\na model checking algorithmic veriﬁcation can be performed.This is still an open problem.\n7 Conclusion and future work\nIn this paper we have developed the theory of predicate abstraction for probabilistic programs within the\nframework of expectation transformers. We have similarly established a criterion to help discover when\nabstractions do not lose information especially for probabilistic programs; and we have demonstrated the\napplicability of the results to data independent programs (or at least their approximations).\nWhilst our theoretical approach identiﬁes when a set of predicates is information-preserving, it does\nnot provide assistance for ﬁnding one. Even though we have computed the abstraction by hand, we\nquickly remark that applying the manual construction technique forN > 3 would seem a laborious task.\nNote that our technique results in a huge success for verifying the termination condition of the algorithm\nwhen compared with the concrete system as modeled in the compendium of case studies at the URL [1].\nHowever, a future direction for this work would be to developan automated strategy which would\nconstruct abstractions “on the ﬂy”, given that our theoretical framework is rich enough to provide intu-\nitions to identifying sets of suitable predicates to aid theconstruction of information-preserving abstrac-\ntions.\nAcknowledgement: The authors are grateful to the anonymous reviewers for their helpful comments.\nUk Ndukwu and AK McIver 143\nReferences\n[1] PRISM: Probabilistic Symbolic Model Checker. URL:http: // www. prismmodelchecker.org/.\n[2] Tarski A.A Lattice-theoretic Fixpoint Theorem and its Applications.Paciﬁc Journal of Mathematics, 5:285-\n309, 1955.\n[3] Jou C. C. and Smolka S.A.Equivalences, Congruences, and Complete Axiomatizationsfor Probabilistic\nProcesses.In J. Baeten and J. Klop, Editors, CONCUR 90 1st Int. Conf. on Concurrency Theory, Number\n458 in LNCS V ol. 94:1-28, Springer, 1990.\n[4] Fudenberg D. and E. Maskin.The Folk Theorem in Repeated Games with Discounting or with Incomplete\nInformation.Econometrica, 1986.\n[5] Larsen K. G. and Skou A.Bisimulation Through Probablistic Testing.Information and Computation, 94:1-\n28, 1991.\n[6] Hansson H. and Jonsson B.A Logic for Reasoning about Time and Reliability.In Formal Aspects of Com-\nputing, 6(5):512-535, 1994.\n[7] Hermanns H., Wachter B., and Zhang L.Probabilistic CEGAR.In Proc. of the 20th international Conference\non Computer Aided Veriﬁcation, Princeton, NJ, USA, 2008.\n[8] McIver A. K. and Morgan C. C.Abstraction, Reﬁnement and Proof for Probabilistic Systems.Monographs\nin Computer Science, Springer, Verlag, 2004.\n[9] Clarke E. M., Grumberg O., and Peled D. A.Model Checking. MIT Press, 1999.\n[10] Kattenbelt M., Kwiatkowska M., Norman G., and Parker D.Abstraction Reﬁnement for Probabilistic Soft-\nware.In Proc. of 10th International Conference on Veriﬁcation, Model Checking and Abstract Interpretation\n(VMCAI ‘09), Springer, 2009.\n[11] Kwiatkowska M., Norman G., and Parker D.Game-based Abstraction for Markov Decision Processes.In\nProc. of 3rd International Conference on Quantitative Evaluation of Systems (QEST’06), pages 157-166,\nIEEE CS Press, 2006.\n[12] Kwiatkowska M., Norman G., and Parker D.Stochastic Model Checking. In Proc. of SFM’07 vol. 4486\nLNCS, 220-270, Springer, 2007.\n[13] Rabin M. O.The Choice Coordination Problem.Acta Informatica vol. 17, 121 - 134, 1982.\n[14] Wolper P.Expressing Interesting Properties of Programs in Propositional Temporal Logic. In Proc. of the\n13th Annual Symposium on Principles of Programming Languages, pp. 184 - 193, ACM, 1986.\n[15] Grimmett G. R. and Welsh D.Probability: An Introduction. Oxford Science Publications, 1986.\n[16] Lazi ´c R. A Semantic Study of Data Independence with Applications to Model Checking. DPhil Thesis, Oxford\nUniversity Computing Laboratory, 1999.\n[17] Ball T.Formalizing Counterexample-driven Reﬁnement with Weakest Preconditions.Technical Report MSR-\nTR-2004-134, Microsoft Research, Redmond, W A 98052, USA, 2004.\n[18] Ndukwu U. Quantitative Safety: Linking Proof-based Veriﬁcation with Model Checking for Probabilistic\nSystems.In Proc. First International Workshop on Quantitative Formal Methods (QFM 2009), Eindhoven,\nNetherlands, 2009.\n[19] Ndukwu U.Generating Counterexamples for Quantitative Safety Speciﬁcations in Probabilistic B.Submitted\nto the Journal of Logic and Algebraic Programming (JLAP) URL: http://web.science.mq.edu.au/\n~ukndukwu/counterexamples.pdf, 2010.\n[20] Dijkstra E. W.A Discipline of Programming. Prentice Hall International, Englewood Cliffs, N.J., 1976."
}