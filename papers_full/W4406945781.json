{
  "title": "Medical Misinformation in AI-Assisted Self-Diagnosis: Development of a Method (EvalPrompt) for Analyzing Large Language Models",
  "url": "https://openalex.org/W4406945781",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5107038593",
      "name": "Troy Zada",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2560956632",
      "name": "Natalie Tam",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2788968033",
      "name": "Francois Barnard",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5092457013",
      "name": "Marlize Van Sittert",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2121536448",
      "name": "Venkat Bhat",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2228413502",
      "name": "Sirisha Rambhatla",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4376872703",
    "https://openalex.org/W4321106177",
    "https://openalex.org/W4384834621",
    "https://openalex.org/W4389519982",
    "https://openalex.org/W4283170666",
    "https://openalex.org/W2403463510",
    "https://openalex.org/W2595038737",
    "https://openalex.org/W2997474044",
    "https://openalex.org/W4385683847",
    "https://openalex.org/W4392521983",
    "https://openalex.org/W4283578429",
    "https://openalex.org/W4281489185",
    "https://openalex.org/W3020431485",
    "https://openalex.org/W3156469750",
    "https://openalex.org/W4386845850",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4324130227",
    "https://openalex.org/W202246478",
    "https://openalex.org/W4366743045",
    "https://openalex.org/W4313232683",
    "https://openalex.org/W4320009668",
    "https://openalex.org/W4361282369",
    "https://openalex.org/W4319083882",
    "https://openalex.org/W4313564799",
    "https://openalex.org/W4321606060",
    "https://openalex.org/W4324304837",
    "https://openalex.org/W4319301446",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4323348223",
    "https://openalex.org/W4391069573",
    "https://openalex.org/W4384484700",
    "https://openalex.org/W4385573087",
    "https://openalex.org/W4323050332",
    "https://openalex.org/W4324373918",
    "https://openalex.org/W3129259813",
    "https://openalex.org/W4319301505",
    "https://openalex.org/W4312126568",
    "https://openalex.org/W4322718832",
    "https://openalex.org/W4312220150",
    "https://openalex.org/W4282981106",
    "https://openalex.org/W4220717877",
    "https://openalex.org/W4319341091",
    "https://openalex.org/W4402582321",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4390833061",
    "https://openalex.org/W4368366148",
    "https://openalex.org/W4386875611"
  ],
  "abstract": "Abstract Background Rapid integration of large language models (LLMs) in health care is sparking global discussion about their potential to revolutionize health care quality and accessibility. At a time when improving health care quality and access remains a critical concern for countries worldwide, the ability of these models to pass medical examinations is often cited as a reason to use them for medical training and diagnosis. However, the impact of their inevitable use as a self-diagnostic tool and their role in spreading health care misinformation has not been evaluated. Objective This study aims to assess the effectiveness of LLMs, particularly ChatGPT, from the perspective of an individual self-diagnosing to better understand the clarity, correctness, and robustness of the models. Methods We propose the comprehensive testing methodology evaluation of LLM prompts (EvalPrompt). This evaluation methodology uses multiple-choice medical licensing examination questions to evaluate LLM responses. Experiment 1 prompts ChatGPT with open-ended questions to mimic real-world self-diagnosis use cases, and experiment 2 performs sentence dropout on the correct responses from experiment 1 to mimic self-diagnosis with missing information. Humans then assess the responses returned by ChatGPT for both experiments to evaluate the clarity, correctness, and robustness of ChatGPT. Results In experiment 1, we found that ChatGPT-4.0 was deemed correct for 31% (29/94) of the questions by both nonexperts and experts, with only 34% (32/94) agreement between the 2 groups. Similarly, in experiment 2, which assessed robustness, 61% (92/152) of the responses continued to be categorized as correct by all assessors. As a result, in comparison to a passing threshold of 60%, ChatGPT-4.0 is considered incorrect and unclear, though robust. This indicates that sole reliance on ChatGPT-4.0 for self-diagnosis could increase the risk of individuals being misinformed. Conclusions The results highlight the modest capabilities of LLMs, as their responses are often unclear and inaccurate. Any medical advice provided by LLMs should be cautiously approached due to the significant risk of misinformation. However, evidence suggests that LLMs are steadily improving and could potentially play a role in health care systems in the future. To address the issue of medical misinformation, there is a pressing need for the development of a comprehensive self-diagnosis dataset. This dataset could enhance the reliability of LLMs in medical applications by featuring more realistic prompt styles with minimal information across a broader range of medical fields.",
  "full_text": null,
  "topic": "Preprint",
  "concepts": [
    {
      "name": "Preprint",
      "score": 0.9431531429290771
    },
    {
      "name": "Misinformation",
      "score": 0.8109738230705261
    },
    {
      "name": "Computer science",
      "score": 0.472662091255188
    },
    {
      "name": "Psychology",
      "score": 0.412079781293869
    },
    {
      "name": "Artificial intelligence",
      "score": 0.40518853068351746
    },
    {
      "name": "Natural language processing",
      "score": 0.3731960654258728
    },
    {
      "name": "World Wide Web",
      "score": 0.14872977137565613
    },
    {
      "name": "Computer security",
      "score": 0.08664733171463013
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I151746483",
      "name": "University of Waterloo",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I185261750",
      "name": "University of Toronto",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I1297363086",
      "name": "St. Michael's Hospital",
      "country": "CA"
    }
  ],
  "cited_by": 10
}