{
  "title": "A Study of Vulnerability Repair in JavaScript Programs with Large Language Models",
  "url": "https://openalex.org/W4393108609",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5027204658",
      "name": "Tan Khang Le",
      "affiliations": [
        "Simon Fraser University"
      ]
    },
    {
      "id": "https://openalex.org/A2229760896",
      "name": "Saba Alimadadi",
      "affiliations": [
        "Simon Fraser University"
      ]
    },
    {
      "id": "https://openalex.org/A2096722238",
      "name": "Steven Y. Ko",
      "affiliations": [
        "Simon Fraser University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6810081322",
    "https://openalex.org/W4320560161",
    "https://openalex.org/W3173591235",
    "https://openalex.org/W4244452926",
    "https://openalex.org/W4288057765",
    "https://openalex.org/W4385187421",
    "https://openalex.org/W4281763794",
    "https://openalex.org/W4224308101"
  ],
  "abstract": "In recent years, JavaScript has become the most widely used programming\\nlanguage, especially in web development. However, writing secure JavaScript\\ncode is not trivial, and programmers often make mistakes that lead to security\\nvulnerabilities in web applications. Large Language Models (LLMs) have\\ndemonstrated substantial advancements across multiple domains, and their\\nevolving capabilities indicate their potential for automatic code generation\\nbased on a required specification, including automatic bug fixing. In this\\nstudy, we explore the accuracy of LLMs, namely ChatGPT and Bard, in finding and\\nfixing security vulnerabilities in JavaScript programs. We also investigate the\\nimpact of context in a prompt on directing LLMs to produce a correct patch of\\nvulnerable JavaScript code. Our experiments on real-world software\\nvulnerabilities show that while LLMs are promising in automatic program repair\\nof JavaScript code, achieving a correct bug fix often requires an appropriate\\namount of context in the prompt.\\n",
  "full_text": "arXiv:2403.13193v1  [cs.CR]  19 Mar 2024\nA Study of Vulnerability Repair in JavaScript Programs with\nLarge Language Models\nTan Khang Le\nSimon Fraser University\nBurnaby, British Columbia, Canada\nkhang_le@sfu.ca\nSaba Alimadadi\nSimon Fraser University\nBurnaby, British Columbia, Canada\nsaba@sfu.ca\nSteven Y. Ko\nSimon Fraser University\nBurnaby, British Columbia, Canada\nsteveyko@sfu.ca\nABSTRACT\nIn recent years, JavaScript has become the most widely used p ro-\ngramming language, especially in web development. However , writ-\ning secure JavaScript code is not trivial, and programmers o ften\nmake mistakes that lead to security vulnerabilities in web a ppli-\ncations. Large Language Models (LLMs) have demonstrated su b-\nstantial advancements across multiple domains, and their e volv-\ning capabilities indicate their potential for automatic co de gener-\nation based on a required speciﬁcation, including automati c bug\nﬁxing. In this study, we explore the accuracy of LLMs, namely\nChatGPT and Bard, in ﬁnding and ﬁxing security vulnerabilit ies\nin JavaScript programs. We also investigate the impact of co ntext\nin a prompt on directing LLMs to produce a correct patch of vul -\nnerable JavaScript code. Our experiments on real-world sof tware\nvulnerabilities show that while LLMs are promising in autom atic\nprogram repair of JavaScript code, achieving a correct bug ﬁ x often\nrequires an appropriate amount of context in the prompt.\nCCS CONCEPTS\n• Security and privacy → Software and application security ;\nWeb application security ; • Computing methodologies → Ma-\nchine learning .\nKEYWORDS\nJavaScript, Automatic Program Repair, Large Language Mode ls, Prompt\nEngineering, CWE\nACM Reference Format:\nTan Khang Le, Saba Alimadadi, and Steven Y. Ko. 2024. A Study of Vul -\nnerability Repair in JavaScript Programs with Large Language Models . In\nCompanion Proceedings of the ACM Web Conference 2024 (WWW ’2 4 Com-\npanion), May 13–17, 2024, Singapore, Singapore. ACM, New York, NY, USA,\n5 pages. https://doi.org/10.1145/3589335.3651463\n1 INTRODUCTION\nDespite the prevalence and popularity of JavaScript progra ms, un-\nderstanding and analyzing them is challenging due to their h et-\nerogeneous, dynamic, and asynchronous nature. As a result, devel-\nopers are prone to making mistakes and exposing many JavaScr ipt\nPermission to make digital or hard copies of all or part of thi s work for personal or\nclassroom use is granted without fee provided that copies ar e not made or distributed\nfor proﬁt or commercial advantage and that copies bear this n otice and the full cita-\ntion on the ﬁrst page. Copyrights for components of this work owned by others than\nthe author(s) must be honored. Abstracting with credit is pe rmitted. To copy other-\nwise, or republish, to post on servers or to redistribute to l ists, requires prior speciﬁc\npermission and/or a fee. Request permissions from permissi ons@acm.org.\nWWW ’24 Companion, May 13–17, 2024, Singapore, Singapore\n© 2024 Copyright held by the owner/author(s). Publication r ights licensed to ACM.\nACM ISBN 979-8-4007-0172-6/24/05\nhttps://doi.org/10.1145/3589335.3651463\nprograms to security vulnerabilities [4]. Developers comm only use\nstatic analysis and fuzzing techniques to mitigate such bug s. How-\never, this process can be tedious in terms of understanding a nd\nidentifying the vulnerabilities, and subsequently modify ing the code\nto repair the bugs.\nWith the rapid development of artiﬁcial intelligence, Larg e Lan-\nguage Models (LLMs) are increasingly trained on large codeb ases\nwith the goal of automatic code generation based on speciﬁca tions\nfrom user inputs [2, 3, 10, 19]. This empowers LLMs to generat e\ncode in diﬀerent ways, given some context such as the develop er’s\nintention expressed in code comments. Although LLMs may oc-\ncasionally produce code with security bugs [14, 15], when co upled\nwith suitable security-aware tooling during code generati on, LLMs\nhave the potential to enhance a software developer’s produc tivity\n[12], thereby reducing the risks of introducing new securit y bugs.\nAs such, the research community has been actively investiga ting\nthe eﬀectiveness of LLMs in ﬁnding and ﬁxing code vulnerabil i-\nties [1, 6, 13, 17, 18]. Most of these studies, however, have f ocused\non programming languages such as C/C++ and Verilog. As such,\nwe currently do not have much insight into the role of LLMs in\nrepairing security vulnerabilities in a dynamic language s uch as\nJavaScript.\nIn this paper, we study the utilization of black-box, “oﬀ-th e-shelf\"\nLLMs, namely ChatGPT and Bard, in the automatic program repa ir\nof JavaScript code. Furthermore, we investigate the eﬀect o f con-\ntext (or cues) in a prompt on LLMs’ ability to generate accurate\nsecurity patches. We aim to address the following research q ues-\ntions:\n• RQ1: How accurate are LLMs in ﬁnding and ﬁxing vulner-\nabilities in JavaScript programs?\n• RQ2: How does the amount of context in a prompt impact\nthe eﬀectiveness of LLMs in producing a correct patch of\nvulnerable JavaScript code?\nTo answer these questions, we conduct a study on over 20 of the\nmost common software vulnerabilities. We compare three dis tinct\nprompt templates with varying degrees of contextual cues. These\ntemplates serve to guide LLMs in repairing vulnerable JavaS cript\ncode. In total, the study involves 60 prompts for two LLMs, co v-\nering the 20 identiﬁed vulnerabilities across the three pro posed\nprompt templates 1. The experimental results show that ChatGPT\nand Bard, on average, accurately generate patches for 71.66 % and\n68.33% of cases, respectively (RQ1). Furthermore, we ﬁnd th at the\nmore context provided in a prompt, the better ChatGPT and Bar d\nperform in producing a correct patch, with an improvement of up\nto 55% in accuracy (RQ2).\n1Our repair prompts and testing results are publicly availab le at:\nhttps://doi.org/10.5281/zenodo.10783763\nWWW ’24 Companion, May 13–17, 2024, Singapore, Singapore Tan K hang Le, Saba Alimadadi, and Steven Y. Ko\n2 RELATED WORK\nIn this section, we review the related work on code security a nd\nvulnerability as well as program repair with large language mod-\nels.\n2.1 Code Security and Vulnerability\nDue to the critical importance of safeguarding systems agai nst po-\ntential threats and breaches, there has been much research i nto\ncode security and vulnerability, providing insights into t he nature\nof security bugs and weaknesses. Speciﬁcally, as system err ors and\nvulnerabilities continue to grow over time, automated prog ram re-\npair [8] emerges as a research ﬁeld that focuses on a class of t ech-\nniques for producing source code-level patches for such bug s. A\nclassical approach for automated program repair is to turn t he pro-\ngram repair problem into a search problem. For example, Le Go ues\net al. [7] used genetic programming to search for a program va ri-\nant that addresses a bug in the given program without changin g\nthe required functionality or producing new errors. An alte rnative\napproach demonstrated by Nguyen et al. [9] is to use semantic anal-\nysis for the automatic construction of patches.\nThe development community also actively engages in studyin g\nand documenting vulnerabilities in software and hardware, such\nas the Common Weakness Enumeration (CWE). CWE functions as\na categorization system designed for both hardware and soft ware\nvulnerabilities, consisting of over 600 categories, namel y buﬀer\noverﬂows, race conditions, and cross-site scripting. Ever y year, MITRE\npublishes a list of the top 25 most dangerous software weakne sses\n(CWE Top 25) [16], which serves as a benchmark for evaluating\nmany automated program repair tools.\n2.2 Program Repair with Large Language\nModels (LLMs)\nWith the rise of LLMs in recent years, the ﬁeld of automated pr o-\ngram repair has seen many major advancements. Much research\nhas shown the potential of LLMs in automated bug ﬁxing for bot h\nsoftware and hardware programs. Particularly, Wu et al. [18 ] eval-\nuated ﬁve diﬀerent LLMs and four automatic program repair to ols\non two Java vulnerability benchmarks. With regard to hardwa re\nvulnerabilities, Ahmad et al. [1] attempted to repair hardw are bugs\nin Verilog programs automatically using LLMs. From the secu rity\nperspective, the study by Pearce et al. [13] on zero-shot vul nerabil-\nity repair demonstrated promising results of using LLMs for ﬁnd-\ning and ﬁxing security bugs in both software and hardware pro -\ngrams, written in Python, C, and Verilog. Furthermore, rece nt re-\nsearch has leveraged LLMs to produce highly secured code thr ough\ncontrolled code generation [6] or to detect and patch side-c hannel\nvulnerabilities in software [17].\n3 METHODOLOGY\nIn our study, given an input prompt that instructs LLMs to ﬁnd and\nﬁx a vulnerability within a provided JavaScript code snippet, we\ninvestigate the accuracy of the responses generated by thes e LLMs.\nAn example of an input prompt and the corresponding response\nreturned by ChatGPT are shown in Table 1.\nIn the given example, we ask LLMs to ﬁx a bug, namely an “Out-\nof-bound Write\" error, in the given JavaScript code. Partic ularly,\nTable 1: An example of an input prompt and the response\nreturned by LLM.\nPrompt Response\nFix the bug in the\nfollowing code:\n/grave.ts1/grave.ts1/grave.ts1js\nlet idSequence = new\nInt16Array(3);\nidSequence[0] = 123;\nidSequence[1] = 234;\nidSequence[2] = 345;\nidSequence[3] = 456;\n// No effect\nconsole.log(idSequence[3])\n// undefined\n/grave.ts1/grave.ts1/grave.ts1\nHere is the corrected code:\n/grave.ts1/grave.ts1/grave.ts1js\nlet idSequence = new\nInt16Array(4);\n// Fix the length to 4\nidSequence[0] = 123;\nidSequence[1] = 234;\nidSequence[2] = 345;\nidSequence[3] = 456;\nconsole.log(idSequence[3]);\n// Accessing the valid\nindex 3\n/grave.ts1/grave.ts1/grave.ts1\nthe issue in the code is that an Int16Array object is created with\na length of 3, but there is a write operation to the element at in-\ndex 3, which will take no eﬀect because the valid indices in this\narray are 0, 1, and 2. In this scenario, ChatGPT successfully iden-\ntiﬁes and ﬁxes the bug by increasing the array length to 4, eﬀec-\ntively validating element access at index 3. We note that various\napproaches may exist for repairing vulnerable code. Howeve r, as\nlong as LLMs can produce a functional and secured patch, we co n-\nsider it a success as our focus lies in determining the capabi lity of\nLLMs to identify a solution rather than exhaustively explor ing all\npotential ﬁxes.\n3.1 Prompt Design\nTo investigate the role of diﬀerent levels of context in the p rompts\non the generated repair, we design three diﬀerent prompt tem -\nplates based on the degree of provided context. First, a cont ext-\nfree (c.f.) prompt comprises solely a repair instruction and a vul-\nnerable JavaScript code. There are no hints or additional in for-\nmation regarding the anticipated vulnerability. Second, a context-\nsensitive ( c.s.) prompt is similar to a context-free prompt but\nwith the inclusion of the name of the expected vulnerability , such\nas “Out-of-bound Write\" and “Integer Overﬂow. \" Last, a cont ext-\nrich ( c.r.) prompt encloses comments along with the vulnerable\nJavaScript code, providing an exhaustive explanation of th e vul-\nnerability within the code as well as how an attacker could ex ploit\nit. While in an ideal scenario, a developer with the knowledg e of\na vulnerability context should be able to repair it directly with-\nout relying on LLMs, explaining the vulnerability to LLMs as in\nc.r. prompts might be beneﬁcial for seeking suggestions or ex-\nploring diﬀerent perspectives on potential ﬁxes. This coll aborative\nA Study of Vulnerability Repair in JavaScript Programs with L arge Language Models WWW ’24 Companion, May 13–17, 2024, Singapo re, Singapore\nTable 2: Samples of the proposed prompt templates.\nTemplate Sample\ncontext-\nfree\n(c.f.)\nFix the bug in the following code:\n/grave.ts1/grave.ts1/grave.ts1js\nconst urlParams = new URLSearchParams(window.\nlocation.search);\nconst username = urlParams.get(/quotesingle.Varusername/quotesingle.Var);\nconst trimmedName = username.trim();\n/grave.ts1/grave.ts1/grave.ts1\ncontext-\nsensitive\n(c.s.)\nFix the /quotedbl.VarNULL Pointer/quotedbl.Var vulnerability in the\nfollowing code:\n/grave.ts1/grave.ts1/grave.ts1js\nconst urlParams = new URLSearchParams(window.\nlocation.search);\nconst username = urlParams.get(/quotesingle.Varusername/quotesingle.Var);\nconst trimmedName = username.trim();\n/grave.ts1/grave.ts1/grave.ts1\ncontext-\nrich\n(c.r.)\nFix the bug in the following code:\n/grave.ts1/grave.ts1/grave.ts1js\n// Get the query parameters from the current\nURL\nconst urlParams = new URLSearchParams(window.\nlocation.search);\n// Get the username value\nconst username = urlParams.get(/quotesingle.Varusername/quotesingle.Var);\n// Trim any leading and ending white spaces\nin username\nconst trimmedName = username.trim();\n// Users can control the query parameters so\nan attacker may set username value to\nundefined or null\n// causing the program to crash when it\nattempts to call the trim method\n/grave.ts1/grave.ts1/grave.ts1\napproach could enhance a developer’s productivity in vulne rabil-\nity repair. A sample prompt for each template is shown in Tabl e\n2.\n3.2 Vulnerability Selection\nTo ensure that our study is practical and relevant to the real world,\nwe leverage the latest 2023 CWE Top 25 List [16]. However, not\nall vulnerabilities listed in the top 25 list are related to J avaScript,\nTable 3: Relevant vulnerabilities selected from 2023 CWE\nTop 25 List.\nID Description\nCWE-20 Improper Input Validation\nCWE-22 Improper Limitation of a Pathname to a Restricted\nDirectory (‘Path Traversal’)\nCWE-77 Improper Neutralization of Special Elements used\nin a Command (‘Command Injection’)\nCWE-78 Improper Neutralization of Special Elements used\nin an OS Command (‘OS Command Injection’)\nCWE-79 Improper Neutralization of Input During Web\nPage Generation (‘Cross-site Scripting’)\nCWE-89 Improper Neutralization of Special Elements used\nin an SQL Command (‘SQL Injection’)\nCWE-94 Improper Control of Generation of Code (‘Code In-\njection’)\nCWE-125 Out-of-bounds Read\nCWE-190 Integer Overﬂow or Wraparound\nCWE-269 Improper Privilege Management\nCWE-276 Incorrect Default Permissions\nCWE-287 Improper Authentication\nCWE-306 Missing Authentication for Critical Function\nCWE-434 Unrestricted Upload of File with Dangerous Type\nCWE-476 NULL Pointer Dereference\nCWE-502 Deserialization of Untrusted Data\nCWE-787 Out-of-bounds Write\nCWE-798 Use of Hard-coded Credentials\nCWE-862 Missing Authorization\nCWE-863 Incorrect Authorization\na few of them are speciﬁc to other programming languages. For\nexample, “CWE-416: Use After Free\" is only applicable to C an d\nC++ as described in MITRE’s documentation. Consequently, w e\ncarefully identify and select 20 out of the 25 vulnerabiliti es that\nare most relevant to JavaScript. The complete list of the ide ntiﬁed\n20 vulnerabilities is presented in Table 3.\n4 EXPERIMENT AND EVALUATION\nIn our study, we conduct a systematic experiment on two publi cly\navailable LLMs, namely ChatGPT and Bard.\n4.1 Experiment Details\nBased on the proposed three prompt templates and the identiﬁ ed\n20 vulnerabilities, we formulate a total of 60 prompts. Spec iﬁcally,\neach of the 20 vulnerabilities is replicated across the thre e prompt\ntemplates with varying degrees of contextual cues, ranging from\nno additional context to comprehensive detail.\nIn our experiment, we feed our prompts to the LLMs and sub-\nsequently evaluate the correctness of their responses in re pairing\nthe anticipated vulnerability within the given JavaScript code snip-\npet. Additionally, as LLMs can be heavily biased in a continu ous\ndialogue [20], we create a new and separate conversation for each\nprompt to avoid such biases and ensure an impartial evaluati on.\nWWW ’24 Companion, May 13–17, 2024, Singapore, Singapore Tan K hang Le, Saba Alimadadi, and Steven Y. Ko\nTable 4: Performance results of large language models on\nﬁnding and ﬁxing vulnerabilities in JavaScript code.\nVulnerability\nID\nChatGPT Bard\nc.f. c.s. c.r. c.f. c.s. c.r.\nCWE-20 ✗ ✓ ✓ ✗ ✓ ✓\nCWE-22 ✗ ✓ ✓ ✗ ✓ ✓\nCWE-77 ✓ ✓ ✓ ✓ ✓ ✓\nCWE-78 ✓ ✓ ✓ ✗ ✓ ✓\nCWE-79 ✓ ✓ ✓ ✓ ✓ ✓\nCWE-89 ✓ ✓ ✓ ✓ ✓ ✓\nCWE-94 ✓ ✓ ✓ ✓ ✓ ✓\nCWE-125 ✗ ✓ ✓ ✗ ✓ ✓\nCWE-190 ✗ ✗ ✓ ✗ ✗ ✗\nCWE-269 ✗ ✗ ✗ ✗ ✓ ✓\nCWE-276 ✓ ✓ ✓ ✓ ✓ ✓\nCWE-287 ✗ ✗ ✓ ✗ ✓ ✓\nCWE-306 ✗ ✗ ✓ ✗ ✓ ✓\nCWE-434 ✗ ✓ ✓ ✗ ✓ ✓\nCWE-476 ✓ ✓ ✓ ✓ ✗ ✗\nCWE-502 ✗ ✓ ✓ ✓ ✓ ✓\nCWE-787 ✓ ✓ ✓ ✓ ✓ ✓\nCWE-798 ✗ ✓ ✓ ✗ ✗ ✗\nCWE-862 ✗ ✓ ✓ ✗ ✗ ✓\nCWE-863 ✗ ✓ ✓ ✗ ✓ ✓\nAccuracy 8/20 16/20 19/20 8/20 16/20 17/20\n4.2 Results and Discussion\nRQ1: How accurate are LLMs in ﬁnding and ﬁxing vulnerabiliti es in\nJavaScript programs?\nTable 4 presents the performance results of ChatGPT and Bard\non repairing various vulnerabilities, with diﬀerent level s of con-\ntext, in JavaScript programs. Particularly, ChatGPT corre ctly ﬁnds\nand ﬁxes 43 out of 60 cases, achieving an accuracy of 71.66%. O n\nthe other hand, Bard has a slightly lower accuracy of 68.33%, with\n41 accurate repairs out of 60.\nRQ2: How does the amount of context in a prompt impact the eﬀec -\ntiveness of LLMs in producing a correct patch of vulnerable J avaScript\ncode?\nThe results in Table 4 also demonstrate that the provided con -\ntext in a prompt has a positive impact on LLMs’ capability to ﬁ nd\nand ﬁx vulnerabilities. When there is no additional context as in\nc.f. prompts, ChatGPT and Bard perform poorly in repairing se-\ncurity bugs, each achieving an accuracy of 40%. However, whe n\ncompared with c.f. prompts, ChatGPT shows improved perfor-\nmance on c.s. and c.r. prompts, showcasing an improved accu-\nracy of 80% and 95%, respectively. Similarly, Bard experien ces a\nbetter accuracy of 80% and 85% when tested with c.s. and c.r.\nprompts, respectively.\n4.3 Threats to Validity\nThe validity of the evaluations drawn from our experimental re-\nsults is subject to a few threats. First, we use the public ver sion\nof both ChatGPT [11] and Bard [5] in our testing (accessed in N o-\nvember 2023), which can change and evolve over time. Second, the\ncorrectness of the repaired JavaScript code produced by LLM s is\nveriﬁed manually and, thus, subject to human biases. Last, w e ac-\nknowledge that more studies are required to draw more accura te\nconclusions.\n5 CONCLUSION\nIn this study, we have identiﬁed 20 common vulnerabilities f rom\nthe CWE Top 25 List that are most relevant to JavaScript and pr o-\nposed three prompt templates with varying degrees of contex t. Based\non these vulnerabilities and templates, we have formulated a total\nof 60 repair prompts for our study with LLMs, namely ChatGPT\nand Bard. Our experimental results show that ChatGPT excels with\na promising accuracy of 71.66%, while Bard closely follows w ith\nan accuracy of 68.33%, in the automatic program repair task o f vul-\nnerable JavaScript code. Furthermore, our ﬁndings indicat e that\nincreased contextual information in a repair prompt positi vely in-\nﬂuences the performance of LLMs in ﬁnding and ﬁxing vulnerab il-\nities, leading to a signiﬁcant boost in accuracy of up to 55%.\nREFERENCES\n[1] Baleegh Ahmad, Shailja Thakur, Benjamin Tan, Ramesh Kar ri, and Hammond\nPearce. 2023. Fixing Hardware Security Bugs with Large Lang uage Models.\narXiv preprint arXiv:2302.01215 (2023).\n[2] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosm a, Henryk\nMichalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le,\net al. 2021. Program synthesis with large language models. arXiv preprint\narXiv:2108.07732 (2021).\n[3] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maar ten Bosma, Gaurav\nMishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Se-\nbastian Gehrmann, et al. 2023. Palm: Scaling language model ing with pathways.\nJournal of Machine Learning Research 24, 240 (2023), 1–113.\n[4] Douglas Crockford. 2008. JavaScript: The Good Parts: The Good Parts . \" O’Reilly\nMedia, Inc.\".\n[5] Google. 2023. Bard. https://bard.google.com/\n[6] Jingxuan He and Martin Vechev. 2023. Large language mode ls for code: Secu-\nrity hardening and adversarial testing. In Proceedings of the 2023 ACM SIGSAC\nConference on Computer and Communications Security . 1865–1879.\n[7] Claire Le Goues, ThanhVu Nguyen, Stephanie Forrest, and Westley Weimer.\n2011. Genprog: A generic method for automatic software repa ir. Ieee trans-\nactions on software engineering 38, 1 (2011), 54–72.\n[8] Claire Le Goues, Michael Pradel, Abhik Roychoudhury, an d Satish Chandra.\n2021. Automatic program repair. IEEE Software 38, 4 (2021), 22–27.\n[9] Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chan-\ndra. 2013. Semﬁx: Program repair via semantic analysis. In 2013 35th Interna-\ntional Conference on Software Engineering (ICSE) . IEEE, 772–781.\n[10] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wa ng, Yingbo Zhou, Sil-\nvio Savarese, and Caiming Xiong. 2022. Codegen: An open larg e language model\nfor code with multi-turn program synthesis. arXiv preprint arXiv:2203.13474\n(2022).\n[11] OpenAI. 2023. ChatGPT. https://chat.openai.com/\n[12] Hammond Pearce, Baleegh Ahmad, Benjamin Tan, Brendan D olan-Gavitt, and\nRamesh Karri. 2022. Asleep at the keyboard? assessing the se curity of github\ncopilot’s code contributions. In 2022 IEEE Symposium on Security and Privacy\n(SP). IEEE, 754–768.\n[13] Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Ka rri, and Brendan\nDolan-Gavitt. 2023. Examining zero-shot vulnerability re pair with large lan-\nguage models. In 2023 IEEE Symposium on Security and Privacy (SP) . IEEE, 2339–\n2356.\n[14] Gustavo Sandoval, Hammond Pearce, Teo Nys, Ramesh Karr i, Siddharth Garg,\nand Brendan Dolan-Gavitt. 2023. Lost at c: A user study on the security impli-\ncations of large language model code assistants. arXiv preprint arXiv:2208.09727\n(2023).\n[15] Mohammed Latif Siddiq, Shafayat H Majumder, Maisha R Mi m, Sourov Jajodia,\nand Joanna CS Santos. 2022. An Empirical Study of Code Smells in Transformer-\nbased Code Generation Techniques. In 2022 IEEE 22nd International Working\nConference on Source Code Analysis and Manipulation (SCAM) . IEEE, 71–82.\nA Study of Vulnerability Repair in JavaScript Programs with L arge Language Models WWW ’24 Companion, May 13–17, 2024, Singapo re, Singapore\n[16] T. M. C. (MITRE). 2023. CWE Top 25 Most Dangerous Software Weaknesses .\nhttps://cwe.mitre.org/top25/index.html\n[17] M Caner Tol and Berk Sunar. 2023. ZeroLeak: Using LLMs fo r Scalable and Cost\nEﬀective Side-Channel Patching. arXiv preprint arXiv:2308.13062 (2023).\n[18] Yi Wu, Nan Jiang, Hung Viet Pham, Thibaud Lutellier, Jor dan Davis, Lin Tan,\nPetr Babkin, and Sameena Shah. 2023. How Eﬀective Are Neural Networks for\nFixing Security Vulnerabilities. arXiv preprint arXiv:2305.18607 (2023).\n[19] Frank F Xu, Uri Alon, Graham Neubig, and Vincent Josua He llendoorn. 2022. A\nsystematic evaluation of large language models of code. In Proceedings of the 6th\nACM SIGPLAN International Symposium on Machine Programming . 1–10.\n[20] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,\nYingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al . 2023. A survey\nof large language models. arXiv preprint arXiv:2303.18223 (2023).",
  "topic": "JavaScript",
  "concepts": [
    {
      "name": "JavaScript",
      "score": 0.9352079629898071
    },
    {
      "name": "Computer science",
      "score": 0.8178755640983582
    },
    {
      "name": "Unobtrusive JavaScript",
      "score": 0.7720531821250916
    },
    {
      "name": "Secure coding",
      "score": 0.7054330110549927
    },
    {
      "name": "Web application",
      "score": 0.5833486914634705
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5808930993080139
    },
    {
      "name": "Programming language",
      "score": 0.5229468941688538
    },
    {
      "name": "World Wide Web",
      "score": 0.4929180145263672
    },
    {
      "name": "Computer security",
      "score": 0.4550515115261078
    },
    {
      "name": "Vulnerability (computing)",
      "score": 0.4249882102012634
    },
    {
      "name": "Code (set theory)",
      "score": 0.4150218069553375
    },
    {
      "name": "Software engineering",
      "score": 0.3684742748737335
    },
    {
      "name": "Rich Internet application",
      "score": 0.29248201847076416
    },
    {
      "name": "Software security assurance",
      "score": 0.23573872447013855
    },
    {
      "name": "Information security",
      "score": 0.14452022314071655
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Security service",
      "score": 0.0
    }
  ]
}