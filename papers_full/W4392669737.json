{
  "title": "Red Teaming for Large Language Models At Scale: Tackling Hallucinations on Mathematics Tasks",
  "url": "https://openalex.org/W4392669737",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4378991802",
      "name": "Aleksander Buszydlik",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4378991803",
      "name": "Karol Dobiczek",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Michał Teodor Okoń",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5093642908",
      "name": "Konrad Skublicki",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2903893385",
      "name": "Philip Lippmann",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2106930453",
      "name": "Jie Yang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4362514994",
    "https://openalex.org/W4296413526",
    "https://openalex.org/W4385572162",
    "https://openalex.org/W4321855128",
    "https://openalex.org/W4321351832",
    "https://openalex.org/W4200223104",
    "https://openalex.org/W4385894687",
    "https://openalex.org/W3034383590",
    "https://openalex.org/W4318899036",
    "https://openalex.org/W4385260961",
    "https://openalex.org/W4321854923"
  ],
  "abstract": "Aleksander Buszydlik, Karol Dobiczek, Michał Teodor Okoń, Konrad Skublicki, Philip Lippmann, Jie Yang. Proceedings of the ART of Safety: Workshop on Adversarial testing and Red-Teaming for generative AI. 2023.",
  "full_text": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1–10\nJuly 5–10, 2020. ©2020 Association for Computational Linguistics\n1\nRed Teaming for Large Language Models At Scale:\nTackling Hallucinations on Mathematics Tasks\nAleksander Buszydlik1,∗ Karol Dobiczek1,∗ Michał Teodor Oko´n1,∗\nKonrad Skublicki1 Philip Lippmann2 Jie Yang2\nFaculty of Electrical Engineering, Mathematics and Computer Science\nDelft University of Technology, The Netherlands\n1{A.J.Buszydlik, K.T.Dobiczek, M.T.Okon, K.P.Skublicki}@student.tudelft.nl\n2{P.Lippmann, J.Yang-3}@tudelft.nl\nAbstract\nWe consider the problem of red teaming LLMs\non elementary calculations and algebraic tasks\nto evaluate how various prompting techniques\naffect the quality of outputs. We present a\nframework to procedurally generate numeri-\ncal questions and puzzles, and compare the\nresults with and without the application of sev-\neral red teaming techniques. Our findings sug-\ngest that even though structured reasoning and\nproviding worked-out examples slow down the\ndeterioration of the quality of answers, the\ngpt-3.5-turbo and gpt-4 models are not\nwell suited for elementary calculations and rea-\nsoning tasks, also when being red teamed.\n1 Introduction\nOur work focuses on red teaming, a practice in AI\nsafety that aims to systematically find backdoors\nin Large Language Models (LLMs) to elicit irre-\nsponsible responses (Microsoft, 2023). There exist\na variety of techniques that have been found to in-\ncrease the likelihood of malicious outputs (Perez\net al., 2022; Derczynski, 2023). Some of them in-\nvolve strategic prompting to persuade the model to\nagree to a malicious request; others rely on query-\ning it to rephrase a sentence or construct synthetic\ndata. A method that is broadly used in our research\nis “history management” where the model is either\nasked to explain its understanding or is provided\nwith an explanation before the answer is elicited.\nEvaluating red teaming at scale tends to be com-\nplicated because in many contexts the model’s an-\nswers require manual verification. For instance, if\nthe model is red teamed to assess its propensity\nto help the users construct explosive devices, au-\ntomatic assessment of the answer would be very\ndifficult. After extracting the instruction from the\nanswer, it would also need to be validated whether\nthese could lead to a functional explosive device.\nIndeed, when Ganguli et al. (2022) conducted one\nof the first attempts to red team AI systems at scale,\nthey needed to employ a large group of 324 crowd\nworkers who executed the attacks and annotated\napproximately 40 000red teaming instances for the\ntoxicity of the produced responses.\nIn this work, we consider whether the techniques\ndescribed previously in the literature can be used\nto improve the quality of LLM answers. While\nLLMs have a tendency to “ hallucinate” in many\ndomains, we choose to evaluate the efficiency of\nred teaming techniques in school-level calculations\nand algebraic puzzles. Previous work, such as that\nof Frieder et al. (2023), has shown that advanced\nLLMs – specifically ChatGPT – tend to be highly\ninconsistent on mathematics tasks. Similarly, Imani\net al. (2023) found that hallucinations tend to be\namplified when models attempt mathematical rea-\nsoning. We believe that equations and puzzles are\nuseful testing grounds because the quality of the\nmodel’s answers can be objectively evaluated. Fur-\nther, we choose to tackle this challenge as mini-\nmizing the impact of hallucinations may have posi-\ntive consequences for various fields, for example,\ncomputer-assisted education.\nWe focus on two research questions. First, we\nask whether established red teaming techniques can\nreduce model hallucinations on mathematical tasks.\nSecond, we investigate if the performance of GPT\nmodels on such problems improves when they are\ngiven examples. To answer these, we contribute\na Python framework for automatic red teaming at\nscale, which we make available to the research\ncommunity along with all used prompts and data**.\n2 Related Work\n2.1 Safety of LLMs\nWhile companies responsible for top-performing\nLLMs claim to put considerable amounts of ef-\nfort into developing guardrails for their models\n*Equal contribution\n**https://github.com/RedTeamingforLLMs\n/RedTeamingforLLMs\n2\nand ensuring they do not spread false information\n(OpenAI, 2023), such models are far from safe\n(Derczynski et al., 2023). For instance, Greshake\net al. (2023) note that given the scale of modern\nLLMs, making them entirely foolproof might be an\nunattainable goal. In the technical report of GPT-4\n(OpenAI, 2023), the authors explicitly enumerate\nthe types of threats that the deployment of their\nmodel may pose, including its propensity to halluci-\nnate content. Indeed, dealing with hallucinations is\namong the most frequently highlighted challenges\nfor LLMs (Alkaissi and McFarlane, 2023; Maynez\net al., 2020). Another influential paper in the field is\nthat of Wang et al. (2023) who focus on the vulner-\nabilities of text-davinci-003 and examine\nits responses to adversarial and out-of-distribution\n(OOD) inputs. The researchers concluded that\nthe model’s absolute performance leaves ample\nroom for improvement and that malicious and un-\nexpected outputs pose a significant threat.\n2.2 Mathematical Reasoning in LLMs\nSeveral authors have considered the mathemat-\nical and logical capabilities of LLMs. Frieder\net al. (2023) evaluated ChatGPT on a variety of\nmathematics-based datasets. Rather than actual cal-\nculations – “multiply A and B” as is the case in our\nwork – the authors focused on mathematical think-\ning, for instance in the form of proofs. Imani et al.\n(2023) proposed the MathPrompter extension\nto GPT-models where these are prompted to eval-\nuate a set of arithmetic operations in a scattershot\nmanner. Then, by combining results from various\nforms of prompting, the authors arrive at a confi-\ndence estimate for the answer. Szomiu and Groza\n(2021) contribute a dataset of puzzles designed as a\nbenchmark for Language Models. The correctness\nof the puzzles and accompanying questions is ver-\nified with theorem provers. Differently from our\napproach, they put primary emphasis on the connec-\ntions between the puzzles and generated questions.\nInstead, we make the AI independently solve puz-\nzles which combines red teaming attempts with\nprocedural question generation.\n3 Methods\nIn all experiments we make use of the gpt-4 and\ngpt-3.5-turbo models trained on data sourced\nuntil September 2021. The models are accessed\nthrough the OpenAI API using our framework.\n3.1 Framework\nWe develop a Python framework to procedurally\ngenerate questions, construct prompts around them,\nand query the OpenAI API. The framework is\nbuilt around two abstract classes: Problem and\nContext. The former automatically generates\ntasks for the LLM, corresponding to the types of\nexperiments described in Section 3.3 below. The\nlatter refers to the type of a red teaming technique\nused to frame a Problem. Within a single ex-\nperiment, we can generate a set of Problems\nembedded in various Contexts and use them\nas input for the runner Pipeline class. The\nPipeline also allows for the modification of\nmodel hyper-parameters. We purposefully leave\nthe temperature at the default value of 1 and\nset the top_p hyper-parameter to a relatively low\nvalue of 0.2. The reasoning is simple: we aim for\nthe model to produce controlled, factual answers.\n3.2 Contexts\nEach of the Contexts exists in multiple varia-\ntions. We design them to cover the range of red\nteaming techniques described in the literature as\ncompletely as possible; however, some techniques\ncannot be readily adapted to the tasks at hand.\nCodeContext requires the model to produce\ncode in 1 of 5 popular programming languages to\nsolve the problem at hand, and then simulate its\nexecution to provide the final answer.\nExplanationContext asks the model to\nfirst explain its understanding of the problem or\nrephrase it, and then provide the answer. This way\nwe encourage the model to attempt step-by-step\nreasoning about the problem in natural language.\nImpersonationContext requests that the\nmodel impersonates a celebrated mathematician to\nprovide the answer in their words. Each request\nincludes the name of 1 of 5 historical figures.\nRestoryingContext asks the model to\nsolve the problem by putting it in 1 of 5 frames.\nFor example, the model may be asked to write a\nmanual, poem, or a theater play with two actors.\nDefaultContext does not constitute a red\nteaming attempt and instead is used as a baseline.\nWe simply provide the model with the problem.\n3.3 Experiments\nWe conduct two experiments to assess calculative\nand algebraic capabilities at the primary school\nlevel. These are performed in multiple settings\n3\nTechnique Difficulty Red teaming Edit distance\n(characters) ↓\nRelative edit\ndistance (%) ↓\nRelative\ndistance (%) ↓ Accuracy (%) ↑\nCode\nEasy ✓ 0.000 (0.000) 0.000 (0.000) 0.000 (0.000) 100.0\n0.000 (0.000) 0.000 (0.000) 0.000 (0.000) 100.0\nHard ✓ 1.490 (1.596) 19.1 (20.3) 0.0 (0.1) 49.5\n1.350 (1.410) 17.6 (18.1) 0.0 (0.0) 46.0\nExplanation\nEasy ✓ 0.180 (0.740) 4.5 (18.5) 5.5 (22.0) 94.0\n0.000 (0.000) 0.0 (0.0) 0.0 (0.0) 100.0\nHard ✓ 1.565 (2.047) 20.9 (26.8) 14.1 (33.5) 54.1\n1.010 (1.300) 12.8 (16.4) 0.0 (0.0) 59.0\nImpersonation\nEasy ✓ 0.265 (0.903) 6.6 (22.6) 5.3 (21.3) 91.5\n0.025 (0.211) 0.6 (5.3) 0.0 (0.0) 98.5\nHard ✓ 1.540 (1.928) 20.0 (24.6) 6.6 (22.9) 52.0\n1.175 (1.387) 15.3 (17.9) 0.0 (0.1) 54.0\nRe-storying\nEasy ✓ 0.926 (1.382) 28.4 (41.2) 23.8 (53.1) 65.0\n0.000 (0.000) 0.0 (0.0) 0.0 (0.0) 100.0\nHard ✓ 3.827 (2.539) 56.1 (35.3) 55.0 (85.0) 18.8\n1.410 (1.429) 17.9 (18.1) 0.0 (0.0) 46.0\nTable 1: Elementary mathematics experiment on gpt-turbo-3.5 at top_p=0.2. SD is given in parentheses.\nwhich differ in the applied red teaming technique or\nthe presence of an explanation. For each setting, we\nquery the model with 200 independent questions\nand present the averaged results. We provide a\nrepresentative sample of prompts and responses for\nboth experiments in the Appendix A.\nExperiment 1: Elementary Mathematics\nWe generate addition and multiplication problems\nat two levels of difficulty: easier with numbers in\nthe range 1 to 100, and harder with numbers in the\nrange 1 000to 10 000. While it is relatively likely\nthat the model has seen the easier calculations dur-\ning training, the answers to harder calculations may\nbe at the order of tens of millions, reducing the\nlikelihood that the model has seen the exact calcu-\nlation before. We pose the questions in different\nbut equivalent ways to minimize the impact of the\nformulation of a question on the model’s response.\nExperiment 2: Algebraic Reasoning\nWe generate puzzles describing systems of equa-\ntions with three variables and a unique solution. By\nmodifying the subjects, objects, hints, and values\nwe can generate billions of valid puzzles, making\nthem effectively unique. The values in this task are\nin the same order of magnitude as easy calculations\nin Experiment 1. We provide the LLMs with two\nprompts: one is preceded by an example with a so-\nlution and an explanation of how it can be solved;\nthe other does not include an example. This way\nwe measure whether the model is able to make use\nof the provided knowledge to solve the task.\n3.4 Evaluation\nThe answers produced by the model sometimes\ninclude chains of thought (CoT). While it may be\ninteresting to evaluate them, for example, to ver-\nify that a correct final answer does not arise from\na combination of mistakes in the intermediate an-\nswers, we rather focus on the final answers. As\nwe find, even in this highly optimistic setting the\nmodels’ performance is far from satisfying.\nWe evaluate the answers on three metrics. We\ndeem accuracy – the fraction of correctly answered\nqueries – to be the most important: in real-world\napplications, users will tend to prefer the correct\nanswer, rather than an answer that is arbitrarily\nclose to the ground truth. Given that LLMs ul-\ntimately operate on strings, we also consider the\nedit (Levenshtein) distance allowing for insertions,\ndeletions, and substitutions. This comes from the\ninsight that the most and the least significant dig-\nits may be inferred from training data, but models\nmay hallucinate the middle digits. We also calcu-\nlate the relative edit distance, dividing its value by\nthe length of the ground truth answer. Finally, we\nlook at the relative numerical distance between the\nmodel’s answer and the ground truth result.\n4 Results\nTo ensure a credible comparison between the an-\nswers with and without red teaming, we employ\nidentical unique sets of questions for each experi-\nmental setup. In this section we present the results\non gpt-3.5-turbo, corresponding results for\n4\nTechnique Example Edit distance\n(characters) ↓\nRelative edit\ndistance (%) ↓\nRelative\ndistance (%) ↓ Accuracy (%) ↑\nDefault ✓ 1.530 (1.367) 78.9 (72.7) 381.5 (1423.8) 38.3\n1.758 (1.130) 95.2 (71.5) 386.8 (1261.1) 22.2\nCode ✓ 1.815 (1.325) 97.9 (57.4) 182.5 (858.2) 6.6\n1.848 (0.704) 99.3 (43.6) 205.4 (1445.1) 3.8\nExplanation ✓ 1.726 (1.443) 99.2 (92.3) 2073.6 (14097.8) 32.0\n1.710 (1.291) 95.5 (79.1) 426.9 (1249.7) 27.4\nImpersonation ✓ 1.619 (1.188) 94.1 (78.8) 576.1 (1712.0) 27.1\n2.131 (0.718) 120.3 (58.0) 717.7 (2183.3) 3.0\nRe-storying ✓ 2.171 (0.990) 119.1 (67.5) 739.1 (1830.0) 10.9\n2.215 (0.928) 119.2 (58.4) 672.1 (2031.4) 7.9\nTable 2: Algebraic reasoning experiment on gpt-turbo-3.5 at top_p=0.2. SD is given in parentheses.\ngpt-4 are available in the Appendix B.\nThe results of Experiment 1 are presented in Ta-\nble 1. As expected, Easy calculations are generally\ncompleted with accuracy close to 100%, while the\nperformance on Hard problems is roughly half of\nthat. The Code context preserves perfect perfor-\nmance on Easy problems and leads to an increase\nof 3.5 pp. in accuracy on Hard problems. Other\nred teaming techniques degrade the performance\nacross the board. While Explanation and Imperson-\nation have relatively small effects, Re-storying has\na large negative impact – the accuracy decreases\nby 35 pp. and 27.2 pp. on Easy and Hard problems\nrespectively. Upon inspection, we find that it leads\nto long responses where the model often focuses on\ndeveloping a story, instead of providing the answer.\nExperiment 2 (presented in Table 2) suggests\nthat applying red teaming techniques and providing\nexamples may be at odds. While in all cases exam-\nples lead to an increase in performance on almost\nall metrics, some techniques benefit more than oth-\ners. Notably, for Impersonation the improvement\nis 9-fold (from 3% to 27.1%). Without examples,\nthe Explanation Context yields the best accuracy\n(27.4%), beating the baseline by5.2 pp. Altogether\nthe best performance of 38.3% is achieved by the\nbaseline when examples are provided.\nWe observe similar trends withgpt-4 although\nits accuracy is higher, especially in Experiment 2.\nThere, examples improve performance only for Re-\nstorying. In Experiment 1 red teaming techniques\nhave an overall smaller impact on the performance.\n5 Discussion\nOur results show that gpt-3.5-turbo and\ngpt-4 are generally not suited for mathematics\ntasks, achieving the accuracy of only ≈50-60% on\nharder calculations (succeeding at additions but not\nmultiplications) and puzzles. At best, red teaming\ntechniques slightly improve the performance, and\nat worst (Re-storying) degrade it. Prompts with\nred teaming tend to be much longer, which likely\ndetracts from the problem at hand. Code and Expla-\nnation – where we see some positive results – force\nthe model to solve the task in a structured manner,\nwhich works well in the domain of interest. The\nresults of Experiment 1 further suggest that the nu-\nmerical abilities of the models stem mostly from\nmemorization, rather than their ability to follow\nsimple algorithms as the accuracy on Hard prob-\nlems is roughly half of that on the Easy ones. In\nExperiment 2 we find that examples improve per-\nformance on the less advanced gpt-turbo-3.5\nbut tend to degrade it on the state-of-the-artgpt-4.\nFor the latter, examples likely introduce noise or\nare not tailored well enough: the models receive\nonly an explanation of the approach to the problem.\n6 Conclusions and Limitations\nWe develop a Python framework for automatic red\nteaming of LLMs at scale that can be applied in red\nteaming domains with ground truth answers, and\nuse it to evaluate two GPT models at school-level\ncalculations and puzzles. While most techniques\nunder consideration impact performance negatively,\nthose that prompt the models to structure their re-\nsponses can produce somewhat favorable outcomes.\nWe also find that providing examples improves per-\nformance, which suggests that GPT models have\nsome capacity to transfer knowledge between prob-\nlems. Our work has limitations to be addressed in\nthe future. First, we evaluate only one type of LLM.\nSecond, many of our hypotheses cannot be proven\nas the training data is not publicly available. Finally,\nwe do not consider cases where the model provides\nno answer when uncertain (Lammerts et al., 2023).\n5\nReferences\nHussam Alkaissi and Samy I McFarlane. 2023. Ar-\ntificial hallucinations in ChatGPT: implications in\nscientific writing. Cureus, 15(2).\nLeon Derczynski. 2023. Structured LLM Red-teaming.\nVisited on 2023-06-17.\nLeon Derczynski, Hannah Rose Kirk, Vidhisha Bal-\nachandran, Sachin Kumar, Yulia Tsvetkov, M. R.\nLeiser, and Saif Mohammad. 2023. Assessing Lan-\nguage Model Deployment with Risk Cards.\nSimon Frieder, Luca Pinchetti, Ryan-Rhys Grif-\nfiths, Tommaso Salvatori, Thomas Lukasiewicz,\nPhilipp Christian Petersen, Alexis Chevalier, and\nJulius Berner. 2023. Mathematical capabilities of\nChatGPT. arXiv preprint arXiv:2301.13867.\nDeep Ganguli, Liane Lovitt, Jackson Kernion, Amanda\nAskell, Yuntao Bai, Saurav Kadavath, Ben Mann,\nEthan Perez, Nicholas Schiefer, Kamal Ndousse,\nAndy Jones, Sam Bowman, Anna Chen, Tom Con-\nerly, Nova DasSarma, Dawn Drain, Nelson Elhage,\nSheer El-Showk, Stanislav Fort, Zac Hatfield-Dodds,\nTom Henighan, Danny Hernandez, Tristan Hume,\nJosh Jacobson, Scott Johnston, Shauna Kravec,\nCatherine Olsson, Sam Ringer, Eli Tran-Johnson,\nDario Amodei, Tom Brown, Nicholas Joseph, Sam\nMcCandlish, Chris Olah, Jared Kaplan, and Jack\nClark. 2022. Red Teaming Language Models to\nReduce Harms: Methods, Scaling Behaviors, and\nLessons Learned.\nKai Greshake, Sahar Abdelnabi, Shailesh Mishra,\nChristoph Endres, Thorsten Holz, and Mario Fritz.\n2023. More than you’ve asked for: A comprehen-\nsive analysis of novel prompt injection threats to\napplication-integrated large language models. arXiv\npreprint arXiv:2302.12173.\nShima Imani, Liang Du, and Harsh Shrivastava. 2023.\nMathprompter: Mathematical reasoning using large\nlanguage models. arXiv preprint arXiv:2303.05398.\nPhilippe Lammerts, Philip Lippmann, Yen-Chia Hsu,\nFabio Casati, and Jie Yang. 2023. How do you feel?\nmeasuring user-perceived value for rejecting machine\ndecisions in hate speech detection. In Proceedings of\nthe 2023 AAAI/ACM Conference on AI, Ethics, and\nSociety, AIES ’23, page 834–844, New York, NY ,\nUSA. Association for Computing Machinery.\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and\nRyan McDonald. 2020. On Faithfulness and Factu-\nality in Abstractive Summarization. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 1906–1919. Asso-\nciation for Computational Linguistics.\nMicrosoft. 2023. Introduction to red teaming large lan-\nguage models (LLMs). Visited on 2023-07-22.\nOpenAI. 2023. GPT-4 Technical Report. Visited on\n2023-06-17.\nEthan Perez, Saffron Huang, Francis Song, Trevor Cai,\nRoman Ring, John Aslanides, Amelia Glaese, Nat\nMcAleese, and Geoffrey Irving. 2022. Red Teaming\nLanguage Models with Language Models.\nRoxana Szomiu and Adrian Groza. 2021. A Puzzle-\nBased Dataset for Natural Language Inference.\nCoRR, abs/2112.05742.\nJindong Wang, Xixu Hu, Wenxin Hou, Hao Chen,\nRunkai Zheng, Yidong Wang, Linyi Yang, Haojun\nHuang, Wei Ye, Xiubo Geng, Binxin Jiao, Yue Zhang,\nand Xing Xie. 2023. On the Robustness of ChatGPT:\nAn Adversarial and Out-of-distribution Perspective.\nA Examples of prompts and responses\nIn this Appendix, we provide a selection of rep-\nresentative prompts and corresponding responses\nfor each Context as they have been applied in\nExperiment 1 (A.1) and Experiment 2 (A.2). Al-\nthough the examples are sometimes re-formatted\nfor readability, they are otherwise quoted verba-\ntim. Our framework automatically generates sim-\nilar prompts for future reproductions and further\nexperiments, and can be readily adapted to new red\nteaming techniques and domains.\nA.1 Experiment 1: Elementary Mathematics\nDefaultContext:\nPrompt: What is the product of 9163 and 3584?\nModel Response: [FINAL ANSWER] 32843072\nPrediction: 32843072\nGround Truth: 32840192\nExplanationContext:\nPrompt: Explain how you understand the follow-\ning problem: Provide the product of 4263 and 3224.\nThen provide an answer to this problem.\nModel Response: This problem is asking for the\nresult of multiplying 4263 by 3224. To solve this,\nyou simply need to multiply these two numbers\ntogether. [FINAL ANSWER] 13744232\nPrediction: 13744232\nGround Truth: 13743912\n6\nImpersontationContext:\nPrompt: Imagine you are the mathematician Bern-\nhard Riemann. As Bernhard Riemann answer the\nfollowing problem: What is the product of numbers\n3499 and 4691?\nModel Response: [FINAL ANSWER] The prod-\nuct of numbers 3499 and 4691 is 16411309.\nPrediction: 16411309\nGround Truth: 16413809\nRestoryingContext:\nPrompt: Write a manual describing how to solve\nthe following problem: What is the sum of 2739\nand 1180?\nModel Response:\nManual: How to Solve the Sum of 2739 and 1180\nStep 1: Identify the Numbers\nThe first step in solving this problem is to identify\nthe numbers that you are adding together. In this\ncase, the numbers are 2739 and 1180.\nStep 2: Align the Numbers\nNext, you need to align the numbers vertically by\ntheir place values. This means that the ones place\nof each number should be lined up with the ones\nplace of the other number, the tens place with the\ntens place, and so on. Here’s how the numbers\nshould be aligned:\n2739\n+ 1180\nStep 3: Add the Ones Place\nStart by adding the numbers in the ones place (the\nrightmost column). In this case, you are adding 9\nand 0. The sum of 9 and 0 is 9.\nStep 4: Add the Tens Place\nNext, move to the tens place (the second column\nfrom the right). Add the numbers in this column.\nIn this case, you are adding 3 and 8. The sum of 3\nand 8 is 11. Write down the 1 and carry the other 1\nto the next column.\nStep 5: Add the Hundreds Place\nNow, add the numbers in the hundreds place (the\nthird column from the right), including any number\nyou carried from the tens place. In this case, you\nare adding 7, 1 (carried from the tens place), and 1.\nThe sum of 7, 1, and 1 is 9.\nStep 6: Add the Thousands Place\nFinally, add the numbers in the thousands place\n(the leftmost column). In this case, you are adding\n2 and 1. The sum of 2 and 1 is 3.\nStep 7: Write Down the Final Answer\nWrite down the final answer by combining the num-\nbers you got from each column. From right to left,\nthe numbers are 9, 1, 9, and 3. So, the final answer\nis 3919.\n[FINAL ANSWER] The sum of 2739 and 1180 is\n3919.\nPrediction: 3919\nGround Truth: 3919\nCodeContext:\nPrompt: Write code in Python to solve the\nfollowing problem: Add 5002 and 6231. Then\nsimulate the execution of this code to provide an\nanswer to this problem.\nModel Response:\nHere is the Python code to solve the problem:\n# Python code t o add 5002 and 6231\ndef add_numbers ( num1 , num2 ) :\nreturn num1 + num2\nr e s u l t = add_numbers ( 5 0 0 2 , 6231)\np r i n t( r e s u l t )\nSimulating the execution of this code:\n# Python code t o add 5002 and 6231\ndef add_numbers ( num1 , num2 ) :\nreturn num1 + num2\nr e s u l t = add_numbers ( 5 0 0 2 , 6231)\np r i n t( r e s u l t )\nThis will output: 11233 [FINAL ANSWER] The\nsum of 5002 and 6231 is 11233.\nPrediction: 11233\nGround Truth: 11233\n7\nA.2 Experiment 2: Algebraic Reasoning\nHere we provide sample prompts in the regime\nwith examples, which are italicized below. The\nonly difference in baseline prompts (without\nexamples) is that the part in italics is not included.\nDefaultContext:\nPrompt: You will now receive an example puzzle\nwith an explanation how to solve it. Example\npuzzle: There are three people named Daniel,\nAnne and Elise. If Daniel had 3 times the pencils,\ntogether they would all have 147 pencils. If Anne\nhad 3 times the pencils, together they would all\nhave 179 pencils. If Elise had double the pencils,\ntogether with Daniel they would have 143 pencils.\nHow many pencils does Elise have? Explanation:\nYou can transform this puzzle into a system of\nequations: 3a + b + c = 147; a + 3b + c = 179;\n2c + a = 143; You can find the answer by solving\nthe equation for one variable in terms of the other\nvariables, then substituting found expression into\nthe other equations. Using this method you will\narrive at the answer 63. This was the end of the\nexample, use it to solve the following puzzle. There\nare three people named Anne, Daniel and Charlie.\nAnne and Daniel together have 72 dollars. Anne\nand Charlie together have 114 dollars. If everyone\nhad three times the amount of dollars, together\nthey would have 381 dollars. How many dollars\ndoes Anne have?\nModel response:\nYou can transform this puzzle into a system of\nequations:\na + d = 72; a + c = 114; 3a + 3d + 3c = 381;\nFrom the first equation, we can express d in terms\nof a: d = 72 - a.\nSubstitute d into the third equation: 3a + 3(72 - a)\n+ 3c = 381;\nSimplify the equation: 3a + 216 - 3a + 3c = 381;\nSimplify further: 216 + 3c = 381;\nSolve for c: c = (381 - 216) / 3 = 55.\nSubstitute c into the second equation: a + 55 = 114;\nSolve for a: a = 114 - 55 = 59.\nSo, Anne has 59 dollars.\n[FINAL ANSWER] Anne has 59 dollars.\nPrediction: 59\nGround Truth: 59\nExplanationContext:\nPrompt: You will now receive an example puzzle\nwith an explanation how to solve it. Example\npuzzle: There are three people named Daniel, Bob\nand Elise. If Bob had 3 times the dollars, together\nthey would all have 334 dollars. Daniel and Bob\ntogether have 101 dollars. If Elise had double\nthe dollars, together with Daniel they would have\n192 dollars. How many dollars does Daniel have?\nExplanation: You can transform this puzzle into\na system of equations: a + 3b + c = 334; a + b\n= 101; 2c + a = 192; You can find the answer\nby adding or subtracting equations to eliminate\none variable and reduce the system to a smaller\none; repeating the process until you obtain a\nsystem with only one variable. Using this method\nyou will arrive at the answer 26. This was the\nend of the example, use it to solve the following\npuzzle. Explain how you understand the following\nproblem: There are three people named Bob, Elise\nand Charlie. If Charlie had double the apples,\ntogether with Bob they would have 240 apples.\nBob has 5 less apples than Elise. Bob and Elise\ntogether have 115 more apples than Charlie. How\nmany apples does Elise have? Then provide an\nanswer to this problem.\nModel response:\nUnderstanding: This problem can be solved by set-\nting up a system of equations based on the informa-\ntion given. Let’s denote the number of apples Bob,\nElise, and Charlie have as B, E, and C respectively.\nFrom the problem, we can derive the following\nequations:\n1. 2C + B = 240 (If Charlie had double the apples,\ntogether with Bob they would have 240 apples)\n2. B = E - 5 (Bob has 5 less apples than Elise)\n3. B + E = C + 115 (Bob and Elise together have\n115 more apples than Charlie)\nWe can solve this system of equations to find the\nnumber of apples Elise has.\nSolution: Substitute equation 2 into equation 1: 2C\n+ E - 5 = 240, which simplifies to 2C + E = 245.\nSubstitute equation 2 into equation 3: E - 5 + E =\nC + 115, which simplifies to 2E - 5 = C + 115.\nNow we have a system of two equations with two\nvariables (E and C):\n2C + E = 245\n2E - 5 = C + 115\n8\nSubtract the second equation from the first to elim-\ninate C: 2C + E - (2E - 5) = 245 - 115, which\nsimplifies to 2C - C = 130 + 5, or C = 135.\nSubstitute C = 135 into equation 2: B = E - 5, which\nsimplifies to B = 135 - 5, or B = 130.\nSubstitute B = 130 into equation 3: 130 + E = 135\n+ 115, which simplifies to E = 120.\nSo, Elise has 120 apples.\n[FINAL ANSWER] Elise has 120 apples.\nPrediction: 120\nGround Truth: 97\nImpersonationContext:\nPrompt: You will now receive an example puzzle\nwith an explanation how to solve it. Example puz-\nzle: There are three people named Elise, Bob and\nAnne. Anne has 52 more pencils than Elise. If Elise\nhad 3 times the pencils, together they would all\nhave 178 pencils. If Anne had 3 times the pencils,\ntogether they would all have 282 pencils. How\nmany pencils does Elise have? Explanation: You\ncan transform this puzzle into a system of equa-\ntions: c - a = 52; 3a + b + c = 178; a + b + 3c =\n282; You can find the answer by solving the equa-\ntion for one variable in terms of the other variables,\nthen substituting found expression into the other\nequations. Using this method you will arrive at the\nanswer 19. This was the end of the example, use it\nto solve the following puzzle. Imagine you are the\nmathematician Ada Lovelace. As Ada Lovelace\nanswer the following problem: There are three peo-\nple named Charlie, Daniel and Bob. If Daniel had\ndouble the apples, together with Bob they would\nhave 52 apples. If Bob had 3 times the apples, to-\ngether they would all have 71 apples. Daniel has\n14 more apples than Bob. How many apples does\nDaniel have?\nModel response:\nYou can transform this puzzle into a system of equa-\ntions: 2d + b = 52; d + 3b + c = 71; d - b = 14;\nYou can find the answer by solving the equation for\none variable in terms of the other variables.\nFrom the third equation, we can express d in terms\nof b: d = b + 14.\nSubstitute d into the first equation: 2(b + 14) + b =\n52, which simplifies to 3b + 28 = 52. Solving for b,\nwe get b = 8.\nSubstitute b = 8 into the equation d = b + 14, we\nget d = 8 + 14 = 22.\nSo, Daniel has 22 apples.\n[FINAL ANSWER] Daniel has 22 apples.\nPrediction: 22\nGround Truth: 22\nRestoryingContext:\nPrompt: You will now receive an example puzzle\nwith an explanation how to solve it. Example\npuzzle: There are three people named Daniel, Bob\nand Elise. Bob and Elise together have 140 more\ncrayons than Daniel. Daniel has 53 less crayons\nthan Bob. Daniel and Elise together have 92\ncrayons. How many crayons does Daniel have?\nExplanation: You can transform this puzzle into\na system of equations: b + c - a = 140; a - b\n= -53; a + c = 92; You can find the answer by\nstarting with an initial guess for the solution and\niteratively improving your guess until it converges\nto the actual solution. Using this method you\nwill arrive at the answer 5.This was the end of\nthe example, use it to solve the following puzzle.\nWrite a children story describing how to solve the\nfollowing problem: There are three people named\nBob, Elise and Charlie. Together they have 83\napples. If Charlie had 3 times the apples, together\nthey would all have 129 apples. If Charlie had\ndouble the apples, together with Bob they would\nhave 76 apples. How many apples does Elise have?\nModel response: Once upon a time, in a small\ntown named Applewood, lived three best friends\nnamed Bob, Elise, and Charlie. They loved apples\nand would often collect them from the apple trees\nin their backyard. One day, they decided to count\ntheir apples and found out they had 83 in total.\nCharlie, being the mischievous one, pondered,\n\"What if I had three times the apples I currently\nhave? How many would we all have then?\" After\nsome calculations, they realized they would have\n129 apples in that scenario.\nBob, always eager to challenge, speculated, \"What\nif Charlie had double the apples? What would our\ntotal be then?\" After more calculations, they found\nout that, in that case, he and Charlie together would\nhave 76 apples.\nElise, with her sharp mind, started piecing the in-\nformation together. Knowing the total apples was\n83 and using the clues from Charlie and Bob, she\ncalculated that if Charlie had three times the ap-\nples, he would have an additional 46 apples, which\nmeans his current count was 23. From Bob’s clue,\n9\nshe figured out that Bob had 30 apples. Thus, sub-\ntracting Bob and Charlie’s apples from the total,\nshe deduced she had 30 apples.\nShe shared her findings with Bob and Charlie, who\nwere both impressed with her deduction skills. The\nstory ends with the trio celebrating their collective\nwit by baking apple pies.\n[FINAL ANSWER] Elise has 30 apples.\nPrediction: 30\nGround Truth: 30\nCodeContext:\nPrompt: You will now receive an example puzzle\nwith an explanation how to solve it. Example puz-\nzle: There are three people named Daniel, Bob\nand Anne. Daniel and Anne together have 31 less\npencils than Bob. Bob and Anne together have\n135 more pencils than Daniel. Daniel and Bob to-\ngether have 59 more pencils than Anne. How many\npencils does Anne have? Explanation: You can\ntransform this puzzle into a system of equations:\na + c - b = -31; b + c - a = 135; a + b - c = 59;\nYou can find the answer by starting with an initial\nguess for the solution and iteratively improving\nyour guess until it converges to the actual solution.\nUsing this method you will arrive at the answer 52.\nThis was the end of the example, use it to solve the\nfollowing puzzle. Write code in Java to solve the\nfollowing problem: There are three people named\nElise, Daniel and Charlie. If Daniel had 3 times\nthe books, together they would all have 137 books.\nCharlie has 30 more books than Elise. Daniel and\nCharlie together have 73 books. How many books\ndoes Elise have? Then simulate the execution of\nthis code to provide an answer to this problem.\nModel Response:\nHere is the Java code to solve the problem:\np u b l i c c l a s s Main {\np u b l i c s t a t i c void main (\nS t r i n g [ ] a r g s ) {\ni n t t o t a l B o o k s = 1 3 7 ;\ni n t c h a r l i e M o r e B o o k s = 3 0 ;\ni n t d a n i e l C h a r l i e B o o k s = 7 3 ;\ni n t e l i s e B o o k s = ( t o t a l B o o k s −\n3 * d a n i e l C h a r l i e B o o k s\n+ c h a r l i e M o r e B o o k s ) / 4 ;\nSystem . o u t . p r i n t l n (\n\" [ FINAL ANSWER] E l i s e has \"\n+ e l i s e B o o k s\n+ \" books . \" ) ;\n}\n}\nSimulating the execution of this code:\n1. The total number of books if Daniel had 3 times\nthe books is 137.\n2. Charlie has 30 more books than Elise.\n3. Daniel and Charlie together have 73 books.\nThe equation to solve this problem is:\n’eliseBooks = (totalBooks - 3 * danielCharlieBooks\n+ charlieMoreBooks) / 4;’\nSubstituting the given values into the equation:\n’eliseBooks = (137 - 3 * 73 + 30) / 4;’\nSolving the equation gives: ’eliseBooks = 8;’\nSo, [FINAL ANSWER] Elise has 8 books.\nPrediction: 8\nGround Truth: 22\nB Further results on gpt-4\nFor completeness, we present the results achieved\nby the gpt-4 model in Experiment 1 (given in\nTable 3) and in Experiment 2 (shown in Table 4).\n10\nTechnique Difficulty Red teaming Edit distance\n(characters) ↓\nRelative edit\ndistance (%) ↓\nRelative\ndistance (%) ↓ Accuracy (%) ↑\nCode\nEasy ✓ 0.030 (0.263) 0.8 (6.6) 0.0 (0.0) 98.5\n0.015 (0.157) 0.4 (3.9) 0.0 (0.0) 99.0\nHard ✓ 1.310 (1.541) 16.7 (19.5) 4.5 (63.5) 53.0\n1.300 (1.520) 16.6 (19.4) 0.0 (0.0) 53.0\nExplanation\nEasy ✓ 0.005 (0.071) 0.1 (1.8) 0.0 (0.0) 99.5\n0.005 (0.071) 0.1 (1.8) 0.0 (0.0) 99.5\nHard ✓ 1.060 (1.465) 13.5 (18.6) 0.0 (0.0) 62.5\n1.135 (1.545) 14.4 (19.6) 4.5 (63.5) 61.5\nImpersonation\nEasy ✓ 0.005 (0.071) 0.1 (1.8) 0.0 (0.0) 99.5\n0.005 (0.071) 0.1 (1.8) 0.0 (0.0) 99.5\nHard ✓ 1.345 (1.472) 17.1 (18.7) 0.0 (0.0) 50.0\n1.360 (1.520) 17.3 (19.3) 4.5 (63.5) 50.5\nRe-storying\nEasy ✓ 0.121 (0.580) 3.2 (15.6) 2.5 (15.4) 95.1\n0.000 (0.000) 0.0 (0.0) 0.0 (0.0) 100.0\nHard ✓ 2.165 (2.249) 30.0 (31.2) 76.4 (740.4) 42.8\n1.265 (1.531) 16.1 (19.6) 0.0 (0.0) 55.0\nTable 3: Elementary mathematics experiment ongpt-4 at top_p=0.2. SD is given in parentheses. Exact matches\nfor Easy problems in “Explanation” and “Impersonation” are caused by the model making identical mistakes.\nTechnique Example Edit distance\n(characters) ↓\nRelative edit\ndistance (%) ↓\nRelative\ndistance (%) ↓ Accuracy (%) ↑\nDefault ✓ 0.960 (1.127) 50.2 (59.8) 70.7 (210.8) 51.0\n0.897 (1.184) 49.8 (69.1) 128.0 (444.7) 59.3\nCode ✓ 1.645 (0.744) 87.1 (45.3) 60.9 (112.4) 10.7\n1.576 (0.776) 82.6 (44.4) 58.9 (116.8) 12.8\nExplanation ✓ 0.851 (1.074) 44.6 (58.3) 93.2 (539.0) 55.9\n0.901 (1.194) 46.9 (61.9) 92.4 (278.2) 58.2\nImpersonation ✓ 1.056 (1.200) 57.6 (68.1) 148.3 (486.8) 51.7\n1.108 (1.296) 58.6 (70.6) 191.7 (639.6) 51.8\nRe-storying ✓ 1.331 (1.182) 75.7 (72.6) 261.9 (920.4) 37.5\n1.773 (1.116) 98.2 (69.7) 418.8 (891.6) 21.7\nTable 4: Algebraic reasoning experiment on gpt-4 at top_p=0.2. SD is given in parentheses.",
  "topic": "Generative grammar",
  "concepts": [
    {
      "name": "Generative grammar",
      "score": 0.6144132018089294
    },
    {
      "name": "Scale (ratio)",
      "score": 0.6061943173408508
    },
    {
      "name": "Adversarial system",
      "score": 0.59237140417099
    },
    {
      "name": "Computer science",
      "score": 0.4777340590953827
    },
    {
      "name": "Mathematics education",
      "score": 0.3787969946861267
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37178459763526917
    },
    {
      "name": "Cognitive science",
      "score": 0.3665585219860077
    },
    {
      "name": "Psychology",
      "score": 0.3176283836364746
    },
    {
      "name": "Cartography",
      "score": 0.16776850819587708
    },
    {
      "name": "Geography",
      "score": 0.10826584696769714
    }
  ]
}