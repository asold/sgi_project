{
  "title": "LAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model",
  "url": "https://openalex.org/W3214665350",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A1597887047",
      "name": "Lee Yu-Kyung",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2057519339",
      "name": "Kim Jin-A",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2595381599",
      "name": "Kang, Pilsung",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3158236124",
    "https://openalex.org/W2948947170",
    "https://openalex.org/W3120105373",
    "https://openalex.org/W2946417913",
    "https://openalex.org/W1990089904",
    "https://openalex.org/W3082274269",
    "https://openalex.org/W2914120296",
    "https://openalex.org/W2972324944",
    "https://openalex.org/W1919179112",
    "https://openalex.org/W2754665629",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W3095840026",
    "https://openalex.org/W179699880",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W3011411500",
    "https://openalex.org/W2039157918",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3034238904",
    "https://openalex.org/W1606177950",
    "https://openalex.org/W2626778328",
    "https://openalex.org/W2525778437",
    "https://openalex.org/W2270070752",
    "https://openalex.org/W2947815220",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W2792645615",
    "https://openalex.org/W3127712067",
    "https://openalex.org/W2551087083",
    "https://openalex.org/W35047313",
    "https://openalex.org/W2107263349",
    "https://openalex.org/W2767094836",
    "https://openalex.org/W2096017373"
  ],
  "abstract": "The system log generated in a computer system refers to large-scale data that are collected simultaneously and used as the basic data for determining errors, intrusion and abnormal behaviors. The aim of system log anomaly detection is to promptly identify anomalies while minimizing human intervention, which is a critical problem in the industry. Previous studies performed anomaly detection through algorithms after converting various forms of log data into a standardized template using a parser. Particularly, a template corresponding to a specific event should be defined in advance for all the log data using which the information within the log key may get lost. In this study, we propose LAnoBERT, a parser free system log anomaly detection method that uses the BERT model, exhibiting excellent natural language processing performance. The proposed method, LAnoBERT, learns the model through masked language modeling, which is a BERT-based pre-training method, and proceeds with unsupervised learning-based anomaly detection using the masked language modeling loss function per log key during the test process. In addition, we also propose an efficient inference process to establish a practically applicable pipeline to the actual system. Experiments on three well-known log datasets, i.e., HDFS, BGL, and Thunderbird, show that not only did LAnoBERT yield a higher anomaly detection performance compared to unsupervised learning-based benchmark models, but also it resulted in a comparable performance with supervised learning-based benchmark models.",
  "full_text": "LAnoBERT : System Log Anomaly Detection\nbased on BERT Masked Language Model\nYukyung Lee1 Jina Kim 1 Pilsung Kang 1\nAbstract\nThe system log generated in a computer system\nrefers to large-scale data that are collected si-\nmultaneously and used as the basic data for de-\ntermining errors, intrusion and abnormal behav-\niors. The aim of system log anomaly detection\nis to promptly identify anomalies while minimiz-\ning human intervention, which is a critical prob-\nlem in the industry. Previous studies performed\nanomaly detection through algorithms after con-\nverting various forms of log data into a standard-\nized template using a parser. Particularly, a tem-\nplate corresponding to a specific event should be\ndefined in advance for all the log data using which\nthe information within the log key may get lost.\nIn this study, we propose LAnoBERT, a parser\nfree system log anomaly detection method that\nuses the BERT model, exhibiting excellent natural\nlanguage processing performance. The proposed\nmethod, LAnoBERT, learns the model through\nmasked language modeling, which is a BERT-\nbased pre-training method, and proceeds with un-\nsupervised learning-based anomaly detection us-\ning the masked language modeling loss function\nper log key during the test process. In addition,\nwe also propose an efficient inference process to\nestablish a practically applicable pipeline to the\nactual system. Experiments on three well-known\nlog datasets, i.e., HDFS, BGL, and Thunderbird,\nshow that not only did LAnoBERT yield a higher\nanomaly detection performance compared to un-\nsupervised learning-based benchmark models, but\nalso it resulted in a comparable performance with\nsupervised learning-based benchmark models.\n1School of Industrial Management Engineering, College of\nEngineering, Korea University, Seoul, Korea. Correspondence to:\nPilsung Kang <pilsung kang@korea.ac.kr>.\n1. Introduction\nOwing to the recent advancement of the IT industry, a grow-\ning emphasis is placed on the importance of the system log\ndata for identifying problems when accidents or failures oc-\ncur in programs (He et al., 2017). The system log comprises\nlarge-scale data collected simultaneously in a computer sys-\ntem and used as the basic data for determining anomalies;\nthus it is a very critical and valuable resource. The log data\ngenerated from various systems should be monitored in real-\ntime for system stability because they represent the current\nstatus of a system. Real-time monitoring is conventionally\nperformed by operators; however, such a method entails the\npossibility of including errors and bias depending on the op-\nerator and is limited by being unable to promptly detect sys-\ntem anomalies (Simache & Kaaniche, 2005). Subsequently,\nanomaly detection using rule-based algorithms has been pro-\nposed to reduce human error (Cinque et al., 2013). However,\nrule-based methodologies also require human intervention;\ntherefore, research is being actively conducted on real-time\nmonitoring-based anomaly detection methods based on ma-\nchine learning, which minimizes human intervention (Du\net al., 2017).\nLog data are sequence data collected in real-time. They\nconsist of a combination of log keys, which can be consid-\nered as words, whereas log sequences can be considered\nas sentences; a log sequence is generated through a series\nof syntax rules (Du & Li, 2016). Also, since log data is\naccumulated based on user actions at regular time intervals,\nthere are many duplicates in an actual log history. Hence,\nalthough the total amount of log instances is very large, a\nsingle log sequence is short and the number of unique log\nkeys are limited in general.\nMachine learning-based log anomaly detection involves\nthree steps: 1) preprocessing log keys, 2) feature embedding,\nand 3) anomaly detection. Preprocessing of log keys refers\nto refining unstructured log keys and can be performed with\nor without a log parser. Parsing-based log anomaly detec-\ntion involves generating log data in a standardized template\nformat using a log parser. Feature embedding involves ex-\ntracting features from preprocessed log sequences. Recent\nmethods (Nedelkoski et al., 2020) use transformer-based\nmodels, whereas earlier methods used RNNs to treat log\narXiv:2111.09564v3  [cs.LG]  23 Jul 2023\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nsequences as natural language (Brown et al., 2018; Du et al.,\n2017; Kim et al., 2016). Anomaly detection involves find-\ning abnormal logs using the extracted features.\nPrevious log anomaly detection studies (Du et al., 2017;\nZhang et al., 2019; Huang et al., 2020; Nedelkoski et al.,\n2020) showed remarkable performance on open datasets,\nbut have limitations in terms of practicality and extensibility.\n‚Ä¢ Reliance on Log Parsers : Parser-based log prepro-\ncessing requires predefined templates for standardizing\nlog keys and manual refinement by experts (Du & Li,\n2016). This method may result in loss of crucial infor-\nmation during standardization (Huang et al., 2020) and\nits performance becomes dependent on log parser com-\npatibility rather than the logic of anomaly detection\nmodels (Nedelkoski et al., 2020).\n‚Ä¢ Feature embedding with rich semantics for long-\nterm dependency : In the field of log anomaly de-\ntection, previous feature embedding methods primar-\nily utilized RNN-based algorithms, which have been\nsuccessful in natural language processing (Vaswani\net al., 2017). However, these algorithms have difficul-\nties in handling long sequences, particularly with re-\ngard to modeling long-term dependencies. To address\nthese limitations, current research is exploring the use\nof transformer-based architecture (Nedelkoski et al.,\n2020), which has recently demonstrated exceptional\nperformance in natural language processing (Vaswani\net al., 2017).\n‚Ä¢ Unrealistic problem formulation: In prior research,\nlog anomaly detection was mostly formulated as a\nbinary classification instead of anomaly detection\n(Huang et al., 2020; Nedelkoski et al., 2020; Zhang\net al., 2019). However, in practical systems, the ma-\njority of logs are normal, with only a small amount\nof abnormal logs. Formulating log anomaly detection\nas a binary classification problem requires a sufficient\namount of abnormal data for model training, which\nis unrealistic as abnormal data is rare in real-world\nsystems. Hence, a more practical approach is to train\nthe model using only normal log data and then uti-\nlize abnormal data only during testing, better reflecting\nreal-world scenarios.\nAs a solution for the aforementioned problem, this study\nproposes a new log anomaly detection model (LAnoBERT;\nLog Anomaly detection based on BERT) established on\nthe following three improvement plans. In LAnoBERT, a\nsimple preprocessing approach utilizing regular expressions\nwas selected to mitigate information loss during the parsing\nprocess and to minimize dependence on a specific log parser.\nContextualized embedding was extracted using the BERT\nmodel, which was trained from scratch to learn the log key\nsequences, in contrast to previous models which relied on\nstatic embedding for feature extraction. Lastly, unsupervised\nlearning-based anomaly detection was performed under the\nassumption that the context of normal logs differs from\nthat of abnormal logs. In the proposed model, LAnoBERT,\nmasked language modeling of BERT (Devlin et al., 2019)\nwas utilized to perform anomaly detection based on the\nmasking predictive probability. An efficient inference pro-\ncess was also proposed, where a log dictionary database was\ndefined, and log key matching was performed for anomaly\ndetection. The model demonstrated superior performance\ncompared to previous models on benchmark datasets of\nsystem logs (HDFS, BGL, and Thunderbird). It showed\nthe best performance among unsupervised learning-based\nmodels and comparable performance to supervised learning-\nbased models, despite being trained in a less advantageous\nenvironment. LAnoBERT satisfied both detection perfor-\nmance and practicality by outperforming some supervised\nlearning-based models.\nIn summary, the main contributions of our study are as\nfollows.\n‚Ä¢ We propose LAnoBERT, a new BERT-based unsuper-\nvised and log parser-free anomaly detection framework\nfor log data. Unlike previous studies, it is a log parser-\nfree and unsupervised learning-based model.\n‚Ä¢ To improve efficiency, an inference process utilizing\na log dictionary database is proposed to identify ab-\nnormal logs. This reduces the computational burden of\nBERT and handles log sequences with lots of redun-\ndant information.\n‚Ä¢ Despite being trained under less favorable conditions,\nLAnoBERT demonstrated better or comparable per-\nformance to supervised learning-based models. In ad-\ndition, LAnoBERT effectively detects anomalies in\nvarious types of logs, validating its practical useful-\nness.\nThis paper is organized as follows. In Section 2, previous\nstudies are reviewed by categorizing them based on neural\nnetworks with parsing and free of parsing. In Section 3, the\nbackground knowledge related to the research is introduced\nin addition to the log parser and BERT model. Section 4\nexplains the proposed model, LAnoBERT, and its structure,\nwhereas Section 5 describes the experimental design, and\nSection 6 describes the log anomaly detection performance.\nLastly, in Section 7, the conclusion of this study and future\nresearch subjects are explained.\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\n2. Related Work\nLog anomaly detection refers to a method for detecting\nabnormal logs from a large log dataset. Studies in earlier\nyears (Cinque et al., 2013; Hansen & Atkins, 1993; Oprea\net al., 2015; Prewett, 2003; Yen et al., 2013) performed\nanomaly detection by regarding specific parts of log data as\nabnormal. However, these studies had a critical limitation of\nrequiring professional domain-specific knowledge. Recent\nmethodologies involve extracting log data features using a\nneural network-based model and performing anomaly detec-\ntion. Log data are unstructured data with a highly complex\nstructure; thus, log anomaly detection can be divided into\nparsing-based or parsing-free depending on the preprocess-\ning method for the log data.\n2.1. Parsing-based log anomaly detection\nIn these methods, a log parser is needed to perform log\nanomaly detection. The Drain parser(He et al., 2017), which\nis the most commonly used parser, classifies log messages\nbased on the length using a decision tree and then allocates\na log template by exploring the word similarity. In this\nprocess, the similarity between the new log message and\nthe existing log template is calculated, and a new template\nis allocated for the data with a different format from the\nexisting template.\nDeepLog (Du et al., 2017) is the first neural network-based\nlog anomaly detection model in which an anomaly is de-\ntected using an unsupervised learning-based LSTM model.\nIn the training phase, a log is generated in a standardized\ntemplate using the Drain parser and then a normal log tem-\nplate pattern is learned. In the test phase, logs having a\npattern not trained with the normal data are determined as\nanomalies. In other words, log patterns with low frequencies\nare given low scores. The concept of the ‚Äòtop g candidate‚Äô\nis introduced to discern log patterns where it is regarded as\nnormal if the log patterns are present within the candidate\nor abnormal if not present; thus, the performance varies\ndepending on the candidate.\nLogRobust (Zhang et al., 2019) is an attention-based bi-\nLSTM model for detecting anomalies. After creating a log\nwith a standardized template using the Drain parser, the\nlog data features are extracted by generating TF-IDF and a\nword semantic vector. Because this particular model detects\nanomalies based on classification, it can be considered as a\nclassification problem.\nHitAnomaly (Huang et al., 2020) is an anomaly detection\nmodel using a transformer. It also conducts preprocessing\nthrough the Drain parser. A template is standardized through\na log parser and the information substituted with a template\nis defined as parameters. The substituted information refers\nto the data that get lost without inclusion in the template.\nTwo types of information are separately encoded using a\ntransformer encoder, and two types of representation are\ncombined based on attention to detect anomalies through\nclassification. This model also performs classification-based\nanomaly detection, thus entailing limitations.\nLogBERT (Guo et al., 2021) is a BERT-based framework\nfor log data anomaly detection, utilizing a Drain parser for\nlog sequence refinement. It follows a similar approach to\nDeepLog in detecting outliers but instead trains using only\nnormal log data through two tasks. The first task, masked log\nkey prediction (MLKP), trains normal log patterns via the\nsame objective function as masked language modeling. The\nsecond task, V olume of Hypersphere Minimization (VHM),\naims to find the smallest sphere that contains normal logs.\nIn the inference stage, the top g predicted log keys are\nselected as a candidate set from a randomly masked normal\nlog sequence, and the observed log key is considered as an\nanomaly if it does not belong to the candidate set. The model\ndetects anomalies by applying BERT‚Äôs masked language\nmodeling, however, it has a limitation in that it cannot fully\nconsider the log sequence when masking due to the random\nselection of a log key from the sequence.\nIn this study, we propose a log anomaly detection model that\ndoes not depend on the log parser. Therefore, even when a\nnew log sequence is recorded, data is not parsed using the\nlog template, but the log sequence is refined using simple\npreprocessing logic. This method can preserve the log se-\nquence as much as possible by minimizing information loss\ncommonly occurred in the parsing process.\n2.2. Parsing-free log anomaly detection\nLogSy (Nedelkoski et al., 2020) is a transformer-based\nanomaly detection model that uses a tokenizer to preprocess\nlog values; thus, it is free from the use of a log parser when\ndetecting anomalies. In LogSy, classification is performed\nusing normal data of a training log and abnormal log data\ngenerated from a different system. In addition, training is\nperformed so that the distance between the normal and ab-\nnormal log increases through a distance-based loss function.\nIt is different from LogRobust and HitAnomaly because it\ndoes not learn the normal and abnormal log generated in\none system based on classification like the previous models.\nHence, this model also entails various limitations to be used\nin the industry as it adapts a classification-based approach.\nAdditionally, NeuralLog (Le & Zhang, 2021) is also a parser-\nfree and classification-based anomaly detection model.\nWhile NeuralLog shares a similar structure with LogSy,\nit distinguishes itself by employing both normal and abnor-\nmal data from the target system, as well as a separate system,\nduring the training process. In contrast, LogSy addresses\nthe classification problem by relying solely on normal data\nfrom the target system and abnormal data generated from a\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\ndifferent system.\nThe proposed model is also a log parser-free methodology.\nAfter refining the log through a simple preprocessing logic,\nthe log sequence is segmented using a word-piece tokenizer.\nThrough this, the log sequence is not categorized into one\nof the predefined templates, but the log sequence itself is\nused as an input of the anomaly detection model. Also, it\ncan be flexibly applied even if a new log sequence that has\nnot been processed ever.\n3. Background\n3.1. Log parser for anomaly detection\nLog data are large-scale data collected in real-time, and raw\nlog messages are usually unstructured because developers\nare allowed to write free-text log messages in the source\ncode (He et al., 2017). Therefore, a log sequence is unstruc-\ntured data that must be converted to structured data. A log\nparser (Du & Li, 2016; He et al., 2017) is a technique pro-\nposed for this process. When a standardized log template is\ngenerated from an actual log, highly complicated data are\nsimply preprocessed for substitution with very few events.\nFor example, 4,747,964 log messages generated from the\nBGL system are converted to 376 events through the Drain\nparser (He et al., 2017). Then, when anomaly detection is\nperformed with preprocessed data, the anomalies can be de-\ntected through a simple process. However, the performance\nof log anomaly detection models using a parser becomes\nheavily dependent on a log parser (Nedelkoski et al., 2020).\n3.2. BERT\nBERT (Devlin et al., 2019) is a model consisting of a trans-\nformer (Vaswani et al., 2017) encoder, which achieved out-\nstanding performance in various natural language process-\ning tasks (Devlin et al., 2019). One of the major charac-\nteristics of BERT is that pre-training is performed using\ntwo unsupervised learning methods, which are masked lan-\nguage modeling (MLM) and next sentence prediction (NSP).\nMLM involves replacing certain tokens of an input sentence\nwith ‚Äò[MASK]‚Äô and predicting that they would appear in the\ncorresponding position. NSP involves combining two sen-\ntences with the token ‚Äò[SEP]‚Äô in between, and then predict-\ning whether the two sentences are semantically connected\nthrough the ‚Äò[CLS]‚Äô token positioned in the very front of\nthe input sentence. These two tasks do not require labeled\ndata as in a specific downstream task; thus, general-purpose\nknowledge can be sufficiently learned through pre-training\nusing a massive unlabeled dataset (Clark et al., 2019; Jawa-\nhar et al., 2019; Tenney et al., 2019). BERT that has been\npre-trained is being applied in fields using sequence data\nin addition to natural language processing; some of the ex-\namples include ProtTrans (Elnaggar et al., 2021) and ESM\n(Rao et al., 2020).\n3.3. BERT for anomaly detection\nThe system log can be deemed as sequence data because\nit is a dataset with an order. Therefore, previous method-\nologies applied the techniques used for natural language\nprocessing to extract the features of logs. The system log\ndata encompass both log messages and natural language. In\nthis study, we propose a BERT-based system log anomaly\ndetection system to overcome the limitations of existing\nmethodologies. Previous methodologies treated all log data\nas sequence data, but applying BERT enables the learning\nof both the log features and natural language. Moreover, a\ntokenizer of BERT can be applied without using a separate\nlog parser during which natural language data that are lost\nwhile converting to a template using a log parser can be\npreserved. Additionally, a model capable of capturing the\nsemantics and context of the system log is necessary for\naccurately detecting abnormal logs in the system log. It is\ncrucial to capture the semantics and context of the system\nlog because the words appearing in the system log may have\na different meaning from natural language. The goal of this\nresearch is to implement an effective pre-training approach\nfor the system log utilizing masked language modeling in\na bi-directional context. Additionally, we present a novel\nframework for identifying context anomalies by means of\nthe trained models‚Äô MLM loss and predictive probability,\nalong with a log key matching technique during the infer-\nence stage.\n4. Proposed Method\nIn this chapter, the major network used in the proposed\nmethodology and the architecture of the proposed model\nare explained. The description and significance of the MLM\nof BERT are presented in Section 4.1, and the training pur-\npose and execution procedure of the proposed model are\npresented in Section 4.2 and 4.3, respectively.\n4.1. Masked Language Model\nThe operation mechanism of LAnoBERT proposed in this\nstudy is shown in Figure 1. Because LAnoBERT is exe-\ncuted through MLM, which is a pre-training method of\nBERT, MLM is explained in detail in this section, and the\nlog anomaly detection procedure is explained in depth in\nSection 4.2.\nMLM was inspired by the cloze task (Taylor, 1953) where\ncertain tokens of an input sentence are replaced with\n[MASK] and then the words in the [MASK] tokens are\npredicted. Entire sentences are replaced with the [MASK]\ntoken at an arbitrary probability of 15%, and appropriate\nwords can be predicted only based on the context. Particu-\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nNormal Log...\n LAnoBERT(BERT)Model Training\nTokenize(Wordpiece)\nLAnoBERT(BERT)\nModel InferenceNormal, Abnormal LogDetect\nTrain\nTest\nLog 1\n Log 2predict\nLog 5\n Log 4predict\nLog 6\n Log 7predict\n[MASK][MASK][MASK]\n[CLS]\n[CLS]\n[CLS]\nlog key matching\nFigure 1.The architecture of LAnoBERT.\nlarly, the MLM objective function can generate bidirectional\nrepresentations, unlike the pre-training of left-to-right lan-\nguage models. Therefore, the proposed method can pre-train\nthe deep bidirectional transformer (Devlin et al., 2019).\nAccording to XLNet (Yang et al., 2019), MLM can be de-\nfined as an auto-encoding (AE) pre-training object. When\nn is the sequence length and the i-th token is xi, the given\ninput sequence can be expressed as X = [x1, x2, ..., xn].\nIf the [MASK] token is defined as ¬Øx = [MASK ] , the in-\nput sequence containing noise can be expressed as ÀÜX =\n[x1, [MASK ], ..., xn]. In BERT, specific tokens are substi-\ntuted with the special token [MASK] at a pre-determined\nprobability (15%). Here, the likelihood and objective func-\ntion can be expressed as follows.\np( ¬ØX| ÀÜX) ‚âà\nNY\nn=1\np(xn| ÀÜX), (1)\nMaxŒ∏ log p(¬Øx| ÀÜX)\n‚âà\nNX\nn=1\nmn log pŒ∏(xn| ÀÜX)\n=\nNX\nn=1\nmn log exp(HŒ∏((ÀÜx)‚ä∫\nne(xn))P\nx‚Ä≤ exp(HŒ∏((ÀÜx)‚ä∫\nne(x‚Ä≤))pŒ∏(xn| ÀÜX)\n(2)\nIn Eq. (2), mn indicates masking, where xn is the [MASK]\ntoken when mn = 1. Furthermore, HŒ∏ indicates the hidden\nvector of a transformer encoder.\nIn this study, MLM was not only applied in the training\nphase but also in anomaly detection to detect abnormal logs.\nThe reasons for using MLM in system log anomaly detection\nare as follows. First, there is ample data available for train-\ning BERT because the log data are collected in real-time.\nMost of the collected data are normal log data, which facili-\ntates the effective pre-training of BERT. When a sufficient\nnumber of data is given, BERT can obtain numerous contex-\ntual and structural features during pre-training. Therefore,\nperforming anomaly detection using the proposed model\nis expected to improve the generalization performance of\neffectively detecting abnormal logs by adequately learn-\ning the features of a normal log system. Second, MLM\ndoes not require the labeling of tasks and accords with the\npurpose of anomaly detection where only normal data are\nused for training. Because anomaly detection is an unsu-\npervised learning-based methodology where only normal\ndata are used for training, it is appropriate for application\nto cases where normal data are predominantly greater than\nabnormal data. Since anomaly detection is an unsupervised\nlearning-based approach that does not use label information\nduring the model training, it is more appropriate than a su-\npervised binary classification-based approach where there\nis an overwhelming amount of normal data. Third, MLM is\nan appropriate methodology to apply to anomaly detection\nfrom the perspective of prompt-based learning (Raffel et al.,\n2020; Petroni et al., 2019; Liu et al., 2021; Radford et al.,\n2019; Schick & Sch¬®utze, 2021). In contrast to conventional\nmethods that require layers conforming to tasks to perform\ndownstream tasks, it is suitable for finding patterns of log\ndata in anomaly detection by comparing the actual log keys\nand the generated log keys. Fourth, the context of abnormal\nlog data can be identified if MLM is performed using only\nnormal log data. Normal log data have a very similar form\nas abnormal log data, but the probability of certain words\nappearing varies if the context of surrounding words is con-\nsidered. It was assumed that the MLM predictive probability\nof abnormal log data is low when anomaly detection is per-\nformed using the BERT model trained only with normal log\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\ndata, and the performance result was relevant.\n4.2. Problem Definition\nThe system log anomaly detection in this study can be de-\nfined as follows. When slen is the sequence length, the log\nkey of the i-th token is wi (wi : wi ‚àà V, i= 1, 2, ..., slen),\nand an individual log sequence is l = ( w1, w2, ..., wslen ).\nAlso mask token is defined ¬Øl = [MASK ]. The goal of the\nproposed model f is to determine whether the input log\nsequence is a normal or abnormal log. The log sequence\nused during training consists of up to slen number of log\nkeys, and a unique set of log keys is defined as V. The log\nsequences used for training are all normal logs.\nInput Representation The input log sequence is defined as\nl, and the BERT model is used. Accordingly, the input data\nused in the train and test phases are configured as follows.\n‚Ä¢ Train phase : [CLS], w1, [MASK ], w3, ¬∑¬∑¬∑ , [SEP ]\n‚Ä¢ Test phase : [CLS], w1, [MASK ], w3, ¬∑¬∑¬∑ , [SEP ] *\nslen-times\nIn the train phase, the existing log keys were substituted with\nthe [MASK] token at an arbitrary probability; masking was\nconducted in this study at 20%. In the test phase, masking\nwas not performed at an arbitrary probability; however, each\nlog key was replaced with the [MASK] token when one log\nsequence was given to generate an slen number of data for\nthe test.\nObjective Function The objective function used for train-\ning is as follows, which is identical to Eq. (2). mi indicates\nmasking, where wi is the [MASK] token when mi = 1. Fur-\nthermore, HŒ∏ indicates the hidden vector of a transformer\nencoder.\nMaxŒ∏ log p(¬Øl|ÀÜl)\n‚âà\nslenX\ni=1\nmi log pŒ∏(wi|ÀÜl)\n=\nslenX\ni=1\nmi log exp(HŒ∏((ÀÜl)\n‚ä∫\ni e(wi))\nP\nw‚Ä≤ exp(HŒ∏((ÀÜl)\n‚ä∫\ni e(w‚Ä≤))\npŒ∏(wi| ÀÜX)\n(3)\n4.3. LAnoBERT\n4.3.1. O VERVIEW\nLAnoBERT proposed in this study can be largely divided\ninto the following three parts: preprocessing, model training,\nand abnormal score computation.\nFirst, the minimum preprocessing of a log sequence was\nperformed in the preprocessing step. Numbers, IPs, and\ndates are preprocessed, and information loss was minimized\nusing regular expressions. An initialized BERT was used\nas the model. During the training process, MLM was per-\nformed using only normal logs, and masking was randomly\nperformed at 20%. The NSP objective function was not\nused in this study when training BERT. Recent studies have\npointed out that the NSP objective function interferes with\nthe performance improvement (Joshi et al., 2020; Lample &\nConneau, 2019; Liu et al., 2019; Yang et al., 2019), and it\nwas excluded as it was unnecessary in log anomaly detection.\nAbnormal scores were calculated from the BERT model,\nwhich had been trained using both normal and abnormal\nlogs during test.\n4.3.2. P REPROCESSING\nBecause this study adopted a log parser-free method, simple\npreprocessing is conducted using regular expressions. As\nshown in Figure 3, the original log is highly complicated,\nunstructured data. When the Drain parser is used (with a\nlog parser), the parts defined as a template are excluded\nand eliminated, whereas certain parts are replaced with ‚å©*‚å™.\nConversely, this study did not use a log parser and instead\nreplaced the data with clear formats such as numbers, dates,\nand IPs with the words ‚ÄòNUM‚Äô or ‚ÄòIP‚Äô. Preprocessed log\nsequences were tokenized using the WordPiece (Wu et al.,\n2016) model used in BERT. The tokenizer for the log data\nwas also trained from scratch to ensure that the vocabulary\nof the log data from each system could be learned. The\ntraining was performed only for the normal logs, and the\ntokenizer created in the training process was used as it was\nduring the test.\n4.3.3. M ODEL\nThe proposed model LAnoBERT executed anomaly detec-\ntion based on a BERT Masked language model. The most\ncrucial assumption of this study is that ‚ÄúThere is a dif-\nference between the context of a normal system log and\nthat of an abnormal system log.‚ÄùIn other words, language\nmodels trained only with normal log data are expected to ex-\nhibit significant errors and low predictive probability when\nthey encounter the context of abnormal logs during the test.\nThe prediction error defined in this study refers to a cross-\nentropy loss that occurs between the label information and\nlogit value generated when the model predicts [MASK] as\na specific token. Additionally, the predictive probability is\ndefined as a value with the highest probability among the\nwords that can appear in the [MASK] token. When the prob-\nability of a predicted word is low, the respective context\nis considered difficult to find in the normal context and is\nidentified as an anomaly. Therefore, the errors and predic-\ntive probability calculated in this process can be utilized\nin anomaly detection. The core assumption of this study\nis as shown in Figure 2. BERT, which is trained only with\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nNormal System LogAbnormal System Log\nLOGn-1(0.93)High Prob.\nüòénatural context!Low Loss LOGn-1(0.2)Low Prob.\nü§îunnatural context..High Loss\nFigure 2.Anomaly score distribution difference between normal and abnormal log sequences.\nWith Log Parser (Drain)\nWithout Log Parser\nBLOCK* NameSystem addStoredBlock  blockMap updated  10 <*> <*> <*> 50010 is added to blk <*>,1719740\n081109 204005 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMapupdated: 10.251.73.220:50010 is added to blk_7128370237687728475 size 67108864\nNUMNUMNUMINFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMapupdated: IPis added to blk_NUMsize NUM\nOriginal Log\nFigure 3.Examples of preprocessing system log (HDFS dataset).\nnormal log data, produces low errors and high predictive\nprobability when performing MLM by receiving normal log\ndata as input because the commonly observed logs with a\nnormal pattern are understood as a familiar context. Contrar-\nily, large errors and low predictive probability are produced\nwhen performing MLM by receiving abnormal log data as\ninput. The logs are understood as an unfamiliar context if\nthe patterns that are not found in normal logs are input.\nPrevious studies that performed anomaly detection using a\ntransformer defined anomaly detection as a classification\nproblem or adjusted the embedding space using additional\nobjective functions. However, when a log parser is not used\nin the system log data where normal and abnormal log data\nare almost identical, a highly complicated format is exhib-\nited and the unsupervised learning-based performance is\nsubstantially reduced (Nedelkoski et al., 2020). In this study,\ntherefore, anomaly detection was performed by reflecting\nthe contextuality of the log data.\nTrain Phase Training is performed using the BERT Masked\nlanguage model for a log sequence that has been tokenized\nthrough a tokenizer trained with normal data. Training is\ninitiated from scratch using the initialized BERT, and the\nsame parameters as the BERT-base-uncased are used for\nthe model. The training parameters are almost identical to\nthose of the original BERT (Devlin et al., 2019); the only\ndifference is that the masking probability is set to 0.2. As\nan unsupervised learning-based anomaly detection model,\ntraining is only performed for normal logs.\nTest Phase In the test phase, the trained BERT is used to\nverify the normal and abnormal logs. Unlike the training\nphase, all log keys present in the log sequence are applied\nwith masking, and the predictive probability and error value\nare calculated. At this time, the test is performed by the\nnumber of log keys for one log sequence. An example of\nthis process is illustrated in Figure 4.\n4.3.4. A BNORMAL SCORE\nAs the most important element of anomaly detection, the\nfinal abnormal score of one log sequence is defined as the\ncollection of all abnormal scores calculated in the test phase.\nOwing to the nature of log keys, normal and abnormal logs\nexhibit almost similar aspects. Therefore, it is not appro-\npriate to use all values calculated for each log key as the\nabnormal score. If the values of all the log keys are used as\nthe abnormal score, it may cause confusion in recognizing\nthe scores of the abnormal and normal logs. Accordingly,\nthe values calculated from the Top- k number of log keys\nwere used to compute the abnormal score of a given text log\nin the proposed LAnoBERT. In this study,k is set to 5.\nThe prediction error proposed in this study and the abnormal\nscore of the predictive probability can be defined as follows.\nWhen a log sequence is defined asl = ( w1, w2, . . . , wslen ),\none sequence is generated by the number of log keys to cal-\nculate the predictive probability and prediction error. The\ntokens are then repeatedly replaced with the [MASK] token\neach; if the i-th token is [MASK], the sequence can be de-\nfined as ÀÜl1 = ( w1, w2, ¬∑¬∑¬∑ , wi‚àí1, [MASK ], wi+1, wslen ).\nThe number of log sequences used for prediction is identical\nto the length of the log sequence; thus, the prediction error\nof the i-th log sequence refers to the error value between the\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nÿªTokenizer ‡®ä\nLOG2\nLOG3\nLOG5\nLOG1\n LOG4\nLOG2\nLOG3\nLOG5\nMASK\n LOG4\nMASK\nLOG3\nLOG5\nLOG1\n LOG4\nLOG2\nMASK\nLOG5\nLOG1\n LOG4\nLOG2\nLOG3\nLOG5\nLOG1\n MASK\nLOG2\nLOG3\nMASK\nLOG1\n LOG4\n# ofLogkeys\nLoss\nProb.\nLoss\nProb.\nLoss\nProb.\nLoss\nProb.\nLoss\nProb.ABNORMALSCOREProb.\nLOG1LOG2LOG3LOG 4LOG5\nTop k aggregate(Low Prob.= Abnormal)\nLOG1LOG2LOG3LOG 4LOG5Loss\nTop k aggregate(high Loss = Abnormal)\nFigure 4.Test phase process of LAnoBERT. The proposed model calculates MASK Loss and Prob for each log key to detect anomalies in\none log sequence and obtains anomaly scores by aggregating top k values.\nlogit value calculated in ÀÜli and the label. Additionally, the\npredictive probability of the i-th log sequence refers to the\nmaximum predictive probability of the word that belongs\nto the [MASK] position as an answer in ÀÜli. The prediction\nerror and predictive probability, named errori and probi\nrespectively, can be obtained for N number of log sequences.\nTop k values are selected from the set of calculated predic-\ntion errors and predictive probabilities to computer the final\nabnormal score. The equations for computing the abnormal\nscores of a test log are shown in Eq. (4) and Eq. (5). The pro-\nposed methodology independently computes the abnormal\nscore with regard to the prediction error and the prediction\nprobability to detect anomalies.\nabnormalerror = 1\nk\nX\ni‚ààTop‚àík indices\nerrori, (4)\nabnormalprob = 1\nk\nX\ni‚ààTop‚àík indices\nprobi. (5)\nAs mentioned in section 4.3.2, LAnoBERT assumed that the\nabnormal logs would have a large prediction error or a low\nprediction probability. The abnormal score calculated from\neach log key is aggregated through the average of the top k\nvalues, which becomes the abnormal score of a log sequence.\nThe larger the abnormalerror, the more likely abnormal a\ngiven log sequence, whereas the lower the abnormalprob,\nthe more likely abnormal the log sequence.\nHowever, as shown in Figure 4, when calculating the ab-\nnormal score by LAnoBERT for all log sequences existing\nin the test dataset, the number of required computations\nbecomes the total number of log sequences √ó the length of\neach log sequence. Therefore, if the above method is applied,\nthe computational cost increases and becomes inefficient\nnot sufficient to be applied in an actual system.\nInspired by the fact that information is accumulated very\nfrequently and there are many duplicates in log data,\nwe propose an efficient inference process by removing\nrepeated computations for duplicated log sequences.\nSince a masked log sequence for ith token is defined as\n‚Äò[CLS], w1, w2, ¬∑¬∑¬∑ , wi‚àí1, [MASK ], wi+1, ¬∑¬∑¬∑ , wslen , [SEP ]‚Äô.\nWe build a log dictionary database with one log\nsequence as a key value for the inference process.\nIn this database, the dictionary key is defined as\na set of KEY = {key0, key1, key2, ¬∑¬∑¬∑ , keyn}.\nEach key has its corresponding abnormalerror\nand abnormalprob as values: DICT =\n{key1 : ( abnormalerror, abnormalprob), key2 :\n(abnormalerror, abnormalprob), ¬∑¬∑¬∑ , keyj :\n(abnormalerror, abnormalprob)}. Whenever one log\ndata arrives, the log key matching is performed. If the\ninput key is not matched to any of the existing keys in\nthe current log dictionary, the values for the new key are\ncomputed through inference, and then the log dictionary is\nupdated. On the other hand, when the input key is matched\nto one of the log keys in the current dictionary, the stored\nvalues are extracted as the abnormal score without an\nactual inference process. The following process reduces\nthe unnecessary time required for detecting anomalies by\ninference of duplicate logs multiple times. Therefore, it is\neffective because it can be applied in a realistic scenario\nand is expected to be effective in online anomaly detection\nsettings. An example of this inference process is illustrated\nin Figure 5 and the algorithm of the entire process is shown\nin Algorithm 1.\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nlog key matching{ key_1 : (ùëéùëèùëõùëúùëüùëöùëéùëô!\"\"#\", ùëéùëèùëõùëúùëüùëöùëéùëô$\"#%),key_2 : (ùëéùëèùëõùëúùëüùëöùëéùëô!\"\"#\", ùëéùëèùëõùëúùëüùëöùëéùëô$\"#%)key_3 : (ùëéùëèùëõùëúùëüùëöùëéùëô!\"\"#\", ùëéùëèùëõùëúùëüùëöùëéùëô$\"#%),...                  }\nabnormal score\nNUMNUMNUMINFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMapupdated: IPis added to blk_NUMsize NUM\nLogdictionarydatabaseMatching O\nMatching X: inference &update dictionary\n: search matched score\nupdate\nsearch\nsearch Detect abnormal Log\nFigure 5.Inference process for LAnoBERT\nAlgorithm 1 Inference Process\n// Definition\nKEY : a set of log sequence keys, DICT : the dictionary of the\nlog sequence keys,\nslen: the sequence length of a log, d : embedding dimension,\n{ln}N\nn=1 : an individual log sequence (Rslen√ód),\nLAnoBERT : the proposed model,TOPK : the top-k aggregation\nfunctions\n// Initialization\nKEY ‚Üê ‚àÖ, DICT ‚Üê ‚àÖ, j= 0\nInput : ln\nOutput :abnormalloss , abnormalprob\nfor n = 1to N do\n// log key matching\nif ln not in DICT then\nscoreloss ‚Üê ‚àÖ, scoreprob ‚Üê ‚àÖ\nfor i = 1to slen do\nln,i = [MASK ]\nlossj, probj ‚Üê LAnoBERT(ln)\nscoreloss ‚Üê scoreloss ‚à™ {lossi}\nscoreprob ‚Üê scoreprob ‚à™ {probi}\nend\nabnormalloss ‚Üê TOPK(scoreloss)\nabnormalprob ‚Üê TOPK(scoreprob)\nkeyj = ln\nKEY ‚Üê KEY ‚à™ {keyj}\nDICT [keyj] = (abnormalloss , abnormalprob)\nj ‚Üê j + 1\nreturn abnormalloss , abnormalprob\nelse\nabnormalloss , abnormalprob ‚Üê DICT [ln]\nreturn abnormalloss , abnormalprob\nend\nend\n5. Experimental Setting\n5.1. Datasets\nIn this study, HDFS (Xu et al., 2009), BGL (Oliner & Stear-\nley, 2007) Thunderbird (Oliner & Stearley, 2007) were used\nas the benchmark log datasets for a fair comparison with pre-\nTable 1.Number of logs in each dataset used in LAnoBERT\nDataset Type Train Test\nHDFS normal 8,712,418\n(446,578 blocks)\n2,463,201\n(128,483 blocks)\nabnormal - 138,410\n(16,838 blocks)\nBGL normal 3,496,193 903,310\nabnormal - 348,460\nThunderbird normal 166,371,162 41,592,791\nabnormal - 3,248,239\nvious studies. The three datasets include answer labels, and\nthe generalization performance of the system log anomaly\ndetection model can be verified as the data are deduced\nfrom different systems. HDFS, which is the Hadoop Dis-\ntributed File System, is log data generated from a private\ncloud environment where one log consists of multiple log se-\nquences. BGL includes data that consist of logs generated by\nthe Blue Gene/L supercomputer, where each individual log\nsequence is accompanied by a corresponding label indicat-\ning either a normal or an abnormal condition.Thunderbird\ndataset was obtained from the Thunderbird supercomputer\nsystem at Sandia National Laboratories (SNL) in Albu-\nquerque. This dataset includes alert and non-alert messages\nthat are identified by alert category tags. Among the three\ndatasets used in this study, the HDFS dataset is consid-\nered to have a relatively simple architecture (Nedelkoski\net al., 2020), while the Thunderbird dataset has the largest\nnumber of log messages. The distribution of normal and\nabnormal log sequences (or blocks) used in the training and\ntest datasets is presented in Table 1.\n5.2. Benchmark Methods\nIn this section, we present the benchmark models for com-\nparison with LAnoBERT‚Äôs performance among various log\nanomaly detection models. The benchmark models were\nselected based on the usage of a log parser and whether the\nlearning was supervised or unsupervised. The selected mod-\nels were LogRobust, HitAnomaly, LogSy, Principal Com-\nponent Analysis (PCA) (Xu et al., 2009), One-Class SVM\n(OCSVM) (Sch¬®olkopf et al., 2001), Isolation Forest (iForest)\n(Liu et al., 2008), LogCluster (Lin et al., 2016), DeepLog,\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\n[ HitAnomaly ] [ LogSy ]\n[ LogRobust ][ DeepLog ]\n[ LogAnomaly ]\n[ LogBERT ]\n[ NeuralLog ]\n[ LAnoBERT ]\nFigure 6.Benchmark models and LAnoBERT for log anomaly detection.\nLogAnomaly (Meng et al., 2019), and LogBERT. Figure 6\nillustrates the following aspects of the deep learning-based\nbaseline models: 1) structural differences among the mod-\nels, 2) log data preprocessing method during training and\ntesting, and 3) anomaly detection method.\n‚Ä¢ LogRobust is a supervised learning-based model that\nutilizes an attention-based bi-LSTM architecture. The\nmodel employs a specialized log parser to preprocess\nlog data, generating a TF-IDF and word semantic vec-\ntor to extract the features of the log data. For training,\nboth normal and abnormal log data are used in solving\na classification problem.\n‚Ä¢ HitAnomaly is a supervised learning-based model that\nemploys a transformer architecture. It utilizes a special-\nized log parser for log data to standardize templates\nand encode log information as parameters. The model\ncombines two features of normal and abnormal log\ndata with an attention mechanism to classify the data.\n‚Ä¢ LogSy is a supervised learning-based anomaly detec-\ntion model that utilizes a transformer architecture. It\ndoes not require the use of a log parser, as log val-\nues are preprocessed using a tokenizer (Nedelkoski\net al., 2020). Both normal and abnormal log data are\nutilized in the model, with data generated from differ-\nent systems and a distance-based loss function being\nemployed.\n‚Ä¢ NeuralLog is a transformer-based classification model\nthat utilizes a tokenizer. NeuralLog has a similar struc-\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nture to LogSy, but differs in its utilization of both nor-\nmal and abnormal data from the target system and\na different system during the training process. This\napproach sets it apart from LogSy, which solves the\nclassification problem by utilizing normal data from\nthe target system and abnormal data generated from\na different system. To evaluate the performance of\nNeuralLog, several popular backbone models, namely\nBERT, GPT2, and RoBERTa, were utilized. Among\nthese models, BERT achieved the highest performance.\n‚Ä¢ PCA is a linear transformation technique that trans-\nforms a set of correlated variables into a set of uncor-\nrelated variables, referred to as principal components.\nThis method builds a counting matrix for log sequence\nfrequency to detect anomalies, then reduces the origi-\nnal counting matrix into a low-dimensional space for\nthe identification of abnormal sequences.\n‚Ä¢ OCSVM is a widely adopted one-class classification\nmodel for log anomaly detection (Wang et al., 2004),\nutilizing only normal log data. The model is designed\nto identify the boundary that separates the majority of\ninput data from the remainder, represented as a hyper-\nplane that separates normal data from outliers.\n‚Ä¢ iForest is a tree-based unsupervised learning algorithm\nthat utilizes the isolation of observations that are dis-\ntinct from the remainder of the input data. The ap-\nproach employs the formation of an ensemble of deci-\nsion trees, each of which partitions the data into smaller\nsubsets.\n‚Ä¢ LogCluster is a clustering method for detecting fre-\nquently occurring line patterns and abnormal events in\ntextual event logs.\n‚Ä¢ DeepLog is a deep learning-based unsupervised log\nanomaly detection model based on an LSTM architec-\nture. A specialized log parser is used to generate the\ninput values for the LSTM, and the model predicts the\nnext word. If the next word appears in a trained pattern,\nit is classified as normal, otherwise, it is considered\nabnormal.\n‚Ä¢ LogAnomaly is proposed as a solution for detect-\ning anomalies in log streams. The model leverages\nattention-based LSTM architecture to consider log data\nas natural language sequences. To extract semantic in-\nformation, the LogAnomaly model employs the tem-\nplate2vec technique on log templates. This enables the\ndetection of both sequential and quantitative anomalies\nin log data.\n‚Ä¢ LogBERT is BERT based anomaly detection model\nthat employs MLM and DeepSVDD (Ruff et al., 2018)\nloss during training. Log data is preprocessed using the\nTable 2.Anomaly detection evaluation criteria\nNormal Abnormal\nNormal True Negative False Positive\nAbnormal False Negative True Positive\nlog parser, after which the LogBERT model identifies\nanomalous patterns in the candidate set similar to the\nDeepLog.\n5.3. Evaluation Metrics\nThe F1 score which is dependent on the threshold and AU-\nROC, which is independent of the threshold, were used as\nevaluation metrics in this study. Most studies on anomaly\ndetection use AUROC as the evaluation metric in general,\nwhereas previous studies that approached log anomaly de-\ntection as a binary classification problem used the best F1\nscore to record the performance; hence, both these metrics\nwere used in this study for comparison with previous studies.\nWhen the threshold of the models in anomaly detection is\ndetermined, the confusion matrix presented in Table 2 is\ngenerated depending on the actual anomaly case and the\nanomaly detected by the models. The recall and precision\nare calculated from the confusion matrix using precision and\nrecall, and the F1 score is calculated based on the harmonic\nmean of the two metrics.\nF1 score = 2 ¬∑ precision ¬∑ recall\nprecision + recall, (6)\nprecision = TP\nTP + FP , recall = TP\nTP + FN ,\nTP : true positive, FP : false positive, FN : false negative.\nThe F1 score calculated using Eq. (6) is a metric influenced\nby the threshold of a model and cannot guarantee the relia-\nbility of the fundamental performance of an anomaly detec-\ntion model; hence, AUROC, which is an evaluation metric\nunaffected by the threshold was also calculated. AUROC\ncalculates the false positive rate (FAR) and true positive rate\n(TPR) for all the threshold candidates, and then illustrates\na receiver operating characteristic curve with the FAR as\nthe x-axis and TPR as the y-axis to calculate the area of\nthe base side. The AUROC value is closer to 1 because the\nanomaly detection model has a better performance, whereas\na random model has a value closer to 0.5.\nThe best F1 score threshold cannot be determined in advance\nin this study because the log anomaly detection experiment\nis conducted with only normal data for training. Therefore,\nthe best F1 score was calculated using the threshold that\nrepresents the best performance theoretically for the test\ndataset, and the same method was used to calculate the best\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nF1 score of benchmark studies for a fair comparison. Addi-\ntionally, benchmark studies examined the performance using\nonly the F1 score; however, this study also utilized AUROC,\nwhich is an evaluation metric that is not affected by the\nthreshold to examine the performance. In this experiment,\nthe method of determining anomalies differs among the\nbenchmark models. Specifically, DeepLog and LogBERT\ndetermine anomalies based on the presence of predicted\nvalues in the top k candidate set, while LogRobust and Hi-\ntAnomaly, being classification models, do not calculate an\nabnormal score. On the other hand, LogSy, LogCluster, and\nLogAnomaly define an abnormal score, but the AUROC\ncould not be calculated because no official implementation\ncode was available. Therefore, it is impossible to calcu-\nlate AUROC for the baseline models for comparison; the\nF1 score and performance of AUROC of LAnoBERT are\npresented in Tables 4 and 5.\n6. Results\nTo verify the excellence of the proposed methodology, this\nstudy compared a supervised and an unsupervised learning-\nbased anomaly detection model. Moreover, the use of a\nparser was recorded for comparison because the perfor-\nmance of the log anomaly detection significantly varies\ndepending on the use of a log parser.\n6.1. Anomaly Detection Performance\nTable 3 shows the F1-score for the proposed LAnoBERT\nmodel and ten additional models, including both super-\nvised learning-based models (LogSy, LogRobust, and Hi-\ntAnomaly) and unsupervised learning-based models (PCA,\nIForest, OCSVM, LogCluster, DeepLog, LogAnomaly, and\nLogBERT). It is important to note that the performance re-\nsults for the supervised models were obtained from their\nrespective original studies, whereas the performance of all\nunsupervised models, except for the proposed LAnoBERT,\nwere obtained from the LogBERT study. As a result, the\nperformance results for LogRobust and HitAnomaly on the\nThunderbird dataset, as well as for LogSy on the HDFS\ndataset, are not reported in this study due to the lack of\ninformation in their respective original papers. The results\nindicate that the performance of the BGL dataset was infe-\nrior compared to the HDFS dataset due to its more complex\nstructure, as previously reported in Huang et al. (2020).\nThe performance of LogRobust and HitAnomaly, which are\nbased on supervised learning, was observed to be favorable\non the HDFS and BGL datasets. Both models underwent\npreprocessing utilizing the Drain parser, and HitAnomaly,\nwhich utilized parameters that were not part of the log tem-\nplate, demonstrated strong performance on both datasets.\nThese results indicate that information loss during log pars-\ning can have a significant impact on model training. LogSy,\nwhich employed a classification model built with normal and\nabnormal data obtained from different systems, recorded\nan F1 score of 0.6500 on the BGL dataset and 0.9900 on\nthe Thunderbird dataset. This highlights the advantage of\nincorporating a more realistic representation of the system\ninto the model, as compared to LogRobust and HitAnomaly.\nHowever, the performance of LogSy on the BGL dataset was\nlower than expected. These results emphasize the limitations\nof performing log anomaly detection without log parsing\non data from a specific system. NeuralLog demonstrated\nhigh performance across three datasets - HDFS, BGL, and\nThunderbird, with scores of 0.9800, 0.9800, and 0.9600 re-\nspectively. This performance was noteworthy, particularly\nconsidering that it didn‚Äôt utilize a parser, yet still outper-\nformed supervised learning-based models such as LogRo-\nbust and HitAnomaly. This outcome can be interpreted as\na meaningful result in itself. However, a limitation of Neu-\nralLog is its reliance on both normal and abnormal logs\nduring the learning process, which could make it less suit-\nable for real-world scenarios. This point can be identified as\na potential shortcoming of the model.\nIn the unsupervised learning models comparison, PCA, iFor-\nest, OCSVM, and LogCluster showed lower performance\ncompared to DeepLog, LogAnomaly, and LogBERT which\nutilized deep learning techniques. Specifically, DeepLog\noutperformed LogAnomaly, demonstrating the effectiveness\nof its ‚Äùtop g candidate‚Äù logic. LogBERT demonstrated re-\nmarkable performance with F1 scores of 0.8232 in HDFS,\n0.9083 in BGL, and 0.9664 in Thunderbird, with especially\nstrong results in BGL. These results suggest that the BERT-\nbased LogBERT model effectively captures rich semantics\nby understanding context-specific information to log data.\nFurthermore, incorporating MLKP and VHM tasks has been\nobserved to improve the model‚Äôs ability to detect anomalies.\nIn Section 4.3.4, it was highlighted that BERT‚Äôs MLM al-\nlows for the calculation of both mask loss and probabil-\nity. In order to evaluate the performance of the proposed\nLAnoBERT, two abnormal scores were generated using\nmask loss and probability. The results showed that the pre-\ndictive loss score led to a performance of 0.9123 in HDFS,\n0.6932 in BGL, and 0.5142 in Thunderbird. It was ob-\nserved that HDFS, with its shorter log sequence length and\nfewer unique log keys, displayed acceptable detection per-\nformance. Conversely, BGL and Thunderbird, characterized\nby longer log sequence lengths and more complex struc-\ntures, showed relatively lower performance than other deep\nlearning-based unsupervised models. This can be attributed\nto the fact that the mask loss calculates the accuracy of\nword-by-word predictions between the original and pre-\ndicted log keys, resulting in low loss values only when the\nlog keys are predicted in the correct order. For example, if\nthe ground truth log key is ‚ÄòA-B-C-D-E‚Äô and the model\npredicts ‚ÄòB-C-D-E-F‚Äô, the loss value would be high due\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nTable 3.F1-score on HDFS, BGL, and Thunderbird. ‚Ä† indicates the performance of benchmark models reported by LogBERT. The highest\nperformance is highlighted in bold and underlined, and the second-best performance is indicated in bold. Supervised comparisons\n(Upper): the performance of LogRobust, HitAnomaly, LogSy, and NeuralLog are compared, and it is observed that LAnoBERT\ndemonstrates comparable or superior performance to these models, despite the fact that LogRobust, HitAnomaly, LogSy, and NeuralLog\nallow for the use of abnormal data in their training, whereas LAnoBERT does not. Unsupervised comparisons (Lower): it is shown that\nLAnoBERT, which is a log parser-free model, produces strong results compared to other unsupervised models.\nLog Parser HDFS BGL Thunderbird\nSupervised\nLogRobust O 0.9700 0.8300 -\nHitAnomaly O 0.9800 0.9200 -\nLogSy X - 0.6500 0.9900\nNeuralLog X 0.9800 0.9800 0.9600\nUnsupervised\nPCA‚Ä† O 0.1112 0.1661 0.5439\niForest ‚Ä† O 0.6049 0.3065 0.0329\nOCSVM ‚Ä† O 0.0495 0.0196 0.2548\nLogCluster ‚Ä† O 0.5399 0.7663 0.5961\nDeepLog ‚Ä† O 0.7734 0.8612 0.9308\nLogAnomaly ‚Ä† O 0.5619 0.7409 0.9273\nLogBERT O 0.8232 0.9083 0.9664\nLAnoBERT\n(Predictive Loss)\nX 0.9123 0.6932 0.5142\nLAnoBERT\n(Predictive Prob.)\nX 0.9645 0.8749 0.9990\nto the incorrect prediction of all tokens. However, from\nthe perspective of the log sequence, the confidence in the\nordered prediction of the keys ‚ÄòB-C-D-E‚Äô must be con-\nsidered when evaluating an abnormal score. The previously\ndiscussed example highlights the limitations of using the\npredictive loss score on long and complex data.\nWhen the predictive probability was used as the abnormal\nscore, LAnoBERT demonstrated superior performance to all\nthe other models, with HDFS scoring 0.9645, BGL scoring\n0.8749, and Thunderbird scoring 0.9990, with the excep-\ntion of BGL. The results showed that the abnormal score\nbased on the mask probability proposed by LAnoBERT\nwas a critical factor in performance improvement. These\nresults highlight the effectiveness of LAnoBERT, an unsu-\npervised learning-based method, compared to the parser-\nbased supervised learning methodologies LogRobust, Hi-\ntAnomaly, and LogSy. Despite not using a parser during\ntraining, LAnoBERT achieved higher performance than\nLogRobust and LogSy, while being only 0.0451 lower than\nHitAnomaly in BGL. This demonstrates the significance of\nconsidering context and pre-training of MLM in the design\nof LAnoBERT for log anomaly detection. Additionally, us-\ning predictive probability allows for the detection of cases\nwith unseen normal log data more accurately compared to\nusing predictive loss, making LAnoBERT more practical\nand useful in real-world applications than benchmark mod-\nels.\nFurthermore, it is critical to perform log anomaly detection\non actual systems. Since logs are collected in real-time, the\nmajority of log data is comprised of normal logs. As a result,\nconducting anomaly detection based on binary classification\nusing normal and abnormal log data poses a significant chal-\nlenge for its practical implementation. Figure 7 illustrates\nthe selected benchmark models of supervised and unsuper-\nvised learning, with and without the use of a parser. The first\nquadrant, which represents the parser-involved supervised\ncase, represents the easiest scenario to ensure the perfor-\nmance of a model, but it is also the most unrealistic. On the\nother hand, the parser-free unsupervised case in the third\nquadrant is the most realistic scenario but also the most chal-\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nSupervised learning\nUnsupervised learning\nUse\nLog parser\nDo not use\nLog parser\nLogRobust\n(0.97)\nHitAnomaly\n(0.98)\nNeuralLog\n(0.98)\nLogCluster\n(0.54)\nLogAnomaly\n(0.56)\nDeepLog\n(0.77)\nLogBERT\n(0.82)\nLAnoBERT\n(0.96)\nUnrealistic &\nModel-\nfriendly\nRealistic &\nModel-\nadversely\nSupervised learning\nUnsupervised learning\nUse\nLog parser\nDo not use\nLog parser\nLogRobust\n(0.83)\nHitAnomaly\n(0.92)\nNeuralLog\n(0.98)\nLAnoBERT\n(0.87)\nUnrealistic &\nModel-\nfriendly\nRealistic &\nModel-\nadversely\n[ HDFS dataset ] [ BGL dataset ]\nSupervised learning\nUnsupervised learning\nUse\nLog parser\nDo not use\nLog parser\nLogSy\n(0.99)\nLAnoBERT\n(0.99)\nUnrealistic &\nModel-\nfriendly\nRealistic &\nModel-\nadversely\n[ Thunderbird dataset ]\nLogAnomaly\n(0.74)\nLogCluster\n(0.77)\nDeepLog\n(0.86)\nLogBERT\n(0.91)\nLogCluster\n(0.59)\nLogAnomaly\n(0.93)\nDeepLog\n(0.93)\nLogBERT\n(0.96)\nLogSy\n(0.65)\nNeuralLog\n(0.96)\nFigure 7.Comparison with LAnoBERT and four benchmark models in realistic scenarios.\nlenging in terms of ensuring the performance of a model.\nDespite these challenges, the proposed LAnoBERT model in\nthis study showed comparable performance (BGL) to bench-\nmark models under the easiest assumption and even better\nperformance (HDFS, Thunderbird) than some benchmark\nmodels in the most difficult scenario. Hence, the LAnoBERT\nmodel proposed in this study appears to be a practical model\nthat can be applied in real-world systems.\nAs explained earlier, supervised learning-based models\nare still proposed for system log anomaly detection. The\nproposed model achieved better performance than LogSy,\nwhich is a supervised learning-based model, and the LogRo-\nbust model, which uses a parser and is a supervised learning-\nbased model. LAnoBERT recorded excellent detection per-\nformance than certain supervised learning-based baseline\nmodels in the most unfair comparison environment. In other\nwords, LAnoBERT is a model trained in the most realis-\ntic yet disadvantageous environment and is a robust model\nexhibiting more outstanding or similar performance com-\npared to other baseline models in the most unrealistic and\nadvantageous environment.\nTable 4 lists the F1 score and AUROC performance of\nLAnoBERT. The performance of benchmark models was\nnot measured using AUROC, which is a frequently used\nevaluation metric in anomaly detection. benchmark models\nmay score highly for the best F1 score to exhibit the best per-\nformance; however, they are limited in identifying whether\nthe model has high reliability regardless of the threshold.\nTherefore, the performances of the two evaluation metrics\nwere determined for LAnoBERT, and the results showed\nthat the F1 score is similar to that of the other models eval-\nuated in a relatively more advantageous environment. By\ncontrast, a high AUROC value closer to 1, which indicates\nthat a model is most idealistic, was obtained. Consequently,\neven if threshold-dependent detection performance metrics\nother than the F1 score are used, LAnoBERT can be re-\ngarded as a highly reliable system log anomaly detection\nmodel with remarkably outstanding performance.\n6.2. Performance according to the BERT learning\nmethod\nBERT includes models pre-trained with natural language,\nand the pre-trained model typically resulted in an excellent\nperformance in various natural language processing tasks.\nTherefore, a comparative experiment was conducted for\nLAnoBERT, which was pre-trained with natural language.\nThe proposed LAnoBERT was trained to utilize an initial-\nized BERT model. In order to investigate the impact of the\npre-training model and provide a practical alternative for\nreal-world log anomaly detection, we conducted an addi-\ntional experiment in which the pre-trained BERT model\nwith natural language is employed instead of training BERT\nfrom scratch. The results of this experiment are documented\nin Table 5.\nWhen the BERT model pre-trained with natural language\nwas used, MLM was additionally performed after import-\ning the pre-trained model. Pre-training has already been\nperformed with massive natural language data, and thus, it\ncan be interpreted that task adaptive pre-training (Gururan-\ngan et al., 2020) was conducted with the log data. Table 5\npresents the result of training 6,000 steps with a batch size\nof 15 per 2080 ti for a total of two 2080 ti‚Äôs.\nWhen the BERT model pre-trained with natural language\nwas used, the F1 score in the BGL data was 0.9020, which\nwas improved by 0.0271 compared to the model trained\nfrom scratch; by contrast, the F1 score in the HDFS data\nwas 0.9304, which was decreased by 0.0341 compared to\nthe model trained from scratch. These results indicate that\nthe HDFS data consisting of a very simple log structure\nhave degraded performance when a model that has learned\nthe context of natural language is used. The number of vo-\ncabularies in the HDFS dataset after preprocessing is only\n200, which is very few for expressing the context of natural\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nTable 4.Performance of our model (F1 Score, AUROC)\nLog Parser HDFS BGL Thunderbird\nF1 Score AUROC F1 Score AUROC F1 Score AUROC\nUnsupervised\nLAnoBERT\n(Predictive Prob.) X 0.9645 0.9901 0.8749 0.9721 0.9990 0.9520\nTable 5.Performance of initialized LAnoBERT and pre-trained LAnoBERT\nLog Parser Training HDFS BGL Thunderbird\nF1 Score AUROC F1 Score AUROC F1 Score AUROC\nUnsupervised\nLAnoBERT\n(Predictive Prob.) X Initialized 0.9645 0.9901 0.8749 0.9721 0.9990 0.9520\nLAnoBERT\n(Predictive Prob.) X pre-trained 0.9304 0.9659 0.9020 0.9912 0.8954 0.3505\nlanguage; hence, the pre-training presumably had a negative\neffect on anomaly detection. Conversely, BGL data with a\nrelatively more complicated structure has a total of 1,000\nvocabularies after preprocessing. This supports the fact that\nthe BGL dataset is a more complicated dataset than HDFS,\nand there are cases where natural language is included in\nthe log data with this number of vocabularies. Therefore, if\nappropriate training is performed additionally for a model\nthat has learned the context of natural language, the anomaly\ndetection performance can be improved compared to other\nmodels that have not been pre-trained. The experimental\nresults in Table 5 show that the log data containing natu-\nral language can have a similar form as human language\nand that pre-trained BERT can be effectively applied. In\nconclusion, the results demonstrate that incorporating the\nLAnoBERT framework with a pre-trained BERT model is a\nviable alternative.\n7. Conclusion\nThis study proposed LAnoBERT, which is an unsupervised\nlearning-based system log anomaly detection model where\na parser is not used. The proposed LAnoBERT learned the\ncontext of normal log data using MLM, and abnormal logs\nwere detected based on the prediction error and predictive\nprobability during the test. In terms of the nature of the\nsystem log, normal and abnormal data have similar charac-\nteristics; thus, a new score calculation method is proposed\nfor defining the abnormal score based on the top-k predictive\nprobability. The proposed model exhibited the best perfor-\nmance compared to the unsupervised models, and superior\nor similar performance compared to supervised learning-\nbased models. In addition, the efficient inference process\nproposed in this study is expected to work well in an actual\nsystem. Although the performances of benchmark models\nare heavily dependent on the use of log parser, our proposed\nLAnoBERT can be a robust and parser-independent log\nanomaly detection model.\nThe proposed LAnoBERT framework exhibits promising\nresults in log anomaly detection, however, there are limita-\ntions that need to be addressed in future research. Firstly,\nLAnoBERT requires individual training for each log dataset.\nA unified framework, as outlined in UniAD (You et al.,\n2022), is needed to cater to diverse log structures in differ-\nent systems like distributed systems, supercomputers, and\nserver applications. Secondly, LAnoBERT‚Äôs Transformer-\nbased architecture incurs higher computational costs com-\npared to RNN-based models due to its self-attention layer\n(O(n2 ¬∑ d) complexity) versus the recurrent layer of RNN\n(O(n ¬∑ d2) complexity). To resolve the computational in-\nefficiency, incorporating recent parameter-efficient learn-\ning methods such as LoRA (Hu et al., 2022) and Adapter\n(Houlsby et al., 2019) is crucial in developing a real-time\nlog anomaly detection model. Finally, in this study, only\nminimal preprocessing was performed using regular expres-\nsions and tokenization using Wordpiece tokenizer. The Log\nParser-free methodology can be improved by templating\nlog sequences into the natural language via prompt tuning\n(Brown et al., 2020; Lester et al., 2021) which could en-\nable anomaly detection with a pre-trained tokenizer and\nlanguage model, without the need for further preprocessing\nor training.\nAcknowledgements\nThis work was supported by the National Research Founda-\ntion of Korea (NRF) grant funded by the Korea government\n(MSIT) (NRF-2022R1A2C2005455). This work was also\nsupported by Institute of Information & communications\nTechnology Planning & Evaluation (IITP) grant funded by\nthe Korea government (MSIT) (No. 2021-0-00471, Devel-\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nopment of Autonomous Control Technology for Error-Free\nInformation Infrastructure Based on Modeling & Optimiza-\ntion).\nReferences\nBrown, A., Tuor, A., Hutchinson, B., and Nichols, N. Re-\ncurrent neural network attention mechanisms for inter-\npretable system log anomaly detection. In Proceedings of\nthe First Workshop on Machine Learning for Computing\nSystems, MLCS‚Äô18, pp. 8, New York, NY , USA,\n2018. Association for Computing Machinery. ISBN\n9781450358651. doi: 10.1145/3217871.3217872. URL\nhttps://doi.org/10.1145/3217871.3217872.\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D.,\nDhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,\nAskell, A., Agarwal, S., Herbert-V oss, A., Krueger, G.,\nHenighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J.,\nWinter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M.,\nGray, S., Chess, B., Clark, J., Berner, C., McCandlish,\nS., Radford, A., Sutskever, I., and Amodei, D. Language\nmodels are few-shot learners. In Larochelle, H., Ran-\nzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.),\nAdvances in Neural Information Processing Systems,\nvolume 33, pp. 1877‚Äì1901. Curran Associates, Inc.,\n2020. URL https://proceedings.neurips.cc/paper/2020/\nfile/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.\nCinque, M., Cotroneo, D., and Pecchia, A. Event logs for\nthe analysis of software failures: A rule-based approach.\nIEEE Transactions on Software Engineering, 39(6):806‚Äì\n821, 2013. doi: 10.1109/TSE.2012.67.\nClark, K., Khandelwal, U., Levy, O., and Manning,\nC. D. What does BERT look at? an analysis of\nBERT‚Äôs attention. In Proceedings of the 2019 ACL\nWorkshop BlackboxNLP: Analyzing and Interpreting\nNeural Networks for NLP, pp. 276‚Äì286, Florence, Italy,\nAugust 2019. Association for Computational Linguistics.\ndoi: 10.18653/v1/W19-4828. URL https://aclanthology.\norg/W19-4828.\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K.\nBERT: Pre-training of deep bidirectional transformers\nfor language understanding. In Proceedings of the\n2019 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human\nLanguage Technologies, V olume 1 (Long and Short\nPapers), pp. 4171‚Äì4186, Minneapolis, Minnesota, June\n2019. Association for Computational Linguistics. doi:\n10.18653/v1/N19-1423. URL https://aclanthology.org/\nN19-1423.\nDu, M. and Li, F. Spell: Streaming parsing of system event\nlogs. In 2016 IEEE 16th International Conference on\nData Mining (ICDM), pp. 859‚Äì864, 2016. doi: 10.1109/\nICDM.2016.0103.\nDu, M., Li, F., Zheng, G., and Srikumar, V . Deeplog:\nAnomaly detection and diagnosis from system logs\nthrough deep learning. In Proceedings of the 2017 ACM\nSIGSAC Conference on Computer and Communications\nSecurity, CCS ‚Äô17, pp. 1285‚Äì1298, New York, NY , USA,\n2017. Association for Computing Machinery. ISBN\n9781450349468. doi: 10.1145/3133956.3134015. URL\nhttps://doi.org/10.1145/3133956.3134015.\nElnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G.,\nYu, W., Jones, L., Gibbs, T., Feher, T., Angerer, C.,\nSteinegger, M., Bhowmik, D., and Rost, B. Prottrans:\nTowards cracking the language of lifes code through self-\nsupervised deep learning and high performance comput-\ning. IEEE Transactions on Pattern Analysis and Machine\nIntelligence, pp. 1‚Äì1, 2021. doi: 10.1109/TPAMI.2021.\n3095381.\nGuo, H., Yuan, S., and Wu, X. Logbert: Log anomaly\ndetection via bert. In2021 International Joint Conference\non Neural Networks (IJCNN), pp. 1‚Äì8, 2021. doi: 10.\n1109/IJCNN52387.2021.9534113.\nGururangan, S., Marasovi ¬¥c, A., Swayamdipta, S., Lo, K.,\nBeltagy, I., Downey, D., and Smith, N. A. Don‚Äôt stop\npretraining: Adapt language models to domains and\ntasks. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pp. 8342‚Äì\n8360, Online, July 2020. Association for Computational\nLinguistics. doi: 10.18653/v1/2020.acl-main.740. URL\nhttps://aclanthology.org/2020.acl-main.740.\nHansen, S. E. and Atkins, E. T. Automated system moni-\ntoring and notification with swatch. In LISA, volume 93,\npp. 145‚Äì152, 1993.\nHe, P., Zhu, J., Zheng, Z., and Lyu, M. R. Drain: An online\nlog parsing approach with fixed depth tree. 2017 IEEE\nInternational Conference on Web Services (ICWS), pp.\n33‚Äì40, 2017.\nHoulsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B.,\nDe Laroussilhe, Q., Gesmundo, A., Attariyan, M.,\nand Gelly, S. Parameter-efficient transfer learning\nfor NLP. In Chaudhuri, K. and Salakhutdinov, R.\n(eds.), Proceedings of the 36th International Conference\non Machine Learning, volume 97 of Proceedings of\nMachine Learning Research, pp. 2790‚Äì2799. PMLR, 09‚Äì\n15 Jun 2019. URL https://proceedings.mlr.press/v97/\nhoulsby19a.html.\nHu, E. J., yelong shen, Wallis, P., Allen-Zhu, Z., Li, Y .,\nWang, S., Wang, L., and Chen, W. LoRA: Low-rank\nadaptation of large language models. In International\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nConference on Learning Representations, 2022. URL\nhttps://openreview.net/forum?id=nZeVKeeFYf9.\nHuang, S., Liu, Y ., Fung, C., He, R., Zhao, Y ., Yang, H.,\nand Luan, Z. Hitanomaly: Hierarchical transformers for\nanomaly detection in system log. IEEE Transactions\non Network and Service Management, 17(4):2064‚Äì2076,\n2020.\nJawahar, G., Sagot, B., and Seddah, D. What does BERT\nlearn about the structure of language? In Proceedings\nof the 57th Annual Meeting of the Association for\nComputational Linguistics, pp. 3651‚Äì3657, Florence,\nItaly, July 2019. Association for Computational Lin-\nguistics. doi: 10.18653/v1/P19-1356. URL https://\naclanthology.org/P19-1356.\nJoshi, M., Chen, D., Liu, Y ., Weld, D. S., Zettlemoyer,\nL., and Levy, O. Spanbert: Improving pre-training\nby representing and predicting spans. Transactions of\nthe Association for Computational Linguistics, 8:64‚Äì77,\n2020.\nKim, G., Yi, H., Lee, J., Paek, Y ., and Yoon, S. Lstm-\nbased system-call language modeling and robust en-\nsemble method for designing host-based intrusion de-\ntection systems. CoRR, abs/1611.01726, 2016. URL\nhttp://arxiv.org/abs/1611.01726.\nLample, G. and Conneau, A. Cross-lingual language model\npretraining. CoRR, abs/1901.07291, 2019. URL http:\n//arxiv.org/abs/1901.07291.\nLe, V .-H. and Zhang, H. Log-based anomaly detection with-\nout log parsing. In 2021 36th IEEE/ACM International\nConference on Automated Software Engineering (ASE),\npp. 492‚Äì504. IEEE, 2021.\nLester, B., Al-Rfou, R., and Constant, N. The power of scale\nfor parameter-efficient prompt tuning. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natural\nLanguage Processing, pp. 3045‚Äì3059, Online and Punta\nCana, Dominican Republic, November 2021. Associa-\ntion for Computational Linguistics. doi: 10.18653/v1/\n2021.emnlp-main.243. URL https://aclanthology.org/\n2021.emnlp-main.243.\nLin, Q., Zhang, H., Lou, J.-G., Zhang, Y ., and Chen,\nX. Log clustering based problem identification\nfor online service systems. In 2016 IEEE/ACM\n38th International Conference on Software Engineering\nCompanion (ICSE-C), pp. 102‚Äì111, 2016.\nLiu, F. T., Ting, K. M., and Zhou, Z.-H. Isolation forest.\nIn 2008 Eighth IEEE International Conference on Data\nMining, pp. 413‚Äì422, 2008. doi: 10.1109/ICDM.2008.\n17.\nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig,\nG. Pre-train, prompt, and predict: A systematic survey of\nprompting methods in natural language processing, 2021.\nLiu, Y ., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy,\nO., Lewis, M., Zettlemoyer, L., and Stoyanov, V . Roberta:\nA robustly optimized bert pretraining approach. arXiv\npreprint arXiv:1907.11692, 2019.\nMeng, W., Liu, Y ., Zhu, Y ., Zhang, S., Pei, D., Liu, Y ., Chen,\nY ., Zhang, R., Tao, S., Sun, P., and Zhou, R. Loganomaly:\nUnsupervised detection of sequential and quantitative\nanomalies in unstructured logs. In Proceedings of\nthe Twenty-Eighth International Joint Conference on\nArtificial Intelligence, IJCAI-19, pp. 4739‚Äì4745. Inter-\nnational Joint Conferences on Artificial Intelligence Or-\nganization, 7 2019. doi: 10.24963/ijcai.2019/658. URL\nhttps://doi.org/10.24963/ijcai.2019/658.\nNedelkoski, S., Bogatinovski, J., Acker, A., Cardoso, J., and\nKao, O. Self-attentive classification-based anomaly de-\ntection in unstructured logs. In 2020 IEEE International\nConference on Data Mining (ICDM), pp. 1196‚Äì1201.\nIEEE, 2020.\nOliner, A. and Stearley, J. What supercomputers say: A\nstudy of five system logs. In 37th Annual IEEE/IFIP\nInternational Conference on Dependable Systems and\nNetworks (DSN‚Äô07), pp. 575‚Äì584. IEEE, 2007.\nOprea, A., Li, Z., Yen, T.-F., Chin, S. H., and Alrwais, S.\nDetection of early-stage enterprise infection by mining\nlarge-scale log data. In 2015 45th Annual IEEE/IFIP\nInternational Conference on Dependable Systems and\nNetworks, pp. 45‚Äì56. IEEE, 2015.\nPetroni, F., Rockt¬®aschel, T., Riedel, S., Lewis, P., Bakhtin,\nA., Wu, Y ., and Miller, A. Language models as knowl-\nedge bases? In Proceedings of the 2019 Conference\non Empirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natural\nLanguage Processing (EMNLP-IJCNLP), pp. 2463‚Äì\n2473, Hong Kong, China, November 2019. Associa-\ntion for Computational Linguistics. doi: 10.18653/v1/\nD19-1250. URL https://aclanthology.org/D19-1250.\nPrewett, J. E. Analyzing cluster log files using logsurfer.\nIn Proceedings of the 4th Annual Conference on Linux\nClusters. Citeseer, 2003.\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., and\nSutskever, I. Language models are unsupervised multitask\nlearners. 2019.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S.,\nMatena, M., Zhou, Y ., Li, W., and Liu, P. J. Exploring the\nLAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model\nlimits of transfer learning with a unified text-to-text trans-\nformer. Journal of Machine Learning Research, 21(140):\n1‚Äì67, 2020. URL http://jmlr.org/papers/v21/20-074.html.\nRao, R., Meier, J., Sercu, T., Ovchinnikov, S., and Rives,\nA. Transformer protein language models are unsuper-\nvised structure learners. In International Conference on\nLearning Representations, 2020.\nRuff, L., Vandermeulen, R., Goernitz, N., Deecke, L.,\nSiddiqui, S. A., Binder, A., M ¬®uller, E., and Kloft, M.\nDeep one-class classification. In Dy, J. and Krause, A.\n(eds.), Proceedings of the 35th International Conference\non Machine Learning, volume 80 of Proceedings of\nMachine Learning Research, pp. 4393‚Äì4402. PMLR, 10‚Äì\n15 Jul 2018. URL https://proceedings.mlr.press/v80/\nruff18a.html.\nSchick, T. and Sch ¬®utze, H. Exploiting cloze-questions\nfor few-shot text classification and natural language in-\nference. In Proceedings of the 16th Conference of the\nEuropean Chapter of the Association for Computational\nLinguistics: Main V olume, pp. 255‚Äì269, Online, April\n2021. Association for Computational Linguistics. doi: 10.\n18653/v1/2021.eacl-main.20. URL https://aclanthology.\norg/2021.eacl-main.20.\nSch¬®olkopf, B., Platt, J. C., Shawe-Taylor, J. C., Smola,\nA. J., and Williamson, R. C. Estimating the support\nof a high-dimensional distribution. Neural Comput.,\n13(7):1443‚Äì1471, jul 2001. ISSN 0899-7667. doi:\n10.1162/089976601750264965. URL https://doi.org/10.\n1162/089976601750264965.\nSimache, C. and Kaaniche, M. Availability assessment of\nsunos/solaris unix systems based on syslogd and wtmpx\nlog files: A case study. In 11th Pacific Rim International\nSymposium on Dependable Computing (PRDC‚Äô05), pp.\n8 pp.‚Äì, 2005. doi: 10.1109/PRDC.2005.20.\nTaylor, W. L. ‚Äúcloze procedure‚Äù: A new tool for measuring\nreadability. Journalism quarterly, 30(4):415‚Äì433, 1953.\nTenney, I., Das, D., and Pavlick, E. BERT rediscovers\nthe classical NLP pipeline. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics, pp. 4593‚Äì4601, Florence, Italy, July 2019.\nAssociation for Computational Linguistics. doi: 10.\n18653/v1/P19-1452. URL https://aclanthology.org/\nP19-1452.\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,\nL., Gomez, A. N., Kaiser, L. u., and Polosukhin, I. At-\ntention is all you need. In Guyon, I., Luxburg, U. V .,\nBengio, S., Wallach, H., Fergus, R., Vishwanathan, S.,\nand Garnett, R. (eds.), Advances in Neural Information\nProcessing Systems, volume 30. Curran Associates, Inc.,\n2017.\nWang, Y ., Wong, J., and Miner, A. Anomaly intrusion detec-\ntion using one class svm. In Proceedings from the Fifth\nAnnual IEEE SMC Information Assurance Workshop,\n2004., pp. 358‚Äì364, 2004. doi: 10.1109/IAW.2004.\n1437839.\nWu, Y ., Schuster, M., Chen, Z., Le, Q. V ., Norouzi, M.,\nMacherey, W., Krikun, M., Cao, Y ., Gao, Q., Macherey,\nK., et al. Google‚Äôs neural machine translation system:\nBridging the gap between human and machine translation.\narXiv preprint arXiv:1609.08144, 2016.\nXu, W., Huang, L., Fox, A., Patterson, D., and Jordan, M. I.\nDetecting large-scale system problems by mining con-\nsole logs. In Proceedings of the ACM SIGOPS 22nd\nsymposium on Operating systems principles, pp. 117‚Äì\n132, 2009.\nYang, Z., Dai, Z., Yang, Y ., Carbonell, J., Salakhutdinov,\nR. R., and Le, Q. V . Xlnet: Generalized autoregressive\npretraining for language understanding. Advances in\nneural information processing systems, 32, 2019.\nYen, T.-F., Oprea, A., Onarlioglu, K., Leetham, T., Robert-\nson, W., Juels, A., and Kirda, E. Beehive: Large-scale\nlog analysis for detecting suspicious activity in enterprise\nnetworks. In Proceedings of the 29th Annual Computer\nSecurity Applications Conference, pp. 199‚Äì208, 2013.\nYou, Z., Cui, L., Shen, Y ., Yang, K., Lu, X., Zheng, Y ., and\nLe, X. A unified model for multi-class anomaly detec-\ntion. In Oh, A. H., Agarwal, A., Belgrave, D., and Cho,\nK. (eds.), Advances in Neural Information Processing\nSystems, 2022. URL https://openreview.net/forum?id=\nbMYU8 qD8PW.\nZhang, X., Xu, Y ., Lin, Q., Qiao, B., Zhang, H.,\nDang, Y ., Xie, C., Yang, X., Cheng, Q., Li, Z.,\net al. Robust log-based anomaly detection on un-\nstable log data. In Proceedings of the 2019 27th\nACM Joint Meeting on European Software Engineering\nConference and Symposium on the Foundations of\nSoftware Engineering, pp. 807‚Äì817, 2019.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.763512134552002
    },
    {
      "name": "Anomaly detection",
      "score": 0.7624646425247192
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.6968515515327454
    },
    {
      "name": "Parsing",
      "score": 0.6650354862213135
    },
    {
      "name": "Key (lock)",
      "score": 0.6025095582008362
    },
    {
      "name": "Anomaly (physics)",
      "score": 0.5850969552993774
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5334150195121765
    },
    {
      "name": "Inference",
      "score": 0.4786176085472107
    },
    {
      "name": "Pipeline (software)",
      "score": 0.4753272831439972
    },
    {
      "name": "Process (computing)",
      "score": 0.44801682233810425
    },
    {
      "name": "Data mining",
      "score": 0.4156169593334198
    },
    {
      "name": "Machine learning",
      "score": 0.39738768339157104
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.34520959854125977
    },
    {
      "name": "Programming language",
      "score": 0.07760801911354065
    },
    {
      "name": "Condensed matter physics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Computer security",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 10
}