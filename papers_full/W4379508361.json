{
  "title": "The Advent of Generative Language Models in Medical Education",
  "url": "https://openalex.org/W4379508361",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3165109671",
      "name": "Mert Karabacak",
      "affiliations": [
        "Mount Sinai Health System"
      ]
    },
    {
      "id": "https://openalex.org/A3214457656",
      "name": "Burak Berksu Ozkara",
      "affiliations": [
        "The University of Texas MD Anderson Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2027235618",
      "name": "Konstantinos Margetis",
      "affiliations": [
        "Mount Sinai Health System"
      ]
    },
    {
      "id": "https://openalex.org/A1998877",
      "name": "Max Wintermark",
      "affiliations": [
        "The University of Texas MD Anderson Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2304641737",
      "name": "Sotirios Bisdas",
      "affiliations": [
        "National Hospital for Neurology and Neurosurgery",
        "University College London",
        "The University of Texas MD Anderson Cancer Center",
        "University College London Hospitals NHS Foundation Trust"
      ]
    },
    {
      "id": "https://openalex.org/A3165109671",
      "name": "Mert Karabacak",
      "affiliations": [
        "Mount Sinai Health System"
      ]
    },
    {
      "id": "https://openalex.org/A3214457656",
      "name": "Burak Berksu Ozkara",
      "affiliations": [
        "The University of Texas MD Anderson Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2027235618",
      "name": "Konstantinos Margetis",
      "affiliations": [
        "Mount Sinai Health System"
      ]
    },
    {
      "id": "https://openalex.org/A1998877",
      "name": "Max Wintermark",
      "affiliations": [
        "The University of Texas MD Anderson Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2304641737",
      "name": "Sotirios Bisdas",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4322761615",
    "https://openalex.org/W2939970150",
    "https://openalex.org/W2163580545",
    "https://openalex.org/W4228997948",
    "https://openalex.org/W3217315014",
    "https://openalex.org/W3112185662",
    "https://openalex.org/W3135353559",
    "https://openalex.org/W2766894906",
    "https://openalex.org/W3196768570",
    "https://openalex.org/W4229033576",
    "https://openalex.org/W2991538617",
    "https://openalex.org/W4286515929"
  ],
  "abstract": "Artificial intelligence (AI) and generative language models (GLMs) present significant opportunities for enhancing medical education, including the provision of realistic simulations, digital patients, personalized feedback, evaluation methods, and the elimination of language barriers. These advanced technologies can facilitate immersive learning environments and enhance medical students' educational outcomes. However, ensuring content quality, addressing biases, and managing ethical and legal concerns present obstacles. To mitigate these challenges, it is necessary to evaluate the accuracy and relevance of AI-generated content, address potential biases, and develop guidelines and policies governing the use of AI-generated content in medical education. Collaboration among educators, researchers, and practitioners is essential for developing best practices, guidelines, and transparent AI models that encourage the ethical and responsible use of GLMs and AI in medical education. By sharing information about the data used for training, obstacles encountered, and evaluation methods, developers can increase their credibility and trustworthiness within the medical community. In order to realize the full potential of AI and GLMs in medical education while mitigating potential risks and obstacles, ongoing research and interdisciplinary collaboration are necessary. By collaborating, medical professionals can ensure that these technologies are effectively and responsibly integrated, contributing to enhanced learning experiences and patient care.",
  "full_text": "Viewpoint\nThe Advent of Generative Language Models in Medical Education\nMert Karabacak1*, MD; Burak Berksu Ozkara2*, MD; Konstantinos Margetis1, MD, PhD; Max Wintermark2, MSc,\nMBA, MD; Sotirios Bisdas2,3, MSc, MD, PhD\n1Department of Neurosurgery, Mount Sinai Health System, New York, NY, United States\n2Department of Neuroradiology, MD Anderson Cancer Center, Houston, TX, United States\n3Department of Neuroradiology, The National Hospital for Neurology and Neurosurgery, University College London NHS Foundation Trust, London,\nUnited Kingdom\n*these authors contributed equally\nCorresponding Author:\nSotirios Bisdas, MSc, MD, PhD\nDepartment of Neuroradiology\nThe National Hospital for Neurology and Neurosurgery\nUniversity College London NHS Foundation Trust\nNational Hospital for Neurology and Neurosurgery\nQueen Square\nLondon, WC1N 3BG\nUnited Kingdom\nPhone: 44 020 3448 3446\nEmail: s.bisdas@ucl.ac.uk\nAbstract\nArtificial intelligence (AI) and generative language models (GLMs) present significant opportunities for enhancing medical\neducation, including the provision of realistic simulations, digital patients, personalized feedback, evaluation methods, and the\nelimination of language barriers. These advanced technologies can facilitate immersive learning environments and enhance\nmedical students' educational outcomes. However, ensuring content quality, addressing biases, and managing ethical and legal\nconcerns present obstacles. To mitigate these challenges, it is necessary to evaluate the accuracy and relevance of AI-generated\ncontent, address potential biases, and develop guidelines and policies governing the use of AI-generated content in medical\neducation. Collaboration among educators, researchers, and practitioners is essential for developing best practices, guidelines,\nand transparent AI models that encourage the ethical and responsible use of GLMs and AI in medical education. By sharing\ninformation about the data used for training, obstacles encountered, and evaluation methods, developers can increase their\ncredibility and trustworthiness within the medical community. In order to realize the full potential of AI and GLMs in medical\neducation while mitigating potential risks and obstacles, ongoing research and interdisciplinary collaboration are necessary. By\ncollaborating, medical professionals can ensure that these technologies are effectively and responsibly integrated, contributing\nto enhanced learning experiences and patient care.\n(JMIR Med Educ 2023;9:e48163) doi: 10.2196/48163\nKEYWORDS\ngenerative language model; artificial intelligence; medical education; ChatGPT; academic integrity; AI-driven feedback; stimulation;\nevaluation; technology; learning environment; medical student\nIntroduction\nThe rapid development of generative language models (GLMs)\nand artificial intelligence (AI) has ignited both excitement and\nconcern in many fields, including medical education [1].\nSophisticated models such as OpenAI's ChatGPT [2] and\nGoogle's BARD [3] present opportunities to transform medical\neducation with enhanced efficiency, interactivity, and realism.\nHowever, these new technologies also bring significant\nchallenges and uncertainties.\nThe integration of these AI tools into medical education\nnecessitates careful consideration and a nuanced understanding\nof potential implications. On the one hand, these models offer\nunparalleled capabilities, such as generating human-like text,\nsimulating complex patient scenarios, and providing\npersonalized learning experiences, thus fostering a more\nJMIR Med Educ 2023 | vol. 9 | e48163 | p. 1https://mededu.jmir.org/2023/1/e48163\n(page number not for citation purposes)\nKarabacak et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\nimmersive and contextually relevant learning environment; on\nthe other hand, potential issues of accuracy, reliability, misuse\nof AI-generated content, and academic integrity concerns are\nvalid and demand careful deliberation. Additionally, the risk of\nbias, privacy issues, and potential dehumanization in the learning\nprocess call for caution. Another important aspect to consider\nis the “digital divide.” Unequal distribution of AI technology\nand resources could exacerbate existing disparities within the\neducation system, particularly in low-resource settings and\namong disadvantaged student populations.\nThis viewpoint aims to explore these dimensions, discussing\nthe benefits, challenges, ethical considerations, and academic\nintegrity issues associated with incorporating AI into medical\neducation. The objective is not to advocate for or against the\nuse of AI in medical education but rather to provide an analysis\nthat assists educators, practitioners, and policy makers in making\ninformed decisions.\nPotential Benefits\nGLMs hold immense potential in augmenting medical education\nthrough the generation of novel content, development of\nsimulations, and creation of digital patients [4]. Compared to\ntraditional computer-based simulations, these AI-enabled tools\npresent a more dynamic and realistic learning experience. They\noffer more sophisticated scenarios for medical students to\npractice, thereby facilitating clinical decision-making and patient\ncare [5]. By leveraging the advanced natural language\nunderstanding and generating capabilities of GLMs, platforms\nsuch as PerSim leverage them to provide students with\ncontextually relevant patient scenarios that are more dynamic\nand adaptable than previous computer-based models [6]. The\nadvantage of GLMs over these older models lies in their ability\nto generate unique and personalized responses, creating a more\nengaging and realistic interaction for the student. These\nenhanced capabilities permit the creation of immersive\nsimulations and digital patients, which provide a more effective\nand individualized educational experience. These AI tools can\nprovide real-time, individualized feedback based on a learner's\nperformance and unique learning requirements during simulation\nexercises. This feedback can help students identify areas for\nimprovement and refine their abilities. Furthermore, GLMs can\ngenerate customized simulation scenarios and case studies for\neach learner, allowing them to practice specific skills repeatedly\nin a controlled environment, thus fostering skill acquisition and\nrefinement. In addition to benefiting students, these AI tools\ncan also assist educators by providing resources and\nrecommendations for simulation implementation. While human\nactors posing as simulated patients can offer a high degree of\nrealism, AI-driven simulations provide a scalable, cost-effective\nalternative that can be customized to each student's learning\nneeds. This innovative approach, thus, represents a significant\nadvancement over traditional computer-based medical\nsimulations.\nAI-driven feedback and evaluation can help identify areas of\nweakness and improve overall performance [7]. The use of\ngenerative AI in formative and summative assessments in\nmedical education can contribute to more personalized, efficient,\nand targeted evaluation methods. The creation of personalized\nquizzes for students is an illustration of the use of generative\nAI in medical education evaluations. By analyzing each student's\nstrengths and weaknesses, generative AI can generate unique\nformative and summative assessments for each student. This\ncould include a combination of questions focusing on areas in\nwhich the student needs improvement and topics in which the\nstudent excels, providing a more balanced and targeted\nevaluation of their medical knowledge. Furthermore, by\nanalyzing student performance and providing real-time feedback,\nthese AI-driven tools can help educators develop customized\nlearning plans that address individual needs and improve overall\noutcomes.\nAs concrete examples of how AI and GLMs can impact medical\neducation, one can consider the following scenarios. A medical\neducator can use a GLM to create a wide array of simulated\npatient scenarios. These scenarios can be highly realistic and\nvaried, enabling students to gain exposure to a broad range of\nmedical conditions and patient interactions. For instance, a\nmedical student could interact with a simulated patient with a\nrare disease, ask questions, and receive responses that mimic\nreal patient responses. This can allow the student to practice\nclinical reasoning skills in a safe and controlled environment.\nLikewise, medical researchers can use GLMs to scan and\nanalyze vast amounts of medical literature quickly, identifying\nrelevant studies and summarizing their findings. This can\nsignificantly reduce the time spent on literature reviews,\nallowing researchers to focus more on their primary research\nwork.\nAI-based educational resources not only cater to the needs of\nmedical students but also aid in disseminating health-related\ninformation to the general public [8]. AI-based educational\nresources can provide patients with individualized health\ninformation, fostering health literacy and equipping people to\nmake wise decisions regarding their health. Moreover, GLMs’\nenhanced comprehension of complex medical terminology and\ncontext might enable AI-powered health companions such as\nAda Health to provide more precise diagnostic suggestions and\nindividualized health advice to both clinicians and patients [9].\nThe nuanced capabilities of these models to generate text at\nvarying degrees of complexity could enhance the communication\nof health information. By adjusting the language and\nterminology used based on the intended audience, AI tools can\nmake health information more accessible and understandable\nto a diverse range of individuals, from laypeople to medical\nprofessionals. This targeted communication approach can\npromote health literacy and empower individuals to make more\ninformed decisions regarding their health.\nOne significant potential benefit of AI and GLMs in medical\neducation that merits discussion is their potential to enhance\nmachine translation, thereby fostering global collaboration and\nknowledge exchange. While machine translation is not a novel\nconcept, the advent of AI and GLMs have significantly enhanced\nits accuracy and sophistication, making it a relevant point of\ndiscussion in the context of medical education. For instance,\neBay's Machine Translation demonstrated a 7% increase in\ntranslation accuracy over its previous service [10], showcasing\nJMIR Med Educ 2023 | vol. 9 | e48163 | p. 2https://mededu.jmir.org/2023/1/e48163\n(page number not for citation purposes)\nKarabacak et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\nthe potential of AI in overcoming language barriers. The\nimplications of such advancements extend to medical education,\nwhere improved translation accuracy can foster global\ncollaboration and knowledge exchange. AI-powered language\nmodels can translate medical lectures, webinars, and research\narticles in real time, making critical information accessible to\nindividuals from diverse linguistic backgrounds. This can create\na more inclusive learning environment and ensure that\nadvancements in medical knowledge and patient care are\nglobally accessible. Therefore, while machine translation itself\nis not new, the application of advanced GLMs promises a\nsignificant improvement over earlier models, and this potential\nbenefit should not be overlooked.\nChallenges and Ethical Considerations\nAs GPT-4 continues to make waves in various industries, it is\ncrucial to acknowledge the potential risks that come with AI\nintegration. OpenAI’s Chief Executive Officer Sam Altman has\nhighlighted the threat of widespread disinformation and\ncyberattacks as prominent concerns [11]. When it comes to\nintegrating generative AI into medical education, these risks\ntake on an even greater significance. Given the high stakes in\nhealth care and the potential for harm, the medical education\nfield must be especially vigilant and proactive in managing\nthese potential problems. The quality of the AI-generated\ncontent, for instance, is paramount. It requires meticulous\nassessment to ensure its accuracy and relevance. Measures such\nas proper prompting and iterative feedback loops can aid in\nenhancing the quality and reliability of AI-generated content in\nmedical education [12,13].\nDue to their training data, AI systems have been shown to\nexhibit discriminatory behavior and reinforce existing\nstereotypes. Incorporating GLMs into medical education\nnecessitates exercising caution and addressing potential biases.\nSeveral past incidents—such as Microsoft's Tay chatbot tweeting\nracist and sexist content, and racial biases in facial recognition\ntechnology—demonstrate the need for vigilance [14,15]. By\nlearning from these examples and avoiding potential pitfalls,\nwe can develop more ethical and objective AI systems for\nmedical education. To ensure the development of fair and\nresponsible educational resources that promote accurate\nknowledge and uphold the integrity of the medical profession,\nit is essential to address inherent biases and ethical concerns.\nRecently, researchers have developed a logic-trained language\nmodel that significantly reduces harmful stereotypes by\npredicting relationships between sentences using context and\nsemantic meaning [16]. This model outperforms large-scale\nmodels on logic-language comprehension tasks, demonstrating\nthe potential for using logical learning to reduce bias and\nstereotypes in GLMs.\nFinally, the incorporation of generative AI in medical education\nraises ethical and legal concerns, highlighting the need for AI\nethics training for students to ensure the responsible and\nconscientious application of these advanced technologies [17].\nIssues related to data privacy, transparency, and intellectual\nproperty must be addressed to ensure that these tools are used\nresponsibly [18]. Furthermore, the potential manipulation of\nAI-generated content to produce misleading medical information\nor endorse unproven treatments could adversely impact not only\nmedical students' education but also patients' understanding of\ntheir conditions. While AI can create highly realistic patient\nscenarios that can enhance medical education, it is crucial to\nnote that these same tools can be misused or misrepresented.\nFor example, an AI-generated scenario may be subtly altered\nto present incorrect or controversial medical advice or to favor\na particular medical product or treatment. These altered\nscenarios, while appearing as realistic as accurate ones, could\nlead to confusion or misinterpretation of essential medical\nconcepts, hence undermining the educational value and\npotentially harming patient care.\nThe unauthorized distribution of AI-generated content raises\nsignificant legal and ethical issues. This concern can be 2-fold.\nOn the one hand, it pertains to the risks of sharing inappropriate\ncontent with AI models, such as uploading copyrighted material\nwithout obtaining the necessary permissions or exposing\nconfidential patient information for training AI models—this\nis particularly problematic as these actions violate privacy laws\nand copyright regulations; on the other hand, it also concerns\nthe potential for AI-generated content to inadvertently repeat\ncopyrighted or confidential data that were used during its\ntraining phase. If an AI model were to generate and distribute\ncontent that mirrors confidential information or copyrighted\nmaterial it was trained on, without proper acknowledgement or\nrespect for privacy, it could have serious legal and ethical\nimplications. Both these scenarios underscore the need for robust\noversight, stringent data governance protocols, and clear usage\npolicies when incorporating AI into medical education. The\ndevelopment of comprehensive guidelines and policies to govern\nthe use of AI-generated content in medical education is crucial\nto ensure that its application in the learning process is both\nresponsible and beneficial, preserving the integrity of medical\neducation and the welfare of patients.\nAddressing the potential for AI-generated content to contribute\nto academic dishonesty is a critical issue [19,20]. The\navailability of GLMs could enable students to produce essays\nor assignment responses, bypassing the learning process and\ndevaluing their educational experience. Further, AI-generated\ncontent can potentially produce misinformation or biased\ninformation, undermining trust in educational materials and\nleading to possible misinterpretation of essential medical\nconcepts. To mitigate these concerns, academic institutions\nneed to establish explicit guidelines concerning the use of\nAI-generated content in medical education. First, transparency\nis paramount. Students should be required to disclose their use\nof AI-generated content in their academic work. Equally,\neducators should also disclose their use of AI tools when\ndeveloping educational materials, fostering a culture of\ntransparency and setting an example for students. Second, the\nimplementation of AI content detectors or AI classifiers is\nrecommended, with the understanding that these tools are used\nnot to detect plagiarism but to identify AI-generated content.\nHowever, the authors urge caution, as these detection tools are\nnot always accurate or reliable, and the risk of unjust accusations\nof academic dishonesty is substantial. Therefore, these tools\nwould need to undergo rigorous validation and regular updates\nJMIR Med Educ 2023 | vol. 9 | e48163 | p. 3https://mededu.jmir.org/2023/1/e48163\n(page number not for citation purposes)\nKarabacak et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\nto ensure their accuracy and fairness in determining the use of\nAI-generated content in student submissions. Third, while the\npotential of AI tools in education is highlighted in this paper,\nit is not meant to promote an unrestricted adoption of such\ntechnologies. Rather, the integration of AI into medical\neducation should be carefully considered, and the use of\nAI-generated content should be limited to specific educational\ncontexts, such as brainstorming or generating ideas for further\nresearch and discussion. Lastly, a shift toward diverse\nassessment methods is recommended. This could include\npresentations, practical assessments, and in-person written\nexaminations, reducing the reliance on traditional essays that\ncan be more easily generated by AI. By establishing, validating,\nand enforcing these guidelines, medical schools can promote\nethical and responsible use of AI-generated content in their\neducational programs. Figure 1 summarizes the potential\nbenefits, challenges, and ethical considerations regarding the\nuse of generative AI in medical education.\nFigure 1. Potential benefits, challenges, and ethical considerations regarding the use of generative AI in medicine. AI: artificial intelligence.\nFuture Directions and Perspectives\nThe future trajectory of medical education will be significantly\ninfluenced by the integration of GLMs and AI as these\ntechnologies continue to evolve [21]. The development of best\npractices, ethical principles, and regulations that support the\nresponsible and effective use of AI in medical education hinges\non the collective efforts of educators, researchers, and\npractitioners [22]. The creation of novel generative AI models\nspecifically suited to medical education represents a promising\narea for future research. These models can produce accurate\nand pertinent content if they are trained on curated, high-quality\ndata sets. In addition, effective interdisciplinary cooperation\nbetween computer scientists and medical professionals is\nnecessary to develop AI-driven tools that cater to the particular\nrequirements of medical education [23].\nA critical consideration in this context is the accessibility of\nthese data sets. Existing AI models are often trained on readily\navailable data, which may not encompass specialized\ninformation necessary for advanced educational pursuits or rare\ndiseases. Much of this vital information could be behind\npaywalls, posing a significant barrier to the development of\ncompetent AI models in these areas. Hence, future endeavors\nneed to address the challenge of sourcing diverse and\nhigh-quality data sets for model training, ensuring that AI\ncompetency extends to niche and specialized areas of medical\neducation.\nThe BLOOM project, a large language model created by over\n1000 volunteer researchers, exemplifies the importance of\ntransparency by sharing details about the data it was trained on,\nthe challenges faced during development, and the methods used\nto evaluate its performance, while in contrast, the lack of\ntransparency surrounding OpenAI's GPT-4 raises concerns as\nJMIR Med Educ 2023 | vol. 9 | e48163 | p. 4https://mededu.jmir.org/2023/1/e48163\n(page number not for citation purposes)\nKarabacak et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\nthe company has not revealed any technical details about its\ndevelopment, data, computing power, or training techniques\n[24,25]. Transparency is also essential in medical education\nwhen developing and incorporating AI models. By openly\nsharing information about the data used for training, the\nchallenges encountered, and the evaluation methods, developers\ncan build trust and credibility within the medical community.\nThis transparency allows medical professionals and educators\nto better understand the AI models' strengths and limitations,\nallowing them to make informed decisions about integrating\nthese tools into their curriculum and practice.\nThe digital divide represents another crucial aspect to address\nwhen incorporating AI-driven resources into education [26,27].\nAs medical education gradually transitions from traditional\nprinted materials toward digital AI-generated resources, it is of\nparamount importance to ensure equitable access to these\nresources. This involves considering disparities in access to\ntechnology and internet connectivity, particularly in\nlow-resource settings such as rural or remote areas, institutions\nin transitional countries, or among students facing\nsocioeconomic challenges.\nFuture research should prioritize the investigation of long-term\neffects of integrating generative AI into medical education.\nUnderstanding the impact of AI-driven tools on student learning,\nclinical judgment, and patient care outcomes is crucial for\ndiscerning potential advantages and drawbacks. Additionally,\nthe creation of instructional materials and tutorials to aid\neducators in incorporating GLMs and AI into medical education\ncould be invaluable. By sharing best practices and insights\ngleaned from early adopters, we can ensure that these\ntechnologies are used effectively, responsibly, and equitably.\nConclusions\nIncorporating GLMs and AI into medical education presents\nboth opportunities and difficulties. GLMs can generate accurate,\nindividualized content for students, allowing for more efficient\nlearning experiences. To ensure the responsible application of\nthese advanced technologies, it is necessary to address potential\nbiases and ethical concerns. Educators, researchers, and\npractitioners must collaborate to create guidelines, policies, and\nbest practices that promote the ethical and effective integration\nof GLMs and AI in medical education. In addition, for the\nmedical community to develop trust and credibility, the\ndevelopment and implementation of AI-powered tools must be\ntransparent. As the fields of AI and GLMs continue to develop,\nongoing research and interdisciplinary collaboration will be\nessential to realizing their full potential in medical education\nwhile mitigating potential risks and obstacles.\nAcknowledgments\nKM has received travel and lodging support for training by Stryker, Medtronic, and Accelus and consulting fees by Viseon.\nAuthors' Contributions\nMK, KM, BBO, MW, and SB conceptualized the study. MK and BBO drafted the manuscript. KM, MW, and SB reviewed and\nedited the manuscript and supervised the study.\nConflicts of Interest\nNone declared.\nReferences\n1. Eysenbach G. The role of ChatGPT, generative language models, and artificial intelligence in medical education: a\nconversation with ChatGPT and a call for papers. JMIR Med Educ 2023 Mar 06;9:e46885 [FREE Full text] [doi:\n10.2196/46885] [Medline: 36863937]\n2. Introducing ChatGPT. OpenAI. URL: https://openai.com/blog/chatgpt [accessed 2023-04-07]\n3. A message from our CEO: an important next step on our AI journey. Google. 2023. URL: https://blog.google/technology/\nai/bard-google-ai-search-updates/ [accessed 2023-05-16]\n4. Chan KS, Zary N. Applications and challenges of implementing artificial intelligence in medical education: integrative\nreview. JMIR Med Educ 2019 Jun 15;5(1):e13930 [FREE Full text] [doi: 10.2196/13930] [Medline: 31199295]\n5. McGaghie WC, Issenberg SB, Petrusa ER, Scalese RJ. A critical review of simulation-based medical education research:\n2003-2009. Med Educ 2010 Jan;44(1):50-63 [doi: 10.1111/j.1365-2923.2009.03547.x] [Medline: 20078756]\n6. What is PerSim®? MedCognition. URL: https://medcognition.com/what-is-persim/ [accessed 2023-04-07]\n7. Hooda M, Rana C, Dahiya O, Rizwan A, Hossain MS. Artificial intelligence for assessment and feedback to enhance student\nsuccess in higher education. Math Probl Eng 2022 May 5;2022:1-19 [doi: 10.1155/2022/5215722]\n8. Liu T, Xiao X. A framework of AI-based approaches to improving eHealth literacy and combating infodemic. Front Public\nHealth 2021;9:755808 [FREE Full text] [doi: 10.3389/fpubh.2021.755808] [Medline: 34917575]\n9. Gilbert S, Mehl A, Baluch A, Cawley C, Challiner J, Fraser H, et al. How accurate are digital symptom assessment apps\nfor suggesting conditions and urgency advice? A clinical vignettes comparison to GPs. BMJ Open 2020 Dec\n16;10(12):e040269 [FREE Full text] [doi: 10.1136/bmjopen-2020-040269] [Medline: 33328258]\nJMIR Med Educ 2023 | vol. 9 | e48163 | p. 5https://mededu.jmir.org/2023/1/e48163\n(page number not for citation purposes)\nKarabacak et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\n10. Relihan T. How machine learning can break down language and trade barriers. MIT Sloan School of Management. 2018.\nURL: https://mitsloan.mit.edu/ideas-made-to-matter/how-machine-learning-can-break-down-language-and-trade-barriers\n[accessed 2023-04-07]\n11. Helmore E. 'We are a little bit scared': OpenAI CEO warns of risks of artificial intelligence. The Guardian. 2023. URL:\nhttps://www.theguardian.com/technology/2023/mar/17/openai-sam-altman-artificial-intelligence-warning-gpt4 [accessed\n2023-04-06]\n12. Gao T. Prompting: Better Ways of Using Language Models for NLP Tasks. The Gradient. 2021. URL: https://thegradient.\npub/prompting/ [accessed 2023-04-07]\n13. Robinson N. Why GPT-powered apps are missing feedback loops. Medium. URL: https://blog.startupstash.com/\nfeedback-loops-how-the-wave-of-gpt-powered-apps-are-leaving-them-behind-1d05c90639c1 [accessed 2023-04-07]\n14. Hunt E. Tay, Microsoft's AI chatbot, gets a crash course in racism from Twitter. The Guardian. 2016 Mar 24. URL: https:/\n/www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter\n[accessed 2023-04-07]\n15. Najibi A. Racial discrimination in face recognition technology. Science in the News. 2020. URL: https://sitn.hms.harvard.edu/\nflash/2020/racial-discrimination-in-face-recognition-technology/ [accessed 2023-04-07]\n16. Gordon R. Large language models are biased. Can logic help save them? MIT CSAIL. 2023. URL: https://www.csail.mit.edu/\nnews/large-language-models-are-biased-can-logic-help-save-them [accessed 2023-04-07]\n17. Katznelson G, Gerke S. The need for health AI ethics in medical school education. Adv Health Sci Educ Theory Pract 2021\nOct 03;26(4):1447-1458 [doi: 10.1007/s10459-021-10040-3] [Medline: 33655433]\n18. Hacker P, Engel A, Mauer M. Regulating ChatGPT and other large generative AI models. arXiv. Preprint posted online\nFebruary 5, 2023\n19. Peritz A. A.I. is making it easier than ever for students to cheat. SLATE. 2022. URL: https://slate.com/technology/2022/\n09/ai-students-writing-cheating-sudowrite.html [accessed 2023-04-07]\n20. Barnett S. ChatGPT is making universities rethink plagiarism. Wired. 2023. URL: https://www.wired.com/story/\nchatgpt-college-university-plagiarism/ [accessed 2023-04-07]\n21. Wartman SA, Combs CD. Medical education must move from the information age to the age of artificial intelligence. Acad\nMed 2018 Aug;93(8):1107-1109 [doi: 10.1097/ACM.0000000000002044] [Medline: 29095704]\n22. Lomis K, Jeffries P, Palatta A, Sage M, Sheikh J, Sheperis C, et al. Artificial intelligence for health professions educators.\nNAM Perspect 2021;2021 [FREE Full text] [doi: 10.31478/202109a] [Medline: 34901780]\n23. Ejaz H, McGrath H, Wong BL, Guise A, Vercauteren T, Shapey J. Artificial intelligence and medical education: a global\nmixed-methods study of medical students' perspectives. Digit Health 2022;8:20552076221089099 [FREE Full text] [doi:\n10.1177/20552076221089099] [Medline: 35521511]\n24. Heaven WD. GPT-4 is bigger and better than ChatGPT—but OpenAI won’t say why. MIT Technology Review. 2023.\nURL: https://www.technologyreview.com/2023/03/14/1069823/gpt-4-is-bigger-and-better-chatgpt-openai/ [accessed\n2023-04-06]\n25. Heikkilä M. Inside a radical new project to democratize AI. MIT Technology Review. 2022. URL: https://www.\ntechnologyreview.com/2022/07/12/1055817/inside-a-radical-new-project-to-democratize-ai/ [accessed 2023-04-06]\n26. Lembani R, Gunter A, Breines M, Dalu MTB. The same course, different access: the digital divide between urban and rural\ndistance education students in South Africa. J Geogr High Educ 2019 Nov 22;44(1):70-84 [doi:\n10.1080/03098265.2019.1694876]\n27. van de Werfhorst HG, Kessenich E, Geven S. The digital divide in online education: inequality in digital readiness of\nstudents and schools. Computers and Education Open 2022 Dec;3:100100 [doi: 10.1016/j.caeo.2022.100100]\nAbbreviations\nAI: artificial intelligence\nGLM: generative language model\nEdited by K Venkatesh; submitted 13.04.23; peer-reviewed by S Pesälä, J Simmich; comments to author 14.05.23; revised version\nreceived 22.05.23; accepted 24.05.23; published 06.06.23\nPlease cite as:\nKarabacak M, Ozkara BB, Margetis K, Wintermark M, Bisdas S\nThe Advent of Generative Language Models in Medical Education\nJMIR Med Educ 2023;9:e48163\nURL: https://mededu.jmir.org/2023/1/e48163\ndoi: 10.2196/48163\nPMID: 37279048\nJMIR Med Educ 2023 | vol. 9 | e48163 | p. 6https://mededu.jmir.org/2023/1/e48163\n(page number not for citation purposes)\nKarabacak et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\n©Mert Karabacak, Burak Berksu Ozkara, Konstantinos Margetis, Max Wintermark, Sotirios Bisdas. Originally published in\nJMIR Medical Education (https://mededu.jmir.org), 06.06.2023. This is an open-access article distributed under the terms of the\nCreative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution,\nand reproduction in any medium, provided the original work, first published in JMIR Medical Education, is properly cited. The\ncomplete bibliographic information, a link to the original publication on https://mededu.jmir.org/, as well as this copyright and\nlicense information must be included.\nJMIR Med Educ 2023 | vol. 9 | e48163 | p. 7https://mededu.jmir.org/2023/1/e48163\n(page number not for citation purposes)\nKarabacak et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX",
  "topic": "Credibility",
  "concepts": [
    {
      "name": "Credibility",
      "score": 0.6971943378448486
    },
    {
      "name": "Relevance (law)",
      "score": 0.47338786721229553
    },
    {
      "name": "Computer science",
      "score": 0.4639527201652527
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.46207454800605774
    },
    {
      "name": "Knowledge management",
      "score": 0.39296841621398926
    },
    {
      "name": "Medical education",
      "score": 0.33647245168685913
    },
    {
      "name": "Medicine",
      "score": 0.18186619877815247
    },
    {
      "name": "Political science",
      "score": 0.1173170804977417
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1320796813",
      "name": "Mount Sinai Health System",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1343551460",
      "name": "The University of Texas MD Anderson Cancer Center",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210151618",
      "name": "National Hospital for Neurology and Neurosurgery",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I45129253",
      "name": "University College London",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I1340918713",
      "name": "University College London Hospitals NHS Foundation Trust",
      "country": "GB"
    }
  ]
}