{
  "title": "How Our Cognition Shapes and Is Shaped by Technology: A Common Framework for Understanding Human Tool-Use Interactions in the Past, Present, and Future",
  "url": "https://openalex.org/W2792378106",
  "year": 2018,
  "authors": [
    {
      "id": null,
      "name": "Osiurak, FranÃ§ois",
      "affiliations": [
        "Institut Universitaire de France",
        "Laboratoire d’Étude des Mécanismes Cognitifs",
        "Université Claude Bernard Lyon 1"
      ]
    },
    {
      "id": "https://openalex.org/A2228369976",
      "name": "Navarro, Jordan",
      "affiliations": [
        "Université Claude Bernard Lyon 1",
        "Laboratoire d’Étude des Mécanismes Cognitifs",
        "Institut Universitaire de France"
      ]
    },
    {
      "id": "https://openalex.org/A4302210107",
      "name": "Reynaud, Emanuelle",
      "affiliations": [
        "Université Claude Bernard Lyon 1",
        "Laboratoire d’Étude des Mécanismes Cognitifs"
      ]
    },
    {
      "id": "https://openalex.org/A4365924132",
      "name": "Osiurak, François",
      "affiliations": [
        "Laboratoire d’Étude des Mécanismes Cognitifs",
        "Institut Universitaire de France"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1970243396",
    "https://openalex.org/W1663973292",
    "https://openalex.org/W121372862",
    "https://openalex.org/W2055926372",
    "https://openalex.org/W2509948470",
    "https://openalex.org/W2112031365",
    "https://openalex.org/W1791587663",
    "https://openalex.org/W2354069731",
    "https://openalex.org/W1993477803",
    "https://openalex.org/W2126672489",
    "https://openalex.org/W2767056600",
    "https://openalex.org/W1976284614",
    "https://openalex.org/W1983670828",
    "https://openalex.org/W2745952964",
    "https://openalex.org/W2091838012",
    "https://openalex.org/W2169866873",
    "https://openalex.org/W1978271112",
    "https://openalex.org/W2050661045",
    "https://openalex.org/W2141373701",
    "https://openalex.org/W2293879964",
    "https://openalex.org/W2060196343",
    "https://openalex.org/W2331739042",
    "https://openalex.org/W2272870795",
    "https://openalex.org/W2149989625",
    "https://openalex.org/W2027566210",
    "https://openalex.org/W2766628990",
    "https://openalex.org/W2472385446",
    "https://openalex.org/W2789296060",
    "https://openalex.org/W1978290313",
    "https://openalex.org/W2069826682",
    "https://openalex.org/W2599954350",
    "https://openalex.org/W1905218964",
    "https://openalex.org/W2075606751",
    "https://openalex.org/W2063052894",
    "https://openalex.org/W2118450042",
    "https://openalex.org/W2293885148",
    "https://openalex.org/W2010014160",
    "https://openalex.org/W1964596829",
    "https://openalex.org/W2003621157",
    "https://openalex.org/W2767448010",
    "https://openalex.org/W2106006415",
    "https://openalex.org/W2097084185",
    "https://openalex.org/W1811781384",
    "https://openalex.org/W1271805369",
    "https://openalex.org/W2166185625"
  ],
  "abstract": "Over the evolution, humans have constantly developed and improved their technologies. This evolution began with the use of physical tools, those tools that increase our sensorimotor abilities (e.g., first stone tools, modern knives, hammers, pencils). Although we still use some of these tools, we also employ in daily life more sophisticated tools for which we do not systematically understand the underlying physical principles (e.g., computers, cars). Current research is also turned toward the development of brain-computer interfaces directly linking our brain activity to machines (i.e., symbiotic tools). The ultimate goal of research on this topic is to identify the key cognitive processes involved in these different modes of interaction. As a primary step to fulfill this goal, we offer a first attempt at a common framework, based on the idea that humans shape technologies, which also shape us in return. The framework proposed is organized into three levels, describing how we interact when using physical (Past), sophisticated (Present), and symbiotic (Future) technologies. Here we emphasize the role played by technical reasoning and practical reasoning, two key cognitive processes that could nevertheless be progressively suppressed by the proficient use of sophisticated and symbiotic tools. We hope that this framework will provide a common ground for researchers interested in the cognitive basis of human tool-use interactions, from paleoanthropology to neuroergonomics.",
  "full_text": "fpsyg-09-00293 March 5, 2018 Time: 19:19 # 1\nMINI REVIEW\npublished: 07 March 2018\ndoi: 10.3389/fpsyg.2018.00293\nEdited by:\nAmon Rapp,\nUniversità degli Studi di Torino, Italy\nReviewed by:\nManuel Bedia,\nUniversity of Zaragoza, Spain\nIon Juvina,\nWright State University, United States\n*Correspondence:\nFrançois Osiurak\nfrancois.osiurak@univ-lyon2.fr\n†These authors have contributed\nequally to this work.\nSpecialty section:\nThis article was submitted to\nCognitive Science,\na section of the journal\nFrontiers in Psychology\nReceived: 15 November 2017\nAccepted: 21 February 2018\nPublished: 07 March 2018\nCitation:\nOsiurak F , Navarro J and Reynaud E\n(2018) How Our Cognition Shapes\nand Is Shaped by Technology:\nA Common Framework\nfor Understanding Human Tool-Use\nInteractions in the Past, Present,\nand Future. Front. Psychol. 9:293.\ndoi: 10.3389/fpsyg.2018.00293\nHow Our Cognition Shapes and Is\nShaped by Technology: A Common\nFramework for Understanding\nHuman Tool-Use Interactions in the\nPast, Present, and Future\nFrançois Osiurak1,2*†, Jordan Navarro1,2† and Emanuelle Reynaud1†\n1 Laboratoire d’Etude des Mécanismes Cognitifs (EA 3082), Institut de Psychologie, Université de Lyon, Lyon, France,\n2 Institut Universitaire de France, Paris, France\nOver the evolution, humans have constantly developed and improved their technologies.\nThis evolution began with the use of physical tools, those tools that increase our\nsensorimotor abilities (e.g., ﬁrst stone tools, modern knives, hammers, pencils). Although\nwe still use some of these tools, we also employ in daily life more sophisticated tools\nfor which we do not systematically understand the underlying physical principles (e.g.,\ncomputers, cars). Current research is also turned toward the development of brain–\ncomputer interfaces directly linking our brain activity to machines (i.e., symbiotic tools).\nThe ultimate goal of research on this topic is to identify the key cognitive processes\ninvolved in these different modes of interaction. As a primary step to fulﬁll this goal, we\noffer a ﬁrst attempt at a common framework, based on the idea that humans shape\ntechnologies, which also shape us in return. The framework proposed is organized\ninto three levels, describing how we interact when using physical (Past), sophisticated\n(Present), and symbiotic (Future) technologies. Here we emphasize the role played\nby technical reasoning and practical reasoning, two key cognitive processes that\ncould nevertheless be progressively suppressed by the proﬁcient use of sophisticated\nand symbiotic tools. We hope that this framework will provide a common ground\nfor researchers interested in the cognitive basis of human tool-use interactions, from\npaleoanthropology to neuroergonomics.\nKeywords: tool use, technology, brain–computer interface, automation, technical reasoning\nINTRODUCTION\nHave you already wondered how researchers living 70 years ago could contact an editor to know\nwhether their manuscript was still under review or not after 5 months? They certainly had to\nwrite a mail and wait for a response, perhaps 5 weeks after. Nowadays, we send emails and expect\nan answer by 2 or 3 days. Perhaps in 1000 years, researchers will just have to think of this and\nthey will receive the answer instantly. These diﬀerent modes of interaction illustrate the constant\nmodiﬁcation of our technologies over time, a phenomenon that characterizes our species (Boyd\nand Richerson, 1985). The ultimate goal of research on this topic is to identify the key cognitive\nprocesses involved in these diﬀerent modes of interaction. As a primary step to fulﬁll this goal,\nFrontiers in Psychology | www.frontiersin.org 1 March 2018 | Volume 9 | Article 293\nfpsyg-09-00293 March 5, 2018 Time: 19:19 # 2\nOsiurak et al. Cognition and Technology: Past, Present, Future\nwe oﬀer a ﬁrst attempt at a common framework, based on the idea\nthat humans shape technologies, which also shape us in return.\nThe framework proposed is organized into three levels,\ndescribing how we interact when using physical (Past),\nsophisticated (Present), and symbiotic (Future) technologies 1.\nThe temporal gradient introduced here implies that, at the species\nlevel, physical technologies are anterior to sophisticated ones,\nwhich are anterior to symbiotic ones, so that the theoretical\nproportion of use for each kind of technology is supposed to\nevolve over time (Figure 1). The distinction made between these\ndiﬀerent kinds of technology is also theorized here at a cognitive\nlevel, based on the idea that our modiﬁcations on the world\nare ﬁrst guided by an intention, needing then the selection of a\npractical solution (i.e., the practical level), and ﬁnally the selection\nand application of a technical action (i.e., the technical level;\nFigure 2). The thesis defended here is that the technical evolution\nfrom physical to sophisticated and symbiotic technologies tends\nto progressively suppress the technical and practical levels.\nThree caveats need to be made at this point. First, there\nis no overview in the literature about the cognitive processes\ninvolved in the diﬀerent interactions we have with tools and\ntechnologies. The major reason for this lack is that this requires a\ncritical, epistemological development as to the way of organizing\nthe ﬁeld so that researchers from diﬀerent topics (e.g., stone\ntools, brain–computer interaction) could communicate within\na single and comprehensive framework. The goal of this paper\nis to ﬁll this gap, by attempting to provide a structured way\nof organizing the literature based on the evolution of our\ntechnology over time. This attempt could be a good starting\npoint for developing such a framework in the future. Second,\nmany cognitive processes are involved in our interactions with\ntools and technologies. Here we could not address all of them\nand preferred to concentrate our attention on two key cognitive\nprocesses, namely, technical reasoning and practical reasoning.\nOf course, further theoretical development would be needed\nto complete our analysis. Third, as with other humans, our\ninteractions with tools and technologies can take diﬀerent forms\naccording to the role taken by technology (e.g., competition,\ncollaboration). These diﬀerent levels of interaction that most\ndirectly deal with the “social” aspect will be addressed partly\nin this paper, particularly in the third section. Nevertheless, we\nacknowledge that a more comprehensive review based on this\nlevel of analysis could complete the present review, discussing\nthe potential parallel between our interactions with social (e.g.,\nhumans) and non-social (e.g., technologies) agents.\nTHE PAST: PHYSICAL TOOLS\nPhysical tools can be deﬁned as those tools that increase our\nsensorimotor abilities (Virgo et al., 2017). Although we still use\na wide variety of physical tools (e.g., hammer, knife), it can be\nconsidered that they correspond to the ﬁrst tools humans have\nmade and used in pre-history. At a cognitive level, the use of\n1The terms tool and technology will be hereafter used interchangeably and in\na broad sense to refer to any environmental object useful to increase the user’s\nsensorimotor or cognitive capacities (Osiurak et al., 2010).\nall physical tools shares the need for the user to understand\nphysical principles (e.g., percussion, cutting). The characteristics\nof early stone tools indicate that makers showed evidence of a\nbasic understanding of stone fracture mechanics (Hovers, 2012).\nThe use of physical tools by modern humans also requires this\nform of physical understanding (Bril et al., 2010).\nSome patients can meet diﬃculties to use everyday tools after\nleft brain damage (Osiurak and Rossetti, 2017). The diﬃculties\nconcern not only the selection of the appropriate tool, but\nalso the mechanical action performed (e.g., pounding a nail\nby rubbing it on the nail instead of hammering with it). The\nsame diﬃculties can be observed when they are asked to solve\nmechanical problems by using novel tools (Goldenberg and\nHagmann, 1998; Jarry et al., 2013). Taken together, these ﬁndings\nindicate that the use of physical tools is grounded on the ability\nto reason about physical properties of tools and objects based on\nmechanical knowledge. This is what we call “technical reasoning”\n(Osiurak et al., 2010; Osiurak and Badets, 2016). This reasoning\nis critical to form a mental representation of the mechanical\naction intended. It is also the key process allowing us to generate\ninstances of “technical misusage” (Figure 2) also called “function\ncreep, ” corresponding to the use of a tool in an unusual way\n(Osiurak et al., 2009). Such instances can be observed relatively\nearly in humans. A 2-years-old child can, for instance, use a tea\nspoon to hammer a piece of cheese in his mashed carrots, calling\nthe spoon “a hammer.” This child knows that the spoon is not a\nhammer but ﬁnds funny to hammer the cheese and handy to use\nthe spoon to do so at that time.\nTechnical reasoning could be unique to humans (e.g., Penn\net al., 2008), explaining a certain number of our speciﬁcities such\nas the use of one tool to create another (e.g., stone knapping)\nor the use of complex tools that transform our motor energy\ninto diﬀerent mechanical energies (Osiurak, 2017). Convergent\nevidence from neuropsychology and cognitive neuroscience\nindicates that technical reasoning could engage the area PF within\nthe left inferior parietal cortex (Goldenberg and Spatt, 2009;\nReynaud et al., 2016), which does not in macaques and other\nnon-human primates (Orban and Caruana, 2014).\nBefore going on to the next section, one important aspect\nneeds to be considered. Technical reasoning is critical for the\nmaking of any technology (physical, sophisticated, symbiotic).\nFor physical technologies, there is no real distance between the\nmaker and the user in that the user needs to mentally make\nthe technology before the use (Osiurak and Heinke, 2017). If\nyou intend to cut a tomato, you are free to select a wide variety\nof tools. Nevertheless, your selection is based on the physical\nproperties of the tomato, leading you to choose a tool with\nthe appropriate physical properties relatively to the tomato. In\na way, you ﬁrst make your tool mentally (e.g., thinking about\nsomething sharp and solid enough) and then you select it really\naccordingly. Things are diﬀerent for sophisticated technologies,\nwhich mainly correspond to interface-based technologies (e.g.,\ncomputers). A key characteristic of these technologies is that the\nmaker/designer has facilitated the interaction, so that the user\nhas no longer to understand the physical principles underlying\nthe use. In this case, the user does not make mentally the tool\nbefore the use but learn the arbitrary relationship between the\nFrontiers in Psychology | www.frontiersin.org 2 March 2018 | Volume 9 | Article 293\nfpsyg-09-00293 March 5, 2018 Time: 19:19 # 3\nOsiurak et al. Cognition and Technology: Past, Present, Future\nFIGURE 1 |Theoretical proportion of physical, sophisticated, and symbiotic technologies used over time. The core idea is that, at the species level, physical\ntechnologies are anterior to sophisticated technologies, which are also anterior to symbiotic technologies. Over time, physical technologies (e.g., stone tools, knifes,\nhammers) tend to decrease and could be completely absent in a far future. Sophisticated technologies have appeared later and are now a great part of the\ntechnologies we use (i.e., interface-based technologies). Again, it can be hypothesized that this kind of technologies will be less and less used. Finally, symbiotic\ntechnologies are developing now even if they remain rarely used (e.g., brain–computer interfaces). In a far future, it can be thought that humans will profusely and\nuniquely use these technologies. The three colored panels correspond to the three time periods (Past, Present, and Future). The color associated to each kind of\ntechnologies corresponds to the color of the period where a given technology is dominant (Past: the reign of physical technologies; Present: the reign of\nsophisticated technologies; Future: the reign of symbiotic technologies).\nmotor response and its eﬀect. The corollary is that sophisticated\ntechnologies may not require, at the technical level ( Figure 2),\ntechnical reasoning skills, but more basic cognitive processes\nsuch as associative learning and procedural memory (Osiurak\nand Heinke, 2017). At least two lines of evidence support\nthis view. First, interface-based technologies (e.g., touchscreens)\ncan be easily used by infants, despite moderate skills to use\nphysical tools (Beck et al., 2011). Likewise, many non-human\nanimals including tool users (e.g., baboons) can use touchscreens\nvery quickly in the absence of any signs of physical tool use\n(Claidière et al., 2014). Second, patients with damage to the left\ninferior parietal cortex are impaired to use physical tools, but\nnot interface-based technologies. The opposite pattern can be\nobserved in patients with deﬁcits of procedural memory (e.g.,\nParkinson’s disease), indicating a double dissociation between\nthe ability to use physical versus sophisticated technologies (see\nOsiurak, 2014, 2017).\nTHE PRESENT: SOPHISTICATED TOOLS\nStopping the alarm clock after waking up, using tramways,\ndriving a car, interacting with a smartphone, taking the elevator,\nand so on. With the sophistication of tools and the advent of\ncognitive tools (e.g., computer spreadsheet) the distance between\nthe making and the use has dramatically increased, so we use\nmany tools we could never build in a lifetime. This does not\nchange the way we interact with tools: the purpose of a tool is not\nin the tool itself, but in the user’s intentions. A computer screen\ncan be used to stick notes, as a visual barrier, as a mirror, and\nso forth (i.e., technical misusage). This fact remains whatever the\nnature of the tool considered, from a very simple stone tool to\nthe most advanced smartphone (e.g., reﬂecting sunlight). There\nis a limit, however, in the lack of freedom oﬀered by sophisticated\ntools to its users at the technical level, because the use of these\ntools for their usual function needs to master pre-established\nprocedures (see above).\nSome sophisticated tools, often referred as automation, do\nnot tend to extend humans but rather to replace them (Young\net al., 2007). Those tools that replaces us tend to be poorly\naccepted by individuals (Navarro et al., 2011). The design of these\ntools also questions about the human role in our societies, and\nabout what should be automated or not (Hancock, 2014). For\ninstance, a highly automated task completion is often considered\nas dehumanizing (Coeckelbergh, 2015). People also select an\nautomatic completion of the task only if much more eﬀective than\na manual completion (Osiurak et al., 2013; Navarro and Osiurak,\n2015, 2017), as if humans tend to avoid the loss of freedom\nassociated to sophisticated tools (Figure 2).\nTool use is not neutral for users. Of course, tools are\nchanging the way humans do things, but tools also change\nhumans themselves (Hancock, 2007). All the data available on\nthe Internet provide considerable beneﬁts, yielding information\neasily. But, it also alters the way people memorize information\nFrontiers in Psychology | www.frontiersin.org 3 March 2018 | Volume 9 | Article 293\nfpsyg-09-00293 March 5, 2018 Time: 19:19 # 4\nOsiurak et al. Cognition and Technology: Past, Present, Future\nFIGURE 2 |Neurocognitive processes involved in physical, sophisticated, and symbiotic technologies. The core idea is that humans develop technologies in order to\nsatisfy intentions (I). To do so, they have to select appropriate practical solution (S), leading then to the selection and application of technical actions (A). In the case\nof physical technologies, the intention can be to communicate information (I1). This can be achieved either by projecting information to a wide surface (S1) or writing\na document (S2). There is no bijection between the “domain” of intentions and the “domain” of practical solutions in that a given intention can be achieved through\ntwo different practical solutions and, inversely, the same practical solutions can be useful to achieve a given intention. At this practical level, humans have to imagine\nthe most appropriate practical solution. Then, once a given practical solution selected (e.g., S1), it has to been operationalized by selecting and applying a technical\naction (e.g., A1). For instance, if the practical solution is to project information to a wide surface, the technical solution can be tracing by using a pencil on a wall.\nAgain, there is no bijection between the “domain” of practical solutions and the “domain” of technical actions. For physical technologies, humans have to do\ntechnical reasoning to select and apply the appropriate technical actions. However, for sophisticated technologies, this technical level is suppressed, people having\njust to learn the procedure thought by the maker/designer to interact with the technology (e.g., pressing a button to activate a given function). Interestingly, for both\nphysical and sophisticated technologies, people are still free to reason at a practical level in order to select which practical solutions to choose. For symbiotic\ntechnologies, this practical level is suppressed, with the idea that the intention is directly implemented, without having to decide between different practical solutions\nand, as a result, technical actions. Bold and thin lines represent, respectively, usages and misusages, that is, the usual or unusual path a user can follow to satisfy an\nintention. Sophisticated technologies tend to suppress misusages at a technical level, because people have no other possibilities than pressing buttons, for instance,\nto power PowerPoint. However, they can still divert the pre-established use of PowerPoint (i.e., communication device) in order to fulﬁll another intention (i.e.,\nexternal memory). For symbiotic tools, both technical reasoning and practical reasoning from the user could be suppressed, because the user intervenes neither at\nthe technical level, nor at the practical level.\nitself in favor of a recall of where to access it Sparrow et al.\n(2011). Is it for the best or for the worst? This is not a new\nquestion, at least in the cognitive ergonomics ﬁeld. Parasuraman\nand Riley (1997) stated that automation “ changes the nature\nof the work that humans do, often in ways unintended and\nunanticipated by the designers of automation” (p. 231). Use is\ndescribed here as the human proneness to activate automation\nwhen available. Besides a correct use of automation, misuse (i.e.,\noverreliance on automation) and disuse (i.e., underutilization of\nautomation) have been reported. Thus, the human is reasoning\nabout its interactions with sophisticated tools to adjust his/her\nbehavior according to the context and his/her own objectives\n(Leplat, 1990). For instance, automation use was found to be\nrelated to a balance between trust in automation and user\nself-conﬁdence (Lee and Moray, 1994). These data can be\ninterpreted as the human nature to keep reasoning based on\ninternal and external assessments (i.e., practical reasoning). This\nis what we refer to as practical misusage, that is, the ability to\ndivert the pre-established use of a tool (e.g., PowerPoint as a\ncommunication device) to fulﬁll another intention (e.g., storing\ninformation; Figure 2 ). A research issue to investigate is the\nneural bases that support this “practical reasoning.” Are there\n(a) partly the same as those required by technical reasoning?\n(b) Rather common to those associated to logical reasoning? Or\n(c) implying areas known to be engaged in interactions with other\nhumans that would be recycled to reason on human–machine\ninteractions?\nAnother aspect speciﬁc to sophisticated tools is that the\nperception or inference of tool functions could be sometimes\ncomplicated because of the distance between the maker and the\nuser, favoring the occurrence of inappropriate and ineﬀective\nuse. To counter this phenomenon, a human-centered design has\nbeen proposed (Billings, 1991). This design process widely used\nin a variety of domains (François et al., 2016) is based on the\nrationale that tool designers should take into account as much\nas possible users’ logic and characteristics during the tool design\nprocess. In a way, the consideration of the user in the design\nprocess aims at reducing the distance between the maker and\nthe user. Nevertheless, if we assume that humans are keen on\npractical reasoning, this quest is necessary deceptive as there is no\nuniversal reasoning process and, thus, neither universal human–\ntool interaction, nor natural interaction with sophisticated tools.\nInversely, the human–tool interaction is rather artiﬁcial because\nbased on an artiﬁce (i.e., a sophisticated tool) for which the user\nignores, at least part of, the design philosophy and the working\nprinciple.\nFrontiers in Psychology | www.frontiersin.org 4 March 2018 | Volume 9 | Article 293\nfpsyg-09-00293 March 5, 2018 Time: 19:19 # 5\nOsiurak et al. Cognition and Technology: Past, Present, Future\nTHE FUTURE: SYMBIOTIC TOOLS\nKid #1: “You mean you have to use your hands?”\nKid #2: “That’s like a baby’s toy!”\n— Back to the Future Part II\nPredicting the future of our technology could be a fortune\nteller’s job, had there not been a few mesmerizing anticipation\nmovies and books, featuring great inventions feeding from\ncontemporary science, the society’s aspirations, and feeding back\ncompanies striving for developing them: inventions such as the\nBlade Runner ﬂying autonomous cars or the gesture-based user\ninterface from Minority Report preﬁgure the tools of the future.\nSome may never be created, some may be part of our everyday\nlives in 30 years, as the video calls from the ﬁrst Blade Runner\nmovie are part of our modern lives. This sneak peek into the\nfuture shows that all these tools have one thing in common:\nthey seem to be operated seamlessly and conveniently by the\nuser, reducing or abolishing four main constraints: mechanics,\nspace, time, and eﬀort (Osiurak, 2014). Although the depicted\nvision of our future world is always more technology-oriented,\nmachines never overwhelm the user, who is becoming a part of a\nhuman–machine system, as the “commander-in-chief.”\nMost of the promised futuristic and fantastic tools are\noperated by thought, voice, or gestures. Because human–machine\ninteraction through devices such as a mouse or keyboard is slow,\nineﬃcient, and sometimes not even feasible, the possibility of\ncommunicating with machines directly from our thoughts has\nemerged (Schalk, 2008). The brain–computer interface (BCI)\n(Wolpaw et al., 2002) ﬁeld has then rapidly gained interest,\nﬁrst because it could be used in motor rehabilitation programs\n(Chaudhary et al., 2016), as the aim of BCI is to translate\nbrain activity (“thoughts”) into commands understandable by a\nmachine. For achieving this, brain activity is captured by the\nmeans of sensors, pre-treated, and assigned to a corresponding\naction to be performed by the artiﬁcial system through an\nadaptive algorithm that learns to discriminate classes in the brain\nsignals recorded (Mitchell, 1997; Bishop, 2006). A successful BCI\ninteraction very often includes a learning phase attuning the\ntechnology to the speciﬁcity of the user’s cognitive system. The\nstructural inter-individual heterogeneity of the brains themselves,\nthe functional diﬀerences, even the intra-individual diﬀerences\nfrom a time to another, will push the need for the learning\nalgorithms to be highly adapted to a particular individual, if not\nto his particular mood.\nFollowing this, the tantalizing promises of body-and-mind-\noperated tools, responding eﬃciently to the user’s intentions,\ncome with the need of individualizing the technology operating\nthe machine. Brain–machine communication needs to be truly\nadapted to each speciﬁc individual for brain patterns to be\nsuccessfully converted into thoughts. In this ultra-individualized\ntechnology, the individual and the tool will then form a\nsystem in a tight relationship, depending on each other to\n“perform” appropriately. The tool is then embodied within\nthe user, and the system they form could be designated as\na “symbiotic tool” (Licklider, 1960; Brangier and Hammes-\nAdelé, 2011). Within this tight interaction, the human has the\nintention, then the tool operates the technical and practical\nchoices (i.e., suppression of the technical and practical levels;\nFigure 2).\nOn the journey to a Future in which Technology and Man\nform a symbiotic system, a few issues remain to be addressed.\nThe ﬁrst one is the acceptation issue (Davis, 1989). Are we\ndesigned to pair with synthetic devices? Can we and shall we\naccept to be part of a man–machine system? Tools of the Present\nneed the user to accept them. We postulate that the future\nsymbiotic tools will need the user to incorporate them. The\nsecond point is to explore the limits of the human cognitive\nsystem in terms of BCI performance. To function as smoothly\nand perfectly as in the Avatar movie for example, many technical\nissues have to be solved from the maker: the sensors need to\nbe implanted, miniaturized; the algorithms need to be fast and\nreliable, etc. (Lebedev and Nicolelis, 2006). If the machine-related\nissues will without any doubt be resolved at some point, only\nfew researches have tackled the man-related issue. Are the neural\nsignals encoding our thoughts speciﬁc and reliable enough to be\ntranslated into a crystal-clear command? For how long can we\nmaintain a neural state corresponding to a sustained command?\nAre we (all) designed to be good BCI-commanders, and always?\nStudies on BCI illiteracy show that 20% of the population cannot\nproduce the brain patterns required for a BCI system to function\nproperly (Vidaurre and Blankertz, 2010). Are their brains faulty,\nor the techniques immature?\nThese questions relate to the fundamental enigma of the\ncognitive system: how can our complex thoughts, dreams,\nfeelings, creativity, instinct, etc. be encoded into less than 10 15\nsignals? How can an inﬁnite and unexplored mental world be\ncreated by a ﬁnite and deﬁned material support? The birth\nof neuroergonomics (Hancock and Szalma, 2003; Parasuraman,\n2003) will certainly help to start answering these issues, and to\ndevelop eﬃcient channels of communication with technology.\nCONCLUSION\nIn this review, we depict the diﬀerent cognitive modes of\ninteraction we have with physical, sophisticated and symbiotic\ntools. The key idea is that there could be a trend to progressively\nsuppress our involvement at technical and practical levels\n(Figure 2). Interestingly, when considering symbiotic tools, users\nmight be, a day, restricted to produce only intentions and will\ndelegate all remaining eﬀorts and choices to machines. The key\nissue is whether this restriction has to be viewed as a source of\nfreedom or not? After all, should this scenario be true, what will\nhumans do to occupy their available brain time? We are also\naware that this review is biased by our ability to envision future\ntools, and how technology will evolve in a far future. Perhaps our\nconception of symbiotic tools is limited, considering only tools\nthat transform our conscious intentions into responses. However,\nperhaps we will be able to develop technologies that will produce\nresponses based on unconscious thoughts, thereby anticipating\nour needs even if we are unable to correctly generate them – or\neven before we generate them (e.g., sending an email to an editor\nbefore we intend to do so). In this respect, a critical question for\nFrontiers in Psychology | www.frontiersin.org 5 March 2018 | Volume 9 | Article 293\nfpsyg-09-00293 March 5, 2018 Time: 19:19 # 6\nOsiurak et al. Cognition and Technology: Past, Present, Future\nfuture research is to determine whether our technological cultural\nevolution will reach an asymptote as suggested here, or whether\nother forms of technological interactions will emerge in a far\nfuture, again shaping our cognition in return.\nAUTHOR CONTRIBUTIONS\nAll authors listed have made a substantial, direct and intellectual\ncontribution to the work, and approved it for publication.\nFUNDING\nThis work was supported by grants from ANR (Agence Nationale\npour la Recherche; Project “Cognition et économie liée à\nl’outil/Cognition and tool-use economy” ECOTOOL; ANR-14-\nCE30-0015-01), and was performed within the framework of\nthe LABEX CORTEX (ANR-11-LABX-0042) of Université de\nLyon, within the program “Investissements d’Avenir” (ANR-11-\nIDEX-0007) operated by the French National Research Agency\n(ANR).\nREFERENCES\nBeck, S. R., Apperly, I. A., Chappell, J., Guthrie, C., and Cutting, N. (2011). Making\ntools isn’t child’s play.Cognition 119, 301–306. doi: 10.1016/j.cognition.2011.01.\n003\nBillings, C. E. (1991). Human-Centered Aircraft Automation: A Concept and\nGuideline. NASA Technology Memorandum No. 103885, Moﬀett Field, CA:\nNASA-Ames Research Center.\nBishop, C. M. (2006). Pattern recognition and machine learning. Pattern Recogn.\n4:738. doi: 10.1117/1.2819119\nBoyd, R., and Richerson, P. (1985). Culture and the Evolutionary Process. Chicago,\nIL: University of Chicago Press.\nBrangier, É., and Hammes-Adelé, S. (2011). “Beyond the technology acceptance\nmodel: elements to validate the human-technology symbiosis model, ” in\nErgonomics and Health Aspects, HCII 2011, LNCS 6779, ed. M. M. Robertson\n(Berlin: Springer-Verlag), 13–21. doi: 10.1007/978-3-642-21716-6_2\nBril, B., Rein, R., Nonaka, T., Wenban-Smith, F., and Dietrich, G. (2010). The\nrole of expertise in tool use: skill diﬀerences in functional action adaptations\nto task constraints. J. Exp. Psychol. Hum. Percept. Perform. 36, 825–839.\ndoi: 10.1037/a0018171\nChaudhary, U., Birbaumer, N., and Ramos-murguialday, A. (2016). Brain –\ncomputer interfaces for communication and rehabilitation. Nat. Rev. 12,\n513–525. doi: 10.1038/nrneurol.2016.113\nClaidière, N., Smith, K., Kirby, S., and Fagot, J. (2014). Cultural evolution of\nsystematically structured behaviour in a non-human primate. Proc. R. Soc.\nLond. B281:20141541. doi: 10.1098/rspb.2014.1541\nCoeckelbergh, M. (2015). The tragedy of the master: automation, vulnerability,\nand distance. Ethics Inf. Technol. 17, 219–229. doi: 10.1098/rspb.2014.\n1541\nDavis, F. (1989). Perceived usefulness, perceived ease of use, and user\nacceptance of information technology. MIS Q. 13, 319–340. doi: 10.2307/24\n9008\nFrançois, M., Osiurak, F., Fort, A., Crave, P., and Navarro, J. (2016). Automotive\nHMI design and participatory user involvement: review and perspectives.\nErgonomics 139, 1–12. doi: 10.1080/00140139.2016.1188218\nGoldenberg, G., and Hagmann, S. (1998). Tool use and mechanical problem\nsolving in apraxia. Neuropsychologia 36, 581–589. doi: 10.1016/S0028-3932(97)\n00165-6\nGoldenberg, G., and Spatt, J. (2009). The neural basis of tool use. Brain 132,\n1645–1655. doi: 10.1093/brain/awp080\nHancock, P. A. (2007). What future for human-machine symbiosis?Ergonomia 29,\n17–18. doi: 10.1088/1741-2552/aa9817\nHancock, P. A. (2014). Automation: how much is too much? Ergonomics 57,\n449–454. doi: 10.1080/00140139.2013.816375\nHancock, P. A., and Szalma, J. L. (2003). The future of neuroergonomics. Theor.\nIssues Ergon. Sci.4, 238–249. doi: 10.1080/1463922021000020927\nHovers, E. (2012). “Invention, reinvention, and innovation: the makings of\nOldowan lithic technology, ” in Origins of Human Innovation and Creativity,\ned. S. Elias (Amsterdam: Elsevier), 51–68. doi: 10.1016/B978-0-444-53821-5.\n00005-1\nJarry, C., Osiurak, F., Delafuys, D., Chauviré, V., Etcharry-Bouyx, F., and Le\nGall, D. (2013). Apraxia of tool use: more evidence for the technical reasoning\nhypothesis. Cortex 49, 2322–2333. doi: 10.1016/j.cortex.2013.02.011\nLebedev, M. A., and Nicolelis, M. A. L. (2006). Brain-machine interfaces: past,\npresent and future. Trends Neurosci. 29, 536–546. doi: 10.1016/j.tins.2006.\n07.004\nLee, J. D., and Moray, N. (1994). Trust, self-conﬁdence, and operators’ adaptation\nto automation. Int. J. Hum. Comput. Stud.40, 153–184. doi: 10.1006/ijhc.1994.\n1007\nLeplat, J. (1990). Relations between task and activity: elements for elaborating\na framework for error analysis. Ergonomics 33, 1389–1402. doi: 10.1080/\n00140139008925340\nLicklider, J. C. R. (1960). Man-computer symbiosis. IRE Trans. Hum. Factors\nElectron. HFE1, 4–11. doi: 10.1109/THFE2.1960.4503259\nMitchell, T. M. (1997). Machine learning. Annu. Rev. Comput. Sci. 4:432.\ndoi: 10.1145/242224.242229\nNavarro, J., Mars, F., and Young, M. S. (2011). Lateral control assistance in car\ndriving: classiﬁcation, review and future prospects. IET Intell. Transp. Syst.5,\n207–220. doi: 10.1049/iet-its.2010.0087\nNavarro, J., and Osiurak, F. (2015). When do use automatic tools rather than doing\na task manually? Inﬂuence of automatic tool speed. Am. J. Psychol.128, 77–88.\ndoi: 10.5406/amerjpsyc.128.1.0077\nNavarro, J., and Osiurak, F. (2017). The more intelligent people are, the\nmore they use tools. Psychol. Fr. 62, 85–91. doi: 10.1016/j.psfr.2015.\n11.002\nOrban, G. A., and Caruana, F. (2014). The neural basis of human tool use. Front.\nPsychol. 5:310. doi: 10.3389/fpsyg.2014.00310\nOsiurak, F. (2014). What neuropsychology tells us about human tool use? The four\nconstraints theory (4CT): mechanics, space, time, and eﬀort.Neuropsychol. Rev.\n24, 88–115. doi: 10.1007/s11065-014-9260-y\nOsiurak, F. (2017). Cognitive paleoanthropology and technology: toward a\nparsimonious theory (PATH). Rev. Gen. Psychol. 21, 292–307. doi: 10.1037/\ngpr0000129\nOsiurak, F., and Badets, A. (2016). Tool use and aﬀordance: manipulation-based\nversus reasoning-based approaches. Psychol. Rev. 123, 534–568. doi: 10.1037/\nrev0000027\nOsiurak, F., and Heinke, D. (2017). Looking for intoolligence: a uniﬁed framework\nfor the cognitive study of human tool use and technology. Am. Psychol.\ndoi: 10.1037/amp0000162 [Epub ahead of print].\nOsiurak, F., Jarry, C., Allain, P., Aubin, G., Etcharry-Bouyx, F., Richard, I.,\net al. (2009). Unusual use of objects after unilateral brain damage: the\ntechnical reasoning model. Cortex 45, 769–783. doi: 10.1016/j.cortex.2008.\n06.013\nOsiurak, F., Jarry, C., and Le Gall, D. (2010). Grasping the aﬀordances,\nunderstanding the reasoning: toward a dialectical theory of human tool use.\nPsychol. Rev.117, 517–540. doi: 10.1037/a0019004\nOsiurak, F., and Rossetti, Y. (2017). Deﬁnition: limb apraxia. Cortex 93:228.\ndoi: 10.1016/j.cortex.2017.03.010\nOsiurak, F., Wagner, C., Djerbi, S., and Navarro, J. (2013). To do it or to let\nan automatic tool do it: the priority of control over eﬀort. Exp. Psychol. 60,\n453–468. doi: 10.1027/1618-3169/a000219\nParasuraman, R. (2003). Neuroergonomics: research and practice. Theor. Issues\nErgon. Sci.4, 5–20. doi: 10.1080/14639220210199753\nParasuraman, R., and Riley, V. (1997). Humans and automation: use, misuse,\ndisuse, abuse. Hum. Factors J. Hum. Factors Ergon. Soc. 39, 230–253.\ndoi: 10.1518/001872097778543886\nFrontiers in Psychology | www.frontiersin.org 6 March 2018 | Volume 9 | Article 293\nfpsyg-09-00293 March 5, 2018 Time: 19:19 # 7\nOsiurak et al. Cognition and Technology: Past, Present, Future\nPenn, D. C., Holyoak, K. J., and Povinelli, D. J. (2008). Darwin’s\nmistake: explaining the discontinuity between human and nonhuman\nminds. Behav. Brain Sci. 31, 109–130. doi: 10.1017/S0140525X0800\n3543\nReynaud, E., Lesourd, M., Navarro, J., and Osiurak, F. (2016). On the\nneurocognitive origins of human tool use. a critical review of neuroimaging\ndata. Neurosci. Biobehav. Rev. 64, 421–437. doi: 10.1016/j.neubiorev.2016.\n03.009\nSchalk, G. (2008). Brain–computer symbiosis. J. Neural Eng.5, 1–15. doi: 10.1088/\n1741-2560/5/1/P01\nSparrow, B., Liu, J., and Wegner, D. M. (2011). Google eﬀects on memory: cognitive\nconsequences of having information at our ﬁngertips. Science 333, 776–778.\ndoi: 10.1126/science.1207745\nVidaurre, C., and Blankertz, B. (2010). Towards a cure for BCI illiteracy. Brain\nTopogr. 23, 194–198. doi: 10.1007/s10548-009-0121-6\nVirgo, J., Pillon, J., Navarro, J., Reynaud, E., and Osiurak, F. (2017). Are you\nsure you’re faster when using a cognitive tool? Am. J. Psychol.130, 493–503.\ndoi: 10.5406/amerjpsyc.130.4.0493\nWolpaw, J., Birbaumer, N., McFarland, D., Pfurtscheller, G., and Vaughan, T.\n(2002). Brain-computer interfaces for communication and control. Clin.\nNeurophysiol. 113, 767–791. doi: 10.1016/S1388-2457(02)00057-3\nYoung, M. S., Stanton, N. A., and Harris, D. (2007). Driving automation:\nlearning from aviation about design philosophies. Int. J. Veh. Des.45, 323–338.\ndoi: 10.1504/IJVD.2007.014908\nConﬂict of Interest Statement: The authors declare that the research was\nconducted in the absence of any commercial or ﬁnancial relationships that could\nbe construed as a potential conﬂict of interest.\nCopyright © 2018 Osiurak, Navarro and Reynaud. This is an open-access article\ndistributed under the terms of the Creative Commons Attribution License (CC BY).\nThe use, distribution or reproduction in other forums is permitted, provided the\noriginal author(s) and the copyright owner are credited and that the original\npublication in this journal is cited, in accordance with accepted academic practice.\nNo use, distribution or reproduction is permitted which does not comply with these\nterms.\nFrontiers in Psychology | www.frontiersin.org 7 March 2018 | Volume 9 | Article 293",
  "topic": "Cognition",
  "concepts": [
    {
      "name": "Cognition",
      "score": 0.6280708312988281
    },
    {
      "name": "Common ground",
      "score": 0.612994909286499
    },
    {
      "name": "Key (lock)",
      "score": 0.5773569345474243
    },
    {
      "name": "Cognitive science",
      "score": 0.5668050050735474
    },
    {
      "name": "Computer science",
      "score": 0.5202399492263794
    },
    {
      "name": "Human–computer interaction",
      "score": 0.463497132062912
    },
    {
      "name": "Data science",
      "score": 0.4259827435016632
    },
    {
      "name": "Psychology",
      "score": 0.29840973019599915
    },
    {
      "name": "Communication",
      "score": 0.1267337203025818
    },
    {
      "name": "Neuroscience",
      "score": 0.11149856448173523
    },
    {
      "name": "Computer security",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I185839726",
      "name": "Institut Universitaire de France",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I4210089378",
      "name": "Laboratoire d’Étude des Mécanismes Cognitifs",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I100532134",
      "name": "Université Claude Bernard Lyon 1",
      "country": "FR"
    }
  ]
}