{
  "title": "A framework for anomaly detection using language modeling, and its applications to finance",
  "url": "https://openalex.org/W2969382103",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2743816767",
      "name": "Nourbakhsh Armineh",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Bang, Grace",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2310155953",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2542094447",
    "https://openalex.org/W3098861490",
    "https://openalex.org/W2051405935",
    "https://openalex.org/W2153579005",
    "https://openalex.org/W1515346963",
    "https://openalex.org/W2172852798",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W1662133657",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2614548997",
    "https://openalex.org/W2951176429",
    "https://openalex.org/W2788025656",
    "https://openalex.org/W288405627",
    "https://openalex.org/W2294192051",
    "https://openalex.org/W2473539527",
    "https://openalex.org/W2964125718",
    "https://openalex.org/W2787560479",
    "https://openalex.org/W1594652350",
    "https://openalex.org/W2784121710"
  ],
  "abstract": "In the finance sector, studies focused on anomaly detection are often associated with time-series and transactional data analytics. In this paper, we lay out the opportunities for applying anomaly and deviation detection methods to text corpora and challenges associated with them. We argue that language models that use distributional semantics can play a significant role in advancing these studies in novel directions, with new applications in risk identification, predictive modeling, and trend analysis.",
  "full_text": "A framework for anomaly detection using language modeling,\nand its applications to finance\nArmineh Nourbakhsh\narmineh.nourbakhsh@spglobal.com\nS&P Global Ratings\nNew York, NY\nGrace Bang\ngrace.bang@spglobal.com\nS&P Global Ratings\nNew York, NY\nABSTRACT\nIn the finance sector, studies focused on anomaly detection are\noften associated with time-series and transactional data analytics.\nIn this paper, we lay out the opportunities for applying anomaly\nand deviation detection methods to text corpora and challenges\nassociated with them. We argue that language models that use\ndistributional semantics can play a significant role in advancing\nthese studies in novel directions, with new applications in risk\nidentification, predictive modeling, and trend analysis.\nKEYWORDS\nanomaly detection, deviation analysis, outlier detection, neural\nnetworks, language modeling, natural language processing, finance\n1 INTRODUCTION\nThe detection of anomalous trends in the financial domain has\nfocused largely on fraud detection [ 23], risk modeling [ 1], and\npredictive analysis [7]. The data used in the majority of such studies\nis of time-series, transactional, graph or generally quantitative\nor structured nature. This belies the critical importance of semi-\nstructured or unstructured text corpora that practitioners in the\nfinance domain derive insights from—corpora such as financial\nreports, press releases, earnings call transcripts, credit agreements,\nnews articles, customer interaction logs, and social data.\nPrevious research in anomaly detection from text has evolved\nlargely independently from financial applications. Unsupervised\nclustering methods have been applied to documents in order to\nidentify outliers and emerging topics [2]. Deviation analysis has\nbeen applied to text in order to identify errors in spelling [ 16]\nand tagging of documents [4]. Recent popularity of distributional\nsemantics [18] has led to further advances in semantic deviation\nanalysis [20]. However, current research remains largely divorced\nfrom specific applications within the domain of finance.\nIn the following sections, we enumerate major applications of\nanomaly detection from text in the financial domain, and contex-\ntualize them within current research topics in Natural Language\nProcessing.\n2 FIVE VIEWS ON ANOMALY\nAnomaly detection is a strategy that is often employed in contexts\nwhere a deviation from a certain norm is sought to be captured,\nespecially when extreme class imbalance impedes the use of a\nsupervised approach. The implementation of such methods allows\nfor the unveiling of previously hidden or obstructed insights.\nIn this section, we lay out five perspectives on how textual anom-\naly detection can be applied in the context of finance, and how each\napplication opens up opportunities for NLP researchers to apply\ncurrent research to the financial domain.\n2.1 Anomaly as error\nPrevious studies have used anomaly detection to identify and cor-\nrect errors in text [ 4, 16]. These are often unintentional errors\nthat occur as a result of some form of data transfer, e.g. from au-\ndio to text, from image to text, or from one language to another.\nSuch studies have direct applicability to the error-prone process of\nearnings call or customer call transcription, where audio quality,\naccents, and domain-specific terms can lead to errors. Consider a\nscenario where the CEO of a company states in an audio confer-\nence, ‘Now investments will be made in Asia. ’ However, the system\ninstead transcribes, ‘No investments will be made in Asia. ’ There is\na meaningful difference in the implication of the two statements\nthat could greatly influence the analysis and future direction of\nthe company. Additionally, with regards to the second scenario,\nit is highly unlikely that the CEO would make such a strong and\nnegative statement in a public setting thus supporting the use of\nanomaly detection for error correction.\nOptical-character-recognition from images is another error-prone\nprocess with large applicability to finance. Many financial reports\nand presentations are circulated as image documents that need to\nundergo OCR in order to be machine-readable. OCR might also\nbe applicable to satellite imagery and other forms of image data\nthat might include important textual content such as a graphical\nrepresentation of financial data. Errors that result from OCR’d docu-\nments can often be fixed using systems that have a robust semantic\nrepresentation of the target domain. For instance, a model that is\ntrained on financial reports might have encoded awareness that\nemojis are unlikely to appear in them or that it is unusual for the\nnumeric value of profit to be higher than that of revenue.\n2.2 Anomaly as irregularity\nAnomaly in the semantic space might reflect irregularities that are\nintentional or emergent, signaling risky behavior or phenomena.\nA sudden change in the tone and vocabulary of a company’s lead-\nership in their earnings calls or financial reports can signal risk.\nNews stories that have abnormal language, or irregular origination\nor propagation patterns might be unreliable or untrustworthy.\n[22] showed that when trained on similar domains or contexts,\ndistributed representations of words are likely to be stable, where\nstability is measured as the similarity of their nearest neighbors\nin the distributed space. Such insight can be used to assess anom-\nalies in this sense. As an example, [12] identified cliques of users\non Twitter who consistently shared news from similar domains.\narXiv:1908.09156v1  [cs.CL]  24 Aug 2019\nCharacterizing these networks as “echo-chambers, ” they then rep-\nresented the content shared by these echo-chambers as distributed\nrepresentations. When certain topics from one echo-chamber began\nto deviate from similar topics in other echo-chambers, the content\nwas tagged as unreliable. [12] showed that this method can be used\nto improve the performance of standard methods for fake-news\ndetection.\nIn another study [24], the researchers hypothesized that trans-\nparent language in earnings calls indicates high expectations for\nperformance in the upcoming quarters, whereas semantic ambigu-\nity can signal a lack of confidence and expected poor performance.\nBy quantifying transparency as the frequent use of numbers, shorter\nwords, and unsophisticated vocabulary, they showed that a change\nin transparency is associated with a change in future performance.\n2.3 Anomaly as novelty\nAnomaly can indicate a novel event or phenomenon that may or\nmay not be risky. Breaking news stories often emerge as anomalous\ntrends on social media. [9] experimented with this in their effort to\ndetect novel events from Twitter conversations. By representing\neach event as a real-time cluster of tweets (where each tweet was\nencoded as a vector), they managed to assess the novelty of the\nevent by comparing its centroid to the centroids of older events.\nNovelty detection can also be used to detect emerging trends on\nsocial media, e.g. controversies that engulf various brands often\nstart as small local events that are shared on social media and attract\nattention over a short period of time. How people respond to these\nevents in early stages of development can be a measure of their\nveracity or controversiality [10, 13].\nAn anomaly in an industry grouping of companies can also\nbe indicative of a company that is disrupting the norm for that\nindustry and the emergence of a new sector or sub-sector. Often\nknown as trail-blazers, these companies innovate faster than their\ncompetitors to meet market demands sometimes even before the\nconsumer is aware of their need. As these companies continually\nevolve their business lines, their core operations are novel outliers\nfrom others in the same industry classification that can serve as\nmeaningful signals of transforming industry demands.\n2.4 Anomaly as semantic richness\nA large portion of text documents that analysts and researchers\nin the financial sectors consume have a regulatory nature. Annual\nfinancial reports, credit agreements, and filings with the U.S. Se-\ncurities and Exchange Commission (SEC) are some of these types\nof documents. These documents can be tens or hundreds of pages\nlong, and often include boilerplate language that the readers might\nneed to skip or ignore in order to get to the “meat” of the content.\nOften, the abnormal clauses found in these documents are buried\nin standard text so as not to attract attention to the unique phrases.\n[17] used smoothed representations of n-grams in SEC filings in\norder to identify boilerplate and abnormal language. They did so by\ncomparing the probability of each n-gram against the company’s\nprevious filings, against other filings in the same sector, and against\nother filings from companies with similar market cap. The aim was\nto assist accounting analysts in skipping boilerplate language and\nfocusing their attention on important snippets in these documents.\nSimilar methods can be applied to credit agreements where\ncovenants and clauses that are too common are often ignored by\nrisk analysts and special attention is paid to clauses that “stand out”\nfrom similar agreements.\n2.5 Anomaly as contextual relevance\nCertain types of documents include universal as well as context-\nspecific signals. As an example, consider a given company’s finan-\ncial reports. The reports may include standard financial metrics\nsuch as total revenue, net sales, net income, etc. In addition to\nthese universal metrics, businesses often report their performance\nin terms of the performance of their operating segments. These\nsegments can be business divisions, products, services, or regional\noperations. The segments are often specific to the company or its\npeers. For example, Apple Inc. ’s segments might include “iPhone, ”\n“iMac, ” “iPad, ” and “services. ” The same segments will not appear in\nreports by other businesses.\nFor many analysts and researchers, operating segments are a cru-\ncial part of exploratory or predictive analysis. They use performance\nmetrics associated with these segments to compare the business to\nits competitors, to estimate its market share, and to project the over-\nall performance of the business in upcoming quarters. Automating\nthe identification and normalization of these metrics can facilitate\nmore insightful analytical research. Since these segments are often\nspecific to each business, supervised models that are trained on a\ndiverse set of companies cannot capture them without overfitting\nto certain companies. Instead, these segments can be treated as\ncompany-specific anomalies.\n3 ANOMALY DETECTION VIA LANGUAGE\nMODELING\nUnlike numeric data, text data is not directly machine-readable, and\nrequires some form of transformation as a pre-processing step. In\n“bag-of-words” methods, this transformation can take place by as-\nsigning an index number to each word, and representing any block\nof text as an unordered set of these words. A slightly more sophisti-\ncated approach might chain words into continuous “n-grams” and\nrepresent a block of text as an ordered series of “n-grams” that have\nbeen extracted on a sliding window of size n. These approaches are\nconventionally known as “language modeling. ”\nSince the advent of high-powered processors enabled the wide-\nspread use of distributed representations, language modeling has\nrapidly evolved and adapted to these new capabilities. Recurrent\nneural networks can capture an arbitrarily long sequence of text\nand perform various tasks such as classification or text generation\n[21]. In this new context, language modeling often refers to training\na recurrent network that predicts a word in a given sequence of\ntext [6]. Language models are easy to train because even though\nthey follow a predictive mechanism, they do not need any labeled\ndata, and are thus unsupervised.\nFigure 1 is a simple illustration of how a neural network that\nis composed of recurrent units such as Long-Short Term Memory\n(LSTM) [5] can perform language modeling. The are four main\ncomponents to the network:\n• The input vectors (xi ), which represent units (i.e. characters,\nwords, phrases, sentences, paragraphs, etc.) in the input text.\n2\nFigure 1: Illustration of a recurrent step in a language model.\nExcerpted from [8].\nOccasionally, these are represented by one-hot vectors that\nassign a unique index to each particular input. More com-\nmonly, these vectors are adapted from a pre-trained corpus,\nwhere distributed representations have been inferred either\nby a simpler auto-encoding process [11] or by applying the\nsame recurrent model to a baseline corpus such as Wikipedia\n[6].\n• The output vectors (yi ), which represent the model’s predic-\ntion of the next word in the sequence. Naturally, they are\nrepresented in the same dimensionality as xi s.\n• The hidden vectors (hi ), which are often randomly initial-\nized and learned through backpropagation. Often trained as\ndense representations, these vectors tend to display charac-\nteristics that indicate semantic richness [14] and composi-\ntionality [11]. While the language model can be used as a\ntext-generation mechanism, the hidden vectors are a strong\nside product that are sometimes extracted and reused as\naugmented features in other machine learning systems [3].\n• The weights of the network (Wi j) (or other parameters in\nthe network), which are tuned through backpropagation.\nThese often indicate how each vectors in the input or hidden\nsequence is utilized to generate the output. These parameters\nplay a big role in the way the output of neural networks are\nreverse-engineered or explained to the end user 1.\nThe distributions of any of the above-mentioned components\ncan be studied to mine signals for anomalous behavior in the con-\ntext of irregularity, error, novelty, semantic richness, or contextual\nrelevance.\n3.1 Anomaly in input vectors\nAs previously mentioned, the input vectors to a text-based neural\nnetwork are often adapted from publicly-available word vector\ncorpora. In simpler architectures, the network is allowed to back-\npropagate its errors all the way to the input layer, which might\ncause the input vectors to be modified. This can serve as a signal for\n1As an example see https://tinyurl.com/y56drbnk\nanomaly in the semantic distributions between the original vectors\nand the modified vectors.\nAnalyzing the stability of word vectors when trained on different\niterations can also signal anomalous trends [22].\n3.2 Anomaly in output vectors\nAs previously mentioned, language models generate a probability\ndistribution over a word (or character) in a sequence. These proba-\nbilities can be used to detect transcription or character-recognition\nerrors in a domain-friendly manner. When the language model is\ntrained on financial data, domain-specific trends (such as the use\nof commas and parentheses in financial metrics) can be captured\nand accounted for by the network, minimizing the rate of false\npositives.\n3.3 Anomaly in hidden vectors\nA recent advancement in text processing is the introduction of fine-\ntuning methods to neural networks trained on text [6]. Fine-tuning\nis an approach that facilitates the transfer of semantic knowledge\nfrom one domain (source) to another domain (target). The source\ndomain is often large and generic, such as web data or the Wikipedia\ncorpus, while the target domain is often specific (e.g. SEC filings).\nA network is pre-trained on the source corpus such that its hidden\nrepresentations are enriched. Next, the pre-trained networks is re-\ntrained on the target domain, but this time only the final (or top\nfew) layers are tuned and the parameters in the remaining layers\nremain “frozen. ” The top-most layer of the network can be modified\nto perform a classification, prediction, or generation task in the\ntarget domain (see Figure 2).\nFine-tuning aims to change the distribution of hidden represen-\ntations in such a way that important information about the source\ndomain is preserved, while idiosyncrasies of the target domain are\ncaptured in an effective manner [15]. A similar process can be used\nto determine anomalies in documents. As an example, consider\na model that is pre-trained on historical documents from a given\nsector. If fine-tuning the model on recent documents from the same\nsector dramatically shifts the representations for certain vectors,\nthis can signal an evolving trend.\n3.4 Anomaly in weight tensors and other\nparameters\nModels that have interpretable parameters can be used to iden-\ntify areas of deviation or anomalous content. Attention mecha-\nnisms [19] allow the network to account for certain input signals\nmore than others. The learned attention mechanism can provide\ninsight into potential anomalies in the input. Consider a language\nmodel that predicts the social media engagement for a given tweet.\nSuch a model can be used to distinguish between engaging and\ninformation-rich content versus clickbait, bot-generated, propagan-\ndistic, or promotional content by exposing how, for these categories,\nengagement is associated with attention to certain distributions of\n“trigger words. ”\nTable 1 lists four scenarios for using the various layers and pa-\nrameters of a language model in order to perform anomaly detection\nfrom text.\n3\nFigure 2: A pre-trained model can be fine-tuned on a new domain, and applied to a classification or prediction task. Excerpted\nfrom [6].\nPossible\nsource of\nanomaly\nPossible\ntype of\nanomaly\nExample\nApplication\nExample\nAnalysis\nInput Novelty\nIdentifying how\nperspectives on ESG\nfactors are changing\nover time in\nfinancial reports\nRetrain the network\non y-o-y data and\nobserve unstable\nword vectors\nOutput Error\nIdentifying errors\nin earnings call\ntranscripts\nAnalyze the\nemission probability\nof observed\nwords\nHidden Semantic\nrichness\nIdentifying\nnon-boilerplate\nlanguage\nDetermine which\nhidden vectors\ndiverge from others\nWeights &\nParams Irregularity\nIdentifying\nclickbait\ncontent\nObserve how a\nresponse-generation\nmodel attends to\nwords in the input\nTable 1: Four scenarios for anomaly detection on text data\nusing signals from various layers and parameters in a lan-\nguage model.\n4 CHALLENGES AND FUTURE RESEARCH\nLike many other domains, in the financial domain, the application\nof language models as a measurement for semantic regularity of text\nbears the challenge of dealing with unseen input. Unseen input can\nbe mistaken for anomaly, especially in systems that are designed for\nerror detection. As an example, a system that is trained to correct\nerrors in an earnings call transcript might treat named entities such\nas the names of a company’s executives, or a recent acquisition, as\nanomalies. This problem is particularly prominent in fine-tuned\nlanguage models, which are pre-trained on generic corpora that\nmight not include domain-specific terms.\nWhen anomalies are of a malicious nature, such as in the case\nwhere abnormal clauses are included in credit agreements, the\nimplementation of the anomalous content is adapted to appear\nnormal. Thereby, the task of detecting normal language becomes\nmore difficult.\nAlternatively, in the case of language used by executives in com-\npany presentations such as earnings calls, there may be a lot of noise\nin the data due to the large degree of variability in the personali-\nties and linguistic patterns of various leaders. The noise variability\npresent in this content could be similar to actual anomalies, hence\nmaking it difficult to identify true anomalies.\nFactors related to market interactions and competitive behavior\ncan also impact the effectiveness of anomaly-detection models.\nIn detecting the emergence of a new industry sector, it may be\nchallenging for a system to detect novelty when a collection of\ncompanies, rather than a single company, behave in an anomalous\nway. The former may be the more common real-world scenario\nas companies closely monitor and mimic the innovations of their\ncompetitors. The exact notion of anomaly can also vary based on\nthe sector and point in time. For example, in the technology sector,\nthe norm in today’s world is one of continuous innovation and\ntechnological advancements.\nAdditionally, certain types of anomaly can interact and make it\ndifficult for systems to distinguish between them. As an example,\na system that is trained to identify the operating segments of a\ncompany tends to distinguish between information that is specific\nto the company, and information that is common across different\ncompanies. As a result, it might identify the names of the company’s\nboard of directors or its office locations as its operating segments.\nTraditional machine learning models have previously tackled the\nabove challenges, and solutions are likely to emerge in the neural\nparadigms as well. Any future research in these directions will have\nto account for the impact of such solutions on the reliability and\n4\nexplainability of the resulting models and their robustness against\nadversarial data.\n5 CONCLUSION\nAnomaly detection from text can have numerous applications in\nfinance, including risk detection, predictive analysis, error correc-\ntion, and peer detection. We have outlined various perspectives on\nhow anomaly can be interpreted in the context of finance, and cor-\nresponding views on how language modeling can be used to detect\nsuch aspects of anomalous content. We hope that this paper lays\nthe groundwork for establishing a framework for understanding\nthe opportunities and risks associated with these methods when\napplied in the financial domain.\nREFERENCES\n[1] Peter Addo, Dominique Guegan, and Bertrand Hassani. 2018. Credit risk analysis\nusing machine and deep learning models. Risks 6, 2 (2018), 38.\n[2] Leon Cheng. 2013. Unsupervised Topic Discovery by Anomaly Detection.\n[3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:\nPre-training of deep bidirectional transformers for language understanding.arXiv\npreprint arXiv:1810.04805(2018).\n[4] Eleazar Eskin. 2000. Detecting Errors within a Corpus using Anomaly Detection.\nIn 1st Meeting of the North American Chapter of the Association for Computational\nLinguistics. https://www.aclweb.org/anthology/A00-2020\n[5] Sepp Hochreiter and JÃĳrgen Schmidhuber. 1997. Long Short-Term Memory.\nNeural Computation9, 8 (1997), 1735–1780.\n[6] Jeremy Howard and Sebastian Ruder. 2018. Fine-tuned Language Models for Text\nClassification. CoRR abs/1801.06146 (2018).\n[7] Cheng F Lee and Oliver M Rui. 2000. Does trading volume contain informa-\ntion to predict stock returns? Evidence from China’s stock markets. Review of\nQuantitative Finance and Accounting14, 4 (2000), 341–360.\n[8] Nicholas Leonard. 2016. Language modeling a billion words. http://torch.ch/\nblog/2016/07/25/nce.html.\n[9] Quanzhi Li, Armineh Nourbakhsh, Sameena Shah, and Xiaomo Liu. 2017. Real-\nTime Novel Event Detection from Social Media. In 33rd IEEE International Con-\nference on Data Engineering, ICDE 2017, San Diego, CA, USA, April 19-22, 2017.\n1129–1139.\n[10] Xiaomo Liu, Armineh Nourbakhsh, Quanzhi Li, Rui Fang, and Sameena Shah.\n2015. Real-time Rumor Debunking on Twitter. In Proceedings of the 24th ACM\nInternational Conference on Information and Knowledge Management, CIKM 2015,\nMelbourne, VIC, Australia, October 19 - 23, 2015. 1867–1870.\n[11] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013.\nDistributed representations of words and phrases and their compositionality. In\nAdvances in neural information processing systems. 3111–3119.\n[12] Armineh Nourbakhsh, Xiaomo Liu, Quanzhi Li, and Sameena Shah. 2017. \"apping\nthe echo-chamber: detecting and characterizing partisan networks on Twitter. In\nProceedings of the 2017 International Conference on Social Computing, Behavioral-\nCultural Modeling, & Prediction and Behavior Representation in Modeling and\nSimulation.\n[13] Armineh Nourbakhsh, Xiaomo Liu, Sameena Shah, Rui Fang, Mohammad Mahdi\nGhassemi, and Quanzhi Li. 2015. Newsworthy Rumor Events: A Case Study of\nTwitter. In IEEE International Conference on Data Mining Workshop, ICDMW 2015,\nAtlantic City, NJ, USA, November 14-17, 2015. 27–32.\n[14] Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher\nClark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word\nrepresentations. arXiv preprint arXiv:1802.05365(2018).\n[15] Sebastian Ruder and Barbara Plank. 2017. Learning to select data for transfer learn-\ning with Bayesian Optimization. InProceedings of the 2017 Conference on Empirical\nMethods in Natural Language Processing. Association for Computational Linguis-\ntics, Copenhagen, Denmark, 372–382. https://doi.org/10.18653/v1/D17-1038\n[16] Pratip Samanta and Bidyut B. Chaudhuri. 2013. A simple real-word error detection\nand correction using local word bigram and trigram. In Proceedings of the 25th\nConference on Computational Linguistics and Speech Processing (ROCLING 2013).\nThe Association for Computational Linguistics and Chinese Language Processing\n(ACLCLP), Kaohsiung, Taiwan, 211–220. https://www.aclweb.org/anthology/\nO13-1022\n[17] Sameena Shah, Dietmar Dorr, Khalid Al-Kofahi, and Jacob Sisk. [n. d.]. Systems\nand methods for determining atypical language.\n[18] Peter D. Turney and Patrick Pantel. 2010. From Frequency to Meaning: Vector\nSpace Models of Semantics. CoRR abs/1003.1141 (2010).\n[19] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All\nyou Need. In Advances in Neural Information Processing Systems 30, I. Guyon,\nU. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett\n(Eds.). Curran Associates, Inc., 5998–6008.\n[20] Eva Maria Vecchi, Marco Baroni, and Roberto Zamparelli. 2011. (Linear) maps of\nthe impossible: capturing semantic anomalies in distributional space. In Proceed-\nings of the Workshop on Distributional Semantics and Compositionality. Association\nfor Computational Linguistics, 1–9.\n[21] Tsung Hsien Wen, Milica Gasic, Dongho Kim, Nikola Mrksic, Pei-Hao Su, David\nVandyke, and Steve Young. 2015. Stochastic Language Generation in Dialogue\nusing Recurrent Neural Networks with Convolutional Sentence Reranking. (08\n2015).\n[22] Laura Wendlandt, Jonathan K Kummerfeld, and Rada Mihalcea. 2018. Fac-\ntors influencing the surprising instability of word embeddings. arXiv preprint\narXiv:1804.09692 (2018).\n[23] Jarrod West and Maumita Bhattacharya. 2016. Intelligent financial fraud detection:\nA comprehensive review. Computers & Security 57 (2016), 47 – 66. https:\n//doi.org/10.1016/j.cose.2015.09.005\n[24] Frank Zhao. 2017. Hanging on Every Word: Natural Language Processing Unlocks\nNew Frontier in Corporate Earnings Sentiment Analysis. https://www.valuewalk.\ncom/2017/09/natural-language-processing-corporate-earnings-sentiment/.\n5",
  "topic": "Anomaly detection",
  "concepts": [
    {
      "name": "Anomaly detection",
      "score": 0.675364077091217
    },
    {
      "name": "Anomaly (physics)",
      "score": 0.5537077188491821
    },
    {
      "name": "Computer science",
      "score": 0.44739827513694763
    },
    {
      "name": "Finance",
      "score": 0.34693360328674316
    },
    {
      "name": "Business",
      "score": 0.301347017288208
    },
    {
      "name": "Artificial intelligence",
      "score": 0.2128695547580719
    },
    {
      "name": "Physics",
      "score": 0.08654320240020752
    },
    {
      "name": "Condensed matter physics",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 8
}