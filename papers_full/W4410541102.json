{
    "title": "An Australasian survey on the use of ChatGPT and other large language models in medical physics",
    "url": "https://openalex.org/W4410541102",
    "year": 2025,
    "authors": [
        {
            "id": null,
            "name": "Norris, Stanley A.",
            "affiliations": [
                "Peter MacCallum Cancer Centre",
                "Monash Health"
            ]
        },
        {
            "id": "https://openalex.org/A2123703275",
            "name": "Kron Tomas",
            "affiliations": [
                "University of Melbourne",
                "Peter MacCallum Cancer Centre"
            ]
        },
        {
            "id": null,
            "name": "Masterson, Maeve",
            "affiliations": [
                "Monash Health"
            ]
        },
        {
            "id": null,
            "name": "Badawy, Mohamed K.",
            "affiliations": [
                "Monash University",
                "Monash Health"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4253763531",
        "https://openalex.org/W4399365040",
        "https://openalex.org/W4206701492",
        "https://openalex.org/W4392942726",
        "https://openalex.org/W4393153538",
        "https://openalex.org/W4391660228",
        "https://openalex.org/W4390102952",
        "https://openalex.org/W4400450490",
        "https://openalex.org/W4383501093",
        "https://openalex.org/W4388931647",
        "https://openalex.org/W4319341091",
        "https://openalex.org/W4387599811",
        "https://openalex.org/W4409273574",
        "https://openalex.org/W4376640725",
        "https://openalex.org/W4390837349",
        "https://openalex.org/W4377010595",
        "https://openalex.org/W4401527931",
        "https://openalex.org/W4387356888",
        "https://openalex.org/W4387747149",
        "https://openalex.org/W2599796687",
        "https://openalex.org/W4394845024",
        "https://openalex.org/W4402406954",
        "https://openalex.org/W4390937018",
        "https://openalex.org/W4386735541",
        "https://openalex.org/W4404555330",
        "https://openalex.org/W4404515893",
        "https://openalex.org/W4403035756",
        "https://openalex.org/W4388343109",
        "https://openalex.org/W4384484700",
        "https://openalex.org/W4402907223",
        "https://openalex.org/W3121252599",
        "https://openalex.org/W3159756513"
    ],
    "abstract": null,
    "full_text": "SCIENTIFIC PAPER\nPhysical and Engineering Sciences in Medicine (2025) 48:1145–1153\nhttps://doi.org/10.1007/s13246-025-01571-9\nsystem is only part of much wider research efforts. A search \nof the PubMed National Institutes of Health (NIH) database \nunder the term ‘Artificial Intelligence’ highlights its signifi-\ncance as a key area of research in medicine, with 45,083 \nnew studies published in 2024 [7]. For a perspective against \nhistorical and current areas of medical physics, the number \nof publications in the PubMed database resulting for each \nof the search terms ‘Large Language Model’, ‘Radiomics’, \n‘ChatGPT’, ‘Monte Carlo Simulations’, ‘Radiopharmaceu -\ntical Therapy’, and ‘Proton Radiotherapy’ plotted over time \nis shown in Fig. 1. The rapid increase in medical research \nrelated to the ChatGPT platform over two years has been \nremarkable. Undoubtedly, the high volume of ChatGPT \nresearch is partly due to its novelty and accessibility.\nMany studies have been published assessing the perfor -\nmance of ChatGPT in tasks such as clinical decision-mak -\ning [ 8–13], answering board-style examination questions \n[14, 15], generating, translating, and summarising diagnos-\ntic radiology reports [16–18], and streamlining patient com-\nmunication [19]. Some of the biggest hurdles in translating \nAI products into clinical practice are those due to safety, \nprivacy, governance, ethical, and regulatory issues. None -\ntheless, private companies have developed AI and Machine \nIntroduction\nThe widespread availability of powerful large language \nmodels (LLMs), such as those offered by the ChatGPT \nplatform (OpenAI, San Francisco, U.S.A.), requiring only \na computer or mobile device with access to the internet, is \nset to have a lasting impact on society. Given their rapid \nadoption by general members of the public, as well as being \nthe subject of a growing and broader research interest in \nArtificial Intelligence (AI), LLMs hold the promise to revo-\nlutionise the professional services industry [1–6]. The drive \nto develop AI models to improve or benefit the healthcare \n \r Stanley A. Norris\nstanley.norris@monashhealth.org\n1 Monash Health, Monash Imaging, Melbourne, Australia\n2 Peter MacCallum Cancer Centre, Department of Physical \nSciences, Melbourne, Australia\n3 Sir Peter MacCallum Department of Oncology, University of \nMelbourne, Melbourne, Australia\n4 Department of Medical Imaging and Radiation Sciences, \nMonash University, Melbourne, Australia\nAbstract\nThis study surveyed medical physicists in Australia and New Zealand on their use of large language models (LLMs), \nparticularly ChatGPT. There is currently no literature on the application of ChatGPT and other LLMs by medical physi -\ncists. This survey targeted a mixed group of professionals, including clinical medical physicists, registrars, students, and \nother specialised roles. It reveals that many respondents integrate LLM platforms into their work for a broad range of \ntasks. Most participants reported efficiency gains, although fewer perceived improvements in the overall quality of their \nwork. Despite these benefits, substantial concerns remain regarding data security, patient confidentiality, and the lack of \nestablished guidelines or professional training for using these tools in a clinical context. Further, the potential for sudden \nchanges in accessibility and pricing, which could disproportionately impact developing countries and under-resourced \ndepartments, implies that other vulnerabilities may exist. These findings suggest the need for the medical physics com -\nmunity to come together and debate the careful balance between exploiting LLM platforms and developing clear best \npractices that implement robust risk management strategies.\nKeywords Medical physics · ChatGPT · Large language model · Generative artificial intelligence\nReceived: 21 February 2025 / Accepted: 13 May 2025 / Published online: 20 May 2025\n© The Author(s) 2025\nAn Australasian survey on the use of ChatGPT and other large \nlanguage models in medical physics\nStanley A. Norris1,2  · Tomas Kron2,3  · Maeve Masterson1 · Mohamed K. Badawy1,4\n1 3\nPhysical and Engineering Sciences in Medicine (2025) 48:1145–1153\nLearning enabled devices that are currently being rolled \nout in different healthcare systems, following approval by \nregulatory bodies such as the Food and Drug Administra -\ntion (USA), Therapeutic Goods Administration (Australia), \nand Medicines and Healthcare Products Regulatory Agency \n(UK).\nDespite its rapid ascent in popular culture, ChatGPT—\nfirst released to the public in November 2022—is still in its \ninfancy and seems to be met by the non-expert audience with \ncuriosity and scepticism. Generative AI models can make \nunacceptable mistakes, such as hallucinations—instances \nwhere the model produces factually incorrect or fabricated \ninformation—and their deep complexity and black-box \nnature leave many perplexed as to how and why these tools \nwork. Although some share the fear that they may lose their \njobs to an AI model [ 20], it is essential to note the limita -\ntions of this technology. In most aspects of medicine, human \nverification is unlikely to be replaced entirely, because the \nconsequences of an error could be catastrophic to the indi -\nvidual patient. However, if the principle of universal access \nis combined with a technology proven to increase efficiency, \nthese models could drive much positive change for society.\nA substantial number of studies have scrutinised the \ncapabilities of ChatGPT and other LLMs in the context of \ndiagnostic imaging, radiation oncology, and radiological \nprotection physics [ 21–30]. Despite the value of AI being \nrecognised by the medical physics community [ 31, 32], \nthere is no literature on the role of ChatGPT in assisting and \nstreamlining the day-to-day, non-specialised tasks of clini -\ncal, academic or research medical physicists. In response \nto this gap, we surveyed medical physicists to explore how \nthey use the ChatGPT platform in professional contexts. \nTo the authors’ knowledge, this study is the first to survey \nmedical physicists on their use of the ChatGPT platform.\nMethods\nRecruitment details\nThe survey was distributed through the Australasian Col -\nlege of Physical Scientists and Engineers in Medicine \n(ACPSEM), which includes members from both Australia \nand New Zealand, as well as via publicly available mailing \nlists for medical physics professionals, including the Austra-\nlian Medical Physics Register and the Victorian Department \nof Health’s list of approved medical physicists. The survey \nwas also shared with academic medical physicists from 15 \nuniversity departments across Australia and New Zealand.\nTo encourage participation in the survey, invited partici-\npants were entered in a draw to win a prize in the form of \na medical physics T-shirt (While You Sleep, Melbourne, \nFig. 1 Plot of the number of new publications per year between 1980 \nand 2024, for different search terms in queries to the NIH’s National \nLibrary of Medicine PubMed database (accessed November 29th, \n2024) [7]. Data points are omitted from the plot for years in which no \nstudies were published on a particular term\n \n1 3\n1146\nPhysical and Engineering Sciences in Medicine (2025) 48:1145–1153\nAustralia) designed and hand-printed for this survey. Invited \nparticipants were given 18 days (31/01/2025-18/02/2025) \nto complete the survey before responses were collected and \nanalysed for the study.\nSurvey design and collection of data\nThe survey is designed to shed light on the patterns of Chat-\nGPT usage by medical physicists of varying seniority lev -\nels and specialisations. Participants were prompted to enter \ntheir name and email address to collect the necessary infor-\nmation to identify and contact the prize winner. The first set \nof questions was defined so respondents could be grouped \ninto experience levels and specialisations. These questions \nprobed details about their role, years of experience, and \nspecialisation(s). The second set of questions was designed \nto assess the patterns of use of ChatGPT (or an alternative \nLLM platform) in the work of these respondents. To ensure \nthe survey is broadly applicable, we include a question to \nidentify which LLM platform respondents might use as \nan alternative to ChatGPT, if applicable. These questions \nprobed details about their experience using LLM platforms, \nthe frequency at which they use them, whether they use the \nfree or paid subscription service, what sort of tasks they use \nthese tools for, whether they expect that their colleagues use \none, whether they opt-in to allow the platform to use their \ncontent for model training, and how they believe these tools \nimpact their work. An overview of the questions is provided \nin Table 1.\nThe survey was distributed using Microsoft Forms \n(Microsoft Corporation, Redmond, Washington, U.S.), a \nsecure, web-based software platform. The Supplementary \nInformation section provides the survey prompts, questions, \nand response options.\nData analysis\nThe survey results were first exported as a Microsoft Excel \n(Microsoft Corporation, Redmond, Washington, U.S.) \nspreadsheet. Open text entries relating to alternative models \nwere merged into a standard format to facilitate downstream \nanalysis. In cases where open text consisted of feedback \nor reiterated the use of ChatGPT, these entries were omit -\nted. Respondents who did not fit the survey criteria, such \nas those outside the medical physics profession (e.g., radi -\nologists), were also omitted from the survey results. The \nanalysis included summary statistics, that is, the number \nand proportion (in %) of respondents in each response cat -\negory, which were performed and visualised using Python \n(v3.12.4). Following the pooling of results into each cat -\negory of response, the data were visualised as bar charts. \nFor ease of visualisation and analysis, several response cat-\negories were grouped. The roles Medical Physics Registrar, \nMedical Physics Trainee, and Master’s Student/Graduate \nwere grouped as Medical Physicist in Training. Medical \nPhysicist and Senior Medical Physicist were grouped as \nQualified Medical Physicist, while Chief Medical Physicist, \nDeputy Chief Medical Physicist, Branch Head, and Princi -\npal Medical Physicist were grouped as Leadership Medical \nPhysicist. Experience levels of ‘<3 years’ and ‘3–5 years’ \nwere combined into a single ‘0–5 years’ group. Responses \nsuch as Radiobiology, Radiation Protection, and Software \nEngineering were grouped under ‘Other’ for the question \nregarding specialisations. For the question regarding roles, \nresponses such as Research or Academic Medical Physicist, \nMedical Physics Software Engineer, Radiation Safety Offi -\ncer, Contractor, and Retired Medical Physicist were grouped \nunder ‘Other’.\nResults\nA total of 101 individuals participated in the survey. The \nresults summarising the distribution of roles, experience \nlevel, specialisation, and prior use of LLMs are shown in \nFig. 2. Of the 101 respondents, 86% reported using a LLM \nplatform at least once before, regardless of purpose or con -\ntext. Responses between specialisations represented the \nworkforce, with 59% of respondents in radiation oncology \nand 24% in diagnostic radiology.\nThe results summarising the responses around alternative \nplatforms, frequency of use, perspective on the use of LLMs \nby colleagues, and subscription status to the paid version of \nplatforms are shown in Fig. 3. Respondents reported using \nTable 1 Overview of survey structure and question types\nQuestion content Response type Questions\nIdentification Name and email (for prize draw) Short answer 2\nDemographics Role, years of experience, specialisation Multiple choice 3\nLLM Access & Awareness Prior use of LLMs, specific platforms used, use by colleagues Yes/No, multiple choice, short answer 3\nUsage Frequency & Access Frequency of use, paid version Multiple choice, Yes/No 2\nLLM Use Cases Tasks categories where LLMs are used Checkbox (multi-select) 1\nLLM Consent Awareness Opt-in for training data use Yes/No/Not Sure 1\nPerceived Impact Beliefs about efficiency and quality improvements Yes/No 2\nTotal 14\n1 3\n1147\nPhysical and Engineering Sciences in Medicine (2025) 48:1145–1153\n(in %) of LLM platform use, grouped by years of experi -\nence, is shown in Fig. 5. Across all experience groups, most \nrespondents use LLM platforms at a frequency of 1 day per \nweek or less. Nonetheless, across all experience groups, \nmany respondents regularly use LLM platforms multiple \ntimes per week. The group with 15 or more years of expe -\nrience has the highest proportion of respondents who use \nLLM platforms less than 1 day per week (80%). In com -\nparison, the 5–10 years of experience group has the high -\nest proportion of respondents who use LLM platforms 3–5 \ntimes per week (35%). The experience group corresponding \nto 5 or fewer years has the highest proportion of respondents \nusing LLM platforms 1–3 times per week (33%).\nDiscussion\nThis survey captured various roles, experience levels, \nand specialisations. Although almost half the respondents \nwere medical physicists or senior medical physicists, other \nrespondents included medical physics registrars, students, \nresearch or academic medical physicists, principal and chief \nmedical physicists, as well as other less common roles such \nmany alternative platforms, at varying frequencies up to \n3–5 days per week. The vast majority, 85% of respondents, \nexpect some of their colleagues to use an LLM platform for \ntheir work in medical physics. However, much fewer (23%) \nrespondents use the paid version of a LLM platform.\nThe results concerning the tasks LLMs are used for, \nwhether respondents opt in to the platform training on their \ndata, and their perspective on the impact of these tools are \nshown in Fig. 4. Medical physicists use LLMs to cover a \nbroad range of tasks. The most common responses included \n‘professional use’, ‘education and learning’, and ‘cod -\ning and technical tasks’, reported by 54%, 54% and 53%, \nrespectively. The survey responses to whether medical \nphysicists opt in to “improve the model for everyone” were \nquite evenly mixed, with 41% answering ‘no’, 40% answer-\ning ‘not sure’, and 19% answering ‘yes’. In response to \nwhether the participants believe that using LLM platforms \nimproves their work efficiency, 82% chose ‘yes’. On the \nother hand, answering the question of whether participants \nbelieve that using LLM platforms improves the quality of \ntheir work, 59% chose ‘yes’.\nTo explore whether the frequency of use differs with \nexperience, a grouped bar plot of the different frequencies \nFig. 2 Responses to questions that probed respondent demographics and use of LLM platforms\n \n1 3\n1148\nPhysical and Engineering Sciences in Medicine (2025) 48:1145–1153\nof use across experience groups suggests that there may \nbe a correlation between experience level and the lack of \nadoption of LLM platforms. However, the sample size is \ntoo small, and the number of respondents in each group is \nuneven, prohibiting a rigorous statistical evaluation. More -\nover, it does not appear to be the case that the most junior \nmedical physicists (with 0–5 years’ experience) use LLM \nplatforms more frequently, given that the 5–10 years of \nexperience group had the highest proportion of respondents \nusing LLM platforms 3–5 times per week. Perhaps the rela-\ntionship between the amount of time a medical physicist \nspends using a computer and their frequency of use of LLM \nplatforms is more relevant. Despite a considerable number \nof medical physicists never using LLM platforms, it is clear \nthat the community is acutely aware of the emergence of \nLLMs in the medical physics profession. However, 77% of \nmedical physicists in this survey reported not using a paid \nversion of these LLM platforms, indicating that they pre -\ndominantly rely on free resources for their AI-driven tasks. \nThis suggests that employers and healthcare organisations \nare either unaware of the utilisation of LLMs or do not con-\nsider it to be of enough value to pay for.\nas trainees, radiation safety officer, contractor, and software \nengineer. The demographics show that this survey captured \nmany clinical medical physicists and other roles performed \nby the medical physics community. Most respondents had at \nleast 5 years of experience in medical physics. Considering \nthat years of experience do not include more general under-\ngraduate studies (e.g., BSc in Physics), this survey captured \na sample of relatively well-established professionals with \nsubstantial expertise within the field. Given that most of the \nmedical physics workforce (~ 80%) consists of radiation \noncology medical physicists [33], this proportion of survey \nrespondents (60%) compared to diagnostic imaging medical \nphysicists aligns with the distribution within the field. The \nsurvey also captured respondents in relatively niche areas of \nclinical medical physics, such as software engineering and \nradiobiology.\nMost survey respondents have used an LLM platform \nbefore, and most respondents regularly use it in their work \nat frequencies up to 5 days per week. In contrast, fewer \nrespondents (21%) report they ‘never’ use LLM platforms \nfor their work in medical physics, and even fewer respon -\ndents (3%) do not expect their colleagues to use LLM plat -\nforms at work. Exploring the differences in the frequency \nFig. 3 Responses to questions on the use of alternative platforms, frequency of use, perspective on the use of colleagues, and subscription to paid \nversions of LLM platforms\n \n1 3\n1149\nPhysical and Engineering Sciences in Medicine (2025) 48:1145–1153\nthe best option. More research and education appear to be \nrequired.\nFor clinical use, there is a risk of creating a dependence \non tools like ChatGPT, where sudden changes in accessibil-\nity and pricing structures could have negative consequences. \nA world health organisation (WHO) report on drug pricing \nstated that “Pharmaceutical companies set prices according \nto their commercial goals, with a focus on extracting the \nmaximum amount that a buyer is willing to pay for a medi-\ncine” and found little evidence of a link between the costs \nof research and development and the price charged for the \nfinal product [34]. Given that an AI company could imple -\nment this strategy, we should at least be aware of our vul -\nnerabilities. Sudden accessibility and pricing changes could \ndisproportionately burden developing countries and under-\nresourced communities, exacerbating existing inequalities.\nThis survey-based research study captures the current \nlandscape of LLM use in the medical physics profession. \nThis study has found that many medical physicists in Aus -\ntralia and New Zealand actively leverage LLM platforms \nfor a broad range of tasks in their day-to-day work. LLM \nplatforms such as ChatGPT are already an asset to the medi-\ncal physics community. This technology holds the most \nThese findings indicate that professional medical physi -\ncists are familiar with or are actively adopting LLM plat -\nforms such as ChatGPT in their work. Although the main \ntasks LLMs are used for in medical physics are coding and \ntechnical tasks, education and learning, and professional \nuse, LLMs are leveraged more broadly. The survey indi -\ncates this technology is also used for research and infor -\nmation gathering (e.g., literature summarisation), creative \ntasks (e.g., generating presentation content), administrative \ntasks (e.g., drafting emails), language and translation (e.g., \nsimplifying technical content), and business and marketing \n(e.g., generating outreach materials). Most medical physi -\ncists responding to this survey believe that LLM platforms \nimprove the efficiency of their work. Interestingly, fewer \nrespondents believe that LLM platforms enhance the quality \nof their work. The survey question around whether medical \nphysicists opt to “improve the model for everyone”, essen -\ntially using the platform to leverage user interactions to train \nmodels, is particularly important. A considerable proportion \nof respondents (39%) answered ‘not sure’, while the rest \nwere evenly split between ‘yes’ and ‘no’. Currently, there \nis no consensus within the medical physics community on \nFig. 4 Responses to questions around tasks LLMs are used for, whether medical physicists opt-in to the platform using their data for model train-\ning, and their perspective around the impact these tools have on their work\n \n1 3\n1150\nPhysical and Engineering Sciences in Medicine (2025) 48:1145–1153\nthat 199 email addresses were on the mailing list, this yields \na response rate of ~ 50%. However, the estimated number \nof medical physicists in Australia and New Zealand would \nbe closer to ~ 700 [33]. Additionally, some participants may \nhave been on annual or sick leave or could not respond due \nto a high workload or the potential sensitivity of the infor -\nmation explored. These factors, combined with general dif-\nficulties inherent in recruiting external survey participants, \nlimit our ability to provide a precise response rate and fully \nassess the sample’s representativeness. The survey was open \nbriefly to represent a well-defined snapshot in time. In a rap-\nidly developing field, this was considered to be important.\nConclusion\nThis study suggests that LLM platforms such as ChatGPT \nhave become an important part of the workflow of many \nmedical physicists in Australia and New Zealand, enhanc -\ning efficiency by accelerating programming, text-based, \nand administrative tasks. Although there have been numer -\nous research studies assessing the performance of LLM \nplatforms in specific areas and for certain tasks, there is \ncurrently no data on the application of this technology by \nmedical physics professionals. In other words, the questions \naround ‘what these tools are capable of’ have been asked, \npromise in automating the repetitive, administrative, and \nmanual tasks that do not require responses grounded in a \ndeep understanding of medical physics. Efficiency gains \nmay be the most important benefit of using LLMs.\nGiven that we have shown LLM platforms have been \nadopted and are regularly used by 79% of respondents for \nwork-related tasks in medical physics (i.e., those who did \nnot select “Never” in response to the question on frequency \nof use), ethical, practical, and safety considerations remain \nsubjects of ongoing debate. Careful thought should be given \nas to whether we should share our data to help improve \nLLM performance, weighing up potential benefits against \nprivacy concerns. To ensure safe and effective use, strate -\ngies to minimise risk should be developed, particularly in \ntasks that could impact patients. Further, the trustworthiness \nof third-party AI companies remains an important concern \ndue to a lack of transparency over data-handling policies. \nAddressing these issues through dedicated research and \npolicy development will ensure that the medical physics \ncommunity leverages this new technology responsibly and \neffectively.\nA limitation of this study is that it is challenging to deter-\nmine how many potential respondents were reached by the \nsurvey, as it was distributed via a mailing list and a post \non the college’s website that may not have been seen by \nall medical physicists in Australia and New Zealand. Given \nFig. 5 Frequency of LLM platform use (in %) among medical physicists, categorised by years of experience\n \n1 3\n1151\nPhysical and Engineering Sciences in Medicine (2025) 48:1145–1153\nholder. To view a copy of this licence, visit  h t t p  : / /  c r e a  t i  v e c  o m m o  n s .  o \nr g  / l i c e n s e s / b y / 4 . 0 /.\nReferences\n1. Cheong I, Xia K, Feng KJK et al (2024) (A)I Am Not a Lawyer, \nBut… Engaging Legal Experts towards Responsible LLM Poli -\ncies for Legal Advice. In: Proceedings of the 2024 ACM Confer-\nence on Fairness, Accountability, and Transparency. Association \nfor Computing Machinery, New York, NY , USA. 454–2469\n2. Jain V , Goel YGS, Uma M (2023) AI Powered Transformative \nPost Generator for LinkedIn using LLM and Explicit Filter. In: \n2023 International Conference on Innovative Computing, Intelli-\ngent Communication and Smart Electrical Systems (ICSES). 1–7\n3. Du Y , Luo D, Yan R et al (2024) Enhancing Job Recommendation \nthrough LLM-Based Generative Adversarial Networks. Proceed-\nings of the AAAI Conference on Artificial Intelligence 38:8363–\n8371.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  6 0 9  / a a  a i . v 3 8 i 8 . 2 8 6 7 8\n4. Singh V (2023) Exploring the role of large language model \n(LLM)-based chatbots for human resources. PhD dissertation, \nUniversity of Texas at Austin\n5. Mohan SK (2024) Management consulting in the artificial Intel -\nligence– LLM era. Manage Consulting J 7:9–24.  h t t p  s : /  / d o i  . o  r g /  1 \n0 . 2  4 7 8  / m c  j - 2 0 2 4 - 0 0 0 2\n6. Lai T, Shi Y , Du Z et al (2024) Supporting the demand on men-\ntal health services with AI-Based conversational large Language \nmodels (LLMs). BioMedInformatics 4:8–33.  h t t p  s : /  / d o i  . o  r g /  1 0 . 3  \n3 9 0  / b i  o m e  d i n  f o r m  a t  i c s 4 0 1 0 0 0 2\n7. PubMed In  h t t p  s : /  / p u b  m e  d . n  c b i .  n l m  . n i  h . g o v /. Accessed 30 Nov \n2024\n8. Zaki HA, Mai M, Abdel-Megid H et al (2024) Using ChatGPT \nto improve readability of interventional radiology procedure \ndescriptions. Cardiovasc Intervent Radiol 47:1134–1141.  h t t p  s : /  \n/ d o i  . o  r g /  1 0 . 1  0 0 7  / s 0  0 2 7 0 - 0 2 4 - 0 3 8 0 3 - z\n9. Barash Y , Klang E, Konen E, Sorin V (2023) ChatGPT-4 assis-\ntance in optimizing emergency department radiology referrals \nand imaging selection. J Am Coll Radiol 20:998–1003.  h t t p  s : /  / d o \ni  . o  r g /  1 0 . 1  0 1 6  / j .  j a c r . 2 0 2 3 . 0 6 . 0 0 9\n10. Horiuchi D, Tatekawa H, Shimono T et al (2024) Accuracy of \nChatGPT generated diagnosis from patient’s medical history \nand imaging findings in neuroradiology cases. Neuroradiology \n66:73–79.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 0  0 2 3 4 - 0 2 3 - 0 3 2 5 2 - 4\n11. Rao A, Kim J, Kamineni M et al (2023) Evaluating ChatGPT as \nan adjunct for radiologic decision-making. medRxiv:2023-02\n12. Rosen S, Saban M (2023) Evaluating the reliability of ChatGPT \nas a tool for imaging test referral: a comparative study with a \nclinical decision support system. Eur Radiol 34:2826–2837.  h t t p  s \n: /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 0  0 3 3 0 - 0 2 3 - 1 0 2 3 0 - 0\n13. Nguyen C, Carrion D, Badawy MK Comparative performance of \nanthropic Claude and openai GPT models in basic radiological \nimaging tasks. J Med Imaging Radiation Oncol N/a:  h t t p  s : /  / d o i  . o  \nr g /  1 0 . 1  1 1 1  / 1 7  5 4 - 9 4 8 5 . 1 3 8 5 8\n14. Bhayana R, Krishna S, Bleakney RR (2023) Performance of \nChatGPT on a radiology Board-style examination: insights into \ncurrent strengths and limitations. Radiology 307:e230582.  h t t p  s : /  \n/ d o i  . o  r g /  1 0 . 1  1 4 8  / r a  d i o l . 2 3 0 5 8 2\n15. Bera K, Gupta A, Jiang S et al (2024) Assessing Performance of \nMultimodal ChatGPT-4 on an image based Radiology Board-\nstyle Examination: An exploratory study. medRxiv:2024-01\n16. Lyu Q, Tan J, Zapadka ME et al (2023) Translating radiology \nreports into plain Language using ChatGPT and GPT-4 with \nprompt learning: results, limitations, and potential. Vis Comput \nInd Biomed Art 6:9.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 8 6  / s 4  2 4 9 2 - 0 2 3 - 0 0 1 3 6 - 5\nbut the questions around ‘what medical physicists regularly \nuse these tools for’ have not. This survey indicates a broad \nadoption across various roles, experience levels, and spe -\ncialisations, reflecting a growing exploitation of these tools. \nHowever, this rapid adoption is accompanied by serious \nconcerns regarding data security, patient confidentiality, and \na lack of professional guidelines or training. Additionally, \nthe potential for sudden changes in accessibility and pricing \nstructures poses risks, particularly for developing countries \nand resource-constrained departments. These findings sug -\ngest the need for the medical physics community to evaluate \nthe benefits and risks of LLM use critically and to establish \neducational guidelines and clear protocols and policies that \nsafeguard sensitive information while enabling progress and \nequitable access to AI-driven technologies.\nSupplementary Information  The online version contains \nsupplementary material available at  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 1  3 2 4 6 - 0 \n2 5 - 0 1 5 7 1 - 9.\nAcknowledgements On behalf of the authors, we thank Zachary Ure \nand the team at While You Sleep for designing and printing the T-shirt \nto increase the survey response rate. We would also like to thank those \nat the ACPSEM for distributing the survey to medical physicists. \nFinally, we thank every survey respondent for their time and willing -\nness to participate, providing valuable insight into the profession.\nAuthor contributions All authors contributed to the study conception \nand design. Material preparation, data collection and analysis were \nperformed by Stanley A Norris. The first draft of the manuscript was \nwritten by Stanley A Norris and all authors commented on previous \nversions of the manuscript. All authors read and approved the final \nmanuscript.\nFunding Open access funding provided by Monash Health, Victorian \nHealth Libraries Consortium (VHLC)\nThe authors declare that no funds, grants, or other support were re -\nceived during the preparation of this manuscript.\nDeclarations\nEthical approval This study was exempt from Human Research Ethics \nCommittee review as a retrospective quality improvement project. It \nwas consistent with the NHMRC Ethical Considerations in Quality \nAssurance and Evaluation Activities (2014) guideline.\nCompeting Interests The authors have no relevant financial or non-\nfinancial interests to disclose.\nOpen Access   This article is licensed under a Creative Commons \nAttribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the \nsource, provide a link to the Creative Commons licence, and indicate \nif changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless \nindicated otherwise in a credit line to the material. If material is not \nincluded in the article’s Creative Commons licence and your intended \nuse is not permitted by statutory regulation or exceeds the permitted \nuse, you will need to obtain permission directly from the copyright \n1 3\n1152\nPhysical and Engineering Sciences in Medicine (2025) 48:1145–1153\nassessment across clinical scenarios. Radiother Oncol 202:110645.  \nh t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  r a d o n c . 2 0 2 4 . 1 1 0 6 4 5\n27. Goto H, Shiraishi Y , Okada S (2024) Performance of generative \nPre-trained transformer (GPT)-4 and gemini advanced on the \nFirst-Class radiation protection supervisor examination in Japan. \nCureus 16:e70614.  h t t p  s : /  / d o i  . o  r g /  1 0 . 7  7 5 9  / c u  r e u s . 7 0 6 1 4\n28. Dennstädt F, Hastings J, Putora PM et al (2024) Exploring capa -\nbilities of large Language models such as ChatGPT in radiation \noncology. Adv Radiation Oncol 9:101400.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 \n6  / j .  a d r o . 2 0 2 3 . 1 0 1 4 0 0\n29. Holmes J, Liu Z, Zhang L et al (2023) Evaluating large Language \nmodels on a highly-specialized topic, radiation oncology physics. \nFront Oncol 13.  h t t p  s : /  / d o i  . o  r g /  1 0 . 3  3 8 9  / f o  n c . 2 0 2 3 . 1 2 1 9 3 2 6\n30. Dvorak C, Vesga-Prada Y , Salazar J et al (2024) Benchmarking \nopenai ChatGPT and Google bard on radiation physics study \nexams (RAPHEX) and implication for their use as a learning tool. \nInt J Radiat Oncol Biol Phys 120:e619.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  \ni j r  o b p  . 2 0 2  4 .  0 7 . 1 3 6 2\n31. Diaz O, Guidi G, Ivashchenko O et al (2021) Artificial intelli -\ngence in the medical physics community: an international survey. \nPhysica Med 81:141–146.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  e j m p . 2 0 2 0 . 1 1 \n. 0 3 7\n32. Santos JC, Wong JHD, Pallath V , Ng KH (2021) The perceptions \nof medical physicists towards relevance and impact of artificial \nintelligence. Phys Eng Sci Med 44:833–841.  h t t p s :   /  / d o  i . o  r  g  /  1 0  . 1 \n0   0 7 /  s 1 3  2 4 6 -  0 2 1 - 0  1 0 3 6 - 9\n33. Crowe S, Bezak E, Oliver L, Kron T (2020) Medical physics \ntraining, education and professional recognition in Australia and \nNew Zealand. Medical Physics. 8.3\n34. World Health Organization (2018) Technical report: pricing of \ncancer medicines and its impacts: a comprehensive technical \nreport for the World Health Assembly Resolution 70.12: opera -\ntive paragraph 2.9 on pricing approaches and their impacts on \navailability and affordability of medicines for the prevention and \ntreatment of cancer. World Health Organization, Geneva\nPublisher’s note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional affiliations.\n17. Soleimani M, Seyyedi N, Ayyoubzadeh SM et al (2024) Practical \nevaluation of ChatGPT performance for radiology report genera-\ntion. Acad Radiol 31:4823–4832.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  a c r a . 2 \n0 2 4 . 0 7 . 0 2 0\n18. Jeblick K, Schachtner B, Dexl J et al (2023) ChatGPT makes \nmedicine easy to swallow: an exploratory case study on simpli -\nfied radiology reports. Eur Radiol 34:2817–2825.  h t t p  s : /  / d o i  . o  r g /  \n1 0 . 1  0 0 7  / s 0  0 3 3 0 - 0 2 3 - 1 0 2 1 3 - 1\n19. Gordon EB, Towbin AJ, Wingrove P et al (2024) Enhancing \npatient communication with Chat-GPT in radiology: evaluating \nthe efficacy and readability of answers to common Imaging-\nRelated questions. J Am Coll Radiol 21:353–359.  h t t p  s : /  / d o i  . o  r g /  \n1 0 . 1  0 1 6  / j .  j a c r . 2 0 2 3 . 0 9 . 0 1 1\n20. McClure PK (2017) You’re fired. Says Robot Social Sci Comput \nRev.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 7 7  / 0 8  9 4 4 3 9 3 1 7 6 9 8 6 3 7\n21. Rydzewski NR, Dinakaran D, Zhao SG et al (2024) Com -\nparative evaluation of LLMs in clinical oncology. NEJM AI \n1:AIoa2300151.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 5 6  / A I  o a 2 3 0 0 1 5 1\n22. Kadoya N, Arai K, Tanaka S et al (2024) Assessing knowledge \nabout medical physics in Language-generative AI with large \nLanguage model: using the medical physicist exam. Radiol Phys \nTechnol 17:929–937.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 1  2 1 9 4 - 0 2 4 - 0 0 8 3 8 \n- 2\n23. Roemer G, Li A, Mahmood U et al (2024) Artificial intelligence \nmodel GPT4 narrowly fails simulated radiological protection \nexam. J Radiol Prot 44:013502.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 8 8  / 1 3  6 1 - 6 4 9 \n8 / a d 1 f d f\n24. Huang Y , Gomaa A, Semrau S et al (2023) Benchmarking Chat-\nGPT-4 on a radiation oncology in-training exam and red journal \nGray zone cases: potentials and challenges for ai-assisted medi -\ncal education and decision making in radiation oncology. Front \nOncol 13.  h t t p  s : /  / d o i  . o  r g /  1 0 . 3  3 8 9  / f o  n c . 2 0 2 3 . 1 2 6 5 0 2 4\n25. Gupta M, Virostko J, Kaufmann C (2025) Large Language mod-\nels in radiology: fluctuating performance and decreasing discor -\ndance over time. Eur J Radiol 182.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  e j r a d \n. 2 0 2 4 . 1 1 1 8 4 2\n26. Ramadan S, Mutsaers A, Chen P-HC et al (2025) Evaluating \nChatGPT’s competency in radiation oncology: A comprehensive \n1 3\n1153"
}