{
    "title": "Factors Associated With the Accuracy of Large Language Models in Basic Medical Science Examinations: Cross-Sectional Study",
    "url": "https://openalex.org/W4405018172",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5094294857",
            "name": "Naritsaret Kaewboonlert",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5094294858",
            "name": "Jiraphon Poontananggul",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2650759807",
            "name": "Natthipong Pongsuwan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A712584871",
            "name": "Gun Bhakdisongkhram",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W1901616594",
        "https://openalex.org/W3017131514",
        "https://openalex.org/W4368377190",
        "https://openalex.org/W4366743045",
        "https://openalex.org/W4200544039",
        "https://openalex.org/W4319460874",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4322758367",
        "https://openalex.org/W4361017283",
        "https://openalex.org/W4372047097",
        "https://openalex.org/W4379966280",
        "https://openalex.org/W3127024416",
        "https://openalex.org/W4386121749",
        "https://openalex.org/W4226037609",
        "https://openalex.org/W4387305434",
        "https://openalex.org/W4386439692",
        "https://openalex.org/W4385568225",
        "https://openalex.org/W4368340908",
        "https://openalex.org/W4376866715",
        "https://openalex.org/W4394956892",
        "https://openalex.org/W4386958277",
        "https://openalex.org/W4385266429",
        "https://openalex.org/W4388861785"
    ],
    "abstract": "Abstract Background Artificial intelligence (AI) has become widely applied across many fields, including medical education. Content validation and its answers are based on training datasets and the optimization of each model. The accuracy of large language model (LLMs) in basic medical examinations and factors related to their accuracy have also been explored. Objective We evaluated factors associated with the accuracy of LLMs (GPT-3.5, GPT-4, Google Bard, and Microsoft Bing) in answering multiple-choice questions from basic medical science examinations. Methods We used questions that were closely aligned with the content and topic distribution of Thailand’s Step 1 National Medical Licensing Examination. Variables such as the difficulty index, discrimination index, and question characteristics were collected. These questions were then simultaneously input into ChatGPT (with GPT-3.5 and GPT-4), Microsoft Bing, and Google Bard, and their responses were recorded. The accuracy of these LLMs and the associated factors were analyzed using multivariable logistic regression. This analysis aimed to assess the effect of various factors on model accuracy, with results reported as odds ratios (ORs). Results The study revealed that GPT-4 was the top-performing model, with an overall accuracy of 89.07% (95% CI 84.76%‐92.41%), significantly outperforming the others ( P &lt;.001). Microsoft Bing followed with an accuracy of 83.69% (95% CI 78.85%‐87.80%), GPT-3.5 at 67.02% (95% CI 61.20%‐72.48%), and Google Bard at 63.83% (95% CI 57.92%‐69.44%). The multivariable logistic regression analysis showed a correlation between question difficulty and model performance, with GPT-4 demonstrating the strongest association. Interestingly, no significant correlation was found between model accuracy and question length, negative wording, clinical scenarios, or the discrimination index for most models, except for Google Bard, which showed varying correlations. Conclusions The GPT-4 and Microsoft Bing models demonstrated equal and superior accuracy compared to GPT-3.5 and Google Bard in the domain of basic medical science. The accuracy of these models was significantly influenced by the item’s difficulty index, indicating that the LLMs are more accurate when answering easier questions. This suggests that the more accurate models, such as GPT-4 and Bing, can be valuable tools for understanding and learning basic medical science concepts.",
    "full_text": null
}