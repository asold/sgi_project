{
  "title": "Improve Vision Transformers Training by Suppressing Over-smoothing",
  "url": "https://openalex.org/W3159885121",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2945145079",
      "name": "CHENGYUE GONG",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2229879960",
      "name": "Dilin Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1986365266",
      "name": "Meng Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2119841321",
      "name": "Vikas Chandra",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1969334843",
      "name": "Qiang Liu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2108598243",
    "https://openalex.org/W2998496395",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2955425717"
  ],
  "abstract": "Introducing the transformer structure into computer vision tasks holds the promise of yielding a better speed-accuracy trade-off than traditional convolution networks. However, directly training vanilla transformers on vision tasks has been shown to yield unstable and sub-optimal results. As a result, recent works propose to modify transformer structures by incorporating convolutional layers to improve the performance on vision tasks. This work investigates how to stabilize the training of vision transformers \\emph{without} special structure modification. We observe that the instability of transformer training on vision tasks can be attributed to the over-smoothing problem, that the self-attention layers tend to map the different patches from the input image into a similar latent representation, hence yielding the loss of information and degeneration of performance, especially when the number of layers is large. We then propose a number of techniques to alleviate this problem, including introducing additional loss functions to encourage diversity, prevent loss of information, and discriminate different patches by additional patch classification loss for Cutmix. We show that our proposed techniques stabilize the training and allow us to train wider and deeper vision transformers, achieving 85.0\\% top-1 accuracy on ImageNet validation set without introducing extra teachers or additional convolution layers. Our code will be made publicly available at this https URL .",
  "full_text": null,
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.7461758255958557
    },
    {
      "name": "Computer science",
      "score": 0.6484469771385193
    },
    {
      "name": "Smoothing",
      "score": 0.6218277812004089
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5049510598182678
    },
    {
      "name": "FLOPS",
      "score": 0.42285650968551636
    },
    {
      "name": "Computer engineering",
      "score": 0.39421188831329346
    },
    {
      "name": "Machine learning",
      "score": 0.3680241107940674
    },
    {
      "name": "Computer vision",
      "score": 0.342154324054718
    },
    {
      "name": "Engineering",
      "score": 0.1459452509880066
    },
    {
      "name": "Parallel computing",
      "score": 0.11865535378456116
    },
    {
      "name": "Voltage",
      "score": 0.11670851707458496
    },
    {
      "name": "Electrical engineering",
      "score": 0.08036324381828308
    }
  ],
  "institutions": [],
  "cited_by": 22
}