{
  "title": "TrAISformer-A generative transformer for AIS trajectory prediction.",
  "url": "https://openalex.org/W3196337680",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2089842116",
      "name": "Duong Nguyen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A26130675",
      "name": "Ronan Fablet",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2972599895",
    "https://openalex.org/W2518108298",
    "https://openalex.org/W2963090522",
    "https://openalex.org/W592244745",
    "https://openalex.org/W2083442964",
    "https://openalex.org/W2962687116",
    "https://openalex.org/W3116651890",
    "https://openalex.org/W2919115771",
    "https://openalex.org/W2964265128",
    "https://openalex.org/W3033790618",
    "https://openalex.org/W2743711613",
    "https://openalex.org/W2891503716",
    "https://openalex.org/W2990822052",
    "https://openalex.org/W3207160263",
    "https://openalex.org/W2022603014",
    "https://openalex.org/W2794787653",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W3109182714",
    "https://openalex.org/W2997428643",
    "https://openalex.org/W3138659144",
    "https://openalex.org/W2940129212",
    "https://openalex.org/W2572270144",
    "https://openalex.org/W2766836212",
    "https://openalex.org/W2944791333",
    "https://openalex.org/W1589221530",
    "https://openalex.org/W2215617441",
    "https://openalex.org/W2982564563",
    "https://openalex.org/W3189199724",
    "https://openalex.org/W2944924828",
    "https://openalex.org/W1959608418",
    "https://openalex.org/W2027646026",
    "https://openalex.org/W2562836854",
    "https://openalex.org/W3047895711",
    "https://openalex.org/W3084233918",
    "https://openalex.org/W2130494750",
    "https://openalex.org/W3161292270",
    "https://openalex.org/W2886960696",
    "https://openalex.org/W3015961574",
    "https://openalex.org/W2990868438",
    "https://openalex.org/W3165782304"
  ],
  "abstract": "Modelling trajectory in general, and vessel trajectory in particular, is a difficult task because of the multimodal and complex nature of motion data. In this paper, we present TrAISformer-a novel deep learning architecture that can forecast vessel positions using AIS (Automatic Identification System) observations. We address the multimodality by introducing a discrete representation of AIS data and re-frame the prediction, which is originally a regression problem, as a classification problem. The model encodes complex movement patterns in AIS data in high-dimensional vectors, then applies a transformer to extract useful long-term correlations from sequences of those embeddings to sample future vessel positions. Experimental results on real, public AIS data demonstrate that TrAISformer significantly outperforms state-of-the-art methods.",
  "full_text": "TrAISformer—A Transformer Network with Sparse\nAugmented Data Representation and Cross Entropy\nLoss for AIS-based Vessel Trajectory Prediction\nDuong Nguyen, Member, IEEE, and Ronan Fablet, Senior Member, IEEE\nAbstract—Vessel trajectory prediction plays a pivotal role\nin numerous maritime applications and services. While the\nAutomatic Identification System (AIS) offers a rich source of\ninformation to address this task, forecasting vessel trajectory\nusing AIS data remains challenging, even for modern machine\nlearning techniques, because of the inherent heterogeneous and\nmultimodal nature of motion data. In this paper, we propose\na novel approach to tackle these challenges. We introduce a\ndiscrete, high-dimensional representation of AIS data and a\nnew loss function designed to explicitly address heterogene-\nity and multimodality. The proposed model—referred to as\nTrAISformer—is a modified transformer network that extracts\nlong-term temporal patterns in AIS vessel trajectories in the\nproposed enriched space to forecast the positions of vessels several\nhours ahead. We report experimental results on real, publicly\navailable AIS data. TrAISformer significantly outperforms state-\nof-the-art methods, with an average prediction performance\nbelow 10 nautical miles up to ∼10 hours.\nI. I NTRODUCTION\nIn the last decades, the development of maritime activities\nhas raised significant concerns relating to Maritime Surveil-\nlance (MS) and Maritime Situational Awareness (MSA), with\nvessel trajectory prediction being a focal point. Anticipating\nthe direction of vessels and their approximate locations at\nmedium-range time horizons, ranging from a few tens of\nminutes to tens of hours ahead, is at the core of diverse MS\nand MSA applications, including but not limited to search and\nrescue [1], [2], traffic control [3], path planning [4]–[6], port\ncongestion avoidance [7]–[9], pollution monitoring [10].\nThe Automatic Identification System—AIS provides in-\nvaluable information for the monitoring and surveillance of\nmaritime traffic. AIS data provide vessels’ kinetic information\n(the current position indicated by the latitude and longitude\ncoordinates, the current Speed Over Ground—SOG, the cur-\nrent Course Over Ground–COG, etc.), the information of the\nvoyages, as well as the static information (the identification\nnumber in the format a Maritime Mobile Service Identity—\nMMSI number, the name of the vessel, etc.) of vessels in\nDuong Nguyen and Ronan Fablet are with IMT Atlantique, Lab-STICC,\n29238 Brest, France (email: nvduong0512@gmail.com and ronan.fablet@imt-\natlantique.fr\nThis work was supported by public funds (Minist `ere de l’Education\nNationale, de l’Enseignement Sup ´erieur et de la Recherche, FEDER, R ´egion\nBretagne, Conseil G ´en´eral du Finist `ere, Brest M ´etropole). It benefited from\nHPC and GPU resources from Azure (Microsoft EU Ocean awards) and\nfrom GENCI-IDRIS (Grant 2020-101030). The authors also acknowledge the\nsupport of ANR (French Agence Nationale de la Recherche) under reference\nANR AI Chair OceaniX (ANR-19-CHIA-0016).\nFig. 1: Illustration of long-term 1dependence patterns in\nAIS vessel trajectories: At E, vessels typically follow one\nof the two main maritime routes indicated by the red and the\nyellow dashed arrows. In order to forecast whether a vessel\nwill continue straight ahead (the red path) or turn right (the\nyellow path), the prediction model may need to roll back\nseveral time steps to D, C, B, and A to understand the vessel’s\nprevious movements. Moreover, if the prediction model is not\nmultimodal, it may output as a prediction an unusual green\ndashed path, which is a merged path of the true red and yellow\nones.\nthe vicinity. Vessel trajectory prediction using AIS data has\nbeen studied for more than a decade [11]–[18]. However,\nthe achievements thus far have been still limited. Most state-\nof-the-art schemes reach a relevant prediction performance\nonly for short time horizons (ranging from a few minutes\nto half an hour) [14], [19], or for longer time horizons un-\nder particular movement patterns corresponding to predefined\nmaritime routes [20], [21] or unimodal movement patterns\n[18], [19]. Due to the complexity of vessel movement patterns\nand the heterogeneous nature of AIS data, forecasting vessel\npositions above several hours remains highly challenging. As\nan illustration, we report in Fig. 1 two vessel paths with very\nsimilar movement patterns on segment C→D but heading to\ntwo different destinations.\narXiv:2109.03958v4  [cs.AI]  3 Jan 2024\nTrajectory prediction has gained significant attention in re-\ncent years, particularly in the context of pedestrian and vehicle\nmovement patterns [22]–[25]. In this context, deep learning\nschemes have emerged as the state-of-the-art approach [26]–\n[30]. These recent advances however barely transfer to AIS-\nbased vessel trajectory prediction [31], [32]. First, the targeted\nspace-time scales strongly differ (e.g., meters and a few sec-\nonds to a few minutes for pedestrian movements vs. kilometers\nand hours for vessel movements). Second, while interaction\nfactors are critical to understanding and predicting pedestrian\nand vehicle trajectories, they have negligible effects on vessels’\nmovements in the open sea. Besides, long-term dependencies\nare key factors for the latter and need to be explicitly addressed\nin AIS-based vessel trajectory prediction models.\nIn the open sea, vessels often follow some common move-\nment patterns in order to optimize fuel consumption and to\nconform with maritime traffic regulations [33], [34]. However,\nthe analysis of the maritime traffic according to a finite\nset of interconnected maritime routes using clustering-based\napproaches [18]–[21] appears too simplistic to account for\nthe heterogeneous and multimodal characteristics of real-world\nAIS data. The core challenge of vessel trajectory prediction for\nthe targeted time horizon in this paper (ranging from half an\nhour to tens of hours) revolves around accurately predicting the\nturning direction at the “intersections”—commonly referred\nto as waypoints—along maritime routes (see Fig. 1). From a\nmathematical perspective, this involves developing a method\nthat effectively represents the multimodal nature of AIS data\nat these waypoints, where each turning direction corresponds\nto a distinct mode of the data distribution. In order to forecast\nthe trajectory correctly, the prediction model may need to\nbacktrack several time steps to know where the vessel comes\nfrom and to fully understand large-scale movement patterns.\nIn essence, we can identify two primary methodological chal-\nlenges: i) learning how to represent maritime traffic flows\nbeyond a fully-structured network of maritime routes; and ii)\ncapturing multi-scale patterns in vessel trajectories.\nTo address these challenges, we propose a novel deep learn-\ning model, referred to as TrAISformer. Our key contributions\nare as follows:\n• TrAISformer exploits a specific sparse, high-dimensional\nrepresentation of AIS data and frames the prediction\ntask as a classification problem to explicitly model the\nheterogeneity of AIS data and the multimodality of vessel\ntrajectories.\n• We leverage a probabilistic transformer architecture to\ncapture long-term dependencies in AIS vessel trajectories.\n• We benchmark TrAISformer w.r.t. state-of-the-art\nschemes on a real AIS dataset and report a prediction\nerror below 10 nmi (nautical mile) up to 10 hours, which\nsignificantly outperforms previous works [14], [18], [19].\nThe paper is organized as follows. Section II states the\nproblem and gives an overview of the related work and\n1In this paper, we use the terms “medium-range time horizon”, “medium-\nrange forecasting”, etc. to indicate the prediction horizons ranging from a few\ntens of minutes to tens of hours. The terms “long-term dependency”, “long-\nterm correlation”, etc., on the other hand, indicate the correlations across\nseveral time steps in the series.\ncurrent limitations for AIS-based vessel trajectory prediction.\nWe present the proposed approach in Section III. Section IV\ndetails our numerical experiments. We further discuss our main\ncontributions and future work in Section V.\nII. P ROBLEM STATEMENT AND RELATED WORK\nAIS-based vessel trajectory prediction involves forecasting\nthe future positions of vessels over a specific time horizon,\nusing a series of historical AIS data. Formally, let us denote\nby xt an AIS observation at time step t, where xt comprises\nthe position of the vessel (indicated by the latitude and the\nlongitude coordinates), its Speed Over Ground—SOG, and its\nCourse Over Ground—COG 2.\nxt ≜ [lat, lon, SOG, COG]T . (1)\nAn AIS vessel trajectory is then represented by a series\nof observations {xt0 , xt1 , ...xtT } where ti < tj if i <\nj. One can use some simple interpolation method to get\na series of T + 1 equally sampled observations x0:T ≜\n{xt0 , xt0+∆t, xt0+2∗∆t, ...,xt0+T∗∆t}. The time step ∆t is\nchosen such that the error inherited from the interpolation has a\nnegligible effect on downstream tasks. In this paper, we fix the\ntime step at 10 minutes and omit ∆t for the sake of notation\nsimplicity, i.e. xt0+n∗∆t ≜ xt+n.\nThe L-step-ahead prediction problem comes to predict the\ntrajectory xT+1:T+L ≜ {xT+1, xT+2, ...,xT+L} given T + 1\nobservations x0:T ≜ {x0, x1, ...,xT } up to time T. Given\nthe nature of the prediction problem, it naturally arises as the\nsampling of the following conditional distribution:\np(xT+1:T+L|x0:T ). (2)\nWe may point out that this probabilistic formulation also cov-\ners deterministic prediction models [14], [36], which reduce p\nto Dirac distributions.\nThere are two primary categories of approaches to AIS-\nbased vessel trajectory prediction. The first one relies on a\nstate-space formulation, which combines a dynamical prior\non vessel movements with a filtering method to infer or\nsample the posterior (2). Models following this approach have\ncertain limitations. Firstly, the dynamical prior often relies on\na simplistic model, such as the Curvilinear Motion Model\n(CMM) [37], which cannot account for complex patterns\nincluding turning points. Secondly, filtering methods, such as\nthe Kalman filter [37], [38] or the particle filter [11], are\nprone to error propagation issues. Consequently, they seem\nless suitable for medium-range prediction.\nIn recent years, the second approach, known as the learning-\nbased approach, has gained substantial popularity [39]. [40],\n[41], [42] leveraged LSTM (Long Short-Term Memory) and\nGRU (Gated Recurrent Unit) to learn the temporal patterns in\nx0:T . However, given the multi-path patterns exhibited in AIS\ndata, such schemes are likely to fail [43]. More sophisticated\nmodels take into account the interactions between vessels. [32]\nused a customized pooling layer—referred to as Collision-\nFree Social Pooling (CFSP), while [31] employed Graph\n2We let the reader refer to [35] for a more detailed presentation of AIS\ndata streams.\nConvolutional Neural Networks (GCN) to model the interac-\ntions between vessels in proximity. These models demonstrate\nimproved prediction performance in dense traffic scenarios\nwith relatively short prediction horizons, typically below one\nhour. However, in the open sea, where vessel density is\nsignificantly lower, and for medium-range horizons (spanning\nfrom a few hours to tens of hours), the impacts of the\ninteractions between vessels are less pronounced. Furthermore,\nsince the surrounding environment of a vessel may change as\nvessels enter or exit the considered zone, it is intractable to\nexplicitly model such interactions for these time horizons (see\nthe Appendix).\nTo address the heterogeneous and multimodal nature of AIS\ndata, several methods rely on clustering [12], [14], [18], [19],\n[44]. They assume that maritime traffic in a given area can\nbe represented as a graph, where each node corresponds to a\nwaypoint and each edge represents the maritime route between\ntwo nodes. The prediction problem then resorts to exploiting\na forecasting model over the defined graph. A rich literature\nexists and exploits among others the constant velocity model\nand the particle filter [12], Gaussian Processes [13] and neural\nnetworks [18], [19]. However, all those schemes face a com-\nmon limitation: they rely on a route-based representation of\nmaritime traffic, which is viable only when the traffic is highly\norganized and structured. In real life, a significant fraction\nof AIS trajectories cannot be assigned to predefined routes\n[43], [45], limiting the practical application of clustering-based\ntechniques in operational systems.\nIn this paper, we present a novel model for AIS-based vessel\ntrajectory prediction, referred to as TrAISformer. To tackle\nthe complexity and multimodality of AIS vessel trajectories,\nwe propose a new data representation and harness the mod-\neling capabilities of deep learning, specifically transformer\narchitectures [46]. Contrary to clustering-based models which\nconstrain the trajectories to a maritime traffic graph structure\n[12], [14], [18], [19], [44], TrAISformer is applicable to any\ntrajectory within the region of interest, without imposing con-\nstraints on an explicit graph of maritime routes. Additionally,\nwe re-frame the prediction as a classification-based learning\nproblem to best forecast the positions of maritime vessels\nseveral hours into the future.\nIII. P ROPOSED APPROACH\nIn this section, we detail the proposed approach. We in-\ntroduce a new representation of AIS data, derive a new loss\nfunction, and provide a brief introduction of the transformer\narchitecture used in TrAISformer.\nA. Discrete and sparse representation of AIS data\nOne of the primary challenges in trajectory prediction in\ngeneral, and AIS-based vessel trajectory prediction in partic-\nular, is the modeling of the heterogeneous and multimodal\nnature of motion data given relatively low-dimensional ob-\nservations. Here, we introduce a novel representation of AIS\ndata, which addresses the heterogeneity aspect. The multi-\nmodality part will be addressed in the next subsection with\na classification-based training loss.\nFig. 2: Proposed representation of AIS data: To overcome\nthe challenge of representing the heterogeneous and multi-\nmodal nature of motion data with relatively low-dimensional\nobservations in AIS-based vessel trajectory prediction, a new\nrepresentation of AIS data is proposed in this study. For each\nattribute att ∈ {lat, lon, SOG, COG}), the observed value\n(which is continuous) is discretized into a one-hot vector hatt\nt .\nEach hatt\nt is then associated with a high dimensional real-\nvalued embedding vector eatt\nt .\nThe most prevalent way to represent an AIS message is\nto use a 4-dimensional real-valued vector composed of the\nposition and the velocity of the vessel, as in (1).\nHowever, as discussed in [43] and [45], it is challeng-\ning to encode complex vessel movement patterns in this\nfeature space. A natural approach is to expand the feature\nspace to a higher dimensional one. Specifically, instead of\nmodeling the conditional probability distribution of the fu-\nture trajectory given the past p(xT+1:T+L|x0:T ), we con-\nsider p(eT+1:T+L|e0:T ), where et ∈ Rde represents a high-\ndimensional embedding vector of xt. Recently, variational\nautoencoders have been very successful in learning such\neffective mappings that encode et from xt, and decode xt\nfrom et [47]–[52]. However, when the dimension ofet is much\nhigher than that of xt, the training becomes extremely difficult\nand prone to overfitting.\nTo overcome the overfitting problem, we exploit the “four-\nhot” representation vector ht, defined in our previous works\n[43], [45]. Specifically, we discretize the latitude, the longi-\ntude, the SOG, and the COG into Nlat, Nlon, NSOG, and\nNCOG bins, respectively. We then build a one-hot vector for\neach attribute {lat, lon, SOG, COG}. The “four-hot” vector\nht is the concatenation of the four one-hot vectors.\nht ≜ [1lat\nt , 1lon\nt , 1SOG\nt , 1COG\nt ]T (3)\nwith 1att\nt (att ∈ {lat, lon, SOG, COG}) being the one-hot\nvector of att. The details are presented in Algorithm 1.\nEach attribute bin of ht will be associated with a high\ndimensional embedding vector, denoted as eatt\nt . The embed-\nding vector et of an AIS observation xt is the concate-\nnation of eatt\nt . This mapping is illustrated in Fig. 2. The\nproposed approach ensures that in the embedding space, only\nNlat × Nlon × NSOG × NCOG values of et will be used. By\nimposing this sparsity constraint, we effectively regularize the\nmapping and avoid overfitting when augmenting the original 4-\ndimensional AIS observation xt to a much higher dimensional\nspace of et [53]. An AIS vessel trajectory is then represented\nby e0:T ≜ {e0, e1, ...,eT }.\nNote that the mapping ht → et is one-to-one, and obtaining\nht from xt is a straightforward process. However, in the\nreverse direction, it is not possible find the exact xt from\nht because of the discretization. In this paper, we employ a\nsimplifying approximation where we use the mid-points of\nthe bins specified by ht to estimate xt. This approximation\nintroduces an error equivalent to half of the resolution of\nthe ht bins in the estimation of xt, even when the bins\nestimation is perfect. Nevertheless, we argue that this inherent\nerror is negligible for medium-range vessel trajectory predic-\ntion applications such as search and rescue, traffic control,\npath planning, and port congestion avoidance. To provide an\nillustration, let’s consider a resolution of 0.01 ◦ for lat and\nlon. The approximation introduces an error of around 0.15\nnautical miles (nmi). This level of error does not significantly\nimpact the aforementioned applications, as it remains well\nwithin acceptable limits.\nB. Transformer architecture\nAs depicted in Fig. 1, in order to forecast the trajectory of a\nvessel correctly, a prediction model needs to capture possible\nlong-term dependencies in the historical AIS observations. In\nthis regard, transformer neural networks [46] naturally arise\nas highly suitable candidates. In this work, we adopt a trans-\nformer architecture akin to the GPT models [54]. The model’s\narchitecture is briefly presented in the following paragraphs.\nInterested readers are encouraged to refer to [55] for a more\ncomplete and formal introduction to transformer.\nThe transformer network in TrAISformer consists of a\nseries of attention layers that are stacked together. Each layer\nfunctions as an auto-regressive model that employs the dot-\nproduct multiple-head self-attention mechanism:\nAttention(Q, K, V) = softmax\n\u0012QKT\n√de\n\u0013\nV, (4)\nwhere Q, K, Vare linear projections of the input sequence\n(which is {et} for the first layer, or the output sequence of\nthe previous layer for other layers), and de is the model size,\ni.e. the dimension of et. At each layer, the input sequence is\nprojected into a new space V , and the output of the attention\nblock is a weighted sum in V , where the weights signify\nthe relative contribution of each time step. These weights\nare computed as the softmax on the dot product of Q and\nK, normalized by √de. The projection operators of Q, K, V\nare learned during the training phase, and the calculation\nis performed in parallel. The parallel processing capability\nallows the model to directly retrieve information from multiple\npast time steps simultaneously. This is a critical advantage\ncompared to recurrent networks, where the model has to\nprocess data sequentially and may not be able to retrieve long-\nterm information.\nThe output of the transformer’s final layer is a vector lt with\nthe same dimension as ht. We will present in the next section\nhow TrAISformer uses this output to model p(hT+l|e0:T+l−1).\nC. Learning scheme\nIn the learning literature, trajectory prediction is commonly\nformulated as a regression problem where a model aims\nFig. 3: Example of multi-resolution “four-hot” vectors for\nAIS data: The model uses the fine-resolution vector ht in the\nembedding module (see Fig.2), while the loss function uses\nboth ht and a coarse-resolution h′\nt.\nto output the best possible continuous-valued eT+1:T+L (or\nxT+1:T+L) given the input e0:T (or x0:T ) [14], [18]. Within a\ndeterministic setting, the most common loss function is the\nmean square error, which measures the squared difference\nbetween the predicted and the actual values [14], [19], [56]:\nLMSE = 1\nL\nLX\nl=1\n||xpred\nT+l − xtrue\nT+l ||2\n2, (5)\nwhere ||.||2 denotes the Euclidean norm L2. However, this\nL2 loss function (which can be interpreted w.r.t. Gaussian\nassumption on the conditional likelihood p(eT+l|e0:T+l−1)\nor p(xT+l|x0:T+l−1)) may not be appropriate for posterior\ndistributions that exhibit multimodality, as illustrated by ves-\nsels’ trajectories in Fig.1. To explicitly account for multimodal\nposteriors, we propose a classification-based formulation that\ninvolves modeling p(eT:T+l|e0:T+l−1) as a concatenation of\nfour categorical distributions, each corresponding to an at-\ntribute {lat, lon, SOG, COG}. Specifically, because the map-\nping ht → et is one-to-one, we have:\np(hT+l|e0:T+l−1) = p(eT+l|e0:T+l−1). (6)\nAs ht is a “four-hot” vector, this transforms the prediction into\na classification problem with four heads, each corresponding\nto one component of the one-hot vector ht). Let us denote\npT+l ≜ p(hT+l|e0:T+l−1) = p(eT+l|e0:T+l−1), the loss\nfunction is defined as:\nLCE ≜\nLX\nl=1\nCE(hT+l, pT+l), (7)\nwith CE being the cross-entropy function. The details are\npresented in Algorithm 2. We demonstrate how the proposed\nloss function helps maintain the multimodal characteristics of\nthe data in Fig. 4.\nNote that ht is a discrete representation of the continuous\nxt. This discretization can be performed at different resolu-\ntions. We empirically observed that the prediction could be\nmarginally improved if we use a multi-resolution version of\nLCE as follows (see Fig. 3) :\nLCE =\nLX\nl=1\nCE(pT+l, hT+l) + βCE (p′\nT+l, h′\nT+l). (8)\nwhere p′\nT+l ≜ p(h′\nT+l|e0:T+l−1), h′\nT+l is a coarser version\nof hT+l, β is a scalar balancing the relative importance of the\ncoarse-resolution loss.\nThe training procedure’s specifics are outlined in Algorithm\n3. For the sake of notation simplicity, we present the training\nFig. 4: Illustration of the loss function LCE to account\nfor multimodal posterior : Let’s consider a scenario where\nat a specific waypoint, half of the vessels in the training set\nturn left and the other half turn right. The true distribution of\nthe longitude at the next time step forms a bimodal normal\ndistribution, depicted by the blue curve. If we use a real-\nvalued scalar to represent the longitude and use LMSE as\nthe loss function, the implicit distribution of the model is an\nunimodal Gaussian distribution. Consequently, the model tends\nto merge the two modes of the true distribution, as illustrated\nby the orange curve. By contrast, if we use a one-hot vector to\nrepresent the longitude and use LCE as the loss function, the\nimplicit distribution of the model is a categorical distribution.\nWith this distribution, the model preserves the two modes, as\nshown by the green curve.\non a per-series basis. In practice, the model processes the data\nin batches.\nThe proposed model is applied recursively. To predict a\nvessel position at time T + l, we sample a “four-hot” vector\nhpred\nT+l from p(hT+l|e0:T+l−1):\nhpred\nT+l ∼ p(hT+l|e0:T+l−1) (9)\nand compute the “pseudo-inverse” of the sampled ”four-hot”\nvector to output the new position xpred\nT+l . The latter is subse-\nquently fed into the network to sample similarly a position at\nthe next time step. We repeat this sampling procedure until\nwe achieve the desired trajectory length. Multiple runs of this\nsampling procedure can be performed for a given AIS vessel\ntrajectory to generate different possible predicted paths. This\nstochastic procedure allows us to address the fact that two\nvessels currently having similar movement patterns at present\nmay diverge in their trajectories at the next waypoint. The de-\ntails are presented in Algorithm 4. We demonstrate in Section\nIV that if we do not sample hpred\nT+l from p(hT+l|e0:T+l−1)\naccording to (9), the performance of the model will degrade.\nA sketch of the resulting TrAISformer architecture is shown\nin Fig. 5.\nIV. E XPERIMENTS AND RESULTS\nIn this section, we report the experimental results of our\nmodel on a real AIS dataset introduced in [18]. We include a\nbenchmarking w.r.t state-of-the-art methods for a prediction\nhorizon up to 15 hours. Additionally, we also present an\nFig. 5: Sketch of the TrAISformer architecture: each AIS\nobservation xt is discretized into a “four-hot” vector ht (for\nvisualization purposes, we illustrate a one-hot vector instead\nof a “four-hot” vector for ht). Subsequently, each ht is paired\nwith a high dimensional real-valued embedding vector et.\nThe sequence of embeddings the e0:t will be fed into a\ntransformer network to predict pt+1 ≜ p(ht+1|e0:t). During\nthe training phase, the model is optimized to minimize the\ncross-entropy loss between the true value ht+1 and pt+1. To\nenhance prediction accuracy, we introduce a “multi-resolution”\nloss. This involves calculating the cross-entropy at different\nspatial resolutions of ht+1. In the forecasting phase, we\ngenerate vessel positions recursively. We sample hpred\nt+1 from\npt+1, calculate the “pseudo-inverse” of it to derive xpred\nt+1 . The\npredicted xpred\nt+1 is fed back into the network to sample the\nnext position (as shown by the red path in the diagram).\nThis iterative process continues until we reach the desired\nprediction horizon L.\nablation study to assess the relevance of each component of the\nproposed model. To facilitate the reproducibility of the work in\nthis paper, we chose a publicly available AIS dataset and made\nthe code of the model available at https://github.com/CIA-\nOceanix/TrAISformer.\nA. Experimental set-up\nDataset: We tested TrAISformer on a public AIS dataset\nprovided by the Danish Maritime Authority (DMA) 3. The\ndataset comprises AIS observations of cargo and tanker vessels\nfrom January 01, 2019 to March 31, 2019. The Region of\nInterest (ROI) is a rectangle from (55.5 ◦, 10.3 ◦) to (58.0 ◦,\n13.0◦). Prior to preprocessing, the raw dataset contained\napproximately 712 million AIS messages. We used AIS data\nfrom January 01, 2019 to March 10, 2019 and from March 11,\n2019 to March 20, 2019 to train the model and tune the hyper-\nparameters, respectively. The test set comprises AIS data from\nMarch 21, 2019 to March 31, 2019. A subset of this dataset\nwas exploited in [18] to evaluate state-of-the-art models for\nAIS-based vessel trajectory prediction, including deep learning\nmodels.\n3https://dma.dk/safety-at-sea/navigational-information/ais-data\nAlgorithm 1: fourhot(xt, R, SOGmax, N).\nDescription: Create ”four-hot” vector.\nInput: AIS observation\nxt ≜ [lat, lon, SOG, COG]T ,\nthe limits of the ROI\nR ≜ [latmin, latmax, lonmin, lonmax]T ,\nSOGmax,\nthe numbers of bins\nN ≜ [Nlat, Nlon, NSOG, NCOG]T .\nOutput: “Four-hot” vector ht.\n// Create the one-hot vector for each\nattribute.\n1lat\nt = onehot(xlat\nt , latmin, latmax, Nlat)\n1lon\nt = onehot(xlon\nt , lonmin, lonmax, Nlon)\n1SOG\nt = onehot(xSOG\nt , 0,SOGmax, NSOG)\n1COG\nt = onehot(xCOG\nt , 0, 360, NCOG)\n// Concatenate the one-hot vectors\nht = [1lat\nt , 1lon\nt , 1SOG\nt , 1COG\nt ]T\nReturn: ht\nAlgorithm 2: ce loss(ht, lt, N).\nDescription: Calculate the cross-entropy loss LCE .\nInput: ”four-hot” vector ht,\nthe output of the transformer lt,\nthe numbers of bins N.\nOutput: the cross-entropy CE(ht, lt).\n// Split ht back into 4 one-hot\nvectors, each corresponding to an\nattribute of the AIS observation.\n1lat\nt , 1lat\nt , 1SOG\nt , 1COG\nt = split(ht, N)\n// Split lt into 4 heads.\nllat\nt , llon\nt , lSOG\nt , lCOG\nt = split(lt, N)\n// Calculate the cross-entropy for\neach head.\nplat\nt = CE(Categorical(logit = llat\nt ), 1lat\nt )\nplon\nt = CE(Categorical(logit = llon\nt ), 1lon\nt )\npSOG\nt = CE(Categorical(logit = lSOG\nt ), 1SOG\nt )\npCOG\nt = CE(Categorical(logit = lCOG\nt ), 1COG\nt )\n// Calculate ‘‘total’’ cross-entropy.\nce with logit(ht, lt) = plat\nt ∗ plon\nt ∗ pSOG\nt ∗ pCOG\nt\nReturn: ce with logit(ht, lt)\nData pre-processing : AIS data often contain outliers and\nmissing data, which can pose challenges to the prediction.\nIn the training phase, the presence of outliers and missing\ndata introduces additional noise and uncertainty, potentially\naffecting the convergence of the learning process. During the\nevaluation phase, missing data prevents us from calculating\nthe prediction errors, while outliers can lead to an inaccurate\nassessment of prediction accuracy. To mitigate the impact\nof outliers and missing data, we implemented the following\npreprocessing steps:\n• Remove AIS messages with unrealistic speed values\n(SOG ≥ 30 knots);\n• Remove moored or at-anchor vessels;\nAlgorithm 3: trAISformer train({x0:T+L}, Θ, R,\nSOGmax, N, β).\nDescription: Train TrAISformer.\nInput: The training set {x0:T+L},\nthe set of TrAISformer’s parameters Θ,\nthe limits of the ROI R,\nSOGmax,\nthe numbers of bins N,\ncoefficient β.\nOutput: The learned set of parameters Θ.\nfor x0:T+L in {x0:T+L} do\n// Create the \"four-hot\" vectors at\ndifferent resolutions.\nfor t in 0 : T + L do\nht = fourhot(xt, R, SOGmax, N)\nh′\nt = fourhot(xt, R, SOGmax, N/3)\nend\n// Get the embeddings and apply the\ntransformer.\ne0:T+L−1 = embedding(h0:T+L−1)\nl1:T+L = transformer(e0:T+L−1)\nl′\n1:T+L = conv1d(l1:T+L, kernel=\n[1/3, 1/3, 1/3]T , stride= 3)\n// Calculate the loss.\nLCE = 0\nfor l in 1 : L do\nce(ht, lt) = ce_loss(ht, lt, N)\nce(h′\nt, l′\nt) = ce_loss(h′\nt, l′\nt, N/3)\nLCE = LCE + ce(ht, lt) + β ∗ ce(h′\nt, l′\nt)\nend\n// Optimize Θ.\nΘ = AdamW(LCE , Θ, x0:T+L)\nend\nReturn: Θ\n• Remove AIS observations within 1 nautical mile distance\nto the coastline;\n• Split non-contiguous voyages into contiguous ones. A\ncontiguous voyage [43], [45] is a voyage whose the max-\nimum interval between two consecutive AIS messages is\nsmaller than a predefined value, here 2 hours;\n• Remove AIS voyages whose length is smaller than 20 or\nthose that last less than 4h;\n• Remove abnormal messages. An AIS message is con-\nsidered abnormal if the empirical speed (calculated by\ndividing the distance traveled by the corresponding inter-\nval between the two consecutive messages) is unrealistic,\nhere above 40 knots;\n• Down-sample AIS data with a sampling rate of 10-\nminute;\n• Split long voyages into shorter ones with a maximum\nsequence length of 20 hours.\nHyper-parameters: the results reported in this paper were\nobtained using a transformer architecture with 8 layers. Each\nlayer contains 8 attention heads. The resolution of the “four-\nhot” vector ht was set to 0.01 ◦ for lat and lon, 1 knot for\nSOG and 5◦ for COG. With this resolution, the corresponding\nAlgorithm 4: trAISformer predict(x0:T , Θ, R,\nSOGmax, N, L).\nDescription: Use TrAISformer to predict vessel\ntrajectory.\nInput: The initial segment of the trajectory to predict\nx0:T ,\nthe trained TrAISformer’s parameters Θ,\nthe limits of the ROI R,\nSOGmax,\nthe numbers of bins N,\nthe prediction horizon L.\nOutput: The predicted trajectory x0:T+L.\n// Create the \"four-hot\" vectors of\nthe initial segment.\nfor t in 0 : T do\nht = fourhot(xt, R, SOGmax, N)\nend\n// Get the embeddings of the initial\nsegment.\ne0:T = embedding(h0:T )\n// Iterate over the prediction\nhorizon.\nfor l in 1 : L do\nl1:T+l = transformer(e0:T+l−1)\n// Split lT+l into 4 heads.\nllat\nT+l, llon\nT+l, lSOG\nT+l , lCOG\nT+l = split(lT+l, N)\n// Create the categorical\ndistributions and sample hatt\nT+l\nfrom them.\nfor att in {lat, lon, SOG, COG} do\nhatt\nT+l ∼ Categorical(logit = latt\nT+l)\nend\n// Get the predicted hT+l, eT+l, and\nxT+l\nhT+l = [hlat\nT+l, hlon\nT+l, hSOG\nT+l , hCOG\nT+l ]T\neT+l = embedding(hT+l)\nxT+l = pseudo-inverse(hT+l)\nend\nReturn: x0:T+L\nsizes of elat\nt , elon\nt , eSOG\nt , eCOG\nt were 256, 256, 128 and 128\nfor the ROI reported in this paper. This resulted in a 768-\ndimensional embedding et. The coarse vector h′\nt was obtained\nby merging three consecutive bins of ht. We noticed that\nwhen we reduced or increased the resolution of ht by 2,\nthe difference in the results was negligible. The historical\nsequence length T was set to 3 hours and the prediction\nhorizon L was up to 15 hours. The model was trained using\nAdamW optimizer [57] with cyclic cosine decay learning rate\nscheduler [58]. The learning rate was set to 6e−4. Other\nimplementation details can be found in the GitHub repository\nthat we shared above. We trained the model on a single GTX\n1080 Ti GPU over 50 epochs with early stopping. In terms of\ncomputational complexity, it took ∼60 minutes to process 10\ndays of data in the test set, which suggests that the model can\nrun in real-time [59].\nBenchmark models : we compare the performance of\nTrAISformer against different state-of-the-art deep learning\nmodels: LSTM seq2seq [14], convolutional seq2seq [60],\nseq2seq with attention [18], [19], GeoTrackNet [45].\nIt is challenging to conduct a fair quantitative comparison\nwith clustering-based methods [12], [14], [18], [19], [36],\n[44]. First, those methods did not state clearly how to address\nclustering noise and small clusters. Second, most of them use\na DBSCAN clustering, which is sensitive to hyper-parameters\n[12], [19], [36]. Different sets of hyper-parameters could lead\nto very different results. Third, as mentioned in Section II,\nclustering-based approaches, such as [19], assume vessels’\ntrajectories belong to a predefined graph of maritime routes.\nThis assumption does not hold for the considered dataset. This\nis the reason why [18] restricted their analysis to a subset of the\nwhole dataset. That subset is composed of tankers’ trajectories\nfor a few predefined routes 4. Though they only involve a\nsubset of trajectories compared with the other benchmarked\napproaches, we regard the resulting score in [18] as a score\nunder a best-case scenario for clustering-based methods for\nthe considered ROI.\nAs the benchmarked models are not public, we conducted\nan independent implementation and fine-tuned each model to\nget optimal outcomes.\nEvaluation criteria : for each prediction, the prediction\nerror at time step t is calculated as the haversine distance\nbetween the true position and the predicted one:\ndk = 2R arcsin\n\u0012q\nsin2(¯ϕ) + cos(ϕ1)cos(ϕ2)sin2(¯λ)\n\u0013\n,\n(10)\nwith R the radius of the Earth, ¯ϕ ≜ 0.5(ϕ2 − ϕ1), ¯λ ≜\n0.5(λ2 −λ1), ϕ1 and ϕ2 denote the latitudes, λ1 and λ2 denote\nthe longitudes of the predicted position and the true position,\nrespectively.\nWe used a best-of-N criterion, i.e. for each model, we\nsampled N predictions for each target trajectory and reported\nthe best result. In this paper, N = 16. This criterion allows us\nto account for the effect of multimodality.\nB. Results\nTable I shows the average prediction errors evaluated at\n1, 2, and 3 hours ahead horizons. The ROI contains several\nwaypoints, rendering prediction for time horizons ranging\nfrom 1 to 15 hours highly challenging. In the case of\nincorrect prediction of turning directions at the waypoints,\nthe prediction errors of a model increase significantly, often\nabove a few nautical miles (nmi), as demonstrated by the\nbenchmarked models in Table I. TrAISformer outperforms all\nthe benchmarked models by a large margin. For instance, for\nthe 2-hour-ahead prediction, it is the only model with an\naverage error below one nautical mile (41% better than the\nsecond best model GeoTracknet). These results confirm the\ncapability of TrAISformer to capture the multimodal nature of\nvessel trajectories, extract pertinent long-term dependencies,\nand deliver accurate predictions of vessel paths.\n4We may point out that, contrary to the whole dataset, that subset has not\nbeen made available.\nTrAISformer improves by a factor of 2 the performance\nof the model proposed in [18], which is one of the current\nstate-of-the-art schemes, with respective scores of 0.94 nmi\nand 1.93 nmi. We may recall that the performance of this\nclustering-based scheme refers to a best-case scenario, as it\nonly involves tankers’ trajectories for a few maritime routes in\nthe case-study region. We also note that the direct application\nof state-of-the-art deep learning schemes on the 4-dimensional\nAIS feature vector, namely LSTM seq2seq [14], convolutional\nseq2seq [60], seq2seq with attention [18], [19], transformer\n[46], [54] (see Table. II) leads to poor prediction performances\n(mean error greater than 6 nmi for a 2-hour-ahead prediction).\nThe second best approach is our previous work GeoTrackNet\n[43], [45]. It shares two key features with TrAISformer: i)\na similar sparse high-dimensional representation of AIS data\nand ii) a probabilistic neural-network-based learning scheme.\nHowever, GeoTrackNet uses a Variational Recurrent Neural\nNetwork (VRNN) [61] instead of a transformer architecture to\ncapture the temporal patterns in the AIS data. The improved\nperformance of TrAISformer over GeoTrackNet suggests that\ntransformers may be a better neural architecture for AIS data\nthan VRNN.\nTo further highlight the importance of the probabilis-\ntic feature of TrAISformer, we report the performance\nof a deterministic version—denoted as TrAISformer No-\nStoch—of TrAISformer. This model outputs the ”four-\nhot” vector with the highest probability, i.e. hpred\nT+l =\nargmaxh p(hT+l|e0:T+l−1), instead of sampling hpred\nT+l like\nin (9). The decrease in the prediction performance (from\n0.94 to 2.88 for the 2-hour-ahead prediction) demonstrates the\nimportance of a multimodal representation of vessels’ trajecto-\nries for the considered case-study. As pointed out previously,\ntwo vessels departing from the same port, having the same\ncurrent position and velocity, may follow different paths at\nthe next waypoint, making it impossible for the prediction\nmodel to produce correct deterministic forecasts all the time.\nModels that are capable of predicting multiple possibilities are\nmore relevant. Yet, the deterministic version of TrAISformer\nis still much better than standard seq2seq models, which again\nstresses the relevance of the transformer architecture as well\nas of the considered representation of AIS feature vector.\nIn maritime downstream tasks, a crucial factor to consider\nwhen using a prediction model is the maximum meaningful\nprediction horizon, which is the longest time horizon where\na prediction is still useful. In some scenarios, such as search\nand rescue operations, a prediction is deemed helpful if the\nprediction error is smaller than the visibility, which is generally\nassumed to be 10 nmi under clear weather conditions [62].\nFig. 6 depicts such prediction horizons of the benchmarked\nmodels. In the best case scenario, TrAISformer can extend the\nprediction horizon by a factor of ∼5.8 compared with current\nstate-of-the-art methods (9.67h for TrAISformer vs. 1.67h for\nLSTM seq2seq att).\nFig. 7 displays some examples of the predictions made\nby TrAISformer and the other benchmarked methods.\nTrAISformer successfully samples realistic turning directions\nto forecast the potential paths taken by vessels. We recall\nTABLE I: Mean prediction performance of the bench-\nmarked models (in nautical miles) .\nModel 1h 2h 3h\nLSTM seq2seq 5.83 8.39 11.64\nConv seq2seq 4.23 6.77 9.66\nLSTM seq2seq att 3.35 6.41 9.65\nClustering LSTM seq2seq att1[18] 0.78 1.93 3.66\nGeoTrackNet [45] 0.72 1.59 2.67\nTrAISformer 0.48 0.94 1.64\nTrAISformer No-Stoch 1.28 2.88 5.02\n1 The result from [18] was evaluated on a subset of the whole\ndataset, which comprises only tankers’ trajectories for a prede-\nfined number of maritime routes. As such, this is regarded as a\nbest-case scenario for clustering-based models.\nFig. 6: Prediction performance w.r.t. prediction time hori-\nzon: we plot for each benchmarked model the mean prediction\nperformance for prediction time horizons from 10 minutes to\n15 hours. We also highlight the time horizon up to which the\nperformance of a given model remains below the maximum\nvisibility under good weather conditions (i.e., 10 nmi).\nhere that for probabilistic models such as GeoTrackNet,\nTrAISformer, we report among 16 sampled trajectories the\none closest to the real trajectory. We may highlight that the\nmodel applies not only to the main maritime routes (the first\nthree columns) but also to less frequent ones (the last column).\nBy contrast, clustering-based methods struggle in such cases.\nThe four examples show the relatively poor performance of\nthe direct application of sequence-to-sequence deep learning\nmodels. GeoTrackNet samples realistic trajectories for the first\nthree examples, though not as close to the real ones as the ones\npredicted by TrAISformer. However, for the last example, it\nperforms poorly, while TrAISformer still succeeds in sampling\na realistic path.\nWe further analyze in Fig. 8 the behavior of TrAISformer\nthrough the activation of an attention block in the first layer\nof TrAISformer for the trajectory shown in Fig. 1. Each\nrow shows the relative importance of each time step in the\npredicted output. Some remarks raised from this analysis:\n• On straight lines, only the information from recent time\nLSTM seq2seq att\nGeoTrackNet\nStandard transformer\nWithout ht\nWithout LCE\nTrAISformer\nFig. 7: Examples of AIS-based vessel trajectory predictions : each column depicts the predictions of a given real vessel\ntrajectory. The rows correspond to the various models used for benchmarking. For each example, we display the AIS\nobservations x0:T used as the input by all models —, the real vessel trajectory -- , and the predicted trajectory • .\nFig. 8: Relative importance of each time step in the\nprediction: Visualization of the activation of one attention\nblock of TrAISformer for the trajectory shown in Fig. 1.\nHorizontal axis: input time step; vertical axis: output time step.\nEach row shows which parts of the input that the model pays\nattention to in order to compute the output at the corresponding\ntime step.\nsteps is used to predict the next time step, which is similar\nto constant velocity models [63];\n• At the waypoints, the model needs to retrieve information\nfrom much earlier time steps, especially at the previous\nwaypoints to predict the next time step. For example,\nrow 40 (the red rectangle) depicts the attention weights\nto compute the prediction at E. The model pays more\nattention to the inputs at A, B, C, D, and E. One intuitive\nexplanation is that the model needs to know where the\nvessel comes from (points A, B, C), what the movement\npattern of the vessel is in the current segment (point D),\nas well as the current position and velocity (point E) to\nguess the movement pattern to come.\nAs such, this example demonstrates the ability of TrAISformer\nto extract relevant long-term dependencies to predict vessel\ntrajectories.\nC. Ablation study\nTo evaluate the significance of the different components of\nTrAISformer architecture, we conducted an ablation study:\n• Firstly, we removed et and ht to demonstrate the\nsignificance of the high-dimensional encoding. This is\nequivalent to applying directly a GPT model [54] to 4-\ndimensional AIS data streams.\n• Secondly, we kept et but removed ht to assess the rele-\nvance of the sparsity constraint. The embedding xt → et\nin this model is a MultiLayer Perceptron (MLP).\n• Finally, we tested a model with the same architecture as\nTrAISformer but used a regression loss as the training loss\nto demonstrate the criticality of the classification loss.\nThe results in Tab. II show that all the ablated models lead to\nsignificantly worse performance compared with TrAISformer.\nInterestingly, the performance degradation is in the same\norder of magnitude for the three ablated models, though\nthe impact of the classification-based loss is slightly greater.\nOverall, these results highlight the importance of integrating\nall the components of our architecture for achieving the best\nprediction performance.\nV. C ONCLUSIONS AND FUTURE WORK\nIn this paper, we presented a novel model—referred to as\nTrAISformer, for vessel trajectory prediction using AIS data.\nThe model uses an augmented, sparse, and high-dimensional\nrepresentation of AIS data as well as a state-of-the-art trans-\nformer network architecture to learn complex patterns in\nvessel trajectories. Using a classification-based training loss,\nTrAISformer can capture the multimodal nature of trajectory\ndata. Experiments on real, public AIS data show TrAISformer\noutperforms existing methods by a significant margin. With\na 9-hour-ahead prediction error below 10 nmi on a real AIS\ndataset in a case-study region involving dense and complex\nmaritime traffic patterns, these results open new research\navenues for various applications such as search and rescue,\nport congestion avoidance, and maritime surveillance.\nThrough an ablation study, we have shown that all the\nabove-mentioned components of TrAISformer have critical\nroles in the reported performance. Though transformer ar-\nchitectures are likely not fully explainable [64], [65], we\nhave also shown that the intermediate attention weights of\nthe transformer architecture provide a natural way to explore\nhow TrAISformer exploits the past AIS data to compute its\npredictions of the future trajectory. This supports that the\nlearned transformer representation could be of interest beyond\nthe considered application to prediction tasks.\nFuture work could further improve the architecture and\ndevelop the applications of TrAISformer framework. Among\nothers, we may cite the learning of conditional TrAISformer\nw.r.t. weather conditions as the latter clearly impact vessels’\nmovement. While we currently omit the influence of ves-\nsel interactions, future work could study the possibility of\nintegrating those interactions into the model. We may also\nstress that the proposed TrAISformer architecture is signifi-\ncantly more complex (see Tab. ??) with ∼300 times more\nparameters than the second most complex architecture among\nthe benchmarked ones. While the greater complexity likely\ncontributes to the significant gain, recent advances in model\ncompression techniques, such as Neural Network Pruning [66]\nand Knowledge Distillation [67], suggest that we could reduce\nthe model’s size typically by a factor of tens to hundreds\nwithout compromising its performance. This would promote\nthe assessment and adoption of TrAISformer in operational\nsystems. The combination of TrAISformer with other learning-\nbased modules for classification and anomaly detections [45]\nis also of interest. Recent advances in the exploitation of AIS\ndata for the inversion of sea surface parameters [68], [69] may\nalso be an appealing line of research for our future work.\nAPPENDIX\nIn this appendix, we present a mathematical demonstration\nexplaining why pedestrian and vehicle trajectory prediction\nTABLE II: Mean prediction performance (in nautical miles) of the models in the ablation study.\nModel AIS data representation Embedding xt → ek Loss function 1h 2h 3h\nWithout et and ht (standard transformer) [lat, lon, SOG, COG]T None LMSE 4.75 8.36 11.40\nWithout ht [lat, lon, SOG, COG]T → et MLP LMSE 5.02 9.69 15.04\nWithout the classification loss LCE “four-hot“ vector → et Via ht LMSE 5.53 10.64 16.06\nTrAISformer “four-hot“ vector → et Via ht LCE 0.48 0.94 1.64\nmodels are not directly applicable to medium-range AIS-based\nvessel trajectory prediction.\nLet us denote by xsi\nt an observation of an agent si at time\nt. For instance, in pedestrian and vehicle trajectory prediction,\nsi can represent either a pedestrian or a vehicle, and xsi\nt\ncorresponds to their respective positions on the map. In AIS\ntrajectory prediction, si represents a vessel, and xsi\nt represents\nits AIS message. The trajectory of agent si from t1 to t2\n(t2 > t1) is then represented by a sequence of observations\nxsi\nt1:t2 = {xsi\nt1 , xsi\nt1+1, ...,xsi\nt2 }. At time t, we denote the group\nof other agents in the vicinity of si as Vi\nt, and their historical\ntrajectories are denoted as xVi\nt\n0:t .\nIn the context of this paper, using these notations, trajectory\nprediction refers to forecasting the trajectory of an agent si\nfor L timesteps ahead, based on the historical observations\nof this agent and the others in the vicinity up to time T, by\nmaximizing the likelihood:\np(xsi\nT+1:T+L|xsi\n0:T , xVi\nt\n0:T ). (11)\nHere we use p in the broad sense, which includes deterministic\nmodels.\nThe conditioning side of (11) encompasses two crucial\ncomponents: the xsi\n0:T component embeds the intention of\nthe agent, while the xVi\nt\n0:T part embeds the interactions with\nthe environment. State-of-the-art methods for pedestrian and\nvehicle trajectory prediction are centered on effectively mod-\neling and integrating these two terms. Prominent examples\ninclude S-LSTM [26], S-GAN [26], S-ATTN [27], SoPhie\n[28], MATF [29], Trajection [70], Trajectron++ [30], etc.\nThose models leverage deep neural networks such as LSTM or\nGAN (Generative Adversarial Network) to capture correlations\nin historical data, and some pooling techniques to embed the\ninteractions between agents. This idea has been adopted for\nshort-term AIS-based vessel trajectory prediction [31], [32].\nAlthough those methods have shown promising results on the\ncorresponding datasets, they are not suitable for medium-range\nvessel trajectory prediction. First, the prediction horizons con-\nsidered in those works are from a few seconds to a few min-\nutes, which are too short for maritime applications. Second,\nthose works address different types of maneuvers, of which the\nmovement of an agent depends highly on the interactions with\nother agents and the surrounding environment. For maritime\ntraffic contexts, and at medium-range time horizons, the path\nthat a vessel will make depends mainly on where it wants to\ngo. It is barely affected by the interactions with other vessels in\nthe vicinity at the current moment. Mathematically, this means\nat time T we have the approximation:\nFig. 9: Illustration of the intractability of the modeling\nof the interactions between agents in medium-range tra-\njectory prediction . Consider the scenario where we aim to\npredict the medium-range trajectory of agent s1 (denoted by\nthe green dot). At time T, there are six other agents (s2, ..., s6)\nwithin its vicinity (enclosed by the dashed rectangle). The\ninteractions between s1 and these agents are depicted by the\ndouble-headed arrows. As we project into the medium-range\nfuture at time T + l − 1, s2 and s6 will have moved away\nfrom s1; and a new, unknown agent s7 (denoted by the red\ndot) may appear near s1. The prediction model would have\nno knowledge of this new vicinity, making the modeling of\ninteractions between agents intractable.\np(xsi\nT+l|xsi\n0:T , xVi\nt\n0:T ) ≈ p(xsi\nT+l|xsi\n0:T )\n\f\f\f\nl>>1\n. (12)\nOne may argue that we could use the predicted value of\nx\nVi\nT+l−1\n0:T+l−1 and xsi\n0:T+l−1 to estimate xsi\nT+l. However, in order\nto predict x\nVi\nT+l−1\n0:T+l−1, we need to predict the trajectory of all the\nagents in the vicinity of si at T + l − 1. This is an expensive\nor even intractable approach. For example, an unknown agent\nmay join the ROI, as illustrated in Fig. 9).\nIt’s important to note that if we remove xVi\nt\n0:T from (11),\nthis objective function simplifies (2), which is the objective\nfunction used in medium-range AIS-based vessel trajectory\nprediction. Likewise, if we remove the module that encodes\nthe interactions between agents in some of the pedestrian\nand vehicle trajectory prediction models mentioned above, we\nget models that have similar architectures to those designed\nfor AIS trajectory prediction. For example, if we remove the\ninteractions between agents part in Trajectron [70], it becomes\nan LSTM seq2seq model.\nREFERENCES\n[1] Z. Ou and J. Zhu, “AIS Database Powered by GIS Technology for\nMaritime Safety and Security,” The Journal of Navigation, vol. 61, no. 4,\npp. 655–665, Oct. 2008, publisher: Cambridge University Press.\n[2] I. Varlamis, K. Tserpes, and C. Sardianos, “Detecting Search and Rescue\nMissions from AIS Data,” in 2018 IEEE 34th International Conference\non Data Engineering Workshops (ICDEW), Apr. 2018, pp. 60–65, iSSN:\n2473-3490.\n[3] T. Fabbri, R. Vicen-Bueno, R. Grasso, G. Pallotta, L. M. Millefiori,\nand L. Cazzanti, “Optimization of surveillance vessel network planning\nin maritime command and control systems by fusing METOC & AIS\nvessel traffic information,” in OCEANS 2015 - Genova, May 2015, pp.\n1–7.\n[4] E. Tu, G. Zhang, L. Rachmawati, E. Rajabally, and G.-B. Huang, “Ex-\nploiting AIS Data for Intelligent Maritime Navigation: A Comprehensive\nSurvey,”IEEE Transactions on Intelligent Transportation Systems, 2017.\n[5] X. K. Dang, H. N. Truong, and V . D. Do, “A path planning control\nfor a vessel dynamic positioning system based on robust adaptive fuzzy\nstrategy,” Automatika, vol. 63, no. 3, pp. 580–592, Jul. 2022.\n[6] X.-P. Nguyen, X.-K. Dang, V .-D. Do, J. M. Corchado, and H.-N. Truong,\n“Robust Adaptive Fuzzy-Free Fault-Tolerant Path Planning Control for a\nSemi-Submersible Platform Dynamic Positioning System With Actuator\nConstraints,” IEEE Transactions on Intelligent Transportation Systems,\nvol. 24, no. 11, pp. 12 701–12 715, Nov. 2023, conference Name: IEEE\nTransactions on Intelligent Transportation Systems.\n[7] J. M. Mou, C. v. d. Tak, and H. Ligteringen, “Study on collision\navoidance in busy waterways by using AIS data,” Ocean Engineering,\nvol. 37, no. 5, pp. 483–490, Apr. 2010.\n[8] C. Liu, J. Liu, X. Zhou, Z. Zhao, C. Wan, and Z. Liu, “AIS data-driven\napproach to estimate navigable capacity of busy waterways focusing\non ships entering and leaving port,” Ocean Engineering, vol. 218, p.\n108215, Dec. 2020.\n[9] M. J. Kang, S. Zohoori, M. Hamidi, and X. Wu, “Study of narrow\nwaterways congestion based on automatic identification system (AIS)\ndata: A case study of Houston Ship Channel,” Journal of Ocean\nEngineering and Science, Oct. 2021.\n[10] G. Soldi, D. Gaglione, N. Forti, A. Di Simone, F. C. Daffin ˜A , G. Bottini,\nD. Quattrociocchi, L. M. Millefiori, P. Braca, S. Carniel, P. Willett,\nA. Iodice, D. Riccio, and A. Farina, “Space-based Global Maritime\nSurveillance. Part II: Artificial Intelligence and Data Fusion Techniques,”\nIEEE Aerospace and Electronic Systems Magazine, vol. 36, no. 9, pp.\n30–42, Sep. 2021, arXiv:2011.11338 [eess].\n[11] B. Ristic, B. La Scala, M. Morelande, and N. Gordon, “Statistical\nanalysis of motion patterns in AIS Data: Anomaly detection and motion\nprediction,” in 2008 11th International Conference on Information\nFusion, Jun. 2008, pp. 1–7.\n[12] F. Mazzarella, V . F. Arguedas, and M. Vespe, “Knowledge-based vessel\nposition prediction using historical AIS data,” in 2015 Sensor Data\nFusion: Trends, Solutions, Applications (SDF), Oct. 2015, pp. 1–6.\n[13] H. Rong, A. P. Teixeira, and C. Guedes Soares, “Ship trajectory\nuncertainty prediction based on a Gaussian Process model,” Ocean\nEngineering, vol. 182, pp. 499–511, Jun. 2019.\n[14] N. Forti, L. M. Millefiori, P. Braca, and P. Willett, “Prediction oof Vessel\nTrajectories From AIS Data Via Sequence-To-Sequence Recurrent Neu-\nral Networks,” in ICASSP 2020 - 2020 IEEE International Conference\non Acoustics, Speech and Signal Processing (ICASSP), May 2020, pp.\n8936–8940, iSSN: 2379-190X.\n[15] T. A. V olkova, Y . E. Balykina, and A. Bespalov, “Predicting ship\ntrajectory based on neural networks using AIS data,” Journal of Marine\nScience and Engineering, vol. 9, no. 3, p. 254, 2021, iSBN: 2077-1312\nPublisher: MDPI.\n[16] B. Murray and L. P. Perera, “Ship behavior prediction via trajectory\nextraction-based clustering for maritime situation awareness,” Journal\nof Ocean Engineering and Science, Mar. 2021.\n[17] J. Park, J. Jeong, and Y . Park, “Ship trajectory prediction based on bi-\nLSTM using spectral-clustered AIS data,” Journal of Marine Science\nand Engineering, vol. 9, no. 9, p. 1037, 2021, iSBN: 2077-1312\nPublisher: MDPI.\n[18] S. Capobianco, L. M. Millefiori, N. Forti, P. Braca, and P. Willett,\n“Deep Learning Methods for Vessel Trajectory Prediction based on\nRecurrent Neural Networks,” IEEE Transactions on Aerospace and\nElectronic Systems, pp. 1–1, 2021, conference Name: IEEE Transactions\non Aerospace and Electronic Systems.\n[19] B. Murray and L. P. Perera, “An AIS-based deep learning framework\nfor regional ship behavior prediction,” Reliability Engineering & System\nSafety, p. 107819, May 2021.\n[20] L. M. Millefiori, G. Pallotta, P. Braca, S. Horn, and K. Bryan, “Validation\nof the Ornstein-Uhlenbeck route propagation model in the Mediterranean\nSea,” in OCEANS 2015 - Genova, May 2015, pp. 1–6.\n[21] L. M. Millefiori, P. Braca, K. Bryan, and P. Willett, “Modeling vessel\nkinematics using a stochastic mean-reverting process for long-term\nprediction,” IEEE Transactions on Aerospace and Electronic Systems,\nvol. 52, no. 5, pp. 2313–2330, Oct. 2016.\n[22] A. Rudenko, L. Palmieri, M. Herman, K. M. Kitani, D. M. Gavrila,\nand K. O. Arras, “Human motion trajectory prediction: a survey,” The\nInternational Journal of Robotics Research, vol. 39, no. 8, pp. 895–935,\nJul. 2020, publisher: SAGE Publications Ltd STM.\n[23] H. Zhao, J. Gao, T. Lan, C. Sun, B. Sapp, B. Varadarajan, Y . Shen,\nY . Shen, Y . Chai, C. Schmid, C. Li, and D. Anguelov, “TNT: Target-\ndriven Trajectory Prediction,” in Proceedings of the 2020 Conference on\nRobot Learning. PMLR, Oct. 2021, pp. 895–904, iSSN: 2640-3498.\n[24] F. Leon and M. Gavrilescu, “A Review of Tracking and Trajectory\nPrediction Methods for Autonomous Driving,” Mathematics, vol. 9,\nno. 6, p. 660, Jan. 2021, number: 6 Publisher: Multidisciplinary Digital\nPublishing Institute.\n[25] J. Gu, C. Sun, and H. Zhao, “DenseTNT: End-to-End Trajectory\nPrediction From Dense Goal Sets,” 2021, pp. 15 303–15 312.\n[26] A. Gupta, J. Johnson, L. Fei-Fei, S. Savarese, and A. Alahi, “Social\nGAN: Socially Acceptable Trajectories With Generative Adversarial\nNetworks,” 2018, pp. 2255–2264.\n[27] A. Vemula, K. Muelling, and J. Oh, “Social Attention: Modeling\nAttention in Human Crowds,” in 2018 IEEE International Conference\non Robotics and Automation (ICRA), May 2018, pp. 4601–4607, iSSN:\n2577-087X.\n[28] A. Sadeghian, V . Kosaraju, A. Sadeghian, N. Hirose, H. Rezatofighi, and\nS. Savarese, “SoPhie: An Attentive GAN for Predicting Paths Compliant\nto Social and Physical Constraints,” 2019, pp. 1349–1358.\n[29] T. Zhao, Y . Xu, M. Monfort, W. Choi, C. Baker, Y . Zhao, Y . Wang,\nand Y . N. Wu, “Multi-Agent Tensor Fusion for Contextual Trajectory\nPrediction,” 2019, pp. 12 126–12 134.\n[30] T. Salzmann, B. Ivanovic, P. Chakravarty, and M. Pavone, “Trajec-\ntron++: Dynamically-Feasible Trajectory Forecasting With Heteroge-\nneous Data,” arXiv:2001.03093 [cs], Jan. 2021, arXiv: 2001.03093.\n[31] R. W. Liu, M. Liang, J. Nie, Y . Yuan, Z. Xiong, H. Yu, and N. Guizani,\n“STMGCN: Mobile Edge Computing-Empowered Vessel Trajectory\nPrediction Using Spatio-Temporal Multigraph Convolutional Network,”\nIEEE Transactions on Industrial Informatics, vol. 18, no. 11, pp. 7977–\n7987, Nov. 2022, conference Name: IEEE Transactions on Industrial\nInformatics.\n[32] R. W. Liu, M. Liang, J. Nie, W. Y . B. Lim, Y . Zhang, and M. Guizani,\n“Deep Learning-Powered Vessel Trajectory Prediction for Improving\nSmart Traffic Services in Maritime Internet of Things,” IEEE Transac-\ntions on Network Science and Engineering, vol. 9, no. 5, pp. 3080–3094,\nSep. 2022, conference Name: IEEE Transactions on Network Science\nand Engineering.\n[33] P. Coscia, P. Braca, L. M. Millefiori, F. A. N. Palmieri, and P. Willett,\n“Multiple Ornstein-Uhlenbeck Processes for Maritime Traffic Graph Re-\npresentation,” IEEE Transactions on Aerospace and Electronic Systems,\npp. 1–1, 2018.\n[34] I. Varlamis, K. Tserpes, M. Etemad, A. S. J ˜Aºnior, and S. Matwin,\n“A Network Abstraction of Multi-vessel Trajectory Data for Detecting\nAnomalies.” in EDBT/ICDT Workshops, 2019.\n[35] R. Bosnjak, L. Simunovic, and Z. Kavran, “Automatic identification\nsystem in maritime traffic and error analysis,” Transactions on maritime\nscience, vol. 1, no. 02, pp. 77–84, 2012, iSBN: 1848-3305 Publisher:\nPomorski fakultet u Splitu.\n[36] Y . Suo, W. Chen, C. Claramunt, and S. Yang, “A Ship Trajectory Predic-\ntion Framework Based on a Recurrent Neural Network,”Sensors, vol. 20,\nno. 18, p. 5133, Jan. 2020, number: 18 Publisher: Multidisciplinary\nDigital Publishing Institute.\n[37] L. P. Perera, P. Oliveira, and C. G. Soares, “Maritime Traffic Monitoring\nBased on Vessel Detection, Tracking, State Estimation, and Trajectory\nPrediction,” IEEE Transactions on Intelligent Transportation Systems,\nvol. 13, no. 3, pp. 1188–1200, Sep. 2012.\n[38] S. Fossen and T. I. Fossen, “Extended Kalman Filter Design and Motion\nPrediction of Ships Using Live Automatic Identification System (AIS)\nData,” in 2018 2nd European Conference on Electrical Engineering and\nComputer Science (EECS), Dec. 2018, pp. 464–470.\n[39] X. Zhang, X. Fu, Z. Xiao, H. Xu, and Z. Qin, “Vessel Trajectory Pre-\ndiction in Maritime Transportation: Current Approaches and Beyond,”\nIEEE Transactions on Intelligent Transportation Systems, vol. 23, no. 11,\npp. 19 980–19 998, Nov. 2022, conference Name: IEEE Transactions on\nIntelligent Transportation Systems.\n[40] C. Wang, H. Ren, and H. Li, “Vessel trajectory prediction based on\nAIS data and bidirectional GRU,” in 2020 International Conference on\nComputer Vision, Image and Deep Learning (CVIDL), Jul. 2020, pp.\n260–264.\n[41] W. Li, C. Zhang, J. Ma, and C. Jia, “Long-term Vessel Motion\nPredication by Modeling Trajectory Patterns with AIS Data,” in 2019\n5th International Conference on Transportation Information and Safety\n(ICTIS), Jul. 2019, pp. 1389–1394.\n[42] H. Tang, Y . Yin, and H. Shen, “A model for vessel trajec-\ntory prediction based on long short-term memory neural net-\nwork,” Journal of Marine Engineering & Technology , vol. 0,\nno. 0, pp. 1–10, Sep. 2019, publisher: Taylor & Francis eprint:\nhttps://doi.org/10.1080/20464177.2019.1665258.\n[43] D. Nguyen, R. Vadaine, G. Hajduch, R. Garello, and R. Fablet, “A\nMulti-task Deep Learning Architecture for Maritime Surveillance using\nAIS Data Streams,” in 2018 IEEE International Conference on Data\nScience and Advanced Analytics (DSAA), Oct. 2018.\n[44] G. Pallotta, M. Vespe, and K. Bryan, “Vessel Pattern Knowledge\nDiscovery from AIS Data: A Framework for Anomaly Detection and\nRoute Prediction,” Entropy, vol. 15, no. 6, pp. 2218–2245, Jun. 2013.\n[45] D. Nguyen, R. Vadaine, G. Hajduch, R. Garello, and R. Fablet,\n“GeoTrackNet-A Maritime Anomaly Detector using Probabilistic Neural\nNetwork Representation of AIS Tracks and A Contrario Detection,”\nIEEE Transactions on Intelligent Transportation Systems, Feb. 2021.\n[46] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\n˚A. Kaiser, and I. Polosukhin, “Attention is All you Need,” in Advances\nin Neural Information Processing Systems, vol. 30. Curran Associates,\nInc., 2017.\n[47] Y . LeCun, Y . Bengio, and G. Hinton, “Deep learning,” Nature, vol. 521,\nno. 7553, pp. 436–444, May 2015.\n[48] I. Goodfellow, Y . Bengio, and A. Courville, Deep learning. MIT press,\n2016.\n[49] D. P. Kingma and M. Welling, “Auto-Encoding Variational Bayes,”\narXiv:1312.6114 [cs, stat], Dec. 2013, arXiv: 1312.6114.\n[50] D. J. Rezende and S. Mohamed, “Variational inference with normalizing\nflows,” arXiv preprint arXiv:1505.05770, 2015.\n[51] Y . Pu, Z. Gan, R. Henao, X. Yuan, C. Li, A. Stevens, and L. Carin,\n“Variational Autoencoder for Deep Learning of Images, Labels and\nCaptions,” in Advances in Neural Information Processing Systems 29,\nD. D. Lee, M. Sugiyama, U. V . Luxburg, I. Guyon, and R. Garnett, Eds.\nCurran Associates, Inc., 2016, pp. 2352–2360.\n[52] A. Vahdat and J. Kautz, “NV AE: A Deep Hierarchical Variational\nAutoencoder,” in Advances in Neural Information Processing Systems,\nvol. 33. Curran Associates, Inc., 2020, pp. 19 667–19 679.\n[53] A. Ng, “Sparse autoencoder,” CS294A Lecture notes, vol. 72, no. 2011,\npp. 1–19, 2011.\n[54] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, “Improving\nLanguage Understanding by Generative Pre-Training,” p. 12, 2018.\n[55] M. Phuong and M. Hutter, “Formal Algorithms for Transformers,” arXiv\npreprint arXiv:2207.09238, 2022.\n[56] P. Dijt and P. Mettes, “Trajectory Prediction Network for Future Antici-\npation of Ships,” in Proceedings of the 2020 International Conference on\nMultimedia Retrieval, ser. ICMR ’20. New York, NY , USA: Association\nfor Computing Machinery, Jun. 2020, pp. 73–81.\n[57] I. Loshchilov and F. Hutter, “Decoupled Weight Decay Regularization,”\narXiv:1711.05101 [cs, math], Jan. 2019, arXiv: 1711.05101.\n[58] ——, “SGDR: Stochastic Gradient Descent with Warm Restarts,”\narXiv:1608.03983 [cs, math], May 2017, arXiv: 1608.03983.\n[59] D. Nguyen, M. Simonin, G. Hajduch, R. Vadaine, C. Tedeschi, and\nR. Fablet, “Detection of Abnormal Vessel Behaviors from AIS data\nusing GeoTrackNet: from the Laboratory to the Ocean,” in 21st IEEE\nInternational Conference on Mobile Data Management (MDM), 2020.\n[60] J. Gehring, M. Auli, D. Grangier, D. Yarats, and Y . N. Dauphin, “Con-\nvolutional Sequence to Sequence Learning,” in International Conference\non Machine Learning. PMLR, Jul. 2017, pp. 1243–1252, iSSN: 2640-\n3498.\n[61] J. Chung, K. Kastner, L. Dinh, K. Goel, A. Courville, and Y . Bengio,\n“A Recurrent Latent Variable Model for Sequential Data,” in Advances\nin neural information processing systems, Jun. 2015, pp. 2980–2988.\n[62] C. A. Blance, Norie’s Nautical Tables. Imray, Laurie, Norie and Wilson\nLtd, 2019.\n[63] Z. Xiao, X. Fu, L. Zhang, and R. S. M. Goh, “Traffic Pattern Mining\nand Forecasting Technologies in Maritime Traffic Service Networks: A\nComprehensive Survey,” IEEE Transactions on Intelligent Transporta-\ntion Systems, vol. 21, no. 5, pp. 1796–1825, May 2020, conference\nName: IEEE Transactions on Intelligent Transportation Systems.\n[64] A. Adadi and M. Berrada, “Peeking Inside the Black-Box: A Survey\non Explainable Artificial Intelligence (XAI),” IEEE Access, vol. 6, pp.\n52 138–52 160, 2018, conference Name: IEEE Access.\n[65] A. Barredo Arrieta, N. D ˜Aaz-Rodr ˜Aguez, J. Del Ser, A. Bennetot,\nS. Tabik, A. Barbado, S. Garcia, S. Gil-Lopez, D. Molina, R. Benjamins,\nR. Chatila, and F. Herrera, “Explainable Artificial Intelligence (XAI):\nConcepts, taxonomies, opportunities and challenges toward responsible\nAI,” Information Fusion, vol. 58, pp. 82–115, Jun. 2020.\n[66] P. Molchanov, A. Mallya, S. Tyree, I. Frosio, and J. Kautz, “Im-\nportance Estimation for Neural Network Pruning,” arXiv, Tech. Rep.\narXiv:1906.10771, Jun. 2019, arXiv:1906.10771 [cs, stat] type: article.\n[67] J. Gou, B. Yu, S. J. Maybank, and D. Tao, “Knowledge Distillation: A\nSurvey,” International Journal of Computer Vision, vol. 129, no. 6, pp.\n1789–1819, Jun. 2021.\n[68] S. Benaichouche, C. Le Goff, Y . Guichoux, F. Rousseau, and R. Fablet,\n“Unsupervised Reconstruction of Sea Surface Currents from AIS Mari-\ntime Traffic Data Using Learnable Variational Models,” in ICASSP 2021\n- 2021 IEEE International Conference on Acoustics, Speech and Signal\nProcessing (ICASSP), Jun. 2021, pp. 4100–4104, iSSN: 2379-190X.\n[69] S. Benaichouche, C. Legoff, Y . Guichoux, F. Rousseau, and R. Fa-\nblet, “Unsupervised Reconstruction of Sea Surface Currents from AIS\nMaritime Traffic Data Using Trainable Variational Models,” Remote\nSensing, vol. 13, no. 16, p. 3162, Jan. 2021, number: 16 Publisher:\nMultidisciplinary Digital Publishing Institute.\n[70] B. Ivanovic and M. Pavone, “The Trajectron: Probabilistic Multi-\nAgent Trajectory Modeling With Dynamic Spatiotemporal Graphs,” in\n2019 IEEE/CVF International Conference on Computer Vision (ICCV).\nSeoul, Korea (South): IEEE, Oct. 2019, pp. 2375–2384.",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.6964920163154602
    },
    {
      "name": "Trajectory",
      "score": 0.6792809367179871
    },
    {
      "name": "Computer science",
      "score": 0.6670745611190796
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5680404901504517
    },
    {
      "name": "Generative grammar",
      "score": 0.564329206943512
    },
    {
      "name": "Generative model",
      "score": 0.5462656617164612
    },
    {
      "name": "Representation (politics)",
      "score": 0.4805072546005249
    },
    {
      "name": "Machine learning",
      "score": 0.35701411962509155
    },
    {
      "name": "Engineering",
      "score": 0.13689792156219482
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Astronomy",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 27
}