{
  "title": "Explaining Data Patterns in Natural Language with Language Models",
  "url": "https://openalex.org/W4389518213",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2099907328",
      "name": "Chandan Singh",
      "affiliations": [
        "Microsoft Research (United Kingdom)",
        "Cornell University",
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2985384378",
      "name": "John X. Morris",
      "affiliations": [
        "Microsoft (United States)",
        "Cornell University",
        "Microsoft Research (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2771044721",
      "name": "Jyoti Aneja",
      "affiliations": [
        "Microsoft Research (United Kingdom)",
        "Microsoft (United States)",
        "Cornell University"
      ]
    },
    {
      "id": "https://openalex.org/A2294834069",
      "name": "Alexander Rush",
      "affiliations": [
        "Cornell University",
        "Microsoft Research (United Kingdom)",
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2104437897",
      "name": "Jian-Feng Gao",
      "affiliations": [
        "Microsoft (United States)",
        "Cornell University",
        "Microsoft Research (United Kingdom)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2891012317",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W1541573578",
    "https://openalex.org/W2951936329",
    "https://openalex.org/W2344975321",
    "https://openalex.org/W4280525837",
    "https://openalex.org/W4297801719",
    "https://openalex.org/W2944675392",
    "https://openalex.org/W4301393026",
    "https://openalex.org/W3173436762",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W3173617765",
    "https://openalex.org/W3212496002",
    "https://openalex.org/W2792641098",
    "https://openalex.org/W3156470785",
    "https://openalex.org/W2129202132",
    "https://openalex.org/W2971034336",
    "https://openalex.org/W4242716081",
    "https://openalex.org/W1979769287",
    "https://openalex.org/W4385571789",
    "https://openalex.org/W3166396011",
    "https://openalex.org/W4236110830",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2951576127",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W4287028759",
    "https://openalex.org/W4283768109",
    "https://openalex.org/W2332488709",
    "https://openalex.org/W2799124508",
    "https://openalex.org/W3174770825",
    "https://openalex.org/W4226251122",
    "https://openalex.org/W4285178342",
    "https://openalex.org/W2516809705",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2170819243",
    "https://openalex.org/W3097280976",
    "https://openalex.org/W3205068155",
    "https://openalex.org/W1546425147",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4285288079",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W4385573003",
    "https://openalex.org/W2963424533",
    "https://openalex.org/W4308244910",
    "https://openalex.org/W4309811444",
    "https://openalex.org/W3210923133",
    "https://openalex.org/W2952186591",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W3194309076",
    "https://openalex.org/W3165015862",
    "https://openalex.org/W4285225959",
    "https://openalex.org/W2808315098",
    "https://openalex.org/W3098267758",
    "https://openalex.org/W4320005767",
    "https://openalex.org/W2963541420",
    "https://openalex.org/W3198599617",
    "https://openalex.org/W4297795751"
  ],
  "abstract": "Large language models (LLMs) have displayed an impressive ability to harness natural language to perform complex tasks. We explore whether we can leverage this ability to find and explain patterns in data. Specifically, given a pre-trained LLM and data examples, we apply interpretable autoprompting (iPrompt) to generate a natural language string explaining the data. iPrompt iteratively generates explanations with an LLM and reranks them based on their performance when used as a prompt. Experiments on a wide range of datasets, from synthetic mathematics to natural language understanding, show that iPrompt can yield meaningful insights by accurately finding dataset explanations that are human-interpretable. Moreover, iPrompt is reasonably efficient, as it does not require access to model gradients and works with relatively small models (e.g. ~6 billion parameters rather than >=100 billion). Finally, experiments with scientific datasets show the potential for iPrompt to aid in scientific discovery.",
  "full_text": "Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP, pages 31–55\nDecember 7, 2023. ©2023 Association for Computational Linguistics\n31\nExplaining data patterns in natural language with language models\nChandan Singh∗♢ John X. Morris∗♣ Jyoti Aneja ♢ Alexander M. Rush♣ Jianfeng Gao♢\n♢ Microsoft Research ♣ Cornell University\nchansingh@microsoft.com jxm3@cornell.edu\nAbstract\nLarge language models (LLMs) have displayed\nan impressive ability to harness natural lan-\nguage to perform complex tasks. We explore\nwhether we can leverage this ability to find and\nexplain patterns in data. Specifically, given a\npre-trained LLM and data examples, we apply\ninterpretable autoprompting (iPrompt) to gener-\nate a natural language string explaining the data.\niPrompt iteratively generates explanations with\nan LLM and reranks them based on their per-\nformance when used as a prompt. Experiments\non a wide range of datasets, from synthetic\nmathematics to natural language understand-\ning, show that iPrompt can yield meaningful\ninsights by accurately finding dataset explana-\ntions that are human-interpretable. Moreover,\niPrompt is reasonably efficient, as it does not\nrequire access to model gradients and works\nwith relatively small models (e.g. 6 billion\nparameters rather than ≥100 billion). Finally,\nexperiments with scientific datasets show the\npotential for iPrompt to aid in scientific discov-\nery. 1\n1 Introduction\nLarge language models (LLMs) have attained an\nextraordinary ability to harness natural language\nfor solving diverse problems (Devlin et al., 2018),\noften without the need for finetuning (Brown\net al., 2020; Sanh et al., 2021). Moreover, LLMs\nhave demonstrated the capacity to excel at real-\nworld problems, such as mathematics (Lewkowycz\net al., 2022), scientific question answering (Sa-\ndat and Caragea, 2022), predicting brain re-\nsponses (Schrimpf et al., 2021), and classifying\nproteins and chemical compounds (Taylor et al.,\n2022).\nIn this work, we probe whether we can lever-\nage the learned skills of an LLM to discover and\nexplain patterns in a dataset. To do so, we invert\n1*Equal contribution. All code for using the methods and\ndata here is made available on Github.\nDataset\nInput: 3 1 Output: 4\nInput: 4 7 Output: 11\n…\nInput: 5 9 Output: 14 LLM\nNatural-languageexplanation\nAdd the inputs\nFigure 1: We use interpretable autoprompting to explain\ndatasets, inverting the standard prediction problem to\ninstead find a natural language explanation of the data\nusing a fixed, pre-trained large language model.\nthe typical problem of fitting an LLM to data and\ninstead ask whether we can use a fixed LLM to pro-\nduce a natural language string explaining dataset\npatterns.\nOur approach to this problem centers around\nprompting. Prompting has emerged as an effective\nmethod for adapting LLMs to new datasets (Liu\net al., 2021a); a prompt string is combined with\neach example in a dataset before querying an LLM\nfor an answer. While prompts were initially con-\nstructed manually, recent work has shown success\nin autoprompting, automatically finding a prompt\nvia optimization (Shin et al., 2020; Li and Liang,\n2021; Deng et al., 2022; Zhou et al., 2022). Here,\nwe study interpretable autoprompting ( iPrompt),\nwhich aims to find a semantically meaningful nat-\nural language prompt that explains a key charac-\nteristic of the data. For example, given a dataset\nof examples of addition, e.g. 2 5 ⇒ 7 ... 3 1 ⇒\n4, iPrompt yields the natural language explanation\nAdd the inputs (see Fig. 1). iPrompt works by us-\ning a pre-trained LLM to iteratively propose and\nevaluate different candidate explanations.\nFor evaluation, we curate a diverse collection\nof datasets written in natural language (Table 1)\nand measure iPrompt’s ability to accurately explain\na ground-truth pattern. We find that iPrompt out-\nperforms baseline methods in accurately finding\na correct description; moreover, the generated de-\nscriptions are interpretable, allowing human audit-\ning and enabling strong generalization when used\n32\nas a prompt in a new setting (i.e. when used for a\ndifferent LLM). On real-world sentiment classifica-\ntion datasets, Finally, we find that iPrompt is able\nto extract information from real-world scientific\ndatasets.\n2 Related work\nProblems related to dataset explanation The\nproblem statement presented in this work closely\nresembles the widely studied problems of sym-\nbolic regression (Augusto and Barbosa, 2000;\nSchmidt and Lipson, 2009), program synthe-\nsis (Gulwani et al., 2017; Manna and Waldinger,\n1980), text/table summarization (Kry´sci´nski et al.,\n2019; Liu et al., 2018), and pattern discovery in\ndata-mining (Hand, 2007). iPrompt can be viewed\nas an algorithm for symbolic regression, in which\nthe set of allowable symbols consists of seman-\ntically meaningful natural language strings. One\nrecent work proposes the task of inferring prompts\nthat improve supervised prediction (Honovich et al.,\n2022), which we generalize here to diverse use\ncases for dataset explanation.\nPrompting and autoprompting. With the ad-\nvent of large-scale models, prompting (i.e. find-\ning the right prompt to use to query an LLM for\na given task) has exploded as an area of inquiry,\noften yielding impressive improvements in perfor-\nmance (Brown et al., 2020; Petroni et al., 2019;\nLiu et al., 2021a) and spurring a line of work aim-\ning to make prompting easier (Strobelt et al., 2022;\nLu et al., 2022; Bach et al., 2022; Logan IV et al.,\n2022). Recently, autoprompting (i.e. automatically\nsearching for a prompt or prompt-embedding via\noptimization) has emerged (Li and Liang, 2021;\nLiu et al., 2021b) to improve the process of prompt-\ning, with methods such as prefix-tuning (Li and\nLiang, 2021), P-tuning (Liu et al., 2021b), prompt-\ntuning with rules (Han et al., 2021), knowledge-\nable prompt tuning (Hu et al., 2021) and many\nmore (Liu et al., 2021a). These strategies use gra-\ndient descent to find a set of “adapter” parameters\nthat maximize model performance, but do not re-\nquire that the new parameters map back to tokens\nin discrete space, rendering them uninterpretable.\nA few methods tackle the more difficult problem\nof searching for prompts that can be expressed in\nnatural language tokens. RLPrompt (Deng et al.,\n2022) searches for such a prompt using reinforce-\nment learning and one recent work (Honovich et al.,\n2022) queries an LLM to produce a prompt. Auto-\nPrompt (Shin et al., 2020) performs autoprompting\nvia input gradients (see Sec. 3). These methods\neffectively alter a model’s predictions, but do not\nconstrain the discovered prompts to be semantically\nmeaningful, resulting in prompts that are difficult\nto interpret (Webson and Pavlick, 2021). Another\nrelated work directly finetunes an LLM to describe\nthe difference between two datasets (Zhong et al.,\n2022). One recent work proposes a method for\ninterpretable autoprompting similar to the one here,\nwith a focus on improving prediction performance\nrather than on explaining data patterns (Zhou et al.,\n2022).\nAlternative methods for neural-network inter-\npretation A popular method for interpreting neu-\nral networks is to inspect an LLM’s individual pre-\ndictions via feature importances (Lundberg et al.,\n2019; Ribeiro et al., 2016), feature-interaction im-\nportances (Singh et al., 2019; Tsang et al., 2017),\nextractive rationales (Zaidan and Eisner, 2008; Sha\net al., 2021), or natural language explanations for\nindividual predictions (Hendricks et al., 2016; Cam-\nburu et al., 2018). These works can provide mean-\ningful insights for individual predictions, but it is\ndifficult to parse them into an understanding of an\nentire dataset. Alternatively, one can investigate\nwhether an LLM’s learned representations via prob-\ning (Conneau et al., 2018; Liu and Avci, 2019) or by\ndirectly analyzing a model’s internal weights and\nactivations (Wang et al., 2021; Olah et al., 2018;\nMeng et al., 2022). However, these approaches\nare limited in their ability to generate previously\nunknown descriptions of data.\n3 Methods: Defining the task and\napproach\n3.1 Task: Dataset Explanation\nGiven a dataset comprised of input-output string\npairs {(x1, y1), . . . ,(xN , yN )}, the goal is to pro-\nduce a “semantically meaningful” natural language\nstring that explains the relationship between x and\ny. We require that a string consists of human-\nunderstandable text rather than a sequence of incon-\ngruous tokens. For example, in the dataset shown in\nFig. 1, given samples of data performing addition,\nour task is to recover text synonymous to Add the\ninputs. This dataset explanation can then be used\nfor various downstream tasks, such as prompting a\ndifferent LLM.\n33\nTable 1: Dataset Explanation Tasks. Each collections\ncontains # different task. Roman numerals correspond\nto the use cases in Fig. 1. For full details on each dataset,\nsee Appendix A.2.\nCollection # Description\n1) Synthetic math 10 Mathematical functions (i), (ii)\n2) Allen NLI 10 Language tasks (i), (ii)\n3) Instr. induction 20 Language tasks (i), (ii)\n4) Sentiment 4 Sentiment classification (i), (ii)\n5) Proteins/chemicals 3 Protein/chemical properties (iii)\n6) Language fMRI 20 Excitation of fMRI voxel (iii),(iii)\nDatasets Table 1 shows the collections of\ndatasets we study: (1) Synthetic math – datasets\nthat require inferring an underlying mathemati-\ncal function based on numeric input and outputs;\n(2) Allen NLI (ANLI) and (3) Instruction induc-\ntion (Honovich et al., 2022) – diverse language\ntasks (Wang et al., 2022) with easily verifiable\ndescriptions (e.g. Find a country’s capital ). (4)\nSentiment – a collection of sentiment classification\ndatasets in different domains. For collections (1-3),\nthere is a ground-truth prompt available for eval-\nuation. For example, when adding two numbers\n(Fig. 1), the rule checks whether a description con-\ntains any of the keywords add, sum, or +. We also\nstudy scientific datasets on (5) proteins/chemicals,\nand (6) fMRI with full details given in Sec. 6.\n3.2 Approach: iPrompt\nWe now detail approaches for the general prob-\nlem of autoprompting before covering interpretable\nautoprompting. We specify autoprompting as a\ndiscrete search problem. Given a dataset of n\ninput-output pairs {( x1, y1), ..., ( xn, yn)} and a\npre-trained LLM f that returns the log-probability\nof a given string, autoprompting finds a natural\nlanguage explanation ˆs maximizing:\nˆs = argmax\ns∈S\nnX\ni=1\nf\n\u0000\nrender(s, xi, yi)\n\u0001\n(1)\nThe render function is a problem-specific function\nthat renders a natural language string from the\nprompt s and each example in the dataset (xi, yi).\nWe use S to indicate the set of fluent strings, under\nsome notion of syntactic fluency. This constraint\nis used to ensure prompts are readable, and poten-\ntially generalize to downstream LLMs. Solving\nthis search problem exactly is intractable.\nA core assumption of this objective is that se-\nmantically accurate prompts lead a model to assign\nGPT-2 (1.5B) GPT-Neo (2.7B)\nSum\nDifferenceMaximum\nFirst\nPrompt keyword\nAdd\nSubtract\nMax\nFirst\nT ask\nGPT-J (6B) GPT-3 (175B)\nFigure 2: Prompt-based reranking depends on model\nsize. Large models (GPT-J 6B and GPT-3) align\nprompts correctly to tasks. The model is given the\nprompt Return the of the inputs., where is filled\nin with the shown prompt keyword before querying the\noutput given two inputs numbers in a string. Darker\nindicates a higher accuracy, and high accuracy along the\ndiagonal indicates that the correct prompt induces the\nhighest accuracy.\nhigher probability to the correct output. To check\nthis assumption, we analyze four datasets from the\ninverse synthetic math collection that share com-\nmon structure for the inputs and prompts. Each\ndataset admits a prompt of the form Return the\nof the inputs., then is given two input numbers and\nqueried for the output.\nFig. 2 shows the accuracy of different models\nat performing these tasks across different input\nprompts.2 For small models, the prompts are un-\nsuccessful, but for large models (GPT-J 6B and\nGPT-3), the model is accurate if and only if given\nthe correct prompt.3 This result suggests that, at\nleast for large models, the search for a prompt that\nmaximizes performance correlates well with the\nunderlying task. We will see in Fig. 4 that dataset\nexplanation depends on this ability.\nBaseline: AutoPrompt AutoPrompt (Shin et al.,\n2020) targets the objective posed in Eq. (1) us-\ning a gradient-based local search. AutoPrompt\nsearches for ˆs following the gradients of the ob-\njective Eq. (1) with respect to individual tokens in\n2The accuracy is normalized for each task using softmax\nin order to visualize the effect of differing prompts.\n3For details on each model, see Table A4.\n34\nCombine the numbers\nCompute the output\nCombine the numbers\nSum in order\nCombine the numbers\nCombine the arguments\nSum all inputs\nSum the numbers\n(ii) Reranking\nSum the numbers\n(i) Proposal\nIn: 3 1 Out: 4\nIn: 4 7 Out: 11\nIn: 5 9 Out: 14\nPrompt: Sum in order\nReturn the output\nCompute the output\nIn: 5 5 Out: 10\nIn: 9 3 Out: 12\nIn: 1 8 Out: 9\nPrompt:\nCombine the numbers\nSum all inputs\nSum the numbers\nCombine the arguments\nCombine the numbers\n(iii) Iterate with exploration\nFigure 3: Overview of iPrompt. iPrompt first proposes\ncandidate prompts, then ranks them based on their per-\nformance as a prompt, then truncates and regenerates\nthem. This entire process is repeated until performance\nstops improving.\nˆs. It discretely changes individual words in ˆs and\nthen checks whether or not the newly updated ˆs\nimproves the objective score. The use of gradients\nallows AutoPrompt to find an effective prompt ˆs,\nbut makes it difficult to find answers that satisfy\nthe fluency constraint S.\nBaseline: Zero-shot suffix decoding LLMs\nthemselves can be directly used to predict\nprompt strings. Following Honovich et al.,\nwe give the model a prompt string which\ncontains data examples (e.g. In: 2 5| {z }\nxi\nOut: 7.| {z }\nyi\nTo compute the output from the input,| {z }\ntemplate\n,) and\nsample the output to recover a prompt ˆs using\nnucleus sampling.4\nProposed method: interpretable autoprompt-\ning iPrompt (Fig. 3) is an iterative local search\nalgorithm that alternates between three steps: (i)\nproposing candidate prompts, (ii) reranking candi-\ndate prompts, (iii) exploration.\n(i) Proposal: Candidate prompts are generated by\nextending the zero-shot LLM generation. Given\na data instance as a prefix, we sample a number\nof candidate prompts. The maximum length of\n4We also consider averaging the model’s output logits\nacross all examples in the dataset before decoding the out-\nput, but find that it does not improve performance (see Ap-\npendix A.4).\neach candidate is pre-specified and fixed. For ex-\nample, in the add-two-numbers task (Fig. 3), we\nmay generate four candidates: {Combine the num-\nbers, Return the output, Sum in order, Compute the\noutput}.\n(ii) Reranking: Given candidates, the objective\nEq. (1) is evaluated for each candidate prompt s.\nThe top few candidates which maximize the objec-\ntive are kept, e.g. narrowing down the candidates\nto {Combine the numbers, Sum in order}.\n(iii) Iterate with exploration: Each of the top\ncandidates from reranking is truncated at a random\nposition. These truncated candidates are used as a\nprefix when generating new candidate prompts via\nsuffix decoding. For example, we may randomly\nselect the start of the previous candidates and fill\nin the endings: {Combine the , Sum } →\n{Combine the numbers, Combine both arguments,\nSum the numbers, Sum all inputs}.\nThe algorithm is repeated until identifying a suit-\nably strong ˆs, e.g. Sum the numbers. Steps (i) and\n(iii) ensure that prompts remain fluent, while step\n(ii) improves the score of the prompts on the ob-\njective. Computationally, iPrompt only requires\nrunning inference on the pre-trained LLM, yield-\ning a significantly lower memory requirement than\nmethods such as AutoPrompt which require access\nto the LLM’s gradients.\n4 Experimental Setup\nWe consider two sets of experiments. First in Sec. 5,\nwe explore iPrompt’s ability to rediscover a correct\nand fluent prompt on the variety of simple instruc-\ntion datasets (Table 1, top) with known answers.\nExperiments test the ability of the model to recover\na known prompt while also remaining fluent in a\nway that generalize to human readers and to other\nlanguage models. In Sec. 6 we apply iPrompt to\nscientific datasets (Table 1, bottom).\nLanguage Models For the main set of experi-\nments, we always generate prompts using GPT-J, a\n6 billion parameter model (Wang and Komatsuzaki,\n2021). We restrict prompts to {6,12} tokens for\nsentiment classification and 6 tokens for the re-\nmaining data collections in Table 1. For generaliza-\ntion experiments, alternative models are tested with\nthe generated prompts including OPT and GPT-\n3 (Zhang et al., 2022; Brown et al., 2020). See\nAppendix A.4 for a full discussion of experimental\ndetails and Appendix A.3 for experiments on more\n35\nTable 2: Performance for dataset explanation. Dataset\nfrom Table 1 (1-3). Accuracy measured via (1) Human-\nevaluation (H, normalized %), (2) Mean Reciprocal\nRank across the collection (M) and (3) 1-best correct-\nness (C, %). For all metrics, higher is better.\niPrompt AutoPrompt Suffix\nH / M / C H / M / C H / M / C\nMath 60 / 0.69 / 60 25 / 0.14 / 13 20 / 0.08 / 03\nANLI 56 / 0.41 / 37 21 / 0.07 / 07 25 / 0.06 / 01\nInduction 42 / 0.35 / 28 21 / 0.09 / 08 23 / 0.04 / 01\nmodels (e.g. Galactica (Taylor et al., 2022)) and\nmore datasets.\nEvaluation metrics Our main evaluation mea-\nsures each prompt’s closeness to groundtruth via\nthree metrics: (1) Correct – whether the gener-\nated explanation contains one of a set of problem-\nspecific keywords. (2) MRR – Mean reciprocal\nrank measuring the rank of the first task-correct\nprompt. Given a set of datasets D = {D1, ...,DN },\nwe compute: MRR = 1\n|D|\nP|D|\ni=1\n1\nranki\n, where ranki\nis the one-indexed rank of the first correct expla-\nnation. (3) Human – The human evaluation scores\nbetween the top-generated explanation and a pre-\nspecified groundtruth explanation, when instructed\n“You are given a groundtruth description along with\na generated one. On a scale of 1 (worst) to 5 (best),\nhow interpretable and accurate is the generated de-\nscription?”5. The mean human evaluation score\n(ranging from 1 to 5) is normalized.\nAs a secondary evaluation, we measure general-\nization ability when we evaluate explanations based\non accuracy as a prompt for other models. Accu-\nracy is computed following (Brown et al., 2020;\nRaffel et al., 2020): using exact matching with\nbeam search, a beam width of 4, and a length\npenalty of α = 0.6.\n5 Results and Analysis\n5.1 Dataset explanation recovery\nTable 2 compares prompting methods across three\ndiverse data collections. The Human evaluation\nscores are much higher for iPrompt than the base-\nlines, suggesting that it finds prompts which are\nboth accurate and human-interpretable. Similarly,\nthe MRR and Correct scores show that iPrompt con-\nsiderably improves in finding accurate explanations.\nSee all generated explanations in Appendix A.3.\n5Human evaluation scores are averaged over 4 PhD stu-\ndents in machine learning not affiliated with the study.\n0 20 40 60 80 100\nModel accuracy with correct prompt\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0Prompt Recovery (MRR)\nMath\nANLI\nFigure 4: Comparison of model accuracy with correct\nprompt and iPrompt ability to find the correct prompt\nacross each individual task (single-task MRR). Prompt\nrecovery ability is dependent on the model’s ability to\nperform the task.\nTable 3: Generalization accuracy (zero-shot) with the\nprompts generated with GPT-J as the LLM across dif-\nferent models.\nCorrect\nPrompt iPrompt Auto\nPrompt\nNo\nprompt\nGPT-J 6.7B* 54.0 51.5 41.6 16.3\nMath\nOPT 6.7B 12.7 19.3 18.9 8.4\nGPT 20B 76.1 54.4 23.2 8.5\nGPT-3 175B 76.0 62.1 40.8 28.4\nGPT-J 6.7B* 9.0 4.7 1.9 2.0\nANLI\nOPT 6.7B 10.7 6.7 4.7 7.9\nGPT 20B 31.0 14.2 5.6 4.0\nGPT-3 175B 37.6 11.7 2.7 7.7\nTo assess the best-case absolute accuracy of the\napproach, we note it is impossible for the approach\nto recover the prompt if the underlying LLM can-\nnot solve the task. Fig. 4 plots the prompt recovery\nperformance (MRR) against the underlying LLM’s\naccuracy (when using the groundtruth prompt) for\neach dataset. When the model can solve the task,\niPrompt does well on recovery. However for many\ntasks the model has low accuracy even with the cor-\nrect prompt, putting a ceiling on the performance\nof iPrompt.\n5.2 Generalization accuracy of prompts\nThe generalization accuracy of generated prompts\nacross different LLMs can inform how well a\nprompt captures an underlying pattern in the data.\nTable 3 shows the generalization accuracy when\ntesting the prompts generated using GPT-J (Table 4)\non different LLMs. The prompts maintain effec-\ntiveness across most models. For the Math datasets,\nthe iPrompt prompts elicit improvement over the\nbaselines and approach the accuracy of the cor-\nrect prompt. For the ANLI datasets, all prompts\n36\ninduce poor performance. Notably, the gap be-\ntween iPrompt and AutoPrompt is larger for larger\nmodels (i.e. GPT 20B and GPT-3); this suggests\nthat, by generating fluent prompts, iPrompt gen-\nerates more generalizable descriptions. Similarly,\niPrompt shows strong results on sentiment analy-\nsis datasets across a variety of models including\nGPT-3 (see Appendix A.1).\nTable 4 shows the top-ranked explanation gener-\nated by each method for selected datasets. iPrompt\noften finds an explanation that is indicative of the\nunderlying relationship, even if the phrasing is not\nperfect. For example, for the add two numbers\ndataset, it finds Create a function named ‘sum. The\nprompts found by iPrompt also read as fairly fluent\nstrings compared to AutoPrompt, which produces\nan incoherent set of tokens.\n5.3 Model ablations\nWe run ablation experiments to analyze the three\nsteps of iPrompt: (1) Proposal, (2) Reranking, and\n(3) Iteration. We use the Math and ANLI datasets\nand run on a maximum of 5000 data points using 5\nshots in context for prompt generation.\n(1) Proposals are partially guided by examples.\nDuring the proposal stage, iPrompt prefixes poten-\ntial prompts with dataset examples. Table 5 con-\nsiders variants of this stage that remove input and\noutput examples during the proposal stage. Note\nthat the system still has access to the full examples\nduring the reranking stage. We find that the system\ncan achieve decent performance on Math simply by\niterating. However for ANLI, the model needs to\nat least see the inputs/outputs during the proposal\nin order to find accurate prompts.\n(2) Reranking zero-shot recovers better\nprompts. iPrompt uses zero-shot accuracy to rank\nprompts. As we have examples of the task, we\ncould instead use in-context few-shot prompting\nfor ranking. Prior work suggests that prompt word-\ning is less influential as the number of in-context\nexamples increases (Webson and Pavlick, 2021).\nTable 5 shows that using these examples in-context\nfor reranking does, in fact, considerably hamper\nprompt recovery. We further find that the LLM\nused for reranking is more important than the LLM\nused for proposals (see Appendix Fig. A3).\n(3) Iteration improves performanceFinally, Ta-\nble 5 shows that without multiple iterations, perfor-\nmance drops nearly to zero (Fig. A2 shows more\ndetails on loss as a function of iterations).\n6 Scientific investigations with iPrompt\nWe now investigate whether iPrompt can explain\npatterns in scientific datasets. Specifically, we ana-\nlyze the Galactica model (Taylor et al., 2022) with\n6.7 billion parameters. We query whether it can de-\nscribe differences in protein sequence before inves-\ntigating a neuroscience problem; see Appendix A.5\nfor similar experiments in a chemical toxicity set-\nting.\nDifferentiating protein sequences We investi-\ngate whether iPrompt can explain the differences\nbetween two groups of proteins. We use protein\nsequences and keywords from Swiss-Prot (Bairoch\nand Boeckmann, 1991) (a high-quality subset of\nUniprot (Consortium, 2015)) to construct two\ndatasets: each dataset contains two groups of pro-\nteins, which are differentiated based on their key-\nwords.6 The first dataset, which we call Cyto,\nhas proteins with either the keyword Cytoplasm\nor Membrane. The second dataset, which we call\nBinding, has proteins with either the keyword RNA-\nbinding or ATP-binding. Each group is randomly\ndownsampled to 100 proteins and iPrompt is run\nwith the same hyperparameters as when finding\nchemical compounds.\nWe make this problem more challenging by feed-\ning the model the raw protein sequence (not the\nprotein name) which ranges from hundreds to thou-\nsands of amino acids. Each input is presented with\nthe following text: Here is a protein sequence:\\n\n[Protein Sequence]\\n Answer: followed by Yes for\na one group and No for the other. Table 6 shows re-\nsults for identifying whether the elicited prompt\ncontains one of the relevant keywords for each\ndataset (e.g. Cytoplasm). Despite the difficult in-\nput format, the correct keywords are successfully\nidentified for both the Cyto and Binding datasets\nbetter than for the Baseline (which again contains\nempty inputs).\nScientific investigation into an fMRI natural lan-\nguage dataset We now explore using iPrompt\nin a simple neuroscience experiment. A central\nchallenge in neuroscience is understanding how\nand where semantic concepts are represented in the\nbrain. A recent seminal study (Huth et al., 2016)\nexplores this question by investigating where dif-\nferent natural language categories are represented\nin the human neocortex. Specifically, the authors\n6We search for reasonably popular but non-cooccuring\nkeywords in the proteins; see details in Fig. A5\n37\nTable 4: Examples of generated explanations by iPrompt and AutoPrompt. See all prompts in Appendix A.3.\nHuman-written prompt iPrompt AutoPrompt\nMath\nReturn the sum of the inputs Create a function named ‘sum >:Returns Adding togetherFont accomplish\nReturn the square of the input Input number and return its square Cal impl qApplySquare fiat\nDifferentiate between prime/non-prime integers Are these pairs of integers prime ropheospels&& Norestricted\nANLI\nDifferentiate vegetarian/non-vegetarian foods Are you a vegetarian? compliedthe whether methamphetamine provided comp\nDifferentiate the subject in a sentence based on\ngender\nPredict the gender (F = < endoftext > -> M Fundamental FG Fav\nReturn a synonym what is a synonym for Word termOn English meanings\nTranslate english to spanish please write English meaning in Spanish the ththebb volunt\nReturn a country’s capital city Which city is the capital and Ang Suppose AUTHthe beh Assassins\nTable 5: Algorithmic ablations for each stage of iPrompt.\nGives prompt recovery (MRR) achieved by ablating\neach stage. Averaged over 3 random seeds.\nMRR\nMath ANLI\niPrompt 0.557 0.278\n(1) Proposal w/o inputs+outputs 0.400 0.015\nw/o inputs 0.463 0.244\nw/o outputs 0.539 0.255\n(2) Reranking w/ in-context examples 0.071 0.152\n(3) Iteration No iteration 0.075 0.050\nTable 6: iPrompt performance at differentiating protein\nsequences. For both the Cyto and Binding datasets, the\ncorrect keywords are succesfully identified better than\nfor the Baseline. Results are averaged over 12 random\nseeds; error bars are standard error of the mean.\niPrompt\n(Cyto)\niPrompt\n(Binding) Baseline\nMRR 0.2 ± 0.08 0.08 ± 0.04 0.03 ± 0.01\nRecall @ 5 0.25 ± 0.13 0.17 ± 0.11 0.05 ± 0.05\nRecall @ 20 0.83 ± 0.11 0.33 ± 0.14 0.23 ± 0.09\ncollect functional MRI (fMRI) responses as human\nsubjects listen to hours of narrative stories. They\nthen build a predictive model of these responses\nfor each voxel (i.e. a small region in space) in the\nbrain, which takes as input the words contained in\nthe stories (and other features). To interpret these\nindividual voxel models, they cluster the words in\nthe narrative stories into 12 groups and manually\nannotate them, resulting in 12 categories, such as\ntactile, visual, and professional. Finally, they view\nthe spatial mapping of these 12 concepts (projected\nonto low dimensions) across the brain using their\nindividual voxel models.\nWe revisit a small piece of this study’s analy-\nsis through the lens of iPrompt. Specifically, we\nask whether iPrompt could generate plausible cat-\negories that are well-represented across the brain\nbut differ from the manually identified 12. We\nfit a predictive model for each voxel, following\nthe pipeline of the original study (details in Ap-\npendix A.8). We then use the resulting models to\nidentify a list of the top-15 words which most ex-\ncite each voxel. For example, the top-15 words that\nexcite the best-predicted voxel are: sheet, edges,\ndiameter, strips, cardboard, copper, steel, colored,\ncoloured, leaf, wire, cap, paper, shaped, tin . To\nidentify a plausible semantic category, we construct\na template string as follows: The following list of\nwords all belong to the same semantic category:\n\\n\\n sheet, edges, ..., shaped, tin. We then use\niPrompt (again with a GPT-6B parameter model)\nto generate a category by filling in the blank (re-\nstricted to a single token). To make iPrompt more\neffective, for each voxel we use iPrompt on a set\nof examples consisting of 15 permutations of the\ntop-15 words, allowing finding patterns that are not\noverly sensitive to the word-ordering.\nGiven the top categories for each voxel, we ana-\nlyze the mapping of recurring categories across the\nneocortex. We aggregate the top-15 inferred cate-\ngories7 over the top-15 best-predicted voxels and\nfind that the most frequently inferred categories are:\nmaterial, color, surface, text, & fabric.\nInterestingly, these are sensible quantities that dif-\nferent voxels could reasonably be selective for. We\nspatially map each of these identified categories\n(e.g. material) across the 10,000 best-predicted\nvoxels by using the LLM in a second way. For\neach voxel, we condition the LLM (again GPT-6B)\non the top-15 words list, and evaluate the predicted\nprobability for each category, i.e. The following\nlist of words all belong to the same semantic cat-\negory: sheet, edges, ..., shaped, tin The semantic\ncategory they all belong to, in one word, is . The\n7We apply stemming and remove stopwords before choos-\ning the best categories.\n38\n0 10\n1\nMaterial\nColor\nFigure 5: Representations of the iPrompt-elicited con-\ncepts material (blue) and color (red) across the sur-\nface of the neocortex are spatially clustered and smooth.\nOnly the top 10,000 best-predicted voxels are shown, re-\nmaining voxels are shown in black. Only the right hemi-\nsphere is shown (see both hemispheres, which show\nconsistent smoothness in Fig. A6).\nhigher this predicted probability, the more selective\nwe infer that a voxel is for the category. Fig. 5\nshows these predicted probabilities for the top-two\ninferred categories (material and color) across the\ncortex of a human subject.\nWhile there is no groundtruth for this seman-\ntic map, one noteworthy feature of the resulting\nmap is that it is spatially smooth (quantitatively,\nFig. A8 shows that the variance of the map among\nneighboring pixels is significantly lower than we\nwould expect by shuffling the map’s values). This\nis non-trivial, as nowhere in the modeling process\nwas spatial information incorporated: each voxel\nwas modeled independently and the displayed pre-\ndiction was queried independently. We expect the\nunderlying map to be smooth, both due to local\nconnectivity in brain regions and also because the\nBOLD signal measured by fMRI does not have\nperfect spatial resolution. Thus, the fact that our\ninferred map is smooth suggests that (i) something\nabout these categories is genuinely captured by\nthe representation in the human brain, and (ii) that\nthe iPrompt approach was able to reflect at least\nsome of it. Beyond the two categories shown, the\nfive categories generated by iPrompt exhibit spatial\nsmoothness across the neocortex (Fig. A8).\n7 Conclusion and Discussion\niPrompt makes a meaningful step towards finding\nnatural language prompts that are both accurate and\nhuman-interpretable. We show this method can\nbe used to recover dataset descriptions, produce\ntransferable prompts, and provide explanations for\nexperimental data. One future direction could elicit\ntargeted information from data via the use of a\ntemplate. For example, one may use iPrompt to ex-\ntract feature importance by prepending the learned\nprompt with the string “To get the answer from\nthe inputs, the most important inputs are ”. As\nanother example, in a scientific study such as the\nfMRI study in Sec. 6, a scientist interested in a\nparticular topic (e.g. fear) may investigate that par-\nticular topic by making a more specific template\n(e.g. How are these words related to the concept of\n“fear”?).\nWhile we focus on text, iPrompt could be ap-\nplied generally settings where an LLM performs\nwell. For example, in computer vision, an inter-\npretable autoprompt may look like a mask of an\nimage, and in vision-language models, an inter-\npretable prompt may be a description of a vision\ntask, e.g. find the largest shape in this image.\nReferences\nDouglas Adriano Augusto and Helio JC Barbosa. 2000. Sym-\nbolic regression via genetic programming. In Proceedings.\nVol. 1. Sixth Brazilian Symposium on Neural Networks ,\npages 173–178. IEEE.\nStephen H Bach, Victor Sanh, Zheng-Xin Yong, Albert Web-\nson, Colin Raffel, Nihal V Nayak, Abheesht Sharma, Tae-\nwoon Kim, M Saiful Bari, Thibault Fevry, et al. 2022.\nPromptsource: An integrated development environment\nand repository for natural language prompts.arXiv preprint\narXiv:2202.01279.\nAmos Bairoch and Brigitte Boeckmann. 1991. The swiss-\nprot protein sequence data bank. Nucleic acids research,\n19(Suppl):2247.\nSid Black, Stella Biderman, Eric Hallahan, Quentin Anthony,\nLeo Gao, Laurence Golding, Horace He, Connor Leahy,\nKyle McDonell, Jason Phang, et al. 2022. Gpt-neox-20b:\nAn open-source autoregressive language model. arXiv\npreprint arXiv:2204.06745.\nSid Black, Gao Leo, Phil Wang, Connor Leahy, and Stella\nBiderman. 2021. GPT-Neo: Large Scale Autoregressive\nLanguage Modeling with Mesh-Tensorflow. If you use this\nsoftware, please cite it using these metadata.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,\nJared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan,\nPranav Shyam, Girish Sastry, Amanda Askell, et al. 2020.\nLanguage models are few-shot learners. Advances in neu-\nral information processing systems, 33:1877–1901.\n39\nOana-Maria Camburu, Tim Rocktäschel, Thomas\nLukasiewicz, and Phil Blunsom. 2018. e-snli: Nat-\nural language inference with natural language explanations.\nAdvances in Neural Information Processing Systems, 31.\nHyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph,\nYi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa\nDehghani, Siddhartha Brahma, Albert Webson, Shixi-\nang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen,\nAakanksha Chowdhery, Sharan Narang, Gaurav Mishra,\nAdams Yu, Vincent Zhao, Yanping Huang, Andrew Dai,\nHongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob De-\nvlin, Adam Roberts, Denny Zhou, Quoc V . Le, and Jason\nWei. 2022. Scaling instruction-finetuned language models.\nAlexis Conneau, German Kruszewski, Guillaume Lample,\nLoïc Barrault, and Marco Baroni. 2018. What you can\ncram into a single vector: Probing sentence embeddings\nfor linguistic properties. arXiv preprint arXiv:1805.01070.\nUniProt Consortium. 2015. Uniprot: a hub for protein infor-\nmation. Nucleic acids research, 43(D1):D204–D212.\nMingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang,\nHan Guo, Tianmin Shu, Meng Song, Eric P Xing, and\nZhiting Hu. 2022. Rlprompt: Optimizing discrete text\nprompts with reinforcement learning. arXiv preprint\narXiv:2205.12548.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina\nToutanova. 2018. Bert: Pre-training of deep bidirectional\ntransformers for language understanding. arXiv preprint\narXiv:1810.04805.\nJames S Gao, Alexander G Huth, Mark D Lescroart, and\nJack L Gallant. 2015. Pycortex: an interactive surface\nvisualizer for fmri. Frontiers in neuroinformatics, page 23.\nSumit Gulwani, Oleksandr Polozov, Rishabh Singh, et al. 2017.\nProgram synthesis. Foundations and Trends® in Program-\nming Languages, 4(1-2):1–119.\nXu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu, and Maosong\nSun. 2021. Ptr: Prompt tuning with rules for text classifica-\ntion. arXiv preprint arXiv:2105.11259.\nDavid J Hand. 2007. Principles of data mining. Drug safety,\n30(7):621–622.\nLisa Anne Hendricks, Zeynep Akata, Marcus Rohrbach, Jeff\nDonahue, Bernt Schiele, and Trevor Darrell. 2016. Gen-\nerating visual explanations. In European conference on\ncomputer vision, pages 3–19. Springer.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin\nChoi. 2019. The curious case of neural text degeneration.\narXiv preprint arXiv:1904.09751.\nOr Honovich, Uri Shaham, Samuel R Bowman, and Omer\nLevy. 2022. Instruction induction: From few examples\nto natural language task descriptions. arXiv preprint\narXiv:2205.10782.\nShengding Hu, Ning Ding, Huadong Wang, Zhiyuan\nLiu, Juanzi Li, and Maosong Sun. 2021. Knowl-\nedgeable prompt-tuning: Incorporating knowledge into\nprompt verbalizer for text classification. arXiv preprint\narXiv:2108.02035.\nAlexander G Huth, Wendy A De Heer, Thomas L Griffiths,\nFrédéric E Theunissen, and Jack L Gallant. 2016. Natural\nspeech reveals the semantic maps that tile human cerebral\ncortex. Nature, 532(7600):453–458.\nWojciech Kry´sci´nski, Nitish Shirish Keskar, Bryan McCann,\nCaiming Xiong, and Richard Socher. 2019. Neural text\nsummarization: A critical evaluation. arXiv preprint\narXiv:1908.08960.\nAitor Lewkowycz, Anders Andreassen, David Dohan, Ethan\nDyer, Henryk Michalewski, Vinay Ramasesh, Ambrose\nSlone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al.\n2022. Solving quantitative reasoning problems with lan-\nguage models. arXiv preprint arXiv:2206.14858.\nXiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Opti-\nmizing continuous prompts for generation. arXiv preprint\narXiv:2101.00190.\nFrederick Liu and Besim Avci. 2019. Incorporating pri-\nors with feature attribution on text classification. arXiv\npreprint arXiv:1906.08286.\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hi-\nroaki Hayashi, and Graham Neubig. 2021a. Pre-train,\nprompt, and predict: A systematic survey of prompting\nmethods in natural language processing. arXiv preprint\narXiv:2107.13586.\nTianyu Liu, Kexiang Wang, Lei Sha, Baobao Chang, and Zhi-\nfang Sui. 2018. Table-to-text generation by structure-aware\nseq2seq learning. In Thirty-Second AAAI Conference on\nArtificial Intelligence.\nXiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie\nQian, Zhilin Yang, and Jie Tang. 2021b. Gpt understands,\ntoo. arXiv preprint arXiv:2103.10385.\nRobert Logan IV , Ivana Balazevic, Eric Wallace, Fabio Petroni,\nSameer Singh, and Sebastian Riedel. 2022. Cutting down\non prompts and parameters: Simple few-shot learning\nwith language models. In Findings of the Association for\nComputational Linguistics: ACL 2022, pages 2824–2835,\nDublin, Ireland. Association for Computational Linguis-\ntics.\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and\nPontus Stenetorp. 2022. Fantastically ordered prompts and\nwhere to find them: Overcoming few-shot prompt order\nsensitivity. In Proceedings of the 60th Annual Meeting of\nthe Association for Computational Linguistics (Volume 1:\nLong Papers), pages 8086–8098, Dublin, Ireland. Associa-\ntion for Computational Linguistics.\nScott M Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave,\nJordan M Prutkin, Bala Nair, Ronit Katz, Jonathan Himmel-\nfarb, Nisha Bansal, and Su-In Lee. 2019. Explainable ai\nfor trees: From local explanations to global understanding.\narXiv preprint arXiv:1905.04610.\nP. Malo, A. Sinha, P. Korhonen, J. Wallenius, and P. Takala.\n2014. Good debt or bad debt: Detecting semantic orien-\ntations in economic texts. Journal of the Association for\nInformation Science and Technology, 65.\nZohar Manna and Richard Waldinger. 1980. A deductive\napproach to program synthesis. ACM Transactions on\nProgramming Languages and Systems (TOPLAS), 2(1):90–\n121.\nKevin Meng, David Bau, Alex Andonian, and Yonatan Be-\nlinkov. 2022. Locating and editing factual knowledge in\ngpt. arXiv preprint arXiv:2202.05262.\n40\nChris Olah, Arvind Satyanarayan, Ian Johnson, Shan Carter,\nLudwig Schubert, Katherine Ye, and Alexander Mordvint-\nsev. 2018. The building blocks of interpretability. Distill,\n3(3):e10.\nBo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class\nrelationships for sentiment categorization with respect to\nrating scales. In Proceedings of the ACL.\nFabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton\nBakhtin, Yuxiang Wu, Alexander H Miller, and Sebas-\ntian Riedel. 2019. Language models as knowledge bases?\narXiv preprint arXiv:1909.01066.\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh,\nGabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda\nAskell, Pamela Mishkin, Jack Clark, et al. 2021. Learning\ntransferable visual models from natural language supervi-\nsion. In International Conference on Machine Learning,\npages 8748–8763. PMLR.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario\nAmodei, Ilya Sutskever, et al. 2019. Language models are\nunsupervised multitask learners. OpenAI blog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,\nSharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Pe-\nter J Liu, et al. 2020. Exploring the limits of transfer\nlearning with a unified text-to-text transformer. J. Mach.\nLearn. Res., 21(140):1–67.\nMarco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.\n2016. Why should i trust you?: Explaining the predictions\nof any classifier. In Proceedings of the 22nd ACM SIGKDD\nInternational Conference on Knowledge Discovery and\nData Mining, pages 1135–1144. ACM.\nAnn M Richard, Ruili Huang, Suramya Waidyanatha, Paul\nShinn, Bradley J Collins, Inthirany Thillainadarajah,\nChristopher M Grulke, Antony J Williams, Ryan R Lougee,\nRichard S Judson, et al. 2020. The tox21 10k com-\npound library: collaborative chemistry advancing toxicol-\nogy. Chemical Research in Toxicology, 34(2):189–216.\nMobashir Sadat and Cornelia Caragea. 2022. Scinli: A corpus\nfor natural language inference on scientific text. arXiv\npreprint arXiv:2203.06728.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H Bach,\nLintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud\nStiegler, Teven Le Scao, Arun Raja, et al. 2021. Multitask\nprompted training enables zero-shot task generalization.\narXiv preprint arXiv:2110.08207.\nMichael Schmidt and Hod Lipson. 2009. Distilling free-\nform natural laws from experimental data. science,\n324(5923):81–85.\nMartin Schrimpf, Idan Asher Blank, Greta Tuckute, Carina\nKauf, Eghbal A Hosseini, Nancy Kanwisher, Joshua B\nTenenbaum, and Evelina Fedorenko. 2021. The neural\narchitecture of language: Integrative modeling converges\non predictive processing. Proceedings of the National\nAcademy of Sciences, 118(45):e2105646118.\nLei Sha, Oana-Maria Camburu, and Thomas Lukasiewicz.\n2021. Learning from the best: Rationalizing predictions\nby adversarial information calibration. In AAAI, pages\n13771–13779.\nTaylor Shin, Yasaman Razeghi, Robert L Logan IV , Eric Wal-\nlace, and Sameer Singh. 2020. Autoprompt: Eliciting\nknowledge from language models with automatically gen-\nerated prompts. arXiv preprint arXiv:2010.15980.\nChandan Singh, W James Murdoch, and Bin Yu. 2019. Hierar-\nchical interpretations for neural network predictions. Inter-\nnational Conference on Learning Representations, page 26.\nRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang,\nChristopher D Manning, Andrew Ng, and Christopher Potts.\n2013. Recursive deep models for semantic composition-\nality over a sentiment treebank. In Proceedings of the\n2013 conference on empirical methods in natural language\nprocessing, pages 1631–1642.\nHendrik Strobelt, Albert Webson, Victor Sanh, Benjamin\nHoover, Johanna Beyer, Hanspeter Pfister, and Alexan-\nder M Rush. 2022. Interactive and visual prompt engineer-\ning for ad-hoc task adaptation with large language models.\narXiv preprint arXiv:2208.07852.\nRoss Taylor, Marcin Kardas, Guillem Cucurull, Thomas\nScialom, Anthony Hartshorn, Elvis Saravia, Andrew Poul-\nton, Viktor Kerkez, and Robert Stojnic. 2022. Galac-\ntica: A large language model for science. arXiv preprint\narXiv:2211.09085.\nMichael Tsang, Dehua Cheng, and Yan Liu. 2017. Detecting\nstatistical interactions from neural network weights. arXiv\npreprint arXiv:1705.04977.\nBen Wang and Aran Komatsuzaki. 2021. GPT-J-6B: A 6\nBillion Parameter Autoregressive Language Model.https:\n//github.com/kingoflolz/mesh-transformer-jax.\nXingqiao Wang, Xiaowei Xu, Weida Tong, Ruth Roberts,\nand Zhichao Liu. 2021. Inferbert: a transformer-based\ncausal inference framework for enhancing pharmacovigi-\nlance. Frontiers in Artificial Intelligence, 4:659622.\nYizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi,\nYeganeh Kordi, et al. 2022. Benchmarking generalization\nvia in-context instructions on 1,600+ language tasks. arXiv.\nAlbert Webson and Ellie Pavlick. 2021. Do prompt-based\nmodels really understand the meaning of their prompts?\narXiv preprint arXiv:2109.01247.\nOmar Zaidan and Jason Eisner. 2008. Modeling annotators:\nA generative approach to learning from annotator ratio-\nnales. In Proceedings of the 2008 conference on Empirical\nmethods in natural language processing, pages 31–40.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe,\nMoya Chen, Shuohui Chen, Christopher Dewan, Mona\nDiab, Xian Li, Xi Victoria Lin, et al. 2022. Opt: Open\npre-trained transformer language models. arXiv preprint\narXiv:2205.01068.\nRuiqi Zhong, Kristy Lee, Zheng Zhang, and Dan Klein. 2021.\nAdapting language models for zero-shot learning by meta-\ntuning on dataset and prompt collections. arXiv preprint\narXiv:2104.04670.\nRuiqi Zhong, Charlie Snell, Dan Klein, and Jacob Steinhardt.\n2022. Describing differences between text distributions\nwith natural language. In International Conference on\nMachine Learning, pages 27099–27116. PMLR.\n41\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran\nPaster, Silviu Pitis, Harris Chan, and Jimmy Ba. 2022.\nLarge language models are human-level prompt engineers.\narXiv preprint arXiv:2211.01910.\n42\nA Appendix\nA.1 Sentiment classification results\nFor sentiment evaluation, we learn a prompt within the template Input: “${input}”{prompt}.8 We use\npositive and negative as positive and negative labels and require the LLM to rank the two options. Human-\nwritten prompts are adapted to this template from open-source prompts available through PromptSource\n(Bach et al., 2022).\nTable A1 shows results on the sentiment analysis datasets. As prompts for GPT-J, iPrompt outperforms\nnot only AutoPrompt, but also the manually-written prompt on all four datasets. Interestingly, the average\nperformance of human-written prompts on GPT-J is very low, unlike the prompts generated by iPrompt.\nThis indicates that models at 6B parameter scale may be brittle to the choice of prompt, even among a\nset of reasonable options, and iPrompt (and to an extent, AutoPrompt) is able to discover how to phrase\nprompts so that models of this scale can complete the task.\nWhen sentiment prompt generalization is tested on GPT-3, we find that iPrompt prompts outper-\nform human-written prompts on two of the four datasets. When tested on GPT-3, iPrompt prompt To\nsummarize this review! : outperforms all PromptSource IMDB prompts that use the same verbalizer\n(positive/negative). When its prompts are tested on GPT-3, baseline AutoPrompt only slightly outperforms\ntesting with no prompt at all.\nTable A2 shows the best prompt produced by each method for each sentiment dataset. iPrompt often\nlearns to recreate significant examples from the dataset, as a prompt. Fig. A1 shows loss across training\nstep for each method and dataset, across three random seeds. We see that AutoPrompt often finds a\nprompt with slightly lower loss on the training data, although its prompts lead to worse generalization, as\nreported in Table A1. Each training step represents a single word swap (in the case of AutoPrompt) or the\ntruncation and generation of a new prefix (in the case of iPrompt).\nDifferent from the other experiments in this paper, for sentiment classification, we initialize AutoPrompt\nwith random tokens instead of all the, as we find AutoPrompt fails to find an effective solution for longer\nprefix lengths when all tokens are initialized to the. To accommodate for a complex input-output\nrelationship, we test prompts of length 12 as well as length 6.\nAccuracy is measured on the test set when available; otherwise, it is measured on a held-out 25% of the\ntrain set.\nTable A2: Best-of-three prompts generated by each method on sentiment classification datasets. (Human-written\nprompts are best-of-eight and taken from PromptSource (Bach et al., 2022)).\nTask Method Prompt\nFinancial phrasebank\nAutoPrompt Fur resultolandgroundur augmented\nHuman-written prompt How does the author of the news headline feel?\niPrompt <input> neutral> The result was due to: \"\nIMDB\nAutoPrompt uclear cend Koretravel NAACP curses SicAstings production received\nHuman-written prompt The movie review in negative/positive sentiment is:\niPrompt This movie needs to be put up on my profile as my\nRotten Tomatoes\nAutoPrompt Whether{{ anotherath<|endoftext|> how\nHuman-written prompt What sentiment does the writer express for the movie?\niPrompt what words would you try to add to help you express that\nSST-2\nAutoPrompt BryceSpecificallyW ASHINGTONRatedam\nHuman-written prompt What is the sentiment expressed in this text?\niPrompt It is clear from the sentence that all three actors have something\n8In initial experiments, we find that performance drops significantly when learning a prompt that comes before the input.\n43\nTable A1: Zero-shot accuracy on sentiment classification datasets: SST-2, Rotten Tomatoes, IMDB, and the\nFinancial Phrasebank (Socher et al., 2013; Malo et al., 2014; Pang and Lee, 2005). Generation with GPT-J 6B and\nevaluation on both on the original GPT-J model and GPT-3 (text-davinci-002). Errors are standard errors of the\nmean.\nHuman-\nwritten iPrompt AutoPrompt No\nprompt\nGPT-J\nFFB 27.0 ± 1.9 79.3 ± 2.1 74.0 ± 9.1 47.5\nRT 58.9 ± 3.1 84.8 ± 0.9 73.0 ± 4.8 59.2\nSST-2 58.4 ± 2.8 86.7 ± 1.0 76.7 ± 3.9 60.9\nIMDB 66.0 ± 3.2 87.9 ± 1.4 86.7 ± 1.2 58.6\nGPT-3\nFFB 39.6 ± 1.6 57.2 ± 6.9 28.2 ± 3.1 39.1\nRT 82.7 ± 3.3 77.4 ± 2.8 57.8 ± 3.5 54.8\nSST-2 90.5 ± 3.9 82.4 ± 2.3 61.8 ± 7.0 58.4\nIMDB 75.6 ± 3.3 86.6 ± 1.1 70.0 ± 6.5 66.2\n0 50 100 150 200 250 300\n0.35\n0.40\n0.45\n0.50\n0.55\n0.60\nffb_train\n0 50 100 150 200 250 300\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n0.55\n0.60\nimdb_train\n0 50 100 150 200 250 300\n0.35\n0.40\n0.45\n0.50\n0.55\n0.60\nrt_train\n0 50 100 150 200 250 300\nNumber of iterations\n100\n2 × 10 1\n3 × 10 1\n4 × 10 1\n6 × 10 1\nNLL\niPrompt Loss\niprompt\nautoprompt\nFigure A1: Loss plots for methods across sentiment analysis datasets, showing AutoPrompt and iPrompt across\nthree random seeds.\n44\nA.2 Data/model details\nTable A3: Details for each dataset. For details on Instruction induction, see (Honovich et al., 2022) and for details\non Distribution differences, see (Zhong et al., 2021).\nTask name Samples Description Example\nfibonacci_one 10 Given an input x, return the xth fibonacci number. Given the input x is 8, the output f(x) is 21.\\n\\n\ndouble_one 10 Given an input x, return 2*x. Given the input x is 6, the output f(x) is 12.\\n\\n\nexp_one 10 Exponentiate the input to get the output. Given the input x is 8, the output f(x) is 2980.96.\\n\\n\nsquare_one 10 Square the input to get the output. Given the input x is 2, the output f(x) is 4.\\n\\n\nfirst_two 100 Return the first of the inputs. Given the input numbers 7 and 8, the answer is 7.\\n\\n\nadd_two 100 Return the sum of the inputs. Given the input numbers 9 and 7, the answer is 16.\\n\\n\nsubtract_two 100 Return the difference of the inputs. Given the input numbers 5 and 4, the answer is 1.\\n\\n\ndivide_two 100 Return the quotient of the inputs. Given the input numbers 2 and 7, the answer is 2/7.\\n\\n\nmultiply_two 100 Return the product of the inputs. Given the input numbers 3 and 3, the answer is 9.\\n\\n\nmax_two 100 Return the maximum of the inputs. Given the input numbers 1 and 1, the answer is 1.\\n\\n\ntask1191_food_veg_nonveg 101 Return whether the input food dish is vegetarian (yes or\nno).\nInput: Haq Maas Answer: no\\n\ntask1149_item_check_edible 119 Return whether the input item is edible (yes or no). Input: vase Answer: no\\n\ntask1146_country_capital 231 In this task, you are given a country name and you need\nto return the capital city of the given country\nInput: Saint Pierre and Miquelon Answer: Saint-Pierre\\n\ntask1147_country_currency 232 You are given a country name and you need to return the\ncurrency of the given country.\nInput: Senegal Answer: CFA Franc BCEAO\\n\ntask1509_evalution_antonyms 551 In this task, you are given an adjective, and your job is to\ngenerate its antonym. An antonym of a word is a word\nopposite in meaning to it.\nInput: paper Answer: scissor\\n\ntask183_rhyme_generation 999 Given an input word generate a word that rhymes exactly\nwith the input word. If not rhyme is found return \"No\"\nInput: think Answer: sync\\n\ntask107_splash_question_to_sql 2031 In this task you are expected to write an SQL query that\nwill return the data asked for in the question. An SQL\nquery works by selecting data from a table where certain\nconditions apply. A table contains columns where every\nrow in that table must have a value for each column. Every\ntable has a primary key that uniquely identifies each row,\nusually an id. To choose which columns are returned you\nspecify that after the \"SELECT\" statement. Next, you use\na \"FROM\" statement to specify what tables you want to\nselect the data from. When you specify a table you can\nrename it with the \"AS\" statement. You can reference\nthat table by whatever name follows the \"AS\" statement.\nIf you want to select data from multiple tables you need\nto use the \"JOIN\" statement. This will join the tables\ntogether by pairing a row in one table with every row in\nthe other table (Cartesian Product). To limit the number\nof rows returned you should use the \"ON\" statement. This\nwill only return rows where the condition...\nInput: What are the order ids and customer ids for or-\nders that have been Cancelled, sorted by their order dates?\nAnswer: SELECT order_id , customer_id FROM cus-\ntomer_orders WHERE order_status_code = \"Cancelled\"\nORDER BY order_date\\n\ntask088_identify_typo_verification 6499 The given sentence contains a typo which could be one\nof the following four types: (1) swapped letters of a word\ne.g. ’niec’ is a typo of the word ’nice’. (2) missing letter\nin a word e.g. ’nic’ is a typo of the word ’nice’. (3) extra\nletter in a word e.g. ’nicce’ is a typo of the word ’nice’.\n(4) replaced letter in a word e.g ’nicr’ is a typo of the word\n’nice’. You need to identify the typo in the given sentence.\nTo do this, answer with the word containing the typo.\nInput: A laege display of apples, pears, and oranges An-\nswer: laege\\n\ntask1336_gender_classifier 6500 Return the gender of the person in the input sentence. Input: Justin made me feel discouraged. Answer: M\\n\ntask092_check_prime_classification 6500 In this task, you need to output ’Yes’ if the given number is\na prime number otherwise output ’No’. A ’prime number’\nis a a whole number above 1 that can not be made by\nmultiplying other whole numbers.\nInput: 9319 Answer: Yes\\n\nTable A4: Models analyzed here.\nModel name Huggingface identifier Citation\nGPT-2 (1.5B) gpt2-xl (Radford et al., 2019)\nOPT (2.7B) facebook/opt-2.7b (Zhang et al., 2022)\nGPT-Neo (2.7B) EleutherAI/gpt-neo-2.7B (Black et al., 2021)\nFlan-T5 (3B) google/flan-t5-xl (Chung et al., 2022)\nGPT-J (6B) EleutherAI/gpt-j-6B (Wang and Komatsuzaki, 2021)\nOPT (6.7B) facebook/opt-6.7b (Zhang et al., 2022)\nGalactica (6.7B) facebook/galactica-6.7b (Taylor et al., 2022)\nGPT-Neo (20B) EleutherAI/gpt-neox-20b (Black et al., 2022)\nGPT-3 (175B) text-davinci-002 (OpenAI API) (Radford et al., 2021)\n45\nA.3 iPrompt results extended\nWe consider discriminators of varying sizes, with GPT-J (6B) as a prompt generator. We also compare\ngenerators of varying sizes with GPT-J (6B) as a prompt discriminator. Models considered are of\n{125M, 1.3B, 2.7B, 6B} parameters from the GPT-Neo/GPT-J language model family. Results are\nshown in Fig. A3. Performance varies smoothly across model sizes, with the highest performance when\nusing the largest model for both reranking and generation. Reranking appears slightly more important\nthan generation. When using a 1.3B parameter model for generation, MRR drops only slightly, from\n0.418 to 0.399, while when using a 1.3B parameter model for reranking, MRR drops to 0.211. In general,\nprompt recovery performance improves smoothly with reranking model size.\nFig. A2 plots the progress of iPrompt across iterations, comparing runs on Math datasets (blue) to runs\non ANLI datasets (gray). iPrompt appears to make most of its progress during the first20% of training and\nthen continue to slowly decrease the average loss. Running for more iterations on additional datapoints\nwould likely increase performance.\n0 50 100 150 200 250 300\nNumber of iterations\n4.0\n4.5\n5.0\n5.5\n6.0NLL\niPrompt Loss\nMath\nANLI\nFigure A2: iPrompt performance across training, averaged across three random seeds and all tasks from Math\ndatasets (Blue) and ANLI (Gray).\n125M\n1.3B\n2.7B\n6B\nGeneration Model Params\n125M\n1.3B\n2.7B\n6B\nReranking Model Params\nMRR\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nFigure A3: iPrompt performance across different size language models for the prompt proposal and reranking steps.\nValues are mean reciprocal rank of first accepted prompt averaged across 20 tasks and 3 random seeds.\n46\nTable A5: Performance of Galactica at prompt recovery, including DD datasets (Zhong et al., 2022, 2021).\niPrompt AutoPrompt Suffix\nMRR\nMath 0.2 0.09 0.025\nANLI 0.39 0.0025 0.085\nInduction 0.14 0.098 0.056\nDD 0.064 0.0082 0.066\nCorrect\nMath 0.12 0.075 0\nANLI 0.34 0 0.025\nInduction 0.071 0.087 0.02\nDD 0.043 0 0.052\nBLEU-Top Prompt\nMath 0.0073 0 0\nANLI 0.01 0 0.00032\nInduction 0.022 0 0.0027\nDD 0 0 0.0015\n47\nTable A6: Examples of top-generated prompts for each method: GPT-J main datasets.\nautoprompt iprompt suff\nactive to passive (= 18 the the subst Choose a pronoun for each sentence Create a sentence or group of\nadd two >:Returns Adding togetherFont accomplish Create a function named `sum n>2 m1\nantonyms the bectheBut But The noun to its opposite ( The code to ascend. You\ncause and effect REG Kinect virginity developed mosquit The What would each sentence be if write programs that read through an\ncommon concept ???????? parted configuredthe ???????? Find a noun that includes all which is a common word used\ndiff \"\"Fair 62 disgust 92 81 Find the difference between largest Write a program or function to\ndivide two soughtWomen surgicalthe Percentage treated \"Divide each digit by write a program or function who\ndouble one says transit Farethe doubles dollars Write a function called double_ Given two function pointer A and\nexp one &&wl +# 123 270 Earthquake Input this into your calculator ( Type in number between 15 &\nfibonacci one baptpi produce347).'' Implement a function to find Fib Given an integer n (1\nfirst two Binding decode wr detect shortest numeric Find first digit of given number When was Python added to Ubuntu\nfirst word letter Exception Ps< endoftext >the the Make a program that reads in nimshul, a\ninformal to formal CLASSIFIEDthe themselves strongly Plays Chamber These are questions on simple sentences Make the following sentences positive statements\nlarger animal ????????thethethethethe What is the most common animal dogAnswer to \"What 's\nletters list fluidsthethethethethe Given the following list of tokens The computer will make this document\nmax two spendingthethethethethe Implement a version of max() Write code to find out given\nmultiply two ruits=\"# multipl integer multiplied False 'How do you multiply a write a program or function who\nnegation performs antiv Sizethe NULL NULL I found these four mistakes below Your friends think that you\nnum to verbal irritatedthedd respectfully Protectivethe Output each number below in the The program outputs the first input\northography starts with nextbusiness wordevery morphpp Name of two homophones You will be given five words\nrhymes Steal batter dating: unfold testosterone Find the missing word for all Input [create] What\nsecond word letter i mascot okay kk Who gave the answer \"o the United states government outlawed\nsentence similarity value %%%% Math 3 (5 marks). The Read five sentences about your topic\nsentiment positively optimistic&&&& negative I 'm voting \"negative\" Melvins at CBGB\nsingular to plural Enhanced shorthand Lets pluralbetweenthe Given a noun and its plural 1. It may be\nsquare one Cal impl qApplySquare fiat Input number and return its square Write a program or function to\nsubtract two ignorethethethethethe Write a function to find difference Given a non-negative integer\nsum Photosthethethethethe Add two numbers together and then The program outputs, without any\nsynonyms Word termOn English meanings what is a synonym for Is there a cure for an\ntask088 identify typo verifi-\ncation\nthethethethethe This word scramble is to test You wake up in the morning\ntask092 check prime classifi-\ncation\nropheospels&& Norestricted Are these pairs of integers prime Print the input numbers in order\ntask107 splash question to\nsql\nHow Do You Connect SQL To To get into MySQL you first\ntask1146 country capital Ang Suppose AUTHthe beh Assassins Which city is the capital and France, England or the UK\ntask1147 country currency aaaathecurrency Nib Sc Ireland. Which currency is spoken \"I am working on a\ntask1149 item check edible no the870830 yes coffee and beans are fruits. Which one of the following is\ntask1191 food veg nonveg compliedthe whether methamphetamine provided comp Are you a vegetarian? It could be any food,\ntask1336 peixian equity eval-\nuation corpus gender classi-\nfier\n< endoftext > -> M Fundamental FG Fav Predict the gender (F = ??????,???,\ntask1509 evalution antonyms contrad orously inverted ironically trans find words with the opposite meaning Record your input and answer,\ntask183 rhyme generation quarterdream dug}. Thro rhy Mind vs Glee! There what do you love to eat\ntaxonomy animal programmingQ errorsBefore admitting mont What are the most common animals Each of these questions is a\ntranslation en-de H prob Hyper Forthe You are a lawyer practicing in This is an example of input\ntranslation en-es the ththebb volunt please write English meaning in Spanish Porque?\ntranslation en-fr IRthe< endoftext >thethe the What is the French word for Your code needs to deal with\nword in context (\"nSame distinguishedthethe Same and Not-Same - What you will do is have\n48\nTable A7: Examples of top-generated prompts for each method: GPT-J DD datasets (Zhong et al., 2022, 2021).\nautoprompt iprompt suff\nd3 0 line contains this string? No contains all 6 items, No\nd3 1 Ghostbustersthe interrogation condition criminall sentence contains \"yes\" or string doesn 't match any template\nd3 10 preceded Roosevelt nonexistentuphem_-_ Tw message contains \"no\". No contains all of these words or\nd3 11 caused senator prompt Recall interacted string contains \"No\" or was matched; output otherwise No\nd3 12 begin:\" r \"},{\" contradict tweet mentions yes is true or output false if\nd3 13 },{\" vote [*\"]=> answer \"no\" (or contains all correct answers, No\nd3 14 nonexistent undead questions Enhance mandated no string begins 'no' and string contains any non blank white\nd3 15 rarely ----Question not},{\" geometric string contains \"no\" or includes exactly two English words with\nd3 16 \\n pearthemar Display RUN text contains any \"yes\". text is true, otherwise write\nd3 17 EMP Similarly\\t=== charsthe is an answer (\"no\", contains all correct answers for this\nd3 18 \\n\\n Verb horm suffix Eucl phrase starts with 'no', contains all correct answers else No\nd3 19 \\n.\",\" Emacs strips colors strips word starts with 'yes', text contains any of these strings\nd3 2 indirectly [[ pervasive?\"Spoiler exhaustive ends with \"yes\". If sentence has an \"O\"\nd3 20 \\n\\n dips Vote flower Ainthe ted sentence contains both \"yes contains one of these words or\nd3 21 \\nthePubLeft Abstract ends with 'no'. No contains all correct answers, or\nd3 22 Nov wholesno Eucl NO can output no/yes, data set contains results for output\nd3 23 vantage immediately recogn example nails 309 no else output none? Input contains data describing or referring to\nd3 24 noBER nonosRew [ datum defines finite number fields is in fact equal 2;\nd3 25 withdrawalsnob inher nob Among contains both gene list data file has already started in state x\nd3 26 Joined robberHigthe contradictionNarr line ends with a space, ted series matches any of these\nd3 27 verseoleon:- inferred cannabinoids was positive answer and \"No string of words, as shown\nd3 28 \\n repet999 REM=[nov refers exclusively (only literally or was a real question that could\nd3 29 \\n Pat uncertaintiesMerit oppos line begins with yes text meets any one or more\nd3 3 \\n\\n887odynamHor mun\\t ends with \"yes\" and statement reflects truth. Otherwise output\nd3 30 detainees gap ${. hardness statement is false? Otherwise is an example from each category\nd3 31 \\n055 helium **** itching phrase does not contain any words given was false or not a\nd3 32 Afghthethethe matches either one of these strings text is true, and write\nd3 33 le \\r 253 has a duplicate word. Correct contains yes\nd3 34 the Carnegie allerg Qu the no,no for (1 was \"The End\" or\nd3 35 Hatch Land pri poker[[ Yah would be a no (I text can create a good argument\nd3 36 ], egregbyte?Sensor matches exactly a \"no\". string meets any, or exactly\nd3 37 noun441...? word first neg question has an answer \"no string meets any, and write\nd3 38 wond <+ HELP\"},{\"InvalidOtherwise says yes \"yes\" has an\nd3 39 notnobbutthe but reads like no. answers \"yes\" for all\nd3 4 \\n\\n 760 consensualNarr Fog cabbage sentence ends with \"no\". string was a valid answer otherwise\nd3 40 modeXP/, \\n but question contains an actual \"no given was wrong or not relevant\nd3 41 opinions universitythe began followingawaru sentence is grammatically correct, equals to zero (i.\nd3 42 disqualified hemor Ratings [ contradiction Moham phrase represents something that is actually has 1 out of 2 responses\nd3 43 \\n\\n saturated Phot misc would be rightAnswer :no was about a government regulation (\nd3 44 \\n <[ npm spaces1 was \"no\": Input was \"yes\" else false\nd3 45 \\n\\n pit VerbFalse Tok string contains one \"no\". text starts with \"OK\",\nd3 46 },{\" Neil kingthe no when a string containing one contains this string! Yes,\nd3 47 network intuitive 19 Lamp sentence implies that no can mean contains all digits, else No\nd3 48 nond307 Literally negativeJun corpor conforms with known facts no ted number from user base 5\nd3 49 Falsethe Rect 802 string contains \"no\" or contains all of these words,\nd3 5 contradicts absurdity Luffythe neg answ string 'no' appears as is correct ; No otherwise\nd3 50 ________________________ WithNo\",\"hedon mentions \"no\" (or contains all correct items, No\nd3 51 \\n\\n 276WithNo noodles Cosponsors reads \"no\" no else given was no; not output\nd3 52 \\n\\n 225Should laure string was 'no' and string contains just one space.\nd3 53 never_{ Johns neo no is all lower case answer 1 was what I described above!\nd3 6 forbids Literally reminisNone negate text contains any \"no\" text contains Syrian\nd3 7 },{\"\\r stringologically $\\ git contains 'no' or output text contains yes\nd3 8 unlikelyEitherselessletter Ches contradictory sentence contains 'no' or contains any newlines after matching\nd3 9 reactive happensMiddle lot Inc matches any word (no is text meets any, or none\n49\nTable A8: Examples of top-generated prompts for each method: Galactica main datasets.\nautoprompt iprompt suff\nactive to passive Transmission Electthe chromosome initialized empl 4-way Multiple Choice Is the context a good response\nadd two addthe Hyper addi In order to add two or Given three real-valued inputs\nantonyms meet equilibration stiptertead asymmetry What is the opposite of each [T1] Question\ncause and effect shaking Dthethethethe Find clues as to why each What do you think will happen\ncommon concept Bary techntbltbltbl Te Where are all the animals? What ' s the most common\ndiff quartic digits shorter recreational genomics Given two positive integers a and What 's the most efficient\ndivide two manipulations comput iterationects quotients The ratio of two real or Given two different positive integers what\ndouble one roll Add Pingthe brakingthe Determine how much money did Al What 's it like to\nexp one visc poplLSPLC Viscositythe Given a number y and an Find a formula for this linear\nfibonacci one start Attstrass Prim Polynomial emotions \\bigcirc m o Write a function that gives an\nfirst two AICthethethe Adethe Solve using negative exponents? Explain We have found it helpful to\nfirst word letter d rthe l c syllable What is the last word? the program {x.\ninformal to formal Why unpredictable comprobablyould Detecting Yes! However, since we Text-to-Text Data\nlarger animal sharkoganopeanionaller descri A question is given about three Is the pair of animals on\nletters list microm phon te photothermal te te How many 8 letter words Given the following paragraph, indicate\nmax two $$amater Penet credible b How large was each of your Is that as simple or complex\nmultiply two aris visualthe Gibson multiplicative lexical When we multiply two even or What number divided by what other\nnegation brood he Apparent denselythe FIG What did these people have as This time we do two prompt\nnum to verbal Pixel lum sedimentary precedenceathion thousand P(data answer) Number pairs that are in the\northography starts with criptions geochemistry Harvey preprocessed Kus Cap The correct verb after each input Why did they choose this strategy\nrhymes hallucinations song cooperationcorner ask smear Which phrase did \"sea My favorite food is a\nsecond word letter oderraj dialectath u o What is the fourth letter Is the object in this image\nsentence similarity false provleastleast Apparently I understand your definition correctly that Chinese No Vote and Euro\nsentiment nominationnegative<unk>indolinivalentpolar What is the sentiment of a What do you think will happen\nsingular to plural mes sequthethethethe Find the pluralization of Do you have any good ways\nsquare one AnalyticmassesAtomnamespace binning pow Determine how much money did Al What 's it like to\nsubtract two ComplexRemthe scienti Event Given a variable called A whose Is that close to your actual\nsum Horujanthethethethe I 'm trying to solve Is the following number even?\nsynonyms straightforward conceptual Striking Etymology tra Can you think of a word [T1],\ntask088 identify typo verifi-\ncation\nEtymology nom scalesrolateral QMples What is the plural form? Other types Task Definition ::\ntask092 check prime classifi-\ncation\nAccept No source Inter question Q3_NoAnswerYes Are there any types of chemical\ntask107 splash question to\nsql\nQuestion answering Input #Name Is the following SQL clause equivalent\ntask1146 country capital Outer Hassan wal Tu Spontaneous Qu List the capital cities in each The country that _____\ntask1147 country currency Llthethestr the Find the most common currency in What currency was the first to\ntask1149 item check edible nonthethe Characterizing Nothe Why is no answer True or False, \"\ntask1191 food veg nonveg gue axiomsepid Output yes Birk Are you a native speaker of In a world where the Supreme\ntask1336 peixian equity eval-\nuation corpus gender classi-\nfier\nlineage Mthe knockdown Fthe What is the gender of Who is a good conversational partner\ntask1509 evalution antonyms Modern Carlson Weyl Linguistic counterfactual met Find the opposite of each given We can predict text from an\ntask183 rhyme generation stellarthethethe pl battle The 6-letter word We are given a dataset consisting\ntaxonomy animal duoull Pap codebook varic lysozyme When two objects collide and expl What 's the most common\ntranslation en-de shor Thanthe condens Intinte Test for spelling error in word Is the object of your activity\ntranslation en-es trophic Description params oscthethe In Spanish, there are two cuatro con la frec\ntranslation en-fr TT tic tgtthethe Disk Les champs du monde What can the words in bold\nword in context \" Tang samethe offOff Identify similar phrases based on given Does this sentence come from an\n50\nTable A9: Examples of top-generated prompts for each method: Galactica DD datasets (Zhong et al., 2022, 2021).\nautoprompt iprompt suff\nd3 0 Alloy ReeABL vetotitledthe satisfies sarcastic predicate; otherwise is sarcastic, otherwise ignore\nd3 1 Cosm compositionallyind locom astro bfnm and output share 82 sentence describes or is related to\nd3 10 onso Seman NichentiVALID paragraph does not contain any word says the answer is yes on\nd3 11 enzo conspicuous Widespreadfeature cis orth mention e does not match any says that the United States president\nd3 12 assert unco Nog antich DesignsFOR contained a negation phrase otherwise an says that someone arrives or de\nd3 13 functionnoAns medi monos BAA text contains no keywords and none is valid, no otherwise.\nd3 14 E PotassiumztheANASS the United Nations integrated multi contains the context word or response\nd3 15 no Nons TRANS Trajectories Exclusionifying phrase is not a noun; example satisfies all rules, otherwise\nd3 16 TiHas Gomes immigPropthe sentence contains the word no mentions the answer and @US\nd3 17 spatiotemporal extragalactic conflicts forbidden data includes at least one Sem was true, and output false\nd3 18 formulAns revisit transcri neither ends in no no contain any formals in it\nd3 19 fatSPR Inhibitsickel nestedyes is valid.Answer: no text contains the word \"\nd3 2 propositional ScalarAsp Attacks train Rabin contain any of given words otherwise\nd3 20 Sem adjunct DCT Eriks admissibleArg is prochoice no otherwise says something about abortion or human\nd3 21 scatterflows vetoriz pen sentences contain both \"no sentence includes sexual, gender identity\nd3 22 yesoscopyGal martingale Yes epistemic no. For ``yes data satisfy certain conditions Otherwise No\nd3 23 NoELO predictors SBATCHvect holds no otherwise [START_REF] Primordial Predictive Models are Interpretable on\nd3 24 norist Investigating Nos tumorigenesis Bit term \"noisy inputs follows the given probability density function\nd3 25 nopins bil field ensembles Locus no output no yea Prom says that neutrinos have been observed\nd3 26 NeuthePreftheDEthe sentence is a negation; an sentence includes \"cutter\nd3 27 no Conditional abstract definiteLD statement contains this word, and says that certain events have happened\nd3 28 CIS raftriendrolimussubseteq data contains feminism, and says that are feminists\nd3 29 noAns Semantic neitherHamiltonian dissoci text contains no, says something against women or gender\nd3 3 nondec yes Census Tam Policies acyclic IS semst; else, says something against your religion on\nd3 30 itasenta Assim allergic Fraser text contains answer=yes and data includes y and n,\nd3 31 Strategy monitors Confl HaleFIELD Rhode data contains a negative sentiment, matches at least one of a\nd3 32 Regulates term Cliff steer VER Saskatchewan mentions no and no sentence includes a pronoun that refers\nd3 33 mut Congress SyntN weakhis text contains the phrase yes sentence includes a token for each\nd3 34 yes<fragments> Kohn povertyyes Circular are based in movies. no says that Erik has his\nd3 35 noon nonlocalakh no no s question contains YesNo words like movie was very good otherwise mark\nd3 36 describes nomoduleno RevealsAs sentence does not contain a factor text includes any unanswerable\nd3 37 penADOapineg autoclHAL phrase no appears only sentence has an answer. Otherwise\nd3 38 noNoEnabl complementation BIT Polar question contains the phrase no, says that certain language has more\nd3 39 Neuastro neur runaway suffixthe utterance contains this phrase no says something about your personality,\nd3 4 MULT semilinear unarybuffer Gior fate sentence does not contain a modal meets any condition given in Sem\nd3 40 outputs vigilance mK Unsupervised Status initial data contains no and no else correctly answers your question, otherwise\nd3 41 answ neph Membership Bess decomp neurop equilibrium does not hold; no does not contain either of x\nd3 42 Surveillance Semantics Obl Inhibits Hels MEL string isn 't in English says that climate issues have worsened\nd3 43 Ans yesArg Zika spar supports my belief no otherwise Input follows the context; Otherwise output\nd3 44 wer: inducible affirm Abl reflex contain any formals words or\nd3 45 ana1 ERGsentence loopsyless string does not occur in training question were \"Is there\nd3 46 GitHub Clevelandck negation RCC Microbial contains no fake or misn movie was released before year\nd3 47 ful eth massoc bis NA debris affects doesnt have any says that we need your assistance\nd3 48 \\n Nons FernclassGridUHFFFAOYSA holds for all possible inputs no sentence includes a pronoun as well\nd3 49 noNo Imper Creating noPan sentence contains no in matches answer which will give correct\nd3 5 volat Salv Artificial economies fut Hale prompt is followed by no says that the output is a\nd3 50 failedkin ResDesMM string does not contain any stop says that wight is decreasing\nd3 51 bl Frederthe Novo phylogeneticthe for \"is my child contains the context of your response\nd3 52 onasnono domainsex Quanti phrase has the value no, sentence includes something that will lead\nd3 53 onisenony anonh includes the words no output will contains at least two noun phrases\nd3 6 Alle substrthe Edmund Hos forks answer no contains this word or is a valid response and vice\nd3 7 Antithethethe Blakethe word is a negation of micro sentence includes all possible answers Prom\nd3 8 Brand abolished affili attri Recon corresponds with prompt question no sentence is suitable Question for yes\nd3 9 Bou counterex abstnougin literal question has answer no, output is correct but maybe not relevant\nA.4 Experiment details / hyperparameters extended\nAverage-output suffix decoding LLMs themselves can be directly used to predict prompt strings.\nWe can give the model a prompt that includes examples such as the following context string:\nIn: 2 5| {z }\nxi\nOut: 7.| {z }\nyi\nTo compute the output from the input,| {z }\ntemplate\n, and sample the output for the blank to recover\na prompt ˆs. Sampling directly from f helps ensure that the generated explanation is fluent and seman-\ntically meaningful. We decode the output using beam search to find the highest-probability outputs for\n51\nmulti-token prompts.9 To improve on this approach, we place several examples into the model’s context,\nand then average the model’s output logits across all the examples in the dataset before decoding the\noutput, an approach we refer to as average-suffix decoding. However, we find that average-suffix decoding\ndoes not yield a performance improvement over straightforward decoding from a single sample with\nexamples in the context. For example, Fig. A4 shows that for the ANLI datasets, the mean reciprocal\nrank for average-output sampling does not tend to be higher than for single-output sampling across two\ndifferent models.\nMRR\nGPT-Neo (2.7B)GPT-J (6.7B)\nFigure A4: Average suffix sampling versus individual-example suffix sampling does not improve performance (for\nANLI datasets).\nHyperparameters for iPrompt and AutoPrompt This subsection discusses the hyperparameters set for\nprompts generated on Math, NLI, and sentiment tasks. For Math and NLI tasks we considered prompts of\nlength 6 tokens; for sentiment we considered prompts of length 16. For all experiments with iPrompt we\nconsider 8 candidate explanations for each step and generate 4 new generations per candidate, for a total\nof 32 candidates. For fair comparison, we consider 32 candidates per step for AutoPrompt. We generate\nMath and NLI from 5, 000 training steps and Sentiment candidates from 10, 000 steps. We truncate\nexamples to a maximum of 128 tokens. We measure loss for re-ranking (used by both AutoPrompt and\niPrompt) using the LLM’s loss over the full space of output tokens, i.e. we do not restrict the vocabulary\nto the space of label tokens for classification problems.\nDetails of iPrompt Here we explicate the details of iPrompt. At each step, we consider a fixed number\nof mutations for each example in the population, as well as an additional number of random generations\nto prevent the population from getting stuck in a local minimum. When we sample a new population, we\nsample the best-performing prompts seen so far, as measured by a running average zero-shot loss. In\norder to encourage diverse candidate prompts, sample a population such that each sample starts with a\ndifferent token. During preliminary experiments, we found that enforcing different starting tokens for\neach candidate prompt helped promote more diverse and interpretable prefixes.\nFor generation, we sample directly from the LLM given the data concatenated with the string\nnPrompt:. We sample with a temperature of 1 and do not use a sampling strategy like nucleus sampling.\nFor Math and NLI, we set the “repetition penalty” for generations to 2.0 to discourage copying from the\ntraining set. For the sentiment experiment, we reduce the repetition penalty to 1.0.\nDetails of AutoPrompt We note several changes to AutoPrompt that were not mentioned in the original\npaper but present in the original codebase, and proved crucial in our implementation.\nFirst, if we compute the top-candidates over every position, the magnitude of the gradient will always\nbe highest at position 0, and thus AutoPrompt will prefer to make a swap at that position every time. To\nfix this issue, at each training step, we randomly select a position of the token to edit and consider word\nswaps only at that position.\nSecond, as described, AutoPrompt will always take one of the candidate substitutions, even when said\ncandidate does not improve the loss compared to the current prefix. Instead, we only make a substitution\nif the candidate prefix loss is lower than the loss on the same batch computed with the current prefix.\n9Here we prefer beam search here over alternatives such as nucleus sampling (Holtzman et al., 2019) as we are interested in\nfinding an accurate prompt description with as few samples as possible.\n52\nTable A10: iPrompt performance at recovering prompts for toxic chemical compounds. Tox21 results are averaged\nover 12 datasets with 3 random seeds each. Null data is averaged over 36 random seeds. Error bars are standard\nerror of the mean.\niPrompt Baseline\nMRR 0.83 ± 0.04 0.0\nTop-prompt correctness 0.67 ± 0.08 0.0\nFinally, unlike the AutoPrompt implementation found online, we allow AutoPrompt to select from any\ntoken to substitute, including special tokens and non-English characters.\nTo make AutoPrompt compatible with ranking-based metrics, we store the losses for each candidate\nranked during training. At the end, we consider the “top prefix” to be the prefix with the lowest average\nloss during training, that has been considered at least three times. This final consideration criteria prevents\ncandidates from the very end of training that only have a few loss estimates from being counted as the top\nprefix.\nA.5 Galactica experiment details\nA.6 Chemical compound toxicity experiments\nToxic chemical compounds We first ask whether iPrompt can explain the difference between two\ngroups of chemical compounds with a known difference. We use the Tox21 dataset (Richard et al., 2020)\nwhich contains toxicity measurements on 12 biological targets. For each of the 12 biological targets, we\nsearch for a prompt that differentiates compounds that are toxic to the target (positive) from those which\nare not toxic to any of the targets (negative). We use 100 positive/negative examples for each biological\ntarget and format each input with the text Here is a compound:\\n [Compound Name]\\n Answer: followed\nby Yes for a positive compound and No for a negative one. iPrompt is run for a single epoch with 5 shots\nin each example.\nIdeally, the elicited prompt would mention toxicity. Table A10 shows results for whether the elicited\nprompts contain the substring tox, both in terms of MRR and top-prompt correctness. iPrompt often finds\nan accurate prompt: one representative example is: Answer yes if the compound is toxic, and Otherwise\nanswer NO. To ensure that this substring is not simply a popular completion for the language model, we\ncompare against a baseline which runs iPrompt using Galactica proposals from empty inputs/outputs and\nreranking with Galactica; over 36 random seeds, tox does not appear in any generated prompt.\n53\nA.7 Protein sequence experiments\nCytoplasm\nMembrane\nTransmembrane\nTransmembrane helix\nCell membrane\nTransport\nRNA-binding\nRibonucleoprotein\nRibosomal protein\nHydrolase\nPhosphoprotein\nMetal-binding\nTransferase\nNucleotide-binding\nATP-binding\nCytoplasm\nMembrane\nTransmembrane\nTransmembrane helix\nCell membrane\nTransport\nRNA-binding\nRibonucleoprotein\nRibosomal protein\nHydrolase\nPhosphoprotein\nMetal-binding\nTransferase\nNucleotide-binding\nATP-binding\n50000\n100000\n150000\nFigure A5: Swiss-Prot (Bairoch and Boeckmann, 1991) protein keyword cooccurences. To construct the Cyto and\nBinding datasets, we search for popular but non-cooccuring keywords.\nA.8 fMRI experiment details\nThis section gives more details on the fMRI experiment analyzed in Sec. 6; for more scientific details\nsee the original study (Huth et al., 2016) and code (github.com/HuthLab/speechmodeltutorial). Sec. 6\nanalyzes data from one human subject in the original study, as the subject listened to approximately two\nhours of narrative speech from the Moth Radio Hour, which consists of short autobiographical stories.\nThe subject underwent fMRI scanning as they listened, yielding an fMRI volume brain scan consisting of\ntens of thousands of voxels roughly every two seconds.\nThe individual voxel models described in Sec. 6 are each fit to 3,737 training points, each corresponding\nto a different time point (after accounting for various preprocessing steps, such as trimming the beginning\nand end of the sequence). They are evaluated on 291 training volumes which come from a 10-minute\nstory that was not seen during draining.\nFig. A7 shows the generalization performance of the model for each voxel, measured by the correlation\nbetween the predicted response and the measured response. Some regions are very poorly predicted\n(black), but many voxels can be predicted quite well (bright).\n54\n0 10\n1\nMaterial\nColor\nFigure A6: Representations of the iPrompt-elicited concepts material (blue) and color (red) across the surface\nof the neocortex are spatially clustered and smooth. Left hemisphere corresponds to Fig. 5. Only the top 10,000\nbest-predicted voxels are shown, remaining voxels are shown in black. Plotted with pycortex (Gao et al., 2015).\n0.0 0.1 0.2 0.3 0.4 0.5\nFigure A7: Generalization performance for individual-voxel models, measured by correlation between the prediction\nand the measured response.\n55\n material  color  fabric  text  surface\nConcept\n0.8\n1.0\n1.2\n1.4\nVariance between\nneighboring voxel scores\nActual scores\nShuffled scores\nFigure A8: Concepts are spatially localized in the brain maps: the variance between neighboring voxels is\nconsiderably lower than would be expected from shuffling the voxel values. Note that we take care ot shuffle the\nmap values only within the 10,000 top-predicted voxels, ignoring the poorly predicted voxels. Error bars (within the\npoints) are standard errors of the mean.",
  "topic": "Leverage (statistics)",
  "concepts": [
    {
      "name": "Leverage (statistics)",
      "score": 0.7902251482009888
    },
    {
      "name": "Computer science",
      "score": 0.7690783739089966
    },
    {
      "name": "Natural language",
      "score": 0.7170490026473999
    },
    {
      "name": "String (physics)",
      "score": 0.531938374042511
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5219968557357788
    },
    {
      "name": "Language model",
      "score": 0.4921690821647644
    },
    {
      "name": "Natural language processing",
      "score": 0.47345513105392456
    },
    {
      "name": "Natural (archaeology)",
      "score": 0.44098687171936035
    },
    {
      "name": "Natural language programming",
      "score": 0.4276280403137207
    },
    {
      "name": "Range (aeronautics)",
      "score": 0.4263139069080353
    },
    {
      "name": "Natural language generation",
      "score": 0.4103383421897888
    },
    {
      "name": "Data science",
      "score": 0.39806753396987915
    },
    {
      "name": "Machine learning",
      "score": 0.35136282444000244
    },
    {
      "name": "Universal Networking Language",
      "score": 0.2769673764705658
    },
    {
      "name": "Comprehension approach",
      "score": 0.09773048758506775
    },
    {
      "name": "Mathematics",
      "score": 0.08601075410842896
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Mathematical physics",
      "score": 0.0
    },
    {
      "name": "Materials science",
      "score": 0.0
    },
    {
      "name": "Composite material",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210164937",
      "name": "Microsoft Research (United Kingdom)",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I205783295",
      "name": "Cornell University",
      "country": "US"
    }
  ],
  "cited_by": 11
}