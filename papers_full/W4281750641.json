{
  "title": "RAAT: Relation-Augmented Attention Transformer for Relation Modeling in Document-Level Event Extraction",
  "url": "https://openalex.org/W4281750641",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2097437188",
      "name": "Yuan Liang",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2317939555",
      "name": "Zhuoxuan Jiang",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2101487513",
      "name": "Yin Di",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A1989366729",
      "name": "Bo Ren",
      "affiliations": [
        "Tencent (China)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2904206140",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2147880316",
    "https://openalex.org/W2952437275",
    "https://openalex.org/W3174691968",
    "https://openalex.org/W2535170495",
    "https://openalex.org/W2890373807",
    "https://openalex.org/W3102725307",
    "https://openalex.org/W3034842695",
    "https://openalex.org/W2072628044",
    "https://openalex.org/W3174660442",
    "https://openalex.org/W2108743083",
    "https://openalex.org/W2788525741",
    "https://openalex.org/W2798636921",
    "https://openalex.org/W2970684294",
    "https://openalex.org/W3173229273",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4321151999",
    "https://openalex.org/W3103519070",
    "https://openalex.org/W2891553865",
    "https://openalex.org/W3003401769",
    "https://openalex.org/W2250999640",
    "https://openalex.org/W2970763364",
    "https://openalex.org/W3035408713",
    "https://openalex.org/W3102925419",
    "https://openalex.org/W2475245295",
    "https://openalex.org/W2803884531",
    "https://openalex.org/W2736065754",
    "https://openalex.org/W3177448563",
    "https://openalex.org/W3121525843",
    "https://openalex.org/W3035000929",
    "https://openalex.org/W2165962657"
  ],
  "abstract": "In document-level event extraction (DEE) task, event arguments always scatter across sentences (across-sentence issue) and multipleevents may lie in one document (multi-event issue). In this paper, we argue that the relation information of event arguments is of greatsignificance for addressing the above two issues, and propose a new DEE framework which can model the relation dependencies, calledRelation-augmented Document-level Event Extraction (ReDEE). More specifically, this framework features a novel and tailored transformer,named as Relation-augmented Attention Transformer (RAAT). RAAT is scalable to capture multi-scale and multi-amount argument relations. To further leverage relation information, we introduce a separate event relation prediction task and adopt multi-task learning method to explicitly enhance event extraction performance. Extensive experiments demonstrate the effectiveness of the proposed method, which can achieve state-of-the-art performance on two public datasets.Our code is available at https://github.com/TencentYoutuResearch/RAAT.",
  "full_text": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 4985 - 4997\nJuly 10-15, 2022 ©2022 Association for Computational Linguistics\nRAAT: Relation-Augmented Attention Transformer for Relation Modeling\nin Document-Level Event Extraction\nYuan Liang∗, Zhuoxuan Jiang∗, Di Yin and Bo Ren\nTencent Cloud, China\n{ericyliang, alexzxjiang, endymecyyin, timren}@tencent.com\nAbstract\nIn document-level event extraction (DEE) task,\nevent arguments always scatter across sen-\ntences (across-sentence issue) and multiple\nevents may lie in one document (multi-event\nissue). In this paper, we argue that the rela-\ntion information of event arguments is of great\nsignificance for addressing the above two is-\nsues, and propose a new DEE framework which\ncan model the relation dependencies, called\nRelation-augmented Document-level Event Ex-\ntraction (ReDEE). More specifically, this frame-\nwork features a novel and tailored transformer,\nnamed as Relation-augmented Attention Trans-\nformer (RAAT). RAAT is scalable to cap-\nture multi-scale and multi-amount argument\nrelations. To further leverage relation in-\nformation, we introduce a separate event re-\nlation prediction task and adopt multi-task\nlearning method to explicitly enhance event\nextraction performance. Extensive experi-\nments demonstrate the effectiveness of the\nproposed method, which can achieve state-of-\nthe-art performance on two public datasets.\nOur code is available at https://github.\ncom/TencentYoutuResearch/RAAT.\n1 Introduction\nEvent extraction (EE) task aims to detect the event\nfrom texts and then extracts corresponding argu-\nments as different roles, so as to provide a structural\ninformation for massive downstream applications,\nsuch as recommendation (Gao et al., 2016; Liu\net al., 2017), knowledge graph construction (Wu\net al., 2019; Bosselut et al., 2021) and intelligent\nquestion answering (Boyd-Graber and Börschinger,\n2020; Cao et al., 2020).\nMost of the previous methods focus on sentence-\nlevel event extraction (SEE) (Ahn, 2006; Liao and\nGrishman, 2010; Li et al., 2013; Chen et al., 2015;\nNguyen et al., 2016; Zhao et al., 2018; Sha et al.,\n2018; Yan et al., 2019; Du and Cardie, 2020; Li\n*These authors contributed equally to this work\net al., 2020; Paolini et al., 2021; Lu et al., 2021),\nextracting events from a single sentence. However,\nSEE is mostly inconsistent with actual situations.\nFor example, event arguments may scatter across\ndifferent sentences. As illustrated in Figure 1, the\nevent argument [ORG1] of event role Pledger is\nmentioned in Sentence 4 and the corresponding\nargument [ORG2] of event role Pledgee is in Sen-\ntence 5 and 6. We call this across-sentence issue.\nAnother situation involves the multi-event issue,\nwhich means that multiple events may exist in the\nsame document. As seen in the example in Fig-\nure 1, where two event records coincide, we should\nrecognize that they may partially share common\narguments.\nRecently, document-level event extraction (DEE)\nattracts great attention from both academic and in-\ndustrial communities, and is regarded as a promis-\ning direction to tackle the above issues (Yang et al.,\n2018; Zheng et al., 2019; Xu et al., 2021b; Yang\net al., 2021; Zhu et al., 2021). However, by our\nobservation, we discover that the relations between\nevent arguments have patterns which are an impor-\ntant indicator to guide the event extraction. This\ninformation is neglected by existing DEE meth-\nods. Intuitively, the relation information could\nbuild long-range relationship knowledge of event\nroles among multiple sentences, which could re-\nlieve the across-sentence issue. For multi-event is-\nsue, shared arguments within one document could\nbe distinguished to different roles based on the dif-\nferent prior relation knowledge. As illustrated in\nFigure 1, [ORG1] and [ORG2] have a prior relation\npattern of Pledger and Pledgee, as well as [ORG1]\nand [SHARE1] for the relation pattern between\nPledger and its Pledged Shares. Therefore, the re-\nlation information could increase the DEE accuracy\nif it is well modeled.\nIn this paper, we propose a novel DEE frame-\nwork, called Relation-augmented Document-level\nEvent Extraction (ReDEE), which is able to model\n4985\nFigure 1: An example document for the event type of Equity Pledge, including selected sentences that are involved\nin multiple event records and where the event arguments scatter across sentences. We can observe that the relations\nbetween these entity mentions have intuitive patterns that could be leveraged to enhance the event extraction task.\nMore information of entity color and complete event-related relations can be found in Appendix A.2.\nthe relation information between arguments by de-\nsigning a tailored transformer structure. This struc-\nture can cover multi-scale and multi-amount rela-\ntions and is general for different relation model-\ning situations. We name the structure as Relation-\naugmented Attention Transformer (RAAT). To\nfully leverage the relation information, we intro-\nduce a relation prediction task into the ReDEE\nframework and adopt multi-task learning method\nto optimize the event extraction task. We conduct\nextensive experiments on two public datasets. The\nresults demonstrate the effectiveness of modeling\nthe relation information, as well as our proposed\nframework and method.\nIn summary, our contributions are as follows:\n• We propose a Relation-augmented Document-\nlevel Event Extraction (ReDEE) framework.\nIt is the first time that relation information\nis implemented in the document-level event\nextraction field.\n• We design a novel Relation-augmented At-\ntention Transformer (RAAT). This network is\ngeneral to cover multi-scale and multi-amount\nrelations in DEE.\n• We conduct extensive experiments and the\nresults demonstrate that our method outper-\nform the baselines and achieve state-of-the-art\nperformance by 1.6% and 2.8% F1 absolute\nincreasing on two datasets respectively.\n2 Related Work\n2.1 Sentence-level Event Extraction\nPreviously, most of the related works focus on\nsentence-level event extraction. For example, a\nneural pipeline model is proposed to identify trig-\ngers first and then extracts roles and arguments\n(Chen et al., 2015). Then a joint model is created\nto extract triggers and arguments simultaneously\nvia multi-task learning (Nguyen et al., 2016; Sha\net al., 2018). To utilize more knowledge, some stud-\nies propose to leverage document contexts (Chen\net al., 2018; Zhao et al., 2018), pre-trained language\nmodels (Yang et al., 2019), and explicit external\nknowledge (Liu et al., 2019a; Tong et al., 2020).\nHowever, these sentence-level models fail to ex-\ntract multiple qualified events spanning across sen-\ntences, while document-level event extraction is a\nmore common need in real-world scenarios.\n2.2 Document-level Event Extraction\nRecently, DEE has attracted a great attention from\nboth academic and industrial communities. At first,\nthe event is identified from a central sentence and\n4986\nother arguments are extracted from neighboring\nsentences separately (Yang et al., 2018). Later, an\ninnovative end-to-end model Doc2EDAG, is pro-\nposed (Zheng et al., 2019), which can generate\nevent records via an entity-based directed acyclic\ngraph to fulfill the document-level event extraction\neffectively. Based on Doc2EDAG, there are some\nvariants appearing. For instance, GIT (Xu et al.,\n2021b) designs a heterogeneous graph interaction\nnetwork to capture global interaction information\namong different sentences and entity mentions. It\nalso introduces a specific Tracker module to mem-\norize the already extracted event arguments for\nassisting record generation during next iterations.\nDE-PPN (Yang et al., 2021) is a multi-granularity\nmodel that can generate event records via limit-\ning the number of record queries. Not long ago, a\npruned complete graph-based non-autoregressive\nmodel PTPCG was proposed to speedup the record\ndecoding and get competitive overall evaluation re-\nsults (Zhu et al., 2021). In summary, although those\nexisting works target for solving across-sentence\nand multi-event issues of the DEE task from vari-\nous perspectives, to our best knowledge, we con-\nduct a pioneer investigation on relation modeling\ntowards this research field in this paper.\n2.3 Trigger-aware Event Extraction\nPreviously a lot of works((Ji and Grishman, 2008;\nLiao and Grishman, 2010; Li et al., 2013; Chen\net al., 2015; Nguyen et al., 2016; Liu et al., 2018))\ndeal with event extraction in two stages: firstly, trig-\nger words are detected, which are usually nouns or\nverbs that clearly express event occurrences. And\nsecondly, event arguments, the main attributes of\nevents, are extracted by modeling relationships be-\ntween triggers and themselves. In our work, we\nunify task as a whole to avoid error propagation\nbetween sub-tasks.\n3 Preliminaries\nFirstly, we clarify several key concepts in event\nextraction tasks. 1) entity: a real world object, such\nas person, organization, location, etc.2) entity men-\ntion: a text span in document referring to an entity\nobject. 3) event role: an attribute corresponding a\npre-defined field in an event. 4) event argument:\nan entity playing a specific event role. 5) event\nrecord: a record expressing an event itself, includ-\ning a series of event arguments.\nIn document-level event extraction task, one doc-\nument can contain multiple event records, and an\nevent record may miss a small set of event argu-\nments. Further more, a entity can have multiple\nevent mentions.\n4 Methodology\nIn this section, we introduce the proposed architec-\nture first and then the key components in detail.\n4.1 Architecture Overview\nEnd-to-end training methods for DEE usually in-\nvolve a pipeline paradigm, including three sub-\ntasks: named entity recognition, event role predic-\ntion and event argument extraction. In this paper,\nwe propose the Relation-augmented Document-\nlevel Event Extraction (ReDEE) framework coordi-\nnated with the paradigm. Our framework features\nleverage the relation dependency information in\nboth encoding and decoding stages. Moreover, a\nrelation prediction task is added into the framework\nto fully utilize the relation knowledge and enhance\nthe event extraction task.\nMore specifically, shown in Figure 2, there are\nfour key components in our ReDEE framework:\nEntity Extraction and Representation(EER), Doc-\nument Relation Extraction(DRE), Entity and Sen-\ntence Encoding(ESE), and Event Record Genera-\ntion(ERG). In the following, we would introduce\nthe detailed definition of each component.\n4.2 Entity Extraction and Representation\nWe treat the component of entity extraction as\na sequence labeling task. Given a document D\nwith multiple sentences {s1,s2,...,s i}, we use a\nnative transformer encoder to represent the token\nsequence. Specifically, we use the BERT (Devlin\net al., 2019) encoder pre-trained in Roberta setting\n(Liu et al., 2019). Then we use the Conditional Ran-\ndom Field(CRF) (Lafferty et al., 2001) to classify\ntoken representations into labels of named entities.\nWe adopt the classical BIOSE sequence labeling\nscheme. The labels are predicted by the follow-\ning calculation: ˆyne = CRF(Trans(D)). Then\nall the intermediate embeddings of extracted entity\nmentions and sentences are concatenate into a ma-\ntrix Mne+s ∈R(j+i)×de by max-pooling operation\non each sentence and entity mention span, where\nj and i are the numbers of entity mentions and\nsentences, and de is the dimension of embeddings.\nThe loss function for named entity recognition is\n4987\nFigure 2: Overall of our proposed ReDEE framework.\ndenoted:\nLne = −\n∑\nsi∈D\nlogP(yi|si) (1)\nwhere si denotes the ith sequence sentence in doc-\nument, and yi is the corresponding ground truth\nlabel sequence.\n4.3 Document Relation Extraction\nThe DRE component takes the document text\n(D) and entities ( {e1,e2,...,e j}) extracted in\nthe previous step as inputs, and outputs the\nrelation pairs among entities, in a form of\ntriples ( {[eh\n1 ,et\n1,r1],[eh\n2 ,et\n2,r2],..., [eh\nk,et\nk,rk]}).\n[eh\nk,et\nk,rk] means the head entity, the tail entity\nand the relationship of the kth triple respectively.\nAn important aspect is how to define and collect\nthe relations from data. Here we assume that every\ntwo arguments in an event record can be connected\nby a relation. For example, Pledger and Pledgee\nin the EquityPledge event could have a relation\nnamed as Pledge2Pledgee, and the order of head\nand tail entities is determined by the pre-order of\nevent arguments (Zheng et al., 2019). In this way,\nevery event record with n arguments could cre-\nate C2\nn relation samples. Note that this method to\nbuild relations is general to event extraction tasks\nfrom various domains, and the supervised relation\ninformation just comes from event record data it-\nself, without any extra human labeling work. We\ndo statistics for the relation types for ChiFinAnn\ndataset. Table 1 shows a snippet of statistics and\nthe full edition can be found in Appendix A.3.\nRelation Type #Train #Dev #Test\nPledger2PledgedShares 20002 2567 2299\nPledger2Pledgee 20002 2567 2299\nPledgedShares2Pledgee 20002 2567 2299\nStart2EndDate 19615 2239 1877\nPledger2TotalHoldingShares 18552 2412 2173\nTable 1: The example relations with top 5 quantities in\nthe ChiFinAnn dataset. The complete statistic can refer\nto the Appendix A.3.\nTo predict the argument relations in this step,\nwe adopt the structured self attention network (Xu\net al., 2021a) which is the latest method for\ndocument-level relation extraction. However, dif-\nferent from previous work using multi-class binary\ncross-entropy loss, we use normal cross-entropy\nloss to predict only one label for each entity pair.\nThe relation type is inferred by this function:\nˆyi,j = argmax(eT\ni Wrej) (2)\nwhere ei,ej ∈Rd denote entity embedding from\nencoder module of DRE and dis the dimension of\nembeddings. Wr ∈Rd×c×d denotes biaffine ma-\ntrix trained by DRE task and cis the total number\nof relations. And the loss function for optimize the\nrelation prediction task is denoted:\nLdre = −\n∑\nyi,j∈Y\nlogP(yi,j|D) (3)\nwhere yi,j denotes ground truth label between the\nith and jth entity, Dfor document text and Y for\nset of all relation pairs among entities.\n4988\nFigure 3: RAAT structure. Firstly each relation between\nentities and sentences are represented as matrices. Then\nthe matrices are clustered by the head entities. At last\nthe clustered matrices are integrated into the transformer\nstructure for attention calculation.\n4.4 Entity and Sentence Encoding\nNow we have embeddings of entity mentions and\nsentences from EER component and a list of pre-\ndicted triple relations from DRE component. Then\nthis component encodes data mentioned above and\noutput embeddings effectively integrated with re-\nlation information. In this subsection, we would\nintroduce the method that translates triple relations\nto calculable matrices and the novel RAAT struc-\nture for encoding all the above data.\n4.4.1 Entity and Sentence Dependency\nFirst, we introduce a mechanism: entity and sen-\ntence dependency, which not only includes relation\ntriples, but also describes links among sentences\nand entities beyond triples.\nCo-relation and Co-reference are defined to rep-\nresent entity-entity dependency. For the former\none, two entities have a Co-relation dependency\nbetween them if they belong to a predicted relation\ntriple. Entity pairs are considered having differ-\nent Co-relation if their involved triples have dif-\nferent relations. Co-reference shows dependency\nbetween entity mentions pointing to same entities.\nThat is, if an entity has several mentions existing\nacross document, then each two of them has Co-\nreference dependency. However, in the case that\nsentence entity\nsentence NA Co-existence/NA\nentity Co-existence/NA Co-relation/Co-\nreference/NA\nTable 2: All types of dependency among sentences and\nentities\nhead and tail entities in relation triple are the same\n(i.e. StartDate and EndDate share same entities\nin some event records), then Co-relation and Co-\nreference are both held between them.\nWe use Co-existence to describe dependency be-\ntween entities and sentences where entity mentions\ncome from. To be more specific, the entity men-\ntion together with its belonged sentence has Co-\nexistence. For remaining entity-entity and entity-\nsentence pairs without any dependency mentioned\nabove, we uniformly treat them as NA dependency.\nTable 2 shows the complete dependency mecha-\nnism. Co-relation differs from NA, Co-reference,\nand Co-existence in that it has several sub-types,\nwith number equaling to that of relation types de-\nfined in document relation extraction task.\n4.4.2 RAAT\nIn order to effectively encode entity and sentence\ndependencies, we design the RAAT which takes ad-\nvantage of a calculable matrix representing depen-\ndencies and integrates it into attention computation.\nAccording to the architecture shown in Figure 3,\nRAAT is inherited from native transformer but has\na distinct attention computation module which is\nmade up of two parts: self-attention and relation-\naugmented attention computation.\nGiven a document shown as D= {s1,s2,...sj},\nall entity mentions in this document as Em =\n{em\n1 ,em\n2 ,...,e m\nt }, where em\ni denotes entity men-\ntions with the superscript mdenotes mention, and\nthe subscript idenotes index, and a list of triples\n{[eh\n1 ,et\n1,r1],[eh\n2 ,et\n2,r2],..., [eh\nk,et\nk,rk]}, we build\na matrix T ∈Rc×(t+j)×(t+j) where cfor the num-\nber of dependencies, and t and j for the num-\nber of sentences and entity mentions respectively.\nT is comprised of c matrices with same dimen-\nsions R∈R(t+j)×(t+j), and each Rrepresents one\ntype of dependency r ∈{Co−relationk,Co −\nreference,Co −existence,NA},k = 1,2,...N,\nN as the number of relation types. For element\nwithin T, tk,i,j represent the dependency between\nnodei and nodej. Specifically, tk,i,j = 1if they\nhave the kth dependency, otherwise, tk,i,j = 0.\nHere, nodek ∈{em\n1 ,em\n2 ,...,e m\nt ,s1,s2,...sj}can\n4989\nbe either entity mention or sentence.\nHowever, T would be giant and sparse if we\nuse the above strategy. To squeeze T and de-\ncrease training parameters, we cluster Co-relation\ndependency based on the type of head entity in\nrelation triple. For example, Pledger2Pledgee\nand Pledger2PledgedShares are clustered as one\nCo-relation dependency, and two matrice Ra\nand Rb corresponding to them are merged into\none matrix. As a result, we finally get T ∈\nR(3+H)×(t+j)×(t+j) where H denotes the num-\nber of head entity type in Co-relation, and 3\ncovers NA, Co-reference, and Co-existence. Let\nX ∈ R(t+j)×d as input embeddings of atten-\ntion module, Wrq,Wrk,Wq,Wk,Wv ∈ Rd×d,\nM ∈R(3+H)×d×d as weight matrices, we com-\npute relation-augmented attention in the following\nsteps:\nQr = XWrq,Kr = XWrk (4)\nSa =\n∑3+H\ni=1 QrM[i,:,:]KT\nr ·T[i,:,:]√\nd\n+ biasi (5)\nwhere Sa denotes score matrix of relation-\naugmented attention, ·denotes element-wise mul-\ntiplication. We compute self attention score and\ncombine it with Sa in the following way:\nQ= XWq,K = XWk,Wv = XWv (6)\nSb = QKT\n√\nd\n(7)\nO= (Sa + Sb)V (8)\nwhere Ois the output of attention module. Similar\nto the structure of native transformer, RAAT has\nmultiple identical blocks stacking up layer by layer.\nFurthermore, T is extensive since the number of\nCo-relation can be selected. RAAT can be adaptive\nto the change of input length, which is equivalent to\nthe total number of sentences and entity mentions.\n4.5 Event Record Generation\nWith the outputs from previous component, the em-\nbeddings of entities and sentences, this ERG com-\nponent actually includes two sub-modules: event\ntype classifier and event record decoder.\n4.5.1 Event Type Classifier\nGiven the embeddings of sentences, we adopt sev-\neral binary classifiers on every event type to predict\nwhether the corresponding event is identified or\nnot. If there is any classifier identifying an event\ntype, the following event record decoder would be\nactivated to iteratively generate every argument for\nthe corresponding event type. The loss function to\noptimize this classifier is as the following:\nLpred = −\n∑\ni\nlog(P(yi|S)) (9)\nwhere yi denotes the label of the ith event type,\nyi = 1if there exists event record with event type\ni, otherwise, yi = 0. Sdenotes input embeddings\nof sentences.\n4.5.2 Event Record Decoder\nTo iteratively generate every argument for a spe-\ncific event type, we refer to the entity-based di-\nrected acyclic graph (EDAG) method (Zheng et al.,\n2019). EDAG is a sequence of iterations with the\nlength equaling to number of roles for certain event\ntype. The objective of each iteration is to predict\nevent argument of certain event role. Inputs of each\niteration are come up with entities and sentences\nembeddings. And the predicted arguments of out-\nputs will be a part of inputs for next iteration. How-\never, different from EDAG, we substitute its vanilla\ntransformer part with our proposed RAAT structure\n(i.e. RAAT-2 as shown in Figure 2). More specif-\nically, the EDAG method uses a memory struc-\nture to record extracted arguments and adds role\ntype representation to predict current-iteration ar-\nguments. However, this procedure hardly captures\ndependency between entities both in memory and\nargument candidates and sentences. In our method,\nRAAT structure can connect entities in memory and\ncandidate arguments via relation triples extracted\nby the DRE component, and it can construct a struc-\nture to represent dependencies. In detail, before\npredicting event argument for current iteration, Ma-\ntrix T is constructed in the way shown above so\nthat dependency is integrated into attention compu-\ntation. After extracting the argument, it is added\ninto memory, meanwhile, a new T is generated to\nadapt next iteration prediction.\nTherefore, the RAAT can strengthen the relation\nsignal for attention computation. The RAAT-2 has\nthe same structure with RAAT-1 but independent\nparameters. The formal definition of loss function\nfor event recorder decoder is:\nLa = −\n∑\nv∈VD\n∑\ne\nlog(P(ye|(v,s))) (10)\nwhere VD denotes node set in event records graph,\nvdenotes extracted event arguments of event record\n4990\nby far, sdenotes embedding of sentences and event\nargument candidates, and ye denotes label of argu-\nment candidate ein current step. ye = 1means eis\nthe ground truth argument corresponding to current\nstep event role, otherwise, ye = 0.\n4.6 Model Training\nTo train the above four components, we leverage\nthe multi-task learning method (Collobert and We-\nston, 2008) and integrate the four corresponding\nloss functions together as the following:\nL= λ1Lne + λ2Ldre + λ3Lpred + λ4La (11)\nwhere the λi pre-set to balance the weight among\nthe four components.\n5 Experiments\nIn this section, we report the experimental results\nto prove the effectiveness of our proposed method.\nIn summary, the experiments could answer the fol-\nlowing three questions:\n• To what degree does the ReDEE model out-\nperform the baseline DEE methods?\n• How well does ReDEE overcome across-\nsentence and multi-event issues?\n• In what level does the each key component of\nReDEE contribute to the final performance?\n5.1 Datasets\nDEE is a relatively new task and there are only\na few datasets published. In our experiments we\nadopt two public Chinese datasets, i.e. ChiFinAnn\n(Zheng et al., 2019) and DuEE-fin (Li, 2021).\nChiFinAnn includes 32,040 documents with 5\ntypes of events, involving in equity-related ac-\ntivities for the financial domain. Statistics show\nthat about 30% of the documents contain multiple\nevent records. We randomly split the dataset into\ntrain/dev/test sets in the ratio of 8/1/1. Readers can\nrefer to the original paper for details.\nDuEE-fin is also from the financial domain with\naround 11,900 documents in total. The dataset is\ndownloaded from an online competition website*.\nSince there is no ground truth publicly available\nfor the test set, we can only submit our extracted\nresults to the website as a black-box online eval-\nuation. Compared to ChiFinAnn, there are two\n*https://aistudio.baidu.com/aistudio/competition/detail/46\ndifferences. The DuEE-fin dataset has 13 different\nevent types and its test set includes a large size\nof document samples that do not have any event\nrecords, which both make it more complicated. We\nget the distribution information of the dataset from\nAppendix A.1.\n5.2 Baselines and Metrics\nFive different baseline models are taken into con-\nsideration: 1) DCFEE (Yang et al., 2018), the first\nmodel proposed to solve DEE task. 2) Doc2EDAG\n(Zheng et al., 2019), proposed an end-to-end model\nwhich transforms DEE as directly filling event ta-\nbles with entity-based path expending. 3) DE-PPN\n(Yang et al., 2021), a pipeline model firstly intro-\nducing the non-autoregressive mechanism. 4) GIT\n(Xu et al., 2021b), a model using heterogeneous\ngraph interaction network as encoder and maintain-\ning a global tracker during the decoding process.\n5) PTPCG (Zhu et al., 2021), a light-weighted and\nlatest DEE model.\nFor evaluation metrics, we use precision, recall,\nand F1 score at the entity argument level for fair\ncomparison with baselines. The overall \"Avg\" in\nthe result tables denotes the micro average value\nof precision, recall, and F1 score. We conduct\nseveral offline evaluations for ChiFinAnn, but only\nan online test for DuEE-fin.\n5.3 Settings\nIn our implementation, for text processing, we con-\nsistently set the maximum sentence number and\nthe maximum sentence length as 128 and 64 sep-\narately. We use BERT encoder in the EER com-\nponent for fine-tuning and Roberta-chinese-wwm\n(Yiming et al., 2020) as the pre-trained model. Both\nRAAT-1 and RAAT-2 have four layers of identical\nblocks. More training details can be found in Ap-\npendix A.5.\n5.4 Results and Analysis\nOverall Performance Table 3 shows the compar-\nison between baselines and our ReDEE model on\nthe ChiFinAnn dataset. The ReDEE can achieve\nthe state-of-the-art performance in terms of micro\naverage recall and F1 scores on almost every type\nof events (i.e. EF, ER, EU, EO, EP), consistent with\nthe Avg. results increased by 1.5% and 1.6% re-\nspectively. Our model also performs competitively\nwell on precision results.\nTable 4 shows the comparison results of our\nmodel with baselines on the developing set of\n4991\nModel EF ER EU EO EP Avg\nP. R. F1. P. R. F1. P. R. F1. P. R. F1. P. R. F1. P. R. F1.\nDCFEE-S† 61.1 37.8 46.7 84.5 86.0 80.0 60.8 39.0 47.5 46.9 46.5 46.7 64.2 49.8 56.1 67.7 54.4 60.3\nDCFEE-M† 44.6 40.9 42.7 75.2 71.5 73.3 51.4 41.4 45.8 42.8 46.7 44.6 55.3 52.4 53.8 58.1 55.2 56.6\nGreedy-Dec† 78.5 45.6 57.7 83.9 75.3 79.4 69.0 40.7 51.2 64.8 40.6 50.0 82.1 40.4 54.2 80.4 49.1 61.0\nDoc2EDAG† 78.7 64.7 71.0 90.0 86.8 88.4 80.4 61.6 69.8 77.2 70.1 73.5 76.7 73.0 74.8 80.3 75.0 77.5\nGIT† 78.9 68.5 73.4 92.3 89.2 90.8 83.9 66.6 74.3 80.7 72.3 76.3 78.6 76.9 77.7 82.3 78.4 80.3\nDE-PPN♠ 78.2 69.4 73.5 89.3 85.6 87.4 69.7 79.9 74.4 81.0 71.3 75.8 83.8 73.7 78.4 - - -\nPTPCG♣ - - - - - - - - - - - - - - - 88.2 69.1 79.4\nReDEE(ours)78.0 70.6 74.1 91.1 90.3 90.7 82.5 69.2 75.3 83.7 73.1 78.1 81.7 78.6 80.1 84.0 79.9 81.9\nTable 3: Comparison of event extraction between baselines and our ReDEE model on the ChiFinAnn dataset. The\nmissing parts are caused by the inaccessibility of baseline codes. †: results from (Xu et al., 2021b); ♠: results from\n(Yang et al., 2021); ♣: results from (Zhu et al., 2021).\nModel Dev Online test\nP. R. F1. P. R. F1.\nDoc2EDAG♣ 73.7 59.8 66.0 67.1 51.3 58.1\nGIT♣ 75.4 61.4 67.7 70.3 46.0 55.6\nPTPCG♣ 71.0 61.7 66.0 66.7 54.6 60.0\nReDEE(ours) 77.0 72.0 74.4 69.2 57.4 62.8\nTable 4: Comparison of event extraction between base-\nlines and our ReDEE model on the DuEE-fin dataset.\n♣: results from (Zhu et al., 2021).\nModel I II III IV\nDCFEE-S† 64.6 70.0 57.7 52.3\nDCFEE-M† 54.8 54.1 51.5 47.1\nGreedy-DEC† 67.4 68.0 60.8 50.2\nDoc2EDAG† 79.6 82.4 78.4 72.0\nGIT† 81.9 85.7 80.0 75.7\nReDEE(ours) 83.9 85.8 81.7 77.9\nTable 5: F1 scores on four sets growing with average\nnumber of sentences involved in event records.†: results\nfrom (Xu et al., 2021b).\nDuEE-fin and its online testing. Seeing from for-\nmer results, our model outperforms in a great leap\nby increasing 6.7% on F1 score. For the online\ntesting evaluation, our model has a distinct growth\nof 2.8% on F1 score than the baselines. This ex-\nperiment demonstrates our model could achieve a\nsuperior performance than existing methods.\nArgument Scattering The across-sentence issue\nwidely exists in datasets. By our statistics, the train-\ning sets of ChiFinAnn and DuEE-fin have about\n98.0% and 98.9% records that scatter across sen-\ntences respectively. To evaluate the performance of\nour model in different argument scattering degree,\nwe compute the average number of sentences in-\nvolved in records for each document and sort them\nin the increasing average number order. Then, all\ndocuments for testing are evenly divided into four\nsets, namely, I, II, III and IV , which means the I\nset is a cluster of documents that have the smallest\naverage number of involved sentences while the\nIV set has the largest ones. According to table 5,\nour model outperforms other baseline models in\nall settings, and meets the largest growth of 2.2%\nF1 score in IV , the most challenging set of all. It\nindicates that our model is capable of capturing\nlonger dependency of records across sentences via\nrelation dependency modeling, thus alleviating the\nargument scattering challenge.\nSingle v.s. Multi Events To illustrate how well\nour model performs in the multi-event aspect, we\nsplit the test set of ChiFinAnn into two parts: one\nfor documents with single event record, and the\nother for documents including multiple events. Ta-\nble 6 shows the comparison results of all baselines\nand ReDEE. We find ReDEE performs much better\nin the multi-event scenario and outperforms base-\nline models dramatically in all five event types, im-\nproving ranging from 1.9% to 3.2% F1 scores. The\nresults suggest that our relation modeling method\nis more effective to overcome the multi-event issue\nthan existing baseline models.\n5.5 Ablation Study\nTo probe the impact of RAAT structure for different\ncomponents in ReDEE, we conduct ablation studies\non whether to use RAAT or vanilla transformer.\nIn this experiment, we implement tests on three\nvariants: 1) -RAAT-1 substitutes the RAAT in the\nESE component with vanilla transformer. 2) -\nRAAT-2 substitutes the RAAT in the event record\ngeneration module with vanilla transformer. 3) -\nRAAT-1&2substitutes the RAATs in both the above\nplaces with vanilla transformers, so that our model\ndegrades to only import a relation extraction task\nvia multi-task learning.\nThe results in Table 7 indicate that both two\nRAATs have positive influence on our model. Es-\npecially on ChiFinAnn, RAAT-2 makes more con-\n4992\nModel EF ER EU EO EP Avg\nS. M. S. M. S. M. S. M. S. M. S. M. S.&M.\nDCFEE-S† 55.7 38.1 83.0 55.5 52.3 41.4 49.2 43.6 62.4 52.2 69.0 50.3 60.3\nDCFEE-M† 45.3 40.5 76.1 50.6 48.3 43.1 45.7 43.3 58.1 51.2 63.2 49.4 56.6\nGreedy-Dec† 74.0 40.7 82.2 50.0 61.5 35.6 63.4 29.4 78.6 36.5 77.8 37.0 61.0\nDoc2EDAG† 79.7 63.3 90.4 70.7 74.7 63.3 76.1 70.2 84.3 69.3 81.0 67.4 77.5\nGIT† 81.9 65.9 93.0 71.7 82.0 64.1 80.9 70.6 85.0 73.5 87.6 72.3 80.3\nDE-PPN♠ 82.1 63.5 89.1 70.5 79.7 66.7 80.6 69.6 88.0 73.2 - - -\nPTPCG♣ - - - - - - - - - - 88.2 69.1 79.4\nReDEE(ours) 79.7 69.1 92.7 73.6 79.9 69.2 81.6 73.7 86.3 76.5 87.9 75.3 81.9\nTable 6: Comparison of event extraction between singular (S.) and multiple (M.) event documents on the ChiFinAnn.\n†: results from (Xu et al., 2021b); ♠: results from (Yang et al., 2021); ♣: results from (Zhu et al., 2021).\nModel ChiFinAnn DuEE-fin\nP. R. F1. P. R. F1.\nReDEE 84.0 79.9 81.9 69.2 57.4 62.8\n-RAAT-1 +0.4 -1.1 -0.4 +1.5 -1.7 -0.5\n-RAAT-2 +1.3 -2.4 -0.7 +0.8 -3.2 -1.7\n-RAAT-1&2 -3.1 -0.1 -1.5 -1.3 -5.1 -3.7\nTable 7: Ablation studies on ReDEE variants for RAAT.\ntribution than RAAT-1, with a decrease of 0.7%\nversus 0.4% in F1 scores once been substituted.\nAfter replacing both two RAATs, the value of re-\nlation extraction task becomes more weak and the\nmodel encounters a 1.5% drop in F1 score. When\nit comes to DuEE-fin, a similar phenomenon can\nbe observed that both the RAATs can contribute\npositively to our model.\n6 Conclusion\nIn this paper, we investigate a challenging task of\nevent extraction at document level, towards the\nacross-sentence and multi-event issues. We pro-\npose to model the relation information between\nevent arguments and design a novel framework\nReDEE. This framework features a new RAAT\nstructure which can incorporate the relation knowl-\nedge. The extensive experimental results can\ndemonstrate the effectiveness of our proposed\nmethod which makes the state-of-the-art perfor-\nmance on two benchmark datasets. In the future,\nwe will make more efforts to accelerate training\nand inference process.\nAcknowledgements\nWe thank the anonymous reviewers for their careful\nreading of our paper and their many insightful com-\nments and suggestions. This work was supported\nby Tencent Cloud and Tencent Youtu Lab.\nReferences\nDavid Ahn. 2006. The stages of event extraction. In\nIn Proceedings of the Workshop on Annotating and\nReasoning about Time and Events, pages 1–8.\nAntoine Bosselut, Ronan Le Bras, and Yejin Choi. 2021.\nDynamic neuro-symbolic knowledge graph construc-\ntion for zero-shot commonsense question answering.\nIn AAAI.\nJordan Boyd-Graber and Benjamin Börschinger. 2020.\nWhat question answering can learn from trivia nerds.\nIn ACL, pages 7422–7435.\nQingqing Cao, Harsh Trivedi, Aruna Balasubramanian,\nand Niranjan Balasubramanian. 2020. Deformer: De-\ncomposing pre-trained transformers for faster ques-\ntion answering. In ACL, pages 4487–4497.\nYubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, and\nJun Zhao. 2015. Event extraction via dynamic multi-\npooling convolutional neural networks. In ACL,\npages 167–176.\nYubo Chen, Hang Yang, Kang Liu, Jun Zhao, and Yan-\ntao Jia. 2018. Collective event detection via a hier-\narchical and bias tagging networks with gated multi-\nlevel attention mechanisms. In EMNLP, pages 1267–\n1276.\nRonan Collobert and Jason Weston. 2008. A unified\narchitecture for natural language processing: Deep\nneural networks with multitask learning. In ICML.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In NAACL, pages 4171–4186.\nXinya Du and Claire Cardie. 2020. Event extraction\nby answering (almost) natural questions. In EMNLP,\npages 671–683.\nLi Gao, Jia Wu, Zhi Qiao, Chuan Zhou, Hong Yang, and\nYue Hu. 2016. Collaborative social group influence\nfor event recommendation. In CIKM.\nHeng Ji and Ralph Grishman. 2008. Refining event ex-\ntraction through cross-document inference. In ACL,\npages 254–262.\n4993\nJohn Lafferty, Andrew McCallum, and Fernando C.N.\nPereira. 2001. Conditional random fields: Probabilis-\ntic models for segmenting and labeling sequence data.\nIn ICML, pages 282–289.\nFayuan Li, Weihua Peng, Yuguang Chen, Quan Wang,\nLu Pan, Yajuan Lyu, and Yong Zhu. 2020. Event\nextraction as multi-turn question answering. In\nEMNLP, pages 829–838.\nQi Li, Heng Ji, and Liang Huang. 2013. Joint event ex-\ntraction via structured prediction with global features.\nIn ACL, pages 73–82.\nX Li. 2021. Duee-fin: a document-level event ex-\ntraction dataset in the financial domain released\nby baidu. https://aistudio.baidu.com/\naistudio/competition/detail/46.\nShasha Liao and Ralph Grishman. 2010. Using doc-\nument level cross-event inference to improve event\nextraction. In ACL, pages 789–797.\nChun-Yi Liu, Chuan Zhou, Jia Wu, Hongtao Xie, Yue\nHu, and Li Guo. 2017. Cpmf: A collective pair-\nwise matrix factorization model for upcoming event\nrecommendation. In IJCNN.\nJian Liu, Yubo Chen, and Kang Liu. 2019a. Exploit-\ning the ground-truth: An adversarial imitation based\nknowledge distillation approach for event detection.\nIn AAAI, pages 6754–6761.\nXiao Liu, Zhunchen Luo, and Heyan Huang. 2018.\nJointly multiple events extraction via attention-based\ngraph information aggregation. In EMNLP, pages\n1247–1256.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du,\nMandar Joshi, Danqi Chen, Omer Levy, Mike\nLewis, Luke Zettlemoyer, and Veselin Stoyanov.\n2019. Roberta: A robustly optimized bert pretraining\napproach. https://arxiv.org/pdf/1907.\n11692.pdf.\nYaojie Lu, Hongyu Lin, Jin Xu, Xianpei Han, Jialong\nTang, Annan Li, Le Sun, Meng Liao, and Shaoyi\nChen. 2021. Text2event: Controllable sequence-to-\nstructure generation for end-to-end event extraction.\nIn ACL, pages 2795–2806.\nThien Huu Nguyen, Kyunghyun Cho, and Ralph Gr-\nishman. 2016. Joint event extraction via recurrent\nneural networks. In NAACL, pages 300–309.\nGiovanni Paolini, Ben Athiwaratkun, Jason Krone, Jie\nMa, and Alessandro Achille. 2021. Structured pre-\ndiction as translation between augmented natural lan-\nguages. In ICLR, pages 829–838.\nLei Sha, Feng Qian, Baobao Chang, and Zhifang Sui.\n2018. Jointly extracting event triggers and arguments\nby dependency-bridge rnn and tensor-based argument\ninteraction. In AAAI.\nMeihan Tong, Bin Xu, Shuai Wang, Yixin Cao, Lei\nHou, Juanzi Li, and Jun Xie. 2020. Improving event\ndetection via open-domain trigger knowledge. In\nACL, pages 5887–5897.\nXindong Wu, Jia Wu, Xiaoyi Fu, Jiachen Li, Peng Zhou,\nand Xu Jiang. 2019. Automatic knowledge graph\nconstruction: A report on the 2019 icdm/icbk contest.\nIn ICDM.\nBenfeng Xu, Quan Wang, Yajuan Lyu, Yong Zhu, and\nZhendong Mao. 2021a. Entity structure within and\nthroughout: Modeling mention dependencies for\ndocument-level relation extraction. In AAAI, pages\n14149–14157.\nRunxin Xu, Tianyu Liu, Lei Li, and Baobao Chang.\n2021b. Document-level event extraction via hetero-\ngeneous graph-based interaction model with a tracker.\nIn ACL, pages 3533–3546.\nHaoran Yan, Xiaolong Jin, Xiangbin Meng, Jiafeng Guo,\nand Xueqi Cheng. 2019. Event detection with multi-\norder graph convolution and aggregated attention. In\nEMNLP, pages 1267–1276.\nHang Yang, Yubo Chen, Kang Liu, Yang Xiao, and Jun\nZhao. 2018. Dcfee: A document-level chinese finan-\ncial event extraction system based on automatically\nlabeled training data. In ACL, pages 50–55.\nHang Yang, Dianbo Sui, Yubo Chen, Kang Liu, Jun\nZhao, and Taifeng Wang. 2021. Document-level\nevent extraction via parallel prediction networks. In\nACL, pages 6298–6308.\nSen Yang, Dawei Feng, Linbo Qiao, Zhigang Kan, and\nDongsheng Li. 2019. Exploring pretrained language\nmodels for event extraction and generation. In ACL,\npages 5284–5294.\nCui Yiming, Che Wanxiang, Liu Ting, Qin Bing, Wang\nShijin, and Hu Guoping. 2020. Revisiting pre-trained\nmodels for chinese natural language processing. In\nEMNLP: Findings, pages 657–668.\nYue Zhao, Xiaolong Jin, Yuanzhuo Wang, and Xueqi\nCheng. 2018. Document embedding enhanced event\ndetection with hierarchical and supervised attention.\nIn ACL, pages 414–419.\nShun Zheng, Wei Cao, Wei Xu, and Jiang Bian. 2019.\nDoc2edag: An end-to-end document-level frame-\nwork for chinese financial event extraction. In\nEMNLP, pages 337–346.\nTong Zhu, Xiaoye Qu, Wenliang Chen, Zhefeng\nWang, Baoxing Huai, Nicholas Jing Yuan, and\nMin Zhang. 2021. Efficient document-level event\nextraction via pseudo-trigger-aware pruned com-\nplete graph. https://arxiv.org/pdf/2112.\n06013.pdf.\n4994\nEvent Type #Train. #Dev.\nShareRedemption 1309 243\nFinanceDeficit 1062 163\nPledge 1027 160\nEnterpriseAcquisition 934 142\nBidWin 915 134\nExecutiveChange 901 134\nShareholderHoldingDecrease 876 147\nPledgeRelease 728 118\nCorporateFinace 535 72\nCompanyListing 482 82\nShareholderHoldingIncrease 321 62\nCompanyBankruptcy 236 44\nAdmonition 172 32\nTotal 9498 1533\nTable 8: Distribution of Duee-fin dataset.\nA Appendix\nIn the appendix, we incorporate the following de-\ntails that are omitted in the main body due to the\nspace limit.\nA.1 Distribution of Event Type DuEE-fin\nTable 8 shows the complete event type and corre-\nsponding distribution of DuEE-fin dataset. Overall,\nthere are 13 event types in total with uneven distri-\nbution. Only train and development sets are shown\nsince test set is not publicly available.\nA.2 Complete Relation Triples\nTable 9 demonstrates the complete of relation\ntriples of the document event extraction example\nshown in Figure 1.\nEntities in blue are involved in both two event\nrecords, while those in green and orange are exclu-\nsive to record 1 and 2 respectively. Heavy coupling\nof arguments among events increases the difficulty\nof multi-event issue.\nA.3 Relation Statistics for ChiFinAnn\nTable 10 shows the relation statistics of ChiFinAnn\ndataset. There are 85 relation types in total, and\ntrain, development, and test sets have similar pat-\ntern in distribution.\nA.4 Case Study\nFigure 4 shows the prediction results of our model\nand the best baseline model GIT on the example\nin Figure 1. Compared with the ground truth, our\nmodel correctly predicts all event arguments except\none, while GIT only captures one event, with an\nargument missed. This example explicitly shows\nthe superiority of our model in dealing with multi-\nevents issue.\nTable 9: Complete relation triplets.\nA.5 More Training Settings\nFor all native transformers and RAATs, the dimen-\nsions of hidden layers and feed-forward layers are\nset to 768 and 1,024 respectively. During train-\ning, we set the learning rate lr = 5e−5, batch\nsize b = 64. The four loss weights are set to\nλ1 = λ3 = 0.05,λ2 = 1.0,λ4 = 0.95. We use 8\nV100 GPUs and set gradient accumulation steps\nto 8. The train epoch are set to 100, and the best\nepoch are selected by the best validation score on\ndevelopment set for the evaluation of test set. And\nwe use Adam to optimize the whole learning task.\n4995\nTable 10: Relation statistics of ChiFinAnn dataset.\n4996\nFigure 4: Case study.\n4997",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6984397172927856
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.6011086702346802
    },
    {
      "name": "Relationship extraction",
      "score": 0.5878296494483948
    },
    {
      "name": "Transformer",
      "score": 0.5550225973129272
    },
    {
      "name": "Event (particle physics)",
      "score": 0.5409724116325378
    },
    {
      "name": "Relation (database)",
      "score": 0.5078261494636536
    },
    {
      "name": "Scalability",
      "score": 0.49289536476135254
    },
    {
      "name": "Data mining",
      "score": 0.4830537438392639
    },
    {
      "name": "Information extraction",
      "score": 0.42801252007484436
    },
    {
      "name": "Artificial intelligence",
      "score": 0.39922893047332764
    },
    {
      "name": "Machine learning",
      "score": 0.328155517578125
    },
    {
      "name": "Database",
      "score": 0.11392509937286377
    },
    {
      "name": "Engineering",
      "score": 0.0755162239074707
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2250653659",
      "name": "Tencent (China)",
      "country": "CN"
    }
  ],
  "cited_by": 27
}