{
  "title": "Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges",
  "url": "https://openalex.org/W4386644279",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4287361722",
      "name": "Ahsan, Hiba",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4286873171",
      "name": "McInerney, Denis Jered",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2184774679",
      "name": "Kim Ji-Soo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3014089554",
      "name": "Potter Christopher",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2998336549",
      "name": "Young Geoffrey",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4287430662",
      "name": "Amir, Silvio",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4224585139",
      "name": "Wallace, Byron C.",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2143514833",
    "https://openalex.org/W4377009978",
    "https://openalex.org/W4387635896",
    "https://openalex.org/W4387323904",
    "https://openalex.org/W2130675789",
    "https://openalex.org/W4353015365",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W4385570802",
    "https://openalex.org/W4389156617",
    "https://openalex.org/W3170450419",
    "https://openalex.org/W4375958700",
    "https://openalex.org/W4244520600",
    "https://openalex.org/W4321276774",
    "https://openalex.org/W4385750370",
    "https://openalex.org/W4389520444",
    "https://openalex.org/W4378464611",
    "https://openalex.org/W4385966001",
    "https://openalex.org/W4287804657",
    "https://openalex.org/W4287813795",
    "https://openalex.org/W4385571232",
    "https://openalex.org/W2963716420",
    "https://openalex.org/W3201487922",
    "https://openalex.org/W3209663319",
    "https://openalex.org/W3034863243",
    "https://openalex.org/W4312220150",
    "https://openalex.org/W4385572236",
    "https://openalex.org/W4389519598",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W4287816160",
    "https://openalex.org/W2396881363",
    "https://openalex.org/W4281644150"
  ],
  "abstract": "Unstructured data in Electronic Health Records (EHRs) often contains critical information -- complementary to imaging -- that could inform radiologists' diagnoses. But the large volume of notes often associated with patients together with time constraints renders manually identifying relevant evidence practically infeasible. In this work we propose and evaluate a zero-shot strategy for using LLMs as a mechanism to efficiently retrieve and summarize unstructured evidence in patient EHR relevant to a given query. Our method entails tasking an LLM to infer whether a patient has, or is at risk of, a particular condition on the basis of associated notes; if so, we ask the model to summarize the supporting evidence. Under expert evaluation, we find that this LLM-based approach provides outputs consistently preferred to a pre-LLM information retrieval baseline. Manual evaluation is expensive, so we also propose and validate a method using an LLM to evaluate (other) LLM outputs for this task, allowing us to scale up evaluation. Our findings indicate the promise of LLMs as interfaces to EHR, but also highlight the outstanding challenge posed by \"hallucinations\". In this setting, however, we show that model confidence in outputs strongly correlates with faithful summaries, offering a practical means to limit confabulations.",
  "full_text": "1–17\nRetrieving Evidence from EHRs with LLMs:\nPossibilities and Challenges\nHiba Ahsan ahsan.hi@northeastern.edu\nNortheastern University, Boston, MA\nDenis Jered McInerney mcinerney.de@northeastern.edu\nNortheastern University, Boston, MA\nJisoo Kim jkim@bwh.harvard.edu\nBrigham and Women’s Hospital, Boston, MA\nChristopher Potter cpotter3@bwh.harvard.edu\nBrigham and Women’s Hospital, Boston, MA\nGeoffrey Young gsyoung@bwh.harvard.edu\nBrigham and Women’s Hospital, Boston, MA\nSilvio Amir s.amir@northeastern.edu\nNortheastern University, Boston, MA\nByron C. Wallace b.wallace@northeastern.edu\nNortheastern University, Boston, MA\nAbstract\nUnstructureddatainElectronicHealthRecords\n(EHRs) often contains critical information—\ncomplementary to imaging—that could inform\nradiologists’ diagnoses. But the large volume\nof notes often associated with patients together\nwith time constraints renders manually identi-\nfying relevant evidence practically infeasible. In\nthis work we propose and evaluate a zero-shot\nstrategy for using LLMs as a mechanism to ef-\nficiently retrieve and summarize unstructured\nevidence in patient EHR relevant to a given\nquery. Our method entails tasking an LLM to\ninfer whether a patient has, or is at risk of, a\nparticular condition on the basis of associated\nnotes; if so, we ask the model to summarize the\nsupporting evidence. Under expert evaluation,\nwe find that this LLM-based approach provides\noutputs consistently preferred to a pre-LLM in-\nformation retrieval baseline. Manual evaluation\nis expensive, so we also propose and validate a\nmethod using an LLM to evaluate (other) LLM\noutputs for this task, allowing us to scale up\nevaluation. Our findings indicate the promise\nof LLMs as interfaces to EHR, but also high-\nlight the outstanding challenge posed by “hal-\nlucinations”. In this setting, however, we show\nthat model confidence in outputs strongly cor-\nrelates with faithful summaries, offering a prac-\ntical means to limit confabulations.\nData and Code Availability We describe the\ndata used for evaluation in §3. Briefly, we evalu-\nate our approach using two datasets: (1) MIMIC-\nIII dataset, (Johnson et al., 2016b), which is avail-\nable on PhysioNet (Johnson et al., 2016a); and (2)\nEHR notes of patients admitted to the Emergency\nRoom of Brigham and Women’s Hospital (BWH) in\nBoston, MA, USA, between 2010 and 2015. Our\ncode and data are available athttps://github.com/\nhibaahsan/chil_diagnosis_evidence/.\nInstitutional Review Board (IRB) This retro-\nspective medical records research was approved by\nthe Mass General Brigham (MGB) IRB with a waiver\nof requirement for informed consent.\n1. Introduction\nWe consider using LLMs as interfaces to unstructured\ndata (notes) in patient Electronic Health Records\n(EHRs), ultimately to aid radiologists performing\nimaging diagnosis. The motivation is that un-\nstructured evidence within EHR may support (or\nrender less likely) particular diagnostic hypotheses\nradiologists come to based on imaging, but time\n© H. Ahsan, D.J. McInerney, J. Kim, C. Potter, G. Young, S. Amir & B.C. Wallace.\narXiv:2309.04550v3  [cs.CL]  10 Jun 2024\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\n(A) Is the patient at risk for \nintracranial hemorrhage?\n(B) Does the patient have \nintracranial hemorrhage?\nLLM\nThe patient is …\n…\nHad undergone an \noperation … \n…\nEHR\n(A) Yes.\n(B) Yes.\n  \n(A) Why is the patient at risk \nfor intracranial hemorrhage?\n(B) Extract signs of \nintracranial hemorrhage.\nLLM\nThe patient is …\n…\nHad undergone an \noperation … \n…\nEHR\n{Step 2 Step 1\n(A) The patient underwent surgery \nand is on anticoagulation\n(B) Acute posterior fossa \nhemorrhage into the third and \nfourth ventricles\n{\nFigure 1: Proposed prompting strategy to identify and summarize evidence relevant to a given query di-\nagnosis using LLMs. We first ask if the patient has (or is at risk of) a condition, then elicit a\nsummary of supporting evidence if so.\nconstraints—combined with the often lengthy records\nassociated with individual patients—make manually\nfinding and drawing upon such evidence practically\ninfeasible. Consequently, radiologists often perform\ndiagnosis with comparatively little knowledge of pa-\ntient history.\nLLMs offer a flexible mechanism to interface with\nunstructured EHR data, e.g., recent work has shown\nthat LLMs can capably performzero-shot informa-\ntion extraction from clinical notes (Agrawal et al.,\n2022; McInerney et al., 2023). In this workwe pro-\npose and evaluate an approach using LLMs to\nextract evidence from EHR notes to aid diag-\nnosis. We envision a clinician providing an initial\nsuspected diagnosis as a query; the LLM should then\nconfirm whether there is unstructured (textual) evi-\ndence in the patient record that might support this\ndiagnosis, and—if so—summarize this for the clini-\ncian (Figure 1).\nLLMs provide an attractive mechanism to per-\nmit such interactions given their established dexter-\nity working with unstructured text, and their flex-\nibility. Critically, they permit general question an-\nswering (e.g., “Is this patient at risk ofAtrial fibril-\nlation?”) and can summarize supporting evidence.\nBut with this flexibility comes challenges: Skillful as\nthey are, LLMs are prone to “hallucinating” content\n(Azamfirei et al., 2023; Zhang et al., 2023), which is\nparticularly concerning in healthcare.\nWeconductanempiricalevaluationwithpracticing\nradiologists to assess the use of LLMs as diagnostic\naids. Our results show that LLMs are more capable\nthan a representative “traditional” (pre-LLM) infor-\nmation retrieval system at surfacing and summariz-\ning evidence relevant to a given diagnosis. However,\nmanual evaluation by domain experts does not scale.\nTherefore, we propose and assess an automated eval-\nuation approach using LLMs. Given a piece of ev-\nidence, we enlist an evaluator LLM to: (i) Extract\nthe conditions stated as risk factors (or signs) in this\nsnippet; (ii) Confirm the presence of each condition\nin the note independently; and then (iii) Validate\nwhether each condition is a risk factor (or sign) of\nthe query diagnosis. We find that this automated as-\nsessment strategy correlates with expert evaluations,\nand therefore use it to scale up our evaluation.\nOur work shows the potential of LLMs as inter-\nfaces to EHRs, but also highlights challenges inher-\nent to their use. How can we know that a gener-\nated summary of supporting evidence faithfully re-\nflects an underlying patient record? We highlight\ntroubling examples where the LLM fabricates plau-\nsible patient history thatwould support a condition\nof interest. At best this frustrates the provider (who\nmust read through the record carefully to ascertain if\nthere is in fact such evidence), and at worst it is dan-\ngerous. However, we find that model confidence in\ngenerations strongly correlates with accuracy in this\ndomain, which mitigates this issue.\nOur contributions are as follows. (1) We intro-\nduce an approach in which we task an LLM to in-\nfer patient risk of a given condition, and to produce\n2\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\na conditional summary of supporting evidence if so.\nWe enlist experts to manually evaluate outputs from\ntwo LLMs—Flan-T5 XXL (Chung et al., 2022) and\nMistral-Instruct (Jiang et al., 2023a)—and find they\nboth outperform a representative baseline evidence\nretrieval approach. (2) We introduce a method to au-\ntomate evaluation of retrieved evidence via an LLM,\nand show this enjoys good correlation with expert\nannotations. Larger scale evaluation using this ap-\nproach confirms the advantage of LLMs over tradi-\ntional methods. (3) We highlight examples that il-\nlustrate the issue of hallucinated content in this con-\ntext, and report results indicating that LLM confi-\ndence may be sufficient to avoid this.\n2. Retrieving and summarizing\nevidence with LLMs\nFor a given query (≡ condition), we attempt to re-\ntrieve two distinct types of evidence from patient his-\ntory: (A) snippets that indicate a patientmay be at\nrisk of developing the condition in the future, and;\n(B) those that suggest the patientcurrently has the\ncondition. For example, a patient on anticoagulants\nafter a recent posterior fossa surgery may be at risk\nof an intracranial hemorrhage, but not experiencing\none currently. By contrast, observing acute posterior\nfossahemorrhageindicatesthepatientmostlikelyhas\nintracranial hemorrhage.\nExtracting evidence for risk informs clinicians\nabout occurrences in the patient’s history (e.g., pro-\ncedures, diagnoses) that make them more vulnera-\nble to the condition. Extracting evidence for signs\nof a condition serves two purposes. Those that oc-\ncur in the patient’s immediate history indicate that\nthey likely have the condition; those that occur ear-\nlier indicate the patient (may) have a history of the\ncondition, which is also important.\nWe consider openly available “medium-scale” mod-\nels, including Flan-T5 XXL (Chung et al., 2022) and\nMistral-Instruct (Jiang et al., 2023a) as representa-\ntive LLMs (11.3B and 7B parameters, respectively).\nWhile larger, proprietary models may offer superior\nresults, we wanted to use an accessible LLM to ensure\nreproducibility. Moreover, protectionsforpatientpri-\nvacy mandated by the Health Insurance Portability\nand Accountability Act (HIPAA), and our institu-\ntional policy on use of LLM restrict us to using mod-\nels that can be deployed “in-house”, precluding hosted\nvariants (e.g., those provided by OpenAI).\nZero-shot sequential prompting We adopt a se-\nquential prompting approach to find and summarize\nevidence relevant to a query. We first ask the LLM\nwhether a given note indicates that the corresponding\npatient is at risk for or has a given query diagnosis—\nprompting the LLM for a binary decision about this.\nIf the answer is ‘Yes’, we prompt the model to provide\nsupport for this response.\nMore specifically, to query whether the patient is\nat risk for the given diagnosis, we use the prompts\nbelow for Flan-T5 and Mistral-Instruct.\nRead the following clinical note of a patient:\n[NOTE].\nQuestion: Is the patient at risk of\n[DIAGNOSIS]?\nChoice -Yes -No.\nAnswer:\nToelicitsupportingevidencefromthemodelforthese\nrisk predictions, we use the following prompt for\nFlan-T5.\nRead the following clinical note of a patient:\n[NOTE].\nBased on the note, why is the patient at risk\nof [DIAGNOSIS]?\nAnswer step by step:\nFor Mistral-Instruct, we found that CoT prompting\nyielded very lengthy responses. We therefore instead\nused the following prompt:\nRead the following clinical note of a patient:\n[NOTE].\nBased on the note, why is the patient at risk\nof [DIAGNOSIS]? Be concise.\nAnswer:\nSimilarly, to query whether the patienthas a given\ndiagnosis, we ask “Question: Does the patient have\n[DIAGNOSIS]?” (asking for a binary response). And\nthen to obtain evidence supporting this assessment\n(in the case of a positive response), we prompt with:\n“Question: Extract signs of [DIAGNOSIS] from the\nnote.”. In the above prompts,[NOTE] denotes a pa-\ntient note, and[DIAGNOSIS] a potential diagnosis for\nwhich we would like to retrieve supporting evidence.\nWe then combine and present the result for the two\ntypes of evidence (risks and signs) to the end user.\n3\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\nWhy not a single prompt? It might seem more\nintuitive to simply ask the model to answer ‘Yes’ or\n‘No’ and explain its reasoning in a single prompt.\nHowever, we found that this strategy yielded many\nfalse positives for both Flan-T5 and Mistral-Instruct.\nTo quantify this, we randomly sampled40 notes and\nused a single prompt to find evidence for conditions\nthat the patient did not have. The single prompt\nproduced ‘No’ for only 7.5% (Flan-T5) and 27.9%\n(Mistral-Instruct) of the notes. By contrast, sequen-\ntial prompting yielded ‘No’ all 40 times for both\nmodels. We provide more details in §A.1. We also\nexperimented with a single few-shot prompt to ex-\ntract evidence (§A.2), but preliminary results were\nnot promising so we did not pursue this further.\nA retrieval baseline (CBERT) As a point of\ncomparison for unsupervised evidence extraction\n(with pre-LLM methods), we use a simple rank-\ning approach using neural embeddings. 1 Specifi-\ncally, given a query[DIAGNOSIS], we retrieve asso-\nciated [RISK FACTORS] using GPT-3.5 and generate\nan embedding erf of the sentence: ‘Risk factors of\n[DIAGNOSIS] include [RISK FACTORS]’ using Clini-\ncalBERT (Alsentzer et al., 2019).2\nTable 7 shows examples of risk factors provided\nby GPT-3.5. The intuition is to generate n-grams\nthat are likely to indicate risk of the corresponding\ndiagnosis so that we can match these against notes\nin EHR. Then, for a patient and[DIAGNOSIS], we\nretrievethetop 20 sentencesinthepatientnotesmost\nsimilar toerf. One downside of such a retrieval-based\napproach is the need to pre-specify the number of\nevidence snippets to retrieve (here, we arbitrarily set\nthis to 20). By contrast, the LLM approach implicitly\nand dynamically adjusts this threshold. We refer to\nthis baseline as CBERT.\n3. Data\nFor evaluation, we collaborated with radiologists\n(specializing in neuroimaging) from the Brigham and\nWomen’s Hospital in Boston (BWH). Three radiol-\nogists with 25,15, and 8 years of experience, respec-\ntively, participated in the evaluation. One of them\n(25 years of experience) had prior experience with\n1. Other, evensimpler, baselinesareapossibility(e.g., BM25,\nTF-IDF), but the expensive expert time required for anno-\ntations limited our ability to evaluate additional baselines.\n2. Note that this does not entail passing any sensitive data\nto OpenAI; we send only a condition name.\nDiagnosis Notes Evidence\nFlan- Mistral-\nT5 Instruct\nMIMIC-III\nintracranial hemorrhage* 95 29 26\nstroke 16 4 2\nsmall vessel disease 16 8 2\npneumocephalus 12 12 11\nsinusitis 49 14 3\nTotal 188 67 44\nBWH\nsmall vessel disease 13 8 2\nchemoradiation necrosis 18 10 20\ndemyelination 21 12 9\nbrain tumor 21 20 17\nintracranial hypotension 20 20 5\ncraniopharyngioma 20 18 10\ncerebral infarction 14 14 20\nsinusitis 17 15 8\nTotal 144 117 91\nTable 1: Evaluation dataset statistics. *intracra-\nnial hemorrhage is the only diagnosis with\nmore than one patient (it has 4).\nMIMIC,\nER\n2001-2012\nInclude admissions with brain \nimaging within 48 hrs of ER \nvisit\nBWH, \nER\n2010-2015\nExclude admissions <10 past \nnotes\nExtract diagnoses from 10 \nimaging reports each\nExclude instances >20 FLAN \nevidence snippets\nSample 8 instances from each\nN=12,430\nN=3,128\nN=15\nN=14\nN=21\nN=18\nN=1,555\nN=349\nN=8 N=8\nadmissions admissions\nadmissionsadmissions\ninstances\ninstances\ninstances\ninstances\ninstances\ninstances\nFigure 2: Data sampling flow-chart. An instance is a\nunique (patient, diagnosis) combination.\n4\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\nLLM projects while the other two did not. For exper-\niments, we used a private dataset from this hospital\nand the publicly available MIMIC-III (Johnson et al.,\n2016b) dataset, to ensure that our findings are robust\nand (partially) reproducible.\nBWH dataset comprises patients admitted to the\nEmergency Room (ER) of BWH between 2010 and\n2015 along with clinical notes including: cardiology,\nendoscopy, operative, pathology, pulmonary, radiol-\nogy reports, and discharge summaries. We sam-\npled patients who underwent brain imaging within\n48 hours of their ER visit. It is typically in the ER\nthat evidence can be beneficial as the initial diagnosis\nis undetermined in most ER cases. Clinicians attend\nto several patients in one shift and have to go through\noften previously unknown patient history to come up\nwith a diagnosis (Murray et al., 2021). Without this\nconstraint, the probability of the diagnosis already\nbeing determined in the past would be higher and\nwould trivialize the problem. We are interested in\nscenarios where patients are associated with a large\nvolume of EHR data, so we included patients with\n≥10 EHR notes.\nMIMIC-III is a publicly available database of dei-\ndentified EHR from patients admitted to the Inten-\nsive Care Unit (ICU) of the Beth Israel Deaconess\nMedical Center between2001 and 2012. It contains\nboth structured data (e.g, demographics, vital sign\nmeasurements, lab test results), and unstructured\ndata (e.g., nurse and physician notes, ECG and radi-\nology reports and discharge summaries). Similar to\nthe BWH dataset, we sampled patients that under-\nwent brain imaging within 48 hours of their ER or\nUrgent Care visit, whose EHR included≥ 10 notes.\nWe sampled data for individual patients, but eval-\nuated models with respect to diagnoses. For exam-\nple, if a patient report mentioned ‘stroke’ and ‘si-\nnusitis’, the radiologist evaluated the surfaced evi-\ndence for each condition independently. To reduce\nannotation effort, we discarded diagnoses with more\nthan 20 pieces of evidence and finally sampled 8 in-\nstances from each source to create our final evalua-\ntion dataset. See Figure 2 for a schematic of our data\nsampling procedure. Table 1 reports statistics about\nthe set of examples used for evaluation.\nFor expert evaluation, one of the collaborating ra-\ndiologists identified all diagnoses discussed in the\nFindings and Impressions sections of the radiology\nreports of 10 patients from each dataset (excluding\nMIMIC-III patients from the pilot study).3 Then,\nfor each diagnosis, we retrieved supporting evidence\nfrom all patient notes using the zero-shot prompting\nstrategy from Section 2. The three collaborating ra-\ndiologists then manually assessed each retrieved piece\nof evidence.\nFigure 6 shows the evaluation interface that our\nradiologist team-members used to assess model out-\nputs. Because the relevance of an evidence snippet\ninherently depends on the context, we ask radiolo-\ngists to ground their assessments by assuming the\nfollowing hypothetical setting: “You are a radiologist\nreviewing a scan of a patient in the ER. Based on\nthe scan, you are concerned that the patient has the\ndiagnosis stated below. Assess the relevance of the re-\ntrieved evidence to support your inference.” For each\npiece of evidence surfaced by a model, radiologists\nanswered two questions:\nIs the evidence present in the note?LLMs can hallu-\ncinate evidence. Therefore, we first ask radiologists\nto confirm whether the model generated evidence is\nin fact supported by the note on the basis of which it\nwas produced. To aid the radiologists in finding the\ncorresponding sentences, we compute ClinicalBERT\n(Alsentzeretal.,2019)embeddingsofsentencesinthe\nnotes and highlight those with a cosine similarity of\n≥ 0.9 withtheClinicalBERTembeddingofthegener-\nated evidence. This heuristic approach realizes high\nprecision but low recall. Therefore, if a highlighted\nsentence is incongruous with generated evidence, we\nask radiologists to read through the entire note to try\nand manually identify support.\nNote that the (non-generative) retrieval method to\nwhich we compare as a baseline is extractive, and\nso incapable of hallucinating content; we neverthe-\nless ask this question with regards to the baseline for\nconsistency and to ensure blinding.\nIs the evidence relevant? If generated evidence is\nsupported by the note, we ask radiologists whether it\nis relevant to the query diagnosis. A piece of evidence\ncan contain multiple reasons summarized from across\nthe note. We collect assessments on the following\nscale (see Table 2 for examples).\nNot Useful None of the evidence is useful; it is\nirrelevant to the query condition.\nWeak Correlation Evidence produced has a plau-\nsible but weak correlation with the query condition.\n3. While this is a relatively small number of patients, we em-\nphasize that manual evaluation is expensive: Radiologists\non our team spent∼9 hours manually assessing outputs.\n5\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\nEvaluation Diagnosis Evidence Explanation\nVery Useful intracranial\nhemorrhage\nRecent fossa surgery and now on anti-\ncoagulants\nSurgery in the brain inevitably leaves some\nhemorrhage. Anticoagulants increase the risk\nof hemorrhage. ‘Recent surgery’ and ‘antico-\nagulants’ make hemorrhage highly likely.\nUseful cerebral infarc-\ntion\nThere is calcified thrombus obstructing\nthe origins of the M2 branches\n‘Thrombus’ is diagnostic of infarction, which is\nvery useful information. But ‘calcified throm-\nbus’ implies chronicity, so the thrombus could\nhave been present for a long time and there\nmay not be an acute infarction at this time.\nPartially\nUseful\nchemoradiation\nnecrosis\nThe patient is at risk of chemoradi-\nation necrosis due to her history of\nseizures and brain abscess, which may\nhave caused damage to the brain tis-\nsue. Additionally, her use of concur-\nrent Temodar and involved field radia-\ntion during her treatment may have fur-\nther increased her risk.\nHistory of seizures and brain abscess are not\nrelevant to chemoradiation necrosis. Concur-\nrent Temodar use and involved field radiation\nis useful information.\nWeak Corre-\nlation\npneumocephalus patient was involved in a motorcycle ac-\ncident\nA traumatic head injury is an important risk\nfactor of pneumocephalus. A motorcycle acci-\ndent increases the likelihood of a head injury.\nNot Useful small vessel\ndisease (SVD)\npatient is at risk of endocarditis Not helpful in diagnosing SVD.\nHallucination intracranial\nhemorrhage\npatient has a brain tumor Not present in the note.\nTable 2: Examples of evidence surfaced by Flan-T5 and Mistral-Instruct for different evaluation categories.\nSnippet highlighted in red is irrelevant to the query diagnosis.\nPartially Useful Out of the multiple risks or signs\nin the evidence, only some are relevant.\nUseful The evidence is relevant and may inform\none’s diagnostic assessment.\nVery Useful The evidence is clearly relevant and\nwould likely inform diagnosis.\n4. Results\nTofirstassessagreementbetweenradiologists, wehad\nall of them annotate evidence surfaced by the LLM\nfor one particular patient, selected at random from\nthe BWH dataset. For this patient, the model gen-\nerated 10 pieces of (potentially) relevant evidence for\nthe query chemoradiation necrosis. On this shared\nset, the inter-annotator agreement score (average\npairwise Cohen’s κ) for relevance assessments be-\ntween the three radiologists was0.68.\nFigure 3 shows our main results. Radiologists\nfound evidence generated by Mistral-Instruct to be\nthe most useful (MIMIC-47.7%, BWH-59.0%), fol-\nlowed by Flan-T5 (MIMIC-41.5%, BWH-48.4%) and\nthen CBERT (MIMIC-34.4%, BWH-39.7%). Flan-\nT5 and CBERT generated more weak correlations\nthan Mistral-Instruct. Both generative models hal-\nlucinated evidence. We observed that unlike Mistral-\n0 20 40 60 80 100\nCBERT    \nFlan-T5    \nMistral-Instruct    \nCBERT    \nFlan-T5    \nMistral-Instruct    \nVery UsefulUseful Partially Useful\nWeak CorrelationNot UsefulHallucinations\nPercentage\nMIMIC \nBWH \nLoading [MathJax]/extensions/MathMenu.js\nFigure 3: Evidence generated by the LLMs is more\noften deemed useful than that retrieved by\nCBERT. But on average,9.4% and 4.9% of\nevidence by Flan-T5 and Mistral-Instruct\nrespectively are hallucinated.\n6\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\n0.4 0.6 0.8 1.0\nNormalized Likelihood\nPresent\nHallucination\nAUC: 0.937\nBWH\nMIMIC\n(a) Flan-T5\n0.7 0.8 0.9\nNormalized Likelihood\nPresent\nHallucination\nAUC: 0.978\nBWH\nMIMIC (b) Mistral-Instruct\nFigure 4: Distributions of normalized likelihood, for present and hallucinated evidence. The score provides\ngood discrimination of “hallucinated” evidence from present evidence (yielding AUCs of>0.9).\nInstruct, Flan-T5didnotsummarizemultiplereasons\nfrom across the note as evidence. Hence, none of its\nevidence was evaluated to be Partially Useful. Since\nCBERT is extractive, there is no clear indication of\nwhich condition is to be evaluated as evidence. For\nthis reason, the evidence from CBERT was evaluated\noverall and Partially Useful was not used. The as-\nsessment of generated evidence implicitly measures\nprecision. We also estimate model recall in §C.\n4.1. Hallucinations\nConcerningly, some model hallucinations flagged by\nradiologists include plausible risk factors. A few il-\nlustrative examples:\nExample 1For a patient with demyelination as the\nquery diagnosis, Flan-T5 hallucinated the evidence\n‘axonal degeneration’. Demyelination is commonly\nviewed as the primary factor responsible for the de-\nterioration of axons within multiple sclerosis lesions.\nThe model also hallucinated signs of demyelination\nas evidence (‘numbness and tingling in the arms and\nlegs’). There was no evidence indicating axonal de-\ngeneration or the symptoms.\nExample2 Forapatientwithchemoradiationnecro-\nsis as the query diagnosis, Mistral-Instruct halluci-\nnated that ‘the patient had a history of chemoradia-\ntion necrosis’. A history of chemoradiation necrosis\nwould be very relevant to its diagnosis, but there was\nno such history in the EHR.\nIn other instances, the model hallucinated vague ev-\nidence, e.g., ‘The patient is taking a lot of medica-\ntions that can cause small vessel disease’ for small\nvessel disease as the query diagnosis (a radiologist\nwent through the note and was unable to find men-\ntion of any such medication).\nHow certain is the model about such hal-\nlucinations? We evaluate the degree to which\nmodel uncertainty—normalized output likelihoods\nunder the LM—suggests ‘hallucinated’ content (Fig-\nure 4). Both models considered yield confidence\nscores that are highly indicative of hallucinations.\nThis is promising, as it suggests we can simply ab-\nstain from providing outputs in such cases.\n4.2. Weakly correlating evidence\nA factor complicating evaluation is that LLMs often\nyield evidence which has plausible but weak correla-\ntion with a query condition. One could argue that\nthe model was ‘correct’ in retrieving such evidence\nfrom an epidemiology perspective, but incorrect (or\nat least not useful) from an individual patient, clini-\ncal perspective. In other words, evidence may be so\nweakly correlated with a condition that it is of small\nvalue, even if technically ‘correct’. See Tables 2 and\n8 for examples.\n4.3. Qualitative Evaluation\nWe summarize the comments offered by radiolo-\ngists during evaluation. Radiologists found out-\nputs of Mistral-Instruct and FLAN-T5 to be more\nprecise and concise compared to CBERT. Abstrac-\ntive evidence was considered better than the ex-\ntractive snippets from CBERT, which often chun-\nked useful evidence with neighboring irrelevant sen-\ntences (notes are usually poorly formatted, making\n7\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\nFLAN-T5/Mistral-Instruct CBERT\nCAD (s/p stents x 2,> 2 MIs, on Coumadin INR=1.9) hx of\n> 3 TIAs in past 2.5 yrs multiple AAAs (largest last measured\nat 5.5 cm, surg intervention held 2/2 cardiac status\nIMMUNIZATIONS: INFLUENZA VACCINE (INAC-\nTIVATED) IM Given [DATE] ALLERGY: AMOX-\nICILLIN ADMIT DIAGNOSIS: Stroke PRINCIPAL\nDISCHARGE DIAGNOSIS ;Responsible After Study\nfor Causing Admission) same OTHER DIAGNO-\nSIS;Conditions,Infections,Complications,affecting Treat-\nment/Stay CAD (s/p stents x 2, > 2 MIs, on Coumadin\nINR=1.9) hx of > 3 TIAs in past 2.5 yrs multiple AAAs\n(largest last measured at 5.5 cm, surg intervention held\n2/2 cardiac status OPERATIONS AND PROCEDURES:\nNone.OTHER TREATMENTS/PROCEDURES (NOT IN\nO.R.)\nThe patient has a TBI A/P- S/P REPAIR [**Doctor Last Name **] & LL ORTHO-\nPEDIC INJURIES STABLE TBI W/CLOSE MONITORING\nFOR CHANGES STABLE LIVER LAC AT PRESENT SUC-\nCESSFULL WEAN/EXTUBATION POST-OP PAIN CONT\nTOMONITORPERORDERS-Q2/HRNEURO&PERIPH-\nERAL VASCULAR CHECKS...?\nTable 3: Examples of evidence when generative models are more concise than CBERT, highlighting the\nbenefits of abstractive summarization.\nsentence-parsing difficult). See Table 3 for exam-\nples. CBERT was preferred in three cases, when both\nMistral-Instruct and FLAN-T5 had poor precision or\nrecall. For instance, both models had a precision of\n∼ 50% for pneumocephalus. Interestingly, our radi-\nologist preferred CBERT for the case of demyelina-\ntion because it helped confirm that the patient did\nnot have demyelination, but in fact had a glioma (tu-\nmor). Demyelinating lesions and glioma present sim-\nilar imaging characteristics and can be difficult to di-\nagnosebasedonconventionalMRimaging(Tohetal.,\n2012). A brain biopsy is often conducted to differen-\ntiate between the two. All the evidence evaluated as\n(very) useful were snippets from the pathology report\ndiscussing the tests and related results that indicated\nthat demyelination was less likely and that the find-\nings were most consistent with glioma.\n5. Automatic Evaluation\nManually evaluating evidence requires a considerable\namount of scarce (expensive) expert time, meaning\nit does not scale. This limited our evaluation above\nto a small set of patients. To expand our evaluation\nwe now also consider the use of LLMs as evaluators.\nPrior work has established that LLM-based evalua-\ntion can provide meaningful signal in general (Chiang\nand Lee, 2023; Min et al., 2023; Chang et al., 2023;\nKim et al., 2023), but there has been limited work\ninvestigating such evaluation in healthcare; it is im-\nModel MIMIC BWH\n2. Verify presence of each risk factor/sign\nH P H P\nFlan-T5 75.0(4) 90 .0 83 .3(6) 86 .1\nMistral-Inst. 100.0(3) 88 .2 60 .0(5) 95 .1\n3. Check validity of present risk factors/signs\nF1 PCC F1 PCC\nFlan-T5 75.6 79 .2 74 .2 37 .8\nMistral-Inst. 81.4 92 .0 77 .5 34 .2\nCBERT 55.0 41 .1 63 .9 68 .1\nTable 4: Evaluating automatic evaluation. We first\ncompute the accuracy for hallucinated (H)\nand present (P) evidence (Step 2 in Figure\n5). We then compute micro-F1 and PCC\nfor present evidence (Step 3 in Figure 5).\nportant to assess automatic evaluation in this domain\ndue to the high cost of manual annotation.\nIn this section, we first verify the degree to\nwhich LLM-based automatic evaluations correlate\nwith manual (expert) assessments (§5.1). Finding ev-\nidence of meaningful (if noisy) correlation, we then\nuse this automated approach to increase the scale of\nour evaluation (§5.2).\nFigure 5 provides an overview of our approach.\nGiven a piece of evidence generated by an LLM to\nevaluate, we use an evaluator LLM to: (1) Extract\nthe risk factors it contains; (2) Verify the presence of\n8\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\n“The patient is at risk of intracranial hemorrhage due to hypertension and \ngout. Additionally, the patient has a low platelet count.”\n1. Extract risk factors \nfrom the evidence.\nHypertension\nGout\nLow platelet count\n2. Does patient have X?\nHypertension\nGout\nLow platelet count\n3. Is X a risk factor of \nintracranial hemorrhage?\nHypertension\nGout\nFigure 5: Automatic LLM-based evaluation of re-\ntrieved evidence. The evaluator LLM: (1)\nextracts risk factors from the evidence; (2)\nverifies the presence of each in the note;\nand (3) validates each present risk factor.\nThe same approach is adopted for evaluat-\ning signs of the query diagnosis.\neach risk factor in the note; (3) Check if each present\nrisk factor is a valid risk factor of the query diagno-\nsis. We execute these steps sequentially by one-shot\nprompting the evaluator LLM for (1) and zero-shot\nprompting it for (2) and (3). We provide more de-\ntails in §B. Note that steps (2) and (3) are performed\nseparately for each extracted risk factor. Recall that\nin addition to risk factors, we prompt for signs of\ndiagnosis; we follow the same approach to evaluate\nthese.\n5.1. Evaluating automatic evaluation\nWe first validate this automated (LLM-based) evalu-\nation approach for our task by comparing it to the\nexpert evaluations described in §3. Given its su-\nperior performance according to expert evaluations,\nwe use Mistral-Instruct as the LLM evaluator. We\ncompute micro-F1 and Pearson’s Correlation Coeffi-\ncient (PCC), using expert evaluations on the set of\ninstances manually annotated as the ground truth.\nMicro-F1 measures how well the LLM evaluates each\nextracted risk or sign individually (irrespective of\nwhich instance these are associated with). PCC is\ncomputed at theinstance-level by calculating the av-\nerage relevance over extracted risks and signs from\nall pieces of evidence; this is therefore an aggregate\nmeasure of how well the LLM evaluates an instance.\nBecause automatic evaluation yields binary predic-\ntions (whether a risk factor/sign is relevant to the\ndiagnosis or not), we map expertrelevance scale to\nbinary labels: Not Useful → 0 and {Weak Correla-\ntion, Useful, Very Useful} → 1. For evidence, we\nassign 1 to pieces marked as (Very) Useful or Weak\nCorrelations, and0 to the rest. As discussed in §4.2,\nWeak Correlations fall into a grey area. Therefore,\nwe also perform astrict evaluation where Weak Cor-\nrelations → 0. We report results in Table 4, and offer\nthe following observations.\nHallucinations can be automatically detected.\nAs seen in Table 4 (top), prompting to confirm\nwhether a patient has a condition based on the note\npermits discrimination of “hallucinated” and actually\npresent conditions.\nMicro-F1 scores are high for generative evi-\ndence. The evaluator LLM is able to extract and\nvalidate risk factors and signs of diagnoses in a way\nthat agrees reasonably well with human experts.\nThe micro-F1 scores are high for both Flan-T5 and\nMistral-Instruct across the datasets.\nMicro-F1scoresarerelativelylowforthebase-\nline retrieval approach. CBERT fares compara-\ntively poorly here. Prompting for risk factors and\nsigns from extractive evidence is difficult because\nthese are not as explicitly stated (as opposed to gen-\nerative outputs of the format ‘The patient is at risk\nof X because ofY ’) and are buried in irrelevant infor-\nmation. (This issue was observed during expert eval-\nuation as well.) The result is noisy outputs (e.g., ‘in-\ntubation’, ‘worsening respiratory status’, ‘age’) that\ngeneratefalsepositivesforvalidriskfactorsandsigns.\nThis highlights the relative advantage of LLMs for\nflexible evidence retrieval.\nPCC varies from moderate to high.While PCC\nis high for both Flan-T5 and Mistral-Instruct for\nMIMIC, the correlation is moderate for BWH. This\nis apparently due to poor evaluative performance for\none diagnosis (chemoradiation necrosis for Flan-T5\nandintracranialhypotensionforMistral-Instruct). In\nboth cases, a unique risk factor was incorrectly val-\nidated by the evaluator LLM. But multiple occur-\nrences of the risk factor across notes, resulting in\nrepeated retrieval as evidence, significantly brought\ndown PCC. Removing the diagnoses out increases\nPCC to 82.3 and 51.3 for Flan-T5 and Mistral-\nInstruct, respectively.\nCorrelation drops significantly in strict eval-\nuation. Table 5 shows thechange in micro-F1 and\nPCC when strict evaluation is performed (compared\nto when Weak Correlations→ 1, shown in Table 4).\nWith the exception of PCC for CBERT (MIMIC),\nthere is a drop in micro-F1 and PCC across all model-\ndataset combinations when Weak Correlations→ 0.\n9\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\nThis owes to the inherent complexity of evaluating\nclinical evidence (automatically or otherwise). What\nconstitutes ‘Useful’ evidence for supporting diagnosis\nis, to a degree, inherently subjective.\nModel MIMIC BWH\n∆ F1 ∆ PCC ∆ F1 ∆ PCC\nFlan-T5 9.9↓ 9.8↓ 6.3↓ 9.7↓\nMistral-Instruct 15.3↓ 14.8↓ 1.9↓ 13.5↓\nCBERT 14.1↓ 18.7↑ 13.5↓ 13.7↓\nTable 5: Evaluating strict automatic evaluation\nmetrics. The figures here indicate the\nchange in micro-F1 and PCC compared to\nwhen Weak Correlations→ 1 (shown in Ta-\nble 4). Correlation with expert evaluation\ndrops when Weak Correlations→ 0.\nOverall, automatic evaluation using an LLM has a\nmeaningful correlation (micro-F1) with expert eval-\nuation when measured at risk factor (sign)-level. At\nthe instance-level, the correlation (PCC) is moderate\n(BWH) to high (MIMIC). The variance may owe to\nthe small number of instances evaluated.\n5.2. Scaling our Evaluation\nHavingverifiedthatautomaticevaluationprovidesan\nimperfect but meaningful assessment of outputs, we\nnow scale our evaluation using this approach. Specif-\nically, we complement our manual analysis with an\nautomatic evaluation of the three models at a larger\nscale. We evaluate 100 and 50 instances (patient-\ndiagnosis combinations) for MIMIC and BWH re-\nspectively. As discussed in §3, a collaborating ra-\ndiologist identified the query diagnoses in the radiol-\nogy reports during manual evaluation. For this au-\ntomatic evaluation, we follow prior work Tang et al.\n(2023), and consider conditions followinglikely indi-\ncators (such as ‘concerning for’, ‘diagnosis include’.\nDetails in §D) as diagnoses.\nTable 6 shows results of the scaled up evaluation\n(see Table 9 for data statistics). Both Flan-T5 and\nMistral-Instruct significantly outperform CBERT,\nconsistent with the findings from our manual evalua-\ntion. Mistral-Instruct appears to generate more use-\nful evidence compared to Flan-T5 (again consistent\nwith the manual evaluation). Both models have com-\nparableratesofhallucination forMIMICbutFlan-T5\nhas a higher rate for BWH.\nModel Useful Not Useful Hallucinations\nFlan-T5\nMIMIC 48.5 42 .1 9 .4\nBWH 47.0 38 .4 14 .6\nMistral-Instruct\nMIMIC 55.0 35 .9 9 .1\nBWH 59.8 32 .0 8 .2\nCBERT\nMIMIC 29.7 70 .3 -\nBWH 28.7 71 .3 -\nTable 6: Results of large-scale evaluation performed\nby using Mistral-Instruct as an evaluator.\nLLMs outperform the retrieval baseline.\nMistral-Instruct generates more useful ev-\nidence compared to Flan-T5.\n6. Related Work\nNLP for EHR. Navigating EHRs is cumbersome,\nmotivating efforts in summarization of and informa-\ntion extraction from EHR (Pivovarov and Elhadad,\n2015). For example, in recent related work, Jiang\net al. (2023b) created a proactive note retrieval sys-\ntem based on the current clinical context to aid note-\nwriting. Adams et al. (2021) considered “hospital-\ncourse summarization”, condensing the notes of a pa-\ntient visit into a paragraph. Other work Liang et al.\n(2019) has sought to produce disease-specific sum-\nmaries from notes.\nLLMs for healthcare. There has been a flurry\nof work on the capabilities of LLMs for healthcare\ngenerally, i.e., in terms of ability to answer general\nquestions and take medical exams, e.g., Singhal et al.\n(2023); Lehman et al. (2023); Nori et al. (2023); Yang\net al. (2022). Our work, however, is focused on a\ngrounded, specific task.\nNLP in Radiology. Previous works regarding\nNLP in radiology primarily focus on processing ra-\ndiology reports. Some work has sought to auto-\nmatically generate the Impression section of reports\n(Van Veen et al., 2023; Zhang et al., 2019; Sotudeh\net al., 2020). Other efforts have focused on extracting\nspecific observations (Smit et al., 2020; Jaiswal et al.,\n2021), and modeling disease progression (Di Noto\net al., 2021; Khanna et al., 2023).\nNLP to aid diagnosis. The prior work most rele-\nvant to this effort concern aiding radiologists in diag-\nnosis. McInerneyet al.(2020) propose a distantly su-\n10\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\npervised model (trained to predict ICD codes) to per-\nform extractive summarization conditioned on a di-\nagnoses; our work addresses this problem with LLMs,\nzero-shot. Tang et al. 2023 address diagnostic uncer-\ntainty by suggesting less likely diagnosis to radiolo-\ngists, learnt by differentiating between likely and less\nlikely diagnoses via contrastive learning.\n7. Discussion and Limitations\nWe proposed an approach for using LLMs to retrieve\nand summarize evidence from patient records which\nmight be relevant to a particular diagnosis of inter-\nest, with the aim of aiding radiologists performing\nimaging diagnosis. Expert evaluations of model out-\nputs performed by radiologists show that this is a\npromising approach, as compared to pre-LLM tech-\nniques. We also established that automated (LLM-\nbased) evaluation is feasible, and confirmed our find-\nings using this approach.\nThere are importantlimitations to the approach\nand to our evaluation. We found that LLMs are\nprone to hallucinating (plausible) evidence, poten-\ntially hindering their utility for the envisioned use.\nHowever, our results also indicate that model con-\nfidence might allow one to pro-actively identify hal-\nlucinations, and abstain from providing (generative)\nsummaries in such cases; extending this is an inter-\nesting direction for future work.\nOur evaluation was limited in a few key ways. We\nenlisted radiologists to perform in-depth evaluation\nof a small number of instances, because evaluation\nis time consuming: We emphasize that this exer-\ncise required substantial allocation (∼16 hours) of\nscarce expert time. We attempted to mitigate this\nvia LLM-based automatic evaluation, performed at\nlarger scale. However, our assessment of this strategy\nalso relied on this relatively small annotated set and\nsomaynotgeneralize. Anotherlimitationhereisthat\nwe considered only two LLMs (specifically, FLAN-T5\nand Mistral-Instruct): Other LLMs might, naturally,\nperform better or worse. In addition, we did not in-\nvestigate the fairness implications of our work. How-\never, the small size of our expert-annotated sample\nand the inherently small samples of underrepresented\ngroups limits our ability to meaningfully assess this.\nWe leave the detailed analysis needed to determine\nif there are significant differences to future work. Fi-\nnally, we did not extensively iterate on the prompts\nused, and this too could substantially affect results.\n8. Acknowledgment\nWe acknowledge partial funding for this work by Na-\ntional Library of Medicine of the National Institutes\nof Health (NIH) under award numbers R01LM013772\nand R01LM013891. The content is solely the respon-\nsibility of the authors and does not necessarily repre-\nsent the official views of the NIH.\nReferences\nGriffin Adams, Emily Alsentzer, Mert Ketenci, Ja-\nson Zucker, and Noémie Elhadad. What’s in a\nsummary? laying the groundwork for advances in\nhospital-course summarization. In Proceedings of\nthe conference. Association for Computational Lin-\nguistics. North American Chapter. Meeting, vol-\nume 2021, page 4794. NIH Public Access, 2021.\nMonica Agrawal, Stefan Hegselmann, Hunter Lang,\nYoon Kim, and David Sontag. Large language\nmodels are zero-shot clinical information extrac-\ntors. arXiv preprint arXiv:2205.12689, 2022.\nEmily Alsentzer, John Murphy, William Boag, Wei-\nHung Weng, Di Jindi, Tristan Naumann, and\nMatthew McDermott. Publicly available clini-\ncal BERT embeddings. In Proceedings of the\n2nd Clinical Natural Language Processing Work-\nshop, pages 72–78, Minneapolis, Minnesota, USA,\nJune 2019. Association for Computational Linguis-\ntics. doi: 10.18653/v1/W19-1909. URL https:\n//aclanthology.org/W19-1909.\nRazvan Azamfirei, Sapna R Kudchadkar, and James\nFackler. Large language models and the perils of\ntheir hallucinations.Critical Care, 27(1):1–2, 2023.\nYapei Chang, Kyle Lo, Tanya Goyal, and Mohit\nIyyer. Booookscore: A systematic exploration\nof book-length summarization in the era of llms.\narXiv preprint arXiv:2310.00785, 2023.\nCheng-Han Chiang and Hung-yi Lee. Can large lan-\nguage models be an alternative to human evalua-\ntions? arXiv preprint arXiv:2305.01937, 2023.\nHyung Won Chung, Le Hou, Shayne Longpre, Bar-\nret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma,\net al. Scaling instruction-finetuned language mod-\nels. arXiv preprint arXiv:2210.11416, 2022.\n11\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\nTommaso Di Noto, Chirine Atat, Eduardo Gamito\nTeiga, Monika Hegi, Andreas Hottinger, Meritx-\nell Bach Cuadra, Patric Hagmann, and Jonas\nRichiardi. Diagnostic surveillance of high-grade\ngliomas: towards automated change detection\nusing radiology report classification. In Joint\nEuropean Conference on Machine Learning and\nKnowledge Discovery in Databases, pages 423–436.\nSpringer, 2021.\nMatthew Honnibal and Ines Montani. spaCy 2: Nat-\nural language understanding with Bloom embed-\ndings, convolutionalneuralnetworksandincremen-\ntal parsing. To appear, 2017.\nAjay Jaiswal, Liyan Tang, Meheli Ghosh, Justin F\nRousseau, Yifan Peng, and Ying Ding. Radbert-\ncl: Factually-aware contrastive learning for radiol-\nogy report classification. InMachine Learning for\nHealth, pages 196–208. PMLR, 2021.\nAlbert Q. Jiang, Alexandre Sablayrolles, Arthur\nMensch, Chris Bamford, Devendra Singh Chap-\nlot, Diego de las Casas, Florian Bressand, Gi-\nanna Lengyel, Guillaume Lample, Lucile Saulnier,\nLélio Renard Lavaud, Marie-Anne Lachaux, Pierre\nStock, Teven Le Scao, Thibaut Lavril, Thomas\nWang, Timothée Lacroix, and William El Sayed.\nMistral 7b, 2023a.\nSharon Jiang, Shannon Shen, Monica Agrawal, Bar-\nbara Lam, Nicholas Kurtzman, Steven Horng,\nDavid Karger, and David Sontag. Conceptualizing\nmachine learning for dynamic information retrieval\nof electronic health record notes. arXiv preprint\narXiv:2308.08494, 2023b.\nAlistairE. W.Johnson, TomJ.Pollard, and RogerG.\nMark. MIMIC-III clinical database (version 1.4),\n2016a.\nAlistair EW Johnson, Tom J Pollard, Lu Shen, Li-\nwei H Lehman, Mengling Feng, Mohammad Ghas-\nsemi, Benjamin Moody, Peter Szolovits, Leo An-\nthony Celi, and Roger G Mark. Mimic-iii, a freely\naccessible critical care database.Scientific data, 3\n(1):1–9, 2016b.\nSameer Khanna, Adam Dejl, Kibo Yoon, Quoc Hung\nTruong, Hanh Duong, Agustina Saenz, and Pranav\nRajpurkar. Radgraph2: Modeling disease progres-\nsion in radiology reports via hierarchical informa-\ntion extraction. arXiv preprint arXiv:2308.05046,\n2023.\nSeungone Kim, Jamin Shin, Yejin Cho, Joel Jang,\nShayne Longpre, Hwaran Lee, Sangdoo Yun,\nSeongjin Shin, Sungdong Kim, James Thorne,\net al. Prometheus: Inducing fine-grained evalua-\ntion capability in language models.arXiv preprint\narXiv:2310.08491, 2023.\nEric Lehman, Evan Hernandez, Diwakar Mahajan,\nJonas Wulff, Micah J Smith, Zachary Ziegler,\nDaniel Nadler, Peter Szolovits, Alistair Johnson,\nand Emily Alsentzer. Do we still need clinical lan-\nguage models? In Bobak J. Mortazavi, Tasmie\nSarker, Andrew Beam, and Joyce C. Ho, editors,\nProceedings of the Conference on Health, Inference,\nand Learning, volume 209 of Proceedings of Ma-\nchine Learning Research, pages 578–597. PMLR,\n22 Jun–24 Jun 2023. URLhttps://proceedings.\nmlr.press/v209/eric23a.html.\nJennifer Liang, Ching-Huei Tsou, and Ananya Pod-\ndar. A novel system for extractive clinical note\nsummarization using ehr data. In Proceedings of\nthe Clinical Natural Language Processing Work-\nshop, pages 46–54, 2019.\nDenis Jered McInerney, Borna Dabiri, Anne-Sophie\nTouret, Geoffrey Young, Jan-Willem Meent, and\nByron C Wallace. Query-focused ehr summariza-\ntion to aid imaging diagnosis. InMachine Learning\nfor Healthcare Conference, pages 632–659. PMLR,\n2020.\nDenis Jered McInerney, Geoffrey Young, Jan-Willem\nvan de Meent, and Byron C. Wallace. CHiLL:\nZero-shot Custom Interpretable Feature Extrac-\ntion from Clinical Notes with Large Language\nModels. In Proceeding of Findings of the Confer-\nence on Empirical Methods for Natural Language\nProcessing (EMNLP), 2023.\nSewonMin, KalpeshKrishna, XinxiLyu, MikeLewis,\nWen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke\nZettlemoyer, and Hannaneh Hajishirzi. Factscore:\nFine-grained atomic evaluation of factual preci-\nsion in long form text generation.arXiv preprint\narXiv:2305.14251, 2023.\nLuke Murray, Divya Gopinath, Monica Agrawal,\nSteven Horng, David Sontag, and David R Karger.\nMedknowts: unified documentation and informa-\ntion retrieval for electronic health records. InThe\n34th Annual ACM Symposium on User Interface\nSoftware and Technology, pages 1169–1183, 2021.\n12\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\nHarsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carig-\nnan, Richard Edgar, Nicolo Fusi, Nicholas King,\nJonathan Larson, Yuanzhi Li, Weishung Liu, Ren-\nqian Luo, Scott Mayer McKinney, Robert Osazuwa\nNess, Hoifung Poon, Tao Qin, Naoto Usuyama,\nChris White, and Eric Horvitz. Can general-\nist foundation models outcompete special-purpose\ntuning? case study in medicine. November 2023.\nRimma Pivovarov and Noémie Elhadad. Automated\nmethods for the summarization of electronic health\nrecords. Journal of the American Medical Infor-\nmatics Association, 22(5):938–947, 2015.\nKaran Singhal, Tao Tu, Juraj Gottweis, Rory Sayres,\nEllery Wulczyn, Le Hou, Kevin Clark, Stephen\nPfohl, Heather Cole-Lewis, Darlene Neal, et al.\nTowards expert-level medical question answer-\ning with large language models. arXiv preprint\narXiv:2305.09617, 2023.\nAkshay Smit, Saahil Jain, Pranav Rajpurkar, Anuj\nPareek, Andrew Y Ng, and Matthew P Lun-\ngren. Chexbert: combining automatic label-\ners and expert annotations for accurate radiol-\nogy report labeling using bert. arXiv preprint\narXiv:2004.09167, 2020.\nSajad Sotudeh, Nazli Goharian, and Ross W Filice.\nAttend to medical ontologies: Content selection for\nclinical abstractive summarization.arXiv preprint\narXiv:2005.00163, 2020.\nLiyan Tang, Yifan Peng, Yanshan Wang, Ying Ding,\nGreg Durrett, and Justin F Rousseau. Less\nlikely brainstorming: Using language models to\ngenerate alternative hypotheses. arXiv preprint\narXiv:2305.19339, 2023.\nCH Toh, K-C Wei, S-H Ng, Y-LWan, M Castillo, and\nC-PLin. Differentiationoftumefactivedemyelinat-\ning lesions from high-grade gliomas with the use of\ndiffusion tensor imaging.American journal of neu-\nroradiology, 33(5):846–851, 2012.\nMiles Turpin, Julian Michael, Ethan Perez, and\nSamuel R Bowman. Language models don’t al-\nways say what they think: Unfaithful explanations\nin chain-of-thought prompting. arXiv preprint\narXiv:2305.04388, 2023.\nDave Van Veen, Cara Van Uden, Maayane Attias,\nAnuj Pareek, Christian Bluethgen, Malgorzata Po-\nlacin, Wah Chiu, Jean-Benoit Delbrouck, Juan\nManuelZambranoChaves, CurtisPLanglotz, etal.\nRadadapt: Radiology report summarization via\nlightweight domain adaptation of large language\nmodels. arXiv preprint arXiv:2305.01146, 2023.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi,\nPierric Cistac, Tim Rault, Rémi Louf, Morgan\nFuntowicz, Joe Davison, Sam Shleifer, Patrick von\nPlaten, Clara Ma, Yacine Jernite, Julien Plu, Can-\nwen Xu, Teven Le Scao, Sylvain Gugger, Mariama\nDrame, Quentin Lhoest, and Alexander M. Rush.\nHuggingface’s transformers: State-of-the-art natu-\nral language processing, 2020.\nXi Yang, Aokun Chen, Nima PourNejatian,\nHoo Chang Shin, Kaleb E Smith, Christopher\nParisien, Colin Compas, Cheryl Martin, An-\nthony B Costa, Mona G Flores, et al. A large\nlanguage model for electronic health records.NPJ\nDigital Medicine, 5(1):194, 2022.\nMuru Zhang, Ofir Press, William Merrill, Al-\nisa Liu, and Noah A Smith. How language\nmodel hallucinations can snowball.arXiv preprint\narXiv:2305.13534, 2023.\nYuhaoZhang, DerekMerck, EmilyBaoTsai, Christo-\npher D Manning, and Curtis P Langlotz. Optimiz-\ning the factual correctness of a summary: A study\nof summarizing radiology reports. arXiv preprint\narXiv:1911.02541, 2019.\nAppendix A. Prompting for Evidence\nA.1. Single prompt\nFor the single prompt setting (§2), we followed McIn-\nerney et al. (2020)’s approach of using ‘future’ ICD\ncodes as the patient’s diagnoses. To select a diagnosis\nthat the patient didnot have, we randomly sampled\nan ICD code, excluding the patient’s diagnoses.\nFor Flan-T5, we use the following Chain of\nThought (CoT) prompt :\nRead the following clinical note of a patient:\n[NOTE]\nQuestion: Is the patient at risk of\n[DIAGNOSIS]?\nAnswer: Let’s think step by step.\nSome examples of incorrect reasoning by Flan-T5:\n13\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\n1. Diagnosis: Diabetes insipidus\nThe patient has a Swan-Ganz catheter in place.\nThe Swan-Ganz catheter is a device that is used\nto measure the amount of blood circulating to the\nbrain. The higher the blood flow to the brain, the\nhigher the risk of diabetes insipidus. The answer:\nyes.\n2. Diagnosis: Extradural and subdural abscess\nThe patient has asymmetrically distributed\nairspace opacities affecting the left lung more\nthan the right with coexisting bilateral septal\nthickening is most suggestive of widespread pul-\nmonary edema. Superimposed aspiration is also\npossible, particularly in the left lung. The heart\nremains enlarged. Small pleural effusions are\nnew. The patient is at risk of extradural and\nsubdural abscess.\nFor Mistral-Instruct, again we found that CoT\nprompting yielded very lengthy responses which were\nharder to parse. We thus used the following prompt:\nRead the following clinical note of a patient:\n[NOTE]\nQuestion: Is the patient at risk of\n[DIAGNOSIS]? Answer Yes or No and ex-\nplain your answer. Be concise.\nAnswer:\nSome examples of incorrect reasoning by Mistral-\nInstruct:\n1. Diagnosis: Pneumocephalus\nThe patient has a history of taking Tylenol PR\nand has a cool bath, ice packs, and a fan to cool\ndown, which may increase the risk of pneumo-\ncephalus.\n2. Diagnosis: Stroke\nThe patient has an endotracheal tube in place,\nwhich can increase the risk of stroke if not prop-\nerly positioned and secured.\nA.2. Few-shot prompting\nWe provide additional details on our preliminary ex-\nperiments with few-shot prompting. As done in §A.1,\nwe followed McInerney et al. (2020)’s approach of us-\ning ‘future’ ICD codes as the patient’s diagnoses. To\nselect a diagnosis that the patient didnot have, we\nrandomly sampled an ICD code, excluding the pa-\ntient’s diagnoses. We used the following prompt:\nRead the following clinical note of a patient:\n[RANDOM NOTE SNIPPET].\nAnswer step by step: can the patient pos-\nsibly have cardioembolic strokes in the fu-\nture?\nAnswer: Thereisnoevidence. Finalanswer:\nNo.\nRead the following clinical note of a pa-\ntient: patient stopped taking a blood thin-\nning medication required for a heart valve\ndue to side effects.\nAnswer step by step: can the patient pos-\nsibly have cardioembolic strokes in the fu-\nture?\nAnswer: Thepatientstoppedtakingablood\nthinning medication required for a heart\nvalve. The medication thins the blood and\nprevents blood clots. Blood clots can lead\nto strokes. Final answer: Yes.\nRead the following clinical note of a patient:\n[NOTE].\nAnswerstepbystep: basedonthenote, why\nis the patient at risk of[DIAGNOSIS]?\nAnswer:\nWe observed that with few-shot prompting the\nmodel surfaced evidence for almost every diagnosis\nthat the patient did not have. For example, for a\npatient with ‘with g/j tube in place for gastropare-\nsis’, the model’s output for the diagnosis, encephali-\ntis, was‘The patient has a jejunostomy tube in place.\nThe jejunostomy tube can be pulled out. The jejunos-\ntomy tube can be pulled out of the body. The jejunos-\ntomy tube can be pulled out of the body and into the\nbrain. Final answer: Yes’.\nWe suspect the prompt biases the model to sup-\nport the query diagnosis which then makes the model\ngenerate incorrect explanations as evidence (Turpin\net al., 2023). We also experimented with prompts\nsuch as ‘Extract evidence for [DIAGNOSIS]. Output\nN/A if no evidence exists’but the model then mostly\ngenerated ‘N/A’. Given these results, we carried the\nrest of the evaluation with the zero-shot prompting\napproach.\nAppendix B. Automatic Evaluation\nOur proposed LLM-based automatic evaluation (Sec-\ntion 5) consists of three steps, each realized as a single\n14\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\nDiagnosis Risk Factors\npneumocephalus head injury, skull fracture, neurosurgical procedures, sinus or mastoid surgery, meningitis,\ncerebrospinal fluid leak, barotrauma, diving or scuba diving accidents, iatrogenic causes, such\nas lumbar puncture or spinal anesthesia\nstroke hypertension, smoking, diabetes, obesity, sedentary lifestyle, high cholesterol levels, atrial\nfibrillation, family history of stroke, previous history of stroke, excessive alcohol consumption,\ndrug abuse.\nintracranial hemorrhage hypertension, aneurysms, arteriovenous malformations, blood clotting disorders, trauma,\ndrug abuse, liver disease, brain tumor, stroke, coagulopathy\nbrain tumor progression genetics, exposure to ionizing radiation, family history of brain tumors, certain\nhereditary conditions, weakened immune system, previous history of brain tumor.\nintracranial hypotension obesity, connective tissue disorders, previous spinal or cranial surgery, leaking cerebrospinal\nfluid, spinal epidural anesthesia, lumbar puncture or spinal tap\nTable 7: Examples of risk factors provided by GPT-3.5\nDiagnosis Evidence Explanation\nintracranial hemorrhage patient had multiple cardiac\nsurgeries\nMultiple cardiac surgeries may suggest anticoagulation or un-\nderlying cardiac dysfunction which could in turn predispose\nthe patient to intracranial hemorrhage.\nintracranial hypotension The patient has a ventricu-\nloperitoneal shunt.\nA ventriculoperitoneal shunt (VPS) is a surgical device used\nto relieve intracranial pressure by draining excessive cere-\nbrospinal fluid. Having a VPS catheter may increase the risk\nof intracranial hypotension due to over drainage.\ncraniopharyngioma s/p resection X2, s/p VPS and\npanhypopitutiarism with sec-\nond resection\nPanhypopituitarism and the fact that something was removed\nthrough surgery suggests there was a tumor involving the sella\nwhich may or may not have been craniopharyngioma.\nTable 8: Examples of weakly correlated evidence surfaced by the model for different diagnosis queries. All\nhave plausible but somewhat removed (or weak) connections.\nprompt. We use a one-shot prompt for the first step\nand zero-shot prompts for the subsequent steps, as\nshown below.\n1. Extract risk factors from the evidence.\nRead the following statement: The pa-\ntient is at risk of intracranial hemor-\nrhage due to presence of an endotra-\ncheal tube (ETT) in the patient’s tra-\nchea which may increase the risk of\ncomplications such as aspiration and\nairway obstruction.\nQuestion: Extract the risk factors\nfrom the statement as a list. Be con-\ncise.\nAnswer: 1. presence of endotracheal\ntube (ETT) in the trachea.\nRead the following statement:\n[EVIDENCE]\nQuestion: Extract the risk factors\nfrom the statement as a list. Be con-\ncise.\nAnswer: \"\n2. Verifythepresenceofeachriskfactorinthenote.\nRead the following clinical note of a\npatient: [NOTE]\nQuestion: Does the patient have\n[RISK FACTOR]? Answer Yes or No.\n3. Validate if each present risk factor is a valid risk\nfactor of query diagnosis.\nIs [RISK FACTOR] a risk factor of\n[DIAGNOSIS]? Choice: -Yes -No. Be\nconcise.\nAnswer:\nWe used the following prompts for signs:\n1. Extract signs from the evidence.\nRead the following statement: A pa-\ntient may have intracranial hemor-\nrhage because of the following report -\nLarge left subdural hematoma, exten-\nsive subarachnoid hemorrhage, right\ntemporal effacement, left uncal herni-\nation, and effacement of the sulci.\n15\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\nDiagnosis: small vessel disease\nEvidence: marked low-attenuation bilateral periventricular changes\nFigure 6: Screenshot of the evaluation interface showing highlighted evidence.\nQuestion: Extract the signs from the\nstatement as a list. Be concise.\nAnswer: 1. Large left subdural\nhematoma 2. Extensive subarachnoid\nhemorrhage 3. Right temporal efface-\nment 4. Left uncal herniation 5. Ef-\nfacement of the sulci\nRead the following statement: A pa-\ntient may have[DIAGNOSIS] because\nof the following report -[EVIDENCE].\nQuestion: Extract the signs from the\nstatement as a list. Be concise.\nAnswer: \"\n2. Verify the presence of each sign in the note.\nRead the following clinical note of a\npatient: [NOTE]\nQuestion: Does the patient have\n[SIGN]? Answer Yes or No.\n3. Validate if each present sign is a valid sign of\nquery diagnosis.\nA patient is showing the following\nsign: [SIGN].\nQuestion: Can the sign indicate\n[DIAGNOSIS]? Choice: -Yes -No. Be\nconcise.\nAnswer:\nAppendix C. Binary decision recall\nRecall that we first ask the LLM whether a note in-\ndicates that the corresponding patient is at risk for,\nor has, a given query diagnosis. The precision of this\nLLM inference is implicitly measured by the assess-\nment of generated evidence; if the patient does not\nhave (is not at risk for) a condition, generated ev-\nidence will necessarily be irrelevant. But this does\nnot capture model recall, i.e., recognizing when a pa-\ntient indeed has (is at risk of) a condition.\nTo also estimate modelrecall, we sampled20 pa-\ntientsfromBWHandfollowedpriorwork(McInerney\net al., 2020) in our evaluation. Specifically, we asked\nradiologists to browse reports from up to one year fol-\nlowing a reference radiology report and tag relevant\ndiagnoses; these constitute “future” diagnoses with\nrespect to the reference report. Radiologists then\nflagged past notes containing supporting evidence for\nthese diagnoses. Of the200 notes marked as contain-\ning evidence, Mistral-Instruct, Flan-T5, and CBERT\nhad a recall of58.2, 70.0, and80.4 respectively.\nAppendix D. Likely Indicators\nFor thelikely indicators in §5.2, we used ‘likely rep-\nresent’, ’concerning for’, and ‘diagnosis include’. We\ndid not consider diagnoses such as ‘old infarction’,\nwhich came up often for ‘likely represent’. An in-\nfarction can be myocardial or cerebral. Since our\ndataset comprises of radiology reports concerning\nbrain scans, we added ’cerebral’ as prefix to ‘infarc-\ntion’ to ensure specificity. Similarly, we added ‘brain’\nas a prefix to ‘metastasis’.\nAppendix E. Implementation Details\nWe used theHuggingFace (Wolf et al., 2020) library\nto run inference using Mistral-Instruct (7B), Flan-T5\nXXL (11B) and ClinicalBERT (110 million parame-\nters). We split notes into sentences using thespaCy\n(en_core_web_sm) library (Honnibal and Montani,\n2017). We processed notes in chunks of size750 to-\nkens (including the prompt text) for Flan-T5 and\n16\nRetrieving Evidence from EHRs with LLMs:Possibilities and Challenges\nModel % instances # evidence # risks\nwith evidence (signs)\nFlan-T5\nMIMIC 91.0 1 , 077 2 , 817\nBWH 88.0 701 2 , 027\nMistral-Instruct\nMIMIC 84.0 968 2 , 894\nBWH 90.0 614 1 , 799\nCBERT\nMIMIC 100.0 2 , 000 7 , 467\nBWH 100.0 1 , 000 3 , 336\nTable 9: Data statistics of large-scale evaluation per-\nformed in §5.2. We evaluated 100 and 50\ninstances from MIMIC and BWH datasets\nrespectively.\nMistral-Instruct. We used a single NVIDIA Tesla\nV100 (32G) GPU.\n17",
  "topic": "Task (project management)",
  "concepts": [
    {
      "name": "Task (project management)",
      "score": 0.6653723120689392
    },
    {
      "name": "Computer science",
      "score": 0.6354904174804688
    },
    {
      "name": "Health records",
      "score": 0.5804563164710999
    },
    {
      "name": "Data science",
      "score": 0.4628305733203888
    },
    {
      "name": "Baseline (sea)",
      "score": 0.45758286118507385
    },
    {
      "name": "Information retrieval",
      "score": 0.45718806982040405
    },
    {
      "name": "Unstructured data",
      "score": 0.4544544219970703
    },
    {
      "name": "Scale (ratio)",
      "score": 0.4248349070549011
    },
    {
      "name": "Data mining",
      "score": 0.3286622166633606
    },
    {
      "name": "Big data",
      "score": 0.3140450119972229
    },
    {
      "name": "Health care",
      "score": 0.1166205108165741
    },
    {
      "name": "Political science",
      "score": 0.0838509202003479
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I12912129",
      "name": "Northeastern University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1283280774",
      "name": "Brigham and Women's Hospital",
      "country": "US"
    }
  ]
}