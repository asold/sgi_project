{
  "title": "An investigation on the use of Large Language Models for hyperparameter tuning in Evolutionary Algorithms",
  "url": "https://openalex.org/W4401214105",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4223263492",
      "name": "Custode, Leonardo Lucio",
      "affiliations": [
        "University of Trento"
      ]
    },
    {
      "id": "https://openalex.org/A3163783608",
      "name": "Caraffini, Fabio",
      "affiliations": [
        "Swansea University"
      ]
    },
    {
      "id": "https://openalex.org/A4225204777",
      "name": "Yaman, Anil",
      "affiliations": [
        "Vrije Universiteit Amsterdam"
      ]
    },
    {
      "id": "https://openalex.org/A3171979206",
      "name": "Iacca, Giovanni",
      "affiliations": [
        "University of Trento"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2029375893",
    "https://openalex.org/W2146879413",
    "https://openalex.org/W4283390570",
    "https://openalex.org/W4402480400",
    "https://openalex.org/W281906528",
    "https://openalex.org/W4284676027",
    "https://openalex.org/W6838782900",
    "https://openalex.org/W4399177300",
    "https://openalex.org/W4401414856",
    "https://openalex.org/W3196732196",
    "https://openalex.org/W4300219688",
    "https://openalex.org/W4250348379",
    "https://openalex.org/W4388134851",
    "https://openalex.org/W2525579820",
    "https://openalex.org/W3151941575",
    "https://openalex.org/W1514875444"
  ],
  "abstract": "Hyperparameter optimization is a crucial problem in Evolutionary Computation.\\nIn fact, the values of the hyperparameters directly impact the trajectory taken\\nby the optimization process, and their choice requires extensive reasoning by\\nhuman operators. Although a variety of self-adaptive Evolutionary Algorithms\\nhave been proposed in the literature, no definitive solution has been found. In\\nthis work, we perform a preliminary investigation to automate the reasoning\\nprocess that leads to the choice of hyperparameter values. We employ two\\nopen-source Large Language Models (LLMs), namely Llama2-70b and Mixtral, to\\nanalyze the optimization logs online and provide novel real-time hyperparameter\\nrecommendations. We study our approach in the context of step-size adaptation\\nfor (1+1)-ES. The results suggest that LLMs can be an effective method for\\noptimizing hyperparameters in Evolution Strategies, encouraging further\\nresearch in this direction.\\n",
  "full_text": "An investigation on the use of Large Language Models for\nhyperparameter tuning in Evolutionary Algorithms\nLeonardo Lucio Custode\nleonardo.custode@unitn.it\nUniversity of Trento\nTrento, Italy\nFabio Caraffini\nfabio.caraffini@swansea.ac.uk\nSwansea University\nSwansea, UK\nAnil Yaman\na.yaman@vu.nl\nVrije Universiteit Amsterdam\nAmsterdam, The Netherlands\nGiovanni Iacca\ngiovanni.iacca@unitn.it\nUniversity of Trento\nTrento, Italy\nABSTRACT\nHyperparameter optimization is a crucial problem in Evolutionary\nComputation. In fact, the values of the hyperparameters directly\nimpact the trajectory taken by the optimization process, and their\nchoice requires extensive reasoning by human operators. Although\na variety of self-adaptive Evolutionary Algorithms have been pro-\nposed in the literature, no definitive solution has been found. In\nthis work, we perform a preliminary investigation to automate the\nreasoning process that leads to the choice of hyperparameter val-\nues. We employ two open-source Large Language Models (LLMs),\nnamely Llama2-70b and Mixtral, to analyze the optimization logs\nonline and provide novel real-time hyperparameter recommenda-\ntions. We study our approach in the context of step-size adaptation\nfor (1 +1)-ES. The results suggest that LLMs can be an effective\nmethod for optimizing hyperparameters in Evolution Strategies,\nencouraging further research in this direction.\nCCS CONCEPTS\n‚Ä¢ Information systems ‚ÜíLanguage models; ‚Ä¢ Theory of com-\nputation ‚ÜíEvolutionary algorithms.\nKEYWORDS\nEvolutionary Algorithms, Large Language Models, Landscape Anal-\nysis, Parameter Tuning\nACM Reference Format:\nLeonardo Lucio Custode, Fabio Caraffini, Anil Yaman, and Giovanni Iacca.\n2024. An investigation on the use of Large Language Models for hyperpa-\nrameter tuning in Evolutionary Algorithms. In Genetic and Evolutionary\nComputation Conference (GECCO ‚Äô24 Companion), July 14‚Äì18, 2024, Mel-\nbourne, VIC, Australia. ACM, New York, NY, USA, 8 pages. https://doi.org/\n10.1145/3638530.3664163\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nGECCO ‚Äô24 Companion, July 14‚Äì18, 2024, Melbourne, VIC, Australia\n¬© 2024 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-0495-6/24/07.\nhttps://doi.org/10.1145/3638530.3664163\n1 INTRODUCTION\nIt is well established in the field of Evolutionary Computation (EC),\nand even more broadly in Machine Learning (ML), that the hyper-\nparameters of an algorithm significantly influence its performance.\nIn evolutionary optimization, improper assignment of these param-\neters can lead to a suboptimal search process and provide inferior\nsolutions [48]. Over the past few decades, various approaches have\nbeen proposed to tackle this challenge by adjusting the parameters\nof the algorithms to positively influence the optimization process.\nFor instance, ontology-based approaches aim to formally repre-\nsent the knowledge revolving around the EC field [47] to enable\ninference-based tuning, whereas ML-based approaches [36] learn\nuseful representations for comparing evolutionary runs for land-\nscape analysis. Other approaches pre-define pools of parameter\nvalues [19, 20] and automatically choose from them during the opti-\nmization process. More recently, Reinforcement Learning (RL) has\nbeen considered to automatically train hyperparameter adaptation\npolicies based on data from previously available evolutionary runs\n[40]. In general, all these approaches aim to find the optimal param-\neter settings of an Evolutionary Algorithm (EA) before or during\nthe evolutionary optimization process and are usually referred to\nas parameter tuning or parameter control , respectively [9].\nUsing data acquired from evolutionary runs is certainly a viable\napproach to leverage the knowledge acquired from past optimiza-\ntion experiences, as shown in [40]. However, the data generated\nby evolutionary runs can be highly unstructured, and they heavily\ndepend on multiple aspects, such as the problem dimensionalities,\nthe different algorithms and strategies being used, the numerical\nprecision, the verbosity of the logging system in use, etc.\nIn recent years, Large Language Models (LLMs) have caused a\nprofound revolution in various fields, going beyond the traditional\ndomain of conversational agents. To date, LLMs have been success-\nfully applied to an ever-growing list of domains, such as chemistry\n[3], protein design [12], robotics [34, 38, 44], swarm motion plan-\nning [23], program synthesis [ 18, 21, 39], game design [ 24], and\nurban delivery route optimization [26].\nOne of the main keys to the success of LLMs is that they are ex-\ntremely well-suited for analyzing unstructured textual data, which\nmakes it easy to adapt them to conceptually similar tasks without\nthe need for retraining. Some recent literature [ 5, 32] has inves-\ntigated the direct usage of LLMs for optimization, although it is\nimportant to note that current LLMs are well-suited especially for\narXiv:2408.02451v1  [cs.NE]  5 Aug 2024\nGECCO ‚Äô24 Companion, July 14‚Äì18, 2024, Melbourne, VIC, Australia Custode et al.\nhigh-level discrete optimization tasks (e.g., planning). On the other\nhand, they are not well-suited for low-level (i.e., numerical) contin-\nuous optimization tasks due to (1) the inference cost of querying\nLLMs, and (2) their limited mathematical reasoning capabilities.\nFinally, several works have investigated the relationship between\nLLM and EC [45], both in the cases where LLMs are used to em-\npower EAs, and in the opposite case. However, none of them studied\nthe use case of hyperparameter optimization, which is an essential\nproblem in EC.\nIn this work, we conduct a preliminary investigation on the pos-\nsibility of automating ‚Äúempirical‚Äù step-size adaptation in Evolution\nStrategies (ES) using LLMs. More specifically, we focus on the case\nof tuning the step-size for (1 +1)-ES using state-of-the-art LLMs,\nnamely Llama2-70b [41] and Mixtral [22]. Our results show that\nLLMs can compete with well-known traditional mechanisms for\nstep-size adaptation.\nThe remainder of the paper is organized as follows. Section 2\nsummarizes the related work on LLMs and their applications to\noptimization, as well as the early work on EC applied to LLMs.\nSection 3 describes our methods. Section 4 presents the numerical\nresults. Finally, Section 5 concludes this research.\n2 RELATED WORK\nThere is a growing trend to combine the strengths of optimization\nalgorithms with LLMs for various purposes. This synergy is evi-\ndent also in the EC research community, where the ‚ÄòLLM‚Äô keyword\nis increasingly prevalent and the increasing number of available\npreprints, see [45] for a recent exhaustive list, is a clear signal that\nmore articles of this kind will soon populate the literature. This\nhighlights a promising direction where LLMs will play an impor-\ntant role in optimization (especially, but not only, evolutionary-\nbased), addressing various challenges associated with optimization\nalgorithms and leading to hybrid systems where optimization algo-\nrithms and LLMs work together for mutual benefits.\n2.1 LLMs as the optimizer\nLLMs make it possible to articulate complex tasks using natural lan-\nguage, thus facilitating and automating decision-making in many\nlogistical scenarios, such as planning and scheduling [28], which\notherwise would require an expert to formulate the problem rigor-\nously (i.e., as a discrete optimization task). For example, ChatGPT\nhas been used to produce the schedule of a construction project\nin [30] and to schedule vehicles and drivers to complete a prede-\ntermined set of trips in a specified period in [43]. These are com-\nbinatorial optimization problems whose operational constraints\nare difficult to formulate mathematically but easy to communicate\nto an LLM. Similarly, in [2], users can ask ‚Äúwhat if‚Äù questions on\nsupply chain demand for a particular scenario in plain text and\nget answers about the outcomes of an underlying supply chain\noptimization algorithm.\nHyperparameter optimization is another intriguing application\nwhere LLMs can act as the optimizer for other ML models. Com-\npared to traditional hyperparameter optimization methods, the\nresults appear promising [27]. For instance, the studies in [51] and\n[49] leverage GPT-4 to perform Neural Architecture Search and\ndesign autoML frameworks, respectively.\nFinally, Optimization by PROmpting (OPRO) is a framework pro-\nposed in [5] for using LLMs as an iterative heuristic for gradient-free\noptimization. In each optimization step, the OPRO LLM generates\nnew solutions from those contained (including their values) in the\nprevious prompt. As with any EC approach, novel candidate so-\nlutions are evaluated and added to the next prompt for the next\noptimization step. This is a general approach that is usable for both\ndiscrete and continuous problems. The results presented in [5] for\nlinear regression and Travelling Salesman Problems are promising,\nhighlighting that OPRO can optimize the prompts without human\nintervention.\n2.2 EAs for prompt or LLM optimization\nThe need for a good quality prompt has opened the way for the\nprompt optimization/engineering field. The existing literature ex-\nplores different methodologies to optimize prompts. Recent work\n[31] suggests using gradient descent with beam search and bandit\nselection assuming that training data and an LLM API are accessible.\nEC offers various tools for this task, which can also be used when\ntraining data and internal LLM information are inaccessible (i.e.,\nthe gradient information cannot be exploited). Genetic Algorithms\nare widely used [11, 50], and ideas borrowed from EAs are explored\nin the EvoPrompt framework [17]. In [37], an interesting approach\nbased on vectorizing prompts in a continuous subspace employs\nCMA-ES to perform the optimization process.\nLLM architecture search is another intriguing optimization chal-\nlenge. EAs can greatly help explore these vast search spaces. In\nthe AutoBERT-Zero framework [15], this is done by performing\nprimitive math operations and through an interesting ‚ÄúOperation-\nPriority‚Äù evolution strategy, which exploits prior information from\noperations during the search. Other studies consider multiple ob-\njectives, such as the one in [ 42], which compares direct search\nmethods and classic heuristics, or the framework in [ 14], where\nEAs are used to find the most suitable distribution of hidden units\nacross layers, ensuring that accuracy and latency requirements are\nmet concurrently.\n2.3 LLMs supporting EAs\nLLMs can support EAs in numerous ways and there is growing\nenthusiasm for employing them to solve various mathematical\nproblems. In this context, the most popular example of incorporat-\ning LLM into EAs is probably the FunSearch algorithm [35]. This\nalgorithm has raised a debate among researchers, with some ap-\nplauding its ability to tackle unresolved mathematical problems\nand demonstrate genuine ‚Äúintelligence‚Äù, while others pointing out\nits limitations, as being ‚Äúremarkable for the shallowness of the math-\nematical understanding that it seems to exhibit ‚Äù [6]. Regardless of\nits public perception, FunSearch is an interesting, but algorithmi-\ncally straightforward approach. It involves employing an LLM to\ngenerate code for a specific subroutine within a larger program in\na Genetic Programming (GP) algorithm, meaning that the LLM is\nembedded into the EA to perform the mutation step. The idea of\nusing LLMs for code generation in EAs is not new. In [25], they are\nused with the MAP-Elites algorithm to generate effective mutation\noperators for GP.\nAn investigation on the use of LLMs for hyperparameter tuning in EAs GECCO ‚Äô24 Companion, July 14‚Äì18, 2024, Melbourne, VIC, Australia\nFitnesses(1+1) Evolution Strategy\nInitial step size\nPrompt\nLog\nLarge Language ModelAdjusted step size\nFigure 1: A block diagram showing the self-adaptive step-size adaptation scheme studied in this work.\nAlgorithm design is another application of LLMs to EAs. For\nexample, in [10] LLMs are employed to generate and evolve algo-\nrithm components such as initialization, selection, crossover, etc.\nto create new algorithms.\nThere are interesting uses for LLMs in other optimization scenar-\nios. The system described in [29] uses these techniques to simplify\nthe formulation of common complex business optimization prob-\nlems, allowing the optimizer to improve performance in production\nscheduling. In [46], LLMs check the feasibility of solutions to con-\nstraints in discrete spaces to facilitate the application of simulated\nannealing and other single-solution metaheuristics. LLMs can also\nfunction as supervisory logic, e.g., they coordinate agents in the\ncoevolutionary algorithm presented in [7].\n3 METHODS\nIn this work, we leverage LLMs to automatically optimize the step-\nsize for (1 +1)-ES, which generates an offspring by adding, to the\ncurrent solution, a uniform perturbation in a hyper-sphere of radius\nùúé, the step-size.\nIn our method, the LLM is queried every ùëù optimization steps\n(with ùëù being user-defined, e.g. based on the available computa-\ntional resources) with the log produced from the beginning of the\noptimization process to the current generation. The LLM is then\nasked to produce a recommendation for the next step-size to be\nused in the subsequent ùëù steps. For the LLM-based step-size adap-\ntation, we use a period of ùëù = 50 generations to calculate the new\nstep-size.\nWe fix the number of fitness evaluations for all the methods to\n103. Our code is publicly available on GitHub1.\n3.1 Benchmark problems\nWe run (1 +1)-ES on the BBOB suite [13], using the IOHProfiler\nsuite [8]. We test all the BBOB problems with dimensionalities 2, 5,\nand 30, to assess the capabilities of the proposed method to work\nin both low- and moderate-sized problems. For each function, we\n1https://github.com/DIOL-UniTN/llm_step_size_adaptation\nperform 10 independent runs with different starting points. Then,\nwe feed the logs to the LLMs, using the prompt described below.\n3.2 Prompt format\nTo provide the LLM with the information needed to tune the step-\nsize, we initially considered three different options: (1) feeding\nonly the fitness values; (2) feeding genotypes and fitnesses; and (3)\nfeeding the genotypes, the relationships between the genotypes\n(i.e., between the parent solution and its offspring, through the\neffect of mutation), and the fitnesses. However, after preliminary\nexperiments (not reported here for brevity), we did notice that\nthe last two approaches required a substantially higher amount of\ntokens, quickly filling the context window of the models. For this\nreason, we eventually use a prompt that only contained the essential\ninformation to make a decision, i.e., the changes in the step-size\nand the fitnesses of all the last individuals evaluated (depending on\nthe size of the context window).\nAn example of such a prompt can be seen in Listing 1. Here, the\n‚Äúsystem‚Äù prompt is used to provide a preliminary context to the\nmodel to properly address the task. Then, the ‚Äúuser‚Äù task represents\nthe actual query. Finally, it is important to note that we request\na step-size ùë† ‚àà[0.001, 0.999]to prevent the LLMs from choosing\nexploding step-sizes.\n3.3 Algorithms and LLMs\nOur comparison investigates the performance of different strategies\nfor adapting the step-size of (1 +1)-ES. We employ two baseline\nmethods and two LLM-based methods. The two baselines consist of:\n(1) a constant step-size for the ES (fixed to0.1); and (2) a well-known\nrule-based strategy, namely the One-Fifth success rule [ 33]. The\nlatter changes the step-size by considering the current candidate\nùë•‚Ä≤= ùë• +N(0, ùúéùë† ), where ùë• is the parent solution, Nis the Gaussian\n(normal) distribution, and ùúéùë† is the step-size, as follows:\nùúé‚Ä≤\nùë† =\nÔ£±Ô£¥Ô£¥Ô£¥ Ô£≤\nÔ£¥Ô£¥Ô£¥Ô£≥\n1.5ùúéùë† ùëñ ùëì ùëì(ùë•‚Ä≤)< ùëì (ùë•)\n1.5‚àí1\n4 ùúéùë† ùëñ ùëì ùëì(ùë•‚Ä≤)> ùëì (ùë•)\nùúéùë† ùëñ ùëì ùëì(ùë•‚Ä≤)= ùëì (ùë•)\n(1)\nGECCO ‚Äô24 Companion, July 14‚Äì18, 2024, Melbourne, VIC, Australia Custode et al.\nRegarding the LLM-based step-size adaptation strategies, we em-\nploy two widely known open-source state-of-the-art LLMs, namely\nLlama2-70b and Mixtral. Llama2-70b is the largest model of the\nLlama2 family [41]. It features 80 transformer layers with a hidden\nsize of 8192 dimensions [4]. It has been trained on 2ùëá tokens and\nhas a maximum context size of 4096 tokens.\nMixtral [22], instead, is a mixture-of-experts model made of 8\nexperts, each with 32 transformer layers with a hidden size of 4096\ndimensions. It has a context size of 32ùëò tokens.\nFor both models, we employ Groq‚Äôs APIs for accelerated infer-\nence2.\n4 RESULTS\nThe results obtained by the4 methods under comparison are shown\nin Figure 3, aggregating the results for all the problem sizes to facil-\nitate visualization. We observe that, in most cases, the performance\nof both Llama2-70b and Mixtral is comparable to that of the One-\nFifth strategy, suggesting a somehow similar behavior in terms of\nstep-size adaptation. Note that, for the ùëì 5 function, the methods\nusing constant step-sizes and the one-fifth rule achieve values very\nclose to zero, and thus they are not visible in the boxplot (which\nuses a logarithmic scale).\nTo verify this hypothesis, we studied the step-size used by each\nof the methods under comparison in Figure 2. Note that the trend\nshown in Figure 2 contains the average step-size computed on all\nthe functions of the benchmark, divided by all the dimensionalities\nconsidered before. We observe that, contrary to our expectations,\ntheir impact on the step-size is actually at two opposite extremes. In\nfact, while the One-Fifth rule pushes the step-size to very high val-\nues, the two LLM-based methods tend to progressively reduce the\nstep-size. Yet, their performance appears to be overall similar. More-\nover, it is interesting to note that the variance of the LLM-based\nstep-size adaptation techniques is inversely proportional to the\nproblem dimensionality, while the variance of the one-fifth adapta-\ntion techniques seems much larger in the highest-dimensionality\ncase.\nFinally, to add a further level of comparative evaluation of the\nfour methods, we performed the glicko2-based ranking [ 16] for\nfixed-budget scenarios, available in the IOHAnalyzer platform 3.\nThe results are shown in Tables 1 to 3. In the tables, we observe an\ninteresting trend: Llama2-70b always ranks first, outperforming all\nthe other methods. On the other hand, we see Mixtral as a runner-up\nwhen the problem dimensionality is 2, and it gradually ranks worse\nas the dimensionality of the problem increases. Another interesting\nremark is that, in the highest-dimensionality case (Table 3), both\nMixtral and the One-Fifth rule rank worse than having a constant\nstep-size. On the other hand, in 30 dimensions Llama2-70b is the\nonly method that performs better than simply using a constant\nstep-size.\nThese preliminary results indicate that it is indeed possible to\nhave well-performing step-size adaptation strategies by using the\nreasoning capabilities in LLMs. However, our results also show that\n2https://groq.com\n3https://iohanalyzer.liacs.nl/\nthe outcomes are heavily dependent on the LLM at hand, suggest-\ning that a specialized LLM (e.g., fine-tuned on a large dataset of\nevolutionary runs) could lead to even better results.\n5 CONCLUSIONS\nThe step-size is a crucial parameter in ES. In fact, it allows the user\nto directly control the exploration and exploitation capabilities of\nthe algorithm. While several approaches have been proposed for\nadapting the step-size in ES, there is no one-fits-all strategy that\nsolves this problem. This is due to the fact that step-size control\nheavily depends on the context at hand, which requires some form\nof reasoning. In this direction, we performed a preliminary investi-\ngation on the use of LLMs for tuning the step-size of(1 +1)-ES. Our\nresults indicate that it is possible to find adaptation strategies that\nare competitive with established methods for step-size adaptation,\nsuch as the One-Fifth rule. Moreover, given the fixed budget used in\nour experiments, the approach based on Llama2-70b showed better\nconsistency w.r.t. the other techniques, always ranking as the best\nalgorithm.\nThe present work suggests several interesting future directions,\nsuch as experimenting with different prompts (and the related\ninformation therein) provided to the LLMs, fine-tuning existing\nopen-source LLMs to the specific domain of adaptation strategies,\nconducting a more extensive study on hyperparameter optimization\nfor EAs using LLMs (i.e., using larger budgets, as suggested in [1],\nand more sophisticated step-size adaptation schemes), and finally\ndeveloping an LLM-guided EA.\nREFERENCES\n[1] Anne Auger. 2009. Benchmarking the (1+1) evolution strategy with one-fifth\nsuccess rule on the BBOB-2009 function testbed. In Genetic and Evolutionary\nComputation Conference Companion . ACM, New York, NY, USA, 2447‚Äì2452.\n[2] Beibin Li and Konstantina Mellou and Bo Zhang and Jeevan Pathuri and\nIshai Menache. 2023. Large Language Models for Supply Chain Optimization.\narXiv:2307.03875.\n[3] Boiko, Daniil A and MacKnight, Robert and Kline, Ben and Gomes, Gabe. 2023.\nAutonomous chemical research with large language models. Nature 624, 7992\n(2023), 570‚Äì578.\n[4] Nuo Chen, Ning Wu, Shining Liang, Ming Gong, Linjun Shou, Dongmei Zhang,\nand Jia Li. 2024. Is Bigger and Deeper Always Better? Probing LLaMA Across\nScales and Layers. arXiv:2312.04333.\n[5] Chengrun Yang and Xuezhi Wang and Yifeng Lu and Hanxiao Liu and Quoc V. Le\nand Denny Zhou and Xinyun Chen. 2023. Large Language Models as Optimizers.\narXiv:2309.03409.\n[6] Ernest Davis. 2024. Using a large language model to generate program mutations\nfor a genetic algorithm to search for solutions to combinatorial problems: Review\nof (Romera-Paredes et al., 2023). https://cs.nyu.edu/~davise/papers/FunSearch.\npdf Accessed on 7/04/2024.\n[7] de Zarz√†, I. and de Curt√≤, J. and Roig, Gemma and Manzoni, Pietro and Calafate,\nCarlos T. 2023. Emergent Cooperation and Strategy Adaptation in Multi-Agent\nSystems: An Extended Coevolutionary Theory with LLMs. Electronics 12, 12\n(2023), 19.\n[8] Carola Doerr, Hao Wang, Furong Ye, Sander van Rijn, and Thomas B√§ck. 2018.\nIOHprofiler: A Benchmarking and Profiling Tool for Iterative Optimization\nHeuristics. arXiv:1810.05281.\n[9] Eiben, √Ågoston E and Hinterding, Robert and Michalewicz, Zbigniew. 1999.\nParameter control in evolutionary algorithms. IEEE Transactions on evolutionary\ncomputation 3, 2 (1999), 124‚Äì141.\n[10] Fei Liu and Xialiang Tong and Mingxuan Yuan and Qingfu Zhang. 2023. Algo-\nrithm Evolution Using Large Language Model. arXiv:2311.15249.\n[11] Chengzhe Feng, Yanan Sun, Ke Li, Pan Zhou, Jiancheng Lv, and Aojun Lu. 2024.\nGenetic Auto-prompt Learning for Pre-trained Code Intelligence Language Mod-\nels. arXiv:2403.13588.\n[12] Ferruz, Noelia and H√∂cker, Birte. 2022. Controllable protein design with language\nmodels. Nature Machine Intelligence 4, 6 (2022), 521‚Äì532.\n[13] Steffen Finck, Nikolaus Hansen, Raymond Ros, and Anne Auger. 2010. Real-\nparameter black-box optimization benchmarking 2009: Presentation of the noiseless\nAn investigation on the use of LLMs for hyperparameter tuning in EAs GECCO ‚Äô24 Companion, July 14‚Äì18, 2024, Melbourne, VIC, Australia\nListing 1: Prompt template.\n{\n\" r o l e \" : \" system \" ,\n\" c o n t e n t \" : \" You a r e a p o w e r f u l and i n t e l l i g e n t AI c a p a b l e o f a n a l y z i n g l o g s and\np e r f o r m i n g r e a s o n i n g \"\n} ,\n{\n\" r o l e \" : \" u s e r \" ,\n\" c o n t e n t \" : \"Q : I am running an o p t i m i z a t i o n p r o c e s s over an unknown f u n c t i o n .\nI am u s i n g a 1+1 ‚àíES t o o p t i m i z e t h e f u n c t i o n .\nf ( x ) = y i n d i c a t e s an e v a l u a t i o n .\nx1 ‚àí> x2 i n d i c a t e s t h a t x1 , u s i n g t h e c u r r e n t s t e p s i z e ,\nproduced a new c a n d i d a t e s o l u t i o n x2 .\nI t i s e x t r e m e l y i m p o r t a n t t h a t t h e s t e p s i z e you propose i s\nc o n t a i n e d between 0 . 9 9 9 and 0 . 0 0 1 .\nHere ' s t h e l o g : ` ` `t x t\n<LOG CONTENT>\n```\nI am c u r r e n t l y u s i n g t h e f o l l o w i n g s t e p s i z e : <STEP SIZE > .\nShould I change i t or not ?\nDo you t h i n k t h a t t h e c u r r e n t s t e p s i z e i s good enough t o make\nt h e p r o c e s s c onverge as soon as p o s s i b l e ?\nReply with t h e f o l l o w i n g s t r u c t u r e :\n` Reasoning : < e x p l a n a t i o n >\nRecommended s t e p s i z e : <new s t e p s i z e > `\"\n}\n0 200 400 600 800 1000\nfunction evaluation\n10‚àí3\n10‚àí2\n10‚àí1\n100\n101\n102\nStep size\ndim = 2\n0 200 400 600 800 1000\nfunction evaluation\ndim = 5\n0 200 400 600 800 1000\nfunction evaluation\ndim = 30\nConstant Llama2-70b Mixtral One-Fifth\nFigure 2: Average step-size for each function evaluation for all the methods under comparison. The solid lines represent the\nmean value for the step-size (averaged over all problems and problem dimensionalities), while the shaded area represents the\n95% confidence interval.\nfunctions. Technical Report. Citeseer.\n[14] Vinod Ganesan, Gowtham Ramesh, and Pratyush Kumar. 2021. SuperShaper:\nTask-Agnostic Super Pre-training of BERT Models with Variable Hidden Dimen-\nsions. arXiv:2110.04711.\n[15] Jiahui Gao, Hang Xu, Han Shi, Xiaozhe Ren, LH Philip, Xiaodan Liang, Xin Jiang,\nand Zhenguo Li. 2022. AutoBERT-Zero: Evolving BERT Backbone from Scratch.\nIn AAAI Conference on Artificial Intelligence , Vol. 36, no. 10. AAAI, Washington,\nDC, US, 10663‚Äì10671.\n[16] Mark E Glickman. 2012. Example of the Glicko-2 system . Technical Report. Boston\nUniversity.\n[17] Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing\nLiu, Jiang Bian, and Yujiu Yang. 2024. Connecting Large Language Models with\nEvolutionary Algorithms Yields Powerful Prompt Optimizers. arXiv:2309.08532.\n[18] Erik Hemberg, Stephen Moskal, and Una-May O‚ÄôReilly. 2024. Evolving Code\nwith A Large Language Model. arXiv:2401.07102.\n[19] Giovanni Iacca, Fabio Caraffini, and Ferrante Neri. 2015. Continuous Parameter\nPools in Ensemble Self-Adaptive Differential Evolution. InIEEE Symposium Series\non Computational Intelligence . IEEE, New York, NY, USA, 1529‚Äì1536.\n[20] Giovanni Iacca, Ferrante Neri, Fabio Caraffini, and Ponnuthurai Nagaratnam\nSuganthan. 2014. A differential evolution framework with ensemble of parameters\nGECCO ‚Äô24 Companion, July 14‚Äì18, 2024, Melbourne, VIC, Australia Custode et al.\n10‚àí10\n10‚àí6\n10‚àí2\n102\n106\n1010\nbest-so-far f(x)\nf = f1\n f = f2\n f = f3\n f = f4 f = f5\n10‚àí10\n10‚àí6\n10‚àí2\n102\n106\n1010\nbest-so-far f(x)\nf = f6\n f = f7\n f = f8\n f = f9\n f = f10\n10‚àí10\n10‚àí6\n10‚àí2\n102\n106\n1010\nbest-so-far f(x)\nf = f11\n f = f12\n f = f13\n f = f14\n f = f15\n10‚àí10\n10‚àí6\n10‚àí2\n102\n106\n1010\nbest-so-far f(x)\nf = f16\n f = f17\n f = f18 f = f19\nConstantLlama2-70b Mixtral One-Fifth\nmethod\nf = f20\nConstantLlama2-70b Mixtral One-Fifth\nmethod\n10‚àí10\n10‚àí6\n10‚àí2\n102\n106\n1010\nbest-so-far f(x)\nf = f21\nConstantLlama2-70b Mixtral One-Fifth\nmethod\nf = f22\nConstantLlama2-70b Mixtral One-Fifth\nmethod\nf = f23\nConstantLlama2-70b Mixtral One-Fifth\nmethod\nf = f24\nFigure 3: Boxplot of the best fitness obtained in 10 runs by each of the methods on each function from the BBOB suite. Note\nthat we aggregate the values from 10 runs on all the considered problem sizes.\nand strategies and pool of local search algorithms. InApplications of Evolutionary\nComputation: 17th European Conference, EvoApplications 2014, Granada, Spain,\nApril 23-25, 2014, Revised Selected Papers 17 . Springer, Berlin Heidelberg, Germany,\n615‚Äì626.\n[21] Jain, Naman and Vaidyanath, Skanda and Iyer, Arun and Natarajan, Nagarajan\nand Parthasarathy, Suresh and Rajamani, Sriram and Sharma, Rahul. 2022. Jigsaw:\nLarge Language Models Meet Program Synthesis. In International Conference\non Software Engineering . Association for Computing Machinery, New York, NY,\nUSA, 1219‚Äì1231.\n[22] Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche\nSavary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou\nHanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample,\nL√©lio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep\nSubramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Th√©ophile Gervet,\nThibaut Lavril, Thomas Wang, Timoth√©e Lacroix, and William El Sayed. 2024.\nMixtral of Experts. arXiv:2401.04088.\nAn investigation on the use of LLMs for hyperparameter tuning in EAs GECCO ‚Äô24 Companion, July 14‚Äì18, 2024, Melbourne, VIC, Australia\nTable 1: Glicko2-based ranking of the methods on functions from the BBOB suite with dimensionality 2.\nStep-size adaptation method Rating Deviation Volatility Games Win Draw Loss\nLlama2-70b 1532 18.9 0.0480 5700 3189 9 2502\nMixtral 1510 18.0 0.0431 5700 2853 9 2838\nConstant step-size 1479 17.5 0.0409 5700 2705 6 2989\nOne-Fifth rule 1479 17.3 0.0392 5700 2640 2 3058\nTable 2: Glicko2-based ranking of the methods on functions from the BBOB suite with dimensionality 5.\nStep-size adaptation method Rating Deviation Volatility Games Win Draw Loss\nLlama2-70b 1562 17.8 0.0415 5700 3537 0 2163\nOne-Fifth rule 1495 16.6 0.0365 5700 2778 0 2922\nMixtral 1481 18.1 0.0436 5700 2695 0 3005\nConstant step-size 1459 16.7 0.0359 5700 2390 0 3310\nTable 3: Glicko2-based ranking of the methods on functions from the BBOB suite with dimensionality 30.\nStep-size adaptation method Rating Deviation Volatility Games Win Draw Loss\nLlama2-70b 1570 17.3 0.0378 5700 3591 0 2109\nConstant step-size 1540 16.6 0.0354 5700 3202 0 2498\nOne-Fifth rule 1457 16.7 0.0361 5700 2363 0 3337\nMixtral 1430 17.5 0.0390 5700 2244 0 3456\n[23] Jiao, Aoran and Patel, Tanmay P and Khurana, Sanjmi and Korol, Anna-Mariya\nand Brunke, Lukas and Adajania, Vivek K and Culha, Utku and Zhou, Siqi and\nSchoellig, Angela P. 2023. Swarm-GPT: Combining Large Language Models with\nSafe Motion Planning for Robot Choreography Design. arXiv:2312.01059.\n[24] Lanzi, Pier Luca and Loiacono, Daniele. 2023. ChatGPT and other large language\nmodels as evolutionary engines for online interactive collaborative game design.\narXiv:2303.02155.\n[25] Lehman, Joel and Gordon, Jonathan and Jain, Shawn and Ndousse, Kamal and\nYeh, Cathy and Stanley, Kenneth O. 2023. Evolution through large models. In\nHandbook of Evolutionary Machine Learning . Springer, Singapore, 331‚Äì366.\n[26] Liu, Yang and Wu, Fanyou and Liu, Zhiyuan and Wang, Kai and Wang, Feiyue and\nQu, Xiaobo. 2023. Can language models be used for real-world urban-delivery\nroute optimization? The Innovation 4, 6 (2023), 8 pages.\n[27] Michael R. Zhang and Nishkrit Desai and Juhan Bae and Jonathan Lorraine and\nJimmy Ba. 2023. Using Large Language Models for Hyperparameter Optimization.\narXiv:2312.04528.\n[28] Vishal Pallagani, Kaushik Roy, Bharath Muppasani, Francesco Fabiano, Andrea\nLoreggia, Keerthiram Murugesan, Biplav Srivastava, Francesca Rossi, Lior Horesh,\nand Amit Sheth. 2024. On the Prospects of Incorporating Large Language Models\n(LLMs) in Automated Planning and Scheduling (APS). arXiv:2401.02500.\n[29] Pivithuru Thejan Amarasinghe and Su Nguyen and Yuan Sun and Damminda\nAlahakoon. 2023. AI-Copilot for Business Optimisation: A Framework and A\nCase Study in Production Scheduling. arXiv:2309.13218.\n[30] Samuel A. Prieto, Eyob T. Mengiste, and Borja Garc√≠a de Soto. 2023. Investigating\nthe Use of ChatGPT for the Scheduling of Construction Projects. Buildings 13, 4\n(2023), 16 pages.\n[31] Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng.\n2023. Automatic Prompt Optimization with ‚ÄúGradient Descent‚Äù and Beam Search.\narXiv:2305.03495.\n[32] Qingyan Guo and Rui Wang and Junliang Guo and Bei Li and Kaitao Song and\nXu Tan and Guoqing Liu and Jiang Bian and Yujiu Yang. 2023. Connecting\nLarge Language Models with Evolutionary Algorithms Yields Powerful Prompt\nOptimizers. arXiv:2309.08532.\n[33] Ingo Rechenberg. 1973. Evolutionsstrategie: Optimierung technischer Systeme\nnach Prinzipien derbiologischen Evolution . Frommann-Holzboog Verlag, Stuttgart,\nGermany.\n[34] Ren, Allen Z and Dixit, Anushri and Bodrova, Alexandra and Singh, Sumeet and\nTu, Stephen and Brown, Noah and Xu, Peng and Takayama, Leila and Xia, Fei and\nVarley, Jake and others. 2023. Robots that ask for help: Uncertainty alignment\nfor large language model planners. arXiv:2307.01928.\n[35] Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov,\nAlexander and Balog, Matej and Kumar, M Pawan and Dupont, Emilien and Ruiz,\nFrancisco JR and Ellenberg, Jordan S and Wang, Pengming and Fawzi, Omar and\nothers. 2023. Mathematical discoveries from program search with large language\nmodels. Nature (early access) (2023), 1‚Äì3.\n[36] Moritz Vinzent Seiler, Pascal Kerschke, and Heike Trautmann. 2024. Deep-\nELA: Deep Exploratory Landscape Analysis with Self-Supervised Pretrained\nTransformers for Single- and Multi-Objective Continuous Optimization Problems.\narXiv:2401.01192.\n[37] Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, and Xipeng Qiu. 2022.\nBlack-Box Tuning for Language-Model-as-a-Service. In International Conference\non Machine Learning (Proceedings of Machine Learning Research, Vol. 162) , Ka-\nmalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and\nSivan Sabato (Eds.). PMLR, Honolulu, HI, US, 20841‚Äì20855.\n[38] Sun, Lingfeng and Jha, Devesh K and Hori, Chiori and Jain, Siddarth and Corcodel,\nRadu and Zhu, Xinghao and Tomizuka, Masayoshi and Romeres, Diego. 2023.\nInteractive Planning Using Large Language Models for Partially Observable\nRobotics Tasks. arXiv:2312.06876.\n[39] Tao, Ning and Ventresque, Anthony and Saber, Takfarinas. 2023. Program Syn-\nthesis with Generative Pre-trained Transformers and Grammar-Guided Genetic\nProgramming Grammar. In IEEE Latin American Conference on Computational\nIntelligence. IEEE, New York, NY, USA, 6 pages.\n[40] Michele Tessari and Giovanni Iacca. 2022. Reinforcement learning based adaptive\nmetaheuristics. In Genetic and Evolutionary Computation Conference Companion .\nACM, New York, NY, USA, 1854‚Äì1861.\n[41] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-\nmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucu-\nrull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia\nGao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini,\nRui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel\nKloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut\nLavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet,\nTodor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton,\nJeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva,\nEric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross\nTaylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov,\nYuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2:\nOpen Foundation and Fine-Tuned Chat Models. arXiv:2307.09288.\nGECCO ‚Äô24 Companion, July 14‚Äì18, 2024, Melbourne, VIC, Australia Custode et al.\n[42] Christophe Tribes, Sacha Benarroch-Lelong, Peng Lu, and Ivan Kobyzev. 2024.\nHyperparameter Optimization for Large Language Model Instruction-Tuning.\narXiv:2312.00949.\n[43] Vo√ü, Stefan. 2023. Successfully Using ChatGPT in Logistics: Are We There Yet?.\nIn Computational Logistics . Springer Nature, Cham, Switzerland, 3‚Äì17.\n[44] Wang, Lirui and Ling, Yiyang and Yuan, Zhecheng and Shridhar, Mohit and Bao,\nChen and Qin, Yuzhe and Wang, Bailin and Xu, Huazhe and Wang, Xiaolong.\n2023. GenSim: Generating Robotic Simulation Tasks via Large Language Models.\narXiv:2310.01361.\n[45] Xingyu Wu, Sheng hao Wu, Jibin Wu, Liang Feng, and Kay Chen Tan. 2024.\nEvolutionary Computation in the Era of Large Language Model: Survey and\nRoadmap. arXiv:2401.10034.\n[46] Xianggen Liu and Pengyong Li and Fandong Meng and Hao Zhou and Huasong\nZhong and Jie Zhou and Lili Mou and Sen Song. 2021. Simulated annealing for\noptimization of graphs and sequences. Neurocomputing 465 (2021), 310‚Äì324.\n[47] Yaman, Anil and Hallawa, Ahmed and Coler, Matt and Iacca, Giovanni. 2017.\nPresenting the ECO: evolutionary computation ontology. In Applications of Evo-\nlutionary Computation . Springer, Cham, Switzerland, 603‚Äì619.\n[48] Yaman, Anil and Iacca, Giovanni and Caraffini, Fabio. 2019. A comparison of\nthree differential evolution strategies in terms of early convergence with different\npopulation sizes. InAIP Conference Proceedings, Vol. 2070. AIP Publishing, Melville,\nNY, USA, 4 pages.\n[49] Shujian Zhang, Chengyue Gong, Lemeng Wu, Xingchao Liu, and Mingyuan Zhou.\n2023. AutoML-GPT: Automatic Machine Learning with GPT. arXiv:2305.02499.\n[50] Jiangjiang Zhao, Zhuoran Wang, and Fangchun Yang. 2023. Genetic Prompt\nSearch via Exploiting Language Model Probabilities. InInternational Joint Confer-\nence on Artificial Intelligence , Edith Elkind (Ed.). International Joint Conferences\non Artificial Intelligence Organization, Macao, 5296‚Äì5305.\n[51] Mingkai Zheng, Xiu Su, Shan You, Fei Wang, Chen Qian, Chang Xu, and Samuel\nAlbanie. 2023. Can GPT-4 Perform Neural Architecture Search? arXiv:2304.10970.",
  "topic": "Hyperparameter",
  "concepts": [
    {
      "name": "Hyperparameter",
      "score": 0.9406534433364868
    },
    {
      "name": "Computer science",
      "score": 0.7301130294799805
    },
    {
      "name": "Machine learning",
      "score": 0.5877196788787842
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5844096541404724
    },
    {
      "name": "Hyperparameter optimization",
      "score": 0.5531675219535828
    },
    {
      "name": "Evolutionary computation",
      "score": 0.5278180241584778
    },
    {
      "name": "Evolutionary algorithm",
      "score": 0.5242854952812195
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5109297633171082
    },
    {
      "name": "Process (computing)",
      "score": 0.4680364429950714
    },
    {
      "name": "Adaptation (eye)",
      "score": 0.4415396749973297
    },
    {
      "name": "Psychology",
      "score": 0.10180863738059998
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Support vector machine",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I193223587",
      "name": "University of Trento",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I39586589",
      "name": "Swansea University",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I865915315",
      "name": "Vrije Universiteit Amsterdam",
      "country": "NL"
    }
  ]
}