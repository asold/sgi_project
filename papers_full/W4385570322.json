{
    "title": "TempLM: Distilling Language Models into Template-Based Generators",
    "url": "https://openalex.org/W4385570322",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2116085444",
            "name": "Tianyi Zhang",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2120172011",
            "name": "Mina Lee",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2953445399",
            "name": "Xiang Lisa Li",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5048371209",
            "name": "Ende Shen",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2169829788",
            "name": "Tatsunori Hashimoto",
            "affiliations": [
                "Stanford University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3202712981",
        "https://openalex.org/W3034383590",
        "https://openalex.org/W3200914550",
        "https://openalex.org/W1956340063",
        "https://openalex.org/W3034948406",
        "https://openalex.org/W2889009749",
        "https://openalex.org/W2963592583",
        "https://openalex.org/W1970207841",
        "https://openalex.org/W3100355250",
        "https://openalex.org/W2953369829",
        "https://openalex.org/W1821462560",
        "https://openalex.org/W2963084773",
        "https://openalex.org/W3212893438",
        "https://openalex.org/W140747314",
        "https://openalex.org/W3034999214",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W2962784628",
        "https://openalex.org/W2123301721",
        "https://openalex.org/W1521413921",
        "https://openalex.org/W2963091658",
        "https://openalex.org/W4287553002",
        "https://openalex.org/W1985610876",
        "https://openalex.org/W2963655793",
        "https://openalex.org/W3106255016",
        "https://openalex.org/W2117010802",
        "https://openalex.org/W4233573184",
        "https://openalex.org/W1763968285"
    ],
    "abstract": "While pretrained language models (PLMs) have greatly improved text generation, they have also been known to produce unfaithful or inappropriate content. In contrast, classic template-based systems provide strong guarantees of faithfulness at the cost of fluency. We propose TempLM, which achieves the best of both worlds by distilling a PLM into a template-based generator. On the E2E and SynthBio data-to-text datasets, we show that TempLM is more faithful than the original PLM and is more fluent than prior template systems. Notably, on an out-of-domain evaluation, TempLM reduces a finetuned BART model's unfaithfulness rate from 83% to 0%. In a human study, we find that TempLM's templates substantially improve upon human-written ones in BERTScore.",
    "full_text": "Findings of the Association for Computational Linguistics: ACL 2023, pages 1970–1994\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nTempLM: Distilling Language Models into Template-Based Generators\nTianyi Zhang, Mina Lee∗, Lisa Li∗, Ende Shen∗, Tatsunori B. Hashimoto\nComputer Science Department, Stanford University\n{tz58, minalee, xlisali, endeshen, thashim}@stanford.edu\nAbstract\nWhile pretrained language models (PLMs)\nhave greatly improved text generation, they\nhave also been known to produce unfaithful\nor inappropriate content. In contrast, classic\ntemplate-based systems provide strong guaran-\ntees of faithfulness at the cost of fluency. We\npropose TempLM, which achieves the best of\nboth worlds by distilling a PLM into a template-\nbased generator. On the E2E and SynthBio\ndata-to-text datasets, we show that TempLM is\nmore faithful than the original PLM and is more\nfluent than prior template systems. Notably,\non an out-of-domain evaluation, TempLM re-\nduces a finetuned BART model’s unfaithfulness\nrate from 83% to 0%. In a human study, we\nfind that TempLM’s templates substantially im-\nprove upon human-written ones in BERTScore.\n1 Introduction\nPretrained language models (PLMs; Brown et al.,\n2020; Lewis et al., 2020) can generate fluent text\nand are data-efficient when being transferred to\ndownstream tasks (Chen et al., 2020; Schick and\nSchütze, 2021). However, PLMs have been known\nto produce unfaithful outputs (Maynez et al., 2020)\nand inappropriate content (Gehman et al., 2020)\nthat can lead to disastrous outcomes in real-world\ndeployments (Wired, 2021). These errors can be\nworsened when models are queried with out-of-\ndomain (OOD) input. Figure 1 shows that query-\ning a finetuned PLM with a novel entity (e.g. Star-\nbucks) not in the training data can lead to surprising\nfailures even though the PLM achieves high in-\ndomain performance. This poses a great challenge\nin deploying PLMs in real-world applications.\nIn stark contrast, classic template-based sys-\ntems (Reiter and Dale, 1997; Barzilay and Lee,\n2003; Angeli et al., 2010) employ templates con-\nsisting of words and nonterminal fields, which are\nrobust to novel entities by design. Moreover, tem-\nplates are directly readable by humans, and human\nIn domain : PLM generates high-quality output\nname Aromi\nfood Chinese\nnear the Crown Plaza Hotel\narea City Centre\nInput data Output T ext\nAromi  is a Chinese restaurant \nnear the Crown Plaza Hotel \nin the city centre.\nOut of domain : PLM produces unfaithful output\nname Starbucks\nfood Chinese\nnear the Crown Plaza Hotel\nInput data\narea City Centre\nOutput T ext\nThe Chinese restaurant,  \nis located in the city centre.  \nthe Crown Plaza Hotel,  \nFigure 1: A high-performance PLM finetuned on the\nE2E dataset generates unfaithful outputs when given\nout-of-domain inputs. We show later that BART pro-\nduces such errors 83% of the time while TempLM never\nsuffers from such failures.\ninspection can provide direct guarantees of faith-\nfulness. However, templates can be too rigid and\nproduce disfluent text with unexpected inputs. In\nthis work, we seek to borrow the merits of classic\ntemplate-based techniques to improve faithfulness\nand interpretability, while retaining the PLM’s flex-\nibility and data efficiency.\nWe propose TempLM, a novel framework that\ndistills a PLM into a template-based system for\ndata-to-text tasks. At training time, TempLM\nextracts templates that maximally recover the\ninduced probability distribution of the PLM,\nsimilar to model distillation (Hinton et al., 2015).\nAt inference time, TempLM uses the PLM to\nselect appropriate data (content selection) and\ntemplates (surface realization).\nWhile distilling a PLM into a template-based\ngenerator brings benefits, it also raises new chal-\nlenges. Extracting templates that match a PLM’s\nprobability distribution is a challenging combina-\ntorial optimization problem with no clear solution.\nOur approach relies on two new ideas. First, be-\ncause our goal is to recover the PLM’s induced\nprobability distribution, TempLM initializes its\nsearch procedure by delexicalizing PLM’s genera-\n1970\ntion outputs, i.e. abstracting the value in the output\nwith data fields. For example, we can delexicalize\n“Aromi is a Chinese restaurant” into “[name] is a\n[food] restaurant.” Second, TempLM leverages\nthe PLM’s generation ability to refine templates,\nusing a novel consensus beam search algorithm.\nUnlike prior works (Wiseman et al., 2018), our\napproach can leverage any PLM to generate tem-\nplates, allowing us to take advantage of improve-\nments in the data efficiency and fluency of PLMs.\nWe evaluate TempLM on the E2E (Novikova\net al., 2017) and the SynthBio datasets (Yuan et al.,\n2021). We observe that TempLM is the most faith-\nful generation method (with zero faithfulness er-\nrors) on the E2E in-domain test set. Furthermore,\nTempLM fixes the unreliable OOD behavior of\nPLMs, reducing the unfaithful output rate from\n83% to 0%. In addition, we show that TempLM\nachieves higher metric scores than classic text gen-\neration techniques and a previous hybrid neural-\ntemplate method (5 BLEU scores higher than Wise-\nman et al. (2018) even when trained with 42 times\nless data). We further conduct a human study where\nwe ask annotators to write templates for SynthBio\nwith a time constraint. We observe that TempLM\nproduces more fluent templates than both the aver-\nage template writer and an ensemble aggregating\nall the template writers.\n2 Related Works\nPLMs for language generation. PLMs (Radford\net al., 2019; Brown et al., 2020; Lewis et al., 2020)\nare pretrained over large scale text corpora and have\nsignificantly improved generation fluency and data\nefficiency. However, PLMs can still produce un-\nreliable outputs, including hallucination (Maynez\net al., 2020), inconsistency (Elazar et al., 2021),\ntoxicity (Gehman et al., 2020), or privacy viola-\ntions (Carlini et al., 2021). TempLM addresses\nthese shortcomings by distilling a PLM into a less\nexpressive but more trustworthy template-based\nsystem, while retaining fluency and data efficiency.\nClassic template-based methods. Classic tem-\nplate methods often delexicalize the training set\ndata, i.e. they abstract the values in examples\nfrom the training data with the nonterminal data\nfields (Ratnaparkhi, 2002; Oh and Rudnicky, 2000;\nRudnicky et al., 1999; Angeli et al., 2010). For\nexample, “The restaurant name is Aromi” can\nbe delexicalized into “The restaurant name is\n[name].” However, delexicalization can be chal-\nlenging for human-written text. When describing\nthat the customer rating is “3 out of 5,” human writ-\ners may paraphrase it into “3 stars” or “average.”\nDelexicalization has difficulties capturing this para-\nphrasing problem and often leaves lexicalized val-\nues in templates, which makes the templates less\ngeneralizable. In contrast, TempLM first finetunes\na PLM on the data-to-text task and then exploits\nthe PLM’s ability in smoothing the text distribution\nto tackle the paraphrasing problem. This technique\nenables TempLM to generate more fluent outputs\nthan classic template-based systems.\nHybrid neural generation methods. There have\nbeen many works that explore different ways to\nleverage intermediate representations/operations\nto guide neural generation, including designing an\nexplicit planning module (Puduppully et al., 2019),\nediting exemplar training examples (Wiseman\net al., 2021), and inducing latent variables (Wise-\nman et al., 2018; Li and Rush, 2020; Ye et al.,\n2020). Much like classic template-based meth-\nods, these systems attempt to learn structured\nrepresentation from diverse human-written text,\nwhich is challenging and often requires heuristics\nfor additional supervision. We differ from\nprior methods in two important aspects: first,\nTempLM’s templates consist of terminal words\nand nonterminal fields, which make the templates\nrobust and interpretable. Second, TempLM can\nleverage any PLM to generate templates, allowing\nus to take advantage of improved fluency and data\nefficiency brought by PLMs.\n3 TempLM: Template-Based Generators\n3.1 Problem Statement\nWe are interested in data-to-text tasks (Fig-\nure 3), where we are given input data d, con-\nsisting of field and value pairs where a field\nmay correspond to multiple values. For exam-\nple, d could be {name: [Aromi, aromi],\narticle: [a, an]} , where name is a data\nfield corresponding to multiple values “Aromi” and\n“aromi”. Note that we differ from common data-\nto-text setups in allowing multiple data values and\naugmenting d with different capitalization and func-\ntion words to accommodate for template systems.\nOur task is to describe d by some text x gener-\nated by p(x|d). To this end, we want to learn a\nmodel pθ(x|d) using training examples (x, d). In\nthe PLM approach, pθ is implemented by finetun-\ning a PLM on (x, d), using standard log loss.\n1971\nT empLM T emplate Extraction\nname Aromi\nfood Chinese\nrating 3 out of 5\nname\nfood Chinese\nrating 3 out of 5\nname Aromi\nfood Chinese\nrating 3 out of 5,\naverage\nAromi is a Chinese\nRestaurant,  rated as \n3 out of 5.\nTraining Data\n Finetuning PLM\nAromi is a Chinese restaurant\nwith a so-so rating.\n[name] is a Chinese restaurant\nwith a so-so rating.\nAromi is a Chinese restaurant\nwith a so-so rating.\n[name] is a Chinese restaurant\nwith a so-so rating.\nAromi is a Chinese restaurant\nwith a so-so rating.\n[name] [food]  is a restaurant\nwith a  rating.\n \nso-so\nDelexicalizing  \nPLM outputs\n[name] [food]\n[rating]\nprovides food\nwith a rating.   \n[name] [food]  is a  restaurant\nwith a  rating.   so-so\n[name]  provides food from \nwith a  rating.   China so-so\nT emplate V alidation\nvia PLM probabilities\n[name] [food]\n[rating]\n provides  food\nwith a  rating.  \n[name] [food]\n[rating]\nis a  restaurant\nwith a  rating.  \nT emplate Refinement via\nConsensus Beam Search\nSubway Chinese\nhigh\n provides \nfood with a  rating.  \nSubway Chinese\n5 out of 5\n is a  restaurant\nwith a  rating.  \nSurface Realizatio n \n( PLM - based O utput Selection )\nSubway Chinese\nhigh\n provides \nfood with a  rating.  \nSubway Chinese\n5 out of 5\n is a  restaurant\nwith a  rating.  \nContent Selection\n( PLM - based Data Selection )\nname Aromi\nfood Chinese\nrating 3 out of 5\nname Aromi\nfood Chinese\nrating 3 out of 5\nname Subway\nfood Chinese\nrating high , \n5 out of 5\nT esting Data\nPotentia l \nH uman I nspection\nT empLM I n f erence\nE xtracte d \nT emplate Set\nFigure 2: Overview of TempLM. TempLM performs template extraction and inference by treating the finetuned\nPLM as the ground truth optimization target. We want to extract generalizable templates that contain nonterminal\ndata fields and do not contain lexicalized values.\nHelmuth von Schneider\nName Helmuth von Schneider\nBorn 04 June 1931,  Düren,  Germany\nEducation German Literature,  German Language\nBe {is,  are,  was,  were}\n... ...\nBio: Helmuth von Schneider was a German Editor and writer best \nknown for his novel \"Der Heilige Gral\" and \"Reise der Harlekin\". \nBorn on June 4, 1931 in Dür en, Germany to par ents Anna and \nAnton Schneider , Schneider attended the University of Dür en, \nwher e he studied German literatur e and German Language. [...] \nHe died in a car accident on May 13, 1999 in Dür en. Schneider \nwas married to Regina Schneider , and the couple had no childr en.\nFigure 3: Example of the SynthBio data-to-text task.\nWe are given Wikipedia-style datad about a person and\nare tasked with generating the biography x.\nIn template-based generation, we want to obtain\na template set T consisting of templates t and en-\nsure that for new input data d, we can generate a\nhigh-quality output x. We define a template t as a\nsequence of terminal tokens and nonterminal fields\nthat can be replaced by their values in d. For exam-\nple, a template “The restaurant name is [name]”\ncan be filled in as “The restaurant name is Aromi”.\nWe represent the action of filling in a template t\nwith data d as x = F(t, d).\nA set of templates T captures the data distribu-\ntion well if at least one template from t is high-\nquality for every input d. We formalize this goal by\nstating that for a given input d, we are interested in\nmaximizing maxt∈T log p(F(t, d)|d). Because we\nwant templates to be inspectable by humans, we\nwant to limit the size of T by a budget B, |T|≤ B.\nPutting these constraints together, we have the fol-\nlowing optimization problem:\nargmax\nT,|T|≤B\nEd[max\nt∈T\nlog p(F(t, d)|d)]. (1)\nWhat are the implications of Equation (1)? Equa-\ntion (1) suggests that we would prefer generaliz-\nable templates such that a single t can be flexibly\nfilled in so that log p(F(t, d)|d) is high for many\ndifferent d. In practice, this means that our objec-\ntive prefers templates with few or no lexicalized\nvalues. Compare the two templates, “The restau-\nrant name is Aromi” versus “The restaurant name\nis [name]”. Equation (1) would prefer the latter\ntemplate because the first one does not work well\nwhen d describes a different restaurant name.\nAlthough Equation (1) nicely captures our intu-\nition of a generalizable template, it presents several\noptimization challenges. Equation (1) is a size-\nconstrained combinatorial problem that does not\nhave a clear solution. Analyzing the structure of\nEquation (1), we can decompose it into two sep-\narate maximization problems. First, we have the\ntemplate extraction problem of identifying the\nbest template set argmaxT,|T|≤B. Second, given\na template set T, we have the template inference\nproblem of identifying the best template maxt∈T.\nIn the next two sections, we discuss how to leverage\nPLMs to solve these two problems respectively.\n3.2 Template Extraction\nThe inherent challenge of template extraction is\nthat human-written text in the form of x ∼p(x|d)\nmay not follow a template structure. This is espe-\ncially true when humans paraphrase the same data\nvalue differently, but it could also occur as human-\nwritten texts have complex syntactic structures that\nare not covered by templates. This linguistic di-\nversity makes delexicalization, and more generally\nlearning templates from x, extremely challenging.\n1972\nOur objective in Equation (1) addresses this key\nproblem. Maximizing log p(F(t, d)|d) is equiva-\nlent to asking for a template t to match at least\none high probability sequence under p, rather than\nmatching all high probability sequences, as is typi-\ncal in delexicalization or latent-variable based tem-\nplate models. While this approach resolves the\nparaphrasing problem, it relies upon the true data-\ngenerating probability p(F(t, d)|d) which we can-\nnot evaluate. Therefore, we propose to approximate\np with a PLM pθ. This amounts to treating pθ as the\nground truth optimization target, similar to model\ndistillation (Hinton et al., 2015).\nWhile targeting pθ makes the optimization prob-\nlem easier, Equation (1) is still intractable because\nof its difficult combinatorial structure. We design\na series of approximations to circumvent the opti-\nmization difficulty (Figure 2).\nClustering. Suppose we can obtain the optimal\ntemplate set T∗= {t∗\n1, . . . , t∗\ni, . . . , t∗\nB}. Then we\ncan identify a cluster functionC∗where C∗(d) = i\nreturns the index of the optimal template t∗\ni for ex-\nample d. With C∗, we can decompose Equation (1)\ninto B subproblems that are easier to solve,\nargmax\nti\nE\nds.t. C∗(d)=i\n[log pθ(F(ti, d)|d)]. (2)\nWhile obtaining C∗is impossible, we can design\napproximate clusters C based on the presence of\ndifferent fields, as is standard in other data-to-text\nmethods (Wiseman et al., 2021).\nDelexicalizing PLM outputs. Equipped with ap-\nproximate clusters C, how can we find templates\nthat work for all examples in the same cluster?\nBecause we are optimizing for pθ, one natural start-\ning point is to delexicalize the model beam search\noutput xθ. We denote tdelex\nθ (d) as the template\nwe obtain from delexicalizing the PLM output xθ\nof the input d and denote Tdelex\nθ (d) as the corre-\nsponding template set.\nDelexicalizing xθ also allows us to be more\ndata efficient and robust. This is because obtain-\ning Tdelex\nθ (d) only requires unlabeled inputs d as\nopposed to requiring full supervision (x, d). Ob-\ntaining unlabeled data for out-of-domain inputs is\nsubstantially easier, and this allows us to exploit\ndata beyond the training set. In practice, we per-\nform data recombination (Jia and Liang, 2016) to\nnot only increase the quantity of d but also explore\nmore field and value compositions.\nTemplate validation via PLM probabilities.\nWhile Tdelex\nθ (d) provides a good initial template\nAlgorithm 1 Consensus Beam Search\nk: beam size, M: maximum length\nV: terminal tokens, VT: nonterminal fields\nN: number of inputs\nt′: partial template where ungeneralizable spans are removed\nx′\ni: F(t′, di) , di: ith input data\ndi.get(·): return the best value token for a field token\n1: B0 ←{⟨0, BOS ⟩}\n2: for t ∈{1, . . . , M−1}do\n3: H ←∅\n4: for ⟨s, y⟩∈ Bt−1 do # Expansion.\n5: for y ∈V◦V T do\n6: S ←∅\n7: for i ∈{1, . . . , N−1}do\n8: if y ∈V then\n9: S.add(log pθ(y ◦y|x′\ni, di))\n10: else # Field token substitution.\n11: S.add(log pθ(y ◦di.get(y)|x′\ni, di))\n12: end if\n13: end for\n14: s ←S.avg() # Aggregation.\n15: H.add(⟨s, y ◦y⟩)\n16: end for\n17: end for\n18: Bt ←H.topk(k)\n19: end for\n20: return Bt.max()\nAlgorithm 1 : We search for a common constituent y\nthat can be infilled to all partial descriptions x′\ni. In\ncontrast to conventional beam search, we aggregate the\nlog probability scores across different inputs at each\nstep (Line 6 to Line 14). To generate nonterminal fields\n(e.g. [name]), we account for how they will be filled\nin with different input d′\ni in Line 11.\nset, some of these templates may contain a substan-\ntial number of lexicalized data values. To remove\nthese less generalizable templates and fulfill the\ntemplate budget constraint B, we want to filter the\ntemplate set Tdelex\nθ (d). We leverage the PLM’s\nprobability estimates to evaluate the template gen-\neralizability, defined as a template’s average log\nprobability over the entire cluster. For a template\ngenerated by delexicalizing d, this objective can be\nwritten as\n∑\nd′s.t. C(d′)=C(d)\nlog pθ(F(tdelex\nθ (d), d′)|d′). (3)\nwhere d′are examples sampled from the same data\ncluster, C(d′) = C(d). Equation (3) assigns a\nscalar value to each tdelex\nθ (d) that we use to filter\nout any ungeneralizable templates. In practice, we\nretain the top-K best templates in each cluster to\nform the template set.\nTemplate Refinement via Consensus Beam\nSearch. If a template contains only a few lexi-\ncalized values, we can further identify these spans\n1973\nusing a token-level version of Equation (3) and\nthen replace ungeneralizable spans by executing a\nsearch algorithm with Equation (3) as the objective.\nTo identify the ungeneralizable spans, we begin\nby evaluating the token-level equivalent to Equa-\ntion (3) (see Appendix A.1 for details). We then ag-\ngregate these token-level scores into a constituent-\nlevel score using a constituency parser, and mark\nany constituent whose score is lower than a thresh-\nold as ungeneralizable.\nTo salvage these ungeneralizable spans, we lever-\nage a PLM to optimize for Equation (3) directly.\nWe remove the ungeneralizable spans to form\npartial template x′ and learn an infilling model\npinfill\nθ (x|x′, d) to replace the ungeneralizable spans.\nWe implement pinfill\nθ by finetuning a different PLM\nand present the details in Appendix B.3.\nThere are two challenges we face in optimiz-\ning Equation (3). First, the infilling model pinfill\nθ\nis learned to generate text, not templates. Second,\nEquation (3) is an unusual objective in text genera-\ntion that is a mixture-of-experts of many language\nmodels where each model conditions on some input\nd′. We propose two modifications to the standard\nbeam search algorithm to address these challenges\n(Algorithm 1). First, we empower the infilling\nmodel pinfill\nθ with the ability to generate nontermi-\nnal data fields and define their scores based on how\nthey will be filled in (Line 11). Second, we search\nfor a common output that is the “consensus” of\nmany inputs d′by aggregating the log probability\nscores across inputs at each decoding step (Line 6\nto Line 14). Empirically, we find that template re-\nfinement can correct for errors in the earlier steps\nby removing lexicalized values or incorrect fields\nin the template. We present a qualitative study of\ntemplate refinement in Appendix B.3.\nHuman Inspection and Validation. Once tem-\nplates are refined, we save them as an internal\npart of TempLM and use them for template in-\nference at test time. To obtain an even stronger\nfaithfulness guarantee, we can have human inspec-\ntors validate each template. TempLM offers two\nadvantages for such human-in-the-loop inspection.\nFirst, templates in TempLM are readable by hu-\nmans. Second, TempLM by design has limited\nfreedom during inference: an output can only be\ngenerated from filling in a template with input data.\nAs long as none of the templates contains hallucina-\ntion or inconsistency, TempLM will be guaranteed\nto return a faithful output. The combination of in-\nterpretability and restricted output space enables\na natural interface for human-in-the-loop cooper-\nation, where a human inspector can sanitize all\nthe templates before deploying TempLM into real-\nworld applications.\n3.3 TempLM Template Inference\nGiven the template set T that we extracted, we now\nneed to solve the problem of identifying the best\ntemplate maxt∈T for a new input d. In TempLM,\nwe leverage PLMs as a core primitive in both the\ncontent selection and surface realization steps.\nContent Selection requires us to substitute a\nnonterminal field with the most appropriate value\namong the multiple values that a field corresponds\nto. We perform this step using a left-to-right auto-\nregressive PLM. At each decoding step, we directly\ncopy from t when encountering a terminal word;\notherwise, we select the most probable data value\nto replace a field. PLMs are typically trained with\nbyte-pair encoding (Sennrich et al., 2016), which\nmight break up data values into multiple tokens.\nPerforming an exact search involves computing the\nprobability of each multi-token value by additional\nroll-outs, which slows down inference. We circum-\nvent this problem by performing a greedy search\non the first token, which leads to faster or on-par\ninference time with standard PLM inference.\nSurface Realization requires us to select the\nmost appropriate output after templates are filled\nin. We perform this step by computing F(t, d) for\nall templates in the same clusterC(d) and returning\nthe one with the highest pθ(F(t, d)|d).\n4 Experiments\nWe evaluate TempLM’s ability to generate faith-\nful and fluent text in three settings: an in-domain\nevaluation on standard data-to-text benchmarks, an\nout-of-domain evaluation that stress tests the ability\nto generalize to novel inputs, and a human study\ncomparing TempLM’s template extraction ability\nto that of human template writers.\n4.1 Experiment Setup\nDatasets. We consider two data-to-text datasets:\nE2E (Novikova et al., 2017) and SynthBio (Yuan\net al., 2021). The E2E dataset contains data entries\nabout restaurants and asks for text descriptions of\nrestaurant data. Originally, the E2E dataset con-\ntained 42K training samples with eight distinct\nfields and 109 field combinations. To better evalu-\n1974\nate data efficiency and faithfulness, we downsam-\nple the training set to ten samples per field combi-\nnation. Results on the full E2E dataset are similar\nand are shown in Appendix B.3. We evaluate on\nthe official validation and test sets.\nSynthBio asks systems to write biographies\nbased on Wikipedia-style data tables and was origi-\nnally proposed as an evaluation set for WikiBio (Le-\nbret et al., 2016). Because WikiBio is a noisy\ndataset created by automatic retrieval and contains\npervasive hallucinations, we decided to use Synth-\nBio instead, by splitting it into training, validation,\nand test sets, and evaluate on the test set. We sum-\nmarize the dataset statistics in Table 5.\nEvaluation Metrics. We evaluate the fluency of\nthe generated outputs by reference-based evalu-\nation. For E2E, we use the official toolkit and\nevaluate in terms of BLEU (Papineni et al., 2002),\nNIST (Belz and Reiter, 2006), ROUGE-L (Lin\nand Rey, 2004), CIDEr (Vedantam et al., 2015),\nand METEOR (Banerjee and Lavie, 2005). For\nSynthBio, we evaluate by BLEU, ROUGE-L, and\nBERTScore (Zhang et al., 2020).\nOn the E2E dataset, we also evaluate the faith-\nfulness of a system output. We define an output\ndescription to be faithful if it does not contradict the\ninput data or hallucinate information not present in\nthe input. To automatically evaluate this, we man-\nually inspected system output descriptions in the\nvalidation set and collected common paraphrases\nof each possible data value. For example, a cus-\ntomer rating of “3 out of 5”, may appear as “3\nstars”, “average”, etc. This allows us to develop a\nmatching-based metric: we count precision error\nEprecision when a piece of system output contains\nany paraphrase that matches with a value not in the\ninput (hallucination) or a value different from the\none provided in the input (inconsistency).\nNote that Eprecision is a conservative metric.\nWhen we encounter novel phrasings that do not\nmatch any entry in our phrasing collection, we\ndo not count them toward Eprecision. We present\nmore implementation details in Appendix B.2. For\ntemplate-based methods, we reuse the same rou-\ntine to measure the percentage of templates that\ncontain lexicalized values (%. Lex. Temp), which\nmeasures the generalizability of the templates. We\ncalculate an analogous recall-oriented metricErecall\nand provide the results in Appendix B.3. We fo-\ncus on Eprecision instead of Erecall, as E2E does not\nrequire systems to verbalize every value in d.\nImplementing TempLM. We implement pθ(x|d)\nand the infilling model pθ(x|x′, d) by finetuning\nBARTBASE (Lewis et al., 2020). On E2E, we assign\ntraining samples that have the same combination\nof fields into the same cluster, which results in\n109 clusters. We use data recombination (Jia and\nLiang, 2016) to combinatorially create 50 samples\nfor each cluster and thereby increase the training\ndata size by five times for template extraction. We\ndefine the target number of templates per cluster\nfor TempLM to be five, which results in around\n500 templates after deduplication. On SynthBio,\nwe cluster data by the “occupation” field, which\nresults in eight clusters, and we set the TempLM’s\nbudget to be ten templates per cluster. We do not\nperform any data augmentation for SynthBio. More\ntraining details are described in Appendix B.2.\nBaselines. We compare to three classes of\nbaselines. To compare to existing PLMs, we\nevaluate a finetuned BARTBASE model and a\nKGPT model (Chen et al., 2020), which improves\na LM by knowledge-grounded pretraining.\nFor classic template systems that delexicalize\ntraining samples, we compare to TempClassic,\nwhich delexicalizes the training data but uses our\nPLM based inference procedure. We also compare\nto the SUB baseline (Wiseman et al., 2018), which\nreplaces the PLMs based inference in TempClassic\nwith a rule-based procedure.\nFor recent hybrid neural-template methods, we\ncompare to the NTemp method (Wiseman et al.,\n2018). As we were unable to obtain good perfor-\nmance by NTemp on the downsampled training\nset, we evaluate the model trained on the full E2E\ntraining set.\nFinally, we performed ablation studies by re-\nmoving the template refinement ( - Refinement)\nand template validation (- Validation) components\nfrom TempLM.\n4.2 In-domain Experiment\nTable 1 shows that on E2E and SynthBio,TempLM\nis more faithful than BART while achieving higher\nmetric scores than other template-based methods.1\nTempLM is faithful. TempLM is the only method\nthat achieves zero Eprecision across validation and\ntest sets. This improvement over BART suggests\nTempLM’s usefulness in practice. For real-world\ndeployments, we can further leverage human in-\n1We present other metric scores and validation set results\nin Appendix B.3.\n1975\nEprecision ↓ BLEU↑ ROUGE-L↑\nBART 6.0 ±2.9 66.2 ±0.5 68.4 ±0.7\nTempLM 0.0 ±0.0 61 .5 ±1.0 64 .5 ±0.8\nKGPT 8 58.41 63.93\nNeighbor Splicing∗ 543 24.12 37.46\nNTemp† 7 55 .17 65 .70\nTempClassic 46.7 ±25.4 52 .1 ±2.0 62 .2 ±2.3\nSUB 110.7 ±36.2 45 .3 ±1.9 55 .6 ±2.4\nBLEU↑ BERTScore F1↑\nBART 40.8 ±0.2 55.2 ±0.1\nTempLM 40.3 ±0.3 54 .3 ±0.1\nTempClassic 36.6 ±0.2 48 .8 ±0.1\nSUB 14.1 ±0.1 18 .9 ±0.1\nTable 1: Automatic metrics averaged over three random seeds on the E2E and SynthBio test sets. We bold the best\nnumbers in each column and show standard errors with error bars. First, TempLM produces zero unfaithful outputs\non E2E. Second, TempLM achieves better or on-par performance on reference-based evaluation than other template\nsystems. ∗:We find the specialized training procedure of Wiseman et al. (2021) cannot do well on the subsampled\nE2E training set. †:We compare to a model trained on the full E2E training set, which was released by Wiseman\net al. (2018). We were unable to train NTemp models on the subsampled E2E dataset to convergence.\nE2E SynthBio\nEprecision ↓ %. Lex. Temp ↓ BLEU↑ #. Temp ↓ BLEU↑ #. Temp ↓\nTempLM 0.0 ±0.0 5.2 ±1.2 61 .5 ±1.0 471.7 ±62.9 40.3 ±0.3 80\n- Refinement 0.0 ±0.0 12 .1 ±1.3 61 .4 ±0.9 534 .3 ±8.5 35 .2 ±0.9 80\n- Validation 2.7 ±2.2 21 .4 ±2.6 64.0 ±1.0 2047 .3 ±43.7 36 .4 ±0.1 1511\nTempClassic 46.7 ±25.4 37 .4 ±0.5 52 .1 ±2.0 978 .3 ±1.2 36 .6 ±0.2 1511\nTable 2: Ablation results averaged over three random seeds on different template-based systems. We bold the best\nnumbers in each column and show standard errors with error bars. TempLM extracts most generalizable templates\nand achieves good performance with a small number of templates.\nspection to sanitize TempLM’s template set, which\nallows us to remove any lexicalized values in\nthe templates and obtain a strict guarantee for\nTempLM’s faithfulness. In contrast, TempClassic\nproduces almost eight times more precision errors\nthan BART (46 vs. 6), which shows the difficulty\nof inducing templates over human-written text.\nTempLM is fluent and data-efficient. We ob-\nserve that on E2E, TempLM achieves higher met-\nric scores than other baselines except BART, and\non SynthBio, TempLM even performs similarly to\nBART despite using the less expressive template\nrepresentation. This demonstrates that TempLM\nachieves better fluency than previous template\nmethods and is competitive with neural methods.\nIn addition, TempLM retains the data efficiency\nof PLMs. In particular, TempLM achieves a sig-\nnificant 5 BLEU score improvement over NTemp,\nwhich is trained with much more data ( 1090 vs.\n42K training samples). In contrast, the state-of-\nthe-art method Neighbor Splicing cannot do well\nwhen trained with only 1090 data points.\nTempLM enables trade-offs between fluency,\nrobustness, and interpretability. We designed\nTempLM to have a small number of templates to\nmake TempLM more conducive to human inspec-\ntion. TempLM successfully achieves this, using\nless than 500 templates for E2E and only 80 tem-\nplates for SynthBio. Comparing TempLM without\nRefinement and TempLM without Validation, we\nfind that template validation reduces the number\nof templates and substantially increases reliabil-\nity (halving the percentage of templates containing\nlexicalized values), but may incur a minor perfor-\nmance drop in fluency.\nWe find that the template structure is simpler on\nE2E, and refinement does not add substantial ben-\nefit. However, on Synthbio refinement is critical\nto reversing the performance drop and results in\na 4 BLEU score gain. Upon inspection, we find\nthat template refinement can accurately remove un-\ngeneralizable spans in the longer and more compli-\ncated templates, which is necessary for SynthBio.\nOverall, we find that TempLM ensures faith-\nfulness, retains the PLM’s fluency and data effi-\nciency, and balances between performance and in-\nterpretability. In the following sections, we go\nbeyond automatic in-domain evaluation. We first\nstress test systems with out-of-domain inputs and\nperform a human study to showcase the difficulty\nof template extraction.\n4.3 Out-of-domain Experiment\nModels deployed in real-world applications need\nto be robust to test distributions different from the\ntraining distribution. To test for out-of-domain\n1976\nUnfaithful Output Rate (%)\nBART 83.3\nKGPT 16.6\nNeighbor Splicing 100\nTempLM 0\nTable 3: Human annotated unfaithful output rates in\nout-of-domain (OOD) evaluation. We observe outputs\nfrom other systems exhibit pervasive unfaithful errors\nwhereas TempLM continues to remain faithful.\nBERTScore F1\nCluster\nWriter\nHuman 51.3 ±2.3\nEnsemble\nHuman 54.0\nBART 58.5 ±0.2\nTempLM 58.8 ±1.0\nCluster\nSpy\nHuman 42.2 ±4.4\nEnsemble\nHuman 48.5\nBART 55.3 ±0.1\nTempLM 50.8 ±0.9\nTable 4: Human study results on two clusters of the Syn-\nthBio test set. Human-written templates result in low\nmetric scores even in the ensemble setting, showcasing\nthe difficulty of identifying distributional characteristics\nfor human and the efficacy of TempLM.\n(OOD) generalization, we simulate such a setting\non E2E by testing models with entities that are not\nseen during training.\nWe create our OOD evaluation by tak-\ning fields in E2E (area, eatType, food,\nname, near) and filling in common enti-\nties scraped from the internet to create 54\nnovel examples. For instance, we create exam-\nples like {area: Central Park, name:\nMcDonald’s, ...}. We inspect the system\noutputs manually to check the correctness and\npresent the results in Table 3. We observe that\noutputs from other systems produce are frequently\nunfaithful, often confusing entities from different\ntypes. In the previous example, BART mistakenly\noutputs “Central park is a restaurant ...”, confusing\narea with name. In contrast, TempLM is robust\nto novel inputs and does not produce any unfaith-\nful outputs. We provide the list of novel entities\nused in creating OOD input and more qualitative\nexamples in Appendix B.4.\n4.4 Human Study\nTo demonstrate the difficulty of generating tem-\nplates, we conduct a human study on two clusters\nof the SynthBio dataset. We recruited ten volun-\nteers from our institution to be our template writers\nand assigned five writers to work on each cluster.\nEach template writer was given thirty minutes to\nwrite templates, and they wrote eleven templates\non average. We presented them the same data that\nTempLM operated on: roughly 200 training ex-\namples per cluster, including the input data d and\nassociated text x. We include our human study\ninstruction and interface in Appendix B.5.\nTo evaluate human performance, we used the\nhuman-written templates in our LM-based in-\nference pipeline and measured automatic metric\nscores. Table 4 shows the BERTScore F1 for both\nthe average template writer as well as an ensemble\nof five template writers. We report other metric\nscores in Appendix B.5. We observe that the tem-\nplates extracted by TempLM lead to better perfor-\nmance than the human-written ones, indicating the\nintrinsic difficulty of template writing. Based on\nobserving template writers during the writing pro-\ncess, we found that a common strategy is to first go\nthrough a subset of the training examples and then\nfind canonical examples to delexicalize. However,\nwe identified a few shortcomings. First, our writers\ntypically only read a few examples (approximately\n5 to 20) before they exhaust their cognitive load.\nAs a result, some writers fail to write templates\nthat capture the less common examples. Second,\nour volunteers may fail to pick the more canoni-\ncal examples and choose to delexicalize examples\nthat are not the most generalizable. Although well-\ntrained template writers with domain knowledge\nmight have written better templates, the difficulty\nin identifying such distributional characteristics re-\nmains true for any sizable data.\n5 Conclusion and Future Work\nWe propose TempLM, a novel framework for\ndistilling PLMs into template-based systems.\nTempLM is designed to achieve better robustness\nand interpretability while inheriting the fluency and\ndata efficiency of PLMs. Our evaluations show that\nTempLM can completely eliminate the unfaithful\noutputs produced by a finetuned BART model for\nout-of-domain inputs. On in-domain evaluation,\nTempLM is able to produce more fluent outputs\ncompared to classic template systems, prior neural-\nhybrid template methods, and even human template\nwriters. In the future, we look forward to extend-\ning the TempLM framework to learn compositional\ntemplates and grammars, as well as improving its\ncoverage to diverse outputs, potentially via para-\nphrases of its input data.\n1977\nLimitations\nOur system distills PLMs into a less expressive but\ntrustworthy set of templates. In developing this\nmethod, we explicitly trade off linguistic diversity\nfor faithfulness guarantees. While this approach\nworks well on academic benchmarks, in more com-\nplicated real world settings sacrificing linguistic\ndiversity may impact different groups to a different\nextent. This raises the question of fairness and we\nhope to investigate such problems on more realistic\ndatasets in future work.\nReferences\nGabor Angeli, Percy Liang, and Dan Klein. 2010. A\nsimple domain-independent probabilistic approach to\ngeneration. In Proceedings of the 2010 Conference\non Empirical Methods in Natural Language Process-\ning, pages 502–512, Cambridge, MA. Association\nfor Computational Linguistics.\nS. Banerjee and A. Lavie. 2005. METEOR: An auto-\nmatic metric for mt evaluation with improved cor-\nrelation with human judgments. In Association for\nComputational Linguistics (ACL).\nRegina Barzilay and Lillian Lee. 2003. Learning to para-\nphrase: An unsupervised approach using multiple-\nsequence alignment. In Proceedings of the 2003 Hu-\nman Language Technology Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics, pages 16–23.\nAnja Belz and Ehud Reiter. 2006. Comparing automatic\nand human evaluation of NLG systems. In 11th Con-\nference of the European Chapter of the Association\nfor Computational Linguistics.\nT. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan,\nP. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry,\nA. Askell, S. Agarwal, A. Herbert-V oss, G. Krueger,\nT. Henighan, R. Child, A. Ramesh, D. M. Ziegler,\nJ. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler,\nM. Litwin, S. Gray, B. Chess, J. Clark, C. Berner,\nS. McCandlish, A. Radford, I. Sutskever, and\nD. Amodei. 2020. Language models are few-shot\nlearners. arXiv preprint arXiv:2005.14165.\nNicholas Carlini, Florian Tramèr, Eric Wallace,\nMatthew Jagielski, Ariel Herbert-V oss, Katherine\nLee, Adam Roberts, Tom Brown, Dawn Song, Úlfar\nErlingsson, Alina Oprea, and Colin Raffel. 2021. Ex-\ntracting training data from large language models. In\n30th USENIX Security Symposium (USENIX Security\n21), pages 2633–2650.\nWenhu Chen, Yu Su, Xifeng Yan, and William Yang\nWang. 2020. KGPT: Knowledge-grounded pre-\ntraining for data-to-text generation. In Proceed-\nings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , pages\n8635–8648. Association for Computational Linguis-\ntics (ACL).\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Abhi-\nlasha Ravichander, Eduard Hovy, Hinrich Schütze,\nand Yoav Goldberg. 2021. Measuring and improving\nconsistency in pretrained language models. Transac-\ntions of the Association for Computational Linguis-\ntics, 9:1012–1031.\nSamuel Gehman, Suchin Gururangan, Maarten Sap,\nYejin Choi, and Noah A. Smith. 2020. RealToxi-\ncityPrompts: Evaluating neural toxic degeneration in\nlanguage models. pages 3356–3369.\nGeoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean.\n2015. Distilling the knowledge in a neural network.\nArXiv, abs/1503.02531.\nRobin Jia and Percy Liang. 2016. Data recombina-\ntion for neural semantic parsing. In Association for\nComputational Linguistics (ACL), pages 12–22. As-\nsociation for Computational Linguistics.\nNikita Kitaev and Dan Klein. 2018. Constituency pars-\ning with a self-attentive encoder. In Association for\nComputational Linguistics (ACL), pages 2676–2686.\nRémi Lebret, David Grangier, and Michael Auli. 2016.\nNeural text generation from structured data with ap-\nplication to the biography domain. In Proceedings\nof the 2016 Conference on Empirical Methods in\nNatural Language Processing, pages 1203–1213.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020. Bart:\nDenoising sequence-to-sequence pre-training for nat-\nural language generation, translation, and comprehen-\nsion. In Association for Computational Linguistics\n(ACL).\nXiang Lisa Li and Alexander Rush. 2020. Posterior\ncontrol of blackbox generation. In Association for\nComputational Linguistics (ACL), pages 2731–2743.\nC. Lin and M. Rey. 2004. Looking for a few good\nmetrics: ROUGE and its evaluation. In NTCIR Work-\nshop.\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and\nRyan McDonald. 2020. On faithfulness and factual-\nity in abstractive summarization. In Association for\nComputational Linguistics (ACL), pages 1906–1919.\nJekaterina Novikova, Ondˇrej Dušek, and Verena Rieser.\n2017. The E2E dataset: New challenges for end-to-\nend generation. In Special Interest Group on Dis-\ncourse and Dialogue (SIGDIAL), pages 201–206.\nAlice H. Oh and Alexander I. Rudnicky. 2000. Stochas-\ntic language generation for spoken dialogue systems.\nIn ANLP-NAACL 2000 Workshop: Conversational\nSystems.\n1978\nK. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.\nBLEU: A method for automatic evaluation of ma-\nchine translation. In Association for Computational\nLinguistics (ACL).\nRatish Puduppully, Li Dong, and Mirella Lapata. 2019.\nData-to-text generation with content selection and\nplanning. AAAI Conference on Artificial Intelligence.\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and\nI. Sutskever. 2019. Language models are unsuper-\nvised multitask learners. OpenAI Blog, 1(8).\nA. Ratnaparkhi. 2002. Trainable approaches to surface\nnatural language generation and their application to\nconversational dialog systems. Computer Speech &\nLanguage., 16:435–455.\nEhud Reiter and Robert Dale. 1997. Building applied\nnatural language generation systems. Natural Lan-\nguage Engineering, page 57–87.\nAlexander I. Rudnicky, Eric H. Thayer, Paul C. Constan-\ntinides, Chris Tchou, Rande Shern, Kevin A. Lenzo,\nW. Xu, and Alice H. Oh. 1999. Creating natural di-\nalogs in the carnegie mellon communicator system.\nIn EUROSPEECH.\nTimo Schick and Hinrich Schütze. 2021. Few-shot text\ngeneration with natural language instructions. In\nEmpirical Methods in Natural Language Processing.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Neural machine translation of rare words with\nsubword units. In Association for Computational\nLinguistics (ACL), pages 1715–1725.\nR. Vedantam, C. L. Zitnick, and D. Parikh. 2015. CIDEr:\nConsensus-based image description evaluation. In\nComputer Vision and Pattern Recognition (CVPR),\npages 4566–4575.\nWired. 2021. It began as an ai-fueled dungeon game.\nit got much darker. Https://www.wired.com/story/ai-\nfueled-dungeon-game-got-much-darker/.\nSam Wiseman, Arturs Backurs, and Karl Stratos. 2021.\nData-to-text generation by splicing together nearest\nneighbors. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 4283–4299.\nSam Wiseman, Stuart Shieber, and Alexander Rush.\n2018. Learning neural templates for text generation.\nIn Proceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n3174–3187, Brussels, Belgium. Association for Com-\nputational Linguistics.\nRong Ye, Wenxian Shi, Hao Zhou, Zhongyu Wei, and\nLei Li. 2020. Variational template machine for data-\nto-text generation. In International Conference on\nLearning Representations.\nAnn Yuan, Daphne Ippolito, Vitaly Nikolaev, Chris\nCallison-Burch, Andy Coenen, and Sebastian\nGehrmann. 2021. Synthbio: A case study in faster\ncuration of text datasets. In Thirty-fifth Conference\non Neural Information Processing Systems Datasets\nand Benchmarks Track (Round 2).\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Eval-\nuating text generation with bert. In International\nConference on Learning Representations.\n1979\nA Additional Details on Template Refinement\nA.1 Token-level Generalizability Measure\nOur goal is to identify a set of generalizable templates given a budgetB such that a single t can be flexibly\nfilled in so that log pθ(F(t, d)|d) is high for many different examples d. Equation (3) does this exactly:\nwe fill in a single template t with many other examples d from the same cluster and measure the sum\nof their log probabilities. We want to generalize Equation (3) to a token-level generalizability measure,\nwhich tells us which tokens within a template t will receive a high probability after the template is filled\nin with new data. Our idea is to align tokens in the template with tokens in the output and aggregate the\ncorresponding token probabilities across many different outputs.\nLet us use j as the token index and denote xj as the jth token in an output text x and tj as the jth token\nin a template t. We use x:j to represent the prefix up to the jth token in x and analogously defined t:j.\nWe leverage an alignment function A(t, d, j), where F(t, d)A(t,d,j) gives the token that corresponds to tj\nafter t is filled in. The alignment A handles the discrepancy in length that is caused by the template fill-in\nprocess because the fill-in function F substitutes nonterminal fields with various length data given in d.\nWith the help of A, we can define the token-level generalizability for a token tj as,\nΣ\nd′s.t. C(d′)=C(d)\n[log pθ(F(tdelex\nθ (d)A(t,d,j), d′)|F(tdelex, d′)θ(d):A(t,d,j)]. (4)\nEquation (4) provides a token-level measure, which we can easily turn into a span-level measure\nby calculating the joint token-level probability. We use this idea to calculate the generalizability of\nnonterminal fields that correspond to values of multiple tokens. Equation (4) gives us an useful tool for\ntelling which tokens are ungeneralizable and we can then leverage the generation ability to replace these\ntokens by directly optimizing Equation (4).\nNow that we formalize token-level generalizability with Equation (4), our plan is to iteratively remove\nungeneralizable spans and use an infilling model to generate new template spans. We can decompose this\nprocedure into two subproblems: removing ungeneralizable spans and generating new template spans. We\ndiscuss them in the next two sections, respectively.\nA.2 Removing Ungeneralizable Spans\nThe key problem we want to solve in span removal is to group multiple ungeneralizable tokens together\nand remove them at the same time. This is because if we remove ungeneralizable tokens one at a time, we\nwould still condition on other ungeneralizable tokens, which deteriorates performance in practice. We\nleverage constituency parsing (Kitaev and Klein, 2018) to solve this problem. For each constituent in the\nparse tree, we calculate Equation (4) for each token in the constituent and compute the average. We set a\nthreshold and remove all constituents whose generalizability measure is worse than this threshold.\nA.3 Generating Template with Consensus Beam Search\nWe refer to Section 3.2 for the description of our template generation process. In Algorithm 1, we rely\non the subroutine di.get(·), which gives us the best data value among the multiple options in d for a\nnonterminal field. Implementing this subroutine exactly requires us to evaluate all data values at each\ndecoding step, which is computationally expensive. In practice, we perform a greedy selection based on\nthe first token in each data value.\nB Additional Details on Experiments\nB.1 Dataset Details\nWe include the dataset statistics of SynthBio and subsampled E2E datasets in Table 5.\nB.2 Model Training Details\nLeft-to-right Autoregressive LM. We finetune a BARTBASE model to implement pθ(x|d). On the\ndownsampled E2E dataset, we train for 10 epochs for a batch size of 16 and a learning rate of 3 ×10−5.\n1980\n# Train Average Length # Fields\nE2E 1090 19 .8 8\nSynthBio 2896 93 .1 78\nTable 5: Statistics of SynthBio and the downsampled E2E dataset.\nData Field Data Value\narticle a, an\nbe is, are, was, were\nnumber six, seven, eight, nine, ten\none, two, three, four, five,\npronoun_a he, she, they\npronounce_b him, her, them\npronounce_c his, her, their\nrelation son, daughter\nTable 6: Data fields and values we used for augmenting SynthBio input.\nWe train with half precision using the huggingface implementation. On SynthBio, we train for 5 epochs\nfor a batch size of 8 and a learning rate of 3 ×10−5. We train with half precision using the huggingface\nimplementation.\nInfilling LM. We train our infilling models by masking a random 0 to 10 word span and predicting the\nmasked out span. We finetune a BARTBASE model to implement pθ(x|x′, d). On the downsampled E2E\ndataset, we train for 50 epochs for a batch size of 16 and a learning rate of 3 ×10−5. We train with half\nprecision using the huggingface implementation. On SynthBio, we train for 20 epochs for a batch size of\n16 and a learning rate of 3 ×10−5. We train with half precision using the huggingface implementation.\nTempLM. On E2E, we cluster based on field combination. In total, we have 109 clusters and in\neach cluster, we have 10 training samples. We perform data recombination to create 50 examples for\neach cluster. Our template validation selects the top 5 templates and performs template refinement on\nthese templates. Our template refinement process uses −2 log probability as a threshold for removing\nungeneralizable spans.\nB.3 In-domain Evaluation\nAdditional Details for Experiment Setup. On E2E, the familyFriendly field is a binary field\nwith values being either “yes” or “no”. To accommodate template-based generation, we replace “yes”\nwith “family friendly” and “family-friendly” and replace “no” with “not family friendly” and “not\nfamily-friendly”. We augment E2E input d with article words [article: [a, an]] .\nOn SynthBio, we augment inputs with values listed in Table 6. For article, be, and number, we\ninclude them as multiple value options in the input. For pronouns and relations, we assign the correct\nvalue based on the gender field in the input. We parse all dates into day, month, and year and create\nseparate fields to support different data formats in the templates.\nImplementation of Faithfulness Evaluation. We present the phrasing collection we used for matching\noutput in Table 7 and Table 8. We use this phrasing collection to perform a matching based faithfulness\nevaluation. We consider a phrase in an output to have a precision error if it matches with a field and\nvalue pair that is not present in the input data. We consider an output as having recall errorErecall if we\ncannot identify any phrase in the output that corresponds to some field and value pair in the input data\n1981\nM or e G ener alizable L es s G ener alizable\nFigure 4: A qualitative example of the TempLM refinement process. We color a terminal word or a nonterminal\nfield as more red if it is less generalizable, measured by the token-level generalizability (Appendix A.1). We mark\nthe refinements TempLM by arrows, coloring the refinement outcome in green.\nBecause our phrasing collection is imperfect and alternative phrasing may exist, we expect Eprecision to be\nan underestimate and Erecall to be an overestimate of actual errors.\nAdditional Results for Section 4.2. We present a full set of metrics scores for subsampled E2E and\nSynthBio in Table 9 and Table 10. We make similar observations as in Section 4.2: first,TempLM is the\nmost faithful system on E2E, never producing any precision error; second, TempLM is more fluent than\nother template systems, achieves better scores with the most of the metrics (BLEU, NIST, CIDEr), and\non-par scores with METEOR and ROUGE-L.\nWe carry out the same experiment on E2E with models trained on the full dataset and present the results\nin Table 11. We observe that similar to TempLM is the only model that never produces unfaithful on both\nthe test set and the validation set. BART becomes more faithful with more training data. Similar to the\nexperiments on the subsampled training set, TempLM achieves better fluency than NTemp and SUB. One\ndifferent observation from Table 11 is that TempClassic achieves much better fluency and faithfulness.\nThis is because by leveraging the full training data, TempClassic obtains a large number of templates\n(39964). While using a large number of templates is helpful, it makes PLM-based inference infeasibly\nslow, requiring hours of computation to perform inference on the test and validation sets. Having many\ntemplates also makes the template set less interpretable by human inspectors. Therefore, we consider\nTempClassic an impractical baseline.\nQualitative Examples of Template Refinement. To better explain the inner workings of TempLM, we\nvisualize one example of refinement in Figure 4. We color each word according to its generalizability,\nmeasured by a token-level generalizability (see Appendix A.1). From Figure 4, we first observe that\nour generalizability measure is reliable, successfully distinguishing the lexicalized value “south korea”\nand disfluent span “married” from the rest of the template. Second, we observe that the refinement\nstep correctly fixes both errors by replacing “south korea” with more generalizable, nonterminal fields\nand inserting “was” to fix the grammatical error. Figure 4 demonstrates the effectiveness of template\nrefinement and helps explain why refinement leads to a substantial performance gain on SynthBio in\nTable 2.\nFrom Figure 4, we also observe that the words after “and” often appear less generalizable. This is\nbecause there are many alternative “branches” that could continue the prefix in these positions and each\nalternative option will receive a lower probability under a left-to-right PLM pθ(x|d). We find that the\ninfilling PLM pθ(x|x′, d) is robust to these false positives and typically will leave these spans unchanged.\nThis illustrates the benefits of combining a left-to-right and an infilling PLMs in template refinement.\nB.4 Out-of-domain Evaluation\nTable 12 displays the list of entities we used for creating the 54 OOD examples we used in our evaluation.\nTable 13 shows example outputs from the BART model finetuned on the downsampled E2E data with\n1982\nOOD input. We find that BART often confuses the entity in the area field with name or ignores the\ninput value and hallucinates “city centre.”\nB.5 Human Study\nWe present a full list of metric scores that we used to evaluate our human study in Table 14. We have\nsimilar observations as in Section 4.4 that TempLM extracts more fluent templates than our template\nwriters. We append our instructions for template writers and screenshots of our interface to the end of this\ndocument.\n1983\nfield value phrasing\nfood Fast food fast food\nFast food\nfamilyFriendly yes\nfor a child friendly\nfor a family-friendly\nfor a children friendly\nfor a kid friendly\nfor a family friendly\nis a child friendly\nis a family-friendly\nis a children friendly\nis a kid friendly\nis a family friendly\nis child friendly\nis family-friendly\nis children friendly\nis kid friendly\nis family friendly\nfamilyFriendly no\nnon child friendly\nnon children friendly\nnon-family friendly\nnon family friendly\nnon-family-friendly\nnon family-friendly\nnot child friendly\nnot family-friendly\nnot children friendly\nnot kid friendly\nnot family friendly\ncustomer rating 1 out of 5\n1 star\none star\nlow customer rating\n1 out of 5\ncustomer rating 3 out of 5\n3 star\nmoderate customer rating\nthree star\naverage customer rating\ncustomer rating is average\n3 out of 5\ncustomer rating 5 out of 5\n5 star\nfive star\nhigh customer rating\n5 out of 5\nTable 7: A collection of common paraphrases of given input data. We use this phrasing collection to perform a\nmatching-based faithfulness evaluation for E2E. The second half of this table is in Table 8.\n1984\nfield value phrasing\ncustomer rating high\n5 star\nfive star\nhigh customer rating\n5 out of 5\ncustomer rating average\n3 star\nthree star\naverage customer rating\ncustomer rating is average\n3 out of 5\ncustomer rating low\n1 star\none star\nlow customer rating\n1 out of 5\npriceRange less than £20\nlow priced\nlow-priced\nlow price range\ncheap\nless than £20\npriceRange £20-25\naverage priced\nmoderate prices\nmoderately priced\naverage price range\nmoderate price range\n£20-25\npriceRange more than £30\nprice range is high\nexpensive\nhigh priced\nhigh price range\nmore than £30\npriceRange low low-priced\nlow price range\npriceRange cheap\nlow priced\nlow price range\ncheap\npriceRange moderate\naverage prices\nmoderate prices\nprice range is moderate\nmoderately priced\nmoderate price range\npriceRange high\nprice range is high\nexpensive\nhigh priced\nhigh price range\nTable 8: A collection of common paraphrases of given input data. We use this phrasing collection to perform a\nmatching-based faithfulness evaluation for E2E. The first half of this table is in Table 7.\n1985\nSplit Methods BLEU↑ NIST↑ METEOR↑ ROUGE-L↑ CIDEr↑ Eprecision↓ Erecall↓\nTest\nBART 66.2±0.5 8.5±0.0 43.1±0.2 68.4±0.7 2.2±0.0 6 .0±2.9 376.3±48.1\nTempLM 61.5±1.0 8 .0±0.1 41 .0±0.8 64 .5±0.8 2 .1±0.1 0 .0±0.0 471 .7±62.9\nNTemp† 55.17 7.14 41.91 65.70 1.70 7 539\nTempClassic52.1±2.0 7 .3±0.1 41 .7±1.0 62 .2±2.3 1 .9±0.1 46 .7±25.4 451 .7±36.9\nSUB 45.3±1.9 6 .9±0.2 40 .0±0.2 55 .6±2.4 1 .4±0.1 110 .7±36.2 421 .0±12.7\nValid.\nBART 70.8±0.7 8.3±0.1 47.0±0.1 72.8±0.2 2.4±0.0 5 .0±1.5 182.0±11.8\nTempLM 64.8±0.6 8 .0±0.0 43 .1±0.4 67 .8±0.2 2 .2±0.0 0.0±0.0 308 .7±4.3\nNTemp† 64.53 7.66 42.46 68.60 1.82 7 539\nTempClassic52.2±0.6 7 .2±0.0 40 .9±0.2 60 .7±0.9 1 .7±0.0 92 .7±6.1 401 .0±13.2\nSUB 43.0±0.4 6 .6±0.1 39 .4±0.2 55 .0±0.4 1 .3±0.0 85 .3±16.9 409 .7±13.7\nTable 9: Evaluation of systems trained on the subsampled E2E datasets.\nBLEU BERTScore F1 ROUGE-L\nTest\nBART 40.8 ±0.2 55.2 ±0.1 48.4 ±0.2\nTempLM 40.3 ±0.3 54 .3 ±0.1 48 .3 ±0.1\nTempClassic 36.6 ±0.2 48 .8 ±0.1 43 .1 ±0.1\nSUB 14.1 ±0.1 18 .9 ±0.1 26 .4 ±0.1\nValid\nBART 41.7 ±0.3 55.6 ±0.1 48 .8 ±0.1\nTempLM 41.3 ±0.2 55 .2 ±0.2 49.1 ±0.2\nTempClassic 35.1 ±0.2 47 .7 ±0.1 42 .0 ±0.1\nSUB 14.0 ±0.1 19 .0 ±0.1 26 .4 ±0.0\nTable 10: Automatic evaluation results on the SynthBio test and validation sets.\nSplit Methods BLEU↑ NIST↑ METEOR↑ ROUGE-L↑ CIDEr↑ Eprecision ↓ Erecall ↓ #. Templates\nTest\nBART 67.1 ±0.2 8.7 ±0.0 45.2 ±0.0 69.5 ±0.1 2.3 ±0.0 0.0 ±0.0 110.7 ±5.2 N/A\nTempLM 57.4 ±0.6 7 .6 ±0.0 41 .0 ±0.3 65 .8 ±0.3 2 .0 ±0.0 0.0 ±0.0 506 .7 ±15.6 509\nNTemp† 55.17 7 .14 41 .91 65 .70 1 .70 7 539 N/A\nTempClassic 58.2 ±0.0 7 .5 ±0.0 43 .7 ±0.0 67 .6 ±0.0 2 .2 ±0.0 0.0 ±0.0 516 .0 ±1.0 39964\nSUB 36.8 ±0.2 5 .9 ±0.0 39 .5 ±0.1 51 .2 ±0.2 0 .81 ±1.6 183 .7 ±3.2 416 .3 ±1.5 39964\nValid.\nBART 69.8 ±0.1 8.4 ±0.0 47.6 ±0.1 74.3 ±0.1 2.5 ±0.0 0 .3 ±0.3 256.3 ±5.8 N/A\nTempLM 65.5 ±0.1 7 .8 ±0.0 45 .7 ±0.1 71 .9 ±0.2 2 .4 ±0.0 0.0 ±0.0 365 .7 ±9.4 509\nNTemp† 64.53 7 .66 42 .46 68 .60 1 .82 7 539 N/A\nTempClassic 64.6 ±0.1 7 .8 ±0.0 46 .0 ±0.0 71 .3 ±0.0 2 .4 ±0.0 4 .0 ±0.0 425 .7 ±0.9 39964\nSUB 35.9 ±0.1 5 .6 ±0.0 38 .8 ±0.1 51 .7 ±0.1 0 .73 ±0.4 136 .0 ±3.8 374 .0 ±1.7 39964\nTable 11: Evaluation of systems trained on the full E2E training set.\nArea Times Square, Central Park, Union Station\nFood Thai, Russian, German\nRestaurant McDonald’s, Subway, Starbucks, KFC\nNear McDonald’s, Subway, Starbucks, KFC\nTable 12: List of novel entities used for creating OOD examples.\n1986\nInput data name: McDonald’s, near: Subway}\n{area: Times Square, eatType: restaurant, food: Thai,\nBART output Near Subway in the city center is a restaurant that serves Thai food called the Mcdonald’s.\nInput data name: McDonald’s, near: Subway}\n{area: Central Park, eatType: restaurant, food: Thai,\nBART output Central park is a restaurant that serves thai food. it is located near subway.\nInput data name: McDonald’s, near: KFC}\n{area: Times Square, eatType: restaurant, food: Russian,\nBART output Near KFC in the city center is a restaurant called the Times Square. it serves Russian food.\nInput data name: Subway, near: Starbucks}\n{area: Union Station, eatType: restaurant, food: German,\nBART output In the center of the city near Starbucks is a restaurant called Subway.\nTable 13: Examples OOD output from the BART model finetuned on the downsampled E2E dataset. We color\nunfaithful information red.\nBLEU BERTScore F1 ROUGE-1 ROUGE-2 ROUGE-L\nCluster\nWriter\nHuman 37.3 ±1.5 51 .3 ±2.3 64 .5 ±1.1 41 .1 ±1.6 44 .9 ±1.7\nHuman\nEnsemble 39.1 54 .0 63 .7 44 .1 47 .3\nBART 44.0 ±0.2 58 .5 ±0.2 70.6 ±0.3 45 .8 ±0.3 50 .9 ±0.2\nTempLM 44.3 ±1.3 58.8 ±1.0 68 .6 ±1.1 46.8 ±1.3 51.8 ±0.7\nCluster\nSpy\nHuman 24.9 ±2.0 42 .2 ±4.4 54 .8 ±2.0 34 .8 ±0.6 40 .5 ±1.2\nHuman\nEnsemble 32.1 48 .5 57 .2 37 .2 40 .7\nBART 40.5 ±0.4 55.4 ±0.1 68.2 ±0.4 42.7 ±0.3 46.5 ±0.1\nTempLM 34.4 ±2.4 50 .8 ±0.9 61 .4 ±0.9 39 .8 ±1.2 44 .1 ±0.4\nTable 14: Human study results on two clusters of the SynthBio test set. We observe that human written templates\ncannot achieve high metric scores even in the ensemble setting, showcasing the difficulty of writing templates and\nthe efficacy of TempLM.\n1987\n Designing templates for data to text conversion \n Goal:  Write (ideally ten or more) templates  that generate  realistic biography \n Time:  30 minutes \n 1. What is this task? \n Your goal is to write a set of  templates  that can  be used to automatically convert data into text. \n For example, consider this  data  which have three ﬁeld  and value pairs: \n Field  Value \n name  Ramazan Inal \n nationality  Turkish \n occupation  writer \n In order to automatically generate this  text  from  the data: \n Ramazan Inal  is a  Turkish  writer  . \n we can create this template: \n [  name  ] is a [  nationality  ] [  occupation  ]. \n and our system will deterministically replace each ﬁeld with the value speciﬁed in the data. \n [  name  ] →  Ramazan Inal \n [  nationality  ] →  Turkish \n [  occupation  ] →  writer \n [  name  ] is a [  nationality  ] [  occupation  ]. →  Ramazan  Inal  is a  Turkish  writer  . \n Because we want to make templates  ﬂexible  so that  they can account for potential grammatical \n changes necessary for different values (e.g. “  a  Turkish  writer” vs. “  an  English writer”), we added \n these additional ﬁelds and possible values to all input data: \n Field  Value \n1988\n be  One of the following: \n is, are, was, were \n article  One of the following: \n a, an \n number  One of the following: \n One, two, three, four, \n ﬁve, six, seven, eight, \n nine, ten \n Therefore, the ﬁnal template with these additional ﬁelds and values will be: \n [  name  ] [  be]  [  article]  [  nationality  ] [  occupation  ]. \n [  name  ] →  Ramazan Inal \n [  be  ] →  is \n [  article  ] →  a \n [  nationality  ] →  Turkish \n [  occupation  ] →  writer \n [  name  ] [  be  ] [  article  ] [  nationality  ] [  occupation  ].  →  Ramazan Inal  is  a  Turkish  writer  . \n Note that sometimes,  not all ﬁelds are used  to generate  the text. In the previous example, the \n number  ﬁeld is not used anywhere in the text, hence  no need to be speciﬁed in the template. \n 2. What is the goal? \n Given hundreds of pairs of such data and desired texts, your goal is to  write ten or more \n templates  that  can  best represent the given data and  text pairs  as well as  can be used to \n generate realistic biography for new data  . \n For example, the previous template can be used with new data to generate biography as follows: \n Template: \n [  name  ] [  be  ] [  article  ] [  nationality  ] [  occupation  ]. \n New data: \n Field  Value \n name  Joseph Duch \n1989\n gender  non-binary \n nationality  Andorran \n occupation  writer \n be  One of the following: \n is, are, was, were \n article  One of the following: \n a, an \n number  One of the following: \n One, two, three, four, \n ﬁve, six, seven, eight, \n nine, ten \n Automatically generated text: \n Joseph Duch  is  a  Andorran  writer  . \n 3. How do I do this task? \n 1.  Click one of the links to start:  [  writer  ][  spy  ] \n a.  Please do not refresh your window! The timer will be reset and you will start over. \n b.  We suggest that you maximize the window and zoom out so that you can browse \n the data easily. \n 2.  In the left panel, you will see all pairs of data and desired texts.  Click through them and \n get yourself familiar with ﬁelds, values, and texts. \n 3.  In the right panel, you will see a  text editor  where  you can write templates while browsing \n1990\n multiple data and desired texts at the same time. Please enclose the ﬁeld names with \n brackets (e.g. [name]). Valid ﬁeld names will be colored in  orange  . \n a.  Each time you write a template, click the “add a template” button in the right \n panel, copy and paste your template, and click the “save” button. \n b.  You can view the list of templates you have written by clicking the “list of \n templates” button in the left panel. \n1991\n c.  If necessary, you can delete templates by clicking the close button next to each \n template in the list. \n 4.  On the bottom of the screen, you will see a  counter  for the number of templates and a \n timer  . \n 5.  When you are done, click  the ﬁnish button  next to  the timer to save your templates. Share \n the veriﬁcation code you got with Mina and share the templates you wrote with Tianyi. \n1992\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□\u0013 A1. Did you describe the limitations of your work?\nafter conclusion before references\n□\u0013 A2. Did you discuss any potential risks of your work?\nLeft blank.\n□\u0017 A3. Do the abstract and introduction summarize the paper’s main claims?\nLeft blank.\n□\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB □\u0017 Did you use or create scientiﬁc artifacts?\nLeft blank.\n□ B1. Did you cite the creators of artifacts you used?\nNo response.\n□ B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nNo response.\n□ B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nNo response.\n□ B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nNo response.\n□ B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nNo response.\n□ B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\nNo response.\nC □\u0013 Did you run computational experiments?\nLeft blank.\n□\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nsection 4.1 speciﬁed the kind of model used.\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n1993\n□\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\nsection 4.1 discussed experimental setup and section B.2 provides hyperparameter details\n□\u0013 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nTable 1 and Table 2 provide error bars\n□\u0017 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nNot in the paper but clear from code release (will be made avaiable after anonymous. period)\nD □\u0013 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nLeft blank.\n□\u0013 D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\ninstruction appended to page 19 onward\n□\u0013 D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nsection 4.4\n□\u0013 D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nsee instruction appended\n□\u0017 D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nLeft blank.\n□\u0013 D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nsee section 4.4\n1994"
}