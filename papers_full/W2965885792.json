{
    "title": "Fast and Accurate Capitalization and Punctuation for Automatic Speech Recognition Using Transformer and Chunk Merging",
    "url": "https://openalex.org/W2965885792",
    "year": 2019,
    "authors": [
        {
            "id": "https://openalex.org/A5091142923",
            "name": "Binh P. Nguyen",
            "affiliations": [
                "Hanoi University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A5040635512",
            "name": "Vu Bao Hung Nguyen",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5048931285",
            "name": "Hien D. Nguyen",
            "affiliations": [
                "Thai Nguyen University"
            ]
        },
        {
            "id": "https://openalex.org/A5067573637",
            "name": "Pham Ngoc Phuong",
            "affiliations": [
                "Thai Nguyen University"
            ]
        },
        {
            "id": "https://openalex.org/A5005800339",
            "name": "The-Loc Nguyen",
            "affiliations": [
                "Hanoi University of Mining and Geology"
            ]
        },
        {
            "id": "https://openalex.org/A5102847246",
            "name": "Quoc Truong",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5110641459",
            "name": "Lương Chi",
            "affiliations": [
                "Hanoi University of Science and Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2963212250",
        "https://openalex.org/W6679436768",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6729956949",
        "https://openalex.org/W6749669830",
        "https://openalex.org/W2962989741",
        "https://openalex.org/W6752909555",
        "https://openalex.org/W6684662674",
        "https://openalex.org/W6712411474",
        "https://openalex.org/W6713441181",
        "https://openalex.org/W6624114792",
        "https://openalex.org/W6714054690",
        "https://openalex.org/W2745785989",
        "https://openalex.org/W2133564696",
        "https://openalex.org/W2963418779",
        "https://openalex.org/W2166116787",
        "https://openalex.org/W2147880316",
        "https://openalex.org/W2398104528",
        "https://openalex.org/W2407834842",
        "https://openalex.org/W2403334028",
        "https://openalex.org/W886998232",
        "https://openalex.org/W2130942839",
        "https://openalex.org/W2553303224",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W2143017621",
        "https://openalex.org/W2857028992"
    ],
    "abstract": "In recent years, studies on automatic speech recognition (ASR) have shown outstanding results that reach human parity on short speech segments. However, there are still difficulties in standardizing the output of ASR such as capitalization and punctuation restoration for long-speech transcription. The problems obstruct readers to understand the ASR output semantically and also cause difficulties for natural language processing models such as NER, POS and semantic parsing. In this paper, we propose a method to restore the punctuation and capitalization for long-speech ASR transcription. The method is based on Transformer models and chunk merging that allows us to (1), build a single model that performs punctuation and capitalization in one go, and (2), perform decoding in parallel while improving the prediction accuracy. Experiments on British National Corpus showed that the proposed approach outperforms existing methods in both accuracy and decoding speed.",
    "full_text": "Fast and Accurate Capitalization and Punctuation for\nAutomatic Speech Recognition Using Transformer and Chunk Merging\nBinh Nguyen1,5, Vu Bao Hung Nguyen1, Hien Nguyen1,3, Pham Ngoc Phuong1,3, The-Loc Nguyen1,4,\nQuoc Truong Do1, Luong Chi Mai1,2\n1Vietnam Artiﬁcial Intelligence System, Vietnam\n2University of Science and Technology of Hanoi, Vietnam\n3Thai Nguyen University, Vietnam\n4Hanoi University of Mining and Geology, Vietnam\n5Hanoi University of Science and Technology, Vietnam\n{binhnguyen|hungnguyen|locnguyen|truongdo}@vais.vn, nguyenthuhien@dhsptn.edu.vn,\nphuongpn@tnu.edu.vn, lcmai@ioit.ac.vn\nAbstract\nIn recent years, studies on automatic speech recognition (ASR)\nhave shown outstanding results that reach human parity on short\nspeech segments. However, there are still difﬁculties in stan-\ndardizing the output of ASR such as capitalization and punc-\ntuation restoration for long-speech transcription. The problems\nobstruct readers to understand the ASR output semantically and\nalso cause difﬁculties for natural language processing models\nsuch as NER, POS and semantic parsing. In this paper, we pro-\npose a method to restore the punctuation and capitalization for\nlong-speech ASR transcription. The method is based on Trans-\nformer models and chunk merging that allows us to (1), build\na single model that performs punctuation and capitalization in\none go, and (2), perform decoding in parallel while improving\nthe prediction accuracy. Experiments on British National Cor-\npus showed that the proposed approach outperforms existing\nmethods in both accuracy and decoding speed.\nIndex Terms: speech recognition, capitalization and punctua-\ntion insertion\n1. Introduction\nIn a typical setup of an ASR system, punctuation and capital-\nization of words are removed because they do not affect the\npronunciation of words. As the result, the output of ASR con-\ntains purely a sequence of words or alphabet characters depend-\ning on the model type. While this output is sufﬁcient for many\napplications, such as voice commands, virtual assistants, where\nspeech segments are usually short and independent, it is difﬁcult\nto be used in applications that transcribes long speech segments.\nIt would be easier for human to read a document with proper\npunctuation and word capitalization. Moreover, when ASR re-\nsults are fed into NLP models to perform machine translation\n(MT) or name entity recognition (NER), punctuation and word\ncapitalization are crucial pieces of information that can help to\nboost the performance [1, 2, 3].\nRegarding studies on segmentation and punctuation inser-\ntion for ASR, Cho et al. [1] proposed a method to use phrase-\nbased translation models that consider the punctuation insertion\nas machine translation tasks. The model takes input is unpuc-\ntuted text and translates into a punctuated one. Zelasko et al.\n[4] and Tilk et al. [5] incoporate more information from speech\nsignal to improve the performance. In [6, 7], dynamic condi-\ntional random ﬁelds (CRFs) [8] were used to predict punctua-\ntion. The works proposed by Cho et al. [9] and Tilk et al. [5]\nProposed Method\nIn his ﬁrst appearances, Superman was considered a vigilante. \nin his ﬁrst appearances superman was considered a vigilante\nFigure 1: The proposed method for performing both punctua-\ntion and word capitalization in one go\nmade use of end-to-end translation model with LSTM to pre-\ndict punctuation and segmentation. They successfully demon-\nstrated that the end-to-end models outperform conventional ap-\nproaches. While existing works are capable of predicting punc-\ntuation, they share similar limitation. First, the models only\nhandle one task which is punctuation insertion, however, out-\nput from ASR is also typically uncapitalized. While adding just\npunctuation might help speech translation to determine when to\ntranslate, other NLP tasks such as NER and PoS tagging do not\nget much help because one of the key feature of these models\nis word capitalization. Second, long input sentences are usually\nsplit into ﬁx-length and non-overlapped chunks before feeding\ninto the model. Although this method helps to speedup the in-\nference by processing chunks independently and in parallel, it is\nprone to bad prediction of words around the chunk’s boundary\nbecause there isn’t enough both left and right context informa-\ntion in the area.\nIn this paper, we proposed a method based on transformer\nmodels and overlapped chunk-merging to restore both word\ncapitalization and punctuation in one go as illustrated in Fig-\nure 1. The system consists of 3 components (Figure 2 - b). The\nﬁrst component is an overlapped chunk spliting that takes a long\ninput sequence and splits them into chunks with overlap. This\nprocess make sure that the second component, which is the cap-\nitalization and punctuation model, always have enough left and\nright context of words to make the prediction. The last com-\nponent is the chunk-merging where the overlapped output are\ncombined into a single sentence. This process decides which\npart of the overlap area to be removed and to be kept. The\nmethod allows us to (1), build a single model that performs\narXiv:1908.02404v1  [cs.CL]  7 Aug 2019\ndoesbillthe not become law unless houses of congress vote to   vetooverride the\ndoesbillThe not become law unless houses of congress vote to   veto.override the\nCapitalization and Punctuation Model\nChunk Split\nof congress vote to   vetooverride thedoesbillthe not become law unless houses\nof congress vote to   veto.override thedoesbillThe not become law unless houses\n(a) Capitalization and Punctuation System Without Overlap-\nping Segments\ndoesbillthe not become law unless houses of congress\ndoesbillthe not become law unless houses of congress\nvote to   vetooverride the\nlaw unless houses of congress vote to   vetooverride the\ndoesbillThe not become law, unless houses of congress\nlaw unless houses of Congress vote to   veto.override the\ndoesbillThe not become law, unless houses of Congress vote to   veto.override the\nOverlapped-Chunk Merging\nCapitalization and Punctuation Model\nOverlapped-Chunk Split\n(b) Proposed System Architecture for Capitalization and Punc-\ntuation. Because of more context, it can add comma after “law”\nand upper case “congress”\nFigure 2: Capitalization and Punctuation System With and\nWithout Overlap-ping Segments. Ground truth of this exam-\nple is “The bill does not become law, unless Congress vote to\noverride the veto. ”\npunctuation and capitalization without the need of pipeline re-\nsults from one system to another, and (2), perform decoding in\nparallel while improving the prediction accuracy.\n2. End-to-end Model for Punctuation and\nSegmentation\nEnd2end models for punctuation works in a similar way with\nmachine translation tasks [10, 11] where it takes input is a se-\nquence of of lowercase, unpunctuated words and outputs a se-\nquence with truecase and punctuation inserted. Figure 2a illus-\ntrates the use of end-to-end models for restoring capitalization\nand punctuation proposed in [12]. First, a long input text from\nASR is split into small segments and then, they are fed into\na translation model to produce an output sequence. While the\napproach can take advantages of LSTM models that it is able\nto learn longer context information, it usually failed to predict\ntruecase or punctuation of words near the segment boundary.\nPrevious studies [13] has pointed out that Transformer per-\nforms better than LSTM models by exploiting its self-attention\nlayer to capture context more efﬁciently and speedup the train-\ning process. Transformer is basically an encoder-decoder\nmodel. It contains multiple identical encoders and identical\ndecoders stacked upon each other. Each encoder has a self-\nattention layer that extract surrounding words information when\na word is being encoded. This layer is followed by a feed for-\nward neural network; the networks in different encoders do not\nshare weights. Each decoder also has a self-attention layer and\na feed forward neural network, but to enhance the relevant parts\nof input, an attention layer (similar to attention in sequence-to-\nsequence model) is added between the 2 sub-components.\nTransformer’s architecture was hand-crafted manually,\nEvolved Transformer (ET) was created to enhance Transformer.\nThe idea behind ET is using neural architecture search (NAS)\n[14] to look for the most promising setup among different al-\nternatives of neural networks. To modify Transformer model\nconﬁguration toward a better one, ET uses an evolution-based\nalgorithm with an innovative approach to expedite the process.\n3. Proposed Method\nFigure 2b describes our system architecture. The system works\nas follows, ﬁrst, output from and ASR module (lowercase with-\nout punctuation) is fed to the Overlapped-Chunk Split module\nto produce overlapped segments. Second, the Capitalization and\nPunctuation Model takes the split segments and processes them\nin parallel to output a list of outputs. Finally, the outputs are\nmerged back to form a ﬁnal sentence using the Overlapped-\nChunk Merging module. Details of each modules are described\nin the following sections.\n3.1. Capitalization and Punctuation Model\nThis section describes the architecture and hyperparameters of\nour models. To be certain that our method of overlapping seg-\nments are efﬁcient regardless of models, we preformed the ex-\nperiments on sequence-to-sequence LSTM model and Evolved\nTransformer framework one by one. Our models are imple-\nmented based on Tensor2Tensor[15] and OpenNMT[10] frame-\nwork. Concatenating overlapped chunks is developed as a sep-\narated module and used only after the inferring process.\nTo replicate the same condition, both the models have 6\nhidden layers, word embedding size of 256, batch size of 4096\nand trained for 200 epochs; the number of head in transformer\nmodel is 8. Their jobs is to convert from a sequence of lower-\ncase text without punctuation to another sequence of capitalized\ntext with punctuation. With 500 MB of text data for training,\neach model took 20 hours to train on an NVIDIA 2080Ti GPU.\n3.2. Algorithm for Overlapped-Chunk Split and Merging\nFrom preliminary experiments, we observed that the model\noften makes mistakes when processing words near the chunk\nboundary. We hypothesize that there is not enough context in-\nformation around the area, leading to the poor performance of\nthe model. To mitigate the problem, we proposed a method to\nsplit long input sentences into chunks with a chunk size of k\nwords and a sliding window of k/2 words so that 2 consecu-\ntive chunks are overlapped. Later, the output of the model are\nmerged in the way that we only keep predictions of the model\nwhere there is enough context information (an example is illus-\ntrated in Figure 2b).\nWhile splitting input sentences into overlapped chunks is\nstraight-forward as we only need to decide the chunk and over-\nlapped size, merging the overlapped results is more difﬁcult.\nSince the output of the overlapped region between 2 consecu-\ntive chunks can be different, we need to decide which words\nto keep and which word to remove to form a complete sen-\ntence. According to the hypothesis above, we deﬁned a pa-\nrameter called min_words_cut that indicates the number of\nwords at the end the ﬁrst chunk to be removed and also the\nnumber of words to be kept at the end of overlapped words in\nthe second chunk. It ranges from 0 to the overlap size. With\nthe value of 0, the whole overlapped words in the ﬁrst chunk\nare kept while the overlapped words in the second chunk are\nFirst chunk\nSecond chunk\ndoes\nmin_words_cut\nConcatenate result\nmin_words_cut\nbillThe not become\ndoesbillThe not become\nlaw, unless\nlaw, unless\nvote to\nhouses of congress\nlaw unless houses of Congress\nhouses of Congress\noverride the veto.\nvote to override the veto.\nFigure 3: Overlapped Chunk Concatenation\nOriginal data:\nThe bill does not become law, unless houses of Congress vote\nto override the veto.\nInput data:\nthe bill does not become law unless houses of congress\nlaw unless houses of congress vote to override the veto.\nPlain text output:\nThe bill does not become law, unless houses of Congress\nlaw, unless houses of Congress vote to override the veto.\nEncoded output:\nU$ L$ L$ L$ L$ L, L$ L$ L$ U$\nL, L$ L$ L$ U$ L$ L$ L$ L$ L.\nFigure 4: Data samples with chunk size of 10\nremoved (illustrated in Figure 3). The same principle is applied\nwhen min_words_cut equals to the overlapped size.\n3.3. Data Preparation\nTo simulate the ASR output, we preprocess the dataset as fol-\nlowed. First, the characters are cleaned up: only the alphabet\ncharacters and three punctuation (comma, full stop and ques-\ntion mark) are kept. Then, we make sure that the punctuation\nbelongs to the previous word, for instance, we use “laptop, mo-\nbile” not “laptop , mobile”. Finally, we split data into chunks\naccording to the split algorithm described in the above section.\nAn example is shown in Figure 4.\nWe prepared 2 formats of training data: plain text and en-\ncoded text [9]. Both formats takes the lowercase text without\npunctuation as input. The plain text model, as the name sug-\ngest, provides output as plain text with punctuation and capi-\ntalization. The encoded text model, on the other hand, gives\nthe result in an encoded format that contains only 6 classes as\nshowed in Table 1. It is obvious that the encoded format will\nhelp the model to train and infer faster than the plain text since\nits vocabulary size is ﬁxed and very limited. However, due to\nthe limited vocabulary size, the decoder of the end-to-end model\ndoes not have much information of the words and the context in-\nformation. We are interested to see how this method affect the\nquality in comparision with the plain text model.\n4. Experiments and Results\n4.1. Corpus Description\nTo train and evaluate the proposed method, we use the British\nNational Corpus (BNC) [16] that contains 100 million words in\nboth written and spoken language from a wide range of sources.\nIt is designed to represent a large cross-section of British En-\nglish from late 20 th century. We use the XML edition which\ncontains 4049 ﬁles with the size of 515 MB in total. The li-\nbrary NLTK [17] is used to extract 6M sentences from BNC\ndataset. For the test set, we use 67 thousand sentences. The\nnumber of label instances for each of the punctuation and cap-\nitalization classes available in our training and testing data set\nare displayed in Table 1.\nTable 1: BNC dataset detail. “U” and “L” respectively denote\nuppercase and lowercase word (either ﬁrst or all character);\n“. ”, “, ” and “?” denotes full stop, comma, and question mark.\nThe dollar sign (“$”) indicates there are no punctuation coming\nafter the word.\nClass Training Testing\nU 13 M 146 K\nL 81 M 1 M\n. 4.6 M 54 K\n, 4.9 M 57 K\n? 380 K 5 K\n$ 87 M 1 M\n4.2. Evaluation metric\nThe models (described in section 3.1) are evaluated using pre-\ncision, recall, and F1 scores. For ease of representation, we\nconverted output words and punctuation to the 6-class encoded\nformat as illustrated in Table 1. The evaluation results indicate\nhow well the method can predict truecase of words and punctu-\nation restoration. Since prediction of lowercase and blank space\nare good in every models, we ignore them in compare table.\n4.3. Evaluation of chunk-merging\nTable 2: Comparison Seq2seq LSTM with and without using\nChunk Merging for plain text format\nModel Class Precision Recall F1-score\nChunk Merging\nSeq2seq LSTM\nU 0.74 0.53 0.62\n. 0.43 0.41 0.42\n, 0.10 0.87 0.19\n? 0.49 0.22 0.30\nNon-Chunk Merging\nSeq2seq LSTM\nU 0.70 0.53 0.61\n. 0.40 0.41 0.41\n, 0.10 0.85 0.18\n? 0.45 0.20 0.28\nTable 2 shows the result of the seq2seq LSTM model with\nand without chunk-merging. As we can see, with the help of\n0 2 4 6 8 10 12 14\nmin_words_cut\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9f1 score\nF1 score on different min_words_cut\nU\nL\n$\n.\n,\n?\nFigure 5: F1-score on different min word cut. It peak in the\nmiddle range of overlap size (4-10). Predicting uppercase and\nlowercase are stable and independent from minword cut, ques-\ntion mark is quite sensitive with this hyper-parameter.\nTable 3: Comparison Evolved Transformer with and without\nusing Chunk Merging for plain text format\nModel Class Precision Recall F1-score\nChunk Merging\nEvolved Transformer\nU 0.90 0.84 0.87\n. 0.74 0.72 0.73\n, 0.61 0.51 0.56\n? 0.82 0.63 0.71\nNon-Chunk Merging\nEvolved Transformer\nU 0.84 0.79 0.81\n. 0.56 0.66 0.61\n, 0.40 0.42 0.41\n? 0.70 0.46 0.56\nchunk merging, F1 score on all classes are improved consis-\ntently by 1%. The result indicates that the overlapped words\ngive the model more information to make better prediction, and\nthat our chunk-merging method can select good portion of the\noverlap area.\nThe chunk-merging method even shows superior perfor-\nmance over non-chunk-merging when it is used with Evolved\nTransformer models. Results on Table 3 shows that the predic-\ntion accuracy of the question mark raises from 56% to 71%, this\nis a margin of 15% improvement and the minimum improve-\nment of the system is 6% for the uppercase class. Figure 6 dis-\nplays the confusion matrix of the model. The matrix shows that\nthe comma is the most difﬁcult class to predict and it is often\nmis-predicted as blank characters. In addition, the matrix also\nindicates that the model always predict a word (either lowercase\nor uppercase) when the input is word.\nThe results prove our hypothesis that there is not enough\ncontext for model to predict efﬁciently at the beginning and\nthe end of each sample and that drawback can be overcome\nby adding more context with chunk overlapping and chunk-\nmerging method.\n4.4. Evaluation on plain-text model and encoded-text\nmodel\nWe further compare the result on models using plain text and\nencoded text. The ones with plain text outperform the ones with\nU L $ . , ?\nPredicted label\nU\nL\n$\n.\n,\n?\nTrue label\n0.84 0.16 0.00 0.00 0.00 0.00\n0.01 0.99 0.00 0.00 0.00 0.00\n0.00 0.00 0.98 0.01 0.02 0.00\n0.00 0.00 0.24 0.72 0.04 0.00\n0.00 0.00 0.41 0.08 0.51 0.00\n0.00 0.00 0.17 0.14 0.07 0.63\n0.0\n0.2\n0.4\n0.6\n0.8\nFigure 6: Confusion matrix of Evolved Transformer model with\nplain text and overlapping format\nencoded text, however the model using encoded text has smaller\nmodel size and is faster for inference. The details are in Table 4\nTable 4: Comparison of results encoded text and plain text using\nEvolved Transformer\nModel Class Precision Recall F1-score\nEncoded Text\nChunk Merging\nEvolved Transformer\nU 0.87 0.80 0.84\n. 0.68 0.66 0.67\n, 0.50 0.40 0.44\n? 0.76 0.55 0.63\nPlain Text\nChunk Merging\nEvolved Transformer\nU 0.90 0.84 0.87\n. 0.74 0.72 0.73\n, 0.61 0.51 0.56\n? 0.82 0.63 0.71\nTo explore the impact of min_words_cut value to the\nquality of the result, we performed the experiment on sequence-\nto-sequence LSTM model with the overlapping of 15 words\nand min_words_cut ranges from 0 to 15. The outcome\nshown in Figure 5 indicates that f1-scores peak in the mid-\ndle range of chunk size (4-10). It demonstrate that predictions\nof uppercase and lowercase are stable and independent from\nmin_words_cut.\nAs processing chunks is paralleled and the concatenation\nalgorithm has O(n), this approach is fast and proved to be su-\nperior to conventional methods.\n5. Conclusion\nIn this research, we have proposed an end-to-end model that\nrestores both punctuation and capitalization in one go. With\nchunk-split-merging, the method can splits and processes sen-\ntences in parallel and merges outputs to form the ﬁnal sentence\noutput. Experiments shows that the approach outperform exist-\ning methods that do not utilize chunk-merging by a signiﬁcant\nmargin, especially when combining with Evolved Transformer.\nIn the future, we will integrate this solution with ASR model to\nform an end-to-end model that can transform speech to a well\nformat text document.\n6. References\n[1] E. Cho, J. Niehues, and A. Waibel, “Segmentation and punctua-\ntion prediction in speech language translation using a monolingual\ntranslation system,” in International Workshop on Spoken Lan-\nguage Translation (IWSLT) 2012, 2012.\n[2] M. Tkachenko and A. Simanovsky, “Named entity recognition:\nExploring features.” in Proceeding of KONVENS, 2012, pp. 118–\n127.\n[3] V . Yadav and S. Bethard, “A survey on recent advances in named\nentity recognition from deep learning models,” in Proceedings of\nCICLing, 2018, pp. 2145–2158.\n[4] P. elasko, P. Szymaski, J. Mizgajski, A. Szymczak, Y . Carmiel,\nand N. Dehak, “Punctuation prediction model for conversational\nspeech,” Interspeech 2018 , Sep 2018. [Online]. Available:\nhttp://dx.doi.org/10.21437/Interspeech.2018-1096\n[5] O. Tilk and T. Alum ¨ae, “Lstm for punctuation restoration in\nspeech transcripts,” in Sixteenth annual conference of the inter-\nnational speech communication association, 2015.\n[6] W. Lu and H. T. Ng, “Better punctuation prediction with dynamic\nconditional random ﬁelds,” inProceedings of the 2010 conference\non empirical methods in natural language processing , 2010, pp.\n177–186.\n[7] N. Uefﬁng, M. Bisani, and P. V ozila, “Improved models for auto-\nmatic punctuation prediction for spoken and written text.” in In-\nterspeech, 2013, pp. 3097–3101.\n[8] J. Lafferty, A. McCallum, and F. C. Pereira, “Conditional random\nﬁelds: Probabilistic models for segmenting and labeling sequence\ndata,” 2001.\n[9] E. Cho, J. Niehues, and A. Waibel, “Nmt-based segmentation and\npunctuation insertion for real-time spoken language translation.”\nin INTERSPEECH, 2017, pp. 2645–2649.\n[10] G. Klein, Y . Kim, Y . Deng, J. Senellart, and A. M.\nRush, “OpenNMT: Open-source toolkit for neural machine\ntranslation,” in Proc. ACL , 2017. [Online]. Available: https:\n//doi.org/10.18653/v1/P17-4012\n[11] D. Bahdanau, K. Cho, and Y . Bengio, “Neural machine translation\nby jointly learning to align and translate,” 2014.\n[12] I. Sutskever, O. Vinyals, and Q. V . Le, “Sequence to sequence\nlearning with neural networks,” inAdvances in neural information\nprocessing systems, 2014, pp. 3104–3112.\n[13] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,”\nin Advances in Neural Information Processing Systems, 2017, pp.\n5998–6008.\n[14] B. Zoph and Q. V . Le, “Neural architecture search with reinforce-\nment learning,”arXiv preprint arXiv:1611.01578, 2016.\n[15] A. Vaswani, S. Bengio, E. Brevdo, F. Chollet, A. N. Gomez,\nS. Gouws, L. Jones, L. Kaiser, N. Kalchbrenner, N. Parmar,\nR. Sepassi, N. Shazeer, and J. Uszkoreit, “Tensor2tensor for\nneural machine translation,” CoRR, vol. abs/1803.07416, 2018.\n[Online]. Available: http://arxiv.org/abs/1803.07416\n[16] B. Consortium, The British National Corpus, version 3 (BNC\nXML Edition). Bodleian Libraries, University of Oxford, 2007.\n[17] E. Loper and S. Bird, “Nltk: the natural language toolkit,” arXiv\npreprint cs/0205028, 2002."
}