{
    "title": "Bolt-Dumbo Transformer: Asynchronous Consensus As Fast As the Pipelined BFT",
    "url": "https://openalex.org/W3135974488",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A5067515788",
            "name": "Yuan Lu",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5112876910",
            "name": "Zhenliang Lu",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5077863367",
            "name": "Qiang Tang",
            "affiliations": [
                null
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2131848219",
        "https://openalex.org/W2903448660",
        "https://openalex.org/W3013530784",
        "https://openalex.org/W1698117324",
        "https://openalex.org/W1991153938",
        "https://openalex.org/W2035362408",
        "https://openalex.org/W2113929724",
        "https://openalex.org/W2119795353",
        "https://openalex.org/W2139359217",
        "https://openalex.org/W3005846522",
        "https://openalex.org/W3183732253",
        "https://openalex.org/W2167882086",
        "https://openalex.org/W2964159515",
        "https://openalex.org/W2023051771",
        "https://openalex.org/W1836078613",
        "https://openalex.org/W3046841722",
        "https://openalex.org/W3106855293",
        "https://openalex.org/W2223468118",
        "https://openalex.org/W2584840935",
        "https://openalex.org/W2131817624",
        "https://openalex.org/W2914780660",
        "https://openalex.org/W2126087831",
        "https://openalex.org/W2569772192",
        "https://openalex.org/W1840851275",
        "https://openalex.org/W2534313446",
        "https://openalex.org/W2106004025",
        "https://openalex.org/W2969395421",
        "https://openalex.org/W2170561193",
        "https://openalex.org/W3175534079",
        "https://openalex.org/W66503885",
        "https://openalex.org/W2103178123",
        "https://openalex.org/W1526359699",
        "https://openalex.org/W1965159636",
        "https://openalex.org/W3037776643",
        "https://openalex.org/W2140036537",
        "https://openalex.org/W2131132597",
        "https://openalex.org/W2794717484",
        "https://openalex.org/W3204209583",
        "https://openalex.org/W2990690033",
        "https://openalex.org/W3212664445",
        "https://openalex.org/W3208802531",
        "https://openalex.org/W2896715746",
        "https://openalex.org/W2006699751",
        "https://openalex.org/W2138775315",
        "https://openalex.org/W3095752586",
        "https://openalex.org/W3096691500",
        "https://openalex.org/W2890933237",
        "https://openalex.org/W3095928864",
        "https://openalex.org/W2766783464",
        "https://openalex.org/W3019947961",
        "https://openalex.org/W2034791526",
        "https://openalex.org/W3015234426",
        "https://openalex.org/W2110880385",
        "https://openalex.org/W3022186314",
        "https://openalex.org/W1572695506",
        "https://openalex.org/W3005051998",
        "https://openalex.org/W1991476961",
        "https://openalex.org/W2963873436",
        "https://openalex.org/W2039727452",
        "https://openalex.org/W2886754822",
        "https://openalex.org/W2003214215",
        "https://openalex.org/W2094982524",
        "https://openalex.org/W2973068416",
        "https://openalex.org/W3133572969",
        "https://openalex.org/W2013608896",
        "https://openalex.org/W2770149261",
        "https://openalex.org/W1988655303",
        "https://openalex.org/W3137092842",
        "https://openalex.org/W2114579022"
    ],
    "abstract": "An urgent demand of deploying BFT consensus over the Internet is raised for implementing blockchain services. The deterministic (partial) synchronous protocols can be simple and fast in good network conditions, but are subject to denial-of-service when synchrony assumption fails. Asynchronous protocols, on the contrary, are robust against the adversarial network, but are substantially more complicated and slower for the inherent use of randomness. Facing the issues, optimistic asynchronous atomic broadcast ( Kursawe-Shoup, 2002; Ramasamy-Cachin, 2005) was proposed to improve the normal-case performance of the slow asynchronous consensus. They run a deterministic fastlane if the network condition remains good, and can fall back to a fully asynchronous protocol via a pace-synchronization mechanism if the fastlane fails. Unfortunately, existing pace-synchronization directly uses a heavy tool of asynchronous multi-valued validated Byzantine agreement (MVBA). We present Bolt-Dumbo Transformer (BDT), a generic framework for practical optimistic asynchronous atomic broadcast. At the core of BDT, we set forth a new fastlane abstraction that is simple and fast, while preparing honest parties to gracefully face potential fastlane failures caused by malicious leader or bad network. This enables a highly efficient pace-synchronization to handle fallback. The resulting design reduces a cumbersome MVBA to a variant of the conceptually simplest binary agreement only. Besides detailed security analyses, we also give concrete instantiations of our framework and implement them. Extensive experiments demonstrate that BDT can enjoy both the low latency of deterministic protocols (e.g. 2-chain version of HotStuff) and the robustness of state-of-the-art asynchronous protocols in practice.",
    "full_text": "Bolt-Dumbo Transformer: Asynchronous Consensus As Fast As\nthe Pipelined BFT\nYuan Luâˆ—\nInstitute of Software\nChinese Academy of Sciences\nluyuan@iscas.ac.cn\nZhenliang Luâˆ—\nSchool of Computer Science\nThe University of Sydney\nzhlu9620@uni.sydney.edu.au\nQiang Tangâˆ—\nSchool of Computer Science\nThe University of Sydney\nqiang.tang@sydney.edu.au\nABSTRACT\nAn urgent demand of deploying BFT consensus (e.g., atomic broad-\ncast) over the Internet is raised for implementing (permissioned)\nblockchain services. The deterministic (partial) synchronous pro-\ntocols can be simple and fast in good network conditions, but are\nsubject to denial-of-service (or even safety vulnerability) when syn-\nchrony assumption fails. Asynchronous protocols, on the contrary,\nare robust against the adversarial network, but are substantially\nmore complicated and slower for the inherent use of randomness.\nFacing the issues, optimistic asynchronous atomic broadcast\n(Kursawe-Shoup, 2002; Ramasamy-Cachin, 2005) was proposed to\nimprove the normal-case performance of the slow asynchronous\nconsensus. They run a deterministic fastlane if the network condi-\ntion remains good, and can fall back to a fully asynchronous proto-\ncol via a pace-synchronization mechanism (analog to view-change\nwith asynchronous securities) if the fastlane fails. Unfortunately,\nexisting pace-synchronization directly uses a heavy tool of asyn-\nchronous multi-valued validated Byzantine agreement (MVBA).\nWhen such fallback frequently occurs in the fluctuating wide-area\nnetwork setting, the benefits of adding fastlane can be eliminated.\nWe present Bolt-Dumbo Transformer (BDT), a generic frame-\nwork for practical optimistic asynchronous atomic broadcast. At\nthe core of BDT, we set forth a new fastlane abstraction that is\nsimple and fast, while preparing honest parties to gracefully face\npotential fastlane failures caused by malicious leader or bad net-\nwork. This enables a highly efficient pace-synchronization to handle\nfallback. The resulting design reduces a cumbersome MVBA to a\nvariant of the conceptually simplestbinary agreement only. Besides\ndetailed security analyses, we also give concrete instantiations of\nour framework and implement them. Extensive experiments demon-\nstrate that BDT can enjoy both the low latency of deterministic\nprotocols (e.g. 2-chain version of HotStuff) and the robustness of\nstate-of-the-art asynchronous protocols in practice.\nCCS CONCEPTS\nâ€¢ Security and privacy â†’Systems security; Distributed systems\nsecurity; â€¢ Computer systems organization â†’Reliability.\nKEYWORDS\nByzantine-fault tolerance, asynchronous consensus, optimsitic path\n1 INTRODUCTION\nThe explosive popularity of decentralization [ 21, 61] creates an\nunprecedented demand of deploying robust Byzantine fault tolerant\nâˆ—Authors are listed alphabetically. Yuan Lu and Zhenliang Lu contributed equally. A\npreliminary version of this paper will appear at ACM CCS 2022.\n(BFT) consensus on the global Internet. These consensus protocols\nwere conventionally abstracted as BFT atomic broadcast (ABC) to\nreplicate an ever-growing linearized log of transactions among ğ‘›\nparties [26]. Informally, ABC ensures Safety and Liveness despite\nthat an adversary controls the communication network (e.g., delay\nmessages) and corrupt some participating parties (e.g., ğ‘›/3). Safety\nensures all honest parties to eventually output the same log of\ntransactions, and liveness guarantees that any transaction inputted\nby some honest party eventually appears in honest partiesâ€™ logs.\nA desideratum for robust BFT in the absence of synchrony .\nThe dynamic nature of Internet poses new fundamental challenges\nfor implementing secure yet still highly efficient BFT consensus\nprotocols. Traditionally, most practical BFT protocols were stud-\nied for the in-house scenarios where participating parties are ge-\nographically close and well connected. Unsurprisingly, their se-\ncurities rely on some form of assumptions about the network\nconditions. For example, classic synchrony assumption needs all\nmessages to deliver within a known delay, and its weaker vari-\nant called partial synchrony [ 39] (a.k.a. eventual synchrony) as-\nsumes that after an unknown global stabilization time (GST), all\nmessages can be delivered synchronously. Unfortunately, these\nsynchrony assumptions may not always hold in the wide-area net-\nwork (WAN), because of fluctuating bandwidth, unreliable links,\nsubstantial delays, and even network attacks. Whatâ€™s worse, in an\nasynchronous network [9], such (partially) synchronous protocols\n[7, 8, 10, 11, 15, 29, 30, 47, 48, 66, 72] will grind to a halt (i.e., suffers\nfrom the inherent loss of liveness [40, 57]), and Bitcoin might even\nhave a safety issue of potential double-spending [ 69] when the\nadversary can arbitrarily schedule message deliveries. That said,\nwhen the network is adversarial, relying on synchrony could lead\nto fatal vulnerabilities.\nIt becomes a sine qua non to consider robust BFT consensus that\ncan thrive in the unstable or even adversarial Internet for mission-\ncritical applications (e.g., financial services or cyber-physical sys-\ntems). Noticeably, the class of fully asynchronous protocols [23, 38,\n50, 57, 73] can ensure safety and liveness simultaneously without\nany form of network synchrony, and thus become the arguably most\nrobust candidates for implementing mission-critical applications.\nFully asynchronous BFT? Robustness with a high price! Nev-\nertheless, the higher security assurance of asynchronous BFT con-\nsensus does not come for free: the seminal FLP â€œimpossibilityâ€ [40]\nstates that no deterministic protocol can ensure both safety and live-\nness in an asynchronous network. So asynchronous ABC must run\nrandomized subroutines to circumvent the â€œimpossibilityâ€, which\nalready hints its complexity. Indeed, few asynchronous protocols\nhave been deployed in practice during the past decades due to large\n1\narXiv:2103.09425v4  [cs.CR]  31 Aug 2022\ncomplexities, until the recent HoneyBadgerBFT [57] and Dumbo\nprotocols [50] (and very recent their improved variants [ 49, 73])\nprovide novel paths to practical asynchronous ABC in terms of re-\nalizing optimal linear communication cost per output transaction.\nDespite those recent progresses, the actual performance of state-\nof-the-art randomized asynchronous consensus is still far worse\nthan the deterministic (partial) synchronous ones (e.g., HotStuff\n[74]1), especially regarding the critical latency metric. For example,\nin the same WAN deployment environments consisting ofğ‘›=16, 64,\n100 Amazon EC2 instances across the globe, HotStuff is dozens of\ntimes faster than the state of the art Dumbo protocol [50]. Even\nworse, the inferior latency performance of asynchronous protocols\nstems from the fact that all parties generate some common ran-\ndomness (e.g., â€œcommon coinâ€ [24, 27]), and multiple repetitions\nare necessary to ensure the parties to coincidentally output with\nan overwhelming probability. Even if in one of the fastest existing\nasynchronous protocols such as Dumbo [50] and its improved ver-\nsion Speeding-Dumbo [49], they still cost about a dozen of rounds\non average. While for their (partial) synchronous counterparts, only\na very small number of rounds are required in the optimistic cases\nwhen the underlying communication network is luckily synchro-\nnous [6], e.g., 5 in the two-chain HotStuff and 3 in PBFT.\nThe above issues correspond to a fundamental â€œdilemmaâ€ lying\nin the design space of BFT consensus protocols suitable for the open\nInternet: the cutting-edge (partially) synchronous deterministic pro-\ntocols can optimistically work very fast, but lack liveness guarantee\nin adversarial networks; on the contrary, the fully asynchronous\nrandomized protocols are robust even in malicious networks, but\nsuffer from poor latency performance in the normal case. Facing\nthat, a natural question arises:\nCan we design a BFT consensus achieving the best of both\nsynchronous and asynchronous paradigms, such that it (i) is â€œas fast\nasâ€ the state-of-the-art deterministic BFT consensus on the normal\nInternet with fluctuations and (ii) performs nearly same to the\nexisting performant asynchronous BFT consensus even if in a\nworst-case asynchronous network?\n1.1 Our contributions\nWe answer the aforementioned question affirmatively, by present-\ning the firstpractical and generic framework for optimistic asynchro-\nnous atomic broadcast calledBolt-Dumbo Transformer (or BDT for\nshort). Here, optimistic asynchronous atomic broadcast [44, 54, 68]\nrefers to an asynchronous consensus that has a deterministic fast-\nlane that might luckily progress in the benign network environment\n(optimistic case) without randomized execution.\nAt a very high-level, BDT has three phases as shown in Fig. 1:\nâ€¢Fastlane (nickname Bolt): It initially runs a deterministic pro-\ntocol as fastlane to quickly progress in the optimistic case that\nsynchrony assumption holds.\nâ€¢Pace-synchronization (called pace-sync for short or nickname\nTransformer): If the fastlane fails to progress in time, a fast\npace-synchronization mechanism (analog to view-change with\n1Remark that [ 74] gave a 3-chain HotStuff protocol along with a 2-chain variant.\nThroughout the paper, we let HotStuff refer to the 2-chain version (with minor differ-\nence to fix the view-change issue) for the lower latency of the 2-chain version.\n \n \n \n \n \n \nBolt (Fastlane):\n    general and very fast but \n    vunerable w.r.t. liveness attacks\nDumbo (Pessimistic Path):\n   secure against arbitrary network\n   delay but suffer from slow execution\nTransformer (Pace-Sync):\n    use Binary BA only to decide how\n    many TXs were output via fastlane\nLevel-1 fallback if:\n  1. timeout (i.e., fastlane halts)\n  2. or TXs might be censored\nLevel-2 fallback if:\n   the fastlane did output nothing, \n   i.e., completely failed\nInit\nRestart\nfastlane\n1) New fastlane abstraction:\n     general for implementing  \n     and simplifies pace-sync\n2) Optimal pace-sync:\n     from heavy multi-value BA\n     to much simpler binary BA\n3) Two fallback levels: \n     reduce the runs of async\n     protocols in benign network\nBDT (Our Optimist. Async. Atomic Broadcast Framework)\nFigure 1: The overview of Bolt-Dumbo Transformer.\nasynchronous securities) is triggered to make all honest par-\nties agree on from where and how to restart (directly restart\nBolt or enter pessimistic path).\nâ€¢Pessimistic path (nickname Dumbo 2): In case the fastlane was\ncompletely failed to make progress, the honest parties enter a\npessimistic path of asynchronous BFT to ensure liveness even\nin the worst case.\nBDT is featured with guaranteed liveness and safety even in a\nhostile asynchronous network with optimal tolerance against ğ‘›/3\nbyzantine parties. More importantly, as depicted in Fig. 2, it indeed\nrealizes the best of its both paths, i.e., it is as fast as deterministic\nprotocols (such as the state-of-the-art pipeline BFT protocols, e.g.,\n2-chain HotStuff) in â€œgoodâ€ synchronous periods; and also as robust\nas asynchronous protocols in the â€œbadâ€ network.\n0\n1x10\n6\n2x10\n6\n3x10\n6\n4x106\n5x10\n6\n6x10\n6\n# of Confirmed TXs\n \nB D T\nExecution Time (sec)\n0 60 120 180 240\n D u m b o \nLevel-1\n fallback\nLevel-1\n fallback\nLevel-2\n fallback\nLevel-2\n fallback\n2-chain HotStuff\n\"Bad\" Network: 300ms-50Mbps\"Good\" Network: 50ms-200Mbps\nPace-Sync (BDT)\nFigure 2: Simulated executions of BDT, 2-chain HotStuff and\nDumbo-BFT under fluctuating network ( ğ‘›=64). Bad network\nhappens twice: one lasts 2 seconds and one lasts 120 seconds.\nSee Section 7 for the details on simulation setup.\nTechnical overview . Different from pioneering studies [ 10, 47,\n54, 68] that only demonstrated theoretic feasibility and had ques-\ntionable practicability because of complex and slow asynchronous\npace-synchronization (cf. Section 2 for detailed discussions on their\n2Here we call the pessimistic path Dumbo and call the concrete ABC protocol in [50]\nDumbo-BFT. The latter could be an instantiation for the former (as in our experiments),\nbut other better ABC protocol could also instantiate the former pessimistic path.\n2\nefficiency bottleneck), BDT makes several technical contributions\nto harvest the best of both paths in practice. In greater detail,\nA new fastlane abstraction better prepared for failures . To simplify\nthe complicated pace-sync, we propose a new fastlane abstrac-\ntion of notarizable weak atomic broadcast (nw-ABC for short) to\nprepare honest parties in a graceful condition when facing potential\nfastlane failures. Notably, nw-ABC realizes ABC in the optimistic\ncase, and only ensures â€œnotarizabilityâ€ otherwise: any output block\nis with a quorum proof to attest that sufficient honest parties have\nreceived a previous block (along with valid proof). Such annw-ABC\ncan be easily constructed to be very fast, e.g., from a sequence of\nsimple (provable) multicasts; and more importantly, the notarizabil-\nity (as we will carefully analyze) guarantees that any two honest\nparties will be at neighboring blocks when entering pace-sync, thus\nenables us to leverage simpler binary agreement to replace the cum-\nbersome full-fledged asynchronous atomic broadcast or multi-value\nagreement used in prior art [10, 47, 54, 68].\nCheapest possible pace-synchronization . More importantly, with the\npreparation of nw-ABC, Transformer reduces pace-sync to a prob-\nlem that we calltwo-consecutive-valued Byzantine agreement (tcv-BA),\nwhich is essentially an asynchronous binary Byzantine agreement\n(ABBA). In contrast, prior art [54, 68] leveraged cumbersome multi-\nvalued agreement (MVBA) for pace-sync (cf. Sec. 2 for a careful\nreview). Transformer thus improves the communication complexity\nof pace-sync by an O(ğ‘›)factor, and is essentially optimal for pace-\nsync, because the pace-sync problem can be viewed as a version\nof asynchronous consensus, and ABBA is the arguably simplest\nasynchronous consensus. In practice, Transformer attains a mini-\nmal overhead similar to the fastlane latency. Further care is needed\nfor invoking nw-ABC to ensure the safety (see next section).\nAvoiding pessimistic path whenever we can . To further exploit the\nbenefits brought by fast Transformer, we add a simple check after\npace-sync to create two-level fallbacks: if pace-sync reveals that\nthe fastlane still made some output, it immediately restarts another\nfastlane without running the actual pessimistic path. This is in con-\ntrast with previous works [54, 68] where the slow pessimistic path\nwill always run after each pace-sync, which is often unnecessarily\ncostly if there are only short-term network fluctuations. Remark\nthat the earlier studies cannot effectively adopt our two-level fall-\nback tactic, because their heavy pace-sync might bring extra cost\nand it may even nullify the advantages of the fastlane in case of\nfrequent fallbacks.\nGeneric framework enabling flexible instantiations . BDT is generic,\nas it enables flexible choices of the underlying building blocks for\nall three phases. For example, we present two exemplary fastlane\ninstantiations, resulting in two BDT implementations that favor\nlatency and throughput, respectively, so one can instantiate BDT\naccording to the actual application scenarios. Also,Transformer can\nbe constructed around any asynchronous binary agreement, thus\nhaving the potential of using any more efficient ABBA to further\nreduce the fallback overhead (e.g., by adopting the recent progress\nfrom Crain [33], Das et al. [ 36] and Zhang et al. [ 75]). Similarly,\nthough currently we use Dumbo-BFT as the pessimistic path, this\ncan be replaced by more efficient recent designs [49].\nExtensive evaluations. To demonstrate the practical performance\nof BDT, we implement the framework using Dumbo-BFT [50] as\nthe exemplary pessimistic path. We compare two typical BDT im-\nplementations to Dumbo and HotStuff, and conduct extensive ex-\nperiments in real-world/simulated environments.\nWe first deploy all protocols in the same real-world WAN envi-\nronment consisting of up to 100 Amazon EC2 c5.large instances\nacross the globe. Some highlighting experimental results could be\nfound in Table 1, which are: (i) the BDT implementation based on\nsequential multicasts can attain a basic latency about only 0.44\nsecond (i.e., nearly same to 2-chain HotStuffâ€™s and less than 3%\nof Dumboâ€™s latency), even if we intentionally raise frequent pace\nsynchronizations after every 50 optimistic blocks; (ii) in the worst\ncase that we intentionally make fastlane to always fail, the through-\nput of BDT remains 90% of Dumbo BFTâ€™s and is close to 20,000\ntransaction per second, even if we do let BDT wait as long as 2.5\nseconds to timeout before invoking pace-sync. Those demonstrate\nBDT can be â€œas fast asâ€ the deterministic protocols in normal cases\nand can maintain robust performance in the worst case.\nTo understand more scenarios in-between, we then conduct eval-\nuations in a controlled test environment that can simulate fluctuat-\ning network (i.e., switching between â€œgoodâ€ and â€œbadâ€ networks). In\nthe simulated good network (i.e., 50 ms packet delay and 200 Mbps\npeer-to-peer link), BDT is almost as fast as 2-chain HotStuff; while\nin the simulated bad network (i.e., 300 ms packet delay and 50 Mbps\npeer-to-peer link), BDT can closely track the performance of under-\nlying pessimistic asynchronous protocol, though HotStuff might\ngrind to a halt due to inappropriately chosen timeout parameter.\nSee Section 7 for more detailed experiment setup and results.\nTable 1: BDT, 2-chain HotStuff and Dumbo-BFT running over\n100 EC2 c5.large servers across 16 regions in 5 continents\nGood-Case v.s. HotStuff\n(fastlanes always complete)\nWorst-Case v.s. Dumbo\n(fastlanes always fail)\nBDT-sCASTâˆ—âˆ—BDT-sRBCâ€  HotStuffÂ§ BDT-Timeoutâ€¡ DumboBFT\nBasic latency (sec) 0.44 0.67 0.42 21.95 16.36\nThroughput (tx/sec)âˆ— 9,253 18,234 10,805 18,806 21,242\n* Each transaction has 250 bytes to approximate the basic Bitcoin transaction.\n** BDT-sCAST is BDT with using Bolt-sCAST, where Bolt-sCAST is the fastlane\ninstantiation built from pipelined multicasts.\nâ€  BDT-sRBC is BDT with using Bolt-sRBC, where Bolt-sRBC is the fastlane in-\nstantiation built from sequential reliable broadcasts.\nâ€¡ BDT-Timeout idles for 2.5 sec in the fastlane, and then runs Pace-Sync+Dumbo.\nÂ§ Reasons why our evaluations for HotStuff different from [74]: (i) we tested among\n16 AWS regions instead of one AWS region; (ii) we let the implementation to agree\non 250-byte tx instead of 32-byte tx hash; (iii) we use a single-process network\nlayer written in Python, differing from multi-processing network layer in [74].\n2 EFFICIENCY BOTTLENECK OF PRIOR ART\nAND OUR SOLUTION IN A NUTSHELL\nEfficiency obstacles in prior art . As briefly mentioned, pioneer-\ning works of Kursawe-Shoup [54] (KS02) and a following improve-\nment of Ramasamy-Cachin [68] (RC05) initiated the study of op-\ntimistic asynchronous atomic broadcast by adding a deterministic\nfastlane to fully asynchronous atomic broadcast, and they adopted\nmulti-valued validated Byzantine agreement (MVBA) to facilitate\nfallback once the fastlane fails to progress.\nNevertheless, these prior studies are theoretical in asynchronous\nnetworks, as they rely on heavyMVBA or even heavier full-fledged\n3\nstate-machine replication for fallback. Serious efficiency hurdle\nremains in such cumbersome fallback, thus failing to harvest the\nbest of both paths in practice. Let us first overview the remaining\nhurdles and design challenges.\nChallenge and effiency bottleneck lying in pace-synchronization . As\nFig. 3 illustrates, the fastlane of KS02 and RC05 directly employs a\nsequence of some broadcast primitives (the output of which is also\ncalled a block for brevity). If a party does not receive a block within\na period (defined by a timeout parameter), then it requests fallback\nby informing other parties about the index of the block that it just\nreceived. When the honest parties receive a sufficient number of\nfallback requests (e.g., 2ğ‘“ +1 in the presence of ğ‘“ faulty parties),\nthey execute the pace-synchronization mechanism to decide where\nto continue the pessimistic path.\nSince different honest parties may have different progress in the\nfastlane when they decide to fall back, e.g., some are now at block\n5, some at block 10, thus pace-synchronization needs to ensure: (i)\nall honest parties can eventually enter the pessimistic path from\nthe same block; and (ii) all the â€œmess-upsâ€ (e.g., missing blocks)\nleft by the fastlane can be properly handled. Both requirements\nshould be satisfied in an asynchronous network! These require-\nments hint that all the parties may need to agree on a block index\nthat is proposed by some honest party, otherwise they might decide\nto sync up to some blocks that were never delivered. Unfortunately,\ndirectly implementing such a functionality requires one-shot asyn-\nchronous (multi-valued) Byzantine agreement with strong validity\n(that means the output must be from some honest party), which is\ninfeasible because of inherent exponential communication [41].\n \nIf timeout: fallback\n...BroadCast2\nmulticast Complain \nIf enough \nvalid Complants\nOptimistic Fastlane\nPessimistic Path\nUse some Async Consensus\n(e.g., MVBA) to ensure honest \nnodes' inputs eventually output\nRestart\nfastlane\nSeveral cumbersome async. MVBAs\nDelivered Broadcasts\nPace Synchronization\n(Use MVBAs to decide from where to fallback)\nEnsure liveness by \nasync consensus\nCoin-Toss\nBroadCastsBroadCast1\nInit\nKS02 and RC05\nDeterministic, fast, but no liveness assurance\nBroadCast3\nFigure 3: Execution flow of KS02 [54] and RC05 [68]. Both\nrely on cumbersome asynchronous MVBA to do pace-sync.\nAs depicted in Fig. 3, both KS02 and RC05 smartly implement\npace-synchronization through asynchronous multi-valued vali-\ndated Byzantine agreement (MVBA) to get around the infeasible\nstrong validity. An MVBA is a weaker and implementable form of\nasynchronous multi-valued Byzantine agreement, the output of\nwhich is allowed to be from a malicious party but has to satisfy a\npredefined predicate. Still, MVBA is a cumbersome building block\n(and can even construct full-fledged asynchronous atomic broadcast\ndirectly [23]). Whatâ€™s worse, KS02 and RC05 invoke this heavy prim-\nitive for both pace-synchronization and pessimistic path, causing at\nleast O(ğ‘›3)-bit communication and dozens of rounds. Although we\nmay reduce the O(ğ‘›3)communication to O(ğ‘›2)by some very re-\ncent results (e.g., Dumbo-MVBA [56]), however, they remain costly\nin practice due to a large number of extra execution rounds and\nadditional computing costs (e.g., erasure encoding/decoding).\nSlow pace-sync remains in a more general framework [10] . Later,\nAublin et al. [10] studied a more general framework that is flexible\nto assemble optimistic fastlanes and full-fledged BFT protocols,\nas long as the underlying modules all satisfy a defined Abstract\nfunctionality. To facilitate fallback when the fastlane fails due to\nnetwork asynchrony or corruptions, [10] used a stronger version of\nAbstract variant with guaranteed liveness (called Backup). Backup\ncan guarantee all parties to output exact ğ‘˜ common transactions\n[10], so it can handle fallback by first finishing pace-sync, then\ndeciding some output transactions (i.e., running as the pessimistic\npath), and finally restarting the fastlane.\nAublin et al. [10] also pointed out that Backup (with guaranteed\nprogress) can be obtained from full-fledged BFT protocols. For\nexample, [10] gave exemplaryBackup instantiations based on PBFT\n[28] and Aardvark [31] in the partially synchronous setting. This\nindicated another feasible way to implement asynchronous fallback,\ni.e., implement Backup by full-fledged asynchronous BFT protocols.\nUnfortunately, when Backup is implemented via full-fledged\nasynchronous BFT, it would be as heavy asMVBA (or even heavier),\nsince most existing performant asynchronous BFT protocols are\neither constructed from MVBA [49, 50] or have implicit MVBA\n[44]. That said, though the framework presented in [ 10] is more\ngeneral than KS02 and RC05, it is not better than KS02 and RC05\nwith respect to the efficiency of pace-sync (and thus has the same\nefficiency bottleneck lying in pace-sync).\nIn contrast, we identify an extra simple property (not covered\nby Abstract [10]), so the new fastlane abstraction (1) enables us to\nutilize a much simpler asynchronous pace-synchronization, and (2)\nstill can be easily obtained with highly efficient instantiations.\nConsequences of slow pace-synchronization. The inefficient pace-sync\nseverely harms the practical effectiveness of adding fastlane. In\nparticular, when the network may fluctuate as in the real-world\nInternet, the pace-sync phase might be triggered frequently, and\nits high cost might eliminate the benefits of adding fastlane.\n \n \n \n \n....\nsync period sync period sync periodasync periodasync period\nFastlane Pace-sync Pessimistic path Pace-sync Pessimistic path\nasync period\nPace-sync Pessimistic path Pace-syncPace-sync Pessimistic path\n(a) Usual Unstable Network\n(b) Worst Async. Network\nFigure 4: Consequence of slow fallback in KS02/RC05 in fluc-\ntuating networks. The length of each phase denotes latency.\nTo see the issue, consider the heavy pace-sync of existing work\nthat is as slow as the asynchronous pessimistic path and dozens of\n4\ntimes slower than the fastlane.3 As Fig. 4 (a) exemplifies, although\nthe network stays in good conditions for the majority of time, the\noverall average latency of the protocol is still way larger than its\nfastlane. One slow fallback could â€œwasteâ€ the gain of dozens of\noptimistic blocks, and it essentially renders the optimistic fastlane\nineffective. In the extreme case shown in Fig. 4 (b), the fallback is\nalways triggered because the fastlane leaders are facing adaptive\ndenial-of-service attack, it even doubles the cost of simply running\nthe pessimistic asynchronous protocol alone.\nIt follows that in the wide-area Internet, inefficient pace syn-\nchronization in previous theoretical protocols likely eliminates the\npotential benefits of optimistic fastlane, and thus their applicability\nis limited. So a fundamental practical challenge remains to mini-\nmize the overhead of pace-sync, such that we can harvest the best\nof both paths in optimistic asynchronous atomic broadcast.\nOur Solution in a Nutshell . Now we walk through how we over-\ncome the above challenge and reduce the complex pace-sync prob-\nlem to only a variant of asynchronous binary agreement.\nFirst ingredient: a new abstraction of the fastlane . We put forth a new\nsimple fastlane abstraction called notarizable weak atomic broadcast\n(nw-ABC, with nickname Bolt). In the optimistic case, it performs\nas a full-fledged atomic broadcast protocol and can output a block\nper ğœ clock ticks. But if the synchrony assumption fails to hold,\nit wonâ€™t have liveness nor exact agreement, only a notarizability\nproperty can be ensured: whenever any party outputs a block at\nposition ğ‘— with a valid quorum proof, at least ğ‘“ +1 honest parties\nalready output at the position ğ‘—âˆ’1, cf. Fig. 5.\nHow â€œnotarizabilityâ€ better prepares honest parties? To see how no-\ntarizability simplifies pace-sync, let us examine the pattern of the\nhonest partiesâ€™ fastlane outputs before entering pace-sync.\nSuppose all honest parties have quit the fastlane, exchanged\ntheir fallback requests (containing their latest block index and the\ncorresponding quorum proof), received such2ğ‘“+1 fallback requests,\nand thus entered the pace synchronization. At the time, let ğ‘  to be\nthe largest index of all fastlane blocks with valid proofs.\nWe can make two easy claims: (i) no honest party can see a valid\nfallback request with an index equal or larger than ğ‘  +1; (ii) all\nhonest parties must see some fallback request with an index equal\nor larger than ğ‘ âˆ’1. If (i) does not hold, following notarizability, at\nleast one party can produce a proof for blockğ‘ +1, which contradicts\nthe definition of ğ‘ . While for (ii), since block ğ‘  is with a valid proof,\nat least ğ‘“ +1 honest parties received block ğ‘ âˆ’1 with valid proof.\nSo for any party waits for 2ğ‘“ +1 fallback requests, it must see at\nleast one fallback sent from some of these ğ‘“ +1 honest parties, thus\nseeing ğ‘ âˆ’1; otherwise, there would be 3ğ‘“ +2 parties.\nThe above two claims narrow the range of the honest partiesâ€™\nfallback positions to {ğ‘ âˆ’1,ğ‘ }, i.e., two unknown consecutive integers .\nSecond ingredient: async. agreement for consecutive values . Pace-sync\nnow is reduced to pick one value of two unknown consecutive\nintegers {ğ‘ âˆ’1,ğ‘ }. To handle the problem, we further define two-\nconsecutive-valued Byzantine agreement (tcv-BA), which can be eas-\nily implemented from any asynchronous binary Byzantine agree-\nment (cf. Section 5 for the concrete construction).\n3Actual situation might be much worse in RC02 [ 54] because several more MVBA\ninvocations with much larger inputs are executed in the pace-sync.\n \n \n \n \nProof1\nBlock1\nProof2\nBlock2\nProof3\nBlock3\nProof4\nBlock4\nProof5\nBlock5\nProof6\nBlock6 Block7\nProof1\nBlock1\nProof2\nBlock2\nProof1\nBlock1\nProof2\nBlock2\nProof3\nBlock3\nProof4\nBlock4\nProof5\nBlock5\nProof6\nBlock6\nProof1\nBlock1\nProof2\nBlock2\nProof3\nBlock3\nProof4\nBlock4\nProof5\nBlock5\nProof6\nBlock6\nA snapshot of all parties' local views of nw-ABC\nParty 1's \nParty 2's \nParty 3's \nParty 4's \n    Block  w/ valid proof âŸ¹  f+1 honest parties receive:7\n      1) all blocks through Block  to Block  w/ valid proofs 1 6\n      2) Block , though it might not be notarized by a proof     7\nBlock7\npossible\nno proof\nNotarizability\nProof7\nBlock7\npossible\nno proof\nFigure 5: Notarizability of fastlane abstraction ( nw-ABC).\nFinal piece of the puzzle: adding â€œsafe-bufferâ€ to the fastlane. When\ntcv-BA outputs ğ‘¢, all honest parties can sync up to block ğ‘¢accord-\ningly. Because no matterğ‘¢is ğ‘ or ğ‘ âˆ’1, theğ‘¢-th fastlane block is with\na valid quorum proof, so it can be retrieved due to notarizability (cf.\nFig. 5). Nevertheless, a subtle issue remains: tcv-BA cannot guaran-\ntee ğ‘¢ = ğ‘ , and thusğ‘¢could be ğ‘ âˆ’1. This is because an asynchronous\nadversary can always delay the messages of the honest parties that\ninput ğ‘  to make them seemingly crashed. That means, if a party\noutputs a fastlane block immediately when seeing its proof, it faces\na threat that the pace-sync returns a smaller index and revokes\nthe latest output fastlane block. This can even temporarily violate\nsafety requirement, if other parties output a different block after\npace-sync. To solve the issue, we introduce a â€œsafe bufferâ€ to let the\nnewest fastlane block be pending, i.e., not output until one more\nfastlane block with valid proof is received.\n3 OTHER RELATED WORK\nIn the past decades, asynchronous BFT protocols are mostly theo-\nretical results [2, 12â€“14, 20, 27, 32, 63, 64, 67], until several recent\nprogresses such as HoneyBadgerBFT [57], BEAT [38], Dumbo pro-\ntocols [49, 50, 56], VABA [5], DAG-based asynchronous protocols\n[34, 52], and DispersedLedger [73]. Nevertheless, they still have a\nlatency much larger than that of good-case partially synchronous\nprotocols. Besides the earlier discussed optimistic asynchronous\nconsensus [54, 68] and more general framework [10], Spiegelman\nrecently [71] used VABA [5] to instantiate pace-sync in optimistic\nasynchronous atomic broadcast. However, it is still inefficient, espe-\ncially when fallbacks frequently occur. BDT framework presents a\ngeneric and efficient solution to add a deterministic fastlane to most\nexisting asynchronous consensus protocols (except the DAG-based\nprotocols). For example, it is compatible with two very recent re-\nsults of DispersedLedger [73] and Speeding-Dumbo [49], and can\ndirectly employ them to instantiate more efficient pessimistic path.\nIt is well known that partially synchronous protocols [ 29, 74]\ncan be responsive after GST in the absence of failures. Nonetheless,\nif some parties are slow or even act maliciously, they might suffer\nfrom a worst-case latency related to the upper bound of network\ndelay. Some recent studies [4, 6, 48, 58, 66, 70] also consider synchro-\nnous protocols with optimistic responsiveness, such that when some\nspecial conditions were satisfied, they can confirm transactions\nvery quickly (with preserving optimal ğ‘›/2 tolerance). Our protocol\n5\nis responsive all the time, because it does not wait for timeout that\nis set as large as the upper bound of network delay in all cases.\nBesides, some literature [ 16â€“18, 55, 59] studied how to com-\nbine synchronous and asynchronous protocols for stronger and/or\nflexible security guarantees in varying network environment. We\ninstead aim to harvest efficiency from the deterministic protocols.\nConcurrent works. A concurrent work [ 45] considers adding an\nasynchronous view-change to a variant of HotStuff. Very recently\nits extended version [44] was presented with implementations. They\nfocus on a specific construction of asynchronous fallback tailored\nfor HotStuff by opening up a recent MVBA protocol [5], thus can\nhave different efficiency trade-offs. On the other hand, they cannot\ninherit the recent progress of asynchronous BFT protocols to pre-\nserve the linear per transaction communication (as we do) in the\npessimistic path, or future improvements (since BDT is generic).\nMoreover, [44] essentially still uses an MVBA to handle pace-sync,\nwhile we reduce the task to conceptual minimumâ€”a binary agree-\nment, which itself could have more efficient constructions.\n4 PROBLEM FORMULATION\nTransaction. Without loss of generality, we let a transaction de-\nnoted by tx to represent a string of |ğ‘š|bits.\nBlock structure . A block is a tuple in form of block := âŸ¨ğ‘’ğ‘ğ‘œğ‘â„,\nğ‘ ğ‘™ğ‘œğ‘¡, TXs,ProofâŸ©, where ğ‘’ğ‘ğ‘œğ‘â„ and ğ‘ ğ‘™ğ‘œğ‘¡ are natural numbers, TXs is\na sequence of transactions also known as the payload. Throughout\nthe paper, we assume|TXs|= ğµ, whereğµbe the batch size parameter.\nThe batch size can be chosen to saturate the networkâ€™s available\nbandwidth in practice. Proof is a quorum proof attesting that at\nleast ğ‘“ +1 honest parties indeed vote the block by signing it.\n \n \n \n \nepoch slot=1\nt x t x t x . . . T X s \nP r o o f \n. . . . . . \nb l o c k \nepoch slot=2\nt x t x t x . . . T X s \nP r o o f \nb l o c k \nepoch slot=3\nt x t x t x . . . T X s \nP r o o f \nb l o c k \nConsecutive l o g \nl o g [ 1 ] l o g [ 2 ] l o g [ 3 ] l o g [ L ] \nepoch slot=L\nt x t x t x . . . T X s \nP r o o f \nb l o c k \nFigure 6: Block and output log due to our terminology.\nBlocks as output log. Throughout the paper, alog (or interchange-\nably called asblocks) refers to an indexed sequence of blocks. Forlog\nwith length ğ¿:= |log|, we might use hereunder notations. (1) log[ğ‘–]\ndenotes the ğ‘–-th block in log. For example, log[1]is the first block\nof log, log[âˆ’1]is the alias of the last block inlog, and log[âˆ’2]repre-\nsents the second-to-last block in log, and so forth. (2)log.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(Â·)\ncan append some block to log. For example, when log.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(Â·)\ntakes a block â‰  âˆ…as input, |log|increases by one and log[âˆ’1]\nbecomes this newly appended block; when log.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(Â·)takes\na sequence of non-empty blocks [blockğ‘¥+1,..., blockğ‘¥+ğ‘˜]as in-\nput, |log|would increase by ğ‘˜, and log[âˆ’1]= blockğ‘¥+ğ‘˜, log[âˆ’2]=\nblockğ‘¥+ğ‘˜âˆ’1 and so on after the operation; whenlog.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(Â·)takes\nan empty block âˆ…as input, the ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘ operation does nothing.\nConsecutive output log. An output log consisting of ğ¿blocks is\nsaid to be consecutive if it satisfies: for any two successive blocks\nlog[ğ‘–]and log[ğ‘–+1]included by log, either of the following two\ncases is satisfied: (i)log[ğ‘–].ğ‘’ğ‘ğ‘œğ‘â„ = log[ğ‘–+1].ğ‘’ğ‘ğ‘œğ‘â„ and log[ğ‘–].ğ‘ ğ‘™ğ‘œğ‘¡+\n1 = log[ğ‘– +1].ğ‘ ğ‘™ğ‘œğ‘¡; or (ii) log[ğ‘–].ğ‘’ğ‘ğ‘œğ‘â„ +1 = log[ğ‘– +1].ğ‘’ğ‘ğ‘œğ‘â„ and\nlog[ğ‘–+1].ğ‘ ğ‘™ğ‘œğ‘¡ = 1. Without loss of generality, we let all logs to be\nconsecutive throughout the paper for presentation simplicity.\n4.1 Modeling the system and threats\nWe consider the standard asynchronous message-passing system\nwith trusted setup, which can be detailed as follows.\nKnown identities and trusted setup . There are ğ‘› designated\nparties, each of which has a unique identity (i.e., P1 through Pğ‘›)\nknown by everyone else. All involved threshold cryptosystems are\nproperly set up, so all parties can get and only get their own secret\nkeys in addition to relevant public keys. The setup can be done by\na trusted dealer or distributed key generation [3, 35, 37, 43, 46, 51,\n53, 65].\nByzantine corruptions. The adversary can choose up toğ‘“ parties\nto fully control before the protocol starts. Our instantiations focus\non static corruptions, which is same to all recentpractical asynchro-\nnous atomic broadcast [38, 49, 50, 57, 73]. Also, no asynchronous\nBFT can tolerate more than ğ‘“ = âŒŠ(ğ‘›âˆ’1)/3âŒ‹Byzantine corruptions.\nThrough the paper, we stick with this optimal resilience.\nFully-meshed reliable asynchronous network . There exists a\nreliable asynchronous peer-to-peer channel between any two par-\nties. The adversary can arbitrarily delay or reorder messages, but\ncannot drop or modify messages sent among honest parties.\nComputationally-bounded adversary . We consider computa-\ntionally bounded adversary that can perform some probabilistic\ncomputing steps bounded by polynomials in the number of message\nbits generated by honest parties, which is standard cryptographic\npractice in the asynchronous network.\nAdversary-controlling local â€œtimeâ€ . It is impossible to imple-\nment global time in the asynchronous model. Nevertheless, we do\nnot require any global wall-clock for securities. Same to [22, 54], it\nis still feasible to let each party keep an adversary-controlling local\nâ€œclockâ€ that elapses at the speed of the actual network delayğ›¿: each\nparty sends a â€œtickâ€ message to itself via the adversary-controlling\nnetwork, then whenever receiving a â€œtickâ€, it increases its local\nâ€œtimeâ€ by one and resends a new â€œtickâ€ to itself via the adversary.\nUsing the adversary-controlling â€œclockâ€, each party can maintain\na timeout mechanism, for example, let ğ‘¡ğ‘–ğ‘šğ‘’ğ‘Ÿ(ğœ).ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡()to denote\nthat a local timer is initialized and will â€œexpireâ€ after ğœ clock ticks,\nand let ğ‘¡ğ‘–ğ‘šğ‘’ğ‘Ÿ(ğœ).ğ‘Ÿğ‘’ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ ()denote to reset the timer.\n4.2 Security goal: async. atomic broadcast\nOur primary goal is to develop an asynchronous atomic broad-\ncast protocol defined as follows to attain high robustness against\nunstable or even hostile network environment.\nDefinition 4.1. In atomic broadcast (ABC), each party is with\nan implicit queue of input transactions (i.e., the input backlog) and\noutputs a log of blocks. Besides the syntax, the ABC protocol shall\nsatisfy the following properties with all but negligible probability:\nâ€¢Total-order. If an honest party outputs alog, and another honest\nparty outputs another logâ€², then log[ğ‘–]= logâ€²[ğ‘–]for every ğ‘–\nthat 1 â‰¤ğ‘– â‰¤min{|log|,|logâ€²|}.\nâ€¢Agreement. If an honest party adds a block to its log, all honest\nparties would eventually add the block to their logs.\nâ€¢Liveness (adapted from [23]). If all honest parties input a trans-\naction tx, tx would output within some asynchronous rounds\n(bounded by polynomials in security parameters).\n6\nRemarks on the definition of ABC. Throughout the paper, we let\nsafety refer to the union of total-order and agreement. Besides, we\ninsist on the liveness notion from [ 23] to ensure that each input\ntransaction can output reasonably quickly instead of eventually.\nThis reasonable aim can separate some studies that have exponen-\ntially large confirmation latency [12]. Moreover, the protocol must\nterminate in polynomial number of rounds to restrict the computing\nsteps of adversary in the computationally-secure model [5, 23, 62],\notherwise cryptographic primitives are potentially insecure.\n4.3 Performance metrics and preliminaries\nWe are particularly interested in practical asynchronous protocols,\nand therefore, consider the following critical efficiency metrics:\nâ€¢Communication complexity. We primarily focus on the (average)\nbits of all messages associated to output each block. Because\nthe communicated bits per block essentially reflects the (amor-\ntized) communication per delivered transaction, in particular\nwhen each block includes O(ğµ)-sized transactions, where ğµis\na specified batch-size parameter.\nâ€¢Message complexity. This characterizes the number of messages\nexchanged among honest parties to produce a block.\nâ€¢Asynchronous round complexity . The eventual delivery in asyn-\nchronous network causes the protocol execution independent\nto â€œreal timeâ€. Nevertheless, it is still needed to characterize\nthe running time, and a standard way to do so is counting\nasynchronous â€œroundsâ€ as in [23, 27].\nCryptographic abstractions. Hdenotes a collision-resistant hash\nfunction. TSIG and TPKE denote threshold signature and threshold\nencryption, respectively. Established TSIG is a tuple of algorithms\n(SignShareğ‘¡,VrfyShareğ‘¡,Combineğ‘¡,Vrfyğ‘¡), and throughout the pa-\nper, we call the signature share output from SignShareğ‘¡ the partial\nsignature, and call the output of Combineğ‘¡ the full signature . Es-\ntablished TPKE consists three algorithms (Encğ‘¡,DecShareğ‘¡,Decğ‘¡).\nIn all notations, the subscript ğ‘¡ represents the threshold, cf. some\nclassic literature such as [57]. The cryptographic security parameter\nis denoted by ğœ†, capturing the bit-length of signatures and hashes.\nBuilding blocks. We might use the following asynchronous broad-\ncast/consensus protocols in the black-box manner.\nDefinition 4.2. Reliable broadcast (RBC) has a designated sender\nwho aims to send its input to all parties, and satisfies the next prop-\nerties except with negligible probability: (i) Validity. If the sender is\nhonest and inputs ğ‘£, then all honest parties output ğ‘£; (ii) Agreement.\nThe outputs of any two honest parties are same; (iii) Totality. If an\nhonest party outputs ğ‘£, then all honest parties output ğ‘£.\nDefinition 4.3. Asynchronous binary Byzantine agreement\n(ABBA) [24, 27, 60] has a syntax that each party inputs and outputs\na single bit ğ‘, where ğ‘ranges over {0,1}, and shall guarantee the\nfollowing properties except with negligible probability: (i) Validity.\nIf any honest party outputs ğ‘, then at least one honest party takes\nğ‘ as input; (ii) Agreement. The outputs of any two honest parties\nare same; (iii) Termination. If all honest parties activate the protocol\nwith taking a bit as input, then all honest parties would output a\nbit in the protocol.\nDefinition 4.4. Asynchronous common subset ( ACS) [14] has\na syntax that each party input a value and output a set of values,\nwhere ğ‘›parties participate in this protocol and up to ğ‘“ corruption\nparties. It satisfies the next properties except with negligible proba-\nbility: (i) Validity. The output set S of an honest party contains the\ninputs of at least ğ‘›âˆ’2ğ‘“ honest parties; (ii) Agreement. The outputs\nof any two honest parties are same; (iii) Termination. If all honest\nparties activate the protocol, then all honest parties would output.\n5 ALLSPARK: FASTLANE ABSTRACTION\nAND TWO-CONSECUTIVE-VALUE BA\nThe simple and efficient pace-synchronization is the crux of making\nBDT practical, and this becomes possible for two critical ingredients,\ni.e., a novel fastlane abstraction ( nw-ABC) and a new variant of\nbinary Byzantine agreement (tcv-BA). Specifically,\nâ€¢nw-ABC ensures that all partiesâ€™ fastlane outputs are some-\nwhat weakly consistent, namely, if the(ğ‘ )-th block is the latest\nblock with valid quorum proof, then at least ğ‘“ +1 honest par-\nties must already output the (ğ‘  âˆ’1)-th block with the valid\nquorum proof (cf. Fig. 5).\nâ€¢Considering the above property of nw-ABC fastlane, we can\nconclude that: after exchanging timeout requests, all honest\nparties either know ğ‘  or ğ‘ âˆ’1. We thus lift the conventional\nbinary agreement to a special variant ( tcv-BA) for deciding\na common value out of {ğ‘ âˆ’1,ğ‘ }, despite that the adversary\nmight input arbitrarily, say ğ‘ âˆ’2 or ğ‘ +1.\n5.1 Abstracting and constructing the fastlane\nWe first put forth notarizable weak atomic broadcast (nw-ABC) to\nbetter prepare the fastlane for more efficient pace-sync.\nDefinition 5.1. Notarizable weak atomic broadcast (nw-ABC,\nnicknamed by Bolt). In the protocol with an identification id, each\nparty takes a transaction buffer as input and outputs alog of blocks,\nwhere each blocklog[ğ‘—]is in form ofâŸ¨id,ğ‘—, TXsğ‘—,Proofğ‘—âŸ©. There also\nexists two external functions Bolt.verify and Bolt.extract taking\nid, slot ğ‘— and Proofğ‘— as input (whose outputs and functionalities\nwould soon be explained below). We require that Bolt satisfies the\nfollowing properties except with negligible probability:\nâ€¢Total-order. Same to atomic broadcast.\nâ€¢Notarizability. If any (probably malicious) party outputslog[ğ‘—]:=\nâŸ¨id,ğ‘—, TXsğ‘—,Proofğ‘—âŸ©s.t. Bolt.verify(id,ğ‘—, Proofğ‘—)= 1, then: there\nexist at least ğ‘“ +1 honest parties, each of which either already\noutputs log[ğ‘—], or already outputs log[ğ‘—âˆ’1]and can invoke\nBolt.extract function with valid Proofğ‘— to extract log[ğ‘—]from\nreceived protocol scripts.\nâ€¢Abandonability. An honest party will not output any block\nin Bolt[id]after invoking abandon(id). In addition, if ğ‘“ +1\nhonest parties invoke abandon(id)before output log[ğ‘—], then\nno party can output valid log[ğ‘—+1].\nâ€¢Optimistic liveness . There exist a non-empty collection of opti-\nmistic conditions to specify the honesty of certain parties, s.t.\nonce an honest party outputs log[ğ‘—], it will output log[ğ‘—+1]\nin ğœ…asynchronous rounds, where ğœ…is a constant.\nComparing to ABC, nw-ABC does not have the exact agreement\nand liveness properties: (i) notarizability compensates the lack of\nagreement, as it ensures that whenever a party outputs a block\nlog[ğ‘—]at position ğ‘—, at least ğ‘“ +1 honest parties already output\n7\nat the position ğ‘—âˆ’1, and in addition, ğ‘“ +1 honest parties already\nreceive the protocol scripts carrying the payload of log[ğ‘—], so they\ncan extract the block log[ğ‘—]once seeing valid Proofğ‘—; (ii) liveness\nis in an optimistic form, which enables simple deterministic imple-\nmentations of nw-ABC in the asynchronous setting.\nCareful readers might notice that the above fastlane abstraction,\nin particular the notarizability property, share similarities with the\npopular lock-commit paradigm widely used in (partially) synchro-\nnous byzantine/crash fault tolerant protocols [8, 29, 39, 48, 74]. For\nexample, when any honest party outputs some value (i.e. â€œcommitâ€),\nthen at least ğ‘“ +1 honest parties shall receive and already vote this\noutput (i.e. â€œlockâ€). In such a sense, the fastlane can be easily instan-\ntiated in many ways through the lens of (partially) synchronous\nprotocols. Unsurprisingly, one candidate is the fastlane used in KS05\n[68]. Here we present two more exemplary Bolt constructions.\nComparing with the Abstract component in [10] . As aforementioned,\n[10] defined Abstract as a basic component to compose full-fledged\nBFT consensus with optimistic fastlane. Abstract was defined to\ncapture a very broad array of optimistic conditions (including very\noptimistic cases such as no fault at all), such that a fastlane satis-\nfying Abstract definition could be designed as simple as possible\n(with the price that no guarantee of similar progress among hon-\nest parties, as we have, before triggering fallback). For example,\n[10] presented Quorum, an implementation of Abstract that only\ninvolves one round trip (with an optimistic condition allowing no\nfault), but Quorum cannot meet the critical notarizability property\nof nw-ABC though satisfying Abstract. TakingQuorum as example,\nthe weakening of Abstract prevents us from using binary agree-\nment to handle some failed Abstract fastlanes, because the parties\ncannot reduce the failed position of the fastlane to two consecu-\ntive numbers. This corresponds to the necessity of our stronger\nnw-ABC definition in the context of facilitating a simplest possible\npace-sync in the asynchronous setting.\nBolt from sequential multicasts . As shown in Fig. 7, Bolt can be\neasily constructed from pipelined multicasts with using threshold\nsignature, and we call it Bolt-sCAST. The idea is as simple as: the\nleader proposes a batch of transactions via multicast, then all parties\nsend back their signatures on the proposed batch as their votes, once\nthe leader collects enough votes from distinct parties (i.e., 2ğ‘“ +1),\nit uses the votes to form a quorum proof for its precedent proposal,\nand then repeats to multicast a new proposal of transactions (along\nwith the proof). Upon receiving the new proposal and the precedent\nproof, the parties output the precedent proposal and the proof (as\na block), and then vote on the new proposal. Such execution is\nrepeated until the abandon interface is invoked.\nBolt from sequential reliable broadcast . As shown in Fig. 8, we\ncan also use sequential RBC instances to implement Bolt. In the\nimplementation, a designated fastlane leader can reliably broadcast\nits proposed transaction batches one by one. For each party receives\na batch from some RBC, it signs the batch andRBCâ€™s identifier, and\nmulticasts the signature as vote, then wait for 2ğ‘“ +1 valid votes to\nform a quorum proof, such that the batch and the proof assemble\nan output block, and the party proceeds into the next RBC. Note\nthat a RBC implementation [57] can use the technique of verifiable\ninformation dispersal [25] for communication efficiency as well\nas balancing network workload, such that the leaderâ€™s bandwidth\nlet id be the session identification of Bolt[id], buf be a FIFO queue of input, ğµbe\nthe batch parameter, and Pâ„“ be the leader (where â„“ = (id mod ğ‘›)+ 1)\nPğ‘– initializes ğ‘  = 1, ğœ0 = âŠ¥and runs the protocol in consecutive slot number ğ‘ as:\nâ€¢ Broadcast. if Pğ‘– is the leader Pâ„“\nâ€“ if ğ‘  > 1 then:\nâˆ— wait for 2ğ‘“ +1 Vote(id,ğ‘ âˆ’1,ğœğ‘ âˆ’1,ğ‘–)from distinct parties Pğ‘–, where ğœğ‘ âˆ’1,ğ‘–\nis the valid partial signature signed by Pğ‘– for âŸ¨id,ğ‘  âˆ’1,H(TXsğ‘ âˆ’1)âŸ©\nâˆ— compute ğœğ‘ âˆ’1, the full-signature for âŸ¨id,ğ‘ âˆ’1,H(TXsğ‘ âˆ’1)âŸ©, by aggregating\nthe 2ğ‘“ +1 received valid partial signatures\nâ€“ multicast proposal(id,ğ‘ , TXsğ‘ ,ğœğ‘ âˆ’1), where TXsğ‘  â†buf [: ğµ]\nâ€¢ Commit and Vote . upon receiving proposal(id,ğ‘ , TXsğ‘ ,ğœğ‘ âˆ’1)from Pâ„“\nâ€“ if ğ‘  > 1 then:\nâˆ— proceed only if ğœğ‘ âˆ’1 is valid full signature that aggregates 2ğ‘“ +1 partial\nsignatures for âŸ¨id,ğ‘  âˆ’1,H(TXsğ‘ âˆ’1)âŸ©, otherwise abort\nâˆ— output block:=(id,ğ‘  âˆ’ 1,TXsğ‘ âˆ’1,Proofğ‘ âˆ’1), where Proofğ‘ âˆ’1 :=\nâŸ¨H(TXsğ‘ âˆ’1),ğœğ‘ âˆ’1 âŸ©\nâ€“ send Vote(id,ğ‘ ,ğœğ‘ ,ğ‘–)to the leader Pâ„“, where ğœğ‘ ,ğ‘– is the partial signature for\nâŸ¨id,ğ‘ , H(TXsğ‘ )âŸ©, then let ğ‘  â†ğ‘ +1\nâ€¢ Abandon. upon abandon(id)is invoked then: abort the above execution\nFigure 7: Bolt from sequential multicasts ( Bolt-sCAST). The\nexternal functions are presented in Fig. 9.\nusage is at the same order of other partiesâ€™. In contrast,Bolt-sCAST\nmight cause the leaderâ€™s bandwidth usage ğ‘›times more than the\nother partiesâ€™, unless an additional mempool layer is implemented\nto further decouple the dissemination of transactions from Bolt.\nlet id be the session identification of Bolt[id], buf be a FIFO queue of input, ğµbe\nthe batch parameter, and Pâ„“ be the leader (where â„“ = (id mod ğ‘›)+ 1)\nPğ‘– initializes ğ‘  = 1, ğœ0 = âŠ¥and runs the protocol in consecutive slot number ğ‘ as:\nâ€¢ Broadcast. if Pğ‘– is the leader Pâ„“, activates RBC[âŸ¨id,ğ‘ âŸ©]with input TXsğ‘  â†\nbuf [: ğµ]; else activates RBC[âŸ¨id,ğ‘ âŸ©]as non-leader party\nâ€¢ Vote. upon RBC[âŸ¨id,ğ‘ âŸ©]returns TXsğ‘ \nâ€“ send Vote(id,ğ‘ ,ğœğ‘ ,ğ‘–) to all, where ğœğ‘ ,ğ‘– is the partial signature for\nâŸ¨id,ğ‘ , H(TXsğ‘ )âŸ©\nâ€¢ Commit. upon receiving2ğ‘“+1 Vote(id,ğ‘ ,ğœğ‘ ,ğ‘–)from distinct parties Pğ‘–, where\nğœğ‘ ,ğ‘– is the valid partial-signature signed by Pğ‘– for âŸ¨id,ğ‘ , H(TXsğ‘ )âŸ©\nâ€“ output block:=(id,ğ‘ , TXsğ‘ ,Proofğ‘ ), where Proofğ‘  := âŸ¨H(TXsğ‘ ),ğœğ‘ âŸ©and ğœğ‘ \nis the valid full signature that aggregates the 2ğ‘“ +1 partial signatures for\nâŸ¨id,ğ‘ , H(TXsğ‘ )âŸ©, then let ğ‘  â†ğ‘ +1\nâ€¢ Abandon. upon abandon(id)is invoked then: abort the above execution\nFigure 8: Bolt from sequential RBCs (Bolt-sRBC). The external\nfunctions are presented in Fig. 9.\n// Validate Proofğ‘  to check whether at least ğ‘“ +1 honest parties output the ğ‘ -th\nblock or can extract it (according to the next Bolt.extract function)\nexternal function Bolt.verify(id,ğ‘ , Proofğ‘ ):\nparse Proofğ‘  as âŸ¨â„ğ‘ ,ğœğ‘ âŸ©\nreturn TSIG.Vrfy2ğ‘“+1 (âŸ¨id,ğ‘ ,â„ğ‘ âŸ©,ğœğ‘ )\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n// Leverage the valid Proofğ‘  to extract the ğ‘ -th block from some received protocol\nmessages (though the block was not output yet).\nexternal function Bolt.extract(id,ğ‘ , Proofğ‘ ):\nif Bolt.verify(id,ğ‘ , Proofğ‘ )= 1, then parse Proofğ‘  as âŸ¨â„ğ‘ ,ğœğ‘ âŸ©\nif TXsğ‘  was received during executing Bolt s.t. â„ğ‘  = H(TXsğ‘ ), then:\nreturn block:=(id,ğ‘ , TXsğ‘ ,Proofğ‘ ), where Proofğ‘  := âŸ¨â„ğ‘ ,ğœğ‘ âŸ©\nreturn block:=(id,ğ‘ , âŠ¥,âŠ¥)\nFigure 9: Invocable external functions for Bolt instantiations\nAnalysis of the Bolt constructions. The security analyses ofBolt-\nsCAST and Bolt-sRBC are simple by nature (cf. Appendix A). Their\ncomplexities can be easily counted as well (cf. Appendix F).\n5.2 Two-consecutive-value BA\nAnother critical ingredient is a variant of binary agreement that can\nhelp the honest parties to choose one common integer out of two\nunknown but consecutive numbers. Essentially,tcv-BA extends the\nconventional binary agreement and can be formalized as follows.\n8\nDefinition 5.2. Two-consecutive-value Byzantine agreement\n(tcv-BA) satisfies termination, agreement and validity (same to\nthose of asynchronous binary agreement) with overwhelming prob-\nability, if all honest parties input a value in {ğ‘£,ğ‘£ +1}where ğ‘£ âˆˆN.\nFor each party Pğ‘–, make the following modifications to the ABBA code in Alg. 7\nof [50] (originally from [60] but with some adaptions to use Ethan MacBroughâ€™s\nsuggestion [1] to fix the potential liveness issues of [60]):\nReplace line 13-23 of Algorithm 7 in [50] with the next instructions:\nâ€¢ğ‘ â†Coinğ‘Ÿ.GetCoin()\nâ€“ if ğ‘†ğ‘Ÿ = {ğ‘£}then:\nâˆ— if ğ‘£%2 = ğ‘%2\nÂ· if ğ‘‘ğ‘’ğ‘ğ‘–ğ‘‘ğ‘’ğ‘‘ = false then: output ğ‘£; ğ‘‘ğ‘’ğ‘ğ‘–ğ‘‘ğ‘’ğ‘‘ = true\nÂ· else (i.e, ğ‘‘ğ‘’ğ‘ğ‘–ğ‘‘ğ‘’ğ‘‘ = true) then: halt\nâˆ— estğ‘Ÿ+1 â†ğ‘£\nâ€“ if ğ‘†ğ‘Ÿ = {ğ‘£1,ğ‘£2 }then:\nâˆ— if ğ‘£1%2 = ğ‘%2, then estğ‘Ÿ+1 â†ğ‘£1\nâˆ— else (i.e, ğ‘£2%2 = ğ‘%2), then estğ‘Ÿ+1 â†ğ‘£2\nFigure 10: tcv-BA protocol. Lines different to Alg. 7 in [50]\nare in orange texts.\nTo squeeze extreme performance of pace synchronization, we\ngive a non-black-box construction tcv-BA that only has to revise\nthree lines of code of the practicalABBA construction adapted from\n[60]. This non-black-box construction basically reuses the protocol\npseudocode except several if-else checking (see Fig. 10) and hence\nhas the same performance of this widely adopted ABBA protocol.\nIn addition, tcv-BA can be constructed from any ABBA with\nonly one more â€œmulticastâ€ round, cf. Figure 11. This black-box\nconstruction provides us a convenient way to inherit any potential\nimprovements of underlying ABBA primitives [33, 36].\nLet ABBA be any asynchronous binary agreement, then party Pğ‘– executes:\nUpon receiving input ğ‘…then:\nâ€¢ multicast Value(id,ğ‘…)\nâ€¢ upon receiving Value(id,ğ‘…â€²)from ğ‘“ +1 parties containing the same ğ‘…â€²\nâ€“ if Value(id,ğ‘…â€²)has not been sent before, then: multicast Value(id,ğ‘…â€²)\nâ€¢ wait for receiving 2ğ‘“ +1 Value(id,ğ‘£)messages from distinct parties carrying\nthe same ğ‘£, and activate ABBA[id]with ğ‘£%2 as input\nâ€¢ wait for ABBA[id]returns ğ‘:\nâ€“ if ğ‘£%2 = ğ‘, then: return ğ‘£\nâ€“ else: wait for receiving ğ‘“ +1 Value(id,ğ‘£â€²)messages from distinct parties\ncontaining the same ğ‘£â€²such that ğ‘£â€²%2 = ğ‘, then return ğ‘£â€²\nFigure 11: tcv-BA protocol built from any ABBA â€œblack-boxâ€\n6 Bolt-Dumbo Transformer FRAMEWORK\nAs Fig. 12 outlines, the fastlane ofBDT is aBolt instance wrapped by\na timer. If honest parties can receive a new Bolt block in time, they\nwould restart the timer to wait for the next Bolt block. Otherwise,\nthe timer expires, and the honest parties multicast a fallback request\ncontaining the latest Bolt blockâ€™s quorum proof that they can see.\nAfter timeout, each party waits for ğ‘›âˆ’ğ‘“ fallback requests with\nvalid Bolt block proofs, and enters pace-sync. They invoke tcv-BA\nwith using the maximum block index (slot) in the received fallback\nrequests as input. Eventually, the honest parties enter the tcv-BA\nand decide to either retry the fastlane or start the pessimistic path.\nAs we briefly mentioned before, the reason we can use such a simple\nversion of binary agreement is that via a careful analysis, we can\nfind that nw-ABC prepares all honest parties will entertcv-BA with\none of neighboring indices as input.\nBlocks-1\nProofs-1\n...\nP1\nP2\nP3\nP4\nP1\nP2\nP3\nP4\nP1\nP2\nP3\nP4\nP1\nP2\nP3\nP4\nP1\nP2\nP3\nP4\ntcv-BA\nACS\nMVBA\n   etc.\nOptimistic Fastlane Pace-Sync Pessimistic Path\n(s, Proof )s\nIf: s=0\nmax({s})\nIf: Bolt still works (s>0)\nPending\nBlocks\nProofs\nIf: Bolt completely fails (s=0)\nTimeout\nFinalized\ns\nBolt Transformer Dumbo\nFigure 12: The execution flow of Bolt-Dumbo Transformer\nThe remaining non-triviality is that tcv-BA cannot ensure its\noutput to always be the larger number out of the two possible inputs,\nthat means the globally latest Bolt block can be revoked after pace-\nsync. Hence, the latest fastlane block is marked as â€œpendingâ€, and a\nâ€œpendingâ€ block is finally output until the fastlane returns another\nnew block. This pending fastlane block ensures safety in BDT.\nProtocol details. BDT is formally illustrated in Fig. 13. It employs\na reduction to nw-ABC, tcv-BA, and some asynchronous consensus\n(e.g., ACS). Informally, it proceeds as follows by successive epochs:\n(1) Bolt phase. When an honest party enters an epochğ‘’, it activates\na Bolt[ğ‘’]instance, and locally starts an adversary-controlling\nâ€œtimerâ€ that expires afterğœclock â€œticksâ€ and resets once hearing\nthe â€œheartbeatâ€ of Bolt[ğ‘’](e.g., Bolt[ğ‘’]returns a new block). If\none party receives a new Bolt[ğ‘’]block in time without â€œtime-\noutâ€, it temporarily records the block as pending, finalizes\nthe previous (non-empty) pending block as BDTâ€™s output, and\nsets its â€œpaceâ€ ğ‘ğ‘’ to the new blockâ€™s slot number. Otherwise,\nthe â€œtimeoutâ€ mechanism interrupts, and the party abandons\nBolt[ğ‘’]. Beside the above â€œtimeoutâ€ mechanism to ensure Bolt\nprogress in time, we also consider that some transactions are\nprobably censored: if the oldest transaction (at the top of the\ninput backlog) is not output for a durationğ‘‡, an interruption is\nalso raised to abandon Bolt[ğ‘’]. Once a party abandons Bolt[ğ‘’]\nfor any above reason, it immediately multicasts latest â€œpaceâ€ğ‘ğ‘’\nwith the corresponding blockâ€™s proof via a PaceSync message.\n(2) Transformer phase. If an honest party receives ( ğ‘›âˆ’ğ‘“) valid\nPaceSyncmessages from distinct parties w.r.t.Bolt[ğ‘’], it enters\nTransformer. In the phase, the party chooses the maximum\nâ€œpaceâ€ maxPace out of the ğ‘› âˆ’ğ‘“ â€œpacesâ€ sent from distinct\nparties, and it would use this maxPace as input to invoke the\ntcv-BA[ğ‘’]instance. When tcv-BA[ğ‘’]returns a valuesyncPace,\nall parties agree to continue from the syncPace-th block in\ntcv-BA[ğ‘’]. In some worse case that a party did not yet receive\nall blocks up to syncPace, it can fetch the missing blocks from\nother parties by calling the CallHelp function (cf. Fig. 14).\n(3) Pessimistic phase. This phase may not be executed unless the\noptimistic fastlane of the current epochğ‘’makes no progress at\nall, i.e, syncPace = 0. In the worst case, Pessimistic is invoked\nto guarantee that some blocks (e.g., one) can be generated de-\nspite an adversarial network or corrupt leaders, which becomes\nthe last line of defense to ensure the critical liveness.\nHelp and CallHelp. Besides the above main protocol procedures, a\nparty might invoke the CallHelp function to broadcast a CallHelp\nmessage, when it realizes that some fastlane blocks are missing.\n9\nAs Fig. 14 illustrates, CallHelp messages specify which blocks\nto retrieve, and every party also runs a Help daemon to handle\nCallHelp messages. Actually, any honest party that invokesCallHelp\ncan eventually retrieve the missing blocks, because at least ğ‘“ +1\nhonest parties indeed output the blocks under request. The Help\ndaemon can also use the techniques of erasure-code and Merkle\ncommitment tree in verifiable information dispersal [25, 57], such\nthat it only responds with a coded fragment of the requested blocks,\nthus saving the overall communication cost by an O(ğ‘›)order.\nAlternative pessimistic path. The exemplary Pessimistic path\ninvokes Dumbo to output one single block. Nonetheless, this is\nnot the only design choice. First, BDT is a generic framework, and\nthus it is compatible with many recent asynchronous BFT protocols\nsuch as DispersedLedger [73] and not restricted to Dumbo. Second,\nthere could be some global heuristics to estimate how many blocks\nneeded to generate during the pessimistic path according to some\npublic information (e.g., how many times the fastlane completely\nfails in a stream). Designing such heuristics to better fit real-world\nInternet environments could be an interesting engineering question\nto explore in the future but does not impact any security analysis.\nSecurity intuitions. We brief the security intuitions ofBDT in the\nfollowing, and defer detailed proofs to Appendix C for space limit.\n// Optimistic Path (also the BDT protocolâ€™s main entry)\nEvery party Pğ‘– runs the protocol in consecutive epoch numbered ğ‘’(initialized as 1) as follows:\nâ€¢ initialize: ğ‘ğ‘’ â†0, Proofğ‘’ â†âŠ¥, Pacesğ‘’ â†{}, pendingğ‘’ â†âˆ…\nâ€¢ activate Bolt[ğ‘’]instance, and start a timer that expires if not being restarted after ğœclock â€œticksâ€ (i.e., invoke ğ‘¡ğ‘–ğ‘šğ‘’ğ‘Ÿ(ğœ).ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ ())\nâ€¢ upon Bolt[ğ‘’]delivers a block:\nâ€“ parse block:=âŸ¨ğ‘’,ğ‘, TXsğ‘,Proofğ‘âŸ©, where ğ‘is the â€œslotâ€ number\nâ€“ log.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(pendingğ‘’), buf â†buf \\{TXs in pendingğ‘’}, pendingğ‘’ â†block //finalized the elder pending block, pending the newly fastlane block\nâ€“ ğ‘ğ‘’ â†ğ‘, Proofğ‘’ â†Proofğ‘, ğ‘¡ğ‘–ğ‘šğ‘’ğ‘Ÿ(ğœ).ğ‘Ÿğ‘’ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ // Bolt[ğ‘’]makes progress in time, so restart the â€œheartbeatâ€ timer\nâ€¢ upon ğ‘¡ğ‘–ğ‘šğ‘’ğ‘Ÿ(ğœ)expires or the front tx in the backlog buf was buffered ğ‘‡ clock â€œticksâ€ ago:\nâ€“ invoke Bolt[ğ‘’].abandon()and multicast PaceSync(ğ‘’,ğ‘ğ‘’,Proofğ‘’) // the fastlane is probably stucking or censoring certain transactions\nâ€¢ upon receiving message PaceSync(ğ‘’,ğ‘ğ‘—\nğ‘’,Proofğ‘—\nğ‘’)from Pğ‘— for the first time:\nâ€“ if Bolt.verify(ğ‘’,ğ‘ğ‘—\nğ‘’,Proofğ‘—\nğ‘’)= 1: Pacesğ‘’ â†Pacesğ‘’ âˆªğ‘ğ‘—\nğ‘’\nâ€“ if |Pacesğ‘’|= ğ‘›âˆ’ğ‘“: // enough parties have already quitted the fastlane\nâˆ— invoke Transformer(e) and wait for its return to continue // enter into the pace-synchronization phase\nâˆ— proceed to the next epoch ğ‘’ â†ğ‘’+1 // restart the fastlane of next epoch\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n// Pace Synchronization\ninternal function Transformer(ğ‘’): // internal function shares all internal states of the BDT protocol\nâ€¢ let maxPaceğ‘’ â†max(Pacesğ‘’)and then syncPaceğ‘’ â†tcv-BA[ğ‘’](maxPaceğ‘’) // see Fig. 10 or 11 for concrete implementations of tcv-BA\nâ€¢ if syncPaceğ‘’ > 0:\nâ€“ send PaceSync(ğ‘’,syncPaceğ‘’,Proof)to all if syncPaceğ‘’ âˆˆPacesğ‘’, where Bolt.verify(ğ‘’,syncPaceğ‘’,Proof)= 1\nâ€“ if syncPaceğ‘’ = ğ‘ğ‘’: log.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(pendingğ‘’)and buf = buf \\{TXs in pendingğ‘’}\nâ€“ if syncPaceğ‘’ = ğ‘ğ‘’ +1:\nâˆ— wait for a valid PaceSync(ğ‘’,syncPaceğ‘’,Proof), then blockâ€²â†Bolt.extract(ğ‘’,syncPaceğ‘’,Proof)// try to extract the missing block\nâˆ— if blockâ€²is in form of (ğ‘’,syncPaceğ‘’,âŠ¥,âŠ¥), then: blockâ€²â†CallHelp(ğ‘’,ğ‘ğ‘’,1)// failed to extract, have to rely on other parties to fetch, cf. Fig. 14\nâˆ— log.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(pendingğ‘’).ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(blockâ€²)and buf = buf \\{TXs in pendingğ‘’ and blockâ€²}\nâ€“ if syncPaceğ‘’ > ğ‘ğ‘’ +1: blocks â†CallHelp(ğ‘’,ğ‘ğ‘’,syncPaceğ‘’ âˆ’ğ‘ğ‘’)// contact other parties to fetch missing fastlane blocks, cf. Fig. 14\nâˆ— log.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(pendingğ‘’).ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(blocks)and buf = buf \\{TXs in pendingğ‘’ and blocks}\nâ€“ continue Optimistic Path with ğ‘’ â†ğ‘’+1\nâ€¢ if syncPaceğ‘’ = 0: invoke Pessimistic(e) and wait for its return, then continue Optimistic Path with ğ‘’ â†ğ‘’+1\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n// Pessimistic Path\ninternal function Pessimistic(ğ‘’): // internal function shares all internal states of the BDT protocol\nâ€¢ txsğ‘– â†randomly select âŒŠğµ/ğ‘›âŒ‹-sized transactions from the first ğµ-sized transactions at the top of buf\nâ€¢ ğ‘¥ğ‘– â†TPKE.Enc(ğ‘’ğ‘ğ‘˜,txsğ‘–), namely, encrypt txsğ‘– to obtain ğ‘¥ğ‘–\nâ€¢ {ğ‘¥ğ‘—}ğ‘—âˆˆğ‘† â†ACS[ğ‘’](ğ‘¥ğ‘–), where ğ‘† âŠ‚[ğ‘›]and |ğ‘†|â‰¥ ğ‘›âˆ’ğ‘“\nâ€¢ For each ğ‘— âˆˆğ‘†, jointly decrypt the ciphertext ğ‘¥ğ‘— to obtain txsğ‘—, so the payload TXs = Ã\nğ‘—âˆˆğ‘† txsğ‘— â†{TPKE.Dec(ğ‘’ğ‘ğ‘˜,ğ‘¥ ğ‘—)}ğ‘—âˆˆğ‘†\nâ€¢ let block := âŸ¨ğ‘’,1,TXs,âŠ¥âŸ©, then log.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(block)and buf = buf \\{TXs in block}\nFigure 13: The Bolt-Dumbo Transformer (BDT) protocol\n// The Help daemon process\nHelp: It is a daemon process that can read the finalized output log of Bolt-Dumbo Transformer, and it listens to the down below event:\nâ€¢ upon receiving message CallHelp(ğ‘’,tip,gap)from party Pğ‘— for the first time:\nâ€“ assert 1 â‰¤gap â‰¤ğ¸ğ‘ ğ‘–ğ‘§ğ‘’\nâ€“ wait for log containing the block := âŸ¨ğ‘’,tip +gap,âˆ—,âˆ—âŸ©\nâ€“ let ğ‘€ â†retrieve all blocks in log from block := âŸ¨ğ‘’,tip +1,âˆ—,âˆ—âŸ©to block := âŸ¨ğ‘’,tip +gap,âˆ—,âˆ—âŸ©\nâˆ— let {ğ‘šğ‘˜}ğ‘˜âˆˆ[ğ‘›]be the fragements of a (ğ‘›âˆ’2ğ‘“,ğ‘› )-erasure code applied to ğ‘€and â„be a Merkle tree root computed over {ğ‘šğ‘˜}ğ‘˜âˆˆ[ğ‘›]\nâˆ— send Help(ğ‘’,tip,gap,â„,ğ‘šğ‘–,ğ‘ğ‘–)to Pğ‘— where ğ‘šğ‘– is the ğ‘–-th erasure-code fragement of ğ‘€and ğ‘ğ‘– is the ğ‘–-th Merkle tree branch\n// The CallHelp function\nexternal function CallHelp(ğ‘’,tip,gap):\nâ€¢ let ğ¹ â†[] to be a dictionary structure such that ğ¹[â„]can store all leaves committed to Merkle tree root â„\nâ€¢ multicast message CallHelp(ğ‘’,tip,gap)\nâ€¢ upon receiving the message Help(ğ‘’,tip,gap,â„,ğ‘š ğ‘—,ğ‘ğ‘—)from party Pğ‘— for the first time:\nâ€“ if ğ‘ğ‘— is a valid Merkle branch for root â„and leaf ğ‘šğ‘— then: ğ¹[â„]â† ğ¹[â„]âˆª( ğ‘—,ğ‘šğ‘—); otherwise discard the message\nâ€“ if |ğ¹[â„]|= ğ‘›âˆ’2ğ‘“ then:\nâˆ— interpolate the ğ‘›âˆ’2ğ‘“ leaves stored in ğ¹[â„]to reconstruct ğ‘€, then parse ğ‘€as a sequence of blockğ‘ and return blockğ‘ \nFigure 14: Help and CallHelp. Help is a daemon process having access to the output log, and CallHelp is a function to call Help\n10\nSafety. The core ideas of proving agreement and total-order are:\nâ€¢Transformer returns a common index . All honest parties must\nobtain the same block index from Transformer, so they always\nagree the same fastlane block to continue the pessimistic path\n(or retry the fastlane). This is ensured by tcv-BAâ€™s agreement.\nâ€¢Transformer returns an index not â€œtoo largeâ€ . For the index\nreturned from Transformer, at least ğ‘“ +1 honest parties did\nreceive all blocks (with valid proofs) up to this index. As such,\nif any party misses some blocks, it can easily fetch the correct\nblocks from these ğ‘“ +1 parties. This is because the notariz-\nability of Bolt prevents the adversary from forging a proof\nfor a fastlane block with an index higher than the actually\ndelivered block. So no honest party would input some index\nof an irretrievable block to tcv-BA, and then the validity of\ntcv-BA simply guarantees the claim.\nâ€¢Transformer returns an index not â€œtoo smallâ€ . No honest party\nwould revoke any fastlane block that was already committed\nas a finalized output. Since each honest party waits for 2ğ‘“ +\n1 PaceSync messages from distinct parties, then due to the\nnotarizability of Bolt, there is at least one PaceSync message\ncontains ğ‘ âˆ’1, where ğ‘  is the latest fastlane block (among all\nparties). So every honest party at least inputstcv-BA with ğ‘ âˆ’1.\nThe validity of tcv-BA then ensures the output at least to be\nğ‘  âˆ’1 as well. Recall that there is a â€œsafe bufferâ€ to hold the\nlatest fastlane block as a pending one, the claim is then correct.\nâ€¢Pessimistic path and fastlane are safe . Pessimistic path is triv-\nially safe due to its agreement and total order. Fastlane has\ntotal-order by definition, and its weaker agreement (notariz-\nability) is complemented by Transformer as argued above.\nLiveness. This stems from the liveness of all three phases. The\nliveness of fastlane is guaranteed by the â€œtimeoutâ€ parameter ğœ.\nThat means, all honest parties can leave the fastlanes without â€œget-\nting stuckâ€. After that, all parties would invoke tcv-BA and obtain\nsyncPace as the tcv-BA output due to the termination of tcv-BA;\nmoreover, if any honest party realizes that it misses some fastlane\nblocks after obtaining syncPace, it can sync up to syncPace within\nonly two asynchronous rounds, because at leastğ‘“ +1 honest parties\ncan help it to fetch the missing blocks. So no honest party would\nâ€œstuckâ€ during the Transformer phase. Finally, the honest parties\nwould enter the Pessimistic phase if the fastlanes completely fail\nto output nothing. After that, the protocol must output expected\nO(ğµ)-sized transactions, and ensures that any transactions (at the\nğµ-top of all honest partiesâ€™ backlogs) can output with a constant\nprobability, thus ensuring liveness even if in the worst case.\nEfficiency analysis. The complexities can be analyzed by count-\ning these of each underlying module. Overall, BDT would cost\n(expected) O(ğ‘›)communicated bits per output transaction, and\nthe latency of each output block is of expected constant rounds.\nThese complexities hold in all cases (no matter the network is syn-\nchronous or asynchronous). We defer such tedious counting on the\nnumber of exchanged bits and execution rounds to Section F.\nOptimistic conditions. BDT has a simple and efficient determinis-\ntic fastlane that might keep on progressing under certain optimistic\nconditions, which intuitively are: (i) the actual network delay is\nsmaller than some guessed timing parameter and (ii) the leader of\nfastlane is honest. In Appendix D, we discuss why such optimistic\nconditions can ensure the progress of fastlanes.\n7 PERFORMANCE EVALUATION\nImplementation details . We program the proof-of-concept im-\nplementations of BDT, Dumbo and 2-chained HotStuff in the same\nlanguage (i.e. Python 3), with using the same libraries and secu-\nrity parameters for all cryptographic implementations. The BFT\nprotocols are implemented by single-process code. Besides, a com-\nmon network layer is programmed by using unauthenticated TCP\nsockets. The network layer is implemented as a separate Python\nprocess to provide non-blocking communication interface.\nFor common coin, it is realized by hashing Boldyrevaâ€™s pairing-\nbased unique threshold signature [19] (implemented over MNT224\ncurve). For quorum proofs, we concatenate ECDSA signatures (im-\nplemented over secp256k1 curve). For threshold public key en-\ncryption, the hybrid encryption approach implemented in Honey-\nBadger BFT is used [ 57]. For erasure coding, the Reed-Solomon\nimplementation in the zfec library is adopted. For timeout mech-\nanism, we use the clock in each EC2 instance to implement the\nlocal time in lieu of the adversary-controlling â€œclockâ€ in our for-\nmal security model. Our proof-of-concept codebase is available at\nhttps://github.com/yylluu/BDT.\nFor notations, BDT-sCAST denotes BDT using Bolt-sCAST as\nfastlane, while BDT-sRBC denotes the other instantiation using\nBolt-ğ‘ RBC. In addition, BDT-Timeout denotes to use an idle fast-\nlane that just waits for timeout, which can be used as benchmark\nto â€œmimicâ€ the worst case that the fastlanes always output nothing\ndue to constant denial-of-service attacks.\nDue to space limitation, we only presented most intuitive exper-\niments here, more evaluations can be found in Appendix E.\n7.1 Evaluations in wide-area network\nSetup on Amazon EC2 . To demonstrate the practicability ofBDT\nin realistic wide-area network (WAN), we evaluate it among Ama-\nzon EC2 c5.large instances (2 vCPUs and 4 GB RAM) for ğ‘›=64 and\n100 parties, and also test Dumbo and HotStuff in the same setting\nas reference points. All EC2 instances are evenly distributed in\n16 AWS regions, i.e., Virginia, Ohio, California, Oregon, Central\nCanada, SÃ£o Paulo, Frankfurt, Ireland, London, Paris, Stockholm,\nMubai, Seoul, Singapore, Tokyo and Sydney. All evaluation results\nin the WAN setting are measured back-to-back and averaged over\ntwo executions (each run for 5-10 minutes).\nIn the WAN setting tests, we might fix some parameters ofBDT to\nintentionally amplify the fallback cost. For example, let each fastlane\ninterrupt after output only 50 blocks, so Transformer is frequently\ninvoked. We also set the fastlaneâ€™s timeout parameter ğœ as large as\n2.5 sec (nearly twenty times of the one-way network latency in our\ntest environment), so all fallbacks triggered by timeout would incur\na 2.5-second overhead in addition to the Transformerâ€™s latency.\nBasic latency. We firstly measure the basic latency to reflect how\nfast the protocols are (in the good cases without faults or timeouts),\nif all blocks have nearly zero payload (cf. Fig. 15). This provides\nus the baseline understanding about how fast BDT, HotStuff and\nDumbo can be to handle the scenarios favoring low-latency.\n11\n0\n.395630 .425690.403090 .431760.675630 .698087\n.744021\n6.360\n.395630 .425690.403090 .431760.675630 .698087\n.744021\n6.366\n41 00024681012141618Basic latency (second)S\ncale (# of parties) \nHotStuff-no-fault BDT-sCAST-no-fault BDT-sRBC-no-fault Dumbo-no-fault\nFigure 15: Basic latency in experiments over WAN for two-\nchain HotStuff, BDT-sCAST, BDT-sRBC and Dumbo.\nWhen ğ‘›= 100, BDT-sCAST is 36x faster than Dumbo, and BDT-\nsRBC is 23x faster than Dumbo; when ğ‘› = 64, BDT-sCAST is 18x\nfaster than Dumbo, and BDT-sRBC is 10x faster thanDumbo; more-\nover, the execution speed of both BDT-sCAST and BDT-sRBC are\nat the same magnitude of HotStuff. In particular, the basic latency\nof BDT-sCAST is almost as same as that of 2-chainHotstuff, which\nis because the fastlane of BDT-sCAST can be thought of a stable-\nleader 2-chain Hotstuff and its optimistic latency has five rounds 4,\ni.e., same to that of 2-chain Hotstuff.\nPeak throughput. We then measure throughput in unit of trans-\nactions per second (where each transaction is a 250 bytes string\nto approximate the size of a typical Bitcoin transaction). The peak\nthroughput is depicted in Fig. 16, and gives us an insight how well\nBDT, HotStuff and Dumbo can handle transaction burst. 5\n1\n43831 0805118329 2532\n42761\n8234267722\n12421\n43831 0805118329 2532\n42761\n8234267722\n12426\n41 0001\n0k2\n0k3\n0k4\n0kMaximum throughput (tps)S\ncale (# of parties) \nHotStuff-no-fault BDT-sCAST-no-fault BDT-sRBC-no-fault Dumbo-no-fault\nFigure 16: Peak throughput in experiments over WAN for\ntwo-chain HotStuff, BDT-sCAST, BDT-sRBC and Dumbo.\nBDT-sCAST realizes a peak throughput about 85% of HotStuffâ€™s\nwhen either ğ‘›is 100 or 64, BDT-sRBC achieves a peak throughput\nthat is as high as around 90% of Dumboâ€™s for ğ‘›= 64 case and about\n85% of Dumboâ€™s for ğ‘›= 100 case. All these throughput numbers are\nachieved despite frequent Transformer occurrence, as we intend to\nlet each fastlane to fallback after output mere 50 blocks.\nOverhead of Transformer. It is critical for us to understand the\npractical cost of Transformer. We estimate such overhead from two\ndifferent perspectives as shown in Fig. 17 and 18.\n4The five-round latency of BDT-sCAST in the best cases can be counted as follows:\none round for the leader to multicast the proposed batch of transactions, one round\nfor the parties to vote (by signing), one round for the leader to multicast the quorum\nproof (and thus all parties can get a pending block), and finally two more rounds for\nevery parties to receive one more block and therefore output the earlier pending block.\nThe concrete of rounds of BDT-sRBC in the best cases can be counted similarly.\n5Note that we didnâ€™t implement an additional layer of mempool as in [42] and [34],\nand we can expect much higher throughout if we adopt their mempool techniques.\n6 41 00024681012141618H\notStuff'sHotStuff'sD\numbo's basic latency ( no-fault, n=64) L\natency of Transformer(second)S\ncale (# of parties) \nBDT-sCAST-no-fault BDT-sRBC-no-fault MVBA-fallback-no-fault (KS02,RC05) BDT-sCAST-1/3-crash BDT-sRBC-1/3-crash MVBA-fallback-1/3-crash (KS02,RC05)D\numbo's basic latency ( no-fault, n=100) \nFigure 17: Latency of Transformer for pace-sync in BDT-sCAST\nand BDT-sRBC (when no fault and 1/3 crash, respectively).\nMVBA fallback in RC05 is also tested as a reference point.\nAs shown in Fig. 17, we measure the execution time ofTransformer\nin various settings by taking combinations of the following setups:\n(i) BDT-sCAST or BDT-sRBC; (ii) 1/3 crashes on or off; (iii) 64\nEC2 instances or 100 EC2 instances. Moreover, in order to compre-\nhensively compare Transformer with the prior art [10, 54, 68], we\nalso measure the latency of MVBA pace-sync (which instantiates\nthe Backup/Abstract primitive in [10] to combine the fastlane and\nDumbo 6) as a basic reference point, cf. Section 2 for the idea of\nusing Backup/Abstract for asynchronous fallback [10]. The com-\nparison indicates that Transformer is much cheaper in contrast to\nthe high cost of MVBA pace-sync. For example, Transformer al-\nways costs less than 1 second in BDT-sRBC, despite ğ‘›and on/off\nof crashes, while MVBA pace-sync is about 10 times slower.\n0 5 0001 00001 50002 00002 500002\n04\n06\n08\n01\n00Latency (second)T\nhroughput (tps) \nBDT-Timeout-64-no-fault (fastlane always fails) Dumbo-64-no-fault  BDT-Timeout-100-no-fault (fastlane always fails) Dumbo-100-no-fault\nFigure 18: Latency v.s. throughput for experiments of BDT\nwith idling fastlane (i.e., fastlane just timeouts after 2.5 sec).\nAs illustrated in Fig. 18, we measure the latency-throughput\ntradeoffs for BDT-Timeout, namely, to see how BDT worse than\nDumbo when BDTâ€™s fastlane is under denial-of-service. This is ar-\nguably the worst-case test vector for BDT, since relative to Dumbo,\nit always costs extra 2.5 seconds to timeout and then executes the\nTransformer subprotocol. Nevertheless, the performance of BDT is\nstill close to Dumbo. In particular, to realize the same throughput,\nBDT spends only a few additional seconds (which is mostly caused\nby our conservation 2.5-second timeout parameter).\n6Following [10] that used full-fledged SMR to instantiate Backup for fallback, one can\ncombine stable-leader 2-chain HotStuff (the fastlane of BDT-sCAST) and Dumbo by\na single block of asynchronous SMR. This intuitive idea can be realized from MVBA\n[23, 68] as follows after the fastlane times out: each party signs and multicasts the\nhighest quorum proof received fromHotStuff, then waits forğ‘›âˆ’ğ‘“ such signed proofs\nfrom distinct parties, and takes them asMVBA input; MVBA thus would output ğ‘›âˆ’ğ‘“\nvalid HotStuff quorum proofs (signed by ğ‘›âˆ’ğ‘“ parties), and the highest quorum proof\nin the MVBA output can represent the HotStuff block to continue Dumbo.\n12\nLatency-throughput trade-off. Figure 19 plots latency-throughput\ntrade-offs of BDT-sCAST, BDT-sRBC, HotStuff and Dumbo in the\nWAN setting forğ‘›= 64 and 100 parties. This illustrates thatBDT has\nlow latency close to that of HotStuff under varying system load.\n1 1 001\n0k2\n0k3\n0k4\n0k HotStuff-100-no-fault BDT-sCAST-100-no-fault BDT-sRBC-100-no-fault Dumbo-100-no-faultT\nhroughput (tps)L\natency (second) \nHotStuff-64-no-fault BDT-sCAST-64-no-fault BDT-sRBC-64-no-fault Dumbo-64-no-fault\nFigure 19: Throughput v.s. latency for experiments over\nWAN when ğ‘› = 64 and 100, respectively (in case of periodi-\ncally running pace-sync in BDT per only 50 fastlane blocks).\nEither BDT-sCAST or BDT-sRBC is much faster than Dumbo\nby several orders of magnitude in all cases, while the two BDT\ninstantiations have different favors towards distinct scenarios.BDT-\nsCAST has a latency-throughput trade-off similar to that of 2-chain\nHotStuff, and their small variance in latency is because we in-\ntentionally trigger timeouts in BDT-sCAST after each 50 fastlane\nblocks. BDT-sRBC has a latency-throughput trend quite differ-\nent from HotStuff and BDT-sCAST. Namely, when fixing larger\nthroughput, BDT-sRBC has a latency less thanBDT-sCASTâ€™s; when\nfixing small throughput, BDT-sRBC could be slower. This separates\nthem clearly in terms of application scenarios, sinceBDT-sRBC is a\nbetter choice for large throughput-favoring cases and BDT-sCAST\nis more suitable for latency-sensitive scenarios.\nSummary of evaluations in the WAN setting. The above results\nclearly demonstrate the efficiency of our pace-synchronizationâ€”\nTransformer. And thanks to that, BDT in the WAN setting is:\nâ€¢As fast as 2-chain HotStuff in the best case (i.e., synchronous\nnetwork without faulty parties); 7\nâ€¢As robust as the underlying asynchronous pessimistic path in\nthe worst case (i.e., the fastlane always completely fails).\n7.2 Evaluation in controlled dynamic network\nSetup on the simulated fluctuating network . We also deploy\nour Python-written protocols forğ‘›=64 parties in a high-performance\nserver having 4 28-core Xeon Platinum 8280 CPUs and 1TB RAM.\nThe code is same to the earlier WAN experiments, except that we\nimplement all TCP sockets with controllable bandwidth and delay.\nThis allows us to simulate a dynamic communication network.\nIn particular, we interleave â€œgoodâ€ network (i.e., 50ms delay\nand 200Mbps bitrate) and â€œbadâ€ network (i.e., 300ms delay and\n50Mbps bitrate) in the following experiments to reflect network\nfluctuation. Through the subsection,BDT refers to BDT-sCAST, the\napproach of using Abstract primitive [10] to combine stable-leader\n2-chain HotStuff (BDT-sCASTâ€™s fastlane) and Dumbo is denoted\nby HS+Abstract+Dumbo (where Backup/Abstract is instantiated\n7As discussed in Footnote 4, BDT-sCASTâ€™s fastlane has a 5-round latency, which is\nsame to that of 2-chain HotStuff. The tiny difference between their evaluated latency\nis because we periodically trigger Transformer in the experiments of BDT-sCAST.\nby MVBA as explained in Footnote 5). For experiment parameters,\nthe fastlaneâ€™s timeout is set as 1 second, the fastlane block and\npessimistic block contain 104 and 106 transactions respectively, and\nwe would report the number of confirmed transactions over time\nin random sample executions.\nGood network with very short fluctuations . We first examine\nin a network that mostly stays at good condition except interleaving\nsome short-term bad network condition that lasts only 2 seconds\n(which just triggers fastlane timeout). The sample executions in\nthe setting are plotted in Fig. 20. The result indicates that the per-\nformance of BDT does not degrade due to the several short-term\nnetwork fluctuation, and it remains as fast as 2-chainHotStuff. This\nfeature is becauseBDT adopts a two-level fallback mechanism, such\nthat it can just execute the light pace-sync and then immediately\nretry another fastlane. In contrast, usingBackup/Abstract primitive\n(instantiated by MVBA) as pace-sync would encounter rather long\nlatency (âˆ¼25 sec) to run the heavy pace-sync and pessimistic path\nafter the short-term network fluctuations.\n0.0\n2.0M\n4.0M\n6.0M\n8.0M\n10.0M\n12.0M\n14.0M\n# of Confirmed TXs\n BDT\nExecution Time (sec)\n0 60 120 180 240 300 360\n Dumbo\n HotStuff\n HS+Abstract+Dumbo\nFigure 20: Sample executions of BDT, 2-chain HotStuff,\nDumbo, and the composition of HotStuff+Abstract+Dumbo for\nğ‘›=64, when facing a few 2-second bad periods. The red re-\ngion represents the 2-second period of bad network.\nIntermittent network with long bad time . We then evaluate\nthe effect of long-lasting bad network condition. We visualize such\nsample executions in Fig. 21. Clearly, BDT can closely track the\nperformance of its underlying pessimistic path during the long\nperiods of bad network condition. Again, this feature is a result of\nefficient pace-sync, as it adds minimal overhead to the fallback. In\ncontrast, using Backup/Abstract primitive (instantiated by MVBA)\nto compose stable-leader HotStuff and Dumbo would incur a la-\ntency âˆ¼10 seconds larger than BDT during the bad network due to\nits cumbersome pace-sync.\nSummary of evaluations in fluctuating network . As expected\nby our efficient pace-sync subprotocol, BDT also performs well in\nthe fluctuating network environment. Specifically,\nâ€¢When encountering short-term network fluctuations, BDT\ncan quickly finish pace-sync and restart a new fastlane, thus\nprogressing at a speed same to 2-chain HotStuff.\nâ€¢When the network becomes slow for longer periods (and even\nHotStuff grinds to a halt),BDT still is robust to progress nearly\nas fast as the underlying asynchronous protocol.\n8 CONCLUSIONS\nIn this paper, we proposed the firstpractical and generic framework\nfor optimistic asynchronous atomic broadcast BDT, in which we\n13\n0.0\n2.0M\n4.0M\n6.0M\n8.0M\n10.0M\n# of Confirmed TXs\n BDT\nExecution Time (sec)\n0 60 120 180 240 300 360\n Dumbo\n HotStuff\n HS+Abstract+Dumbo\nFigure 21: Sample executions of BDT, 2-chain HotStuff,\nDumbo, and the composition of HotStuff+Abstract+Dumbo for\nğ‘›=64, when suffering from 120-second bad network. The red\nregion represents the 120-second period of bad network.\nabstract a new and simple deterministic fastlane that enables us\nto reduce the asynchronous pace-synchronization to the concep-\ntually minimum binary agreement. Several interesting questions\nremain: theoretically, formally demonstrating efficiency gap be-\ntween asynchronous consensus and deterministic consensus, e.g.,\na better lower bound would be very interesting; practically, our\ncurrent pessimistic path requires asynchronous common subset\n(ACS), building on top an ABC directly may need some further care;\nalso, the paradigm of adding an optimistic path could be further\ngeneralized to provide not only efficiency, but also better resilience,\nor flexibility.\nACKNOWLEDGMENTS\nWe would like to thank Vincent Gramoli and the anonymous re-\nviewers for their valuable comments. Yuan is supported in part\nby NSFC under Grant 62102404 and the Youth Innovation Promo-\ntion Association CAS. Qiang and Zhenliang are supported in part\nby research gifts from Ethereum Foundation, Stellar Foundation,\nProtocol Labs, Algorand Foundation and The University of Sydney.\nREFERENCES\n[1] Bug in ABA protocolâ€™s use of Common Coin. https://github.com/amiller/\nHoneyBadgerBFT/issues/59\n[2] Ittai Abraham, Danny Dolev, and Joseph Y Halpern. An almost-surely terminat-\ning polynomial protocol for asynchronous byzantine agreement with optimal\nresilience. In Proc. PODC 2008 . 405â€“414.\n[3] Ittai Abraham, Philipp Jovanovic, Mary Maller, Sarah Meiklejohn, Gilad Stern,\nand Alin Tomescu. 2021. Reaching consensus for asynchronous distributed key\ngeneration. In Proc. PODC 2021 . 363â€“373.\n[4] Ittai Abraham, Dahlia Malkhi, Kartik Nayak, Ling Ren, and Maofan Yin. 2020.\nSync hotstuff: Simple and practical synchronous state machine replication. In\n2020 IEEE Symposium on Security and Privacy (SP) . IEEE, 106â€“118.\n[5] Ittai Abraham, Dahlia Malkhi, and Alexander Spiegelman. Asymptotically Opti-\nmal Validated Asynchronous Byzantine Agreement. InProc. PODC 2019 . 337â€“346.\n[6] Ittai Abraham, Kartik Nayak, Ling Ren, and Zhuolun Xiang. Good-Case Latency\nof Byzantine Broadcast: A Complete Categorization. In Proc. PODC 2021 .\n[7] Yair Amir, Brian Coan, Jonathan Kirsch, and John Lane. 2010. Prime: Byzantine\nreplication under attack. IEEE transactions on dependable and secure computing 8,\n4 (2010), 564â€“577.\n[8] Yackolley Amoussou-Guenou, Antonella Del Pozzo, Maria Potop-Butucaru, and\nSara Tucci-Piergiovanni. Correctness of tendermint-core blockchains. In Proc.\nOPODIS 2018 .\n[9] Hagit Attiya and Jennifer Welch. 2004. Distributed computing: fundamentals,\nsimulations, and advanced topics . Vol. 19. John Wiley & Sons.\n[10] Pierre-Louis Aublin, Rachid Guerraoui, Nikola KneÅ¾eviÄ‡, Vivien QuÃ©ma, and\nMarko VukoliÄ‡. 2015. The next 700 BFT protocols.ACM Transactions on Computer\nSystems (TOCS) 32, 4 (2015), 1â€“45.\n[11] Pierre-Louis Aublin, Sonia Ben Mokhtar, and Vivien QuÃ©ma. 2013. Rbft: Re-\ndundant byzantine fault tolerance. In 2013 IEEE 33rd International Conference on\nDistributed Computing Systems . 297â€“306.\n[12] Michael Ben-Or. Another advantage of free choice (Extended Abstract) Com-\npletely asynchronous agreement protocols. In Proc. PODC 1983 . 27â€“30.\n[13] Michael Ben-Or and Ran El-Yaniv. 2003. Resilient-optimal interactive consistency\nin constant time. Distributed Computing 16, 4 (2003), 249â€“262.\n[14] Michael Ben-Or, Boaz Kelmer, and Tal Rabin. Asynchronous secure computations\nwith optimal resilience. In Proc. PODC 1994 . 183â€“192.\n[15] Alysson Bessani, JoÃ£o Sousa, and Eduardo EP Alchieri. 2014. State machine\nreplication for the masses with BFT-SMaRt. In Proc. DSN 2014 . 355â€“362.\n[16] Erica Blum, Jonathan Katz, and Julian Loss. Synchronous consensus with optimal\nasynchronous fallback guarantees. In Proc. TCC 2019 . 131â€“150.\n[17] Erica Blum, Jonathan Katz, and Julian Loss. 2021. Tardigrade: An Atomic Broad-\ncast Protocol for Arbitrary Network Conditions. InInternational Conference on the\nTheory and Application of Cryptology and Information Security . Springer, 547â€“572.\n[18] Erica Blum, Chen-Da Liu-Zhang, and Julian Loss. 2020. Always have a backup\nplan: fully secure synchronous MPC with asynchronous fallback. In Annual\nInternational Cryptology Conference . Springer, 707â€“731.\n[19] Alexandra Boldyreva. Threshold signatures, multisignatures and blind signatures\nbased on the gap-Diffie-Hellman-group signature scheme. In Proc. PKC 2003 .\n31â€“46.\n[20] Gabriel Bracha. 1987. Asynchronous Byzantine agreement protocols. Information\nand Computation 75, 2 (1987), 130â€“143.\n[21] Vitalik Buterin et al. 2014. A next-generation smart contract and decentralized\napplication platform. white paper 3, 37 (2014).\n[22] Christian Cachin, Klaus Kursawe, Anna Lysyanskaya, and Reto Strobl. Asynchro-\nnous verifiable secret sharing and proactive cryptosystems. In Proc. CCS 2002 .\n88â€“97.\n[23] Christian Cachin, Klaus Kursawe, Frank Petzold, and Victor Shoup. Secure and\nefficient asynchronous broadcast protocols. In Proc. CRYPTO 2001 . 524â€“541.\n[24] Christian Cachin, Klaus Kursawe, and Victor Shoup. Random oracles in constan-\ntipole: practical asynchronous Byzantine agreement using cryptography. In Proc.\nPODC 2020 . 123â€“132.\n[25] Christian Cachin and Stefano Tessaro. Asynchronous verifiable information\ndispersal. In Proc. SRDS 2005 . 191â€“201.\n[26] Christian Cachin and Marko Vukolic. Blockchain Consensus Protocols in the\nWild (Keynote Talk). In Proc. DISC 2017 .\n[27] Ran Canetti and Tal Rabin. Fast asynchronous Byzantine agreement with optimal\nresilience. In Proc. STOC 1993 . 42â€“51.\n[28] Miguel Castro and Barbara Liskov. 2002. Practical Byzantine fault tolerance and\nproactive recovery. ACM Transactions on Computer Systems (TOCS) 20, 4 (2002),\n398â€“461.\n[29] Miguel Castro, Barbara Liskov, et al. Practical Byzantine fault tolerance. In Proc.\nOSDI 1999 . 173â€“186.\n[30] Benjamin Y Chan and Elaine Shi. Streamlet: Textbook streamlined blockchains.\nIn Proc. AFT 2020 . 1â€“11.\n[31] Allen Clement, Edmund L Wong, Lorenzo Alvisi, Michael Dahlin, and Mirco\nMarchetti. Making Byzantine Fault Tolerant Systems Tolerate Byzantine Faults..\nIn Proc. NSDI 2009 , Vol. 9. 153â€“168.\n[32] Miguel Correia, Nuno Ferreira Neves, and Paulo VerÃ­ssimo. 2006. From consensus\nto atomic broadcast: Time-free Byzantine-resistant protocols without signatures.\nComput. J. 49, 1 (2006), 82â€“96.\n[33] Tyler Crain. 2020. Two More Algorithms for Randomized Signature-Free Asyn-\nchronous Binary Byzantine Consensus with t< n/3 and O(nË†2) Messages and O(1)\nRound Expected Termination. arXiv preprint arXiv:2002.08765 (2020).\n[34] George Danezis, Lefteris Kokoris-Kogias, Alberto Sonnino, and Alexander Spiegel-\nman. 2022. Narwhal and Tusk: a DAG-based mempool and efficient BFT consen-\nsus. In Proc. EuroSys 2022 . 34â€“50.\n[35] Sourav Das, Zhuolun Xiang, and Ling Ren. 2021. Asynchronous data dissemina-\ntion and its applications. In Proc. CCS 2021 . 2705â€“2721.\n[36] Sourav Das, Tom Yurek, Zhuolun Xiang, Andrew Miller, Lefteris Kokoris-Kogias,\nand Ling Ren. 2021. Practical asynchronous distributed key generation. Cryptol-\nogy ePrint Archive (2021).\n[37] Sourav Das, Thomas Yurek, Zhuolun Xiang, Andrew Miller, Lefteris Kokoris-\nKogias, and Ling Ren. 2022. Practical Asynchronous Distributed Key Generation.\nIn 2022 IEEE Symposium on Security and Privacy (SP) . 2518â€“2534.\n[38] Sisi Duan, Michael K Reiter, and Haibin Zhang. BEAT: Asynchronous BFT made\npractical. In Proc. CCS 2018 . 2028â€“2041.\n[39] Cynthia Dwork, Nancy Lynch, and Larry Stockmeyer. 1988. Consensus in the\npresence of partial synchrony. JACM 35, 2 (1988), 288â€“323.\n[40] Michael J Fischer, Nancy A Lynch, and Michael S Paterson. 1985. Impossibility\nof Distributed Consensus with One Faulty Process. Journal of the Assccktion for\nComputing Machinery 32, 2 (1985), 374â€“382.\n[41] Matthias Fitzi and Juan A Garay. 2003. Efficient player-optimal protocols for\nstrong and differential consensus. In Proceedings of the twenty-second annual\nsymposium on Principles of distributed computing . 211â€“220.\n[42] Yingzi Gao, Yuan Lu, Zhenliang Lu, Qiang Tang, Jing Xu, and Zhenfeng Zhang.\nDumbo-NG: Fast Asynchronous BFT Consensus with Throughput-Oblivious\nLatency. In Proc. CCS 2022 .\n14\n[43] Yingzi Gao, Yuan Lu, Zhenliang Lu, Qiang Tang, Jing Xu, and Zhenfeng Zhang.\n2022. Efficient Asynchronous Byzantine Agreement without Private Setups. In\nProc. ICDCS 2022 .\n[44] Rati Gelashvili, Lefteris Kokoris-Kogias, Alberto Sonnino, Alexander Spiegel-\nman, and Zhuolun Xiang. 2021. Jolteon and Ditto: Network-Adaptive Efficient\nConsensus with Asynchronous Fallback. arXiv preprint arXiv:2106.10362 (2021).\n[45] Rati Gelashvili, Lefteris Kokoris-Kogias, Alexander Spiegelman, and Zhuolun\nXiang. 2021. Be Prepared When Network Goes Bad: An Asynchronous View-\nChange Protocol. arXiv preprint arXiv:2103.03181 (2021).\n[46] Rosario Gennaro, StanisÅ‚aw Jarecki, Hugo Krawczyk, and Tal Rabin. Secure\ndistributed key generation for discrete-log based cryptosystems. In Proc. EURO-\nCRYPT 1999 . 295â€“310.\n[47] Rachid Guerraoui, Nikola KneÅ¾eviÄ‡, Vivien QuÃ©ma, and Marko VukoliÄ‡. 2010.\nThe next 700 BFT protocols. In Proceedings of the 5th European conference on\nComputer systems . 363â€“376.\n[48] Guy Golan Gueta, Ittai Abraham, Shelly Grossman, Dahlia Malkhi, Benny Pinkas,\nMichael Reiter, Dragos-Adrian Seredinschi, Orr Tamir, and Alin Tomescu. SBFT:\na Scalable and Decentralized Trust Infrastructure. In Proc. DSN 2019 . 568â€“580.\n[49] Bingyong Guo, Yuan Lu, Zhenliang Lu, Qiang Tang, Jing Xu, and Zhenfeng Zhang.\n2022. Speeding Dumbo: Pushing Asynchronous BFT Closer to Practice. In The\n29th Network and Distributed System Security Symposium (NDSS) .\n[50] Bingyong Guo, Zhenliang Lu, Qiang Tang, Jing Xu, and Zhenfeng Zhang. Dumbo:\nFaster asynchronous bft protocols. In Proc. CCS 2020 . 803â€“818.\n[51] Aniket Kate and Ian Goldberg. Distributed key generation for the internet. In\nProc. ICDCS 2009 . 119â€“128.\n[52] Idit Keidar, Eleftherios Kokoris-Kogias, Oded Naor, and Alexander Spiegelman.\n2021. All you need is dag. arXiv preprint arXiv:2102.08325 (2021).\n[53] Eleftherios Kokoris Kogias, Dahlia Malkhi, and Alexander Spiegelman. Asyn-\nchronous Distributed Key Generation for Computationally-Secure Randomness,\nConsensus, and Threshold Signatures.. In Proc. CCS 2020 . 1751â€“1767.\n[54] Klaus Kursawe and Victor Shoup. first announced in 2002. Optimistic asynchro-\nnous atomic broadcast. In Proc. ICALP 2005 . 204â€“215.\n[55] Julian Loss and Tal Moran. 2018. Combining Asynchronous and Synchronous\nByzantine Agreement: The Best of Both Worlds. IACR Cryptol. ePrint Arch. 2018\n(2018), 235.\n[56] Yuan Lu, Zhenliang Lu, Qiang Tang, and Guiling Wang. Dumbo-mvba: Optimal\nmulti-valued validated asynchronous byzantine agreement, revisited. In Proc.\nPODC 2020 . 129â€“138.\n[57] Andrew Miller, Yu Xia, Kyle Croman, Elaine Shi, and Dawn Song. The honey\nbadger of BFT protocols. In Proc. CCS 2016 . 31â€“42.\n[58] Atsuki Momose, Jason Paul Cruz, and Yuichi Kaji. 2020. Hybrid-BFT: Optimisti-\ncally Responsive Synchronous Consensus with Optimal Latency or Resilience.\nIACR Cryptol. ePrint Arch. 2020 (2020), 406.\n[59] Atsuki Momose and Ling Ren. Multi-Threshold Byzantine Fault Tolerance. In\nProc. CCS 2021 .\n[60] Achour Mostefaoui, Hamouma Moumen, and Michel Raynal. Signature-free\nasynchronous byzantine consensus with ğ‘¡ < ğ‘›/3 and O(ğ‘›2)messages. In Proc.\nPODC 2014 . 2â€“9.\n[61] Satoshi Nakamoto. 2008. Bitcoin: A peer-to-peer electronic cash system. (2008).\n[62] Rafael Pass and Elaine Shi. 2017. The sleepy model of consensus. In Advances in\nCryptology â€“ ASIACRYPT 2017 . 380â€“409.\n[63] Arpita Patra. Error-free multi-valued broadcast and Byzantine agreement with\noptimal communication complexity. In Proc. OPODIS 2011 . 34â€“49.\n[64] Arpita Patra, Ashish Choudhary, and Chandrasekharan Pandu Rangan. Simple\nand efficient asynchronous byzantine agreement with optimal resilience. In Proc.\nPODC 2009 . 92â€“101.\n[65] Torben Pryds Pedersen. A Threshold Cryptosystem without a Trusted Party. In\nProc. EUROCRYPT 1991 . 522â€“526.\n[66] R. Pass, and E. Shi. 2018. Thunderella: Blockchains with optimistic instant\nconfirmation. In Proc. EUROCRYPT 2018 . 3â€“33.\n[67] Michael O Rabin. 1983. Randomized byzantine generals. In 24th Annual Sympo-\nsium on Foundations of Computer Science . IEEE, 403â€“409.\n[68] HariGovind V Ramasamy and Christian Cachin. Parsimonious asynchronous\nbyzantine-fault-tolerant atomic broadcast. In Proc. OPODIS 2005 . 88â€“102.\n[69] Muhammad Saad, Afsah Anwar, Srivatsan Ravi, and David Mohaisen. 2021. Re-\nvisiting Nakamoto Consensus in Asynchronous Networks: A Comprehensive\nAnalysis of Bitcoin Safety and ChainQuality. In Proceedings of the 2021 ACM\nSIGSAC Conference on Computer and Communications Security . 988â€“1005.\n[70] Nibesh Shrestha, Ittai Abraham, Ling Ren, and Kartik Nayak. On the Optimality\nof Optimistic Responsiveness. In Proc. CCS 2020 . 839â€“857.\n[71] Alexander Spiegelman. 2021. In Search for an Optimal Authenticated Byzantine\nAgreement. In Proc. DISC 2021 .\n[72] Giuliana Santos Veronese, Miguel Correia, Alysson Neves Bessani, and Lau Cheuk\nLung. Spin oneâ€™s wheels? Byzantine fault tolerance with a spinning primary. In\nProc. SRDS 2009 . 135â€“144.\n[73] Lei Yang, Seo Jin Park, Mohammad Alizadeh, Sreeram Kannan, and David Tse.\n2022. DispersedLedger: High-Throughput Byzantine Consensus on Variable\nBandwidth Networks. In 19th USENIX Symposium on Networked Systems Design\nand Implementation (NSDI 22) .\n[74] Maofan Yin, Dahlia Malkhi, Michael K Reiter, Guy Golan Gueta, and Ittai Abra-\nham. 2019. Hotstuff: Bft consensus with linearity and responsiveness. In Proc.\nPODC 2019 . 347â€“356.\n[75] Haibing Zhang and Sisi Duan. PACE: Fully Parallelizable BFT from Reproposable\nByzantine Agreement. In Proc. CCS 2022 .\nA DEFERRED PROOFS FOR Bolt\nCONSTRUCTIONS\nLemma A.1. The algorithm in Figure 7 satisfies the total-order,\nnotarizability, abandonability and optimistic liveness properties of\nBolt except with negligible probability.\nProof: Here we prove the four properties one by one:\nFor total-order : First, we prove at same position, for any two\nhonest parties Pğ‘– and Pğ‘— return blockğ‘– and blockğ‘—, respectively,\nthen blockğ‘– = blockğ‘—. It is clear that if the honest party Pğ‘– outputs\nblockğ‘–, then at least ğ‘“ +1 honest parties did vote for blockğ‘– because\nTSIG.Vrfy2ğ‘“+1 passes verification. So did ğ‘“ +1 honest parties vote\nfor blockğ‘—. That means at least one honest party votes for both\nblocks, so blockğ‘– = blockğ‘—.\nFor notarizability: Suppose a party Pğ‘– outputs blocks[ğ‘—]:= âŸ¨id,ğ‘—,\nTXsğ‘—,Proofğ‘—âŸ©, it means at leastğ‘“+1 honest parties vote forblock[ğ‘—],\naccording to the pseudocode, at least those sameğ‘“+1 honest parties\nalready output blocks[ğ‘— âˆ’1]and received the TXsğ‘—, hence, those\nhonest parties can further use the valid Proofğ‘— to extract blocks[ğ‘—]\nfrom the receivied protocol messages.\nFor abandonability : it is immediate to see from the pseudocode\nof the abandon interface.\nFor optimistic liveness : suppose that the optimistic condition\nis that the leader is honest, then any honest party would output\nblock[1]in three asynchronous rounds after entering the protocol\nand would output log[ğ‘—+1]within two asynchronous rounds after\noutputting log[ğ‘—](for all ğ‘— â‰¥1). â–¡\nLemma A.2. The algorithm in Figure 8 satisfies the total-order,\nnotarizability, abandonability and optimistic liveness properties of\nBolt except with negligible probability.\nProof: It is clear that the total-order, notarizability and abandon-\nability follow immediately from the properties of RBC and the\npseudocode of Bolt-sRBC, since the agreement of RBC guarantees\nthat the output TXs by any parties is the same and a valid proof\nalong with the sequentially executing nature of all RBC instances\nwould ensure total-order and notarizability. For optimistic liveness ,\nthe optimistic condition remains to be that the leader is honest, and\nğœ…is 4 due to the RBC construction in [57] and an extra vote step. â–¡\nB DEFERRED PROOFS FOR tcv-BA\nLemma B.1. The algorithm in Figure 10 satisfies the termination,\nvalidity and agreement properties of tcv-BA except with negligible\nprobability.\nProof: First, from [ 60] we know: for any ğ‘£ âˆˆğ‘†ğ‘Ÿ, then ğ‘£ was\nthe input of at least one honest party, then in next round ğ‘Ÿ +1,\nevery honest partyâ€™s input estğ‘Ÿ+1 will always from at least one\nhonest partyâ€™s input of round ğ‘Ÿ by the code. Again, according to\nthe pseudocode, the output is the element of ğ‘†, hence, validity is\nsatisfied.\n15\nSecond, suppose one honest party Pğ‘– is the first party to output\nand Pğ‘– outputs ğ‘£ in round ğ‘Ÿ. Then for any other honest parties,\neither output the same ğ‘£, or have ğ‘†ğ‘Ÿ = {ğ‘£,ğ‘£ +1}, hence, all honest\nparties will have same input estğ‘Ÿ+1 = ğ‘£ (ğ‘£%2 = ğ‘ğ‘Ÿ%2) in next round\nğ‘Ÿ+1, then, ğ‘†ğ‘Ÿ+1 = {ğ‘£}, and estğ‘Ÿ+2 = ğ‘£for round ğ‘Ÿ+2. Once in some\nround ğ‘Ÿâ€², the ğ‘£%2 = ğ‘ğ‘Ÿâ€²%2, all honest parties output the same ğ‘£. So\nthe agreement is met.\nThird, the termination analysis is similar to that in [1, 60]. â–¡\nLemma B.2. The algorithm in Figure 11 satisfies the termination,\nvalidity and agreement properties of tcv-BA except with negligible\nprobability.\nProof: For termination : Since all honest parties input a value in\n{ğ‘£,ğ‘£ +1}where ğ‘£ âˆˆN, without loss of generality, suppose value ğ‘£\nwas input by at leastğ‘“+1 honest parties, then after amplifying, every\nhonest parties can receive2ğ‘“+1 Value(id,ğ‘£)messages from distinct\nparties carrying the same ğ‘£. Hence, all honest parties can activate\nABBA with one input ğ‘£â€²%2. Then, the ABBA guarantees that all\nhonest parties return ğ‘. Since the validity of ABBA guarantees the\noutput of ABBA is at least one honest partyâ€™s input, according to\nthe code, if one honest party input ğ‘into ABBA, then the party has\nreceived at least 2ğ‘“ +1 Value(id,ğ‘£â€²)messages from distinct parties\ncarrying the same ğ‘£â€²and ğ‘£â€²%2 = ğ‘, hence, all honest parties can\nreceive ğ‘“ +1 Value(id,ğ‘£â€²)messages from distinct honest parties\ncontaining the same ğ‘£â€²such that ğ‘£â€²%2 = ğ‘.\nFor validity : Since the validity of ABBA guarantees the output ğ‘\nof ABBA is at least one honest partyâ€™s input, then according to the\ncode, the party has received at least 2ğ‘“ +1 Value(id,ğ‘£â€²)messages\nfrom distinct parties carrying the same ğ‘£â€², where ğ‘£â€²%2 = ğ‘, hence,\nat least one honest party with taking ğ‘£â€²as input and multicast\nValue(id,ğ‘£â€²).\nFor agreement : Since the agreement of ABBA guarantees all hon-\nest parties have the same output ğ‘. Hence, all honest parties will\noutput value ğ‘£â€², where ğ‘£â€²%2 = ğ‘. Without loss of generality, sup-\npose honest party Pğ‘– output ğ‘£ and honest party Pğ‘— output ğ‘£+2ğ‘˜\n(ğ‘˜ â‰  0), then following the validity proof, both ğ‘£ and ğ‘£ +2ğ‘˜ are\nhonest partyâ€™s input, then it is a contradiction with thetcv-BA input\nassumption. â–¡\nC DEFERRED PROOFS FOR\nBolt-Dumbo Transformer\nSafety proof. We first prove the total-order and agreement, assum-\ning the underlying Bolt, tcv-BA and ACS are secure.\nClaim 1. If an honest party activates tcv-BA[ğ‘’], then at least\nğ‘›âˆ’2ğ‘“ honest parties have already invoked abandon(ğ‘’), and from\nnow on: suppose these same parties invoke abandon(ğ‘’)before they\noutput block:=âŸ¨ğ‘’,ğ‘…, Â·,Â·âŸ©, then any party (including the faulty ones)\ncannot receive (or forge) a valid block:=âŸ¨ğ‘’,ğ‘… +1,Â·,Â·âŸ©, and all honest\nparties would activate tcv-BA[ğ‘’].\nProof: When an honest party Pğ‘– activates tcv-BA[ğ‘’], it must\nhave received ğ‘›âˆ’ğ‘“ valid PaceSync messages from distinct par-\nties, so there would be at least ğ‘› âˆ’2ğ‘“ honest parties multicast\nPaceSync messages. By the pseudocode, it also means that at least\nğ‘› âˆ’2ğ‘“ honest parties have invoked abandon(ğ‘’). Note that ğ‘› âˆ’\n2ğ‘“ â‰¥ ğ‘“ +1 and these same parties invoke abandon(ğ‘’)before\nthey output block:=âŸ¨ğ‘’,ğ‘…, Â·,Â·âŸ©, so no party would deliver any valid\nblock:=âŸ¨ğ‘’,ğ‘… +1,Â·,Â·âŸ©in this epochâ€™s Bolt phase due to the abandon-\nability property of Bolt. It is also implies that any parties cannot\nfrom the Bolt receive valid block:=âŸ¨ğ‘’,ğ‘… +1,Â·,Â·âŸ©, then all honest\nparties will eventually be interrupted by the â€œtimeoutâ€ mechanism\nafter ğœ asynchronous rounds and then multicast PaceSync mes-\nsages. This ensures that all honest parties finally receiveğ‘›âˆ’ğ‘“ valid\nPaceSyncmessages from distinct parties, causing all honest parties\nto activate tcv-BA[ğ‘’]. â–¡\nClaim 2. Suppose that some party receives a valid block:=âŸ¨ğ‘’,ğ‘…, Â·,Â·âŸ©\nfrom Bolt[ğ‘’]when an honest party invokes tcv-BA[ğ‘’]s.t. this block\nis the one with largest slot number among all partiesâ€™ valid pending\nblocks (which means the union of the honest partiesâ€™ actual pending\nblocks and the malicious partiesâ€™ arbitrary valid Bolt[ğ‘’]block), then\nall honest partiesâ€™ maxPaceğ‘’ must be either ğ‘…or ğ‘…âˆ’1.\nProof: Following Claim 1, once an honest party invokestcv-BA[ğ‘’],\nthe Bolt[ğ‘’]block with the largest slot number ğ‘…ğ‘šğ‘ğ‘¥ would not\nchange anymore. Let us call this already fixed Bolt[ğ‘’]block with\nhighest slot number as blockğ‘šğ‘ğ‘¥. Since there is someone that re-\nceives blockğ‘šğ‘ğ‘¥:=âŸ¨ğ‘’,ğ‘…, Â·,Â·âŸ©, at least ğ‘“ +1 honest parties (e.g., de-\nnoted by ğ‘„) have already received the block âŸ¨ğ‘’,ğ‘… âˆ’1,Â·,Â·âŸ©, which\nis because of the notarizability property of Bolt. So these honest\nparties would broadcast a valid PaceSync(ğ‘’,ğ‘… âˆ’1,Â·)message or a\nvalid PaceSync(ğ‘’,ğ‘…, Â·)message. According to the pseudocode in\nFigure 13, maxPaceğ‘’ is the maximum number in the set of Pacesğ‘’,\nwhere Pacesğ‘’ contains the slot numbers encapsulated byğ‘›âˆ’ğ‘“ valid\nPaceSyncmessages. Therefore, Pacesğ‘’ must contain one PaceSync\nmessageâ€™s slot number from at least ğ‘›âˆ’2ğ‘“ â‰¥ğ‘“ +1 honest parties\n(e.g., denoted by Â¯ğ‘„). All honest partiesâ€™ local Pacesğ‘’ set must con-\ntain ğ‘…âˆ’1 and/or ğ‘…, because Â¯ğ‘„ and ğ‘„ contain at least one common\nhonest party. Moreover, there is no validPaceSync message con-\ntaining any slot larger thanğ‘…since the proof for that is unforgeable,\nwhich means ğ‘…is the largest possible value in all honest partiesâ€™\nPacesğ‘’. So any honest partyâ€™s maxPaceğ‘’ must be ğ‘…or ğ‘…âˆ’1. â–¡\nClaim 3. No honest party would get a syncPaceğ‘’ smaller than the\nslot number of it latest finalized block log[âˆ’1](i.e., no block finalized\nin some honest partyâ€™s log can be revoked).\nProof: Suppose an honest party invokes tcv-BA[ğ‘’]and a valid\nBolt[ğ‘’]block âŸ¨ğ‘’,ğ‘…, Â·,Â·âŸ©is the one with largest slot number among\nthe union of the honest partiesâ€™ actual pending blocks and the\nmalicious partiesâ€™ arbitrary valid Bolt[ğ‘’]block. Because of Claim\n2, all honest parties will activate tcv-BA[ğ‘’]with taking either ğ‘…\nor ğ‘…âˆ’1 as input. According to the strong validity of tcv-BA, the\noutput syncPaceğ‘’ of tcv-BA[ğ‘’]must be either ğ‘…or ğ‘…âˆ’1. Then we\nconsider the next two cases:\n(1) Only malicious parties have this âŸ¨ğ‘’,ğ‘…, Â·,Â·âŸ©block;\n(2) Some honest party Pğ‘– also has the âŸ¨ğ‘’,ğ‘…, Â·,Â·âŸ©block.\nFor Case 1) Due to the notarizability property of Bolt and this\ncaseâ€™s baseline, there exist ğ‘“ +1 honest parties (denoted by a set\nğ‘„) have the block âŸ¨ğ‘’,ğ‘… âˆ’1,Â·,Â·âŸ©as their local pending. Note that\nremaining honest parties (denoted by a set Â¯ğ‘„) would have local\npending block not higher than ğ‘…âˆ’1. According to the algorithm\nin Figure 13, we can state that: (i) if the output is ğ‘…, then all honest\nparties will sync their log up to the block âŸ¨ğ‘’,ğ‘…, Â·,Â·âŸ©(which include\nall honest partiesâ€™ local pending); (ii) similarly, if the output isğ‘…âˆ’1,\nall honest parties will sync up till âŸ¨ğ‘’,ğ‘… âˆ’1,Â·,Â·âŸ©(which also include\n16\nall honest partiesâ€™ local pending). So in this case, all honest parties\n(i.e., Â¯ğ‘„âˆªğ‘„) will not discard their pending block, let alone discard\nsome Bolt that are already finalized to output into log.\nFor Case 2) Let ğ‘„ denote the set of honest parties that have the\nblock âŸ¨ğ‘’,ğ‘…, Â·,Â·âŸ©as their local pending. Note the remaining honest\nparties Â¯ğ‘„ would have the pending block not higher than ğ‘…. In this\ncase, following the algorithm in Figure 13, we can see that: (i) if\nthe output is ğ‘…, then all honest parties will sync their log up to the\nblock âŸ¨ğ‘’,ğ‘…, Â·,Â·âŸ©(which include all honest partiesâ€™ local pending); (ii)\nsimilarly, if the output is ğ‘…âˆ’1, all honest parties will sync up to\nâŸ¨ğ‘’,ğ‘… âˆ’1,Â·,Â·âŸ©(which include Â¯ğ‘„ partiesâ€™ local pending and ğ‘„ partiesâ€™\nfinalized output log). So in this case, all honest parties (i.e., Â¯ğ‘„âˆªğ‘„)\nwill not discard any block in their finalized log. â–¡\nClaim 4. If tcv-BA[ğ‘’]returns syncPaceğ‘’, then at least ğ‘“+1 honest\nparties can append blocks with slot numbers from 1 to syncPaceğ‘’\nthat all received from Bolt[ğ‘’]into the log without invoking CallHelp\nfunction.\nProof: Suppose tcv-BA[ğ‘’]returns syncPaceğ‘’, then from thestrong\nvalidity of tcv-BA, at least one honest party inputs the number\nsyncPaceğ‘’. The same honest party must receive a valid message\nPaceSync(ğ‘’,syncPaceğ‘’,Proof), which means there must exists a\nvalid Bolt block âŸ¨ğ‘’,syncPaceğ‘’,Â·,ProofâŸ©. By the code, the honest\nparty will multicst PaceSync(ğ‘’,syncPaceğ‘’,Proof)if tcv-BA[ğ‘’]re-\nturns syncPaceğ‘’, then all honest parties can get the Proof. Follow-\ning the notarizability and total-order properties of Bolt, at least ğ‘“ +1\nhonest parties can appendblocks fromâŸ¨ğ‘’,1,Â·,Â·âŸ©to âŸ¨ğ‘’,syncPaceğ‘’,Â·,Â·âŸ©\ninto the log without invoking CallHelp function. â–¡\nClaim 5. If an honest party invokes CallHelp function to retrieve\na block log[ğ‘–], it eventually can get it; if another honest party retrieves\na block log[ğ‘–]â€²at the same log position ğ‘– from the CallHelp function,\nthen log[ğ‘–]= log[ğ‘–]â€².\nProof: Due to Claim 4 andtotal-order properties of Bolt, any block\nlog[ğ‘–]that an honest party is retrieving through CallHelp function\nshall have been in the output log of at least ğ‘“ +1 honest parties, so\nit eventually can get ğ‘“ +1 correct Help messages with the same\nMerkle tree root â„from distinct parties, then it can interpolate the\nğ‘“ +1 leaves to reconstruct log[ğ‘–]which is same to other honest\npartiesâ€™ local log[ğ‘–]. We can argue the agreement by contradiction,\nin case the interpolation of honest party fails or it recovers a block\nlogâ€²[ğ‘–]different from the the honest partyâ€™s locallog[ğ‘–], that means\nthe Merkle tree with rootâ„commits some leaves that are not coded\nfragments of log[ğ‘–]; nevertheless, there is at least one honest party\nencode log[ğ‘–]and commits the blockâ€™s erasure code to have a Merkle\ntree root â„; so the adversary indeed breaks the collision resistance\nof Merkle tree, implying the break of the collision-resistance of\nhash function, which is computationally infeasible. So all honest\nparties that attempt to retrieve a missing block log[ğ‘–]must fetch\nthe block consistent to other honest partiesâ€™. â–¡\nLemma C.1. If all honest parties enter the Bolt phase with the\nsame log, then they will always finish the Transformer phase with\nstill having the same logâ€².\nProof: If all honest parties enter the epoch with the same log,\nit is easy to see that they all will eventually interrupt to abandon\nthe Bolt phase. Due to Claim 1, all honest parties would activate\ntcv-BA[ğ‘’]. Following the agreement and termination of tcv-BA[ğ‘’],\nall parties would finish tcv-BA[ğ‘’]to get a common syncPaceğ‘’, and\nthen by the pseudocode, all honest parties will sync up to the same\nlog, and the last block of log with slot number syncPaceğ‘’ (due to\ntotal-order properties ofBolt, Claim 4 and Claim 5), hence, all parties\nwill finish the Transformer phase with the same output log. â–¡\nLemma C.2. For any two honest parties before finishing the Trans-\nformer phase, then there exists one party, such that its log is a prefix\nof (or equal to) the otherâ€™s.\nProof: The blocks outputted before the completion of the Trans-\nformer phase were originally generated from the Bolt phase, then\nthe Lemma holds immediately by following thetotal-order property\nof Bolt and Claim 3. â–¡\nLemma C.3. If any honest party enters the Pessimistic phase, then\nall honest parties will enters the phase and always leave the phase\nwith having the same log.\nProof: If any honest party enter the Pessimistic phase, all honest\nparties would enter this phase, which is due to Claim 1, the agree-\nment and termination property of tcv-BA and syncPaceğ‘’ = 0. Let us\nassume that all honest parties enter the Pessimistic phase with the\nsame log, it would be trivial too see the statement for theagreement\nand termination properties of ACS and the correct and robustness\nproperties of threshold public key encryption. Then considering\nLemma C.1 and the simple fact that all honest parties activate with\nthe common empty log, we can inductively reason that all honest\nparties must enter any Pessimistic phase with the same log. So the\nLemma holds. â–¡\nLemma C.4. For any two honest parties in the same epoch, there\nexists one party, such that its log is a prefix of (or equal to) the otherâ€™s.\nProof: If two honest parties do not enter thePessimistic phase dur-\ning the epoch, both of them only participate inBolt or Transformer,\nso this Lemma holds immediately by following Lemma C.2. For two\nhonest parties that one enters the Pessimistic phase and one does\nnot, this Lemma holds because the latter oneâ€™s log is either a prefix\nof the former oneâ€™s or equal to the former oneâ€™s due to Lemma C.1\nand C.2. For the remaining case that both honest parties enter the\nPessimistic phase, they must initially have exactly same log (due\nto Lemma C.1). Moreover, in the phase, all honest parties would\nexecute the ACS instances in a sequential manner (e.g., there is only\none ACS instance in our exemplary pseudocode), so every honest\nparty would output in one ACS instance only if it has already out-\nputted in all earlier ACS instances. Besides, any two honest party\nwould output the same transaction batch in every ACS instance for\nthe agreement property of ACS. So this Lemma also holds for any\ntwo honest parties that are staying in the same epoch. â–¡\nTheorem C.5. The Bolt-Dumbo Transformer protocol satisfies\nthe agreement and total order properties.\nProof: The total order be induced by Lemma C.4 along with the\nfact the protocol is executed epoch by epoch. The agreement follows\nimmediately from Lemma C.1 and C.3 along with the fact that all\nhonest parties initialize with the same empty log to enter the first\nepochâ€™s Bolt phase. â–¡\nLiveness proof. Then we prove the liveness property of BDT.\n17\nLemma C.6. If all honest parties enter the Bolt phase, once the\nliveness failed, then they will leave the phase in at most polynomial\nnumber of asynchronous rounds and also all enter the Transformer\nphase.\nProof: The liveness failed in the Bolt phase, it could be either\n(1). no progress within ğœ time or (2). some oldest transactions is\nnot output within ğ‘‡ time. For (1), at worst case, all honest partiesâ€™\ntimeout will interrupt, causing them to abandon the Bolt phase\nin at most O(ğœ)asynchronous rounds. For (2), it will take at most\nO(ğ‘‡)asynchronous rounds to leave the Bolt phase if there is a\nsuspiciously censored tx in all honest partiesâ€™ buffers due to some\ntimeout parameter ğ‘‡. Hence, once the liveness failed, all honest\nparties will leave the phase in at most O(ğœ +ğ‘‡)asynchronous\nrounds. After that, the broadcast of PaceSync message will take\none more asynchronous round. After that, all honest parties would\nreceive enough PaceSyncmessages to enter theTransformer phase,\nwhich costs at most O(ğœ+ğ‘‡ +1)asynchronous rounds. â–¡\nLemma C.7. If all honest parties enter the Transformer phase, they\nall leave the phase in expected constant asynchronous rounds and\nthen either enter the Pessimistic phase or enter the next epochâ€™s Bolt\nphase.\nProof: If all honest parties enter the Transformer phase, it is\ntrivial to see the Lemma since the underlying tcv-BA terminates in\non-average constant asynchronous rounds. If the output of tcv-BA\nequal 0, then enter the Pessimistic phase, otherwise, enter the next\nepochâ€™s Bolt phase. â–¡\nLemma C.8. If all honest parties enter the Pessimistic phase, all\nhonest parties will leave this Pessimistic phase in on-average constant\nasynchronous rounds with outputting some blocks containing on-\naverage O(ğµ)-sized transactions.\nProof: Similar to [57]â€™s analysis, Pessimistic phase at least out-\nputs O(ğµ)-sized transactions (without worrying that the adversary\ncan learn any bit about the transactions to be outputted before\nthey are actually finalized as output) for each execution. Here we\nremark that the original analysis in [ 57] only requires IND-CPA\nsecurity of threshold public key encryption might be not enough,\nsince we need to simulate that the adversary can query decryption\noracle by inserting her ciphertext into the ACS output. Moreover,\nthe underlying Dumbo ACS construction [50] ensures all parties\nto leave the phase in on-average constant asynchronous rounds. â–¡\nTheorem C.9. The Bolt-Dumbo Transformer protocol satisfies\nthe liveness property.\nProof: Due to Lemma C.6 and C.7, the adversary would not be\nable to stuck the honest parties during the Bolt and Transformer\nphases. Even if in the worst cases, the two phases do not deliver\nany useful output and the adversary intends to prevent the par-\nties from running the Pessimistic phase (thus not eliminating any\ntransactions from the honest partiesâ€™ input buffer), we still have\na timeout mechanism against censorship, which can ensure to ex-\necute the Pessimistic phase for every O(ğ‘‡)asynchronous rounds\nif there is a suspiciously censored tx in all honest partiesâ€™ buffers\ndue to some timeout parameter ğ‘‡. Recall Lemma C.8, for each tx in\nall honest partiesâ€™ buffers, it would take O(ğ‘‹ğ‘‡/ğµ)asynchronous\nrounds at worst (i.e., we always rely on the timeoutğ‘‡ to invoke the\nPessimistic phase) to make tx be one of the topğµtransactions in all\npartiesâ€™ buffers, where ğ‘‹ is the bound of buffer size (e.g., an unfixed\npolynomial in ğœ†). After that, any luckily finalized optimistic phase\nblock would output tx (in few more ğ›¿), or still relying on the time-\nout to invoke the Pessimistic phase, causing the worst case latency\nO((ğ‘‹/ğµ+ğœ†)ğ›¿ğ‘‡), which is a function in the actual network delay ğ›¿\nfactored by some (unfixed) polynomial of security parameters. â–¡\nD OPTIMISTIC CONDITIONS OF FASTLANE\nHere we discuss that the fastlane can successfully execute without\ninvoking pace-synchronization, if the following two optimistic\nconditions hold: (i) the network stays in synchrony, such that the\nguessed timeout parameter is larger than the â€œheartbeatâ€ period\nof the underlying fastlane; (ii) the optimistic liveness condition of\nfastlane is satisfied, e.g. the leader is honest.\nFirst, it is clear to see: if all honest parties have already enter\nthe same epochâ€™s fastlane at the same time, then the fastlane must\nsuccessfully progress in the presence of above optimistic conditions.\nActually, the above argument still holds, even if the honest parties\nenter the fastlane with minor difference in time, because one can\nslightly tune up the guessed timing parameter.\nThen, let us briefly argue that when the network is synchro-\nnous, BDT can ensure all honest parties to enter the same fastlane\nwithin a bounded period. This actually reduces to the next question:\nwhen some honest party first outputs and halts in the asynchro-\nnous pessimistic path, would all honest parties output soon (if\nthe network is synchronous)? Fortunately, the answer is yes if we\ncheck the detailed construction of asynchronous protocols (such\nas Dumbo). This indicates that the asynchronous pessimistic path\nitself can work as a clock synchronizer to ensure that all honest\nparties restart the fastlane nearly at the same time (when network\nsynchrony holds).\nE MORE EXPERIMENTS IN WAN SETTING\nFor sake of completeness, we also measure (i) latency and through-\nput on varying batch sizes and (ii) the latency-throughput trade-off\n(with ğ‘›/3 faults) in the WAN experiment setting, and plot the results\nas follows.\nVarying batch sizes . For understanding to what an extent the\nbatch size matters, we report how throughput and latency depend\non varying batch sizes in Figure 22 and 23, respectively.\n1 001 0001 00001 000001 0000001\n1\n01\n00Latency (second)B\natch Size (tx) \nHotStuff-64-no-fault BDT-sCAST-64-no-fault BDT-sRBC-64-no-fault Dumbo-64-no-fault HotStuff-100-no-fault BDT-sCAST-100-no-fault BDT-sRBC-100-no-fault Dumbo-100-no-fault\nFigure 22: Latency v.s. batch size for experiments over wide-\narea network when ğ‘›= 64 and ğ‘›= 100, respectively.\nFigure 22 illustrates how latency increases with larger batch size\nin BDT-sCAST, BDT-sRBC, HotStuff and Dumbo when ğ‘›= 64 and\n18\nğ‘› = 100, respectively. It clearly states that: Dumbo always takes\na latency much larger than BDT-sCAST, BDT-sRBC and HotStuff;\nfor BDT-sRBC, its latency increases much slower thanBDT-sCAST\nand HotStuff, in particular when ğµ = 10000, the latency of BDT-\nsRBC is around one second only, while these of BDT-sCAST and\nHotStuff have been more than 2 seconds. The slow increasing of\nBDT-sRBCâ€™s latency is mainly because its better balanced network\nload pattern.\n1 001 0001 00001 000001 00000001\nx104 2\nx104 3\nx104 Throughput (tps)B\natch Size (tx) \nHotStuff-64-no-fault BDT-sCAST-64-no-fault BDT-sRBC-64-no-fault Dumbo-64-no-fault HotStuff-100-no-fault BDT-sCAST-100-no-fault BDT-sRBC-100-no-fault Dumbo-100-no-fault\nFigure 23: Throughput v.s. batch size for experiments over\nwide-area network when ğ‘›= 64 and ğ‘›= 100, respectively.\nFigure 23 illustrates how throughput increases with larger batch\nsize in BDT-sCAST, BDT-sRBC, HotStuff and Dumbo when ğ‘›= 64\nand ğ‘› = 100, respectively. Dumbo really needs very large batch\nsize to have acceptable throughput;BDT-sCAST and HotStuff have\na similar trend that the throughput would stop to increase soon\nafter the batch sizes become larger (e.g., 10000 transactions per\nblock); in contrast, the throughput ofBDT-sRBC is increasing faster\nthan those of BDT-sCAST and HotStuff, because larger batch sizes\nin BDT-sRBC would not place much worse bandwidth load on\nthe leader, and thus can raise more significant increment in the\nthroughput.\nLatency-throughput trade-off (1/3 crashes) . We also report the\nlatency-throughput trade-off in the presence of 1/3 crashes. The\ncrashes not only lag the execution of all protocols, but also mimic\nthat a portion of Bolt instances are under denial-of-services. We\nmight fix the batch size of the pessimistic path in BDT-sCAST and\nBDT-sRBC as 106 transactions in these tests, because this batch\nsize parameter brings reasonable throughput-latency trade-off in\nDumbo. Shown in Figure 24, bothBDT-sCAST and BDT-sRBC have\nsome design spaces that show a latency better than Dumboâ€™s and\npresents a throughput always better than HotStuffâ€™s, despite that\non average 1/3 instances of Bolt are unluckily stuck to wait for\n2.5 sec to timeout without returning any optimistic output. That\nmeans our practical BDT framework does create new design space\nto harvest the best of both paths, resulting in that we can achieve\nreasonable throughput and latency simultaneously in fluctuating\ndeployment environments. 8\n8We would like to note that here we did a very pessimistic evaluation for BDT while\noptimistic evaluation for HotStuff in the sense that we manually trigger Transformer\nby manually muting a leader for 2.5s once in 50 blocks, while for HotStuff we did a\nstable leader version (with honest leader). In reality, the performance curves for BDT\nmight be a bit more to the left, while HotStuff will surely be more to the right/bottom.\n \n \n \n \n \n \nNew design space\nFigure 24: Throughput v.s. latency for experiments over\nwide-area network when ğ‘› = 64 and ğ‘› = 100, respectively\n(in case of 1/3 crash fault). We fix the fallback batch size of\nBDT instances to 106 transactions in all tests.\nF COMPLEXITY AND NUMERICAL\nANALYSES\nThis section discusses the critical complexity metrics of the BDT\nframework and those of its major modules. We then assign each\nmodule a running time cost according to our real-world experimen-\ntal data, thus enabling more precise numerical analysis to estimate\nthe expected latency of BDT in various â€œsimulatedâ€ unstable de-\nployment environments.\nComplexity analysis . Here we analyze BDT regarding its com-\nplexities. Recall that we assume the batch size ğµsufficiently large,\ne.g., Î©(ğœ†ğ‘›2 log ğ‘›), throughout the paper.\nComplexities of the fastlane (also of the optismtic cases). For the op-\ntimistic fastlane, we have two instantiations, namely Bolt-sCAST\nand Bolt-sRBC. As shown in Table 2, Bolt-sCAST is with linear\nO(ğ‘›)per-block message complexity, and the leaderâ€™s per-block\nbandwidth usage O(ğ‘›ğµ)is also linear in ğ‘›; Bolt-sRBC is with qua-\ndratic per-block message complexity as O(ğ‘›2), while the per-block\nbandwidth usage of every party is not larger than the batch size\nO(ğµ). We can also consider their latency in term of â€œroundsâ€ to\ngenerate a block, i.e., the time elapsed between when a blockâ€™s trans-\naction is first multicasted and when the honest parties output this\nblock with valid proof. The latency of generating two successive\nblocks can also be considered to reflect the confirmation latency of\nBDTâ€™s fastlane. Though both â€œfastlaneâ€ instantiations will costO(1)\nrounds to generate fastlane blocks, Bolt-sCAST has slightly less\nconcrete rounds: Bolt-sCAST can use at most 3 rounds to generate\none (pending) block and can use 5 rounds to output two successive\nblocks (thus the former block can be finalized in BDT framework);\nBolt-sRBC would cost 4 rounds to generate one (pending) block\nand use 8 rounds to output two successive blocks.\nNote that in the optimistic case when (i) the fastlane leaders are\nalways honest and (ii) the network condition is benign such that the\nfastlanes never timeout, the Pessimistic phase is not executed, so\nthe fastlane cost shown in Table 2 would also reflect the amortized\ncomplexities of the overall BDT protocol (in case that the epoch\nsize ğ¸ğ‘ ğ‘–ğ‘§ğ‘’ is large enough, e.g., ğ‘›).\nComplexities of the worst cases (disregarding the adversary) . In the\noptimistic fastlane, there is a worst-case overhead of using O(ğœ)\nasynchronous rounds to leave the tentatively optimistic execution\nwithout outputting any valid blocks. After the stop of fastlane,\nall parties enter the Transformer phase, and would participate in\n19\nTable 2: Per-block performance of different Bolt instantia-\ntions (which is also per-block cost of BDT in the good cases)\nMsg. Comm. Per-block\nlatency\nTwo blocks\nlatency\nBandwidth Cost\nLeader Others\nBolt-sCAST O(ğ‘›) O(ğ‘›ğµ) 3 rounds 5 rounds O(ğ‘›ğµ) O(ğµ)\nBolt-sRBC O(ğ‘›2) O(ğ‘›ğµ) 4 rounds 8 rounds O(ğµ) O(ğµ)\ntcv-BA, in which the expected message complexity is O(ğ‘›2), the\nexpected communication complexity is O(ğœ†ğ‘›2), and the expected\nbandwidth cost of each parties isO(ğœ†ğ‘›). Besides, if the output value\nof tcv-BA is large than zero, then the CallHelp subroutine could\nprobably be invoked, this process will incur O(ğ‘›2)overall message\ncomplexity and O(ğ‘›ğµ)per-block communication complexity and\ncauses each party to spend O(ğµ)bandwidth to fetch each block on\naverage. In the worst case, Dumbo is executed after Transformer,\nwhich on average costs overall O(ğ‘›3)messages,9 overall O(ğ‘›ğµ)\ncommunicated bits, and O(ğµ)bandwidth per party for each block if\nbatch size ğµis sufficiently large. The latency of generating a block\nin the pessimistic path is of O(1)rounds on average.\nTable 3: Per-block performance of BDT in the worst cases\nMsg. Comm. Block latency (rounds) Bandwidth Cost\nLeader Others\nBDT-sCAST O(ğ‘›3) O(ğ‘›ğµ) 3+1+ğ‘‡tcv-BA+ğ‘‡Dumbo O(ğ‘›ğµ) O(ğµ)\nBDT-sRBC O(ğ‘›3) O(ğ‘›ğµ) 4+1+ğ‘‡tcv-BA+ğ‘‡Dumbo O(ğµ) O(ğµ)\nâˆ— Note that the worst-case block latency reflects the case of turning off the\nlevel-1 fallback.\nTo summarize these, we can have the worst-case performance\nillustrated in Table 3. Note that the latency of generating a block\nshall consider the following possible worst case: the fastlane times\nout to run pace-sync, but pace-sync finalizes no fastlane block, and\nall parties have to start the pessimistic path to generate a block.\nThus, to count the worst-case latency, we need to include: (i) the\ntimeout parameter ğœ; (ii) the latency of fallback (including 1 round\nfor multicast PaceSync message and the expected latency ğ‘‡tcv-BA\nof tcv-BA), and (iii) the expected pessimistic path latency ğ‘‡Dumbo.\nHere the timeout parameter ğœin our system is not necessarily close\nto the network delay upper bound Î”, and it can represent some\nadversary-controlling â€œclock ticksâ€ to approximate the number of\nasynchronous rounds spent to generate each fastlane block, i.e.,\nO(ğœ)= O(1). For example, in BDT-sCAST, ğœ can approximate 3\nrounds because in Bolt-sCAST, the first fastlane block (i.e., the\nfirst â€œheartbeatâ€) needs 3 rounds to deliver and the interval of two\nsuccessive fastlane blocks (i.e., the interval of two â€œheartbeatsâ€) is 2\nrounds; similarly, ğœ can approximate 4 rounds in BDT-sRBC.\nComplexities in comparision to other BFT consensuses. Here we also\nsummarize the communication complexities of BDT and some\nknown BFT protocols in the optimistic case and the worst case,\nrespectively. To quantify the latency of those protocols in unstable\nnetwork environment, Table 4 also lists each protocolâ€™s average\nlatency (in â€œunitâ€ of fastlaneâ€™s good-case latency).\nThis metric considers that the fastlane has a probabilityğ›¼ âˆˆ[0,1]\nto output blocks in time, and also has a chance ofğ›½ = 1âˆ’ğ›¼that falls\n9Note that if instantiating the pessimistic path by more recent asynchronous BFT\nconsensus protocols (e.g., Speeding Dumbo) instead of Dumbo-BFT, the O(ğ‘›3)per-\nblock messages can be reduced to O(ğ‘›2).\nback and then executes the pessimistic asynchronous protocol. Let\nğ¶ be the latency of using earlier asynchronous protocols [23, 57]\ndirectly as the pessimistic path and ğ‘ be that of the state-of-the-\nart Dumbo BFT [50] and that of using MVBA for synchronization\nduring fallback. Both ğ¶and ğ‘are represented in the unit of fastlane\nlatency. According to the experimental data [50, 57],ğ¶is normally at\nhundreds and the latterğ‘is typically dozens ([57] runsğ‘›instances of\nABBA, thus rounds depend on number of parties, while [50] reduces\nit to constant). Our fallback is almost as fast as the fastlane, so its\nmagnitude around one. As such, we can do a simple calculation\nas shown in Table 4 to roughly estimate the latency of all those\nprotocols deployed in the realistic fluctuating network.\nTable 4: Complexities of BFT protocols in various settings\n(where ğµis sufficiently large s.t. all ğœ†terms are omitted, and\nğ›¼+ğ›½ = 1)\nProtocol Per-block Com. Compl. Normalized average latency\nOptim. Worst considering fastlane latency as â€œunitâ€\nPBFT [29] O(ğ‘›ğµ) âˆ 1/ğ›¼\nHotStuff [74] O(ğ‘›ğµ) âˆ 1/ğ›¼\nHBBFT [57] O(ğ‘›ğµ) O(ğ‘›ğµ) ğ¶\nDumbo [50] O(ğ‘›ğµ) O(ğ‘›ğµ) ğ‘\nKS02 [54] O(ğ‘›2ğµ) O(ğ‘›3ğµ) (ğ›¼+ ğ›½\nğ¶+ğ‘˜ğ‘)âˆ’1 â˜…\nRC05 [68] O(ğ‘›ğµ) O(ğ‘›3ğµ) (ğ›¼+ ğ›½\nğ¶+ğ‘)âˆ’1\nBDT (ours) O(ğ‘›ğµ) O(ğ‘›ğµ) (ğ›¼+ ğ›½\nğ‘+1 )âˆ’1\nâ˜… There is an integer parameter ğ‘˜in [54] to specify the degree of parallelism for the\nfastlane, thus probably incurring extra cost of fallback.\nNumerical analysis on latency in unstable network . To under-\nstand the applicability level of BDT framework, we further conduct\nmore precise numerical estimations to visualize the average latency\nof BDT and prior art (e.g. RC05) in the unstable Internet deployment\nenvironment, in particular for some typical scenarios between the\nbest and the worst cases.\nThe real-world experiment data shown in Section 7 is considered\nto specify the cost of each protocol module in the estimations. In\nparticular, we use our experimental results over the globe when\nğ‘›= 100 to specify the parameters used in the numerical estimations\nregarding both RC05 and BDT: we set the latency of fastlane as 1\nsecond (to reflect the actual latency of Bolt) and set the latency of\npessimistic path as 20 seconds (according to the measured latency\nof Dumbo); the fastlane block and the pessimistic block are set to\ncontain 104 and 106 transactions, respectively; the MVBA fallback\nin RC05 is set to use 10 seconds and our Transformer is set to cost\n1 second (cf. Figure 18); for fair comparison, we let RC05 to use the\nstate-of-the-art Dumbo protocol as its pessimistic path; other pro-\ntocols parameters (e.g., epoch size and timeout) are also taken into\nthe consideration and are set as same as those in the experiments.\nNote that a â€œsecondâ€ in the simulations is a measurement of virtual\ntime (normalized by the fastlane latency) rather than a second in\nthe real world.\nWe consider two simulated scenarios. One is illustrated in Figure\n25 (a), in which there are some portion of fastlane instances that\ncompletely fail and output nothing but just timeout and fallback\nafter idling for 2.5 seconds, while the else fastlane instances suc-\ncessfully output all optimistic blocks. In the case, BDT can save up\n20\n1\n02 03 04 05 06 07 08 09 01 00051015202530351\n02 03 04 05 06 07 08 09 01 0005101520253035L\natency of FastlaneL\natency of DumboA\nverage Latency (second)P\nercent of Failing-in-the-Begin Fastlanes (%) \nBDT with failed fastlanes RC05 with failed fastlanes(\na) When some fastlanes fail in the beginL\natency of FastlaneL\natency of Dumbo(\nb) When some fastlanes fail in the middleA\nverage Latency (second)P\nercent of Failing-in-the-Middle Fastlanes (%) \nBDT with failed fastlanes RC05 with failed fastlanes\nFigure 25: Numerical analysis to reflect the average latency\nof BDT and RC05 [68] in fluctuating deployment environ-\nment. The analysis methodology is similar to the formulas\nin Table 4 except that here consider more protocol parame-\nters such as batch size, epoch size, timeout, etc.\nto almost 10 seconds on average latency relative to RC05. This is\na result of the much more efficient fallback mechanism; more im-\nportantly, the efficient fallback brings much robuster performance\nagainst unstable network environment, for example, RC05 starts to\nperform worse than Dumbo once more than 45% fastlane instances\ncompletely fail in the beginning of their executions, while BDT can\nbe faster than Dumbo until more than 75% fastlane instances com-\npletely fail. The other case is shown in Figure 25 (b), where some\nfastlane instances stop to progress in the middle of their executions\n(e.g., stop to progress after 25 optimistic blocks are finalized) and\nthen wait for 2.5 seconds to timeout and fallback. In the case, BDT\nperforms almost as fast as its underlying fastlane (i.e., the average\ndelay is really close to 1 second) despite the overheads of timeout\nand Transformer in this fluctuating network condition; in contrast,\nRC05 can be an order of magnitude slower than BDT, and it would\nbe even slower than Dumbo if more than 55% fastlane instances\nfail to progress in the middle of their optimistic executions.\n21"
}