{
    "title": "Dermatological Knowledge and Image Analysis Performance of Large Language Models Based on Specialty Certificate Examination in Dermatology",
    "url": "https://openalex.org/W4402965924",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2916582303",
            "name": "Ka Siu Fan",
            "affiliations": [
                "Imperial College London",
                "University of Surrey"
            ]
        },
        {
            "id": "https://openalex.org/A2980689001",
            "name": "Ka Hay Fan",
            "affiliations": [
                "Imperial College London",
                "University of Surrey"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2995872180",
        "https://openalex.org/W4319332969",
        "https://openalex.org/W4376866715",
        "https://openalex.org/W4402432594",
        "https://openalex.org/W2910737747",
        "https://openalex.org/W4399208599",
        "https://openalex.org/W4392749797",
        "https://openalex.org/W4385266429",
        "https://openalex.org/W4392508930",
        "https://openalex.org/W4400041715",
        "https://openalex.org/W4319460874",
        "https://openalex.org/W4376640725",
        "https://openalex.org/W4368340908",
        "https://openalex.org/W4401172013",
        "https://openalex.org/W4379093714",
        "https://openalex.org/W4390503224",
        "https://openalex.org/W4402079352",
        "https://openalex.org/W4399923676",
        "https://openalex.org/W4391644915",
        "https://openalex.org/W4377014734",
        "https://openalex.org/W4384071683",
        "https://openalex.org/W4390055906",
        "https://openalex.org/W4402433122",
        "https://openalex.org/W4368360859",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4380291159",
        "https://openalex.org/W4391815795",
        "https://openalex.org/W4402552508",
        "https://openalex.org/W4391808381",
        "https://openalex.org/W6860734135",
        "https://openalex.org/W4388813824",
        "https://openalex.org/W4389577763",
        "https://openalex.org/W4392621058",
        "https://openalex.org/W6864257345",
        "https://openalex.org/W4394579620",
        "https://openalex.org/W2966555834",
        "https://openalex.org/W4366989525",
        "https://openalex.org/W4388077303",
        "https://openalex.org/W4319301505",
        "https://openalex.org/W4205941964",
        "https://openalex.org/W2803760365",
        "https://openalex.org/W4380997513",
        "https://openalex.org/W4388941016",
        "https://openalex.org/W4378470708",
        "https://openalex.org/W2559833064",
        "https://openalex.org/W4207051106",
        "https://openalex.org/W4394573140",
        "https://openalex.org/W4390974900"
    ],
    "abstract": "Large language models (LLMs) are trained using large datasets and may be applied to language-based tasks. Studies have demonstrated their ability to perform and pass postgraduate medical examinations, and with the increasingly sophisticated deep learning algorithms and incorporation of image-analysis capabilities, they may also be applied to the Specialty Certificate Examination (SCE) in Dermatology. The Dermatology SCE sample questions were used to assess the performance of five freely available and high-performance LLMs. The LLMsâ€™ performances were recorded by comparing their output on multiple-choice questions against the sample answers. One hundred questions, four of which included photographs, were entered into the LLMs. The responses were recorded and analysed, with the pass mark set at 77%. The accuracies for Claude-3.5 Sonnet, Copilot, Gemini, ChatGPT-4o, and Perplexity were 87, 88, 75, 90, and 87, respectively (p = 0.023). The LLMs were generally capable of interpreting and providing reasoned responses to clinical scenarios and clinical data. This continues to demonstrate the potential of LLMs in both medical education and clinical settings.",
    "full_text": null
}