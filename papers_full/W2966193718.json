{
  "title": "Differentiable Physics and Stable Modes for Tool-Use and Manipulation Planning - Extended Abtract",
  "url": "https://openalex.org/W2966193718",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A2121676736",
      "name": "Marc Toussaint",
      "affiliations": [
        "Max Planck Institute for Intelligent Systems",
        "University of Stuttgart"
      ]
    },
    {
      "id": "https://openalex.org/A2652795876",
      "name": "Kelsey R. Allen",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2105820431",
      "name": "Kevin A Smith",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2149572011",
      "name": "Joshua B. Tenenbaum",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2059100041",
    "https://openalex.org/W2102883217",
    "https://openalex.org/W2610753682",
    "https://openalex.org/W4246876444",
    "https://openalex.org/W2258731934",
    "https://openalex.org/W2497608796",
    "https://openalex.org/W2141841102",
    "https://openalex.org/W2097556395",
    "https://openalex.org/W2805883505",
    "https://openalex.org/W3021208093",
    "https://openalex.org/W2101340954",
    "https://openalex.org/W2031738727",
    "https://openalex.org/W2510159359",
    "https://openalex.org/W25306814",
    "https://openalex.org/W2008128677",
    "https://openalex.org/W4230987057",
    "https://openalex.org/W2739341730",
    "https://openalex.org/W4230789743",
    "https://openalex.org/W2403069916",
    "https://openalex.org/W2015149365"
  ],
  "abstract": "We propose to formulate physical reasoning and manipulation planning as an optimization problem that integrates first order logic, which we call Logic-Geometric Programming.",
  "full_text": "Differentiable Physics and Stable Modes for Tool-Use and Manipulation Planning\n– Extended Abstract\u0003\nMarc Toussaint1;2y , Kelsey R. Allen3 , Kevin A. Smith3 and Joshua B. Tenenbaum3\n1Machine Learning & Robotics Lab, University of Stuttgart, Germany\n2Max Planck Institute for Intelligent Systems, Stuttgart, Germany\n3Massachusetts Institute of Technology, Cambridge, MA 02139\nmarc.toussaint@informatik.uni-stuttgart.de, fkrallen, k2smith, jbtg@mit.edu\nAbstract\nWe propose to formulate physical reasoning and\nmanipulation planning as an optimization prob-\nlem that integrates ﬁrst order logic, which we call\nLogic-Geometric Programming.\n1 Introduction\nPhysical reasoning is a corner stone of intelligence in hu-\nmans and animals. A large body of animal behavior stud-\nies that aim at characterizing intelligence in animals focus\non experiments related to physical reasoning in novel situa-\ntions, such as tool use, means-end sequential object manipu-\nlation, an the anticipation of physical effects [K¨ohler, 1917;\nWimpenny et al., 2009]. Fundamentally, we are interested in\nAI representations and methods that would enable such gen-\neral physical reasoning.\nEvidence from cognitive science suggests that people have\nan “intuitive physics engine” [Battaglia et al., 2013 ] which\ncan be used to simulate the outcome of an action or tool ma-\nnipulation [Osiurak and Badets, 2016 ], and have dedicated\nneural architectures near the motor cortex for implementing\nthis capability [Fischer et al., 2016]. But a typical physics en-\ngine only predicts outcomes for an action, not how to choose\nthose actions.\nPhysical reasoning can be viewed as a problem ofinverting\nphysics, which means that we can formulate any objectives\nor constraints on the end result or trajectory of the simula-\ntion and solve for the inputs (control signals of an embedded\nrobot, or parameters of the scene or kinematics) that render\nthe desired constraints true. Fully (auto-) differentiable phys-\nical simulations are currently discussed as candidates for in-\nverting physics [Todorov, 2011; Filipe de Avila Belbute-Peres\nand J. Zico Kolter, 2017], and could be embedded in end-to-\nend trainable systems [Tamar et al., 2016].\nHowever, we argue that gradients alone cannot solve the\nproblem of inverting physics, for several reasons. From the\nNLP theory we know that their solutions are only piece-wise\ndifferentiable, where pieces are deﬁned by stable constraint\n\u0003The original paper “Differentiable Physics and Stable Modes\nfor Tool-Use and Manipulation Planning” was ﬁrst presented at the\nRobotics: Science and Systems (R:SS 2018) conference in 2018.\nyContact Author\nactivity (discussed below). From the theory on path planning\nwe know that our problem is NP complete [LaValle, 2006].\nFinally, the problem is highly non-unimodal, where different\ncontact sequences imply different local optima. Overall the\nstructure inverse problem includes a combinatorics of local\noptimal and discontinuities in physical effects.\nOur approach is to use logic to explicitly represent the\ncombinatorics of possible physical interactions and respec-\ntive local optima and differentiable modes. This follows the\nparadigm of Mixed-Integer Program (MIP) formulations in\nhybrid control synthesis [Deits and Tedrake, 2014 ]. How-\never, it extends this to 1st-order logic, leveraging the strong\ngeneralization over objects of classical AI formulations. It\nalso follows the standard task and motion planning (TAMP)\napproach of using logic to describe the task level, but now\ndescribes the combinatorics of possible physical interactions.\nGiven this general approach, the core of our method is to\nintroduce explicit predicates and a PDDL-style decision rules\nthat describe possible sequences of modes, as well as ground-\ning these modes in differentiable constraints on the resulting\npath optimization problem.\nIn this extended abstract we focus on aspects that could not\nbe discussed thoroughly in the original presentation [Tous-\nsaint et al., 2018]. In particular, we ﬁrst discuss why physics\nis only piece-wise differentiable, which we believe is key to\nunderstand the limitations of purely gradient-based methods.\nWe then summarize the technical approach, including Multi-\nBound Tree Search (MBTS), which was previously only de-\nscribed in [Toussaint and Lopes, 2017]. More speciﬁcally, we\npresent the simpliﬁed version of MBTS that reﬂects the cur-\nrent implementation of our Logic-Geometric Program (LGP)\nsolver3, which pinpoints that the key for efﬁciency currently\nis in the formulation and solver of the various optimization\nsub-problems (the bounds, or “heuristics”), rather than in\nlogic search itself. We then brieﬂy summarize our experimen-\ntal results, and discuss in more depth limitations and chal-\nlenges with the current solver.\n2 Physics Is Only Piece-Wise Differentiable\nPhysics can be described by a differential equation _x =\nf(x) (neglecting external controls u). One of the core chal-\nlenges for physical simulation is to integrate physical dy-\nnamics when hard objects interact. There are roughly three\napproaches: (1) smoothly modeling contact interactions as\nProceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence (IJCAI-19)\n6231\nx\u0003\n\u0012\n(a)\n (b)\n (c)\n (d)\nFigure 1: Illustrations for non-differentiable physics: (a) The solu-\ntion map for minx(x\u0000 \u0012)2 s.t. x \u0015 0, (b) a ball dropping close to\na corner, (c) a ball might be touched or not by a robot, (d) jumping\ncontact points for a cube.\nspring-dampers and choosing very small time steps for in-\ntegration; (2) detecting events (by backtracking penetra-\ntions) and applying impulse exchanges there (which leads to\nnon-regular time stepping); and (3) choosing a ﬁxed coarse\ntime stepping scheme but formulating the next state xt+1 =\nargminx P(x;xt) as the solution of a non-linear constrained\nmathematical program P, typically a so-called linear comple-\nmentary problem (LCP) [Posa et al., 2014]. The latter is the\nstandard in control and many physical simulations.\nIn all cases, physical simulation is a forward iteration of\ncomputing xt+1 as a function of xt. If each iteration is differ-\nentiable, we can back-propagate and compute gradients dxT\ndxt\nof any conﬁguration xT w.r.t. any previous conﬁguration xt\n(and analogously, any control signal or conﬁguration param-\neter). A series of recent works aim to embed such differ-\nentiable physics simulation in trainable computation graphs\n[Filipe de Avila Belbute-Peres and J. Zico Kolter, 2017].\nHowever, ﬁrst, physics is not differentiable; it is only\npiece-wise differentiable. And second, typical objective func-\ntions have a combinatorics of local optima—and unlike to\nwhat seems to be the case in neural networks, here the ma-\njority of local optima are likely to be infeasibility traps and\nonly one of many local optima might be an acceptable solu-\ntion to the problem.\n2.1 Differentiability of NLP Solutions\nConcerning differentiability, let us consider the case\nwhere we simulate physics by iteratively solving xt+1 =\nargminx P(x;xt), for some non-linear mathematical pro-\ngram (NLP) P. Each xt+1 fulﬁlls the (Karush-Kuhn-Tucker)\nKKT conditions of P. The classical literature on sensitivity\nanalysis of NLPs considers the quasi-solution map S : \u0012 7!\nfx : KKT hold for P(\u0012)gof a parametrized NLPs P(\u0012), and\ninvestigates how S(\u0012) varies with a change in \u0012. E.g., [Levy\nand Rockafellar, 1995] show that “under a standard constraint\nqualiﬁcation [...], S is differentiable in a generalized sense,\nand we present a formula for its derivative”. Also earlier\nwork provides differentiability results [Fiacco and Kypari-\nsis, 1985 ], and later work generalizations [Izmailov, 2010].\nThis classical work gives more insight in the role of con-\nstraint qualiﬁcation for differentiability than more recent re-\ndiscoveries [Filipe de Avila Belbute-Peres and J. Zico Kolter,\n2017]. As a conclusion, NLPs are only piece-wise differen-\ntiable. They are not differentiable across a change of con-\nstraint activity, e.g., a change of contact conﬁguration in a\nphysical simulation.\nIt is straight-forward to give simple illustrations of the non-\ndifferentiability of physical interaction. As a ﬁrst minimal\nexample, consider the problem minx(x\u0000\u0012)2 s.t. x \u00150. It\nhas the solution map S : \u0012 7!x\u0003 = max f0;xg, which is\nthe ReLu illustrated in Fig. 1(a). This principle translates to\nphysical settings: Figure (b) illustrates a ball dropping close\nto a corner, where the end state will bifurcate depending on\nwhether it hits the corner or not. Figure (c) is similar, where\nthe ball’s end-state depends on the robot joint angles, depend-\ning on whether the robot touched the ball or not. And in Fig-\nure (d) the contact points jump with the cube’s angle, which\nleads to bifurcation and chaos, if iterated.\nOur LGP approach is to use logic to chop the overall prob-\nlem of inverting physics into its (smoothly) differentiable\npieces, which we call modes. It uses logic to explicitly enu-\nmerate these modes.\n2.2 The Zero Gradient Problem, Relaxation, and\nLocal Optima\nA physical world of hard objects has a very particular struc-\nture: objects interact only when they are in contact. Interac-\ntion should here be understood in terms of gradient propaga-\ntion: The gradient of an object w.r.t. any aspect of another\nobject at any previous time is zero, unless there was some\n(chain of) contacts over time. Therefore, even if a conﬁgu-\nration may have thousands of degrees of freedom, gradient\npropagation between these is rather sparse.\nPurely gradient-based planning for physical interaction\nplanning has a serious problem with zero gradients. If the\ninitial conﬁguration, or rather, the conﬁguration path initial-\nization, does not already have an appropriate chain of contact\ninteractions to inﬂuence certain target objects, the gradient of\ngoal objective is exactly zero. Therefore, the gradient does\nnot help to decide on which objects should interact in a plan.\nPrevious work has proposed to relax the interaction of ob-\njects and proposed force exchange models that smoothly de-\ncay with the distance between objects. This relaxation can be\nscheduled to be very smooth in the initial phase of optimiza-\ntion, which might allow the optimizer to ﬁnd a rough inter-\naction plan, and tighten it during optimization to the limit of\nthe exact hard contact model [Mordatch et al., 2012]. How-\never, we should be clear that this approach still is greedy: it\nwill ﬁxate on the ﬁrst interaction schedule that gradient de-\nscend in the initial relaxed phase converged to, without any\nmechanisms to escape local optima. The problem of deciding\non an interaction sequence falls into the category of classical\nPDDL planning, and it should be clear that gradient descent\non a relaxation cannot solve this inherently NP hard problem.\nIn LGP we employ classical search over possible mode se-\nquences and then constrain the mathematical program to con-\nverge to a solution within this mode sequence, exploiting the\nsmooth differentiability of this mode even in the early itera-\ntions of optimization that are not yet within the mode. The\nkey for efﬁciency for this approach are good heuristics for\nsearch, where we propose using a hierarchy of simpler math-\nematical problems that deﬁne lower bounds.\n3 Logic-Geometric Programming\nWe consider the conﬁguration space X = Rn \u0002SE(3)m of\nan n-dimensional robot and mrigid objects, in an initial con-\nProceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence (IJCAI-19)\n6232\nﬁguration x0 2X. We aim to ﬁnd a path x: [0;T] !X\nmin\nx\nZ T\n0\nfpath(\u0016x(t)) dt+ fgoal(x(T))\ns.t. x(0) = x0; hgoal(x(T)) = 0; ggoal(x(T)) \u00140 ;\n8t2[0;T] : hpath(\u0016x(t)) = 0; gpath(\u0016x(t)) \u00140 ;\n(1)\nwhere (h;g)path deﬁne path constraints which depend on\n\u0016x(t) = ( x(t); _x(t);x(t)) and describe what is physically\nand kinematically feasible. The function fpath deﬁnes control\ncosts, which in our experiments we choose as sum-of-squares\nof joint accelerations. And (f;h;g )goal specify arbitrary ob-\njectives or constraints on the ﬁnal conﬁguration. In our ex-\nperiments this will be a single equality constraint expressing\ncontact between an object and a target.\nWe augment this formulation with additional logic deci-\nsion variables a1:K;s1:K, so that we may assume that the\npath constraints (h;g)path are smooth for constant logical state\nsk, and we have smooth constraints for transitioning between\nlogical states. We call this a Logic-Geometric Program [Tou-\nssaint, 2015; Toussaint and Lopes, 2017; Toussaint et al.,\n2018],\nmin\nx;a1:K;s1:K\nZ T\n0\nfpath(\u0016x(t)) dt+ fgoal(x(T))\ns.t. x(0) = x0; hgoal(x(T)) = 0; ggoal(x(T)) \u00140;\n8t2[0;T] : hpath(\u0016x(t);sk(t)) = 0;\ngpath(\u0016x(t);sk(t)) \u00140\n8k2f1;::;K g: hswitch(^x(tk);ak) = 0;\ngswitch(^x(tk);ak) \u00140;\nsk 2succ(sk-1;ak) : (2)\nHere, ^x = ( x; _x; _x0) captures the conﬁguration velocity _x\nbefore and after ( _x0) an instantaneous impulse exchange at a\nstate transition.\nIn practice, feasible logical decision sequences a1:K are\ndescribed in PDDL. We call the sequence a1:K a skeleton\n[Lozano-P´erez and Kaelbling, 2014], which uniquely deﬁnes\ns1:K, and use the notation P(a1:K) to denote the path opti-\nmization problem (2) for a given skeleton. As (h;g)path and\n(h;g)switch are smooth conditional to the logic decisions, all\nobjectives and constraints in P(a1:K) are smooth and our im-\nplementations are differentiable to provide constraint Jaco-\nbians and pseudo-Hessians when the costs fpath;goal are sum-\nof-squares terms. Solving P(a1:K) implicitly solves for all\naction parameters jointly and optimally: E.g. when the se-\nquence involves a grasp ﬁrst, a hit second, and a placement\nthird, then all parameters of these actions (grasp pose, hit-\nting angle, placement pose) are jointly optimized to yield the\noverall optimal manipulation path.\nIn [Toussaint et al., 2018] we detail the concrete predicates\nused to represent geometric constraints (touch, inside, above)\nand constraints on the system dynamics (e.g., impulse, sta-\nbleFree, dynamicFree). For instance, dynamicFree imposes\nthe Newton-Euler equation on a particular object,impulse im-\nposes instantaneous impulse exchange between two objects,\nand touch imposes the distance between two convex shapes to\nbe zero. In this way, logic predicates are grounded as differ-\nentiable constraints on the resulting path optimization prob-\nlem.\n4 Solver\nWe assume we have a generic NLP solver 1 which, for any\nNLP P returns either infeasible or a feasible solution x and\ncost fP(x). Note that the NLP solver does not return further\ninsight in which constraints rendered a solution infeasible,\nwhat would be a minimal constrained removal for feasibility,\nor what are the origin of costs. The higher-level algorithm can\nonly send P-queries to the NLP solver and check feasibility\nand costs.\nAs higher-level algorithm we use Multi-Bound Tree Search\n(MBTS) [Toussaint and Lopes, 2017], which leverages a hier-\narchy of bounds to prioritize search and NLP computations,\nthereby integrating the concepts of branch-and-bound from\nMIP. We sketch the method here brieﬂy and defer to the orig-\ninal publication for more details.\nAssume that purely symbolic tree search (based on the\ngiven PDDL) has found a node that represent a potential so-\nlution skeleton a1:K. Trying to solve the full path problem\nP(a1:K) is in the order of roughly \u001810 seconds and far too\nexpensive as a heuristic to guide search. We therefore de-\nﬁne a hierarchy of lower bounds ofP(a1:K), each of which is\na simpliﬁcation of the full path problem, which essentially\ndrops constraints, cost terms and decision variables and is\nstraight-forward to prove to be a lower bound. Speciﬁcally,\nthe lower bound P1(a1:k) optimizes only over a single world\nconﬁguration x(tk) for k 2f1;::;K g, a generalized form of\ninverse kinematics, and we can compute this efﬁciently for\nall k 2f1;::;K gto check feasibility of intermediate conﬁg-\nurations. If all these are feasible, we then evaluate feasibil-\nity of P2(a1:K), which jointly optimizes over all intermedi-\nate conﬁgurations (keyframes) (x(t1);::;x (tK)), but neglects\nthe motion paths connecting them. Only if P2(a1:K) is also\nfeasible, we eventually try solving for the full path P(a1:K).\nMBTS maintains best-ﬁrst queues for tree expansion as\nwell as for computations of poses (P 1), sequences (P2), and\npaths (P), and schedules computations following the above\nprinciples. Importantly, it also prunes large parts of the tree if\nsome pose computations (P1) turn out infeasible: Similar to\nthe infeasible in [Srivastavaet al., 2014] we add a predicate to\nthe PDDL description that rules out the corresponding action\nalso in other branches of the tree.\n5 Summary of Experiments\nWe point the reader to2 for a collection of videos demonstrat-\ning the approach, and here3 for the available source code.\nWe investigated our method on 6 problems as illustrated\nand described in Fig. 2. The problems were designed to\n1We use KOMO [Toussaint, 2017], an Augmented Lagrangian\nquasi-Newton method.\n2Videos: http://ipvs.informatik.uni-stuttgart.de/mlr/lgp/\nhttps://www.youtube.com/watch?v=-L4tCIGXKBE\n3Source code: https://github.com/MarcToussaint/rai-python\nhttps://github.com/MarcToussaint/18-RSS-PhysicalManipulation\nProceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence (IJCAI-19)\n6233\nFigure 2: In the 6 investigated problems the goal is to reach for\nthe red ball or get the blue ball in the green area. Solutions involve\nusing a hook to pull a desired object, push-sliding a ball along a wall,\npushing a ball onto a strip of paper to then pull it closer, hitting a ball\nwith a stick, throwing a box at a ball, and using a hook to reach for\nanother hook to reach a ball.\ncover a spectrum of types of interactions, including the need\nto use tools, hit objects, or throw objects in order to reach the\ngoal. Fig. 3 displays a sequences of key frames for the dou-\nble hook problem; it is these keyframes that are optimized\nin P2. The accompanying videos illustrate solutions to the\nproblems. The source code includes the precise scene de-\nscriptions. Note that the videos display the computed paths\nx, not a “simulation” of their execution. The fact that they\n“look like a simulation” shows that the constraints we impose\non paths result in physically plausible paths.\nThe solver surprised us in ﬁnding much larger varieties of\nsolutions than anticipated. For instance, in problem 1 a natu-\nral solution is grasping the hook, pulling the ball, and grasp-\ning it. Our method also found solutions that involve hitting\nthe ball, or sliding the hook to the ball to hit it. Handovers are\nmuch more frequent than anticipated. The solver exploited\nthe combinatorics of manipulations that are possible with the\ngiven primitives beyond what we had in mind when designing\nthe problems.\nThe solver is an anytime method. For each problem we\nran it until 12 solutions (with different skeletons) were found\nor 400 seconds were exceeded. The solver then presents and\nranks solutions by their cost. First reasonable solutions are\nroughly found after 20-200 seconds, depending on depth of\nthe simplest solution. Interestingly, a major amount of com-\nputation time is spend on trying to solve NLPs that eventually\nturn out infeasible. Although the sub-problems are not guar-\nanteed to be convex, we empirically tested how often restarts\nconverge to the same optimum and found a high degree of\nconsistency of convergence. See [Toussaint et al., 2018] for\nmore details.\n6 Discussion\nOur approach is, to our knowledge, the ﬁrst to embed dy-\nnamic physical manipulations in a task and motion planning\n(TAMP) framework, combining a discrete logic level for se-\nFigure 3: Example sequence of key frames (subject to P2) for the\ndouble hook problem.\nquences of possible interaction modes with a continuous path\noptimization level. We tackled sequential manipulation and\ntool-use planning problems, a hallmark of intelligent behav-\nior. But the approach also raises a series of fundamental ques-\ntions for future research, which we want to discuss here.\nThe current approach focuses on planning against a deter-\nministic model of physics. It therefore neither constructs a\nreactive controller for execution, nor estimates the robustness\nof plans under stochasticity. Extending our path optimization\napproach to account for probabilities, e.g., to a stochastic op-\ntimal control setting, is therefore a core challenge. How to\neffectively represent beliefs, that is, represent possible path\ndistributions, including the combinatorics implicit in the logic\nas well as the complementarity condition of the KKT condi-\ntions seems a key question.\nIn the present study we deﬁned a concrete set of possible\nmodes by hand, including speciﬁc modes for stable grasps\nand placements. We experimented with using only a sin-\ngle and fundamental mode predicate which only represents\ncontact between objects and lets the NLP solver decide on\nexchanged forces (using complementarity formulations sim-\nilar to [Posa et al., 2014 ]). The videos 2 demonstrate simple\nresults. However, while being very general, it scales much\nworse than the hand-designed interaction modes. The poten-\ntial to learn efﬁcient interaction modes is an interesting av-\nenue for future research.\nThe present MBTS solver uses trivial tree search instead\nof efﬁcient PDDL solvers to ﬁnd potential skeletons. This\ncan easily be replaced (assuming that PDDL solvers can be\nmade to enumerate all possible symbolic solutions), but com-\nputation time spent on logic search is marginal in the current\napplications. Scaling to larger domains is limited much more\nby the large NLPs to be solved. Our approach can be viewed\nas an extreme, where the eventual solution jointly optimizes\nover all decision variables, whereas all previously existing\nTAMP solvers construct solutions in a very decomposed man-\nner. Scaling to larger domains will require ﬁnding a compro-\nmise between joint optimization and full decomposition.\nProceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence (IJCAI-19)\n6234\nReferences\n[Battaglia et al., 2013] Peter Battaglia, Jessica Hamrick, and\nJoshua B Tenenbaum. Simulation as an engine of phys-\nical scene understanding. Proceedings of the National\nAcademy of Sciences, 110:18327–18332, 2013.\n[Deits and Tedrake, 2014] Robin Deits and Russ Tedrake.\nFootstep planning on uneven terrain with mixed-integer\nconvex optimization. In RAS Int. Conf. on Humanoid\nRobots. IEEE, 2014.\n[Fiacco and Kyparisis, 1985] Anthony V . Fiacco and Jerzy\nKyparisis. Sensitivity analysis in nonlinear programming\nunder second order assumptions. In Systems and Opti-\nmization, pages 74–97. Springer, 1985.\n[Filipe de Avila Belbute-Peres and J. Zico Kolter, 2017]\nFilipe de Avila Belbute-Peres and J. Zico Kolter. A\nModular Differentiable Rigid Body Physics Engine. In\nNeural Information Processing Systems (NIPS’17), 2017.\n[Fischer et al., 2016] Jason Fischer, John G Mikhael,\nJoshua B Tenenbaum, and Nancy Kanwisher. Functional\nneuroanatomy of intuitive physical inference.Proceedings\nof the national academy of sciences, 113:E5072–E5081,\n2016.\n[Izmailov, 2010] Alexey F Izmailov. Solution sensitivity for\nKarush–Kuhn–Tucker systems with non-unique Lagrange\nmultipliers. Optimization, 59(5):747–775, 2010.\n[K¨ohler, 1917] Wolfgang K ¨ohler. Intelligenzpr¨ufungen am\nMenschenaffen. Springer, Berlin (3rd edition, 1973), 1917.\nEnglish version: Wolgang K¨ohler (1925): The Mentality of\nApes. Harcourt & Brace, New York.\n[LaValle, 2006] Steven M. LaValle. Planning Algorithms.\nCambridge university press, 2006.\n[Levy and Rockafellar, 1995] Adam B Levy and R. Tyrrell\nRockafellar. Sensitivity of Solutions in Nonlinear Pro-\ngramming Problems with Nonunique Multipliers. In Re-\ncent Advances in Nonsmooth Optimization, pages 215–\n223. WORLD SCIENTIFIC, September 1995.\n[Lozano-P´erez and Kaelbling, 2014] Tom´as Lozano-P ´erez\nand Leslie Pack Kaelbling. A constraint-based method\nfor solving sequential manipulation planning problems.\nIn Int. Conf. on Intelligent Robots and Systems (IROS’14),\npages 3684–3691. IEEE, 2014.\n[Mordatch et al., 2012] Igor Mordatch, Emanuel Todorov,\nand Zoran Popovi ´c. Discovery of complex behaviors\nthrough contact-invariant optimization.ACM Transactions\non Graphics (TOG), 31(4):43, 2012.\n[Osiurak and Badets, 2016] Franc ¸ois Osiurak and Arnaud\nBadets. Tool use and affordance: Manipulation-based ver-\nsus reasoning-based approaches. Psychological Review,\n123:534, 2016.\n[Posa et al., 2014] Michael Posa, Cecilia Cantu, and Russ\nTedrake. A direct method for trajectory optimization of\nrigid bodies through contact. The International Journal of\nRobotics Research, 33(1):69–81, 2014.\n[Srivastava et al., 2014] Siddharth Srivastava, Eugene Fang,\nLorenzo Riano, Rohan Chitnis, Stuart Russell, and Pieter\nAbbeel. Combined task and motion planning through\nan extensible planner-independent interface layer. In Int.\nConf. on Robotics and Automation (ICRA’14), pages 639–\n646. IEEE, 2014.\n[Tamar et al., 2016] Aviv Tamar, Yi Wu, Garrett Thomas,\nSergey Levine, and Pieter Abbeel. Value iteration net-\nworks. In Advances in Neural Information Processing Sys-\ntems, pages 2154–2162, 2016.\n[Todorov, 2011] Emanuel Todorov. A convex, smooth and\ninvertible contact model for trajectory optimization. In\nInt. Conf. on Robotics and Automation (ICRA’11), pages\n1071–1076. IEEE, 2011.\n[Toussaint and Lopes, 2017] Marc Toussaint and Manuel\nLopes. Multi-bound tree search for logic-geometric pro-\ngramming in cooperative manipulation domains. In Proc.\nof the IEEE Int. Conf. on Robotics and Automation (ICRA\n2017), 2017.\n[Toussaint et al., 2018] Marc Toussaint, Kelsey R Allen,\nKevin A Smith, and Josh B Tenenbaum. Differentiable\nphysics and stable modes for tool-use and manipulation\nplanning. In Proc. of Robotics: Science and Systems (R:SS\n2018), 2018.\n[Toussaint, 2015] Marc Toussaint. Logic-geometric pro-\ngramming: An optimization-based approach to combined\ntask and motion planning. In Proc. of the Int. Joint Conf.\non Artiﬁcial Intelligence (IJCAI 2015), 2015.\n[Toussaint, 2017] Marc Toussaint. A tutorial on Newton\nmethods for constrained trajectory optimization and rela-\ntions to SLAM, Gaussian Process smoothing, optimal con-\ntrol, and probabilistic inference. In Jean-Paul Laumond,\neditor, Geometric and Numerical Foundations of Move-\nments. Springer, 2017.\n[Wimpenny et al., 2009] Joanna H Wimpenny, Alex AS\nWeir, Lisa Clayton, Christian Rutz, and Alex Kacelnik.\nCognitive processes associated with sequential tool use in\nnew caledonian crows. PLoS One, 4:e6471, 2009.\nProceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence (IJCAI-19)\n6235",
  "topic": "Differentiable function",
  "concepts": [
    {
      "name": "Differentiable function",
      "score": 0.7392001748085022
    },
    {
      "name": "Computer science",
      "score": 0.5985438823699951
    },
    {
      "name": "Order (exchange)",
      "score": 0.4428776800632477
    },
    {
      "name": "Programming language",
      "score": 0.37302541732788086
    },
    {
      "name": "Mathematical optimization",
      "score": 0.3266562521457672
    },
    {
      "name": "Mathematics",
      "score": 0.16139480471611023
    },
    {
      "name": "Pure mathematics",
      "score": 0.06358891725540161
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Finance",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210135521",
      "name": "Max Planck Institute for Intelligent Systems",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I100066346",
      "name": "University of Stuttgart",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I63966007",
      "name": "Massachusetts Institute of Technology",
      "country": "US"
    }
  ]
}