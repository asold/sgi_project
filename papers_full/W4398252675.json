{
    "title": "Partial discharge localization in power transformer tanks using machine learning methods",
    "url": "https://openalex.org/W4398252675",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5098777563",
            "name": "Farzin Khodaveisi",
            "affiliations": [
                "Bu-Ali Sina University"
            ]
        },
        {
            "id": "https://openalex.org/A2151741246",
            "name": "Hamidreza Karami",
            "affiliations": [
                "HES-SO University of Applied Sciences and Arts Western Switzerland"
            ]
        },
        {
            "id": "https://openalex.org/A5102675331",
            "name": "Matin Zarei Karimpour",
            "affiliations": [
                "Hamedan University of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2120368504",
            "name": "Marcos Rubinstein",
            "affiliations": [
                "HES-SO University of Applied Sciences and Arts Western Switzerland"
            ]
        },
        {
            "id": "https://openalex.org/A2057551680",
            "name": "Farhad Rachidi",
            "affiliations": [
                "École Polytechnique Fédérale de Lausanne"
            ]
        },
        {
            "id": "https://openalex.org/A5098777563",
            "name": "Farzin Khodaveisi",
            "affiliations": [
                "Bu-Ali Sina University"
            ]
        },
        {
            "id": "https://openalex.org/A2151741246",
            "name": "Hamidreza Karami",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5102675331",
            "name": "Matin Zarei Karimpour",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2120368504",
            "name": "Marcos Rubinstein",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2057551680",
            "name": "Farhad Rachidi",
            "affiliations": [
                "École Polytechnique Fédérale de Lausanne"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2991242907",
        "https://openalex.org/W3118328364",
        "https://openalex.org/W2140785014",
        "https://openalex.org/W2032386162",
        "https://openalex.org/W2153678297",
        "https://openalex.org/W2141157014",
        "https://openalex.org/W2110606923",
        "https://openalex.org/W2115383907",
        "https://openalex.org/W3009408004",
        "https://openalex.org/W3110754121",
        "https://openalex.org/W3199813641",
        "https://openalex.org/W4239510810",
        "https://openalex.org/W2295598076",
        "https://openalex.org/W2919115771",
        "https://openalex.org/W4224758958",
        "https://openalex.org/W2087309216"
    ],
    "abstract": null,
    "full_text": "1\nVol.:(0123456789)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports\nPartial discharge localization \nin power transformer tanks using \nmachine learning methods\nFarzin Khodaveisi 1, Hamidreza Karami 2*, Matin Zarei Karimpour 3, Marcos Rubinstein 2 & \nFarhad Rachidi 4\nThis paper presents a comparison of machine learning (ML) methods used for three-dimensional \nlocalization of partial discharges (PD) in a power transformer tank. The study examines ML and deep \nlearning (DL) methods, ranging from support vector machines (SVM) to more complex approaches \nlike convolutional neural networks (CNN). Multiple case studies are considered, each with different \nattributes, including sensor position, frequency content of the PD signal, and size of the transformer \ntank. The paper focuses on predicting the PD location in three-dimensional space using single-sensor \nelectric field measurements. Various aspects of each method are analyzed, such as the input signal, \ncore methodology, correlation coefficient between the predicted location and the actual location, \nand root mean square error (RMSE). These features are discussed and compared across the different \nmethods. The results indicate that the CNN model exhibits superior performance in terms of location \naccuracy among the methods considered.\nKeywords Machine learning, Deep learning, Power energy system, Power transformers, Partial discharge \nlocalization, Conditional monitoring in power system\nSource localization has many applications in fields such as medicine, acoustics, electromagnetics, and  lightning1. \nIn the realm of electromagnetics, Partial discharges (PDs) are electrical breakdowns that occur within electrical \ninsulations, such as those in transformers. Over time, PDs can lead to the complete breakdown of the insula-\ntion system, causing extensive damage to the transformer. PDs are a major contributor to the failure of power \ntransformers, transmission lines, and gas insulation, among other components. Any malfunction in a power \ntransformer can result in power outages and reduced reliability of electrical power networks. Therefore, the early \ndetection and localization of PDs is crucial in order to prevent potential hazards and minimize further  damage2,3.\nPD localization  techniques 2 can be categorized into two groups: acoustic and electromagnetic. Acoustic \ndetection and localization  methods2,4–7 rely on detecting the sound waves emitted by PD sources. Compared \nto electromagnetic methods, acoustic methods are less sensitive to weak PDs and those that occur within the \n winding7,8. Acoustic sensors can be mounted on the external walls of the power transformer, making acoustic \ndetection a non-invasive technique. Nevertheless, the acoustic signal may be contaminated by external acoustic \nenvironmental noise.\nElectromagnetic localization based  methods2,4,7–10 utilize electromagnetic waves emitted by PD sources. The \ndetection methods that employ ultra high frequency (UHF) radiation are particularly sensitive to weak PDs \noccurring within the winding. Moreover, UHF measurements are commonly electromagnetically shielded by \ngrounding the transformer tank to mitigate external disturbances such as corona and environmental  noise11.\nClassical acoustic and electromagnetic three-dimensional localization methods rely on the Time Difference \nof Arrival (TDoA) of signals. However, these methods are highly sensitive to noise due to the need for precise \ndetermination of the onset time of the arriving  signals11. Moreover, they require a minimum of four time-\nsynchronized sensors as well as direct propagation paths from the PD sources to the multiple sensors to operate \neffectively. In the case of acoustic methods, reasonable accuracy can be achieved by implementing appropriate \nsignal processing techniques. However, TDoA-based electromagnetic methods encounter inaccuracies caused \nby inhomogeneities and scattering within transformers.\nOPEN\n1Department of Electrical Engineering, Bu-Ali Sina University, Hamedan, Iran. 2University of Applied Sciences \nof Western Switzerland (HES-SO), 1400 Yverdon-Les-Bains, Switzerland. 3Electrical Engineering Department, \nHamedan University of Technology, Hamedan, Iran. 4Electromagnetic Compatibility Laboratory, Swiss Federal \nInstitute of Technology (EPFL), 1015 Lausanne, Switzerland. *email: Hamidreza.karami@heig-vd.ch\n2\nVol:.(1234567890)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nRecently, a novel approach based on time reversal has been proposed in the electromagnetic and acoustic \nregimes. This approach can localize the sources of partial discharges inside a transformer using only a single \nsensor. In comparison to the conventional TDoA method, the time reversal-based method demonstrates robust-\nness to noise in the experimental signals. Moreover, it remains effective even in the presence of obstacles that \nobstruct the direct line of sight between the sensor and the PD source. The technique requires a model of the \ntransformer tank to carry out the backward propagation  stage12.\nThe creation of a PD localization system demands a significant level of accuracy, sensitivity, and robustness. \nThese qualities have been essential for power grid operators and installers over the past decades. Traditionally, \nPD diagnostics primarily rely on features extracted through conventional techniques such as statistical analysis, \nand time–frequency analysis. Simple threshold values are then computed to make  decisions11. Advanced signal \nprocessing techniques like the discrete wavelet transform (DWT) are employed to extract more sophisticated \nand powerful features, while conventional machine learning (ML) methods, including Back-Propagation Neural \nNetworks (BPNN), support vector machines (SVM), and fuzzy inference systems (FIS), are gradually utilized \nfor classification and regression  tasks11. In recent times, with advancements in computing and information tech-\nnologies, deep learning (DL) has gained significant attention as a subset of ML for intelligent PD  diagnostics13.\nTable S1, based on the review  of13 and including articles published since 2021, presents an overview of papers \nthat utilize ML methods for PD diagnosis. The studies predominantly focus on detection, pattern recognition, \nand classification, as shown in the table. However, only about 12.7% of these studies address the problem of \nlocalization. In terms of applications, only 16.50% of the studies are focused on transformers, while others \nexamine PDs in gas-insulated transmission lines (GIL), gas-insulated switchgear (GIS), high-voltage cables, and \nelectrical equipment. One of the primary reasons for the limited attention given to PD localization is its inherent \ndifficulty compared to detection and classification. Notably, the CNN model has garnered researchers’ attention \ndue to its exceptional performance in signal and image processing, as depicted in Table S1. For PD localization, \nthe bagging-kernel extreme learning machine (Bagging-KELM)14 achieves the best result in GIL, with an average \nerror of 0.93 cm. Neural networks, bagging techniques, and SVMs are the most frequently employed models \nin PD localization studies. It should be noted that all the methods presented in Table S1 have been individually \ninvestigated, considering various configurations and scenarios. This diversity in approaches has made the task of \ncomparison quite challenging. The aim of this paper is to provide a comprehensive comparison of these models \nwithin specific and well-defined scenarios. In particular, several well-known ML-based methods are investi-\ngated for the three-dimensional localization of partial discharges inside a power transformer tank. ML and DL \nmethods frequently used in recent articles on PDs are examined, considering their compatibility for regression \nproblems. Multiple case studies involving various attributes are presented. These attributes encompass sensor \npositioning, number of sensors, frequency content of the PD signal, and the size of the transformer tank. The \nPD location in the three-dimensional space is determined using single-sensor electric field measurements for \nall case studies, except for one case study in which three sensors are considered. The features of each method, \nsuch as input signal, core methodology, correlation coefficient of predicted location with the real location, and \nroot mean square error (RMSE) analysis, are discussed and compared.\nThe novelty of the paper lies in the three-dimensional localization of PD sources within a power transformer \ntank using only a single sensor, achieved through ML and DL techniques. These techniques include BPNN, CNN, \nSVR, and XGBoost methods. The paper also provides a comprehensive comparison of the performance of each \nmethod in localizing the PD sources.\nThe remainder of the paper is organized as follows: “ Case studies” presents the data generation, “ Data pre-\nprocessing” illustrates the data preprocessing procedure, and in “ Machine learning methods” , explanations for \neach model are provided. “ Results and discussion” focuses on the model comparison and presents the results. \nFinally, in “Conclusion” , concluding remarks are provided.\nCase studies\nThis section presents the various case studies considered in the analysis. All the case studies have been simulated \nusing microwave studio (CST) software. The geometry of the transformer tank is illustrated in Fig.  1. The ori-\ngin of the coordinate system is located at the center of the transformer tank. For simplicity, the study does not \ninclude the windings and ferromagnetic cores. The transformer tank is made of steel with a conductivity σ of \n7.69e6 S/m. The volume of the transformer tank, as shown in Fig. 1, is 1000 × 500 × 500  mm3. The thickness of the \ntank walls is 10 mm. In the study, the PD sources are modeled as small dipole antennas with a length of 10 mm, \nexcited by a Gaussian pulse. The figure does not depict the dipole antenna used to model the PD source. Different \norientations of the PDs are considered in the considered case studies. Please refer to Table 1 for further details.\nThe emitted fields from the PD sources are detected by three different sensors, represented by monopole \nantennas, as shown in Fig. 1. The length and radius of the monopole antennas are 67.8 and 2.5 mm, respectively. \nThe red cones in Fig. 1 depict the antenna inputs. Five different case studies are discussed in the paper, as shown \nin Table 1. The description of each case study is presented in the subsequent subsections.\nCase study #1\nIn the first case study, a single monopole antenna placed along the x-axis is employed to receive the PD signal \n(see Fig. 1 and Table 1). The coordinates of the monopole antenna are (x = −500 mm, y = −150 mm, z = −150 mm). \nThe PD is modeled as a 10 mm y-polarized dipole antenna positioned randomly within the transformer tank of \nFig. 1. The PD signal in the simulation is a Gaussian pulse with a frequency bandwidth of 0.5–3 GHz, see Table 1. \nA total of 600 Monte-Carlo simulations were conducted for this case study. The location of the PD source within \nthe transformer tank was randomly selected using a uniform probability distribution function for each direction.\n3\nVol.:(0123456789)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nCase study #2\nThe second case study is similar to CS#1, except for the location and polarization of the monopole antenna used \nto receive the PD signals. In CS#2, a y-axis polarized monopole antenna is employed as the receiving sensor, \nsituated at coordinates (x = −400 mm, y = −240 mm, z = −150 mm). This case study utilizes 1000 Monte-Carlo \nsimulations, see Table 1.\nCase study #3\nIn the third case study, the location of the PD sources is randomly selected inside the transformer tank using a \nuniform probability function, similar to case study #1. However, unlike the previous case studies, the PD source \npolarization is arbitrary. To achieve this, three new variables are introduced to indicate the rotation angles \nalong the x, y, and z axes. These three angles are selected using a uniform probability distribution function in \nthe range of 0–360 degrees. The three dipole antennas are used to record the electric fields emitted by the PD \nsource. However, even though the fields are captured by all three antennas, each at a different location and with \na different polarization, the captured signals from the monopole antennas are considered separately. In other \nwords, for the purpose of localizing the PD source, the electric field components are utilized individually. The \nlocations of the receiving antenna can be found in Fig. 1.\nThe PD signal used in this case study is a Gaussian pulse with a frequency bandwidth covering the range of 0.5 \nto fmax GHz. The value of fmax is randomly selected using a uniform probability distribution function between \n1 and 3 GHz. A total of 1000 Monte Carlo simulations were conducted for this case study to ensure a consistent \nnumber of instances and maintain uniform fairness across all case studies. Additionally, another 1000 samples \nare planned for consideration in the triple sensor case study.\nCase study #4\nThe fourth case study is similar to the previous case study (CS#3), but it uses a larger transformer tank size: \n1000 × 1000 × 500  mm3, which is twice as long in the y-axis direction compared to the tank size used in the \nprevious three cases. The locations of the monopole antennas used in this study are, respectively, at posi-\ntions (x = −500 mm, y = −400 mm, z = −150 mm), (x = 400 mm, y = −500 mm, z = −150 mm), and (x = 400 mm, \ny = 400 mm, z = −250 mm).\nFigure 1.  The transformer tank including three identical monopole antennas representing sensors aligned in \nthree different axes. The inset is a zoom of antenna 2.\nTable 1.  Five different case studies are discussed in the paper. 1 The three monopole antenna feeds are located, \nrespectively, at positions (x = −500 mm, y = −150 mm, z = −150 mm), (x = 400 mm, y = −250 mm, z = −150 mm), \nand (x = 400 mm, y = 150 mm, z = −250 mm). 2fmax is randomly selected between 1.0 to 3.0 GHz.\nCase study Tank dimension  (mm3) PD orientation Antenna  polarization1 Bandwidth (GHZ) Number of samples\nCS#1 1000 × 500 × 500 y-axis x-axis 0.5–3 600\nCS#2 1000 × 500 × 500 y-axis y-axis 0.5–3 1000\nCS#3 1000 × 500 × 500 Random x-, y-, or/and z-axis 0.5−fmax\n2 2000\nCS#4 1000 × 1000 × 500 Random x-, y-, or z-axis 0.5−fmax 1000\nCS#5 2000 × 1000 × 1000 Random x-, y-, or z-axis 0.5−fmax 1000\n4\nVol:.(1234567890)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nCase study #5\nThe transformer tank size used in this last case study is 2000 × 1000 × 1000  mm3, which means that the length \nof the tank sides along the axes is twice that of the tank used in CS#1 to CS#3. The monopole antennas used in \nthis study are, respectively, at positions (x = −500 mm, y = −400 mm, z = −150 mm), (x = 400 mm, y = −500 mm, \nz = −150 mm), and (x = 400 mm, y = 400 mm, z = −250 mm).\nData preprocessing\nData preprocessing is a crucial step in signal processing that plays a vital role in achieving accurate and efficient \nsolutions with minimal complexity. Moreover, preliminary experiments have demonstrated the necessity of \npreprocessing of both the PD signals and actual labels (locations). In this study, data preprocessing consists of \nfive key steps: cut-off, normalization, resampling, label shifting, and train-test dataset splitting.\nCut off\nThe first stage of preprocessing involves trimming a specific duration of time from all signal instances. This step \nis crucial in simulations because the wave maintains a constant speed, and the onset time provides information \nabout the location of the PD (partial discharge) in the radial direction. However, this approach can lead to unfair \npredictions when compared to practical tests. To achieve a more robust model, it is beneficial to implement this \npreprocessing step.\nSpecifically, the duration of the signal is cut down to 40 ns by trimming the beginning and the end as follows: \nA starting threshold is defined as the time at which the signal begins to fluctuate more than 0.001 V in amplitude. \nThis threshold is denoted as t, representing the starting time. Any data prior to this threshold is discarded. The \nremaining time duration (duration of the signal–t) is then trimmed from the end of the signal so that the total \nduration is 40 ns. However, since the initial sample rates of the instances differ, they will have varying numbers \nof samples.\nNormalization\nThe next step in preprocessing is normalization, which aims to expedite the training of the model. To achieve this, \nthe entire signal is divided by the absolute value of the maximum signal amplitude, which can vary significantly \nfor PD signals in the database. Consequently, the output signal is constrained to fluctuate between −1 and 1.\nResampling\nThe simulated signals generated using the CST-MWS software have varying sampling rates due to the imple-\nmentation of the finite integration technique during the simulations. Consequently, these signals have different \nnumbers of samples. To ensure consistency in the input shape of the model, resampling becomes a crucial step, \naiming to achieve an equal number of samples for all signals. In this paper, the down-sampling procedure is \nbased on polyphase filtering, which offers computationally efficient resampling and filtering capabilities with \nhigh accuracy when applied to signals with defined sample rates.\nBased on the conducted experiments, the best performance was observed when using 400, 800, and 1200 \nsamples as the number of input features for the model for values ranging between 50 and 4800 for SVR. The \nnumber of samples does not have a significant effect on XGBoost performance. Consequently, a value of 400 \nsamples was selected. Increasing the number of samples beyond this value would not significantly enhance \naccuracy but would significantly prolong the model training process. Additionally, polyphase filtering has proven \nto be a suitable approach, preserving over 98% of the signal content, as indicated by the computed correlation \ncoefficient between the original and resampled signals.\nIn Fig. 2, the effect of sample rates ranging from 50 to 4800 is depicted across three separate databases (used \nfor CS#1, CS#2, and CS#3) for the x, y, and z directions (horizontal axis). The coefficient of determination (R) \nfor predicted locations by the Support Vector Regression (SVR) model is shown on the vertical axis. The best \nresult is obtained with a number of samples ranging from 400 to 1200. Therefore, signals with a sample rate of \n400 are used throughout the paper to reduce computational tasks.\nFigure 2.  The variation of the R metric versus the number of samples for three separate datasets (CS#1, CS#2, \nand CS#3) along the y-axis using the SVR method.\n5\nVol.:(0123456789)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nShifting labels (location of PD sources)\nSince labels are ranged from negative to positive numbers, which correspond to the location of the PD source \ninside the cavity along the x-, y-, and z-axis, the model might not be able to distinguish the sign of numbers \nduring both the training and evaluation stages. The solution used here involves shifting all the labels to positive \nregions, thereby yielding a more resilient model. Nonetheless, the amount of shifting may vary depending on \nthe specific tank shape in each case study.\nSplitting training and test dataset\nBefore training, the datasets are divided into train and test data, with 80% of the dataset used for training and 20% \nfor testing. To ensure a fair comparison of results between models, the training dataset is randomly shuffled using \na seed number of 11. This procedure guarantees that each partition undergoes a complete pattern randomization.\nMachine learning methods\nA flowchart depicting the ML and DL-based approaches proposed in the paper is presented in Figure S1 in \nthe Supplementary Information. The initial step involves data collection, which is simulated using CST-MWS \nsoftware. Once the data is collected, it needs to undergo preprocessing before being fed into the models. During \npreprocessing, the data is initially trimmed and then normalized to fall within the range of 1 to −1. Following \nnormalization, the data is resampled to consist of 400 samples. Given that the labels span from negative to posi-\ntive numbers, representing the PD source’s location within the cavity along the x-, y-, and z-axis, the location \nlabels’ origin is shifted to ensure all labels are positive.\nAfter the data is prepared for model input, a range of models is assessed to identify the one with the highest \naccuracy. Subsequently, these models are trained using 80% of the preprocessed data and evaluated using the \nremaining preprocessed data for testing purposes. Finally, the model that performs the best is selected as the \noptimal choice.\nFour frequent models have been chosen from those in Table S1: Support Vector Machine (SVM), neural \nnetworks (NN), convolution neural networks (CNN) and XGBoost which encompasses boosting methods.\nEach model used in this paper has gone through a grid search for hyperparameters. The grid search condition \nis slightly different depending on each model architecture. All ML methods used in this paper have the same \ninput: a 1D preprocessed PD signal in the time domain with 400 samples, except for three sensor case study (see \n“Three sensors” , for which 1200 samples were used. To assess the degree of association between two variables, \ncorrelation coefficients are used.\nSupport vector regression\nA simple linear support vector machine (SVM) classifier operates by drawing a straight line between two classes. \nThis means that all the data points on one side of the line will be classified as one category, while the data points \non the other side will be assigned to a different category. As a result, there are numerous possible lines to select \nfrom.\nSupport vector regression (SVR) applies the same principle as SVM, but it is used for regression problems. \nSVR is a widely used algorithm with various  applications15. To optimize SVR, a grid search is performed on \nthe gamma, regularization parameter, and kernel. The best outcome was achieved by setting the gamma value \nto 0.01, the regularization parameter to 1000 (where the strength of regularization is inversely proportional) \nand employing the radial basis function (“RBF”) as the kernel. Since SVR does not inherently support multi-\ndimensional regression, the multi-target regression strategy is employed to expand its capabilities, fitting one \nregressor per target.\nXGBoost\nA gradient boosting decision tree (GBDT) is an ensemble learning algorithm, similar to random forest, used \nfor both classification and regression tasks. Ensemble learning algorithms combine multiple machine learning \nalgorithms to obtain improved models. XGBoost is an example of a parallel tree boosting  algorithm16 and it is \nimplemented using the XGBoost library. In this case, default hyperparameters are used as the model performance \ndoes not improve after grid search. Additionally, XGBoost also supports multi-target regression strategy.\nback-propagation neural network (BPNN)\nDL has made significant progress in various applications. One of the first DL models that has been extensively \nexamined is the Backpropagation Neural Network (BPNN). The BPNN consists of multiple layers, with each \nlayer containing a number of neurons that adapt complex functions through a series of nonlinear transforma -\ntions. The architecture of this model is illustrated in Fig. 3. It comprises three main parts: the input layer, hidden \nlayers, and output layer.\nThe input layer serves as a simple fully connected layer that feeds into the hidden layers. The hidden layers \nconsist of three dense layers, each containing 512 units with the rectified linear unit (ReLU) activation function. \nOn the other hand, the output layer is another dense layer with three units representing the 3D source location. To \noptimize the model, the Nadam  optimizer17 is used, and the learning rate gradually decreases from 0.1 to 0.001.\nConvolutional neural network (CNN)\nA convolutional neural network (CNN) operates in a similar manner to conventional fully connected multilayer \nperceptron neural networks, but with additional convolutional layers positioned at the front of the  network18. The \nmodel considered in this study is the 1D CNN  model19. This particular model yielded the best results, as indicated \n6\nVol:.(1234567890)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nin Table 2. In comparison to the back-propagation neural network (BPNN), the CNN 1D model is more com -\nplex, which leads to higher computational cost but also improved accuracy. All layers in the model employ the \nrectified linear unit (ReLU) activation function, and the optimizer used is similar to that of the back propagation \nneural network (BPNN). For a comprehensive representation of the model’s architecture, please refer to Fig. 4.\nCNN-based methods automatically identify and utilize hierarchical features in signals received by sensors. \nIn CNN-based methods, multiple layers of convolutional filters are applied to the signal, progressively obtaining \nhigher-level features. This is crucial for localizing partial discharges, where the spatial information of the source \nis encoded in the signal. Other methods like SVM and XGBoost rely on global features extracted from the signal \nin partial discharge localization applications. It should be noted that in other applications, feature engineering \ncan improve the performance by selecting the best features to achieve better results. For example, SVM-based \napproaches excel in classification tasks where feature boundaries can be distinctly defined in a high-dimensional \nFigure 3.  Architecture of BPNN model. The first layer is the input layer, each fully connected layer has 512 \nunits, and the output layer estimates the x, y and z coordinates of the PD source.\nTable 2.  RMSE in mm and correlation coefficient (R) for each model and case study. For CS#3, three different \ndirections corresponding to the receiving antenna are listed as X, Y , and Z. The origin of the coordinate system \nis at the center of the transformer tank.\nModels case studies SVR XGBOOST BPNN CNN\nCS#1\nR\nx 0.94 0.88 0.94 0.99\ny 0.91 0.91 0.91 0.97\nz 0.84 0.73 0.86 0.94\nRMSE 74.46 95.57 73.22 39.89\nCS#2\nR\nx 0.94 0.89 0.94 0.99\ny 0.96 0.84 0.95 0.98\nz 0.94 0.88 0.89 0.97\nRMSE 58.76 83.62 60.98 27.04\nCS#3 X\nR\nx 0.92 0.83 0.9 0.95\ny 0.42 0.36 0.5 0.56\nz 0.4 0.32 0.5 0.59\nRMSE 106.46 122.51 102.42 89.44\nCS#3 Y\nR\nx 0.87 0.81 0.87 0.96\ny 0.77 0.49 0.74 0.83\nz 0.69 0.55 0.65 0.8\nRMSE 97.38 117.71 100.18 67.14\nCS#3 Z\nR\nx 0.86 0.81 0.82 0.93\ny 0.75 0.58 0.71 0.81\nz 0.69 0.3 0.65 0.79\nRMSE 100.46 119.82 109.2 75.7\n7\nVol.:(0123456789)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nspace but do not inherently extract features from complex patterns like images. Therefore, through the use of \nconvolutional layers and pooling operations, CNNs can capture spatial hierarchies and dependencies between \ndifferent parts of the data, such as the location and spread of discharge patterns within a transformer tank.\nResults and discussion\nAll models are evaluated based on their performance measured by the root mean square error (RMSE) and cor-\nrelation coefficient (R) criteria in each coordinate for all case studies. The Pearson correlation  coefficient20 is a \nnumerical measure that determines the linear correlation between measured values and values simulated by the \nmodel, with an optimal value of 1.\nIn Eq. (1), the variable i represents the actual location, while j represents the predicted location in the same \ndirection, such as the y direction. The parameter C ij denotes the covariance between i  and j, and Cii represents \nthe standard deviation of i.\nOne way to evaluate the goodness of fit of a regression model to a dataset is by calculating the Root Mean \nSquare Error (RMSE). RMSE is a metric that measures the distance between the predicted values from the model \nand the actual values in the dataset. A lower RMSE indicates a better fit of the model to the dataset. The formal \ndefinition of RMSE is as follows:\nwhere, ˆx l , ˆy l , and ˆz l are predicted values, x i, yi, and zi  are observed values respectively. The quantity n  is the \nnumber of samples.\nThe constructed models were trained and tested using eightfold cross-validation. However, for all the results \npresented in this paper, the seed number 11 was used to split the training and test datasets. The implementation \nwas done using the Python programming language, and the models were trained and evaluated on a computer \nwith an NVIDIA GeForce GTX 1660 TI and 4 GB of graphics memory. To facilitate further research, all codes \nand datasets used in this study have been made available on GitHub. (https:// github. com/ Farzi  nkh/ Parti al_ \nDisch arge.)\nSingle sensor\nTable 2 presents the R metric (corresponding to the correlation coefficient of the PD source estimation) and \nthe RMSE value (corresponding to the three-dimensional localization error) for four different models: SVR, \nXGBoost, BPNN, and CNN. The first main column provides experiment details, including the case study number \n(refer to Table 1), and displays the R metric or the RMSE. The second to fifth columns present the results for the \nSVR, XGBoost, BPNN, and CNN models, respectively. For instance, the shaded row in Table 2 represents the R \nmetric for the z-coordinate of all the different models in the first case study (CS#1).\nIn CS#1, the CNN model performs the best, with accuracies of 0.99, 0.97, and 0.94 for the x, y, and z-coor -\ndinates, respectively. The RMSE is 39.89 mm, which is considered excellent for partial discharge applications. \nIn this case study, the receiving antenna is oriented along the x-axis, and the PD source polarization is along \nthe y-axis. The second-best model is BPNN, which achieves accuracies of 0.94, 0.96, and 0.80 for the x, y, and \nz-coordinates, respectively. SVR exhibits similar performance to BPNN, with a slight reduction (2 percent) in \n(1)R ij = C ij√C iiC jj\n,\n(2)RMSE =\n√\nn∑\ni=1\n(\nˆxl − xi\n)2 +\n(\nˆyl − yi\n)2 +\n(\nˆzl − zi\n)2\nn ,\nFigure 4.  Architecture of the CNN model. The input layer consists of 400 nodes. Layer 1 is a 1D CNN layer \nwith dimensions (394, 64) followed by an average pooling layer with dimensions (98, 64). Layer 2 is another 1D \nCNN layer with dimensions (89, 256) followed by an average pooling layer with dimensions (44, 256). The first \nfully connected (FC) layer has 512 units, the second FC layer has 256 units, and the third FC layer has 512 units. \nThe output of the model represents the x, y, and z coordinates of PD.\n8\nVol:.(1234567890)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nthe estimation accuracy along the z-coordinate. Finally, XGBoost achieves accuracies of 0.8, 0.91, and 0.73 for \nthe x, y, and z-coordinates, respectively. The localization error averages for SVR, XGBoost, BPNN, and CNN are \n74.46, 95.57, 73.22, and 39.89 mm, respectively. Figure  5 (a) (b), and (c) show the evaluation curves (the esti-\nmated versus the actual location of the PD source) for the CNN method for the x, y, and z coordinates in CS#1.\nIn CS#2, the performance of the CNN method is better than in other models, similar to the previous case \nstudy. It can estimate the PD source location with accuracies of 0.99, 0.98, and 0.97 for the x, y, and z-coordinates, \nrespectively. In contrast to CS#1, the SVR performs slightly better than the BPNN method. The accuracies of \nSVR and BPNN are (0.94, 0.96, 0.94) and (0.94, 0.95, 0.89), respectively, with each parenthesis representing the \nx, y, and z coordinates. Finally, the XGBoost method presents the worst results in terms of accuracy in estimating \nthe PD source. Its accuracy is lower than 0.89 for all coordinates. In CS#2, both the antenna direction and PD \npolarization are along the y-axis. The localization error averages for SVR, XGBoost, BPNN, and CNN are 58.76, \n83.62, 60.98, and 27.04 mm, respectively. Figure  6 (a), (b), and (c) show the evaluation curves (the estimated \nversus the actual location of the PD source) for the CNN method for the x, y, and z coordinates in CS#2.\nThe last three main rows in Table 2 are devoted to CS#3. Unlike the two previous case studies (i.e., CS#1 and \nCS#2), the performance of all models is reduced. This is because in CS#3, the polarization of the PD source is \nrandomly changed in the simulation. Generally, the CNN method performs better than the other methods, simi-\nlar to the previous case studies. In CS#3, when the receiving antenna along the x-axis is used, the performance of \nBPNN is better than SVR; otherwise, SVR outperforms the BPNN method. In this case study, like the previous \nones, the performance of XGBoost is the worst. The evaluation curves for all four models are shown in Fig. 7. It \ncan be observed from the figure that the performance of the CNN method is superior to that of the other meth-\nods. The CNN exhibits higher accuracy for the x-coordinate compared to the y and z coordinates, as indicated \nin Table 2. According to Table 2 and Fig. 7, it is evident that, across all techniques and case studies (especially for \nCS#3), the accuracy of PD source estimation yields better results for the x-coordinate. To investigate the reason \nbehind this observation, CS#4 and CS#5 were employed.\nObserve the antenna oriented along the y axis in CS#3 (forth column of Table 2). In this case, the minimum \nand maximum localization errors are 12.1 and 347.54 mm, respectively, and the mean value is 98.09 mm. Figure 8 \ndisplays the density of the three-dimensional localization error obtained from the CNN model on the test dataset. \nFor better insight, all predicted errors are classified in Fig. 8 into eight 42 mm bins, starting with zero and ending \nwith the maximum error. The blue bars represent the local density in each stage, while the yellow bars represent \nthe overall density. According to this figure, 88% of PD source localizations have errors less than 168 mm (lower \nthan 17 cm), which validates the relatively accurate nature of this model in predicting locations of PD sources.\nTo investigate the effects of the PD’s location on the obtained results, Fig. 9 presents the RMSE of the CNN \nmodel results for CS#3 with the y-direction receiving antenna. The transformer tank is divided into three sec-\ntions based on the distance between each section and the corner of the transformer tank. The vertical axis \nrepresents the RMSE for each section. It can be observed that the CNN method can accurately estimate the \nPD’s location anywhere inside the tank, as the localization error associated with the PD’s location in the CNN \nmethod is negligible.\nFigure 5.  The CNN model’s estimated location compared to the actual location of PD sources for CS#1: (a) \nx-coordinate, (b) y-coordinate, and (c) z-coordinate. The number of instances for all the curves is 120.\nFigure 6.  The CNN model’s estimated location compared to the actual location of PD sources for CS#2: (a) \nx-coordinate, (b) y-coordinate, and (c) z-coordinate. The number of instances for all the curves is 196.\n9\nVol.:(0123456789)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nThree sensors\nA possible approach to increase the accuracy of the model is to increase the number of sensors, as increasing the \nnumber of samples for each signal does not provide any significant advantage (see Fig. 2). Using three separate \nsensors in different directions is beneficial when dealing with a variety of PD frequencies (ranging from 0.5 to \n3 GHz). The procedure becomes slightly more complex in terms of the model architecture, as shown in Fig. 10. \nBased on the conducted experiments, since simple preprocessing methods for merging PD signals like sum-\nmation, subtraction, and averaging as feature extraction on three signals (each containing 400 samples) in the \nFigure 7.  Evaluation curves for (a–c) SVR, (d–f) XGBoost, (g–i) BPNN, and (j–l) CNN (the y direction is \nconsidered for the receiving antenna) methods. The number of instances for all the curves is 200.\n10\nVol:.(1234567890)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nelement-wise procedure do not improve the accuracy of the model, a more advanced method was required. One \nsolution for achieving high model accuracy is by employing CNN models once again as feature extraction lay-\ners to achieve a 400-sample signal which is the desired input shape for the base model and utilizes the transfer \nlearning technique. According to the figure, a solution for achieving high model accuracy in merging the PD \npreprocessed signals (each containing 400 samples) is to employ CNN models once again and to utilize transfer \nlearning techniques. The architecture used to adapt a signal with 400 samples for input into the preceding model \n(the base model) to include a CNN 1D layer (1137,10), a Max pooling layer (162,10), and an FC layer with 400 \nunits as embedding layer. These extra layers are added before the base model. It is important to note that the \npreceding model plays a vital role and was specifically trained for one sensor operating within the 0 to 3 GHz \nPD frequency range.\nFigure 8.  The density of three-dimensional localization error obtained from the CNN model. The blue bars \nrepresent the local density, while the yellow bars represent the overall density.\nFigure 9.  The RMSE versus the location of the PD source inside the transformer for CNN method in CS#3 in \nranges less than 162, between 162 and 336 and more than 336.\nFigure 10.  Architecture of the CNN model to utilize transfer learning techniques.\n11\nVol.:(0123456789)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nFor this experiment, two scenarios are considered. The datasets of CS#3 are divided into two equal parts, each \nwith a length of 1000 samples. The first scenario involves training the base model on CS#3 (Part I) and CS#3 (Part \nII) for 3-sensor transfer learning. The second scenario reverses the order of the datasets. The results of these two \nexperiments are presented in Table 3. In the first scenario, the RMSE error decreases from 67.14 to 46.13 mm \nfor the single-sensor and the three-sensor CNN models, respectively, leading to a 31.2% improvement. In the \nsecond scenario, the RMSE error decreases from 84.2 to 61.85 mm for the single and the three-sensor CNN \nmodels, respectively, leading to a 22.35% improvement. According to these records, the use of three sensors lead \nto an improvement in the accuracy of about 26%.\nFigures 11 and 12 display the overall density of the three-dimensional localization error obtained from the \nCNN models on CS#3 (Part I) and (Part II) (refer to the fourth column of Table 3). The dashed lines represent the \noverall density for the single-sensor pre-trained CNN model, while the solid lines represent the overall density \nfor the three-sensor CNN model. According to these figures, using three sensors leads to a more robust model \nTable 3.  RMSE in mm and correlation coefficient (R) for the CNN method for CS#3.\nPre-trained model dataset Direction\nAccuracy (R)\nR RMSE (mm)\nCS#3 (Part I)\nx 0.9821\n46.1367y 0.9262\nz 0.9169\nCS#3 (Part II)\nx 0.9679\n61.8552y 0.8327\nz 0.8668\nFigure 11.  The density of three-dimensional localization error obtained from the CNN models for the first \nscenario. The dashed lines represent the overall density for the single-sensor CNN model trained on CS#3 (Part \nI) with a y-direction receiving antenna, while the solid lines represent the overall density for the three sensor \nCNN model.\nFigure 12.  The density of three-dimensional localization error obtained from the CNN models for the second \nscenario. The dashed lines represent the overall density for the single-sensor CNN model trained on CS#3 (Part \nII) with a y-direction receiving antenna, while the solid lines represent the overall density for the three-sensor \nCNN model.\n12\nVol:.(1234567890)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nwhile evaluating unseen data for 80% density regarding transfer model performance on the base model’s dataset \n(DS) and base model performance on the transfer model’s DS.\nEffect of the cavity shape and size\nIn the previous case studies, the localization accuracy in the x direction was observed to be higher than in the \nother directions. The only difference between the directions in the procedure is in the lengths of the transformer \ntank sides. Specifically, the x direction is longer than the others. Two experiments were conducted in CS#4 and \nCS#5 changing the tank dimensions and using the same single-sensor CNN model used in the preceding case \nstudies to examine the impact of the shape and size of the cavity (see Table 1).\nIn the first experiment, CS#4 was used to determine the relationship between the accuracy of the predicted \nPD localization in all coordinates and the shape of the cavity. Since the cavity in this dataset has dimensions of \n1000 × 1000 × 500  mm3, (compare to the 500 × 1000 × 500  mm3 dimensions of the previous case studies), it is \nexpected that the accuracy in the x and y directions will be approximately the same. This is indeed the case, as \nindicated in Table 4.\nIn the second experiment, CS#5, the cavity size was increased by a factor of 2 compared to case study CS#3, \nresulting in dimensions of 2000 × 1000 × 1000  mm3. Comparatively, the accuracy remains approximately constant \ncompared to the CS#3 (refer to the fourth column of Table 2 and fourth column of Table 4).\nConclusions\nIn this study, a DL-based approach was presented for the 3D localization of PDs within the transformer tanks. \nFour models were examined, namely BPNN, CNN, SVR, and XGBoost, which were selected based on their fre-\nquency in recent related articles and their previous success in localization tasks. Five case studies were considered \nfor this study, each encompassing various conditions such as the maximum and minimum frequency content \nof the PD signals, antenna and PD source polarization, and the size of the transformer tank. These case studies \nwere generated through Monte Carlo simulations. The models were developed using the Python language on a \nGPU processor to enhance the computational process.\nCNN showed significant accuracy compared to the other models, with an average correlation coefficient of \n0.98 and 0.86 for all dimensions in the case studies CS#2 (maximum frequency of 3 GHz) and CS#3 (random \nmaximum frequency in the y-direction), respectively. In the former case study, 99.2% of the localizations had an \nerror of less than 13.3 cm, and in the latter, 88% had an error of less than 17 cm. However, CNN still exhibited \nlimitations in practical robustness. To address this problem, a three-sensor CNN model was introduced, which \ndemonstrated a 26% improvement in robustness compared to the single sensor model, as well as at least a 22% \nimprovement in accuracy. The accuracy of the models is related to the size of the cavity; however, there is no \nsimple relationship. Based on the experiments, the models performed much better in a cavity with two equal \ndimensions.\nThe most challenging aspect of implementing this research in practice is collecting enough signals from differ-\nent types of real power transformers in various locations where PD sources occur. In future work, the proposed \nmethod will be applied to a practical power transformer using signals received by a single antenna inside the \ntransformer tank under real-world conditions.\nData availability\nThe datasets generated and analyzed during the current study, as well as the source codes and all computed \nresults, figures, and other related materials, are available in the “Partial_Discharge” repository at github.com/\nFarzinkh/Partial_Discharge.\nReceived: 2 November 2023; Accepted: 17 May 2024\nTable 4.  RMSE in mm and correlation coefficient (R) for the CNN method for CS#4 and CS#5.\nCase study Direction\nAccuracy\nCase study Direction\nAccuracy\nR RMSE (mm) R RMSE (mm)\nCS#4 X direction\nx 0.8755\n109.1582 CS#5 X direction\nx 0.8392\n242.6377y 0.8685 y 0.6205\nz 0.8550 z 0.6104\nCS#4 Y direction\nx 0.8378\n121.2639 CS#5 Y direction\nx 0.9141\n190.1929y 0.8382 y 0.7397\nz 0.8482 z 0.8008\nCS#4 Z direction\nx 0.6192\n174.0885 CS#5 Z direction\nx 0.9227\n199.3289y 0.6368 y 0.7285\nz 0.6651 z 0.6593\n13\nVol.:(0123456789)Scientific Reports |        (2024) 14:11785  | https://doi.org/10.1038/s41598-024-62527-9\nwww.nature.com/scientificreports/\nReferences\n 1. Mostajabi, A. et al. Single-sensor source localization using electromagnetic time reversal and deep transfer learning: application \nto lightning. Sci. Rep. 9, 1–14 (2019).\n 2. CIGRE Working Group. Partial Discharges in Transformers. CIGRE Working Group D1.29. (CIGRE Working Group, London, \nUK, 2017). \n 3. Karami, H., Azadifar, M., Rubinstein, M. & Rachidi, F . An experimental validation of partial discharge localization using electro-\nmagnetic time reversal. Sci. Rep. 11, 1–12 (2021).\n 4. Markalous, S. M., Tenbohlen, S. & Feser, K. Detection and location of partial discharges in power transformers using acoustic and \nelectromagnetic signals. IEEE Trans. Dielectr. Electr. Insul. 15, 1576–1583 (2008).\n 5. Lundgaard, L. E., Berg, G., Brede, A. P . & Kyrkjeeide, S. L (2003) Acoustic Location of Discharges in Power Transformers. In: XIIIth \nInternational Symposium on High Voltage Engineering 582–583\n 6. Lundgaard, L. E. Partial discharge-part XIV: Acoustic partial discharge detection-practical application. IEEE Electr. Insul. Mag. 8, \n34–43 (1992).\n 7. Tenbohlen, S., Pfeffer, A. & Coenen, S. On-site experiences with multi-terminal IEC PD measurements, UHF PD measurements \nand acoustic PD localisation. in 2010 IEEE International Symposium on Electrical Insulation 1–5 (IEEE, 2010).\n 8. Raja, K. & Floribert, T. Comparative investigations on UHF and acoustic PD detection sensitivity in transformers. In: Conference \nRecord of the the 2002 IEEE International Symposium on Electrical Insulation (Cat. No. 02CH37316) 150–153 (IEEE, 2002).\n 9. Judd, M. D., Y ang, L. & Hunter, I. B. B. Partial discharge monitoring of power transformers using UHF sensors. Part I: Sensors \nand signal interpretation. IEEE Electr. Insul. Mag. 21, 5–14 (2005).\n 10. Tenbohlen, S., Denissov, D., Hoek, S. M. & Markalous, S. M. Partial discharge measurement in the ultra high frequency (UHF) \nrange. IEEE Trans. Dielectr. Electr. Insul. 15, 1544–1552 (2008).\n 11. Raymond, W . J. K., Illias, H. A., Bakar, A. H. A. & Mokhlis, H. Partial discharge classifications: Review of recent progress. Measure-\nment 68, 164–181 (2015).\n 12. Karami, H. et al. Partial discharge localization using time reversal: Application to power transformers. Sensors https:// doi. org/ 10. \n3390/ s2005 1419 (2020).\n 13. Lu, S., Chai, H., Sahoo, A. & Phung, B. T. Condition monitoring based on partial discharge diagnostics using machine learning \nmethods: A comprehensive state-of-the-art review. IEEE Trans. Dielectr. Electr. Insul. 27, 1861–1888 (2020).\n 14. Wang, Y . et al. A domain adaptive deep transfer learning method for gas-insulated switchgear partial discharge diagnosis. IEEE \nTrans. Power Deliv. 37, 2514–2523 (2022).\n 15. Cortes, C., Vapnik, V . & Saitta, L. Support-vector networks. Mach. Learn. 203(20), 273–297 (1995).\n 16. Chen, T. & Guestrin, C. XGBoost: A scalable tree boosting system. Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discov. Data Min \n(2016).\n 17. Dozat, T. Incorporating nesterov momentum into Adam. ICLR workshop (Caribe Hilton, San Juan, Puerto Rico, 2016).\n 18. LeCun, Y ., Bengio, Y . & Hinton, G. Deep learning. Nature 521, 436–444 (2015).\n 19. Ding, R. et al. Detection and analysis of GIS discharge defects based on deep learninng method. In Asia Energy Electr. Eng. Symp. \n(AEEES, 2022). https:// doi. org/ 10. 1109/ AEEES 54426. 2022. 97595 66.\n 20. Sedgwick, P . Pearson’s correlation coefficient. BMJ https:// doi. org/ 10. 1136/ bmj. e4483 (2012).\nAuthor contributions\nF .K. and M.K. developed the theory and performed the computations, designed the model and the computational \nframework and analyzed the data and carried out the implementation. H.K. developed the theoretical formal -\nism, verified the analytical methods and performed the numerical simulations. H.K. M.R. and F .R. reviewed \nthe manuscript.\nCompeting interests \nThe authors declare no competing interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at https:// doi. org/ \n10. 1038/ s41598- 024- 62527-9.\nCorrespondence and requests for materials should be addressed to H.K.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n© The Author(s) 2024"
}