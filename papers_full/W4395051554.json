{
    "title": "Unlocking the Capabilities of Large Language Models for Accelerating Drug Development",
    "url": "https://openalex.org/W4395051554",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2040972993",
            "name": "Wes Anderson",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2944911310",
            "name": "Ian Braun",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2994903579",
            "name": "Roopal Bhatnagar",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2136475275",
            "name": "Klaus Romero",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2163566604",
            "name": "Ramona Walls",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2131964481",
            "name": "Marco Schito",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2044911359",
            "name": "Jagdeep T. Podichetty",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2040972993",
            "name": "Wes Anderson",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2944911310",
            "name": "Ian Braun",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2994903579",
            "name": "Roopal Bhatnagar",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2136475275",
            "name": "Klaus Romero",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2163566604",
            "name": "Ramona Walls",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2131964481",
            "name": "Marco Schito",
            "affiliations": [
                "Critical Path Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2044911359",
            "name": "Jagdeep T. Podichetty",
            "affiliations": [
                "Critical Path Institute"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4282960293",
        "https://openalex.org/W4392619039",
        "https://openalex.org/W4385573087",
        "https://openalex.org/W6607514010",
        "https://openalex.org/W4385381606"
    ],
    "abstract": "Recent breakthroughs in natural language processing (NLP), particularly in large language models (LLMs), offer substantial advantages in model-informed drug development (MIDD). With billions of parameters and comprehensive pre-training on diverse data, these models effectively extract information from unstructured and structured data throughout the drug development lifecycle. This perspective envisions LLMs supporting MIDD, enhancing drug development, and emphasizes C-Path's strategic use of LLM innovations for actionable real-world evidence from real-world data (RWD). Previously, our work has succinctly summarized the potential opportunities for implementation of NLP in MIDD, emphasizing areas for improvement in the use of smaller scale models.1 Recent advancements in LLMs showcase unique abilities that are not present in smaller scale models (Figure 1).2 One is known as prompt engineering, referring to the ability of an LLM to complete a task through a response based on a prompt without further training in both zero- or few-shot settings. In the zero-shot setting, a model learns an entirely new task without being given specific examples, while few-shot learning (or in-context learning [ICL]) involves presenting a LLM with a few task demonstrations (\"shots\"). The model can then produce the anticipated output for test instances by completing an input text sequence without the need for further training or gradient updates. Prompting methods that involve providing an LLM with a sequence of intermediate reasoning steps that make up a reasoning path depicting how to solve a problem (i.e., chain-of-thought [COT] prompting), as well as multiple reasoning path from a combinatorial problem space (i.e., Tree of Thought [TOT] prompting), have also been developed to improve the performance of LLMs in the prompting setting. Considerations such as prompt clarity, specificity, domain understanding, context of the topic, and iterative evaluation and prompt adjustment are crucial in prompt engineering. Using techniques such as effective prompting principles, along with ICL, COT, TOT, and similar prompting methods, enable a single LLM to be reused across various tasks (including MIDD) with minimal adaptation or retraining needed for different tasks, enabling rapid adaptation without extensive retraining or task-specific datasets. C-Path has explored the utility of LLMs in data curation pipelines, especially for information relevant to downstream decisions in free-text or semi-structured fields. Unlike traditional biomedical NLP pipelines that extract specific entities or relationships from clinical notes through training or fine-tuning on large volumes of annotated data, LLMs enable zero-or-few shot question answering with configurable tasks through templated prompts without the need for task-specific tuning.3 C-Path envisions leveraging this property of LLMs and simple templates with target output structures to perform arbitrary data cleaning or knowledge extraction tasks. Recently, the utility of this approach was demonstrated through defining and automating data extraction tasks \"on-the-fly,\"4 redirecting curation time from more code-intensive data-wrangling or mapping approaches to manual review and revision of the LLM-enabled automated extraction processes. Leveraging prompt engineering to define LLM-assisted tasks dynamically through arbitrary data schemas extends to the data discovery process. Large language models excel in translating natural language inquiries into queries that conform to schemas defined in a few-shot setting to retrieve structured information from graphs or tabular databases. We anticipate leveraging this technique to enable data discovery (e.g., identifying relevant datasets for specific research questions). Within C-Path, another opportunity for LLM implementation is in synthetic textual data generation, where LLMs such as GPT-3.5 strategically generate data that is representative in content and structure to the desired end point through ICL prompting for several different NLP settings, including fine-tuning a downstream model (i.e., weak supervision5). This approach enhances effectiveness in the MIDD space (including real-world settings), reducing the burden of human annotation or manual data collection for this supervised fine-tuning.3, 5 The future of LLMs within NLP tasks related to MIDD across the drug development lifecycle (e.g., biomarker discovery through named entity recognition and assertion status detection using free-text and EHR curation through LLMs) (Figure 2) presents significant implementation opportunities. The massive size of many of the popular LLMs prohibits their operation on desktop computers. Furthermore, the proprietary nature of models accessible only via a paid API can hinder reproducibility, incur costs, and raise concerns about patient privacy and data security. There is, however, the opportunity to utilize open-source, commercially nonrestricted models stored and readily available for download on platforms such as HuggingFace (https://huggingface.co/). Such models allow for flexibility in model usage, both in the form of prompt engineering and fine-tuning, and do not require the use of an API. The ability to fine-tune is especially important for MIDD, as adapting generic existing LLMs to be domain-specific experts can be done effectively through fine-tuning.3 Full model fine-tuning of LLMs demands storage and memory allocation for each task, incurring computational costs. However, recent advancements in parameter-efficient fine tuning (PEFT) methodologies, such as Low-Rank Adaptation (LoRA)7 of LLMs, mitigate these demands. Low-Rank Adaptation includes freezing of pre-trained model weights and the introduction of trainable rank decomposition matrices into the layers of the transformer architecture. This action diminishes the count of trainable parameters during the fine-tuning phase, enabling the capacity to train and incorporate multiple LoRAs tailored for distinct inference tasks, all based on a base LLM. Creating impactful prompts is essential for leveraging the potential of zero or few-shot learning without requiring extensive training. This involves crafting task descriptions with clear, decomposable goals, offering model-friendly input data, and using examples in the few-shot setting. Essential components are examples in the few-shot setting, ensuring model verification, utilizing external tools when needed, sequencing examples thoughtfully, and assigning specific roles to the LLM (e.g., humans, like a clinician). Notably, prompt design lacks consistency across models, and subtle syntax variations, often nonintuitive to humans, can result in significant output changes. As research progresses, incorporating new insights into effective prompt design will enhance performance in tasks related to MIDD. Evaluation of LLMs has continued to expand since the onset of popular models (e.g., GPT-3.5). This evaluation is dependent on the method of evaluation, the data, and the task of interest. In the scope of MIDD, rigorous evaluations must take place to determine the level at which they can assist in the field of MIDD. Existing LLM benchmarks combine evaluations of general language tasks and specific downstream tasks, stratified into manual and automated assessments. Manual evaluation relies on human evaluation, introducing high variance and stability challenges due to cultural and individual differences among reviewers.8 Similarly, automated evaluation employs standard scenario-based evaluation metrics (e.g., accuracy, F1-score, ROUGE, and BLEU), with concerns about the limitations of these static metrics and necessitating holistic evaluations like those developed by Liang et al.9 Large language model evaluation will benefit from real-world datasets, not just those that are smaller and publicly available (e.g., MIMIC-III). C-Path, in its position as a leader in data acquisition and harmonization, can contribute to this work. In the same sense, continued evaluation that furthers the explicit definition of scenarios in which the emergent capabilities of LLMs achieve their purported benefits must occur.10 Finally, we must present evaluations in combination with details in the training schema (e.g., the amount of training data used, along with other training details) to get a reported performance, as it demonstrates how LLMs (clinical LLMs specifically) exhibit improved sample efficiency.10 Obtaining a proper understanding of where LLMs are thriving and where they are not successful helps determine the scope of their use while also warning against the potential bias and inaccuracies that may be present in certain areas or tasks. C-Path recognizes that challenges exist around addressing the limitations and potential ethical considerations in LLMs. For example, in synthetic data generation, these approaches include noise in generated datasets and the difficulty in ensuring the representativeness of the distribution compared with actual data.6 Addressing these challenges is crucial for optimizing the utility of synthetic data in diverse NLP scenarios. Similarly, noise in the form of hallucinations, or false or misleading information generated by an LLM, leads to inaccurate outputs across NLP tasks, which is especially important in the drug development space, as there is the potential for increased risk to patients and decision making (depending on the task being addressed with the LLM). Although methods such as proper prompting and retrieval augmented generation aim to limit hallucinations, further improvements are needed. Concerns about patient data sharing can be addressed through open-science development of LLMs outside of proprietary models (e.g., GPT-3.5). Interpretability of LLMs is challenging due to their scale and complexity, making them opaque, while bias in LLMs introduces an additional layer of complexity, potentially skewing the insights derived from these models. As these models evolve alongside their role in drug discovery, it is crucial to address the dual challenges of poor interpretability and potential bias. Developing methodologies to unravel the intricate decision-making process of LLMs enhances transparency, mitigating the risk of bias while advancing their application in MIDD. With the advancement of LLMs, there are many key opportunities for organizations working in MIDD to continue working on implementing LLMs. The challenges of effective prompt design, addressing the lack of interpretability and potential bias in LLMs, and determining the scope of their use in different areas must be addressed head-on to utilize this technology to its full potential. Continued open-science development in this field is crucial to improve the evaluation of the utility of these models with respect to the different NLP tasks while increasing their utility in MIDD. C-Path has identified implementation strategies, including data curation through ICL, synthetic data generation for weak supervision of more domain-specific models for information extraction, and fine-tuning through computationally efficient methodologies. This will allow for continued progress in harnessing unstructured and structured information to be used and with appropriate evaluation strategies, the implementation of LLMs in the drug development lifecycle will be successful. AI tools were employed for drafting assistance, aiding in the creation of figures and tables, and improving overall readability and language. Critical Path Institute is supported by the Food and Drug Administration (FDA) of the Department of Health and Human Services (HHS) and is 55% funded by the FDA/HHS, totalling $17,612,250, and 45% funded by non-government source(s), totalling $14,203,111. The contents are those of the author(s) and do not necessarily represent the official views of, nor an endorsement by, FDA/HHS or the US Government. The authors declared no competing interests for this work.",
    "full_text": null
}