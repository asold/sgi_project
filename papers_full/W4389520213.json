{
    "title": "Two Directions for Clinical Data Generation with Large Language Models: Data-to-Label and Label-to-Data",
    "url": "https://openalex.org/W4389520213",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2504337560",
            "name": "Rumeng Li",
            "affiliations": [
                "Amherst College",
                "VA New England Healthcare System"
            ]
        },
        {
            "id": "https://openalex.org/A2110100846",
            "name": "Xun Wang",
            "affiliations": [
                "Microsoft (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2111112795",
            "name": "Hong Yu",
            "affiliations": [
                "Amherst College",
                "University of Massachusetts Lowell",
                "VA New England Healthcare System"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4299832927",
        "https://openalex.org/W2082302018",
        "https://openalex.org/W2768488789",
        "https://openalex.org/W2743290174",
        "https://openalex.org/W4376652993",
        "https://openalex.org/W4323709074",
        "https://openalex.org/W4377009978",
        "https://openalex.org/W2604918751",
        "https://openalex.org/W2751687090",
        "https://openalex.org/W4221143046",
        "https://openalex.org/W3159530258",
        "https://openalex.org/W4384071683",
        "https://openalex.org/W2084397926",
        "https://openalex.org/W2066918975",
        "https://openalex.org/W4360891289",
        "https://openalex.org/W4353015365",
        "https://openalex.org/W2750956523",
        "https://openalex.org/W4206774749",
        "https://openalex.org/W2805089815",
        "https://openalex.org/W2396881363",
        "https://openalex.org/W2962979297",
        "https://openalex.org/W3214401235",
        "https://openalex.org/W4385573893",
        "https://openalex.org/W2994829590",
        "https://openalex.org/W1981208470",
        "https://openalex.org/W3178751578",
        "https://openalex.org/W2937845937",
        "https://openalex.org/W3030772833",
        "https://openalex.org/W4309674289",
        "https://openalex.org/W2943552823",
        "https://openalex.org/W4226399820",
        "https://openalex.org/W4389777735",
        "https://openalex.org/W2971668428",
        "https://openalex.org/W4312091558",
        "https://openalex.org/W3169068430",
        "https://openalex.org/W4289764000",
        "https://openalex.org/W2963034797",
        "https://openalex.org/W2923014074",
        "https://openalex.org/W2963748441",
        "https://openalex.org/W2168041406",
        "https://openalex.org/W2129404933",
        "https://openalex.org/W4311642023",
        "https://openalex.org/W3200891190",
        "https://openalex.org/W2925863688",
        "https://openalex.org/W3128912454",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W4322718191",
        "https://openalex.org/W4318677156",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W3214865795"
    ],
    "abstract": "Large language models (LLMs) can generate natural language texts for various domains and tasks, but their potential for clinical text mining, a domain with scarce, sensitive, and imbalanced medical data, is under-explored. We investigate whether LLMs can augment clinical data for detecting Alzheimer's Disease (AD)-related signs and symptoms from electronic health records (EHRs), a challenging task that requires high expertise. We create a novel pragmatic taxonomy for AD sign and symptom progression based on expert knowledge and generated three datasets: (1) a gold dataset annotated by human experts on longitudinal EHRs of AD patients; (2) a silver dataset created by the data-to-label method, which labels sentences from a public EHR collection with AD-related signs and symptoms; and (3) a bronze dataset created by the label-to-data method which generates sentences with AD-related signs and symptoms based on the label definition. We train a system to detect AD-related signs and symptoms from EHRs. We find that the silver and bronze datasets improves the system performance, outperforming the system using only the gold dataset. This shows that LLMs can generate synthetic clinical data for a complex task by incorporating expert knowledge, and our label-to-data method can produce datasets that are free of sensitive information, while maintaining acceptable quality.",
    "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 7129–7143\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nTwo Directions for Clinical Data Generation with Large Language Models:\nData-to-Label and Label-to-Data\nRumeng Li1,2 and Xun Wang3 and Hong Yu1,2,4\n1Umass Amherst, Amherst, MA, USA\n2V A Bedford Healthcare System, Bedford, MA, USA\n3Microsoft, Redmond, W A, USA\n4Umass Lowell, Lowell, MA, USA\nAbstract\nLarge language models (LLMs) can generate\nnatural language texts for various domains and\ntasks, but their potential for clinical text min-\ning, a domain with scarce, sensitive, and im-\nbalanced medical data, is under-explored. We\ninvestigate whether LLMs can augment clinical\ndata for detecting Alzheimer’s Disease (AD)-\nrelated signs and symptoms from electronic\nhealth records (EHRs), a challenging task that\nrequires high expertise. We create a novel prag-\nmatic taxonomy for AD sign and symptom pro-\ngression based on expert knowledge and gener-\nated three datasets: (1) a gold dataset annotated\nby human experts on longitudinal EHRs of AD\npatients; (2) a silver dataset created by the data-\nto-label method, which labels sentences from\na public EHR collection with AD-related signs\nand symptoms; and (3) a bronze dataset cre-\nated by the label-to-data method which gener-\nates sentences with AD-related signs and symp-\ntoms based on the label definition. We train a\nsystem to detect AD-related signs and symp-\ntoms from EHRs. We find that the silver and\nbronze datasets improves the system perfor-\nmance, outperforming the system using only\nthe gold dataset. This shows that LLMs can\ngenerate synthetic clinical data for a complex\ntask by incorporating expert knowledge, and\nour label-to-data method can produce datasets\nthat are free of sensitive information, while\nmaintaining acceptable quality.\n1 Introduction\nClinical text holds a large amount of valuable in-\nformation that is not recorded by the structured\ndata fields in electronic health records (Wang et al.,\n2018b). Clinical text mining, which aims to ex-\ntract and analyze information from medical records,\nsuch as diagnosis, symptoms, treatments, and out-\ncomes, has various applications, such as clinical\ndecision support, disease surveillance, patient ed-\nucation, and biomedical research (Murdoch and\nDetsky, 2013). However, clinical text mining faces\ntwo major obstacles: the scarcity and sensitivity\nof medical data. Medical data is often limited in\nquantity and diversity, due to the high cost and\ndifficulty of data collection and annotation, which\nrequire expert knowledge and consent from patients\nand providers. On the other hand, medical data is\nhighly sensitive and confidential, due to the ethi-\ncal and legal issues of data privacy and security,\nwhich impose strict regulations and restrictions on\ndata collection and usage (Berman, 2002). These\nobstacles hinder the development and evaluation\nof clinical text mining methods, especially those\nbased on data-hungry deep learning models.\nRecently LLMs have demonstrated impressive\nperformance on many natural language processing\n(NLP) benchmarks,(Wang et al., 2018a, 2019; Ra-\njpurkar et al., 2016), as well as in medical domain\napplications (Singhal et al., 2023, 2022; Nori et al.,\n2023). However, they also face some common\nproblems like hallucination, homogenisation, etc\n(Azamfirei et al., 2023). Hallucination means that\nLLMs produce factual errors or inconsistencies in\ntheir outputs that do not match the input or the real\nworld. This can damage the reliability and credibil-\nity of LLMs, especially for applications in clinical\ndomain that need high accuracy and consistency.\nIn addition, data generated by LLMs tends to be\nhighly homogeneous and fails to capture the diver-\nsity and realism of real data, which are essential for\nmany downstream tasks. For example, for clinical\ntext analysis, we need the generated data to cover\ndifferent types of clinical texts, such as patient his-\ntories, diagnoses, or treatment plans. This presents\na huge challenge for LLM. The difference between\nLLM generated data and real data makes people\ndoubt LLMs’ practical application value.\nIn this paper, we investigated whether the out-\nputs of LLMs can be a valuable data source for clin-\nical text mining despite all these aforementioned\ndrawbacks. We focus on Alzheimer’s Disease\n(AD) signs and symptoms detection from electronic\n7129\nhealth records (EHRs) notes. Alzheimer’s Disease\n(AD) is a progressive neurodegenerative disorder\nthat affects millions of people worldwide (Schel-\ntens et al., 2021; Schachter and Davis, 2022). It can\ncause cognitive impairment, behavioral changes,\nand functional decline. Detecting AD-related signs\nand symptoms from EHR is a crucial task for early\ndiagnosis, treatment, and care planning (Leifer,\n2003). In addition to the scarcity, sensitivity, and\nimbalance of clinical data, this task is highly chal-\nlenging due to the high expertise required to inter-\npret the complex and diverse manifestations of AD\n(Dubois et al., 2021).\nWe propose a novel pragmatic taxonomy for AD\nsign and symptom progression based on expert\nknowledge, which consists of nine categories that\ncapture the cognitive, behavioral, and functional\naspects of AD (Bature et al., 2017; Lanctôt et al.,\n2017). We created three datasets following the\ntaxonomy: (1) a gold dataset annotated by human\nexperts on longitudinal EHRs of AD patients; (2) a\nsilver dataset created by the data-to-label method\nwhich labels sentences from a public EHR collec-\ntion with AD-related signs and symptoms; and (3) a\nbronze dataset created by the label-to-data method\nwhich generates sentences with AD-related signs\nand symptoms based on the label definition. The\n\"data-to-label\" method employs LLMs as annota-\ntors and has been widely adopted in many tasks.\nThe \"label-to-data\", on the other hand, relies on\nthe LLM’s generation ability to produce data with\nlabels based on instructions.\nWe performed experiments of binary classifica-\ntion (whether the sentence is related to AD signs\nand symptoms or not) and multi-class classifica-\ntion (assign one category from the nine pre-defined\ncategories of AD signs and symptoms to an input\nsentence), using different data combinations to fine-\ntune pre-trained language models (PLMs), and we\ncompared their performance on the human anno-\ntated gold test set. We observed that the system\nperformances can be significantly improved by the\nsilver and bronze datasets. In particular, combing\nthe gold and bronze dataset, which is generated\nby the label-to-data method, outperform the model\ntrained only on the gold or gold+silver dataset for\nsome categories. The minority classes with much\nfewer gold data samples benefit more from the im-\nprovement. We noticed slight degradation of per-\nformances for a small proportion of categories. But\nthe overall increases in results demonstrates that\nLLM can be applied to medical data annotation,\nand even its hallucinations can be leveraged to cre-\nate datasets that are free of sensitive information,\nwhile preserving acceptable quality.\nThe contributions of this paper are as follows:\n• We create a novel pragmatic taxonomy for AD\nsign and symptom progression based on expert\nknowledge, and it has shown to be reliably anno-\ntated using information described in EHR notes.\n• We investigate whether LLMs can augment\nclinical data for detecting AD-related signs and\nsymptoms from EHRs, using two different meth-\nods: data-to-label and label-to-data.\n• We train a system to detect AD-related signs\nand symptoms from EHRs, using three datasets:\ngold, silver, and bronze. And evaluate the qual-\nity of the synthetic data generated by LLMs using\nboth automatic and human metrics. We show that\nusing the synthetic data improves the system per-\nformances, outperforming the system using only\nthe gold dataset.\n2 Related Work\n2.1 Large Language Models\nLarge language models (LLMs) have enabled re-\nmarkable advances in many NLP domains because\nof their excellent results and ability to comprehend\nnatural language. Popular LLMs including GPT-2\n(Radford et al., 2019), GPT-3 (Brown et al., 2020),\nand GPT-4 (OpenAI, 2023), LaMDA (Thoppilan\net al., 2022), BLOOM (Scao et al., 2022), LLaMA\n(Touvron et al., 2023), etc. vary in their model size,\ndata size, training objective, and generation strat-\negy, but they all share the common feature of being\nable to generate natural language texts across vari-\nous domains and tasks. They have achieved impres-\nsive results on many natural language processing\n(NLP) benchmarks by leveraging the large-scale\nand diverse text data from the web.\nHowever, researchers have noticed the draw-\nbacks of LLMs since their debut. Some limita-\ntions of LLMs have widely acknowledged and\nhave drawn wide attentions from the research com-\nmunity like hallucination, homogenisation, etc.\n(Tamkin et al., 2021)\nHallucination is a well-known and widely-\nstudied problem in natural language generation\n(NLG), which is often defined as \"generated con-\ntent that is nonsensical or unfaithful to the provided\nsource content\" (Ji et al., 2023). Hallucination has\nbeen observed and analyzed in various NLG tasks,\n7130\nsuch as machine translation (MT) (Guerreiro et al.,\n2023), text summarization (Cao et al., 2021), and\ndialogue generation (Das et al., 2023). Hallucina-\ntion can be caused by various factors, such as data\nnoise, model bias, lack of commonsense knowl-\nedge, or insufficient supervision. It can be detected\nand mitigated by various methods, such as data\ncleaning, model regularization, knowledge injec-\ntion, or output verification (Ji et al., 2023).\nIn this paper, we explore a different angle on hal-\nlucination, and examine whether the hallucinations\nof LLMs can be a valuable data source for clinical\ntext processing, rather than a difficulty. We propose\nthat the hallucinations of LLMs can be leveraged\nto create synthetic or augmented datasets that do\nnot expose sensitive information, but still maintain\nthe linguistic and semantic features of clinical texts,\nsuch as vocabulary, syntax, and domain knowledge.\nExperiments on classification tasks confirmed the\nvalidity of the proposal.\nHomogenisation is also a potential drawback\nof using LLMs at a large scale. While it ensures\nthe stability of the text quality, it also reduces\nthe diversity of text. This issue has been noticed\nand discussed (Marian, 2023), but there is still a\nlack of research in this direction. In this work,\nwe have observed homogenisation in the \"label-\nto-data\" method and conducted experiment which\nhelp reveal how it impacts the system performances\non the studied task.\n2.2 Clinical Text Mining and synthetic data\ngeneration\nClinical text mining faces two main obstacles: the\nlimited availability and the confidentiality of health\ndata. Various attempts have been done to over-\ncome the lack of and the privacy issues with health\ndata. Public datasets, such as MIMIC (Johnson\net al., 2016), i2b2 (Uzuner et al., 2011), or BioASQ\n(Tsatsaronis et al., 2015) etc, are openly available\nfor research purposes. Synthetic datasets, such\nas Synthea (Walonoski et al., 2018) and MedGAN\n(Choi et al., 2017) etc., are constructed based on sta-\ntistical models, generative models, or rules. They\ncan be used to augment or complement real medical\ndata, without violating the privacy or confidential-\nity of the patients or providers. Data augmentation\nor transfer learning techniques are machine learn-\ning techniques used to address the data scarcity\nor imbalance issue by generating or utilizing addi-\ntional or related data, such as synthetic data, noisy\ndata, or cross-domain data, to enrich or improve the\ndata representation or diversity (Che et al., 2017;\nGligic et al., 2020; Gupta et al., 2018; Xiao et al.,\n2018; Amin-Nejad et al., 2020; Li et al., 2021).\nHowever, synthetic datasets may not capture the\nnaturalness and realism of human-written medical\ntexts, and may introduce errors or biases that can\naffect the performance and validity of clinical text\nmining methods.\nLLMs have also been explored for clinical text\nprocessing. Research has demonstrated that LLM\nholds health information (Singhal et al., 2022).\nStudies has shown that LLMs can generate unstruc-\ntured data from structured inputs and benefit down-\nstream tasks (Tang et al., 2023). There are also\nsome work that leveraged LLMs for clincal data\naugmentation (Chintagunta et al., 2021; Guo et al.,\n2023) In this paper, we propose a novel approach\nto leverage LLMs, especially its hallucination abil-\nity via the label-to-data method as a data source\nfor clinical text processing, which can mitigate the\nscarcity and sensitivity of medical data.\n2.3 Alzheimer’s disease signs and symptoms\ndetection\nClinical text mining methods have been increas-\ningly applied to detect AD or identify AD signs\nand symptoms from spontaneous speech or elec-\ntronic health records, which could be potentially\nsevered as a natural and non-invasive way of as-\nsessing cognitive and linguistic functions. (Kar-\nlekar et al., 2018) applied neural models to classify\nand analyze the linguistic characteristics of AD\npatients using the DementiaBank dataset. (Wang\net al., 2021) developed a deep learning model for\nearlier detection of cognitive decline from clinical\nnotes in EHRs. (Liu and Yuan, 2021) used a novel\nNLP method based on term frequency-inverse doc-\nument frequency (TF-IDF) to detect AD from the\ndialogue contents of the Predictive Challenge of\nAlzheimer’s Disease. (Agbavor and Liang, 2022)\nused large language models to predict dementia\nfrom spontaneous speech, using the DementiaBank\nand Pitt Corpus datasets. These studies demon-\nstrate the potential of clinical mining methods for\nassisting diagnosis of AD and analyzing lexical\nperformance in clinical settings.\n3 Methodology\nIn this section, we introduce our task of AD signs\nand symptoms detection, and how we leveraged\n7131\nLLMs’s capabilities for medical data annotation\nand generation. We also present the three different\ndatasets (gold, silver and bronze) that we created\nand used for training and evaluating classifiers for\nAD signs and symptoms detection.\n3.1 Task overview\nAlzheimer’s disease (AD) is a neurodegenerative\ndisorder that affects memory, thinking, reasoning,\njudgment, communication, and behavior. It is the\nfifth-leading cause of death among Americans age\n65 and older (Mucke, 2009). This task aims to\nidentify nine categories of AD signs and symp-\ntoms from unstructured clinical notes. The cat-\negories are: Cognitive impairment, Notice/con-\ncern by others, Require assistance/functional im-\npairment, Physiological changes, Cognitive assess-\nments, Cognitive intervention/therapy, Diagnostic\ntests, Coping strategy, and Neuropsychiatric symp-\ntoms. These categories indicate the stages and\nseverity of AD. Capturing them in unstructured\nEHRs can help with early diagnosis and interven-\ntion, appropriate care and support, disease mon-\nitoring and treatment evaluation, and quality of\nlife improvement for people with AD and their\ncaregivers. This is very challenging a task as the\nAD-related signs and symptoms can vary in form\nand severity, and it requires a lot of knowledge and\nexperience to capture them from a large amount\nof text. We ask experts to create the annotation\nguideline by defining each category of AD-related\nsigns and symptoms and providing examples and\ninstructions for the annotators (See Appendix A for\ndetails).\n3.2 Datasets\nAs stated above, we created and utilized three dif-\nferent datasets for our experiments: gold, silver and\nbronze.\n3.2.1 Gold data (Human annotation)\nWe expert annotated 5112 longitudinal EHR notes\nof 76 patients with AD from the U.S. Department\nof Veterans Affairs Veterans Health Administration\n(VHA). The use of the data has been approved by\nthe Institutional Review Board at the VHA Bed-\nford Healthcare System, which also approved the\nwaiver of documentation of informed consent. Un-\nder physician supervision, two medical profession-\nals annotate the notes for AD signs and symptoms\nfollowing the annotation guidelines. They selected\nsentences to be annotated and labelled its categories\nas output, and resolved the disagreements by dis-\ncussion. The inter-annotator agreement was mea-\nsured by Cohen’s kappa as k=0.868, indicating a\nhigh level of reliability. This leads to the gold stan-\ndard dataset with 16,194 sentences with a mean\n(SD) sentence length of 17.60 (12.69) tokens.\n3.2.2 Silver data (Data-to-Label)\nThe silver dataset consisted of 16,069 sentences\nwith a mean (SD) sentence length of 19.60 (15.44)\ntokens extracted from the MIMIC-III database\n(Johnson et al., 2016), which is a large collection\nof de-identified clinical notes from intensive care\nunits. We randomly sampled the sentences from\nthe discharge summaries, and used the LLM model\nto annotate them with AD-related symptoms. The\nLLM receives the annotation guidelines and the\nclinical text as input and produces the sentence to\nbe annotated and its categories as output. The out-\nputs are further checked by the LLM by asking\nfor a reason to explain why the sentence belongs\nto the assigned category. In this step, the inputs\nto the LLM are the guidelines and the annotated\nsentences and the outputs are Boolean values and\nexplanations. This chain-of-thoughts style check-\ning has been proved to improve LLM performances\n(Wei et al., 2022). Although many LLMs can be\nused here, we adopt the Llama 65B (Touvron et al.,\n2023) due to its performances, availability, costs\nand privacy concerns.\n3.2.3 Bronze data (Label-to-Data)\nWe used GPT-4, a state-of-the-art LLM that has\nbeen shown to generate coherent and diverse texts\nacross various domains and tasks (OpenAI, 2023).\nGPT-4 is a transformer-based model with billions\nof parameters, trained on a large corpus of web\ntexts. We accessed GPT-4 through the Azure Ope-\nnAI service 1.\nIn the generation task, GPT-4 takes only the an-\nnotation guidelines as input and produces a piece of\nnote text and outputs the sentence to be annotated\nand its categories. This is a bronze-level dataset\nthat does not contain any sensitive personal infor-\nmation. It consists of 16,047 sentences with an\naverage sentence length of 16.58 words. Figure 1\nshows a snippet of the generated text and annota-\ntions. As shown in the example, the model firstly\ngenerates a clinical text and then extract sentences\nof interests for annotation. The generated text is\n1https://azure.microsoft.com/en-us/products/cognitive-\nservices/openai-service/\n7132\nrich in AD signs and symptoms and contains no\nProtected Health Information (PHI) or (Personally\nIdentifiable Information) PII. While the text doesn’t\ncompletely convey the complexity of AD diagnosis,\nor the follow-up required to arrive at AD diagnosis\n(e.g. \"I immediately drove over and took him to the\nER. After a series of tests, including an MRI and a\nneuropsychological evaluation, he was diagnosed\nwith Alzheimer’s disease. \" In fact, the diagnosis\nof AD is a challenging task and it’s unlikely to\nget diagnosed with AD at the ER department), it\nmaintains the linguistic and semantic features of\nclinical texts, i.e., vocabulary, syntax, and domain\nknowledge, and represents high quality annotation.\nWe processed the datasets by tokenizing, lower-\ncasing, and removing duplicate sentences. We split\nthem into train, validation, and test sets (80/10/10\nratio). Table 1 shows the dataset statistics. The\ngold and silver data have similar average length\nand standard deviation. The bronze data has a\nsmaller standard deviation and a more balanced\ncategorical distribution than the gold and silver\ndata, which differs from real patient notes. The\nsmaller SD in sentence lengths indicates less diver-\nsity in the bronze data. We will experiment with\nthese datasets to see how the LLM’s output can\nhelp clinical text mining.\n3.3 Experiments\n3.3.1 Classifiers\nWe use an ensemble method that integrates mul-\ntiple models and relies on voting to produce the\nfinal output. This reduces the variance and bias\nof individual models and enhances the accuracy\nand generalization of the prediction, which is cru-\ncial for clinical text mining (Mohammed and Kora,\n2023).\nFor the base models, we utilized the power of\npre-trained language models (PLMs), which are\nneural networks that have been trained on large\namounts of text data and can capture general lin-\nguistic patterns. Three different PLMs, namely\nBERT (bert-base-uncased) (Devlin et al., 2018) ,\nRoBERTa (roberta-base) (Liu et al., 2019) and Clin-\nicalBERT (Huang et al., 2019) are used in this work.\nThese models have been widely used for clinical\ntext processing and achieved good performances\n(Vakili et al., 2022; Alsentzer et al., 2019) .\nWe fine-tune the PLM models on different com-\nbinations of the gold, silver, and bronze datasets, as\ndescribed below. We use cross-entropy loss, Adam\noptimizer (with a learning rate of 1e-4 and a batch\nsize of 32), and 10 epochs for training. We select\nthe best checkpoints based on the validation accu-\nracy for testing. The outputs are determined by a\nmajority vote strategy.\nWe use a subset of the gold dataset as the test\nset. We compare the performances using accuracy,\nprecision, recall, and F1-score.\n3.3.2 Data Combinations\nGold only We fine-tuned the PLMs only on the\ntraining set of the gold data and evaluate the perfor-\nmance on the test set of the gold data.\nBronze + Gold, we fine-tuned the PLMs on the\nbronze data and further fine-tuned them on the train-\ning set of the gold data and evaluate the perfor-\nmance on the test set of the gold data.\nSilver + Gold, we fine-tuned the PLMs on the sil-\nver data and further fine-tuned them on the training\nset of the gold data and evaluate the performance\non the test set of the gold data.\nBronze + Silver + Gold, we fine-tuned the PLMs\non the combination of the bronze data and silver\ndata, and further fine-tuned them on the training\nset of the gold data and evaluate the performance\non the test set of the gold data.\nFor each data setting, we trained the models as a\nbinary classifier and multi-class classifier. For the\nbinary classification task, we randomly sampled\nsentences with no AD signs and symptoms from\nthe longitudinal notes of the 76 patients, where our\ngold data comes from, as negative data. The nega-\ntive/positive data ratio is 5:1 2. The task is to test\nwhether this sentences is AD signs and symptoms\nrelevant or not. For the multi-class classification\ntask, the classifiers need to identify specifically one\ncategory that the sentence belongs to among our\nnine categories of AD signs and symptoms.\n4 Results and Discussion\n4.1 Results\nTable 2 and Table 3 show the performance of the\nsystem on the test set of the gold data, using differ-\nent combinations of data for fine-tuning PLMs.\nThe results demonstrate that the system bene-\nfits from the silver and bronze data and most in-\ncreases are significant. For binary classification,\nthe highest performance is obtained by fine-tuning\nthe system on both the bronze+silver data (over-\nall accuracy=0.94, 4.44% ↑), followed by adding\n2See Appendix for negative data generation.\n7133\nFigure 1: Illustration of the text and annotation generated by the GPT-4 based on the annotation guideline. (Class\nnames are shown here for better readability.)\nCategory Gold Silver Bronze\nCognitive impairment 6240 1378 2704\nNotice/concern by others 785 366 1710\nRequire assistance 1864 614 1205\nPhysiological changes 1340 5718 1769\nCognitive assessments 2099 327 2168\nCognitive intervention/therapy 1097 3508 2104\nDiagnostic tests 1084 2933 2021\nCoping strategy 343 893 1058\nNeuropsychiatric symptoms 1342 318 1308\nTotal 16194 16069 16047\nAvg length +/- SD (tokens) 17.60 +/- 12.69 19.60+/-15.44 16.58+/-4.69\nTable 1: Category Distribution of the Gold/Silver/Bronze Datasets\nbronze data only (overall accuracy=0.93 3.33% ↑).\nThe silver data, though derived from MIMIC-III,\nthe real world EHR data, only improves slightly\n(0.91, 1.11% ↑).\nFor multi-class classification, the bronze data\nalone provides the biggest overall performance\nimprovement (7.35%↑). On the contrary the sil-\nver data does not improve much (1.47% ↑) and\neven reduces the performance when combined\nwith the bronze data (5.88%↑< 7.35%↑). For sub-\ncategories, the performance gain is large in minor-\nity classes including coping strategy (31.82%↑ by\nadding bronze+silver) and notice/concern by others\n(21.05%↑ by adding bronze+silver).\n4.2 Analysis\nThe performances of machine learning models are\nlargely decided by data quantity and quality. To\nbetter understand the results, we conducted a series\nof analysis.\nAs Table 1 shows, the gold data has an imbal-\nanced distribution of categories. This poses a chal-\nlenge for classification tasks. The bronze+silver\ndata, with a more balanced categorical distribu-\ntion, helps to mitigate this problem. We notice an\nincrease in the performance for Coping strategy\n(31.82%↑) using bronze+silver data. Performance\ngains are also observed for other minority classes\nincluding NPS, Requires assistance, Cognitive as-\nsessment, etc., by adding more training examples.\nThe amount of data is not the only factor that\ninfluences the performance. For the physiological\nchanges category, adding silver data 4 times the\nsize of the gold data makes no difference, while\nadding a smaller amount of bronze data results in\n7134\nGold\nOnly + Bronze + Silver + Bronze + Silver\nPrecision (Positive) 0.73 0.88 (20.55%↑) 0.73 (0%) 0.86 (17.81%↑)\nRecall (Positive) 0.75 0.7 (6.67%↓) 0.77 (2.67%↑) 0.74 (1.33%↓)\nF-1(Positive) 0.74 0.78 (5.41%↑) 0.75 (1.35%↑) 0.8 (8.11%↑)\nOverall Accuracy 0.9 0.93 (3.33%↑) 0.91 (1.11%↑) 0.94 (4.44%↑)\nTable 2: Performance (P/R/F-1/Accuracy (change compared to gold only)) of the ensemble system on the gold test\nset using different data combinations for training (Binary Classification).\nGold\nOnly + Bronze + Silver + Bronze + Silver\nCognitive impairment 0.72 0.73 (1.4%↑) 0.72 (0%) 0.74 (2.78%↑)\nNotice/concern by others 0.38 0.4 (5.26%↑) 0.41 (7.89%↑) 0.46 (21.05%↑)\nRequires assistance 0.64 0.64 (0%) 0.63 (1.56%↓) 0.68 (6.25%↑)\nPhysiological changes 0.64 0.78 (21.88%↑) 0.64 (0%) 0.76 (18.75%↑)\nCognitive assessment 0.69 0.75 (8.70%↑) 0.7 (1.45%↑) 0.77 (11.59%↑)\nCognitive intervention/therapy 0.71 0.74(4.23%↑)) 0.72 (1.41%↑) 0.76 (7.04%↑)\nDiagnostic tests 0.84 0.83 (1.19%↓) 0.87 (3.57%↑) 0.82 (2.38%↓)\nCoping strategy 0.44 0.42 (4.55%↓) 0.47 (6.82%↑) 0.58(31.82%↑)\nNPS 0.67 0.71 (5.97%↑) 0.68 (1.49%↑) 0.69 (2.99%↑)\nOverall Accuracy 0.68 0.73 (7.35%↑) 0.69 (1.47%↑) 0.72 (5.88%↑)\nTable 3: Performance (F-1/Accuracy (change compared to gold only)) of the ensemble system on the gold test set\nusing different data combinations for training (Multi-class Classification).\na significant improvement of 21.88% in F-scores.\nThis suggests that the bronze data has a higher\nquality than the silver data for some categories.\nWe randomly selected 100 samples from both\nthe silver data and the bronze data and asked our\nhuman experts to check the quality of the anno-\ntation. The annotation accuracy on bronze data\nis around 85%, and annotation accuracy on silver\ndata is around 55% indicating the complexity and\nchallenge of real world data. Some examples of\nLLM’s labeling errors are shown in Table 4.\nExperts identify at least two types of labelling\nerrors by the LLM in the silver data:\n1. Over-inference (example 1&2), the LLM\ntends to make inference based on the informa-\ntion that is presented, and goes beyond what\nis supported by the evidence or reasoning.\n2. The LLM couldn’t handle negation properly\n(example 3).\nIn example 1, the LLM infers that the patient\nis weak so assistance must be required. Similar\nto example 2, we found that there are some sen-\ntences that mentioned son/daughter as nurses also\nget labelled as Concerns by others. The LLM in-\nfers that specific medical knowledge of children\nor spouse/children being present at hospital may\nindicate concern, but this could be wrong.\nThe mis-classified data impacts the two tasks dif-\nferently. For binary classification, the system only\nneeds to distinguish sentences with AD-related\nsigns and symptoms from other texts, so the mis-\nclassification is less critical. However, for multi-\nclass classification task, the system needs to cor-\nrectly assign the categories of the AD-related signs\nand symptoms, which can be confused by the\nLLMs outputs. This partially offsets the advantage\nof increasing the amount of data, especially when\nusing the silver dataset, which has a much lower\naccuracy than the bronze dataset. We observe that\nthe silver dataset even harms the performance on\n\"Requires Assistance\" in multi-class classification\ntask.\nOn the other hand, when using the bronze\ndataset, which has a relatively higher quality, we\nsee overall performance improvements for both\nbinary and multi-class classification tasks. We no-\nticed that in the multi-class classification task, the\nbronze data causes performance degradation on\n7135\nsome categories. The bronze data differs from the\ngold or silver data, which are real patient notes.\nThis may cause distribution mismatch with the test\ndataset and lower performance for some categories.\nTable 1 shows the bronze data has less variation\nin lengths (4.69 vs 12.69,15.44). This suggests\nthat we need to steer LLMs to produce data that\nmatches the data encountered in practice.\nTo sum up, different data combinations affect\nthe results (Table 2&3) by varying the training data\nin amount, quality and distribution. However, the\nperformance generally improves with the addition\nof the bronze and/or silver data, though further\nanalysis is needed for each category.\n5 Conclusion and Future Work\nIn this paper, we examined the possibility of using\nLLMs for medical data generation, and assessed the\neffect of LLMs’ outputs on clinical text mining. We\ndeveloped three datasets: a gold dataset annotated\nby human experts from a medical dataset, which is\nthe most widely used method for clinical data gen-\neration, a silver dataset annotated by the LLM from\nMIMIC (data-to-label) and a bronze dataset gen-\nerated by the LLM from its hallucinations (label-\nto-data). We conducted experiments to train classi-\nfiers to detect and categorize Alzheimer’s disease\n(AD)-related symptoms from medical records. We\ndiscovered that using a combination of gold data\nplus bronze and/or silver achieved better perfor-\nmances than using gold data only, especially for\nminority categories, and that the LLM annotations\nand hallucinations were helpful for augmenting the\ntraining data, despite some noise and errors.\nOur findings suggest that LLM can be a valuable\ntool for medical data annotation when used care-\nfully, especially when the data is scarce, sensitive,\nor costly to obtain and annotate. By using LLM\nhallucinations, we can create synthetic data that\ndoes not contain real patient information, and that\ncan capture some aspects of the clinical language\nand domain knowledge. However, our approach\nalso has some ethical and practical challenges, such\nas ensuring the quality, diversity, validity, and reli-\nability of the LLM annotations and hallucinations,\nprotecting the privacy and security of the data and\nthe model, and avoiding the potential harms and\nbiases of the LLM outputs.\nFor future work, we will investigate other meth-\nods and techniques for enhancing and regulating\nthe LLM annotations and hallucinations, such as\nusing prompts, feedback, or adversarial learning.\nAnd we would also tackle the ethical and practical\nissues of using LLM for medical data annotation,\nby adhering to the best practices and guidelines for\nresponsible and trustworthy AI. We also intend to\napply our approach to other clinical text processing\ntasks, such as relation extraction, entity linking,\nand clinical note generation.\n6 Limitations\nDespite the promising results, our approach has sev-\neral limitations that need to be acknowledged and\naddressed in future work. First, our experiments\nare based on the experimented LLMs and a sin-\ngle clinical task (AD-related signs and symptoms\ndetection). It is unclear how well our approach\ncan generalize to other LLMs, and other clinical\ntasks. Different LLMs may have different hallu-\ncination patterns and biases, and different clinical\ntasks may have different annotation criteria and\nchallenges. Therefore, more comprehensive and\nsystematic evaluations are needed to validate the\nrobustness and applicability of our approach.\nSecond, our approach relies on the quality and\nquantity of the LLMs annotations and hallucina-\ntions, which are not guaranteed to be consistent or\naccurate. The LLMs produces irrelevant, incorrect,\nor incomplete annotations or hallucinations, which\nwill introduce noise or confusion to the classifier.\nMoreover, the LLMs may not cover the full spec-\ntrum of the AD-related signs and symptoms, or\nmay generate some rare or novel symptoms that\nare not in the gold dataset. Therefore, the LLMs’\nannotations and hallucinations may not fully reflect\nthe true distribution and diversity of the clinical\ndata. To mitigate these issues, we suggest using\nsome quality control mechanisms, such as filtering,\nsampling, or post-editing, to improve the LLMs’\noutputs. Fine tuning on high quality gold data can\npartially address these problems. We also suggest\nusing some data augmentation techniques, such as\nparaphrasing, synonym substitution, or adversarial\nperturbation, to enhance the LLMs’ outputs.\nThird, our approach may raise some ethical and\npractical concerns regarding the use of LLMs for\nmedical data annotation, especially its hallucina-\ntions. Although not observed in this work, there\nis still a slight possibility that the LLMs may pro-\nduce some sensitive or personal information that\nmay breach the privacy or consent of the patients\nor the clinicians. The LLMs may also generate\n7136\nNo. Sentence LLM annotation Human comments\n1 [Pt] was profoundly weak, but was no longer\ntachycardic and had a normal blood pressure.\nRequires assistance Over-inference\n2 Her husband is a pediatric neurologist at\n[Hospital].\nNotice/concern by others Over-inference\n3 Neck is supple without lymphadenopathy. Physiological changes Miss negation\nTable 4: Examples of the LLM’s incorrect annotations from the silver data\nsome misleading or harmful information that may\naffect the diagnosis or treatment of the patients or\nthe decision making of the clinicians. Therefore,\nthe LLM outputs should be used with caution and\nresponsibility, and should be verified and validated\nby human experts before being used for any clinical\npurposes. We also suggest using some anonymiza-\ntion or encryption techniques to protect the confi-\ndentiality and security of the LLM outputs.\n7 Acknowledgement\nThis study was supported by the National Insti-\ntute on Aging of the National Institutes of Health\n(NIH) under award number R01AG080670. The\nauthors are solely responsible for the content and\ndo not represent the official views of the NIH. We\nare grateful to Dan Berlowitz, MD from Univer-\nsity of Massachusetts Lowell, Brian Silver, MD\nand Alok Kapoor, MD, from UMass Chan Medical\nSchool for their clinical expertise in developing\nour annotation guidelines of Alzheimer’s Disease.\nWe also appreciate the work of our annotators Rae-\nlene Goodwin, BS and Heather Keating, PhD and\nWen Hu, MS from the Center for Healthcare Or-\nganization & Implementation Research, Veterans\nAffairs Bedford Healthcare System, Bedford, Mas-\nsachusetts, for developing annotation guidelines\nand annotating electronic health record notes that\nwere essential for training/evaluating our natural\nlanguage processing system and assessing the qual-\nity of the automatically generated data by LLMs.\nFinally, we thank our anonymous reviewers and\nchairs for their constructive comments and feed-\nback that helped us improve our paper.\nReferences\nFelix Agbavor and Hualou Liang. 2022. Pre-\ndicting dementia from spontaneous speech using\nlarge language models. PLOS Digital Health ,\n1(12):e0000168.\nEmily Alsentzer, John R Murphy, Willie Boag, Wei-\nHung Weng, Di Jin, Tristan Naumann, and Matthew\nMcDermott. 2019. Publicly available clinical bert\nembeddings. arXiv preprint arXiv:1904.03323.\nAli Amin-Nejad, Julia Ive, and Sumithra Velupillai.\n2020. Exploring transformer text generation for med-\nical dataset augmentation. In Proceedings of the\nTwelfth Language Resources and Evaluation Confer-\nence, pages 4699–4708.\nRazvan Azamfirei, Sapna R Kudchadkar, and James\nFackler. 2023. Large language models and the perils\nof their hallucinations. Critical Care, 27(1):1–2.\nFidelia Bature, Barbara-ann Guinn, Dong Pang, and\nYannis Pappas. 2017. Signs and symptoms preceding\nthe diagnosis of alzheimer’s disease: a systematic\nscoping review of literature from 1937 to 2016. BMJ\nopen, 7(8):e015746.\nJules J Berman. 2002. Confidentiality issues for medical\ndata miners. Artificial intelligence in medicine, 26(1-\n2):25–36.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nMeng Cao, Yue Dong, and Jackie Chi Kit Cheung. 2021.\nInspecting the factuality of hallucinated entities in\nabstractive summarization. CoRR, abs/2109.09784.\nZhengping Che, Yu Cheng, Shuangfei Zhai, Zhaonan\nSun, and Yan Liu. 2017. Boosting deep learning risk\nprediction with generative adversarial networks for\nelectronic health records. In 2017 IEEE International\nConference on Data Mining (ICDM), pages 787–792.\nIEEE.\nBharath Chintagunta, Namit Katariya, Xavier Amatri-\nain, and Anitha Kannan. 2021. Medically aware\ngpt-3 as a data generator for medical dialogue sum-\nmarization. In Machine Learning for Healthcare\nConference, pages 354–372. PMLR.\nEdward Choi, Siddharth Biswal, Bradley Malin, Jon\nDuke, Walter F Stewart, and Jimeng Sun. 2017. Gen-\nerating multi-label discrete patient records using gen-\nerative adversarial networks. In Machine learning\nfor healthcare conference, pages 286–305. PMLR.\n7137\nSouvik Das, Sougata Saha, and Rohini K. Srihari. 2023.\nDiving deep into modes of fact hallucinations in dia-\nlogue systems.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nBruno Dubois, Nicolas Villain, Giovanni B Frisoni,\nGil D Rabinovici, Marwan Sabbagh, Stefano Cappa,\nAlexandre Bejanin, Stéphanie Bombois, Stéphane\nEpelbaum, Marc Teichmann, et al. 2021. Clinical\ndiagnosis of alzheimer’s disease: recommendations\nof the international working group. The Lancet Neu-\nrology, 20(6):484–496.\nLuka Gligic, Andrey Kormilitzin, Paul Goldberg, and\nAlejo Nevado-Holgado. 2020. Named entity recogni-\ntion in electronic health records using transfer learn-\ning bootstrapped neural networks. Neural Networks,\n121:132–139.\nNuno M Guerreiro, Duarte Alves, Jonas Waldendorf,\nBarry Haddow, Alexandra Birch, Pierre Colombo,\nand André FT Martins. 2023. Hallucinations in\nlarge multilingual translation models. arXiv preprint\narXiv:2303.16104.\nZhen Guo, Peiqi Wang, Yanwei Wang, and Shangdi Yu.\n2023. Dr. llama: Improving small language models\nin domain-specific qa via generative data augmenta-\ntion. arXiv preprint arXiv:2305.07804.\nPriyanka Gupta, Pankaj Malhotra, Lovekesh Vig, and\nGautam Shroff. 2018. Transfer learning for clinical\ntime series analysis using recurrent neural networks.\narXiv preprint arXiv:1807.01705.\nKexin Huang, Jaan Altosaar, and Rajesh Ranganath.\n2019. Clinicalbert: Modeling clinical notes and\npredicting hospital readmission. arXiv preprint\narXiv:1904.05342.\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan\nSu, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea\nMadotto, and Pascale Fung. 2023. Survey of halluci-\nnation in natural language generation. ACM Comput-\ning Surveys, 55(12):1–38.\nAlistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H\nLehman, Mengling Feng, Mohammad Ghassemi,\nBenjamin Moody, Peter Szolovits, Leo Anthony Celi,\nand Roger G Mark. 2016. Mimic-iii, a freely accessi-\nble critical care database. Scientific data, 3(1):1–9.\nSweta Karlekar, Tong Niu, and Mohit Bansal. 2018.\nDetecting linguistic characteristics of alzheimer’s de-\nmentia by interpreting neural models. arXiv preprint\narXiv:1804.06440.\nKrista L Lanctôt, Joan Amatniek, Sonia Ancoli-\nIsrael, Steven E Arnold, Clive Ballard, Jiska Cohen-\nMansfield, Zahinoor Ismail, Constantine Lyketsos,\nDavid S Miller, Erik Musiek, et al. 2017. Neuropsy-\nchiatric signs and symptoms of alzheimer’s disease:\nNew treatment paradigms. Alzheimer’s & Demen-\ntia: Translational Research & Clinical Interventions,\n3(3):440–449.\nBennett P Leifer. 2003. Early diagnosis of alzheimer’s\ndisease: clinical and economic benefits. Journal\nof the American Geriatrics Society , 51(5s2):S281–\nS288.\nJianfu Li, Yujia Zhou, Xiaoqian Jiang, Karthik Natara-\njan, Serguei Vs Pakhomov, Hongfang Liu, and Hua\nXu. 2021. Are synthetic clinical notes useful for real\nnatural language processing tasks: A case study on\nclinical entity recognition. Journal of the American\nMedical Informatics Association, 28(10):2193–2201.\nNing Liu and Zhenming Yuan. 2021. Spontaneous lan-\nguage analysis in alzheimer’s disease: evaluation of\nnatural language processing technique for analyzing\nlexical performance. Journal of Shanghai Jiaotong\nUniversity (Science), pages 1–8.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nViorica Marian. 2023. Opinion | ai could cause a mass-\nextinction of languages - and ways of thinking.\nAmmar Mohammed and Rania Kora. 2023. A com-\nprehensive review on ensemble deep learning: Op-\nportunities and challenges. Journal of King Saud\nUniversity-Computer and Information Sciences.\nLennart Mucke. 2009. Alzheimer’s disease. Nature,\n461(7266):895–897.\nTravis B Murdoch and Allan S Detsky. 2013. The in-\nevitable application of big data to health care. Jama,\n309(13):1351–1352.\nHarsha Nori, Nicholas King, Scott Mayer McKinney,\nDean Carignan, and Eric Horvitz. 2023. Capabili-\nties of gpt-4 on medical challenge problems. arXiv\npreprint arXiv:2303.13375.\nOpenAI. 2023. Gpt-4 technical report.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. Squad: 100,000+ questions\nfor machine comprehension of text. arXiv preprint\narXiv:1606.05250.\nTeven Le Scao, Angela Fan, Christopher Akiki, El-\nlie Pavlick, Suzana Ili ´c, Daniel Hesslow, Roman\nCastagné, Alexandra Sasha Luccioni, François Yvon,\nMatthias Gallé, et al. 2022. Bloom: A 176b-\nparameter open-access multilingual language model.\narXiv preprint arXiv:2211.05100.\n7138\nArmand S Schachter and Kenneth L Davis. 2022.\nAlzheimer’s disease. Dialogues in clinical neuro-\nscience.\nPhilip Scheltens, Bart De Strooper, Miia Kivipelto,\nHenne Holstege, Gael Chételat, Charlotte E Teu-\nnissen, Jeffrey Cummings, and Wiesje M van der\nFlier. 2021. Alzheimer’s disease. The Lancet ,\n397(10284):1577–1590.\nKaran Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mah-\ndavi, Jason Wei, Hyung Won Chung, Nathan Scales,\nAjay Tanwani, Heather Cole-Lewis, Stephen Pfohl,\net al. 2022. Large language models encode clinical\nknowledge. arXiv preprint arXiv:2212.13138.\nKaran Singhal, Tao Tu, Juraj Gottweis, Rory Sayres,\nEllery Wulczyn, Le Hou, Kevin Clark, Stephen\nPfohl, Heather Cole-Lewis, Darlene Neal, et al.\n2023. Towards expert-level medical question an-\nswering with large language models. arXiv preprint\narXiv:2305.09617.\nAlex Tamkin, Miles Brundage, Jack Clark, and Deep\nGanguli. 2021. Understanding the capabilities, limi-\ntations, and societal impact of large language models.\narXiv preprint arXiv:2102.02503.\nRuixiang Tang, Xiaotian Han, Xiaoqian Jiang, and\nXia Hu. 2023. Does synthetic data generation of\nllms help clinical text mining? arXiv preprint\narXiv:2303.04360.\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam\nShazeer, Apoorv Kulshreshtha, Heng-Tze Cheng,\nAlicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al.\n2022. Lamda: Language models for dialog applica-\ntions. arXiv preprint arXiv:2201.08239.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al. 2023. Llama: Open and effi-\ncient foundation language models. arXiv preprint\narXiv:2302.13971.\nGeorge Tsatsaronis, Georgios Balikas, Prodromos\nMalakasiotis, Ioannis Partalas, Matthias Zschunke,\nMichael R Alvers, Dirk Weissenborn, Anastasia\nKrithara, Sergios Petridis, Dimitris Polychronopou-\nlos, et al. 2015. An overview of the bioasq large-scale\nbiomedical semantic indexing and question answer-\ning competition. BMC bioinformatics, 16(1):1–28.\nÖzlem Uzuner, Brett R South, Shuying Shen, and\nScott L DuVall. 2011. 2010 i2b2/va challenge on\nconcepts, assertions, and relations in clinical text.\nJournal of the American Medical Informatics Associ-\nation, 18(5):552–556.\nThomas Vakili, Anastasios Lamproudis, Aron Henriks-\nson, and Hercules Dalianis. 2022. Downstream task\nperformance of bert models pre-trained using auto-\nmatically de-identified clinical data. In Proceedings\nof the Thirteenth Language Resources and Evalua-\ntion Conference, pages 4245–4252.\nJason Walonoski, Mark Kramer, Joseph Nichols, Andre\nQuina, Chris Moesel, Dylan Hall, Carlton Duffett,\nKudakwashe Dube, Thomas Gallagher, and Scott\nMcLachlan. 2018. Synthea: An approach, method,\nand software mechanism for generating synthetic pa-\ntients and the synthetic electronic health care record.\nJournal of the American Medical Informatics Associ-\nation, 25(3):230–238.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Aman-\npreet Singh, Julian Michael, Felix Hill, Omer Levy,\nand Samuel Bowman. 2019. Superglue: A stick-\nier benchmark for general-purpose language under-\nstanding systems. Advances in neural information\nprocessing systems, 32.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R Bowman. 2018a.\nGlue: A multi-task benchmark and analysis platform\nfor natural language understanding. arXiv preprint\narXiv:1804.07461.\nLiqin Wang, John Laurentiev, Jie Yang, Ying-Chih Lo,\nRebecca E Amariglio, Deborah Blacker, Reisa A\nSperling, Gad A Marshall, and Li Zhou. 2021. De-\nvelopment and validation of a deep learning model\nfor earlier detection of cognitive decline from clini-\ncal notes in electronic health records. JAMA network\nopen, 4(11):e2135174–e2135174.\nYanshan Wang, Liwei Wang, Majid Rastegar-Mojarad,\nSungrim Moon, Feichen Shen, Naveed Afzal, Sijia\nLiu, Yuqun Zeng, Saeed Mehrabi, Sunghwan Sohn,\net al. 2018b. Clinical information extraction appli-\ncations: a literature review. Journal of biomedical\ninformatics, 77:34–49.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.\nChain of thought prompting elicits reasoning in large\nlanguage models. arXiv preprint arXiv:2201.11903.\nCao Xiao, Edward Choi, and Jimeng Sun. 2018. Oppor-\ntunities and challenges in developing deep learning\nmodels using electronic health records data: a sys-\ntematic review. Journal of the American Medical\nInformatics Association, 25(10):1419–1428.\n7139\nA Annotation Guideline\nThe annotation guideline comprises the main part\nof the prompts used in this work. It is created by\nexperts and revised based on LLM outputs. The\nversion used in this work is as follows:\n|Start of annotation schema|\nThese classes are as follows:\n|Class begin|\nClass 1:\n|Title begin| Cognitive impairment |Title end|\n|Definition begin|\n(collect broadly, will not be specific to AD).\nCognitive impairment is when a person has\ntrouble remembering, learning,\nconcentrating, or making decisions that\naffect their everyday life.\nCurrently captured by patients subjective\nstatements as well as Dr. statements as\nfollows:\nForgetting appointments and dates.\nForgetting recent conversations and events.\nHaving a hard time understanding directions\nor instructions.\nLosing your sense of direction.\nLosing the ability to organize tasks.\nBecoming more impulsive.\nMemory loss.\nFrequently asking the same question or\nrepeating the same story over and over\n(perseveration)\nNot recognizing familiar people and places\nHaving trouble exercising judgment, such as\nknowing what to do in an emergency\nDifficulty planning and carrying out tasks,\nsuch as following a recipe or keeping\ntrack of monthly bills\nmeaningless repetition of own words, lack of\nrestraint, wandering and getting lost\nlose your train of thought or the thread of\nconversations\ntrouble finding your way around familiar\nenvironments\nproblems with speech or language\nfeel increasingly overwhelmed by making\ndecisions, planning steps to accomplish\na task or understanding instructions\nmental decline, difficulty thinking and\nunderstanding, confusion in the evening\nhours, delusion, disorientation, lack\nof orientation, forgetfulness, making\nthings up, mental confusion, difficulty\nconcentrating, inability to create new\nmemories, inability to do simple math,\nor inability to recognize common\nthings, poor judgment, impaired\ncommunication, poor concentration,\ndifficulty remembering recent\nconversations, names or events\nforget things more often, forget important\nevents such as appointments or social\nengagements, issues with recall,\nchanges in abstract reasoning ability\nattention, cognition, speech, orientation,\njudgment\nAD, dementia, MCI: capture diagnoses\nrelevant to this category.\nSTM: short term memory loss\n|Definition end|\n|Class end|\n|Class begin|\nClass 2:\n|Title begin| Notice/concern by others |Title\nend|\n|Definition begin|\nThese concerns are about cognition, mood or\ndaily activities, not from nurses or\ndoctors or medical care providers, but from\nfriends or family or neighbors.\nfamily complains of something (may be\nrelated to any class including\nphysiology)\nnoticed changes in ability, speed\nconcern expressed by family/friends\ncomplaints of pt. easily angered\nsome examples:\nDaughter reports that she repeatedly asks\nthe same question...had difficulties\nusing her smartphone.\nDaughter reports that she has issues with\nbanking...some decrease in personal\nhygiene, forgets to take meds, forgets\nwhere food is in the house, etc.\nPt. has gone out at 1:30 a.m. without\ntelling anyone; they are concerned, but\npt. always has a response.\nShe (daughter) tells me that her mom has\nrepeatedly changed the medications in\nthe pill boxes that she has arranged\nfor her.\n|Definition end|\n|Class end|\n|Class begin|\nClass 3:\n|Title begin| Requires assistance |Title end|\n|Definition begin|\ndefined as Requires assistance from a person\nneeds help with or loss of ability with\nADLs/iADLs, difficulty with self-care,\ntrouble managing belongings\nADLs: dressing, eating, toileting, bathing,\ngrooming, mobility\niADLs: housekeepingrelated activities\n(cleaning, cooking, and laundry) and\ncomplex activities (telephone use,\nmedication intake, use of\ntransportation/driving, budget/finance\nmanagement, and shopping)\nsome examples:\nThe patient will continue to require\nassistance with all complex medical,\nlegal and financial decision making.\nShe will need 24-hour supervision for her\nsafety.\nDirect supervision is required for\nmedications using a pillbox.\nBest not to have him use stove.\nIf left alone for period of time, will need\nguardian alert or consider camera\nsurveillance.\nHe is able to make a meal, to dress himself,\nto bathe, to shave, but continues to\nneed help with finances.\n7140\nWife has to remind him about appointments,\nin particular.\nDriving should not be permitted, and he will\nneed assistance with IADLs and decision\nmaking.\nVeteran does need assistance with all IADLs\nand most ADLs.\nTraveling out of neighborhood, driving,\narranging to take buses-limited night\ndriving now\nResides in assisted living facility or\nnursing home\nWriting checks, paying bills, balancing\ncheckbook-minimal (automatic payment)\nN/A\nPlaying a game of skill-no hobbies N/A\n|Definition end|\n|Class end|\n|Class begin|\nClass 4:\n|Title begin| Physiological changes |Title end|\n|Definition begin|\nsenses: vision, hearing, smell loss, SNHL:\nsensorineural hearing loss, HoH\nsleep: Excessive daytime sleepiness, changes\nin sleep patterns\nspeech/swallowing (speech difficulties also\nin \"Cognitive Impairment\" class)\nmovement/gait/balance\ninability to combine muscle movements:\njumbled speech, difficulty speaking,\naphasia, dysphasia, difficulty\nswallowing, dysphagia, difficulty\nwalking, mobility, problems with gait\nand balance, gait slowing\nBrain (and blood vessel-associated)\nabnormalities\nstroke, ischemia, blood vessel\nocclusion/stenosis, infarct,\nencephalomalacia, small vessel changes,\nvascular/microvascular changes (in\nbrain), carotid artery\nocclusion/disease/atherosclerosis\nloss of appetite, loneliness, general\ndiscontent, TBI, skull fracture\n|Definition end|\n|Class end|\n|Class begin|\nClass 5:\n|Title begin| Cognitive assessment |Title end|\n|Definition begin|\nmemory tests, scores irrelevant; mark all\npresent\nBlessed Orientation Memory and Concentration\n(BOMC) test: 0-10 out of 28 is normal\nto minimally impaired; 11-19 is mild to\nmoderate impairment || VAMC BOMC\nScoring: score >10 is consistent with\nthe presence of dementia, score < 7 are\nconsidered normal for the elderly\nBNT: Boston Naming Test\nBVMT-R: Brief Visuospatial Memory Test\nCERAD-NAB: Consortium to Establish a\nRegistry for Alzheimer's\nDisease-Neuropathological Assessment\nBattery\nClock in a Box\nCNS VS: Computerized Neurocognitive\nAssessment Software Vital Signs\nCOWAT: Controlled Oral Word Association Test\nCVLT: California Verbal Learning Test\nDRS: Dementia Rating Scale, Mattis Dementia\nRating Scale\nD-KEFS: Delis-Kaplan Executive Function\nSystem\nFAS: a test measuring phonemic word fluency\n(using words starting with letters F,\nA, S)\nHVLT-R: Hopkins Verbal Learning Test-Revised\nHVOT: Hooper Visual Organization Test\nMini Mental State Exam (MMSE; also known as\nFolstein Test): >=24 and <28 out of 30\n(maybe MCI) no CPT code || VAMC MMSE\nGuidelines: 25-30 normal, 21-24 mild\ndementia, 13-20 moderate dementia, 0-12\nsevere dementia || Dr. Peter Morin's\nscoring: 30 normal, 28-29 MCI, 22-27\nmild dementia, 14-21 moderate dementia,\n0-13 severe dementia\nMontreal Cognitive Assessment (MoCA): >=17\nand <26 out of 30 (MCI) free, there is\nalso a Blind MoCA with total score of\n21, not 30. || VAMC MoCA Scoring: 26-30\nnormal, 20-25 suggestive of mild\nimpairment, 15-19 suggestive of\nmoderate impairment, 10-14 suggestive\nof significant impairment, 0-9\nsuggestive of severe impairment || Dr.\nPeter Morin's scoring: 30 normal, 23-26\nMCI, 18-22 mild dementia, 10-17\nmoderate dementia, 0-9 severe dementia\nNAB: Neuropsychological Assessment Battery\nNBSE: Neurobehavioral status exam (clinical\nassessment of thinking, reasoning and\njudgment, e.g., acquired knowledge,\nattention, language, memory, planning\nand problem solving, and visual spatial\nabilities)\nNCSE (Cognistat): Neurobehavioral Cognitive\nStatus Exam\nNPT/Neuropsych test/neuropsych inventory\nPASAT: Paced Auditory Serial Addition Test\nProverb interpretation (test of abstract\nreasoning; part of MMSE)\nRBANS: Repeatable Battery for Assessment of\nNeuropsychological Status\nRCFT: Rey Complex Figure Test (sometimes\nROCFT)\nRFFT: Ruff Figural Fluency Test\nRMT: (Warrington) Recognition Memory Test\nSaint Louis University Mental Status\nExamination (SLUMS): 21-26 out of 30\n(MCI) free || VAMC SLUMS Scoring: high\nschool education 27-30 normal, 21-26\nmild neurocognitive disorder, 1-20\ndementia; less than high school\neducation 25-30 normal, 20-24 mild\nneurocognitive disorder, 1-19 dementia\nSDMT: Symbol Digit Modalities Test a measure\nof processing speed, concept formation\nSerial sevens (part of MMSE)\nSILS: Shipley Institute of Living Scale\nSpelling a word forward and backward (part\nof MMSE)\nTOMM: Test of Memory Malingering\nTrail Making Test\nUFOV: Useful Field of View test\n7141\nVF: Verbal Fluency (test)\nWAIS: Wechsler Adult Intelligence Scale\nWCST: Wisconsin Card Sorting Test\nWTAR: Wechsler Test of Adult Reading\n|Definition end|\n|Class end|\n|Class begin|\nClass 6:\n|Title begin| Cognitive intervention/therapy\n|Title end|\n|Definition begin|\nThis includes mentions of drugs, doesn't\nrequire pt to actually start drug or adhere\nto taking drug\nAricept being taken\noccupational therapy, cognitive linguistic\ntherapy, cognitive behavioral therapy\nmemory group therapy\ninformed pt. of memory group and she had\npossible interest in this\nSmartThink: (regional VA offering) large\ngroup available to any Veteran who\nwould like to improve memory,\nattention, or other cognitive function.\nDementia-related medications, any\ninterventions initiated by provider\ne.g., medications, therapies.\nrelevant meds: cholinesterase inhibitors\n(general term), Aducanumab/Aduhelm,\nMemantine/Namenda/Namzaric, Razadyne\n(galantamine), Exelon (rivastigmine),\nAricept (donepezil)\nPimavanserin (for\nbehavior/agitation/psychosis\nexperimental)\nflickering light therapy\nvitamin B12/cyanocobalamin\nvitamin B1/thiamine\nvitamin D/cholecalciferol (in context of\nmemory issues only)\n|Definition end|\n|Class end|\n|Class begin|\nClass 7:\n|Title begin| Diagnostic tests of the head or\nbrain that are related to neurocognitive\nsymptoms. |Title end|\n|Definition begin|\nincluding CT, EEG, EMG, FDG-PET, MRI, PET,\nPET-CT, MRA, CSF\nMRA=Magnetic resonance angiography\nradiology study (context: header\nneuroimaging)\nimaging (referring to MRI or PET imaging)\nNOT capturing diagnostic test results in\nseparate sentences from the test name\nNOT capturing imaging header if specific\ninfo (MRI) follows\nInclude distant MRI (e.g., from childhood);\nconcussion/head trauma may be relevant\nto CTE\ngenetic testing: APOE4 for sporadic AD,\nmutations in APP, PSEN1 (PS1 protein), PSEN2\nlinked to early onset AD\nNote MRI in context of spine or joints or EMG\nin context of carpal tunnel syndrome should\nnot be considered.\n|Definition end|\n|Class end|\n|Class begin|\nClass 8:\n|Title begin| Coping strategy |Title end|\n|Definition begin|\nrepetition and written reminders may be a\nuseful tool in therapy\nhas been encouraged to keep mentally active\nto slow the rate of cognitive decline\nrequires shopping list when going for\ngroceries otherwise she will forget\nitems\nuses a planner for appointments\nreliant on GPS for driving\nmemory exercise\nkeep mentally active\nuses medication organizer\n|Definition end|\n|Class end|\n|Class begin|\nClass 9:\n|Title begin| Neuropsychiatric symptoms |Title\nend|\n|Definition begin|\nmood changes: depression, irritability,\naggression, anxiety, apathy,\npersonality changes, behavioral\nchanges, agitation\nFeeling increasingly overwhelmed by making\ndecisions and plans.\nparanoia, delusions, hallucinations\n|Definition end|\n|Class end|\n|End of annotation schema|\nB Prompts\nWe used 3 prompts in this work.\n1. Prompt 1 is to ask LLM to annotate provided\ntext following the above guidelines.\nTask: Annotate the text based on the\nprovided annotation guideline.\n|Start of text|\n[text here]\n|End of text|\n|Start of annotation guideline|\n[annotation guideline here]\n|End of annotation guideline|\nFormat output as a valid json with the\nfollowing structure:\n[\n{\n\"sentence\":str,\\\\ The sentence that is\nannotated.\n\"class\":int \\\\ The class that the\nsentence belongs to.\n}\n]\n7142\n2. Prompt 2 is to ask LLM to check the annota-\ntion results and explain the reasons for making\njudgements.\nTask: Check if the annotations of the text\nbased on the provided annotation\nguideline are correct or not and\nexplain why.\n|Start of text|\n[text here]\n|End of text|\n|Start of annotation guideline|\n[annotation guideline here]\n|End of annotation guideline|\n|Start of annotation|\n[annotation here]\n|End of annotation|\nFormat output as a valid json with the\nfollowing structure:\n[\n{\n\"sentence\":str,\\\\ The sentence that is\nannotated\n\"class\":int, \\\\ The class that the\nsentence belongs to.\n\"decision\":bool, \\\\ Whether the\nannotation is correct or not.\n\"reason\":str \\\\ Explain why.\n}\n]\n3. Prompt 3 is to ask LLM to generate a note and\nconduct annotations based on the provided\nguideline.\nTask: Generate a clinical note and\nannotate the text based on the\nprovided annotation guideline.\n|Start of text|\n[text here]\n|End of text|\n|Start of annotation guideline|\n[annotation guideline here]\n|End of annotation guideline|\nFormat annotation output as a valid\njson with the following structure:\n[\n{\n\"sentence\":str,\\\\ The sentence that is\nannotated.\n\"class\":int \\\\ The class that the\nsentence belongs to.\n}\n]\nThese prompts are for reference and are slightly\nmodified to adapt to each LLM for format control\nin practice.\nC Negative Data Generation\nThe negative data is sampled from the notes anno-\ntated by experts. It consists of data that are not an-\nnotated as having any AD-related symptoms. Also\nsentences that are too short (<5 tokens after re-\nmoving punctuation and stop words) are removed.\nTables/forms/questionnaires are excluded. The ra-\ntio of negative:positive data is decided based on\nstatistics from VHA data.\nD Model Training\nThe system contains 3 base models. All models\nare PLMs that are fine tuned on the training data.\nThe models are implemented using Transformers 3.\nThe training parameters are:\nepoch=10.\noptimizer=Adam.\nlr=1e-3.\nbeats=(0.9, 0.999).\neps=1e-6.\nwarmup_steps=200.\nweight_decay=0.01.\n3https://huggingface.co/docs/transformers/index\n7143"
}