{
    "title": "Ranking LLM-Generated Loop Invariants for Program Verification",
    "url": "https://openalex.org/W4389520453",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2152902633",
            "name": "Saikat Chakraborty",
            "affiliations": [
                "Microsoft Research (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A4271745676",
            "name": "Shuvendu Lahiri",
            "affiliations": [
                "Microsoft Research (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A2796307633",
            "name": "Sarah Fakhoury",
            "affiliations": [
                "Microsoft Research (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A2123176980",
            "name": "Akash Lal",
            "affiliations": [
                "Microsoft Research (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A2306824899",
            "name": "Madanlal Musuvathi",
            "affiliations": [
                "Microsoft Research (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A1965378997",
            "name": "Aseem Rastogi",
            "affiliations": [
                "Microsoft Research (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A4366451183",
            "name": "Aditya Senthilnathan",
            "affiliations": [
                "Microsoft Research (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A2102821039",
            "name": "Rahul Sharma",
            "affiliations": [
                "Microsoft Research (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A2129316828",
            "name": "Nikhil Swamy",
            "affiliations": [
                "Microsoft Research (United Kingdom)"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2843529596",
        "https://openalex.org/W2987907651",
        "https://openalex.org/W3019119050",
        "https://openalex.org/W4242057943",
        "https://openalex.org/W2130427425",
        "https://openalex.org/W2185676247",
        "https://openalex.org/W2094878426",
        "https://openalex.org/W3177813494",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W4288102827",
        "https://openalex.org/W2043100293",
        "https://openalex.org/W2247845964",
        "https://openalex.org/W1970168990",
        "https://openalex.org/W4212792638",
        "https://openalex.org/W1563374593",
        "https://openalex.org/W1497571013",
        "https://openalex.org/W1510368738",
        "https://openalex.org/W1877129949",
        "https://openalex.org/W4224308101",
        "https://openalex.org/W1498946538",
        "https://openalex.org/W3099700870",
        "https://openalex.org/W4226278401",
        "https://openalex.org/W2416392025",
        "https://openalex.org/W2797067769",
        "https://openalex.org/W1540815577",
        "https://openalex.org/W3100198463",
        "https://openalex.org/W4281557260",
        "https://openalex.org/W2151643528",
        "https://openalex.org/W2767382859"
    ],
    "abstract": "Saikat Chakraborty, Shuvendu Lahiri, Sarah Fakhoury, Akash Lal, Madanlal Musuvathi, Aseem Rastogi, Aditya Senthilnathan, Rahul Sharma, Nikhil Swamy. Findings of the Association for Computational Linguistics: EMNLP 2023. 2023.",
    "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 9164–9175\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nRanking LLM-Generated Loop Invariants for Program Verification\nSaikat Chakraborty, Shuvendu K. Lahiri, Sarah Fakhoury, Madanlal Musuvathi,\nAkash Lal, Aseem Rastogi, Aditya Senthilnathan, Rahul Sharma, Nikhil Swamy\nMicrosoft Research\n{saikatc, shuvendu, sfakhoury, madanm, akashl, aseemr,\nt-adityas, rahsha, nswamy}@microsoft.com\nAbstract\nSynthesizing inductive loop invariants is fun-\ndamental to automating program verification.\nIn this work, we observe that Large Language\nModels (such as gpt-3.5 or gpt-4) are capa-\nble of synthesizing loop invariants for a class of\nprograms in a 0-shot setting, yet require several\nsamples to generate the correct invariants. This\ncan lead to a large number of calls to a program\nverifier to establish an invariant. To address this\nissue, we propose a re-ranking approach for the\ngenerated results of LLMs. We have designed\na ranker that can distinguish between correct in-\nductive invariants and incorrect attempts based\non the problem definition. The ranker is op-\ntimized as a contrastive ranker. Experimental\nresults demonstrate that this re-ranking mecha-\nnism significantly improves the ranking of cor-\nrect invariants among the generated candidates,\nleading to a notable reduction in the number of\ncalls to a verifier.\n1 Introduction\nProgram verification is a crucial step toward build-\ning trustworthy software. Unfortunately, the prob-\nlem of verifying properties of programs contain-\ning loops is undecidable. Verifying properties of\nprograms containing loops boils down to inferring\nloop invariants, which are facts that hold for any\niteration of the loop, and also ensure the desired\nproperty. There is a rich body of prior work on syn-\nthesizing loop invariants for program verification\nthrough symbolic techniques (Cousot and Cousot,\n1977; Colón et al., 2003; Graf and Saïdi, 1997;\nMcMillan, 2003), and their use in verifying safety\nproperties of real-world programs (Ball et al., 2001;\nBlanchet et al., 2003; Lahiri et al., 2009). More re-\ncently, there is a growing interest in the application\nof machine learning towards invariant synthesis\n(Garg et al., 2016; Padhi et al., 2016; Yao et al.,\n2020; Si et al., 2018).\nIn recent years, Large Language Models\n(LLMs) (Radford et al., 2018) have emerged as\nfoundational AI models that have revolutionized\nLanguage Processing applications. Though LLMs\nwere originally proposed for natural languages,\nthey have exhibited great success in formal lan-\nguages such as programming languages (Chen\net al., 2021). In fact, with the increased size, mod-\nels have started to exhibit emergent properties. For\nexample, modern LLMs such as gpt-3.5 (Ouyang\net al., 2022), gpt-4 (OpenAI, 2023), PaLM (Chowd-\nhery et al., 2022) are capable of reasoning about a\ngiven task with few-shot (Brown et al., 2020), or\neven zero-shot prompting (Kojima et al., 2022).\nSuch an impressive footprint of LLM naturally\nraises the question: How well can LLMs automati-\ncally synthesize inductive loop invariants?\nTo this end, we employ two different state-of-the-\nart LLMs for synthesizing loop invariants. We ob-\nserve that these models can generate well-formed\ninvariants, but finding the correct one often re-\nquires a large number of samples. A solution\nbased on guess and check, with the aid of an au-\ntomated program verifier based on Z3 (De Moura\nand Bjørner, 2008), can be computationally very\nexpensive due to several invocations on incorrect\ninvariants. To minimize such costs, we propose\nreranking the generated invariants based on their\nlikelihood of successful verification. Inspired by\nthe use of contrastive learning in information re-\ntrieval (Karpukhin et al., 2020), our approach,\ncalled iRank, transforms the problem and invariants\nto bring the correct solution closer in vector space\nwhile pushing away incorrect ones. Empirical re-\nsults show that such re-ranking moves the median\nrank of the verified invariant to 4 in contrast to the\nexpected median rank of 31 for the generations\nfrom gpt-3.5.\nIn summary, in this paper, we propose to rerank\nthe LLM-generated loop invariants to reduce the\ncost of wasted verification effort. We have de-\nsigned a ranker to contrast correct and incorrect\ninvariants and show a significant reduction in the\n1\n9164\ninvariant checking effort compared to raw LLM\ngenerations.\n2 Related Work\nPrior works on loop invariant generation can be\nbroadly grouped into symbolic or machine learn-\ning based. Symbolic approaches either construct\ninvariants that are correct by construction (Cousot\nand Cousot, 1977; Colón et al., 2003), or leverage\nSatisfiability-Modulo-Theories (SMT) solvers such\nas Z3 (De Moura and Bjørner, 2008) to enumer-\nate and check candidate invariants over a space\nof pre-defined predicates (Flanagan and Leino,\n2001; Flanagan and Qadeer, 2002; Lahiri and\nBryant, 2007; Gulwani et al., 2009; Fedyukovich\nand Bodík, 2018) or predicates constructed through\nvariants of Craig’s interpolants (McMillan, 2003;\nHenzinger et al., 2004; Dillig et al., 2013). On\nthe other hand, recent techniques leverage machine\nlearning to synthesize candidate invariants that are\nchecked for correctness using an SMT-based pro-\ngram verifier. Techniques range from incorporating\nthe feedback from a verifier using active learning\nover decision trees (Garg et al., 2016), learning\nfrom counter examples (Sharma and Aiken, 2016;\nPadhi et al., 2016), reinforcement learning over\ngraph neural networks (Si et al., 2018) and the\nuse of continuous logic networks (Yao et al., 2020;\nRyan et al., 2020). Unlike these techniques, our ap-\nproach leverages an LLM for generation and ranks\nusing a purely neural model and does not require\na program verifier at the inference time. This is\nimportant for scenarios where the verifier is semi-\nautomated, as is the case of most real-world pro-\ngram verification tools such as Dafny (Leino, 2010)\nand F* (Swamy et al., 2011). Finally, Pei et al.\n(2023) predict program invariants using LLMs, but\nthey do not aim at generating inductive invariants\nthat are sufficient for formal program verification.\n3 Background & Motivation\n3.1 Background: Loop Invariant Inference\nIn this section, we recall the problem of loop in-\nvariant generation in program verification. First,\nlet us define a grammar for program statements S,\nintegral expressions aand Boolean expressions b,\noperating on scalar variables. Most statements and\nexpressions are self-explanatory.\nS ::= x:= a|skip |S; S |if bthen Selse S\na ::= n|x|a+ a|a−a|a∗a|...\nb ::= true |false |a= a|a<a |b∧b|b∨b|¬b\nIn its simplest form, the goal of program verifica-\ntion is to verify that a program fragment satisfies its\nspecifications denoted by the Hoare-triple (Hoare,\n1969) - {pre}while bdo S {post}. Given a pro-\ngram pand a pair of Boolean expressions (denoted\nby bin the grammar) ϕand ψdenoting the precon-\ndition and postcondition of a program p, the Hoare-\ntriple {ϕ}p {ψ}denotes that every terminating\nexecution of pthat starts in an pre-state satisfying\nthe predicate ϕends up in a post-state that satisfies\nthe predicate ψ. Since loops can execute an un-\nbounded number of iterations, verifying programs\nwith a loop requires a loop invariant ithat satisfies\nthe following conditions:\n{pre}skip {i}\n{i∧b}S{i}\n{i∧¬b}skip {post}\n(1)\nThe conditions respectively denote that the loop\ninvariant iholds on loop-entry, is preserved by an\narbitrary iteration of the loop and implies the post\ncondition on exit. The problem of loop invariant\ninference is to infer an i that satisfies the three\nchecks above, and denoted as i⊢p.\nFurthermore, for the loop-free statements S in\nthe grammar above, checking the Hoare-triple\n{ψ}S {ϕ}can be reduced to (decidable) logi-\ncal formulas in the Satisfiability-Modulo-Theories\n(SMT) using standard techniques in program ver-\nification (Leino, 2010). One can use a predicate\ntransformer called weakest precondition WP to con-\nvert the Hoare-triple to a decidable SMT formula\nthat can be checked by Z3.\nψ =⇒ WP(S,ϕ)\n{ψ}S{ϕ}\nThe WP is defined inductively on the structure\nof statements as follows:\nWP(x:= a,ϕ) .= ϕ[a/x]\nWP(skip,ϕ) .= ϕ\nWP(S1; S2,ϕ) .= WP(S1,WP(S2,ϕ))\nWP(if bthen S1 else S2,ϕ) .= ⋀ (b =⇒ WP(S1,ϕ))\n(¬b =⇒ WP(S2,ϕ))\n3.2 Motivation and Problem Formulations\nGiven a problem definition pthat consists of pre-\nconditions pre, a loop while bdo S, and postcon-\nditions post, we can query LLMs to generate an\ninvariant i that satisfies the conditions specified\nin Equation (1). Although we have observed that\n2\n9165\niRank during Training\nProblem\nVerified InvariantVerified InvariantVerified Invariant\nWrong InvariantWrong InvariantWrong Invariant\nInitial Embedding\n(wrong invariants) Increase  Distance\nDecrease  Distance\nEmbedding\nModel\nInitial Embedding\n(problem definition)\nTransformed Embedding\n(used for ranking)\nEmbedding\nTransformation\n(3-layer fully\nconnected ANN)\nAnnotated example from training dataVerified InvariantVerified InvariantVerified Invariant\nInitial Embedding\n(correct invariants)\nInitial Embeddings\nnor(<= n \n i  forall((j\nInt)) (=>\n(and ( ...\nand(< i n)\nkforall((j\nInt)) (=\n (and (...\nor(<= i n)\n(forall((\nj Int))(=>\n(and  ...\n=>(<= i n)\n((j Int)) \n(=> (and (\n...\n  \nInvariant Synth. Problem\n(define-fun pre_fun ...)\n(define-fun trans_fun ...)\n(define-fun post_fun ...)\nEmbedding\nModel\nCandidate Invariants Transformed Embeddings\n0.7\n0.8\n0.9\n0.5\n=>(<= i n)\n((j Int)) \n(=> (and (\n...\nnor(<= n \n i  forall((j\nInt)) (=>\n(and ( ...\nand(< i n)\nkforall((j\nInt)) (=\n (and (...\nor(<= i n)\n(forall((\nj Int))(=>\n(and  ...\nSimilarity (Dot Products)\n(problem emb. and candidate inv. emb.)\nRe-ranked Candidate\nInvatiants\niRank during Ranking\nFigure 1: LLM for Loop Invariant synthesis.\nLLMs are capable of producing loop invariants\nwithout syntax errors, they often require numerous\nsamples before generating a correct invariant (we\nrefer to Appendix B for a details). This results in in-\nefficient resource utilization during the verification\nprocess, particularly when dealing with complex\nproblem instances. More importantly, for a more\npractical scenario where generated invariants are\nused as part of an interactive verification system\nsuch as Dafny/F*, an incorrect invariant would take\nup valuable user time to perform a manual failed\nverification effort. Consequently, we propose the\nutilization of iRank to prioritize the generated in-\nvariants based on their likelihood of being correct.\nFigure 1 provides a high-level overview of the en-\nvisioned invariant generation-ranking system.\n4 iRank: Methodology\nThe main intuition behind iRank is learning to pull\nthe likely correct invariants to the front of a ranked\nlist. Figure 1 shows a high-level overview of the\nranker. We rely on a dataset, D= {(p,I+,I−)},\ncontaining Loop Invariant generation problem, p, a\nset of verified loop invariants, I+ = {i+ |i+ ⊢\np}, and a set of wrong loop invariant, I− =\n{i− | i− ⊬ p} for each of the problems, to\nbuild iRank. Our goal is to learn a function be-\ntween a problem definition pand invariant i, i.e.,\nσ(p,i), which should satisfy the following con-\nstraint ∀{i+,i−}(σ(p,i+) >σ(p,i−)).\nContrastive Ranking. To learn σ, we first ex-\ntract the embedding of problem definitions and the\ninvariants with an embedder, Φ, i.e., x = Φ( p),\nand y = Φ(i), where xand yare the embeddings\nof problem definition p, and invariant i, respec-\ntively. We learn a transformation function, Ψ(x|θ),\nwhich applies non-linear transformation on input\nvector xwith learnable parameter θ. We then trans-\nform problem embedding xto x′ = Ψ(x|θ), and\ntransform invariant embedding yto y′ = Ψ(y|θ).\nNow our target is to maximize the similarity be-\ntween x′ and y′, when y′ corresponds to a cor-\nrect invariant, minimize the similarity otherwise.\nWe use the absolute cosine similarity as the mea-\nsurement. Use of such allows us to set the max-\nimum similarity to 1 (in the case of correct in-\nvariant) and the minimum to 0 (in the case of\nwrong invariant). We optimize the mean squared\nerror loss to learn the parameters in Ψ. We ex-\nperimented with two different embedding models\nbased on LLMs, i.e.,text-embedding-ada-002\nand davinci-similarity. Appendix A presents\nfurther details of iRank’s working procedure.\n5 Experimental Design and Results\n5.1 Experimental Setup\nBenchmarks. We use Loop Invariant Synthesis\nbenchmarks assimilated by Padhi et al. (2016) 1\nconstituting a set 940 challenge problems in Sy-\n1https://github.com/SaswatPadhi/LoopInvGen/\ntree/master/benchmarks\n3\n9166\nGus (Alur et al., 2013) format, with a SMT for-\nmula for the pre-condition, post-condition, and the\ntransfer-function for the loop. We chose a SMT\nrepresentation for our problem description pto be\nagnostic to different encoding of C programs into\nlogic. Among these problems, 541 were in the\nscope of LLM due to the context window size. We\nset the maximum context size as 4096 (with 3584\nfor prompt, 512 for generation).\nGathering LLM-generated Invariants. We con-\nducted experiments involving two distinct language\nmodels: gpt-3.5-turbo and gpt-4. Our objec-\ntive was to assess the capabilities of these language\nmodels out-of-the-box, and thus we employed a\nzero-shot prompting approach. This involved pro-\nviding a problem description and an appropriate\ntask explanation as a prompt (refer to Appendix C\nfor an example). For each problem, we allowed\nboth the models to generate invariants for a maxi-\nmum duration of 10 minutes or until a verified in-\nvariant was found, whichever occurred first, result-\ning in solving 250 problems by gpt-3.5-turbo,\nand 188 problems for gpt-42. It is important to\nclarify that the purpose of this paper is not to con-\nduct a comparative analysis of these language mod-\nels in relation to this specific problem. Instead,\nour objective is to propose a method to orthogo-\nnally augment LLM capabilities by reranking LLM\ngenerated invariants.\nTraining Data. We create the training dataset for\niRank (D= {(p,I+,I−)}) by combining invari-\nants generated from different sources, such as dif-\nferent generations from LLMs, and invariants gen-\nerated by LoopInvGen (Padhi et al., 2017). We\ndivided the problems into five folds and trained 5\ndifferent rankers, one for each fold. During the\nevaluation, we select and load the trained model\nbased on the problem under evaluation. Detailed\nstatistics of data is available in Appendix A.3.\nEvaluation Metric. We then sequentially attempt\nto check invariants from a ranked list. We evaluate\nthree metrics – (i) i+ ranks - rank of the correct\ninvariant in the list, (ii) V@K - the percentage of\nproblems where the verified invariant is found in\ntop K invariants from the re-ranked list, and (iii)\nNumber of Z3 calls - the total number of z3 calls\nbefore finding and reporting a correct invariant, a\nhigher number of z3 calls indicate a high waste of\ncomputational resources.\n2Note that the rate limit for gpt-4 was an order lower than\ngpt-3.5 in our usage resulting in an order less samples.\nExperiment i+ ranks V@K (%)\nMean Median K=1 K=5 k=10\nLLM-ranks 189.78 62.00 5.2 11.6 18.4\nExpected ranks 95.35 31.02 8.0 19.2 25.2\nTF-IDF 103.45 24.00 17.6 32.0 38.8\nEmb. Ada 115.89 31.50 11.2 21.6 30.0\nDavinci 120.02 32.00 10.4 20.8 33.6\niRank Ada 38.78 5.00 28.0 51.2 60.8\nDavinci 34.48 4.00 29.2 52.8 62.8\n(a) Invariants generated by gpt-3.5-turbo .\nExperiment i+ ranks V@K (%)\nMean Median K=1 K=5 k=10\nLLM-ranks 39.20 9.00 17.6 40.4 51.6\nExpected ranks 20.23 4.96 31.9 52.1 65.4\nTF-IDF 24.16 3.00 32.00 45.6 53.6\nEmb. Ada 20.69 5.50 26.6 51.1 64.9\nDavinci 23.56 5.00 27.7 52.1 63.3\niRank Ada 13.18 2.00 44.7 74.4 81.4\nDavinci 11.96 2.00 44.7 71.8 81.9\n(b) Invariants generated by gpt-4 .\nTable 1: Comparison between different ranking strategies for\nre-ranking the invariants generated by different LLMs.\nBaselines. (a) LLM-ranks. We take the invariants,\nin the order generated by the LLMs, as a ranklist.\n(b) Expected-ranks. We estimate the expected val-\nues of the evaluated metrics in this paper by ran-\ndomly permuting the LLM-generated list of invari-\nants (see Appendix D for more details). (c) Em-\nbeddings. We use the raw embeddings from LLM-\nbased embedding models to calculate similarity\nwithout training. (d) TF-IDF .We use the textual\nsimilarity between the problem description and the\ncandidate invariants for ranking.\nResearch Questions. In this paper, we studied\ntwo research questions. (i) How effective are LLM-\nbased embeddings for ranking invariants? and (ii)\nCan a trained iRank help reduce the verification\ncost?\n5.2 Results\nTable 1 shows the quantitative evaluation ofiRank.\nIf we consider LLM-generated list of invariants as\nis, we observe that LLMs are able to generate a ver-\nified invariant after a significant number of wasted\ntrials. For example, on average, gpt-3.5-turbo\nfound an invariant after ∼190 failed attempt at\ngeneration. gpt-4 does much better, in compar-\nison, with the mean rank of verified invariants be-\ning 39.20. The expected rank of the verified in-\nvariant from LLM-generations is 95.35 and 20.23,\nfor gpt-3.5-turbo and gpt-4, respectively. The\nuse of LLM-based embeddings (without any train-\n4\n9167\nLLM Ranks\nExpected Ranks\nTF-IDF\nDavinci emb.\nAda emb.\niRank-Ada\niRank-Davinci\nExperiments\n0\n100\n200\n300\n400\n500Rank of the verified invariant\nRank\nLLM Ranks\nExpected Ranks\nTF-IDF\nDavinci emb.\nAda emb.\niRank-Ada\niRank-Davinci\nExperiments\n0\n200\n400\n600\n800\n1000\n1200Number of Z3 calls # Z3 calls\n(a) gpt-3.5-turbo.\nLLM Ranks\nExpected Ranks\nTF-IDF\nDavinci emb.\nAda emb.\niRank-Ada\niRank-Davinci\nExperiments\n0\n20\n40\n60\n80Rank of the verified invariant\nRank\nLLM Ranks\nExpected Ranks\nTF-IDF\nDavinci emb.\nAda emb.\niRank-Ada\niRank-Davinci\nExperiments\n0\n50\n100\n150\n200Number of Z3 calls # Z3 calls\n(b) gpt-4.\nFigure 2: Detailed results comparing ranks of the correct invariants and number of z3 calls.\n0 10 20 30 40 50\nT op k Invariants Tried\n20\n40\n60\n80Percentage of Problems Verified\nLLM Ranks\nExpected Ranks\nTF-IDF\nDavinci emb.\nAda emb.\niRank-Ada\niRank-Davinci\n(a) gpt-3.5-turbo\n0 10 20 30 40 50\nT op k Invariants Tried\n20\n40\n60\n80\n100Percentage of Problems Verified\nLLM Ranks\nExpected Ranks\nTF-IDF\nDavinci emb.\nAda emb.\niRank-Ada\niRank-Davinci (b) gpt-4\nFigure 3: Percentage of problems solved w.r.t. number of\ninvariants from the (re-)ranked list.\ning) such as from text-embedding-ada-002 or\ndavinci-similarity results is the mean rank of\nthe verified invariant to be 115.89 and 120.02,\nrespectively for gpt-3.5-turbo, and 20.69 and\n23.56, respectively for gpt-4. While such a result\nlooks like a significant improvement over LLM-\nranks, it is slightly worse than expected ranks.\n✓ LLM-based embeddings standalone may not\nserve well for reranking verified invariants.\nThe training procedure in iRank significantly\ncontributes to improving the ranking of verified\ninvariants by transforming the embeddings. The\nmedian rank of the verified invariant is 32 when\nusing the embedding from davinci-similarity\nembeddings. With the contrastive training in\niRank, the median rank is brought down to 4,\nshowing a significant improvement. Such a trend\npersists across different embedding models and\ngenerations from different LLMs. Figure 2a,\nand Figure 2b shows the detailed results invari-\nants generated by gpt-3.5-turbo and gpt-4.\nIn both trained and raw embeddings, the dif-\nference between text-embedding-ada-002 and\ndavinci-similarity models, the performance\ndifferences are not different with statistical sig-\nnificance (with p-value > 0.1). In both models’\ncases, there is no statistically significant difference\nbetween the expected rank and raw embedding-\nbased ranking. Note that, similar to the existing\nworks (Ryan et al., 2020), we use z3 call to mea-\nsure resource wastage. However, depending on the\nsystem the experiments are carried on, the time\nsaved from reranking with iRank could be different.\nWe report our experimental results of wall clock\ntime in Appendix B (Table 2).\nFigure 3 shows the percentage of problems veri-\nfied after trying k invariants (V@K). We observe\nthat the iRank curves are very steep at the begin-\nning of the curves compared to the baseline, sig-\nnifying that it could rank the verified invariants in\nsignificantly higher positions than baselines.\n✓ Contrastive training in iRank brings the veri-\nfied invariant closer to the problem while pushing\nthe wrong ones resulting in a significant reduc-\ntion in the verification cost.\n6 Conclusion\nWe presented a novel approach, iRank, to rank the\nloop invariants generated by LLMs based on their\nlikelihood of being correct. Our ranker leverages\na contrastive learning technique to discriminate\nbetween correct and incorrect invariants. Our eval-\nuation demonstrates that our approach significantly\nreduces the invariant checking effort compared to\nthe original LLM outputs.\n5\n9168\nLimitations\nAssumptions of LLM inference cost. In this\npaper, we assumed the cost of calling LLMs is neg-\nligible compared to the cost of calling the verifier\nfor checking an invariant. Current access to LLMs\n(at least the one we studied in the paper) is avail-\nable through the rest API, which can be scaled up\nby the API vendor with distributed processing of\nLLM. However, with the increase in the problem\ncomplexity, i.e., non-linear invariants, high number\nof variables, the check for correctness of an invari-\nant become exponentially more expensive. In the\ncase where call to LLM is much more expensive\nthan LLM, iRank will reduce the number of Z3\ncalls, but may not contribute to actual cost savings.\nComparison with state-of-the-art (SOTA) invari-\nant synthesis. The goal of this paper is not to\nestablish SOTA for loop invariant synthesis. In con-\ntrast, we investigate LLMs’ capacity to generate\nLoop invariant relying on their emergent behav-\nior. iRank is proposed as an orthogonal tool and\nevaluated to rank LLM generations in this paper.\nHowever, in theory,iRank should be able to rerank\ninvariants generated by any generator. Neverthe-\nless, the design of the SOTA technique of Loop\nInvariant Synthesis with LLM (perhaps with other\ntools) remain an open problem, which we leave for\nfuture research.\nStability of LLM predictions. Due to the\nstochastic (and nondeterministic 3) nature of the\nLLM, especially in higher temp, we observe un-\nstable generation from the LLM. Nevertheless, we\nevaluated the results from one sample run from\ngpt-3.5-turbo and one from gpt-4 as case stud-\nies. While we acknowledge the possibility of un-\nstable behavior, similarity in the performance trend\n(i.e., iRank’s performance improvement over LLM\nand expected ranks, also over raw embeddings)\ngive us confidence about the impact of iRank.\nReferences\nRajeev Alur, Rastislav Bodik, Garvit Juniwal, Milo MK\nMartin, Mukund Raghothaman, Sanjit A Seshia,\nRishabh Singh, Armando Solar-Lezama, Emina Tor-\nlak, and Abhishek Udupa. 2013. Syntax-guided syn-\nthesis. IEEE.\n3https://platform.openai.com/docs/guides/gpt/\nwhy-are-model-outputs-inconsistent\nThomas Ball, Rupak Majumdar, Todd D. Millstein, and\nSriram K. Rajamani. 2001. Automatic predicate ab-\nstraction of C programs. In Proceedings of the 2001\nACM SIGPLAN Conference on Programming Lan-\nguage Design and Implementation (PLDI), Snowbird,\nUtah, USA, June 20-22, 2001, pages 203–213. ACM.\nBruno Blanchet, Patrick Cousot, Radhia Cousot, Jérome\nFeret, Laurent Mauborgne, Antoine Miné, David\nMonniaux, and Xavier Rival. 2003. A static analyzer\nfor large safety-critical software. In Proceedings of\nthe ACM SIGPLAN 2003 Conference on Program-\nming Language Design and Implementation, PLDI\n’03, page 196–207, New York, NY , USA. Association\nfor Computing Machinery.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-\nplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, et al. 2021. Evaluating large\nlanguage models trained on code. arXiv preprint\narXiv:2107.03374.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, et al. 2022. Palm: Scaling\nlanguage modeling with pathways. arXiv preprint\narXiv:2204.02311.\nMichael A. Colón, Sriram Sankaranarayanan, and\nHenny B. Sipma. 2003. Linear invariant generation\nusing non-linear constraint solving. In Computer\nAided Verification, pages 420–432, Berlin, Heidel-\nberg. Springer Berlin Heidelberg.\nPatrick Cousot and Radhia Cousot. 1977. Abstract inter-\npretation: A unified lattice model for static analysis\nof programs by construction or approximation of\nfixpoints. In Proceedings of the 4th ACM SIGACT-\nSIGPLAN Symposium on Principles of Programming\nLanguages, POPL ’77, page 238–252, New York,\nNY , USA. Association for Computing Machinery.\nLeonardo De Moura and Nikolaj Bjørner. 2008. Z3:\nAn efficient smt solver. In Tools and Algorithms for\nthe Construction and Analysis of Systems: 14th In-\nternational Conference, TACAS 2008, Held as Part\nof the Joint European Conferences on Theory and\nPractice of Software, ETAPS 2008, Budapest, Hun-\ngary, March 29-April 6, 2008. Proceedings 14, pages\n337–340. Springer.\nIsil Dillig, Thomas Dillig, Boyang Li, and Ken McMil-\nlan. 2013. Inductive invariant generation via abduc-\ntive inference. Acm Sigplan Notices , 48(10):443–\n456.\n6\n9169\nGrigory Fedyukovich and Rastislav Bodík. 2018. Accel-\nerating syntax-guided invariant synthesis. In Tools\nand Algorithms for the Construction and Analysis\nof Systems, pages 251–269, Cham. Springer Interna-\ntional Publishing.\nCormac Flanagan and K. Rustan M. Leino. 2001. Hou-\ndini, an annotation assistant for esc/java. In FME\n2001: Formal Methods for Increasing Software Pro-\nductivity, International Symposium of Formal Meth-\nods Europe, Berlin, Germany, March 12-16, 2001,\nProceedings, volume 2021 of Lecture Notes in Com-\nputer Science, pages 500–517. Springer.\nCormac Flanagan and Shaz Qadeer. 2002. Predicate\nabstraction for software verification. SIGPLAN Not.,\n37(1):191–202.\nPranav Garg, Daniel Neider, P. Madhusudan, and Dan\nRoth. 2016. Learning invariants using decision trees\nand implication counterexamples. In Proceedings\nof the 43rd Annual ACM SIGPLAN-SIGACT Sym-\nposium on Principles of Programming Languages,\nPOPL 2016, St. Petersburg, FL, USA, January 20 -\n22, 2016, pages 499–512. ACM.\nSusanne Graf and Hassen Saïdi. 1997. Construction of\nabstract state graphs with PVS. In Computer Aided\nVerification, 9th International Conference, CAV ’97,\nHaifa, Israel, June 22-25, 1997, Proceedings, volume\n1254 of Lecture Notes in Computer Science, pages\n72–83. Springer.\nSumit Gulwani, Saurabh Srivastava, and Ramarathnam\nVenkatesan. 2009. Constraint-based invariant in-\nference over predicate abstraction. In Verification,\nModel Checking, and Abstract Interpretation, pages\n120–135, Berlin, Heidelberg. Springer Berlin Heidel-\nberg.\nThomas A. Henzinger, Ranjit Jhala, Rupak Majumdar,\nand Kenneth L. McMillan. 2004. Abstractions from\nproofs. In Proceedings of the 31st ACM SIGPLAN-\nSIGACT Symposium on Principles of Programming\nLanguages, POPL 2004, Venice, Italy, January 14-16,\n2004, pages 232–244. ACM.\nCharles Antony Richard Hoare. 1969. An axiomatic\nbasis for computer programming. Communications\nof the ACM, 12(10):576–580.\nVladimir Karpukhin, Barlas O˘guz, Sewon Min, Patrick\nLewis, Ledell Wu, Sergey Edunov, Danqi Chen, and\nWen-tau Yih. 2020. Dense passage retrieval for\nopen-domain question answering. arXiv preprint\narXiv:2004.04906.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. arXiv preprint\narXiv:2205.11916.\nShuvendu K. Lahiri and Randal E. Bryant. 2007. Predi-\ncate abstraction with indexed predicates. ACM Trans.\nComput. Logic, 9(1):4–es.\nShuvendu K. Lahiri, Shaz Qadeer, Juan P. Galeotti,\nJan W. V oung, and Thomas Wies. 2009. Intra-module\ninference. In Computer Aided Verification, 21st Inter-\nnational Conference, CAV 2009, Grenoble, France,\nJune 26 - July 2, 2009. Proceedings, volume 5643 of\nLecture Notes in Computer Science, pages 493–508.\nSpringer.\nK Rustan M Leino. 2010. Dafny: An automatic pro-\ngram verifier for functional correctness. In Logic\nfor Programming, Artificial Intelligence, and Reason-\ning: 16th International Conference, LPAR-16, Dakar,\nSenegal, April 25–May 1, 2010, Revised Selected\nPapers 16, pages 348–370. Springer.\nShang-Wei Lin, Jun Sun, Hao Xiao, Yang Liu, David\nSanán, and Henri Hansen. 2017. Fib: Squeez-\ning loop invariants by interpolation between for-\nward/backward predicate transformers. In 2017 32nd\nIEEE/ACM International Conference on Automated\nSoftware Engineering (ASE), pages 793–803. IEEE.\nKenneth L. McMillan. 2003. Interpolation and sat-\nbased model checking. In Computer Aided Verifi-\ncation, 15th International Conference, CAV 2003,\nBoulder, CO, USA, July 8-12, 2003, Proceedings ,\nvolume 2725 of Lecture Notes in Computer Science,\npages 1–13. Springer.\nOpenAI. 2023. Gpt-4 technical report.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow instruc-\ntions with human feedback. Advances in Neural\nInformation Processing Systems, 35:27730–27744.\nSaswat Padhi, Rahul Sharma, and Todd Millstein.\n2017. Loopinvgen: A loop invariant generator\nbased on precondition inference. arXiv preprint\narXiv:1707.02029.\nSaswat Padhi, Rahul Sharma, and Todd D. Millstein.\n2016. Data-driven precondition inference with\nlearned features. In Proceedings of the 37th ACM\nSIGPLAN Conference on Programming Language\nDesign and Implementation, PLDI 2016, Santa Bar-\nbara, CA, USA, June 13-17, 2016, pages 42–56.\nKexin Pei, David Bieber, Kensen Shi, Charles Sutton,\nand Pengcheng Yin. 2023. Can large language mod-\nels reason about program invariants?\nAlec Radford, Karthik Narasimhan, Tim Salimans, Ilya\nSutskever, et al. 2018. Improving language under-\nstanding by generative pre-training.\nGabriel Ryan, Justin Wong, Jianan Yao, Ronghui Gu,\nand Suman Jana. 2020. Cln2inv: Learning loop in-\nvariants with continuous logic networks. In Interna-\ntional Conference on Learning Representations.\nRahul Sharma and Alex Aiken. 2016. From invariant\nchecking to invariant inference using randomized\nsearch. Formal Methods in System Design, 48:235–\n256.\n7\n9170\nExperiment i+ ranks V@K (%) Time(s) (Mean/Median)\nMean Median K=1 K=5 k=10 Embed Ranking Verification Total\nLLM-ranks 189.78 62.00 5.2 11.6 18.4 0 / 0 0 / 0 7.33 / 2.23 7.33 / 2.23\nExpected ranks 95.35 31.02 8.0 19.2 25.2 0 / 0 0 / 0 3.67 / 1.12 3.67 / 1.12\nTF-IDF 103.45 24.00 17.6 32.0 38.8 0 / 0 0.05 / 0.02 3.83 / 0.94 3.88 / 1.00\nEmb. Ada 115.89 31.50 11.2 21.6 30.0 1.29 / 0.42 0.05 / 0.01 4.43 / 1.23 5.78 / 1.82\nDavinci 120.02 32.00 10.4 20.8 33.6 9.17 / 3.02 0.45 / 0.15 4.79 / 1.20 14.41 / 4.48\niRank Ada 38.78 5.00 28.0 51.2 60.8 1.29 / 0.42 0.06 / 0.02 1.64 / 0.19 2.98 / 0.97\nDavinci 34.48 4.00 29.2 52.8 62.8 9.17 / 3.02 0.48 / 0.15 1.28 / 0.16 10.93 / 3.68\n(a) Invariants generated by gpt-3.5-turbo .\nExperiment i+ ranks V@K (%) Time(s) (Mean/Median)\nMean Median K=1 K=5 k=10 Embed Ranking Verification Total\nLLM-ranks 39.20 9.00 17.6 40.4 51.6 0 / 0 0 / 0 1.61 / 0.24 1.61 / 0.24\nExpected ranks 20.23 4.96 31.9 52.1 65.4 0 / 0 0 / 0 0.83 / 0.19 0.83 / 0.19\nTF-IDF 24.16 3.00 32.00 45.6 53.6 0 / 0 0.01 / 0.006 0.80 / 0.11 0.81 / 0.12\nEmb. Ada 20.69 5.50 26.6 51.1 64.9 0.23 / 0.06 0.01 / 0.004 0.67 / 0.19 0.94 / 0.26\nDavinci 23.56 5.00 27.7 52.1 63.3 1.93 / 0.48 0.12 / 0.03 0.75 / 0.16 2.80 / 0.77\niRank Ada 13.18 2.00 44.7 74.4 81.4 0.25 / 0.06 0.02 / 0.004 0.44 / 0.06 0.71 / 0.16\nDavinci 11.96 2.00 44.7 71.8 81.9 1.93 / 0.48 0.13 / 0.03 0.74 / 0.06 2.80 / 0.72\n(b) Invariants generated by gpt-4 .\nTable 2: Comparison between different ranking strategies for re-ranking the invariants generated by different LLMs.\nXujie Si, Hanjun Dai, Mukund Raghothaman, Mayur\nNaik, and Le Song. 2018. Learning loop invariants\nfor program verification. Advances in Neural Infor-\nmation Processing Systems, 31.\nNikhil Swamy, Juan Chen, Cédric Fournet, Pierre-\nYves Strub, Karthikeyan Bhargavan, and Jean Yang.\n2011. Secure distributed programming with value-\ndependent types. In Proceedings of the 16th ACM\nSIGPLAN International Conference on Functional\nProgramming, ICFP ’11, page 266–278, New York,\nNY , USA. Association for Computing Machinery.\nJianan Yao, Gabriel Ryan, Justin Wong, Suman Jana,\nand Ronghui Gu. 2020. Learning nonlinear loop in-\nvariants with gated continuous logic networks. In\nProceedings of the 41st ACM SIGPLAN Conference\non Programming Language Design and Implementa-\ntion, pages 106–120.\nA Further Details of iRank\nIn this section, we present a comprehensive\noverview of the operational workflow of iRank,\nas visualized in Figure 1.\nA.1 Training iRank\nAs elucidated in Section 4, the training of iRank\nnecessitates a dataset containing invariant synthesis\nproblems, akin to those illustrated in Figure 4. Each\nproblem in the training dataset requires at least one\ncorrect invariant and a set of incorrect invariants,\nall expressed in the SyGus format (refer to Figure 5\nfor an example). We employ the specified embed-\nding model, namely text-embedding-ada-002 or\nExperiment i+ranks V@K (%)Mean MedianK=1 K=5 k=10\nExpected ranksOriginal 95.35 31.02 8.0 19.2 25.2\nDeduplicated65.24 24.07 8.4 22.8 31.2\niRank-ada Original 38.78 5.00 28.0 51.2 60.8Deduplicated18.79 4.00 28.4 56.0 65.6\n(a) Invariants generated by gpt-3.5-turbo .\nExperiment i+ranks V@K (%)Mean MedianK=1 K=5 k=10\nExpected ranksOriginal 20.23 4.96 31.9 52.1 65.4\nDeduplicated13.99 4.89 31.4 53.7 72.8\niRank-ada Original 13.18 2.00 44.7 74.4 81.4Deduplicated8.73 2.00 46.8 77.1 86.7\n(b) Invariants generated by gpt-4-turbo .\nTable 3: Ranking result of correct invariant by de-duplicating\nsemantic equivalent candidates\ndavinci-similarity, to acquire initial embed-\ndings for both the problems and candidate solutions.\nThese initial embeddings undergo transformation\nvia a three-layered fully connected feedforward\nnetwork to yield transformed embeddings. The\ntraining objective is twofold: minimize the dis-\ntance between the transformed embedding of the\nproblem and the corresponding correct solutions,\nwhile maximizing the distance from incorrect ones.\nOnce this model is trained, it is employed to rank\nthe candidate invariants generated by the LLM or\nany other generator.\nA.2 Ranking with iRank\nUpon successful training of the transformation\nnetwork within iRank, it is used for ranking pur-\n8\n9171\nProblem Statistics\nTotal Problems 541\nProblem Types Statistics\nLinear Integer (LIA) 496 (91.68%)\nNon-Linear Integer (NIA) 27 (4.99%)\nArray Linear Integer (ALIA) 18 (3.33%)\nProblem Semantics Statistics\nNumber of functions Min = 3, Max = 9\nNumber of Variables Min = 2, Max = 90\nVariable types\nInteger = 80.31%\nBoolean = 19.31%\nArray[Integer] = 0.36%\nArray[Boolean] = 0.03%\nOperator Statistics (of the correct invariants)\nConjuctions 43% (of all operators)\n1.12 (avg. per example)\nDisjunctions 20% (of all operators)\n0.53 (avg. per example)\nNegations 37% (of all operators)\n0.96 (avg. per example)\nAddition/Subraction 43% (of all operators)\n0.5 (avg. per example)\nMultiplication/Division 3.1% (of all operators)\n0.18 (avg. per example)\nLogical Comparison 88.5% (of all operators)\n5.25 (avg. per example)\nLength Statistics\nProblem Length\nMin = 92 (N), 88 (T)\nMax = 2732 (N), 3146 (T)\nMean = 740 (N), 922 (T)\nInvariant Length (gpt-3.5-turbo)\nMin = 18 (N), 15 (T)\nMax = 605 (N), 506 (T)\nMean = 110 (N), 125 (T)\nInvariant Length (gpt-4)\nMin = 18 (N), 15 (T)\nMax = 513 (N), 488 (T)\nMean = 90 (N), 102 (T)\nN = Tokenized with NLTK\nT = Tokenized with TikToken\nTable 4: Stattistics of the experimental data\nposes. To rank the candidate invariants, iRank\ninitially extracts the initial embedding of the\nproblem and a list of solutions, using the same\nembedding model (text-embedding-ada-002 or\ndavinci-similarity) as employed during train-\ning. The trained transformation network is then\nused to transform these embeddings. These trans-\nformed embeddings serve as vectors for the re-\nranking process, where iRank calculates the cosine\nsimilarity between the transformed embedding of\nthe problem and each of the candidate solutions.\nThe candidate solutions are then sorted and re-\nturned based on their similarity with the problem.\nA.3 Data Details and Training\nHyperparameters\nTable 4 shows the statistics of the data we used to\nexperimentally evaluate iRank. Table 5 shows the\nhyperparameters for the models and training we\nNumber of Layers 3\nHidden Size 1536 (text-embedding-ada-002)\n12288 (davinci-similarity)\nOptimizer Adam\n# Training Epochs 20\nWeight Decay 0.001\nMax Gradient Norm 1.0\nLearning Rate 5 ∗105\nLR Scheduler Type Linear\nWarmup Steps 500\nTable 5: Hyperparameter for Model and Training\nused in this study.\nB Detailed Results\nIn addition to comparing the number of Z3 calls,\nwe compared the wall clock time. Table 2 shows\na comparison of time (as an extension of Table 1).\nWe conducted all the experiments in 24 cores\nAMD Epyc 7V13 Linux server running on Linux\nUbuntu 20.04 LTS with 220 GB RAM, and a sin-\ngle NVIDIA A100-PCIE-80GB GPU. For LLM-\nRanks, Expected ranks there is no embedding and\nranking, thus the verification time is the bottleneck.\nFor TF-IDF, while there is no embedding time, the\nis a little bit of ranking time.\nThe Ada embedding time in iRank was very\nsmall compared to the Davinci embedding, thus,\nin the case of iRank-ada, embedding and ranking\ntime was offset by the time iRank reduced in the\nverification effort. In contrast, the Davinci embed-\nding in iRank is more expensive than the reduc-\ntion in the verification time, resulting in a worse\nwall clock time performance than the LLM ranks.\nWe conjecture that the text-embedding-ada-002\n(embedding dim = 1536) is a smaller model com-\npared to davinci-similarity (embedding dim =\n12188), thus requiring significantly longer time to\nembed an input sequence (problem description or\ninvariant).\nIt is important to note here that, this experiment\nis only meant for an illustration of potential threats\nto iRank, and is dependent on a lot of variables,\nincluding, but not limited to OpenAI subscription\nmaximum rate limit, network latency for initial\nembeddings, etc.\nIn addition, we analyzed the generated invariant\ncandidates from LLMs, and removed any semantic\nduplicates. Given two invariant candidates ia and\nib parameterized by set of variables {v1,...v n},\n9\n9172\nwe define semantic equivalence as,\n∀v1,...,v n : ia(v1,...,v n) ⇔ib(v1,...,v n)\nFor comparing equivalence of two candidate invari-\nants, we make one call to the z3. Such a seman-\ntic deduplication requires comparison of a newly\ngenerated candidate invariant with all previous can-\ndidates, necessitating Θ(n2) z3 calls, just to dedu-\nplicate. Table 3 shows the results on deduplicated\ncandidates in comparison with the original list of\ninvariants. As expected, after deduplicating, the\nexpected ranks improves. Interestingly, even in\nthe list of candidates where all candidates are se-\nmantically unique, iRank improves the rank of the\ncorrect invariant, resulting in higher V@K.\nC Illustrative example\nAs an illustration of our proposed approach, we\npresent an example from FiB (Lin et al., 2017)\nbenchmark 4. The problem is represented in SyGus\nformat as shown in Figure 4.\n(set-logic LIA)\n(synth-inv inv_fun ((i Int) (n Int) (a Int) (b Int)))\n(define-fun pre_fun ((i Int) (n Int) (a Int) (b Int)) Bool\n    (and\n        (= i 0) (= a 0) (= b 0) (>= n 0)\n    )\n)\n(define-fun trans_fun ((i Int) (n Int) (a Int) (b Int)\n        (i! Int) (n! Int) (a! Int) (b! Int)) Bool\n    (or\n        (and\n            (< i n) (= i! (+ i 1)) (= a! (+ a 1))\n            (= b! (+ b 2)) (= n! n)\n        )\n        (and\n            (< i n) (= i! (+ i 1)) (= a! (+ a 2))\n            (= b! (+ b 1)) (= n! n)\n        )\n        (and\n            (>= i n) (= i! i) (= a! a) (= b! b) (= n! n)\n        )\n    )\n)\n(define-fun post_fun ((i Int) (n Int) (a Int) (b Int)) Bool\n    (=> (not (< i n)) (= (+ a b) (+ (+ n n) n))))\n(inv-constraint inv_fun pre_fun trans_fun post_fun)\n(check-synth)\nFigure 4: Invariant synthesis problem in FiB-8.sl\nWe create the following prompt to call LLMs.\nHere is a loop invariant synthesis problem\nin SyGus format .\n<<<< The problem definition from above >>>>>\n4https://github.com/spencerxiao/\nase2017-results-and-tools/tree/master/FiB_Tool/\nbenchmarks\nSynthesize a necessary and sufficient invariant .\nStart the invariant with\n\"( define - fun inv_fun ((i Int ) (n Int ) (a Int )\n(b Int )) Bool (\" and end with \")\".\nSurround only the invariant with <code > and\n</code >. You don 't need to explain the invariant ,\njust synthesize it.\nThe gpt-3.5-turbo model generated invariant\nshown in Figure 5 after 144 unsuccessful attempts.\n(define-fun inv_fun ((i Int) (n Int) (a Int) (b Int))\nBool\n    (or\n        (and (<= i n) (= (+ a b) (* 3 i)))\n        (and (> i n) (= (+ a b) (* 3 n)))\n    )\n)\nFigure 5: Correct invariant generated by gpt-3.5-turbo.\nThe gpt-4 model generated the invariant shown\nin Figure 6 after 2 unsuccessful attempts.\n(define-fun inv_fun ((i Int) (n Int) (a Int) (b Int))\nBool\n    (and (<= i n) (= (+ a b) (* i 3)))\n)\nFigure 6: Correct invariant generated by gpt-4.\niRank trained based on text-embedding-ada-\n002 repositioned the gpt-3.5-turbo at 8th posi-\ntion in the list and the gpt-4 generated correct\ninvariant in position 2. Note that we show this\nexample only for illustration purposes.\nD Experiment on Expected re-ranking\nThe list of invariants generated by LLM as a ranked\nlist could be unstable and susceptible to variations\nin performance across different experiments. Thus,\nas described in Section 5.1, we estimate the ex-\npected ranks by randomly permutating the list. Ide-\nally, to get a perfect estimation, we should consider\nall possible permutations of the list, which can be\nvery expensive (exponential order on the number\nof elements in the list). Figure 7 shows ablation\nof mean rank w.r.t.the number of random permuta-\ntions. As we can see, with a gradual increase in the\nnumber of permutations, the variance in the met-\nrics gradually reduces, i.e., the metrics converges.\nThroughout the paper, we set the number of permu-\ntations to be 100 for estimating the expected rank\nmetrics.\n10\n9173\n5 10 15 20 25 30 35 40 45 50 55 60 70 80 90 100\nNumber of Random Permutations\n87.5\n90.0\n92.5\n95.0\n97.5\n100.0\n102.5Mean Rank\n(a) gpt-3.5-turbo\n5 10 15 20 25 30 35 40 45 50 55 60 70 80 90 100\nNumber of Random Permutations\n18\n19\n20\n21\n22Mean Rank\n(b) gpt-4\nFigure 7: Result stabilization with an increasing number of\nrandom permutations\nE Visualization of the impact of training\nin iRank\nFigure 8 show a t-SNE plot of the raw LLM em-\nbeddings and the transformed embeddings for a\nfew example problems. For the first three exam-\nples(Figures 8a, 8b, 8c, respectively), iRank brings\nthe correct invariant closer to the problem than any\nother invariants. For the example presented in Fig-\nure 8d, iRank could not make the correct invariant\nas the closest to the problem. While there are cases\nwhere iRank’s transformation fails to bring the cor-\nrect invariant in the closest proximity, in most cases,\nit can bring correct invariants closer to the trans-\nformed problem embedding, as corroborated by the\nresults in Appendix B\n11\n9174\nProblem Correct Invariant Incorrect Invariant\nW/O training\nProblem Correct Invariant Incorrect Invariant With training\n(a) Example - 1\nProblem Correct Invariant Incorrect Invariant\nW/O training\nProblem Correct Invariant Incorrect Invariant With training\n(b) Example - 2\nProblem Correct Invariant Incorrect Invariant\nW/O training\nProblem Correct Invariant Incorrect Invariant With training\n(c) Example - 3\nProblem Correct Invariant Incorrect Invariant\nW/O training\nProblem Correct Invariant Incorrect Invariant With training\n(d) Example - 4\nFigure 8: t-SNE plots of embeddings with and without training for a few example problems. The number of incorrect invariants\nis downsampled for better visualization clarity.\n12\n9175"
}