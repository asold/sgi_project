{
  "title": "Large language models in perioperative medicine—applications and future prospects: a narrative review",
  "url": "https://openalex.org/W4411148566",
  "year": 2025,
  "authors": [
    {
      "id": null,
      "name": "Mbadjeu Hondjeu, Arnaud Romeo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5025066296",
      "name": "Zhao Zi-Ying",
      "affiliations": [
        "Ottawa Hospital",
        "University of Ottawa"
      ]
    },
    {
      "id": null,
      "name": "Newton, Luka",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Ajenkar, Anass",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Hladkowicz, Emily",
      "affiliations": [
        "Ottawa Hospital",
        "Ottawa Hospital Research Institute"
      ]
    },
    {
      "id": null,
      "name": "Ladha, Karim",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Wijeysundera, Duminda N.",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": null,
      "name": "McIsaac, Daniel I.",
      "affiliations": [
        "Ottawa Hospital Research Institute",
        "Ottawa Hospital",
        "Institute for Clinical Evaluative Sciences",
        "University of Ottawa"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4386693657",
    "https://openalex.org/W3144293453",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2908029493",
    "https://openalex.org/W4312220150",
    "https://openalex.org/W4362522726",
    "https://openalex.org/W4379769651",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W4392928544",
    "https://openalex.org/W4392547002",
    "https://openalex.org/W4404356490",
    "https://openalex.org/W4402408693",
    "https://openalex.org/W4365446686",
    "https://openalex.org/W4384700226",
    "https://openalex.org/W2108017634",
    "https://openalex.org/W2910183178",
    "https://openalex.org/W2139839572",
    "https://openalex.org/W4401544581",
    "https://openalex.org/W4390105593",
    "https://openalex.org/W4387894790",
    "https://openalex.org/W1976348699",
    "https://openalex.org/W4382931491",
    "https://openalex.org/W4328049465",
    "https://openalex.org/W3038382016",
    "https://openalex.org/W4366234719",
    "https://openalex.org/W4387242094",
    "https://openalex.org/W3181025656",
    "https://openalex.org/W4391576545",
    "https://openalex.org/W4399489002",
    "https://openalex.org/W4399363701",
    "https://openalex.org/W4283722961",
    "https://openalex.org/W2896570235",
    "https://openalex.org/W4317435411",
    "https://openalex.org/W2016136159",
    "https://openalex.org/W4390227458",
    "https://openalex.org/W4384626331",
    "https://openalex.org/W4399070654",
    "https://openalex.org/W4386757338",
    "https://openalex.org/W4402351533",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4388337082",
    "https://openalex.org/W4381189340",
    "https://openalex.org/W4385778931",
    "https://openalex.org/W4362723632",
    "https://openalex.org/W4379985834",
    "https://openalex.org/W4376270181",
    "https://openalex.org/W4385325757",
    "https://openalex.org/W2319729735",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W4381587418",
    "https://openalex.org/W4385436582",
    "https://openalex.org/W4382930233",
    "https://openalex.org/W4386284533",
    "https://openalex.org/W4380887490",
    "https://openalex.org/W4380319827",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4399810434",
    "https://openalex.org/W386982330"
  ],
  "abstract": null,
  "full_text": "REVIEW ARTICLE/BRIEF REVIEW\nLarge language models in perioperative medicine—applications\nand future prospects: a narrative review\nLes grands mode`les de langage en me´decine pe´riope´ratoire—leurs\napplications et les perspectives d’avenir : un compte rendu\nnarratif\nArnaud R. Mbadjeu Hondjeu, MD, MSc . Zi Ying Zhao, MD . Luka Newton, BHSc .\nAnass Ajenkar, BSc . Emily Hladkowicz, PhD . Karim Ladha, MD, MSc, FRCPC .\nDuminda N. Wijeysundera, MD, PhD, FRCPC, FAHA . Daniel I. McIsaac, MD, MPH, FRCPC\nReceived: 30 October 2024 / Revised: 24 March 2025 / Accepted: 25 March 2025 / Published online: 9 June 2025\n/C211 The Author(s) 2025\nAbstract\nPurpose Large language models (LLMs) are a subset of\nartiﬁcial intelligence (AI) and linguistics designed to help\ncomputers understand and analyze human language.\nClinical applications of LLMs have recently been\nrecognised for their potential enhanced analytic capacity.\nAvailability and performance of LLMs are expected to\nincrease substantially over time with a signiﬁcant impact\non patient care and health care provider workﬂow. Despite\nincreasing recognition of LLMs, insights on the utilities,\nassociated beneﬁts and limitations are scarce among\nperioperative clinicians. In this narrative review, we\ndelve into the functionalities and prospects of existing\nLLMs and their clinical application in perioperative\nmedicine. Furthermore, we summarize challenges and\nconstraints that must be addressed to fully realize the\npotential of LLMs\nSource We searched MEDLINE, Google Scholar, and\nPubMed/C210 databases for articles referencing LLMs in\nperioperative care.\nPrincipal ﬁndings We found that in the perioperative\nsetting (from surgical diagnosis to discharge\npostoperatively), LLMs have the potential to improve the\nefﬁciency and accuracy of health care delivery by\nextracting and summarizing clinical data, making\nrecommendations on the basis of these ﬁndings, as well\nas addressing patient queries. Moreover, LLMs can be\nused for clinical decision-making support, surveillance\nA. R. M. Hondjeu, MD, MSc ( &)\nDepartment of Anesthesiology and Pain Medicine, University of\nOttawa, Ottawa, ON, Canada\nThe Ottawa Hospital, Ottawa, ON, Canada\nOttawa Hospital Research Institute, Ottawa, ON, Canada\nDepartment of Anesthesiology and Pain Medicine, The Ottawa\nHospital, General Campus CCW1401-501 Smyth Rd, Ottawa,\nON K1H 8L6, Canada\ne-mail: ambadjeu@toh.ca\nZ. Y. Zhao, MD\nDepartment of Anesthesiology and Pain Medicine, University of\nOttawa, Ottawa, ON, Canada\nThe Ottawa Hospital, Ottawa, ON, Canada\nL. Newton, BHSc /C1A. Ajenkar, BSc\nDepartment of Anesthesiology and Pain Medicine, University of\nOttawa, Ottawa, ON, Canada\nE. Hladkowicz, PhD\nThe Ottawa Hospital, Ottawa, ON, Canada\nOttawa Hospital Research Institute, Ottawa, ON, Canada\nK. Ladha, MD, MSc, FRCPC /C1\nD. N. Wijeysundera, MD, PhD, FRCPC, FAHA\nDepartment of Anesthesiology & Pain Medicine, University of\nToronto, Toronto, ON, Canada\nD. I. McIsaac, MD, MPH, FRCPC\nDepartment of Anesthesiology and Pain Medicine, University of\nOttawa, Ottawa, ON, Canada\nThe Ottawa Hospital, Ottawa, ON, Canada\nOttawa Hospital Research Institute, Ottawa, ON, Canada\nInstitute for Clinical Evaluative Sciences, Ottawa, ON, Canada\n123\nCan J Anesth/J Can Anesth (2025) 72:1000–1014\nhttps://doi.org/10.1007/s12630-025-02980-w\n\ntools, predictive modelling, and enhancement of medical\nresearch and education.\nConclusions The integration of LLMs into perioperative\nmedicine presents a signiﬁcant opportunity to enhance\npatient care, clinical decision-making, and operational\nefﬁciency. These models can streamline processes, provide\npersonalized patient education, and offer robust decision\nsupport. Nevertheless, their clinical implementation\nrequires addressing several key challenges, including\nmanaging hallucinations, ensuring data security, and\nmitigating inherent biases. If these challenges are met,\nLLMs can revolutionize perioperative practice, improving\nboth patient outcomes and clinician workﬂow.\nRe´sume´\nObjectif Les grands mode `les de langage (LLM) sont a ` la\ncroise´e des chemins de l’intelligence artiﬁcielle (IA) et de\nla linguistique et sont conc ¸us pour aider les ordinateurs a `\ncomprendre et analyser le langage humain. Les\napplications cliniques des LLM ont re ´cemment e ´te´\nreconnues pour leur capacite ´ analytique potentiellement\name´liore´e. La disponibilite ´ et les performances des LLM\ndevraient augmenter conside ´rablement au ﬁl du temps, ce\nqui aura un impact signiﬁcatif sur les soins a ` la patiente`le\net le ﬂux de travail des prestataires de soins de sante ´.\nMalgre´la reconnaissance croissante des LLM, les e ´quipes\ncliniques pe´riope´ratoires ont peu d’informations sur leurs\nutilite´s, ainsi que sur les avantages et limites qui y sont\nassocie´s. Dans ce compte rendu narratif, nous nous\npenchons sur les fonctionnalite ´s et les perspectives des\nLLM existants et leur application clinique en me ´decine\npe´riope´ratoire. Nous re ´sumons e´galement les de ´ﬁs et les\ncontraintes qui doivent e ˆtre aborde ´s pour re ´aliser\npleinement le potentiel des LLM.\nSources Nous avons recherche ´ des articles faisant\nre´\nfe´rence a` des LLM en soins pe ´riope´ratoires dans les\nbases de donne ´es MEDLINE, Google Scholar et\nPubMed/C210 .\nConstatations principales Nous avons constate ´que dans\nle cadre pe ´riope´ratoire (du diagnostic chirurgical au\nconge´ postope´ratoire), les LLM ont le potentiel\nd’ame´liorer l’efﬁcacite´ et la pre ´cision de la prestation\ndes soins de sante ´en extrayant et en re ´sumant les donne´es\ncliniques, en formulant des recommandations sur la base\nde ces re ´sultats, ainsi qu’en re ´pondant aux questions des\npatients et patientes. De plus, les LLM peuvent e ˆtre utilise´s\npour l’aide a ` la prise de de ´cision clinique, les outils de\nsurveillance, la mode ´lisation pre´dictive et l’ame ´lioration\nde la recherche me ´dicale et de l’e ´ducation.\nConclusion L’inte´gration des LLM dans la me ´decine\npe´riope´ratoire repre ´sente une opportunite ´ majeure\nd’ame´liorer les soins a ` la patiente`le, la prise de de ´cision\nclinique et l’efﬁcacite´ope´rationnelle. Ces mode`les peuvent\nrationaliser les processus, fournir une e ´ducation\npersonnalise´ea ` la patiente `le et offrir une aide a ` la\nde´cision solide. Ne ´anmoins, leur mise en œuvre clinique\nne´cessite de relever plusieurs de ´ﬁs cle´s, notamment la prise\nen charge des hallucinations, la se ´curite´ des donne´es et\nl’atte´nuation des pre ´juge´s inhe ´rents. Si ces de ´ﬁs sont\nreleve´s, les LLM pourraient re ´volutionner la pratique\npe´riope´ratoire, en ame´liorant a` la fois les devenirs pour la\npatiente`le et le ﬂux de travail des e ´quipes cliniques.\nKeywords artiﬁcial intelligence /C1ChatGPT /C1\ngenerative AI /C1health care /C1large language models /C1\nmachine learning applications /C1\nnatural language generation /C1natural language processing /C1\nperioperative medicine\nArtiﬁcial intelligence (AI) involves the study of algorithms\nthat empower machines to reason and perform executive\nfunctions including problem-solving, decision-making,\nobject, word recognition, and inference of world states. 1\nWithin this expansive ﬁeld, generative AI has emerged as a\npowerful tool capable of creating new content on different\nformats, including audio, code, images, text, simulations,\nand videos.\n2 These capabilities are driven by advancements\nin natural language processing (NLP), an interdisciplinary\nsubﬁeld of computer science and AI, which enables\ncomputers to comprehend, generate, and manipulate the\nhuman language.\n3\nAt the core of generative AI are large language models\n(LLMs)—advanced neural networks trained on vast\ndatasets to generate human-like text by predicting\nsubsequent words in a sequence. By leveraging cutting-\nedge NLP techniques, LLMs excel at speech recognition,\ninformation retrieval, machine translation, and text\ngeneration on the basis of prompts (a set of speciﬁc\ninstructions provided to LLMs to elicit speciﬁc and\nrelevant responses).\n4\nLarge language models are generating both excitement\nand concern in perioperative medicine, a ﬁeld that\nintegrates the multidisciplinary care of patients from\nsurgical planning to recovery. 5 These models offer the\npotential to improve health care efﬁciency and accuracy by\nextracting and summarizing clinical data, streamlining\nadministrative workﬂows, as well as supporting medical\nresearch, quality improvement, and education.\n6,7\nResearchers are exploring their integration into electronic\nhealth records to maximize these beneﬁts. 6 Moreover,\nLLMs can be versatile tools for supporting diagnosis or\nprognosis.8,9 While current applications primarily assist\nclinicians, such as generating patient summaries or\nsynthesizing medical literature, LLMs also hold promise\n123\nLarge language models in perioperative medicine 1001\nfor patient education. By translating complex medical\ninformation into accessible language and answering patient\nquestions, they can enhance personalized care and\nempower patients to participate in their health care\ndecisions.\n10,11 While the perioperative ﬁeld has seen\nexciting progress, they have also been met with caution\nas AI requires human oversight to ensure safety and\nreliability.\n12 The American Medical Association reinforces\nthis perspective, deﬁning augmented intelligence as a tool\ndesigned to enhance, rather than replace, human judgement\nin clinical decision-making.\n13\nDespite the growing adoption of LLMs, their role in\nperioperative medicine remains underexplored. As their\nuse expands, perioperative clinicians and researchers must\nunderstand what these technologies are and how to harness\nLLMs to enhance patient safety, efﬁciency, ethics, and\ncost-effectiveness in care delivery.\nOur aim for this narrative review was to guide\nperioperative researchers and clinicians in optimizing\ntheir research and clinical practices with LLMs. First, we\nprovide a foundational overview of LLMs’ technology. We\nthen explore their clinical application in perioperative\nmedicine. Lastly, we present challenges and constraints,\nincluding security, bias, and ethical concerns, that must be\naddressed to fully realize LLMs potential in perioperative\nmedicine.\nMethods\nWe searched MEDLINE, Google Scholar, and PubMed /C210\ndatabases using combinations of the following keywords:\nlarge language model, ChatGPT, machine learning,\nartiﬁcial intelligence, neural networks, anesthesiology,\nanesthesia, surgery, perioperative medicine, preoperative,\nintraoperative, and postoperative. We included articles\ndirectly related to the use of a LLM in the care of patients\npreparing for, undergoing, or recovering from anesthesia\nand/or any type of surgery, as well as those related to the\nuse of a LLM in support of clinicians in anesthesia and/or\nsurgery. An author with experience in perioperative\nmedicine and LLM research made the ﬁnal decisions for\ninclusion.\nBasic understanding of large language models\nThe evolution of natural language processing\nThe evolution of NLP has gone through several phases,\nwith each development building upon the strengths and\nlimitations of its predecessors. Early statistical models\nstruggled with word prediction owing to data sparsity and\nfailure to capture language complexity. Neural models\nimproved upon early statistical models with recurrent\nneural networks (RNNs), which retained contextual\ninformation from previous words in a sentence.\nNevertheless, RNNs had limitations, particularly in\nunderstanding long-range word relationships. Pretrained\nmodels extended RNNs’ capabilities but still faced\nchallenges with context retention. The introduction of\nLLMs, powered by transformers, overcame these issues by\nprocessing entire sentences simultaneously, signiﬁcantly\nimproving comprehension and prediction. Large language\nmodels allowed for more accurate language comprehension\nand the ability to perform a wide range of tasks.\nMultimodal LLMs take this further by processing not just\ntext but also images, audio, and video, allowing even\nbroader applications.\n14\nFigure 1 presents the timeline and key milestones in the\nevolution of NLP, showcasing the transition from early\nstatistical models to advanced transformer-based LLMs.\nEach stage represents a signiﬁcant leap in language\ncomprehension and processing.\nWhat is a large language model?\nAn LLM is an advanced AI system designed to understand\nand generate human-like text. Here is a simpler\nexplanation:\n• Training: LLMs are trained on enormous amounts of\ntext from various sources such as books, websites, and\narticles.\n• Learning: through this training, LLMs learn patterns in\nlanguage, including grammar, meaning, and context.\n• Structure: LLMs use complex mathematical structures\ncalled neural networks, which are loosely inspired by\nhow the human brain works.\n• Capability: LLMs can handle long pieces of text and\nunderstand the relationships between words and ideas\nacross entire paragraphs or documents.\n• Applications: LLMs can assist with tasks such as\nsummarizing medical literature, drafting patient notes,\nor answering general medical questions.\nHow does a large language model work?\nLarge language models generate text by predicting the\nmost likely next word in a sequence, no matter the length\nof the sequence, or the language. Below is an explanation\nof some keywords:\n• Prompt: the user provides initial input to the LLM in\nthe form of a question or instruction. On the basis of the\nlevel of instructions provided, the prompts can be\n123\n1002 A. R. M. Hondjeu et al.\nclassiﬁed as zero-shot (minimal instructions are\nprovided), few-shot (instructions are provided with\nexamples), and the more complex chain-of-thought\n(complex reasoning and detailed instructions are\nprovided).\n15\n• Input processing : the LLM breaks the prompt into\nsmaller units called tokens (usually words or parts of\nwords).\n• Analysis: using attention mechanisms, LLMs focus on\nthe most important parts of the input to improve\npredictions, identifying key words in a sentence or\nrelevant data in a data set.\n• Context understanding : the model considers\nsurrounding words for better comprehension.\n• Prediction: on the basis of its training and prompting,\nthe LLM calculates probabilities and selects the most\nlikely next word.\n• Output generation : using a continuous process, the\nmodel chooses the word with the highest probability\nand adds it to the output. The process repeats until the\nresponse is complete. For example, it might stop when\nit has answered a question or reached a speciﬁed length.\nThe LLM can indicate varying levels of ‘‘conﬁdence’’\nin its outputs.\n• Pattern recognition : LLMs do not ‘‘understand’’\nmeaning like humans do but reproduce patterns\ninformed by their training data.\n• Limitations: because LLMs act on patterns and\nprobabilities, they can sometimes produce incorrect or\nnonsensical information. Large language models do not\nhave true understanding or the ability to fact-check\noutputs. Moreover, LLMs can reﬂect biases present in\ntheir training data.\nWhat are the most common large language models?\nThe number of LLMs is growing rapidly, and some are\nespecially relevant for medical professionals. Here are the\nkey models to know:\n• Generative Pretrained Transformers (GPT) Series (by\nOpenAI, Inc,, San Francisco, CA, USA): best known\nfor ChatGPT, the latest version (GPT-4) can handle\nboth text and images. In clinical practice, GPT-4 can\nhelp with various clinical tasks. Nevertheless, its full\nworkings are not publicly available.\n• Claude (by Anthropic PBC, San Francisco, CA, USA):\nblends strong reasoning with built-in ethical safeguards\nthrough Constitutional AI. It upholds societal norms via\nadvanced moderation and a strict trust and safety\nprocess while prioritizing privacy by deleting user data\nwithin ninety days. With its ability to analyze complex\nmedical texts, Claude is a reliable tool for clinical\ndecision support, minimizing the risk of inappropriate\nrecommendations.\n• Pathways Language Model (PaLM) Series (by Google\nResearch, Alphabet Inc., Mountain View, CA, USA):\nMed-PaLM2 is designed for health care. It has shown\nstrong potential in medical reasoning and answering\npatient queries.\n• Large Language Model Meta AI (Llama) Series (by\nMeta, Menlo Park, CA, USA): these open-source\nmodels can be ﬁne-tuned for speciﬁc tasks, making\nthem useful for researchers interested in building\ncustomized health care applications or analyzing\nclinical datasets.\n• Bidirectional Encoder Representations from\nTransformers (BERT) and variants (by Google\nFig. 1 Timeline and key milestones in the evolution of natural language processing\nLLM = large language model\n123\nLarge language models in perioperative medicine 1003\nResearch): used widely in medical research, BERT\nexcels in understanding clinical notes. It is an ideal tool\nfor automating tasks such as extracting information\nfrom electronic health records (EHRs).\n• Galactica (by Meta): built for scientiﬁc and medical\nknowledge, Galactica can help clinicians stay updated\non the latest research or generate literature summaries\nfor quick reference.\n• Bloom (by BigScience [ https://bigscience.huggingface.\nco; accessed May 2025]): an open-access model\ndesigned for multiple languages. This can be particu-\nlarly useful for clinicians working with multilingual\npopulations, offering language support and translation\ncapabilities.\n• Grok (by xAI, Palo Alto, CA, USA): a newcomer to the\nscene, Grok aims to improve collaboration between AI\nand humans. While still emerging, we expect it play a\nrole in making medical AI more interactive and user-\nfriendly.\n• Google Gemini (by Google, Alphabet Inc., Mountain\nView, CA, USA): Google’s multimodal AI model\ncapable of processing text, images, audio, and video. It\naims to improve AI’s contextual understanding and\nreasoning, making it a strong candidate for advanced\nmedical applications.\n• Mistral AI (by Mistral AI, Paris France): an open-\nsource LLM optimized for efﬁciency and scalability. It\noffers lightweight, high-performance models\nsuitable for real-time applications, including medical\nchatbots and clinical documentation support.\n• DeepSeek (by DeepSeek, Hangzhou, Zhejiang, China):\na Chinese AI company that develops open-source\nLLMs, such as DeepSeek R1 and 67B, excelling in\nefﬁciency, multilingual support, and reasoning. They\noutperform rivals in code generation and mathematic\nbut have weak security guardrails, raising concerns\nabout misuse.\nFigure 2 demonstrates the exponential increase in the\nsize of LLMs over time, represented by the number of\nparameters (in billions). The ﬁgure highlights how the\ncapacity of these models to understand and generate text\nhas expanded, driving their application in complex medical\nenvironments. Key differences and considerations between\nmodels are:\n• Size and capability : larger models are typically more\npowerful but may require signiﬁcant computing\nresources.\nFig. 2 Evolution of the size of large language models\n123\n1004 A. R. M. Hondjeu et al.\n• Specialization: models such as Med-PaLM2 and\nGalactica are designed for health care, making them\nbetter for medical tasks.\n• Accessibility: open-source models such as Llama and\nBloom are free to use and can be customized, making\nthem ideal for research projects.\n• Input types : models such as GPT-4 can handle both text\nand images, which could be useful for interpreting\ndiagnostic scans alongside medical histories.\n• Ethical considerations : models such as Claude\nprioritize safety and ethical use, making them\nsuitable for sensitive clinical environments.\n• Continuous updates : many models are regularly\nupdated, ensuring that they remain accurate and useful.\n• Integration: some of these LLMs are being developed\nto be integrated into clinical decision support systems\nand EHRs, offering real-time assistance for patient\ncare.\nHow are large language models classiﬁed?\nVarious classiﬁcations of LLMs have been proposed on the\nbasis of different criteria including size, data used for\ntraining, and task speciﬁcity. The Table provides a\nsummarized classiﬁcation of LLMs.\nCurrent applications of large language models\nin perioperative medicine\nGiven their advanced capabilities, LLMs are actively\ntransforming clinical practice, including perioperative\nmedicine. In Figure 3 and the following sections, we\noutline these practical applications and their potential to\ntransform patient care, which includes decision support\nsystems, patient education tools, diagnostic assistance, and\nadministrative task automation. Each application aims at\nimproving the quality, efﬁciency, and personalization of\nperioperative care.\nTable Classiﬁcation of large language models\nClassiﬁcation Category Description\nSize Small Number of parameters B 1B\nMedium 1 B \\ number of parameters B 10 B\nLarge 10 B \\ number of parameters B 100 B\nVery large 100 B \\ number of parameters\nAvailability Publicly available Model and weights are publicly released and are available\nExample: Llama\nPublicly unavailable Model and weights are not publicly released and are not available\nExample: GPT-4\nType Foundation model Pretrained language model with no instruction or chat ﬁne-tuning\nExample: MPT-7B\nInstruction model Pretrained model that is also ﬁne-tuned on following instructions\nExample: MPT-7B-instruct\nChat model Pretrained model that is also ﬁne-tuned on chat\nExample: MPT-7B-chat\nOriginality Original model An original model released with either foundation, instruction, or chat model\nExample: Llama\nTuned model Fine-tuned models that are originally based on original models\nExample: Alpaca\nSpeciﬁcity of the task Summarization\nQuestion answering\nTranslation\nData analysis\nData used for training General-purpose Trained on large amounts of general web-based text data\nDomain-speciﬁc Trained on speciﬁc datasets to enhance efﬁcacy in particular domains\nThis table categorizes large language models by size, availability, task speciﬁcity, and training data. It outlines the distinctions between smalland\nlarge models, public and private access, and their use in speciﬁc tasks, such as summarization and question answering, relevant to perioperative\nmedicine.\n123\nLarge language models in perioperative medicine 1005\nMedical diagnosis and risk stratiﬁcation\nIn fast-paced perioperative environments, rapid and\naccurate diagnosis is essential for effective surgical\nplanning and management. This requires synthesizing\ndiverse clinical data, including patient history, physical\nexams, lab results, and imaging studies. A recent study by\nLiu et al. evaluated the diagnostic accuracy of GPT-3.5 and\nGPT-4.0 for colon cancer diagnoses across seven\ncategories, such as symptoms, lab results, and\nintraoperative ﬁndings.\n16 GPT-4.0 signiﬁcantly\noutperformed GPT-3.5 in both primary and secondary\ndiagnoses. The mean (standard deviation [SD]) accuracy\nrate for primary diagnoses was 0.97 (0.14) for GPT-4.0 and\n0.85 (0.33) for GPT-3.5 ( P \\ 0.001). Similarly, for\nsecondary diagnoses, GPT-4.0 achieved a mean (SD)\naccuracy of 0.91 (0.16) vs 0.62 (0.35) for GPT-3.5\n(P \\ 0.001).\nLarge language models also show potential in risk\nstratiﬁcation by analyzing large datasets and identifying\npatterns in medical records and clinical data.\n17 For\ninstance, Lim et al. used 10 standardized hypothetical\npatient scenarios to show that GPT-3.5-turbo consistently\nclassiﬁed patients according to the American Society of\nAnesthesiologists Physical Status (ASA-PS) score,\nperforming comparably to anesthesiologists with a Fleiss’\nkappa of 0.62.\n18 The authors further validated these\nﬁndings with variations of the patient scenarios, where\nthe model achieved Fleiss’ kappa scores of 0.73 and 0.60,\nindicating substantial agreement.\nWhile LLMs have shown promise in simulations, they\nhave yet to be adopted in routine clinical practice. Large\nlanguage models’ integration into perioperative care could\nimprove diagnostic accuracy and enable timely risk\nmitigation strategies. Future research should focus on\nreal-world clinical applications to fully assess their impact.\nPatient care: patient-facing education material\nThe ASA holds anesthesiologists responsible for ensuring\nthat patients understand and adhere to preoperative\ninstructions, which should be presented at an appropriate\nliteracy level. 19,20 Nevertheless, studies show that most\nwritten materials are too complex for the average patient,\ncontributing to nonadherence, delayed or canceled\nsurgeries, and worse outcomes, further exacerbating\nhealth care disparities.\n21,22\nLarge language models can personalize information on\nsurgical risks, preoperative instructions, and postoperative\nrecovery by adapting content to patients’ reading levels.\nFor instance, Hong et al. compared standard English-\nlanguage preoperative instructions with those enhanced by\nlanguage models and found that GPT-4 improved the\nreadability to a sixth-grade level, outperforming GPT-3.5\n(mean readability score of 5.0 [0.76] vs 10 [0.37]), while\nmaintaining accuracy and detail.\n23 GPT-4’s preoperative\ninstructions were signiﬁcantly less complex across all\npatient scenarios than both the standard hospital text\n(P \\ 0.01) and GPT-3.5 ( P \\ 0.01).\n23 The assessment of\naccuracy and completeness showed no missing, inaccurate,\nor incomplete information. 23 Similar improvements have\nbeen observed in the creation of postoperative instructions\nfor common surgeries. 24,25\nBy leveraging LLMs, perioperative clinicians can\nproduce tailored, easy-to-understand patient education\nmaterials, enhancing comprehension and ultimately\nFig. 3 Clinical applications of large language models in perioperative medicine\n123\n1006 A. R. M. Hondjeu et al.\nimproving patient outcomes. Nevertheless, ensuring the\naccuracy and reliability of LLM-generated content is\ncrucial to maintain patient safety.\nPatient care: patient-facing Chatbot\nClear perioperative instructions can ease postoperative\nrecovery, reduce anxiety, and shorten hospital stays. 26\nLarge language model-powered chatbots provide 24/7\nsupport by assisting with scheduling, reminders, health\nassessments, and answering common questions. Patnaik\net al. examined how well LLMs could respond to\nanesthesia-related queries from a patient’s perspective.\n27\nPatients indicated that ChatGPT’s linguistic quality was\n19.7% better than Bard’s (ChatGPT: 66.2 [13.4] vs Bard:\n55.3 [11.8]; P \\ 0.001). Nevertheless, the issue of\nhallucinations—plausible but incorrect responses—\nremains a concern, especially with Bard. Notably,\nChatGPT provided no incorrect answers or hallucinations,\nwhereas Bard had a marked error rate (0 out of 33 queries\nfor ChatGPT vs 10 out of 33 for Google Bard, resulting in a\n30.3% error rate).\nLarge language models can offer personalized,\naccessible responses to each patient’s questions on\nprocedure, recovery, and concerns. Integrating LLMs into\nclinical practice could allow patients to explore the surgical\nprocess, learn pain management techniques, and reduce\nanxiety, promoting a more personalized and informed\nperioperative experience. While LLM-powered chatbots\nshow promise for personalized patient education, further\nefforts are needed to reduce hallucinations and rigorously\ncompare LLM performance against clinicians.\nClinical decision support\nPerioperative clinicians face time-sensitive decisions that\ncan signiﬁcantly affect patient outcomes and safety.\nCognitive errors, often exacerbated by fatigue or\ninexperience, contribute to over half of the adverse\nevents reported in clinical settings.\n28,29 To mitigate this,\nLLMs are increasingly being explored for their ability to\nquickly process vast datasets, offering enhanced predictive\nand classiﬁcation capabilities that can support decision-\nmaking. These models improve health care quality and\nFig. 4 Key limitations of large language models in perioperative medicine\n123\nLarge language models in perioperative medicine 1007\nefﬁciency by helping clinicians navigate complex clinical\nscenarios and deliver personalized care. 30,31\nAI-driven clinical decision support systems integrate\ndiverse perioperative data, from imaging trends to\nmedication adjustments, to predict critical events. These\nsystems also enhance access to the relevant literature,\nstreamline chart reviews, improve documentation, and\nprovide real-time recommendations.\n32,33 In a recent study,\nGomez-Cabello et al. compared the performance of\nChatGPT-4 and Google’s Gemini Pro for intraoperative\ndecision-making in plastic and reconstructive surgery using\n32 independent intraoperative scenarios spanning ﬁve\nprocedures.\n34 The authors used 5-point and 3-point Likert\nscales to assess the medical accuracy and relevance,\nrespectively, as well as model response time. While both\nmodels demonstrated sufﬁcient knowledge to assist\nsurgeons, ChatGPT-4 signiﬁcantly outperformed Gemini\nin terms of accuracy (3.6 [0.8] vs 3.1 [0.8], P = 0.022) and\nrelevance (2.3 [0.8] vs 1.9 [0.8], P = 0.032). Nevertheless,\nGemini provided notably faster response times\n(8.1 [1.4] sec vs 13.7 [2.9] sec, P \\ 0.001). Although\npromising, further validation of LLMs in real-time surgical\nenvironments is needed, considering the dynamic, high\nstakes nature of perioperative care.\nResource allocation and administration\nPerioperative care involves a coordinated network of\nprofessionals, technology, and processes. Large language\nmodels, combined with clinician expertise, can enhance\nresource allocation by predicting factors such as ASA-PS\nscores, intensive care unit (ICU) admissions, hospital\nmortality, and surgical outcomes. Nevertheless, current\nmodels struggle with accurately predicting the duration of\npostoperative recovery, including time spent in the\npostanesthesia care unit (PACU) and hospital.\n35\nChung et al. investigated the capabilities of GPT-4\nTurbo in risk stratiﬁcation and the prediction of\npostoperative outcomes. 35 The authors examined the\nmodel’s ability to explain its decisions on the basis of\ndescriptions of procedures and the patients’ preoperative\nclinical notes.35 GPT-4 Turbo achieved an F1 score of 0.50\nfor ASA-PS, 0.6 for hospital admissions, 0.8 for ICU\nadmissions, 0.6 for unplanned admissions, and 0.9 for\npredicting hospital mortality.35 While these scores indicate\na balanced performance (F1 score C 0.50), the model\nstruggled to accurately predict duration outcomes, such as\nPACU phase 1 duration, hospital length of stay, and ICU\nduration.\n35\nDanilov et al . corroborated the challenges faced by\nLLMs in predicting length of stay, by comparing physician\nestimates with the Russian-language version of GPT-3 in\npredicting patient length of stay in neurosurgery, using\nmean absolute error (MAE) in days.\n36 The analysis of\nnarrative medical records by ruGPT achieved accuracy\ncomparable to, but still inferior to, that of physicians and\npatients, with MAE values of 3.5, 2.5, and 3.5,\nrespectively. This integration of LLMs with clinician\nexpertise can optimize workﬂow efﬁciency, improving\npredictions of case durations, hospital stays, and workforce\nscheduling.\n37,38 Nevertheless, LLMs still need to enhance\ntheir performance in accurately predicting length of stay.\nAdministrative tasks, such as patient registration,\nbilling, documentation, and scheduling consume\nsigniﬁcant clinician time, reducing overall care quality. 39\nRecent research found that ChatGPT-4 efﬁciently\ngenerated billing codes, thus alleviating some of these\nburdens.40 Ongoing studies are investigating how LLMs\ncan further optimize operating room scheduling and\nimprove efﬁciency, potentially reducing clinician burnout.\nAutomated medical report synthesis from imaging data\nRapid bedside imaging, particularly whole-body point-of-\ncare ultrasound (POCUS), plays a vital role in\nperioperative diagnosis and clinical management. The use\nof GPT models to assist in interpreting imaging ﬁndings is\na growing area of interest.\n41,42 In addition to image\ninterpretation, report generation also remains a time-\nintensive task, often involving the synthesis of images,\nclinical notes, and other documents—processes that are\nprone to human error and dependent on the clinician’s\nexperience level. Automating report generation has\nemerged as a priority owing to its potential to improve\nefﬁciency and reduce errors.\n43 Bernardi et al. highlighted\nthat Llama LLMs, when equipped with retrieval-\naugmented generation (RAG), can access and utilize\nexternal information to generate responses.\n44 Retrieval-\naugmented generation enables LLMs to provide more\naccurate and relevant answers, surpassing existing\nradiology reporting methods in both quality and\naccuracy. While these ﬁndings are primarily from\nradiology, LLMs application to POCUS could\nrevolutionize perioperative care by improving the\ndiagnostic accuracy and efﬁciency. Combining LLMs\nwith clinician oversight could reduce the time spent on\nreport generation, allowing for faster, more accurate\nclinical decision-making.\nMedical education\nLarge language models, such as ChatGPT, have gained\nprominence in medical education by achieving\nperformance levels comparable to or surpassing\nthresholds on medical licensing exams, suggesting\npotentially impactful applications in medical education.\n45\n123\n1008 A. R. M. Hondjeu et al.\nFor instance, Subbaramaiah et al. demonstrated that GPT-\n3.5 could generate multiple-choice questions for regional\nanesthesia fellowship exams, with half of the candidates\nrating the LLM-generated exams as superior to previous\nversions. Nevertheless, human oversight is essential to\ncorrect factual inaccuracies and grammatical errors.\n46\nIn addition to generating exam questions, these models\ncan draft admission applications, raising serious concerns\nabout the integrity of the application process. Studies by\nJohnstone et al. and Patel et al. found that LLM-generated\npersonal statements for residency applications were often\nindistinguishable from those written by applicants; in fact,\n80% of program directors could not tell the difference\nbetween the two.\n47,48 While LLMs hold promise for\nsupporting exam preparation, their practical\nimplementation in medical education faces challenges\nrelated to academic integrity and error detection.\nResearch medical literature analysis\nThe increasing volume of scientiﬁc literature generated\nannually can overwhelm perioperative researchers and\nclinicians, making it difﬁcult to identify relevant data. As a\nresult, the demand for systematic reviews has grown\nsigniﬁcantly over the past few decades. Nevertheless,\ncompleting these reviews requires substantial time and\nresources. The National Institute for Health and Care\nExcellence (NICE) has recognized the potential of AI,\nparticularly LLMs, to automate the systematic review\nprocess, reducing both the time and effort required.\n49\nLarge language models have also been used to draft,\nedit, and guide writing in perioperative topics.\nNevertheless, their outputs often suffer from\nhallucinations, which are plausible yet incorrect\ninformation, as well as poor organization.\n49 Studies by\nHallo-Carrasco et al. and Wu et al. noted that LLMs lacked\nmethodological rigor and originality in their analyses. 50,51\nWhile earlier studies by Grigio et al. identiﬁed fabricated\nreferences, more recent research by Boussen et al. found\nthat ChatGPT-4, when combined with better prompts and\nplugin integration, generated more accurate citations. 52,53\nThis suggests that ongoing developments, including web\nintegration, have improved the utility of LLMs for\nliterature review tasks. With careful oversight, LLMs\nhold the potential to streamline research efforts and\nrevolutionize academic work.\nThe International Committee of Medical Journal Editors\n(ICMJE) now requires authors to disclose the use of AI-\nassisted technologies in manuscript preparation, including\nthis information in both the manuscript and the cover letter.\nAI technologies cannot be credited as authors due to\nseveral ICMJE authorship criteria being unmet, such as the\nability to take responsibility for published work, declare\ncompeting interests, and engage in copyright and licensing\nagreements. As a result, human authors must ensure that all\nAI-generated content is accurate and free from errors,\nfabrications, and plagiarism. Additionally, AI-assisted\ntechnologies should not be cited as primary sources, as\ninformation is merely replicated from other sources, which\ncan often be inaccurate or of questionable quality.\n54\nWhile LLMs hold signiﬁcant promise for medical\nliterature analysis, realizing their full potential requires a\ncritical evaluation of the limitations and challenges they\npresent, both in academia and routine clinical practice.\nChallenges associated with large language models\nin perioperative medicine\nWhile LLMs offer signiﬁcant promise in perioperative\ncare, it is essential to acknowledge their limitations.\nUnderstanding the challenges, such as hallucinations,\nbiases, and data security concerns, is critical for LLMs\nsuccessful integration into clinical workﬂows.\nHallucinations and fabricated information\nHallucinations occur when LLMs generate content that is\nnonsensical or inconsistent with source data. This problem\nstems from training on a diverse range of data, including\nboth high-quality and unreliable information that may\ncontain inaccuracies, outdated details, or biases.\nAdditionally, LLMs lack genuine understanding and\nreasoning abilities, which can lead them to\novergeneralize from their training data and conﬁdently\nassert false facts. Finally, ambiguous prompts can trigger\nthe generation of hallucinations, as the models may attempt\nto ‘‘ﬁll in’’ gaps with incorrect or fabricated information to\nmaintain coherence and ﬂuency.\n55 Hallucinations can be\nbroadly categorized into two types:\n1. Intrinsic hallucinations : these directly conﬂict with the\nsource material, introducing factual inaccuracies or\nlogical inconsistencies.\n2. Extrinsic hallucinations : these are unveriﬁable against\nthe source and include speculative or unconﬁrmable\nelements.\nIn perioperative medicine, incorrect information can\nhave serious consequences. The automated measurement of\nhallucinations in LLMs has been proposed through a\ncombination of statistical and model-based metrics.\nDespite advances in automated statistical and model-\nbased metrics, human judgement remains vital and\ntypically involves two methodologies:\n123\nLarge language models in perioperative medicine 1009\n1. Scoring: human evaluators rate hallucinations on a\npredeﬁned scale.\n2. Comparative analysis : evaluators compare generated\ncontent with veriﬁed references, adding an essential\nlayer of subjective assessment.\nMitigation strategies include:\n• User interaction and design : tailored case design,\nstructuring the input/output, or providing mechanisms\nfor user feedback.\n• Data management : tracking and analyzing\nhallucinations for improvement.\n• Prompt engineering : optimizing prompts on the basis\nof model capabilities. This process is iterative and\nexploratory.\n• Domain-speciﬁc ﬁne-tuning : reducing hallucination\nrisks through targeted training.\nHallucinations are a multifaceted challenge, and\nmultiple research endeavors are dedicated to addressing\nand mitigating them. The introduction of the Medical\nDomain Hallucination Test (Med-HALT), a novel\nbenchmark data set, serves to evaluate hallucination\nphenomena in LLMs in medical contexts.\n56,57\nExplainability and transparency\nExplainable AI enables users to understand and trust\nmachine learning outputs, while AI transparency ensures\nclarity in decision-making processes and algorithms. In\nperioperative medicine, these principles are critical for\nfostering trust and adoption of LLMs. Best clinical practice\nemphasizes the continuous pursuit of transparency and\ninterpretable frameworks to enhance decision-making in\nperioperative medicine.\n58 Nevertheless, LLMs often lack\ntransparency owing to their opaque nature, which can\nhinder acceptance among perioperative clinicians.\nMoreover, biases in training data may compromise\naccuracy, potentially leading to incorrect diagnoses or\ntreatment recommendations. In perioperative medicine,\nclinicians and researchers must critically assess LLM\noutputs before integration into practice. Creating more\ninterpretable and transparent models remains an ongoing\nchallenge.\n59\nSecurity and privacy considerations\nProtecting patient data is essential when using publicly\navailable LLMs. Input data must be fully anonymized, as it\nmay be used for future training. Strong safeguards,\nincluding data anonymization, secure storage, and strict\nadherence to ethical guidelines, are necessary to mitigate\nthe risks. Proactive policies should extend beyond basic\nprivacy laws to anticipate challenges, and experts must\nverify that LLMs meet ethical guidelines. Engaging\npatients and health care providers in the development\nprocess promotes transparency and maintains trust in data\nhandling. Some companies are working with speciﬁc health\nnetworks to create encrypted local LLMs that are Health\nInsurance Portability and Accountability Act (HIPAA)\ncompliant.\nBias and fairness\nLarge language models can amplify pre-existing biases\ninherent in their training data, especially those linked to\ndemographics, disease prevalence, or treatment outcomes.\nConsequently, the generated outputs may inadvertently\nperpetuate and even magnify these biases, posing\nsigniﬁcant challenges to achieving equitable and unbiased\ncare. To address these challenges, researchers and\nclinicians should diligently curate and preprocess training\ndata to reduce inherent biases and address sources of\ninequality.\n60 Routine audits and evaluations are necessary\nto identify and correct biases in model training and\ndeployment. Collaborative efforts between domain\nexperts, ethicists, and data scientists can establish\nguidelines and best practices for unbiased LLM\ndevelopment, fostering fairness and inclusivity in\nbiomedical research and health care. Researching ways to\nreduce biases in LLMs, while also understanding their\nethical ramiﬁcations, remains a pivotal research domain.\nAbsence of memory\nLarge language models possess ﬁxed and limited memory\ncapacity because of the self-attention algorithm. This\nmechanism allows LLMs to weigh the importance of\ndifferent input elements when making predictions or\ndecision. Consequentially, this prevents LLMs from\nretaining prior inputs and limits. Their usefulness in tasks\nrequiring continuity is thus limited.\nStochastic/probabilistic nature\nLarge language models generate probabilistic responses,\nmeaning identical prompts may yield different answers.\nWhile variability can be adjusted, it remains an inherent\nlimitation.\nAccess to external data\nMost LLMs operate solely on their training data, limiting\nreal-time knowledge updates. This can be a critical\nlimitation in a continuous evolving ﬁeld of perioperative\nmedicine. Some models integrate search engines (e.g.,\n123\n1010 A. R. M. Hondjeu et al.\nChatGPT with Bing [Microsoft Corporation, Redmond,\nWA, USA]) to provide current information, but reliability\nconcerns remain owing to unveriﬁed sources.\nCost\nInﬂation, rising fabrication costs, inventory restrictions,\nand limited market competition have led to a continuous\nincrease in the price of graphics processing units. Large\nlanguage models, which can be extremely resource-\nintensive, require expensive and complex graphics\nprocessing units for both training and deployment.\nEnvironmental considerations\nThe rapid development of LLMs comes with signiﬁcant\nenvironmental considerations. Training these models\nrequires massive computational resources, which\nconsume vast amounts of energy. This energy is\nprimarily used by large, energy-intensive data centres,\ncontributing to greenhouse gas emissions. The carbon\nfootprint of these models is inﬂuenced by the energy\nsource—whether renewable or fossil fuel-based.\nAdditionally, deploying LLMs for real-time applications,\nsuch as patient-facing chatbots, increases their energy\ndemands as every interaction requires continuous\ncomputation. The environmental impact of LLMs goes\nbeyond just the training and inference phases. The full life\ncycle, including the manufacturing of hardware,\ntransportation, and eventual disposal of outdated\ncomponents, adds to the overall environmental cost. This\nis particularly relevant as AI hardware is continuously\nupgraded to keep up with larger, more powerful models.\nStrategies to reduce the carbon footprint include:\n• Model distillation : training smaller, efﬁcient models.\n• Sparse computing : activating only necessary model\ncomponents.\n• Renewable energy adoption : transitioning data centres\nto sustainable power sources.\nAs LLMs become increasingly integrated into health\ncare, including perioperative settings, balancing AI\nadvancements with environmental sustainability will\ncontinue to be a growing priority.\nLegal and ethical reasons\nA major ethical consideration is the blurred line between\nLLM-generated and human-written text. This poses a risk\nof misinformation dissemination, plagiarism, and\nimpersonation in medical literature. Regulatory\nframeworks, such as the European Union’s AI Act and\nthe US’ HIPAA, also signiﬁcantly limit AI deployment in\nhealth care. Other relevant laws and compliance\nframeworks include the General Data Protection\nRegulation in the European Union and the Medical\nDevice Regulation, which ensure the safety and efﬁcacy\nof AI-driven medical devices. These regulations impose\nstrict compliance requirements, including detailed\ndocumentation of AI models, advanced data encryption\nand access controls, and rigorous clinical testing to ensure\nreliability and safety.\nBy balancing innovation with reliability, legal\naccountability, and ethical standards in AI development,\ntrust can be fostered among stakeholders and encourages\nthe responsible and wider adoption of AI technologies in\nhealth care.\n61 Figure 4 summarizes key limitations of\nLLMs in perioperative medicine, including hallucinations,\nbias, transparency issues, security risks, and environmental\nconcerns. Addressing these challenges is essential for safe\nclinical integration.\nProspects and open challenges of perioperative use\nof large language models\nDespite current limitations, ongoing research aims to\nenhance LLM accuracy, mitigate biases, and ensure\nethical integration into clinical care. Below, we highlight\nkey challenges and areas of active development.\n• Smaller, more efﬁcient models : while larger models,\nsuch as GPT-4, excel in accuracy and performance,\nthey are costly and inefﬁcient, particularly in latency\n(time delay between when LLM receives an input and\ngenerates the corresponding output). There is growing\ninterest in developing smaller, task-speciﬁc models that\noffer cost-effective alternatives without sacriﬁcing\nessential capabilities.\n• Multimodal models : unlike early LLMs, multimodal\nLLMs process diverse data types—including text,\nimages, videos, and audio—expanding their potential\napplications. Research in this ﬁeld continues to\naccelerate.\n• Enhanced LLM performance through augmentation :\nseveral techniques improve LLM reliability and reduce\nlimitations such as hallucination:\n1) Prompt engineering : this involves crafting\noptimized inputs to guide model output on the\nbasis of domain expertise and AI understanding.\n2) RAG: this enables LLMs to retrieve and\nincorporate external information, improving\nresponse accuracy.\n62 It functions similarly to how\na person consults reference materials before\nanswering a complex question. A RAG system\nconsists of three key components: retrieval,\ngeneration, and augmentation. The process begins\n123\nLarge language models in perioperative medicine 1011\nwith extracting a query from the input prompt,\nretrieving relevant information from external\nsources (e.g., search engines or databases), and\nintegrating this data into the model’s response. By\nspecifying the external source, users can use RAG\nto ensure LLM responses are more accurate and\nrelevant to the database desired. For example,\nLong et al. used RAG to develop ChatENT, an\notolaryngology-trained LLM.\n63 ChatENT\noutperformed GPT-4 on Canadian and US exam\nquestions, providing scientiﬁcally valid answers\nwithout the safety concerns.\n63 This success\nhighlights the potential for specialty-speciﬁc\nLLMs, an area of research expected to grow\nrapidly.\n3) Tools: these are external functions or services that\nLLMs can utilize to extend their task range, from\nbasic information retrieval to complex interactions\nwith external databases.\n• Post-attention architecture : transformer-based LLMs\nrely on self-attention mechanisms but will struggle with\nlong-context comprehension. Research into\npostattention paradigms seeks to enhance their ability\nto process extended inputs more effectively.\n• Security ethics and responsible LLMs : ensuring that\nLLMs are fair, unbiased, and capable of handling\nsensitive medical data responsibly remains a priority.\nAs these models integrate further into health care,\nmaintaining ethical safeguards is critical.\n• LLM integration in perioperative medicine : the\nsuccessful adoption of LLMs in perioperative practice\nrequires interdisciplinary collaboration for\ndevelopment, validation, and implementation. To fully\nleverage AI’s potential, anesthesia teams must establish\nrobust systems for high-quality data collection, storage,\nand analysis, fostering a structured approach to\ninnovation.\nConclusions\nThe integration of LLMs into perioperative medicine\npresents a signiﬁcant opportunity to enhance patient care,\nclinical decision-making, and operational efﬁciency. These\nmodels can streamline processes, provide personalized\npatient education, and offer robust decision support.\nNevertheless, their clinical implementation requires\naddressing several key challenges, including managing\nhallucinations, ensuring data security, and mitigating\ninherent biases.\nFuture research should focus on the real-world\nvalidation of LLMs, particularly in high-stakes clinical\nenvironments such as surgery and anesthesiology. Ethical\nconsiderations and the transparent use of LLMs are crucial\nto maintaining trust among clinicians and patients alike. By\ncollaborating across disciplines, the perioperative\ncommunity can harness the full potential of LLMs to\ndeliver safer, more efﬁcient, and personalized care. If these\nchallenges are met, LLMs can revolutionize perioperative\npractice, improving both patient outcomes and clinician\nworkﬂow.\nAuthor contributions Arnaud R. Mbadjeu Hondjeu conceptualized\nthe review, designed the literature search strategy, conducted the\ndatabase searches, selected the articles for inclusion, provided expert\ninsights into LLMs and AI, content expertise in perioperative\nmedicine, analyzed the ﬁndings, drafted the manuscript, and\nensured scientiﬁc rigor. Zi Ying Zhao assisted in reﬁning the\nliterature search criteria, provided content expertise in perioperative\nmedicine, elaborated data visualization, provided critical input on\narticle inclusion decisions, and contributed to manuscript revisions.\nLuka Newton and Anass Ajenkar assisted in reﬁning the literature\nsearch criteria, provided critical input on article inclusion decisions,\nand contributed to manuscript revisions. Emily Hladkowicz\ncontributed to manuscript revisions. Karim Ladha provided expert\ninsights into perioperative medicine and contributed to manuscript\nrevisions. Duminda N. Wijeysundera provided expert insights into\nperioperative medicine, ensured scientiﬁc rigor, and contributed to\nmanuscript revisions. Daniel I. McIsaac Conceptualized the review,\ndesigned the literature search strategy, provided critical input on\narticle inclusion decisions, provided expert insights into perioperative\nmedicine, reviewed, and revised the manuscript for important\nintellectual content, and ensured scientiﬁc rigor.\nAcknowledgements We sincerely thank Maggie Z. X. Xiao for\ntheir invaluable contributions to this project.\nDisclosures The authors declare no conﬂicts of interest related to\nthe content of this article.\nFunding statement Drs Mbadjeu Hondjeu and McIsaac are\nsupported by The Ottawa Hospital Anesthesia Alternate Funds\nAssociation.\nEditorial responsibility This submission was handled by\nDr. Stephan K. W. Schwarz, Editor-in-Chief, Canadian Journal of\nAnesthesia/Journal canadien d’anesthe´sie.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate\nif changes were made. The images or other third party material in this\narticle are included in the article’s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visit http://creativecommons.\norg/licenses/by/4.0/.\n123\n1012 A. R. M. Hondjeu et al.\nReferences\n1. Bellman RE . Artiﬁcial Intelligence: Can Computers Think? San\nFrancisco: Boyd & Fraser Publising Company; 1978.\n2. Feuerriegel S, Hartmann J, Janiesch C, Zschech P . Generative\nAI. Bus Inf Syst Eng 2024; 66: 111–26. https://doi.org/10.1007/\ns12599-023-00834-7\n3. Chowdhary KR . Natural language processing. In: Fundamentals\nof Artiﬁcial Intelligence. New Delhi: Springer; 2020: 603–49.\n4. Devlin J, Chang MW, Lee K, Toutanova K . Bert: pre-training of\ndeep bidirectional transformers for language understanding.\narXiv preprint arXiv:181004805 (Preprint). 2019. https://doi.\norg/10.18653/v1/N19-1423\n5. Grocott M, Edwards M, Mythen M, Aronson S . Peri-operative\ncare pathways: re-engineering care to achieve the ’triple aim’.\nAnaesthesia 2019; 74: 90–9. https://doi.org/10.1111/anae.14513\n6. Yang X, Chen A, PourNejatian N, et al . A large language model\nfor electronic health records. NPJ Digit Med 2022; 5: 194. https://\ndoi.org/10.1038/s41746-022-00742-2\n7. Adams LC, Truhn D, Busch F, et al . Leveraging GPT-4 for post\nhoc transformation of free-text radiology reports into structured\nreporting: a multilingual feasibility study. Radiology 2023; 307:\ne230725. https://doi.org/10.1148/radiol.230725\n8. McDuff D, Schaekermann M, Tu T, et al . Towards accurate\ndifferential diagnosis with large language models. arXiv preprint\narXiv:231200164 (Preprint). 30 November 2023. Available from\nURL: https://jakegarrison.me/doc/Towards%20Accurate%\n20Differential%20Diagnosis%20with%20Large%20Language%\n20Models.pdf (accessed April 2025).\n9. Jiang LY, Liu XC, Nejatian NP, et al . Health system-scale\nlanguage models are all-purpose prediction engines. Nature 2023;\n619: 357–62. https://doi.org/10.1038/s41586-023-06160-y\n10. Clusmann J, Kolbinger FR, Muti HS, et al . The future landscape\nof large language models in medicine. Commun Med (London)\n2023; 3: 141. https://doi.org/10.1038/s43856-023-00370-1\n11. Liu S, McCoy AB, Wright AP, et al. Leveraging large language\nmodels for generating responses to patient messages—a\nsubjective analysis. J Am Med Inform Assoc 2024; 31:\n1367–79. https://doi.org/10.1093/jamia/ocae052\n12. Mello MM, Rose S . Denial—artiﬁcial intelligence tools and\nhealth insurance coverage decisions. JAMA Health Forum 2024;\n5: e240622. https://doi.org/10.1001/jamahealthforum.2024.0622\n13. American Medical Association. Artiﬁcial intelligence vs.\naugmented intelligence; 2025. Available from URL: https://\nwww.ama-assn.org/practice-management/digital/augmented-\nintelligence-medicine (accessed April 2025).\n14. Yin S, Fu C, Zhao S, et al . A survey on multimodal large language\nmodels. Natl Sci Rev; 2024; 11: nwae403. https://doi.org/10.\n1093/nsr/nwae403\n15. Radford A, Narashimhan K, Salimans T, Sutskever I . Improving\nlanguage understanding by generative pre-training. (Preprint).\n2018. Available from URL: https://www.mikecaptain.com/\nresources/pdf/GPT-1.pdf\n(accessed April 2025).\n16. Liu J, Liang X, Fang D, et al . The diagnostic ability of GPT-3.5\nand GPT-4.0 in surgery: comparative analysis. J Med Internet Res\n2024; 26: e54985. https://doi.org/10.2196/54985\n17. Becker M, Nassar H, Espinosa C, et al . Large-scale correlation\nnetwork construction for unraveling the coordination of complex\nbiological systems. Nat Comput Sci 2023; 3: 346–59. https://doi.\norg/10.1038/s43588-023-00429-y\n18. Lim DY, Ke YH, Sng GG, Tung JY, Chai JX, Abdullah HR . Large\nlanguage models in anaesthesiology: use of ChatGPT for\nAmerican Society of Anesthesiologists physical Status\nclassiﬁcation. Br J Anaesth 2023; 131: e73–5. https://doi.org/\n10.1016/j.bja.2023.06.052\n19. Apfelbaum J, Connis R, Nickinovich D, et al . Practice advisory\nfor preanesthesia evaluation: an updated report by the American\nSociety of Anesthesiologists Task Force on Preanesthesia\nEvaluation. Anesthesiology 2012; 116: 522–38. https://doi.org/\n10.1097/aln.0b013e31823c1067\n20. Weiss BD . Health literacy: a manual for clinicians; 2003.\nAvailable from URL: http://lib.ncfh.org/pdfs/6617.pdf (accessed\nApril 2025).\n21. Kumar G, Jaremko KM, Kou A, Howard SK, Harrison TK,\nMariano ER . Quality of patient education materials on safe\nopioid management in the acute perioperative period: what do\npatients ﬁnd online? Pain Med 2020; 21: 171–5. https://doi.org/\n10.1093/pm/pny296\n22. Baker DW, Gazmararian JA, Williams MV, et al . Functional\nhealth literacy and the risk of hospital admission among Medicare\nmanaged care enrollees. Am J Public Health 2002; 92: 1278–83.\nhttps://doi.org/10.2105/ajph.92.8.1278\n23. Hong HJ, Schmiesing CA, Goodell AJ . Enhancing the readability\nof preoperative patient instructions using large language models.\nAnesthesiology 2024; 141: 608–10. https://doi.org/10.1097/aln.\n0000000000005122\n24. Lockie E, Choi J . Evaluation of a Chat GPT generated patient\ninformation leaﬂet about laparoscopic cholecystectomy. ANZ J\nSurg 2024; 94: 353–5. https://doi.org/10.1111/ans.18834\n25. Nanji K, Caberry WY, Wong TY, et al . Evaluation of\npostoperative ophthalmology patient instructions from ChatGPT\nand Google Search. Can J Ophthalmol 2024; 59: e69–71. https://\ndoi.org/10.1016/j.jcjo.2023.10.001\n26. Klafta JM, Roizen MF . Current understanding of patients’\nattitudes toward and preparation for anesthesia: a review.\nAnesth Analg 1996; 83: 1314–21. https://doi.org/10.1097/\n00000539-199612000-00031\n27. Patnaik SS, Hoffmann U . Comparison of ChatGPT vs. Bard to\nanesthesia-related queries. medRxiv (Preprint). 30 June 2023.\nhttps://doi.org/10.1101/2023.06.29.23292057\n28. Loftus TJ, Altieri MS, Balch JA, et al . Artiﬁcial intelligence–\nenabled decision support in surgery: state-of-the-art and future\ndirections. Ann Surg 2023; 278: 51–8. https://doi.org/10.1097/sla.\n0000000000005853\n29. Navarrete-Welton AJ, Hashimoto DA . Current applications of\nartiﬁcial intelligence for intraoperative decision support in\nsurgery. Front Med 2020; 14: 369–81. https://doi.org/10.1007/\ns11684-020-0784-7\n30. He Y, Tang H, Wang D, Gu S, Ni G, Wu H . Will ChatGPT/GPT-4\nbe a lighthouse to guide spinal surgeons? Ann Biomed Eng 2023;\n51: 1362–5. https://doi.org/10.1007/s10439-023-03206-0\n31. Goodman RS, Patrinely JR, Stone CA Jr, et al\n. Accuracy and\nreliability of Chatbot responses to physician questions. JAMA\nNetw Open 2023; 6: e2336483. https://doi.org/10.1001/\njamanetworkopen.2023.36483\n32. Yuan Q, Cai T, Hong C, et al. Performance of a machine learning\nalgorithm using electronic health record data to identify and\nestimate survival in a longitudinal cohort of patients with lung\ncancer. JAMA Netw Open 2021; 4: e2114723. https://doi.org/10.\n1001/jamanetworkopen.2021.14723\n33. Abi-Rafeh J, Henry N, Xu HH, et al . Utility and comparative\nperformance of current artiﬁcial intelligence large language\nmodels as postoperative medical support chatbots in aesthetic\nsurgery. Aesthet Surg J 2024; 44: 889–96. https://doi.org/10.\n1093/asj/sjae025\n34. Gomez-Cabello CA, Borna S, Pressman SM, Haider SA, Forte\nAJ. Large language models for intraoperative decision support in\nplastic surgery: a comparison between ChatGPT-4 and Gemini.\nMedicina (Kaunas) 2024; 60: 957. https://doi.org/10.3390/\nmedicina60060957\n123\nLarge language models in perioperative medicine 1013\n35. Chung P, Fong CT, Walters AM, Aghaeepour N, Yetisgen M,\nO’Reilly-Shah VN . Large language model capabilities in\nperioperative risk prediction and prognostication. JAMA Surg\n2024; 159: 928–37. https://doi.org/10.1001/jamasurg.2024.1621\n36. Danilov G, Kotik K, Shevchenko E, et al . Predicting the length of\nstay in neurosurgery with RuGPT-3 language model. Stud Health\nTechnol Inform 2022; 295: 555–8. https://doi.org/10.3233/\nshti220788\n37. Bartek MA, Saxena RC, Solomon S, et al . Improving operating\nroom efﬁciency: machine learning approach to predict case-time\nduration. J Am Coll Surg 2019; 229: 346–54. https://doi.org/10.\n1016/j.jamcollsurg.2019.05.029\n38. Eshghali M, Kannan D, Salmanzadeh-Meydani N, Esmaieeli\nSikaroudi AM . Machine learning based integrated scheduling and\nrescheduling for elective and emergency patients in the operating\ntheatre. Ann Oper Res 2024; 332: 989–1012. https://doi.org/10.\n1007/s10479-023-05168-x\n39. Duszak R, Blackham WC, Kusiak GM, Majchrzak J . CPT coding\nby interventional radiologists: a multi-institutional evaluation of\naccuracy and its economic implications. J Am Coll Radiol 2004;\n1: 734–40. https://doi.org/10.1016/j.jacr.2004.05.003\n40. Zaidat B, Lahoti YS, Yu A, Mohamed KS, Cho SK, Kim JS.\nArtiﬁcially intelligent billing in spine surgery: an analysis of a\nlarge language model. Global Spine J 2025; 15: 1113–20. https://\ndoi.org/10.1177/21925682231224753\n41. Ueda D, Mitsuyama Y, Takita H, et al. ChatGPT’s diagnostic\nperformance from patient history and imaging ﬁndings on the\nDiagnosis Please quizzes. Radiology 2023; 308: e231040. https://\ndoi.org/10.1148/radiol.231040\n42. Horiuchi D, Tatekawa H, Oura T, et al. Comparing the diagnostic\nperformance of GPT-4-based ChatGPT, GPT-4V-based\nChatGPT, and radiologists in challenging neuroradiology cases.\nClin Neuroradiol 2024; 34: 779–87. https://doi.org/10.1007/\ns00062-024-01426-y\n43. Nakaura T, Yoshida N, Kobayashi N, et al. Preliminary\nassessment of automated radiology report generation with\ngenerative pre-trained transformers: comparing results to\nradiologist-generated reports. Jpn J Radiol 2024; 42: 190–200.\nhttps://doi.org/10.1007/s11604-023-01487-y\n44. Bernardi ML, Cimitile M . Report generation from x-ray imaging\nby retrieval-augmented generation and improved image-text\nmatching. Proc Int Jt Conf Neural Netw 2024; https://doi.org/\n10.1109/ijcnn60899.2024.10650332\n45. Kung TH, Cheatham M, Medenilla A, et al . Performance of\nChatGPT on USMLE: potential for AI-assisted medical education\nusing large language models. PLOS Digit Health 2023; 2:\ne0000198. https://doi.org/10.1371/journal.pdig.0000198\n46. Subbaramaiah MT, Dixit A, Sivashanmugam T . Impact of\nChatGPT support on conducting regional anaesthesia\nexamination. Indian J Anaesth 2023; 67: 1025–6. https://doi.\norg/10.4103/ija.ija_841_23\n47. Johnstone RE, Neely G, Sizemore DC. Artiﬁcial intelligence\nsoftware can generate residency application personal statements\nthat program directors ﬁnd acceptable and difﬁcult to distinguish\nfrom applicant compositions. J Clin Anesth 2023; 89: 111185.\nhttps://doi.org/10.1016/j.jclinane.2023.111185\n48. Patel V, Deleonibus A, Wells MW, Bernard SL, Schwarz GS .\nDistinguishing authentic voices in the age of ChatGPT:\ncomparing AI-generated and applicant-written personal\nstatements for plastic surgery residency application. Ann Plast\nSurg 2023; 91: 324–5. https://doi.org/10.1097/sap.\n0000000000003653\n49. National Institute for Health and Care Excellence . Use of AI in\nevidence generation: NICE position statement; 2024. Available\nfrom URL: https://www.nice.org.uk/about/what-we-do/our-\nresearch-work/use-of-ai-in-evidence-generation–nice-position-\nstatement (accessed April 2025).\n50. Hallo-Carrasco A, Gruenbaum B, Gruenbaum S\n. Heat and\nmoisture exchanger occlusion leading to sudden increased airway\npressure: a case report using ChatGPT as a personal writing\nassistant. Cureus 2023; 15: e37306. https://doi.org/10.7759/\ncureus.37306\n51. Wu CL, Cho B, Gabriel R, et al. Addition of dexamethasone to\nprolong peripheral nerve blocks: a ChatGPT-created narrative\nreview. Reg Anesth Pain Med 2023; 49: 777–81. https://doi.org/\n10.1136/rapm-2023-104646\n52. Grigio TR, Timmerman H, Wolff AP . ChatGPT in anaesthesia\nresearch: risk of fabrication in literature searches. Br J Anaesth\n2023; 131: e29–30. https://doi.org/10.1016/j.bja.2023.04.009\n53. Boussen S, Denis JB, Simeone P, Lagier D, Bruder N, Velly L .\nChatGPT and the stochastic parrot: artiﬁcial intelligence in\nmedical research. Br J Anaesth 2023; 131: e120–1. https://doi.\norg/10.1016/j.bja.2023.06.065\n54. International Committee of Medical Journal Editors.\nRecommendations for the conduct, reporting, editing, and\npublication of scholarly work in medical journals; 2025.\nAvailable from URL: https://www.icmje.org/icmje-\nrecommendations.pdf (accessed April 2025).\n55. Ji Z, Lee N, Frieske R, et al . Survey of hallucination in natural\nlanguage generation. ACM Comput Surv 2023; 55: 1–38. https://\ndoi.org/10.1145/3571730\n56. Tian S, Jin Q, Yeganova L, et al . Opportunities and challenges for\nChatGPT and large language models in biomedicine and health.\nBrief Bioinform 2024; 25: bbad493. https://doi.org/10.1093/bib/\nbbad493\n57. Umapathi LK, Pal A, Sankarasubbu M . Med-halt: Medical\ndomain hallucination test for large language models. arXiv\npreprint arXiv:230715343 (Preprint). 14 October 2023; https://\ndoi.org/10.48550/arXiv.2307.15343\n58. Reddy S . Evaluating large language models for use in healthcare:\na framework for translational value assessment. Inform Med\nUnlocked 2023; 41: 101304. https://doi.org/10.1016/j.imu.2023.\n101304\n59. Briganti G . A clinician’s guide to large language models. Future\nMed AI 2023; 1: FMAI1. https://doi.org/10.2217/fmai-2023-0003\n60. Thapa S, Adhikari S . ChatGPT, bard, and large language models\nfor biomedical research: opportunities and pitfalls. Ann Biomed\nEng 2023; 51: 2647–51. https://doi.org/10.1007/s10439-023-\n03284-0\n61. Hacker P, Engel A, Mauer M . Regulating ChatGPT and other\nlarge generative AI models. FAccT 2023; 1112–23. https://doi.\norg/10.1145/3593013.3594067\n62. Lewis P, Perez E, Piktus A, et al . Retrieval-augmented generation\nfor knowledge-intensive NLP tasks. Adv Neural Inf Process Syst\n2020; 33: 9459–74.\n63. Long C, Subburam D, Lowe K, et al. ChatENT: augmented large\nlanguage model for expert knowledge retrieval in\nOtolaryngology–Head and Neck Surgery. Otolaryngol Head\nNeck Surg 2024; 171: 1042–51. https://doi.org/10.1002/ohn.864\nPublisher’s Note Springer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional afﬁliations.\n123\n1014 A. R. M. Hondjeu et al.",
  "topic": "Narrative",
  "concepts": [
    {
      "name": "Narrative",
      "score": 0.652842104434967
    },
    {
      "name": "Narrative review",
      "score": 0.5935752391815186
    },
    {
      "name": "Computer science",
      "score": 0.36309802532196045
    },
    {
      "name": "Linguistics",
      "score": 0.34940093755722046
    },
    {
      "name": "Medicine",
      "score": 0.34293287992477417
    },
    {
      "name": "Intensive care medicine",
      "score": 0.3132999539375305
    },
    {
      "name": "Philosophy",
      "score": 0.14468783140182495
    }
  ]
}