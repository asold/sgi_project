{
  "title": "CrisisBERT: a Robust Transformer for Crisis Classification and Contextual Crisis Embedding",
  "url": "https://openalex.org/W3024089051",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A1523044921",
      "name": "Liu Jun-hua",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4202211126",
      "name": "Singhal, Trisha",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4227844198",
      "name": "Blessing, Lucienne T. M.",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4294568728",
      "name": "Wood, Kristin L.",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4202211128",
      "name": "Lim, Kwan Hui",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2999678654",
    "https://openalex.org/W2807945507",
    "https://openalex.org/W2562892017",
    "https://openalex.org/W3019094172",
    "https://openalex.org/W3010726743",
    "https://openalex.org/W1821462560",
    "https://openalex.org/W2949541494",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2151098288",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W2923864562",
    "https://openalex.org/W1934362406",
    "https://openalex.org/W2970872015",
    "https://openalex.org/W2962707464",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2920828800",
    "https://openalex.org/W2187303655",
    "https://openalex.org/W2963947170",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2950541952",
    "https://openalex.org/W2783064254",
    "https://openalex.org/W2880875857",
    "https://openalex.org/W2281420995",
    "https://openalex.org/W2153579005",
    "https://openalex.org/W2132339004",
    "https://openalex.org/W2971193649",
    "https://openalex.org/W2124499489",
    "https://openalex.org/W2529142661",
    "https://openalex.org/W2981352723",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2535764243",
    "https://openalex.org/W3013515664",
    "https://openalex.org/W2154424391",
    "https://openalex.org/W641710284",
    "https://openalex.org/W3015767757",
    "https://openalex.org/W2713160533"
  ],
  "abstract": "Classification of crisis events, such as natural disasters, terrorist attacks and pandemics, is a crucial task to create early signals and inform relevant parties for spontaneous actions to reduce overall damage. Despite crisis such as natural disasters can be predicted by professional institutions, certain events are first signaled by civilians, such as the recent COVID-19 pandemics. Social media platforms such as Twitter often exposes firsthand signals on such crises through high volume information exchange over half a billion tweets posted daily. Prior works proposed various crisis embeddings and classification using conventional Machine Learning and Neural Network models. However, none of the works perform crisis embedding and classification using state of the art attention-based deep neural networks models, such as Transformers and document-level contextual embeddings. This work proposes CrisisBERT, an end-to-end transformer-based model for two crisis classification tasks, namely crisis detection and crisis recognition, which shows promising results across accuracy and f1 scores. The proposed model also demonstrates superior robustness over benchmark, as it shows marginal performance compromise while extending from 6 to 36 events with only 51.4% additional data points. We also proposed Crisis2Vec, an attention-based, document-level contextual embedding architecture for crisis embedding, which achieve better performance than conventional crisis embedding methods such as Word2Vec and GloVe. To the best of our knowledge, our works are first to propose using transformer-based crisis classification and document-level contextual crisis embedding in the literature.",
  "full_text": "CRISIS BERT: A R OBUST TRANSFORMER FOR CRISIS\nCLASSIFICATION AND CONTEXTUAL CRISIS EMBEDDING\nJunhua Liu1,2, Trisha Singhal1, Lucienne T.M. Blessing1, Kristin L. Wood1, Kwan Hui Lim1\nj@forth.ai, {trisha_singhal, lucienne_blessing, kristinwood, kwanhui_lim}@sutd.edu.sg\n1Singapore University of Technology and Design\n2ProQod Singapore\nABSTRACT\nClassiﬁcation of crisis events, such as natural disasters, terrorist attacks and pandemics, is a crucial task to\ncreate early signals and inform relevant parties for spontaneous actions to reduce overall damage. Despite\nthe crises, such as natural disaster, that can be predicted by professional institutions, certain events are ﬁrst\nsignaled by everyday citizens, i.e., civilians, such as the recent COVID-19 pandemics. Social media platforms\nsuch as Twitter often expose ﬁrsthand signals on such crises through high volume information exchange. In\nthe case of Twitter, this corresponds to on average over half a billion tweets posted daily. Prior works proposed\nvarious crisis embeddings and classiﬁcation using conventional Machine Learning and Neural Network models.\nHowever, none of the works perform crisis embedding and classiﬁcation using state of the art attention-based\ndeep neural networks models, such as Transformers and document-level contextual embeddings. This work\nproposes CrisisBERT, an end-to-end transformer-based model for two crisis classiﬁcation tasks, namely\ncrisis detection and crisis recognition, which shows promising results across accuracy and f1 scores. The\nproposed model demonstrates superior robustness over various benchmarks, as it shows marginal performance\ncompromise while extending from 6 to 36 events with only 51.4% additional data points. We also propose\nCrisis2Vec, an attention-based, document-level contextual embedding architecture for crisis embedding, which\nachieves better performance than conventional crisis embedding methods such asWord2Vecand GloVe. To\nthe best of our knowledge, our works are ﬁrst to propose using transformer-based crisis classiﬁcation and\ndocument-level contextual crisis embedding in the literature.\nKeywords Crisis Classiﬁcation ·Contextual Crisis Embedding ·CrisisBERT ·Crisis2Vec ·Tweets\n1 Introduction\nCrisis-related events, such as earthquakes, hurricanes and train or airliner accidents, often stimulate a sudden surge of attention\nand actions from both media and the general public. Despite the fact that crises, such as natural disasters, can be predicted by\nprofessional institutions, certain events are ﬁrst signaled by everyday citizens, i.e., civilians. For instance, the recent COVID-19\npandemics was ﬁrst informed by general public in China via Weibo, a popular social media site, before pronouncements by\ngovernment ofﬁcials.\nSocial media sites have become centralized hubs that facilitate timely information exchange across government agencies,\nenterprises, working professionals and the general public. As one of the most popular social media sites, Twitter enables users\nto asynchronously communicate and exchange information with tweets, which are mini-blog posts limited to 280 characters.\nThere are on average over half a billion tweets posted daily[1]. Therefore, one can leverage on such high volume and frequent\ninformation exchange to expose ﬁrsthand signals on crisis-related events for early detection and warning systems to reduce\noverall damage and negative impacts.\nEvent detection from tweets has received signiﬁcant attention in research in order to analyze crisis-related messages for better\ndisaster management and increasing situational awareness. Several recent works studied various natural crisis events, such as\nhurricanes and earthquakes, and artiﬁcial disasters, such as terrorist attacks and explosions[2, 3, 4, 5].\narXiv:2005.06627v2  [cs.CL]  18 May 2020\nLIU ET AL . - A PREPRINT\nThese works focus on binary classiﬁcations for various attributes of crisis, such as classifying source type, predicting relatedness\nbetween tweets and the crises, and assessing informativeness and applicability [ 6, 7, 8]. On the other hand, several works\nproposed multi-label classiﬁers on affected individuals, infrastructure, casualties, donations, caution, advice, etc. [9, 10]. Crisis\nrecognition tasks are likewise conducted such as identifying crisis types, i.e. hurricanes, ﬂoods and ﬁres [11, 12].\nMachine Learning-based models are commonly introduced in performing the above mentioned tasks. Conventional linear\nmodels such as Logistic Regression, Naive Bayes and Support Vector Machine (SVM) are reported for automatic binary\nclassiﬁcation on informativeness [ 13] and relevancy [8], among others. These models were implemented with pre-trained\nword2vec embeddings [14]. Several unsupervised approaches are also proposed for classifying crisis-related events, such as the\nCLUSTOP algorithm utilizing Community Detection for automatic topic modelling [15]. A transfer-learning approach is also\nproposed [16], though its classiﬁcation is only limited to two classes. The ability for cross-crisis evaluation remains questionable.\nMore recently, numerous works proposed Neural Networks (NN) models for crisis-related data detection and classiﬁcation. For\ninstance, ALRashdi and O’Keefe investigated two deep learning architectures, namely Bidirectional Long Short-Term Memory\n(BiLSTM) and Convolutional Neural Networks (CNN) using domain-speciﬁc and GloVe embeddings [17]. Nguyen et al.propose\na CNN-based classiﬁer with Word2Vec embedding pretrained on Google News [ 14] and domain-speciﬁc embeddings [ 18].\nLastly, parallel CNN architecture was proposed to detect disaster-related events using tweets [19, 20].\nWhile prior works report remarkable performance on various crisis classiﬁcation tasks using NN models and word embeddings,\nno studies are found to leverage the most recent Natural Language Understanding (NLU) techniques, such as attention-based\ndeep classiﬁcation models [ 21] and document-level contextual embeddings [ 22], which reportedly improve state-of-the-art\nperformance for many challenging natural language problems from upstream tasks such as Named Entity Recognition and Part\nof Speech Tagging, to downstream tasks such as Machine Translation and Neural Conversation.\n1.1 Main Contributions\nThis work focuses on deep attention-based classiﬁcation models and document-level contextual representation models to address\ntwo important crisis classiﬁcation tasks. We study recent NLU models and techniques that reportedly demonstrated drastic\nimprovement on state-of-the-art and localize for domain-speciﬁc crisis related tasks.\nOverall, our main contribution of this work includes:\n• proposing CrisisBERT, an attention-based classiﬁer that improves state-of-the-art performance for both crisis detection\nand recognition tasks;\n• demonstrating superior robustness over various benchmarks, where extendingCrisisBERT from 6 to 36 events with\n51.4% of additional data points only results in marginal performance decline, while increasing crisis case classiﬁcation\nby 500%;\n• proposing Crisis2Vec, a document-level contextual embedding approach for crisis representation, and showing substan-\ntial improvement over conventional crisis embedding methods such as Word2vecand GloVe . . .\nTo the best of our knowledge, this work is the ﬁrst to propose a transformer-based classiﬁer for crisis classiﬁcation tasks. We are\nalso ﬁrst to propose a document-level contextual crisis embedding approach.\n2 Attention-based Neural Crisis Classiﬁer\nIn this section, we discuss the recent works that propose various machine learning approaches for crisis classiﬁcation tasks. While\nthese works report substantial improvement in performance over prior works, none of the works uses state of the art attention-\nbased models, i.e., Transformers [ 21], to perform crisis classiﬁcation tasks. We propose CrisisBERT, a transformer-based\narchitecture that builds upon a Distilled BERT model, ﬁne-tuned by large-scale hyper-parameter search.\n2.1 Conventional Crisis classiﬁers\nVarious works propose linear classiﬁers for crisis-related events. For instance, Parilla-Ferrer et al.proposed an automatic binary\nclassiﬁcation, based on informative and uninformative tweets using Naive Bayes and Support Vector Machine (SVM)[13]. A\nSVM with pretrained word2vec embeddings approach was also proposed [14].\nBesides linear models, recent works also propose deep learning based methods with different neural network architectures. For\ninstance, ALRashdi and O’Keefe investigated Bidirectional Long Short-Term Memory (BiLSTM) and Convolutional Neural\n2\nLIU ET AL . - A PREPRINT\nFigure 1: Illustration of CrisisBERT and Crisis2Vec models. During the tokenization phase, word-level and subword-level\nembeddings are created to produce context embedding for each input word. The vectors are then preﬁxed with a class header\n(shown as [CLS] in the ﬁgure) and passed into a DistrilBERT model. Since we are performing classiﬁcation task, the CLS token\nvector, i.e. the ﬁrst output vector, is then passed into a linear classiﬁer for detection or recognition task, whereas the remainder of\nthe output vectors are average-pooled to create Crisis2Vec embeddings.\nNetwork (CNN) models using domain-speciﬁc and GloVe embeddings [23]. Nguyen et al.proposed a CNN model to classify\ntweets to get information types using Google News and domain-speciﬁc embeddings [18].\n2.2 Transformer\nIn 2017, Vaswani et al. from Google introduced Transformer [ 21], a new category of deep learning models which are\nsolely attention-based and without convolution and recurrent mechanisms. Later, Google proposed the Bidirectional Encoder\nRepresentations from Transformers (BERT) model [24] which drastically improved state-of-the-art performance for multiple\nchallenging Natural Language Processing (NLP) tasks. Since then, multiple transformer-based models have been introduced,\nsuch as GPT [25] and XLNet [26], among others. Transformer-based models were also deployed to solve domain speciﬁc tasks,\nsuch as medical text inferencing [27] and occupational title embedding [28], and demonstrated remarkable performance.\nThe Bidirectional Encoder Representation of Transformer (BERT), for instance, is a multi-layer bidirectional Transformer\nen- coder with attention mechanism [ 24]. The proposed BERT model has two variants, namely (a) BERT Base, which has\n12 transformer layers, a hidden size of 768, 12 attention heads, and 110M total parameters; and (b) BERT Large, which\nhas 24 transformer layers, a hidden size of 1024, 16 attention heads, and 340M total parameters. BERT is pre-trained with\nself-supervised approaches, i.e., Masked Language Modeling (MLM) and Next Sentence Prediction (NSP).\nWhile Transformers such as BERT are reported to perform well in natural language processing, understanding and inference\ntasks, to the best of our knowledge, no prior works propose and examine the performance of transformer-based models for crisis\nclassiﬁcation.\n2.3 CrisisBERT\nIn this work, we investigate the transformer approach for crisis classiﬁcation tasks and propose CrisisBERT, a transformer-based\nclassiﬁcation model that surpasses conventional linear and deep learning models in performance and robustness. Figure 1\nillustrates an overview of the proposed architecture. Overall, the architecture of CrisisBERT includes three layers, namely (1)\nContextual Tokenization, (2) Transformer Language Model, and (3) Logistic Classiﬁer.\n3\nLIU ET AL . - A PREPRINT\nTokenization. DistrilBERT inherits the embedding layer from BERT, where each word is tokenized contextually with subword-\nlevel word embeddings and positional encoders. Preﬁxed with a special token ([CLS]), the vector pairs are concatinated and\npassed into a DistilBERT LM for training.\nHyper Parameter Final Search Space\nTransformer BERT {BERT, XLNet, GPT2, RoBERTa}\nDistillation True {True, False}\nOptimizer ADAMW {AdamW, Adam, SGD}\nLearning Rate 5e-5 {5e-3, 2e-3, 5e-4, 2e-4, 5e-5, 2e-5}\nBatch Size 32 {16, 32, 64}\nTable 1: Hyper-parameter search space and ﬁnal values used\nTransformer LM. We perform large-scale model selection and hyperparameter search to ﬁn the best performing transformer\nLM for the crisis classiﬁcation tasks. Several transformer models are investigated, including BERT, XLNet, GPT2 and RoBERTa.\nFor each model, we conduct hyper-parameter search, where the search space includes variations of distillation [29], optimizers,\nlearning rates, and batch sizes.\nTable 1 shows the breakdown of the search space and the ﬁnal hyper-parameters for CrisisBERT. Each set of parameters is\nrandomly chosen and ran with 3 epochs and two trials. In total, we evaluate over 300 hyper-parameters sets using a Nvidia\nTitan-X (Pascal) for over 1,000 GPU hours.\nTaking into consideration of performance and efﬁciency trade-off, we select the DistilBERT model for our Transformer LM\nlayer. DistilBERT is a compressed version of BERT Base through Knowledge Distillation. With utilization of only 50% of the\nlayers of BERT, DistilBERT performs 60% faster while preserving 97% of the capabilities in language understanding tasks. The\noptimal set of hyper-parameters for DistilBERT includes an AdamW [30] optimizer, and initial learning rate of 5e-5, and a batch\nsize of 32.\nOutput Layer. The output layer of DistilBERT LM is a set of 768-d vectors led by the class header vector. Since we are\nconducting classiﬁcation tasks, only the [CLS] token vector is used as the aggregate sequence representation for classiﬁcation\nwith a linear classiﬁer. The remainder of the output vectors are processed into Crisis2Vec embeddings using Mean-Pooling\noperation.\n2.4 Crisis2Vec\nAs discussed in Section 2.3, Crisis2Vec embedding is a byproduct of CrisisBERT, where the embeddings are constructed\nbased on a pre-trained BERT model, and subsequently ﬁne-tuned with three corpora of crisis-related tweets [6, 31, 32] to be\ndomain-speciﬁc for crisis-related tweet representation.\nCrisis2Vecleverages the advantages of Transformers, including (1) leveraging a self-attention mechanism to incorporate sentence-\nlevel context bidirectionally, (2) leveraging both word-level and positional information to create contextual representation of\nwords, and (3) taking advantage of the pre-trained models on large relevant corpora.\nTo the best of our knowledge, we are the ﬁrst who propose a document-level contextual embedding approach for crisis-related\ndocument representation. Upon convergence, we construct the ﬁxed-length tweet vector using a MEAN-Pooling strategy [22],\nwhere we compute the mean of all output vectors, as illustrated in Algorithm 1.\nAlgorithm 1: Crisis2Vec with Mean Pooling\nInput: Tweet as a sequence of Words\nOutput: Tweet_Embedding\nInitialize Token_Vector;\nfor wordin Tweet do\nWord_Token ← Embed(Word);\nAppend Token_Vector ← Word_Token;\nend\nOutput_Vectors ← CrisisBERTLM (Token_Vector);\nTweet_Embedding ← PoolMean (Output_Vectors);\nreturn Tweet_Embedding;\n4\nLIU ET AL . - A PREPRINT\n3 Crisis Classiﬁcation\nIn this work, we conduct two crisis classiﬁcation tasks, namely Crisis Detectionand Crisis Recognition. We formulate the\nCrisis Detectiontask as a binary classiﬁcation model that identiﬁes if a tweet is relevant to a crisis-related event. The Crisis\nRecognition task on the other hand extends the problem into multi-class classiﬁcation, where the output is a probability vector\nthat indicate the likelihood of a tweet indicating speciﬁc events. Both tasks are modelled as Sequence Classiﬁcation problems\nthat are formally deﬁned below.\n3.1 Crisis Detection\nWe deﬁne the Crisis Detection task D= (S,Φ), which is speciﬁed by S = {s1,...,s n}a ﬁnite sample space of tweets with size\nn. Each sample si is a sequence of tokens at T time steps, i.e., si = {s1\ni ,...,s T\ni }. Φ denotes the set of labels that has the same\nsequence as the sample set, Φ = {φ1,...,φ n}and φi ∈{0,1}where φi = 1 indicates that sample si is relevant to crisis, and\nφi = 0 indicates otherwise. A deterministic classiﬁer CD : S →φspeciﬁes the mapping from sample tweets to their ﬂags.\nOur objective is to train a crisis detector using the provided tweets and labels that minimizes the differences between predicted\nlabels and true labels, i.e.,\nmin.JD(Φ,CD(S)) (1)\nwhere JD denotes some cost function.\n3.2 Crisis Recognition\nSimilarly, we deﬁne a Crisis Recognition task R = (S,L), where sample space S is identical to that in Crisis Detection. L\ndenotes a sequence of multi-class labels that have the same sequence as S, i.e., L= {l1,...,l n}, and li ∈Rm for mnumber of\nclasses. A deterministic classiﬁer CR : S →Lspeciﬁes the mapping from the sample tweets to the crisis classes.\nThe objective of the crisis classiﬁcation tasks is to train a sequence classiﬁer using the provided tweets and labels that minimizes\nthe differences between predicted labels and true labels, i.e.,\nmin.JR(L,CR(S)) (2)\nwhere JR denotes some cost function for classiﬁer CR.\nLabel Crisis event # Data Points Dataset Label Crisis event # Data Points Dataset\n1 2012_Sandy_Hurricane 6318 C6 2 2013_Alberta_Floods 5189 C6\n3 2013_Boston_Bombings 6577 C6 4 2013_Oklahoma_Tornado 4827 C6\n5 2013_Queensland_Floods 6333 C6 6 2013_West_Texas_Explosion 6157 C6\n7 sydneysiege 837 C8 8 charliehebdo 903 C8\n9 ferguson 859 C8 10 germanwings-crash 248 C8\n11 putinmissing 59 C8 12 ottawashooting 639 C8\n13 ebola-essien 21 C8 14 prince-toronto 93 C8\n15 2012_Colorado_wildﬁres 953 C26 16 2012_Costa_Rica_earthquake 909 C26\n17 2012_Guatemala_earthquake 940 C26 18 2012_Italy_earthquakes 940 C26\n19 2012_Philipinnes_ﬂoods 906 C26 20 2012_Typhoon_Pablo 907 C26\n21 2012_Venezuela_reﬁnery 939 C26 22 2013_Australia_bushﬁre 949 C26\n23 2013_Bohol_earthquake 969 C26 24 2013_Brazil_nightclub_ﬁre 952 C26\n25 2013_Colorado_ﬂoods 925 C26 26 2013_Glasgow_helicopter_crash 918 C26\n27 2013_LA_airport_shootings 912 C26 28 2013_Lac_Megantic_train_crash 966 C26\n29 2013_Manila_ﬂoods 921 C26 30 2013_NY_train_crash 999 C26\n31 2013_Russia_meteor 1133 C26 32 2013_Sardinia_ﬂoods 926 C26\n33 2013_Savar_building_collapse 911 C26 34 2013_Singapore_haze 933 C26\n35 2013_Spain_train_crash 991 C26 36 2013_Typhoon_Yolanda 940 C26\nTable 2: Classes Description\n4 Experiments and Results\nIn this section, we discuss the experiments performed and their results in order to propose a highly effective and efﬁcient\napproach for text classiﬁcation.\n5\nLIU ET AL . - A PREPRINT\n4.1 Datasets\nThree datasets of labelled crisis-related tweets [6, 31, 32] are used to conduct crisis classiﬁcation tasks and evaluate the proposed\nmethods against benchmarks. In total, these datasets consist of close to 8 million tweets, where overall 91.6k are labelled. These\ndata sets are in the form of: (1) 60k labelled tweets on 6 crises[6], (2) 3.6k labelled tweets for 8 crises [32], and (3) 27.9k labelled\ntweets for 26 crises [31]. Table 2 describes more detail about each dataset and their respective classes.\nFor our experimental evaluation, the 91.6k labelled crisis-related tweets are organized into two datasets, annotated as C6 and\nC36. In particular, C6 consists of 60k tweets from 6 classes of crises, whereas C36 comprises all 91.6k tweets in 36 classes.\nBoth datasets are split into training, validation and test sets that consist of 90%, 5% and 5% of the original sets, respectively.\nTable 3 describes the statistics of the split sets.\nDataset # Data Points # Classes Train Test Split\nC6 60k 6 + 1 54072 3004 3004\nC36 91.6k 36 + 1 82506 4584 4584\nTable 3: Dataset Description\n4.2 Proposed Models\nCrisisBERT. We evaluate the performance ofCrisisBERT against multiple benchmarks, which comprise recently proposed crisis\nclassiﬁcation models in the literature. These works include linear classiﬁers, such as Logistic Regression (LR), Support Vector\nMachine (SVM) and Naive Bayes [33], and non-linear neural networks, such as Convolutional Neural Network (CNN) [20] and\nLong Short-Term Memory [34].\nFurthermore, we investigate the robustness ofCrisisBERT for both detection and recognition tasks. This is achieved by extending\nthe experiments from C6 to C36, which comprise 6 and 36 classes respectively, but with only 51.4% additional data points. We\nevaluate the robustness of the proposed models against benchmarks by observing the compromise in robustness performance,\nwhile realizing the drastically improved classiﬁcation performance.\nAs described in Section 2.3, we use the optimal set of hyper-parameters for CrisisBERT in the experiments, which include the\nuse of a BERT model with distillation (i.e. DistilBERT), an AdamW [30] optimizer, an initial learning rate of 5e-5, a batch size\nof 32, and a word dropout rate of 0.25.\nCrisis2Vec. To evaluate Crisis2Vec, we choose the two classiﬁers with the aim to represent both traditional Machine Learning\napproaches and the NN approaches. The two selected models are: (1) a linear Logistic Regression model, denoted as LRc2v,\nand (2) a non-linear LSTM model, denoted as LSTMc2v. We evaluate the performance of Crisis2Vec with the two models by\nreplacing the original embedding to Crisis2Vec, ceteris paribus.\n4.3 Metrics\nWe use two common evaluation metrics, namely Accuracy and F1 score, which are functions of True-Positive (TP), False-Positive\n(FP), True-Negative (TN) and False-Negative (FN) predictions. Accuracy is calculated by:\nAccuracy = TP + TN\nTP + TN + FP + FN (3)\nFor a F1-score of multiple classes, we calculate the unweighted mean for each label, i.e., for nclasses of labels as:\nF1 = 2 ∗Recall∗Precision\nRecall+ Precision (4)\nwhere\nPrecision = TP\nTP + FP (5)\nand\nRecall= TP\nTP + FN (6)\n6\nLIU ET AL . - A PREPRINT\n4.4 Benchmark Algorithms\nWe select and implement several crisis classiﬁers proposed in recent works to serve as benchmarks for evaluating our proposed\nmethods. Concretely, we compare CrisisBERT with the following models:\n• LRw2v: Logistic regression model with Word2Vecembedding pre-trained on Google News Corpus [33]\n• SVMw2v: Support Vector Machine model with Word2Vecembedding pre-trained on Google News Corpus [33]\n• NBw2v: Naive Bayes model assuming Gaussian distribution for features with Word2Vecembedding pre-trained on\nGoogle News Corpus [33]\n• CNNgv: Convolutional Neural Network model with 2 convolutional layers of 128 hidden units, kernel size of 3, pool\nsize of 2, 250 ﬁlters, and GloVe for word embedding [20]\n• LSTMw2v: Long Short-Term Memory model with 2 layers of 30 hidden states and a Word2Vec-based Crisis Embed-\nding [34]\nModels Detection-C6 Detection-C36 Recognition-C6 Recognition-C36\nF1 Accuracy F1 Accuracy F1 Accuracy F1 Accuracy\nProposed\nCrisisBERT 95.5 95.6 94.2 94.7 98.7 98.6 97.1 97.9\nLSTM c2v 95.1 95.1 92.8 93.5 97.5 97.5 88.0 95.6\nLRc2v 93.2 93.2 89.0 90.1 93.6 93.7 85.1 90.9\nBenchmark\nLRw2v [33] 91.5 91.6 85.3 86.6 87.3 88.5 72.1 82.3\nSVM w2v [33] 91.3 91.4 85.0 86.3 86.6 87.9 71.6 81.9\nNBw2v [33] 86.8 86.8 82.4 83.4 78.8 80.5 47.6 63.5\nCNN gv [20] 91.2 91.3 91.1 91.2 90.5 90.4 23.3 64.4\nLSTM w2v [34] 91.7 91.7 88.0 89.3 87.3 87.3 58.9 72.3\nTable 4: Experimental results of Crisis Classiﬁcation tasks on C6 and C36 datasets for proposed models and benchmarks, where\nbest performers are emphasized. Results show that CrisisBERT records highest performance across all tasks.\n4.5 Results\nOverall, the experimental results show that both proposed models achieve signiﬁcant improvement on performance and robustness\nover benchmarks across all tasks. The experimental results for CrisisBERT and Crisis2Vec are tabulated in Table 4.\nCrisis Detection. For Crisis Detection tasks on C6 dataset, CrisisBERT achieves a 95.5% F1-score and 95.6% Accuracy, which\nexceeds previous best model results, namely LSTM with pre-trained Word2Vecembeddings, by 3.8% and 3.8% respectively. In\nterms of embedding, LSTM with Crisis2Vec records 95.1% for both F1-score and Accuracy, which shows 3.4% improvement\nover LSTM with Word2Vec. Similarly, LR with Crisis2Vec records 93.2% for both F1-score and Accuracy, which shows 1.6%\nimprovement over LR with Word2Vec.\nFor Crisis Detection tasks on C36 dataset, CrisisBERT achieves 94.2% F1-score and 94.7% Accuracy, which exceeds previous\nbest model results, namely CNN with pre-trained GloVe embedding, by 2.7% and 2.1% respectively. In terms of embeddings,\nLSTM with Crisis2Vec records 92.8% F1-score and 93.5% Accuracy, which exceedLSTM with Word2Vecby 4.8% and 4.2%.\nSimilarly, LR with Crisis2Vec records 89.0% F1-score and 90.1% Accuracy, which exceed LR with Word2Vecby 3.7% and 3.5%\nrespectively.\nCrisis Recognition. For Crisis Recognition tasks on C6 dataset, CrisisBERT achieves 98.7% F1-score and 98.6% Accuracy,\nwhich exceeds previous best model results, namely CNN with pre-trained GloVe embeddings, by 8.2% for both F1-score and\nAccuracy. In terms of embedding, LSTM with Crisis2Vec records 97.5% for both F1-score and Accuracy, which shows a\nsigniﬁcant improvement of 10.2% over LSTM with Word2Vec. Similarly, LR with Crisis2Vec records 93.6% F1-score and 93.7%\nAccuracy, which shows 6.3% and 5.2% improvement respectively overLR with Word2Vec.\nFor Crisis Detection tasks on C36 dataset, CrisisBERT achieves 97.1% F1-score and 97.9% Accuracy, which signiﬁcantly\nexceeds previous best model results, namely LR with pre-trained Word2Vecembedding, by 25.0% and 15.6% respectively. In\nterms of embeddings, LSTM with Crisis2Vec records 88.0% F1-score and 95.6% Accuracy, which signiﬁcantly exceed LSTM\nwith Word2Vecby 29.1% and 23.3%. Similarly, LR with Crisis2Vec records 85.1% F1-score and 90.9% Accuracy, which\nsigniﬁcantly exceed LR with Word2Vecby 13.0% and 8.6% respectively.\n7\nLIU ET AL . - A PREPRINT\nRobustness. Comparing Crisis Detection task between C6 and C36, CrisisBERT shows 1.7% and 1.3% decline for F1-score and\nAccuracy, which is much better than most benchmarks, i.e., from 1.7% to 6.3%, exceptCNN. However, when we compare the\nmore challenging Crisis Recognition tasks between C6 and C36, the performance of CrisisBERT compromises marginally, i.e.,\n1.6% for F1-score and 0.7% for Accuracy. On the contrary, all benchmark models record signiﬁcant decline, i.e. from 6.0% to\n67.2%.\nDiscussion. Based on experimental results discussed above, we observe that: (1) CrisisBERT’s performance exceeds state-of-the-\nart performance for both detection and recognition tasks, with up to 8.2% and 25.0% respectively, (2) CrisisBERT demonstrates\nhigher robustness with marginal decline for performance (i.e. less than 1.7% in F1-score and Accuracy), and (3) Crisis2Vec\nshows superior performance as compared to conventional Word2Vecembeddings, for both LR and LSTM models across all\nexperiments.\n5 Related Work\n5.1 Crisis Classiﬁcation\nEvent detection from tweets has received signiﬁcant attention in research in order to analyze crisis-related messages for better\ndisaster management and increasing situational awareness [4, 5, 2, 3]. Parilla-Ferrer et al.proposed automatic binary classiﬁcation\nof informativeness using Naive Bayes and Support Vector Machine (SVM) [13]. Stowe et al.presented an annotation scheme\nfor tweets to classify relevancy and six [ 8]. Furthermore, use of pre-trained word2vec reportedly improved SVM for Crisis\nclassiﬁcation [14]. Lim et al.proposed CLUSTOP algorithm utilizing the community detection approach for automatic topic\nmodelling [15]. Pedrood et al.proposed to transfer-learn classiﬁcation of one event to the other using a sparse coding model [16],\nthough the scope was only limited to only two events, i.e. Hurricane Sandy (2012) and Supertyphoon Yolanda (2013).\nA substantial number of works focusses on usign Neural Networks (NN) with word embeddings for crisis-related data classiﬁca-\ntion. Manna et al.[33] compared NN models with conventional ML classiﬁers [33]. ALRashdi and O’Keefe investigated and\nshowed good performance for two deep learning architectures, namely Bidirectional Long Short-Term Memory (BiLSTM) and\nConvolutional Neural Networks (CNN) with domain-speciﬁc GloVe embeddings [17]. However, the study had yet to validate the\nrelevance of model on a different crisis type. Nguyen et al.applied CNN to classify information types using Google News and\ndomain-speciﬁc embeddings[18]. Kersten et al.[20] implemented a parallel CNN to detect two disasters, namely hurricanes and\nﬂoods, which reported a F1-score of 0.83. The CNN architecture was proposed earlier by Kim et al. [19].\n5.2 Crisis Embedding\nWord-level Embeddings such asWord2Vec[35] and GloVe [23] are commonly used to form the basis of Crisis Embedding [18, 36]\nin various crisis classiﬁcation works to improve model performance. For context, Word2Vecuses a Neural Network Language\nModel (NNLM) that is able to represent latent information on the word level. GloVe achieved better results with a simpler\napproach, constructing global vectors to represent contextual knowledge of the vocabulary.\nMore recently, a series of high quality embedding models, such as FastText [37] and Flair [38], are proposed and reported to have\nimproved state of the art for multiple NLP tasks. Both word-level contextualization and character-level features are commonly\nused for these works. Pre-trained models on large corpora of news and tweets collections are also made publicly available\nto assist in downstream tasks. Furthermore, Transformer-based models are proposed to conduct sentence-level embedding\ntasks [22].\n6 Conclusion\nSocial media such as Twitter has become a hub of crowd generated information for early crisis detection and recognition tasks. In\nthis work, we present a transformer-based crisis classiﬁcation modelCrisisBERT, and a contextual crisis-related tweet embedding\nmodel Crisis2Vec. We examine the performance and robustness of the proposed models by conducting experiments with three\ndatasets and two crisis classiﬁcation tasks. Experimental results show that CrisisBERT improves state of the art for both detection\nand recognition class, and further demonstrates robustness by extending from 6 classes to 36 classes, with only 51.4% additioanl\ndata points. Finally, our experiments with two classiﬁcation models show that Crisis2Vec enhances classiﬁcation performance as\ncompared to Word2Vecembeddings, which is commonly used in prior works.\n8\nLIU ET AL . - A PREPRINT\n7 Acknowledgement\nThis research is funded in part by the Singapore University of Technology and Design under grant SRG-ISTD-2018-140.\nReferences\n[1] Internet Live Statistics. Twitter usage statistics. Internet, 2020.\n[2] Naina Said, Kashif Ahmad, Michael Riegler, Konstantin Pogorelov, Laiq Hassan, Nasir Ahmad, and Nicola Conci. Natural\ndisasters detection in social media and satellite imagery: a survey.Multimedia Tools and Applications, 78(22):31267–31302,\n2019.\n[3] Luke S Snyder, Morteza Karimzadeh, Christina Stober, and David S Ebert. Situational awareness enhanced through social\nmedia analytics: A survey of ﬁrst responders. arXiv preprint arXiv:1909.07316, 2019.\n[4] Muhammad Imran, Carlos Castillo, Fernando Diaz, and Sarah Vieweg. Processing social media messages in mass\nemergency: A survey. ACM Computing Surveys (CSUR), 47(4):1–38, 2015.\n[5] Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo. Earthquake shakes twitter users: real-time event detection by social\nsensors. In Proceedings of the 19th international conference on World wide web, pages 851–860, 2010.\n[6] Alexandra Olteanu, Carlos Castillo, Fernando Diaz, and Sarah Vieweg. Crisislex: A lexicon for collecting and ﬁltering\nmicroblogged communications in crises. In Eighth international AAAI conference on weblogs and social media, 2014.\n[7] Shanshan Zhang and Slobodan Vucetic. Semi-supervised discovery of informative tweets during the emerging disasters.\narXiv preprint arXiv:1610.03750, 2016.\n[8] Kevin Stowe, Michael Paul, Martha Palmer, Leysia Palen, and Kenneth M Anderson. Identifying and categorizing\ndisaster-related tweets. In Proceedings of The fourth international workshop on natural language processing for social\nmedia, pages 1–6, 2016.\n[9] Muhammad Imran, Shady Elbassuoni, Carlos Castillo, Fernando Diaz, and Patrick Meier. Extracting information nuggets\nfrom disaster-related messages in social media. In Iscram, 2013.\n[10] Amanda L Hughes, Lise AA St. Denis, Leysia Palen, and Kenneth M Anderson. Online public communications by police\n& ﬁre services during the 2012 hurricane sandy. In Proceedings of the SIGCHI conference on human factors in computing\nsystems, pages 1505–1514, 2014.\n[11] Grégoire Burel, Hassan Saif, Miriam Fernandez, and Harith Alani. On semantics and deep learning for event detection in\ncrisis situations. 2017.\n[12] Justin Michael Crow. Verifying baselines for crisis event information classiﬁcation on twitter. In Proceedings of the 17th\nInternational Conference on Information Systems for Crisis Response and Management (ISCRAM 2020). ISCRAM Digital\nLibrary, 2020.\n[13] Beverly Estephany Parilla-Ferrer, PL Fernandez, and JT Ballena. Automatic classiﬁcation of disaster-related tweets. In\nProc. International conference on Innovative Engineering Technologies (ICIET), volume 62, 2014.\n[14] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words and phrases\nand their compositionality. In Advances in neural information processing systems, pages 3111–3119, 2013.\n[15] Kwan Hui Lim, Shanika Karunasekera, and Aaron Harwood. Clustop: A clustering-based topic modelling algorithm for\ntwitter using word networks. In 2017 IEEE International Conference on Big Data (Big Data), pages 2009–2018. IEEE,\n2017.\n[16] Bahman Pedrood and Hemant Purohit. Mining help intent on twitter during disasters via transfer learning with sparse\ncoding. In International Conference on Social Computing, Behavioral-Cultural Modeling and Prediction and Behavior\nRepresentation in Modeling and Simulation, pages 141–153. Springer, 2018.\n[17] Reem ALRashdi and Simon O’Keefe. Deep learning and word embeddings for tweet classiﬁcation for crisis response.\narXiv preprint arXiv:1903.11024, 2019.\n[18] Dat Tien Nguyen, Kamela Ali Al Mannai, Shaﬁq Joty, Hassan Sajjad, Muhammad Imran, and Prasenjit Mitra. Robust\nclassiﬁcation of crisis-related data on social networks using convolutional neural networks. In Eleventh International AAAI\nConference on Web and Social Media, 2017.\n[19] Yoon Kim. Convolutional neural networks for sentence classiﬁcation. arXiv preprint arXiv:1408.5882, 2014.\n[20] Jens Kersten, Anna Kruspe, Matti Wiegmann, and Friederike Klan. Robust ﬁltering of crisis-related tweets. In ISCRAM\n2019 Conference Proceedings-16th International Conference on Information Systems for Crisis Response and Management,\n2019.\n9\nLIU ET AL . - A PREPRINT\n[21] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia\nPolosukhin. Attention is all you need. In Advances in neural information processing systems, pages 5998–6008, 2017.\n[22] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint\narXiv:1908.10084, 2019.\n[23] Jeffrey Pennington, Richard Socher, and Christopher D Manning. Glove: Global vectors for word representation. In\nProceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532–1543,\n2014.\n[24] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers\nfor language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186,\nMinneapolis, Minnesota, June 2019. Association for Computational Linguistics.\n[25] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised\nmultitask learners. OpenAI Blog, 1(8), 2019.\n[26] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. Xlnet: Generalized\nautoregressive pretraining for language understanding. In Advances in neural information processing systems, pages\n5754–5764, 2019.\n[27] Lung-Hao Lee, Yi Lu, Po-Han Chen, Po-Lei Lee, and Kuo-Kai Shyu. Ncuee at mediqa 2019: Medical text inference using\nensemble bert-bilstm-attention model. In Proceedings of the 18th BioNLP Workshop and Shared Task, pages 528–532,\n2019.\n[28] Junhua Liu, Yung Chuen Ng, Kristin L Wood, and Kwan Hui Lim. Ipod: An industrial and professional occupations dataset\nand its applications to occupational data mining and analysis. arXiv preprint arXiv:1910.10495, 2019.\n[29] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv preprint\narXiv:1503.02531, 2015.\n[30] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017.\n[31] Alexandra Olteanu, Sarah Vieweg, and Carlos Castillo. What to expect when the unexpected happens: Social media\ncommunications across crises. In Proceedings of the 18th ACM conference on computer supported cooperative work &\nsocial computing, pages 994–1009, 2015.\n[32] Arkaitz Zubiaga, Maria Liakata, Rob Procter, Geraldine Wong Sak Hoi, and Peter Tolmie. Analysing how people orient to\nand spread rumours in social media by looking at conversational threads. PloS one, 11(3), 2016.\n[33] Sukanya Manna and Haruto Nakai. Effectiveness of word embeddings on classiﬁers: A case study with tweets. In 2019\nIEEE 13th International Conference on Semantic Computing (ICSC), pages 158–161. IEEE, 2019.\n[34] Abhinav Kumar, Jyoti Prakash Singh, Yogesh K Dwivedi, and Nripendra P Rana. A deep multi-modal neural network for\ninformative twitter content classiﬁcation during emergencies. Annals of Operations Research, pages 1–32, 2020.\n[35] Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and Christian Jauvin. A neural probabilistic language model. Journal\nof machine learning research, 3(Feb):1137–1155, 2003.\n[36] Dat Tien Nguyen, Shaﬁq Joty, Muhammad Imran, Hassan Sajjad, and Prasenjit Mitra. Applications of online deep learning\nfor crisis response using social media information. arXiv preprint arXiv:1610.01030, 2016.\n[37] Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. Enriching word vectors with subword information.\nTransactions of the Association for Computational Linguistics, 5:135–146, 2017.\n[38] Alan Akbik, Duncan Blythe, and Roland V ollgraf. Contextual string embeddings for sequence labeling. InCOLING 2018,\n27th International Conference on Computational Linguistics, pages 1638–1649, 2018.\n10",
  "topic": "Embedding",
  "concepts": [
    {
      "name": "Embedding",
      "score": 0.7447769045829773
    },
    {
      "name": "Computer science",
      "score": 0.6367273330688477
    },
    {
      "name": "Word2vec",
      "score": 0.5555207133293152
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5481541156768799
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.5282145142555237
    },
    {
      "name": "Machine learning",
      "score": 0.49179890751838684
    },
    {
      "name": "Transformer",
      "score": 0.47562411427497864
    },
    {
      "name": "Deep learning",
      "score": 0.41584187746047974
    },
    {
      "name": "Engineering",
      "score": 0.17269104719161987
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    }
  ],
  "institutions": []
}