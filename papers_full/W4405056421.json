{
  "title": "RNA language models predict mutations that improve RNA function",
  "url": "https://openalex.org/W4405056421",
  "year": 2024,
  "authors": [
    {
      "id": null,
      "name": "Trinidad, Marena",
      "affiliations": [
        "Innovative Genomics Institute",
        "University of California, Berkeley",
        "QB3"
      ]
    },
    {
      "id": "https://openalex.org/A2251266551",
      "name": "Jamie Cate",
      "affiliations": [
        "Innovative Genomics Institute",
        "Howard Hughes Medical Institute",
        "University of California, Berkeley"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3177828909",
    "https://openalex.org/W4327550249",
    "https://openalex.org/W4388539614",
    "https://openalex.org/W3212533323",
    "https://openalex.org/W4390975839",
    "https://openalex.org/W3135161193",
    "https://openalex.org/W4367681391",
    "https://openalex.org/W4290546063",
    "https://openalex.org/W4404349982",
    "https://openalex.org/W4392236160",
    "https://openalex.org/W4387931208",
    "https://openalex.org/W4384664255",
    "https://openalex.org/W4386704695",
    "https://openalex.org/W4388520896",
    "https://openalex.org/W4393219516",
    "https://openalex.org/W4308616064",
    "https://openalex.org/W3100348855",
    "https://openalex.org/W2034285706",
    "https://openalex.org/W3095979265",
    "https://openalex.org/W2141152740",
    "https://openalex.org/W4311276451",
    "https://openalex.org/W2047544230",
    "https://openalex.org/W3195899639",
    "https://openalex.org/W2336207123",
    "https://openalex.org/W2291071388",
    "https://openalex.org/W1149835906",
    "https://openalex.org/W2902321532",
    "https://openalex.org/W3165323947",
    "https://openalex.org/W3199575259",
    "https://openalex.org/W4321014564",
    "https://openalex.org/W4386193823",
    "https://openalex.org/W2979902043",
    "https://openalex.org/W2109441358",
    "https://openalex.org/W2118265845",
    "https://openalex.org/W2145317354",
    "https://openalex.org/W2889019390",
    "https://openalex.org/W1825235522",
    "https://openalex.org/W3045908771",
    "https://openalex.org/W4200308339",
    "https://openalex.org/W2949670700",
    "https://openalex.org/W4211030178",
    "https://openalex.org/W3155806510",
    "https://openalex.org/W4403023684",
    "https://openalex.org/W4317528980",
    "https://openalex.org/W2806245693",
    "https://openalex.org/W3133656302",
    "https://openalex.org/W4383532437",
    "https://openalex.org/W2034800216",
    "https://openalex.org/W2078248271",
    "https://openalex.org/W4225649494",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2998437600",
    "https://openalex.org/W4390744090",
    "https://openalex.org/W2513506562",
    "https://openalex.org/W2138122982",
    "https://openalex.org/W2114392707",
    "https://openalex.org/W2170747616",
    "https://openalex.org/W2160378127",
    "https://openalex.org/W6743235451",
    "https://openalex.org/W2184115732",
    "https://openalex.org/W3112235282",
    "https://openalex.org/W2008026560",
    "https://openalex.org/W2099540110",
    "https://openalex.org/W2226712470",
    "https://openalex.org/W4394063270",
    "https://openalex.org/W4405056421",
    "https://openalex.org/W2073149987"
  ],
  "abstract": "Abstract Structured RNA lies at the heart of many central biological processes, from gene expression to catalysis. RNA structure prediction is not yet possible due to a lack of high-quality reference data associated with organismal phenotypes that could inform RNA function. We present GARNET (Gtdb Acquired RNa with Environmental Temperatures), a new database for RNA structural and functional analysis anchored to the Genome Taxonomy Database (GTDB). GARNET links RNA sequences to experimental and predicted optimal growth temperatures of GTDB reference organisms. Using GARNET, we develop sequence- and structure-aware RNA generative models, with overlapping triplet tokenization providing optimal encoding for a GPT-like model. Leveraging hyperthermophilic RNAs in GARNET and these RNA generative models, we identify mutations in ribosomal RNA that confer increased thermostability to the Escherichia coli ribosome. The GTDB-derived data and deep learning models presented here provide a foundation for understanding the connections between RNA sequence, structure, and function.",
  "full_text": "Article https://doi.org/10.1038/s41467-024-54812-y\nRNA language models predict mutations that\nimprove RNA function\nYekaterina Shulgina 1,2,3,12,M a r e n aI .T r i n i d a d1,4,12,\nConner J. Langeberg1,2,3,12, Hunter Nisonoff5,12, Seyone Chithrananda1,6,12,\nPetr Skopintsev 1,3,12,A m o sJ .N i s s l e y7,12, Jaymin Patel 1,R o nS .B o g e r1,8,\nHonglue Shi 1,4, Peter H. Yoon1,2,E r i nE .D o h e r t y1,3,T a r aP a n d e6,\nAditya M. Iyer9, Jennifer A. Doudna1,2,3,4,7,10,11&J a m i eH .D .C a t e1,2,3,7,10,12\nStructured RNA lies at the heart of many central biological processes, from\ngene expression to catalysis. RNA structure prediction is not yet possible due\nto a lack of high-quality reference data associated with organismal phenotypes\nthat could inform RNA function. We present GARNET (Gtdb Acquired RNa with\nEnvironmental Temperatures), a new database for RNA structural and func-\ntional analysis anchored to the Genome Taxonomy Database (GTDB). GARNET\nlinks RNA sequences to experimentaland predicted optimal growth tem-\nperatures of GTDB reference organisms. Using GARNET, we develop sequence-\nand structure-aware RNA generative models, with overlapping triplet tokeni-\nzation providing optimal encoding for a GPT-like model. Leveraging hyper-\nthermophilic RNAs in GARNET and these RNA generative models, we identify\nmutations in ribosomal RNA that confer increased thermostability to the\nEscherichia coliribosome. The GTDB-derived data and deep learning models\npresented here provide a foundation for understanding the connections\nbetween RNA sequence, structure, and function.\nRNAs serve many fundamental roles in biology ranging from gene\nexpression to catalysis, and can adopt complex three-dimensional\nfolds to carry out these functions. Inspired by the successes in protein\nstructure prediction\n1,2, multiple groups have made progress towards\ndeveloping deep learning models for RNA secondary and tertiary\nstructure prediction\n3– 10. However, based on assessment of the CASP15\nRNA modeling challenge and the metrics used therein, RNA structure\nprediction using deep learning approaches has not reached human-\ntailored model performance, and human modeling of RNA structure is\nstill not at the level of protein structure prediction\n11– 14. A fundamental\nweakness in RNA modeling is the state of RNA sequence, structural,\nand phenotypic databases available for training deep learning\nmodels\n13,15. Rfam, the closest analogue to Pfam for proteins16,p r o v i d e s\ncurated seed sequences, alignments and homology models for thou-\nsands of RNA families17. However, Rfam alignments have limited phy-\nlogenetic scope, only drawing from Uniprot reference genomes\n(n = 14,451). The SILVA database contains highly-curated information\nfor 16S and 23S ribosomal RNA (rRNA) sequences\n18, but not for other\nRNAs. Another major database, RNAcentral, aggregates RNA sequence\nand structural information from a range of RNA databases\n19. However,\nReceived: 18 May 2024\nAccepted: 20 November 2024\nCheck for updates\n1Innovative Genomics Institute, University of California, Berkeley, CA, USA.2Department of Molecular and Cell Biology, University of California, Berkeley, CA,\nUSA. 3California Institute for Quantitative Biosciences, University of California, Berkeley, CA, USA.4Howard Hughes Medical Institute, University of California,\nBerkeley, CA, USA.5Center for Computational Biology, University of California, Berkeley, CA, USA.6Department of Electrical Engineering and Computer\nSciences, University of California, Berkeley, CA, USA.7Department of Chemistry, University of California, Berkeley, CA, USA.8Biophysics Graduate Program,\nUniversity of California, Berkeley, CA, USA.9Department of Physics, University of California, Berkeley, CA, USA.10MBIB Division, Lawrence Berkeley National\nLaboratory, Berkeley, CA, USA.11Gladstone Institutes, University of California, San Francisco, CA, USA.12These authors contributed equally: Yekaterina\nShulgina, Marena I. Trinidad, Conner J. Langeberg, Hunter Nisonoff, Seyone Chithrananda, Petr Skopintsev, Amos J. Nissley, Jamie H. D. Cate.\ne-mail: j-h-doudna-cate@berkeley.edu\nNature Communications|        (2024) 15:10627 1\n1234567890():,;\n1234567890():,;\nRNAcentral overrepresents rRNAs, tRNAs, lncRNAs and a few small\nRNA families (i.e. snRNAs, snoRNAs, miRNAs, and piRNAs). Further-\nmore, some of the underlying databases are no longer maintained or\nupdated, or have substantial sequence overlap leading to redundant\nentries in the database. Taken together these databases are far less\nextensive than protein databases that include hundreds of millions of\nunique sequences\n16. Furthermore, a related fundamental challenge\nwith RNA structure prediction is the difﬁculty in building robust\nsequence alignments for intact functional RNAs due to limitations in\nidentifying their 5’and 3’ends and the uneven sampling of sequences\nacross phylogeny\n20,21. Finally, the number of available high-quality RNA\nstructures in the Protein Data Bank (PDB)22 lags those for proteins by\norders of magnitude, and is heavily biased towards a small number of\nRNA structural types, particularly those found in ribosomes\n13.\nThe ribosome is a major target for engineering an expanded\ngenetic code23. Ribosomal RNA (rRNA) catalyzes peptide bond for-\nmation by the ribosome, and many efforts have attempted to use\ndirected evolution of rRNA to engineer ribosomes that can incor-\nporate non-proteinogenic monomers into polypeptides\n24– 27. How-\never, the complexity of ribosome assembly constrains directed\nevolution of the ribosome for novel functions\n28– 31.I nEscherichia coli,\nribosomes comprise three ribosomal RNAs (5S, 16S, and 23S rRNAs)\nand 54 proteins, along with many protein factors required to\nassemble them in cells. As a result of this complexity, ribosomes\nobtained from directed evolution experiments often have defects in\ntheir assembly and lose activity\n32. Strategies for the directed evolu-\ntion of proteins for new function often begin with thermostable\nproteins, which are more robust to mutations required to recover\nfunctional variants\n33– 35. It is presently infeasible, however, to replace\nthe E. coli large ribosomal subunit RNA (23S rRNA) with a thermo-\nstable 23S rRNA from another organism, as efforts at 23S rRNA\ndirected evolution beginning from the rRNA from other organisms\nhave so far been unsuccessful\n29.\nHere we leveraged the Genome Taxonomy Database (GTDB)36 to\nbuild more comprehensive RNA sequence databases and alignments.\nThe GTDB provides a standardized taxonomy across all high-quality\nbacterial and archaeal genomes including metagenome-assembled\ngenomes and single-cell ampliﬁed genomes. This greatly expands the\navailable RNA sequence diversity, as the vast majority of microbes are\nunculturable. Furthermore, as a standardized taxonomy, the GTDB\nprovides a framework for linking sequence data to phenotypes and\nother experimental data, which are often limited to cultured microbes.\nThe taxonomy presently includes over 400,000 bacterial and archaeal\ngenomes organized around over 85,000 species clusters, which pro-\nvides a rich resource for principled genomic comparisons, sequence\nanalysis and sequence alignment. Weﬁnd that RNA sequences mined\nfrom GTDB genomes represent a more diverse set of sequences than\nstate-of-the-art databases with only one clear exception– 16S rRNA. We\nmapped growth temperatures from other sources to the GTDB and\nused an existing machine-learning approach to predict optimal growth\ntemperatures for reference genomes lacking direct growth tempera-\nture information. We combined these with the RNA sequences mined\nfrom the GTDB to create the GARNET (Gtdb Acquired RNa with\nEnvironmental Temperatures) database. Using GARNET, we developed\ntwo types of machine-learning models to map sequences to functional\nproperties of the RNA. We trained a compact RNA generative Graph\nNeural Network (GNN) using a 23S rRNA multiple sequence alignment\n(MSA) with structural conditioning. We also trained Generative Pre-\ntrained Transformer (GPT)-like RNA language models that revealed an\noptimal triplet encoding for RNA. Byﬁnetuning these RNA generative\nmodels on hyperthermophilic RNA sequences, we were able to predict\nmutations in theEscherichia coliribosome that increased its thermo-\nstability. These results open new approaches to expand computational\nalgorithms for predicting RNA structure and altering RNA function in\nbiology.\nResults\nBuilding RNA sequence datasets from GTDB genomes\nTo generate diverse and minimally-redundant alignments of RNA\nsequence families for the GARNET database, we turned to the GTDB\ngenomes which represent 80,789 bacterial and 4416 archaeal species\nclusters (release 214.1) (Fig.1a). First, we built an rRNA sequence\ndataset by searching each GTDB species reference genome for 23S,\n16S, and 5S rRNA sequences. Searches were performed with Infernal\n20\nusing the corresponding Rfam covariance models (CMs), taking the\ntop hit per genome with an e-value < 1e-5 and aligning to at least 85%\nof the consensus CM sequence. If no such hit could be found, we\nadditionally searched the available non-representative genomes in\neach species cluster. We further ensured alignment quality by\nremoving hits that broke a substantial fraction of the consensus base\npairs or had exceedingly long insertions (see Methods for details).\nFor 23S rRNA, which is roughly 2.9 kb in length, we identiﬁed a 23S\nrRNA sequence for 32,317 species (Fig.1b). The absence of a full-\nlength 23S or 16S rRNA sequence in many genomes likely reﬂects the\nfragmented nature of some metagenome-assembled genomes and\nthe occasional presence of introns that cause partial hits. We addi-\ntionally searched all GTDB representative genomes for 228 RNA\nfamilies using Rfam models that are likely to occur in bacteria or\narchaea and are over 100 nucleotides long, applying the same\nquality-control criteria as for ribosomal RNAs except allowing for\nmultiple hits per genome. This search identi ﬁed a total of\n714,662 sequences, with the seven largest families comprising 58% of\nthe 228 RNA sequence dataset (Fig.1c).\nWe evaluated the sequence diversity of the GTDB-derived data-\nsets by assessing the number of unique sequences at different frac-\ntional identity thresholds compared to state-of-the-art datasets for\nthese RNA families. For 23S and 16S rRNA alignments, we compared\nagainst the SILVA database\n18; for 5S rRNA, we compared against the\n5SRNAdb37 and the Rfam full alignment17; for the top three most\nabundant of the 228 RNA families (T-box leader, cobalamin riboswitch,\nand TPP riboswitch), we compared against Rfam full alignments. In all\ncases, except for 16S rRNA and 23S rRNA, the GTDB-derived align-\nments had substantially greater sequence diversity compared to the\nstate-of-the-art dataset (Fig.1d, e, Supplementary Fig. 1c, d). For 23S\nrRNA, the SILVA database had comparable diversity to the GTDB-\nderived alignment, and for 16S rRNA, the SILVA database had greater\ndiversity (Fig.1d, Supplementary Fig. 1c), likely due to the widespread\nuse of 16S rDNA sequencing of new microbial isolates and environ-\nmental samples. Taken together, these results highlight the beneﬁto f\nusing the GTDB as a framework for building comprehensive RNA\nsequence datasets.\nMapping optimal growth temperatures to GTDB reference\ngenomes\nThe GTDB taxonomic framework allows us to link RNA sequences\nderived from the GTDB genomes to phenotypes, which can aid in\nRNA modeling and engineering. We chose to map GTDB species to\noptimal growth temperatures (OGTs) from TEMPURA\n38 and Gosha39\ndatabases. However, since the TEMPURA and Gosha databases only\ninclude cultivated species, they only have experimental OGTs for 15%\nof the GTDB reference species. We therefore inferred OGTs of all\nGTDB reference genomes using TOME\n40. TOME predicts the OGT for\nan organism using a machine learning model trained on proteome-\nwide dipeptide (2-mer) distributions. Importantly, TOME was trained\non only a subset of organisms now available in the TEMPURA and\nGosha databases. We therefore used these new organisms to validate\nTOME predictions, and found that the predicted OGTs correlated\nwell with the TEMPURA and Gosha sets not used for TOME training\n(Fig. 2a, Supplementary Data 2; R\n2 values of 0.868 and 0.881,\nrespectively). We also used isolation source metadata associated\nwith each GTDB reference genome as a check on TOME OGT\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 2\npredictions, especially for uncultivated species. Although the isola-\ntion source of each organism is heterogeneous in terminology and\nmay not reﬂect the actual optimal growth conditions, we found that\nthe metadata with unambiguous source information is consistent\nwith TEMPURA and Gosha OGTs (Fig.2b, Supplementary Data 2) (See\nMethods). This is also true for OGTs predicted using TOME (Fig.2b,\nSupplementary Data 2). Interestingly, TOME predicted hyperther-\nmophilic species (OGT > = 60 °C) in both archaea and bacteria in\nclades with no known hyperthermophiles in the TEMPURA or Gosha\ndatabases (Fig. 2c, Supplementary Fig. 2, Supplementary Data 2).\nThese results provide a rich resource for inferring the physiological\ntemperature at which RNAs and proteins from GTDB organisms\nfunction optimally. We combined the GTDB-derived RNA sequences\nwith the TOME-predicted OGTs to create the GARNET (Gtdb\nAcquired RNa with Environmental Temperatures) database, to use\nfor training new RNA deep learning models.\nA sequence and structure based RNA generative model for\n23S rRNA\nGenerative deep learning models that integrate structural information\nprovide highly compact representations of protein families that have\nproven useful for protein design\n41. These models leverage the fact that\nstructure is generally conserved within protein families. We extended\nthis framework to RNA, creating compact structure-informed models\nto circumvent scalability constraints inherent to the extensive length\nof 23S RNA. We harnessed the sequence diversity within the GTDB and\nthe wealth of high-resolution structures available for the large ribo-\nsomal (50S) subunit to develop a Graph Neural Network (GNN) model.\nFor 23S rRNA, the known representative 3D structures provide abun-\ndant information to benchmark MSAs and better model the RNA\nfamily. Our generative model inputs a distance matrix for the repre-\nsentative structure of the family\n42, and is trained on next-token pre-\ndiction for an aligned MSA41.\nGTDB v214.1\nGenomes and phylogenetic \ntree for 80,789 bacterial / \n4,416 archaeal species\nGrowth temperature\nTOME predicted optimal \ngrowth temperature for all \nGTDB reference genomes \nRNA alignments\nAnnotation & alignment of \nRNA sequences from GTDB \ngenomes using Infernal / Rfam\na\nbacteria\nGTDB species\n23S rRNA\n16S rRNA\n5S rRNA\narchaea\n80,789\n30,928\n34,076\n51,872\n4,416\n1,389\n1,465\n3,221\nb\n# sequences # Rfam full\nT-box leader 129,071 12,315\nCobalamin riboswitch 74,360 14,022\nTPP riboswitch 53,555 10,206\nBacterial RNase P class A 53,493 6,481\ntmRNA 46,559 6,693\nSAM riboswitch 34,758 6,161\n6S RNA 22,856 3,786\nc\nGARNET\nRfam full\ne TPP riboswitch\nFractional identity\n1.00 .95  .90  .85  .80  .75  .70  .65  .60\n1,000\n10,000\n100,000\nCobalamin riboswitch\nFractional identity\n1.00 .95  .90  .85  .80  .75  .70  .65  .60\n1,000\n10,000\n100,000\nT-box leader\nFractional identity\n1.00 .95  .90  .85  .80  .75  .70  .65  .60\n1,000\n10,000\n100,000Number of sequences\nFractional identity\n1.00 .95 .90 .85 .80 .75 .70 .65\n23S rRNA\n100\n1,000\n10,000\n100,000Number of sequences\nd\nGARNET\nRfam full\nSILVA NR99\n5SRNAdb\nArchaea\nBacteria\nFractional identity\n1.00 .95 .90 .85 .80 .75 .70\n1,000\n100\n10,000\n100,000\n1,000,000 16S rRNA\nFractional identity\n1.00 .95 .90 .85 .80 .75 .70 .65\n100\n1,000\n10,000\n100,000 5S rRNA\nFig. 1 | The Genome Taxonomy Database as a source for RNA sequences.\na Construction of the GARNET database centered on the GTDB structure,\nlinking RNA alignments mined from GTDB genomes with growth temperature\nprediction through a consistent taxonomy.b Number of GTDB species found\nto have at least one high-quality, near-full length hit for 23S, 16S, and 5S rRNA.\nc Top seven non-rRNA Rfam families with most sequences found in GTDB\nrepresentative genomes compared against the Rfam full alignment. In contrast\nto the rRNA alignments, multiple sequences per genome were allowed. Infor-\nmation for the entire 228 RNA dataset can be found in Supplementary Data 1.\nd Comparing diversity of GARNET RNA sequences against state-of-the-art\ndatasets for 23S rRNA, 16S rRNA, and 5S rRNA byﬁltering the sequences at a\nrange of pairwise fractional identity thresholds with VSEARCH\n58. e Diversity\ncomparison for the top three most abundant of the 228 RNA families in GAR-\nNET with VSEARCH.\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 3\na\nb\nc\nThermoplasmatota\nThermoproteota\nHalobacteriota\nAsgardarchaeota\nMicrarchaeota\nNanoarchaeota\nAenigmatarchaeota\nIainarchaeota\nOther\n30 100\nGrowth Temperature (°C)\nPhylum\nSpecies in Node\n1\n10\n100\nGosha / TEMPURA\nOGT ≥ 60°C\nGosha / TEMPURA\nOGT < 60°C\nTOME OGT ≥ 60°C\nTOME OGT < 60°C\nTOME OGT ≥ 60°C in\nnew thermophile family\n0\nn=336\nn=12,708\nn=1,248\nn=83,957\nn=580\n10050\nPercent\nNo isolation\nsource data\nNot thermophilic\nisolation source\nThermophilic\nisolation source\nPhylum\nTOME\nTEMPURA\nGosha\n23S\n16S\n5S\n7.5\n7.0\n6.5\nFig. 2 | Optimal growth temperatures of GTDB reference organisms.\na Correlation of TOME-predicted and experimental OGTs from Gosha and TEM-\nPURA, excluding species from TOME’s training set (n = 3346 and 7404 species,\nrespectively).b Archaeal phylogenetic tree of GTDB reference organisms, grouped\nat the Family taxonomic rank, arbitrarily rooted. A similar tree for bacteria is in\nSupplementary Fig. 2. Node tip sizes are proportional to the number of species\nrepresented by node (log2 transformed). Inner circle indicates Phylum. The next\ncircle represents TOME-predicted min, median, and maximal optimal growth\ntemperatures of all species within rank. The next two circles similarly represent\nempirically measured optimal growth temperatures pulled from the TEMPURA and\nGosha datasets, respectively. Outer circles represent the total number of 23S, 16S,\nand 5S detected in each rank, respectively (log2 transformed).c Thermal isolation\nsources for GTDB bacterial and archaeal species (manually classiﬁed from GTDB\nmetadata) comparing species with hyperthermophilic OGTs (> = 60 °C) in the\nGosha / TEMPURA databases, TOME hyperthermophiles, and non-\nhyperthermophiles. The bottom bar corroborates TOME hyperthermophiles\n(n = 580) with no close hyperthermophilic relatives in Gosha / TEMPURA\n(family-level).\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 4\nThe model leverages a graph-based representation of the RNA\nstructure to build a sparse attention mechanism (i.e. Graph Attention\nNetwork) in which the positions attend to theirk-nearest neighbors in\nstructure space at each layer (Fig.3a, b). We pre-processed the 23S\nrRNA MSA of the GARNET sequences for training. The corresponding\ngraph was created by choosingk-nearest neighbors to each nucleotide\nfrom a distance matrix ofE. coli23S rRNA, aligned with the MSA so that\nnucleotides in matrix columns and rows match their counterparts in\nthe MSA (see Methods). This matrix was derived by calculating the\nminimal interatomic distances between nucleotides pairs in the 23S\nrRNA. We found that usingk = 50 nearest neighbors provided an\noptimally trained model, with respect to model size and perplexity\n(Fig. 3c). For the model input analysis, the distance matrix was trans-\nformed into a binary contact map by selecting thek-nearest neighbors\nf o re a c hn u c l e o t i d e( s e eS u p p l e m e n t a r yF i g .2 ) .W ef o u n dt h a ta tk =5 0\nnearest neighbors, the model samples all contacts below ~12 Å, and a\nsubset of longer-range contacts up to 24 Å, or distances at which inter-\nhelical packing can be detected (see Fig. 3d– f, Supplementary\nFigs. 3 and 4). Complete model speciﬁcations are available in Supple-\nmentary Data 3.\nAm o d iﬁed GPT language model for RNA\nAlphaFold relies on MSAs as a central component of an end-to-end\ndeep learning algorithm for protein structure prediction1. However,\nlarge language models for proteins such as ESM-2 replace MSAs in\nstructure prediction, and are particularly useful when MSA informa-\ntion is lacking. In the case of RNA, obtaining robust MSAs can be\nchallenging\n20,21, even with databases as large and diverse as GARNET.\nFurthermore, whereas GNNs require a structural prior for training,\nlanguage models are not restricted by structural constraints or\nassumptions about RNAﬂexibility or whether an RNA might adopt\nmultiple folds. We therefore tested whether a language model (LM) for\nRNA could be developed using sequences from GARNET. Weﬁrst\nmodiﬁed a compact GPT model architecture– nanoGPT\n43– for training\non RNA sequences and tested different methods of tokenizing\nnucleotides (Fig.4a). Using 23S ribosomal RNA (rRNA) sequences from\nGARNET (Fig.1, Supplementary Data 1), we found that models trained\nusing tokens representing three nucleotides, with a 1-nucleotide shift\nper token, performed substantially better than using either individual\nnucleotides or paired nucleotides (Fig.4b, Supplementary Data 3 and\nMethods). We also found using rotary positional embedding (RoPE)\n44\nin each attention layer allowed RNA LMs to be trained with paired-\nnucleotide encodings. However, paired-nucleotide tokenization\nrequired training models with a slower learning rate, and these models\nhad a higher validation perplexity than models using RoPE with triplet-\nnucleotide encoding (Fig.4b ) .I na d d i t i o nt o2 3 Sr R N A ,w ea l s ot r a i n e d\na more general RNA LM using sequences from 231 RNA families in\nGARNET (228 RNA dataset plus three rRNA datasets), as described\nabove (Fig.4c). These models had lower validation perplexities com-\npared to the RNA LMs trained only on 23S rRNA sequences (Supple-\nmentary Data 3). They also are capable of generating RNA sequences\nthat align with full-length 23S and 16S rRNA when queried with their\nrespective 5’ends (Fig.4d).\nFinetuning RNA generative models with hyperthermophilic\nsequences\nReplacing theE. coli 23S rRNA with a thermostable 23S rRNA from\nanother organism is presently not feasible29.W et h e r e f o r et e s t e d\nwhether ﬁnetuning the GNN and RNA LM models using hyperther-\nmophilic 23S rRNAs could help identify mutations that make theE. coli\nribosome more stable for future directed evolution efforts. Weﬁne-\ntuned the GNN and RNA LM pretrained models described above using\n23S rRNA sequences from hyperthermophilic bacteria and archaea\nwith TOME-predicted OGTs of 60°C or higher (Methods). We then\nused the resulting pretrained andﬁnetuned models to generate sets of\n1000 RNA sequences seeded with the 5’-end ofE. coli23S rRNA, and a\nrange of“temperature” scaling factors to modulate the probabilities of\ntoken generation (Methods).\nWe assessed the quality of the RNA sequences generated from the\nmodels, i.e. how“23S-like” they are, by comparing them to the covar-\niance model for bacterial 23S rRNA in Rfam (RF02451) using cmsearch\nin the Infernal suite of programs\n20,29. We evaluated the full set of 23S\nrRNA sequences in the GARNET database as a control. Naturally\noccurring sequences in GARNET had cmsearch scores that clustered\naround 1900 and 2700 for archaeal 23S and bacterial 23S, respectively\n(Fig. 5a-d). Sequences generated from the GNN had high cmsearch\nscores within the range of natural sequences, although these dropped\nat higher generation temperatures likely due to the dropout of local\nRNA sequence segments (Fig. 5a, b, and Supplementary Fig. 5).\nSequences generated by the RNA LMs also had high cmsearch scores,\nsuggesting they have bacterial 23S rRNA-like properties across all\ngeneration temperatures tested (Fig.5c, d). At lower generation tem-\nperatures, the ﬁnetuned RNA LM generated some sequences that\nharbored long stretches of repetitive sequence, resulting in low\ncmsearch scores (Supplementary Fig. 6c, d).\nWe also examined secondary structure preservation as a separate\nmeasure of the 23S-like properties of the generated sequences. Natu-\nrally occurring 23S rRNAs typically contain a small percentage of non-\ncanonical base pairs (i.e. base pairs other than standard Watson-Crick-\nFranklin and G-U pairs) in the consensus secondary structure for\nRF02451 model (Fig.5e– h). Sequences generated by the pretrained\nRNA LM retained a similar proportion of non-canonical base pairs up to\na generation temperature of 0.9, while theﬁnetuned models inserted\nmore non-canonical pairs relative to natural sequences at tempera-\ntures higher than 0.5 (Fig.5g, h, and Supplementary Fig. 6d). The GNN\nmodels started to include a higher percentage of non-canonical pairs\nat generation temperatures of 0.6 or higher (Supplementary Fig. 5d).\nTaken together, these quality control measures inform selection of\nsequence generation temperatures that can aid subsequent analyses of\nsequences generated from the 23S rRNA GNNs and RNA LMs trained\non GARNET sequences (Supplementary Fig. 7, Supplementary Data 3).\nSequences generated by GenerRNA\nSeparately, we attempted to use a different generative RNA language\nmodel implemented based on the nanoGPT code\n43,45. This imple-\nmentation of nanoGPT, called GenerRNA, was pretrained using the\nRNAcentral database\n19, and used a byte pair encoding (BPE)\nalgorithm46 to generate a 1024 token library for RNA. We used the\nGenerRNA model pretrained on RNAcentral sequences, and alsoﬁne-\ntuned this model on the GARNET-all and GARNET-hyperthermophile\nsequences using the provided GenerRNA tokenization and training\ncode. We then generated sets of 1000 23S sequences, analogous to the\nprocess for the RNA LMs. However, none of the three GenerRNA\nmodels was capable of generating full-length 23S-like sequences\n(Supplementary Fig. 8, see Methods).\nIdentifying mutations to stabilize theE. coliribosome\nTo identify potential mutations to theE. coli 23S rRNA that might\nconfer thermostability, we examined sequences generated from the\n23S rRNA GNN and LM pretrained andﬁn e t u n e dm o d e l s( P Ta n dF T\nmodels, respectively) using a generation temperature of T = 0.5\n(Methods). Weﬁrst compared the Jensen-Shannon divergence (JSD) of\nnucleotide frequency distributions of the FT-generated sequences\nrelative to the PT-generated sequences, after masking the positions\nused as the seed as well as those with less than 50% occupancy in the\nalignment (Supplementary Data 4). We also calculated the JSD of nat-\nural hyperthermophilic 23S rRNA sequences used forﬁnetuning rela-\ntive to the entire GARNET 23S rRNA set (Supplementary Data 4). 23S\nrRNA positions with high JSDs differ the most in which nucleotides are\ngenerated by the PT and FT models, indicating mutations that may be\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 5\na b\nInformation flow\nStructure\nStructure and sequenceBackbone\nNode (ribonucleotide)\nStructure encoder Sequence decoder\n(autoregressive)\nNode embeddings\nStructure\nSelf-attention\nPosition-wise Feedforward\nEncoder\nDecoder\nCausal Self-attention\nPosition-wise Feedforward\nSequence\nEdge embeddings\n660 690 720 750 780 810 840\nSequence coordinate i\n660\n690\n720\n750\n780\n810\n840 Sequence coordinate j\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\ne\n3 6 9 1 21 51 82 12 42 73 0\nPairwise nucleotide distance, Å\n0\n2000\n4000\n6000\n8000\n10000Density, a.u.\n0 2 04 06 08 0 1 0 0\nk nearest neighbors\n1.75\n1.8\n1.85Test perplexity\nH33\nH34\nH35\nG774\nA685\nDistance cutoff (12 Å)\nk nearest neighbors (50)\nH33\nH34\nH35\nf\ndc\n64\nHidden dimension d\n128\nk nearest \nneighbors\nAll\n100\n50\n20\n10\n5\nA\nU\nG\nU\nA\nU\nG\nU\nU\nG\nU\nA A A G\nC\n5’ 5’\n3’3’\nFig. 3 | A 23S rRNA generative model using GTDB sequences and large ribo-\nsomal subunit structures. aGraph Neural Network (GNN) model schematic.\nb GNN model architecture. Panels (a)a n d(b) are adapted from Ingraham et al41.t o\nillustrate their use for RNA. For detailed model parameters and training data sta-\ntistics refer to Supplementary Data 3.c Test perplexity of the GNN models plotted\nas a function ofk-nearest neighbors, highlighting that the model does not sig-\nniﬁcantly improve fork values greater than 50. Theﬁnal perplexity of the model\nwith hidden dimensionsd =1 2 8 ,a n dk = 50 was 1.751.d Histogram of inter-\nnucleotide distances sampled by selectingk nearest neighbors in the distance\nmatrix forE.coli 23S rRNA structure (PDB ID: 7K00)\n42. Choosingk =5 0c o v e r sa l l\ndistances less than 12 Å.e Comparison of the contact maps generated from the\ndistance matrices, based either on the distance cutoff or thek nearest-neighbors\ncriteria (see Methods). Top-right, the sum of the contact maps for 18 bacterial and\narchaeal ribosomal RNA structures, projected onto the MSA sequence alignment,\nand based on the 12 Å distance cutoff criterion. The number of contact maps that\nalign for a given pair of nucleotides is color-coded in the color bar on the right.\nBottom-left, contact map forE. coli23S rRNA, based on selectingk = 50 nearest\nneighbors to each nucleotide. The two types of contact maps show high similarity.\nf Structure of the three stem-loops highlighted in (e). A 12 Å inter-helical packing\ncontact is shown with a dashed line in (f), and with an arrow in (e).\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 6\nimportant for thermostability (Supplementary Figs. 9– 11). Interest-\ningly, there was very little overlap in positions with the highest JSDs\nwhen comparing GNN- or RNA LM-generated sequences to those\npredicted by comparing natural sequences, whereas there was sub-\nstantial overlap between the deep learning approaches (Fig.6a).\nNucleotide positions predicted to confer thermostability using the 231-\nRNA trained LMs also differed from those obtained from natural\nsequences in GARNET (Fig.6a). These results show that the deep\nlearning models predict nucleotide changes inE. coli 23S rRNA that\ndiffer markedly from those that could be gleaned from the 23S rRNA\ndata in GARNET.\nAlthough sorting by JSD can help identify candidate stabilizing\nmutations, individual mutations may depend on sequence context and\nmay require evaluation as part of an entire 23S rRNA sequence. Fur-\nthermore, the generated sequences may not represent all stabilizing\nmutations learned by the models. For example, a rare sequence var-\niation in the A loop of 23S rRNA at positions U2554 and U2555 only\noccurs in a single phylum of archaeal hyperthermophiles, Thermo-\nproteota, in which one or both nucleotides are mutated to a C\n47.T h e s e\nmutations in theE. coli ribosome are known to improve ribosome\nstability47, yet neither position appears as a top candidate using the JSD\nﬁltering described above. To assess whether the GNN and RNA LM FT\nmodels support these mutations, we calculated the probability of\ngenerating mutantE. coli23S rRNA sequences. Since the models were\ntrained on sequences similar toE. coli, mutations away from the\nwildtype (WT)E. colisequence often lead to lower probabilities. We\ntherefore compared the probability of generating a mutantE. coli23S\nsequence from the FT model relative to the PT model, and normalized\nit to that of the WT sequence (ΔΔlogP) (Fig.6b). Using this metho-\ndology, a U2554C mutation is supported by the FT model better than\n85.4% and 72.3% of all possible single mutants when evaluated by the\n23S LM and 231-RNA LM, respectively, and 57.4% of single mutants\nwhen evaluated by the GNN model (Supplementary Fig. 12 and Sup-\nplementary Data 5), consistent with the moderate increase in ther-\nmostability seen withE. coli50S subunits harboring this mutation\n47.W e\nalso found that the combined U2554C-U2555C mutation had a positive\nΔΔlogP predicted from the GNN and RNA LMs (Supplementary Data 5).\nTaken together, JSD-based sorting and the use of model probabilities\nhelp identify sites in 23S rRNA that could confer higher thermostability\nto theE. coli50S subunit.\nTesting 23S rRNA mutations predicted to stabilize the ribosome\nOne of the strongest predictions from the LM and GNN models for a\nmutation that could confer thermostability to theE. coli50S subunit\noccurs in the closing loop at the end of helix H89 in 23S rRNA, adjacent\nto the peptidyl transferase center of the ribosome. The H89 stem-loop\nFig. 4 | Tokenization schemes for RNA language models. aRepresentation of\nnucleotides as tokens for single, paired, or triplet nucleotides. Tokens are encoded\nfor nucleotides in 1-nucleotide steps, i.e. are overlapping for paired and triplet\nnucleotides. Beginning and end tokens are also included in the token library.\nb Perplexity of RNA language models trained on 23S rRNA sequences, with the\nnanoGPT model modiﬁed to use an overall rotary positional embedding (RoPE), or\nwith RoPE applied to each attention layer. Training with paired-nt and overall RoPE\nwas conducted for 100,000 iterations, whereas the other models were trained for\n1 M iterations, with a batch size of 18 in all models. A perplexity value of 4 would be\nrandom (i.e. 4 nucleotides to choose from), and a value of 1 would indicate perfect\ncertainty in nucleotide choice. The perplexity after training for a random model\nshould be 4 regardless of the tokenization scheme, due to the 1-nucleotide steps\nused with the paired and triplet encoding.c Perplexity of an RNA LM pretrained on\n231 RNA sequence families in GARNET (Supplementary Data 1). The perplexity of an\nRNA LM modelﬁnetuned on hyperthermophilic RNAs, starting from the pretrained\ngeneral model, is 1.33. For detailed model parameters and training data statistics in\npanels (b) and (c) refer to Supplementary Data 3.d Alignment of 23S rRNA\nsequences generated using the more general pretrained 231-RNA LM, showing the\n3’end of the generated sequences (n = 100).e Alignment of 16S rRNA sequences\ngenerated using the more general pretrained 231-RNA LM, showing the 3’end of the\ngenerated sequences (n = 100). Sequence generation in panels (d)a n d(e)w a s\nseeded with 100 nucleotides ofE. coli23S rRNA or 16S rRNA, respectively, and using\na temperature of 0.2. The bottom row is theE. colisequence, andE. colinucleotide\nnumbering is also shown. White space shows regions where insertions and dele-\ntions are present in the sequences.\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 7\nfolds late in 50S subunit assembly and also engages with ribosome\nassembly factors48,49. We, therefore, examined the JSDs of generated\nsequences and model probabilitiesin this region for potential muta-\ntions that might stabilize the ribosome. Theﬁnetuned GNN model and\nboth ﬁnetuned LMs predict a U to C mutation in the apical loop of H89\nat position 2477 to confer thermotolerance using the JSD calculation\n(ranked 65, 18, or 178 by the 23S rRNA GNN, 23S rRNA LM, or 231-RNA\nLM, respectively). By contrast, nucleotide 2477 is not a top hit when\nusing the JSD metric on natural GTDB sequences (ranked 1007 out of\n2904 positions). Introducing the U2477C mutation inE. coli23S rRNA\nis also supported by the log-probability calculations (Fig.6d, Supple-\nmentary Fig. 12a). The models also support sequences with U to C\nmutations at nearby positions 2473 and 2474, either individually\n(U2474C) or in combination, and predict these to confer thermo-\ntolerance (Supplementary Data 5, Fig.6d), consistent with their slight\nenrichment in hyperthermophilic 23S rRNAs in GARNET (Supplemen-\ntary Data 4, Supplementary Data 1). The sequences generated by the\nGNN and RNA LMs often introduced compensatory base pair changes\nin H89, and the models yielded lowerΔΔlogP values when only one\nnucleotide in a pair was changed (Supplementary Fig. 12b). However,\nwe did not prioritize base pair changes in the H89 stem, as compen-\nsatory base pairs were deemed unlikely to have a dramatic impact on\nribosome stability at the initial stages of unfolding based on our\nprevious work\n47. Given the importance of H89 late in ribosome\nassembly, we made mutations at positions 2473, 2474, and 2477 to test\ntheir effects on E. coli 50S subunit thermostability. We also re-\nexamined the A loop mutations in the closing loop of H92 at positions\n2554 and 2555 (Supplementary Data 5, Fig.6c, f, g). As noted above,\nU2554C and U2555C mutations in H92 (H92-CC) were previously\nshown to globally stabilize theE. coli50S subunit\n47.\nWe puriﬁed in vivo assembled 50S subunits with U2473C-U2474C,\nU2477C, U2554C-U2555C, and U2477C-U2554C-U2555C mutations\nusing MS2-tagging\n50,51. We additionally puriﬁed WTE. coli50S subunits\nwith an MS2-tag to serve as a control. To test for thermal stability, we\npre-incubated the 50S subunits at 65 °C, cooled them to room tem-\nperature, and then assessed if they maintained activity after heat\ntreatment in an in vitro translation reaction (Fig.6e). We found that\nH89 mutations U2473C-U2474C and U2477C do not affect the activity\nof ribosomes at 37 °C (Fig.6f). However after pre-incubation at 65 °C,\n50S subunits with a U2477C mutation are roughly twice as active as WT\nsubunits (Fig. 6f), indicating that this mutation stabilizes the 50S\nsubunit. By contrast, ribosomes with the U2473C-U2474C mutations\nare not more active than WT after pre-incubation at 65 °C (Fig.6f),\nindicating these mutations do not stabilize the 50S subunit in this\nassay. We also examined whether the stabilization from mutations in\nH89 and H92 are additive. 50S subunits with U2554C-U2555C (H92-CC)\na\nf\nd\nc\nh\ng\nb\ne\n0.00\n0.02\n0.01Density\n0 500 1500 1000 3000 25002000 3500\ncmsearch score\npretrained LM\n(T=0.5)\nfraction non-canonical base pairs\n0.00 0.08 0 . 0 20 . 0 40 . 0 6\n0\n100\n50\nDensity\n0 500 1500 1000 3000 25002000 3500\ncmsearch score\n0.000\n0.006\n0.002Density\n0.004\nfinetuned GNN\n(T=0.5)\nfraction non-canonical base pairs\n0.00 0.08 0.02 0.04 0.06\n0\n50\n25\nDensity\n75\nGARNET bacteria\nGARNET archaea\nGenerated\nGARNET full\nfraction non-canonical base pairs\n0.00 0.08 0.02 0.04 0.06\n0\n100\n50\nDensity\n0 500 1500 1000 3000 25002000 3500\n0.0000\n0.0075\n0.0025Density\n0.0050\ncmsearch score\npretrained GNN\n(T=0.5)\n0 500 15001000 300025002000 3500\ncmsearch score\n0.000\n0.004\n0.002Density\nfraction non-canonical base pairs\n0.00 0.08 0.02 0.04 0.06\n0\n40\n20\nDensity\n60finetuned LM\n(T=0.5)\nFig. 5 | 23S rRNA sequences generated by GNN and GPT-like RNA models.\na– d Cmsearch scores for sequences generated from the pretrained GNN model (a),\nﬁnetuned GNN model (b), pretrained RNA LM (c), andﬁnetuned RNA LM (d)t r a i n e d\non 23S rRNA sequences at generation temperature T = 0.5 compared to naturally\noccurring 23S rRNAs in GARNET. For the GARNET reference distributions, random\nsubsets of 1000 bacterial sequences and 1000 archaeal sequences were used.\ne– h 23S rRNA sequences generated from the pretrained GNN model (e), ﬁnetuned\nGNN model (f), pretrained RNA LM (g), andﬁnetuned RNA LM (h) according to the\nfraction of disrupted canonical base pairs (i.e. Watson-Crick-Franklin and G-U)\nrelative to the Rfam RF02541 consensus secondary structure (denoted non-\ncanonical base pairs) in the generated sequences compared to naturally-occuring\n23S rRNAs.\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 8\nmutations were more than threefold as active as WT subunits after pre-\nincubation at 65 °C. Addition of the U2477C mutation to the H92-CC\nmutations (U2477C-H92-CC) did not increase the stability past that of\nthe H92-CC mutations on their own (Fig.6g).\nWe focused on two additional regions in domains IV and V— helix\nH68 and helices H81 and H82— that contained multiple positions\nranking in the top 200 highest JSD values (Fig.6c, Supplementary\nFigs. 9– 11). Domain IV is the penultimate domain to fold\n31,48 and\nFig. 6 | Mutations in 23S rRNA predicted by deep learning models to confer\nthermostability onE. coliribosomes. aMatrix showing the overlap in the 200\npositions with highest Jensen-Shannon divergence inﬁnetuned (FT) model-\ngenerated versus pretrained (PT) model-generated sequences for the GNN, LM\nmodels, and in the hyperthermophilic versus total GARNET 23S rRNA sequences.\nb Strategy for calculatingΔΔlogP values for candidate mutations, using log like-\nlihoods of sequence generation from FT versus PT models, with WTE. coliserving\nas a normalization control.c Positions within four regions of theE. coli23S rRNA\nwith JSD values ranked in the top 200. Coloring indicates the number of models\nwhich identify each position.d Analysis of the four regions in panel (c)f o rc a n d i -\ndate thermostabilizing mutations. For each position, the most frequent nucleotide\nin FT-generated sequences (top FT nucleotide) is grafted into theE. coli23S rRNA\nsequence and used to calculateΔΔlogP for the 23S LM, 231-RNA LM, and GNN\nmodels. Overlapping values are denoted with an asterisk in the graph for clarity.\ne Schematic for the heat-treatment in vitro translation assay. Puriﬁed 50S subunits\nare incubated at the indicated temperature, cooled to room temperature, and then\nadded to a HiBit in vitro translation assay. The peptide complements an inactive\nprotein fragment to form an active luciferase.f– i Activity of pre-incubated ribo-\nsomes in the HiBit in vitro translation assay. Secondary structures of helices H89 (f),\nH92 (g), H68 (h), and H81/H82 (i)o fE. coli23S rRNA. Positions that were mutated in\nthis study are shown in red. For panelsf throughi, WT, and mutant 50S subunits all\ncontain an MS2 tag (Methods). Relative activity is calculated as the slope of the\ninitial increase in luminescence during translation and normalized to the WT value\nat the given temperature. Data and error bars represent the average and standard\ndeviation of three reactions, respectively. Source data for panels (f) through (i)a r e\nprovided as a Source Dataﬁle.\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 9\nincludes helix H68, which harbors multiple non-canonical base pairs in\nt h em i d d l eo ft h es t e m42 with high JSD values. Notably with the GPT-like\nLMs, pairwise changes for all three of these non-canonical pairs inde-\npendently resulted in higher log probabilities than changes to indivi-\ndual bases in a pair (Fig.6d). Due to the fact that H68 includes multiple\nadjacent non-canonical base pairs, we tested the H68 changes as a\ngroup (H68\nmut) and found that changing these base pairs increasedE.\ncoli ribosome stability (Fig.6h). A second set of nucleotides with high\nJSD values that cluster in helices H81/H82 involve four changes in two\nWatson-Crick-Franklin base pairs, from A-U to C-G pairs (Fig.6i). The\nﬁfth nucleotide, G2286, is unpaired (Fig.6i) and interacts with ribo-\nsomal protein bL33. In contrast to H68, the two base pair changes do\nnot result in more positiveΔΔlogP values using any of the language\nmodels, and the change G2286A gives differing results across the three\nlanguage models (Fig.6d). As with H68, we tested theseﬁve mutations\nas a group (H81/H82\nmut), given their close proximity in the structure.\nConsistent with our hypothesis that canonical base pair changes are\nunlikely to be limiting for thermostability in theE. colicontext, the H81/\nH82 mutations result in ribosomes with equivalent activity and ther-\nmostability as WT ribosomes (Fig.6i). Thus, taking the H68 and H81/\nH82 mutation groups together with the mutations in H89 and H92, the\nGNN and LM models are able to inform 23S rRNA mutations that sta-\nbilize theE. coli50S subunit in four of six cases tested here, and one\ntested previously\n47.\nDiscussion\nHere we show that two distinct deep learning frameworks, a GNN and a\ngenerative RNA LM, could be used to identify functional RNA mutations\nin the ribosome. RNA structure prediction and design using deep\nlearning has lagged behind efforts for proteins, in large part due to the\nlimited abundance and quality of available RNA sequence and struc-\ntural information\n13.W h i l ei tm i g h tb ep o s s i b l ei nt h ef u t u r et or eﬁne the\nRNAcentral database, this will require careful handling of RNA\nsequence duplication, as well as rigorous division of sequences into\ntraining and validation sets. To address the database problem, we\ncreated GARNET, an entirely new RNA database built from the GTDB\n36.\nThe GTDB incorporates not only bacteria and archaea that can be\ngrown in the lab, but also genomes for uncultured microbes, expanding\nthe scope of RNA sequence alignments that can be obtained for bac-\nteria and archaea. The GTDB framework also enables linking pheno-\ntypes to genomes, as well as multiple sequences from the same genome\nacross alignments, which can aid studies of protein and RNA com-\nplexes. We used a machine learning approach\n40 to assign an optimal\ngrowth temperature to each reference genome in the GTDB, building\non experimental measurements\n38,39.W et h e nt e s t e dw h e t h e rt h e s e\ntemperatures, assigned to the RNAs identiﬁed in the GTDB genomes,\ncould be used to identify thermophilic mutations that stabilize theE.\ncoli ribosome. Using two different deep learning architectures– ag r a p h\nneural network (GNN) and an RNA language model (LM)– we were able\nto identify mutations inE. coli23S rRNA that stabilize the 50S subunit to\nheat treatment (Fig.6). Importantly, instead of relying on generated\nsequences individually, we generated sets of 1000 sequences to ana-\nlyze, in order to avoid possible issues with model-generated artifacts\n(i.e. “hallucination”). We used two different kinds of sequence inter-\nrogation to identify stabilizing mutations, namely Jensen-Shannon\ndivergence (JSD) and model probability calculations (Fig.6). Sorting\npositions by JSD identiﬁes individual positions that differ the most\nbetween the pretrained andﬁnetuned generated sequences. Calculat-\ning the model probabilities allowed us to evaluate whether these\nmutations are still supported when grafted individually into theE. coli\n23S rRNA sequence. We focused on identifying individual mutations, or\nat most several substitutions. Futu r ew o r kt om i n et h ec o m b i n a t o r i a l\neffects of multiple mutations, as well as higher-throughput assays, may\nhelp maximize the ability to query the GNN and RNA LMs for stabilizing\nRNA mutations. Overall, the methods used here to identify functional\nRNA mutations, by comparing modelspretrained on the entire GARNET\nRNA dataset to models ﬁnetuned on GARNET hyperthermophilic\nsequences, could likely be adapted for protein engineering.\nThermostabilizing mutations identiﬁed using GNNs and RNA LMs\nare distinct from those that could be gleaned through direct analysis of\nnatural 23S rRNA sequences in GARNET, consistent with these deep\nlearning models extracting new information from the sequence data.\nThis may be in part due to sequence co-dependence. For example, a\nnucleotide change at U2477C is strongly predicted to confer higher\nthermostability in theE. colicontext using the JSD calculation and model\nprobabilities, and mutations U2473C-U2474C have a higher probability\nof conferring thermostability relative to the WTE. colisequence. How-\never, only U2477C is capable of stabilizing theE. coli50S subunit in the\nin vitro translation assay used here (Fig.6f), suggesting positions 2473\nand 2474 may have other dependencies. In theE. coli ribosome, the\nU2477 base stacks with A2476 and interacts with an arginine side chain\nof ribosomal protein bL36 (Supplementary Fig. 13a). Cytosine has a lar-\nger dipole moment than uridine\n52, which could increase the strength of\nthe rRNA-ribosomal protein interaction and thereby stabilize theE. coli\n50S ribosomal subunit. The predicted H89 mutation maintains and\npotentially strengthens this rRNA-ribosomal protein interaction despite\nthe RNA LMs having no knowledge of ribosomal proteins. By contrast\nU2473C-U2474C mutations showed no improvement in ribosome sta-\nbility, although U2473 contacts an arginine side chain in ribosome\nassembly factor ObgE during 50S subunit maturation\n49. Notably, ribo-\nsome assembly factors are missing from the in vitro assay we used here,\nsuggesting the U2473C mutation might still be beneﬁcial in the assembly\nof destabilized engineered ribosomes in vivo.\nWhile a GNN utilizes both sequenceand structural information for\ntraining, GPT-like LMs use only sequences for training. Interestingly, the\nuse of a structural component in the GNN model allowed these models\nt op e r f o r ma sw e l la st h eG P T - l i k eL Mwith an order of magnitude fewer\nparameters (Fig.5, Supplementary Data 3). Notably, we identiﬁed a\nunique feature of RNA that favors representation of overlapping\nnucleotide triplets as tokens for training GPT-like LMs. These tokens\noutperform other embedding schemes by substantial margins in our\ntests. It is possible that this representation captures a fundamental\nproperty of RNA, in which nucleotide base stacking is the dominant\ndriving force for RNA structural stability\n53. This contrasts with proteins,\nin which higher-order structure depends more on backbone features, i.e.\nbackbone hydrogen bonding in secondary structure elements. Tokeni-\nzation of nucleotides as overlappingtriplets effectively represents each\nof the 4 nucleotides 16 different ways, with additional representations\nfor beginning and ending tokens. The fact that overlapping triplet\nencoding substantially decreases the perplexity of the resulting LMs\nsuggests that these different representations of the 4 nucleotides cap-\nture distinct features that are hard to train in a simpler token scheme. In\nprinciple the embedding dimension for nucleotides encoded individu-\nally could be increased and might possibly capture this information. For\nexample with proteins, single-amino acid encoding results in“clustering”\nof amino acids by physicochemical properties\n54. However, for nucleo-\nt i d e st h i si sl i k e l yi n f e a s i b l ed u et ot h ef a c tt h a tm o d e lp a r a m e t e r sa n d\nmemory use scale as the square of the embedding dimension for a\ntransformer-based model\n55. Projecting the total embedding dimensions\nof overlapping triplets to single nucleotides would likely require a model\nwith over 100-fold more parameters and memory than used here. While\nwe were unable toﬁnd sets of parameters and hyperparameters that\nallowed training of the RNA LMs using single-nucleotide tokens, this\ncould be further explored in the future. Nevertheless triplet-encoding\nwith a 1-nucleotide shift should serve as a useful approach for the rela-\ntively small models we developed here.\nProtein language models can serve as a foundation for structure\nprediction. For example, the ability of ESM-2 to predict correct amino\nacids in a sequence, as measured by a decrease in the model perplexity,\ncorrelates strongly with the ability of the model to serve as a basis for\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 10\nprotein tertiary structure prediction2.F o rR N A ,i nw h i c ha l t e r n a t i v e\nsecondary and tertiary structures may play important functional bio-\nlogical roles\n56,57, starting from an RNA language model may prove\ncrucial for success in future structural prediction efforts. RNA LMs\ncould also beneﬁt from coupling to additional data. For example,\ncombining the RNA LM with a protein LM could help reﬁne searches\nfor mutations in proteins that confer thermostability to the ribosome,\ni.e. in ribosomal proteins or maturation factors. Language models for\nRNA could also beneﬁt from information on nucleotide modiﬁcations.\nThese modiﬁcations can have profound effects on nucleotide con-\ntributions to RNA secondary and tertiary structure, and hence RNA\nfunction. However, information on nucleotide modiﬁcations is scarce\napart from a very small select number of organisms. Future efforts to\nexpand post-transcriptional modi ﬁcation databases could help\nimprove deep-learning approaches for RNA. RNA language models\ncould also be combined with experimental data, for example chemical\nprobing data as a means of introducing additional structural infor-\nmation into the model. Finally, there is also room to expand RNA\nsequences in the GARNET database, which could improve the RNA LMs\ncreated here. For example, the larger diversity present in the SILVA 16S\nrRNA database, which includes ribosomal RNA sequences from species\nwithout a sequenced genome, suggests the GTDB could grow in spe-\ncies clusters by many times in the coming years. The GTDB also pre-\nsently lacks eukaryotic, mitochondrial, and chloroplast genomes, as\nwell as those of viruses. However, even with the above limitations, we\nshow that deep learning models including LMs with optimized triplet\nencoding can be built and trained using RNA sequences extracted from\nthe GTDB, and applied to RNA functional engineering.\nMethods\nRNA sequence searches and multiple sequence alignment\nconstruction\nSequences for the three ribosomal RNAs were identiﬁed by searching\nthe corresponding Rfam 14.9 covariance models (23S rRNA: archaea\nRF02540, bacteria RF02541; 16S rRNA: archaea RF01959, bacteria\nRF00177; 5S rRNA: RF00001) against genomes in the Genome Tax-\nonomy Database (GTDB) v214.1. The representative genomes of each\nGTDB species cluster was searched using Infernal 1.1.4 with an e-value\ncutoff of 1e-5 and omitting hits shorter than 85% of the model length,\nkeeping the most signiﬁcant hit per genome. If no such hit could be\nfound, then any available non-representative genomes for that species\ncluster was searched, in order of increasing CheckM contamination,\nwhich is provided in the GTDB metadata.\nFor each ribosomal RNA family, multiple sequence alignments\nwere created by aligning the Infernal hits to a single Rfam covariance\nmodel (23S rRNA: RF02541; 16S rRNA: RF00177; 5S rRNA: RF00001).\nThe alignments were further ﬁltered for quality by 1) removing\nsequences with >5% ambiguity characters, 2) removing sequences that\naligned to <85% of the Rfam consensus positions, 3) removing\nsequences with a length greater than two standard deviations above\nthe mean (greater than one standard deviation for 16S and 23S rRNA),\nand 4) removing sequences with a fraction of non-canonical base pairs\n(not Watson-Crick-Franklin or G-U pairs) in the Rfam consensus sec-\nondary structure greater than two standard deviations above the mean\nto remove potential pseudogenes. For the GNN approach, the 23S\nrRNA alignment was further processed to remove positions that\naligned to insertions relative to the Rfam RF02541 model and positions\nthat are not present in theE. coli23S rRNA sequence from PDB 7K00.\nFor the expanded 228-RNA dataset, we selected 256 Rfam families\nthat are present in bacteria and archaea, contain 10 or more sequences\nin the Rfam seed, and have 100 or more consensus positions. The\nmodels were then searched against each GTDB species representative\ngenome using Infernal 1.1.4\n20 with an e-value cutoff of 1e-5, allowing\nmultiple hits per genome. Across all models, hits with any overlapping\nnucleotides were resolved by keeping the hit with the lower e-value.\nThe resulting sequences were then aligned to their respective Rfam\ncovariance model. These alignments wereﬁltered for quality in the\nsame way as described above for rRNA sequences, except sequences\nthat aligned to <90% of Rfam consensus positions were removed. Rfam\nfamilies with fewer than 10 sequences afterﬁltering were excluded\nfrom further analysis, resulting in 228 RNA families in theﬁnal dataset.\nTo compare alignment diversity relative to existing RNA align-\nments, each alignment wasﬁltered at a range of fractional identity\ncutoffs using a greedy algorithm implemented by two methods:\nVSEARCH v2.15.2\n58 with options --cluster_fast --iddef 0 --id <cutoff> and\nesl-weight (HMMER version 3.4)59 with options --rna -f --idf <cutoff > .\nVSEARCH takes unaligned sequences as input, while esl-weight\nrequires input sequences to be aligned. For 23S rRNA, the compar-\nison database was SILVA 138.1 LSURef NR99, and for 16S rRNA, SILVA\n138.1 SSURef NR99\n18. The full-length SILVA sequences were aligned\nusing SINA 1.7.260 to the corresponding ARBﬁle for esl-weight com-\nparisons. For 5S rRNA, two comparison databases were used:\n5SRNAdb\n37 and Rfam 14.917 full alignment for RF00001. 5SRNAdb\nprovides aligned sequences and Rfam sequences were aligned using\nInfernal to the Rfam covariance model RF00001. For the TPP ribos-\nwitch, cobalamin riboswitch, and T-box leader RNA, the comparison\ndatabases were Rfam 14.9 full alignment for RF00059, RF00174, and\nRF00230, respectively, aligned using Infernal to the corresponding\ncovariance model.\nGeneration of RNA training and test sets for training deep\nlearning models\nWe applied hierarchical clustering with CD-HIT-EST61 to generate\ntraining and test sets from 231 Rfam RNA families extracted from the\nGTDB genomes. To increase cluster diversity, CD-HIT was customized\nby reducing cluster_thd to 60% in the cdhit-common.c + + script (line\n358) and recompiling the software. Sequences for each Rfam family\nwere independently clustered at decreasing percent identities as fol-\nlows: 90% with n-mer = 8, 80% with n-mer = 5, 70% with n-mer=4, and\n60% with n-mer=4. While the rRNA families were diverse at the 60%\nidentity level, the remaining Rfam families were generally less so due to\nthe stringentﬁlters used in the Infernal search (described above). We\ntherefore used the following strategy for dividing these Rfam\nsequences into an overall training and test set. First, for the 124/231\nremaining Rfam families that had sufﬁcient sequence diversity at the\n60% level, clusters were randomly sorted into the training and test sets\nuntil up to 33% of sequences from a family were in the test set. Then,\nintact Rfam families with single clusters were randomly selected for the\ntest set until the test set contained 10% of the total tokens. Rfam\nfamilies with intermediate diversity, i.e. that had dominant clusters\nwithin them, were kept intact in the training set. For models requiring\nMSA format, sequences were then formatted using esl-reformat\n(HMMER version 3.4)\n59. The same method was used to split the 5S,\n16S and 23S datasets, except 5% of sequences were reserved for testing.\nGrowth temperature curation and prediction\nOptimal growth temperatures (OGTs) were predicted by TOME40\nfrom proteome sequences from each representative genome in the\nGenome Taxonomy Database (release 214.1), yielding a dataset of\n85,205 OGTs. This compares to a total of 13,011 out of the 85,205\nGTDB species with an OGT listed in TEMPURA and/or GOSHA data-\nbases. To determine the accuracy of the TOME predictions, the R\n2\nvalue was calculated against the optimal growth temperatures from\nthe TEMPURA (Release 200617)\n38 and Gosha databases (accessed on\n23 October 2023)39, for all species absent from TOME’s training set\n(Fig. 2a. n = 7404 and 3346 species for Gosha and TEMPURA,\nrespectively). OGTs from TOME were further validated by inspecting\nthe NCBI Isolation Source of species in the GTDB metadata. Isolation\nsources indicating direct acquisition from environments warmer than\n60 °C were categorized as“hyperthermophilic,” while the remaining\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 11\nisolates were classiﬁed as “not hyperthermophilic” (Supplementary\nData 2). Manual labels were compared to classiﬁcations based on\nTOME, where species with a predicted OGT≥ 60 °C were categorized\nas hyperthermophiles (Fig.2c).\nStructural analysis of 23S rRNA for graph representations\nThe Graph Neural Network (GNN) model takes as input information on\nthe nucleotides’ structurally proximal neighbors, represented by a\ngraph. Further, the GNN model is trained on the Infernal MSA of 23S\nrRNA sequences from GARNET, truncated to align with theE.coli 23S\nrRNA sequence in PDB entry 7K00 and tailored to the Rfam RF02541\nmodel, as detailed in the‘RNA sequence searches and multiple\nsequence alignment construction’section. This alignment is further\nreferred to as the‘GNN MSA’. To train the GNN, we generated a graph\nfrom a structural distance matrix based on theE.coli 23S rRNA struc-\nture from PDB entry 7K00, adjusting the nucleotide coordinates in the\ndistance matrix to align with those in the GNN MSA. This was accom-\nplished through a procedure outlined below.\nTo generate the aligned distance matrices, we chose 18 repre-\nsentative archaeal and bacterial ribosome structures from the PDB\n( 3 C C 2 ,4 W 2 E ,5 D M 6 ,5 N G M ,8 H K U ,6 S K F ,6 S P B ,6 V 3 9 ,7 J I 1 ,7 N H K ,\n7OOD, 7S0S, 7S9U, 7SFR, 8A57, 8FMW, 7K00, and 4YBB), extracting\nthe 23S rRNA chains. Using a custom script, we converted nucleotides\nwith post-translational modiﬁcations in these structures to sequences\nwith canonical A, C, G, and U, further referred to as the‘PDB-derived\nsequences’. We then produced distance matrices by calculating the\nminimum all-to-all atom distances between nucleotide pairs in the PDB\nﬁles. To align these distance matrices with the GNN sequence align-\nments, a multi-step matrix adjustment procedure was implemented\n(see Supplementary Fig. 2). First, to account for the absence of\nunstructured regions in the PDB-derived sequences, these were\naligned with the corresponding rRNA FASTA sequences from the PDB-\nderived sequences using MAFFT\n62. Empty rows and columns were\ninserted into the distance matrices corresponding to the locations of\nthe alignment gaps, signifying the regions of unstructured nucleotides.\nSubsequently, in the second step, the FASTA sequences of the 18\nrRNAs were aligned with the GTDB-derived 23S rRNA sequences using\nInfernal as outlined above in section‘RNA sequence searches and\nmultiple sequence alignment construction’, ensuring all rRNA\nsequences were mapped onto a consistent coordinate framework with\nthe necessary gaps and insertions. Empty columns and rows were again\npositioned at the coordinates of the gaps and insertions in the distance\nmatrices. Finally, in the third step, rows and columns in the distance\nmatrices that correspond to the gaps and insertions speciﬁct ot h e\nE.coli 7K00 sequence in the Infernal MSA, were removed, replicating\nhow the GNN MSA was created. The resulting aligned distance matri-\nces’nucleotide coordinates matched their counterpart coordinates in\nthe GNN MSA.\nThe aligned distance matrices, showing internucleotide distances\nin Å, were transformed into binary contact maps, where‘1’ denotes\ncontact and‘0’indicates no contact, with two different methods. In the\nﬁrst intuitive method, contact‘1’was assigned to pairs of nucleotides\nhaving a distance below a certain distance cutoff. Analysis of the\ncontact map alignment involved summing the 18 maps (see top-right\nhalves of the plots in Supplementary Fig. 3a-d and Fig.3e). The align-\nment’s accuracy was conﬁrmed by the precise matching of secondary\nstructures across the maps. To quantitatively assess rRNA structural\nhomology, we introduced a structural correlation metric\nCorr A\nij, Bij\n/C16/C17\n=\nP\ni, j AijBijﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃP\ni, jA2\nij\nP\ni, j B2\nij\nq\nwhere Aij = Aij dðÞ and Bij = Bij dðÞ are the two contact maps compared at\na distance cutoffd, withi, j being the nucleotides coordinates. Pairwise\ncorrelation of the contact maps generated atd = 12Å was on average\n0.94 and 0.95 for bacterial species and for archaeal species, respec-\ntively, and 0.88-0.90 when comparing bacterial to archaeal 23S rRNA,\nwhich indicated that most of the structural features were identical\nbetween all ribosomal subunits, and prompted us to combine the\nsequences for training the GNN (see Supplementary Fig. 3e). We fur-\nther analyzed the average correlation between the contact maps as a\nfunction of distance cutoffd (see Supplementary Fig. 3f), and saw that\nthe structural correlation did not signi ﬁcantly improve for d\nabove 12 Å.\nIn the second method, similar to the one applied in the original\nStructured Transformer model introduced by Ingraham et al\n41., we\nsorted pairs of nucleotides according to their distances, and selected\nthe k-nearest neighbors for each. To justify the use of the second\nmethod, we analyzed the distributions of internucleotide distances\nreturned for different amounts of nearest neighborsk (see Fig.3d).\nWe observed that by choosing a certaink, all internucleotide dis-\ntances below a certain cutoff are included (e.g. ~12 Å fork =5 0 ) .W e\nfurther saw high similarity of thek-nearest neighbors contact maps\nwith the contact maps generated for the corresponding cutoff dis-\ntances captured by a givenk nearest neighbor value (see Fig.3ea n d\nSupplementary Fig. 3a– d). We concluded that the two methods for\ngenerating contact maps could be used interchangeably, and we\nchose to proceed with thek-nearest neighbors method for generating\nthe graph and training the GNN model.\nGNN model\nAs described above, the Graph Neural Network (GNN) RNA model\ntakes as input a contact map describing the 3D fold of the RNA family\nthat is being modeled to construct aﬁxed graph. Each node in the\ngraph corresponds to a conserved position of the RNA family MSA.\nEach node is connected to thek-nearest neighbors. The graph contains\nnode and edge features. Node features consist of a learned absolute\npositional encoding with 16 hidden features as well as information\nabout the sequence. As in Ingraham et al\n41., this sequence information\nis causally masked during the decoding process. The edge features\nconsist of the sinusoidal relative positional encodings and the pairwise\ndistance between nodes in the graph use 16 radial basis functions\nspaced between 0 and 20 Ångstroms, as previously described\n41.A l l\nnode and edge features were mapped to a hidden dimension of 128\nwith a learned linear layer. The model leverages the transformer\nencoder-decoder architecture of Ingraham et al\n41. A single encoder\nlayer and three decoder layers were used. All sequences were toke-\nnized using one token per nucleotide with an alphabet consisting of\nthe four nucleotides (A, U, C, and G) as well as a gap character (-) and an\n“unknown” character (X). The “unknown” character is found in\nsequences where, due to sequencing issues, the identity of the\nnucleotide was not determined.\nFor training, we performed a sweep on the 23S pretraining set,\nvarying bothk-NN (k-nearest neighbors on which to perform message-\npassing), and layer dimension. We trained across values ofk = {5, 10,\n20, 50, 100} and layer dimension = {64, 128} with learning rate 1e-3, to\nproﬁle the contribution of added structural context and/or dimension\non autoregressive perplexity. We trained all models using a dropout\nrate of 10% and a label smoothing rate of 10%. For training, we initially\nrandomly partitioned 20% of the training set into a validation set, to\nallow early stopping based on validation perplexity for the hyper-\nparameter sweep. We found that structural context begins to saturate\nafter k = 50 nearest neighbors. Using the best set of hyperparameters\non the holdout, divergent test set (k = 50, layer dimension = 128), we\nthen partitioned the 10% of the training set for validation for early-\nstopping on theﬁnal pretrained model. We pause training after vali-\ndation perplexity stopped improving for 5 epochs, training the model\nfor 32 epochs. Forﬁnetuning on hyperthermophilic sequences, we\nlowered the learning rate to 1e-4, andﬁnetuned the pretrained model\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 12\n(k = 50, layer dimension = 128). We similarly held out 10% of the\nhyperthermophiles training set as a validation set to allow early stop-\nping based on validation perplexity. Finally, we measured the perfor-\nmance of the model by calculating test perplexity after training for 50\nepochs. Extended details for each model are available in Supplemen-\ntary Data 3.\nRNA language model pretraining andﬁnetuning on hyperther-\nmophilic sequences\nTo construct a Generative Pretrained Transformer (GPT) RNA lan-\nguage model, RNA sequences were converted to n-gram tokens of 1, 2,\nor 3 nucleotides, with a step size of one between tokens (Fig.4a). A\nsmall GPT model, nanoGPT\n43, was then adapted to train an RNA lan-\nguage model for comparisons of these token schemes, using 23S rRNA\nsequences from GARNET. Batch sequences were adjusted to be aligned\na ti n d e x=0 ,a n du s e dp a d d i n gi ft h es e q u e n c ei n c l u d e dt h eR N A3’-\nend. Padding tokens were excluded from loss calculations. We were\nunable to ﬁnd suitable hyperparameters for training models with\nsingle-nucleotide embeddings. For hyperparameter optimization, we\ndivided the 23S rRNA training set described above into training and\nvalidation sets using CD-HIT-EST\n61 for hierarchical clustering (85 M/\n4 M tokens in the training/validation sets). Final models were trained\nusing the full training and tests sets for 23S rRNA described above,\nusing the test set as a validation set (89 M/5.5 M tokens in the training/\nvalidation sets). The architecture and hyperparameters for GPT mod-\nels in the comparisons shown in Fig.4b were the following: context\nw i n d o w=3 8 4t o k e n s ,a t t e n t i o nl a y e r s=1 8 ,a t t e n t i o nh e a d s=6 ,\ne m b e d d i n gd i m e n s i o n=3 0 0 ,l e a r n i n gr a t e=5 e - 5d e c a y e do v e r\n100,000 iterations to 5e-6, AdamW optimizer beta2 = 0.998, batch size\n= 18, use of Flash attention\n63, and with the nanoGPT model modiﬁed to\nuse rotary positional embeddings (RoPE) for relative positional\ninformation\n44. We also replaced layer normalization in the transformer\nlayer blocks with root-mean-square normalization64.W ea l s ot e s t e dt h e\nuse of non-overlapping dinucleotide and non-overlapping triplet-\nnucleotide encodings. Non-overlapping dinucleotide encodings could\nbe optimized to some degree, possibly beneﬁtting from multiple\nrepresentations of each nucleotide in the token set. However, non-\noverlapping dinucleotides require additional tokens to account for\nRNAs with an odd number of nucleotides and are not as intuitive to\ninterconvert between tokens and nucleotides. We therefore did not\npursue non-overlapping embeddings further.\nWe trained theﬁnal RNA language models using the overlapping\ntriplet-nucleotide scheme (n-gram of 3 with step size 1), and with RoPE\napplied to each attention layer. Theﬁnal model for the 231 RNA set\nsimilarly used the train/test sets described above, with the test set used\nfor validation (274 M/31 M tokens in the training/validation sets). We\nused early stopping based on the validation loss score to output the\nﬁnal model checkpoint ﬁles. The hyperparameters and perplexity\nvalues of the pretrained models are given in Supplementary Data 3. 16S\nand 23S rRNA sequences were generated from the pretrained 231-RNA\nLM using 100 nucleotides ofE. coli16S or 23S rRNA, respectively, at a\ngeneration temperature of 0.2. These sets of 100 sequences were\naligned using the MAFFT aligner in Wasabi\n65,w i t ht h eE. colisequence\nincluded for comparison purposes in Fig.4da n de .\nRNA language models trained on 23S rRNA sequences from\nGARNET wereﬁnetuned using hyperthermophilic 23S rRNA sequences\nfrom GARNET identiﬁed as described above. Hyperthermophilic\nsequences were divided into a training set and validation set splits\nbased on their partitioning in the data used for pretraining, i.e.\nhyperthermophilic sequences in the training set of the pretraining data\nwere used in the ﬁnetuning training set, and hyperthermophilic\nsequences in the validation set of the pretraining data were used in the\nﬁnetuning validation set. As with the pretrained models, early stopping\nbased on the validation loss score was used to output theﬁnal model\ncheckpoint ﬁles. We also ﬁnetuned the RNA language model\npretrained on the 231-RNA dataset using a similar workﬂow (Supple-\nmentary Data 3).\nAnalysis of 23S rRNA sequences to identify candidate thermo-\nphilic mutations\nFull-length 23S rRNA sequences were generated from the pretrained\nand ﬁnetuned GNN and LM models using a seed sequence beginning\nwith the 5’end ofE. coli23S rRNA composed of 100 nucleotides (GNN)\nor 384 nucleotides (LM). Sequences were generated in sets of 1000\nusing a range of“temperature” scaling factors of the model output\nlogits, then aligned to the consensus 23S sequence using the Rfam\ncovariance model RF02541 (LSU_rRNA_bacteria). The GNN-generated\nsequences lacked regions in the uL1 and bL12 binding regions, which\nwere missing in PDB entry 7K00. These regions were masked in sub-\nsequent analyses. Sequences generated from the LMs aligned to the\nRfam model for 23S rRNA across their entire length (Supplementary\nFig. 6a, c and Supplementary Fig. 7a, c). By contrast, the GNN models\ndeleted local RNA segments with higher frequency at the higher gen-\neration temperatures tested (Supplementary Fig. 5a, c). Although\nshorter as a function of increasingtemperature, the GNN sequences\nstill aligned well to the Rfam model (Supplementary Figs. 5– 7).\nTo choose an appropriate temperature for generating sequences,\nthey were analyzed for their 23S rRNA-like properties as follows. First,\ngenerated sequences were scored against the Rfam covariance model\nRF02541 using cmsearch in the Infernal suite of programs\n20.T h e\ncmsearch score is a combination of sequence and secondary structure\nconservation, giving a global view of the 23S-like properties of the\ngenerated RNAs. However, a 1-2% change in secondary structure may\nnot affect the score substantially if the rest of the ~3k long sequence is\nconserved. We therefore used a second metric, the fraction of con-\nsensus base pairs in the RF02541 model aligned to each sequence that\ndeviate from canonical G-C/C-G, A-U/U-A, or G-U/U-G pairs, compared\nto proportion of base pairs disrupted in natural 23S rRNA sequences\nfrom GARNET. Generated sequences were also visually checked for\nalignment properties using the SILVA Alignment, Classiﬁcation, and\nTree (AC) service\n60, together with the SILVA-associated Wasabi\nsequence viewer66.\nTo identify candidate mutations inE. coli 23S rRNA that might\nconfer thermostability, we analyzed generated sequences with a gen-\neration temperature of T = 0.5 for all GNN and RNA LMs, except for the\n231-RNA FT model, where we used a generation temperature of T = 0.3.\nWe ﬁrst aligned the generated sequences to the Rfam RF02541 cov-\nariance model using cmalign in the Infernal suite of programs, and\ntrimmed the alignment to positions corresponding to theE. coli23S\nrRNA sequence. We calculated the Jensen-Shannon divergence (JSD) at\neach nucleotide position in the 23S rRNA alignment, comparing\nnucleotide frequencies for sequences generated by the pretrained\nmodels and modelsﬁnetuned on hyperthermophilic sequences, after\nmasking positions used to seed sequence generation (n = 100 for GNN,\nn = 386 for LM to account for tokenization) and with nucleotide\noccupancy <50%.\nSince JSD-based sorting considers each position in the sequence\nindependently, we also used log probability values for candidate 23S\nsequences to assess mutations. Using the probability of a sequence\nbeing generated by an RNA language model allows us to assess whe-\nther candidate mutations work in theE. coli23S rRNA context or may\ndepend on other co-occurring mutations, i.e. compensatory mutations\nin base pairs. Notably, many of the highest-scoring JSD sites do in fact\ncorrespond to base paired positions in 23S rRNA, and the deep\nlearning models generated compensatory mutations at both nucleo-\ntide positions to maintain the base pair. However, given the large\nnumber of mutations in each GNN- and LM-generated sequence, on\nthe order of 200 or more per sequence, it is also possible that candi-\ndate mutations might not function in an otherwise WTE. coli 23S\nbackground.\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 13\nWe used four probability calculations in our log probability ana-\nlysis (Fig.6b). First, we calculated the log probability of theﬁnetuned\n(FT) model generating a mutatedE. coli 23S rRNA sequence, and\ncompared this to the log probability from the pretrained (PT) model.\nSecond, we calculated the log probability of the FT model generating\nthe wildtypeE. coli23S rRNA, and compared this to the log probability\nfrom the PT model. We evaluated the mutant log probability difference\nbetween FT and PT normalized to wildtype log probability difference\nas ΔΔlogP. Mutant sequences with a positiveΔΔlogP are supported by\nthe FT model better than the PT model relative to the wildtypeE. coli\n23S rRNA. As controls, we generated all possible single-nucleotide\nmutations in theE. coli23S rRNA sequence and calculated log prob-\nabilities for each of these being generated from the FT or PT models.\nWe found the average difference in log probabilities from the FT and\nPT models,ΔΔlogP, to be close to 0 (−0.82 for the 23S rRNA GNN, 0.07\nfor the 23S rRNA LM, and−0.52 for the 231-RNA LM). Comparing single\nmutations to this reference distribution allowed us to assess the per-\ncentile of individual candidate thermostabilizing mutations. Multiple-\nmutation cases should be compared to an analogous reference dis-\ntribution considering all the mutations in a sequence in the probability\ncalculations, which could be used to investigate nucleotide depen-\ndencies learned by the models. We chose not to comprehensively\nassay these due to the computational complexity.\nCloning and ribosome puriﬁcation\nFor ribosome expression, a modiﬁed version of the pLK35 plasmid67,\nwhich contains an IPTG inducible tac promoter followed by the 5S, 16S,\nand 23S rRNA with the MS2-tag from Nissley et al50.i n s e r t e di nh e l i xH 9 8 ,\nwas used. 23S rRNA mutations were introduced to the pLK35 plasmid\nusing the corresponding primer set (Supplementary Data 6) and the In-\nFusion Cloning kit (Takara Bio). All sequences were conﬁrmed with full\nplasmid nanopore sequencing (Plasmidsaurus and Elim Bio).\nMS2-tagged ribosomes were expressed and puriﬁed as previously\ndescribed\n47 with adaptations. pLK35 plasmids were transformed into\nNEB Express Iq cells (NEB) which are a bL21 derivative that con-\nstitutively expresses the lac repressor. Transformants were grown\novernight in LB media and the following day were diluted 1:100 in 1 L of\nLB media with 100µg/mL ampicillin. The cultures were grown at 37 °C\nwith shaking and once the cultures reached an OD\n600 of 0.6, expres-\nsion of the rRNA was induced with 0.5 mM Isopropyl ß-D-1-\nthiogalactopyranoside. Induced cultures were grown for three hours\nat 37 °C and then cells were pelleted and resuspended in 30 mL of\nbuffer A (20 mM Tris– HCl pH 7.5, 100 mM NH\n4Cl, 10 mM MgCl2)w i t ha\nPierce protease inhibitor tablet (Thermo Fisher). The cell suspension\nwas lysed by sonication and the lysate was clariﬁed by centrifugation at\n14,000 rpm (34,000xg ) for 45 min in a F14-14 × 50cy rotor (Ther-\nmoFisher). The clariﬁed lysate was then loaded onto a sucrose cushion\nwith 24 mL of buffer B (20 mM Tris– HCl pH 7.5, 500 mM NH\n4Cl, 10 mM\nMgCl2) with 0.5 M sucrose and 17 mL of buffer C (20 mM Tris– HCl pH\n7.5, 60 mM NH4Cl, 6 mM MgCl2) with 0.7 M sucrose in Ti-45 tubes\n(Beckman-Coulter). Ribosomes were pelleted by centrifugation at\n27,000 rpm (57,000xg)f o r1 6ha t4° Ca n dt h e nr e s u s p e n d e di nd i s -\nsociation buffer (20 mM Tris– HCl pH 7.5, 60 mM NH\n4Cl, 1 mM MgCl2).\nMBP-MS2 fusion protein was puriﬁed as previously described32.\n10 mg of MBP-MS2 protein was loaded onto a MBP Trap column\n(Cytiva) that was equilibrated with MS2-150 buffer (20 mM HEPES pH\n7.5, 150 mM KCl, 1 mM EDTA, 2 mM 2-mercaptoethanol). The column\nwas washed with 5 column volumes (CV) of buffer A-1 (20 mM Tris– HCl\npH 7.5, 100 mM NH\n4Cl, 1 mM MgCl2) and the resuspended ribosome\npellet (~100 mg) was then loaded onto the column. The column was\nwashed with 5 CV buffer A-1 followed by 10 CV of buffer A-250 (20 mM\nTris– HCl pH 7.5, 250 mM NH4Cl, 1 mM MgCl2) and ribosomes were\neluted with 10 mL of elution buffer (20 mM Tris– HCl pH 7.5, 100 mM\nNH4Cl, 1 mM MgCl2, 10 mM maltose). The 50S subunit sample was then\nconcentrated using a 100 kDa cut-off spinﬁlter (Millipore) and washed\nwith buffer A-1. 50S ribosomal subunits were quantiﬁed using the\napproximation of 1 A260 =3 6n M ,ﬂash frozen, and stored at−80°C. WT\nuntagged 30S subunits were puriﬁed from E. coli MRE600 as pre-\nviously described47.\nEndogenous E. coli 50S subunit contamination was quantiﬁed\nusing semi-quantitative RT-PCR. The rRNA from 50 pmol of MS2-\npuriﬁe d5 0 Ss u b u n i t sw a sd e n a t u r e da t9 5° Ca n dp r e c i p i t a t e dw i t h4M\nLiCl. 75 ng of rRNA was reverse transcribed and ampliﬁed with 8 PCR\ncycles using the OneStep RT-PCR kit (Qiagen) and primers\nMS2_quant_F and MS2_quant_R (Supplementary Data 6). DNA products\nwere resolved on a 10% TBE gel, visualized with SYBR gold\nstain (Thermo Fisher), and quantiﬁed using Image J software\n68.\nUncropped gel images for Supplementary Fig. 13 are provided in the\nSource Data.\nHiBit in vitro translation reactions\nThe 11S nanoluciferase fragment that is complemented by the HiBit\npeptide to enable luminescence\n69 was puri ﬁed as previously\ndescribed47. In vitro HiBit translation assays were performed as pre-\nviously described47 with adaptations. 50S ribosomal subunits were\ndiluted to 1.4μM in buffer A described above with aﬁnal concentration\nof 10 mM MgCl2. The subunits were then incubated at 37 °C or 65 °C as\nindicated for 15 minutes, and then cooled at room temperature for\n15 minutes. After cooling, an in vitro translation mixture was assem-\nbled using theΔRibosome PURExpress kit (NEB): 3.2μLs o l u t i o nA\n(NEB), 1μL factor mix (NEB), 250 nM pre-incubated 50S ribosomal\nsubunits, 500 nM WT untagged 30S ribosomal subunits, 1 U/μLM u r i n e\nRNAse inhibitor (NEB), 400 nM 11S NanoLuc protein, 1:50 (v/v) dilution\nof Nano-Glo substrate (Promega), and 1 ng/μL of DNA template\nencoding the HiBit peptide\n69 (ﬁnal volume of 8μL). 2μLo ft h ei nv i t r o\ntranslation mixture was placed in a 384 well plate per well, and lumi-\nnescence was measured for one hour in a Spark Plate Reader (Tecan)\nset to 37 °C. Ribosome activity was calculated by determining the slope\nof the initial linear region of each in vitro translation reaction. The\nreported ribosome activities are the average from three HiBit in vitro\ntranslation reactions.\nBenchmarking of GenerRNA\nThe GenerRNA model was downloaded from the following GitHub\nrepository: https://github.com/pfnet-research/GenerRNA.gitand built\nfollowing the instructions provided in the READMEﬁle. The GenerRNA\npretrained model, trained to 330,000 iterations on the deduplicated\nRNAcentral dataset, as provided on Hugging Face, was additionallyﬁne-\ntuned on two datasets, GARNET-all and GARNET-hyperthermophiles.\nTo do so, each dataset wasﬁrst reformatted from the default FASTA\nformat to have each sequence on a single line lacking headers, as\nrequired by GenerRNA, using a custom Python script. Following this,\neach dataset was partitioned into training and validation sets and\ntokenized using the included tokenizer_bpe_1024 scheme and the\ndefault vocabulary to ensure consistency with the original GenerRNA\ntraining workﬂow. Two versions of GenerRNA were thenﬁne-tuned on\nthese datasets using the includedﬁnetuning example conﬁg ﬁle and\nﬁnetune.py script for 50,000 iterations on four A4500 GPUs to ensure\nthe validation loss plateaued.\nWe then sampled 1000 sequences from each GenerRNA model\nusing the provided sampling.py code. We tested a number of para-\nmeters including temperature, seed, token generation strategy, and\nmax tokens to generate the most 23S-like set of 1000 sequences\npossible from the default GenerRNA model, the GenerRNA modelﬁne-\ntuned on GARNET-all, and the GenerRNA model ﬁne-tuned on\nGARNET-hyperthermophiles. Broadly, these parameters ended up\nbeing a 100-nucleotide seed from the 5’ end of theE. coli23S rRNA,\n--max_new_tokens 520, --temperature 0.5 or 1.0 for the pretrained and\nﬁne-tuned models respectively, and --strategy top_k. We chose 520\ntokens, because for the 1024-token vocabulary, sequences are\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 14\ncompressed about 5x once tokenized (Figure S1 in the GenerRNA\nmanuscript45). Increasing the number of tokes did not result in longer\ngenerated sequences.\nIn addition to these parameters, we were forced to edit the code\nof the model.py and sampling.py scripts to suppress the <|endoftext | >\ntoken, as without this, sequences would almost always terminate\nwithin 100-150 nucleotides of starting. This was accomplished by set-\nting the <|endoftext | > logit value to negative inﬁnity, as well as adding\na ﬂag that allowed us to deﬁne a forbidden token, <|endoftext | >.\nHowever, this did not totally alleviate the early sequence termination\nissues but did allow us to generate longer, though still prematurely\nterminated, 23S-like sequences. Following generation, we assessed the\nsequences using two metrics, cmsearch score and the fraction of non-\nWatson-Crick base pairs, as described for the RNA LM models. With\nboth metrics, the sequences generated using the default GenerRNA\nmodel yielded poor cmsearch score values, more dissimilar to natu-\nrally occurring 23S rRNA sequences than those generated by the\nGARNET RNA LM models. The fraction of non-WatsonCrick base pairs\non the surface look 23S-like for the default model. However, this metric\ndoes not account for truncation of the sequences at the 3’ end. The\nsequences generated by the GARNETﬁne-tuned GenerRNA models\ncatastrophically failed, generating only fragmentary sequences with\nlow cmsearch scores and exceptionally high non-Watson-Crick base\npair fractions.\nReporting summary\nFurther information on research design is available in the Nature\nPortfolio Reporting Summary linked to this article.\nData availability\nAssociated data, models, and the GARNET Database70 are provided\nhere: https://doi.org/10.5281/zenodo.14003346.P D Bc o o r d i n a t e sa r e\navailable at:7K00. 4YBB. 6SPB. 8A57. 7S0S. 7NHK. 7SFR. 8FMW. 5DM6.\n7OOD. 6V39. 7JIL. 5NGM. 4W2E. 7S9U. 6SKF. 3CCZ. 8HKU. Source data\nare provided as a Source Dataﬁle. Source data are provided with\nthis paper.\nCode availability\nCode described in this work is publicly available on Github (https://\ngithub.com/Doudna-lab/GARNET_DL70) and at the followinghttps://\ndoi.org/10.5281/zenodo.13999143.\nReferences\n1. Jumper, J. et al. Highly accurate protein structure prediction with\nAlphaFold.Nature 596,5 8 3– 589 (2021).\n2. Lin, Z. et al. Evolutionary-scale prediction of atomic-level protein\nstructure with a language model.Science 379, 1123– 1130 (2023).\n3. Zhang, Y. et al. Multiple sequence alignment-based RNA language\nmodel and its application to structural inference.Nucleic Acids Res.\n52, e3 (2024).\n4. Fu, L. et al. UFold: fast and accurate RNA secondary structure pre-\ndiction with deep learning.Nucleic Acids Res.50, e14 (2022).\n5. Sumi, S., Hamada, M. & Saito, H. Deep generative design of RNA\nfamily sequences.Nat. Methods21,4 3 5– 443 (2024).\n6. Singh, J. et al. Improved RNA secondary structure and tertiary base-\npairing prediction using evolutionary proﬁle, mutational coupling\nand two-dimensional transfer learning.Bioinformatics37,\n2589– 2600 (2021).\n7. Zhang, H. et al. Algorithm for optimized mRNA design improves\nstability and immunogenicity.Nature 621,3 9 6– 403 (2023).\n8. Chen, J. et al. Interpretable RNA foundation model from unan-\nnotated data for highly accurate RNA structure and function pre-\ndictions.arXiv [q-bio.QM](2022).\n9. Nguyen, E. et al. Sequence modeling and design from molecular to\ngenome scale with Evo.Science 386, eado9336 (2024).\n10. He, S. et al. Ribonanza: deep learning of RNA structure through dual\ncrowdsourcing. Preprint atbioRxivhttps://doi.org/10.1101/2024.02.\n24.581671(2024).\n11. Das, R. et al. Assessment of three-dimensional RNA structure pre-\nd i c t i o ni nC A S P 1 5 .Proteins91,1 7 4 7– 1770 (2023).\n12. Kretsch, R. C. et al. RNA target highlights in CASP15: Evaluation of\npredicted models by structure providers.Proteins 91,1 6 0 0– 1615\n(2023).\n13. Schneider, B. et al. When will RNA get its AlphaFold moment?\nNucleic Acids Res.51,9 5 2 2– 9532 (2023).\n14. Wang, W. et al. trRosettaRNA: automated prediction of RNA\n3D structure with transformer network.Nat. Commun.14,\n7266 (2023).\n15. Szikszai, M., Magnus, M., Sanghi, S., Kadyan, S., Bouatta, N. & Rivas,\nE. RNA3DB: A structurally-dissimilar dataset split for training and\nbenchmarking deep learning models for RNA structure prediction.\nJ. Mol. Biol.436, 168552 (2024).\n16. Paysan-Lafosse, T. et al. InterPro in 2022.Nucleic Acids Res.51,\nD418– D427 (2023).\n17. Kalvari, I. et al. Rfam 14: expanded coverage of metagenomic,\nviral and microRNA families.Nucleic Acids Res.49,D 1 9 2– D200\n(2021).\n18. Quast, C. et al. The SILVA ribosomal RNA gene database project:\nimproved data processing and web-based tools.Nucleic Acids Res.\n41,D 5 9 0– D596 (2013).\n19. RNAcentral Consortium. RNAcentral 2021: secondary structure\nintegration, improved sequence search and new member data-\nbases. Nucleic Acids Res.49,D 2 1 2– D220 (2021).\n20. Nawrocki, E. P. & Eddy, S. R. Infernal 1.1: 100-fold faster RNA\nhomology searches.Bioinformatics29,2 9 3 3– 2935 (2013).\n21. Zhang, C., Zhang, Y. & Pyle, A. M. rMSA: a sequence search and\nalignment algorithm to improve RNA structure modeling.J. Mol.\nBiol. 435,1 6 7 9 0 4( 2 0 2 3 ) .\n22. Berman, H. M. et al. The Protein Data Bank.Acta Crystallogr. D. Biol.\nCrystallogr.58,8 9 9– 907 (2002).\n23. Hecht, S. M. Expansion of the genetic code through the use of\nmodiﬁed bacterial ribosomes.J. Mol. Biol.434, 167211 (2022).\n2 4 . M e l oC z e k s t e r ,C . ,R o b e r t s o n ,W .E . ,W a l k e r ,A .S . ,S ö l l ,D .&S c h e -\npartz, A. In vivo biosynthesis of aβ-amino acid-containing protein.J.\nAm. Chem. Soc.138,5 1 9 4– 5197 (2016).\n25. Maini, R. et al. Protein synthesis with ribosomes selected for the\nincorporation ofβ-amino acids.Biochemistry54,\n3694– 3706 (2015).\n26. Maini, R. et al. Ribosome-mediated incorporation of dipeptides and\ndipeptide analogues into proteins in vitro.J. Am. Chem. Soc.137,\n11206– 11209 (2015).\n27. Schmied, W. H. et al. Controlling orthogonal ribosome subunit\ninteractions enables evolution of new function.Nature 564,\n444– 448 (2018).\n28. Schedlbauer, A. et al. A conserved rRNA switch is central to\ndecoding site maturation on the small ribosomal subunit.Sci. Adv.\n7,e a b f 7 5 4 7( 2 0 2 1 ) .\n29. Liu, F., Bratulić, S., Costello, A., Miettinen, T. P. & Badran, A. H.\nDirected evolution of rRNA improves translation kinetics and\nrecombinant protein yield.Nat. Commun.12, 5638 (2021).\n3 0 . Q i n ,B .e ta l .C r y o - E Mc a p t u r e searly ribosome assembly in action.\nNat. Commun.14,8 9 8( 2 0 2 3 ) .\n31. Sheng, K. et al. Assembly landscape for the bacterial large riboso-\nmal subunit.Nat. Commun.14, 5220 (2023).\n32. Ward, F. R., Watson, Z. L., Ad, O., Schepartz, A. & Cate, J. H. D.\nDefects in the assembly of ribosomes selected forβ-amino acid\nincorporation.Biochemistry58,4 4 9 4– 4504 (2019).\n33. Bloom, J. D., Labthavikul, S. T., Otey, C. R. & Arnold, F. H. Protein\nstability promotes evolvability.P r o c .N a t lA c a d .S c i .U S A103,\n5869– 5874 (2006).\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 15\n34. Romero, P. A. & Arnold, F. H. Exploring proteinﬁtness landscapes\nby directed evolution.Nat. Rev. Mol. Cell Biol.10,8 6 6– 876 (2009).\n35. Tokuriki, N. & Tawﬁk, D. S. Stability effects of mutations and protein\nevolvability.Curr. Opin. Struct. Biol.19,5 9 6– 604 (2009).\n36. Parks, D. H. et al. A standardized bacterial taxonomy based on\ngenome phylogeny substantially revises the tree of life.Nat. Bio-\ntechnol.36, 996– 1004 (2018).\n37. Szymanski, M., Zielezinski, A., Barciszewski, J., Erdmann, V. A. &\nKarlowski, W. M. 5SRNAdb: an information resource for 5S riboso-\nmal RNAs.Nucleic Acids Res.44,D 1 8 0– D183 (2016).\n38. Sato, Y., Okano, K., Kimura, H. & Honda, K. TEMPURA: Database of\nGrowth TEMPeratures of Usual and RAre Prokaryotes.Microbes\nEnviron.35, ME20074 (2020).\n39. Helena-Bueno K., Brown C. R., Melnikov S. Gosha: a database of\norganisms with deﬁned optimal growth temperatures. Preprint at\nbioRxiv https://doi.org/10.1101/2021.12.21.473645(2023).\n40. Li, G., Rabe, K. S., Nielsen, J. & Engqvist, M. K. M. Machine\nlearning applied to predicting microorganism growth tempera-\ntures and enzyme catalytic optima.ACS Synth. Biol.8, 1411– 1420\n(2019).\n41. Ingraham, J., Garg, V. K., Barzilay, R. & Jaakkola, T. Generative\nmodels for graph-based protein design. NeurIPS Proceed-\nings (2019).\n42. Watson, Z. L. et al. Structure of the bacterial ribosome at 2 Å reso-\nlution. Elife 9, e60482 (2020).\n43. Karpathy, A. nanoGPT. GitHubhttps://github.com/karpathy/\nnanoGPT (2023).\n44. Su, J., et al. RoFormer: Enhanced transformer with rotary position\nembedding. arXivhttps://doi.org/10.48550/arXiv.2104.\n09864 (2021).\n45. Zhao, Y., Oono, K., Takizawa, H. & Kotera, M. GenerRNA: A gen-\nerative pre-trained language model for de novo RNA design.PLoS\nOne 19, e0310814 (2024).\n46. Gage, P. A new algorithm for data compression.The C Users Jour-\nnal, Volume 12, (1994).\n47. Nissley, A. J., Penev, P. I., Watson, Z. L., Banﬁeld, J. F. & Cate, J. H. D.\nRare ribosomal RNA sequences from archaea stabilize the bacterial\nribosome.Nucleic Acids Res.51, 1880– 1894 (2023).\n48. Nikolay, R. et al. Structural visualization of the formation and acti-\nvation of the 50S ribosomal subunit during in vitro reconstitution.\nMol. Cell70,8 8 1– 893.e3 (2018).\n49. Nikolay, R. et al. Snapshots of native pre-50S ribosomes reveal a\nbiogenesis factor network and evolutionary specialization.\nMol. Cell\n81,1 2 0 0– 1215.e9 (2021).\n50. Nissley, A. J., Kamal, T. S. & Cate, J. H. D. Interactions between\nterminal ribosomal RNA helices stabilize the large ribosomal sub-\nunit. RNA 29,1 5 0 0– 1508 (2023).\n51. Youngman, E. M. & Green, R. Afﬁnity puriﬁcation of in vivo-\nassembled ribosomes for in vitro biochemical analysis.Methods36,\n305– 312 (2005).\n52. Sponer, J., Leszczynski, J. & Hobza, P. Electronic properties,\nhydrogen bonding, stacking, and cation binding of DNA and RNA\nbases. Biopolymers61,3 – 31 (2001).\n53. Zuber, J., Schroeder, S. J., Sun, H., Turner, D. H. & Mathews, D.\nH. Nearest neighbor rules for RNA helix folding thermo-\ndynamics: improved end effects.Nucleic Acids Res.50,\n5251– 5262 (2022).\n54. Rives, A. et al. Biological structure and function emerge from\nscaling unsupervised learning to 250 million protein sequences.\nP r o c .N a t lA c a d .S c i .U S A118, e2016239118 (2021).\n55. Vaswani A., et al. Attention is all you need. arXivhttps://doi.org/10.\n48550/arXiv.1706.03762(2017).\n56. Wu, M. T.-P. & D’Souza, V. Alternate RNA structures.Cold Spring\nHarb. Perspect. Biol.12, a032425 (2020).\n57. Bose, R., Saleem, I. & Mustoe, A. M. Causes, functions, and ther-\napeutic possibilities of RNA secondary structure ensembles and\nalternative states.Cell Chem. Biol.31,1 7– 35 (2024).\n58. Rognes, T., Flouri, T., Nichols, B., Quince, C. & Mahé, F. VSEARCH: a\nversatile open source tool for metagenomics.PeerJ4, e2584 (2016).\n59. Eddy, S. R. Accelerated proﬁle HMM searches.PLoS Comput. Biol.\n7, e1002195 (2011).\n60. Pruesse, E., Peplies, J. & Glöckner, F. O. SINA: accurate high-\nthroughput multiple sequence alignment of ribosomal RNA genes.\nBioinformatics28,1 8 2 3– 1829 (2012).\n61. Fu, L., Niu, B., Zhu, Z., Wu, S. & Li, W. CD-HIT: accelerated for\nclustering the next-generation sequencing data.Bioinformatics28,\n3150– 3152 (2012).\n62. Katoh, K. & Standley, D. M. MAFFT multiple sequence alignment\nsoftware version 7: improvements in performance and usability.\nMol. Biol. Evol.30,7 7 2– 780 (2013).\n6 3 . D a o ,T . ,F u ,D .Y . ,E r m o n ,S . ,R u d r a ,A .&R é ,C .F l a s h A t t e n t i o n :F a s t\nand memory-efﬁcient exact attention with IO-awareness.arXiv\nhttps://arxiv.org/abs/2205.14135(2022).\n64. Sennrich, B. Z. A. Root mean square layer normalization. arXiv\n12360– 12371 (2019).\n65. Veidenberg, A., Medlar, A. & Löytynoja, A. Wasabi: An integrated\nplatform for evolutionary sequence analysis and data visualization.\nMol. Biol. Evol.33,1 1 2 6– 1130 (2016).\n66. Veidenberg, A. & Löytynoja, A. Evolutionary sequence analysis and\nvisualization with Wasabi.Methods Mol. Biol.2231, 225– 240 (2021).\n6 7 . D o u t h w a i t e ,S . ,P o w e r s ,T . ,L e e ,J .Y .&N o l l e r ,H .F .D eﬁning the\nstructural requirements for a helix in 23 S ribosomal RNA that\nconfers erythromycin resistance.J. Mol. Biol.209,6 5 5– 665 (1989).\n68. Schneider, C. A., Rasband, W. S. & Eliceiri, K. W. NIH Image to\nImageJ: 25 years of image analysis.Nat. Methods9,6 7 1– 675 (2012).\n69. Dixon, A. S. et al. NanoLuc complementation reporter optimized for\naccurate measurement of protein interactions in cells.ACS Chem.\nBiol. 11,4 0 0– 408 (2016).\n70. Shulgina, Y. et al. RNA language models predict mutations that\nimprove RNA function. GARNET_DL.https://doi.org/10.5281/\nzenodo.14003346(2024).\nAcknowledgements\nThis manuscript is the direct outcome of a community effort, gener-\nously hosted by the Innovative Genomics Institute and University of\nCalifornia Berkeley Electrical Engineering and Computer Sciences\nDepartment. We thank the RNA Consortium for the useful discussions\nthat inspired this work, including: Dr. Benjamin Adler, Professor Adam\nArkin, Dr. Jigyasa Arora, Teena Bajaj, Dr. Daniel Bellieny-Rabelo, Dr.\nDavid Ding, Dr. Hope Henderson, Aditya Iyer, Ryan Keivanfar, Annabel\nLarge, Kenneth Loi, Dr. Andrew Murdoch, Ruchir Rastogi, Omer Ronen,\nAdit Shah, Rachel Weissman and Chengzhong Ye. These discussions\nwere coordinated by Dr. Daniel Bellieny-Rabelo, Elaine Zhang, Keana\nLucas and Theodore Prompichai. We are also grateful to Jamie Irvine\nwho reviewed the manuscript and provided essential insights. Finally,\nwe thank Dr. Robert Wang, Alex Lotz and Tafadzwa Chimbindi from\nAmazon Web Services, whose extensive support and enablement\nmade this event possible. This work was supported by the NSF Center\nfor Genetically Encoded Materials (C-GEM, CHE-2002182: J.H.C., Y.S.,\nA.J.N.) and the NSF Graduate Research Fellowships Program (P.Y.). Y.S.\nis a Don Brown Awardee of the Life Sciences Research Foundation. S.C.\nis supported by the Masason Foundation and the Mercatus Center’s\nEmergent Ventures Fellowship. P.S. is supported by the Swiss National\nScience Foundation Mobility fellowship (P500PB_214418). H.S. is an\nHHMI Fellow of The Jane Cofﬁn Childs Fund for Medical Research.\nE.E.D. is funded by the CIRM Training Program (EDUC4-12790). J.A.D. is\nan investigator of the Howard Hughes Medical Institute, and research\nin the Doudna lab is supported by the Howard Hughes Medical Institute\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 16\n(HHMI), NIH/NIAID (U54AI170792, U19AI135990, UH3AI150552,\nU01AI142817), NIH/NINDS (U19NS132303), NSF (2334028), DOE (DE-\nAC02-05CH11231, 2553571, B656358), Lawrence Livermore National\nLaboratory, Apple Tree Partners (24180), UCB-Hampton University\nSummer Program, Mr. Li Ka Shing, Emerson Collective and the Inno-\nvative Genomics Institute (IGI).\nAuthor contributions\nJ.H.C. conceptualized the RNA LM project. Y.S., M.I.T., P.S., H.N., R.S.B.,\nand H.S. conceptualized strategy for project implementation. Y.S., C.L.,\nand M.I.T. produced the GARNET database. J.H.C., H.N., S.C., R.S.B., and\nA.M.I. developed the software and methodology for the models. Y.S.,\nJ.H.C., C.L., and H.N. validated models. Y.S., C.L., M.I.T., J.P., P.S., and\nH.S. contributed to bioinformatics analyses. M.I.T, P.Y., E.E.D., J.P., P.S.,\nH.S., and T.P. reviewed taxonomic data. A.J.N. designed and performed\nall experiments. J.H.C., Y.S., C.L., M.I.T., J.P., P.S., and A.J.N. prepared\nﬁgures and visual representations. J.H.C., Y.S., C.L., M.I.T., H.N., S.C.,\nP.S., and A.J.N. wrote the initial draft and all authors reviewed and edited\nthe manuscript. J.H.C. and J.A.D. were responsible for funding and\nsupervised the project.\nCompeting interests\nJ.H.C. is the founder, board and SAB member of Initial Therapeutics. The\nRegents of the University of California have patents issued and pending\nfor CRISPR technologies on which J.A.D. is an inventor. J.A.D. is a\ncofounder of Azalea Theratupics, Caribou Biosciences, Editas Medicine,\nEvercrisp, Scribe Therapeutics, Intellia Therapeutics, and Mammoth\nBiosciences. J.A.D. is a scientiﬁc advisory board member at Evercrisp,\nCaribou Biosciences, Intellia Therapeutics, Scribe Therapeutics, Mam-\nmoth Biosciences, The Column Group, and Inari. J.A.D. is Chief Science\nAdvisor to Sixth Street, a Director at Johnson & Johnson, Altos, and\nTempus, and has a research project sponsored by Apple Tree Partners.\nThe remaining authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41467-024-54812-y.\nCorrespondenceand requests for materials should be addressed to\nJamie H. D. Cate.\nPeer review informationNature Communicationsthanks the anon-\nymous reviewer(s) for their contribution to the peer review of this work. A\npeer reviewﬁle is available.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to jur-\nisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article’s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visithttp://creativecommons.org/\nlicenses/by/4.0/.\n© The Author(s) 2024, corrected publication 2025\nArticle https://doi.org/10.1038/s41467-024-54812-y\nNature Communications|        (2024) 15:10627 17",
  "topic": "RNA",
  "concepts": [
    {
      "name": "RNA",
      "score": 0.8030255436897278
    },
    {
      "name": "Computational biology",
      "score": 0.5819586515426636
    },
    {
      "name": "Biology",
      "score": 0.5241109132766724
    },
    {
      "name": "Genetics",
      "score": 0.4947482943534851
    },
    {
      "name": "Non-coding RNA",
      "score": 0.48710036277770996
    },
    {
      "name": "Nucleic acid structure",
      "score": 0.4514351487159729
    },
    {
      "name": "Ribosomal RNA",
      "score": 0.43727102875709534
    },
    {
      "name": "RNA editing",
      "score": 0.429463267326355
    },
    {
      "name": "Gene",
      "score": 0.3742000460624695
    }
  ]
}