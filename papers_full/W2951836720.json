{
  "title": "A Novel Deep Recurrent Belief Network Model for Trend Prediction of Transformer DGA Data",
  "url": "https://openalex.org/W2951836720",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A1933846818",
      "name": "Qi Bo",
      "affiliations": [
        "North China Electric Power University"
      ]
    },
    {
      "id": "https://openalex.org/A2095829628",
      "name": "Yiming Wang",
      "affiliations": [
        "North China Electric Power University"
      ]
    },
    {
      "id": "https://openalex.org/A1972955069",
      "name": "Peng Zhang",
      "affiliations": [
        "North China Electric Power University"
      ]
    },
    {
      "id": "https://openalex.org/A2124464027",
      "name": "Chengrong Li",
      "affiliations": [
        "North China Electric Power University"
      ]
    },
    {
      "id": "https://openalex.org/A2116476370",
      "name": "Hongbin Wang",
      "affiliations": [
        "China Southern Power Grid (China)"
      ]
    },
    {
      "id": "https://openalex.org/A1933846818",
      "name": "Qi Bo",
      "affiliations": [
        "North China Electric Power University"
      ]
    },
    {
      "id": "https://openalex.org/A2095829628",
      "name": "Yiming Wang",
      "affiliations": [
        "North China Electric Power University"
      ]
    },
    {
      "id": "https://openalex.org/A1972955069",
      "name": "Peng Zhang",
      "affiliations": [
        "North China Electric Power University"
      ]
    },
    {
      "id": "https://openalex.org/A2124464027",
      "name": "Chengrong Li",
      "affiliations": [
        "North China Electric Power University"
      ]
    },
    {
      "id": "https://openalex.org/A2116476370",
      "name": "Hongbin Wang",
      "affiliations": [
        "China Southern Power Grid (China)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2102259958",
    "https://openalex.org/W61267734",
    "https://openalex.org/W2922207751",
    "https://openalex.org/W7021047971",
    "https://openalex.org/W2597866042",
    "https://openalex.org/W2921108624",
    "https://openalex.org/W2178155017",
    "https://openalex.org/W1964155876",
    "https://openalex.org/W2159852473",
    "https://openalex.org/W2084277209",
    "https://openalex.org/W2747648188",
    "https://openalex.org/W2136922672",
    "https://openalex.org/W2100495367",
    "https://openalex.org/W2770049107",
    "https://openalex.org/W2026637527",
    "https://openalex.org/W2043032216",
    "https://openalex.org/W2770597112",
    "https://openalex.org/W2313609130",
    "https://openalex.org/W2135099239",
    "https://openalex.org/W2766447205",
    "https://openalex.org/W2350984194"
  ],
  "abstract": "Oil chromatography data together with its variation trend provide the key basis for the evaluation of the transformer health state. The existing studies on deep belief network (DBN) and support vector machine (SVM) have reported a few results in the field of oil chromatography data prediction. However, the above-mentioned methods are proposed for the classification problem, so there is no theoretical basis for applying the above-mentioned methods to the time-series prediction. The wrong usage limits the accuracy of the predicted results, which is observed as the obvious &#x201C;time-shift&#x201D; error in the prediction curve, leading to the predicted state inconsistent with the actual situation. To fill the gap, a deep recurrent belief network (DRBN) model for the transformer state prediction was proposed based on the time-series theory and oil chromatography data characteristics. In this model, the construction shortage of DBN in time-series prediction was analyzed as a prototype pattern to structure the stereoscopic mapping relation. The self-adaptive delay network based on the principle of autocorrelation, together with the corresponding error feedback network, realized the stereoscopic flow of data in multi-dimensional space and, thus, ensured the model's valid expression of the time-domain correlation. In addition, the cross-entropy loss function, based on the Kullback-Leibler divergence and the Weibull distribution with an obvious characteristic of DGA, was constructed to eliminate the uncertainty of initialization process and also effectively control the direction and step size of the error gradient. The examples in the field were used to verify the method to find that the model proposed in this paper can availably overcome the &#x201C;time-shift&#x201D; error, and its prediction accuracy can reach more than 95.16%.",
  "full_text": "SPECIAL SECTION ON ADVANCES IN PROGNOSTICS AND SYSTEM HEALTH MANAGEMENT\nReceived May 9, 2019, accepted June 8, 2019, date of publication June 14, 2019, date of current version July 2, 2019.\nDigital Object Identifier 10.1 109/ACCESS.2019.2923063\nA Novel Deep Recurrent Belief Network Model for\nTrend Prediction of Transformer DGA Data\nBO QI\n 1,2, (Member, IEEE), YIMING WANG1,2, PENG ZHANG1,2, CHENGRONG LI1,2, (Senior Member, IEEE),\nAND HONGBIN WANG3\n1State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing 102206, China\n2Beijing Key Laboratory of High V oltage and EMC, North China Electric Power University, Beijing 102206, China\n3Guangzhou Power Grid Company of China Southern Power Grid Co., Ltd., Guangzhou 510620, China\nCorresponding author: Bo Qi (lqicb@163.com)\nThis work was supported by the National High Technology Research and Development Program of China under Grant 2015AA050204.\nABSTRACT Oil chromatography data together with its variation trend provide the key basis for the\nevaluation of the transformer health state. The existing studies on deep belief network (DBN) and support\nvector machine (SVM) have reported a few results in the ﬁeld of oil chromatography data prediction.\nHowever, the above-mentioned methods are proposed for the classiﬁcation problem, so there is no theoretical\nbasis for applying the above-mentioned methods to the time-series prediction. The wrong usage limits the\naccuracy of the predicted results, which is observed as the obvious ‘‘time-shift’’ error in the prediction curve,\nleading to the predicted state inconsistent with the actual situation. To ﬁll the gap, a deep recurrent belief\nnetwork (DRBN) model for the transformer state prediction was proposed based on the time-series theory\nand oil chromatography data characteristics. In this model, the construction shortage of DBN in time-series\nprediction was analyzed as a prototype pattern to structure the stereoscopic mapping relation. The self-\nadaptive delay network based on the principle of autocorrelation, together with the corresponding error\nfeedback network, realized the stereoscopic ﬂow of data in multi-dimensional space and, thus, ensured the\nmodel’s valid expression of the time-domain correlation. In addition, the cross-entropy loss function, based\non the Kullback–Leibler divergence and the Weibull distribution with an obvious characteristic of DGA, was\nconstructed to eliminate the uncertainty of initialization process and also effectively control the direction and\nstep size of the error gradient. The examples in the ﬁeld were used to verify the method to ﬁnd that the model\nproposed in this paper can availably overcome the ‘‘time-shift’’ error, and its prediction accuracy can reach\nmore than 95.16%.\nINDEX TERMS Transformer, state prediction, deep belief network (DBN), oil chromatography, self-\nadaptive delay network.\nI. INTRODUCTION\nTransformer is key equipment in the power system. Its oper-\nating state directly affects the reliability of the regional power\nnetwork [1], [2]. Dissolved Gas Analysis (DGA) is among the\nmost reliable methods for state estimation and fault diagnosis\nof oil-immersed transformer [3]. International Electrotech-\nnical Commission (IEC) recommended it as the main test\nmethod for the state evaluation of oil-immersed power equip-\nment [4]. The analysis results of oil chromatography online\nmonitoring data can be used to effectively predict the devel-\nopment trend of equipment state, so as to timely avoid the\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Dong Wang.\noccurrence of irreversible insulation damage, and thus ensure\nand improve the safety and stability of the power system.\nIn recent years, the Deep Belief Network (DBN) has been\nwidely used in trend prediction thanks to its advantages in\ndealing with complex nonlinear problems. The network is\ncomposed of Restricted Boltzmann Machine (RBM) based\non the energy model. In order to enhance the network’s\nperformance over complex dynamics, the RBM unit was\nclosely combined with the error feedback process that could\nhelp to eliminate the error [5], [6]. In addition, the Com-\nparison Divergence algorithm has been adopted to optimize\nthe original Gibbs sampling process, which would improve\nthe computational efﬁciency of the network and realize the\naccurate expression of complex scenarios. As the DGA data\nVOLUME 7, 2019\n2169-3536 \n 2019 IEEE. Translations and content mining are permitted for academic research only.\nPersonal use is also permitted, but republication/redistribution requires IEEE permission.\nSee http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\n80069\nB. Qiet al.: Novel DRBN Model for Trend Prediction of Transformer DGA Data\nFIGURE 1. Diagram of prediction error based on DBN.\nhas strong nonlinear properties, it is difﬁcult for the con-\nventional mathematical model to grasp its ﬂuctuation trend.\nUnexpectedly, DBN is incorrectly in the prediction of time\nseries such as oil chromatography.\nA large number of studies have been carried out on time-\nseries prediction with the application of DBN, but with\nthe prediction error manifested as the ‘‘time-shift’’ error on\nthe time scale and the ‘‘amplitude’’ error on the amplitude\nscale [7]–[10]. Liang applied DBN to power system load\nprediction, and then the predicted values were optimized\nand reconstructed by particle swarm algorithm. However,\nthe predicted results were found with ‘‘time-shift’’ error [7].\nDai et al. applied DBN in the prediction of transformer\noil chromatography. Despite that the prediction accuracy of\nDBN has been improved in comparison with the Back Prop-\nagation Neural Network (BPNN), there still witnessed the\nsame error as mentioned above in the previous study [8].\nIn other ﬁelds, an obvious ‘‘time-shift’’ error has also been\nfound in the DBN network prediction results, as shown in\nFigure 1. Surprisingly, the similar ‘‘time-shift’’ error was\nfound in the DGA prediction model based on SVM [10]. The\nmain reason for this error is that DBN has limited ability\nto express time-series data. At present, there have been few\nstudies on the source of the error and the suppression method.\nIn order to address the ‘‘time-shift’’ error, a series of math-\nematical models including the Grey Model (GM), Recur-\nrent Neural Network (RNN) and Long Short Term Memory\nNetwork (LSTM) has been proposed successively [11]–[13].\nThe RNN, among others, is a model structure with historical\nmemory [14], [15]. Compared with the multilayer perceptron,\nthis network increases the feedback path of the time dimen-\nsion, so it is especially suitable for modeling sample data\nwith strong correlation time-series information. The predic-\ntion of temporal sequence for oil chromatography data is a\ntypical application of strong correlation time-series informa-\ntion processing, which determines that RNN can effectively\novercome the ‘‘time-shift’’ error in complex nonlinear time-\nseries prediction.\nTherefore, the Deep Recurrent Belief Network (DRBN)\nwas proposed for transformer state prediction in the present\nresearch. This model constructed a deep network structure\nFIGURE 2. Topology of multidimensional stereoscopic mapping\nrelationship in oil chromatography prediction.\nwith time-series correlation characteristics, eliminated the\n‘‘time-shift’’ error in the prediction results, and corrected\nthe error’s iterative update process, ensuring that the error\nﬂows simultaneously between and within the network layers.\nIn addition, a cross-entropy loss function based on Kullback-\nLeibler divergence was proposed to deal with the uncertainty\nin the initialization process, which effectively controlled the\ndirection and step size of the error gradient.\nII. TYPES OF TIME-SERIES DATA OF DGA\nThe dissolved gases constantly generated alongside insula-\ntion cracking, namely the CH 4, C 2H6, C 2H4, C 2H2, H 2,\nCO, CO 2, O 2, are affected by such environmental factors\nas temperature, pressure, moisture, cavity material, etc. The\nabsolute value of the gas concentration at the current time\nis called the cross-sectional data, which can only represent\nthe states or parameters at the current time. As time goes\non, different cross-sectional data are sequentially arranged on\nthe time scale, which constitutes the time-series data of oil\nchromatography [16], [17].\nThe temporal sequence prediction for oil chromatography\ndata is fundamentally different from the classiﬁcation of the\ndata. Compared with data classiﬁcation, the oil chromatog-\nraphy data prediction not only contains the mapping relation\nbetween gas concentration and the corresponding states, but\nalso includes the mapping relation between the same gas at\ndifferent times and the same states at different times. On this\nbasis, the time prediction adds a time dimension path, through\nwhich data at different times can be mapped to each other. The\nmapping relation of oil chromatography temporal sequence\nprediction is shown in Figure 2.\nIII. COMPARING THE PERFORMANCE OF COMMON\nMODELS IN TIME-SERIES PREDICTION OF DGA\nA. DBN MODEL\nThe training process of DBN consists of two parts, including\nthe local optimization of the RBM and the global error updat-\ning from the output layer to the input layer. As the iterative\ncalculations go on, the model output gets closer to the label\nvalue [18], [19]. The network topology is shown in Figure 3.\nWith the time-series regression, DBN weakens the corre-\nlation of data in the time dimension and thus the ‘‘time-shift’’\nerror is inevitably generated. The error is expressed as ‘‘time-\nshift’’ of 1-5 time units, and the uncertainty mentioned above\n80070 VOLUME 7, 2019\nB. Qiet al.: Novel DRBN Model for Trend Prediction of Transformer DGA Data\nFIGURE 3. Topology of DBN model.\nFIGURE 4. Topology of RNN model.\nis difﬁcult to be eliminated by moving data coordinates. Espe-\ncially for the oil chromatography data with strong nonlinear\ncharacteristics, this error has more obvious interference to the\nprediction results. It can be seen from the model topology\ndiagram that DBN can only be used to address cross-sectional\ndata, as is determined by the network structure itself.\nThe input layer of DBN is an RBM unit. The structure\nof the unit shows that the neurons in the same layer are not\nconnected whilst those in the adjacent layers are fully con-\nnected. In this structure, the input variables are independent\nand the correlation between the input variables is ignored.\nTherefore, the main error type of DBN is ‘‘time-shift’’ error,\nwhich comes from structural defects. In order to eliminate the\nprediction error, a model with a strengthened ability to indict\ntime-series data should be proposed by building a network\nmodel that can signiﬁcantly express the inﬂuence of historical\ndata.\nB. RNN MODEL\nThe most outstanding structural characteristic of RNN is its\nfeedback loop with time delay function, which constructs the\nchannels with variable long memory function and has the\nability to deal with time-series data. The topology of RNN\nis shown in Figure 4. The output value of the hidden layer\nunit at the previous time will be delayed to participate in the\nnetwork operation at the next time. This kind of network with\ndelay units takes into account the correlation of data to data\nin the cross-sectional data and that of time to time in the time\ndimension. It can, therefore, achieve good application effect\nin the processing of stable time-series data.\nThe oil chromatography data has extremely strong nonlin-\near properties. Though RNN has limited ability to express\ncomplex laws, there is no delay error generated in the model.\nThe time-series curve of its predicted results is shown in Fig-\nure 5. With the DBN model, the prediction accuracy can\nreach more than 90%. But there remains the ‘‘time-shift’’\nerror which could affect the state prediction. In comparison,\nthe prediction accuracy with RNN is not as high, whilst the\n‘‘time-shift’’ error of the result is rather minor. Therefore,\nRNN has a strong ability to express the temporal correlation\nof data.\nThe performance of other mathematical models in the\nprediction of oil chromatography data is shown in Table 1.\nDue to the big inﬂuence of kernel function, SVM is not good\nFIGURE 5. Temporal sequence prediction curves of DBN and RNN models.\nC. Other Models. (a) H2. (b) CH4.\nTABLE 1. Comparison of mathematical models performance in DGA\nprediction.\nFIGURE 6. Topology of DRBN model and process of information transfer.\nat expressing nonlinear problems, and there is no clear rule for\nthe construction of kernel function [11]. GM is a short-term\nprediction model, which performs poorly in long-term trend\nprediction [13]. RNN model can signiﬁcantly eliminate the\n‘‘time-shift’’ error, thanks to its time-domain path reﬂecting\nthe ﬂow of historical data. The main error of BPNN and DBN\nin the prediction problem is the ‘‘time-shift’’ error [20].\nIV. DRBN FOR TRANSFORMER STATE PREDICTION\nThe topology of DRBN is shown in Figure 6. Its model\nstructure is mainly composed of three parts: the forward\ngeneration network, the self-adaptive delay network and the\nerror feedback network.\nThe forward generation network consists of the input layer,\nthe multiple hidden layers, and the output layer. After it is\nreconstructed by multiple RBM units, the oil chromatography\ndata will ﬁnally be transferred to the label layer, as is shown\nby the grey arrow in Figure 6. The self-adaptive delay network\nis composed of the last hidden layer and the multiple time\ndimension pathways, which can realize the intercommunica-\ntion between relevant time and current time data to represent\nthe correlation of time-series, as is shown by the shaded\narrow. The error feedback network is made up of the error\nVOLUME 7, 2019 80071\nB. Qiet al.: Novel DRBN Model for Trend Prediction of Transformer DGA Data\nTABLE 2. The list of notations used in the paper.\nfeedback processes of the time dimension and the cross-\nsectional dimension. As is shown in the white arrow and the\nreverse shadow arrow, the network can guarantee the stereo\nnetwork correction and ensure both efﬁciency and accuracy\nof the calculation.\nA. CONSTRUCTION OF FORWARD GENERATION\nNETWORK\nThe network consists of n RBM units. The oil chromatog-\nraphy historical data were input into the model through the\ninput layer. The input data underwent continuous reconstruc-\ntion in each RBM unit. When the reconstruction error reached\nthe set threshold value, the training of the current RBM unit\nterminated. Different from DBN, the feedback loop with\ndelay parts was established in each RBM units in this paper,\nwhich has the function of short-term historical memory. The\nhistorical memory data and the current time data extracted\nby the deep energy model served as the model input, which\nimproves the ﬁtting ability of the network to the complex\ntime-series relations. The output layer is the label correspond-\ning to the data. Network errors were obtained by comparing\nthe labels with the model output. The network parameters\nwere adjusted through the improved ﬁne-tuning process. The\nlist of notations used in the paper is shown in Table 2.\nThe training process of RBM is basic and obvious. In order\nto clear the reasoning and emphasize information transfer\nbetween layers in this paper, the section of RBM was delib-\nerately ignored during the formula derivation.\nThe forward generation calculation process is expressed as\nfollows:\nSi(t) =\n\n\n\n\n\n\n\nf [Ui(t)X(t) +ai(t)], i=1\nf [Ui(t)Si−1(t) +ai(t)], i∈[2,k −2]\nf [Ui(t)Si−1(t)\n+W (t)Si(t −1) +ai(t)], i=k −1\n(1)\nˆO(t) =g[V (t)Si(t) +b(t)] (2)\nFIGURE 7. Topology of self-adaptive delay network.\nAssuming the hidden layer (i-1) contains n neurons and the\nhidden layer (i-2) contains m neurons, the forward generation\nprocess without bias can be expressed as follows:\nSi(t) =f [(u1\ni (t),u2\ni (t),···um\ni (t)) ×Si−1(t)\n+(w1\ni (t),w2\ni (t),···wm\ni (t)) ×Si(t −1)] (3)\nB. CONSTRUCTION OF SELF-ADAPTIVE DELAY NETWORK\nBased on the above analysis, it is inferred that the oil\nchromatography data has a distinct correlation on the time\ndomain. The self-adaptive delay network was constructed to\nrepresent the impact of historical data on the current time,\nwhich is mainly composed of the module of self-adaptive\ndiscriminating, the module of conditioning output and the\nmodule of time delay units group. Its network topology is\nshown in Figure 7. The dark arrow represents the process of\noutput and input, the white arrow represents the process of\ninternal information collection, and the shaded arrow repre-\nsents the process of internal information forward propagation.\nFinally, the information was collected by the module of con-\nditioning output and passed to the hidden layer. At present,\nthe commonly used time-domain network construction meth-\nods mostly adopt the ﬁxed-length time-scale to determine\nthe number of delay parts. However, the chromatography\ndata of transformer oil under different voltage levels and\ndifferent stages are obviously different. The ﬂuctuation of\ndifferent gases under different environmental factors is also\nsigniﬁcantly different. It is therefore difﬁcult to reﬂect the\nactual state of the present moment with historical data of a\nﬁxed-length time scale. In this paper, a variable-length time-\nscale selection method based on the autocorrelation of time-\nseries theory was proposed.\nThe autocorrelation of time-series theory refers to the cor-\nrelation degree between the values of the same data set at any\ndifferent times, which can be used to evaluate the correlation\nbetween discrete sampling points within the sequence. If the\ncurrent oil chromatography is x(t), the Autocorrelation Coef-\nﬁcient r(k) can be obtained through the following function:\nr(k) =1\nT\nT −k∑\nt=1\n(x(t) −¯x)(x(t +k) −¯x)\nc(0) (4)\n80072 VOLUME 7, 2019\nB. Qiet al.: Novel DRBN Model for Trend Prediction of Transformer DGA Data\nFIGURE 8. Autocorrelation coefficient of oil chromatography data with\nCO gas concentration data as examples.\nwhere, k is the number of delay units, x(t +k) is the oil\nchromatography before k time units, ¯x is the sample average\nof the time series, c0 is the sample variance of the time\nseries. This index represents the gas concentration correlation\nbetween the current time and several delayed times.\nThe autocorrelation coefﬁcients of oil chromatography\ndata of 1-20 delay units were calculated, and the result of CO\ngas was shown in Figure 8. In this ﬁgure, the horizontal axis\nshows the number of delay parts whilst the vertical axis marks\nthe Autocorrelation Coefﬁcient (AC). The higher the AC is,\nthe stronger the correlation between the two series on the time\ndimension will be.\nIn order to ensure the validity of the temporal sequence\nprediction, this paper holds that when the AC is bigger than\n0.85, there is a signiﬁcant correlation between the same\ndata at different times. The selection of this threshold is\nthe empirical value by carrying out a large number of tests,\nwhich has instructive signiﬁcance for the prediction of the\nDGA time series. In this paper, six-time delay pathways were\nconstructed, representing the inﬂuence of the ﬁrst unit until\nthe ﬁrst 6 units of historical data on the current time. This\nmodeling technique has realized the dynamic length selection\nof the time-scale historical data.\nC. CONSTRUCTION OF ERROR FEEDBACK NETWORK\nThe construction of the error feedback network ensures that\nthe network can approach the optimal direction to obtain the\nglobal superior solution ﬁnally. Compared with the simple\nclassiﬁcation, the error feedback network of prediction based\non time-series data was carried out simultaneously in the\ncross-sectional dimension and time dimension. If the output\nvalue of the model is set as ˆO(t), the model error at time t is\nas follows:\nE(t) =ˆO(t) −O(t) (5)\nThe error gradient δi(t) is the derivative of the error. In the\nfeedback processing, the error was extended in two different\ndirections:\n1) Error E1(t) is extended in the cross section. Suppose\nthe error gradient along this direction is δi−1(t), according to\nequation (2), this part of error is only related to the weight\nU(t). The error gradient δi−1(t) can be obtained as follows:\n{\nψi(t) =Ui(t)Si−1(t) +W (t)Si(t −1)\nSi(t −1) =f [ψi(t)] (6)\nIts error gradient is as follows:\nδi−1(t) = ∂E\n∂ψi−1(t)\n= ∂E\n∂ψi−1(t) × ∂ψi−1(t)\n∂ψi−1(t −1) ×···× ∂ψi−1(0)\n∂ψi−1(1) (7)\nThe chain rule is presented as follows:\n∂ψi−1(t)\n∂ψi−1(t −1) = ∂ψi−1(t)\n∂Si−1(t −1) ×∂Si−1(t −1)\n∂ψi−1(t −1) (8)\nThe error gradient that is extended in the cross section is\nas follows:\nδi−1(t) = ∂E\n∂ψi−1(t)\nk−1∏\ni=1\nW (t)diag{f ′\ni−1[ψi−1(t −1)]} (9)\n2) Error E2(t) is extended along the direction of the time\naxis, and the error gradient along this direction is set as\nδi(t-1). Similarly, according to equation (2), this part of error\nis only related to weight W (t). The error gradient δi(t-1) can\nbe obtained as follows:{\nψi(t) =Ui(t)Si−1(t) +W (t)Si(t −1)\nSi−1(t) =f [ψi−1(t)] (10)\nSimilarly, the error gradient is presented as follows:\nδi(t −1) = ∂E\n∂ψi(t −1) × ∂ψi(t −1)\n∂ψi−1(t −1) (11)\nD. LOSS FUNCTION OF OIL CHROMATOGRAPHY BASED\nON CROSS-ENTROPY PRINCIPLE\nThere are obvious Weibull distribution characteristics for oil\nchromatography data. The characteristics mentioned above\ncan be used for reference to the loss function, which provides\nthe basis for the convergence procedure. Therefore, a loss\nfunction based on the cross-entropy principle is used in this\npaper. By comparing the distribution of the model output\nand the original gas concentration data set, this loss function\ncalculates and optimizes the information increment in the\ntime domain [21], [22].\nSuppose the oil chromatography data sample obeys the\nWeibull distribution P and the model output obeys the sam-\nple Q, the formula of Kullback-Leibler (KL) divergence is\nexpressed as follows.\nDKL (p||q) =\nn∑\ni=1\np(xi) log p(xi)\nq(xi) (12)\nwhere, the p(xi) is the Weibull distribution value of actual oil\nchromatography data, q(xi) is the distribution value of pre-\ndicted oil chromatography data. The equation (12) consists\nof 2 parts. Its constant part could be ignored as it does not\nVOLUME 7, 2019 80073\nB. Qiet al.: Novel DRBN Model for Trend Prediction of Transformer DGA Data\nparticipate in the calculation of cross-entropy increase. The\nremaining part is taken as the loss function, called the cross-\nentropy function H(p, q).\nH(p,q) =−\nn∑\ni=1\np(xi) log q(xi) (13)\nThe H(p, q) reﬂects the mapping ability of the network model\nto the label distribution. If the value is close to 0, it indicates\nthat the network model can effectively express the data rules.\nE. MULTIDIMENSIONAL EVALUATION INDEX SET OF\nTIME-SERIES OF OIL CHROMATOGRAPHY\nBased on the oil chromatography data, the time-series mul-\ntidimensional evaluation index set was proposed. This index\nset contained 4 indexes including the Mean Absolute Percent\nError(IMAPE ), the 95% Conﬁdence Interval of Error(I CIE ),\nthe Coefﬁcient of Determination(I CD), and the Cross Corre-\nlation Coefﬁcient(ICCC ).\n1) The IMAPE is one of the most commonly used prediction\nevaluation index. Its mathematical deﬁnition is presented as\nfollows:\nIMAPE =1\nm\nm∑\ni=1\n|Oi −ˆOi|\n|Oi| ×100% (14)\n2) The ICIE is the 95% interval estimation of the sample\npopulation. This index is used to characterize the dispersion\ndegree of gas concentration prediction error. Suppose the\nmean value of error is µe, and the standard deviation of error\nis σe, the ICIE of the overall mean will be (µ e −Z0.025σe,\nµe +Z0.025σe).\n3) The ICCC is used to measures the similarity between a\ntime series and lagged versions of another time series as a\nfunction of the lag. This index can express the correlation\ndegree between the model output and the label value in the\nfrequency domain, and can be used to determine the similarity\ndegree between adjacent signals. Its mathematical deﬁnition\nis presented as follows:\nc(k) =\n\n\n\n\n\n\n\n1\nT\nT −k∑\nt=1\n(Ot −¯O)( ˆOt+k −¯ˆO), k =0,1,2 ...\n1\nT\nT +k∑\nt=1\n(Ot−k −¯O)( ˆOt −¯\nˆO), k =0,−1,−2 ...\n(15)\nr(k) = c(k)\nsOs ˆO\n(16)\nwhere, the sO is the square root for the coefﬁcient of variation\nof O(t), the s ˆO is the square root for the coefﬁcient of variation\nof ˆOt . The cross-spectrum is shown in Figure 9. The origin\nvalue of ICCC is used as the reference of the current time.\nThe numerical meaning of ICCC can be expressed as follows\nin Table 3.\n4) The ICD is used to judge the ratio of the model variance\nto the total variance. If the value is close to 1.0, it indicates that\nFIGURE 9. Cross-correlation coefficient of oil chromatography data with\nCH4 gas concentration data as examples.\nTABLE 3. The numerical meaning ofICCC.\nthe model mapping is the main factor of the total variance.\nThe mathematical expression is as follows:\nICD = SSreg\nSSreg +SSres\n×100% (17)\nwhere, SSreg is the regression sum of variance and SSres is the\nresidual sum of variance.\nF. THE PROCESS OF TRAINING\nThe oil chromatography data collected on the experiment\nsite usually has a large number of empty values, continuous\nvalues, and singular values. If the original oil chromatography\ndata are not preprocessed, there is a huge risk of divergence\nin the model. Therefore, the oil chromatography data opti-\nmization method described in reference [23] was adopted\nto correct the abnormal data points existing in the original\ndata. The preprocessing reduces the possibility of model\ndivergence that could be caused by data anomaly.\nThe neural network has many parameters which are the\nsource of its ﬁne regression ability. The initial value of these\nparameters has an obvious inﬂuence on the iterative process\nof the model. If it is not properly selected, the model diver-\ngence is also likely to occur. At present, random initialization\nis often used to set initial values for network parameters.\nConsequently, the network is at risk of extreme conditions\nsuch as local optimization or iterative divergence at the initial\nmoment. If the initial value of the parameters is not selected\nproperly, the network will easily fall into local optimization\nand therefore reduces the prediction accuracy.\nMoreover, due to the error feedback process of time dimen-\nsion introduced in the algorithm, the time delay part is ini-\ntial at the incomplete establishment stage, which also poses\nrisks of model divergence at the initial stage [24]. Therefore,\n80074 VOLUME 7, 2019\nB. Qiet al.: Novel DRBN Model for Trend Prediction of Transformer DGA Data\nTABLE 4. The key parameters of the network.\nFIGURE 10. The training flow chart of DRBN.\nbefore the training started, the initialization process had been\nintroduced in this paper to initialize the network (weight and\nbias). The speciﬁc method of initialization was DBN, and the\nsetting of key parameters is shown in Table 4.\nAs described above, a DRBN was then established on\nthe basis of the initialized network. The preprocessed oil\nchromatography time-series data was input into the network\nmodel. The network training ﬂow chart is shown in Figure 10.\nAfter multistep iteration processes, the network reached the\nexit condition and the multi-dimensional evaluation was\nperformed.\nV. CASE VALIDATION\nTaking a series of oil chromatography data from 110kV and\n220kV substation main transformer as the sample. Some\nbasic information about the equipment and monitoring data\nis shown in Table 5.\nA. NORMAL CONDITION\nIn this section, case A data is used to verify the performance\nof DRBN model under normal condition, and the predicted\nresults are shown in Figure 11. 50 consecutively predicted\nvalues of H 2, CH 4, C 2H4, and C 2H6 were captured in the\nTABLE 5. The basic information about the equipment and monitoring\ndata.\nFIGURE 11. The curves of the prediction result at the training of 50000.\n(a) H2. (b) CH4. (c) C2H2. (d) C2H6.\nTABLE 6. The multi-dimensional evaluation index of different gas at the\ntraining of 50000.\nﬁgure respectively. The key parameters of the network were\nset as shown in Table 4. The multi-dimensional evaluation\nindexes output by the model are shown in Table 6. The\nIMAPE of the oil chromatography samples of the four different\ngroups was observed to be at a low level, ranging between\n1.8% and 2.5%. The ICIE was between +2.5% to −2.5%.\nIt is inferred from these two indicators that there is a low\nprobability of singular prediction value and hence the error of\nthe prediction result is minimal. The ICD of the samples was\nbetween 0.72 and 0.87, indicating that the network mapping\nerror (white noise) on the cross section was tiny. The ICCC\nwas between 0.85 and 0.94, which indicates that there is a\nhigh accuracy of the network in the time dimension.\nTaking the above parameters as an example, the pro-\nposed algorithm was compared with the LSTM, DBN,\nGM and SVM algorithms. The comparison results are shown\nVOLUME 7, 2019 80075\nB. Qiet al.: Novel DRBN Model for Trend Prediction of Transformer DGA Data\nTABLE 7. The multi-dimensional evaluation index of different algorithm\nat the training of 50000.\nTABLE 8. The multi-dimensional evaluation index of different delay units\nat the training of 50000.\nin Table 7. It informs that the prediction results of DRBN\nare more sensitive and accurate to the variation trend of oil\nchromatography data.\nIn order to test that the self-adaptive DRBN model based\non the autocorrelation of time-series theory has achieved\nthe global optimum, the prediction results of the different\nnumber of delay units DRBN was listed in Table 8. The\nmodel structure with the 0 delay unit is the same as the DBN.\nVeriﬁcation results, which are consistent with theory, show\nthat the DRBN with 6 delay units has the optimal evaluation\nindex and competitive efﬁciency. The results are consistent\nwith the theory.\nB. FAULT CONDITION\nIn this section, case B data is used to verify the performance of\nthe DRBN model under fault condition. This case collected\nthe online monitoring data of a 220kV substation #1 main\ntransformer from June 3, 2013 to July 3, 2014. By consulting\nthe analysis report on the operation of the main transformer,\nit was found that the transformer had two high-temperature\noverheating faults on March 16 and May 25, and both of\nthem adopted the method of reducing load as fault disposal.\nLimited by load requirements and line planning, the disposed\nof transformers continue to operate.\nThe raw data was divided into 310 groups, each group\ncontaining 34 pieces of data. The ﬁrst 248 groups were taken\nto form the training set, and the remaining 62 groups were\ntaken to form the test set. The predicted results are shown\nin Figure 12. The prediction accuracy under the fault state was\nabout 98%, and the high-temperature fault caused by overload\non May 25 (around the 315th day) was accurately predicted.\nThe proposed DRBN model effectively predicted the trend\nof DGA data in the fault process, and there was no obvious\n‘‘time-shift’’ error in the predicted results.\nFIGURE 12. The curves of the prediction result under fault condition at\nthe training of 50000.\nFIGURE 13. The curves of the prediction result at the training of 100000.\nTABLE 9. The results of prediction model at the training of 100000 (µL/L).\nC. MODEL PERFORMANCE UNDER DIFFERENT\nAPPLICATION REQUIREMENTS\nTo simulate the scenario where higher accuracy is required,\nthe network training times were increased to capture the\nprediction results. Using the C 2H4 concentration data as an\nexample, the training was iterated for 100,000 times and\nthe prediction effect at this time is shown in Figure 13 and\nTable 9. The training under such parameters took 7 hours, and\nthe prediction results were evaluated as shown in Table 10.\nAll the indexes of the network model were improved, and the\nprediction ability of the network model was further enhanced.\nWhen greater computational efﬁciency is required, the net-\nwork should be initialized before the training process so as\nto achieve the high-precision convergence in a short time.\nFigure 14 shows the loss function value of the initialized\nnetwork during the ﬁrst 15,000 cycles of the training process\nin comparison with that of the uninitialized network. Under\n80076 VOLUME 7, 2019\nB. Qiet al.: Novel DRBN Model for Trend Prediction of Transformer DGA Data\nTABLE 10. The multi-dimensional evaluation index of the model at the\ntraining of 100000.\nFIGURE 14. Comparison trend of loss function value of initialized\nnetwork in the first 15000 times.\nthe same training period of about 1 hour, the initialized net-\nwork could achieve better convergence, and its convergence\nprocess appeared to be more stable, especially in the ﬁrst\n4500 cycles.\nVI. CONCLUSION\nIn order to address the ‘‘time-shift’’ error in the oil chro-\nmatography for the power transformer state prediction,\nthe present research proposed a DRBN model. This paper\nconcludes that:\n1) Oil chromatography data prediction involves multidi-\nmensional time-series. However, the DBN modeling process\ndoes not contain time dimension pathways, and hence the\ntime-domain correlation of oil chromatography data cannot\nbe expressed, which results in an obvious ‘‘time-shift’’ error.\n2) The proposed DRBN algorithm established a multidi-\nmensional time domain pathway based on the autocorrelation\nprinciple, reconstructed the error feedback network, added\nthe network initialization process, and eliminated the inac-\ncuracy of DBN in time-series prediction.\n3) Veriﬁcation tests in the ﬁeld showed, when the iteration\nnumber of training reached 100,000 times, the prediction\naccuracy could reach 99% and the ICCC could reach 0.95. The\nproposed transformer state prediction method based on the\nDRBN model had strong generalization performance, which\ncan provide a useful reference for transformer state prediction\nand fault prediction.\nREFERENCES\n[1] Y . Biçen, F. Aras, and H. Kirkici, ‘‘Lifetime estimation and monitoring of\npower transformer considering annual load factors,’’ IEEE Trans. Dielectr.\nElectr. Insul., vol. 21, no. 3, pp. 1360–1367, Jun. 2014.\n[2] H. B. Zheng, R. J. Liao, S. Grzybowski, and L. J. Yang, ‘‘Fault diagnosis of\npower transformers using multi-class least square support vector machines\nclassiﬁers with particle swarm optimisation,’’ IET Electr. Power Appl.,\nvol. 5, no. 9, pp. 691–696, Nov. 2011.\n[3] J. Dai, H. Song, G. Sheng, and X. Jiang, ‘‘Cleaning method for status moni-\ntoring data of power equipment based on stacked denoising autoencoders,’’\nIEEE Access, vol. 5, pp. 22863–22870, 2017.\n[4] M. Duval and A. dePabla, ‘‘Interpretation of gas-in-oil analysis using new\nIEC publication 60599 and IEC TC 10 databases,’’ IEEE Elect. Insul. Mag.,\nvol. 17, no. 2, pp. 31–41, Aug. 2001.\n[5] G. E. Hinton and R. R. Salakhutdinov, ‘‘Reducing the dimensionality of\ndata with neural networks,’’ Science, vol. 313, no. 5786, pp. 504–507,\n2006.\n[6] G. E. Hinton, S. Osindero, and Y .-W. Teh, ‘‘A fast learning algorithm for\ndeep belief nets,’’ Neural Comput., vol. 18, no. 7, pp. 1527–1554, 2006.\n[7] Z. Liang, G. Sun, H. Li, Z. Wei, H. Zang, Y . Zhou, and S. Chen, ‘‘Short-\nterm load forecasting based on VMD and PSO optimized deep belief\nnetwork,’’ (in Chinese), Power Syst. Technol., vol. 42, no. 2, pp. 598–606,\nFeb. 2018.\n[8] J. Dai, H. Song, G. Sheng, and X. Jiang, ‘‘Dissolved gas analysis of\ninsulating oil for power transformer fault diagnosis with deep belief net-\nwork,’’IEEE Trans. Dielectr. Electr. Insul., vol. 24, no. 5, pp. 2828–2835,\nOct. 2017.\n[9] E. T. Affonso, R. L. Rosa, and D. Z. Rodríguez, ‘‘Speech quality assess-\nment over lossy transmission channels using deep belief networks,’’ IEEE\nSignal Process. Lett., vol. 25, no. 1, pp. 70–74, Jan. 2018.\n[10] A. M. Shah and B. R. Bhalja, ‘‘Discrimination between internal faults\nand other disturbances in transformer using the support vector machine-\nbased protection scheme,’’ IEEE Trans. Power Del., vol. 28, no. 3,\npp. 1508–1515, Jul. 2013.\n[11] R. J. Liao, H. B. Zheng, S. Grzybowski, L. J. Yang, C. Tang, and\nY . Y . Zhang, ‘‘Fuzzy information granulated particle swarm optimisation-\nsupport vector machine regression for the trend forecasting of dissolved\ngases in oil-ﬁlled transformers,’’ IET Electr. Power Appl., vol. 5, no. 2,\npp. 230–237, Jan. 2011.\n[12] X. Tang, ‘‘Large-scale computing systems workload prediction using\nparallel improved LSTM neural network,’’ IEEE Access, vol. 7,\npp. 40525–40533, Mar. 2019.\n[13] Z. Zhang, Y . Sun, and Z. Wang, ‘‘A new Stlf approach based on the fusion\nof optimal neighbor points in phase space and the recursive neural net-\nwork,’’Proc.-Chin. Soc. Elect. Eng., vol. 23, no. 8, pp. 45–50, May 2003.\n[14] H. Shi, M. Xu, and R. Li, ‘‘Deep learning for household load forecasting–\nA novel pooling deep RNN,’’ IEEE Trans. Smart Grid, vol. 9, no. 5,\npp. 5271–5280, Sep. 2018.\n[15] B. Qi, P. Zhang, Z. Rong, C. Li, Y . Yang, and Y . Chen, ‘‘Optimal length\nselection method of DGA data based on phase space reconstruction,’’ (in\nChinese), Proc. CSEE, vol. 8, no. 2, pp. 2504–2512, Aug. 2018.\n[16] J. Jiang, Z. Wen, M. Zhao, Y . Bie, C. Li, M. Tan, and C. Zhang,\n‘‘Series arc detection and complex load recognition based on principal\ncomponent analysis and support vector machine,’’ IEEE Access, vol. 7,\npp. 47221–47229, 2019.\n[17] C. L. P. Chen, C.-Y . Zhang, L. Chen, and M. Gan, ‘‘Fuzzy restricted\nBoltzmann machine for the enhancement of deep learning,’’ IEEE Trans.\nFuzzy Syst., vol. 23, no. 6, pp. 2163–2173, Dec. 2015.\n[18] H. Larochelle, and Y . Bengio, ‘‘Classiﬁcation using discriminative\nrestricted Boltzmann machines,’’ in Proc. 25th Int. Conf. Mach. Learn.,\nSantander, Cantabria, Spain, 2008, pp. 536–543.\n[19] Q. He, J. Si, and D. J. Tylavsky, ‘‘Prediction of top-oil temperature for\ntransformers using neural networks,’’ IEEE Trans. Power Del., vol. 15,\nno. 4, pp. 1205–1211, Oct. 2000.\n[20] D. C. Cavalieri, S. E. Palazuelos-Cagigas, T. F. Bastos-Filho, and\nM. Sarcinelli-Filho, ‘‘Combination of language models for word predic-\ntion: An exponential approach,’’ IEEE/ACM Trans. Audio, Speech, Lan-\nguage Process., vol. 24, no. 9, pp. 1481–1494, Sep. 2016.\n[21] I. H. Woodhouse, ‘‘The ratio of the arithmetic to the geometric mean:\nA cross-entropy interpretation,’’ IEEE Trans. Geosci. Remote Sens.,\nvol. 39, no. 1, pp. 188–189, Jan. 2001.\n[22] R. Machlev, Y . Levron, and Y . Beck, ‘‘Modiﬁed cross-entropy method for\nclassiﬁcation of events in NILM system,’’ IEEE Trans. Smart Grid, to be\npublished.\n[23] B. Qi, P. Zhang, and R. Xu, ‘‘Calculation method on differentiated warning\nvalue of power transformer based on distribution model,’’ High Voltage\nEng., vol. 42, no. 7, pp. 2290–2298, Jul. 2016.\n[24] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang,\nA. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton, Y . Chen, T. Lillicrap,\nF. Hui, L. Sifre, G. van den Driessche, T. Graepel, and D. Hassabis,\n‘‘Mastering the game of go without human knowledge,’’ Nature, vol. 550,\nno. 7676, pp. 354–359, 2017.\nVOLUME 7, 2019 80077\nB. Qiet al.: Novel DRBN Model for Trend Prediction of Transformer DGA Data\nBO QI (M’12) was born in Shandong, China,\nin 1980. He received the B.S. degree in electrical\nengineering, the M.S. degree in high voltage and\ninsulation, and the Ph.D. degree in high voltage\nand insulation from North China Electric Power\nUniversity, in 2003, 2006, and 2010, respectively,\nwhere he is currently an Associate Professor with\nthe School of Electric and Electronic Engineering.\nHis current research interest includes condition\nmonitoring of power apparatus.\nYIMING WANG was born in Liaoning, China,\nin 1994. He received the B.S. degree in electric\nand electronic engineering from the Shanghai Uni-\nversity of Electric Power. He is currently pursuing\nthe master’s degree with the School of Electric\nand Electronic Engineering, North China Electric\nPower University. His current research interest\nincludes condition monitoring of power apparatus.\nPENG ZHANG was born in Jiangsu, China,\nin 1990. He received the B.S. degree in informa-\ntion and computing science from Northeast Power\nUniversity. He is currently pursuing the Ph.D.\ndegree with the School of Electric and Electronic\nEngineering, North China Electric Power Univer-\nsity. His current research interest includes condi-\ntion monitoring of power apparatus.\nCHENGRONG LI (SM’03) was born in Xi’an,\nChina, in 1957. He received the B.S. and M.S.\ndegrees in electrical engineering from North China\nElectric Power University (NCEPU), in 1982 and\n1984, respectively, and the Ph.D. degree in electri-\ncal engineering from Tsinghua University, in 1989.\nIn 1992, he joined the University of South Car-\nolina, USA, as a Postdoctoral Research Fellow.\nIn 1995, he joined NCEPU, where he is currently a\nProfessor with the Department of Electrical Engi-\nneering. His current research interests include gas discharge, electrical insu-\nlation and materials, and condition monitoring of power apparatus.\nHONGBIN WANG, photograph and biography not available at the time of\npublication.\n80078 VOLUME 7, 2019",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6442495584487915
    },
    {
      "name": "Transformer",
      "score": 0.5403014421463013
    },
    {
      "name": "Data modeling",
      "score": 0.4914017915725708
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4288908541202545
    },
    {
      "name": "Machine learning",
      "score": 0.32240909337997437
    },
    {
      "name": "Engineering",
      "score": 0.09191888570785522
    },
    {
      "name": "Electrical engineering",
      "score": 0.07091692090034485
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Database",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I153473198",
      "name": "North China Electric Power University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I74872605",
      "name": "China Southern Power Grid (China)",
      "country": "CN"
    }
  ]
}