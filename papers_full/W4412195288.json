{
  "title": "Synthetic Patient–Physician Conversations Simulated by Large Language Models: A Multi-Dimensional Evaluation",
  "url": "https://openalex.org/W4412195288",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2181606656",
      "name": "Syed Ali Haider",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A5113380855",
      "name": "Srinivasagam Prabha",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": null,
      "name": "Cesar Abraham Gomez-Cabello",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2996112792",
      "name": "Sahar Borna",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A3124939960",
      "name": "Ariana Genovese",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A3193997096",
      "name": "Maissa Trabilsy",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": null,
      "name": "Bernardo G. Collaco",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A5059276975",
      "name": "Nadia G. Wood",
      "affiliations": [
        "Mayo Clinic in Arizona"
      ]
    },
    {
      "id": "https://openalex.org/A2274935649",
      "name": "Sanjay Bagaria",
      "affiliations": [
        "Jacksonville College"
      ]
    },
    {
      "id": "https://openalex.org/A2137772693",
      "name": "Cui Tao",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A4208346536",
      "name": "Antonio Jorge Forte",
      "affiliations": [
        "Mayo Clinic",
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2181606656",
      "name": "Syed Ali Haider",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A5113380855",
      "name": "Srinivasagam Prabha",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": null,
      "name": "Cesar Abraham Gomez-Cabello",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2996112792",
      "name": "Sahar Borna",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A3124939960",
      "name": "Ariana Genovese",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A3193997096",
      "name": "Maissa Trabilsy",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": null,
      "name": "Bernardo G. Collaco",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A5059276975",
      "name": "Nadia G. Wood",
      "affiliations": [
        "Mayo Clinic in Arizona"
      ]
    },
    {
      "id": "https://openalex.org/A2274935649",
      "name": "Sanjay Bagaria",
      "affiliations": [
        "Jacksonville College"
      ]
    },
    {
      "id": "https://openalex.org/A2137772693",
      "name": "Cui Tao",
      "affiliations": [
        "Mayo Clinic in Florida"
      ]
    },
    {
      "id": "https://openalex.org/A4208346536",
      "name": "Antonio Jorge Forte",
      "affiliations": [
        "Mayo Clinic in Florida",
        "Mayo Clinic"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1827163378",
    "https://openalex.org/W4400348041",
    "https://openalex.org/W2980195833",
    "https://openalex.org/W4409283601",
    "https://openalex.org/W4404070391",
    "https://openalex.org/W47871192",
    "https://openalex.org/W6866460623",
    "https://openalex.org/W4308548596",
    "https://openalex.org/W4322499862",
    "https://openalex.org/W4400438459",
    "https://openalex.org/W4285090325",
    "https://openalex.org/W4387457231",
    "https://openalex.org/W4396738182",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W4406327404",
    "https://openalex.org/W4405995927",
    "https://openalex.org/W4403789625",
    "https://openalex.org/W4407853749",
    "https://openalex.org/W3195967506",
    "https://openalex.org/W4410343193",
    "https://openalex.org/W6775037036",
    "https://openalex.org/W4406210587",
    "https://openalex.org/W2012633225",
    "https://openalex.org/W4403283816",
    "https://openalex.org/W2274499216",
    "https://openalex.org/W4389577325",
    "https://openalex.org/W4404642707",
    "https://openalex.org/W4386082956",
    "https://openalex.org/W6872166645",
    "https://openalex.org/W4406986127",
    "https://openalex.org/W4386714656",
    "https://openalex.org/W3112357189",
    "https://openalex.org/W2019206074",
    "https://openalex.org/W2093526229",
    "https://openalex.org/W2046675378",
    "https://openalex.org/W6693919207",
    "https://openalex.org/W4297103182",
    "https://openalex.org/W4366082964",
    "https://openalex.org/W4406887664",
    "https://openalex.org/W4405515374",
    "https://openalex.org/W4404869895",
    "https://openalex.org/W4398223047",
    "https://openalex.org/W6872892287",
    "https://openalex.org/W4399462810",
    "https://openalex.org/W4400409409",
    "https://openalex.org/W6872915513",
    "https://openalex.org/W4407426547",
    "https://openalex.org/W4312126456",
    "https://openalex.org/W2963133359",
    "https://openalex.org/W4403001844",
    "https://openalex.org/W4387538627",
    "https://openalex.org/W4390880284",
    "https://openalex.org/W4408474238",
    "https://openalex.org/W4403220723",
    "https://openalex.org/W4394999741",
    "https://openalex.org/W3013023334",
    "https://openalex.org/W4403535933",
    "https://openalex.org/W4402150025",
    "https://openalex.org/W4396667204"
  ],
  "abstract": "Background: Data accessibility remains a significant barrier in healthcare AI due to privacy constraints and logistical challenges. Synthetic data, which mimics real patient information while remaining both realistic and non-identifiable, offers a promising solution. Large Language Models (LLMs) create new opportunities to generate high-fidelity clinical conversations between patients and physicians. However, the value of this synthetic data depends on careful evaluation of its realism, accuracy, and practical relevance. Objective: To assess the performance of four leading LLMs: ChatGPT 4.5, ChatGPT 4o, Claude 3.7 Sonnet, and Gemini Pro 2.5 in generating synthetic transcripts of patient–physician interactions in plastic surgery scenarios. Methods: Each model generated transcripts for ten plastic surgery scenarios. Transcripts were independently evaluated by three clinically trained raters using a seven-criterion rubric: Medical Accuracy, Realism, Persona Consistency, Fidelity, Empathy, Relevancy, and Usability. Raters were blinded to the model identity to reduce bias. Each was rated on a 5-point Likert scale, yielding 840 total evaluations. Descriptive statistics were computed, and a two-way repeated measures ANOVA was used to test for differences across models and metrics. In addition, transcripts were analyzed using automated linguistic and content-based metrics. Results: All models achieved strong performance, with mean ratings exceeding 4.5 across all criteria. Gemini 2.5 Pro received mean scores (5.00 ± 0.00) in Medical Accuracy, Realism, Persona Consistency, Relevancy, and Usability. Claude 3.7 Sonnet matched the scores in Persona Consistency and Relevancy and led in Empathy (4.96 ± 0.18). ChatGPT 4.5 also achieved perfect scores in Relevancy, with high scores in Empathy (4.93 ± 0.25) and Usability (4.96 ± 0.18). ChatGPT 4o demonstrated consistently strong but slightly lower performance across most dimensions. ANOVA revealed no statistically significant differences across models (F(3, 6) = 0.85, p = 0.52). Automated analysis showed substantial variation in transcript length, style, and content richness: Gemini 2.5 Pro generated the longest and most emotionally expressive dialogues, while ChatGPT 4o produced the shortest and most concise outputs. Conclusions: Leading LLMs can generate medically accurate, emotionally appropriate synthetic dialogues suitable for educational and research use. Despite high performance, demographic homogeneity in generated patients highlights the need for improved diversity and bias mitigation in model outputs. These findings support the cautious, context-aware integration of LLM-generated dialogues into medical training, simulation, and research.",
  "full_text": null,
  "topic": "Usability",
  "concepts": [
    {
      "name": "Usability",
      "score": 0.6991254091262817
    },
    {
      "name": "Likert scale",
      "score": 0.5420495271682739
    },
    {
      "name": "Persona",
      "score": 0.5342715382575989
    },
    {
      "name": "Consistency (knowledge bases)",
      "score": 0.5278071165084839
    },
    {
      "name": "Rubric",
      "score": 0.5090662837028503
    },
    {
      "name": "Computer science",
      "score": 0.5061129927635193
    },
    {
      "name": "Empathy",
      "score": 0.5025744438171387
    },
    {
      "name": "Psychology",
      "score": 0.4396214187145233
    },
    {
      "name": "Natural language processing",
      "score": 0.4312066435813904
    },
    {
      "name": "Narrative",
      "score": 0.4145446717739105
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3710785508155823
    },
    {
      "name": "Social psychology",
      "score": 0.2584036588668823
    },
    {
      "name": "Human–computer interaction",
      "score": 0.2160826027393341
    },
    {
      "name": "Linguistics",
      "score": 0.15728193521499634
    },
    {
      "name": "Mathematics education",
      "score": 0.13609951734542847
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Developmental psychology",
      "score": 0.0
    }
  ]
}