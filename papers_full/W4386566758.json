{
  "title": "Multilingual Normalization of Temporal Expressions with Masked Language Models",
  "url": "https://openalex.org/W4386566758",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5052583514",
      "name": "Lukas Lange",
      "affiliations": [
        "Robert Bosch (Germany)"
      ]
    },
    {
      "id": "https://openalex.org/A5066026428",
      "name": "Jannik Strötgen",
      "affiliations": [
        "Robert Bosch (Germany)"
      ]
    },
    {
      "id": "https://openalex.org/A5055589412",
      "name": "Heike Adel",
      "affiliations": [
        "Robert Bosch (Germany)"
      ]
    },
    {
      "id": "https://openalex.org/A5008875255",
      "name": "Dietrich Klakow",
      "affiliations": [
        "Saarland University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2294517764",
    "https://openalex.org/W2251066042",
    "https://openalex.org/W2973088264",
    "https://openalex.org/W2567922298",
    "https://openalex.org/W2148559593",
    "https://openalex.org/W2252081637",
    "https://openalex.org/W2964114970",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3091432621",
    "https://openalex.org/W2251758222",
    "https://openalex.org/W4297234531",
    "https://openalex.org/W2811433702",
    "https://openalex.org/W2147923392",
    "https://openalex.org/W3168656614",
    "https://openalex.org/W2250269617",
    "https://openalex.org/W2007451316",
    "https://openalex.org/W2171857887",
    "https://openalex.org/W3024417166",
    "https://openalex.org/W2250299334",
    "https://openalex.org/W3037223009",
    "https://openalex.org/W2147880316",
    "https://openalex.org/W3204621313",
    "https://openalex.org/W4309811444",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W1893213668",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3009017276",
    "https://openalex.org/W2572068829"
  ],
  "abstract": "The detection and normalization of temporal expressions is an important task and preprocessing step for many applications. However, prior work on normalization is rule-based, which severely limits the applicability in real-world multilingual settings, due to the costly creation of new rules. We propose a novel neural method for normalizing temporal expressions based on masked language modeling. Our multilingual method outperforms prior rule-based systems in many languages, and in particular, for low-resource languages with performance improvements of up to 33 F1 on average compared to the state of the art.",
  "full_text": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 1174–1186\nMay 2-6, 2023 ©2023 Association for Computational Linguistics\nMultilingual Normalization of Temporal Expressions\nwith Masked Language Models\nLukas Lange1 Jannik Strötgen1\n1 Bosch Center for Artiﬁcial Intelligence, Renningen, Germany\n2 Spoken Language Systems (LSV), Saarland University, Saarbrücken, Germany\n{Lukas.Lange,Jannik.Stroetgen,Heike.Adel}@de.bosch.com\ndietrich.klakow@lsv.uni-saarland.de\nHeike Adel1 Dietrich Klakow2\nAbstract\nThe detection and normalization of temporal\nexpressions is an important task and prepro-\ncessing step for many applications. However,\nprior work on normalization is rule-based,\nwhich severely limits the applicability in real-\nworld multilingual settings, due to the costly\ncreation of new rules. We propose a novel\nneural method for normalizing temporal ex-\npressions based on masked language model-\ning. Our multilingual method outperforms\nprior rule-based systems in many languages,\nand in particular, for low-resource languages\nwith performance improvements of up to 33\nF1 on average compared to the state of the art.\n1 Introduction\nTemporal tagging consists of the extraction of\ntemporal expressions (TE) from texts and their\nnormalization to a standard format (e.g., May\n’22: 2022-05). While there are deep-learning ap-\nproaches for the extraction, temporal tagging as a\nwhole is usually solved with highly speciﬁc rule-\nbased systems, such as SUTime (Chang and Man-\nning, 2012) or HeidelTime (Strötgen and Gertz,\n2013). However, transferring rule-based methods\nto new languages or text domains requires a large\nmanual effort to create rules speciﬁc to the target\nlanguage. Although work on the automatic gen-\neration of rules for many languages (Strötgen and\nGertz, 2015) exists, the rule quality typically does\nnot match the high accuracy of hand-crafted rules.\nIn contrast to rule-based systems, neural net-\nworks are known for their ability to generalize to\nnew targets, in particular, for cross- and multilin-\ngual applications (Rahimi et al., 2019; Artetxe and\nSchwenk, 2019). In the context of temporal tag-\nging, recent works have shown promising results\nof neural networks for TE extraction in monolin-\ngual (Laparra et al., 2018) and multilingual settings\n(Lange et al., 2020) where a single neural model is\ntrained on many languages at once. However, TE\n... appear in <TIMEX3 type=\"DATE\" value=MASK>May</TIMEX3>.\nCIR: UNDEF-year-05\nSlots: ... \nThe Eta Auariids meteor shower will appear in May .\n(1) Extraction\n(2) Normalization to CIRUNDEF-\nyear 05P AD P AD \n(3) Anchoring\nAnchor:  2022-03-15 FUTURE2022-05\nP AD with MLM\nmodel\nFigure 1: Overview of our 3-step pipeline for tempo-\nral tagging consisting of extraction of temporal expres-\nsions (step 1), normalization to a context-independent\nrepresentation (CIR) using a slot-based masked lan-\nguage model (step 2) and anchoring given a reference\ntime and further contextual cues (step 3).\nnormalization remains challenging, and no solution\nfor the normalization across languages exists yet.\nWe propose a new multilingual normalization\nmethod which can make use of labeled data from\nmany languages by training a neural transformer\nmodel with a masked language modeling (MLM)\nobjective. Thus, we adopt the MLM objective func-\ntion for a new purpose: TE normalization.\nTo the best of our knowledge, this is the ﬁrst\nwork that uses neural networks for TE normaliza-\ntion. For this, as shown in Figure 1 and detailed\nbelow, we split the normalization task into two\nsteps: normalization to a context-independent rep-\nresentation (CIR) and anchoring this representation\nusing the document context.\nThe main contribution of this paper is our novel\nneural normalization method based on masked lan-\nguage modeling. For this, we create a large-scale\nmultilingual dataset with weakly-supervised anno-\ntations of TEs and their normalized values in 87\nlanguages. Our extensive set of experiments across\n17 languages demonstrates that our multilingual\nmethod robustly works for many languages and\noutperforms the state of the art for multilingual\ntemporal tagging, HeidelTime (Strötgen and Gertz,\n2015), especially for low-resource languages by\n1174\nmore than 33 F1 on average. Further, we explore\ndifferent training and decoding strategies for our\nmodel. The code for our models and the weakly-\nsupervised data is publicly available.1\n2 Related Work\nTE Normalization. Besides rule-based systems\n(Chang and Manning, 2012; Strötgen and Gertz,\n2013), one normalization method for TEs are\ncontext-free grammars (Bethard, 2013; Lee et al.,\n2014) which are independent of the extraction\nmethod. However, they are even more language-\nspeciﬁc than rule-based systems and hardly gen-\neralizable to new languages. Laparra et al. (2018)\nused a rule-based procedure for English TE nor-\nmalization based on the SCATE format proposed\nby Bethard and Parker (2016). While their method\ncould be extended to multilingual applications, no\nannotated data for other languages is available in\nthe SCATE format, and it is mostly incompatible\nwith the predominant TimeML (Pustejovsky et al.,\n2005) annotation format. Therefore, we will focus\non the TimeML format in this work and present the\nﬁrst neural approach to TE normalization.\nMasked Language Modeling (MLM). The\nMLM paradigm gains a lot of attention (Sun\net al., 2021) due to popular language models like\nBERT (Devlin et al., 2019) This leads to active re-\nsearch on using MLM to solve further tasks like\ntext classiﬁcation (Brown et al., 2020), named en-\ntity recognition (Ma et al., 2021) and relation ex-\ntraction (Han et al., 2021), also in low-resource\nlanguages (Hedderich et al., 2021). In this work,\nwe adopt it to TE normalization for the ﬁrst time.\n3 Background on Temporal Tagging\nTemporal tagging addresses the detection, clas-\nsiﬁcation and normalization of temporal expres-\nsions in unstructured texts — often following the\nTimeML speciﬁcations (Pustejovsky et al., 2005).\nTimeML’s most important attributes are type\n(the class of an expression, e.g., DATE, TIME , DU-\nRATION or SET), and value (the normalized mean-\ning of an expression, e.g., YYYY-MM-DD for speciﬁc\ndays, such as 2022-05-01 for May 1, 2022). While\nsome TEs contain all necessary information for the\nnormalization, e.g., “May 1, 2022”, many expres-\nsions are incomplete w.r.t. the temporal informa-\ntion required for a normalization. An example is a\n1https://github.com/boschresearch/\ntemporal-tagging-eacl\nrelative expressionlike “yesterday” which needs an\nanchor point. Given the anchor point May 1, 2022,\nfor example from the document creation time, “yes-\nterday” should be annotated with type=DATE and\nvalue=2022-04-30.\nDetermining the anchor point can be challeng-\ning as it requires additional context information\nthat could be given anywhere in the document.\nTherefore, systems for TE normalization, such as\nHeidelTime (Strötgen and Gertz, 2013), create an\nintermediate context-independent representation\n(CIR) of the value. In the syntax of HeidelTime,\nthe expression yesterday would result in a CIR of\nUNDEF-last-day. Similarly, an underspeciﬁed ex-\npression, such as “May” would be represented with\na CIR of UNDEF-year-05. Note that such a syntax\nfor CIRs is language-independent. See Appendix A\nfor more details. To determine the ﬁnal value, the\nCIR needs to be anchored given, e.g., a reference\ndate and further cues (such as tense information).\n4 Approach\nWe propose to approach multilingual temporal tag-\nging in three steps as shown in Figure 1: (1) Extrac-\ntion of temporal expressions and their types using\na multilingual sequence tagger; (2) Normalization\nof TEs to CIRs with our novel MLM-based nor-\nmalization model; (3) Anchoring of CIRs given a\nreference time, e.g., using HeidelTime rules.\nOur main contribution is a neural model for the\nsecond subtask, the normalization to a CIR. To the\nbest of our knowledge, this has not been addressed\nwith neural networks before. In this section, we\ndetail all components of our approach. Information\non the models that we apply for the ﬁrst and third\nsubtasks as well as an ablation study of directly\npredicting the normalized anchored value (without\nCIRs) are given in Section 5.\nMasked Language Modeling. We model the\ntask of assigning CIRs to temporal expressions\nas masked language modeling. In particular, we\nadd TimeML annotations as inline information\nto the text sequences and mask the value ﬁeld\nfor prediction, e.g., \"... <TIMEX3 type=\"DATE\"\nvalue=\"MASK\">yesterday</TIMEX3> ...\". Note\nthat those annotations could be the ground-truth an-\nnotations when applying the model on gold tempo-\nral expressions or predicted temporal expressions\nwhen using the model in the 3-step pipeline as\ndescribed above. In our experiments, we train a\ntransformer model for CIR prediction using the\n1175\nmasked language modeling (MLM) objective.\nSlot-Based Value Representation. Using only a\nsingle mask token for the whole CIR would require\nthe model to store all possible CIRs in its vocabu-\nlary. Since it is not possible to enumerate, i.a., all\npossible dates, we model the CIRs as a ﬁxed-length\nsequence of slots. In particular, we deﬁne 11 slots\nand use regular expressions to split the value ﬁeld\ninto slots in the training data. Figure 1 shows an\nexample for the CIR “UNDEF-year-05” that is rep-\nresented as the slots “ [PAD], [year], [05], [PAD],\n..., [PAD]”. Details on the slots and regular expres-\nsions are given in Appendix A. To cover the full\nvocabulary of CIRs, we introduce 200 new tokens\nto the vocabulary of the language model.2\nCurriculum Learning. Our slot-based represen-\ntation with 11 slots per CIR results in 11 masks. To\ntrain the model on this task, we apply curriculum\nlearning in the ﬁrst half of the training. In particu-\nlar, we start with masking only a single slot of the\nCIR and steadily increase the number of masks up\nto the maximum of 11. For the second half of the\ntraining, masking is applied to all slots. We follow\nDevlin et al. (2019) and mask different parts of\nthe input with different probabilities. In particular,\nwe mask the value slots with a probability of 70%,\nannotated tokens with 15%, types with 10% and\nother text parts with 5%.\nInference and Decoding. For inference, we ﬁrst\nadd 11 masks (i.e., one per slot) to the input sen-\ntence. They serve as value placeholders that need\nto be predicted. Then, we use the masked language\nmodel to predict the most probable sequence of\nslots for the CIR. To decode the sequence, we ap-\nply sequential left-to-right decoding of all masks by\niteratively decoding the left-most mask and replac-\ning the mask with its predicted value until all masks\nare resolved. We compare this to two alternative\ndecoding strategies: (i) decoding all masks simul-\ntaneously, (ii) training a conditional random ﬁeld\nmodel that takes the logits as input and uses the\nViterbi algorithm to determine the most probable\nsequence of predictions (Lafferty et al., 2001).\n5 Experiments\nThis section describes our experiments and dis-\ncusses the results. We compare our model to Hei-\ndelTime (Strötgen and Gertz, 2013), the current\n2In our experiments, we compare our pre-deﬁned slots to\nusing subtokens from the language model tokenizer.\nstate of the art for multilingual temporal tagging.\nFor evaluation, we use the TempEval3 evaluation\nscript (UzZaman et al., 2013) and report strict, re-\nlaxed and type F1 for the extraction and value F1\nfor our normalization experiments, respectively.\nEvaluation Data. Our models are evaluated on\ngold-standard corpora in 17 languages. Details on\nthe corpora are given in Appendix B.2. We divide\nthe languages into high- and low-resource depend-\ning on whether manually created HeidelTime rules\nare available for the respective language.\nTraining Data. For training the normalization\nmodel, we create a large-scale weakly-supervised\ndataset covering 87 languages.3 Reasons are that (i)\nexisting gold training data is too small to cover the\nwide range of different values and (ii) CIRs are not\npart of existing annotations. For all languages, we\ntake the data from GlobalV oices4 (news-style docu-\nments) and Wikipedia5 (narrative-style documents),\nuse spacy for tokenization and HeidelTime for the\nannotation with temporal expressions. The number\nand quality of annotations is highly dependent on\nthe amount of available data for that language and\nthe quality of HeidelTime’s rules. Details on the\nweakly-supervised data are given in Appendix B.1.\n3-Step Pipeline for Temporal Tagging. Both\nour temporal expression extraction and normaliza-\ntion models are based on the mulitlingual XLM-R\ntransformer (Conneau et al., 2020).6\nWe model the TE extraction as a sequence-\nlabeling problem following Lange et al. (2020). For\nthis, we convert the annotated corpora into the BIO\nformat. For the monolingual setting (Mono), we\ntrain one model per language on the gold-standard\nresources if available or the weakly-supervised data\notherwise. For the multilingual setting (Multi), we\ntrain a single model on the combined training re-\nsources of all languages.\nFor the normalization to CIRs, we train our pro-\nposed model with masked language modeling (see\nSection 4). In our experiments, we evaluate this\nmodel in combination with the multilingual extrac-\ntion model (Multi+OUR) as well as in combination\nwith the gold boundaries for temporal expressions\n(Gold+OUR) which serves as an upper bound.\n3The set of 87 languages is the intersection of languages\ncovered by HeidelTime, our data and the XLM-R language\nmodel that we use for initializing our models.\n4https://globalvoices.org/\n5https://wikipedia.org/\n6xlm-roberta-base with 270M parameters.\n1176\nHeidelTime Mono+O UR Multi+OUR Gold+OUR\nStr. Rel. Type Val. Str. Rel. Type Val. Str. Rel. Type Val. Val.\nde (N) 69.7 79.3 75.4 62.4 75.4 85.9 80.6 61.5 70.9 82.6 76.2 59.5 74.1\nde (W) 88.5 94.3 89.0 84.8 89.6 97.0 96.0 83.8 88.9 96.7 95.4 85.7 87.5\nen (N) 81.8 90.7 83.3 78.1 85.7 92.3 86.5 72.5 82.0 88.9 82.8 70.5 79.0\nen (W) 90.6 94.3 90.6 94.3 93.1 96.6 93.1 89.7 94.7 98.3 87.7 94.2 94.2\nes (N) 83.7 90.2 86.1 80.9 89.6 94.5 91.4 79.0 89.3 94.2 90.0 77.1 84.4\net (N) 42.4 57.4 51.3 44.0 3.3 28.0 24.4 9.6 55.5 78.0 72.0 45.2 64.8\nfr (N) 85.6 90.6 82.3 73.3 82.5 88.1 79.7 67.9 82.4 89.8 76.9 61.4 68.0\nhr (W) 93.3 95.8 94.6 85.7 84.1 90.8 89.5 74.6 86.3 91.7 90.1 75.7 84.7\nit (N) 84.4 92.9 83.5 74.1 69.8 81.4 73.7 60.4 76.8 82.4 78.4 67.2 75.3\nnl (N) 54.0 91.3 79.0 44.4 61.4 73.0 67.2 42.7 76.0 82.7 81.4 53.5 64.6\npt (N) 71.3 80.9 76.5 63.2 87.1 91.2 85.0 68.7 87.1 91.1 86.5 68.7 76.6\nvi (W) 92.6 89.5 96.6 91.6 87.6 85.0 89.8 83.5 91.5 93.8 92.6 90.8 91.2\navg. 78.2 87.3 82.4 75.6 75.8 83.7 79.7 66.2 81.8 89.2 84.2 70.7 78.7\nHeidelTime-auto Mono+O UR Multi+OUR Gold+OUR\nStr. Rel. Type Val. Str. Rel. Type Val. Str. Rel. Type Val. Val.\nca (N) 28.1 62.8 61.1 43.6 29.5 64.3 62.3 40.2 77.3 87.8 82.5 59.7 67.9\nel (W) 2.2 4.9 4.9 1.3 47.0 88.2 86.1 64.6 81.7 92.0 90.2 70.6 83.7\neu (N) 22.5 26.8 23.9 18.3 0.0 0.0 0.0 0.0 59.7 70.2 66.0 45.0 51.2\nid (N) 19.7 54.7 44.5 40.1 17.4 39.7 30.6 25.6 49.7 79.5 63.9 46.9 64.8\npl (N) 18.8 27.2 16.5 11.2 86.1 92.5 87.6 58.7 86.7 92.2 87.7 59.0 66.0\nro (N) 3.2 19.5 16.7 5.5 3.8 22.6 37.0 7.7 9.8 47.2 39.1 19.7 54.6\nua (W) 1.6 2.8 2.2 1.2 80.2 90.6 87.5 63.6 79.4 90.7 88.8 65.4 74.5\navg. 12.7 28.4 24.3 17.3 37.7 56.8 55.9 37.2 63.5 79.9 74.0 50.9 66.1\nTable 1: Detailed overview of our results for extraction (Str., Rel., Typ.) and normalization (Val.) per language for\nNews and Wiki domains. The upper and lower parts display high- and low-resource languages, respectively.\nFor anchoring CIRs, we use rules similar to Hei-\ndelTime’s rules.7 In particular, anchor dates can be\ngiven by the document creation time or by previous\ntemporal expressions (Strötgen and Gertz, 2016).\nResults. Table 1 gives an overview of our ex-\nperimental results. Multilingual extraction outper-\nforms monolingual extraction, probably because\nthe model is able to use knowledge from different\nlanguages. Our multilingual model achieves +2\nF1 for high-resource and +51 F1 for low-resource\nlanguages compared to HeidelTime.\nThe normalization results are given in the Val.\ncolumns of Table 1. Our masked language model\nis matching HeidelTime’s performance rather close\nfor high-resource languages and outperforms it for\nlow-resource languages with an increase of 33 F1\npoints on average with our multilingual extraction\nmodel. Note that our models are multilingual, thus,\nwe can use the same model for all languages.8 The\nupper bound of using gold extractions (Gold+OUR)\n7More precisely, we use a slightly modiﬁed version of\nHeidelTime’sSPECIFY AMBIGUOUS VALUES STRING function\nwhich incorporates tense information of the context using mor-\nphological features from spacy (https://spacy.io/usage/\nlinguistic-features#morphology).\n8Since we actually train the MLM model on 87 languages,\nwe could even apply it to more languages if there were gold-\nstandard evaluation datasets publicly available.\nshows that the extraction part still offers room for\nfuture improvements.\nNote that HeidelTime with automatically cre-\nated rules has a poor performance for some low-\nresource languages (el, ro, ua). This is similar\nto the observations by Grabar and Hamon (2019)\nwho found that “[e]xploitation of this automatically\nbuilt system produced no results when applied to\nthe Ukrainian data.” For those languages, the auto-\nmatic rule generation is not good enough in prac-\ntice which emphasizes the need for multilingual\nsystems like our model.\nAblation Studies. As our proposed model con-\nsists of multiple components, we now investigate\ntheir individual effects in more detail. The results\nfor our ablation studies are given in Table 2.\nFirst, we test different decoding strategies as\ndescribed in Section 4. We ﬁnd that sequential de-\ncoding works best. However, it also requires more\ncomputation time. A cheaper alternative with only\nminor performance decreases is the simultaneous\ndecoding of all masks.\nSecond, we analyze the impact of differentvalue\nrepresentations by comparing our proposed ap-\nproach with CIR and slot tokenization to (i) to-\nkenization of values using the standard XLM-R\n1177\ntokenizer instead of pre-deﬁned slots (w/o OUR\nSlots), and (ii) training a model to directly predict\nthe anchored value without CIRs in between (w/o\nOUR CIR). For (i), we ﬁnd that our slot method has\nmajor advantages when processing narrative texts,\nsuch as Wikipedia, due to the higher amount of\nrelative expressions (cf., Table 3 in Appendix B.3),\nthat are tokenized into many subtokens (up to 34,\ninstead of 11 when using our slots). For (ii), we\nadd the document creation time to the input so that\nthe model has more temporal information to predict\nthe fully normalized value directly instead of a CIR.\nHowever, we ﬁnd that current transformers are not\nable to correctly incorporate this information in a\ncombined normalizing+anchoring step and mostly\npredict a memorized, incorrect value. Thus, using\nCIRs as an intermediate step is important for neural\ntemporal tagging.\nThird, we investigate the training strategy and\ntraining data . Our curriculum learning has ad-\nvantages for low-resource languages as it reduces\nthe training complexity which helps for the difﬁ-\ncult adaptation to languages with few resources.\nWeakly-supervised training data is required, as the\namount of gold-standard data is too small to train\nthe MLM model. Finetuning the trained MLM\nmodel further on gold data (Weak+Gold) decreases\nperformance slightly. Training the model on mono-\nlingual data only also decreases performance, high-\nlighting the prospects of our multilingual approach.\nFinally, we compare our models to an encoder-\ndecoder model , i.e., an autoregressive language\nmodel that we adapt to TE normalization. For this,\nwe follow the entity linking approach from De Cao\net al. (2021) and train a BART encoder-decoder\nmodel (Lewis et al., 2020) for constrained decod-\ning against a subspace of normalized TEs with\nour weakly-supervised data. We add the document\ncreation time to the input, mark the extracted an-\nnotations and keep other TEs in the context, as in\nour other experiments. Given the gigantic amount\nof possible temporal expressions, e.g., there are\nroughly 32M seconds in a single year, we have to\nprune the search space to a reasonable size. Thus,\nwe do not use time expressions of hour and smaller\ngranularities and restrict the search space to years\nand months from 1 AD to 2100. Finer elements like\nweeks, days and daytimes are added for years be-\ntween 2000 and 2026. We use durations for all de-\nﬁned units with numbers up to 10,000, e.g., 10,000\ndays. With this, we prune the search space to 1.4B\nNews Wiki Low-R.\nde en de en ca eu\nOUR 74.1 79.0 87.5 94.2 67.9 51.2\nDecoding Strategy (OUR uses Sequential)\nw/ Simultaneous 73.3 78.3 87.5 93.5 68.1 50.4\nw/ Viterbi 73.3 78.3 87.5 94.2 67.9 50.4\nValue Representation\nw/o OUR Slots 71.9 77.9 83.3 92.8 63.7 27.8\nw/o OUR CIR 68.5 68.0 66.5 55.7 41.6 21.2\nTraining Strategy\nw/o Curriculum 72.1 80.4 85.5 94.4 64.7 29.3\nTraining Data (OUR uses Weak)\nWeak + Gold 68.3 76.1 58.2 93.3 - -\nonly Gold 14.2 13.8 6.7 3.6 - -\nonly Monolingual 63.1 76.8 86.8 91.4 29.2 8.9\nEncoder-Decoder Model\nMonolingual 59.3 67.4 49.4 59.6 2.2 7.3\nMultilingual 63.5 63.0 49.0 58.5 54.8 25.2\nTable 2: Ablation study for our model components\n(Value F1) on gold extractions. Low-R. stands for low-\nresource languages without gold training data.\nterms which we store in a preﬁx tree. This re-\nsults in an acceptable inference speed with BEAM\nsearch (5 beams). It takes roughly twice as long\nas our sequential MLM decoding. Note that this\nBART model has more parameters (400M) than\nthe base version of XLM-R (270M) that we use in\nour model. The results are shown in the lower part\nof Table 2. We see, that our proposed MLM nor-\nmalization model outperforms the BART model by\na large margin. Nonetheless, the encoder-decoder\nmodel performs comparable to our model variant\nthat directly predicts fully-normalized expressions.\nThis clearly highlights the need for normalizing to\nCIRs before anchoring temporal expressions.\n6 Conclusion\nIn this paper, we introduced a new method for nor-\nmalizing temporal expressions based on masked\nlanguage modeling and a new slot-based predic-\ntion scheme of context-independent representa-\ntions. With this approach, we were able to train a\nsingle multilingual model for the task. We evalu-\nated our method in 17 languages and set the new\nstate of the art in low-resource languages with mas-\nsive improvements of 35F1 points on average. The\nsuccess of our method demonstrates the potential\nof neural networks for temporal normalization and\nwe are convinced that it will enable future research\non this topic. An interesting research direction is\nthe joint modeling of extraction and normalization.\n1178\nLimitations\nOur experiments are focused on Indo-European\nlanguages due to the lack of publicly available,\nlabeled data points in other languages. Excep-\ntions for which we could test zero-shot transfer\nwere Basque, Estonian, Indonesian and Vietnamese.\nEven though, our model is working for these lan-\nguages, it is not clear if the multilingual models\ntransfer to all languages seen in the pre-training or\nby our weak supervision. The training of the mul-\ntilingual models requires a considerable number\nof computational resources (up to 1.5 GPU days),\nwhich might not be available for all people/orga-\nnizations. By publishing our model, we hope to\nlower the barrier for this kind of research by provid-\ning a pre-trained starting point. An in-depth error\nanalysis to better understand which types of tem-\nporal expressions are well or less well covered in\nwhich language by our model was not performed.\nWe are full of hope that such analyses can be tack-\nled by users of our models who have the required\nlanguage skills so that the analysis does not have\nto be limited to English.\nAcknowledgments\nWe would like to thank the members of the BCAI\nNLP & NS-AI research group and the anonymous\nreviewers for their helpful comments.\nReferences\nBegoña Altuna, María Jesús Aranzabe, and Arantza\nDíaz de Ilarraza. 2020. Eustimeml: A mark-up lan-\nguage for temporal information in basque. Research\nin Corpus Linguistics, 8(1):86–104.\nMikel Artetxe and Holger Schwenk. 2019. Massively\nMultilingual Sentence Embeddings for Zero-Shot\nCross-Lingual Transfer and Beyond. Transactions\nof the Association for Computational Linguistics ,\n7:597–610.\nSteven Bethard. 2013. A synchronous context free\ngrammar for time normalization. In Proceedings of\nthe 2013 Conference on Empirical Methods in Nat-\nural Language Processing, pages 821–826, Seattle,\nWashington, USA. Association for Computational\nLinguistics.\nSteven Bethard and Jonathan Parker. 2016. A seman-\ntically compositional annotation scheme for time\nnormalization. In Proceedings of the Tenth Inter-\nnational Conference on Language Resources and\nEvaluation (LREC’16), pages 3779–3786, Portorož,\nSlovenia. European Language Resources Associa-\ntion (ELRA).\nAndré Bittar, Pascal Amsili, Pascal Denis, and Lau-\nrence Danlos. 2011. French TimeBank: An ISO-\nTimeML annotated reference corpus. In Proceed-\nings of the 49th Annual Meeting of the Associa-\ntion for Computational Linguistics: Human Lan-\nguage Technologies, pages 130–134, Portland, Ore-\ngon, USA. Association for Computational Linguis-\ntics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry,\nAmanda Askell, Sandhini Agarwal, Ariel Herbert-\nV oss, Gretchen Krueger, Tom Henighan, Rewon\nChild, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu,\nClemens Winter, Chris Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In\nAdvances in Neural Information Processing Systems,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nAngel X. Chang and Christopher Manning. 2012. SU-\nTime: A library for recognizing and normalizing\ntime expressions. In Proceedings of the Eighth In-\nternational Conference on Language Resources and\nEvaluation (LREC’12).\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nFrancisco Costa and António Branco. 2012. Time-\nBankPT: A TimeML annotated corpus of Por-\ntuguese. In Proceedings of the Eighth International\nConference on Language Resources and Evaluation\n(LREC’12), pages 3727–3734, Istanbul, Turkey. Eu-\nropean Language Resources Association (ELRA).\nNicola De Cao, Gautier Izacard, Sebastian Riedel, and\nFabio Petroni. 2021. Autoregressive entity retrieval.\nIn 9th International Conference on Learning Repre-\nsentations, ICLR 2021, Virtual Event, Austria, May\n3-7, 2021. OpenReview.net.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nCorina For˘ascu and Dan Tuﬁ¸ s. 2012. Romanian Time-\nBank: An annotated parallel corpus for temporal\n1179\ninformation. In Proceedings of the Eighth Inter-\nnational Conference on Language Resources and\nEvaluation (LREC’12), pages 3762–3766, Istanbul,\nTurkey. European Language Resources Association\n(ELRA).\nNatalia Grabar and Thierry Hamon. 2019. Wikiwars-\nua: Ukrainian corpus annotated with temporal ex-\npressions. Computational Linguistics and Intelli-\ngent Systems, 2:22–31.\nXu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu,\nand Maosong Sun. 2021. Ptr: Prompt tuning\nwith rules for text classiﬁcation. arXiv preprint\narXiv:2105.11259.\nMichael A. Hedderich, Lukas Lange, Heike Adel, Jan-\nnik Strötgen, and Dietrich Klakow. 2021. A survey\non recent approaches for natural language process-\ning in low-resource scenarios. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 2545–2568, On-\nline. Association for Computational Linguistics.\nEmmanouil I. Kapernaros. 2020. Extending the tempo-\nral tagger heideltime for the greek language.\nJan Kocon, Marcin Oleksy, Tomasz Bernas, and\nMichał Marcinczuk. 2019. Results of the poleval\n2019 shared task 1: Recognition and normalization\nof temporal expressions. Proceedings ofthePolE-\nval2019Workshop, page 9.\nJohn D. Lafferty, Andrew McCallum, and Fernando\nC. N. Pereira. 2001. Conditional random ﬁelds:\nProbabilistic models for segmenting and labeling se-\nquence data. In Proceedings of the Eighteenth Inter-\nnational Conference on Machine Learning , ICML\n’01, pages 282–289, San Francisco, CA, USA. Mor-\ngan Kaufmann Publishers Inc.\nLukas Lange, Anastasiia Iurshina, Heike Adel, and Jan-\nnik Strötgen. 2020. Adversarial alignment of multi-\nlingual models for extracting temporal expressions\nfrom text. In Proceedings of the 5th Workshop on\nRepresentation Learning for NLP , pages 103–109,\nOnline. Association for Computational Linguistics.\nEgoitz Laparra, Dongfang Xu, and Steven Bethard.\n2018. From characters to time intervals: New\nparadigms for evaluation and neural parsing of time\nnormalizations. Transactions of the Association for\nComputational Linguistics, 6.\nKenton Lee, Yoav Artzi, Jesse Dodge, and Luke Zettle-\nmoyer. 2014. Context-dependent semantic parsing\nfor time expressions. In Proceedings of the 52nd An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers).\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\n2020. BART: Denoising sequence-to-sequence pre-\ntraining for natural language generation, translation,\nand comprehension. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 7871–7880, Online. Association\nfor Computational Linguistics.\nRuotian Ma, Xin Zhou, Tao Gui, Yiding Tan,\nQi Zhang, and Xuanjing Huang. 2021. Template-\nfree prompt tuning for few-shot ner. arXiv preprint\narXiv:2109.13532.\nPawel Mazur and Robert Dale. 2010. WikiWars: A\nnew corpus for research on temporal expressions.\nIn Proceedings of the 2010 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n913–922, Cambridge, MA. Association for Compu-\ntational Linguistics.\nAnne-Lyse Minard, Manuela Speranza, Ruben Urizar,\nBegoña Altuna, Marieke van Erp, Anneleen Schoen,\nand Chantal van Son. 2016. MEANTIME, the\nNewsReader multilingual event and time corpus. In\nProceedings of the Tenth International Conference\non Language Resources and Evaluation (LREC’16),\npages 4417–4422, Portorož, Slovenia. European\nLanguage Resources Association (ELRA).\nParamita Mirza. 2016. Recognizing and normalizing\ntemporal expressions in indonesian texts. In Com-\nputational Linguistics , pages 135–147, Singapore.\nSpringer Singapore.\nSiim Orasmaa. 2014. Towards an integration of syn-\ntactic and temporal annotations in Estonian. In\nProceedings of the Ninth International Conference\non Language Resources and Evaluation (LREC’14),\npages 1259–1266, Reykjavik, Iceland. European\nLanguage Resources Association (ELRA).\nJames Pustejovsky, Robert Ingria, Roser Saurí, José\nCastaño, Jessica Littman, Rob Gaizauskas, Andrea\nSetzer, Graham Katz, and Inderjeet Mani. 2005. The\nspeciﬁcation language TimeML. In The language of\ntime: a reader , pages 545–557. Oxford University\nPress.\nAfshin Rahimi, Yuan Li, and Trevor Cohn. 2019. Mas-\nsively multilingual transfer for NER. In Proceed-\nings of the 57th Annual Meeting of the Association\nfor Computational Linguistics, pages 151–164, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nRoser Saurı. 2010. Annotating temporal relations in\ncatalan and spanish timeml annotation guidelines.\nTechnical report, Technical report, Technical Report\nBM 2010-04, Barcelona Media.\nLuka Skukan, Goran Glavaš, and Jan Šnajder. 2014.\nHeideltime. hr: extracting and normalizing tempo-\nral expressions in croatian. In Proceedings of the\n9th Slovenian Language Technologies Conferences\n(IS-LT 2014), pages 99–103.\nJannik Strötgen, Ayser Armiti, Tran Van Canh, Julian\nZell, and Michael Gertz. 2014. Time for more lan-\nguages: Temporal tagging of arabic, italian, spanish,\n1180\nand vietnamese. ACM Transactions on Asian Lan-\nguage Information Processing, 13(1).\nJannik Strötgen and Michael Gertz. 2011. Wikiwarsde:\nA german corpus of narratives annotated with tem-\nporal expressions. In Proceedings of the conference\nof the German society for computational linguistics\nand language technology (GSCL 2011), pages 129–\n134. Citeseer.\nJannik Strötgen and Michael Gertz. 2013. Multilingual\nand cross-domain temporal tagging. Language Re-\nsources and Evaluation, 47(2).\nJannik Strötgen and Michael Gertz. 2015. A baseline\ntemporal tagger for all languages. In Proceedings of\nthe 2015 Conference on Empirical Methods in Natu-\nral Language Processing.\nJannik Strötgen and Michael Gertz. 2016. Domain-\nsensitive temporal tagging , volume 9. Morgan &\nClaypool Publishers.\nJannik Strötgen, Anne-Lyse Minard, Lukas Lange,\nManuela Speranza, and Bernardo Magnini. 2018.\nKRAUTS: A German temporally annotated news\ncorpus. In Proceedings of the Eleventh International\nConference on Language Resources and Evaluation\n(LREC 2018), Miyazaki, Japan. European Language\nResources Association (ELRA).\nTianxiang Sun, Xiangyang Liu, Xipeng Qiu, and\nXuanjing Huang. 2021. Paradigm shift in\nnatural language processing. arXiv preprint\narXiv:2109.12575.\nNaushad UzZaman, Hector Llorens, Leon Derczyn-\nski, James Allen, Marc Verhagen, and James Puste-\njovsky. 2013. SemEval-2013 task 1: TempEval-3:\nEvaluating time expressions, events, and temporal\nrelations. In Second Joint Conference on Lexical\nand Computational Semantics (*SEM), Volume 2:\nProceedings of the Seventh International Workshop\non Semantic Evaluation (SemEval 2013) , pages 1–\n9, Atlanta, Georgia, USA. Association for Computa-\ntional Linguistics.\nA Slot Tokenization of CIRs\nIn this section, we describe our slot-based tok-\nenization of the context-independent representa-\ntion (CIR) of values as introduced in Section 3 and\nSection 4 of the main paper.\nA.1 Overview of Slots\nWe use the following 11 slots to represent CIRs\nvalues.9 These slots are then used for masking\nduring training and inference with our normaliza-\ntion model (which basically is a masked language\nmodel).\n9Note that our CIRs describe a superset of TimeML.\nSB: This slot can contain BC information of\nyears (e.g., as in BC4000 for the year 4000 BC) or\nthe duration markers P and PT. Moreover, mathe-\nmatical operations like PLUS are covered as used in\nrelative expression involving offset computations\n(e.g., this-day-plus-2 for the day after tomor-\nrow) and holiday names (EasterSunday).\nSD1, SD2: These slots are used to represent 4-\ndigit year numbers (SD1 = 20 and SD2 = 22 for the\nyear 2022) by splitting the 4-digit number into two\n2-digit numbers. This helps to generalize to unseen\nyears as fewer parameters have to be learned. In\naddition, we useSD1 to mark reference expressions\nlike PAST_REF. For underspecifed expressions like\nUNDEF-this-day, this is stored in SD1 and day\nin SD2. Moreover, SD1 and SD2 are used to store\nnumbers of DURATION expressions.\nSD3, SD4: Analogously to SD1 and SD2 that\nare used to store year information, SD3 is used for\nmonths and SD4 for days.\nST1, ST2, ST3: Temporal information from ex-\npressions of type TIME that are smaller than day\ngranularity are stored in the ST slots. For exam-\nple, the hour information of 24:00 and the daytime\ninformation, such as EV is stored in ST1. Informa-\ntion on minutes and seconds is stored in ST2 and\nST3, respectively. Moreover, these slots are used\nto cover additional units in durations, such as in\nP1D2H (1 day and 2 hours).\nSA1, SA2, SA3: Finally, some CIRs include\nfunction calls which can be augmented with ar-\nguments that we store in the SA slots. For example,\nthe argument 2 of this-day-plus-2 is stored in\nSA1. Other function calls are used to compute\ndays with respect to holidays like EaserSunday or\nspeciﬁc weekdays.\nNote that slots can be optional depending on the\ntemporal expression. For example, the value 2022\nrepresenting the year 2022 would only require SD1\nand SD2. All other slots are set to a padding value\n[PAD] then which allows a ﬁxed-sized representa-\ntions of CIRs that can be predicted with our masked\nlanguage model.\nExamples. The following examples show tempo-\nral expressions, their corresponding CIRs and the\ntokenization into our slots. Note that there is no\nneed to capture terms like UNDEF in our slots as\nthe presence of words like this, next or last in\na CIR implies the existence of UNDEF in the CIR.\n1181\nThis information can be reconstructed when obtain-\ning a CIR from our slots. This also includes -- to\nseparate numbers as in YYYY-MM-DD values, REF in\nreference expressions and T for time information.\nWe use the following format to give examples for\nour CIR conversion: Text →CIR →Slot Sequence\n• Now ...\n→ PRESENT_REF\n→ SD1=PRESENT\n• ... for 1000 days ...\n→ P1000D\n→ SB=P, SD1=10, SD2=00, SD4=D\n• ... for one and a half day ...\n→ P1D12H\n→ SB=P, SD1=1, SD4=D, ST1=12, ST2=H\n• ... in 1000 BC ...\n→ BC1000\n→ SB=BC, SD1=10, SD2=00\n• ... on the morning of March 15, 2022 ...\n→ 2022-03-15TMO\n→ SD1=20, SD2=22, SD3=03, SD4=15,\nST1=MO\n• On March 15, ...\n→ UNDEF-year-03-15\n→ SD1=year, SD3=03, SD4=15\n• ... the day after tomorrow ...\n→ UNDEF-this-day-PLUS-2\n→ SB=PLUS, SD1=this, SD2=day, SA1=2\n• ... at Pentecost10 ...\n→ UNDEF-year-00-00 funcDate ...\n...Calc(EasterSunday(YEAR, 49))\n→ SB=EasterSunday, SD1=year, SD2=00,\nSA1=49\nA.2 Regular expressions\nIn the following, we will describe the six regular ex-\npressions used to split CIR values from HeidelTime\noutputs into our slots for the weakly-supervised\ntraining data.\nNotation. For readability, we deﬁne the follow-\ning groups to capture temporal units and other\nﬁxed names. Note that these are used across lan-\nguages. For example, the German expression Mon-\ntag would still be represented with monday.\n10In christian communities, the holiday of Pentecost is cele-\nbrated 49 days after Easer Sunday.\nUNITS = (H|D|DE|DT|M|C|Y|\nC|CE|W|WE|Qu|Q|S)\nUNITS_F = ( day | month | year |\ndecade | century | week |\nweekend | quarter |\nhour | minute | second )\nDAYTIME = (NI|AF|MO|EV|MD|MI)\nSPECIAL = (SP|SU|FA|AU|WI|\nH1|H2|Q1|Q2|Q3|Q4|H|Q)\nNAMES = ( monday | tuesday |\nwednesday | thursday |\nfriday | saturday | sunday |\njanuary | february | march |\napril | may | june | july |\naugust | september |\noctober | november | december )\nIn the following, DX(n) marks the n-th group\ncaptured by the regular expression DX.\nD1: References. The ﬁrst regular expression D1\nis used to capture simple reference expressions that\nrefer to uncertain points in time.\nD1 = ( PRESENT | PAST | FUTURE ) _REF\nSlots : SD1=D1 (1)\nD2: Explicit Dates. The second regular expres-\nsion D2 detects explicit values that do not need fur-\nther normalization, such as days in theYYYY-DD-MM\nformat, e.g., 20222-03-15.\nD2 =( BC )?(\\ d\\d?| XX )?(\\ d\\d|XX )?\n(?: -( W )?(\\ d\\d?| XX| SPECIAL ))?\n(?: -(\\ d\\d?| XX|WE ))?\\)?\n(?: T(\\d\\d|X| DAYTIME |XX )?\n(?::(\\ d\\d ))?\n(?:(?::| -)(\\ d\\d ))?)?\nSlots : SB=D2 (1) , SD1=D2 (2) ,\nSD2=D2 (3) , SD3=D2 (5) , SD4=D2 (6) ,\nST1=D2 (7) , ST2=D2 (8) ,\nST3=D2 (9)| D2 (4)\nP1: Durations. The third regular expression\nP1 detects expressions of type DURATION , e.g.,\nP1D2H. These are deﬁned as P<number><unit>\nfor units of at least day granularity and\nPT<number><unit> for smaller granularities. We\ncapture up to two different units P1D2H (1 day and\n2 hours) but ignore further units that are theoreti-\ncally deﬁned in the TimeML speciﬁcations but do\nnot occur often in practice (in our datasets those\ndid not occur at all).\nP1 = (P|PT )(\\ d\\d?|X|XX)\n(\\d\\d |\\.)?(\\ d\\d ?)?)?( UNITS )?\n(\\d\\d ?)?( UNITS )?\nSlots : SB=P1 (1) , SD1=P1 (2) ,\nSD2=P1 (3) , SD3=P1 (4) , SD4=P1 (6) ,\nST1=P1 (5) , ST2=P1 (7)\n1182\nD3: Relative Dates. While the previous regular\nexpressions D1, D2 and P1 follow the TimeML\nspeciﬁcations and capture fully normalized expres-\nsions, i.e., anchored values, the following regular\nexpressions capture CIRs as used internally by Hei-\ndelTime. They represent relative expressions that\nneed to be anchored.\nD3 detects relative expressions with respect to\na certain point in time, such as this-day-plus-2\n(the day after tomorrow).\nD3 = UNDEF -( this | next | last | REF |\nREFUNIT | REFDATE )? -?\n( UNITS_F | SPECIAL )? -??\n( NAMES | SPECIAL )| XX |\\d\\d ?)?\n(?: -?(\\ d\\d?| XX ))?\n(?: -( PLUS | MINUS | LESS ) -(\\d\\d?) -?\n(\\d\\d ?)? -?(\\ d\\d ?)?)?\\)?\n(?: T(\\d\\d?|X| DAYTIME |XX )?\n(?::(\\ d\\d?| XX ))?(?:(?::| -)\n(\\d\\d|XX ))?)\nSlots : SB=D3 (5) , SD1=D3 (1) ,\nSD2=D3 (2) , SD3=D3 (3) , SD4=D3 (4) ,\nST1=D3 (9) , ST2=D3 (10) , ST3=D3 (11) ,\nSA1=D3 (6) , SA2=D3 (7) , SA3=D3 (8)\nD4: Relative Dates (coarse). D4 captures un-\nderspeciﬁed expressions like May that is missing\nyear information and would be represented with\nthe CIR UNDEF-year-05.\nD4 = UNDEF -( year | decade | century ?)\n-?(\\d\\d?|X )? -?(\\ d\\d?|X)? -?\n(\\d\\d?|X| SPECIAL )?\\)?\n(?: T(\\d\\d?|X| DAYTIME )?\n(?::(\\ d\\d?| XX ))?\n(?:(?::| -)(\\ d\\d|XX ))?)?\nSlots : SD1=D4 (1) , SD2=D4 (2) ,\nSD3=D4 (3) , SD4=D4 (4) ,\nST1=D4 (5) , ST2=D4 (6) , ST3=D4 (7)\nD5: Holidays and functions. Finally, D5 cov-\ners special functions used by HeidelTime. These\nfunctions are used to compute days with respect to\nweekdays and moveable feasts like EasterSunday\nthat refer to different days depending on the year.\nFor example, the earliest possible date of Easter\nSunday is March 22 and the latest is April 25 in\nthe Gregorian calendar.11 The concrete date is then\ncomputed by an external function given a year.12\nD5 = ( UNDEF - year | UNDEF -this - year |\nUNDEF - century \\d\\d|\\d\\d\\d\\d)-\n(\\d\\d) -00 funcDateCalc \\((\nWeekdayRelativeTo |\nEasterSundayOrthodox |\nEasterSunday |\n11https://en.wikipedia.org/wiki/List_of_dates_\nfor_Easter\n12https://www.linuxtopia.org/online_books/\nprogramming_books/python_programming/python_ch38.\nhtml\nShroveTideOrthodox )\n\\( YEAR (?:(?: -(\\ d\\d )))?\n(?: -(\\ d\\d))\n(?: ,\\ s ?( -?\\ d\\d ?))?\n(?: ,\\ s ?( -?\\ d\\d ?))?\n(?: , ( true | f a l s e))?\\)\\)\nSlots : SB=D5 (3) , SD1=D4 (1) ,\nSD2=D4 (2) , SD3=D4 (5) ,\nSD4=D4 (7) , ST1=D4 (3) ,\nSA1=D5 (6) , SA2=D5 (7) , SA3=D5 (8)\nB Data Statistics\nB.1 Weakly-Supervised Data\nAs detailed in Section 5, we create weakly-\nsupervised data to train our normalization model,\nas the gold standard is too small and is not an-\nnotated with CIRs which are required by our\nmethod. For all languages, we take the data\nfrom GlobalV oices13 (news-style documents) and\nWikipedia14 (narrative-style documents), use spacy\nfor tokenization and our HeidelTime version that\noutputs CIRs for the annotation with temporal ex-\npressions. The sizes of our weakly-supervised data\nfor each language are given in Table 4.\nB.2 Gold-Standard Data\nDetailed information on the datasets used in this\npaper (their languages, domains, sizes and refer-\nences) are provided in Table 5. Note that all corpora\ncome from the news domain except the WikiWars\ncorpora that are based on Wikipedia articles.\nB.3 Distribution of Explicit and Relative\nValues\nThe distribution of explicit and relative values has\na large impact on the normalization performance\nof different models, as shown in our ablation study\nin Section 5. Exemplarily, we analyze their dis-\ntribution in the German and English datasets for\nwhich we have data from two domains: News and\nWikipedia. The results are given in Table 3. We\nsee, that the Wikipedia corpora contain a much\nlarger percentage of relative values as these articles\noften follow a narrative structure (cf., (Strötgen and\nGertz, 2016).\nC A Note on Adopting HeidelTime\nIn our experiments, we used a modiﬁed version of\nHeidelTime. First, we implemented a new UIMA\ncollection reader based on spacy as an alternative to\n13https://globalvoices.org/\n14https://en.wikipedia.org/wiki/List_of_\nWikipedias\n1183\nDe En\nNews 67.1 / 32.9 52.3 / 47.7\nWiki 47.6 / 52.4 44.2 / 55.8\nTable 3: Distribution of explicit / relative values accord-\ning to HeidelTime by domains (in %).\nthe TreeTagger that has a restrictive license. This\nresults in a slightly different sentence segmenta-\ntion and tokenization, and, thus, minor differences\nin performance. For example, the original Heidel-\nTime achieves 63.47F1 on the Portuguese test data,\nwhile our spacy version achieves 63.24 F1 as one\nadditional false positive expression was annotated\ndue to different sentence boundaries. Second, we\nadapted HeidelTime to output its internal CIRs for\nthe TimeML values, such that we can create our\nweakly-supervised training data.\nThe rather low performance of our models and\nHeidelTime for the high-resource languages Esto-\nnian (et) and Dutch (nl) can be explained by poor\ndata quality. An inter-annotator agreement of 44\nF1 was reported for the Estonian corpus (Orasmaa,\n2014), which is close to our results. The Dutch data\nwas translated from English and automatically an-\nnotated via cross-lingual projections (Minard et al.,\n2016), which may reduce the annotation quality.\nNote, that only the ﬁrst ﬁve sentences for each doc-\nument were annotated in the Meantime corpora\n(it and nl). We restricted our evaluation to these\nannotated parts accordingly.\n1184\nRank Lang #Ann.\n1 de 870897\n2 en 542087\n3 fr 284871\n4 ar 280446\n5 es 250871\n6 pt 215209\n7 it 199236\n8 nl 194944\n9 ru 122884\n10 zh 105421\n11 hr 50233\n12 ro 33545\n13 vi 22048\n14 af 21081\n15 mk 19539\n16 tr 19532\n17 gl 17416\n18 ca 16747\n19 bn 16284\n20 cy 14738\n21 bg 14550\n22 et 13948\n23 sv 13705\n24 id 13031\n25 da 12919\n26 fy 12852\n27 pl 11283\n28 fa 11041\n29 eu 10992\nRank Lang #Ann.\n30 ne 10750\n31 ms 10017\n32 mg 9271\n33 kk 8080\n34 hi 7762\n35 eo 7353\n36 ur 6228\n37 hu 5871\n38 sq 5760\n39 sk 5172\n40 sr 4276\n41 ka 4247\n42 el 4217\n43 he 4057\n44 sw 3979\n45 ja 3696\n46 br 3582\n47 uz 3361\n48 th 3162\n49 cs 3096\n50 ga 2799\n51 mn 2778\n52 gd 2772\n53 lt 2734\n54 mr 2623\n55 la 1876\n56 uk 1673\n57 hy 1642\n58 ta 1556\nRank Lang #Ann.\n59 my 1103\n60 ml 1079\n61 kn 1029\n62 ﬁ 1017\n63 oa 979\n64 jv 968\n65 ky 926\n66 is 804\n67 am 776\n68 ku 557\n69 so 506\n70 yi 485\n71 ko 483\n72 si 442\n73 ps 403\n74 lo 354\n75 km 350\n76 su 335\n77 lv 323\n78 as 299\n79 ug 283\n80 sd 278\n81 gu 258\n82 ha 205\n83 sl 125\n84 yo 102\n85 sa 24\n86 or 19\n87 xh 3\nTable 4: Languages and the sizes of our weakly-supervised data.\n1185\nCorpus Language #Annotations\n(train / test) Reference\nCorpora only used for evaluation\nKRAUTS-DieZeit German (de) _ / 493 (Strötgen et al., 2018)\nTempEval-3 (platinum) English (en) _ / 137 (UzZaman et al., 2013)\nKOMPAS (test) Indonesian (id) _ / 192 (Mirza, 2016)\nTimeBankCA Catalan (ca) _ / 1383 (Saurı, 2010)\nEstTimeML Estonian (et) _ / 622 (Orasmaa, 2014)\nEusTimeML Basque (eu) _ / 112 (Altuna et al., 2020)\nFr TimeBank French (fr) _ / 423 (Bittar et al., 2011)\nRo TimeBank Romanian (ro) _ / 151 (For ˘ascu and Tuﬁ¸ s, 2012)\nPT-TimeBank (test) Portuguese (pt) _ / 151 (Costa and Branco, 2012)\nWikiWars-EL (test) Greek (el) _ / 414 (Kapernaros, 2020)\nCorpora split into train and test sets\nMeantime (IT) Italian (it) 229 / 244 (Minard et al., 2016)\nMeantime (NL) Dutch (nl) 221 / 259 (Minard et al., 2016)\nTempEval-3 (ES) Spanish (es) 730 / 551 (UzZaman et al., 2013)\nPolEval-2019 Polish (pl) 633 / 6011 (Kocon et al., 2019)\nWikiWars English (en) 1378 / 1251 (Mazur and Dale, 2010)\nWikiWars-DE German (de) 1510 / 684 (Strötgen and Gertz, 2011)\nWikiWars-HR Croatian (hr) 724 / 677 (Skukan et al., 2014)\nWikiWars-UA Ukrainian (ua) 454 / 2237 (Grabar and Hamon, 2019)\nWikiWars-VI Vietnamese (vi) 118 / 101 (Strötgen et al., 2014)\nCorpora only used for training\nKRAUTS-Dolomiten German (de) 388 / _ (Strötgen et al., 2018)\nMeantime (EN) English (en) 472 / _ (Minard et al., 2016)\nTempEval-3 (train, en) English (en) 1240 / _ (UzZaman et al., 2013)\nPT-TimeBank (train) Portuguese (pt) 1127 / _ (Costa and Branco, 2012)\nWikiWars-EL (train) Greek (el) 1496 / _ (Kapernaros, 2020)\nTable 5: Overview of datasets and details on their usage as training (extraction-only) or evaluation data.\n1186",
  "topic": "Normalization (sociology)",
  "concepts": [
    {
      "name": "Normalization (sociology)",
      "score": 0.8895916938781738
    },
    {
      "name": "Computer science",
      "score": 0.8442761301994324
    },
    {
      "name": "Preprocessor",
      "score": 0.7550661563873291
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6332844495773315
    },
    {
      "name": "Natural language processing",
      "score": 0.5492503643035889
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Anthropology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I889804353",
      "name": "Robert Bosch (Germany)",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I91712215",
      "name": "Saarland University",
      "country": "DE"
    }
  ],
  "cited_by": 4
}