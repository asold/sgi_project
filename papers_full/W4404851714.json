{
  "title": "TCMChat: A generative large language model for traditional Chinese medicine",
  "url": "https://openalex.org/W4404851714",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2805329338",
      "name": "Yizheng Dai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2106611242",
      "name": "Xin Shao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2134709804",
      "name": "Jinlu Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2121903534",
      "name": "Yulong Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2095682294",
      "name": "Qian Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100313762",
      "name": "Jie Liao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2111721631",
      "name": "Fei Chi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2109047561",
      "name": "Junhua Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2147865693",
      "name": "Xiaohui Fan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4322766882",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4399206078",
    "https://openalex.org/W2898468989",
    "https://openalex.org/W3108860514",
    "https://openalex.org/W4402429489",
    "https://openalex.org/W3205803342",
    "https://openalex.org/W4390221451",
    "https://openalex.org/W3157265962",
    "https://openalex.org/W6898505805",
    "https://openalex.org/W6678262379",
    "https://openalex.org/W6682631176",
    "https://openalex.org/W2247119764",
    "https://openalex.org/W6600339963",
    "https://openalex.org/W6852870998",
    "https://openalex.org/W6859510294",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2792643794",
    "https://openalex.org/W4311642023",
    "https://openalex.org/W3198659451",
    "https://openalex.org/W4376653782",
    "https://openalex.org/W4389520259",
    "https://openalex.org/W2123301721",
    "https://openalex.org/W4366327277",
    "https://openalex.org/W2981040094",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4366198844",
    "https://openalex.org/W3039201763",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W4399400859",
    "https://openalex.org/W3129831491",
    "https://openalex.org/W4301581299",
    "https://openalex.org/W4392679398",
    "https://openalex.org/W4319653544",
    "https://openalex.org/W4390075948",
    "https://openalex.org/W4391125434",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W4387947536",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W4380989429",
    "https://openalex.org/W4389157038",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4402667025",
    "https://openalex.org/W3174394143",
    "https://openalex.org/W4393212947",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W3144194608",
    "https://openalex.org/W4386942538",
    "https://openalex.org/W4385245566"
  ],
  "abstract": "The utilization of ground-breaking large language models (LLMs) accompanied with dialogue system has been progressively prevalent in the medical domain. Nevertheless, the expertise of LLMs in Traditional Chinese Medicine (TCM) remains restricted despite several TCM LLMs proposed recently. Herein, we introduced TCMChat (https://xomics.com.cn/tcmchat), a generative LLM with pre-training (PT) and supervised fine-tuning (SFT) on large-scale curated TCM text knowledge and Chinese Question-Answering (QA) datasets. In detail, we first compiled a customized collection of six scenarios of Chinese medicine as the training set by text mining and manual verification, involving TCM knowledgebase, choice question, reading comprehension, entity extraction, medical case diagnosis, and herb or formula recommendation. Next, we subjected the model to PT and SFT, using the Baichuan2-7B-Chat as the foundation model. The benchmarking datasets and case studies further demonstrate the superior performance of TCMChat in comparison to existing models. Our code, data and model are publicly released on GitHub (https://github.com/ZJUFanLab/TCMChat) and HuggingFace (https://huggingface.co/ZJUFanLab), providing high-quality knowledgebase for the research of TCM modernization with a user-friendly dialogue web tool.",
  "full_text": null,
  "topic": "Generative grammar",
  "concepts": [
    {
      "name": "Generative grammar",
      "score": 0.7116023302078247
    },
    {
      "name": "Linguistics",
      "score": 0.4087708294391632
    },
    {
      "name": "Traditional medicine",
      "score": 0.346706748008728
    },
    {
      "name": "Computer science",
      "score": 0.3250439763069153
    },
    {
      "name": "Medicine",
      "score": 0.30545490980148315
    },
    {
      "name": "Artificial intelligence",
      "score": 0.23053249716758728
    },
    {
      "name": "Philosophy",
      "score": 0.11662009358406067
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I76130692",
      "name": "Zhejiang University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I12411659",
      "name": "Tianjin University of Traditional Chinese Medicine",
      "country": "CN"
    }
  ]
}