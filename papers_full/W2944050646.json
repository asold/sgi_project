{
    "title": "VetTag: improving automated veterinary diagnosis coding via large-scale language modeling",
    "url": "https://openalex.org/W2944050646",
    "year": 2019,
    "authors": [
        {
            "id": "https://openalex.org/A2116257466",
            "name": "Yuhui Zhang",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2787408661",
            "name": "Allen Nie",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2133678037",
            "name": "Ashley Zehnder",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2166409588",
            "name": "Rodney L. Page",
            "affiliations": [
                "Colorado State University"
            ]
        },
        {
            "id": "https://openalex.org/A2207784945",
            "name": "James Zou",
            "affiliations": [
                "Stanford University",
                "Chan Zuckerberg Initiative (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2116257466",
            "name": "Yuhui Zhang",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2787408661",
            "name": "Allen Nie",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2133678037",
            "name": "Ashley Zehnder",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2166409588",
            "name": "Rodney L. Page",
            "affiliations": [
                "Colorado State University"
            ]
        },
        {
            "id": "https://openalex.org/A2207784945",
            "name": "James Zou",
            "affiliations": [
                "Chan Zuckerberg Initiative (United States)",
                "Stanford University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2404369708",
        "https://openalex.org/W2784499877",
        "https://openalex.org/W2625625371",
        "https://openalex.org/W2201086533",
        "https://openalex.org/W2093388371",
        "https://openalex.org/W2101454456",
        "https://openalex.org/W2334703889",
        "https://openalex.org/W2557060223",
        "https://openalex.org/W1902526473",
        "https://openalex.org/W2769330882",
        "https://openalex.org/W2951125449",
        "https://openalex.org/W2897056441",
        "https://openalex.org/W2096664202",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W1832693441",
        "https://openalex.org/W2064675550",
        "https://openalex.org/W2396881363",
        "https://openalex.org/W2964142373",
        "https://openalex.org/W2122402213",
        "https://openalex.org/W6675354045",
        "https://openalex.org/W4245267204",
        "https://openalex.org/W2962784628",
        "https://openalex.org/W1997057722",
        "https://openalex.org/W2963537482",
        "https://openalex.org/W2101234009",
        "https://openalex.org/W1579838312",
        "https://openalex.org/W2143017621",
        "https://openalex.org/W2626778328",
        "https://openalex.org/W3098949126",
        "https://openalex.org/W2962912956",
        "https://openalex.org/W2273556505"
    ],
    "abstract": null,
    "full_text": "ARTICLE OPEN\nVetTag: improving automated veterinary diagnosis coding via\nlarge-scale language modeling\nYuhui Zhang1, Allen Nie2, Ashley Zehnder 2, Rodney L. Page3 and James Zou 2,4\nUnlike human medical records, most of the veterinary records are free text without standard diagnosis coding. The lack of\nsystematic coding is a major barrier to the growing interest in leveraging veterinary records for public health and translational\nresearch. Recent machine learning effort is limited to predicting 42 top-level diagnosis categories from veterinary notes. Here we\ndevelop a large-scale algorithm to automatically predict all 4577 standard veterinary diagnosis codes from free text. We train our\nalgorithm on a curated dataset of over 100 K expert labeled veterinary notes and over one million unlabeled notes. Our algorithm is\nbased on the adapted Transformer architecture and we demonstrate that large-scale language modeling on the unlabeled notes\nvia pretraining and as an auxiliary objective during supervised learning greatly improves performance. We systematically evaluate\nthe performance of the model and several baselines in challenging settings where algorithms trained on one hospital are evaluated\nin a different hospital with substantial domain shift. In addition, we show that hierarchical training can address severe data\nimbalances for ﬁne-grained diagnosis with a few training cases, and we provide interpretation for what is learned by the deep\nnetwork. Our algorithm addresses an important challenge in veterinary medicine, and our model and experiments add insights into\nthe power of unsupervised learning for clinical natural language processing.\nnpj Digital Medicine           (2019) 2:35 ; https://doi.org/10.1038/s41746-019-0113-1\nINTRODUCTION\nLarge-scale electronic health records (EHR) can be a powerful\nresource for patient care and research. There have been many\nexciting efforts applying machine learning to human medical\nrecords— e.g. predicting in-hospital mortality, 30-day unplanned\nreadmission, and prolonged length of stay\n1,2 — with the goal of\nassisting medical professionals. In comparison to the human EHR,\nthere has been little machine learning (ML) work on veterinary\nEHR, which faces several unique challenges. While it is standard\npractice for clinicians to enter standardized diagnosis and billing\ncodes for human EHR, almost all veterinary clinics lack resources to\nannotate their patient notes with standard diagnosis coding.\nVeterinary records can be extremely valuable for research and\npublic health— 60–70% of all emerging diagnoses are transmitted\nfrom animals to humans. Beyond that, companion animals have\nbeen increasingly used to study naturally occurring diseases as\nthey share similar environments to humans and are often more\nrepresentative disease models compared with induced mouse\nmodels, which frequently do not accurately recapitulate diseases\nin humans. While cancer is a leading area of cross-species\ntranslational studies,\n3 other diseases such as genetic neuromus-\ncular disorder,4 osteoarthritis5 and diabetes6 are being studied in\ncompanion animals as well. The lack of standard diagnosis coding\non veterinary records is a major bottleneck for public health\nmonitoring and these cross-species translational studies.7\nInferring diseases and diagnoses from free text such as\ndiagnostic reports and clinical notes has been actively studied in\nclinical natural language processing (NLP).\n8 However, most of\nthese works are designed for human EHR. They are often trained\nand evaluated on clinical notes gathered from the same hospital\nas well. Veterinary notes have different styles and vocabulary, and\nits diagnosis codes use a terminology framework different from\nhumans. Therefore an automated veterinary coding algorithm is\nneeded. Moreover, due to the lack of general coding practice in\nthe veterinary clinics, algorithms can only be trained on coded\nnotes collected from a handful of training hospitals, but need to\nmaintain high performance when they are applied to notes from a\ndiverse set of clinics across the country. Clinical notes from\ndifferent clinics can differ substantially in its writing style, making\nautomated coding a challenging task.\nProcessing free text such as diagnostic reports and clinical\nnotes, as well as generating structured information understand-\nable by human have been a central focus of clinical natural\nlanguage processing.\n8 Most of the previous research has focused\non the human healthcare systems, assisting a wide range of\nclinical operations such as adenoma detection, assisting billing\ncode assignment,\n9 and discovering novel phenotypes and\ndiagnoses using unsupervised learning method on a large set of\nmultimodal data.\n10\nPrevious work has also focused on searching for effective\narchitectures for the automated coding of human diagnoses, from\napplying the long short-term memory networks (LSTM),11 multi-\nlevel hierarchical text processing models,12 to memory conden-\nsing networks.13 Rajkomar et al. have also proposed using deep\nlearning models to predict a wide range of quantities in electronic\nmedical record.\n1 Learning text representation that generalizes\nacross domains is the goal of many recent papers. These\npromising results share the same approach: pretrain the model\nReceived: 25 January 2019 Accepted: 17 April 2019\n1Department of Computer Science and Technology, Tsinghua University, Beijing, China;2Department of Biomedical Data Science, Stanford University, Stanford, CA 94305, USA;\n3Department of Clinical Sciences, Colorado State University, Fort Collins, CO 80523, USA and4Chan-Zuckerberg Biohub, San Francisco, CA 94158, USA\nCorrespondence: James Zou (jamesz@stanford.edu)\nThese authors contributed equally: Yuhui Zhang, Allen Nie\nwww.nature.com/npjdigitalmed\nScripps Research Translational Institute\non a large unlabeled text corpus using unsupervised learning\nobjectives. Such unsupervised pretraining allows the model to\nachieve state-of-the-art results on many tasks such as question\nanswering, named entity recognition, and commonsense\nreasoning.\n14,15\nVeterinary clinical notes, due to the lack of infrastructure and\nthird-party payer system, are almost entirely uncoded, making it\nchallenging to analyze the record for diagnosis prevalence,\noutcome studies, and drug adverse effects. A recent method,\nDeepTag, takes theﬁrst step toward addressing this challenge.\n16\nDeepTag predicts 42 top-level diagnosis codes from veterinary\nclinical notes by training a deep learning model on the Colorado\nState University Veterinary (CSU) dataset. Although the training\ndataset is large, DeepTag suffers from signi ﬁcant performance\ndrop when it is deployed to another set of notes collected from a\nprivate practice. This new work differs from DeepTag as we\naugment supervised training with a form of unsupervised learning\n– language modeling to read through millions of unlabeled notes\nprovided by another hospital. Such unsupervised training is a\npromising new approach to boost the power of many clinical NLP\nmethods on both human and veterinary data.\nSNOMED-CT codes, similar to other structured diagnostic codes\nassigned to clinical notes, are designed to form a hierarchy.\nDeepTag predicts whether a given noteﬁts in with a subset of the\n42 broad diagnosis codes, corresponding to the highest level of\nSNOMED-CT hierarchy. It does not predict speciﬁc diagnoses. The\nchallenge with directly predicting each ﬁne-grained diagnosis\ncode is that there are thousands of diagnoses and many of them\nare rare in the training set. Perotte et al. had proposed a training\nmethod for support vector machine (SVM) to leverage the\nhierarchy and alleviate the problem of low recall on very rare\nlabel classes.\n17 In this work, we extend this hierarchical training\nmethod to neural network classiﬁers and apply it to veterinary\ndiagnosis coding to predict 4577 SNOMED-CT codes with high\nperformance.\nWe develop a large-scale algorithm, VetTag, that automatically\npredicts thousands of ﬁne-grained veterinary diagnosis codes\nfrom free-form veterinary notes. Our algorithm is trained on a\ncurated dataset of over 100 K expert labeled veterinary notes and\nover one million unlabeled notes. We adapt the new state-of-the-\nart Transformer model proposed by Vaswani et al.,\n18 and\ndemonstrate that large-scale language modeling on the unlabeled\nnotes substantially improves coding accuracy. We systematically\nevaluate the model performance in challenging settings where\nVetTag trained on one hospital is evaluated in a different hospital\nwith substantial domain shift. We use hierarchical training to\nalleviate data imbalances and demonstrate such training scheme\nsubstantially bene ﬁt rare diagnoses. In addition, we provide\ninterpretation for what is learned by the deep network. VetTag\naddresses an important application in healthcare and our\nexperiments add insights into the power of unsupervised learning\nfor clinical natural language processing.\nRESULTS\nProblem deﬁnition\nVetTag takes a free-text clinical note as input and infers a set of\nclinical diagnoses from the note. The inferred diagnosis is in the\nform of SNOMED-CT codes and each note can be associated with\nmultiple codes if the patient has several diagnoses. Figure 1\nprovides examples of veterinary notes from Colorado State\nUniversity (CSU), a private practice clinic in Northern California\n(PP), and a large private specialty veterinary group (PSVG) that we\nuse to train and evaluate our coding algorithms. CSU and PP notes\nare expert labeled with the relevant SNOMED-CT codes, and PSVG\nis unlabeled.\nVetTag is trained in two stages: unsupervised learning and then\nsupervised learning. During the unsupervised learning stage, we\ntrain VetTag on 1,019,747 unlabeled veterinary clinical notes from\na large private specialty veterinary group that operates multiple\nspecialty clinics (PSVG) to simply predict the next word condi-\ntioned on all previous words. The goal of this unsupervised\nlearning is to “familiarize” VetTag with medical concepts and\nwriting, so that it can more efﬁciently learn from the labeled data.\nDuring the supervised learning stage, we train VetTag on 112,557\nlabeled veterinary notes from the Colorado State University of\nVeterinary Medicine and Biomedical Sciences (CSU). VetTag adapts\nthe Transformer architecture as the encoder\n18 to generate a\ncontextualized vector representation for the input text, and\npredicts the diagnosis using the vector. Figure 2 provides a\nschematic overview of VetTag and details of the model are\nprovided in Supplementary Materials.\nVetTag aims to predict whether each of the 4577 SNOMED-CT\ndiagnosis codes applies to the clinical note. A major challenge\nhere is the large number of potential diagnoses and the fact that\nmany of the codes are rare in the dataset. We leverage the\nhierarchical structure of SNOMED-CT codes to improve VetTag\ntraining. In the SNOMED-CT hierarchy, the top level codes (i.e.\nFig. 1 Example clinical notes from the Colorado State University (CSU), a private practice clinic (PP) and a private specialty veterinary group\n(PSVG) datasets. CSU and PP are expert labeled and PSVG is unlabeled\nY. Zhang et al.\n2\nnpj Digital Medicine (2019)    35 Scripps Research Translational Institute\n1234567890():,;\ndepth 1 and 2 starting from the top) correspond to broad\ndiagnosis categories, while the lower level codes are increasingly\nmore ﬁne-grained diagnoses. Instead of predicting all of the codes\nin parallel, we use a hierarchical prediction approach where\nVetTag ﬁrst predicts the top level codes and then sequentially\npredicts on a child diagnosis when its parent diagnosis is\npredicted to be present. This approach enables VetTag to leverage\nthe relations between the diagnosis. Figure3 provides an example\nof the hierarchical training and more details are in the Methods\nSection.\nWe evaluate VetTag ’s performance on two datasets. One\ncontains a set of holdout non-overlapping 5628 notes randomly\nselected from the CSU dataset. The second is an external\nvalidation dataset that we collected from a different commercial\nhospital PP that contains 586 documents. CSU dataset contains\nnotes collected from a tertiary referral academic hospital— the\nwriting tends to be more polished and longer. PP and PSVG notes\nare collected from primary and secondary referral hospitals, where\nthe notes are shorter and written with expediency using more\nabbreviations. We provide a comparison of these datasets in\nSupplementary Figs. 1 and 2.\nPerformance evaluation\nWe systematically compare the performance of VetTag on both\nCSU and PP test data with commonly used non-deep learning\nalgorithms (MetaMap) and standard deep learning algorithms\nbased on convolutional neural networks (CNN),\n19 long short-term\nmemory networks (LSTM),20 as well as recent variations including\nthe state-of-the-art model on MIMIC — an open data of ICU\nmedical records 21 (CAML),22 bidirectional LSTM (BLSTM) and\npretrained LSTM encoder with auxiliary language modeling\nobjective (LSTM + AP). As none of these algorithms have been\napplied to this veterinary coding task previously, we trained our\nown implementations for the purpose of this comparison. Table1\nreports the performance of all of the algorithms. Each algorithm is\nevaluated based on prediction precision (the fraction of predicted\ndiagnoses that match the expert diagnoses), recall (the fraction of\nthe expert diagnoses that are successfully retrieved), F\n1 (the\nharmonic mean of precision and recall), and exact match (EM, the\nfraction of notes where the algorithm ’s predicted diagnoses\nexactly match the expert diagnoses). Since there are 4577 possible\ndiagnoses, getting an exact match is quite challenging. VetTag\nachieves the best performance across all of the metrics. The\nFig. 2 Our proposed model architecture for automated diagnosis coding. Two tasks are shown: unsupervised language modeling (top) and\nsupervised learning (bottom). The dashed red arrows represent the pretraining process on the unlabeled PSVG data, and the solid blue arrows\nrepresent the ﬁne-tuning process on the labeled CSU data. Additional test is done on the PP data (not shown)\nFig. 3 Example of hierarchical training. We show a 4-layer subtree of SNOMED-CT Codes in the left part and its vector representation in the\nright part. Each node is labeled with diagnosis name, depth, true diagnosis label (marked as check or cross) and VetTag’s predicted probability\n(shown as the horizontal bar). During training, we only consider the binary cross entropy loss for nodes whose parent diagnosis is present in\nthe expert label— each node is linked with a solid line in the tree.Malformation and Anemia are not taken into consideration, i.e. they are\nmasked, because their parentsCongenital and Chronic are not present in the expert labels. These masked nodes are linked with dotted edges.\nThe masked predictions are not used to update the model during training\nY. Zhang et al.\n3\nScripps Research Translational Institute npj Digital Medicine (2019)    35 \nimprovement over other algorithms is especially notable for the\nPP test data, demonstrating that VetTag is more robust to\nvariations across different hospitals and clinics.\nAs discussed above, VetTag combines the recently developed\nTransformer model 18 with an auxiliary language modeling\nobjective (A), pretrained encoder (P) and the SNOMED hierarchical\nloss. In order to evaluate the contribution of each of these\ncomponents, we also systematically quantify the model’s perfor-\nmance when each of these three components is removed. Using\nonly a subset of these components leads to strictly worse\nperformance on both CSU and PP test data, indicating that they\nare all required to produce the optimal results.\nDeepTag is the previous state-of-the-art algorithm for auto-\nmated veterinary diagnosis.\n16 DeepTag is a bidirectional LSTM\ntrained to predict 42 top-level SNOMED diagnoses, and can not be\ndirectly applied to predict the 4577 ﬁne-grained codes we are\ninterested in here. Therefore we can not compare it directly in\nTable 1; the DeepTag architecture is the most similar to BLSTM. In\norder to head-to-head compare VetTag with DeepTag, we restrict\npredictions to 41 top-level diagnoses except for clinicalﬁnding\n(the spurious category) and report its results in Supplementary\nTable 1 and Supplementary Fig. 3. Note that since VetTag is\noptimized for all 4577 diagnoses and DeepTag is optimized for\nonly 42 diagnoses, this comparison is favorable for DeepTag.\nDespite this, VetTag and DeepTag achieve similar accuracy on the\nCSU data, with VetTag having higher EM score, and VetTag is\nsubstantially better on the PP test data.\nPerformance analysis\nLanguage model helps Transformer. Training a system on multiple\ntasks with shared encoding can often improve the model ’s\nperformance on all tasks, as different tasks serve as implicit\nregularization to prevent the model from overﬁtting to a particular\ntask.\n23 In our experiment, we compare the performance of our\nsystem by adding language modeling objective as an auxiliary task\nduring the classiﬁcation task (Transformer+A vs. Transformer in\nTable 1). Adding the language modeling as an auxiliary task\nimproves Transformer CSU test set as well as the cross-hospital PP\nevaluation set. We also combine the language modeling pretraining\nas well as the auxiliary task during the classiﬁcation task and observe\na substantially better performance on the overall model compared\nto the baseline model with either approach alone (Transformer+AP\nvs. Transformer+Ao rT r a n s f o r m e r+P in Table1).\nTable 1. Evaluation of trained classiﬁers on the CSU test data and\nPP data\nModel CSU PP (Cross-hospital)\nF1 Prec Rec EM F1 Prec Rec EM\nVetTag 66.2 72.1 63.1 26.2 48.6 54.9 47.7 9.2\nMetaMap (SVM) 56.8 56.4 57.7 8.9 32.7 35.7 37.3 0.0\nMetaMap (MLP) 50.8 55.2 47.5 13.8 21.6 27.3 20.2 0.3\nCNN 62.7 75.6 55.8 20.2 33.1 42.0 30.7 1.9\nCAML 62.6 74.1 56.2 17.8 37.7 54.7 32.0 3.1\nLSTM 60.1 72.4 53.4 22.3 30.3 49.9 24.1 7.5\nBLSTM 60.2 70.6 54.5 20.2 35.5 50.9 30.2 4.4\nLSTM + AP 45.3 63.8 38.7 12.5 31.3 48.9 26.3 2.2\nTransformer 38.2 55.3 32.2 13.9 22.9 34.8 22.3 2.2\nTransformer + W 44.6 61.6 38.0 14.8 29.0 45.6 25.1 1.7\nTransformer + P 63.3 76.6 56.1 22.8 30.1 56.4 24.3 6.5\nTransformer + A 63.5 72.2 58.3 20.9 41.2 51.6 37.3 5.5\nTransformer + AP 64.8 74.4 59.8 20.3 45.0 53.1 42.7 7.0\nEM is the fraction of cases where the set of diagnoses predicted by the\nmodel exactly matches the expert labels. The classiﬁers are trained on a\nsubset of CSU. Notation: CNN, LSTM and Transformer are our base models;\nBLSTM is bidirectional LSTM; CAML is the state-of-the-art model on MIMIC,\nan open data of ICU medical records.+W uses Word2Vec trained on PSVG\nto initialize; +P uses language modeling objective trained on PSVG to\ninitialize; +A uses language modeling objective on CSU in addition to\nclassiﬁcation objective on CSU; Hierarchical uses hierarchical loss during\ntraining process; VetTag trains a transformer with auxiliary objective (+A),\npretraining (+P) and hierarchical loss\nTable 2. Comparison of tagging performance by depth with/without hierarchical training\nDataset Depth #Diagnosis #Case Without Hierarchical With Hierarchical\nF1 Prec Rec EM F1 Prec Rec EM\nCSU 1 56 91109 76.2 81.8 74.1 51.3 76.6 83.8 72.9 52.7\n2 299 90880 73.3 79.1 70.0 35.9 73.8 78.3 71.3 38.9\n3 632 89856 66.9 75.9 61.1 31.0 68.1 72.9 65.1 33.3\n4 1086 85783 62.6 73.3 56.7 33.7 63.9 69.7 60.9 33.8\n5 1298 70242 55.6 68.4 49.8 45.8 57.7 65.2 54.2 44.1\n6 804 46250 45.2 62.7 39.7 68.2 49.4 59.2 45.7 65.5\n7 283 12994 37.9 54.7 31.1 90.2 45.3 56.1 43.3 89.7\n8 66 2918 19.7 41.9 14.4 97.4 31.7 44.1 31.5 97.4\nPP 1 56 497 57.8 61.8 57.2 26.8 57.7 67.6 54.9 25.3\n2 299 495 52.4 56.3 52.0 13.8 55.5 58.7 56.5 15.0\n3 632 489 46.0 54.5 42.4 14.2 50.2 55.6 49.8 11.9\n4 1086 462 43.4 54.7 39.3 16.9 46.9 54.1 45.2 14.5\n5 1298 389 28.3 38.7 26.9 25.8 33.4 42.2 31.3 24.6\n6 804 216 16.1 28.6 17.7 58.9 22.9 28.7 21.6 54.3\n7 283 68 10.9 10.3 13.0 86.5 14.9 24.3 14.5 86.3\n8 66 9 18.2 50.0 11.1 95.1 0.0 0.0 0.0 97.8\nData are more unbalanced as depth increases, and thus we observe more signiﬁcant improvements by hierarchical training\nY. Zhang et al.\n4\nnpj Digital Medicine (2019)    35 Scripps Research Translational Institute\nHierarchical training improves performance. Diagnosis codes at a\ngreater depth in the SNOMED hierarchy tend to be more speciﬁc,\nand thus fewer positive cases can be found for it. In the traditional\nmultilabel classiﬁcation setting, rare diagnoses will have signiﬁ-\ncantly more negative labels than positive labels, encouraging the\nclassiﬁer to always output a negative label. We use hierarchical\ntraining to address this imbalance problem. We report the\nperformance comparison by depth in Table2. We observe more\nsigniﬁcant improvement as depth increases when we use\nhierarchical training compared to the same model with the\nstandard non-hierarchical loss (Transformer+ AP). In Table 3,w e\ngive samples of the representative diagnoses and VetTag ’s\nperformance at theﬁrst ﬁve depth levels.\nVetTag achieves good performance across species . Our CSU\ntraining and test data contain a broad range of animal species,\nwith canine being the dominant species (over 75% of the dataset).\nIn the PP test data, we observe that canine make up around 70%\nof the cases and a larger portion of feline. In Table4, we break\ndown the test performance of VetTag for each species. Overall,\nVetTag achieves the highestF\n1 on the canine cases, and slightly\nlower performance for feline and equine cases. We provide\nstatistics on the number of notes per species for both CSU and PP\ndata in Supplementary Fig. 2.\nMetaMap fails to extract discriminative information. We investi-\ngate the effectiveness of traditional feature extraction techniques\nprovided by MetaMap, which is a popular method in medical NLP\nfor extracting medically relevant keywords from text.\n24 We apply\nMetaMap directly to each veterinary note to extract a bag-of-\nkeywords. Then we use either Support Vector Machine (SVM) with\nthe linear kernel or Multilayer Perceptron (MLP) as the classiﬁca-\ntion algorithm from scikit-learn.25 We treat these as our baseline\nand report the result in Table1.W eﬁnd that MetaMap features are\nnot very discriminative at identifying diagnoses in the veterinary\nmedicine domain, and its performance is worse than our various\nbaselines on both the CSU and PP test data.\nPretrained language model outperforms Word2Vec. Perplexity is a\ncommon metric to evaluate the quality of a language model;\nlower the perplexity, higher the quality.\n26 Our Transformer model\nachieves a test perplexity of 15.6 on the PSVG dataset, which is\nsubstantially better than the 20.7 perplexity achieved by LSTM on\nthe same data. We also note that compared to the state-of-the-art\nperplexity achieved on other corpora such as Wall Street Journal\nor Wikipedia, 47.69 and 40.68 respectively,\n27 the perplexity we\nobtained is much lower, signaling that the clinical notes are much\nmore structured than other sources of written text. In the\nexperiments reported in Table 1, we also ﬁnd that language\nmodeling as pretraining is sufﬁcient for models to learn useful\nword embeddings— model with +P outperforms model using\nWord2Vec embedding trained on PSVG (+W) on both CSU and the\ncross-hospital dataset PP.\nInterpreting how VetTag works\nIn order to better understand how VetTag predicts diagnosis\ncodes from clinical notes, we implement a simple saliency-based\ninterpretation method for VetTag. The saliency of each word\nquantiﬁes how much that word inﬂuences VetTag’s predictions,\nand it is computed as the gradient of the predicted probability\nTable 3. Label performance by depth\nDepth Diagnosis CSU PP (Cross-hospital)\n# F1 Prec Rec EM # F1 Prec Rec EM\n1 Disease by body site 84832 91 90 92 87 461 83 84 82 74\nInﬂammatory disorder 25271 72 77 68 89 193 64 73 57 79\nInfectious disease 11304 60 70 52 93 88 42 68 31 87\n2 Disorder of body systems 79365 90 88 91 85 459 83 85 81 74\nDisorder of soft tissue 36237 75 78 73 85 205 65 57 76 72\nDisease of trunk 35398 78 77 79 86 147 56 53 59 77\n3 Malignant tumor 28058 91 93 89 96 19 52 36 90 95\nInﬂam. of speciﬁc body systems 23911 72 71 73 88 190 66 66 67 78\nInﬂam. of speciﬁc body organs 22531 72 71 73 89 170 66 65 68 80\n4 Disease of abdomen 20215 73 71 75 90 90 44 46 42 84\nDisease of digestive organ 19136 68 70 65 90 177 55 62 50 76\nDisease of digestive tract 17997 71 75 68 92 184 60 69 53 78\n5 Disease of upper digestive tract 11316 65 69 61 94 154 57 65 51 80\nDisease of gastrointestinal tract 9265 70 74 67 96 33 29 29 30 92\nDisorder of anterior eye segment 7638 80 77 83 97 38 58 56 61 94\nWe sample three of theﬁve most frequent diagnoses from each layer and report its performance for each depth. Diagnoses are more speciﬁc as layer\ngoes deeper\nTable 4. VetTag performance stratiﬁed by species\nSpecies CSU PP (Cross-hospital)\n# F1 Prec Rec EM # F1 Prec Rec EM\nCanine 4351 67.2 73.3 63.9 24.5 425 49.7 56.9 48.2 7.8\nFeline 607 59.8 64.1 58.8 23.4 149 43.9 46.8 45.4 12.8\nEquine 549 61.3 65.1 60.3 39.7 0 0.0 0.0 0.0 0.0\nBovine 60 47.8 55.0 46.1 40.0 0 0.0 0.0 0.0 0.0\nCaprine 21 39.5 36.8 45.0 38.1 0 0.0 0.0 0.0 0.0\nPorcine 26 63.6 77.2 57.6 38.5 1 31.2 31.2 31.2 0.0\nOvine 8 54.7 52.0 60.9 50.0 0 0.0 0.0 0.0 0.0\nOther\nMammals\n6 56.9 53.8 62.9 33.3 10 53.1 54.2 54.3 10.0\nY. Zhang et al.\n5\nScripps Research Translational Institute npj Digital Medicine (2019)    35 \nwith respect to the input word. We show an example of the\nkeywords highlighted by saliency scores in Fig.4— the higher the\nsaliency score, the darker the color and the more inﬂuential is the\nword to VetTag’s prediction. We report the top ten most salient\nwords for ten top-level diagnosis codes that overlap DeepTag’s\ndiagnosis codes in Table5. The full list of salient words for all the\ntop-level diagnosis codes is provided in Supplementary Table 2.\nMore precisely, for each diagnosis category, we compute the\nmedical words that are the most likely to be salient— i.e. with\nsaliency score≥0.2, a score chosen to select on average 11 words\nper note— and report these words. Words captured by the model\nhave high quality and agree with medical domain knowledge.\nMost words captured by the model is in the expert-curated\ndictionary from the MetaMap. Moreover, we notice that the model\nis capable of capturing abbreviations (i.e.,‘kcs’— keratoconjuncti-\nvitis sicca), combinations (i.e., ‘immune-mediated’) and rare\nprofessional terms (i.e.,‘cryptorchid’) that MetaMap fails to extract.\nDISCUSSION\nProcessing veterinary clinical notes and generating structured\ninformation has a tremendous impact on the ecosystem of\nveterinary clinical data science. In this study, we extended the\nprevious work in two important directions.\n16 First, we propose a\nlanguage model framework to leverage a massive amount of\nunlabeled clinical notes, demonstrating that this type of\nunsupervised learning is crucial in improving the performance\nand robustness of the diagnosis coding model. Second, we build a\nsystem to predict 4577 SNOMED codes— DeepTag was also able\nto predict 42 top-level diagnosis codes by comparison — by\nleveraging the hierarchy amongst the SNOMED codes so that\nthe model only predicts the child diagnosis when all of its parents\nare present. We demonstrate that this hierarchical training is\nsigniﬁcantly better than the standard multi-label prediction\nscheme especially for rare diagnosis categories which previously\nsuffered from low recall. We show that training with diagnosis\nhierarchy not only improves performance on the original task, but\nalso improves the robustness of VetTag when it is applied to data\nfrom a different clinic.\nWe analyze the impact of depth (speciﬁcity) of a diagnosis to\nthe performance of the model. Clinical note coders are instructed\nto apply lower-level, more speciﬁc codes as much as they can.\nMany labeled codes correspond to very speciﬁc diagnoses, and\nsimply predicting top-level diagnosis is not sufﬁcient in practice.\nAs speci ﬁcity and depth increase, the number of potential\ndiagnoses also increases and the number of relevant cases\ndecreases. With hierarchical training, we ﬁnd a substantial\nimprovement for the more speciﬁc diagnosis.\nWe additionally provide a saliency method to explain VetTag by\nvisualizing the words in the clinical note that most signiﬁcantly\ninﬂuences VetTag’s prediction. The most salient words for VetTag\nagree well with the clinically meaningful terms. Moreover, VetTag\nsaliency map identiﬁes words such as acronyms and combinations\nbeyond what the standard MetaMap vocabulary. Highlighting\nsuch salient in clinical notes can help human curators to label\ndocuments more quickly and provide rationalization over the\nVetTag’s decision process.\nAs we make meaningful progress toward a more robust\nautomated coding system for veterinary medicine, we note that\nthere is still a signiﬁcant drop in performance when applied to text\nfrom a different hospital. The signiﬁcant improvement over the\nbaseline methods as well as the ability to infer a wide range of\ndiagnosis codes gives us cautious optimism to apply this tool to\nlabel veterinary clinical notes and conduct analyses. However, due\nto the inherent bias from our training data, some important\ndiagnoses such as neoplasm and/or hamartoma are over-\nrepresented, resulting in lower precision when applied in the\ncross-hospital setting. We can partially mitigate this effect by\nadjusting the decision threshold of the binary classiﬁer, but further\nresearch needs to be conducted on learning both over-\nrepresented diagnoses and under-represented diagnoses in this\nsetting. An important step of future work will be to fully study the\ncross-hospital performance of our algorithm by collaborating with\nother veterinary academic institutions, and conduct pilot studies\nFig. 4 Example of text interpretation from the CSU dataset. Words positively contributing to the predicted label are highlighted in red by the\ngradient map\nTable 5. Most salient words for VetTag\nDiagnosis (SNOMED-CT code) Extracted keywords\nTraumatic AND/OR non-traumatic injury fracture, wound, laceration, due, assessment, trauma, this, bandage, time, owner\nVisual system disorder eye, ophthalmology, surgery, eyelid, assessment, sicca, time, uveitis, diagnosed, this\nHypersensitivity condition dermatitis, allergic, therapy, atopic, otitis, pruritus, ears, assessment, allergies, dermatology\nMetabolic disease diabetes, nph, hypercalcemia, glargine, vetsulin, weeks, home, insulin, amlodipine, dose\nAnemia pancytopenia, anemia, visit, hemolytic, persistent, steroids, hypertension, neoplasia, exam, thickening\nDisorder of immune function eosinophilic, then, problem, todays, hypocalcemia, cornea, dose, skin, alt, weeks\nDisorder of endocrine system methimazole, thyroid, weeks, levothyroxine, carcinoma, mass, hyperadrenocorticism, assessment, diabetes,\ndiagnosed\nDisorder of connective tissue osteosarcoma, assessment, ligament, surgery, carboplatin, disease, dysplasia, rupture, cruciate, fracture\nPoisoning ingestion, assessment, toxicity, chocolate, vomiting, charcoal, not, maya, chance, activated\nCongenital disease dysplasia, hip, bilateral, assessment, testicle, right, cerebellar, service, surgery, echo\nWe select ten representative diagnosis categories. For each diagnosis, we show the top 10 words in the MetaMap medical dictionary that the model most\nstrongly associates with the phenotype. Words are sorted in decreasing order by its frequency in the CSU test set\nY. Zhang et al.\n6\nnpj Digital Medicine (2019)    35 Scripps Research Translational Institute\nthat integrate VetTag into the veterinary IT infrastructure. There\ncould be potential values to mapping SNOMED labels to a\nrestricted subset of codes that are currently used in clinical\npractices. We focused on SNOMED because it is commonly used\nand we believe similar model as VetTag can be used to predict\nother codes with potentially even better accuracy. This is a good\ndirection of further work.\nMETHODS\nDatasets\nWe use three datasets in our experiments (Table6). Three examples are\nsampled from each dataset and shown in Fig.1.\nLabeled data 1: Colorado State University (CSU). We use a curated set of\n112,557 veterinary notes from the Colorado State University College of\nVeterinary Medicine and Biomedical Sciences. Each note is labeled with a\nset of SNOMED-CT codes by veterinarians at Colorado State. Colorado State\nis a tertiary referral center with an active and nationally recognized cancer\ncenter. We ﬁnd 4577 total SNOMED codes present in the CSU labeled\ndataset. These represent the relatively more common diagnosis and we\nfocus on predicting these codes.\nLabeled data 2: private practice (PP). We also use a smaller set of 586\ndischarge summaries curated from a commercial veterinary practice\nlocated in Northern California. Two veterinary experts applied SNOMED-CT\ncodes to these records. Records with coding discrepancies were reviewed\nby both coders to reach a consensus on each record. This dataset is\ndrastically different from the CSU dataset. PP notes are written often in an\ninformal style, evidenced by their shorter length and usage of abbrevia-\ntions. The PP data also has a different diagnosis distribution compared to a\nspecialized academic cancer center CSU.\nUnlabeled data: private specialty veterinary group (PSVG). We obtained a\nlarge set of over one million unlabeled notes from a large private specialty\nveterinary group that operates multiple veterinary clinics. This is a set of\nraw clinical notes without any codes applied to them.\nData Processing.W e ﬁlter out all non-ASCII characters in our documents,\nconvert all letters to lower case, and then tokenize with NLTK.\n28 We apply\nthe standard BPE (Byte Pair Encoding)29 algorithm to address the out-of-\nvocabulary problem, and to speed up the language modeling training. BPE\nuses a vocabulary size of 50 K, and out-of-vocabulary words are encoded as\nsubword units. We randomly split the CSU and PSVG dataset into training,\nvalidation and test set for supervised learning and unsupervised learning.\nSNOMED-CT Codes . SNOMED-CT is a comprehensive clinical health\nterminology managed by the International Health Terminology Standards\nDevelopment Organization.\n30 Annotations are applied from the SNOMED-\nCT veterinary extension (SNOMED-CT VET), which is a veterinary extension\nof the International SNOMED-CT edition. In this work, we try to predict\ndisease-level SNOMED-CT codes.\nICD-9/ICD-10 billing codes are the results of complex interactions\nbetween the patient, care-provider, potentially third-party coders and\ninsurance policies, all of which could introduce systematic bias in what\ncodes are assigned.\n31 In order to reduce potential biases, the SNOMED-CT\nVET codes in our dataset are assigned by veterinary school students using\nstandardized procedures to facilitate cohort identi ﬁcation and record\nretrieval for clinical science.\nDisease-level SNOMED-CT codes are organized as a directed acyclic\ngraph. However, there are only a small number of nodes with more than\ntwo ancestors. By applying the breadth-ﬁrst search algorithm from the root\nnode, the general disease in SNOMED-CT codes, we can get the shortest\npath from the root node to any speciﬁc diagnosis node. For each node, we\nonly reserve the shortest path from the root node. The directed acyclic\ngraph is transformed to a tree after processing. For each node, depth\nrepresents for the distance from the root node to the current node, and\nbranch represents the number of children of the current node. We show\nstatistics of processed disease-level SNOMED-CT codes in Table7.\nAlgorithm development and analysis\nWe build the base of our model using the multi-layer Transformer\narchitecture similar to the setup in Radford et al.15 We concisely summarize\nthe VetTag algorithm here and more details are provided in Supplemen-\ntary Materials.\nWe model automated coding as a multi-label classiﬁcation problem.\nGiven a note, we want to predict whether the note is positive (i.e. supports\nthe diagnosis) of each diagnosis labely in a predeﬁned set of diagnosesY.\nFor the i-th diagnosis, we want to predict whether the binary diagnosis\nlabel y\ni is 0 or 1. Here each label corresponds to a SNOMED-CT diagnosis\ncode. Our proposed model architecture is shown in Fig.2. Three tasks are\nshown: unsupervised learning, supervised learning and hierarchical\ntraining. We describe these three tasks in the following section and details\nare provided in Supplementary Materials.\nUnsupervised Learning . We build a generative model over text for\nunsupervised learning, also referred to as a language model. Text\nsequence is an ordered list of tokens. Therefore, we can build an\nautoregressive model to estimate the joint probability of the entire text\nsequence X: p(X) = p(x\n1, … , xT), where xt represents the t-th token in the\nsequence of length T. In an ordered sequence, we can factorize it as\npðXÞ¼ QT\nt¼1\npðxt jx1; :::;xt/C0 1Þ. Concretely, we estimate the token distribution\nof xt by using the contextualized representation vectorht 2 Rd provided\nby our encoder:ht = Encoder(h1, … , ht−1), whered is latent dimensions of\nthe model. We optimize over the negative log-likelihood of the distribution\n/C0 log pðXÞ¼/C0 PT\nt¼1\nlogpðxtjx1; :::;xt/C0 1Þ.\nIn our model, we examine the effect of language modeling on two\nencoder architectures: Transformer and the long short-term memory\n(LSTM). We use this objective in two parts of our system: (1) pretrain\nencoder’s parameters; (2) serve as anauxiliary task during training of the\nclassiﬁer.\nSupervised Learning. We get a summary representation vectorc 2 R\nd for\nthe entire sequence from the encoder. We then use a fully connected layer\nto down project it and calculate the probability of whetherj-th diagnosis\nshould be predicted: pðyj Þ¼ σðwT\nj c þ bj Þ, where wj 2 Rd and bj 2 R are\nthe weight and bias for the classiﬁer ofj-th diagnosis, andσ is the sigmoid\nfunction: σ(x) = 1/(1 + e−x). We compute the binary cross entropy lossLðCÞ\nacross m labels: LðCÞ ¼ /C0 1\nm\nPm\nj¼1\nyj log pðyj Þþð 1 /C0 yj Þ logð1 /C0 pðyj ÞÞ, where\nbinary label yj ∈ {0, 1} indicates whether j-th diagnosis is true in the\nexpert label.\nFinally, we use a mixture of two lossesLtotal ¼ LðCÞ /C0 λ /C3 log pðXÞ and\nuse hyperparameter λ = 0.5 to set the strength of the auxiliary loss when\nwe use language modeling as anauxiliary taskin our classiﬁcation training.\nHierarchical Training. There are less training cases for a more speci ﬁc\ndiagnosis. The severe data imbalance for certain diagnosis makes classiﬁer\ntend not to predict these diagnoses. We alleviate the problem by utilizing\nhierarchy in SNOMED-CD codes. Instead of predicting each diagnosis\nindividually, we predict diagnosis from top to bottom, and we call it\nhierarchical training. We show an example in Fig.3.\nTable 6. Descriptive statistics of the three datasets\nCSU (Labeled) PP (Labeled) PSVG (Unlabeled)\n# of notes 112,557 586 1,019,747\n# of training set 101,301(90%) 0(0%) 917,665(90%)\n# of validation set 5,628(5%) 0(0%) 51,103(5%)\n# of test set 5,628(5%) 586(100%) 50,979(5%)\nAvg # of words 368 253 72\nTable 7. Descriptive statistics of the disease-level SNOMED-CT codes\nMean Std Min Max Median\nDepth (Distance from root) 5.0 1.5 0 11 5\nBranch (# of children) 1.9 8.9 0 891 0\nY. Zhang et al.\n7\nScripps Research Translational Institute npj Digital Medicine (2019)    35 \nFor training, we update the classiﬁer using its prediction of a diagnosis\nonly when all the ancestors of this diagnosis are true in the expert label. In\npractice, we ignore the binary cross entropy loss of the diagnosis if any\nancestor of this diagnosis is not true in the expert label.\nFor prediction, we only predict that the diagnosis is true when all the\nancestors of the diagnosis are predicted as true. In practice, we predict the\ndiagnosis as false if any of the ancestors of the diagnosis has been\npredicted to be false.\nDATA AVAILABILITY\nThe data were made available to Stanford for the current study, and are not publicly\navailable. The data are available from the authors upon reasonable request and with\npermission of the veterinary centers.\nCODE AVAILABILITY\nVetTag is freely available athttps://github.com/yuhui-zh15/VetTag.\nACKNOWLEDGEMENTS\nWe would like to acknowledge Devin Johnsen for her help in annotating the private\npractice records used in this work. We want to acknowledge Dr. Terry Ward and Mr.\nBob Provopulos at Colorado State University for critical assistance in patient record\ncoding and collating. We also want to thank Arturo Pineda for feedback. Our work is\nfunded by the Chan-Zuckerberg Investigator Program and National Science\nFoundation (NSF) Grant CRII 1657155. This work was also supported by a National\nHuman Genome Research Institute (NHGRI) grant funding the Clinical Genome\nResource (ClinGen).\nAUTHOR CONTRIBUTIONS\nY.Z. and A.N. share co-ﬁrst authorship. Y.Z., A.N. and J.Z. designed the project and\nwrote the paper. Y.Z. and A.N. developed VetTag and performed the analyses. J.Z.\nsupervised the project. A.Z. and R.P. helped to collect data and provided feedback.\nADDITIONAL INFORMATION\nSupplementary information accompanies the paper on the npj Digital Medicine\nwebsite (https://doi.org/10.1038/s41746-019-0113-1).\nCompeting interests: The authors declare no competing interests.\nPublisher’s note:Springer Nature remains neutral with regard to jurisdictional claims\nin published maps and institutional afﬁliations.\nREFERENCES\n1. Rajkomar, A. et al. Scalable and accurate deep learning with electronic health\nrecords. NPJ Dig. Med.1, 18 (2018).\n2. Shickel, B., Tighe, P. J., Bihorac, A. & Rashidi, P. Deep ehr: a survey of recent\nadvances in deep learning techniques for electronic health record (ehr) analysis.\nIEEE J. Biomed. Health Inform.22, 1589–1604 (2018).\n3. LeBlanc, A. K., Mazcko, C. N. & Khanna, C. Deﬁning the value of a comparative\napproach to cancer drug development.Clin. Cancer Res.22, 2133–2138 (2016).\n4. Vainzof, M. et al. Animal models for genetic neuromuscular diseases. J. Mol.\nNeurosci. 34, 241–248 (2008).\n5. Gregory, M. H. et al. A review of translational animal models for knee osteoar-\nthritis. Arthritis 2012, 764621 (2012).\n6. Adin, C. A. & Gilor, C. Focus: Comparative medicine: the diabetic dog as a\ntranslational model for human islet transplantation. Yale J. Biol. Med. 90, 509\n(2017).\n7. Kol, A. et al. Companion animals: Translational scientist’s new best friends.Sci.\nTransl. Med. 7, 308ps21 (2015).\n8. Velupillai, S., Mowery, D., South, B. R., Kvist, M. & Dalianis, H. Recent advances in\nclinical natural language processing in support of semantic analysis.Yearb. Med.\nInform. 10, 183 (2015).\n9. Demner-Fushman, D. & Elhadad, N. Aspiring to unintended consequences of\nnatural language processing: a review of recent developments in clinical and\nconsumer-generated text processing.Yearb. Med. Inform.25, 224–233 (2016).\n10. Pivovarov, R. et al. Learning probabilistic phenotypes from heterogeneous ehr\ndata. J. Biomed. Inform.58, 156–165 (2015).\n11. Lipton, Z. C., Kale, D. C., Elkan, C. & Wetzel, R. Learning to diagnose with lstm\nrecurrent neural networks.arXiv preprint arXiv:1511.03677(2015).\n12. Baumel, T., Nassour-Kassis, J., Cohen, R., Elhadad, M. & Elhadad, N. Multi-label\nclassiﬁcation of patient notes: case study on icd code assignment. InWorkshops\nat the Thirty-Second AAAI Conference on Artiﬁcial Intelligence (2018).\n13. Prakash, A. et al. Condensed memory networks for clinical diagnostic inferencing.\nIn AAAI, 3274–3280 (2017).\n14. Peters, M. E. et al. Deep contextualized word representations. arXiv preprint\narXiv:1802.05365 (2018).\n15. Radford, A., Narasimhan, K., Salimans, T. & Sutskever, I. Improving language\nunderstanding by generative pre-training (2018).\n16. Nie, A. et al. Deeptag: inferring diagnoses from veterinary clinical notes.NPJ Dig.\nMed. 1, 60 (2018).\n17. Perotte, A. et al. Diagnosis code assignment: models and evaluation metrics.J.\nAm. Med. Inform. Assoc.21, 231–\n237 (2013).\n18. Vaswani, A. et al. Attention is all you need. InAdvances in Neural Information\nProcessing Systems, 5998–6008 (2017).\n19. Kim, Y. Convolutional neural networks for sentence classiﬁcation. arXiv preprint\narXiv:1408.5882 (2014).\n20. Hochreiter, S. & Schmidhuber, J. Long short-term memory. Neural Comput. 9,\n1735–1780 (1997).\n21. Johnson, A. E. W. et al. Mimic-iii, a freely accessible critical care database.Sci. data\n3, 160035 (2016).\n22. Mullenbach, J., Wiegreffe, S., Duke, J., Sun, J. & Eisenstein, J. Explainable prediction\nof medical codes from clinical text. InProceedings of the 2018 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Papers), 1101–1111 (2018).\n23. Kaiser, L. et al. One model to learn them all.arXiv preprint arXiv:1706.05137(2017).\n24. Aronson, A. R. & Lang, F.-M. An overview of metamap: historical perspective and\nrecent advances. J. Am. Med. Inform. Assoc.17, 229–236 (2010).\n25. Pedregosa, F. et al. Scikit-learn: Machine learning in Python.J. Mach. Learn. Res.\n12, 2825–2830 (2011).\n26. Jurafsky, D. & Martin, J. H.Speech and Language Processing: An Introduction to\nNatural Language Processing, Computational Linguistics, and Speech Recognition.\n1st edn (Prentice Hall PTR, Upper Saddle River, NJ, USA, 2000).\n27. Yang, Z., Dai, Z., Salakhutdinov, R. & Cohen, W. W. Breaking the softmax bottle-\nneck: A high-rank RNN language model. InInternational Conference on Learning\nRepresentations (2018).\n28. Bird, S. & Loper, E. Nltk: the natural language toolkit. InProceedings of the ACL\n2004 on Interactive poster and demonstration sessions, 31. Association for Com-\nputational Linguistics (2004).\n29. Sennrich, R., Haddow, B. & Birch, A. Neural machine translation of rare words with\nsubword units. In Proceedings of the 54th Annual Meeting of the Association for\nComputational Linguistics, Volume 1 (Long Papers), 1715–1725 (2016).\n30. Donnelly, K. Snomed-ct: The advanced terminology and coding system for\nehealth. Stud. Health Technol. Inform.121, 279 (2006).\n31. O’malley, K. J. et al. Measuring diagnoses: Icd code accuracy.Health Serv. Res.40,\n1620–1639 (2005).\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the Creative\nCommons license, and indicate if changes were made. The images or other third party\nmaterial in this article are included in the article’s Creative Commons license, unless\nindicated otherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons license and your intended use is not permitted by statutory\nregulation or exceeds the permitted use, you will need to obtain permission directly\nfrom the copyright holder. To view a copy of this license, visithttp://creativecommons.\norg/licenses/by/4.0/.\n© The Author(s) 2019\nY. Zhang et al.\n8\nnpj Digital Medicine (2019)    35 Scripps Research Translational Institute"
}