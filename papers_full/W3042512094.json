{
  "title": "BERTERS: Multimodal representation learning for expert recommendation system with transformers and graph embeddings",
  "url": "https://openalex.org/W3042512094",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A5084161457",
      "name": "Narjes Nikzad-Khasmakhi",
      "affiliations": [
        "University of Tabriz"
      ]
    },
    {
      "id": "https://openalex.org/A5089205977",
      "name": "Mohammad Ali Balafar",
      "affiliations": [
        "University of Tabriz"
      ]
    },
    {
      "id": "https://openalex.org/A5056445813",
      "name": "Mohammad‐Reza Feizi‐Derakhshi",
      "affiliations": [
        "University of Tabriz"
      ]
    },
    {
      "id": "https://openalex.org/A5026725002",
      "name": "Cina Motamed",
      "affiliations": [
        "Université d'Orléans"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3039137888",
    "https://openalex.org/W3112756409",
    "https://openalex.org/W4288083766",
    "https://openalex.org/W2025605741",
    "https://openalex.org/W1139185857",
    "https://openalex.org/W2065877818",
    "https://openalex.org/W2939250612",
    "https://openalex.org/W1989298268",
    "https://openalex.org/W6750233373",
    "https://openalex.org/W6663296103",
    "https://openalex.org/W2947008755",
    "https://openalex.org/W6683674676",
    "https://openalex.org/W2004749298",
    "https://openalex.org/W3081889057",
    "https://openalex.org/W6772152462",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W2891177506",
    "https://openalex.org/W3001252854",
    "https://openalex.org/W6948116018",
    "https://openalex.org/W6707620307",
    "https://openalex.org/W6773616876",
    "https://openalex.org/W6768464860",
    "https://openalex.org/W2585027938",
    "https://openalex.org/W2963797960",
    "https://openalex.org/W6650438560",
    "https://openalex.org/W2099386756",
    "https://openalex.org/W2611228204",
    "https://openalex.org/W6640404942",
    "https://openalex.org/W3137012641",
    "https://openalex.org/W6782109901",
    "https://openalex.org/W2765484901",
    "https://openalex.org/W2920503532",
    "https://openalex.org/W6680511098",
    "https://openalex.org/W6756112785",
    "https://openalex.org/W2510295449",
    "https://openalex.org/W6745766045",
    "https://openalex.org/W6726757218",
    "https://openalex.org/W7055618970",
    "https://openalex.org/W6730954720",
    "https://openalex.org/W2078784669",
    "https://openalex.org/W2578606145",
    "https://openalex.org/W2908274699",
    "https://openalex.org/W6789915741",
    "https://openalex.org/W3156333129",
    "https://openalex.org/W6761749748",
    "https://openalex.org/W2009746817",
    "https://openalex.org/W2963224980",
    "https://openalex.org/W2612872092",
    "https://openalex.org/W2071956453",
    "https://openalex.org/W3185161717",
    "https://openalex.org/W3161419939",
    "https://openalex.org/W3047376427",
    "https://openalex.org/W3049143069",
    "https://openalex.org/W1925528506",
    "https://openalex.org/W2912193172",
    "https://openalex.org/W2156445059",
    "https://openalex.org/W2962756421",
    "https://openalex.org/W3015777882",
    "https://openalex.org/W2619383789",
    "https://openalex.org/W3097232347",
    "https://openalex.org/W2132613313",
    "https://openalex.org/W1996203480",
    "https://openalex.org/W4210535201",
    "https://openalex.org/W1890727290",
    "https://openalex.org/W2311697578",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2975788427",
    "https://openalex.org/W3122507327",
    "https://openalex.org/W1608019811",
    "https://openalex.org/W3071070866",
    "https://openalex.org/W3137799364",
    "https://openalex.org/W2798433136",
    "https://openalex.org/W4237977885",
    "https://openalex.org/W3199252595",
    "https://openalex.org/W2561827022",
    "https://openalex.org/W2610512602",
    "https://openalex.org/W2739273093",
    "https://openalex.org/W4239110337",
    "https://openalex.org/W2022149269",
    "https://openalex.org/W3126099397",
    "https://openalex.org/W2962833907",
    "https://openalex.org/W2000389083",
    "https://openalex.org/W1986044318",
    "https://openalex.org/W1535467187",
    "https://openalex.org/W2051549144",
    "https://openalex.org/W3002085040",
    "https://openalex.org/W2767580670",
    "https://openalex.org/W2519076635",
    "https://openalex.org/W3104097132",
    "https://openalex.org/W4229811062",
    "https://openalex.org/W4286431284",
    "https://openalex.org/W2739535923",
    "https://openalex.org/W2053485498",
    "https://openalex.org/W2611311161",
    "https://openalex.org/W2995256665",
    "https://openalex.org/W4250485806",
    "https://openalex.org/W2984100107",
    "https://openalex.org/W3006484790",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3005845839",
    "https://openalex.org/W2465787853",
    "https://openalex.org/W2161479044",
    "https://openalex.org/W2911840101"
  ],
  "abstract": null,
  "full_text": "BERTERS: Multimodal Representation Learning for Expert\nRecommendation System with Transformer\nN. Nikzad–Khasmakhia, M. A. Balafara,∗, M. Reza Feizi–Derakhshia, Cina Motamedb\naDepartment of Computer Engineering, University of Tabriz, Tabriz, Iran\nbDepartment of Computer Science, University of Orleans, Orléans, France\nAbstract\nThe objective of an expert recommendation system is to trace a set of candidates’ expertise and preferences,\nrecognize their expertise patterns, and identify experts. In this paper, we introduce a multimodal classiﬁcation\napproach for expert recommendation system (BERTERS). In our proposed system, the modalities are derived\nfrom text (articles published by candidates) and graph (their co-author connections) information. BERTERS\nconverts text into a vector using the Bidirectional Encoder Representations from Transformer (BERT).\nAlso, a graph Representation technique called ExEm is used to extract the features of candidates from\nco-author network. Final representation of a candidate is the concatenation of these vectors and other\nfeatures. Eventually, a classiﬁer is built on the concatenation of features. This multimodal approach can be\nused in both the academic community and the community question answering. To verify the eﬀectiveness of\nBERTERS, we analyze its performance on multi-label classiﬁcation and visualization tasks.\nKeywords: Multimodal representation learning, Expert recommendation system, Transformer, Graph\nembedding\n1. Introduction\nRecently, the shadow of recommendation system (RS) has appeared on various domains and applications.\nOn the other hand, signiﬁcant new advances in deep learning approaches have important eﬀects on the\ntremendous success of the recommendation system [1]. The overall structure of a RS follows a set of phases\nincluding collection, learning, and recommendation [2, 3]. In the ﬁrst phase, appropriate resources that\ncomprise the relevant information of users are selected. Then, a leaner (supervised or unsupervised learning)\nanalyzes the users’ preferences, and extracts their behavioral patterns. Final phase recommends the entities\nthat are the most similar to the users’ interests. It is important to recognize that, within a common core\n∗Corresponding author\nEmail addresses: n.nikzad@tabrizu.ac.ir (N. Nikzad–Khasmakhi ),balafarila@tabrizu.ac.ir (M. A. Balafar ),\nmfeizi@tabrizu.ac.ir (M. Reza Feizi–Derakhshi),motamed@free.fr (Cina Motamed)\nPreprint submitted to Journal of Pattern Recognition July 15, 2020\narXiv:2007.07229v1  [cs.IR]  30 Jun 2020\nstructure of RS, there are variations from application to application. Some of the most sophisticated and\nheavily used RSs in industry are Last.fm, YouTube, and Amazon.\nFurthermore, we can ﬁnd the footprint of RS in the knowledge management system where RS tries to\nspecify experts who have the most relevant knowledge about a particular topic [4, 5]. This category of RS is\ncalled expert recommendation system (ERS) or expert ﬁnding system. So, it is obvious that an ERS has\nsimilar phases compared to general RSs. An ERS takes a user topic or query, traces a set of candidates’\nexpertise, learns their expertise patterns, and ﬁnally produces a list of experts sorted by a score. Each\ncandidate’s score indicates the degree of this candidate’s relevant expertise with the given topic. In the most\nstudies, the candidates’ expertise is deﬁned as content-based information and non-content-based information\n[6]. Content-based information is candidates’ shared textual content like their articles, questions, answers\nand so on. In contrast, candidates’ interactions with each others in social networks make non-content-based\ninformation. Depending on the application scenarios, each ERS has its own set of contextual information.\nFor example, in academic environment, the attempt is to detect researchers who have the subject areas\nrelated to the query. This detection is based on the content of the articles published by them and their\nco-author relations in diﬀerent papers. However, in Community Question Answering (CQA), the main goal\nis to ﬁnd the users with expertise and willingness to answer the given questions in terms of the content of\nthe question asked and the answered posted by them, and their question-answer relations [7].\nWith a brief look at previous studies, it can be concluded that there are three diﬀerent outlooks on\nERSs. In one of the attitudes, studies have focused on the textual expertise of candidates. These works\nhave used text mining or information retrieval techniques and selected ones as experts who their published\nitems are semantically relevant to the query [8]. On the other hand, some other researches have investigated\nthe social relations between candidates and represented their connections as a graph [9]. After that, social\nnetwork analysis and mining techniques, such as page ranking algorithms, are applied on this graph to\nidentify important candidates and rank them. Moreover, recent studies have shown that the combination of\ndiﬀerent types of expertise information have notable performance compared to other. A number of them have\nintegrated textual expertise and social network connection information with linear or nonlinear functions.\nAlso, to achieve higher accuracy, a few authors proposed the usage of heterogeneous network which is a\ncombination of the users’ interactions in social networks and their question–answer relationships in CQAs\nbesides bearing in mind the content of questions and answers.\nIn recent years, multimodal machine learning has been attracting attention. This popularity is because of\nhuge multimodal content being generated by the users of social media networks [10] . The goal of multimodal\nmachine learning is to create a joint model that can retrieve contextual information from multiple modalities\n[11]. In this research, we aim to ﬁnd academic experts that whether using a multimodal learning approach\nprovides an eﬀective solution for ERS or not. Also, the other purpose of our work is to solve the expert\nﬁnding problem as a multi-label classiﬁcation task. In such a way, we combine text (articles) and graph\n2\n(co-author connections) information in a multimodal approach. The text component is converted into vector\nusing BERT Transformer. On the other hand, to obtain the node representation of candidates, a graph\nembedding technique, ExEm introduced in [12], is used. Also, normalized h-index value of candidate is added\nas another feature. Then, the captured fusion features are fed to train the classiﬁer. We evaluate BERTERS\non the multi-label classiﬁcation and visualization tasks. However, to the best of our knowledge, we present\nthe ﬁrst approach in ﬁeld of expert recommendation using multimodal learning and transformers.\nThe rest of the paper is structured as follows: Section 2 reviews the related works. Section 3 discusses\nthe background of the research. Section 4 presents our proposed method and explains it in detail. The\ndescriptions of the dataset and the tasks that are used to test our proposed method and parameter setting\nare presented in Section 5. Section 6 provides and discusses the experimental results. Finally, Section 7\nconcludes the paper.\n2. Related Work\nIn this section, we review the approaches proposed for ERS. We group these models into the three\ncategories, based on their main outlooks: document-based, graph-based and hybrid models. The bellow\nsubsections will explain the underlying method logy and existing approaches for the speciﬁed categories. In\ncase of reader curiosity, we highly recommend reading [5] that explains in more detail and is dedicated to\nreview all the related articles in this scope.\n2.1. Document-based models\nDocument-based models are intended to compare the characteristics of the content contained in the\npublished items associated with a candidate and the query. On the other hand, document-based models\nwork well where capturing the level of expert’s knowledge in the ﬁeld of the topic query is the goal. A\nnumber of works employed topic modeling techniques for this task. In study [13], authors suggested a\nframework to automatically direct new questions to the best experts based on tracking their answering\nhistory in the community. Their proposed solution employed diﬀerent methods consisting language models\nwith Dirichlet smoothing, TF-IDF, Latent Dirichlet Allocation (LDA) and Segmented Topic Model for this\naim. Research [14] applied LDA method to collect the topics of documents. After that, the probability of\neach candidate query is calculated based on the extracted topics for each query. Experts are sorted according\nto this probability. In another paper, Neshati et al. [15] emphasized on the dynamic aspects of the expert\nﬁnding. Authors considered four content features including topic similarity, emerging topics, user behavior\nand topic transition features to predict the best ranking of experts in future. There are other interesting\ndocument-based models. Nobari et al. [16] proposed two translation models based on a statistical approach\n3\nand a word embedding model. [17] presented a tag-LDA approach to model the candidate topic distribution.\nDespite the fact that document-based approaches are helpful in ﬁnding the knowledgeable candidates, they\ncan not detect the important or inﬂuential experts in the social network.\n2.2. Graph-based models\nDocument-based models recognize expertise patterns across documents, whereas graph-based approaches\nlearn to recognize patterns across graph. Graph-based models work well where authority and reputation\nscores of candidates are important. Authority score measures the inﬂuence and popularity of candidates\nin social networks. On the other hand, candidates with high reputation scores share more knowledge and\ninformation with others in the communities [5]. The graph-based method formulates the problem of ERS\nfrom the perspective of a graphG(V, E), whereV denotes a set of candidates andE a set of edges among\nthe nodes. Depending on the applications at hand, nodes can represent candidate experts of various types\nsuch as academic candidates. On the other hand, edges represent diﬀerent types of relations between any\ncandidates, such as question posters and repliers relations in CQA or follower-following connections in social\nnetworks, etc. Most previous graph-based methods were used PageRank and HITS, two popular link analysis\napproaches to measure the similarity between candidates with a topic query, calculate candidates’ scores\nand make recommendation. Fu et al. [18] proposed an expertise propagation algorithm that is very similar\nto PageRank to build the relationship between candidates. Zhang et al. [19] used the authority value of\nHITS algorithm to select a user as expert who helps many others. Also, authors introduced ExpertiseRank,\nan algorithm similar to PageRank, to measure experts’ authorities [20]. Also, there are some other papers\nfocusing on detecting the top-K inﬂuential candidates in communities [21]. Mumtaz and Wang [22] proposed\na simple technique to ﬁnd the inﬂuential node set in a network with largest betweenness centrality. Paper [23]\nreviewed the existing works on identifying top-k inﬂuential and signiﬁcant nodes. Although, the graph based\napproaches ﬁnd the inﬂuential candidates in the social network, they fail to consider each expert candidate’s\ntopical expertise.\n2.3. Hybrid models\nHybrid models have drawn a lot of attention for ERS in recent years. These methods have been developed\nto combine features extracted from the documents (or questions and answers), and features obtained from\ncandidates’ social network communications to formulate a recommendation. It should be noted that hybrid\nmodels need to use a feature-combination method to merge content and non-content expertise and calculate\nscores. This section reviews some of the most prominent hybrid models which created new state-of-the-arts\non ERS. Zhao et al. [24] proposed a hybrid model (GRMC) created from both the social relationship between\ncandidates and their history of questions and answers. In proposed model, the goal is to consider expert\n4\nﬁnding as missing value estimation and estimate values via a matrix completion method. In [25], Zhao\net al. proposed a ranking metric network learning framework (RMNL) for the problem of expert ﬁnding.\nAs illustrated in Fig 1, they performed a heterogeneous CQA network built by the combination of both\ncandidates’ relative quality rank to questions and their social connections. Sang et al. [26] proposed a hybrid\nmodel (MMSE) which is similar to GRMC in [25]. Authors designed a bayesian embedding model which\nintegrates multiple modalities and multiple semantic perspectives. Zhou et al. [27] considered the candidate\nexpertise and reputation score for ﬁnding experts. They proposed a user-topic model to analyze the content\nof the questions and answers. Moreover, authors introduced a topic-sensitive method to reﬂect both the link\nstructure and the topic relevance between questioners and answerers. In [28], Liu et al. merged knowledge,\nreputation and authority scores of candidates to produce a recommended expert list. Knowledge score shows\nthe similarity of the proﬁle and the target question. Moreover, the number of answers and best answers given\nby candidates are used to ﬁnd the reputation score. Finally, the authority score is calculated using HITS\nand Page Rank approaches. Xie et al. [29] used LDA and HITS algorithms to extract topical feature. The\nsuggested method evaluated social relation, time and location factors in order to extract contextual features.\nFinally, a SVM algorithm was used as scoring function. There are other interesting hybrid models including\nCQARank [30], ExpertRank [6], Expert2Vec [8]. The hybrid models have achieved high accuracy on many\nERS benchmarks. But, the important point in these approaches is how to combine text and link elements to\ndetecting experts.\nFigure 1: The architecture of ranking metric network learning framework [25].\n3. Background\nIn this section, we discuss the concepts which organize the background of our study. In this way, ﬁrstly,\nthe text representation method, BERT Transformer, is explained. After that, the graph embedding technique,\nExEm, is introduced.\n5\n3.1. Text representation learning\nIn recent years, researchers have devoted many eﬀorts on extracting features from text data, and have\nproposed many models including neural embedding, attention mechanism, self attention, and Transformer.\nAs investigated in many papers, the sequential processing of text and the computational cost of obtaining\nremarkable relationships between words in a sentence are two issues that RNN and CNN models are\nencountered with, respectively. On the other hand, Transformers eliminate these bottlenecks by assigning in\nparallel an attention score to each word in a document to consider the impact of words on each others [31].\nFig 2 illustrates the architecture of the Transformer model that comprises of both encoding and decoding\ncomponents which are all identical in structure. These components include the stacked layers. For example,\nthe encoding component is a stack of encoders where each stack layer is broken down into two sub-layers.\nEach sub-layer has a multi-head attention layer and a feed-forward neural network. The multi-head attention\nlayer extracts the dependencies between representation pairs regardless of the distance between them in the\nsequence and is more eﬀective than single-head attention [31, 32]. The outputs of the the attention layer\nare injected to the feed-forward. For each set of queriesQ, keysK and valuesV , the multi-head attention\nmodule appliesh attention functions which is the scaled dot-product attention as shown in equation 1.\nAttention(Q, K, V) = softmax(QKT\n√dk\n)V (1)\nScaled Dot-Product\nAttention\nFF \nFF \nFF \nScaled Dot-Product\nAttention\nFF \nFF \nFF \nScale \nSoftmax \nMatMul Q \nK \nV \nMatMul \nScaled Dot-Product\nAttention\nQ \nK \nV \nFF \nFF \nFF \nh \nConcat \nFF \nFigure 2: The Transformer model architecture [33]\nOne the most widely used Transformer models is BERT Transformer [34] that is the new state-of-the-art\nsentence embedding models [31]. The BERT Transformer architecture is shown in 3. A masked language\nmodeling task is used for training BERT. It randomly selects some tokens in a text sequence for masking,\nand then independently retrieves the masked tokens by conditioning on the encoding vectors which are the\noutputs of a bidirectional Transformer. For using BERT, ﬁrstly, two tokens, that are known as[CLS] and\n[SEP ], are added at the beginning and the end of the text input, respectively. After that, the input ﬂows\n6\nthrough the two transformer layers. The output of the last transformer layer is the embedding of the input.\nBrieﬂy, BERT model has two parametersh and L. h is the size of the output embedding vector andL shows\nthe number of stacked layers in each component.\nThis paper proposed new approach[CLS] [SEP]\nECLS E1 E 5 E SEP \nTrm\nThis\nTrm Trm Trm...\n... ...\n... ...\n...\nTrm Trm Trm Trm\nTCLS T1 TN TSEP\n... ... ...\n... ... ...\nESEP\n[SEP]\nE5\nFigure 3: The BERT Transformer architecture.\n3.2. Node representation learning\nOne of the key concepts in the analysis of social networks is the idea of presenting the knowledge inside\nthem as a graph structure [35]. On the other hand, in the recent times, one of the most widely used graph\nanalysis approaches is graph embedding. Graph embedding represents the graph nodes as low-dimensional\nvectors [36, 37]. It gives us a deeper vision to analyze users’ activity patterns and their relationships in social\nnetworks. A number of recent techniques have developed to embed graph nodes. In our study, we focus on\nthree embedding techniques including DeepWalk [38], Node2vec [39] and ExEm [12] that employ random\nwalks on a graph to obtain node representations.\nDeepWalk is the ﬁrst eﬀort proposing the deep learning techniques into graph analysis. Because the\nrandom walks can govern the structure of graph, DeepWalk uses a stream of short random walks. It considers\neach random walk as a sentence, and the graph nodes as words. Therefore, authors generalized the idea of\nlanguage modeling in NLP to explore the graph. The aim of language modeling is compute the probability\nof a sentence or the sequences of words as shown in equation 2.\nP(w) = P(w1w2...wm) =\nm∏\ni=1\nP(wi|w1w2...w(i −1)) = P(w1)P(w2|w1)P(w3|w1w2)...P(wm|w1...wm−1) (2)\nTo transfer the language modeling into the graph, the task is to estimate the probability of equation 3.\nP(vi|(v1v2...vi−1)) = P(vi|Φ(v1)Φ(v2)...Φ(vi−1)) =\nm∏\ni=1\nP(vi|Φ(v1)Φ(v2)...Φ(vi−1)) (3)\n7\nwhere Φ is the low-dimensional representation of each node in the graph.\nIn Node2vec, authors introduced a ﬂexible strategy to generate the node’s neighborhood. They designed\na biased random walk procedure based on the concept of the breadth-ﬁrst and depth-ﬁrst search algorithms.\nIn order to bias the random walks, two parametersp and q control the likelihood of immediately revisiting\na node in the walk and the distances from a given source node, respectively. Node2vec uses an extended\nversion of the Skip-gram architecture to optimize the stochastic gradient descent.\nExEm is another graph embedding technique that applies the dominating set theory on the graph and\nﬁnds the dominating nodes. Then, ExEm creates a set of random walks that contains at least two dominating\nnodes, and stores it as a corpus. In the next step, the corpus is fed to Word2vec, fastText and their\ncombination to train the Skip-gram neural network.\n4. Proposed Method\nThe aim of this paper is to design a new hybrid model with a multimodal neural network, which is called\nBERTERS, that is able to ﬁnd academic experts. The overall structure of BERTERS is shown in Fig 4.\nIn the ﬁrst step, we extract the adequate dataset from Scopus which is the largest abstract and citation\ndatabase. The gathered dataset includes the content and non-content features of expert candidates such\nas their published articles, subject areas, aﬃliations, h-index, and their co-author interactions. In the next\nphase, BERTERS takes as input the articles and the co-author connections that have various types (e.g.,\ntext and graph). Hence, these diﬀerent modalities enable a multimodal deep learning approach to create\ncomprehensive and meaningful representations of expert candidates. To capture candidates’ representations\nfrom these diﬀerent modalities, BERTERS is comprised of three diﬀerent neural networks: one for document\nrepresentation generation, the other one for node representation generation and the third one for learning a\nshared representation between modalities. Each feature is separately obtained from the respective neural\nnetwork and then merged with other features to create a single representation for each candidate. Finally,\nthe model provides a list of candidates as experts via collaborative ﬁltering.\nTo the best of our knowledge, BERTERS is the ﬁrst recommendation model for ERS that employs\nmultimodal learning and transformers. Although MMSE [26] proposed a multimodal approach for ﬁnding\nexperts in CQA, but BERTERS is the ﬁrst use of the multimodal classiﬁcation approach in the context\nof ERS in an academic community. As of another meaning, BERTERS perceives the ERS as a vision of\na multi-label classiﬁcation task using multimodal learning. In MMSE, authors used the Skip-gram model\nand DeepWalk to learn word embeddings and network-based user embeddings, respectively. Conversely,\nBERTERS employs BERT transformer and ExEm method to capture document and graph embeddings,\naccordingly. Also, our approach adds candidate’s h-index as another feature. The following subsections\ndescribe the procedures of BERTERS in detail.\n8\nRecommendation List\nMulti-modal deep\n learning approach\nFigure 4: The overall structure of BERTERS.\n4.1. Model Architecture\nAs it was mentioned previously, in this study, we introduce a multimodal deep learning approach that\nconsiders the ERS as a multi-label classiﬁcation task, shown in Fig 5. From this viewpoint, the prediction\nproblem becomes accurately classifying a speciﬁc expert candidate where the candidates’ subject areas are\ndeﬁned as their labels. This model can be formalized as computing the probability all possible subject areas\nfor an expert candidate based on the average of all document embedddingsDe, candidate social connection\nembeddding Ne, and h-indexHi:\nP(Csa|De, Ne, Hi) = P(vi|[De; Ne; Hi]) ≈P(Csa|E) (4)\nwhere E is deﬁned as the concatenation ofDe, Ne, Hiand applying three dense layers with ReLU function.\nIn other sense, the task is to learn expert candidate embeddingsE as a function of articles, co-author relations\nand h-index that is presented in equation 5.\n9\nE = ReLU(ReLU(ReLU([De; Ne; Hi]W)W)W) (5)\nThe direct analog is to estimate the likelihood of subject areas of a candidate based onE. Hence, a\nSigmoid classiﬁer applies on the embeddingE. Equation 6 shows this probability.\nP(Csa|E) = Sigmoid(E) (6)\n. \n. \n. \nAverage\nBERTExEm\nReLU (1024) \nReLU (256) \nReLU (512)  \nSigmoid\nNode embedding Document embeddingh-index (normalize) \nFigure 5: multimodal architecture of BERTERS\n4.2. Document representation generation\nAs it can be concluded from Fig 4, one of the BERTERS modalities is text information that comes from\nthe articles published by candidates. It aims at extracting distinguishing text expertise of candidates. As\npresented in Fig 5, we learn the representation of each document in a ﬁxed-sized via BERT Transformer\ndemonstrated in section 3.1. The input of BERT is an article of each candidate. The article passes through\nthe layers of BERT, and the output is its embedding. Consequently, a candidate’s content information is\nrepresented by a high-dimensional vector,De, which is the average of his/her all article embeddings.\nIt is worth noting that we can extend this procedure for the ERS in CQA. For this aim, the questions\nasked and the answers posted by candidates are fed into inputs of the BERT model. After that, the average\nof these embeddings are used as the text modality value.\n10\n4.3. Node representation generation\nLearning features of modalities is the foundation of multimodal deep learning approaches. As explained\nbefore, another modality in BERTERS fetches from candidates’ co-author network. To interpret information\nof this network, we use the graph embedding techniques, DeepWalk, node2vec, and ExEm that are described\nin section 3.2. The candidate’ node embedding representationNe is generated by applying the graph\nembedding method on the collaborative network.\nIn order to apply this strategy in CQA, the desired graph is constructed based on the interactions between\nquestion posters and repliers. Other steps are done as described above.\n4.4. Other features\nAdding features results in having a depth knowledge about candidates’ expertise, accurately learning\ntheir subject areas, and improving precision. Hence, we also add h-index of candidates in form of additional\nfeature. On the other hand, the proper normalization of features is critical for convergence. So, h-index is\nnormalized, deﬁned asHi, to combine with the features obtained from previous stages.\nTo use BERTERS in CQA system, we can add number of best answers provided by candidates, their\nreputation score, number of thumbs up and down as extra features.\n4.5. Joint Features\nThe important point in a multimodal deep learning model is to properly integrating multimodal features.\nBut in practice, combining diﬀerent modalities is challenging. Furthermore, modalities have diﬀerent\nquantitative eﬀects on the prediction output. There are at least three common ways to combine embedding\nvectors a single feature vector including: summing, averaging and concatenating [40].\nIn our case study, because the length of modality representations are not the same, it is not possible\nusing summing and averaging methods. In this way, we integrate all features into a single representation\nthrough concatenation and get1 ×L vector, whereL equals to the sum of the length of feature vectors. In\nthe next step, BERTERS employs a feed-forward neural network which consists of three stacked dense layers\nwith Rectiﬁed Linear Units (ReLU) activation function. The last layer is Sigmoid classiﬁer. To eﬃciently\ntrain BERTERS, a cross-entropy loss is minimized and embeddings are learned jointly with all other model\nparameters.\n5. Experiments\nIn this section, we present the details of the experiment process. We start with explaining the dataset\nand how it is obtained and the related information, later we jump into the experimental setup of our work\nand then tasks, model variation and metrics are described in order.\n11\n(a) IE topic\n (b) ML topic\n (c) NLP topic\nFigure 6: Word cloud presentation of articles related to the top experts for three topics\n5.1. Dataset\nTo evaluate the performance of BERTERS, we search for a dataset which guarantees both content and\nnon-content modalities. The dataset introduced in [12], gathered from Scopus eliminates the require to a\nlabeled data for constructing a collaborative network. The graph extracted from this dataset has arisen out\nof the collaborations of authors in diﬀerent articles. Each node presents an author that his/her subject areas\nare considered as node labels. Moreover, the edges indicate the co-author interactions between authors. This\ndataset only ensures the data of graph modality. To adapt this dataset to our multimodal approach, we\nextract some other features from Scopus for text modality. The obtained information consists of authors’\narticles, their h-index and aﬃliations. An important point about the dataset which our experiments use,\nis that the total number of the graph nodes is 27,473, but the text information is gathered only for 9,378\nauthors. The descriptions of the dataset is summarized in Table 1.\nTable 1: Dataset information.\n|V | |E| Labels # Articles # Authors with articles\n27,473 285,231 27 472,566 9,378\nBecause BERTERS is a supervised multimodal classiﬁcation approach, so it needs a ground truth for\nlearning. Hence, to ﬁnd a proper ground truth for our collected dataset, we follow the same procedure\ndescribed in [12]. We derive a list of experts fromArnetminer for three topics: information extraction (IE),\nnatural language processing (NLP), and machine learning (ML). This list of experts and the topics are\ndeﬁned as ground truth and query, respectively. Fig 6 shows the word cloud presentation of the articles\nrelated to the top expert in three topics.\n5.2. Experimental Setup\nIn our study, we employ a version of BERT called BERT-Small. Its encoding and decoding parts have 4\nstacked layers. Also, the size of the output embedding vector in BERT-Small is 512. The required information\n12\nabout setup is denoted in Table 2. Furthermore, Table 3 presents the information of system that the\nexperiments were performed on.\nBERT embedding vector size 512\nExEm embedding vector size 128\nh-index feature size 1\nTotal embedding size 641\nNumber of classes 27\nNumber of clusters 3\nTable 2: Experimental setup\nTable 3: System Information.\nModel Description\nOS Ubuntu 18.04.3 LTS -\nRAM - 26G\nCPU Intel(R) Xeon(R) 2.20GHz\nGPU NVIDIA Tesla P100\n5.3. Tasks\nWe evaluate the performance of BERTERS on two tasks including multi-label classiﬁcation and visualiza-\ntion that are described in the following.\n5.3.1. Multi-Label Classiﬁcation\nIn this task, the eﬀort is to predict the labels of candidates with high precision. In our work, the labels of\ncandidates are deﬁned according to their subject areas and represented as a one-hot numeric array.\n5.3.2. Visualization\nVisualization assists in the achievement of more vision into the structure of the network. BERTERS\nillustrates the goodness of its embedding approach by clustering together experts based on three topics.\n5.4. Model Variations\nWe experiment with several variants of the model.\nBERT: This model only operates on authors’ articles. Each article is presented by a vector created form\nBERT transfromer.\n13\nExEm(fastText): It is a version of ExEm that engages fastText method to learn the node representation.\nExEm(Word2Vec): This one is another form of ExEm that allows to create vector representations for\nnodes by using Word2Vec.\nBERTERS(ExEm(fastText)): It is the combination of text and graph modalities. Text features are\nobtained by BERT transformer from articles. On the other side, ExEm(fastText) extracts node features\nfrom co-author graph.\nBERTERS(ExEm(Word2Vec)): SameasabovebutthenodevectorsarecapturedbyExEm(Word2Vec).\nBERTERS(Node2Vec): This architecture is almost identical to the previous one. The diﬀerence is\nthat Node2Vec approach creates the node vectors.\nBERTERS(DeepWalk): In this structure, DeepWalk derives the nodes features. The rest of the\nprocedure is similar to the other BERTERS variations.\n5.5. Evaluation Metrics\nThe main metric which is used to evaluate the micro and macro F1 score that is expressed by the equation\n7. From this equation,Pr denotes precision andRe denotes recall. However, this form ofF1 is for general\npropose and not for macro and micro. The macro and microF1 is expressed by using micro and macro\nprecision and recall instead.\nF1 = 2 ×Pr ×Re\nPr + Re (7)\nUsing micro and macro evaluation metrics makes sense in using multilabel or multi-dataset evaluations. In\nour work, a multilabel task has been proposed and accordingly, the micro and macro F1 should be reported.\nFor computing the precision and recall, in micro, equations 8 and 9 express the mathematical deﬁnition; For\nthe macro precision and recall, 10 and 11 present deﬁnitions respectively.\nmicroPr =\n∑\nc∈Classes\nTPc\n∑\nc∈Classes\n(TPc + FPc) (8)\nmicroRe =\n∑\nc∈Classes\nTPc\n∑\nc∈Classes\n(TPc + FNc) (9)\nmacroPr = 1\nN(Classes)\n∑\nc∈Classes\nPrc (10)\nmacroRe = 1\nN(Classes)\n∑\nc∈Classes\nRec (11)\n14\n6. Results\nIn this section, we investigate the eﬃciency of diﬀerent embeddings on the tasks presented above. We\nalso present the eﬀect of number of embedding dimensions on the performance for each task.\n6.1. Multi-Label classiﬁcation\nEvaluation and comparison of our proposed models is acquired by using the equations from subsection\n5.5. Macro and micro F1 score of our method with its diﬀerent variations are presented in tables 4 and 5.\nUtilization of text modality with the representation obtained from graph by diﬀerent graph representation\nlearners and our trained BERT model, shows that our hypothesis about using multimodal learning and\nobtaining better results is true. However, based on the learner itself that is the base for graph representation\nlearning, BERTERS(ExEm(fastText)) is far better than others.\nAs it can be concluded from the tables, two single-modality based methods, BERT and ExEm produce\npoor consequences. However, employing document embeddings built by BERT presents better outcomes than\nnode embeddings obtained from ExEm. In contrast, using the multimodal approach can signiﬁcantly improve\nthe performance of ERS than single modal. Among variants of BERTERS, BERTERS(ExEm) achieves high\nmicro and macro values in most cases. It comes from the fact that ExEm eﬀectively monitors the network by\nhelp of dominating nodes. Although, DeepWalk and Node2vec also are random walk based methods but their\nwalks do not provide enough information about nodes [12]. On the other hand, the results prove the eﬃciency\nof BERTERS(Node2Vec) than BERTERS(DeepWalk) due to designing biased random walk procedure.\nEﬀect of dimension. We conduct investigations on the eﬀect of dimension on the multi-Label classiﬁ-\ncation task. For this goal, we change the embedding size of last ReLU layer in Fig 5. Figure 7 illustrates the\nresults of Micro-F1 and Macro-F1 for BERTERS(ExEm(fastText)) by varying the number of dimensions.\nAs the number of dimensions increase, the capable of storing more information becomes higher. Hence, We\nobserve that the Micro and Macro values enhance as the number of dimensions rise.\n6.2. Visualization\nFigure 8 shows the obtained results for the visualization task. Three diﬀerent topics are used to\ncolor the nodes. Figures (a) to (c) respectively cluster experts based on ExEm(fastText), BERT, BERT-\nERS(ExEm(fastText)) that is the concatenation of ExEm(fastText), BERT and normalized h-index and\nhas 641 dimensions. Although ExEm embeds experts farthest apart, but embeddings generated by BERT-\nERS(ExEm(fastText)) well separate the communities. The reason is that three topics have overlaps, and a\ncandidate can be expert in all of them. Thus the partition originated by this approach is more meaningful.\nIn contrast, BERT embeds communities very closely.\n15\nEﬀect of dimension. Figures (c) to (f) illustrate the eﬀect of dimension on visualization. We make\nthe observation that the performance of clustering improves as the number of dimensions grow. BERT-\nERS(ExEm(fastText)) with dimensions 64 and 256 attempt to cluster experts with high intra-cluster edges\ntogether. By comparison, BERTERS(ExEm(fastText)) with size 512 preserves the community structure\nbetter than low dimensions. Finally, the embeddings created from the concatenation can ﬁnd the overlapping\ncommunities in which experts are interested in the same topic.\n6.3. Discussion\nThe presented results in tables 5 and 4 shows the comparison of our proposed multimodal approach using\ndiﬀerent setups. From these tables, BERTERS(ExEm(fastText)) and BERTERS(ExEm(Word2Vec)) are\nsuperior to other in terms of metrics. The reason behind this superiority is because of utilization ExEm. This\nmethod provides better graph presentation compared to others by using dominating set theories and thus, it\nis able to provide better results in various tasks such as classiﬁcation. On the other hand, combination of\ndocument and graph modalities provides more accurate results because of adding extra textual information\nto existing method. According to our experiments, better presentation in both sides, text and graph, yields\nin better results for classiﬁcation task but using which algorithm for presenting is hard choice and requires\nexperiments to be evaluated.\nFigure 8 shows the visualization results for diﬀerent setup that clearly from this ﬁgure is seen the\nembedding size is also another important hyper-parameter that aﬀects the presentation. Part (a) from this\nﬁgure shows using ExEm without document data that yields to completely separating three subject areas\nof ML, NLP and IE that we know is not correct due to the fact that there are signiﬁcant overlaps among\ntopics. Having this in mind, and what is clearly seen from part (f), this separation is not done completely for\nauthors who have been working in multiple ﬁelds such as IE and NLP together or any other combination of\nthese three subject areas. A clear separation in this presentation is not always acceptable and for some hard\ncases such as what is shown in this ﬁgure, the inseparable subject areas must have collisions in some cases.\nIt is worth noting that gain in performance with increasing dimensions can be observed in both tasks. As\na conclusion, the best embeddings for ﬁnding experts in a ERS are directly generated from the concatenation\nof their values of normalized h-index, their presentations obtained from a co-author network by ExEm and\nexperts’ published items that converted into vectors by BERT. As mentioned in previous sections, it is\npossible to extend BERTERS into CQA to ﬁnd the best users for answering the posted questions.\n7. Conclusion\nIn this paper, a multimodal classiﬁcation approach, called BERTERS, has been proposed for expert\nrecommendation system. In BERTERS, each candidate expert is represented by a vector which is the\n16\nModel Train ratio\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\nBERT 0.6258 0.6565 0.6562 0.6624 0.6699 0.6602 0.6706 0.6718 0.6605\nExEm(fastText) 0.5207 0.5309 0.5438 0.55 0.5628 0.5668 0.5655 0.5753 0.5769\nExEm(Word2Vec) 0.5187 0.521 0.5489 0.5491 0.5604 0.5655 0.5631 0.5683 0.5686\nBERTERS(DeepWalk) 0.6497 0.6902 0.698 0.6973 0.6961 0.709 0.7098 0.7065 0.7129\nBERTERS(Node2Vec) 0.6648 0.6922 0.6951 0.7042 0.7042 0.714 0.7118 0.7025 0.7088\nBERTERS(ExEm(Word2Vec) 0.6552 0.6906 0.6809 0.7047 0.7048 0.7042 0.7072 0.7058 0.7127\nBERTERS(ExEm(fastText)) 0.6609 0.6924 0.6977 0.7001 0.7059 0.7129 0.7124 0.7141 0.7182\nTable 4: Micro-F1 of multi-label classiﬁcation task varying the train-test split ratio\nTable 5: Macro-F1 of multi-label classiﬁcation task varying the train-test split ratio\nModel Train ratio\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\nBERT 0.4721 0.5201 0.5242 0.5306 0.5511 0.5284 0.533 0.5212 0.5361\nExEm(fastText) 0.3728 0.3953 0.4031 0.4035 0.4231 0.4294 0.4357 0.4284 0.4269\nExEm(Word2Vec) 0.3703 0.3783 0.4041 0.4062 0.4236 0.4253 0.4255 0.424 0.4227\nBERTERS(DeepWalk) 0.5086 0.5686 0.5818 0.5747 0.5774 0.5876 0.5856 0.5785 0.5809\nBERTERS(Node2Vec) 0.5263 0.5707 0.5731 0.5841 0.58 0.5981 0.5768 0.587 0.5769\nBERTERS(ExEm(Word2Vec) 0.5137 0.5636 0.5712 0.5735 0.5803 0.5813 0.5819 0.5811 0.5878\nBERTERS(ExEm(fastText)) 0.5257 0.5702 0.5737 0.5743 0.5817 0.5836 0.5857 0.5883 0.5942\nconcatenation of three important features. One feature is the average of embeddings of all articles concerned\nwith an expert. Each article converts to a vector by using BERT transformer. The second feature comes\nfrom applying a graph embedding technique on the co-author graph. BERTERS uses three diﬀerent graph\nembedding approaches including DeepWalk, Node2vec and ExEm. Finally, normalized value of h-index is\nconsidered as third feature. Then, the concatenation of features is fed into a classiﬁer that composes of three\ndense layers with ReLU function. In the ﬁnal step, the performance of BERTERS was evaluated on the\nmulti-label classiﬁcation and visualization tasks and seven variants of the model. The results show that\nBERTERS(ExEm(fastText)) performs better than the other variants.\nReferences\n[1] S. Zhang, L. Yao, A. Sun, Y. Tay, Deep learning based recommender system: A survey and new perspectives (2019).\narXiv:1707.07435, doi:10.1145/3285029.\n17\n64 128 256 512\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7 0.6969 0.698 0.7059 0.7079\n0.5678 0.5794 0.5817 0.5873\nMicro Macro\nFigure 7: Micro-F1 and Macro-F1 of multi-label classiﬁcation task for BERTERS(ExEm(fastText)) varying the number of\ndimensions. The train-test split is 50\n[2] J. Bobadilla, F. Ortega, A. Hernando, A. Gutiérrez, Recommender systems survey, Knowledge-Based Systems (2013).\ndoi:10.1016/j.knosys.2013.03.012.\n[3] F. O. Isinkaye, Y. O. Folajimi, B. A. Ojokoh, Recommendation systems: Principles, methods and evaluation (2015).\ndoi:10.1016/j.eij.2015.06.005.\n[4] L. Zhen, H. T. Song, J. T. He, Recommender systems for personal knowledge management in collaborative environments,\nExpert Systems with Applications (2012).doi:10.1016/j.eswa.2012.04.060.\n[5] N. Nikzad-Khasmakhi, M. Balafar, M. R. Feizi-Derakhshi, The state-of-the-art in expert recommendation systems,\nEngineering Applications of Artiﬁcial Intelligence 82 (2019) 126–147.\n[6] G. A. Wang, J. Jiao, A. S. Abrahams, W. Fan, Z. Zhang, ExpertRank: A topic-aware expert ﬁnding algorithm for online\nknowledge communities, Decision Support Systems (2013).doi:10.1016/j.dss.2012.12.020.\n[7] S. Yuan, Y. Zhang, J. Tang, J. B. Cabotà, Expert ﬁnding in community question answering: A review, CoRR abs/1804.07958\n(2018).\n[8] S. Mumtaz, C. Rodriguez, B. Benatallah, Expert2Vec: Experts Representation in Community Question Answering for\nQuestion Routing, in: Lecture Notes in Computer Science (including subseries Lecture Notes in Artiﬁcial Intelligence and\nLecture Notes in Bioinformatics), 2019.doi:10.1007/978-3-030-21290-2_14 .\n[9] K. H. Yang, C. Y. Chen, H. M. Lee, J. M. Ho, EFS: Expert ﬁnding system based on wikipedia link pattern analysis, in:\nConference Proceedings - IEEE International Conference on Systems, Man and Cybernetics, 2008.doi:10.1109/ICSMC.\n2008.4811348.\n[10] T. Baltrusaitis, C. Ahuja, L. P. Morency, Multimodal Machine Learning: A Survey and Taxonomy (2019).arXiv:1705.09406,\ndoi:10.1109/TPAMI.2018.2798607.\n[11] F. Atefeh, W. Khreich, A survey of techniques for event detection in Twitter, Computational Intelligence (2015).doi:\n10.1111/coin.12017.\n[12] N. Nikzad-Khasmakhi, M. Balafar, M. R. Feizi-Derakhshi, C. Motamed, Exem: Expert embedding using dominating set\ntheory with deep learning approaches, arXiv preprint arXiv:2001.08503 (2020).\n[13] Finding expert users in Community Question Answering, in: WWW’12 - Proceedings of the 21st Annual Conference on\nWorld Wide Web Companion, 2012.doi:10.1145/2187980.2188202.\n[14] S. Momtazi, F. Naumann, Topic modeling for expert ﬁnding using latent Dirichlet allocation, Wiley Interdisciplinary\nReviews: Data Mining and Knowledge Discovery (2013).doi:10.1002/widm.1102.\n18\n(a) ExEm (dimension of embedding is 128)\n(b) BERT (dimension of embedding is 512)\n(c) BERTERS(ExEm(fastText)) (dimen-\nsion of embedding is 641)\n(d) BERTERS(ExEm(fastText)) (dimen-\nsion of embedding is 64)\n(e) BERTERS(ExEm(fastText)) (dimen-\nsion of embedding is 256)\n(f) BERTERS(ExEm(fastText)) (dimen-\nsion of embedding is 512)\nFigure 8: Visualization of communities of 50 top experts in three topics for diﬀerent techniques and dimensions. Each point\ncorresponds to an expert. Color of an expert denotes its cluster.\n[15] M. Neshati, Z. Fallahnejad, H. Beigy, On dynamicity of expert ﬁnding in community question answering, Information\nProcessing and Management (2017).doi:10.1016/j.ipm.2017.04.002.\n[16] A. D. Nobari, S. S. Gharebagh, M. Neshati, Skill translation models in expert ﬁnding, in: SIGIR 2017 - Proceedings\nof the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2017.doi:\n10.1145/3077136.3080719.\n[17] H. Li, S. Jin, S. Li, A Hybrid Model for Experts Finding in Community Question Answering, in: Proceedings - 2015\nInternational Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, CyberC 2015, 2015.\ndoi:10.1109/CyberC.2015.87.\n[18] Y. Fu, R. Xiang, Y. Liu, M. Zhang, S. Ma, Finding experts using social network analysis, in: Proceedings of the\nIEEE/WIC/ACM International Conference on Web Intelligence, WI 2007, 2007.doi:10.1109/WI.2007.59.\n[19] J. Zhang, M. S. Ackerman, L. Adamic, Expertise networks in online communities: Structure and algorithms, in: 16th\nInternational World Wide Web Conference, WWW2007, 2007.doi:10.1145/1242572.1242603.\n[20] S. Lin, W. Hong, D. Wang, T. Li, A survey on expert ﬁnding techniques, Journal of Intelligent Information Systems (2017).\n19\ndoi:10.1007/s10844-016-0440-5 .\n[21] J. Zhan, V. Guidibande, S. P. K. Parsa, Identiﬁcation of top-K inﬂuential communities in big networks, Journal of Big\nData (2016). doi:10.1186/s40537-016-0050-7 .\n[22] S. Mumtaz, X. Wang, Identifying top-k inﬂuential nodes in networks, in: Proceedings of the 2017 ACM on Conference on\nInformation and Knowledge Management, 2017, pp. 2219–2222.\n[23] R. Bian, Y. S. Koh, G. Dobbie, A. Divoli, Identifying top-k nodes in social networks: A survey (2019).doi:10.1145/3301286.\n[24] Z. Zhao, L. Zhang, X. He, W. Ng, Expert Finding for Question Answering via Graph Regularized Matrix Completion,\nIEEE Transactions on Knowledge and Data Engineering (2015).doi:10.1109/TKDE.2014.2356461.\n[25] Z. Zhou, Y. Qifan, D. Cai, X. He, Z. Yueting, Expert ﬁnding for community-based question answering via ranking metric\nnetwork learning, in: IJCAI International Joint Conference on Artiﬁcial Intelligence, 2016.\n[26] L. Sang, M. Xu, S. S. Qian, X. Wu, Multi-modal multi-view Bayesian semantic embedding for community question\nanswering, Neurocomputing (2019).doi:10.1016/j.neucom.2018.12.067.\n[27] G. Zhou, J. Zhao, T. He, W. Wu, An empirical study of topic-sensitive probabilistic model for expert ﬁnding in question\nanswer communities, Knowledge-Based Systems (2014).doi:10.1016/j.knosys.2014.04.032.\n[28] D. R. Liu, Y. H. Chen, W. C. Kao, H. W. Wang, Integrating expert proﬁle, reputation and link analysis for expert ﬁnding\nin question-answering websites, Information Processing and Management (2013).doi:10.1016/j.ipm.2012.07.002.\n[29] X. Xie, Y. Li, Z. Zhang, H. Pan, S. Han, A topic-speciﬁc contextual expert ﬁnding method in social network, in: Asia-Paciﬁc\nWeb Conference, Springer, 2016, pp. 292–303.\n[30] L. Yang, M. Qiu, S. Gottipati, F. Zhu, J. Jiang, H. Sun, Z. Chen, CQARank: Jointly model topics and expertise in\nCommunity Question Answering, in: International Conference on Information and Knowledge Management, Proceedings,\n2013. doi:10.1145/2505515.2505720.\n[31] S. Minaee, N. Kalchbrenner, E. Cambria, N. Nikzad, M. Chenaghlu, J. Gao, Deep learning based text classiﬁcation: A\ncomprehensive review, arXiv preprint arXiv:2004.03705 (2020).\n[32] F. Sun, J. Liu, J. Wu, C. Pei, X. Lin, W. Ou, P. Jiang, Bert4rec: Sequential recommendation with bidirectional encoder\nrepresentations from transformer, in: International Conference on Information and Knowledge Management, Proceedings,\n2019. arXiv:1904.06690, doi:10.1145/3357384.3357895.\n[33] M. Asgari-Chenaghlu, M. R. Feizi-Derakhshi, L. Farzinvash, C. Motamed, A multimodal deep learning approach for named\nentity recognition from social media, arXiv preprint arXiv:2001.06888 (2020).\n[34] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Bert: Pre-training of deep bidirectional transformers for language\nunderstanding, arXiv preprint arXiv:1810.04805 (2018).\n[35] D. F. Nettleton, Data mining of social networks represented as graphs (2013).doi:10.1016/j.cosrev.2012.12.001.\n[36] H. Cai, V. W. Zheng, K. C. C. Chang, A Comprehensive Survey of Graph Embedding: Problems, Techniques, and\nApplications, IEEE Transactions on Knowledge and Data Engineering (2018).arXiv:1709.07604, doi:10.1109/TKDE.2018.\n2807452.\n[37] P. Goyal, E. Ferrara, Graph embedding techniques, applications, and performance: A survey, Knowledge-Based Systems\n(2018). arXiv:1705.02801, doi:10.1016/j.knosys.2018.03.022.\n[38] B. Perozzi, R. Al-Rfou, S. Skiena, DeepWalk: Online learning of social representations, in: Proceedings of the ACM\nSIGKDD International Conference on Knowledge Discovery and Data Mining, 2014.arXiv:1403.6652, doi:10.1145/\n2623330.2623732.\n[39] A. Grover, J. Leskovec, Node2vec: Scalable feature learning for networks, in: Proceedings of the ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining, 2016.arXiv:1607.00653, doi:10.1145/2939672.2939754.\n[40] T. Damoulas, M. A. Girolami, Combining feature spaces for classiﬁcation, Pattern Recognition (2009).doi:10.1016/j.\npatcog.2009.04.002.\n20",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7714176177978516
    },
    {
      "name": "Embedding",
      "score": 0.646669864654541
    },
    {
      "name": "Popularity",
      "score": 0.5719339847564697
    },
    {
      "name": "Graph",
      "score": 0.5205525159835815
    },
    {
      "name": "Information retrieval",
      "score": 0.5042585134506226
    },
    {
      "name": "Machine learning",
      "score": 0.501323938369751
    },
    {
      "name": "Feature learning",
      "score": 0.49649912118911743
    },
    {
      "name": "Artificial intelligence",
      "score": 0.47865235805511475
    },
    {
      "name": "Representation (politics)",
      "score": 0.4621281325817108
    },
    {
      "name": "Graph embedding",
      "score": 0.42424124479293823
    },
    {
      "name": "Recommender system",
      "score": 0.4217378795146942
    },
    {
      "name": "Visualization",
      "score": 0.42012208700180054
    },
    {
      "name": "Similarity (geometry)",
      "score": 0.4180243909358978
    },
    {
      "name": "Data mining",
      "score": 0.33698469400405884
    },
    {
      "name": "Natural language processing",
      "score": 0.3247024118900299
    },
    {
      "name": "Theoretical computer science",
      "score": 0.24079293012619019
    },
    {
      "name": "Image (mathematics)",
      "score": 0.0
    },
    {
      "name": "Social psychology",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Psychology",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I41832843",
      "name": "University of Tabriz",
      "country": "IR"
    },
    {
      "id": "https://openalex.org/I12449238",
      "name": "Université d'Orléans",
      "country": "FR"
    }
  ]
}