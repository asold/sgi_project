{
  "title": "Large language models for knowledge graph extraction from tables in materials science",
  "url": "https://openalex.org/W4409208370",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2311996699",
      "name": "Max Dreger",
      "affiliations": [
        "Forschungszentrum Jülich"
      ]
    },
    {
      "id": "https://openalex.org/A2101366168",
      "name": "Kourosh Malek",
      "affiliations": [
        "Forschungszentrum Jülich"
      ]
    },
    {
      "id": "https://openalex.org/A212616833",
      "name": "Michael Eikerling",
      "affiliations": [
        "RWTH Aachen University",
        "Forschungszentrum Jülich"
      ]
    },
    {
      "id": "https://openalex.org/A2311996699",
      "name": "Max Dreger",
      "affiliations": [
        "Forschungszentrum Jülich"
      ]
    },
    {
      "id": "https://openalex.org/A2101366168",
      "name": "Kourosh Malek",
      "affiliations": [
        "Forschungszentrum Jülich"
      ]
    },
    {
      "id": "https://openalex.org/A212616833",
      "name": "Michael Eikerling",
      "affiliations": [
        "Forschungszentrum Jülich",
        "RWTH Aachen University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2338402873",
    "https://openalex.org/W2972219719",
    "https://openalex.org/W3104073206",
    "https://openalex.org/W3129472090",
    "https://openalex.org/W3040330580",
    "https://openalex.org/W3122333722",
    "https://openalex.org/W3153062923",
    "https://openalex.org/W2794792904",
    "https://openalex.org/W3183861986",
    "https://openalex.org/W2974675506",
    "https://openalex.org/W3031142281",
    "https://openalex.org/W4285397420",
    "https://openalex.org/W4392462078",
    "https://openalex.org/W3216291003",
    "https://openalex.org/W2884430236",
    "https://openalex.org/W3035848341",
    "https://openalex.org/W2032080497",
    "https://openalex.org/W3011353988",
    "https://openalex.org/W1969248908",
    "https://openalex.org/W4391897357",
    "https://openalex.org/W3010336026",
    "https://openalex.org/W2734806099",
    "https://openalex.org/W4382468920",
    "https://openalex.org/W3000180033",
    "https://openalex.org/W191520398",
    "https://openalex.org/W2964864162",
    "https://openalex.org/W4391836235",
    "https://openalex.org/W4392489035",
    "https://openalex.org/W4323342132",
    "https://openalex.org/W2145769341",
    "https://openalex.org/W2222512263",
    "https://openalex.org/W3185825176",
    "https://openalex.org/W3100874232",
    "https://openalex.org/W2898316900",
    "https://openalex.org/W3091055370",
    "https://openalex.org/W2531274738",
    "https://openalex.org/W3103584381"
  ],
  "abstract": "Large language models are promising tools for unifying scattered data, extracting information, and creating knowledge graphs.",
  "full_text": "Large language models for knowledge graph\nextraction from tables in materials science\nMax Dreger, *a Kourosh Malekab and Michael Eikerling abc\nResearch in materials science increasingly harnesses machine learning (ML) models. These models are\ntrained with experimental or theoretical data, the quality of their output hinges on the data's quantity and\nquality. Improving data quality and accessibility necessitates advanced data management solutions.\nToday, data are often stored in non-standardized table formats that lack interoperability, accessibility and\nreusability. To address this issue, we present a semi-automated data ingestion pipeline that transforms\nR&D tables into knowledge graphs. Utilizing large language models and rule-based feedback loops, our\npipeline transforms tabular data into graph structures. The proposed process consists of entity\nrecognition and relationship extraction. It facilitates better data interoperability and accessibility, by\nstreamlining data integration from various sources. The pipeline is integrated into a platform harboring\na graph database as well as semantic search capabilities.\n1 Introduction\nMaterials science is increasingly implementing data-driven\napproaches, marking the much-quoted shi  towards the\nfourth paradigm.1,2 The use of emerging articial intelligence\n(AI) tools in materials research promises to accelerate materials\ndiscovery by guiding e ﬃcient and time-saving exploration\nthrough high-dimensional materials parameter spaces.3–7 In the\ngrowing eld of autonomous experimentation, machine\nlearning models are deployed to plan experiments8–11 while\ncomputer vision tools automate imaging analysis.12–15\nThe quality and availability of data are crucial in this realm.\nData generation in materials science is frequently tied to short-\nterm projects and is considered time-consuming and costly,\nleading to the creation of many small and scattered datasets.16,17\nData management in research labs typically relies on relational\ndatabases or le systems, predominantly lled with tables.\nThose tables are rich data assets; however, information on how\ndata points across diﬀerent columns are interconnected is oen\nonly implicitly provided. The lack of data management stan-\ndards, therefore, leaves valuable data silos scattered with very\nlimited accessibility and interoperability among labs or\ninstitutions.\n18–20\nSeveral recent papers have emphasized the need for openly\naccessible databases; however, data heterogeneity due to\nvarying length scales and structural complexity of materials\npresents intricate technical challenges. 21,22 Consequently,\ndatabases are o en limited to single length scales, highly\ndomain-specic, and focused on chemical elements and\ncompound properties that do not depend on\nmicrostructure.\n23–30 Thus, the materials science community is\nexperiencing a trend toward information silos separated by\ndomain, design, or exploration space, hindering the full\npotential of AI methods.\n31 This separation complicatesnding\nanswers to generic research questions. Filtering a corpus of\nmaterials for desired properties or identifying processing\nconditions associated with desired materials properties oen\nrequires consulting domain experts or scientic literature.\n32\nKnowledge graphs are promising data structures, respond-\ning to these challenges. They consist of nodes and relationships\nforming a network of connected entities.\n33 These relationships\nmake information and contextualized data machine-readable,\nfacilitating the integration of tools to analyze, organize, and\nshare information. Furthermore, graphs excel in representing\nhighly heterogeneous data due to their focus on connectivity,\nwhich provides a high degree ofexibility.\n34,35 Materials science\nincreasingly uses knowledge graphs to integrate and organize\ndata from literature, databases, and ontologies.\n35–37 To elevate\nthem to viable data management solutions on lab-scale and\nbeyond, these tools need to be broadly appealing to materials\nscience.\nAttractive data management solutions provide intuitive\nmechanisms for data storage and retrieval, streamlining the\nprocess for data owners by removing unnecessary complexity.\nMoreover, they ought to reduce their usage barrier, ensuring\nsmooth integration into the user's routine data practices, with\nminimal interruption.\n17 The capacity to mine existing data,\naTheory and Computation of Energy Materials (IET-3), Institute of Energy\nTechnologies, Forschungszentrum Jülich GmbH, 52425 Jülich, Germany. E-mail: m.\ndreger@fz-juelich.de\nbCentre for Advanced Simulation and Analytics (CASA), Simulation and Data Lab for\nEnergy Materials, Forschungszentrum Jülich, 52425 Jülich, Germany\ncChair of Theory and Computation of Energy Materials, Faculty of Georesources and\nMaterials Engineering, RWTH Aachen University, 52062 Aachen, Germany\nCite this:Digital Discovery,2 0 2 5 ,4,\n1221\nReceived 9th November 2024\nAccepted 28th March 2025\nDOI: 10.1039/d4dd00362d\nrsc.li/digitaldiscovery\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4, 1221–1231 | 1221\nDigital\nDiscovery\nPAPER\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nView Journal\n | View Issue\nderive insights, and integrate them into one's data assets is\na crucial feature of data management systems. Thus, broad\nadoption of graph-based data management solutions requires\ntools that facilitate the migration from existing tabular data\nassets to knowledge graphs. Knowledge extraction is an\nemerging eld aiming to extract information from structured\nand unstructured sources\n38 and is increasingly applied in the\nmaterials science domain. 39,40 Recent advances in natural\nlanguage processing through the availability of Large Language\nModels (LLMs) provide novel disruptive tools in thiseld.41,42\nLLMs excel in inferring context and meaning of unseen data\nwithout the need for expensive training. This eases the imple-\nmentation of LLM-enabled knowledge extraction tools, making\nthem attractive for data management solutions.\nIn a recent publication, we proposed a data model for graph\ndatabases\n43 that follows the logic of the Elementary Multi-\nperspective Material Ontology (EMMO). 44 An ontology is\na structured framework that de nes and categorizes the\nconcepts, entities and their relationships within a speci c\ndomain. The proposed data model is able to represent experi-\nmental workows in materials science with any desired degree\nof granularity. Entities within the database are labeled via\na semantically connected system of nodes that span a wide\nrange of processes, matter and quantities (see Fig. 1). These\nlabels are based on the EMMO and BattINFO, a domain-specifc\nEMMO extension focused on batteries and their characteriza-\ntion.\n45 The database aims to help research groups manage their\ndata assets in an intuitive way while making it interoperable\nwith other data vendors.\nIn this study, we introduce a knowledge graph extraction\npipeline to improve the eﬃciency of populating graph data-\nbases with existing table data. The pipeline semi-automatically\ntransforms tables into connected knowledge graphs that follow\nthe data model we proposed in Fig. 1. The extraction process\nutilizes LLMs to infer meaning from headers and extract\ninformation from tables. We divided the process into four\nstages, which can be veried by the user through a graphical\nuser interface, ensuring the high quality of the knowledge\ngraph. To enhance the cost eﬃciency and scalability, we inte-\ngrated various caching strategies to streamline the extraction\nprocess from known tables.\nComparatively, alternative solutions— such as Microso's\nGraphRag\n46 and manual data transformation approaches —\noen require expertise in database querying languages or\nextensive iterative prompt engineering. While these methods\nare viable, they tend to be labor-intensive and face scalability\nchallenges due to their technical complexity. In contrast,\nenterprise cloud data management platforms like Databricks,\n47\nGoogle Cloud,48 and Splunk49 are designed to integrate seam-\nlessly with standard work ows, providing streamlined and\nrobust data operations. However, their architectures are\ngenerally optimized for more homogeneous data, which makes\nit diﬃcult for them to natively handle the high complexity and\nheterogeneity inherent in scientic data. Consequently, eﬀec-\ntive data management in the scientic domain should seam-\nlessly integrate into existing data handling routines. Thus, data\nmanagement should not impose signicant technical overhead\nor require specic expertise from researchers, while allowing\nthem to accommodate the full complexity and interconnected\nnature of their data.\nIn the following, we thoroughly discuss the methodologies\nand metrics of the extraction procedure and its results. This\narticle is relevant to those interested in using our data\nmanagement system or engaging in knowledge extraction in\ndiﬀerent scientic domains.\n2 Methods\nThe generation of a knowledge graph involves two key\nprocesses, node extraction and relationship extraction. Node\nextraction from tables is a multi-step procedure. Initially, each\ncolumn is assigned a node type (e.g., matter, property). Next, the\nattribute type of each column is identied (e.g., Name, Value).\nFinally, columns representing diﬀerent attributes of the same\nnode are aggregated.\nThe entities extracted through this process are then used to\ninfer relationships, constituting the build-up of a knowledge\ngraph. The following sections provide an overview of the data\ntypes encountered in this study, introducing the input and\noutput and delineating the specics of the extraction pipeline.\n2.1 The input: tables\nThe pipeline is designed to transform tables, which are the\nmost common format for researchers to store, analyze, and\ncommunicate their data. It accepts CSV les as input and\nrequires the tables to beat— that is, each row represents a data\nrecord and each column contains specic values (e.g., numbers,\nstrings, or dates). In contrast, nested tables allow columns to\ncontain sub-tables or arrays. We tested and validated our\npipeline on a dataset of 15at tables. We minimized bias in our\ntest dataset by ensuring high heterogeneity; the dataset\ncomprises data from various subdomains of materials science,\nwith data from measurements, syntheses, simulations, prop-\nerties, organizational data, and single processing steps. We also\nvaried the data sources by incorporating tables from self-driving\nlabs and from diﬀerent research groups. Table 1 shows an\nexcerpt of one such table that can be transformed into a graph.\nThe pipeline was tested on tables with between 4 and 90\ncolumns. Since only the table headers paired with sample rows\nare used in the transformation, the total number of rows does\nnot aﬀect the process. The tables are available in our GitHub\nrepository.\n50\nFig. 1 Schema of the proposed graph data model (a) and example of\nthe labeling system (b).\n1222 | Digital Discovery,2 0 2 5 ,4, 1221–1231 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nIn materials science, these tables typically describe entities\nsuch as materials, components, devices, chemicals, properties,\nmeasurements, manufacturing steps, and processing condi-\ntions. The goal is to extract these entities and contextualize\nthem by inferring relationships among them.\nFor example, the excerpt in Table 1 contains a column titled\n“Ionomer” immediately followed by a column labeled“Equiv-\nalent Weight” that holds numerical values. To retrieve mean-\ningful information, the pipeline must extract a matter node\nrepresenting the ionomer cell “Aquivion” and connect it to\na property node labeled“Equivalent Weight”, which carries the\nnumerical value of 790 and the unit g mol\n−1. Given the signif-\nicant variations in table structures and header terminologies,\nour pipeline is designed to be agnostic to both structure and\nterminology, enabling it to process a wide range of tables\nwithout prior knowledge of their layout. The pipeline leverages\nLLMs to extract data within the domain of materials science,\nwith a particular focus on energy materials.\n2.2 The output: knowledge graphs\nThe graph model we introduced in a previous publication\nfollows the logic of the Elementary Multiperspective Material\nOntology (EMMO). The graph model consists of the node types\nand relationships shown in Fig. 1.\n43 These nodes and their\nrelationships are capable of representing materials and\nprocesses in materials science. To capture domain-speci c\nterminologies and ensure data interoperability, we introduced\na labeling system for our graph database. This labeling system\ncomprises classes such as matter, property, parameter,\nmeasurement, simulation, and manufacturing, along with their\nsubclasses. These tree-like structures were derived from EMMO\nand its domain-specic extensions like BattInfo. Each ingested\ndata point is labeled by linking it to a label nodevia an IS_IN-\nSTANCE relation (see Fig. 1(b)). Label nodes are semantically\nconnected via IS_A relations to indicate parent/child relation-\nships. The label nodes form taxonomies of the matter,\nmanufacturing, property, and property nodes. This structure\nsemantically embeds alternative labels in a tree format, as each\nnode is connected to a specic label node and indirectly linked\nto all its sub- and parent classes. The labeling of each nodevia\na semantically contextualized label is the foundation for\na semantic search functionality that allows for highly specic\nand very broad querying of the knowledge graph. Additionally,\nwe introduce a tool for the dynamic extension of the labeling\nsystem (see Section 2.4). The labeling system is available on our\nGitHub repository as .owlles.\n51\n2.3 The pipeline\nTransforming table data into a knowledge graph requires\nextracting implicit information, which involves domain\nknowledge and understanding of table structures. Due to the\nvariety of table structures, rule-based algorithms are insuﬃ-\ncient. We utilize LLMs for their domain knowledge and ability\nto interpret table content and structures. To address scalability,\nwe implemented caches (look-up tables) for tables and columns\nto reduce LLM usage for known data. The latter allows known\ntable structures to be processed without the use of LLMs.\nFeedback loops and validation functions enhance accuracy and\ndeterminism. Our pipeline processes only the table headers and\na sample row with altered numerical data to ensure data secu-\nrity while using the APIs of OpenAI. The transformation task is\ndivided into four sequential steps, each adding context and\ninformation. Fig. 2 provides a schema of the full pipeline.\n2.3.1 Node type extraction task. Each table column is\nassigned to a specic node type (e.g., matter, property, property)\nby converting the header and a sample cell into embeddings.\nEmbeddings are high-dimensional vector representations of\nhuman language. These embeddings are compared to a static\npool of various examples for the diﬀerent node types. Non-\nclassiable or ambiguous headers are agged for user\nassignment.\nWe use the OpenAI embedding generator as it has shown\nhigh accuracy in benchmarking, especially in classi cation\ntasks. To improve the accuracy of this step, the table header of\neach validated classication is transformed into an embedding\nand added to the pool of node examples. The candidate selec-\ntion uses cosine similarities tond the most similar vector in\nthe pool of examples.\nThe process is encapsulated into a classier Python class\nthat iterates over all table headers, creates embeddings from the\nTable 1 Excerpt of a table from the dataset we used to test and\nevaluate our pipeline. The whole dataset can be a accessed in our\nGitHub repository\nDrymilltime\n(h)\nDrying T\n(°C) Catalyst Ionomer Equiv. weight I/C\n6 55 F50E-HT Aquivion 790 0.7\n24 55 F50E-HT Aquivion 790 0.7\n48 55 F50E-HT Aquivion 790 0.7\n6 55 F50E-HT Aquivion 790 0.9\n24 55 F50E-HT Aquivion 790 0.9\n48 55 F50E-HT Aquivion 790 0.9\n6 55 F50E-HT Aquivion 790 1.1\n24 55 F50E-HT Aquivion 790 1.1\n48 55 F50E-HT Aquivion 790 1.1\n«« « « « «\nFig. 2 Schematic overview of the extraction pipeline on the example\nof a speciﬁc table. The pipeline consists of a node type extraction (see\nSection 2.3.1), node attribute extraction (see Section 2.3.2), node\nextraction (see Section 2.3.3), and relationship extraction (see Section\n2.3.4).\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4, 1221–1231 | 1223\nPaper Digital Discovery\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\ntable header and the sample cell, identies the best match from\nthe pool of examples, and returns a dictionary with each header\nrepresenting a key with its node type as the value. As the node\ntype assignment of each header is an isolated task, it can be\neasily parallelized.\nFig. 2 presents an example for the node type extraction. The\nassignments of the correct node types to the columns that\ncontain matter nodes are straightforward as they contain\nheaders that are semantically very close to matter and can\ntherefore be easily assigned to an example for the node type\nmatter. A challenge can arise with the heading“Method” as it\nhas a high semantic overlap with measurement and\nmanufacturing and could therefore be attributed to both node\ntypes. Since manufacturing steps and measurements have\ndiﬀerent methods (e.g., “mixing”, “imaging”, etc.) both node\ntypes show a high semantic overlap with the word“Method”\nalone. For that reason, the header and sample cell are trans-\nformed into an embedding. The word“mixing” is less ambig-\nuous and, therefore, the embedding from the header and the\nsample cell can successfully be assigned to the node type\nmanufacturing.\n2.3.2 Attribute extraction task. Aer assigning node types,\nthe next step identies node attributes in each column. The\nAttributeClassier generates embeddings for headers and\nsample cells by comparing them to a pool of candidates. The\nbest match is identied following the same logic as the node\ntype extraction.\nIn Fig. 2, we illustrate the attribute extraction process. In the\nexample, columns containing Identier attributes contain“ID”\nin their headers, while those listing material names reference\nwell-established materials in the cells and headers. Columns\nwith property and parameter values display numerical entries\nthat can be directly associated with the corresponding attribute,\nvalue. Because the node type of each column is determined in\nthe rst step, the range of possible attributes is constrained. For\nexample, matter, manufacturing, and measurement nodes\ninclude an identier attribute, whereas parameter and property\nnodes do not. Thus, knowledge of the node types, along with the\nunambiguous headers and cell contents, makes the assignment\nof each column to the correct attribute straightforward.\n2.3.3 Node aggregation task. The third step aggregates\ncolumns into nodes, combining attributes of the same entities\nto form cohesive nodes. We leverage LLMs to overcome limi-\ntations of rule-based approaches. We implemented a NodeAg-\ngregator, NodeEvaluator, and NodeCorrector class for each\nnode type, which use Chat-GPT-4-o. The node extraction is\nexecuted in parallel for each node type, with results validated\nand corrected iteratively.\n2.3.3.1 NodeAggregator. Each NodeAggregator of a specic\nnode type consists of a prompt generator and an LLM agent.\nThe NodeAggregator transforms the given table data into a list\nof nodes that follow a node-type-specic JSON schema (see\nFig. 3). The prompt generator of a specic NodeAggregator\naccepts all table columns that contain attributes of its node\ntype, along with the context provided by the user and all table\nheaders as additional context. From this input data, it generates\na prompt that requests transforming the given table headers\ninto a list of nodes while considering the context and the table\nstructure. The generated prompt is used to initialize an LLM\nagent with a node-type-specic setup message.\nThe agent is given the following information:\n(1) Introduction and general task (system message).\n(2) Explanation of the expected output (schema).\n(3) Context provided by the user (user input).\n(4) Examples (few-shot).\nEach agent is initiated with a xed system message\nexplaining the task and providing general input and guidelines.\nAdditionally, we employ few-shot learning by generating an\narticial conversation history in which the agent was given\na table and produced the correct nodes. These examples serve as\nvaluable guidelines on how to aggregate nodes correctly and\nwhich format to follow. The actual prompt is automatically\ngenerated and contains the table headers, a sample row, and\na string of additional context provided by the user. Fig. 3\nrepresents the general structure of an LLM-enabled pipeline\ncontaining extractor, validator, and corrector classes. Node\naggregation and relationship extraction are implemented\nfollowing this general structure and vary only in inputs and\nstatic components.\n2.3.3.2 NodeValidator.\nThe NodeAggregator's output is for-\nwarded to a corresponding NodeValidator instance, which\nanalyzes the output for logical mistakes. The specic validation\nfunctions depend on the node type and can be checked in the\nGitHub project. In general, the validation consists of logic\nchecks implemented in a rule-based approach that aim to\nimprove the determinism of the NodeAggregator output. They\ncheck for typical mistakes the LLM agent makes, such as\nassigning the same column to attributes of diﬀerent nodes.\nAdditionally, the NodeValidator checks for any violation of the\ngraph data model. For example, a property or quantity node\nalways needs the attribute name, value, and unit to be non-null.\nEach validation function returns the wrongly aggregated nodes\nor True, if the agent did aggregate correctly, considering the\nspecic aspect that the validation function inspects. Aer all\nvalidation functions are executed, the NodeValidator creates\na dictionary containing each validation function and its output.\n2.3.3.3 NodeCorrector. These validation results are used by\nthe NodeCorrector class to rene the NodeAggregator results.\nEach validation function is mapped to one correction function\nFig. 3 Schematic representation of an Extractor, Validator, and\nCorrector class.\n1224 | Digital Discovery,2 0 2 5 ,4, 1221–1231 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nthat generates a prompt, asking for revision by providing the\nincorrectly aggregated nodes along with an explanation of the\nerror, as well as optional error-specic context. Each mistake\ndetected by the NodeEvaluator is transformed into a revision\nprompt resulting in a list of revision prompts. This list of revi-\nsion prompts is merged into a single prompt to the LLM that\nlists all mistakes and asks for revision. This prompt is given to\nan agent initiated with an identical conversational memory as\nthe agent of the initial aggregation. The NodeCorrector gener-\nates a revised list of nodes that can be validated and corrected\nagain in an iterative rening process.\nTo clarify the node aggregation procedure, we will follow the\naggregation of all matter nodes in the example of Fig. 2. The\nagent of the MatterNodeAggregator receives a prompt contain-\ning the table, user context, and instructions to transform\ncolumns 1, 2, 3, and 6 into nodes. The agent should then\ncorrectly assume that the table provides information about the\nfabrication of a catalyst ink, and therefore propose the creation\nof three matter nodes per row: one for the ionomer, one for the\ncatalyst, and one for the catalyst ink. The catalyst name and\nidentier must be extracted from columns 1 and 2. The matter\nnode representing the ionomer has a name that is taken from\ncolumn 3. The node representing the catalyst ink has an iden-\ntier in column 6. Since no column provides a name for the\ncatalyst ink and it is a crucial attribute, the agent needs to infer\nit (for example, “catalyst ink”) from the header of column 6.\nEach row of the table can thus be transformed into three matter\nnodes, with attributes varying by row, except for the name of the\ncatalyst ink node, which is inferred from the table headers. If\nthe MatterNodeAggregator does not infer the name“catalyst\nink” for the matter node representing the catalyst ink, the\nMatterNodeValidator would detect this during its sanity check.\nIn that case, the MatterNodeCorrector would be invoked to\ncorrect the error by inferring the missing name attribute.\n2.3.4 Relationship extraction task. The current state of the\ntable transformation represents the table as a list of nodes, with\nall columns aggregated into nodes of various types. However, to\nform a complete graph, relationships must be inferred from the\ntable's content. Since most tables contain these relationships\nonly implicitly, extracting them requires an understanding of\nthe information hidden within the data. The implementation of\nrelationship extraction follows the same structure as node\nextraction (see Fig. 3).\n2.3.4.1 RelationshipExtractor. For each relationship type,\na specic RelationshipExtractor was implemented that extracts\nan initial list of relationships from the table. Each instance\nconsists of an LLM agent and a prompt generator. An instance\nof a specic RelationshipExtractor is initialized with two lists of\nnodes, the context provided by the user, the table headers, and\na sample row. The prompt generator generates a query that\nrequests reasonable relationships to connect pairs of nodes. As\neach relationship type is extracted separately, only nodes with\nthe correct types are given as possible candidates. The\n“HAS_PROPERTY” relationship connects a matter node with\nproperty nodes, which means that the HasPropertyExtractor\nreceives a list of matter nodes and a list of property nodes as the\nmain input. Since a knowledge of the complete table structure is\ncrucial for a successful relationship extraction, the prompt also\ncontains the table's header andrst row as well as the context\ngiven by the user. The LLM-agent of each extractor instance is\ninitiated with a relationship type-specic setup message con-\ntaining an explanation of the task, the input data, relationship-\nspecic rules and tips, as well as examples with a chain of\nthought to further improve accuracy.\n2.3.4.2 RelationshipValidator. For each relationship type,\none RelationshipValidator class was implemented. Depending\non the relationship type, these classes execute a number of\nvalidation functions to check the output for logical errors. These\nvalidation functions check graph logic, such as the connectivity\nof the graph or its nodes, or the cardinality of certain relation-\nships. Each validator generates a dictionary containing the\nexecuted validation functions and their results. The classes'\nstructure is therefore very similar to the NodeValidator, as both\nrun validation functions and return the results as a dictionary.\n2.3.4.3 RelationshipCorrector. Each evaluation function has\na corresponding correction function that generates a prompt\nspecifying the identied mistakes and requesting a revision.\nThe RelationshipCorrector uses the output of the validator and\ngenerates a list of prompts that are concatenated into a single\nprompt that lists all extraction errors. The corrector then\ninitializes a new agent with the same conversational memory as\nthe RelationshipExtractor and requests a revision of the results,\nstating all detected errors. The output is a rened list of rela-\ntionships that can be evaluated and corrected again.\nThe relationship extraction in Fig. 2 can be illustrated using\nthe example of the HasPropertyRelationshipExtractor. This\nclass extracts the HAS_PROPERTY relationships that connect\nmatter and property nodes. In this example, the extractor would\nreceive a list of all matter nodes (e.g., the ionomer, the catalyst,\nand the catalyst ink) as well as a single property node (e.g., the I/\nC ratio). The agent must then decide to which matter node the\nproperty node belongs. This can be inferred either by recog-\nnizing that “I/C” stands for “ionomer to catalyst ratio”— indi-\ncating it is a property of the catalyst ink, or by analyzing the\ntable structure, since the property node's column is directly\nadjacent to the catalyst ink node's column.\n2.4 Label assignment\nTo make the data searchable and interoperable, the extracted\nnodes need to be labeled correctly. Labeling data means that\neach Name attribute within the extracted nodes is processed\nand mapped to a label node within the graph database's\nlabeling system. If no adequate label can be found within the\ndatabase, an LLM agent is used to create a new label node and\nextend the existing labeling system. This step is essential to\nenable eﬀective querying of the database later on. It requires\ndiﬀerent instances of the same kind to be assigned the same\nlabel, so that they can be searched and found with the same\nqueries. To enhance interoperability, the used labels should\nfollow lingo and terminology that at least parts of the commu-\nnity already agreed on.\n2.4.1 Generation of the labeling system.As a basic labeling\nsystem, we ingested the matter, Quantity, and Process branches\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4, 1221–1231 | 1225\nPaper Digital Discovery\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nof EMMO and its BattInfo extension into the graph database.\nThese branches form a taxonomy of label nodes that can be\nused to classify the extracted data. A branch here is a tree\nstructure that contains each top-level label node and its\nsubordinate nodes. For each label node within the branches, we\ngenerated a list of alternative labels as well as a short descrip-\ntion. As the three branches contain more than 1000 label nodes,\nadding alternative labels and descriptions to each node is done\nautomatically using the Chat-GPT-4-turbo module of OpenAI.\nThe label node's name, its alternative labels, and the descrip-\ntion are then used to generate embeddings that capture the full\nsemantic bandwidth of each label node. The embeddings are\ngenerated by the OpenAI API and stored in the graph database\nas vector nodes connected to the label nodes.\n2.4.2 Similarity-based classi cation. Finding the appro-\npriate label for an extracted node is a classication task and\nrequires nding the most similar label node within the\ntaxonomy (e.g., the labeling system). Identifying the correct\nlabel is done using embeddings and Chat-GPT-4-turbo. The\nname of the node that needs to be labeled is transformed into\nan embedding. The embedding is then compared to the\nembeddings stored within the labeling system of the database,\nand the best matching label node is identied by calculating\nand comparing cosine similarities. If the highest similarity\nscore does not exceed a threshold value of 0.95, it is very likely\nthat no label node suﬃciently represents the given name.\n2.4.3 LLM-assisted extension of the taxonomy.In that case,\nwe employ an LLM agent with the task ofnding a matching\nlabel node or extending the taxonomy dynamically. The agent is\ninitiated with a node-type-specic setup message containing the\ntask, relevant hints, rules, and examples. Furthermore, the\nagent receives the node name that needs to be labeled, as well as\nthe most similar label nodes as possible candidates. The agent's\ntask is to identify a label node from among the candidates that\neither adequately describes the node or could describe one of its\n“child” or “parent” label nodes. This prompt can lead to three\ndiﬀerent outcomes:\n(1) No match found: if none of the candidates is a suitable\nlabel node, or a child or parent class of the unlabeled node, the\nagent is given all possible labels of the given node type. If the\nunlabeled node is a matter node, this means all label nodes that\nare children of the label node named“matter”are forwarded to\nthe agent. Among them, the agent chooses a label node that\nrepresents a parent label of the unlabeled node. Then, the agent\nis asked to suggest a new label and additional child labels— if\nnecessary— to seamlessly extend that branch. The output of the\nagent is used to create new label nodes within the graph data-\nbase. They are used to label the unlabeled node and extend the\nexisting taxonomy.\n(2) Adequate match found: if one of the candidates repre-\nsents an adequate label for the node, the task ends and the node\ngets assigned the label chosen by the agent.\n(3) Subclass/parentclass found: if one of the candidates is\na parent or child label of the unlabeled node, the agent is given\nall parent or child labels of that candidate. The agent then has\nto identify the semantically closest label node and generate\na new label node that adequately represents the extracted node.\nTo improve the quality of the extension, the agent can suggest\nadditional labels to smooth the branching. The output of the\nagent is used to create new label nodes, connecting them to the\nexisting taxonomy. The unlabeled node is then stored within\nthe graph database and linked to the newly generated label\nnode.\nThe complete procedure is depicted in Fig. 4. As the correct\nextension of the labeling system is crucial to make the data\nretrievable and interoperable, all newly added label nodes are\nagged for curation by the database admins.\n2.5 Caching\nCurrently, using the pipeline is slow and expensive for unseen\ntables. To compensate for that drawback, we implemented look-\nup tables to allow wide adoption of the pipeline. These look-up\ntables are a means to cache graphs for recurring tables or table\nparts. If a known table needs to be transformed, the cache can\nbe used to bypass the LLM usage, which is the time- and cost-\ndetermining part of the graph extraction. Tables and their\nparts are only added to the cache and look-up tables if their\ntransformation has been validated by the user and the admin.\nTwo ways of caching have been implemented:\nSingle-column cache: single-column caches contain the\nheaders of individual columns and the assigned node types and\nattributes. Columns that contain already known table headers\ncan be cached, and therst two steps of the transformation\npipeline can be skipped. Additionally, table headers with\nalready correctly extracted labels and attributes are transformed\ninto embeddings and added to the pool of examples for the\nlabels and attributes they represent. These additional embed-\ndings facilitate type and attribute extraction of headers with\nsimilar wording and therefore help boost the accuracy of the\nrst two steps of the pipeline.\nTable cache: as researchers or self-driving labs o en\ngenerate the same table structures, caching full graph extrac-\ntion is crucial to enhance the scalability of the pipeline. We\nimplemented look-up tables that store the table headers and the\nresulting graph of each validated extraction. If already cached\ntables need to be transformed into graphs for ingestion into the\ndatabase, the cache is activated and the correct graph can be\ndirectly requested from the look-up table.\nAll look-up tables are within an SQL database and accessible\nvia the django-admin user interface. Each transformation\nprocedure generates one single-column cache for each table\nFig. 4 Schematic overview of the labeling workﬂow.\n1226 | Digital Discovery,2 0 2 5 ,4, 1221–1231 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\ncolumn and one table cache entry for the full table. These new\ncache entries are directly validated by the user through the GUI.\nThrough the django-admin interface the cached tables can be\nchecked and validated by the admin. Aer validation by the\ndatabase administrator, the columns and tables are fully\ncached.\n3 Results\nThe pipeline operates in a semi-automated fashion, requiring\nthe user to verify the results of each step when the table to be\ningested is unknown. Successful extractions are cached, allow-\ning fully automated graph extraction for known table structures.\nThe semi-automated approach ensures high-quality graph\nextraction, as the transformation from a table to graph can\nresult in multiple possible graphs if the table headings and\nstructure are ambiguous. This uncertainty accommodates the\ndiverse and unrestricted nature of table structures and termi-\nnology that we allow as users' inputs.\nTo set up a robust pipeline, it is necessary to optimize each\nstep. Therst two steps are classication tasks, to assign a node\ntype and node attribute to each column. Optimizing node type\nand attribute extraction (see Sections 2.3.1 and 2.3.2) requires\noptimization of:\n/C15 Examples: each column is assigned to a node type and\nnode attribute by a similarity comparison to a pool of examples\n(e.g., examples for the node type Parameter might be:“Oper-\nating Condition”, “Process Parameter”, “Heating Speed”).\n/C15 Input: depending on the format and structure of the\nexamples, the input for the classication can be optimized (e.g.,\nHeading:Sample_Cell, Heading, “Key”: Heading, Value:\n“Sample Row” are diﬀerent ways to generate input for a simi-\nlarity comparison and will lead to diﬀerent results).\n/C15 Matching: the logic of how the correct node type/attribute\nis chosen can be varied (e.g., a naive approach is to select the\nexample with the highest similarity).\nThe subsequent steps, which extract nodes and relation-\nships, mainly depend on prompt engineering. The accuracy\nhere was improved by prompt engineering and iterative\ntweaking of the input to the LLM agent. Prompt engineering is\nvery expensive; therefore, we optimized the prompts on tables\nwith high complexity that contain nodes and relationships of all\ntypes and most labels. Increasing accuracy requires optimiza-\ntion of the following:\n/C15 System message: the system message contains the general\ninformation and task the LLM Agent is given (e.g., “You are\na world-class node extracting algorithm.”).\n/C15 Prompt: the actual prompt the agent is given to extract\nnodes/relationships from a given input.\n/C15 Examples: examples that are given to the agent that show\nhow to correctly extract data from a given input.\n/C15 Schema: the desired output format that contains small\ndescriptions of the parts of the output.\n/C15 Input data: the input data is part of the prompt. It is\nimportant to include it in a way that is easy to process and\ncontains exactly the information and context that is needed to\nsolve the given task.\nThe nal parameters for every step are made available on our\nGitHub repository.\n52\n3.1 Evaluation\n3.1.1 Evaluation of the classication tasks. The node type\nand node attribute extraction are evaluated using precision,\nrecall, and the F\n1 score as metrics:\nP ¼ TP\nTP þ FP ; R ¼ TP\nTP þ FN ; F1 ¼ 2$ P$R\nP þ R (1)\nWe evaluated the classication tasks on the headings of all\ntables listed in the data repository. Additionally, we created an\narticially generated dataset of 100 heading/sample_cell pairs\nfor each node/attribute type. The accuracy of the classication\ntask is given in Table 2.\nThe classication part of the pipeline yieldsF\n1 scores from\n0.90 to 1.0. Especially, the classication of the node types was\nchallenging, as the parameter and property types have a high\nsemantic overlap that complicates distinguishing them.\n3.1.2 Evaluation of the node extraction task.Node extrac-\ntion involves aggregating the tables' column data into nodes,\nwith attributes inferred from the context or the entire table.\nEvaluating this step requires comparing a list of nodes to the\nground truth. To assess the similarity between two lists of\nnodes, we dene a metric that compares each node's attributes\nand optimally matches nodes from one list to the other. This\napproach has been previously used to evaluate the accuracy of\nknowledge graph pipelines.\n53,54 The steps are as follows:\n(1) Pairwise similarity calculation\nWe compare the attributes of each pair of nodesn\ni and nj\nfrom the listsL1 and L2. LetAi and Aj be the attributes of nodesni\nand nj, respectively.\nIf Ai\nk and Aj\nk are strings, their similarity Sij\nk is computed\nusing cosine similarity:\nSij\nk ¼ cosðqÞ¼ Ai\nk$Aj\nk\nkAi\nkkkAj\nkk\nIf Ai\nk and Aj\nk are numerical, their similaritySij\nk is:\nTable 2 Results of the node type and attribute type classiﬁcation\nNode type Table dataset Arti cial dataset\nAttribute type Precision Recall F1 Precision Recall F1\nMatter 0.97 1.0 0.99 0.95 0.98 0.96\nProperty 0.98 0.90 0.94 0.94 0.99 0.96\nParameter 0.91 0.96 0.94 0.98 0.98 0.98\nMeasurement 0.88 1.0 0.93 0.96 0.93 0.95\nMetadata 0.94 0.94 0.94 1.0 0.92 0.96\nManufacturing 1.0 0.92 0.96 0.99 0.99 0.99\nIdentier 0.95 1.0 0.97 0.91 0.97 0.94\nValue 1.0 0.94 0.97 0.96 0.97 0.97\nName 1.0 0.97 0.98 0.97 0.95 0.96\nUnit 1.0 1.0 1.0 1.0 0.97 0.98\nError 0.89 1.0 0.94 1.0 0.96 0.98\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4, 1221–1231 | 1227\nPaper Digital Discovery\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nSij\nk ¼\n(\n1i f Ai\nk ¼ Aj\nk\n0i f Ai\nksAj\nk\nThe overall node similarity Sij is the weighted average of\nattribute similarities; unpaired attributes are given a similarity\nof 0:\nS\nij ¼ 1\njKj\n0\n@X\nk˛Kij\nSij\nk\n1\nA\nwhere K is the set of all attribute keys,Kij is the set of common\nkeys in Ai and Aj, and Kmiss is the set of keys missing in either\nnode.\n(2) Optimal matching\nThe similarity comparison of each possible combination of\nnodes from the model output and the ground truth generates an\nn × m matrix, with dimensions equal to the number of nodes in\nthe model output and the ground truth, where each value\nrepresents the similarity of a pair. To yield the overall similarity\nbetween the output and its ground truth, we need to map the\nelements of both lists one-to-one while optimizing the overall\nsimilarity of the pairs. This assignment problem can be solved\nwith the Hungarian method.\nThe Hungarian method, also known as the Kuhn–Munkres\nalgorithm, is an optimization technique used to nd the\noptimal one-to-one matching in a weighted bipartite graph,\nminimizing the total cost.\n55 It iteratively improves the matching\nthrough augmenting paths until the best possible assignment is\nachieved.\n(3) Similarity score calculation\nThe total similarity scoreS is the sum of the similarities of\nthe matched pairsS\ntotal, normalized by the length of the longer\nlist max(jL1j, jL2j):\nS ¼ Stotal\nmaxðjL1j; jL2jÞ\nThis evaluation metric ensures a comprehensive comparison\nof node lists, optimally matching nodes while accounting for\nmissing attributes and diﬀerent data types.\nThe results of the evaluation are given in Fig. 5, and the\npipeline was tested on a total of 500 columns from various\nmaterials science tables. Additionally, the pipeline was tested\non tables from diﬀerent scientic publications across diﬀerent\ndomains. To test the exibility of the pipeline, tables from\nchemistry were used as well.\nAs can be seen, accuracies range from 0.95 to 1.0. Inaccur-\nacies occurred when the table was missing the units of physical\nquantities or when a table contained duplicate table headings.\nIn case of a missing unit, the pipeline tries to infer the unit from\nthe content of the table and makes an educated guess. Dupli-\ncate table headings introduce ambiguity to the table and\ntherefore uncertainty to its transformation. In both cases, the\nLLM agent has to make a guess, which is intrinsically error-\nprone.\n3.1.3 Evaluation of the relationship extraction task. The\nevaluation of relationship extraction was conducted using\nprecision, recall, and F\n1 score metrics, as detailed in Section\n3.1.1. Both the model output and the ground truth contain lists\nof relationships that connect the input nodes. Since relation-\nships are dened solely by their type and the source and target\nnode IDs, their evaluation is binary.\nThe results are depicted in Fig. 6.\nThe relationship extraction achievedF\n1 scores ranging from\n0.92 to 1.0. The validation tables contain up to 98 columns and\nmay list the same fabrication technique multiple times, pre-\nsenting a signi cant challenge for relationship extraction.\nGenerally, most tables yield highF\n1 scores, while more complex\ntables tend to produceF1 score outliers.\n3.2 Qualitative evaluation\nGraph extraction works well in principle; however, certain table\nheadings or structural properties remain especially challenging\nfor the proposed pipeline. Therst two steps, the assignment of\nthe correct node type and attribute type, are classication tasks\nthat employ embeddings.\nAnalyzing the results of these classication tasks, we realized\nthat recurring problems could be traced back to the widespread\nuse of abbreviations in tables. These abbreviations are highly\nchallenging for embedding-based classication tasks, as they\nare oen ambiguous and require context to be understood.\nExamples include the name of a commercial catalyst,“F50E-\nHT”, the abbreviation for an ionomer,“AQ”, or its equivalent\nFig. 5 Evaluation of the node extraction segregated by node type.\nFig. 6 Evaluation of the diﬀerent extracted relationship types.\n1228 | Digital Discovery,2 0 2 5 ,4, 1221–1231 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nweight, “EW”. Such abbreviations demand domain knowledge\nas well as an understanding of the general content of the table\nand can lead to incorrect classications. Another challenge\narises from inherently ambiguous column headings, such as\n“Column1”, which cannot be assigned to the correct node types\nor node attributes. A third issue involves column headings\ncontaining too much information, such as“RH sensitivity at\n85C”, which implies both a sensitivity measurement and\na specic operating condition— two separate nodes within the\ngraph. Node extraction uses the table, along with the previously\nassigned node and attribute types, to transform the table into\na list of nodes. Similar to the classication tasks, the LLM can\nstruggle to interpret ambiguous table headings or cell contents,\nespecially abbreviations. Because the task is handled by Chat-\nGPT-4-o and entails providing the full table headings and\nsample rows to the LLM, its robustness toward these abbrevia-\ntions is somewhat improved. Nonetheless, abbreviations not\nwell established in the domain, such as “NOC” for normal\noperating condition in a fuel cell, may still lead to errors.\nAnother example is the ambiguous abbreviation“I/C”, which in\nthe context of fuel cell fabrication oen denotes the ionomer-to-\ncatalyst ratio, but can also mean ionic conductivity. Beyond\nsemantics, the structure of tables presents additional hurdles.\nLarge tables, for instance, inate the number of columns and\nbroaden the range of possible nodes. Additionally, large tables\nnecessitate a larger context window for the LLM, which can\ninvite inaccuracies due to its susceptibility to information\noverload.\nThe nal step, converting a list of disconnected nodes into\na graph, faces the same challenges as the earlier stages.\nFurthermore, it requires deep domain knowledge, since rela-\ntionships are usually only implicitly present within tables and\nmust be inferred. In conclusion, the pipeline is a robust tool to\nextract information from tables by transforming them into\ngraphs. It is limited by the content and structure of the given\ntable and, similarly to a human, it can make errors. These errors\nare oen caused by the ambiguity of the table data, as tables are\nfrequently created and used internally, tying their interpreta-\ntion to knowledge about the underlying scientic procedures\nthey represent.\nTo conclude, the biggest challenge in table transformation is\ndealing with ambiguities in table structures and terminology.\nThese ambiguities o en arise because researchers typically\nimply important context when creating tables. As a result,\nachieving a correct transformation may require feedback from\nthe original data generators. Recognizing that extracting graphs\nfrom tables inherently involves uncertainty, we implemented\nthe pipeline in a semi-automated way that incorporates feed-\nback at every step.\n3.3 Cost evaluation\nThe proposed pipeline transforms a table into a JSON-formatted\ngraph, ingests the graph into a Neo4j graph database, and\nassigns semantically meaningful labels to each node. Perform-\ning these steps manually would require familiarity with the\nNeo4j query language and signicant time investment.\nFig. 7 shows the costs of the table transformation. Note that\nthis gure neglects the rst two steps of the pipeline and\nfocuses solely on the last two steps, which are the main inu-\nences on overall costs and processing time, while therst two\nsteps are negligible in cost and time. Fig. 7(a) illustrates the\ntime required for both node extraction and relationship\nextraction, as well as the combined duration of these steps.\nSince the extraction procedures for the diﬀerent node types and\nrelationship types are independent, they are executed in\nparallel. As a result, the overall time cost is determined by the\nextraction process that takes the longest— eﬀectively becoming\nthe bottleneck of the operation. The costs are calculated as the\nsum of all node and all relationship extractions. The error bars\nshow the standard deviation of the results, as each table was\ntransformed three times to account for the nondeterministic\nnature of LLMs. Large standard deviations arise if the initial\nextraction is not correct and the output needs to be corrected. In\nthat case, the token consumption is increased by a factor of two,\napproximately. The number of rows does not aﬀect the trans-\nformation as the LLM agents are solely given the table headings\nand a sample row. The\ngure shows that the costs for the node\nand relationship extraction increase with an increasing table\nsize. A contributing factor is the increasing uncertainty, caused\nby the complexity introduced by larger table sizes. A clear trend\nis diﬃcult to determine, though, as the table size is only one\nfactor for the duration and costs of the transformation. The\ntable structure and table lingo also contribute to the complexity\nof the task and therefore inuence cost and duration as well.\n4 Conclusions\nIn this article, we have presented a semi-automated table\ntransformation pipeline designed to extract knowledge graphs\nfrom at tables using LLMs in conjunction with rule-based\nPython logic. Integrated within a Django application, this\npipeline actively populates a native Neo4j graph database.\nWhile the extensive use of LLMs for graph extraction and logic\napplication results in higher costs and reduced speed, the\npipeline's caching capabilities help minimize redundant LLM\nusage.\nThis pipeline, coupled with semantic search capabilities and\nintegrated within a user-friendly graphical interface, signi-\ncantly enhances data management for small research groups or\nwithin research projects. It simplies complex data manage-\nment tasks, making data ingestion and transformation intui-\ntive. By extracting relationships and adding valuable context, it\nincreases the overall value of the data.\nFig. 7 This ﬁgure shows the table size in columnsvs. time (a) and table\nsize vs. costs (b).\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4, 1221–1231 | 1229\nPaper Digital Discovery\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nLLMs have proven to be valuable tools in data extraction and\ngraph construction, as they do not require intensive training.\nThe rapid advances in theeld of LLMs imply that our pipeline\nwill continue to improve in accuracy, speed, and cost-eﬃciency\nby incorporating the latest models. Currently utilizing GPT-4,\nour evaluation shows that it extracts graphs with high accu-\nracy. The nondeterministic nature of the output can be mini-\nmized through validation functions.\nIn future works, the proposed pipeline will be integrated into\na comprehensive data management system. Specic tasks will\nfocus on testing it as a data management solution for research\ngroups, which will involve adding additional interfaces and\nenhancing user management capabilities.\nData availability\nThe datasets and code supporting the conclusions of this article\nhave been deposited in https://github.com/MaxDreger92/\nMatGraph/tree/enhancement/publication and are availablevia\nthe DOI: https://doi.org/10.5281/zenodo.15094951. This\nrepository includes all materials necessary for the\nreproduction of the results presented in this study.\nAuthor contributions\nPerformed the research and draed the manuscript: Dreger\nMax revised andnalized the manuscript: Dreger Max, Eikerl-\ning H. Michael, Malek Kourosh.\nConﬂicts of interest\nAll authors declare that there are no conicts of interests.\nAcknowledgements\nThe authors gratefully acknowledge the nancial support\nprovided by the Federal Ministry of Science and Education\n(BMBF) under the German-Canadian Materials Acceleration\nCentre (GC-MAC) grant number 01DM21001A and the HITEC\nfellowship. Additionally, the authors are thankful for the use of\nthe data shared with them. In particular, they wish to thank\nJasna Jankovic (University of Connecticut), Jens Hauch (For-\nschungszentrum Jülich), and Fabian Tipp (Forschungszentrum\nJülich) for their generous contribution of data.\nNotes and references\n1 A. Agrawal and A. Choudhary,APL Mater., 2016,4(5), 053208.\n2 L. Himanen, A. Geurts, A. S. Foster and P. Rinke,Adv. Sci.,\n2019, 6, 1900808.\n3 S. M. Moosavi, K. M. Jablonka and B. Smit,J. Am. Chem. Soc.,\n2020, 142, 20273–20287.\n4 H. Wang, Y. Ji and Y. Li,Wiley Interdiscip. Rev.: Comput. Mol.\nSci., 2020,10, e1421.\n5 R. Vasudevan, G. Pilania and P. V. Balachandran,J. Appl.\nPhys., 2021,129(7), 070401.\n6 Y. Liu, B. Guo, X. Zou, Y. Li and S. Shi,Energy Storage Mater.,\n2020, 31, 434–450.\n7 Y. Liu, O. C. Esan, Z. Pan and L. An,Energy AI, 2021, 3,\n100049.\n8 J. Wagner, C. G. Berger, X. Du, T. Stubhan, J. A. Hauch and\nC. J. Brabec,J. Mater. Sci., 2021,56, 16422–16446.\n9 J.-P. Correa-Baena, K. Hippalgaonkar, J. van Duren, S. Jaﬀer,\nV. R. Chandrasekhar, V. Stevanovic, C. Wadia, S. Guha and\nT. Buonassisi,Joule, 2018,2, 1410–1420.\n10 E. Stach, B. DeCost, A. G. Kusne, J. Hattrick-Simpers,\nK. A. Brown, K. G. Reyes, J. Schrier, S. Billinge,\nT. Buonassisi, I. Foster, et al.,Matter, 2021,4, 2702–2726.\n11 H. S. Stein and J. M. Gregoire,Chem. Sci., 2019, 10, 9640–\n9649.\n12 E. A. Holm, R. Cohn, N. Gao, A. R. Kitahara, T. P. Matson,\nB. Lei and S. R. Yarasi,Metall. Mater. Trans. A, 2020, 51,\n5985–5999.\n13 M. J. Eslamibidgoli, K. Malek and M. Eikerling,ECS Meet.\nAbstr., 2022,241, 1908.\n14 A. Colliard-Granero, K. A. Gompou, C. Rodenbücher,\nK. Malek, M. Eikerling and M. J. Eslamibidgoli, Phys.\nChem. Chem. Phys., 2024,26(20), 14529–\n14537.\n15 A. Colliard-Granero, M. Batool, J. Jankovic, J. Jitsev,\nM. H. Eikerling, K. Malek and M. J. Eslamibidgoli,\nNanoscale, 2022,14,1 0–18.\n16 K. T. Butler, D. W. Davies, H. Cartwright, O. Isayev and\nA. Walsh,Nature, 2018,559, 547–555.\n17 L. Banko and A. Ludwig,ACS Comb. Sci., 2020,22, 401–409.\n18 T. Wuest, R. Tinscher, R. Porzel and K.-D. Thoben, 2015,\npreprint, arXiv:1501.01149, DOI:10.5121/ijait.2014.4601.\n19 T. Wuest, J. Mak-Dadanski and K.-D. Thoben,Advances in\nProduction Management Systems, Innovative and Knowledge-\nBased Production Management in a Global-Local World: IFIP\nWG 5.7 International Conference, APMS 2014, Ajaccio,\nFrance, September 20-24, 2014, Proceedings, Part I, 2014, pp.\n42–49.\n20 T. J. Oweida, A. Mahmood, M. D. Manning, S. Rigin and\nY. G. Yingling,MRS Adv., 2020,5, 329–346.\n21 N. Science and T. C. (US), Materials genome initiative for\nglobal competitiveness, Executive O ﬃce of the President,\nNational Science and Technology Council, 2011.\n22 N. R. Council, D. on Engineering, P. Sciences, N. M. A. Board\nand C. on, Integrated Computational Materials Engineering,\nIntegrated computational materials engineering:\na transformational discipline for improved competitiveness\nand national security, National Academies Press, 2008, pp.\n83–90.\n23 Citrine Informatics, Citrine Informatics, 2014, http://\nwww.citrination.com, Accessed: [2024-04-05].\n24 Clean Energy Project, 2014, http://\ncleanenergy.molecularspace.org.\n25 The Materials Project, 2014, http://\nwww.materialsproject.org.\n26 Automatic-FLOW for Materials Discovery, 2014, http://\nwww.aowlib.org.\n27 CALPHAD (Computer Coupling of Phase Diagrams and\nThermochemistry), 2014,http://www.calphad.org.\n1230 | Digital Discovery,2 0 2 5 ,4, 1221–1231 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n28 Open Quantum Materials Database, 2014,http://oqmd.org.\n29 NIST (National Institute of Standards and Technology) Data\nGateway, 2014, http://srdata.nist.gov/gateway/gateway?\ndblist=1.\n30 NIST Material Measurement Laboratory, 2014, http://\nwww.ctcms.nist.gov/potentials/.\n31 A. White,MRS Bull., 2012,37, 715–716.\n32 V. Venugopal and E. Olivetti,Sci. Data, 2024,11, 217.\n33 A. Hogan, E. Blomqvist, M. Cochez, C. d'Amato, G. D. Melo,\nC. Gutierrez, S. Kirrane, J. E. L. Gayo, R. Navigli, S. Neumaier,\net al.,ACM Comput. Surv., 2021,54,1 –37.\n34 X. Wilcke, P. Bloem and V. De Boer,Data Sci., 2017,1,3 9–57.\n35 M. J. Statt, B. A. Rohr, D. Guevarra, S. K. Suram,\nJ. M. Gregoire, et al.,Digital Discovery, 2023,2, 909–914.\n36 E. Blokhin and P. Villars, in The Pauling File Project and\nMaterials Platform for Data Science: From Big Data Toward\nMaterials Genome, 2020, pp. 1837–1861.\n37 D. Mrdjenovich, M. K. Horton, J. H. Montoya, C. M. Legaspi,\nS. Dwaraknath, V. Tshitoyan, A. Jain and K. A. Persson,\nMatter, 2020,2, 464–480.\n38 J. Unbehauen, S. Hellmann, S. Auer and C. Stadler,Search\nComputing: Broadening Web Search, 2012, pp. 34–52.\n39 N. Wadhwa, S. Sarath, S. Shah, S. Reddy, P. Mitra, D. Jain and\nB. Rai, Proceedings of the AAAI Conference on Arti cial\nIntelligence, 2021, pp. 15416–15423.\n40 L. Weston, V. Tshitoyan, J. Dagdelen, O. Kononova,\nA. Trewartha, K. A. Persson, G. Ceder and A. Jain,J. Chem.\nInf. Model., 2019,59, 3692–3702.\n41 J. Dagdelen, A. Dunn, S. Lee, N. Walker, A. S. Rosen,\nG. Ceder, K. A. Persson and A. Jain,Nat. Commun., 2024,\n15, 1418.\n42 H. Cai, X. Cai, J. Chang, S. Li, L. Yao, C. Wang, Z. Gao, Y. Li,\nM. Lin, S. Yang, et al. , arXiv, 2024, preprint,\narXiv:2403.01976, DOI:10.48550/arXiv.2403.01976\n.\n43 M. Dreger, M. J. Eslamibidgoli, M. H. Eikerling and\nK. Malek, Synergizing ontologies and graph databases for\nhighly exible materials-to-device work ow\nrepresentations, J. Mater. Inf., 2023, 3(1), DOI: 10.20517/\njmi.2023.01.\n44 The EMMC Consortium, The European Materials Modeling\nOntology, 2021, https://emmc.info/emmo-info/, Accessed:\n2024-04-05.\n45 S. Clark, F. Bleken, J. Friis and C. Anderson,Battery INterFace\nOntology (BattINFO), 2021.\n46 Microso, Microso  GraphRag, https://github.com/\nmicroso/GraphRag, 2025, [Online; accessed 7-February-\n2025].\n47 Databricks, Databricks Unied Analytics Platform, https://\ndatabricks.com/, Accessed: 2025-02-13.\n48 G. Cloud, Google Cloud Platform,https://cloud.google.com/,\nAccessed: 2025-02-13.\n49 S. Inc., Splunk: The Data Platform for Machine Data,https://\nwww.splunk.com/, Accessed: 2025-02-13.\n50 M. Dreger, MatGraph Repository, https://github.com/\nMaxDreger92/MatGraph/tree/enhancement/publication,\nGitHub repository, 2023 (accessed: 2025-02-18).\n51 M. Dreger, MatGraph Ontology, https://github.com/\nMaxDreger92/MatGraph/tree/enhancement/publication/\nOntology, 2021, Accessed: 2025-02-23.\n52 M. Dreger, MatGraph: A Framework for Converting Tables to\nGraphs, https://github.com/MaxDreger92/MatGraph, 2024,\nAccessed: 2024-06-06.\n53 M. Schuhmacher and S. P. Ponzetto,Proceedings of the 7th\nACM international conference on Web search and data\nmining, 2014, pp. 543–552.\n54 Z. Hussain, J. K. Nurminen, T. Mikkonen and M. Kowiel,\n10th Symposium on Languages, Applications and Technologies\n(SLATE 2021), 2021.\n55 H. W. Kuhn,Nav. Res. Logist. Q., 1955,2,8 3–97.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4, 1221–1231 | 1231\nPaper Digital Discovery\nOpen Access Article. Published on 07 April 2025. Downloaded on 11/5/2025 3:54:58 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online",
  "topic": "Knowledge graph",
  "concepts": [
    {
      "name": "Knowledge graph",
      "score": 0.5319066047668457
    },
    {
      "name": "Computer science",
      "score": 0.49854469299316406
    },
    {
      "name": "Graph",
      "score": 0.41246336698532104
    },
    {
      "name": "Natural language processing",
      "score": 0.34773024916648865
    },
    {
      "name": "Data science",
      "score": 0.3334563970565796
    },
    {
      "name": "Information retrieval",
      "score": 0.2896210551261902
    },
    {
      "name": "Theoretical computer science",
      "score": 0.22017377614974976
    }
  ]
}