{
  "title": "Knowledge-Augmented Language Models for Cause-Effect Relation Classification",
  "url": "https://openalex.org/W4285265874",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2951670205",
      "name": "Pedram Hosseini",
      "affiliations": [
        "George Washington University"
      ]
    },
    {
      "id": "https://openalex.org/A2370467627",
      "name": "David A. Broniatowski",
      "affiliations": [
        "George Washington University"
      ]
    },
    {
      "id": "https://openalex.org/A2124289572",
      "name": "Mona Diab",
      "affiliations": [
        "George Washington University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3171434230",
    "https://openalex.org/W2982944182",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3122890974",
    "https://openalex.org/W1964575979",
    "https://openalex.org/W2963159690",
    "https://openalex.org/W3174776104",
    "https://openalex.org/W1991145427",
    "https://openalex.org/W4296557505",
    "https://openalex.org/W2114976145",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3170875954",
    "https://openalex.org/W2970161131",
    "https://openalex.org/W3034385177",
    "https://openalex.org/W2970062726",
    "https://openalex.org/W2889363461",
    "https://openalex.org/W3014521650",
    "https://openalex.org/W3034238904",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W1811279891",
    "https://openalex.org/W2508239101",
    "https://openalex.org/W2798865369",
    "https://openalex.org/W2158194939",
    "https://openalex.org/W2984452801",
    "https://openalex.org/W2115178013",
    "https://openalex.org/W2109485526",
    "https://openalex.org/W2142321231",
    "https://openalex.org/W2153105942",
    "https://openalex.org/W2891382250",
    "https://openalex.org/W53390990",
    "https://openalex.org/W2946361563",
    "https://openalex.org/W2964210047",
    "https://openalex.org/W2145755360",
    "https://openalex.org/W3174464510"
  ],
  "abstract": "Previous studies have shown the efficacy of knowledge augmentation methods in pretrained language models. However, these methods behave differently across domains and downstream tasks. In this work, we investigate the augmentation of pretrained language models with knowledge graph data in the cause-effect relation classification and commonsense causal reasoning tasks. After automatically verbalizing triples in ATOMIC2020, a wide coverage commonsense reasoning knowledge graph, we continually pretrain BERT and evaluate the resulting model on cause-effect pair classification and answering commonsense causal reasoning questions. Our results show that a continually pretrained language model augmented with commonsense reasoning knowledge outperforms our baselines on two commonsense causal reasoning benchmarks, COPA and BCOPA-CE, and a Temporal and Causal Reasoning (TCR) dataset, without additional improvement in model architecture or using quality-enhanced data for fine-tuning.",
  "full_text": "Proceedings of the First Workshop on Commonsense Representation and Reasoning (CSRR 2021), pages 43 - 48\nMay 27, 2022 ¬©2022 Association for Computational Linguistics\nKnowledge-Augmented Language Models for Cause-Effect Relation\nClassification\nPedram Hosseini1 David A. Broniatowski1 Mona Diab1,2\n1The George Washington University 2Meta AI\nphosseini@gwu.edu\nAbstract\nPrevious studies have shown the efficacy of\nknowledge augmentation methods in pretrained\nlanguage models. However, these methods\nbehave differently across domains and down-\nstream tasks. In this work, we investigate\nthe augmentation of pretrained language mod-\nels with knowledge graph data in the cause-\neffect relation classification and commonsense\ncausal reasoning tasks. After automatically ver-\nbalizing triples in ATOMIC20\n20, a wide cover-\nage commonsense reasoning knowledge graph,\nwe continually pretrain BERT and evaluate\nthe resulting model on cause-effect pair classi-\nfication and answering commonsense causal\nreasoning questions. Our results show that\na continually pretrained language model aug-\nmented with commonsense reasoning knowl-\nedge outperforms our baselines on two com-\nmonsense causal reasoning benchmarks, COPA\nand BCOPA-CE, and a Temporal and Causal\nReasoning (TCR) dataset, without additional\nimprovement in model architecture or using\nquality-enhanced data for fine-tuning.\n1 Introduction\nAutomatic extraction and classification of causal\nrelations in text has been an important yet challeng-\ning task in natural language understanding. Early\nmethods in the 80s and 90s (Joskowicz et al., 1989;\nKaplan and Berry-Rogghe, 1991; Garcia et al.,\n1997; Khoo et al., 1998) mainly relied on defin-\ning hand-crafted rules to find cause-effect relations.\nStarting 2000, machine learning tools were utilized\nin building causal relation extraction models (Girju,\n2003; Chang and Choi, 2004, 2006; Blanco et al.,\n2008; Do et al., 2011; Hashimoto et al., 2012;\nHidey and McKeown, 2016). Word-embeddings\nand Pretrained Language Models (PLMs) have also\nbeen leveraged in training models for understand-\ning causality in language in recent years (Dunietz\net al., 2018; Pennington et al., 2014; Dasgupta et al.,\n2018; Gao et al., 2019).\nInvestigating the true capability of pretrained\nlanguage models in understanding causality in text\nis still an open question. More recently, Knowl-\nedge Graphs (KGs) have been used in combination\nwith pretrained language models to address com-\nmonsense reasoning. Two examples are Causal-\nBERT (Li et al., 2020) for guided generation\nof Cause and Effect and the model introduced\nby Guan et al. (2020) for commonsense story gen-\neration.\nATOM IC2020\n(Subject, Relation, Target)\nKG-To-TextGrammar Check\nData Preparation\nEventSocial\nPhysical\nMLM PretrainingTriple Template\nRelation Categories\nEvaluationCOPABCOPA-CE\nBERT\nTCR\nFigure 1: Overview of our proposed framework to con-\ntinually pretrain PLMs with commonsense reasoning\nknowledge.\nMotivated by the success of continual pre-\ntraining of PLMs for downstream tasks (Gururan-\ngan et al., 2020), we explore the impact of common\nsense knowledge injection as a form of continual\npretraining for causal reasoning and cause-effect\nrelation classification. It is worth highlighting that\neven though there are studies to show the efficacy\nof knowledge injection with continual pretraining\nfor commonsense reasoning (Guan et al., 2020),\nperformance of these techniques is very dependent\non the domain and downstream tasks (Gururangan\net al., 2020). And, to the best of our knowledge,\nthere are limited studies on the effect of common-\nsense knowledge injection with knowledge graph\ndata on cause-effect relation classification (Dalal\n43\net al., 2021). Our contributions are as follows:\n‚Ä¢ We study performance of PLMs augmented\nwith knowledge graph data in the less investi-\ngated cause-effect relation classification task.\n‚Ä¢ We demonstrate that a simple masked lan-\nguage modeling framework using automat-\nically verbalized knowledge graph triples,\nwithout any further model improvement (e.g.,\nnew architecture or loss function) or qual-\nity enhanced data for fine-tuning, can signifi-\ncantly boost the performance in cause-effect\npair classification.\n‚Ä¢ We publicly release our knowledge graph ver-\nbalization codes and continually pretrained\nmodels.\n2 Method\nThe overview of our method is shown in Figure 1.1\nWe first convert triples in ATOMIC20\n20 (Hwang et al.,\n2021) knowledge graph to natural language texts.\nThen we continually pretrain BERT using Masked\nLanguage Modeling (MLM) and evaluate perfor-\nmance of the resulting model on different bench-\nmarks. Samples in ATOMIC20\n20 are stored as triples\nin the form of (head/subject, relation, tail/target)\nin three splits including train, development, and\ntest. ATOMIC20\n20 has 23 relation types that are clas-\nsified into three categorical types including com-\nmonsense relations of social interactions, physical-\nentity commonsense relations, and event-centric\ncommonsense relations. In the rest of the paper, we\nrefer to these three categories as social, physical,\nand event, respectively.\n2.1 Filtering Triples\nWe remove all duplicates and ignore all triples\nin which the target value is none. Moreover,\nwe ignore all triples that include a blank. Since\nin masked language modeling we need to know\nthe gold value of masked tokens, a triple that al-\nready has a blank (masked token/word) in it may\nnot help our pretraining. For instance, in the\ntriple: [PersonX affords another ___,\nxAttr, useful] it is hard to know why or un-\nderstand what it means for a person to be useful\nwithout knowing what they afforded. This prepro-\ncessing step yields in 782,848 triples with 121,681,\n1Codes and models are publicly available at https://\ngithub.com/phosseini/causal-reasoning.\n177,706, and 483,461 from event, physical, and so-\ncial categories, respectively. Distribution of these\nrelations is shown in Figure 2.\nxReason\nCauses\nDesires\nNotDesires\nMadeUpOf\nHasProperty\nCapableOf\nHasSubEvent\nisAfter\nisBefore\nAtLocation\noReact\noEffect\noWant\nxIntent\nxReact\nxEffect\nxNeed\nHinderedBy\nxWant\nxAttr\nObjectUse\nRelation type\n0\n25000\n50000\n75000\n100000\n125000Number of triples\nFigure 2: Distribution of relation types in ATOMIC20\n20.\nPersonX accidentally fellxEffectPersonX breaks an armRelationSubject Target\nTracyaccidentally fell. As a result,Tracybreaks an arm\nPersonXcreates an appxIntentTo do something creativeRelationSubject Target\nTracycreates an app becauseTracywanted to do something creativeRelationHuman readable templatexEffectAs a resultxIntentBecause PersonXwantedPersonXTracyReplace by\nWe verbalize ATOMIC2020 knowledge graph\nFigure 3: Examples of converting two triples in\nATOMIC20\n20 to natural language text using human read-\nable templates. Following Sap et al. (2019), we replace\nPersonX with a name.\n2.2 Converting Triples\nEach relation in ATOMIC20\n20 is associated with a\nhuman-readable template. For example, xEffect‚Äôs\nand HasPrerequisite‚Äôs templates are as a result,\nPersonX willand to do this, one requires, respec-\ntively. We use these templates to convert triples\nin ATOMIC20\n20 to sentences in natural language by\nconcatenating the subject, relation template, and\ntarget. Examples of converting triples to text are\nshown in Figure 3.\n2.3 Checking Grammar\nWhen we convert triples to natural language text,\nideally we want to have grammatically correct sen-\ntences. Human readable templates provided by\nATOMIC20\n20 are not necessarily rendered in a way\nto form error-free sentences when concatenated\nwith subject and target in a triple. To address this\nissue, we use an open-source grammar and spell\n44\nchecker, LanguageTool,2 to double-check our con-\nverted triples to ensure they do not contain obvious\ngrammatical mistakes or spelling errors. Similar\napproaches that include deterministic grammati-\ncal transformations were also previously used to\nconvert KG triples to coherent sentences (Davison\net al., 2019). It is worth pointing out that the Data-\nTo-Text generation (KG verbalization) for itself is a\nseparate task and there have been efforts to address\nthis task (Agarwal et al., 2021). We leave investi-\ngating the effects of using other Data-To-Text and\ngrammar-checking methods to future research.\n2.4 Continual Pretraining\nAs mentioned earlier, we use MLM to continually\npretrain our PLM, BERT-large-cased (Devlin et al.,\n2018). We follow the same procedure as BERT to\ncreate the input data to our pretraining (e.g., num-\nber of tokens to mask in input examples). We run\nthe pretraining using ATOMIC20\n20‚Äôs train and devel-\nopment splits as our training and evaluation sets,\nrespectively, for 10 epochs on Google Colab TPU\nv2 using PyTorch/XLApackage with a maximum\nsequence length of 30 and batch size of 128.3 To\navoid overfitting, we use early stopping with the\npatience of 3 on evaluation loss. We select the best\nmodel based on the lowest evaluation loss at the\nend of training.4\n3 Experiments\n3.1 Benchmarks\nWe chose multiple benchmarks of commonsense\ncausal reasoning and cause-effect relation classi-\nfication to ensure we thoroughly test the effects\nof our newly trained models. These benchmarks\ninclude: 1) Temporal and Causal Reasoning (TCR)\ndataset (Ning et al., 2018), a benchmark for joint\nreasoning of temporal and causal relations; 2)\nChoice Of Plausible Alternatives (COPA) (Roem-\nmele et al., 2011) dataset which is a widely used\nand notable benchmark (Rogers et al., 2021) for\ncommonsense causal reasoning; And 3) BCOPA-\nCE (Han and Wang, 2021), a new benchmark\ninspired by COPA, that contains unbiased token\ndistributions which makes it a more challenging\nbenchmark. For COPA-related experiments, since\nCOPA does not have a training set, we use COPA‚Äôs\n2https://tinyurl.com/yc77k3fb\n3%99.99 of ATOMIC20\n20 instances have 30 tokens or less.\n4We use Huggingface‚Äôs BertForMaskedLM implementa-\ntion.\ndevelopment set for fine-tuning our models and\ntesting them on COPA‚Äôs test set (COPA-test) and\nBCOPA-CE. For hyperparameter tuning, we ran-\ndomly split COPA‚Äôs development set into train\n(%90) and dev (%10) and find the best learning rate,\nbatch size, and number of train epochs based on the\nevaluation accuracy on the development set. Then\nusing COPA‚Äôs original development set and best set\nof hyperparameters, we fine-tune our models and\nevaluate them on the test set. In all experiments,\nwe report the average performance of models using\nfour different random seeds. For TCR, we fine-tune\nand evaluate our models on train and test splits, re-\nspectively.\n3.2 Models and Baseline\nWe usebert-large-cased pre-trained model in all ex-\nperiments as our baseline. For COPA and BCOPA-\nCE, we convert all instances to a SW AG-formatted\ndata (Zellers et al., 2018) and use Huggingface‚Äôs\nBertForMultipleChoice ‚Äìa BERT model with a\nmultiple-choice classification head on top. And for\nTCR, we convert every instance by adding special\ntokens to input sequences as event boundaries and\nuse the R-BERT 5 model (Wu and He, 2019). We\nchose R-BERT for our relation classification since\nit not only leverages the pretrained embeddings but\nalso transfers information of target entities (e.g.,\nevents in a relation) through model‚Äôs architecture\nand incorporates encodings of the targets entities.\nExamples of COPA and TCR are shown in Figure 4.\nBCOPA-CE has the same format as COPA.\nùëÉ: The computer crashed.ùêª!: I backed up my files.asks-for=‚Äùcause\"\nùêª\": I downloaded a virus.\nCOPATCRThe death toll <e1>climbed</e1>to 99 on Sunday after a suicide car bomb <e2>exploded</e2>Friday in the middle of a group of men playing volleyball in northwest Pakistan, police said.Cause-Effect(e1,e2)\n[CLS]The computer crashed.[SEP]I backed up my files.[SEP][CLS]The computer crashed.[SEP]I downloaded a virus.[SEP]\nFigure 4: COPA and TCR examples. The COPA in-\nstance is converted to Multiple Choice format.\n4 Results and Discussion\nResults of our experiments on TCR are shown in\nTable 1. As can be seen, our model significantly\noutperforms both our baseline and the joint infer-\n5We use the following implementation of R-BERT:\nhttps://github.com/monologg/R-BERT\n45\nence framework by Ning et al. (2018) formulated\nas an integer linear programming (ILP) problem.\nModel Acc (%)\nJoint system (Ning et al., 2018) 77.3\nBERT-large (baseline)‚ùà 75.0\nATOMIC-BERT-largeMLM ‚ùà 91.0\nTable 1: TCR Accuracy results. ‚ùà Our models\nResults of experiments on COPA-test are shown\nin Table 2. We initially observed that a continually\npretrained model using all three types of relations\nhas a lower performance than our baseline. By\ntaking a closer look at each relation type, we de-\ncided to train another model, this time only using\nthe event relations. The reason is that event-centric\nrelations in ATOMIC20\n20 specifically contain com-\nmonsense knowledge about event interaction for\nunderstating likely causal relations between events\nin the world (Hwang et al., 2021). In addition,\nevent relations have a relatively longer context (#\nof tokens) than the average of all three relation\ntypes combined which means more context for a\nmodel to learn from. Our new pretrained model out-\nperformed the baseline by nearly %5 which shows\nthe effect of augmented pretrained language model\nwith commonsense reasoning knowledge.\nModel Acc (%)\nPMI (Roemmele et al., 2011) 58.8\nb-l-reg(Han and Wang, 2021) 71.1\nGoogle T5-base (Raffel et al., 2019) 71.2\nBERT-large (Kavumba et al., 2019) 76.5\nCausalBERT (Li et al., 2020) 78.6\nBERT-SocialIQA (Sap et al., 2019)‚àó 80.1\nBERT-large (baseline)‚ùà 74.4\nATOMIC-BERT-largeMLM ‚ùà\n- Event only 79.2\nGoogle T5-11B (Raffel et al., 2019) 94.8\nDeBERTa-1.5B (He et al., 2020) 96.8\nTable 2: COPA-test Accuracy results. ‚ùà Our models.\n‚àó For a fair comparison, we report BERT-SocialIQA‚Äôs\naverage performance.\nWe further experiment on the Easy and Hard\nquestion splits in COPA-test separated by Kavumba\net al. (2019) to see how our best model performs\non harder questions that do not contain superficial\ncues. Results are shown in Table 3. As can be\nseen, our ATOMIC-BERT model significantly out-\nperforms both the baseline and former models on\nHard and Easy questions.\nModel Easy ‚Üë Hard‚Üë\n(Han and Wang, 2021) - 69.7\n(Kavumba et al., 2019) 83.9 71.9\nBERT-large (baseline)‚ùà 83.0 69.2\nATOMIC-BERT-large‚ùà 88.9 73.1\nTable 3: COPA-test Accuracy results on Easy and Hard\nquestion subsets. ‚ùà Our models.\nIt is worth mentioning three points here. First,\nour model, BERT-large, has a significantly lower\nnumber of parameters than state-of-the-art models,\nGoogle T5-11B (‚àº32x) and DeBERTa-1.5B (‚àº4x)\nand it shows how smaller models can be compet-\nitive and benefit from continual pretraining. Sec-\nond, we have not yet applied any model improve-\nment methods such as using a margin-based loss\nintroduced by Li et al. (2019) and used in Causal-\nBERT (Li et al., 2020), an extra regularization loss\nproposed by Han and Wang (2021), or fine-tuning\nwith quality-enhanced training data, BCOPA, intro-\nduced by Kavumba et al. (2019). As a result, there\nis still great room to improve current models that\ncan be a proper next step. Third, we achieved a per-\nformance on par with BERT-SocialIQA (Sap et al.,\n2019) 6 while we did not use crowdsourcing or any\nmanual re-writing/correction, which is expensive,\nfor verbalizing KG triples to create our pretraining\ndata.\nModel Acc (%)\nb-l-aug(Han and Wang, 2021) 51.1\nb-l-reg(Han and Wang, 2021) 64.1\nBERT-large (baseline)‚ùà 55.8\nATOMIC-BERT-largeMLM ‚ùà\n- Event only 58.1\nTable 4: BCOPA-CE Accuracy results. ‚ùà Our models.\n‚àó Base model in b-l-* is BERT-large.\n4.1 BCOPA-CE: Prompt vs. No Prompt\nResults of experiments on BCOPA-CE are shown\nin Table 4. As expected based on the results also\nreported by Han and Wang (2021), we initially ob-\nserved that our models are performing nearly as\nrandom baseline. Since we do not use the type\nof question when encoding input sequences, we\ndecided to see whether adding question type as a\nprompt to input sequences will improve the perfor-\nmance. We added It is because and As a\n6Our best random seed run achieved %81.4 accuracy.\n46\nresult, as prompt for asks-for=\"cause\"\nand asks-for=\"effect\", respectively. Inter-\nestingly, the new model outperforms the baseline\nand Han and Wang (2021)‚Äôsb-l-aug model that is\nfine-tuned with the same data as ours, when ques-\ntion types are added as prompts to input sequences\nof correct and incorrect answers in the test set. We\nalso ran a similar experiment on COPA-test (Ta-\nble 5) in which adding prompt did not help with\nperformance improvement.\nTrain / Test ‚úóPrompt ‚úìPrompt\n‚úóPrompt 79.2 76.4\n‚úìPrompt 75.5 77.9\nTable 5: COPA-test Accuracy ablation study results for\nprompt vs. no prompt.\n5 Conclusion\nWe introduced a simple framework for augmenting\nPLMs with commonsense knowledge created by\nautomatically verbalizing ATOMIC20\n20. Our results\nshow that commonsense knowledge-augmented\nPLMs outperform the original PLMs on cause-\neffect pair classification and answering common-\nsense causal reasoning questions. As the next\nstep, it would be interesting to see how the pre-\nviously proposed model improvement methods\nor using unbiased fine-tuning datasets can poten-\ntially enhance the performance of our knowledge-\naugmented models.\nReferences\nOshin Agarwal, Heming Ge, Siamak Shakeri, and Rami\nAl-Rfou. 2021. Knowledge graph based synthetic\ncorpus generation for knowledge-enhanced language\nmodel pre-training. In Proceedings of the 2021 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, pages 3554‚Äì3565.\nEduardo Blanco, Nuria Castell, and Dan I Moldovan.\n2008. Causal relation extraction. In Lrec.\nDu-Seong Chang and Key-Sun Choi. 2004. Causal\nrelation extraction using cue phrase and lexical pair\nprobabilities. In International Conference on Natural\nLanguage Processing, pages 61‚Äì70. Springer.\nDu-Seong Chang and Key-Sun Choi. 2006. Incremen-\ntal cue phrase learning and bootstrapping method\nfor causality extraction using cue phrase and word\npair probabilities. Information processing & manage-\nment, 42(3):662‚Äì678.\nDhairya Dalal, Mihael Arcan, and Paul Buitelaar. 2021.\nEnhancing multiple-choice question answering with\ncausal knowledge. In Proceedings of Deep Learning\nInside Out (DeeLIO): The 2nd Workshop on Knowl-\nedge Extraction and Integration for Deep Learning\nArchitectures, pages 70‚Äì80.\nTirthankar Dasgupta, Rupsa Saha, Lipika Dey, and Abir\nNaskar. 2018. Automatic extraction of causal rela-\ntions from text using linguistically informed deep\nneural networks. In Proceedings of the 19th Annual\nSIGdial Meeting on Discourse and Dialogue, pages\n306‚Äì316.\nJoe Davison, Joshua Feldman, and Alexander M Rush.\n2019. Commonsense knowledge mining from pre-\ntrained models. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 1173‚Äì1178.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nQuang Xuan Do, Yee Seng Chan, and Dan Roth. 2011.\nMinimally supervised event causality identification.\nIn Proceedings of the Conference on Empirical Meth-\nods in Natural Language Processing, pages 294‚Äì303.\nAssociation for Computational Linguistics.\nJesse Dunietz, Jaime G Carbonell, and Lori Levin. 2018.\nDeepcx: A transition-based approach for shallow se-\nmantic parsing with complex constructional triggers.\nIn Proceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1691‚Äì1701.\nLei Gao, Prafulla Kumar Choubey, and Ruihong Huang.\n2019. Modeling document-level causal structures for\nevent causal relation identification. In Proceedings\nof the 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long and\nShort Papers), pages 1808‚Äì1817.\nDaniela Garcia et al. 1997. Coatis, an nlp system to\nlocate expressions of actions connected by causality\nlinks. In International Conference on Knowledge En-\ngineering and Knowledge Management, pages 347‚Äì\n352. Springer.\nRoxana Girju. 2003. Automatic detection of causal re-\nlations for question answering. In Proceedings of\nthe ACL 2003 workshop on Multilingual summariza-\ntion and question answering-Volume 12, pages 76‚Äì83.\nAssociation for Computational Linguistics.\nJian Guan, Fei Huang, Zhihao Zhao, Xiaoyan Zhu, and\nMinlie Huang. 2020. A knowledge-enhanced pre-\ntraining model for commonsense story generation.\nTransactions of the Association for Computational\nLinguistics, 8:93‚Äì108.\n47\nSuchin Gururangan, Ana Marasovi ¬¥c, Swabha\nSwayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,\nand Noah A Smith. 2020. Don‚Äôt stop pretraining:\nAdapt language models to domains and tasks. In\nProceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics, pages\n8342‚Äì8360.\nMingyue Han and Yinglin Wang. 2021. Doing good\nor doing right? exploring the weakness of common-\nsense causal reasoning models. In Proceedings of the\n59th Annual Meeting of the Association for Compu-\ntational Linguistics and the 11th International Joint\nConference on Natural Language Processing (Vol-\nume 2: Short Papers), pages 151‚Äì157, Online. Asso-\nciation for Computational Linguistics.\nChikara Hashimoto, Kentaro Torisawa, Stijn De Saeger,\nJong-Hoon Oh, and Jun‚Äôichi Kazama. 2012. Ex-\ncitatory or inhibitory: A new semantic orientation\nextracts contradiction and causality from the web. In\nProceedings of the 2012 Joint Conference on Empir-\nical Methods in Natural Language Processing and\nComputational Natural Language Learning, pages\n619‚Äì630. Association for Computational Linguistics.\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and\nWeizhu Chen. 2020. Deberta: Decoding-enhanced\nbert with disentangled attention. arXiv preprint\narXiv:2006.03654.\nChristopher Hidey and Kathy McKeown. 2016. Identi-\nfying causal relations using parallel Wikipedia arti-\ncles. In Proceedings of the 54th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 1424‚Äì1433, Berlin, Ger-\nmany. Association for Computational Linguistics.\nJena D. Hwang, Chandra Bhagavatula, Ronan Le Bras,\nJeff Da, Keisuke Sakaguchi, Antoine Bosselut, and\nYejin Choi. 2021. Comet-atomic 2020: On sym-\nbolic and neural commonsense knowledge graphs. In\nAAAI.\nLeo Joskowicz, T Ksiezyck, and Ralph Grishman. 1989.\nDeep domain models for discourse analysis. In\n[1989] Proceedings. The Annual AI Systems in Gov-\nernment Conference, pages 195‚Äì200. IEEE.\nRandy M Kaplan and Genevieve Berry-Rogghe. 1991.\nKnowledge-based acquisition of causal relationships\nin text. Knowledge Acquisition, 3(3):317‚Äì337.\nPride Kavumba, Naoya Inoue, Benjamin Heinzerling,\nKeshav Singh, Paul Reisert, and Kentaro Inui. 2019.\nWhen choosing plausible alternatives, clever hans\ncan be clever. EMNLP 2019, page 33.\nChristopher SG Khoo, Jaklin Kornfilt, Robert N Oddy,\nand Sung Hyon Myaeng. 1998. Automatic extrac-\ntion of cause-effect information from newspaper text\nwithout knowledge-based inferencing. Literary and\nLinguistic Computing, 13(4):177‚Äì186.\nZhongyang Li, Tongfei Chen, and Benjamin Van Durme.\n2019. Learning to rank for plausible plausibility. In\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 4818‚Äì\n4823.\nZhongyang Li, Xiao Ding, Ting Liu, J Edward Hu, and\nBenjamin Van Durme. 2020. Guided generation of\ncause and effect. IJCAI.\nQiang Ning, Zhili Feng, Hao Wu, and Dan Roth. 2018.\nJoint reasoning for temporal and causal relations. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 2278‚Äì2288, Melbourne, Aus-\ntralia. Association for Computational Linguistics.\nJeffrey Pennington, Richard Socher, and Christopher D\nManning. 2014. Glove: Global vectors for word rep-\nresentation. In Proceedings of the 2014 conference\non empirical methods in natural language processing\n(EMNLP), pages 1532‚Äì1543.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2019. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. arXiv preprint arXiv:1910.10683.\nMelissa Roemmele, Cosmin Adrian Bejan, and An-\ndrew S Gordon. 2011. Choice of plausible alter-\nnatives: An evaluation of commonsense causal rea-\nsoning. In 2011 AAAI Spring Symposium Series.\nAnna Rogers, Matt Gardner, and Isabelle Augenstein.\n2021. Qa dataset explosion: A taxonomy of nlp\nresources for question answering and reading com-\nprehension. arXiv preprint arXiv:2107.12708.\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan\nLe Bras, and Yejin Choi. 2019. Social IQa: Com-\nmonsense reasoning about social interactions. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 4463‚Äì\n4473, Hong Kong, China. Association for Computa-\ntional Linguistics.\nShanchan Wu and Yifan He. 2019. Enriching pre-\ntrained language model with entity information for\nrelation classification. In Proceedings of the 28th\nACM international conference on information and\nknowledge management, pages 2361‚Äì2364.\nRowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin\nChoi. 2018. Swag: A large-scale adversarial dataset\nfor grounded commonsense inference. In Proceed-\nings of the 2018 Conference on Empirical Methods\nin Natural Language Processing, pages 93‚Äì104.\n48",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8030694127082825
    },
    {
      "name": "Commonsense reasoning",
      "score": 0.7733581066131592
    },
    {
      "name": "Commonsense knowledge",
      "score": 0.760408341884613
    },
    {
      "name": "Natural language processing",
      "score": 0.6339588165283203
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6153702735900879
    },
    {
      "name": "Language model",
      "score": 0.5932010412216187
    },
    {
      "name": "Relation (database)",
      "score": 0.5530840754508972
    },
    {
      "name": "Causal reasoning",
      "score": 0.5213485956192017
    },
    {
      "name": "Question answering",
      "score": 0.5154215097427368
    },
    {
      "name": "Graph",
      "score": 0.5082566142082214
    },
    {
      "name": "Causal model",
      "score": 0.44364750385284424
    },
    {
      "name": "Model-based reasoning",
      "score": 0.4298956096172333
    },
    {
      "name": "Knowledge graph",
      "score": 0.4101945757865906
    },
    {
      "name": "Machine learning",
      "score": 0.3585864305496216
    },
    {
      "name": "Knowledge representation and reasoning",
      "score": 0.33248692750930786
    },
    {
      "name": "Cognition",
      "score": 0.1633351445198059
    },
    {
      "name": "Data mining",
      "score": 0.15325379371643066
    },
    {
      "name": "Psychology",
      "score": 0.09651502966880798
    },
    {
      "name": "Theoretical computer science",
      "score": 0.07691973447799683
    },
    {
      "name": "Pathology",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    }
  ]
}