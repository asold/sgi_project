{
  "title": "Can ChatGPT Support Developers? An Empirical Evaluation of Large Language Models for Code Generation",
  "url": "https://openalex.org/W4391986589",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3178803803",
      "name": "Jin Kailun",
      "affiliations": [
        "York University"
      ]
    },
    {
      "id": null,
      "name": "Wang, Chung-Yu",
      "affiliations": [
        "York University"
      ]
    },
    {
      "id": "https://openalex.org/A1971583385",
      "name": "Pham Hung Viet",
      "affiliations": [
        "York University"
      ]
    },
    {
      "id": "https://openalex.org/A2743705350",
      "name": "Hemmati, Hadi",
      "affiliations": [
        "York University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4362659486",
    "https://openalex.org/W4318159335",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W4285284404",
    "https://openalex.org/W4321013654",
    "https://openalex.org/W4225108562",
    "https://openalex.org/W1981795678",
    "https://openalex.org/W4281763794"
  ],
  "abstract": "Large language models (LLMs) have demonstrated notable proficiency in code generation, with numerous prior studies showing their promising capabilities in various development scenarios. However, these studies mainly provide evaluations in research settings, which leaves a significant gap in understanding how effectively LLMs can support developers in real-world. To address this, we conducted an empirical analysis of conversations in DevGPT, a dataset collected from developers' conversations with ChatGPT (captured with the Share Link feature on platforms such as GitHub). Our empirical findings indicate that the current practice of using LLM-generated code is typically limited to either demonstrating high-level concepts or providing examples in documentation, rather than to be used as production-ready code. These findings indicate that there is much future work needed to improve LLMs in code generation before they can be integral parts of modern software development.",
  "full_text": "Can ChatGPT Support Developers? An Empirical Evaluation of\nLarge Language Models for Code Generation\nKailun Jin, Chung-Yu Wang, Hung Viet Pham, Hadi Hemmati\n{ktaming,cywang14,hvpham,hemmati}@yorku.ca\nYork University\nToronto, ON Canada\nABSTRACT\nLarge language models (LLMs) have demonstrated notable\nproficiency in code generation, with numerous prior studies\nshowing their promising capabilities in various development\nscenarios. However, these studies mainly provide evaluations\nin research settings, which leaves a significant gap in un-\nderstanding how effectively LLMs can support developers\nin real-world. To address this, we conducted an empirical\nanalysis of conversations in DevGPT, a dataset collected\nfrom developers’ conversations with ChatGPT (captured\nwith the Share Link feature on platforms such as GitHub).\nOur empirical findings indicate that the current practice\nof using LLM-generated code is typically limited to either\ndemonstrating high-level concepts or providing examples in\ndocumentation, rather than to be used as production-ready\ncode. These findings indicate that there is much future work\nneeded to improve LLMs in code generation before they can\nbe integral parts of modern software development.\nACM Reference Format:\nKailun Jin, Chung-Yu Wang, Hung Viet Pham, Hadi Hemmati.\n2024. Can ChatGPT Support Developers? An Empirical Evalu-\nation of Large Language Models for Code Generation. In21st\nInternational Conference on Mining Software Repositories (MSR\n’24), April 15–16, 2024, Lisbon, Portugal.ACM, New York, NY,\nUSA, 5 pages. https://doi.org/10.1145/3643991.3645074\n1 INTRODUCTION\nThe field of Artificial Intelligence (AI) has seen a major para-\ndigm shift, characterized by powerful Large Language Models\n(LLMs) [6]. Recently, LLMs such as CodeGPT [13], Code-\nParrot [20], and Codex [4] have demonstrated their ability\nto facilitate code completion [25], source code mapping [10],\nsystem maintenance, [22] and other related Software Engi-\nneering tasks. Their contribution to software development is\nfurther reinforced by the iterative improvement through the\ncollaboration between humans and AI [18].\nPermission to make digital or hard copies of all or part of this work\nfor personal or classroom use is granted without fee provided that\ncopies are not made or distributed for profit or commercial advantage\nand that copies bear this notice and the full citation on the first page.\nCopyrights for components of this work owned by others than the au-\nthor(s) must be honored. Abstracting with credit is permitted. To copy\notherwise, or republish, to post on servers or to redistribute to lists,\nrequires prior specific permission and/or a fee. Request permissions\nfrom permissions@acm.org.\nMSR ’24, April 15–16, 2024, Lisbon, Portugal\n© 2024 Copyright held by the owner/author(s). Publication rights\nlicensed to ACM.\nACM ISBN 979-8-4007-0587-8/24/04...$15.00\nhttps://doi.org/10.1145/3643991.3645074\nHowever, amidst the promising developments, it is not\nclear how practical the integration of these LLMs into real-\nworld production software development is, as prior work only\ndemonstrates LLMs’ potential in research settings. Specifi-\ncally, the use of ChatGPT has not been studied as well as\nother code models yet [3]. Hence, it is imperative to criti-\ncally evaluate the limitations and practicality of applying\nChatGPT in real-world data practice.\nTo address this evaluation gap, this paper focuses on two\nkey research questions (RQs):\n∙ RQ1: How do the developers interact with ChatGPT for\ncode generation?\n∙ RQ2: How helpful is the code generated by ChatGPT in\nassisting developers?\nRQ1 seeks to understand the structure of conversations be-\ntween developers and ChatGPT during code generation which\nindicates the dynamics of collaboration and can affect the\nquality of code produced. It will also help identify future direc-\ntion on how to better interact with LLMs through prompts,\nin this domain. RQ2 explores deeper into the usage of the\ngenerated code and studies to what extent the output of\nChatGPT is useful for developers.\nThe main contributions of this work are:\n∙ A detailed analysis of the real-world interactions between\ndevelopers and ChatGPT\n∙ An empirical examination of the usage of generated code\nresulted from developers and ChatGPT\n∙ A publicly available dataset of developers and ChatGPT\ninteractions, labelled with the prompt types and the final\nuse cases of the generated code.\n2 STUDY DESIGN\nThe main goal of this study is to gain valuable insights into\nhow ChatGPT are now being utilized as a tool in real-world\ncode practice, which can help direct future research in this\ndomain. We focus on answering two key Research Questions\n(RQs). RQ1 seeks to investigate the characteristics of the\ninteraction between the developers and LLMs. Specifically,\nin RQ1.1, we explore where exactly in the development pro-\ncess ChatGPT is being used. RQ1.2 studies the length of\nconversation between the developers and ChatGPT as the\naverage number of prompt-response rounds needed to reach\na satisfactory conclusion. And finally, RQ1.3 is designed to\nidentify the common categories in which developers improve\nChatGPT’s output using different prompting strategies.\nRQ2 targets to understand how and to what extent devel-\nopers utilize generated code in production.\narXiv:2402.11702v2  [cs.SE]  16 Mar 2024\nMSR ’24, April 15–16, 2024, Lisbon, Portugal Kailun Jin, Chung-Yu Wang, Hung Viet Pham, Hadi Hemmati\n2.1 DevGPT Dataset\nTo answer the mentioned RQs, we utilize the DevGPT [24]\ndataset. It is formed by searching with the keyword “https:\n//chat.openai.com/share/” in the GitHub GraphQL API to\nidentify mentions of shared links sourced from software de-\nvelopment artifacts, such as source code, commits, issues,\npull requests, discussions, and Hacker News threads. Eventu-\nally, DevGPT comprised 17,913 prompts and ChatGPT’s re-\nsponses, which encompass 11,751 code snippets. The dataset\nprovides six snapshots at six specific points from July 24th\nto August 31st, 2023.\n2.2 RQ1 Design\nTo answer RQ1, we followed two steps: (a) Automated data\ncleaning and (b) Manual labelling.\nAutomated data cleaning:The original DevGPT dataset com-\nprised ChatGPT Sharing URLs from GitHub and Hacker\nNews references. Since this study focuses on interactions be-\ntween developers and ChatGPT on GitHub, we filter out con-\nversations from Hacker News sources. DevGPT includes Chat-\nGPT conversations linked from five GitHub artifacts: source\nCode files, Commits, Issues, Pull requests, andDiscussions.\nThe DevGPT dataset contains JSON files documenting the\ndetails of each ChatGPT interaction. Parsing the “Conversa-\ntions”attribute intheJSON files allowsus to extractthetotal\nnumber of conversation rounds for each ChatGPT interaction.\nHowever, during our analysis, we identified instances where\nconversations included irrelevant prompt-response rounds\nsuch as expressions of gratitude and greetings to ChatGPT.\nFor instance, following a successful solution, developers fre-\nquently express their appreciation by stating, “Thank you,\nthe approach worked”, bringing the conversation to a close.\nAlternatively, they might commence the interaction with a\ngreeting such as, “Hi, can you help me with the problem?”.\nTo eliminate such prompts, two co-authors conducted man-\nual reviews of the conversations and excluded a total of 344\nirrelevant conversation rounds from the 2,299 conversations\nrelated to code generation. To ensure the conversations were\ncorrectly reviewed, each conversation was reviewed by both\nauthors and any disagreement was resolved with a discussion.\nManual labeling:To address RQ1.3, we looked into how devel-\nopers use the prompts to have a conversation with ChatGPT\nfor code generation and how they evolve their prompts to\nimprove the outputs. We used an existing list of categories\nfrom a recent study [18] where the authors have looked into\nthe same problem but within a small interview study.\nIn our case, due to the volume of data to label, we utilize\nthe crowd-sourcing process to label each data sample (each\nconversation) using one of the labels [18] as shown in Table 2.\nTo run the crowd-sourcing, first, we developed a descrip-\ntion of the task with clear instructions and examples based\non the definitions above. The task is assigning each pair of\ngenerated code (accessed via the given ChatGPT sharing\nlink) and changed source code (access via the given source\nGithub link) to one of the 9 categories as shown in Table 2.\nUsing crowd-sourcing methods, we distributed the 2,299 valid\ndata entries to volunteers whom we recruited from our local\nsoftware engineering community. The crowdsourcing model\nleverages the experience and diversity of our local software\nengineering community to ensure the high-quality and profes-\nsional classification of data. Each pair of data was reviewed\nby three developers and the majority was used as the label.\nIf all three initial judgments were completely different, the\nopinions of another two developers were added. We continue\nadding two more opinions until a category gets at least two\nvotes more than any other category.\n2.3 RQ2 Design\nTo answer RQ2 we look into code generation conversations\nthat are shared in Pull Requests. As shown in Table 1, there\nare 189 distinct conversations pertaining to code generation\nwithin the Pull Request category. To efficiently determine\nwhether the generated code is implemented in the actual\nproduction system, we utilized the “View review changes”\nfunctionality for each merged Pull Request on GitHub. Con-\nsequently, we excluded 51 Pull Request records that were not\nmerged into the primary project, resulting in 138 merged Pull\nRequests forming the basis for our data in terms of usage\nclassification.\nDuring our initial investigation, we found that some of the\ngenerated code snippets are used in the master branch (either\ndirectly as a copy, with some modifications, or integrated\nonly into the instructional document), while a lot of them\nwere not used at all. Thus we assign each generated code\nsnippet with one of the following labels, manually (leveraging\nthe View review changes functionality of GitHub) labeled by\ntwo co-authors (independently, and then double checked and\ndiscussed if disagreed until resolved):\n∙ Exact Matchdenotes instances where developers employed\nthe code exactly as generated by LLM without any modifi-\ncations.\n∙ Modified Codesignifies cases where developers made slight\nalterations to certain sections of the generated code to\nalign with the production code.\n∙ Document encompasses situations where developers incor-\nporated the generated code into instructional documents,\nsuch as README or test case files.\n∙ Supplementary Infocharacterizes scenarios where develop-\ners did not directly employ the generated code but provided\nit as supplementary information or as a source of concep-\ntual inspiration.\nTo verify the accuracy of the labels, each code snippet was\nreviewed by both authors and any disagreement was resolved\nwith a discussion.\n3 RESULT AND DISCUSSION\nIn this section, we will present our findings on RQ1 and 2.\n3.1 RQ1: How do the developers interact with\nChatGPT for code generation?\nTo investigate the interaction between developers and Chat-\nGPT across different timestamps, we extracted and filtered\nall accessible and distinct conversations from each of the six\nCan ChatGPT Support Developers? An Empirical Evaluation of Large Language Models for Code Generation MSR ’24, April 15–16, 2024, Lisbon, Portugal\nTable 1: The number of analyzed conversations between Chat-\nGPT and developers.\nGitHub categories CG Non-CG Both % of CG\nPull Request 189 79 268 70.5%\nIssue 362 154 516 70.2%\nDiscussion 36 23 59 61.0%\nCommit 660 10 670 98.5%\nCode File 1052 958 2010 52.3%\nTotal 2299 1224 3523 65.3%\nsnapshots in the DevGPT dataset. Parsing JSON files and\nchoosing conversations with multiple instances of “Listof-\nCode” in ChatGPT’s responses, we categorize a conversation\nas related to code generation (CG) if it contains at least\none code snippet in ChatGPT’s responses. Table 1 displays\nthe number of conversations categorized as related to code\ngeneration (CG) and not related to code generation (Non-\nCG). The conversations are split into five GitHub categories\n(five rows) with a total number of analyzed conversations\nlisted in the Total row. The five categories correspond to the\nsources of conversations (i.e.,Pull Request, Issue, Discussion,\nCommit, and SourceCode file. For each category, the number\nof CG, Non-CG, and both types of conversations along with\nthe percentage of CG-related conversations are listed in the\ncorresponding row.\nRQ1.1: What is the distribution of conversations from different\nGitHub sources?Overall, we analyze 3523 conversations with\n65.3% of them are CG-related. Our analysis shows that while,\nthe majority of conversations occurred in the context of code\nfiles (2010), only about half (52.3%) of them are directly\nassociated with code generation which is the lowest among\nall categories. In contrast, the Commit category exhibits a\nmarkedly high association with code generation with the\nmajority of conversations (98.5%) involving some form of\ncode snippet generation. Our manual analysis shows that, in\ncode file conversations, developers often seek clarification on\ncertain code snippets rather than asking for code generation.\nOn the other hand, during Commit-related discussions, de-\nvelopers frequently ask ChatGPT to improve provided code\nsnippets. A further explanation is mentioned in RQ1.2.\nRQ1.2: How many prompt-response rounds does it take on\naverage upon conclusion?To further analyze the characteris-\ntics of the conversations between developers and ChatGPT\nin a code-generating context, we investigate the number of\nprompt-response rounds required for each CG-related con-\nversation to reach its conclusion. Due to the presence of\nirrelevant conversation rounds at times, we manually ana-\nlyze each CG-related conversation and count the number\nof rounds required for the code-generation question to be\nsatisfactorily answered by ChatGPT. Figure?? shows the\nbox plot that represents the distribution of the number of\nrequired prompt-response rounds for the five GitHub cate-\ngories. The means are represented by the red stars and the\nmedians are represented by the orange lines.\nFigure ?? highlights that conversations in the Commit\ncontext lasted on average only 2.4 rounds while conversations\nTable 2: The number of studied code generation conversations\nper prompt category, as defined by Shin at el[18]\nCategories Count\nRequest improvements 613\nRequest more description 353\nAdd specific instructions 351\nAsk questions to find correct way 297\nAdd more context 256\nRequest examples 155\nRequest verification 93\nPoint mistake then request fix 112\nRequest another generation 69\nTotal 2299\nin the Code file context lasted on average significantly longer\nat 10.4 rounds.\nRQ1.3: How do developers use ChatGPT to improve their\ncode? As described in Section 2, to investigate how developers\nuse ChatGPT to improve their code, we analyze the six\ncheckpoints from DevGPT. We manually categorized the\ndata based on the nine conversational prompting categories,\nas proposed by Shin et al. [18]. Table 2 shows the number of\nstudied conversations per category.\nMost of the conversations (more than a quarter) are about\n“Request improvements” while only a few are about “Request\nexamples” or “Request verification”. After consolidating the\nfindings from RQ1.2, it was observed that 64.98% of conversa-\ntions sourced from Commit focused onCode Improvement, in-\ncluding “request improvements”, “Add specific instructions”,\n“Add more context”, “Request verification”, “Point mistake\nthen request fix” and “Request another generation”. Addi-\ntionally, 35.02% of conversations within Code files centred\naround Code Clarification and Explanation, such as “Request\nmore description”, “Ask questions to find correct way” and\n“request examples”. The result explains that, when developers\nprovide specific code snippets directly to ChatGPT for im-\nprovement (in the Commit context), the desirable outcomes\nare likely achieved quicker with fewer clarifications or expla-\nnations of the prompts. Conversely, more prompt-response\nrounds are needed to explain and clarify code functions in\nCode file conversations.\nTable 2 shows that “Request another generation” conver-\nsation is rare. We suspect that since GPT-3.5 is based on\ntransformer architecture, it will tend to “remember” recent\nconversations and “forget” older context[8]. This leads to\nadditional generation requests to confuse ChatGPT into gen-\nerating bad-quality code, hence the developers avoided this\noption.\n3.2 RQ2: How helpful is the code generated by\nChatGPT in assisting developers?\nAs described in Section 2, we categorize the conversation\nbased on how the generated code snippets are used (if at all)\nin the master branch of the corresponding project. Figure 1\nshows the proportions of conversation in each usage category.\nMSR ’24, April 15–16, 2024, Lisbon, Portugal Kailun Jin, Chung-Yu Wang, Hung Viet Pham, Hadi Hemmati\nFigure 1: The proportion of different generated code usages\nin real-world projects\nAs shown in Figure 1, in most cases, the generated code is\nSupplementary Infoto developers, perhaps due to the inferior\nquality. For instance, a commit conversation indicates that\nthe generated code is considered unhelpful, causing a notable\nslowdown instead of enhancing code execution speed. Some-\ntimes (24.4%), the code snippets are used in instructional\nDocuments or test cases. For instance, developers could re-\nquest ChatGPT to generate a README file by providing a\nprompt that includes descriptions of the GitHub repository.\nIn 16.8% of conversations, the generated code snippets are\nExact Matchesto the code in the master branch of the corre-\nsponding projects. In such cases, the snippets are used exactly\nor with very trivial modifications. For instance, developers\nsubmit a prompt that encompasses a segment of the source\ncode along with details about an exception they encountered.\nThey request ChatGPT to identify and modify the source\ncode. The generated code is subsequently employed directly\nin the source code without any further modifications.\nIn some other cases (26%), the generated code snippets\nare heavilyModified before being included in the source code\nof the corresponding projects. For instance, developers might\nrename variables or add exception handling before merging\ninto the primary project.\n3.3 Discussion\nSurvivorship bias poses a validity threat in the DevGPT\nconversations dataset, as it is constructed from retained con-\nversations, potentially overlooking a broader spectrum of\ndeveloper interactions. The filtering bias, where developers\nare less likely to include ChatGPT URLs in commit messages\nif the generated code’s quality is too low. This may skew the\ndataset towards resolved discussions. Therefore, conclusions\nlike \"Commits often require fewer prompt-response rounds\non average\" and \"a majority of conversations occurred in the\ncontext of code files,\" may be based on incomplete informa-\ntion. We acknowledge dataset limitations based on empirical\nexperience during manual dataset processing, but lack of\nquantitative evidence. Future work might need to address\nthis threat is essential for more robust conclusions.\n4 RELATED WORK\nEvaluation of LLMs in generating code: Recent improve-\nments [21, 26] in LLMs’ code generation ability has brought\nattention to evaluating LLM-generated code from research\ncommunities.LLMshavebeenevaluatedintermsofgenerated\ncode correctness [1, 4, 12], robustness [26]. Prior work [5, 26]\nhas also conducted human studies to evaluate how code gen-\neration supports developers in their tasks. These studies have\ndemonstrated the potential of LLMs in code generation, how-\never, they were all conducted in research settings. Hence\nthe LLMs’ effectiveness in real-world scenarios is inconclu-\nsive. [19]. This study focuses on accessing the code generation\ncapabilities of LLMs using data scraped from an open-source\nplatform dedicated to software development.\nInteraction with LLMs regarding source code:Prior studies\nanalyze the interaction of developers with LLMs to improve\nthe usability [2] and reliability [15] of code generation. Prior\nstudies discovered that LLMs reduce distractions during soft-\nware development [11] and introduce fewer vulnerabilities [16].\nHowever, studies have shown that both novices (e.g., stu-\ndents) [14] and experienced developers [17] can struggle to\nuse LLMs on programming tasks. Our study provides some\ninsight on all of the above aspects when LLMs are used in\nreal-world development settings.\nCode generation on software development platforms:Stack-\nOverflow and GitHub are the two most popular platforms\nused in software development for purposes such as commu-\nnication, question-answering, and collaborative efforts [23].\nRecently, LLMs have been used to generate code addressing\nproblems raised on these platforms. [9, 26]. However, there\nhave been limited prior studies that analyze the actual us-\nage of such generated code in real-world workflow[7]. This\nstudy aims to bridge that gap and provide additional insight\ninto how LLM code generation is integrated into software\ndevelopment.\n5 CONCLUSION\nLargelanguagemodelssuchasChatGPThaveshownpromises\nin code generation.\nOur study reveals that while a majority of ChatGPT con-\nversations within code files focus on discussions, only half\nare related to code generation. Commit-related interactions\npredominantly revolve around code improvement, with fewer\nprompt-response rounds. Developers primarily use ChatGPT\nfor requesting improvements and tend to avoid additional\ncode generation within the same conversation to prevent\nconfusion. Notably, 32.8% of generated code is not used, em-\nphasizing the need for further exploration of the practical\nutility of AI-generated code. These insights provide valuable\nconsiderations for refining AI-assisted development tools and\nenhancing collaboration between developers and AI systems.\nMuch improvement is needed before LLMs become an integral\npart of modern software development.\n6 ACKNOWLEDGEMENT\nThis work was partly supported by NSERC and Alberta\nInnovates.\nCan ChatGPT Support Developers? An Empirical Evaluation of Large Language Models for Code Generation MSR ’24, April 15–16, 2024, Lisbon, Portugal\nREFERENCES\n[1] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma,\nHenryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai,\nMichael Terry, Quoc Le, et al. 2021. Program synthesis with\nlarge language models.arXiv preprint arXiv:2108.07732(2021).\n[2] Shraddha Barke, Michael B James, and Nadia Polikarpova.\n2023. Grounded copilot: How programmers interact with code-\ngenerating models. Proceedings of the ACM on Programming\nLanguages 7, OOPSLA1 (2023), 85–111.\n[3] Christian Bird, Denae Ford, Thomas Zimmermann, Nicole Fors-\ngren, Eirini Kalliamvakou, Travis Lowdermilk, and Idan Gazit.\n2023. Taking Flight with Copilot: Early Insights and Opportu-\nnities of AI-Powered Pair-Programming Tools.Queue 20, 6 (jan\n2023), 35–57. https://doi.org/10.1145/3582083\n[4] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique\nPonde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri\nBurda, Nicholas Joseph, Greg Brockman, et al. 2021. Evalu-\nating large language models trained on code. arXiv preprint\narXiv:2107.03374 (2021).\n[5] Yunhe Feng, Sreecharan Vanam, Manasa Cherukupally, Weijian\nZheng, Meikang Qiu, and Haihua Chen. 2023. Investigating Code\nGeneration Performance of Chat-GPT with Crowdsourcing Social\nData. InProceedings of the 47th IEEE Computer Software and\nApplications Conference. 1–10.\n[6] Luciano Floridi and Massimo Chiriatti. 2020. GPT-3: Its nature,\nscope, limits, and consequences.Minds and Machines30 (2020),\n681–694.\n[7] Mehdi Golzadeh, Tom Mens, Alexandre Decan, Eleni Constanti-\nnou, and Natarajan Chidambaram. 2022. Recognizing bot activity\nin collaborative software development.IEEE Software39, 5 (Sept.\n2022), 56–61. https://doi.org/10.1109/MS.2022.3178601\n[8] Albert Gu, Caglar Gulcehre, Tom Le Paine, Matt Hoffman, and\nRazvan Pascanu. 2020. Improving the Gating Mechanism of\nRecurrent Neural Networks. arXiv:1910.09890 [cs.NE]\n[9] Jae Yong Lee, Sungmin Kang, Juyeon Yoon, and Shin Yoo. 2023.\nThe GitHub Recent Bugs Dataset for Evaluating LLM-based De-\nbugging Applications. arXiv preprint arXiv:2310.13229(2023).\n[10] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff,\nDenis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki,\nJia Li, Jenny Chim, et al. 2023. StarCoder: may the source be\nwith you! arXiv preprint arXiv:2305.06161(2023).\n[11] Jenny T Liang, Chenyang Yang, and Brad A Myers. 2023. Un-\nderstanding the Usability of AI Programming Assistants.arXiv\npreprint arXiv:2303.17125(2023).\n[12] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming\nZhang. 2023. Is your code generated by chatgpt really correct?\nrigorous evaluation of large language models for code generation.\narXiv preprint arXiv:2305.01210(2023).\n[13] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svy-\natkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin\nJiang, Duyu Tang, Ge Li, Lidong Zhou, Linjun Shou, Long Zhou,\nMichele Tufano, Ming Gong, Ming Zhou, Nan Duan, Neel Sun-\ndaresan, Shao Kun Deng, Shengyu Fu, and Shujie Liu. 2021.\nCodeXGLUE: A Machine Learning Benchmark Dataset for Code\nUnderstanding and Generation. arXiv:2102.04664 [cs.SE]\n[14] James Prather, Brent N Reeves, Paul Denny, Brett A Becker, Juho\nLeinonen, Andrew Luxton-Reilly, Garrett Powell, James Finnie-\nAnsley, and Eddie Antonio Santos. 2023. \" It’s Weird That it\nKnows What I Want\": Usability and Interactions with Copilot for\nNovice Programmers. arXiv preprint arXiv:2304.02491(2023).\n[15] Steven I Ross, Fernando Martinez, Stephanie Houde, Michael\nMuller, and Justin D Weisz. 2023. The programmer’s assistant:\nConversational interaction with a large language model for soft-\nware development. InProceedings of the 28th International Con-\nference on Intelligent User Interfaces. 491–514.\n[16] Gustavo Sandoval, Hammond Pearce, Teo Nys, Ramesh Karri,\nBrendan Dolan-Gavitt, and Siddharth Garg. 2022. Security im-\nplications of large language model code assistants: A user study.\narXiv preprint arXiv:2208.09727(2022).\n[17] Advait Sarkar, Andrew D Gordon, Carina Negreanu, Christian\nPoelitz, Sruti Srinivasa Ragavan, and Ben Zorn. 2022. What is\nit like to program with artificial intelligence? arXiv preprint\narXiv:2208.06213 (2022).\n[18] Jiho Shin, Clark Tang, Tahmineh Mohati, Maleknaz Nayebi, Song\nWang, and Hadi Hemmati. 2023. Prompt Engineering or Fine\nTuning: An Empirical Assessment of Large Language Models in\nAutomated Software Engineering Tasks. arXiv:2310.10508 [cs.SE]\n[19] Giriprasad Sridhara, Sourav Mazumdar, et al. 2023. ChatGPT:\nA Study on its Utility for Ubiquitous Software Engineering Tasks.\narXiv preprint arXiv:2305.16837(2023).\n[20] Lewis Tunstall, Leandro Von Werra, and Thomas Wolf. 2022.Nat-\nural Language Processing with Transformers, Revised Edition.\n\"O’Reilly Media, Inc.\".\n[21] Priyan Vaithilingam, Tianyi Zhang, and Elena L Glassman. 2022.\nExpectation vs. experience: Evaluating the usability of code gener-\nation tools powered by large language models. InChi conference\non human factors in computing systems extended abstracts. 1–7.\n[22] Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song\nWang, and Qing Wang. 2023. Software testing with large lan-\nguage model: Survey, landscape, and vision. arXiv preprint\narXiv:2307.07221 (2023).\n[23] Shaowei Wang, David Lo, and Lingxiao Jiang. 2013. An empirical\nstudy on developer interactions in stackoverflow. InProceedings\nof the 28th annual ACM symposium on applied computing. 1019–\n1024.\n[24] Tao Xiao, Christoph Treude, Hideaki Hata, and Kenichi Mat-\nsumoto. 2024. DevGPT: Studying Developer-ChatGPT Conversa-\ntions. InProceedings of the International Conference on Mining\nSoftware Repositories (MSR 2024).\n[25] Frank F Xu, Uri Alon, Graham Neubig, and Vincent Josua Hel-\nlendoorn. 2022. A systematic evaluation of large language models\nof code. InProceedings of the 6th ACM SIGPLAN International\nSymposium on Machine Programming. 1–10.\n[26] Li Zhong and Zilong Wang. 2023. A study on robustness and\nreliability of large language model code generation.arXiv preprint\narXiv:2308.10335 (2023).",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7939363121986389
    },
    {
      "name": "Programming language",
      "score": 0.5667378306388855
    },
    {
      "name": "Code generation",
      "score": 0.533721923828125
    },
    {
      "name": "Code (set theory)",
      "score": 0.5298264622688293
    },
    {
      "name": "Code review",
      "score": 0.5108792185783386
    },
    {
      "name": "Software engineering",
      "score": 0.3776276409626007
    },
    {
      "name": "Static program analysis",
      "score": 0.2667122781276703
    },
    {
      "name": "Software",
      "score": 0.15960410237312317
    },
    {
      "name": "Software development",
      "score": 0.12207069993019104
    },
    {
      "name": "Operating system",
      "score": 0.11396202445030212
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    },
    {
      "name": "Key (lock)",
      "score": 0.0
    }
  ]
}