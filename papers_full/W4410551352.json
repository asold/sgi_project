{
    "title": "A foundation model for the Earth system",
    "url": "https://openalex.org/W4410551352",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A4222229419",
            "name": "Bodnar, Cristian",
            "affiliations": [
                "Silicon Designs (United States)",
                "Microsoft (Netherlands)"
            ]
        },
        {
            "id": "https://openalex.org/A4221965596",
            "name": "Bruinsma, Wessel P.",
            "affiliations": [
                "Microsoft (Netherlands)"
            ]
        },
        {
            "id": "https://openalex.org/A4202120612",
            "name": "Lucic, Ana",
            "affiliations": [
                "Microsoft (Netherlands)",
                "University of Amsterdam"
            ]
        },
        {
            "id": "https://openalex.org/A4288853281",
            "name": "Stanley, Megan",
            "affiliations": [
                "Microsoft (Netherlands)"
            ]
        },
        {
            "id": null,
            "name": "Allen, Anna",
            "affiliations": [
                "University of Cambridge"
            ]
        },
        {
            "id": "https://openalex.org/A4225900670",
            "name": "Brandstetter, Johannes",
            "affiliations": [
                "Microsoft (Netherlands)",
                "Johannes Kepler University of Linz"
            ]
        },
        {
            "id": null,
            "name": "Garvan, Patrick",
            "affiliations": [
                "Microsoft (Netherlands)"
            ]
        },
        {
            "id": "https://openalex.org/A4288917376",
            "name": "Riechert, Maik",
            "affiliations": [
                "Microsoft (Netherlands)"
            ]
        },
        {
            "id": "https://openalex.org/A4362450741",
            "name": "Weyn, Jonathan A",
            "affiliations": [
                "Microsoft (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2367904931",
            "name": "Dong, Haiyu",
            "affiliations": [
                "Microsoft (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A4221862930",
            "name": "Gupta, Jayesh K.",
            "affiliations": [
                "Silicon Designs (United States)",
                "Microsoft (United States)"
            ]
        },
        {
            "id": null,
            "name": "Thambiratnam, Kit",
            "affiliations": [
                "Microsoft (United States)"
            ]
        },
        {
            "id": null,
            "name": "Archibald, Alexander T.",
            "affiliations": [
                "University of Cambridge"
            ]
        },
        {
            "id": "https://openalex.org/A4317467313",
            "name": "Wu Chun-Chieh",
            "affiliations": [
                "National Taiwan University"
            ]
        },
        {
            "id": null,
            "name": "Heider, Elizabeth",
            "affiliations": [
                "Microsoft (Netherlands)"
            ]
        },
        {
            "id": "https://openalex.org/A4221603798",
            "name": "Welling, Max",
            "affiliations": [
                "Microsoft (Netherlands)",
                "University of Amsterdam"
            ]
        },
        {
            "id": "https://openalex.org/A4222746451",
            "name": "Turner, Richard E.",
            "affiliations": [
                "The Alan Turing Institute",
                "University of Cambridge",
                "Microsoft (Netherlands)"
            ]
        },
        {
            "id": "https://openalex.org/A4221646617",
            "name": "Perdikaris, Paris",
            "affiliations": [
                "Microsoft (Netherlands)",
                "University of Pennsylvania"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6964120315",
        "https://openalex.org/W4383218913",
        "https://openalex.org/W4388654737",
        "https://openalex.org/W4396721167",
        "https://openalex.org/W1498436455",
        "https://openalex.org/W2031580446",
        "https://openalex.org/W2075022329",
        "https://openalex.org/W2001675020",
        "https://openalex.org/W2160203977",
        "https://openalex.org/W2089080766",
        "https://openalex.org/W2146235859",
        "https://openalex.org/W1985864871",
        "https://openalex.org/W2084547407",
        "https://openalex.org/W4246045209",
        "https://openalex.org/W4388728292",
        "https://openalex.org/W4391513958",
        "https://openalex.org/W4362706666",
        "https://openalex.org/W3138516171",
        "https://openalex.org/W3134144764",
        "https://openalex.org/W3190965961",
        "https://openalex.org/W2617759587",
        "https://openalex.org/W6963479928",
        "https://openalex.org/W2900933286",
        "https://openalex.org/W6755722108",
        "https://openalex.org/W6945294104",
        "https://openalex.org/W4312160734",
        "https://openalex.org/W4232492625",
        "https://openalex.org/W6944576743",
        "https://openalex.org/W6769905080",
        "https://openalex.org/W278168223",
        "https://openalex.org/W3105826485",
        "https://openalex.org/W4210904397",
        "https://openalex.org/W4290855687",
        "https://openalex.org/W4382048606",
        "https://openalex.org/W4403620447",
        "https://openalex.org/W6908435960",
        "https://openalex.org/W1645858368",
        "https://openalex.org/W4379925125",
        "https://openalex.org/W4392284590",
        "https://openalex.org/W4403667177",
        "https://openalex.org/W4408435224",
        "https://openalex.org/W4395010148",
        "https://openalex.org/W4408657432",
        "https://openalex.org/W3212191691",
        "https://openalex.org/W4312349930",
        "https://openalex.org/W6796581206",
        "https://openalex.org/W2145339207",
        "https://openalex.org/W2023227600",
        "https://openalex.org/W6671488044",
        "https://openalex.org/W4386075535",
        "https://openalex.org/W6847218314",
        "https://openalex.org/W4386346187",
        "https://openalex.org/W4399779937",
        "https://openalex.org/W6888839266",
        "https://openalex.org/W6869497118",
        "https://openalex.org/W4384268586",
        "https://openalex.org/W3003709258",
        "https://openalex.org/W3080366021",
        "https://openalex.org/W4225591000",
        "https://openalex.org/W6853517571",
        "https://openalex.org/W2011301426",
        "https://openalex.org/W6893294234",
        "https://openalex.org/W6772383348"
    ],
    "abstract": null,
    "full_text": "1180 | Nature | Vol 641 | 29 May 2025\nArticle\nA foundation model for the Earth system\nCristian Bodnar1,2,11, Wessel P . Bruinsma1,11, Ana Lucic1,3,11, Megan Stanley1,11, Anna Allen4,11, \nJohannes Brandstetter1,5, Patrick Garvan1, Maik Riechert1, Jonathan A. Weyn6, Haiyu Dong6, \nJayesh K. Gupta2,7, Kit Thambiratnam6, Alexander T . Archibald4, Chun-Chieh Wu8, \nElizabeth Heider1, Max Welling1,3, Richard E. Turner1,4,9 & Paris Perdikaris1,10 ✉\nReliable forecasting of the Earth system is essential for mitigating natural disasters \nand supporting human progress. Traditional numerical models, although powerful, \nare extremely computationally expensive1. Recent advances in artificial intelligence \n(AI) have shown promise in improving both predictive performance and efficiency2,3, \nyet their potential remains underexplored in many Earth system domains. Here we \nintroduce Aurora, a large-scale foundation model trained on more than one million \nhours of diverse geophysical data. Aurora outperforms operational forecasts in \npredicting air quality, ocean waves, tropical cyclone tracks and high-resolution \nweather, all at orders of magnitude lower computational cost. With the ability to be \nfine-tuned for diverse applications at modest expense, Aurora represents a notable \nstep towards democratizing accurate and efficient Earth system predictions. These \nresults highlight the transformative potential of AI in environmental forecasting  \nand pave the way for broader accessibility to high-quality climate and weather \ninformation.\nEarth system forecasts are indispensable tools for human societies, \nas evidenced by recent natural events such as the floods in Valencia, \nthe air quality crisis in New Delhi and hurricanes Helene and Milton in \nthe eastern United States. Such systems not only provide crucial early \nwarnings for extreme events but are also important for diverse appli-\ncations ranging from agriculture to healthcare to global commerce. \nModern Earth system predictions rely on complex models developed \nusing centuries of accumulated physical knowledge, providing global \nforecasts of diverse variables for weather, air quality, ocean currents, \nsea ice and hurricanes.\nDespite their vital role, Earth system forecasting models face several \nlimitations. They are computationally demanding, often requiring \npurpose-built supercomputers and dedicated engineering teams for \nmaintenance. Their complexity, built up over years of development \nby large teams, complicates rapid improvements and necessitates \nsubstantial time and expertise for effective management. Finally, fore-\ncasting models incorporate various approximations, such as those for \nsub-grid-scale processes, limiting accuracy. These challenges open the \ndoor for alternative approaches that may offer enhanced performance.\nMachine learning provides an attractive toolbox for addressing these \nissues. Breakthroughs in numerous fields have shown that complex \nprediction systems can be streamlined with machine learning models \nthat deliver superior outcomes4,5. This concept was introduced to the \nEarth sciences as early as the 1990s, with pioneering work on neural \nnetworks6 applied to various Earth forecasting problems7–15. However, \nthese early models could not scale to replace full dynamical systems. \nIn 2023, a breakthrough came with Pangu-Weather2, in which a neural \nnetwork replaced a numerical solver, outperforming state-of-the-art \nforecasting systems and sparking a wave of weather prediction models \nbased on AI3,16–18. These advancements have mostly centred on global \nmedium-range weather forecasting at 0.25° resolution, leaving sub-\nstantial gaps in other essential areas, including ocean dynamics, wave \nmodelling and atmospheric chemistry. Furthermore, the potential for \nmachine learning to outperform complex extreme weather prediction \nsystems, which at present rely on human analysis of a wide range of \nmodels, remains underexplored.\nIn this paper, we introduce Aurora, a foundation model for the Earth \nsystem, capable of tackling a variety of forecasting tasks. Taking inspira-\ntion from recent successes of foundation models in other fields4,5, we \nfirst pretrain Aurora on more than one million hours of diverse Earth \nsystem data. We then fine-tune the model on a range of downstream \ntasks, demonstrating for the first time that an AI model can outperform \nseveral existing operational systems while also being orders of magni-\ntude faster. Specifically, Aurora achieves state-of-the-art performance \nin the following critical forecasting domains:\n• 5-day global air pollution forecasts at 0.4° resolution, outperforming \nresource-intensive numerical atmospheric chemistry simulations \non 74% of targets;\n• 10-day global ocean wave forecasts at 0.25° resolution, exceeding \ncostly numerical models on 86% of targets;\n• 5-day tropical cyclone track forecasts, outperforming seven opera-\ntional forecasting centres on 100% of targets;\n• 10-day global weather forecasts at 0.1° resolution, surpassing \nstate-of-the-art numerical models on 92% of targets while also improv-\ning performance on extreme events.\nAurora: an Earth system foundation model\nAurora is a machine learning model that produces forecasts for any col-\nlection of Earth system variables at any desired resolution. The model \nhttps://doi.org/10.1038/s41586-025-09005-y\nReceived: 28 May 2024\nAccepted: 9 April 2025\nPublished online: 21 May 2025\nOpen access\n Check for updates\n1Microsoft Research, AI for Science, Amsterdam, The Netherlands. 2Silurian AI, Kirkland, WA, USA. 3University of Amsterdam, Amsterdam, The Netherlands. 4University of Cambridge,  \nCambridge, UK. 5Johannes Kepler University Linz, Linz, Austria. 6Microsoft Corporation, Redmond, WA, USA. 7Microsoft Research, Redmond, WA, USA. 8National Taiwan University, Taipei,  \nTaiwan. 9Alan Turing Institute, London, UK. 10University of Pennsylvania, Philadelphia, PA, USA. 11These authors contributed equally: Cristian Bodnar, Wessel P. Bruinsma, Ana Lucic, Megan Stanley, \nAnna Allen. ✉e-mail: pgp@seas.upenn.edu\nNature | Vol 641 | 29 May 2025 | 1181\nconsists of three parts: (1) an encoder that converts heterogeneous \ninputs into a universal latent three-dimensional (3D) representation; \n(2) a processor that evolves the representation forward in time; and \n(3) a decoder that translates the standard 3D representation back into \nphysical predictions. The processor is implemented as a 3D Swin Trans-\nformer19,20 and both the encoder and the decoder as Perceiver-based \nmodules21,22 (Fig. 1). Forecasts for different lead times are generated \nby recursively feeding predictions back into the model as inputs. For \na detailed discussion of the model, see Supplementary Information \nSection B.\nWe train Aurora on a large body of Earth system data to learn a general- \npurpose representation of the dynamics that govern atmospheric and \noceanic flow and associated second-order processes. This first training \nphase is called pretraining and includes a mixture of forecasts, analy-\nsis data, reanalysis data and climate simulations (see Supplementary \nInformation Section C.2). After the model has been pretrained, a second \ntraining phase can make use of the learned general-purpose representa-\ntions to efficiently adapt to new tasks, new datasets and new variables. \nThis second training phase is called fine-tuning. Whereas pretraining \nis expensive and requires large amounts of data, fine-tuning is much \ncheaper and can typically be performed with little data. We primarily \npretrain on atmospheric data, because this is one of the largest sources \nof information about the dynamical processes underlying the Earth sys-\ntem. Concretely, the pretraining objective is to minimize the next time \nstep (6-h lead time) mean absolute error (MAE) for 150,000 steps on \n32 A100 graphics processing units (GPUs), corresponding to approxi-\nmately 2.5  weeks of training.\nAurora is able to achieve unprecedented performance in fine-tuning \ntasks by simultaneously scaling the volume of data used during pre-\ntraining along with its model size. T o evidence this scaling, we demon-\nstrate that pretraining on more diverse data systematically improves \nvalidation performance as more datasets are added, especially for \nextreme values (see Supplementary Information Section G and \nExtended Data Figs. 1  and 2). Moreover, we demonstrate that vali -\ndation performance improves by approximately 6% for every ten \ntimes increase in model size (see Supplementary Information Sec -\ntion G and Extended Data Figs. 1 and 2). Finally, to measure the benefits \nof data and model scaling against existing numerical and AI models, \nwe fine-tune Aurora for medium-range weather forecasting at 0.25° \nresolution, a common task for state-of-the-art AI weather models. \nAurora outperforms both the Integrated Forecasting System (IFS) of \nthe European Centre for Medium-Range Weather Forecasts (ECMWF)1, \nthe state-of-the-art numerical weather prediction system and Graph-\nCast3 on more than 91% of all targets (see Supplementary Information  \nSection H).\nAtmospheric chemistry and air pollution\nAir quality, a crucial factor in human health, is determined by atmos-\npheric concentrations of specific gases and aerosols23. Accurately pre-\ndicting global atmospheric composition can help mitigate the impact \nof air pollution events. However, forecasting atmospheric composition \nis much more complex and computationally costly than weather fore-\ncasting. It involves modelling complex chemical reactions through hun-\ndreds of stiff equations and accounting for anthropogenic emissions \nthat drive heterogeneous pollution levels globally24. The Copernicus \nAtmosphere Monitoring Service (CAMS) takes this approach and pro-\nduces global atmospheric composition forecasts and analysis products \nat 0.4° resolution and reanalysis products at 0.75° resolution25. T o do \nthis, CAMS extends the IFS with further modules for aerosols, reactive \ngases and greenhouse gases, which increases computational costs by \napproximately a factor of ten. So far, no AI method has attempted to \nproduce operational predictions for global atmospheric composition \nat this scale.\nFine-tuning AI models on CAMS analysis data is extremely chal -\nlenging for several reasons. First, the CAMS system is relatively new \nand frequently updated, so training data are limited and change in \ndistribution. Second, air pollution concentrations are highly hetero-\ngeneous, sparse and have large dynamic ranges (see ‘Discussion’). \nFinally, pollution is driven by complex anthropogenic factors. These \nsources underwent complex changes during the global response to the  \nCOVID-19 pandemic, further complicating the available training data.\nSix air pollutants are the main drivers of poor air quality23,26: carbon \nmonoxide (CO), nitrogen oxide (NO), nitrogen dioxide (NO2), sulfur \ndioxide (SO2), ozone (O3) and particulate matter at 1 μm (PM1), 2.5 μm \n(PM2.5) and 10 μm (PM10). Air quality warnings are usually based on \nthreshold values for PM2.5 and PM10. Aurora models the five chemical \nspecies (CO, NO, NO2, SO2 and O3) across atmospheric levels and as \ntotal column (TC) values as well as the particulate matter variables, \nwith CAMS analysis taken to be ground truth. We fine-tune Aurora on \nCAMS analysis data from October 2017 to May 2022 and test on CAMS \nanalysis data from May 2022 to November 2022 (see Supplementary \n3D Perceiver\nencoder\n3D Perceiver \ndecoder\n3D Swin\nTransformer\nU-Net\nTimes (t – 1, t) Time t + 1\nArbitrary variables, \npressure levels and\nresolutions\nArbitrary variables, \npressure levels and\nresolutions\nLatent atmospheric\ninput\nLatent atmospheric\noutput\n+\nLoRA\nAtmospheric chemistry\nand air quality\nAurora foundation model\nWave modelling Hurricane tracking Weather forecasting 0.1°\na\nb\nFig. 1 | Aurora is a 1.3-billion-parameter foundation model for the Earth \nsystem.  Icons are for illustrative purposes only. a , Aurora is pretrained  \non several heterogeneous datasets with different resolutions, variables  \nand pressure levels. The model is then fine-tuned for several operational \nforecasting scenarios at different resolutions: atmospheric chemistry and air \nquality at 0.4°, wave modelling at 0.25°, hurricane tracking at 0.25° and  \nweather forecasting at 0.1°. b, Aurora is a flexible 3D Swin Transformer19 with  \n3D Perceiver-based 21 atmospheric encoders and decoders. The model is able  \nto ingest inputs with different spatial resolutions, numbers of pressure levels \nand variables.\n1182 | Nature | Vol 641 | 29 May 2025\nArticle\nInformation Section C.4). As the CAMS analysis dataset is very limited \nin temporal extent, we also incorporate CAMS reanalysis data EAC4 \n(ref. 27) from January 2003 to December 2021 in the fine-tuning pro-\ncess. We note that CAMS reanalysis data are considered to be lower \nquality because it uses a lower resolution and a much older version \nof the underlying model (see Supplementary Information Section C).\nAurora is competitive with CAMS (within 20% root mean square error \n(RMSE)) on 95% of all targets and matches or outperforms CAMS on \n74% of all targets (Fig. 2a). At the 3-day mark, Aurora is competitive with \nCAMS (within 20% RMSE) on all variables and matches or outperforms \nCAMS on 89% of all variables (Fig. 2b). CAMS outperforms Aurora on \nozone in the very upper atmosphere and the 12-h prediction of all \nspecies in the lower part of the atmosphere. Aurora generates these \npredictions in approximately 0.6 s per hour lead time on a single A100 \nGPU. This yields roughly a 100,000 times speed-up over CAMS (see \nSection 2.1.5 in ref. 28 for the cost of the IFS), representing an important \nadvancement in the field of atmospheric composition forecasting. \nFine-tuning the pretrained model produces large gains over training \na model from scratch, giving improvements for all targets with an \naverage magnitude of 54% (see Fig. I24 in Supplementary Informa-\ntion Section I.1).\nWe conduct a case study evaluating the predictions of Aurora for PM10 \non 13 June 2022, when Iraq was hit by a particularly severe sandstorm \n(see Fig. I21 in Supplementary Information Section I.1), one of a series \nthat led to more than 5,000 hospitalizations in the Middle East 29. \nSandstorms involve complex interactions between particulate matter \nvariables and atmospheric dynamics. Nevertheless, Aurora accurately \npredicts the sandstorm a day in advance with similar accuracy to CAMS, \nat a fraction of the computational cost. This case study shows that a \nfoundation model approach for predicting air pollution can generalize \nto extreme events involving complex interactions between atmospheric \ndynamics and pollutants.\nOcean wave dynamics\nAccurate ocean wave forecasts are critical for shipping, coastal \ndefences, aquaculture, off-shore energy generation and disaster \npreparedness. The IFS High RESolution WAve Model (HRES-WAM) \nsystem30 produces state-of-the-art wave forecasts up to 10 days  \nlead time. IFS HRES-WAM extends the IFS by adding a coupled ocean \nwave module. No AI model has yet attempted to produce operational \npredictions for global wave forecasts at this scale.\nFine-tuning Aurora on the ECMWF’s HRES-WAM analysis dataset \nis challenging. Ocean wave variables include information about the \ndirection, time periods and spectral properties of waves, all of which \nare complex to model. Wave components can also be absent, meaning \nAurora\n1 September 2022 12 UTC\n 2 September 2022 00 UTC\nCAMS forecasts\nCAMS analysis\n0 2 4 6 8 10\nTC NO2 (mg m−2)\n1 2 3 4 5\n50\n100\n150\n200\n250\n300\n400\n500\n600\n700\n850\n925\n1,000 Pressure (hPa)\nCO\n1 2 3 4 5\nNO\n1 2 3 4 5\nNO2\n1 2 3 4 5\nSO2\n1 2 3 4 5\nO3\n–40% –20% 0% +20% +40%\nRMSE relative to CAMS\n1 2 3 4 5\nTC CO\n1 2 3 4 5\nTC NO\n1 2 3 4 5\nTC NO2\n1 2 3 4 5\nTC SO2\n1 2 3 4 5\nTC O3\n1 2 3 4 5\nPM1\n1 2 3 4 5\nPM2.5\n1 2 3 4 5\nPM10\nLead time (days)\nSO2 150 hPa\nSO2 250 hPa\nSO2 200 hPa\nNO2 500 hPa\nNO2 400 hPa\nNO 500 hPa\nNO 600 hPa\nNO 400 hPa\nNO2 300 hPa\nNO 300 hPa\nSO2 100 hPa\nNO2 600 hPa\nNO2 250 hPa\nCO 50 hPa\nNO 150 hPa\nNO 250 hPa\nSO2 300 hPa\nTC NO\nCO 600 hPa\n O3 600 hPa\n O3 700 hPa\n O3 500 hPa\nCO 700 hPa\nTC NO2\nNO2 100 hPa\nO3 400 hPa\nNO 100 hPa\nCO 150 hPa\nNO2 150 hPa\nSO2 400 hPa\nNO2 700 hPa\nNO2 925 hPa\nO3 300 hPa\nO3 850 hPa\nNO 700 hPa\nCO 200 hPa\nNO 200 hPa\nO3 250 hPa\nO3 925 hPa\nCO 100 hPa\nTC SO2\nSO2 50 hPa\nPM1\nCO 250 hPa\nSO2 600 hPa\nSO2 700 hPa\nCO 500 hPa\nCO 400 hPa\nCO 300 hPa\nSO2 500 hPa\nSO2 925 hPa\nNO2 200 hPa\nNO2 850 hPa\nCO 925 hPa\nCO 1,000 hPa\nCO 850 hPa\nO3 1,000 hPa\nO3 200 hPa\nNO2 1,000 hPa\nNO 1,000 hPa\nTC CO\nSO2 850 hPa\nPM2.5\nNO 850 hPa\nNO 50 hPa\n NO2 50 hPa\nNO 925 hPa\nPM10\nSO2 1,000 hPa\nO3 150 hPa\nO3 50 hPa\nTC O3\nO3 100 hPa\n–30%\n–20%\n–10%\n0%\n+10%\n+20%\nRMSE relative\nto CAMS\nAurora versus CAMS at 3 days lead time\nCAMS\nAurora\na b\nc\nFig. 2 | In an operational setting, Aurora matches or outperforms CAMS  \nin most comparisons, at orders of magnitude smaller computational \nexpense.  a, Predictions for TC NO 2 by Aurora accurately predict CAMS \nanalysis. Predicting atmospheric gases correctly is extremely challenging \nowing to their spatially heterogeneous nature. In particular, NO 2, like most  \nair pollution variables, is skewed towards high values in areas with large \nanthropogenic emissions, such as densely populated regions of East Asia. \nAlso, NO 2 exhibits a strong diurnal cycle; for example, sunlight reduces \nbackground levels of NO 2 through a process called photolysis. Aurora \naccurately captures both the extremes and background levels. Aurora and \nCAMS 25 forecasts are initialized with CAMS analysis on 1 September 2022 at \n00 UTC. b, Across all lead times, Aurora matches or outperforms CAMS on \n74% of all targets. c , At a lead time of 3 days, Aurora matches or outperforms \nCAMS on 89% of all variables. See Supplementary Information Section I.1 for \nthe full results.\nNature | Vol 641 | 29 May 2025 | 1183\nthat the new variables can be undefined at arbitrary and variable spa-\ntial locations. Moreover, data for the variables that we consider in this \nexperiment are only available back to 2016, a short record for such a \ncomplex task.\nThe key variables in ocean wave modelling are significant wave \nheight (SWH), mean wave period (MWP) and mean wave direction \n(MWD). Each of these is predicted for wind waves (WW), total swell \n(TS), primary swell (1) and secondary swell (2). We also include peak \nwave period (PP1D) and the components of neutral wind 31 at 10 m, \n10UN and 10VN (see Supplementary Information Section C.5). For the \nfull set of variables, see Table C2 in Supplementary Information sec -\ntion C.2. We simultaneously fine-tune Aurora on both wave and mete -\norological variables by aligning HRES-WAM analysis and HRES T0 in \ntime. HRES T0 refers to the zero-hour forecasts of the high-resolution \nconfiguration of the IFS 32, which provides an accurate ground truth \nfor a wide range of meteorological variables. Both HRES-WAM analysis \nand HRES T0 are regridded to 0.25° spatial resolution. Because the \nHRES-WAM variables are undefined over land and over oceans when -\never sea ice is present, we extend Aurora to support missing data33 (see \n‘Discussion’). We use the years 2016–2021 inclusive for fine-tuning \nand evaluate on 2022 (see Supplementary Information Section C.4).\nAurora is competitive with HRES-WAM (within 20% RMSE) on 96% \nof all targets and matches or outperforms HRES-WAM on 86% of all \nwave variables (Fig.  3b). At the 3-day mark, Aurora is competitive \nwith HRES-WAM (within 20% RMSE) on all but one variable, PP1D, \nand matches or outperforms IFS HRES-WAM on 91% of all variables \n(Fig. 3c). In particular, Aurora accurately predicts neutral wind speeds, \na critical variable for the coupling of atmospheric and wave models31. \nFine-tuning the pretrained model produces large gains over training a \nmodel from scratch, giving improvements for all targets with an aver-\nage magnitude of 22% (see Fig. I28 in Supplementary Information  \nSection I.2).\nSigni/f_icant wave height (m)\n10.2 m\nAurora 0.25° (1 day lead time)\n11.3 m\nIFS HRES-WAM 0.25° analysis\nMean wave direction\n0\n2\n4\n6\n8\n10\nN (0°) \nE (90°)\nS (180°)\nW (270°)\n1 5 10\n10UN\n1 5 10\n10VN\n1 5 10\nWSN\n1 5 10\nPP1D\nSWH\n MWP\n MWD\nSHWW\n MPWW\n MDWW\nSHTS\n MPTS\n MDTS\nSWH1\n MWP1\n MWD1\n1 5 10\nSWH2\n1 5 10\nMWP2\n1 5 10\nMWD2\n–100%\n–75%\n–50%\n–25%\n0%\n+25%\n+50%\n+75%\n+100%\nRMSE relative to IFS HRES-WAM 0.25°\nLead time (days)\n+40%\nRMSE relative to HRES-WAM 0.25°\nat 3 days lead time\nMPWW\nWSN\n10UN\n10VN\n10U\n10V\nMDWW\nMWP2\nSHWW\nSWH2\nSWH1\nSHTS\nMWP1\nMSL\nMPTS\nSWH\nMWP\n2T\nMWD1\nMDTS\nMWD\nMWD2\nPP1D\n–20%\n–10%\n0%\n+10%\nHRES-WAM 0.25°\nAurora 0.25°\na\nb c\nFig. 3 | In an operational setting, Aurora matches or outperforms HRES-  \nWAM in most comparisons. a, Aurora accurately predicts significant wave \nheight and mean wave direction for Typhoon Nanmadol, the most intense \ntropical cyclone in 2022. The red box shows the location of the typhoon  \nand the number is the peak significant wave height. Aurora’s prediction and \nHRES-WAM analysis 30 are for 17 September 2022 at 12 UTC, when Typhoon \nNanmadol reached peak intensity. Aurora was initialized on 16 September 2022 \nat 12 UTC. b, Across all lead times, Aurora matches or outperforms HRES-WAM \non 86% of all wave variables. c, At a lead time of 3 days, Aurora matches or \noutperforms HRES-WAM on 91% of all surface-level variables. See Supplementary \nInformation Section I.2 for the full results.\n1184 | Nature | Vol 641 | 29 May 2025\nArticle\nWe conduct a case study of Aurora’s prediction of the significant \nwave height and mean wave direction during Typhoon Nanmadol, \nwhich struck the southern coast of Japan on 19 September 2022 \n(Fig. 3a). Aurora generally produces strong global predictions for \nsignificant wave height and mean wave direction that follow the pre-\nvailing global wind patterns, with large waves in the typhoon accurately  \ncaptured.\nTropical cyclone tracking\nTropical cyclones have caused more than US$1.4 trillion in dam -\nage since 1950 and pose substantial threats to lives and property34.  \nOfficial forecasts of tropical cyclone tracks are vital for emergency \nservices and the general public. These forecasts are produced by run-\nning various dynamical and statistical models, ranging from global \nensembles such as the IFS to purpose-built tropical cyclone forecast-\ning systems such as the Hurricane Weather Research and Forecast-\ning model35. The output from these systems, together with several \nconsensus products, is analysed by a team of human forecasters who \ncreate the final operational product. Here we demonstrate that a sin-\ngle, deterministic run of Aurora fine-tuned to HRES T0 at 0.25° (see \nSupplementary Information Section H) outperforms the track fore-\ncasts from these complex systems for several agencies on a dataset \nof all tropical cyclones globally in 2022–2023. Aurora fine-tuned to \nHRES T0 is not specifically fine-tuned for tropical cyclone tracking \nand therefore illustrates the performance of the model on an unseen  \ndownstream task.\nPrevious comparisons of AI-based tropical cyclone forecasts with \nofficial operational forecasts have focused on forecasting track and \nintensity at short lead times of up to 24 h (refs. 36,37) and showed only \nmarginal improvements at best. The analysis of other large-scale global \nmachine learning models2,3,38 has been limited to comparisons of tracks, \nwith recent comparisons indicating that performance lags behind that \nof the official operational forecasts39.\nT o generate the track forecasts with Aurora, we run a simple heuris-\ntic tracker labelling the centre fix of the vortex as the minimum mean \nsea-level pressure in consecutive predictions (see Supplementary \nInformation Section I.3.3). We compare the Aurora track predictions \nwith the official forecasts for four basins worldwide, issued by the \nNational Hurricane Center (North Atlantic and East Pacific), China \nMeteorological Administration, Central Weather Administration \nTaiwan, Joint Typhoon Warning Centre and Japan Meteorological \nAgency (Northwest Pacific) and Australian Bureau of Meteorology \n(Australian region). For all agencies and lead times, Aurora outper -\nforms the official track forecast (Fig. 4a) when compared with the \nground-truth paths from the International Best Track Archive for \nClimate Stewardship (IBTrACS) dataset40,41. For example, in the North \nAtlantic and East Pacific, we observe improvements of 6% at lead time \n1 day and 20–25% at lead times 2–5 days. This is the first time that \na machine learning model has surpassed full operational tropical \ncyclone forecasts up to 5 days.\nAurora is able to produce accurate forecasts for several high-impact \nevents. For example, in the case of Typhoon Doksuri in 2023, Aurora \naccurately predicts landfall in the Philippines at 4 days lead time, in \ncontrast to the official predictions centring the vortex off the coast \nof Northern Taiwan (Fig. 4b). It is also important to consider the per-\nformance of Aurora relative to the wider set of models available to the \nhuman forecasters to create the official forecast, as certain models \noutperform the official prediction at various lead times42,43. We there-\nfore compare Aurora with the headline models in the track verification \nreport42 of the National Hurricane Center (NHC) for the North Atlantic \nand East Pacific. Aurora outperforms all headline models (Fig. 4a), \nOFCL\nOCD5\nHWFI\nHMNI\nCTCI\nNVGI\nEMXI\nCMCI\nAEMI\nFSSE\nTVCA\nHCCA\n1\n2\n3\n4\n5\nLead time (days)\n≈\n≈\nNorth Atlantic and East Paci/f_ic\nPGTW\nCWA\nBABJ\nRJTD\nRKSL\n≈\n≈ ≈ ≈ ≈ ≈\nNorthwest Paci/f_ic\nBoM\n≈\n≈\nAus.\n–50%\n–40%\n–30\n–20%\n–10%\n0\nMAE of Aurora\nrelative to model\n21 July 2023 12 UTC\n117.5° E 125.0° E 130.0° E\n12.5° N\n15.0° N\n17.5° N\n20.0° N\n22.5° N\n25.0° N\n27.5° N\n21 July 2023 18 UTC\n117.5° E 125.0° E 130.0° E\n12.5° N\n15.0° N\n17.5° N\n20.0° N\n22.5° N\n25.0° N\n27.5° N\n22 July 2023 00 UTC\n117.5° E 125.0° E 130.0° E\n12.5° N\n15.0° N\n17.5° N\n20.0° N\n22.5° N\n25.0° N\n27.5° N\nAurora\nPGTW\nIBTrACS\na\nb\nFig. 4 | In an operational setting, Aurora outperforms state-of-the-art \ntropical cyclone prediction systems for several agencies and regions \nworldwide.  a, Aurora attains better track prediction MAE than several \nagencies in various regions. Official forecasts are given by OFCL, PGTW, \nCWA, BABJ, RJTD, RKSL and BoM (in bold). For the North Atlantic and East \nPacific, we also compare with various models used in creating OFCL (not \nbold). A model does not always make forecasts, which means that different \ncolumns are computed over different data. Columns are therefore not \nindicative of model performance and only indicate the performance compared \nwith Aurora. Here ‘≈’ indicates that the 95% confidence interval for the cell \ncontains zero (see Supplementary Information Section I.3.4 for details). On \naverage, Aurora is 20% better than other agencies in the North Atlantic and \nEast Pacific, 18% in the Northwest Pacific and 24% in the Australian region \n(Aus.). b, On 21 July, a tropical depression intensified into a tropical storm and \nwas named Typhoon Doksuri. Typhoon Doksuri would become the costliest \nPacific typhoon so far, inflicting more than US$28 billion in damage. The \nblack lines show its ground-truth paths extracted from IBTrACS 40,41. Aurora \ncorrectly predicts that Typhoon Doksuri will make landfall in the Northern \nPhilippines, whereas PGTW predicts that it will pass over Taiwan.\nNature | Vol 641 | 29 May 2025 | 1185\ngiving confidence that this is indeed a notable step forward in tropical \ncyclone track forecast skill.\nHigh-resolution weather forecasting\nT o accurately resolve high-impact weather events such as severe storms, \nit is essential that weather prediction systems operate at a high spatial \nresolution to resolve processes occurring at smaller scales, such as \nconvective and boundary layer effects. HRES32, the high-resolution \nconfiguration of the IFS, operates on a Gaussian grid (TCo1279), which \nis approximately 0.1° in mid-latitudes. By contrast, current state-of-\nthe-art AI weather prediction models2,3,16,38,44 can only operate at 0.25° \nresolution. The reason why state-of-the-art AI approaches are focused \non 0.25° is the wealth of high-quality data available at this resolution, \nwhereas 0.1° data are only available from 2016 onwards. Here we demon-\nstrate that a pretraining–fine-tuning protocol can be used to efficiently \nadapt Aurora to 0.1° and surpass the forecasting skill of IFS HRES under \noperational evaluation protocols.\nWe fine-tune Aurora to 0.1° IFS HRES analysis data, which span \n2016–2022 (see ‘Discussion’ and Supplementary Information Sec -\ntion B). For evaluation, we follow the operational protocol in ref. 45, \ninitializing Aurora with IFS HRES analysis and evaluating forecasts \nagainst IFS HRES analysis. T o ensure that we do not disadvantage \nIFS HRES, we follow ref. 3  and evaluate IFS HRES against its own \nso-called zero-hour forecast, referred to as HRES T0, instead of IFS HRES  \nanalysis.\nAurora achieves lower RMSE than IFS HRES on 92% of target vari-\nables, pressure levels and lead times (Fig. 5a). The performance gains \nare most pronounced at lead times of more than 12 h into the future, \nfor which we observe a reduction in RMSE of up to 24%. At the shortest \nlead times, IFS HRES outperforms Aurora for many targets, as is the \ncase for other AI models3. We also evaluate the forecasts of Aurora on \nin situ measurements of 10-m wind speed and 2-m temperature from the \nWeatherReal-ISD dataset46, which includes more than 13,000 weather \nobserving stations globally. We find that Aurora outperforms IFS HRES \nfor all lead times up to 10 days (see Fig. 5b and Supplementary Informa-\ntion Section I.5). Owing to the limited availability of 0.1° data, we find \nthat pretraining Aurora is essential in this application. On average, \nthe pretrained model is better than training from scratch by 25% (see \nSupplementary Information Section I.4).\nWe conduct a case study of Storm Ciarán, a high-impact mid-latitude \nstorm that took place across Northwest Europe in late 2023, resulting \nin the lowest recorded pressure in November in England47. Following \nref. 48, we initialize a selection of AI models at 31 October 00 UTC and \ncompare them with Aurora (see Fig. 5d). We observe that, among the AI \nmodels tested2,3,38, Aurora is the only one capable of accurately predict-\ning the abrupt increase in maximum 10-m wind speed, closely matching \nIFS analysis, which is taken to be the ground truth.\n1 5 10\n500\n600\n700\n850\n925\nPressure (hPa)\nU\n1 5 10\nV\n1 5 10\nT\n1 5 10\nQ\n1 5 10\nZ\n–50%\n–25%\n0%\n+25%\n+50%\nRMSE relative to IFS HRES 0.1°\n1 5 10\n10U\n1 5 10\n10V\n1 5 10\nMSL\n1 5 10\n2T\nLead time (days)\n1 5 10\nLead time (days)\n2.00\n2.25\n2.50\n2.75\nWind speed at weather\nstations, RMSE (m s–1)\nAurora 0.1°\nIFS HRES 0.1°\nAurora\n24.5 m s–1\n1 November 12 UTC\n 1 November 18 UTC\n 2 November 00 UTC\n 2 November 06 UTC\nIFS analysis\n0 5 10 15 20 25 30 35\nWind speed (m s–1)\n15\n31 October 06 UTC31 October 12 UTC31 October 18 UTC1 November 00 UTC1 November 06 UTC1 November 12 UTC1 November 18 UTC2 November 00 UTC2 November 06 UTC\n20\n25\n30\n35\n40\nMaximum 10-m wind\nspeed (m s–1)\nIFS analysis\nIFS HRES\nFourCastNet\nGraphCast\nPangu-Weather\nAurora 0.1°\na\nc\nb\nd\n28.6 m s–1\n32.3 m s–1\n32.1 m s–1\n32.6 m s–1\n35.2 m s–1 30.0 m s–1\n27.3 m s–1\nFig. 5 | In an operational setting, Aurora outperforms IFS HRES in most \ncomparisons and is the only AI model to accurately estimate the maximum \nwind speeds in Storm Ciarán.  a, Aurora outperforms IFS HRES at 0.1° on more \nthan 92% of targets. The scorecard is limited to pressure levels lower in the \natmosphere owing to restricted availability of test year data. b , Wind speed \nRMSE computed against measurements at weather stations. Aurora greatly \noutperforms IFS HRES. c , Operational predictions for Storm Ciarán compared \nwith IFS HRES analysis at 0.1°. Black dots show the location of minimum MSL \nand therefore trace the path of the storm. The maximum 10-m wind speed of \nthe storm is shown in the bottom-left corner of each prediction. To better \nfacilitate the prediction of extreme events, Aurora was run without LoRA. See \nSupplementary Information Section I.7 for details. d , Operational predictions \nfor maximum 10-m wind speed during Storm Ciarán by Aurora, FourCastNet, \nGraphCast and Pangu-Weather. Aurora is able to predict the sudden increase in \n10-m wind speed, unlike the other AI models. The numbers for all AI models \nexcept Aurora have been extracted from Fig. 3 in ref. 48.\n1186 | Nature | Vol 641 | 29 May 2025\nArticle\nDiscussion\nWe have introduced Aurora, a large-scale foundation model for the \nEarth system that outperforms several specialized operational predic-\ntion systems at a fraction of the computational cost. We demonstrate \nstate-of-the-art results for air quality, ocean waves, tropical cyclone \ntracks and high-resolution weather forecasting. From start to finish, \neach fine-tuning experiment took 4–8 weeks with a small team of engi-\nneers, compared with a typical development period of several years for \ndynamical baseline models. However, it should be noted that such an \naccelerated timeline is only possible because of the wealth of data that \nis available as a result of decades of research into traditional numerical \napproaches.\nImprovements are possible along several axes. First, Aurora can easily \nbe extended to generate an ensemble of forecasts, which are crucial \nin situations in which predictions are uncertain, such as for forecasts \nat longer lead times or for localized phenomena. Moreover, our scaling \nresults indicate that we have not yet hit a performance ceiling and that \nimproved fine-tuning results can be obtained by scaling pretraining to \nmore diverse data and scaling Aurora to even larger sizes. Although \nAurora is fully operational in all experiments, the model does still rely \non initial conditions from traditional data assimilation systems. Fol-\nlowing recent advances in end-to-end weather forecasting49, Aurora \ncould be extended to directly operate on observational data. We \ncould also investigate the interpretability of Aurora, aiming to under-\nstand whether specific patterns learned by the model can be linked to  \nphysical processes.\nThe potential implications of Aurora for the field of Earth system \nprediction are profound. Although in this paper we showcase the \napplication of Aurora to four domains, it could be fine-tuned for any \ndesired Earth system prediction task, potentially producing fore -\ncasts that outperform the current operational systems at a fraction \nof the cost. Some examples include predicting ocean circulation, \nlocal and regional weather, seasonal weather, vegetation growth and \nphenology, extreme weather modalities such as floods and wildfires, \npollination patterns, agricultural productivity, renewable energy \nproduction and sea ice extent. With the ability to fine-tune Aurora \nto diverse application domains at only modest computational cost, \nAurora represents notable progress in making actionable predictions \naccessible to anyone.\nOnline content\nAny methods, additional references, Nature Portfolio reporting summa-\nries, source data, extended data, supplementary information, acknowl-\nedgements, peer review information; details of author contributions \nand competing interests; and statements of data and code availability \nare available at https://doi.org/10.1038/s41586-025-09005-y.\n1. European Centre for Medium-Range Weather Forecasts (ECMWF). IFS Documentation \nCY48R1, Vol. 8. https://doi.org/10.21957/0f360ba4ca (2023).\n2. Bi, K. et al. Accurate medium-range global weather forecasting with 3D neural networks. \nNature 619, 533–538 (2023).\n3. Lam, R. et al. Learning skillful medium-range global weather forecasting. Science 382, \n1416–1421 (2023).\n4. Abramson, J. et al. Accurate structure prediction of biomolecular interactions with \nAlphaFold 3. Nature 630, 493–500 (2024).\n5. OpenAI et al. GPT-4 technical report. Preprint at https://arxiv.org/abs/2303.08774  \n(2024).\n6. Rumelhart, D. E., Hinton, G. E. & Williams, R. J. Learning representations by back-propagating \nerrors. Nature 323, 533–536 (1986).\n7. Marzban, C. & Stumpf, G. J. A neural network for tornado prediction based on Doppler \nradar-derived attributes. J. Appl. Meteorol. Climatol. 35, 617–626 (1996).\n8. McCann, D. W. A neural network short-term forecast of significant thunderstorms. \nWeather Forecast. 7, 525–534 (1992).\n9. Kuligowski, R. J. & Barros, A. P. Experiments in short-term precipitation forecasting using \nartificial neural networks. Mon. Weather Rev. 126, 470–482 (1998).\n10. Kuligowski, R. J. & Barros, A. P. Localized precipitation forecasts from a numerical \nweather prediction model using artificial neural networks. Weather Forecast. 13,  \n1194–1204 (1998).\n11. Spellman, G. An application of artificial neural networks to the prediction of surface \nozone concentrations in the United Kingdom. Appl. Geogr. 19, 123–136 (1999).\n12. Deo, M. & Naidu, C. S. Real time wave forecasting using neural networks. Ocean Eng. 26, \n191–203 (1998).\n13. Tangang, F., Hsieh, W. & Tang, B. Forecasting the equatorial pacific sea surface temperatures \nby neural network models. Clim. Dyn. 13, 135–147 (1997).\n14. Hsieh, W. W. & Tang, B. Applying neural network models to prediction and data  \nanalysis in meteorology and oceanography. Bull. Am. Meteorol. Soc. 79, 1855–1870 \n(1998).\n15. Kolehmainen, M., Martikainen, H., Hiltunen, T. & Ruuskanen, J. Forecasting air quality \nparameters using hybrid neural network modelling. Environ. Monit. Assess. 65, 277–286 \n(2000).\n16. Chen, L. et al. FuXi: a cascade machine learning forecasting system for 15-day global \nweather forecast. npj Clim. Atmos. Sci. 6, 190 (2023).\n17. Han, T. et al. FengWu-GHR: learning the kilometer-scale medium-range global weather \nforecasting. Preprint at https://arxiv.org/abs/2402.00059 (2024).\n18. Chen, K. et al. FengWu: pushing the skillful global medium-range weather forecast \nbeyond 10 days lead. Preprint at https://arxiv.org/abs/2304.02948 (2023).\n19. Liu, Z. et al. Swin Transformer: hierarchical vision transformer using shifted windows.  \nIn Proc. IEEE/CVF International Conference on Computer Vision (ICCV) 10012–10022  \n(IEEE, 2021).\n20. Dosovitskiy, A. et al. An image is worth 16 × 16 words: transformers for image recognition \nat scale. In International Conference on Learning Representations, https://openreview.\nnet/forum?id=YicbFdNTTy (Curran Associates, 2021).\n21. Jaegle, A. et al. Perceiver: general perception with iterative attention. In Proc. 38th \nInternational Conference on Machine Learning (eds Meila, M. & Zhang, T.) 4651–4664, \nhttps://proceedings.mlr.press/v139/jaegle21a.html (PMLR, 2021).\n22. Jaegle, A. et al. Perceiver IO: a general architecture for structured inputs & outputs.  \nIn International Conference on Learning Representations, https://openreview.net/\nforum?id=fILj7WpI-g (Curran Associates, 2022).\n23. World Health Organization (WHO). WHO global air quality guidelines: particulate matter \n(PM2.5 and PM10), ozone, nitrogen dioxide, sulfur dioxide and carbon monoxide. https://\nwww.who.int/publications/i/item/9789240034228 (WHO, 2021).\n24. Brasseur, G. P. & Jacob, D. J. Modeling of Atmospheric Chemistry (Cambridge Univ. Press, \n2017).\n25. European Centre for Medium-Range Weather Forecasts (ECMWF). IFS Documentation \nCY48R1 - Part VIII: Atmospheric Composition. https://doi.org/10.21957/749dc09059  \n(2023).\n26. U.S. Environmental Protection Agency. Technical assistance document for the \nreporting of daily air quality – the air quality index (AQI). Technical report, https://\ndocument.airnow.gov/technical-assistance-document-for-the-reporting-of-daily-air- \nquailty.pdf (2024).\n27. Inness, A. et al. The CAMS reanalysis of atmospheric composition. Atmos. Chem. Phys. \n19, 3515–3556 (2019).\n28. Buizza, R. et al. The development and evaluation process followed at ECMWF to upgrade \nthe integrated forecasting system (IFS). Technical Report 829, https://doi.org/10.21957/\nxzopnhty9 (2018).\n29. Francis, D. et al. On the Middle East’s severe dust storms in spring 2022: triggers and \nimpacts. Atmos. Environ. 296, 119539 (2023).\n30. European Centre for Medium-Range Weather Forecasts (ECMWF). Ocean Wave Model \nhigh resolution 15-day forecast (Set II - HRES-WAM). https://www.ecmwf.int/en/forecasts/\ndatasets/set-ii (2024).\n31. European Centre for Medium-Range Weather Forecasts (ECMWF). IFS DOCUMENTATION – \nCy43r3 operational implementation 11 July 2017. PART VII: ECMWF WAVE MODEL. https://\nwww.ecmwf.int/sites/default/files/elibrary/2017/17739-part-vii-ecmwf-wave-model.pdf \n(2017).\n32. Malardel, S. et al. A new grid for the IFS. ECMWF Newsl. 146, 23–28 (2016).\n33. Gordon, J. et al. Convolutional conditional neural processes. In International Conference \non Learning Representations, https://openreview.net/forum?id=Skey4eBYPS (Curran \nAssociates, 2020).\n34. World Meteorological Organization (WMO). Tropical cyclone. https://wmo.int/topics/\ntropical-cyclone (2024).\n35. National Hurricane Center (NHC). NHC track and intensity models. https://www.nhc.\nnoaa.gov/modelsummary.shtml (2019).\n36. Boussioux, L., Zeng, C., Guénais, T. & Bertsimas, D. Hurricane forecasting: a novel \nmultimodal machine learning framework. Weather Forecast. 37, 817–831 (2022).\n37. Huang, C., Bai, C., Chan, S. & Zhang, J. MMSTN: a multi-modal spatial-temporal  \nnetwork for tropical cyclone short-term prediction. Geophys. Res. Lett. 49, e2021GL096898 \n(2022).\n38. Kurth, T. et al. FourCastNet: accelerating global high-resolution weather forecasting \nusing adaptive Fourier neural operators. In Proc. Platform for Advanced Scientific \nComputing Conference, article no. 13 (Association for Computing Machinery, 2023).\n39. DeMaria, M. et al. Evaluation of tropical cyclone track and intensity forecasts from \nArtificial Intelligence Weather Prediction (AIWP) models. Preprint at https://arxiv.org/\nabs/2409.06735 (2024).\n40. Gahtan, J. et al. International Best Track Archive for Climate Stewardship (IBTrACS) \nproject, version 4r01. NOAA National Centers for Environmental Information, https://doi.\norg/10.25921/82ty-9e16 (2024).\n41. Knapp, K. R., Kruk, M. C., Levinson, D. H., Diamond, H. J. & Neumann, C. J. The International \nBest Track Archive for Climate Stewardship (IBTrACS): unifying tropical cyclone data. \nBull. Am. Meteorol. Soc. 91, 363–376 (2010).\n42. National Hurricane Center (NHC). National Hurricane Center forecast verification report. \n2022 hurricane season. NOAA technical report, https://www.nhc.noaa.gov/verification/\npdfs/Verification_2022.pdf (2022).\n43. National Hurricane Center (NHC). National Hurricane Center forecast verification report. \n2023 hurricane season. NOAA technical report, https://www.nhc.noaa.gov/verification/\npdfs/Verification_2023.pdf (2023).\nNature | Vol 641 | 29 May 2025 | 1187\n44. Bonev, B. et al. Spherical Fourier neural operators: learning stable dynamics on the \nsphere. In Proc. 40th International Conference on Machine Learning (eds Krause, A. \net al.) 2806–2823, https://proceedings.mlr.press/v202/bonev23a.html (PMLR,  \n2023).\n45. Ben Bouallègue, Z. et al. The rise of data-driven weather forecasting: a first statistical \nassessment of machine learning-based weather forecasts in an operational-like context. \nBull. Am. Meteorol. Soc. 105, E864–E883 (2024).\n46. Jin, W. et al. WeatherReal: a benchmark based on in-situ observations for evaluating \nweather models. Preprint at https://arxiv.org/abs/2409.09371 (2024).\n47. UK Met Office. Storm Ciarán, 1 to 2 November 2023. https://www.metoffice.gov.uk/\nbinaries/content/assets/metofficegovuk/pdf/weather/learn-about/uk-past-events/\ninteresting/2023/2023_09_storm_ciaran_2.pdf (2023).\n48. Charlton-Perez, A. J. et al. Do AI models produce better weather forecasts than physics- \nbased models? A quantitative evaluation case study of Storm Ciarán. npj Clim. Atmos. Sci. \n7, 93 (2024).\n49. Allen, A. et al. Aardvark weather: end-to-end data-driven weather forecasting. Nature \nhttps://doi.org/10.1038/s41586-025-08897-0 (2025).\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in \npublished maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution-\nNonCommercial-NoDerivatives 4.0 International License, which permits any \nnon-commercial use, sharing, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide \na link to the Creative Commons licence, and indicate if you modified the licensed material.  \nYou do not have permission under this licence to share adapted material derived from this \narticle or parts of it. The images or other third party material in this article are included in the \narticle’s Creative Commons licence, unless indicated otherwise in a credit line to the material. \nIf material is not included in the article’s Creative Commons licence and your intended use is  \nnot permitted by statutory regulation or exceeds the permitted use, you will need to obtain \npermission directly from the copyright holder. To view a copy of this licence, visit http://\ncreativecommons.org/licenses/by-nc-nd/4.0/.\n© The Author(s) 2025\nArticle\nMethods\nProblem statement\nWe represent the observed state of the atmosphere and surface at a \ndiscrete time t as a multidimensional array RX ∈tV HW×× , in which V is \nthe total number of variables and H and W are the number latitude and \nlongitude coordinates, respectively. The state can be split into surface \n(St) and atmospheric (At) components: Xt = (St, At), in which S ∈tV HW××SR  \nand RA ∈tV CH W××A  with VS the number of surface-level variables, VA the \nnumber of atmospheric variables and C the number of pressure levels. \nThe goal is to predict a future state at time t′ > t. We learn a simulator \nΦ :( )→VH WV HW×× 2× ×RR , /uni0302XX XΦ(, )=tt t−1 +1\n, which maps the observed \nstates at the previous time Xt−1 and current time Xt to a predicted state \nX\nt +1/uni0302 at the next time step. For predictions at later time steps, we repeat-\nedly apply the simulator, producing an autoregressive roll-out:\n()\n()\n()\nXX X\nXX X\nXX X\nΦ, =,\nΦ, =,\nΦ, =.\nt tt\ntt t\ntk tk tk\n+1 +2\n+1 +2 +3\n+− 2+ −1 +\n/uni0302/uni0302\n/uni0302/uni0302/uni0302\n/uni22EE\n/uni0302/uni0302/uni0302\nFor a detailed description of the notation and problem statement, \nincluding the specific multidimensional array dimensions and variable \ndefinitions, see Supplementary Information Section A.\nThe Aurora model\n3D Perceiver encoder. T o accommodate heterogeneous weather \ndatasets with varying variables, pressure levels and resolutions, we \ndesign a flexible encoder that maps different datasets into a standard-\nized 3D representation for input into the model backbone (Extended \nData Fig. 3a).\nThe encoder treats all variables as H × W images. We incorporate \nstatic variables (orography, land–sea mask and soil-type mask) by treat-\ning them as extra surface-level variables. The images are split into P × P \npatches and the patches are mapped to embedding vectors of dimension \nD using variable-specific linear transformations. For the surface and \nevery pressure level, the embeddings of different variables are summed \nand tagged with an additive encoding of the pressure level or a learned \nvector for the surface. A Perceiver module21 then reduces variable num-\nbers of physical pressure levels C to a fixed number L = 3 of latent pres-\nsure levels. The result is a L××\nH\nP\nW\nP  collection of embeddings. This 3D \nrepresentation is tagged with additive encodings for the patch position, \npatch area and absolute time. These encodings use a Fourier expansion \nscheme with carefully chosen minimum and maximum wavelengths to \ncapture relevant information at appropriate scales. The patch area \nencoding enables Aurora to operate at different resolutions.\nFor a detailed description of the encoder architecture, including \nspecifics on input processing, pressure-level aggregation and further \nencodings, see Supplementary Information Sections B.1 and B.4.\nMultiscale 3D Swin Transformer U-Net backbone. The backbone \nof Aurora is a 3D Swin Transformer U-Net19,50, which serves as a neural \nsimulator (see Fig. B1 Supplementary Information Section B.1). This \narchitecture allows for efficient simulation of underlying physics at \nseveral scales. This architecture falls under the general family of Vision \nTransformers. However, unlike classical Vision Transformers, here we \nuse local self-attention operations within windows and a symmetric \nupsampling–downsampling structure.\nThe backbone is characterized by the following key features: a sym-\nmetric upsampling–downsampling structure with three stages each, \nenabling multiscale processing; 3D Swin Transformer layers perform-\ning local self-attention operations within windows, emulating local \ncomputations in numerical integration methods; window shifting \nevery other layer to propagate information between neighbouring \nregions while accounting for Earth’s spherical topology; res-post-norm \nlayer normalization 50 for increased training stability; and a flexible \ndesign allowing operation at several resolutions without fixed posi-\ntional biases.\nOur backbone contains 48 layers across three stages, compared \nwith the 16 layers and two stages used in ref. 2. This increased depth \nis made possible by our efficient encoding procedure, which uses a \nsmall number of latent levels. For detailed information on the back -\nbone architecture, including window sizes, attention mechanisms and \ncomparisons with previous work, see Supplementary Information \nSection B.2.\n3D Perceiver decoder. The decoder reverses the operations of the \nencoder, converting the output of the backbone, again a 3D repre-\nsentation, back to the normal latitude–longitude grid (see Fig. 6b). \nThis involves disaggregating the latent atmospheric pressure levels \nusing a Perceiver layer21 to any desired collection of pressure levels \nand dynamically decoding into patches by means of variable-specific \nlinear layers. For a detailed description of the decoder architecture, \nsee Supplementary Information Section B.3.\nTraining methods\nThe overall training procedure is composed of three stages: (1) pretrain-\ning; (2) short-lead-time fine-tuning; and (3) roll-out (long-lead-time) \nfine-tuning. We provide an overview for each of these stages in the \nfollowing.\nTraining objective. Throughout pretraining and fine-tuning, we use \nthe MAE as our training objective XX(, )\nt tL /uni0302. Decomposing the pre-\ndicted state /uni0302X\nt\n and ground-truth state Xt into surface-level variables \nand atmospheric variables, /uni0302/uni0302/uni0302X SA=( ,)\ntt t\n and Xt = (St, At) (see Supplemen-\ntary Information Section A), the loss can be written as\nL ∑∑ ∑\n∑∑ ∑∑\nXX γ\nVV α w\nHW SS\nβ CH W wA A\n(, )= +× −\n+ 1\n×× −,\n(1)\nt t\nk\nV\nk\ni\nH\nj\nW\nki j\nt\nki j\nt\nk\nV\nc\nC\nkc\ni\nH\nj\nW\nkc ij\nt\nkc ij\nt\nSA =1\nS\n=1 =1\n,, ,,\n=1 =1\n,\nA\n=1 =1\n,, ,, ,,\nS\nA\n/uni0302/uni0302\n/uni0302\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nin which wk\nS is the weight associated with surface-level variable k , \nwkc,\nA  is the weight associated with atmospheric variable k  at pressure \nlevel c, α is a weight for the surface-level component of the loss, β  is \na weight for the atmospheric component of the loss and γ  is a \ndataset-specific weight. See Supplementary Information Section D.1 \nfor more details.\nPretraining methods. All models are pretrained for 150,000 steps on \n32 A100 GPUs, with a batch size of one per GPU. We use a (half) cosine \ndecay with a linear warm-up from zero for 1,000 steps. The base learning \nrate is 5 × 10−4, which the schedule reduces by a factor of ten at the end \nof training. The optimizer we use is AdamW51. We set the weight decay \nof AdamW to 5 × 10−6. The only other form of regularization we use is \ndrop path (that is, stochastic depth)52, with the drop probability set to \n0.2. T o make the model fit in memory, we use activation checkpointing \nfor the backbone layers and we shard all of the model gradients across \nthe GPUs. The model is trained using bf16 mixed precision. See Sup-\nplementary Information Section D.2 for further details.\nShort-lead-time fine-tuning. After pretraining Aurora, for each task \nthat we wish to adapt Aurora to, we start by fine-tuning the entire archi-\ntecture through one or two roll-out steps (depending on the task and \nits memory constraints). See Supplementary Information Section D.3 \nfor more details.\nRoll-out fine-tuning. T o train very large Aurora models on long-term \ndynamics efficiently, even at high resolutions, we develop a new roll-out \nfine-tuning approach. Our approach uses low-rank adaptation (LoRA)53 \nto fine-tune all linear layers in the backbone’s self-attention opera -\ntions, allowing adaptation of very large models in a data-efficient and \nparameter-efficient manner. T o save memory, we use the ‘pushforward \ntrick’54, which propagates gradients only through the last roll-out step. \nFinally, to enable training at very large numbers of roll-out steps without \ncompromising memory or training speed, we use an in-memory replay \nbuffer, inspired by deep reinforcement learning55,56 (see Fig. D2 in Sup-\nplementary Information Section D.3). The replay buffer samples initial \nconditions, computes predictions for the next time step, adds predic-\ntions back to the replay buffer and periodically refreshes the buffer with \nnew initial conditions from the dataset. For detailed roll-out protocols \nfor each fine-tuning task, see Supplementary Information Section D.4.\nDatasets\nAurora was trained and evaluated using a diverse set of weather and cli-\nmate datasets, encompassing five main categories: analysis, reanalysis, \nforecast, reforecast and climate simulation datasets. This variety of data \nsources exposes Aurora to different aspects of atmospheric dynamics, \nreflecting variability in initial conditions, model parametrizations \nand chaotic dynamics. Key datasets used in our experiments include \nERA5 reanalysis, HRES operational forecasts, IFS ensemble forecasts, \nGFS operational forecasts, GEFS ensemble reforecasts, CMIP6 climate \nsimulations, MERRA-2 atmospheric reanalysis, as well as CAMS fore-\ncasts, analysis and reanalysis data. For a detailed inventory of all data-\nsets used, including specific pressure levels, resolutions and further \ncontext for each dataset, see Supplementary Information Section C. \nThese datasets vary in resolution, variables included and temporal \ncoverage, providing a comprehensive basis for training, fine-tuning \nand evaluating the performance of Aurora across different scenarios.\nTask-specific adaptations\nOcean wave forecasting. In the IFS HRES-WAM analysis data, there is \na spatially varying absence of data reflecting the distribution of sea ice \namong other effects. T o account for this dynamic nature of the spatial \ndistribution of defined variables, we give each variable an extra chan-\nnel to represent the presence of a measurement, so we add an extra set \nof density variables33 (see Supplementary Information Section B.8).\nData infrastructure\nTraining Aurora presented substantial technical challenges owing to the \nlarge size of individual data points (nearly 2 GB for 0.1° data) and the \nneed to handle heterogeneous datasets with varying resolutions, vari-\nables and pressure levels. Owing to the size of data points, training is typi-\ncally bottlenecked by data loading and not by the model. This means that \ntraining smaller models is not always cheaper, because training costs \nwill be dominated by data loading. We developed a sophisticated data \nstorage and loading infrastructure to address these technical challenges.\nData storage and preprocessing. We use Azure Blob Storage with \nseveral optimizations to ensure efficient data access. These optimiza-\ntions include colocating data and compute to minimize latency and \ncosts, storing datasets in appropriate chunks to avoid unnecessary data \ndownload and to minimize the number of concurrent connections and \ncompressing these chunks to reduce network bandwidth.\nData loading. We have developed an advanced multisource data load-\ning pipeline to efficiently handle heterogeneous data. We now outline \nthe main design principles of our pipeline. Datasets are instantiated \nusing YAML configuration files specifying loading parameters. Each \ndataset generates a stream of lightweight BatchGenerator objects. The \nscope of the BatchGenerator class is to abstract away the details and par-\nticularities of datasets by offering a common interface for generating \ndata batches. The streams are combined, shuffled and sharded across \nGPUs. After sharding, finally the common interface of BatchGenerator \nis used to do the work needed to download and construct batches for \ntraining and inference.\nThis pipeline enables efficient training on several heterogeneous \ndatasets by batching only samples from the same dataset together \nand automatically balances workloads across GPUs by using different \nbatch sizes for different datasets. This design offers flexibility needed \nto experiment with the Aurora model architecture while efficiently \nhandling the challenges of large-scale, heterogeneous weather data \nprocessing. For a detailed description of the data loading pipeline, \nincluding the BatchGenerator object structure and the unpacking \nprocess, see Supplementary Information Section E.\nVerification metrics\nWe evaluate the performance of Aurora using two main metrics: the \nRMSE and the anomaly correlation coefficient. Both metrics incorpo-\nrate latitude weighting to account for the non-uniform grid of the Earth. \nThe RMSE measures the magnitude of errors between predictions and \nground truth, whereas the anomaly correlation coefficient measures \nthe correlation between the deviation of the prediction and ground \ntruth from the daily climatology.\nT o assess performance on extreme weather events, we use a thres-\nholded RMSE. The thresholded RMSE uses a threshold to determine \nwhich latitude–longitude grid points should be included in the calcu-\nlation, allowing for evaluation of model performance across different \nintensity levels of weather phenomena. The thresholds are defined \nusing the mean and standard deviation of the ERA5 reanalysis data over \nall training years computed separately for each latitude–longitude \npoint. We vary these thresholds linearly for both positive and negative \nvalues to obtain RMSE curves for different intensity levels.\nFor a comprehensive explanation of the verification methods used \nin this work, including their mathematical formulation and interpreta-\ntion, see Supplementary Information Section F . Taken together, the \nmetrics used here provide a robust framework for evaluating the per-\nformance of Aurora across various weather conditions, from typical \nto extreme events.\nFurther details\nFurther details are available in the Supplementary Information and \nrely on refs. 26,46,57–75.\nData availability\nMost of the data used to train and evaluate Aurora can be obtained from \npublicly available sources. The ERA5 dataset can be obtained from the \nClimate Data Store (CDS) (https://cds.climate.copernicus.eu). The \nHRES Forecasts, HRES T0 and HRES-WAM data can be obtained from \nthe Meteorological Archival and Retrieval System (MARS) (https://\nconfluence.ecmwf.int/display/WEBAPI/Access+MARS). The ECMWF \nIFS Ensemble data were obtained from the WeatherBench2 repository \n(https://weatherbench2.readthedocs.io/en/latest/data-guide.html). \nThe GFS Forecasts and GFS T0 datasets can be downloaded from the \nNational Oceanic and Atmospheric Administration (NOAA; https://\nwww.nco.ncep.noaa.gov/pmb/products/gfs/). The GEFS reforecasts \ndataset is also made available by the NOAA at https://registry.open-\ndata.aws/noaa-gefs-reforecast/. The MERRA-2 dataset is made publicly \navailable by NASA (https://gmao.gsfc.nasa.gov/reanalysis/merra-2/\ndata_access/). The CAMS global reanalysis (EAC4) is available on the \nADS (Atmosphere Data Store) (https://ads.atmosphere.copernicus.\neu/datasets/cams-global-reanalysis-eac4)76. The CAMS forecasts and \nanalysis are similarly available at https://ads.atmosphere.copernicus.\neu/datasets/cams-global-atmospheric-composition-forecasts. The \nWeatherReal-ISD weather station dataset can be downloaded from \nGitHub (https://github.com/microsoft/WeatherReal-Benchmark).  \nArticle\nThe ground-truth tropical cyclone tracks were obtained from the Inter-\nnational Best Track Archive for Climate Stewardship (IBTrACS)40,41. \nTropical cyclone tracks for baselines in the North Atlantic and East \nPacific were downloaded from Automated Tropical Cyclone Forecast \n(ATCF; https://ftp.nhc.noaa.gov/atcf/)57 of the National Hurricane \nCenter (NHC) and tracks for baselines in the West Pacific and Austral-\nian region were acquired from private communication with the National \nTaiwan University and the Australian Bureau of Meteorology. All of our \nplots were made using Matplotlib77 and the geographical maps were \nproduced using Cartopy78. A more detailed description of the data \nsources is provided in Supplementary Information Section C.\nCode availability\nOur code and weights are publicly available at https://github.com/\nmicrosoft/aurora (refs. 58–75,79–81).\n \n50. Liu, Z. et al. Swin Transformer v2: scaling up capacity and resolution. In Proc. IEEE/CVF \nConference on Computer Vision and Pattern Recognition (CVPR) 12009–12019 (IEEE, 2022).\n51. Loshchilov, I. & Hutter, F. Decoupled weight decay regularization. In International \nConference on Learning Representations, https://openreview.net/forum?id=Bkg6RiCqY7 \n(Curran Associates, 2019).\n52. Larsson, G., Maire, M. & Shakhnarovich, G. FractalNet: ultra-deep neural networks without \nresiduals. In International Conference on Learning Representations, https://openreview.\nnet/forum?id=S1VaB4cex (Curran Associates, 2017).\n53. Hu, E. J. et al. LoRA: low-rank adaptation of large language models. In International \nConference on Learning Representations, https://openreview.net/forum?id=nZeVKeeFYf9 \n(Curran Associates, 2022).\n54. Brandstetter, J., Worrall, D. E. & Welling, M. Message passing neural PDE solvers.  \nIn International Conference on Learning Representations, https://openreview.net/\nforum?id=vSix3HPYKSU (Curran Associates, 2022).\n55. Lin, L.-J. Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie \nMellon Univ. (1993).\n56. Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, \n529–533 (2015).\n57. Sampson, C. R. & Schrader, A. J. The automated tropical cyclone forecasting system \n(version 3.2). Bull. Am. Meteorol. Soc. 81, 1231–1240 (2000).\n58. Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O. & Dahl, G. E. Neural message passing \nfor quantum chemistry. In Proc. 34th International Conference on Machine Learning  \n(eds Precup, D. & Teh, Y. W.) 1263–1272 (PMLR, 2017).\n59. Beyer, L. et al. FlexiViT: one model for all patch sizes. In Proc. IEEE/CVF Conference on \nComputer Vision and Pattern Recognition (CVPR) 14496–14506 (IEEE, 2023).\n60. Rasp, S. et al. WeatherBench 2: a benchmark for the next generation of data-driven global \nweather models. J. Adv. Model. Earth Syst. 16, e2023MS004019 (2024).\n61. Hersbach, H. et al. ERA5 hourly data on single levels from 1940 to present. Copernicus \nClimate Change Service (C3S) Climate Data Store (CDS), https://cds.climate.copernicus.\neu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview (2018).\n62. Hersbach, H. et al. ERA5 hourly data on pressure levels from 1940 to present. Copernicus \nClimate Change Service (C3S) Climate Data Store (CDS), https://cds.climate.copernicus.\neu/cdsapp#!/dataset/reanalysis-era5-pressure-levels?tab=overview (2018).\n63. European Centre for Medium-Range Weather Forecasts (ECMWF). Section 2.1.2.4 HRES - \nHigh Resolution Forecasts. https://www.ecmwf.int/en/forecasts/datasets/set-i (2024).\n64. European Centre for Medium-Range Weather Forecasts (ECMWF). Section 5 Forecast \nEnsemble (ENS) - Rationale and Construction. https://confluence.ecmwf.int/display/FUG/\nSection+5+Forecast+Ensemble+%28ENS%29+-+Rationale+and+Construction (2024).\n65. National Oceanic and Atmospheric Administration (NOAA). NOAA Global Forecast \nSystem (GFS). https://registry.opendata.aws/noaa-gfs-bdp-pds (2024).\n66. National Oceanic and Atmospheric Administration (NOAA). NOAA Global Ensemble \nForecast System (GEFS). https://registry.opendata.aws/noaa-gefs (2024).\n67. Scoccimarro, E., Bellucci, A. & Peano, D. CMCC CMCC-CM2-VHR4 model output \nprepared for CMIP6 HighResMIP hist-1950. Earth System Grid Federation, https://doi.org/ \n10.22033/ESGF/CMIP6.3818 (2018).\n68. European Centre for Medium-Range Weather Forecasts (ECMWF). PRIMAVERA: European \nCentre for Medium-Range Weather Forecasts (ECMWF) ECMWF-IFS-HR model output for \nthe “hist-1950” experiment. NERC EDS Centre for Environmental Data Analysis, https:// \ncatalogue.ceda.ac.uk/uuid/470e43e166c44e5990f4f74bc90562d6 (2022).\n69. Global Modeling and Assimilation Office (GMAO). MERRA-2: 2d, 1-hourly, time-averaged, \nsingle-level, assimilation, single-level diagnostics V5.12.4. Goddard Earth Sciences Data \nand Information Services Center (GES DISC), https://disc.gsfc.nasa.gov/information/\nmission-project?title=MERRA-2 (2022).\n70. European Centre for Medium-Range Weather Forecasts (ECMWF). CAMS: global \natmospheric composition forecast data documentation. https://confluence.ecmwf. \nint/display/CKB/CAMS%3A+Global+atmospheric+composition+forecast+data+ \ndocumentation (2024).\n71. Lang, S. et al. AIFS – ECMWF’s data-driven forecasting system. Preprint at https://arxiv.org/ \nabs/2406.01465 (2024).\n72. Dehghani, M. et al. Patch n’ Pack: NaViT, a vision transformer for any aspect ratio and \nresolution. In Advances in Neural Information Processing Systems 36 (eds Oh, A. et al.) \n2252–2274, https://proceedings.neurips.cc/paper_files/paper/2023/file/06ea400b9b7cf\nce6428ec27a371632eb-Paper-Conference.pdf (2023).\n73. Rasp, S. et al. WeatherBench: a benchmark data set for data-driven weather forecasting. \nJ. Adv. Model. Earth Syst. 12, e2020MS002203 (2020).\n74. Hoffmann, J. et al. Training compute-optimal large language models. In Proc. 36th \nInternational Conference on Neural Information Processing Systems (eds Koyejo, S. et al.) \n30016–30030 (Curran Associates, 2024).\n75. Gunasekar, S. et al. Textbooks are all you need. In International Conference on Learning \nRepresentations, https://openreview.net/forum?id=Fq8tKtjACC (Curran Associates, \n2024).\n76. Inness, A. et al. CAMS global reanalysis (EAC4). Copernicus Atmosphere Monitoring \nService (CAMS) Atmosphere Data Store (ADS), https://ads.atmosphere.copernicus.eu/\ncdsapp#!/dataset/cams-global-reanalysis-eac4?tab=overview (2024).\n77. Hunter, J. D. Matplotlib: a 2D graphics environment. Comput. Sci. Eng. 9, 90–95 (2007).\n78. UK Met Office. Cartopy: a cartographic Python library with a Matplotlib interface.  \nhttps://scitools.org.uk/cartopy (2010–2015).\n79. Bodnar, C. et al. microsoft/aurora: v1.5.1. Zenodo https://doi.org/10.5281/zenodo.14983584 \n(2025).\n80. Nguyen, T., Brandstetter, J., Kapoor, A., Gupta, J. K. & Grover, A. ClimaX: a foundation \nmodel for weather and climate. In Proc. 40th International Conference on Machine \nLearning (eds Krause, A. et al.) 25904–25938, https://proceedings.mlr.press/v202/\nnguyen23a.html (PMLR, 2023).\n81. Kaplan, J. et al. Scaling laws for neural language models. Preprint at https://arxiv.org/\nabs/2001.08361 (2020)\nAcknowledgements We thank the European Centre for Medium-Range Weather Forecasts \n(ECMWF) and the National Oceanic and Atmospheric Administration (NOAA) for their \ncommitment to open science and their substantial efforts to generate, curate and openly \ndisseminate all of the datasets that enabled our work and we thank M. Chantry for the helpful \nadvice on the ECMWF’s data sources. We thank the Copernicus Atmosphere Monitoring \nService (CAMS) team at the ECMWF for insightful discussions. We thank W. Shi, Y. Wang, P. Hu \nand Q. Meng from Microsoft Research, AI for Science and R. T. des Combes and S. Chen from \nMicrosoft Research for helpful inputs in the early stages of this work. We thank D. Kumar, W. Jin, \nS. Klocek, S. Xiang and H. Sun from MSN Weather for their technical feedback throughout this \nproject. We also thank D. Schwarenthorer for his help with Azure computing and licensing. \nFinally, we thank A. Foong and F. Noé for constructive feedback during the writing of this \nmanuscript. We are also grateful to N. Shankar for his assistance with the HRES T0 dataset. \nR.E.T. was financed by EPSRC Prosperity Partnership EP/T005386/1 between Microsoft \nResearch and the University of Cambridge during the final stages of the project.\nAuthor contributions C.B., W.P.B., A.L. and M.S. were the four core contributors of this project. \nThey formulated, implemented and evaluated all aspects of Aurora, including the model \narchitecture, the training and fine-tuning pipelines, as well as all experiments and evaluations, \nexcept for the tropical cyclone results. A.A. was also a core contributor, provided critical \nfeedback and helped conceptualize, formulate and design the experiments. A.A. originated and \ncarried out the tropical cyclone experiments and evaluations, with the assistance of W.P.B. and \nC.-C.W. P.G. and M.R. supported the engineering infrastructure of this project. J.B., J.K.G. and \nM.W. contributed to the initial development and conceptualization of this research. J.A.W.,  \nH.D. and K.T. provided regular feedback and carried out all comparisons against weather \nstation data. A.T.A. provided guidance on the CAMS experiments and model evaluation.  \nE.H. provided assistance with programme management and research timelines. R.E.T. and  \nP.P. supervised all aspects of this project. All authors contributed to the writing and editing of \nthis manuscript.\nCompeting interests C.B., W.P.B., M.S., J.B., P.G., M.R., J.A.W., H.D., J.K.G., K.T., E.H., M.W. and P.P. \nown Microsoft stock. W.P.B., M.S., P.G., M.R., J.A.W., H.D. and K.T. are Microsoft employees. C.B. \nand J.K.G. are employees of Silurian AI Inc. and own Silurian AI Inc. stock. The remaining \nauthors declare no competing interests.\nAdditional information\nSupplementary information The online version contains supplementary material available at \nhttps://doi.org/10.1038/s41586-025-09005-y.\nCorrespondence and requests for materials should be addressed to Paris Perdikaris.\nPeer review information Nature thanks Qi Tian and the other, anonymous, reviewer(s) for their \ncontribution to the peer review of this work. Peer reviewer reports are available.\nReprints and permissions information is available at http://www.nature.com/reprints.\nExtended Data Fig. 1 | Pretraining on diverse data and increasing model \nsize improves performance.  a, Performance on ERA5 2021 at 6-h lead time  \nfor models pretrained on different dataset configurations, labelled C1–C4, \nwithout fine-tuning. Adding low-fidelity simulation data from CMIP6 (that is, \nCMCC and IFS-HR) improves performance almost uniformly (C2). Adding even \nmore simulation data improves performance further on most surface variables \nand for the atmospheric levels present in this newly added data (C3). Finally, \nconfiguration C4, which includes comprehensive atmospheric coverage  \nand analysis data from GFS, achieves the best overall performance, with \nimprovements across the board. b , For the same configurations considered in \na, performance for extreme values on IFS HRES 2022 at 6-h lead time. Shows \nRMSEs computed only on data below (left panels) or above (right panels) a \nthreshold b together with a 95% confidence interval obtained through \nbootstrapping. Pretraining on many diverse data sources also improves the \nforecasting of extreme values. c , Bigger models obtain lower IFS HRES \nvalidation loss for the same number of GPU hours. At 5,000 GPU hours, we find \nthat the validation loss behaves like L NN() ∝ −0.026, in which N is the number of \nparameters, which corresponds to a 6% reduction in validation loss for every \nten times increase in model size.\nArticle\nExtended Data Fig. 2 | Validation curves for all surface-level variables during pretraining. For every surface-level variable, at 5,000 GPU hours, we find that \nthe validation loss roughly behaves like f (N) ∝ N−α, in which N is the number of parameters and α > 0 is an estimated parameter.\nAtmospheric \nPerceiver\nLATENT SURFACE\nDE-AGGREGATED \nATMOSPHERIC LEVELS\nOUTPUT \nPATCHES\nOUTPUT ATMOSPHERIC VARIABLES\nOUTPUT LEVELS\n50 hPA\n100 hPA\n200 hPA\n1000 hPA\nFourrier encoding\nATMOSPHERIC KEYS & VALUES\nOUTPUT \nLEVEL QUER IES\nOUTPUT SURFACE VARIABLESLATENT LEVELS\nWIDTH\nHEIGHT\nC C\nC\nD\nD\nD\nK\nV\nD\nBACKBONE OUTPUT\nINPUT ATMOSPHERIC VARIABLES\nINPUT SURFACE VARIABLES\nINPUT PATCHES\n50 hPA\n1000 hPA\nFourier encoding C\nAtmospheric \nPerceiver\nStack\nFourier encoding\nLATENT LEVELS\nWIDTH\nHEIGHT\nBACKBONE INPUT\nATMOSPHERIC \nKEYS & VALUES\nLATENT LEVEL QUERIES POSITION PATCH AREA TIME\nINPUT LEVELS\nINPUT \nLEVEL ENCODINGS\nSURFACE ENCODING\nLATENT SURFACE\nLATENT \nATMOSPHERIC LEVELS\nLATENT  LEVELS\nATMOSPHERIC\nPATCH EMBEDDINGS\nSURFACE PATCH EMBEDDING\nD\nD\nD K\nV\nD\nC\nC\nD\nD\nD\nD D\nD\nC\nC\nLATENT \nATMOSPHERIC LEVELS\na\nb\nExtended Data Fig. 3 | Aurora is an encoder–decoder model with a 3D latent \nrepresentation.  The colours are for illustrative purposes only. a , Aurora’s \nencoder module. Input weather states are tokenized and compressed into a  \n3D latent representation using Perceiver-style 21 cross-attention blocks.  \nThe resulting latent tokens are augmented with appropriate encodings that \nprovide spatial, temporal and scale information. b , Aurora’s decoder module. \nThe target output variables are reconstructed in spatial patches by decoding \nAurora’s 3D latent state using Perceiver-style cross-attention blocks."
}