{
  "title": "From Text to Maps: Automated Concept Map Generation Using Fine-tuned Large Language Model",
  "url": "https://openalex.org/W4391148989",
  "year": 2023,
  "authors": [
    {
      "id": null,
      "name": "Wagner de A. Perin",
      "affiliations": [
        "University of Finance and Economics"
      ]
    },
    {
      "id": "https://openalex.org/A5114120954",
      "name": "Davidsom Cury",
      "affiliations": [
        "University of Finance and Economics"
      ]
    },
    {
      "id": "https://openalex.org/A2767750645",
      "name": "Camila Zacché de Aguiar",
      "affiliations": [
        "University of Finance and Economics"
      ]
    },
    {
      "id": "https://openalex.org/A2430442547",
      "name": "Crediné S. de Menezes",
      "affiliations": [
        "Universidade Federal do Rio Grande do Sul"
      ]
    },
    {
      "id": null,
      "name": "Wagner de A. Perin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5114120954",
      "name": "Davidsom Cury",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2767750645",
      "name": "Camila Zacché de Aguiar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2430442547",
      "name": "Crediné S. de Menezes",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4367365458",
    "https://openalex.org/W2063978074",
    "https://openalex.org/W2151034031",
    "https://openalex.org/W1513851544",
    "https://openalex.org/W156414033",
    "https://openalex.org/W2152183901",
    "https://openalex.org/W2294038891",
    "https://openalex.org/W2550631396",
    "https://openalex.org/W2762170396",
    "https://openalex.org/W2125730438",
    "https://openalex.org/W1963374379",
    "https://openalex.org/W2027711578",
    "https://openalex.org/W4387839554",
    "https://openalex.org/W2122840359",
    "https://openalex.org/W2003068264",
    "https://openalex.org/W1998731162",
    "https://openalex.org/W2777917715",
    "https://openalex.org/W2074195322",
    "https://openalex.org/W2076039115",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4206762630",
    "https://openalex.org/W4237977861"
  ],
  "abstract": "Concept maps (CMs) are tools for visualizing relationships between ideas, facilitating more effective comprehension and learning. However, the automatic generation of CMs from unstructured text presents a challenge, often requiring semantic markup and subsequent complex processing. This paper introduces a novel approach to address this hurdle by harnessing the capabilities of fine-tuned Large Language Models (LLMs). Our innovative methodology uses these models to extract structured propositions from unstructured text, subsequently serving as the foundation for constructing a CM. This process reverses the transformation of CM relations into first-order logic propositions, a concept explored in our previous work. To achieve this, we train the LLM using fine-tuning techniques, leveraging the latest advancements in artificial intelligence and machine learning. We evaluate our proposed solution based on precision and recall metrics, comparing our outcomes against models crafted by experts. Notably, the results indicate that our method can contribute significantly to advancements in the automatic generation of CMs, illustrating another application bolstered by recent breakthroughs in artificial intelligence. As a stepping stone in this promising direction, future research should continue to refine the model and explore potential applications across diverse domains.",
  "full_text": "From Text to Maps: Automated Concept Map Generation\nUsing Fine-tuned Large Language Model\nWagner de A. Perin1, Davidsom Cury1, Camila Zacch´e de Aguiar1,\nCredin´e S. de Menezes2\n1Departamento de Inform´atica – Universidade Federal do Esp´ırito Santo (UFES)\nCT-7 – Av. Fernando Ferrari, 514 – 29075-910 – Vit´oria – ES – Brazil\n2Faculdade de Educac ¸˜ao – Universidade Federal do Rio Grande do Sul (UFRGS)\nAv. Paulo Gama, s/nº – 90040-060 – Porto Alegre – RS – Brazil\n{wagner.perin, davidsom.cury, camila.z.aguiar, credine.menezes}@ufes.br\nAbstract. Concept maps (CMs) are tools for visualizing relationships between\nideas, facilitating more effective comprehension and learning. However, the\nautomatic generation of CMs from unstructured text presents a challenge, of-\nten requiring semantic markup and subsequent complex processing. This paper\nintroduces a novel approach to address this hurdle by harnessing the capabili-\nties of fine-tuned Large Language Models (LLMs). Our innovative methodology\nuses these models to extract structured propositions from unstructured text, sub-\nsequently serving as the foundation for constructing a CM. This process reverses\nthe transformation of CM relations into first-order logic propositions, a concept\nexplored in our previous work. To achieve this, we train the LLM using fine-\ntuning techniques, leveraging the latest advancements in artificial intelligence\nand machine learning. We evaluate our proposed solution based on precision\nand recall metrics, comparing our outcomes against models crafted by experts.\nNotably, the results indicate that our method can contribute significantly to ad-\nvancements in the automatic generation of CMs, illustrating another application\nbolstered by recent breakthroughs in artificial intelligence. As a stepping stone\nin this promising direction, future research should continue to refine the model\nand explore potential applications across diverse domains.\n1. Introduction\nConcept maps (CMs) are graphical tools for organizing and representing knowledge.\nThey play a key role in the more profound understanding of complex information, al-\nlowing students and researchers to visually represent the relationships and connections\nbetween concepts, helping them understand, communicate and retain knowledge. Howe-\nver, manually creating CMs from unstructured text is time-consuming and cognitively\ndemanding, requiring substantial experience and effort.\nRecent years have demonstrated the incredible potential of artificial intelligence\n(AI), primarily related to Natural Language Processing (NLP), with considerable advan-\nces, particularly with the advent of Large Language Models (LLMs). These models in-\ncreasingly demonstrate an unprecedented ability to understand and generate human-like\ntext, opening space for many applications, from chatbots and content generation to more\nsophisticated tasks, such as summarizing and translating text.\n\nDespite these advances, the automatic generation of CMs from unstructured text\nremains a significant challenge. Unsurprisingly, a secondary study by [Aguiar et al. 2016]\nidentified several techniques and proposed one to assist in automatically constructing CMs\nfrom unstructured texts. These processes usually involve semantic markings, followed by\ncomplex processing to identify and extract the elements present in the text. However,\nall these studies realized that the vast variability and ambiguity inherent in natural lan-\nguage make it particularly challenging to accurately extract the meaningful relationships\nbetween concepts that form the basis of a CM.\nIn light of these challenges, this study explores a new approach to automate the\ncreation of CMs from textual data, leveraging the features of fine-tuned LLMs. Speci-\nfically, we intend to leverage these models to extract structured propositions from uns-\ntructured text, thus providing the necessary fundamental elements for constructing a CM.\nThis strategy will reverse the transformation of CMs into first-order logical propositions,\nconcepts explored in our previous research [Perin et al. 2015].\nWe used precision and recall metrics, comparing the results with models created\nby specialists and results reported in [Aguiar et al. 2016]. From the results presented in\nsection 4, our approach has demonstrated a significant improvement over the previously\nestablished methods by utilizing a fine-tuned LLM. Regarding concept identification, our\napproach outperformed by approximately 23.5% in precision and held comparable recall\nvalues. Even more notably, in proposition identification, we saw an increase of 121% in\nprecision and a 33.2% improvement in recall compared to the previous methods. These\nnumbers highlight a substantial increase in the effectiveness of our methodology, show-\ncasing the transformative potential of applying LLMs in the realm of automatic CM ge-\nneration. Ultimately, this work significantly contributes to the automatic CM generation\nfield, highlighting the potential of recent advances in AI to boost this field.\nThis work will be developed as follows: Section 2 will review the background\nconcepts and related work in the field; Section 3 will detail our proposed methodology and\nits implementation; Section 4 will discuss the results and their implications respectively;\nand, finally, Section 5 will conclude the article and propose directions for future research.\n2. Related Works and Background\nThe automatic construction of CMs from unstructured texts has been a research topic\nof great interest for many years. Based on a comprehensive literature review conducted\nbetween 1994 and 2016, various technological approaches for automatic CM construction\nwere identified and categorized [Aguiar et al. 2016]. Four notable works stood out among\nthese approaches, each offering unique methods for generating CMs [Wang et al. 2008,\nˇZubrini´c et al. 2015, Zouaq and Nkambou 2009, de la Villa et al. 2012]. The underlying\nmethodology used across these approaches typically involved morphological and syntac-\ntic analysis, semantic mapping, statistical analysis, and linguistic techniques. However,\nthey highlighted several challenges: sentence fragmentation, long or missing concept la-\nbels, and dependence on other data sources like ontologies, knowledge bases, or thesauri.\nIn parallel, data mining methods have been used effectively to unearth use-\nful information in large datasets across various fields [Booth 2007, Li et al. 2004,\nCowan 2002, Hirschman et al. 2002]. Despite its later adoption in education, educati-\nonal data mining has shown great promise in designing smarter learning technologies\n[Romero and Ventura 2007, Baker 2014]. In this context, CMs have been leveraged\nto represent knowledge structures, with several research efforts being directed towards\ngenerating these maps [Acharya and Sinha 2017, Tseng et al. 2007, Bai and Chen 2008,\nChen and Sue 2013, Oppl and Stary 2011, Acharya and Sinha 2017].\nDespite the various algorithms and promising results achieved by these studies,\nthey often relied on explicit final datasets. They also rarely delved into the challen-\nges of handling multi-semantic data like raw textual data, which takes time to acquire.\nIn contrast, many studies have focused on text analysis and automatic CM generation\n[Lai et al. 2017, Wang and Hu 2016, Qasim et al. 2013, Nugumanova et al. 2015]. These\nstudies have demonstrated the ability to save time by effectively dealing with unstructured\ntexts, thus expediting the process of CM generation [Shao et al. 2020].\nThis article presents a new approach for automatic CM construction using fine-\ntuned LLMs to face some of the limitations identified in our previous works on NLP and\nthe specific challenges of this domain, taking advantage of the opportunities offered by\nthe recent advances in AI technologies, especially concerning NLP[Perin et al. 2014].\n2.1. Fine-Tuning of Large Language Models (LLMs)\nLarge Language Models(LLMs) are AI models trained on massive amounts of data to\nunderstand and generate human-like text. They can perform tasks like language transla-\ntion, question answering, and summarization. However, while these pre-trained LLMs\nare powerful, they may need to be optimized for specific applications or domains. In such\ninstances, fine-tuning is employed to enhance the LLM’s performance.\nFigura 1. Fine-tuning of a pre-existing LLM for specific purposes\nAs illustrated in Fig.1, fine-tuning involves retraining a pre-existing model on new,\ntask-specific data, enhancing its capability to handle specialized tasks or domains. This\nprocess includes loading the pre-trained model, adjusting its upper layers for the new task,\nand freezing the lower layers to maintain the general features already learned.\nUpon training the new layers, the whole model undergoes fine-tuning using task-\nspecific data. This process customizes the model to the new task, improving its perfor-\nmance and accuracy, thereby allowing it to serve domain-specific applications effectively.\nThe following section will detail the proposed architecture for leveraging fine-\ntuned LLMs in automatically generating CMs from unstructured text.\n3. Methodology and Implementation\nLLMs demonstrate remarkable capabilities in processing and interpreting complex lan-\nguage structures, recognizing sentence structures, identifying named entities, syntactic\nstructures, and much more. Our methodology leverages these capabilities to understand\nunstructured text, identify pertinent propositions, and produce structured data that subse-\nquently form the basis of a CM. This section elucidates how these fine-tuned LLMs can\nreplace complex processing algorithms and streamline the transformation from unstruc-\ntured texts to structured ones.\n3.1. Conceptual Architecture: A Comparative Overview\nA proposition comprises a tuple (concept-relation-concept), where the relational term (of-\nten a verb) outlines the semantic link between two concepts. Some studies use the propo-\nsitions in CMs as a knowledge base in intelligent systems [Perin and Cury 2016].\nAs mentioned, the automatic generation of CMs from unstructured texts requires\na sophisticated network of specific algorithms to detect and treat textual elements. The\ncentral principle that drives these algorithms is identifying and extracting these tuples, or\npropositions, forming the fundamental structures for constructing the corresponding CM.\nTherefore, an overview of automatic CM generators will invariably reveal components\nanalogous to those depicted in Fig.2(a).\nFigura 2. (a) Classical Architecture of CM Generators [Aguiar et al. 2016].\n(b) Proposed Architecture.\nIn Fig.2(a), procedures inscribed in the arrows represent specialized algorithms\ndesigned for the text’s treatment, annotation, identification, and interpretation, to reach the\nultimate goal of extracting the propositions that will constitute the generated CM. In addi-\ntion to being computationally complex, these algorithms depend on auxiliary databases:\nin that case, the authors use WordNet 1 and DBpedia2, which, together with SPARQL 3,\nsupport the process of ’labeling’ and ’semantic analysis.’\n1WordNetis an extensive lexical database of English. Nouns, verbs, adjectives, and adverbs are grouped\ninto sets of cognitive synonyms (synsets), each expressing a distinct concept.\n2DBpedia is a project that aims to extract structured content from the information created as part of the\nWikipedia project.\n3SPARQL is a query language and protocol for semantic web data sources used to retrieve information\nfrom databases stored in Resource Description Framework (RDF) format.\nIn classical architecture, every specialized algorithm has a specific role in proces-\nsing text. However, as a set, they work towards one goal: converting raw input text into a\nset of extracted propositions.\nConsidering that LLMs are inherently equipped with the necessary ’capabilities’\nfor this task, the proposed architecture—depicted in Fig.2(b)—replaces these complex\nalgorithms with a fine-tuned LLM. This template’s goal is straightforward: direct raw\ntext input into a list of propositions. This means that the complexities associated with\nmanaging complex structures and variations in syntax and semantics in unstructured text\nare handled by the lower layers of LLM. The upper layers, in turn, are tuned to extract\npropositions specifically (see Fig.1).\n3.2. Implementation\nTo implement the proposed architecture, we followed a four-step process whose interrela-\ntionships can be seen in Fig.3. Each process plays a crucial role in the overall architectural\npicture. In the following subsections, we present some important details of each process,\nits sub-processes, inputs, and artifacts:\nFigura 3. Conceptual Architecture Overview\n3.2.1. Process 1: Initial LLM Selection\nLLM selection is critical as it sets the stage for the rest of the implementation process. In\nour proposed architecture, this first process revolves around analyzing and choosing the\nLLM as the foundation for the subsequent fine-tuning stage (Process 3). This process was\nsubdivided into three distinct sub-processes:\n• Selection of Candidate LLMs : entailed reviewing a comprehensive secondary\nstudy[Yang et al. 2023] and extensive web-based searches to identify existing\nLLMs readily accessible online. As an artifact of this sub-process, we generate a\ntabulated inventory called the LLM Candidate Pool (n=52).\n• Criteria Definition and Weights: we define the crucial criteria list to select the\nmost appropriate LLM for our project. Each criterion was assigned a weight ran-\nging between 0 and 5, denoting its significance to our objectives. Consequently,\nthis sub-process yielded an artifact called the Criteria Set , which comprises a\nweighted set of criteria for the next sub-process (LLM evaluation).\n• Criteria Application (LLM Evaluation: was conducted in two steps. Step 1: the\nmost important criteria (4 or 5 in theCriteria Set) were used to filter theCandidate\nLLM Pool, reducing it from 52 to 9. Step 2: These latter were evaluated with the\nremaining criteria through a scoring system, producing a final ranking.\nFollowing this analysis, we settled on GPT-4 as the LLM of choice for our project\n[Ecoffet 2023]. This decision has been mainly influenced by its superior understanding\nand generation of coherent text, capacity to identify named entities, and capability to\ninterpret complex sentences and syntax: crucial attributes for automatic proposition ex-\ntraction from unstructured text. Also, its popularity, extensive documentation, and access\nto pre-trained models and fine-tuning tutorials further facilitated our implementation. Fi-\nnally, the vast training dataset and high grammatical and factual accuracy made it the most\nsuitable LLM for our project’s requirements.\n3.2.2. Process 2: Training Data Preparation\nThis process involves creating a dataset with examples of expected inputs and outputs.\nThis dataset lays the groundwork for the subsequent fine-tuning process, as the model\nlearns to perform the specific task by observing the patterns in this dataset. We divide this\nprocess into two sub-processes, namely:\n• Text Selection: we chose a range of texts to form the basis for the dataset cons-\ntruction. Despite GPT-4’s capability of handling inputs up to 25,000 words, our\nteam selected 11 texts with a limit of 4,000 words each. This decision was based\non the size of our research team and the subsequent sub-process, which demands\nsubstantial cognitive effort from the research team. Also, higher-capacity models,\nsuch as GPT-4, are trained on large volumes of data with multiple layers, requiring\nfewer examples in fine-tuning, facilitating the dataset construction process.\n• Reading and Conversion into Structured Propositions : our researchers meti-\nculously read the selected texts, identify the inherent propositions, and transform\nthese into a structured format akin to the approach adopted in our prior research\n[Perin 2014]. Consequently, from the 11 chosen texts, 387 propositions were dis-\ncerned. So, each text was individually associated with its corresponding set of\npropositions, forming the Training Dataset.\n3.2.3. Process 3: Fine-tuning Process\nThis process focuses on customizing the LLM to accomplish a specific task, made pos-\nsible by leveraging the dataset created in the previous process as a guide for further re-\nfinement of the LLM. The training process involves feeding this dataset into the model,\nallowing the machine learning engine to identify and adapt to the patterns and structures\ncharacteristic of our task. The result is a new variant of the LLM, fine-tuned and uniquely\nsuited for the task: extracting propositions from unstructured texts. This process is cri-\ntical, as it tailors the broad capabilities of the general LLM to our specific requirement,\nenhancing its performance and efficiency in generating structured data for CM generation.\n3.2.4. Process 4: CM Builder\nThis process utilizes the Fine-Tuned Model as an initial component, responsible for per-\nforming the entire NLP task: primarily extracting a list of propositions from the input\nunstructured text. This list represents the key concepts and their relationships, essentially\nthe ’knowledge’ contained within the text. They form the backbone of our CM, informing\nthe identification and extraction of elements to be visualized as nodes (concepts) and links\n(relations) within the generated map.\nFollowing the extraction process, an initial automatic layout is created. Levera-\nging techniques referenced in previous studies [de Castro et al. 2015], this layout forms a\nvisually coherent and meaningful representation of the information contained within the\ntext, thus producing the main artifact: an automatically generated CM.\n4. Results and Implications\nThis section will present the preliminary results of implementing the proposed metho-\ndology, reconstructing the experiments described in [Aguiar and Cury 2017]. We draw\na comparative analysis between the CMs produced by humans, the results reported by\nthe authors, and those obtained through our approach, to highlight our methodology’s\neffectiveness and potential within the same experimentation framework. Afterward, we\ncritically reflect on the comparison procedure and the data obtained, both in the authors’\nexperiments and ours, providing valuable information on the practical implications, care\nrelated to the experiment setup, and the treatment of the data obtained.\n4.1. Experiment Settings\n[Aguiar and Cury 2017] engaged five graduate students for their experimental process.\nAfter receiving requisite training on CM generation from text sources, these students\nwere tasked with independently creating CMs based on a pre-selected text provided by\nthe authors. These CMs were later juxtaposed with the outcomes yielded by the automatic\ngeneration tool proposed by the authors, using precision and recall metrics, scrutinizing\nindividual participant results against those rendered by the automatic generator.\nFigura 4. Comparison of Experiment Settings\nIn our experimental design, we implemented a slight modification. Given that\nour primary objective was to compare the outcomes of automatic generators against col-\nlective human effort rather than individual human performance, we amalgamated the\nCMs produced by the five participants. Leveraging the merging algorithm proposed by\n[Vassoler et al. 2014], we generated a collective CM encompassing all propositions iden-\ntified by the five participants. This merged map then served as the basis for comparison\nagainst the results presented in [Aguiar and Cury 2017] and those yielded by our appro-\nach. Fig. 4 provides a detailed depiction of our experimental setup, elucidating the com-\nparison parameters and the metrics employed.\n4.2. Results\nThis experiment was conducted using the introductory section of the well-regarded article\nby [Novak and Ca ˜nas 2008] as a data source. This seminal work in Concept Mapping\npresented a suitable, content-rich, and complex text source for our experiment. We used\nthe ideas and propositions presented in the introductory section to test the effectiveness of\nour approach in recognizing and extracting key concepts and generating a corresponding\nconcept map. This allowed us to test our approach against the other mentioned CMs\nrigorously.\nIt starts by detailing the size of the CMs obtained in the procedures outlined in the\nprevious subsection. The main object of this study, the MC generated by our approach, is\nshown in Fig. 5.\nFigura 5. Generated CM from Our Approach\nTo encapsulate the scale of CMs produced, we provide a summary in Tab. 1,\nthrough which it is possible to observe that: the MC obtained from the fusion of the\nfive CMs generated by human participants comprises 63 concepts and 137 propositions;\nCM produced by the methodology proposed by [Aguiar and Cury 2017] encapsulates 80\nconcepts and 123 propositions; in contrast, the CM processed by our approach contains\n51 concepts and 43 propositions.\nConcerning identifying concepts and propositions, as summarized in Table 2. Re-\ngarding the identification of concepts, our approach demonstrated a considerable impro-\nvement in precision by around 23.5% (0.603 versus 0.488) and a similar recall within\n2.65% (0.619 versus 0.603). This result indicates that our method was more accurate\nTabela 1. Generated CMs Summary\nGenerated CMs Summary\nMerged [Aguiar et al., 2017] approach Our approach\nNumber of Concepts 63 80 51\nNumber of Propositions 137 123 43\nTabela 2. Precision and Recall Results\nConcepts on\n[Aguiar et al., 2017] approach\nConcepts on\nOur approach\nConcepts on precision 0,488 0,603\nMerged recall 0,603 0,619\nPropositions on\n[Aguiar et al., 2017] approach\nPropositions on\nOur approach\nPropositions on precision 0,358 0,791\nMerged recall 0,307 0,409\nin identifying true positives and minimizing false positives, thus demonstrating a higher\nquality of results.\nAs for the identification of propositions, our approach surpassed the previous\nmethod in precision by a substantial margin of approximately 121% (0.791 versus 0.358)\nand displayed superior recall by around 33.2% (0.409 versus 0.307). This result suggests\nthat our approach is better in identifying true propositions from the given texts and mi-\nnimizing the omission of valid propositions, thus ensuring more comprehensive coverage\nof the information contained in the input text.\nThese superior precision and recall results reflect the efficacy of our approach.\nThe improved precision denotes a higher rate of relevant concepts and propositions iden-\ntified and a lower rate of false positives. The enhanced recall illustrates that our method\nsuccessfully identifies a more significant proportion of true positives. Consequently, these\nfindings suggest that our model offers a more accurate and exhaustive method for extrac-\nting concepts and propositions from the text.\n4.3. Caveats and Considerations\nOur methodology employed both quantitative and qualitative analytical techniques to fa-\ncilitate a comprehensive understanding of the results. In this process, we acknowledged\nequivalent propositions as valid. For instance, the propositions includes(concept maps,\nconcepts) and has(concept maps, concepts) were treated as equivalent in our computati-\nons. This is an important aspect to consider when interpreting our results, as it significan-\ntly evaluates accuracy and recall.\nAdditionally, we evaluated the equivalence of more straightforward propositions\nwith their more complex counterparts. As an illustrative example, the proposition defi-\nnedAs(concept, perceived regularity in events) was deemed equivalent to the combined\npropositions definedAs(concept, regularity) and perceivedAt(regularity, event), as both\nstructures essentially communicate the same core idea. It is important to note that the\nresults reported in this study were obtained under controlled conditions and with limited\nsample size. As such, they may need to fully reflect the performance of the approach in\nbroader, real-world contexts. In future research, we aim to expand the scope of our expe-\nriments to encompass diverse scenarios and population characteristics. This will provide\nus with a more nuanced understanding of the effectiveness of our approach and enable us\nto fine-tune it further based on these additional insights.\n5. Conclusions and Future Works\nThis paper presents a novel approach to automatically extracting propositions from uns-\ntructured texts and generating concept maps from these propositions. Leveraging the\ncapabilities of large language models (LLMs) like GPT-4, we devised an architecture that\nreplaces a complex stack of traditional natural language processing (NLP) algorithms with\na fine-tuned LLM. This architecture simplifies the process and demonstrates remarkable\npromise in proposition extraction and concept map generation.\nThrough a series of controlled experiments, we demonstrated our approach’s su-\nperior precision and recall compared to previous methods. These results highlight the\npotential benefits of using LLMs for NLP tasks, particularly in education and learning\ntools.\nHowever, it is important to acknowledge the limitations of our research. The re-\nsults were obtained under controlled conditions with a limited sample size, which may\nnot fully reflect real-world scenarios. Additionally, despite employing a careful analy-\nsis process that considers the equivalence of simple and complex propositions, natural\nlanguage’s inherent variability and subtlety can pose challenges.\nLooking ahead, our future work will focus on scaling up our approach and testing\nit in diverse scenarios and with broader population characteristics. This will provide us\nwith a more nuanced understanding of its strengths and potential areas for improvement.\nFurthermore, we intend to explore ways of integrating the proposed architecture with\nother educational tools and systems to enhance learning experiences. The current work is\nonly the first step on a promising journey toward harnessing the full potential of LLMs in\nthe educational domain.\nReferˆencias\nAcharya, A. and Sinha, D. (2017). An educational data mining approach to concept map\nconstruction for web based learning. Informatica Economica, 21(4):41–58.\nAguiar, C. and Cury, D. (2017). Minerac ¸˜ao de mapas conceituais a partir de textos em\nportuguˆes. In Brazilian Symposium on Computers in Education (Simp ´osio Brasileiro\nde Inform´atica na Educac ¸˜ao-SBIE), volume 28, page 1117.\nAguiar, C. Z., Cury, D., and Zouaq, A. (2016). Automatic construction of concept maps\nfrom texts. In Proceedings of the 7th International Conference on Concept Mapping ,\nvolume 2, pages 20–30, Tallinn, Estonia. CMC 2016.\nBai, S.-M. and Chen, S.-M. (2008). Automatically constructing concept maps based on\nfuzzy rules for adapting learning systems.Expert Systems with Applications, 35(1):41–\n49.\nBaker, R. S. (2014). Educational data mining: An advance for intelligent systems in\neducation. IEEE Intelligent Systems, 29(3):78–82.\nBooth, D. E. (2007). Data mining methods and models. Technometrics, 49(4):500–500.\nChen, S.-M. and Sue, P.-J. (2013). Constructing concept maps for adaptive learning sys-\ntems based on data mining techniques. Expert Systems with Applications, 40(7):2746–\n2755.\nCowan, A. M. (2002). Data mining in finance: Advances in relational and hybrid methods:\nBoris kovalerchuk and evgenii vityaev (eds.), kluwer academic publishers, norwell,\nmassachusetts, 2000, hb us $120, isbn 0-7923-7804-0. International Journal of Fore-\ncasting, 18(1):155–156.\nde Castro, R. N., Perin, W. A., and Cury, D. (2015). Layouts autom ´aticos para mapas\nconceituais-um servic ¸o integrado a uma plataforma de servic ¸os web. InXX Congresso\nInternacional de Inform´atica Educativa (TISE).\nde la Villa, M., Aparicio, F., Ma˜na, M. J., and de Buenaga, M. (2012). A learning support\ntool with clinical cases based on concept maps and medical entity recognition. In\nProceedings of the 2012 ACM International Conference on Intelligent User Interfaces,\nIUI ’12, page 61–70, New York, NY , USA. Association for Computing Machinery.\nEcoffet, A. (2023). Gpt-4 technical report. arXiv preprint arXiv:2303.08774.\nHirschman, L., Park, J. C., Tsujii, J., Wong, L., and Wu, C. H. (2002). Accomplishments\nand challenges in literature data mining for biology. Bioinformatics, 18(12):1553–\n1561.\nLai, C.-F., Chen, S.-Y ., Tsai, C.-W., Chang, Y .-C., and Su, Y .-S. (2017). Using information\nretrieval to construct an intelligent e-book with keyword concept map.Eurasia Journal\nof Mathematics, Science and Technology Education, 13(10):6737–6747.\nLi, L., Tang, H., Wu, Z., Gong, J., Gruidl, M., Zou, J., Tockman, M., and Clark, R. A.\n(2004). Data mining techniques for cancer detection using serum proteomic profiling.\nArtificial Intelligence in Medicine, 32(2):71–83.\nNovak, J. D. and Ca ˜nas, A. J. (2008). The theory underlying concept maps and how to\nconstruct and use them. IHMC.\nNugumanova, A., Mansurova, M., Alimzhanov, E., Zyryanov, D., and Apayev, K. (2015).\nAutomatic generation of concept maps based on collection of teaching materials. InIn-\nternational conference on data management technologies and applications, volume 2,\npages 248–254. SCITEPRESS.\nOppl, S. and Stary, C. (2011). Effects of a tabletop interface on the co-construction of\nconcept maps. In Human-Computer Interaction–INTERACT 2011: 13th IFIP TC 13\nInternational Conference, Lisbon, Portugal, September 5-9, 2011, Proceedings, Part\nIII 13, pages 443–460. Springer.\nPerin, W. and Cury, D. (2016). Uma plataforma de servic ¸os para mapas conceituais. In\nBrazilian Symposium on Computers in Education (Simp´osio Brasileiro de Inform´atica\nna Educac ¸˜ao-SBIE), volume 27, page 230.\nPerin, W., Cury, D., and Menezes, C. d. (2015). imap & cmpaas-de ferramenta `a pla-\ntaforma de servic ¸os para mapas conceituais. Revista Brasileira de Inform ´atica na\nEducac ¸˜ao, 24(3).\nPerin, W. d. A. (2014). imap: um mecanismo de infer ˆencia para mapas conceituais.\nRepositorio de Dissertacoes UFES (repositorio.ufes.br:10/1484).\nPerin, W. d. A., Cury, D., and Menezes, C. (2014). Nlp-imap: Integrated solution based\non question-answer model in natural language for an inference mechanism in concepts\nmaps. In Proceedings of the 14th International Conference on Concept Mapping.\nQasim, I., Jeong, J.-W., Heu, J.-U., and Lee, D.-H. (2013). Concept map construc-\ntion from text documents using affinity propagation. Journal of Information Science,\n39(6):719–736.\nRomero, C. and Ventura, S. (2007). Educational data mining: A survey from 1995 to\n2005. Expert Systems with Applications, 33(1):135–146.\nShao, Z., Li, Y ., Wang, X., Zhao, X., and Guo, Y . (2020). Research on a new automa-\ntic generation algorithm of concept map based on text analysis and association rules\nmining. Journal of ambient intelligence and humanized computing, 11:539–551.\nTseng, S.-S., Sue, P.-C., Su, J.-M., Weng, J.-F., and Tsai, W.-N. (2007). A new approach\nfor constructing the concept map. Computers & Education, 49(3):691–707.\nVassoler, G. A., Perin, W. d. A., and Cury, D. (2014). Mergemaps–a computational tool\nfor merging of concept maps. In Proceedings of the 14th International Conference on\nConcept Mapping.\nWang, M. and Hu, Y . (2016). I-raid: A novel redundant storage architecture for improving\nreliability, performance, and life-span of solid-state disk systems. In Proceedings of\nthe 31st Annual ACM Symposium on Applied Computing , SAC ’16, page 1824–1831,\nNew York, NY , USA. Association for Computing Machinery.\nWang, W., Cheung, C., Lee, W., and Kwok, S. (2008). Mining knowledge from natural\nlanguage texts using fuzzy associated concept mapping. Information Processing &\nManagement, 44(5):1707–1719.\nYang, J., Jin, H., Tang, R., Han, X., Feng, Q., Jiang, H., Yin, B., and Hu, X. (2023).\nHarnessing the power of llms in practice: A survey on chatgpt and beyond. arXiv\npreprint arXiv:2304.13712.\nZouaq, A. and Nkambou, R. (2009). Evaluating the generation of domain ontologies in the\nknowledge puzzle project. IEEE Transactions on Knowledge and Data Engineering ,\n21(11):1559–1572.\nˇZubrini´c, K., Obradovi ´c, I., and Sjekavica, T. (2015). Implementation of method for\ngenerating concept map from unstructured text in the croatian language. In 2015 23rd\nInternational Conference on Software, Telecommunications and Computer Networks\n(SoftCOM), pages 220–223.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8081799149513245
    },
    {
      "name": "Markup language",
      "score": 0.7427831888198853
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5995545387268066
    },
    {
      "name": "Process (computing)",
      "score": 0.5380240678787231
    },
    {
      "name": "Precision and recall",
      "score": 0.4686683118343353
    },
    {
      "name": "Natural language processing",
      "score": 0.460345983505249
    },
    {
      "name": "Comprehension",
      "score": 0.431124746799469
    },
    {
      "name": "Machine learning",
      "score": 0.36037278175354004
    },
    {
      "name": "Data science",
      "score": 0.33631467819213867
    },
    {
      "name": "Programming language",
      "score": 0.2399645447731018
    },
    {
      "name": "XML",
      "score": 0.14118099212646484
    },
    {
      "name": "World Wide Web",
      "score": 0.1392882764339447
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I51235708",
      "name": "Universidade Federal do Espírito Santo",
      "country": "BR"
    },
    {
      "id": "https://openalex.org/I130442723",
      "name": "Universidade Federal do Rio Grande do Sul",
      "country": "BR"
    }
  ],
  "cited_by": 1
}