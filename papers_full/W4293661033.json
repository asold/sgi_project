{
    "title": "CAiTST: Conv-Attentional Image Time Sequence Transformer for Ionospheric TEC Maps Forecast",
    "url": "https://openalex.org/W4293661033",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A3144656301",
            "name": "Guozhen Xia",
            "affiliations": [
                "Wuhan University"
            ]
        },
        {
            "id": "https://openalex.org/A2291758550",
            "name": "Moran Liu",
            "affiliations": [
                "Wuhan University"
            ]
        },
        {
            "id": "https://openalex.org/A2116721887",
            "name": "Fubin Zhang",
            "affiliations": [
                "Wuhan University"
            ]
        },
        {
            "id": "https://openalex.org/A2066704773",
            "name": "Zhou Chen",
            "affiliations": [
                "Wuhan University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2747371672",
        "https://openalex.org/W2899563669",
        "https://openalex.org/W2784690196",
        "https://openalex.org/W2957387369",
        "https://openalex.org/W3096375705",
        "https://openalex.org/W1822117460",
        "https://openalex.org/W3010406726",
        "https://openalex.org/W2942194952",
        "https://openalex.org/W2086555535",
        "https://openalex.org/W1946416597",
        "https://openalex.org/W3030556784",
        "https://openalex.org/W2153105094",
        "https://openalex.org/W1969608025",
        "https://openalex.org/W2029557308",
        "https://openalex.org/W2990229927",
        "https://openalex.org/W1545415609",
        "https://openalex.org/W1631751207",
        "https://openalex.org/W2790261559",
        "https://openalex.org/W3104446864",
        "https://openalex.org/W4221054205",
        "https://openalex.org/W3112737963",
        "https://openalex.org/W4226335819",
        "https://openalex.org/W4224066624",
        "https://openalex.org/W4286209456",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W1974679987",
        "https://openalex.org/W3097065222",
        "https://openalex.org/W2163605009",
        "https://openalex.org/W2791978127",
        "https://openalex.org/W4213059695",
        "https://openalex.org/W3025313534",
        "https://openalex.org/W2795067691",
        "https://openalex.org/W2995297292",
        "https://openalex.org/W3158425022",
        "https://openalex.org/W1998983070",
        "https://openalex.org/W1907127744",
        "https://openalex.org/W3170872340",
        "https://openalex.org/W3145491624",
        "https://openalex.org/W3202525453"
    ],
    "abstract": "In recent years, transformer has been widely used in natural language processing (NLP) and computer vision (CV). Comparatively, forecasting image time sequences using transformer has received less attention. In this paper, we propose the conv-attentional image time sequence transformer (CAiTST), a transformer-based image time sequences prediction model equipped with convolutional networks and an attentional mechanism. Specifically, we employ CAiTST to forecast the International GNSS Service (IGS) global total electron content (TEC) maps. The IGS TEC maps from 2005 to 2017 (except 2014) are divided into the training dataset (90% of total) and validation dataset (10% of total), and TEC maps in 2014 (high solar activity year) and 2018 (low solar activity year) are used to test the performance of CAiTST. The input of CAiTST is presented as one day’s 12 TEC maps (time resolution is 2 h), and the output is the next day’s 12 TEC maps. We compare the results of CAiTST with those of the 1-day Center for Orbit Determination in Europe (CODE) prediction model. The root mean square errors (RMSEs) from CAiTST with respect to the IGS TEC maps are 4.29 and 1.41 TECU in 2014 and 2018, respectively, while the RMSEs of the 1-day CODE prediction model are 4.71 and 1.57 TECU. The results illustrate CAiTST performs better than the 1-day CODE prediction model both in high and low solar activity years. The CAiTST model has less accuracy in the equatorial ionization anomaly (EIA) region but can roughly predict the features and locations of EIA. Additionally, due to the input only including past TEC maps, CAiTST performs poorly during magnetic storms. Our study shows that the transformer model and its unique attention mechanism are very suitable for images of a time sequence forecast, such as the prediction of ionospheric TEC map sequences.",
    "full_text": null
}