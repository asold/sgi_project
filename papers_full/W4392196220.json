{
  "title": "Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning",
  "url": "https://openalex.org/W4392196220",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2112761320",
      "name": "Stefan E. Huber",
      "affiliations": [
        "University of Graz"
      ]
    },
    {
      "id": "https://openalex.org/A1252427242",
      "name": "Kristian Kiili",
      "affiliations": [
        "Tampere University"
      ]
    },
    {
      "id": "https://openalex.org/A2105248890",
      "name": "Steve Nebel",
      "affiliations": [
        "University of Potsdam"
      ]
    },
    {
      "id": "https://openalex.org/A2101546085",
      "name": "Richard M. Ryan",
      "affiliations": [
        "Ewha Womans University",
        "Australian Catholic University"
      ]
    },
    {
      "id": "https://openalex.org/A2109263912",
      "name": "Michael Sailer",
      "affiliations": [
        "University of Augsburg"
      ]
    },
    {
      "id": "https://openalex.org/A1950352473",
      "name": "Manuel Ninaus",
      "affiliations": [
        "University of Graz",
        "University of Tübingen"
      ]
    },
    {
      "id": "https://openalex.org/A2112761320",
      "name": "Stefan E. Huber",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1252427242",
      "name": "Kristian Kiili",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2105248890",
      "name": "Steve Nebel",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2101546085",
      "name": "Richard M. Ryan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2109263912",
      "name": "Michael Sailer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1950352473",
      "name": "Manuel Ninaus",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4376866715",
    "https://openalex.org/W4323350039",
    "https://openalex.org/W2484280006",
    "https://openalex.org/W4365503792",
    "https://openalex.org/W4376111157",
    "https://openalex.org/W4387491382",
    "https://openalex.org/W4322719791",
    "https://openalex.org/W2104071326",
    "https://openalex.org/W2489205528",
    "https://openalex.org/W4249654063",
    "https://openalex.org/W2150932122",
    "https://openalex.org/W3190815597",
    "https://openalex.org/W798773559",
    "https://openalex.org/W2073338313",
    "https://openalex.org/W2037998138",
    "https://openalex.org/W2023718959",
    "https://openalex.org/W2724114227",
    "https://openalex.org/W4364355594",
    "https://openalex.org/W4360620450",
    "https://openalex.org/W4378628090",
    "https://openalex.org/W4315784554",
    "https://openalex.org/W2335306536",
    "https://openalex.org/W2137247190",
    "https://openalex.org/W2280608971",
    "https://openalex.org/W4255172604",
    "https://openalex.org/W4389984066",
    "https://openalex.org/W4389002521",
    "https://openalex.org/W129640393",
    "https://openalex.org/W2063077274",
    "https://openalex.org/W4211007743",
    "https://openalex.org/W2564668751",
    "https://openalex.org/W2075111500",
    "https://openalex.org/W3132066327",
    "https://openalex.org/W4386322180",
    "https://openalex.org/W6835387598",
    "https://openalex.org/W4362513839",
    "https://openalex.org/W4321366933",
    "https://openalex.org/W4229035407",
    "https://openalex.org/W4307688794",
    "https://openalex.org/W4367678106",
    "https://openalex.org/W2124942656",
    "https://openalex.org/W2255937970",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W2127420602",
    "https://openalex.org/W4362584541",
    "https://openalex.org/W4387495024",
    "https://openalex.org/W4362673335",
    "https://openalex.org/W2164682760",
    "https://openalex.org/W4385291101",
    "https://openalex.org/W6793012178",
    "https://openalex.org/W4386867830",
    "https://openalex.org/W2092284648",
    "https://openalex.org/W4319332969",
    "https://openalex.org/W3209444840",
    "https://openalex.org/W2079372873",
    "https://openalex.org/W4388481599",
    "https://openalex.org/W4378771701",
    "https://openalex.org/W2567395843",
    "https://openalex.org/W4293036536",
    "https://openalex.org/W4361019436",
    "https://openalex.org/W4283163023",
    "https://openalex.org/W6838192869",
    "https://openalex.org/W4205309512",
    "https://openalex.org/W2338810375",
    "https://openalex.org/W6630410620",
    "https://openalex.org/W2290217614",
    "https://openalex.org/W4323927170",
    "https://openalex.org/W4321607388",
    "https://openalex.org/W1992038660",
    "https://openalex.org/W2084944215",
    "https://openalex.org/W6729446361",
    "https://openalex.org/W4389554327",
    "https://openalex.org/W4242883546",
    "https://openalex.org/W2902999784",
    "https://openalex.org/W2023062420",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W2097228681",
    "https://openalex.org/W4322008312",
    "https://openalex.org/W4283705032",
    "https://openalex.org/W4361293442",
    "https://openalex.org/W4323539897",
    "https://openalex.org/W2128992388",
    "https://openalex.org/W4200269929",
    "https://openalex.org/W4317390716",
    "https://openalex.org/W4363651325",
    "https://openalex.org/W2043670866",
    "https://openalex.org/W4319083882",
    "https://openalex.org/W2175857708",
    "https://openalex.org/W4367626167",
    "https://openalex.org/W4210702550",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W4386554921",
    "https://openalex.org/W4328049434",
    "https://openalex.org/W4362716521",
    "https://openalex.org/W4233087874",
    "https://openalex.org/W2493946644",
    "https://openalex.org/W611967425",
    "https://openalex.org/W4230086062",
    "https://openalex.org/W3086778309"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)\nEducational Psychology Review (2024) 36:25\nhttps://doi.org/10.1007/s10648-024-09868-z\n1 3\nREFLECTION ON THE FIELD\nLeveraging the Potential of Large Language Models \nin Education Through Playful and Game‑Based Learning\nStefan E. Huber1  · Kristian Kiili2  · Steve Nebel3  · Richard M. Ryan4,5  · \nMichael Sailer6  · Manuel Ninaus1,7 \nAccepted: 9 February 2024 / Published online: 27 February 2024 \n© The Author(s) 2024\nAbstract\nThis perspective piece explores the transformative potential and associated chal-\nlenges of large language models (LLMs) in education and how those challenges \nmight be addressed utilizing playful and game-based learning. While providing \nmany opportunities, the stochastic elements incorporated in how present LLMs pro-\ncess text, requires domain expertise for a critical evaluation and responsible use of \nthe generated output. Yet, due to their low opportunity cost, LLMs in education may \npose some risk of over-reliance, potentially and unintendedly limiting the develop-\nment of such expertise. Education is thus faced with the challenge of preserving \nreliable expertise development while not losing out on emergent opportunities. To \naddress this challenge, we first propose a playful approach focusing on skill prac-\ntice and human judgment. Drawing from game-based learning research, we then go \nbeyond this playful account by reflecting on the potential of well-designed games \nto foster a willingness to practice, and thus nurturing domain-specific expertise. We \nfinally give some perspective on how a new pedagogy of learning with AI might \nutilize LLMs for learning by generating games and gamifying learning materials, \nleveraging the full potential of human-AI interaction in education.\nKeywords Large language models · Generative artificial intelligence · Education · \nPlayful learning · Gamification · Game-based learning\nIntroduction\nLarge language models (LLMs) and their recently increased accessibility via chat-\nbots like ChatGPT (OpenAI, 2023), Bard (Google, 2023), or Bing Chat (Microsoft, \n2023) provide both new opportunities and challenges for education. On the one \nhand, they legitimately promise effective ways to assist with many tasks involved in \nboth teaching and learning (Bernabei et al., 2023; Kohnke et al., 2023), to provide \nscalable, personalized learning material (Abd-alrazaq et  al., 2023; Sallam, 2023), \nExtended author information available on the last page of the article\n Educational Psychology Review (2024) 36:25\n1 325 Page 2 of 20\nand thus easy and scalable opportunities for exercise (Kasneci et al., 2023). On the \nother hand, they come with the educational challenge to avoid becoming overly or \nnaïvely reliant on their support (Abd-alrazaq et al., 2023; Bernabei et al., 2023; Kas-\nneci et al., 2023; Kohnke et al., 2023; Shue et al., 2023; Zhu et al., 2023), and thus \nto prevent inadvertently adopting inherent biases (Abd-alrazaq et al., 2023; Bernabei \net al., 2023; Dwivedi et al., 2023; Kasneci et al., 2023; Zhu et al., 2023) or losing \nout on opportunities for reflection and practice for developing domain expertise and \njudgment competence (Dwivedi et al., 2023; Krügel et al., 2023). These are, how -\never, especially needed for the responsible use of present LLMs, because, due to \ntheir inherent random mechanisms utilized during text generation (Wolfram, 2023), \nmistakes or fabricated information cannot be entirely ruled out. Hence, at least for \nthe time being, the output generated by LLMs definitely requires domain exper -\ntise for critical revision and evaluation. Education thus finds itself currently faced \nwith the challenge to find an appropriate balance between seizing new and welcome \nopportunities and protecting against inadvertent risks of losing out on the develop-\nment of required expertise at the same time.\nIn this perspective piece, we propose that—in a first step—a more exploratory, \nplayful approach towards the use of LLMs may help with finding such an appro-\npriate balance. Such an approach has already been utilized in the form of prompt \nengineering in various domains (Oppenlaender et al., 2023; Polak & Morgan, 2023; \nShort & Short, 2023; Shue et al., 2023; Wang et al., 2023; White et al., 2023; Zhu \net al., 2023). Beyond those accounts, we further suggest that—in a second step—\ngoing the full way to a game-based education could eventually provide a new peda-\ngogy of learning with artificial intelligence (AI) leveraging the full potential within \na well-balanced cooperation between human and machine intelligence. We further \nargue that this second step allows utilization of LLMs for devising appropriate \ngame-based learning environments, such that LLMs may eventually serve to over -\ncome exactly those challenges they pose for education in the first place.\nTo serve a systematic development of our arguments, the article is organized as \nfollows: first, we briefly illustrate both opportunities and challenges posed by the \nusage of LLMs in educational contexts. In a second section, we argue how a more \nplayful approach to the usage of LLMs in education may already help to resolve \nsome of the tension between opportunities, challenges, and risks. In a final section, \nwe outline our proposition how game-based learning can extend the limits of said \nplayful approaches, paving the way for a prolific co-operation between human and \nartificial intelligence in education.\nLLMs in Education—Opportunities and Challenges\nGenerally, LLMs are a recently developed form of AI (i.e., algorithms historically \ndevised to mimic, extend, or replace parts of human cognition or behavior). More \nspecifically, they are a form of generative AI, representing algorithms capable of \ngenerating new media like images or text.\nRecent LLMs (like those provided via ChatGPT) use large datasets of text in con-\njunction with artificial neural networks with billions of parameters to process and \n1 3\nEducational Psychology Review (2024) 36:25 Page 3 of 20 25\ngenerate text. Chat-like interfaces allow the user to obtain human-like responses in \nconversational style upon entering arbitrary prompts. While earlier language models \nlike Wordtune, Paperpal, or Generate (Hutson, 2022) could help writers restructure \na sentence, more recent versions like ChatGPT can help with devising entire manu-\nscripts, providing feedback, finding limitations (Zimmerman, 2023), or devising \nspecialized text like computer code (Shue et al., 2023).\nThe essential core principles have, however, remained similar (Wolfram, 2023): \nthe computation of likely continuations of the user-provided prompt based on identi-\nfied relations between text elements in the vast amount of training data. An impor -\ntant ingredient in the computation is the fact that not always the most likely, but \nsometimes a less likely continuation is chosen. While this serves the impression of \nan especially spontaneous, human-like, fluently emergent text, it also is the reason \nwhy the information provided by present LLMs can be misleading or erroneous and \nthus requires continuous supervision and critical evaluation.\nOpportunities\nGiven their capabilities, LLMs provide a wide range of opportunities for education \n(Kasneci et al., 2023). LLMs can assist with management tasks (e.g., development \nof teaching units, curricula, or personalized study plans), with assessment and eval-\nuation, and with program monitoring and review (Abd-alrazaq et al., 2023). They \ncan take the roles of content providers (Abd-alrazaq et al., 2023; Jeon & Lee, 2023; \nSarsa et al., 2022), temporary interlocutors, teaching assistants, and evaluators (Jeon \n& Lee, 2023). They can assist with writing tasks of both teachers and learners (Ber -\nnabei et al., 2023), regarding not only content creation, but also basic information \nretrieval (Zhu et al., 2023) and literature review (Abd-alrazaq et al., 2023).\nLLMs can further assist teachers in orchestrating a continuously growing plethora \nof teaching resources, making the teachers’ resources (bound to developing and revis-\ning learning material in earlier times) more available for designing creative, well-\norganized, and engaging lessons (Jeon & Lee, 2023). They enable personalized learn-\ning (Abd-alrazaq et al., 2023; Sallam, 2023) and may benefit learners’ understanding \nof topics (Bernabei et al., 2023; Sarsa et al., 2022; Zhu et al., 2023). If used carefully, \nthey can enhance critical thinking and problem-based learning (Bernabei et al., 2023; \nSallam, 2023; Shue et  al., 2023), emphasize the role the role of students as active \ninvestigators, and raise ethical awareness regarding the use of AI (Jeon & Lee, 2023).\nChallenges\nHowever, careful use of LLMs also presents a challenge to both teachers and learn-\ners (Kasneci et al., 2023). This is related to a variety of shortcomings of LLMs that \nhave not yet been entirely resolved. These include the possibility of mistakes or fab-\nricated information; the lack of recent, state-of-the-art, domain knowledge; the lack \nof originality; inherent (social or gender) biases; various ethical and legal issues like \n Educational Psychology Review (2024) 36:25\n1 325 Page 4 of 20\ncopyright, plagiarism, and false citations; lacks of transparency and accountability; \ncybersecurity issues; and the risk of infodemics (Sallam, 2023; Zhu et al., 2023).\nIn contrast to pocket calculators, present LLMs are not designed to yield reliably \nthe same deterministic output upon the same given prompt. A stochastic element \nin generation of such output is a part of how and why they work so astonishingly \nwell in producing seemingly human-like responses (Wolfram, 2023). This, however, \nhas also the consequence that their output definitely requires critical evaluation and \ncareful revision by domain experts (Ali et al., 2023; Biswas, 2023; Hosseini et al., \n2023; Howard et al., 2023; Kasneci et al., 2023; Mogali, 2023; Salvagno et al., 2023; \nVan Dis et al., 2023; Zhu et al., 2023). Especially when it is about decisions that \nshould guide human action, the support provided by LLMs should be supervised by \nhuman expertise (Molenaar, 2021).\nExpertise as a Crucial Factor in Human‑AI Systems\nThis resonates well with the general assertion that the quality of decisions by \nhuman-AI systems depends crucially on the human expertise within such systems \n(Ninaus & Sailer, 2022). However, both the development and preservation of exper-\ntise require practicing domain-specific problem-solving capabilities (Elvira et  al., \n2017; Tynjälä, 2008; Tynjälä et al., 2006).\nAs novices advance from easier to more difficult problems, they continuously engage \nin three learning processes. First, they transform conceptual knowledge into experiential \nknowledge when, for instance, applying general concepts to specific problems in particu-\nlar contexts. Second, they also need to explicate experiential into conceptual knowledge \nto, for instance, make tacit knowledge (Patterson et al., 2010) accessible to other people as \nwell as to metacognitive processes like reflection. Reflecting on experiential and concep-\ntual knowledge finally allows for improving problem-solving strategies, further supports \nthe transfer of tacit to explicable knowledge, and facilitates the development of learning \nstrategies, metacognitive, and self-regulatory skills (Elvira et al., 2017).\nAll three processes have in common that continuous practice in integrating con-\nceptual, experiential, and self-reflective knowledge during problem-solving utilizes \nalready existing expertise and contributes to its further development. Although mod-\nern theories on expertise acknowledge that many factors besides practice contribute \nto expertise development (Hambrick et al., 2016), they do not deny the relevance or \neven necessity of (deliberate) practice (Campitelli & Gobet, 2011; Ericsson et al., \n1993; Hambrick et al., 2014).\nInteraction Between Use of LLMs and Expertise Development\nIn formal education, which lays the foundations for the development of expertise, \npractice sometimes requires that learners engage in effortful or even strenuous tasks. \nThat is, learners need to regulate their attention and efforts toward a task that might \nbe associated with aversive feelings and also to resist engaging in more pleasurable \nactivities (Kurzban et al., 2013; Miller et al., 2012).\n1 3\nEducational Psychology Review (2024) 36:25 Page 5 of 20 25\nHowever, the convenience and low opportunity cost that LLMs bring for certain \ntasks, bears the risk of over-reliance (Kasneci et  al., 2023) or over-trust (Morris \net  al., 2023), which has also been recognized as a hindrance for critical thinking \n(Shue et al., 2023), learning, and reflection (Zhu et al., 2023). In addition to that, \nlearners (and sometimes also teachers) can feel tempted by the authoritative nature \nof the responses to take them at face value without critically evaluating and process-\ning them further (Kohnke et al., 2023). Lastly, learners can be tempted to outsource \nthe activity. While such outsourcing might be appropriate for tasks that are merely \nmeans to an end, it becomes problematic when tasks represent essential learning \nopportunities for skills that a person should have even without AI support (Salomon \net al., 1991). Over-reliance on LLMs in educational contexts is thus associated with \nsome risk of losing out on essential ingredients for the development and preserva-\ntion of expertise, potentially and inadvertently providing also a risk of deskilling \n(Morris et al., 2023), and consequentially of automation bias, reduced human auton-\nomy and judgment competence (Dwivedi et al., 2023; Deutscher Ethikrat, 2023).\nIt is important, however, to note that an eventual shift in what is considered an \nessential skill is not problematic per se. As with every new useful tool, LLMs also \nbring about a shift in what is considered essential expertise. While in earlier times, \ndoing a statistical analysis might have involved manually integrating a normal curve \nto determine a p-value, this would hardly suggest that a social scientist not know -\ning anymore how to do this has not developed any statistical expertise (we thank \nthe anonymous reviewer for providing this example). The advent of the digital com-\nputer has changed the outline of the skill set determining the meaning of statistical \nexpertise.\nOngoing developments of generative AI technology like retrieval augmented gen-\neration, improving on both factual reliability and timeliness of responses provided \nby LLMs (Gao et al., 2023), are likely to push the boundaries of what kind of exper-\ntise may be called essential even further. The critical point remains that high-quality \ndecisions of human-AI systems presuppose some human expertise (Ninaus & Sailer, \n2022). And it is difficult to judge in advance which skill sets will remain essential in \nthe future. As Dwivedi et al. (2023) note, we as educators must ask ourselves first: \nwhich skills are still needed? Once these are identified, a second question remains: \nhow can we devise new, appropriate ways of developing and practicing these skills \nin a new pedagogy of learning with AI?\nBanning LLMs?\nOne response addressing this challenge are calls for more closely regulating the \nuse of LLMs, ranging from simply requiring disclosure (Stokel-Walker, 2023) over \nadaption of examination procedures (Dwivedi et al., 2023) to complete bans (John-\nson, 2023; Rosenzweig-Ziff, 2023). Yet attempts at external control face at least one \nvery pragmatic issue: It can be difficult, if possible at all, to distinguish between \nhuman- and AI-produced material (Ariyaratne et al., 2023; Dunn et al., 2023; Else, \n2023). Although tools are developed that allow (at least temporarily) AI-support \ndetection to some extent (Bernabei et  al., 2023; Else, 2023), we also think that \n Educational Psychology Review (2024) 36:25\n1 325 Page 6 of 20\nresearch and higher education needs to devise ways to use LLMs ethically, transpar-\nently, and responsibly (Van Dis et al., 2023). Furthermore, “it makes no sense to ban \nthe technology for students that will live in a world where this technology will play a \nmajor role” (Dwivedi et al., 2023, p. 9).\nA completely different response to the outlined challenge originates long before \nthe most recent advent of AI in the form of LLMs. It involves a more playful stance \ntowards the new possibilities that come with new technology.\nOn Playful Approaches to Integrate New Technology in Education\nAs early as in the 1960s, Papert (1980) developed a pedagogical approach which \nallowed to utilize computers to facilitate children’s understanding of geometry. \nHowever, instead of thinking of ways to use computers just as providers of more \nsophisticated, digital teaching or learning material, children were enabled to build \nup their geometrical understanding by providing them with a tool to let comput-\ners do something meaningful to them. For this purpose, the programing language \nLogo was developed (Papert, 1980) which allowed children to control the movement \nof a virtual turtle which left behind lines as it moved over the screen. By under -\nstanding how to draw geometrical shapes by controlling the turtle, and further, how \nsimple geometrical shapes constitute more complex images, a gradually improving \nunderstanding of geometry allowed the children to draw more beautiful and complex \nimages. Playful experimentation with the Logo language allowed to build up experi-\nential knowledge by applying basic, conceptual knowledge of how to draw squares, \ntriangles, and so forth. At the same time, purposeful drawing of more complex, \ncomposite objects (like a house with a door, windows, and a roof) required trans-\nlating experiential knowledge into conceptual knowledge by the necessity to pro-\nvide specific commands. Learning by purposive doing and by engaging in discovery \nvia the natural processes of trial and error would further provide ample opportunity \nto reflect on both, experiential and conceptual knowledge to further improve draw -\ning capabilities and thus, understanding geometry. Papert’s pedagogical approach \n(1980), hence, naturally nurtured all three learning processes involved in devel-\noping expertise (Elvira et al., 2017; Tynjälä, 2008; Tynjälä et al., 2006). Not only \nbecame children able to produce images and experiences of meaning for themselves, \nbut they did so just inasmuch as they improved in their geometrical understanding, \nprograming capabilities, and computational thinking. Furthermore, new technology, \ni.e., the digital computer, which could have just been programmed to do the same \ngeometrical operations much more efficiently, was instead utilized to promote edu-\ncation (Papert, 1980).\nYet, why did Papert come up with his playful, constructionist approach to learn-\ning in the first place? In fact, he was inspired by constructivist theory of how chil-\ndren construct new schemas by interacting with their environment (Piaget, 1962). In \nPiaget’s theory of cognitive development (1962), play facilitates children’s cogni-\ntive development by activating basic units for organizing knowledge and behavior, \nknown as schemas. Play allows both the practice of existing schemas, and thus of \n1 3\nEducational Psychology Review (2024) 36:25 Page 7 of 20 25\nexisting skills and knowledge, and the development of new ones by combining ele-\nments of existing ones in ways that transcend existing knowledge.\nSocial development theory (Vygotsky, 1967), scrutinizing also the developmental \nimportance of play, adds the notion that the crucial point of play for learning is its \ncapability to provide children with opportunities to explore outcomes beyond their \ncurrent abilities. Play allows players to experience and simulate potential outcomes \nwithout the real-life costs (Homer et al., 2020). It allows to probe their capabilities, \nand by that, it allows them to grow beyond their current limitations. Although high-\nlighting somewhat different aspects, both theories of play highlight their potential \nfor facilitating learning and development.\nMore recently, research within self-determination theory (SDT; Ryan & Deci, \n2017) has specifically highlighted the importance of intrinsic motivation, the enjoy -\nment of the activity itself, as critical to learning across development (Reeve, 2023). \nThat is, much if not most of human learning (both within and outside formal edu-\ncation) occurs because of our interest and curiosity in activities, from which we \nacquire knowledge and skills. Research in SDT suggests that sustained playful learn-\ning involves experiencing a sense of autonomy and competence, which are often \nrichly afforded within game environments (Rigby & Ryan, 2011).\nCarefully applying these concepts to the challenge posed by LLMs for expertise \ndevelopment may turn the outlined risks into promising learning opportunities. The \nidea is the same as the one exemplified by Papert’s approach (1980) to utilize com-\nputers as educational tools. Instead of seeing LLMs as possibilities to outsource task \naccomplishment, they are understood as tools that can be utilized to engage in a \nmeaningful activity. The interface, which has been the Logo language in Papert’s \ncase (1980), now is, for instance, ChatGPT, allowing to provide prompts that steer \nthe underlying LLM in the desired direction. In this case, the meaningful product, \nis not necessarily an image, but can be a manuscript, some computer code, or any \npiece of text. The specific expertise required to be acquired to make LLMs work in \nsuch a useful way has become known as prompt engineering.\nPrompt Engineering as a Form of Playful Interaction with LLMs\nPrompt engineering generally refers to the iterative process in which users fine-tune \ntheir textual inputs to achieve a desired output from the LLM (Meskó, 2023). It has \nbeen recognized as an essential competence within future digital literacy (Eager \n& Brunton, 2023; Korzynski et  al., 2023), eventually enabling to fully harness \nLLMs’ potential to provide personalized learning, unlimited practice opportunities, \nand interactive engagement with immediate feedback (Heston & Khun, 2023). It \nhas been successfully applied in diverse domains including software development \n(White et  al., 2023), entrepreneurship (Short & Short, 2023), art (Oppenlaender \net al., 2023), science (Polak & Morgan, 2023), and healthcare (Wang et al., 2023).\nPrompt engineering may involve role play or persona modeling (letting the LLM \nadopt a specific role such as a domain expert in a certain field; Short & Short, 2023), \ntext format, style or tone (Zhu et al., 2023), length and (coding) language restric-\ntions (Shue et  al., 2023), question refinement or alternative approaches requests, \n Educational Psychology Review (2024) 36:25\n1 325 Page 8 of 20\nflipped interaction patterns (e.g., requesting questions rather than elaboration from \nthe LLM; White et al., 2023), chain-of-thought-prompting (generating intermediate \noutputs; e.g., “Take a deep breath and work on this problem step-by-step”; Yang \net al., 2023), or emotional prompting (e.g., “This is very important for my career”; \nLi et al., 2023) among many more possible techniques. Noteworthy, identified func-\ntional prompt patterns have been found to be generalizable over many different \ndomains (White et al., 2023).\nAlthough optimizing prompts has been shown to be capable of vastly improv -\ning the accuracy of outputs generated by LLMs (Li et al., 2023; Yang et al., 2023), \nthe fact remains that the critical evaluation of resulting outputs still requires domain \nexpertise. Critically reviewing the resulting output is just as important as optimizing \nthe prompts (Shue et al., 2023).\nPrompt engineering itself can actually be regarded as an expert skill requiring \nnot only expertise within the domain (for the selection of appropriate keywords \nand prompt content) but also of prompt modifiers and the training data and system \nconfiguration settings of the specific LLMs (Oppenlaender et al., 2023). Becoming \nproficient in prompt engineering thus has an analogous meaning for a user of an \nLLM as becoming proficient in the Logo language for Papert’s (1980) students. It \nnot only allows one to make use of LLMs efficiently, but in order for it to work, i.e., \nto result in reliable and useful output, it entails practicing exactly that domain exper-\ntise which it presupposes. Given the necessary expertise, prompt engineering can \nthus become a form of playful interaction with LLMs, exploring various aspects of \na topic by varying prompt patterns and techniques. Under those circumstances, the \ndomain expert’s intrinsic interest in the reliability and usefulness of results produced \nin cooperation with LLMs might provide some protection from over-reliance on a \nsingle output and associated risks of more narrowly directed LLM employments.\nHowever, such risks might be more severe for learners who are not yet domain \nexperts but are presently on their way to developing such expertise. Their primary \ngoals may be less intrinsically motivated but eventually correspond rather to the \nmere accomplishment of educational tasks like the submission of seminar papers, \nhomework, or sample calculations. In light of the especially low opportunity costs \nof LLMs, supporting a playful approach for working with them also under those cir-\ncumstances may require more than to appeal to individual integrity and virtue. Such \nsupport, however, may then be accomplished by providing a learning environment in \nwhich playing becomes a natural form of activity (Plass et al., 2020) and a designed \npathway to learning. That means, such support may be provided by a pedagogy of \nlearning based on games.\nGame‑Based Learning as a Way to Harness the Full Potential \nof Human‑AI Interaction in Education\nGames, in both non-digital and digital forms, have repeatedly proven valuable for \nlearning, training, and education (Dillon et al., 2017; Pahor et al., 2022; Pasqualotto \net al., 2022). They provide space for playful learning experiences, allow room for \nexperimentation, and provide safe spaces for graceful failure, a crucial component \n1 3\nEducational Psychology Review (2024) 36:25 Page 9 of 20 25\nfor learning with games, allowing the players to learn from mistakes and motivating \nthem to practice until feeling confident (Plass et al., 2015).\nDue to their capabilities in capturing and holding people’s attention and in fos-\ntering sustained engagement and long-term loyalties, games have further become \nrole models for engaging learners (Rigby, 2014) and citizens to solve complex sci-\nentific problems (Cooper et al., 2010; Spiers et al., 2023). Well-designed games can \nindeed promote both the required persistence in activities for practice and high qual-\nity of engagement that can foster deep human learning and problem solving (Barz \net al., 2023; Hu et al., 2022; Ryan & Rigby, 2020). The extension of SDT (Ryan & \nDeci, 2000, 2017) based on research on video games (Ryan et al., 2006), technology \ndesign (Calvo & Peters, 2014), or digital learning (Sørebø et al., 2009) has shown in \nwhich ways psychological satisfactions for autonomy, competence, and relatedness \ncan be evoked or undermined and thus affect players’ intrinsic motivation and sus-\ntained engagement (Ryan & Rigby, 2020). In games, a complex set of skills is chal-\nlenged in a constrained environment in which those skills can be explored, analyzed, \nmanipulated, extended (Ryan & Rigby, 2020), or in other words: practiced. Thereby, \nample opportunities allow experiences of autonomy, competence, and relatedness \nfuelling intrinsic motivation. “In a well-designed game, the learning becomes its \nown reward” (Ryan & Rigby, 2020, p. 169).\nThe problem-based gaming model (Kiili, 2007) further emphasizes the meaning \nof experiential learning and reflection in educational games. It is argued that the \nability to reflect may be the main factor determining who learns effectively from \nexperience (Kiili, 2007). This is especially true for games that require problem-solv-\ning (e.g., simulation games). In the model, the level of reflection concerns whether \nthe player considers the consequences of their actions and the changes in the game \nworld to create better playing strategies (double-loop learning) or merely applies the \npreviously formed playing strategy (single-loop learning). Games that trigger dou-\nble-loop learning are effective because they persuade players to test different kinds \nof hypotheses and consider the learning content deeply from several perspectives. \nThe challenge of educational game design is to design game mechanics that trigger \nsuch meaningful reflection practices.\nGames as a Culture Medium for the Development of Expertise\nGames naturally serve all three learning processes facilitating the development \nof expertise. By providing ample space for playful engagement, they support the \ntransformation of experiential into conceptual knowledge. By being—in contrast \nto free-form play—yet structured by explicit rule sets and specific goals (Deterding \net al., 2011), they also require and thus facilitate the transformation of conceptual \ninto experiential knowledge. Finally, as outlined above, they invite diverse forms of \nreflection serving the further development of problem-solving strategies as well as \nmetacognitive and self-regulatory skills.\nThe capabilities of games to invite reflection are further emphasized by the fact \nthat successful games have repeatedly been identified as sources of spontaneously \nemergent culture. Affinity groups (Gee, 2005) may emerge (online or offline) in \n Educational Psychology Review (2024) 36:25\n1 325 Page 10 of 20\nwhich players meet to communicate, reflect, and influence game rules, extend new \ngame content, and contribute to game development (Brown, 2016), engage in theo-\nrycrafting (Choontanom & Nardi, 2012) and peer-to-peer apprenticeship (Steinkue-\nhler & Oh, 2012). Both the explication of experiential knowledge into conceptual \nknowledge and reflecting on both knowledge types happen naturally in such sponta-\nneously forming collaborative spaces.\nThe emergence of those spaces is not induced by top-down mechanisms (e.g., \nby game developers) but happens horizontally within the game community (Steink -\nuehler & Tsaasan, 2020). For instance, in the Just Press Play project (Decker & \nLawley, 2013), investigating the effect of gamification on undergraduate experience \nin computer science, students spontaneously requested access to computer labs for \ntutoring other students for free, on their own time and out of their own desire. In \naddition, a lively community of educators emerged, constantly creating new learn-\ning environments and trying to include the game in the class room against all tech-\nnical and bureaucratic odds. After the release of Minecraft, communities emerged, \nmodifying the game and creating content way beyond the games’ original intended \nmeaning and functionalities (Nebel et al., 2016). Users—and mostly pupils—used \nthe games’ mechanics to create functioning CPUs, landscapes of their favorite books \nor sustainable environments, all in their free time. Those are both unforeseen and \nastonishing results. Not only provide they examples of what the notion of “learning \noutcomes” in game-based learning can actually encompass: the spontaneous emer -\ngence of teachers or experts from a community of students or novices (Steinkuehler \n& Tsaasan, 2020). They also provide examples of what potential game-based learn-\ning might bear for education.\nFurthermore, they provide examples of how games can foster spontaneous pro-\nfound engagement with the learning material far beyond a mere accomplishment of \ntasks. When within well-designed games, in which the basic needs of autonomy, \ncompetence, and relatedness are met, learning becomes its own reward (Ryan & \nRigby, 2020), the option to outsource cognitive efforts to LLMs becomes less tempt-\ning. Instead, well-designed games might even foster the motivation to utilize LLMs \nfor engaging deeper with the content and finding out more. That means, game envi-\nronments might provide novices with a flavor of that kind of intrinsic interest that \nmay protect domain experts from over-reliance and associated risks.\nYet Where Are All the Educational Games?\nHowever, if games hold such an educational potential, the question needs to be \naddressed: Why have they not become much more abundant in schools and univer -\nsities? One simple reason is that making good games, i.e., games that satisfy basic \npsychological needs (Ryan & Rigby, 2020), is tough. Even established developers in \nthe entertainment game industry, i.e., in the business of manufacturing fun, repeat-\nedly fail to deliver and are regularly hit with closures and layoffs (Hodent, 2018), \nwhereas some of the most successful games started as low-budget side projects. \nEducational games face many additional challenges.\n1 3\nEducational Psychology Review (2024) 36:25 Page 11 of 20 25\nOn a socio-cultural dimension (Fernández-Manjón et al., 2015), an issue is social \nrejection of games, which may be reduced by improving society’s understanding of \ngames as another form of cultural good, and informing stakeholders (students, edu-\ncators, and parents) about the social potential and positive effects of video games \n(Granic et al., 2014) and their usefulness in education (Bourgonjon et al., 2010). At \nthe same time, violence, sexism, and discrimination are advised to be avoided in the \ndesign of educational games (Fernández-Manjón et al., 2015).\nAlong an educational dimension, limited accessibility to educational games can \nprevent their further adoption in education (Fernández-Manjón et al., 2015). Whereas \ncreating and maintaining user manuals and best practice guides are ways to facilitate \naccessibility (Fernández-Manjón et al., 2015), both require further structural support. \nThe latter can be provided by simultaneous support and creation of communities of \npractice (Wenger, 1998) allowing participation in development processes (Moreno-\nGer et al., 2008) and knowledge production and transfer between educators, develop-\ners, and researchers (Fernández-Manjón et al., 2015; Hébert et al., 2021).\nAlong a technological dimension, limited accessibility to technology is an issue \n(Hébert et al., 2021). Lowering development costs and developing environments that \nallow educators some game development without requiring substantial program-\nming skills and specific game development expertise are regarded as necessary steps \nto address this issue (Fernández-Manjón et al., 2015).\nLLMs as an Opportunity for Harnessing the Potential of Games Within Education\nIn this context, LLMs or more generally generative AI tools have the potential to \ntransform game-based learning practices and—again similarly to the use of comput-\ners in Papert’s class (1980)—could even become once more part of their own rem-\nedy regarding the challenge they pose for education. This, however, warrants a new \npedagogy of learning with artificial intelligence.\nIn particular, we identified two use scenarios in which generative AI tools can \nboost the use of games in educational settings. First, generative AI tools provide new \nways to implement making games for learning approaches (Kafai & Burke, 2015), in \nwhich students learn educational content by designing and making games. Second, \nteachers and educators can utilize AI tools to gamify their learning materials or even \ncreate fully-fledged learning games for their students. In the following, we consider \nhow LLMs can be utilized in these scenarios.\nLearning by Generating Games\nMaking games for learning is another prime example of a constructionist learning \nactivity (Kafai & Burke, 2015) similar to Papert’s (1980) early use of computers in \nthe classroom discussed above. Kafai and Burke (2015) argue that we are witnessing \na paradigmatic shift toward constructionist gaming, in which students design games \nfor learning instead of just consuming games created by professional developers.\n Educational Psychology Review (2024) 36:25\n1 325 Page 12 of 20\nWe believe that generative AI tools will further accelerate this shift. LLMs have \nthe potential to make game creation more accessible for novices in a similar way as \nblock-based visual programming environments like Scratch (Resnick et  al., 2009) \nlowered the demands to program interactive stories and animations in educational \nsettings. The pedagogical idea behind learning by generating games relies mostly \non the assumption that game-making activities help students reformulate their \nunderstanding of the subject matter (educational content) and express their personal \nunderstanding and ideas about the subject (Kafai, 2006). In addition, generating \ngames using AI’s technical backup can be open and creative, allowing for experi-\nences of autonomy and competence essential to sustained interest and intrinsic moti-\nvation (Ryan & Rigby, 2020). As the technicalities of programming can be largely \noutsourced to LLMs, students can focus more on the topic and game design aspects.\nA recent study indicates that game-designing activities can be even more benefi-\ncial, especially for the long-term retention of knowledge, than learning by playing \ngames (Chen & Liu, 2023). Furthermore, Resnick et  al., (2009) have emphasized \nthat digital fluency requires more than just interacting with media; it requires an \nability to collaboratively design, create, and invent with media. Similar abilities are \nneeded when creating games with the help of LLMs and seem now more important \nthan ever. However, making games with LLMs also imposes unique requirements \nfor students as well as for teachers who are orchestrating the game-making activities.\nWe coined the term prompting pedagogy to capture fundamental pedagogi-\ncal practices involved in generating games or other digital outputs with the help of \nLLMs going beyond prompt engineering as discussed above and constituting one \naspect of a new pedagogy of learning with AI. While prompt engineering will be a \ncrucial competence for harnessing the potential of AI in education (Eager & Brun-\nton, 2023), we also want to emphasize that the ability to critically evaluate gener -\nated outputs and its facilitation by existing (domain) expertise are equally important \n(Dwivedi et al., 2023; Krügel et al., 2023). This critical evaluation informs the craft-\ning of prompts leading to meaningful and constructive dialogue with LLMs. Such \ncumulative and continuous dialog is crucial when using LLMs in complex tasks \nlike game-making. Moreover, using LLMs in such a reflective and critical manner \nenhances critical thinking and problem-based learning (Bernabei et al., 2023; Sal-\nlam, 2023; Shue et al., 2023).\nIt is evident that effective prompting is challenging, and students need support \nto develop adequate prompting skills to generate games with LLMs. Prompting \npedagogy for game-making also involves the preparation of support materials (e.g., \nprompting templates for different purposes) and sequencing the prompting activities \nto specific phases (e.g., idea generation, core design, prototyping, and assessment).\nEven though the use of LLMs plays a crucial role in the suggested learning by \ngenerating games approach, the design and production activities need to be inte-\ngrated into a meaningful teaching process. For example, the creative thinking \nspiral process (imagine, create, play, share, reflect, imagine, and so forth) can be \nadapted to the learning by generating games approach (Resnick, 2009). According \nto Resnick (2009, p. 1), in this process, “people imagine what they want to do, cre-\nate a project based on their ideas, play with their creations, share their ideas and \ncreations with others, and reflect on their experiences—all of which leads them to \n1 3\nEducational Psychology Review (2024) 36:25 Page 13 of 20 25\nimagine new ideas and new projects.” This thus provides a way to emphasize play -\ntesting with peers (sharing and testing game prototypes and games) as well as reflec-\ntive discussion sessions about prompting and game design strategies in LLMs-based \ngame-making projects.\nOverall, learning by generating games promotes a creative, experimental, playful, \nand inclusive learning culture that aims to support the learning of academic content \nwhile preparing students for utilizing generative AI tools effectively and creatively \nin different contexts. As teachers have a significant role in this approach, a starting \npoint for them may be to generate at least one learning game with an LLM before \napplying the learning approach in their teaching. Such first-hand experience can \nfacilitate perceiving the affordances that LLMs provide, preparing support materials \nfor students, and planning the workflow of activities.\nThe use of generative AI for developing learning games may also help to decrease \nthe barriers to the creation of low-budget game productions and educational games. \nOne problem with educational games is that we have become more and more accus-\ntomed to big-budget releases. Many educational games seem degraded by compari-\nson (e.g., poor graphics and mechanics) and are thus perceived as boring or unap-\npealing. A reasonable utilization of LLMs for game development could eventually \nhelp to close this gap. Moreover, since the activities are learner generated, they may \nwell engender a different kind of interest and sense of ownership than studio pro-\nduced educational outputs.\nGamifying Learning Materials\nGenerative AI provides many low-threshold possibilities for educators to gamify \ntheir teaching or to generate learning games for teaching. That is, LLMs and gen-\nerative AI might establish themselves as a useful tool for developing (educational) \ngames, for instance, by supporting the generation of artwork, code, or game levels \n(Nasir & Togelius, 2023; Todd et al., 2023). LLMs can further assist educators in \nthe analysis, design, evaluation, and development phases of game creation projects, \nallowing, for instance, the adaption of popular board games such as Monopoly for \nspecific learning purposes (Gatti Junior et al., 2023).\nIt may eventually not matter whether the game makers are students or educators; \nthe generation of games with LLMs requires a playful, experimental, and iterative \nstyle of engagement in which game makers continually reassess their goals, explore \nnew solutions, and imagine new possibilities based on the generated outputs and \ndialogue with LLMs. Resnick and Rosenbaum (Resnick & Rosenbaum, 2013) called \nsuch a bottom-up approach “tinkering.” As highlighted above, one of the key skills \nof the successful generation of games with LLMs is prompting and critical evalua-\ntion of generated outputs, which requires expertise such tinkering might enhance.\nAs game development is usually a highly interdisciplinary process requiring \nexpertise in various areas, LLMs might be used to complement individuals’ skills \nin a particular area. For instance, it might allow an educator with expertise in \nthe pedagogical approach for a given problem and an idea for the game design \nto implement a working prototype of an educational game, which would have \nbeen significantly more difficult for the educator without using generative AI \n Educational Psychology Review (2024) 36:25\n1 325 Page 14 of 20\ntechnologies. Furthermore, as game design is a very complex activity, it is impor -\ntant to break complex prompts into a series of small, specific steps and phases, \nstarting from the idea generation and identification of instructional approaches \nand core game mechanics. For example, chain-of-thought prompting (generating \nintermediate outputs) or role prompting (giving the LLM, e.g., the specific role of \nan instructional designer or target group player) can increase the model’s contex-\ntual tenability and enhance the quality of outputs.\nConclusions and General Remarks\nOn balance, implementing insights from game-based learning in educational con-\ntexts is far from a straightforward task. However, game-based learning research \nhas revealed that well-designed games indeed address, challenge, and promote \nplayers holistically, incorporating all cognitive (Mayer, 2020), affective (Loderer \net al., 2020), motivational (Ryan & Rigby, 2020), and sociocultural (Steinkuehler \n& Tsaasan, 2020) aspects of the human condition. Applications of game-based \nlearning in science, technology, engineering, and mathematics (Klopfer & Thomp-\nson, 2020), or the development of educational games for critical thinking (Butcher \net  al., 2017) or social problem-solving (Ang et  al., 2017) indicate at least the \npotential games may have for fostering deep engagement with the learning mate-\nrial and continuous practice of expertise. Utilizing LLMs for learning by generat-\ning games and purposefully gamifying learning materials may allow educators to \nfully harness the potential of games toward a new pedagogy of learning with AI.\nThe potential of playful and game-based learning we see for education is \nstrongly related to games’ motivational and engaging power, that “in play, the aim \nis play itself” (Flanagan, 2009). Even if the activities associated with the playful \nengagement encountered in games could be delegated to AI support, who would \nwant this—because in this context, it would be outsourcing the fun and intrinsic \nsatisfactions of play. That would be like delegating joy to a robot. Even if we \ncould, why should we want that?\nThe notion of (good) practice has since Aristotle (2020) involved the aspect of \nbearing its meaning in itself, a quality which practice has, according to Rousseau \nand Schiller (Greipl et al., 2020), in common with play. It seems as if the advent \nof AI challenges us as educators to remember and revive research and its teach-\ning, as such practice calls for the creation and cultivation of playful spaces within \neducation. While this perspective is certainly not about advocating that we rede-\nsign each class into a game promising enjoyment or entertainment, we think that \ngame-based learning could be especially valuable in taking advantage of the edu-\ncational capabilities of AI, which themselves require capable human partnership.\nFunding Open access funding provided by University of Graz. The authors acknowledge the financial \nsupport of the University of Graz. Kristian Kiili was supported by the Strategic Research Council (SRC) \nestablished within the Research Council of Finland [Grants: 335625, 358250].\n1 3\nEducational Psychology Review (2024) 36:25 Page 15 of 20 25\nData Availability Not applicable to this article as no datasets were generated or analysed during the cur -\nrent study.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, \nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, provide a link to the Creative \nCommons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permis-\nsion directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/.\nReferences\nAbd-alrazaq, A., AlSaad, R., Alhuwail, D., Ahmed, A., Healy, P. M., Latifi, S., Aziz, S., Damseh, R., \nAlabed Alrazak, S., & Sheikh, J. (2023). Large language models in medical education: Oppor -\ntunities, challenges, and future directions. JMIR Medical Education, 9, e48291. https:// doi. org/ \n10. 2196/ 48291\nAli, S. R., Dobbs, T. D., Hutchings, H. A., & Whitaker, I. S. (2023). Using ChatGPT to write patient \nclinic letters. The Lancet Digital Health, 5(4), e179–e181. https:// doi. org/ 10. 1016/ S2589- \n7500(23) 00048-1\nAng, R. P., Tan, J. L., Goh, D. H., Huan, V. S., Ooi, Y. P., & Boon, J. S. T. (2017). A game-based \napproach to teaching social problem-solving skills. In R. Z. Zheng & M. K. Gardner (Eds.), \nHandbook of research on serious games for educational applications (pp. 115–148). IGI \nGlobal.\nAristotle. (2020). The Nicomachean Ethics (A. Beresford, Trans.). Penguin Classics. (Original work pub-\nlished ca. 350 B.C.E.).\nAriyaratne, S., Iyengar, K. P., Nischal, N., ChittiBabu, N., & Botchu, R. (2023). A comparison of Chat-\nGPT-generated articles with human-written articles. Skeletal Radiology. https:// doi. org/ 10. 1007/ \ns00256- 023- 04340-5\nBarz, N., Benick, M., Dörrenbächer-Ulrich, L., & Perels, F. (2023). The effect of digital game-based \nlearning interventions on cognitive, metacognitive, and affective-motivational learning outcomes \nin school: A meta-analysis. Review of Educational Research, 003465432311677. https:// doi. org/ 10. \n3102/ 00346 54323 11677 95\nBernabei, M., Colabianchi, S., Falegnami, A., & Costantino, F. (2023). Students’ use of large language \nmodels in engineering education: A case study on technology acceptance, perceptions, efficacy, \nand detection chances. Computers and Education: Artificial Intelligence, 5, 100172. https:// doi. org/ \n10. 1016/j. caeai. 2023. 100172\nBiswas, S. S. (2023). Potential use of Chat GPT in global warming. Annals of Biomedical Engineering. \nhttps:// doi. org/ 10. 1007/ s10439- 023- 03171-8\nBourgonjon, J., Valcke, M., Soetaert, R., & Schellens, T. (2010). Students’ perceptions about the use of \nvideo games in the classroom. Computers and Education, 54(4), 1145–1156. https:// doi. org/ 10. \n1016/j. compe du. 2009. 10. 022\nBrown, J. K. (2016). To literacy and beyond: The poetics of Disney Infinity 3.0 as facilitators of new lit-\neracy practices (Master’s thesis). University of California, Irvine.\nButcher, K. R., Runburg, M., & Altizer, R. (2017). Dino Lab: Designing and developing an educational \ngame for critical thinking. In R. Z. Zheng & M. K. Gardner (Eds.), Handbook of research on seri-\nous games for educational applications (pp. 115–148). IGI Global.\nCalvo, R. A., & Peters, D. (2014). Positive computing: Technology for wellbeing and human potential. \nMIT Press.\nCampitelli, G., & Gobet, F. (2011). Deliberate practice: Necessary but not sufficient. Current Directions \nin Psychological Science, 20(5), 280–285. https:// doi. org/ 10. 1177/ 09637 21411 421922\nChen, S., & Liu, Y.-T. (2023). Learning by designing or learning by playing? A comparative study of \nthe effects of game-based learning on learning motivation and on short-term and long-term \n Educational Psychology Review (2024) 36:25\n1 325 Page 16 of 20\nconversational gains. Interactive Learning Environments, 31(7), 4309–4323. https:// doi. org/ 10. \n1080/ 10494 820. 2021. 19611 59\nChoontanom, T., & Nardi, B. (2012). Theorycrafting: The art and science of using numbers to interpret \nthe world. In C. Steinkuehler, K. Squire, & S. Barab (Eds.), Games, Learning, and Society (1st ed., \npp. 185–209). Cambridge University Press. https:// doi. org/ 10. 1017/ CBO97 81139 031127. 017\nCooper, S., Khatib, F., Treuille, A., Barbero, J., Lee, J., Beenen, M., Leaver-Fay, A., Baker, D., Popović, \nZ., & Players, F. (2010). Predicting protein structures with a multiplayer online game. Nature, \n466(7307), 756–760. https:// doi. org/ 10. 1038/ natur e09304\nDecker, A., & Lawley, E. L. (2013). Life’s a game and the game of life: How making a game out of it can \nchange student behavior. Proceeding of the 44th ACM Technical Symposium on Computer Science \nEducation, 233–238. https:// doi. org/ 10. 1145/ 24451 96. 24452 69\nDeterding, S., Dixon, D., Khaled, R., & Nacke, L. (2011). From game design elements to gamefulness: \nDefining “gamification.” Proceedings of the 15th International Academic MindTrek Conference: \nEnvisioning Future Media Environments, 9–15. https:// doi. org/ 10. 1145/ 21810 37. 21810 40\nDeutscher Ethikrat. (2023). Mensch und Maschine – Herausforderungen durch Künstliche Intelligenz. \nStellungnahme. Deutscher Ethikrat. https:// www. ethik rat. org/ themen/ aktue lle- ethik ratth emen/ \nmensch- und- masch ine/. Accessed 4 May 2023.\nDillon, M. R., Kannan, H., Dean, J. T., Spelke, E. S., & Duflo, E. (2017). Cognitive science in the \nfield: A preschool intervention durably enhances intuitive but not formal mathematics. Science,  \n357(6346), 47–55. https:// doi. org/ 10. 1126/ scien ce. aal47 24\nDunn, C., Hunter, J., Steffes, W., Whitney, Z., Foss, M., Mammino, J., Leavitt, A., Hawkins, S. D., \nDane, A., Yungmann, M., & Nathoo, R. (2023). Artificial intelligence–derived dermatology \ncase reports are indistinguishable from those written by humans: A single-blinded observer \nstudy. Journal of the American Academy of Dermatology, S019096222300587X. https:// doi.  \norg/ 10. 1016/j. jaad. 2023. 04. 005\nDwivedi, Y. K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., Baabdullah, A. M., \nKoohang, A., Raghavan, V., Ahuja, M., Albanna, H., Albashrawi, M. A., Al-Busaidi, A. S., \nBalakrishnan, J., Barlette, Y., Basu, S., Bose, I., Brooks, L., Buhalis, D., … Wright, R. (2023). \nOpinion paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportuni-\nties, challenges and implications of generative conversational AI for research, practice and pol-\nicy. International Journal of Information Management, 71, 102642. https:// doi. org/ 10. 1016/j. \nijinf omgt. 2023. 102642\nEager, B., & Brunton, R. (2023). Prompting higher education towards AI-augmented teaching and \nlearning practice. Journal of University Teaching and Learning Practice, 20(5). https:// doi. org/ \n10. 53761/1. 20.5. 02\nElse, H. (2023). Abstracts written by ChatGPT fool scientists. Nature, 613(7944), 423–423. https://  \ndoi. org/ 10. 1038/ d41586- 023- 00056-7\nElvira, Q., Imants, J., Dankbaar, B., & Segers, M. (2017). Designing education for professional exper -\ntise development. Scandinavian Journal of Educational Research, 61(2), 187–204. https:// doi.  \norg/ 10. 1080/ 00313 831. 2015. 11197 29\nEricsson, K. A., Krampe, R. T., & Tesch-Römer, C. (1993). The role of deliberate practice in the \nacquisition of expert performance. Psychological Review, 100(3), 363–406. https:// doi. org/ 10. \n1037/ 0033- 295X. 100.3. 363\nFernández-Manjón, B., Moreno-Ger, P., Martinez-Ortiz, I., & Freire, M. (2015). Challenges of serious \ngames. EAI Endorsed Transactions on Game-Based Learning, 2(6), 150611. https:// doi. org/ 10. \n4108/ eai.5- 11- 2015. 150611\nFlanagan, M. (2009). Critical play: Radical game design. MIT Press.\nGao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J., Guo, Q., Wang, M., & Wang, H. \n(2023). Retrieval-augmented generation for large language models: A survey. https:// doi. org/ \n10. 48550/ ARXIV. 2312. 10997\nGatti Junior, W., Marasco, E., Kim, B., Behjat, L., & Eggermont, M. (2023). How ChatGPT can \ninspire and improve serious board game design. International Journal of Serious Games, 10(4), \n33–54. https:// doi. org/ 10. 17083/ ijsg. v10i4. 645\nGee, J. P. (2005). Semiotic social spaces and affinity spaces: From The Age of Mythology to today’s \nschools. In D. Barton & K. Tusting (Eds.), Beyond communities of practice (1st ed., pp. 214–\n232). Cambridge University Press. https:// doi. org/ 10. 1017/ CBO97 80511 610554. 012\nGoogle. (2023). Bard [large language model]. https:// bard. google. com/. Accessed 6 Dec 2023.\n1 3\nEducational Psychology Review (2024) 36:25 Page 17 of 20 25\nGranic, I., Lobel, A., & Engels, R. C. M. E. (2014). The benefits of playing video games. American \nPsychologist, 69(1), 66–78. https:// doi. org/ 10. 1037/ a0034 857\nGreipl, S., Moeller, K., & Ninaus, M. (2020). Potential and limits of game-based learning. Interna-\ntional Journal of Technology Enhanced Learning, 12(4), 363. https:// doi. org/ 10. 1504/ IJTEL. \n2020. 110047\nHambrick, D. Z., Macnamara, B. N., Campitelli, G., Ullén, F., & Mosing, M. A. (2016). Beyond born \nversus made. In Psychology of learning and motivation (Vol. 64, pp. 1–55). Elsevier. https:// doi.  \norg/ 10. 1016/ bs. plm. 2015. 09. 001\nHambrick, D. Z., Oswald, F. L., Altmann, E. M., Meinz, E. J., Gobet, F., & Campitelli, G. (2014). \nDeliberate practice: Is that all it takes to become an expert? Intelligence, 45, 34–45. https:// doi. \norg/ 10. 1016/j. intell. 2013. 04. 001\nHébert, C., Jenson, J., & Terzopoulos, T. (2021). “Access to technology is the major challenge”: \nTeacher perspectives on barriers to DGBL in K-12 classrooms. E-Learning and Digital Media,  \n18(3), 307–324. https:// doi. org/ 10. 1177/ 20427 53021 995315\nHeston, T. F., & Khun, C. (2023). Prompt engineering in medical education. International Medical \nEducation, 2(3), 198–205. https:// doi. org/ 10. 3390/ ime20 30019\nHodent, C. (2018). The gamer’s brain. CRC Press.\nHomer, B. D., Raffaele, C., & Henderson, H. (2020). Games as playful learning: Implications of develop-\nmental theory for game-based learning. In J. L. Plass, R. E. Mayer, & B. D. Homer (Eds.), Hand-\nbook of game-based learning (pp. 25–52). MIT Press.\nHosseini, M., Gao, C. A., Liebovitz, D. M., Carvalho, A. M., Ahmad, F. S., Luo, Y., MacDonald, N., Hol-\nmes, K. L., & Kho, A. (2023). An exploratory survey about using ChatGPT in education, health-\ncare, and research [Preprint]. Medical Ethics. https:// doi. org/ 10. 1101/ 2023. 03. 31. 23287 979\nHoward, A., Hope, W., & Gerada, A. (2023). ChatGPT and antimicrobial advice: The end of the con-\nsulting infection doctor? The Lancet Infectious Diseases, 23(4), 405–406. https:// doi. org/ 10. 1016/ \nS1473- 3099(23) 00113-5\nHu, Y., Gallagher, T., Wouters, P., Van Der Schaaf, M., & Kester, L. (2022). Game-based learning has \ngood chemistry with chemistry education: A three-level meta-analysis. Journal of Research in Sci-\nence Teaching, 59(9), 1499–1543. https:// doi. org/ 10. 1002/ tea. 21765\nHutson, M. (2022). Could AI help you to write your next paper? Nature, 611(7934), 192–193. https:// doi. \norg/ 10. 1038/ d41586- 022- 03479-w\nJeon, J., & Lee, S. (2023). Large language models in education: A focus on the complementary rela-\ntionship between human teachers and ChatGPT. Education and Information Technologies, 28(12), \n15873–15892. https:// doi. org/ 10. 1007/ s10639- 023- 11834-1\nJohnson, A. (2023). ChatGPT in schools: Here’s where it’s banned—And how it could potentially help \nstudents. Forbes. https:// www. forbes. com/ sites/ arian najoh nson/ 2023/ 01/ 18/ chatg pt- in- schoo ls- \nheres- where- its- banned- and- how- it- could- poten tially- help- stude nts. Accessed 6 Dec 2023.\nKafai, Y. B. (2006). Playing and making games for learning: Instructionist and constructionist perspectives \nfor game studies. Games and Culture, 1(1), 36–40. https:// doi. org/ 10. 1177/ 15554 12005 281767\nKafai, Y. B., & Burke, Q. (2015). Constructionist gaming: Understanding the benefits of making games for \nlearning. Educational Psychologist, 50(4), 313–334. https:// doi. org/ 10. 1080/ 00461 520. 2015. 11240 22\nKasneci, E., Sessler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, \nG., Günnemann, S., Hüllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, \nJ., Poquet, O., Sailer, M., Schmidt, A., Seidel, T., … Kasneci, G. (2023). ChatGPT for good? On \nopportunities and challenges of large language models for education. Learning and Individual Dif-\nferences, 103, 102274. https:// doi. org/ 10. 1016/j. lindif. 2023. 102274\nKiili, K. (2007). Foundation for problem-based gaming. British Journal of Educational Technology, \n38(3), 394–404. https:// doi. org/ 10. 1111/j. 1467- 8535. 2007. 00704.x\nKlopfer, E., & Thompson, M. (2020). Game-based learning in science, technology, engineering, and \nmathematics. In J. L. Plass, R. E. Mayer, & B. D. Homer (Eds.), Handbook of game-based learning \n(pp. 387–408). MIT Press.\nKohnke, L., Moorhouse, B. L., & Zou, D. (2023). ChatGPT for language teaching and learning. RELC \nJournal, 54(2), 537–550. https:// doi. org/ 10. 1177/ 00336 88223 11628 68\nKorzynski, P., Mazurek, G., Krzypkowska, P., & Kurasinski, A. (2023). Artificial intelligence prompt \nengineering as a new digital competence: Analysis of generative AI technologies such as ChatGPT. \nEntrepreneurial Business and Economics Review, 11(3), 25–37. https:// doi. org/ 10. 15678/ EBER. \n2023. 110302\n Educational Psychology Review (2024) 36:25\n1 325 Page 18 of 20\nKrügel, S., Ostermaier, A., & Uhl, M. (2023). ChatGPT’s inconsistent moral advice influences users’ \njudgment. Scientific Reports, 13(1), 4569. https:// doi. org/ 10. 1038/ s41598- 023- 31341-0\nKurzban, R., Duckworth, A., Kable, J. W., & Myers, J. (2013). An opportunity cost model of subjective \neffort and task performance. Behavioral and Brain Sciences, 36(6), 661–679. https:// doi. org/ 10. \n1017/ S0140 525X1 20031 96\nLi, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., & Xie, X. (2023). Large lan-\nguage models understand and can be enhanced by emotional stimuli. https:// doi. org/ 10. 48550/ \nARXIV. 2307. 11760\nLoderer, K., Pekrun, R., & Plass, J. L. (2020). Emotional foundations of game-based learning. In J. L. Plass, \nR. E. Mayer, & B. D. Homer (Eds.), Handbook of game-based learning (pp. 111–151). MIT Press.\nMayer, R. E. (2020). Cognitive foundations of game-based learning. In J. L. Plass, R. E. Mayer, & B. D. \nHomer (Eds.), Handbook of game-based learning (pp. 83–110). MIT Press.\nMeskó, B. (2023). Prompt engineering as an important emerging skill for medical professionals: Tutorial. \nJournal of Medical Internet Research, 25, e50638. https:// doi. org/ 10. 2196/ 50638\nMicrosoft. (2023). Bing Chat [large language model]. https:// www. bing. com/ chat. Accessed 6 Dec 2023.\nMiller, E. M., Walton, G. M., Dweck, C. S., Job, V., Trzesniewski, K. H., & McClure, S. M. (2012). \nTheories of willpower affect sustained learning. PLoS One, 7(6), e38680. https:// doi. org/ 10. 1371/ \njourn al. pone. 00386 80\nMogali, S. R. (2023). Initial impressions of ChatGPt for anatomy education. Anatomical Sciences Edu-\ncation, ase.2261. https:// doi. org/ 10. 1002/ ase. 2261\nMolenaar, I. (2021). Personalisation of learning: Towards hybrid human-AI learning technologies. In \nOECD digital education outlook 2021: Pushing the frontiers with artificial intelligence, blockchain \nand robots. OECD Publishing. https:// read. oecd. org/ 10. 1787/ 2cc25 e37- en? format= html. Accessed \n26 Jun 2023.\nMoreno-Ger, P., Martinez-Ortiz, I., Sierra, J. L., & Fernandez-Manjon, B. (2008). A content-centric \ndevelopment process model. Computer, 41(3), 24–30. https:// doi. org/ 10. 1109/ MC. 2008. 73\nMorris, M. R., Sohl-dickstein, J., Fiedel, N., Warkentin, T., Dafoe, A., Faust, A., Farabet, C., & Legg, \nS. (2023). Levels of AGI: Operationalizing progress on the path to AGI. https:// doi. org/ 10. 48550/ \nARXIV. 2311. 02462\nNasir, M. U., & Togelius, J. (2023). Practical PCG through large language models. https:// doi. org/ 10. \n48550/ ARXIV. 2305. 18243\nNebel, S., Schneider, S., & Rey, G. D. (2016). Mining learning and crafting scientific experiments: A lit-\nerature review on the use of minecraft in education and research. Journal of Educational Technol-\nogy and Society, 19(2), 355–366.\nNinaus, M., & Sailer, M. (2022). Closing the loop – The human role in artificial intelligence for educa-\ntion. Frontiers in Psychology, 13, 956798. https:// doi. org/ 10. 3389/ fpsyg. 2022. 956798\nOpenAI. (2023). ChatGPT [large language model]. https:// chat. openai. com/ chat. Accessed 6 Dec 2023.\nOppenlaender, J., Linder, R., & Silvennoinen, J. (2023). Prompting AI art: An investigation into the crea-\ntive skill of prompt engineering. https:// doi. org/ 10. 48550/ ARXIV. 2303. 13534\nPahor, A., Seitz, A. R., & Jaeggi, S. M. (2022). Near transfer to an unrelated N-back task mediates the \neffect of N-back working memory training on matrix reasoning. Nature Human Behaviour, 6(9), \n1243–1256. https:// doi. org/ 10. 1038/ s41562- 022- 01384-w\nPapert, S. (1980). Mindstorms. Children, computers and powerful ideas. Basic Books.\nPasqualotto, A., Altarelli, I., De Angeli, A., Menestrina, Z., Bavelier, D., & Venuti, P. (2022). Enhanc-\ning reading skills through a video game mixing action mechanics and cognitive training. Nature \nHuman Behaviour, 6(4), 545–554. https:// doi. org/ 10. 1038/ s41562- 021- 01254-x\nPatterson, R. E., Pierce, B. J., Bell, H. H., & Klein, G. (2010). Implicit learning, tacit knowledge, exper -\ntise development, and naturalistic decision making. Journal of Cognitive Engineering and Deci-\nsion Making, 4(4), 289–303. https:// doi. org/ 10. 1177/ 15553 43410 00400 403\nPiaget, J. (1962). Play, dreams, and imitation in childhood. Norton.\nPlass, J. L., Homer, B. D., & Kinzer, C. K. (2015). Foundations of game-based learning. Educational \nPsychologist, 50(4), 258–283. https:// doi. org/ 10. 1080/ 00461 520. 2015. 11225 33\nPlass, J. L., Homer, B. D., Mayer, R. E., & Kinzer, C. K. (2020). Theoretical foundations of game-based \nand playful learning. In J. L. Plass, R. E. Mayer, & B. D. Homer (Eds.), Handbook of game-based \nlearning (pp. 3–24). MIT Press.\nPolak, M. P., & Morgan, D. (2023). Extracting accurate materials data from research papers with con-\nversational language models and prompt engineering. https:// doi. org/ 10. 48550/ ARXIV. 2303. 05352\n1 3\nEducational Psychology Review (2024) 36:25 Page 19 of 20 25\nReeve, J. (2023). Cognitive evaluation theory: The seedling that keeps self-determination theory growing. \nIn R. M. Ryan (Ed.), The Oxford handbook of self-determination theory (1st ed., pp. 33-C2P117). \nOxford University Press. https:// doi. org/ 10. 1093/ oxfor dhb/ 97801 97600 047. 013.3\nResnick, M. (2009, April 4). Sowing the seeds for a more creative society. Proceedings of the SIGCHI \nConference on Human Factors in Computing Systems. CHI ’09: CHI Conference on Human Fac-\ntors in Computing Systems, Boston MA USA. https:// doi. org/ 10. 1145/ 15187 01. 21671 42\nResnick, M., Maloney, J., Monroy-Hernández, A., Rusk, N., Eastmond, E., Brennan, K., Millner, A., \nRosenbaum, E., Silver, J., Silverman, B., & Kafai, Y. (2009). Scratch: Programming for all. Com-\nmunications of the ACM, 52(11), 60–67. https:// doi. org/ 10. 1145/ 15927 61. 15927 79\nResnick, M., & Rosenbaum, E. (2013). Designing for tinkerability. In M. Honey (Ed.), Design, make, \nplay: Growing the next generation of STEM innovators (pp. 163–181). Routledge.\nRigby, C. S. (2014). Gamification and motivation. In S. P. Walz & S. Deterding (Eds.), The gameful world \n(pp. 113–138). MIT Press.\nRigby, C. S., & Ryan, R. M. (2011). Glued to games: How video games draw us in and hold us spell-\nbound. Praeger.\nRosenzweig-Ziff, D. (2023). New York City blocks use of the ChatGPT bot in its schools. The Wash-\nington Post. https:// www. washi ngton post. com/ educa tion/ 2023/ 01/ 05/ nyc- schoo ls- ban- chatg pt/. \nAccessed 6 Dec 2023.\nRyan, R. M., & Deci, E. L. (2000). Self-determination theory and the facilitation of intrinsic motivation, \nsocial development, and well-being. American Psychologist, 55(1), 68–78. https:// doi. org/ 10. 1037/ \n0003- 066X. 55.1. 68\nRyan, R. M., & Deci, E. L. (2017). Self-determination theory: Basic psychological needs in motivation, \ndevelopment, and wellness. Guilford Press.\nRyan, R. M., & Rigby, C. S. (2020). Motivational foundations of game-based learning. In J. L. Plass, R. \nE. Mayer, & B. D. Homer (Eds.), Handbook of game-based learning (pp. 153–176). MIT Press.\nRyan, R. M., Rigby, C. S., & Przybylski, A. (2006). The motivational pull of video games: A self-deter -\nmination theory approach. Motivation and Emotion, 30(4), 344–360. https:// doi. org/ 10. 1007/ \ns11031- 006- 9051-8\nSallam, M. (2023). ChatGPT utility in healthcare education, research, and practice: Systematic review \non the promising perspectives and valid concerns. Healthcare, 11(6), 887. https:// doi. org/ 10. 3390/ \nhealt hcare 11060 887\nSalomon, G., Perkins, D. N., & Globerson, T. (1991). Partners in cognition: Extending human intelli-\ngence with intelligent technologies. Educational Researcher, 20(3), 2–9. https:// doi. org/ 10. 3102/ \n00131 89X02 00030 02\nSalvagno, M., Taccone, F. S., & Gerli, A. G. (2023). Can artificial intelligence help for scientific writing? \nCritical Care, 27(1), 75. https:// doi. org/ 10. 1186/ s13054- 023- 04380-2\nSarsa, S., Denny, P., Hellas, A., & Leinonen, J. (2022). Automatic generation of programming exercises and \ncode explanations using large language models. Proceedings of the 2022 ACM Conference on Interna-\ntional Computing Education Research - Volume, 1, 27–43. https:// doi. org/ 10. 1145/ 35013 85. 35439 57\nShort, C. E., & Short, J. C. (2023). The artificially intelligent entrepreneur: ChatGPT, prompt engineer -\ning, and entrepreneurial rhetoric creation. Journal of Business Venturing Insights, 19, e00388. \nhttps:// doi. org/ 10. 1016/j. jbvi. 2023. e00388\nShue, E., Liu, L., Li, B., Feng, Z., Li, X., & Hu, G. (2023). Empowering beginners in bioinformatics with \nChatGPT [Preprint]. Bioinformatics. https:// doi. org/ 10. 1101/ 2023. 03. 07. 531414\nSørebø, Ø., Halvari, H., Gulli, V. F., & Kristiansen, R. (2009). The role of self-determination theory in \nexplaining teachers’ motivation to continue to use e-learning technology. Computers and Educa-\ntion, 53(4), 1177–1187. https:// doi. org/ 10. 1016/j. compe du. 2009. 06. 001\nSpiers, H. J., Coutrot, A., & Hornberger, M. (2023). Explaining world-wide variation in navigation ability \nfrom millions of people: Citizen science project sea hero quest. Topics in Cognitive Science, 15(1), \n120–138. https:// doi. org/ 10. 1111/ tops. 12590\nSteinkuehler, C., & Oh, Y. (2012). Apprenticeship in massively multiplayer online games. In C. Steink -\nuehler, K. Squire, & S. Barab (Eds.), Games, learning, and society: Learning and meaning in the \ndigital age (pp. 185–209). Cambridge University Press. https:// doi. org/ 10. 1017/ CBO97 81139 \n031127. 017\nSteinkuehler, C., & Tsaasan, A. M. (2020). Sociocultural foundations of game-based learning. In J. L. Plass, \nR. E. Mayer, & B. D. Homer (Eds.), Handbook of game-based learning (pp. 177–206). MIT Press.\nStokel-Walker, C. (2023). ChatGPT listed as author on research papers: Many scientists disapprove. \nNature, 613(7945), 620–621. https:// doi. org/ 10. 1038/ d41586- 023- 00107-z\n Educational Psychology Review (2024) 36:25\n1 325 Page 20 of 20\nTodd, G., Earle, S., Nasir, M. U., Green, M. C., & Togelius, J. (2023). Level Generation Through Large \nLanguage Models. Proceedings of the 18th International Conference on the Foundations of Digital \nGames, 1–8. https:// doi. org/ 10. 1145/ 35824 37. 35872 11\nTynjälä, P. (2008). Perspectives into learning at the workplace. Educational Research Review, 3(2), 130–\n154. https:// doi. org/ 10. 1016/j. edurev. 2007. 12. 001\nTynjälä, P., Slotte, V., Nieminen, J., Lonka, K., & Olkinuora, E. (2006). From university to working life: \nGraduates’ workplace skills in practice. In P. Tynjälä, J. Välimaa, & G. Boulton-Lewis (Eds.), \nHigher education and working life: Collaborations, confrontations and challenges (pp. 77–88). \nElsevier Earli.\nVan Dis, E. A. M., Bollen, J., Zuidema, W., Van Rooij, R., & Bockting, C. L. (2023). ChatGPT: Five \npriorities for research. Nature, 614(7947), 224–226. https:// doi. org/ 10. 1038/ d41586- 023- 00288-7\nVygotsky, L. S. (1967). Play and its role in the mental development of the child. Soviet Psychology, 5(3), \n6–18. https:// doi. org/ 10. 2753/ RPO10 61- 04050 5036\nWang, J., Shi, E., Yu, S., Wu, Z., Ma, C., Dai, H., Yang, Q., Kang, Y., Wu, J., Hu, H., Yue, C., Zhang, H., \nLiu, Y., Li, X., Ge, B., Zhu, D., Yuan, Y., Shen, D., Liu, T., & Zhang, S. (2023). Prompt engineer-\ning for healthcare: Methodologies and applications. https:// doi. org/ 10. 48550/ ARXIV. 2304. 14670\nWenger, E. (1998). Communities of practice: Learning, meaning, and identity. Cambridge University \nPress.\nWhite, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert, H., Elnashar, A., Spencer-Smith, J., & \nSchmidt, D. C. (2023). A prompt pattern catalog to enhance prompt engineering with ChatGPT. \nhttps:// doi. org/ 10. 48550/ ARXIV. 2302. 11382\nWolfram, S. (2023). What is ChatGPT doing and why does it work? Wolfram Media.\nYang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., & Chen, X. (2023). Large language models as \noptimizers. https:// doi. org/ 10. 48550/ ARXIV. 2309. 03409\nZhu, J.-J., Jiang, J., Yang, M., & Ren, Z. J. (2023). ChatGPT and environmental research. Environmental \nScience & Technology, acs.est.3c01818. https:// doi. org/ 10. 1021/ acs. est. 3c018 18\nZimmerman, A. (2023). A ghostwriter for the masses: ChatGPT and the future of writing. Annals of Sur -\ngical Oncology, s10434–023–13436–0. https:// doi. org/ 10. 1245/ s10434- 023- 13436-0\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps \nand institutional affiliations.\nAuthors and Affiliations\nStefan E. Huber1  · Kristian Kiili2  · Steve Nebel3  · Richard M. Ryan4,5  · \nMichael Sailer6  · Manuel Ninaus1,7 \n * Manuel Ninaus \n manuel.ninaus@uni-graz.at\n1 Department of Psychology, University of Graz, Graz, Austria\n2 Faculty of Education and Culture, Tampere University, Tampere, Finland\n3 Media Education, Department of Educational Research, University of Potsdam, Potsdam, \nGermany\n4 Institute for Positive Psychology and Education, Australian Catholic University, Sydney, NSW, \nAustralia\n5 College of Education, Ewha Womans University, Seoul, South Korea\n6 Learning Analytics and Educational Data Mining, University of Augsburg, Augsburg, Germany\n7 LEAD Graduate School and Research Network, University of Tübingen, Tübingen, Germany",
  "topic": "Transformative learning",
  "concepts": [
    {
      "name": "Transformative learning",
      "score": 0.7655900716781616
    },
    {
      "name": "Perspective (graphical)",
      "score": 0.6082748174667358
    },
    {
      "name": "Psychology",
      "score": 0.5297974944114685
    },
    {
      "name": "Limiting",
      "score": 0.4808381497859955
    },
    {
      "name": "Process (computing)",
      "score": 0.46082744002342224
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.45159077644348145
    },
    {
      "name": "Educational psychology",
      "score": 0.4500763714313507
    },
    {
      "name": "Engineering ethics",
      "score": 0.3544536232948303
    },
    {
      "name": "Pedagogy",
      "score": 0.2822895050048828
    },
    {
      "name": "Computer science",
      "score": 0.21719592809677124
    },
    {
      "name": "Artificial intelligence",
      "score": 0.16950881481170654
    },
    {
      "name": "Engineering",
      "score": 0.09960433840751648
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    }
  ]
}