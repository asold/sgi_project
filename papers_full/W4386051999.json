{
  "title": "Operational prediction of solar flares using a transformer-based framework",
  "url": "https://openalex.org/W4386051999",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5001819562",
      "name": "Yasser Abduallah",
      "affiliations": [
        "New Jersey Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5100378977",
      "name": "Jason T. L. Wang",
      "affiliations": [
        "New Jersey Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5061307319",
      "name": "Haimin Wang",
      "affiliations": [
        "New Jersey Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5013145357",
      "name": "Yan Xu",
      "affiliations": [
        "New Jersey Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2169129617",
    "https://openalex.org/W2299182275",
    "https://openalex.org/W2621606460",
    "https://openalex.org/W3004960979",
    "https://openalex.org/W4221159020",
    "https://openalex.org/W4221037255",
    "https://openalex.org/W2946010671",
    "https://openalex.org/W4311059206",
    "https://openalex.org/W4327663846",
    "https://openalex.org/W2022075238",
    "https://openalex.org/W2991464110",
    "https://openalex.org/W3172319599",
    "https://openalex.org/W3215402087",
    "https://openalex.org/W1619432394",
    "https://openalex.org/W2146967864",
    "https://openalex.org/W2110362175",
    "https://openalex.org/W2093586470",
    "https://openalex.org/W3084244220",
    "https://openalex.org/W4310848395",
    "https://openalex.org/W4310813326",
    "https://openalex.org/W2800761015",
    "https://openalex.org/W4232733515",
    "https://openalex.org/W2122755404",
    "https://openalex.org/W3008201674",
    "https://openalex.org/W3203259653",
    "https://openalex.org/W1506174203",
    "https://openalex.org/W2055916162",
    "https://openalex.org/W2969487577",
    "https://openalex.org/W3205998005",
    "https://openalex.org/W2743247456",
    "https://openalex.org/W2793171700",
    "https://openalex.org/W2990852342",
    "https://openalex.org/W1973192023",
    "https://openalex.org/W1981760120",
    "https://openalex.org/W2035306675",
    "https://openalex.org/W2159977948",
    "https://openalex.org/W3009596998",
    "https://openalex.org/W1999016464",
    "https://openalex.org/W3178109510",
    "https://openalex.org/W2620664872",
    "https://openalex.org/W2963123914",
    "https://openalex.org/W3188872815",
    "https://openalex.org/W2896370767",
    "https://openalex.org/W3160650708",
    "https://openalex.org/W4297199214",
    "https://openalex.org/W4225424856",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W3104343165",
    "https://openalex.org/W3103868036",
    "https://openalex.org/W3102780218",
    "https://openalex.org/W3099838057",
    "https://openalex.org/W3098949033",
    "https://openalex.org/W3103216244",
    "https://openalex.org/W3105003569",
    "https://openalex.org/W3098453601",
    "https://openalex.org/W2066092263",
    "https://openalex.org/W3100360708",
    "https://openalex.org/W3198752290",
    "https://openalex.org/W3101667008",
    "https://openalex.org/W3123786616",
    "https://openalex.org/W3121631677"
  ],
  "abstract": "Abstract Solar flares are explosions on the Sun. They happen when energy stored in magnetic fields around solar active regions (ARs) is suddenly released. Solar flares and accompanied coronal mass ejections are sources of space weather, which negatively affects a variety of technologies at or near Earth, ranging from blocking high-frequency radio waves used for radio communication to degrading power grid operations. Monitoring and providing early and accurate prediction of solar flares is therefore crucial for preparedness and disaster risk management. In this article, we present a transformer-based framework, named SolarFlareNet, for predicting whether an AR would produce a $$\\gamma$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mi>γ</mml:mi> </mml:math> -class flare within the next 24 to 72 h. We consider three $$\\gamma$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mi>γ</mml:mi> </mml:math> classes, namely the $$\\ge$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mo>≥</mml:mo> </mml:math> M5.0 class, the $$\\ge$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mo>≥</mml:mo> </mml:math> M class and the $$\\ge$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mo>≥</mml:mo> </mml:math> C class, and build three transformers separately, each corresponding to a $$\\gamma$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mi>γ</mml:mi> </mml:math> class. Each transformer is used to make predictions of its corresponding $$\\gamma$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mi>γ</mml:mi> </mml:math> -class flares. The crux of our approach is to model data samples in an AR as time series and to use transformers to capture the temporal dynamics of the data samples. Each data sample consists of magnetic parameters taken from Space-weather HMI Active Region Patches (SHARP) and related data products. We survey flare events that occurred from May 2010 to December 2022 using the Geostationary Operational Environmental Satellite X-ray flare catalogs provided by the National Centers for Environmental Information (NCEI), and build a database of flares with identified ARs in the NCEI flare catalogs. This flare database is used to construct labels of the data samples suitable for machine learning. We further extend the deterministic approach to a calibration-based probabilistic forecasting method. The SolarFlareNet system is fully operational and is capable of making near real-time predictions of solar flares on the Web.",
  "full_text": "1\nVol.:(0123456789)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports\nOperational prediction of solar \nflares using a transformer‑based \nframework\nYasser Abduallah 1,2, Jason T. L. Wang 1,2*, Haimin Wang 1,3,4 & Yan Xu 1,3,4\nSolar flares are explosions on the Sun. They happen when energy stored in magnetic fields around \nsolar active regions (ARs) is suddenly released. Solar flares and accompanied coronal mass ejections \nare sources of space weather, which negatively affects a variety of technologies at or near Earth, \nranging from blocking high‑frequency radio waves used for radio communication to degrading power \ngrid operations. Monitoring and providing early and accurate prediction of solar flares is therefore \ncrucial for preparedness and disaster risk management. In this article, we present a transformer ‑\nbased framework, named SolarFlareNet, for predicting whether an AR would produce a γ‑class flare \nwithin the next 24 to 72 h. We consider three γ classes, namely the ≥M5.0 class, the ≥ M class and the \n≥ C class, and build three transformers separately, each corresponding to a γ class. Each transformer \nis used to make predictions of its corresponding γ‑class flares. The crux of our approach is to model \ndata samples in an AR as time series and to use transformers to capture the temporal dynamics of \nthe data samples. Each data sample consists of magnetic parameters taken from Space‑weather HMI \nActive Region Patches (SHARP) and related data products. We survey flare events that occurred from \nMay 2010 to December 2022 using the Geostationary Operational Environmental Satellite X‑ray flare \ncatalogs provided by the National Centers for Environmental Information (NCEI), and build a database \nof flares with identified ARs in the NCEI flare catalogs. This flare database is used to construct labels \nof the data samples suitable for machine learning. We further extend the deterministic approach to a \ncalibration‑based probabilistic forecasting method. The SolarFlareNet system is fully operational and \nis capable of making near real‑time predictions of solar flares on the Web.\nSolar flares are sudden explosions of energy that occur on the Sun’s surface. They often occur in solar active \nregions (ARs), caused by strong magnetic fields typically associated with sunspot areas. Solar flares are catego -\nrized into five classes A, B, C, M, and X, with A-class flares having the lowest intensity and X-class flares hav-\ning the highest intensity. Major flares are usually accompanied by coronal mass ejections and solar energetic \n particles1–7. These eruptive events can have significant and harmful effects on or near Earth, damaging technolo-\ngies, power grids, space stations, and human  life8–11. Therefore, providing accurate and early forecasts of solar \nflares is crucial for disaster risk management, risk mitigation, and preparedness.\nAlthough a lot of effort has been devoted to flare  prediction12–15, developing accurate, operational near-real-\ntime flare forecasting systems remains a challenge. In the past, researchers designed statistical models for the \nprediction of flares based on the physical properties of active  regions16–18. With the availability of large amounts of \nflare-related  data14, researchers started using machine learning methods for flare  forecasting3,19,20. More recently, \ndeep learning, which is a subfield of machine learning, has emerged and showed promising results in predicting \nsolar eruptions, including solar  flares21,22.\nFor example, Nishizuka et al.23 developed deep neural networks to forecast M- and C-class flares that would \noccur within 24 h using data downloaded from the Solar Dynamics Observatory (SDO) 24 and the Geostation-\nary Operational Environmental Satellite (GOES). Sun et al. 22 employed three-dimensional (3D) convolutional \nneural networks (CNNs) to forecast ≥M-class and ≥C-class flares using Space-weather HMI Active Region \nPatches (SHARP)25 magnetograms downloaded from the Joint Science Operations Center (JSOC) accessible at \nhttp:// jsoc. stanf ord. edu/. Li et al. 26 also adopted a CNN model to forecast ≥M-class and ≥C-class flares using \nOPEN\n1Institute for Space Weather Sciences, New Jersey Institute of Technology, University Heights, Newark, \nNJ 07102-1982, USA. 2Department of Computer Science, New Jersey Institute of Technology, University Heights, \nNewark,  NJ  07102-1982, USA.  3Center  for  Solar-Terrestrial  Research,  New  Jersey  Institute  of  Technology, \nUniversity Heights, Newark, NJ 07102-1982, USA. 4Big Bear Solar Observatory, New Jersey Institute of Technology, \n40386 North Shore Lane, Big Bear City, CA 92314-9672, USA. *email: wangj@njit.edu\n2\nVol:.(1234567890)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports/\nSHARP magnetograms where the authors restructured the CNN layers in their neural network with different \nfilter sizes. Deng et al. 27 developed a hybrid CNN model to predict solar flares during the rising and declining \nphases of Solar Cycle 24.\nSome researchers adopted SHARP magnetic parameters in time series for flare prediction. Static SHARP \nparameters quantitatively describe the properties of ARs, especially their ability to produce flares, at a given \ntime. On the other hand, dynamic information, such as the magnetic helicity injection rate, sunspot motions, \nshear flows, and magnetic flux emergence/flux cancelation, is more important for flare forecasting. Using time \nseries of SHARP parameters allows a model to capture the relationship between the evolution of magnetic fields \nof ARs and solar flares, hence achieving more accurate flare predictions 28,29. In an earlier study, Yu et al.30 added \nthe evolutionary information of ARs to a predictive model for the prediction of short-term solar flares. More \nrecently, Chen et al.31 designed a long short-term memory (LSTM) network to identify precursors of solar flare \nevents using time series of SHARP parameters. LSTM is suitable for capturing the temporal dynamics of time \nseries. Liu et al.9 developed another LSTM network with a customized attention mechanism to direct the network \nto focus on important patterns in time series of SHARP parameters. Sun et al.32 attempted to distinguish between \nARs with strong flares ( ≥M-class flares) and ARs with no flare at all. The authors showed that combining LSTM \nand CNN can better solve the “strong versus quiet” flare prediction problem, with data from both Solar Cycle 23 \nand Cycle 24. All of the aforementioned studies provided valuable models and algorithms in the field. However, \nthe existing methods focused on short-term forecasts (usually within 24 h). Furthermore, the models were not \nused as operational systems.\nIn this paper, we propose a new deep learning approach to predicting solar flares using time series of SHARP \nparameters. Our approach employs a transformer-based framework, named SolarFlareNet, which predicts \nwhether there would be a flare within 24 to 72 h, where the flare could be a ≥M5.0-, ≥M-, or ≥C-class flare. We \nfurther extend SolarFlareNet to produce probabilistic forecasts of flares and implement the probabilistic model \ninto an operational, near real-time flare forecasting system. Experimental results demonstrate that SolarFlareNet \ngenerally performs better than, or is comparable to, related flare prediction methods.\nResults\nDeterministic prediction tasks. For any given active region (AR) and time point t, we predict whether \nthere would be a γ-class flare within the next 24 h (48 h, 72 h, respectively) of t where γ can be ≥M5.0, ≥ M, or \n≥ C. A ≥M5.0-class flare means the GOES X-ray flux value of the flare is above 5× 10−5 Wm −2 . A ≥M-class flare \nrefers to an X- or M-class flare. A ≥C-class flare refers to an X-class, M-class, or C-class flare. We focus on these \nthree classes of flares due to their importance in space  weather9,19,23,33. We developed three transformer models \nto tackle the three prediction tasks individually and separately. Notice that we did not consider γ to be ≥ X due \nto the lack of samples for X-class flares. Instead, we use ≥M5.0 as the most significant class, which contains suf-\nficient samples.\nComparison with previous methods. We conducted a series of experiments to compare the proposed \nSolarFlareNet framework with closely related methods. All these methods perform binary classifications/pre-\ndictions as defined above. We adopt several performance metrics. Formally, given an AR and a data sample \nxt observed at time point t, we define xt to be a true positive (TP) if the ≥M5.0 ( ≥ M, ≥ C, respectively) model \npredicts that xt is positive, i.e., the AR will produce a ≥M5.0- ( ≥M-, ≥C-, respectively) class flare within the \nnext 24 h of t, and xt is indeed positive. We define xt as a false positive (FP) if the ≥M5.0 ( ≥ M, ≥ C, respectively) \nmodel predicts that xt is positive while xt is actually negative, i.e., the AR will not produce a ≥M5.0- ( ≥M-, ≥\nC-, respectively) class flare within the next 24 h of t. We say xt is a true negative (TN) if the ≥M5.0 ( ≥ M, ≥ C, \nrespectively) model predicts xt to be negative and xt is indeed negative; xt is a false negative (FN) if the ≥M5.0 \n( ≥ M, ≥ C, respectively) model predicts xt to be negative while xt is actually positive. We also use TP (FP , TN, and \nFN, respectively) to represent the total number of true positives (false positives, true negatives, and false nega-\ntives, respectively). The TP , FP , TN, and FN for the 48-h and 72-h ahead predictions are defined similarly. The \nperformance metrics are calculated as follows:\nTable 1 compares SolarFlareNet with related methods for 24-h ahead flare predictions. The performance metric \nvalues of SolarFlareNet are mean values obtained from 10-fold cross-validation9. The metric values of the highest \n(1)Recall= TP\nTP + FN\n(2)Precision= TP\nTP + FP\n(3)Accuracy (ACC)= TP + TN\nTP + FP + TN + FN\n(4)Balanced Accuracy (BACC) = 1\n2\n( TP\nTP + FN + TN\nTN + FP\n)\n(5)True Skill Statistics (TSS)= TP\nTP + FN − FP\nFP + TN\n3\nVol.:(0123456789)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports/\nperformance models in the related studies are taken directly from those studies and are displayed in Table 1. The \nsymbol ‘–’ means that a method does not produce the metric value for the corresponding prediction task. The \nbest metric values are highlighted in boldface. TSS is the primary metric used in the literature on flare prediction. \nIt can be seen from Table 1 that SolarFlareNet outperforms the state-of-the-art methods in terms of TSS except \nthat Liu et al.9 perform better than SolarFlareNet in predicting ≥M5.0 class flares.\nTable 2 presents the mean performance metric values with standard deviations enclosed in parentheses for \nthe 48- and 72-h forecasts made by SolarFlareNet. None of the existing methods in Table 1 provides predictions \nTable 1.  Performance comparison between SolarFlareNet and related methods for 24-h ahead flare \npredictions. Best values are in bold.\nMetric Method ≥M5.0 class ≥ M class ≥ C class\nRecall\nHuang et al.34 – – –\nLi et al.26 – 0.817 0.889\nLiu et al.9 0.960 0.885 0.773\nSun et al.22 – 0.925 0.862\nWang et al.35 – 0.730 0.621\nThis work 0.853 0.842 0.891\nPrecision\nHuang et al.34 – – –\nLi et al.26 – 0.889 0.906\nLiu et al.9 0.048 0.222 0.541\nSun et al.22 – 0.595 0.878\nWang et al.35 – 0.282 0.541\nThis work 0.977 0.848 0.949\nACC \nHuang et al.34 – – –\nLi et al.26 – 0.891 0.861\nLiu et al.9 0.921 0.907 0.826\nSun et al.22 – 0.904 0.879\nWang et al.35 – 0.945 0.883\nThis work 0.964 0.928 0.915\nBACC \nHuang et al.34 – – –\nLi et al.26 – – –\nLiu et al.9 0.940 0.896 0.806\nSun et al.22 – – –\nWang et al.35 – – –\nThis work 0.926 0.919 0.917\nTSS\nHuang et al.34 – 0.662 0.487\nLi et al.26 – 0.749 0.679\nLiu et al.9 0.881 0.792 0.612\nSun et al.22 – 0.826 0.756\nWang et al.35 – 0.681 0.553\nThis work 0.818 0.839 0.835\nTable 2.  Performance metric values of SolarFlareNet for 48- and 72-h ahead flare predictions.\nMetric Hour ≥M5.0 class ≥ M class ≥ C class\nRecall\n48 0.739 (0.108) 0.735 (0.089) 0.722 (0.089)\n72 0.717 (0.100) 0.708 (0.078) 0.702 (0.089)\nPrecision\n48 0.890 (0.210) 0.823 (0.092) 0.812 (0.072)\n72 0.872 (0.045) 0.812 (0.089) 0.809 (0.051)\nACC \n48 0.923 (0.003) 0.907 (0.007) 0.896 (0.047)\n72 0.906 (0.002) 0.883 (0.005) 0.863 (0.040)\nBACC \n48 0.864 (0.054) 0.857 (0.045) 0.848 (0.040)\n72 0.856 (0.039) 0.843 (0.048) 0.834 (0.029)\nTSS\n48 0.736 (0.112) 0.728 (0.090) 0.719 (0.079)\n72 0.729 (0.108) 0.714 (0.095) 0.709 (0.058)\n4\nVol:.(1234567890)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports/\nin 48 or 72 h in advance and, therefore, they are not listed in Table  2. Overall, SolarFlareNet performs well for \nthe 48- and 72-h forecasts. However, the metric values of the tool in Table 2 are lower than those in Table 1. This \nis understandable due to the longer range of predictions in Table 2.\nProbabilistic forecasting with calibration. SolarFlareNet is essentially a probabilistic forecasting \nmethod, producing a probability between 0 and 1. The method compares the probability with a predetermined \nthreshold, which is set to 0.5. Given an AR and a data sample xt at time point t, if the predicted probability is \ngreater than or equal to the threshold, then the AR will produce a flare within the next 24 (48, 72, respectively) \nhours of t (i.e., xt belongs to the positive class); otherwise, the AR will not produce a flare within the next 24 (48, \n72, respectively) hours of t (i.e., xt belongs to the negative class). We can turn SolarFlareNet into a probabilistic \nforecasting method by directly outputting the predicted probability without comparing it with the threshold. \nUnder this circumstance, the output is interpreted as a probabilistic estimate of how likely the AR will produce \na flare within the next 24 (48, 72, respectively) hours of t. We employ a probability calibration technique with \nisotonic regression 36,37 to adjust the predicted probability and avoid the mismatch between the distributions of \nthe predicted and expected probabilistic values  5. We add a suffix “-C” to SolarFlareNet to denote the network \nwithout calibration.\nTo evaluate the performance of a probabilistic forecasting method, we use the Brier score (BS) and Brier skill \nscore (BSS), defined as  follows4,5,38:\nwhere N is the number of data samples in a test set; yi denotes the observed probability and ˆyi denotes the pre-\ndicted probability of the ith test data sample, respectively; ¯y = 1\nN\n∑N\ni=1 yi denotes the mean of all the observed \nprobabilities. BS values range from 0 to 1, with 0 being a perfect score. BSS values range from −∞ to 1, with 1 \nbeing a perfect score.\nTable 3 compares SolarFlareNet, used as a probabilistic forecasting method, with a closely related  method9. \nThe BS and BSS values in the table are mean values (with standard deviations enclosed in parentheses) obtained \nfrom 10-fold cross-validation. The metric values for the existing method are taken directly from the related  work9. \nThe best BS and BSS values are highlighted in bold. Notice that the existing method did not make 48-h or 72-h \nforecasts in advance. Table  3 shows that there is no definitive conclusion regarding the relative performance \nof SolarFlareNet and the existing method. The existing method is better in terms of BS, while SolarFlareNet is \nbetter in terms of BSS. On the other hand, the calibrated version of a model is better than the model without \ncalibration. Notice also that the results of the 48-h and 72-h forecasts are worse than those of the 24-h forecasts. \nThis is understandable since the longer the prediction window, the worse the performance a model achieves due \nto data deviation over time.\n(6)BS = 1\nN\nN∑\ni=1\n(yi −ˆyi)2\n(7)BSS = 1 − BS\n1\nN\n∑N\ni=1(yi −¯y)2\nTable 3.  Performance comparison between SolarFlareNet and an existing method for probabilistic flare \npredictions (24 to 72 h in advance). Best values are in bold.\nHour Metric Method ≥M5.0 class ≥ M class ≥ C class\n24\nBS\nLiu et al.9 0.090 (0.011) 0.090 (0.009) 0.133 (0.007)\nSolarFlareNet 0.226 (0.024) 0.244 (0.013) 0.285 (0.034)\nSolarFlareNet-C 0.263 (0.024) 0.281 (0.050) 0.313 (0.033)\nBSS\nLiu et al.9 −21.576 (2.956) −2.241 (0.319) 0.152 (0.047)\nSolarFlareNet 0.584 (0.022) 0.521 (0.042) 0.409 (0.062)\nSolarFlareNet-C 0.504 (0.026) 0.491 (0.031) 0.349 (0.055)\n48\nBS\nLiu et al.9 – – –\nSolarFlareNet 0.272 (0.091) 0.312 (0.101) 0.361 (0.091)\nSolarFlareNet-C 0.315 (0.049) 0.336 (0.033) 0.378 (0.104)\nBSS\nLiu et al.9 – – –\nSolarFlareNet 0.569 (0.045) 0.524 (0.021) 0.502 (0.033)\nSolarFlareNet-C 0.457 (0.062) 0.424 (0.091) 0.411 (0.056)\n72\nBS\nLiu et al.9 – – –\nSolarFlareNet 0.313 (0.062) 0.327 (0.063) 0.344 (0.049)\nSolarFlareNet-C 0.329 (0.094) 0.369 (0.088) 0.376 (0.102)\nBSS\nLiu et al.9 – – –\nSolarFlareNet 0.549 (0.067) 0.524 (0.089) 0.501 (0.093)\nSolarFlareNet-C 0.514 (0.077) 0.469 (0.095) 0.447 (0.059)\n5\nVol.:(0123456789)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports/\nThe SolarFlareNet system. We have implemented the probabilistic forecasting method described above \ninto an operational, near real-time flare forecasting system. To access the system, visit the SolarDB website at \nhttps:// nature. njit. edu/ solar db/ index. html. On the website, select and click the menu entry “Tools” and then \nselect and click “Flare Forecasting System. ” Figure 1 shows the graphical user interface (GUI) of the system. It \ndisplays a probabilistic estimate of how likely an AR will produce a flare within the next 24, 48, and 72 h of the \ntime point at which the system is updated each day. No prediction is made for an AR marked with a special \ncharacter *, #, or ∼ where\n• * means the AR is near the limb,\n• # means the AR is spotless with the number of spots being zero,\n• ∼ means no SHARP data is available for the AR.\nThe system provides daily predictions based on the data obtained from the previous day. When the user clicks \nthe link to the previous day, the user is led to the SolarMonitor site that is accessible at https:// www. solar monit \nor. org/ index. php where detailed AR information for that day is available. The system also provides previous \nforecasting results since the operational system came online. We compare the previous forecasting results with \nthe true flare events in the GOES X-ray flare catalogs provided by NCEI. The SolarFlareNet system achieves 89% \n(76%, 71%, respectively) accuracy for 24-h (48-h, 72-h, respectively) ahead predictions.\nDiscussion and conclusion\nIn this article, we present a novel transformer-based framework to predict whether a solar active region (AR) \nwould produce a γ-class flare within the next 24 to 72 h where γ is ≥M5.0, ≥ M, or ≥ C. We use three transform \nmodels to handle the three classes of flares individually and separately. All three transformer models perform \nbinary predictions. We collect ARs with flares that occurred between 2010 and 2022 from the GOES X-ray flare \ncatalogs provided by the National Centers for Environmental Information (NCEI). In addition, we downloaded \nSHARP magnetic parameters from the Joint Science Operations Center (JSOC). Each data sample contains \nSHARP parameters suitable for machine learning. We conducted experiments using 10-fold cross-validation 9. \nBased on the experiments, our transformer-based framework generally performs better than closely related \nmethods in terms of TSS (true skill statistics), as shown in Table 1. We further extend our framework to produce \nprobabilistic forecasts of flares and implement the framework into an operational, near real-time flare forecasting \nsystem accessible on the Web. The probabilistic framework is comparable to a closely related  method9 in terms \nof BS (Brier score) and BSS (Brier skill score) when making 24-h forecasts, as shown in Table  3, although the \nFigure 1.  The graphical user interface of the SolarFlareNet system.\n6\nVol:.(1234567890)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports/\nexisting method did not make 48- or 72-h forecasts. Thus, we conclude that SolarFlareNet is a feasible tool for \nproducing flare forecasts within 24 to 72 h.\nMethods\nData collection. In this study we used SHARP magnetic  parameters2,9,25 downloaded from the Joint Science \nOperations Center (JSOC) accessible at http:// jsoc. stanf ord. edu/. Specifically, we collect data samples, composed \nof SHARP parameters, at a cadence of 12 minutes where the data samples are retrieved from the hmi.sharp_\ncea_720s data series on the JSOC website using the Python package  SunPy39. We selected nine SHARP mag-\nnetic parameters as suggested in the  literature2–4,9,19. These nine parameters include the total unsigned current \nhelicity (TOTUSJH), total unsigned vertical current (TOTUSJZ), total unsigned flux (USFLUX), mean charac-\nteristic twist parameter (MEANALP), sum of flux near polarity inversion line (R_V ALUE), total photospheric \nmagnetic free energy density (TOTPOT), sum of the modulus of the net current per polarity (SAVNCPP), area \nof strong field pixels in the active region (AREA_ACR), and absolute value of the net current helicity (ABSN-\nJZH). Table 4 presents an overview of the nine parameters. The SHARP parameters’ values are in different scales \nand units; therefore, we normalize each parameter’s values using the min-max normalization  method4,5. For-\nmally, let pk\ni be the original value of the ith parameter of the kth data sample. Let qk\ni be the normalized value of \nthe ith parameter of the kth data sample. Let mini be the minimum value of the ith parameter. Let max i be the \nmaximum value of the ith parameter. Then\nWe collected A-, B-, C-, M- and X-class flares that occurred between May 2010 and December 2022, and their \nassociated active regions (ARs) from the GOES X-ray flare catalogs provided by the National Centers for Envi-\nronmental Information (NCEI). Flares without identified ARs were excluded. This process yielded a database of \n8 A-class flares, 6571 B-class flares, 8973 C-class flares, 895 M-class flares, and 58 X-class flares. Also, we collected \n10 nonflaring  ARs40. We collected data samples that were 24 (48, 72, respectively) hours before a flare. Further-\nmore, we collected data samples that were 24 (48, 72, respectively) hours after the start time of each nonflaring \nAR. The data was then cleaned as  follows2,5,9.\nWe discard ARs that are outside ± 70◦ of the central meridian. These ARs are near the limb and have projec-\ntion effects that render the calculation of the ARs’ SHARP parameters incorrect. In addition, we discard a data \nsample if (i) its corresponding flare record has an absolute value of the radial velocity of SDO greater than 3500 m \ns−1 , (ii) the HMI data have low  quality41, or (iii) the data sample has missing values or incomplete SHARP param-\neters. Thus, we exclude low-quality data samples and keep qualified data samples of high quality in our study.\nData labeling. Data labeling is crucial in machine learning. To predict ≥C-class flares, suppose that a C-, \nM-, or X-class flare occurs at time point t on an AR (more precisely, the start time of the flare is t). Data samples \nbetween t and t − 24 h (48, 72 h, respectively) in the AR are labeled positive. If the flare occurs at time point t is \nan A-class or B-class flare, the data samples between t and t − 24 h (48, 72 h, respectively) in the AR are labeled \nnegative. Figure 2 illustrates the labeling scheme to predict whether a ≥C-class flare would occur within 24 h. \nIn predicting ≥M-class flares, we use ≥M-class flares to label positive data samples; use ≤C-class flares to label \nnegative data samples. In predicting ≥M5.0-class flares, we use ≥M5.0-class flares to label positive data samples; \nuse ≤C-class flares as well as M1.0- through M4.0-class flares to label negative data samples. If there are recurring \nflares whose corresponding data samples overlap, we give priority to the largest flare and label the overlapped \ndata samples based on the largest flare. In all three prediction tasks, the data samples in the nonflaring ARs are \nlabeled negative.\nTable 5 shows the total numbers of positive and negative data samples in each class for 24-, 48-, and 72-h \nahead flare predictions. The numbers in the table are lower than expected. This is because we discarded/removed \nmany low-quality data samples as described above. If a gap occurs in the middle of a time series due to removal, \nwe use a zero-padding  strategy5,9 to create a synthetic data sample to fill the gap. The synthetic data sample has \n(8)qk\ni = pk\ni − mini\nmax i − mini\nTable 4.  Overview of the nine SHARP parameters used in our study.\nKeyword Description Formula\nTOTUSJH Total unsigned current helicity H ctotal ∝ ∑|Bz ·Jz |\nTOTUSJZ Total unsigned vertical current Jztotal = ∑|Jz |dA\nUSFLUX Total unsigned flux /Phi1= ∑|Bz|dA\nMEANALP Mean characteristic twist parameter, α αtotal ∝\n∑Jz B z∑B 2z\nR_V ALUE Sum of flux near polarity inversion line /Phi1= ∑|BLoS|dAwithinR mask\nTOTPOT Total photospheric magnetic free energy density ρtot∝ ∑(BBBObs −BBBPot)2dA\nSAVNCPP Sum of the modulus of the net current per polarity Jzsum ∝| ∑B+z JzdA |+|∑B−z JzdA |\nAREA_ACR Area of strong field pixels in the active region Area = ∑Pixels\nABSNJZH Absolute value of the net current helicity H cabs ∝| ∑Bz ·Jz|\n7\nVol.:(0123456789)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports/\nzero values for all nine SHARP parameters. The synthetic data sample is added after normalization of the values \nof the SHARP parameters, and therefore the synthetic data sample does not affect the normalization procedure.\nFor each prediction task, we divide the corresponding data samples into 10 equal sized distinct partitions/\nfolds that are used to perform 10-fold cross-validation experiments. In the run i, where 1 ≤ i ≤ 10 , we use fold \ni as the test set and the union of the other nine folds as the training set. The data samples of the same AR are \nplaced in the training set or the test set, but not both. This scheme ensures that a model is trained with data \ndifferent from the test data and makes predictions on the test data that it has never seen during training. There \nare 10 folds and, consequently, 10 runs. The means and standard deviations of the performance metrics’ values \nover the 10 runs are calculated and recorded.\nData augmentation. The data sets used in this study to predict flares of the ≥ M- and ≥M5.0-class are \nimbalanced as shown in Table 5 where negative data samples are much more than positive data samples. Imbal-\nanced data pose a challenge in model training and often result in poor model performance. One may use data \naugmentation to combat the imbalanced data. Data augmentation is an important technique that enriches train-\ning data and increases the generalization of the model  42. Here, we adopt the Gaussian white noise (GWN) \ndata augmentation scheme because it has shown a significant improvement in model  performance43,44. GWN \nassumes that any two values are statistically independent, regardless of how close they are in time. The stationary \nrandom values of GWN are generated using the zero mean and 5 % of the standard deviation. During training, \nthe data augmentation is applied to the minority (positive) class, leaving the majority (negative) class as is. Dur-\ning testing, the data are left without any augmentation so that the model predicts only on the actual test data to \navoid any misleading performance assessment.\nThe SolarFlareNet architecture. Figure 3 presents the architecture of SolarFlareNet. It is a transformer-\nbased framework that combines a one-dimensional convolutional neural network (Conv1D), long short-term \nmemory (LSTM), transformer encoder blocks (TEBs), and additional layers that include batch normalization \n(BN) layers, dropout layers, and dense layers. The first layer is the input layer, which takes as input a time series \nof m consecutive data samples xt−m +1 , xt−m +2 ...xt−1 , xt where xt is the data sample at time point t5. (In the study \npresented here, m is set to 10.) The input layer is followed by a BN layer. BN is an additional mechanism to sta-\nbilize SolarFlareNet, make it faster, and help to avoid overfitting during  training45. We applied BN after the input \nlayer, the LSTM layer, and within the TEBs to make sure that SolarFlareNet is stable throughout the training pro-\ncess. The BN layer is followed by the Conv1D layer because time series generally have a strong 1D time locality \nthat can be extracted by the Conv1D  layers46. Then, the LSTM layer is used, which is equipped with regulariza-\ntion to also avoid overfitting. LSTM is suitable for handling time series data to capture the temporal correlation \nand dependency in the data. Adding an LSTM layer after a Conv1D layer has shown significant improvement in \ntime series  prediction47–49. The LSTM layer passes the learned features and patterns to a BN layer to stabilize the \nnetwork before the data go to the TEBs.\nFigure 2.  Illustration of positive and negative data samples used in predicting ≥C-class flares. In the left panel, \nthe red vertical line indicates the start time of a ≥C-class flare. The data samples collected in the 24 h prior to the \nred vertical line are labeled positive (in green color). In the right panel, the red vertical line indicates the start \ntime of an A-class or B-class flare. The data samples collected in the 24 h prior to the red vertical line are labeled \nnegative (in yellow color).\nTable 5.  Total numbers of positive and negative data samples in each class for 24-, 48-, and 72-h ahead flare \npredictions.\nHour Data samples ≥M5.0 class ≥ M class ≥ C class\n24\nPositive 2,125 13,989 244,968\nNegative 461,060 449,196 218,517\n48\nPositive 2,255 16,709 316,149\nNegative 615,708 602,154 304,714\n72\nPositive 2,375 18,505 356,219\nNegative 704,997 689,567 350,953\n8\nVol:.(1234567890)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports/\nWe use transformer encoders without decoders because we process time series here, rather than performing \nnatural language processing where the decoders are required to decode the words for sentence translation. The \nnumber of TEBs is set to 4. This number has a significant effect on the overall performance of the  model50. When \nwe use less than 4 TEBs, the model is not able to learn useful patterns and is under-fitted. When we use more \nthan 4 TEBs, the large number of TEBs causes overhead on the encoder processing while the model tends to do \nexcessive overfitting and lean toward the majority class (i.e., negative class) in the data, ignoring the minority \nclass (i.e., positive class) entirely. Each TEB is configured with a dropout layer, multi-head attention (MHA) \nlayer, a BN layer, a Conv1D layer, and an LSTM layer. The MHA layer is the most important layer in the encoder \nbecause it provides the transformation on the sequence values to obtain the different metrics. The MHA layer is \nconfigured with 4 heads and each attention head is also set to 4. The dropout layer is mainly used to overcome \nthe overfitting caused by the imbalanced data. It drops a percentage of the neurons from the architecture, which \ncauses the internal architecture of the model to change, allowing for better performance and stability. Finally, the \nsoftmax function is used as the final activation function, which produces a probabilistic estimate of how likely \na flare will occur within the next 24 (48, 72, respectively) hours of t .\nAblation study. We performed ablation tests to assess each component of SolarFlareNet. We consider \nfour variants of SolarFlareNet, denoted SolarFlareNet-Conv, SolarFlareNet-L, SolarFlareNet-ConvL, and Solar-\nFlareNet-T, respectively. Here, SolarFlareNet-Conv (SolarFlareNet-L, SolarFlareNet-ConvL, SolarFlareNet-T, \nrespectively) represents the subnet of SolarFlareNet in which the Conv1D layer (LSTM layer, Conv1D and LSTM \nlayers, transformer network with the 4 TEBs, respectively) is removed while keeping the remaining components \nof the SolarFlareNet framework. Table 6 compares the TSS values of the five models for the 24-, 48-, and 72-h \nahead flare prediction. It can be seen from Table  6 that the full model, SolarFlareNet, outperforms the four \nsubnets in terms of the TSS metric. This happens because the SolarFlareNet-Conv model captures the temporal \ncorrelation of the test data, but does not learn additional characteristics of the data to build a stronger relation-\nship between the test data. SolarFlareNet-L captures the properties of the test data, but lacks knowledge of the \ntemporal correlation patterns in the data to deeply analyze the sequential information in the test data. It can \nalso be seen from Table 6 that the SolarFlareNet-ConvL model is not as good as the full model, indicating that \nthe transformer network alone is not enough to produce the best results. Lastly, SolarFlareNet-T has the least \nperformance among the four subnets, demonstrating the importance of the transformer network. In conclusion, \nour ablation study indicates that the performance of the proposed SolarFlareNet framework is not dominated \nFigure 3.  Architecture of SolarFlareNet.\n9\nVol.:(0123456789)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports/\nby any single component. In fact, all components have made contributions to the overall performance of the \nproposed framework.\nData availability\nThe trained SolarFlareNet model and datasets used in this study can be downloaded from https:// nature. njit. \nedu/ solar db/ solar flare net.\nReceived: 8 June 2023; Accepted: 17 August 2023\nReferences\n 1. Qahwaji, R., Colak, T., Al-Omari, M. & Ipson, S. Automated prediction of CMEs using machine learning of CME - flare associa-\ntions. Sol. Phys. 248, 471–483 (2008).\n 2. Bobra, M. G. & Ilonidis, S. Predicting coronal mass ejections using machine learning methods. Astrophys. J. 821, 127 (2016).\n 3. Liu, C., Deng, N., Wang, J. T. L. & Wang, H. Predicting solar flares using SDO/HMI vector magnetic data products and the random \nforest algorithm. Astrophys. J. 843, 104 (2017).\n 4. Liu, H., Liu, C., Wang, J. T. L. & Wang, H. Predicting coronal mass ejections using SDO/HMI vector magnetic data products and \nrecurrent neural networks. Astrophys. J. 890, 12 (2020).\n 5. Abduallah, Y . et al. Predicting solar energetic particles using SDO/HMI vector magnetic data products and a bidirectional LSTM \nnetwork. Astrophys. J. Suppl. Ser. 260, 16 (2022).\n 6. Moreland, K. et al. A machine-learning oriented dataset for forecasting SEP occurrence and properties. In 44th COSPAR Scientific \nAssembly, vol. 44, 1151 (2022).\n 7. Singh, T., Benson, B., Raza, S., Kim, T. & Pogorelov, N. Improving the arrival time prediction of coronal mass ejections using \nmagnetohydrodynamic ensemble modeling, heliospheric imager data and machine learning. In EGU General Assembly Conference \nAbstracts, EGU22–13167 (2022).\n 8. Daglis, I., Baker, D., Kappenman, J., Panasyuk, M. & Daly, E. Effects of space weather on technology infrastructure. Space Weather \n2, S02004 (2004).\n 9. Liu, H., Liu, C., Wang, J. T. L. & Wang, H. Predicting solar flares using a long short-term memory network. Astrophys. J. 877, 121 \n(2019).\n 10. Zhang, H. et al. Solar flare index prediction using SDO/HMI vector magnetic data products with statistical and machine-learning \nmethods. Astrophys. J. Suppl. Ser. 263, 28 (2022).\n 11. He, X.-R. et al. Solar flare short-term forecast model based on long and short-term memory neural network. Chin. Astron. Astro-\nphys. 47, 108–126 (2023).\n 12. Huang, X., Zhang, L., Wang, H. & Li, L. Improving the performance of solar flare prediction using active longitudes information. \nAstron. Astrophys. 549, A127 (2013).\n 13. Panos, B. & Kleint, L. Real-time flare prediction based on distinctions between flaring and non-flaring active region spectra. \nAstrophys. J. 891, 17 (2020).\n 14. Georgoulis, M. K. et al. The flare likelihood and region eruption forecasting (FLARECAST) project: flare forecasting in the big \ndata & machine learning era. J. Space Weather Space Clim. 11, 39 (2021).\n 15. Tang, R. et al. Solar flare prediction based on the fusion of multiple deep-learning models. Astrophys. J. Suppl. Ser. 257, 50 (2021).\n 16. Gallagher, P . T., Moon, Y . J. & Wang, H. Active-region monitoring and flare forecasting I. Data processing and first results. Solar \nPhys. 209, 171–183 (2002).\n 17. Leka, K. D. & Barnes, G. Photospheric magnetic field properties of flaring versus flare-quiet active regions. IV . A statistically \nsignificant sample. Astrophys. J. 656, 1173–1186 (2007).\n 18. Mason, J. P . & Hoeksema, J. T. Testing automated solar flare forecasting with 13 years of Michelson Doppler Imager magnetograms. \nAstrophys. J. 723, 634–640 (2010).\n 19. Bobra, M. G. & Couvidat, S. Solar flare prediction using SDO/HMI vector magnetic field data with a machine-learning algorithm. \nAstrophys. J. 798, 135 (2015).\n 20. Abduallah, Y ., Wang, J. T. L., Nie, Y ., Liu, C. & Wang, H. DeepSun: Machine-learning-as-a-service for solar flare prediction. Res. \nAstron. Astrophys. 21, 160 (2021).\nTable 6.  TSS values of the five methods considered in the ablation study. Best values are in bold.\nHour Method ≥M5.0 class ≥ M class ≥ C class\n24\nSolarFlareNet 0.818 (0.021) 0.839 (0.030) 0.835 (0.048)\nSolarFlareNet-Conv 0.780 (0.036) 0.759 (0.052) 0.822 (0.023)\nSolarFlareNet-L 0.779 (0.022) 0.737 (0.041) 0.713 (0.039)\nSolarFlareNet-ConvL 0.742 (0.029) 0.719 (0.041) 0.728 (0.037)\nSolarFlareNet-T 0.716 (0.101) 0.704 (0.093) 0.712 (0.078)\n48\nSolarFlareNet 0.736 (0.112) 0.728 (0.090) 0.719 (0.079)\nSolarFlareNet-Conv 0.729 (0.049) 0.715 (0.055) 0.695 (0.035)\nSolarFlareNet-L 0.694 (0.066) 0.689 (0.012) 0.675 (0.021)\nSolarFlareNet-ConvL 0.681 (0.063) 0.676 (0.054) 0.673 (0.048)\nSolarFlareNet-T 0.662 (0.061) 0.647 (0.032) 0.641 (0.033)\n72\nSolarFlareNet 0.729 (0.108) 0.714 (0.095) 0.709 (0.058)\nSolarFlareNet-Conv 0.703 (0.042) 0.696 (0.011) 0.658 (0.023)\nSolarFlareNet-L 0.688 (0.046) 0.666 (0.039) 0.658 (0.016)\nSolarFlareNet-ConvL 0.665 (0.026) 0.643 (0.031) 0.632 (0.030)\nSolarFlareNet-T 0.635 (0.028) 0.624 (0.046) 0.619 (0.033)\n10\nVol:.(1234567890)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports/\n 21. Liu, S. et al. Deep learning based solar flare forecasting model. II. Influence of image resolution. Astrophys. J. 941, 20 (2022).\n 22. Sun, P . et al. Solar flare forecast using 3D convolutional neural networks. Astrophys. J. 941, 1 (2022).\n 23. Nishizuka, N., Sugiura, K., Kubo, Y ., Den, M. & Ishii, M. Deep flare net (DeFN) model for solar flare prediction. Astrophys. J. 858, \n113 (2018).\n 24. Pesnell, W . D. Solar Dynamics Observatory (SDO). In Handbook of Cosmic Hazards and Planetary Defense, 179–196 (Springer, \n2015).\n 25. Bobra, M. G. et al. The Helioseismic and Magnetic Imager (HMI) vector magnetic field pipeline: SHARPs - Space-weather HMI \nActive Region Patches. Sol. Phys. 289, 3549–3578 (2014).\n 26. Li, X., Zheng, Y ., Wang, X. & Wang, L. Predicting solar flares using a novel deep convolutional neural network. Astrophys. J. 891, \n10 (2020).\n 27. Deng, Z. et al. Fine-grained solar flare forecasting based on the hybrid convolutional neural networks. Astrophys. J. 922, 232 (2021).\n 28. Tian, Y . Relationship between the evolution of solar magnetic field and flares in different active regions. J. Phys: Conf. Ser. 2282, \n012025 (2022).\n 29. van Driel-Gesztelyi, L. & Green, L. M. Evolution of active regions. Living Rev. Sol. Phys. 12, 1 (2015).\n 30. Yu, D., Huang, X., Wang, H. & Cui, Y . Short-term solar flare prediction using a sequential supervised learning method. Sol. Phys. \n255, 91–105 (2009).\n 31. Chen, Y . et al. Identifying solar flare precursors using time series of SDO/HMI images and SHARP parameters. Space Weather 17, \n1404–1426 (2019).\n 32. Sun, Z. et al. Predicting solar flares using CNN and LSTM on two solar cycles of active region data. Astrophys. J. 931, 163 (2022).\n 33. Jonas, E., Bobra, M., Shankar, V ., Todd Hoeksema, J. & Recht, B. Flare prediction using photospheric and coronal image data. Sol. \nPhys. 293, 48 (2018).\n 34. Huang, X. et al. Deep learning based solar flare forecasting model. I. Results for line-of-sight magnetograms. Astrophys. J.  856, 7 \n(2018).\n 35. Wang, X. et al. Predicting solar flares with machine learning: Investigating solar cycle dependence. Astrophys. J. 895, 3 (2020).\n 36. Kruskal, J. B. Nonmetric multidimensional scaling: A numerical method. Psychometrika 29, 115–129 (1964).\n 37. Sager, T. W . & Thisted, R. A. Maximum likelihood estimation of isotonic modal regression. Ann. Stat. 10, 690–707 (1982).\n 38. Wilks, D. S. Sampling distributions of the Brier score and Brier skill score under serial dependence. Q. J. R. Meteorol. Soc. 136, \n2109–2118 (2010).\n 39. The SunPy Community et al. SunPy—Python for solar physics. Computational Science and Discovery8, 014009 (2015).\n 40. Hazra, S., Sardar, G. & Chowdhury, P . Distinguishing between flaring and nonflaring active regions. Astron. Astrophys. 639, A44 \n(2020).\n 41. Hoeksema, J. T. et al. The Helioseismic and Magnetic Imager (HMI) vector magnetic field pipeline: Overview and performance. \nSol. Phys. 289, 3483–3530 (2014).\n 42. Deng, Y . et al. Deep transfer learning and data augmentation improve glucose levels prediction in type 2 diabetes patients. Nat. \nPortf. J. Digit. Med. 4, 1013345 (2021).\n 43. Um, T. T. et al. Data augmentation of wearable sensor data for Parkinson’s disease monitoring using convolutional neural networks. \nIn Proceedings of the 19th Association for Computing Machinery International Conference on Multimodal Interaction (2017).\n 44. Li, K., Daniels, J., Liu, C., Herrero, P . & Georgiou, P . Convolutional recurrent neural networks for glucose prediction. IEEE J. \nBiomed. Health Inform. 24, 603–613 (2020).\n 45. Zerveas, G., Jayaraman, S., Patel, D., Bhamidipaty, A. & Eickhoff, C. A transformer-based framework for multivariate time series \nrepresentation learning. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (2021).\n 46. Kravchik, M. & Shabtai, A. Detecting cyber attacks in industrial control systems using convolutional neural networks. In Proceed-\nings of the 2018 Workshop on Cyber-Physical Systems Security and PrivaCy (2018).\n 47. Abduallah, Y . et al. Reconstruction of total solar irradiance by deep learning. In Proceedings of the 34th International Florida \nArtificial Intelligence Research Society Conference (2021).\n 48. Abduallah, Y ., Wang, J. T. L., Xu, C. & Wang, H. A transformer-based framework for geomagnetic activity prediction. In Proceed-\nings of the 26th International Symposium on Methodologies for Intelligent Systems (2022).\n 49. Abduallah, Y . et al. Forecasting the disturbance storm time index with Bayesian deep learning. In Proceedings of the 35th Interna-\ntional Florida Artificial Intelligence Research Society Conference (2022).\n 50. Vaswani, A. et al. Attention is all you need. In Proceedings of the Annual Conference on Neural Information Processing Systems  \n(2017).\nAcknowledgements\nThe authors thank members of the Institute for Space Weather Sciences for helpful discussions. We also thank \nthe reviewers for valuable comments and suggestions.\nAuthor contributions\nJ.W . and H.W . conceived the study. Y .A. implemented the operational, near real-time flare forecasting system. \nY .X. evaluated and tested the system. All authors reviewed the manuscript.\nFunding\nThis work was supported in part by US NSF grants AGS-1927578, AGS-2149748, and AGS-2228996.\nCompeting interests \nThe authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to J.T.L.W .\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\n11\nVol.:(0123456789)Scientific Reports |        (2023) 13:13665  | https://doi.org/10.1038/s41598-023-40884-1\nwww.nature.com/scientificreports/\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n© The Author(s) 2023",
  "topic": "Solar flare",
  "concepts": [
    {
      "name": "Solar flare",
      "score": 0.6871277093887329
    },
    {
      "name": "Computer science",
      "score": 0.5355363488197327
    },
    {
      "name": "Transformer",
      "score": 0.4590633511543274
    },
    {
      "name": "Environmental science",
      "score": 0.3221401870250702
    },
    {
      "name": "Electrical engineering",
      "score": 0.1188911497592926
    },
    {
      "name": "Engineering",
      "score": 0.11860179901123047
    },
    {
      "name": "Physics",
      "score": 0.10140421986579895
    },
    {
      "name": "Astronomy",
      "score": 0.09553980827331543
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I118118575",
      "name": "New Jersey Institute of Technology",
      "country": "US"
    }
  ],
  "cited_by": 20
}