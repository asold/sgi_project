{
    "title": "Knowledge Enhanced Multi-intent Transformer Network for Recommendation",
    "url": "https://openalex.org/W4396843698",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2019208841",
            "name": "Ding Zou",
            "affiliations": [
                "Huazhong University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A1947499342",
            "name": "Wei Wei",
            "affiliations": [
                "Huazhong University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2160602068",
            "name": "Feida Zhu",
            "affiliations": [
                "Singapore Management University"
            ]
        },
        {
            "id": "https://openalex.org/A2162829609",
            "name": "Chuanyu Xu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1973217115",
            "name": "Tao Zhang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2172031020",
            "name": "Chengfu Huo",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2911778742",
        "https://openalex.org/W4286986033",
        "https://openalex.org/W2998324911",
        "https://openalex.org/W2997024057",
        "https://openalex.org/W2893775232",
        "https://openalex.org/W2792839191",
        "https://openalex.org/W2963869731",
        "https://openalex.org/W2963911286",
        "https://openalex.org/W2913560138",
        "https://openalex.org/W2945623882",
        "https://openalex.org/W3129482887",
        "https://openalex.org/W3044311607",
        "https://openalex.org/W2966349618",
        "https://openalex.org/W3034364571",
        "https://openalex.org/W4386158527",
        "https://openalex.org/W3094605801",
        "https://openalex.org/W4225412853",
        "https://openalex.org/W2807021761",
        "https://openalex.org/W2010187764",
        "https://openalex.org/W2743159750",
        "https://openalex.org/W4224914537",
        "https://openalex.org/W4292950683",
        "https://openalex.org/W3106439716",
        "https://openalex.org/W3153325943",
        "https://openalex.org/W3098087397",
        "https://openalex.org/W3100324210",
        "https://openalex.org/W2593390416",
        "https://openalex.org/W3100848837",
        "https://openalex.org/W4388125271",
        "https://openalex.org/W3155919942"
    ],
    "abstract": "Incorporating Knowledge Graphs into Recommendation has attracted growing\\nattention in industry, due to the great potential of KG in providing abundant\\nsupplementary information and interpretability for the underlying models.\\nHowever, simply integrating KG into recommendation usually brings in negative\\nfeedback in industry, due to the ignorance of the following two factors: i)\\nusers' multiple intents, which involve diverse nodes in KG. For example, in\\ne-commerce scenarios, users may exhibit preferences for specific styles,\\nbrands, or colors. ii) knowledge noise, which is a prevalent issue in Knowledge\\nEnhanced Recommendation (KGR) and even more severe in industry scenarios. The\\nirrelevant knowledge properties of items may result in inferior model\\nperformance compared to approaches that do not incorporate knowledge. To tackle\\nthese challenges, we propose a novel approach named Knowledge Enhanced\\nMulti-intent Transformer Network for Recommendation (KGTN), comprising two\\nprimary modules: Global Intents Modeling with Graph Transformer, and Knowledge\\nContrastive Denoising under Intents. Specifically, Global Intents with Graph\\nTransformer focuses on capturing learnable user intents, by incorporating\\nglobal signals from user-item-relation-entity interactions with a graph\\ntransformer, meanwhile learning intent-aware user/item representations.\\nKnowledge Contrastive Denoising under Intents is dedicated to learning precise\\nand robust representations. It leverages intent-aware representations to sample\\nrelevant knowledge, and proposes a local-global contrastive mechanism to\\nenhance noise-irrelevant representation learning. Extensive experiments\\nconducted on benchmark datasets show the superior performance of our proposed\\nmethod over the state-of-the-arts. And online A/B testing results on Alibaba\\nlarge-scale industrial recommendation platform also indicate the real-scenario\\neffectiveness of KGTN.\\n",
    "full_text": "Knowledge Enhanced Multi-intent Transformer Network for\nRecommendation\nDing Zouâˆ—\nCCIIP Lab\nSchool of Computer Science and\nTechnology\nHuazhong University of Science and\nTechnology\nJoint Laboratory of HUST and Pingan\nProperty & Casualty Research (HPL)\nWuhan, China\nTaotian Group\nHangzhou, China\nm202173662@hust.edu.cn\nWei Weiâ€ \nCCIIP Lab\nSchool of Computer Science and\nTechnology\nHuazhong University of Science and\nTechnology\nJoint Laboratory of HUST and Pingan\nProperty & Casualty Research (HPL)\nWuhan, China\nweiw@hust.edu.cn\nFeida Zhu\nSingapore Management University\nSingapore, Singapore\nfdzhu@smu.edu.sg\nChuanyu Xu\nTaotian Group\nHangzhou, China\ntracy.xcy@taobao.com\nTao Zhang\nTaotian Group\nHangzhou, China\nguyan.zt@taobao.com\nChengfu Huo\nTaotian Group\nHangzhou, China\nchengfu.huocf@taobao.com\nABSTRACT\nIncorporating Knowledge Graphs (KGs) into Recommendation has\nattracted growing attention in industry, due to the great potential\nof KG in providing abundant supplementary information and inter-\npretability for the underlying models. However, simply integrating\nKG into recommendation usually brings in negative feedback in\nindustry, mainly due to the ignorance of the following two fac-\ntors: i) usersâ€™ multiple intents, which involve diverse nodes in KG.\nFor example, in e-commerce scenarios, users may exhibit prefer-\nences for specific styles, brands, or colors. ii) knowledge noise,\nwhich is a prevalent issue in Knowledge Enhanced Recommen-\ndation (KGR) and even more severe in industry scenarios. The\nirrelevant knowledge properties of items may result in inferior\nmodel performance compared to approaches that do not incorpo-\nrate knowledge. To tackle these challenges, we propose a novel\napproach named Knowledge Enhanced Multi-intent Transformer\nNetwork for Recommendation (KGTN), which comprises two pri-\nmary modules: Global Intents Modeling with Graph Transformer,\nand Knowledge Contrastive Denoising under Intents. Specifically,\nGlobal Intents with Graph Transformer focuses on capturing learn-\nable user intents, by incorporating global signals from user-item-\nrelation-entity interactions with a well-designed graph transformer,\nâˆ—Work done during internship at Taotian Group.\nâ€ Corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nWWW â€™24 Companion, May 13â€“17, 2024, Singapore, Singapore.\nÂ© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0172-6/24/05. . . $15.00\nhttps://doi.org/10.1145/3589335.3648296\nand meanwhile learning intent-aware user/item representations.\nOn the other hand, Knowledge Contrastive Denoising under In-\ntents is dedicated to learning precise and robust representations.\nIt leverages the intent-aware user/item representations to sam-\nple relevant knowledge, and subsequently proposes a local-global\ncontrastive mechanism to enhance noise-irrelevant representation\nlearning. Extensive experiments conducted on three benchmark\ndatasets show the superior performance of our proposed method\nover the state-of-the-arts. And online A/B testing results on Al-\nibaba large-scale industrial recommendation platform also indicate\nthe real-scenario effectiveness of KGTN. The implementations are\navailable at: https://github.com/CCIIPLab/KGTN.\nCCS CONCEPTS\nâ€¢ Information systems â†’Recommender systems.\nKEYWORDS\nKnowledge Enhanced Recommendation, Graph Transformer, Graph\nNeural Networks\nACM Reference Format:\nDing Zou, Wei Wei, Feida Zhu, Chuanyu Xu, Tao Zhang, and Chengfu\nHuo. 2024. Knowledge Enhanced Multi-intent Transformer Network for\nRecommendation. In Companion Proceedings of the ACM Web Conference\n2024 (WWW â€™24 Companion), May 13â€“17, 2024, Singapore, Singapore. ACM,\nNew York, NY, USA, 9 pages. https://doi.org/10.1145/3589335.3648296\n1 INTRODUCTION\nKnowledge graphs (KGs) have emerged as a promising approach\nto enhance the accuracy and interpretability of recommender sys-\ntems in both academic and industry scenarios. By incorporating\nentities and relations, KGs provide a rich source of information\nfor user/item representation learning, which not only captures the\ndiverse relationships among items (such as the same item brand),\narXiv:2405.20565v1  [cs.IR]  31 May 2024\nWWW â€™24 Companion, May 13â€“17, 2024, Singapore, Singapore. Ding Zou et al.\nğ‘¢1 \nğ‘–1 \nğ‘–2 \nğ‘’1 \nğ‘’2 \nğ‘1 \n...\nğ‘2 \nğ‘ğ‘˜ \nğ‘1 \n: Passing time\n: Long-term interest\n: Social reason\nğ‘2 \nğ‘ğ‘˜ \n...\nğ‘’3 \nğ‘’4 \nğ‘–ğ‘› \n   \n   \n   \n   \n   \nğ‘¢2 \n   \n   \n   \n: Style is\n: Type of\n: Color is\n(a) Intent Case\nMusic Book Movie\nCF-based 0.174 0.0525 0.1512\nKG-based 0.1532 0.048 0.1364\n0\n0.05\n0.1\n0.15\n0.2\nMusic Book Movie\nRecall@20\nDatasets\nModels\nCF-based\nKG-based (b) Comparison\nFigure 1: (a) A simple case for illustrating multiple user in-\ntents with global information; (b)Performance comparison.\nbut also allows for the interpretation of user preferences (such as\nattributing a userâ€™s selection of a clothing to its fashionable style).\nIn an effort to effectively integrate the item-side KG information\ninto recommendation, considerable research efforts have been de-\nvoted to Knowledge Enhanced Recommendation (aka. KGR). Early\nstudies [7, 19, 33] directly integrate knowledge graph embeddings\nwith items to enhance their representations. Some subsequent stud-\nies [6, 16, 25] enrich the interactions via meta-paths that capture\nrelevant connectivities between users and items with KG. They\neither select prominent paths over KG [17], or represent the interac-\ntions with multi-hop paths from users to items [6, 25]. Nevertheless,\nmost of them heavily rely on manually designed meta-paths, which\nmakes it hard to optimize in reality. As a result, later methods have\nembraced Graph Neural Networks (GNNs) [22, 23] to automatically\naggregate high-order information over KG, which iteratively inte-\ngrate multi-hop neighbors into representations and have demon-\nstrated promising performance for recommendation. Most recently,\nthere have been efforts to incorporate Contrastive Learning (CL)\ninto KGR for addressing noisy knowledge and long-tail problems\n[27, 29, 37] via contrasting the user-item (collaborative part) and\nitem-entity (knowledge part) graphs.\nHowever, current KGR methods usually bring poor performance\nin large-scale industry scenarios, due to their commonly overlook-\ning two crucial factors: 1) Usersâ€™ multiple intents underlying inter-\naction behavior. For instance, as depicted in Figure 1(a), users may\nhave diverse intentions when shopping in Alibaba E-commerce\nplatform, such as long-term interest, passing time, or social reason,\netc. 2) Redundant Knowledge information. In the context of user\nintents, some knowledge facts in the KG may be irrelevant noise\n[3], which can potentially disrupt the learning process of user/item\nrepresentations. As shown in Figure 1(b), incorporating KGs may\nresult in a worse model performance than the models without KG\nutilization (the details of comparison could refer to Section 4.2 ).\nBut still, itâ€™s not trivial to model user intents in KGR, since user\nintents may be composed of multiple heterogeneous information,\nincluding items, relations, and entities. Previous multi-intent mod-\neling methods usually define the intents as a linear combination of\neither interacted items [24] or entire relation sets [23], then update\nthe intent representations through local aggregation in the user-\nintent-item heterogeneous graph. Nevertheless, such a multi-intent\nlearning paradigm may not fully meet the requirements for KGR, as\nit neglects the global information in intent defining and learning. To\nillustrate this, we present an example in Figure 1(a). In this example,\nuser ğ‘¢1 may purchase the item ğ‘–1 for the intent ğ‘1 of long-term\ninterest, resulting in a focus on clothing style ( e.g., whether it is\nfashionable), which means intent ğ‘1 is associated with KG relation\nğ‘Ÿ1 and entity ğ‘’1; while ğ‘¢1 may buy the item ğ‘–ğ‘› for the intent ğ‘ğ‘˜ of\nsocial reason (such as friend ğ‘¢2 recommend), which means intent\nğ‘ğ‘˜ is associated with user ğ‘¢2 and item ğ‘–ğ‘˜.\nIn this paper, we focus on modeling user intents behind interac-\ntion behaviors with global collaborative (user-item) and knowledge\n(item-relation-entity) information, and exploiting these modeled\nintents to guide knowledge sampling, facilitating fine-grained and\naccurate user/item representation learning. We propose a novel\nmodel, KGTN, which comprises two essential components for solv-\ning the foregoing limitations: i) Global Intents Modeling with Graph\nTransformer. We predefineğ¾ intent representations for user/item,\nthen learn these intents with global information from collaborative\nand knowledge graphs. Specifically, it first merges knowledge infor-\nmation into items, then propose a novel graph transformer in the\nuser-item graph to learn global intents and generate intent-aware\nuser/item representations. ii) Knowledge Contrastive Denoising\nunder Intents. KGTN first exploits the intent-aware user/item rep-\nresentations to guide the knowledge sampling, effectively pruning\nthe irrelevant knowledge. Then a novel local-global contrastive\nmechanism is proposed here to denoise the user/item representa-\ntions. Empirically, KGTN outperforms the state-of-the-art models\non three benchmark datasets in offline testing, and achieves signifi-\ncant improvements in online A/B testing.\nOur contributions of this work can be summarized as follows:\nâ€¢General Aspects: We emphasize the importance of intent mod-\neling with global information, which plays a crucial role in fine-\ngrained representation learning and knowledge denoising.\nâ€¢Novel Methodologies: We propose a novel model KGTN, which\nmodels user intents from global signals with a novel graph trans-\nformer; and denoises item representations with i) knowledge\ndenoising under intents, and ii) local-global graph contrastive\nlearning.\nâ€¢Multifaceted Experiments: We conduct extensive offline ex-\nperiments on three benchmark datasets and online A/B testing\non Alibaba recommendation platform. The results demonstrate\nthe advantages of our KGTN in better representation learning.\n2 PROBLEM FORMULATION\nIn this section, we begin by formulating the structural data of CF\n(user-item interactions) and KG (item-relation-entity knowledge)\nin KGR, then present the problem statement.\nInteraction Data. In a typical recommendation scenario, let U=\n{ğ‘¢1,ğ‘¢2,...,ğ‘¢ ğ‘€}be a set of ğ‘€ users and V= {ğ‘£1,ğ‘£2,...,ğ‘£ ğ‘}a set\nof ğ‘ items. Let Y âˆˆRğ‘€Ã—ğ‘ be the user-item interaction matrix,\nwhere ğ‘¦ğ‘¢ğ‘£ = 1 indicates that user ğ‘¢engaged with item ğ‘£, such as\nbehaviors like clicking or purchasing; otherwise ğ‘¦ğ‘¢ğ‘£ = 0.\nKnowledge Graph. A KG stores luxuriant real-world facts asso-\nciated with items, encompassing item attributes or external com-\nmonsense knowledge, in the form of a heterogeneous graph [16].\nLet G= {(â„,ğ‘Ÿ,ğ‘¡ )| â„,ğ‘¡ âˆˆE,ğ‘Ÿ âˆˆR} be the KG, where â„, ğ‘Ÿ, ğ‘¡ rep-\nresent the head, relation, tail of a knowledge triple, respectively;\nEand Rdenote the sets of entities and relations in G. In many\nrecommendation scenarios, an item ğ‘£ âˆˆ Vcorresponds to one\nentity ğ‘’ âˆˆE. We hence establish a set of item-entity alignments\nKnowledge Enhanced Multi-intent Transformer Network for Recommendation WWW â€™24 Companion, May 13â€“17, 2024, Singapore, Singapore.\nA= {(ğ‘£,ğ‘’)|ğ‘£ âˆˆV,ğ‘’ âˆˆE}, where (ğ‘£,ğ‘’)indicates that item ğ‘£can be\naligned with an entity ğ‘’in KG. With the alignments between items\nand KG entities, KG is able to profile items and offer complementary\ninformation to the interaction data.\nProblem Statement. Given the user-item interaction matrixY and\nthe KG G, KGR aims to learn a function that can predict how likely\na user would adopt an item.\n3 METHODOLOGY\nWe now present the proposed Knowledge Enhanced Multi-intent\nTransformer Network for Recommendation (KGTN). KGTN aims\nat modeling user intents with global information and exploiting\nuser intents to denoise KG for accurate and robust user/item rep-\nresentation learning. Figure 2 displays the framework of KGTN,\nwhich mainly consists of two key components: 1) Global Intent\nModeling with graph transformer. Initially, KGTN defines a set of\nğ¾ learnable global intents for users and items. It then models these\nintents and learns intent-aware user/item representations, via in-\ntegrating global signals with a graph transformer in the user-item\ngraph, where knowledge information has been encoded into items.\n2) Knowledge Contrastive Denoising under intents. It first exploits\nthe learned intent-aware user/item representations to sample intent-\nrelevant knowledge, then designs a contrastive self-supervised\ntask between the local aggregation and global aggregation fea-\ntures within the sampled graph to facilitate robust representation\nlearning.\n3.1 Global Intents Modeling with Graph\nTransformer\n3.1.1 Intent Initialization with Global signals. When interacting\nwith items, users often have diverse intents, such as preferences\nfor specific clothing brands and styles, friends recommending, or\npassing time with randomly clicking [ 14, 23]. To capture these\ndiverse intents, we assume ğ¾ different intents ğ‘ğ‘¢ and ğ‘ğ‘£ from the\nuser and item sides, respectively, where the intents on the item\nside can also be understood as the theme or context of the item, for\nexample, a user who intends to purchase a fashionable dress may\nlike clothes of â€œyoungâ€ topic. Our predictive objective of user-item\npreference can be presented as follows:\nâˆ«\nğ‘ğ‘¢\nâˆ«\nğ‘ğ‘£\nğ‘ƒ(ğ‘¦,ğ‘ğ‘¢,ğ‘ğ‘£|ğ‘¢,ğ‘£)ğ‘‘ğ‘ğ‘£ğ‘‘ğ‘ğ‘¢ =\nğ¾âˆ‘ï¸\nğ‘˜\nğ‘ƒ(ğ‘¦,ğ‘ğ‘˜\nğ‘¢,ğ‘ğ‘˜\nğ‘£|ğ‘¢,ğ‘£). (1)\nSpecifically, we define ğ¾ global intent prototypes {cğ‘˜ğ‘¢ âˆˆRğ‘‘}ğ¾\nğ‘˜=1\nand {cğ‘˜ğ‘£ âˆˆRğ‘‘}ğ¾\nğ‘˜=1 for user and item, respectively. With these pre-\ndefined intent prototypes, we then are supposed to integrate them\ninto user/item representations, and update them with related global\nsignals.\n3.1.2 Intent Modeling with graph transformer. Towards accurately\nmodeling user intents with global information and learning intent-\naware user/item representations, we perform an intent-aware infor-\nmation propagation with these learnable intents. Specifically, intent-\naware user/item embeddings are acquired by an attentive sum of\nthe intent prototypes, and user/item embeddings of each layer are\nupdated by aggregating the global user/item/relation/entity signals.\nFormally, we could get intent-aware user/item representations\nat the ğ‘™-th user/item embedding layer, by aggregating information\nacross different ğ¾learnable intent prototypes (including cğ‘¢ and cğ‘£),\nusing the following design:\neğ‘™\nğ‘¢ =\nğ¾âˆ‘ï¸\nğ‘˜\ncğ‘˜\nğ‘¢ğ‘ƒ(cğ‘˜\nğ‘¢|eğ‘™\nğ‘¢), (2)\nğ‘ƒ(cğ‘˜\nğ‘¢|eğ‘™\nğ‘¢)= ğœ‚(eğ‘™âˆ’1âŠ¤ğ‘¢ cğ‘˜ğ‘¢)\nÃğ¾\nğ‘˜â€²ğœ‚(eğ‘™âˆ’1âŠ¤ğ‘¢ cğ‘˜â€²\nğ‘¢ )\n, (3)\nwhere the ğ‘ƒ(cğ‘˜ğ‘¢|eğ‘™ğ‘¢)and ğ‘ƒ(cğ‘˜ğ‘£|eğ‘™ğ‘£)denotes the importance score of\ncğ‘˜ğ‘¢ for ğ‘™âˆ’th user embeddings that has encodes the global signals.\nSimilarly, the ğ‘ƒ(cğ‘˜ğ‘£|eğ‘™ğ‘£)denotes the importance score of cğ‘˜ğ‘¢ for ğ‘™âˆ’th\nitem embeddings.\nAs for the way of calculating theğ‘™âˆ’th user/item embeddings, we\npropose to adopt a two-step process to encode the global user/item/\nrelation/entity information in the whole heterogeneous graph. The\nfirst step is to merge the knowledge information (including both\nrelation and entity) into item embeddings with a proposed relation-\naware graph aggregation, making the item representation more\ncomprehensive and informative. It injects the relational context\ninto the embeddings of the neighboring entities, and weighting\nthem with the knowledge rationale scores (Itâ€™s worth noting that\nitems are a subset of knowledge entities), as follows:\ne(ğ‘™+1)\nğ‘– = 1\n|Nğ‘–|\nâˆ‘ï¸\n(ğ‘Ÿ,ğ‘£)âˆˆNğ‘–\nğ›½(ğ‘–,ğ‘Ÿ,ğ‘£ )eğ‘Ÿ âŠ™e(ğ‘™)\nğ‘£ ,\nğ›½(ğ‘–,ğ‘Ÿ,ğ‘£ )= softmax\n\u0010\n(eğ‘–||eğ‘Ÿ)ğ‘‡ Â·(eğ‘£||eğ‘Ÿ)\n\u0011\n=\nexp\n\u0010\n(eğ‘–||eğ‘Ÿ)ğ‘‡ Â·(eğ‘£||eğ‘Ÿ)\n\u0011\nÃ\n(ğ‘£â€²,ğ‘Ÿ)âˆˆË†N(ğ‘–)\nexp\n\u0010\n(eğ‘–||eğ‘Ÿ)ğ‘‡ Â·(eğ‘£â€²||eğ‘Ÿ)\n\u0011,\n(4)\nwhere ||denotes concat operation,ğ‘ğ‘– denotes the set of neighboring\nentities.\nThen the second step is to apply a novel graph transformer\namong user-item graph, which encodes global user/item/entity in-\nformation into user/item representations. By doing so, the user/item\nrepresentations of each layer are integrated with global signals,\nwhich would be exploited into intent modeling and representation\nupdating, as follows:\neğ‘™+1\nğ‘¢ =\nâˆ‘ï¸\nğ‘–\nğ»\f\f\f\n\f\f\f\nâ„=1\nğ‘šğ‘¢,ğ‘–ğ›½â„\nğ‘¢,ğ‘–Wâ„\nVeğ‘™\nğ‘–; ğ‘šğ‘¢,ğ‘– =\n\u001a1 if (ğ‘¢,ğ‘–)âˆˆ Y\n0 otherwise\nğ›½â„\nğ‘¢,ğ‘– =\nexp Â¯ğ›½â„\nğ‘¢,ğ‘–\nÃ\nğ‘– exp Â¯ğ›½â„\nğ‘¢,ğ‘–\n; Â¯ğ›½â„\nğ‘£,ğ‘£â€² =\n(Wâ„\nQ Â·eğ‘™ğ‘¢)âŠ¤Â·(Wâ„\nK Â·eğ‘™\nğ‘–)\nâˆšï¸\nğ‘‘/ğ»\n, (5)\nwhere ğ» denotes the number of attention heads (indexed by â„).\nğ‘šğ‘£,ğ‘£â€² is the binary indicator to decide whether to calculate the\nattentive relations between user ğ‘¢ and item ğ‘–. ğ›½â„\nğ‘¢,ğ‘– denotes the\nattention weight for user-item interaction pair (ğ‘¢,ğ‘–)w.r.t. the â„-\nth head representation space. Wâ„\nQ,Wâ„\nK,Wâ„\nV âˆˆ Rğ‘‘/ğ»Ã—ğ‘‘ denotes\nthe query, key, the value embedding projection for theâ„-th head,\nrespectively.\nWWW â€™24 Companion, May 13â€“17, 2024, Singapore, Singapore. Ding Zou et al.\nKnowledge\nInjection\nğ‘¢1 \nğ‘–1 \nğ‘¢1 \nğ‘–2 \nğ‘¢2 \nğ‘–2 \n...\nğ‘¢ğ‘€ \nğ‘–ğ‘ \nGlobal Intent Modeling with Graph Transformer\nSampled graph\nğ‘¢1 \nğ‘¢2 \nğ‘–1 \nğ‘–2 \nğ‘–3 \nğ‘–1 \nğ‘–2 \nğ‘–3 \nLocal-Global Contrastive LearningLight-GCN\nBPR\nRecommendation\nCL\nInfoNCE\nğ‘¢1 \nğ‘¢2 \nğ‘–1 \nğ‘–2 \nğ‘–3 \nğ‘’1 \nğ‘’2 \nğ‘’3 \nğ‘–1 \nğ‘–2 \nğ‘–3 \nğ‘1 \nğ‘2 \n...\nğ‘’4 \nğ‘ğ¾ \nLocal \nGlobal\n         ğ‘» Â·         / \n d/H \nH\nğ›½ğ‘¢,ğ‘–\nâ„ = exp ğ›½ğ‘¢,ğ‘–\nâ„\n expâ¡ğ›½ğ‘¢,ğ‘–\nâ„\nğ‘–\n \n ğ›½ğ‘¢,ğ‘–\nâ„\nğ‘–\n \nÂ·    +  \nğ‘Šğ‘„\nâ„ \nğ‘Šğ¾\nâ„ \nğ‘Šğ‘‰\nâ„ \nğ‘ğ‘¢ \nğ‘ğ‘– \nIntent-aware \nEmbeddings\neğ‘¢\nğ‘™ =  cğ‘¢\nğ‘˜\nğ¾\nğ‘˜\nğ‘ƒ(cğ‘¢\nğ‘˜|eğ‘¢\nğ‘™ ) \nFigure 2: Overall framework illustration of the proposed KGTN model. Best viewed in color.\nBy integrating global information into users/items, we could\nlearn intent-aware user/item representations and update the learn-\nable intents according to Equation 2.\n3.2 Knowledge Contrastive Denoising under\nIntents\nIt is intuitive that noisy or irrelevant connections between entities in\nknowledge graphs can lead to suboptimal representation learning,\nwhich is opposite to original purpose of introducing the KG. To\neliminate the noise effect in the KG and distill informative signals\nthat benefit the recommendation task, we propose to highlight\nimportant connections consistent to user intents, while removing\nthe irrelevant ones.\n3.2.1 Knowledge Sampling under intents. With the intent-aware\nuser/item representations, we then try to denoise the item-entity\ngraph by removing the irrelevant edges and nodes and sampling the\nimportant ones. We first exploit the intent-aware representations\nto calculate the importance score of knowledge triplets ( i.e., the\nitem-relation-entity pairs) same as Equation 4, then add the Gumbel\nnoise [8] to the learned importance scores to improve the sampling\nrobustness, as follows:\nğ›½(ğ‘–,ğ‘Ÿ,ğ‘£ )= softmax\n\u0010\n(eğ‘–||eğ‘Ÿ)ğ‘‡ Â·(eğ‘£||eğ‘Ÿ)\n\u0011\nğ›½(ğ‘–,ğ‘Ÿ,ğ‘£ )= ğ›½(ğ‘–,ğ‘Ÿ,ğ‘£ )âˆ’log (âˆ’log(ğœ–)); ğœ– âˆ¼Uniform (0,1),\n(6)\nwhere ğœ– is a random variable sampled from a uniform distribution.\nThen it follows a top-k sampling strategy for generating the new\nitem-entity graph that removes the irrelevant edges and nodes:\nbğ›½(ğ‘–,ğ‘Ÿ,ğ‘£ )=\n\u001a ğ›½(ğ‘–,ğ‘Ÿ,ğ‘£ ), ğ›½ (ğ‘–,ğ‘Ÿ,ğ‘£ )âˆˆ top-k (ğ›½(ğ‘–,ğ‘Ÿ,ğ‘£ )),\n0, otherwise, (7)\nwhere bğ›½(ğ‘–,ğ‘Ÿ,ğ‘£ )is the sampled triples in item-entity graph, which\nwould be used to replace the original graph structure in the follow-\ning user/item representation learning.\n3.2.2 Local-Global Knowledge Contrastive Learning. With the sam-\npled item-entity graph, we then propose to iteratively update the\nintent-aware representations in it. And inspired by previous con-\ntrastive learning based methods that align the item representations\nfrom KG and CF to denoise, we further propose a local-global con-\ntrastive mechanism to improve the robustness of representation\nlearning.\nSpecifically, we exploit the user-item graph and sampled item-\nentity graph to perform light information aggregation with intent-\naware user/item representationseğ‘¢,eğ‘– as input z(0)\nğ‘¢ ,z(0)\nğ‘– , for acquir-\ning a robust and effective intent-aware user/item representations,\nas follows:\nz(ğ‘™+1)\nğ‘– = 1\n|Nğ‘– |\nÃ\n(ğ‘Ÿ,ğ‘£)âˆˆNğ‘–\neğ‘Ÿ âŠ™z(ğ‘™)\nğ‘£ ,\nz(ğ‘™+1)\nğ‘¢ = 1\n|Nğ‘¢ |\nÃ\nğ‘–âˆˆNğ‘¢\nz(ğ‘™)\nğ‘– ,\n(8)\nwhere z(0)\nğ‘¢ ,z(0)\nğ‘– memorize the global signals, and we hence get final\nrepresentations of user/item z(ğ‘™)\nğ‘¢ ,z(ğ‘™)\nğ‘– (ğ‘™ âˆˆğ¿).\nBesides the supervised user/item representation learning, we\npropose to perform a contrastive learning between the nodes em-\nbeddings that encode global signals and local signals, which is\ndifferent from traditional cl-based methods that contrast the CF\nand KG parts. We perform information aggregation in the sam-\npled graph with the initial user/item representations e(0)\nğ‘¢ ,e(0)\nğ‘– to\nacquire the local results z(ğ‘™)\nğ‘¢,ğ‘™ğ‘œğ‘ğ‘ğ‘™,z(ğ‘™)\nğ‘–,ğ‘™ğ‘œğ‘ğ‘ğ‘™ (ğ‘™ âˆˆğ¿), while utilizing the\nintent-aware user/item representations eğ‘¢,eğ‘– that contains global\nsignals to acquire the global results z(ğ‘™)\nğ‘¢ ,z(ğ‘™)\nğ‘– (ğ‘™ âˆˆğ¿). Then perform\nlayer-wise contrastive learning between local and global results.\nThe local aggregation layer embeddingsz(ğ‘™)\nğ‘¢,ğ‘™ğ‘œğ‘ğ‘ğ‘™,z(ğ‘™)\nğ‘–,ğ‘™ğ‘œğ‘ğ‘ğ‘™ and global\naggregation layer embeddings z(ğ‘™)\nğ‘¢ ,z(ğ‘™)\nğ‘– are made to be contrasted\nin a layer-wise way. We generate each positive pair using the em-\nbeddings of the same user (item) from the local view and each of\nthe global view, and other nodes form the negative pairs. We could\nget the contrastive loss of users as follows:\nLğ‘¢ğ‘ = 1\nğ¿\nğ¿Ã\nğ‘™=0\nâˆ’log\nğ‘’ğ‘¥ğ‘(s\n\u0010\nzğ‘™\nğ‘¢,zğ‘™\nğ‘¢,ğ‘™ğ‘œğ‘ğ‘ğ‘™\n\u0011\n/ğœ)\nÃ\nğ‘˜â‰ ğ‘¢\nğ‘’ğ‘¥ğ‘(s\n\u0010\nzğ‘™ğ‘¢,zğ‘™\nğ‘˜\n\u0011\n/ğœ)+Ã\nğ‘˜â‰ ğ‘¢\nğ‘’ğ‘¥ğ‘(s\n\u0010\nzğ‘™ğ‘¢,zğ‘™\nğ‘˜,ğ‘™ğ‘œğ‘ğ‘ğ‘™\n\u0011\n/ğœ)\n, (9)\nwhere s(Â·)denotes the cosine similarity calculating, andğœdenotes a\ntemperature parameter. And similarly we could get the contrastive\nloss of item Lğ‘–ğ‘. By summing the two contrastive losses we hence\nhave the total local-global contrastive loss Lğ‘.\nKnowledge Enhanced Multi-intent Transformer Network for Recommendation WWW â€™24 Companion, May 13â€“17, 2024, Singapore, Singapore.\nBook-CrossingMovieLens-1MLast.FM\nUser-item\nInteraction\n# users 17,860 6,036 1,872\n# items 14,967 2,445 3,846\n# interactions 139,746 753,772 42,346\nKnowledge\nGraph\n# entities 77,903 182,011 9,366\n# relations 25 12 60\n# triplets 151,500 1,241,996 15,518\nTable 1: Statistics for the three datasets.\n3.3 Model Prediction\nAfter learning intent-aware user/item representations with global\nsignals and performing contrastive learning between local and\nglobal information, we have multi-layer intent-aware representa-\ntions for user/item. By summing all the layersâ€™ representations, we\nhave the final user/item representations and predict their matching\nscore through inner product, as follows:\nzğ‘¢ = z(0)\nğ‘¢ +Â·Â·Â·+ z(ğ¾)\nğ‘¢ , zğ‘– = z(0)\nğ‘– +Â·Â·Â·+ z(ğ¾)\nğ‘– .\nË†y(ğ‘¢,ğ‘–)= zâŠ¤ğ‘¢zğ‘–. (10)\nBy adopting a BPR loss [15] to reconstruct the historical data,\nwhich encourages the prediction scores of a userâ€™s historical items\nto be higher than the unobserved items, we acquire the supervised\nloss:\nLBPR =\nâˆ‘ï¸\n(ğ‘¢,ğ‘–,ğ‘—)âˆˆğ‘‚\nâˆ’ln ğœ \u0000Ë†yğ‘¢ğ‘– âˆ’Ë†yğ‘¢ğ‘—\n\u0001 , (11)\nwhere ğ‘¶ =\n\b\n(ğ‘¢,ğ‘–,ğ‘— )|( ğ‘¢,ğ‘–)âˆˆ ğ‘¶+,(ğ‘¢,ğ‘— )âˆˆ ğ‘¶âˆ’\t\nis the training dataset\nconsisting of the observed interactions ğ‘¶+and unobserved coun-\nterparts ğ‘¶âˆ’; ğœ is the sigmoid function.\n3.4 Multi-task Training\nTo combine the recommendation task with the self-supervised task,\nwe optimize the whole model with a multi-task training strategy.\nWe combine the local-global contrastive loss with BPR loss, and\nlearn the model parameter via minimizing the following objective\nfunction:\nLğ¾ğºğ‘‡ğ‘ = LBPR +ğ›¼Lğ‘ +ğœ†âˆ¥Î˜âˆ¥2\n2, (12)\nwhere Î˜ is the model parameter set, ğ›¼ is a hyperparameter to de-\ntermine the local-global contrastive loss ratio, ğ›½ and ğœ† are two\nhyperparameters to control the contrastive loss and ğ¿2 regulariza-\ntion term, respectively.\n4 EXPERIMENT\nAiming to answer the following research questions, we conduct\nboth offline experiments and online A/B tests on three public\ndatasets and Alibaba online platform:\nâ€¢RQ1: How does KGTN perform, compared to present mod-\nels?\nâ€¢RQ2: How do the main components in KGTN affect its ef-\nfectiveness?\nâ€¢RQ3: How do different hyper-parameter settings affect KGTN?\nâ€¢RQ4: How does KGTN perform with noisy injection?\nâ€¢RQ5: How does KGTN perform in a live system serving\nbillions of users?\n4.1 Experiment Settings\n4.1.1 Dataset and Metrics. Three benchmark datasets are utilized\nto evaluate the effectiveness of KGTN: Last.FM 1, Book-Crossing 2,\nand MovieLens-1M3. The detailed statistics of them are summarized\nin Table 1, which vary in size and sparsity and make our experi-\nments more convincing. As for the data pre-process, we first follow\nRippleNet [18] to transform their explicit feedback into implicit\none, and randomly sample negative samples from his unwatched\nitems with the size equal to his positive ones to construct the neg-\native parts. As for the sub-KG construction, we follow RippleNet\n[18] and use Microsoft Satori4 to construct it for MovieLens-1M,\nBook-Crossing, and Last.FM datasets. Each sub knowledge graph\nthat follows the triple format is a subset of the whole KG with a\nconfidence level greater than 0.9.\nWe evaluate our method in two experimental scenarios: (1) In\nclick-through rate (CTR) prediction, we apply the trained model\nto predict each interaction in the test set. We adopt two widely\nused metrics [18, 21] ğ´ğ‘ˆğ¶ and ğ¹1 to evaluate CTR prediction. (2) In\ntop-ğ¾ recommendation, we use the trained model to select ğ¾ items\nwith the highest predicted click probability for each user in the test\nset, and we choose Recall@ğ¾ to evaluate the recommended sets.\n4.1.2 Baselines. To demonstrate the effectiveness of our proposed\nKGTN, we compare it with four types of KGR methods: CF-based\nmethods (BPRMF [15]), embedding-based method (CKE [33], Rip-\npleNet [ 18]), path-based method (PER [ 32]), GNN-based meth-\nods(KGCN [21], KGNN-LS [20], KGAT [22], CKAN [26], KGIN [23],\nCG-KGR [3]), CL-based methods (KGCL[29], MCCLK [37]).\n4.1.3 Parameter Settings. We implement our KGTN and all base-\nlines in Pytorch and carefully tune the key parameters. For a fair\ncomparison, we fix the embedding size to 64 for all models, and the\nembedding parameters are initialized with the Xavier method [4].\nWe optimize our method with Adam [9] and set the batch size to\n2048. A grid search is conducted to confirm the optimal settings, we\ntune the learning rateğœ‚among{0.0001,0.0003,0.001,0.003}and ğœ†of\nğ¿2 regularization term among {10âˆ’7,10âˆ’6,10âˆ’5,10âˆ’4,10âˆ’3}. Other\nhyper-parameter settings are provided in Table 1. The best settings\nfor hyper-parameters in all comparison methods are researched by\neither empirical study or following the original papers.\n4.2 Performance Comparison (RQ1)\nWe report the empirical results of all methods in Table 2 and Table\n3. The improvements and statistical significance test are performed\nbetween KGTN and the strongest baselines (highlighted with un-\nderline). Analyzing such performance comparison, we have the\nfollowing observations:\nâ€¢Our proposed KGTN achieves the best results. KGTN consis-\ntently outperforms all baselines across three datasets in terms of\nall measures, which achieves significant improvements over the\n1https://grouplens.org/datasets/hetrec-2011/\n2http://www2.informatik.uni-freiburg.de/~cziegler/BX/\n3https://grouplens.org/datasets/movielens/1m/\n4https://searchengineland.com/library/bing/bing-satori\nWWW â€™24 Companion, May 13â€“17, 2024, Singapore, Singapore. Ding Zou et al.\nModel Book-Crossing MovieLens-1M Last.FM\nAUC F1 AUC F1 AUC F1\nBPRMF 0.6583(âˆ’13.18%) 0.6117(âˆ’7.59%) 0.8920(âˆ’4.52%) 0.7921(âˆ’7.21%) 0.7563(âˆ’13.41%) 0.7010(âˆ’9.95%)\nCKE 0.6759(âˆ’11.42%) 0.6235(âˆ’6.41%) 0.9065(âˆ’3.07%) 0.8024(âˆ’6.18%) 0.7471(âˆ’14.33%) 0.6740(âˆ’12.65%)\nRippleNet 0.7211(âˆ’6.90%) 0.6472(âˆ’4.04%) 0.9190(âˆ’1.82%) 0.8422(âˆ’2.20%) 0.7762(âˆ’11.42%) 0.7025(âˆ’9.80%)\nPER 0.6048(âˆ’18.53%) 0.5726(âˆ’11.50%) 0.7124(âˆ’22.48%) 0.6670(âˆ’19.72%) 0.6414(âˆ’24.90%) 0.6033(âˆ’19.72%)\nKGCN 0.6841(âˆ’10.60%) 0.6313(âˆ’5.63%) 0.9090(âˆ’2.82%) 0.8366(âˆ’2.76%) 0.8027(âˆ’8.77%) 0.7086(âˆ’9.19%)\nKGNN-LS 0.6762(âˆ’11.39%) 0.6314(âˆ’5.62%) 0.9140(âˆ’2.32%) 0.8410(âˆ’2.32%) 0.8052(âˆ’8.52%) 0.7224(âˆ’7.81%)\nKGAT 0.7314(âˆ’5.87%) 0.6544(âˆ’3.32%) 0.9140(âˆ’2.32%) 0.8440(âˆ’2.02%) 0.8293(âˆ’6.11%) 0.7424(âˆ’5.81%)\nCKAN 0.7420(âˆ’4.81%) 0.6671(âˆ’2.05%) 0.9082(âˆ’2.90%) 0.8410(âˆ’2.32%) 0.8418(âˆ’4.86%) 0.7592(âˆ’4.13%)\nKGIN 0.7273(âˆ’6.28%) 0.6614(âˆ’2.62%) 0.9190(âˆ’1.82%) 0.8441(âˆ’2.01%) 0.8486(âˆ’4.18%) 0.7602(âˆ’4.03%)\nCG-KGR 0.7498(âˆ’4.03%) 0.6689(âˆ’1.87%) 0.9110(âˆ’2.62%) 0.8359(âˆ’2.83%) 0.8336(âˆ’5.68%) 0.7433(âˆ’5.72%)\nKGCL 0.7453(âˆ’4.48%) 0.6679(âˆ’1.97%) 0.9184(âˆ’1.88%) 0.8437(âˆ’2.05%) 0.8455(âˆ’4.49%) 0.7596(âˆ’4.00%)\nMCCLK 0.7625(âˆ’2.76%) 0.6777(âˆ’0.99%) 0.9252(âˆ’1.20%) 0.8559(âˆ’0.83%) 0.8663(âˆ’2.41%) 0.7753(âˆ’2.43%)\nKGTN 0.7901* 0.6876* 0.9372* 0.8642* 0.8904* 0.7996*\nTable 2: The result of ğ´ğ‘ˆğ¶ and ğ¹1 in CTR prediction. The best results are in boldface and the second best results are underlined.\n* denotes statistically significant improvement by unpaired two-sample ğ‘¡-test with ğ‘ < 0.001.\nModel Book-Crossing MovieLens-1M Last.FM\nR@10 R@20 R@10 R@20 R@10 R@20\nBPRMF 0.0334 0.0525 0.0939 0.1512 0.0923 0.1740\nCKE 0.0421 0.0562 0.0867 0.1364 0.0780 0.1532\nRippleNet 0.0507 0.0622 0.1082 0.1766 0.0942 0.1520\nPER 0.0322 0.0481 0.0523 0.1204 0.0540 0.1167\nKGCN 0.0496 0.0540 0.0965 0.1720 0.1416 0.1776\nKGNN-LS 0.0422 0.0526 0.1286 0.1757 0.1312 0.1933\nKGAT 0.0522 0.0670 0.1468 0.2296 0.1640 0.2313\nCKAN 0.0462 0.0566 0.1511 0.2400 0.1412 0.2465\nKGIN 0.0555 0.0699 0.1511 0.2404 0.1758 0.2487\nCG-KGR 0.0612 0.0781 0.1621 0.2495 0.1578 0.2106\nKGCL 0.0679 0.0845 0.1633 0.2499 0.1759 0.2471\nMCCLK 0.0769 0.0936 0.1642 0.2503 0.1835 0.2598\nKGTN 0.1060* 0.1275* 0.1841* 0.2826* 0.2104* 0.3106*\nTable 3: The result of ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™@10 and ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™@20 in top-ğ¾ rec-\nommendation.\nstrongest baselines w.r.t.AUC by 2.76%, 1.20%, and 2.41% in Book,\nMovie, and Music respectively, and demonstrates its effectiveness.\nWe attribute such improvements to the following aspects: (1) By\nmodeling user intents with global signals, KGTN is able to learn\nuser/item representations in a more fine-grained and comprehen-\nsive manner; (2) The knowledge sampling strategy under intents\ncould remove less relevant knowledge information for a robust\nrepresentation learning; (3) The local-global contrastive learning\nimproves the representation learning in a self-supervised manner,\nvia contrasting the local and global information.\nâ€¢Incorporating KG not always benefits recommender sys-\ntem. Comparing CKE with BPRMF, leaving KG untapped limits\nthe performance of BPRMF, which shows the effectiveness of KG\ninformation. While PER gets a worse performance than BPRMF,\nwhich means that only incorporating suitable knowledge could\nbenefit the model. This fact stresses the importance of knowledge\nsampling and knowledge denoising.\nâ€¢GNN has a strong power of graph learning. Most of the\nGNN-based methods perform better, suggesting the importance\nof modeling long-range connectivity for graph representation\nlearning. This fact inspires us to go beyond the local aggregation\nparadigm, and to consider the global signals.\nâ€¢Contrastive Learning is effective. The most recently proposed\nCL-based methods have the best performance, which shows the\neffectiveness of incorporating a self-supervised task for improv-\ning representation learning. It inspires us to design proper con-\ntrastive mechanisms to denoise the knowledge and improve the\nmodel performance.\n4.3 Ablation Studies (RQ2)\nAs shown in Figure 3, here we examine the contributions of main\ncomponents in our model to the final performance by comparing\nKGTN with the following three variants: 1) KGTNğ‘¤/ğ‘œ ğ‘†: In this\nvariant, the knowledge sampling under intents module is removed.\n2) KGTNğ‘¤/ğ‘œ ğ¶: This variant removes local-global contrastive mech-\nanism. 3) KGTNğ‘¤/ğ‘œ ğ¼: This variant removes the multi-intent mod-\neling, which means both global intent modeling and knowledge\ncontrastive denoising do not exist in this variant. The results of two\nvariants and KGTN are reported in Figure 3, from which we have\nthe following observations:\nâ€¢Removing both knowledge sampling and local-global con-\ntrasting would degrade model performance, which shows\ntheir effectiveness in representation learning.\nâ€¢Ablating the multi-intent modeling brings the worst perfor-\nmance, which shows the importance of incorporating global\nsignals and considering multiple intents.\n4.4 Sensitivity Analysis (RQ3)\n4.4.1 Impact of graph transformer depth. To study the influence of\ngraph transformer depth, we vary ğ¿in range of {1, 2, 3} on book,\nmovie, and music datasets. As shown in Table 4, KGTN performs\nbest when ğ¿ = 1. It convinces that one iteration is enough for\nKnowledge Enhanced Multi-intent Transformer Network for Recommendation WWW â€™24 Companion, May 13â€“17, 2024, Singapore, Singapore.\nAUC F10.762\n0.768\n0.774\n0.78\n0.786AUC\nBook-Crossing\nKGTN\nKGTNw/o S\nKGTNw/o C\nKGTNw/o I\nAUC F10.932\n0.933\n0.934\n0.935\n0.936\n0.937AUC\nMovieLens-1M\nAUC F10.876\n0.879\n0.882\n0.885\n0.888AUC\nLast.FM\n0.67\n0.674\n0.678\n0.682\n0.686\nF1\n0.857\n0.858\n0.859\n0.86\n0.861\n0.862\n0.863\n0.864\nF1\n0.784\n0.787\n0.79\n0.793\n0.796\n0.799\nF1\nFigure 3: Effect of ablation study.\nBook Movie Music\nAuc F1 Auc F1 Auc F1\nğ¿=1 0.7901 0.6876 0.9372 0.8642 0.8904 0.7996\nğ¿=2 0.7743 0.6783 0.9349 0.8623 0.8834 0.8068\nğ¿=3 0.7603 0.6709 0.9278 0.8481 0.8785 0.7951\nTable 4: Impact of graph transformer depth.\n1 16 32 64 128 2560.580\n0.624\n0.668\n0.712\n0.756\n0.800AUC\nAUC\nF1\n0.664\n0.669\n0.674\n0.679\n0.684\n0.689\nF1\n(a) Book\n1 16 32 64 128 2560.870\n0.876\n0.882\n0.888\n0.894\n0.900AUC\nAUC\nF1\n0.760\n0.768\n0.776\n0.784\n0.792\n0.800\nF1\n (b) Music\nFigure 4: Impact of intent number ğ¾.\n1 0.1 0.01 0.0010.00010.580\n0.624\n0.668\n0.712\n0.756\n0.800AUC\nAUC\nF1\n0.570\n0.594\n0.618\n0.642\n0.666\n0.690\nF1\n(a) Book\n1 0.1 0.01 0.0010.0001\n0.600\n0.660\n0.720\n0.780\n0.840\n0.900AUC\nAUC\nF1\n0.580\n0.624\n0.668\n0.712\n0.756\n0.800\nF1\n (b) Music\nFigure 5: Impact of contrastive loss ratio ğ›¼.\nintegrating the global signals into user/item representations, which\nshows its low reliance on model depth.\n4.4.2 Impact of intent number ğ¾. To investigate the impact of the\nintent number, we vary it from the range {16, 32, 64, 128, 256} and the\nmodel performance is shown in Figure 4, from which we could draw\nthe following conclusions: i) Ignoring the multiple intents (ğ¾ = 1)\nresults in the worst performance, which convinces the effectiveness\nof incorporating multi-intent modeling. ii) The model performance\nfirst arises then drops with the intent increasing. A suitable intents\nnumber boosts the model performance with fine-grained preference\nlearning, while too many intents mean too fine-grained modeling\nand inversely introduce noise into representation learning.\n4.4.3 Impact of contrastive loss ratio ğ›¼. The parameter ğ›¼ deter-\nmines the importance of the contrastive loss during the multi-task\n0 0.05 0.1 0.15 0.2\nNoisy Ratio\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4%Drop Percent\nKGTN\nMCCLK\n(a) Book\n0 0.05 0.1 0.15 0.2\nNoisy Ratio\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0%Drop Percent\nKGTN\nMCCLK (b) Music\nFigure 6: Noise Analysis in Music and Book datasets.\ntraining. Hence we vary it in range {1, 0.1, 0.01, 0.001} to study its\ninfluence. As shown in Figure 5, we observe that: ğ›¼ = 0.1 brings\nthe best model performance, the main reason is that changing the\ncontrastive loss to a fairly equal level to recommendation task loss\ncould boast the model performance.\n4.5 Denoising Analysis (RQ4)\nWe additionally conduct a denoising experiment here, for check-\ning the model robustness under noisy interactions. Specifically,\nwe contaminate the training set by adding a certain proportion\nof adversarial examples (i.e., 5%, 10%, 15%, 20% negative user-item\ninteractions), meanwhile keeping the validation and testing sets\nunchanged, following SGL [28]. This experiment could show the\nmodel ability of noise-irrelevant representation learning, from an\noverall perspective. The experimental results on Baby are shown in\nFigure 6, where the Noisy Ratio means the percentage of noisy inter-\nactions added for the model, and the %Drop Percentage represents\nthe percentage of performance degradation.\nFrom the experimental results, we could clearly find that: Al-\nthough adding noise degrades the model performance of both KGTN\nand MCCLK, the proposed KGTN is clearly less influenced than the\nGNN-based and CL-based MCCLK. It is more apparent with a big-\nger noise ratio, since the performance dropping gap between KGTN\nand MCCLK becomes larger and larger as the noise ratio increases,\nwhich suggests that KGTN is more robust to noisy perturbation.\nWWW â€™24 Companion, May 13â€“17, 2024, Singapore, Singapore. Ding Zou et al.\nMetric Relative Improvement\nItem page view per user +2.3%\nUnique visitor list to order +2.22%\nUnique visitor click through rate +2.3%\nTable 5: Results of online A/B testing.\n4.6 Online A/B Testing (RQ5)\nWe conduct online A/B testing in our recommender system in Al-\nibaba, to validate the benefits of KGTN in the real business scenario.\nIn our online A/B testing, users are randomly divided into A group\nand B group. When group A browses the website, the system recom-\nmends results provided by the previous model, while the group B\nis recommended with results provided by our KGTN model. Exper-\niments are run for three weeks, during which both the control and\nexperiment models are trained continuously with new interactions\nand feedback being used as training data. As shown in Table 5,\nKGTN improves item page view (ipv) per user by 2.3%, unique visi-\ntor list to order (uv l2o) by 2.22%, and unique visitor click through\nrate (uv ctr) by 2.3% relatively compared with DMR [ 12], which\nis the last version of CTR model in our system. This reveals the\npractical application value of KGTN.\n5 RELATED WORK\n5.1 Knowledge Enhanced Recommendation\nExisting Knowledge Enhanced recommendation methods can be\nroughly categorized into three lines: embedding-based, path-based,\nand GNN-based methods. Embedding-based methods [7, 19, 34]\npre-train the KG entity embeddings with knowledge graph em-\nbeddings methods (KGE) [ 1, 10], for enriching item representa-\ntions, such as CKE [33] and KTUP [2], and RippleNet [18]. Path-\nbased methods [16, 31, 35] explore various patterns of connections\namong items in KG to provide additional guidance for the recom-\nmendation, such as PER [ 32] and MCRec[ 6]. KPRN [ 25] further\nautomatically extracts paths between users and items, modeling\nthese paths with RNNs. GNN-based methods are founded on\nthe information aggregation mechanism of graph neural networks\n(GNNs) [5, 30], which integrates multi-hop neighbors into node\nrepresentations, modeling long-range connectivity. KGCN [21] and\nKGNN-LS [20] firstly utilize GNN on KG side, then KGAT[22] pro-\npose to utilizes GAT on the unified user-item-entity heterogeneous\ngraph. Then CKAN [ 26] separately models collaborative signals\nand knowledge signals, and CG-KGR [3] exploits the collaborative\nsignals to guide the aggregation on KG. KGIN [23] models user-item\ninteractions at an intent level, which reveals user intents behind the\nKG interactions and performs GNN on the user-intent-item-entity\ngraph. More recently, CL-based Methods such as MCCLK [37],\nKGIC [38], and KGCL [ 29] combine a contrastive learning para-\ndigm wtih GNN-based methods, and build cross-view contrastive\nframeworks as additional self-discrimination supervision signals to\nenhance robustness.\n5.2 Multi-intent Modeling\nCurrent multi-intent modeling usually adopts a disentangled rep-\nresentation learning paradigm, which splits the user embedding\ninto multiple chunks and tries to learn each chunked emebedding\nrespectively for representing each user intent. In graph representa-\ntion learning area, DisenGCN [13], IPGDN [11] and ADGCN [36]\nadopt such a paradigm and utilize the Hilbert-Schmidt Indepen-\ndence Criterion (HSIC) and adversarial learning for ensuring the\neffectiveness of intent modeling. As for recommendation scenar-\nios, DGCF [24] proposes to disentagnle the user representations\nand adopts a mutual information restraint for the independence\nof all intents. And KGIN [23] considers each intent as an attentive\ncombination of KG relations, then use a local aggregation manner\nfor the intent modeling. MIDGN [39] performs fine-grained intent\ndisentanglement from the hierarchical structure in bundle recom-\nmendation, together with an intent contrastive mechanism. Despite\nthe success of disentangled learning attempts in previous methods,\nthey commonly learns the multi-intent representations with local\ninformation, while ignore the importance of global signals. Hence,\nour work focuses on learning intent-aware representations with\nglobal information, and exploits the intent features to denoise the\nknowledge information.\n6 CONCLUSION\nIn this paper, we focus on modeling multiple intents with global\ninformation, and leveraging intents to denoise the knowledge in-\nformation. We propose a novel framework, KGTN, which achieves\nfine-grained and robust user/item representation learning from two\ndimensions: 1) KGTN models global intents and learns intent-aware\nuser/item representations with a proposed graph transformer, by in-\ntegrating global signals into learnable intents. 2) KGTN exploits the\nuser intents to sample the relevant knowledge, and designs a local-\nglobal contrastive mechanism within the sampled graph, for robust\nrepresentation learning. Extensive experiments on three public\ndatasets demonstrate that KGTN significantly improves the recom-\nmendation performance over baselines on both Click-Through rate\nprediction and Top-K recommendation tasks. Furthermore, the on-\nline A/B testing on recommender system of Alibaba demonstrates\nthe practical application value of KGTN.\nACKNOWLEDGMENTS\nThis work was supported in part by the National Natural Science\nFoundation of China under Grant No. 62276110, No. 62172039 and in\npart by the fund of Joint Laboratory of HUST and Pingan Property\n& Casualty Research (HPL). The authors would also like to thank\nthe anonymous reviewers for their comments on improving the\nquality of this paper.\nREFERENCES\n[1] Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Ok-\nsana Yakhnenko. 2013. Translating embeddings for modeling multi-relational\ndata. In Neural Information Processing Systems (NIPS) . 1â€“9.\n[2] Yixin Cao, Xiang Wang, Xiangnan He, Zikun Hu, and Tat-Seng Chua. 2019.\nUnifying knowledge graph learning and recommendation: Towards a better\nunderstanding of user preferences. In WWW. 151â€“161.\n[3] Yankai Chen, Yaming Yang, Yujing Wang, Jing Bai, Xiangchen Song, and Irwin\nKing. 2022. Attentive Knowledge-aware Graph Convolutional Networks with\nCollaborative Guidance for Personalized Recommendation. In ICDE. 299â€“311.\n[4] Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training\ndeep feedforward neural networks. In AISTATS. 249â€“256.\n[5] William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representation\nlearning on large graphs. In NeurIPS. 1025â€“1035.\nKnowledge Enhanced Multi-intent Transformer Network for Recommendation WWW â€™24 Companion, May 13â€“17, 2024, Singapore, Singapore.\n[6] Binbin Hu, Chuan Shi, Wayne Xin Zhao, and Philip S Yu. 2018. Leveraging\nmeta-path based context for top-n recommendation with a neural co-attention\nmodel. In SIGKDD. 1531â€“1540.\n[7] Jin Huang, Wayne Xin Zhao, Hongjian Dou, Ji-Rong Wen, and Edward Y Chang.\n2018. Improving sequential recommendation with knowledge-enhanced memory\nnetworks. In SIGIR. 505â€“514.\n[8] Eric Jang, Shixiang Gu, and Ben Poole. 2017. Categorical reparametrization with\ngumble-softmax. In International Conference on Learning Representations (ICLR\n2017). OpenReview. net.\n[9] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-\nmization. arXiv preprint arXiv:1412.6980 (2014).\n[10] Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning\nentity and relation embeddings for knowledge graph completion. In AAAI.\n[11] Yanbei Liu, Xiao Wang, Shu Wu, and Zhitao Xiao. 2020. Independence promoted\ngraph disentangled networks. In Proceedings of the AAAI Conference on Artificial\nIntelligence, Vol. 34. 4916â€“4923.\n[12] Ze Lyu, Yu Dong, Chengfu Huo, and Weijun Ren. 2020. Deep match to rank\nmodel for personalized click-through rate prediction. In Proceedings of the AAAI\nConference on Artificial Intelligence , Vol. 34. 156â€“163.\n[13] Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, and Wenwu Zhu. 2019. Disentangled\ngraph convolutional networks. In International conference on machine learning .\nPMLR, 4212â€“4221.\n[14] Xubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, and Chao Huang. 2023. Dis-\nentangled Contrastive Collaborative Filtering. arXiv preprint arXiv:2305.02759\n(2023).\n[15] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.\n2012. BPR: Bayesian personalized ranking from implicit feedback. arXiv (2012).\n[16] Chuan Shi, Binbin Hu, Wayne Xin Zhao, and S Yu Philip. 2018. Heterogeneous\ninformation network embedding for recommendation. IEEE Transactions on\nKnowledge and Data Engineering (2018), 357â€“370.\n[17] Zhu Sun, Jie Yang, Jie Zhang, Alessandro Bozzon, Long-Kai Huang, and Chi Xu.\n2018. Recurrent knowledge graph embedding for effective recommendation. In\nRecSys. 297â€“305.\n[18] Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie,\nand Minyi Guo. 2018. Ripplenet: Propagating user preferences on the knowledge\ngraph for recommender systems. In CIKM. 417â€“426.\n[19] Hongwei Wang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2018. DKN: Deep\nknowledge-aware network for news recommendation. In WWW. 1835â€“1844.\n[20] Hongwei Wang, Fuzheng Zhang, Mengdi Zhang, Jure Leskovec, Miao Zhao,\nWenjie Li, and Zhongyuan Wang. 2019. Knowledge-aware graph neural networks\nwith label smoothness regularization for recommender systems. InSIGKDD. 968â€“\n977.\n[21] Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, and Minyi Guo. 2019. Knowledge\ngraph convolutional networks for recommender systems. In WWW. 3307â€“3313.\n[22] Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng Chua. 2019. Kgat:\nKnowledge graph attention network for recommendation. In SIGKDD. 950â€“958.\n[23] Xiang Wang, Tinglin Huang, Dingxian Wang, Yancheng Yuan, Zhenguang Liu,\nXiangnan He, and Tat-Seng Chua. 2021. Learning Intents behind Interactions\nwith Knowledge Graph for Recommendation. In WWW. 878â€“887.\n[24] Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng\nChua. 2020. Disentangled graph collaborative filtering. In Proceedings of the 43rd\ninternational ACM SIGIR conference on research and development in information\nretrieval. 1001â€“1010.\n[25] Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin Cao, and Tat-Seng\nChua. 2019. Explainable reasoning over knowledge graphs for recommendation.\nIn AAAI, Vol. 33. 5329â€“5336.\n[26] Ze Wang, Guangyan Lin, Huobin Tan, Qinghong Chen, and Xiyang Liu. 2020.\nCKAN: Collaborative Knowledge-aware Attentive Network for Recommender\nSystems. In SIGIR. 219â€“228.\n[27] Ziyang Wang, Wei Wei, Ding Zou, Yifan Liu, Xiao-Li Li, Xian-Ling Mao, and\nMinghui Qiu. 2024. Exploring global information for session-based recommen-\ndation. Pattern Recognition 145 (2024), 109911.\n[28] Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, and\nXing Xie. 2021. Self-supervised graph learning for recommendation. In SIGIR.\n726â€“735.\n[29] Yuhao Yang, Chao Huang, Lianghao Xia, and Chenliang Li. 2022. Knowledge\ngraph contrastive learning for recommendation. In Proceedings of the 45th In-\nternational ACM SIGIR Conference on Research and Development in Information\nRetrieval. 1434â€“1443.\n[30] Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton,\nand Jure Leskovec. 2018. Graph convolutional neural networks for web-scale\nrecommender systems. In SIGKDD. 974â€“983.\n[31] Xiao Yu, Xiang Ren, Quanquan Gu, Yizhou Sun, and Jiawei Han. 2013. Collabora-\ntive filtering with entity similarity regularization in heterogeneous information\nnetworks. IJCAI HINA (2013).\n[32] Xiao Yu, Xiang Ren, Yizhou Sun, Quanquan Gu, Bradley Sturt, Urvashi Khandel-\nwal, Brandon Norick, and Jiawei Han. 2014. Personalized entity recommendation:\nA heterogeneous information network approach. In WSDM. 283â€“292.\n[33] Fuzheng Zhang, Nicholas Jing Yuan, Defu Lian, Xing Xie, and Wei-Ying Ma. 2016.\nCollaborative knowledge base embedding for recommender systems. In SIGKDD.\n353â€“362.\n[34] Yongfeng Zhang, Qingyao Ai, Xu Chen, and Pengfei Wang. 2018. Learn-\ning over knowledge-base embeddings for recommendation. arXiv preprint\narXiv:1803.06540 (2018).\n[35] Huan Zhao, Quanming Yao, Jianda Li, Yangqiu Song, and Dik Lun Lee. 2017. Meta-\ngraph based recommendation fusion over heterogeneous information networks.\nIn SIGKDD. 635â€“644.\n[36] Shuai Zheng, Zhenfeng Zhu, Zhizhe Liu, Shuiwang Ji, Jian Cheng, and Yao Zhao.\n2021. Adversarial graph disentanglement. arXiv preprint arXiv:2103.07295 (2021).\n[37] Ding Zou, Wei Wei, Xian-Ling Mao, Ziyang Wang, Minghui Qiu, Feida Zhu,\nand Xin Cao. 2022. Multi-level cross-view contrastive learning for knowledge-\naware recommender system. In Proceedings of the 45th International ACM SIGIR\nConference on Research and Development in Information Retrieval . 1358â€“1368.\n[38] Ding Zou, Wei Wei, Ziyang Wang, Xian-Ling Mao, Feida Zhu, Rui Fang, and\nDangyang Chen. 2022. Improving knowledge-aware recommendation with multi-\nlevel interactive contrastive learning. InProceedings of the 31st ACM international\nconference on information & knowledge management . 2817â€“2826.\n[39] Ding Zou, Sen Zhao, Wei Wei, Xian-ling Mao, Ruixuan Li, Dangyang Chen, Rui\nFang, and Yuanyuan Fu. 2023. Towards Hierarchical Intent Disentanglement for\nBundle Recommendation. IEEE Transactions on Knowledge and Data Engineering\n(2023)."
}