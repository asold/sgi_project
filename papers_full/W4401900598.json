{
  "title": "Leveraging large language models through natural language processing to provide interpretable machine learning predictions of mental deterioration in real time",
  "url": "https://openalex.org/W4401900598",
  "year": 2024,
  "authors": [
    {
      "id": null,
      "name": "de Arriba-Pérez, Francisco",
      "affiliations": [
        "Universidade de Vigo"
      ]
    },
    {
      "id": null,
      "name": "García-Méndez, Silvia",
      "affiliations": [
        "Universidade de Vigo"
      ]
    },
    {
      "id": null,
      "name": "de Arriba-P\\'erez, Francisco",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Garc\\'ia-M\\'endez, Silvia",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3214022523",
    "https://openalex.org/W4383618720",
    "https://openalex.org/W3094848124",
    "https://openalex.org/W3092338261",
    "https://openalex.org/W4324309277",
    "https://openalex.org/W2995724321",
    "https://openalex.org/W3204089331",
    "https://openalex.org/W2914528675",
    "https://openalex.org/W2992862671",
    "https://openalex.org/W4388734695",
    "https://openalex.org/W2898155085",
    "https://openalex.org/W3097533615",
    "https://openalex.org/W4387372812",
    "https://openalex.org/W4312091558",
    "https://openalex.org/W3196716035",
    "https://openalex.org/W4221150160",
    "https://openalex.org/W4213288032",
    "https://openalex.org/W4386002582",
    "https://openalex.org/W4383747813",
    "https://openalex.org/W2913713488",
    "https://openalex.org/W4396877921",
    "https://openalex.org/W4387485634",
    "https://openalex.org/W4386155683",
    "https://openalex.org/W4385729976",
    "https://openalex.org/W2922711788",
    "https://openalex.org/W3182482959",
    "https://openalex.org/W4210812846",
    "https://openalex.org/W4315490012",
    "https://openalex.org/W4360841377",
    "https://openalex.org/W4385647263",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2944069152",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W2971258845",
    "https://openalex.org/W2976476443",
    "https://openalex.org/W4320920036",
    "https://openalex.org/W3092557781",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W4367681098",
    "https://openalex.org/W4386214544",
    "https://openalex.org/W3190367510",
    "https://openalex.org/W2990556942",
    "https://openalex.org/W3015919348",
    "https://openalex.org/W4385250451",
    "https://openalex.org/W4205941964",
    "https://openalex.org/W2550576290",
    "https://openalex.org/W2921208286",
    "https://openalex.org/W4294647382",
    "https://openalex.org/W3163715127",
    "https://openalex.org/W1574447377",
    "https://openalex.org/W4225154016",
    "https://openalex.org/W3104405162"
  ],
  "abstract": null,
  "full_text": "Arabian Journal for Science and Engineering (2025) 50:11577–11591\nhttps://doi.org/10.1007/s13369-024-09508-2\nRESEARCH ARTICLE-COMPUTER ENGINEERING AND COMPUTER SCIENCE\nLeveraging large language models through natural language\nprocessing to provide interpretable machine learning predictions of\nmental deterioration in real time\nFrancisco de Arriba-Pérez 1 · Silvia García-Méndez 1\nReceived: 25 December 2023 / Accepted: 12 August 2024 / Published online: 27 August 2024\n© The Author(s) 2024\nAbstract\nBased on ofﬁcial estimates, 50 million people worldwide are affected by dementia, and this number increases by 10 million\nnew patients every year. Without a cure, clinical prognostication and early intervention represent the most effective ways to\ndelay its progression. To this end, artiﬁcial intelligence and computational linguistics can be exploited for natural language\nanalysis, personalized assessment, monitoring, and treatment. However, traditional approaches need more semantic knowledge\nmanagement and explicability capabilities. Moreover, using large language models ( llms) for cognitive decline diagnosis is\nstill scarce, even though these models represent the most advanced way for clinical–patient communication using intelligent\nsystems. Consequently, we leverage an llm using the latest natural language processing ( nlp) techniques in a chatbot\nsolution to provide interpretable machine learning prediction of cognitive decline in real-time. Linguistic-conceptual features\nare exploited for appropriate natural language analysis. Through explainability, we aim to ﬁght potential biases of the models\nand improve their potential to help clinical workers in their diagnosis decisions. More in detail, the proposed pipeline is\ncomposed of (i) data extraction employing nlp-based prompt engineering; (ii) stream-based data processing including feature\nengineering, analysis, and selection; (iii) real-time classiﬁcation; and (iv) the explainability dashboard to provide visual and\nnatural language descriptions of the prediction outcome. Classiﬁcation results exceed 80% in all evaluation metrics, with a\nrecall value for the mental deterioration class about 85%. To sum up, we contribute with an affordable, ﬂexible, non-invasive,\npersonalized diagnostic system to this work.\nKeywords Artiﬁcial intelligence · Explainability · Healthcare · Large language models · Natural language processing ·\nStream-based machine learning\n1 Introduction\nNeurodegenerative Alzheimer’s disorder ( ad) is the leading\ncause of chronic or progressive dementia, which negatively\nimpacts cognitive functioning, including comprehension,\nspeech, and thinking problems, memory loss, etc. [ 1]. More\nin detail, the typical stages of cognitive decline can be cate-\nF. de Arriba-Pérez and S. García-Méndez have contributed equally to\nthis work.\nB Silvia García-Méndez\nsgarcia@gti.uvigo.es\nFrancisco de Arriba-Pérez\nfarriba@gti.uvigo.es\n1 Information Technologies Group, atlanTTic, University of\nVigo, Vigo, Spain\ngorized as pre-clinical ad, mild cognitive impairment ( mci)\ncaused by ad, and ﬁnally ad dementia [2]. Generally, cogni-\ntively impaired users ﬁnd difﬁcult to perform daily tasks with\nthe consequent detrimental impact on their life quality [ 3]. In\nthis line, cognitive decline is a leading cause of dependency\nand disability for our elders [ 4].\nAccording to the Alzheimer’s Association report on the\nimpact of this disease in the USA [ 5], it is the sixth-leading\ndeath cause that increased more than 145% in the last years.\nMoreover, it affects 6.7 million people 65 or older. Dread-\nfully, this number is predicted to grow to 13.8 million by\n2060. Regarding medical expenses related to people affected\nwith dementia 65 or older, these are three times greater than\nthose of people without this condition, reaching 345 billion\ndollars so far in 2023. Overall, the World Health Organiza-\n123\n11578 Arabian Journal for Science and Engineering (2025) 50:11577–11591\ntion estimates that 50 million people worldwide are affected\nby dementia, with 10 million new patients yearly. 1\nClinical prognostication and early intervention, the most\npromising ways to address mental deterioration, rely on\neffective progression detection [ 2]. Among the beneﬁts\nof early identiﬁcation, care planning assistance, medical\nexpense reduction, and the opportunity to receive the latest\ntreatments, including non-invasive therapy, given the rapid\nbiologic therapeutics advancements, stand out [ 6, 7]. The\nsocial stigma and socioeconomic status must also be con-\nsidered when accessing mental health services [ 8]. However,\nthe latter early diagnosis is challenging since the symptoms\ncan be confused with normal aging decline [ 9]. To address\nit, computational linguistics can be exploited [ 10]. Natu-\nral language analysis is particularly relevant, constituting a\nsigniﬁcant proportion of healthcare data [ 11]. Particularly,\nimpairment in language production mainly affects lexical\n(e.g., little use of nouns and verbs), semantic (e.g., the use of\nempty words like thing/stuff), and pragmatic (e.g., discourse\ndisorganization) aspects [ 12].\nDigital and technological advances such as artiﬁcial intel-\nligence ( ai)-based systems represent promising approaches\ntoward individuals’ needs for personalized assessment, mon-\nitoring, and treatment [ 13]. Accordingly, these systems\nhave the capabilities to complement traditional methodolo-\ngies such as the Alzheimer’s Disease Assessment Scale-\nCognition ( adascog), the Mini-Mental State Examination\n(mmse), and the Montreal Cognitive Assessment ( moca),\nwhich generally involve expensive, invasive equipment, and\nlengthy evaluations [ 14]. In fact, paper-and-pencil cogni-\ntive tests continue to be the most common approaches even\nthough the latest advances in the natural language process-\ning ( nlp) ﬁeld enable easy screening from speech data\nwhile at the same time avoiding patient/physician burden-\ning [ 15]. Summing up, language analysis can translate into\nan effective, inexpensive, non-invasive, and simpler way of\nmonitoring cognitive decline [ 14, 16] provided that sponta-\nneous speech of cognitive impaired people is characterized\nby the aforementioned semantic comprehension problems\nand memory loss episodes [ 17].\nConsequently, clinical decision support systems ( cdsss),\ndiagnostic decision support systems ( ddsss), and intelligent\ndiagnosis systems ( idss), which apply ai techniques (e.g.,\nmachine learning ml, nlp, etc.) to analyze patient medical\ndata (i.e., clinical records, imaging data, lab results, etc.) and\ndiscover relevant patterns effectively and efﬁciently, have sig-\nniﬁcantly attracted the attention of the medical and research\ncommunity [18]. However, one of the main disadvantages of\ntraditional approaches is their lack of semantic knowledge\nmanagement and explicability capabilities [ 17]. The latter\n1 Available at https://www.who.int/news-room/fact-sheets/detail/\ndementia, May 2024.\ncan be especially problematic in the medical domain regard-\ning accountability of the decision process for the physicians\nto recommend personalized treatments [ 14].\nIntegrating ai-based systems in conversational assistants\nto provide economical, ﬂexible, immediate, and personal-\nized health support is particularly relevant [ 19]. Their use\nhas been greatly enhanced by the nowadays popular large\nlanguage models ( llms), enabling dynamic dialogues com-\npared to previous developments [ 20]. Subsequently, llms\nhave been powered by the latest advancements in deep\nlearning techniques and the availability of vast amounts of\ncross-disciplinary data [21]. These models represent the most\ninnovative approach of ai into healthcare by expediting med-\nical interventions and providing new markers and therapeutic\napproaches to neurological diagnosis from patient narra-\ntive processing [ 22]. Note that patient experience can also\nbe improved with the help of llms in terms of informa-\ntion and support seeking [ 23]. Summing up, conversation\nassistants that leverage llms have the potential to monitor\nhigh-risk populations and provide personalized advice, apart\nfrom offering companion [ 19, 24] constituting the future of\ntherapy in the literature [ 25].\nGiven the still poor accuracy of cdsss[ 26, 27], we plan to\nleverage an llm using the latest nlp techniques in a chatbot\nsolution to provide interpretable ml prediction of cogni-\ntive decline in real-time. Linguistic-conceptual features are\nexploited for appropriate natural language analysis. The main\nlimitation of llms is that their outcomes may be misleading.\nThus, we apply prompt engineering to avoid the “hallucina-\ntion” effect. Through explainability, we aim to ﬁght potential\nbiases of the models and improve their potential to help clin-\nical workers in their diagnosis decisions. Summing up, we\ncontribute with an affordable, non-invasive diagnostic sys-\ntem in this work.\nThe rest of this paper is organized as follows. Section 2\nreviews the relevant competing works on cognitive decline\ndetection involving llms and interpretable ml predictions\nof mental deterioration. The contribution of this work is\nsummarized in Sect. 2.1. Section 3 explains the proposed\nsolution, while Sect. 4 describes the experimental data set,\nour implementations, and the results obtained. Finally, Sect. 5\nconcludes the paper and proposes future research.\nProblemThe World Health Organization predicts a yearly\nincrease of 10 million people affected with dementia.\nWhat is already known Paper-and-pencil cognitive tests\ncontinue to be the most common approach. The latter\nis impractical, given the disease growth rate. Moreover,\none of the main disadvantages of intelligent approaches is\ntheir lack of semantic knowledge management and expli-\ncability capabilities.\nWhat this paper adds\nWe leverage an llm using the latest\nnlp techniques in a chatbot solution to provide inter-\n123\nArabian Journal for Science and Engineering (2025) 50:11577–11591 11579\npretable ml prediction of cognitive decline in real-time.\nTo sum up, we contribute with an affordable, ﬂexi-\nble, non-invasive, personalized diagnostic system to this\nwork.\n2 Related Work\nAs previously mentioned, the main focus of dementia treat-\nment is to delay the cognitive deterioration of patients [ 17].\nConsequently, early diagnosis, which simultaneously con-\ntributes to reducing medical expenses in our aging society\nand avoiding invasive treatments with subsequent side effects\non the users, is desirable [ 6]. To this end, ai has been suc-\ncessfully applied to idss in order to recommend treatments\nbased on their diagnosis prediction [ 28, 29].\nWhile ml models perform well and fast in diagnosis tasks,\nthey require extensive training data previously analyzed by\nexperts, which is labor-intensive and time-consuming [ 17]. In\ncontrast, advanced nlp-based solutions exploit transformer-\nbased models already trained with large corpora, including\ndomain-related data, which results in very sensitive text\nanalysis capabilities [ 30]. Consequently, transformer-based\npre-trained language models ( plms) (e.g., bert [31], gpt-\n3 [32]) which preceded the popular llms (e.g., gpt- 4\n2)\nhave disruptively transformed the nlp research. These mod-\nels exhibit great contextual latent feature extraction abilities\nfrom textual input [ 30]. The latter models are implemented to\npredict the next token based on massive training data, result-\ning in a word-by-word outcome [ 33]. Nowadays, they are\nused for various tasks, including problem-solving, question-\nanswering, sentiment analysis, text classiﬁcation, and gener-\nation [ 34].\nThere exist plm versions over biomedical and clinical data\nsuch as Bio bert [35], Bio gpt [36], Blue bert [37], Clini-\ncalbert\n3, and tcm- bert [38]. Open-domain conversational\nassistants, whose dialogue capabilities are not restricted to\nthe conversation topic, exploit llms[ 19]. However, using\nllms for cognitive decline diagnosis is still scarce even\nthough these models represent the most advanced way\nfor clinical-patient communication using intelligent systems\n[39]. More in detail, they overcome the limitation of tradi-\ntional approaches that lack semantic reasoning, especially\nrelevant in clinical language [ 40]. Unfortunately, despite the\nsigniﬁcant advancement they represent, llms still exhibit\ncertain limitations in open-domain task-oriented dialogues\n(e.g., medical use cases) [ 41]. For the latter, the reinforcement\nlearning from human feedback ( rlhf, i.e., prompt engineer-\n2 Available at https://platform.openai.com/docs/models/gpt-4 ,M a y\n2024.\n3 Available at https://github.com/EmilyAlsentzer/clinicalBERT,M a y\n2024.\ning) technique is applied to enhance their performance based\non end users’ instructions and preferences [ 42].\nRegarding the application of plm to the medical ﬁeld,\nSyed et al. [ 3] performed two tasks: (i) dementia prediction\nand (ii) mmse score estimation from speech recordings com-\nbining acoustic features and text embeddings obtained with\nthe bert model from their transcription. The input data cor-\nrespond to cognitive tests ( cts). Y uan et al. [ 12] analyzed\ndisﬂuencies (i.e., uh/um word frequency and speech pauses)\nwith bert and ernie modes based on data from the Cookie\nTheft picture from the Boston Diagnostic Aphasia Exam.\nClose to the work by Syed et al. [ 3], Chen et al. [ 15] analyzed\nthe performance of bert model to extract embeddings in\ncognitive impairment detection from speech gathered during\ncts. Santander-Cruz et al. [ 17] combined the Siamese bert\nnetworks ( sberts) with ml classiﬁers to ﬁrstly extract the\nsentence embeddings and then predict Alzheimer’s disease\nfrom ct data. In contrast, V ats et al. [ 1] performed dementia\ndetection combining ml,t h e bert model, and acoustic fea-\ntures to achieve improved performance. Moreover, Li et al.\n[16] compared gpt- 2 with its artiﬁcially degraded version\n(gpt- d ) created with a dementia-related linguistic anoma-\nlies layer induction based on data from a picture description\ntask, while Agbavor and Liang [ 14] predicted dementia and\ncognitive score from ct data using gpt- 3 exploiting both\nword embeddings and acoustic knowledge. Finally, Mao et\nal. [ 2] pre-trained the bert model with unstructured clinical\nnotes from Electronic Health Records ( ehrs) to detect mci\nto ad progression.\nMore closely related to our research is the work by\nBertacchini et al [ 13]. The authors designed Pepper, a social\nrobot with real-time conversational capabilities exploiting\nthe Chat gpt gpt- 3.5 model. However, the use case of the\nsystem is autism spectrum disorder detection. Furthermore,\nCaruccio et al. [ 18] compared the diagnoses performance of\ndifferent models of Chat gpt (i.e.,\nada, babbage, curie,\ndavinci and gpt- 3.5 ) with Google Bard and traditional\nml approaches based on symptomatic data. The authors\nexploited prompt engineering to ensure appropriate perfor-\nmance when submitting clinical-related questions to the llm\nmodel. Moreover, Hirosawa et al. [ 39] analyzed the diagnosis\nability of Chat gpt gpt- 3.5 model using clinical vignettes.\nThen, the llm was evaluated compared to physicians’ diag-\nnosis. However, the authors again focus not on cognitive\ndecline prediction but on ten common chief complaints.\nConsideration should be given to the work by Koga et al.\n[30], who used Chat gpt (i.e., gpt- 3.5 and gpt- 4 models)\nand Google Bard to predict several neurodegenerative dis-\norders based on clinical summaries in clinicopathological\nconferences without being a speciﬁc solution tailored for ad\nprediction. Finally, regarding conversational assistants that\nintegrate llms, Zaman et al. [ 43] developed a chatbot based\n123\n11580 Arabian Journal for Science and Engineering (2025) 50:11577–11591\nTable 1 Comparison of\ndiagnostic llm-based solutions\ntaking into account the ﬁeld of\napplication, the model used, the\ninput data, and explainability\n(Ex.) capability\nAuthorship Application LLM Input data Ex.\nCaruccio et al. [ 18] General diagnosis Chat gpt Symptomatic data ×\nGoogle Bard\nml\nHirosawa et al. [ 39] Common complaints Chat gpt Clinical vignettes ×\nKoga et al. [ 30] Neurodegenerative disorders Chat gpt Clinical summaries ×\nGoogle Bard\nProposal Mental decline Chat gpt + ml Spontaneous speech ✓\non Chat gpt gpt- 3.5 model to provide emotional support to\ncaregivers (i.e., practical tips and shared experiences).\n2.1 Contributions\nAs previously described, a vast amount of work in the state of\nthe art exploits plms even in the clinical ﬁeld [ 44]. However,\nscant research has been performed in the case of llm models.\nTable 1 summarizes the reviewed diagnostic solutions that\nexploit llms in the literature. Note that explainability rep-\nresents a differential characteristic of the solution proposed\ngiven the relevance of promoting transparency in ai-based\nsystems [ 45].\nGiven the comparison with competing works:\n• Our system is the ﬁrst that jointly considers the appli-\ncation of an llm over spontaneous speech and provides\ninterpretable ml results for the use case of mental decline\nprediction.\n• Our solution implements ml models in streaming to pro-\nvide real-time functioning, hence avoiding the re-training\ncost of batch systems.\n• In this work, we leverage the potential of llms by apply-\ning the rlhf technique through prompt engineering in a\nchatbot solution. Note that the natural language analysis\nis performed with linguistic-conceptual features. Conse-\nquently, we contribute with an affordable, non-invasive\ndiagnostic system.\n• Our system democratizes access to researchers and end\nusers within the public health ﬁeld to the latest advances\nin nlp.\n3 Methodology\nFigure 1 depicts the system scheme proposed for real-time\nprediction of mental decline combining llms and ml algo-\nrithms with explainability capabilities. More in detail, it\nis composed of (i) data extraction employing nlp-based\nprompt engineering (Sect. 3.1); (ii) stream-based data pro-\ncessing including feature engineering, analysis and selection\n(Sect. 3.2); (iii) real-time classiﬁcation (Sect. 3.3); and (iv)\nthe explainability dashboard to provide visual and natural\nlanguage descriptions of the prediction outcome (Sect. 3.4).\nAlgorithm 1 describes the complete process.\n3.1 Data Extraction\nThe Chat gpt gpt- 3.5 model used serves two purposes: (i) it\nenables a natural, free dialogue with the end users, and (ii)\ndata are extracted due to its semantic knowledge management\ncapabilities. The latter information is gathered once the con-\nversation is concluded (either more than 3 min of inactivity\nor farewell detected) and used to compute the features used\nfor classiﬁcation (see Sect. 3.2.1). For this extraction, prompt\nengineering is exploited. The complete data extraction pro-\ncess is described in Algorithm 2.\n3.2 Stream-Based Data Processing\nStream-based data processing encompasses feature engi-\nneering, analysis, and selection tasks to ensure the optimal\nperformance of the ml classiﬁers.\n3.2.1 Feature Engineering\nTable 2 details the features used to predict mental decline.\nNote that conversational, emotional, and linguistic-conceptual\nfeatures are computed. The conversational features.\n4 (1–\n10) represent relevant semantic and pragmatic information\nrelated to the free dialogue (e.g., ﬂuency, repetitiveness, etc.),\nwhile emotional features focus on the mental and physical\nstate of the users. Finally, linguistic features represent lexi-\ncal and semantic knowledge (e.g., disﬂuencies, placeholder\nwords, etc.).\nFurthermore, the system maintains a history of each user\ndata (i.e., past and current feature values) that enables the\ncomputation of four new characteristics per each in Table 2:\naverage, q1, q2, and q3 as indicated in Eq. ( 1), where n is\nthe user conversation counter and X[n]represents a particular\nfeature with historical data.\n4 Features 9–10 are not computed using the llm.\n123\nArabian Journal for Science and Engineering (2025) 50:11577–11591 11581\nFig. 1 System scheme\nAlgorithm 1 Methodology\nscenario , model _name , selector _mode , selector _thresho ld %Conﬁguration parameters deﬁned by the user\ncount = 0\nlist _y, list _y_ pred , list _sessions =[ ]\ninput (session ) %A new dialogue session enters the system\nwhile session != null do\nlist _sessions .append (session )\nlist _ fe a t u re s = data _extraction (session )\nlist _ fe a t u re s_selected = data _ processing (list _sessions , list _ fe a t u re s, selector _mode , selector _thresho ld )\nlist _y.append (session .y)\ny_ pred = classi f ication (list _ fe a t u re s_selected , scenario , model _name , count , list _y)\nlist _y_ pred .append (y_ pred )\ncount = count + 1\ninput (session )\nend while\nAlgorithm 2 Data extraction\nfunction data _extraction (session )\nlist _human _interactions =[ ] %To save only the human interactions, excluding those made by the chatbot\ncomplete _human _dialogue = “\"\nfor item in session do\nif item .type () == “human \" then\nlist _human _intereactions .append (item )\ncomplete _human _dialogue = complete _human _dialogue .concat (item )\nend if\nend for\nfe a t u re_9 = len (list _human _intereactions ) %See Table 2\nfe a t u re_10 = len (complete _human _dialogue .split ())\nrest _ fe a t u re s = prompt _data _extraction () %See Listing 1\nreturn ( fe a t u re_9, fe a t u re_10, rest _ fe a t u re s)\nend function\n123\n11582 Arabian Journal for Science and Engineering (2025) 50:11577–11591\nTable 2 Features engineered for mental deterioration prediction\nCategory ID Name Description\nConversational 1 Amnesia Showing difﬁculty in recalling past data.\n2 Incoherence Use of inconsistent responses.\n3 Incomprehension Inability to understand certain aspects.\n4 Confusion Showing uncertainty about what is discussed.\n5 Fluency Use of smooth quality utterances.\n6 Initiative Willingness to engage in the dialogue even posing questions.\n7 Repetitiveness Use of repetitive utterances that affect the conversation ﬂow.\n8 Secretive Inclined to hide feelings and personal information.\n9 Interactions Total number of bot–human interaction pairs in the dialogue.\n10 Words Total number of words in the dialogue.\nEmotional 11 Health state Absence/presence of mental or physical health concerns.\n12 Fatigue Sense of tiredness.\n13 Loneliness Sense of abandonment.\n14 Polarity Providing negative, neutral or positive information.\n15 Sadness Sense of depression.\nLinguistic 16 Colloquial registry Using a casual and simple language registry.\n17 Conjugation problems Inability to correctly conjugate verb tenses.\n18 Disﬂuency Use of interjections to complete pauses.\n19 Formal registry Exhibiting a well-mannered language registry.\n20 Placeholder words Use of auxiliary words instead of a more precise one.\n21 Sesquipedalian words Employing ceremonial, long, uncommon words.\n22 Short response Providing quick answers.\n∀n ∈{ 1...∞}\nX[n]={ x[0],..., x[n]}.\nY [n]={ y0[n], y1[n],..., yn−1[n]} |\ny0[n]≤ y1[n]≤ ... ≤ yn−1[n],\nwhere;∀ x ∈ X[n], x ∈ Y [n].\navgn[n]= 1\nn\nn∑\ni=0\nyi [n]\nQn\n1 [n]= y⌊\n1\n4 n\n⌉ [n]\nQn\n2 [n]= y⌊\n2\n4 n\n⌉ [n]\nQn\n3 [n]= y⌊\n3\n4 n\n⌉ [n] (1)\n3.2.2 Feature Analysis & Selection\nFeature analysis and selection tasks are necessary to opti-\nmize the performance of the ml classiﬁers. These tasks are\neven more important in the streaming scenario where samples\narrive at a real-time pace. The latter means that the classiﬁ-\ncation problem layout (e.g., the most relevant features) may\nvary over time.\nThe proposed system follows two thresholding strategies\nfor feature analysis and selection based on cut-off points\nregarding correlation and variance values to remove irrel-\nevant features. The former, correlation analysis, limits the\nnumber of features to extract the most relevant characteris-\ntics. For the latter variance analysis, the number of features\nselected is dynamically established in each interaction of the\nstream-based model, selecting those that meet the threshold\ncriteria.\nAlgorithm 3 details the data processing stage, including\nfeature engineering, analysis, and selection.\n3.3 Stream-Based Classification\nTwo classiﬁcation scenarios are considered:\nScenario 1 analyzes the behavior of the classiﬁers in a\nstreaming setting. Under this consideration, sequential\nand continual testing and training over time is assumed.\nScenario 2 analyzes the models’ performance under\nmore realistic conditions. Thus, the testing is continuous\n(i.e., in streaming) while training is performed desyn-\nchronized in blocks of 100 samples.\nThe following ml models are selected based on their good\nperformance in similar classiﬁcation problems [ 46–48]:\n123\nArabian Journal for Science and Engineering (2025) 50:11577–11591 11583\nAlgorithm 3 Data processing\nfunction data _ processing (list _sessions , list _ fe a t u re s, selector _mode , selector _thresho ld )\nfor fe a t u rei nl i s t _ fe a t u re s do\nlist _ fe a t u re s.append (avg(list _sessions [ fe a t u re]))\nlist _ fe a t u re s.append (Q1(list _sessions [ fe a t u re]))\nlist _ fe a t u re s.append (Q2(list _sessions [ fe a t u re]))\nlist _ fe a t u re s.append (Q3(list _sessions [ fe a t u re]))\nend for\nlist _ fe a t u re s_selected =[ ]\nfor fe a t u rei nl i s t _ fe a t u re s do\nif selector _mode == “variance \"a n d varizance ( fe a t u re)> selector _thresho ld then\nlist _ fe a t u re s_selected .append ( fe a t u re)\nelse if selector _mode == “correlation \"a n d correlation ( fe a t u re)> selector _thresho ld then\nlist _ fe a t u re s_selected .append ( fe a t u re)\nend if\nend for\nreturn list _ fe a t u re s_selected\nend function\n• Gaussian Naive Bayes (gnb)[ 49] exploits the Gaussian\nprobability distribution in a stream-based ml model. It is\nused as a reference for performance analysis.\n• Approximate Large Margin Algorithm (alma)[ 50]i sa\nfast incremental learning algorithm comparable to sup-\nport vector machine to approximate the maximal margin\nbetween a hyperplane concerning a norm (with a value\nof p ≥ 2) for a set of linearly separable data.\n• Hoeffding Adaptive Tree Classiﬁer (hatc)[ 51] com-\nputes single-tree branch performance and is designed for\nstream-based prediction.\n• Adaptive Random Forest Classiﬁer (arfc)[ 52] con-\nstitutes an advanced model of hatc in which branch\nperformance is computed by majority voting in an ensem-\nble tree scenario.\nAlgorithm 4 describes the stream-based prediction pro-\ncess.\n3.4 Explainability Dashboard\nPrediction transparency is promoted through explainability\ndata provided to the end users regarding relevant features\nin the prediction outcome. Thus, those relevant features are\nincluded in the natural language description of the decision\npath. The ﬁve features whose mathematical module is high-\nest or with the highest variance and whose values are the\nmost distant from the average are selected. In the case of the\ncounters (features 9–10), this average is obtained from the\naverage of all users in the system.\n4 Evaluation and Discussion\nThis section discusses the experimental data set used, the\nimplementation decisions, and the results obtained. The eval-\nuations were conducted on a computer with the following\nspeciﬁcations:\n• Operating system Ubuntu 18.04.2 LTS 64 bits\n• Processor Intel Core i9-10900K 2.80GHz\n• RAM 96GB DDR4\n• Disk 480GB NVME + 500GB SSD\n4.1 Experimental Data Set\nThe experimental data set 5 consists of an average of 6 .92 ±\n3.08 utterances with 62 .73 ±57.20 words involving 44 users\nwith 13 .66 ± 7.86 conversations by user. The distribution\nof mental deterioration in the experimental data set is 238\nsamples in which mental deterioration is present and 363 in\nwhich it is absent. Figure 2 depicts the histogram distribution\nof words and interactions by absent and present mental dete-\nrioration, respectively. While the distributions of the number\nof interactions in the absence or presence of cognitive impair-\nment follow a normal function, the number of words can be\napproximated by a positive normal centered on 0. The most\nrelevant issue is that, as expected, users with mental deterio-\nration present a lower number of interactions and a signiﬁcant\ndecrease in the number of words used in their responses.\n4.2 Data Extraction\nData to engineer conversational (1–8), emotional, and lin-\nguistic features in Table 2 were obtained with gpt-3.5-\nturbo6 model. The prompt used is shown in Listing 1.\n5 Data are available on request from the authors.\n6 Available at https://platform.openai.com/docs/models/gpt-3-5 ,M a y\n2024.\n123\n11584 Arabian Journal for Science and Engineering (2025) 50:11577–11591\nFig. 2 Distribution of\ninteractions and number of\nwords\n123\nArabian Journal for Science and Engineering (2025) 50:11577–11591 11585\nAlgorithm 4 Classiﬁcation\nfunction classi f ication (list _ fe a t u re s_selected , scenario , model _name , count , list _y)\ny_ pred = machine _learning _model (model _name , list _ fe a t u re s_selected ). predict ()\nif scenario == 1 then\nmachine _learning _model (model _name , list _ fe a t u re s_selected ).train (list _y[last ])\nelse if count %100 == 0 then\nmachine _learning _model (model _name , list _ fe a t u re s_selected ).train (list _y[−100 : last ])\nend if\nreturn y _ pred\nend function\nListing 1 Prompt used for data extraction.\nThis is a conversation between a bot and a h u m a n.\nAnswer what I ask below with a value between 0.0\nand 1.0 , being 0.0 never and 1.0 always.\nDetect i f t h e human: has any memory l o s s , i s\nincoherent , exhibits compr ehension problems ,\nis confused , fl uent , shows in itiative , uses\nrepetitive l anguage , hides feelings and pers onal\ninformation , expresses mental or physical health\nconcerns , is tired , feels l onely , the polarity of\nthe conversation , seems sad, interacts with a\ncolloquial registry , has conjugation problems,\nuses interjections to complete pauses , interacts\nwith a formal registry , uses placeholder words,\nsesquipedalian terms, and short res ponses .\nRespond only in the following JSON format :\n‘‘Amnesia’ ’:0.0 , ‘‘Incoherence ’ ’:0.0 ,\n‘ ‘Incomprehension’ ’:0.0 , ‘ ‘Confusion’ ’:0.0 ,\n‘ ‘Fluency’ ’:0.0 , ‘ ‘ In itiative ’’:0.0,\n‘‘Repetitiveness ’ ’:0.0 , ‘‘Secretive ’ ’:0.0 ,\n‘‘Health_state ’ ’:0.0 , ‘‘Fatigue ’ ’:0.0 ,\n‘‘Loneliness ’ ’:0.0 , ‘‘Polarity ’ ’:0.0 ,\n‘ ‘Sadness’ ’:0.0 , ‘ ‘Coll oquial_registry ’ ’:0.0 ,\n‘‘Conjugation_problems’ ’:0.0 , ‘‘Disfl uency ’ ’:0.0 ,\n‘‘Formal_registry ’ ’:0.0 , ‘‘Placeholder_words ’ ’:0.0 ,\n‘‘Sesquipedalian words’ ’:0.0 ,\n‘‘Short response ’ ’:0.0.\nALWAYS RETURN A JSON I N THE GIVEN FORMAT WITHOUT\nADDING MORE TEXT OR MODIFYING THE FIELD NAMES I N\nTHE JSON . DO NOT ANSWER ANY QUESTIONS IN THE\nCONVERSATION .\n<Dialogue>\n4.3 Stream-Based Data Processing\nThis section reports the algorithms used for feature engineer-\ning, analysis, and selection and their evaluation results.\nFig. 3 Distribution of conversations by user\n4.3.1 Feature Engineering\nA total of 88 features were generated 7 in addition to the\n22 features generated in each conversation (see Table 2)\nresulting in 110 features. In Fig. 3, we show the distribution\nof conversations by the user, which approaches a uniform\ndensity function, being relevant that the large majority con-\ncentrates between 15 and 20 conversations.\n4.3.2 Feature Analysis & Selection\nCorrelation and variance thresholding decisions were based\non experimental tests. For the correlation thresholding,\nSelectKBest\n8 was applied using the Pearson correlation\ncoefﬁcient [ 53]. The K value corresponds to the most rele-\nvant features of the 80% experimental data. Table 3 shows\nthe features with a correlation value greater than 0.2 with the\nmental deterioration target when the last sample entered the\nstream-based classiﬁcation model.\n7 New four characteristics (average, q1, q2, and q3) per each of the 22\nfeatures in Table 2.\n8 Available at https://riverml.xyz/0.11.1/api/feature-selection/\nSelectKBest, May 2024.\n123\n11586 Arabian Journal for Science and Engineering (2025) 50:11577–11591\nTable 3 Correlation and variance results\nFeature Statistic metric V alue\nCorrelation 22 Average 0.296\n9 Q1 0.292\nQ2 0.248\nAverage 0.219\n19 Average −0.203\n18 Q3 −0.213\n14 Q1 −0.226\n12 Average −0.238\n14 Q3 −0.272\nAverage −0.278\nQ2 −0.318\n6A v e r a g e −0.391\nQ3 −0.458\nV ariance 16 Q1 0.171\nOriginal 0.165\n6 Original 0.11\n16 Q2 0.086\n14 Original 0.084\n6 Q3 0.079\n14 Q3 0.055\nRegarding the variance thresholding, the implementa-\ntion used was VarianceThreshold9 from the River\nlibrary.10 Moreover, the cut-off point, 0.001, is computed\nwith the 10th percentile variance value of the features con-\ntained in the 20% of the experimental data set, which acts as\nthe cold start of this method. Consequently, only those fea-\ntures that exceed the abovementioned cut-off are selected as\nrelevant for classiﬁcation purposes. Table 3 also details the\nfeatures with a variance greater than 0.5.\n11\nTable 3 shows that among the conversational features,\nuser initiative (feature 6 in Table 2) plays an important role.\nThe same applies to the number of interactions within a\ndialogue (feature 9). Regarding emotional features, consid-\neration should be given to fatigue (feature 12) and polarity\n(feature 14). Finally, using a colloquial/formal registry (fea-\ntures 16/19), disﬂuency (feature 18), and short responses\n(feature 22) stand out among linguistic characteristics. Con-\nsidering correlation and variance analysis jointly, initiative\nand polarity are the most relevant data for prediction pur-\nposes.\n9 Available at https://riverml.xyz/0.11.1/api/feature-selection/\nV arianceThreshold, May 2024.\n10 Available at https://riverml.xyz/0.11.1, May 2024.\n11 Note that we have discarded features 9 and 10 from Table 2 from\nthis example since they represent counters and their variance is always\ngreater than 1.\n4.4 Stream-Based Classification\nThe River implementations of the ml models selected are:\ngnb,12 alma,13 hatc14 and arfc.15 Listings 2, 3 and 4\ndetail the hyper-parameter optimization ranges used, exclud-\ning the baseline model, from which the following values were\nselected as optimal:\nCorrelation thresholding\n• ALMA: alpha=0.5, B=1.0, C=1.0.\n• HATC: depth=None, tiethreshold=0.5, maxsize=50.\n• ARFC: models=10,features=5, lambda=50.\nVariance thresholding\n• ALMA: alpha=0.5, B=1.0, C=1.0.\n• HATC: depth=None, tiethreshold=0.5, maxsize=50.\n• ARFC: models=100,features=sqrt, lambda=50.\nListing 2 alma hyper-parameter conﬁguration.\nalpha = [0.5,0.7,0.9]\nB = [1.0, 1.41, 1.2]\nC = [1.0,1.11, 1.2]\nListing 3 hatc hyper-parameter conﬁguration.\ndepth = [None, 50, 200]\ntiethreshold = [0.5 , 0.05, 0.005]\nmaxsize = [50, 100, 200]\nListing 4 arfc hyper-parameter conﬁguration.\nmodels = [10 , 25, 100]\nfeatures = [sqrt , 5, 50]\nlambda = [25, 50, 100]\nTable 4 presents the results for evaluation scenarios 1\nand 2. In both scenarios, the feature selection methodology\nbased on correlation thresholding returns lower classiﬁca-\ntion metric values than those obtained with the variance\nmethod. Thus, once the variance feature selection method is\napplied, the arfc is the most promising performance algo-\nrithm regardless of the evaluation scenario.\nConsideration should be given to the fact that even in sce-\nnario 2, in which training is performed desynchronized and\n12 Available at https://riverml.xyz/dev/api/naive-bayes/GaussianNB ,\nMay 2024.\n13 Available at https://riverml.xyz/0.11.1/api/linear-model/ALMA\nClassiﬁer , May 2024.\n14 Available at https://riverml.xyz/0.11.1/api/tree/Hoeffding\nAdaptiveTreeClassiﬁer, May 2024.\n15 Available at https://riverml.xyz/0.11.1/api/ensemble/Adaptive\nRandomForestClassiﬁer , May 2024.\n123\nArabian Journal for Science and Engineering (2025) 50:11577–11591 11587\nTable 4 Classiﬁcation results\n(Sce.: scenario, time in seconds) Sce Selection Model Acc. Precision Recall Time\nMacro Present Absent Macro Present Absent\n1 Correlation gnb 63.11 68.57 52.13 85.00 67.24 87.39 47.09 0 .76\nalma 67.67 66.20 59.32 73.08 66.15 58.82 73.48 0.63\nhatc 63.27 64.65 52.69 76.60 65.09 73.95 56.23 0 .98\narfc 72.29 74 .23 60 .53 87 .94 74 .79 86.97 62.60 1 .57\nV ariance gnb 61.94 59.48 56.10 62.86 54.68 19.33 90.03 0 .31\nalma 67.33 65.88 58.82 72.93 65.88 58.82 72.93 0 .20\nhatc 69.78 68.98 60.52 77.44 69.63 68.91 70.36 0 .54\narfc 89.15 88 .47 83 .92 93 .02 89 .28 89 .92 88 .64 17.72\n2 Correlation gnb 58.60 66.76 48.85 84.66 63.86 89.50 38.23 0 .74\nalma 63.67 61.40 55.32 67.48 60.25 43.70 76.80 0.62\nhatc 58.10 55.80 47.06 64.55 55.64 43.70 67.59 0 .94\narfc 63.27 65.44 52.57 78.31 65.66 77.31 54.02 1 .42\nV ariance gnb 62.10 59.86 56.79 62.93 54.82 19.33 90.30 0.31\nalma 63.33 60.89 56.00 65.78 58.53 35.29 81.77 0 .20\nhatc 65.94 65.57 55.90 75.24 66.23 67.65 64.82 0 .49\narfc 84.81 84 .04 78 .38 89 .71 84 .89 85 .29 84.49 15 .50\nBest values are marked in bold\nTable 5 Classiﬁcation results in\nbatch for the rf model (time in\nseconds)\nAcc. Precision Recall Time\nMacro Present Absent Macro Present Absent\n93.18 93.15 93.01 93.28 92.54 89.50 95.59 1.96\nTable 6 Classiﬁcation results\nfor the arfc model using the\nexperimental data from [ 54]\n(time in seconds)\nAcc. Precision Recall Time\nMacro Present Absent Macro Present Absent\n77.70 76.62 81.32 71.93 76.46 82.22 70.69 4.72\nin batch, the robustness of arfc stands out with classiﬁca-\ntion results exceeding 80% and with a recall for the mental\ndeterioration class about 85%.\nProvided that our system operates in streaming and to\nenable direct comparison with batch ml solutions, additional\nevaluation measures from tenfold cross-validation are pro-\nvided, particularly, for Random Forest ( rf16) equivalent to\nthe best model, arfc, in stream-based classiﬁcation. The\nresults are displayed in Table 5, most surpassing the 90%\nthreshold. Note that the increase in performance compared\nto streaming operation (e.g., +8.37% points in accuracy) is\nderived from the fact that in batch classiﬁcation, the model\nhas access to the 90% of the experimental data for training.\nIn contrast, stream-based classiﬁcation relies on the ordered\nincoming new samples, which is more demanding. Conse-\nquently, having achieved a comparable performance in batch\nand stream-based classiﬁcation is noteworthy.\n16 Available at https://scikit-learn.org/stable/modules/generated/\nsklearn.ensemble.RandomForestClassiﬁer.html, May 2024.\nTo verify the system’s operation in a more challenging sce-\nnario, we have experimented with a data set from a previous\nstudy [ 54] with fewer interactions per session. Even when\nthe system is fed with less information, the evaluation met-\nrics are promising, as shown in Table 6 with all values above\n70%, and the precision and recall of the mental deterioration\ncategory above 80%. Comparing the rf batch model in our\npast research [ 54] with the proposed arfc algorithm, which\noperates in streaming, the improvement reaches 10% points\nand 4% points in the recall metric of mental deterioration and\nabsence of mental deterioration categories, respectively.\n4.5 Explainability Dashboard\nFigure 4 shows the explainability dashboard. In this example,\nthe variation in predicting cognitive impairment is visual-\nized, considering two weeks of past data. This variation is\nrepresented with the predict_proba function of arfc\nalgorithm. At the bottom, the most relevant features are dis-\n123\n11588 Arabian Journal for Science and Engineering (2025) 50:11577–11591\nFig. 4 Explainability dashboard\nplayed. Each ﬁgure card contains the identiﬁer and statistic\nrepresented in colors following this scheme: 1–0.5 in green,\n0.5–0.25 in yellow, and 0.25–0 in red. The latter assignation is\ninverted for negative values. At the bottom, a brief description\nin natural language is provided. The average accumulated\npredict_proba value, and the conﬁdence prediction of\nthe current sample are displayed on the right.\n5 Conclusions\nCognitively impaired users ﬁnd it difﬁcult to perform daily\ntasks with the consequent detrimental impact on their life\nquality. Thus, progression detection and early intervention\nare essential to effectively and timely address mental dete-\nrioration to delay its progress. In this work, we focused\non impairment in language production (i.e., lexical, seman-\ntic, and pragmatic aspects) to engineer linguistic-conceptual\nfeatures toward spontaneous speech analysis (e.g., seman-\ntic comprehension problems, memory loss episodes, etc.).\nCompared to traditional diagnostic approaches, the pro-\nposed solution has semantic knowledge management and\nexplicability capabilities thanks to integrating an llm in a\nconversational assistant.\nConsideration should be given to the limitations of using\nllms, which are transversal into the healthcare ﬁeld beyond\nmental deterioration detection. The potential biases and lack\nof inherent transparency stand out among the risks of apply-\ning these models for medical purposes. The latter black-box\nproblem, also present in traditional opaque ml models, is\nparticularly critical in the healthcare ﬁeld by negatively\nimpacting the decision process of physicians due to their\nlimited corrective capabilities and even the end users, lim-\niting their trust in medical applications. Moreover, these\nsystems’ current limited memory management capability is\nworth mentioning, which prevents the realization of longi-\ntudinal clinical analysis. The same applies to the associated\ncomplexity of context information management. Ultimately,\nthe difﬁculty in collecting data due to the sensitivity and con-\nﬁdentiality of the information in the medical ﬁeld should also\nbe mentioned.\nMore in detail, the solution provides interpretable ml pre-\ndiction of cognitive decline in real-time. rlhf (i.e., prompt\nengineering) and explainability are exploited to avoid the\n“hallucination” effect of llms and avoid potential biases by\nproviding natural language and visual descriptions of the\ndiagnosis decisions. Note that our system implements ml\nmodels in streaming to provide real-time functioning, hence\navoiding the re-training cost of batch systems.\nSumming up, we contribute with an affordable, ﬂexible,\nnon-invasive, personalized diagnostic system that enables\nthe monitoring of high-risk populations and offers com-\npanionship. Ultimately, our solution democratizes access to\nresearchers and end users within the public health ﬁeld to the\nlatest advances in nlp.\nAmong the challenges and potential ethical concerns\nraised by the application of ai into the healthcare ﬁeld, the\ndouble effect principle must be considered. In this sense,\nfew can deny its promising potential to provide innovative\ntreatments while at the same time presenting safety-critical\n123\nArabian Journal for Science and Engineering (2025) 50:11577–11591 11589\nconcerns, notably regarding their interpretability. Apart from\nthe algorithmic transparency mentioned, the main consider-\nations are privacy and safety of the medical data, fairness,\nand autonomous decision-making without human interven-\ntion. In future work, we plan to test the performance of\nnew approaches, such as reinforcement learning, to enhance\nthe system’s personalizing capabilities further. Moreover, we\nwill explore co-design practices with end users, and we seek\nto move our solution to clinical practice within an ongo-\ning project with daycare facilities. Note that reinforcement\nlearning with human feedback will also allow us to mitigate\nsome of the limitations discussed, such as physicians’ lack\nof interpretability and corrective capabilities. The latter will\nalso have a positive ethical impact on the deployment of llm-\nbased medical applications by ensuring fairness. The societal\nimpact derived from reduced costs compared to traditional\napproaches may result in broader accessibility to clinical\ndiagnosis and treatment on a demand basis. The equity will be\nimpulsed by the capability of these systems to provide unlim-\nited personalized support. In future research, we will work on\nmitigating health inequities by performing longitudinal stud-\nies to measure bias in our ai solution, particularly related to\nthe algorithm design, bias in the training data, and the ground\ntruth. Underperformance in certain social groups may also be\nconsidered. For that purpose, we will gather social context\ndata, which will allow us to measure equity (e.g., gender,\nrace, socioeconomic status, etc.). To ensure patient data pro-\ntection while at the same time increasing data available for\nresearch, federated learning approaches will be explored.\nAuthor Contributions Francisco de Arriba-Pérez contributed to con-\nceptualization, methodology, software, validation, formal analysis,\ninvestigation, resources, data curation, writing—original draft, writing—\nreview and editing, visualization, supervision, project administration,\nand funding acquisition. Silvia García-Méndez contributed to conceptu-\nalization, methodology, software, validation, formal analysis, investiga-\ntion, resources, data curation, writing—original draft, writing—review\n& editing, visualization, supervision, project administration, and fund-\ning acquisition.\nFunding Open Access funding provided thanks to the CRUE-CSIC\nagreement with Springer Nature. This work was partially supported by\n(i) Xunta de Galicia grants ED481B-2022-093 and ED481D 2024/014,\nSpain; and (ii) University of Vigo/CISUG for open access charge.\nDeclarations\nConﬂict of interest The authors have no conﬂict of interest to declare\nrelevant to this article’s content.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing, adap-\ntation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indi-\ncate if changes were made. The images or other third party material\nin this article are included in the article’s Creative Commons licence,\nunless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your\nintended use is not permitted by statutory regulation or exceeds the\npermitted use, you will need to obtain permission directly from the copy-\nright holder. To view a copy of this licence, visit http://creativecomm\nons.org/licenses/by/4.0/.\nReferences\n1. V ats, N.A.; Yadavalli, A.; Gurugubelli, K.; et al.: Acoustic features,\nBERT model and their complementary nature for Alzheimer’s\ndementia detection. In: Proceedings of the International Confer-\nence on Contemporary Computing. Association for Computing\nMachinery, pp. 267–272 (2021). https://doi.org/10.1145/3474124.\n3474162\n2. Mao, C.; Xu, J.; Rasmussen, L.; et al.: AD-BERT: using pre-\ntrained language model to predict the progression from mild\ncognitive impairment to Alzheimer’s disease. J. Biomed. Inform.\n144, 104,442-104,449 (2023). https://doi.org/10.1016/j.jbi.2023.\n104442\n3. Syed, M.S.S.; Syed, Z.S.; Lech, M.; et al.: Automated screen-\ning for Alzheimer’s dementia through spontaneous speech. In:\nProceedings of the Interspeech Conference. International Speech\nCommnunication Association, pp. 2222–2226 (2020). https://doi.\norg/10.21437/Interspeech.2020-3158\n4. Nadira, C.S.; Rahayu, M.S.: The relationship of cognitive function\nand independence activities of daily living (ADL) in elderly at Panti\nDarussa’adah and An-Nur Lhokseumawe. J. Kedokt. dan Kesehat.\nPubl. Ilm. Fak. Kedokt. Univ. Sriwij. 7, 55–60 (2020). https://doi.\norg/10.32539/JKK.V7I3.10690\n5. Association, A.; Thies, W.; Bleiler, L.: 2023 Alzheimer’s disease\nfacts and ﬁgures. Alzheimer’s Dement. 19, 1598–1695 (2023).\nhttps://doi.org/10.1002/alz.13016\n6. Rasmussen, J.; Langerman, H.: Alzheimer’s disease—Why we\nneed early diagnosis. Degener. Neurol. Neuromuscul. Dis. 9, 123–\n130 (2019). https://doi.org/10.2147/DNND.S228939\n7. Manly, J.J.; Glymour, M.M.: What the aducanumab approval\nreveals about Alzheimer disease research. JAMA Neurol. 78, 1305–\n1306 (2021). https://doi.org/10.1001/jamaneurol.2021.3404\n8. Kandratsenia, K.: Social stigma towards people with mental dis-\norders among the psychiatrists, general practitioners and young\ndoctors. Eur. Neuropsychopharmacol. 29, 401–402 (2019). https://\ndoi.org/10.1016/j.euroneuro.2018.11.608\n9. Tucker-Drob, E.M.: Cognitive aging and dementia: a life-span per-\nspective. Annu. Rev. Dev. Psychol. 1, 177–196 (2019). https://doi.\norg/10.1146/annurev-devpsych-121318-085204\n10. Pl, R.; Ks, G.: Cognitive decline assessment using semantic lin-\nguistic content and transformer deep learning architecture. Int. J.\nLang. Commun. Disord. 59, 1110–1127 (2024). https://doi.org/10.\n1111/1460-6984.12973\n11. V elupillai, S.; Suominen, H.; Liakata, M.; et al.: Using clinical Nat-\nural Language Processing for health outcomes research: overview\nand actionable suggestions for future advances. J. Biomed. Inform.\n88, 11–19 (2018). https://doi.org/10.1016/j.jbi.2018.10.005\n12. Y uan, J.; Bian, Y .; Cai, X.; et al.: Disﬂuencies and ﬁne-tuning pre-\ntrained language models for detection of Alzheimer’s disease. In:\nProceedings of the Interspeech Conference. International Speech\nCommunication Association, pp. 2162–2166 (2020). https://doi.\norg/10.21437/Interspeech.2020-2516\n13. Bertacchini, F.; Demarco, F.; Scuro, C.; et al.: A social robot con-\nnected with chatGPT to improve cognitive functioning in ASD\nsubjects. Front. Psychol. 14, 1–22 (2023). https://doi.org/10.3389/\nfpsyg.2023.1232177\n123\n11590 Arabian Journal for Science and Engineering (2025) 50:11577–11591\n14. Agbavor, F.; Liang, H.: Predicting dementia from spontaneous\nspeech using large language models. PLOS Digit. Health 1(12),\n1–14 (2022). https://doi.org/10.1371/journal.pdig.0000168\n15. Chen, J.; Ye, J.; Tang, F.; et al.: Automatic detection of Alzheimer’s\ndisease using spontaneous speech only. In: Proceedings of the\nInterspeech Conference, vol 6. International Speech Communica-\ntion Association, pp. 3830–3834. (2021). https://doi.org/10.21437/\nInterspeech.2021-2002\n16. Li, C.; Knopman, D.; Xu, W.; et al.: GPT-D: Inducing dementia-\nrelated linguistic anomalies by deliberate degradation of artiﬁcial\nneural language models. In: Proceedings of the Annual Meeting of\nthe Association for Computational Linguistic, vol 1. Association\nfor Computational Linguistics, pp. 1866–1877 (2022). https://doi.\norg/10.18653/v1/2022.acl-long.131\n17. Santander-Cruz, Y .; Salazar-Colores, S.; Paredes-García, W.J.;\net al.: Semantic feature extraction using SBERT for dementia\ndetection. Brain Sci. 12, 270–287 (2022). https://doi.org/10.3390/\nbrainsci12020270\n18. Caruccio, L.; Cirillo, S.; Polese, G.; et al.: Can ChatGPT pro-\nvide intelligent diagnoses? A comparative study between predictive\nmodels and ChatGPT to deﬁne a new medical diagnostic bot. Expert\nSyst. Appl. 235, 121,186-121,199 (2023). https://doi.org/10.1016/\nj.eswa.2023.121186\n19. KS, N.P .; Sudhanva, S.; Tarun, T.N.; Y uvraaj, Y .; Vishal, D.A.;\net al.: Conversational chatbot builder - smarter virtual assistance\nwith domain speciﬁc AI. In: Proceedings of the International Con-\nference for Emerging Technology, pp. 1–4. IEEE (2023). https://\ndoi.org/10.1109/INCET57972.2023.10170114\n20. Palanica, A.; Flaschner, P .; Thommandram, A.; et al.: Physicians’\nperceptions of Chatbots in health care: cross-sectional web-based\nsurvey. J. Med. Internet Res. 21, 1–10 (2019). https://doi.org/10.\n2196/12887\n21. Idris, M.D.; Feng, X.; Dyo, V .: Revolutionizing higher education:\nunleashing the potential of large language models for strategic\ntransformation. IEEE Access 12, 67,738-67,757 (2024). https://\ndoi.org/10.1109/ACCESS.2024.3400164\n22. Romano, M.F.; Shih, L.C.; Paschalidis, I.C.; et al.: Large language\nmodels in neurology research and future practice. Neurology 1–29\n(2023). https://doi.org/10.1212/WNL.0000000000207967\n23. Fear, K.; Gleber, C.: Shaping the future of older adult care: Chat-\nGPT, advanced AI, and the transformation of clinical practice.\nJMIR Aging 6, 1–3 (2023). https://doi.org/10.2196/51776\n24. Alessa, A.; Al-Khalifa, H.: Towards designing a ChatGPT con-\nversational companion for elderly people. In: Proceedings of the\nInternational Conference on Pervasive Technologies Related to\nAssistive Environments. Association for Computing Machinery,\npp. 667–674 (2023). https://doi.org/10.1145/3594806.3596572\n25. V aidyam, A.N.; Wisniewski, H.; Halamka, J.D.; et al.: Chatbots and\nconversational agents in mental health: a review of the psychiatric\nlandscape. Can. J. Psychiatry 64, 456–464 (2019). https://doi.org/\n10.1177/0706743719828977\n26. Ceney, A.; Tolond, S.; Glowinski, A.; et al.: Accuracy of online\nsymptom checkers and the potential impact on service utilisation.\nPLOS ONE 16, 1–16 (2021). https://doi.org/10.1371/journal.pone.\n0254088\n27. Schmieding, M.L.; Kopka, M.; Schmidt, K.; et al.: Triage accuracy\nof symptom checker apps: 5-year follow-up evaluation. J. Med.\nInternet Res. 24, 1–13 (2022). https://doi.org/10.2196/31810\n28. Kiliçarslan, S.; Közkurt, C.; Ba¸ s, S.; et al.: Detection and classi-\nﬁcation of pneumonia using novel Superior Exponential (SupEx)\nactivation function in convolutional neural networks. Expert Syst.\nAppl. 217, 119,503-119,514 (2023). https://doi.org/10.1016/j.\neswa.2023.119503\n29. Y u, B.; Chen, H.; Jia, C.; et al.: Multi-modality multi-scale cardio-\nvascular disease subtypes classiﬁcation using Raman image and\nmedical history. Expert Syst. Appl. 224, 119,965-119,976 (2023).\nhttps://doi.org/10.1016/j.eswa.2023.119965\n30. Koga, S.; Martin, N.B.; Dickson, D.W.: Evaluating the performance\nof large language models: ChatGPT and Google Bard in gener-\nating differential diagnoses in clinicopathological conferences of\nneurodegenerative disorders. Brain Pathol. 1–4 (2023). https://doi.\norg/10.1111/bpa.13207\n31. Kenton, J.D.M.W.C.; Toutanova, L.K.: Bert: pre-training of deep\nbidirectional transformers for language understanding. In: Pro-\nceedings of Annual Conference of the North American Chapter\nof the Association for Computational Linguistics on Human\nLanguage Technology, vol 1. Association for Computational Lin-\nguistics, pp. 4171–4186 (2019)\n32. Brown, T.B.; Mann, B.; Ryder, N.; et al.: Language models are\nfew-shot learners. In: Proceedings of the Advances in Neural\nInformation Processing Systems Conference, pp. 1–25. MIT Press\n(2020)\n33. Deriu, J.; Rodrigo, A.; Otegi, A.; et al.: Survey on evaluation meth-\nods for dialogue systems. Artif. Intell. Rev. 54, 755–810 (2021).\nhttps://doi.org/10.1007/s10462-020-09866-x\n34. Brown, T.; Mann, B.; Ryder, N.; et al.: Language models are few-\nshot learners. Adv. Neural Inf. Process. Syst. 33, 1877–1901 (2020)\n35. Lee, J.; Y oon, W.; Kim, S.; et al.: BioBERT: a pre-trained biomed-\nical language representation model for biomedical text mining.\nBioinformatics 36, 1234–1240 (2020). https://doi.org/10.1093/\nbioinformatics/btz682\n36. Luo, R.; Sun, L.; Xia, Y .; et al.: BioGPT: generative pre-trained\ntransformer for biomedical text generation and mining. Brief.\nBioinform. 23, 1–11 (2022). https://doi.org/10.1093/bib/bbac409\n37. Peng, Y .; Yan, S.; Lu, Z.: Transfer learning in biomedical natural\nlanguage processing: an evaluation of BERT and ELMo on ten\nbenchmarking datasets. In: Proceedings of the BioNLP Workshop\nand Shared Task. Association for Computational Linguistics, pp.\n58–65 (2019). https://doi.org/10.18653/v1/W19-5006\n38. Yao, L.; Jin, Z.; Mao, C.; et al.: Traditional Chinese medicine clin-\nical records classiﬁcation with BERT and domain speciﬁc corpora.\nJ. Am. Med. Inform. Assoc. 26, 1632–1636 (2019). https://doi.org/\n10.1093/jamia/ocz164\n39. Hirosawa, T.; Harada, Y .; Y okose, M.; et al.: Diagnostic accuracy\nof differential-diagnosis lists generated by generative pretrained\ntransformer 3 Chatbot for clinical vignettes with common chief\ncomplaints: a pilot study. Int. J. Environ. Res. Public Health 20,\n3378–3387 (2023). https://doi.org/10.3390/ijerph20043378\n40. Gillioz, A.; Casas, J.; Mugellini, E.; et al.: Overview of the\ntransformer-based models for NLP tasks. In: Proceedings of the\nFederated Conference on Computer Science and Information Sys-\ntems. Polish Information Processing Society, pp. 179–183 (2020).\nhttps://doi.org/10.15439/2020F20\n41. Ji, Z.; Lee, N.; Frieske, R.; et al.: Survey of hallucination in natural\nlanguage generation. ACM Comput. Surv. 55, 248–285 (2023).\nhttps://doi.org/10.1145/3571730\n42. Chen, H.; Y uan, K.; Huang, Y .; et al.: Feedback is all you need: from\nChatGPT to autonomous driving. Sci. China Inf. Sci. 66, 166,201-\n166,203 (2023). https://doi.org/10.1007/s11432-023-3740-x\n43. Zaman, K.T.; Hasan, W.U.; Li, J.; et al.: Empowering caregivers\nof Alzheimer’s disease and related dementias (ADRD) with a\nGPT-powered voice assistant: leveraging peer insights from social\nmedia. In: Proceedings of the IEEE Symposium on Computers and\nCommunications, pp. 1–7. IEEE (2023). https://doi.org/10.1109/\nISCC58397.2023.10218142\n44. Alomari, A.; Idris, N.; Sabri, A.Q.M.; et al.: Deep reinforcement\nand transfer learning for abstractive text summarization: a review.\nComput. Speech Lang. 71, 101,276-101,318 (2022). https://doi.\norg/10.1016/j.csl.2021.101276\n123\nArabian Journal for Science and Engineering (2025) 50:11577–11591 11591\n45. Wischmeyer, T.: Artiﬁcial Intelligence and Transparency: Open-\ning the Black Box, pp. 75–101. Springer International Publishing\n(2020). https://doi.org/10.1007/978-3-030-32361-5_4\n46. Mathkunti, N.M.; Rangaswamy, S.: Machine learning techniques\nto identify dementia. SN Comput. Sci. 1, 118–124 (2020). https://\ndoi.org/10.1007/s42979-020-0099-4\n47. Ilias, L.; Askounis, D.: Context-aware attention layers coupled\nwith optimal transport domain adaptation and multimodal fusion\nmethods for recognizing dementia from spontaneous speech.\nKnowledge-based Syst. 277, 110,834-110,851 (2023). https://doi.\norg/10.1016/j.knosys.2023.110834\n48. Kumar, Y .; Koul, A.; Singla, R.; et al.: Artiﬁcial intelligence in dis-\nease diagnosis: a systematic literature review, synthesizing frame-\nwork and future research agenda. J. Ambient. Intell. Humaniz.\nComput. 14, 8459–8486 (2023). https://doi.org/10.1007/s12652-\n021-03612-z\n49. Xu, S.: Bayesian Naïve Bayes classiﬁers to text classiﬁca-\ntion. J. Inf. Sci. 44, 48–59 (2018). https://doi.org/10.1177/\n0165551516677946\n50. Kang, S.; Kim, D.; Cho, S.: Approximate training of one-class\nsupport vector machines using expected margin. Comput. Ind. Eng.\n130, 772–778 (2019). https://doi.org/10.1016/j.cie.2019.03.029\n51. Weinberg, A.I.; Last, M.: EnHA T - Synergy of a tree-based Ensem-\nble with Hoeffding Adaptive Tree for dynamic data streams mining.\nInf. Fusion 89, 397–404 (2023). https://doi.org/10.1016/j.inffus.\n2022.08.026\n52. Zhang, W.; Bifet, A.; Zhang, X.; et al.: FARF: A Fair and Adap-\ntive Random Forests Classiﬁer, vol. 12713 LNAI, pp. 245–256.\nSpringer (2021). https://doi.org/10.1007/978-3-030-75765-6_20\n53. Benesty, J.; Chen, J.; Huang, Y .; et al.: Pearson correlation coefﬁ-\ncient. In: Springer Topics in Signal Processing, vol 2. Springer, pp.\n37–40 (2009). https://doi.org/10.1007/978-3-642-00296-0_5\n54. de Arriba-Pérez, F.; García-Méndez, S.; González-Castaño, F.J.;\net al.: Automatic detection of cognitive impairment in elderly\npeople using an entertainment chatbot with Natural Language\nProcessing capabilities. J. Ambient Intell. Humaniz. Comput.\n14, 16,283-16,298 (2023). https://doi.org/10.1007/s12652-022-\n03849-2\n123",
  "topic": "Natural language processing",
  "concepts": [
    {
      "name": "Natural language processing",
      "score": 0.5620816349983215
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5530102849006653
    },
    {
      "name": "Computer science",
      "score": 0.5332680940628052
    },
    {
      "name": "Natural (archaeology)",
      "score": 0.5235552191734314
    },
    {
      "name": "Natural language",
      "score": 0.4853174090385437
    },
    {
      "name": "Mental model",
      "score": 0.44880443811416626
    },
    {
      "name": "Machine learning",
      "score": 0.40687280893325806
    },
    {
      "name": "Psychology",
      "score": 0.30857813358306885
    },
    {
      "name": "Cognitive science",
      "score": 0.24722608923912048
    },
    {
      "name": "History",
      "score": 0.09413054585456848
    },
    {
      "name": "Archaeology",
      "score": 0.0
    }
  ]
}