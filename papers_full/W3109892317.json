{
  "title": "Molecular representation learning with language models and domain-relevant auxiliary tasks",
  "url": "https://openalex.org/W3109892317",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4310926207",
      "name": "Fabian, Benedek",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Edlich, Thomas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2323486952",
      "name": "Gaspar Helena",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4287437918",
      "name": "Segler, Marwin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4229131980",
      "name": "Meyers, Joshua",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Fiscato, Marco",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2101253228",
      "name": "Ahmed Mohamed",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3032781902",
    "https://openalex.org/W3005364306",
    "https://openalex.org/W2042110087",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W3200781945",
    "https://openalex.org/W2911109671",
    "https://openalex.org/W2937307539",
    "https://openalex.org/W2558999090",
    "https://openalex.org/W3007488165",
    "https://openalex.org/W2594183968",
    "https://openalex.org/W2886791556",
    "https://openalex.org/W3103092523",
    "https://openalex.org/W2279490987",
    "https://openalex.org/W1975147762",
    "https://openalex.org/W3036931110",
    "https://openalex.org/W2953128081",
    "https://openalex.org/W3087318293",
    "https://openalex.org/W2405035126",
    "https://openalex.org/W1988037271",
    "https://openalex.org/W2966357564",
    "https://openalex.org/W2060821341",
    "https://openalex.org/W2962764460",
    "https://openalex.org/W2973114758",
    "https://openalex.org/W3005552578",
    "https://openalex.org/W2119512897",
    "https://openalex.org/W2980789587",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2578240541",
    "https://openalex.org/W1522301498"
  ],
  "abstract": "We apply a Transformer architecture, specifically BERT, to learn flexible and high quality molecular representations for drug discovery problems. We study the impact of using different combinations of self-supervised tasks for pre-training, and present our results for the established Virtual Screening and QSAR benchmarks. We show that: i) The selection of appropriate self-supervised task(s) for pre-training has a significant impact on performance in subsequent downstream tasks such as Virtual Screening. ii) Using auxiliary tasks with more domain relevance for Chemistry, such as learning to predict calculated molecular properties, increases the fidelity of our learnt representations. iii) Finally, we show that molecular representations learnt by our model `MolBert' improve upon the current state of the art on the benchmark datasets.",
  "full_text": "Molecular representation learning with language\nmodels and domain-relevant auxiliary tasks\nBenedek Fabian Thomas Edlich Héléna Gaspar Marwin Segler\nJoshua Meyers Marco Fiscato Mohamed Ahmed\nBenevolentAI\n4-8 Maple St, Bloomsbury, London W1T 5HD\n<firstname.lastname>@benevolent.ai\nAbstract\nWe apply a Transformer architecture, speciﬁcally BERT, to learn ﬂexible and\nhigh quality molecular representations for drug discovery problems, and study the\nimpact of using different combinations of self-supervised tasks for pre-training.\nOur results on established Virtual Screening and QSAR benchmarks show that: i)\nThe selection of appropriate self-supervised task(s) for pre-training has a signiﬁcant\nimpact on performance in subsequent downstream tasks such as Virtual Screening.\nii) Using auxiliary tasks with more domain relevance for Chemistry, such as\nlearning to predict calculated molecular properties, increases the ﬁdelity of our\nlearnt representations. iii) Finally, we show that molecular representations learnt by\nour model ‘MOLBERT’ improve upon the current state of the art on the benchmark\ndatasets.\n1 Introduction\nMolecular representations underpin predictive, generative and analytical tasks in drug discovery [1].\nThe choice of a suitable representation can drastically impact the efﬁciency of discovering a novel drug\ncandidate. For instance, applications such as Virtual Screeningand Quantitative Structure-Activity-\nRelationship (QSAR)modeling rely on the availability of effective molecular representations [2].\nLanguage models have been applied to text-based molecular representations such as Simpliﬁed\nMolecular Input Line Entry System (SMILES) [3]. They show impressive performance across a range\nof domain applications including molecular property [4, 5] and reaction prediction problems [6, 7],\nas well as generative tasks [8]. Numerous strategies have been explored to encourage learning of\nhigh quality representations with language models including input reconstruction [9–11], whereby a\nmodel learns to predict masked or corrupted tokens; and input translation [5, 12], where the goal is to\ntranslate the input to another modality or representation. Further improvements have been made by\nincorporating calculated molecular properties into the representation, either by concatenating with the\nlearnt representations [13], or through devising pre-training schemes [14]. Finally, a range of model\narchitectures have been explored including autoencoders [5], RNNs [9] and transformers [10, 11].\nAside from the modal limitations of representing molecules as strings, a drawback to learning from\ntext-based molecular representations is introduced by the ambiguity of linearizing the molecular\ngraph [ 15]. In the case of SMILES, many valid sequences may represent the same molecule\ndepending on the traversal path of the molecular graph. This ambiguity has led to the development of\ncanonicalization algorithms [16, 17] which, while practical, introduce artifacts to linearized SMILES\nsuch that a language model may be distracted by the rules of canonicalization. Previous works have\nshown the beneﬁts of learning using permutations of SMILES [18].\nMachine Learning for Molecules Workshop at NeurIPS 2020. https://ml4molecules.github.io\narXiv:2011.13230v1  [cs.LG]  26 Nov 2020\nMolBERT\nCLS C ( MASK N...\nCLS C ( C N...\nEMBEDDING\nPHYSCHEMPREDSMILES-EQMASKEDLM\nSMILES (or pair of SMILES)\nFigure 1: Diagram of M OLBERT illustrating the various auxiliary tasks utilized for pre-training.\nIn this work, we evaluate the application of the widely used Bidirectional Encoder Representations\nfrom Transformers (BERT) [19] architecture for the generation of molecular representations. We\nexplore the impact of employing a range of domain-relevant auxiliary tasks during pre-training and\nevaluate the produced learnt representations on downstream Virtual Screening and QSAR benchmarks.\nCode and pre-trained models are available at https://github.com/BenevolentAI/MolBERT.\n2 M OLBERT\nMOLBERT, as depicted in Figure 1, is a bidirectional language model that uses the BERT archi-\ntecture [19]. To understand the impact of pre-training with different domain-relevant tasks on\ndownstream applications, we experiment with the following set of self-supervised tasks:\nMasked language modeling (MASKED LM): The canonical task proposed by BERT, whereby the\nmodel is trained to predict the true identity of masked tokens. The task is optimized using the\ncross-entropy loss between the sequence output and the masked tokens of the input.\nSMILES equivalence (SMILES-EQ): Given an input of two SMILES where the second is, with\nequal probability, either randomly sampled from the training set or a synonymous permutation of\nthe ﬁrst SMILES, the task is to predict whether the two inputs represent the same molecule. This\nis a binary classiﬁcation task, which may be traditionally solved by comparing the canonicalized\nmolecular graphs of the inputs. It is optimized using the cross-entropy loss.\nCalculated molecular descriptor prediction (PHYS CHEM PRED ): Using RDKit [20] we are able\nto calculate a simple set of real-valued descriptors of chemical characteristics and composite models\nof physicochemical properties for each molecule (see Appendix C). The goal of this task is to\npredict the normalized [21] set of descriptors for each molecule. The task is optimized using the\nmean squared error over all predicted values.\nThe ﬁnal loss is given by the arithmetic mean of all individual task losses.\nFine-tuning\nThe representations learnt after pre-training MOLBERT may be applied to downstream tasks in\nseveral manners. Here we explore: i) using representations directly for similarity search, ii) training\na downstream model; in this case, following Winter et al. [5], we use a Support Vector Machine\n(SVM), and ﬁnally iii), following [ 19], we add an explicit downstream task head in the form of a\nnewly initialized network which is then optimized.\nEvaluation methodology\nWe evaluate MOLBERT on two downstream applications: Virtual Screeningand QSAR. In Virtual\nScreening we are typically interested in selecting from a pool of candidate compounds the ones\nthat best satisfy a property of interest, such as the likelihood of binding to a particular drug target.\nAlternatively, in QSAR we are interested in learning to predict a given molecular property, such as\nthe binding afﬁnity to a target of interest. We evaluate MOLBERT when used directly and when\nspecialized for downstream applications using two established benchmarks:\nVirtual Screening:we use the ﬁltered virtual screening subset (version 1.2) from the RDKit bench-\nmarking platform [22, 23]. The benchmark is made up of 69 datasets, each corresponding to an\nindividual protein target. Each dataset consists of a small number of active molecules amongst\na larger number of target speciﬁc decoys. The benchmark measures how well-suited molecular\n2\nw/ permutation w/o permutation\nMaskedLM PhysChemPred SMILES-Eq AUROC BEDROC20 AUROC BEDROC20\n\u0013 \u0013 \u0013 0.685±0.069 0 .246±0.041 0 .707±0.059 0 .280±0.042\n\u0013 \u0013 \u0017 0.738±0.060 0 .323±0.071 0 .740±0.066 0 .322±0.065\n\u0013 \u0017 \u0013 0.483±0.092 0 .092±0.069 0 .493±0.068 0 .108±0.070\n\u0017 \u0013 \u0013 0.476±0.077 0 .064±0.034 0 .514±0.165 0 .084±0.014\n\u0013 \u0017 \u0017 0.696±0.058 0 .283±0.077 0 .676±0.060 0 .250±0.073\n\u0017 \u0013 \u0017 0.719±0.057 0 .293±0.071 0 .716±0.061 0 .290±0.076\n\u0017 \u0017 \u0013 0.129±0.067 0 .005±0.037 0 .508±0.068 0 .048±0.035\nTable 1: The impact of pre-training MOLBERT with different auxiliary task combinations on the\nVirtual Screening benchmark performance. Best values are in bold, higher values are better.\nAUROC BEDROC20\nMOLBERT(100 epochs) 0.743±0.062 0 .344±0.062\nCDDD 0.725±0.057 0 .310±0.080\nRDKit descriptors 0.633±0.027 0 .217±0.000\nECFC4 0.603±0.056 0 .170±0.079\nTable 2: Results for Virtual Screening using the RDKit benchmarking platform.\nrepresentations are to retrieving active compounds from the pool, given a ﬁxed number of query\nmolecules (n= 5) – for details see Riniker and Landrum [22].\nRetrieval is performed according to the cosine distance between MOLBERT embeddings. Fol-\nlowing Riniker and Landrum [22], we report results using: i) the Area Under the Curve of the\nReceiver Operating Characteristic (AUROC) and ii) the Boltzmann-Enhanced Discrimination of\nROC (BEDROC, α= 20) – a widely used early enrichment metric that assigns higher weight to\nthe ﬁrst α% of molecules retrieved from the pool according to the Boltzmann distribution [24].\nQSAR: we use a subset of the MoleculeNet benchmark suite [ 25], which consists of datasets of\nvarying size for a range of QSAR problems. Speciﬁcally we report regression results for the ESOL,\nFreeSolv and Lipophilicity datasets, as well as classiﬁcation results for the BACE, BBBP and HIV\ndatasets. Since MoleculeNet does not provide explicit training, validation and test folds for all\ndatasets, we use folds provided by ChemBench [26] to present reproducible results.\n3 Experimental Evaluation\nIn this section, we ﬁrst present an ablation on MOLBERT using the different pre-training tasks using\nthe Virtual Screening datasets, then report our results in the Virtual Screening and QSAR benchmarks.\nPre-training dataset: All models are pre-trained using the GuacaMol benchmark dataset [ 27]\nconsisting of ∼1.6M compounds curated from ChEMBL [28]. We use the training and validation\nsplits which consist of 80% and 5% of the data, respectively.\nModels: MOLBERT models are implemented using the Hugging Face transformers library [29], and\nuse the BERT-Base architecture (12 attention heads, 12 layers, 768 dimensional hidden layer,∼85M\nparameters). We use the Adam optimizer [ 30] with a learning rate of 3 × 10−5, and train for 20\nepochs, except for the ﬁnal model, which we train for 100 epochs. The average pre-training time for\nMOLBERT was ∼40 hours using 2 GPUs and 16 CPUs.\nFine-tuning: All experiments use the same base model, the best model from the ablation trained\nfor 100 epochs. To ease reproducibility we use the SVM parameters published in Winter et al. [5]\n(C = 5.0, RBF kernel) and all ﬁne-tuning networks are a single linear layer attached to the pooled\noutput. To generate molecular embeddings we use the pooled output, except where MASKED LM is\nthe only task used for pre-training, in which case we use the average of the sequence output, since the\npooled output has no dependent tasks.\nMOLBERT is trained using a ﬁxed vocabulary of 42 tokens and a sequence length of 128 characters.\nIn line with [19], all tasks are trained by masking 15% of the tokenized input. To support the use of\narbitrary length input SMILES at inference time, we use relative positional embeddings as described\nby Dai et al. [31].\nResults\nAblation study:We ﬁrst analyze the utility of using different combinations of tasks for pre-training.\nFrom Table 1, the main observations are that: i) The PHYS CHEM PRED task has the highest impact on\n3\nRegression Datasets: RMSE\nRDKit (norm) ECFC4 CDDD M OLBERT MOLBERT (ﬁnetune)\nESOL 0.687±0.08 0 .902±0.06 0 .567±0.06 0 .552±0.07 0.531±0.04\nFreeSolv 1.671±0.45 2 .876±0.38 1 .456±0.43 1 .523±0.66 0.948±0.33\nLipop 0.738±0.04 0 .770±0.03 0 .669±0.02 0 .602±0.01 0.561±0.03\nClassiﬁcation Dataset: AUROC\nRDKit (norm) ECFC4 CDDD MolBERT MolBERT (ﬁnetune)\nBACE 0.831±0.00 0 .845±0.00 0 .833±0.00 0 .849±0.00 0.866±0.00\nBBBP 0.696±0.00 0 .678±0.00 0 .761±0.00 0 .750±0.00 0.762±0.00\nHIV 0.708±0.00 0 .714±0.00 0 .753±0.00 0 .747±0.00 0.783±0.00\nTable 3: QSAR results on regression and classiﬁcation tasks from MoleculeNet. Best values are in\nbold. ± indicates standard deviation over cross-validation splits. First four columns are generated\nusing the SVM, while the last column refers to ﬁne-tuning a new task head.\nthe performance metrics, with an average BEDROC20 of 0.292 when using the PHYS CHEM PRED\ntask alone (with and without permutations) versus 0.266 for the MASKED LM alone. ii) Although the\nbest performing model is trained on both the PHYS CHEM PRED and MASKED LM, the additive gain\nfrom the MASKED LM task is relatively minor; +0.031 on average for the BEDROC20 metric. iii)\nThe addition of the SMILES-E Q task slightly but consistently decreases performance.\nGiven the effectiveness of pre-training with the PHYS CHEM PRED task, we explored the impact of\ngrouping the 200 calculated descriptors into disjoint related subsets. Table A5 shows that, although\nusing ALL the descriptors achieves the best overall result, the SURFACE properties of a molecule\nprovide a very competitive supervision task using only 25% of the descriptors.\nVirtual Screening:Table 2 compares the performance of MOLBERT when trained for 100 epochs\nwith the best performing auxiliary task combination, with three baseline methods. i) CDDD [5],\na neural model that achieves the current state-of-the-art results for this benchmark. ii) The RDKit\ncalculated physicochemical descriptors [20] used for the PHYS CHEM PRED task during pre-training.\niii) Extended Connectivity Fingerprints with a diamater of 4 (ECFC4 ), one of the most commonly\nused descriptors in drug discovery. Our results show thatMOLBERT outperforms all other descriptors\nboth in terms of overall classiﬁcation and early enrichment. A detailed breakdown of per-dataset\nresults is given in Figure A1 for the BEDROC20 and AUROC, respectively. Finally, upon closer\ninvestigation as to the beneﬁt of input permutation and calculated molecular property prediction, we\nobserved that these strategies enable MOLBERT to organize the learnt embeddings. More concretely,\npre-training with the PHYS CHEM PRED task and input permutation leads to models which on average\nassign a lower pairwise similarity to non-identical compounds; see Appendix B.\nQSAR: To further evaluate the usefulness of MOLBERT embeddings, we build QSAR models\nfor datasets from MoleculeNet [ 25] and include models built using CDDD [ 5], ECFC4 [32] and\nthe normalized RDKit calculated physicochemical descriptors [ 20] as baselines. As described in\nSection 2, we train an SVM (implemented using sklearn [33]) using each molecular representation,\nand compare against ﬁne-tuning MOLBERT.\nFrom the results in Table 3, we see that neural models substantially outperform traditional molecular\nrepresentations (RDKIT and ECFC4). Furthermore, ﬁnetuned MOLBERT models achieve the best\nperformance in all of the six benchmark datasets. We also observe that MOLBERT representations\ncombined with a SVM outperform the other descriptors on three of the six tasks.\n4 Conclusions\nWe have introduced MOLBERT, a language model for learning molecular embeddings using BERT.\nWe investigated the impact of pre-training with domain-relevant auxiliary tasks and found that the\nchoice of self supervision task signiﬁcantly impacts the performance on downstream tasks. Never-\ntheless, with the right set of tasks MOLBERT achieves state-of-the-art performance on established\nVirtual Screeningand QSAR benchmarks. We leave to future work the exploration of how to use\nMOLBERT for learning representations of other entities such as proteins [34–36], along with further\ndevelopments in our learning strategies [37].\n4\nReferences\n[1] Laurianne David, Amol Thakkar, Rocío Mercado, and Ola Engkvist. Molecular representations in AI-driven\ndrug discovery: a review and practical guide. Journal of Cheminformatics, 12(1):1–22, 2020.\n[2] Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, Edgardo Ferran, George Lee, Bin\nLi, Anant Madabhushi, Parantu Shah, Michaela Spitzer, and Shanrong Zhao. Applications of machine\nlearning in drug discovery and development. Nature Reviews Drug Discovery, 18(6):463–477, 2019.\n[3] David Weininger. Smiles, a chemical language and information system. 1. introduction to methodology\nand encoding rules. Journal of chemical information and computer sciences, 28(1):31–36, 1988.\n[4] Stanisław Jastrz˛ ebski, Damian Le´sniak, and Wojciech Marian Czarnecki. Learning to SMILE (S). arXiv\npreprint arXiv:1602.06289, 2016.\n[5] Robin Winter, Floriane Montanari, Frank Noé, and Djork-Arné Clevert. Learning continuous and data-\ndriven molecular descriptors by translating equivalent chemical representations. Chemical Science, 10(6):\n1692–1701, 2019.\n[6] Bowen Liu, Bharath Ramsundar, Prasad Kawthekar, Jade Shi, Joseph Gomes, Quang Luu Nguyen, Stephen\nHo, Jack Sloane, Paul Wender, and Vijay Pande. Retrosynthetic reaction prediction using neural sequence-\nto-sequence models. ACS Central Science, 3(10):1103–1113, 2017.\n[7] Philippe Schwaller, Teodoro Laino, Théophile Gaudin, Peter Bolgar, Christopher A Hunter, Costas Bekas,\nand Alpha A Lee. Molecular transformer: A model for uncertainty-calibrated chemical reaction prediction.\nACS Central Science, 5(9):1572–1583, 2019.\n[8] Marwin HS Segler, Thierry Kogej, Christian Tyrchan, and Mark P Waller. Generating focused molecule\nlibraries for drug discovery with recurrent neural networks. ACS Central Science, 4(1):120–131, 2018.\n[9] Xinhao Li and Denis Fourches. Inductive Transfer Learning for Molecular Activity Prediction: Next-Gen\nQSAR Models with MolPMoFiT. Journal of Cheminformatics, 12(27):1–15, 2020.\n[10] Łukasz Maziarka, Tomasz Danel, Sławomir Mucha, Krzysztof Rataj, Jacek Tabor, and Stanisław Jastrz˛ ebski.\nMolecule Attention Transformer. arXiv preprint arXiv:2002.08264, 2020.\n[11] Sheng Wang, Yuzhi Guo, Yuhong Wang, Hongmao Sun, and Junzhou Huang. Smiles-bert: Large scale\nunsupervised pre-training for molecular property prediction. In Proceedings of the 10th ACM International\nConference on Bioinformatics, Computational Biology and Health Informatics, page 429–436, 2019. doi:\n10.1145/3307339.3342186.\n[12] Paul Morris, Rachel St. Clair, William Edward Hahn, and Elan Barenholtz. Predicting binding from\nscreening assays with transformer network embeddings. Journal of Chemical Information and Modeling,\n60(9):4191–4199, 2020.\n[13] Kevin Yang, Kyle Swanson, Wengong Jin, Connor Coley, Philipp Eiden, Hua Gao, Angel Guzman-Perez,\nTimothy Hopper, Brian Kelley, Miriam Mathea, Andrew Palmer, V olker Settels, Tommi Jaakkola, Klavs\nJensen, and Regina Barzilay. Analyzing learned molecular representations for property prediction. Journal\nof Chemical Information and Modeling, 59(8):3370–3388, 2019.\n[14] Garrett B. Goh, Charles Siegel, Abhinav Vishnu, and Nathan Hodas. Using Rule-Based Labels for Weak\nSupervised Learning: A ChemNet for Transferable Chemical Property Prediction. In Proceedings of the\n24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, page 302–310,\n2018. doi: 10.1145/3219819.3219838.\n[15] Milan Randi ´c. On canonical numbering of atoms in a molecule and graph isomorphism. Journal of\nChemical Information and Computer Sciences, 17(3):171–180, 1977.\n[16] B. Weisfeiler and A. A. Lehman. A reduction of a graph to a canonical form and an algebra arising during\nthis reduction. Nauchno-Technicheskaya Informatsia, 2(9), 1968.\n[17] Nadine Schneider, Roger A. Sayle, and Gregory A. Landrum. Get your atoms in order—an open-\nsource implementation of a novel and robust molecular canonicalization algorithm. Journal of Chemical\nInformation and Modeling, 55(10):2111–2120, 2015.\n[18] Esben Jannik Bjerrum and Boris Sattarov. Improving Chemical Autoencoder Latent Space and Molecular\nDe Novo Generation Diversity with Heteroencoders. Biomolecules, 8(4):131, 2018.\n[19] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep\nbidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\n5\n[20] G. A. Landrum. RDKit: Open-Source Cheminformatics Software, 2020. URL http://www.rdkit.org.\n[21] Kevin Yang, Kyle Swanson, Wengong Jin, Connor Coley, Philipp Eiden, Hua Gao, Angel Guzman-Perez,\nTimothy Hopper, Brian Kelley, Miriam Mathea, Andrew Palmer, V olker Settels, Tommi Jaakkola, Klavs\nJensen, and Regina Barzilay. Analyzing learned molecular representations for property prediction. Journal\nof Chemical Information and Modeling, 59(8):3370–3388, 2019.\n[22] Sereina Riniker and Gregory A Landrum. Open-source platform to benchmark ﬁngerprints for ligand-based\nvirtual screening. Journal of Cheminformatics, 5(1):26, 2013.\n[23] Sereina Riniker, Nikolas Fechner, and Gregory A Landrum. Heterogeneous classiﬁer fusion for ligand-\nbased virtual screening: or, how decision making by committee can be a good thing. Journal of Chemical\nInformation and Modeling, 53(11):2829–2836, 2013.\n[24] Jean-François Truchon and Christopher I Bayly. Evaluating virtual screening methods: good and bad\nmetrics for the “early recognition” problem. Journal of Chemical Information and Modeling, 47(2):\n488–508, 2007.\n[25] Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S Pappu,\nKarl Leswing, and Vijay Pande. Moleculenet: a benchmark for molecular machine learning. Chemical\nScience, 9(2):513–530, 2018.\n[26] Shen Wanxiang. ChemBench: The molecule benchmarks and MolMapNet datasets, 2020. URL https:\n//github.com/shenwanxiang/ChemBench.\n[27] Nathan Brown, Marco Fiscato, Marwin H.S. Segler, and Alain C. Vaucher. GuacaMol: Benchmarking\nModels for de Novo Molecular Design. Journal of Chemical Information and Modeling, 59(3):1096–1108,\n2019.\n[28] Anna Gaulton, Anne Hersey, Michał Nowotka, A. Patrícia Bento, Jon Chambers, David Mendez, Prudence\nMutowo, Francis Atkinson, Louisa J. Bellis, Elena Cibrián-Uhalte, Mark Davies, Nathan Dedman, Anneli\nKarlsson, María Paula Magariños, John P. Overington, George Papadatos, Ines Smit, and Andrew R. Leach.\nThe ChEMBL database in 2017. Nucleic Acids Research, 45(D1):D945–D954, 2017.\n[29] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric\nCistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma,\nYacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,\nand Alexander M. Rush. HuggingFace’s Transformers: State-of-the-art Natural Language Processing.\narXiv preprint arXiv:1910.03771, 2019.\n[30] Diederik P Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. arXiv preprint\narXiv:1412.6980, 2014.\n[31] Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G. Carbonell, Quoc V . Le, and Ruslan Salakhutdi-\nnov. Transformer-xl: Attentive language models beyond a ﬁxed-length context. arXiv preprint\narXiv:1901.02860, 2019.\n[32] David Rogers and Mathew Hahn. Extended-connectivity ﬁngerprints. Journal of Chemical Information\nand Modeling, 50(5):742–754, 2010.\n[33] F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\nR. Weiss, V . Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.\nScikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830, 2011.\n[34] Martin Simonovsky and Joshua Meyers. Deeplytough: Learning structural comparison of protein binding\nsites. Journal of Chemical Information and Modeling, 60(4):2356–2366, 2020.\n[35] Ethan C Alley, Grigory Khimulya, Surojit Biswas, Mohammed AlQuraishi, and George M Church. Uniﬁed\nrational protein engineering with sequence-based deep representation learning. Nature Methods, 16(12):\n1315–1322, 2019.\n[36] Paul Kim, Robin Winter, and Djork-Arné Clevert. Deep protein-ligand binding prediction using unsuper-\nvised learned representations. ChemRxiv, 2020. doi: 10.26434/chemrxiv.11523117.v1.\n[37] Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay S. Pande, and Jure Leskovec.\nStrategies for Pre-training Graph Neural Networks. arXiv preprint arXiv:1905.12265, 2019.\n[38] Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of Machine Learning\nResearch, 9(Nov):2579–2605, 2008.\n6\nAppendix\nA Virtual Screening benchmark: performanceper target\nFigure A1 shows results for MOLBERT and other baseline methods on the individual Virtual Screening datasets\nlisted in [22]. The datasets are sorted based on the BEDROC20 enrichment metric. We observe that MOL-\nBERT displays superior performance for 45 of 69 targets and performs competitively in all other cases.\nFigure A1: BEDROC20 and AUROC performance for each of the target datasets in the Virtual\nScreening benchmark [22] sorted based on the BEDROC20 metric. We report results for the best\nperforming MOLBERT model in our ablation study (see Table 1) trained for 100 epochs.\nB Auxiliary task induced biases in MOLBERT models\nTo understand the types of inductive biases introduced by the different auxiliary tasks used in pre-training, we\nexplore the difference in behaviour of the resulting learnt representations.\nTable A1 lists three well-studied compounds. We sample ten random permutations of each, along with 1000\nrandomly selected molecules from ChEMBL, and use this data to compare the distributions of pairwise cosine\nsimilarities of the representations learnt with each task combination in Table 1.\nSince the benchmark is a nearest neighbor retrieval task, we aim to understand whether learning to ﬁnely\ndisambiguate between molecules correlates with benchmark performance. We hypothesize that models that\nachieve high average pairwise similarity between permutations of the same molecule and a low average pairwise\nsimilarity between random molecules achieve improved benchmark performance.\nFigure A2 gives the results of our analysis where we observe three broad behaviours: First,MOLBERT models that\nwere pre-trained on task combinations including the physicochemical property prediction (PHYS CHEM PRED )\ntask successfully assign high similarities to permutations of the same molecule, while assigning low average\nsimilarity between randomly selected ChEMBL compounds. This suggests that tasks that encourage this large\nmargin property help models organize the embedding space in a more semantically meaningful manner.\nThe MOLBERT representations resulting from a sample of tasks with this characteristic are given in Table A2.\nFor each task we plot t-SNE [ 38] projections of MOLBERT representations for the 1000 randomly selected\nmolecules from ChEMBL in gray and each of the three molecules listed in Table A1 along with their ten\nSMILES permutations. We use the sklearn implementation of t-SNE [33] with parameters: perplexity =\n30, early_exaggeration = 12, learning_rate = 200.\nSecond, two task combinations MASKED LM and MASKED LM + P ERMUTE lead to models that assign very\nlow similarities to both the permutations of the same molecule, and to other molecules. This suggests that these\n7\nSeed Molecule Permutations\nPalbociclib\nC1(NC2=NC=C(N3CCNCC3)C=C2)=NC=C2C(C)=C(C(C)-\n=O)C(=O)N(C3CCCC3)C2=N1\nC1(NC2=NC=C(N3CCNCC3)C=C2)=NC=C2C(C)=C(C(C)=O)C(=O)N(C3CCCC3)C2=N1\nC1CCC(N2C3=NC(NC4=NC=C(N5CCNCC5)C=C4)=NC=C3C(C)=C(C(=O)C)C2=O)C1\nC1(C)=C(C(C)=O)C(=O)N(C2CCCC2)C2=NC(NC3=NC=C(N4CCNCC4)C=C3)=NC=C12\nC1C(N2C3=NC(NC4=NC=C(N5CCNCC5)C=C4)=NC=C3C(C)=C(C(=O)C)C2=O)CCC1\nN1=C(NC2=NC=C3C(C)=C(C(=O)C)C(=O)N(C4CCCC4)C3=N2)C=CC(N2CCNCC2)=C1\nC1=CC(N2CCNCC2)=CN=C1NC1=NC=C2C(C)=C(C(=O)C)C(=O)N(C3CCCC3)C2=N1\nC1NCCN(C2=CN=C(NC3=NC=C4C(C)=C(C(C)=O)C(=O)N(C5CCCC5)C4=N3)C=C2)C1\nC1CCC(N2C3=NC(NC4=NC=C(N5CCNCC5)C=C4)=NC=C3C(C)=C(C(C)=O)C2=O)C1\nC1CN(C2=CN=C(NC3=NC=C4C(=N3)N(C3CCCC3)C(=O)C(C(=O)C)=C4C)C=C2)CCN1\nN1(C2=CN=C(NC3=NC=C4C(=N3)N(C3CCCC3)C(=O)C(C(C)=O)=C4C)C=C2)CCNCC1\nSeliciclib\nCC[C@H](CO)NC1=NC(NCC2=CC=CC=C2)=C2C(=N1)-\nN(C(C)C)C=N2\nC(NC1=C2C(=NC(N[C@H](CC)CO)=N1)N(C(C)C)C=N2)C1=CC=CC=C1\nC(NC1=C2N=CN(C(C)C)C2=NC(N[C@@H](CO)CC)=N1)C1=CC=CC=C1\nC1=CC=C(CNC2=C3C(=NC(N[C@@H](CO)CC)=N2)N(C(C)C)C=N3)C=C1\nCC(C)N1C=NC2=C(NCC3=CC=CC=C3)N=C(N[C@@H](CO)CC)N=C12\nC1=CC(CNC2=C3N=CN(C(C)C)C3=NC(N[C@H](CC)CO)=N2)=CC=C1\nN1(C(C)C)C2=NC(N[C@@H](CO)CC)=NC(NCC3=CC=CC=C3)=C2N=C1\nCC(C)N1C2=NC(N[C@@H](CO)CC)=NC(NCC3=CC=CC=C3)=C2N=C1\nC12=NC(N[C@H](CC)CO)=NC(NCC3=CC=CC=C3)=C1N=CN2C(C)C\n[C@H ](CO)(CC)NC1=NC(NCC2=CC=CC=C2)=C2C(=N1)N(C(C)C)C=N2\nC1=C(CNC2=C3N=CN(C(C)C)C3=NC(N[C@@H](CO)CC)=N2)C=CC=C1\nVenetoclax\nCC1(C)CCC(CN2CCN(C3=CC(OC4=CN=C5C(=C4)C=CN-\n5)=C(C(=O)NS(=O)(=O)C4=CC([N+](=O)[O-])=C(NCC5-\nCCOCC5)C=C4)C=C3)CC2)=C(C2=CC=C(Cl)C=C2)C1\nC1CN(CC2=C(C3=CC=C(Cl)C=C3)CC(C)(C)CC2)CCN1C1=CC(OC2=CN=C3C(=C2)-\nC=CN3)=C(C(NS(C2=CC([N+]([O-])=O)=C(NCC3CCOCC3)C=C2)(=O)=O)=O)C=C1\nC1=CC(C(=O)NS(=O)(=O)C2=CC([N+](=O)[O-])=C(NCC3CCOCC3)C=C2)=C(OC2-\n=CN=C3C(=C2)C=CN3)C=C1N1CCN(CC2=C(C3=CC=C(Cl)C=C3)CC(C)(C)CC2)CC1\n[N+\n](=O)(C1=C(NCC2CCOCC2)C=CC(S(NC(=O)C2=CC=C(N3CCN(CC4=C(C5=CC=C-\n(Cl)C=C5)CC(C)(C)CC4)CC3)C=C2OC2=CN=C3C(=C2)C=CN3)(=O)=O)=C1)[O-]\nC1(C2=CC=C(Cl)C=C2)=C(CN2CCN(C3=CC(OC4=CN=C5NC=CC5=C4)=C(C(NS(=O)-\n(C4=CC([N+]([O-])=O)=C(NCC5CCOCC5)C=C4)=O)=O)C=C3)CC2)CCC(C)(C)C1\n[O- ][N+ ](=O)C1=C(NCC2CCOCC2)C=CC(S(=O)(NC(=O)C2=CC=C(N3CCN(CC4=-\nC(C5=CC=C(Cl)C=C5)CC(C)(C)CC4)CC3)C=C2OC2=CN=C3NC=CC3=C2)=O)=C1\nC1(OC2=CN=C3C(=C2)C=CN3)=CC(N2CCN(CC3=C(C4=CC=C(Cl)C=C4)CC(C)(C)-\nCC3)CC2)=CC=C1C(NS(C1=CC([N+](=O)[O-])=C(NCC2CCOCC2)C=C1)(=O)=O)=O\nC1(C2=C(CN3CCN(C4=CC(OC5=CN=C6C(=C5)C=CN6)=C(C(=O)NS(=O)(C5=CC([N+]-\n(=O)[O-])=C(NCC6CCOCC6)C=C5)=O)C=C4)CC3)CCC(C)(C)C2)=CC=C(Cl)C=C1\nC1(N2CCN(CC3=C(C4=CC=C(Cl)C=C4)CC(C)(C)CC3)CC2)=CC(OC2=CN=C3C(=C2)C-\n=CN3)=C(C(=O)NS(C2=CC([N+]([O-])=O)=C(NCC3CCOCC3)C=C2)(=O)=O)C=C1\nC1C(CNC2=C([N+](=O)[O-])C=C(S(=O)(NC(=O)C3=CC=C(N4CCN(CC5=C(C6-\n=CC=C(Cl)C=C6)CC(C)(C)CC5)CC4)C=C3OC3=CN=C4NC=CC4=C3)=O)C=C2)-\nCCOC1\nC12=CC(OC3=CC(N4CCN(CC5=C(C6=CC=C(Cl)C=C6)CC(C)(C)CC5)CC4)=CC=C3-\nC(NS(=O)(=O)C3=CC([N+]([O-])=O)=C(NCC4CCOCC4)C=C3)=O)=CN=C1NC=C2\nTable A1: Drugs and their color highlighted for the t-SNE plots in Tables A2, A3 and A4.\ncombinations encourage models to map inputs to a large representation space, but fail to structure this space in a\nsemantically meaningful way – observed in the two sets of similarities being almost equal. See Table A3.\nFinally, explicit encouragement of the model to learn to recognise permutations of identical SMILES in the\nform of the SMILES -EQ task does not seem to be sufﬁcient to enable models to increase the average margin\nbetween representations of identical permutations and unrelated molecules. Table A4 shows that the SMILES-\nEQ + P ERMUTE combination is not able to generate a structured representation space. However, when the\nMASKED LM task is added, the embeddings of the different permutations are grouped together. This also results\nin an improved BEDROC from Table 1.\n8\nMaskedLM + Permute + PhysChem\nMaskedLM + PhysChem\nMaskedLM + SMILES-Eq + PhysChem\nMaskedLM + SMILES-Eq + PhysChem + Permute\nPhysChem + Permute\nPhysChem\nMaskedLM + Permute\nMaskedLM\nMaskedLM + SMILES-Eq + PermuteSMILES-Eq + PhysChem + Permute\nSMILES-Eq + PhysChemSMILES-Eq + Permute\nSMILES-Eq\nMaskedLM + SMILES-Eq\nModel\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0Cosine Similarity\nSeliciclib Venetoclax Palbociclib ChEMBL\nFigure A2: Average pairwise cosine similarity for each group (Seliciclib, Venetoclax, Palbociclib,\nChEMBL). Models are sorted from left to right by decreasing BEDROC20 as shown in Table 1.\nMaskedLM + Permute\n+ PhysChem PhysChem + Permute\nMaskedLM + SMILES-Eq\n+ PhysChem + Permute\n0.323 ± 0.0071 0 .293 ± 0.071 0 .246 ± 0.041\n40\n 20\n 0 20 40\nTSNE1\n40\n20\n0\n20\n40\nTSNE2\nchembl\nSeliciclib\nVenetoclax\nPalbociclib\n40\n 20\n 0 20 40\nTSNE1\n40\n20\n0\n20\n40\n60\nTSNE2\nchembl\nSeliciclib\nVenetoclax\nPalbociclib\n40\n 20\n 0 20 40\nTSNE1\n40\n20\n0\n20\n40\nTSNE2\nchembl\nSeliciclib\nVenetoclax\nPalbociclib\nTable A2: t-SNE plots of molecules in Table A1. Examples of tasks which encourage disambiguation\nbetween permutations of SMILES and others. Numbers in heading denote the BEDROC performance\nfrom Table 1.\nMaskedLM MaskedLM + Permute\n0.250 ± 0.073 0 .283 ± 0.077\n40\n 20\n 0 20 40\nTSNE1\n60\n40\n20\n0\n20\n40\nTSNE2\nchembl\nSeliciclib\nVenetoclax\nPalbociclib\n40\n 20\n 0 20 40\nTSNE1\n60\n40\n20\n0\n20\n40\nTSNE2\nchembl\nSeliciclib\nVenetoclax\nPalbociclib\nTable A3: t-SNE plots of molecules in Table A1. Examples of task combinations which don’t\nencourage disambiguation between permutations of SMILES and others. Numbers in heading denote\nthe BEDROC performance from Table 1.\n9\nSMILES-Eq + Permute\nMaskedLM + SMILES-Eq\n+ Permute\n0.005 ± 0.037 0 .092 ± 0.069\n20\n 10\n 0 10 20\nTSNE1\n30\n20\n10\n0\n10\n20\n30\nTSNE2\nchembl\nSeliciclib\nVenetoclax\nPalbociclib\n40\n 20\n 0 20 40\nTSNE1\n40\n20\n0\n20\n40\nTSNE2\nchembl\nSeliciclib\nVenetoclax\nPalbociclib\nTable A4: t-SNE plots of molecules in Table A1 for two models trained with the SMILES-E Q\ntask. It shows that even though this task is speciﬁcally aimed at teaching a model the equivalence of\npermuted SMILES, it alone is not sufﬁcient to learn a structured representation space. Numbers in\nheading denote the BEDROC performance from Table 1.\nn AUROC BEDROC20\nALL 200 0.738 ± 0.060 0 .323 ± 0.071\nSURFACE 49 0.738 ± 0.061 0.310 ± 0.056\nCHARGE 18 0.711 ± 0.063 0 .270 ± 0.074\nFRAGMENT 101 0.704 ± 0.065 0 .277 ± 0.070\nSIMPLE 8 0.695 ± 0.065 0 .255 ± 0.060\nGRAPH 19 0.693 ± 0.066 0 .249 ± 0.067\nESTATE 25 0.676 ± 0.063 0 .232 ± 0.070\nDRUGLIKENESS 24 0.671 ± 0.060 0 .214 ± 0.069\nLOGP 13 0.651 ± 0.064 0 .186 ± 0.064\nREFRACTIVITY 11 0.649 ± 0.063 0 .193 ± 0.058\nGENERAL 12 0.633 ± 0.064 0 .201 ± 0.069\nTable A5: AUROC and BEDROC20 on the RDKit virtual screening benchmark forMOLBERT trained\nwith various subsets of the RDKit calculated physicochemical properties.\nC PhysChemPred subset ablation\nTable A5 gives an ablation of the PHYS CHEM PRED task by grouping the 200 descriptors used into smaller\nsubsets of related descriptors, and repeating the Virtual Screening benchmark.\nFrom the table we observe that in general all physicochemical descriptors do well on the benchmark. Moreover,\nsome subsets which contain very few descriptors ( SURFACE n = 49 and CHARGE n = 18 ) are able to\nachieve almost the same results as using all of physicochemical descriptors.\nFinally, the lists of descriptors and their groupings are as follows:\nALL: Full set of 200 descriptors from RDKit.\nBalabanJ, BertzCT, Chi0, Chi0n, Chi0v, Chi1, Chi1n, Chi1v, Chi2n, Chi2v,\nChi3n, Chi3v, Chi4n, Chi4v, EState_VSA1, EState_VSA10, EState_VSA11,\nEState_VSA2, EState_VSA3, EState_VSA4, EState_VSA5, EState_VSA6, EState_VSA7,\nEState_VSA8, EState_VSA9, ExactMolWt, FpDensityMorgan1, FpDensityMorgan2,\nFpDensityMorgan3, FractionCSP3, HallKierAlpha, HeavyAtomCount, HeavyAtomMolWt,\nIpc, Kappa1, Kappa2, Kappa3, LabuteASA, MaxAbsEStateIndex, MaxAbsPartialCharge,\nMaxEStateIndex, MaxPartialCharge, MinAbsEStateIndex, MinAbsPartialCharge,\nMinEStateIndex, MinPartialCharge, MolLogP, MolMR, MolWt, NHOHCount, NOCount,\nNumAliphaticCarbocycles, NumAliphaticHeterocycles, NumAliphaticRings,\nNumAromaticCarbocycles, NumAromaticHeterocycles, NumAromaticRings, NumHAcceptors,\nNumHDonors, NumHeteroatoms, NumRadicalElectrons, NumRotatableBonds,\nNumSaturatedCarbocycles, NumSaturatedHeterocycles, NumSaturatedRings,\nNumValenceElectrons, PEOE_VSA1, PEOE_VSA10, PEOE_VSA11, PEOE_VSA12, PEOE_VSA13,\n10\nPEOE_VSA14, PEOE_VSA2, PEOE_VSA3, PEOE_VSA4, PEOE_VSA5, PEOE_VSA6, PEOE_VSA7,\nPEOE_VSA8, PEOE_VSA9, RingCount, SMR_VSA1, SMR_VSA10, SMR_VSA2, SMR_VSA3,\nSMR_VSA4, SMR_VSA5, SMR_VSA6, SMR_VSA7, SMR_VSA8, SMR_VSA9, SlogP_VSA1,\nSlogP_VSA10, SlogP_VSA11, SlogP_VSA12, SlogP_VSA2, SlogP_VSA3, SlogP_VSA4,\nSlogP_VSA5, SlogP_VSA6, SlogP_VSA7, SlogP_VSA8, SlogP_VSA9, TPSA, VSA_EState1,\nVSA_EState10, VSA_EState2, VSA_EState3, VSA_EState4, VSA_EState5, VSA_EState6,\nVSA_EState7, VSA_EState8, VSA_EState9, fr_Al_COO, fr_Al_OH, fr_Al_OH_noTert,\nfr_ArN, fr_Ar_COO, fr_Ar_N, fr_Ar_NH, fr_Ar_OH, fr_COO, fr_COO2, fr_C_O,\nfr_C_O_noCOO, fr_C_S, fr_HOCCN, fr_Imine, fr_NH0, fr_NH1, fr_NH2, fr_N_O,\nfr_Ndealkylation1, fr_Ndealkylation2, fr_Nhpyrrole, fr_SH, fr_aldehyde,\nfr_alkyl_carbamate, fr_alkyl_halide, fr_allylic_oxid, fr_amide, fr_amidine,\nfr_aniline, fr_aryl_methyl, fr_azide, fr_azo, fr_barbitur, fr_benzene,\nfr_benzodiazepine, fr_bicyclic, fr_diazo, fr_dihydropyridine, fr_epoxide,\nfr_ester, fr_ether, fr_furan, fr_guanido, fr_halogen, fr_hdrzine, fr_hdrzone,\nfr_imidazole, fr_imide, fr_isocyan, fr_isothiocyan, fr_ketone, fr_ketone_Topliss,\nfr_lactam, fr_lactone, fr_methoxy, fr_morpholine, fr_nitrile, fr_nitro,\nfr_nitro_arom, fr_nitro_arom_nonortho, fr_nitroso, fr_oxazole, fr_oxime,\nfr_para_hydroxylation, fr_phenol, fr_phenol_noOrthoHbond, fr_phos_acid,\nfr_phos_ester, fr_piperdine, fr_piperzine, fr_priamide, fr_prisulfonamd,\nfr_pyridine, fr_quatN, fr_sulfide, fr_sulfonamd, fr_sulfone, fr_term_acetylene,\nfr_tetrazole, fr_thiazole, fr_thiocyan, fr_thiophene, fr_unbrch_alkane, fr_urea,\nqed\nSURFACE: MOE-based surface descriptor subset.\nEState_VSA1, EState_VSA10, EState_VSA11, EState_VSA2, EState_VSA3, EState_VSA4,\nEState_VSA5, EState_VSA6, EState_VSA7, EState_VSA8, EState_VSA9, LabuteASA,\nPEOE_VSA1, PEOE_VSA10, PEOE_VSA11, PEOE_VSA12, PEOE_VSA13, PEOE_VSA14, PEOE_VSA2,\nPEOE_VSA3, PEOE_VSA4, PEOE_VSA5, PEOE_VSA6, PEOE_VSA7, PEOE_VSA8, PEOE_VSA9,\nSMR_VSA1, SMR_VSA10, SMR_VSA2, SMR_VSA3, SMR_VSA4, SMR_VSA5, SMR_VSA6, SMR_VSA7,\nSMR_VSA8, SMR_VSA9, SlogP_VSA1, SlogP_VSA10, SlogP_VSA11, SlogP_VSA12, SlogP_VSA2,\nSlogP_VSA3, SlogP_VSA4, SlogP_VSA5, SlogP_VSA6, SlogP_VSA7, SlogP_VSA8,\nSlogP_VSA9, TPSA\nCHARGE: Partial charge and VSA/charge descriptor subset.\nMaxAbsPartialCharge, MaxPartialCharge, MinAbsPartialCharge, MinPartialCharge,\nPEOE_VSA1, PEOE_VSA10, PEOE_VSA11, PEOE_VSA12, PEOE_VSA13, PEOE_VSA14, PEOE_VSA2,\nPEOE_VSA3, PEOE_VSA4, PEOE_VSA5, PEOE_VSA6, PEOE_VSA7, PEOE_VSA8, PEOE_VSA9\nFRAGMENT: Count and fragment based descriptor subset.\nNHOHCount, NOCount, NumAliphaticCarbocycles, NumAliphaticHeterocycles,\nNumAliphaticRings, NumAromaticCarbocycles, NumAromaticHeterocycles,\nNumAromaticRings, NumHAcceptors, NumHDonors, NumHeteroatoms, NumRotatableBonds,\nNumSaturatedCarbocycles, NumSaturatedHeterocycles, NumSaturatedRings,\nRingCount, fr_Al_COO, fr_Al_OH, fr_Al_OH_noTert, fr_ArN, fr_Ar_COO, fr_Ar_N,\nfr_Ar_NH, fr_Ar_OH, fr_COO, fr_COO2, fr_C_O, fr_C_O_noCOO, fr_C_S, fr_HOCCN,\nfr_Imine, fr_NH0, fr_NH1, fr_NH2, fr_N_O, fr_Ndealkylation1, fr_Ndealkylation2,\nfr_Nhpyrrole, fr_SH, fr_aldehyde, fr_alkyl_carbamate, fr_alkyl_halide,\nfr_allylic_oxid, fr_amide, fr_amidine, fr_aniline, fr_aryl_methyl, fr_azide,\nfr_azo, fr_barbitur, fr_benzene, fr_benzodiazepine, fr_bicyclic, fr_diazo,\nfr_dihydropyridine, fr_epoxide, fr_ester, fr_ether, fr_furan, fr_guanido,\nfr_halogen, fr_hdrzine, fr_hdrzone, fr_imidazole, fr_imide, fr_isocyan,\nfr_isothiocyan, fr_ketone, fr_ketone_Topliss, fr_lactam, fr_lactone, fr_methoxy,\nfr_morpholine, fr_nitrile, fr_nitro, fr_nitro_arom, fr_nitro_arom_nonortho,\nfr_nitroso, fr_oxazole, fr_oxime, fr_para_hydroxylation, fr_phenol,\nfr_phenol_noOrthoHbond, fr_phos_acid, fr_phos_ester, fr_piperdine, fr_piperzine,\nfr_priamide, fr_prisulfonamd, fr_pyridine, fr_quatN, fr_sulfide, fr_sulfonamd,\nfr_sulfone, fr_term_acetylene, fr_tetrazole, fr_thiazole, fr_thiocyan,\nfr_thiophene, fr_unbrch_alkane, fr_urea\nSIMPLE:Small set of commonly used descriptors.\nFpDensityMorgan2, FractionCSP3, MolLogP, MolWt, NumHAcceptors, NumHDonors,\nNumRotatableBonds, TPSA\nGRAPH: Graph descriptor subset (following the grouping found in theGraphDescriptors module in RDKit).\nBalabanJ, BertzCT, Chi0, Chi0n, Chi0v, Chi1, Chi1n, Chi1v, Chi2n, Chi2v, Chi3n,\nChi3v, Chi4n, Chi4v, HallKierAlpha, Ipc, Kappa1, Kappa2, Kappa3\nESTATE: Electrotopological state (e-state) and VSA/e-state descriptor subset.\nEState_VSA1, EState_VSA10, EState_VSA11, EState_VSA2, EState_VSA3,\n11\nEState_VSA4, EState_VSA5, EState_VSA6, EState_VSA7, EState_VSA8, EState_VSA9,\nMaxAbsEStateIndex, MaxEStateIndex, MinAbsEStateIndex, MinEStateIndex, VSA_EState1,\nVSA_EState10, VSA_EState2, VSA_EState3, VSA_EState4, VSA_EState5, VSA_EState6,\nVSA_EState7, VSA_EState8, VSA_EState9\nDRUGLIKENESS: Subset of descriptors commonly used to assess druglikeness.\nExactMolWt, FractionCSP3, HeavyAtomCount, MolLogP, MolMR, MolWt, NHOHCount,\nNOCount, NumAliphaticCarbocycles, NumAliphaticHeterocycles, NumAliphaticRings,\nNumAromaticCarbocycles, NumAromaticHeterocycles, NumAromaticRings, NumHAcceptors,\nNumHDonors, NumHeteroatoms, NumRotatableBonds, NumSaturatedCarbocycles,\nNumSaturatedHeterocycles, NumSaturatedRings, RingCount, TPSA, qed\nLOGP: LogP and VSA/LogP descriptor subset.\nMolLogP, SlogP_VSA1, SlogP_VSA10, SlogP_VSA11, SlogP_VSA12, SlogP_VSA2,\nSlogP_VSA3, SlogP_VSA4, SlogP_VSA5, SlogP_VSA6, SlogP_VSA7, SlogP_VSA8, SlogP_VSA9\nREFRACTIVITY: MOE-based refractivity related descriptor subset.\nMolMR, SMR_VSA1, SMR_VSA10, SMR_VSA2, SMR_VSA3, SMR_VSA4, SMR_VSA5, SMR_VSA6,\nSMR_VSA7, SMR_VSA8, SMR_VSA9\nGENERAL: General descriptor subset (following the grouping found in the Descriptors module in RDKit).\nExactMolWt, FpDensityMorgan1, FpDensityMorgan2, FpDensityMorgan3, HeavyAtomMolWt,\nMaxAbsPartialCharge, MaxPartialCharge, MinAbsPartialCharge, MinPartialCharge,\nMolWt, NumRadicalElectrons, NumValenceElectrons\n12",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7378416061401367
    },
    {
      "name": "Virtual screening",
      "score": 0.7320029139518738
    },
    {
      "name": "Transformer",
      "score": 0.6542137265205383
    },
    {
      "name": "Machine learning",
      "score": 0.5634262561798096
    },
    {
      "name": "Fidelity",
      "score": 0.5622067451477051
    },
    {
      "name": "Relevance (law)",
      "score": 0.5615184307098389
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5612612962722778
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5524842739105225
    },
    {
      "name": "Task (project management)",
      "score": 0.5449740290641785
    },
    {
      "name": "Language model",
      "score": 0.47728481888771057
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.46312981843948364
    },
    {
      "name": "Representation (politics)",
      "score": 0.45736464858055115
    },
    {
      "name": "Natural language processing",
      "score": 0.39732348918914795
    },
    {
      "name": "Drug discovery",
      "score": 0.37785854935646057
    },
    {
      "name": "Bioinformatics",
      "score": 0.13819444179534912
    },
    {
      "name": "Engineering",
      "score": 0.07899484038352966
    },
    {
      "name": "Biology",
      "score": 0.07763424515724182
    },
    {
      "name": "Telecommunications",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210122598",
      "name": "BenevolentAI (United Kingdom)",
      "country": "GB"
    }
  ],
  "cited_by": 110
}