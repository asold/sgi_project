{
  "title": "I-MAD: A Novel Interpretable Malware Detector Using Hierarchical Transformer.",
  "url": "https://openalex.org/W2972633094",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A5063351983",
      "name": "Miles Q. Li",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5021788449",
      "name": "Benjamin C. M. Fung",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5052958340",
      "name": "Philippe Charland",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5007693994",
      "name": "Steven H. H. Ding",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2126734536",
    "https://openalex.org/W1580559113",
    "https://openalex.org/W2169492277",
    "https://openalex.org/W2971274815",
    "https://openalex.org/W2144112223",
    "https://openalex.org/W2963271116",
    "https://openalex.org/W2945936049",
    "https://openalex.org/W2099053789",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W1893133781",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2732916693",
    "https://openalex.org/W2964308564",
    "https://openalex.org/W2944815030",
    "https://openalex.org/W2150795982",
    "https://openalex.org/W1663973292",
    "https://openalex.org/W2247776437",
    "https://openalex.org/W1966948031",
    "https://openalex.org/W1902237438",
    "https://openalex.org/W2248270447",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2899771611",
    "https://openalex.org/W928598251"
  ],
  "abstract": "Malware imposes tremendous threats to computer users nowadays. Since signature-based malware detection methods are neither effective nor efficient to identify new malware, many machine learning-based methods have been proposed. A common disadvantage of existing machine learning methods is that they are not based on understanding the full semantic meaning of assembly code of an executable. They rather use short assembly code fragments, because assembly code is usually too long to be modelled in its entirety. Another disadvantage is that those methods have either inferior performance or bad interpretability. To overcome these challenges, we propose an Interpretable MAware Detector (I-MAD), which achieves state-of-the-art performance on static malware detection with excellent interpretability. It integrates a hierarchical Transformer network that can understand assembly code at the basic block, function, and executable level. It also integrates our novel interpretable feed-forward neural network to provide interpretations for its detection results by pointing out the impact of each feature with respect to the prediction. Experiment results show that our model significantly outperforms previous state-of-the-art static malware detection models and presents meaningful interpretations.",
  "full_text": "I-MAD: Interpretable Malware Detector Using Galaxy Transformer\nMiles Q. Lia, Benjamin C. M. Fungb,∗, Philippe Charlandc and Steven H. H. Dingd\naSchool of Computer Science, McGill University, Montreal, Canada\nbSchool of Information Studies, McGill University, Montreal, Canada\ncMission Critical Cyber Security Section, Defence R&D Canada, Quebec, Canada\ndSchool of Computing, Queen’s University, Kingston, Canada\nARTICLE INFO\nKeywords:\nCybersecurity\nMalware detection\nDeep learning\nTransformers\nInterpretability\nAbstract\nMalware currently presents a number of serious threats to computer users. Signature-based mal-\nware detection methods are limited in detecting new malware samples that are signiﬁcantly diﬀerent\nfromknownones. Therefore,machinelearning-basedmethodshavebeenproposed,buttherearetwo\nchallenges these methods face. The ﬁrst is to model the full semantics behind the assembly code of\nmalware. The second challenge is to provide interpretable results while keeping excellent detection\nperformance. Inthispaper,weproposean InterpretableMAlwareDetector (I-MAD)thatoutperforms\nstate-of-the-artstaticmalwaredetectionmodelsregardingaccuracywithexcellentinterpretability. To\nimprovethedetectionperformance, I-MADincorporatesanovelnetworkcomponentcalledthe Galaxy\nTransformer networkthat can understand assembly code at the basic block, function, and executable\nlevels. It also incorporates our proposed interpretable feed-forward neural network to provide in-\nterpretations for its detection results by quantifying the impact of each feature with respect to the\nprediction. Experimentresultsshowthatourmodelsigniﬁcantlyoutperformsexistingstate-of-the-art\nstatic malware detection models and presents meaningful interpretations.\n1. Introduction\nMalware is software written in order to steal credentials\nof computer users, damage computer systems, encrypt doc-\numents for ransom, and other nefarious goals. Recogniz-\ning malware samples downloaded by legitimate users in a\ntimely manner is of crucial importance for users’ protec-\ntion. Signature-basedmalwaredetectionmethodsarewidely\nused in antivirus products, but they are limited in recogniz-\ning signiﬁcant variants of existing malware and new mal-\nware [57, 19]. There is thus a pressing need to create an in-\ntelligentmalwaredetectionsystemthathasbettergenerabil-\nity to capture new malware or nontrivial variants of known\nmalware.\nMachine learning-based malware analysis methods [57,\n37, 17, 6, 48, 20] can automatically learn common patterns\nof malware from the feature space that have better general-\nization ability than manually crafted signatures. However,\nthere are two major challenges for machine learning-based\nmalware detection models.\nInterpretability is one of the dominant features for clas-\nsiﬁcation models in some domains, such as healthcare and\ncybersecurity. In cybersecurity, the interpretations can help\nmalware analysts justify the classiﬁcation results and cre-\nate a knowledge base of malware samples. Hidden Markov\nmodel(HMM)[53,55]andattention-basedrecurrentneural\nnetwork (RNN) [15] have been proposed to provide analyz-\nableorinterpretableclassiﬁcationresultsonsequentialdata.\nLinearmodelssuchaslogistic/softmaxregressionandNaive\nBayesproduceinterpretableresultsonvectorialdatabutusu-\n∗Corresponding author.\nmiles.qi.li@mail.mcgill.ca (M.Q. Li);ben.fung@mcgill.ca\n(B.C.M. Fung);philippe.charland@drdc-rddc.gc.ca (P. Charland);\nding@cs.queensu.ca (S.H.H. Ding)\nORCID(s): 0000-0001-8423-2906 (B.C.M. Fung)\nallyyieldinferiorclassiﬁcationperformancethannon-linear\nmodelssuchasmulti-layerfeed-forwardneuralnetworks[11].\nHowever, the hidden layers between the input and the lo-\ngistic/softmax layer make multi-layer feed-forward neural\nnetworkslosetheinterpretabilityoflogistic/softmaxregres-\nsion to directly attribute the impact of each feature. It’s still\na challenge to keep interpretability as well as classiﬁcation\nperformance for feed-forward neural networks.\nAs the workload of malware exists mainly in its assem-\nbly code, modelling the assembly code could provide im-\nportant information for malware detection. However, it is\nchallenging to model the whole assembly code of executa-\nbles because they are very long sequences. An executable\nof 1 MB could have hundreds of thousands of instructions.\nNoeﬀectivetrainingapproacheshavebeenproposedtotrain\nsuch long sequences, and the memory consumption cannot\nbehandledwithstandardhardwareforsuchlongsequences.\nDeep learning models have achieved signiﬁcant break-\nthroughs in understanding natural language when properly\ntrainedonlargecorpora[41,20,42]. Transformer[52]based\nmodels especially achieve state-of-the-art results in natural\nlanguage understanding and generation [20, 41, 22, 42, 45,\n9]. However, their successful applications are mainly on\nshorttext,i.e.,sentence-leveltaskssuchasparaphrasedetec-\ntion and sentiment analysis [41, 20], or on short-document\ntextssuchasreadingcomprehensionandautomaticsumma-\nrizationofnewsarticles[22]. Forexample,thestate-of-the-\nart sequence modelGPT-3 [9] can process sequences of a\nmaximum length of 2,048 tokens. That makes the transfer-\nenceofthesuccessofexistingmethodstounderstandingas-\nsembly code a challenge. Apart from the fact that assembly\ncode is too long, the diﬀerences between natural language\nand assembly code in the structure composition and basic\nunits stand as another problem to solve.\nM. Li et al.:Preprint submitted to Elsevier Page 1 of 15\narXiv:1909.06865v3  [cs.LG]  21 Jun 2021\nI-MAD: Interpretable Malware Detector\nFigure 1: The comparison of topology of theTransformer, Star/Star-Plus Transformer, andGalaxy Transformer.\nDespite the fact that the assembly code of an executable\nis usually very long, it has an innate hierarchical structure:\ninstructions form basic blocks, basic blocks form assembly\nfunctions, and assembly functions form the ensemble of as-\nsemblycode(i.e.,thefulllogic)ofanexecutable. Thelengths\nofbasicblocks,assemblyfunctions,andtheensembleofthe\nassembly code of an executable in terms of their direct sub-\nunits are usually within thousands. Based on this character-\nistic, we propose theGalaxy Transformernetwork. It con-\ntains three components, namely theSatellite-Planet Trans-\nformer, the Planet-Star Transformer, and theStar-Galaxy\nTransformer. They are three customizedStar-Plus Trans-\nformer networks organized in a hierarchy in order to under-\nstand the semantic meaning of the assembly code of an ex-\necutable at diﬀerent levels: basic block, assembly function,\nand executable. TheStar-Plus Transformeris our improved\nversion of theStar Transformer[27], which was proposed\nfornaturallanguageunderstandingasavariantofthe Trans-\nformer [52]. The time complexity and space complexity of\nTransformer is O(n2), where n is the length of the token.\nTheStar Transformerreplaces the fully connected structure\nof the Transformer with a star-shaped topology to reduce\nthe complexities toO(n), and it achieves better results on\nmodestly sized datasets. A comparison of the topology be-\ntween theTransformer, theStar/Star-Plus Transformer, and\ntheGalaxyTransformer isshowninFigure1. Ourproposed\nuniverse-like topology of theGalaxy Transformermakes it\npossible to train very long sequences.\nTo provide interpretations for the classiﬁcation results,\nwe propose a novelinterpretable feed-forward neural net-\nwork(IFFNN)astheotherkeycomponentofourfullmodel,\ntheInterpretableMAlwareDetector (I-MAD).Ithasthemod-\nelling power of a multi-layer neural network and the inter-\npretability of a logistic regression model. An example of\nthe prediction and its interpretation is given in Table 1. It\nshows the detection result of a target ﬁle, the conﬁdence in\nthe result, the primary contributing features that lead to the\nprediction, and the most related assembly functions.\nThe contributions of this paper are summarized below:\n1. We propose theGalaxy Transformeras an early at-\ntempt in the literature to model the full sequences of\nassembly code for malware detection.\n2. Weproposetwopre-trainingtaskstotrainthe Satellite-\nPlanetTransformerandPlanet-StarTransformer,which\nare both components of theGalaxy Transformer, to\nunderstandthesemanticmeaningofassemblycodeat\nthe basic block and assembly function levels.\n3. We improve the way to use printable string features\nand PE import features from previous works with our\ninsights on malware.\n4. We propose a novel IFFNN as the classiﬁcation mod-\nule ofI-MAD. It has the same interpretability as lo-\ngistic regression and the modelling power of multi-\nlayer feed-forward neural networks. It allowsI-MAD\nto quantify the impact of each feature for the classiﬁ-\ncationresults. Itisalsoageneralclassiﬁcationmodule\nthat can be applied to other classiﬁcation tasks.\nThe rest of the paper is organized as follows. Section 2\ndiscusses related work. Section 3 deﬁnes the research prob-\nlem. Section 4 provides the details of our proposed method.\nSection5presentstheexperimentresultsandanalyses. Sec-\ntion 6 discusses the limitations and our future work. Sec-\ntion 7 concludes the paper.\n2. Related Work\n2.1. Malware Detection\nMalwaredetectionmethodsfallintothreecategories: static,\ndynamic,andhybrid[18]. Wesummarizethecommonstatic\nand dynamic features in Table 2.\nStaticmethodsexaminethestaticcontentofanexecutable,\nwhiledynamicmethodsrunanexecutableandanalyzeitsbe-\nhaviors. Features used in static methods include binary se-\nquences[49,31,3,48,43,25],assemblycodesequences[37,\n17,2,3,47,25],numericalPEheaderfeatures[3,6,48],PE\nM. Li et al.:Preprint submitted to Elsevier Page 2 of 15\nI-MAD: Interpretable Malware Detector\nTable 1\nSample result of our malware detection and its interpretation,\nwhich includes the 5 factors that contribute most to the pre-\ndiction and the most related assembly functions.\nFile: 05c199.exe\nPrediction: malicious\nConﬁdence: 100%\nPrimary factors leading to the prediction of malicious\nFeature description Feature value Impact\nAssembly code N/A 14.56\nNumber of PE imports 8 5.12\nMajor operating system version 1 1.49\nFrequency of the string \"Sleep\" 1 0.82\nFrequency of the string \".data\" 1 0.59\nMost inﬂuential assembly functions\nsub_401010\nsub_4010AE\nimports/API calls [49, 6, 48, 39, 25], printable strings [49,\n29,48],andmalwareimages[38,54,51]. Themostcommon\nway to use binary sequences or assembly code sequences is\nto cut them into n-gram pieces to form features [49, 31, 37,\n17, 2, 3, 47, 48]. Some studies ﬁnd that byte n-grams are\neﬀectivefeatures[7],whileotherssuggestthatbyten-grams\nare weak or deeply ﬂawed [44] and assembly code is more\neﬀective [37, 47]. As control ﬂow graphs could be more\nrobust than assembly code against some obfuscation tech-\nniques, there are also instance-based detection methods that\nidentify malware by checking whether an executable con-\ntains assembly functions or control ﬂow graphs of known\nmalware [12, 3, 13, 14]. Because they are instance-based\nmethods, theysuﬀerfromeﬃciencyissueswhentheknown\nmalware database is large.\nDynamic methods run a target executable in an isolated\nenvironment, e.g., a virtual machine or an emulator, and ex-\ntractfeaturessuchasthememoryimage[33,16,28],theexe-\ncutedinstructions[46,17,2,3],andtheinvokedsystemcalls\nor behaviors derived from them [8, 24, 3, 16, 29, 47, 28, 1].\nBoth static and dynamic methods have their advantages\nanddisadvantages. Comparedwithstaticmethods,dynamic\nmethodsprovidemoreabundantanddirectinformation. Even\nthoughbothstaticanddynamicmethodsextractsystemcalls\nas features, the parameters passed to those invoked system\ncalls can always be seen with dynamic methods, which is\nnot the case with static methods [8, 16, 29, 47]. Moreover,\nwhen a malicious executable is packed or polymorphic, the\npayload probably cannot be seen by static methods. Yet, to\nperformitsmaliciousactionsitmustrevealthepayloaddur-\ning execution [8]. This gives another advantage to dynamic\nover static methods. Therefore, dynamic methods can of-\ntenachievebetterresultsinthemostchallengingcases[53].\nHowever,itdoesnotmeanthatstaticmethodscannotcapture\nmalware with those mechanisms, because their use is suspi-\nciousandcanbedetected. Previousworksonstaticmalware\ndetectionshowthatwhenanalyzinganunknownexecutable\nfrom multiple feature scopes, it is hard for the malware to\nTable 2\nCommon static and dynamic features for malware detection.\nStatic Dynamic\nbinary sequences memory image\nassembly code executed instructions\nPE header numerical ﬁelds invoked system calls\nPE imports/API calls behaviors\nprintable strings\nmalware images\ncontrol ﬂow graph\nevadedetection[3,29]. Ontheotherhand,oneseriousshort-\ncomingofdynamicmethodsisthatwhenmalwareﬁndsthat\nits execution is being monitored, it may not perform its ma-\nlicious action to evade detection. Thus, dynamic methods\nmayfailtodetectit[8,57]. Inaddition,dynamicallyanalyz-\ning an executable is very time consuming.\nHybridmethodsextractbothstaticanddynamicfeatures\nandintegratethemintoonemalwaredetectionmodel[3,29,\n47, 18]. These two kinds of features are expected to pro-\nvide complementary information to the model so that it has\na more comprehensive view of a sample.\n2.2. Transformers\nAs programming languages and natural languages share\nsomesimilarcharacteristics,theexperienceinmodelingthe\nlattercanbecustomizedtomodeltheformer. BeforeVaswani\net al. [52] proposed the deep learning model known as the\nTransformer, most state-of-the-art neural machine transla-\ntion models belonged to the class ofattention-based recur-\nrentneuralnetwork (RNN)models. Inthesemodels,an RNN\nis used to encode the source text, and anotherRNN with at-\ntention mechanism is used to generate the translation word\nby word [5, 36]. The attention mechanism is used to de-\ntermine the importance of the words in the source text for\ngenerating each translated word. One disadvantage of this\ntype of model is that the recurrence nature precludes par-\nallelism. Another disadvantage is that the attention mech-\nanism assigns only one importance weight to a word in the\nsource text so it can focus on just one aspect of the words.\nThe Transformeraddresses both problems and achieves\nnew state-of-the-art performance on machine translation by\nabandoning theRNN and relying only on an improved at-\ntention mechanism [52]. The attention mechanism in the\nTransformerisreferredtoas multi-headattention,whichal-\nlows multiple attention weights to be assigned to each item.\nEachweightcorrespondstooneaspectofanitem,thustheir\nattention mechanism is more powerful than the previously\nproposed attention mechanism in its modeling ability [52].\nAs there is noRNN in it, the recurrence nature of the en-\ncoderdoesnotexistanymore,whichtremendouslyincreases\nthe parallelism and computing eﬃciency. Since 2017, re-\nsearchershaveseenthepotentialofthe Transformerandpro-\nposed their own ways to pre-train theTransformer on un-\nlabeled corpora that are abundant and then ﬁne-tune it for\ndownstreamNLPtasks. Theyconstantlyachievesigniﬁcantly\nM. Li et al.:Preprint submitted to Elsevier Page 3 of 15\nI-MAD: Interpretable Malware Detector\nbetterresultsthanpreviousmethodsonmanyNLPtasks[41,\n20,22,42,56,45,9]. Theproblemofthe Transformeristhat\nitcomputestheattentionweightsbetweenanytwoitemsofa\nsequence, which leads toO(n2) time and space complexity.\nTherefore, theStar Transformer[27] is proposed to reduce\nthecomplexitiesto O(n) byaddinganadditionalnodetocol-\nlect global information and connect only adjacent items of\nthe sequence. When the length of a sequence is very long,\nsuch a sequential model is still hard to train. For this rea-\nson,weproposethe GalaxyTransformer withahierarchical\ntopology,sothatithas O(n) complexitiesandcanbetrained\nat diﬀerent levels.\n2.3. Interpretable Networks\nInmostcases,deeplearningmodelsareproposedtoachieve\nthe best performance for certain research problems without\nconsidering their interpretability. However, interpretability\nis very important in some ﬁelds. In healthcare, the ratio-\nnalefordecisionsorpredictionsmadebydeeplearningmod-\nelsandthecontributionsofdiﬀerentfactorsleadingtothem\nneed to be validated by doctors because they concern pa-\ntients’ health [23, 50, 11]. In cybersecurity, deep learning-\nbasedmalwaredetectionisaimedatreplacingsignature-based\nmethods to be practical for antivirus products to recognize\nandthenquarantine/deletemalwareforcomputerusers. How-\never, a deep learning malware detector that cannot explain\nwhy an executable is malicious is unlikely to be completely\npractical. This is because there are false positives, and mal-\nware analysts often need to justify detection results. The\ninterpretations of a deep learning-based malware detector\nalleviate malware analysts’ eﬀorts of examining them from\nscratchandcreatingaknowledgebaseofmalwaresamples[11].\nShicke et al. [50] make the criticism that deep learn-\ning models are hard to interpret, and therefore linear mod-\nels dominate applied clinical informatics. They also review\nsome attempts to make deep learning models interpretable.\nForsequentialdata,Choietal.[15]proposetheinterpretable\nnetwork RETAIN to compute the importance of each vari-\nable in patients’ medical records to their diagnostic predic-\ntions. RETAIN is composed of two attention-basedRNNs\nto form a softmax regression with dynamically computed\nweights. For image classiﬁcation, Zeiler et al. [58] propose\nDeconvolutionalNetwork(deconvnet)toprovideinterpretable\nclassiﬁcation results by revealing which parts of an image\nare important for its classiﬁcation. For the classiﬁcation of\nvectorial data, logistic/softmax regression and Naive Bayes\ncan interpret how much each feature contributes to a classi-\nﬁcation result. However, they rely on the feature indepen-\ndence assumption, and thus the interactions of diﬀerent fea-\ntures cannot be modelled to inﬂuence the classiﬁcation. In-\nspiredby RETAIN[15],weproposeanovelmulti-layerfeed-\nforwardneuralnetworktosimulatealogisticregressionwith\na dynamically computed weight of each feature to achieve\nthe same interpretability as logistic regression, while keep-\ning the performance of non-linear models.\n3. Problem Deﬁnition\nIn this section, we deﬁne some important concepts, fol-\nlowed by the deﬁnition of the research problem.\nAn executable is a sequence of bytes:\nexe= ⟨byte1,byte2,...⟩ (1)\nThe feature set of an executable is extracted by a set of\nextractors:\nfea(exe) = {ext1(exe),ext2(exe),...} (2)\nExcept for assembly code, the other extracted features\ncan be represented as a vector. We represent the assembly\ncode as a series of nested sets and sequences.\nThe assembly code of an executable is a set of assembly\nfunctions:\ncode(exe) = {f1,f2,...} (3)\nAn assembly functionis a set of basic blocks:\nf = {b1,b2,...} (4)\nA basic blockis a sequence of assembly instructions:\nb= ⟨ins1,ins2,...⟩ (5)\nAnassemblyinstruction isasequenceofoneopcodeand\ntwo operands:\nins= ⟨Opcode,Operand 1,Operand2⟩ (6)\nFortheuncommoninstructionswiththreeoperands,thethird\nisignored. Emptyoperandsaresubstitutedbythespecialto-\nkenEMPTY.Allopcodesandoperandsformaset, andeachof\nthemisassignedanindexnumber. Thus,oneinstructioncan\nbeabstractedasasequenceofthreeintegers,whereeachin-\nteger represents an index of an opcode or operand.\nDeﬁnition1 (MalwareDetection). Consideracollectionof\nexecutablesEandacollectionoflabels Lthatshowtheex-\necutables inE are benign or malicious. Letexebe an un-\nknown executable thatexe ∉ E. The malware detection\nproblem is to build a classiﬁcation modelM based onE\nand L such thatM can be used to determine whether the\nexecutableexeis benign or malicious.\n4. Methodology\nOurmalwaredetectionmodel I-MADincludesthe Galaxy\nTransformertolearnavectortorepresentthesemanticmean-\ningoftheassemblycodeofanexecutableandan interpretable\nfeed-forward neural network(IFFNN) that takes the vector\nrepresenting the assembly code of a target executable and\nvectorsrepresentingotherfeaturesasitsinputstoproducean\ninterpretable detection result. Figure 2 depicts an overview\nof our malware detection model. In this section, we intro-\nduce theStar Transformerand describe how we improve it\ntoformthe Star-PlusTransformertobuildthe GalaxyTrans-\nformer. Then,weproposetwomethodstopre-traindiﬀerent\ncomponents of theGalaxy Transformer. Next, we introduce\ntheotherfeaturesweuse,ournovel IFFNN,andhowweuse\nit to interpret the detection results.\nM. Li et al.:Preprint submitted to Elsevier Page 4 of 15\nI-MAD: Interpretable Malware Detector\nFigure 2: An overview of ourI-MAD model.\n4.1. Galaxy Transformer\n4.1.1. Star Transformer\nThe Star Transformer[27] adopts the multi-head atten-\ntion from the standardTransformer:\nMultiAtt(q,H) =Concat(ℎead1,...,ℎead ℎ)WO\nwℎereℎeadi = Attention(qWQ\ni ,HW K\ni ,HW V\ni )\nAttention(qi,Ki,Vi) =softmax(\nqiKT\ni\n√\ndmodel\n)Vi\nwhere Ki = HWK\ni ,Vi = HWV\ni , WQ\ni ∈ Rdmodel×dk,W K\ni ∈\nRdmodel×dk,W V\ni ∈ Rdmodel×dv,W O ∈ Rℎdv×dmodel are learn-\nable parameters,q∈ Rdk is a query vector, andH ∈ Rn×dk\nis a matrix that contains vector representations ofn items\nto attend to. To compute the self-attention of a sequence\nX = ⟨x1,x2,...,x n⟩, in theTransformer, eachxi is a query\nq, and it attends to all items in the sequence, soH = X.\nThus, its computational complexity isO(n2).\nToreducethecomputationalcomplexity,the StarTrans-\nformer only considers connections between adjacent items\nand between a relay node and each item, as shown in Figure\n1b. First, for each itemxi, a vectorei is computed as the\nsummation of its non-contextual semantic embedding and\nits positional encoding in the same way as theTransformer\ndoes:\nei = Emb(xi) =SE(xi) +PE(i)\nE = [e1; ...; en]\nThen, the embeddings are fed into a multi-layer neural\nnetwork to compute the hidden state for eachxi. ℎt\ni repre-\nsents the hidden state ofxi at layert. ℎ0\ni is initialized as\nei. The initial hidden state of the additional relay node is\ns0 =\n1\nn\n∑\nnei. Tocomputeℎt\ni,itscontextmatrix Ct\ni isformed\nby the hidden states of itselfℎt−1\ni and its adjacent nodes of\nthe previous layerℎt−1\ni−1; ℎt−1\ni , its embeddingei, and the hid-\nden state of the relay nodest−1:\nCt\ni = [ℎt−1\ni−1; ℎt−1\ni ; ℎt−1\ni+1; ei; st−1]\nSo, we haveCt\ni ∈ R6dmodel.\nAt each layer, we have\nℎt\ni = LayerNorm(ReLU(MultiAtt(ℎt−1\ni ,Ct\ni)))\nHt = [ℎt\n1; ...; ℎt\nn]\nst = LayerNorm(ReLU(MultiAtt(st−1,Ht)))\nThus, the relay nodest serves as a global information\ncollector. ℎt\ni collects local information from its adjacency\nnodes andglobal information fromst−1. The computational\ncomplexitytocomputeall ℎt\ni isO(n), andtocompute st itis\nalsoO(n). Theoverallcomputationalcomplexityistherefore\nO(n).\nTo put it all together, we represent aStar Transformer\nLayer as follows:\nHt+1,st+1 = STLt(Ht,st,E)\nThe full computation of theStar Transformeris as fol-\nlows:\nE = [Emb(x1); ...; Emb(xn)]\nH0 = E,s0 =\n1\nn\nÉ\nn\nei\nHT,sT = STLT(STLT−1(...STL1(H0,s0,E),E),E)\n4.1.2. Star-Plus Transformer\nAs previously shown, theStar Transformercan gener-\nate a contextual vector representation for each item in a se-\nquence and a vector representation for the whole sequence\nwith O(n) computational complexity. We propose the fol-\nlowing modiﬁcations for better performance.\n1. There is no obvious reason whyei should be in the\ncontextmatrix Ct\ni,soweremove ei fromCt\ni,resulting\ninCt\ni = [ℎt−1\ni−1; ℎt−1\ni ; ℎt−1\ni+1; st−1].\n2. There was a pointwise feedforward neural network\n(FNN = max(0; xW1 + b1)W2 + b2) after the multi-\nhead attention computation in theTransformer, but it\nis removed in theStar Transformerwithout an expla-\nnation for the rationale. We add it back to compose\ntheinformationcollectedbyallattentionheadsandto\ngenerate higher-level features for the next layer.\n3. Amax-poolingon HT acrossthetoplayermixedwith\nsT was used as the representation for the whole se-\nquence in theStar Transformer. We use onlysT to\nrepresent the whole sequence, since it has collected\nglobal information of the sequence.\nToputittogether,wehavea Star-PlusTransformer layer\nHt+1,st+1 = SPTL t(Ht,st) computed as follows:\nℎt\ni\n¨ = LayerNorm(ReLU(MultiAtt(ℎt−1\ni ,Ct\ni)))\nℎt\ni = LayerNorm(ReLU(FFN (ℎt\ni\n¨)))\nHt = [ℎt\n1; ...; ℎt\nn]\nst¨ = LayerNorm(ReLU(MultiAtt(st−1,Ht)))\nst = LayerNorm(ReLU(FFN (st¨)))\nM. Li et al.:Preprint submitted to Elsevier Page 5 of 15\nI-MAD: Interpretable Malware Detector\n4.2. Satellite-Planet Transformerto Understand\nBasic Blocks\nAs we have stated before, abasic blockis a sequence of\nassembly instructions: b = ⟨ins1,ins2,...⟩. The objective\nof theSatellite-Planet Transformeris to learn a vector rep-\nresentationfor busingitsinstructions. Tobuildthe Satellite-\nPlanetTransformerwiththe Star-PlusTransformer,wemod-\nify the input layer of the latter because each instruction is\nnot an atomic item, but a sequence of three items (i.e., an\nopcode and two operands). Since both the embedding of\nan instructioninsi and its positional encoding should have\ndmodel dimensions, we make the embeddings of the opcode\nand operandsdmodel∕3 dimensions and use the concatena-\ntion of them as the embedding of the instruction. It is then\nadded with the positional encoding to formei. The con-\ncatenation of the vector representation of the opcode and\noperandstoformthevectorofaninstructionwasalsoprevi-\nouslyadoptedbyDingetal. [21]. Fortheoutput,wedirectly\nuse sT, which is the representation of the relay node at the\ntoplayerasthesemanticmeaningrepresentationofthebasic\nblock. To train theSatellite-Planet Transformerwe propose\nthe Masked Assembly Modeltask.\nDeﬁnition 2(Masked Assembly Model). Let (b,ins) be a\nbasicblockandassemblyinstructionpair. Considerasetof\nbasicblockandassemblyinstructionpairs B. Foreachpair\n(b,ins) ∈B,thereisonemaskinstruction minbthatshould\noriginally beins. Lettbe a target basic block that is not in\nany pair ofB, and one of its instructions is replaced bym.\nTheMaskedAssemblyModeltaskistobuildaclassiﬁcation\nmodel M based onB to predict the original instructiont\nreplaced bym.\nThistaskisinspiredbythe MaskedLanguageModel task\nproposedbyDevlinetal.[20]. Inthattask,theauthorsmask\nrandom words from sentences and use theTransformer to\npredict the masked words based on the contextual words in\nthe sentences. Their method is to feed the output vector of\nthe Transformercorresponding to a masked word to an out-\nput softmax over the vocabulary. The prediction requires\nboth global context and local context. The global context\nmeans the semantic meaning of the whole sentence except\nthe masked word. The local context means the position of\nthe masked word and its surrounding words that could indi-\ncatewhatingredientthemissingwordshouldbe. Astheout-\nput vector corresponding to the masked word is the only in-\nformationsourcefortheoutputlayertomaketheprediction,\nithastocapturebothglobalandlocalcontext. Thisdoesnot\nﬁtourobjective,sincetheoutputvectorshouldonlycontain\nthe semantic meaning of a basic block (i.e., global contex-\ntual information). Therefore, we separate the two kinds of\ninformationintwovectors: sT containingtheglobalcontex-\ntualinformationandtheoutputvectorofthemaskedinstruc-\ntionm= [MASK_OPC,EMPTY,EMPTY ] containing\nthe local contextual information. We concatenate these two\nvectors to form one vector and feed it to three feed-forward\nneuralnetworkswithsoftmaxoverthewholesetofopcodes\nand operands to predict the opcode and two operands of the\noriginal masked instruction. It should be noted that after\nthis training step, we only need to keep theSatellite-Planet\nTransformer, which generatessT, the semantic representa-\ntionoftheentirebasicblock,becausethethreefeed-forward\nneural networks to predict the original masked instruction\nare not needed after the training for theMasked Assembly\nModel task.\n4.3. Planet-Star Transformerto Understand\nAssembly Function\nThePlanet-StarTransformerisanothercustomized Star-\nPlus Transformerbuilt on top of theSatellite-Planet Trans-\nformertolearnthevectorrepresentationofthesemanticmean-\ning of an assembly functionf from the set of vectors repre-\nsenting its basic block{b1,b2,...}. As the input is already\nvectors rather than integers, we abandon the input embed-\nding layer of theStar-Plus Transformerthat maps integers\nto embeddings. We directly feed the vectors representing\nthebasicblocksinpositionalordertoformasequencetothe\nPlanet-Star Transformer, which is aStar-Plus Transformer\nwithout an input layer. We usesT as the vector represen-\ntation of the assembly function. To train thePlanet-Star\nTransformer, we propose theAssembly Function Clone De-\ntectiontask.\nDeﬁnition 3(Assembly Function Clone Detection). Let\n(f1,f2) beanassemblyfunctionpair. Let (f1,f2,l) beala-\nbeled assembly function pair in which the labellindicates\nwhether the two assembly functionsf1 and f2 are clones\n(i.e.,semanticallyequivalent)ofeachother. Consideracol-\nlectionoflabeledassemblyfunctionpairs F. Letp= (f1,f2)\nbe a new function pair thatpis not any function pair inF.\nTheassemblyfunctionclonedetectiontaskistobuildaclas-\nsiﬁcationmodel Mbasedon F todeterminewhetherthetwo\nfunctions inpare clones of each other.\nThe intuition is that if the vector representations of as-\nsemblyfunctionscanbeusedtodeterminewhethertwofunc-\ntionsareclonesofeachother,thentheycontainthesemantic\nmeaning of the assembly functions. We train the network to\ngeneratesimilarvectorsincosinemeasure(i.e., cos(sT\nf1,sT\nf2))\nfor real assembly function clone pairs and dissimilar vec-\ntors for non-clone pairs. The way we form the function pair\ndataset is described in Section 5.\n4.4. Star-Galaxy Transformerto Understand Full\nLogic of Executable\nNext, we use theStar-Galaxy Transformerto learn one\nvector representing the full logic of an executable based on\ntherepresentationsofallitsassemblyfunctions: {f1,f2,...}.\nTechnically, this is similar to learning the representation of\nan assembly function from the representations of its basic\nblocks, since both are intended to learn one vector repre-\nsentation from a set of vectors. Therefore, theStar-Galaxy\nTransformeris a duplicate of thePlanet-Star Transformer.\nTheir diﬀerence is that they work at diﬀerent levels of the\nhierarchy. Therepresentationoftheassemblycodeofanex-\necutable generatedby theStar-Galaxy Transformeris fedto\nM. Li et al.:Preprint submitted to Elsevier Page 6 of 15\nI-MAD: Interpretable Malware Detector\ntheIFFNN formalwaredetectionwithoutotherpre-training\ntasks proposed for it.\nWith this, we have completely described how we build\ntheGalaxyTransformer withthreecustomized Star-PlusTrans-\nformers in a hierarchy to compute the vector representation\nof the assembly code of an executable.\n4.5. Other Features\nWhen malware is packed, or is polymorphic or meta-\nmorphic, the assembly code of its payload is encrypted and\nnot statically accessible. Hence, using only assembly code\nwould fail to identify its malicious purpose. According to\nthe experience of previous works [3, 29], static analysis can\nstillbeeﬀective,becausetheuseofthestealthymechanisms\ncan be captured when analyzed from multiple static feature\nscopes. Next,wedescribethethreekindsoffeaturesweuse\nand how we improve the way to use them.\n4.5.1. Printable Strings\nAccording to the literature [49, 29, 16, 28], printable\nstrings are important features, because they include, among\nothers,runtime-linkedlibraries,functions,andregistrykeys\nthatarecommonlyusedbymalware,systempaths,andsome-\ntimes the names of user-deﬁned functions. Hence, we ex-\ntract printable strings from the whole byte sequence of an\nexecutable. In our algorithm, a continuous subsequence is\na printable stringif it satisﬁes three conditions: 1) all of its\nbytes are ASCII characters, 2) it is terminated with a null\nsymbol, and 3) its length is at least 5 bytes. We count the\nnumber of instances of each printable string in the training\nsetandputthestringsthatappearmorethanacertainthresh-\nold, 1,000 in our case, in the frequent string set. Their fre-\nquencies in an executable are used as features. This is not\nnew compared to previous works. The improvement is that\nwe also use the number of printable strings that are not in\nthe frequent string set, i.e., uncommon strings, as a feature,\nand we use the total number of common printable strings in\nthe executable as another feature. This is based on the intu-\nitionthatencryptedmalwarehasmoreuncommonprintable\nstrings and benign software has more common strings.\n4.5.2. PE Imports\nPE Imports are dynamically linked libraries and func-\ntions shown in the import address table of PE headers. The\nimports of an executable often illustrate its behaviors, e.g.,\nmodify the registry or hook a procedure [49, 48]. The total\nnumberofimportsshowwhethertheexecutableishidingits\npotential behaviors, because abnormally few imports indi-\ncate that runtime linking is largely used or most of its im-\nports are hidden in encrypted data. Therefore, we compute\nthese features in the same way as we compute the printable\nstring features.\n4.5.3. PE Header Numerical Features\nTherearemanynumericalﬁeldsinPEheadersthatcon-\ntain information that could form diﬀerent patterns among\nmalware and benign software (benignware) [6, 48]. Hence,\nwe also use these values as features.\nFigure 3: Our proposedIFFNN.\nWe concatenate the vector representing the full logic of\nan executablevcode, printable string feature vectorvstr, PE\nheadernumericalfeaturevector vnum,andPEimportfeature\nvectorvimp toformavectorrepresentationoftheexecutable\nfrom multiple scopesv= [vcode,vstr,vnum,vimp].\n4.6. Interpretable Feed-Forward Neural Network\nInterpretabilityisanimportantqualityofamachinelearn-\ning model for malware detection. Inspired by the work of\nChoi et al. [15], which uses two attention-basedRNN net-\nworks to form a softmax regression model with dynamic\nweights,weproposeanovelinterpretablefeed-forwardneu-\nralnetwork( IFFNN)toforma\"dynamiclogisticregression\"\nmodel. Figure 3 illustrates its architecture.\nLet x ∈ ℝm be a feature vector representing a sample.\nWe ﬁrst feed it tolfully-connected hidden layers:\nvl(x) =FCl(...FC1(x)...) (7)\nwℎereFC i(vi−1(x)) =tanℎ(Wi\n1 vi−1(x) +bi\n1) (8)\nwhere Wi\n1 ∈ ℝdi\nℎ×di−1\nℎ , bi\n1 ∈ ℝdi\nℎ, andvl(x) ∈ ℝdl\nℎ. Then,\nwe apply another normal fully-connected layer of which the\noutput vector has the same dimension asx:\nw(x) =W2vl(x) +b2 (9)\nwhereW2 ∈ ℝm×dl\nℎ,b2 ∈ ℝm,and w(x) ∈ℝm. w(x) serves\nasaweightvectorforeachfeaturein x. Theﬁnalconﬁdence\nthat the input sample is positive (in malware detection, pos-\nitive means malicious) is calculated as follows:\ny= IFFNN (x) =\u001b(w(x)Tx+ b) (10)\nwℎere\u001b(z) =\n1\n1 +e−z (11)\nwhere b ∈ ℝ is a bias term. This is similar to a logistic\nregression (i.e.,y = \u001b(wTx+ b), wherewis a parameter\nvector), and the diﬀerence is that our weight vectorw(x) is\ndynamically computed based onxrather than static param-\neters.\nM. Li et al.:Preprint submitted to Elsevier Page 7 of 15\nI-MAD: Interpretable Malware Detector\nAscanbeseen,the IFFNN hasthesameinterpretability\n(a.k.a., intelligibility [35]) as logistic regression because of\nitsdecomposabilityandalgorithmictransparency[34]when\nthefeatureshavecertainmeanings. Sincetheweightofeach\nfeatureisdynamicallycomputedbyamulti-layerneuralnet-\nwork,thefeatureinteractionsarestillmodelledandtheweight\nof each feature to the prediction is contextualized. Thus, it\nhas the modelling power of a non-linear model.\nThe IFFNN can be used for any binomial classiﬁcation\ntask and can be plainly generalized to a \"dynamic softmax\nregression\" model for multinomial classiﬁcation, as long as\nthe sample can be represented as a vector with ﬁxed dimen-\nsion.\nWe feedv, the feature vector from multiple scopes of an\nexecutable, to the proposedIFFNN to get the conﬁdencey\nthatitismalicious: y= IFFNN (v) andinterprettheresult.\nThus, we complete the full network of the top-level model.\n4.7. Attribution\nFor logistic regression:y = \u001b(wTx+ b) = \u001b(w1x1 +\nw2x2 + ...+ wmxm+ b), wherex= (x1,x2,...,x m) andw=\n(w1,w2,...,w m), the attribution is simple. Whether feature\nxj makesthesamplepositivedependsonthesignof wjxj. If\nwjxj >0, xj makes it positive, and vice versa. The degree\nof the impact ofxj on ydepends onðwjxjð: a largeðwjxjð\nimplies a large impact ofxj. If the model predicts a sample\nto be positive, the most inﬂuential factor that leads to the\nresult ismaxjwjxj. If the model predicts a sample to be\nnegative,themostinﬂuentialfactorthatleadstotheresultis\nminjwjxj.\nThe same idea is applicable to ourIFFNN for malware\ndetection. Its top layer is logistic regression with dynam-\nically computed weight:y = \u001b(w(v)Tv) = \u001b(w(v)1v1 +\nw(v)2v2+...+w(v)mvm). Ifðw(v)jvjðislargeand w(v)jvj >\n0, featurevj has a large impact on the prediction of mali-\ncious. Ifðw(v)jvjðislargeand w(v)jvj <0,feature vj hasa\nlargeimpactonthepredictionofbenign. Forprintablestring\nfeatures,PEimports,andPEheadernumericalfeatures,each\ndimension of their vector representations corresponds to a\nspeciﬁc feature. The features can be the frequency of a cer-\ntain string, whether a certain DLL is imported, the value\nof a certain numerical ﬁeld, etc. By checking itsw(v)jvj,\nwe know whether it makes the executable more likely ma-\nlicious or benign. For the vector representing the full logic\nof an executable:vcode, each of its dimensions has no spe-\nciﬁc meaning, but we can see the impact of the full logic of\nthe executable by computing the summation of the impact\nof each dimension of its vector:∑\nj∈vcode\nwcode,jvcode,j. If\nitis positive, fromthe perspectiveof theassembly code, the\nexecutable is more likely malicious, and vice versa.\nAs vcode is computed by ourStar-Galaxy Transformer\nnetwork, the attention weights of the assembly functions to\nthe relay node at the top layer indicate the importance of\neach assembly function. We compute the summed attention\nweightsofeachassemblyfunctionoverallheadstotherelay\nnode to determine which assembly functions are the main\nfactors that inﬂuence the classiﬁcation results.\n4.8. Model Training\nTo train theSatellite-Planet Transformer, the objective\nfunction is the cross entropy loss of the prediction on the\nmasked opcode and operands against the real opcode and\noperands. To train thePlanet-Star Transformerand simul-\ntaneouslyﬁne-tunethe Satellite-PlanetTransformer,theob-\njective functionis the mean squarederror between the com-\nputedcosinesimilaritybetweentwoassemblyfunctionsand\nthe gold standard (i.e., 1 for clone function pairs, and -1 for\nnon-clonefunctionpairs). Totrainthefulltop-levelnetwork\nincluding theIFFNN and theStar-Galaxy Transformer, the\nobjective function is the cross entropy loss of the prediction\nagainst the real label. To ensure that theStar-Galaxy Trans-\nformer gets suﬃcient training, we ﬁrst train it without con-\ncatenating any other feature, i.e., feedvcode instead ofvto\nthe IFFNN (y= IFFNN (vcode)), and train it for malware\ndetection. This is in fact the pre-training of theStar-Galaxy\nTransformer. Then,weconcatenate vcode withotherfeatures\nto feed it to theIFFNN (y = IFFNN (v)), and train it the\nsamewayformalwaredetection. The Satellite-PlanetTrans-\nformer and Planet-Star Transformernetworks are not ﬁne-\ntunedwhenwetrainthetop-levelnetwork. Forallthetrain-\ning objectives, we use Adam [30] with the initial learning\nrate1e− 4. We use early stopping with the validation set to\navoid overﬁtting [10].\n5. Experiments\nThe objectives of our experiments are to 1) evaluate the\nperformance ofI-MAD for malware detection, 2) compare\nI-MAD to other state-of-the-art static malware detection so-\nlutions, and 3) demonstrate the interpretability ofI-MAD.\nWe train and evaluate the models on a server with two\nXeon E5-2697 CPUs, 384 GB of memory, and four Nvidia\nTitanXPgraphicscards. WeusePyTorch[40]toimplement\nourmodel. Weusethe\"peﬁle\" 1 librarytoextractnumerical\nfeatures from PE headers.\n5.1. Datasets and Pre-training\nFor the two pre-training tasks, we compile several open\nsourceprojectsthatarecompatiblewithGCCand/orLLVM.\nWechoosethesetwocompilersbecausetheyarethemostap-\npropriateoptionstoprovidediﬀerentcompilationoptionsto\ngenerate semantically equal but literally diﬀerent assembly\nfunctions. GCC compiler provides four diﬀerent optimiza-\ntion levels (i.e., O0, O1, O2, and O3) to compile projects.\nWecompile busybox,coreutils,libcurl,libgmp,libtomcrypt,\nlibz, magick, openssl, puttygen, andsqlite3 with GCC at all\nfour optimization levels. Thus, for every assembly function\nin those projects we have four semantically equivalent ver-\nsions. O-LLVM2 is an obfuscator of the LLVM compiler\nthatprovidescontrolﬂowﬂattening,instructionsubstitution,\nand bogus control ﬂow obfuscation mechanisms. We use\nO-LLVMtocompile libcrypto,libgmp,libMagickCore,and\nlibtomcryptwithﬁvediﬀerentsettings: noobfuscation,each\n1https://github.com/erocarrera/peﬁle\n2https://github.com/obfuscator-llvm/obfuscator/wiki\nM. Li et al.:Preprint submitted to Elsevier Page 8 of 15\nI-MAD: Interpretable Malware Detector\nTable 3\nTop 10 majority malware families of the dataset.\nMalware Family Number Percentage\nFareit 9,436 8.2%\nZbot 6,433 5.6%\nEmotet 6,343 5.5%\nGandcrab 4,120 3.6%\nMepaow 4,055 3.5%\nCobaltStrike 3,151 2.7%\nAllaple 2,081 1.8%\nUrsnif 1,552 1.3%\nAutoit 1,017 1.0%\nNaKocTb 794 0.7%\nTotal 38,982 33.9%\nof the three obfuscation mechanisms, and all three mecha-\nnisms. Thus, we have ﬁve versions of their every function.\nWe use IDA Pro3, a commercial disassembler, to disassem-\nbleourcompiledexecutablesandacquiretheassemblyfunc-\ntions.\nWeusebasicblocksoflengthsbetween5to250instruc-\ntions to form ourMasked Assembly Modeldataset; these\nblocksarewithinthetypicallengthrangeofblocksthatpro-\nvideenoughcontextandarenottoolongtoharmtrainingef-\nﬁciency. As a result, this dataset contains 38,427,440 basic\nblocks. We use all of them for training and none for testing\nas the purpose of the dataset is to train theSatellite-Planet\nTransformertounderstandassemblycode,andtheaccuracy\nof this task is uninformative.\nWeusethesemanticallyequivalentbutliterallydiﬀerent\nfunctionswecompiledtoformrealfunctionclonepairs. We\nrandomlypairthesamenumberoffunctionstobenon-clone\nfunctionpairstocreatethedatasetforthe AssemblyFunction\nCloneDetection task. Welimitthemaximumnumberofin-\nstructions per basic block to be 50 and the maximum num-\nberofblocksperfunctiontobe50inthisdataset,sothatthe\nmemory of our graphics cards can hold the data ﬂowing in\nthe bottom two-level networks. There are 213,656 function\npairs in the training set, 26,898 functions in the validation\nset, and 26,746 functions in the test set. Our bottom two-\nlevel networks get a classiﬁcation accuracy of 91.5% on the\ntest set. This means that the assembly function representa-\ntionsitcomputesandtherepresentationsofbasicblocksthat\narefedtoitindeedcapturethesemanticmeaningsofassem-\nbly code. We do not elaborate on the experiments for this\ntasksinceitisnottheobjectivetask,butratheratasktopre-\ntrainthe Planet-StarTransformer andﬁne-tunethe Satellite-\nPlanet Transformer. For malware detection we collected a\ndataset containing 115,000 benign and 115,000 malicious\nexecutables. There is no redundancy in the dataset. Follow-\ningtheliterature[49,31,43],thebenignexecutablesarethe\n.exeand.dllﬁlesfromtheinstallationpathsofsoftwarepro-\ngrams. The malicious executables are collected fromMal-\nShare and VirusShare. The top 10 major malware families\nof the dataset are presented in Table 3. They are obtained\n3https://www.hex-rays.com/products/ida/\nTable 4\nTop 10 packers used in the malware dataset.\nPacker Number Percentage\nUPX 7,776 6.7%\nBobSoft Mini Delphi 5,262 4.5%\nASProtect 1,826 1.59%\nASPack 1,780 1.55%\nPECompact 586 0.51%\nArmadillo 369 0.32%\nD1S1G 155 0.14%\nWinrarSFX 124 0.11%\nMoleBox 69 0.06%\nWinZipSFX 38 0.03%\nTotal 17,985 15.6%\nwith ClamAV4. The top 10 known packers that are applied\non the malware samples are shown in Table 4. The usage of\npackers is acquired with Yara Rules5. The way we split the\ndataset into training set, validation set, and test set is intro-\nduced in Subsection 5.3.\n5.2. Models for Comparison\nWecompareour I-MADmodeltoseveralstate-of-the-art\nstatic malware detection models.\n• Mosk2008OB Moskovitch et al. [37] propose to use\nTF or TF-IDF of opcode bi-grams as features and use\ndocument frequency (DF), information gain ratio, or\nFisher score as the criteria for feature selection. They\napplyArtiﬁcialNeuralNetworks,DecisionTrees,Naïve\nBayes, Boosted Decision Trees, and Boosted Naïve\nBayes as their malware detection models.\n• Bald2013MetaBaldangomboetal.[6]proposetoex-\ntractmultiplerawfeaturesfromPEheadersandusein-\nformation gain and calling frequencies for feature se-\nlectionandPCAfordimensionreduction. Theyapply\nSVM, J48, and Naïve Bayes as their malware detec-\ntion models.\n• Saxe2015DeepSaxeetal.[48]proposeasophisticated\ndeep learning model that works on four diﬀerent fea-\ntures: byte/entropyhistogramfeatures,PEimportfea-\ntures, string 2D histogram features, and PE metadata\nnumerical features. We tried to follow the exact fea-\ntures they extract when we implement it, but they do\nnot provide the exact metadata numerical ﬁelds they\nuse, so we just use the same numerical ﬁelds of PE\nheaders used in our model as part of their input.\n• Raﬀ2017MalC Raﬀ et al. [43] treat an executable as\na sequence of bytes and apply a gated 1D convolu-\ntionalneuralnetwork(CNN)toclassifyanexecutable.\nThenetworkincludesanembeddinglayer,twoconvo-\nlutional layers with large ﬁlters and strides, a global\nmax-poolinglayer,andtwofully-connectedlayers. The\n4https://www.clamav.net/\n5https://github.com/Yara-Rules/rules\nM. Li et al.:Preprint submitted to Elsevier Page 9 of 15\nI-MAD: Interpretable Malware Detector\nTable 5\nResults of k-fold cross-validation experiment. It includes the p-values (pv) of t-test for F1\nand accuracy betweenI-MAD (ST+) and other models.\nModel P R F1 pv (F1) Acc pv (Acc)\nMosk2008OB 96.1 95.8 95.9 3.3e-13 95.9 1.6e-20\nBald2013Meta 96.5 95.9 96.2 1.1e-13 96.2 6.7e-20\nSaxe2015Deep 95.2 96.1 95.7 4.0e-14 95.6 4.5e-21\nRaﬀ2017MalC 95.9 96.3 96.1 5.6e-15 96.1 4.0e-20\nKrcal2018Conv 93.2 93.2 93.2 1.7e-15 93.2 1.0e-23\nMour2019CNN 72.6 71.5 72.0 2.3e-26 71.8 1.5e-30\nSVM (same features) 96.1 96.4 96.2 3.7e-13 96.2 5.6e-20\nI-MAD (no code) 96.5 96.6 96.5 9.8e-13 96.5 4.0e-19\nI-MAD (ST) 97.0 97.9 97.3 5.0e-3 97.2 4.7e-6\nI-MAD (ST+) 97.5 97.9 97.7 N/A 97.7 N/A\noutputofoneconvolutionallayerservesasthegateof\nthe other.\n• Krcal2018Conv Following Raﬀ et al. [43], Krcal et\nal. [32] treat an executable as a sequence of bytes and\napply a CNN for malware detection, but their CNN is\ndeeperandhassmallerﬁlters. Therearefourconvolu-\ntional layers and four fully connected layers. Instead\nofaglobalmax-poolinglayer,theyuseaglobalmean-\npooling layer after the convolutional layers.\n• Mour2019CNNMourtaji et al. [38] convert malware\nbinaries to grayscale images and apply a 2D CNN on\nmalware images for malware classiﬁcation.\nFor the papers in which the authors describe multiple\nwaystoselectfeaturesand/orapplymultiplemachinelearn-\ning models ([37, 6]), we try with all possible settings and\nreportthebestresultsthattheirmethodscanachievetocom-\npare with our model.\nAstheablationstudy,wealsocompareourfullmodel\" I-\nMAD (ST+)\" with \"I-MAD (no code)\" and \"I-MAD (ST)\".\n\"I-MAD (no code)\" is our model without using assembly\ncode. Thesecomparisonscanshowtheeﬀectivenessofmod-\nelingassemblycodewith GalaxyTransformer. \"I-MAD(ST)\"\nis to build theGalaxy Transformerwith the originalStar\nTransformer,ratherthanthe Star-PlusTransformer,toshow\nthe eﬀectiveness of our modiﬁcations.\nWe also compare our model with an SVM model that\nuses the same features asI-MAD except for assembly code,\nsinceitisnotavectorialfeature. Weconsiderlinear,polyno-\nmial, andRBFkernelsandusegridsearchfortuninghyper-\nparameters. Comparingthisbaselinewith I-MAD(nocode),\nwe can separately show the eﬀectiveness of the feature set\nand our model.\n5.3. Experiment Settings\nWe evaluate the models under two diﬀerent experiment\nsettings. The main evaluation metric is accuracy (Acc), but\nwe also evaluate the models with precision (P), recall (R),\nand F1.\n• K-FoldCross-ValidationWeﬁrstevaluateourmodel\nand others with k-fold cross-validation wherek = 5.\nTheoriginaldatasetisrandomlysplitinto5evensub-\nsets. Each subset takes a turn to be chosen as the test\nset. Another subset takes a turn to be chosen as the\nvalidation set. The other 3 subsets form the training\nset. Thus, we have 5P2 = 20 diﬀerent experiment\ngroups. Each group contains 138,000 samples in the\ntrainingset,46,000inthevalidationset,and46,000in\nthe test set. We acquire the experiment results of the\n20 groups and report the averages.\n• TimeSplitEvaluation Inadditiontocross-validation\nevaluation,wealsoevaluatethemodelsinamorechal-\nlenging and realistic scenario. In real life, a malware\ndetection system is expected to detect new malware\nwith its knowledge of known malware. To evaluate\nthis ability of the models, we follow Saxe et al. [48]\nto perform a time split experiment. We use the ex-\necutables compiled before 2015 to form the training\nand validation set, and those compiled after 2017 to\nform the test set. We exclude samples with a compi-\nlation time before 2000 or after 2020, either because\nthe compilation dates are fake or the samples are out-\ndated. There are 106,000 samples in the training set,\n20,000inthevalidationset,and40,000inthetestset.\nWe run each model with diﬀerent initialization and\nrandom seeds 5 times and report the averages of the\nresults.\n5.4. Results\nThe results of the k-fold cross-validation and the time\nsplit experiments are shown in Table 5 and Table 6, respec-\ntively.\nThe full version ofI-MAD achieves statistically signif-\nicantly better accuracy and F1 than the other models in all\nexperiments, as the p-values in t-test are much smaller than\n0.01. The improvements of our model on accuracy and F1\nare larger in the time split experiments than in the cross-\nvalidation experiment. Even though we make sure there is\nnoredundancyinthedataset,somepiecesofmalwarecould\nbeextensivelysimilartoeachotheriftheyarefromthesame\nfamily and compiled with slightly diﬀerent modiﬁcations.\nM. Li et al.:Preprint submitted to Elsevier Page 10 of 15\nI-MAD: Interpretable Malware Detector\nTable 6\nResults of time split experiment. It includes the p-values of t-test for F1 and accuracy\nbetween I-MAD (ST+) and other models.\nModel P R F1 pv (F1) Acc pv (Acc)\nMosk2008OB 88.6 88.6 88.6 1.2e-15 88.6 3.4e-22\nBald2013Meta 88.3 88.1 88.2 1.6e-17 88.2 1.2e-22\nSaxe2015Deep 87.4 87.7 87.5 1.4e-17 87.5 2.6e-23\nRaﬀ2017MalC 88.5 89.0 88.7 1.2e-16 88.7 4.5e-22\nKrcal2018Conv 84.2 83.2 83.7 3.1e-18 83.8 1.2e-27\nMour2019CNN 57.0 56.6 56.8 4.3e-31 56.9 7.1e-34\nSVM (same features) 89.2 88.8 89.0 7.3e-15 89.0 6.1e-22\nI-MAD (no code) 89.4 89.6 89.5 3.2e-15 89.5 6.7e-21\nI-MAD (ST) 91.1 91.1 91.1 8.6e-11 91.1 2.6e-15\nI-MAD (ST+) 91.4 91.6 91.5 N/A 91.5 N/A\nAlso, their compilation time is usually close to each other.\nIn the time split experiment, the executables in the test set\nare compiled at least 2 years later than any executable in\nthe training and validation sets. This is a more diﬃcult set-\nting that can be reﬂected in the pervasively lower accuracy\nin the time split setting than in the cross-validation setting.\nThus, the signiﬁcantly larger improvement of our detection\nmodel over other models in the time split experiment indi-\ncatesthatithasbetterabilitiestolearnrobustandconsistent\npatternsfromoldsamplesthatcanbegeneralizedtoclassify\nnew samples.\nIt is clear that with modelling assembly code with the\nGalaxy Transformer, I-MAD achieves much better results\nthanitdoeswithoutmodellingtheassemblycode. Thisshows\nthat modelling assembly code with ourGalaxy Transformer\nhelps in diﬀerentiating malicious and benign executables.\nWecanalsoseethatthe GalaxyTransformer builtwith Star-\nPlus Transformer(I-MAD(ST+)) is more eﬀective than the\none built with the originalStar Transformer(I-MAD (ST)).\nThis conﬁrms that our modiﬁcations are useful.\nSVMwiththesamefeaturesas I-MADexceptforassem-\nbly code, achieves accuracy similar to other best baseline\nmodels in the cross-validation experiment, and it achieves\nbetteraccuracythanotherbaselinemethodsinthetimesplit\nexperiment,whileworsethan I-MAD(nocode). Thisshows\nthat the feature set we propose is eﬀective, and ourIFFNN\nhas advantages in classiﬁcation performance on the same\nfeature set.\nThat being said, other models, exceptMour2019CNN,\nalsoachievereasonablygoodresultsinallexperiments. How-\never, none of the models consistently achieves the second-\nbest performance in both experiment settings. Even though\nSaxe2015Deep uses features from multiple scopes, they do\nnotshowbetterresultsthan Bald2013MetaandMosk2008OB.\nThe lack of any mechanism to understand assembly code is\nanobviousreason,asmodellingassemblycodeinourmodel\nimproves the performance. Our improved way of represent-\ning printable string and PE import features, combined with\nourIFFNN, is the other reason. This is validated in the next\nsubsection.\nMour2019CNN performs much worse than other mod-\nels,eventhoughwetriedalternativehyper-parametervalues\nin addition to the values the authors provided. One reason\nis that the way it represents an executable as an image is not\nsophisticated; even a small oﬀset change in an executable\nwouldresultintotallydiﬀerenttexturesinitsimage. Inaddi-\ntion,wealsoobserveoverﬁtting,asitsaccuracyonthetrain-\ningsetachieves89.2%,whileonthetestsetitis71.8%. Even\nthough our model is also a deep learning model, it does not\nsuﬀer from the overﬁtting problem because we use two pre-\ntraining tasks to adequately train theSatellite-Planet Trans-\nformer and Planet-Star Transformerwith the rich informa-\ntionembeddedinassemblycode. Incontrast, Mour2019CNN\ncan only be trained with the labels of executables, which is\ninsuﬃcient.\n5.5. Interpretability\n5.5.1. Case Study\nTable 1 shows how our model interprets the detection\nresult of a sample. The primary factors that lead to the pre-\ndictionof05c199.exetobemaliciousandthemainassembly\nfunctions related to the prediction are given. It can be seen\nthattheassemblycodeofthetargetexecutableistheprimary\nreason. Thetwoassemblyfunctionsthatcontributethemost\nto the prediction set the program to sleep for a certain time\nand then download and run an embedded executable from a\nremote address.\n5.5.2. Qualitative Analysis\nTo better understand the impacts of the features we use,\nTable 7 shows the ten most frequent main factors leading to\nthe prediction of a sample to be malware or benign.\nMain factors for both classesThe assembly code of an\nexecutable is one of the most frequent factors inﬂuencing\nthe prediction of an executable to be malicious or benign.\nThis means that the vector representing the semantic mean-\ning of assembly code computed by ourGalaxy Transformer\nis very eﬀective for malware detection. We randomly ex-\namine the assembly functions of some malware that acquire\nthe largest attention by the relay node at the top layer of the\nStar-Galaxy Transformer. Many of them concern malicious\nbehaviors,suchasinstallingitselfintosomeregistry,hijack-\nM. Li et al.:Preprint submitted to Elsevier Page 11 of 15\nI-MAD: Interpretable Malware Detector\nTable 7\nMost frequent main factors leading to the predictions of the\nmalicious or benign class.\nMain factors leading to the prediction of the malicious class\nAssembly code\nTotal number of PE imports\nNumber of uncommon strings\nThe frequency of the string \"Password\"\nThe import ofKERNEL32.dll\nTotal number of strings\nThe import ofWriteFile\nThe frequency of the string \"\\x02\\x02GetLastError\"\nSubsystem\nMaximum entropy of sections\nMain factors leading to the prediction of the benign class\nTotal number of strings\nNumber of uncommon strings\nThe import ofLCMapStringW\nTotal number of PE imports\nAssembly code\nMaximum entropy of sections\nThe frequency of the string \"\\r\\x01\\x01\\x01\\x05\"\nThe frequency of the string \"\\r\\x01\\x01\\x05\\x05\"\nThe import ofinitterm\nMean entropy of sections\ningsomecommonlegitimateDLLs,andinjectingitselfinto\nanotherprocess. Weﬁndthattherearestatisticaldiﬀerences\nbetween the two classes in the mean values of total number\nofstrings,numberofuncommonstrings,totalnumberofPE\nimports, and maximum entropy of the sections. To be more\nspeciﬁc,onaveragetherearelesscommonstrings,moreun-\ncommonstrings,lessPEimports,andhigherentropyamong\nmalware. The fact that these features could be main factors\nfor both classes also shows the superiority of ourIFFNN\noverlogisticregression: asthenumberofuncommonstrings\nandthenumberofPEimportsalwayshavenon-negativeval-\nues,wheneachofthemservesasamainfactorleadingtothe\nprediction of the malicious class, its weight is positive (i.e.,\nw(v)jvj >0&vj >0 ⇒ w(v)j >0),andwhenitservesasa\nmain factor leading to the prediction of the benign class, its\nweightisnegative(i.e., w(v)jvj <0&vj >0 ⇒ w(v)j <0).\nThiscannotbeachievedbylogisticregressionbecausewhen\nit is trained, the weight for each feature is determined and\nstays static, irrelevant of the input samples. However, the\nweight of each feature inIFFNN is dynamically computed\nbased on the whole context, i.e., the vector representing all\nfeatures.\nThe explanation from the perspective of statistics is as\nfollows. Allsupervisedmachinelearningclassiﬁcationmod-\nelsworkbyidentifyingthecorrelationbetweenafeatureand\na class. Logistic regression can only learn the independent\ncorrelation between a feature and a class, without consider-\ning the correlation between features; therefore, it is linear\nand the weight for each feature is static.IFFNN learns the\ncorrelationbetweenafeatureandaclassinacontextconsid-\nering the correlations between diﬀerent features.\nMain factors for malicious classThe import of \"KER-\nNEL32.dll\" is a main factor for the prediction of malicious\nclass because malware relies heavily on a large number of\ncore APIs in it to manipulate memory and the ﬁle system.\nThe \"WriteFile\" function is also a main factor because mal-\nware such as ransomware and worms uses it to write con-\ntent to the ﬁle system. The string of \"Password\" is another\nmain factor that more frequently appears in malware cre-\nated for credential theft purposes. Malware often uses mu-\ntex for diﬀerent reasons. For example, it can be used as a\nlocking mechanism to serialize access to a resource on the\nsystem or to avoid more than one instance of itself running.\n\"GetLastError\" is used to determine whether a mutex al-\nready exists. This is the reason why the frequency of string\n\"\\x02\\x02GetLastError\" is a main factor leading to the pre-\ndiction of malware.\nMainfactorsforbenignclass \"LCMapStringW\"isoften\nusedbybenignsoftwaretoconvertallcharactersofstringsto\nupper/lower case, which is a feature much less used in mal-\nware. \"initterm\"isusedbycorelibrariestoinitializeafunc-\ntion pointer table and does not need to be imported by soft-\nware programs, and therefore it is an indicator of some be-\nnignlibraries. \"\\r\\x01\\x01\\x01\\x05\"and\" \\r\\x01\\x01\\x05\\x05\"\nare two strings that appear 1.8 and 3.6 times respectively\nmore frequently among benign executables than malicious\nexecutables.\n5.5.3. Quantitative Analysis\nWe also use a quantitative measure to analyze the inter-\npretation ofI-MAD. We compute theGini importance (GI)\nandinformationgain(IG) ofthefeatures,andthenrankthem\nbased on those criteria. We then rank the features by the\nfrequencies that they serve as the main factors for the pre-\ndictions. Features serving as main factors more frequently\nshould be relatively important features for malware detec-\ntion. It should be noted that even though the importance\nranked this way is relevant to the rank byGini importance\norinformation gain, they are not supposed to be equivalent.\nEven if the attribution mechanism ofI-MAD gives a per-\nfectinterpretation,thefeatureimportancerankbasedonthat\nwould still be diﬀerent from the rank byGini importanceor\ninformation gain.\nTable 8 shows the Spearman’s Rank Correlation Coef-\nﬁcient between the rank given byI-MAD, Gini importance,\nand information gain. It can be seen that the Spearman’s\nRank Correlation Coeﬃcient between the rank given byI-\nMAD and those given byGini importanceand information\ngainare0.59and0.55,respectively. Thisshowsastrongcor-\nrelation between them. The correlation coeﬃcient between\ntherankbyinformationgainandbyGiniimportanceisonly\n0.72,eventhoughtheyareoftenusedfortheexactsamepur-\npose: feature selection. The result means that theIFFNN in\nI-MAD frequently uses features that have high information\ngain or Gini importance as its main classiﬁcation factors.\nM. Li et al.:Preprint submitted to Elsevier Page 12 of 15\nI-MAD: Interpretable Malware Detector\nTable 8\nThe Spearman’s Rank Correlation Coeﬃcient between the fea-\nture importance rank given byI-MAD, Gini importance, and\ninformation gain.\nIG GI I-MAD\nIG 1.0 0.72 0.59\nGI 0.72 1.0 0.55\nTable 9\nEﬃciency of each model in terms of number of samples classi-\nﬁed per second. The time consumption for feature extraction\nis not included.\nModel n samples per second\nMosk2008OB 32,152\nBald2013Meta 127,988\nSaxe2015Deep 142,711\nRaﬀ2017MalC 86\nKrcal2018Conv 142\nMour2019CNN 391\nSVM (same features) 58\nI-MAD (no code) 28,197\nI-MAD (ST) 15,355\nI-MAD (ST+) 15,239\n5.6. Eﬃciency Study\nThe eﬃciency ofI-MAD and all models for comparison\nmeasured by the number of samples classiﬁed per second is\npresented in Table 9.\nAmongallmodels,theeﬃciencyof I-MADismoderate.\nAndI-MADisthesecondmosteﬃcientdeeplearningmodel.\nSaxe2015Deep is the most eﬃcient because the dimension\nof its feature vector is only 1024, and the network is very\nsmall. Raﬀ2017MalCandKrcal2018Convareslowbecause\nthey rely on whole byte sequences, and they are very com-\nputationally expensive. With our Titan Xp graphics cards\ntheir batch sizes could be around 32 and 128 at most, re-\nspectively. The batch size forMour2019CNN depends on\nthe number of bytes in the samples; in extreme cases we\nneedtorunthemodelontheCPUbecausethegraphicscard\nmemory cannot hold the computation for even one large ex-\necutable. For I-MAD (ST)/(ST+), the batch size could be\nat least 512 for most samples. As the representation of as-\nsembly code is computed at three levels (i.e., basic block,\nfunction, and executable), the memory for the lower level\ncomputation is released and reused after the representation\nis computed. ForI-MAD (no code), the batch size could be\n5,120. It is worth the extra computational cost to model as-\nsemblycodebecausethebeneﬁtofitinclassiﬁcationperfor-\nmanceissigniﬁcant. SVMwiththesamefeaturesas I-MAD\nalsohasveryloweﬃciencybecauseitscomputationalcom-\nplexityislinearwiththedimensionoffeaturevectorandthe\nnumberofsupportvectors,whicharelargewhenthedataset\nis complex. In our experiments, there are always more than\n43,000supportvectors,andthedimensionoffeaturevectors\nis more than 2,700.\n6. Limitations and Future Work\nAdversarial attack and defense are closely related topics\nto classiﬁcation problems such as image classiﬁcation [26]\nandmalwaredetection[4]. Interpretabilityisadouble-edged\nsword considering adversarial attacks in white-box settings,\nwhere adversaries have full access to theI-MAD model and\ncanusetheinterpretationstocraftadversarialsamplesmore\neasily than by using an uninterpretable model.\nEvasion techniques (e.g., adversarial attacks) are exten-\nsively applied in wild malware, as is the case of our dataset.\nFollowing previous experience [3, 29], we counter the eva-\nsiontechniquesbydetectingmalwarefromtheviewsofmul-\ntiple disparate feature sets. Also, since adversarial samples\nare already in our dataset, adversarial training is automati-\ncally performed to defend against the attacks [26]. Usually,\nadversarial attack and defense are discussed in a diﬀerent\nresearch paper than the one proposing a novel classiﬁcation\nmodel. Oneofourfutureworkdirectionsistofurtherinves-\ntigate adversarial attack and defense on malware detection.\n7. Conclusion\nIn this paper, we presentI-MAD, a novel deep learning\nmodelforstaticmalwaredetectionthatisbasedontheunder-\nstandingofassemblycode. Inadditiontoitsexcellentdetec-\ntionperformance,itcanalsoprovideinterpretationforitsde-\ntectionresults,whichcanbeexaminedbymalwareanalysts.\nTherefore, in addition to malware detection, it can also help\nmalwareanalystslocatemaliciouspayloadsandﬁndconsis-\ntentpatternsinmalwaresamples. Theproposed IFFNN has\nvalues that can be applied in interpretable classiﬁcation for\nother tasks as well.\nCRediT authorship contribution statement\nMilesQ.Li: Conceptualization,Methodology,Software,\nValidation, Data Curation, Investigation, Writing - Origi-\nnal Draft.Benjamin C. M. Fung:Conceptualization, Val-\nidation, Supervision, Writing - Review & Editing, Fund-\ning acquisition. Philippe Charland: Project administra-\ntion,Writing-Review&Editing. StevenH.H.Ding: Data\nCuration, Writing - Review & Editing.\nAcknowledgments\nThisresearchissupportedbyDefenceResearchandDe-\nvelopmentCanada(contractno. W7701-176483/001/QCL),\nNSERCDiscoveryGrants(RGPIN-2018-03872),andCanada\nResearchChairsProgram(950-232791). TheTitanXpused\nfor this research was donated by the NVIDIA Corporation.\nReferences\n[1] Amer, E., Zelinka, I., 2020. A dynamic windows malware detection\nand prediction method based on contextual understanding of api call\nsequence. Computers & Security 92, 101760.\n[2] Anderson, B., Quist, D., Neil, J., Storlie, C., Lane, T., 2011. Graph-\nbased malware detection using dynamic analysis. Journal in Com-\nputer Virology 7, 247–258.\nM. Li et al.:Preprint submitted to Elsevier Page 13 of 15\nI-MAD: Interpretable Malware Detector\n[3] Anderson, B., Storlie, C., Lane, T., 2012. Improving malware classi-\nﬁcation: bridging the static/dynamic gap, in: Proceedings of the 5th\nACM workshop on Security and artiﬁcial intelligence, ACM. pp. 3–\n14.\n[4] Anderson, H.S., Kharkar, A., Filar, B., Evans, D., Roth, P., 2018.\nLearning to evade static pe machine learning malware models via re-\ninforcement learning. arXiv preprint arXiv:1801.08917 .\n[5] Bahdanau, D., Cho, K., Bengio, Y., 2014. Neural machine trans-\nlation by jointly learning to align and translate. arXiv preprint\narXiv:1409.0473 .\n[6] Baldangombo, U., Jambaljav, N., Horng, S.J., 2013. A static mal-\nware detection system using data mining methods. arXiv preprint\narXiv:1308.2831 .\n[7] Basole,S.,DiTroia,F.,Stamp,M.,2020. Multifamilymalwaremod-\nels. Journal of Computer Virology and Hacking Techniques , 1–14.\n[8] Bayer,U.,Moser,A.,Kruegel,C.,Kirda,E.,2006. Dynamicanalysis\nof malicious code. Journal in Computer Virology 2, 67–77.\n[9] Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhari-\nwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al.,\n2020. Language models are few-shot learners. arXiv preprint\narXiv:2005.14165 .\n[10] Caruana, R., Lawrence, S., Giles, C.L., 2001. Overﬁtting in neu-\nralnets: Backpropagation,conjugategradient,andearlystopping,in:\nAdvances in Neural Information Processing Systems, pp. 402–408.\n[11] Cerna, A.E.U., Pattichis, M., VanMaanen, D.P., Jing, L., Patel, A.A.,\nStough, J.V., Haggerty, C.M., Fornwalt, B.K., 2019. Interpretable\nneural networks for predicting mortality risk using multi-modal elec-\ntronic health records. arXiv preprint arXiv:1901.08125 .\n[12] Cesare, S., Xiang, Y., 2010. Classiﬁcation of malware using struc-\ntured control ﬂow, in: Proceedings of the Eighth Australasian Sym-\nposiumonParallelandDistributedComputing, AustralianComputer\nSociety, Inc.. pp. 61–70.\n[13] Cesare, S., Xiang, Y., Zhou, W., 2013. Control ﬂow-based malware\nvariantdetection. IEEETransactionsonDependableandSecureCom-\nputing 11, 307–317.\n[14] Chen, J., Alalﬁ, M.H., Dean, T.R., Zou, Y., 2015. Detecting an-\ndroid malware using clone detection. Journal of Computer Science\nand Technology 30, 942–956.\n[15] Choi, E., Bahadori, M.T., Sun, J., Kulas, J., Schuetz, A., Stewart, W.,\n2016. Retain: An interpretable predictive model for healthcare using\nreverse time attention mechanism, in: Advances in Neural Informa-\ntion Processing Systems, pp. 3504–3512.\n[16] Dahl, G.E., Stokes, J.W., Deng, L., Yu, D., 2013. Large-scale mal-\nwareclassiﬁcationusingrandomprojectionsandneuralnetworks,in:\nProceedingsofthe38thIEEEInternationalConferenceonAcoustics,\nSpeech and Signal Processing (ICASSP), IEEE. pp. 3422–3426.\n[17] Dai, J., Guha, R.K., Lee, J., 2009. Eﬃcient virus detection using\ndynamic instruction sequences. JCP 4, 405–414.\n[18] Damodaran, A., Di Troia, F., Visaggio, C.A., Austin, T.H., Stamp,\nM., 2017. A comparison of static, dynamic, and hybrid analysis for\nmalwaredetection. JournalofComputerVirologyandHackingTech-\nniques 13, 1–12.\n[19] Demontis,A.,Melis,M.,Biggio,B.,Maiorca,D.,Arp,D.,Rieck,K.,\nCorona, I., Giacinto, G., Roli, F., 2017. Yes, machine learning can\nbe more secure! a case study on android malware detection. IEEE\nTransactions on Dependable and Secure Computing .\n[20] Devlin, J., Chang, M.W., Lee, K., Toutanova, K., 2018. Bert: Pre-\ntraining of deep bidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805 .\n[21] Ding,S.H.,Fung,B.C.,Charland,P.,2019. Asm2vec: Boostingstatic\nrepresentation robustness for binary clone search against code obfus-\ncation and compiler optimization, in: IEEE Symposium on Security\nand Privacy (SP), IEEE. pp. 472–489.\n[22] Dong, L., Yang, N., Wang, W., Wei, F., Liu, X., Wang, Y., Gao, J.,\nZhou, M., Hon, H.W., 2019. Uniﬁed language model pre-training\nfor natural language understanding and generation, in: Advances in\nNeural Information Processing Systems, pp. 13063–13075.\n[23] Dong, Y., Su, H., Zhu, J., Bao, F., 2017. Towards interpretable deep\nneural networks by leveraging adversarial examples. arXiv preprint\narXiv:1708.05493 .\n[24] Fredrikson, M., Jha, S., Christodorescu, M., Sailer, R., Yan, X.,\n2010. Synthesizing near-optimal malware speciﬁcations from suspi-\ncious behaviors, in: IEEE Symposium on Security and Privacy (SP),\nIEEE. pp. 45–60.\n[25] Gibert, D., Mateu, C., Planes, J., 2020. Hydra: A multimodal deep\nlearningframeworkformalwareclassiﬁcation.Computers&Security\n, 101873.\n[26] Goodfellow, I.J., Shlens, J., Szegedy, C., 2014. Explaining and har-\nnessing adversarial examples. arXiv preprint arXiv:1412.6572 .\n[27] Guo, Q., Qiu, X., Liu, P., Shao, Y., Xue, X., Zhang, Z., 2019. Star-\ntransformer. arXiv preprint arXiv:1902.09113 .\n[28] Huang, W., Stokes, J.W., 2016. Mtnet: a multi-task neural network\nfor dynamic malware classiﬁcation, in: International Conference on\nDetection of Intrusions and Malware, and Vulnerability Assessment,\nSpringer. pp. 399–418.\n[29] Islam, R., Tian, R., Batten, L.M., Versteeg, S., 2013. Classiﬁcation\nof malware based on integrated static and dynamic features. Journal\nof Network and Computer Applications 36, 646–656.\n[30] Kingma,D.P.,Ba,J.,2014. Adam: Amethodforstochasticoptimiza-\ntion. arXiv preprint arXiv:1412.6980 .\n[31] Kolter, J.Z., Maloof, M.A., 2004. Learning to detect malicious exe-\ncutables in the wild, in: Proceedings of the tenth ACM International\nConference on Knowledge Discovery and Data Mining (SIGKDD),\nACM. pp. 470–478.\n[32] Kr/uni010Dál, M., Švec, O., Bálek, M., Jašek, O., 2018. Deep convolutional\nmalware classiﬁers can learn from raw executables and labels only.\nInternational Conference on Learning Representations (ICLR) 2018\nWorkshop .\n[33] Kruegel, C., Kirda, E., Mutz, D., Robertson, W., Vigna, G., 2005.\nPolymorphicwormdetectionusingstructuralinformationofexecuta-\nbles,in: InternationalWorkshoponRecentAdvancesinIntrusionDe-\ntection, Springer. pp. 207–226.\n[34] Lipton, Z.C., 2018. The mythos of model interpretability. Queue 16,\n31–57.\n[35] Lou,Y.,Caruana,R.,Gehrke,J.,2012.Intelligiblemodelsforclassiﬁ-\ncationandregression,in: Proceedingsofthe18thACMInternational\nConference on Knowledge Discovery and Data Mining (SIGKDD),\npp. 150–158.\n[36] Luong, M.T., Pham, H., Manning, C.D., 2015. Eﬀective ap-\nproachestoattention-basedneuralmachinetranslation.arXivpreprint\narXiv:1508.04025 .\n[37] Moskovitch, R., Feher, C., Tzachar, N., Berger, E., Gitelman, M.,\nDolev, S., Elovici, Y., 2008. Unknown malcode detection using\nopcode representation, in: Intelligence and Security Informatics.\nSpringer, pp. 204–215.\n[38] Mourtaji,Y.,Bouhorma,M.,Alghazzawi,D.,2019.Intelligentframe-\nwork for malware detection with convolutional neural network, in:\nProceedings of the 2nd International Conference on Networking, In-\nformation Systems & Security, ACM. p. 7.\n[39] Onwuzurike, L., Mariconti, E., Andriotis, P., Cristofaro, E.D., Ross,\nG., Stringhini, G., 2019. Mamadroid: Detecting android malware\nby building markov chains of behavioral models (extended version).\nACM Transactions on Privacy and Security (TOPS) 22, 1–34.\n[40] Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito,\nZ., Lin, Z., Desmaison, A., Antiga, L., Lerer, A., 2017. Automatic\ndiﬀerentiation in pytorch. Neural Information Processing Systems\nNIPS 2017 Autodiﬀ Workshop .\n[41] Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., 2018. Im-\nprovinglanguageunderstandingwithunsupervisedlearning. Techni-\ncal Report. Technical report, OpenAI.\n[42] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I.,\n2019. Languagemodelsareunsupervisedmultitasklearners. OpenAI\nBlog 1, 8.\n[43] Raﬀ, E., Barker, J., Sylvester, J., Brandon, R., Catanzaro, B.,\nNicholas, C., 2017. Malware detection by eating a whole exe. arXiv\npreprint arXiv:1710.09435 .\nM. Li et al.:Preprint submitted to Elsevier Page 14 of 15\nI-MAD: Interpretable Malware Detector\n[44] Raﬀ, E., Zak, R., Cox, R., Sylvester, J., Yacci, P., Ward, R., Tracy,\nA.,McLean,M.,Nicholas,C.,2018. Aninvestigationofbyten-gram\nfeaturesformalwareclassiﬁcation. JournalofComputerVirologyand\nHacking Techniques 14, 1–20.\n[45] Raﬀel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena,\nM., Zhou, Y., Li, W., Liu, P.J., 2019. Exploring the limits of trans-\nfer learning with a uniﬁed text-to-text transformer. arXiv preprint\narXiv:1910.10683 .\n[46] Royal, P., Halpin, M., Dagon, D., Edmonds, R., Lee, W., 2006.\nPolyunpack: Automating the hidden-code extraction of unpack-\nexecuting malware, in: Proceedings of the 22nd Annual Computer\nSecurity Applications Conference (ACSAC’06), IEEE. pp. 289–300.\n[47] Santos, I., Devesa, J., Brezo, F., Nieves, J., Bringas, P.G., 2013.\nOpem: A static-dynamic approach for machine-learning-based mal-\nware detection, in: Proceedings of the International Joint Conference\nCISIS’12-ICEUTE12-SOCO12SpecialSessions,Springer.pp.271–\n280.\n[48] Saxe, J., Berlin, K., 2015. Deep neural network based malware de-\ntection using two dimensional binary program features, in: Proceed-\ningsofthe10thInternationalConferenceonMaliciousandUnwanted\nSoftware (MALWARE), IEEE. pp. 11–20.\n[49] Schultz, M.G., Eskin, E., Zadok, F., Stolfo, S.J., 2001. Data mining\nmethods for detection of new malicious executables, in: Proceedings\n2001 IEEE Symposium on Security and Privacy. S&P 2001, IEEE.\npp. 38–49.\n[50] Shickel, B., Tighe, P.J., Bihorac, A., Rashidi, P., 2017. Deep ehr: a\nsurvey of recent advances in deep learning techniques for electronic\nhealth record (ehr) analysis. IEEE Journal of Biomedical and Health\nInformatics 22, 1589–1604.\n[51] Vasan, D., Alazab, M., Wassan, S., Safaei, B., Zheng, Q., 2020.\nImage-based malware classiﬁcation using ensemble of cnn architec-\ntures (imcec). Computers & Security , 101748.\n[52] Vaswani,A.,Shazeer,N.,Parmar,N.,Uszkoreit,J.,Jones,L.,Gomez,\nA.N., Kaiser, Ł., Polosukhin, I., 2017. Attention is all you need, in:\nAdvancesinNeuralInformationProcessingSystems,pp.5998–6008.\n[53] Vemparala, S., Di Troia, F., Corrado, V.A., Austin, T.H., Stamo, M.,\n2016. Malware detection using dynamic birthmarks, in: Proceedings\nof the 2016 ACM on international workshop on security and privacy\nanalytics, pp. 41–46.\n[54] Verma, V., Muttoo, S.K., Singh, V., 2020. Multiclass malware clas-\nsiﬁcation via ﬁrst-and second-order texture statistics. Computers &\nSecurity 97, 101895.\n[55] Wong,W.,Stamp,M.,2006. Huntingformetamorphicengines. Jour-\nnal in Computer Virology 2, 211–229.\n[56] Yang,Z.,Dai,Z.,Yang,Y.,Carbonell,J.,Salakhutdinov,R.,Le,Q.V.,\n2019. Xlnet: Generalizedautoregressivepretrainingforlanguageun-\nderstanding. arXiv preprint arXiv:1906.08237 .\n[57] Ye, Y., Li, T., Adjeroh, D., Iyengar, S.S., 2017. Asurveyonmalware\ndetection using data mining techniques. ACM Computing Surveys\n(CSUR) 50, 41.\n[58] Zeiler, M.D., Fergus, R., 2014. Visualizing and understanding con-\nvolutional networks, in: European conference on computer vision,\nSpringer. pp. 818–833.\nMilesQ.Li isaPh.D.candidateintheSchoolofComputerScience,McGill\nUniversity,Montreal,Canada. HereceivedhisB.ScandM.ScfromPeking\nUniversity. His research interests include data mining for cybersecurity,\ndeep learning, and natural language processing.\nBenjaminC.M.Fung isaCanadaResearchChairinDataMiningforCy-\nbersecurity, a Full Professor with the School of Information Studies, and\nanAssociateMemberwiththeSchoolofComputerScienceatMcGillUni-\nversity in Canada. He received a Ph.D. degree in computing science from\nSimonFraserUniversityinCanadain2007. Hehasover130refereedpub-\nlications that span the research forums of data mining, privacy protection,\ncybersecurity,servicescomputing,andbuildingengineering. Hisdatamin-\ningworksincrimeinvestigationandauthorshipanalysishavebeenreported\nbymediaworldwide. Prof. FungisalicensedProfessionalEngineerofsoft-\nware engineering in Ontario, Canada.\nPhilippe Charlandis a Defence Scientist at Defence Research and De-\nvelopment Canada – Valcartier Research Centre, in the Mission Critical\nCyber Security Section. His research interests encompass software reverse\nengineering and computer forensics. As a member of the Systems Vulner-\nabilitiesandLethalityGroup, hisresearchfocusesonbinary-levelprogram\ncomprehension to accelerate the reverse engineering process involved in\nmalicious software analysis and classiﬁcation, as well as for mission assur-\nance. Mr. Charland holds a bachelor and a master’s degree in Computer\nScience, both from Concordia University, Montreal, Canada.\nSteven H. H. Dingis an Assistant Professor in the School of Computing\nat Queen’s University, where he leads the L1NNA Artiﬁcial Intelligence\nand Security Lab. His research bridges the domain of machine learning,\ndata mining, and cybersecurity, aiming at addressing critical cybersecu-\nrity challenges using AI technologies and securing the future of AI sys-\ntems. Dr. Ding obtained his Ph.D. from McGill University in 2019, and he\nwasawardedtheFRQNTDoctoralResearchScholarshipofQuebecandthe\nDean’s Graduate Award at McGill University.\nM. Li et al.:Preprint submitted to Elsevier Page 15 of 15",
  "topic": "Interpretability",
  "concepts": [
    {
      "name": "Interpretability",
      "score": 0.8752371072769165
    },
    {
      "name": "Malware",
      "score": 0.8193128108978271
    },
    {
      "name": "Computer science",
      "score": 0.7909806966781616
    },
    {
      "name": "Executable",
      "score": 0.7332696318626404
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5783807039260864
    },
    {
      "name": "Machine learning",
      "score": 0.5506429672241211
    },
    {
      "name": "Code (set theory)",
      "score": 0.5289820432662964
    },
    {
      "name": "Preprocessor",
      "score": 0.48678871989250183
    },
    {
      "name": "Redundancy (engineering)",
      "score": 0.47018352150917053
    },
    {
      "name": "Data mining",
      "score": 0.3624778389930725
    },
    {
      "name": "Programming language",
      "score": 0.2256743311882019
    },
    {
      "name": "Computer security",
      "score": 0.1283312439918518
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.1210019588470459
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 8
}