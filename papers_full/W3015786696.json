{
  "title": "ReadNet: A Hierarchical Transformer Framework for Web Article Readability Analysis",
  "url": "https://openalex.org/W3015786696",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2284885493",
      "name": "Changping Meng",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    },
    {
      "id": "https://openalex.org/A2656641051",
      "name": "Muhao Chen",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    },
    {
      "id": "https://openalex.org/A2097246535",
      "name": "Jie Mao",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2103964444",
      "name": "Jennifer Neville",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    },
    {
      "id": "https://openalex.org/A2284885493",
      "name": "Changping Meng",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2656641051",
      "name": "Muhao Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097246535",
      "name": "Jie Mao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2103964444",
      "name": "Jennifer Neville",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2957436444",
    "https://openalex.org/W2887976600",
    "https://openalex.org/W3007933224",
    "https://openalex.org/W2802433760",
    "https://openalex.org/W2048587526",
    "https://openalex.org/W2598654328",
    "https://openalex.org/W2036367260",
    "https://openalex.org/W1982643343",
    "https://openalex.org/W2145713659",
    "https://openalex.org/W2340721711",
    "https://openalex.org/W2171575620",
    "https://openalex.org/W2046101831",
    "https://openalex.org/W2117823388",
    "https://openalex.org/W2106695994",
    "https://openalex.org/W2117334662",
    "https://openalex.org/W1965949675",
    "https://openalex.org/W1528370852",
    "https://openalex.org/W1832693441",
    "https://openalex.org/W2043255229",
    "https://openalex.org/W2115613106",
    "https://openalex.org/W3152368098",
    "https://openalex.org/W2251849926",
    "https://openalex.org/W1988834078",
    "https://openalex.org/W1567923459",
    "https://openalex.org/W1536274117",
    "https://openalex.org/W2024546487",
    "https://openalex.org/W2413794162",
    "https://openalex.org/W2963606508",
    "https://openalex.org/W2019416425",
    "https://openalex.org/W2153081451",
    "https://openalex.org/W2055438657",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W2963355447",
    "https://openalex.org/W2250966211",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2514166524",
    "https://openalex.org/W2470673105"
  ],
  "abstract": null,
  "full_text": "ReadNet: A Hierarchical Transformer Framework for\nWeb Article Readability Analysis\nChangping Meng1⋆, Muhao Chen2, Jie Mao3,Jennifer Neville 1\nDepartment of Computer Science, Purdue University, West Lafayette1\nDepartment of Computer Science, University of California, Los Angeles2\nGoogle Inc., Mountain View3\n{meng40, neville}@purdue.edu; muhaochen@ucla.edu; mjmjmtl@google.com\nAbstract. Analyzing the readability of articles has been an important sociolin-\nguistic task. Addressing this task is necessary to the automatic recommendation\nof appropriate articles to readers with different comprehension abilities, and it\nfurther beneﬁts education systems, web information systems, and digital libraries.\nCurrent methods for assessing readability employ empirical measures or statisti-\ncal learning techniques that are limited by their ability to characterize complex\npatterns such as article structures and semantic meanings of sentences. In this pa-\nper, we propose a new and comprehensive framework which uses a hierarchical\nself-attention model to analyze document readability. In this model, measure-\nments of sentence-level difﬁculty are captured along with the semantic mean-\nings of each sentence. Additionally, the sentence-level features are incorporated\nto characterize the overall readability of an article with consideration of article\nstructures. We evaluate our proposed approach on three widely-used benchmark\ndatasets against several strong baseline approaches. Experimental results show\nthat our proposed method achieves the state-of-the-art performance on estimat-\ning the readability for various web articles and literature.\n1 Introduction\nReadability is an important linguistic measurement that indicates how easily readers\ncan comprehend a particular document. Due to the explosion of web and digital infor-\nmation, there are often hundreds of articles describing the same topic, but vary in levels\nof readability. This can make it challenging for users to ﬁnd the articles online that bet-\nter suit their comprehension abilities. Therefore, an automated approach to assessing\nreadability is a critical component for the development of recommendation strategies\nfor web information systems, including digital libraries and web encyclopedias.\nText readabilityis deﬁned as the overall effect of language usage and composition\non readers’ ability to easily and quickly comprehend the document [14]. In this work,\nwe focus on evaluating document difﬁculty based on the composition of words and sen-\ntences. Consider the following two descriptions of the concept rainbow as an example.\n⋆ This work was done during the summer internships of CM and MC at Google, Mountain View.\nWe thank the anonymous reviewers for their insightful comments.\narXiv:2103.04083v1  [cs.IR]  6 Mar 2021\n2 Changping Meng 1, Muhao Chen2, Jie Mao3,Jennifer Neville 1\n1. A more rigid scientiﬁc deﬁnition from English Wikipedia: A rainbow is a me-\nteorological phenomenon that is caused by reﬂection, refraction and dispersion of\nlight in water droplets resulting in a spectrum of light appearing in the sky.\n2. A more generic description from theSimple English Wikipedia: A rainbow is an\narc of color in the sky that can be seen when the sun shines through falling rain.\nThe pattern of colors starts with red on the outside and changes through orange,\nyellow, green, blue, to violet on the inside.\nClearly, the ﬁrst description provides more rigidly expressed contents, but is more so-\nphisticated due to complicated sentence structures and the use of professional words. In\ncontrast, the second description is simpler, with respect to both grammatical and doc-\nument structures. From the reader’s perspective, the ﬁrst deﬁnition is more appropriate\nfor technically sophisticated audiences, while the second one is suitable for general\naudiences, such as parents who want to explain rainbows to their young children.\nThe goal of Readability Analysisis to provide a rating regarding the difﬁculty of an\narticle for average readers. As the above example illustrates that, many approaches for\nautomatically judging the difﬁculty of the articles are rooted in two factors: the difﬁ-\nculty of the words or phrases, and the complexity of syntax [11]. To characterize these\nfactors, existing works [3,29] mainly rely on some explicit features such as Average\nSyllables Per Word, Average Words Per Sentence, etc. For example, the Flesch-Kincaid\nindex is a representative empirical measure deﬁned as a linear combination of these fac-\ntors [4]. Some later approaches mainly focus on proposing new features with the latest\nCohMetrix 3.0 [36] providing 108 features, and they combine and use the features using\neither linear functions or statistical models such as Support Vector Machines or mul-\ntilayer perceptron [43,12,41,40,51]. While these approaches have shown some merits,\nthey also lead to several drawbacks. Speciﬁcally (1) they do not consider sequential and\nstructural information, and (2) they do not capture sentences-level or document-level\nsemantics that are latent but essential to the task [11].\nTo address these issues, we propose ReadNet, a comprehensive readability classiﬁ-\ncation framework that uses a hierarchical transformer network. The self-attention por-\ntion of the transformer encoder is better able to model long-range and global dependen-\ncies among words. The hierarchical structure can capture how words form sentences,\nand how sentences form documents, meanwhile reduce the model complexity exponen-\ntially. Moreover, explicit features indicating the readability of different granularities of\ntext can be leveraged and aggregated from multiple levels of the model. We compare\nour proposed model to a number of widely-adopted document encoding techniques, as\nwell as traditional readability analysis approaches based on explicit features. Experi-\nmental results on three benchmark datasets show that our work properly identiﬁes the\ndocument representation techniques, and achieves the state-of-the-art performance by\nsigniﬁcantly outperform previous approaches.\n2 Related Work\nExisting computational methods for readability analysis [3,29,53,11,40] mainly use em-\npirical measures on the symbolic aspects of the text, while ignoring the sequence of\nReadNet: A Hierarchical Transformer Framework for Readability Analysis 3\nwords and the structure of the article. The Flesch-Kincaid index [28] and related varia-\ntions use a linear combination of explicit features.\nAlthough models based on these traditional features are helpful to the quantiﬁca-\ntion of readability for small and domain-speciﬁc groups of articles, they are far from\ngenerally applicable for a larger body of web articles [45,10,17]. Because those fea-\ntures or formulas generated from a small number of training text speciﬁcally selected\nby domain experts, they are far from generally representing the readability of large\ncollections of corpora. Recent machine learning methods on readability evaluation are\ngenerally in the primitive stage. [18] proposes to combine language models and logis-\ntic regression. The existing way to integrate features is through a statistical learning\nmethod such as SVM [20,43,12,41,40,51]. These approaches ignore the sequential or\nstructural information on how sentences construct articles. Efforts have also been made\nto select optimal features from current hundreds of features [15]. Some computational\nlinguistic methods have been developed to extract higher-level language features. The\nwidely-adopted Coh-Metrix [22,37] provides multiple features based on cohesion such\nas referential cohesion and deep cohesion.\nPlenty of works have been conducted on utilizing neural models for sentimental or\ntopical document classiﬁcation or ranking, while few have paid attention to the read-\nability analysis task. The convolutional neural network (CNN) [27] is often adopted in\nsentence-level classiﬁcation which leverages local semantic features of sentence com-\nposition that are provided by word representation approaches. In another line of ap-\nproaches, a recursive neural network [46] is adopted, which focuses on modeling the\nsequence of words or sentences. Hierarchical structures of such encoding techniques\nare proposed to capture structural information of articles, and have been widely used in\ntasks of document classiﬁcation [48,32,7], and sequence generation [30] and sub-article\nmatching [6]. Hierarchical attention network [52] is the current state-of-the-art method\nfor document classiﬁcation, which employs attention mechanisms on both word and\nsentence levels to capture the uneven contribution of different words and sentences to\nthe overall meaning of the document. The Transformer model [50] uses multi-head self-\nattention to perform sequence-to-sequence translation. Self-attention is also adopted in\ntext summarization, entailment and representation [38,31]. Unlike topic and sentiment-\nrelated document classiﬁcation tasks that focus on leveraging portions of lexemes that\nare signiﬁcant to the overall meanings and sentiment of the document, readability anal-\nysis requires the aggregation of difﬁculty through all sentence components. Besides,\nprecisely capturing the readability of documents requires the model to incorporate com-\nprehensive readability-aware features, including difﬁculty, sequence and structure infor-\nmation, to the corresponding learning framework.\n3 Preliminary\nIn this section, we present the problem deﬁnition, as well as some representative explicit\nfeatures that are empirically adopted for the readability analysis task.\n4 Changping Meng 1, Muhao Chen2, Jie Mao3,Jennifer Neville 1\n3.1 Problem Deﬁnition\nThe readability analysis problem is deﬁned as an ordinal regression problem for articles.\nGiven an article with up tonsentences and each sentence with up tomwords, an article\ncan be represented as a matrix A whose i-th row Ai,: corresponds to the i-th sentences,\nand Ai,j denotes the j-th word of the i-th sentence. Given an article A, a label will be\nprovided to indicate the readability of this article.\nWe consider the examples introduced in Section 1, where two articles describe the\nsame term “rainbow”. The ﬁrst rigorous scientiﬁc article can be classiﬁed as “difﬁcult”,\nand the second general description article can be classiﬁed as “easy”.\nInstead of classifying articles into binary labels like “easy” or “difﬁcult”, more ﬁne-\ngrained labels can help people better understand the levels of readability. For instance,\nwe can map the articles in standardization systems of English tests such as 5-level\nCambridge English Exam (CEE), where articles from professional level English exam\n(CPE) are regarded than those from introductory English exam (KET).\n3.2 Explicit Features\nPrevious works [28,21,24,25,34,11,22] have proposed empirical features to evaluate\nreadability. Correspondingly, we divide these features into sentence-level features and\ndocument-level features. Sentence-level features seek to evaluate the difﬁculty of sen-\ntences. For instance, the sentence-level feature “number of words” for sentences can be\naveraged into “number of words per sentence” to evaluate the difﬁculty of documents.\nDocument-level features include the traditional readability indices and cohesion’s pro-\nposed by Coh-Metrix[22]. These features are listed in Table 1.\nCurrent approaches [43,12,41] average the sentence-level features of each sentence\nto construct document level features. Furthermore, these features are concatenated with\ndocument-level features, and use an SVM to learn on these features. The limitation lies\nin failing to capture the structure information of sentences and documents. For instance,\nin order to get the sentence level features for the document, it averages all these features\nof each sentence. It ignores how these sentences construct an article and which parts of\nthe document more signiﬁcantly decides the readability of the document. While cohe-\nsion features provided by Coh-Metrix tries to captures relationships between sentences,\nthese features mainly depend on the repeat of words across multiple sentences. They\ndid not directly model how these sentences construct a document in perspectives of\nstructure and sequence.\nBrieﬂy speaking, existing works are mainly contributing more features as shown\nin Table 1. But the current models used to aggregate these features are based on SVM\nand linear models. In this work, we target to propose a more advanced model to better\ncombine these features with document information.\n4 Hierarchical Transformer for Readability Analysis\nIn order to address the limitations of traditional approaches, we propose ReadNet: the\nHierarchical Transformer model for readability analysis as shown in Figure 1.\nReadNet: A Hierarchical Transformer Framework for Readability Analysis 5\nName Description\nSentence-level features\n#characters per word The average number of characters per word, which provides a character-level measure for the\ndifﬁculty of words.\n#syllabi per word The average number of syllabi per word, which measures the difﬁculty of words from the\nsyllabus level.\n#words The number of words that measures the verbosity of the sentence.\n#long words The number of words longer than 6 characters in a sentence.\n#difﬁcult words The number of difﬁcult word in a sentence. Difﬁcult word is a word not listed in the 3000\nwords for fourth-grade American students.\n#pronoun The number of pronoun in a sentence.\nDocument-level features\nFlesch Reading Ease [28] The United States Military Standard of readability scoring for technical manuals, which is\ncalculated as 206.835 − 1.015 × #words\n#sentences − 84.6 × #syllables\n#words .\nFlesch-–Kincaid grade\nlevel [28]\nAn empirical readability metric which maps to a U.S. school grade level, calculated as0.39×\n#words\n#sentences + 11.8 × #syllables\n#words − 15.59.\nAutomated Readability In-\ndex [44]\nA metric that also produces an approximate representation of the US grade level needed to\ncomprehend the text, calculated as4.71 × #characters\n#words + 0.5 × #words\n#sentences - 21.43. Instead\nof considering syllables, this metric more generally characterizes on the character level.\nColeman-Liau Index [9] An index used to gauge the understandability of a text from the character-level: 0.0588 ×\n#letters\n#words×100 + 0.296 × #sentences\n#words × 100.\nGunning Fog Index [23] 0.4 × ( #words\n#sentences + 100× #complex words\n#words ); It estimates the years of formal education\na person needs to understand the text on the ﬁrst reading.\nLIX [2] A measure indicating the difﬁculty of reading a text based on the proportions of long words\nand verbosity of sentences: word longer than 6 letters #\n#words + #words\n#sentences .\nRIX [1] A metric based on the proportion of long words in text, # long words\n#sentences .\nSMOG Index [35] A measure of readability that seeks to estimate the years of education needed to understand a\npiece of writing: 1.0430 ×\n√\n# of polysyllables × 30\n#sentences + 3.1291.\nDale Chall Index [19] 0.1579 × #difﬁcult words\n#words × 100 + 0.0496 × #words\n#sentences . Difﬁcult word is a word not\nlisted in the 3000 words for fourth-grade American students\nIncidence of connectives [33] 5 numerical features indicate additive, logic, temporal, causal and negative connectives.\nLogic operator connectiv-\nity [13]\nLogical connectives between logical particles such as “and”, “if” proposed by Coh-Metrix.\nLexical diversity The character-level density of the lexicon: #unique words\n#words .\nContent diversity #content words\n#words . It measures the diversity of content. Content words are adjectives, nouns,\nverbs and adverbs.\nIncidence of part-of-speech el-\nements\nIncidence of word categories (adjectives, nouns, verbs, adverbs, pronouns) per 1000 words in\nthe text\nTable 1: Explicit Features\nThe proposed model incorporates the explicit features with a hierarchical document\nencoder that encodes the sequence and structural information of an article. The ﬁrst\nlevel of the hierarchical learning architecture models the formation of sentences from\nwords. The second level models the formation of the article from sentences. The self-\nattention encoder (to be described in subsection 4.1) is adapted from the vanilla Trans-\nformer encoder [50]. The hierarchical structure, attention aggregation layer, combina-\ntion with explicit features and transfer layer are specially designed for this readability\nanalysis task.\n4.1 From Words to Sentences\nIn this subsection, we introduce the encoding process of sentences in hierarchical mutli-\nhead self-attention. The encoding process has three steps: 1) the self-attention encoder\ntransforms the input sequence into a series of latent vectors; 2) the attention layer ag-\ngregates the encoded sequential information based on the induced signiﬁcance of input\nunits; 3) The encoded information is combined with the explicit features.\n6 Changping Meng 1, Muhao Chen2, Jie Mao3,Jennifer Neville 1\nInput \nEmbedding\nMulti-Head\nAttention\nFeed\nForward\nAdd & Norm\nPositional\nEncoding +\nConcat\nA i ⇤\nLinear\nAdd & Norm\nAttentionu i\nSentence \nFeatures\n… …\nMulti-Head\nAttention\nFeed\nForward\nAdd & Norm\nPositional\nEncoding+\nLinear\nAdd & Norm\nAttention Document \nFeaturesv\nSoftmax\nReadibility\nTransfer\n Layer\nSentence-level encoder Document-level encoder\np ⇥ ⇥ q\nFig. 1: ReadNet: proposed hierarchical transformer model specialized for readability analysis\nTransformer Self-Attention Encoder This encoder is adapted from the vanilla Trans-\nformer encoder [50]. The input for this encoder is Ai,:, which represents the i-th sen-\ntence.\nThe Embedding layer encodes each wordAi,j into a d-dimensional vector based on\nword embedding. The output is am×d-dimensional matrix B where dis the embedding\ndimension and mis the number of words.\nThe position encoding layer indicates the relative position of each word Ai,j. The\nelements of positional embedding matrix P where values in the i-th row j-th column is\ndeﬁned as follows.\nPi,j =\n{\nsin(i/104j/d) jis even\ncos(i/104(j−1)/d) jis odd (1)\nThe embedded matrix B and positional embedding matrix P are added into the\ninitial hidden state matrix H(0) = B + P. H(0) will go through a stack of pidentical\nlayers. Each layer contains two parts: (i) the Multi-Head Attention donated as function\nReadNet: A Hierarchical Transformer Framework for Readability Analysis 7\nfMHA deﬁned in Equation 2, and (ii) the Position-wise Feed-ForwardfFFN deﬁned in\nEquation 4. Layer normalization is used to avoid gradient vanishing or explosion.\nMulti-head Self-Attention function(fMHA ) [50] encodes the relationship among query\nmatrix Q, key matrix K and value matrix V from different representation subspaces at\ndifferent positions. dk = d/h. W is a d×dweight matrix. ⊕denotes concatenation.\nWKi,WV i,WQi are d×dk weight matrix for head function gi.\nfMHA (Q,K,V ) = (g1(Q,K,V )) ⊕...⊕gh(Q,K,V ))W (2)\ngi(Q,K,V ) = softmax(QWQi(KWKi)T\n√dk\n)(V WV i) (3)\nPosition-wise Feed-Forward FunctionfFFN [50] adopts two 1-Dimensional con-\nvolution layers with kernel size 1 to encode input matrix X.\nfFFN (X) = Conv1D(ReLU(Conv1D(X))) (4)\nFor the l-th encoder layer, H(l) is encoded into H(l+1) according to Equation 5\nH(l+1) = fFFN (fMHA (H(l),H(l),H(l))) (5)\nAttention Aggregation Layer After ptransformer encoder layers, each sentence Ai,:\nis encoded into a m×d-dimensional matrix H(p).\nWe ﬁrst pass H(p) through a feed forward layer with d×ddimensional weights\nW1 and bias term b1 to obtain a hidden representation as U:\nU = tanh(H(p)W1 + b1),\nthen compute the similarity between U and the trainable d×1 dimensional context\nmatrix C via\nw = softmax(UC ) ,\nwhich we use as importance weights to obtain the ﬁnal embedding of the sentenceAi,::\nhi =\n∑\nbyRow\nH(p) ·w (6)\nCombination of explicit features The sentence level features ui introduced in Sec-\ntion 3.2 Table 1 for i-th sentence are concatenated by h∗\ni = hi ⊕ui .\n4.2 From Sentences to Articles\nThe second level of the hierarchical learning architecture is on top of the ﬁrst layer. n\nencoded vector h∗\ni (1 ≤i≤n) are concatenated as the input for this layer. The structure\nof second level is the same as the ﬁrst level. The output of this level is a vectory as the\noverall embedding of this article.\n8 Changping Meng 1, Muhao Chen2, Jie Mao3,Jennifer Neville 1\n4.3 Transfer layer\nThe goal of the transfer layer is to improve prediction quality on a target task where\ntraining data are scarce, while a large amount of other training data are available for a\nset of related tasks.\nThe readability analysis problem suffers from the lack of labeled data. Traditional\nbenchmark datasets labeled by domain experts typically contain a small number of\narticles. For instance, CEE contains 800 articles and Weebit contains around 8 thousand\narticles. Such quantities of articles are far smaller than those for sentiment or topic-\nrelated document classiﬁcation tasks which typically involve over ten thousand articles\neven for binary classiﬁcation [27,7]. On the other hand, with the emerging of online\nencyclopedia applications such as Wikipedia, it provides a huge amount of training\ndataset. For instance, English Wikipedia and Simple-English Wikipedia contain more\nthan 100 thousand articles which can be used to train a deep learning model.\nOne fully connected layer combines the article embedding vector y and document-\nlevel features v from Table 1 to output the readability label vector r after a Softmax\nfunction. Wt is the weight of the fully connected layer. For dataset with mcategories\nof readability ratings, each document is embedded into r with m−1 dimensions.\nr = softmax(Wt(y ⊕v))\nIf transfer learning is needed, instead of random initialization, this network is initial-\nized with a pre-trained network based on a larger corpus. During the training process,\nupdate the transfer layer while keeping all other layers frozen. If transfer learning is not\nneeded, all layers are updated during the training process.\n4.4 Learning Objective\nGiven dataset with mcategories of readability ratings, the goal is to minimize ordinal\nregression loss [42] deﬁned as Equation 7. rk represents the k-th dimension of the\nr vector. y is the true label. The threshold parameter θ1,θ2,...θm−1 are also learned\nautomatically from the data.\nL(r; y) =−\nm−1∑\nk=1\nf(s(k; y)(θk −rk)), where s (k; y) =\n{\n−1 k<y\n+1 k≥y (7)\nHere, the objective of learning the readability analysis model is essentially different\nfrom that of a regular document classiﬁcation model, since the classes here do form a\npartial-order. However, the case of two classes degenerates the learning to the same as\nthat of a binary classifer.\n4.5 Why Hierarchical Self-attention\nFor self-attention, the path length in the computation graph between long-range depen-\ndencies in the network is O(1) instead of O(n) for recurrent models such as LSTM.\nReadNet: A Hierarchical Transformer Framework for Readability Analysis 9\nShorter path length in the computation graph makes it easier to learn the interactions\nbetween any elements in the sequence. For readability analysis, modeling the overall\ninteraction between words is more important than modeling the consequent words. For\nsemantic understanding, the consequence of two words such as “ very good ” and “not\ngood” make distinct semantic meanings. While for readability analysis, it does not make\ndifference in difﬁculty to understand it. The overall evaluation of the words difﬁculties\nin the sentences matters.\nThe hierarchical learning structure beneﬁts in two ways. First, it mimics human\nreading behaviors, since the sentence is a reasonable unit for people to read, process\nand understand. People rarely check the interactions between arbitrary words across\ndifferent sentences in order to understand the article. Second, the hierarchical structure\ncan reduce parameter complexity. For a document with nsentences, mwords per sen-\ntence, ddimension per word, the parameter complexity of the model is O((nm)2d) for\nsingle level structure. While for the hierarchical structure, the parameter complexity is\nO(m2d+ n2d).\n5 Experiments\nIn this section, we present the experimental evaluation of the proposed approach. We\nﬁrst introduce the datasets used for the experiments, followed by the comparison of\nthe proposed approach and baselines based on held-out evaluation, as well as detailed\nablation analysis of different techniques enabled by our approach.\n5.1 Datasets\nWe use the following three datasets in our experiment. Table 2 reports the statistics of\nthe three datasets including the average number of sentences per article nsent and the\naverage number of words per sentence nword.\nWiki dataset [26] contains English Wikipediaand Simple English Wikipedia. Sim-\nple English Wikipedia thereof is a simpliﬁed version of English Wikipedia which only\nuses simple English words and grammars. This dataset contains 59,775 English Wikipedia\narticles and 59,775 corresponding Simple English Wikipedia articles.\nCambridge English Exam (CEE) [51] categorizes articles based on the criteria of\nﬁve Cambridge English Exam level (KET, PET, FCE, CAE, CPE). The ﬁve ratings are\nsequentially from the easiest KET to the hardest CPE. In total, it contains 110 KET\narticles, 107 PET articles, 153 FCE articles, 263 CAE articles and 155 CPE articles.\nEven though this dataset designed for non-native speakers may differ from materials for\nnative English speakers, the difﬁculty between ﬁve levels is still comparable. We test\nour model on this dataset in order to check whether our model can effectively evaluate\nthe difﬁculty of English articles according to an existing standard.\nWeebit [49] is one of the largest dataset for readability analysis. It contains 7,676\narticles targeted at different age group readers from Weekly Reader magazine and BBC-\nBitesize website. Weekly Reader magazine categorizes articles according to the ages of\ntargeted readers in 7-8, 8-9 and 9-10 years old. BBC-Bitesize has two levels for age\n11-14 and 15-16. The targeted age is used to evaluate readability levels.\n10 Changping Meng 1, Muhao Chen2, Jie Mao3,Jennifer Neville 1\nDatasets Wiki Cambridge English Exam WeeBit\nEn Simple En KET PET FCE CAE CPE WR 2 WR 3 WR 4 KS3 GCSE\nnsent 37.46 7.74 6.30 8.80 16.47 10.63 16.69 23.41 23.28 28.12 22.71 27.85\nnword 17.03 14.41 9.40 16.63 17.96 16.39 23.47 12.56 13.48 16.29 20.04 18.62\nTable 2: Statistics of datasets Wiki, Cambridge English Exam and Weebit\nAccuracy Explicit Features Semantic Features Explicit+Semantic\nLogistic SVM MLP CNN LSTM HATT HATT+ ReadNet\nWiki 0.822 0.848 0.819 0.583 0.849 0.877 0.898 0.912\n(±0.006) ( ±0.008) (±0.007) (±0.035) (±0.007) (±0.007) (±0.007) (±0.006)\nCEE 0.462 0.492 0.475 0.277 0.473 0.512 0.513 0.528\n(±0.027) ( ±0.041) (±0.044) (±0.031) (±0.047) (±0.043) (±0.041) ( ±0.045)\nWeebit 0.724 0.846 0.845 0.635 0.886 0.884 0.902 0.917\n(±0.007) ( ±0.006) (±0.006) (±0.043) (±0.005) (±0.007) (±0.006) (±0.006)\nTable 3: Cross-validation classiﬁcation accuracy and standard deviation ( in parentheses ) on\nWikipedia(Wiki), Cambridge English Exam (CEE) and Weebit dataset. We report accuracy on\nthree groups of models: (1) statistical classiﬁcation algorithms including multi-class logistic re-\ngression, Linear SVM and Multilayer Perceptron (MLP); (2) Three types of document classiﬁer\nCNN, hierarchical GRNN using LSTM cells (LSTM), Hierarchical Attention Network (HATT);\n(3) Hierarchical Attention Network combined with explicit features(HATT+), and our proposed\napproach which combines explicit features and semantics with Hierarchical Self-Attention (Read-\nNet). Transfer learning is not used, and all parameters in the model are initialized randomly\n(Transfer learning is evaluated separately in Table 5).\nKET PET FCE CAE CPE\nScores 0.381 ±0.078 0.544 ±0.092 0.620 ±0.054 0.671 ±0.085 0.837 ±0.071\nTable 4: Average readability scores of 10 randomly selected articles in Cambridge English Test\npredicted by our model trained using Wikipedia. PET, KET , FCE, CPE and CAE have increas-\ning difﬁculty levels according to Cambridge English. The scores are the conﬁdence scores of\nclassiﬁed as regular English Wikipedia instead of simple English Wikipedia.\n5.2 Evaluation\nIn this subsection, we provide a detailed evaluation of the proposed approach.\nBaseline approaches. We compare our proposed approach (denoted ReadNet) against\nthe following baseline methods.\n– Statistical classiﬁcation algorithms based on explicit features: this category of base-\nlines including the statistical classiﬁcation algorithms that are widely adopted in a\nline of previous works [20,43,12,41,40,51], such as multi-class Logistic Regres-\nsion, the Linear SVM, and the Multilayer Perceptron (MLP) [49]. Explicit features\non which these models are trained have been introduced in Section 3.2. Since this\nwork targets at proposing a more advanced model to utilize features instead of\nproposing new features, all these features from Table 1 are used.\n– Neural document classiﬁers: this category of baselines represents the other line of\nprevious works that adopt variants of neural document models for sentence or docu-\nment classiﬁcation. Corresponding approaches including the Convolutional Neural\nNetworks (CNN) [27], the Hierarchical Gated Neural Network with Long Short-\nterm Memory (LSTM) [48], and the Hierarchical Attention Network (HATT) [52].\nReadNet: A Hierarchical Transformer Framework for Readability Analysis 11\n– The Hierarchical Attention Network combined with explicit features (HATT+), for\nwhich we use the same mechanism as our proposed approach to incorporate the\nexplicit features into the representation of each sentence by the attentive RNN.\nModel conﬁgurations. For article encoding, we limit the number of sentences of\neach article to up to 50, zero-pad short ones and truncate over-length ones. According\nto the data statistics in Table 2, 50 sentences are enough to capture the majority of\ninformation of articles in the datasets. For each sentence, we also normalize the number\nof words to be fed into the model as 50, also via zero-padding and truncating. We ﬁx\nthe batch size to 32, and use Adam [16] as the optimizer with a learning rate 0.001.\nThe epochs of training for the neural models are limited to 300. We set the number of\nencoder layers pand qto 6. The embedding dimension d= 100. Number of heads hin\nfMHA is 3. CNN adopts the same conﬁguration as [27]. Other statistical classiﬁcation\nalgorithms are trained until converge. Source code will be available in the ﬁnal version.\nEvaluation protocol. We formalize the task as a classiﬁcation task following pre-\nvious works on the three benchmark datasets. In order to provide a valid quantitative\nevaluation, we have to follow the existing evaluation method to show the advantage of\nour proposed model compared with the baselines. We adopt 5-fold cross-validation to\nevaluate the proposed model and baselines. We report the classiﬁcation accuracy that is\naggregated on all folds of validation.\nResults. The results are reported in Table 3. Traditional explicit features can pro-\nvide satisfying results. Since the multi-class logistic regression, SVM and MLP models\ncan combine the features number of words per sentenceand number of syllabi per word\nwhich are included in Flesch-Kincaid score, they provide the reasonable result. CNN is\nonly slightly better than random guess. We assume that this is because CNN does not\ncapture the sequential and structural information of documents. The HATT approach\nprovides the best among models without explicit features. The reasons root in the struc-\nture of the model which is able to capture length and structural information of the arti-\ncle. Since it also adopted a hierarchical structure, the conciseness of each sentence and\nthat of the overall article structure is captured, which appears to be signiﬁcant to the\ntask. The explicit features further improve the results of HATT as shown by HATT+.\nEven without explicit features, our proposed approach is better than HATT+. HATT has\nappeared to be successful at highlighting some lexemes and sentence components that\nare signiﬁcant to the overall meanings or sentiment of a document. However, unlike\ntopic and sentiment-related document classiﬁcation tasks, readability does not rely on\nseveral consecutive lexemes, but the aggregation of all sentence components. The path\nlength in the computation graph between arbitrary components dependencies in Read-\nNet is O(1) instead of O(n) for HATT. Shorter path length in the computation graph\nmakes it easier to learn the interactions between any arbitrary words in sentence level,\nor sentences in document-level.\nCompared with traditional approaches, the main advantage of the proposed ap-\nproach is that it uses the document encoder to learn how words are connected into sen-\ntences and how sentences are connected into documents. Baseline approaches only use\nthe averaged explicit features of all the sentences. For these datasets, several extremely\ndifﬁcult and complicated sentences usually determine the readability of a document.\n12 Changping Meng 1, Muhao Chen2, Jie Mao3,Jennifer Neville 1\nThis useful information is averaged and weakened by the total number of sentences in\nbaselines.\n5.3 Analysis on Transfer Learning\nAs shown in Table 3, the standard deviation of the CEE task is large compared with\nthose in Wiki and Weebit tasks since the quantity of CEE articles is not enough to train\na complex deep learning model. Transfer layer in ReadNet is utilized in three steps. First\nis to train and save the model from larger datasets such as Wiki or Weebit. Then, we\ninitialize the model for CEE task and load the parameter weights from the saved model\nexcept for the transfer layer. Eventually on the target task, the transfer layer is trained\nwhile keeping all other layers ﬁxed. As shown in Table 5, loading a pre-trained model\nbased on Weebit or Wiki can increase the accuracy and decrease standard deviation on\nthe CEE task. It is shown that a more accurate and stable model can be achieved by\nutilizing the transfer layer and well-trained models from related tasks.\nOriginal Load Weebit Load Wiki\nAccuracy 0.528 (0.045) 0.568 (0.012) 0.561 (0.014)\nTable 5: Accuracy for CEE classiﬁcation using the transfer layer. Original is the model not us-\ning transfer learning, and without loading trained weights from other dataset. Load Weebitis to\nload the parameters weights trained in Weebit except the transfer layer. Load Wikiis to load the\nparameters weights trained in Wiki except the transfer layer.\nBesides directly training and evaluating the same dataset, we also tried the model\ntrained using Wikipedia dataset and evaluate on Cambridge English dataset. 10 articles\nare randomly selected from each level of Cambridge English Test. The probability of\nbeing classiﬁed as regular English Wikipedia instead of simple English Wikipedia is\ntreated as the difﬁculty score. The average difﬁculty scores predicted by the model are\nshown in Table 4, which shows that our produced readability score implies correctly the\ndifﬁculty of English documents for different levels of exams. A larger score indicates\nhigher difﬁculty. These scores correctly indicate the difﬁculty levels of these exams.\n6 Conclusion and Future Work\nWe have proposed a model to evaluate the readability of articles which can make great\ncontributions to a variety of applications. Our proposed Hierarchical Self-Attention\nframework outperforms existing approaches by combining hierarchical document en-\ncoders with the explicit features proposed by linguistics. For future works, we are inter-\nested in providing the personalized recommendation of articles based on the combina-\ntion of article readability and the understanding ability of the user. Currently, readabil-\nity of articles only evaluate the texts of articles, other modalities such as images [39]\nand taxonomies [8] considered to improve readers’ understanding. More comprehensive\ndocument encoders such as RCNN [5] and tree LSTM [47] may also be considered.\nReadNet: A Hierarchical Transformer Framework for Readability Analysis 13\nReferences\n1. Anderson, J.: Lix and rix: Variations on a little-known readability index. Journal of Reading\n26(6), 490–496 (1983)\n2. Brown, J., Eskenazi, M.: Student, text and curriculum modeling for reader-speciﬁc document\nretrieval. In: Proceedings of the IASTED International Conference on Human-Computer In-\nteraction. Phoenix, AZ (2005)\n3. Chall, J.S.: Readability: An appraisal of research and application (34) (1958)\n4. Chall, J.S., Dale, E.: Readability revisited: The new Dale-Chall readability formula. Brook-\nline Books (1995)\n5. Chen, M., Ju, C., Zhou, G., Chen, X., Zhang, T., Chang, K.W., Zaniolo, C., Wang, W.: Multi-\nfaceted protein-protein interaction prediction based on siamese residual rcnn. Bioinformatics\n35(14), i305–i314 (07 2019)\n6. Chen, M., Meng, C.P., Huang, G., Zaniolo, C.: Neural article pair modeling for wikipedia\nsub-article machine. In: ECML (2018)\n7. Chen, M., Meng, C., Huang, G., Zaniolo, C.: Learning to differentiate between main-articles\nand sub-articles in wikipedia. In: Proceedings of the IEEE International Conference on Big\nData (2019)\n8. Chen, M., Tian, Y ., Chen, X., Xue, Z., Zaniolo, C.: On2vec: Embedding-based relation pre-\ndiction for ontology population. In: Proceedings of the 2018 SIAM International Conference\non Data Mining. pp. 315–323. SIAM (2018)\n9. Coleman, M., Liau, T.L.: A computer readability formula designed for machine scoring.\nJournal of Applied Psychology 60(2), 283 (1975)\n10. Collins-Thompson, K., Callan, J.: A language modeling approach to predicting reading dif-\nﬁculty. In: Proceedings of the Human Language Technology Conference of the North Amer-\nican Chapter of the Association for Computational Linguistics: HLT-NAACL 2004 (2004)\n11. Collins-Thompson, K.: Computational assessment of text readability: A survey of current\nand future research (2014)\n12. Collins-Thompson, K., Callan, J.: Predicting reading difﬁculty with statistical language mod-\nels. Journal of the American Society for Information Science and Technology56(13), 1448–\n1462 (2005)\n13. Coxhead, A.: A new academic word list. TESOL quarterly 34(2), 213–238 (2000)\n14. Dale, E., Chall, J.S.: The concept of readability. Elementary English 26(1), 19–26 (1949)\n15. De Clercq, O., Hoste, V .: All mixed up? ﬁnding the optimal feature set for general readability\nprediction and its application to english and dutch. Computational Linguistics 42(3), 457–\n490 (2016)\n16. Duchi, J., Hazan, E., Singer, Y .: Adaptive subgradient methods for online learning and\nstochastic optimization. Journal of Machine Learning Research 12(Jul), 2121–2159 (2011)\n17. Feng, L., Elhadad, N., Huenerfauth, M.: Cognitively motivated features for readability as-\nsessment. In: Proceedings of the 12th Conference of the European Chapter of the Associa-\ntion for Computational Linguistics. pp. 229–237. Association for Computational Linguistics\n(2009)\n18. Franc ¸ois, T.L.: Combining a statistical language model with logistic regression to predict\nthe lexical and syntactic difﬁculty of texts for fﬂ. In: Proceedings of the 12th Conference of\nthe European Chapter of the Association for Computational Linguistics: Student Research\nWorkshop. pp. 19–27. Association for Computational Linguistics (2009)\n19. Fry, E.: A readability formula that saves time. Journal of reading 11(7), 513–578 (1968)\n20. Fry, E.B.: The varied uses of readability measurement today. Journal of Reading (1987)\n21. Gibson, E.: Linguistic complexity: Locality of syntactic dependencies. Cognition (1998)\n14 Changping Meng 1, Muhao Chen2, Jie Mao3,Jennifer Neville 1\n22. Graesser, A.C., McNamara, D.S., Louwerse, M.M., Cai, Z.: Coh-metrix: Analysis of text on\ncohesion and language. Behavior research methods, instruments, & computers 36(2), 193–\n202 (2004)\n23. Gunning, R.: The fog index after twenty years. Journal of Business Communication 6(2),\n3–13 (1969)\n24. Heilman, M., etc.: Combining lexical and grammatical features to improve readability mea-\nsures for ﬁrst and second language texts. In: Human Language Technologies (2007)\n25. Heilman, M., Collins-Thompson, K., Eskenazi, M.: An analysis of statistical models and\nfeatures for reading difﬁculty prediction. In: 3rd workshop on innovative use of NLP for\nbuilding educational applications (2008)\n26. Kauchak, D.: Improving text simpliﬁcation language modeling using unsimpliﬁed text data.\nIn: Proceedings of the 51st annual meeting of the association for computational linguistics\n(volume 1: Long papers). vol. 1, pp. 1537–1546 (2013)\n27. Kim, Y .: Convolutional neural networks for sentence classiﬁcation. In: Empirical Methods\nin Natural Language Processing (2014)\n28. Kincaid, J.P., Fishburne Jr, R.P., Rogers, R.L., Chissom, B.S.: Derivation of new readability\nformulas for navy enlisted personnel (1975)\n29. Klare, G.R.: The measurement of readability: useful information for communicators. ACM\nJournal of Computer Documentation (JCD) 24(3), 107–121 (2000)\n30. Li, J., Luong, M.T., Jurafsky, D.: A hierarchical neural autoencoder for paragraphs and doc-\numents. arXiv preprint arXiv:1506.01057 (2015)\n31. Li, Z., Wei, Y ., Zhang, Y ., Yang, Q.: Hierarchical attention transfer network for cross-\ndomain sentiment classiﬁcation. In: Thirty-Second AAAI Conference on Artiﬁcial Intelli-\ngence (2018)\n32. Lin, R., Liu, S., Yang, M., Li, M., Zhou, M., Li, S.: Hierarchical recurrent neural network\nfor document modeling. In: Proceedings of the 2015 Conference on Empirical Methods in\nNatural Language Processing. pp. 899–907 (2015)\n33. Louwerse, M.: An analytic and cognitive parametrization of coherence relations. Cognitive\nlinguistics 12(3), 291–316 (2001)\n34. Malvern, D., Richards, B.: Measures of lexical richness. The encyclopedia of applied lin-\nguistics (2012)\n35. Mc Laughlin, G.H.: Smog grading-a new readability formula. Journal of reading 12(8), 639–\n646 (1969)\n36. McNamara, D.S., Graesser, A.C., McCarthy, P.M., Cai, Z.: Automated evaluation of text and\ndiscourse with Coh-Metrix. Cambridge University Press (2014)\n37. McNamara, D.S., Louwerse, M.M., McCarthy, P.M., Graesser, A.C.: Coh-metrix: Capturing\nlinguistic features of cohesion. Discourse Processes 47(4), 292–330 (2010)\n38. Parikh, A.P., T ¨ackstr¨om, O., Das, D., Uszkoreit, J.: A decomposable attention model for\nnatural language inference. arXiv preprint arXiv:1606.01933 (2016)\n39. Pezeshkpour, P., Chen, L., Singh, S.: Embedding multimodal relational data for knowledge\nbase completion. In: Proceedings of the 2018 Conference on Empirical Methods in Natural\nLanguage Processing. pp. 3208–3218 (2018)\n40. Pil ´an, I., V olodina, E., Zesch, T.: Predicting proﬁciency levels in learner writings by trans-\nferring a linguistic complexity model from expert-written coursebooks. In: Proceedings of\nCOLING 2016, the 26th International Conference on Computational Linguistics: Technical\nPapers. pp. 2101–2111 (2016)\n41. Pitler, E., Nenkova, A.: Revisiting readability: A uniﬁed framework for predicting text qual-\nity. In: Proceedings of the conference on empirical methods in natural language processing.\npp. 186–195. Association for Computational Linguistics (2008)\nReadNet: A Hierarchical Transformer Framework for Readability Analysis 15\n42. Rennie, J.D., Srebro, N.: Loss functions for preference levels: Regression with discrete or-\ndered labels. In: Proceedings of the IJCAI multidisciplinary workshop on advances in pref-\nerence handling. pp. 180–186. Kluwer Norwell, MA (2005)\n43. Schwarm, S.E., Ostendorf, M.: Reading level assessment using support vector machines and\nstatistical language models. In: Proceedings of the 43rd Annual Meeting on Association for\nComputational Linguistics. pp. 523–530. Association for Computational Linguistics (2005)\n44. Senter, R., Smith, E.A.: Automated readability index. Tech. rep., CINCINNATI UNIV OH\n(1967)\n45. Si, L., Callan, J.: A statistical model for scientiﬁc readability. In: CIKM. vol. 1, pp. 574–576\n(2001)\n46. Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C.D., Ng, A., Potts, C.: Recursive\ndeep models for semantic compositionality over a sentiment treebank. In: Proceedings of\nthe 2013 conference on empirical methods in natural language processing. pp. 1631–1642\n(2013)\n47. Tai, K.S., Socher, R., Manning, C.D.: Improved semantic representations from tree-\nstructured long short-term memory networks. In: Proceedings of the 53rd Annual Meeting\nof the Association for Computational Linguistics and the 7th International Joint Conference\non Natural Language Processing (V olume 1: Long Papers). pp. 1556–1566 (2015)\n48. Tang, D., Qin, B., Liu, T.: Document modeling with gated recurrent neural network for senti-\nment classiﬁcation. In: Proceedings of the 2015 conference on empirical methods in natural\nlanguage processing. pp. 1422–1432 (2015)\n49. Vajjala, S., Meurers, D.: On improving the accuracy of readability classiﬁcation using in-\nsights from second language acquisition. In: Proceedings of the seventh workshop on build-\ning educational applications using NLP. pp. 163–173. Association for Computational Lin-\nguistics (2012)\n50. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł.,\nPolosukhin, I.: Attention is all you need. In: Advances in neural information processing\nsystems. pp. 5998–6008 (2017)\n51. Xia, M., Kochmar, E., Briscoe, T.: Text readability assessment for second language learners.\nIn: Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational\nApplications. pp. 12–22 (2016)\n52. Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., Hovy, E.: Hierarchical attention networks\nfor document classiﬁcation. In: Proceedings of the 2016 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Technologies.\npp. 1480–1489 (2016)\n53. Zakaluk, B.L., Samuels, S.J.: Readability: Its Past, Present, and Future. ERIC (1988)",
  "topic": null,
  "concepts": []
}