{
  "title": "A Framework and Operational Procedures for Metaverses-Based Industrial Foundation Models",
  "url": "https://openalex.org/W4312854774",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2121845923",
      "name": "Jiangong Wang",
      "affiliations": [
        "Beijing Academy of Artificial Intelligence",
        "University of Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2775974243",
      "name": "Yonglin Tian",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Institute of Automation"
      ]
    },
    {
      "id": "https://openalex.org/A2106662587",
      "name": "Yu-tong Wang",
      "affiliations": [
        "Institute of Automation",
        "Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2083709059",
      "name": "Jing Yang",
      "affiliations": [
        "University of Chinese Academy of Sciences",
        "Beijing Academy of Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2535240739",
      "name": "Xingxia Wang",
      "affiliations": [
        "University of Chinese Academy of Sciences",
        "Beijing Academy of Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A4314097548",
      "name": "Sanjin Wang",
      "affiliations": [
        "China North Industries Group Corporation (China)"
      ]
    },
    {
      "id": "https://openalex.org/A1975269299",
      "name": "Oliver Kwan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4226225860",
    "https://openalex.org/W4224242420",
    "https://openalex.org/W4210592306",
    "https://openalex.org/W2154703456",
    "https://openalex.org/W4296425724",
    "https://openalex.org/W6800751262",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W6762122294",
    "https://openalex.org/W6767737316",
    "https://openalex.org/W6771917389",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W3187018546",
    "https://openalex.org/W6763701032",
    "https://openalex.org/W6769627184",
    "https://openalex.org/W6788811087",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3096609285",
    "https://openalex.org/W6796487566",
    "https://openalex.org/W4312349930",
    "https://openalex.org/W2108598243",
    "https://openalex.org/W3172942063",
    "https://openalex.org/W6682250724",
    "https://openalex.org/W6754278344",
    "https://openalex.org/W3035524453",
    "https://openalex.org/W2883725317",
    "https://openalex.org/W3110446398",
    "https://openalex.org/W6796761347",
    "https://openalex.org/W4313156423",
    "https://openalex.org/W6790978476",
    "https://openalex.org/W6844305113",
    "https://openalex.org/W6843813467",
    "https://openalex.org/W6804184823",
    "https://openalex.org/W6779473860",
    "https://openalex.org/W3173909648",
    "https://openalex.org/W2991120206",
    "https://openalex.org/W3150923322",
    "https://openalex.org/W2991006461",
    "https://openalex.org/W4210553154",
    "https://openalex.org/W4301802352",
    "https://openalex.org/W3135789488",
    "https://openalex.org/W2969933444",
    "https://openalex.org/W3193447528",
    "https://openalex.org/W2904063322",
    "https://openalex.org/W4291653324",
    "https://openalex.org/W2994918793",
    "https://openalex.org/W2907779612",
    "https://openalex.org/W2943316551",
    "https://openalex.org/W2967616623",
    "https://openalex.org/W4296501493",
    "https://openalex.org/W3107376020",
    "https://openalex.org/W3002520801",
    "https://openalex.org/W2980858786",
    "https://openalex.org/W2980066546",
    "https://openalex.org/W2969227524",
    "https://openalex.org/W4304162916",
    "https://openalex.org/W3137904872",
    "https://openalex.org/W2972143761",
    "https://openalex.org/W2984080647",
    "https://openalex.org/W2903814720",
    "https://openalex.org/W3126426351",
    "https://openalex.org/W2969346978",
    "https://openalex.org/W3161934848",
    "https://openalex.org/W2938440964",
    "https://openalex.org/W2947821749",
    "https://openalex.org/W3020107244",
    "https://openalex.org/W2948535293",
    "https://openalex.org/W3196920896",
    "https://openalex.org/W2921644959",
    "https://openalex.org/W2921419166",
    "https://openalex.org/W3111939614",
    "https://openalex.org/W3114969094",
    "https://openalex.org/W3091436929",
    "https://openalex.org/W3016409148",
    "https://openalex.org/W3187318797",
    "https://openalex.org/W3188058378",
    "https://openalex.org/W3198484080",
    "https://openalex.org/W3197088326",
    "https://openalex.org/W2968404378",
    "https://openalex.org/W2038194220",
    "https://openalex.org/W2962703917",
    "https://openalex.org/W3140120893",
    "https://openalex.org/W3096720394",
    "https://openalex.org/W4287824654",
    "https://openalex.org/W4287391717",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4298185919",
    "https://openalex.org/W2887997457",
    "https://openalex.org/W3170863103",
    "https://openalex.org/W4298187450",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W4288089799"
  ],
  "abstract": "Industrial processes are typical cyber–physical–social systems (CPSSs), where the effective management of employees and the efficient control of machines play important roles. Traditional industries heavily rely on human labor and neglect the development of collection–utilization–transmission integrated information loops, thereby leading to high costs and low efficiency in operational procedures. To facilitate the natural interactions and smart operations for humans and machines, industrial foundation models (IFMs) based on metaverses are proposed in this article, serving as the operating systems of industrial parallel machines that provide sustainable data resources and scenarios for management and control experiments. On this basis, IFM comprised of vision foundation models, language foundation models, as well as operational foundation models, are constructed to manage resources in industrial parallel machines and provides comprehensive services for industrial procedures. On the one hand, IFM can efficiently manage various resources including computing power, digital assets, enterprise resources, and platform I/O via the proposed CPSS-based competing, sharing, scheduling, monitoring, allocating, and recovering mechanisms. On the other hand, imaginative intelligence, linguistic intelligence, and algorithmic intelligence can be achieved through vivid visualization of vision foundation models, natural conversations of language foundation models, and smart manipulation of operational foundation models. With the proposed IFM, cyber–physical–social intelligence (CPSI) can be achieved to enhance the efficient management and control of industrial processes.",
  "full_text": "IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS: SYSTEMS, VOL. 53, NO. 4, APRIL 2023 2037\nA Framework and Operational Procedures for\nMetaverses-Based Industrial Foundation Models\nJiangong Wang , Student Member, IEEE, Yonglin Tian , Member, IEEE, Yutong Wang , Member, IEEE,\nJing Yang , Xingxia Wang , Student Member, IEEE, Sanjin Wang, and Oliver Kwan\nAbstract—Industrial processes are typical cyber–physical–\nsocial systems (CPSSs), where the effective management of\nemployees and the efﬁcient control of machines play important\nroles. Traditional industries heavily rely on human labor and\nneglect the development of collection–utilization–transmission\nintegrated information loops, thereby leading to high costs and\nlow efﬁciency in operational procedures. To facilitate the natural\ninteractions and smart operations for humans and machines,\nindustrial foundation models (IFMs) based on metaverses are\nproposed in this article, serving as the operating systems of indus-\ntrial parallel machines that provide sustainable data resources\nand scenarios for management and control experiments. On this\nbasis, IFM comprised of vision foundation models, language foun-\ndation models, as well as operational foundation models, are\nconstructed to manage resources in industrial parallel machines\nand provides comprehensive services for industrial procedures.\nOn the one hand, IFM can efﬁciently manage various resources\nincluding computing power, digital assets, enterprise resources,\nand platform I/O via the proposed CPSS-based competing,\nsharing, scheduling, monitoring, allocating, and recovering mech-\nanisms. On the other hand, imaginative intelligence, linguistic\nintelligence, and algorithmic intelligence can be achieved through\nvivid visualization of vision foundation models, natural conversa-\ntions of language foundation models, and smart manipulation of\noperational foundation models. With the proposed IFM, cyber–\nphysical–social intelligence (CPSI) can be achieved to enhance\nthe efﬁcient management and control of industrial processes.\nIndex Terms —Cyber–physical–social intelligence (CPSI),\ncyber–physical–social systems (CPSSs), industrial foundation\nmodels (IFMs), intelligent enterprises, metaverses, operational\nprocesses, parallel intelligence.\nManuscript received 16 November 2022; accepted 30 November 2022. Date\nof publication 16 December 2022; date of current version 17 March 2023. This\nwork was supported in part by the National Natural Science Foundation of\nChina under Grant 62103411; and in part by the Motion G, Inc. Collaborative\nResearch Project for Modeling, Decision and Control Algorithms of Servo\nDrive Systems. This article was recommended by Associate Editor F.-Y . Wang.\n(Corresponding author: Yonglin Tian.)\nJiangong Wang, Jing Yang, and Xingxia Wang are with the School of\nArtiﬁcial Intelligence, University of Chinese Academy of Sciences, Beijing\n100049, China, and also with the State Key Laboratory for Management and\nControl of Complex Systems, Institute of Automation, Chinese Academy of\nSciences, Beijing 100190, China.\nYonglin Tian and Yutong Wang are with the State Key Laboratory for\nManagement and Control of Complex Systems, Institute of Automation,\nChinese Academy of Sciences, Beijing 100190, China, and also with\nQingdao Academy of Intelligent Industries, Qingdao 266109, China\n(e-mail: yonglin.tian@ia.ac.cn).\nSanjin Wang is with the North Automatic Control Technology Institute,\nChina North Industries North Automatic Control Technology Research\nInstitute, Taiyuan 030006, China.\nOliver Kwan is with the Motion G Inc., Shenzhen 518071, China.\nColor versions of one or more ﬁgures in this article are available at\nhttps://doi.org/10.1109/TSMC.2022.3226755.\nDigital Object Identiﬁer 10.1109/TSMC.2022.3226755\nI. I NTRODUCTION\nI\nNDUSTRIAL production plays signiﬁcant roles in the\neconomy and our daily life. It is a complex system\ninvolving the management of human labor, the scheduling of\nresources as well as the control of machines. With the devel-\nopment of new technologies, the industry is gradually moving\nfrom automation to intelligence. The expansion of industrial\nproduction is hampered by a number of issues, though, as\nindustrial processes have increased and complicated.\nIndustrial processes often lack interaction or are difﬁcult to\ninteract with, resulting in inefﬁcient execution. This can lead\nto production delays, increased costs, and a decline in quality.\nInteractions between different parts of the process are essential\nto optimize the overall ﬂow of work and ensure that tasks\nare completed in an efﬁcient and effective manner. In order\nto ensure that industrial processes are executed efﬁciently, the\ndesigner and implementer need to take into account the various\ninteractions between different parts of the process. This is a\ndifﬁcult task, as it requires a great deal of knowledge and\nexperience. As a result, organizations may miss opportunities\nto improve their operations.\nManagement of resources has always been exceedingly\nchallenging, particularly when it comes to managing mental\nlabor. Low efﬁciency of mental labor and management difﬁcul-\nties are brought on by measurement challenges. It is famously\ndifﬁcult to quantify mental labor, which makes it challenging\nto manage efﬁciently. This leads to low efﬁciency and pro-\nductivity among mental laborers, as they are often not sure\nhow much work is actually expected of them. As a result, it is\nchallenging to efﬁciently regulate and optimize mental labor.\nBusinesses that signiﬁcantly rely on mental work may experi-\nence decreased productivity and increased costs as a result of\nthis inefﬁciency. In addition, mental labor is often subjective\nand difﬁcult to quantify, making it difﬁcult to compare differ-\nent workers and identify areas in which they can be improved.\nEmployers could struggle to defend the expense of mental\nlabor as a result, and employees might feel undervalued and\noverworked [1].\nWith the development of intelligent technologies, there\nhave already been some small models applied in some spe-\nciﬁc industrial scenarios, but the small models with simple\nfunctions fail to meet the needs of enterprises for intelli-\ngent interaction and management. First, small models can\nonly handle separate tasks in a decentralized and independent\nmanner. The inability to work collaboratively between small\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n2038 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS: SYSTEMS, VOL. 53, NO. 4, APRIL 2023\nmodels also means that more efﬁcient and general intel-\nligence is not possible. Second, small models are often\nnot capable and accurate enough to handle large-scale data.\nThe management of various resources requires the process-\ning of large amounts of structured and unstructured data,\nwhich cannot be supported by the model capacity of small\nmodels.\nThe emergence of metaverses [ 2], [ 3], [ 4] and foundation\nmodels provides an effective solution to improve industrial\nprocesses by providing a way to visualize and analyze huge\namounts of data in a more immersive and interactive way. With\nmetaverses and foundation models, companies can improve\ntheir understanding of complex processes and make more\ninformed decisions, at the same time, the value of mental\nlabor can also be accurately measured through data-driven\nanalysis. Additionally, it is possible to train employees on\nnew procedures in metaverses or to simulate and test in\nmetaverses before implementing improvements in the real\nworld.\nThis article proposes a framework and operational pro-\ncedures for metaverses-based industrial foundation mod-\nels (IFMs) in cyber–physical–social systems (CPSSs) [ 5],\nwhich is composed of vision foundation models, language\nfoundation models, and operation foundation models. IFM\nis capable of coordinating and managing the activities of\nmultiple resources in order to optimize production. It is the\nfoundation of the future industrial economy and will have a\nprofound impact on the way we live and work. With cognitive\nintelligence, parallel intelligence, crypto intelligence, federated\nintelligence, social intelligence, and ecological intelligence\n(6I), IFM aims to achieve the safety, security, sustainability,\nsensitivity, service, and smartness (6S) of enterprises, and the\nprocess is measured by safety index, security index, sustain-\nability index, sensitivity index, service index, and smartness\nindex [6].\nII. B\nIG AI M ODELS\nWith large-scale datasets, global modeling frameworks,\nunsupervised learning approaches as well as efﬁcient comput-\ning platforms, developing big AI models have become possible\nand popular in various tasks, such as natural language and\nvisual data processing [ 7]. Overall, the shifting of AI mod-\nels from small-scale ones to big ones is about the extension\nof generalization ability and the reconstruction of the learn-\ning paradigm. First, big models have superior ability in the\ngeneralization to the application on different scenarios and\nthe recognition of different patterns thanks to the increasing\ndata scale and the widely adopted Transformer framework with\nglobal and dynamic aggregation mechanisms. For the recon-\nstruction of the learning paradigm, big AI models have led\nthe way of model development to the pretraining-ﬁnetuning\nparadigm from traditional integrated and individual model\ndevelopment. Different from the fully supervised manners used\nin conventional training processes, the pretraining stage takes\nadvantage of self-supervised learning approaches to alleviate\nthe labeling burdens and learn intrinsic embeddings from the\ninput itself.\nA. NLP Models\nTransformer [ 8], the sole attention-based architecture, is\nﬁrst proposed in the NLP area, which has then become\nthe main framework used for constructing NLP big models.\nTypical structures of big NLP models include encoder-based\nmodels, decoder-based models, and encoder–decoder mod-\nels which are paired with different training strategies and\nused for different tasks. Encoder-based NLP models, such\nas BERT [ 9], UniLM [ 10], XLM [ 11], ELECTRA [ 12], and\nso on, simultaneously consider the context features for each\ntoken and adopt autoencoding (AE) objective to train the\nmodel with masked language modeling-based self-supervision.\nDifferent from the bidirectional design in encoder-based mod-\nels, decoder-based models only consider tokens before the\ncurrent position and use autoregression (AR) objectives dur-\ning the training process. Typical decoder-based NLP models\ninclude GPT [ 13], GPT-2 [ 14], GPT-3 [ 15], ELMo [ 16],\nCPM-1 [ 17], and so on. Encoder-based models have advan-\ntages in the modeling of context features and are widely used\nin language understanding. But due to the masking operations,\nthere are gaps between the inputs at the pretraining stage\nand ﬁnetuning stages. Decoder-based methods adopt unidi-\nrectional designs, which are suitable for generative language\ntasks. XLNET [ 18] explores the combination of advantages\nfrom both AE and AR by token permutation. Encoder–decoder\nframeworks combine the representation and task-speciﬁc mod-\nules in series, which are widely used for sequence-to-sequence\ntasks, such as question answering and machine translation.\nT5 [19], Switch-Transformer [20], and BART [21] are typical\nencoder–decoder-based big language models.\nB. Vision Models\nViT [ 22], DETR [ 23], and other pioneering works\nextend Transformers to computer vision areas, which has\nattracted great attention to the design and application of\nvision Transformers. Several big vision models, such as\nViT-MoE [ 24] and Swin-v2 [ 25] have been developed\nin a supervised manner on large-scale datasets, such as\nImageNet [ 26] and JFT-3B [ 27]. However, the supervised\ntraining manner relies on heavy and expensive annotations\nwhich is unfavorable for the wide application of foundation\nmodels [7]. Augmentation-based, cluster-based, and masking-\nbased methods are three of the main self-supervised training\nstrategies for visual data. Augmentation-based methods con-\nduct different transformations on the inputs and calculate the\nloss with consistency constraints [28], [29], [30]. Cluster-based\napproaches use the cluster results as pseudo labels for the\nsupervision of classiﬁcation task [ 31], [32]. Recent masking-\nbased methods adopt a similar idea from BERT [ 9], which\nrandomly masks a percentage of image patches in the inputs\nand uses a Transformer-based network to infer the masked\npatches [33], [34].\nC. Multimodal Models\nEmerging processes on language and vision big models also\ninspire the development of multimodel inputs. The multimodal\ninputs can be images, videos, texts, speeches tabular data\nW ANG et al.: FRAMEWORK AND OPERATIONAL PROCEDURES FOR META VERSES-BASED IFMs 2039\nFig. 1. Industrial parallel machines based on CPSS: Basic framework,\nprocesses, and functionalities modes.\nas well as predeﬁned rules. Multiple promising applications\nhave been designed, such as text-to-image generation [ 35],\ntext-to-video generation [ 36], text-to-3-D generation [ 37],\nimage-to-video generation [ 38], visual commonsense reason-\ning [ 39], [40], and so on. In multimodal networks, different\ntransformer encoders are used as the main backbones to\nextract the features from diverse inputs and cross-attention\nmechanisms are adopted for information fusion.\nIII. I NDUSTRIAL FOUNDATION MODELS\nIFMs are the operating systems of the industrial parallel\nmachines [41], also the illusionists of industrial management.\nThey can make bad things better, make fewer things more,\nmake complex things simple, and make the parallel machine\npresent to the user in a more intelligent, more convenient, and\nmore powerful way, achieving the 6I and 6S of industrial man-\nagement. At the same time, the operating systems are based on\nthe principle of parallel management, and they are comprehen-\nsive systems that can be used to manage any type of industrial\norganization, from a single factory to a multinational corpora-\ntion. In the future, they will be widely used in the automotive,\naerospace, electronics industry, and other industries.\nA. Industrial Parallel Machines\nParallel machines are the sublimation of computers into\nthe intelligent world of the future. As shown in Fig. 1,t h e\nCPSS-based parallel machines combine the physical-designed\nNewton machines and the software-deﬁned Merton machines\ninto one, bridging the physical space, social space, and\ncyberspace. With parallel machines, biological employees,\nrobotic employees, and digital employees are deeply integrated\nto build a new type of parallel employees, combining human\nand machine, knowledge and action, and virtuality and reality.\nAmong parallel employees, human employees with intuitive\nrationality, i.e., biological humans themselves, who take up\nonly 5% of the workload and are responsible for leading\nthe organization. Robots employees with adaptative rationality,\ni.e., intelligent machines, take up about 15% of the workload\nand dominate physical work. Digital employees with compu-\ntational rationality, i.e., intelligent programs and information\nmachines, who are in charge of the remaining work and inter-\nact with biological humans and robotic humans in a natural\nway [1].\nThe parallel employees are involved in the actual opera-\ntion as users, hardware, and software of the industrial parallel\nmachines, whereas the IFM acts as the operating system of\nthe industrial parallel machine, controlling the operation of\nall matters in the machine. In primitive computers, humans\ncontrolled the machines directly without an operating system.\nHowever, as the complexity of computers grew dramatically,\nhumans were no longer up to the task. Similarly, as comput-\ners will be upgraded to CPSS-based parallel machines, the\nnowadays operating systems will certainly be replaced by the\nfoundation models.\nB. Framework of IFM\nIFMs are operating systems for industrial parallel machines,\nwhich consist of three components, the vision foundation\nmodel for imaginative intelligence, the language foundation\nmodel for linguistic intelligence, and the operational founda-\ntion model for algorithmic intelligence. As shown in Fig. 2,\nCPSS and industrial metaverses are the cornerstones and\nscopes of industrial parallel machines and IFMs. By building a\nvirtual world on the basis of the physical world, we can realize\nthe virtual-real symbiosis of the whole life cycle of industries.\nAnd then, the intelligent management of enterprises and the\nefﬁcient closing loop of production and sales are realized by\nparallel machines with the IFMs as the operating system.\nThe vision foundation models are responsible for the strate-\ngic planning and organization of the enterprises. Their main\nusers are decision makers such as CEOs of companies. With\nincreasingly intricate social relationships and the sheer scale\nof industry data, human decision-makers are no longer able\nto analyze and develop a strategic plan that outlines the com-\npany’s goals and objectives. Instead, they must rely on vision\nfoundation models that can take into account all of the relevant\ninformation and generate TopK plans then make recommen-\ndations under the direction of human decision makers. Even\nthough these models have their limitations at the development\nand evolutionary stage, human decision-makers still need their\nhelp in order to make the best decisions for their companies to\nprevent them from being eliminated by other companies with\nvision foundation models.\nThe language foundation models are responsible for the\ncoordination and management of the enterprises. Their main\nusers are managers such as department heads of companies.\nThe models are designed to help human managers in various\nways, such as improving communication between departments,\ntracking the progress of projects, and managing resources.\nEspecially, with the general trend of industrial automation and\ndigitization, human managers have inefﬁcient communication\nwith smart devices and digital employees, so they simply can-\nnot directly manage the actual running of the company. At\nthis point, language foundation models can understand both\nnatural and machine-intelligent language. Therefore, they have\n2040 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS: SYSTEMS, VOL. 53, NO. 4, APRIL 2023\nFig. 2. Operating systems of industrial parallel machines: imaginative intelligence, linguistic intelligence, and algorithmic intelligence.\nan innate talent to make better decisions and improve the efﬁ-\nciency of the department by coordinating and analyzing the\nrelevant data obtained from other departments and combining\nthem with the operation of their own department, based on the\npremise of understanding the visual foundation model for the\noverall planning of the company.\nThe operational foundation models are responsible for the\nexecution of the enterprises. Their main users are workers\nsuch as grassroots staff of companies. The jobs of grass-\nroots employees are often relatively repetitive, boring, and\neven dangerous sometimes. Based on the experience of past\nsocial developments, such as the emergence of ironware,\ntextile machines, steam engines, electric motors, and com-\nputers, human society is bound to keep moving in the\ndirection of simplicity and efﬁciency. These essential jobs\nare inevitably performed by various robotic humans and dig-\nital humans. The operational foundation models are designed\nto help human workers analyze task information from lan-\nguage foundation models, at the same time, they maximize\nthe productivity of robotic humans and digital humans by\nhelping biological humans to manage and schedule speciﬁc\nwork.\nC. Operational Procedures of IFM\nAs shown in Fig. 3, the management of various resources,\nmainly, including computing power, digital assets, enterprise\nresources, and platform I/O, are the four core mechanisms of\nthe IFMs. The resource management mechanisms of the IFM\nmainly include a resource competition mechanism, resource\nsharing mechanism, resource scheduling mechanism, resource\nmonitoring mechanism, resource allocation mechanism [ 42],\nresource recovery mechanism, and so on. Every management\nmechanism is equipped with its own policies, algorithms,\nrules, etc., that serve particular functions.\nThe computing power is the primary resource, and it refers\nto the processing power of industrial parallel machines run-\nning in the metaverses and CPSS, which can be used to handle\nany of the data processing, information analysis, algorithm\ndevelopment, and model designing involved in the industrial\nprocesses and company management. As shown in Fig. 4,\nwith the artiﬁcial systems, computational experiments, and\nparallel execution (ACP) method of parallel intelligence as a\nguide [43], [44], [45], [46], computing management can carry\nout physical embodied intelligent for the enterprises in the\nphysicspace while also carrying out computationally embodied\nintelligent for the enterprises in the cyberspace. With the sup-\nport of sufﬁcient computing power, scene engineering builds\ndiverse scenarios for task generation and scheduling [47], [48],\n[49], [50], computational experiments, and parallel testing and\nexecution. In particular, the generation and scheduling of tasks\nthrough large-scale operations are implemented to achieve\ndescriptive intelligence. Descriptive intelligence can help you\nsee the big picture of where the industry or business is now and\nwhere it is going based on massive data while generating and\nrecommending the most appropriate development strategies or\nwork methods. Then, the predictive intelligence is realized by\ncomputational experiments on the generated tasks and arrange-\nment in both physicspace and cyberspace. Computational\nexperiments rely on large-scale computing power to reason\nand simulate kinds of strategies generated in descriptive intelli-\ngence through multiple experiments in cyberspace and limited\nexperiments in physicspace. Finally, we test and execute the\nresults of the experiments in both spaces by parallel test-\ning and parallel execution with virtual-real interaction, and\nthen the prescriptive intelligence can be realized. Prescriptive\nintelligence can monitor and guide the direction of pro-\ngresses in a closed-loop manner while the work is being\nexecuted, enabling the most efﬁcient and smartest task-driven\napproach.\nW ANG et al.: FRAMEWORK AND OPERATIONAL PROCEDURES FOR META VERSES-BASED IFMs 2041\nFig. 3. Operational procedures of IFM, i.e., resources management: computing management, digital assets management, production management, and I /O\nmanagement.\nFig. 4. Intelligence in computing management of IFM: descriptive intelligence, predictive intelligence, and prescriptive intelligence.\nDigital assets will become the most valuable asset for\nenterprises in the future. Method innovation, data collection,\nand knowledge automation are the basis for the evolution of\nintelligent enterprises. At the same time, these digital assets\nbring not only direct economic beneﬁts to the enterprise\nbut also attention and trust. These virtual goods, which are\n2042 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS: SYSTEMS, VOL. 53, NO. 4, APRIL 2023\noriginally unquantiﬁable, will also become new commodities\nthat can be mass produced and circulated in CPSS. Digital\nassets management is mainly concerned with the production\nof digital assets, the circulation of digital assets, the transac-\ntion of digital assets, and the supervision of digital assets. In\nthe management processes of digital assets, the federalization\nof digital assets [ 51] helps ensure their security, reliability,\nand privacy [ 52]. In addition, the effective management and\nutilization of digital assets are of great signiﬁcance to the\nself-learning and evolution of IFMs, helping them to further\nbecome the core competence of enterprises.\nEnterprise resources are the basic resources used to produce\ngoods and services, such as land, labor, capital, and so on,\nwhich are essential to both traditional and intelligent indus-\ntries. Close monitoring of the inventory of raw materials and\nproducts is essential to the company’s capital chain and market\npotential. Physical and mental labor will always be a neces-\nsity for industrial production. Intelligent equipment is capable\nof efﬁciently completing production tasks. Enough physical\nand cyberspace to ensure the continuous growth of enterprises.\nBy allocating capital reasonably, companies can make up for\ntheir shortcomings and develop more effectively. Energy and\necology are the two main constraints faced by industrial pro-\nduction in recent years. The implementation of new intelligent\ntechnologies and the allocations of energy and ecology indi-\ncators can help reduce the waste of energy and ecological\nresources in production processes, making them more efﬁ-\ncient and maximizing their effectiveness. Overall, with the\nhelp of IFMs, production management is able to go further\nthan robotic process automation (RPA) and achieves digital\nprocess intelligence (DPI) [ 53].\nThe platform I/O are necessary components to maintain the\nhealthy operation of the enterprise, including human resources\nto update the labor, supply chain [ 54], [ 55], [ 56] to update\nthe materials and products, and business agreements to update\nthe enterprise strategy and development plan. I/O of human\nresources, supply chain, and commercial agreements refer to\nthe onboarding and offboarding of employees, the procurement\nof raw materials and consumption of products, and the coop-\neration and termination of agreements, respectively. The IFMs\nare expandable, and they can connect and interact with each\nother. Therefore, cooperation and communication with various\nenterprises, government departments, and other entities can be\naccomplished with the help of IFMs. At the same time, all\nenterprises with IFMs can form a decentralized autonomous\norganization (DAO) [ 57], and various resources can ﬂow in\nthe organization autonomously and efﬁciently.\nIV . S\nUPPORTS FOR INDUSTRIAL FOUNDATION MODELS\nThe explosive emergence and development of all kinds of\nadvanced sciences and technologies have provided gradually\nrich and effective technical support for the implementation and\nrealization of IFMs.\n1) New Information Technology (Artiﬁcial Intelligence):\nArtiﬁcial intelligence [ 58], [ 59], [ 60], [ 61] is the core\nsupport for the IFMs. Whether vision foundation mod-\nels, language foundation models, or operation foundation\nmodels, they are all based on the new information\ntechnology, artiﬁcial intelligence [ 62].\n2) Knowledge Automation: Data-driven AI models con-\ntribute to industrial automation and intelligence, but lack\ninterpretability. However, data-driven models are not\nalways efﬁcient and applicable. For example, when deal-\ning with laws and theorems that seem very obvious and\nsimple to humans, data-driven models may require large\namounts of data and consume huge amounts of com-\nputing power. Knowledge automation [ 63] encompasses\nnot only the modeling of traditional rules [ 64], reason-\ning, and explicit representations but also the modeling of\ntacit knowledge, pattern recognition, group experience,\netc. [65], [66]. Building executable knowledge software\nsystems with the help of intelligent technology and soft-\nware technology can liberate knowledge workers from\nrepetitive tasks.\n3) Cognitive Sciences and Parallel Cognition: To a con-\nsiderable extent, cognitive science [ 67] and AI have\nthe same origin, being different statements and differ-\nent aspects of the same function and goal. Cognitive\nscience is the scientiﬁc study of the mind and its\nprocesses, speciﬁcally, the exploration of the nature,\ntasks, and functions of cognition in general. Parallel\ncognition circulates and integrates multidisciplinary and\ninterdisciplinary knowledge in the physical, mental, and\nartiﬁcial worlds, with three consciousnesses in three\nworlds facilitating the development of IFMs.\n4) Interface Technology: The ultimate purpose of IFMs is\nto serve biological humans, and the interaction technol-\nogy is the one that humans are closest to and have the\nmost contact with, which plays a key role in the experi-\nence of using IFMs. Human–computer interaction [68]i s\nthe focus of interaction technology, and the brain nerves\nare the most natural and effective means of human\ninteraction. The brain neural recognition technology has\nmade great strides in recent years, while text [ 69],\nspeech [70], [71], and visual [ 72], [73], [74], [75], [76],\n[77] recognition technologies are slowly becoming part\nof our daily lives. These interaction technologies provide\nthe necessary support for IFMs.\n5) Connection Technology: The advancement of high-\ncapacity, high-reliability, low-latency mobile commu-\nnication technologies [ 78], [ 79], such as 5G and 6G\nhas led to further development and application of tech-\nnologies, such as edge-cloud cooperation and edge\ncomputing [80\n], [81]. By communicating closely and in\nreal-time, simple computing based on local small models\nand complex computing based on remote large models\ncan be achieved. These supports are necessary for the\nlocal-cloud collaborative deployment of IFMs and their\ninteraction.\n6) Ecological Technology: Ecological technologies, such as\nDAO [82] and blockchain [ 83], [84], [85] maintain the\nsecure [86] and smart operation of the IFMs by building\nan intelligent ecosystem of enterprises. Related enter-\nprises linked together through DAO and blockchain can\ninteract and share resources safely and securely. At the\nW ANG et al.: FRAMEWORK AND OPERATIONAL PROCEDURES FOR META VERSES-BASED IFMs 2043\nFig. 5. Vision foundation models in parallel manufacturing: a case study\non intelligent clothing manufacturer (all images are generated by vision\nfoundation models).\nsame time, members of the organization can participate\nin the rule-making and governance of the organization\nto achieve optimal development of the enterprise itself\nas well as self-management and autonomous evolution\nof the organization.\nV. C\nASE STUDIES\nIn this section, we apply the IFMs to the oil ﬁeld, manufac-\nturing, and automatic optical inspection (AOI) industries, and\npropose parallel oil ﬁeld, parallel manufacturing, and parallel\nAOI, respectively.\nA. Parallel Manufacturing\nAs the most common component of industries, manufactur-\ning is the main engine of economic growth. With human and\nsocial factors being introduced into manufacturing systems,\nwhich are characterized by uncertainty, diversity, and complex-\nity, the current manufacturing systems are facing some issues:\nexcessive human interventions, lack of ﬂexibility, inability\nto achieve on-demand production, and inefﬁcient human-\ncomputer interaction. As a new paradigm in smart manufac-\nturing, parallel manufacturing provides a feasible solution for\ntackling those problems, which is comprised of cyber systems\nfor product life-cycle management, physical systems for totally\nintegrated automation, and social systems for manufactur-\ning intelligence. Various manufacturing resources, including\nmaterials, equipment, robots, and humans are integrated and\ncoordinated through Industrial Internet and Industrial Internet\nof Things (IoT) [ 87], where the knowledge automation tech-\nnology is embedded to form industrial Internet of Minds\n(IoM).\nDigital humans and robotic humans accomplish the majority\nof manufacturing tasks in cooperative manners, whereas bio-\nlogical humans focus more on creative and global tasks with\nthe help of vision foundation models in IFM, as illustrated\nin Fig. 5. Vision foundation models can design products and\nbuild production processes and blueprints of enterprise based\non social needs, at the same time, the models can deliver\nFig. 6. Language foundation models in parallel oil ﬁelds: a case study on\ndynamometer cards of pumping units.\nthem more effectively to digital humans and other foundation\nmodels for efﬁcient production.\nB. Parallel Oil Fields\nWith the development and needs of human production and\nlife, the traditional technologies for oil ﬁelds have also under-\ngone a transformation. Based on Industry 4.0, many experts\nand scholars have proposed the concept of smart/intelligent oil\nﬁelds (IOFs) based on digital oil ﬁelds (DOFs), which aims to\nincrease oil production and acquire more economic or political\nbeneﬁts.\nHowever, the proposal of IOFs is based on the traditional\ncyber–physical systems (CPSs), which does not fully consider\nthe role of social systems [ 88] where the biological human\nis located and has certain limitations. Therefore, we applied\nIndustry 5.0 and the IFMs in CPSS to the oil ﬁelds to produce\na new model of oil ﬁeld production and operation: the parallel\noil ﬁelds. As shown in Fig. 6, the role of language foundation\nmodels in IFM is highlighted in the coordination and manage-\nment of tasks, such as production calculation and scheduling,\nand equipment monitoring and maintenance in parallel oil\nﬁelds. Dynamometer cards are the most important parame-\nter schematic in parallel oil ﬁelds. Based on the dynamometer\ncards, the language foundations models can not only obtain\ninformation on the operation status of the pumping unit and\nfurther issue and arrange maintenance work, but also realize\nthe scheduling and control of production by setting the target\ndynamometer cards of the pumping units.\nC. Parallel AOI\nDefect detection is an important part of the industrial pro-\nduction process, used to identify product quality and provide\nguidance for subsequent repair. LCD panels, IC carrier boards,\nprecision PCBs, etc., have high production costs and strict\nrequirements for quality, and defects in the production pro-\ncess can easily lead to the scrapping of the ﬁnal product or\n2044 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS: SYSTEMS, VOL. 53, NO. 4, APRIL 2023\nFig. 7. Operational foundation models in parallel AOI: a case study on defect\ndetection of PCB.\ncause hidden dangers to the use of the product. Therefore,\ndefect detection for these products is particularly important.\nEarly defect detection is completely manual sorting. With the\ndevelopment of computer vision and automation equipment,\nAOI equipment greatly reduces the burden of manual inspec-\ntion, while improving the efﬁciency and stability of detection.\nHowever, in the actual PCB defect detection, in order to\nachieve higher detection accuracy, it is still necessary to manu-\nally double-check the PCB after the automatic defect detection\nequipment.\nThis reinspection process currently requires a lot of labor\ncosts and gradually becomes a bottleneck in PCB production.\nOn the one hand, workers need a lot of professional knowledge\nand practical experience to make a correct judgment on the\ntype and severity of defects. On the other hand, the accuracy\nand efﬁciency of manual restoration are very low and cannot\nmeet the needs of modern production.\nAs shown in Fig. 7 robotic and digital workers managed\nby operational foundation models in IFM assist biological\nworkers to complete the reinspection operation can effectively\nimprove efﬁciency and reduce work difﬁculty. Equip each\nbiological worker with exclusive digital workers to achieve\nan understanding of defect information and restoration opera-\ntions simultaneously through data and knowledge. The defect\ndetection and repair work in the physical world is performed\nby robotic workers, and only in rare cases does a biological\nhuman intervention become necessary. In this process, IFM\ncoordinates and manages the various resources of the enter-\nprise, monitoring, and scheduling the work of robotic and\ndigital humans [ 89], while making communication between\nthem and biological humans more efﬁcient.\nVI. C\nONCLUSION\nWith the purpose of effective and efﬁcient management\nand control of industrial processes, the framework and oper-\nating procedures of IFMs are proposed in this article to\nschedule various resources and achieve natural interactions,\nwhich lay the foundation for the sustainable development\nof enterprises. Speciﬁcally, three-level foundation models are\nconstructed to achieve smart task comprehension, speciﬁca-\ntion, and planning in the industrial processes involving both\nhumans and machines, so as to form a new type of operat-\ning system for the parallel machines in CPSS. Three typical\napplications, including clothing manufacturing, oil exploita-\ntion, and optical inspection, are elaborated to explore the\npotential of the potential IFM. IFM can drive enterprise man-\nagement to achieve cognitive intelligence, parallel intelligence,\ncrypto intelligence, federated intelligence, social intelligence,\nand ecological intelligence for realizing “6S” goals of enter-\nprises, which are safety, security, sustainability, sensitivity,\nservice, and smartness.\nA\nCKNOWLEDGMENT\nThe authors would like to extend the sincere gratitude to\nDr. Juanjuan Li for her useful help to this article.\nREFERENCES\n[1] F.-Y . Wang, “Parallel management: The DAO to smart ecological\ntechnology for complexity management intelligence,” Acta Automatica\nSinica, vol. 48, no. 11, pp. 2655–2669, 2022.\n[2] Q. Yang, Y . Zhao, H. Huang, Z. Xiong, J. Kang, and Z. Zheng, “Fusing\nblockchain and AI with metaverse: A survey,” IEEE Open J. Comput.\nSoc., vol. 3, pp. 122–136, 2022.\n[3] F.-Y . Wang, “MetaVehicles in the metaverse: Moving to a new phase for\nintelligent vehicles and smart mobility,” IEEE Trans. Intell. Veh.,v o l .7 ,\nno. 1, pp. 1–5, Mar. 2022.\n[4] F.-Y . Wang, R. Qin, X. Wang, and B. Hu, “MetaSocieties in meta-\nverse: metaeconomics and metamanagement for metaenterprises and\nmetacities,” IEEE Trans. Computat. Social Syst. , vol. 9, no. 1, pp. 2–7,\nFeb. 2022.\n[5] F.-Y . Wang, “The emergence of intelligent enterprises: From CPS to\nCPSS,” IEEE Intell. Syst. , vol. 25, no. 4, pp. 85–88, Jul./Aug. 2010.\n[6] X. Li, P. Ye, J. Li, Z. Liu, L. Cao, and F.-Y . Wang, “From features\nengineering to scenarios engineering for trustworthy AI: I&i, C&C, and\nV&V ,”IEEE Intell. Syst. , vol. 37, no. 4, pp. 18–26, Jul./Aug. 2022.\n[7] R. Bommasani et al., “On the opportunities and risks of foundation\nmodels,” 2021, arXiv:2108.07258.\n[8] A. Vaswani et al., “Attention is all you need,” in Proc. Int. Conf. Adv.\nNeural Inf. Process. Syst. , vol. 30, 2017, pp. 6000–6010.\n[9] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training\nof deep bidirectional transformers for language understanding,” 2018,\narXiv:1810.04805.\n[10] L. Dong et al., “Uniﬁed language model pre-training for natural lan-\nguage understanding and generation,” in Proc. Int. Conf. Adv. Neural\nInf. Process. Syst. , vol. 32, 2019, pp. 13063–13075.\n[11] A. Conneau and G. Lample, “Cross-lingual language model pretrain-\ning,” in Proc. Int. Conf. Adv. Neural Inf. Process. Syst. , vol. 32, 2019,\npp. 7059–7069.\n[12] K. Clark, M.-T. Luong, Q. V . Le, and C. D. Manning, “ELECTRA: Pre-\ntraining text encoders as discriminators rather than generators,” 2020,\narXiv:2003.10555.\n[13] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever. “Improving\nlanguage understanding by generative pre-training.” 2018. [Online].\nAvailable: https://s3-us-west-2.amazonaws.com/openai-assets/research-\ncovers/language-unsupervised/language_understanding_paper.pdf\n[14] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,\n“Language models are unsupervised multitask learners,” OpenAI Blog,\nvol. 1, no. 8, p. 9, 2019.\n[15] T. Brown et al., “Language models are few-shot learners,” in Proc. Int.\nConf. Adv. Neural Inf. Process. Syst. , vol. 33, 2020, pp. 1877–1901.\n[16] M. E. Peters et al., “Deep contextualized word representations,” in Proc.\nConf. North Amer. Ch. Assoc. Comput. Linguist. Human Lang. Technol.\nVol. 1 (Long Papers), 2018, pp. 2227–2237.\n[17] Z. Zhang et al., “CPM: A large-scale generative chinese pre-trained\nlanguage model,” AI Open, vol. 2, pp. 93–99, Jan. 2021.\n[18] Z. Yang, Z. Dai, Y . Yang, J. Carbonell, R. R. Salakhutdinov, and\nQ. V . Le, “XLNET: Generalized autoregressive pretraining for lan-\nguage understanding,” in Proc. Int. Conf. Adv. Neural Inf. Process. Syst.,\nvol. 32, 2019, p. 517.\nW ANG et al.: FRAMEWORK AND OPERATIONAL PROCEDURES FOR META VERSES-BASED IFMs 2045\n[19] C. Raffel et al., “Exploring the limits of transfer learning with a uniﬁed\ntext-to-text transformer,” J. Mach. Learn. Res. , vol. 21, no. 1, pp. 1–67,\n2020.\n[20] W. Fedus, B. Zoph, and N. Shazeer, “Switch transformers: Scaling to\ntrillion parameter models with simple and efﬁcient sparsity,” J. Mach.\nLearn. Res., vol. 23, no. 120, pp. 1–39, 2022.\n[21] M. Lewis et al., “BART: Denoising sequence-to-sequence pre-\ntraining for natural language generation, translation, and comprehen-\nsion,” in Proc. 58th Annu. Meeting Assoc. Comput. Linguist. , 2020,\npp. 7871–7880.\n[22] A. Dosovitskiy et al., “An image is worth 16 ×16 words: Transformers\nfor image recognition at scale,” in Proc. Int. Conf. Learn. Represent. ,\n2020, pp. 1–21.\n[23] N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov, and\nS. Zagoruyko, “End-to-end object detection with transformers,” in Proc.\nEur. Conf. Comput. Vis., 2020, pp. 213–229.\n[24] C. Riquelme et al., “Scaling vision with sparse mixture of experts,”\nin Proc. Int. Conf. Adv. Neural Inf. Process. Syst. , vol. 34, 2021,\npp. 8583–8595.\n[25] Z. Liu et al., “Swin transformer v2: Scaling up capacity and resolu-\ntion,” in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. , 2022,\npp. 12009–12019.\n[26] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “ImageNet:\nA large-scale hierarchical image database,” in Proc. IEEE Conf. Comput.\nVis. Pattern Recognit., 2009, pp. 248–255.\n[27] X. Zhai, A. Kolesnikov, N. Houlsby, and L. Beyer, “Scaling vision\ntransformers,” in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.,\n2022, pp. 12104–12113.\n[28] A. Dosovitskiy, J. T. Springenberg, M. Riedmiller, and T. Brox,\n“Discriminative unsupervised feature learning with convolutional neural\nnetworks,” in Proc. Int. Conf. Adv. Neural Inf. Process. Syst. , vol. 27,\n2014, pp. 766–774.\n[29] R. D. Hjelm et al., “Learning deep representations by mutual information\nestimation and maximization,” 2018, arXiv:1808.06670.\n[30] K. He, H. Fan, Y . Wu, S. Xie, and R. Girshick, “Momentum contrast for\nunsupervised visual representation learning,” in Proc. IEEE/CVF Conf.\nComput. Vis. Pattern Recognit. , 2020, pp. 9729–9738.\n[31] M. Caron, P. Bojanowski, A. Joulin, and M. Douze, “Deep clustering for\nunsupervised learning of visual features,” in Proc. Eur. Conf. Comput.\nVis. (ECCV), 2018, pp. 132–149.\n[32] W. Van Gansbeke, S. Vandenhende, S. Georgoulis, M. Proesmans, and\nL. Van Gool, “SCAN: Learning to classify images without labels,” in\nProc. Eur. Conf. Comput. Vis. , 2020, pp. 268–285.\n[33] H. Bao, L. Dong, S. Piao, and F. Wei, “BEiT: BERT pre-training of\nimage transformers,” 2021, arXiv:2106.08254.\n[34] K. He, X. Chen, S. Xie, Y . Li, P. Dollár, and R. Girshick, “Masked\nautoencoders are scalable vision learners,” in Proc. IEEE/CVF Conf.\nComput. Vis. Pattern Recognit. , 2022, pp. 16000–16009.\n[35] A. Ramesh et al., “Zero-shot text-to-image generation,” in Proc. Int.\nConf. Mach. Learn. , 2021, pp. 8821–8831.\n[36] U. Singer et al., “Make-a-video: Text-to-video generation without text-\nvideo data,” 2022, arXiv:2209.14792.\n[37] B. Poole, A. Jain, J. T. Barron, and B. Mildenhall, “DreamFusion: Text-\nto-3D using 2D diffusion,” 2022, arXiv:2209.14988.\n[38] C. Wu et al., “NÜW A: Visual synthesis pre-training for neural visual\nworld creation,” 2021, arXiv:2111.12417.\n[39] Z. Gan, Y .-C. Chen, L. Li, C. Zhu, Y . Cheng, and J. Liu, “Large-scale\nadversarial training for vision-and-language representation learning,”\nin Proc. Int. Conf. Adv. Neural Inf. Process. Syst. , vol. 33, 2020,\npp. 6616–6628.\n[40] F. Yu et al., “ERNIE-ViL: Knowledge enhanced vision-language rep-\nresentations through scene graphs,” in Proc. AAAI Conf. Artif. Intell. ,\nvol. 35, 2021, pp. 3208–3216.\n[41] Y . Tian et al., “Metaverse-based parallel machines in CPSS: From\ninformation technology to intelligent technology,” Int. J. Intell. Control\nSyst., vol. 1, no. 4, pp. 6–10, 2021.\n[42] P. Chu, J. A. Zhang, X. Wang, G. Fang, and D. Wang, “Semi-\npersistent resource allocation based on trafﬁc prediction for vehicular\ncommunications,” IEEE Trans. Intell. Veh. , vol. 5, no. 2, pp. 345–355,\nJun. 2020.\n[43] S. Wang et al., “Robotic intra-operative ultrasound: Virtual environments\nand parallel systems,” IEEE/CAA J. Automatica Sinica , vol. 8, no. 5,\npp. 1095–1106, May 2021.\n[44] Z. Yuan, H. Li, J. Liu, and J. Luo, “Multiview scene image inpaint-\ning based on conditional generative adversarial networks,” IEEE Trans.\nIntell. Veh., vol. 5, no. 2, pp. 314–323, Jun. 2020.\n[45] J. Wang et al., “Parallel vision for long-tail Regularization: Initial results\nfrom IVFC autonomous driving testing,” IEEE Trans. Intell. Veh.,v o l .7 ,\nno. 2, pp. 286–299, Jun. 2022.\n[46] J. Wang et al., “A parallel teacher for synthetic-to-real domain adapta-\ntion of trafﬁc object detection,” IEEE Trans. Intell. Veh. , vol. 7, no. 3,\npp. 441–455, Sep. 2022.\n[47] M. E. Kabir, I. Sorkhoh, B. Moussa, and C. Assi, “Joint routing and\nscheduling of mobile charging infrastructure for V2V energy transfer,”\nIEEE Trans. Intell. Veh., vol. 6, no. 4, pp. 736–746, Dec. 2021.\n[48] S. Mao et al., “A ﬁnite-time distributed optimization algorithm for eco-\nnomic dispatch in smart grids,” IEEE Trans. Syst., Man, Cybern., Syst. ,\nvol. 51, no. 4, pp. 2068–2079, Apr. 2021.\n[49] Y . Du, L. Wang, L. Xing, J. Yan, and M. Cai, “Data-driven heuristic\nassisted memetic algorithm for efﬁcient inter-satellite link scheduling\nin the BeiDou navigation satellite system,” IEEE/CAA J. Automatica\nSinica, vol. 8, no. 11, pp. 1800–1816, Nov. 2021.\n[50] Y .-H. Jia et al., “An intelligent cloud workﬂow scheduling system with\ntime estimation and adaptive ant colony optimization,”IEEE Trans. Syst.,\nMan, Cybern., Syst. , vol. 51, no. 1, pp. 634–649, Jan. 2021.\n[51] Y . Tian, J. Wang, Y . Wang, C. Zhao, F. Yao, and X. Wang, “Federated\nvehicular transformers and their federations: Privacy-preserving comput-\ning and cooperation for autonomous driving,” IEEE Trans. Intell. Veh. ,\nvol. 7, no. 3, pp. 456–465, Sep. 2022.\n[52] D. Yi et al., “Implicit Personalization in driving assistance: State-of-the-\nart and open issues,” IEEE Trans. Intell. Veh., vol. 5, no. 3, pp. 397–413,\nSep. 2020.\n[53] J. Wang et al., “Digital workers in industrial metaverses: From robotic\nprocess automation to digital process intelligence,” J. Intell. Sci.\nTechnol., vol. 2, no. 2, pp. 7–11, 2022.\n[54] C.-K. Chen, M. A. ’Ulya, and U. A. Mancasari, “A study of product\nquality and marketing efforts in closed-loop supply chains with reman-\nufacturing,” IEEE Trans. Syst., Man, Cybern., Syst. , vol. 50, no. 12,\npp. 4870–4881, Dec. 2020.\n[55] S.-M. Hosseini-Motlagh, M. Nematollahi, M. Johari, and T.-M. Choi,\n“Reverse supply chain systems coordination across multiple links with\nduopolistic third party collectors,” IEEE Trans. Syst., Man, Cybern.,\nSyst., vol. 50, no. 12, pp. 4882–4893, Dec. 2020.\n[56] D. Fu, H.-T. Zhang, A. Dutta, and G. Chen, “A cooperative distributed\nmodel predictive control approach to supply chain management,” IEEE\nTrans. Syst., Man, Cybern., Syst. , vol. 50, no. 12, pp. 4894–4904,\nDec. 2020.\n[57] C. Zhao, Y . Lv, J. Jin, Y . Tian, J. Wang, and F.-Y . Wang, “DeCAST\nin TransVerse for parallel intelligent transportation systems and smart\ncities: Three decades and beyond,” IEEE Intell. Transp. Syst. Mag. ,\nvol. 14, no. 6, pp. 6–17, Nov./Dec. 2022.\n[58] M. Morsali, E. Frisk, and J. Åslund, “Spatio-temporal planning in\nmulti-vehicle scenarios for autonomous vehicle using support vec-\ntor machines,” IEEE Trans. Intell. Veh. , vol. 6, no. 4, pp. 611–621,\nDec. 2021.\n[59] X. Pang, Y . Xu, and X. Xiao, “A doubly sparse multiclass support vector\nmachine with simultaneous feature and sample screening,” IEEE Trans.\nSyst., Man, Cybern., Syst. , vol. 51, no. 11, pp. 6911–6925, Nov. 2021.\n[60] Y . Liu, S. Cao, P. Lasang, and S. Shen, “Modular lightweight network\nfor road object detection using a feature fusion approach,” IEEE Trans.\nSyst., Man, Cybern., Syst. , vol. 51, no. 8, pp. 4716–4728, Aug. 2021.\n[61] L. Xiao, J. Dai, L. Jin, W. Li, S. Li, and J. Hou, “A noise-enduring and\nﬁnite-time zeroing neural network for equality-constrained time-varying\nnonlinear optimization,” IEEE Trans. Syst., Man, Cybern., Syst., vol. 51,\nno. 8, pp. 4729–4740, Aug. 2021.\n[62] J. Chen et al., “E-LSTM-D: A deep learning framework for dynamic\nnetwork link prediction,” IEEE Trans. Syst., Man, Cybern., Syst., vol. 51,\nno. 6, pp. 3699–3712, Jun. 2021.\n[63] F.-Y . Wang, “The DAO to metacontrol for metasystems in metaverses:\nThe system of parallel control systems for knowledge automation and\ncontrol intelligence in CPSS,” IEEE/CAA J. Automatica Sinica ,v o l .9 ,\nno. 11, pp. 1899–1908, Nov. 2022.\n[64] Z. Feng, W. He, Z. Zhou, X. Ban, C. Hu, and X. Han, “A new safety\nassessment method based on belief rule base with attribute reliabil-\nity,” IEEE/CAA J. Automatica Sinica , vol. 8, no. 11, pp. 1774–1785,\nNov. 2021.\n[65] H. Han, Z. Liu, H. Liu, and J. Qiao, “Knowledge-data-driven model\npredictive control for a class of nonlinear systems,” IEEE Trans. Syst.,\nMan, Cybern., Syst. , vol. 51, no. 7, pp. 4492–4504, Jul. 2021.\n[66] Z.-J. Zhou, G.-Y . Hu, C.-H. Hu, C.-L. Wen, and L.-L. Chang, “A survey\nof belief rule-base expert system,” IEEE Trans. Syst., Man, Cybern.,\nSyst., vol. 51, no. 8, pp. 4944–4958, Aug. 2021.\n2046 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS: SYSTEMS, VOL. 53, NO. 4, APRIL 2023\n[67] Y . Shi, Y . Mi, J. Li, and W. Liu, “Concept-cognitive learning model for\nincremental concept learning,” IEEE Trans. Syst., Man, Cybern., Syst. ,\nvol. 51, no. 2, pp. 809–821, Feb. 2021.\n[68] D. Xiong, D. Zhang, X. Zhao, and Y . Zhao, “Deep learning for EMG-\nbased human-machine interaction: A review,” IEEE/CAA J. Automatica\nSinica, vol. 8, no. 3, pp. 512–533, Mar. 2021.\n[69] X. S. Lu, M. Zhou, and K. Wu, “A novel fuzzy logic-based text classi-\nﬁcation method for tracking rare events on Twitter,” IEEE Trans. Syst.,\nMan, Cybern., Syst. , vol. 51, no. 7, pp. 4324–4333, Jul. 2021.\n[70] P. Liu, Y . Zhou, D. Peng, and D. Wu, “Global-attention-based neural\nnetworks for vision language intelligence,” IEEE/CAA J. Automatica\nSinica, vol. 8, no. 7, pp. 1243–1252, Jul. 2021.\n[71] S. Wen et al., “Memristive LSTM network for sentiment analysis,”\nIEEE Trans. Syst., Man, Cybern., Syst. , vol. 51, no. 3, pp. 1794–1804,\nMar. 2021.\n[72] C. Zhu, J. Yang, Z. Shao, and C. Liu, “Vision based hand gesture recog-\nnition using 3D shape context,” IEEE/CAA J. Automatica Sinica,v o l .8 ,\nno. 9, pp. 1600–1613, Sep. 2021.\n[73] P. Cai, Y . Sun, H. Wang, and M. Liu, “VTGNet: A vision-based\ntrajectory generation network for autonomous vehicles in urban environ-\nments,” IEEE Trans. Intell. Veh., vol. 6, no. 3, pp. 419–429, Sep. 2021.\n[74] A. K. Bhandari, A. Singh, and I. V . Kumar, “Spatial context energy\ncurve-based multilevel 3-D Otsu algorithm for image segmentation,”\nIEEE Trans. Syst., Man, Cybern., Syst. , vol. 51, no. 5, pp. 2760–2773,\nMay 2021.\n[75] T. Zhang, J. Xiao, L. Li, C. Wang, and G. Xie, “Toward coordination\ncontrol of multiple ﬁsh-like robots: Real-time vision-based pose estima-\ntion and tracking via deep neural networks,” IEEE/CAA J. Automatica\nSinica, vol. 8, no. 12, pp. 1964–1976, Dec. 2021.\n[76] M. Wu, W. Su, L. Chen, Z. Liu, W. Cao, and K. Hirota, “Weight-adapted\nconvolution neural network for facial expression recognition in human–\nrobot interaction,” IEEE Trans. Syst., Man, Cybern., Syst., vol. 51, no. 3,\npp. 1473–1484, Mar. 2021.\n[77] X. Liang, D. Zhang, G. Lu, Z. Guo, and N. Luo, “A novel multicamera\nsystem for high-speed touchless palm recognition,” IEEE Trans. Syst.,\nMan, Cybern., Syst. , vol. 51, no. 3, pp. 1534–1548, Mar. 2021.\n[78] P. Watta, X. Zhang, and Y . L. Murphey, “Vehicle position and context\ndetection using V2V communication,” IEEE Trans. Intell. Veh. ,v o l .6 ,\nno. 4, pp. 634–648, Dec. 2021.\n[79] P. Sewalkar and J. Seitz, “MC-COCO4V2P: Multi-channel clustering-\nbased congestion control for vehicle-to-pedestrian communication,”\nIEEE Trans. Intell. Veh., vol. 6, no. 3, pp. 523–532, Sep. 2021.\n[80] M. Han, A. Wan, F. Zhang, and S. Ma, “An attribute-isolated secure\ncommunication architecture for intelligent connected vehicles,” IEEE\nTrans. Intell. Veh., vol. 5, no. 4, pp. 545–555, Dec. 2020.\n[81] M. Hasan, S. Mohan, T. Shimizu, and H. Lu, “Securing vehicle-to-\neverything (V2X) communication platforms,” IEEE Trans. Intell. Veh. ,\nvol. 5, no. 4, pp. 693–713, Dec. 2020.\n[82] H. Lu, Y . Tang, and Y . Sun, “DRRS-BC: Decentralized routing regis-\ntration system based on blockchain,” IEEE/CAA J. Automatica Sinica ,\nvol. 8, no. 12, pp. 1868–1876, Dec. 2021.\n[83] D. Xu, W. Shi, W. Zhai, and Z. Tian, “Multi-candidate voting model\nbased on blockchain,” IEEE/CAA J. Automatica Sinica , vol. 8, no. 12,\npp. 1891–1900, Dec. 2021.\n[84] S. Dustdar, P. Fernández, J. M. García, and A. Ruiz-Cortés, “Elastic\nsmart contracts in blockchains,” IEEE/CAA J. Automatica Sinica,v o l .8 ,\nno. 12, pp. 1901–1912, Dec. 2021.\n[85] S. K. Dwivedi, R. Amin, and S. V ollala, “Blockchain-based secured\nIPFS-enable event storage technique with authentication protocol\nin V ANET,” IEEE/CAA J. Automatica Sinica , vol. 8, no. 12,\npp. 1913–1922, Dec. 2021.\n[86] Y . Lin et al., “Dynamic control of fraud information spreading in mobile\nsocial networks,” IEEE Trans. Syst., Man, Cybern., Syst. , vol. 51, no. 6,\npp. 3725–3738, Jun. 2021.\n[87] L. D. Xu, W. He, and S. Li, “Internet of Things in industries: A survey,”\nIEEE Trans. Ind. Informat.\n, vol. 10, no. 4, pp. 2233–2243, Nov. 2014.\n[88] M. Xu et al., “Crowd behavior simulation with emotional contagion in\nunexpected multihazard situations,” IEEE Trans. Syst., Man, Cybern.,\nSyst., vol. 51, no. 3, pp. 1567–1581, Mar. 2021.\n[89] Y . Wang and X. Zuo, “An effective cloud workﬂow scheduling approach\ncombining PSO and idle time slot-aware rules,”IEEE/CAA J. Automatica\nSinica, vol. 8, no. 5, pp. 1079–1094, May 2021.\nJiangong Wang (Student Member, IEEE) received the Bachelor of\nEngineering degree in electronic information and engineering from Tongji\nUniversity, Shanghai, China, in 2018. He is currently pursuing the Ph.D.\ndegree in pattern recognition and intelligent systems with the Institute of\nAutomation, Chinese Academy of Sciences, Beijing, China, and the University\nof Chinese Academy of Sciences, Beijing.\nHis research interests include parallel vision, unsupervised learning, trafﬁc\nscene understanding, and medical image processing.\nYonglin Tian (Member, IEEE) received the Ph.D. degree in control science\nand engineering from the University of Science and Technology of China,\nHefei, China, in 2022.\nHe is currently a Postdoctoral Researcher with the Institute of Automation,\nChinese Academy of Sciences, Beijing, China, and the Executive Director of\nthe Parallel Intelligence Innovation Research Center, Qingdao Academy of\nIntelligent Industries, Qingdao, China. His research interests include computer\nvision and intelligent transportation systems.\nYutong Wang (Member, IEEE) received the Ph.D. degree in control theory\nand control engineering from the University of Chinese Academy of Sciences,\nBeijing, China, in 2021.\nAfter that, she joined the Institute of Automation, Chinese Academy\nof Sciences, Beijing, and became an Assistant Professor with the State\nKey Laboratory for Management and Control of Complex Systems, and\nthe Assistant President of the Qingdao Academy of Intelligent Industries,\nQingdao, China. Her research interests include computer vision and adversar-\nial attacks.\nJing Yang received the bachelor’s degree in automation from the Beijing\nUniversity of Chemical Technology, Beijing, China, in 2020. She is currently\npursuing the Ph.D. degree in automation with the Institute of Automation,\nChinese Academy of Sciences, Beijing, and the University of Chinese\nAcademy of Sciences, Beijing.\nHer research interests include parallel manufacturing, social manufacturing,\ncyber–physical–social systems, and artiﬁcial intelligence.\nXingxia Wang (Student Member, IEEE) received the master’s degree in con-\ntrol theory and control engineering from Nankai University, Tianjin, China,\nin 2021. She is currently pursuing the Ph.D. degree in pattern recognition\nand intelligent system with the Institute of Automation, Chinese Academy of\nSciences, Beijing, China, and the University of Chinese Academy of Sciences,\nBeijing.\nHer research interests include parallel oilﬁelds, artiﬁcial intelligence, and\nfault diagnosis of complex industrial processes.\nSanjin Wang is a Principal Investigator with North Automatic Control\nTechnology Institute, China North Industries North Automatic Control\nTechnology Research Institute, Taiyuan, China. His research interests include\nparallel intelligence and parallel control.\nOliver Kwan received the master’s degree in industrial management from the\nUniversity of Arizona, Tucson, AZ, USA, in 1993.\nHe is currently the Founder and a CEO of Motion G, Inc., Shenzhen, China.\nHe also works on industrial applications of digital twins, foundation mod-\nels, and intelligent control. His research focuses on the relationships between\nstatistics, inference, and knowledge transfer.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6116799116134644
    },
    {
      "name": "Cyber-physical system",
      "score": 0.4802580177783966
    },
    {
      "name": "Scheduling (production processes)",
      "score": 0.4559723138809204
    },
    {
      "name": "Foundation (evidence)",
      "score": 0.42738670110702515
    },
    {
      "name": "Knowledge management",
      "score": 0.33956602215766907
    },
    {
      "name": "Engineering",
      "score": 0.2800024747848511
    },
    {
      "name": "Operations management",
      "score": 0.11493754386901855
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    }
  ]
}