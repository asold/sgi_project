{
  "title": "BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models",
  "url": "https://openalex.org/W4385570599",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2336628527",
      "name": "Shibo Hao",
      "affiliations": [
        "UC San Diego Health System"
      ]
    },
    {
      "id": "https://openalex.org/A2533527777",
      "name": "Bowen Tan",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A2312011797",
      "name": "Kai-Wen Tang",
      "affiliations": [
        "UC San Diego Health System"
      ]
    },
    {
      "id": "https://openalex.org/A2095873270",
      "name": "Bin Ni",
      "affiliations": [
        "UC San Diego Health System"
      ]
    },
    {
      "id": "https://openalex.org/A5063281020",
      "name": "Xiyan Shao",
      "affiliations": [
        "UC San Diego Health System"
      ]
    },
    {
      "id": "https://openalex.org/A3016447353",
      "name": "Hengzhe Zhang",
      "affiliations": [
        "UC San Diego Health System"
      ]
    },
    {
      "id": "https://openalex.org/A3168967200",
      "name": "Eric Xing",
      "affiliations": [
        "Carnegie Mellon University",
        "Mohamed bin Zayed University of Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2156033562",
      "name": "Zhiting Hu",
      "affiliations": [
        "UC San Diego Health System"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3216037316",
    "https://openalex.org/W2999524812",
    "https://openalex.org/W2561529111",
    "https://openalex.org/W2251913848",
    "https://openalex.org/W3102049052",
    "https://openalex.org/W3167136668",
    "https://openalex.org/W2998557616",
    "https://openalex.org/W4286903575",
    "https://openalex.org/W4285255684",
    "https://openalex.org/W3155001903",
    "https://openalex.org/W4389520747",
    "https://openalex.org/W3202712981",
    "https://openalex.org/W3166846774",
    "https://openalex.org/W3167906655",
    "https://openalex.org/W4210706440",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2970161131",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3166986030",
    "https://openalex.org/W2935052563",
    "https://openalex.org/W2038721957",
    "https://openalex.org/W2912351665",
    "https://openalex.org/W4287660741",
    "https://openalex.org/W2972167903",
    "https://openalex.org/W2986213397",
    "https://openalex.org/W2903721568",
    "https://openalex.org/W3012590175",
    "https://openalex.org/W2604165577",
    "https://openalex.org/W3194243418",
    "https://openalex.org/W4394672037",
    "https://openalex.org/W2963101081",
    "https://openalex.org/W4206118214",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W2963687836",
    "https://openalex.org/W3207166518",
    "https://openalex.org/W3152979241",
    "https://openalex.org/W2127795553",
    "https://openalex.org/W4307407665",
    "https://openalex.org/W4285258797",
    "https://openalex.org/W2509019445",
    "https://openalex.org/W3034918576",
    "https://openalex.org/W4229038710",
    "https://openalex.org/W3107969673",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4223974161",
    "https://openalex.org/W4385572965"
  ],
  "abstract": "It is crucial to automatically construct knowledge graphs (KGs) of diverse new relations to support knowledge discovery and broad applications. Previous KG construction methods, based on either crowdsourcing or text mining, are often limited to a small predefined set of relations due to manual cost or restrictions in text corpus. Recent research proposed to use pretrained language models (LMs) as implicit knowledge bases that accept knowledge queries with prompts. Yet, the implicit knowledge lacks many desirable properties of a full-scale symbolic KG, such as easy access, navigation, editing, and quality assurance. In this paper, we propose a new approach of harvesting massive KGs of arbitrary relations from pretrained LMs. With minimal input of a relation definition (a prompt and a few shot of example entity pairs), the approach efficiently searches in the vast entity pair space to extract diverse accurate knowledge of the desired relation. We develop an effective search-and-rescore mechanism for improved efficiency and accuracy. We deploy the approach to harvest KGs of over 400 new relations, from LMs of varying capacities such as RoBERTaNet. Extensive human and automatic evaluations show our approach manages to extract diverse accurate knowledge, including tuples of complex relations (e.g., \"A is capable of but not good at B\"). The resulting KGs as a symbolic interpretation of the source LMs also reveal new insights into the LMs' knowledge capacities.",
  "full_text": "Findings of the Association for Computational Linguistics: ACL 2023, pages 5000–5015\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nBertNet: Harvesting Knowledge Graphs with Arbitrary Relations\nfrom Pretrained Language Models\nShibo Hao1∗, Bowen Tan 2∗, Kaiwen Tang 1∗, Bin Ni 1, Xiyan Shao 1,\nHengzhe Zhang1, Eric P. Xing 2,3, Zhiting Hu 1\n1UC San Diego, 2Carnegie Mellon University,\n3Mohamed bin Zayed University of Artificial Intelligence\n{s5hao,zhh019}@ucsd.edu, {btan2}@cs.cmu.edu\nAbstract\nIt is crucial to automatically construct knowl-\nedge graphs (KGs) of diverse new relations to\nsupport knowledge discovery and broad appli-\ncations. Previous KG construction methods,\nbased on either crowdsourcing or text mining,\nare often limited to a small predefined set of\nrelations due to manual cost or restrictions in\ntext corpus. Recent research proposed to use\npretrained language models (LMs) as implicit\nknowledge bases that accept knowledge queries\nwith prompts. Yet, the implicit knowledge\nlacks many desirable properties of a full-scale\nsymbolic KG, such as easy access, navigation,\nediting, and quality assurance. In this paper,\nwe propose a new approach of harvesting mas-\nsive KGs of arbitrary relations from pretrained\nLMs. With minimal input of a relation defini-\ntion (a prompt and a few shot of example entity\npairs), the approach efficiently searches in the\nvast entity pair space to extract diverse accurate\nknowledge of the desired relation. We develop\nan effective search-and-rescore mechanism for\nimproved efficiency and accuracy. We deploy\nthe approach to harvest KGs of over 400 new\nrelations from different LMs. Extensive human\nand automatic evaluations show our approach\nmanages to extract diverse accurate knowledge,\nincluding tuples of complex relations (e.g., \"A\nis capable of but not good at B\"). The\nresulting KGs as a symbolic interpretation of\nthe source LMs also reveal new insights into\nthe LMs’ knowledge capacities.\n1 Introduction\nSymbolic knowledge graphs (KGs) are a power-\nful tool for indexing rich knowledge about entities\nand their relationships, and are useful for informa-\ntion access (Google, 2012), decision making (Yang\net al., 2021; Santos et al., 2022), and improving\nmachine learning in general (Li et al., 2019; Wang\net al., 2019; Tan et al., 2020; Xiong et al., 2017).\n∗Equal contribution. Code available at https://github.\ncom/tanyuqian/knowledge-harvest-from-lms. Demo\navailable at https://lmnet.io\nText MiningAlbert Einstein, a German theoretical physicist, publishedthe theory of relativity in 1915. (Albert Einstein, publish, the theory of relativity)\n(bridge, UsedFor, cross water)(bowl, UsedFor, holdingpopcorn) (toothpaste, Usedfor,?) (freshen breath)\nKG Completion (COMET)\nA can doBbut not good atAneeds B to doC…Other arbitrary relations\n(frog, A can do Bbut not good at,swim)(war, Aneeds B to doC, violence, end war)…knowledge of arbitrary relations!\nBertNet(Ours)\nMechanical PipelinesNER, CR, RE... \nPrompting Finetuned LMs\nLMs trained with existing KG\nAutomatic Harvesting Framework\nBlack-box Language Models\nPrompt CreationEntityPairSearch\nFigure 1: Different example paradigms of harvesting knowl-\nedge. Text miningextracts knowledge of relations explicitly\nmentioned in the text. KG completionproduces tail entities\nto complete knowledge of preexisting relations. Our method\nis capable of harvesting knowledge of arbitrary new relations\nfrom LMs.\nIt has been a long-term desire to construct KGs\nof diverse relations to comprehensively character-\nize the structures between entities. The traditional\ncrowdsourcing-based approach (Speer et al., 2017;\nFellbaum, 2000; Sap et al., 2019) tends to cover\nonly a restricted relation set, such as ConceptNet\n(Speer et al., 2017) that contains a small set of 34\nrelations. The popular method based on text mining\n(Luan et al., 2019; Zhong and Chen, 2020; Wang\net al., 2021b) has a similar limitation, as the text\nunderstanding models can often recognize only a\npredefined set of relations included in training data.\nSome open-schema text mining approaches (e.g.,\nbased on syntactic patterns) exist (Tandon et al.,\n2014; Romero et al., 2019; Zhang et al., 2020b;\nNguyen et al., 2021), yet the extracted relations are\nlimited to those explicitly stated in the text, miss-\ning all others that are not mentioned or do not have\nexact match with the text in the corpus. Similarly,\nKG completion approaches (Bordes et al., 2013;\nBosselut et al., 2019; Yao et al., 2019) is restricted\n5000\nMethod Module(s) Outcome Arbitrary relation\nText mining (Zhang et al., 2020a; Nguyen et al., 2021) NER, CR, RE, etc. 1 KG ✗\nLAMA (Petroni et al., 2019), LPAQA (Jiang et al., 2020) LMs tail entity ✓\nCOMET (Bosselut et al., 2019) Finetuned GPT-2 tail entity ✗\nSymbolic Knowledge Distillation (West et al., 2022) GPT-3 KG ✓2\nBertNet (ours) LMs KG ✓\nTable 1: Categorization of works on automatic knowledge extraction. Compared to other categories of approaches, our method\nextracts full explicit KGs of arbitrary new relationsfrom any LMs.\nto the preexisting relations (Figure 1).\nOn the other hand, large language models (LMs)\npretrained on massive text corpus, such as BERT\n(Devlin et al., 2019) and GPT-3 (Brown et al.,\n2020), have been found to encode a significant\namount of knowledge implicitly in their parameters.\nRecent research attempted to use LMs as flexible\nknowledge bases by querying the LMs with arbi-\ntrary prompts (e.g., \"Obama was born in \"for\nthe answer \"Hawaii\") (Petroni et al., 2019). How-\never, such implicit query-based knowledge falls\nshort of many desirable properties of a full-scale\nKG such as ConceptNet (AlKhamissi et al., 2022),\nincluding easy access, browsing, or even editing\n(Zhu et al., 2020; Cao et al., 2021), as well as\nassurance of knowledge quality thanks to the sym-\nbolic nature (Anderson et al., 2020). Symbolic\nKnowledge Distillation (SKD, West et al., 2022)\nexplicitly extracts a knowledge base from GPT-3.\nHowever, the approach exclusively relies on the\nstrong in-context learning capability of GPT-3 and\nthus is not applicable to other rich LMs such as\nBERT (Devlin et al., 2019) and ROBERTA (Liu\net al., 2019). Moreover, its use of a quality dis-\ncriminator trained on existing KGs can limit its\ngeneralization to new relations not included in the\ntraining data.\nIn this paper, we propose a new approach of\nharvesting massive KGs of arbitrary new relations\nfrom any pretrained LMs. Given minimal user in-\nput of a relation definition, including a prompt and\na few shot of example entity pairs, our approach\nautomatically searches within the LM to extract an\nextensive set of high-quality knowledge about the\ndesired relation. To ensure search efficiency in the\nvast space of entity pairs, we devise an effective\nsearch-and-rescore strategy. We also adapt the pre-\nvious prompt paraphrasing mechanism (Jiang et al.,\n1\"NER\", \"CR\", \"RE\" refer to \"named entity recognition\",\n\"coreference resolution\", \"relation extraction\", respectively.\n2SKD has an optional filter that requires existing KG to\nfinetune, which doesn’t work for arbitrary relations.\n2020; Newman et al., 2021) and enhance with our\nnew rescore strategy for prompt weighting, leading\nto consistent and accurate outcome knowledge.\nWe apply our approach on a range of LMs of\nvarying capacities, such as ROBERTA, BERT, and\nDISTIL BERT. In particular, we harvest knoweldge\nof over 400 new relations (an order of magnitude\nmore than ConceptNet relations) not available in\npreexisting KGs and previous extraction methods.\nExtensive human and automatic evaluations show\nour approach successfully extracts diverse accurate\nknowledge, including tuples for complex relations\nsuch as “A is capable of, but not good at,\nB” and 3-ary relations such as “A can do B at\nC”. Interestingly, the resulting KGs also serve as a\nsymbolic interpretation of the source LMs, reveal-\ning new insights into their knowledge capacities in\nterms of varying factors such as model size, pre-\ntraining strategies, and distillation.\n2 Related Work\nKnowledge graph construction Popular knowl-\nedge bases or KGs are usually constructed with\nheavy human labor. For example, WordNet (Fell-\nbaum, 2000) is a lexical database that links words\ninto semantic relations; ConceptNet (Speer et al.,\n2017) is a large commonsense knowledge graph\npresented as a set of knowledge triples; ATOMIC\n(Sap et al., 2019) is a crowd-sourced social com-\nmonsense KG of if-then statements. Recently, Au-\ntomatic Knowledge Base Construction (AKBC) as\na research focus has led to various approaches (sum-\nmarized in Table 1). Text mining-based works aim\nfor knowledge extraction from text. A typical in-\nformation extraction system (Angeli et al., 2015) is\ncomposed of several sub-tasks like coreference res-\nolution, named entity recognition, and relationship\nextraction. Some works on commonsense knowl-\nedge extraction include WebChild (Tandon et al.,\n2014), TransOMCS (Zhang et al., 2020a), DIS-\nCOS (Fang et al., 2021), Quasimodo (Romero et al.,\n2019), ASCENT (Nguyen et al., 2021). These ex-\n5001\ntraction pipelines are based on linguistic pattern,\nand involve complex engineering such as corpus\nselection, term aggregation, filtering, etc. Recent\nattempts also utilize LMs for AKBC. Wang et al.\n2021a finetuned LMs for link prediction. Feldman\net al. 2019; Bouraoui et al. 2020 utilized LMs to\nscore entity pairs collected from the Internet or\nmissing edges in existing KGs. COMET (Bosselut\net al., 2019) is a generative LM trained to predict\ntail entities given head entities and relations. West\net al. 2021 distill the knowledge in GPT-3 to a gen-\nerative LM. By prompting GPT-3 (Brown et al.,\n2020) with examples, they produced ATOMIC 10x\nto teach the student model. Yet, this method re-\nquires the strong few-shot learning ability of GPT-3\nand is not generally applicable to most LMs. To\nthe best of our knowledge, our framework is the\nfirst to construct a KG by extracting purely from\nan LM (with the minimal definition of relations\nas input). The new paradigm can also be seen as\noptimizing a symbolic KG with (pretrained) neu-\nral models as supervision (Hu and Xing, 2022),\nwhich inverts the conventional problem of using\nsymbolic knowledge to learn neural networks (Hu\net al., 2016).\nLMs as knowledge bases Another line of works\nattempted to use LMs as knowledge bases (LAMA,\nPetroni et al. 2019). These works are also known as\nfactual probing because they measured how much\nknowledge is encoded in LMs. This is usually im-\nplemented by prompting methods and leveraging\nthe masked LM pretraining task. LPAQA (Jiang\net al., 2020) proposes to use text mining and para-\nphrasing to find and select prompts to optimize\nthe prediction of a single or a few correct tail enti-\nties, instead of extensively predicting all the valid\nentity pairs like in our framework. AutoPrompt\n(Shin et al., 2020), Qin and Eisner, 2021 and OP-\nTIPrompt (Zhong et al., 2021) learn discrete or\ncontinuous prompts automatically with an addi-\ntional training set. Though making prompts un-\nreadable, these methods achieve higher accuracy\non the knowledge probing tasks. Our framework\ndiffers from these works in that we aim to explicitly\nharvest knowledge graphs instead of measuring the\nknowledge in a simplified setting.\nConsistency of LMs Consistency is a significant\nchallenge for LMs, which stresses that they should\nnot produce conflicting predictions across infer-\nence sessions. For example, models should be-\nhave invariantly under inputs with different surface\nforms but the same meaning. Elazar et al. 2021\nanalyzed the consistency of pretrained LMs with\nrespect to factual knowledge. Jiang et al. 2020 used\nparaphrasing to improve factual probing. Newman\net al. 2021 trains an additional layer on top of word\nembedding to improve consistency. Recently, con-\nsistency is also shown helpful to improve the rea-\nsoning ability of large LMs (Wang et al., 2022;\nJung et al., 2022; Hao et al., 2023). In our frame-\nwork, the extracted entity pairs for each relation\nare enforced to consistently satisfy a diverse set of\nprompts and regularized by several scoring terms.\n3 Harvesting KGs from LMs\nThis section presents the proposed framework\nfor extracting a relational KG from a given pre-\ntrained LM, where the LM can be arbitrary fill-\nin-the-blank models such as BERT (Devlin et al.,\n2019), ROBERTA (Liu et al., 2019), BART (Lewis\net al., 2020), or GPT-3 (with appropriate instruc-\ntions) (Brown et al., 2020). The KG consists of\na set of knowledge tuples in the form ⟨HEAD EN -\nTITY (h), RELATION (r), TAIL ENTITY (t)⟩. Our\napproach utilizes the LM to automatically har-\nvest a large number of appropriate entity pairs\n(h1,t1),(h2,t2),... , for every given relation r.\nThis presents a more challenging problem than tra-\nditional LM probing tasks, which typically predict\na single tail entity or a small number of valid tail\nentities given a head entity and relation.\nOur approach for extracting knowledge tu-\nples of a specific relation of interest, such as\n\"potential_risk\" as depicted in Figure 2, only\nrequires minimal input information that defines the\nrelation. This includes an initial prompt, such as\n\"The potential risk of A is B\" and a small\nnumber of example entity pairs, such as ⟨EATING\nCANDY, TOOTH DECAY ⟩. The prompt provides the\noverall semantics of the relation, while the exam-\nple entity pairs clarify possible ambiguities. For\nnew relations not included in existing KGs, it is\nimpractical to require a large set (e.g., hundreds)\nof example entity pairs as in previous knowledge\nprobing or prompt optimization methods (Petroni\net al., 2019; Jiang et al., 2020; Shi et al., 2019;\nZhong et al., 2021). In contrast, our approach ne-\ncessitates only a small number of example entity\npairs, for example, as few as 2 in our experiments,\nwhich can easily be collected or written by users.\nIn the following sections, we describe the core\n5002\nPrompt SetSampleThe potential risk of eating candy istooth decay. ParaphraseCandycan potentially cause tooth decay.ExtractAcan potentiallycause B. Add\nPrompt Creation\nSearch w/ LM\n(hair, infection) (alcohol, suicide)(food, obesity)...\nCandidate Entity Pairs\nRanked Entity Pairs\nP1:The potential risk of A is B.P2:A may lead to B.P3:If you A, you may be at risk for B.… PromptweightingP1 P2 P3 P4 …\nEntity Pair SearchBertNet!Input\nInitialize -Haircan potentially cause infection. -The potential risk of alcoholis suicide.-Foodmayleadtoobesity\n0.85 (smoking, cancer)0.43 (fishing, fish bite)0.11(speeding, crash)\npotential_risk\nRe-scoringw/LM\nExampleEntity PairsInitial Prompt(eating candy, tooth decay)(playing game, fail the exam)...The potential risk of A is B.\nWeighted Prompt Set\nFigure 2: An overview of the knowledge harvesting framework. Given the minimal definition of the relation as input (an initial\nprompt and a few shot of example entity pairs), the approach first automatically creates a set of prompts expressing the relation\nin a diverse ways (§3.1). The prompts are weighted with confidence scores. We then use the LM to search a large collection of\ncandidate entity pairs, followed by re-scoring/ranking that yields the top entity pairs as the output knowledge (§3.2).\ncomponents of our approach, namely the auto-\nmatic creation of diverse prompts with confidence\nweights (§3.1) and the efficient search to discover\nconsistent entity pairs (§3.2) that compose the de-\nsired KGs. Figure 2 illustrate the overall frame-\nwork.\n3.1 Creating Diverse Weighted Prompts\nOur automated approach utilizes input information,\nspecifically the initial prompt and several exam-\nple entity pairs, to generate a set of semantically\nconsistent but linguistically diverse prompts for\ndescribing the relation of interest. The generated\nprompts are assigned confidence weights to accu-\nrately measure consistency of knowledge in the\nsubsequent step (§3.2).\nTo generate diverse prompts for a desired re-\nlation, we begin by randomly selecting an entity\npair from a example set and inserting it into an\ninitial prompt to form a complete sentence. This\nsentence is then passed through an off-the-shelf\ntext paraphrase model, which produces multiple\nparaphrased sentences with the same meaning. By\nremoving the entity names, each paraphrased sen-\ntence results in a new prompt that describes the\ndesired relation. To ensure a wide range of expres-\nsions of the relation, we retain only those prompts\nthat are distinct from one another in terms of edit\ndistance. This process is repeated by continuously\nparaphrasing the newly created prompts until a min-\nimum of 10 prompts for the relation have been\ncollected.\nThe automatic generation of prompts can be im-\nprecise, resulting in prompts that do not accurately\nconvey the intended relation. To mitigate this, we\npropose a reweighting method that utilizes compat-\nibility scores to calibrate the impact of each prompt\nin the subsequent knowledge search step. Specifi-\ncally, we evaluate the compatibility of new prompts\nwith example entity pairs by measuring the like-\nlihood of the prompts under a LM, considering\nboth the individual entities and the entity pair as a\nwhole. This allows us to determine the appropriate\nweights for each prompt and improve the precision\nof the knowledge search process. Formally, the\ncompatibility score between an entity pair (h,t)\nand a prompt pcan be written as:\nfLM(⟨h,t⟩,p) =αlog PLM(h,t |p)\n+ (1−α) min{log PLM(h|p),log PLM(t|p,h)}\n(1)\nwhere the first term is the joint log-likelihood un-\nder the LM distribution PLM , the second term is\nthe minimum individual log-likelihood given the\nprompt (and the other entity), and αis a balancing\nfactor (α = 2/3 in our experiments). We com-\npute the average compatibility score of each cre-\nated prompt over all example entity pairs, and the\nweight of the prompt is then defined as the softmax-\nnormalized score across all prompts.\n3.2 Efficient Search for Consistent Knowledge\nWith the set of prompts and corresponding confi-\ndence weights obtained in the steps described in\nSection 3.1, we proceed to search entity pairs that\nconsistently align with all prompts. To guide the\nsearching process and evaluate the compatibility\nof searched-out entity pairs (hnew,tnew), we reuse\nthe previously defined prompt/entity-pair compati-\n5003\nRelationEntities Relation Entitiesprevent(humidity, excessive temperature)potential risk(viruses, virus transmission)prevent(care, harm)potential risk(prolonged sleep, sleep disorders)can help(localcouncil, village) potential risk(serious offence, conviction)can help(therapist, client)ingredient for(electricity, electric lamp)place for(lake, picnic tables)ingredient for(rice, soup)place for(studios,live shows)ingredient for(milk, butter)can but not good(appletree, wood) can but not good(locomotive, speed trains)A can doB at C(people, communicate, web)A needs B to C(singers, vocal accompaniment, dance)A can doB at C(adult couples, marry, marriage) A needs B to C(human lives, survival, flourish)A can doB at C(skier, ski downhill, mountain)A needs B to C(actors, dialogue, portray characters)\nFigure 3: Examples of knowledge tuples harvested from DISTILL BERT (randomly sampled). The first 7 rows shows relations\nwith two entities (head and tail), and last 3 rows shows more complex relations with 3 entities.\nbility function (Eq.1), and intuitively define consis-\ntency as the weighted average of its compatibility\nwith the various prompts, i.e.,\nconsistency((hnew,tnew)) =\n∑\np\nwp·fLM((hnew,tnew),p)\n(2)\nwhere wp is the prompt weight and the sum is over\nall automatically created prompts as above, so that\nentity pairs compatible with all prompts are consid-\nered to be consistent.\nBased on the consistency criterion, we develop\nan efficient search strategy to search for consis-\ntent entity pairs. A straightforward approach in-\nvolves enumerating all possible pairs of entities,\ncalculating their respective consistency scores, and\nselecting the top-K entity pairs with the highest\nscores as the resulting knowledge. However, this\napproach can be computationally expensive due\nto the large vocabulary size V (e.g., V = 50,265\nfor ROBERTA) and the high time complexity of\nthe enumeration process (i.e., O(V2) even when\neach entity consists of only one token). To over-\ncome this limitation, we have proposed an appro-\npriate approximation that leads to a more efficient\nsearch and re-scoringmethod. Specifically, we first\nuse the minimum individual log-likelihoods (i.e.,\nthe second term in the compatibility score Eq.1)\nweighted averaged across different prompts (simi-\nlar as in Eq.2), to propose a large set of candidate\nentity pairs. The use of the minimum individual\nlog-likelihoods allows us to apply pruning strate-\ngies, such as maintaining a heap and eliminating\nentities ranked outside top-K in every single search-\ning step. Once we have collected a large number\nof proposals, we re-rank them using the full consis-\ntency score in Eq.2 and select the top-K instances\nas the output knowledge. We describe more nu-\nanced handling in the search procedure (e.g., the\nprocessing of multi-token entities, detailed pruning\nstrategies) in the appendix.\nGeneralization to complex relations Most ex-\nisting KGs or knowledge bases include relations\nthat are predicates connecting two entities, e.g., \"A\nis capable of B\". However, many real-life rela-\ntions are more complex. Our approach is flexible\nand easily extensible to extract knowledge about\nthese complex relations. We demonstrate this in\nour experiments by exploring two cases: (1) highly\ncustomized relationsthat have specific and sophis-\nticated meanings, such as \"A is capable of,\nbut not good at, B\" . This type of sophisti-\ncated knowledge is often difficult for humans to\nwrite down on a large scale. Our automatic ap-\nproach naturally supports harvesting this kind of\nknowledge given only an initial prompt and a few\nexample entities that can be collected easily, e.g.,\n⟨DOG , SWIM ⟩, ⟨CHICKEN , FLY⟩, etc.; (2) N-ary\nrelations involving more than two entities, such as\n\"A can do B at C\". Our approach can straight-\nforwardly be extended to handle n-ary relations\nby generalizing the compatibility score and search\nstrategy accordingly to accommodate more than\ntwo entities.\nSymbolic interpretation of neural LMs The\nharvested knowledge tuples, as consistently recog-\nnized across varying prompts by the LM, can be\nconsidered as the underlying \"beliefs\" of the LM\nabout the world (Stich, 1979; Hase et al., 2021).\nThese fully symbolic and interpretable tuples pro-\nvide a means for easily browsing and analyzing the\nknowledge capabilities of the black-box LM. For\nexample, via these outcome KGs, one can compare\n5004\nParadigm Method (Size) Relation Set #Relations Accuracy (%) Novelty (%)\nOurs\nRobertaNet (122.2k) Auto 487 65.3 -\nRobertaNet (2.2K) Human 12 81.8 -\nRobertaNet (7.3K) Human 12 68.6 -\nRobertaNet (23.6k) Human 12 58.6 -\nRobertaNet (6.7K) ConceptNet 20 88.0 64.4\nRobertaNet (24.3K) ConceptNet 20 81.6 68.8\nRobertaNet (230K) ConceptNet 20 55.0 87.0\nKG Completion COMET (6.7K) ConceptNet 20 92.0 35.5\nCOMET (230K) ConceptNet 20 66.6 72.4\nText Mining\nWebChild (4.6M) - 20 82.0* -\nASCENT (8.6M) - - 79.2* -\nTransOMCS (18.4M) ConceptNet 20 56.0* 98.3\nTable 2: Statistics of KGs constructed with different methods. Different paradigms of works can not be directly compared\ndue to their different settings discussed in Table 1. We put the results together for reference purpose. Novelty refers to the\nproportion of entities that do not appear in ConceptNet, so only the methods with ConceptNet relations set haveNovelty numbers.\nThe accuracy with ∗ are from the original papers and subject to different evaluation protocol. As a finetuned knowledge base\ncompletion model, COMET(Bosselut et al., 2019) can only predict the tail entity given a source entity and a relation, we generate\nKGs with COMET by feeding it the head entity produced by our ROBERTA NET. The bottom block of the table summarizes\nthe results from some major text mining methods described in Table 1, including WebChild (Tandon et al., 2014), ASCENT\n(Nguyen et al., 2021) and TransOMCS (Zhang et al., 2020a).\ndifferent LMs to understand the performance im-\npact of diverse configurations, such as model sizes\nand pretraining strategies, as demonstrated in our\nexperiments.\n4 Experiments\nTo evaluate our framework, we extract knowledge\nof diverse new relations from various language\nmodels, and conduct human evaluation. We then\nmake deeper analysis of prompt creation and scor-\ning function in our framework. Finally, by utilizing\nour framework as a tool to interpret the knowledge\nstored in language models, we have made notewor-\nthy observations regarding the knowledge capacity\nof black-box models.\n4.1 Setup\nRelations We evaluate our framework with sev-\neral relation sets: (1) ConceptNet (Speer et al.,\n2017): Following Li et al. 2016, we filter the\nKG and use a set of 20 common relations (e.g.\nHAS _SUBEVENT , MOTIVATED _BY_GOAL ). The\ninitial prompts for these relations are from the Con-\nceptNet repository, and we randomly sample 5 ex-\nample entity pairs from the ConceptNet KG for\neach relation. (2) LAMA (Petroni et al., 2019):\nFollowing previous works, we use the T-REx split\n(41 relations from WikiPedia, such as capital_of,\nmember_of). For each relation, the human-written\nprompt provided in Petroni et al. 2019 is used as\nthe initial prompt and we randomly sample 5 exam-\nple entity pairs for each relation. (3) Human: We\nwrite 12 new relations of interests that can hardly be\nfound in any existing KGs, and manually write an\ninitial prompt and 5 example entity pairs for them.\nThe resulting relations include complex relations\nas described in Section 3.2. (4) Auto: Besides rela-\ntions from existing KGs and human-written ones,\nwe automatically derive a large set of relations from\nE-KAR (Chen et al., 2022), a dataset for analogical\nreasoning. In the original dataset, given an entity\npair, e.g. ⟨ID_CARD , IDENTITY ⟩, the task is to se-\nlect an analogous tuple from multiple choices, e.g.\n⟨PRACTICE LICENSE , QUALIFICATION ⟩. To turn a\nsample in E-KAR into a relation, we use the tuple\nin the question and the correct choices as 2 exam-\nple entity pairs, and extract the initial prompt from\nthe explanation provided in E-KAR (e.g. Proof of\nA requires B.), resulting in 487 relations. Some of\nthe relations are not straightforward, making this\nrelation set more difficult than other ones. 3\n4.2 Extracting Knowledge of Diverse New\nRelations\nOur framework is applied to extract knowledge\ngraphs from LMs with relations of ConceptNet,\nAuto, and Human. The accuracy of the ex-\ntracted knowledge is then evaluated with hu-\nman annotation using Amazon Mechanical Turk\n(MTurk). Each extracted knowledge tuple is la-\n3For reference, finetuned ROBERTA-LARGE achieves\nabout 50% accuracy on the original dataset.\n5005\nMethods Acc Rej\nAUTOPROMPT 0.33 0.47\nHUMAN PROMPT 0.60 0.27\nTOP-1 P ROMPT (Ours) 0.69 0.23\nMULTI PROMPTS (Ours) 0.73 0.20\nTable 3: The portions of accepted and rejected tuples in human\nevaluation across settings, with the ROBERTA-LARGE as the\nLM.\nbeled for correctness by three annotators using a\nTrue/False/Unjudgeable judge. A tuple is consid-\nered \"accepted\" if at least two annotators deem it\nto be true knowledge, and \"rejected\" if at least two\nannotators rate it as false. Here we refers portion\nof accepted tuples as accuracy.\nThe statistics of our resulting KGs are listed\nin Table 2. Besides, we also put the results of\nother paradigms of methods, including COMET\nfor KG completion and text-mining based methods\n(Figure 1). Note that the results across different\nparadigms are generally not directly comparable\ndue to vastly different settings. Yet we still collect\nthe results together for reference purpose. From\nour RebertaNet with relation set \"Auto\", we are\nable to extract a reasonably large sets of knowl-\nedge (122K), by extracting knowledge with 487\neasy-to-collect \"Auto\" relations. The set of rela-\ntion is an order of magnitude larger than the prede-\nfined set of relations in both KG completion and\ntext mining based on ConceptNet as shown in the\ntable. The accuracy of 65% is at a comparable\nlevel with that of COMET (230K) and TransOMCS\n(18.4M), which is reasonable especially consider-\ning our method solely uses an LM as the source\nof knowledge without any external training data,\nbringing flexibility to dynamically incorporate new\nrelations. Besides, for our RobertaNet on Concept-\nNet relations, although the numbers listed in the\ntable are not simply comparable, we can still find\nthat RobertaNet achieves similar accuracy and ab-\nsolutely higher novelty comparing with the knowl-\nedge from COMET, which is already finetuned\nusing large number of knowledge terms under the\nsame set of ConceptNet relations. Further, our re-\nsults on the \"human\" relation set demonstrate that\nour RobertaNet keeps working comfortably on our\nhighly realistic relations of user interests, includ-\ning the complex ones as described in section §3.2.\nWe showcase knowledge samples harvested from\nDISTILL BERT in Figure 3.\nSource LMs Acc Rej\nDISTIL BERT 0.67 0.24\nBERT-BASE 0.63 0.26\nBERT-LARGE 0.70 0.22\nROBERTA-BASE 0.70 0.22\nROBERTA-LARGE 0.73 0.20\nTable 4: The portions of accepted and rejected tuples in human\nevaluation across different LMs, using the MULTI -PROMPTS\napproach.\n4.3 Analyzing Automatic Prompt Creation\nTo evaluate the effect of our automatic creation\nof prompts, we compare the generated KGs under\nseveral settings on the Human relations: (1) Multi-\nPrompts refers to the the full framework described\nin §3 which use the automatically created diverse\nprompts in knowledge search. (2) Top-1 Prompt:\nTo ablate the effect of ensembling multiple prompts,\nwe evaluate the variant that uses only the prompt\nwith largest weight (§3.1) for knowledge extraction.\n(3) Human Prompt: To further understand the ef-\nfectiveness of the automatically created prompts,\nwe assess the variant that uses the initial prompt of\neach relation. (4) AutoPrompt (Shin et al., 2020),\nwhich was proposed to learn prompts by optimiz-\ning the likelihood of tail entity prediction on the\ntraining set. To fit in our setting, we adapt it to opti-\nmize the compatibility score (Eq.1) on the example\nentity pairs. We omit other prompt tuning work\n(e.g., Zhong et al., 2021; Qin and Eisner, 2021) be-\ncause they either are difficult to fit in our problem\nor require more training data and fail with only the\nfew shot of example entity pairs in our setting.\nWe harvest 1000 tuples for each Human rela-\ntion, and evaluate them with human annotation.\nThe annotation results are presented in Table 3\n(We also list the detailed results per relation in\nTable 5 for reference) Our TOP-1 P ROMPT signif-\nicantly improves the accuracy up to 9% over the\nHUMAN PROMPT , demonstrating the effectiveness\nof our prompt searching algorithm in generating\nhigh-quality prompts. MULTI -PROMPTS further\nimproves the accuracy by an additional 4%, indicat-\ning that the combination of diverse prompts better\ncaptures the semantics of a relation. However, the\nmethod utilizing the optimized prompt by AUTO -\nPROMPT results in lower accuracy than the use of\nhuman or searched prompts. This can be attributed\nto the insufficient number of example knowledge\ntuples used to learn effective prompts for the de-\nsired relations.\nBased on the results above, we move a step for-\n5006\n0.0 0.2 0.4 0.6 0.8 1.0\nRecall\n0.5\n0.6\n0.7\n0.8\n0.9Precision\nAutoPrompt\nCOMET\nHuman-written Prompt\nTop-1 Prompt (ours)\nMultiple Prompts (ours)\nFigure 4: Precision-recall on ConceptNet relations.\nward to see how the created prompts influence\nthe subsequent scoring module in the framework.\nSpecifically, we study both the precision and re-\ncall of our scoring function parameterized by the\nprompts, to see if the automatically created prompts\n(§3.1) bring the consistency scoring (§3.2) better\nbalance of knowledge accuracy (precision) and cov-\nerage (recall). To compare with other scoring meth-\nods that are restricted to specific sets of relations,\nthis experiment was conducted using existing terms\nfrom both the ConceptNet and LAMA datasets.\nSpecifically, we use the knowledge tuples from\nConceptNet and LAMA as positive samples (§4.1),\nand synthesize the same amount of negative sam-\nples with the same strategy in Li et al. (2016) by\nrandom replacing entities or relations in a true\nknowledge tuple. Each scoring function ranks the\nsamples based on the scores from high to low. We\ncan then compute both the precision and recall of\npositive samples at different cut-off points along\nthe ranking, and plot the precision-recall curves for\neach method.\nThe automatic evaluation setting on given knowl-\nedge terms enables us to adapt existing prevalent\nworks, e.g., KG completion and factual probing\n(Table 1), for comparison with our approach: (1)\nCOMET (Bosselut et al., 2019) is a transformer-\nbased KG completion model trained to predict the\ntail entity t conditioning on the head entity and\nrelation (h,r) on ConceptNet. We use its log-\nlikelihood log P(t|h,r) as the score for each given\nknowledge tuple. (2) LPAQA (Jiang et al., 2020)\ncollects a set of prompts on LAMA with text min-\ning and paraphrasing, and optimize their weights\ntowards the objective of log P(t|h,r) on training\nsamples.\nThe resulting precision-recall curves on Concept-\nNet and LAMA knowledge are shown in Figure 4\n0.0 0.2 0.4 0.6 0.8 1.0\nRecall\n0.5\n0.6\n0.7\n0.8Precision\nAutoPrompt\nLPAQA\nHuman-written Prompt\nTop-1 Prompt (ours)\nMultiple Prompts (ours)\nFigure 5: Precision-recall curve on LAMA relations.\nand Figure 5, respectively. Scoring with multiple\nprompts always achieves best performance, fol-\nlowed by Top-1 prompts and then Human-written\nprompts. The finding is consistent with previous\nexperiments, which verified the effectiveness of our\nscoring function design. Our framework also out-\nperforms other baselines, such as COMET on Con-\nceptNet and LPAQA on LAMA. Though trained\nwith labeled data, these methods are only optimized\nto completing a tail entity given a query, in stead of\nscoring an entity pair, which is essential to extract\nKGs from LMs.\n4.4 Analysis of Knowledge in Different LMs\nAs previously mentioned in Section §3, the result-\ning knowledge graphs can be viewed as a sym-\nbolic interpretation of LMs. We extract knowledge\ngraphs from 5 distinct language models and submit\nthem to human annotation evaluation. The findings\nare presented in Table 4 (The detailed results per\nrelation is listed in Table 5), which sheds some\nnew light on several knowledge-related questions\nregarding the LMs’ knowledge capacity.\nDoes a larger LM encode better knowledge?\nThe large version of BERT and RoBERTa have the\nsame pretraining corpus and tasks as their base ver-\nsions, but have larger model architecture in terms\nof layers (24 v.s. 12), attention heads (16 v.s. 12),\nand the number of parameters (340M v.s. 110M).\nWe can see that the accuracies of BertNet-large and\nRoBERTaNet-large are around 7% and 3% higher\nthan their base version, separately, indicating the\nlarger models indeed encoded better knowledge\nthan the base models.\nDoes better pretraining bring better knowl-\nedge? RoBERTa uses the same architecture as\nBERT but with better pretraining strategies, like dy-\nnamic masking, larger batch size, etc. In their corre-\n5007\nsponding KGs from our framework, RoBERTaNet-\nlarge performs better than BertNet-large (0.73 v.s.\n0.70), and RoBERTaNet-base is also better than\nBertNet-base (0.70 v.s. 0.63), showing that the bet-\nter pretraining in RoBERTa leads to better knowl-\nedge learning and storage.\nIs knowledge really kept in the knowledge\ndistillation process? DistilBERT is trained by\ndistilling BERT-base, and it reduces 40% param-\neters from the latter. Interestingly, the knowledge\ndistillation process instead improves around 4%\nof accuracy in the result knowledge graph. This\nshould be attributed to the knowledge distillation\nprocess which might eliminate some noisy infor-\nmation from the teacher model.\n5 Conclusion\nWe have developed an automatic framework that\nextracts a KG from a pretrained LM (e.g, BERT,\nROBERTA), in an efficient and scalable way, result-\ning in a family of new KGs, which we refer to as\nBERTNET, ROBERTANET, etc. Our framework is\ncapable of extracting knowledge of arbitrary new\nrelation types and entities, without being restricted\nby pre-existing knowledge or corpora. The result-\ning KGs also serve as interpretation of source LMs.\nLimitations Our current design and experimental\nstudies are limited on LMs in the generic domain,\nand are not yet been studied in specific domains\nsuch as extracting healthcare knowledge from rele-\nvant neural models. We leave the exciting work of\nharvesting knowledge from various kinds of neural\nnetworks across applications and domains in the\nfuture work.\nEthical considerations In this work, the har-\nvested knowledge is automatically generated by\nLMs. We would like to note that the language mod-\nels could possibly generate unethical knowledge\ntuples, same with the risks of other applications\nusing language models for generation. We hope\nthat the knowledge extraction study could offer\ntechniques to better interpret and understand the\nlanguage models, and in turn foster the future re-\nsearch of language model ethics. Since the knowl-\nedge graph only consists simple phrases, we think\nfiltering sensitive words would be effective. No\nforeseeable negative societal impacts are caused by\nthe method itself.\nReferences\nBadr AlKhamissi, Millicent Li, Asli Celikyilmaz, Mona\nDiab, and Marjan Ghazvininejad. 2022. A review on\nlanguage models as knowledge bases. arXiv preprint\narXiv:2204.06031.\nGreg Anderson, Abhinav Verma, Isil Dillig, and Swarat\nChaudhuri. 2020. Neurosymbolic reinforcement\nlearning with formally verified exploration. Ad-\nvances in neural information processing systems,\n33:6172–6183.\nGabor Angeli, Melvin Johnson, and Christopher D.\nManning. 2015. Leveraging linguistic structure for\nopen domain information extraction. In ACL.\nAntoine Bordes, Nicolas Usunier, Alberto Garcia-\nDuran, Jason Weston, and Oksana Yakhnenko.\n2013. Translating embeddings for modeling multi-\nrelational data. Advances in neural information pro-\ncessing systems, 26.\nAntoine Bosselut, Hannah Rashkin, Maarten Sap, Chai-\ntanya Malaviya, Asli Çelikyilmaz, and Yejin Choi.\n2019. Comet: Commonsense transformers for knowl-\nedge graph construction. The Association for Com-\nputational Linguistics.\nZied Bouraoui, José Camacho-Collados, and Steven\nSchockaert. 2020. Inducing relational knowledge\nfrom bert. In AAAI.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, T. J. Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens\nWinter, Christopher Hesse, Mark Chen, Eric Sigler,\nMateusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. ArXiv,\nabs/2005.14165.\nNicola De Cao, Wilker Aziz, and Ivan Titov. 2021. Edit-\ning factual knowledge in language models.\nJiangjie Chen, Rui Xu, Ziquan Fu, Wei Shi, Zhongqiao\nLi, Xinbo Zhang, Changzhi Sun, Lei Li, Yanghua\nXiao, and Hao Zhou. 2022. E-kar: A benchmark for\nrationalizing natural language analogical reasoning.\narXiv preprint arXiv:2203.08480.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In NAACL-HLT (1).\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Abhi-\nlasha Ravichander, Eduard Hovy, Hinrich Schütze,\nand Yoav Goldberg. 2021. Measuring and improving\nconsistency in pretrained language models. Transac-\ntions of the Association for Computational Linguis-\ntics, 9:1012–1031.\n5008\nTianqing Fang, Hongming Zhang, Weiqi Wang,\nYangqiu Song, and Bin He. 2021. Discos: Bridg-\ning the gap between discourse knowledge and com-\nmonsense knowledge. In Proceedings of the Web\nConference 2021, pages 2648–2659.\nJoshua Feldman, Joe Davison, and Alexander M. Rush.\n2019. Commonsense knowledge mining from pre-\ntrained models. In EMNLP.\nChristiane D. Fellbaum. 2000. Wordnet : an electronic\nlexical database. Language, 76:706.\nGoogle. 2012. Introducing the knowledge graph: things,\nnot strings.\nShibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong,\nZhen Wang, Daisy Zhe Wang, and Zhiting Hu. 2023.\nReasoning with language model is planning with\nworld model.\nPeter Hase, Mona T. Diab, Asli Çelikyilmaz, Xian Li,\nZornitsa Kozareva, Veselin Stoyanov, Mohit Bansal,\nand Srini Iyer. 2021. Do language models have be-\nliefs? methods for detecting, updating, and visualiz-\ning model beliefs. ArXiv, abs/2111.13654.\nZhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard H\nHovy, and Eric P Xing. 2016. Harnessing deep neural\nnetworks with logic rules. In ACL (1).\nZhiting Hu and Eric P. Xing. 2022. Toward\na ’Standard Model’ of Machine Learn-\ning. Harvard Data Science Review , 4(4).\nHttps://hdsr.mitpress.mit.edu/pub/zkib7xth.\nZhengbao Jiang, Frank F. Xu, J. Araki, and Graham\nNeubig. 2020. How can we know what language\nmodels know? TACL.\nJaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brah-\nman, Chandra Bhagavatula, Ronan Le Bras, and\nYejin Choi. 2022. Maieutic prompting: Logically\nconsistent reasoning with recursive explanations.\narXiv preprint arXiv:2205.11822.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020. Bart:\nDenoising sequence-to-sequence pre-training for nat-\nural language generation, translation, and compre-\nhension. In ACL.\nChristy Y . Li, Xiaodan Liang, Zhiting Hu, and Eric P.\nXing. 2019. Knowledge-driven encode, retrieve,\nparaphrase for medical image report generation. In\nAAAI.\nXiang Li, Aynaz Taheri, Lifu Tu, and Kevin Gimpel.\n2016. Commonsense knowledge base completion.\nIn Proceedings of the 54th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 1445–1455, Berlin, Germany.\nAssociation for Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. ArXiv, abs/1907.11692.\nYi Luan, Dave Wadden, Luheng He, Amy Shah, Mari\nOstendorf, and Hannaneh Hajishirzi. 2019. A general\nframework for information extraction using dynamic\nspan graphs. arXiv preprint arXiv:1904.03296.\nBenjamin Newman, Prafulla Kumar Choubey, and\nNazneen Rajani. 2021. P-adapters: Robustly extract-\ning factual information from language models with\ndiverse prompts. ArXiv, abs/2110.07280.\nTuan-Phong Nguyen, Simon Razniewski, Julien\nRomero, and Gerhard Weikum. 2021. Refined com-\nmonsense knowledge from large-scale web contents.\narXiv preprint arXiv:2112.04596.\nFabio Petroni, Tim Rocktäschel, Patrick Lewis, An-\nton Bakhtin, Yuxiang Wu, Alexander H. Miller, and\nSebastian Riedel. 2019. Language models as knowl-\nedge bases? EMNLP.\nGuanghui Qin and Jas’ Eisner. 2021. Learning how to\nask: Querying lms with mixtures of soft prompts. In\nNAACL.\nJulien Romero, Simon Razniewski, Koninika Pal, Jeff\nZ. Pan, Archit Sakhadeo, and Gerhard Weikum. 2019.\nCommonsense properties from query logs and ques-\ntion answering forums. In Proceedings of the 28th\nACM International Conference on Information and\nKnowledge Management, pages 1411–1420.\nAlberto Santos, Ana R Colaço, Annelaura B Nielsen,\nLili Niu, Maximilian Strauss, Philipp E Geyer,\nFabian Coscia, Nicolai J Wewer Albrechtsen, Filip\nMundt, Lars Juhl Jensen, et al. 2022. A knowledge\ngraph to interpret clinical proteomics data. Nature\nBiotechnology, 40(5):692–702.\nMaarten Sap, Ronan Le Bras, Emily Allaway, Chan-\ndra Bhagavatula, Nicholas Lourie, Hannah Rashkin,\nBrendan Roof, Noah A. Smith, and Yejin Choi. 2019.\nAtomic: An atlas of machine commonsense for if-\nthen reasoning. ArXiv, abs/1811.00146.\nShaoyun Shi, Hanxiong Chen, Min Zhang, and\nYongfeng Zhang. 2019. Neural logic networks.\nArXiv, abs/1910.08629.\nTaylor Shin, Yasaman Razeghi, Robert L Logan IV , Eric\nWallace, and Sameer Singh. 2020. Eliciting knowl-\nedge from language models using automatically gen-\nerated prompts. EMNLP.\nRobyn Speer, Joshua Chin, and Catherine Havasi. 2017.\nConceptnet 5.5: An open multilingual graph of gen-\neral knowledge. In AAAI.\nStephen P Stich. 1979. Do animals have beliefs? Aus-\ntralasian Journal of Philosophy, 57(1):15–28.\n5009\nBowen Tan, Lianhui Qin, Eric Xing, and Zhiting\nHu. 2020. Summarizing text on any aspects: A\nknowledge-informed weakly-supervised approach.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 6301–6309.\nNiket Tandon, Gerard De Melo, Fabian Suchanek, and\nGerhard Weikum. 2014. Webchild: Harvesting and\norganizing commonsense knowledge from the web.\nIn Proceedings of the 7th ACM international confer-\nence on Web search and data mining, pages 523–532.\nBo Wang, Tao Shen, Guodong Long, Tianyi Zhou, and\nYi Chang. 2021a. Structure-augmented text represen-\ntation learning for efficient knowledge graph comple-\ntion. Proceedings of the Web Conference 2021.\nHongwei Wang, Fuzheng Zhang, Miao Zhao, Wenjie Li,\nXing Xie, and Minyi Guo. 2019. Multi-task feature\nlearning for knowledge graph enhanced recommen-\ndation. The World Wide Web Conference.\nLiming Wang, Siyuan Feng, Mark Hasegawa-Johnson,\nand Chang Yoo. 2022. Self-supervised semantic-\ndriven phoneme discovery for zero-resource speech\nrecognition. In Proceedings of the 60th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 8027–8047, Dublin,\nIreland. Association for Computational Linguistics.\nQingyun Wang, Manling Li, Xuan Wang, Niko-\nlaus Nova Parulian, Guangxing Han, Jiawei Ma,\nJingxuan Tu, Ying Lin, H. Zhang, Weili Liu, Aab-\nhas Chauhan, Yingjun Guan, Bangzheng Li, Ruisong\nLi, Xiangchen Song, Heng Ji, Jiawei Han, Shih-Fu\nChang, James Pustejovsky, David Liem, Ahmed El-\nsayed, Martha Palmer, Jasmine Rah, Cynthia Schnei-\nder, and Boyan A. Onyshkevych. 2021b. Covid-19\nliterature knowledge graph construction and drug re-\npurposing report generation. In NAACL.\nPeter West, Chandra Bhagavatula, Jack Hessel, Jena\nHwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,\nSean Welleck, and Yejin Choi. 2022. Symbolic\nknowledge distillation: from general language mod-\nels to commonsense models. In Proceedings of the\n2022 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 4602–4625, Seat-\ntle, United States. Association for Computational\nLinguistics.\nPeter West, Chandra Bhagavatula, Jack Hessel, Jena D\nHwang, Liwei Jiang, Ronan Le Bras, Ximing\nLu, Sean Welleck, and Yejin Choi. 2021. Sym-\nbolic knowledge distillation: from general language\nmodels to commonsense models. arXiv preprint\narXiv:2110.07178.\nChenyan Xiong, Russell Power, and Jamie Callan. 2017.\nExplicit semantic ranking for academic search via\nknowledge graph embedding. Proceedings of the\n26th International Conference on World Wide Web.\nYunrong Yang, Zhidong Cao, Pengfei Zhao, Da-\njun Daniel Zeng, Qingpeng Zhang, and Yin Luo.\n2021. Constructing public health evidence knowl-\nedge graph for decision-making support from\nCOVID-19 literature of modelling study. Journal\nof Safety Science and Resilience, 2(3):146–156.\nLiang Yao, Chengsheng Mao, and Yuan Luo. 2019. Kg-\nbert: Bert for knowledge graph completion. ArXiv,\nabs/1909.03193.\nHongming Zhang, Daniel Khashabi, Yangqiu Song, and\nDan Roth. 2020a. Transomcs: From linguistic graphs\nto commonsense knowledge. In IJCAI.\nHongming Zhang, Xin Liu, Haojie Pan, Yangqiu Song,\nand Cane Wing-Ki Leung. 2020b. Aser: A large-\nscale eventuality knowledge graph. In Proceedings\nof the web conference 2020, pages 201–211.\nZexuan Zhong and Danqi Chen. 2020. A frustrat-\ningly easy approach for entity and relation extraction.\narXiv preprint arXiv:2010.12812.\nZexuan Zhong, Dan Friedman, and Danqi Chen. 2021.\nFactual probing is [mask]: Learning vs. learning to\nrecall. NAACL.\nChen Zhu, Ankit Singh Rawat, Manzil Zaheer, Srinadh\nBhojanapalli, Daliang Li, Felix X. Yu, and Sanjiv\nKumar. 2020. Modifying memories in transformer\nmodels. ArXiv, abs/2012.00363.\n5010\nA Detailed Results of Harvested\nKnowledge\nIn Table 3 and Table 4, we show the human-\nannotated results of harvested knowledge in dif-\nferent settings. Here we list the detailed results per\nrelation in Table 5.\nB Preprocessing of ConceptNet\nWe filter out some linguistic relations (e.g.\netymologically derived from) and some triv-\nial relations (e.g. related to). We only consider\nthe tuples with confidence higher than 1, and filter\nout relations comprising less than 1000 eligible tu-\nples. We don’t directly take the test set from (Li\net al., 2016) because they reserve a lot of tuples for\ntraining, resulting in a small and unbalanced test\nset.\nC Efficient knowledge tuple search\nIn the candidate entity pairs proposal step, we\nuse the minimum token log-likelihoods (shorted as\nMTL) instead of the full Equation 2, which allows\nus to apply a pruning strategy. The pseudo-code is\nshown in Algorithm 1. For simplicity of the pseudo-\ncode, we only include the case where each entity\nis composed of a single token. Appendix ?? illus-\ntrates the processing of multi-token entities. It’s\nworth noting that our algorithm is an exact search\nalgorithm instead of approximated algorithms like\nbeam search, which prevents the results from bias-\ning towards more probable head entities.\nAs a running example, when we are searching\nfor 100 entity tuples, we maintain a minimum heap\nto keep track of the MTL of the entity tuples. The\nmaximum size of this heap is 100, and the heap\ntop can be used as a threshold for future search\nbecause it’s the 100-th largest MTL: When we are\nsearching for a new entity tuple, once we find the\nlog-likelihood at any time step is lower than the\nthreshold, we can prune the continuous searching\nimmediately, because this means the MTL of this\ntuple will never surpass any existing tuples in the\nheap. If a new entity tuple is searched out without\nbeing pruned, we will pop the heap and push the\nMTL of the new tuple. Intuitively, the pruning pro-\ncess makes sure that the generated part of the tuple\nin searching is reasonable for the given prompt.\nAlgorithm 1 Efficient Entity Tuple Search\nInput: LM: A language model; nr: The entity number for\na tuple of relation r; N: maximum number of candidate\ntuples; Pr: The set of prompts describing relation r\nOutput: tuple_list: A list of N entity tuples\nheap ←MinHeap()\nfunction DFS(cur_tuple, cur_MTL)\nidx←Count(cur_tuple)\nif idx = nr then\nheap.push((cur_tuple, cur_MTL))\nif len(heap) > N then\nheap.pop()\nend if\nend if\nfor v ∈V ocab(LM)do\ncur_L ←log pLM (v|cur_tuple,Pr)\ncur_MTL = min(cur_L, cur_MTL)\nif Count(cur_tuple > 0) and cur_MTL < heap.top()\nthen return ▷Pruning\nend if\ncur_tuple.append(v)\nDFS(cur_tuple, cur_MTL)\nend for\nend function\nDFS(EmptyList(), 0)\ntuple_list ←list(heap)\nD Detailed Experiment setting\nWe use GPT-3 with the instruction \"para-\nphrase:sentence\" with a few examples as the off-\nthe-shelf paraphraser. In entity pair searching, we\nrestrict every entity to appear no more than 10 times\nto improve the diversity of generated knowledge\nand search out at most 50,000 entity tuples for each\nrelation. We finally use various score thresholds\nto get the outcome KGs in different scales, includ-\ning (1) 50%: taking half of all searched-out entity\npairs with higher consistency for each relation (2)\nbase-k: Naturally, there are different numbers of\nvalid tuples for different relations (e.g. tuples of ⟨\n. . . , CAPITAL _OF, . . .⟩should not exceed 200 as\nthat is the number of all the countries in the world).\nWe design a relation-specific thresholding method,\nthat is to set 10% of the k-th consistency as the\nthreshold (i.e., 0.1 ×consistencyk), and retain all\ntuples with consistency above the threshold. We\nname the settings base-10 and base-100 when k\nis 10 and 100, respectively. We list the truncation\nmethod applied to each variant of ROBERTANET\nlisted in Table 2:\n• RobertaNet (122.2k) - Auto: base-10\n• RobertaNet (6.7K) - ConceptNet: base-10\n• RobertaNet (24.3K) ConceptNet: base-100\n• RobertaNet (230K) ConceptNet: 50%\n5011\nTable 5: Detailed result of human evaluation. The numbers indicate the portions of accepted and rejected tuples. Ro-l, DB, B-b,\nB-l, Ro-b are short for Roberta-large, DistilBert, Bert-large, Bert-base, Roberta-base. Human, Auto, Top-1, and Multi stand for\nmethods that use Human Prompt, Autoprompt, Top-1 Prompt (Ours), and Multi Prompts (Ours).\nModel Ro-l Ro-l Ro-l Ro-l DB B-b B-l Ro-b\nPrompt Human Auto Top-1 Multi Multi Multi Multi Multi\nBUSINESS 0.60/0.32 0.76/0.13 0.75/0.16 0.88/0.07 0.54/0.27 0.64/0.23 0.76/0.13 0.74/0.19\nHELP 0.77/0.12 0.52/0.34 0.92/0.03 0.87/0.05 0.91/0.04 0.81/0.04 0.88/0.06 0.88/0.06\nINGREDIENT FOR 0.59/0.33 0.33/0.59 0.73/0.20 0.71/0.24 0.70/0.26 0.55/0.40 0.72/0.23 0.51/0.40\nPLACE FOR 0.76/0.10 0.41/0.36 0.63/0.32 0.89/0.07 0.84/0.14 0.78/0.18 0.87/0.11 0.88/0.09\nPREVENT 0.42/0.42 0.18/0.67 0.60/0.25 0.40/0.45 0.60/0.32 0.44/0.39 0.62/0.25 0.68/0.25\nSOURCE OF 0.76/0.17 0.21/0.67 0.52/0.44 0.60/0.33 0.63/0.36 0.65/0.32 0.75/0.24 0.55/0.37\nSEPARATED BY THE OCEAN0.48/0.38 0.16/0.48 0.56/0.35 0.55/0.40 0.51/0.24 0.57/0.26 0.44/0.46 0.44/0.49\nANTONYM 0.50/0.41 0.10/0.83 0.50/0.48 0.55/0.44 0.38/0.56 0.41/0.56 0.52/0.42 0.75/0.22\nFEATURED THING0.85/0.12 0.38/0.40 0.88/0.06 0.89/0.10 0.37/0.44 0.44/0.40 0.46/0.44 0.65/0.20\nNEEDATO DOB 0.71/0.18 0.62/0.21 0.66/0.22 0.79/0.10 0.83/0.12 0.62/0.25 0.65/0.18 0.72/0.17\nCAN BUT NOT GOOD AT0.52/0.34 0.29/0.42 0.61/0.19 0.44/0.21 0.51/0.31 0.60/0.21 0.64/0.22 0.39/0.35\nWORTH CELEBRATING0.47/0.29 0.23/0.51 0.81/0.05 0.85/0.08 0.79/0.12 0.74/0.14 0.84/0.10 0.83/0.10\nPOTENTIAL RISK 0.40/0.23 0.31/0.45 0.70/0.21 0.76/0.19 0.87/0.05 0.66/0.22 0.72/0.16 0.79/0.08\nADOBAT 0.56/0.33 0.14/0.55 0.79/0.14 0.97/0.03 0.93/0.07 0.93/0.05 0.94/0.06 0.94/0.06\nAVERAGE 0.60/0.27 0.33/0.47 0.69/0.22 0.73/0.20 0.67/0.24 0.63/0.26 0.70/0.22 0.70/0.22\n[MASK] is the place for [MASK]\nBERT\nLibrary is the place for [MASK]\nBERT\n𝑃𝑃𝐿𝐿𝐿𝐿(ℎ|𝑝𝑝)\n𝑃𝑃𝐿𝐿𝐿𝐿(𝑡𝑡|𝑝𝑝, ℎ)\n[MASK] [MASK] is the place for [MASK]\nBERT\n𝑃𝑃𝐿𝐿𝐿𝐿(ℎ1|𝑝𝑝)\nStudy [MASK] is the place for [MASK]\nBERT\n𝑃𝑃𝐿𝐿𝐿𝐿(ℎ|𝑝𝑝)=𝑃𝑃𝐿𝐿𝐿𝐿 ℎ1 𝑝𝑝 ∗𝑃𝑃𝐿𝐿𝐿𝐿(ℎ2|𝑝𝑝, ℎ1)\n𝑃𝑃𝐿𝐿𝐿𝐿(ℎ2|𝑝𝑝, ℎ1)\n(Multiple tokens)\nFigure 6: We demonstrate the calculation with an example where p=\"A IS THE PLACE FOR B\". The left two figures shows how\nwe calculate PLM (h|p) and PLM (t|p,h). In this example, h=\"library\" when we set both head and tail entities to have one\nsingle token. The right block shows how we calculate the conditional probability of multiple-token entities by decomposing it\ninto two steps. In this example, the first token of the head entity h1 =\"study\".\n• RobertaNet (2.2K) Human: base-10\n• RobertaNet (7.3K) Human: base-100\n• RobertaNet (23.6k) Human: 50%\nE Human evaluation\nWe present the screenshot of the instruction in Fig-\nure 7 and question in Figure 8. The inter-annotator\nagreement (Krippendorff’s Alpha) is 0.27, showing\nfair agreement.\nF Compute resource\nAll of our experiments are running on a single\nNvidia GTX1080Ti GPU. Harvesting a knowl-\nedge graph of one relation with Roberta-large takes\nabout one hour.\nG The license of the assets\nAll the data we used in this paper, including\ndatasets, relation definitions, seed entity pairs, etc.,\nare officially public resources.\nH Potential Risks\nWe identify that our system is minimal in risks. Our\nproposed system produce results only based on the\nsource language models like BERT. The risks of\nlanguage models are well studied and our meth-\nods do not perpetuate or add to the known risks.\nHowever, we acknowledge the methods could be\napplied to maliciously trained language models and\ndiscourage such uses.\n5012\nFigure 7: The instruction to annotators\nFigure 8: The questions to annotators\n5013\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□\u0013 A1. Did you describe the limitations of your work?\nLimitations section\n□\u0013 A2. Did you discuss any potential risks of your work?\nAppendix F\n□\u0013 A3. Do the abstract and introduction summarize the paper’s main claims?\nYes. Abstract and section 1\n□\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB □\u0013 Did you use or create scientiﬁc artifacts?\nSection 4\n□\u0013 B1. Did you cite the creators of artifacts you used?\nSection 4\n□\u0013 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\n4.1\n□\u0013 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\n4.1\n□ B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nNot applicable. Left blank.\n□\u0013 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\n4.1\n□\u0013 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\n4.1\nC □\u0013 Did you run computational experiments?\n4\n□\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\n4\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n5014\n□\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\n4\n□\u0013 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\n4\n□\u0013 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\n4\nD □\u0013 Did you use human annotators (e.g., crowdworkers) or research with human participants?\n4.2.2\n□\u0013 D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nappendix E\n□\u0013 D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nappendix E\n□\u0013 D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nappendix E\n□\u0013 D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\n4.2\n□ D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nNot applicable. Left blank.\n5015",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8184831142425537
    },
    {
      "name": "Relation (database)",
      "score": 0.6645611524581909
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.5958786606788635
    },
    {
      "name": "Crowdsourcing",
      "score": 0.5894140601158142
    },
    {
      "name": "Construct (python library)",
      "score": 0.5828648805618286
    },
    {
      "name": "Tuple",
      "score": 0.5807923674583435
    },
    {
      "name": "Knowledge graph",
      "score": 0.4951697885990143
    },
    {
      "name": "Artificial intelligence",
      "score": 0.42875513434410095
    },
    {
      "name": "Natural language processing",
      "score": 0.36862075328826904
    },
    {
      "name": "Information retrieval",
      "score": 0.3509749472141266
    },
    {
      "name": "Data mining",
      "score": 0.23441433906555176
    },
    {
      "name": "Programming language",
      "score": 0.14049163460731506
    },
    {
      "name": "World Wide Web",
      "score": 0.1316494643688202
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Discrete mathematics",
      "score": 0.0
    }
  ]
}