{
    "title": "On Automated Assistants for Software Development: The Role of LLMs",
    "url": "https://openalex.org/W4388483079",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2912645733",
            "name": "Mira Leung",
            "affiliations": [
                "University of British Columbia"
            ]
        },
        {
            "id": "https://openalex.org/A2660379905",
            "name": "Gail Murphy",
            "affiliations": [
                "University of British Columbia"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4321013654",
        "https://openalex.org/W4366587430",
        "https://openalex.org/W4221106082",
        "https://openalex.org/W4388858772",
        "https://openalex.org/W4366851162",
        "https://openalex.org/W6777901801",
        "https://openalex.org/W2905589099",
        "https://openalex.org/W2051098322",
        "https://openalex.org/W2162363818",
        "https://openalex.org/W2741371834",
        "https://openalex.org/W1987702312",
        "https://openalex.org/W1853657545",
        "https://openalex.org/W2113351233",
        "https://openalex.org/W2953723845",
        "https://openalex.org/W4239191916",
        "https://openalex.org/W6846870107",
        "https://openalex.org/W6853611289",
        "https://openalex.org/W6850936240",
        "https://openalex.org/W4238562525",
        "https://openalex.org/W4360836968",
        "https://openalex.org/W2810767260",
        "https://openalex.org/W4379539325",
        "https://openalex.org/W4309395891"
    ],
    "abstract": "Software developers handle many complex tasks that include gathering and applying domain knowledge, coordinating subtasks, designing interfaces, turning ideas into elegant code, and more. They must switch contexts between these tasks, incurring more cognitive costs. Recent advances in large language models (LLMs) open up new possibilities for moving beyond the support provided by automated assistants (AAs) available today. In this paper, we explore if a human memory model can provide a framework for the systematic investigation of AAs for software development based on LLMs and other new technologies.",
    "full_text": "On Automated Assistants for Software\nDevelopment: The Role of LLMs\nMira Leung\nUniversity of British Columbia\nV ancouver, BC\nmiralng@cs.ubc.ca\nGail Murphy\nUniversity of British Columbia\nV ancouver, BC\nmurphy@cs.ubc.ca\nAbstract—Software developers handle many complex tasks\nthat include gathering and applying domain knowledge, coordi-\nnating subtasks, designing interfaces, turning ideas into elegant\ncode, and more. They must switch contexts between these tasks,\nincurring more cognitive costs. Recent advances in large language\nmodels (LLMs) open up new possibilities for moving beyond the\nsupport provided by automated assistants (AAs) available today.\nIn this paper , we explore if a human memory model can provide\na framework for the systematic investigation of AAs for software\ndevelopment based on LLMs and other new technologies.\nIndex T erms—automation, machine learning, artiﬁcial intelli-\ngence, large language models, software development productivity\nI. I NTRODUCTION\nThe ability to automate software engineering (SE) tasks\nhas increased substantially with recent advances in generating\ncode with large language models (LLMs). Emerging research\non LLMs in SE has explored areas such as developer-LLM\ninteraction interfaces [1], [2], test case generation [3], and\nquality and security concerns of LLM-generated code [4]–[6].\nIn this paper, we step back and ask if a model of human\nmemory can help guide the development of future AAs for SE\nbased on LLMs or other emerging technologies. The model we\nexplore is Adaptive Control of Thought Rational (ACT-R) [7],\nwhich has distinct modules for declarative, production, and\nworking memory. Among other cognitive models, ACT-R’s\nhybrid architecture best balances production rules with infor-\nmation structuring, and aims to match human cognition [8].\nWe use the model to describe modular automation in the\ncontext of a common SE task, namely ﬁxing a race condition\nbug (Section II). We then introduce a framework to describe\nthree tiers of AAs for SE based on the model (Section III),\nexplain how it applies to the above bug (Section IV) and raise\nopen questions for future work (Section V). We weave earlier\nefforts applying cognitive models to SE tasks and AA support\nthroughout. Our paper makes three contributions:\n• We describe how the ACT-R memory model applies to\ncognitive processing needed in software development.\n• We present a novel, ACT-R-based framework to describe\nhow AAs might augment a developer’s cognitive capacity.\n• We describe a structured roadmap for future work in au-\ntomated assistants for SE, mainly those based on LLMs.\nThis work was partly funded via NSERC by a post-graduate scholarship and\na grant (RGPIN-2022-03139). The ﬁrst author is also afﬁliated with Google.\nII. ACT-R AND SE\nResearchers have long been interested in the cognitive pro-\ncesses at play in software development. For example, Robillard\ndiscussed key concepts such as declarative memory, chunking\nand planning, and their relation to software development [9].\nParnin applied cognitive concepts to understand how develop-\ners work on long-term tasks, despite frequent interruptions and\ntask switches [10]. Others considered the cognitive processes\nused for speciﬁc tasks such as program comprehension [11].\nMore recently, researchers sought to link aspects of cognition\ntheory with brain activity through fMRI studies [12].\nCommon to many of the models explored about cognitive\nprocesses in software development are the ideas that develop-\ners rely on knowledge, of both a given project and on domain\nbackground, and rely on strategies or procedures to use this\ninformation to complete tasks. These ideas are captured and\nstructured by Anderson’s ACT-R model that describes how the\nbrain structures knowledge [7].\nWe use this model in a novel way to explore how a devel-\noper’s work might be enhanced through automation. Much of\nthe automation work in SE has focused on replacing a single\nkind of task, such as generating tests or refactoring code [3],\n[13]. When looking at these tasks from the perspective of the\nACT-R memory model, we see an approach where assistants\ninstead automate pieces of these tasks, then work together\ntowards full automation. By focusing on individual parts, it\nmay be possible to build assistants that can be tailored to\nspeciﬁc projects, yet generalized to support automation of\nmore kinds of tasks, working in concert with the developer.\nIn the ACT-R model (Fig. 1a), declarative memory holds\nfacts, or declarative knowledge, which can be temporal. An\nexample of a long-lived fact is the binary search algorithm,\nwhereas a short-lived one might consist of the value of\nprogram variables in a given loop iteration.Production mem-\nory applies transformations to declarative knowledge. Finally,\nworking memoryperforms higher-level functions such as coor-\ndinating the declarative and production memory modules, stor-\ning interim results, and activating subsequent operations [14].\nTo illustrate how this model maps to a software development\ntask, consider a race condition bug in a Java project. A present-\nday developer may ﬁx this bug with the simpliﬁed journey\nbelow, with relevant memory modules shown in parentheses.\nWork licensed under Creative Commons Attribution NonCommercial, No Derivatives 4.0 License.\nhttps://creativecommons.org/licenses/by-nc-nd/4.0/\n1737\n2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)\nDOI 10.1109/ASE56229.2023.00035\n2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE) | 979-8-3503-2996-4-4-23 ©AUTHORS | DOI: 10.1109/ASE56229.2023.00035\n(a) ACT-R model.\n (b) Framework tier 1.\n (c) Framework tier 2\n (d) Framework tier 3.\nFig. 1: ACT-R as applied to human cognition (1a) and our developer-tool framework (1b-1d).\nT.A (Declarative/Working): Refresh knowledge on race con-\nditions, and understand the logic at potential error sites.\nT.B (Production/Working): Rank potential error sites in de-\nscending order of likelihood.\nT.C (Declarative/Working): Understand runtime behavior of\nthe top-ranked site fromT.B. Assuming this is the culprit,\nlook up example ﬁxes.\nT.D (Production/Working): Design the ﬁx.\nT.E (Production/Working): Implement the approach fromT.D.\nT.F (Production/Working): Write preventative tests.\nA developer tackling this bug must process different kinds\nof information as they perform these tasks, decide next steps,\nand apply transformations. ACT-R suggests that human cogni-\ntion power is proportional to the amount of knowledge stored\nand how effectively it is deployed, which leads us to ask: Can\nAAs increase a developer’s cognitive power?\nIII. D\nEVELOPER -TOOL INTERACTION TIERS IN SE\nWe introduce a framework, depicted in Fig. 1, that describes\nthree tiers in which modules, such as AAs, could help extend\nthe cognition of a software developer based on the ACT-R\nmodel. We illustrate this framework by exploring requirements\nfor these modules and anchoring them in present-day tools.\nThe ﬁrst tier of the framework introduces a module that\nextends the developer’s declarative memory, the second tier\nanother module that supplements their production memory,\nand in the third tier, a corresponding module that augments\ntheir working memory. We describe each tier in turn.\nA. Tier 1: Declarative Memory Extension\nIn this tier (Fig. 1b), declarative memory is extended with\nan external module that makes it easy to store and retrieve\ndeclarative knowledge through an integrated development en-\nvironment (IDE) or a similar set of tools. For this module\nto be most helpful to the developer, it should gather and\npresent all task-relevant declarative knowledge at once, which\nreduces context-switching for the developer while expanding\nthe capacity of their declarative memory.\nUsing the race condition example from Section II, a present-\nday developer’s initial declarative knowledge might consist of\nthe following facts: there are two or more threads accessing\none or more values, and multithreaded code areas are potential\ncauses. The developer might act upon this starting point to\ninform how they gather bits of knowledge for subtasks T.A\nand T.C via internet searches and code lookup tools. After-\nwards, they might keep these knowledge bits at hand across\nmany web browser and code editor tabs for easy access, and to\nsupport synthesizing varied facts in their declarative memory.\nB. Tier 2: Production Memory Extension\nTier 2 (Fig. 1c) would augment Tier 1’s capabilities by\nadding an externalized production module, again accessed\nthrough tooling like an IDE, to alleviate the developer’s pro-\nduction memory by taking on transformation sub-tasks such\nas architecture and code design, implementation, and writing\ntests. A production module can most beneﬁt a developer by\nreducing the manual labor needed to transform declarative\nknowledge, as long as it is provided with a description of the\nexpected output. This module can go beyond the principles\nin recommenders and refactoring tools [13], [15] to handle a\nwider variety of software development tasks.\nToday, a developer working on the race condition bug would\nhave to rely on their mental production memory to apply the\ntransformations in T.B, T.D, T.E, and T.F, as bug localization\ntools have not yet been widely adopted by industry developers.\nC. Tier 3: Working Memory Extension\nThis tier (Fig. 1d) would add an external working memory\nmodule to perform higher-level functions such as coordinating\nbetween the declarative and production modules from prior\n1738\ntiers, deciding what knowledge or transformations are needed,\nand keeping state of task status. These capabilities extend\nthe developer’s cognitive capacity by alleviating the mental\noverhead involved in coordination activities.\nTaking T.A as an example, the developer’s working memory\nmanages information gathering by evaluating if sufﬁcient\nknowledge has been gathered, and whether to continue the\nsearch. In T.B, the working memory gives the list of snippets\nto production memory with the transformation to apply.\nDevelopers today rely primarily on their own working\nmemory to manage and context-switch between declarative\nand production memory. Empirical studies of developers’ work\nin depth [16] help inform the kinds of tools that are likely\nneeded to support a developer’s working memory.\nIV . A F\nUTURE WORLD WITH AUTOMA TED ASSISTANTS\nWe use the race condition example from Section II to revisit\neach tier, to illustrate what each of their AAs can be, and to\nconsider how they can elevate a developer’s cognitive power.\nA. Tier 1 Example\nIn an environment with a declarative memory assistant,\ninstead of sequentially executing several internet and codebase\nsearches for T.A, a developer might pose a single question,\nsuch as “ Provide context on race conditions and potential\nerror sites in my codebase.” In response, the assistant would\nsearch the internet to provide a refresher on race conditions in\nJava, search the codebase for multithreaded areas, and return\nall this information together. ForT.C, the developer might ask\nthe declarative assistant to help explain the result, to which it\nmight invoke a debugger and report back on stateful behavior\nsuch as the value of variables in theith iteration of a loop.\nBy automating information-ﬁnding activities and reducing\nthe number of round trips between the developer’s declarative\nand working memory, this declarative assistant can help a\ndeveloper complete a task more efﬁciently.\nB. Tier 2 Example\nA second assistant would be added to Tier 1 to augment the\ndeveloper’s production memory abilities. A developer working\non subtask T.B would retrieve a list of all multithreaded code\nareas from the declarative assistant, then ask the production\nassistant to transform them into a ranked list of probabilities\nwhere the bug is most likely to occur. ForT.D, the developer\nwould ask the assistant to transform facts from the declarative\nassistant into a design for the selected approach.\nProduction assistants introduce the potential for parallelized\nworkﬂows. For instance, the assistant could apply several mit-\nigation options in T.B, instead of just implementing only one,\nwhich shares similar concepts with speculative execution [17].\nThis parallelization means the developer can examine the\nconcrete code of multiple solutions and their runtime behavior\nto choose the best one. Presently, implementing code requires\nsigniﬁcant developer time, which gives rise to the current\nworkﬂow of picking only one to implement based on design\nanalysis. However, if the chosen solution needs to be replaced\ndue to unanticipated side effects, the developer will have\nwasted their time on implementing the initial option. Tasks\nthat involve reducing execution time or machine memory\nusage would especially beneﬁt from this approach, since\nthe chosen solution’s interaction with existing behavior can\nworsen performance in ways that were not anticipated during\nthe pre-implementation design stage.\nC. Tier 3 Example\nImagine an IDE with a fully-featured working memory\nassistant added to the production and declarative assistants\nfrom Tier 2; an example interaction with the developer on\nthe race condition but is shown in Fig. 2. The developer\nwould start by asking the working memory assistant to ﬁx\nthe race condition (Step 1 in Fig. 2), to which the assistant\nwould interact with the declarative and production assistants\nto obtain the most likely error sites (Steps 2 and 3, which\nmap to T.A and T.B). The working memory assistant would\nthen conﬁrm the sites to ﬁx with the developer, who picks\none (Step 4 and 5) based on environmental factors such as the\ncode’s intended use. Next, the assistant asks the developer to\npick the most appropriate ﬁx from the ones suggested by the\ndeclarative assistant (Steps 6-8, equal to T.C), determines a\ntask list and the corresponding transformations to apply (Step\n9), then asks the production assistant to execute them (Step\n10, analogous to T.D to T.F), ﬁnishing the task.\nThe working memory assistant should consult the developer\nfor decisions that only a human can make. Examples include\n(a) where a ﬁx should be applied, (b) what kind of ﬁx is\ncorrect, and (c) what end-user needs to consider. For the race\ncondition bug, the developer might answer with (a) a race con-\ndition bug-ﬁx is not applicable to stateless code, (b) a generic\nJava ﬁx may not work for an Android app, and (c) runtime\nlatency is not an acceptable trade-off. These environmental\nfactors may ﬂuctuate in task-speciﬁc and project-speciﬁc ways,\nso the assistant should know when to seek human intervention.\nV. T\nHE ROLE OF LLM SI N S E-AR OADMAP\nThe concepts of the assistants in each tier are tantalizing,\nCan recent advances in LLMs help build these assistants?\nIn this section, we focus on unique opportunities for LLMs\nbased on mapping the ACT-R model to software development.\nWe recognize the challenges identiﬁed elsewhere with LLMs,\nsuch as hallucination or security against prompt injection\nattacks [18], but do not focus on them in this short paper.\nA. Declarative Assistant\nLLMs can effectively summarize knowledge [19], making\nthem a good foundation for declarative assistants. Instead\nof developers having to ﬁnd and assemble disparate bits of\ninformation like API documentation or code snippets, LLMs\ncan leapfrog that by providing answers to high-level questions.\nCurrently, LLMs are focused not only on extracting and\nassembling bits of knowledge, but also on synthesis. For\nthe purposes of a declarative assistant, it might be helpful\nfor LLM technology to produce bits of knowledge without\n1739\nFig. 2: Simpliﬁed Tier 3 developer-tool workﬂow for the race condition bug. Steps are shown with numbers and grey arrows.\nsynthesizing them together, or synthesizing smaller bits at a\ntime. A focus on smaller nuggets of synthesized facts may\nbe easier for a developer or tool to verify. Nascent efforts are\nemerging in this area, such as recent end-user tools that begin\nto provide interactive citations in LLM-generated content [20].\nHowever, verifying bits of knowledge still requires a broader\ninvestigation into what sources are considered reliable, and\nwhat text metrics or human-computer interaction models can\nensure and inspire human conﬁdence in factual accuracy.\nOpen questions remain on how LLMs can help build such\na declarative assistant. For one, how can an LLM be cus-\ntomized to a developer’s project environment, like language\nor library versions, so that returned answers are relevant? As\nanother example, what is the most appropriate way to present\ninformation so the developer can process it easily? A helpful\nformat could involve connecting nodes of knowledge pieces\nas a network graph, a mental structure that is currently hard\nto decipher from the content generated by present-day LLMs.\nB. Production Assistant\nProduction assistants focus on applying transformations\nto declarative knowledge, which can be built upon LLMs\nsince they can perform transformations like natural language\ntranslations or code generation [6], [21]. While developer tasks\nalso involve transformations, bridging the large gap between\nan initial problem statement (e.g., ﬁx a race condition bug) and\nits ﬁnal solution requires us to address many open questions.\nCould LLMs be helpful for a production memory assistant\nif specialized for particular tasks, like separating design pro-\nduction from code generation? Or should there be access to the\ninternal steps of an LLM? How could correctness be managed\nin this LLM, such that its transformations always produce valid\nand correct results, or emits errors otherwise? How could we\nensure the assistant can detect, and return errors, when it is\ngiven insufﬁcient input or bad transformations?\nC. Working Memory Assistant\nAre LLMs appropriate as working memory assistants? Early\nexperiments such as Auto-GPT signal possible directions for\nfuture research, but recent evaluations show there exists room\nfor growth [22]. Working memory necessitates comprehension\nof a task and its domain, strategizing ways to solve the\ntask, and adapting to environmental factors such as problem\nconstraints. LLMs currently lack these and other higher level\ncognitive functions typically attributed to Artiﬁcial General\nIntelligence (AGI) [23]. Thus, AGI may be a more appropriate\nbuilding block for working memory assistants.\nHow could an AGI assistant know how to adapt problem-\nsolving strategies or make conceptual leaps while working\non task? Unlike well-deﬁned domains like chess, software\ndevelopment tasks can be highly varied depending on factors\nlike program behavior, library dependencies, and external\nworld constraints, to name a few. Can project management\nand decision-making skills be developed in an AGI assistant,\nsuch that it can and adapt its instructions to mitigate any\ndeﬁciencies in the output of the declarative and production\nassistants? If a generated solution is insufﬁcient, how might\nthis AGI assistant know when, and where, in the lifecycle of\na task to solicit human intervention? Further, how would it\nlearn from its experiences to improve continuously for future\ntasks? Challenges like these remain to advance AGI assistants,\nparticularly for building the strategizing and cognitive abilities\nneeded to meaningfully assist software developers.\nVI. C\nONCLUSION\nApplying an ACT-R model to the work of a software de-\nveloper shows promise for teasing apart the different kinds of\ncognitive support needed to augment a developer’s capabilities.\nViewing a developer’s work through this model suggests ways\nin which LLMs can best augment human capabilities through\nmodular automation of parts or all of software development\ntasks. The path to build these assistants raises exciting chal-\nlenges for the future research needed to achieve this vision.\nVII. A\nCKNOWLEDGMENT\nWe gratefully acknowledge the reviews and helpful com-\nments by reviewers on an earlier version of this paper.\n1740\nREFERENCES\n[1] S. I. Ross, F. Martinez, S. Houde, M. Muller, and J. D. Weisz,\n“The programmers assistant: Conversational interaction with a large\nlanguage model for software development,” inProceedings of the 28th\nInternational Conference on Intelligent User Interfaces, 2023, pp. 491–\n514.\n[2] A. M. McNutt, C. Wang, R. A. Deline, and S. M. Drucker, “On the\ndesign of ai-powered code assistants for notebooks,” inProceedings of\nthe 2023 CHI Conference on Human Factors in Computing Systems,\n2023, pp. 1–16.\n[3] Z. Khaliq, S. U. Farooq, and D. A. Khan, “Transformers for gui testing:\nA plausible solution to automated test case generation and ﬂaky tests,”\nComputer, vol. 55, no. 3, pp. 64–73, 2022.\n[4] S. Houde, V . Radhakrishna, P . Reddy, J. Darwade, H. Hu, K. Krishna,\nM. Agarwal, K. Talamadupula, and J. Weisz, “User and technical\nperspectives of controllable code generation,” inAnnual Conference on\nNeural Information Processing Systems, 2022.\n[5] N. Perry, M. Srivastava, D. Kumar, and D. Boneh, “Do users write more\ninsecure code with ai assistants?” arXiv preprint arXiv:2211.03622,\n2022.\n[6] B. Y etis ¸tiren, I.¨Ozsoy, M. Ayerdem, and E. T ¨uz¨un, “Evaluating the\ncode quality of ai-assisted code generation tools: An empirical study\non github copilot, amazon codewhisperer, and chatgpt,” arXiv preprint\narXiv:2304.10778, 2023.\n[7] J. R. Anderson, “Production systems and the act-r theory,”Rules of the\nmind, pp. 17–44, 1993.\n[8] F. E. Ritter, F. Tehranchi, and J. D. Oury, “Act-r: A cognitive architecture\nfor modeling cognition,” Wiley Interdisciplinary Reviews: Cognitive\nScience, vol. 10, no. 3, p. e1488, 2019.\n[9] P . N. Robillard, “The role of knowledge in software development,”\nCommunications of the ACM, vol. 42, no. 1, pp. 87–92, 1999.\n[10] C. Parnin, “A cognitive neuroscience perspective on memory for pro-\ngramming tasks.”\n[11] A. V on Mayrhauser and A. M. V ans, “Program comprehension during\nsoftware maintenance and evolution,”Computer, vol. 28, no. 8, pp. 44–\n55, 1995.\n[12] J. Siegmund, N. Peitek, C. Parnin, S. Apel, J. Hofmeister, C. K¨astner,\nA. Begel, A. Bethmann, and A. Brechmann, “Measuring neural efﬁ-\nciency of program comprehension,” in Proceedings of the 2017 11th\nJoint Meeting on F oundations of Software Engineering, 2017, pp. 140–\n150.\n[13] J. Hannemann, G. C. Murphy, and G. Kiczales, “Role-based refactoring\nof crosscutting concerns,” in Proceedings of the 4th international con-\nference on Aspect-oriented software development, 2005, pp. 135–146.\n[14] M. C. Lovett, L. M. Reder, and C. Lebiere, “Modeling working memory\nin a uniﬁed architecture: An act-r perspective.” 1999.\n[15] J. Anvik and G. C. Murphy, “Reducing the effort of bug report triage:\nRecommenders for development-oriented decisions,”ACM Transactions\non Software Engineering and Methodology (TOSEM), vol. 20, no. 3, pp.\n1–35, 2011.\n[16] S. Chattopadhyay, N. Nelson, Y . R. Gonzalez, A. A. Leon, R. Pandita,\nand A. Sarma, “Latent patterns in activities: A ﬁeld study of how\ndevelopers manage context,” in 2019 IEEE/ACM 41st International\nConference on Software Engineering (ICSE). IEEE, 2019, pp. 373–\n383.\n[17] K. Mus ¸lu, Y . Brun, R. Holmes, M. D. Ernst, and D. Notkin, “Specula-\ntive analysis of integrated development environment recommendations,”\nACM SIGPLAN Notices, vol. 47, no. 10, pp. 669–682, 2012.\n[18] F. Perez and I. Ribeiro, “Ignore previous prompt: Attack techniques for\nlanguage models,” arXiv preprint arXiv:2211.09527, 2022.\n[19] Z. Luo, Q. Xie, and S. Ananiadou, “Chatgpt as a factual incon-\nsistency evaluator for abstractive text summarization,” arXiv preprint\narXiv:2303.15621, 2023.\n[20] S. Hsiao, “Whats ahead for bard: More global, more visual,\nmore integrated,” May 2023. [Online]. Available: https://blog.google/\ntechnology/ai/google-bard-updates-io-2023\n[21] W. Jiao, W. Wang, J.-t. Huang, X. Wang, and Z. Tu, “Is chatgpt a good\ntranslator? a preliminary study,”arXiv preprint arXiv:2301.08745, 2023.\n[22] H. Y ang, S. Y ue, and Y . He, “Auto-gpt for online decision making:\nBenchmarks and additional opinions,”arXiv preprint arXiv:2306.02224,\n2023.\n[23] S. Bubeck, V . Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Ka-\nmar, P . Lee, Y . T. Lee, Y . Li, S. Lundberget al., “Sparks of artiﬁcial\ngeneral intelligence: Early experiments with gpt-4,” arXiv preprint\narXiv:2303.12712, 2023.\n1741"
}