{
  "title": "Few-Shot Semantic Parsing with Language Models Trained on Code",
  "url": "https://openalex.org/W4226226396",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2113353992",
      "name": "Richard Shin",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2113965177",
      "name": "Benjamin Van Durme",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4226242393",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4287024925",
    "https://openalex.org/W3105388824",
    "https://openalex.org/W3206547074",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W3214600982",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W3104713013",
    "https://openalex.org/W3173157360",
    "https://openalex.org/W2251957808",
    "https://openalex.org/W3156012351"
  ],
  "abstract": "Large language models can perform semantic parsing with little training data, when prompted with in-context examples. It has been shown that this can be improved by formulating the problem as paraphrasing into canonical utterances, which casts the underlying meaning representation into a controlled natural language-like representation. Intuitively, such models can more easily output canonical utterances as they are closer to the natural language used for pre-training. Recently, models also pre-trained on code, like OpenAI Codex, have risen in prominence. For semantic parsing tasks where we map natural language into code, such models may prove more adept at it. In this paper, we test this hypothesis and find that Codex performs better on such tasks than equivalent GPT-3 models. We evaluate on Overnight and SMCalFlow and find that unlike GPT-3, Codex performs similarly when targeting meaning representations directly, perhaps because meaning representations are structured similar to code in these datasets.",
  "full_text": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 5417 - 5425\nJuly 10-15, 2022 ©2022 Association for Computational Linguistics\nFew-Shot Semantic Parsing with Language Models Trained on Code\nRichard Shin\nMicrosoft Semantic Machines\nrichard.shin@microsoft.com\nBenjamin Van Durme\nMicrosoft Semantic Machines\nben.vandurme@microsoft.com\nAbstract\nLarge language models can perform semantic\nparsing with little training data, when prompted\nwith in-context examples. It has been shown\nthat this can be improved by formulating the\nproblem as paraphrasing into canonical utter-\nances, which casts the underlying meaning rep-\nresentation into a controlled natural language-\nlike representation. Intuitively, such models\ncan more easily output canonical utterances as\nthey are closer to the natural language used\nfor pre-training. Recently, models also pre-\ntrained on code, like OpenAI Codex, have risen\nin prominence. For semantic parsing tasks\nwhere we map natural language into code, such\nmodels may prove more adept at it. In this pa-\nper, we test this hypothesis and ﬁnd that Codex\nperforms better on such tasks than equivalent\nGPT-3 models. We evaluate on Overnight and\nSMCalFlow and ﬁnd that unlike GPT-3, Codex\nperforms similarly when targeting meaning rep-\nresentations directly, perhaps because meaning\nrepresentations are structured similar to code\nin these datasets.\n1 Introduction\nSemantic parsing is the task of mapping natural\nlanguage to a target meaning representation. Many\napproaches have been explored by the community,\nincluding a recent focus on the use of large au-\ntoregressive language models (LMs). Such pre-\ntrained LMs can achieve surprising levels of ac-\ncuracy with relatively small numbers of examples.\nFurther gains have come from constraining a de-\ncoder to only consider syntactically valid outputs.\nHistorically, language models have been con-\nstructed using a large collection of natural lan-\nguage. And yet, the term “language” clearly applies\nto non-natural languages as well. Very large mod-\nels have been trained on mixed corpora, explicitly\ncurated to include code (programming language)\nas well as natural language. Examples include\nGPT-J (Wang and Komatsuzaki, 2021), MT-NLG\n(Kharya and Alvi , 2021), and Gopher ( Rae et al. ,\n2021), with OpenAI Codex ( Chen et al. , 2021),\nPaLM-Coder (Chowdhery et al. , 2022), and Austin\net al. (2021) particularly focused on code.\nWe revisit few-shot semantic parsing experi-\nments from Shin et al. (2021), which used GPT-3\nwith constrained decoding into a controlled sublan-\nguage of English (canonical utterances) then trans-\nlated the canonical utterance output into the mean-\ning representation using a synchronous context-free\ngrammar (SCFG). In this work, we perform similar\nexperiments on the Overnight ( Wang et al. , 2015)\nand SMCalFlow ( Andreas et al. , 2020) datasets, 1\nbut using OpenAI Codex instead. As Codex has\nbeen trained on code, including natural language\ncomments that explain its intent, we hypothesize\nthat Codex will be more adept at semantic parsing\nfor meaning representations resembling code.\nIn this work, we ﬁnd that:\n• Codex substantially narrows the gap in accuracy\nbetween predicting meaning representations di-\nrectly versus canonical utterances, thus obviat-\ning the need to deﬁne canonical utterances. We\nobserve this even though the meaning represen-\ntations use bespoke languages, rather than ones\nlike Python which frequently appeared in the\ntraining data.\n• Surprisingly, Codex also generates canonical\nutterances more accurately than GPT-3, even\nthough those look more like English than code.\n• Even with Codex, constrained decoding with a\nCFG and a non-greedy search procedure are still\nvaluable in providing improved accuracy.\n• Speculative constrained decoding, an adaptation\nof Poesia et al. (2022, Appendix F), gives com-\nparable accuracy as beam search but with greater\nefﬁciency, on the language model APIs provided\nby OpenAI.\n1Both are in English and available under CC BY-SA 4.0.\n5417\nDataset Natural language Canonical utterance Meaning representation\nSMCalFlow Schedule Hide and\nSeek in the mall for\nSaturday night\ncreate event called\n\"Hide and Seek\"\nstarting next Satur-\nday night at \"mall\"\n(Yield :output (CreateCommitEventWrapper :event\n(CreatePreflightEventWrapper :constraint\n(Constraint[Event] :subject (?= #(String\n\"Hide and Seek\")) :start (DateTimeConstraint\n:constraint (Night) :date (NextDOW :dow\n#(DayOfWeek \"SATURDAY\"))) :location (?=\n#(LocationKeyphrase \"mall\"))))))\nOvernight Cal. which meeting has\nthe earliest end time\nmeeting that has the\nsmallest end time\n(call listValue (call superlative (call\ngetProperty (call singleton en.meeting) (string\n!type)) (string min) (call ensureNumericProperty\n(string end_time))))\nTable 1: Examples from the Overnight Calendar and SMCalFlow datasets.\n2 Preliminaries\n2.1 Constrained language model parsing\nIn semantic parsing, our goal is to convert an ut-\nterance u into the meaning representation m. We\nuse the same approach as Shin et al. (2021): (1)\npriming the underlying language model with dy-\nnamically created prompts, (2) constrained decoder,\nand (3) optionally using a canonical utterance c as\nthe target output instead of m.\nSince GPT-3 and Codex can perform in-context\nfew-shot learning(Brown et al. , 2020), we retrieve\n20 (ui, mi) pairs most similar 2 to u from the train-\ning set, then translate mi into ci if using canonical\nutterances, to form the prompt p which looks like:\nLet's translate what a human user says\ninto what a computer might say.\nHuman: when is the standup ←u1\nComputer: start time of \"standup\" ←c1\nHuman: what date is the standup ←u2\nComputer: date of \"standup\" ←c2\n[...]\nHuman: how long is the daily standup ←u\nComputer:\nwhere italics are annotations for exposition in this\npaper, and not included verbatim in the prompt.\nWe then generate a completion for p using the\nlanguage model, which we will take as the pre-\ndicted value of canonical utterance c or meaning\nrepresentation m, depending on our choice for (3).\nTo ensure that the generated completion is well-\nformed, we assume the existence of a function\nnextTokens(s) = {wi} ⊆ V ∪ { EOS}. For a\ngiven preﬁx s of a canonical utterance or meaning\nrepresentation, this function returns the set of sub-\nsequent tokens that we can can append to s such\nthat it remains a preﬁx of a well-formed c or m.\n2We use GPT-3 itself for this, following Shin et al. (2021).\nThe similarity function is identical for all our experiments,\nregardless of whether we use GPT-3 or Codex for decoding.\nIt also indicates whether s is already a complete,\nwell-formed c or m by including EOS in the result;\nif nextTokens(s) = {EOS}, then s is a valid\ncanonical utterance or meaning representation with\nno possible extensions.\nAs an example, nextTokens(“start\ntime”) would contain of, but not EOS or in.\nWe use nextTokens to ﬁlter candidates from\nthe language model such that it only generates\ngrammatical outputs; if we build the completion\nby appending what nextTokens advises, we are\nguaranteed to obtain a grammatically conformant\noutput. We implement nextTokens using a\ntrie and a CFG for Overnight and SMCalFlow,\nrespectively.\n2.2 OpenAI language models\nOpenAI operates a service offering GPT-3 ( Brown\net al. , 2020) through a networked API. The API\nincludes multiple variants of GPT-3, named Ada,\nBabbage, Curie, and Davinci, with the model size\nincreasing in that order. Two Codex ( Chen et al. ,\n2021) models, which had code from GitHub in-\ncluded in their training data, are also offered. They\nare named Cushman Codex and Davinci Codex. 3\nThe primary use case for the API is generating\ncompletions from a preﬁx, by sequentially sam-\npling from p(wn|w1w2 · · · wn−1) until some limit\nis reached. The API provides for specifying a soft-\nmax temperature to modify this distribution, for\nexample enabling greedy argmax sampling with a\ntemperature of 0.0. The API also allows for directly\nquerying p(wn|w1w2 · · · wn−1), but only returns\nprobabilities for up to 100 most likely tokens; we\nuse this capability for constrained beam search.\n3We used the models available in late 2021; OpenAI may\nchange them from time to time.\n5418\n2.3 Experimental setup\nWe used two of the datasets from Shin et al. (2021)\nfor our experiments. We build on their released\ncode and use the same subsets of the training data.\nWe brieﬂy describe some of the details below.\nOvernight. This dataset from Wang et al. (2015)\ncontains 13,682 examples across eight different\ndomains, curated to exhibit a variety of linguistic\nphenomena and semantic structures. We used 200\nrandomly-sampled training examples for each do-\nmain, and evaluate on the domains separately. For\nevaluation, we use denotational accuracy, based on\ncomparing the execution results of the predicted\nand reference programs.\nSMCalFlow. Introduced in Andreas et al. (2020),\nthis task-oriented dialogue dataset consists of con-\nversations about calendars, weather, places, and\npeople. Each utterance u is annotated with dataﬂow\nprograms m containing function composition, com-\nplex constraints, and references to computations\nfrom previous turns. Of the 133,821 (ui, mi) pairs\nin training, we use a stratiﬁed sample of 300 for\nour experiments, following Shin et al. (2021). For\nevaluation, we use syntactical match between the\npredicted and reference programs, which requires\nthem to be structurally identical but allows differ-\nences of spacing and named arguments in function\ncalls.\nTest set sampling for certain experiments.As\nusage of GPT-3 and Codex requires signiﬁcant\nresources, we conduct our initial experiments\non smaller subsets of the evaluation sets. For\nOvernight, we used 100 uniformly sampled exam-\nples from test set for the calendar domain. For\nSMCalFlow, we used 200 uniformly sampled ex-\namples from the validation set.\nWe used the subsets for the experiments de-\nscribed in Sections 3.1 to 3.4. In the ﬁnal ex-\nperiments of Section 3.5, we use the full test set\nfor Overnight and the full validation set for SM-\nCalFlow.\n3 Experiments\n3.1 Comparing GPT-3 and Codex\nTable 2 summarizes our initial comparison of the\nGPT-3 and Codex models when applied to se-\nmantic parsing. Davinci Codex performs better\nthan Davinci on both Overnight Calendar and SM-\nCalFlow when using identical settings. More inter-\nAccuracy\nModel Overnight Cal. SMCalFlow\nDavinci 0.81 0.340\nCurie 0.66 0.260\nDavinci Codex 0.86 0.355\nCushman Codex 0.87 0.320\nTable 2: Comparing various OpenAI models using con-\nstrained decoding to generate canonical utterances, with\nbeam search having beam size 5. These results are on\n100 sampled test examples. The larger Davinci models\ndo better, the Codex models show better performance.\nestingly, Cushman Codex, which is one step down\nfrom Davinci Codex, performs substantially better\nthan Curie, which is one step down from Davinci.\nThese results support our hypothesis that language\nmodels trained on code can perform better at se-\nmantic parsing.\n3.2 Targeting canonical utterances versus\nmeaning representations\nAccuracy\nModel Canonical Meaning C −M\nDavinci 0.81 0.68 0.13\nDavinci Codex 0.86 0.86 0.00\n(a) Overnight Calendar\nAccuracy\nModel Canonical Meaning C −M\nDavinci 0.340 0.245 0.095\nDavinci Codex 0.355 0.345 0.010\n(b) SMCalFlow\nTable 3: Differences in accuracy when using canonical\nutterances versus directly using meaning representations.\nDavinci Codex performs better on canonical utterances,\nbut the gap is much smaller than with Davinci. Results\nusing constrained decoding with beam size 5.\nShin et al. (2021) demonstrated that as language\nmodels have (conventionally) been trained to gen-\nerate natural language, we would beneﬁt by for-\nmulating semantic parsing as paraphrasing into a\ncontrolled sublanguage of English. In Table 3, we\ninvestigate whether that still holds true when us-\ning Codex. We observe that when using GPT-3\n(Davinci), targeting meaning representations can\nresult in more than a 25% relative drop in accuracy.\nIn contrast, Davinci Codex exhibits no or a very\nsmall drop in accuracy when targeting meaning\nrepresentations.\nNotably, the meaning representations used for\nOvernight and SMCalFlow are in Lisp-like lan-\n5419\nguages, rather than in programming languages com-\nmon on GitHub. Our experiments indicate that\nCodex can nevertheless pick up on the semantics\nwith only a few examples in the prompt.\nHaving canonical utterances as the target output\nstill performs better than meaning representations.\nThis holds true even though our evaluation proce-\ndure ﬁrst translates canonical utterances back into\nmeaning representations, which is a lossy proce-\ndure for SMCalFlow as described in ( Shin et al. ,\n2021). However, designing a suitable system of\ncanonical utterances is a non-trivial effort. The\nsmaller performance gap we observe with Codex\nchanges the cost/beneﬁt calculations on authoring\nSCFGs.\n3.3 Value of constraints and beam search\nAs mentioned in Section 2.2, the primary capability\nof OpenAI’s API is generating completions from a\npreﬁx using sequential sampling. Their documen-\ntation4 suggests using it that way to generate code\nfrom comments, a similar task to semantic pars-\ning. Nevertheless, we see in Table 4 that the use\nof constraints and beam search lead to beneﬁts in\naccuracy. Even with constrained decoding, greedy\nargmax sampling (equivalent to a beam size of 1)\nperforms worse than using beam search.\nAccuracy\nDecoding Beam Overnight Cal. SMCalFlow\nConstrained 5 0.86 0.345\nConstrained 1 0.75 0.300\nUnconstrained 5 0.80 0.315\nUnconstrained 1 0.73 0.280\nTable 4: Results comparing constrained with uncon-\nstrained decoding and multiple beam sizes, when gen-\nerating meaning representations. Even when using\nDavinci Codex, trained speciﬁcally on code, constrained\ndecoding and beam search lead to higher accuracy.\n3.4 Speculative constrained decoding\nWhile constrained decoding and beam search im-\nprove accuracy, they are slow to perform with Ope-\nnAI’s API. Extending a partial hypothesis requires\none network round-trip per token. The API lacks\nstate and so each request includes the prompt and\nall previously generated tokens. In the worst case,\nthe statelessness implies decoding will take O(n3)\ncomplexity rather than the typical O(n2) of trans-\nformers due to needing to re-encode the preﬁx each\n4https://beta.openai.com/docs/guides/\ncompletion/working-with-code\ntime. Even if the hidden states for previous tokens\nwere cached, their retrieval and transfer to GPUs\nor other accelerators takes overhead.\nAs such, we adapt a method from Synchromesh\n(Poesia et al. , 2022, Appendix F) to obtain the ben-\neﬁts of beam search and constrained decoding with\ngreater efﬁciency. We extend Synchromesh’s ap-\nproach with a width parameter W , which functions\nsimilar to the beam size. We call it speculative\nconstrained decoding.\nTo expand a partial hypothesis in the search, we\nquery the API to create W completions with soft-\nmax temperature T .5 The API samples from the\nmodel, without reference to any grammars, until\nEOS is sampled or a length limit is reached. Using\nthe nextTokens function, we check each of the\nW completions left-to-right until we encounter an\ninvalid token, and truncate there so that we only\nhave valid tokens; we return the truncated comple-\ntions as new hypotheses. If no completion contains\nany valid tokens, then we query the API for the\nW best tokens and return those as new hypothe-\nses. As done in beam search, we start with a single\nempty hypothesis, and keep the W best expansions\nat each step. We stop after 16 steps if W com-\nplete hypotheses were not generated by then. More\ndetails are in Appendix D.\nTable 5 shows the results from trying various\nvalues for W and T , along with beam search for\nW = 1 and W = 5. When W = 1 and T = 0,\nwhich is equivalent to Synchromesh’s approach, we\nobtain very similar results to constrained greedy\ndecoding (beam size 1). However, speculative con-\nstrained decoding is substantially faster.\nIn order to obtain results comparable to beam\nsearch with beam size 5, we require W = 5or 10.\nIn comparison, Synchromesh only supports W = 1.\nWe see notable speedups compared to beam search,\nbut typically obtain comparable accuracy.\nWe also observe that we can generate gener-\nate canonical utterances more quickly than mean-\ning representations, as the canonical utterances are\nshorter. However, these timing results do not in-\nclude the time required to convert canonical utter-\nances into meaning representations.\n5The softmax function with temperature T computes\nexp(xi/T )∑|V |\nj=1 exp(xj/T )\n, to compute probabilities for each of the\n|V |tokens in the vocabulary. As T approaches 0, the output\nbecomes 1 for the largest value of xi and 0 for all others,\neffectively computing the argmax.\n5420\nOvernight Calendar SMCalFlow\nAccuracy Items/second Accuracy Items/second\nWidth Temperature Canonical Meaning Canonical Meaning Canonical Meaning Canonical Meaning\n1 0.0 0.86 0.76 0.520 0.246 0.300 0.320 0.193 0.184\n1 BS 0.84 0.75 0.237 0.059 0.305 0.300 0.116 0.040\n5 0.5 0.87 0.80 0.380 0.155 0.335 0.315 0.076 0.140\n5 1.0 0.87 0.85 0.260 0.145 0.325 0.330 0.076 0.034\n5 BS 0.86 0.86 0.133 0.030 0.355 0.345 0.065 0.008\n10 0.5 0.87 0.86 0.355 0.150 0.345 0.345 0.038 0.085\n10 1.0 0.87 0.85 0.193 0.068 0.370 0.335 0.028 0.014\nTable 5: Comparing various settings on speculative constrained decoding with beam search. “BS” indicates use of\nbeam search. Speculative constrained decoding gets similar accuracy as beam search, but at higher speed.\n3.5 Putting everything together\nAccuracy\nModel Overnight Avg. SMCalFlow\nShin et al. (2021),\nConstrained Canonical 0.765 0.32\nShin et al. (2021),\nConstrained Meaning 0.657* 0.25*\nOurs, Canonical 0.785 0.342\nOurs, Meaning 0.750 0.330\nTable 6: Comparison to Shin et al. (2021). Results are on\nthe entire test set for Overnight and the entire dev set for\nSMCalFlow. For Overnight, we took a simple average\nof the accuracy for each of the 8 domains. Results\nmarked with * are on subsampled evaluation sets. We\nused speculative constrained decoding with a width of\n10 and a temperature of 0.5.\nAs explained in Section 2.3, earlier results in this\narticle are based on smaller subsets of the evalua-\ntion sets due to resource limitations. In Table 6, we\nevaluate on the full evaluation sets using lessons\nlearned from our previous experiments. We achieve\nbetter accuracies than when Shin et al. (2021) used\nGPT-3. We re-conﬁrm Section 3.2 that Codex per-\nforms nearly as well at meaning representations as\ncanonical utterances.\n4 Related Work\nChen et al. (2020) observed that for low-\nresource semantic parsing, ﬁne-tuning a pretrained\nsequence-to-sequence model improved over the use\nof a pretrained encoder only. Scholak et al. (2021),\nWu et al. (2021), and Shin et al. (2021) each pro-\nposed the use of constrained decoding for semantic\nparsing with LMs. The latter two works argued\nthat language models were best used to parse lan-\nguage into controlled natural language, rather than\ndirectly to a code-like representation. Here we con-\nsider whether that conclusion changes based on\nnew LMs that are trained with code.\nPasupat et al. (2021) proposed a retrieval-\naugmented solution to semantic parsing, which\nrelates to the dynamic prompt selection of Shin\net al. (2021), and which we followed here without\nalteration. Future work may consider the impact of\nmore advanced prompt selection techniques.\n5 Conclusion\nWe investigate the use of OpenAI Codex, a large\nlanguage model trained on code, for few-shot se-\nmantic parsing. We ﬁnd that it performs better\nthan GPT-3 for our tasks. While constrained de-\ncoding and a non-greedy decoding procedure still\nnon-trivially improve accuracy, mapping to canoni-\ncal natural language is no longer as important with\nCodex, thereby lightening the burden on develop-\ning few shot semantic parsers based on large LMs.\nEthical Considerations\nOur work heavily relies on OpenAI’s GPT-3 and\nCodex models, which are large language models\ntrained on big datasets. Such language models may\nreﬂect biases present in their training data ( Brown\net al. , 2020; Bender et al. , 2021). However, our\nuse of constrained decoding largely mitigates the\nrisks from such bias as we only allow the model to\ngenerate outputs allowed by a small grammar. Fur-\nthermore, the outputs are interpreted by machines\nrather than directly shown to humans. The potential\nfor harm may increase when the grammars used in\nconstrained decoding allow for a wider variety of\noutputs (such as including unconstrained free-text\nﬁelds), and if semantic parsing is used for particu-\nlarly sensitive domains.\nAcknowledgements\nWe would like to thank Adam Pauls, Jason Eisner,\nMatt Gardner, and other colleagues at Microsoft Se-\n5421\nmantic Machines, who provided helpful feedback\nand engaged in stimulating discussions which have\ngreatly improved the paper.\nReferences\nJacob Andreas, John Bufe, David Burkett, Charles\nChen, Josh Clausman, Jean Crawford, Kate Crim,\nJordan DeLoach, Leah Dorner, Jason Eisner, Hao\nFang, Alan Guo, David Hall, Kristin Hayes, Kellie\nHill, Diana Ho, Wendy Iwaszuk, Smriti Jha, Dan\nKlein, Jayant Krishnamurthy, Theo Lanman, Percy\nLiang, Christopher H. Lin, Ilya Lintsbakh, Andy Mc-\nGovern, Aleksandr Nisnevich, Adam Pauls, Dmitrij\nPetters, Brent Read, Dan Roth, Subhro Roy, Jesse\nRusak, Beth Short, Div Slomin, Ben Snyder, Stephon\nStriplin, Yu Su, Zachary Tellman, Sam Thomson, An-\ndrei V orobev, Izabela Witoszko, Jason Wolfe, Abby\nWray, Yuchen Zhang, and Alexander Zotov. 2020.\nTask-oriented dialogue as dataﬂow synthesis . Trans-\nactions of the Association for Computational Linguis-\ntics, 8:556–571.\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten\nBosma, Henryk Michalewski, David Dohan, Ellen\nJiang, Carrie J. Cai, Michael Terry, Quoc V . Le, and\nCharles Sutton. 2021. Program synthesis with large\nlanguage models. CoRR, abs/2108.07732.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language mod-\nels be too big? In Proceedings of the 2021 ACM\nConference on Fairness, Accountability, and Trans-\nparency, FAccT ’21, page 610623, New York, NY ,\nUSA. Association for Computing Machinery.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen,\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam Mc-\nCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020. Language models are few-shot learn-\ners. CoRR.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan,\nHenrique Ponde de Oliveira Pinto, Jared Kaplan,\nHarrison Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, Alex Ray, Raul Puri, Gretchen\nKrueger, Michael Petrov, Heidy Khlaaf, Girish Sas-\ntry, Pamela Mishkin, Brooke Chan, Scott Gray,\nNick Ryder, Mikhail Pavlov, Alethea Power, Lukasz\nKaiser, Mohammad Bavarian, Clemens Winter,\nPhilippe Tillet, Felipe Petroski Such, Dave Cum-\nmings, Matthias Plappert, Fotios Chantzis, Eliza-\nbeth Barnes, Ariel Herbert-V oss, William Hebgen\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie\nTang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\nWilliam Saunders, Christopher Hesse, Andrew N.\nCarr, Jan Leike, Joshua Achiam, Vedant Misra, Evan\nMorikawa, Alec Radford, Matthew Knight, Miles\nBrundage, Mira Murati, Katie Mayer, Peter Welinder,\nBob McGrew, Dario Amodei, Sam McCandlish, Ilya\nSutskever, and Wojciech Zaremba. 2021. Evaluat-\ning large language models trained on code . CoRR,\nabs/2107.03374.\nXilun Chen, Asish Ghoshal, Yashar Mehdad, Luke\nZettlemoyer, and Sonal Gupta. 2020. Low-resource\ndomain adaptation for compositional task-oriented\nsemantic parsing . In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 5090–5100, Online. As-\nsociation for Computational Linguistics.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pil-\nlai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022. Palm: Scaling language mod-\neling with pathways . CoRR, abs/2204.02311.\nParesh Kharya and Ali Alvi. 2021. Using DeepSpeed\nand Megatron to Train Megatron-Turing NLG 530B,\nthe Worlds Largest and Most Powerful Generative\nLanguage Model. https://developer.nvid\nia.com/blog/using-deepspeed-and-me\ngatron-to-train-megatron-turing-nl\ng-530b-the-worlds-largest-and-most\n-powerful-generative-language-mode\nl.\nPanupong Pasupat, Yuan Zhang, and Kelvin Guu. 2021.\nControllable semantic parsing via retrieval augmen-\ntation. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 7683–7698, Online and Punta Cana, Domini-\ncan Republic. Association for Computational Lin-\nguistics.\nGabriel Poesia, Alex Polozov, Vu Le, Ashish Tiwari,\nGustavo Soares, Chris Meek, and Sumit Gulwani.\n2022. Synchromesh: Reliable code generation from\npre-trained language models . In ICLR 2022.\n5422\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie\nMillican, Jordan Hoffmann, H. Francis Song, John\nAslanides, Sarah Henderson, Roman Ring, Susan-\nnah Young, Eliza Rutherford, Tom Hennigan, Ja-\ncob Menick, Albin Cassirer, Richard Powell, George\nvan den Driessche, Lisa Anne Hendricks, Mari-\nbeth Rauh, Po-Sen Huang, Amelia Glaese, Jo-\nhannes Welbl, Sumanth Dathathri, Saffron Huang,\nJonathan Uesato, John Mellor, Irina Higgins, Antonia\nCreswell, Nat McAleese, Amy Wu, Erich Elsen, Sid-\ndhant M. Jayakumar, Elena Buchatskaya, David Bud-\nden, Esme Sutherland, Karen Simonyan, Michela Pa-\nganini, Laurent Sifre, Lena Martens, Xiang Lorraine\nLi, Adhiguna Kuncoro, Aida Nematzadeh, Elena\nGribovskaya, Domenic Donato, Angeliki Lazaridou,\nArthur Mensch, Jean-Baptiste Lespiau, Maria Tsim-\npoukelli, Nikolai Grigorev, Doug Fritz, Thibault\nSottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao\nGong, Daniel Toyama, Cyprien de Masson d’Au-\ntume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor\nBabuschkin, Aidan Clark, Diego de Las Casas, Au-\nrelia Guy, Chris Jones, James Bradbury, Matthew\nJohnson, Blake A. Hechtman, Laura Weidinger, Ia-\nson Gabriel, William S. Isaac, Edward Lockhart,\nSimon Osindero, Laura Rimell, Chris Dyer, Oriol\nVinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Ben-\nnett, Demis Hassabis, Koray Kavukcuoglu, and Ge-\noffrey Irving. 2021. Scaling language models: Meth-\nods, analysis & insights from training gopher . CoRR,\nabs/2112.11446.\nTorsten Scholak, Nathan Schucher, and Dzmitry Bah-\ndanau. 2021. PICARD: Parsing incrementally for\nconstrained auto-regressive decoding from language\nmodels. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 9895–9901, Online and Punta Cana, Domini-\ncan Republic. Association for Computational Lin-\nguistics.\nRichard Shin, Christopher Lin, Sam Thomson, Charles\nChen, Subhro Roy, Emmanouil Antonios Platanios,\nAdam Pauls, Dan Klein, Jason Eisner, and Benjamin\nVan Durme. 2021. Constrained language models\nyield few-shot semantic parsers . In Proceedings of\nthe 2021 Conference on Empirical Methods in Natu-\nral Language Processing, pages 7699–7715, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nBen Wang and Aran Komatsuzaki. 2021. GPT-J-6B: A\n6 Billion Parameter Autoregressive Language Model.\nhttps://github.com/kingoflolz/mesh\n-transformer-jax.\nYushi Wang, Jonathan Berant, and Percy Liang. 2015.\nBuilding a semantic parser overnight . In Proceedings\nof the 53rd Annual Meeting of the Association for\nComputational Linguistics and the 7th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 1332–1342, Beijing,\nChina. Association for Computational Linguistics.\nShan Wu, Bo Chen, Chunlei Xin, Xianpei Han, Le Sun,\nWeipeng Zhang, Jiansong Chen, Fan Yang, and Xun-\nliang Cai. 2021. From paraphrasing to semantic pars-\ning: Unsupervised semantic parsing via synchronous\nsemantic decoding . In Proceedings of the 59th An-\nnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 5110–5121, Online. Association\nfor Computational Linguistics.\nA Measuring performance of beam\nsearch and speculative constrained\ndecoding\nFor measuring the items/second of beam search and\nspeculative constrained decoding in Table 5 and Ta-\nble 8, we used the ﬁrst 10 items of the evaluation\nsets. As we only had access to shared instances of\nGPT-3 and Codex, we were unable to guarantee\nlack of interference from other users. While the\nnumbers are not precise, we believe they are gener-\nally indicative of the expected performance of the\ntwo methods.\nB Prompt for Codex when using meaning\nrepresentations\nInstead of the prompt in Section 2.1, we used the\nprompt depicted below:\n;;; Translate questions into Lisp\nexpressions\n; [utterance from training example]\n[meaning representation from example]\n; [utterance from training example]\n[meaning representation from example]\n[...]\n; [test utterance]\nThe text in square brackets are for exposition\nand not included verbatim in the prompt.\nC Supplementary results\nTable 7 contains all results from using beam search,\nused to construct Tables 2, 3, and 4. Table 8 is a\nversion of Table 5 with more rows.\nD Speculative constrained decoding\nalgorithm\nTo further expand on the description in Section 3.4,\nwe express the speculative constrained decoding\nmethod in Python-like pseudocode in Listing 1.\n5423\nAccuracy\nModel Output Decoding Beam size Overnight Cal. SMCalFlow\nDavinci Canonical Constrained 5 0.81 0.340\nDavinci Canonical Constrained 1 0.76 0.290\nDavinci Canonical Unconstrained 5 0.72 0.295\nDavinci Canonical Unconstrained 1 0.72 0.255\nDavinci Meaning Constrained 5 0.68 0.245\nDavinci Meaning Constrained 1 0.62 0.210\nDavinci Meaning Unconstrained 5 0.53 0.230\nDavinci Meaning Unconstrained 1 0.48 0.190\nCurie Canonical Constrained 5 0.66 0.260\nCurie Canonical Constrained 1 0.58 0.210\nCurie Canonical Unconstrained 5 0.50 0.225\nCurie Canonical Unconstrained 1 0.47 0.210\nCurie Meaning Constrained 5 0.44 0.200\nCurie Meaning Constrained 1 0.39 0.165\nCurie Meaning Unconstrained 5 0.38 0.185\nCurie Meaning Unconstrained 1 0.31 0.160\nDavinci Codex Canonical Constrained 5 0.86 0.355\nDavinci Codex Canonical Constrained 1 0.84 0.305\nDavinci Codex Canonical Unconstrained 5 0.79 0.310\nDavinci Codex Canonical Unconstrained 1 0.77 0.295\nDavinci Codex Meaning Constrained 5 0.86 0.345\nDavinci Codex Meaning Constrained 1 0.75 0.300\nDavinci Codex Meaning Unconstrained 5 0.80 0.315\nDavinci Codex Meaning Unconstrained 1 0.73 0.280\nCushman Codex Canonical Constrained 5 0.87 0.320\nCushman Codex Canonical Constrained 1 0.80 0.290\nCushman Codex Canonical Unconstrained 5 0.83 0.300\nCushman Codex Canonical Unconstrained 1 0.77 0.285\nCushman Codex Meaning Constrained 5 0.80 0.340\nCushman Codex Meaning Constrained 1 0.73 0.280\nCushman Codex Meaning Unconstrained 5 0.72 0.305\nCushman Codex Meaning Unconstrained 1 0.70 0.250\nTable 7: All results on Overnight Calendar and SMCalFlow using beam search.\nOvernight Calendar SMCalFlow\nAccuracy Items/second Accuracy Items/second\nWidth Temperature Canonical Meaning Canonical Meaning Canonical Meaning Canonical Meaning\n1 0.0 0.86 0.76 0.520 0.246 0.300 0.320 0.193 0.184\n1 BS 0.840 0.750 0.237 0.059 0.305 0.300 0.116 0.040\n5 0.25 0.86 0.79 0.553 0.208 0.330 0.325 0.071 0.050\n5 0.5 0.87 0.80 0.380 0.155 0.335 0.315 0.076 0.140\n5 0.75 0.86 0.84 0.344 0.129 0.320 0.340 0.076 0.081\n5 1.0 0.87 0.85 0.260 0.145 0.325 0.330 0.076 0.034\n5 BS 0.860 0.860 0.133 0.030 0.355 0.345 0.065 0.008\n10 0.25 0.88 0.81 0.537 0.213 0.345 0.310 0.020 0.040\n10 0.5 0.87 0.86 0.355 0.150 0.345 0.345 0.038 0.085\n10 0.75 0.87 0.82 0.266 0.103 0.350 0.355 0.039 0.034\n10 1.0 0.87 0.85 0.193 0.068 0.370 0.335 0.028 0.014\nTable 8: Comparing various settings on speculative decoding with beam search. “BS” for temperature indicates use\nof beam search. This table is an expanded version of Table 5\n5424\n# Parameters:\n# - W = width of the search\n# - T = softmax temepature\n# - MAX_STEPS = How many times we invoke the model. We set this to 16.\n#\n# Helper functions:\n# - nextTokens: as defined in Section 2.1\n# - model_completions: ask the model to generate completions with the given\n# prefix. Returns a list of token sequences sampled after the prefix.\n# - length_normalized_logprob: compute the log probability of a token sequence,\n# where longer sequences receive a bonus.\n# - is_finished: check if a token sequence is finished according to the grammar.\n#\n# /grave.ts1search/grave.ts1is invoked with tokens for the prompt p for a given example.\ndef expand(tokens):\nsamples = model_completions(tokens, temperature =T, num_completions =W)\nresults = []\nfor sample in samples:\nvalid_prefix = tokens\nfor token in sample:\nif token not in nextTokens(prefix):\nbreak\nvalid_prefix += [token]\nif valid_prefix == tokens:\n# No tokens in the completion were grammatically valid.\n# Back off to regular constrained decoding to advance by one token,\n# and append to results\n...\nelse:\nresults += [valid_prefix]\nreturn results\ndef search(prompt):\n# We start with one hypothesis containing tokens from the prompt.\nbeam = [prompt]\nfinished = []\nfor _ in range(MAX_STEPS):\ncandidates = []\nfor state in beam:\ncandidates += expand(state)\ncandidates.sort(key=length_normalized_logprob, reverse =True)\nnew_beam = []\nfor cand in candidates:\nif is_finished(cand):\nfinished.append(cand)\nelse:\nnew_beam.append(cand)\nif len(finished) + len(new_beam) == W:\nbreak\nif len(new_beam) == 0:\nbreak\nelse:\nbeam = new_beam\nreturn finished\nListing 1: Pseudocode for speculative constrained decoding\n5425",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8410202860832214
    },
    {
      "name": "Natural language processing",
      "score": 0.8086968660354614
    },
    {
      "name": "Parsing",
      "score": 0.7665092945098877
    },
    {
      "name": "Artificial intelligence",
      "score": 0.7105849385261536
    },
    {
      "name": "Natural language",
      "score": 0.7024905681610107
    },
    {
      "name": "Natural language understanding",
      "score": 0.6107740998268127
    },
    {
      "name": "Meaning (existential)",
      "score": 0.5997621417045593
    },
    {
      "name": "Language model",
      "score": 0.555171012878418
    },
    {
      "name": "Code (set theory)",
      "score": 0.5516079068183899
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5116949081420898
    },
    {
      "name": "Representation (politics)",
      "score": 0.5079131722450256
    },
    {
      "name": "Semantic role labeling",
      "score": 0.41067296266555786
    },
    {
      "name": "Programming language",
      "score": 0.26430031657218933
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0816618800163269
    },
    {
      "name": "Sentence",
      "score": 0.0740135908126831
    },
    {
      "name": "Psychology",
      "score": 0.07176396250724792
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Psychotherapist",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 37
}