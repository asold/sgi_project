{
  "title": "Systematic review and meta-analysis of AI-based conversational agents for promoting mental health and well-being",
  "url": "https://openalex.org/W4388931687",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2078732449",
      "name": "Robert Kraut",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2097517997",
      "name": "Han Li",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2970212114",
      "name": "Yi -Chieh Lee",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2106887638",
      "name": "Ren-Wen Zhang",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A2166669856",
      "name": "David C. Mohr",
      "affiliations": [
        "Northwestern University",
        "Behavioral Tech"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4361994630",
    "https://openalex.org/W3197232629",
    "https://openalex.org/W2977128309",
    "https://openalex.org/W4323900694",
    "https://openalex.org/W3196926390",
    "https://openalex.org/W3171455429",
    "https://openalex.org/W4229029590",
    "https://openalex.org/W4205207624",
    "https://openalex.org/W4280539423",
    "https://openalex.org/W3126938010",
    "https://openalex.org/W3213035528",
    "https://openalex.org/W4206793304",
    "https://openalex.org/W3190938315",
    "https://openalex.org/W4226502953",
    "https://openalex.org/W4252907012",
    "https://openalex.org/W3110570584",
    "https://openalex.org/W4384923078",
    "https://openalex.org/W4319789552",
    "https://openalex.org/W3153837393",
    "https://openalex.org/W3012444575",
    "https://openalex.org/W2760160110",
    "https://openalex.org/W2950709739",
    "https://openalex.org/W3150372151",
    "https://openalex.org/W1598602811",
    "https://openalex.org/W3183473388",
    "https://openalex.org/W2098923148",
    "https://openalex.org/W2005501262",
    "https://openalex.org/W3014634077",
    "https://openalex.org/W2972598474",
    "https://openalex.org/W4321606060",
    "https://openalex.org/W2937940701",
    "https://openalex.org/W2889335577",
    "https://openalex.org/W4294214983",
    "https://openalex.org/W4229372097",
    "https://openalex.org/W3128157571",
    "https://openalex.org/W2156098321",
    "https://openalex.org/W4381805620",
    "https://openalex.org/W3089273598",
    "https://openalex.org/W4320164613",
    "https://openalex.org/W3213790166",
    "https://openalex.org/W3022528244",
    "https://openalex.org/W2771925981",
    "https://openalex.org/W2895995041",
    "https://openalex.org/W3028999579",
    "https://openalex.org/W3136897485",
    "https://openalex.org/W1766812542",
    "https://openalex.org/W3202472344",
    "https://openalex.org/W3168346183",
    "https://openalex.org/W4229082340",
    "https://openalex.org/W2623779865",
    "https://openalex.org/W4389589630",
    "https://openalex.org/W3197552798",
    "https://openalex.org/W2165010366",
    "https://openalex.org/W2792708398",
    "https://openalex.org/W4205956657",
    "https://openalex.org/W2750377858",
    "https://openalex.org/W3166427010",
    "https://openalex.org/W4255544519",
    "https://openalex.org/W4304112197",
    "https://openalex.org/W2654569425",
    "https://openalex.org/W3198359754",
    "https://openalex.org/W4246277771",
    "https://openalex.org/W2999403486",
    "https://openalex.org/W4313728180",
    "https://openalex.org/W2062645441",
    "https://openalex.org/W2962948182"
  ],
  "abstract": "Conversational artificial intelligence (AI), particularly AI-based conversational agents (CAs), is gaining traction in mental health care. Despite their growing usage, there is a scarcity of comprehensive evaluations of their impact on mental health and well-being. This systematic review and meta-analysis aims to fill this gap by synthesizing evidence on the effectiveness of AI- based CAs in improving mental health and factors influencing their effectiveness and user experience. Twelve databases were searched for experimental studies of AI-based CAs’ effects on mental illnesses and psychological well-being published before May 26, 2023. Out of 7834 records, 35 eligible studies were identified for systematic review, out of which 15 randomized controlled trials were included for meta-analysis.The meta-analysis revealed that AI-based CAs significantly reduce symptoms of depression (Hedge’s g 0.64 [95% CI 0.17-1.12]) and distress (Hedge’s g 0.7 [95% CI 0.18-1.22]). These effects were more pronounced in CAs that are multimodal, generative AI-based, integrated with mobile/instant messaging apps, and targeting clinical/subclinical and elderly populations. However, CA-based interventions showed no significant improvement in overall psychological well-being (Hedge’s g 0.32 [95% CI -0.13 - 0.78]). User experience with AI-based CAs was largely shaped by the quality of human-AI therapeutic relationships, content engagement, and effective communication. These findings underscore the potential of AI-based CAs in addressing mental health issues. Future research should investigate the underlying mechanisms of their effectiveness, assess long-term effects across various mental health outcomes, and evaluate the safe integration of large language models (LLMs) in mental health care.",
  "full_text": "1 \n \n \nSystematic review and meta-analysis of AI-based conversational agents for promoting \nmental health and well-being \n \n \nHan Li, PhD 1 * \nRenwen Zhang, PhD 1 * \nYi-Chieh Lee, PhD 2 \nRobert E. Kraut, PhD 3 \nDavid C. Mohr, PhD 4 \n \n \n1 Department of Communications and New Media \nNational University of Singapore \nSingapore 117416 \nSingapore \n \n2 Department of Computer Science \nNational University of Singapore \nSingapore 117416 \nSingapore \n \n 3 Human-Computer Interaction Institute \nCarnegie Mellon University \nPittsburgh PA 15213 \nUSA \n \n4 Center for Behavioral Intervention Technologies, Department of Preventive Medicine \nNorthwestern University \nChicago IL 60611 \nUSA \n \n \nCorresponding author:  \nRenwen Zhang \n \nEmail: r.zhang@nus.edu.sg \nPhone: (+65) 83762508 \n \n \n \n                                                 \n* These authors contributed equally. \n\n \n \n \n \n2 \n \nAbstract  \nConversational artificial intelligence (AI) , particularly AI-based conversational agents (CAs) , is \ngaining traction in  mental health care . Despite their growing usage, there is a scarcity of \ncomprehensive evaluations of their impact on mental health and well -being. This systematic \nreview and meta-analysis aims to fill this gap by synthesizing evidence on the effectiveness of AI-\nbased CAs in improving mental health and  factors influencing  their effectiveness and user \nexperience. Twelve databases were searched for experimental studies of AI-based CAs’ effects on \nmental illnesses and psychological well -being published before May 26, 2023 . Out of 7834 \nrecords, 35 eligible studies were identified for systematic review, out of which 15 randomized \ncontrolled trials were included for meta-analysis.  \nThe m eta-analysis revealed that AI-based CAs  significantly reduce symptoms of \ndepression (Hedge’s g 0.64 [95% CI 0.17-1.12]) and distress (Hedge’s g 0.7 [95% CI 0.18-1.22]). \nThese effects were more pronounced in CAs that are multimodal, generative AI-based, integrated \nwith mobile/instant messaging apps, and targeting clinical/subclinical and elderly populations . \nHowever, CA-based interventions showed no significant improvement in overall psychological \nwell-being (Hedge’s g 0.3 2 [95% CI -0.13 - 0.78]). User experience  with AI -based CAs was  \nlargely shaped by the quality of human -AI therapeutic relationships, content engagement, and \neffective communication. These findings underscore the potential of AI-based CAs in addressing \nmental health issues. Future research should investigate the underlying  mechanisms of their \neffectiveness, assess long-term effects across various mental health outcomes , and evaluate the \nsafe integration of large language models (LLMs) in mental health care.    \n \nKeywords: Systematic review, Meta -analysis, Conversational Agent, Mental Health, Well -\nbeing \n \n \n \n \n \n \n\n \n \n \n \n3 \n \nIntroduction \nConversational agents (CAs), or chatbots, have shown substantial promise in the realm of mental \nhealth care. These agents can assist with diagnosis, facilitate consultations, provide \npsychoeducation, and deliver treatment options 1-3, while also playing a role in offering social \nsupport and boosting mental resilience4-6. Yet, a majority of these CAs currently operate on rule -\nbased systems, which rely on predefined scripts or decision trees to interact with users 7. While \neffective to a certain degree, these rule -based CAs are somewhat constrained, primarily due to \ntheir limited capability to understand user context and intention. Recent advancements in artificial \nintelligence (AI), such as natural language processing (NLP) and generative AI, have opened up a \nnew frontier--AI-based CAs. Powered by NLP, machine learning and deep learning, these AI -\nbased CAs possess expanding capabilities to process more complex information and thus allow \nfor more personalized, adaptive, and sophisticated responses to mental health needs8,9.  \nDespite their advantages, AI-based CAs carry risks, such as privacy infringement, biases, \nand safety issues10. Their unpredictable nature may generate flawed, potentially harmful outcomes \nleading to unexpected negative consequences11. To ensure the safe and effective integration of AI-\nbased CAs into mental health care, it is imperative to comprehensively review the current research \nlandscape on the use of AI -based CAs in mental health support and treatment. This will inform \nhealthcare practitioners, tec hnology designers, policymakers, and the general public about the \nevidence-based effectiveness of these technologies, while identifying challenges and gaps for \nfurther exploration.   \nA plethora of research has examined the effectiveness of CAs in influencing mental health, \nindicating that CAs can effectively mitigate symptoms of depression, anxiety, and distress, while \nalso fostering well-being and quality of life3,12-15. However, these reviews have largely focused on \n\n \n \n \n \n4 \n \nspecific types of CA12 or particular types of mental disorders13,14. Two comprehensive systematic \nreviews and meta-analyses3,15 provide evidence that supports the effectiveness of various types of \nCAs across a range of mental health outcomes. However, the over -representation of studies \nutilizing rule-based CAs in these reviews leaves the effectiveness of AI -based CAs in improving \nmental health remains underexplored. Moreover, the rapid progress in generative AI, such as Large \nLanguage Models (LLMs), necessitates an exploration of this technology ’s potential and pitfalls, \namidst uncertainties associated with its deployment in mental health care16. Yet, the latest studies \non these advanced technologies have not been incorporated into review papers, and thus little is \nknown about their effectiveness  compared to other types of AI -based CAs for mental health \nsupport. Beyond clinical effectiveness, user experience is vital in impacting clinical outcomes. \nNonetheless, prior reviews have not conclusively addressed user experience with AI-based CAs in \nmental health care or elucidated the factors driving the success of AI-based CA interventions.     \nThis systematic review and meta-analysis aims to evaluate the effects of AI-based CAs on \npsychological distress and well-being, and to pinpoint factors influencing the effectiveness of AI-\nbased CAs in improving mental health. Specifically, we focus on experimental studies where an \nAI-based CA is a primary intervention affecting mental health outcomes. Additionally, we conduct \nnarrative synthesis to delve into factors shaping user experiences with these AI-based CAs. To the \nbest of our knowledge, this review is the most up -to-date synthesis of evidence regarding the \neffectiveness of AI-based CAs on mental health. Our findings provide valuable insights into the \neffectiveness of AI-based CAs across various mental health outcomes, populations, and CA types, \nguiding their safe, effective, and user-centered integration into mental health care. \n\n \n \n \n \n5 \n \nResults \nResults of systematic review \nSearches of twelve databases identified 7834 unique citations (Fig. 1). We excluded 7301 \nrecords based on titles and abstracts, resulting in 533 records for full-text review. A total of 35 \nstudies from 34 full-text articles met the inclusion criteria and were included in the systematic \nreview for narrative synthesis. Among the 35 studies, one randomized trial17 did not report \nsufficient data for calculating pooled effect size and 19 studies were not randomized trials, \nleaving 15 randomized trials eligible for meta-analysis to estimate the effectiveness of AI-based \nCAs on psychological outcomes. Table 1 presents selected major characteristics of studies \nincluded in the systematic review (additional details are presented in Supplementary Table 1 and \nSupplementary Table 2).  \nOf the 35 studies included in our systematic review, 19 employed a quasi-experimental \ndesign, and 16 were randomized trials. The studies involved 17,123 participants from 15 \ncountries and regions. Most were single-site studies, with 14 conducted in the United States and \nonly one multi-site study conducted in the UK and Japan27. Studies were published between \n2017 and 2023, with 27 published since 2020. The majority of studies (n=28) had sample sizes \nunder 200. Participants’ ages ranged from 10.7 to 92 years. Five studies 30,33,43,44,48 focused on \nadolescents or children, while the rest included adult populations. In terms of gender, one study \nexclusively evaluated female populations31, and the rest included both genders. Half of the \nstudies (n=18) involved non-clinical populations, while 10 studies 18,23,24,26,29,36,37,39,49,50 included \nparticipants with self-report or screened symptoms of mental illnesses, and another seven studies \n\n \n \n \n \n6 \n \n21,30,31,34,38,40,42 involved patients with diagnosed mental or physical issues. Study duration varied \nconsiderably, from several minutes to 6 months.   \nWe extracted data on both the characteristics of the CA intervention and the technical \ndesign features of the CAs (see Table 2 for a summary). In total, 23 distinct CAs were evaluated \nacross the 35 studies. Most commonly, CAs were used for the delivery of psychotherapy and/or \npsychoeducational content (n=22). The integrative approach and CBT emerged as the most \nprevalent therapeutic approaches, represented in 11 and 6 studies respectively. Additionally, \nseveral CAs were designed to offer social assistance, companionship, or act as a source of \nemotional support for users25,27,32,35,36,40,44,45. There were also instances where CAs were \nemployed for specific purposes such as coaching22,38, counseling41, remote monitoring35, \nteleconsultation21 or to coordinate within a larger system39. A significant majority of the studies \n(n=32) featured CAs as independent, stand-alone systems. \nRegarding the design characteristics of CAs, smartphone and tablet applications emerged \nas the most popular platforms for delivering CA interventions, featured in 16 studies. This was \nfollowed by widely used instant messenger platforms like Facebook messenger (n=9), robots \n(n=5), web-based platforms (n=3), and two studies used VR and EMDR, respectively. The \nmajority of the studies (n=30) employed retrieval-based CAs to direct conversations through a \nset of established responses. In all of these retrieval-based CAs, NLP was leveraged to analyze \nthe intent and context of user inputs and to select the appropriate responses. In some instances, \nthis NLP capability was enhanced with machine learning (n=7), emotion algorithm (n=6), \nreinforcement learning (n=2), natural language understanding (n=2), or neural network \ntechniques (n=2) to improve learning and contextual understanding. Conversely, a smaller set of \nstudies (n=5) implemented generative CAs for mental health interventions, which can generate \n\n \n \n \n \n7 \n \nwholly original dialogues. Of these, one employed both GPT-2 and BERT24, the other four \nutilized GPT32, BERT41, LSTM25 and DP26, respectively. Regarding interaction mode, most \nstudies used text-based CAs (n=24). In eight studies 20,29,35,40,41,44,45, CAs incorporated emotion \nAI, such as sentiment analysis, to understand users’ emotional states and address their in-situ \nneeds. Other notable design features included personalization and customization (n=20), regular \ncheck-ins (n=10), mood tracking (n=8), empathic responses (n=7), multimedia (n=5), and \nhuman-like character and personality (n=2). Despite the growing significance of safety concerns \nregarding CAs in mental health, only 15 studies incorporated safety assessment or protection \nmeasures in CAs, such as access to human experts 33,42,48, onboarding processes 18,23,30,33,37, \nassessment of adverse events 18,29,37,50 and automatic crises or harm identification \n17,18,20,30,32,34,35,37,46,50. \nThe studies evaluated a diverse range of mental health outcomes, with depression (n=19) \nand anxiety (n=18) being the most frequently assessed (see Fig.2 for a summary). In addition to \nthe psychotherapeutic approaches, three studies incorporated social psychological theories \nincluding empathy theory41, cultural competency theory27 and goal attainment theory22 to guide \nthe CA intervention design. We did not identify any eligible studies that examined potential \nmediators accounting for changes in mental health outcomes, highlighting a critical gap that \nwarrants further exploration. As for moderators, three studies probed the moderating role of user \nengagement. Notably, increased interactions were tied to enhanced effectiveness in reducing \ndepression46 and anxiety symptoms 34,46. However, another study33 observed divergent effects of \ninteraction duration and amount on well-being, suggesting the need for more nuanced user \nengagement measurements to better understand the relationship between user engagement with \nCAs and the mental health outcomes. Of the four studies examining participant-related \n\n \n \n \n \n8 \n \nmoderators, those with severe baseline mental health symptoms reported greater reductions in \npsychological distress19,50. Participants’ concurrent therapies or treatments, however, showed \ninconsistent results. Specifically, two studies noted smaller reductions in anxiety18,50 and \ndepression50 among those engaging concurrent treatments, while another study documented \nlarger reductions in depression in a similar cohort37. One study50 also revealed that unmarried \nparticipants experienced greater reductions in depression and anxiety than self-identified sexual \nminorities.  \n \nNarrative synthesis of user engagement and experience \nOf the 35 studies, 19 detailed various measures of CA engagement, including metrics such as the \namount and length of conversations/messages (n=13), frequency and duration of CA usage \n(n=11), as well as the usage of specific modules or features (n=5). User experiences with AI-\nbased CAs were reported in 16 studies, primarily focusing on satisfaction (n=8), acceptability \n(n=7), and usability (n=5), followed by working alliance (n=4), helpfulness (n=3), feasibility \n(n=3), and likeability (n=1). A total of 10 studies 17,20,23,26,29,32,38,43,47,49 documented open-ended \nuser feedback on their experiences interacting with AI-based CAs. Through inductive thematic \nanalysis, these user feedbacks were classified into positive and negative experiences and further \ncategorized into sub-themes (see Table 3). Notably, process factors fostering the formation of \ntherapeutic relationships were frequently identified as positive experiences in eight studies, with \nempathic communication being the most commonly cited aspect (n=5). Participants from six \nstudies emphasized the value of specific therapeutic approaches or techniques (n=3) and the \nrichness of content (n=3). Moreover, participants from three studies appraised the learning \nprocess facilitated by the CAs, and two favored accessibility. Text-based communication was \n\n \n \n \n \n9 \n \nregarded as a positive aspect in one study. Negative experiences predominantly revolved around \ncommunication breakdowns–when the CA failed to effectively understand, process, and respond \nto user input (n=8). Content-related factors, both in terms of topics and formats, were indicated \nas unsatisfactory elements during interactions (n=4). The impersonal nature of CAs was \nhighlighted in two studies as a contributing factor to negative user experience while technical \nissues were reported in one study. Furthermore, in one study, participants voiced dissatisfaction \nregarding the CA’s lack of initiative and its interaction mode. Interestingly, one study found that \nparticipants suffering from more severe symptoms expressed a preference for human support \nover CAs. \n \nResults of Meta-analysis \nA total of 15 studies, involving 1744 participants, were eligible for inclusion in our meta-\nanalysis. Among these, 13 trials examined indicators of psychological distress (Fig. 3), and eight \ntrials assessed psychological well-being (Fig. 4). Compared to various control conditions, \nparticipants interacting with AI-based CAs exhibited a significantly greater reduction in \npsychological distress, with an effect size of g=0.7 (95% CI 0.18-1.22). The “leave-one-out” \nsensitivity analyses demonstrated the robustness of this result, with estimated effect sizes ranging \nfrom 0.529 to 0.787. However, when we excluded two influential studies24,31, the overall effect \nsizes modestly decreased to 0.529 and 0.564, respectively but maintained the same direction and \nsignificance (refer to Supplementary Table 3). Interestingly, both of these two studies employed \ngenerative CAs, suggesting that the response generation approach of CAs could potentially \ninfluence their effectiveness. Although participants interacting with AI-based CA showed \nimprovements in psychological well-being, this enhancement was not statistically significant \n\n \n \n \n \n10 \n \n(g=0.32; 95% CI -0.13-0.78), perhaps because of insufficient power. Only eight trials \ninvestigated psychological well-being compared to 13 examining psychological distress. \nAdditional meta-analyses on specific mental health outcomes, detailed in Supplementary Fig. 1-\n4, indicated that CA interventions significantly outperformed control conditions in ameliorating \ndepression (g=0.644, 95% CI 0.17-1.12). However, they did not significantly impact anxiety \n(g=0.65, 95% CI -0.46-1.77), positive affect (g=0.07, 95% CI -0.43-0.57) or negative affect \n(g=0.52, 95% CI -0.67-1.71). \nAnalyses revealed significant heterogeneity for both psychological distress (Q=267.98, \np<0.001, I2=95.3%) and psychological well-being (Q=85.7, p<0.001, I2=91.3%). Egger’s \nregression test suggested no clear publication bias (Supplementary Table 4). While AI-based \nCAs demonstrated high effectiveness in addressing psychological distress, we graded the quality \nof evidence as moderate. This decision was driven by the substantial heterogeneity observed \nacross the studies and the wide confidence interval of the effect estimate, which cast doubts on \nthe consistency and precision of the results. The grade of recommendation for AI-based CAs in \nenhancing psychological well-being was rated as low (see Supplementary Table 5 for the \nSummary of Findings). The overall risk of bias was low for two studies, high for five studies, \nand the remaining eight studies had unclear risk of bias. The most notable source of bias arose \nfrom performance bias, largely due to the lack of blinding of participants and personnel, which \naligns with findings from a previous study51. Furthermore, the presence of attribution bias in five \nstudies, influenced by either improper methods of addressing missing data or a significant \ndropout rate, might have caused deviations in the intended interventions (for a visual \nrepresentation of risk of bias, see Supplementary Fig. 5). \n\n \n \n \n \n11 \n \nTo explore the potential sources of heterogeneity, we performed subgroup analyses \nfocusing on various participant-, study- and CA- related moderators. Regarding psychological \ndistress, the results showed that the ameliorative impact of CAs was more pronounced for \ngenerative CAs (g=1.244) in contrast to retrieval-based ones (g=0.523, F(2, 19)=4.883, p=0.019), \nand stronger for multimodal/voice-based agents (g=0.828) compared to text-based ones \n(g=0.665, F (2, 19) = 3.655, p = 0.045). Additionally, the effect was stronger when the \nintervention was delivered through smartphone or tablet apps (g=0.963) and instant messengers \n(g=0.751), than that observed for web-based platforms (g=-0.075, F (3,18) =3.261, p=0.046). As \nfor participants’ characteristics, a larger effect size was observed in middle-aged/older adults \n(g=0.846) in comparison with adolescents/young adults (g=0.64, F (2, 19) =3.691, p=0.044). \nMoreover, the reduction in psychological distress was more pronounced in the \nclinical/subclinical population (g=1.069) compared to non-clinical population (g=0.107, F (2,19) \n=7.152, p=0.005). Female percentage in the sample did not moderate the effects of CA on \npsychological distress (g=-0.47, F (1, 19) =0.105, p=0.749). Similarly, CA intervention effects \non psychological distress did not differ by the type of control groups (F (5, 20) =2.598, p=0.06). \nYet, the effects of AI-based CA on psychological well-being did not exhibit significant \nvariations associated with participants’ age (F(2,12)=1.444, p=0.274), gender (F(1, 12)=0.462, \np=0.51), health status (F(2, 12)=1.624, p=0.238), the response generation approach (F(2, 12) \n=1.253, p=0.32), interaction mode (F(2, 12) = 1.338, p = 0.299) and delivery platform (F(3, \n11)=1.677, p=0.23) of the CAs, or the type of control groups (F(4,14) =0.175, p=0.948). The \ndetailed results of subgroup analysis are presented in Supplementary Table 6.  \n\n \n \n \n \n12 \n \nDiscussion  \nIn this systematic review and meta-analysis, we synthesized evidence on the effectiveness and \nuser evaluation of AI-based CAs in mental health care. Our findings suggest that these CAs can \neffectively alleviate psychological distress, with the most pronounced effects seen in studies \nemploying generative AI, using multimodal or voice-based CAs, or delivering interventions via \nmobile applications and instant messaging platforms. CA-based interventions are also more \neffective among clinical and subclinical groups, and elderly adults. Furthermore, AI-based CAs \nwere generally well-received by the users; key determinants shaping user experiences included \nthe therapeutic relationship with the CA, the quality of content delivered, and the prevention of \ncommunication breakdowns.  \nNotably, we observed a significant and large effect size of AI-based CAs in mitigating \npsychological distress (g=0.7) compared to small-to-moderate effects (g ranging from 0.24 to \n0.47) reported in a recent review that primarily included rule-based CAs15. This suggests that \nconversational agents enhanced by advanced AI and machine learning technologies outperform \ntheir rule-based counterparts in managing psychological distress. Furthermore, the notably larger \neffect size of generative CAs (g =1.244) relative to retrieval-based ones (g = 0.523) suggests that \nthe effectiveness of CA interventions may be influenced by the response generation approach \nemployed, which determines how well these agents are capable of simulating human \nconversations. Given the rapid advancements in AI technologies, further investigations are \nwarranted to explore the potential benefits and risks of generative CAs. Identifying conditions \nfor optimal effectiveness of different response generation approaches is vital to developing \n\n \n \n \n \n13 \n \nevidence-based guidelines for the implementation of various conversational agents across diverse \nclinical contexts.  \nWhile AI-based CAs consistently reduced psychological distress, their impact on \npsychological well-being was less consistent, which aligns with a previous review52. There are \ntwo possible explanations for this result. First, fewer studies investigated psychological well-\nbeing (n=8) compared to psychological distress (n=13), which could potentially curtail the \nstatistical power necessary to detect a significant pooled effect on well-being53. Second, \nmeasures of psychological distress tend to be more sensitive to recent experience-induced \nchanges, while measures of psychological well-being are typically more stable over time, \nrequiring sustained and long-term engagement. As such, future research should explore the long-\nterm effects of AI-based CAs to evaluate their effectiveness in promoting psychological well-\nbeing and to better understand CA effectiveness across diverse mental health outcomes.  \nMultimodal or voice-based CAs were slightly more effective than text-based ones in \nmitigating psychological distress. Their integration of multiple communication modalities may \nenhance social presence54 and deepen personalization, thus fostering a more human-like \nexperience55,56 and boost the therapeutic effects57. In addition, a CA including text and voice \nfunctionalities might support individuals with cognitive, linguistic, literacy, or motor \nimpairments. However, a recent study found text-based chatbots were better at promoting fruits \nand vegetable consumption58. This suggests that the effectiveness of chatbot modality may vary \nbased on context and desired outcomes, underscoring the importance of adaptable, tailored CA \ndesigns. Moreover, a significant subgroup difference in psychological distress was noted \nregarding CA’s delivery platform. Mobile applications and instant messaging platforms may \n\n \n \n \n \n14 \n \noffer advantages in terms of reach, ease of use, and convenience when juxtaposed with web-\nbased platforms, potentially leading to enhanced outcomes.  \nOur analysis also revealed that AI-based CAs were more effective in clinical and \nsubclinical populations. This result echoes previous studies suggesting that psychological \ninterventions are more effective for people with mental or physical health conditions compared \nto the general population52 and such effect is larger when mental health symptoms are more \nsevere59. However, prior research also shows that people with more severe symptoms showed a \npreference for human support38. This underscores the need for research to untangle the complex \ninterplay between symptom severity, CA intervention, human support, and clinical outcomes, \nand to pinpoint the conditions under which CAs are most effective and when human support is \nindispensable. Another interesting finding was that middle-aged and older adults seemed to \nbenefit more from AI-based CAs than younger populations. One possible explanation might be \nthe variations in engagement levels, but due to the high heterogeneity across studies, we were \nunable to validate these assumptions. Future research is warranted, as a prior review suggests a \ncurvilinear relationship between age and treatment effects60. Notably, we did not find a \nsignificant moderating effect of gender, consistent with earlier findings demonstrating that digital \nmental health interventions are similarly effective across genders61.  \nIn terms of user evaluation, most studies included in our review reported positive \nfeedback for AI-based CAs, suggesting their feasibility across diverse demographic groups. Our \nanalysis of open-ended user feedback revealed that factors such as the therapeutic relationship, \ncontent quality, and communication breakdowns were key determinants of user experience, \nwhich corresponds to previous psychotherapy research that identifies these common elements \n(e.g., therapeutic alliance, empathy, and therapist effect) as active ingredients contributing to \n\n \n \n \n \n15 \n \ntherapeutic changes across various therapeutic frameworks62. Communication breakdowns with \nCAs can lead to negative user experiences, making the intervention less likely to succeed. \nAlthough retrieval-based CAs understand user context better than rule-based CAs, their \nlimitations in generating responses can cause unnatural or repetitive interactions, potentially \nreducing clinical effectiveness. Despite these factors being identified as important based on \nqualitative user feedback, none of the included studies empirically examined their mediating or \nmoderating effects. Future research should delve into these elements to understand the \nmechanisms of change and key components for successful CA interventions.   \nThis review has its limitations. First, our broad search strategy, while exhaustive, led to \nconsiderable heterogeneity in outcome measures and results, making definitive conclusions and \ndirect comparisons challenging. Standardized evaluation methods for clinical and non-clinical \noutcomes in future studies would help address this issue. Second, due to a limited number of \nstudies reporting follow-up effects (n=6) and the substantial variation in follow-up durations, we \nwere unable to conduct a meta-analysis of the long-term effects of CA interventions on \npsychological outcomes. Therefore, the lasting effects of CA interventions remain unclear. \nThird, by only including English-language publications, we may have overlooked relevant \nstudies in other languages, potentially limiting the generalizability of our findings. Fourth, the \nnarrative synthesis of user experiences heavily depends on the interpretative reliability of the \noriginal studies, which may have methodological issues influencing their results. Lastly, the \nrealm of generative AI and LLMs is evolving at an unprecedented pace. While we identified five \nstudies using generative CAs powered by various generative AI models and frameworks, we \nwere unable to examine the effect of specific AI models on outcomes due to the limited sample \n\n \n \n \n \n16 \n \nsize. As the adoption of generative AI for mental health care expands, future research may \nbenefit from differentiating the impacts of various generative AI forms.      \nAI-based CAs are surfacing as an impactful component in mental health care. This \nreview provides preliminary and most up-to-date evidence supporting their effectiveness in \nalleviating psychological distress, while also highlighting key factors influencing effectiveness \nand user experience. While AI-based CAs are not designed to replace professional mental health \nservices, our review suggests their potential to serve as a readily accessible and effective solution \nto address the expanding treatment gap. Future research endeavors need to delve deeper into the \nmechanisms and empirically evaluate the key determinants of successful AI-based CA \ninterventions, spanning diverse mental health outcomes and populations. \nMethods \nSearch strategy and selection criteria \nWe conducted a systematic search across twelve datasets, using a wide array of search terms. The \nsearch covered all data from the inception of each database up until Aug 16, 2022 and was later \nupdated to include new entries up to May 26, 2023. We fine-tuned our search strategy based on \nprevious systematic reviews 3,52,63 to locate sources related to AI-based CAs for addressing mental \nhealth problems or promoting mental well -being. The search was limited to English -language \npublications. Complete lists of datasets and search strategies are detailed in Supplementary Table \n7.  \nAfter removing duplicates, we screened all retrieved citations and abstracts in two stages: \ntitle/abstract screening and full-text review. Two reviewers independently reviewed al l titles and \n\n \n \n \n \n17 \n \nabstracts for eligibility, followed by a full -text review. At each screening stage, a 10% subset of \nrecords was jointly reviewed to evaluate inter -rater reliability; disagreements were resolved \nthrough discussion, with the involvement of a thi rd reviewer if needed. Inter -rater reliability, \nassessed using Cohen’s Kappa64, indicated near-perfect agreement for title/abstract screening (0.9) \nand full-text review (0.83).  \nThe full description and examples of eligibility criteria are outlined in Supplementary \nTable 8. Briefly, we developed our eligibility criteria based on PICOS framework: (1) Population: \nall demographics or groups were eligible; (2) Intervention: we included studies that used an AI -\nbased CA as the primary intervention, which entails a two-way interaction between a user and the \nCA. These AI -based CAs are defined as software agents or bots that leverage NLP, machine \nlearning or other AI models and techniques to simulate human -like conversations. Unlike rule -\nbased systems that depend  on predefined rules or decision trees to formulate responses 7, these \nagents possess the capability to understand user intent, analyze contexts, and retrieve or generate \nappropriate response based on the users’ input and the context of the conversation; (3) Comparator: \nwe included studies with any comparison, ranging from active CA or human control groups to \nusual care, or those without a direct comparator, such as single group pre-post studies; (4) Outcome: \nwe considered any outcomes related to psychologic al distress or well -being as eligible. These \ncould be measured through self -reported questionnaires, objective metrics (e.g., audio or visual \nsignals from passive sensing systems) or third -party evaluations; (5) Study: we included any \nexperimental study design.     \n\n \n \n \n \n18 \n \nData management and extraction \nWe developed a comprehensive data extraction form and pilot -tested it on a subset of included \nstudies to ensure reliability and reproducibility. The following data were then extracted from all \nincluded studies: publ ication details (author, title, journal, year), study details (region, duration, \nmethod), participant characteristics (population type, sample size, demographics), CA intervention \ncharacteristics (deployment, session, role, target condition, safety measure s), CA design features \n(name, delivery platform, AI model/framework/technique, interaction mode, and other reported \ndesign features), therapeutic orientation (e.g., cognitive behavioral therapy; CBT), user evaluation \napproach (user engagement, user experie nce, and other reported user feedback), psychological \noutcomes and measures, and mechanisms (theory, moderator, mediator).  \nWe also extracted and narratively synthesized data related to engagement and user \nexperience of AI-based CAs from studies reporting relevant information, encompassing users’ \ninvolvement, interactions with CA interventions, and their affective and cognitive evaluations65. \nMoreover, we observed that some studies reported open-ended user feedback on their \nexperiences with CAs, potentially providing insights into factors affecting the success of CA \ninterventions. To analyze user feedback, two coders performed an inductive thematic analysis to \nidentify prevalent themes in user feedback and summarized these themes narratively.  \nMeta-analysis methods \nTo assess the effectiveness of AI -based CA interventions, we conducted a meta -analysis on \nrandomized trials wherein participants were randomly assigned to an experimental group receiving \na target CA intervention or to control groups receiving alternative treatments, information, or being \nplaced on a waitlist. Since all of the included randomized controlled trials (RCTs) reported at least \n\n \n \n \n \n19 \n \none indicator of psychological distress (i.e., distress, depression, anxiety and stress) 66 and/or \npsychological well -being (i.e., psychological well -being, positive and negative affect, mental \nresilience, mental health self -efficacy), we performed two separate meta -analyses to estimate \npooled effect sizes for these two overall psychological out comes. Furthermore, we conducted \nmeta-analyses for specific psychological outcomes reported by at least three trials, including \ndepressive symptom, generalized anxiety symptom, and positive affect and negative affect.  \nThe meta -analyses were conducted usin g R software (version 3.6.2) and the metafor \npackage. Data were extracted from RCTs to calculate pooled effect sizes of Hedges’ g, with \ncorresponding 95% confidence intervals and P -values. Hedges’ g of 0.2 indicated a small effect, \n0.5 a moderate effect and 0.8 a large effect67. Since we expected considerable heterogeneity among \nRCTs, random-effects models were used for all meta-analyses a priori. Heterogeneity among trials \nwas assessed using Cochran’s Q test and I 2. Egger’s regression test was used to eval uate \npublication bias. As most trials contributed more than one observed effect size in assessing the two \noverall psychological outcomes, we fit two three -level random-effects meta-analytical models to \naccount for dependencies between effect sizes, which a llow effect sizes to vary between \nparticipants, outcomes, and studies 68. We calculated Hedges’g using post -intervention outcome \ndata that provided means and standard deviations (SDs). When SDs were not reported, they were \nobtained by mathematical transformation69. When both intention-to-treat and completer analyses \nwere reported, we extracted and analyzed the former. For studies with multi -arm designs that \nincluded multiple experimental or control groups, we combined the means and SDs from the \ndifferent arms to create a single pair -wise comparison, as suggested by the Cochrane guidelines \nfor integrating multiple groups from a single study70. If a study did not report sufficient data (mean, \nSD, SE, 95% CI) to calculate Hedges’g, we contacted corresponding aut hors for missing data; \n\n \n \n \n \n20 \n \nstudies lacking necessary data were excluded from the meta-analysis. For sensitivity analysis, we \nemployed a “leave-one-out” method71 to identify influential studies and assess the robustness of \nestimates.     \nTo investigate potentia l sources of heterogeneity, we conducted a series of subgroup \nanalyses on the two primary psychological outcomes. In accordance with previous research, we \nexamined participant-specific characteristics (i.e., gender, age, and health status) as well as the \ntype of control groups  61. Additionally, we considered three CA technical features (i.e., response \ngeneration approach, interaction mode and delivery platform) as potential moderators. We defined \nresponse generation approach as the technique a CA employs to formulate responses to user inputs. \nFor building AI -based CAs, there are two major response generation approaches: the retrieval -\nbased approach and the generative approach. The key distinction between the two approaches \nstems from their underlying mechani sms in response generation. Retrieval -based CAs, like \nWoebot and Wysa, rely on dialogue management frameworks to track the flow of conversation \nand select appropriate responses from a pre-established repository of conversational utterances. In \ncontrast, generative CAs, such as ChatGPT and Replika, leverage machine learning algorithms to \nlearn and auto -generate responses based on a large amount of training data 72. In terms of the \ninteraction mode, we categorized the CAs into text-based, where users communicate with the CA \nvia textual messages, and multimodal/voice -based, allowing users to engage with the CA using \neither text or vocal inputs. Furthermore, based on the medium through which the CA interacts with \nthe users, the CAs were grouped into smartphone/ta blet app, instant messaging platform, web -\nbased platform, or robot.For categorical variables such as response generation approach, we used \nmixed-effects models for the subgroup analyses, while a meta-regression approach was employed \n\n \n \n \n \n21 \n \nfor the continuous vari able (i.e., gender). A detailed description of the moderators is outlined in \nTable 4. \nWe employed the Cochrane risk of bias assessment 73 to assess the risk of bias in the \nincluded RCTs. This assessment tool evaluates seven domains of potential bias: select ion bias, \nperformance bias, detection bias, attrition bias, reporting bias and other bias. For each domain, a \ntrial can be categorized as having a low, high or unclear risk of bias. For the overall risk -of-bias \njudgment, we adopted the approach from He et al.15 Specifically, a trial was deemed to have a low \nrisk of bias only if all domains were rated as low-risk. Conversely, any trial was judged to have a \nhigh risk of bias if it scored high in any domain, with the exception of performance bias. We \nexcluded performance bias from this criterion due to the practical challenges associated with \nblinding participants and personnel in CA -based interventions51. Trials with at least one domain \nrated as unclear, but no domains rated as high risk were classified as having “some concerns”. For \nvisualization, the risk of bias was represented using Review Manager (version 5.4).  \nTo evaluate the quality of evidence presented in the two primary meta -analyses of RCTs, \nwe used the GRADE approach74, which provides a holistic assessment of the combined evidence \nfrom meta-analyses. It incorporates five key considerations, and the quality of evidence may be \ndowngraded if any of these are not adequately met. Specifically, the five considerations focus on \nstudy limitations (i.e., concerns about the risk of bias), inconsistency of the effects (i.e., variability \nin the effect estimates, often indicated by heterogeneity), indirectness (i.e., differences in the \npopulation, intervention, or outcome from what was intended), imprecision (i.e., uncertainty in the \neffect estimate, e.g., wide confidence interval), and publication bias (potential underreporting of \nstudies with negative or null results). Conversely, factors like a large magnitude of effect or \nevidence of a dose-response gradient can lead to upgrades. The overall quality of evidence can be \n\n \n \n \n \n22 \n \nclassified as high, moderate, low, or very low. The GRADE assessment is presented in the \nSummary of Findings table.  \n        The study protocol was registered in PROSPERO, CRD 42023392187, and adh ered to the \nPreferred Reporting Items for Systematic reviews and Meta-Analyses76 (Supplementary Table 9).  \n \nData Availability \nData collected and used in this meta-analysis can be requested from the corresponding author. \n \nAcknowledgements \nThe present study is supported by the Singapore Ministry of Education Academic Research Fund \nTier 1 A-8000877-00-00, National University of Singapore Start-up Grant A-8000936-01-00, \nand NIMH grant P50 MH119029. The funders of the study had no role in the study design, data \ncollection, data analysis, data interpretation, or writing of the manuscript. \n \nAuthor Contributions \nH.L. and R.Z. have contributed equally to this manuscript. H.L. and R.Z. developed the protocol. \nH.L. searched the electronic databases. The study selection process, data extraction, and risk of \nbias assessment were carried out by H.L. and R.Z. Data synthesis was conducted by H.L. and \nR.Z. H.L. did the statistical analysis and visualization. H.L., R.Z., Y.C.L., R.E.K., and D.C.M. \ncontributed to data interpretation. H.L. and R.Z. prepared the original manuscript draft. The \narticle was revised critically for important intellectual content by all authors. All authors \napproved the final manuscript for submission.  \n \nCompeting Interests \nThe authors declare no competing interests. \n \n \n \n \n\n \n \n \n \n23 \n \nReferences  \n \n1.     Dingler T, Kwasnicka D, Wei J, Gong E, Oldenburg B. The use and promise of \nconversational agents in digital health. Yearb Med Inform 30, 191-9 (2021). \n2.     Jabir, A. I. et al. Evaluating conversational agents for mental health: Scoping review of \noutcomes and outcome measurement instruments. J. Med. Internet Res 25, e44548 (2023). \n3. Abd-Alrazaq, A. A., Rababeh, A., Alajlani, M., Bewick, B. M. & Househ, M. Effectiveness \nand safety of using chatbots to improve mental health: Systematic review and meta-\nanalysis. J. Med. Internet Res 22, e16021 (2020). \n4. Loveys, K., Fricchione, G., Kolappa, K., Sagar, M. & Broadbent, E. Reducing patient \nloneliness with artificial agents: Design insights from evolutionary neuropsychiatry. J. Med. \nInternet Res 21, e13664 (2019). \n5. Inkster, B., Sarda, S. & Subramanian, V. An empathy-driven, conversational artificial \nintelligence agent (Wysa) for digital mental well-being: Real-world data evaluation mixed-\nmethods study. JMIR Mhealth Uhealth 6, e12106 (2018). \n6.     Torous J, Bucci S, Bell IH, et al. The growing field of digital psychiatry: current evidence \nand the future of apps, social media, chatbots, and virtual reality. World Psychiatry 20, 318-\n35 (2021). \n7. Abd-Alrazaq, A. A. et al. An overview of the features of chatbots in mental health: A \nscoping review. Int. J. Med. Inform 132, 103978 (2019). \n8. Koutsouleris, N., Hauser, T. U., Skvortsova, V. & De Choudhury, M. From promise to \npractice: Towards the realisation of AI-informed mental health care. Lancet Digit Health 4, \ne829–e840 (2022). \n\n \n \n \n \n24 \n \n9.     Adamopoulou, E. & Moussiades, L. An overview of chatbot technology. in Artificial \nIntelligence Applications and Innovations 373–383 (Springer International Publishing, \n2020). \n10. May, R. & Denecke, K. Security, privacy, and healthcare-related conversational agents: A \nscoping review. Inform. Health Soc. Care 47, 194–210 (2022). \n11. Luxton, D. D. Ethical implications of conversational agents in global public health. Bull. \nWorld Health Organ 98, 285–287 (2020). \n12. Scoglio, A. A., Reilly, E. D., Gorman, J. A. & Drebing, C. E. Use of social robots in mental \nhealth and well-being research: Systematic review. J. Med. Internet Res 21, e13322 (2019). \n13. Lim, S. M., Shiau, C. W. C., Cheng, L. J. & Lau, Y. Chatbot-delivered psychotherapy for \nadults with depressive and anxiety symptoms: A systematic review and meta-regression. \nBehav. Ther 53, 334–347 (2022). \n14. Vaidyam, A. N., Linggonegoro, D. & Torous, J. Changes to the psychiatric chatbot \nlandscape: A systematic review of conversational agents in serious mental illness. Can. J. \nPsychiatry 66, 339–348 (2021). \n15. He, Y. et al. Conversational agent interventions for mental health problems: Systematic \nreview and meta-analysis of randomized controlled trials. J. Med. Internet Res. 25, e43862 \n(2023). \n16.   Arora, A. & Arora, A. The promise of large language models in health care. Lancet 401, \n641 (2023). \n17. Fulmer, R., Joerin, A., Gentile, B., Lakerink, L. & Rauws, M. Using psychological \nArtificial Intelligence (Tess) to relieve symptoms of depression and anxiety: Randomized \ncontrolled trial. JMIR Ment Health 5, e64 (2018). \n\n \n \n \n \n25 \n \n18. Prochaska, J. J. et al. A randomized controlled trial of a therapeutic relational agent for \nreducing substance misuse during the COVID-19 pandemic. Drug Alcohol Depend. 227, \n108986 (2021). \n19. Bird, T., Mansell, W., Wright, J., Gaffney, H. & Tai, S. Manage your life online: A web-\nbased randomized controlled trial evaluating the effectiveness of a problem-solving \nintervention in a student sample. Behav. Cogn. Psychother. 46, 570–582 (2018). \n20. Klos, M. C. et al. Artificial Intelligence–based chatbot for anxiety and depression in \nuniversity students: Pilot randomized controlled trial. JMIR Formative Research 5, e20678 \n(2021). \n21. Ogawa, M. et al. Can AI make people happy? The effect of AI-based chatbot on smile and \nspeech in Parkinson’s disease. Parkinsonism Relat. Disord. 99, 43–46 (2022). \n22. Terblanche, N., Molyn, J., De Haan, E. & Nilsson, V. O. Coaching at scale: Investigating \nthe efficacy of Artificial Intelligence coaching. Int. J. Evid. Based Coach. Mentor 20, 20-36 \n(2022). \n23. Fitzpatrick, K. K., Darcy, A. & Vierhile, M. Delivering cognitive behavior therapy to young \nadults with symptoms of depression and anxiety using a fully automated conversational \nagent (Woebot): A randomized controlled trial. JMIR Ment Health 4, e19 (2017). \n24. Romanovskyi, O., Pidbutska, N. & Knysh, A. Elomia Chatbot: The effectiveness of \nArtificial Intelligence in the fight for mental health. in COLINs 5th International \nConference on Computational Linguistics and Intelligent Systems, 1215–1224 (2021). \n25. Drouin, M., Sprecher, S., Nicola, R. & Perkins, T. Is chatting with a sophisticated chatbot as \ngood as chatting online or FTF with a stranger? Comput. Human Behav. 128, 107100 \n(2022). \n\n \n \n \n \n26 \n \n26. He, Y. et al. Mental health chatbot for young adults with depressive symptoms during the \nCOVID-19 pandemic: Single-blind, three-arm randomized controlled trial. J. Med. Internet \nRes. 24, e40719 (2022). \n27. Papadopoulos, C. et al. The CARESSES randomised controlled trial: Exploring the health-\nrelated impact of culturally competent Artificial Intelligence embedded into socially \nassistive robots and tested in older adult care homes. Adv. Robot. 14, 245–256 (2022). \n28. Bennion, M. R., Hardy, G. E., Moore, R. K., Kellett, S. & Millings, A. Usability, \nacceptability, and effectiveness of web-based conversational agents to facilitate problem \nsolving in older adults: Controlled study. J. Med. Internet Res. 22, e16794 (2020). \n29. Liu, H., Peng, H., Song, X., Xu, C. & Zhang, M. Using AI chatbots to provide self-help \ndepression interventions for university students: A randomized trial of effectiveness. \nInternet Interv 27, 100495 (2022). \n30. Nicol, G., Wang, R., Graham, S., Dodd, S. & Garbutt, J. Chatbot-delivered cognitive \nbehavioral therapy in adolescents with depression and anxiety during the COVID-19 \npandemic: Feasibility and acceptability study. JMIR Form Res 6, e40242 (2022). \n31.  Tawfik, E., Ghallab, E. & Moustafa, A. A nurse versus a chatbot ‒ the effect of an \nempowerment program on chemotherapy-related side effects and the self-care behaviors of \nwomen living with breast Cancer: a randomized controlled trial. BMC Nurs. 22, 102 (2023). \n32.  Sabour, S. et al. A chatbot for mental health support: Exploring the impact of Emohaa on \nreducing mental distress in China. Front. digit. health 5, 1133987 (2023). \n33. Vertsberger, D., Winsberg, M. & Naor, N. Adolescents’ wellbeing while using a mobile \nArtificial Intelligence-powered acceptance commitment therapy tool: Evidence from a \nlongitudinal study. JMIR AI 1, e38171 (2022). \n\n \n \n \n \n27 \n \n34. Leo, A. J. et al. A digital mental health intervention in an orthopedic setting for patients \nwith symptoms of depression and/or anxiety: Feasibility prospective cohort study. JMIR \nForm Res 6, e34889 (2022). \n35. Rathnayaka, P. et al. A mental health chatbot with cognitive skills for personalised \nbehavioural activation and remote health monitoring. Sensors 22, (2022). \n36. Abdollahi, H., Mollahosseini, A., Lane, J. T. & Mahoor, M. H. A pilot study on using an \nintelligent life-like robot as a companion for elderly individuals with dementia and \ndepression. in 2017 IEEE-RAS 17th International Conference on Humanoid Robotics \n(Humanoids) 541–546 (2017). \n37. Prochaska, J. J. et al. A therapeutic relational agent for reducing problematic substance use \n(Woebot): Development and usability study. J. Med. Internet Res. 23, e24850 (2021). \n38. Bassi, G. et al. A virtual coach (Motibot) for supporting healthy coping strategies among \nadults with diabetes: Proof-of-Concept study. JMIR Hum Factors 9, e32211 (2022). \n39. Goga, N. et al. An efficient system for Eye Movement Desensitization and Reprocessing \n(EMDR) therapy: A pilot study. Healthcare (Basel) 10, (2022). \n40. Tulsulkar, G. et al. Can a humanoid social robot stimulate the interactivity of cognitively \nimpaired elderly? A thorough study based on computer vision methods. Vis. Comput. 37, \n3019–3038 (2021). \n41. Trappey, A. J. C., Lin, A. P. C., Hsu, K. Y. K., Trappey, C. V. & Tu, K. L. K. Development \nof an empathy-centric counseling chatbot system capable of sentimental dialogue analysis. \nProcesses 10, 930 (2022). \n42. Leo, A. J. et al. Digital mental health intervention plus usual care compared with usual care \nonly and usual care plus in-person psychological counseling for orthopedic patients with \n\n \n \n \n \n28 \n \nsymptoms of depression or anxiety: Cohort study. JMIR Form Res 6, e36203 (2022). \n43. De Nieva, J. O., Joaquin, J. A., Tan, C. B., Marc Te, R. K. & Ong, E. Investigating \nstudents’ use of a mental health chatbot to alleviate academic stress. in 6th International \nACM In-Cooperation HCI and UX Conference (ACM, 2020).  \n44. Gamborino, E., Yueh, H.-P., Lin, W., Yeh, S.-L. & Fu, L.-C. Mood estimation as a social \nprofile predictor in an autonomous, multi-session, emotional support robot for children. in \n2019 28th IEEE International Conference on Robot and Human Interactive Communication \n(RO-MAN) 1–6 (2019). \n45. Pham, M., Do, H. M., Su, Z., Bishop, A. & Sheng, W. Negative emotion management using \na smart shirt and a robot assistant. IEEE Robotics and Automation Letters 6, 4040–4047 \n(2021). \n46. Daley, K. et al. Preliminary evaluation of the engagement and effectiveness of a mental \nhealth chatbot. Front Digit Health 2, 576361 (2020). \n47. Demirci, H. M. User experience over time with conversational agents: Case study of \nWoebot on supporting subjective well-being. (Middle East Technical University, 2018). \n48. Legaspi, C. M., Jr, Pacana, T. R., Loja, K., Sing, C. & Ong, E. User perception of Wysa as a \nmental well-being support tool during the COVID-19 pandemic. in Asian HCI \nSymposium’22 52–57 (Association for Computing Machinery, 2023). \n49.  Wrightson-Hester, A.-R. et al. An artificial therapist (Manage Your Life Online) to support \nthe mental health of youth: Co-design and case series. JMIR Hum Factors 10, e46849 \n(2023). \n50.  Chiauzzi, E. et al. Demographic and clinical characteristics associated with anxiety and \ndepressive symptom outcomes in users of a digital mental health intervention incorporating \n\n \n \n \n \n29 \n \na relational agent. Preprint at https://doi.org/10.21203/rs.3.rs-2488688/v1 (2023). \n51. Linardon, J, Cuijpers, P, Carlbring, P, Messer, M, & Fuller-Tyszkiewicz, M. The efficacy of \napp-supported smartphone interventions for mental health problems: a meta-analysis of \nrandomized controlled trials. World Psychiatry. 18 (3), 325-336 (2019).  \n52. van Agteren J, Iasiello M, Lo L, Bartholomaeus J, Kopsaftis Z, Carey M, et al. A systematic \nreview and meta-analysis of psychological interventions to improve mental wellbeing. Nat \nHum Behav 5(5), 631–52 (2021). \n53. Hak, T., van Rhee, H. & Suurmond, R. How to interpret results of meta-analysis. \n(Rotterdam, The Netherlands: Erasmus Rotterdam Institute of Management, 2016). \n54. Cho, E. Hey Google, Can I ask you something in private? in Proceedings of the 2019 CHI \nConference on Human Factors in Computing Systems 1–9 (Association for Computing \nMachinery, 2019). \n55.   Druga, S., Williams, R., Breazeal, C. & Resnick, M. Hey Google is it OK if I eat you? in \nProceedings of the 2017 Conference on Interaction Design and Children (Association for \nComputing Machinery, 2017). \n56.   Loveys, K., Hiko, C., Sagar, M., Zhang, X. & Broadbent, E. ‘I felt her company’: A \nqualitative study on factors affecting closeness and emotional support seeking with an \nembodied conversational agent. Int. J. Hum. Comput. Stud. 160, 102771 (2022). \n57.   Sezgin, E., Huang, Y., Ramtekkar, U. et al. Readiness for voice assistants to support \nhealthcare delivery during a health crisis and pandemic. npj Digit. Med. 3, 122 (2020). \n58.   Singh, B., Olds, T., Brinsley, J. et al. Systematic review and meta-analysis of the \neffectiveness of chatbots on lifestyle behaviours. npj Digit. Med. 6, 118 (2023).  \n59. Driessen, E., Cuijpers, P., Hollon, S. D. & Dekker, J. J. M. Does pretreatment severity \n\n \n \n \n \n30 \n \nmoderate the efficacy of psychological treatment of adult outpatient depression? A meta-\nanalysis. J. Consult. Clin. Psychol. 78, 668–680 (2010). \n60.  Cuijpers, P. et al. Psychotherapy for depression across different age groups: A systematic \nreview and meta-analysis. JAMA Psychiatry 77, 694–702 (2020). \n61.   Firth, J. et al. The efficacy of smartphone-based mental health interventions for depressive \nsymptoms: a meta-analysis of randomized controlled trials. World Psychiatry 16, 287–298 \n(2017). \n62.  Wampold, B. E. How important are the common factors in psychotherapy? An update. \nWorld Psychiatry 14, 270–277 (2015). \n63. Charlson, F. et al. New WHO prevalence estimates of mental disorders in conflict settings: \na systematic review and meta-analysis. Lancet 394, 240–248 (2019). \n64. McHugh, M. L. Interrater reliability: the kappa statistic. Biochem. Med.  22, 276–282 \n(2012). \n65. O’Brien, H. L. & Toms, E. G. What is user engagement? A conceptual framework for \ndefining user engagement with technology. J. Am. Soc. Inf. Sci. Technol. 59, 938–955 \n(2008). \n66. Viertiö, S. et al. Factors contributing to psychological distress in the working population, \nwith a special reference to gender difference. BMC Public Health 21, 611 (2021). \n67. Cohen, J. A power primer. Psychol. Bull. 112, 155–159 (1992). \n68. Assink, M. & Wibbelink, C. J. M. Fitting three-level meta-analytic models in R: A step-by-\nstep tutorial. Quant. Methods Psychol. 12, 154–174 (2016). \n69. Higgins JPT, Green S. Cochrane handbook for systematic reviews of interventions version \n5.1.0. 2011. https://handbook-5 1.cochrane.org /chapter_7/7_7_3_2_obtaining_ standard_ \n\n \n \n \n \n31 \n \ndeviations_from_standard_errors_and.htm (accessed Nov 10, 2022). \n70. Higgins JPT, Green S. Cochrane handbook for systematic reviews of interventions version \n5.1.0. 2011. https://handbook-5-1.cochrane.org/chapter_16/ 16_5_4_how_to_include _ \nmultiple_groups_from_one_study.htm (accessed Nov 10, 2022). \n71. Higgins, J. P. T. et al. Cochrane Handbook for Systematic Reviews of Interventions. (John \nWiley & Sons, 2019). \n72. Wang, L., Mujib, M. I., Williams, J., Demiris, G. & Huh-Yoo, J. An evaluation of \ngenerative pre-training model-based therapy chatbot for caregivers. Preprint at  \nhttps://doi.org/10.48550/arXiv.2107.13115 (2021). \n73. Higgins, J. P. T. et al. The Cochrane Collaboration’s tool for assessing risk of bias in \nrandomised trials. BMJ 343, d5928 (2011). \n74. Guyatt, G.H., Oxman, A.D., Vist, G.E., Kunz, R., Falck-Ytter, Y., Alonso-Coello, P., \nSchünemann, H.J. GRADE: an emerging consensus on rating quality of evidence and \nstrength of recommendations. BMJ 336, 924-6 (2008). \n75. Massetti, G. M., Thomas, C. C., King, J., Ragan, K. & Buchanan Lunsford, N. Mental \nHealth Problems and Cancer Risk Factors Among Young Adults. Am. J. Prev. Med. 53, \nS30–S39 (2017). \n76.   Moher, David, et al. Preferred reporting items for systematic reviews and meta-analyses: the \nPRISMA statement. Int J Surg. 8 (5), 336-341 (2010). \n\n32 \n \n \nFigure Legends \nFig.1 PRISMA flow diagram. Search and study selection process. \n \nFig.2 Summary of psychological outcomes evaluated in the studies \n \nFig.3 Effects of AI-based CA interventions on psychological distress. Note: the pooled effect \nsizes (Hedges’g) on psychological distress were reverse coded from their original values to align \nwith the directionality of the pooled effect sizes on psychological well-being, i.e., positive effect \nsizes indicate a more favorable outcome for the CA intervention compared to control conditions.  \n \nFig. 4 Effects of AI-based CA interventions on psychological well-being. Note: positive effect \nsizes indicate a more favorable outcome for the CA intervention compared to control conditions.  \n  \n \n \n \n \n \n\n\n\nRE model\n−1 0 1 2 3 4 5\nSabout et al. (2023).2\nSabout et al. (2023).1\nTawfik et al. (2023)\nNicol et al. (2022).2\nNicol et al. (2022).1\nLiu et al. (2022).2\nLiu et al. (2022).1\nBennion et al. (2020)\nHe et al. (2022)\nRomanovskyi et al. (2021).2\nRomanovskyi et al. (2021).1\nFitzpatrick et al. (2017).2\nFitzpatrick et al. (2017).1\nTerblanche et al. (2022)\nOgawa et al. (2022)\nKlos et al. (2021).1\nBird et al. (2018).3\nBird et al. (2018).2\nBird et al. (2018).1\nProchaska et al. (2021).2\nProchaska et al. (2021).1\n70\n70\n50\n10\n10\n33\n33\n47\n45\n42\n42\n31\n31\n97\n10\n27\n82\n82\n82\n71\n71\n177\n177\n100\n7\n7\n30\n30\n47\n80\n40\n40\n25\n25\n121\n10\n23\n77\n77\n77\n81\n81\nHigh risk of bias\nHigh risk of bias\nSome concerns\nLow risk of bias\nLow risk of bias\nSome concerns\nSome concerns\nHigh risk of bias\nLow risk of bias\nSome concerns\nSome concerns\nSome concerns\nSome concerns\nHigh risk of bias\nSome concerns\nHigh risk of bias\nHigh risk of bias\nHigh risk of bias\nHigh risk of bias\nSome concerns\nSome concerns\n6.20% 0.10 [ −0.18, 0.37]\n6.20% 0.23 [ −0.05, 0.51]\n2.81% 2.37 [ 1.94, 2.80]\n3.35% 0.69 [ −0.30, 1.69]\n3.32% 0.91 [ −0.10, 1.93]\n5.24% 0.94 [ 0.42, 1.46]\n5.27% 0.34 [ −0.15, 0.84]\n2.83% 0.04 [ −0.36, 0.45]\n2.85% 0.88 [ 0.50, 1.27]\n4.51% 3.98 [ 3.24, 4.73]\n4.91% 1.70 [ 1.20, 2.21]\n5.14% 0.62 [ 0.08, 1.16]\n5.16% −0.15 [−0.68, 0.38]\n2.91% 0.11 [ −0.16, 0.38]\n2.34% 1.02 [ 0.09, 1.95]\n2.71% 0.48 [ −0.08, 1.05]\n7.38% −0.15 [−0.46, 0.16]\n7.38% −0.16 [−0.47, 0.15]\n7.38% −0.20 [−0.51, 0.12]\n6.05% 0.11 [ −0.21, 0.42]\n6.05% 0.13 [ −0.19, 0.44]\n100.00% 0.70 [ 0.18, 1.22](Q = 267.98, df = 20, p = 0.00, I2=95.3%) Favor control Favor CA\nAuthor(s) and Year CA(n) Control(n) Risk of Bias Weight Hedges'g 95% CI\n\nRE model\n−1 0 1 2 3\nSabout et al. (2023).2\nSabout et al. (2023).1\nNicol et al. (2022)\nLiu et al. (2022).2\nLiu et al. (2022).1\nPapadopoulos et al. (2022)\nDrouin et al. (2022).2\nDrouin et al. (2022).1\nRomanovskyi et al. (2021).2\nRomanovskyi et al. (2021).1\nFitzpatrick et al. (2017).2\nFitzpatrick et al. (2017).1\nTerblanche et al. (2022).2\nTerblanche et al. (2022).1\n70\n70\n10\n33\n33\n12\n132\n132\n42\n42\n31\n31\n97\n97\n177\n177\n7\n30\n30\n21\n146\n146\n40\n40\n25\n25\n121\n121\nHigh risk of bias\nHigh risk of bias\nLow risk of bias\nSome concerns\nSome concerns\nSome concerns\nSome concerns\nSome concerns\nSome concerns\nSome concerns\nSome concerns\nSome concerns\nHigh risk of bias\nHigh risk of bias\n8.88% 0.19 [ −0.09, 0.46]\n8.88% −0.08 [−0.36, 0.20]\n2.82% 0.70 [ −0.30, 1.69]\n6.70% −0.10 [−0.59, 0.40]\n6.69% −0.20 [−0.69, 0.30]\n3.49% 0.84 [ 0.11, 1.58]\n9.28% 0.08 [ −0.15, 0.32]\n9.28% −0.18 [−0.42, 0.05]\n6.38% 2.28 [ 1.72, 2.84]\n6.83% 0.80 [ 0.35, 1.25]\n6.39% 0.22 [ −0.31, 0.75]\n6.40% 0.12 [ −0.41, 0.64]\n8.98% 0.01 [ −0.25, 0.28]\n8.98% −0.09 [−0.36, 0.17]\n100.00% 0.32 [ −0.13, 0.78](Q = 85.70, df = 13, p = 0.00, I2=91.3%) Favor control Favor CA\nAuthor(s) and Year CA(n) Control(n) Risk of Bias Weight Hedges'g 95% CI\n\n    Table 1 Major characteristics of studies included in the systematic review \nStudy and Sample characteristics Intervention characteristics CA design characteristics Mechanisms Outcomes  Note \nAuthor, \nyear,  \nregion \nStudy \ntype, \nduration \nPopulation \ntype \nSample \nsize \nTarget \ncondition \nDeplo\nyment \nCA name, role  Response \ngeneration \napproach, \nAI \nframework/ \ntechnique \nInterac\ntion \nmode \nDelivery \nplatform \nTherapeutic \napproach \nPsychological \noutcomes (and \nmeasures) \nIncluded in \nmeta-\nanalysis \nProchaska \net al. \n(2021)18; \nUSA \nRCT \n[8 weeks] \nSubclinical \n[adults \nscreened \nwith SUDs] \n180 Substance \nuse \ndisorders \nStand-\nalone \nWoebot-SUDs; \npsychotherapy/\neducation \nRetrieval-\nbased \n[NLP] \nText-\nbased \nSmartpho\nne app \nIntegrative \napproach \n[DBT, CBT, \nmindfulness] \nDepression, \nanxiety [PHQ-\n8, GAD-7] \nYes \nBird et al. \n(2018)19; \nUK \nRCT \n[15 \nminutes] \nNonclinical \n[college \nstudents] \n213 Problem \ndistress \nStand-\nalone \nMYLO; \npsychotherapy \nRetrieval-\nbased \n[NLP] \nText-\nbased \nWeb- \nbased \nMOL Problem \ndistress, \ndepression, \nanxiety, stress \n[DASS-21] \nYes \nKlos et al. \n(2021)20; \nArgentina \nRCT  \n[8 weeks] \nNonclinical \n[college \nstudents] \n181 Depression \nand \nanxiety  \nStand-\nalone \nTess; \npsychotherapy/\neducation \nRetrieval-\nbased [NLP, \nemotion \nalgorithm] \nText-\nbased \nFacebook \nmessenge\nr \nIntegrative \napproach \n[CBT, EFT, \nSFBT, \nmotivational \ninterviewing] \nDepression, \nanxiety [PHQ-\n9, GAD-7] \nYes \nOgawa et \nal. \n(2022)21; \nJapan \nRCT \n[5 \nmonths] \nClinical \n[older adults \ndiagnosed \nwith \nParkinson’s \ndisease] \n20 Parkinson’s \ndisease \nIntegra\nted \nwith \nvideo \nconfer\nence \nNo name; \nteleconsultation \nRetrieval-\nbased \n[NLP] \nVoice- \nbased \nTablet \napp \nNR Depression \n[BDI-II] \nYes \n\nTerblanch\ne et al. \n(2022)22; \nUK \nRCT  \n[6 \nmonths] \nNonclinical \n[college \nstudents] \n268 Psychologi\ncal well-\nbeing \nStand- \nalone \nVici;  \ncoach for goal \nattainment \nRetrieval-\nbased \n[NLP] \nText-\nbased \nTelegram \nmessenge\nr \nNR Psychological \nwell-being, \nperceived \nstress, mental \nresilience \n[WEMWBS, \nPSS, BRS] \nYes \nFitzpatric\nk et al. \n(2017)23; \nUSA \nRCT  \n[2 weeks] \nSubclinical \n[college \nstudents \nscreened \nwith \ndepression \nand anxiety] \n70 Depression \nand anxiety \nStand- \nalone \nWoebot; \npsychotherapy/ \neducation \nRetrieval-\nbased \n[NLP]  \nText-\nbased \nSmartpho\nne app \nCBT Depression, \nanxiety, \npositive and \nnegative \naffect [PHQ-\n9, GAD-7, \nPANAS] \nYes \nRomanov\nskyi et al. \n(2021)24; \nUkraine \nRCT  \n[4 weeks] \nSubclinical \n[college \nstudents \nscreened \nwith \ndepression \nand/or \nanxiety] \n82 Depression\n, anxiety, \nand \nnegative \nemotions \nStand- \nalone  \nElomia; \npsychotherapy/ \neducation \nGenerative \n[GPT-2, \nBERT, \nemotion \nalgorithm] \nText-\nbased  \nSmartpho\nne app \nCBT Depression, \nanxiety, \npositive and \nnegative \naffect [PHQ-\n9, GAD-7, \nPANAS] \nYes \nDrouin et \nal. \n(2022)25; \nUSA \nRCT \n [20 \nminutes] \nNonclinical \n[college \nstudents] \n417 Psychologi\ncal well-\nbeing \nStand- \nalone \nReplika;  \nsocial \ncompanion \nGenerative \n(LSTM) \nMulti\nmodal \nDesktop \napp \nNR Positive and \nnegative \naffect \n[PANAS] \nYes \nHe et al. \n(2022)26; \nChina \nRCT  \n[1 week]  \nSubclinical \n[college \nstudents \nscreened \nwith \ndepression] \n148 Depression Stand- \nalone \nXiaoE; \npsychotherapy/ \neducation \nGenerative \n[NLP, DP] \nMulti\nmodal \nWeChat \nmessenge\nr \nCBT Depression \n[PHQ-9] \nYes \n\nPapadopo\nulos et al. \n(2022)27; \nUK and \nJapan \nRCT  \n[2 weeks] \nNonclinical \n[older adults \nin care \nhome] \n33 Psychologi\ncal well-\nbeing \nStand- \nalone \nPepper;  \nsocial \nassistance \nRetrieval-\nbased \n[NLP] \nVoice- \nbased \nrobot NR Emotional \nwell-being, \nloneliness \n[SF-36, ULS-\n8] \nYes \nBennion \net al. \n(2020)28; \nUK \nRCT  \n[20 \nminutes] \nNonclinical \n[older \nadults] \n112 Problem \ndistress \nStand- \nalone \nMYLO; \npsychotherapy \nRetrieval-\nbased \n[NLP] \nText-\nbased \nWeb-\nbased \nMOL Problem \ndistress, \ndepression, \nanxiety, stress \n[DASS-21] \nYes \nLiu et al. \n(2022)29; \nChina \nRCT \n [16 \nweeks] \nSubclinical \n[college \nstudents \nscreened \nwith \ndepression] \n83 Depression Stand- \nalone \nXiaoNan; \npsychotherapy/ \neducation  \nRetrieval-\nbased [NLP, \nML, \nemotion \nalgorithm] \nMulti\nmodal \nWeChat \nmessenge\nr \nCBT Depression, \nanxiety, \npositive and \nnegative \naffect [PHQ-\n9, GAD-7, \nPANAS] \nYes \nNicol et \nal. \n(2022)30; \nUSA \nRCT  \n[4 weeks] \nClinical \n[adolescents \ndiagnosed \nwith \ndepression \nand anxiety] \n17 Depression Stand- \nalone \nWoebot; \npsychotherapy/ \neducation \nRetrieval-\nbased [NLP, \nML] \nText-\nbased \nSmartpho\nne app \nIntegrative \napproach \n[CBT, DBT, \ninterpersonal \npsychotherap\ny] \nDepression, \nanxiety, \nmental health \nself-efficacy \n[PHQ-9, \nGAD-7, \nMHSES] \nYes \nTawfik et \nal. \n(2023)31; \nEgypt \nRCT  \n[3 \nmonths] \nClinical \n[women \ndiagnosed \nbreast \ncancer] \n150 Breast \ncancer \nStand- \nalone  \nChemoFreeBot\n; \npsychoeducatio\nn \nRetrieval-\nbased \n[NLP] \nText-\nbased \nWhatsapp \nmessenge\nr \nNR Psychological \ndistress \n[MSAS-\nPSYCH] \nYes \nSabour et \nal. \n(2023)32; \nChina \nRCT  \n[3 weeks] \nNonclinical \n[general \npopulation] \n247 Psychologi\ncal distress \nStand- \nalone \nEmohaa-ES; \nsocial \ncompanion/ \nGenerative \n[GPT] \nText-\nbased \nWeChat \nmessenge\nr \nNR Depression, \nanxiety, \npositive and \nnegative \nYes \n\nemotional \nsupport  \naffect [PHQ-\n9, GAD-7, \nPANAS] \nFulmer et \nal. \n(2018)17; \nUSA \nRCT  \n[2-4 \nweeks] \nNonclinical \n[college \nstudents] \n74 Depression \nand anxiety \nStand- \nalone \nTess; \npsychotherapy/ \neducation \nRetrieval-\nbased [NLP, \nML] \nText-\nbased \nCommon \ninstant \nmessenge\nrs \nIntegrative \napproach \n[CBT, EFT, \nACT, \nmindfulness, \nself-\ncompassion \ntherapy, \ninterpersonal \npsychotherap\ny] \nDepression, \nanxiety, \npositive and \nnegative \naffect [PHQ-\n9, GAD-7, \nPANAS]  \nNo \n[insufficient \ndata \nreported] \nVertsberg\ner et al. \n(2022)33; \nUSA \nQuasi-\nexperime\nnt \n[4 \nmonths] \nNonclinical \n[adolescents\n] \n10387 Psychologi\ncal well-\nbeing \nStand- \nalone \nKai.ai; \npsychotherapy/ \neducation \nRetrieval-\nbased \n[NLP] \nText-\nbased \nCommon \ninstant \nmessenge\nrs \nIntegrative \napproach \n[ACT, \nmindfulness, \npositive \npsychology] \nPsychological \nwell-being \n[WHO-5] \nNo [Non-\nRCT] \nLeo et al. \n(2022)34; \nUSA \nQuasi-\nexperime\nnt  \n[2 \nmonths] \nClinical \n[adults \ndiagnosed \nwith \nmusculoskel\netal \ncondition \nand \nscreened \nwith \ndepression \nand/or \nanxiety] \n61 Depression \nand \nanxiety  \nStand- \nalone \nWysa; \npsychotherapy/ \neducation \nRetrieval-\nbased [NLP, \nML] \nText-\nbased \nSmartpho\nne app \nIntegrative \napproach \n[BA, CBT, \nDBT, \nmindfulness] \nDepression \nand anxiety \n[PROMIS] \nNo [Non-\nRCT] \n\nRathnaya\nka et al. \n(2022)35; \nUSA (S1) \nQuasi-\nexperime\nnt  \n[8 weeks] \nNonclinical \n[general \npopulation] \n34 Mental \nhealth \nproblems \nStand- \nalone \nBunji; social \ncompanionship \n/remote mental \nhealth \nmonitoring \nRetrieval-\nbased [NLP, \nneural \nnetwork \nmodel, \nemotion \nalgorithm] \nText-\nbased \nSmartpho\nne app \nBA Mood [self-\nreport feeling \ncheck] \nNo [Non-\nRCT] \nRathnaya\nka et al. \n(2022)35; \nUSA (S2) \nQuasi-\nexperime\nnt [8 \nweeks] \nNonclinical \n[general \npopulation] \n30 Mental \nhealth \nproblems \nStand- \nalone \nBunji; social \ncompanionship \n& remote \nmental health \nmonitoring \nRetrieval-\nbased [NLP, \nneural \nnetwork \nmodel, \nemotion \nalgorithm] \nText-\nbased \nSmartpho\nne app \nBA Mood and \nemotion states \n[self-report \nfeeling check \nand emotion \nanalysis] \nNo [Non-\nRCT] \nAbdollahi \net al. \n(2017)36; \nUSA \nQuasi-\nexperime\nnt [4-6 \nweeks] \nSubclinical \n[older adults \nin dementia \nand/or \ndepression] \n6 Quality of \nlife \nStand- \nalone \nRyan; social \ncompanion and \nassistance \nRetrieval-\nbased \n[NLP] \nVoice-\nbased \nRobot NR Mood [self-\nreport Likert \nand caregiver \nevaluation] \nNo [Non-\nRCT] \nProchaska \net al. \n(2021)37; \nUSA \nQuasi-\nexperime\nnt  \n[8 weeks] \nSubclinical \n[adults \nscreened \nwith SUDs] \n101 Substance \nuse \ndisorders \nStand- \nalone \nWoebot-SUDs; \npsychotherapy/ \neducation  \nRetrieval-\nbased \n[NLP] \nText-\nbased \nSmartpho\nne app \nIntegrative \napproach \n[DBT, CBT, \nmindfulness] \nDepression, \nanxiety [PHQ-\n8, GAD-7] \nNo [Non-\nRCT] \nBassi et \nal. \n(2022)38; \nItaly \nQuasi-\nexperime\nnt  \n[12 days] \nClinical \n[adults \ndiagnosed \nwith \ndiabetes \nmellitus] \n13 Depression\n, anxiety, \nand \ndiabetes-\nrelated \ndistress \nStand- \nalone \nMotibot; \npsychotherapy/\neducation, \ncounseling \nRetrieval-\nbased [NLP, \nNLU] \nText-\nbased \nTelegram \nmessenge\nr \nTranstheoreti\ncal model of \nchange \nDepression, \nanxiety, \nstress, \npsychological \nwell-being, \ndiabetes-\nrelated \ndistress \n[ PHQ-9, \nGAD-7, PSS-\nNo [Non-\nRCT] \n\n10, WHO-5, \nPAID-5] \nGoga et \nal. \n(2022)39; \nRomania \nQuasi-\nexperime\nnt \n[several \nfour-\nminute \nsessions] \nSubclinical \n[adults \nscreened \nwith PTSD] \n31 PTSD Integra\nted \nwith \nEMDR  \nNo name; \nEMDR \ncoordination \nRetrieval-\nbased [NLP, \nML] \nMulti\nmodal \nEMDR NR Psychological \ndistress, \nanxiety [IES-\nR, STAI] \nNo [Non-\nRCT] \nTulsulkar \net al. \n(2021)40; \nSingapore \nQuasi-\nexperime\nnt  \n[6 days] \nClinical \n[older adults \ndiagnosed \nwith \ncognitive \nimpairments\n] \n14 Psychologi\ncal well-\nbeing \nStand- \nalone \nNadine;  \nsocial \ncompanionship\n/ assistance  \nRetrieval-\nbased [NLP, \nemotion \nalgorithm] \nVoice-\nbased \nrobot NR Emotion \nstates [OERS] \nNo [Non-\nRCT] \nTrappey \net al. \n(2022)41; \nTaiwan \nQuasi-\nexperime\nnt [NR] \nNonclinical \n[college \nstudents] \n34 Psychologi\ncal well-\nbeing \nIntegra\nted \nwith \ncounse\nling \nsystem \nVRECC; \npsychotherapy, \ncounseling \nGenerative \n[BERT, \nNLU, NLG] \nMulti\nmodal \nVR Person-\ncentered \ntherapy  \nStress, \npsychological \nsensitivity \n[Student \nStress Survey] \nNo [Non-\nRCT] \nLeo et al. \n(2022)42; \nUSA  \nQuasi-\nexperime\nnt  \n[2 \nmonths] \nClinical \n[orthopedic \npatients \nscreened \nwith \ndepression \nand/or \nanxiety] \n153 Depression \nand anxiety \nStand- \nalone \nWysa; \npsychotherapy/\neducation \nRetrieval-\nbased [NLP, \nML] \nText-\nbased \nSmartpho\nne app \nIntegrative \napproach \n[CBT, BA, \nmindfulness] \nDepression, \nanxiety \n[PROMIS] \nNo [Non-\nRCT] \nDe Nieva \net al. \n(2020)43; \nQuasi-\nexperime\nnt  \nNonclinical \n[adolescents\n] \n25 Stress Stand- \nalone \nWoebot; \npsychotherapy/\neducation \nRetrieval-\nbased \n[NLP] \nText-\nbased \nSmartpho\nne app \nCBT Stress [PSS] No [Non-\nRCT] \n\nPhilippine\ns \n[2 weeks] \nGamborin\no et al. \n(2019)44; \nTaiwan \nQuasi-\nexperime\nnt \n [4 days] \nNonclinical \n[children] \n19 Psychologi\ncal well-\nbeing, \nemotional \nsupport \nStand- \nalone \nRoBoHoN; \nsocial \ncompanion \nRetrieval-\nbased [IRL, \nNLP, \nemotion \nalgorithm] \nVoice-\nbased \nrobot NR Mood [facial \nexpression \nand body \ngesture] \nNo [Non-\nRCT] \nPham et \nal. \n(2021)45; \nUSA  \nQuasi-\nexperime\nnt [NR] \nNonclinical \n[community\n-dwelling \nolder adults] \n26 Psychologi\ncal well-\nbeing \nStand- \nalone \nNo name;  \nsocial \ncompanion/ \nassistance \nRetrieval-\nbased [NLP, \nemotion \nalgorithm] \nVoice-\nbased \nrobot NR Loneliness, \npositive and \nnegative \naffect, fatigue \n[ULS-8, \nPANAS, IFS]  \nNo [Non-\nRCT] \nDaley et \nal. \n(2020)46; \nBrazil \nQuasi-\nexperime\nnt  \n[1 month] \nNonclinical \n[general \npopulation] \n3629 Depression\n, anxiety \nand stress \nStand- \nalone \nVitalk; \npsychotherapy/\neducation \nRetrieval-\nbased [NLP, \nNLU] \nText-\nbased \nCommon \ninstant \nmessenge\nrs \nIntegrative \napproach \n[CBT, \npositive \npsychology] \nDepression, \nanxiety, stress \n[PHQ-9, \nGAD-7, \nDASS-21] \nNo [Non-\nRCT] \nDEMİRC\nİ. \n(2018)47; \nTurkey \nQuasi-\nexperime\nnt  \n[2 weeks] \nNonclinical \n[college \nstudents] \n16 Psychologi\ncal well-\nbeing \nStand- \nalone \nWoebot; \npsychotherapy/\neducation \nRetrieval-\nbased \n[NLP] \nText-\nbased \nSmartpho\nne app \nCBT Psychological \nwell-being \n[FS] \nNo [Non-\nRCT] \nLegaspi \nJr. et al. \n(2022)48; \nPhilippine\ns \nQuasi-\nexperime\nnt  \n[1 week] \nNonclinical \n[adolescents\n] \n10 Psychologi\ncal well-\nbeing \nStand- \nalone \nWysa; \npsychotherapy/\neducation \nRetrieval-\nbased [NLP, \nML] \nText-\nbased \nSmartpho\nne app \nIntegrative \napproach \n[positive \npsychology, \nmindfulness] \nStress, \nloneliness, \nworry [PSS, \nULS-8, \nPSWQ] \nNo [Non-\nRCT] \nWrightso\nn-Hester \net al. \n(2023)49; \nAustralia \nQuasi-\nexperime\nnt  \n[2 weeks] \nSubclinical \n[young \npeople \nexperiencin\ng \n13 Mental \nhealth \nproblems \nStand- \nalone \nMYLO; \npsychotherapy \nRetrieval-\nbased [NLP, \nRL] \nText-\nbased \nSmartpho\nne app \nMOL Depression, \nanxiety, \npsychiatric \nimpairment, \nproblem \nNo [Non-\nRCT] \n\ndepression, \nanxiety \nand/or low \nmood] \ndistress, \nmental health \nself-efficacy \n[PHQ-9, \nGAD-7, \nGHQ-12, \nPSYCHLOPS\n, General Self-\nEfficacy \nScale] \nChiauzzi \net al. \n(2023)50; \nUSA \nQuasi-\nexperime\nnt  \n[8 weeks] \nSubclinical \n[adults \nscreened for \ndepression \nor anxiety] \n256 Depression \nand/or \nanxiety \nStand- \nalone \nWoebot; \npsychotherapy/\neducation \nRetrieval-\nbased \n[NLP] \nText-\nbased \nSmartpho\nne app \nIntegrative \napproach \n[CBT, IPT, \nDBT] \nDepression, \nanxiety [PHQ-\n8, GAD-7] \nNo [Non-\nRCT] \nAbbreviations. \nAbbreviations for therapeutic approaches: ACT=Acceptance and commitment therapy, BA=Behavioral Activation, CBT=Cognitive Behavioral Therapy, DBT=Dialectical \nBehavior Therapy, EFT=Emotion-Focused Therapy, MOL=Method of Levels, SFBT=Solution-Focused Brief Therapy; \n \nAbbreviations for outcome measures: BDI-II=Beck Depression Inventory-II, BRS=Brief Resilience Scale, DASS-21=Depression Anxiety Stress Scales-21, FS=The \nFlourishing Scale, GAD-7=Generalized Anxiety Disorder-7, GDS=Geriatric Depression Scale, GHQ-12=General Health Questionnaire, IES-R=Impact of Events Scale-\nRevised, IFS=Iowa Fatigue Scale, MHSES=Mental health Self-Efficacy Scale, MSAS-PSYCH=Memorial Symptom Assessment Scale-Psychological symptom distress, \nOERS=Observed Emotion Rating Scale, PAID-5=Problem Areas in Diabetes-5, PANAS=Positive and Negative Affect Scale, PHQ-8=Patient Health Questionnaire-8, PHQ-\n9=Patient Health Questionnaire-9, PROMIS=Patient-Reported Outcomes Measurement Information System, PSS=Perceived Stress Scale, PSS-10=Perceived Stress Scale-10, \nPSWQ=Penn State Worry Questionnaire, SF-36=36-Item Short Form Survey, PSYCHLOPS=Psychological Outcome Profiles, STAI=State-Trait Anxiety Inventory, ULS-\n8=UCLA Loneliness-8, WEMWBS=Warwick-Edinburgh Mental Wellbeing Scale, WHO-5=5-item World Health Organization Well-being Index; \n \nAbbreviations for AI techniques: ALML=Artificial Intelligence Markup Language, DP=Deep Learning, GPT=Generative Pre-training Transformer, GPT-2=Generative Pre-\ntraining Transformer-2, IRL=Interactive Reinforcement Learning, LSTM=Long Short-Term Memory Networks, ML=Machine Learning, NLG=Natural Language Generation, \nNLP=Natural Language Processing, RL=Reinforcement Learning; \n  \nOther Abbreviations: EMDR=Eye Movement Desensitization and Reprocessing, NR=Not report, PTSD=Post-Traumatic Stress Disorder, SUDs=Substance Use Disorders. \n \nNotes.  \n\n1. We classified CA deployment into two categories: stand-alone: the CA operates independently without being part of any other system or ap plication; integrated: the CA is \nincorporated into or combined with another system, therapy, or service, which means that the CA is a component of a larger therapeutic system or framework.   \n2. Study duration refers to the active period of the CA-based interventions, which did not include any subsequent follow-up periods.  \n \n \n\n \nTable 2 Summary of CA intervention and technical design characteristics \nCA intervention characteristics  CA design characteristics  \nCA intervention  No. (prop.) of studies CA design  No. (prop.) of studies \nDeployment of CA Response generation approach & AI techniques \n \n \nStand-alone \n \n \n32 (91.4%) \nRetrieval-based \n● NLP \n● Machine learning \n● Emotion algorithm \n● NLU \n● Neural network \n● RL \n30 (85.7%) \n30 (85.7%) \n7 (20%) \n6 (17.1%) \n2 (5.7%) \n2 (5.7%) \n2 (5.7%) \nIntegrated 3 (8.6%) Generative \n● GPT \n● BERT \n● LSTM \n● DP \n5 (14.3%) \n2 (5.7%) \n2 (5.7%) \n1 (2.9%) \n1 (2.9%) \nRole of CA Delivery platform \nPsychotherapy and/or \npsychoeducation \n22 (62.9%) Smartphone/ \ntablet app  \n16 (45.7%) \nSocial companionship \nand/or assistance \n9 (25.7%) Instant messenger  \nplatform \n9 (25.7%) \nRemote monitoring 2 (5.7%) robot 5 (14.3%) \nCoaching  2 (5.7%) web-based 3 (8.6%) \nCounseling  1 (2.9%) VR platform 1 (2.9%) \nTeleconsultation  1 (2.9%) EMDR platform 1 (2.9%) \nCoordination in \nEMDR \n1 (2.9%) Interaction mode \n  Text-based 24 (68.6%) \n  Multimodal/voice-based 11 (31.4%) \n \n\nTable 3 Narrative synthesis of open-ended user feedback \n \n \n \n \n \nFactors associated with \npositive user experience \nTherapeutic alliance support (n=8): \n Empathic communication17,23,26,29,38 (n=5)  \n Non-judgmental47,49 (n=2) \n Accountability (e.g., regular check-ins)23,43 (n=2) \n Human-like personality23,47 (n=2) \n Tailored feedback26 (n=1) \n Relationship26 (n=1) \nContent (n=6): \n Specific therapeutic approach and techniques29,38,43 (n=3) \n Content richness17,23,47 (n=3) \nLearning process17,23,29 (n=3) \nAccessibility17,29 (n=2) \nInteraction mode49 (n=1) \n \n \nFactors associated with \nnegative user experience \nCommunication breakdowns17,20,23,26,29,32,43,49 (n=8) \nContent (n=4): \n Topic of content17,26,29 (n=3) \n Format of content17,20 (n=2) \nImpersonal17,29 (n=2) \nInteraction mode32 (n=1) \nPreference for human support38 (n=1) \nTechnical issues26 (n=1) \n \n\nTable 4 Description of potential moderators \nModerator Type Subgroup (n) Description \n \n \n \n \n \n \nParticipant \ncharacteristics \nGender Percent of female in the sample. \nAge group: \n Adolescents/young \nadults (n=10) \n Middle-aged/older \nadults (n=5) \nStudies were categorized into two broad age groups \nbased on the mean age of participants in the sample75:  \n Adolescents/young adults (13-40 years);  \n middle-aged/older adults (>= 40 years).  \nHealth status: \n Clinical/subclinical \npopulation (n=8) \n Non-clinical \npopulation (n=7) \nWe defined clinical population as patients with a \nformal diagnosis of either physical or mental issues; \nSubclinical population includes those screened for or \nself-identified as having symptoms of mental \ndisorders, such as depression and anxiety during the \nstudy; Non-clinical consists of participants without \nself-identified or screened mental illness symptoms, or \nany diagnosed health issues. For the purposes of data \nanalysis, we further classified health statuses into two \ncategories: the clinical/subclinical population and the \nnon-clinical population.  \n \n \n \n \n \n \nCA features \nResponse generation \napproach: \n Retrieval-based \n(n=11) \n Generative (n=4) \nResponse generation approach pertains to the \ntechnique a CA employs to formulate responses to \nuser inputs \n Retrieval-based CAs select appropriate responses \nfrom a repository of pre-existing conversational \nutterances; \n Generative CAs automatically generate responses \nvia machine learning algorithms. \nInteraction mode: \n Text-based (n=10) \n Multimodal/voice-\nbased (n=5) \nText-based: users interact with the CA through textual \nmessages; \nMultimodal/voice-based: users interact with the CA \nusing either text or voice.  \nDelivery platform:  \n Smartphone/tablet \napplication (n=6) \n Instant messaging \nplatform (n=6) \n Web-based \nplatform (n=2) \n Robot (n=1) \nDelivery platform refers to the specific medium or \nchannel through which the CA interacts with users or \ndelivers its services.  \n Smartphone/tablet application: a CA deployed as \na standalone application on a smartphone, tablet, \nor other mobile devices.  \n Instant messenger: a CA that operates within \ncommon instant messaging platforms, such as \nWhatsApp, Facebook Messenger.   \n Web-based platform: a CA accessible through a \nweb browser on a computer or mobile device.  \n Robot: a CA integrated into a physical robot.   \n\n \n \n \nStudy design \nControl group type: \n Machine control \n(n=5) \n Human control \n(n=3) \n Psychoeducation \n(n=6) \n Usual care (n=2) \n Waitlist (n=3) \nWe categorized the types of control groups into five \ntypes:  \n Machine control: use of another type of CAs (e.g., \nrule-based);  \n Human control: human-led interventions;  \n Psychoeducation: information-only controls that \ndeliver minimal psychoeducational content, such \nas self-help guides or basic therapeutic advice;  \n Usual care: standard or conventional care \npractices; \n Waitlist: waitlist   \nNote. Given that some RCTs employed a three-arm design that included two control groups, the total count \nof control groups surpasses the number of RCTs.  \n \n",
  "topic": "Mental health",
  "concepts": [
    {
      "name": "Mental health",
      "score": 0.7368773818016052
    },
    {
      "name": "Psychological intervention",
      "score": 0.6013649702072144
    },
    {
      "name": "Meta-analysis",
      "score": 0.5453907251358032
    },
    {
      "name": "Systematic review",
      "score": 0.5013322830200195
    },
    {
      "name": "Randomized controlled trial",
      "score": 0.4757273495197296
    },
    {
      "name": "Psychology",
      "score": 0.46167609095573425
    },
    {
      "name": "Distress",
      "score": 0.4260198175907135
    },
    {
      "name": "Medicine",
      "score": 0.3670309782028198
    },
    {
      "name": "MEDLINE",
      "score": 0.3543202877044678
    },
    {
      "name": "Clinical psychology",
      "score": 0.3487880825996399
    },
    {
      "name": "Applied psychology",
      "score": 0.32367777824401855
    },
    {
      "name": "Psychiatry",
      "score": 0.250171959400177
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Surgery",
      "score": 0.0
    },
    {
      "name": "Internal medicine",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I165932596",
      "name": "National University of Singapore",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I74973139",
      "name": "Carnegie Mellon University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210163195",
      "name": "Behavioral Tech",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I111979921",
      "name": "Northwestern University",
      "country": "US"
    }
  ],
  "cited_by": 18
}