{
  "title": "MFVT: an anomaly traffic detection method merging feature fusion network and vision transformer architecture",
  "url": "https://openalex.org/W4226016066",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A1996079675",
      "name": "Ming Li",
      "affiliations": [
        "Shanghai Maritime University"
      ]
    },
    {
      "id": "https://openalex.org/A2107457640",
      "name": "De-zhi Han",
      "affiliations": [
        "Shanghai Maritime University"
      ]
    },
    {
      "id": "https://openalex.org/A2124725057",
      "name": "Dun Li",
      "affiliations": [
        "Shanghai Maritime University"
      ]
    },
    {
      "id": "https://openalex.org/A2126168353",
      "name": "Han Liu",
      "affiliations": [
        "Shanghai Maritime University"
      ]
    },
    {
      "id": "https://openalex.org/A2122019568",
      "name": "Chin-Chen Chang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1996079675",
      "name": "Ming Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2107457640",
      "name": "De-zhi Han",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2124725057",
      "name": "Dun Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2126168353",
      "name": "Han Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2122019568",
      "name": "Chin-Chen Chang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2961087419",
    "https://openalex.org/W3023906497",
    "https://openalex.org/W433644524",
    "https://openalex.org/W3211243177",
    "https://openalex.org/W2093859880",
    "https://openalex.org/W2600058599",
    "https://openalex.org/W2999988394",
    "https://openalex.org/W3125728023",
    "https://openalex.org/W2278186031",
    "https://openalex.org/W2040403168",
    "https://openalex.org/W2925211503",
    "https://openalex.org/W3131268649",
    "https://openalex.org/W3216889285",
    "https://openalex.org/W2031163547",
    "https://openalex.org/W3204421027",
    "https://openalex.org/W3191622740",
    "https://openalex.org/W3198675107",
    "https://openalex.org/W3182542716",
    "https://openalex.org/W2762776925",
    "https://openalex.org/W2097034581",
    "https://openalex.org/W2547629195",
    "https://openalex.org/W2120685459",
    "https://openalex.org/W2512144135",
    "https://openalex.org/W2100537916",
    "https://openalex.org/W2512772081",
    "https://openalex.org/W2092505457",
    "https://openalex.org/W2917814433",
    "https://openalex.org/W2952066300",
    "https://openalex.org/W2965481252",
    "https://openalex.org/W2997442262",
    "https://openalex.org/W6600662924",
    "https://openalex.org/W3161302809",
    "https://openalex.org/W2972825840",
    "https://openalex.org/W6604896550",
    "https://openalex.org/W3041454767",
    "https://openalex.org/W3016440541",
    "https://openalex.org/W3025413549",
    "https://openalex.org/W3196283616",
    "https://openalex.org/W3096547803"
  ],
  "abstract": null,
  "full_text": "MFVT: an anomaly traffic detection method \nmerging feature fusion network and vision \ntransformer architecture\nMing Li1, Dezhi Han1* , Dun Li1, Han Liu1 and Chin‑Chen Chang2 \n1 Introduction\nThe rapid development of the mobile Internet not only brings great convenience to net -\nwork users and society but also allows criminals to create a series of attacks in the net -\nwork. These attacks have seriously threatened the normal operation of the network, not \nonly caused a lot of economic losses but also brought hidden dangers to national secu -\nrity [1–3]. A group of behaviors that violate computer security policies such as confiden-\ntiality, integrity, and availability are defined as intrusion detection [4, 5]. As a security \nprotection system used to monitor computer network, the intrusion detection system \ncan detect suspicious behaviors and take corresponding measures to ensure the nor -\nmal operation of the network and reduce economic losses, which has been in use since \nthe 1980s [6, 7]. Recently, due to the rapid development of mobile Internet, attacks on \nInternet-connected devices are gradually increasing. Thus, many scholars have a strong \nAbstract \nNetwork intrusion detection, which takes the extraction and analysis of network traf‑\nfic features as the main method, plays a vital role in network security protection. The \ncurrent network traffic feature extraction and analysis for network intrusion detection \nmostly uses deep learning algorithms. Currently, deep learning requires a lot of training \nresources and has weak processing capabilities for imbalanced datasets. In this paper, \na deep learning model (MFVT) based on feature fusion network and vision transformer \narchitecture is proposed, which improves the processing ability of imbalanced datasets \nand reduces the sample data resources needed for training. Besides, to improve the \ntraditional raw traffic features extraction methods, a new raw traffic features extraction \nmethod (CRP) is proposed, and the CPR uses PCA algorithm to reduce all the processed \ndigital traffic features to the specified dimension. On the IDS 2017 dataset and the IDS \n2012 dataset, the ablation experiments show that the performance of the proposed \nMFVT model is significantly better than other network intrusion detection models, and \nthe detection accuracy can reach the state‑of‑the‑art level. And, when MFVT model is \ncombined with CRP algorithm, the detection accuracy is further improved to 99.99%.\nKeywords: Network intrusion detection, Traffic features, Deep learning, Feature fusion \nnetwork, Vision transformer, MFVT, CRP , Detection accuracy\nOpen Access\n© The Author(s) 2022. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits \nuse, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original \nauthor(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third \nparty material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the mate‑\nrial. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// \ncreat iveco mmons. org/ licen ses/ by/4. 0/.\nRESEARCH\nLi et al. J Wireless Com Network         (2022) 2022:39  \nhttps://doi.org/10.1186/s13638-022-02103-9\n*Correspondence:   \ndezhihan88@sina.com \n1 Department of Engineering, \nShanghai Maritime University, \nShanghai, China\nFull list of author information \nis available at the end of the \narticle\nPage 2 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \ninterest in the research of intrusion detection systems and good detection results have \nbeen achieved [8–10].\nBesides, the detection of anomaly network traffic is an important task of network \nintrusion detection, which is essential to classify network traffics [11], which requires \nresearchers to make accurate judgments on the collected network traffic data and detect \nnetwork traffic with offensive behavior. To detect anomaly traffics more effectively, net -\nwork traffic packets are usually divided into flows according to source IP , destination IP , \nsource port, destination port, protocol, and timestamp [12]. The current anomaly traf -\nfic detection technology mainly includes traditional network anomaly traffic detection \ntechnology and network anomaly traffic detection method based on machine learning. \nIn this paper, deep learning methods were used to classify network traffics. Deep learn -\ning methods have the characteristics of end-to-end and automatic extraction of network \ntraffic data features, to avoid the cumbersome process of manual extraction of features, \nand deep learning methods have good adaptability, self-organization, and promotion \nability. So, the use of deep learning can make the detection system have more stable per-\nformance and higher detection efficiency [13, 14].\nHowever, deep learning technology needs a large amount of labeled data for training, \nand labeled data require experts with specific knowledge to spend a lot of time on labe -\nling, which is time-consuming and laborious. Most of the datasets used in deep learning \nare imbalanced datasets. These problems cause a significant impact on the performance \nof deep learning models. Under-sampling and over-sampling are commonly used to \nsolve data imbalance problems, but under-sampling will discard some data leading to \nthe loss of some features, and over-sampling will add some data leading to changing the \noriginal data distribution, both of which have an impact on the experimental accuracy \n[15]. In this paper, the traffic features learned from a two-layer convolutional networks \nare fused, which can alleviate the impact of data imbalance on the accuracy of the exper-\niment. Due to the outstanding performance of transformer architecture in the field of \nnatural language processing (NLP) and the limitations of its application in computer \nvision, Dosovitskiy [16] improved the transformer architecture and proposed vision \ntransformer architecture for image sequence converter realize image classification and \nachieved good results. Meanwhile, experiments proved that vision transformer required \nfewer training resources. Inspired by the vision transformer architecture, a deep learning \nmodel (MFVT) based on the feature fusion network and the vision transformer archi -\ntecture was proposed in this paper for network anomaly traffic detection. MFVT model \nhas strong ability to deal with imbalanced datasets and therefore effectively reduce the \nsample resources required for training. This paper also studies the influence of learning \nrate change and the number of training epochs on the experimental accuracy based on \nthe MFVT model.\nSo far, there are many ways to process raw network traffic data, but there is no uniform \nstandard. Since the data that a neural network can accept must be of the same dimen -\nsion, the extracted network traffic data must be filtered to a specific dimension before it \ncan be used as the input of the neural network model. Most of the traditional methods \ndirectly intercept the data of specific dimensions from the network traffic data. Although \nthe effect is quite good, there is room for improvement. Therefore, PCA algorithm is \nused in this paper to reduce all the processed digital traffic features to a specified \nPage 3 of 22\nLi et al. J Wireless Com Network         (2022) 2022:39 \n \ndimension. The experimental accuracy obtained in the datasets IDS 2017 [17] and IDS \n2012 [18] is significantly higher than the traditional methods.\nIn summary, the main contributions of this paper are as follows.\n• A deep learning model (MFVT) based on feature fusion network and vision trans -\nformer architecture is proposed, which can effectively improve the detection accu -\nracy while reducing the training resources. On the IDS 2017 dataset and the IDS \n2012 dataset, MFVT model can achieve the best performance on all evaluation met -\nrics.\n• A new raw traffic data extraction algorithm (CRP) is proposed, which uses the PCA \n[19] algorithm to reduce the processed digital traffic features to a specified dimen -\nsion. The ablation experiment results show that the detection accuracy has signifi -\ncantly improved to compare with traditional methods.\n• Based on the MFVT model, the impact of training epochs and the variation of the \nlearning rate on the detection performance of the model is further studied.\nThe rest of this paper is organized as follows. Section 2 introduces the related works to \nthe model and method presented in this paper, Sect.3  details the deep learning model \nand the raw network traffic data processing algorithm, Sect.4 introduces ablation experi-\nments and experimental results of MFVT model in detail, and finally, our work is sum -\nmarized in Sect.5 .\n2  Related work\nThis section mainly summarizes some documents related to the work of this paper, \nincluding intrusion detection and transformer architecture.\n2.1  Intrusion detection\nWith the continuous development of artificial intelligence big data and cloud comput -\ning technology, intrusion detection technology is constantly updated using new tech -\nnologies [20–23] In 1980, Anderson [24] proposed the concept of intrusion detection \ntechnology, which aims to timely identify abnormal behaviors in the network and reduce \nlosses caused by abnormal behaviors. Over the past 40 years, many methods have been \nused in intrusion detection, all of which aim to sense attacks with good predictive accu -\nracy and improve real-time prediction. These methods all attempting to extract a pattern \nfrom network traffics to distinguish attack traffics from regular traffics.\nSpecifically, Table 1 briefly summarizes the methods used in intrusion detection. Cur -\nrently, the traditional machine learning methods applied to the field of intrusion detec -\ntion are mainly supervised learning, such as support vector machine (SVM) [25–27], \nK-nearest neighbor (KNN) [28], and random forest (RF) [29, 30]. These methods men -\ntioned above have a high false alarm rate and a low detection rate for attack traffics. It is \na common problem in traditional machine learning methods to design a feature set that \ncan accurately reflect traffic characteristics, and the quality of feature set directly affects \nthe classification performance of the method. In recent years, although many research -\ners have been working on the problem of how to design feature sets [31, 32], how to \ndesign a set of suitable traffic feature sets is still an unresolved research topic.\nPage 4 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \nMoreover, deep learning [33] has good self-adaptability, self-organization, and gener -\nalization capabilities. Therefore, it can be a good solution to the problem that traditional \nmachine learning needs to manually design a group of feature sets. The use of deep learn-\ning can enable detection systems with higher detection efficiency and therefore has been \nwidely studied by scholars in recent years. Yan [34] constructed an intrusion detection \nsystem based on convolutional neural network (CNN) and applied generative adversarial \nnetwork to synthesize attack traces, and experimental results verified the effectiveness \nof the system. Zhang [13] proposed a deep hierarchical network-based intrusion detec -\ntion model that combines CNN and long short-term memory (CNN_LSTM) network, \nand the CNN_LSTM model achieved good performance on the IDS2017 dataset. Lin \n[35] constructed a dynamic network anomaly detection system, which uses long short-\nterm memory (LSTM) network combined with attention mechanism to detect anoma -\nlies. Zhang [36] proposed a two-layer parallel learning cross-fusion deep learning model \n(PCCN), which uses feature fusion technology to improve the extraction of features \nfrom small sample data, and experiments on ablation experiments showed good per -\nformance. Zhong [37] proposed HELAD, a network anomaly traffic detection algorithm \nintegrating multiple deep learning techniques. Although HELAD has better adaptability \nand detection accuracy, its bit error rate is slightly higher.\n2.2  Transformer architecture\nIn 2018, transformer architecture [38] first appeared in the field of natural language \nprocessing (NLP), and it has occupied an important position in the field of NLP . Trans -\nformer architecture has been continuously improved by subsequent scholars [39]. Vas -\nwani [40] first constructed transformer architecture based on attention mechanism. \nDevlin et al. [41] proposed BERT, a new language representation model, which pretrains \na transformer from unmarked text through joint adjustments of left and right contexts. \nBERT got the latest results from 11 natural language processing tasks at the time.\nInfluenced by the excellent performance of transformer architecture in NLP task, \nscholars began to extend transformer architecture to the field of computer vision and \nachieved good results. Chen et al. [42] constructed a sequence transformer to perform \nregression prediction of pixels and obtained competitive results in the image classifica -\ntion task. In 2020, Dosovitskiy et  al. [43] proposed a vision transformer architecture, \nTable 1 A brief summary of intrusion detection methods\nAuthor Method DataSets References\nYin C L Machine learning SVM NSL‑KDD [25]\nReddy R.R KDD99 [27]\nLi W KNN Flooding Attack [28]\nFarnaaz N RF NSL‑KDD Dataset [29]\nZhang J KDD99 [30]\nYan Q Deep learning CNN KDDCUP’99 [34]\nZhang Y CNN_LSTM CICIDS2017 [13]\nLin P Attention+LSTM CSE‑CIC‑IDS2018 [35]\nZhang Y PCCN CICIDS2017 [36]\nZhong Y HELAD KDDCUP99 +CICIDS2017 [37]\nPage 5 of 22\nLi et al. J Wireless Com Network         (2022) 2022:39 \n \nwhich uses a pure transformer to directly extract the features of image block sequences \nand obtain the most advanced performance on multiple image recognition reference \ndatasets. Besides the most basic image classification tasks [44], transformer models are \ngradually applied to various computer vision tasks, and the number of vision models \nbased on transformer architecture has gradually become more and more.\nIn this paper, the latest intrusion detection model based on feature fusion is improved \nand integrated into vision transformer architecture, and then a deep learning model \n(MFVT) that combines feature fusion network with vision transformer architecture is \nproposed for network anomaly traffic detection. The MFVT takes full advantage of the \nrespective strengths of feature fusion and vision transformer architecture and further \nimproves the detection accuracy of abnormal network traffic by combining with the \nCPR algorithm proposed by us.\n3  Model and methods\nThis section mainly introduces the CPR algorithm and MFVT model.\nIn order to improve the processing capacity of existing deep learning models for \nimbalanced datasets and reduce the required training set resources, in this paper, a new \nmodel MFVT and a new raw data processing algorithm CPR were designed. This sec -\ntion mainly introduces the MFVT model and the CPR algorithm. The MFVT model \ncan improve the detection ability of small sample datasets and reduce the training set \nresources, and the CPR can effectively remove the interference features in the raw data. \nFigure 1 shows the entire detection process. The MFVT model mainly composed of a \nfeature fusion network and the vision transformer architecture. MFVT can use the \nraw features of network traffics to automatically learn the differences between different \ncategories of network traffic features to classify anomaly network traffics, but the net -\nwork model requires that the dimensionality of all input data must be consistent, so an \nFig. 1 Anomaly network traffic detection process\nPage 6 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \nalgorithm named CPR was proposed to extract the raw features of network traffics and \nintercept the same dimensional data.\n3.1  Data processing\nThe raw data processing algorithm (CPR) proposed in this paper mainly accomplishes \nthe task of extracting raw traffic data from pcap files and processing them into the two-\ndimensional matrix that required by the network model [45, 46]. Figure  2 shows the \nentire data processing process.\nThree steps are required to process the raw flow data into a two-dimensional matrix. \nThe specific steps are as follows.\nThe first step is to extract the raw data of network traffic from the pcap file and then \nconvert the extracted byte type data into binary type data.\nIn the second step, the converted packets are divided into flows according to the five-\ntuple, and the number of packets and bytes contained in each packet are limited when \ndividing the flow. If the number of data packets is insufficient, fill in the preceding item, \nand if the number of bytes contained in the data packet is insufficient, fill in 0. For the \nFig. 2 Overall flow of data processing\nPage 7 of 22\nLi et al. J Wireless Com Network         (2022) 2022:39 \n \ncompletion of this step, refer to the paper [47]. Through the above operations, a dataset \nwith fixed dimensions can be obtained. The pseudocode is shown in algorithm 1.\nIn the third step, the network traffic data obtained after the first two steps contain high \ndata dimensions and may have redundant features that are useless for network training, \nwhich need to be further extracted. In this paper, the data obtained from the first two \nsteps are directly fed into the PCA algorithm to obtain the data of the required dimen -\nsions, and then the data are processed into a two-dimensional matrix. The pseudocode is \nshown in algorithm 2.\nThe main idea of PCA is to map the N-dimensional features to the K-dimension, \nwhich is a new orthogonal feature, also known as the principal component, and is a \nPage 8 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \nreconstructed K-dimensional feature based on the original N-dimensional features, as \nshown in Formula 1,2,3,4,5.\nFormula 1 indicates that the original data X is arranged into a matrix with n rows and \nD columns, and then the matrix is zero-averaged. x ij represents the data in row i and \ncolumn j of matrix X. In Formula 2, c represents the covariance matrix of matrix X. For -\nmula 3 expresses getting the eigenvalue and eigenvector of the covariance matrix c, eig() \nis the function of getting the eigenvalue and eigenvector, w indicates the obtained eigen -\nvector, and b indicates the corresponding eigenvalue. In Formula  4, the eigenvectors \nare arranged into a matrix in rows from top to bottom according to the corresponding \neigenvalues. The first k rows are taken to form the matrix p, where sort() is the sort -\ning function and slect() is the selection function. Formula  5 represents the dataset Y \nobtained after dimension reduction.\n3.2  The structure of MFVT\nFigure 3 is the overall structure of the MFVT model, which composed of two parts.\nFirst part is the feature fusion network, which is composed of two layers of parallel \nconvolution networks. The first layer is stacked with two convolution layers, the first \nconvolution has a step of 1, the second convolution has a step of 2, and the size of the \nkernel is 3. The second layer consists of a convolutional layer and a pooling layer, where \nthe convolutional layer has a kernel size of 3 and a step size of 1, and the pooling layer \nhas a step size of 2. The padding size used in the two-layer convolution process is all 1. \nTo make full use of the features extracted by convolution layer and pooling layer, the \nextracted features are fused to improve the extraction effect of features for small sam -\nple data.The whole calculation process of the feature fusion network is shown in For -\nmula 6–16. Formula  6 represents the padding operation, and Formula  7 represents the \nsize change of the output matrix of convolution processing after the padding opera -\ntion. Under the premise that padding_n is equal to 1, the stride=1 keeps the output size \nunchanged, and the stride=2 halves the output size.\n(1)xij =xij−\n∑n\ni=1 xi,j\nn 0 < i < n,0 < j < d\n(2)C = 1\nm XXT\n(3)w ,b =eig (c)\n(4)p =select(sort (w ,b),k)\n(5)Y =PXn,d\nPage 9 of 22\nLi et al. J Wireless Com Network         (2022) 2022:39 \n \n(6)\nX = Padding (X0 ,1) =\n\n\nx11 ··· x1W\n... ... ...\nxH1 ··· xHW\n\n\n⇒\n\n\n0 ··· 0\nx11 ··· x1W\n...\n... ···\n...\n...\nxH1 ... xHW\n0 ··· 0\n\n\nFig. 3 MFVT’s overall structure\nPage 10 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \nWhere XO represents the matrix data obtained after the original flow data is processed \nby the CPR algorithm, because the convolution manipulation will change the size of the \ninput matrix, in order to keep the matrix size unchanged it is necessary to perform the \npadding operation by Formula 7.X represents the matrix after the padding operation, X ij \nrepresents the specific data value in the matrix. W is the width of the matrix, and H is \nthe height.\nFormulas 6, 8,9, 10 represent the entire calculation process of the first layer in the fea -\nture fusion network. Formulas 8 and 10 represent the convolution operation, V repre -\nsents the convolution kernel matrix, v ij represents the specific value in the convolution \nkernel matrix, and k represents the kernel sizes. X1\n1 represents the eigenmatrix obtained \nafter the first convolution operation. Since the stride in Formula 7 is 1, the output size \nremains unchanged. X2\n1 represents the matrix obtained after the padding operation of \nX1\n1 , and X3\n1 represents the eigenmatrix obtained after the second convolution, and the \noutput size is halved because the stride in Formula 7 is 2.\nFormulas 6, 11, 12 represent the entire computational process of the second layer in the \nfeature fusion network, whereX1\n2 denotes the feature matrix extracted after the convolu-\ntion operation, the stride=1 does not change the output size, and X2\n2 denotes the feature \nmatrix obtained after the maximum pooling operation, which halves the size of the out -\nput feature matrix.\nFormula 13 shows the scale changes of the features extracted from the first and second \nlayers of the feature fusion network. Formula 14 represents the specific process of fusing \n(7)\nH =\n⌈ H + padding_n − w + 1\nstride\n⌉\nW =\n⌈ W + padding_n − w + 1\nstride\n]\n(8)X 1\n1 =X ⊙ V =\n\n\nx11 ··· x1k\n... ... ...\nxk1 ··· xkk\n\n ⊙\n\n\nv11 ··· v1k\n... ... ...\nvk1 ··· vkk\n\n\n(9)X2\n1 = padding\n(\nX1\n1 ,1\n)\n(10)X 3\n1 =X 2\n1 ⊙ V =\n\n\nx2\n11 ··· x2\n1k\n... ... ...\nx2\nk1 ··· x2\nkk\n\n\n⊙\n\n\nv11 ··· v1k\n... ... ...\nvk1 ··· vkk\n\n\n(11)X 1\n2 =X ⊙ V =\n\n\nx11 ··· x1k\n... ... ...\nxk1 ··· xkk\n\n ⊙\n\n\nv11 ··· v1k\n... ... ...\nvk1 ··· vkk\n\n\n(12)X 2\n2 = Maxpooling\n(\nX 1\n2\n)\n=\nmax\n{\nx1\nij\n}\ni,j ∈[ 1,k ]\nPage 11 of 22\nLi et al. J Wireless Com Network         (2022) 2022:39 \n \nthe first layer with the second layer features. The fusion refers to the summation of the \nnumber of channels, but the data must be kept consistent except for the number of \nchannels. C represents the number of channels, C(1) represents the number of channels \nis 1, C(32) represents the number of channels is 32 and so on, X f represents the features \nextracted by the feature fusion network.\nThe second part is composed of the vision transformer architecture. To combine vision \ntransformer architecture with feature fusion network, the structure of vision trans -\nformer is modified in this paper. The main methods used include feature embedding, \nlearnable embedding, and transformer encoder.\nFor feature embedding, standard transformer accepts sequence of token embeddings \nas input. To process the feature X f learned by the feature fusion network, we recon -\nstructed X f into a flattened 2D block sequence Xp . Formula 15 is a specific variation \nof the formula, the same as NLP , will be added to the sequence of images in the token \nclassification, the sequence of images is cut into multiple patches by a picture to get the \nnumber of patches where p indicates.\nLearnable embedding, a learnable embedding z0\n0 = xclass is preset for the feature block \nembedding sequence, xclass denotes the category vector whose state/feature Z0\nL at the \ntransformer encoder output is used as the feature representation y, as shown in For -\nmula 21. Learnable embedding is randomly initialized at the beginning of training and \nobtained by training.\nTransformer encoder consists of several blocks, each containing a multi-head atten -\ntion block and a multi-layer perceptron (MLP) block, with normalization applied before \neach block and residual concatenation applied after each block. Figure  4 shows the \nstructure of head attention. Formula 16, 17 show how to get the multi-head attention \nvalues by head attention. Where W Q\ni ,W K\ni ,W V\ni  and W O are all weight matrices.\n(13)(C(1),H,W ) ⇒\n(\nC(32), H\n2 ,W\n2\n)\n(14)\nXf =\n(\nC(32), H\n2 , W\n2\n)\n⊕\n(\nC(32), H\n2 , W\n2\n)\n=\n(\nC(32 + 32), H\n2 , W\n2\n)\n(15)\nXf ∈ RC(64)×H\n2 ×W\n2\nXp ∈ RN ×\n(\nP2C(64)\n)\nN =\nH\n2\nW\n2\nP2\nXf → Xp\n(16)Head i= Attention\n(\nQW Q\ni ,KW K\ni ,VW V\ni\n)\n(17)Multihead (Q,K,V) = Concat ( head 1,... , head b)W o\nPage 12 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \nFinally, the embedding vectors that combine category vectors and feature block embed -\nding can be input into transformer encoder. The encoder built up by blocks can extract \ndata features for classification just like CNN. The whole calculation process is shown in \nFormula 18, 19, 20, 21.\nThe feature embedding block X1\nPE and the category vector X class form the embedding \ninput vector Z0 . Formula 19 adopts skip connection, where MAS represents multi-head \nattention operation, LN represents normalization operation, L represents repeatable \ntimes, and Z\n′\nl represents the lth output. Formula 20 adopts skip connection, MLP repre -\nsents the multi-layer perceptron block, L represents repeatable times, and Z l represents \nthe lth output. y represents the feature representation.\n4  Experiments and results analysis\nThis section first introduces the experimental environment, the datasets IDS 2017 \nand IDS 2012 used in the experiments, the evaluation criteria used in the experiments \nand finally specifies the ablation experiments and some details of the experiments. In \nthe ablation experiments, a series of advanced models were compared with the MFVT \nmodel.\n4.1  The experimental environment of this paper\nIn this paper, ablation experiments were conducted on the MFVT model and CPR data \nprocessing algorithm under the environment shown in Table 2.\n(18)Z0 =\n[\nX class; X1\nPE\n]\n, E ∈ R\n(\nP2·C)×D\n,Epos ǫR(N +1)×D\n(19)Z′\nl =MSA\n(\nLN\n(\nZl−\n))\n+ Zl−1, l= 1 ... L\n(20)Zl=MLP\n(\nLN\n(\nZ′\nl\n))\n+ Z′\nl, l= 1 ... L\n(21)y=LN\n(\nZ0\nL\n)\nFig. 4 Attention structure\nPage 13 of 22\nLi et al. J Wireless Com Network         (2022) 2022:39 \n \n4.2  Datasets\nIn this paper, A series of ablation experiments were designed using both IDS 2012 and \nIDS 2017 datasets.\nThe IDS 2012 dataset contains a week of network activity including both normal and \nmalicious activity, with three days consisting of all normal traffics and the remaining \nfour days consisting of a large amount of normal traffics with a specific type of attack \ntraffics. IDS 2012 dataset contains attack traffic including internal penetration, HTTP \ndenial of service, distributed denial of service using IRC botnet, and brute force cracking \nof SSH [18].\nThe IDS 2017 data collection period lasts for five days from 9am on Monday, July 3, \n2017, to 5pm on Friday, July 7, 2017, of which Mondays only include normal traffic. The \nattacks implemented included brute force FTP , brute force SSH, DoS, Heartbleed, web \nattack, infiltration, Botnet, and DDoS [17].\nFigure 5a is a bar chart of the amount of various attack traffics contained in the IDS \n2017 dataset, and Fig.  5b is a pie chart of the amount of various attack traffics contained \nin the IDS 2012 dataset. It is observed from the figures that both IDS 2017 and IDS 2012 \ndatasets have serious data imbalance problems. The data volume of DDOS, Hulk, and \nPortScan attacks in the IDS 2017 dataset is significantly larger than that of other types of \nattacks. The data volume of Infiltrator attacks in the IDS 2012 dataset directly accounts \nfor 55% of the dataset\n4.3  Evaluation metrics\nAuthoritative evaluation metrics must be used to judge the merits of a network anom -\naly traffic detection method. The effectiveness of the machine learning-based network \nanomaly traffic detection algorithm can be evaluated by the metrics shown in For -\nmula 26, 25, 23, 22, 24 [48]. TP represents the positive sample predicted to be positive \nby the model, which can be called the accuracy rate judged to be true. TN  represents \nthe negative sample predicted to be negative by the model, which can be referred to as \nthe percentage of correct judgments that are false. FP  represents the negative sample \npredicted by the model to be positive, which can be referred to as the false alarm rate. \nFN represents the positive sample predicted to be negative by the model, which can be \nreferred to as the underreporting rate [37].\n(22)Recall= TP\nTP + FN\nTable 2 Experimental environment of this paper\nCPU: i7-10875H CPU@2.30GHz 2.30GHz\nRAM: 16G\nGPU: RTX 2060 6G\nCompiler environment: Python 3.8.2\nOS: Windows 10\nPage 14 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \n4.4  Ablation experiment and results analysis\nIn this paper, two datasets of IDS 2012 and IDS 2017 were used for ablation experiments. \nIn addition, this paper also carried out an exploratory study on the impact of model opti-\nmization methods on MFVT model detection performance on IDS 2012 dataset.\nIn the MFVT model, the size of the kernels used in the convolutional neural network \nis 3 ∗ 3 , the segmentation size set in the vision transformer architecture is 11 ∗ 11 , the \nnumber of the head in the multi-head attention is 12, and the number of blocks in the \nencoder is 12. In the process of model training, the data input batch used in this paper is \n256, the epoch of the training iteration is set to 100, and the stochastic gradient descent \n(SGD) optimizer is used to accelerate the network convergence. The momentum is fixed \nat 0.9, the learning rate is fixed at 3e-2, weight_decay Set to 0, the loss function uses \nCrossEntropyLoss. All ablation experiments and results will be described in detail below.\n4.4.1  Ablation experiment based on IDS 2012\nFigure 6 shows the parameter changes of MFVT model when using IDS 2012 dataset for \ntraining, including training loss, verification loss, and verification accuracy. As shown in \nthe picture, the convergence speed of MFVT model is fast, but there are large fluctua -\ntions in the later stages of training.\nTable 3 shows the experimental results based on IDS 2012 dataset. It is obvious from \nthe table that the MFVT model combined with CPR algorithm proposed in this paper is \nsuperior to other methods on all evaluation metrics, reaching the state-of-the-art level. \n(23)Precision= TP\nTP + FP\n(24)F1 − Measure =2 ∗ Precision∗ Recall\nPrecision+ Recall\n(25)Accuracy= TP + TN\nTP + TN + FP + FN\n(26)FPR= FP\nFP+ TN\nFig. 5 Percentage of various types of traffic data\nPage 15 of 22\nLi et al. J Wireless Com Network         (2022) 2022:39 \n \nIt can also be concluded from the table that MFVT model has superior performance, \nand its detection accuracy is only slightly worse than that of DT (Decision Tree), but it \nhas higher precision. To better demonstrate the ability of the MFVT model to deal with \nimbalanced data, the experimental results of all evaluation metrics of the MFVT model \nin various types of attack traffic are shown in Table 4.\nCombining the (B) in Fig.  5 and Table  4 (the experimental results of Infiltrating and \nDistributedenial, which account for a relatively large proportion, have been marked in \nbold),it can be concluded that the traffic of HTTP and rutesh, which account for a rel -\natively small proportion, still obtains good experimental results. It shows that MFVT \nmodel has strong ability to recognize small sample data. The detection performance is \nfurther improved by combining the CPR algorithm with the MFVT model.\n4.4.2  Ablation experiment based on IDS 2017\nThe IDS 2012 dataset contains fewer types of attack traffic, and the effectiveness of the \nMFVT model and the data processing algorithm CPR are demonstrated to be not gener -\nalizable on this dataset only. So, ablation experiments also were performed on the more \ncomplex IDS 2017 dataset. Figures  7 and 8 are the results of the ablation experiment, \nfrom which it can be seen that the accuracy, recall, F1-score and accuracy of the MFVT \nmodel and the combination of MFVT model and CPR algorithm all reached nearly \n100%, which was significantly better than other comparison models. Figure  7 shows that \nthe detection results obtained by MFVT model and the combination of MFVT model \nand CPR algorithm are close to 100% in the evaluation criteria, which is significantly \nbetter than other comparison models. The comparison of the FPR between the MFVT \nmodel and other comparison models is shown in Fig.  8, from which it can be seen that \nthe MFVT model is still the best. Combined with Fig.  5a and Table  5(experimental \nresults of DDos, Hulk and Portscan, which account for a large proportion of attacks, \nhave been marked in bold), it can be concluded that the MFVT model combined with \nthe CPR algorithm has a better ability to recognize small samples.\nTo further demonstrate the error of the prediction results of the MFVT model pro -\nposed in this paper combined with CPR, the experimental results were made into the \nheat map shown in Fig.  9. From the heat map, the performance of the MFVT model \ncombined with CPR is very high, and the prediction error rate is extremely low.\nTo verify that the MFVT model can reduce the sample resources required for training, \nwe tested it on the IDS 2017 dataset by reducing the training set data volume accord -\ning to Formula 27 with all other conditions held constant, data0 is the initial assigned \ntraining set data volume, datan is the updated data volume, and n is taken according to \nFormula 28, where n0 is the initial value of n equal to 0.9, and N takes values in the range \nof 1–7. Table 6 shows the test results.\nAs can be seen from Fig.  10, when the training set data amount is reduced to 80% of \nthe original training set data amount, the impact on the overall accuracy of the test set is \nvery small. Through this experiment, it is proved that the MFVT model combined with \n(27)Datan =(1 − 0.1∗ n) ∗ data0\n(28)n =n0 − 0.1N\nPage 16 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \nFig. 6 Variation of some training results, a train loss, b Val accuracy, c Val loss\nTable 3 Experimental results on the 2012 dataset\nMethods Precision Recall F1-socre FPR Accuracy\nMFVT 0.9986 0.9975 0.998 0.000525 0.9988\nMFVT (CPR) 0.9995 0.9994 0.9995 0.000175 0.9996\nvision transformer 0.9984 0.9977 0.998 0.000625 0.9985\nPCCN 0.9987 0.9979 0.9983 0.000575 0.9986\nCNN 0.9958 0.9942 0.9949 0.00145 0.9962\nCNN_LSTM 0.9949 0.9936 0.9942 0.001775 0.9951\nDLSTM 0.9939 0.9928 0.9933 0.00195 0.9944\nKNN 0.993 0.9903 0.9917 0.002125 0.9939\nLR 0.9891 0.9902 0.9897 0.00315 0.9909\nRF 0.9973 0.9966 0.9969 0.00085 0.9979\nDT 0.9984 0.9984 0.9984 0.000375 0.999\nSVM 0.9943 0.9937 0.994 0.0018 0.9949\nPage 17 of 22\nLi et al. J Wireless Com Network         (2022) 2022:39 \n \nCPR algorithm can effectively reduce the training resources and maintain the accuracy \nof the test set as much as possible.\n4.4.3  Optimization of MFVT model\nIn the conclusion of this section, it is hoped to further improve the detection accu -\nracy and the stability of the model by increasing the training epochs and continuously \nadjusting the learning rate (lr) during the training process. Thus, IDS 2012 is used as the \nablation experiment dataset, which takes less time to train than IDS 2017.Two sets of \nTable 4 Performance of MFVT model and CPR algorithm in each category in IDS 2012 data\nMethods Class Precision Recall F1-socre False alarm rate\nMFVT Infiltrating 0.999 0.9994 0.9992 0.0012\nhttp 0.9984 0.9968 0.9976 0.0004\nDistributedenial 0.9985 0.9992 0.9988 0.0005\nrutessh 0.9984 0.9945 0.9965 0\nMFVT(CPR) Infiltrating 0.9995 0.9998 0.9997 0.0006\nhttp 0.9995 0.9985 0.999 0.0001\nDistributedenial 0.9999 0.9999 0.9999 0\nrutessh 0.9992 0.9992 0.9992 0\nFig. 7 Partial experimental results, blue represents precision, purple represents recall, green represents \nF1‑score, and red represents accuracy\nPage 18 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \nexperiments were conducted. In the first group, our model was trained 1,000 times and \nthe results were recorded every 100 times.\nIn the second group, based on the first group, lr  is changed 100 times per iteration \naccording to Formula 29, where lri is the learning rate changed every time according to \nthe formula, lr0 is the initial learning rate, and the epoch is every hundred iterations. To \nensure the rigor of the experiment, the values were obtained after conducting the two \nsets of experiments several times. It can be seen from Fig.  11 that both the increase of \ntraining epochs and the change of lr can get better prediction accuracy in some interme-\ndiate results, but the experimental results tend to be stable in the end. In comparison, \nthe variation of lr will make the variation of experimental results more stable.\n(29)lri = 0.95epoch/10 · lr0\nFig. 8 The result of FPR\nTable 5 Performance of MFVT(CPR) in the IDS 2017 dataset\nClass Precision Recall F1-socre\nbotnet 0.9928 1 0.9964\nDDoS 0.9999 0.9999 0.9999\ngoldeneye 0.9995 0.9998 0.9996\nhulk 0.9999 1 0.9999\nslowhttp 0.9993 0.9971 0.9982\nslowloris 1 0.999 0.9995\nftppatator 1 0.9992 0.9996\nheartbleed 1 0.9995 0.9997\ninfiltration 1 0.9981 0.9991\nportscan 1 1 1\nsshpatator 0.9996 1 0.9998\nwebattack 0.9991 0.9991 0.9991\nPage 19 of 22\nLi et al. J Wireless Com Network         (2022) 2022:39 \n \nFig. 9 Heat map of prediction results of MFVT model combined with CPR algorithm\nTable 6 Test results‑% of original training data\nMethods 100% 90% 80% 70% 60% 50% 40% 30%\nMFVT(CPR) 0.999932 0.999931 0.999929 0.999845 0.999839 0.999783 0.999532 0.999321\nFig. 10 Experimental results for different training set data amounts\nPage 20 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \n5  Results and discussion\nSince most of the deep learning models need a lot of training resources, a network \nanomaly traffic detection model (MFVT) which combining a feature fusion network \nwith the vision transformer architecture was proposed. MFVT can reduce training \nresources while maintaining high detection accuracy. In this paper, a new raw traffic \ndata extraction algorithm (CRP) was proposed. The MFVT model combined with the \nCRP algorithm achieved nearly 100% detection accuracy on both datasets IDS 2012 and \nIDS 2017, and with much better performance than the other methods in the comparison \nexperiments. The MFVT model combined with the CRP algorithm is more capable of \nhandling imbalanced datasets and can further improves the detection accuracy of the \nexperiment.\nAlthough the MFVT model combined with the CRP algorithm has an excellent perfor-\nmance in the field of anomaly traffic detection, the scalability of the model is weak and \nthe detection accuracy of new types of attack traffic that do not appear in the training set \nneeds to be improved in the face of the increasingly complex network environment and \nthe emergence of new attack types.\nConsidering the importance and practical significance of scalability, the scalability of \nthe MFVT model will be further improved in the future to enhance the practical value \nand practical significance of the model.\nAbbreviations\nMFVT: An anomaly traffic detection method merging feature fusion network and vision transformer architecture; CPR: A \nnew raw traffic features extraction method; PCA: Principal component analysis.\nAuthors’ contributions\nAll authors read and participated in the manuscript’s completion. All authors read and approved the final manuscript.\nFunding\nThis research is supported by the National Natural Science Foundation of China under Grants 61873160, 61672338 and \nNatural Science Foundation of Shanghai under Grant 21ZR1426500.\nFig. 11 Experimental results. Blue represents MFVT, red represents accuracy MFVT change lr\nPage 21 of 22\nLi et al. J Wireless Com Network         (2022) 2022:39 \n \nDeclarations\nCompeting interests\nThe authors declare that they have no competing interests.\nAuthor details\n1 Department of Engineering, Shanghai Maritime University, Shanghai, China. 2 Department of Information Engineering \nand Computer Science, Shanghai Maritime University, Taichung, Taiwan. \nReceived: 5 September 2021   Accepted: 10 March 2022\nReferences\n 1. D. Han, N. Pan, K.‑C. Li, A traceable and revocable ciphertext‑policy attribute‑based encryption scheme based on \nprivacy protection. IEEE Trans. Depend. Secure Comput. (2020)\n 2. M. Cui, D. Han, J. Wang, An efficient and safe road condition monitoring authentication scheme based on fog com‑\nputing. IEEE Internet Things J. 6(5), 9076–9084 (2019)\n 3. Q. Tian, D. Han, K.‑C. Li, X. Liu, L. Duan, A. Castiglione, An intrusion detection approach based on improved deep \nbelief network. Appl. Intell. 50(10), 3162–3178 (2020)\n 4. L. Hung‑Jen, R.L. Chun‑Hung, L. Ying‑Chih, T. Kuang‑Yuan, Intrusion detection system:a comprehensive review. J. \nNetw. Comput. Appl. 36, 16–24 (2013)\n 5. D. Li, D. Han, Z. Zheng, T.‑H. Weng, H. Li, H. Liu, A. Castiglione, K.‑C. Li, Moocschain: A blockchain‑based secure stor‑\nage and sharing scheme for moocs learning. Comput. Stand. Interfaces, 103597 (2021)\n 6. D.J. Weller‑Fahy, B.J. Borghetti, A.A. Sodemann, A survey of distance and similarity measures used within network \nintrusion anomaly detection. IEEE Commun. Surv. Tutor. 17, 70–91 (2015)\n 7. A. Abraham, C. Grosan, C. Martin‑Vide, Evolutionary design of intrusion detection programs. Int. J. Netw. Secur. 4, \n328–339 (2007)\n 8. S. Anwar, J. Mohamad Zain, M. Zolkipli, Z. Inayat, S. Khan, B. Anthony Jnr, V. Chang, From intrusion detection to an \nintrusion response system: Fundamentals, requirements, and future directions. Algorithms 10, 39 (2017)\n 9. W. Zhang, D. Han, K.‑C. Li, F.I. Massetto, Wireless sensor network intrusion detection system based on mk‑elm. Soft \nComputing, 1–14 (2020)\n 10. W. Liang, L. Xiao, K. Zhang, M. Tang, D. He, K.‑C. Li, Data fusion approach for collaborative anomaly intrusion detec‑\ntion in blockchain‑based systems. IEEE Internet of Things J. (2021)\n 11. A. Ajith, G. Crina, M.V. Carlos, A survey of network anomaly detection techniques. J. Netw. Comput. Appl. 60, 19–31 \n(2016)\n 12. J. Zhang, C. Chao, X. Yang, W. Zhou, X. Yong, Internet traffic classification by aggregating correlated naive bayes \npredictions. IEEE Trans. Inf. Forens. Secur. 8, 5–15 (2013)\n 13. Y. Zhang, X. Chen, L. Jin, X. Wang, D. Guo, Network intrusion detection: based on deep hierarchical network and \noriginal flow data. IEEE Access 7, 37004–37016 (2019)\n 14. H. Liu, D. Han, D. Li, Behavior analysis and blockchain based trust management in vanets. J. Parallel Distrib. Comput. \n151, 61–69 (2021)\n 15. K. Oksuz, B.C. Cam, S. Kalkan, E. Akbas, Imbalance problems in object detection: a review. IEEE Trans. Pattern Anal. \nMach. Intell. pp. 1–1 (2020)\n 16. A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, N. Houlsby, An image is worth 16x16 words: transformers for \nimage recognition at scale. arXiv preprint arXiv: 2010. 11929 (2020)\n 17. I. Sharafaldin, A.H. Lashkari, A.A. Ghorbani, Toward generating a new intrusion detection dataset and intrusion traffic \ncharacterization. ICISSp 1, 108–116 (2018)\n 18. A. Shiravi, H. Shiravi, M. Tavallaee, A.A. Ghorbani, Toward developing a systematic approach to generate benchmark \ndatasets for intrusion detection. Comput. Secur. 31(3), 357–374 (2012)\n 19. L.I. Smith, A tutorial on principal components analysis. Inf. Fusion 51, 52 (2002)\n 20. D. Han, Y. Zhu, D. Li, W. Liang, A. Souri, K.‑C. Li, A blockchain‑based auditable access control system for private data in \nservice‑centric iot environments. IEEE Trans. Ind. Inform. (2021)\n 21. W. Liang, Z. Ning, S. Xie, Y. Hu, S. Lu, D. Zhang, Secure fusion approach for the internet of things in smart autono‑\nmous multi‑robot systems. Inf. Sci. 579, 468–482 (2021)\n 22. H. Li, D. Han, M. Tang, A privacy‑preserving storage scheme for logistics data with assistance of blockchain. IEEE \nInternet of Things J. (2021)\n 23. X. Chen, W. Liang, J. Xu, C. Wang, K.‑C. Li, M. Qiu, An efficient service recommendation algorithm for cyber‑physical‑\nsocial systems. IEEE Trans. Netw. Sci. Eng. (2021)\n 24. J.P . Anderson, Computer security threat monitoring and surveillance (1980)\n 25. C.L. Yin, Y.F. Zhu, J.L. Fei, X.Z. He, A deep learning approach for intrusion detection using recurrent neural networks. \nIEEE Access, pp. 1–1 (2017)\n 26. F. Kuang, W. Xu, S. Zhang, A novel hybrid kpca and svm with ga model for intrusion detection. Appl. Soft Comput. \n18, 178–184 (2014)\n 27. R.R. Reddy, Y. Ramadevi, K. Sunitha, Effective discriminant function for intrusion detection using svm. In: 2016 Inter‑\nnational Conference on Advances in Computing, Communications and Informatics (ICACCI), pp. 1148–1153 (2016)\n 28. W. Li, P . Yi, Y. Wu, L. Pan, J. Li, A new intrusion detection system based on knn classification algorithm in wireless sen‑\nsor network. J. Electr. Comput. Eng. 2014 (2014)\n 29. N. Farnaaz, M.A. Jabbar, Random forest modeling for network intrusion detection system. Procedia Comput. Sci. 89, \n213–217 (2016)\nPage 22 of 22Li et al. J Wireless Com Network         (2022) 2022:39 \n 30. Random‑forests‑based network intrusion detection systems, IEEE Trans. Syst. Man Cybernet. Part C 38, 649–659 \n(2008)\n 31. Y. Dhote, S. Agrawal, A.J. Deen, A survey on feature selection techniques for internet traffic classification. In: Interna‑\ntional Conference on Computational Intelligence & Communication Networks, pp. 1375–1380 (2015). IEEE\n 32. H. Zhang, G. Lu, M.T. Qassrawi, Y. Zhang, X. Yu, Feature selection for optimizing traffic classification. Comput. Com‑\nmun. 35, 1457–1471 (2012)\n 33. A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks. Adv. Neural. \nInf. Process. Syst. 25, 1097–1105 (2012)\n 34. Q. Yan, M. Wang, W. Huang, X. Luo, F.R. Yu, Automatically synthesizing dos attack traces using generative adversarial \nnetworks. Int. J. Mach. Learn. Cybern. 10, 3387–3396 (2019)\n 35. P . Lin, K. Ye, C.‑Z. Xu, Dynamic network anomaly detection system by using deep learning techniques. In: Interna‑\ntional Conference on Cloud Computing, pp. 161–176 (2019). Springer\n 36. Y. Zhang, X. Chen, D. Guo, M. Song, X. Wang, Pccn: Parallel cross convolutional neural network for abnormal network \ntraffic flows detection in multi‑class imbalanced network traffic flows. IEEE Access, pp. 1–1 (2019)\n 37. Y. Zhong, W. Chen, Z. Wang, Y. Chen, K. Li, Helad: A novel network anomaly detection model based on heterogene‑\nous ensemble learning. Comput. Netw. 169, 107049 (2019)\n 38. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A.N. Gomez, Ł. Kaiser, I. Polosukhin, Attention is all you need. \nIn: Advances in Neural Information Processing Systems, pp. 5998–6008 (2017)\n 39. K. Han, Y. Wang, H. Chen, X. Chen, D. Tao, A survey on visual transformer. arXiv preprint arXiv: 2012. 12556 (2020)\n 40. A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever et al., Language models are unsupervised multitask learn‑\ners. OpenAI blog 1, 9 (2019)\n 41. M. Kim, G. Kim, S.‑W. Lee, J.‑W. Ha, St‑bert: Cross‑modal language model pre‑training for end‑to‑end spoken lan‑\nguage understanding. In: ICASSP 2021‑2021 IEEE International Conference on Acoustics, Speech and Signal Process‑\ning (ICASSP), pp. 7478–7482 (2021). IEEE\n 42. Y. Chang, Z. Huang, Q. Shen, The same size dilated attention network for keypoint detection. In: International Con‑\nference on Artificial Neural Networks, pp. 471–483 (2019). Springer\n 43. J. Chung, C. Gulcehre, K. Cho, Y. Bengio, Empirical evaluation of gated recurrent neural networks on sequence mod‑\neling. arXiv preprint arXiv: 1412. 3555 (2014)\n 44. W. Liang, J. Long, K.‑C. Li, J. Xu, N. Ma, X. Lei, A fast defogging image recognition algorithm based on bilateral hybrid \nfiltering. ACM transactions on multimedia computing, communications, and applications (TOMM) 17, 1–16 (2021)\n 45. T. Xiao, D. Han, J. He, K.‑C. Li, R.F. de Mello, Multi‑keyword ranked search based on mapping set matching in cloud \nciphertext storage system. Connect. Sci. 33, 95–112 (2021)\n 46. W. Liang, D. Zhang, X. Lei, M. Tang, K.‑C. Li, A. Zomaya, Circuit copyright blockchain: Blockchain‑based homomorphic \nencryption for ip circuit protection. IEEE Trans. Emerg. Top. Comput. (2020)\n 47. M. Li, D. Han, X. Yin, H. Liu, D. Li: Design and implementation of an anomaly network traffic detection model inte‑\ngrating temporal and spatial features. Secur. Commun. Netw. 2021 (2021)\n 48. M. Cui, D. Han, J. Wang, K.‑C. Li, C.‑C. Chang, Arfv: an efficient shared data auditing scheme supporting revocation \nfor fog‑assisted vehicular ad‑hoc networks. IEEE Trans. Veh. Technol. 69(12), 15815–15827 (2020)\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8780372738838196
    },
    {
      "name": "Intrusion detection system",
      "score": 0.5947374701499939
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5873739123344421
    },
    {
      "name": "Feature extraction",
      "score": 0.5444286465644836
    },
    {
      "name": "Data mining",
      "score": 0.5136494040489197
    },
    {
      "name": "Transformer",
      "score": 0.49482864141464233
    },
    {
      "name": "Anomaly detection",
      "score": 0.49028995633125305
    },
    {
      "name": "Deep learning",
      "score": 0.48699647188186646
    },
    {
      "name": "Traffic classification",
      "score": 0.4812450110912323
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.40034061670303345
    },
    {
      "name": "Machine learning",
      "score": 0.3468739688396454
    },
    {
      "name": "Computer network",
      "score": 0.10760724544525146
    },
    {
      "name": "Quality of service",
      "score": 0.08735814690589905
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ]
}