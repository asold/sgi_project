{
  "title": "Supervised and unsupervised language modelling in Chest X-Ray radiological reports",
  "url": "https://openalex.org/W3012070096",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2055145341",
      "name": "Ignat Drozdov",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2297401059",
      "name": "Daniel Forbes",
      "affiliations": [
        "Queen Elizabeth University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2951106620",
      "name": "Benjamin Szubert",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2087587524",
      "name": "Mark Hall",
      "affiliations": [
        "Queen Elizabeth University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A3021490454",
      "name": "Chris Carlin",
      "affiliations": [
        "Queen Elizabeth University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2040248035",
      "name": "David J. Lowe",
      "affiliations": [
        "Queen Elizabeth University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2055145341",
      "name": "Ignat Drozdov",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2297401059",
      "name": "Daniel Forbes",
      "affiliations": [
        "Queen Elizabeth University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2951106620",
      "name": "Benjamin Szubert",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2087587524",
      "name": "Mark Hall",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3021490454",
      "name": "Chris Carlin",
      "affiliations": [
        "Queen Elizabeth University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2040248035",
      "name": "David J. Lowe",
      "affiliations": [
        "Queen Elizabeth University Hospital"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2019566532",
    "https://openalex.org/W4244665703",
    "https://openalex.org/W2901954625",
    "https://openalex.org/W2963466845",
    "https://openalex.org/W2939788146",
    "https://openalex.org/W2949301588",
    "https://openalex.org/W2962843773",
    "https://openalex.org/W2899768131",
    "https://openalex.org/W2338526423",
    "https://openalex.org/W1504212872",
    "https://openalex.org/W2043768386",
    "https://openalex.org/W2139865360",
    "https://openalex.org/W2611650229",
    "https://openalex.org/W2768567289",
    "https://openalex.org/W2963441585",
    "https://openalex.org/W2897228760",
    "https://openalex.org/W2001741247",
    "https://openalex.org/W2784499877",
    "https://openalex.org/W2995225687",
    "https://openalex.org/W2951187834",
    "https://openalex.org/W2102634410",
    "https://openalex.org/W1566256432",
    "https://openalex.org/W2964142373",
    "https://openalex.org/W1902237438",
    "https://openalex.org/W2531468880",
    "https://openalex.org/W2772121968",
    "https://openalex.org/W2516809705",
    "https://openalex.org/W2265846598",
    "https://openalex.org/W2076162527",
    "https://openalex.org/W2470673105",
    "https://openalex.org/W2911410812",
    "https://openalex.org/W2986571455",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W2952566282",
    "https://openalex.org/W2468328197",
    "https://openalex.org/W3101520758",
    "https://openalex.org/W2950577311",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2770241596",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2930304691",
    "https://openalex.org/W3098949126",
    "https://openalex.org/W2116516955",
    "https://openalex.org/W2624413595",
    "https://openalex.org/W2952230511",
    "https://openalex.org/W2904183610",
    "https://openalex.org/W2626778328",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W3101156210",
    "https://openalex.org/W2912664121",
    "https://openalex.org/W2948093896",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2966462242",
    "https://openalex.org/W2149684865",
    "https://openalex.org/W2913279579",
    "https://openalex.org/W2786052267"
  ],
  "abstract": "Chest radiography (CXR) is the most commonly used imaging modality and deep neural network (DNN) algorithms have shown promise in effective triage of normal and abnormal radiograms. Typically, DNNs require large quantities of expertly labelled training exemplars, which in clinical contexts is a major bottleneck to effective modelling, as both considerable clinical skill and time is required to produce high-quality ground truths. In this work we evaluate thirteen supervised classifiers using two large free-text corpora and demonstrate that bi-directional long short-term memory (BiLSTM) networks with attention mechanism effectively identify Normal, Abnormal, and Unclear CXR reports in internal (n = 965 manually-labelled reports, f1-score = 0.94) and external (n = 465 manually-labelled reports, f1-score = 0.90) testing sets using a relatively small number of expert-labelled training observations (n = 3,856 annotated reports). Furthermore, we introduce a general unsupervised approach that accurately distinguishes Normal and Abnormal CXR reports in a large unlabelled corpus. We anticipate that the results presented in this work can be used to automatically extract standardized clinical information from free-text CXR radiological reports, facilitating the training of clinical decision support systems for CXR triage.",
  "full_text": "RESEA RCH ARTICL E\nSupervised and unsupervised language\nmodelling in Chest X-Ray radiological reports\nIgnat Drozdov\nID\n1\n*, Daniel Forbes\n2\n, Benjamin Szubert\n1\n, Mark Hall\n3\n, Chris Carlin\nID\n4\n, David\nJ. Lowe\nID\n2\n1 Bering Limited, London, United Kingdom, 2 Emerge ncy Department, Queen Elizabeth Univers ity Hospital,\nGlasgow, Scotland , 3 Radiolog y Department, Queen Elizabe th University Hospita l, Glasgow, Scotland,\n4 Department of Respirator y Medicine. Queen Elizabeth Universit y Hospital, Glasgow, Scotland\n* idrozdo v@bering research.co m\nAbstract\nChest radiography (CXR) is the most commonly used imaging modality and deep neural\nnetwork (DNN) algorithms have shown promise in effective triage of normal and abnormal\nradiograms. Typically, DNNs require large quantities of expertly labelled training exemplars,\nwhich in clinical contexts is a major bottleneck to effective modelling, as both considerable\nclinical skill and time is required to produce high-quality ground truths. In this work we evalu-\nate thirteen supervised classifiers using two large free-text corpora and demonstrate that bi-\ndirectional long short-term memory (BiLSTM) networks with attention mechanism effectively\nidentify Normal, Abnormal, and Unclear CXR reports in internal (n = 965 manually-labelled\nreports, f1-score = 0.94) and external (n = 465 manually-labelled reports, f1-score = 0.90)\ntesting sets using a relatively small number of expert-labelled training observations (n =\n3,856 annotated reports). Furthermore, we introduce a general unsupervised approach that\naccurately distinguishes Normal and Abnormal CXR reports in a large unlabelled corpus.\nWe anticipate that the results presented in this work can be used to automatically extract\nstandardized clinical information from free-text CXR radiological reports, facilitating the\ntraining of clinical decision support systems for CXR triage.\nIntroduction\nChest radiography (CXR) is the most commonly used imaging modality, with over two billion\nprocedures performed annually [1]. There is a general consensus that an Artificial Intelligence\n(AI)-supported reporting of CXR images could be a valuable adjunct to imaging interpretation,\nproviding substantial benefit in many clinical contexts, from improved workflow prioritization\nand clinical decision support to large-scale screening and global population health initiatives [2–\n4]. Indeed, deep learning algorithms have been successfully applied to detect heterogeneous tho-\nracic disease [3, 5], triage normal and abnormal radiographs [2], and identify specific pathologies\nsuch as pulmonary tuberculosis [6], pneumonia [7], and lung cancer [8].\nDeep learning models require large quantities of expertly labelled training exemplars [9]\nand the well-established computer science mantra “Garbage In, Garbage Out” holds especially\ntrue in clinical applications of AI [10]. Whilst the gold-standard of image annotation remains\ndirect application of expert knowledge, the sheer size of the required datasets makes this\nPLOS ONE\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 1 / 16\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Drozdov I, Forbes D, Szubert B, Hall M,\nCarlin C, Lowe DJ (2020) Supervised and\nunsupervise d language modelling in Chest X-Ray\nradiological reports. PLoS ONE 15(3): e0229963.\nhttps://do i.org/10.1371/j ournal.pone .0229963\nEditor: Ulas Bagci, University of Central Florida\n(UCF), UNITED STATES\nReceived: October 23, 2019\nAccepted: February 17, 2020\nPublished: March 10, 2020\nCopyright: © 2020 Drozdov et al. This is an open\naccess article distributed under the terms of the\nCreative Commons Attribution License, which\npermits unrestricte d use, distribu tion, and\nreproduction in any medium, provided the original\nauthor and source are credited.\nData Availabilit y Statement: Our internal\nradiological report dataset cannot be shared\npublicly due to patient confident iality. MIMIC-CX R\ndata set can be accessed through https://\nphysionet.o rg/content/m imic-cxr/.\nFunding: This work is supported by Bering Limited\nand the Industrial Center for AI Researc h in Digital\ndiagnostics (iCAIRD ) which is funded by the Data\nto Early Diagnosis and Precision Medicine strand of\nthe government’s Indust rial Strategy Challenge\nFund, manag ed and delivered by Innovate UK on\nbehalf of UK Researc h and Innovation (UKRI)\nendeavour impractical [11]. Therefore, Natural Language Processing (NLP) approaches offer\nan opportunity to automate the annotation of free-text reports [12]. For example, the Medical\nLanguage Extraction and Encoding (MedLEE) system relies on controlled vocabulary and\ngrammatical rules to convert free text into a structured database [13]. PeFinder, an NLP system\nfor pulmonary embolism classification, uses pre-defined lexical cues and context terms to\nachieve high sensitivity and positive predictive value [14]. Finally, NegEx, utilises hand-crafted\nregular expression rules to identify pertinent negatives from patient discharge summaries [15].\nNevertheless, applying text mining techniques to radiological reports, which may contain bro-\nken grammar and misspellings, poses a number of challenges due to extensive variability in lin-\nguistic ambiguity. Indeed, in the publicly-available ChestXray14 [16] imaging dataset, labels do\nnot accurately reflect the visual content of the images, with positive predictive values of 10–\n30% lower than the values presented in the original documentation [11].\nNeural network-driven modelling of radiological language has been proposed to supersede\nthe hand-crafted rules and grammatical relations of the traditional rules-based algorithms\n[17]. Recently, a bi-directional long short-term memory (BiLSTM) network, which does not\nuse any hand-engineered features, was demonstrated to perform favourably in a corpus of\nCXR reports (f1 = 0.87) [18]. Similarly, a supervised approach using a Recurrent Neural Net-\nwork (RNN) with attention mechanism achieves high accuracy on expert-labelled CXR dataset\n(f1 = 0.93) [19]. Finally, Convolutional Neural Networks (CNNs) have been used to extract\npulmonary embolism findings from thoracic computed tomography reports, outperforming\nstate-of-the-art NLP systems (f1 = 0.94) [17].\nMulti-label annotation of abnormal reports has been the primary aim of radiological lan-\nguage models [2, 4, 18, 19]. Nevertheless, practicalities of day-to-day clinical workflows suggest\nthat the ability to identify ‘normal’ images and remove them from worklists would be antici-\npated to generate significant efficiency and cost savings [2, 20]. In addition, for clinicians\nreviewing images at the point of care, accurate triage of abnormal findings has potential\nsafety, clinical outcome, and assistive (e.g. reduced cognitive overload) benefits [21, 22].\nIn this study we describe an approach to automatically extract standardized clinical informa-\ntion from free-text CXR radiological reports. More specifically, it is anticipated that accurate\nidentification of Normal and Abnormal entities (irrespective of clinical sign or pathology) will\nfacilitate training of AI-enabled triage systems at scale. We evaluate the utility of classical super-\nvised machine learning techniques as well as state-of-the-art Long Short-Term Memory net-\nworks (LSTM) in the context of large corpora of free-text reports from Greater Glasgow and\nClyde Health Board (n = 500,000) and the Beth Israel Deaconess Medical Center (MIMIC-CXR\ndatabase [n = 227,835]) [23]. Additionally, we use ivis, an unsupervised Siamese Neural Net-\nwork-based algorithm [24], which accurately classifies radiological reports and visualises docu-\nment embeddings. Finally, we explore generalisability of machine learning techniques across\nEuropean and North American radiological report corpora.\nMaterials and methods\nRadiology reports and data preparation\nInternal training, validation, and testing sets were produced using an in-house corpus of\n500,000 deidentified CXR reports provided by NHS Greater Glasgow and Clyde (GGC) Safe-\nHaven. NHS GGC is the largest health board in Europe and delivers health care for 1.1 million\npatients with seven cute hospital sites. The reports cover the period between January 2007 and\nJanuary 2019. The repository consists of text typed or dictated by the clinicians after radio-\ngraph analysis and does not contain clinician or patient identifiable information such as\nnames, addresses or dates of birth. The reports had a minimum of 1 word and maximum of\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 2 / 16\n[Project number 104690 ]. Views expressed are\nthose of the authors and not necessarily those of\nBering, the iCAIRD Consortium members, the NHS,\nInnovate UK or UKRI. The funders had no role in\nstudy design, data collection and analysis, decision\nto publish, or preparation of the manuscript. ID and\nBS are employe es of Bering Limited. The funder\nprovided support in the form of salaries for authors\nID and BS, but did not have any additional role in\nthe study design, data collection and analysis,\ndecision to publish, or preparation of the\nmanuscript. The specific roles of these authors are\narticulated in the ‘author contributions’ section.\nCompeting interests : ID and BS are employees of\nBering Limited. This does not alter our adherenc e\nto PLOS ONE policies on sharing data and\nmaterials.\n380 words, with an average of 33.2 words and standard deviation of 20.5 words. On average,\nthere were 4.8 sentences per report. Prior to analysis, reports were converted to lower case and\nlemmatized. Numbers, punctuation marks, special characters, and words that occurred in\nfewer than three documents were discarded. The final vocabulary contained 9,598 words.\nA random sample of 5,000 reports was selected from the corpus for the purpose of creating\nexpert-labelled training, validation, and testing sets. The reports were manually labelled by a\nclinical fellow (DF) with special interest in Radiology. The annotation schema included three\nclasses–Normal, Abnormal, and Uncertain. The decision on the labelling was guided by the\nFleischner Society Glossary of Terms for Thoracic Imaging [25]. A report was deemed to be\nNormal if it was explicitly stated as such in the free-form report and if there were no reported\nmedical or surgical paraphernalia (e.g. pacemaker, sutures). An Abnormal label was assigned\nto reports with at least one documented radiological sign or presence of medical or surgical\nparaphernalia. If a report was normal for the patient (e.g. hyperinflated lungs in a patient with\nknown Chronic Obstructive Pulmonary Disease), the report was still categorised as Abnormal.\nIn cases where insufficient clinical information was provided to reliably label a report as Nor-\nmal or Abnormal, a label of Uncertain was assigned. Reports that were either blank or incon-\nclusive (e.g. “see above”, “same as above”) were excluded from the labelling exercise. All\nreports were labelled using the open source text annotation tool Doccano [26]. The final\nlabelled corpus consisted of 4,821 reports.\nThe external testing set was drawn from 227,835 radiographic studies recorded within the\nMIMIC-CXR database [23]. A random sample of 500 reports was selected from the corpus for\nthe purpose of creating an expert-labelled testing set. Pre-processing and annotation were per-\nformed as above. Following exclusion of inconclusive reports (e.g. reported only as “as above”,\n“see above”), the final external testing corpus contained 465 reports. The reports had a mini-\nmum of 2 words and maximum of 118 words, with an average of 13.4 words and standard\ndeviation of 16.2 words. On average, there were 2.9 sentences per report.\nSupervised report classification\nExpert-annotated reports were used to train three types of supervised classifiers: non-neural\n(i.e. classical machine learning algorithms), LSTM-based, and attention-based models\n(Transformers).\nNon-neural classifiers. The labelled corpus, consisting of Normal, Abnormal, and\nUnclear reports, was converted to term frequency-inverse document frequency (tf-idf) matrix\nand reduced to 100 dimensions using Singular Value Decomposition (SVD). Subsequently,\nthe transformed matrix was randomised into training (80%) and testing sets (20%) using a\nstratified split (Fig 1). Five supervised machine learning algorithms were evaluated on tf-idf/\nSVD-transformed radiology reports–K-Nearest Neighbour Classifier (KNN), Logistic Regres-\nsion (LR), Gaussian Naïve Bayes Classifier (NBC), Random Forest (RF), and Support Vector\nMachine (SVM). Each model’s hyperparameters were tuned on the training set using a Grid\nSearch algorithm with stratified five-fold cross-validation. Hyperparameters that yielded the\nbest macro-averaged f1 statistic across the five folds were retained for predictions on the inde-\npendent testing set.\nLSTM classifiers. The internal labelled corpus, consisting of Normal, Abnormal, and\nUnclear reports, was randomised into training (80%) and testing sets (20%) using stratified\nsplits. Each report was then represented as a tokenised sequence of words. We limited the maxi-\nmum length of the input sequence to 40, padding shorter sequences with zeros, whilst cropping\nlonger sequences. Model inputs were mapped to an Embedding layer, which was initialised\neither by using either pre-trained fastText [27] weights or by drawing from a uniform\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 3 / 16\ndistribution in the (−0.01, 0.01) range. The fastText model was trained on an unlabelled corpus\nof lemmatised and pre-processed free-text reports (n = 495,179, see above). Window size was\nset to three and embedding dimensionality was set to 50. Subsequently, a Bidirectional LSTM\n(BiLSTM) architecture [28] was implemented, with each LSTM layer consisting of 100 memory\ncells. The loss function was the categorical cross-entropy between the predicted probabilities of\nthe report tags and the true tags.\nOur BiLSTM model was also supplemented with an attention mechanism (BiLSTM-ATT)\n[19, 29], in which the BiLSTM layer is followed with an attention module. The attention module\ngenerates a predictive distribution over the LSTM encodings for each step by firstly calculating\nthe dot-product of the latest hidden state and the previous states, and then using the SoftMax\nfunction [30]. Applying these scores to the previous hidden state vectors effectively samples the\nmost useful input vectors dynamically by predicting which vectors are most important for the\npredictions. By enabling selective sampling of relevant information from all encoder states, the\nmodel is able to deal with long sequences of words and maintain global information about the\ninput sentence. Finally, all models were trained for 20 epochs with batches of 32 sentences\nusing the Adam optimiser with the learning rate set to 0.001. Training was terminated early if\nthe validation loss did not improve for three consecutive epochs.\nTransformer classifiers. The Transformer is a novel neural network architecture based\nsolely on a self-attention mechanism [31]. Four Transformer models were trained on the inter-\nnal training set—Bidirectional Encoder Representations from Transformers (BERT) [32], Dis-\ntilBERT [33], XLNet [34], and RoBERTa [35]. Each Transformer model was initialised using\npre-trained weights provided by the HuggingFace’s Transformers library [36]. A sequence-\nclassification head (a linear layer) was added on top of the base model’s hidden states. Radiol-\nogy reports were then represented as a tokenized sequence according to the requirements of\neach of the Transformer models–using a punctuation and wordpiece tokenizer (BERT,\nFig 1. Flowch art showing supervise d approach to radiology report classific ation.\nhttps://doi.o rg/10.1371/j ournal.pone .0229963.g001\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 4 / 16\nDistilBERT), SentencePiece tokenizer (XLNet), or Byte-Pair Encoding (RoBERTa). We limited\nthe maximum length of the input sequence to 128, padding shorter sequences with zeros,\nwhilst cropping longer sequences. Subsequently, all models were trained using the Adam opti-\nmizer for 20 epochs. Training was terminated early if validation loss did not improve for three\nconsecutive epochs.\nUnsupervised report classification\nReliable ground truths in radiological data is a scarce resource, which requires considerable\nclinical time and expertise. To address this limitation, we introduce a fully unsupervised\napproach to assigning Normal and Abnormal labels to free-text radiological reports.\nDimensionality reduction using siamese neural networks. The unsupervised ivis algo-\nrithm [24] was used to reduce dimensionality of 50-dimensional fastText embeddings of unla-\nbelled reports within the GGC corpus. To obtain report-level embeddings, fastText word\nvectors within each report were averaged [37] and the resulting 50-dimensional vector was\nused to as inputs into the ivis algorithm. ivis Siamese Neural Network was initialised using\nthree identical three-layer dense networks consisting of 500, 500, and 2,000 neurons each,\nfollowed by an embedding layer with the number of neurons reflecting dimensionality of\ndesired embeddings. The layers preceding the embedding layer use the SELU activation func-\ntion, which gives the network a self-normalizing property [38]. The weights for these layers are\nrandomly initialized with the LeCun normal distribution. The embedding layers use a linear\nactivation and have their weights initialized using Glorot’s uniform distribution. The network\nwas trained using a triplet loss function, whilst Euclidean distance was used to establish simi-\nlarity between points in the embedding space [24]. Nearest neighbour selection was limited to\n130 points and the training was halted early if the triplet loss did not improve for five epochs.\nGaussian mixture model clustering. A Gaussian Mixture Model (GMM) with two mix-\nture components was applied to either FastText or ivis embeddings (Fig 2). Posterior probabil-\nities of each mixture component were then obtained on the expertly labelled internal (GGC)\nand external (MIMIC-CXR) testing sets. The GMM’s performance was evaluated by compar-\ning ground truth labels of the testing set to mixture component probabilities.\nCheXpert labeller. The CheXpert labeller is an NLP tool based on keyword matching\nwith hardcoded rules describing negation [4], which assigns each report with one or more\nlabels associated with thoracic pathology. The labeller operates in three stages: 1) extraction, 2)\nclassification, and 3) aggregation. In the extraction stage, all mentions of a label are identified,\nincluding alternate spellings, synonyms, and abbreviations. Mentions are then classified as\npositive, uncertain, or negative using local context. In cases where keyword matching fails to\nproduce a reliable result, a label of No Findings is assigned. We considered all reports with a\nlabel of No Findings to be Normal, whilst remaining reports were considered to be Abnormal.\nPerformance assessment\nModel performance was assessed on internal (NHS GGC) and external (MIMIC-CXR Data-\nbase) testing sets. The following performance metrics were recorded–precision, recall,\nf1-score, and Area Under Receiver Operating Characteristic Curve (AUROC). In multi-class\nclassification problems, we weigh the average of the precision, recall, and f1-score by the num-\nber of instances of each class.\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 5 / 16\nResults\nSupervised report classification\nFive supervised multi-class classifiers were trained on tf-idf/SVD-transformed document\nmatrices (n = 1,315 Normal, n = 2,399 Abnormal, n = 142 Uncertain)–KNN, Logistic Regres-\nsion, Naïve Bayes, Random Forest, and SVM (Fig 3). For each model, an exhaustive grid search\nwas carried out on the training set using 5-fold cross validation, optimising the f1 score, and\nthe best performing parameters were fixed for subsequent performance assessment. SVM and\nLogistic Regression performed consistently well in identifying Normal and Abnormal reports,\nboth in internal (AUROC 0.97–0.98, Fig 3B and 3E) and external (AUROC 0.97–0.98, Fig 3G\nand 3J) testing sets. Although SVM performed well in differentiating Unclear reports in the\ninternal testing set (AUC = 0.86), all classifiers yielded suboptimal accuracy for this class in the\nexternal set (AUROC 0.39–0.51, Fig 3F–3J).\nNext, we used the expert-labelled internal radiological reports to train a series of three-class\nBiLSTM classifiers using tokenised report sequences. We hypothesised that by considering\ntemporal word relationships within each report, a more nuanced and generalisable model\ncould be obtained through modelling radiological language with BiLSTMs. As above, perfor-\nmance was assessed on both internal and external testing sets. Pre-training BiLSTM with fas-\ntText embeddings (BiLSTM-fastText) produced robust classifiers compared to randomly\ninitialised model weights (Fig 4A–4D, Table 1). Whilst BiLSTM-fastText resulted in marginally\nFig 2. Flowch art demonstr ating unsuperv ised approach to radiology report classification .\nhttps://doi.o rg/10.1371/j ournal.pone .0229963.g002\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 6 / 16\nbetter detection of Unclear class compared to the top-performing SVM classifier (AUC\nBiLSTM-\nfastTet\n= 0.87 vs. AUC\nSVM\n= 0.86, Fig 4A), this performance was further superseded by intro-\nducing attention mechanism to BiLSTM-fastText architecture (AUC\nBiLSTM-Att-fastText\n= 0.88,\nFig 4C, Table 1).\nFig 3. Performance assessmen t of non-neur al classifiers on internal and external testing sets. A-E. ROC curves displaying performan ce metrics on\nan expert-la belled internal testing set (n = 329 Normal, n = 601 Abnormal, n = 35 Uncertain). F-G. ROC curves demonstrati ng classifier performan ce\non external MIMIC-C XR free-text reports (n = 272 Normal, n = 184 Abnormal , n = 9 Uncertain).\nhttps://d oi.org/10.1371/j ournal.pon e.0229963.g0 03\nFig 4. Perform ance assessment of BiLSTM classifier s on internal and external testing sets. A-D. ROC curves displaying performance metrics on an\nexpert-labell ed internal testing set (n = 329 Normal, n = 601 Abnormal , n = 35 Uncerta in). E-H. ROC curves demonstrat ing classifier performance on\nthe external MIMIC-C XR expert-la belled free-text reports (n = 272 Normal, n = 184 Abnormal, n = 9 Uncert ain).\nhttps://doi.o rg/10.1371/j ournal.pone .0229963.g004\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 7 / 16\nTo assess how well our BiLSTM models generalise to an external testing set, we compared\npredicted labels to manually annotated reports from the MIMIC-CXR database (n = 272 Normal,\nn = 184 Abnormal, n = 9 Unclear, Fig 4E and 4F). Randomly-initialised BiLSTMs (BiLSTM-ran-\ndom) exhibited worse performance compared to both fastText-pretrained models and non-neu-\nral classifiers (Fig 4F and 4H). Interestingly, BiLSTM-Att-fastText, generalised well across\nNormal and Abnormal classes, and performed favourably on the Unclear class in the internal\nand external testing sets (Fig 4C and 4G).\nFinally, four self-attention based models (BERT, DistilBERT, XLNet, and RoBERTa) were\nevaluated on the internal and external testing sets (Fig 5). Whilst all models performed well in\nclassifying Normal and Abnormal reports (AUC = 0.97–0.99), XLNet achieved favourable\nTable 1. Performance comparis on of supervised multi-c lass classifier s on internal and extern al testing sets. Class-weighte d values are reported.\nClassifier Internal Testing Set (n = 978) Externa l Testing Set (n = 465)\nPrecision Recall F1-score Precision Recall f1-score\nKNN 0.82 0.86 0.84 0.81 0.82 0.81\nLogistic Regression 0.85 0.90 0.87 0.91 0.93 0.92\nNaïve Bayes 0.78 0.82 0.80 0.70 0.47 0.38\nRandom Forest 0.83 0.88 0.86 0.84 0.80 0.80\nSVM 0.85 0.90 0.88 0.91 0.93 0.92\nBiLSTM-fastText 0.93 0.93 0.93 0.91 0.91 0.91\nBiLSTM-random 0.91 0.91 0.91 0.72 0.58 0.57\nBiLSTM-Att-fastText 0.94 0.94 0.94 0.90 0.91 0.90\nBiLSTM-Att-random 0.90 0.91 0.90 0.73 0.55 0.53\nBERT 0.92 0.93 0.92 0.94 0.93 0.93\nDistilBERT 0.91 0.91 0.91 0.93 0.93 0.93\nXLNet 0.93 0.93 0.93 0.95 0.95 0.95\nRoBERTa 0.91 0.91 0.91 0.93 0.93 0.93\nhttps://do i.org/10.1371/j ournal.pone .0229963.t001\nFig 5. Performance assessmen t of Transforme r-based classifiers on internal and external testing sets. A-D. ROC curves displaying performan ce\nmetrics on an expert-labell ed internal testing set (n = 329 Normal, n = 601 Abnormal , n = 35 Uncert ain). E-H. ROC curves demonstrat ing classifier\nperforman ce on the external MIMIC-C XR expert-labe lled free-text reports (n = 272 Normal, n = 184 Abnormal , n = 9 Uncertain).\nhttps://d oi.org/10.1371/j ournal.pon e.0229963.g0 05\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 8 / 16\nperformance on the Unclear class in both internal and external testing sets (AUC = 0.80 and\nAUC = 0.83 respectively, Fig 5C and 5G).\nUnsupervised report classification\nWe demonstrated that supervised classifiers achieve excellent performance using a relatively\nsmall number of labelled training exemplars (n = 3,856 reports). Furthermore, neural networks\nthat utilise the BiLSTM architecture with attention mechanism appear to generalise well to\nexternal radiological reports. Nevertheless, generation of reliable ground truths remains a bar-\nrier to training effective deep learning models due to the required clinical time and expertise.\nTo address this limitation, we set out to develop and evaluate an unsupervised approach to\nassigning Normal and Abnormal labels to free-text radiological reports.\nAn internal corpus of n = 495,179 unlabelled reports was represented as a collection of\n50-dimensional fastText document vectors (see Methods). We hypothesised that free-text enti-\nties can be modelled using Gaussian Mixture Distributions due to inherently distinct semantic\nstructure of Normal and Abnormal reports. To test this hypothesis, a GMM with two compo-\nnents was constructed from the unlabelled document vectors and posterior probabilities of\neach component were extracted from the expert-labelled reports of the internal (n = 1,315\nNormal and n = 2,400 Abnormal) and external (MIMIC-CXR, n = 272 Normal and n = 184\nAbnormal) corpora. Whilst GMM performance on an internal testing set was sub-optimal,\nmodel validation on an external testing set produced acceptable metrics (AUC = 0.50 and\nAUC = 0.86 respectively, Fig 6D).\nRecently, we introduced a novel algorithm, ivis, for dimensionality reduction and feature\nengineering in large datasets [14]. ivis is a parametric method that utilises a Siamese Neural\nNetwork to generate low-dimensional data representations that preserve both local and global\nproperties of original observations. To further refine fastText embeddings, we applied ivis to\n50-dimensional report vectors prior to GMM clustering (Fig 6A). Reduction of fastText\nreports to two-dimensional ivis representations resulted in marked performance improve-\nments in both internal and external datasets (AUC = 0.89 and AUC = 0.90 respectively, Fig 6B\nand 6C). GMM performance was enriched further by expanding ivis representations to ten\nembedding dimensions (ivis-10D, AUC\nInternal\n= 0.89, AUC\nExternal\n= 0.94, Fig 6E and 6F).\nFinally, we compared GMM-clustered ivis embeddings to annotations generated by the\nCheXpert Labeller. The labeller is a rule-based classifier which operates in three stages: 1)\nextraction, 2) classification, and 3) aggregation. In the extraction stage, all mentions of a label\nare identified, including alternate spellings, synonyms, and abbreviations. Mentions are then\nclassified as positive, uncertain, or negative using local context. The CheXpert Labeller is tai-\nlored for CXRs, and recently demonstrated favourable performance on free-text reports [23].\nBoth the Labeller and GMM-clustered ivis-10D embeddings achieved comparable perfor-\nmances on an internal and external dataset (f1-score\nInternal\n= 0.81 and f1-score\nExternal\n= 0.92,\nTable 2). Interestingly, just two-dimensional ivis embeddings achieved acceptable classifica-\ntion performance, making the datasets amenable to interpretable visualisation (Fig 6A–6C).\nDiscussion\nIn this work we examine the application of supervised machine learning algorithms to classifi-\ncation of free-text CXR reports. Rigorous performance benchmarking on two independent\ncorpora from two international health systems demonstrate that BiLSTM networks with self-\nattention mechanism produce state-of-the-art classification results and are generalise to exter-\nnal testing sets. Furthermore, we introduce a fully unsupervised approach for abnormality\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 9 / 16\ndetection in free-text reports, which performs favourably compared to a well-established rules-\nbased classifier tuned for CXR labelling.\nOur analysis of five non-neural supervised classifiers (KNN, Logistic Regression, Naïve\nBayes, Random Forest, and SVM) demonstrated that whilst all models achieved excellent per-\nformance on an internal testing set, only SVM successfully captured Normal and Abnormal\nentities in both testing sets. Reports labelled as Unclear were consistently misclassified by all\nFig 6. Unsuperv ised report classificatio n using fastText, ivis, and Gaussian Mixture Model clustering. A. Two-dim ensional ivis representati on of\n50-dimen sional fastText embeddin gs of n = 495,179 unlabell ed radiologi cal reports from NHS GGC. Colour gradient reflects posterior probability of\nNormal and Abnormal report cluster. B. Scatterplot of predicted ivis embeddin gs for n = 3,715 expert-labe lled reports in the internal testing set. Blue\nand red points represent manuall y-labelled Normal and Abnormal report s respectively. Colour gradient reflects contours of posterior probabil ity\ndistributi ons obtained from GMM model trained on two-dim ensional ivis representati ons of n = 495,179 unlabelled radiological reports. C. Scatterplot\nof predicted ivis embeddings for n = 456 expert-labelled reports in the MIMIC-C XR testing set. Blue and red points represent manuall y-labelled\nNormal and Abnormal reports respective ly. Colour gradient reflects contours of posterior probability distributi ons obtained from GMM model trained\non two-dim ensional ivis representati ons of n = 495,179 unlabelled radiologi cal reports. D. ROC curves of unsuper vised GMM classifier applied to\n50-dimen sional fastText embeddin gs of internal (n = 3,715) and external (n = 456) manually-lab elled reports. E-F. ROC curves of unsupervised GMM\nclassifier applied to two- and ten-dimensi onal ivis embeddin gs of manually labelled internal (n = 3,715) and external (n = 456) reports.\nhttps://d oi.org/10.1371/j ournal.pon e.0229963.g0 06\nTable 2. Performance comparis on of unsuperv ised classifiers on internal and external radiologi cal reports. Average performan ce values are reported.\nClassifie r Internal Testing Set (n = 3715) Externa l Testing Set (n = 456)\nPrecision Recall f1-score Precision Recall f1-score\nfastText+GMM 0.42 0.65 0.51 0.88 0.84 0.84\nivis-2D+GMM 0.83 0.80 0.80 0.88 0.88 0.88\nivis-10D+GMM 0.82 0.80 0.81 0.91 0.91 0.92\nCheXpert Labeller 0.81 0.81 0.81 0.93 0.93 0.92\nhttps://do i.org/10.1371/j ournal.pone .0229963.t002\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 10 / 16\nalgorithms in the external testing set (Fig 3F–3J). These findings are consistent with the general\nnotion that SVMs are well-suited for a text classification task due to 1) the algorithm’s ability\nto learn independently of the dimensionality of the feature space, 2) suitability to problems\nwith dense concepts and sparse instances (document vectors are sparse as each document vec-\ntor contains only few entries which are not zero), and 3) linearly separable nature of most text\nproblems [39]. Indeed, an SVM trained on a bag of phrases was used to detect hospital admis-\nsions due to specific diseases [40] as well as classify medical subdomain across clinical notes\n[41]. Interestingly, the SVM only marginally outperforms Logistic Regression classifier. Con-\nsidering that Logistic Regression predictions may be viewed as locally interpretable [42], the\nminor trade-off in accuracy may be justified in favour of trusting and understanding intuition\nbehind each classification [43].\nNon-neural classifiers rely on a bag-of-words (BOW) representation of the training corpus.\nThe approach maintains word multiplicity, but disregards grammatical nuances and word\norder of original sentences. Additionally, BOW matrices are often sparse, with only a few\nentries which are not zero. This convention has often proven to be problematic for non-neural\nclassifiers due to the data sparsity problem [44]. In recent years, deep artificial neural networks\nhave been found to yield consistently good and often state-of-the-art results on a variety of\nNLP tasks [18]. It can be argued that by considering complex inter-relationships between\nwords within sentences, deep neural networks achieve state-of-the-art performance across\nNLP tasks such as part-of-speech tagging, shallow parsing, named entity recognition, and\nsemantic role labelling [45].\nWe demonstrated that BiLSTM networks learn to differentiate Normal and Abnormal CXR\nreports and generalise well to an independent testing set (Table 1). Traditionally, BiLSTMs have\nshown performance improvements in NLP tasks over Unidirectional LSTMs, lkely due to inclu-\nsion of information from both future and past words in the sentence [28]. We demonstrate that\nan important requirement to a generalisable model is initialising the network with pre-trained\nword embeddings. Indeed, pre-trained BiLSTMs weights considerably outperformed random\nweight initialisation in terms of precision, recall, and f1-scores (Table 1). Previous reports have\nshown only marginal accuracy gains attributed to pre-training [18]. However, this is like\nbecause only an internal testing set was used to benchmark algorithm performance, whilst we\nnote considerable gains on external datasets.\nTo pre-train our models, we applied fastText to an unlabelled corpus of n = 495,179 reports\nfrom NHS GGC. Several important features prompted us to choose fastText over other compa-\nrable approaches. First, the algorithm is fast and can train on our corpus within a few minutes.\nThis allowed us to experiment with hyperparameters in order to produce better embeddings.\nSecond, fastText operates at a character level, meaning that word vectors can still be extracted\nfor those words that are not present in the original vocabulary. This is especially important as\nspelling and abbreviations vary greatly between radiological reports [46]. Indeed, it is not\nunreasonable to hypothesise that this feature of the fastText algorithm contributed signifi-\ncantly to model generalisability across testing sets. Finally, unlike word vectors from word2vec\n[47], fastText word features can be averaged together to form good sentence representations\n[37]. It is plausible that adding more reports into the pre-training corpus will lead to further\nperformance gains–this is something that we intend to explore in greater detail as our work\nevolves.\nIn an earlier work, the attention mechanism was demonstrated to achieve high accuracy on\nan expertly labelled CXR dataset (f1-score = 0.93) [19]. The attention layer learns heteroge-\nneous text representations for each label under an assumption that each snippet containing\ndistinguishing information could be anywhere in the text and would differ across labels [19].\nAs such, attention can help combine global and local information in order to improve\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 11 / 16\nclassification performance [48]. In this work, a BiLSTM (pre-trained with fastText vectors)\nwith attention mechanism was the top-performing LSTM classifier (f1-score\nInternal\n= 0.94,\nf1-score\nExternal\n= 0.90, Table 1). Interestingly, the approach also identified Uncertain reports\nconsiderably better on an external testing set (AUC = 0.67, Fig 4G), suggesting that more\nnuanced information can still be learnt from small number of exemplars. Overall, this work,\ntogether with independent reports [19, 48, 49], suggests that training a BiLSTM with attention\non a relatively small corpus of labelled data produces generalisable state-of-the-art free-text\nclassifiers that may augment training of computer vision models.\nRecently, several novel network architectures, based solely on attention mechanisms, have\nachieved state-of-the-art performance across NLP tasks [31]. In this work we demonstrate that\nfour Transformer-based models, namely BERT, DistilBERT, XLNet, and RoBERTa, achieve\nexcellent performance (AUC: 0.97–0.99, Fig 5) on free-text radiological reports, which general-\nises well to an external testing set. Although performances of all Transformer-based models\nwere comparable to BiLSTM with attention mechanism for Normal and Abnormal reports,\nXLNet identified Uncertain reports with increased accuracy (AUC\nXLNet\n= 0.80–0.83 vs. AUC-\nBiLSTM-Att-fastText\n= 0.67–0.88). This improvement is likely due to the capacity of XLNet to learn\nbidirectional contexts and its autoregressive formulation [34]. Nevertheless, despite marginal\nincrease in performance, training and finetuning Transformer-based models is a computation-\nally expensive task. Marginal performance gains are offset by the hardware resources required\nto complete training and inference experiments.\nSo far, we have shown that supervised classifiers achieve excellent performance using a rela-\ntively small number of labelled training exemplars (n = 3,856 reports). Nevertheless, genera-\ntion of reliable ground truths remains a barrier to training effective deep learning models due\nto the required clinical time and expertise [11]. To address this limitation, we set out to\ndevelop and evaluate an unsupervised approach to assigning Normal and Abnormal labels to\nfree-text radiological reports. Our top-performing approach involves three steps: 1) obtaining\nsentence vectors by averaging fastText word features, 2) feature extraction using ivis, a novel\nSiamese Network algorithm, and 3) fitting a GMM with two components (assuming that dis-\ntributions of Normal and Abnormal reports are inherently different) to ivis embeddings. Per-\nformance of this three-step approach was comparable to the CheXpert Labeller, which utilises\nhand-crafted rules tailored for CXR report annotation [4, 23]. We have previously applied ivis\nto structured single-cell datasets [24], demonstrating that the algorithm reliably preserves local\nand global distances in a low-dimensional space. Briefly, ivis employs a Siamese Neural Net-\nwork architecture that learns to discriminate between similar and dissimilar fastText vectors\nwithout imposing strong priors. This property enables natural creation of dense clusters with\nshared nearest neighbours, making sentence vectors amenable to modelling with GMMs.\nInterestingly, although ivis was trained on the unlabelled internal corpus, it performed consid-\nerably better on an external testing set (Table 2). This was also the case for the CheXpert Label-\nler. It is likely that given that external testing set reports were shorter than internal reports\n(external average: 13.4 words vs. internal average: 33.2 words), the external reports were more\nlinearly separable (Fig 6C), resulting in improved unsupervised performance.\nWhilst ivis+GMM performance was comparable to CheXpert Labeller, we have identified\nseveral advantages of our unsupervised approach. First, GMMs can be used to obtain posterior\nprobabilities of each component for every report. This provides a degree of granularity to our\nresults. For example, at a component probability threshold greater than 0.99, ivis+GMM iden-\ntified 30% of Abnormal reports with 100% positive predictive value. Conversely, the CheXpert\nLabeller provides strictly categorical outputs, that cannot be used to fine-tune an algorithm’s\nconfidence. Second, ivis+GMM is a general approach and is not restricted to CXR reports. It is\nlikely that application of this algorithm will yield comparable results in other free-text medical\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 12 / 16\nrecords. Finally, ivis is a dimensionality reduction technique, which can be used to visualise\ncomplex data structures in two-dimensional space. It has been shown to scale linearly to mil-\nlions of data points, resulting in more interpretable visualisations than comparable techniques\nsuch as t-distributed Stochastic Neighbour Embedding (t-SNE) [50].\nTaken together, we have shown that supervised machine learning algorithms can reliably\nlabel free-text CXR radiological reports with excellent performance and using a relatively small\nnumber of training exemplars. More specifically, pre-training BiLSTM with fastText weights\nand the inclusion of the attention mechanism yields state-of-the-art accuracy that can be gen-\neralised to an independent testing set. To the best of our knowledge this is the first study\nwhere the generalisability of a machine learning algorithm for free-text CXR report interpreta-\ntion has been demonstrated across two independently sourced and expert-labelled testing sets.\nFurthermore, we validate a general fully unsupervised approach that utilises Siamese Neural\nNetworks and GMMs to reliably label large free-text corpora. Although direct application of\nexpert knowledge to unlabelled radiograms remains the gold-standard of image annotation,\nwe anticipate that our results can be used to effectively extract standardized clinical informa-\ntion from CXR radiological reports, facilitating large-scale training of modern clinical decision\nsupport systems for CXR triage.\nAcknowledgmen ts\nWe thank Dr. David Stobo for the invaluable clinical feedback throughout the study, Claire\nMacDonald for data extraction from NHS GGC SafeHaven, and James Blackwood for help\nwith project coordination.\nAuthor Contributions\nConceptualization: Ignat Drozdov, David J. Lowe.\nData curation: Daniel Forbes.\nFormal analysis: Ignat Drozdov, Daniel Forbes, Benjamin Szubert, Mark Hall, Chris Carlin.\nFunding acquisition: Ignat Drozdov, David J. Lowe.\nInvestigation: Ignat Drozdov, Mark Hall, Chris Carlin, David J. Lowe.\nMethodology: Ignat Drozdov, Daniel Forbes, Benjamin Szubert, Mark Hall, Chris Carlin.\nProject administration: Ignat Drozdov.\nResources: Ignat Drozdov, Mark Hall, David J. Lowe.\nSoftware: Benjamin Szubert.\nSupervision: Ignat Drozdov.\nValidation: Ignat Drozdov, Benjamin Szubert, Mark Hall, Chris Carlin.\nVisualization: Benjamin Szubert.\nWriting – original draft: Daniel Forbes, Benjamin Szubert, Mark Hall, Chris Carlin, David J.\nLowe.\nWriting – review & editing: Daniel Forbes, Benjamin Szubert, Mark Hall, Chris Carlin, David\nJ. Lowe.\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 13 / 16\nReferences\n1. Raoof S, Feigin D, Sung A, Raoof S, Irugulpati L, Rosenow EC 3rd. Interpreta tion of plain chest roent-\ngenogram . Chest. 2012; 141(2):545 –58. Epub 2012/02/09. https:// doi.org/10.13 78/chest.10 -1302\nPMID: 223151 22.\n2. Annarumm a M, Withey SJ, Bakewell RJ, Pesce E, Goh V, Montana G. Automate d Triaging of Adult\nChest Radiogr aphs with Deep Artificial Neural Networks. Radiolog y. 2019; 291(1):272 . Epub 2019/03/\n22. https://doi. org/10.1148/r adiol.201919 4005 PMID: 30897046.\n3. Rajpurkar P, Irvin J, Ball RL, Zhu K, Yang B, Mehta H, et al. Deep learning for chest radiograph diagno -\nsis: A retrospectiv e comparison of the CheXN eXt algorithm to practicing radiologists . PLoS Med. 2018;\n15(11):e10 02686. Epub 2018/11 /21. https://doi. org/10.1371/j ournal.pm ed.1002686 PMID: 304579 88\nfollowing competing interests: CPL holds shares in whiterabb it.ai and Nines.a i, is on the Advisory Board\nof Nuance Commun ications and on the Board of Directors for the Radiolog ical Society of North Amer-\nica, and has other research support from Philips , GE Healthc are, and Philips Healthcare . MPL holds\nshares in and serves on the Advisory Board for Nines.ai. None of these organiz ations have a financial\ninterest in the results of this study.\n4. Irvin J, Rajpurkar P, Ko M, Yu Y, Ciurea-Ilc us S, Chute C, et al. CheXpert : A Large Chest Radiograph\nDataset with Uncertainty Labels and Expert Comp arison. arXiv e-prints [Interne t]. 2019 January 01,\n2019. https://u i.adsabs.ha rvard.edu/abs /2019arXiv19 0107031 I.\n5. Putha P, Tadepa lli M, Reddy B, Raj T, Chiramal JA, Govil S, et al. Can Artificia l Intellig ence Reliably\nReport Chest X-Rays?: Radiolog ist Validation of an Algorithm trained on 2.3 Million X-Rays. arXiv e-\nprints [Interne t]. 2018 July 01, 2018. https:// ui.adsabs.h arvard.edu/ab s/2018ar Xiv18070 7455P.\n6. Pasa F, Golkov V, Pfeiffer F, Cremers D, Pfeiffer D. Efficient Deep Network Archite ctures for Fast\nChest X-Ray Tuberculos is Screening and Visuali zation. Sci Rep. 2019; 9(1):6268. Epub 2019/04/20.\nhttps://doi.or g/10.103 8/s41598 -019-42557 -4 PMID: 31000728\n7. Rajpurkar P, Irvin J, Zhu K, Yang B, Mehta H, Duan T, et al. CheXNet: Radiolog ist-Level Pneumo nia\nDetection on Chest X-Rays with Deep Learning. arXiv e-prints [Interne t]. 2017 Novemb er 01, 2017.\nhttps://ui.ads abs.harva rd.edu/abs/ 2017arXiv17 1105225R .\n8. Ausawalai thong W, Marukatat S, Thirach A, Wilaipras itporn T. Automatic Lung Cance r Predict ion from\nChest X-ray Images Using Deep Learning Approach. arXiv e-prints [Interne t]. 2018 August 01, 2018.\nhttps://ui.ads abs.harva rd.edu/abs/ 2018arXiv18 0810858A.\n9. Sun C, Shrivastava A, Singh S, Gupta A. Revisiting Unreasona ble Effectivene ss of Data in Deep Learn-\ning Era. arXiv e-prints [Interne t]. 2017 July 01, 2017. https://ui. adsabs.har vard.edu/abs /\n2017arXiv17 070296 8S.\n10. Vayena E, Blasimm e A, Cohen IG. Machine learning in medicine: Addressi ng ethical challeng es. PLoS\nMed. 2018; 15(11):e10 02689. Epub 2018/11 /07. https://doi. org/10.1371/j ournal.pm ed.1002689 PMID:\n30399149 following competing interests: EV has received speaking fees from SwissRe, Novartis R&D\nAcademy, and Google Netherlan ds. IGC served as a consultant for Otsuka Pharmac euticals advising\non the use of digital medicine for its Abilify MyCite product. IGC is supporte d by the Collabor ative\nResearch Program for Biomed ical Innovation Law, which is a scientifically independent collaborativ e\nresearch program supported by Novo Nordisk Foundation. AB served as a consultant for Celgene Cor-\nporation for the preparatio n of a worksh op on pharmace utical innovatio n and received honoraria from\nSwissRe for participating at an intern al event on genome editing.\n11. Oakden-R ayner L. Exploring large scale public medical image datasets. arXiv e-prints [Interne t]. 2019\nJuly 01, 2019. https://ui.a dsabs.harva rd.edu/abs /2019arXiv19 0712720O.\n12. Pons E, Braun LM, Hunink MG, Kors JA. Natural Langua ge Processin g in Radiology: A Systematic\nReview. Radiology. 2016; 279(2):329 –43. Epub 2016/04 /19. https://do i.org/10.1148 /radiol.1614 2770\nPMID: 270891 87.\n13. Friedman C, Alderso n PO, Austin JH, Cimino JJ, Johnson SB. A genera l natura l-language text proces-\nsor for clinical radiology. J Am Med Inform Assoc. 1994; 1(2):161–7 4. Epub 1994/03/01. https:// doi.org/\n10.1136/ jamia.1994.9 5236146 PMID: 7719797\n14. Chapman BE, Lee S, Kang HP, Chapman WW. Docume nt-level classifica tion of CT pulmonary angiog -\nraphy reports based on an extension of the ConTex t algorithm. J Biomed Inform. 2011; 44(5):728– 37.\nEpub 2011/04/ 05. https://doi.or g/10.101 6/j.jbi.2011.03 .011 PMID: 21459155\n15. Chapman WW, Bridewe ll W, Hanbury P, Cooper GF, Buchan an BG. A simple algorithm for identifyin g\nnegated finding s and diseases in discharge summaries. J Biomed Inform. 2001; 34(5):301– 10. Epub\n2002/07/ 19. https://doi.or g/10.100 6/jbin.2001.10 29 PMID: 12123149.\n16. Wang X, Peng Y, Lu L, Lu Z, Bagheri M, Summers RM. ChestX-ra y8: Hospital-s cale Chest X-ray Data-\nbase and Benchmark s on Weakly-S upervised Classificat ion and Localizatio n of Common Thorax Dis-\neases. arXiv e-prints [Interne t]. 2017 May 01, 2017. https://ui.adsab s.harvard .edu/abs/\n2017arXiv17 050231 5W.\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 14 / 16\n17. Chen MC, Ball RL, Yang L, Moradzade h N, Chapma n BE, Larson DB, et al. Deep Learning to Classify\nRadiolog y Free-Tex t Reports. Radiolog y. 2018; 286(3):845 –52. Epub 2017/11/15. https:/ /doi.org/10.\n1148/radiol .201717 1115 PMID: 29135365.\n18. Cornegrut a S, Bakewell R, Withey S, Montana G. Modelling Radiolog ical Langua ge with Bidirectiona l\nLong Short-Term Memo ry Networks. arXiv e-prints [Internet ]. 2016 Septemb er 01, 2016. https://ui.\nadsabs.har vard.edu /abs/2016arXi v160908 409C.\n19. Bustos A, Pertusa A, Salinas J-M, de la Iglesia- Vaya ´ M. PadChest: A large chest x-ray image dataset\nwith multi-label annotate d reports. arXiv e-prints [Interne t]. 2019 January 01, 2019. https:// ui.adsabs.\nharvard.edu/ abs/2019arXi v190107 441B.\n20. Lindsey R, Daluisk i A, Chopra S, Lachape lle A, Mozer M, Sicular S, et al. Deep neural network improves\nfracture detection by clinicians. Proc Natl Acad Sci U S A. 2018; 115(45):11 591–6. Epub 2018/10 /24.\nhttps://doi.or g/10.107 3/pnas.18 06905115 PMID: 303487 71\n21. Drew BJ, Harris P, Zegre-He msey JK, Mammo ne T, Schindl er D, Salas-Boni R, et al. Insights into the\nproblem of alarm fatigue with physiolog ic monitor devices : a comprehe nsive observatio nal study of con-\nsecutive intensive care unit patients. PLoS One. 2014; 9(10):e110 274. Epub 2014/10/ 23. https://doi.\norg/10.1371/ journal.pon e.0110274 PMID: 253380 67\n22. Rajkoma r A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalabl e and accurate deep learning with\nelectronic health records. NPJ Digit Med. 2018; 1:18. Epub 2018/05 /08. https://doi.o rg/10.1038/\ns41746-018 -0029-1 PMID: 31304302\n23. Johnson AEW, Pollard TJ, Berkowitz SJ, Greenbau m NR, Lungren MP, Deng C-y, et al. MIMIC-C XR: A\nlarge publicly availabl e database of labeled chest radiograp hs. arXiv e-prints [Interne t]. 2019 January\n01, 2019. https:/ /ui.adsabs.h arvard.edu/ab s/2019arXiv190 107042 J.\n24. Szubert B, Cole JE, Monaco C, Drozdov I. Structure-pr eserving visualisation of high dimension al sin-\ngle-cell datasets. Sci Rep. 2019; 9(1):8914. Epub 2019/06/22. https://doi.or g/10.1038/ s41598-019-\n45301-0 PMID: 312220 35\n25. Hansell DM, Bankier AA, MacMa hon H, McLoud TC, Muller NL, Remy J. Fleischner Society: glossary\nof terms for thoracic imaging. Radiolog y. 2008; 246(3):697 –722. Epub 2008/01 /16. https://doi.or g/10.\n1148/radiol .246207 0712 PMID: 18195376.\n26. Doccano . Doccano: Open source text annotati on tool for machine learning practitioner 2019 [cited 2019\nAugust 1, 2019]. https://githu b.com/chak ki-works/docc ano.\n27. Bojanow ski P, Grave E, Joulin A, Mikolov T. Enriching Word Vectors with Subword Informatio n. arXiv e-\nprints [Interne t]. 2016 July 01, 2016. https:// ui.adsabs.h arvard.edu/ab s/2016ar Xiv16070 4606B.\n28. Graves A, Ferna ´ ndez S, Schmidhu ber J, editors. Bidirectiona l LSTM Networks for Improved Phoneme\nClassifica tion and Recognition 2005; Berlin, Heidelbe rg: Springer Berlin Heidelbe rg.\n29. Mullenb ach J, Wiegre ffe S, Duke J, Sun J, Eisenstein J. Explain able Prediction of Medical Codes from\nClinical Text. arXiv e-prints [Internet] . 2018 February 01, 2018. https://ui.ads abs.harvard.ed u/abs/\n2018arXiv18 020569 5M.\n30. Luong M-T, Pham H, Manning CD. Effective Approaches to Attention-ba sed Neural Machine Transla-\ntion. arXiv e-prints [Interne t]. 2015 August 01, 2015. https:/ /ui.adsabs.h arvard.edu/a bs/\n2015arXiv15 080402 5L.\n31. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, et al. Attentio n Is All You Need.\narXiv e-prints [Interne t]. 2017 June 01, 2017. https://ui.ad sabs.harvar d.edu/abs /\n2017arXiv17 060376 2V.\n32. Devlin J, Chang M-W, Lee K, Toutanova K. BERT: Pre-training of Deep Bidirection al Transfor mers for\nLanguage Understand ing. arXiv e-prints [Internet] . 2018 October 01, 2018. https://ui.adsab s.harvard .\nedu/abs/2 018arXiv181 004805 D.\n33. Sanh V, Debut L, Chaumond J, Wolf T. DistilBERT, a distilled version of BERT: smaller, faster, cheaper\nand lighter. arXiv e-prints [Interne t]. 2019 October 01, 2019. https://ui.ads abs.harva rd.edu/abs /\n2019arXiv19 100110 8S.\n34. Yang Z, Dai Z, Yang Y, Carbone ll J, Salakhu tdinov R, Le QV. XLNet: Generalize d Autoregre ssive Pre-\ntraining for Language Understand ing. arXiv e-prints [Internet] . 2019 June 01, 2019. https://ui.adsa bs.\nharvard.edu/ abs/2019arXi v190608 237Y.\n35. Liu Y, Ott M, Goyal N, Du J, Joshi M, Chen D, et al. RoBERTa: A Robustly Optimized BERT Pretrainin g\nApproach. arXiv e-prints [Internet]. 2019 July 01, 2019. https://ui.ads abs.harvard.e du/abs/\n2019arXiv19 071169 2L.\n36. Wolf T, Debut L, Sanh V, Chaumond J, Delangue C, Moi A, et al. HuggingFa ce’s Transforme rs: State-\nof-the-art Natural Language Processin g. arXiv e-prints [Interne t]. 2019 October 01, 2019. https://ui.\nadsabs.har vard.edu /abs/2019arXi v191003 771W.\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 15 / 16\n37. Joulin A, Grave E, Bojanow ski P, Mikolov T. Bag of Tricks for Efficient Text Classifica tion. arXiv e-prints\n[Internet ]. 2016 July 01, 2016. https://ui.ad sabs.harvar d.edu/abs /2016arXiv16 0701759J .\n38. Klambau er G, Unterthine r T, Mayr A, Hochreiter S. Self-Norm alizing Neural Networ ks. arXiv e-prints\n[Internet ]. 2017 June 01, 2017. https://ui.ads abs.harva rd.edu/abs/2 017arXiv170 602515K.\n39. Joachims T, editor Text categoriza tion with Suppo rt Vector Machines: Learning with many relevant fea-\ntures 1998; Berlin, Heidelbe rg: Springer Berlin Heidelbe rg.\n40. Kocbek S, Cavedon L, Martinez D, Bain C, Manus CM, Haffari G, et al. Text mining electron ic hospital\nrecords to automatical ly classify admissions against disease: Measurin g the impact of linking data\nsources. J Biomed Inform. 2016; 64:158–67 . Epub 2016/10/16. https:// doi.org/10.10 16/j.jbi.2 016.10.\n008 PMID: 277423 49.\n41. Weng WH, Wagholikar KB, McCray AT, Szolovits P, Chueh HC. Medical subdomain classific ation of\nclinical notes using a machine learning-b ased natural language processing approach. BMC Med Inform\nDecis Mak. 2017; 17(1):155. Epub 2017/12/02. https:/ /doi.org/10.11 86/s1291 1-017-055 6-8 PMID:\n29191207\n42. Slack D, Friedler SA, Scheide gger C, Dutta Roy C. Assessing the Local Interpretabil ity of Machine\nLearning Models. arXiv e-prints [Interne t]. 2019 February 01, 2019. https://ui.ads abs.harva rd.edu/abs /\n2019arXiv19 020350 1S.\n43. Tulio Ribeiro M, Singh S, Guestrin C. \"Why Should I Trust You?\": Explain ing the Predictions of Any\nClassifier. arXiv e-prints [Internet]. 2016 Februa ry 01, 2016. https:// ui.adsabs.h arvard.edu/ab s/\n2016arXiv16 020493 8T.\n44. Lai S, Xu L, Liu K, Zhao J. Recurren t convolutio nal neural networks for text classification. Procee dings\nof the Twenty- Ninth AAAI Conferen ce on Artifici al Intelligence; Austin, Texas. 2886636 : AAAI Press;\n2015. p. 2267–7 3.\n45. Collobert R, Weston J, Bottou L, Karlen M, Kavukcuogl u K, Kuksa P. Natural Language Processin g\n(almost) from Scratch. arXiv e-prints [Interne t]. 2011 March 01, 2011. https://u i.adsabs.ha rvard.edu/\nabs/2011 arXiv1103.03 98C.\n46. Thompson AJ. Re: The radiology report—ar e we getting the message across? Clin Radiol. 2012; 67\n(7):723; author reply 4–5. Epub 2012/06/05. https:// doi.org/10.10 16/j.crad .2012.01.008 PMID:\n22655596.\n47. Mikolov T, Chen K, Corrado G, Dean J. Efficient Estimation of Word Representa tions in Vector Space.\narXiv e-prints [Interne t]. 2013 January 01, 2013. https:// ui.adsabs.h arvard.edu/ab s/2013ar Xiv1301.\n3781M.\n48. Guan Q, Huang Y, Zhong Z, Zheng Z, Zheng L, Yang Y. Diagnose like a Radiolog ist: Attentio n Guided\nConvolution al Neural Network for Thorax Disease Classifica tion. arXiv e-prints [Interne t]. 2018 January\n01, 2018. https:/ /ui.adsabs.h arvard.edu/ab s/2018arXiv180 109927 G.\n49. Yang Z, Yang D, Dyer C, He X, Smola A, Hovy E, editor s. Hierarchica l Attention Networks for Docume nt\nClassifica tion 2016 jun; San Diego, California: Assoc iation for Computationa l Linguisti cs.\n50. Maaten Lvd. Learning a Parame tric Embedding by Preserving Local Structure. In: David van D, Max W,\neditors. Procee dings of the Twelth Interna tional Conferen ce on Artificial Intellige nce and Statistics; Pro-\nceeding s of Machine Learning Research: PMLR; 2009. p. 384–91.\nPLOS ONE\nLanguage modellin g in Chest X-Ray reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02299 63 March 10, 2020 16 / 16",
  "topic": "Triage",
  "concepts": [
    {
      "name": "Triage",
      "score": 0.7719348669052124
    },
    {
      "name": "Computer science",
      "score": 0.6263969540596008
    },
    {
      "name": "Artificial intelligence",
      "score": 0.624378502368927
    },
    {
      "name": "Artificial neural network",
      "score": 0.4986996650695801
    },
    {
      "name": "Modality (human–computer interaction)",
      "score": 0.49414733052253723
    },
    {
      "name": "Bottleneck",
      "score": 0.49270394444465637
    },
    {
      "name": "F1 score",
      "score": 0.4836210310459137
    },
    {
      "name": "Radiography",
      "score": 0.469659686088562
    },
    {
      "name": "Convolutional neural network",
      "score": 0.46497488021850586
    },
    {
      "name": "Radiological weapon",
      "score": 0.45179131627082825
    },
    {
      "name": "Machine learning",
      "score": 0.40922126173973083
    },
    {
      "name": "Natural language processing",
      "score": 0.397222101688385
    },
    {
      "name": "Medical physics",
      "score": 0.3549794554710388
    },
    {
      "name": "Radiology",
      "score": 0.3358597159385681
    },
    {
      "name": "Medicine",
      "score": 0.30939406156539917
    },
    {
      "name": "Emergency medicine",
      "score": 0.0
    },
    {
      "name": "Embedded system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210158502",
      "name": "Queen Elizabeth University Hospital",
      "country": "GB"
    }
  ]
}