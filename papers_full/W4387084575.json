{
  "title": "Use Large Language Models for Named Entity Disambiguation in Academic Knowledge Graphs",
  "url": "https://openalex.org/W4387084575",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2102098616",
      "name": "Shaojun Liu",
      "affiliations": [
        "Institute of Scientific and Technical Information",
        "Jiangsu Provincial Key Laboratory of Network and Information Security"
      ]
    },
    {
      "id": "https://openalex.org/A2171654970",
      "name": "Yanfeng Fang",
      "affiliations": [
        "Jiangsu Provincial Key Laboratory of Network and Information Security",
        "Institute of Scientific and Technical Information"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2127289991",
    "https://openalex.org/W4323927248",
    "https://openalex.org/W4380993239",
    "https://openalex.org/W4375869973",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W2120699290",
    "https://openalex.org/W3169484023"
  ],
  "abstract": "This study investigates the application of large language models (LLMs) in disambiguating homonymous named entities in academic knowledge graphs.Current state-of-the-art methods rely on supervised learning techniques that often necessitate extensive annotated datasets, which may be scarce in specialized domains.For further exploration, we constructed an academic knowledge graph in the science and technology domain using publicly available data and extracted contrasting homonymous named entities from different projects to create a test dataset.We evaluated the performance of the ChatGPT model on this dataset using zero-shot, in-context, and chain-of-thought prompting strategies.The experimental results reveal that while LLMs achieve limited success in a zero-shot setting, chain-of-thought prompting can enhance their reasoning abilities.However, a performance gap persists when compared to supervised learning methods specifically trained on the dataset.These findings suggest that LLMs, such as ChatGPT, present a promising direction for assisting in knowledge graph construction for named entity disambiguation, particularly when labeled data is scarce.The utilization of LLMs could be especially beneficial for domains lacking extensive annotated datasets, offering a competitive alternative for disambiguating homonymous named entities.",
  "full_text": "Use Large Language Models for Named Entity \nDisambiguation in Academic Knowledge Graphs \nShaojun Liu1,2*, Yanfeng Fang1,2 \n1Fujian Institute of Scientific and Technological Information, Fuzhou, 350001, China \n2Fujian Provincial Key Laboratory of Information and Network, Fuzhou, 350001, China  \nCorresponding author. Email: liusj@fjinfo.org.cn; \nafang@fjinfo.org.cn \nAbstract. This study investigates the application of large language models \n(LLMs) in disambiguating homonymous named entities in academic knowledge \ngraphs. Current state-of-the-art methods rely on supervised learning techniques \nthat often necessitate extensive annotated datasets, which may be scarce in spe-\ncialized domains. For further exploration , we constructed an academic \nknowledge graph in the science and technology domain using publicly available \ndata and extracted contrasting homonymous named entities from different pro-\njects to create a test dataset. We evaluated the performance of the ChatGPT \nmodel on this dataset using zero -shot, in-context, and chain-of-thought prompt-\ning strategies. The experimental results reveal that while LLMs achieve limited \nsuccess in a zero -shot setting, chain -of-thought prompting can enhance their \nreasoning abilities. However, a performance gap persists when compared to su-\npervised learning methods specifically trained on the dataset. These findings \nsuggest that LLMs, such as ChatGPT, present a promising direction for assist-\ning in knowledge graph construction for named entity disambiguation, particu-\nlarly when labeled data is sc arce. The utilization of LLMs could be especially \nbeneficial for domains lacking extensive annotated datasets, offering a competi-\ntive alternative for disambiguating homonymous named entities. \nKeywords: Large language models; Named entity disambiguation; Academic \nknowledge graphs; ChatGPT; Chain-of-thought \n1 Introduction  \nDisambiguating named entities with the same name is a critical challenge in con-\nstructing and organizing knowledge graphs, particularly in the domain of academic \nknowledge graphs. Named entities, such as companies, organizations, and individuals, \noften share common names, leading to ambiguity when distinguishing between dis-\ntinct entities within a knowledge graph [1]. This issue is especially prevalent in aca-\ndemic knowledge graphs, where multip le researchers, institutions, or publications \nmay bear the same name but represent distinct entities. Accurate disambiguation is \n© The Author(s) 2024\nG. Guan et al. (eds.), Proceedings of the 2023 3rd International Conference on Education, Information\nManagement and Service Science (EIMSS 2023), Atlantis Highlights in Computer Sciences 16,\nhttps://doi.org/10.2991/978-94-6463-264-4_79\n\ncrucial for ensuring the reliability of information retrieval, data integration, and net-\nwork analysis in various applications [2]. \nCurrent state -of-the-art methods for disambiguating named entities primarily in-\nvolve measuring the similarity between entity nodes to distinguish them. These ap-\nproaches often rely on supervised learning techniques using neural networks to model \nsimilarity. For example, Basile et al. proposed a deep recurrent network approach to \nresolve company name ambiguity by employing a Siamese Long Short-Term Memory \n(LSTM) network. This method extracts embeddings of company name strings in a \nrelatively low -dimensional vector space through supervised learning. These embed-\ndings can then be utilized to identify pairs of company names that represent the same \nentity [3]. Despite advancements in current methods for disambiguating named enti-\nties, the complexity of real -world heterogeneous data often results in performance \nlimitations. Consequently, researchers have proposed leveraging human intelligence \nto enhance the disambiguation process. For instance, Ferreira et al. introduced \n\"AuthCrowd,\" a crowdsourcing system designe d to tackle author name disambigua-\ntion and entity matching by decomposing tasks for crowd workers. Experimental \nresults on a real-world dataset of publicly available papers published in peer-reviewed \nvenues demonstrate the potential of this approach to improve author name disambigu-\nation [4]. \nGiven the recent success of large -scale Language Models (LLMs), which have \ndemonstrated human-like capabilities in various tasks [5], their potential application \nin constructing knowledge graphs has generated significan t interest. LLMs can effi-\nciently perform tasks such as entity recognition, relation extraction, and fact verifica-\ntion, thereby contributing to the automatic generation and enrichment of knowledge \ngraphs [6]. In their roadmap for unifying LLMs and knowledge  graphs, Pan et al. \npropose three general frameworks: KG -enhanced LLMs, LLM -augmented KGs, and \nsynergized LLMs + KGs. These frameworks aim to leverage the strengths of both \nLLMs, like ChatGPT and GPT -4, and structured knowledge models like knowledge \ngraphs, to enhance their capabilities and address their limitations. Recently, Peeters \nand Bizer (2023) investigated the use of ChatGPT for entity matching, demonstrating \nits competitiveness with traditional Transformer models. Their study showed that \nChatGPT achieved a zero-shot performance of 82.35% F1 on a challenging matching \ntask while also benefiting from in -context demonstrations and higher -level matching \nknowledge. These findings suggest that ChatGPT can significantly contribute to the \nefficiency and effectiveness of entity matching in knowledge graph construction [7]. \nGiven the significance of disambiguating homonymous named entities in construct-\ning academic knowledge graphs and the frequent absence of accurate annotation data, \nwe delve into the possibili ties offered by Large Language Models (LLMs) to tackle \nthis issue. Our inquiry focuses on determining if the extensive textual knowledge in-\nherent in LLMs, combined with their contextual understanding and information extrac-\ntion capabilities, can efficiently resolve named entity ambiguity without depending on \ncopious labeled data. \n682             S. Liu and Y. Fang\n2 Dataset Construction and Preprocessing \nIn our study, we aim to construct an academic knowledge graph using publicly avail-\nable research data. The data sources for the graph include r esearch projects and talent \ninformation, with the primary data consisting of research project records. A signifi-\ncant portion of the nodes in the constructed graph exhibit the challenge of homony-\nmous named entity disambiguation, particularly for nodes repre senting researcher \nnames. Each researcher's name in the research projects is accompanied by a unique \nidentifier, allowing us to differentiate between individuals sharing the same name. We \nexploit this data to create a named entity disambiguation dataset to  assess ChatGPT's \nperformance on this specific task. \nThe research project dataset comprises a total of 636,324 projects, involving \n50,997 unique PIs, encompassing 48,386 unique names. Out of these, 40,227 PIs \nshare their names with at least one other PI, a nd the most frequently occurring PI \nname is shared by 262 distinct researchers. \nTo evaluate the disambiguation capability of LLMs, we consider the scenario \nwhere the same name appears in different projects and assess whether it represents the \nsame individual. The number of pairwise comparisons involving the same name ap-\npearing in distinct projects can be calculated using the combination formula, resulting \nin a substantial figure of 17,347,659 total comparisons for all names and projects. In \npractical applic ations, not all pairs require comparison; a project only needs to be \ncompared with a well -matched project from a pool of same -named individuals. To \nassess LLMs' disambiguation ability, we randomly select 10,000 pairwise compari-\nsons from the extensive pool to compose our test dataset. Among these 10,000 com-\nparisons, 9,003 pairs involve the same named participant, while 997 pairs concern \ndifferent individuals sharing the same name. To establish a performance baseline, we \nemploy a supervised learning method, n ecessitating an additional 1,400 pairwise \ncomparisons for training purposes. The data samples are presented in Table 1, while \nthe data distribution can be observed in Table 2. \nTable 1. Sample of Named Entity Disambiguation Dataset for Research Projects \nName excuOrganName \nplan\nYear \n… Research \nAttribute \nresearch-\nField \nre-\nsearch-\nType \nplanA\nmt \nisSame-\nPerson \nGuo \nBoche\nng \nInstitute of Mate-\nrials Science and \nEngineering \n2003 … Applied \nresearch \nMaterial \ntechnology \nAcadem-\nic grant \n1,422,\n000 \n1 Institute of Mate-\nrials Science and \nEngineering \n2002 … Applied \nresearch \nMaterial \ntechnology \nAcadem-\nic grant \n1,048,\n000 \nChen \nZhife\nng \nDepartment of \nAnimal Science, \nNational Chung \nHsing University \n2018 … Basic \nresearch \nAnimal \nhusbandry \nand veteri-\nnary medi-\ncine \nCoop-\nerative \nresearch \n900,00\n0 \n0 \nDepartment of \nChinese Litera-\nture, Shixin \nUniversity \n2019 … Basic \nresearch \nChinese Academ-\nic subsi-\ndy \n517,00\n0 \nUse Large Language Models for Named Entity Disambiguation              683\nTable 2. Distribution of Named Entity Disambiguation Dataset for Research Projects \nDataset Type # Pairs # Pos # Neg \ntest 10000 9003 997 \ntraining 1400 1262 138 \n3 Methodology \nThe previously constructed dataset consists of rows containing various pieces of in-\nformation about each research project. As ChatGPT and similar language models \nprimarily operate on textual data, it is essential to transform the tabular data into a \nhuman-readable format. For example, the column name 'excuOrganName' is adapted \nto 'Executing Organization Name,' and 'researchField' is converted to 'Research Field.' \nWe concatenate the column names and values using the term 'is,' and separate indi-\nvidual columns within the same row with commas. An example of a transformed row \nappears as follows:   \"Executing Organization Name is Department of Information \nEngineering, University of Science and Technology, Plan English Name is The Study \nand Implementation of Agent -Based Hybrid Cloud Environment with QoS Dynamic \nResource Allocation, Plan Year is 2010, Plan Start Date is February 1, 2010, Plan End \nDate is March 1, 2011, Plan Chinese Name is Implementation and Research of Agent-\nBased Dynamic Resource Allocation with QoS on Hybrid Cloud, Research Category \nis Technology Development, Research Field is Information Engineering -- Hardware \nEngineering, Research Type is Academic Grant, Pl an Title is Implementation and \nResearch of Agent-Based Dynamic Resource Allocation with QoS on Hybrid Cloud, \nPlan Amount is 663,000.\" \nAfter transposing the projects into text, we submit the paired projects to the \nChatGPT API for evaluation. The results are  predominantly contingent upon the con-\nstructed prompt; consequently, we design a fundamental base prompt and incorporate \nIn-Context Learning and Chain -of-thoughts for testing purposes. During the prompt \ntesting phase, we observe that ChatGPT's results are highly susceptible to the influ-\nence of non -essential columns. As a result, we derive the most influential column \nrankings from the supervised learning baseline method and transmute the top three \nmost pertinent columns into text for submission to ChatGPT as a comparison. \nIn the subsequent subsections, we expound on the specifics of the Supervised \nLearning Method, Base Prompt, In-Context Learning, Chain-of-thoughts, and Column \nSelection approaches. \n3.1 Supervised Learning Method \nThe current state-of-the-art approaches for named entity disambiguation predominant-\nly involve supervised learning methods that utilize neural network -based encodings. \nIn the present study, we employ the Luotuo Embedding method as our encoding tech-\nnique[8]. This generative text embedding mo del is distilled from the OpenAI API, \noffering a unique and powerful approach to capturing semantic information in textual \n684             S. Liu and Y. Fang\ndata. This model is meticulously trained by employing a combination of three distinct \nloss functions: (1) a distillation loss that ha rmonizes the model's embedding with that \nof OpenAI's, (2) a KL divergence loss that fosters coherence between the embeddings \nof interconnected textual data, and (3) a margin loss that mitigates the risk of the \nmodel mastering an excessively simplistic task . Experimental evidence demonstrates \nthat their model achieves performance metrics that are on par with OpenAI's state -of-\nthe-art embedding model  text-embedding-ada-002, across a diverse range of down-\nstream applications including text visualization, search , and dialogue. After outlining \nthe Luotuo Embedding method as our primary encoding technique, we employed two \ndistinct approaches for encoding the data. The first approach, akin to ChatGPT, in-\nvolved converting the entire row of data into a single text seg ment for encoding. The \nsecond approach, on the other hand, focused on encoding each column of data indi-\nvidually. This latter method proved to be more effective in extracting the distinct \ninfluences of different columns on the results within the labeled datasets. \nUpon vectorizing the data using these two encoding approaches, we proceeded to \ntrain a Random Forest model on the training set and evaluated its performance on the \ntest set. The purpose of this step was to compare the results obtained from the Random \nForest model with those achieved using ChatGPT. This comparison allowed us to as-\nsess the effectiveness and validity of our chosen encoding techniques in the context of \nnamed entity disambiguation tasks. \n3.2 Base Prompt \nPrompt engineering is a crucial aspect of fine-tuning large-scale language models for \nspecific tasks. It involves designing effective input queries or statements that enable \nthe model to generate desired outputs[9]. Crafting well-structured prompts can signif-\nicantly improve the performance of m odels like GPT -3, allowing them to produce \nmore accurate and coherent responses. The c areful consideration of the phrasing, \ncontext, and format of the prompt can greatly influence the model's understanding and \nresponse generation, leading to better task performance. \nIn our task, we encountered several challenges due to the limited information pro-\nvided to the large language model (LLM), which needed to return a definitive result. \nWhen directly providing project information and asking for a judgment, the LLM \nmight indicate that more information is needed before making a decision. In cases \nwhere a clear result is required, the LLM is more likely to return an \"uncertain\" re-\nsponse. Moreover, considering that the test set consists of 10,000 records, employing \nmanual evaluation would be too labor-intensive. \nTo address these issues, we explicitly requested the LLM to assess probabilities in \nthe prompt, and then returned results based on the assessed probabilities. If the proba-\nbility fell within the categories of \"Ver y likely,\" \"Highly probable,\" \"Likely,\" \"Proba-\nble,\" or \"Possible,\" we returned a value of 1. If the probability was categorized as \n\"Unlikely,\" \"Improbable,\" \"Highly improbable,\" \"Very unlikely,\" or \"Impossible,\" we \nreturned a value of 0.  The system content  was phrased as follows: 'As a scientist, I \nneed your expert opinion on two projects and a specific individual involved in them.  ' \nUse Large Language Models for Named Entity Disambiguation              685\nThe user content was formulated as: 'Given the following information about two re-\nsearch plans: \n{delimiter} \n**Plan 1:** {str(porject1)} \n**Plan 2:** {str(project2)} \n{delimiter} \nBased on the provided information, can we conclude that the person named \n{name} in both plans is the same individual, or are they two different people with the \nsame name? please consider the possibility of in both plans is the same individual, \nRespond with 1 or 0:   \n    0 - If the possibility is \"Unlikely\" or \"Improbable\" or \"Highly improbable\" or \n\"Very unlikely\"  or \"Impossible\". \n    1 - If the possibility is \"Very likely\" or \"Highly probable\" or \"Likely\" or \"Proba-\nble\" or \"Possible\". \nOutput a single character.' \nUsing the aforementioned prompt structure, we were able to ensure that the LLM \nconsistently generated output in the form of either 1 or 0 as the final result. This de-\nsign effectively streamlined the r esponse generation process, enabling the model to \nproduce clear and definitive answers based on the assessed probabilities.  \n3.3 In-Context Learning \nIn-Context Learning is an essential technique employed by large-scale language mod-\nels to adapt their understand ing and responses to the given context. This learning \nparadigm allows models, such as GPT -3, to leverage the contextual information em-\nbedded in a sequence of tokens and make accurate predictions based on the surround-\ning text [5]. In -Context Learning plays a  vital role in enhancing the performance of \nlanguage models for various tasks, including question -answering, sentiment analysis, \nand summarization, by providing them with the necessary context for generating more \ncoherent and contextually relevant responses.  \nIn our task, we provide judgment examples in the prompt. However, due to the \nmaximum token length of GPT -3.5 being 4097 and the average token count of our \nproject information being around 400, we cannot provide too many examples. There-\nfore, we have ran domly selected two positive examples and two negative examples \nfrom our training set to serve as prompts. The format is to add the following before \nthe user content: \n'For example： \n{Two plan information as in Base Prompt} \n**Result:**The names of the persons in charge of the two plans are both ***, they \nare the same person.     \n{Two plan information as in Base Prompt} \n**Result:**The names of the persons in charge of the two plans ar e both ***, but \nthey are different people . ' \n686             S. Liu and Y. Fang\n3.4 Chain-of-thought \nIn recent research, Wei et al. proposed an innovative method called Chain-of-Thought \nPrompting to enhance the reasoning capabilities of large language models. This ap-\nproach revolves around gene rating a chain of thought, which consists of intermediate \nnatural language reasoning steps that ultimately lead to the final output. By incorpo-\nrating a few chain of thought demonstrations as exemplars in the prompting process, \nthe authors demonstrated that  this technique significantly improves the performance \nof language models on various arithmetic, commonsense, and symbolic reasoning \ntasks. Notably, Chain -of-Thought Prompting outperforms standard prompting meth-\nods and achieves state -of-the-art accuracy on  benchmarks such as the GSM8K math \nword problems. This method offers a promising avenue for unlocking the full poten-\ntial of large language models in reasoning tasks, while also providing an interpretable \nwindow into their behavior[10]. \nIn our task, conside ring that we do not have a precise understanding of the impact \nof each column on the results, we aim to avoid potential biases from flawed thought \nprocesses. To achieve this, we simply add a sentence after the question: \"Let's do it \nstep by step.\" Experime ntal results reveal that adding this sentence may lead to more \nconcise reasoning steps when we only require the final response to be 1 or 0. Conse-\nquently, we have removed the requirement for a specific response format from the \nprompt and shifted to using multi-turn dialogues. After receiving the reasoning result, \nwe request ChatGPT to summarize the outcome as 1 or 0, akin to the basic prompt. \nAlthough this approach significantly increases token consumption, empirical evidence \nindicates that it effectively utilizes the Chain-of-Thought reasoning process. \n3.5 Column Selection \nConsidering that when only returning 1 and 0 as results, it is evident that ChatGPT \ncan be easily influenced by variations in columns that have minimal impact on the \nactual outcome. Without t he effect of the Chain -of-Thought, the model may lack the \ncomplex reasoning ability to accurately distinguish between the effects of important \ncolumns and those of less significant ones. Therefore, we decided to leverage the \nresults of supervised learning to obtain the importance ranking of the columns and \nthen experiment with providing only the important columns to ChatGPT. \nWe used code to visualize the feature importances of a trained Random Forest \nclassifier. The process involved extracting the feature i mportances from the classifier \nand sorting them in descending order. This visualization is useful for understanding \nthe relative importance of each feature in the model, which can aid in feature selection \nand model interpretation in the context of the rese arch. The results are shown in Fig . \n1. It is clear that the impact of the first four columns is far greater than that of the \nsubsequent columns. Considering that the influence of 'Plan Chinese Name' and 'Plan \nEnglish Name' might overlap, we selected 'Execu ting Organization Name', 'Plan Chi-\nnese Name', and 'Research Field' as the columns. We then conducted experiments \nusing the Base Prompt, In -Context Learning, and C hain-of-Thought approaches, fo l-\nlowing the methods previously described. \nUse Large Language Models for Named Entity Disambiguation              687\n \nFig. 1. Feature Importance Ranking \n4 Experimental Results \nWe conducted experiments using OpenAI's gpt -3.5-turbo-0613 model, setting the \ntemperature parameter to 0 to obtain deterministic responses. The API rate limits for \nRPM were 3,500 and TPM w ere 90,000. During the experiment, the RPM limit was \nnot reached, but the TPM limit was occasionally hit. The call duration was affected by \nthe number of tokens, with Base Prompt and In -Context Learning experiments com-\npleted within a day, while Chain -of-Thought experiments required more than three \ndays due to longer responses and two -turn dialogues. We will now discuss the exper-\nimental results and subsequent analysis. \n4.1 Results \nThe disambiguation problem of named entities with the same name differs slightly \nfrom other issues like entity matching, as it requires considering not only the preci-\nsion of positive examples but also that of negative ones. We used macro precision, \nmacro recall, and macro F1 to evaluate the performance of the methods, along with \nthe ave rage cost of calling the API. Costs were calculated based on the number of \ntokens: input pricing was $0.0015 per 1K tokens, and output pricing was $0.002 per \n1K tokens. The results are shown in Table 3. \n \n \n688             S. Liu and Y. Fang\nTable 3. Experimental results and associated costs \nMethod \nResults \nMacro \nP \nMacro \nR \nMacro \nF1 ΔF1 \nCost(¢) \nPer \npair \nCost \nIncrease \ncost \nincrease \nper ΔF1 \nChatGPT-zeroshot 54.91 62.87 52.59 - 0.13 - - \nChatGPT-in-content 56.28 67.45 53.15 0.56 0.51 304% 542% \nChatGPT-think-chain 66.35 82.36 69.84 17.25 0.33 163% 9.46% \nSelect-zeroshot 85.23 58.75 62.53 9.94 0.06 -54% -5.52% \nSelect- in-content 64.06 79.18 66.79 14.20 0.22 73% 5.14% \nSelect- think-chain 65.41 76.81 68.52 15.94 0.21 68% 4.28% \nEmbeddings-rf 69.12 68.44 68.77 16.18 - - - \nMulti-embeddings-rf 87.49 79.90 83.16 30.57 - - - \n \n4.2 Discussion \nFrom the experimental results, it can be seen that the performance of ChatGPT using \nzero-shot and requiring direct return of results is very limited, clearly affected by the \ninterference of columns with little impact on the results. Even when using In -Context \nLearning to increase example prompts, the performance only shows a slight im-\nprovement. The significant performance improvement after using only important \ncolumns indicates that providin g a large amount of information in the case of direct \nreturn does not help the model make more accurate judgments. \nA substantial performance improvement was observed when using the Chain -of-\nThought approach, suggesting that tasks requiring reasoning abilit ies indeed achieve \nbetter results with this method. Comparing the supervised learning results of random \nforests after row vectorization, the performance of the Chain -of-Thought approach is \nslightly better, indicating that it can indeed make accurate judgme nts based on textual \ninformation. However, there is still a gap compared to the performance of supervised \nlearning using random forests with column vectorization. This difference may arise \nfrom various factors, including the data's inherent characteristics , the model's lan-\nguage understanding, and its ability to reason about specific domain knowledge.  In \nthe case of the data itself, the impact of each label on the result is specific and may \nexhibit complex relationships. For example, when using logistic regr ession for super-\nvised learning, specific weights can be learned for each label, which heavily depend \non the dataset's characteristics. This nuanced understanding of the data is challenging \nfor ChatGPT to capture, as it is trained on general -purpose corpora  and might not \nhave exposure to the specific domain or dataset. \nFurthermore, while ChatGPT has shown remarkable performance in various natu-\nral language understanding tasks, its reasoning capabilities in specialized domains \nmight still be limited compared t o supervised learning models explicitly trained on \nthose domains. Despite this, considering the relatively low cost of each comparison \nusing the Chain -of-Thought approach, it remains a competitive alternative in situa-\ntions where labeled data is scarce. \nUse Large Language Models for Named Entity Disambiguation              689\n5 Conclusion \nIn this study, we explored the potential of leveraging large language models (LLMs) \nto disambiguate homonymous named entities in academic knowledge graphs. The \nexperimental results demonstrate that while models like ChatGPT show promise in \nthis task, their performance is still limited compared to supervised learning methods. \nThe Chain-of-Thought prompting approach was shown to improve ChatGPT's reason-\ning abilities, allowing it to surpass supervised learning methods that use entire lines of \ntext. However, there still exists a performance gap compared to models trained specif-\nically on the dataset using structured data. The main factors contributing to this per-\nformance gap include:  \n(1) The data's inherent complexity and specific characteristics which a re difficult \nfor general-purpose LLMs to capture.  \n(2) The LLMs' limited understanding of the domain and exposure to similar data.  \n(3) The LLMs' relatively restricted reasoning capabilities in specialized domains \ncompared to models explicitly trained on those domains. \nOverall, while LLMs exhibit some success in tasks requiring zero -shot or few-shot \nlearning, their performance is still constrained for complex reasoning problems that \nbenefit from explicit training on nuanced data. Further research into enhancing LLMs' \ndomain-specific knowledge and training them jointly with specialized knowledge \ngraphs may help bridge the current performance gap. Nevertheless, LLMs represent a \npromising direction for assisting in knowledge graph construction, particularly for  \ntasks requiring common-sense or textual reasoning, or in situations where labeled data \nis scarce, making them a competitive choice.  \nAcknowledgment  \nThis work was supported by the Fujian Provincial Department of Science and Tech-\nnology's External Cooperation Project (Grant No. 2022I0025). \nReferences \n1. Navigli, R., and Ponzetto, S. P. (2012) BabelNet: The automatic construction, evaluation \nand application of a wide -coverage multilingual semantic network. Artificial Intelligence, \n193: 217-250. \n2. Moro, A., Raganat o, A., and Navigli, R. (2014). Entity linking meets word sense disam-\nbiguation: A unified approach. Transactions of the Association for Computational Linguis-\ntics, 2: 231-244. \n3. Basile, A., Crupi, R., Grasso, M., Mercanti, A., Regoli, D., Scarsi, S., Yang, S.,  and Co-\nsentini, A. (2023). Disambiguation of Company names via Deep Recurrent Networks. \narXiv preprint arXiv:2303.05391. [https://doi.org/10.48550/arXiv.2303.05391] \n4. Correia A, Guimarães D, Paulino D, et al. Authcrowd: Author name disambiguation and \nentity matching using crowdsourcing[C]//2021 IEEE 24th International Conference on \nComputer Supported Cooperative Work in Design (CSCWD). IEEE, 2021: 150-155. \n690             S. Liu and Y. Fang\n5. Brown T, Mann B, Ryder N, et al. Language models are few -shot learners[J]. Advances in \nneural information processing systems, 2020, 33: 1877-1901. \n6. Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., and Wu, X. (2023). Unifying Large Lan-\nguage Models and Knowledge Graphs: A Roadmap. arXiv preprint arXiv:2306.08302v2. \n[https://doi.org/10.48550/arXiv.2306.08302] \n7. Peeters, R., and Bizer, C. (2023). Using ChatGPT for Entity Matching. Proceedings of \nADBIS 2023. arXiv preprint arXiv:2305.03423v2.  \n[https://doi.org/10.48550/arXiv.2305.03423] \n8. Liu, S., Leng, Z., Huang, H., Chen, S., Hu, J., Sun, A., Chen, Q., and Li, C. (2023). Luotuo \nEmbedding: Generative Text Embedding Model distilled from OpenAI API. GitHub re-\npository. Retrieved from https://github.com/LC1332/Luotuo-Text-Embedding \n9. Radford, A., Narasimhan, K., Salimans, T., Sutskever, I. (2021). Improving Language Un-\nderstanding by Generative Pre-Training. OpenAI.  \nhttps://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-\nunsupervised/language_understanding_paper.pdf \n10. Wei J, Wang X, Schuurmans D, et al. Chain -of-thought prompting elicits reasoning in \nlarge language models[J]. Advances in Neural Information Processing Systems, 2022, 35: \n24824-24837. \nOpen Access  This chapter is licensed under the terms of the Creative Commons Attribution-\nNonCommercial 4.0 International License ( http://creativecommons.org/licenses/by-nc/4.0/ ),\nwhich permits any noncommercial use, sharing, adaptation, distribution and reproduction in any\nmedium or format, as long as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons license and indicate if changes were made.\n        The images or other third party material in this chapter are included in the chapter's\nCreative Commons license, unless indicated otherwise in a credit line to the material. If material\nis not included in the chapter's Creative Commons license and your intended use is not\npermitted by statutory regulation or exceeds the permitted use, you will need to obtain\npermission directly from the copyright holder.\nUse Large Language Models for Named Entity Disambiguation              691",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7106110453605652
    },
    {
      "name": "Natural language processing",
      "score": 0.6673814058303833
    },
    {
      "name": "Entity linking",
      "score": 0.6588347554206848
    },
    {
      "name": "Knowledge graph",
      "score": 0.627475380897522
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5278477668762207
    },
    {
      "name": "Linguistics",
      "score": 0.4271780550479889
    },
    {
      "name": "Knowledge base",
      "score": 0.08765923976898193
    },
    {
      "name": "Philosophy",
      "score": 0.07010683417320251
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210101880",
      "name": "Institute of Scientific and Technical Information",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210142126",
      "name": "Jiangsu Provincial Key Laboratory of Network and Information Security",
      "country": "CN"
    }
  ],
  "cited_by": 5
}