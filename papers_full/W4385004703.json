{
  "title": "\"It Felt Like Having a Second Mind\": Investigating Human-AI Co-creativity in Prewriting with Large Language Models",
  "url": "https://openalex.org/W4385004703",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2157852039",
      "name": "Wan Qian",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4365681761",
      "name": "Hu, Siying",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102355683",
      "name": "Zhang Yu",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Wang, Piaohong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098082197",
      "name": "Wen Bo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4221630293",
      "name": "Lu, Zhicong",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W145927622",
    "https://openalex.org/W4224940987",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W4293567606",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W2918341242",
    "https://openalex.org/W4213435830",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W4394748224",
    "https://openalex.org/W3161188800",
    "https://openalex.org/W2888081003",
    "https://openalex.org/W2903313692",
    "https://openalex.org/W2333722819",
    "https://openalex.org/W3031000691",
    "https://openalex.org/W2792969545",
    "https://openalex.org/W1615506555",
    "https://openalex.org/W2972072326",
    "https://openalex.org/W4247758476",
    "https://openalex.org/W2047171242",
    "https://openalex.org/W1979625382",
    "https://openalex.org/W2059216172",
    "https://openalex.org/W3155340931",
    "https://openalex.org/W2916904544",
    "https://openalex.org/W3196731672",
    "https://openalex.org/W4225012671",
    "https://openalex.org/W3115337388",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W4285281355",
    "https://openalex.org/W3104847483",
    "https://openalex.org/W4283783607",
    "https://openalex.org/W3032125649",
    "https://openalex.org/W4297630849",
    "https://openalex.org/W2147781035",
    "https://openalex.org/W2730111376",
    "https://openalex.org/W4286910674",
    "https://openalex.org/W4230381966",
    "https://openalex.org/W2973049411",
    "https://openalex.org/W4303648559",
    "https://openalex.org/W2042659035",
    "https://openalex.org/W3136035550",
    "https://openalex.org/W3161926791",
    "https://openalex.org/W3131976765",
    "https://openalex.org/W1771080006",
    "https://openalex.org/W4292760860",
    "https://openalex.org/W2262682754",
    "https://openalex.org/W3027475104",
    "https://openalex.org/W4235278727",
    "https://openalex.org/W4308244910",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3098267758",
    "https://openalex.org/W4221055872",
    "https://openalex.org/W4308900200",
    "https://openalex.org/W2911664431",
    "https://openalex.org/W4225100122",
    "https://openalex.org/W4287207937",
    "https://openalex.org/W4220962633",
    "https://openalex.org/W4402478963",
    "https://openalex.org/W4213451626",
    "https://openalex.org/W2974071289",
    "https://openalex.org/W3132570160",
    "https://openalex.org/W3146248196",
    "https://openalex.org/W2979392537",
    "https://openalex.org/W4225080353",
    "https://openalex.org/W3188546948",
    "https://openalex.org/W2729410860",
    "https://openalex.org/W3032828722",
    "https://openalex.org/W3154248444",
    "https://openalex.org/W4224047978"
  ],
  "abstract": "Prewriting is the process of discovering and developing ideas before a first draft, which requires divergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc. Although large language models (LLMs) have been demonstrated to be useful for a variety of tasks including creative writing, little is known about how users would collaborate with LLMs to support prewriting. The preferred collaborative role and initiative of LLMs during such a creativity process is also unclear. To investigate human-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative study with 15 participants in two creative tasks: story writing and slogan writing. The findings indicated that during collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process that includes Ideation, Illumination, and Implementation stages. This collaborative process champions the human in a dominant role, in addition to mixed and shifting levels of initiative that exist between humans and LLMs. This research also reports on collaboration breakdowns that occur during this process, user perceptions of using existing LLMs during Human-AI Co-creativity, and discusses design implications to support this co-creativity process.",
  "full_text": "“It Felt Like Having a Second Mind”: Investigating Human-AI\nCo-creativity in Prewriting with Large Language Models\nQIAN WAN,City University of Hong Kong, China\nSIYING HU, City University of Hong Kong, China\nYU ZHANG, City University of Hong Kong, China\nPIAOHONG WANG,City University of Hong Kong, China\nBO WEN, University of Macau, China\nZHICONG LU, City University of Hong Kong, China\nPrewriting is the process of discovering and developing ideas before writing a first draft, which requires\ndivergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc.\nAlthough large language models (LLMs) have been demonstrated to be useful for a variety of tasks including\ncreative writing, little is known about how users would collaborate with LLMs to support prewriting. The\npreferred collaborative role and initiative of LLMs during such a creative process is also unclear. To investigate\nhuman-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative\nstudy with 15 participants in two creative tasks: story writing and slogan writing. The findings indicated that\nduring collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process\nthat includes Ideation, Illumination, and Implementation stages. This collaborative process champions the\nhuman in a dominant role, in addition to mixed and shifting levels of initiative that exist between humans and\nLLMs. This research also reports on collaboration breakdowns that occur during this process, user perceptions\nof using existing LLMs during Human-AI Co-creativity , and discusses design implications to support this\nco-creativity process.\nCCS Concepts: • Human-centered computing →Empirical studies in HCI .\nAdditional Key Words and Phrases: human-AI collaboration, creativity support, prewriting, creative writing,\nlarge language models\nACM Reference Format:\nQian Wan, Siying Hu, Yu Zhang, Piaohong Wang, Bo Wen, and Zhicong Lu. 2024. “It Felt Like Having a\nSecond Mind”: Investigating Human-AI Co-creativity in Prewriting with Large Language Models. Proc. ACM\nHum.-Comput. Interact. 8, CSCW1, Article 84 (April 2024), 26 pages. https://doi.org/10.1145/3637361\n1 INTRODUCTION\nLarge language models (LLMs) are machine learning-based language models that are pre-trained on\nlarge amounts of data [8]. Recent models such as GPT-3 have been shown to exhibit high levels of\naccuracy and performance for tasks [7] such as translation [8], question asking [51], story writing\n[13, 70], and programming [76]. They have also opened up the potential for human-AI collaboration\nAuthors’ addresses: Qian Wan, City University of Hong Kong, Hong Kong, China, qianwan3-c@my.cityu.edu.hk; Siying\nHu, City University of Hong Kong, Hong Kong, China, siyinghu-c@my.cityu.edu.hk; Yu Zhang, City University of Hong\nKong, Hong Kong, China, yui.zhang@my.cityu.edu.hk; Piaohong Wang, City University of Hong Kong, Hong Kong, China,\npiaohwang2-c@my.cityu.edu.hk; Bo Wen, University of Macau, Macau, China, bowen@um.edu.mo; Zhicong Lu, City\nUniversity of Hong Kong, Hong Kong, China, zhicong.lu@cityu.edu.hk.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the\nfull citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored.\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\nprior specific permission and/or a fee. Request permissions from permissions@acm.org.\n© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM 2573-0142/2024/4-ART84\nhttps://doi.org/10.1145/3637361\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\narXiv:2307.10811v3  [cs.HC]  29 Feb 2024\n84:2 Qian Wan et al.\n[7], as such models can quickly adapt to user-specified tasks that are created using only natural\nlanguage descriptions or prompts.\nPrior research has already shed light on the strategies and challenges that exist when collaborating\nwith LLMs in real-life writing scenarios [67, 69, 78]. In particular, the potential to use LLMs for\ncreativity support has become a focus in the academic literature [13] and among online communities\nsuch as Reddit, where there has been an increasing number of users that have collaborated with\nLLMs to write poets, stories, and even books (e.g., on r/OpenAI 1, r/GPT3 2, r/WritingWithAI 3,\netc.). Compared to other writing tasks, creative writing requires divergent thinking [59, 62], which\ninvolves the creative generation of multiple answers to a set problem. Existing literature often\napproaches creative writing in convergent thinking tasks or phases with the goal of reaching a final\nor at least decent draft [67, 70, 77, 78], leaving earlier divergent thinking phases such as prewriting\nunder-explored. As a result, this field lacks nuanced insights into key stages of the creativity process\n[27, 68, 72] from a human-AI collaboration perspective [73].\nIn prewriting that entails divergent thinking, originality is as equally important as effectiveness\n[27, 60]. In such contexts, goals and expectations of human-AI collaboration might differ from\nconvergent thinking phases or tasks. For example, during the pre-writing phase of a science fiction\nstory, writers often begin by generating and organising ideas, asking LLMs to ideate as many\nnovel plots as possible. To this end, the suggestions generated by LLMs might have to be original\nand diverse in the first place, other than being coherent, plausible, structured, or logically-sound.\nFurthermore, prewriting is known to be iterative and unstructured [58]. To prewrite with an LLM,\none should expect to organise their vague and unstructured thoughts into prompts iteratively,\nwhich presents unique collaboration challenges. It remains unknown what challenges might arise\nwhen using state-of-the-art LLMs during such process that is iterative and unstructured, and how\nthey in turn affect collaboration patterns for creativity. We formalise these aforementioned gaps as\nthe following research questions:\n•RQ1: During creative tasks, which collaboration processes, workflows, or strategies are\nadopted by users while prewriting with LLMs and what is the LLMs’ role during this collabo-\nration?\n•RQ2: What challenges exist when using existing LLMs to support prewriting and how do\nthese challenges affect collaboration?\nTo address these research questions, we conducted a three-session qualitative study with 15\nparticipants. During the study, participants completed common creative tasks, i.e., story writing and\nslogan writing. The findings uncovered a novel three-stage collaboration process, i.e.,Human-AI Co-\ncreativity, that exists while prewriting with a state-of-the-art LLM (GPT-3). This process was found to\ninclude three distinct stages:Ideation, Illumination, and Implementation. The results also highlighted\nthe dominant role of humans during such collaborations and the mixed and shifting levels of\ninitiative that exist during the Human-AI Co-creativity process. Lastly, the findings highlighted\ncommon collaboration breakdowns and workarounds that were employed while collaborating with\nLLMs and led to several design implications that should be considered during the development of\nfuture LLMs for creativity support.\nOur contributions to the HCI and CSCW community are threefold. First, we provide a nuanced\ndescription of the Human-AI Co-creativity process, situated in the context of prewriting with LLMs\n(GPT-3) in two creative tasks. Second, we summarise collaboration breakdowns and workarounds\n1https://www.reddit.com/r/OpenAI/\n2https://www.reddit.com/r/GPT3/\n3https://www.reddit.com/r/WritingWithAI\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:3\nduring this process using the existing LLM. Third, we provide design implications for future work\nto leverage LLMs for creativity support.\n2 RELATED WORK\nThe present research was informed and inspired by prior research on creativity, human-AI collabo-\nration, and writing support tools, especially those using LLMs.\n2.1 Creativity Process Models\nOur study is informed by a long line of psychological models of creativity. In 1929, Wallas presented\none of the first models of the creative process that includes four phases: preparation, incubation,\nillumination, and verification [72]. According to Wallas, creative thoughts began with preparation\nand unconscious processing (i.e., incubation). Creative ideas emerged into conscious awareness\nduring illumination and were ultimately verified, elaborated, and applied during the verification\nstage. The modern-day creativity research is usually considered to have begun with Guilford’s\naddress to the American Psychological Association (APA) in 1950 [68], in which he accentuated\nthe need to engage more profoundly in the study of creativity, and to focus attention on scien-\ntific approaches to conceptualizing creativity, as Guilford argued that creativity could be studied\nobjectively by examining cognitive processes [59].\nAt the intersection of creativity research and HCI, a huge amount of work was dedicated to\nsupporting creativity using computing technologies, notably via the design of Creativity Support\nTools (CSTs) [27]. Early work by Shneiderman proposed a four-phase framework to support the\ndevelopment of user interfaces for creative problem solving, which included phases where one\nCollects ( learn from previous works), Relates (consult with peers and mentors), Creates (explore,\ncompose, discover and evaluate possible solutions), and Donates (disseminate results) [64]. In 2019,\nFrich et al. conducted a systematic review of previous CSTs developed by researchers since 1999.\nThrough a thematic analysis of these academic papers, they identified 6 stages of creativity that\nthose CSTs aimed to support, including pre-ideation, ideation, evaluation, implementation, iteration\nand project management [27].\nTo approach today’s co-creativity process with an LLM, it is necessary to integrate perspectives\nfrom both psychology and creativity support. The former delineates a human’s psychological process\nwithout modelling the interaction with computers and intelligent agents, while the latter focuses on\navailable CSTs without referring to the complete psychological process. To this end, our research\nconceptualizes the Human-AI Co-creativity process. While engaging with Wallas’ model,Human-AI\nCo-creativity focuses on collaboration with an intelligent agent beyond human thinking processes\nalone. Compared to Shneiderman’s and Frich’s models, our model incorporates the Illumination\nstage from Wallas’ model, a stage often overlooked in previous studies of creativity support. We\nrefer our readers to subsection 3.4 for how Human-AI Co-creativity model was developed.\n2.2 Human-AI Collaboration and Co-creativity\nNowadays, it has become commonplace for humans to collaborate with Artificial Intelligence\n(AI) for tasks such as decision-making [ 9, 34, 41, 54], gaming [4, 82], content moderation [ 40],\neducation [52], and data science [74]. According to Wang et al., “collaboration” is more complex\nthan interaction because it involves “mutual goal understanding, preemptive task co-management,\nand shared progress tracking ” [73]. To integrate AI into the complex human workflows, they propose\nto bring a Computer-Supported Cooperative Work (CSCW) perspective. Echoing this call, recent\nyears have seen a growing number of research that approaches AI as a “collaborator” with goals,\ndesignated tasks, and abilities to communicate with humans. For example, Wang et al. found\nthat there was a frequent mismatch between AutoAI’s goal to produce models of high prediction\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:4 Qian Wan et al.\naccuracy and data scientists’ goals to understand relationships in data [74]. To coordinate tasks\nbetween human and AI, Mackeprang et al. proposed a method to find an optimal task allocation\nbased on a levels-of-automation (LoA) framework [50].\nFrom early-day research on human interactions with computers [1, 33, 71], to recent advances\nin human-AI collaboration [ 56], initiative has always been studied as one of the key research\nquestions. The most popular discourse on initiative concerns whether direct manipulation or\nintelligent interface agents should be employed for user interfaces [ 25, 65]. The former grants\nusers control and predictability, while the latter requires the delegation of tasks to agents. Research\nhas also proposed a “mixed-initiative” principle to support interactions between humans and\ncomputers [33, 71]. To support the design of human-AI co-creative systems, Rezwana and Maher\nproposed the Co-Creative Framework for Interaction design (COFI), which categorized human-AI\ncollaboration styles into spontaneous or planned based on the timing of initiative [ 56] . They\nfound that most existing co-creative systems support “planned” instead of “spontaneous” timings,\nsuggesting non-improvisational co-creativity.\nAlong this line of research, recent studies have extensively explored the potential of AI, notably\ngenerative models, for creative tasks such as drawing [19, 20, 42, 53, 79], contemporary art composi-\ntion [11], fashion design [36], musical composition [47], digital mood board creation [38], and so on.\nSeveral works have specifically studied the co-creation experience from a human-AI collaboration\nperspective. For instance, Oh et al. investigated co-creation user experiences during drawing tasks,\nfocusing on communication and initiative [53]. Their findings in controlled experiments revealed\nthat humans always wanted to lead and preferred “just enough instruction ”. In particular, as Natural\nLanguage Processing (NLP) technologies have gained traction, research to support creative writing\nhas become increasingly popular [14, 29, 30, 49, 57, 67, 80, 81]. Clark et. al explored the potential\nof human-AI co-creation during creative writing through two machine-in-the-loop prototypes\n[14], echoing prior work on mixed initiative user interfaces [33]. They found that users generally\nexpected AIs to deviate from existing results during early stages of story writing and criticised AIs\nfor lacking novelty during slogan writing tasks.\nInspired by this prior research, the present exploration provides nuances on how initiative shifts\nbetween users and LLMs and users’ preferred collaborative roles during each key stage of the\nHuman-AI Co-creativity process in two prewriting tasks.\n2.3 Writing Support and Large Language Models\nDating back to 1981, Flower and Hayes modelled writing as three on-linear and hierarchical\ncognitive processes, i.e., planning, translating, and reviewing [26]. Alternatively, Rohman divided\nthe writing process into three iterative phases that included prewriting, writing, and rewriting\n[58]. Without explicitly referencing the creativity literature, Rohman [58] connected the prewriting\nstage to the creativity process by formalising it as “ that activity of mind which brings forth and\ndevelops ideas, plans and designs, not merely the entrance of an idea into one’s mind; an active, not a\npassive enlistment in the ‘cause’ of an idea; conceiving, which includes consecutive logical thinking but\nmuch more besides; essentially the imposition of pattern upon experience. ”.\nIn recent years, with significantly scaled up model sizes, large language models (LLMs) have\nemerged as a promising tool to support a range of writing tasks [ 8, 22, 75], including academic\nwriting [77, 78], story writing [13], etc. One of the most successful LLMs, GPT-3, is able to generate\nhigh-quality natural language text via natural language description of tasks or prompts [16]. To\nleverage LLMs for creative writing, Chung et al. proposed a generative story ideation tool using\nline sketching interactions with an LLM. It supported granular sequence control over the fortune\nof the protagonist in a GPT-generated story, by translating sketches of users to GPT prompts via a\ncontrol module [13].\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:5\nDespite their emergent capabilities, LLMs require careful prompt design [ 78], resulting in a\nbody of literature in NLP dedicated to prompt engineering [6, 46, 48, 55] and automatic prompt\noptimisation [63, 83]. There have also been several efforts in HCI to make LLMs more transparent,\nexplainable, and controllable to support collaboration. For example, Wu et al. introduced the idea of\nchaining LLM steps together, wherein the output of one step became the input of another [77, 78].\nThey created a set of LLM primitive operations and proposed a framework for chaining these\noperations together to produce satisfying results. Sun et al. also investigated the explainability of\nLLMs for code generation using a question-driven approach [43, 44, 69]. They proposed different\ntypes of explainable AI features such as AI documentation to support LLM usage in coding scenarios.\nWithin this body of literature, prewriting was seldom approached as a standalone stage. By\nexact definition, prewriting is a mental activity before “writing ideas are ready for words or on\nthe pages”, implying iterative and often loosely-structured workflows [ 58]. Only a handful of\ntools, such as [49, 61], were framed as prewriting tools that specifically support mental activities\nof idea generation and organisation rather than implementation. Our work enriches empirical\nunderstanding of how users might perceive and leverage an LLM for creative tasks during prewriting,\nthe earliest stage of the writing process. While our study is situated in the context of prewriting, we\ndraw upon creativity models to further dissect the collaborative process. This perspective presents\nnew challenges of modeling uncertainty, as the creativity process entails divergent thinking [59, 62]\nand values originality over quality [27, 60].\n3 METHOD\nTo investigate human-AI collaboration dynamics during prewriting tasks, we conducted a qualitative\nstudy based on Constructivist Grounded Theory [12]. Thus, our findings about the Human-AI Co-\ncreativity process were co-constructed among researchers, participants’ data, and existing theories.\nThe entire study was conducted in Mandarin and was audio and screen recorded.\n3.1 Participants\nPurposive sampling was used to recruit participants. We recruited students of creativity-related\nmajors at our university (e.g., creative media, art & design, literature, etc.) and specifically targeted\nthose with little to none expertise in AI research or engineering as we believed that a layman’s\nusage of LLMs would not be biased by any technical details of the model. This process resulted in\n15 participants agreeing to participate in our study (Table 1; P1-15). All participants were ethnically\nChinese and English was their second language. All participants provided consent to participate in\nthe study and agreed to audio and screen recording of the session. Each participant was provided\nwith a coupon equivalent to 50 HKD after the study to thank them for their participation.\n3.2 Tasks\nThe study used two writing tasks: story writing and slogan writing. These tasks were chosen as they\nwere the most common writing tasks mentioned in the literature about human-AI collaboration\nand creativity support [13, 14, 67]. Each participant was required to first complete the story writing\ntask about a given scenario such as detective fiction, science fiction, and so forth. In the story\nwriting task, each participant was asked to at least work out and articulate a general storyline. In\nthe slogan writing task, the participant was asked to write a concise but memorable slogan for the\nstory writing fiction they just came up with. The slogan took the form of a film title, a social media\nadvertising post, a marketing slogan, and so on.\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:6 Qian Wan et al.\nID Age Gender Knowledge of AI Story Writing Genre Slogan Type\nP1 28 Female No knowledge Action fiction Marketing slogan\nP2 27 Male A little Science fiction Marketing slogan\nP3 28 Male No knowledge Science fiction Film title\nP4 20 Female A little Science fiction Film title\nP5 20 Female No knowledge Detective fiction Film title\nP6 21 Male A little Horror fiction Social media ad\nP7 21 Female A little Science fiction Film title\nP8 23 Female No knowledge Horror fiction Marketing slogan\nP9 23 Female A little Science fiction Film title\nP10 22 Female A little Science fiction Film title\nP11 25 Female No knowledge Horror fiction Film title\nP12 22 Female Frequent user Science fiction Film title\nP13 24 Male A little Action fiction Film title\nP14 25 Male Frequent user Action fiction Marketing slogan\nP15 22 Female A little Science fiction Marketing slogan\nTable 1. Participant Demographics and the story writing genres and slogan types used during the study.\n3.3 Study Procedure\nAt the beginning of the study, each participant completed a demographic survey about their age,\ngender, ethnicity, first language, and AI knowledge. They were also asked to list some creative\nwriting tasks they encountered in their daily lives. We then introduced participants to the concept\nof LLMs and trained them on how to generate and input prompts by walking them through the\nOpenAI GPT-3 Playground API. In addition to using the examples and tips provided by OpenAI, we\nalso used examples and tips that were collected from online communities (e.g., r/WritingPrompts,\nr/WritingWithAI, etc.) and the academic literature (e.g., [3, 18, 55]; subsection A.1). Each participant\nwas also allowed to explore the interface for 10 minutes.\nThe study was then comprised of three sessions: a scenario-based ideation session, a think-aloud\nsession, and an interview session. In an earlier pilot study with two HCI researchers, we found that\nparticipants became fixated on the affordances of the LLM interface, although in prewriting they\ncould adopt various strategies such as free-writing, listing, mind-mapping, concept mapping, etc.\nTherefore, we added an ideation session before the usage of LLMs, where each participant would\nideate about how they would prewrite with an LLM on a writing interface.\n3.3.1 Session I: Scenario-based Ideation. After the training session, each participant was given a\npen and a piece of paper. The participant was asked to treat the paper as a writing interface that\nthey could freely write or draw on and prompt the AI to generate ideas whenever necessary. We\nthen assigned the participant a genre from our genre bank (e.g., science fiction, horror fiction, etc.)\nand asked the participant to ideate on different prewriting strategies that could be used with the\nLLM for story writing and slogan writing. We used prewriting strategies from previous literature\n[5] as a starting point for the ideation process, which included concept mapping, brainstorming,\nfree-writing, mind-mapping, listing, Q/A (How, When, What, Why), and so forth. We then asked\neach participant about their initial ideas or thoughts on prewriting with the LLM, and then walked\nthem through existing strategies that could be used as prompts. For each prewriting strategy, we\nshowed participants formal descriptions and example images and asked them how they would\ncollaborate with the LLM if they were to adopt such a strategy. We then asked them to reflect on the\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:7\nstrategy, whether they liked it or not, and why. Each participant was also required to demonstrate\ntheir prewriting strategies or collaboration workflows by writing or drawing on the paper.\n3.3.2 Session II: Think-Aloud. After the ideation session, participants were encouraged to execute\na think-aloud implementation of their strategies for the LLM interface. Each participant used the\nOpenAI GPT-3 Playground interface 4 to try out their prewriting strategies to complete the two\nwriting tasks, in order. We chose this API because it was the state-of-the-art LLM model at the\ntime of our study. Moreover, GPT-3 Playground was flexible enough for prewriting as it offered\na variety of options with examples (e.g., ‘insert mode’ to generate in the middle of given inputs,\n‘Q/A’ templates for conversation-like interaction, etc.). The freedom of organizing prompts within\nthe interface also overcame concerns about fixation [35]. Participants could specify where the AI\nshould write and model parameters such as randomness.\nAt the beginning of this session, all GPT-3 parameters used OpenAI’s default values (Model:\ntext-davinci-002 model, Temperature: 1, Top P: 1, Frequency penalty: 0, Presence penalty: 0, Best\nof: 1). Each participant was informed beforehand about the meaning of each parameter and when\nparameter tuning could be helpful. Each participant was then required to perform the story-writing\ntask to create a rough, but articulated, idea of a storyline and then perform the slogan-writing\ntask to promote the story. We asked participants to speak about their collaboration workflow,\nprewriting strategies, how they prompted the LLM, how they perceived the output, and so on.\nTo assist participants in collaborating, we provided prompt guidance using the examples and\ntips provided during the training session, but only when the collaboration broke down and the\nparticipant did not know how to obtain output after several failed attempts of rewriting prompts.\nDuring the implementation of the prewriting strategies, we also asked participants to compare\ntheir expectations with their experiences and if any mismatches would affect their strategies. After\nthe two tasks, we also asked participants to use the LLM to perform creative writing tasks that\nthey carried out in their daily lives.\n3.3.3 Session III: Interview. In the third session, we conducted a semi-structured interview in a\nreflective manner. Participants were first asked to reflect on their usage of the LLM, including the\nprewriting and prompt strategies they adopted, their general perception of the LLM (e.g., “What do\nyou think of the creative capability of the LLM?”), overall collaboration experience (e.g., “What\nbreakdowns did you come across?”, “What output of the LLM were the most impressive?”), and so\non. Based on this reflection, we then asked them to think of potential future designs that could be\nimplemented to support prewriting with the LLM during creative tasks.\n3.4 Data Analysis\nOur study data was comprised of screen and audio recordings and the strategies and workflows\ndrawn on paper by participants. To analyze this data, the first author (with an AI research back-\nground) first performed an initial open coding [15] of the audio and screen recording by playing\nthem simultaneously, and referring to the paper drawings when necessary to understand strategies\nadopted. During this round of coding, the author focused on what the participant said about\nthe LLM, how he or she collaborated with it, and what he or she said, wrote, or drew about the\nprewriting strategies. They also recorded timestamps, a description of the data (transcription of\naudio or description of video content), initial themes that emerged, and kept an analytic memo to\ntrack emerging themes.\nDuring a discussion session, the first and second author (with a design background) then analyzed\nthese initial codes through the lens of the existing theories of creativity and writing from the\n4https://beta.openai.com/playground\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:8 Qian Wan et al.\nFig. 1. The Human-AI co-creativity process that exists during prewriting when collaborating with LLMs.\nliterature. They both concurred that the existing models were insufficient to interpret the data\nbecause emerging themes could not fit in one single writing or creativity model. Writing models\nsuch as [26, 58] did not further decompose the psychological process of the prewriting stage from a\ncreativity perspective. Creativity theories from Psychology, such as Wallas’ four-stage model [72],\ndescribed human thinking processes without the mention of interactions with computers. Existing\nmodels of creativity support also either precluded collaboration with an intelligent agent such\nas an LLM [64] or lacked key stages in the psychological process, such as illumination [27]. The\nfirst and second author then agreed to choose Wallas’ [72] and Frich’s [27] models as the starting\npoint of a new theoretical framework, as these models were thought to be sufficient to cover the\npsychological processes and state-of-the-art creativity support.\nBased on these models, the first and second author performed a second round of coding, where we\nrevisited the analytic memo and assigned the initial themes into different stages of the two models.\nWe then grouped these stages into categories and constructed a new model that had three key stages:\nIdeation, Illumination, and Implementation. The terminology of Ideation and Implementation was\nborrowed from Frich’s model, though these two stages were also mentioned by Wallas. In Wallas’\nmodel, Ideation related to both preparation and incubation, and Implementation was included in\nthe verification stage. The second stage, Illumination, came from Wallas’ model and was rarely\ntouched on by previous CSTs. Finally, we validated our codes by looking at each data description\nand the recordings and extracted higher-level themes to complement prior theories or construct\nnew theories or insights in the analytic memo. All of the codes and themes were later translated\ninto English for reporting herein.\n4 FINDINGS\nDrawing upon previous literature on the creativity [27, 72] and writing [26, 58] processes, we found\nthat LLMs were most intensively used to support three key stages of the entire creativity process:\nIdeation, Illumination, and Implementation (Figure 1). Participants usually used the LLM for Ideation\nwhen they initially had no ideas or only a vague picture in their minds. If they happened to have any\nthoughts, most preferred using the LLM as an Illumination tool to organize, summarize and reify\ntheir existing thoughts, rather than for ideation. Once an idea could be articulated or formalized,\nparticipants often experimented with them by writing them down during the Implementation stage,\neither as a title while slogan writing or as a film script or storyline while story writing.\nIn general, the three stages often occurred in the linear order, where creative thoughts were\nnoticed during Ideation, elucidated during Illumination, and experimented with during Implementa-\ntion. However, just as previous theories of writing suggest [26, 58], the process of prewriting is also\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:9\niterative, notably the usage of LLMs for Ideation. We found that participants often used the LLM for\nIdeation whenever they encountered writer’s block during the Implementation stage. Furthermore,\nthe unexpected results and randomness (sometimes even “failure”) of the LLM output from any of\nthe three stages was also considered to be a source of inspiration, which implicitly led to Ideation.\nHerein, we first report on each of the three stages of the creativity process, focusing on partici-\npants’ prewriting and prompt strategies, and describe the roles of the human and LLMs during\ncollaboration (RQ1). We then report on how participants perceived the LLM during collaboration\nand common breakdowns and workarounds that occurred during Session II (RQ2).\n4.1 Human-LLM Collaboration During Ideation\nThe results demonstrated that the LLM was used in a variety of explicit, iterative, and random\nways to help generate ideas during Ideation. Examples of such utilization are described next.\n4.1.1 Explicit Ideation. When participants did not have an initial idea, they would directly ask\nthe LLM for ideas in the hopes that it would provide brief keywords or outlines to spark their\ninspiration. This was preferred to the generation of longer passages of text that made perfect sense.\nFor example, P5 wanted the LLM to keep randomly generating related keywords or phrases from\nwhich she could draw inspiration during slogan writing. P9 instead wanted to ideate with the LLM\nby listing related keywords or general ideas. She said she could write down some brief keywords for\na science fiction story (e.g., outdoor, expenditure) to prompt the LLM to generate related ideas. She\nwould also list some general ideas (or plots) and ask the LLM to follow the pattern of the list and\ncontinue to write. During Session II, she wrote “1. time travel and save life 2. exploring in the jungle,\n3. investigation of evidence ” as a few-shot prompt, and expected the LLM to continue the list. P8, said\nshe wanted to structure the general settings (e.g., time, location, activities, themes, etc.) of a horror\nfiction using concept maps and then prompt the LLM to ideate on each concept. She expected\nthe LLM to generate something like “December”, “around Christmas”, “School Life”, etc. P11 was\nrequired to write a “horror fiction” in Session I, and she said she would like the LLM to provide a\nlist of horror elements in ancient Chinese cultures at the very beginning to seek inspiration.\n4.1.2 Context-Enriched, Iterative Ideation. During Session II, we observed that explicit ideation\nwas usually iterative. After the first attempt at ideation, the output of LLM was often perceived\nto be too general, and somewhat bland, typically because the prompts of the first attempt were\nalso broad and vague. To improve the results, participants usually added more context to the initial\nprompt, such as naming a scenario, providing an example, or directly specifying where or how to\nimprove. For instance, after working on a rough plot for a science fiction story, P2 said he would\nlike to improve the output by enriching the “emotional arc ”. He added that the hero (protagonist) of\nthe story fell in love with a nurse after waking up in a hospital and asked the LLM to generate what\nwould happen next. The LLM continued, “The nurse is killed by the monster ”, which P2 thought was\nquite amazing. While performing the slogan writing task, we also observed that P10 was constantly\nchanging her prompts by adding constraints. Upon getting the initial output “Change is inevitable ”,\nshe thought it was too short, and changed the last sentence of her prompt from “ Please write a\nslogan based on the story above. ” to “Please write a slogan in two sentences based on the story above. ”.\nAfter submitting the prompt several times, she obtained results such as “The women killed the alien:\na fresh start for Mars ”, but this time she thought the result was too plain so she tried asking the\nLLM to improve the results by using rhetoric such as metaphors or exaggeration.\nDespite the results being general and bland during Session II, especially during the first few\nattempts, most participants (e.g., P1, P3-6, P8, P10) mentioned that they would still use LLMs for\nideation as long as they could provide something new. P8 explained that she only expected the\nLLM to “introduce new concepts that she could not think of” , and she would “take care of the rest and\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:10 Qian Wan et al.\nprocess those concepts into intriguing and articulated ideas” . P4 also stressed in reflection that she\nbelieved the LLM could generate more ideas than humans and that it provided ideas that escaped\nher during collaboration. After prompting the LLM to use a metaphor in the generated slogan, P10\nobtained an awkward result that did not look like a slogan at all, i.e., “The alien’s blood on her hand\nwas a symbol of the couple’s new beginning ”. She said it still inspired her about where or how she\ncould draw a metaphor, although the result did not fit the prompt perfectly.\n4.1.3 From Implementation Back to Ideation. Participants (e.g., P4-6) also often encountered writer’s\nblock during the Implementation stage while experimenting with their existing ideas, so they would\nturn to the LLM for another round of ideation. Among our participants, P3 spent most of their\ntime free-writing with the LLM during Session II, mostly in a co-creation-like manner, because he\nalready had an idea of his opening scene. In an explanation of his strategies, he said,\n“I would like to write down something as a scene, and then save it and move to the next\nscene. I would be using the LLM either to generate a scene or something if I happen to run\nout of ideas, or as a source inspiration to explore other possibilities. ”\nDuring his implementation of the story writing task, he first wrote down a simple opening scene\nfor a science fiction film, where the protagonist, John opened up his eyes and managed to lift his\nupper body. The LLM was then asked to continue the opening so it wrote that a woman showed up\nin the monitor in front of him and welcomed his return. P3 then further wrote that John asked who\nshe was and where he was and the LLM wrote that the woman had to keep her identity secret and\nthat John was in cryogenic sleep for fifty years before waking up in the space station. P3 said he\ndid not think of such impressive, detailed plot when asking the LLM who the woman was and that\nhe would directly follow the generated ideas to continue writing.\nWhen participants iteratively used the LLM for ideation during Implementation, they often had\ndifficulty structuring and designing their prompts because they needed to ask the LLM for ideation\nbased on their already written context. Most participants ended up directly using previous output as\nthe context in the prompt and added an imperative sentence (e.g., “Please brainstorm something”)\nor used the ‘insert mode’ of the OpenAI API, which did not always provide satisfying results. While\nfree-writing their opening scene with the LLM, P4 found that the sentence “The spaceship is pulled\ninto the black hole and Alan is killed ” was a little confusing, and she wanted to ask the LLM to\nbrainstorm how Alan was killed. Assuming that adding an imperative sentence within an opening\nscene would be odd and invalid, she used the ‘insert mode’ several times with the prompt: “The\nspaceship is pulled into the black hole and Alan is killed by [insert] ”. The LLM failed to understand\nthe prompt was intended for brainstorming how Alan was killed and instead generated something\nsimilar to “The spaceship is pulled into the black hole and Alan is killed by the intense force ”.\n4.1.4 Unexpected Results and Randomness. We also found that the LLM could be implicitly used\nfor ideation, where ideas were accidentally generated. Unexpected results and the randomness of\nthe LLM were the most common source of inspiration. The unexpected results during Session II\nwere either caused by the ambiguity in the prompts or the limitations of the LLM. In such cases,\nthe LLM returned seemingly valid generations that amazed the participant, but derailed them\nfrom their original intentions. For instance, during P8’s slogan writing, the LLM generated a title\nthat was thought to be out-of-context, i.e., “the demonic dough ”. However, P8 said it is intriguing\nbecause it provided a new concept, “dough” that was “demonic”, which she did not think of while\nstory writing. She could have considered adding more suspense or horror elements related to this\nconcept, e.g., writing a scene about a bakery lesson where dough was being made and something\nsupernatural happened. While free-writing, P2 expected the LLM to specify the upbringing of the\nhero (protagonist) of his story so he prompted the LLM by asking for the “background” of the hero\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:11\n(a) The randomness of the LLM’s\noutput, which was perceived as in-\nspiring by P10.\n(b) The collaboration broke down between P2 and\nthe LLM when the LLM generated nine titles that\ndid not contain a metaphor.\n(c) P4’s LLM-generated science fiction film script, which was perceived to be vivid\nin details, but have a corny ending.\nbased on a given storyline. This ambiguous prompt led the LLM to generate the background of the\nstory rather than the hero alone, such as where monsters came from, how the monsters destroyed\nthe world, and how humans fought back led by the hero. P2 said the results were impressive and\nhe was open to continuing ideation or writing based on such generation.\nImplicit ideation was also triggered by the randomness of the LLM, where participants drew\ninspiration from LLM output that was believed to be a complete failure or breakdown. While listing\nstorylines in the form of timelines using the LLM’s “insert mode”, P10 expected the LLM to continue\nwriting what happened at a given time. She then came across incorrect output where the LLM\nonly repeated what was already written by P10 at another time, which she said was nonsensical (\nFigure 2a). However, P10 said that such output was quite inspiring as it reminded her about using a\ntime loop in her storyline where an alien was trapped and managed to break out.\n4.2 Human-LLM Collaboration During Illumination\nIllumination is a stage where creative ideas burst into conscious awareness and become articulated\nor formalised. Collaboration with LLMs was often found to involve summarization, organization,\nand reification of vague, rough, and disjointed thoughts. We now report how participants leveraged\nthe LLM for illumination and how useful it was as a tool for illumination.\n4.2.1 Leveraging LLMs for Illumination. Many participants (e.g., P4, P6, P8-9, P12-15) mentioned\nthat if they already had something in mind, they preferred using the LLM to illuminate their\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:12 Qian Wan et al.\nexisting thoughts rather than for ideation. Such “thoughts” were mostly in incubation, which\nparticipants found difficult to consciously articulate. While writing a science fiction story, P9 said\nshe already had some rough ideas in mind, but she was only able to name some vague keywords\nsuch as “outdoor”, “expenditure”, “starry night”, and so on. During Session I, she said she preferred\nusing concept maps and asking the LLM to organise keywords and generate other details such as\ncharacters, locations, plots, and so on. For example, the LLM could merge the two concepts such\nas “outdoor” and “starry night” in the concept map and generate possible plots in new concept\nboxes that could be added to the existing concept map. She also noted that she might sometimes\nfree-write some fleeting thoughts on the prewriting interface and she expected that the LLM would\nkeep track of her thoughts and present a summary or a suggested storyline. Similarly, P7 mentioned\nthat she would like to list some thought fragments and expected the LLM to organise them into\nsomething promising.\nWhen using the LLM to summarise and organise their existing thoughts, participants expected\nthe LLM to help elucidate their ideas with nuances via the reification of vague and fleeting concepts.\nFor example, P8 said she thought of a “terrible night ” after Ideation with the LLM, and wanted the\nLLM to keep track of such thoughts and provide some clarification such as what terrible things\nhappened that night. P10 said that while listing their vague and unstructured thoughts with the\nLLM, she expected the LLM would help enrich existing ideas in the list with more details. P12\ninitially outlined elements of a story such as characters, locations, themes, events, etc., and asked\nthe LLM to provide more details such as relationships between characters, possible settings for\nscenes, how an event unfolds, etc.\nWhile slogan writing during Session II, P4 created a title for her science fiction film where an\nastronaut was pulled into a black hole and accidentally discovered the truth of the universe and\n“experienced everything that has ever happened and will ever happen ” before his death. She thought\nof keywords such as “lights” to represent the experience of the astronaut and expected the LLM to\nuse them in a concise title, preferably via rhetoric (e.g., use the word “lights” as a contrast against\nthe black hole). Therefore, she directly used a previously written storyline as context to ask the\nLLM to name the story within 6 words using the list of keywords.\n4.2.2 The Capabilities of LLMs as an Illumination Tool. The capabilities of the LLM were often\nnoted as being astonishing, where vague prompts with fragmented concepts could be interpreted\nby the LLM into concrete and fascinating ideas. Some participants, such as P2, commented that “the\nAI seemed to know what I was about to say ”, while they could not articulate their ideas themselves.\nP4 used the LLM to draft a content plan for a real-life mobile app design task. She only had a vague\nidea of the immersive mobile application she wanted to design, which monitored users’ heart rate\nand potentially featured summer night scenes and fireflies. She said the app could be a sports or\nhealth app, or a game, but it was far from even a prototype. She then prompted the LLM in a quite\nmessy way,\n“Please write an overview of my application which includes a philosophical description of\nfireflies and life, summer night scenes, and heart rate frequency of the user. \"\nThe LLM then articulated a concrete idea that had her in awe,\n“The application is a digital recreation of a summer night scene, with fireflies flitting about\nand the user’s heart rate affecting the frequency of their flashes. The philosophy behind\nthe fireflies is that they represent life – with its ups and downs, its surprises and miracles,\nits beauty and fragility. Just as each firefly’s light is unique, so too is each person’s life.\nAnd just as the fireflies’ light fades as summer comes to an end, so too will our time on\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:13\nthis earth come to an end. But the light of our lives can still shine brightly and bring joy\nto others, even after we’re gone. \"\nP4 said the LLM seemed to understand what was in her mind, articulated the function of the\napplication, and abstracted philosophical meaning based on fragmented concepts via a very concrete\nand detailed description. She said that she came across the idea when she saw a meadow during\nthe summer. She suddenly imagined fireflies and wanted to incorporate such a scene into the\napplication, i.e., “it was a crazy idea that didn’t seem to make sense, but the AI makes it work. ”\n4.3 Human-LLM Collaboration During Implementation\nImplementation occurred after participants already had a concrete idea that was small and wasn’t\naccompanied by a bigger picture. They then tentatively experimented with their ideas by writing\nthem down and polishing them with the LLM. During Session II, there were generally two types\nof collaboration to implement an idea, i.e., participants directly asked for LLM generations based\non given specifications of the idea or they prompted the LLM to fill in details based on what they\nwrote themselves.\nThe first approach was usually used at the beginning of the Implementation stage. Participants\nliked to clarify their structured ideas as the context to tentatively prompt the LLM for a first draft.\nFor example, during Session II, P8 specified characters, locations, time, themes, and key events\nabout her story and directly asked the LLM to write an overview of the complete storyline. P5\ninstead asked the LLM to generate an opening scene of a detective film script based on her plot.\nThe second approach was generally adopted by participants to polish their writing. Based on a\ndraft, the LLM was asked to bridge a logical gap in a plot, provide a nuanced portrait of a scene, or\nrephrase a paragraph. For example, after adding a love story between the hero and the nurse, P2\nwanted more details about how the emotional arc affected the main storyline of the fight against a\nmonster. He used the ‘insert mode’ to prompt the LLM to generate content within his storyline and\nobtained the suggestion “The nurse is killed by the monster ”. While free-writing with the LLM, P6\nfelt the following scene lacked nuance and could be further enriched:\nThey went on a bus bound to a village. But when they jumped on the bus happily, they\nsuddenly found that was the last bus today. Worse, all passengers got off three bus stops\nbefore reaching the terminus.\nHe therefore added an “[insert]” between “...the last bus today ” and “Worse, ...” to prompt the LLM\nto provide more details to explain why all passengers got off early.\nWhen implementing their ideas, most participants (e.g., P2-6) noted that they would like to take\ncare of the general picture, either a storyline or the rhetoric of a slogan. The LLM was expected to\nenrich the details or fill the gaps. For instance, P3 explained that “I would like to scaffold the writing\nby providing a structure and a general storyline ... I would use it mostly for details or to overcome\nwriter’s block” . He also added that it was mainly just his own preference. However, this behavior\nwas found to be quite common among our participants and was often caused by perceptions of\nthe LLM after extended usage during Session II. The LLM’s ability to generate nuanced details\nwas appreciated by many, but its ability for high-level logic reasoning or sense-making was often\nquestioned. During Session II, P6 tried prompting the LLM to enrich or develop his main storyline\nmany times, but most of the LLM generations were viewed as failures to understand his general\ncontext. The LLM initially generated “Worse still, the bus was out of service ”, which was contradictory\nto the context.\nDuring their interviews, P2, P3, P4 and P5 spoke highly of the LLM because of its capability\nof generating nuanced details, while they all acknowledged the LLM seemed to have problems\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:14 Qian Wan et al.\nunderstanding their general ideas or developing a storyline in a valid way. In one scenario, the\nLLM generated a film script based on P4’s storyline (Figure 2c):\nINT. BLACK HOLE - DAY\nWe see Alan, floating in the black hole. He is lost and confused, his mind reeling from all\nthat he has seen and experienced. He looks down at his body, but makes no move to take it\nback. He is lost in thought, his mind trying to process all that he has seen...\nINT. MILITARY LAB - DAY\n...\nThe screen goes dark and the people in the room cheer. Alan is gone, but his sacrifice has\nsaved the universe.\nP4 said the output was vivid in detail but that the ending scene was unexpected and corny. She\nthought the film should be themed around the discovery of the truth of the universe but the LLM\nwrote a super-hero style film script.\n4.4 The Collaborative Roles of Humans and LLMs\nIn this subsection we summarise the roles of human and the LLM during the whole prewriting\nprocess (Table 2).\nScenario Goal Initiative\nIdeation without ideas generate ideas LLM-lead\nIllumination with vague thoughts elucidate thoughts Human-led\nImplementation with concrete ideas experiment with ideas by writing Human-led\nTable 2. Collaboration patterns of Human-AI Co-creativity found during the study.\n4.4.1 The Shift of Initiatives. Most of the time, participants wanted to take initiative, especially\nduring the Implementation stage, unless they ran out of ideas. Only when they had no ideas or\nthey happened to encounter writer’s block, would they let the LLM take the initiative to generate\nideas from scratch. For example, during Session II, P3 explained that, “I liked to collaborate with it\nwhile I still had control. I could delete generations I didn’t like, and ask it [the LLM] to re-generate or\nsimply write on my own. It felt like having a second mind in parallel that processed all the context\nand provided new ideas when requested. ” P2 also believed that the initiative of the human while\ncollaborating with the LLM was a major advantage compared to human-human collaboration. He\nsaid that, “Human collaborators might have their own unique thoughts and failed to get what I’m\nthinking or writing but the LLM could do exactly what I asked it to do based on my thoughts. ”\nNevertheless, while letting the LLM take initiative, participants were quite open-minded as\nlong as the LLM could generate something new. During iterative ideation, many participants\n(e.g., P3-4, P8-9) mentioned they would like the LLM to “defend” their generations by providing\nspecifications, even if they were vague and confusing in the first place. For instance, during story\nwriting, P8 mentioned she did not mind following the LLM’s suggested storylines for ideation if\nshe encountered writer’s block, even if the suggested ideas diverged from her expectations. P4 used\nthe LLM to brainstorm an ending for her story and she thought the results were a little vague and\nseemingly out of line with her context. She said she would like to ask the LLM to explain how it\ncould align its results with the given plot.\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:15\n4.4.2 Verification of Results. As the definition of creativity implies both originality and effectiveness\n[27, 60], the verification of the effectiveness of ideas is also important for creativity support [27].\nThroughout the entire creativity process, participants always verified the results themselves and\nintegrated them with their existing thoughts, which later led to an iterative ideation or iteration\nacross prewriting stages. While asking the LLM to explain its generations, P4 liked to evaluate the\nresults in the following way:\nThere are three points to consider. First, does it align with what I expect? Second, what’s\nthe difference between my expectation and the LLM generation, and is it acceptable? Third,\nif the generation is novel and intriguing, how should I integrate it with my existing ideas.\nIn only two cases did we find that participants would use the LLM to verify their ideas. P8 said\nshe would use the LLM as Grammarly to proofread her writing. P2 said he would like the LLM to\nperform a plagiarism check of his writing against its training data.\nWe also found that participant agency during collaboration alleviated copyright concerns because\nparticipants either took care of the big picture or verified and integrated the generations with their\nown thoughts if the LLM took the lead. P3 said he would not consider copyright a problem because\nhe was leading the collaboration most of the time. P7 also mentioned copyright was not an issue\nbecause she would blend the generations with her own writing rather than use them directly.\n4.5 Breakdowns and Workarounds\nThe collaboration breakdowns during prewriting fell roughly into two categories, i.e., dynamically-\nadjusted context and uncertainty in communication via prompts. These breakdowns were mainly\ncaused by the nature of LLMs rather than affordances of the OpenAI interface.Herein, we report on\nthese breakdowns, how participants worked around them, and design fearures that were suggested\nto overcome these breakdowns.\n4.5.1 Dynamically-Adjusted Contexts. Prewriting with LLMs was almost never observed to only\nrequire one single prompt. It was usually iterative, which required participants to dynamically\nadjust the context of their prompts. In this situation, participants often had no idea what they should\ndo. For example, while moving to slogan writing, many participants (P2-4, P6-7) found that their\nprevious results while story writing were messy and cluttered, which could not be directly used\nas context. Some participants (P3, P6) had to delete all the results and ask the LLM to brainstorm\nslogans, sometimes based on a completely rephrased storyline. P4 iteratively asked the LLM to\nbrainstorm endings for her story. She reflected that she had difficulty asking the LLM to enrich\neach ending on the list with more details and inquired about how each ending connected to the\nopening. Sometimes she even thought of completely dropping the previous context and starting all\nover again to brainstorm something for her story.\nTo support the dynamic adjustment of context, some participants (e.g., P2, P7, P10) mentioned\nthat they wanted to see some examples, suggestions, templates, or tutorials as a reference. For\ninstance, P10 said she preferred a template so that she could fill in the blank to specify her context.\nP7 said she wanted to have multiple panels in the interface for context adjustments so she could\ndevelop the main storyline in a main panel and ask the LLM questions or request details in another\npanel. In this case, the context in each panel would not be conflated.\n4.5.2 Uncertain Communication via Prompts. The communication between participants and the\nLLM often broke down due to the uncertainty of prompt-based communication, which is a known\nchallenge when interacting with generative AI models such as GPT-3 [7]. Many participants re-\nported they did not know how to tell the LLM to do certain things. The most common breakdowns\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:16 Qian Wan et al.\nwere failure (i.e., nonsensical results) and fixation (i.e., the LLM continued to generate unsatisfac-\ntory results regardless of how a prompt was adjusted). In an extreme case, P2 found that minor\ngrammatical mistakes in his prompts could lead to random LLM generations.\nMoreover, the LLM could also easily misunderstood or completely ignore the requirements of\nthe participant, even if it generated something seemingly valid. P6 recalled that,\nI was quite curious sometimes what kind of a prompt was needed to get what I want...\nSome of my prompts were completely ineffective that the LLM failed to understand. I felt\nit wouldn’t work either if I rephrased my prompts and changed some keywords. I’d like to\nknow what prompts are preferred by the LLM.\nP2 summarised such a situation as “ context-sensitivity”, where the LLM could sometimes be\nextremely sensitive to some words even if they were insignificant in the prompt, and other times\ncompletely ignore some words as if they did not understand them. He reflected that the LLM\nseemed to misunderstand what a slogan was, but returned decent results when he changed “slogan”\nto “title”. He then once prompted the LLM to “Please give five titles of a sci-fi movie using metaphors\nbased on the above outline\" the LLM understood what the “title” was, but generated nine titles\nwithout using metaphors as if it did not understand what “metaphor” meant (Figure 2b).\nDuring their interview, P2 said that,\nWhile collaborating with a human, you can communicate with ambiguity and he or\nshe could still understand you but the LLM seemed to comprehend some words by exact\ndefinition. You have to be very specific when communicating with the LLM, which could\nbe difficult.\nHe therefore suggested that he would like to see all the potential training data that contributed\nto the understanding of some keywords or concepts.\n4.6 Perceptions of Existing LLMs\nParticipants had various perceptions about existing LLMs during prewriting and varied thoughts\non how such perceptions might influence collaboration.\n4.6.1 Strengths. In general, participants felt that the LLM was good at introducing new concepts\nduring Ideation, elucidating vague thoughts with nuance for Illumination, and enriching results of\nImplementation with details. Therefore, during the Illumination and Implementation stage, partici-\npants often expected nuanced and detailed results from the LLM while they preferred taking care\nof the big picture. During the Ideation stage, however, results were often said to lack nuance, but\ncould still introduce new concepts which benefited creativity output.\n4.6.2 Mediocrity. Throughout different stages of usage, almost all participants encountered results\nthat were mediocre. They described them as “too general ” (P1, P14), “featureless” (P4, P9, P15), “too\nplain” (P2, P6, P13-14), “corny” (P3-4, P15), and so forth. Such mediocre results were partially due\nto prompts being too vague and broad or too specific. The former lacked proper context to deliver\ndecent results, while the latter often caused the LLM to keep summarizing the existing context.\nFor example, P14 once prompted the LLM to write a slogan based on a detailed storyline, but the\nresults were said to be only a summary of what was given without anything inspiring. P15 instead\nwas initially requesting a background of a science fiction with very vague descriptions, and found\nresults were too general. She guessed “perhaps it (GPT-3) couldn’t know where to start, or how to\nreturn something promising with so little context given ”\nSuch mediocrity sometimes compromised credibility to the degree that participants would\nbecome suspicious of the creativity of the LLM. P15 said that, “I feel that it (GPT-3) can only learn\nfrom previous data and generate similar patterns, but is unable to conceive anything truly novel, like\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:17\nmany masterpieces. ”. Many participants (e.g., P2-3, P9-10) noted they would like to look at the\nLLM’s training data to understand its creative potential.\n4.6.3 High-Level Sense-Making. Participants often questioned the comprehension skills of the\nLLM as it often failed to comprehend abstract concepts or high-level themes such as storyline. In\nthese cases, the communication often broke down due to misunderstandings. Therefore, some of\nparticipants (e.g., P3, P6) mentioned that they would take care of the big picture themselves. P6\nstressed he would not use the LLM in the future for anything ther than details or ideation because\nit could not understand what he was writing.\n4.6.4 Training Data. Many participants mentioned that they wanted to see the LLMs training data\nbecause they did not trust it. P3 and P4 said the “corny” plots generated by the LLM made them\nfeel like it was trained on novels from the last century. P3 added that he would not even consider\nusing it, if the LLM was only trained on old-fashioned fictions.\nP1, P9, and P11 said that the plot generated by the LLM was Western-style, which might imply\nbias in its training data. When asking the LLM to write an action film in ancient times, the LLM\ngenerated an opening scene of a king’s army on an expedition, while P1 expected Asian styles such\nas Kung Fu, swordsman, etc. P11 was asking the LLM to search for elements of horror in ancient\nChinese culture, but she found LLM was misinterpreting some ancient Chinese stories such as\n“Butterfly Lovers” as “horror fictions”.\n‘P2 also mentioned that he was suspicious about if the LLM was directly copying its training\ndata, and therefore wanted to look at all data related to its current generations. P5 initially doubted\nthe LLM’s ability to writing dialogue in a film script based on the presumption that the LLM might\nnot find dialogue in its dataset.\n5 DISCUSSION\nOur findings lead to a three-stage collaboration process of prewriting in two creative tasks and\nuncovered current practices that are employed while using an existing state-of-the-art LLM. We\nfirst formalize the Human-AI Co-creativity process to outline the role of LLMs in generating new\nconcepts and providing nuance and detail how initiative shifts during collaboration. We then situate\nour model in existing literature of human-AI collaboration and creativity support, and explore its\ndistinctive nature to leverage uncertainty for creativity. We also discuss the design implications of\nsupporting co-creativity from the perspectives of prompt strategies, writing, and explainability. We\nconclude by documenting the limitations of the Human-AI Co-creativity model.\n5.1 Human-AI Co-Creativity Process: Collaborative Roles and Initiatives\nWe aim to approach creativity from the perspective of human-AI collaboration. Our findings led to a\nthree-stage collaboration process while prewriting a creative story and slogan that includedIdeation,\nIllumination, and Implementation. We term this process Human-AI Co-creativity. It complements\nprevious investigations into the role of LLMs in the writing process [30, 67, 80] by highlighting the\ncollaborative roles and shifting initiatives that exist between humans and LLMs in creativity during\nprewriting. Our study suggests that during the human-LLM collaboration, LLMs were delegated\nthe tasks of generating new concepts and providing nuance by elucidating vague thoughts and\npolishing writing with details. In general, when beginning with no or several concrete ideas, LLMs\nassisted humans as a source of inspiration and reified and enriched their existing thoughts.\nOur study also highlighted the dominant role of the human throughout the process of co-\ncreativity, which echoes prior work on human-AI co-creation [53]. Taking such a dominant role\nwas two-fold. On the one hand, humans take the generated output from LLMs with a grain of salt.\nThey like to verify the results themselves and integrate output from LLMs with their own thoughts.\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:18 Qian Wan et al.\nOn the other hand, humans like to take charge of the general picture, such as a storyline or the\nrhetoric of a slogan. LLMs are mostly used to provide nuanced details, either for elucidation during\nIllumination or while experimenting with their ideas during Implementation. However, our work\ndistinguishes itself from prior work [13, 14, 53] as participants did not mind following the LLM\nfor Ideation, and even iteratively fine-tuned its results, which benefits divergent thinking [59, 62].\nFurthermore, the Human-AI Co-creativity process is an iterative process, which aligns with existing\nwriting models [26, 58]. Apart from iteration led purely by humans, the unexpected results and\nrandomness of LLMs could accidentally revert the three stages back towards Ideation.\nWith such collaboration patterns, LLMs are put in a new position with respect to initiative\n[25, 65]. During the Ideation stage of the co-creativity process, LLMs were granted initiative since\nthe originality of generations was prioritised over quality. For the other two stages, LLMs took\nmore of an assistive role, while the shift of initiatives might accidentally occur based on users’\nevaluations of collaboration outcomes. In this situation, participants also perceived their outcome,\neither a slogan or a storyline, as original, due to their agency during collaboration and the relatively\nlightweight usage of LLMs compared to other LLM writing tasks [13, 67, 77, 78]. We believe the\nconceptualisation of Human-AI Co-creativity could tentatively help piece together the puzzle of\nethical interrogations of AI co-creativity or AI-generated art [21, 28, 45].\n5.2 Theoretical Implications: Collaboration and Creativity\nThe proposed Human-AI Co-creativity process model combines perspectives from human-AI collab-\noration, creativity theories, and creativity support in two creative writing scenarios. In comparison\nto previous studies of LLM-powered writing support, such as Singh et al. [67], our model concerns\ncollaboration patterns and dynamics, including goals, initiatives, communication, workflows, etc.\nThis approach aligns with the call for a CSCW perspective [ 73] in human-AI collaboration, as\nthe LLM was conceived as an intelligent collaborator throughout our study, both reflected in\nparticipants’ account and by how we interpreted our data.\nFurthermore, the Human-AI Co-creativity process enhances previous understanding of human-AI\nco-creative experience [14, 30, 53], by incorporating Wallas’ creativity theories in the two prewriting\ntasks. In particular, the Illumination stage has received limited attention in previous literature of\ncreativity support. To our best knowledge, the closest accounts in HCI to this stage are convergent\nphases in CSTs (e.g., [ 36]), or iteration of design prototypes [ 23, 24]. They are both related to\nrefining existing ideas (or prototypes), while the Illumination stage starts from unconsciousness\nor inarticulate thoughts in incubation, and emphasizes the burst of creative ideas into conscious\nawareness. Previously AI models might not be able to directly translate vague, rough, or disjointed\nconcepts into concrete or promising outcomes, but our findings suggest the feasibility of using\nLLMs to support Illumination.\nThis new finding can hopefully inspire future design of CSTs to facilitate emergence of creative\nideas in incubation. Notably, some theories of creativity [ 10, 66] posit that a process of blind\nvariations is essential for reaching true creativity, during which creators become ignorant of the\neffectiveness of any creative ideas. In this sense, supporting Illumination is crucial in that it can\nsignificantly accelerate the blind variation process: not by generating alternatives, but “guiding”\nthe creator with AI throughout the thinking process. We expect empirical studies to enhance\nunderstanding of this stage while collaborating with generative AI models. Specifically, other\ncreative scenarios, such as drawing or music composition, might have different forms of an “idea”\ncompared to writing. It requires a new study to figure out how other generative AI models can\nhelp “illuminate” these forms of ideas.\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:19\n5.3 Uncertainty as Creativity in Human-AI Co-Creativity\nWhile other writing or human-AI collaboration tasks mainly expect certain and precise output\n[69, 77, 78], one of the most distinctive features of Human-AI Co-creativity in the two prewriting\ntasks was treating uncertainty as a source of creativity. While prewriting with LLMs, participants\ndid not expect a high-quality or once-for-all result that perfectly fits the given prompt. Instead, the\nLLM was usually used to avoid writer’s block or fixation [35], where imperfect ideas, unexpected\nresults, and the randomness of the LLM all served as a source of inspiration provided that they\nintroduced new concepts or remind users of other possibilities. A change of initiative can also\noccur without irritating users due to the nature of divergent thinking [59, 62], which echoes prior\nwork on generative AI models for art and resonates with the call for an inclusive view of AI [11].\nSuch uncertainty does compromise the quality and efficiency of human-AI communication and\nsometimes leads to collaboration breakdowns. This duality of uncertainty in the creativity process\nadvances the exploration of the imperfection of generative AI models [69, 76], and also opens up\npossibilities for future explainability features to model uncertainty for creative tasks. We expect\nfuture investigations into what kind of, or what level of, certainty could be used for creativity\nand how we could explain or communicate such uncertainty to facilitate communication and\nsense-making for creativity support.\nFurthermore, the previous literature on LLMs for human-AI collaboration was largely dedicated\nto controlling the uncertainty of an AI model [77, 78]. Based on our findings, research attention\nshould go beyond reducing randomness or delivering satisfying yet definite generation when it\ncomes to creativity support. During prewriting with a LLM, uncertainty could be leveraged to\nfacilitate divergent thinking by sometimes disrupting communication, although future effort is\nneeded to understand the balance between the two. As the most common participant frustration\nwas the “mediocre” generations that seemed reasonable but lacked originality, such needs will pose\na challenge for algorithmically improving LLMs or addressing related collaboration breakdown.\nCategory Applied to Definition\nExamples & Tutorials Inputs Example prompts, templates, or related tips needed to address collabora-\ntion breakdown\nData Models Transparency of task-related training data and those that contribute to\nthe understanding of certain concepts\nContext Sensitivity Outputs Which part of the prompt most significantly led to the output\nCapability Models Whether the LLM is capable of understanding or generating something\nbecause it has seen related data\nTable 3. Categories of AI documentation for LLMs for creativity support\n5.4 Design Implications\nSeveral design implications arose from our research relating to prompt strategies for prewriting,\nwriting support tools, and potential explainability features.\n5.4.1 Prompt Strategies for Prewriting. As prewriting is iterative, prewriting with LLMs cannot be\ncompleted via a single prompt without proper context. The context to prompt a LLM also often\nneeds to be dynamically adapted based on user requirements. Thus, there is a design opportunity to\ntrack context during collaboration and semi-automate the process of adjusting context by providing\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:20 Qian Wan et al.\nsuggestions or guidance. For example, systems could prompt users with real-time summaries of\ncontext (i.e., what was written; e.g., [17]) and example questions (i.e., how to ask the LLM to do\nsomething), whenever the collaboration seems to breakdown. Systems could then adapt off-the-shelf\nprompt strategies (e.g., [3]) to wrap these requirements into a valid prompt. Like one participant\n(P7) suggested, systems should maintain multiple writing panels in parallel to maintain context. In\nthis case, any iterations, either intentionally or unexpectedly, would not influence the previous\ncontext or writing results.\n5.4.2 LLM-Augmented Writing Support Tools. Our study also shed light on possible writing support\ntool designs that integrate LLMs. Building upon previous prewriting tools such as [ 49], design\nefforts should be made to scaffold the co-creativity process using LLMs. For Ideation, for instance,\nprewriting tools could support translating diagrams or lists into prompts to request more LLM\ngenerated concepts. To support Illumination, systems could provide features to organize writing in\nan interface, or elucidate keywords in a diagram. We also expect future tools leveraging LLMs to\nsupport creative thoughts in incubation while users step away from a problem. For Implementation,\nsystems can also introduce human-LLM co-creation to experiment ideas like previous creative\nwriting systems [13, 14, 80].\nIn addition, the initiative of the human should be properly supported. During a typical ideation\nscenario, LLMs should be allowed to take the initiative to overcome writer’s block or design fixation\n[35]. Prompt strategies should be designed to support iteratively requesting that LLMs polish their\ngenerations. In other scenarios, however, humans should be granted full agency while LLMs should\ntake a more assistive role, addressing details without disrupting the creative thoughts of humans.\nTo seamlessly integrate the two initiative modes into one writing tool, efforts should be made to\nidentify the uncertainty of LLMs (or alternatively, the perception of humans) that caused a change\nof initiative.\n5.4.3 Explainability for Co-Creativity. Our findings implied that, while working with a LLM, users\nwould rarely care about the technical details of the model. The most requested explainability\nfeatures in our study used to be related to input and output, such as transparency of training data,\nguidance of prompt strategies, examples and templates as a guidance for input, etc. We advocate\nfor new dimensions of AI documentation [2, 32, 37] related to our participants’ concerns to support\nhuman-LLM co-creativity. We summarize categories of AI documentation identified in our study in\nTable 3 for non-expert users to support creativity. The table is adapted from Sun et al. ’s templates\nfor AI documentation of generative AI models for code [69].\n5.5 Limitations and Future Work\nIt is important to note that the presentedHuman-AI Co-creativity model was based on two prewriting\ntasks (i.e., story writing and slogan writing) and involved participants with design or writing related\nmajors and little AI expertise. Our research also used the GPT-3 model. Thus, although some of our\nfindings such as shifting initiatives echo and complement previous research in similar scenarios\n[14, 30, 67, 80], additional efforts are needed to investigate the generality of the process to other\ncreative scenarios (e.g., drawing), writing stages or tasks, expert or novice writers, and LLMs aside\nfrom GPT-3. An expert fiction writer, for example, might not follow theHuman-AI Co-creativity\nworkflow but instead start from a known storyline. With the release of ChatGPT or even GPT-\n4, some of our findings regarding perceptions or collaboration breakdowns might not apply to\nsuch chat bot-style interactions and new collaboration opportunities or challenges might arise.\nFurthermore, our three-session study protocol might have impacted the collaboration workflow\ninvestigated, though it aimed to simulate a general prewriting scenario. Without being introduced\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:21\nto established strategies or asked to both ideate and implement strategies, participants might have\nemployed different workflows in this one-shot study.\nIt is also worth noting that our participants were ethnically Chinese and English was their second\nlanguage. This demographic setup allowed us to provide a non-eurocentric documentation of\nHuman-AI Co-creativity and opens up future research opportunities into the potential bias of LLMs\nacross ethnic and language groups. Yet, it also means that several findings regarding prompt design\nor the evaluation of LLM output might need to be taken with a grain of salt for other language\ngroups or native English speakers. For instance, though our participants reported the LLM had\ncultural misunderstandings, it would require a future study to investigate its overall comprehension\nof ancient Chinese cultures beyond just a few cases, and many other studies to understand its\ncultural bias across different language groups.\nNevertheless, this research paves the way for future efforts to revisit creative writing or creativity\nsupport from a Human-AI Co-creativity perspective to examine applicability of the model to other\nworkflows or scenarios. We also highlight the need for new models or theories relating to more\ndiverse tasks and scenarios and the participation of users with more diverse backgrounds to enrich\nour understanding of the Human-AI Co-creativity process.\n6 CONCLUSION\nThis research presented a three-stage, iterative process of Human-AI Co-creativity that was based\non the findings from two creative prewriting tasks. It implies that the human plays a dominant\nrole while discovering and developing ideas, but also that there is a shifting initiative between\nhumans and LLMs while collaboratively prewriting. We also reported common breakdowns and\nuser perceptions of LLMs that existed. This research invites future investigation into Human-AI\nCo-creativity and benefit researchers endeavoring to leverage human-AI collaboration for creativity\nsupport, such as the design of LLM-augmented writing tools.\n7 ACKNOWLEDGEMENT\nWe are thankful to all reviewers for their constructive suggestions that helped make this paper\nmuch stronger.\nREFERENCES\n[1] Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi\nIqbal, Paul N Bennett, Kori Inkpen, et al. 2019. Guidelines for human-AI interaction. In Proceedings of the 2019 chi\nconference on human factors in computing systems . 1–13.\n[2] Matthew Arnold, Rachel KE Bellamy, Michael Hind, Stephanie Houde, Sameep Mehta, Aleksandra Mojsilović, Ravi\nNair, K Natesan Ramamurthy, Alexandra Olteanu, David Piorkowski, et al. 2019. FactSheets: Increasing trust in AI\nservices through supplier’s declarations of conformity. IBM Journal of Research and Development 63, 4/5 (2019), 6–1.\n[3] Simran Arora, Avanika Narayan, Mayee F Chen, Laurel J Orr, Neel Guha, Kush Bhatia, Ines Chami, Frederic Sala,\nand Christopher Ré. 2022. Ask Me Anything: A simple strategy for prompting language models. arXiv preprint\narXiv:2210.02441 (2022).\n[4] Zahra Ashktorab, Q Vera Liao, Casey Dugan, James Johnson, Qian Pan, Wei Zhang, Sadhana Kumaravel, and Murray\nCampbell. 2020. Human-ai collaboration in a cooperative game setting: Measuring social perception and outcomes.\nProceedings of the ACM on Human-Computer Interaction 4, CSCW2 (2020), 1–20.\n[5] Ismail Baroudy. 2008. A Procedural Approach to Process Theory of Writing: Prewriting Techniques. The International\nJournal of Language Society and Culture 24, 4 (2008), 45–52.\n[6] Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking aloud: Dynamic context generation improves\nzero-shot reasoning performance of gpt-2. arXiv preprint arXiv:2103.13033 (2021).\n[7] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein,\nJeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. 2021. On the opportunities and risks of foundation models.\narXiv preprint arXiv:2108.07258 (2021).\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:22 Qian Wan et al.\n[8] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan,\nPranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural\ninformation processing systems 33 (2020), 1877–1901.\n[9] Carrie J Cai, Emily Reif, Narayan Hegde, Jason Hipp, Been Kim, Daniel Smilkov, Martin Wattenberg, Fernanda Viegas,\nGreg S Corrado, Martin C Stumpe, et al. 2019. Human-centered tools for coping with imperfect algorithms during\nmedical decision-making. In Proceedings of the 2019 chi conference on human factors in computing systems . 1–14.\n[10] Donald T Campbell. 1960. Blind variation and selective retentions in creative thought as in other knowledge processes.\nPsychological review 67, 6 (1960), 380.\n[11] Baptiste Caramiaux and Sarah Fdili Alaoui. 2022. \" Explorers of Unknown Planets\" Practices and Politics of Artificial\nIntelligence in Visual Arts. Proceedings of the ACM on Human-Computer Interaction 6, CSCW2 (2022), 1–24.\n[12] Kathy Charmaz. 2006. Constructing grounded theory: A practical guide through qualitative analysis . sage.\n[13] John Joon Young Chung, Wooseok Kim, Kang Min Yoo, Hwaran Lee, Eytan Adar, and Minsuk Chang. 2022. TaleBrush:\nSketching Stories with Generative Pretrained Language Models. In CHI Conference on Human Factors in Computing\nSystems. 1–19.\n[14] Elizabeth Clark, Anne Spencer Ross, Chenhao Tan, Yangfeng Ji, and Noah A Smith. 2018. Creative writing with a\nmachine in the loop: Case studies on slogans and stories. In 23rd International Conference on Intelligent User Interfaces .\n329–340.\n[15] Juliet Corbin and Anselm Strauss. 2014. Basics of qualitative research: Techniques and procedures for developing grounded\ntheory. Sage publications.\n[16] Robert Dale. 2021. GPT-3: What’s it good for? Natural Language Engineering 27, 1 (2021), 113–118.\n[17] Hai Dang, Karim Benharrak, Florian Lehmann, and Daniel Buschek. 2022. Beyond Text Generation: Supporting Writers\nwith Continuous Automatic Text Summaries. In Proceedings of the 35th Annual ACM Symposium on User Interface\nSoftware and Technology . 1–13.\n[18] Hai Dang, Lukas Mecke, Florian Lehmann, Sven Goller, and Daniel Buschek. 2022. How to Prompt? Opportunities and\nChallenges of Zero-and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models.\narXiv preprint arXiv:2209.01390 (2022).\n[19] Nicholas Davis, Chih-PIn Hsiao, Kunwar Yashraj Singh, Lisa Li, and Brian Magerko. 2016. Empirically studying\nparticipatory sense-making in abstract drawing with a co-creative cognitive agent. InProceedings of the 21st International\nConference on Intelligent User Interfaces . 196–207.\n[20] Nicholas Mark Davis, Chih-Pin Hsiao, Kunwar Yashraj Singh, and Brian Magerko. 2016. Co-creative drawing agent\nwith object recognition. In Twelfth artificial intelligence and interactive digital entertainment conference .\n[21] Celine Melanie A Dee. 2018. Examining copyright protection of AI-generated art. Delphi 1 (2018), 31.\n[22] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional\ntransformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).\n[23] Steven P Dow, Alana Glassco, Jonathan Kass, Melissa Schwarz, Daniel L Schwartz, and Scott R Klemmer. 2010.\nParallel prototyping leads to better design results, more divergence, and increased self-efficacy. ACM Transactions on\nComputer-Human Interaction (TOCHI) 17, 4 (2010), 1–24.\n[24] Steven P Dow, Kate Heddleston, and Scott R Klemmer. 2009. The efficacy of prototyping under time constraints. In\nProceedings of the seventh ACM conference on Creativity and cognition . 165–174.\n[25] Umer Farooq, Jonathan Grudin, Ben Shneiderman, Pattie Maes, and Xiangshi Ren. 2017. Human computer integration\nversus powerful tools. In Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing\nSystems. 1277–1282.\n[26] Linda Flower and John R Hayes. 1981. A cognitive process theory of writing. College composition and communication\n32, 4 (1981), 365–387.\n[27] Jonas Frich, Lindsay MacDonald Vermeulen, Christian Remy, Michael Mose Biskjaer, and Peter Dalsgaard. 2019.\nMapping the landscape of creativity support tools in HCI. In Proceedings of the 2019 CHI Conference on Human Factors\nin Computing Systems . 1–18.\n[28] Harsha Gangadharbatla. 2022. The role of AI attribution knowledge in the evaluation of artwork. Empirical Studies of\nthe Arts 40, 2 (2022), 125–142.\n[29] Katy Ilonka Gero and Lydia B Chilton. 2019. Metaphoria: An algorithmic companion for metaphor creation. In\nProceedings of the 2019 CHI conference on human factors in computing systems . 1–12.\n[30] Katy Ilonka Gero, Vivian Liu, and Lydia Chilton. 2022. Sparks: Inspiration for science writing using language models.\nIn Designing Interactive Systems Conference . 1002–1019.\n[31] Branwen Gwern. 2022. GPT-3 Creative Fiction . Retrieved Jan 10, 2023 from https://www.gwern.net/GPT-3\n[32] Michael Hind, Stephanie Houde, Jacquelyn Martino, Aleksandra Mojsilovic, David Piorkowski, John Richards, and\nKush R Varshney. 2020. Experiences with improving the transparency of AI models and services. In Extended Abstracts\nof the 2020 CHI Conference on Human Factors in Computing Systems . 1–8.\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:23\n[33] Eric Horvitz. 1999. Principles of mixed-initiative user interfaces. In Proceedings of the SIGCHI conference on Human\nFactors in Computing Systems . 159–166.\n[34] Ruchika Jain, Naval Garg, and Shikha N Khera. 2022. Effective human–AI work design for collaborative decision-making.\nKybernetes ahead-of-print (2022).\n[35] David G Jansson and Steven M Smith. 1991. Design fixation. Design studies 12, 1 (1991), 3–11.\n[36] Youngseung Jeon, Seungwan Jin, Patrick C Shih, and Kyungsik Han. 2021. FashionQ: an ai-driven creativity support\ntool for facilitating ideation in fashion design. InProceedings of the 2021 CHI Conference on Human Factors in Computing\nSystems. 1–18.\n[37] Bran Knowles and John T Richards. 2021. The sanction of authority: Promoting public trust in ai. In Proceedings of the\n2021 ACM Conference on Fairness, Accountability, and Transparency . 262–271.\n[38] Janin Koch, Nicolas Taffin, Michel Beaudouin-Lafon, Markku Laine, Andrés Lucero, and Wendy E Mackay. 2020.\nImagesense: An intelligent collaborative ideation tool to support diverse human-computer partnerships. Proceedings of\nthe ACM on human-computer interaction 4, CSCW1 (2020), 1–27.\n[39] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large Language Models\nare Zero-Shot Reasoners. arXiv preprint arXiv:2205.11916 (2022).\n[40] Vivian Lai, Samuel Carton, Rajat Bhatnagar, Q Vera Liao, Yunfeng Zhang, and Chenhao Tan. 2022. Human-AI\nCollaboration via Conditional Delegation: A Case Study of Content Moderation. In CHI Conference on Human Factors\nin Computing Systems . 1–18.\n[41] Min Hun Lee, Daniel P Siewiorek, Asim Smailagic, Alexandre Bernardino, and Sergi Bermúdez i Badia. 2021. A\nhuman-ai collaborative approach for clinical decision making on rehabilitation assessment. In Proceedings of the 2021\nCHI Conference on Human Factors in Computing Systems . 1–14.\n[42] Yong Jae Lee, C Lawrence Zitnick, and Michael F Cohen. 2011. Shadowdraw: real-time user guidance for freehand\ndrawing. ACM Transactions on Graphics (TOG) 30, 4 (2011), 1–10.\n[43] Q Vera Liao, Daniel Gruen, and Sarah Miller. 2020. Questioning the AI: informing design practices for explainable AI\nuser experiences. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems . 1–15.\n[44] Q Vera Liao, Milena Pribić, Jaesik Han, Sarah Miller, and Daby Sow. 2021. Question-driven design process for explainable\nai user experiences. arXiv preprint arXiv:2104.03483 (2021).\n[45] Gabriel Lima, Assem Zhunis, Lev Manovich, and Meeyoung Cha. 2021. On the Social-Relational Moral Standing of AI:\nAn Empirical Study Using AI-Generated Art. Frontiers in Robotics and AI 8 (2021).\n[46] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good\nIn-Context Examples for GPT-3? arXiv preprint arXiv:2101.06804 (2021).\n[47] Ryan Louie, Andy Coenen, Cheng Zhi Huang, Michael Terry, and Carrie J Cai. 2020. Novice-AI music co-creation via\nAI-steering tools for deep generative models. In Proceedings of the 2020 CHI conference on human factors in computing\nsystems. 1–13.\n[48] Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically ordered prompts and\nwhere to find them: Overcoming few-shot prompt order sensitivity. arXiv preprint arXiv:2104.08786 (2021).\n[49] Zhicong Lu, Mingming Fan, Yun Wang, Jian Zhao, Michelle Annett, and Daniel Wigdor. 2018. Inkplanner: Supporting\nprewriting via intelligent visual diagramming. IEEE transactions on visualization and computer graphics 25, 1 (2018),\n277–287.\n[50] Maximilian Mackeprang, Claudia Müller-Birn, and Maximilian Timo Stauss. 2019. Discovering the sweet spot of\nhuman-computer configurations: A case study in information extraction. Proceedings of the ACM on Human-Computer\nInteraction 3, CSCW (2019), 1–30.\n[51] Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-task generalization via natural\nlanguage crowdsourcing instructions. arXiv preprint arXiv:2104.08773 (2021).\n[52] Felicia Ng, Jina Suh, and Gonzalo Ramos. 2020. Understanding and supporting knowledge decomposition for machine\nteaching. In Proceedings of the 2020 ACM Designing Interactive Systems Conference . 1183–1194.\n[53] Changhoon Oh, Jungwoo Song, Jinhan Choi, Seonghyeon Kim, Sungwoo Lee, and Bongwon Suh. 2018. I lead, you help\nbut only with enough details: Understanding user experience of co-creation with artificial intelligence. In Proceedings\nof the 2018 CHI Conference on Human Factors in Computing Systems . 1–13.\n[54] Phanish Puranam. 2021. Human–AI collaborative decision-making as an organization design problem. Journal of\nOrganization Design 10, 2 (2021), 75–80.\n[55] Laria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond the few-shot\nparadigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems . 1–7.\n[56] Jeba Rezwana and Mary Lou Maher. 2022. Designing Creative AI Partners with COFI: A Framework for Modeling\nInteraction in Human-AI Co-Creative Systems. ACM Transactions on Computer-Human Interaction (2022).\n[57] Melissa Roemmele and Andrew S Gordon. 2018. Automated assistance for creative writing with an rnn language\nmodel. In Proceedings of the 23rd International Conference on Intelligent User Interfaces Companion . 1–2.\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:24 Qian Wan et al.\n[58] D Gordon Rohman. 1965. Pre-writing the stage of discovery in the writing process. College composition and communi-\ncation 16, 2 (1965), 106–112.\n[59] MA Runco. 2014. Creativity: theories and themes: Research, development, and practice.\n[60] Mark A Runco and Garrett J Jaeger. 2012. The standard definition of creativity. Creativity research journal 24, 1 (2012),\n92–96.\n[61] John Sadauskas, Daragh Byrne, and Robert K Atkinson. 2015. Mining memories: Designing a platform to support\nsocial media based writing. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems .\n3691–3700.\n[62] R Keith Sawyer. 2011. Explaining creativity: The science of human innovation . Oxford university press.\n[63] Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace, and Sameer Singh. 2020. Autoprompt: Eliciting\nknowledge from language models with automatically generated prompts. arXiv preprint arXiv:2010.15980 (2020).\n[64] Ben Shneiderman. 2001. Supporting creativity with advanced information-abundant user interfaces. In Frontiers of\nhuman-centered computing, online communities and virtual environments . Springer, 469–480.\n[65] Ben Shneiderman and Pattie Maes. 1997. Direct manipulation vs. interface agents. interactions 4, 6 (1997), 42–61.\n[66] Dean Keith Simonton. 2022. The blind-variation and selective-retention theory of creativity: Recent developments and\ncurrent status of BVSR. Creativity Research Journal (2022), 1–20.\n[67] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L Glassman. 2022. Where to hide a stolen elephant: Leaps\nin creative writing with multimodal machine intelligence. ACM Transactions on Computer-Human Interaction (2022).\n[68] Robert J Sternberg and Todd I Lubart. 1999. The concept of creativity: Prospects and paradigms. Handbook of creativity\n1, 3-15 (1999).\n[69] Jiao Sun, Q Vera Liao, Michael Muller, Mayank Agarwal, Stephanie Houde, Kartik Talamadupula, and Justin D Weisz.\n2022. Investigating Explainability of Generative AI for Code through Scenario-based Design. In 27th International\nConference on Intelligent User Interfaces . 212–228.\n[70] Ben Swanson, Kory Mathewson, Ben Pietrzak, Sherol Chen, and Monica Dinalescu. 2021. Story Centaur: Large\nLanguage Model Few Shot Learning as a Creative Writing Tool. In Proceedings of the 16th Conference of the European\nChapter of the Association for Computational Linguistics: System Demonstrations . 244–256.\n[71] Gheorghe Tecuci, Mihai Boicu, and Michael T Cox. 2007. Seven aspects of mixed-initiative reasoning: An introduction\nto this special issue on mixed-initiative assistants. AI Magazine 28, 2 (2007), 11–11.\n[72] Graham Wallas. 1926. The art of thought . Vol. 10. Harcourt, Brace.\n[73] Dakuo Wang, Elizabeth Churchill, Pattie Maes, Xiangmin Fan, Ben Shneiderman, Yuanchun Shi, and Qianying Wang.\n2020. From human-human collaboration to Human-AI collaboration: Designing AI systems that can work together\nwith people. In Extended abstracts of the 2020 CHI conference on human factors in computing systems . 1–6.\n[74] Dakuo Wang, Justin D Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst\nSamulowitz, and Alexander Gray. 2019. Human-AI collaboration in data science: Exploring data scientists’ perceptions\nof automated AI. Proceedings of the ACM on Human-Computer Interaction 3, CSCW (2019), 1–24.\n[75] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma,\nDenny Zhou, Donald Metzler, et al. 2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682\n(2022).\n[76] Justin D Weisz, Michael Muller, Stephanie Houde, John Richards, Steven I Ross, Fernando Martinez, Mayank Agar-\nwal, and Kartik Talamadupula. 2021. Perfection not required? Human-AI partnerships in code translation. In 26th\nInternational Conference on Intelligent User Interfaces . 402–412.\n[77] Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. 2022.\nPromptchainer: Chaining large language model prompts through visual programming. In CHI Conference on Human\nFactors in Computing Systems Extended Abstracts . 1–10.\n[78] Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022. Ai chains: Transparent and controllable human-ai interaction\nby chaining large language model prompts. In CHI Conference on Human Factors in Computing Systems . 1–22.\n[79] Chuan Yan, John Joon Young Chung, Yoon Kiheon, Yotam Gingold, Eytan Adar, and Sungsoo Ray Hong. 2022. FlatMagic:\nImproving Flat Colorization through AI-driven Design for Digital Comic Professionals. In CHI Conference on Human\nFactors in Computing Systems . 1–17.\n[80] Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito. 2022. Wordcraft: story writing with large language models.\nIn 27th International Conference on Intelligent User Interfaces . 841–852.\n[81] Chao Zhang, Cheng Yao, Jiayi Wu, Weijia Lin, Lijuan Liu, Ge Yan, and Fangtian Ying. 2022. StoryDrawer: A Child–AI\nCollaborative Drawing System to Support Children’s Creative Visual Storytelling. In CHI Conference on Human Factors\nin Computing Systems . 1–15.\n[82] Rui Zhang, Nathan J McNeese, Guo Freeman, and Geoff Musick. 2021. \" An Ideal Human\" Expectations of AI Teammates\nin Human-AI Teaming. Proceedings of the ACM on Human-Computer Interaction 4, CSCW3 (2021), 1–25.\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\nInvestigating Human-AI Co-creativity in Prewriting with Large Language Models 84:25\n[83] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. 2022.\nLarge language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910 (2022).\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.\n84:26 Qian Wan et al.\nA APPENDIX\nA.1 Training Material: Prompt Strategies\nThe training material used in this study was comprised of a list of prompt strategies for GPT-3\ncollected from online resources and the academic literature [ 3, 18, 55]. Specifically, we divided\nthese strategies into three categories: Samples, Tips, and Guidelines (Table A1).\nCategory Description Content/Example\nSamples\nSample results where proper constraints or con-\ntext were given in the prompt to deliver structural\noutput, often multiple times towards the final writ-\ning [18, 31]\na 4chan greentext story1\npoetry writing2\na short play3\na Ramen shop story4\nTips\nParticular words or phrases to be added to the\nprompt that might significantly improve the qual-\nity of the output [39]\n\"let’s think step by step\"5\n\"tl;dr\" for summary6\nstop words/sequences7\nGuidelines The prompt design tutorials for the GPT-3 model\ngiving instructions8\ndescribing what you have in mind9\nadding context to the prompts10\nTable A1. Prompt Strategies for Training\nBased on these strategies, the training material contained examples such as:\n•“Write an one act play with Jesus and Carl Jung”\n•“Write a funny and philosophical 4chan greentext story”\n•“What is the meaning of life? Let’s think step by step”\n•“Brainstorm solutions to increase sales at your store”\n•“Come up with ideas for a new product that is environmentally friendly”\n•“My company produces reusable water bottles that can be refilled from the tap”\nThis training materials was also used to provide guidance when collaboration broke down and\nparticipants had no ideas.\nReceived January 2023; revised July 2023; accepted November 2023\n1https://absolutewrite.com/forums/index.php?threads/gpt-3-text-generator-excellent-for-story-ideas.352606/\n2https://www.gwern.net/GPT-3\n3https://twitter.com/GanWeaving/status/1585358381191086080\n4https://ricardodejong.com/how-i-used-a-i-to-create-my-first-book-and-generate-a-podcast-from-it/\n5https://medium.com/merzazine/prompt-design-gpt-3-step-by-step-b5b2a7a3ea85\n6https://towardsdatascience.com/gpt-3-parameters-and-prompt-design-1a595dc5b405\n7https://help.openai.com/en/articles/5072263-how-do-i-use-stop-sequences\n8https://towardsdatascience.com/gpt-3-parameters-and-prompt-design-1a595dc5b405\n9https://www.reddit.com/r/WritingWithAI/comments/ybskwc/how_to_start_a_prompt_with_instruction_or/\n10https://towardsdatascience.com/gpt-3-parameters-and-prompt-design-1a595dc5b405\nProc. ACM Hum.-Comput. Interact., Vol. 8, No. CSCW1, Article 84. Publication date: April 2024.",
  "topic": "Prewriting",
  "concepts": [
    {
      "name": "Prewriting",
      "score": 0.9356682896614075
    },
    {
      "name": "Creativity",
      "score": 0.8746756911277771
    },
    {
      "name": "Psychology",
      "score": 0.4858219623565674
    },
    {
      "name": "Process (computing)",
      "score": 0.4829675257205963
    },
    {
      "name": "Writing process",
      "score": 0.47563838958740234
    },
    {
      "name": "Collaborative writing",
      "score": 0.4733714461326599
    },
    {
      "name": "Pedagogy",
      "score": 0.30434125661849976
    },
    {
      "name": "Computer science",
      "score": 0.24940744042396545
    },
    {
      "name": "Social psychology",
      "score": 0.23621535301208496
    },
    {
      "name": "Teaching method",
      "score": 0.17702212929725647
    },
    {
      "name": "Cooperative learning",
      "score": 0.1618596315383911
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I168719708",
      "name": "City University of Hong Kong",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I204512498",
      "name": "University of Macau",
      "country": "MO"
    }
  ],
  "cited_by": 5
}