{
  "title": "Self-Supervised Hypergraph Transformer for Recommender Systems",
  "url": "https://openalex.org/W4289433255",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4224912081",
      "name": "Xia, Lianghao",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2104312933",
      "name": "Huang Chao",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2266028823",
      "name": "Zhang, Chuxu",
      "affiliations": [
        "Brandeis University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2741249238",
    "https://openalex.org/W2998431760",
    "https://openalex.org/W3168146412",
    "https://openalex.org/W3080913646",
    "https://openalex.org/W2605350416",
    "https://openalex.org/W3173955760",
    "https://openalex.org/W3042563449",
    "https://openalex.org/W3096875747",
    "https://openalex.org/W2054141820",
    "https://openalex.org/W2896537337",
    "https://openalex.org/W2963085847",
    "https://openalex.org/W3210910782",
    "https://openalex.org/W3012816161",
    "https://openalex.org/W3088777230",
    "https://openalex.org/W1720514416",
    "https://openalex.org/W2984100107",
    "https://openalex.org/W3035666843",
    "https://openalex.org/W2945827670",
    "https://openalex.org/W2911286998",
    "https://openalex.org/W3044311607",
    "https://openalex.org/W3093563174",
    "https://openalex.org/W3094605801",
    "https://openalex.org/W3207257408",
    "https://openalex.org/W3177890934",
    "https://openalex.org/W2807021761",
    "https://openalex.org/W3157014581",
    "https://openalex.org/W3156939347",
    "https://openalex.org/W3153325943",
    "https://openalex.org/W3100324210",
    "https://openalex.org/W3100278010",
    "https://openalex.org/W3100848837"
  ],
  "abstract": "Graph Neural Networks (GNNs) have been shown as promising solutions for\\ncollaborative filtering (CF) with the modeling of user-item interaction graphs.\\nThe key idea of existing GNN-based recommender systems is to recursively\\nperform the message passing along the user-item interaction edge for refining\\nthe encoded embeddings. Despite their effectiveness, however, most of the\\ncurrent recommendation models rely on sufficient and high-quality training\\ndata, such that the learned representations can well capture accurate user\\npreference. User behavior data in many practical recommendation scenarios is\\noften noisy and exhibits skewed distribution, which may result in suboptimal\\nrepresentation performance in GNN-based models. In this paper, we propose SHT,\\na novel Self-Supervised Hypergraph Transformer framework (SHT) which augments\\nuser representations by exploring the global collaborative relationships in an\\nexplicit way. Specifically, we first empower the graph neural CF paradigm to\\nmaintain global collaborative effects among users and items with a hypergraph\\ntransformer network. With the distilled global context, a cross-view generative\\nself-supervised learning component is proposed for data augmentation over the\\nuser-item interaction graph, so as to enhance the robustness of recommender\\nsystems. Extensive experiments demonstrate that SHT can significantly improve\\nthe performance over various state-of-the-art baselines. Further ablation\\nstudies show the superior representation ability of our SHT recommendation\\nframework in alleviating the data sparsity and noise issues. The source code\\nand evaluation datasets are available at: https://github.com/akaxlh/SHT.\\n",
  "full_text": "Self-Supervised Hypergraph Transformer for\nRecommender Systems\nLianghao Xia\nUniversity of Hong Kong\nHong Kong, China\naka_xia@foxmail.com\nChao Huangâˆ—\nUniversity of Hong Kong\nHong Kong, China\nchaohuang75@gmail.com\nChuxu Zhang\nBrandeis University\nWaltham, USA\nchuxuzhang@brandeis.edu\nABSTRACT\nGraph Neural Networks (GNNs) have been shown as promising\nsolutions for collaborative filtering (CF) with the modeling of user-\nitem interaction graphs. The key idea of existing GNN-based recom-\nmender systems is to recursively perform the message passing along\nthe user-item interaction edge for refining the encoded embeddings.\nDespite their effectiveness, however, most of the current recom-\nmendation models rely on sufficient and high-quality training data,\nsuch that the learned representations can well capture accurate user\npreference. User behavior data in many practical recommendation\nscenarios is often noisy and exhibits skewed distribution, which\nmay result in suboptimal representation performance in GNN-based\nmodels. In this paper, we propose SHT, a novel Self-Supervised\nHypergraph Transformer framework (SHT) which augments user\nrepresentations by exploring the global collaborative relationships\nin an explicit way. Specifically, we first empower the graph neu-\nral CF paradigm to maintain global collaborative effects among\nusers and items with a hypergraph transformer network. With\nthe distilled global context, a cross-view generative self-supervised\nlearning component is proposed for data augmentation over the\nuser-item interaction graph, so as to enhance the robustness of\nrecommender systems. Extensive experiments demonstrate that\nSHT can significantly improve the performance over various state-\nof-the-art baselines. Further ablation studies show the superior\nrepresentation ability of our SHT recommendation framework in\nalleviating the data sparsity and noise issues. The source code and\nevaluation datasets are available at: https://github.com/akaxlh/SHT.\nCCS CONCEPTS\nâ€¢ Information systems â†’Recommender systems.\nKEYWORDS\nSelf-Supervised Learning, Graph Neural Networks, Hypergraph\nRepresentation, Recommender System\nâˆ—Chao Huang is the corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nKDDâ€™22, August 14â€“18, 2022, Washington, DC, USA\nÂ© 2022 Association for Computing Machinery.\nACM ISBN 978-1-4503-9385-0/22/08. . . $15.00\nhttps://doi.org/10.1145/3534678.3539473\nACM Reference Format:\nLianghao Xia, Chao Huang, and Chuxu Zhang. 2022. Self-Supervised Hy-\npergraph Transformer for Recommender Systems. In Proceedings of the\n28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n(KDDâ€™22), August 14â€“18, 2022, Washington, DC, USA. ACM, Washington DC,\n10 pages. https://doi.org/10.1145/3534678.3539473\n1 INTRODUCTION\nRecommender systems have become increasingly important to alle-\nviate the information overload for users in a variety of web applica-\ntions, such as e-commerce systems [5], streaming video sites [17]\nand location-based lifestyle apps [4]. To accurately infer the user\npreference, encoding user and item informative representations\nis the core part of effective collaborative filtering (CF) paradigms\nbased on the observed user-item interactions [7, 8, 20].\nEarlier CF models project interaction data into latent user and\nitem embeddings using matrix factorization (MF) [13]. Due to the\nstrong representation ability of deep learning, various neural net-\nwork CF models have been developed to project users and items into\nlatent low-dimensional representations, such as autoencoder [15]\nand attention mechanism [ 2]. Recent years have witnessed the\ndevelopment of graph neural networks (GNNs) for modeling graph-\nstructural data [27, 30]. One promising direction is to perform the\ninformation propagation along the user-item interactions to refine\nuser embeddings based on the recursive aggregation schema. For\nexample, upon the graph convolutional network, PinSage [38] and\nNGCF [26] attempt to aggregate neighboring information by cap-\nturing the graph-based CF signals for recommendation. To simplify\nthe graph-based message passing, LightGCN [6] omits the burden-\nsome non-linear transformer during the embedding propagation\nand improve the recommendation performance. To further enhance\nthe graph-based user-item interaction modeling, some follow-up\nstudies propose to learn intent-aware representations with disentan-\ngled graph neural frameworks (e.g., DisenHAN [29]), differentiate\nbehavior-aware embeddings of users with multi-relational graph\nneural models (e.g., MB-GMN [34]).\nDespite the effectiveness of the above graph-based CF models by\nproviding state-of-the-art recommendation performance, several\nkey challenges have not been well addressed in existing methods.\nFirst, data noise is ubiquitous in many recommendation scenar-\nios due to a variety of factors. For example, users may click their\nuninterested products due to the over-recommendation of popu-\nlar items [42]. In such cases, the user-item interaction graph may\ncontain â€œ interest-irrelevantâ€ connections. Directly aggregating\ninformation from all interaction edges will impair the accurate\nuser representation. Worse still, the embedding propagation among\nmulti-hop adjacent vertices (user or item) will amplify the noise\narXiv:2207.14338v1  [cs.IR]  28 Jul 2022\neffects, which misleads the encoding of underlying user interest\nin GNN-based recommender systems. Second, data sparsity and\nskewed distribution issue still stand in the way of effective user-\nitem interaction modeling, leading to most existing graph-based\nCF models being biased towards popular items [14, 41]. Hence, the\nrecommendation performance of current approaches severely drops\nwith the user data scarcity problem, as the high-quality training\nsignals could be small. While there exist a handful of recently devel-\noped recommendation methods (SGL [31] and SLRec [37]) leverag-\ning self-supervised learning to improve user representations, these\nmethods mainly generate the additional supervision information\nwith probability-based randomly mask operations, which might\nkeep some noisy interaction and dropout some important training\nsignals during the data augmentation process.\nContribution. In light of the aforementioned challenges, this work\nproposes a Self-Supervised Hypergraph Transformer (SHT) to en-\nhance the robustness and generalization performance of graph-\nbased CF paradigms for recommendation. Specifically, we integrate\nthe hypergraph neural network with the topology-aware Trans-\nformer, to empower our SHT to maintain the global cross-user\ncollaborative relations. Upon the local graph convolutional net-\nwork, we first encode the topology-aware user embeddings and\ninject them into Transformer architecture for hypergraph-guided\nmessage passing within the entire user/item representation space.\nIn addition, we unify the modeling of local collaborative relation\nencoder with the global hypergraph dependency learning under a\ngenerative self-supervised learning framework. Our proposed new\nself-supervised recommender system distills the auxiliary super-\nvision signals for data augmentation through a graph topological\ndenoising scheme. A graph-based meta transformation layer is intro-\nduced to project hyergraph-based global-level representations into\nthe graph-based local-level interaction modeling for user and item\ndimensions. Our new proposed SHT is a model-agnostic method\nand serve as a plug-in learning component in existing graph-based\nrecommender systems. Specifically, SHT enables the cooperation of\nthe local-level and global-level collaborative relations, to facilitate\nthe graph-based CF models to learn high-quality user embeddings\nfrom noisy and sparse user interaction data.\nThe key contributions of this work are summarized as follows:\nâ€¢In this work, we propose a new self-supervised recommendation\nmodelâ€“SHT to enhance the robustness of graph collaborative fil-\ntering paradigms, by integrating the hypergraph neural network\nwith the topology-aware Transformer.\nâ€¢In the proposed SHT method, the designed hypergraph learning\ncomponent encodes the global collaborative effects within the\nentire user representation space, via a learnable multi-channel\nhyperedge-guided message passing schema. Furthermore, the\nlocal and global learning views for collaborative relations are\nintegrated with the cooperative supervision for interaction graph\ntopological denoising and auxiliary knowledge distillation.\nâ€¢Extensive experiments demonstrate that our proposed SHT frame-\nwork achieves significant performance improvement over 15\ndifferent types of recommendation baselines. Additionally, we\nconduct empirical analysis to show the rationality of our model\ndesign with the ablation studies.\n2 PRELIMINARIES AND RELATED WORK\nRecap Graph Collaborative Filtering Paradigm . To enhance\nthe Collaborative Filtering with the multi-order connectivity in-\nformation, one prominent line of recommender systems generates\ngraph structures for user-item interactions. Suppose our recom-\nmendation scenario involves ğ¼ users and ğ½ items with the user set\nU= {ğ‘¢1,...ğ‘¢ğ¼}and item set V= {ğ‘£1,...ğ‘£ ğ½}. Edges in the user-item\ninteraction graph Gare constructed if user ğ‘¢ğ‘– has adopted item\nğ‘£ğ‘—. Upon the constructed interaction graph structures, the core\ncomponent of graph-based CF paradigm lies in the information\naggregation functionâ€“gathering the feature embeddings of neigh-\nboring users/items via different aggregators, e.g., mean or sum.\nRecommendation with Graph Neural Networks . Recent stud-\nies have attempted to design various graph neural architectures to\nmodel the user-item interaction graphs through embedding prop-\nagation. For example, PinSage [38] and NGCF [26] are built upon\nthe graph convolutional network over the spectral domain. Later\non, LightGCN [6] proposes to simplify the heavy non-linear trans-\nformation and utilizes the sum-based pooling over neighboring\nrepresentations. Upon the GCN-based message passing schema,\neach user and item is encoded into the transformed embeddings\nwith the preservation of multi-hop connections. To further improve\nthe user representation, some recent studies attempt to design\ndisentangled graph neural architecture for user-item interaction\nmodeling, such as DGCF [28] and DisenHAN [29]. Several multi-\nrelational GNNs are proposed to enhance recommender systems\nwith multi-behavior modeling, including KHGT [ 32] and HMG-\nCR [35]. However, most of existing graph neural CF models are\nintrinsic designed to merely rely on the observation interaction\nlables for model training, which makes them incapable of effec-\ntively modeling interaction graph with sparse and noisy supervi-\nsion signals. To overcome these challenges, this work proposes a\nself-supervised hypergraph transformer architecture to generate\ninformative knowledge through the effective interaction between\nlocal and global collaborative views.\nHypergraph-based Recommender Systems . There exist some\nrecently developed models constructing hypergraph connections to\nimprove the relation learning for recommendation [11, 25, 39]. For\nexample, HyRec [25] regards users as hyperedges to aggregate in-\nformation from the interacted items. MHCN [39] constructs multi-\nchannel hypergraphs to model high-order relationships among\nusers. Furthermore, DHCF [11] is a hypergraph collaborative fil-\ntering model to learn the hybrid high-order correlations. Different\nfrom these work for generating hypergraph structures with manu-\nally design, this work automates the hypergraph structure learning\nprocess with the modeling of global collaborative relation.\nSelf-Supervised Graph Learning . To improve the embedding\nquality of supervised learning, self-supervised learning (SSL) has\nbecome a promising solution with auxiliary training signals [16],\nsuch as augmented image data [ 12], pretext sequence tasks for\nlanguage data [24], knowledge graph augmentation [36]. Recently,\nself-supervised learning has also attracted much attention on graph\nrepresentation [10]. For example, DGI [23] and GMI [18] perform\nthe generative self-supervised learning over the GNN framework\nwith auxiliary tasks. Inspired by the graph self-supervised learning,\nSGL [31] produces state-of-the-art performance by generating con-\ntrastive views with randomly node and edge dropout operations.\nFollowing this research line, HCCF [33] leverages the hypergraph\nto generate contrastive signals to improve the graph-based rec-\nommender system. Different from them, this work enhances the\ngraph-based collaborative filtering paradigm with a generative self-\nsupervised learning framework.\n3 METHODOLOGY\nIn this section, we present the proposed SHT framework and show\nthe overall model architecture in Figure 1. SHT embeds local struc-\nture information into latent node representations, and conduct\nglobal relation learning with the local-aware hypergraph trans-\nformer. To train the proposed model, we augment the regular param-\neter learning with the local-global cross-view self-augmentation.\n3.1 Local Graph Structure Learning\nTo begin with, we embed users and items into a ğ‘‘-dimensional\nlatent space to encode their interaction patterns. For user ğ‘¢ğ‘– and\nitem ğ‘£ğ‘—, embedding vectors eğ‘–,eğ‘— âˆˆRğ‘‘ are generated, respectively.\nAlso, we aggregate all the user and item embeddings to compose\nembedding matrices E(ğ‘¢) âˆˆRğ¼Ã—ğ‘‘,E(ğ‘£) âˆˆRğ½Ã—ğ‘‘, respectively. We\nmay omit the superscript (ğ‘¢)and (ğ‘£)for notation simplification\nwhen it is not important to differentiate the user and item index.\nInspired by recent success of graph convolutional networks [6,\n30] in capturing local graph structures, we propose to encode the\nneighboring sub-graph structure of each node into a graph topology-\naware embedding, to inject the topology positional information\ninto our graph transformer. Specifically, SHT employs a two-layer\nlight-weight graph convolutional network as follows:\nÂ¯E(ğ‘¢)= GCN2 (E(ğ‘£),G)= Â¯AÂ· Â¯AâŠ¤E(ğ‘¢)+ Â¯AÂ· E(ğ‘£) (1)\nwhere Â¯E(ğ‘¢) âˆˆRğ¼Ã—ğ‘‘ denotes the topology-aware embeddings for\nusers. GCN2 (Â·)denotes two layers of message passing. Â¯Aâˆˆ Rğ¼Ã—ğ½\nrefers to the normalized adjacent matrix of graph G, which is cal-\nculated by Â¯Ağ‘–,ğ‘— = Ağ‘–,ğ‘—/(D(ğ‘¢)1/2\nğ‘– D(ğ‘£)1/2\nğ‘— ), where Ais the original\nbinary adjacent matrix.D(ğ‘¢)\nğ‘– ,D(ğ‘£)\nğ‘— refer to the degree ofğ‘¢ğ‘– and ğ‘£ğ‘— in\ngraph G, respectively. Note that SHT considers neighboring nodes\nin different distance through residual connections. The topology-\naware embeddings for items can be calculated analogously.\n3.2 Hypergraph Transformer for Global\nRelation Learning\nThough existing graph-based neural networks have shown their\nstrength in learning interaction data [3, 6, 26], the inherent noise\nand skewed data distribution in recommendation scenario limit the\nperformance of graph representation for user embeddings. To ad-\ndress this limitation, SHT adopts a hypergraph transformer frame-\nwork, which i) alleviates the noise issue by enhancing the user\ncollaborative relation modeling with the adaptive hypergraph rela-\ntion learning; ii) transfer knowledge from dense user/item nodes to\nsparse ones. Concretely, SHT is configured with a Transformer-like\nattention mechanism for structure learning. The encoded graph\ntopology-aware embeddings are injected into the node represen-\ntations to preserve the graph locality and topological positions.\nMeanwhile, the multi-channel attention [22] further benefits our\nstructure learning in SHT.\nIn particular, SHT generates input embedding vectors for ğ‘¢ğ‘–\nand ğ‘£ğ‘— by combining the id-corresponding embeddings (eğ‘–,eğ‘—) to-\ngether with the topology-aware embeddings ( vectors Â¯eğ‘–,Â¯eğ‘— from\nembedding tables Â¯E(ğ‘¢)and Â¯E(ğ‘£)) as follows:\nËœeğ‘– = eğ‘– +Â¯eğ‘–; Ëœ eğ‘— = eğ‘— +Â¯eğ‘— (2)\nThen, SHT conducts hypergraph-based information propagation\nas well as hypergraph structure learning using Ëœeğ‘–,Ëœeğ‘— as input. We\nutilize ğ¾ hyperedges to distill the collaborative relations from the\nglobal perspective. Node embeddings are propagated to each other\nusing hyperedges as intermediate hubs, where the connections\nbetween nodes and hyperedges are optimized to reflect the implicit\ndependencies among nodes.\n3.2.1 Node-to-Hyperedge Propagation. Without loss of gener-\nality, we mainly discuss the information propagation between user\nnodes and user-side hyperedges for simplicity. The same process\nis applied for item nodes analogously. The propagation from user\nnodes to user-side hyperedges can be formally presented as follows:\nËœzğ‘˜ =\nğ»\f\f\f\n\f\f\f\nâ„=1\nÂ¯zğ‘˜,â„; Â¯zğ‘˜,â„ =\nğ¼âˆ‘ï¸\nğ‘–=1\nvğ‘–,â„kâŠ¤\nğ‘–,â„qğ‘˜,â„ (3)\nwhere Ëœzğ‘˜ âˆˆRğ‘‘ denotes the embedding for the ğ‘˜-th hyperedge. It is\ncalculated by concatenating the ğ» head-specific hyperedge embed-\ndings Â¯zğ‘˜,â„ âˆˆRğ‘‘/ğ». qğ‘˜,â„,kğ‘–,â„,vğ‘–,â„ âˆˆRğ‘‘/ğ» are the query, key and\nvalue vectors in the attention mechanism which will be elaborated\nlater. Here, we calculate the edge weight between hyperedge ğ‘˜ and\nuser ğ‘¢ğ‘– through a linear dot-product kâŠ¤\nğ‘–,â„qğ‘˜,â„, which reduces the\ncomplexity from ğ‘‚(ğ¾Ã—ğ¼Ã—ğ‘‘/ğ»)to ğ‘‚((ğ¼+ğ¾)Ã—ğ‘‘2/ğ»2)by avoiding\ndirectly calculating the node-hyperedge connections (i.e. kâŠ¤\nğ‘–,â„qğ‘˜,â„),\nbut the key-value dot-product first (i.e. Ãğ¼\nğ‘–=1 vğ‘–,â„kâŠ¤\nğ‘–,â„).\nIn details, the multi-head query, key and value vectors are cal-\nculated through linear transformations and slicing. The â„-head-\nspecific embeddings are calculated by:\nqğ‘˜,â„ = Zğ‘˜,ğ‘â„âˆ’1:ğ‘â„; kğ‘–,â„ = Kğ‘â„âˆ’1:ğ‘â„,: Ëœeğ‘–; vğ‘–,â„ = Vğ‘â„âˆ’1:ğ‘â„,: Ëœeğ‘– (4)\nwhere qğ‘˜,â„ âˆˆ Rğ‘‘/ğ» denotes the â„-head-specific query embed-\nding for the ğ‘˜-th hyperedge, kğ‘–,â„,vğ‘–,â„ âˆˆRğ‘‘/ğ» denotes the â„-head-\nspecific key and value embedding for user ğ‘¢ğ‘–. Z âˆˆRğ¾Ã—ğ‘‘ represents\nthe embedding matrix for the ğ¾ hyperedges. K,V âˆˆ Rğ‘‘Ã—ğ‘‘ rep-\nresents the key and the value transformation of all the ğ» heads,\nrespectively. ğ‘â„âˆ’1 = (â„âˆ’1)ğ‘‘\nğ» and ğ‘â„ = â„ğ‘‘\nğ» denote the start and the\nend indices of the â„-th slice.\nTo further excavate the complex non-linear feature interactions\namong the hyperedges, SHT is augmented with two-layer hierar-\nchical hypergraph neural networks for both user side and item side.\nSpecifically, the final hyperedge embeddings are calculated by:\nË†Z = HHGN2 (ËœZ); HHGN(X)= ğœ(HÂ· X +X) (5)\nwhere Ë†Z, ËœZ âˆˆRğ¾Ã—ğ‘‘ represent the embedding tables for the final\nand the original hyperedge embeddings, consisting of hyperedge-\nspecific embedding vectors Ë†z,Ëœz âˆˆRğ‘‘, respectively. HHGN2 (Â·)de-\nnotes applying the hierarchical hypergraph network (HHGN) twice.\nUser-Item Interaction Graph\nÃ—2Res id embeddings\nGraph Topology-aware Embed.\n Hypergraph Transformer\nğ™\nğŠ\nğ•\nâ‹… Ã—ğ¿\nâ„ = 1\nğ‘£\nğ»\nğ‘ğ‘˜âŠ¤\nSelf-Augmented Learning\nâ‹…  ğ‘ \nğœ™(ğ‘¢)\nğœ™(ğ‘£)\nğ‘ \nMeta\nMeta\nLocal\nGlobal\nâ„’sğ‘\nEdge Pairs\nFigure 1: Overall framework of the proposed SHT model.\nHHGN is configured with a learnable parametric matrixHâˆˆ Rğ¾Ã—ğ¾,\nwhich characterizes the hyperedge-wise relations. An activation\nfunction ğœ(Â·)is introduced for non-linear relation modeling. Ad-\nditionally, we utilize a residual connection to facilitate gradient\npropagation in our hypergraph neural structures.\n3.2.2 Hyperedge-to-Node Propagation. With the final hyper-\nedge embeddings Ë†Z, we propagate the information from hyperedges\nto user/item nodes through a similar but reverse process:\nËœeâ€²\nğ‘– =\nğ»\f\f\f\n\f\f\f\nâ„=1\nÂ¯eâ€²\nğ‘–,â„; Â¯ eâ€²\nğ‘–,â„ =\nğ¾âˆ‘ï¸\nğ‘˜=1\nvâ€²\nğ‘˜,â„kâ€²âŠ¤\nğ‘˜,â„qâ€²\nğ‘–,â„ (6)\nwhere Ëœeâ€²\nğ‘– âˆˆRğ‘‘ denotes the new embedding for userğ‘¢ğ‘– refined by the\nhypergraph neural network. Â¯eâ€²\nğ‘–,â„ âˆˆRğ‘‘/ğ» denotes the node embed-\nding calculated by the â„-th attention head for ğ‘¢ğ‘–. qâ€²\nğ‘–,â„,kâ€²\nğ‘˜,â„,vâ€²\nğ‘˜,â„ âˆˆ\nRğ‘‘/ğ» represent the query, key and value vectors for user ğ‘¢ğ‘– and\nhyperedge ğ‘˜. The attention calculation in this hyperedge-to-node\npropagation process shares most parameters with the aforemen-\ntioned node-to-hyperedge propagation. The former query serves\nas key, and the former key serves as query here. The value calcu-\nlation applies the same value transformation for the hyperedge\nembedding. The calculation process can be formally stated as:\nqâ€²\nğ‘–,â„ = kğ‘–,â„; kâ€²\nğ‘˜,â„ = qğ‘˜,â„; vâ€²\nğ‘˜,â„ = Vğ‘â„âˆ’1:ğ‘â„,: Ë†zğ‘˜ (7)\n3.2.3 Iterative Hypergraph Propagation. Based on the promi-\nnent node-wise relations captured by the learned hypergraph struc-\ntures, we propose to further propagate the encoded global col-\nlaborative relations via stacking multiple hypergraph transformer\nlayers. In this way, the long-range user/item dependencies can be\ncharacterized by our SHT framework through the iterative hyper-\ngraph propagation. In form, taking the embedding tablesËœEğ‘™âˆ’1 in the\n(ğ‘™âˆ’1)-th iteration as input, SHT recursively applies the hypergraph\nencoding (denoted by HyperTrans(Â·)) and obtains the final node\nembeddings Ë†E âˆˆRğ¼Ã—ğ‘‘ or Rğ½Ã—ğ‘‘ as follows:\nËœEğ‘™ = HyperTrans(ËœEğ‘™âˆ’1); Ë†E =\nğ¿âˆ‘ï¸\nğ‘™=1\nËœEğ‘™ (8)\nwhere the layer-specific embeddings are combined through element-\nwise summation. The iterative hypergraph propagation is identical\nfor the user nodes and item nodes. Finally, SHT makes predictions\nthrough dot product as ğ‘ğ‘–,ğ‘— = Ë†e(ğ‘¢)âŠ¤\nğ‘– Ë†e(ğ‘£)\nğ‘— , where ğ‘ğ‘–,ğ‘— is the forecast-\ning score denoting the probability of ğ‘¢ğ‘– interacting with ğ‘£ğ‘—.\n3.3 Local-Global Self-Augmented Learning\nThe foregoing hypergraph transformer addresses the data sparsity\nproblem through adaptive hypergraph message passing. However,\nthe graph topology-aware embedding for local collaborative rela-\ntion modeling may still be affected by the interaction data noise.\nTo tackle this challenge, we propose to enhance the model training\nwith self-augmented learning between the local topology-aware\nembedding and the global hypergraph learning. To be specific,\nthe topology-aware embedding for local information extraction is\naugmented with an additional task to differentiate the solidity of\nsampled edges in the observed user-item interaction graph. Here,\nsolidity refers to the probability of an edge not being noisy, and\nits label in the augmented task is calculated based on the learned\nhypergraph dependencies and representations. In this way, SHT\ntransfers knowledge from the high-level and denoised features in\nthe hypergraph transformer, to the low-level and noisy topology-\naware embeddings, which is expected to recalibrate the local graph\nstructure and improve the model robustness. The workflow of our\nself-augmented module is illustrated in Fig 2.\n3.3.1 Solidity Labeling with Meta Networks. In our SHT model,\nthe learned hypergraph dependency representations can serve as\nuseful knowledge to denoise the observed user-item interactions by\nassociating each edge with a learned solidity score. Specifically, we\nreuse the key embeddings kğ‘–,â„,kğ‘—,â„ in Eq 4 to represent userğ‘¢ğ‘– and\nitem ğ‘£ğ‘— when estimating the solidity score for the edge(ğ‘¢ğ‘–,ğ‘£ğ‘—). This\nis because that the key vectors are generated for relation modeling\nand can be considered as helpful information source for interac-\ntion solidity estimation. Furthermore, we propose to also take the\nhyperedge embeddings Z âˆˆRğ¾Ã—ğ‘‘ in Eq 4 into consideration, to\nintroduce global characteristics into the solidity labeling.\nConcretely, we first concatenate the multi-head key vectors and\napply a simple perceptron to eliminate the gap between user/item-\nhyperedge relation learning and user-item relation learning. For-\nmally, the updated user/item embeddings are calculated by:\nÎ“ğ‘– = ğœ™(ğ‘¢)Â©Â­\nÂ«\nğ»\f\f\f\n\f\f\f\nâ„=1\nkğ‘–,â„\nÂªÂ®\nÂ¬\n; Î“ğ‘— = ğœ™(ğ‘£)Â©Â­\nÂ«\nğ»\f\f\f\n\f\f\f\nâ„=1\nkğ‘—,â„\nÂªÂ®\nÂ¬\n(9)\nwhere ğœ™(ğ‘¢)(Â·),ğœ™(ğ‘£)(Â·)are the user- and item-specific perceptrons\nfor feature vector transformation, respectively. This projection is\nconducted with a meta network, using the user-side and the item-\nside hyperedge embeddings as input individually:\nğœ™(x; Z)= ğœ(Wx +b); W = V1Â¯z +W0; b = V2Â¯z +b0 (10)\nwhere x âˆˆRğ‘‘ denotes the input user/item key embedding (e.g. Î“ğ‘–,Î“ğ‘—).\nğœ™(Â·)being user-specific or item-specific depends on Z being user-\nside or item-side hyperedge embedding table. W âˆˆ Rğ‘‘Ã—ğ‘‘ and\nb âˆˆ Rğ‘‘ are the parameters generated by the meta network ac-\ncording to the input Z. In this way, the parameters are generated\nbased on the learned hyperedge embeddings, which encodes global\nfeatures of user- or item-specific hypergraphs. Â¯z âˆˆRğ‘‘ denotes\nSample ğ‘… edge pairs\nğ‘’1,1\nğ‘’1,2\nğ‘’ğ‘…,1\nğ‘’ğ‘…,2\nSolidity Labeling\nğ‘‰ ğ‘\nğœ™(ğ‘¢)\nğœ™(ğ‘£)\nMeta Network\nğ‘ ğ‘–ğ‘—\nÎ“ğ‘–\nÎ“j\nSolidity Predicting\nÃ—2\nâ‹…\n ğ‘ ğ‘–ğ‘—\nâ€¦\nâ„’ğ‘ ğ‘ â†’ â„’\ns  ğ‘ \ns  ğ‘ \nÃ—\nFigure 2: Workflow of the self-augmented learning.\nthe mean pooling of hyperedge embeddings (i.e. Â¯z = Ãğ¾\nğ‘˜=1 zğ‘˜/ğ¾).\nV1 âˆˆRğ‘‘Ã—ğ‘‘Ã—ğ‘‘,W0 âˆˆRğ‘‘Ã—ğ‘‘,V2 âˆˆRğ‘‘Ã—ğ‘‘,b0 âˆˆRğ‘‘ are the parameters\nof the meta network.\nWith the updated user/item embeddings Î“ğ‘–,Î“ğ‘—, SHT then calcu-\nlates the solidity labels for edge (ğ‘¢ğ‘–,ğ‘£ğ‘—)through a two-layer neural\nnetwork as follows:\nğ‘ ğ‘–,ğ‘— = sigm(dâŠ¤Â·ğœ(T Â·[Î“ğ‘–; Î“ğ‘—]+Î“ğ‘– +Î“ğ‘— +c)) (11)\nwhere ğ‘ ğ‘–,ğ‘— âˆˆR denotes the solidity score given by the hypergraph\ntransformer. sigm(Â·)denotes the sigmoid function which limits the\nvalue range of ğ‘ ğ‘–,ğ‘—. d âˆˆRğ‘‘,T âˆˆRğ‘‘Ã—2ğ‘‘,c âˆˆRğ‘‘ are the parametric\nmatrices or vectors. [Â·; Â·]denotes the vector concatenation.\n3.3.2 Pair-wise Solidity Ranking. To enhance the optimization\nof topological embeddings, SHT employs an additional objective\nfunction to better estimate the edge solidity using the above ğ‘ ğ‘–,ğ‘— as\ntraining labels. In particular,ğ‘…pairs of edges{(ğ‘’1,1,ğ‘’1,2),...,(ğ‘’ğ‘…,1,ğ‘’ğ‘…,2)}\nfrom the observed edges in Gare sampled, and SHT gives predic-\ntions on the solidity using the topology-aware embeddings. The\npredictions are then updated by optimizing the loss below:\nLğ‘ ğ‘ =\nğ‘…âˆ‘ï¸\nğ‘Ÿ=1\nmax(0,1 âˆ’(Ë†ğ‘ ğ‘¢ğ‘Ÿ,1,ğ‘£ğ‘Ÿ,1 âˆ’Ë†ğ‘ ğ‘¢ğ‘Ÿ,2,ğ‘£ğ‘Ÿ,2 )(ğ‘ ğ‘¢ğ‘Ÿ,1,ğ‘£ğ‘Ÿ,1 âˆ’ğ‘ ğ‘¢ğ‘Ÿ,2,ğ‘£ğ‘Ÿ,2 ));\nË†ğ‘ ğ‘¢ğ‘Ÿ,1,ğ‘£ğ‘Ÿ,1 = eâŠ¤\nğ‘¢ğ‘Ÿ,1 eğ‘£ğ‘Ÿ,1 ; Ë†ğ‘ ğ‘¢ğ‘Ÿ,2,ğ‘£ğ‘Ÿ,2 = eâŠ¤\nğ‘¢ğ‘Ÿ,2 eğ‘£ğ‘Ÿ,2 (12)\nwhere Lğ‘ ğ‘ denotes the loss function for our self-augmented learn-\ning. Ë†ğ‘ ğ‘¢ğ‘Ÿ,1,ğ‘£ğ‘Ÿ,1 ,Ë†ğ‘ ğ‘¢ğ‘Ÿ,2,ğ‘£ğ‘Ÿ,2 denote the solidity scores predicted by the\ntopology-aware embedding, while ğ‘ ğ‘¢ğ‘Ÿ,1,ğ‘£ğ‘Ÿ,1 ,ğ‘ ğ‘¢ğ‘Ÿ,2,ğ‘£ğ‘Ÿ,2 denote the edge\nsolidity labels given by the hypergraph transformer. Here ğ‘¢ğ‘Ÿ,1 and\nğ‘£ğ‘Ÿ,1 represent the user and the item node of edge ğ‘’ğ‘Ÿ,1, respectively.\nIn the above loss function, the label term (ğ‘ ğ‘¢ğ‘Ÿ,1,ğ‘£ğ‘Ÿ,1 âˆ’ğ‘ ğ‘¢ğ‘Ÿ,2,ğ‘£ğ‘Ÿ,2 )\nnot only indicates the sign of the difference (i.e. which one of ğ‘’ğ‘Ÿ,1\nand ğ‘’ğ‘Ÿ,2 is bigger), but also indicates how bigger the difference is.\nIn this way, if the solidity labels for a pair of edges given by the\nhypergraph transformer are close to each other, then the gradients\non the predicted solidity scores given by the topology-aware embed-\nding will become smaller. In this way, SHT is self-augmented with\nan adaptive ranking task, to further refine the low-level topology-\naware embeddings using the high-level embeddings encoded from\nthe hypergraph transformer.\n3.4 Model Learning\nWe train our SHT by optimizing the main task on implicit feedback\ntogether with the self-augmented ranking task. Specifically, ğ‘…â€²\npositive edges (observed in G) and ğ‘…â€²negative edges (not observed\nTable 1: Statistical information of the experimental datasets.\nStat. Yelp Gowalla Tmall\n# Users 29601 50821 47939\n# Items 24734 24734 41390\n# Interactions 1517326 1069128 2357450\nDensity 2.1 Ã—10âˆ’3 4.0 Ã—10âˆ’4 1.2 Ã—10âˆ’3\nin G) are sampled {(ğ‘’1,1,ğ‘’1,2),(ğ‘’2,1,ğ‘’2,2)...,(ğ‘’ğ‘…â€²,1,ğ‘’ğ‘…â€²,2)}, where ğ‘’ğ‘Ÿ,1\nand ğ‘’ğ‘Ÿ,2 are individual positive and negative sample, respectively.\nThe following pair-wise marginal objective function is applied:\nL=\nğ‘…â€²\nâˆ‘ï¸\nğ‘Ÿ=1\nmax(0,1 âˆ’(ğ‘ğ‘¢ğ‘Ÿ,1,ğ‘£ğ‘Ÿ,1 âˆ’ğ‘ğ‘¢ğ‘Ÿ,2,ğ‘£ğ‘Ÿ,2 ))+ ğœ†1Lsa +ğœ†2 âˆ¥Î˜âˆ¥2\nF (13)\nwhere ğ‘ğ‘¢ğ‘Ÿ,1,ğ‘£ğ‘Ÿ,1 and ğ‘ğ‘¢ğ‘Ÿ,2,ğ‘£ğ‘Ÿ,2 are prediction scores for edge ğ‘’ğ‘Ÿ,1 and\nğ‘’ğ‘Ÿ,2, respectively. ğœ†1 and ğœ†2 are weights for different loss terms.\nâˆ¥Î˜âˆ¥2\nF denotes the ğ‘™2 regularization term for weight decay.\n3.4.1 Complexity Analysis. We compare our SHT framework\nwith several state-of-the-art approaches on collaborative filtering,\nincluding graph neural architectures (e.g. NGCF [26], LightGCN [6])\nand hypergraph neural networks(e.g. DHCF [11]). As discussed be-\nfore, our hypergraph transformer enables the complexity reduction\nfrom ğ‘‚(ğ¾Ã—(ğ¼+ğ½)Ã—ğ‘‘)to ğ‘‚((ğ¼+ğ½+ğ¾)Ã—ğ‘‘2). As the typical value\nof the number of hyperedge ğ¾ is much smaller than the number of\nnodes ğ¼ and ğ½, but larger than the embedding size ğ‘‘, the latter term\nis smaller and close toğ‘‚((ğ¼+ğ½)Ã—ğ‘‘2). In comparison, the complexity\nfor a typical graph neural architecture is ğ‘‚(ğ‘€Ã—ğ‘‘+(ğ¼ +ğ½)Ã—ğ‘‘2).\nSo our hypergraph transformer network can achieve comparable\nefficiency as GNNs, such as graph convolutional networks in model\ninference. The existing hypergraph-based methods commonly pre-\nprocess high-order node relations to construct hypergraphs, which\nmakes them usually more complex than the graph neural networks.\nIn our SHT, the self-augmented task with the lossLsa has the same\ncomplexity with the original main task.\n4 EVALUATION\nTo evaluate the effectiveness of our SHT, our experiments are de-\nsigned to answer the following research questions:\nâ€¢RQ1: How does our SHT perform by comparing to strong base-\nline methods of different categories under different settings?\nâ€¢RQ2: How do the key components of SHT (e.g., the hypergraph\nmodeling, the transformer-like information propagation) con-\ntribute to the overall performance of SHT on different datasets?\nâ€¢RQ3: How well can our SHT handle noisy and sparse data, as\ncompared to baseline methods?\nâ€¢RQ4: In real cases, can the designed the self-supervised learning\nmechanism in SHT provide useful interpretations?\n4.1 Experimental Settings\n4.1.1 Experimental Datasets. The experiments are conducted\non three datasets collected from real-world applications, i.e., Yelp,\nGowalla and Tmall. The statistics of them are shown in Table 1.\nâ€¢Yelp: This commonly-used dataset contains user ratings on busi-\nness venues collected from Yelp. Following other papers on im-\nplicit feedback [ 9], we treat usersâ€™ rated venues as interacted\nitems and treat unrated venues as non-interacted items.\nâ€¢Gowalla: It contains usersâ€™ check-in records on geographical\nlocations obtained from Gowalla. This evaluation dataset is gen-\nerated from the period between 2016 and 2019.\nâ€¢Tmall: This E-commerce dataset is released by Tmall, containing\nusersâ€™ behaviors for online shopping. We collect the page-view\ninteractions during December in 2017.\n4.1.2 Evaluation Protocols. Following the recent collaborative\nfiltering models [6, 31], we split the datasets by 7:2:1 into training,\nvalidation and testing sets. We adopt all-rank evaluation protocol.\nWhen testing a user, the positive items in the test set and all the\nnon-interacted items are tested and ranked together. We employ\nthe commonly-used Recall@N and Normalized Discounted Culmu-\nlative Gain (NDCG)@N as evaluation metrics for recommendation\nperformance evaluation [19, 26]. N is set as 20 by default.\n4.1.3 Compared Baseline Methods. We evaluate our SHT by\ncomparing it with 15 baselines from different research lines for\ncomprehensive evaluation.\nTraditional Factorization-based Technique.\nâ€¢BiasMF [13]: This method augments matrix factorization with\nuser and item bias vectors to enhance user-specific preferences.\nNeural Factorization Method.\nâ€¢NCF [7]: This method replaces the dot-product in conventional\nmatrix factorization with multi-layer neural networks. Here, we\nadopt the NeuMF variant for comparison.\nAutoencoder-based Collaborative Filtering Approach.\nâ€¢AutoR [21]: It improves user/item representations with a three-\nlayer autoencoder trained under a behavior reconstruction task.\nGraph Neural Networks for Recommendation.\nâ€¢GCMC [1]: This is one of the pioneering work to apply graph\nconvolutional networks (GCNs) to the matrix completion task.\nâ€¢PinSage [38]: It applies random sampling in graph convolutional\nframework to study the collaborative filtering task .\nâ€¢NGCF [26]: This graph convolution-based approach addition-\nally takes source-target representation interaction learning into\nconsideration when designing its graph encoder.\nâ€¢STGCN [40]: The model combines conventional graph convolu-\ntional encoders with graph autoencoders to improve the model\nrobustness against sparse and cold-start samples.\nâ€¢LightGCN [6]: This work conducts in-depth analysis to study\nthe effectiveness of modules in standard GCN for collaborative\ndata, and proposes a simplified GCN model for recommendation.\nâ€¢GCCF [3]: This is another method which simplifies the GCNs by\nremoving the non-linear transformation. In GCCF, the effective-\nness of residual connections across graph iterations is validated.\nDisentangled Graph Model for Recommendation.\nâ€¢DGCF [28]: It disentangles user interactions into multiple latent\nintentions to model user preference in a fine-grained way.\nHypergraph-based Neural Collaborative Filtering.\nâ€¢HyRec [25]: This is a sequential collaborative model that learns\nitem-wise high-order relations with hypergraphs.\nâ€¢DHCF [11]: This model adopts dual-channel hypergraph neural\nnetworks for both users and items in collaborative filtering.\nRecommenders enhanced by Self-Supervised Learning .\nâ€¢MHCN [39]: This model maximizes the mutual information be-\ntween node embeddings and global readout representations, to\nregularize the representation learning for interaction graph.\nâ€¢SLRec [37]: This approach employs the contrastive learning\nbetween the node features as regularization terms to enhance\nthe existing recommender systems.\nâ€¢SGL [31]: This model conducts data augmentation through ran-\ndom walk and feature dropout to generate multiple views. It\nenhances LightGCN with self-supervised contrastive learning.\n4.1.4 Implementation Details. We implement our SHT using\nTensorFlow and use Adam as the optimizer for model training with\nthe learning rate of 1ğ‘’âˆ’3 and 0.96 epoch decay ratio. The models\nare configured with 32 embedding dimension size, and the number\nof graph neural layers is searched from {1,2,3}. The weights ğœ†1,ğœ†2\nfor regularization terms are selected from{ğ‘Ã—10âˆ’ğ‘¥ : ğ‘ âˆˆ{1,3},ğ‘¥ âˆˆ\n{2,3,4,5}}. The batch size is selected from {32,64,128,256,512}.\nThe rate for dropout is tuned from {0.25,0.5,0.75}. For our model,\nthe number of hyperedges is set as 128 by default. Detailed hyper-\nparameter settings can be found in our released source code.\n4.2 Overall Performance Comparison (RQ1)\nIn this section, we validate the effectiveness of our SHT framework\nby conducting the overall performance evaluation on the three\ndatasets and comparing SHT with various baselines. We also re-\ntrain SHT and the best-performed baseline (i.e. SGL) for 10 times\nto compute p-values. The results are presented in Table 2.\nâ€¢Performance Superiority of SHT . As shown in the results,\nSHT achieves best performance compared to the baselines un-\nder both top-20 and top-40 settings. The t-tests also validate the\nsignificance of performance improvements. We attribute the supe-\nriority to: i) Based on the hypergraph transformer, SHT not only\nrealizes global message passing among semantically-relevent\nusers/items, but also refines the hypergraph structure using the\nmulti-head attention. ii) The global-to-local self-augmented learn-\ning distills knowledge from the high-level hypergraph transform-\ners to regularize the topology-aware embedding learning, and\nthus alleviate the data noise issue.\nâ€¢Effectiveness of Hypergraph Architecture . Among the state-\nof-the-art baselines, approaches that based on hypergraph neural\nnetworks (HGNN) (i.e., HyRec and DHCF) outperforms most of\nthe GNN-based baselines (e.g., GCMC, PinSage, NGCF, STGCN).\nThis sheds lights on the insufficiency of conventional GNNs in\ncapturing high-order and global graph connectivity. Meanwhile,\nour SHT is configured with transformer-like hypergraph struc-\nture learning which further excavates the potential of HGNN in\nglobal relation learning. In addition, most existing hypergraph-\nbased models utilize user or item nodes as hyperedges, while our\nSHT adopts latent hyperedges which not only enables automatic\ngraph dependency modeling, but also avoids pre-calculating the\nlarge-scale high-order relation matrix.\nâ€¢Effectiveness of Self-Augmented Learning . From the evalu-\nation results, we can observe that self-supervised learning ob-\nviously improves existing CF frameworks (e.g., MHCN, SLRec,\nSGL). The improvements can be attributed to incorporating the\naugmented learning task, which provides the beneficial regular-\nization on the parameter learning based on the input data itself.\nTable 2: Performance comparison on Yelp, MovieLens, Amazon datasets in terms of Recall and NDCG.\nData Metric BiasMF NCF AutoR GCMC PinSage NGCF STGCN LightGCN GCCF DGCF HyRec DHCF MHCN SLRec SGL SHT p-val.\nYelp\nRecall@20 0.0190 0.0252 0.0259 0.0266 0.0345 0.0294 0.0309 0.0482 0.0462 0.0466 0.0472 0.0449 0.0503 0.0476 0.0526 0.0651 9.3ğ‘’âˆ’7\nNDCG@20 0.0161 0.0202 0.0210 0.0251 0.0288 0.0243 0.0262 0.0409 0.0398 0.0395 0.0395 0.0381 0.0424 0.0398 0.0444 0.0546 9.1ğ‘’âˆ’8\nRecall@40 0.0371 0.0487 0.0504 0.0585 0.0599 0.0522 0.0504 0.0803 0.0760 0.0774 0.0791 0.0751 0.0826 0.0821 0.0869 0.1091 4.1ğ‘’âˆ’7\nNDCG@40 0.0227 0.0289 0.0301 0.0373 0.0385 0.0330 0.0332 0.0527 0.0508 0.0511 0.0522 0.0493 0.0544 0.0541 0.0571 0.0709 2.2ğ‘’âˆ’7\nGowalla\nRecall@20 0.0196 0.0171 0.0239 0.0301 0.0576 0.0552 0.0369 0.0985 0.0951 0.0944 0.0901 0.0931 0.0955 0.0925 0.1030 0.1232 5.3ğ‘’âˆ’7\nNDCG@20 0.0105 0.0106 0.0132 0.0181 0.0373 0.0298 0.0217 0.0593 0.0535 0.0522 0.0498 0.0505 0.0574 0.0581 0.0623 0.0731 6.3ğ‘’âˆ’7\nRecall@40 0.0346 0.0216 0.0343 0.0427 0.0892 0.0810 0.0542 0.1431 0.1392 0.1401 0.1306 0.1356 0.1393 0.1305 0.1500 0.1804 1.5ğ‘’âˆ’7\nNDCG@40 0.0145 0.0118 0.0160 0.0212 0.0417 0.0367 0.0262 0.0710 0.0684 0.0671 0.0669 0.0660 0.0689 0.0680 0.0746 0.0881 3.2ğ‘’âˆ’7\nTmall\nRecall@20 0.0103 0.0082 0.0103 0.0103 0.0202 0.0180 0.0146 0.0225 0.0209 0.0235 0.0233 0.0156 0.0203 0.0191 0.0268 0.0387 4.3ğ‘’âˆ’9\nNDCG@20 0.0072 0.0059 0.0072 0.0072 0.0136 0.0123 0.0105 0.0154 0.0141 0.0163 0.0160 0.0108 0.0139 0.0133 0.0183 0.0262 4.9ğ‘’âˆ’9\nRecall@40 0.0170 0.0140 0.0174 0.0159 0.0345 0.0310 0.0245 0.0378 0.0356 0.0394 0.0350 0.0261 0.0340 0.0301 0.0446 0.0645 4.0ğ‘’âˆ’9\nNDCG@40 0.0095 0.0079 0.0097 0.0086 0.0186 0.0168 0.0140 0.0208 0.0196 0.0218 0.0199 0.0145 0.0188 0.0171 0.0246 0.0352 3.5ğ‘’âˆ’9\nSpecifically, MHCN regularizes the node embeddings according\nto a read-out global information of the holistic graph. This ap-\nproach may be too strict for large graphs containing many local\nsub-graphs with their own characteristics. Meanwhile, SLRec\nand SGL adopt stochastic data augmentation to construct mul-\ntiple data views, and conduct contrastive learning to capture\nthe invariant feature from the corrupted views. In comparison\nto the above methods, the self-augmentation in our SHT has\nmainly two merits: i) SHT adopts meta networks to generate\nglobal-structure-aware mapping functions for domain adaption,\nwhich adaptively alleviates the gap between local and global\nfeature spaces. ii) Our self-supervised approach does not depend\non random masking, which may drop important information to\nhinder representation learning. Instead, SHT self-augment the\nmodel training by transferring knowledge from the high-level\nhypergraph embeddings to the low-level topology-aware embed-\nding. The superior performance of SHT compared to the baseline\nself-supervised approaches validates the effectiveness of our new\ndesign of self-supervised learning paradigm.\n4.3 Model Ablation Test (RQ2)\nTo validate the effectiveness of the proposed modules, we individ-\nually remove the applied techniques in the three major parts of\nSHT (i.e., the local graph structure capturing, the global relation\nlearning, and the local-global self-augmented learning). The vari-\nants are re-trained for test on the three datasets. Both prominent\ncomponents (e.g., the entire hypergraph transformer) and small\nmodules (e.g., the deep hyperedge feature extraction) of SHT are\nablated. The results can be seen in Table 3. We have the following\nmajor conclusions:\nâ€¢Removing either the graph topology-aware embedding module\nor the hypergraph transformer ( i.e., -Pos and -Hyper) severely\ndamage the performance of SHT in all cases. This result suggests\nthe necessity of local and global relation learning, and validates\nthe effectiveness of our GCN-based topology-aware embedding\nand hypergraph transformer networks.\nâ€¢The variant without self-augmented learning (i.e. -SAL) yields\nobvious performance degradation in all cases, which validates the\npositive effect of our augmented global-to-local knowledge trans-\nferring. The effect of our meta-network-based domain adaption\ncan also be observed in the variant -Meta.\nâ€¢We also ablate the components in our hypergraph neural network.\nSpecifically, we substitute the hypergraph transformer with in-\ndependent node-hypergraph matrices (-Trans), and we remove\nthe deep hyperedge feature extraction to keep only one layer of\nTable 3: Ablation study on key components of SHT.\nCategory Data Yelp Gowalla Tmall\nVariants Recall NDCG Recall NDCG Recall NDCG\nLocal -Pos 0.0423 0.0352 0.0816 0.0487 0.0218 0.0247\nGlobal\n-Trans 0.0603 0.0504 0.0999 0.0608 0.0321 0.0206\n-DeepH 0.0645 0.0540 0.1089 0.0634 0.0347 0.0234\n-HighH 0.0598 0.0497 0.1091 0.0646 0.0336 0.0227\n-Hyper 0.0401 0.0346 0.0879 0.0531 0.0209 0.0144\nSAL -Meta 0.0615 0.0526 0.1108 0.0717 0.0375 0.0255\n-SAL 0.0602 0.0519 0.1099 0.0699 0.0363 0.0251\nSHT 0.0651 0.0546 0.1232 0.0731 0.0387 0.0262\nhyperedges (-DeepH). Additionally, we remove the high-order hy-\npergraph iterations (-HighH). From the results we can conclude\nthat: i) Though using much less parameters, the transformer-like\nhypergraph attention works much better than learning hypergraph-\nbased user/item dependencies. ii) The deep hyperedge layers in-\ndeed make contribution to the global relation learning through\nnon-linear feature transformation. iii) Though our hypergraph\ntransformer could connect any users/items using learnable hyper-\nedges, high-order iterations still improve the model performance\nthrough the iterative hypergraph propagation.\n4.4 Model Robustness Test (RQ3)\n4.4.1 Performance w.r.t. Data Noise Degree. In this section,\nwe first investigate the robustness of SHT against the data noise.\nTo evaluate the influence of noise degrees on model performance,\nwe randomly substitute different percentage of real edges with\nrandomly-generated fake edges, and re-train the model using the\ncorrupted graphs as input. Concretely 5%, 10%, 15%, 20%, 25% of\nthe edges are replaced with noisy signals in our experiments. We\ncompare SHT with MHCN and LightGCN, which are recent recom-\nmenders based on HGNN and GNN, respectively. To better study\nthe effect of noise on performance degradation, we evaluate the\nrelative performance compared to the performance on original data.\nThe results are shown in Fig 3. We can observe that our method\npresents smaller performance degradation in most cases compared\nto the baselines. We ascribe this observation to two reasons: i) The\nglobal relation learning and information propagation by our hy-\npergraph transformer alleviate the noise effect caused by the raw\nobserved user-item interactions. ii) The self-augmented learning\ntask distills knowledge from the refined hypergraph embeddings,\nso as to refine the graph-based embeddings. In addition, we can\nobserve that the relative performance degradation on the Gowalla\ndata is more obvious compared with other two datasets. This is\nbecause the noisy data has larger influence for the performance on\nthe sparsest Gowalla dataset.\n0.0 0.05 0.10 0.15 0.20 0.25\nNoise Ratio\n0.80\n0.85\n0.90\n0.95\n1.00Relative Recall\nMHCN LightGCN Ours\n0.0 0.05 0.10 0.15 0.20 0.25\nNoise Ratio\n0.80\n0.85\n0.90\n0.95\n1.00Relative NDCG\nMHCN LightGCN Ours\n(a) Yelp data\n0.0 0.05 0.10 0.15 0.20 0.25\nNoise Ratio\n0.7\n0.8\n0.9\n1.0Relative Recall\nMHCN LightGCN Ours\n0.0 0.05 0.10 0.15 0.20 0.25\nNoise Ratio\n0.7\n0.8\n0.9\n1.0Relative NDCG\nMHCN LightGCN Ours\n(b) Gowalla data\n0.0 0.05 0.10 0.15 0.20 0.25\nNoise Ratio\n0.7\n0.8\n0.9\n1.0Relative Recall\nMHCN LightGCN Ours\n0.0 0.05 0.10 0.15 0.20 0.25\nNoise Ratio\n0.7\n0.8\n0.9\n1.0Relative NDCG\nMHCN LightGCN Ours\n(c) Tmall data\nFigure 3: Relative performance degradation w.r.t noise ratio.\n4.4.2 Performance w.r.t. Data Sparsity. We further study the\ninfluence of data sparsity from both user and item side on model per-\nformance. We compare our SHT with two representative baselines\nLightGCN and SGL. Multiple user and item groups are constructed\nin terms of their number of interactions in the training set. For\nexample, the first group in the user-side experiments contains users\ninteracting with 15-20 items, and the first group in the item-side\nexperiment contains items interacting with 0-8 users.\nIn Fig 4, we present both the recommendation accuracy and\nperformance difference between our SHT and compared methods.\nFrom the results, we have the following observations: i) The supe-\nrior performance of SHT is consistent on datasets with different\nsparsity degrees, which validates the robustness of SHT in handling\nsparse data for both users and items. ii) The sparsity of item interac-\ntion vectors has obviously larger influence on model performance\nfor all the methods. This indicates that the collaborative pattern\nof items are more difficult to model compared to users, such that\nmore neighbors usually result in better representations. iii) In the\nitem-side experiments, the performance gap on the middle sub-\ndatasets is larger compared to the gap on the densest sub-dataset.\nThis suggests the better anti-sparsity capability of SHT for effec-\ntively transferring knowledge among dense samples and sparse\nsamples with our proposed hypergraph transformer.\n4.5 Case Study (RQ4)\nIn this section, we analyze the concrete data instances to investigate\nthe effect of our hypergraph transformer with self-augmentation\nfrom two aspects: i) Is the hypergraph-based dependency modeling\nin SHT capable of learning useful node-wise relations, especially\nthe implicit relations unknown to the training process? ii) Is the self-\naugmented learning with meta networks in SHT able to differentiate\nnoisy edges in the training data? To this end, we select three users\n0-8 8-12 12-16 16-20 20-24\nSparsity Degree\n0.0\n0.5\n1.0\n1.5Recall@40 (1e-2)\n0.0\n0.5\n1.0\n1.5\nRecall Diff. (1e-2)\nLightGCN SGL Ours\n0-8 8-12 12-16 16-20 20-24\nSparsity Degree\n0.0\n0.1\n0.2\n0.3NDCG@40 (1e-2)\n0.0\n0.1\n0.2\n0.3\nNDCG Diff. (1e-2)\nLightGCN SGL Ours\n(a) Performance w.r.t. item interaction numbers\n15-20 20-25 25-30 30-35 35-40\nSparsity Degree\n0.0\n0.5\n1.0\n1.5Recall@40 (1e-1)\n0\n1\n2\n3\nRecall Diff (1e-1).\nLightGCN SGL Ours\n15-20 20-25 25-30 30-35 35-40\nSparsity Degree\n0.0\n0.2\n0.4\n0.6NDCG@40 (1e-1)\n0.0\n0.5\n1.0\nNDCG Diff (1e-1).\nLightGCN SGL Ours\n(b) Performance w.r.t. user interaction numbers\nFigure 4: Performance w.r.t. different data sparsity degrees\non Gowalla data. Lines present Recall@40 and NDCG@40\nvalues, and bars shows performance differences between\nbaselines and our SHT with corresponding colors.\nwith fair number of interactions from Tmall dataset. The interacted\nitems are visualized as colored circles representing their trained\nembeddings (refer to the supplementary material for details about\nthe visualization algorithm). The results are shown in Fig 5. For the\nabove questions, we have the following observations:\nâ€¢Implicit relation learning . Even if the items are interacted by\nsame users, their learned embeddings are usually divided into\nmultiple groups with different colors. This may relate to usersâ€™\nmultiple interests. To study the differences between the item\ngroups, we present additional item-wise relations that are not\nutilized in the training process. Specifically, we connect items\nbelonging to same categories, and items co-interacted by same\nusers. Note that only view data is used in model training, so inter-\nactions in other behaviors are unknown to the trained model. It\nis clear that there exist dense implicit correlations among same-\ncolored items (e.g., the green items of user (a), the purple items\nof user (b), and the orange items of user (c)). Meanwhile, there\nare much less implicit relations between items of different colors.\nThis results shows the capability of SHT in identifying useful im-\nplicit relations, which we ascribe to the global structure learning\nof our hypergraph transformer.\nâ€¢Noise discrimination. Furthermore, we show the solidity scores\nğ‘  estimated from our self-augmented learning, for the user-item\nrelations in Fig 5. We also show the normalized values of some\nnotable edges in the corresponding circles ( e.g., edges of item\n10202 and 6508 are labeled with 2.3 and 1.9). The red values are\nanomalously low, which may indicates noise. The black values\nare the lowest and highest solidity scores for edges except the\nanomalous ones. By analyzing user (a), we can regard the yellow\nand green items as two interests of user (a) as they are correlated\nin terms of their learned embeddings. In contrast, item 6508 and\n10202 have few relations to other interacted items of user (a),\nwhich may not reflect the real interactive patterns of this user.\nThus, the model may consider this two edges as noisy interac-\ntions. Similar cases can be found for user (b), where item 2042 has\nfew connections to the other items and show difference with the\n2.3\n1.9\n3.6\n4.8\n(a)\n3.3\n5.7\n4.7\n(b)\nview-cart\n5.7\n4.6\n(c)\nsame category co-interacted low s scores\n6508\n10202\n2042\nFigure 5: Case study on inferring implicit item-wise rela-\ntions and discriminating potential noise edges. Circles de-\nnote items interacted by the centric users, and their learned\nembeddings are visualized with colors. Implicit item-wise\nrelations not utilized during model training are presented\nby green and blue lines. The type of co-interactions are also\nlabeled ( e.g., view-cart denotes viewed and added-to-cart by\nsame users). Also, the inferred solidity scores ğ‘  are shown\non the circles, where red values are anomalously low scores\nindicating noisy edges.\nembedding color. It is labeled with lowğ‘ scores and considered as\nnoise by SHT. The results show the effective noise discrimination\nability of the self-augmented learning in SHT, which recalibrate\nthe topology-aware embedding using global information encoded\nfrom hypergraph transformer.\n5 CONCLUSION\nIn this work, we explore the self-supervised recommender systems\nwith an effective hypergraph transformer network. We propose a\nnew recommendation framework SHT, which seeks better user-\nitem interaction modeling with self-augmented supervision signals.\nOur SHT model improves the robustness of graph-based recom-\nmender systems against noise perturbation. In our experiments,\nwe achieved better recommendation results on real-world datasets.\nOur future work would like to extend our SHT to explore the disen-\ntangled user intents with diverse user-item relations for encoding\nmulti-dimensional user preferences.\nACKNOWLEDGMENTS\nThis research work is supported by the research grants from the De-\npartment of Computer Science & Musketeers Foundation Institute\nof Data Science at the University of Hong Kong.\nREFERENCES\n[1] Rianne van den Berg, Thomas N Kipf, and Max Welling. 2017. Graph convolu-\ntional matrix completion. In KDD.\n[2] Jingyuan Chen, Hanwang Zhang, Xiangnan He, Liqiang Nie, Wei Liu, and Tat-\nSeng Chua. 2017. Attentive collaborative filtering: Multimedia recommendation\nwith item-and component-level attention. In SIGIR. 335â€“344.\n[3] Lei Chen, Le Wu, Richang Hong, Kun Zhang, and Meng Wang. 2020. Revisiting\nGraph Based Collaborative Filtering: A Linear Residual Graph Convolutional\nNetwork Approach. In AAAI, Vol. 34. 27â€“34.\n[4] Yudong Chen, Xin Wang, Miao Fan, Jizhou Huang, Shengwen Yang, et al. 2021.\nCurriculum meta-learning for next POI recommendation. In KDD. 2692â€“2702.\n[5] Ruocheng Guo, Xiaoting Zhao, Adam Henderson, Liangjie Hong, and Huan Liu.\n2020. Debiasing grid-based product search in e-commerce. In KDD. 2852â€“2860.\n[6] Xiangnan He, Kuan Deng, Xiang Wang, et al. 2020. Lightgcn: Simplifying and\npowering graph convolution network for recommendation. In SIGIR. 639â€“648.\n[7] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng\nChua. 2017. Neural collaborative filtering. In WWW. 173â€“182.\n[8] Chao Huang. 2021. Recent advances in heterogeneous relation learning for\nrecommendation. arXiv preprint arXiv:2110.03455 (2021).\n[9] Chao Huang, Huance Xu, Yong Xu, Peng Dai, Lianghao Xiao, Mengyin Lu, Liefeng\nBo, Hao Xing, Xiaoping Lai, and Yanfang Ye. 2021. Knowledge-aware coupled\ngraph neural network for social recommendation. In AAAI.\n[10] Dasol Hwang, Jinyoung Park, Sunyoung Kwon, KyungMin Kim, Jung-Woo Ha,\nand Hyunwoo J Kim. 2020. Self-supervised auxiliary learning with meta-paths\nfor heterogeneous graphs. NIPS 33 (2020), 10294â€“10305.\n[11] Shuyi Ji, Yifan Feng, Rongrong Ji, Xibin Zhao, Wanwan Tang, and Yue Gao. 2020.\nDual channel hypergraph collaborative filtering. In KDD. 2020â€“2029.\n[12] Minguk Kang and Jaesik Park. 2020. Contragan: Contrastive learning for condi-\ntional image generation. NIPS 33 (2020), 21357â€“21369.\n[13] Yehuda Koren, Robert Bell, et al. 2009. Matrix factorization techniques for rec-\nommender systems. Computer 8 (2009), 30â€“37.\n[14] Adit Krishnan, Ashish Sharma, et al. 2018. An adversarial approach to improve\nlong-tail performance in neural collaborative filtering. In CIKM. 1491â€“1494.\n[15] Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. 2018.\nVariational autoencoders for collaborative filtering. In WWW. 689â€“698.\n[16] Xiao Liu, Fanjin Zhang, Zhenyu Hou, Li Mian, Zhaoyu Wang, Jing Zhang, and\nJie Tang. 2021. Self-supervised learning: Generative or contrastive. TKDE (2021).\n[17] Yiyu Liu, Qian Liu, Yu Tian, et al. 2021. Concept-Aware Denoising Graph Neural\nNetwork for Micro-Video Recommendation. In CIKM. 1099â€“1108.\n[18] Zhen Peng, Wenbing Huang, Minnan Luo, et al . 2020. Graph representation\nlearning via graphical mutual information maximization. In WWW. 259â€“270.\n[19] Ruiyang Ren, Zhaoyang Liu, Yaliang Li, Wayne Xin Zhao, Hui Wang, Bolin\nDing, and Ji-Rong Wen. 2020. Sequential recommendation with self-attentive\nmulti-adversarial network. In SIGIR. 89â€“98.\n[20] Steffen Rendle, Walid Krichene, Li Zhang, and John Anderson. 2020. Neural\ncollaborative filtering vs. matrix factorization revisited. In Recsys. 240â€“248.\n[21] Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie. 2015.\nAutorec: Autoencoders meet collaborative filtering. In WWW. 111â€“112.\n[22] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.\n2019. BERT4Rec: Sequential recommendation with bidirectional encoder repre-\nsentations from transformer. In CIKM. 1441â€“1450.\n[23] Petar Velickovic, William Fedus, William L Hamilton, Pietro LiÃ², Yoshua Bengio,\nand R Devon Hjelm. 2019. Deep Graph Infomax.. In ICLR.\n[24] Ivan VuliÄ‡, Edoardo Maria Ponti, Anna Korhonen, and Goran GlavaÅ¡. 2021. LexFit:\nLexical fine-tuning of pretrained language models. In ACL. 5269â€“5283.\n[25] Jianling Wang, Kaize Ding, Liangjie Hong, Huan Liu, and James Caverlee. 2020.\nNext-item recommendation with sequential hypergraphs. In SIGIR. 1101â€“1110.\n[26] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019.\nNeural Graph Collaborative Filtering. In SIGIR.\n[27] Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S\nYu. 2019. Heterogeneous graph attention network. In WWW. 2022â€“2032.\n[28] Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua.\n2020. Disentangled graph collaborative filtering. In SIGIR. 1001â€“1010.\n[29] Yifan Wang, Suyao Tang, et al. 2020. Disenhan: Disentangled heterogeneous\ngraph attention network for recommendation. In CIKM. 1605â€“1614.\n[30] Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, et al . 2019.\nSimplifying graph convolutional networks. In ICML. PMLR, 6861â€“6871.\n[31] Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, et al.\n2021. Self-supervised graph learning for recommendation. In SIGIR. 726â€“735.\n[32] Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Xiyue Zhang, Hongsheng Yang,\nJian Pei, and Liefeng Bo. 2021. Knowledge-enhanced hierarchical graph trans-\nformer network for multi-behavior recommendation. InAAAI, Vol. 35. 4486â€“4493.\n[33] Lianghao Xia, Chao Huang, Yong Xu, Jiashu Zhao, Dawei Yin, and Jimmy Xiangji\nHuang. 2022. Hypergraph Contrastive Collaborative Filtering. arXiv preprint\narXiv:2204.12200 (2022).\n[34] Lianghao Xia, Yong Xu, Chao Huang, Peng Dai, and Liefeng Bo. 2021. Graph\nmeta network for multi-behavior recommendation. In SIGIR. 757â€“766.\n[35] Haoran Yang, Hongxu Chen, Lin Li, et al. 2021. Hyper Meta-Path Contrastive\nLearning for Multi-Behavior Recommendation. In ICDM. IEEE, 787â€“796.\n[36] Yuhao Yang, Chao Huang, Lianghao Xia, and Chenliang Li. 2022. Knowledge\nGraph Contrastive Learning for Recommendation.arXiv preprint arXiv:2205.00976\n(2022).\n[37] Tiansheng Yao, Xinyang Yi, Derek Zhiyuan Cheng, et al. 2021. Self-supervised\nLearning for Large-scale Item Recommendations. In CIKM. 4321â€“4330.\n[38] Rex Ying, Ruining He, Kaifeng Chen, et al . 2018. Graph convolutional neural\nnetworks for web-scale recommender systems. In KDD. 974â€“983.\n[39] Junliang Yu, Hongzhi Yin, Jundong Li, Qinyong Wang, Nguyen Quoc Viet Hung,\nand Xiangliang Zhang. 2021. Self-Supervised Multi-Channel Hypergraph Convo-\nlutional Network for Social Recommendation. In WWW. 413â€“424.\n[40] Jiani Zhang, Xingjian Shi, Shenglin Zhao, et al . 2019. Star-gcn: Stacked and\nreconstructed graph convolutional networks for recommender systems. InIJCAI.\n[41] Yin Zhang, Derek Zhiyuan Cheng, Tiansheng Yao, Xinyang Yi, Lichan Hong,\nand Ed H Chi. 2021. A model of two tales: Dual transfer learning framework for\nimproved long-tail item recommendation. In WWW. 2220â€“2231.\n[42] Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, et al. 2021. Causal intervention\nfor leveraging popularity bias in recommendation. In SIGIR. 11â€“20.\n6 SUPPLEMENTAL MATERIAL\nIn the supplementary material, we first show the learning process\nof SHT with pseudocode summarized in Algorithm 1. Then, we\ninvestigate the influences of different hyperparameter settings, and\ndiscuss the impact of three key hyperparameters. Finally, we de-\nscribe the details of our vector visualization algorithm used in the\ncase study experiments.\n6.1 Learning process of SHT\nAlgorithm 1: Learning Process of SHT Framework\nInput: user-item interaction graph G, number of graph\nlayers ğ¿, number of edges to sample ğ‘…,ğ‘…â€², maximum\nepoch number ğ¸, learning rate ğœ‚\nOutput: trained parameters in Î˜\n1 Initialize all parameters in Î˜\n2 for ğ‘’ = 1 to ğ¸do\n3 Draw a mini-batch U from all users {1,2,...,ğ¼ }\n4 Calculate the graph topology-aware embeddings Â¯E\n5 Generate input embeddings ËœE0 for hypergraph\ntransformer\n6 for ğ‘™ = 1 to ğ¿do\n7 Conduct node-to-hyperedge propagation to obtain\nËœZ(ğ‘¢), ËœZ(ğ‘£)for both users and items\n8 Conduct hierarchical hyperedge feature\ntransformation for Ë†Z(ğ‘¢),Ë†Z(ğ‘£)\n9 Propagate information from hyperedges back to\nuser/item nodes to obtain ËœE(ğ‘¢)\nğ‘™ , ËœE(ğ‘£)\nğ‘™\n10 end\n11 Aggregate the iteratively propagated embeddings to get\nË†E\n12 Sample ğ‘…edge pairs for self-augmented learning\n13 Acquire the user/item transformation function ğœ™(ğ‘¢)and\nğœ™(ğ‘£)with the meta network\n14 Conduct user/item embedding transformations using\nğœ™(Â·)to get Î“(ğ‘¢),Î“(ğ‘£)\n15 Calculate the solidity score ğ‘  for the ğ‘…edge pairs\n16 Calculate the solidity predictions Ë†ğ‘  for the ğ‘…edge pairs\n17 Compute loss Lsa for self-augmented learning\naccording to Eq 12\n18 Sample ğ‘…â€²edge pairs for the main task\n19 Calculate the pair-wise marginal loss Laccording to\nEq 13\n20 for each parameter ğœƒ âˆˆÎ˜ do\n21 ğœƒ = ğœƒ âˆ’ğœ‚Â·ğœ•L/ğœ•ğœƒ\n22 end\n23 end\n24 return all parameters Î˜\n6.2 Hyperparameter Investigation\nWe study the effect of three important hyperparameters, i.e., the\nhidden dimensionality ğ‘‘, the number of latent hyperedges ğ¾, and\nthe number of graph iterations ğ¿. To present more results, we\ncalculate the relative performance decrease in terms of evaluation\nmetrics, compared to the best performance under default settings.\nThe results are shown in Fig 6, our observations are shown below:\nâ€¢The latent embedding dimension size largely determines the\nrepresentation ability of the proposed SHT model. Smallğ‘‘greatly\nlimits the efficacy of SHT, by 15%-35% performance decrease.\nHowever, greaterğ‘‘does not always yield obvious improvements.\nAs shown by results when ğ‘‘ = 68 on Yelp data, the performance\nincreases marginally due to the over-fitting effect.\nâ€¢The curve of performance w.r.t. hyperedge numberğ¾ typically\nfollows the under- to over-fitting pattern. However, it is inter-\nesting that ğ¾ has significantly less influence compared to ğ‘‘ (at\nmost âˆ’6% and âˆ’35%, respectively). This is because the hyperedge-\nnode connections in SHT are calculated in ağ‘‘-dimensional space,\nwhich reduces the amount of independent parameters related to\nğ¾ to ğ‘‚(ğ¾Ã—ğ‘‘). So ğ¾ has much smaller impact on model capacity\ncompared to ğ‘‘, which relates to ğ‘‚((ğ¼ +ğ½)Ã—ğ‘‘)parameters.\nâ€¢For the number of graph iterations ğ¿, smaller ğ¿hinders nodes\nfrom aggregating high-order neighboring information. When\nğ¿= 0, graph neural networks degrades significantly. Meanwhile,\nby stacking more graph layers may cause over-smoothing issue,\nwhich yields indistinguishable node embeddings.\n10 20 30 40 50 60\nâˆ’30\nâˆ’20\nâˆ’10\n0\n10\nNumber of Latent Factorsğ‘‘\nDecrease of Recall@20 (%)\nYelpGowallaTmall 50 100150200250âˆ’12\nâˆ’10\nâˆ’8\nâˆ’6\nâˆ’4\nâˆ’2\n0\nNumber of Hyper Edgesğ¾\nDecrease of Recall@20 (%)\nYelpGowallaTmall 1 1.5 2 2.5 3 3.5 4\nâˆ’60\nâˆ’40\nâˆ’20\n0\nNumber of Graph Iterationsğ¿\nDecrease of Recall@20 (%)\nYelpGowallaTmall\n10 20 30 40 50 60\nâˆ’30\nâˆ’20\nâˆ’10\n0\n10\nNumber of Latent Factorsğ‘‘\nDecrease of NDCG@20 (%)\nYelpGowallaTmall 50 100150200250âˆ’12\nâˆ’10\nâˆ’8\nâˆ’6\nâˆ’4\nâˆ’2\n0\nNumber of Hyper Edgesğ¾\nDecrease of NDCG@20 (%)\nYelpGowallaTmall 1 1.5 2 2.5 3 3.5 4\nâˆ’60\nâˆ’40\nâˆ’20\n0\nNumber of Graph Iterationsğ¿\nDecrease of NDCG@20 (%)\nYelpGowallaTmall\nFigure 6: Hyperparameter study of the SHT.\n6.3 Vector Visualization Algorithm\nIn our case study experiments, each item embeddings of 32 dimen-\nsions is visualized with a color. This visualization process should\npreserve the learned item information in the embedding vectors.\nMeanwhile, to make the visualization results easy to understand, it\nwould be better to pre-select several colors to use. Considering the\nabove two requirements, we design a neural-network-based dimen-\nsion reduction algorithm. Specifically, we train a multi-layer per-\nceptron to map 32-dimensional item embeddings to 3-dimensional\nRGB values. The network is trained using two objective functions,\ncorresponding to the forgoing two requirements. Firstly, the com-\npressed 3-d vectors (colors) are fed into a classifier, to predict the\noriginal item ids. Through this self-discrimination task, the network\nis trained to preserve the original embedding information in the\nRGB vectors. Secondly, the network is trained with a regularizer\nthat calculates the distance between each color vectors and the\npreferred colors. Using the two objectives, we can map embeddings\ninto preferred colors while preserving the embedding information.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8187462687492371
    },
    {
      "name": "Recommender system",
      "score": 0.75057452917099
    },
    {
      "name": "Hypergraph",
      "score": 0.693405032157898
    },
    {
      "name": "Collaborative filtering",
      "score": 0.5866149067878723
    },
    {
      "name": "Machine learning",
      "score": 0.5197545886039734
    },
    {
      "name": "Feature learning",
      "score": 0.4440465271472931
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.4424830973148346
    },
    {
      "name": "Transformer",
      "score": 0.44045940041542053
    },
    {
      "name": "Pairwise comparison",
      "score": 0.42652755975723267
    },
    {
      "name": "Graph",
      "score": 0.41851937770843506
    },
    {
      "name": "Artificial intelligence",
      "score": 0.41377392411231995
    },
    {
      "name": "Data mining",
      "score": 0.4111429750919342
    },
    {
      "name": "Theoretical computer science",
      "score": 0.3144708275794983
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Discrete mathematics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I889458895",
      "name": "University of Hong Kong",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I6902469",
      "name": "Brandeis University",
      "country": "US"
    }
  ],
  "cited_by": 119
}