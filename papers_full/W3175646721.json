{
    "title": "Space Efficient Context Encoding for Non-Task-Oriented Dialogue Generation with Graph Attention Transformer",
    "url": "https://openalex.org/W3175646721",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A4288954785",
            "name": "Galetzka, Fabian",
            "affiliations": [
                "University of Potsdam",
                "Volkswagen Group (Germany)"
            ]
        },
        {
            "id": null,
            "name": "Rose, Jewgeni",
            "affiliations": [
                "Volkswagen Group (Germany)",
                "University of Bonn"
            ]
        },
        {
            "id": "https://openalex.org/A3177905161",
            "name": "Schlangen, David",
            "affiliations": [
                "University of Potsdam"
            ]
        },
        {
            "id": "https://openalex.org/A2753561913",
            "name": "Lehmann, Jens",
            "affiliations": [
                "University of Bonn"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2586847566",
        "https://openalex.org/W2963858333",
        "https://openalex.org/W4288624561",
        "https://openalex.org/W2914204778",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2963825865",
        "https://openalex.org/W2963520511",
        "https://openalex.org/W2606780347",
        "https://openalex.org/W3022187094",
        "https://openalex.org/W2913443447",
        "https://openalex.org/W2891416139",
        "https://openalex.org/W2962883855",
        "https://openalex.org/W2154652894",
        "https://openalex.org/W2951008357",
        "https://openalex.org/W2101105183",
        "https://openalex.org/W1885389775",
        "https://openalex.org/W2157331557",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2962854379",
        "https://openalex.org/W2963448850",
        "https://openalex.org/W2997736261",
        "https://openalex.org/W4287822960",
        "https://openalex.org/W2574102609",
        "https://openalex.org/W2963217826",
        "https://openalex.org/W2971351151",
        "https://openalex.org/W2964113829",
        "https://openalex.org/W2963790827",
        "https://openalex.org/W2950457956",
        "https://openalex.org/W3155584966",
        "https://openalex.org/W2950898568",
        "https://openalex.org/W2950902819",
        "https://openalex.org/W2893684749",
        "https://openalex.org/W1654173042",
        "https://openalex.org/W3164706026",
        "https://openalex.org/W2891501508",
        "https://openalex.org/W1793121960",
        "https://openalex.org/W1518951372",
        "https://openalex.org/W1591706642",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W4297733535",
        "https://openalex.org/W2981258463",
        "https://openalex.org/W3032852168",
        "https://openalex.org/W2064675550"
    ],
    "abstract": "To improve the coherence and knowledge retrieval capabilities of non-task-oriented dialogue systems, recent Transformer-based models aim to integrate fixed background context. This often comes in the form of knowledge graphs, and the integration is done by creating pseudo utterances through paraphrasing knowledge triples, added into the accumulated dialogue context. However, the context length is fixed in these architectures, which restricts how much background or dialogue context can be kept. In this work, we propose a more concise encoding for background context structured in the form of knowledge graphs, by expressing the graph connections through restrictions on the attention weights. The results of our human evaluation show that this encoding reduces space requirements without negativ e effects on the precision of reproduction of knowledge and perceived consistency. Further, models trained with our proposed context encoding generate dialogues that are judged to be more comprehensive and interesting.",
    "full_text": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natural Language Processing, pages 7028–7041\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n7028\nSpace Efﬁcient Context Encoding for Non-Task-Oriented\nDialogue Generation with Graph Attention Transformer\nFabian Galetzka1,2,∗, Jewgeni Rose 1,3,∗,†, David Schlangen 2 and Jens Lehmann3,4\n1V olkswagen Innovation Center, Wolfsburg, Germany\n2Computational Linguistics, University of Potsdam, Germany\n3University of Bonn, Germany\n4Fraunhofer IAIS, Dresden, Germany\n{jewgeni.rose,fabian.galetzka}@volkswagen.de\njens.lehmann@iais.fraunhofer.de\ndavid.schlangen@uni-potsdam.de\nAbstract\nTo improve the coherence and knowledge re-\ntrieval capabilities of non-task-oriented dia-\nlogue systems, recent Transformer-based mod-\nels aim to integrate ﬁxed background context.\nThis often comes in the form of knowledge\ngraphs, and the integration is done by cre-\nating pseudo utterances through paraphrasing\nknowledge triples, added into the accumulated\ndialogue context. However, the context length\nis ﬁxed in these architectures, which restricts\nhow much background or dialogue context can\nbe kept. In this work, we propose a more con-\ncise encoding for background context struc-\ntured in the form of knowledge graphs, by ex-\npressing the graph connections through restric-\ntions on the attention weights. The results of\nour human evaluation show that this encod-\ning reduces space requirements without nega-\ntive effects on the precision of reproduction of\nknowledge and perceived consistency. Further,\nmodels trained with our proposed context en-\ncoding generate dialogues that are judged to\nbe more comprehensive and interesting.\n1 Introduction\nBuilding on the idea of attention-based seq2seq\nmodels (Vaswani et al., 2017), recent language\nmodels such as BERT (Devlin et al., 2019) and\nGPT-2 (Radford et al., 2019) enable neural conver-\nsational models to generate responses that appear\nhuman-like and engaging (Yu et al., 2019). A closer\nlook, however, reveals that the lack of long-term\nmemory to represent consistent (world) knowledge\nand personality over multiple speaker turns can\nlead to incoherent content being generated (Li et al.,\n2016; Serban et al., 2017). Initiated by the Con-\nversational Intelligence Challenge (Burtsev et al.,\n2018; Dinan et al., 2020), the research focus there-\nfore shifted towards knowledge-grounded dialogue\n∗The ﬁrst two authors contributed equally to this paper.\n†Corresponding author\ngeneration, resulting in ﬁrst promising approaches\nusing Transformer-based architectures (Dinan et al.,\n2019; Ghazvininejad et al., 2018; Galetzka et al.,\n2020).\nThe basic idea of these approaches is to provide\nthe required background knowledge together with\nthe current dialogue context when decoding the\nnext system utterance. As the underlying language\nmodel’s input sequence length is limited – for in-\nstance, to 1024 tokens in the case of GTP-2 – the\npresentation of the background knowledge to the\nmodel highly impacts the amount of context infor-\nmation that can be fed into a Transformer network.\nIn these earlier attempts, the knowledge was para-\nphrased into pseudo-utterances, on a par with the\nutterances from the dialogue history. In this paper,\nwe show that a structured knowledge representa-\ntion offers advantages over unstructured text: facts\nand complex relationships between different enti-\nties can be encoded concisely without performance\ndrop in key indicators, such as knowledge correct-\nness, consistency, and interestingness. Chaudhuri\net al. (2019) showed the general feasibility of in-\ntegrating knowledge graphs into domain-speciﬁc\ndialogues. With this work, we integrate arbitrary\nknowledge graphs into open-domain knowledge-\ngrounded dialogues, preserving the information\nencoded in their structure.\nSpace Efﬁcient Context Encoding For our pro-\nposed encoding, we generate dialogue-speciﬁc lo-\ncal knowledge graphs (subgraphs of a background\nknowledge graph) that capture the information rel-\nevant to the dialogue (similar to (Chaudhuri et al.,\n2021)). We transform these subgraphs into a con-\ncise representation that ﬁts the input sequence en-\ncoding for the underlying language model (GPT-2):\nLabels of the distinct nodes and edges (entities and\ncorresponding relations) are concatenated with the\ndialogue history. To preserve the graph structure,\n7029\nwe ﬁt the attention mask to force the self-attention\nlayers for each node to attend to only connected\nnodes in the original graph (if there is a connection,\nattention weight is set to 1, otherwise to 0). This\nresembles the message-passing approach of graph\nneural networks (Gilmer et al., 2017).\nNaive concatenation of graph triples has a space\ncomplexity of O(n ·k), with n being the number\nof triples and k the number of word tokens per\nverbalized triple. Paraphrasing these triples into\npseudo-utterances results in even larger space com-\nplexity. Our proposed encoding has a space com-\nplexity of O(l), with l being the number of distinct\nnode and edge labels (entities and relations). This\nreduces the required context space compared to\ntriple concatenation or paraphrasing if entities are\nrepeated in the triples (and hence l < n·k), which\ncan be assumed to be the case in knowledge graphs\n(see discussion below). The space savings grow\nwith the size and average degree (connectedness)\nof the graph. Empirical results with two different\nknowledge-grounded dialogue datasets conﬁrm our\ntheoretical considerations and show that we can\nreduce the required space by a factor of up to 3.6.\nThese results imply that we can feed more context\ninformation into the model, which should result in\nhigher accuracy. We discuss these results in detail\nin Section 4.3.\nContributions We propose an approach to in-\ntegrate a concise encoding of knowledge graphs\ninto a Transformer-based decoder architecture for\nknowledge-grounded dialogue generation. Trans-\nformers for natural language generation can be\nviewed as graph neural networks which use self-\nattention (Veliˇckovi´c et al., 2018) for neighborhood\naggregation on fully-connected word graphs (Xu\net al., 2019). We utilize this relationship and restrict\nthe self-attention weights to match the underlying\ngraph structure. Our comprehensive human evalu-\nation with models trained with the publicly avail-\nable datasets KOMODIS (Galetzka et al., 2020) and\nOPEN DIAL KG (Moon et al., 2019), both provid-\ning dialogues enriched with structured knowledge,\nshows that we can reduce the space requirement for\ncontext without negative effects on the precision\nof reproduction of knowledge and perceived con-\nsistency. Moreover, our models generate dialogues\nthat are judged to be more detailed and interesting.\nFor reproducibility, we publish all necessary source\ncode and data (https://github.com/fabiangal/\nspace-efficient-context-encoding-acl21 ).\n2 Knowledge-Augmented Neural\nConversational Models\nNeural conversational models can be categorized\ninto retrieval-based approaches (Lowe et al., 2015;\nWu et al., 2017) that choose a next utterance from\na set of suitable candidates, and generative ap-\nproaches (Serban et al., 2016; Wolf et al., 2019;\nChaudhuri et al., 2019; Roller et al., 2021) which\ndecode the next utterance token by token out of a\nﬁxed vocabulary. The architectures are based on\nrecurrent neural networks such as LSTM (Hochre-\niter and Schmidhuber, 1997) or GRU (Cho et al.,\n2014) cells or self-attention layers (Vaswani et al.,\n2017) in sequence-to-sequence structures. To inte-\ngrate knowledge in addition to the dialogue history\nthese models can be augmented by additional re-\ncurrent cells to encode the knowledge into a ﬁxed-\nsized vector representation (Young et al., 2018;\nParthasarathi and Pineau, 2020; Ghazvininejad\net al., 2018). This can be traced back to ﬁrst end-\nto-end approaches reading documents for question-\nanswering (Miller et al., 2016) or more general\nsequential data (Sukhbaatar et al., 2015). He et al.\n(2017) embedded knowledge graphs (stored as\ntriples) with LSTM cells and message-passing, and\nthen used a decoder LSTM to generate a suitable\nanswer. Long et al. (2017) used a CNN architecture\nto encode external knowledge instead.\nThe recent success of unsupervised pre-trained\nlanguage generation models such as GPT-2 yielded\na variety of conversational models using self-\nattention based on the idea of ﬁne-tuning the\nmodels with speciﬁc knowledge-grounded dia-\nlogue datasets (which we will discuss in Sec-\ntion 3). These models concatenate the additional\ncontext information as plain text to the input se-\nquence (Zhang et al., 2018; Dinan et al., 2019;\nGaletzka et al., 2020). To differentiate context\nfrom dialogue, additional tokens are learned during\nﬁne-tuning and added to the word tokens. For big-\nger knowledge graphs, the limitation of the input\nsequence length of these models makes an informa-\ntion retrieval system necessary to estimate a small\nsubset of relevant information that can be fed into\nthe model.\n3 Knowledge-Grounded Dialogue\nDatasets\nThe increasing availability of conversational con-\ntent on social media platforms such as Twitter\nor Reddit led to the construction of many dia-\n7030\ntype\nactor\nopinion\nage certificate\nshot location\nyear\ntrivia\nactor\ngenre\nPulp Fiction\ntrivia type\nBruce Willis\nMovie\n1994\nI like\n“Worked on the film only \nfor 18 days.” Actor\n16\nUnited States\ntype\nSamuel L.\nJackson\nActor\nyear\ntype\nopinion\ngenre\nGoodfellas\nCrime\nMovie\nFavourite\n1990depth 0\ndepth 1\ndepth 2\nActor\nactor\nFigure 1: Illustration of the underlying subgraph data model for the external knowledge of a KOMODIS dialogue\nfor different graphs depths: Nodes (green) with their fact-based attributes (blue) and opinions (orange). Subgraphs\nfor depth 1 and depth 2 are incomplete.\nlogue datasets, with Open-Subtitles (Vinyals and\nLe, 2015) and Twitter-Corpus (Sordoni et al., 2015)\nbeing some popular examples (see also (Ritter et al.,\n2010; Duplessis et al., 2016)).\nSome recently published datasets emphasize\nknowledgeable dialogues by integrating external\ninformation sources. The objective is to create mod-\nels that generate consistent dialogues with a high\nknowledge retrieval accuracy (utilizing informa-\ntion from user proﬁles or knowledge graphs). Di-\nnan et al. (2019) released the Wizard of Wikipedia\ndataset with over 22k open-domain dialogues. In\neach dialogue, one participant is playing the “wiz-\nard”, i.e. an expert who is presented with poten-\ntially interesting and relevant Wikipedia article ex-\ncerpts, while the chat partner is the curious appren-\ntice. The textual knowledge passages that were\nshown to the wizard are part of the dataset. The\nPERSONA -CHAT dataset (Zhang et al., 2018) con-\ntains over 10k dialogues that are conditioned on\nproﬁle information (personas), which ranges from\nhobbies or favorite food to family background. The\ninformation is shown to the participants as a set\nof sentences and they are tasked to integrate them\ninto the dialogues. In addition, the dataset contains\nrevised personas, which are rephrased, generalized,\nor specialized versions of the original personas.\n3.1 Dialogue Datasets with Knowledge\nGraphs\nWe use two publicly available human/human multi-\nturn dialogue datasets that use structured back-\nground knowledge.\nKOMODIS (Galetzka et al., 2020) is a closed-\ndomain dataset with dialogues between human par-\nticipants that were tasked to chit-chat about one\ngiven movie and use provided information about it.\nThis information includes facts about the ﬁlm, such\nas release year or shot location (“Movie was shot in\nCanada.” or “The release year is 1995.”), free text\ncontaining plot or trivia related to the ﬁlm crew and\ncast, and opinions towards the facts and entities\n(“I agree with the age restriction.” or “I don’t like\nBruce Willis.”). The dataset contains over 7,500\nconversations with an average of 13.8 utterances\nper dialogue.\nOpenDialKG (Moon et al., 2019) is an open-\ndomain dataset containing 15K dialogues, which\nwere collected in a Wizard-of-Oz setup, by connect-\ning two human participants that were tasked to have\nan engaging dialogue about a given topic. Each di-\nalogue is paired with its corresponding “KG paths”\nfrom Freebase (Bollacker et al., 2007) (connecting\nentities and relations mentioned in the dialogue).\n3.2 Subgraph Generation\nFor our experiments with different encoding strate-\ngies, we restructure the context information pro-\nvided by both datasets into dialogue-speciﬁc sub-\ngraphs. Figure 1 illustrates an example of an (in-\ncomplete) subgraph that belongs to a dialogue\nfrom KOMODIS . The inner subgraph containing\nthe two green entity nodes ’Pulp Fiction’ and\n’Bruce Willis’, and corresponding attribute nodes\n(blue), marked as depth 0, represents the informa-\ntion on which one particular dialogue was based.\n7031\nBOS movie movie year genre EOS\nwords\nsegments\npositions\ngraph encoding dialogue history next utterance\nBOS Pulp Fiction 1994 crime Do you like movies ? Yes , I love Pulp Fiction EOS\nFigure 2: Shortened illustration of the input sequence with encoded context sequence, dialogue history and next\nutterance with three layers of embeddings: word, segment and positional embeddings. The layers are summed up\nto yield the by-token embeddings.\nKnowledge\nEstimator GPT-2\nSub-\nGraph\nDialog\nHistory\nGenerated\nAnswerupdate \nKnowledge Graph\nFigure 3: Model architecture: A knowledge estima-\ntor creates a subgraph based on the previous conversa-\ntion. Processed subgraph and input sequence are con-\ncatenated and fed into the GPT-2 decoder. We experi-\nment with different ways of encoding and adding in the\nknowledge.\nTo test the limits of the capacity for represent-\ning knowledge, we also experiment with expanded\nsubgraphs— depths 1 and depths 2 in the ﬁgure—\nby including information from external knowledge\nsources (IMDb for KOMODIS , and Freebase for\nOPEN DIAL KG). For instance, Pulp Fiction also\nhas Samuel L. Jackson as an actor (depth 1) who\nalso stars in Goodfellas (depth 2). This way, the\nsubgraph depth directly reﬂects the hop distance\nfrom the entities in the core subgraph.\nFor subgraphs of depth 2, we restrict some at-\ntributes and entities to prevent the subgraphs to\nexplode in size, thus unlikely to ﬁt in GPT-2. For\nexample, we don’t add trivia information that isn’t\nalready in the dialogues or limit additional actors\nper movie to three. In contrast to OPEN DIAL KG,\nthe dialogues in KOMODIS are about one main en-\ntity (here, the movie) each. To better compare the\nexperiments across datasets, we create two versions\nof depth 1 for KOMODIS , where depth 1b includes\na second movie that is related to the ﬁrst movie\n(e.g. by an actor). This version is then used to\ncreate the subgraph of depth 2.\n4 Graph Attention Transformer\n4.1 Model Overview\nFor all experiments, we use the GPT-2 model pro-\nposed by Radford et al. (2019), which is com-\nmonly used in Transformer-based dialogue gen-\neration for English. The authors published four dif-\nferent sized variations. We use the model with 117\nmillion parameters, 12 self-attention layers, and\n768-dimensional word embeddings. The model has\n12 heads per attention layer and 3072 nodes in all\nfeed-forward layers. Our architecture is visualized\nin Figure 3. A knowledge estimator creates a sub-\ngraph from the available knowledge graphs for both\ndatasets based on the dialogue history and converts\nit using our encoding. Then, the dialogue history\nand encoded context sequences are concatenated\nand fed into the GPT-2 model. For training, we op-\ntimize model weights from GPT-2 by minimizing\nthe negative log-likelihood for next-token predic-\ntion. Training details are listed in Appendix B.\n4.2 Concise Graph Encoding\nFigure 2 shows the general encoding strategy\nthat we propose. Similar to our previous ap-\nproach (Galetzka et al., 2020) and Wolf et al.\n(2019), we use three layers of input embeddings\nfor words, segments and positions. But instead\nof concatenating paraphrased triples (e.g. ⟨‘Pulp\nFiction’, ‘is a’, ‘movie’⟩, ⟨‘Pulp Fiction’, ‘release\nyear’, ‘1994’⟩), we convert the graph into unique\nentity-relation pairs (e.g. ⟨‘Pulp Fiction’, ‘movie’⟩,\n⟨‘1994’, ‘release year’⟩in the leftmost part of the\nﬁgure) and concatenate them with the dialogue his-\ntory (middle part in ﬁgure). In previous work, the\nsegments layer distinguished context and different\nspeakers. We experiment with two different encod-\ning strategies, utilizing the segments layer in other\nways. Figure 4 illustrates both encoding strategies.\nIn the series encoding (upper half of the ﬁgure),\nrelation and entity tokens are sequenced in a se-\n7032\nBOSentityentity rel. entityrel. rel.\nwords\nsegments\nBOS PulpFictionmovie1994releaseyear\nwords\nsegments\nBOS PulpFiction1994<pad>\nseries encoding\nparallel encoding\nBOSmovie<pad>releaseyear\nFigure 4: Illustration of the difference between series\nand parallel encoding with data from the example graph\nin Figure 1.\nries and added to the words layer. Two new tokens\n(⟨entity⟩and ⟨relation⟩) differentiate between re-\nlations and entities in the segments layer. In the\nparallel encoding, entity tokens are added to the\nwords layer and according relations to the segments\nlayer—thus in parallel. Padding tokens are used to\nalign the length between the two layers.\nnodes attention mask\nPulp Fiction (1)\nBruce Willis (2)\nI like (3)\n1994 (4)\n“Worked on the ...” (n)\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n(1)(2)(3)(4) (n)\n...\n...\n...\n1 1 1 1 1\n1 1 0 0 1\n1 0 1 0 0\n1 0 0 1 0\n1 1 0 0 1\nFigure 5: Simpliﬁed and shortened illustration of the\nattention mask for the example graph from Figure 1.\nThe node ‘Bruce Willis’ (highlighted in blue) is con-\nnected (ones) with the movie ‘ Pulp Fiction’ and the\ntrivia ‘Worked on the ...’. Other nodes (‘I like’, ‘1994’)\nare masked out (zeros), since they only belong to the\nmovie.\nThis encoding via a segments layer reduces the\nspace requirements compared to paraphrasing, as\nrepeating tokens occur only once, but on its own\nloses information encoded in the graph structure\n(node-edge connections). To preserve this struc-\nture information, we create and add a per-graph\nattention mask to all hidden layers. Given an input\nsequence S, the hidden state hl\ni of the i’th token at\nlayer l in the GPT-2 model can be computed by:\nhl\ni =\n∑\nj∈S\nwij(V l−1hl−1\nj ), (1)\nwhere\nwij = softmaxj(mj + Ql−1hl−1\ni ·Kl−1hl−1\nj ),\n(2)\nwith learnable weights K, Q, and V . Equation 1\nis similar to message-passing algorithms (Duve-\nnaud et al., 2015; Li et al., 2016; Gilmer et al.,\n2017), where a new hidden state for a graph node\nis computed by an arbitrary function of all previous\nhidden states of connected nodes. Our attention\nmasks mj are added as shown in Equation 2 so that\nentity and relation tokens can only attend to tokens\nfrom their neighboring nodes. This attention mask-\ning was originally used for mask out future tokens\n(setting mi,j for all j > ito the masking value).\nFigure 5 illustrates the concept with an attention\nmask of the graph example from Figure 1. Here, the\nnode ‘Bruce Willis’ (blue) is not connected with the\nrelease year ‘1994’. Thus, the attention weights are\nmasked out with zeros. But, it is connected with\nthe trivia information ‘Worked on the movie for\nonly 18 days’ andthese attentions are not masked\n(ones).\nAlthough entities and relations from the knowl-\nedge graph are position invariant within S, the\nword order still matters. Therefore, we keep the\npositional encoding of the model but shufﬂe the\nknowledge graph nodes and relations for each train-\ning sample to facilitate order invariance of the\ngraph encoding.\n4.3 Context Length Requirement\nFigure 6 shows the growth of the number of re-\nquired context tokens when the graph size is in-\ncreased (and hence, more knowledge is provided\nto the model), for different encoding types. The\nbaselines are paraphrased-based encodings, where\nbase-triples are the concatenated triples (“Pulp Fic-\ntion release year 1994”) and base-paraphrased the\nverbalized paraphrase ( “The movie Pulp Fiction\nwas released in 1994” ). For OPEN DIAL KG, no\nparaphrased version is available. For both datasets,\nthe average number of tokens increases with the\ngraph depth and the average number of nodes and\nrelations for all encodings, as expected. However,\nit grows much slower in the case of our proposed\nencodings.\nThe increase of required tokens for OPEN DI-\nALKG is steeper than for KOMODIS , due to the\ndifferent structure of the dialogue context and\nthe underlying knowledge graphs. The context\ngraph for OPEN DIAL KG is initially rather small\n7033\nFigure 6: Average number of context tokens in the input sequence for different encodings and knowledge graph\ndepths (KOMODIS from left: d0, d1a, d1b, d2; O PEN DIAL KG from left: d0, d1, d2). Data extracted from the\nwhole train subset.\nand increases very fast with more hops. Further,\nthe KOMODIS context graph contains information\nabout plot and trivia, which are normally longer\nstrings that belong to one entity, thus the beneﬁt of\nseries-encoding (series-enc) and parallel-encoding\n(parallel-enc) regarding this information is rather\nsmall compared to the baselines. Concluding, the\nsequence length reduction correlates with the av-\nerage number of edges per node. The series-enc\nis between 14% and 30% longer than the parallel-\nenc, due to representing relation labels within the\nsegments instead of word embeddings (as shown\nin Figure 4).\n5 Automated Evaluation, And Its Limits\nWe trained 25 models with both datasets with\nseries-encoding, parallel-encoding, base-triples\nand base-paraphrased (only KOMODIS ) and with\ngraph depths d0, d1 and d2. As we were also in-\nterested to investigate the effect of different de-\ncoding strategies, we used beam-search and top-\nk-sampling when generating the dialogues. These\nwere created by four colleagues (who were not in-\nvolved in the creation of the models and did not\nknow what the innovation was) interacting with the\nmodels. In sum, we created 500 dialogues.\nAt training time, we use perplexity on the valida-\ntion subset as the stopping criterion. Table 3 lists\nthe results for all models estimated on the test set.\nBase-triples (baselines) models reach the lowest\nperplexity and an increasing graph depth increases\nperplexity, which is reasonable since the format of\nthe baseline encodings resembles the pre-training\ndata of the GPT-2 model the most. This corre-\nlation is stronger for OPEN DIAL KG models. In\nour experiments, perplexity does not correlate with\nnaturalness (estimated by the human evaluators),\nindicating that this metric is insufﬁcient to evaluate\nthe overall dialogue quality, in particular across\nmodels trained on different datasets.\nIn information retrieval, precision/recall and F1\nscore are typically chosen as automated metrics\nto evaluate the retrieval capabilities of a system.\nIn our case, we are interested in the ability of re-\nproducing entities and relations from the knowl-\nedge graph. Commonly used word-overlap met-\nrics, such as ROUGE-N/ROUGE-L (Lin, 2004),\nor BLEU (Papineni et al., 2001), aren’t capable of\nmeasuring these. Evaluating precision and recall\nrequires precise co-reference resolution, parse tree\nannotation and question labelling (e.g. entities, rela-\ntions, intent). Assume following background facts\nand generated utterance:\n• ⟨‘Pulp Fiction’, ‘has genre’, ‘crime’⟩\n• ⟨‘comedy’, ‘bot opinion’, ‘I like’⟩\n• “It is a crime movie, but I am more interested\nin comedy ﬁlms.”\nWithout knowing the intent (asking for the genre\nof ’Pulp Fiction’ vs. asking for the preferred genre)\nof the previous utterance, we cannot determine if\nthe occurrences of crime and comedy are true or\nfalse positives concerning the underlying knowl-\nedge graph. Moreover, in a conversation knowl-\nedge is not only used when answering a question\n7034\ndialogue context inference\nmodel “have you seen ghost, the musical with brad pitt?” genre: drama neutral\nhuman “no, but is the genre really a musical?”\nmodel “yes, it’s a crime and drama movie. ” genre: drama entailment\nhuman “nice. what is the age certiﬁcate?”\nmodel “the age restriction is 12. i think that’s a age certiﬁcate: 12 entailment\ngood age to watch it . ” age certiﬁcate: agree entailment\nhuman “and do you know the budget?”\nmodel “yes, it was $24,000,000. i think that’s a lot budget: 22$ million contradiction\nof money for a movie that came out in 1990. ” year: 1990 entailment\nTable 1: Example of a dialogue from the series-enc-d1 model trained on KOMODIS . Relevant utterance-context\npairs are shown together with annotations from our human evaluators. Line one is labeled with “neutral”, as\na “drama” might be a “musical”, the utterance in line three entails with the context regarding the genre and is\ntherefore labeled with “entailment”. Line seven is labeled with “contradiction” as the value of the budget is wrong,\nbut also as “entailment”, as the proactive use of the release year is correct.\nbut also proactively (“ Did you know that Bruce\nWillis worked on the movie only for 18 days?” ).\nHowever, the resources that we use offer no such\nannotations and to the best of our knowledge, no\npublished dataset does. Without it, automated met-\nrics don’t work well. To tackle these challenges,\nwe put our effort into a comprehensive human eval-\nuation and annotation, which is described in the\nnext section.\n6 Human Evaluation\n6.1 Method\nParticipants The evaluation study was managed\nby researchers not involved in setting up the models\nand experiments. They recruited 20 participants\nnot familiar with our research and the goals of the\nstudy. Demographic data is given in Appendix A.\nParticipants were paid for their effort.\nMaterials To keep the number of assessed dia-\nlogues manageable, we limited the number of ex-\nperiments and did not test all possible variations\nof the factors described in Section 5. We prepared\nthree series of experiments, aimed at evaluating the\ninﬂuence of decoding algorithms, encoding strate-\ngies and graph depths. Early samples indicated\nthat beam-search generates more precise dialogues\nregarding context. We, therefore, decided to evalu-\nate the decoding algorithm series beforehand. As\nshown in Section 6.2 our hypothesis proved to be\ncorrect, so that the other two series of experiments\nwere done with beam-search only.\nProcedure All participants were instructed be-\nfore and supervised during the study by a super-\nvisor to ensure their understanding of the metrics.\nThey were given a participant-speciﬁc question-\nnaire with the human/chatbot dialogues and had\nto perform three tasks. First, mark utterances that\neither entail (correct use) or contradict (wrong use)\nthe dialogue context. Based on these annotations\nwe measure the model’s knowledge retrieval ability\nas the ratio between entailing utterances and the\nsum of entailing and contradicting utterances (pre-\ncision). Second, rate the dialogues with the follow-\ning statements for agreement on a 7-point Likert\nscale: (1) Person B sounds natural. (2) Person B\nsounds consistent. (3) Person B sounds interesting.\nPerson B is always a model, Person A a human.\nLast, choose between two dialogues, by answering:\n“To which Person B would you prefer to talk?”.\nAdditionally, the participants could brieﬂy reason\ntheir decision. An example questionnaire can be\nfound in Appendix A.\n6.2 Results and Discussion\nDecoding Table 2 shows the results for beam-\nsearch and top-k-sampling decoding. Knowledge\nprecision is better with beam-search for all mod-\nels, while dialogues generated with top-k-sampling\nare considered more natural, less self-contradicting,\nand less repetitive. N-gram ﬁltering reduces repeti-\ntion through beam-search, but could not be avoided\ncompletely. Decoding with top-k-sampling in-\ncludes more often wrong entity nouns when es-\n7035\nexperiment knowledge precision naturalness\nbase-triples series-enc-d1 base-triples series-enc-d1\nKOMODIS beam-search 0.69 0.74 5.0 (1.5) 4.8 (1.6)\nKOMODIS top-k-sampling 0.52 0.56 5.9 (1.2) 5.9 (1.3)\nOPEN DIAL KG beam-search 0.73 0.70 4.0 (1.6) 3.4 (1.5)\nOPEN DIAL KG top-k-sampling 0.54 0.45 5.3 (1.4) 5.4 (1.3)\nTable 2: Human evaluation results for beam-search and top-k-sampling, with respect to the correct reproduction\nof dialogue context. Precision as the ratio between entailing utterances and the sum of entailing and contradicting\nutterances. Naturalness on a 7-point Likert scale. Higher is better. Standard deviation in brackets.\nexperiment ppl win\nratio (%)\nprecision agreements\nknowledge opinions natural consistent interesting\nKOMODIS\nbase-paraphrased 10.3 12.5 0.74 0.50 4.7 (1.7) 4.1 (1.7) 4.2 (1.2)\nbase-triples 9.73 43.8 0.69 0.71 5.0 (1.5) 4.0 (2.0) 4.6 (1.1)\nseries-enc-d1 10.01 66.7 0.74 0.36 4.8 (1.7) 4.5 (1.9) 4.9 (1.1)\nseries-enc-d2 10.28 62.5 0.73 0.43 4.8 (1.7) 4.2 (1.6) 4.4 (1.2)\nparallel-enc-d1 10.07 56.3 0.70 0.33 4.5 (1.7) 4.5 (1.2) 4.5 (1.1)\nparallel-enc-d2 10.36 60.0 0.72 0.57 4.8 (1.5) 4.6 (1.5) 4.5 (1.2)\nOpenDialKG\nbase-triples 8.40 65.0 0.73 — 4.0 (1.6) 3.9 (1.6) 3.6 (1.6)\nseries-enc-d1 9.93 66.7 0.62 — 3.9 (1.9) 4.1 (1.9) 3.5 (1.9)\nseries-enc-d2 10.53 51.3 0.46 — 3.7 (1.7) 4.0 (2.0) 3.8 (1.6)\nparallel-enc-d1 9.88 38.5 0.70 — 3.4 (1.6) 3.2 (1.8) 3.0 (1.3)\nparallel-enc-d2 10.44 32.5 0.62 — 3.4 (1.9) 3.6 (1.9) 3.3 (1.6)\nTable 3: Perplexity on the test set (lower is better) and human evaluation results for models trained on both datasets.\nMetrics explained in Section 6.1. Agreements are on a 7-point Likert scale (higher is better). Standard deviation\nin brackets. “base-*” are the baseline models; “series/parallel-enc-*” denotes the way the knowledge is encoded\nand “-*d1/d2” is the depth of the graphs.\ntimating the best next tokens, which are then se-\nlected by the algorithm. In this work, we emphasize\nthe model’s ability to integrate additional dialogue\ncontext correctly. Here, models with beam-search\nperform signiﬁcantly better. Thus, our further eval-\nuation focuses on beam-search.\nGraph Encoding The results with series and par-\nallel graph encodings are shown in Table 3 and com-\npared against the baselines. Within each dataset,\nall models perform similar regarding knowledge\nprecision. Due to the high standard deviation on\nthe agreements, the difference between the mod-\nels is statistically insigniﬁcant. Our graph encod-\ning approach reduces the required input sequence\nlength by a factor of up to 3.6 and still achieves the\nsame quality of knowledge reproduction, consis-\ntency, and naturalness as the baselines. Further, the\ndirect dialogue comparison (win ratio) indicates\nmore comprehensive and interesting utterances for\nKOMODIS . Dialogue preference correlates high-\nest with interestingness and non-existence of con-\ntradicting statements. The most common reasons\nfrom participants in no speciﬁc order are “longer\nand more comprehensive utterances”, “more inter-\nesting”, “asks counter questions” and “more pleas-\nant”. The OPEN DIAL KG models perform worse\nin general but show similar results between the dif-\nferent encodings. Both datasets have similar sizes\nbut OPEN DIAL KG is not limited to the movie do-\nmain, which makes it harder to train compared to\nKOMODIS .\nSeries vs. Parallel Encoding A quick summary:\nthe segments layer encodes the typing of the word\ntokens (from the words layer). The intuition be-\nhind it is that the model learns the meaning of the\nwords instead of the word distribution alone. For\nthe series encoding, we encode the types generi-\ncally as either entity or relation. For the parallel\nencoding, we use the actual typing from the under-\nlying knowledge graph, such as movie, actor, or\nrelease year (Section 4.2). We had two objectives.\nFirst, reducing the required context space even fur-\n7036\nther (which we achieved, see Figure 6). Second,\nanalyzing if this improves the accuracy. The re-\nsults show, that parallel encoding performs slightly\nworse compared to series encoding. We assume\nthat this is the case due to the lack of training data,\nwhich is, in particular, evident for OPEN DIAL KG\nthat has much more entity and relation types than\nKOMODIS , i.e. fewer samples per type.\nGraph Depth Results for training with different\ncontext lengths with KOMODIS are shown in Ta-\nble 4. All metrics (one outlier for opinion precision\nwith d = 1) correlate with increasing graph depth.\nResults for d = 2, however, are statistically not\nsigniﬁcantly higher than for d = 1. A bigger sub-\ngraph leads to more difﬁcult training data, as the\nmodel has more options to choose from. The same\nresults couldn’t be reproduced forOPEN DIAL KG.\nThis dataset was created for graph generation based\non dialogues. However, the dialogue structure is\ndifferent due to the recommendation task of the\ndata collection. Most entities in these dialogues\n(e.g. persons, books, movies) are exchangeable\n(“Can you recommend me a crime book similar\nto X?”, “Can you recommend me a crime movie\nsimilar to Y?”) and therefore not mandatory for a\ncorrect and consistent dialogue. Adding more of\nthese entities did not help to determine a correct\nnext entity, as all entities of the same type could be\nused correctly by the model.\nEffectiveness of Graph Attention Masking\nGraph masking encodes the relationships between\nthe entities. We hypothesize that dropping these\nrelationships will lead to an information gap, par-\nticularly for bigger subgraphs due to more entities\nthat are not represented (well) in the training data.\nTable 5 shows the results from an early evalua-\ntion phase for KOMODIS and OPEN DIAL KG with\ngraph depth 1 and 2 without graph masking. The\ndialogues are signiﬁcantly worse, in particular in\nterms of reproducing entities correctly for graph\ndepth 2 – which validates our hypothesis. As our\nresources were limited, we had to reduce the num-\nber of models for a thorough human evaluation\nand thus decided to not pursue this approach any\nlonger.\n7 Conclusion\nWe proposed a new and concise encoding for\nknowledge triples from a knowledge graph, which\ncan be integrated into a Transformer architecture\nmetric d0 d1 d2\nknowledge precision 0.56 0.70 0.721\nopinion precision 0.42 0.33 0.57\nnaturalness 4.5 4.5 4.81\nwin-ratio (%) 28.6 56.3 60.01\nTable 4: Inﬂuence of graph depth on various metrics\nfrom the human evaluation for the parallel-enc model\ntrained on KOMODIS . 1Statistically not signiﬁcant com-\npared to d1.\nexperiment knowledge opinions naturalness\nKOMODISd2 0.44 0.25 4.4\nKOMODISd1 0.61 0.46 4.1\nOPENDIALKG d2 0.37 — 3.8\nOPENDIALKG d1 0.54 — 3.9\nTable 5: Results from a pre-evaluation for models with-\nout graph attention masking. There are no opinions in\nthe case of O PEN DIAL KG. Knowledge and opinions\nas precision (ratio between entailing utterances and the\nsum of entailing and contradicting utterances). Natural-\nness on a 7-point Likert scale. Higher is better. Stan-\ndard deviation in brackets.\nfor consistent non-goal-driven dialogue generation.\nIn our encoding, we reduce the context length by\navoiding repetition by concatenating the whole\ntriples with the dialogue history. By manipulat-\ning self-attention layers to reﬂect connections be-\ntween nodes in the graphs, we preserve the graph\nstructure. The evaluation results prove that our\nencoding reduces space requirements without neg-\native effects on the precision of reproduction of\nknowledge and perceived consistency. For repro-\nducibility, we publish the source code and data.\nAcknowledgements\nWe thank our colleagues from the Digital Assis-\ntant for Mobility team at the V olkswagen Group\nInnovation Europe for their support in preparing\nthe human evaluation.\nReferences\nKurt Bollacker, Robert Cook, and Patrick Tufts. 2007.\nFreebase: A shared database of structured general\nhuman knowledge. Proceedings of the national con-\nference on Artiﬁcial Intelligence, 22(2):1962.\nMikhail Burtsev, Varvara Logacheva, Valentin Malykh,\nIulian Vlad Serban, Ryan Lowe, Shrimai Prabhu-\nmoye, Alan W Black, Alexander Rudnicky, and\n7037\nYoshua Bengio. 2018. The ﬁrst conversational in-\ntelligence challenge. In The NIPS’17 Competition:\nBuilding Intelligent Systems, pages 25–46. Springer.\nDebanjan Chaudhuri, Md Rashad Al Hasan Rony, Si-\nmon Jordan, and Jens Lehmann. 2019. Using a KG-\nCopy Network for Non-goal Oriented Dialogues.\nLecture Notes in Computer Science (including sub-\nseries Lecture Notes in Artiﬁcial Intelligence and\nLecture Notes in Bioinformatics) , 11778 LNCS:93–\n109.\nDebanjan Chaudhuri, Md Rashad Al Hasan Rony, and\nJens Lehmann. 2021. Grounding Dialogue Systems\nvia Knowledge Graph Aware Decoding with Pre-\ntrained Transformers. pages 1–16.\nKyunghyun Cho, Bart Van Merri ¨enboer, Caglar Gul-\ncehre, Dzmitry Bahdanau, Fethi Bougares, Holger\nSchwenk, and Yoshua Bengio. 2014. Learning\nphrase representations using RNN encoder-decoder\nfor statistical machine translation. EMNLP 2014\n- 2014 Conference on Empirical Methods in Natu-\nral Language Processing, Proceedings of the Con-\nference, pages 1724–1734.\nJacob Devlin, Ming Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In NAACL HLT 2019 - 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies - Proceedings of the Conference, volume 1,\npages 4171–4186.\nEmily Dinan, Varvara Logacheva, Valentin Ma-\nlykh, Alexander Miller, Kurt Shuster, Jack Ur-\nbanek, Douwe Kiela, Arthur Szlam, Iulian Serban,\nRyan Lowe, Shrimai Prabhumoye, Alan W. Black,\nAlexander Rudnicky, Jason Williams, Joelle Pineau,\nMikhail Burtsev, Jason Weston, and Others. 2020.\nThe second conversational intelligence challenge\n(convai2). In The NeurIPS’18 Competition, pages\n187–208. Springer.\nEmily Dinan, Stephen Roller, Kurt Shuster, An-\ngela Fan, Michael Auli, and Jason Weston. 2019.\nOf Wikipedia: Knowledge-powered conversational\nagents. 7th International Conference on Learning\nRepresentations, ICLR 2019, pages 1–18.\nGuillaume Dubuisson Duplessis, Vincent Letard,\nAnne Laure Ligozat, and Sophie Rosset. 2016.\nPurely corpus-based automatic conversation author-\ning. Proceedings of the 10th International Confer-\nence on Language Resources and Evaluation, LREC\n2016, pages 2728–2735.\nDavid Duvenaud, Dougal Maclaurin, Jorge Aguilera-\nIparraguirre, Rafael G ´omez-Bombarelli, Timothy\nHirzel, Al ´an Aspuru-Guzik, and Ryan P. Adams.\n2015. Convolutional networks on graphs for learn-\ning molecular ﬁngerprints. Advances in Neural\nInformation Processing Systems, 2015-Janua:2224–\n2232.\nFabian Galetzka, Chukwuemeka Uchenna Eneh, and\nDavid Schlangen. 2020. A Corpus of Controlled\nOpinionated and Knowledgeable Movie Discussions\nfor Training Neural Conversation Models. Proceed-\nings of The 12th Language Resources and Evalua-\ntion Conference, (May):565–573.\nMarjan Ghazvininejad, Chris Brockett, Ming Wei\nChang, Bill Dolan, Jianfeng Gao, Wen Tau Yih, and\nMichel Galley. 2018. A knowledge-grounded neural\nconversation model. 32nd AAAI Conference on Arti-\nﬁcial Intelligence, AAAI 2018, pages 5110–5117.\nJustin Gilmer, Samuel S. Schoenholz, Patrick F. Riley,\nOriol Vinyals, and George E. Dahl. 2017. Neural\nmessage passing for quantum chemistry. 34th In-\nternational Conference on Machine Learning, ICML\n2017, 3:2053–2070.\nHe He, Anusha Balakrishnan, Mihail Eric, and Percy\nLiang. 2017. Learning symmetric collaborative dia-\nlogue agents with dynamic knowledge graph embed-\ndings. ACL 2017 - 55th Annual Meeting of the Asso-\nciation for Computational Linguistics, Proceedings\nof the Conference (Long Papers), 1:1766–1776.\nSepp Hochreiter and J ¨urgen Schmidhuber. 1997.\nLong Short-Term Memory. Neural Computation ,\n9(8):1735–1780.\nYujia Li, Richard Zemel, Marc Brockschmidt, and\nDaniel Tarlow. 2016. Gated graph sequence neural\nnetworks. 4th International Conference on Learn-\ning Representations, ICLR 2016 - Conference Track\nProceedings, (1):1–20.\nC Y Lin. 2004. Rouge: A package for automatic eval-\nuation of summaries. Proceedings of the workshop\non text summarization branches out (WAS 2004).\nYinong Long, Jianan Wang, Zhen Xu, Zongsheng\nWang, Baoxun Wang, and Zhuoran Wang. 2017.\nA Knowledge Enhanced Generative Conversational\nService Agent. DSTC6 Conference, pages 1–5.\nRyan Lowe, Nissan Pow, Iulian V . Serban, and Joelle\nPineau. 2015. The Ubuntu Dialogue Corpus: A\nlarge dataset for research in unstructured multi-turn\nDialogue systems. SIGDIAL 2015 - 16th Annual\nMeeting of the Special Interest Group on Discourse\nand Dialogue, Proceedings of the Conference, pages\n285–294.\nAlexander H. Miller, Adam Fisch, Jesse Dodge,\nAmir Hossein Karimi, Antoine Bordes, and Jason\nWeston. 2016. Key-value memory networks for di-\nrectly reading documents. EMNLP 2016 - Confer-\nence on Empirical Methods in Natural Language\nProcessing, Proceedings, pages 1400–1409.\nSeungwhan Moon, Pararth Shah, Anuj Kumar, and Ra-\njen Subba. 2019. OpenDialKG: Explainable conver-\nsational reasoning with attention-based walks over\nknowledge graphs. In Proceedings of the 57th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 845–854, Florence, Italy. Associ-\nation for Computational Linguistics.\n7038\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2001. BLEU: a method for automatic eval-\nuation of machine translation. In Acl, volume 371,\npages 311–318, Morristown, NJ, USA. Association\nfor Computational Linguistics.\nPrasanna Parthasarathi and Joelle Pineau. 2020. Ex-\ntending neural generative conversational model us-\ning external knowledge sources. Proceedings of\nthe 2018 Conference on Empirical Methods in Natu-\nral Language Processing, EMNLP 2018, pages 690–\n695.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nBlog, 1(8):9.\nAlan Ritter, Colin Cherry, and Bill Dolan. 2010.\nUnsupervised modeling of twitter conversations.\nNAACL HLT 2010 - Human Language Technologies:\nThe 2010 Annual Conference of the North Ameri-\ncan Chapter of the Association for Computational\nLinguistics, Proceedings of the Main Conference ,\n(June):172–180.\nStephen Roller, Emily Dinan, Naman Goyal, Da Ju,\nMary Williamson, Yinhan Liu, Jing Xu, Myle Ott,\nEric Michael Smith, Y-Lan Boureau, and Jason We-\nston. 2021. Recipes for Building an Open-Domain\nChatbot. In Proceedings of the 16th Conference of\nthe European Chapter of the Association for Compu-\ntational Linguistics: Main Volume , pages 300–325,\nOnline. Association for Computational Linguistics.\nIulian V . Serban, Alessandro Sordoni, Yoshua Bengio,\nAaron Courville, and Joelle Pineau. 2016. Building\nend-To-end dialogue systems using generative hier-\narchical neural network models. 30th AAAI Con-\nference on Artiﬁcial Intelligence, AAAI 2016, pages\n3776–3783.\nIulian Vlad Serban, Alessandro Sordoni, Laurent Char-\nlin, Joelle Pineau, Aaron Courville, and Yoshua\nBengio. 2017. A Hierarchical Latent Variable\nEncoder-Decoder Model for Generating Dialogues.\nAaai2017, pages 3295–3301.\nAlessandro Sordoni, Michel Galley, Michael Auli,\nChris Brockett, Yangfeng Ji, Margaret Mitchell,\nJian Yun Nie, Jianfeng Gao, and Bill Dolan. 2015. A\nneural network approach to context-sensitive genera-\ntion of conversational responses. NAACL HLT 2015\n- 2015 Conference of the North American Chapter\nof the Association for Computational Linguistics:\nHuman Language Technologies, Proceedings of the\nConference, pages 196–205.\nSainbayar Sukhbaatar, Arthur Szlam, Jason Weston,\nand Rob Fergus. 2015. End-to-end memory net-\nworks. Advances in Neural Information Processing\nSystems, 2015-Janua:2440–2448.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. Advances in Neural Information Process-\ning Systems, 2017-Decem(Nips):5999–6009.\nPetar Veli ˇckovi´c, Arantxa Casanova, Pietro Li `o,\nGuillem Cucurull, Adriana Romero, and Yoshua\nBengio. 2018. Graph attention networks. 6th Inter-\nnational Conference on Learning Representations,\nICLR 2018 - Conference Track Proceedings , pages\n1–12.\nOriol Vinyals and Quoc Le. 2015. A Neural Conversa-\ntional Model. 37.\nThomas Wolf, Victor Sanh, Julien Chaumond, and\nClement Delangue. 2019. TransferTransfo: A Trans-\nfer Learning Approach for Neural Network Based\nConversational Agents. (ii).\nYu Wu, Wei Wu, Chen Xing, Zhoujun Li, and Ming\nZhou. 2017. Sequential matching network: A\nnew architecture for multi-turn response selection in\nretrieval-based chatbots. ACL 2017 - 55th Annual\nMeeting of the Association for Computational Lin-\nguistics, Proceedings of the Conference (Long Pa-\npers), 1:496–505.\nPeng Xu, Chaitanya K. Joshi, and Xavier Bresson.\n2019. Multi-Graph Transformer for Free-Hand\nSketch Recognition.\nTom Young, Erik Cambria, Iti Chaturvedi, Hao Zhou,\nSubham Biswas, and Minlie Huang. 2018. Aug-\nmenting end-to-end dialogue systems with common-\nsense knowledge. 32nd AAAI Conference on Artiﬁ-\ncial Intelligence, AAAI 2018, pages 4970–4977.\nDian Yu, Michelle Cohn, Yi Mang Yang, Chun Yen\nChen, Weiming Wen, Jiaping Zhang, Mingyang\nZhou, Kevin Jesse, Austin Chau, Antara Bhowmick,\nShreenath Iyer, Giritheja Sreenivasulu, Sam David-\nson, Ashwin Bhandare, and Zhou Yu. 2019. Gun-\nrock: A Social Bot for Complex and Engaging Long\nConversations. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP): System Demonstrations , pages 79–84,\nStroudsburg, PA, USA. Association for Computa-\ntional Linguistics.\nSaizheng Zhang, Emily Dinan, Jack Urbanek, Arthur\nSzlam, Douwe Kiela, and Jason Weston. 2018. Per-\nsonalizing dialogue agents: I have a dog, do you\nhave pets too? ACL 2018 - 56th Annual Meeting of\nthe Association for Computational Linguistics, Pro-\nceedings of the Conference (Long Papers) , 1:2204–\n2213.\n7039\nA Human Evaluation\nDemographic data 45% of the 20 participants\nare women. 75% of the participants stated that\nthey already have experience with various forms of\nchatbots. Due to data privacy reasons, age infor-\nmation is classiﬁed into three different categories.\n65% of the participants are 18–35 years old, 20%\n36–50 years, and three participants are older than\n50 years.\nQuestionnaire The questionnaire contains a sur-\nvey guide and a set of dialogue pairs to evaluate.\nAn example dialogue pair is shown in Figure 7. La-\nbels were added by the authors. The survey guide\nconsists of four pages with examples and explana-\ntions for the participants. The following excerpts\nare from the guide.\nGeneral instructions: Following, you are pre-\nsented with two dialogues between Person A and\nPerson B with according background information.\nThe dialogues are completely independent of each\nother. You must read both dialogues carefully.\nPlease take time for this task.\nInstructions for evaluating the knowledge and\nopinion precision: Please remember that the evalu-\nation is for Person B only! Please add ‘entailment’\nto the ﬁelds, when the utterance entails a speciﬁc\nfact or opinion. Please add ‘contradiction’ if an\nutterance contradicts a speciﬁc fact or opinion.\nPlease leave all other ﬁelds empty.\nInstructions for rating the dialogues on the 7-\npoint Likert scale: Please rate the three statements\nfor each dialogue on a scale from 1 to 7, where 1\nmeans that you strongly disagree with it and 7 that\nyou strongly agree with it. Please rate all state-\nments independently from the given facts and opin-\nions. For instance, if a dialogue contains wrong\nfacts, it still can sound very natural.\nInstructions for deciding between two dialogues:\nPlease rate intuitively with which Person B you\nwould prefer to talk. Please reason your decision\nbrieﬂy.\nAll instructions are provided with examples.\nB Training Details\nFor ﬁne-tuning GPT-2, we reused most training pa-\nrameters from the generative pre-training (Radford\net al., 2019). The learning rate linearly decreases\nto zero with an initial value of lr = 6.25e−6 with\nmax-norm gradient clipping. The language mod-\neling loss is multiplied by 2 before summed up\nwith the next sentence classiﬁer loss. Each mini-\nbatch consists of 32 sequences of up to 256 tokens\n(padded to maximum length). If dialogue history\nexceeds maximum sequence length, the ﬁrst ut-\nterances are cut off. For each sample, only the\ntokens from the last utterance are considered for\nthe language modeling loss. Encoded nodes and\nedges are shufﬂed randomly for each sample, not\nfor each dialogue. We used a cluster of 4 GeForce\nRTX 2080 Titan to train our models with batch dis-\ntribution and gradient accumulation to handle the\nmini-batch size. Based on graph depth an epoch\ntook up to 4 hours. We trained the models for 7 to\n10 epochs. Our graph encoding approaches took\nlonger to converge, compared to the baselines.\nC Dialogue Examples\nWe show three additional typical dialogue exam-\nples for both models in Tables 6, 7 and 8. They\ncontain entailing and contradicting statements re-\ngarding the context. The inconsistent opinion in\nTable 8 (correct in line 4, but incorrect in line 6)\nwas observed more often. For both datasets, we\nsometimes observe slight misspellings of entities\n(see Table 8, line 6, ‘Charlie Chaplin’ and ‘Charles\nChaplin’). We left the decision, whether this is a\ncontradiction (a wrong entity) or not (a misspelling)\nto the participants. Another issue that occurred mul-\ntiple times, is the wrong use of repeated entities\n(see Figure 7 with ‘Julia Roberts’ in line 6). Mod-\nels trained with OPEN DIAL KG also sometimes use\nentities that are not in the knowledge graph (see\nTable 7, line 4 ‘The Player’).\n7040\nDialogue Sarfarosh is of genre Action.\nSmita Jaykar has trivia: \nOften plays the role of \nthe mother in \nBollywood movies.\nSonali Bendre is an actor in \nSarfarosh.\nSarfarosh was released in \n1999.\nAction is not a \ngood genre.\nSonali Bendre is \nvery good.\nI like Sarfarosh \nvery much.\nWith which Person \nB would you prefer \nto talk? Why?\nPerson B \nsounds natural\nPerson B \nsounds \nconsistent\nPerson B \nsounds \ninteresting\n1\nA hey, how are you? I watched Sarfarosh yesterday.\ncontradiction\n2\nIt would be \nmore \ninteresting to \ntalk to the \nsecond Person.\n5 3 4\nB i'm good thanks... yourself?. i don't know that movie actually... what's it about? \nA I am good! It's an action movie with sonali bendre.\nentailment entailment\nB oh okay cool... sounds like it might be a good one to watch with your kids.  \nA why do you think so? \nentailment entailment contradiction\nB i don't really care for action movies... so maybe that's why i didn't care for this one.  \nA what do you like?\nentailment\nB i just don't think it's a good genre to be a part of... idon't like action movies either.  \nBill Raymond is an actor in \nTwelve Monkeys.\nTwelve Monkeys is of \ngenre Sci-Fi.\nTwelve Monkeys was released \nin 1995.\nTwelve Monkeys is of genre \nMystery.\nAge restriction: I \nagree.\nI like Bill Raymond \nvery much.\n'Twelve Monkeys' \nis good.\n2\nA hey, how are you?\n6 4 6\nB i'm good. i just watched a movie called \"twelve monkeys\". have you seen it? \nA yes, but I didn't like it. entailment\nB really? i thought it was pretty good. \nA Bill Raymond is such a good actor!\nentailment contradiction\nB i don't really like bill raymond, but he did a good job in this movie.  \nA Do you know the release year?\nentailment\nB\ni believe it was 1995. do you know what the budget was for this movie by any \nchance? \nFigure 7: Example of one dialogue pair from the questionnaire.\n7041\ndialogue context inference\nhuman “I am a fan of FC Bayern Munich!”\nmodel “they are a good team. they are in the allianz arena right nowbuilding: allianz arena neutral\nand they are playing in the bundesliga, do you like them?”team: fc bayern munich entailment\nhuman “Yes I do, what is the Allianz arena?”\nmodel “it is a building of the fc bayern munich and was built bybuilding: allianz arena entailment\nmark van bommel. ” player: mark van bommel contradiction\nhuman “Did they participate in the UEFA champions league?”\nmodel “yes, they did. it is the team that won the 2012-13 champions league 2012-13entailmentchampions league. ” champion: fc bayern munich\nTable 6: Example of a dialogue from the series-enc-d1 model trained on O PEN DIAL KG. Relevant utterance-\ncontext pairs are shown with gathered labels from our human evaluation.\ndialogue context inference\nhuman “Do you recommend Pretty Woman?”\nmodel “pretty woman is starring hank azaria. has actor: hank azaria entailmentdo you like him?”\nhuman “Yes, who else plays in the movie?”\nmodel “julia roberts is also in pretty woman. she is married tohas actor: julia roberts entailment\ndaniel moder, who also starred in the player and a few others. ”j. roberts spouse: daniel moder entailment\nhuman “do they have children?”\nmodel “yes, they have a daughter named julia roberts. ” j. roberts has child: henry contradiction\nTable 7: Example of a dialogue from the series-enc-d1 model trained on O PEN DIAL KG. Relevant utterance-\ncontext pairs are shown with gathered labels from our human evaluation.\ndialogue context inference\nhuman “Hey, what’s up?”\nmodel “not much. i just watched a movie called\ncity lights, have you seen it?”\nhuman “No, what genre is it?”\nmodel “it is a drama and family movie. i really like genre: drama entailment\ndrama movies, but this one didn’t do it for me. ” City Lights: don’t like entailment\nhuman “So you wouldn’t recommend it?”\nmodel\n“i think charlie chaplin is a bad director, but he did a gooddirector: Charles Chaplin entailment\njob with this movie. ” Charles Chaplin: don’t like entailment\nCity Lights: don’t like contradiction\nhuman “What else do you know about him?”\nmodel “i don’t know much about him, but he cofounded Charles Chaplin has trivia:entailmentthe distribution company united artists in 1919. ” Co-founded the ... in 1919.\nTable 8: Example of a dialogue from the series-enc-d1 model trained on KOMODIS . Relevant utterance-context\npairs are shown with gathered labels from our human evaluation."
}