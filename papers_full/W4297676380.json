{
  "title": "Risk of Bias in Chest Radiography Deep Learning Foundation Models",
  "url": "https://openalex.org/W4297676380",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5007222325",
      "name": "Ben Glocker",
      "affiliations": [
        "Imperial College London"
      ]
    },
    {
      "id": "https://openalex.org/A5046046780",
      "name": "Charles Jones",
      "affiliations": [
        "Imperial College London"
      ]
    },
    {
      "id": "https://openalex.org/A5043673097",
      "name": "Mélanie Roschewitz",
      "affiliations": [
        "Imperial College London"
      ]
    },
    {
      "id": "https://openalex.org/A5017366213",
      "name": "Stefan Winzeck",
      "affiliations": [
        "Imperial College London"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3195577433",
    "https://openalex.org/W4282960557",
    "https://openalex.org/W4205869058",
    "https://openalex.org/W2102826803",
    "https://openalex.org/W3177617320",
    "https://openalex.org/W4285794963",
    "https://openalex.org/W4286267143",
    "https://openalex.org/W4206154777",
    "https://openalex.org/W3085109610",
    "https://openalex.org/W4280519765",
    "https://openalex.org/W3011721937",
    "https://openalex.org/W4224322386",
    "https://openalex.org/W4200454910",
    "https://openalex.org/W4288474812",
    "https://openalex.org/W4291002614",
    "https://openalex.org/W4200191097",
    "https://openalex.org/W3044971416",
    "https://openalex.org/W4365143687",
    "https://openalex.org/W4289598835",
    "https://openalex.org/W3005030567",
    "https://openalex.org/W3139379779",
    "https://openalex.org/W4225904073",
    "https://openalex.org/W3030030520",
    "https://openalex.org/W4307923847",
    "https://openalex.org/W3110181119",
    "https://openalex.org/W2963466845",
    "https://openalex.org/W4381716616",
    "https://openalex.org/W2963446712",
    "https://openalex.org/W2886283492",
    "https://openalex.org/W4281254305",
    "https://openalex.org/W4223506650",
    "https://openalex.org/W4320516369",
    "https://openalex.org/W3165710866"
  ],
  "abstract": "Purpose: To analyze a recently published chest radiography foundation model for the presence of biases that could lead to subgroup performance disparities across biological sex and race. Materials and Methods: This retrospective study used 127,118 chest radiographs from 42,884 patients (mean age, 63 [SD] 17 years; 23,623 male, 19,261 female) from the CheXpert dataset collected between October 2002 and July 2017. To determine the presence of bias in features generated by a chest radiography foundation model and baseline deep learning model, dimensionality reduction methods together with two-sample Kolmogorov-Smirnov tests were used to detect distribution shifts across sex and race. A comprehensive disease detection performance analysis was then performed to associate any biases in the features to specific disparities in classification performance across patient subgroups. Results: Ten out of twelve pairwise comparisons across biological sex and race showed statistically significant differences in the studied foundation model, compared with four significant tests in the baseline model. Significant differences were found between male and female (P &lt; .001) and Asian and Black patients (P &lt; .001) in the feature projections that primarily capture disease. Compared with average model performance across all subgroups, classification performance on the 'no finding' label dropped between 6.8% and 7.8% for female patients, and performance in detecting 'pleural effusion' dropped between 10.7% and 11.6% for Black patients. Conclusion: The studied chest radiography foundation model demonstrated racial and sex-related bias leading to disparate performance across patient subgroups and may be unsafe for clinical applications.",
  "full_text": "1 \n \nRisk of Bias in Chest Radiography Deep Learning \nFoundation Models \n \nBen Glocker* · Charles Jones · Mélanie Roschewitz · Stefan Winzeck \n \nDepartment of Computing, Imperial College London, London, SW7 2AZ, United Kingdom \n \n*Corresponding author: b.glocker@imperial.ac.uk \n \nPre-print. Published journal version is available under https://doi.org/10.1148/ryai.230060 \nAbstract \nPurpose \nTo analyze a recently published chest radiography foundation model for the presence of biases that \ncould lead to subgroup performance disparities across biological sex and race. \nMaterials and Methods \nThis retrospective study used 127,118 chest radiographs from 42,884 patients (mean age, 63 ± [SD] \n17 years; 23,623 male, 19,261 female) from the CheXpert dataset collected between October 2002 \nand July 2017 . To determine the presence of bias  in features generated by a chest radiography \nfoundation model and baseline deep learning model, dimensionality reduction methods together with \ntwo-sample Kolmogorov-Smirnov tests were used to detect distribution shifts across sex and race. \nA comprehensive disease detection performance analysis was then performed to associate any \nbiases in the features to specific disparities in classification performance across patient subgroups. \nResults \nTen out of twelve pairwise comparisons across biological sex and race showed statistically significant \ndifferences in the studied foundation  model, compared with four significant tests in the baseline \nmodel. Significant differences were found between male and female (P < .001) and Asian and Black \npatients (P < .001) in the feature projections that primarily capture disease. Compared with average \nmodel performance across all subgroups, classification performance on the ‘no finding’ label dropped \nbetween 6.8% and 7.8% for female patients, and performance in detecting ‘pleural effusion’ dropped \nbetween 10.7% and 11.6% for Black patients. \nConclusion \nThe studied chest radiography foundation model demonstrated racial and sex-related bias leading \nto disparate performance across patient subgroups and may be unsafe for clinical applications. \n  \n2 \n \nIntroduction \nDeep learning-based predictive models have found great success in medical imaging applications , \nsuch as disease detection in chest radiography  (CXR) (1). However,  training of these models \nrequires access to large amounts of representative data. Generalization across different clinical sites \nremains a major challenge for wider clinical adoption (2). Training on limited data makes models \nsusceptible to failure whenever the data characteristics change, often caused by differences in the \npatient demographics (i.e. population shift) and/or imaging technique (i.e. acquisition shift) (3,4). \nFoundation models have emerged as a promising solution to mitigate these issues (5,6). These \nmodels are pretrained on large-scale, heterogeneous, and diverse datasets, often by self-supervised \nor semi-supervised learning strategies that do not require ground truth annotations, with the hope to \nprovide robust ‘backbones’ for task-agnostic feature extraction. These backbone features then serve \nas inputs for the subsequent, data -efficient training of task -specific prediction models. The term \n‘foundation model’ is now widely used to describe pretrained, versatile deep learning models that \ncan be adapted to a wide range of downstream prediction tasks (7). \nIn medical imaging, pretraining is particularly attractive due to the difficulty of collecting large amounts \nof high-quality training data. Recent work includes self -supervised pretraining on large unlabeled \nmedical imaging datasets , which appears to not only improve performance on data from similar \nsources (in-distribution) but also across various downstream tasks on new, out -of-distribution data \n(8). These findings were corroborated by Ghesu et al, (9) who proposed a foundation model trained \non over one million diverse medical images. Similarly, Sellergren et al (10) have recently developed \na CXR foundation model, demonstrating that it can improve performance in downstream tasks as \nwell as dra stically reduce the amount of labeled training data required for task -specific finetuning. \nThe pretrained model yielded an area under the receiver operating characteristic curve ( AUC) of \n0.95 for detecting tuberculosis when using only 45 chest radiographs for task-specific training, which \nwas noninferior to radiologist performance. Outcome prediction after COVID-19 was found to be \nbetter when freezing the backbone versus finetuning the entire model on the complete dataset, when \nusing only 528 chest radiographs for training. \nDespite their increasing popularity, little is known about potential biases encoded and reinforced in \nthese foundation models , as well as their effect on embedding biases in downstream models. \nPrevious studies on foundation models in medi cal imaging largely lack a comprehensive bias \nanalysis. This deserves a closer investigation in light of ethical and regulatory concerns regarding \nuse of foundation models in healthcare applications  (11) and, specifically, in radiology (12). Use of \nfoundation models in medical imaging may be of particular concern given the recently demonstrated \nability of deep learning models to accurately recognize protected characteristics such as racial \nidentity and other demographic information (13,14). \nIn this study, we specifically analyze a recently published CXR foundation model proposed in the \nwork by Sellergren et al. (10). We inspect the generated features of this proprietary model for the \npresence of biases that could potentially lead to disparate perform ance across patient subgroups \n(15,16). We conduct a comprehensive subgroup performance analysis when employing the \nfoundation model for the downstream application of disease detection. Our performance analysis \nassociates biases found in feature representat ion to specific performance disparities in protected \nsubgroups. \n3 \n \nMaterials and Methods \nThis retrospective study is exempt from ethical approval, as the analysis is based on secondary data \nthat is publicly available, and no permission is required to access the data. The study was compliant \nwith the Health Insurance Portability and Accountability Act (HIPAA). \nStudy Sample \nWe used a sample from the publicly available CheXpert dataset (17) composed of data from a total \nof 42,884 patients with 127,118 chest radio graphs divided into three sets for training (76,205  \nradiographs), validation (12,673  radiographs) and testing (38,240  radiographs) collected between \nOctober 2002 and July 2017. The study sample and data splits used in our study are identical to the \nones used in the recent study by Gichoya et al. (13). We refer the reader to the study by Gichoya et \nal, and specifically to their extensive supplementary material  (page 2), for an excellent discussion \nand further information about the definitions of the used rac ial groupings. The code repository  \n(https://github.com/biomedia-mira/cxr-foundation-bias) released with our study contains detailed \ninformation on how to construct the study sample from the original CheXpert dataset. \nModels \nThe primary model of our investi gation is the recently proposed CXR foundation model (10). \nAccording to the description, this model was first pretrained on a large corpus of natural images \nfollowed by a second pretraining on more than 800,000 chest radiographs from India and the United \nStates. This second pretraining step is based on supervised contrastive learning to specifically train \nfor the classification of images with and without pathology, leveraging disease labels extracted from \nradiology reports using natural language processing. The foundation model is intended to serve as \na robust feature extractor used for subsequent training of downstream, task -specific prediction \nmodels. Access to the foundation model is made available through a programming interface which \nallows only the processing of input images, with the output corresponding to the generated features. \nThe network weights of the CXR foundation model itself, however, are not publicly available, meaning \nit is not possible to update the parameters of the feature extractor duri ng training of downstream \ntasks. \nIn order to compare the CXR foundation model with a ‘traditional’ approach of model development, \nwe adopt ed a widely used deep convolutional neural network, DenseNet -121 (18), trained and \nvalidated on the CheXpert training and validation sets. This network is pretrained on natural images \nand then finetuned for the task of disease detection in chest radiography, using the disease \nannotations available in the CheXpert dataset. We use d the identical, publicly available model \ndescribed in the work by Glocker et al. (19). The already fully trained model was obtained from their \ncode repository, and no further modifications were made. Hereafter, we refer to this baseline model \nas the CheXpert model. A similar model has been used in other works and is considered state -of-\nthe-art for chest radiography disease detection (16,20). \nModel Inspection \nTo analyze whether biases may persist in the features generated by the foundation model, we used \nthe CheXpert test set with 38,240 scans. We employ ed test set resampling to correct for variations \nacross subgroups, such as racial imbalance, differences in age, and varying prevalence of disease. \nWe then used the feature exploration framework proposed by Glocker et al. (19). First, we obtained \nthe corresponding features for the entire test set by passing each scan through the model backbones \nof the CXR foundation model and the CheXpert model. The high -dimensional feature vectors were \nthen projected down to lower dimensional feature spaces using principal component analysis (PCA) \n4 \n \nand t -distributed stochastic neighbor embedding (t -SNE). For PCA, these new dimensi ons (also \ncalled modes) capture the direction of the largest variation in the high -dimensional feature space. \nThis means that for a model trained for disease detection, we find the strongest separation of \nsamples with and without the disease in the first f ew modes of PCA.  We applied t-SNE on top of \nPCA using all modes to retain 99% of the variance, aiming to capture the overall similarity between \nsamples in the original high-dimensional feature space. For the bias analysis, we randomly sampled \na set of 3,00 0 patients (1,000 samples from each racial group) and inspect ed whether the PCA \nmodes that separate samples by disease may additionally separate non -disease related patient \ncharacteristics such as biological sex or racial identity. Similarly, we inspect ed t-SNE projections to \ndetermine whether any groupings or distributional differences appear across patient subgroups. \nDifferences found across subgroups in PCA and/or t -SNE projections may indicate that the \nunderlying features do not only capture variation i n disease status but also encode biases with \nrespect to protected patient characteristics. \nModel Performance \nWhile biases in the features may not necessarily be problematic, it is important to assess if such \nbiases may affect downstream disease detection p erformance. To this end, we perform ed a \ncomprehensive subgroup performance analysis comparing different disease detection models built \nwith and without the use of the CXR foundation model. First, we used the CXR foundation model as \na feature extractor to b uild three different disease detection models by training classification \nsubmodels with increasing complexity. The classification submodels take the features generated by \nthe CXR foundation model as inputs and produce multi -label, probabilistic outputs for  different \ndisease labels. The three submodels correspond to a single , fully-connected classification layer, \ndenoted as CXR-Linear, and two multi-layer perceptrons (MLPs) with three and five hidden layers, \ndenoted as CXR-MLP-3 and CXR-MLP-5, respectively. These disease detection models represent \nthe intended use of the CXR foundation model, acting as a mechanism to facilitate effective transfer \nlearning for task-specific training of prediction models. All three classification models were trained \nusing the CheXpert training set with the corresponding validation set being used for model selection. \nWe then compared the performance of these models to our baseline CheXpert model, a DenseNet-\n121, trained on the exact same data. All models were then evaluated on the CheXpert test set, using \ntest set resampling to correct for demographic variations across subgroups. Here, we follow ed the \ntest set resampling strategy for an unbiased estimation of subgroup performance as described by \nGlocker et al. (19). We used resampling with replacement to construct balanced test sets, correcting \nfor racial imbalance, differences in age, and varying prevalence of disease. In this study, we \nevaluated and compared disease detection performance on four different labels, ‘no finding’, ‘pleural \neffusion’, ‘cardiomegaly’, and ‘pneumothorax’ , to provide a variety of results and insights across \ndifferent target predictions.  \nStatistical Analysis \nTo determine whether the features generated by a model were biased, we use d two-sample \nKolmogorov-Smirnov tests to determine p -values for the null hypothesis that the marginal \ndistributions for a given pair of subgroups are identical in each of the first four modes of PCA. These \nstatistical tests were performed for all relevant pairwise comparis ons regarding the presence of \ndisease, biological sex, and race. The p -values were adjusted for multiple testing using the \nBenjamini-Yekutieli procedure, and significance was determined at a 95% confidence level (P < .05). \nTo evaluate and compare the disease detection performance of different models, we computed the \nAUC, true positive rate (TPR), and false positive rate (FPR). TPR and FPR in subgroups were \ndetermined at a fixed decision threshold, which was optimized for each model to yield an FPR of \n0.20 o n the whole patient sample. The fixed target FPR allows for immediate identification of \n5 \n \nperformance deviations across subgroups. To provide a single measure of classification \nperformance, we report the Youden’s J statistic (measured at the target FPR), which is defined as J \n= TPR - FPR. We used bootstrapping with 2,000 samples to calculate 95% confidence intervals. \n \nAll information to recreate the exact study sample used in this paper , including splits of training, \nvalidation, and test sets, and all code that is required for reproducing the results are available under \nan open-source Apache 2.0 license in a dedicated GitHub repository ( https://github.com/biomedia-\nmira/cxr-foundation-bias). All deep learning models were implemented in PyTorch. The model \ninspection via PCA and t-SNE was done using scitkit-learn. All statistical tests were performed using \nSciPy version 1.10.0. \nResults \nPatient Characteristics \nThe study included 127,118 chest radiographs from 42,884 Asian, Black, and White patients (mean \nage, 63 ± [SD] 17 years; 23,623 male, 19,261 female). Table 1 provides a full breakdown of the study \nsample characteristics. \nModel Inspection \nFigure 1 presents t he PCA-based feature space analysis of the two inspected backbone models , \nshowing marginal distribu tions for different subgroups across the first four PCA modes. The \ncorresponding scatter plots are given in the Supplementary Material in Figure S1. Visually, we \nobserved more and larger differences in the marginal distributions for the CXR foundation mode l \nacross the protected characteristics of biological sex and race. This is particularly visible in the \nsubgroup distributions for biological sex (second column in Fig. 1) where clear shifts between males \nand females were observed in all four PCA modes, whi le no obvious separation is visible for the \nCheXpert model. Similarly, we observed larger differences in the distributions of racial groups in the \nCXR foundation model compared with the model trained on CheXpert (third column in Fig. 1). Figure \n2 presents the marginal distributions for the t-SNE projections, with the corresponding scatter plots \nshown in Figure S2. As the orientation of t -SNE dimensions is somewhat arbitrary, it was generally \nmore difficult to visually detect any potential relationship between disease information and protected \ncharacteristics. However, we still observed larger differences between subgroup distributions for both \nbiological sex and race for the CXR foundation model compared with the CheXpert model, which \nwas visible when focusing on the marginal distributions in the second and third column of Figure 2. \nThe statistical analysis confirm ed these qualitative observations  (Table 2). For biological sex, we \nfound significant differences between the marginal distribu tions for male and female patients in all \nfour PCA modes (P < .001, P = .0013, P < .001, P < .001), compared with no evidence of differences \nfound in the CheXpert model  (P > .99, P = .26, P > .99, P = .15) . Significant differences are also \nfound between the groups of Asian and Black patients in all four PCA modes in the CXR foundation \nmodel (all P < .001) versus two significant differences in the first and second mode of PCA for the \nCheXpert model (P = .021, P < .001, P = .29, P = .40). More differences were also observed between \nWhite and Asian and White and Black patients in the CXR foundation model compared to the \nCheXpert model. Focusing on the first three PCA modes, which primarily capture differences in the \nfeatures related to presence of disease (indicated by the significant differences between ‘no finding’ \nand ‘pleural effusion’), we found that ten out of twelve pairwise comparisons on protected \ncharacteristics of biological sex and race show ed significant differences in the CXR foundation \nmodel, compared with four out of twelve significant tests in the CheXpert model. Considering the \nexplained variance for each PCA mode (see Table 2), we found that the first three PCA modes \ncombined explained more than 53% of the variance in the CheXpert model compare d with 37% in \n6 \n \nthe CXR foundation model, indicating that the latter captures substantially more information in its \nfeature representation that may be unrelated to disease prediction. To rule out within patient cluster \neffects due to the presence of multiple scans per patient within the test set, we redid the analysis for \na subsampled test set with only one scan per patient. The overall findings and conclusions remained \nunchanged, confirming the larger disparities for the CXR foundation model. \nModel Performance \nThe differences in performance in terms of Youden’s J statistic across models and patient subgroups \nare summarized in the graphs presented in Figure 3. We found that the models built on top of the \nCXR foundation model, CXR -Linear, CXR-MLP-3, and CXR -MLP-5, consistently underperform ed \ncompared with the CheXpert model. Compared with average model performance across all \nsubgroups, performance in detecting ‘no finding’ dropped between 6.8% and 7.8%  for female \npatients, and performance in detecting ‘pleural effusion’ dropped between 10.7% and 11.6% for  \nBlack patients . We also observe d a drastic decrease in overall performance in classifying  \n‘cardiomegaly’ across all patient groups. Additionally, we observe d a clear difference in relative \nperformance, leading to concerning subgroup disparities. Figure 4 present s the relative change in \nperformance in terms of Youden’s J statistic for each subgroup when compared with each model’s \naverage performance over all subgroups. We observe d substantially larger d isparities in relative \nperformance across biological sex and race for the CXR foundation models compared with the \nCheXpert model. The absolute and relative performance s in terms of AUC are summarized in the \ngraphs presented in Figures S3 and S4, with similar findings of larger performance disparities across \nsubgroups for the CXR foundation model. Detailed results of the subgroup performance analysis \nwith various performance metrics are given in Tables S1-S4 in the Supplementary Material. \nDiscussion \nThis investigation aims to highlight the potential risks for using foundation models in the development \nof medical imaging artificial intelligence . The fact that the investigated CXR foundation model \nencodes protected characteristics more strongly than a task-specific backbone raises concerns, as \nthese biases could amplify already existing health disparities (21–24). Our bias analysis showed \nsignificant differences between features related to disease detection across biological sex (P < .001) \nand race (P < .001).  When using the foundation model in downstream disease detection, our \nsubgroup performance analysis revealed a substantial degradation in classification performance , \nwith specific disparities in protected subgroups. Classification performance on the ‘no finding’ label \ndropped between 6.8% and 7.8% for female patients, and performance in detecting ‘pleural effusion’ \ndropped between 10.7% and 11.6% for Black patients. \nThese findings are in line with the study by Seyyed-Kalantari et al who found performance disparities \nin chest radiograph disease detection across underrepresented subgroups (16). Our results indicate \nthat there is a risk of bias for classification models built on top of features extracted with the CXR \nfoundation model. Identifying these issues for the CheXpert dataset is noteworthy, as this dataset \nwas specifically used in the original study to evaluate the generalization ability of the foundation \nmodel (10). This highlights that even for artificial intelligence developers, it remains difficult to assess \nwhether their models may be suitable for a specific target dataset. End-users of third-party foundation \nmodels, who may have less knowledge and insights about model pretraining, may find it even more \ndifficult to assess risk of bias for their specific application and data. This is particularly concerning in \nthe light of recent studies demonstrating that medical images encode protected characteristics that \ncan be recognized by deep learning models (13,14). The availability of diverse and representative \ndatasets with detailed demographic information will be key for  algorithmic auditing and  \ncomprehensive assessment of algorithmic bias (25–27). \n7 \n \nWe believe that our findings have implications beyond the studied model, as the difficulty to scrutinize \nfoundation models applies in general , as pointed out in the work by Bommasani et al.  (5). Th is \ndifficulty stems from the fact that detailed information about the data -generating processes and the \nexact training strategies is often missing. If biases remain undetected, they can cause serious harm, \nsuch as underdiagnosis of underserved populations (16). To mitigate these risks, it will be important \nto better understand how biases are encoded and how we may prevent the use of undesired \ninformation in prediction tasks (19,28). Of note, when a prediction model is trained via finetuning of \na pretrained foundation model, we typically have two options: (a) we can ‘unfreeze’ the backbone \nmodel, allowing the finetuning process to modify the mapping f rom input images to features, \npotentially overriding biases in the backbone; or (b) we can ‘freeze’ the backbone model and learn \nonly the parameters specific to the task prediction model, which usually requires substantially fewer \ntraining data, and is therefore more appealing in practice. Arguably, the latter is more likely to carry \nforward any biases from the backbone, as the method that  features are generated remains \nunchanged. If the backbone features separate patients based on a protected characteristic, it is likely \nthat the task-specific prediction model will learn separate mechanisms for the different subgroups. \nFinetuning is unlikely to be able to ‘unlearn’ biases and may potentially exploit shortcuts for making \npredictions due to the presence of undesirable correlations in the training data (29,30). In this context, \nthe provided access to the CXR foundation model by Sellergren et al.  (10) is problematic, as the \ndevelopers only offer option (b). The original backbone model is not publicly shared ; hence, one \ncannot update the mechanism for feature extraction when performing the task -specific finetuning, \nwhich limits the use of debiasing tech niques (28,31). The observed differences in absolute  and \nrelative subgroup performance may be partly explained by the fact that the CXR foundation model \nwas frozen during training of the classification submodels. \nOur study has important limitations. We ana lyzed only one foundation model that was trained in a \nspecific way, using supervised contrastive learning. Future work should explore whether biases also \nmanifest in other chest radiography foundation models that are trained differently, such as via self -\nsupervision without any annotations  (8,9). Such models, however, are currently not publicly \navailable. We may expect to find similar biases in models with fully self-supervised training, as such \ntraining strategies encourage grouping of individuals in featu re space s that are visually similar. \nTherefore, we may expect to see clusters for biological sex and potentially race, as these \ncharacteristics are known to be separable with high predictive accuracy (13,14,32). We believe that \nour work may provide a methodological basis for future bias analyses. Another limitation is that we \ncould not shed light on the exact origin of the biases in the studied foundation model due to \ninsufficient insights into the exact training data characteristics. While the amount of training data for \nthe foundation model was considerably large, with more than 800,000 chest radiographs, it was \nlimited to data from two countries, India and the United States. Most images, over 700,000, were \nreported to come from India, which may contribute  to the observed bias across racial subgroups. It \nhas been argued previously that mixing effects from dataset bias are notoriously difficult to analyze \n(33). Thus, a more systematic approach with controlled, simulated environments to specifically inject \ndifferent types of bias may be required to isolate the effect of each bias on classification performance. \nIn conclusion, our study demonstrates that biases in the CXR foundation model related to race and \nbiologic sex led to substantial performance disparities across protected subgroups. To minimize the \nrisk of bias associated with use of foundation models in critical applications such as clinical decision \nmaking, we argue that these models need to be fully accessible and transparent. This is important \nfor allowing a more detailed analysis of potential biases and scrutiny of the resulting task -specific \nprediction models. Here, we advocate for comprehensive bias analysis and subgroup performance \nanalysis to become integral parts in the development and auditing of future foundation models, which \nis essential for their safe and ethical use in healthcare applications. \n  \n8 \n \nDeclaration of interests \nB.G. is a part -time employee of HeartFlow and Kheiron Medical Technologies and holds stock \noptions with both as part of the standard compensation packag e. He was a part -time employee at \nMicrosoft Research until May, 2021 and a scientific advisor for Kheiron Medical Technologies until \nSeptember, 2021. All other authors declare no competing interests. \nData and code availability \nAll data and code used in this work is publicly available. The CheXpert imaging dataset can be \nobtained from https://stanfordmlgroup.github.io/competitions/chexpert/. The demographic \ninformation is available on https://stanfordaimi.azurewebsites.net/datasets/192ada7c-4d43-466e-\nb8bb-b81992bb80cf. \n \nAll information and code to reproduce our results and recreate the exact study sample used in this \npaper including splits of training, validation, and test sets is available under an open source Apache \n2.0 license in our dedicated GitHub repository https://github.com/biomedia-mira/cxr-foundation-bias/. \nAcknowledgments \nB.G. received funding from the European Research Council (ERC) under the European Union’s \nHorizon 2020 research and innovation programme (Grant Agreement No. 757173, Project MIRA) . \nS.W. is supported by the UKRI London Medical Imaging & Artificial Intelligence Centre for Value \nBased Healthcare. C.J. is supported by Microsoft Research and EPSRC. M.R. is funded through an \nImperial College London President’s PhD Scholarship. \n9 \n \nReferences \n1.  Çallı E, Sogancioglu E, van Ginneken B, van Leeuwen KG, Murphy K. Deep learning for chest X -ray \nanalysis: A survey. Med Image Anal. 2021;72:102125. \n2.  Finlayson SG, Subbaswamy A, Singh K, et al. The Clinician and Dataset Shift in Artificial Intelligence. N \nEngl J Med. 2021;385(3):283–286. \n3.  Castro DC, Walker I, Glocker B. Causality matters in medical imaging. Nat Commun. 2020;11(1):3673.  \n4.  Cohen JP, Hashir M, Brooks R, Bertrand H. On the limits of cross-domain generalization in automated \nX-ray prediction. In: Arbel T, Ben Ayed I, de Bruijne M, Descoteaux M, Lombaert H, Pal C, editors. \nProceedings of the Third Conference on Medical Imaging with Deep Learning. PMLR; 06 --08 Jul 2020. \np. 136–155. \n5.  Bommasani R, Hudson DA, Adeli E, et al. On the Opportunities and Risks of Foundation Models. arXiv \n[cs.LG]. 2021. http://arxiv.org/abs/2108.07258. \n6.  Moor M, Banerjee O, Abad ZSH, et al. Foundation models for generalist medical artificial intelligence. \nNature. 2023;616(7956):259–265. \n7.  Willemink MJ, Roth HR, Sandfort V. Toward Foundational Deep Learning Models for Medical Imaging in \nthe New Era of Transformer Networks. Radiol Artif Intell. 2022;4(6):e210284. \n8.  Azizi S, Culp L, Freyberg J, et al. Robust and Efficient Medical Imaging with Self -Supervision. arXiv \n[cs.CV]. 2022. http://arxiv.org/abs/2205.09723. \n9.  Ghesu FC, Georgescu B, Mansoor A, et al. Self-supervised Learning from 100 Million Medical Images. \narXiv [cs.CV]. 2022. http://arxiv.org/abs/2201.01283. \n10.  Sellergren AB, Chen C, Nabulsi Z, et al. Simplified Transfer Learning for Chest Radiography Models \nUsing Less Data. Radiology. 2022;212482. \n11.  Wójcik MA. Foundation Models in Healthcare: Opportunities, Biases and Regulatory Prospects in \nEurope. Electronic Government and the Information Systems Perspective. Springer International \nPublishing; 2022. p. 32–46. \n12.  Wiggins WF, Tejani AS. On the Opportunities and Risks of Foundation Models for Natural Language \nProcessing in Radiology. Radiol Artif Intell. 2022;4(4):e220119. \n13.  Gichoya JW, Banerjee I, Bhimireddy AR, et al. AI recognition of patient race in medical imaging: a \nmodelling study. Lancet Digit Health. 2022;4(6):e406–e414. \n14.  Adleberg J, Wardeh A, Doo FX, et al. Predicting Patient Demographics From Chest Radiographs With \nDeep Learning. J Am Coll Radiol. 2022;19(10):1151–1161. \n15.  Larrazabal AJ, Nieto N, Peterson V, Milone DH, Ferrante E. Gender imbalance in medical imaging \ndatasets produces biased classifiers for computer-aided diagnosis. Proc Natl Acad Sci U S A. \n2020;117(23):12592–12594. \n16.  Seyyed-Kalantari L, Zhang H, McDermott MBA, Chen IY, Ghassemi M. Underdiagnosis bias of artificial \nintelligence algorithms applied to chest radiographs in under-served patient populations. Nat Med. \n2021;27(12):2176–2182. \n17.  Irvin J, Rajpurkar P, Ko M, et al. CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels \nand Expert Comparison. AAAI. 2019;33(01):590–597. \n18.  Huang G, Liu Z, Van Der Maaten L, Weinberger KQ. Densely connected convolutional networks. \nProceedings of the IEEE conference on computer vision and pattern recognition. 2017. p. 4700 –4708. \n19.  Glocker B, Jones C, Bernhardt M, Winzeck S. Algorithmic encoding of protected characteristics in ches t \nX-ray disease detection models. EBioMedicine. 2023;89:104467. \n20.  Seyyed-Kalantari L, Liu G, McDermott M, Chen IY, Ghassemi M. CheXclusion: Fairness gaps in deep \n10 \n \nchest X-ray classifiers. Pac Symp Biocomput. 2021;26:232–243. \n21.  Pinkerton KE, Harbaugh M, Han MK, et al. Women and Lung Disease. Sex Differences and Global \nHealth Disparities. Am J Respir Crit Care Med. 2015;192(1):11–16. \n22.  Adamson AS, Smith A. Machine Learning and Health Care Disparities in Dermatology. JAMA \nDermatology. 2018. p. 1247. doi: 10.1001/jamadermatol.2018.2348. \n23.  Cho MK. Rising to the challenge of bias in health care AI. Nat. Med. 2021. p. 2079–2081. \n24.  Cullen MR, Lemeshow AR, Russo LJ, Barnes DM, Ababio Y, Habtezion A. Disease-Specific Health \nDisparities: A Targeted Review Focusing on Race and Ethnicity. Healthcare (Basel). 2022;10(4). doi: \n10.3390/healthcare10040603. \n25.  Liu X, Glocker B, McCradden MM, Ghassemi M, Denniston AK, Oakden-Rayner L. The medical \nalgorithmic audit. Lancet Digit Health. 2022; doi: 10.1016/S2589-7500(22)00003-6. \n26.  McCradden MD, Anderson JA, A Stephenson E, et al. A Research Ethics Framework for the Clinical \nTranslation of Healthcare Machine Learning. Am J Bioeth. 2022;1–15. \n27.  Yi PH, Kim TK, Siegel E, Yahyavi-Firouz-Abadi N. Demographic Reporting in Publicly Available Chest \nRadiograph Data Sets: Opportunities for Mitigating Sex and Racial Disparities in Deep Learning Models. \nJ Am Coll Radiol. 2022;19(1, Part B):192–200. \n28.  Marcinkevics R, Ozkan E, Vogt JE. Debiasing Deep Chest X-Ray Classifiers using Intra- and Post-\nprocessing Methods. In: Lipton Z, Ranganath R, Sendak M, Sjoding M, Yeung S, editors. Proceedings of \nthe 7th Machine Learning for Healthcare Conference. PMLR; 05--06 Aug 2022. p. 504–536. \n29.  DeGrave AJ, Janizek JD, Lee S-I. AI for radiographic COVID-19 detection selects shortcuts over signal. \nmedRxiv. 2020; doi: 10.1101/2020.09.13.20193565. \n30.  Oakden-Rayner L, Dunnmon J, Carneiro G, Ré C. Hidden Stratification Causes Clinically Meaningful \nFailures in Machine Learning for Medical Imaging. Proc ACM Conf Health Inference Learn (2020). \n2020;2020:151–159. \n31.  Nazer LH, Zatarah R, Waldrip S, et al. Bias in artificial intelligence algorithms and recommendations for \nmitigation. PLOS Digit Health. 2023;2(6):e0000278. \n32.  Yi PH, Wei J, Kim TK, et al. Radiology “forensics”: determination of age and sex from chest radiographs \nusing deep learning. Emerg Radiol. 2021;28(5):949–954. \n33.  Bernhardt M, Jones C, Glocker B. Potential sources of dataset bias complicate investigation of \nunderdiagnosis by machine learning algorithms. Nat. Med. 2022. p. 1157–1158. \n \n  \n11 \n \nFigure 1. Inspection of subgroup distribution shifts in the PCA feature space projections.  \nMarginal distributions are plotted across subgroups for the first four modes of PCA applied to the \nextracted feature vectors of the CheXpert test data for (a-d) the CheXpert model and (e-h) the CXR \nfoundation model. The plots are generated using a random set of 3,000 patients (1,000 samples from \neach racial group). Marginal distributions are normalized independently to remove differences in \nsubgroup base rates and shown for different characteristics (from left to right): presence of disease, \nbiological sex, and racial identity. Larger distribution shifts across sex and race are observed for the \nCXR foundation model. CXR = chest radiography, PCA = principal component analysis \n \n \n\n12 \n \nFigure 2. Inspection of subgroup distribution shifts in the t -SNE feature space projections.  \nMarginal distributions are plotted across subgroups for the two dimensions of t -SNE applied to the \nextracted feature vectors of the CheXpert test data for (a,b) the CheXpert model and (c,d) the CXR \nfoundation model. The plots are generated using a random set of 3,000 patients (1,000 samples from \neach racial group). Marginal distributions are normalized independently to remove differences in \nsubgroup base rates and shown for different characteristics (from left to right): presence of disease, \nbiological sex, and racial identity. Larger distribution shifts across sex and race are observed for the \nCXR foundation model.  CXR = chest radiography, t -SNE = t -distributed stochastic neighbor \nembedding \n \n\n13 \n \nFigure 3. Comparison of disease detection performance across patient subgroups.  \nAverage classification performance across patient subgroups is shown in terms of Youden’s J \nstatistic for the DenseNet -121 CheXpert model and three variants of the CX R foundation model. \nClassification performance is shown on four different labels of (a) ‘no finding’, (b) ‘pleural effusion’, \n(c) ‘cardiomegaly’, and (d) ‘pneumothorax’. The CXR foundation models consistently \nunderperformed compared with the CheXpert model , with specific underperformance on the \nsubgroup of female patients for ‘no finding’ and the subgroup of Black patients on ‘pleural effusion’. \nThere was also  a drastic decrease in overall performance across all subgroups for the CXR \nfoundation models for ‘cardiomegaly’. CXR = chest radiography, MLP = multi-layer perceptrons \n  \n\n14 \n \n \nFigure 4. Relative change in disease detection performance across patient subgroups.  \nThe relative change in performance for each subgroup was measured by comparing the subgroup \nperformance with each model’s average performance over all subgroups. Performance is measured \nin terms of Youden’s J statistic on the labels of (a) ‘no finding’, (b) ‘pleural effusion’, (c) ‘cardiomegaly’, \nand (d) ‘pneumothorax’. There were substantially larger disparities in relative performance across \nbiological sex and race for the three CXR foundation models, CXR -Linear, CXR-MLP-3, and CXR-\nMLP-5 when compared with the DenseNet-121 CheXpert model. CXR = chest radiography, MLP = \nmulti-layer perceptrons \n \n \n  \n\n15 \n \nTable 1. Characteristics of the Study Sample \n CheXpert Dataset \n All White Asian Black Male Female \nAttribute All data \nPatients 42,884 33,338  6,642 2,904 23,623 19,261 \nScans 127,118 99,027 (78) 18,830 (15) 9,261 (7) 74,682 (59) 52,436 (41) \nAge (years) 63 ± 17 64 ± 17 61 ± 17  56 ± 17 62 ± 17 64 ± 18 \nFemale 52,436 (41) 39,735 (40) 8,132 (43)  4,569 (49)  - - \nNo finding 10,916 (9)  8,236 (8)  1,716 (9)  964 (10)  6,280 (8) 4,636 (9) \nPleural effusion 51,574 (41)  40,545 (41)  7,953 (42) 3,076 (33) 30,171 (40) 21,403 (41) \nCardiomegaly 15,790 (12) 11,561 (12) 2,375 (13) 1,854 (20) 9,793 (13) 5,997 (11) \nPneumothorax 12,237 (10) 9,653 (10) 2,013 (11) 571 (6) 7,280 (10) 4,957 (9) \n Training data \nPatients 25,730 20,034 3,945  1,751 14,164 11,566 \nScans 76,205 59,238 (78) 11,371 (15) 5,596 (7) 44,773 (59) 31,432 (41) \nAge (years) 63 ± 17 64 ± 17  62 ± 17  56 ± 17 62 ± 17 64 ± 18 \nFemale 31,432 (41)  23,715 (40)  4,976 (44)  2,741 (49) - - \nNo finding 6,514 (9) 4,910 (8) 1,046 (9) 558 (10) 3,756 (8) 2,758 (9) \nPleural effusion 31,015 (41) 24,405 (41) 4,754 (42) 1,856 (33) 18,174 (41) 12,841 (41) \nCardiomegaly 9,353 (12) 6,835 (12) 1,397 (12) 1,121 (20) 5,864 (13) 3,489 (11) \nPneumothorax 7,435 (10) 5,871 (10) 1,235 (11) 329 (6) 4,461 (10) 2,974 (9) \n Validation data \nPatients 4,288  3,348  666 274 2,367 1,921 \nScans 12,673 9,945 (79) 1,809 (14) 919 (7) 7,643 (60) 5,030 (40) \nAge (years) 62 ±17  63 ± 17 62 ± 17  55 ± 16 62 ± 17 63 ± 18 \nFemale 5,030 (40)  3,933 (40) 667 (37)  430 (47) - - \nNo finding 1,086 (9)  817 (8)  175 (10)  94 (10) 602 (8) 484 (10) \nPleural effusion  5,049 (40)  3,988 (40)  738 (41)  323 (35)  3,086 (40) 1,963 (39) \nCardiomegaly 1,548 (12) 1,156 (12) 222 (12) 170 (18) 987 (13) 561 (11) \nPneumothorax 1,220 (10) 956 (10) 168 (9) 96 (10) 744 10) 476 (9) \n Test data \nPatients 12,866 9,956 2,031 879 7,092 5,774 \nScans 38,240  29,844 (78)  5,650 (15) 2,746 (7) 22,266 (58) 15,974 (42) \nAge (years) 63 ± 17 64 ± 17 61 ± 17 57 ± 16 63 ± 16 64 ± 18 \nFemale 15,974 (42)  12,087 (41)  2,489 (44)  1,348 (49) - - \nNo finding 3,316 (9)  2,509 (8)  495 (9)  312 (11) 1,922 (9) 1,394 (9) \nPleural effusion 15,510 (41)  12,152 (41)  2,461 (44) 897 (33) 8,911 (40) 6,599 (41) \nCardiomegaly 4,889 (13) 3,570 (12) 756 (13) 563 (21) 2,942 (13) 1,947 (12) \nPneumothorax 3,582 (9) 2,826 (9) 610 (11) 146 (5) 2,075 (9) 1,507 (9) \nNote.—Breakdown of demographics over the set of patient scans by racial groups and training, validation and test splits. \nPercentages in brackets are with respect to the number of scans. Age is reported as mean ± SD. We also report the \nnumber of unique patients.  \n16 \n \nTable 2. Kolmogorov-Smirnov Tests for Comparing Marginal Distributions Across PCA Modes \n  CheXpert model \n  No finding / \nPleural effusion White / Asian Asian / Black Black / White Male / Female \nMode Exp. Var. p-values \nPCA mode 1 31.2% <0.0001** 1.00 0.021* 0.40 1.00 \nPCA mode 2 9.0% 0.012* 1.00 <0.0001** <0.0001** 0.26 \nPCA mode 3 7.9% <0.0001** 0.025* 0.29 1.00 1.00 \nPCA mode 4 5.1% 0.12 1.00 0.40 0.16 0.15 \n  CXR foundation model \n  No finding / \nPleural effusion White / Asian Asian / Black Black / White Male / Female \nMode Exp. Var. p-values \nPCA mode 1 16.8% <0.0001** 0.96 <0.0001** 0.00031** <0.0001** \nPCA mode 2 8.6% <0.0001** 0.0013* <0.0001** 0.0044* 0.0013* \nPCA mode 3 7.3% <0.0001** <0.0001** <0.0001** 1.00 <0.0001** \nPCA mode 4 4.2% 1.00 <0.0001** <0.0001** 0.00018** <0.0001** \nNote.—Two-sample Kolmogorov-Smirnov tests were performed between the pairs of subgroups indicated in each \ncolumn. The p-values are adjusted for multiple testing using the Benjamini-Yekutieli procedure, and significance is \ndetermined at a 95% confidence level. Statistically significant results are marked with * P < .05 and ** P < .001. CXR = \nchest radiography, PCA = principal component analysis \n \n17 \n \nSupplementary Material \nFigure S1. Inspection of the PCA feature space projections of two different models.  \nScatter plots with marginal distributions displayed at the axes are shown for the first four modes of \nPCA applied to the extracted feature vectors of the CheXpert test data in for  (a,b) the CheXpert \nmodel, and in for  (c,d) the CXR foundation model. The plots are generated using a random set of \n3,000 patients (1,000 samples from each racial group). Marginal distributions are normalized \nindependently to remove differences in subgroup base rates. Different characteristics are overlaid in \ncolor (from left to right ): presence of disease, biological sex, racial identity, and age. Larger \ndistribution shifts across sex and race are observed for the CXR foundation model.  CXR = chest \nradiography, PCA = principal component analysis \n\n18 \n \n \nFigure S2. Inspection of the t -SNE feature space projections of two different models.  \nScatter plots with marginal distributions displayed at the axes are shown for the two dimensions of t-\nSNE applied to the extracted feature vectors of the CheXpert test data in (a) for the CheXpert model, \nand in (b) for the CXR foundation model. The plots are generated using a random set of 3,000 \npatients (1,000 samples from each racial group). Marginal distributions are normalized independently \nto remove differences in subgroup base rates. Different characteristics are overlaid in color (from left \nto right): presence of disease, biological sex, racial identity, and age. Larger distribution shifts across \nsex and race are observed for the CXR foundation model.  CXR = chest radiography, t -SNE = t -\ndistributed stochastic neighbor embedding \n \n\n19 \n \n \nFigure S3. Comparison of disease detection performance across patient subgroups.  \nAverage classification performance across patient subgroups is shown in terms of AUC for the \nDenseNet-121 CheXpert model, and three variants of the CXR foundation model. Classification \nperformance is shown on four different labels of (a) ‘no finding’, (b) ‘pleural effusion’, (c) \n‘cardiomegaly’, and (d) ‘pneumothorax’. The CXR foundation models consistently underperform \ncompared to the CheXpert model. CXR = chest radiography, MLP = multi-layer perceptrons, AUC = \narea under the receiver operating characteristic curve \n \n  \n\n20 \n \nFigure S4. Relative change in disease detection performance across patient subgroups.  \nThe relative change in performance for each subgroup is measured by comparing the subgroup \nperformance to each model’s average performance over all subgroups. Performance is measured in \nterms of AUC on the labels of (a) ‘no finding’, (b) ‘pleural effusion’, (c) ‘cardiomegaly’, and (d) \n‘pneumothorax’. We observe substantially larger disparities in relative performance across biological \nsex and race for the three CXR foundation models, CXR-Linear, CXR-MLP-3, and CXR-MLP-5 when \ncompared to the DenseNet -121 CheXpert model.  CXR = chest radiography, MLP = multi -layer \nperceptrons, AUC = area under the receiver operating characteristic curve \n \n \n  \n\n21 \n \nTable S1. Comparison of disease detection performance for the label ‘no finding’ \n No finding \n White Asian Black Female Male \nModel AUC (95% CI) \nDenseNet-121 0.87 (0.86-0.88) 0.87 (0.87-0.88) 0.89 (0.88-0.89) 0.87 (0.86-0.87) 0.89 (0.88-0.89) \nCXR-Linear 0.85 (0.85-0.86) 0.85 (0.85-0.86) 0.87 (0.87-0.88) 0.85 (0.84-0.85) 0.87 (0.86-0.87) \nCXR-MLP-3 0.86 (0.85-0.87) 0.86 (0.85-0.86) 0.87 (0.87-0.88) 0.85 (0.85-0.86) 0.87 (0.87-0.88) \nCXR-MLP-5 0.85 (0.85-0.86) 0.86 (0.85-0.86) 0.87 (0.86-0.88) 0.85 (0.84-0.85) 0.87 (0.87-0.88) \n TPR (95% CI) \nDenseNet-121 0.80 (0.78-0.81) 0.79 (0.78-0.81) 0.81 (0.80-0.82) 0.78 (0.76-0.79) 0.82 (0.81-0.83) \nCXR-Linear 0.78 (0.77-0.80) 0.79 (0.78-0.81) 0.80 (0.78-0.81) 0.76 (0.75-0.77) 0.82 (0.81-0.83) \nCXR-MLP-3 0.78 (0.77-0.79) 0.79 (0.77-0.80) 0.80 (0.78-0.81) 0.74 (0.73-0.75) 0.83 (0.82-0.84) \nCXR-MLP-5 0.77 (0.75-0.78) 0.78 (0.77-0.79) 0.77 (0.76-0.79) 0.73 (0.71-0.74) 0.81 (0.80-0.82) \n FPR (95% CI) \nDenseNet-121 0.20 (0.20-0.21) 0.20 (0.20-0.20) 0.20 (0.19-0.20) 0.20 (0.20-0.20) 0.20 (0.20-0.20) \nCXR-Linear 0.20 (0.20-0.20) 0.19 (0.19-0.20) 0.21 (0.20-0.21) 0.21 (0.21-0.21) 0.19 (0.19-0.20) \nCXR-MLP-3 0.20 (0.19-0.20) 0.20 (0.20-0.20) 0.21 (0.20-0.21) 0.20 (0.20-0.20) 0.20 (0.20-0.20) \nCXR-MLP-5 0.21 (0.20-0.21) 0.20 (0.19-0.20) 0.20 (0.19-0.20) 0.20 (0.19-0.20) 0.20 (0.20-0.21) \n Youden’s J statistic (95% CI) \nDenseNet-121 0.59 (0.58-0.61) 0.59 (0.58-0.61) 0.61 (0.60-0.63) 0.58 (0.56-0.59) 0.62 (0.61-0.63) \nCXR-Linear 0.58 (0.57-0.60) 0.60 (0.59-0.62) 0.59 (0.58-0.61) 0.55 (0.54-0.56) 0.63 (0.61-0.64) \nCXR-MLP-3 0.58 (0.57-0.60) 0.59 (0.57-0.60) 0.59 (0.58-0.61) 0.54 (0.53-0.55) 0.63 (0.62-0.64) \nCXR-MLP-5 0.56 (0.55-0.58) 0.58 (0.57-0.60) 0.58 (0.56-0.59) 0.53 (0.52-0.54) 0.61 (0.60-0.62) \nNote.—Disease detection results reported separately for each race group and biological sex. TPR and FPR in subgroups \nare determined using a fixed decision threshold optimized over the whole patient population for a target FPR of 0.20. \nPerformance is reported as mean and 95% confidence interval (CI). AUC = area under the receiver operating \ncharacteristic curve, TPR = true positive rate, FPR = false positive rate, CXR = chest radiography, MLP = multi-layer \nperceptrons \n \n  \n22 \n \nTable S2. Comparison of disease detection performance for the label ‘pleural effusion’ \n Pleural effusion \n White Asian Black Female Male \nModel AUC (95% CI) \nDenseNet-121 0.87 (0.86-0.87) 0.88 (0.88-0.89) 0.85 (0.84-0.85) 0.87 (0.87-0.87) 0.86 (0.86-0.86) \nCXR-Linear 0.84 (0.84-0.84) 0.85 (0.85-0.86) 0.81 (0.80-0.81) 0.83 (0.83-0.84) 0.83 (0.83-0.84) \nCXR-MLP-3 0.84 (0.84-0.85) 0.86 (0.85-0.86) 0.81 (0.81-0.81) 0.84 (0.83-0.84) 0.84 (0.83-0.84) \nCXR-MLP-5 0.84 (0.84-0.85) 0.86 (0.85-0.86) 0.81 (0.80-0.81) 0.84 (0.83-0.84) 0.83 (0.83-0.84) \n TPR (95% CI) \nDenseNet-121 0.78 (0.78-0.79) 0.80 (0.80-0.81) 0.72 (0.71-0.73) 0.78 (0.77-0.79) 0.76 (0.75-0.76) \nCXR-Linear 0.73 (0.72-0.74) 0.76 (0.75-0.77) 0.62 (0.61-0.63) 0.73 (0.72-0.74) 0.68 (0.67-0.69) \nCXR-MLP-3 0.73 (0.72-0.74) 0.76 (0.75-0.77) 0.62 (0.61-0.63) 0.71 (0.70-0.72) 0.70 (0.69-0.70) \nCXR-MLP-5 0.74 (0.73-0.75) 0.75 (0.74-0.76) 0.63 (0.62-0.64) 0.72 (0.72-0.73) 0.69 (0.68-0.70) \n FPR (95% CI) \nDenseNet-121 0.21 (0.21-0.21) 0.21 (0.20-0.21) 0.18 (0.18-0.19) 0.20 (0.20-0.21) 0.20 (0.19-0.20) \nCXR-Linear 0.21 (0.21-0.22) 0.21 (0.21-0.22) 0.17 (0.17-0.18) 0.22 (0.21-0.22) 0.19 (0.18-0.19) \nCXR-MLP-3 0.22 (0.21-0.22) 0.21 (0.21-0.22) 0.17 (0.17-0.17) 0.21 (0.20-0.21) 0.19 (0.19-0.20) \nCXR-MLP-5 0.21 (0.21-0.22) 0.21 (0.20-0.21) 0.18 (0.17-0.18) 0.21 (0.20-0.21) 0.19 (0.19-0.20) \n Youden’s J statistic (95% CI) \nDenseNet-121 0.57 (0.56-0.58) 0.59 (0.59-0.60) 0.54 (0.52-0.55) 0.57 (0.57-0.58) 0.56 (0.55-0.57) \nCXR-Linear 0.51 (0.51-0.52) 0.54 (0.54-0.55) 0.44 (0.44-0.46) 0.51 (0.50-0.52) 0.49 (0.48-0.50) \nCXR-MLP-3 0.52 (0.51-0.53) 0.55 (0.54-0.56) 0.45 (0.44-0.46) 0.50 (0.49-0.51) 0.50 (0.50-0.51) \nCXR-MLP-5 0.52 (0.52-0.53) 0.54 (0.53-0.55) 0.45 (0.44-0.46) 0.52 (0.51-0.52) 0.50 (0.49-0.50) \nNote.—Disease detection results reported separately for each race group and biological sex. TPR and FPR in subgroups \nare determined using a fixed decision threshold optimized over the whole patient population for a target FPR of 0.20. \nPerformance is reported as mean and 95% confidence interval (CI). AUC = area under the receiver operating \ncharacteristic curve, TPR = true positive rate, FPR = false positive rate, CXR = chest radiography, MLP = multi-layer \nperceptrons \n \n  \n23 \n \nTable S3. Comparison of disease detection performance for the label ‘cardiomegaly’ \n Cardiomegaly \n White Asian Black Female Male \nModel AUC (95% CI) \nDenseNet-121 0.85 (0.85-0.86) 0.86 (0.85-0.87) 0.86 (0.86-0.87) 0.86 (0.85-0.86) 0.87 (0.86-0.87) \nCXR-Linear 0.80 (0.79-0.81) 0.82 (0.81-0.83) 0.80 (0.79-0.80) 0.80 (0.79-0.80) 0.82 (0.81-0.82) \nCXR-MLP-3 0.81 (0.80-0.81) 0.82 (0.81-0.83) 0.80 (0.80-0.81) 0.80 (0.80-0.81) 0.82 (0.82-0.82) \nCXR-MLP-5 0.81 (0.80-0.81) 0.82 (0.81-0.82) 0.79 (0.79-0.80) 0.80 (0.79-0.80) 0.82 (0.81-0.82) \n TPR (95% CI) \nDenseNet-121 0.75 (0.73-0.76) 0.73 (0.72-0.74) 0.81 (0.80-0.82) 0.75 (0.74-0.76) 0.79 (0.78-0.80) \nCXR-Linear 0.61 (0.59-0.62) 0.65 (0.64-0.66) 0.69 (0.68-0.71) 0.66 (0.65-0.67) 0.66 (0.65-0.67) \nCXR-MLP-3 0.62 (0.60-0.63) 0.64 (0.63-0.65) 0.71 (0.70-0.72) 0.67 (0.66-0.68) 0.66 (0.65-0.67) \nCXR-MLP-5 0.61 (0.59-0.62) 0.63 (0.62-0.64) 0.68 (0.66-0.69) 0.65 (0.64-0.66) 0.64 (0.63-0.65) \n FPR (95% CI) \nDenseNet-121 0.18 (0.18-0.19) 0.17 (0.17-0.18) 0.25 (0.24-0.25) 0.19 (0.19-0.20) 0.20 (0.20-0.21) \nCXR-Linear 0.17 (0.16-0.17) 0.19 (0.18-0.19) 0.25 (0.25-0.26) 0.22 (0.22-0.22) 0.18 (0.18-0.19) \nCXR-MLP-3 0.18 (0.17-0.18) 0.18 (0.17-0.18) 0.25 (0.25-0.25) 0.22 (0.22-0.22) 0.18 (0.18-0.19) \nCXR-MLP-5 0.18 (0.17-0.18) 0.18 (0.18-0.19) 0.24 (0.24-0.25) 0.22 (0.21-0.22) 0.19 (0.18-0.19) \n Youden’s J statistic (95% CI) \nDenseNet-121 0.57 (0.55-0.58) 0.56 (0.54-0.57) 0.56 (0.55-0.57) 0.56 (0.55-0.57) 0.58 (0.57-0.59) \nCXR-Linear 0.44 (0.43-0.46) 0.46 (0.45-0.48) 0.44 (0.43-0.45) 0.44 (0.43-0.45) 0.47 (0.46-0.48) \nCXR-MLP-3 0.44 (0.42-0.45) 0.46 (0.45-0.48) 0.46 (0.45-0.47) 0.45 (0.44-0.46) 0.48 (0.47-0.49) \nCXR-MLP-5 0.43 (0.42-0.45) 0.45 (0.43-0.46) 0.43 (0.42-0.44) 0.43 (0.42-0.45) 0.45 (0.44-0.46) \nNote.—Disease detection results reported separately for each race group and biological sex. TPR and FPR in subgroups \nare determined using a fixed decision threshold optimized over the whole patient population for a target FPR of 0.20. \nPerformance is reported as mean and 95% confidence interval (CI). AUC = area under the receiver operating \ncharacteristic curve, TPR = true positive rate, FPR = false positive rate, CXR = chest radiography, MLP = multi-layer \nperceptrons \n \n  \n24 \n \nTable S4. Comparison of disease detection performance for the label ‘pneumothorax’ \n Pneumothorax \n White Asian Black Female Male \nModel AUC (95% CI) \nDenseNet-121 0.85 (0.84-0.86) 0.87 (0.86-0.87) 0.87 (0.86-0.88) 0.87 (0.86-0.87) 0.87 (0.86-0.87) \nCXR-Linear 0.81 (0.80-0.81) 0.82 (0.81-0.83) 0.83 (0.82-0.84) 0.83 (0.82-0.83) 0.82 (0.81-0.82) \nCXR-MLP-3 0.80 (0.80-0.81) 0.82 (0.81-0.83) 0.84 (0.83-0.85) 0.82 (0.81-0.83) 0.83 (0.82-0.83) \nCXR-MLP-5 0.81 (0.80-0.81) 0.82 (0.81-0.83) 0.82 (0.80-0.83) 0.82 (0.81-0.82) 0.82 (0.81-0.83) \n TPR (95% CI) \nDenseNet-121 0.77 (0.75-0.78) 0.78 (0.77-0.80) 0.77 (0.75-0.79) 0.77 (0.76-0.78) 0.78 (0.77-0.79) \nCXR-Linear 0.67 (0.65-0.68) 0.71 (0.69-0.72) 0.69 (0.66-0.71) 0.67 (0.66-0.69) 0.70 (0.69-0.72) \nCXR-MLP-3 0.69 (0.67-0.71) 0.70 (0.68-0.71) 0.67 (0.65-0.70) 0.64 (0.63-0.67) 0.72 (0.71-0.73) \nCXR-MLP-5 0.68 (0.67-0.70) 0.71 (0.69-0.72) 0.67 (0.64-0.69) 0.66 (0.64-0.68) 0.71 (0.70-0.73) \n FPR (95% CI) \nDenseNet-121 0.22 (0.22-0.23) 0.21 (0.20-0.21) 0.17 (0.17-0.17) 0.18 (0.18-0.19) 0.21 (0.21-0.22) \nCXR-Linear 0.22 (0.22-0.23) 0.22 (0.21-0.22) 0.16 (0.16-0.16) 0.18 (0.18-0.19) 0.21 (0.21-0.22) \nCXR-MLP-3 0.22 (0.22-0.22) 0.22 (0.22-0.22) 0.16 (0.16-0.17) 0.18 (0.17-0.18) 0.22 (0.22-0.22) \nCXR-MLP-5 0.22 (0.21-0.22) 0.22 (0.22-0.23) 0.16 (0.16-0.16) 0.18 (0.18-0.18) 0.22 (0.21-0.22) \n Youden’s J statistic (95% CI) \nDenseNet-121 0.55 (0.53-0.56) 0.58 (0.56-0.59) 0.60 (0.58-0.62) 0.59 (0.57-0.60) 0.56 (0.55-0.58) \nCXR-Linear 0.44 (0.43-0.46) 0.49 (0.48-0.50) 0.53 (0.50-0.55) 0.49 (0.47-0.50) 0.49 (0.48-0.50) \nCXR-MLP-3 0.47 (0.45-0.49) 0.48 (0.46-0.49) 0.50 (0.48-0.54) 0.47 (0.45-0.49) 0.50 (0.49-0.51) \nCXR-MLP-5 0.47 (0.45-0.48) 0.48 (0.47-0.50) 0.51 (0.48-0.53) 0.48 (0.46-0.49) 0.50 (0.48-0.51) \nNote.—Disease detection results reported separately for each race group and biological sex. TPR and FPR in subgroups \nare determined using a fixed decision threshold optimized over the whole patient population for a target FPR of 0.20. \nPerformance is reported as mean and 95% confidence interval (CI). AUC = area under the receiver operating \ncharacteristic curve, TPR = true positive rate, FPR = false positive rate, CXR = chest radiography, MLP = multi-layer \nperceptrons \n \n ",
  "topic": "Radiography",
  "concepts": [
    {
      "name": "Radiography",
      "score": 0.7316491603851318
    },
    {
      "name": "Medicine",
      "score": 0.696743369102478
    },
    {
      "name": "Race (biology)",
      "score": 0.4304007887840271
    },
    {
      "name": "Radiology",
      "score": 0.3034263253211975
    },
    {
      "name": "Biology",
      "score": 0.0803384780883789
    },
    {
      "name": "Botany",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I47508984",
      "name": "Imperial College London",
      "country": "GB"
    }
  ]
}