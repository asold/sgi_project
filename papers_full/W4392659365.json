{
  "title": "Identifying incarceration status in the electronic health record using large language models in emergency department settings",
  "url": "https://openalex.org/W4392659365",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2101979092",
      "name": "Thomas Huang",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2787252827",
      "name": "Vimig Socrates",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A3134629398",
      "name": "Aidan Gilson",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A4284204345",
      "name": "Conrad Safranek",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1966855885",
      "name": "Ling Chi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2202911576",
      "name": "Emily A. Wang",
      "affiliations": [
        "Center for Health Justice",
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A4214468553",
      "name": "Lisa B. Puglisi",
      "affiliations": [
        "Yale University",
        "Center for Health Justice"
      ]
    },
    {
      "id": "https://openalex.org/A2046099468",
      "name": "Cynthia Brandt",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2171721584",
      "name": "R. Andrew Taylor",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2185238367",
      "name": "Karen Wang",
      "affiliations": [
        "Yale University",
        "Center for Health Justice"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3166844729",
    "https://openalex.org/W2101253644",
    "https://openalex.org/W2626951004",
    "https://openalex.org/W2165607248",
    "https://openalex.org/W4386279123",
    "https://openalex.org/W2035217215",
    "https://openalex.org/W2007241846",
    "https://openalex.org/W4385802729",
    "https://openalex.org/W2965971185",
    "https://openalex.org/W4221143384",
    "https://openalex.org/W6804393672",
    "https://openalex.org/W3201324897",
    "https://openalex.org/W6858518522",
    "https://openalex.org/W2621822663",
    "https://openalex.org/W2482604459",
    "https://openalex.org/W2097768735",
    "https://openalex.org/W2945347427",
    "https://openalex.org/W3002510375",
    "https://openalex.org/W4220947643",
    "https://openalex.org/W4378713629",
    "https://openalex.org/W2063880778",
    "https://openalex.org/W4206917417",
    "https://openalex.org/W2980700722",
    "https://openalex.org/W2604936718",
    "https://openalex.org/W2118228493",
    "https://openalex.org/W2944811075",
    "https://openalex.org/W4296483254",
    "https://openalex.org/W4388893405",
    "https://openalex.org/W4200193860"
  ],
  "abstract": "Abstract Background: Incarceration is a significant social determinant of health, contributing to high morbidity, mortality, and racialized health inequities. However, incarceration status is largely invisible to health services research due to inadequate clinical electronic health record (EHR) capture. This study aims to develop, train, and validate natural language processing (NLP) techniques to more effectively identify incarceration status in the EHR. Methods: The study population consisted of adult patients (≥ 18 y.o.) who presented to the emergency department between June 2013 and August 2021. The EHR database was filtered for notes for specific incarceration-related terms, and then a random selection of 1,000 notes was annotated for incarceration and further stratified into specific statuses of prior history, recent, and current incarceration. For NLP model development, 80% of the notes were used to train the Longformer-based and RoBERTa algorithms. The remaining 20% of the notes underwent analysis with GPT-4. Results: There were 849 unique patients across 989 visits in the 1000 annotated notes. Manual annotation revealed that 559 of 1000 notes (55.9%) contained evidence of incarceration history. ICD-10 code (sensitivity: 4.8%, specificity: 99.1%, F1-score: 0.09) demonstrated inferior performance to RoBERTa NLP (sensitivity: 78.6%, specificity: 73.3%, F1-score: 0.79), Longformer NLP (sensitivity: 94.6%, specificity: 87.5%, F1-score: 0.93), and GPT-4 (sensitivity: 100%, specificity: 61.1%, F1-score: 0.86). Conclusions: Our advanced NLP models demonstrate a high degree of accuracy in identifying incarceration status from clinical notes. Further research is needed to explore their scaled implementation in population health initiatives and assess their potential to mitigate health disparities through tailored system interventions.",
  "full_text": "Journal of Clinical and\nTranslational Science\nwww.cambridge.org/cts\nResearch Methods and\nTechnology\nResearch Article\nCite this article:Huang T, Socrates V, Gilson A,\nSafranek C, Chi L, Wang EA, Puglisi LB, Brandt C,\nTaylor RA, and Wang K. Identifying\nincarceration status in the electronic health\nrecord using large language models in\nemergency department settings.Journal of\nClinical and Translational Science8: e53, 1– 10.\ndoi: 10.1017/cts.2024.496\nReceived: 24 October 2023\nRevised: 6 February 2024\nAccepted: 6 March 2024\nKeywords:\nChatGPT; emergency department;\nincarceration; justice involvement; large\nlanguage models; machine learning; natural\nlanguage processing\nCorresponding author:\nR. A. Taylor, MD, MHS;\nEmail: richard.taylor@yale.edu\nR. Andrew Taylor and Karen Wang have\ncontributed equally to this work.\n© The Author(s), 2024. Published by Cambridge\nUniversity Press on behalf of Association for\nClinical and Translational Science. This is an\nOpen Access article, distributed under the\nterms of the Creative Commons Attribution\nlicence (http://creativecommons.org/licenses/\nby/4.0/), which permits unrestricted re-use,\ndistribution and reproduction, provided the\noriginal article is properly cited.\nIdentifying incarceration status in the electronic\nhealth record using large language models in\nemergency department settings\nThomas Huang1 , Vimig Socrates2,3, Aidan Gilson1,2, Conrad Safranek1, Ling Chi2,\nEmily A. Wang2,4,5, Lisa B. Puglisi2,4,5, Cynthia Brandt2, R. Andrew Taylor1,2 and\nKaren Wang2,4,5,6\n1Department of Emergency Medicine, Yale School of Medicine, New Haven, CT, USA;2Section for Biomedical\nInformatics and Data Science, Yale University School of Medicine, New Haven, CT, USA;3Program of Computational\nBiology and Bioinformatics, Yale University, New Haven, CT, USA;4SEICHE Center for Health and Justice, Yale School\nof Medicine, New Haven, CT, USA;5Department of Medicine, Yale School of Medicine, New Haven, CT, USA and\n6Equity Research and Innovation Center, Yale School of Medicine, Yale University, New Haven, CT, USA\nAbstract\nBackground: Incarceration is a significant social determinant of health, contributing to high\nmorbidity, mortality, and racialized health inequities. However, incarceration status is largely\ninvisible to health services research due to inadequate clinical electronic health record (EHR)\ncapture. This study aims to develop, train, and validate natural language processing (NLP)\ntechniques to more effectively identify incarceration status in the EHR.Methods: The study\npopulation consisted of adult patients (≥ 18 y.o.) who presented to the emergency department\nbetween June 2013 and August 2021. The EHR database was filtered for notes for specific\nincarceration-related terms, and then a random selection of 1,000 notes was annotated for\nincarceration and further stratified into specific statuses of prior history, recent, and current\nincarceration. For NLP model development, 80% of the notes were used to train the\nLongformer-based and RoBERTa algorithms. The remaining 20% of the notes underwent\nanalysis with GPT-4.Results: There were 849 unique patients across 989 visits in the 1000\nannotated notes. Manual annotation revealed that 559 of 1000 notes (55.9%) contained\nevidence of incarceration history. ICD-10 code (sensitivity: 4.8%, specificity: 99.1%, F1-score:\n0.09) demonstrated inferior performance to RoBERTa NLP (sensitivity: 78.6%, specificity:\n73.3%, F1-score: 0.79), Longformer NLP (sensitivity: 94.6%, specificity: 87.5%, F1-score: 0.93),\nand GPT-4 (sensitivity: 100%, specificity: 61.1%, F1-score: 0.86).Conclusions: Our advanced\nNLP models demonstrate a high degree of accuracy in identifying incarceration status from\nclinical notes. Further research is needed to explore their scaled implementation in population\nhealth initiatives and assess their potential to mitigate health disparities through tailored system\ninterventions.\nIntroduction\nPerhaps one of the most underappreciated but highly prevalent social determinants of health is\nbeing exposed to incarceration. The United States has one of the highest incarceration rates\nglobally, with over 7 million admissions to jails annually and over 1.2 million in prison as of\nyear-end 2022 [1– 3]. Disproportionately high incarceration rates are observed among racially\nminoritized individuals, as well as those of low socioeconomic status. Incarcerated individuals\nhave higher rates of communicable and noncommunicable diseases, in addition to mental health\nand substance use disorders compared with those never incarcerated [4,5]. It is estimated that\n40 percent of these individuals receive their diagnoses while incarcerated, where there is a\nconstitutional guarantee to health care, but where the acquisition of self-management skills for\nchronic diseases is hindered by the restrictive and punitive nature of the penal system [6].\nUpon release, these individuals continue to encounter barriers to care, including limited\naccess to housing, employment, and primary care services [7,8]. Compounding these issues,\ninadequate coordination of care transitions between correctional facilities and community\nhealth systems contributes to an elevated risk of death, hospitalization, and deteriorating health\noutcomes post-release [9]. Past work indicates that people with histories of incarceration face\nsignificant barriers to accessing consistent and high-quality care, including under-insurance and\ndiscrimination within the healthcare system [10– 12].\nThese underlying structural factors and social needs drive an important association between\nincreased frequency of acute care utilization and recent or impending incarceration. Studies\nhave revealed a correlation between the frequency of Emergency Department (ED) visits and\nhttps://doi.org/10.1017/cts.2024.496 Published online by Cambridge University Press\nsubsequent jail encounters within a year. Particularly, individuals\nwith super-frequent ED usage, defined as 18 or more visits per\nyear, are found to have 12.3 times higher odds of subsequent\nincarceration. In addition, those who were incarcerated saw a\nsignificantly increased likelihood of visiting the ED within 30 days\nprior to incarceration or 30 days following jail exit [13]. These\ninteractions with the health system serve as opportunities for\nhealth system level interventions to address this social risk, such as\nengagement in interventions to prevent incarceration (initiation\nof medications for opioid use disorder, violence intervention\nprograms) or prevent poor outcomes after release (engagement\ninto primary care programs)[14– 17]. Additionally, systematically\nimplementing broader health systems level interventions, such as\nmedical legal partnerships, and quality of care analyses necessitate\nan ability to identify those with a history of incarceration within\nhealth system information systems. Currently there is no reliable\nway to do collect information on this social determinant of health\nand screening directly can be stigmatizing [18,19].\nThe electronic health record (EHR) holds promise as a research\ntool for understanding the drivers of poor health among\nindividuals with a history of incarceration, given the large sample\nsizes, generalizability to a wide range of patient populations, low\nexpense, and relatively fewer resources needed to conduct studies\n[19]. However, EHRs currently are not designed to systematically\nmeasure incarceration exposure. Providers do not receive training\nin how to ask about or consistently document incarceration history\ninto patients' social history, leading to current limitations in\nthe documentation of incarceration history in standardized or\nstructured formats [18]. Natural language processing (NLP) has\nthe potential to extract valuable information from unstructured\ndata in the EHR, such as in provider notes. NLP techniques, such as\nnamed entity recognition, relation extraction, and text classifica-\ntion, can identify relevant information and classify clinical notes\naccording to specific criteria. So far, studies that examine the EHR’s\nability to accurately capture data regarding incarceration exposure\nare limited but demonstrate the potential of this approach. One\nprevious study assessed the identification of incarceration history\nusing an NLP tool, YTEX, on a dataset created through linkage\nof Veterans’ Health Affairs (VHA) EHR, the Department of\nCorrection (DOC) data, and Centers of Medicare and Medicaid\nServices (CMS) data. While findings were promising for NLP as an\neffective means of identification of incarceration history, the study\nwas limited to only VHA EHR which is not generalizable to other\nhealth system EHRs. In addition, the YTEX NLP tool is an example\nof a rule-based NLP in comparison to deep learning techniques for\nNLP that are able to handle the variability and diversity of human\nlanguage better in settings utilizing unstructured data, such as\nclinician notes from the ED [19]. Boch et al. proposed a BERT-\nbased model that examined overall parental justice involvement\namong the pediatric population, demonstrating the utility of NLP\nin the identification and exploration of justice involvement [20].\nHowever, there currently is no generalized tool which identifies an\nindividual’s own history of incarceration and timing of the event\nbased on unstructured clinical encounter notes.\nThe primary objective of this investigation was to develop\nan accurate NLP model, using state-of-the-art methods, to reliably\nand accurately identify incarceration history from unstructured\nclinical notes in the EHR. We also aimed to assess the ability for\nother large language models, such as Generative Pre-trained\nTransformer 4 (GPT-4), in its performance of identifying\nincarceration status. By pursuing these goals, our investigation\nwill contribute to a better understanding of the utility of NLP\ntechniques for identifying incarceration history in the EHR\ncontext, paving the way for improved research on the health of\nindividuals with a history of incarceration and the development of\ntargeted interventions to address their unique health needs.\nMaterial and methods\nStudy population and setting\nThe study population consisted of a set of adult patients (≥ 18 years\nof age) who presented to the emergency department (ED) between\nJune 2013 and August 2021 and had an ED note containing at least\none of the following incarceration-related terms:“incarceration,”\n“jail,”“ handcuffs,”“ prison,”“ incarcerated,”“ felony,”“ probation,”\n“parole,”“ convict,”“ inmate,”“ imprisoned.” (Fig. 1) These terms\nwere defined and selected after a literature review and consultation\nwith expert opinions (LP, EW, KW, RAT). The study was\ncompleted across 10 EDs within a regional healthcare network in\nthe northeastern United States, covering a geographic area of\napproximately 650 square miles, and closely resembling the overall\nnational population [ 21]. The study followed the STROBE\nreporting guidelines for observational studies and was approved\nby the institutional review board, which waived the need for\ninformed consent (HIC# 1602017249).\nData collection and processing\nFrom an initial set of 81,140 total clinical notes that had at least\none of the prespecified key-words, we randomly sampled 1000\nnotes for annotation, which came from 849 unique patients across\n989 visits. The size of this random sample of clinical notes was\nselected to ensure representation of the diverse presentations and\nencounter types that a patient with incarceration history could\npresent to the ED with. To ensure model robustness to note type, a\ntotal of 25 different note types were selected, the majority of which\nwere ED Provider Notes, Progress Notes, and ED Psych Eval\nNotes. A full list is in AppendixA. All text was sampled from the\nsystem-wide electronic health record (Epic, Verona, WI) using a\ncentralized data warehouse (Helix).\nDefining history of incarceration\nThe broad definition of incarceration, as the state of being confined\nin prison or imprisonment, was further stratified into more specific\nstatuses of previous history of incarceration, recent incarceration,\nand current incarceration. Similar to the process for identifying\ninitial incarceration-related terms, related terms were chosen\nafter an extensive literature review and consultation with expert\nopinions (LP, EW, KW, RAT). We stratified temporal relationship\nto incarceration because there are different health risks associated\nwith each. As an example, transition into and out of correctional\nfacilities is disruptive and traumatic and can have differential\neffects on health [22]. Additionally, there are likely different health\nsystem level interventions that are feasible to improve care for\ncurrently and formerly incarcerated individuals due to the role of\ndepartments of corrections in managing health care. Currently,\ntwo ICD-10 codes (Z65.1 Imprisonment and other incarceration,\nZ65.2 Problems related to release from prison) exist in the EHR\nspecific to incarceration history.\nDocument annotation\nThe process began with the assembly of a set of provider notes,\ncapturing various clinical encounters related to incarceration and\n2 Huang et al.\nhttps://doi.org/10.1017/cts.2024.496 Published online by Cambridge University Press\njustice involvement. Using the definitions in section “Defining\nHistory of Incarceration,” senior authors (AT, KW) defined an\ninitial set of annotation guidelines to determine incarceration\nstatus as at least one of three categories: Prior, Current, and Recent\nincarceration (Table 1). Led by AT, our team of annotators (LC,\nTH, CS) underwent thorough training on the annotation guide-\nlines. Our annotation process then followed an iterative approach,\nupdating guidelines while classifying an initial set of 50 notes,\nutilizing Fleiss’Kappa to evaluate consistency across annotators to\nensure a reliable and standardized annotation process throughout\nthe study. Following high reliability between annotators, the\nremainder of the 1000 notes were randomly distributed among the\nannotators, and the full set was annotated. The task was framed as a\nclassic multilabel text classification task, allowing annotators to\nselect if patient reports had evidence of any of the following: Prior,\nCurrent, and Recent Incarceration. If a patient had a history of\nincarceration and was currently incarcerated, both could be\nselected.\nLabel text classification for“Prior History” was contingent on\nexplicit stated evidence in the note for history of incarceration, or\nother mentions that could allow for inference that the subject of the\nnote had previously experienced incarceration. This included\nevidence of history of or current parole as well as halfway houses\nthat were explicitly mentioned to serve previously incarcerated\nindividuals. “Current Incarceration” was coded in instances with\nconfirmed evidence in the text that the subject of the note\ncame directly from a correctional facility.“Recent incarceration”\nrequired mention by the author of note stating recent release from\na correctional facility or if the language was absent, an explicit\nmention of date of release as well as date of the note or time since\nrelease that fell within 6 months. For annotation, we employed\nProdigy v1.11.7., a scriptable annotation tool designed to enable\ndata scientists to perform the annotation tasks themselves and\nfacilitating rapid iterative development in NLP projects.\nNLP development\nOnce annotations were completed, we initially fine-tuned RoBERTa,\na classic BERT-based model, to predict incarceration status in ED\nnotes using Huggingface transformers v4.20.1. However, upon initial\ninspection, we found that the majority of documents (68.2%) were\ntoo long to fit in the context window of classic BERT models (512\ntokens, ~400 words), reducing performance (shown in AppendixB).\nTherefore, we utilized an advanced BERT-based model, known as\nClinical-Longformer (shown in Appendix C). Transformer-\nbased models leverage self-attention to consider context along\nthe full length of the input sequence. While this provides\nsignificant performance improvements, memory consumption\nenlarges quadratically with sequence length, making analysis\nof longer documents with classic transformer-based, such as\nBERT, models computationally infeasible. The Clinical-\nLongformer model uses sparse attention with a sliding context\nwindow, along with reduced global attention for key tokens to\nreduce memory consumption while keeping performance\nhigh and increasing context wi ndows. In particular, we take\nadvantage of the benefits of fine-tuning on domain-specific data\nand fine-tune Clinical-Longfor mer on our annotated incarcer-\nation status dataset [23]. We trained both the classic BERT-\nbased model and Clinical-Longformer model on 800 notes\n(80%) of the data and evaluated performance on 200 (20%)\nn o t e s .T h em o d e l sw e r ef i n e - t u n e dt op r e d i c tt h ep r e s e n c eo fa n y\nof the categories of i ncarceration status using a multilabel\nclassification layer added to the top of the base model. We used a\nbinary cross-entropy loss function for training. The training\nprocess involved 10 iterations over the dataset with a predefined\nTable 1. Incarceration history and annotation labels and their definitions\nLabel Definition\nPrior History of\nIncarceration\n Patient has stated history of incarceration (jail or\nprison), including recent incarceration.\n Patient has stated current parole status or has a\nstated history of parole.\n Patient is stated to be currently living in halfway\nhouse specific to incarceration.\n Note: Label if there is evidence of history of or\ncurrent parole as well as halfway houses that were\nexplicitly mentioned to serve previously\nincarcerated individuals\nCurrent\nIncarceration\n Patient is stated to be currently in or came from\njail or prison.\nRecent\nIncarceration\n Patient has stated history of being released from\njail or prison in the last 6 months.\n Provider explicitly states recent release from jail\nor prison.\nFigure 1. Graphic overview of note selection and NLP training process.\nJournal of Clinical and Translational Science 3\nhttps://doi.org/10.1017/cts.2024.496 Published online by Cambridge University Press\nbatch size of 16, and gradient descent optimization was utilized\nto minimize the loss function.\nIn order to measure the ability of the model to identify\nincarceration status generally, we collapsed the 3 labels of prior\nhistory, current, and recent history of incarceration, to represent\nany indication of incarceration history. For both settings, we report\nstandard evaluation metrics such as precision, recall, and F1-score\nto quantitatively measure the model’s performance in identifying\nincarceration status from the provider notes.\nInitial prompt development and GPT-4 evaluation\nInitial drafts of the prompt were deployed in the pipeline on\nsynthetic notes external to the test set, with a total of three iterative\nimprovements to the prompt, integrating the exact definitions used in\nthe final iteration of the codebook for Prior History of Incarceration,\nCurrent Incarceration, and Recent Incarceration as used by the\nannotators when annotating the gold standard (Table1). The final\ndeveloped prompt (Fig.2) was combined with each individual note\nfrom the test set, incorporating features of prompt design from other\nresearch, such as triple delimiters to improve recognition of parsing of\ninput and forced JSON response to control the output.\nThe pipeline was deployed in the Azure OpenAI service,\niterating through the entire test set, querying and retrieving JSON\nobjects from GPT-4 that represent encoding of annotations within\nthe three pre-defined incarceration status labels. Azure GPT-4\nModel’s max input window is 8192 tokens, which was not a\nlimitation in any instance of this test set. Within the 200-note test\nset, 3 instances in which notes queried to GPT-4 on the Azure\nOpenAI service did not receive an eligible response due to its\ncontent filtering system, such as for instances of hate, sexual,\nviolence, and self-harm categories. These instances were omitted\nfrom the final analysis of the GPT-4 model performance as\ncompared to gold standard rather than censoring portions of text\nthat may be triggering the content filtering policy as such language\nmay be important in the consideration of incarceration status.\nIndividual JSON objects returned by GPT-4 were combined\ninto a python DataFrame, and the 3 labels of prior history, current,\nand recent history of incarceration were collapsed to an additional\nlabel of any indication of incarceration history similarly as done in\nthe Longformer and RoBERTa models, external to the GPT-4 query.\nResults\nDataset\nOf the 1000 notes included which were identified as having at least\none incarcerated-related term via keyword, only 559 were found to\ncontain evidence that the patient experienced any history of\nincarceration, including recent incarceration (137 notes), current\nincarceration (80 notes), and prior history of incarceration (484\nnotes). Many notes that were included by simple keyword search\nfor incarceration-related terms but not defined as containing\nevidence for any history of incarceration included instances\nwhere family history of incarceration was documented in the\nnote, other forms of justice involvement, incorrect contexts such\nas “incarcerated hernia, ” and many other examples. Utilizing\nICD codes (Z65.1 Imprisonment and other incarceration,\nZ65.2 Problems related to release from prison) as a means of\nidentification, only 27 of the 562 notes annotated to have any\nhistory of incarceration were identified resulting in an accuracy\nof 46.10%, sensitivity of 4.80%, specificity of 99.09%, precision\nof 87.10%, and F1 of 0.09 (Fig.3).\nInter-rater reliability/annotator performance\nTo assess the inter-rater reliability, a Fleiss’ Kappa was calculated\nutilizing overlap of sets of 50 annotated notes between each of the\nthree annotators (TH, CS, LC). The annotators achieved agree-\nment throughout annotating tasks with kappa’s of 0.826 between\nall annotators.\nRoBERTa natural language processing\nTo establish a baseline and point of comparison for the Clinical-\nLongformer model, RoBERTa, another deep learning NLP model,\nw a su t i l i z e dt oi d e n t i f yp r i o rh i s t o r yo fi n c a r c e r a t i o ni nt h et e s t\nset of 200 manually identified ED encounter notes, recent\nincarceration, and current incarceration as well as the overall\nFigure 2. Identification of incarceration status prompt and pipeline into GPT-4 through the Azure openAI service.\n4 Huang et al.\nhttps://doi.org/10.1017/cts.2024.496 Published online by Cambridge University Press\ncollapsed label of any history ofincarceration. For the collapsed\nlabel of any history of incarceration, RoBERTa demonstrated an\naccuracy of 77.0%, sensitivity of 78.6%, specificity of 73.3%,\nprecision of 80.0%, and F1 score of 0.793. Figure 4 shows\nthree confusion matrices illustrating the performance of the\nRoBERTa model (left), Longformer model (middle), and GPT-4\n(right). Of the total test set of 200 manually annotated notes,\nthere were 22 encounter notes falsely labeled as positive for\nincarceration history and 24 falsely labeled as negative for\nincarceration history (Fig. 4).\nAs for the more specific temporal labels, RoBERTa demon-\nstrated precision of 78.3%, recall of 75.8%, and F1 score of 0.77 for\nprior history of incarceration; a precision of 72.4%, recall of 65.6%,\nand F1-score of 0.689 for recent incarceration, and precision\nof 56.2%, recall of 56.2%, and F1 score of 0.562 for current\nincarceration (Fig. 5). Additional information about RoBERTa\nmultilabel performance can be found in AppendixB.\nClinical-Longformer Natural Language Processing\nOn the same test set of 200 manually annotated notes, the Clinical-\nLongformer model demonstrated an accuracy of 91.5%, sensitivity\nof 94.6%, specificity of 87.5%, precision of 90.6%, and F1 score of\n0.926 for the identification of any history of incarceration. Of the\ntotal 200 individual test encounter notes, 11 notes were falsely\nidentified for a positive incarceration history, and 6 notes were\nfalsely identified as negative for incarceration history (Fig.4).\nSimilar to the RoBERTa pattern of performance, the Clinical-\nLongformer model was relatively limited in its ability to identify\nspecific temporal relationships and in distinguishing between prior\nhistory of incarceration (precision: 84.9%, recall: 65.3%, F1: 0.738)\nrecent incarceration (precision: 70%, recall: 65.6%, F1: 0.677), and\ncurrent incarceration (precision: 64.7%, recall: 68.8%, F1: 0.667)\n(Fig. 5). Additional information about Clinical-Longformer\nperformance on the multilabel task can be found in AppendixC.\nThe behavior of the Clinical-Longformer model was qualita-\ntively assessed through the use of Shapley plots to identify what\ncontextual clues and phrases the model utilizes as signals when\nidentifying incarceration history. These Shapley plots demonstrate\ntremendous utility for both assessing what elements of an ED\nencounter notes strongly signal to the model whether a note is\npositive for incarceration history or negative for incarceration\nhistory. These plots are also useful for identifying potential\npatterns that can cause misidentification, leading to false positives\nand negatives. This deidentified Shapley plot of an ED encounter\nnote (Fig. 6) demonstrates the Clinical-Longformer model\ncorrectly identifying incarceration status. Phrases or lines of text\nthat the Clinical-Longformer model often attends to when\nidentifying incarceration history include “in jail,”“ in prison,”\n“released from jail, ”“ when incarcerated, ”“ history of being\nincarcerated.” An interesting pattern of reporting incarceration\nis when it is used as a time frame, by either the patient or the\nphysician, when discussing illness, medication usage, substance\nusage, such as“He reports his insulin doses have been incorrect at\nhis prison where he has been incarcerated.”\nAmong those 11 notes that were false positives and 6 false\nnegatives for incarceration history, a common trend for the\nClinical-Longformer model’s confusion was complex language and\nphrasing separating current incarceration and instances where the\nindividual was brought in by police or under custody, but not\ncurrently incarcerated. While often difficult to even manually\nannotate, the separation between instances where patients are\nbrought in under a Police Emergency Examination Request\n(PEER) or from a temporary overnight lock-up is an important\ndifference to distinguish from a patient transported from the\ncarceral system. Phrases such as“She states the patient was kept in\nthe “hospital” part of the jail” confused the model, causing it to be\noversensitive in this regard when unable to infer the appropriate\ncontext. Other instances of oversensitivity include contextual\nphrases of “conviction” or “release from court.” This phrasing\nsignals general justice involvement but not necessarily incarcer-\nation (Fig.6).\nGPT-4 in Azure openAI service performance\nIn addition, the same 200 test set was queried to GPT-4 using the\nAzure OpenAI service to protect deidentified patient information.\nGPT-4, demonstrating a zero-shot approach, achieved an accuracy\nof 82.3%, sensitivity of 100%, specificity of 61.1%, precision of\n75.7%, and F1 score of 0.86 for the identification of any history of\nincarceration (Fig.4). GPT-4 was more sensitive compared to both\nthe Longformer and RoBERTa models, but less accurate and precise\nthan Longformer. GPT-4 demonstrated 0 false negatives, but its\ngreater sensitivity resulted in significantly more false positives, 35\ncompared to the 11 of Longformer and 22 of RoBERTa NLPs\nmodels. It is important to note that GPT-4’\ns performance statistics\nomitted 3 of the 200 notes used in the test set due to the content\nfiltering policy in-place by Azure OpenAI resulting in an inability to\nquery an appropriate response from GPT-4.\nContrary to both the Longformer and RoBERTa patterns of\nperformance, GPT-4 demonstrated better performance (F1 score\ncomparison) in identifying specific temporal relationships.\nHowever, in the identification of the collapsed label of any history\nof incarceration, Clinical-Longformer still outpaced GPT-4,\ndespite GPT-4’s relatively superior performance across all three\ntemporal labels of prior history of incarceration (precision: 73.8%,\nrecall: 98.9%, F1: 0.85), recent incarceration (precision: 68.1%,\nrecall: 100%, F1: 0.81), and current incarceration (precision: 50%,\nrecall: 89.7%, F1: 0.63) (Fig.5).\nFigure 3. ICD-10 code vs. manual annotation.\nJournal of Clinical and Translational Science 5\nhttps://doi.org/10.1017/cts.2024.496 Published online by Cambridge University Press\nDiscussion\nThe criminal justice system, and thus incarceration, is one of the\ngreatest drivers of health inequity that impacts communities across\nthe US [24]. Identifying patients with incarceration history within\nhealthcare settings is a key initial step in attending to healthcare\ninequality and disparity in this underserved patient population.\nOur Clinical-Longformer model can reliably and accurately\nidentify incarceration status based on free-form clinician notes\nin the EHR. This method offers several advantages over other\nforms of identification such as ICD-10 codes, rule-based NLP\ntechniques, and other NLP techniques like RoBERTa. The NLP\nalgorithm does not rely on providers entering ICD-10 codes which\nare not used accurately or reliably to measure social determinants\nof health. The NLP algorithm can capture nuanced information\nbeyond these specific codes through the use of unstructured data\nwhen structured data, such as ICD-10 codes and problem lists,\noften under-report. In addition, the NLP algorithm surpasses\nsimple keyword searches by considering the context and meaning\nof the text, leading to more accurate identification of incarceration\nhistory [ 25]. The Clinical-Longformer model demonstrated\nsuperior sensitivity, specificity, precision, and F1 score when\ncompared to the RoBERTa model and a superior F1 score when\ncompared to zero-shot GPT-4. However, when identifying specific\nincarceration status and further granulating any incarceration\nhistory into prior history of incarceration and recent incarceration,\nGPT-4 demonstrated superior performance compared to both\nClinical-Longformer and the RoBERTa models.\nThe Clinical-Longformer model developed in this study\nutilizing deep learning elements offers improvement over previous\nmethods of identification such as the rule-based YTEX model\n(F1: 0.75), specifically in sensitivity and overall F1 score [19].\nAdditionally, the utilization of a larger training set of 800 unique\nclinician notes compared to the 228 used in Wang et al., as well as\nthe use of the Clinical-Longformer to improve the attention and\nanalysis over longer notes, likely contributed to the improvement\nin this NLP model. The improved performance of the Clinical-\nLongformer model as compared to GPT-4 when defined by the F1\nscore is likely due to the sacrifice of sensitivity for improved\nprecision. GPT-4 demonstrated near 100% sensitivity in recent\nhistory and prior history of incarceration labels, as well as 100%\nsensitivity for any history of incarceration, but significantly lower\nspecificity compared to Clinical Longformer (60.1% vs. 87.5%)\nFurther, our study applies the similar principles utilized by\nBoch et al. to identify parental criminal justice system involvement\nin a pediatric population to a more specific and different goal [25].\nWe focused on the identification of incarceration status and\nhistory in the subject of the encounter notes, while Boch et al.\nlooked at any pediatric exposure to parental justice involvement,\nincluding jail, prison, parole, and probation. We focused on\nnarrowing the identification to incarceration history of the patient\nrather than any justice involvement, further developing our\nunderstanding of how NLP can be an asset to healthcare as\npopulations exposed to long-term jail and incarceration histories\nhave unique experiences, health outcomes, and possible inter-\nventions through social programs and referrals available to them.\nIn addition, our Clinical-Longformer model is able to capture\nand attend to longer documents compared to the BERT model\nwhich was used in that study, which is not able to accurately attend\nto notes over 500 tokens and required significant preprocessing to\nreduce notes down to snippets containing a total 500 tokens. A\nstudy of over 1.6 million ED provider notes, which represented a\nsignificant portion (46.2%) of the notes we used for our model,\nwere shown to have an average of 2067 words [26]. It is important\nto note that one token represents 4 characters in English. Thus, the\nClinical-Longformer is able to attend well to lengthy ED provider\nnotes and other forms of unstructured data without extensive\npreprocessing and possible loss of important contextual informa-\ntion that was necessary for the original BERT-based model.\nGPT-4’s increased query window of 8192 tokens, as well as the\navailability of a 32k window, further adds to the potential of\nincreased contextual attention if the use case arises. Although the\nmetrics of our Clinical-Longformer model are on par with the\nprevious work of Boch et al., the granulation of incarceration\nhistory as well as identifying incarceration history specific to the\nsubject of the clinical encounter note can distinguish and help\nincrease the specificity of possible utility for research purposes and\npossible interventions.\nThe use of Clinical-Longformer allows for the rapid identi-\nfication of documented incarceration exposure in the EHR and\nmay have implications for health service research, clinical care, and\nhealth outcomes for this population.\nThe identification of individuals who have had contact with the\ncarceral system in EHR is an important step in understanding and\nmitigating disparities in healthcare and health outcomes for this\nFigure 4. Longformer, roBERTa, and GPT-4 predicted label vs. true label by manual annotation for any history of incarceration.\n6 Huang et al.\nhttps://doi.org/10.1017/cts.2024.496 Published online by Cambridge University Press\npopulation. Previous research has been limited by the difficulty of\ncorrectly identifying this population. The use of NLP as a rapid and\nreliable mechanism to achieve this critical step opens the possibility\nof future research studies targeting issues such as the dispropor-\ntionate mortality rate for those diagnosed with cancer during\nincarceration, or the elevated cardiovascular-related morbidity and\nmortality for those who have been exposed to the carceral system,\nand providing an opportunity to study quality of care delivery\n[28,29]. An effective means of identifying individuals that have had\ncontact with the carceral system via the EHR can contribute to a\nmore comprehensive understanding of a patient’s social determi-\nnants of health and improve access to real-time referrals to social\nprograms aimed at enhancing healthcare outcomes and finding\nalternative means of rehabilitation. It can also be used to help guide\nfuture research on the potential impact of incarceration on various\nhealth outcomes. Through the development of models that can\nFigure 5. RoBERTa, clinical-longformer, and GPT-4 performance on multilabel task (prior history of incarceration, recent incarceration, and current incarceration).\nJournal of Clinical and Translational Science 7\nhttps://doi.org/10.1017/cts.2024.496 Published online by Cambridge University Press\nhelp with incarceration history, steps toward improving the quality\nof healthcare for previously incarcerated patients can be taken as\nwell as addressing existing disparities [27].\nThe utility of correctly identifying those who have been\nincarcerated extends beyond research or academic interests and\nhas implications for clinical care. While currently incarcerated\npatients may be most easily identified in a clinical encounter, those\nwith recent or past history of incarceration often go unidentified, as\ndemonstrated by the poor sensitivity of current implemented\nsystems of identification in ICD-19 codes. Such individuals\ncould benefit by being connected to programs such as the Jail\nDiversion Task Force, which can help prevent incarceration or\nre-incarceration and offers rehabilitation to those who would\nbenefit. The Transitions Clinic Network is another evidence-based\nprogram available in certain states that acts as a community-based\nprimary care clinic for those returning from incarceration [30].\nThe use of NLP to identify our target population can improve the\nreferral to these programs, as well as encourage the development of\nadditional targeted interventions to help patients avoid imprison-\nment or reduce the impact of imprisonment on their health.\nHowever, the possibility of false positives must also be considered.\nCare should be taken when approaching patients, no matter how\nwell-intentioned a provider may be, to confirm incarceration\nhistory in a non-judgmental way, and to qualify why the provider is\nasking, before offering resources in order to avoid eroding the\npatient– physician relationship by contributing to stigma.\nWhile the NLP and machine learning approach for identifying\nincarceration status shows promise, it is essential to acknowledge\nits limitations. These limitations include data quality issues,\nvariations in clinician note quality, and potential biases inherent\nin the algorithm. In addition, the standard for measurement of\nidentification by ICD-10 codes, RoBERTa, and Clinical-\nLongformer is the compiled manual annotation of three different\nannotators under the consultation and by the definition developed\nby both literature review and expert opinion (RAT, KW). Although\nsignificant effort and steps were taken to ensure the standard of\ncomparison was representative and consistently applicable, only a\ntotal of 1,000 ED encounter notes were manually annotated with a\ngood but not perfect measure of inter-rater reliability. This\nrepresents the complexities found within the encounter notes and\nlanguage when interpreting incarceration status and history.\nHesitancy by patients to disclose incarceration history, as well\nas hesitancy by providers to include this information in their notes,\ncan lead to underreporting of important incarceration informa-\ntion, rendering the NLP unable to correctly identify incarceration\nhistory. Such hesitancy by patients in reporting incarceration\nhistory should be heavily considered when utilizing models such as\nour Clinical-Longformer for identifying patients with incarcer-\nation history and applying it in clinical settings. Stigma around\nincarceration history that is pervasive both within the healthcare\nsystem and throughout society at large. The possibility of mis-use\nof this incredibly powerful tool cannot be ignored. Care should be\nFigure 6. Shapley visualization of the Clinical-Longformer model correctly identifying and misidentifying any history of incarceration.\n8 Huang et al.\nhttps://doi.org/10.1017/cts.2024.496 Published online by Cambridge University Press\ntaken to limit access to this information to those who can be\nentrusted to work in the patient’s best interest. Thus, the Clinical-\nLongformer model, given its superior sensitivity and relatively\npoorer specificity compared to previous models, would more\nappropriately act as a screening tool or“potential” cohort identifier\nfor further investigation of incarceration history rather than an\nendpoint of status. Manual confirmation following the use of this\nClinical-Longformer model would be best to avoid false positives\nor misplacements of such electronic labels in a patient file.\nIn addition, our Clinical-Longformer model was trained over\nonly a small subset of possible ED notes taken from a specific\nregion of the US. While the subset and the annotation were meant\nto represent the different possible presentations of incarceration\nhistory in an unstructured setting, it is possible that this model\nwould not attend well and misrepresent incarceration history in\nother unstructured data settings such as clinician notes outside of\nthe ED. In addition, with each creation of definitions and\nannotations, these iterations themselves may add to misclassifi-\ncations and further decrease the external validity of this NLP\nmodel. These misclassifications contributed to a slightly lower\nspecificity in our Clinical-Longformer model when compared to\nprevious YTEX model (99.3%) or ICD-10 code identification.\nGiven the complexity of disparity in healthcare, the impact of\nincarceration, and stigma surrounding incarceration, any marker\nfor incarceration history should be closely scrutinized.\nWhile the NLP cannot overcome perceived and extant biases in\nthe healthcare system that lead to these documentation short-\ncomings, our hope is that improving the ease of identifying\npreviously incarcerated individuals for health services research and\nconnection with community programs decreases the stigma around\ndiscussions about incarceration. Regarding our NLP itself, while it\nperforms well, it is still early in its development. The majority of\nphrases used to describe incarceration have likely been captured in\nthis model; however, there are certainly other contextual words and\nphrases that insinuate a history of incarceration that may have been\nmissed and would make this model even stronger.\nThe Clinical-Longformer NLP was limited in its ability to\ndistinguish the temporal relationship of incarceration based on\nindividual unstructured ED notes. Individually, current, recent,\nand prior history of incarceration labels were relatively poor in\nidentification compared to identification of“any” prior history of\nincarceration. Temporal relationships not specific to incarceration\nhave been shown to be difficult to extract using current NLP\nframeworks [25]. This framework, dependent upon using text from\nunstructured clinical text taken from a specific time frame,\nstructurally limits the ability for the NLP to extract relevant\ninformation to establish temporal relationships. Regarding GPT-4,\nother research has shown ChatGPT also demonstrates difficulty in\nidentifying temporal between two events. However, ChatGPT has\nexhibited strong performance in causal relationships and discourse\nconnectives in other work. It is possible that these other forms of\nevaluation, given enough context within the clinical notes, are\nallowing ChatGPT to demonstrate superior identification in the\ntemporal labels of prior, recent, and current incarceration through\nmeans not necessarily dependent on pure temporal reasoning.\nThe Clinical-Longformer NLP model was not able to distinguish\nthe temporal relationship of incarceration history based on each\nindividual clinician note as well as GPT-4, but it was still superior in\nits identification of any history of incarceration. The identification of\nany history of incarceration, however, is still important in its own\nright regardless of recency as the very exposure to incarceration is\ncorrelated with a wide array of adverse health conditions such as\ngreater self-reported chronic conditions, infectious disease, and\nmortality [31].\nOur NLP model serves as a proof-of-concept for future projects\naimed at using machine learning to utilize the vast amount of\ninformation present in EHR to provide targeted interventions and\ntreatment to patients. Further, improving the ability of this NLP\nmodel to attend across multiple notes across data available\nlongitudinally can possibly improve the usage of this model in\nstratifying incarceration history into distinct sub-periods. The\nClinical Longformer here was measured against a dataset of 1000\nmanually annotated notes based on definitions developed\nthorough literature review and consultation with experts that\nwas iteratively performed to ensure consistent and reliable\nannotation. Future application could include measuring this\nNLP model using linked data systems including EHR and DOC\nsystems.\nConclusions\nOur NLP model utilizing Clinical-Longformer with a semi-\nsupervised machine learning approach represents both a reliable\nand accurate method for identifying incarceration status from\nnonstructured free form clinician notes in an EHR. It presents\nseveral advantages over other methods of identification of\nincarceration history, such as ICD-10 codes, simple keyword\nsearches, including greater sensitivity specificity [ 19]. Future\nresearch can continue to fine-tune this tool, potentially allowing\nfor the differentiation of current versus previous incarceration in\norder to better target services and interventions offered to these\nindividuals.\nSupplementary material.The supplementary material for this article can be\nfound athttps://doi.org/10.1017/cts.2024.496.\nAuthor contributions. RAT, KHW conceived the study and designed the\nanalyses. VS provided data engineering and analyzed the data. TH, CS, LC\nprovided data annotation. TH, VS, CS, LC, and RAT drafted the manuscript,\nand all authors contributed substantially to its revision. RAT and KHW take\nresponsibility for the paper as a whole.\nFunding statement.YCCI Doris Duke Charitable Foundation: Fund to Retain\nClinical Scientists (FRCS).\nThis publication was made possible by the Yale School of Medicine Office of\nStudent Research.\nCompeting interests.None.\nReferences\n1. Prisons report series: Preliminary data release. Bureau of Justice Statistics.\nhttps://bjs.ojp.gov/library/publications/prisons-report-series-preliminary-da\nta-release. Accessed September 26, 2023.\n2. Jails report series: Preliminary data release. Bureau of Justice Statistics.\nhttps://bjs.ojp.gov/library/publications/jails-report-series-preliminary-da\nta-release. Accessed September 26, 2023.\n3. Dumont DM, Brockmann B, Dickman S, Alexander N, Rich JD.Public\nhealth and the epidemic of incarceration.Annu Rev Public Health. 2012;\n33(1):325– 339.\n4. Nosrati E, Kang-Brown J, Ash M, McKee M, Marmot M, King LP.\nIncarceration and mortality in the United States. SSM Popul Health.\n2021;15:100827.\n5. Fazel S, Yoon IA, Hayes AJ.Substance use disorders in prisoners: an\nupdated systematic review and meta-regression analysis in recently\nincarcerated men and women.Addiction. 2017;112(10):1725– 1739.\nJournal of Clinical and Translational Science 9\nhttps://doi.org/10.1017/cts.2024.496 Published online by Cambridge University Press\n6. Wang EA, Hong CS, Shavit S, Sanders R, Kessell E, Kushel MB.Engaging\nindividuals recently released from prison into primary care: a randomized\ntrial. Am J Public Health. 2012;102(9):e22– e29.\n7. Petersilia, Joan, When Prisoners Come Home: Parole and Prisoner Reentry,\nStudies in Crime and Public Policy(New York, 2009; online edn, Oxford\nAcademic, 24 May 2012), https://doi.org/10.1093/acprof:oso/97801\n95160864.001.0001. Accessed 14 March 2024.\n8. Morenoff JD, Harding DJ. Incarceration, prisoner reentry, and\ncommunities. Annu Rev Sociol. 2014;40(1):411– 429.\n9. Binswanger IA, Stern MF, Deyo RA, et al.Release from prison– a high risk\nof death for former inmates.N Engl J Med. 2007;356(2):157– 165.\n10. Frank, Joseph W., Emily A. Wang, Marcella Nunez-Smith, Hedwig Lee,\nand Megan Comfort. Discrimination based on criminal record and\nhealthcare utilization among men recently released from prison: a\ndescriptive study.Health & Justice. 2014;2:1– 8.\n11. Redmond N, Aminawung JA, Morse DS, Zaller N, Shavit S, Wang EA.\nPerceived discrimination based on criminal record in healthcare settings\nand self-reported health status among formerly incarcerated individuals.J\nUrban Health. 2020;97(1):105– 111.\n12. Wildeman C, Wang EA.Mass incarceration, public health, and widening\ninequality in the USA.Lancet. 2017;389(10077):1464– 1474.\n13. Eswaran V, Raven MC, Wang RC, Cawley C, Izenberg JM, Kanzaria HK.\nUnderstanding the association between frequent emergency department\nuse and jail incarceration: a cross-sectional analysis.Acad Emerg Med.\n2022;29(5):606– 614.\n14. Shavit S, Aminawung JA, Birnbaum N, et al. Transitions clinic network:\nchallenges and lessons in primary care for people released from prison.\nHealth Aff. 2017;36(6):1006– 1015.\n15.\nSugarman OK, Bachhuber MA, Wennerstrom A, Bruno T, Springgate\nBF. Interventions for incarcerated adults with opioid use disorder in the\nUnited States: a systematic review with a focus on social determinants of\nhealth. PLoS One. 2020;15(1):e0227968.\n16. Cooper C, Eslinger DM, Stolley PD.Hospital-based violence intervention\nprograms work.J Trauma. 2006;61(3):534– 537.\n17. Tong G, Spell VT, Horton N, et al. Trusted residents and housing\nassistance to decrease violence exposure in New Haven (TRUE HAVEN): a\nstrengths-based and community-driven stepped-wedge intervention to\nreduce gun violence.BMC Public Health. 2023;23(1):1545.\n18. Eisenstein LG, Fisher J, Simon L, Tobey M.Challenges and opportunities\nfor patients released from correctional facilities: a qualitative analysis.J Gen\nIntern Med. 2020;35(4):1328– 1329.\n19. Wang EA, Long JB, McGinnis KA, et al.Measuring exposure to incarceration\nusing the electronic health record.Med Care. 2019;57(Suppl 2):S157– S163.\n20. Boch S, Hussain SA, Bambach S, DeShetler C, Chisolm D, Linwood S.\nLocating youth exposed to parental justice involvement in the electronic\nhealth record: development of a natural language processing model.JMIR\nPediatr Parent. 2022;5(1):e33614.\n21. US Census Bureau. Connecticut’s Population Inched Up 0.9% Last\nDecade. Published online July 18, 2023.https://www.census.gov/library/sto\nries/state-by-state/connecticut-population-change-between-census-decade.\nhtml. Accessed August 28, 2023.\n22. Browne CC, Korobanova D, Chemjong P, et al. Continuity of mental\nhealth care during the transition from prison to the community following\nbrief periods of imprisonment.Front Psychiatry. 2022;13:934837.\n23. Li, Yikuan, Ramsey M. Wehbe, Faraz S. Ahmad, Hanyin Wang, and\nYuan Luo. “Clinical-longformer and clinical-bigbird: Transformers for\nlong clinical sequences.” arXiv preprintarXiv:2201.11838 (2022).\n24. National Academies of Sciences, Engineering, and Medicine. “Health\nand Medicine Division, Board on Population Health and Public Health\nPractice, Roundtable on the Promotion of Health Equity, Roundtable on\nPopulation Health Improvement.” In Achieving Rural Health Equity and\nWell-Being: Proceedings of a Workshop. 2018.\n25. Gumiel YB, LE Silva e Oliveira, Claveau V, et al. Temporal relation\nextraction in clinical texts: a systematic review. ACM Comput Surv.\n2021;54(7):1– 36.\n26. Marshall K, Strony R, Hohmuth B, Vawdrey DK.New coding guidelines\nreduce emergency department note bloat but more work is needed.Ann\nEmerg Med. 2023;30(6):713– 717. doi:10.1016/j.annemergmed.2023.07.023.\n27. Wang EA, Wildeman C. Studying health disparities by including\nincarcerated and formerly incarcerated individuals.JAMA. 2011;305(16):\n1708– 1709.\n28. Aminawung JA, Soulos PR, Oladeru OT, et al. Cancer incidence among\nincarcerated and formerly incarcerated individuals: a statewide retrospec-\ntive cohort study.Cancer Med. 2023;12(14):15447– 15454.\n29. Richman IB, Soulos PR, Lin HJ, et al.Incarceration and screen-detectable\ncancer diagnosis among adults in Connecticut.J Natl Cancer Inst. 2023;22:\ndjad242.\n30. Hawks L, Lopoo E, Puglisi L, et al. Community investment interventions\nas a means for decarceration: a scoping review.Lancet Reg Health Am.\n2022;8(100150):100150.\n31. Massoglia M, Remster B. Linkages between incarceration and health.\nPublic Health Rep. 2019;134(1_suppl):8S– 14S.\n10 Huang et al.\nhttps://doi.org/10.1017/cts.2024.496 Published online by Cambridge University Press",
  "topic": "Emergency department",
  "concepts": [
    {
      "name": "Emergency department",
      "score": 0.772576093673706
    },
    {
      "name": "Electronic health record",
      "score": 0.5508409738540649
    },
    {
      "name": "Medical emergency",
      "score": 0.5323522686958313
    },
    {
      "name": "Health records",
      "score": 0.4186103343963623
    },
    {
      "name": "Medicine",
      "score": 0.37512752413749695
    },
    {
      "name": "Psychology",
      "score": 0.3408122956752777
    },
    {
      "name": "Health care",
      "score": 0.2065473198890686
    },
    {
      "name": "Political science",
      "score": 0.17329421639442444
    },
    {
      "name": "Psychiatry",
      "score": 0.15736067295074463
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I32971472",
      "name": "Yale University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I2800957949",
      "name": "United States Congress",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210146887",
      "name": "Center for Health Justice",
      "country": "US"
    }
  ]
}