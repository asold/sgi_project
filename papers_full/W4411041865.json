{
    "title": "A survey of transformers and large language models for ECG diagnosis: advances, challenges, and future directions",
    "url": "https://openalex.org/W4411041865",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A3146533865",
            "name": "Mohammed Yusuf Ansari",
            "affiliations": [
                "Carnegie Mellon University Qatar",
                "Texas A&M University"
            ]
        },
        {
            "id": "https://openalex.org/A2027779554",
            "name": "Mohammed Yaqoob",
            "affiliations": [
                "Texas A&M University"
            ]
        },
        {
            "id": "https://openalex.org/A2029306800",
            "name": "Mohammed Ishaq",
            "affiliations": [
                "Texas A&M University"
            ]
        },
        {
            "id": "https://openalex.org/A296088480",
            "name": "Eduardo Feo Flushing",
            "affiliations": [
                "Carnegie Mellon University Qatar"
            ]
        },
        {
            "id": "https://openalex.org/A5092582485",
            "name": "Iffa Afsa Changaai Mangalote",
            "affiliations": [
                "Hamad General Hospital",
                "Hamad Medical Corporation"
            ]
        },
        {
            "id": "https://openalex.org/A2015936148",
            "name": "Sarada Prasad Dakua",
            "affiliations": [
                "Hamad Medical Corporation",
                "Hamad General Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A2828915432",
            "name": "Omar Aboumarzouk",
            "affiliations": [
                "Hamad Medical Corporation",
                "Hamad General Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A2944408984",
            "name": "Raffaella Righetti",
            "affiliations": [
                "Texas A&M University"
            ]
        },
        {
            "id": "https://openalex.org/A2068488440",
            "name": "Marwa Qaraqe",
            "affiliations": [
                "Hamad bin Khalifa University"
            ]
        },
        {
            "id": "https://openalex.org/A3146533865",
            "name": "Mohammed Yusuf Ansari",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2027779554",
            "name": "Mohammed Yaqoob",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2029306800",
            "name": "Mohammed Ishaq",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A296088480",
            "name": "Eduardo Feo Flushing",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5092582485",
            "name": "Iffa Afsa Changaai Mangalote",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2015936148",
            "name": "Sarada Prasad Dakua",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2828915432",
            "name": "Omar Aboumarzouk",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2944408984",
            "name": "Raffaella Righetti",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2068488440",
            "name": "Marwa Qaraqe",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4309189427",
        "https://openalex.org/W2008293401",
        "https://openalex.org/W2980607836",
        "https://openalex.org/W4220719668",
        "https://openalex.org/W3195282191",
        "https://openalex.org/W2029399558",
        "https://openalex.org/W2118549020",
        "https://openalex.org/W3205366539",
        "https://openalex.org/W2015887634",
        "https://openalex.org/W2916066245",
        "https://openalex.org/W3131687983",
        "https://openalex.org/W3028005831",
        "https://openalex.org/W4223910124",
        "https://openalex.org/W4399008172",
        "https://openalex.org/W4387298343",
        "https://openalex.org/W4392904542",
        "https://openalex.org/W4365600948",
        "https://openalex.org/W4404304528",
        "https://openalex.org/W4406260782",
        "https://openalex.org/W4402943216",
        "https://openalex.org/W4400974494",
        "https://openalex.org/W4399939632",
        "https://openalex.org/W4210820029",
        "https://openalex.org/W3199582773",
        "https://openalex.org/W3172243723",
        "https://openalex.org/W4288049494",
        "https://openalex.org/W4400335482",
        "https://openalex.org/W3090982581",
        "https://openalex.org/W4387847058",
        "https://openalex.org/W3114190944",
        "https://openalex.org/W3015384184",
        "https://openalex.org/W3118266219",
        "https://openalex.org/W4320490460",
        "https://openalex.org/W3092000919",
        "https://openalex.org/W3149121678",
        "https://openalex.org/W3014318198",
        "https://openalex.org/W3092557781",
        "https://openalex.org/W3088265803",
        "https://openalex.org/W4404962869",
        "https://openalex.org/W4406113259",
        "https://openalex.org/W4401753296",
        "https://openalex.org/W4408182749",
        "https://openalex.org/W4408747274",
        "https://openalex.org/W2892009249",
        "https://openalex.org/W2972818416",
        "https://openalex.org/W4313399770",
        "https://openalex.org/W4362603432",
        "https://openalex.org/W4393405247",
        "https://openalex.org/W4318566866",
        "https://openalex.org/W4292296585",
        "https://openalex.org/W3142047004",
        "https://openalex.org/W4281710423",
        "https://openalex.org/W4313555269",
        "https://openalex.org/W4308259083",
        "https://openalex.org/W4385892652",
        "https://openalex.org/W4405517758",
        "https://openalex.org/W2704923930",
        "https://openalex.org/W2942497026",
        "https://openalex.org/W4388979610",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W2946794439",
        "https://openalex.org/W4205460703",
        "https://openalex.org/W4388550106",
        "https://openalex.org/W2095409369",
        "https://openalex.org/W1984193729",
        "https://openalex.org/W4392779950",
        "https://openalex.org/W6884848120",
        "https://openalex.org/W4391946900",
        "https://openalex.org/W4391517686",
        "https://openalex.org/W4392137273",
        "https://openalex.org/W4327928254",
        "https://openalex.org/W4390956126",
        "https://openalex.org/W4304197317",
        "https://openalex.org/W4385071598",
        "https://openalex.org/W3163178735",
        "https://openalex.org/W4396877717",
        "https://openalex.org/W4379114023",
        "https://openalex.org/W4296617823",
        "https://openalex.org/W4206480139",
        "https://openalex.org/W3098699929",
        "https://openalex.org/W4390971309",
        "https://openalex.org/W4225332066",
        "https://openalex.org/W2794550444",
        "https://openalex.org/W4206135956",
        "https://openalex.org/W4296550854",
        "https://openalex.org/W3161020793",
        "https://openalex.org/W3167986199",
        "https://openalex.org/W6884862154",
        "https://openalex.org/W2164179736",
        "https://openalex.org/W4400233432",
        "https://openalex.org/W4386523205",
        "https://openalex.org/W4386472807",
        "https://openalex.org/W4318773510",
        "https://openalex.org/W4394766452",
        "https://openalex.org/W4286222405",
        "https://openalex.org/W2026761333",
        "https://openalex.org/W4317748853",
        "https://openalex.org/W2791370475",
        "https://openalex.org/W4392052980",
        "https://openalex.org/W4391769133",
        "https://openalex.org/W3027572331",
        "https://openalex.org/W4312579111",
        "https://openalex.org/W4224437668",
        "https://openalex.org/W2162800060",
        "https://openalex.org/W2552408385",
        "https://openalex.org/W4393405337",
        "https://openalex.org/W4379537722",
        "https://openalex.org/W4385299212",
        "https://openalex.org/W4379929073",
        "https://openalex.org/W3195146636",
        "https://openalex.org/W2894771803",
        "https://openalex.org/W2026891775",
        "https://openalex.org/W4382603098",
        "https://openalex.org/W4391979508",
        "https://openalex.org/W4399251481",
        "https://openalex.org/W3008167346",
        "https://openalex.org/W6903462226",
        "https://openalex.org/W4392764172",
        "https://openalex.org/W4392736196",
        "https://openalex.org/W4406982964",
        "https://openalex.org/W2082704080",
        "https://openalex.org/W4376504248",
        "https://openalex.org/W3188872815",
        "https://openalex.org/W3175466730",
        "https://openalex.org/W4362496488",
        "https://openalex.org/W3190152617",
        "https://openalex.org/W4281398647",
        "https://openalex.org/W3012835873",
        "https://openalex.org/W3037983807",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2975059944",
        "https://openalex.org/W2996035354",
        "https://openalex.org/W2964110616",
        "https://openalex.org/W3106210592",
        "https://openalex.org/W6761628794",
        "https://openalex.org/W6776048684",
        "https://openalex.org/W6779163297",
        "https://openalex.org/W4321593177",
        "https://openalex.org/W3035038672",
        "https://openalex.org/W4287854593",
        "https://openalex.org/W4281481109",
        "https://openalex.org/W6852449896",
        "https://openalex.org/W4390490761",
        "https://openalex.org/W4381797997",
        "https://openalex.org/W4402671653",
        "https://openalex.org/W4372349720",
        "https://openalex.org/W4406121152",
        "https://openalex.org/W4386836424",
        "https://openalex.org/W3216163675",
        "https://openalex.org/W3007328579",
        "https://openalex.org/W4388153871",
        "https://openalex.org/W4396982316",
        "https://openalex.org/W3200271021",
        "https://openalex.org/W3094771832"
    ],
    "abstract": "Abstract Electrocardiograms (ECGs) are widely utilized in clinical practice as a non-invasive diagnostic tool for detecting cardiovascular diseases. Convolutional neural networks (CNNs) have been the primary choice for ECG analysis due to their capability to process raw signals. However, their localized convolutional operations limit the ability to capture long-range temporal dependencies across heartbeats, impeding a comprehensive cardiovascular assessment. To address these limitations, transformer-based frameworks have been introduced, employing self-attention mechanisms to effectively model complex temporal patterns over entire ECG sequences. Recent advancements in large language models (LLMs) have further expanded the utility of transformers by enabling multimodal integration and facilitating zero-shot diagnosis, thereby enhancing the scope of ECG-based clinical applications. Despite the increasing adoption of these methodologies, a comprehensive survey systematically examining transformer and LLM-based approaches for ECG analysis is absent from the literature. Consequently, this article surveys existing methods and proposes a novel hierarchical taxonomy based on the complexity of diagnosis, ranging from single-beat analysis to multi-beat and full-length signal evaluations. A thorough cross-category comparison is performed to highlight overarching commonalities and limitations. In light of these limitations, the paper presents a discussion of critical gaps and introduces new future directions aimed at improving ECG representation, enhancing positional encodings, refining self-attention architectures, and addressing challenges related to hallucinations and confidence measures in LLMs. The insights and guidelines presented aim to inform future research and clinical practices, enabling the next generation of intelligent ECG diagnostic systems.",
    "full_text": "Accepted: 11 May 2025 / Published online: 4 June 2025\n© The Author(s) 2025\nM.Y . Ansari, M. Yaqoob, and M. Ishaq have been contributed equally to this work.\nExtended author information available on the last page of the article\nA survey of transformers and large language models for ECG \ndiagnosis: advances, challenges, and future directions\nMohammed Yusuf Ansari1,2 · Mohammed Yaqoob1 · Mohammed Ishaq1 · \nEduardo Feo Flushing2 · Iffa Afsa changaai Mangalote3 · Sarada Prasad Dakua3 · \nOmar Aboumarzouk3 · Raffaella Righetti1 · Marwa Qaraqe4\nArtificial Intelligence Review (2025) 58:261\nhttps://doi.org/10.1007/s10462-025-11259-x\nAbstract\nElectrocardiograms (ECGs) are widely utilized in clinical practice as a non-invasive diag -\nnostic tool for detecting cardiovascular diseases. Convolutional neural networks (CNNs) \nhave been the primary choice for ECG analysis due to their capability to process raw \nsignals. However, their localized convolutional operations limit the ability to capture long-\nrange temporal dependencies across heartbeats, impeding a comprehensive cardiovascular \nassessment. To address these limitations, transformer-based frameworks have been intro -\nduced, employing self-attention mechanisms to effectively model complex temporal pat -\nterns over entire ECG sequences. Recent advancements in large language models (LLMs) \nhave further expanded the utility of transformers by enabling multimodal integration and \nfacilitating zero-shot diagnosis, thereby enhancing the scope of ECG-based clinical appli -\ncations. Despite the increasing adoption of these methodologies, a comprehensive survey \nsystematically examining transformer and LLM-based approaches for ECG analysis is ab -\nsent from the literature. Consequently, this article surveys existing methods and proposes \na novel hierarchical taxonomy based on the complexity of diagnosis, ranging from single-\nbeat analysis to multi-beat and full-length signal evaluations. A thorough cross-category \ncomparison is performed to highlight overarching commonalities and limitations. In light \nof these limitations, the paper presents a discussion of critical gaps and introduces new \nfuture directions aimed at improving ECG representation, enhancing positional encodings, \nrefining self-attention architectures, and addressing challenges related to hallucinations \nand confidence measures in LLMs. The insights and guidelines presented aim to inform \nfuture research and clinical practices, enabling the next generation of intelligent ECG \ndiagnostic systems.\nKeywords Arrhythmia · ECG representation · Hallucination · Large language models · \nMyocardial infarction · Positional encoding · Self-attention architecture · Single-beat \nand multi-beat analysis · Sleep apnea · Zero-shot diagnosis\n et al. [full author details at the end of the article]\n1 3\nM. Y. Ansari et al.\n1 Introduction\nAn electrocardiogram (ECG) is a widely adopted multi-channel signal that records the car-\ndiac electrical activity during the contraction and relaxation phases of the atria and ven -\ntricles. ECGs are a significant first step in several cardiac-related clinical protocols. To \nelaborate, ECGs are promptly performed in emergencies to assess cardiac function and \nguide immediate treatment in cases such as chest pain or suspected myocardial infarction \n(Gustafsson et al. 2022). ECGs are also integral to routine physical exams and preoperative \nassessments, especially for patients with cardiovascular risk factors, to detect asymptom -\natic abnormalities and evaluate cardiac risk before anesthesia and surgery (van Klei et al. \n2007). Additionally, implantable loop recorders (Milstein et al. 2020) and wearable ECG \ndevices (Bouzid et al. 2022) enable longitudinal ECG monitoring (Ha et al. 2021) to track \ndisease progression and assess the effectiveness of cardiac treatments. Consequently, ECG \nserves as a primary cardiac monitoring test in healthcare settings because of its non-invasive \nnature, cost-effectiveness, broad availability, versatility, reliability, and ability to provide \nimmediate and valuable insights into cardiac health.\nConventionally, electrophysiologists perform ECG analysis by extracting ECG features \n(i.e., amplitudes and duration of ECG waves). Subsequently, the derived features are com -\npared with the clinically established ECG normal values for the subject’s age group to for -\nmulate a diagnosis (Dickinson 2005; Rijnbeek et al. 2014). However, the manual nature of \nconventional ECG analysis raises several challenges. Specifically, manual ECG analysis \nis subjective, which can be time-consuming and cause human error, potentially leading \nto variability in diagnosis and missed subtle abnormalities. Machine learning addresses \nthese limitations by processing handcrafted features to provide objective and instantaneous \ndiagnosis of cardiac conditions. To elucidate, decision trees recursively partition the ECG \nfeatures into subsets generating tree-like interpretable structures, facilitating ECG diagno -\nsis (Kumari and Sai 2022). Bagging for ECG diagnosis employs multiple weak learners \n(e.g., decision trees) trained on a subset of data and aggregates (e.g., voting) their output for \nenhanced diagnostic accuracy (Mert et al. 2014). Similarly, boosting employs a strategy to \ntrain multiple weak learners sequentially, where each model tries to minimize the errors of \nits predecessor by placing higher emphasis on misdiagnosed ECG instances (Shi et al. 2019). \nAltogether, machine learning strategies have significantly advanced automated ECG diag -\nnosis but lack the ability to leverage raw ECG data, rely heavily on ECG domain knowledge \nfor feature extraction, and fail to utilize subtle ECG features that are not apparent or known \nto electrophysiologists. Deep learning has addressed these challenges by learning mappings \nbetween raw ECG signals and diagnostic tasks (i.e., representation learning) without the \nneed for manual feature extraction. Predominantly, CNNs have become the standard for \nECG analysis and diagnosis. The convolutional layers autonomously extract task-relevant \nfeatures, which are then passed through a multilayer perceptron to predict ECG disease \ndiagnosis (Rashed-Al-Mahfuz et al. 2021; Makimoto et al. 2020; Karthiga et al. 2022).\nECG data is inherently sequential and captures heartbeats over time steps. Thus, iden -\ntifying and tracking subtle changes across multiple beats in the wave morphology, ampli -\ntudes, and durations could play a significant role in diagnosing rhythmic abnormalities \n(e.g., arrhythmia) among other cardiac diseases (e.g., long QT syndrome and myocardial \nischemia). The mathematical formulation of CNNs using fixed kernel sizes intrinsically \nenables them to learn local spatial correlations. As a result, CNNs lack the ability to cap -\n1 3\n261 Page 2 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nture long-range dependencies due to their localized receptive fields and reliance on pooling \nlayers. Transformer architectures overcome this limitation using self-attention mechanisms \nthat capture long-range dependencies by attending to all positions in the sequence simul -\ntaneously. Conventionally, transformers are used for natural language tasks, allowing them \nto learn the context/relevance of the word in a sentence with respect to other words in \nthe current and previous sentences, improving the performance in language translation and \ngeneration tasks. Given the success of transformers for processing temporal data (e.g., lan -\nguage and speech), transformer-based networks with vanilla/modified self-attention, and \nhybrid CNN-transformer networks have been gaining traction in automated ECG diagnosis \nliterature. Particularly, atypical heartbeat (Peng et al. 2024), abnormal cardiac rhythm (Ji \net al. 2024), obstructive sleep apnea (Wang et al. 2024), and myocardial infarction (Liu \net al. 2024) diagnosis have significantly benefited from transformer-based neural network \nmethodologies.\nLLMs have recently advanced ECG diagnosis and analysis by leveraging their increased \nparameter count and deep layers, which enable them to capture complex patterns and \nnuanced relationships in ECG signals. LLMs (e.g., GPT) are typically pre-trained using \nlarge-scale datasets on a generic natural language task and subsequently fine-tuned for \nECG diagnosis and analysis tasks. A unique attribute of LLMs is their ability to handle \nmulti-modal data, such as ECG signals, patient history in natural language, and structured \ndemographic information, to enhance diagnostic Sensitivity  (Qiu et al. 2023). Additionally, \nthe comprehensive language understanding capabilities of LLMs can be harnessed by inte-\ngrating them with diagnostic databases, enabling zero-shot diagnoses. Recent advances in \nLLMs have enabled the integration of diverse clinical data, including ECG signals, radiol -\nogy images, and corresponding reports, to support comprehensive patient evaluations. For \nexample, Thapa et al. ( 2024) introduced MoRE, which fuses X-ray images, ECG signals, \nand cardiology reports into a unified representation for comprehensive patient evaluation. \nTrained with Lora-Peft and optimized using contrastive loss to align modality-specific fea-\ntures, MoRE enables effective multimodal retrieval and zero-shot classification, achiev -\ning state-of-the-art performance on downstream task datasets such as Mimic-IV , CheXpert, \nEdema Severity, and PTB-XL. Similarly, Guo et al. ( 2024) developed ECGChat, a mul -\ntimodal LLM that addresses discrepancies between ECG waveforms and textual cardiol -\nogy reports. ECGChat supports zero-shot report retrieval and the autonomous generation \nof detailed ECG analyses by employing contrastive learning to synchronize ECG data with \ncorresponding reports. Recently, Yu et al. (2023) proposed a zero-shot retrieval-augmented \ndiagnosis technique, where LLMs retrieve ECG expert knowledge from a curated database \nto analyze ECG data without needing extensive prior training for diagnosing arrhythmia \nand sleep apnea. LLMs are currently being used in real-world settings to generate discharge \nsummary reports (Chua et al. 2024), with pilot studies on RUSSEL GPT. Additionally, ran-\ndomized clinical trials are being conducted to evaluate their impact on diagnostic reasoning, \ndemonstrating their potential to influence clinical decision-making (Gallifant et al. 2025).\nECG analysis for diagnosis has been a constantly evolving domain, continuously adapt-\ning to the latest advancements in mainstream machine learning and deep learning. Several \nsurveys have been published to capture the progress in automated ECG diagnosis research. \nThese surveys focus on specific cardiac diseases, such as myocardial infarction (Han et \nal. 2024), hypertrophic cardiomayopathy (Maron et al. 2022), arrhythmia (Ebrahimi et al. \n2020), and long QT syndrome (Dehkordi et al. 2024). Reviews have also focused on the use \n1 3\nPage 3 of 42 261\nM. Y. Ansari et al.\nof specific computational approaches, like machine learning (Salari et al. 2022), CNNs (Liu \net al. 2021), and unsupervised learning (Nezamabadi et al. 2022).\nTo our knowledge, no existing work comprehensively captures the progress and scope of \ntransformer-based methodologies and the application of LLMs in the context of automated \nECG diagnosis. As such, this survey comprehensively reviews transformer-based methodol-\nogies and their evolution into LLMs for ECG diagnosis, highlighting their technical novelty, \napplication, limitations, and essential future directions. Particularly, the core contributions \nof this review are as follows:\n ● The categorization of the reviewed method follows a hierarchical analysis, starting with \ngranular abnormal beat detection and advancing to more complex rhythm-level analysis \nwithin arrhythmias, before extending to other diseases, such as sleep apnea and cardio-\nvascular diseases (CVDs) (e.g., myocardial infarction), among others. The review also \ncaptures the evolution of the transformer-based methodologies into LLMs, highlighting \ntheir applications in ECG-based diagnosis.\n ● Tabular summaries are provided to comprehensively capture ECG dataset details, meth-\nodological innovations, core results, and notable observations for each method dis -\ncussed in the review. Additionally, the textual descriptions offer insights complementing \nthe tabular summaries, providing descriptions and limitations specific to each work.\n ● The review conducts a cross-category comparison of methods to uncover overarching \ncommonalities and limitations in transformer and LLM approaches for ECG-based di -\nagnosis.\n ● In light of the limitations, the survey proposes essential ECG embedding enhancements \nand architectural innovations within the transformer and LLM pipelines. Subsequently, \nthe review introduces strategies to overcome the critical shortcomings of LLMs in ECG \ndiagnosis, potentially enhancing their transparency.\nFor transparency, this review adheres to the following inclusion and exclusion criteria: The \nmanuscript only includes articles from peer-reviewed journals and conferences that have \nundergone a robust peer-review process for the last five years (i.e., 2019-2024). Particularly, \nthe Google Scholar search engine was used in July-August 2024 to gather the articles within \nthe scope of this review. Specific search queries utilized are as follows: \"ECG Arrhyth -\nmia Transformers\", \"ECG Analysis Transformers\", \"ECG Diagnosis Transformers\", \"ECG \nSleep Apnea Transformers\", \"ECG diagnosis LLMs\", and \"ECG Analysis Large Language \nModels\". Popular shortlisted articles were cross-referenced to discover additional articles \nwithin the scope of this review.\nThe remainder of this survey is structured as follows: Sect. 2 provides the fundamental \nconceptual understanding of ECG and its role in CVD diagnosis along with an overview of \ntransformer architecture for ECG analysis. Section 3 comprehensively reviews the trans -\nformer and LLM methodologies for ECG-based diagnosis, highlighting commonalities and \nlimitations across these methods. Section 4 presents novel technical innovations to further \nimprove the state-of-the-art for ECG-based diagnosis and highlights novel applications of \nLLMs. Finally, sect. 5 summarizes the findings and concludes the paper.\n1 3\n261 Page 4 of 42\nA survey of transformers and large language models for ECG diagnosis:…\n2 ECG and transformer fundamentals\nThe section provides an overview of essential concepts pertaining to ECGs and transformer \narchitectures that are necessary to understand the reviewed articles.\n2.1 ECG leads and waveform basics\nA standard ECG for adults is a 12-lead multi-channel signal captured using 10 elec -\ntrodes (Ansari et al. 2024). As shown in Fig. 1, the 12 leads of the ECG can be broadly clas-\nsified into limb leads (i.e., I, II, III, aVL, aVR, and aVF) and chest leads (i.e., V1-V6). Six \nelectrodes are placed on the precordial region and capture their corresponding chest leads. \nThe remaining four electrodes are placed on the limbs, with one of them (typically right leg) \nserving as the ground/reference electrode. Limb leads measure the electrical activity in the \nfrontal plane of the body, providing insights into the heart’s rhythm and axis. Specifically, \nleads I, II, and III are standard limb leads that are captured by taking the difference of elec-\ntrodes on the right arm, left arm, and left leg. Leads aVL, aVR, and aVF are augmented limb \nleads calculated by taking the average of two limb electrodes with respect to the third limb \nelectrode. Key views covered by the limb leads include the lateral and inferior walls of the \nheart. In contrast, the chest leads measure the electrical activity in the horizontal plane of \nthe body, offering detailed views of the heart’s anterior and lateral walls. Specifically, leads \nV1 and V2 are oriented toward the right ventricle, offering a direct view of the septum wall. \nLeads V3 and V4 are positioned to face the interventricular septum anteriorly, capturing the \nelectrical signals from the muscle that separates the left and right ventricles. Finally, leads \nV5 and V6 are directed toward the left ventricle and focus on the lateral wall (Wasimuddin \net al. 2020; Ansari et al. 2023).\nECG waveform corresponds to the contraction and relaxation of the cardiac chambers, \nenabling blood flow. Specifically, the P-wave captures atrial depolarization that occurs with \nthe generation of electrical impulse in the sinoatrial node (i.e., natural cardiac pacemaker), \ncausing the atria to contract and push blood into the ventricles. Abnormalities in P-wave \nmorphology and duration could indicate atrial enlargement (Yokota et al. 2021), atrial fibril-\nlation (Rasmussen et al. 2020), or other atrial abnormalities. The QRS complex represents \nFig. 1 Cardiac anatomy and Electrocardiogram lead placement. A Cross-sectional view of the heart il -\nlustrating key structures of the cardiac conduction system. B Standard 12-lead ECG electrode positions\n \n1 3\nPage 5 of 42 261\nM. Y. Ansari et al.\nventricular depolarization, which occurs as the electrical impulse travels through the ven -\ntricles, pumping blood to the rest of the body. QRS waveform is crucial for assessing ven -\ntricular function and extended QRS duration or abnormal morphology (e.g., bundle branch \nblocks) can indicate conduction delays (Wu et al. 2021), ventricular hypertrophy (Pelliccia \net al. 2023), or myocardial infarction (Luo et al. 2020). Finally, the T-wave encapsulates the \nprocess of the ventricles returning to their resting state after contraction. Abnormalities such \nas T wave inversion, flattening, or peaking can indicate ischemia (Li et al. 2021) or cardio-\nmyopathies (D’Ascenzi et al. 2020). The duration of the individual waves and the intervals \nbetween them hold significant diagnostic importance. The PR interval is the duration from \nthe onset of the P wave to the start of the QRS complex, capturing the time taken for the \nelectrical impulse to travel from the atria to the ventricles. The ST segment represents the \nperiod between the end of ventricular depolarization and the beginning of ventricular repo-\nlarization. The QT interval indicates the net time for ventricular depolarization and repolar-\nization, from the start of the QRS complex to the end of the T wave.\n2.2 Overview of transformers and LLMs\nDeep neural network-based approaches have gained significant momentum across a range \nof domains, including natural language processing (Gillioz et al. 2020; Tetko et al. 2020), \ngeoscience (Yaqoob et al. 2024, 2025; Yaqoob et al. 2025a; Dahmani et al. 2025; Yaqoob \net al. 2025b), speech recognition (Dong et al. 2018; Karita et al. 2019), medical imag -\ning (Ansari et al. 2023; Shamshad et al. 2023; Ansari et al. 2024; Li et al. 2023; Ansari \net al. 2022; Akhtar et al. 2021; Ansari et al. 2022; Ansari and Qaraqe 2023), and biomedical \nsignal analysis (Zhang et al. 2023; Lih et al. 2023; Afsa et al. 2024). Recently, transformer \narchitecture has been proposed to overcome the design limitations of previous sequence \nanalysis models such as Recurrent Neural Networks (RNNs) (Salloum and Kuo 2017) and \nLong Short-Term Memory networks (LSTMs) (Hou et al. 2019). RNNs/LSTMs lack the \nability to capture long-range dependencies due to issues like vanishing gradients and fixed-\nlength context, limiting their understanding of how a data point relates to other points in a \nlong sequence. Furthermore, the sequential nature of these models leads to longer training \ntimes, limiting their efficiency, especially with large datasets. Transformers overcome these \nchallenges by utilizing self-attention mechanisms that allow for parallel processing of all \nelements in a sequence (see Fig. 2 for the schematic architecture of the transformer). This \nparallelism addresses the inefficiencies of sequential processing and enables the model to \nmaintain a more comprehensive contextual understanding across entire sequences. Specific \ncomponents that are combined to form the transformer architecture for ECG analysis are \nas follows:\n2.2.1 Component 1: data embeddings\nTransformers were initially developed for natural language processing (NLP) tasks, with \none primary task being predicting the next word in a sequence. However, raw textual data \n(e.g., words) cannot be directly processed by the transformer, as it is designed to operate on \nnumerical inputs. To overcome this challenge, words are represented as a dense vector in a \nhigh-dimensional space (i.e., embeddings) (Takase and Kobayashi 2020). Embeddings are \ncarefully designed/learned to capture nuance details from the data. For instance, embeddings \n1 3\n261 Page 6 of 42\nA survey of transformers and large language models for ECG diagnosis:…\ncapture semantic similarity with similar words with related meanings positioned closely in \nthe embedding space. Additionally, advanced embeddings are context-aware, meaning that \nthe vector representation of words is adjusted based on the surrounding context (e.g., the \nwords \"bank\" may have different meanings in the context of river and finance), thus captur-\ning nuanced meanings. In the context of ECG, embeddings are typically learned from ECG \nleads through a sequence of convolutional blocks (i.e., representation learning), enabling \nthe network to learn condensed and meaningful representations of ECG signals for the given \ntask.\n2.2.2 Component 2: positional encoding\nTransformers process all data points of a sequence in parallel, which enhances efficiency \nand the ability to capture long-range dependencies. However, this parallelism means that \nthe embeddings lack intrinsic information about the order of the sequence. To address \nthis, positional encodings are generated and added to the word embeddings, providing the \ntransformer with the necessary information about the position of each data point within the \nsequence (Su et al. 2024). In NLP and ECG diagnosis tasks, it is common to employ posi -\ntional embeddings that combine sine and cosine functions. For each position, a positional \nencoding vector is generated by applying the sine function to even-numbered dimensions \nand the cosine function to odd-numbered dimensions. Additionally, the frequency of the \nsine and cosine waves varies with the position in the sequence. Given a fixed position in \nthe embedding vector, as the position in sequence increases, the frequency increases, thus, \ncreating a unique pattern for each position. It is crucial to note that positional encodings \nhave small values relative to the values in the word embeddings, ensuring that the addition \nof positional encodings doesn’t overwhelm or dominate the information in the word embed-\ndings. Mathematically, the sine-cosine positional encoding can be expressed as:\n \nPE(pos,i) =\n\n\n\nsin\n(\npos\n10000\n2i\nd\n)\nif i is even\ncos\n(\npos\n10000\n2i\nd\n)\nif i is odd\n (1)\nFig. 2 Design of a transformer-based architecture for ECG analysis and cardiovascular disease prediction\n \n1 3\nPage 7 of 42 261\nM. Y. Ansari et al.\nHere, pos represents the data point position in the sequence, i represents the index within the \nembedding vector, and d is the dimensionality of the embeddings. 10000\n2i\nd  scales the input \nto create distinct and smooth positional encodings across the dimensions.\n2.2.3 Component 3: self-attention\nThe fundamental novelty of the transformer architecture is the self-attention mecha -\nnism (Vaswani et al. 2017). Specifically, given a condensed representation of ECG leads, \nself-attention computes the relevance of a feature, such as the P-wave amplitude, in relation \nto other critical features like the R-peak and T-wave amplitude within the same or across dif-\nferent beats. To achieve this, the model linearly transforms the ECG embeddings into Query \n(Q), Key (K), and Value (V) vectors. Mathematically, the vectors are generated as follows:\n Q = XWQ, K = XWK, V = XWV  (2)\nHere, X represents the ECG embeddings. The matrices WQ, WK, and WV  are learnable \nweight matrices that project the input embeddings into three distinct spaces to generate \nthe Q, K, and V matrices. The Query vector represents the feature whose influence or rel -\nevance the model seeks to understand (e.g., the P-wave amplitude). The Key vectors encode \nrelated ECG features (e.g., R-peak, T-wave) to determine their relevance to the Query. The \nValue vector contains the actual ECG data that is weighted according to the attention scores \nderived from the Q-K interactions. Mathematically, the attention scores are computed as:\n \nAttention(Q, K, V)= softmax\n(\nQK⊤\n√dk\n)\nV (3)\nHere, dk represents the dimensionality of keys, and √dk scales the scores to prevent large \nscores during training. The resulting weighted sum is a contextually enriched representation \nof the initial ECG embeddings that enhances the model’s ability to analyze complex inter-\nbeat and intra-beat relationships.\n2.2.4 Component 4: multi-head attention\nMultiple self-attention mechanisms in parallel can allow the transformer model to attend to \ndifferent aspects of the ECG signal (V oita et al. 2019). This idea is implemented in trans -\nformers using multiple heads (i.e., multi-head self-attention (MHSA)) parallelly. To elabo-\nrate, one head can identify the relationships between P-wave features across multiple beats, \nwhich is essential for analyzing atrial activity. Another head could concentrate on the timing \nand amplitude of R-peaks, evaluating heart rhythm and ventricular depolarization. MHSA \ncan be implemented by first splitting the Q, K, and V matrices (equation 2) along the embed-\nding dimension, enabling each head to operate on a subspace of these matrices with dimen-\nsion dk = dmodel/h. Subsequently, each head can compute the attention score from Qh and \nKh and reweigh Vh as shown in equation 3. The heads are then combined to generate the \noutput. Mathematically, this can be represented as:\n Output = Concat(head1, head2,..., headh)WO (4)\n1 3\n261 Page 8 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nHere, WO represents the linear transformation used for generating the output of MHSA.\n2.2.5 Component 5: add and norm and feed-forward networks\nAfter the MHSA reweighs the input ECG embeddings, the feature maps go through the \nAdd&Norm layer. The \"Add\" component represents a residual connection, allowing the \nmodel to cope with vanishing gradients and dilution of feature information that may occur \nduring the MHSA transformations. Next, the \"Norm\" depicts layer normalization which \nnormalizes the feature map by using the sum across the channel dimension. Layer normal -\nization minimizes the internal covariate shift that may happen during training and speeds up \nthe convergence of the model. Subsequently, a series of fully connected layers with activa-\ntion functions are used to introduce non-linearity to the model. The fully connected layers \nare arranged in an inverted bottleneck layout. To elaborate, the first linear layer expands the \ndimensionality of the input (e.g., 4 × dmodel), and the second layer reduces it back to the \noriginal size (i.e., dmodel) (Geva et al. 2020). The expansion allows the transformer model \nto utilize higher dimensional feature space, enabling the capture of detailed and abstract \nfeatures before compressing to the initial embedding space. The Add&Norm process is \nrepeated after the feature map passes through the fully connected layers.\n3 Reviewed methods\nThis section presents the findings from the surveyed literature, focusing on the role of trans-\nformers and LLMs for ECG-based disease classification. The review is organized hierarchi-\ncally, beginning with granular abnormal beat detection and rhythm-level analysis within \narrhythmias, then extending to other diseases, such as sleep apnea and CVDs (see Fig. 3 for \na timeline of relevant studies). The section also covers the recent applications of LLMs for \nECG analysis and diagnosis.\n3.1 Arrhythmia\n3.1.1 Beat classification\nTransformer-based architectures have gained prominence in classifying abnormal heart -\nbeats from ECG signals. Several studies focus exclusively on employing transformers to \nprocess raw ECG signals, leveraging their ability to capture both temporal and spatial fea -\ntures through enhancements like convolutional layers and sequential processing units (refer \nto Table 1). El-Ghaish and Eldele ( 2024) present ECGTransForm by integrating a bidi -\nrectional transformer (BiTrans) mechanism with multi-scale convolutions and a channel \nre-calibration module (CRM). The architecture differs from standard transformer models by \nincorporating multi-scale convolutional layers that capture spatial features across different \nscales, followed by a CRM that recalibrates channel-wise features to enhance inter-depen -\ndencies between channels. The Bidirectional transformer captures temporal dependencies \nfrom both past and future contexts. However, a limitation of the paper is the potential com-\nputational complexity introduced by the Bidirectional transformer. Hu et al. (2021) pro-\npose a robust wave-feature adaptive heartbeat classification using transformers. An adaptive \n1 3\nPage 9 of 42 261\nM. Y. Ansari et al.\nheartbeat segmentation method is proposed, which dynamically adjusts the segmentation \nwindow based on the local RR interval. This modification allows the model to focus on \nrelevant heartbeat segments within the ECG waveform. The architecture employs a standard \ntransformer encoder that receives ECG wave features produced by 1D convolutional lay -\ners. However, a limitation of this approach is its reliance on the accuracy of the RR interval \ncalculation for segmentation; any error in RR interval detection can propagate through the \nmodel. Islam et al. ( 2024) propose CAT-Net architecture. CAT-Net comprises CNN layers \nthat capture the morphological features of the ECG signals, while the MHSA refines these \nfeatures by reweighing the relevant segments. However, this model’s evaluation on balanced \ndatasets remains a limitation, as its performance on minority classes is sub-optimal. Busia et \nal. (2024) present a novel \"Tiny Transformer\" model optimized for low-power arrhythmia \nclassification on microcontrollers, achieving a balance between high accuracy (98.97% on \n8-bit quantization) and low computational complexity (requiring only 6,649 parameters and \n0.09mJ per inference). The architecture utilizes a standard ViT block modified for 1D ECG \nsignals with a single standard encoder block. A convolutional embedding stage prepares the \nECG signal patches for processing with ViT. The authors limit the embedding size to 16 and \nthe number of heads to 8 to minimize computational cost. Despite these innovations, the \nmodel’s dependency on a single MHSA limits its ability to fully capture complex interac -\ntions within ECG signals, potentially impacting its generalizability for noisy ECG signals.\nLiu et al. ( 2024) introduce the PSC-Net architecture. PSC-Net uses a modified trans -\nformer encoder where traditional fully connected layers are replaced with gated recurrent \nunit (GRU) layers that improve the model’s ability to handle sequential data by reducing \nthe risk of information loss across layers. The architecture also includes a unique feature \nfusion block that combines local features extracted by the GLNet (a CNN-based mod -\nule) with global features obtained from the transformer encoder. However, a limitation of \nthis approach is the potential overfitting caused by the extensive use of feature fusion and \nweighted residual connections. Lastly, Din et al. (2024) implements a hybrid model that \nintegrates CNN, LSTM, and transformer in a single architecture. The proposed model capi-\nFig. 3 Timeline of studies utilizing transformer-based architectures for ECG analysis in various cardio -\nvascular conditions, categorized by arrhythmia detection, sleep apnea detection, myocardial infarction \ndetection, and other cardiovascular conditions\n \n1 3\n261 Page 10 of 42\nA survey of transformers and large language models for ECG diagnosis:…\ntalizes on the spatial feature extraction capability of CNNs, the temporal sequence learning \nability of LSTMs, and the long-range dependency capturing strength of transformers. The \ntransformer component of the model uses 6 MHSA modules. Feature fusion layer merge \noutputs from CNN, LSTM, and transformer branches, and classification is done using a \nmajority voting system. One limitation of this approach is its reliance on three separate \nbranches, which makes it computationally intensive. Lastly, Chon et al. ( 2023) integrate a \nmulti-kernel resNet (MK-ResNet) with a transformer model. The MK-ResNet employs two \ndifferent kernel sizes (5 and 11) to capture features at multiple scales. These feature maps \nare then fed into a standard transformer architecture. The HRV-based position encoding \nwithin the transformer integrates heart rate variability data directly into the model. This \nTable 1 Summary of transformer-based models using raw ECG signals for beat classification\nRefer-\nence \n(Year)\nDataset Core \nmethodology\nResults Remarks\nEl-\nGhaish \nand \nEldele \n(2024)\nMIT-BIH (Moody \nand Mark 2001)\n+\nPTB (Bousseljot et \nal. 1995)\nECGTransForm Accuracy: \n99.35±0.16,\nF1 Score: \n94.26±0.28\nContext aware Loss (CAL) addresses\nthe inherent class imbalance in\nECG signals by dynamically adjusting\nthe weights based on class \nrepresentation\nIslam \net al. \n(2024)\nMIT-BIH (Moody \nand Mark 2001)\n+\nINCART (Tiho-\nnenko et al. 2007)\nCAT-Net F1 Score: \n99.14%\nSMOTE-Tomek was used\nto address class imbalance in\nthe ECG data\nBusia \net al. \n(2024)\nMIT-BIH (Moody \nand Mark 2001)\nTiny\nTransformer\nAccuracy: \n98.97%\nThe transformer model, with\nonly 6,000 parameters, can\nclassify the five most common\narrhythmia classes\nLiu \net al. \n(2024)\nCustom CHD \nDataset\n+\nMIT-BIH (Moody \nand Mark 2001)\n+\nMIT-BIH ST \nChange (Albrecht \n1983)\nPSC-Net Specificity: \n89.93%,\nSensitivity: \n84.06%\nA LSTM based network\n(GRWA-LSTM) is utilized for local\ntemporal feature extraction\nDin \net al. \n(2024)\nMIT-BIH (Moody \nand Mark 2001)\nHybrid\nTransformer\nModel\n(HTM)\nF1 Score: \n99.34%\nFuses features extracted by\na CNN, LSTM, and transformer model\nto leverage the unique advantages\nof each\n(Chon \net al. \n2023)\nMIT-BIH (Moody \nand Mark 2001)\nHybrid\nTransformer\nModel\n(HTM)\nSpecific-\nity:0.898,\nSensitivity: \n0.807\nMulti-kernel ResNet was used\nto extract fetures, and postion\nembedding based on the heart rate\nwas used\nHu et al. \n(2021)\nMIT-BIH (Moody \nand Mark 2001)\nCustom\nTransformer\nF1 Score: \n99.83%\nAn adaptive heartbeat segmentation\nmethod was implemented to electively\nfocus on the time-dependent \nrepresentation\nof heartbeats\nThe table compares models based on dataset usage, core methodologies, performance metrics, and unique \ninnovations in handling raw ECG data, focusing on how different architectures leverage transformers to \nimprove classification accuracy and efficiency\n1 3\nPage 11 of 42 261\nM. Y. Ansari et al.\nstructure allows the transformer to recalibrate features extracted from MK-ResNet, leading \nto improved classification performance. However, the model’s heavy reliance on pretraining \nwith external datasets, like icentia11k, can lead to performance degradation when applied to \nECG signals from new, diverse patient populations not represented in the pretraining data.\nSeveral studies have advanced transformer-based ECG beat classification by integrat -\ning additional preprocessing techniques and multimodal data to enhance feature extraction \nand address challenges like data imbalance and signal variability (refer to Table 2). Zhu et \nal. (2024) employ ICMT-Net, focusing on both ECG and wrist pulse signals. The model \nintegrates an improved ConvNeXt with a multimodal transformer and MLP fusion layers, \nenabling the extraction and fusion of features from both signal modalities. The standard \ntransformer architecture is modified with batch normalization layers and a convolutional \nblock attention module. However, ICMT-Net is dependent on a carefully tuned multimodal \nfusion strategy, which may not generalize well to other types of physiological signals. Xia \nRefer-\nence \n(Year)\nDataset \ninformation\nCore \nmethodology\nResult Remarks\nZhu \net al. \n(2024)\nMIT-BIH \n(Moody and \nMark 2001)\nICMT-Net Specific-\nity: 98.29,\nSensitiv-\nity: 96.30\nUses both ECG \nand wrist\npulse signal \n(WPS) for a \nmultimodal\nclassifier\nXia \net al. \n(2023)\nMIT-BIH \n(Moody and \nMark 2001)\nTCGAN Accuracy: \n94.69%\nGenerates heart-\nbeat signals per\ndisease type \nwhich are then\nadded to the \noriginal dataset \nto\naddress the \ndata-imbalance \nproblem\nXia \net al. \n(2023)\nMIT-BIH \n(Moody and \nMark 2001)\nHybrid\nTransformer\nModel\n(HTM)\nSpecific-\nity:99.37,\nSensitiv-\nity: 99.91\nLocal features \nare extracted by\na denoising \nencoder before \nbeing\npassed to a \nlightweight \ntransformer\nGuan \net al. \n(2021)\nMIT-BIH \n(Moody and \nMark 2001)\nLDTF Speci-\nficity: \n98.39%,\nSensi-\ntivity: \n98.41%\nThe low-dimen-\nsional denoising\nembedding \n(LDE) captures \nlow\ndimensional \nrepresenta-\ntion of\nthe signal in the \ntime-frequency\ndomain, retain-\ning the signals\ntemporal \ninformation\nTable 2 Summary of transform-\ner-based models with specialized \npreprocessing of ECG signals \nand multimodal data integration \nfor ECG beat classification\nThe table compares models \nbased on dataset usage, core \nmethodologies, performance \nmetrics, and innovations \nin preprocessing and data \nintegration techniques\n \n1 3\n261 Page 12 of 42\nA survey of transformers and large language models for ECG diagnosis:…\net al. (2023) presents a transformer and convolution-based generative adversarial network \n(TCGAN) for addressing the class imbalance problem in abnormal beat classification. The \ntransformer encoder is modified by incorporating two-stage upsampling to enhance the res-\nolution of generated ECG signals. The discriminator remains a conventional CNN, focusing \non local feature extraction to differentiate between real and synthetic data. These modifica-\ntions allow the model to generate high-quality ECG signals that closely resemble real data. \nHowever, the reliance on fixed-length input sequences may reduce the model’s generaliz -\nability to ECG signals of varying lengths. Xia et al. (2023) introduce a novel seq2seq model \nthat combines a lightweight transformer with CNN and denoising autoencoder (DAE) \nembeddings to improve inter-patient ECG arrhythmia classification. The CNN and DAE \nmodules extract ECG wave features from individual heartbeats that are merged with manu-\nally extracted R-R features. Combined features with positional encoding are passed through \na transformer encoder for capturing global dependencies. This approach leads to improved \nperformance, particularly in minority classes. However, a limitation of the proposed model \nis its reliance on the pre-training of the DAE using external datasets, which introduces a \ndependency on data not inherent to the target domain. Lastly, Guan et al. (2021) implement \na low-dimensional denoising embedding transformer (LDTF) for abnormal beat classifi -\ncation. The low-dimensional denoising embedding (LDE) stage combines features from \nboth time and frequency domains using discrete wavelet transform (DWT) and fast Fourier \ntransform (FFT). This LDE is integrated with a transformer architecture, which includes 8 \nstandard transformer encoder layers. The blocks are strategically placed to maximize the \nextraction of both time-domain and frequency-domain features, enhancing the model’s abil-\nity to classify arrhythmias. However, a shortcoming of this approach is its dependence on \nhand-crafted feature extraction techniques like DWT and FFT.\nA few works have introduced innovations in attention mechanisms within transformers, \ndeveloping modified or novel strategies to improve the accuracy of ECG beat classification \n(refer to Table 3). Meng et al. (2022) present a lightweight fussing transformer model where \nstandard self-attention is replaced with a lightConv attention (LCA) mechanism to reduce \nthe model’s complexity while maintaining performance. The architecture incorporates a \nCNN-based input embedding structure, which extracts intra-heartbeat features using local \nattention mechanisms. The LCA reduces parameters by 72% compared to self-attention, \nimproving efficiency without hampering accuracy. However, a critical limitation of this \napproach is its reliance on handcrafted convolutional structures. Tao et al. (2024) introduce \na refined transformer model arrhythmia beat detection. The model uses two specialized \nattention mechanisms: refined diagonal attention and refined gated linear (GAL) attention. \nThese mechanisms reduce the computational burden by selectively focusing on critical cor-\nrelations between heartbeats, thus maintaining the essential temporal and morphological \ninformation needed for arrhythmia detection. The attention blocks are placed within a col -\nlaborative framework that processes both rhythmic and beat arrhythmia. This placement also \naccelerates model convergence by approximately 50% compared to other models. However, \nthe model’s reliance on predefined rhythm and heartbeat segmentation may restrict its abil-\nity to generalize to unsegmented ECG datasets. Wu et al. ( 2024) present the SRT model, a \nCNN-Transformer with a dilated stem module, and the spatial and channel residual gated \nattention (SC-RGA) modules for classifying 2D heartbeat images. The dilated stem module \nis placed at the input stage to expand the receptive field without losing spatial resolution. \nThe SC-RGA module is placed after the MHSA layer to enhance the focus on critical spatial \n1 3\nPage 13 of 42 261\nM. Y. Ansari et al.\nand channel-wise features. However, a critical limitation of this approach is its reliance on \nthe spatial configuration of 2D ECG images. Lastly, Wang et al. (2023) propose a novel \nMHSA, termed ACA-MA for transformer models for ECG beat classification. ACA-MA \nutilizes a linear projection layer to extract semantic features from ECG signals. Moreover, \na position encoding-based spatiotemporal characterization method is used to integrate time \nseries information into a matrix format, and a MHSA to capture global contextual informa-\ntion. However, a critical limitation of this model is its dependency on carefully engineered \nposition encoding, which may not adapt well to variations in ECG signals.\n3.1.2 Rhythm classification\nTransformer-based architectures have been popular in identifying irregular cardiac rhythms \nfrom ECG signals (refer to Table 4). Wang et al. (2021) introduce a heartbeat-aware trans-\nformer (HAT) that incorporates heartbeat position attention within the transformer block. \nThe architecture features a convolutional backbone that processes ECG to extract ECG \nfeatures. Subsequently, the model employs heartbeat-aware transformer blocks to incor -\nporate heartbeat positions into the standard self-attention process. However, the model is \nlimited to short ECG inputs (8 s), potentially missing long-term temporal patterns essential \nTable 3 Summary of transformer-based architectures employing novel attention mechanisms for ECG beat \nclassification\nRefer-\nence \n(Year)\nDataset information Core \nmethodology\nResult Remarks\nTao \net al. \n(2024)\nMIT-BIH (Moody \nand Mark 2001)\nRefined-attention\ntransformer \nmodel\nSpecificity: \n95.22%,\nSensitivity: \n97.50%\nTwo transformer models share\nrhythm information through a\n\"collaborative block\" that facilitates\ninteraction between them\nWu \net al. \n(2024)\nMIT-BIH (Moody \nand Mark 2001)\nHybrid\nTransformer\nModel\n(HTM)\nAccuracy: \n95.7%,\nSensitivity: \n0.881,\nF1 Score: 0.826\nModel’s performance was improved\nby expanding the transformer’s\nreceptive field and extracting \nfeatures\nfrom multiple subspaces using the\nSC-RGA attention mechanism\nWang \net al. \n(2023)\n(2023)\nMIT-BIH (Moody \nand Mark 2001)\nACA-MA\nTransformer\nAccuracy: \n96.61%,\nSpecificity: \n99.31%,\nSensitivity: \n93.27%\nA linear projection layer is used\nto capture the semantic features\nof ECG signals by aligning ECG \ntags\nwith their corresponding\nsegmented signals\nMeng \net al. \n(2022)\n(2022)\nCustom Dataset\n(10 dynamic single \nlead\nECG recordings, \ncollected\nusing a unified \nwearable\nECG device,\nsampling frequency:\n400Hz,\nduration: 24 h)\nLightweight \nFussing \nTransformer\nSpecificity: \n0.9975, Sensi-\ntivity: 0.9984\nLightConv Attention (LCA) is \na replacement for traditional \nself-attention\nin transformers, offering compa-\nrable or superior performance while \nutilizing\nfewer parameters\nThe table compares various models in terms of dataset usage, core methodologies, performance metrics, \nand unique innovations in attention mechanisms\n1 3\n261 Page 14 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nfor accurate arrhythmia classification. Similarly, Yang et al. (2022) propose a component-\naware transformer (CAT) that first decomposes ECG waveforms into components like the \nP-wave, QRS-complex, and T-wave using a 1D U-net-based segmentation model. These \ncomponents are then converted into tokens that include information about their length and \ntype, allowing the model to capture detailed characteristics of each waveform segment. \nThis approach enhances the model’s ability to analyze both single-lead and multi-lead ECG \nsignals. However, the model heavily depends on the accuracy of the ECG segmentation, \nwhich was trained on a small dataset (LUDB(Kalyakulina et al. 2020) with only 200 cases), \npotentially limiting its generalizability.\nSeveral works attempt to enhance traditional transformer architectures with residual and \nconvolutional techniques. Pratiher et al. ( 2022) present an enhanced vision transformer \n(ViT) by introducing dilated convolutional and residual connections. The ECG signals are \ntransformed into time-frequency representations (TFRs) using continuous wavelet trans -\nform (CWT), short-time fourier transform (STFT), and chirplet transform (CT). These TFRs \nare then stacked and used as input to the ViT for AF detection. The dilated convolutional \nstem expands the receptive field for multi-scale feature extraction without loss of resolution. \nSubsequently, eight transformer layers, with an MHSA mechanism are employed. Residual \nconnections are integrated throughout to improve training stability and aid convergence. \nHowever, the model’s reliance on time-frequency representations (TFRs) may limit its \nadaptability to raw ECG data, and its performance across different arrhythmia types remains \nunderexplored. Che et al. (2021) propose a transformer architecture that is embedded within \na CNN framework. Specifically, the architecture includes 8 standard transformer blocks \nwith MHSA. Performance is enhanced by using a novel link constraint loss function that \nclusters embedding vectors of the same class closer together, improving the model’s abil -\nity to differentiate between classes and mitigating the effects of data imbalance. This link \nconstraint improves feature consistency and classification accuracy, but it adds significant \ncomputational costs due to the complexity, making it impractical for resource-constrained \nenvironments like portable ECG devices.\nLastly, some studies have focused on leveraging self-supervised learning and multi-scale \nattention mechanisms. Zou et al. ( 2023) employ a CNN-Transformer architecture for AF \ndetection, with a core novelty centered around a self-supervised learning approach. The \narchitecture employs a standard transformer consisting of three blocks with MHSA, follow-\ning a four-block CNN backbone for initial feature extraction. The self-supervised learning \napproach involves a \"next clip\" prediction task, where the model is pre-trained to predict the \nnext segment of an ECG signal based on the previous interval, enabling it to learn temporal \nfeatures critical for AF detection. However, like Wang et al. (2021), the model is limited to \nshort ECG inputs (10 s) potentially missing long-term temporal patterns. In another work, Ji \net al. (2024) present a transformer architecture that combines multi-scale grid attention with \nself-attention mechanisms to effectively capture both spatial and temporal features of ECG \nsignals. The model first divides the 12-lead ECG into limb and chest leads, subsequently \nusing self-attention to fuse features from these lead subsets. Next, the multi-scale grid atten-\ntion mechanism dynamically adjust grid sizes to extract temporal features at various scales, \nenabling the model to capture both local and global patterns in the ECG data. However, \nthis integration of multi-scale grid and self-attention mechanisms introduces significant \ncomputational complexity, which may reduce the model’s practicality for computationally-\nconstrained environments.\n1 3\nPage 15 of 42 261\nM. Y. Ansari et al.\nTable 4 Overview of recent advancements for rhythm classification using ECG signals\nRefer-\nence \n(Year)\nDataset Core \nmethodology\nResult Remarks\nJi et al. \n(2024)\nCPSC 2018 \n(Alday et al. \n2020)\n+\nMIT-BIH \n(Moody and \nMark 2001)\nMulti-Scale Grid\nTransformer\n(MSGformer)\nF1 Score: 0.86,\nSensitivity: 97.13%,\nSpecificity: 97.87%,\nAccuracy: 99.28%\nSpatial features captured from\nlimb and chest leads are used\nby a multi-scale grid attention\nmechanismto capture temporal \nfeatures\n(Zou \net al. \n2023)\nCPSC 2018 \n(Alday et al. \n2020)\nSelf supervised \nlearning\nwitha \nCNNTransformer\narchitecture\nSensitivity: 0.84 ± 0.01,\nSpecificity: 0.84 ± 0.01\nThe model only accepted \n10-second\nECG recordings and showed \nlowered\nclassification upon pre-training\nPrati-\nher \net al. \n(2022)\nPCC 2017 \n(Clifford et al. \n2017)\n+\nPCC 2021 \n(Reyna et al. \n2021)\nDilated Residual \nViT\n(DiResViT)\nSensitivity: 98.05%,\nSpecificity: 98.16%\nThe standard patchify stem\nof the ViT is replaced with \ndilated\nconvolutional stem with \nresidual\nconnections for improved \ndetection\nYang \net al. \n(2022)\nShaoxing \nHospital\nZhejiangUni-\nversity\nSchool of\nMedicine\ndatabase \n(Zheng et al. \n2022)\nComponent-\nAware\nTransformer\n(CAT)\nF1 Score: 81.53−85.13%,\nAUC: 0.9767−0.9823\nThe ECG waveform is \ndecomposed\ninto components, which are \nvectorized\ninto a single vector with length \nand\ntype information, and used \nas the\ntransformer’s input\nWang \net al. \n(2021)\nCustom Dataset\n(multi-lead\nECGrecords\nof over\n200,000 \npatients\nfrom200+\nhospitals.\n(sampling freq\n250 Hz,\nleads = 4)\nHeartbeat-Aware\nTransformer\n(HAT)\nF1 Score: 0.9628 Introduces Heartbeat Position \nAttention\nwhich heartbeat positions into\nencoder-decoder attention\nChe \net al. \n(2021)\nCPSC 2018 \n(Alday et al. \n2020)\nTransformer \nmerged\nCNN \narchitecture\nF1 Score: 0.786 The quality of feature \nembeddings\nwas enhanced using link \nconstraints\nthat enforced similar data items\nto have closely aligned features\n(Must-link) and different items \nto have\ndistinctly separate features \n(No-link)\n1 3\n261 Page 16 of 42\nA survey of transformers and large language models for ECG diagnosis:…\n3.2 Sleep apnea\nSeveral studies have focused on employing transformers to improve the detection of \nobstructive sleep apnea (OSA) from ECG signals (refer to Table 5). Hu et al. ( 2022) pres-\nent a hybrid transformer model (HTM) for OSA detection using single-lead ECG signals. \nThe model introduces a multiperspective channel attention (MPCA) block to automatically \nderive and fuse features from raw ECG sequences, R-peak amplitude, interbeat (RR) inter-\nval, and RR interval first-order difference. The MPCA block employs three parallel two-\nlayer convolutional networks with varying kernel sizes to capture multiperspective features. \nAdditionally, a squeeze-and-excitation (SE) block is integrated to adaptively focus on the \nmost relevant features. These features along with positional encodings are fed into trans -\nformer blocks to capture long-range dependency in features. While this architecture reduces \ncomplexity by using automatically derived features, the selected features might oversim -\nplify the ECG’s complex, nonlinear characteristics, potentially limiting the model’s ability \nto capture subtle OSA-related patterns. Similarily, Wei et al. (2024) introduce the MSAF-\nTransformer, a multi-scale attentive feature network for OSA prediction using single-lead \nECG signals. First, the network extracts features from raw ECG signals with CNNs of vary-\ning kernel sizes. Next, the extracted features pass through an attention channel compression \nmodule that performs point-to-point convolution to reduce the number of feature channels. \nThis decreases the overall network parameters and computational complexity. Additionally, \nSE blocks are employed to mitigate the impact of compression and enhance feature expres-\nsion, while the transformer’s self-attention mechanism captures long-distance dependen -\ncies to improve OSA detection. However, the model’s reliance on pre-defined multi-scale \nconvolutional kernels may not fully adapt to the varying temporal dynamics and feature \nscales present in ECG signals. Liu et al. (2023) propose a CNN-Transformer architecture \nfor OSA detection using single-lead ECG signals. The architecture uses 10 CNN-BN-ReLU \nblocks for dimensional transformation, followed by 2 transformer encoder blocks designed \nto capture temporal dependencies through self-attention. The encoder blocks employ \nMHSA, focusing on global feature extraction. This hybrid approach allows for robust fea -\nture learning and classification, yet the reliance on a fixed 3-minute input window may limit \nadaptability to varying apnea event durations, potentially reducing detection accuracy for \nevents longer than this window. Hu et al. (2023) present a HTM-based personalized transfer \nlearning approach for OSA detection. The HTM architecture captures multiscale features \nwith four parallel convolution branches and utilizes channel attention through SE modules. \nThese features are then processed by two standard transformer blocks to capture temporal \ndependencies and enhance sleep apnea detection. The model also introduces a label map -\nping length (LML) selection strategy, which involves experimenting with different time \nwindows for mapping signal segments to enhance the model’s focus on relevant features \nduring training. Additionally, the fine-tuning strategy is employed to adjust the model’s \nparameters to individual patient data, ensuring better personalization of the model’s predic-\ntions. However, the reliance on SE modules may lead to overemphasizing certain signal fea-\ntures, potentially missing subtle indicators critical for accurate apnea detection. Lastly, Li \net al. (2023) propose a time-frequency information fusion-based CNN-Transformer model \n(TFFormer) for OSA detection using single-lead ECG signals. Unlike standard transformer \narchitectures, the TFFormer introduces a series of specialized modules, including a deep \nresidual shrinkage network (DRSN) for noise reduction, a multiscale convolutional atten -\n1 3\nPage 17 of 42 261\nM. Y. Ansari et al.\nTable 5 Overview of recent advancements in Sleep Apnea (SA) detection using ECG signals\nRefer-\nence \n(Year)\nDataset Core methodology Result Remarks\nWang \net al. \n(2024)\nApnea-\nECG(Penzel et \nal. 2000)\n+\nPrivate Database\n(PSG record-\nings of\n49 males and 13 \nfemailes,\nsampling freq: \n256 Hz)\nResT-ECGAN Sensitivity: 0.957,\nSpecificity: 0.917\nAddresses the lack of data,\nand low data quality by \naugmenting\nthe data with a GAN network\nWei \net al. \n(2024)\nApnea-\nECG(Penzel et \nal. 2000)\nMSAF-Transformer Accuracy: 88.9%,\nSensitivity: 0.844,\nSpecificity: 0.917\nProposes a mutil-scale attentive\nfeature network to extract rich\nlocal and temporal features from\nsingle-lead ECG signals\nHu \net al. \n(2023)\nApnea-ECG \n(Penzel et al. \n2000)\n+\nUCDDB \n(Heneghan \n2011)\nHybrid Transformer\nModel\n(HTM)\nAccuracy: 85.4%,\nAUC: 0.915\nModel performance improved\nwhen the dataset was balanced\nusing a random cropping \nstrategy\nLi et al. \n(2023)\nApnea-ECG \n(Penzel et al. \n2000)\n+\nXJ Dataset (Shi \net al. 2023)\nTFFormer Accuracy: 91.68%,\nSensitivity: \n89.15%,\nSpecificity: \n93.25%,\nF1 Score: 89.11%\nPropose a gated self-attention\nmechanism for time-frequency\ninformation and ECG data \nfusion\nFayyaz \net al. \n(2023)\nNHC Sleep\nData Bank (Lee \net al. 2022)\n+\nCHAT (Redline \net al. 2011)\nCustom\nTransformer\nF1 Score: 83.9,\nROC-AUC: 90.6\nThe model demonstrated the \nhighest\napnea classification performance\nwhen using the combination of\nECG and SpO2 signals, \noutperforming\nall other combinations of the\nsix available PSG signals\nLiu \net al. \n(2023)\nApnea-ECG \n(Penzel et al. \n2000)\nCNNTransformer Accuracy: 88.2%,\nSensitivity: 78.5%,\nspecificity: 94.1 %,\nF1 Score: 89.0,\nAUC: 0.947\nProvides a promising and \nreliable\nsolution for home portable \ndetection\nof OSA\nHu \net al. \n(2022)\nApnea-ECG \n(Penzel et al. \n2000)\nHybrid Transformer\nModel\n(HTM)\nAccuracy: 91%,\nROC-AUC: 0.96,\nSpecificity: \n93.34%,\nSensitivity: \n86.46%,\nF1 Score: 87.47,\nMAE: 2.71,\nMCC: 79.86\nThe model inputs are four typi-\ncal feature\nsequences are directly derived \nfrom\nthe raw ECG data without rely-\ning on\nmanual expert feature extraction\n1 3\n261 Page 18 of 42\nA survey of transformers and large language models for ECG diagnosis:…\ntion (MSCA) module for rich feature extraction, and an adaptive pruning time-frequency \nfusion attention (APTFFA) module. The time-frequency information fusion is achieved \nby separately extracting time-domain and frequency-domain features using self-attention \nmechanisms and then merging these through a gated mechanism that balances the contribu-\ntion of each domain. These modifications enhance the model’s ability to remove redundant \ntokens, effectively combining time- and frequency-domain information for more accurate \nOSA detection. However, a critical limitation of this approach is its dependency on the fixed \nscaling of time- and frequency-domain features, which may restrict the model’s adaptability \nto variations in signal characteristics across different patient populations.\nSome studies have focused on data augmentation techniques and data-fusion based \narchitectures to improve model performance. Fayyaz et al. ( 2023) present a customized \ntransformer-based architecture for detecting OSA, utilizing a novel data representation tech-\nnique to effectively handle polysomnography (PSG) modalities. The model segments sleep \nsignals and electronic health records (EHRs) into equal-length segments, which are then \nsynchronized and tokenized. The tokenizer re-samples evenly spaced time series (like ECG \nand SpO2) and applies interpolation to irregular time series (like R-R intervals from ECG). \nThis processed data is converted into tokens that are fed into a standard transformer encoder \nblock for further analysis. The architecture utilizes five standard transformer encoder blocks \nfor the detection of OSA. However, the model’s reliance on PSG-derived signals may reduce \nits effectiveness in at-home testing scenarios where signal quality is typically lower. Wang \net al. ( 2024) propose a ResT-ECGAN framework for OSA detection, introducing a novel \ncombination of a transformer and ResNet, along with a GAN-based data augmentation tech-\nnique (ECGAN). ECGAN is trained on combined architectures of DCGAN and LSTMs and \nit filters the generated ECG signals by incorporating the concept of fuzziness, effectively \nincreasing the amount of high-quality data. The core architecture, ResT-Net (Li et al. 2018), \nuses a modified ResNet backbone, where standard 3x3 convolutions are replaced with 1D \nconvolutions to reduce computational complexity, followed by a transformer encoder layer \nto capture dependencies between local and global features. The integration of the ECGAN \nfor data augmentation boosts the model’s performance by generating high-quality synthetic \nECG segments, addressing the data scarcity issue. However, the reliance on synthetic data \nmay introduce subtle artifacts that could impact the generalization of the model to real-\nworld data.\n3.3 Myocardial infarction\nTransformer-based models have emerged as powerful tools in the detection of myocar -\ndial infarction (MI) using ECG signals (refer to Table 6). Shan et al. ( 2022) presents a \nhybrid network designed for MI localization using 12-lead ECG signals, combining the \nstrengths of convolutional and transformer architectures. The core innovation lies in inte -\ngrating lightweight depthwise separable convolutions, which reduce computational load, \nwith an enhanced transformer that uses relative position representations. This enhancement \novercomes the traditional transformer’s limitation of losing accuracy when dealing with \nshifted ECG waveforms, thereby making the self-attention mechanism more robust for ECG \nanalysis. The transformer block, positioned after the CNN module, fine-tunes the extracted \nfeatures by focusing on the most critical regions, while the branch attention mechanism \nprioritizes the most informative ECG leads, improving the overall localization accuracy. \n1 3\nPage 19 of 42 261\nM. Y. Ansari et al.\nHowever, the model’s separate processing of each ECG lead may miss crucial inter-lead \nrelationships and dependencies, limiting its adaptability and accuracy in real-world sce -\nnarios with varied lead placements or signal abnormalities. Wahid et al. (2024) implements \na hybrid model combining ResNet and ViT architectures to improve MI detection by lever-\naging both global and local features. The core novelty is found in the modification of the \nstandard ViT, where a slim model incorporates multibranch networks and a channel atten -\ntion mechanism. This modification involved replacing the conventional 16×16 convolution \nfor patch embedding with a series of smaller convolutions, enhancing the richness of the \nextracted features. The hybrid architecture strategically places these blocks to optimize the \nintegration of ResNet’s local features with ViT’s global features, leading to a more compre-\nhensive feature representation. However, the reliance on standard dense layers for feature \nalignment between ResNet and ViT can potentially lead to suboptimal feature integration \ndue to the inherent differences in the feature extraction processes of the two models.\nResNet-based architectures continue to play a crucial role in ECG classification, par -\nticularly in enhancing model performance and convergence. Zhang et al. ( 2023) introduce \nMSFNet, a model that leverages a multi-stage architecture, combining ResNet-18 and trans-\nformer Encoder blocks to improve MI classification from ECG signals. The architecture \nimproves upon standard ResNet by introducing weight sharing, accelerating convergence, \nand boosting performance. A streamlined 6-layer transformer block refines feature extrac -\ntion while minimizing parameters and training time. The Position Attention Module (PAM) \nhighlights and localizes key ECG segments by aggregating spatial features and assigning \nhigher attention weights to abnormal areas, thereby improving classification accuracy. \nHowever, the potential loss of subtle inter-lead relationships in ECG signals due to the \narchitecture’s reliance on separate processing branches, may lead to less accurate MI local-\nization in complex cases.\nTable 6 Overview of recent advancements in myocardial infarction (MI) detection using ECG signals\nRefer-\nence \n(Year)\nDataset \ninformation\nCore \nmethodology\nResult Remarks\nLiu et al. \n(2024)\nPTB (Bousseljot \net al. 1995)\nSRTNet Sensitivity: 99.15%,\nSpecificity: 98.58%\nECG diagnosis by integrating \nscanning,\nreading, and thinking modules\nto mimic a doctor’s analysis\nWahid \net al. \n(2024)\nCustom Dataset\n(1500 cases,\nof different\ntypes ofMI)\nHybrid\nTransformer\nModel\n(HTM)\nSpecificity: 0.96,\nSensitivity: 0.94\nFuses ResNet and ViT\nfeature vectors to create a\nrobust representative\nfeature vector\nZhang \net al. \n(2023)\nPTB-XL (Wagner \net al. 2020)\nMSFNet Sensitivity: 52.14%,\nSpecificity: 77.52%,\nF1 Score: 53.89%\nUses a modified ResNet \narchitecture\nwith weights sharing to speed\nup model convergence\nShan \net al. \n(2022)\nPTB (Bousseljot \net al. 1995)\nMobi-Trans Specificity: 99.91%,\nSensitivity: 99.91%\nDesigned a 12-lead ECG signal\nacquisitiondevice with Wi-Fi\nTransmission for remote \nmonitoring\nLiu et al. \n(2022)\nMITNSR (Gold-\nberger et al. 2000)\n+\nBIDMC (Pimentel \net al. 2016)\nECVT-Net Specificity: 99.96%,\nSensitivity: 99.96%\nInter-patient and intra-patient\nevaluations were conducted,\nalong with anti-noise testing\nusing ECGs of varying quality\nto assess model robustness\n1 3\n261 Page 20 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nCustom network architectures offer specialized solutions for MI detection, enhancing the \ndiagnostic capabilities of ECG-based systems. Liu et al. (2024) presents a novel architec -\nture named SRTNet, designed for MI detection and localization using 12-lead ECG signals. \nThe core novelty lies in the integration of three specialized modules-Scanning, Reading, \nand Thinking-each addressing different aspects of ECG analysis. The architecture signifi -\ncantly modifies standard transformer elements by incorporating large-kernel convolutions \nin the Scanning module and grouped convolutions in the Reading module, enhancing fea -\nture extraction and reducing parameter count. The Thinking module uses a simplified trans-\nformer to extract temporal features, strategically positioned after spatial feature extraction \nto capture comprehensive ECG information. However, a limitation of this approach is the \nunderperformance in MI localization tasks, likely due to the insufficient and imbalanced \ndata used for training, which hinders the model’s ability to generalize effectively across dif-\nferent MI types. Liu et al. (2022) introduces ECVT-Net, a novel architecture that integrates \nCNNs with ViTs for detecting congestive heart failure (CHF) using ECG signals. The core \nnovelty of this work is the combination of the local feature extraction capabilities of CNNs \nwith the global dependency modeling of ViTs. Unlike standard ViT models, the model has \na transition block that splits the CNN-derived feature maps into fixed-size sequences and \napplies a linear transformation before feeding them into the ViT. This modification enhances \nthe model’s ability to capture both short-term and long-term dependencies in the ECG sig -\nnals. Standard transformer blocks are strategically placed after the convolutional layers to \noptimize the integration of local and global features. However, the paper lacks investigation \ninto the interpretability of the model, particularly in understanding how the transformer lay-\ners contribute to decision-making, which is essential for clinical applications.\n3.4 Miscellaneous diagnosis and analysis\nSeveral studies have addressed the task of leveraging transformers for comprehensive CVD \ndiagnosis (refer to Table 7). Vaid et al. (2023) introduce HeartBEiT, a ViT-based designed \nto enhance the diagnostic performance of ECGs, with the application being the detection of \ncardiac conditions such as hypertrophic cardiomyopathy (HCM), low left ventricular ejec -\ntion fraction (EF), and ST-elevation MI. The core novelty lies in its use of masked image \nmodeling (MIM) for pre-training on ECG data, which allows the model to learn from vast \namounts of unlabeled ECGs by treating ECG waveforms as 2D images. The standard ViT \narchitecture is modified by converting ECG signals into 14x14 patches, tokenized using the \nDall-E model. These modifications significantly improve diagnostic accuracy, particularly \nin limited-data scenarios. However, the model relies on accurate patch tokenization; any \ninaccuracies in this process could impair the model’s ability to detect subtle diagnostic fea-\ntures. Similarly, Fu et al. (2024) propose CardioGPT, a novel approach for ECG interpreta-\ntion that integrates a wavelet scattering network having a transformer-based architecture, \ndesigned to generate natural language interpretations of ECGs. The core novelty lies in \nadapting the GPT architecture, traditionally used for text, to interpret 12-lead ECG signals \nby treating them as a sequence of vectors. The architecture uses standard transformer blocks \nspecifically adapted to handle the 3D input variables generated by the wavelet scattering \ntransformation. A limitation of the model is its dependency on the accuracy of wavelet scat-\ntering for feature extraction, which may affect its performance in cases of noise or signal \ndistortion.\n1 3\nPage 21 of 42 261\nM. Y. Ansari et al.\nRecent advancements in transformer-based models have shown significant promise in the \ndetection of CVDs by effectively leveraging multi-modal medical data. Wang et al. ( 2023) \npresent MF-CADNet, a transformer-based multi-feature fusion network designed for the \ndetection of coronary artery disease (CAD) using a combination of ECG, vectrocardiogram \n(VCG), spectrograms, and electronic medical records (EMR). The core novelty of the work \nlies in its integration of multiple data modalities with SeResNet modules handling initial \nfeature extraction and a transformer encoder performing inter-module information fusion. \nTable 7 Overview of recent transformer-based methodologies for detection of various cardiovascular condi-\ntions using ECG signals\nRefer-\nence \n(Year)\nApplication Dataset Core \nmethodology\nResult Remarks\nFu \net al. \n(2024)\nNatural \nlanguage\ninterpreta-\ntions of \nECG\nPrivate Dataset\n(1,128,553 ECG \nreadings\nfrom 754,920 \npatients,\n10 sec, 12 channel,\nsampling rate: 500 \nHz)\nCardioGPT BLEU: 0.68,\nROUGE: 0.78\nThe model builds on the\nContrastiveLanguage\n-Image Pretraining\n(CLIP) model developed\n by OpenAI\nVaid \net al. \n(2023)\nCardiac \ncondition\n diagnosis\nMSHS\nECG\ndataset\n(private) (Vaid et al. \n2023)\nHeartBEiT MI Detection\nAUROC:0.94,\nHCM\nAUROC: 0.92,\nEF: 0.93\nThe model was \npre-trained\non over 8.5 million\nECGs showing\ncapablities to detect \nvarious\ncardiac diseases\nWang \net al. \n(2023)\nCoronary \nArtery\n Disease \nDetection\n(CAD)\nPTB (Bousseljot et \nal. 1995)\n+\nPKUSZ Diagnostic\n CAD Database\n(private) (Wang et \nal. 2023)\nMF-CADNet Sensitivity: \n97.74%,\nSpecificity: \n95.83%\nThe mode incorporates\ninformation from ECG,\nSpectrogram,\nVectrocardiogram (VCG) \nand\nelectronic medical \nrecords\n (EMR) to make accurate\n detection of CAD\nRyu \net al. \n(2023)\nLeft \nVentricular\nHypertro-\nphy\n(LVH)\nPrivate Dataset\n(34,302 subjects\n[19,044 male\n15,258 female \nsubjects],\nover 31 days, \n12-lead,\n10sec long ECG,\nsampling rate:500 \nHz)\nCoAt-Mixer Mean \nsensitivity\n78.37%,\nMean \nSpecificity\n74.04%\nConstructed a learning\nenvironment wherein the\ngender differences\nwere leveraged to better\nclassify LVH\nBehi-\nnaein \net al. \n(2021)\nStress\nDetection\nWESAD (Schmidt \net al. 2018)\n+\nSWELL-KW \n(Koldijk et al. \n2014)\nHybrid\nTransformer\nModel\n(HTM)\nAccuracy: \n91.1%,\nF1 Score: 83.3\nThe model is an \nend-to-end\nnetwork comprising three\nsubnetworks, a \nconvolutional\nsubnetwork, a transformer \nencoder, and a  fully\nconnected (FC) \nsubnetwork\n1 3\n261 Page 22 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nThe transformer architecture in MF-CADNet uses standard MHSA, but these are strate -\ngically placed to combine and extract high-dimensional features from the various input \nmodalities, enhancing the model’s diagnostic accuracy. However, the model is dependent \non the accuracy of the VCG generation from ECG; as any inaccuracies in this conversion \nprocess could negatively impact the overall diagnostic performance. Similarily, Ryu et al. \n(2023) presents CoAt-Mixer, a self-attention-based framework designed for the detection \nof left ventricle hypertrophy (LVH) using ECG. The core novelty of the work lies in uti -\nlizing a hybrid model that integrates MBConv blocks with a CBAM attention module for \nfeature extraction, followed by transformer blocks for capturing long-range dependencies. \nThe modifications, such as replacing the SE module with the CBAM module, help improve \nthe attention mechanism within the convolutional process, enhancing the model’s ability \nto focus on relevant ECG features. A limitation of this approach is the potential oversim -\nplification in handling complex ECG variations, as the model heavily relies on predefined \nconvolutional operations, which might not fully capture subtle yet clinically significant vari-\nations in ECG signals. Behinaein et al. (2021) employs a transformer-based architecture for \nstress detection using ECG signals. The convolutional blocks are specifically tasked with \nextracting spatio-temporal features, which are then enhanced by positional encoding before \nbeing fed into the transformer. The architecture uses standard transformer blocks, includ -\ning MHSA. However, the model’s dependency on fine-tuning with subject-specific data to \nachieve competitive performance may limit its scalability in real-world applications where \nindividual calibration is not feasible.\n3.5 LLMs for ECG analysis\nLLMs have been gaining traction for ECG analysis and diagnosis due to their sophisti -\ncated understanding of natural language, enabling them to merge knowledge from multiple \nsources and expertly interpret ECGs (refer to Table 8). Yu et al. (2023) proposed a zero-shot \nretrieval-augmented diagnosis technique for diagnosing arrhythmia and sleep apnea. The \nfirst stage involves the construction of a vector database of ECG diagnosis books, which \nis used to retrieve relevant diagnostic information based on extracted ECG features (i.e., \ndiagnostic guidance). The diagnostic information is combined with feature prompts and \nfed into LLMs (i.e., LLaMA2 and GPT−3.5) to generate a structured diagnostic output and \nexplanations. One key limitation of this work is that the diagnostic capability of the LLMs \nis constrained by the information derived from ECG textbooks and the handcrafted ECG \nfeatures available in open-source databases. Oh et al. ( 2024) present ECG-QA for training \nand fine-tuning LLMs for ECG analysis. The dataset includes 70 distinct question-answer -\ning templates that can be categorized into two main types: 1) query a single ECG and 2) \ncomparative analysis between two different ECGs. The single ECG questions encompass a \nwide range of attributes, including SCP codes (e.g., identifying first-degree A V block), noise \ntypes (e.g., baseline drift or static noise), stages of infarction, detection of extrasystoles, \nheart axis deviations, and numeric features such as RR interval deviations. The comparative \nquestions, on the other hand, focus on differences between two ECGs, such as resolving \nsymptoms, comparing RR intervals, and other diagnostic changes, facilitating a deeper and \nmore comprehensive ECG analysis. Xu et al. ( 2024) explore the idea of LLMs interacting \nwith IoT sensors and actuators, termed \"Penetrative AI\". The acquired ECG data is down-\nsampled and quantized before being fed to LLM (i.e., ChatGPT), which is guided by a fixed \n1 3\nPage 23 of 42 261\nM. Y. Ansari et al.\nTable 8 Overview of LLM-based methodologies for ECG-based diagnosis and report generation\nRefer-\nence \n(Year)\nApplication Dataset Core \nmethodology\nResult Remarks\nOh \net al. \n(2024)\nECG question\nanswering \ndataset\nfor LLMs\nECG-QA (Oh et \nal. 2023)\nDiverse \ncollection\nof questions \nrelevant\nfor ECG \nanalysis\nTest exact match \naccuracy:\nsingle-verify: 76%\nsingle-choose: \n58.2%\nsingle-query: 40.0\nECG-QA includes \nquestions\nfor comparative \nanalysis\nof two different \nECGs\nXu \net al. \n(2024)\nExplore LLMs\nability to \ninteract\nwith IoT sensor \ndata\nMIT-\nBIH (Moody \nand Mark 2001)\nUtilize LLMs \nfor analyzing\ndown sampled \n&\nMAE (beats/min):\nChatGPT-4 with\nexpert knowledge: \n1.92\nLLMs are capable \nof analyzing ECG\nwaveform changes \n(e.g., heartbeat) \nfrom\n raw downsampled \nECG signals\nYu \net al. \n(2024)\nArrhythmia and\nECG-based \nsubject\ndetection\nCSN (Zheng \net al. 2020)\nMIMIC-IV-\nECG (Gow et \nal. 2023)\nPTB-XL (Wag-\nner et al. 2020)\nFuse clinically \nenhanced ECG\ndescription with \nECG waveform\nfeature for ECG \nanalysis\nand diagnosis\nArrhythmia AUC: \n93.9\nUser-based \nidentification\nAUC: 0.97\n(PTB-XL)\nClinically enhanced \ndescription\nof ECG signal im-\nprove understanding\nof deep learning \nmodels enabling\nbetter diagnosis than \nstandard self-\nsupervised \nmethodologies\nWan \net al. \n(2024)\nECG report \ngeneration\nwith LLMs and \nmultimodal\n instructions\nMIMIC-IV-\nECG (Gow et \nal. 2023)\nPTB-XL (Wag-\nner et al. 2020)\nMultimodal \nECG Instruction\nTuning (MEIT) \nframework\nBLEU-1 \nperformance:\nMistral-Instruc: \n0.714\n(MIMIC-IV-ECG)\nLLaMA-2: 0.515\n(PTB-XL)\nInstruction tuning \nsignificantly\nimproves perfor-\nmance across\nall LLMs and \nmetrics\nLiu \net al. \n(2024)\nECG \nSelf-supervised\nLearning \n(eSSL)\nMIMIC-\nECG (Gow et \nal. 2023)\nPTB-XL (Wag-\nner et al. 2020)\nCPSC2018 (Liu \net al. 2018)\nCSN (Zheng \net al. 2020)\nMulti-\nmodal ECG \nRepresentation\nLearning \n(MERL) \nframework\nwith Clinical \nKnowledge\nEnhanced \nPrompt\nEngineering \n(CKEPE)\nLinear Probing\n(100%) results:\nPTB-XL Super: \n88.67\nPTB-XL Sub: \n84.72\nPTB-XL Form: \n79.65\nPTB-XL Rhythm: \n88.34\nCPSC2018: 90.57\nCSN: 87.95\nEnhancing prompts \nwith clinical\nknowledge is crucial \nfor MERL\noutperforming other \neSSL approaches\nChen \net al. \n(2024)\nHeart failure \nrisk\nprediction\nUK-HYP (Sud-\nlow et al. 2015)\nUK-MI (Sudlow \net al. 2015)\nECG dual \nattention\n network \n(ECG-DAN)\nC-index scores:\nUKB-HYP: \n0.6349,\nUKB-MI: 0.5805\nLLM-informed pre-\ntraining is curcial\nfor risk prediction\nYu \net al. \n(2023)\nZero-shot \narrhythmia\nand sleep apnea \ndiagnosis\nPTB-\nXL(Strodthoff \net al. 2023)\n+\nApnea-ECG-\nPenzel et al. \n(2000)\nLLM-based \nECG diagnosis\nsupported by \nECG\nretrieval-aug-\nmented QA\nAccuracy: 75.7\nMacro Sensitivity: \n79.1\nMacro Specificity: \n61.6\nMacro F1: 66.9\nProposed zero-shot \napproach\noutperforms few-\nshot approches\nand achieves com-\npetitive performance\nto supervised learn-\ning methods\n1 3\n261 Page 24 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nprompt to identify R-peaks. The prompt encodes expert knowledge and directs ChatGPT \nto evaluate the ECG sequence, tasking it to identify significant upward trends in ECG and \nselect the highest points as R-peaks. This method illustrates the potential of LLMs to handle \nreal-time ECG signal processing tasks, such as ECG feature detection and segmentation, \nwithin IoT frameworks. One key shortcoming of this work is that it is confined to detect -\ning basic ECG features and does not extend to identifying more complex patterns, such \nas arrhythmias. Yu et al. ( 2024) learn enhanced ECG representations using a multimodal \ncontrastive pertaining framework. Two core components of this framework include cardio \nquery assistant (CQA) and ECG semantic intergator (ESI). First, CQA constructs a vector \ndatabase of ECG-specific knowledge. When CQA is queried with specific ECG conditions is \nutilizes LLMs to retrieve relevant information, mapping ECG conditions to enriched wave-\nform patterns. Next, the ESI component integrates enhanced ECG explanation (i.e., textual \nprompts) with corresponding ECG signals using a dual-encoder architecture that separately \nprocesses text and ECG signals. subsequently, a cross-modality decoder is employed cap -\ntioning and contrastive losses to align and unify the textual and waveform representations, \nenabling the model to capture nuanced clinical insights essential for arrhythmia diagnosis \nand ECG-based user identification tasks. One shortcoming of this approach is that it solely \nrelies on 10-second ECG signals without accounting for temporal duration variability in the \nreal world. Wan et al. (2024) propose a multimodal ECG instruction tuning (MEIT) frame-\nwork for generating ECG reports using LLMs. Instruction tuning is performed on LLMs \nwith autoregressive objectives, leading to report ECG-based report generation. The MEIT \narchitecture includes an ECG encoder that processes multi-lead ECG data and integrates it \nwith a text-based report generation model, optimized using LoRA (Low-Rank Adaptation). \nExperiments with nine different LLM backbones underscore MEIT’s superior performance, \nrobustness in zero-shot scenarios, and resilience to signal perturbations.\nLiu et al. (2024) introduce a multimodal ECG representation learning (MERL) framework \nutilizing ECG waveform as well as the report. MERL framework employs Cross-Modal \nAlignment (CMA) to align representations between the ECG signals and corresponding \nclinical reports (generated using different encoders), utilizing cross-modal contrastive \nlosses. The framework also incorporates Uni-Modal Alignment (UMA), which applies latent \naugmentation through independent dropout operations on ECG embeddings to prevent pat-\ntern corruption. The authors also propose clinical knowledge-enhanced prompt engineering \n(CKEPE) that generates enhanced prompts by linking LLMs with expert-verified clinical \nknowledge databases. Results show that MERL outperforms other ECG self-supervised \nlearning approaches in zero-shot classification and linear probing tasks. The main limitation \nof this approach is that the use of LLMs for extracting ECG expert knowledge is not a fully \ncontrolled and transparent process. Chen et al. (2024) propose the use of an LLM-informed \nneural network for enhanced heart failure prediction. The proposed ECG-DAN (ECG Dual \nAttention Network) simultaneously captures cross-lead relationships and temporal dynam -\nics within each lead, thereby enhancing feature aggregation. During pretraining, LLM is \nemployed to generate text embeddings for structured reports (i.e., SCP code-based reports), \nwhich are aggregated based on their confidence scores. These aggregated embeddings are \naligned with ECG embeddings using an alignment loss to ensure that the textual and ECG \nrepresentations are closely related. During fine-tuning, encoder pre-trained weights are uti-\nlized to generate ECG embeddings, which are passed through a fully connected network for \n1 3\nPage 25 of 42 261\nM. Y. Ansari et al.\nrisk prediction. One shortcoming of this work is that it discounts the use of metadata (e.g., \nage, sex, noise presence) for generating textual embeddings.\n3.6 Overarching commonalities and limitations\nThis subsection synthesizes the commonalities and limitations of transformer-based and \nLLM-based methodologies for ECG-driven diagnosis, focusing on their architectural \ndesigns and roles within the diagnostic workflow. Transformer-based approaches are pri -\nmarily dictated by the type and preprocessing of ECG data, leading to four principal catego-\nries: (1) representation learning from raw ECG signals using convolutional layers followed \nby MHSA blocks (Hu et al. 2022; Wei et al. 2024). (2) segmentation of raw ECG signals into \nsub-waveforms, also processed through MHSA blocks (Hu et al. 2021; Yang et al. 2022). \n(3) transformation of raw ECG signals into time-frequency representations, such as CWT, \nSTFT, or CT, followed by ViTs (Pratiher et al. 2022). (4) conversion of raw ECG signals into \nimages, subsequently processed by ViTs (Wu et al. 2024). In parallel, LLM-based frame -\nworks for ECG diagnosis are distinguished by the function LLMs serve in the diagnostic \npipeline. These methods can be categorized as: (1) constructing expert knowledge databases \nfrom CVD books and articles and linking them with LLMs, enabling zero-shot diagnoses by \nintegrating ECG features with textual knowledge (Yu et al. 2023). (2) exploiting extensive \ncontextual understanding and long-range dependency capabilities of LLMs to directly ana-\nlyze downsampled raw ECG data for feature extraction (Xu et al. 2024). (3) facilitating mul-\ntimodal learning by aligning textual explanations of ECGs generated by LLMs with ECG \nfeatures derived from CNNs or transformers (Yu et al. 2024). Figure 4 provides a visual rep-\nresentation of these methodologies, highlighting the distinct yet interconnected approaches \nof transformer and LLM-based techniques in advancing ECG-driven diagnostics.\nA common trend in the literature is to innovate within the network stem or transformer \nencoder to address the unique challenges in ECG data. Several studies enhance the feature \nrepresentation before passing them to standard transformer blocks by integrating core mod-\nules from other architectures in the network stem, such as GRUs (Liu et al. 2024), LSTM \nnetworks (Din et al. 2024), and ResNet (Wahid et al. 2024), to refine the feature represen -\ntation of ECG signals processed by the transformer encoder. Additionally, some studies \nintroduce novel loss functions, such as link constraint loss (Che et al. 2021), to enhance the \ndifferentiation between disease classes. On the other hand, some studies have modified the \nself-attention mechanism and the transformer encoder block to enhance the ECG diagnosis \nperformance. To elaborate, Li et al. ( 2023) have proposed the TFFormer, which performs \ntime and frequency information fusion by independently extracting the time and frequency \ndomain features using MHSA, combining them using a gated mechanism accounting for \ncontribution from each domain. Wang et al. (2021) have introduced a heartbeat-aware trans-\nformer which incorporated the heartbeat positions using r-peaks to improve the efficacy of \nthe standard self-attention mechanism. Zhang et al. (2023) have developed MSFNet which \nincorporates the position attention module responsible for localizing key ECG segments and \nassigning higher attention weight to abnormal areas.\nA prominent trend in recent literature is the employment of GANs to address class \nimbalance and to develop lightweight, efficient architectures for ECG analysis. Specifically, \nconvolution-based GANs have been proposed for generating ECG abnormal beats in under-\nrepresented classes, demonstrating their efficacy in augmenting minority class data (Xia \n1 3\n261 Page 26 of 42\nA survey of transformers and large language models for ECG diagnosis:…\net al. 2023). Moreover, the integration of fuzzy logic with one-dimensional GANs has been \nexplored to produce high-quality ECG data for OSA detection (Wang et al. 2024). Concur-\nrently, researchers have focused on optimizing transformer-based methodologies to reduce \ncomputational overhead in ECG-driven diagnostics. For instance, Meng et al. ( 2022) have \nproposed the use of efficient local attention for ECG embedding generation and global light-\nconv attention. Busia et al. ( 2024) have tuned the number of MHSA blocks, ECG embed -\nding size, and number of heads in their architecture to make it compatible with low-power \ndevices with power consumption as low as 0.09 mJ per inference. Shan et al. ( 2022) have \nfocused on minimizing the parameters in the network stem used for generating ECG embed-\nding by using depthwise separable convolutions with SE blocks inspired by MobileNet-V3. \nCollectively, these advancements in network stem design, along with the refinement of ECG \nembedding sizes and MHSA blocks, have significantly advanced transformer-based ECG \nmethods, facilitating their deployment on wearable and IoT devices.\nDespite the advancements in transformer-based methods for ECG diagnosis, several lim-\nitations persist, specifically in the areas of ECG embeddings, positional encodings, and the \ndesign of the MHSA block. Several methodologies rely on representation learning through \nconvolutional layers to generate ECG embeddings. However, whether these embeddings \neffectively distinguish between different ECG classes within the embedding space remains \nunclear. This ambiguity may cause a performance bottleneck as a poorly defined embedding \nspace can severely limit the ability of MHSA blocks to optimize performance across diag -\nnostic classes. Furthermore, most current approaches employ standard sinusoidal positional \nencodings originally designed for the NLP tasks. While the standard encoding is effective in \ncapturing the sequence of positions in linear data, it may not be well-suited for the specific \nrequirements of ECG signals. ECG signals are characterized by repetitive structures, such \nas the P-wave, QRS complex, and T-wave, across successive heartbeats. A more tailored \npositional encoding can help the model to link similar structures across different beats (e.g., \nP-waves) while still recognizing the temporal order of beats. Without such an encoding, \nthe model may struggle to effectively leverage the recurring patterns in ECG waveforms, \npotentially impairing its ability to accurately capture the temporal and morphological details \nessential for diagnosis. Additionally, many existing methodologies often utilize standard \nMHSA blocks, developed primarily for NLP applications. This approach may not fully align \nwith the unique properties of ECG signals, such as the slight variations in repetitive beat \nFig. 4 Overview of ECG-driven diagnosis methods using transformer-based and LLM-based approaches\n \n1 3\nPage 27 of 42 261\nM. Y. Ansari et al.\nwaveforms, potentially leading to overfitting and limiting the model’s ability to accurately \ninterpret waveform duration and morphology. Moreover, ECG diagnosis benefits from a \nmulti-perspective analysis, where information from multiple leads is integrated to form a \ncomprehensive understanding of cardiac electrical activity. However, the standard MHSA \nlacks a structured, dedicated approach to handle these specific requirements, further limiting \nits effectiveness in ECG signal processing.\nLLM-based methodologies for ECG analysis face significant limitations related to gener-\nalizability, reliance on predefined data sources, and adaptability to real-world clinical vari -\nability. One key issue is the over-reliance on existing ECG literature (e.g., textbooks and \nacademic articles) for crafting expert databases without accounting for bias and errors, rais-\ning concerns over the correctness of the final predicted diagnosis/outcome. Another essen -\ntial concern of LLM-based methods is the lack of transparency and fact-checking while \nextracting expert knowledge from ECG vector databases, raising doubts about the reliabil -\nity and interpretability of the clinical insights generated. Furthermore, many LLM-based \napproaches ignore critical metadata, such as patient demographics and noise presence, dur-\ning the construction of textual embeddings. Given the genetic underpinning of ECG sig -\nnals and their variation with age and gender, this could lead to significant oversights in the \nmodel’s predictions across different demographics and populations. Collectively, these limi-\ntations underscore the need for more adaptive, transparent, and context-aware approaches \nthat can effectively accommodate the inherent complexity and variability of ECG data in \nclinical settings.\n4 Discussion\nThis section discusses data and architectural enhancements needed to improve the state-\nof-the-art transformer and LLM techniques in ECG diagnosis and analysis. Furthermore, it \nprovides potential directions to overcome existing shortcomings of LLMs.\n4.1 Data enhancements and architectural innovations\n4.1.1 Self-supervised and unsupervised ECG representation learning\nRecently, novel approaches have been proposed in various domains for enhancing the qual-\nity of data embeddings that are subsequently fed to the MHSA blocks within the transformer \nencoder. Zerveas et al. ( 2021) propose an unsupervised pretraining setup for enhancing \nembedding for multi-variate time series representation learning. To elaborate, a proportion r \nof each variable sequence within the input is independently masked. The model’s objective \nduring this pretraining phase is to predict the complete input vectors from the masked input \nsequences. The predictions on the masked values are then evaluated using a mean squared \nerror (MSE) loss, which guides the optimization of the model’s parameters to enhance the \nfidelity of the learned representations. This pretraining strategy is crucial for developing \nrobust embeddings, as it forces the model to capture essential temporal dependencies and \nfeature interactions within the data, despite the presence of noise and missing information. \nAnother work by Li et al. (2021) also capitalizes on the pertaining for enhancing the embed-\nding quality for ViTs. Specifically, the authors first demonstrate that sparse self-attention \n1 3\n261 Page 28 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nhampers the ability of the model to capture fine-grained dependencies among the image \npatches. To compensate for this shortcoming, the authors propose a region-matching pre -\ntraining task that forces the model to accommodate the fine-grained dependencies of the \npatches within the embeddings, thereby improving the quality of learned representations. \nThis approach can be adopted for transformer-based methods working with images of ECG \nbeats to learn dependencies between the different sub-waveforms (e.g., p-wave and QRS \ncomplex). Wu et al. ( 2024) propose the use of self-supervised learning using a set of sig -\nnal transformations as the pretext task to learn robust, modality-invariant representation of \nsignals. Specifically, permutation, time-warping, noise addition, magnitude-warping, and \ncropping transformations are used to enhance the signal representations/embeddings. In the \ncontext of ECG signals, signal transformation pertaining tasks can be used as an effective \nalternative to other data augmentation techniques (e.g., GANs) to learn distinctive ECG \nembeddings corresponding to minority classes. Eldele et al. (2021) introduce temporal con-\ntextual contrastive learning for enhanced representation of time series signals. Specifically, \nin temporal contrastive learning, a strongly augmented version of the data is used to predict \nfuture timesteps of a weakly augmented version, and vice versa. Subsequently, in contextual \ncontrastive learning, the model maximizes the similarity between matching contexts from \nthe two different augmented views and minimizes the similarity with contexts derived from \nother samples in the batch. Consequently, this framework can be employed to generate ECG \nembeddings as an alternative to the CNN-based network stem. Zhang et al. (2023) propose a \nrepresentation learning framework using a cross-reconstruction transformer. First, the time \nseries data is transformed into the frequency domain to calculate magnitude and phase com-\nponents. These data components are then segmented into patches and some patches are \nrandomly dropped. The generated embeddings from time, magnitude, and phase modalities \nare passed to a cross-domain transformer encoder, which integrates information across the \ndomains. During pretraining, the cross-domain representations are passed to a transformer \ndecoder for reconstructing the original time series, magnitude, and phase data, facilitat -\ning robust representation learning. For downstream tasks, the model condenses the cross-\ndomain embeddings into compact representations, optimizing them for further applications \nsuch as classification.\nAltogether, these unsupervised and self-supervised pretraining strategies ranging from \nmasked input reconstruction, region matching, signal transformations, temporal and con -\ntextual contrastive learning, and cross-domain reconstruction can provide sophisticated and \nenriched ECG embeddings suitable for MHSA blocks.\n4.1.2 Enhanced positional encoding\nECG signals exhibit recurring morphology across successive heartbeats. Implementing a \nspecialized positional encoding can enhance the model’s ability to associate/link analo -\ngous structures (e.g., P-waves) across different heartbeats while preserving the temporal \nsequence of beats. The conventional sinusoidal positional encoding lacks flexibility, as it is \nmanually parameterized and lacks learnable parameters. Furthermore, this positional encod-\ning strategy limits the maximum length of the input sequence. Liu et al. ( 2020) propose \nFLOATER, which encodes positional information via a continuous dynamical model in a \ndata-driven and parameter-efficient manner. Consequently, the continuous dynamic model \nallows the transformer to handle variable length inputs. This approach can allow ECG-\n1 3\nPage 29 of 42 261\nM. Y. Ansari et al.\nbased transformers to work with varying sampling rate signals, enhancing their applicabil -\nity in healthcare settings. Ke et al. ( 2020) demonstrate that absolute positional encoding \n(e.g., sinusoidal encoding) when added to data embeddings brings mixed correlations due to \ntwo different heterogeneous sources. Consequently, the authors propose a transformer with \nuntied positional encoding (TUPE) that separately computes word contextual correlation \nand positional correlation with different parameterizations and then adds them together. \nFurthermore, TUPE makes the ’CLS’ token positionless in the relative positional encoding \nmatrix, enabling the capture of global information. Subsequently, the modifications made in \nTUPE can be employed for ECG positional encoding to capture relative positions of ECG \nsub-waveforms (e.g., p-wave) across beats and minimize mixed correlation between posi -\ntional and ECG information. recently Su et al. (2024) proposed a rotary position embedding \n(RoPE), which encodes the relative position of tokens by multiplying the context repre -\nsentations with a rotation matrix. RoPE enables the decay of inter-token dependency with \nincreasing relative distances and enables relative positional encoding for linear self-atten -\ntion. Given these properties of RoPE, it can be employed for ECG-based transformers to \nbetter capture the context within ECG sub-waveforms, such as the QRS complex. However, \nthe nature of decay in RoPE may need to be adjusted depending on the CVD diagnosis \ntask. For instance, rhythm-based abnormalities span over multiple cardiac beats and may \nrequire a slow decay to effectively capture information about the underlying arrhythmia. In \ncontrast, beat-based abnormalities can adopt a modified RoPE with a faster decay of inter-\ntoken dependency.\nOverall, these innovations in positional encodings, involving learnable encodings (Ken-\nton et al. 2019; Lan et al. 2019; Clark et al. 2020), separate position parametrization (Ke \net al. 2020), relative position encoding (Dai et al. 2019; Huang et al. 2020; Raffel et al. \n2020), and rotary transformations (Su et al. 2024) could play a significant role in enhancing \ntransformer-based ECG diagnosis methodologies.\n4.1.3 Custom self-attention mechanisms\nStandard self-attention computes the weights of each sequence element with every other \nelement. This calculation can be computationally expensive for long sequences (e.g., high \nsampling rate ECG or long duration ECG) and may also lead to overfitting due to repetitive \nstructure ECG waveform. Consequently, custom sparse self-attention (Child et al. 2019) can \nbe employed to minimize computations and resolve overfitting.  Guo et al. (2019) introduce \nthe Starformer, a model inspired by star-shaped weight computation among sequence ele -\nments. Specifically, Starformer emphasizes weights between adjacent elements while dis -\ncounting relationships between distant elements, a mechanism known as band attention. \nAdditionally, it computes attention weights between a central, influential element within the \nsequence (the star node) and all other elements, referred to as global attention. This self-\nattention topology is particularly relevant for beat abnormality analysis in ECG data, with \npotential for further refinement. For instance, the neighborhood defined by band attention \ncould be adapted to focus on specific waveform segments, such as the p-wave. Furthermore, \nthe R-peak could be designated as the star node, enabling the model to capture relation -\nships between ECG sub-waveforms and the central R-peak. This approach could potentially \nenhance beat abnormality detection while reducing computational complexity. Beltagy et al. \n(2020) present the Longformer, an extension of the Starformer that generalizes its approach \n1 3\n261 Page 30 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nby incorporating band attention for capturing local dependencies and allowing for mul -\ntiple global attention elements within a sequence. This architecture holds potential for the \nefficient analysis of multi-beat ECG signals, where the R-peak of each beat could serve \nas a global attention element, facilitating the detection of rhythmic abnormalities, such as \narrhythmias. Moreover, the Longformer can be further enhanced by replacing band atten -\ntion with block attention, which computes the weights between elements within a defined \npatch or block (e.g., an ECG beat). Subsequently, the relationships between these blocks \ncan be captured using global attention, with each beat potentially having multiple global \nattention nodes (e.g., the P-wave peak, R-peak, or T-wave peak). Another crucial modifica-\ntion of self-attention that could improve the performance of transformers for ECG analysis \nis self-attention priors. Guo et al. (2019) demonstrate that dependencies in text can be more \neffectively captured when the importance of neighboring tokens is emphasized while the \ninfluence of distant tokens is diminished. To achieve this, they propose the Gaussian trans-\nformer, which realigns self-attention scores using a modified Gaussian prior. This approach \ncan be similarly applied to ECG waveforms, where Gaussian priors can focus on specific \nwaveforms, such as the P-wave, to compute wave-focused features. Subsequent encoder \nlayers can then integrate these wave-specific features, enhancing the accuracy of ECG diag-\nnosis. A mathematical formulation of integration of priors is as follows:\n \nScores = softmax\n(\nα · QK⊤\n√dk\n+ (1− α) · P\n)\nV  (5)\nHere, P represents the prior matrix and α is the weight controlling the contribution of the \nprior.\nTo enhance the computational efficiency of transformer-based models for real-time \nECG monitoring, optimizations can be introduced within the self-attention mechanism \nand in the overall architectural design. Within the self-attention block, computational cost \ncan be significantly reduced by employing sparse attention (Child et al. 2019), approxi-\nmate attention (Wang et al. 2020), or attention-free (Poli et al. 2023) mechanisms. Sparse \nattention (Child et al. 2019) selectively attends to a subset of tokens rather than all tokens, \nreducing the computational complexity. Approximate attention (Wang et al. 2020) further \nreduces the computational burden by using low-rank factorization or kernel-based methods \nto approximate the attention matrix, maintaining performance while improving efficiency. \nAttention-free (Poli et al. 2023) mechanisms, such as gated convolutions or linearized \nattention, eliminate the quadratic complexity of traditional self-attention, making real-time \ninference more feasible. Beyond self-attention, the overall transformer architecture can be \noptimized by replacing the standard feed-forward network (FFN) with a mixture-of-experts \n(MoE) approach (Fedus et al. 2022), where a learned router directs inputs to specialized \nsmaller FFNs, activating only a subset of parameters per inference step. In addition, early \nexit mechanisms can be introduced at multiple depths (Xin et al. 2020), allowing confident \npredictions to bypass deeper layers, reducing inference latency while maintaining accuracy. \nTogether, these modifications improve the real-time applicability of transformer-based ECG \nanalysis in clinical settings.\n1 3\nPage 31 of 42 261\nM. Y. Ansari et al.\n4.2 Overcoming shortcomings of LLMs in ECG Diagnosis\nTwo critical challenges hindering the widespread adoption of LLMs in healthcare settings \nare the issue of hallucination and the absence of reliable metrics to assess the confidence \nof LLM-generated responses. Hallucination in the context of LLMs refers to the genera -\ntion of outputs that are factually inaccurate, fabricated, or not grounded in the input data or \nreal-world context. This phenomenon can significantly hinder diagnostic accuracy, as hal -\nlucinated information can mislead medical professionals, especially when integrated into \nclinical decision support systems. Particularly, hallucinations are concerning in high-stakes \nenvironments pertaining to diagnosis, treatment planning, and patient outcomes. These erro-\nneous generations can also introduce biases into downstream tasks, potentially amplifying \nrisks in automated healthcare workflows. Dziri et al. ( 2022) demonstrate that lack of rel -\nevant factual data and repeated data are the main causes of LLM hallucination. Hernandez \net al. (2022) show that the performance of large LLMs decreases to their counterparts with \nnearly half the parameters by introducing 10% redundant data in the training set. Recently, \nZhou et al. ( 2024) compare the relative importance of unsupervised pretraining versus \ninstruction tuning and reinforcement learning. Their findings indicate that the majority of \nknowledge in LLMs is acquired during the pretraining phase, with only minimal instruction \ntuning data required to guide models in generating high-quality outputs. Given the findings \nof Dziri et al. (2022) and Hernandez et al. (2022) on hallucination, as well as the importance \nof pretraining highlighted by Zhou et al. (2024), it can be concluded that a large-scale ECG \ncorpus should be developed from scratch. Specifically, this corpus should comprehensively \ncover the underlying physics of ECG signals, the interpretation of ECG waveforms and \nleads, clinically relevant ECG features and their thresholds for age groups, and the ECG \ndiagnosis knowledge base of expert electrophysiologists, while minimizing data redundan-\ncies to reduce the risk of hallucinations.\nLLMs tend to be overconfident in their responses and can be influenced to reflect the \ndemands of users through repeated prompting. This can be a significant drawback in clinical \nsystems as medical practitioners do not have established techniques to quantify the confi -\ndence of LLM’s response. Uncertainty quantification (UQ)  is an emerging research area \nthat aims to understand the reliability and limitations of LLMs (Zhao et al. 2024).  Xiong \net al. (2024) propose a consistency-based uncertainty estimation approach, which involves \ninducing randomness during the answer generation phase or introducing misleading hints \nin the prompt to assess whether the LLM’s response varies. If the model’s response remains \nconsistent despite these variations, it can be inferred that the model is more confident in \nits output. Alternatively, Duan et al. ( 2024) combine the token level uncertainties in the \npredicted response to quantify the overall uncertainty in the LLMs. Specifically, the authors \npropose shifting attention to relevant (SAR) that focuses on the most meaningful tokens and \nsentence components, rather than treating all tokens as equally important, thereby provid -\ning more accurate uncertainty assessments. These UQ approaches have to be integrated \ninto LLM methodologies for ECG analysis and diagnosis to enhance transparency. Subse -\nquently, UQ could lay the foundation for integrating LLM-driven ECG systems in clinics \nand hospitals.\n1 3\n261 Page 32 of 42\nA survey of transformers and large language models for ECG diagnosis:…\n4.3 Federated learning for resource-constrained environments, scalability, and \npatient privacy\nFederated learning (FL) is a decentralized learning framework that enables collaborative \nmodel training across multiple devices without requiring raw data exchange, making it \nparticularly well-suited for resource-constrained healthcare settings. Conventionally, neu -\nral networks and LLMs require centralized data aggregation, which is often infeasible in \nclinical environments due to strict patient privacy regulations and limited infrastructure \nin under-resourced hospitals. In the context of ECG-based disease diagnosis, FL facili -\ntates the development of robust, generalizable models by leveraging heterogeneous data \ndistributions across diverse patient populations while ensuring that sensitive ECG signals \nremain confined to local hospital systems. Consequently, FL can be a key learning paradigm \nfor deploying LLMs for ECG-based diagnosis in resource-constrained environments. Xu \net al. ( 2023) propose an FL-based framework that integrates differential privacy (DP) to \nensure formal privacy guarantees. A fundamental challenge in applying DP to FL is that the \nrequired noise magnitude increases with model size, often leading to degraded convergence. \nTo mitigate this issue, the authors introduce Partial Embedding Updates (PEU), a strategy \nthat selectively updates only a subset of model embeddings, thereby reducing the payload \nsize and limiting the impact of DP noise on training stability. Furthermore, to address the \ncomputational constraints, the methodology incorporates Low-Rank Adaptation (LoRA) to \noptimize parameter efficiency and Noise Contrast Estimation (NCE) to minimize memory \noverhead. While federated learning ensures privacy-preserving training, it does not inher -\nently reduce model size, leading to high inference latency, excessive memory demands, \nand communication overhead. To address these limitations,  Yao et al. (2025) propose Fed-\nSpine, a framework that integrates PEFT with a structured pruning approach to enable the \ndeployment of LLMs in resource-constrained environments. FedSpine employs an iterative \nprocess of pruning and fine-tuning, progressively reducing model complexity while main -\ntaining task performance. Additionally, to account for the heterogeneous computing and \ncommunication capacities of different edge devices, the framework leverages a multi-armed \nbandit (MAB) algorithm to adaptively determine optimal pruning ratios and low-rank adap-\ntation (LoRA) ranks for each device.\nFL supports scalability in ECG-based diagnosis by enabling hospitals, as decentralized \nnodes, to incrementally contribute to model improvements without requiring a centralized \ndata repository. As participating hospitals increase, the system scales efficiently by lever -\naging parallel updates from multiple institutions. Beyond just node scalability, federated \nlearning also supports data scalability, allowing models to generalize across hospitals with \ndiverse patient populations and ECG acquisition conditions. Computational scalability is \nmaintained by optimizing model pruning and adaptation per node, ensuring that even low-\nresource hospitals and edge devices can participate without excessive computational over -\nhead. Additionally, communication scalability is preserved through asynchronous updates \nand hierarchical aggregation, minimizing network congestion as the system expands. These \nscalability mechanisms collectively enable federated learning to support large-scale, real-\nworld deployment of LLM-based ECG diagnosis across diverse healthcare infrastructures.\nIn summary, FL offers a viable solution for deploying LLMs in ECG-based disease diag-\nnosis in resource-constrained environments by preserving patient privacy across hospitals \nthrough differential privacy mechanisms and mitigating computational and memory over -\n1 3\nPage 33 of 42 261\nM. Y. Ansari et al.\nhead via structured pruning, iterative fine-tuning, and parameter-efficient adaptation tech -\nniques such as PEFT.\n4.4 Dataset considerations for large language models in ECG analysis and \ndiagnosis\nWith the advent of LLMs, new tasks related to ECG have emerged, such as ECG caption -\ning, ECG report generation, and multimodal ECG diagnosis, which were not previously \nexplored with standard convolutional networks or transformer-based architectures. Prior \nreviews have comprehensively studied existing datasets for ECG disease diagnosis using \nCNNs (Ansari et al. 2023). However, key challenges remain regarding dataset bias, quality, \nand diversity, particularly for LLM-based ECG analysis.\nCurrent approaches in multimodal ECG learning generally fall into two categories: (1) \nleveraging existing metadata, such as SCP codes or machine-generated diagnostic reports, \nfor contrastive learning to enhance ECG-text representations, and (2) retrieval-augmented \ngeneration (RAG) methods, where LLMs are supplemented with external knowledge bases. \nMost publicly available datasets for these tasks, including PTB-XL (predominantly repre -\nsenting the German population), MIMIC-IV , and Chapman-Shaoxing (primarily covering \nChinese populations), lack diversity in Middle Eastern, South Asian, and African popula -\ntions. This raises concerns about model generalizability, as ECG morphology is influenced \nby genetic and demographic factors. Additionally, while RAG-based methods enhance zero-\nshot ECG diagnosis by integrating external databases, the clinical reliability of these data -\nbases remains uncertain. Although they may be sourced from reputable repositories, their \npopulation coverage can introduce biases, potentially limiting the model’s performance.\nAnother challenge pertains to preprocessing and encoding strategies for ECG metadata. \nDifferent studies have adopted varied encoders to transform textual ECG metadata into \nfeature representations for contrastive learning. However, there is no consensus on the most \neffective encoding framework, leading to inconsistencies in how textual information is \nincorporated into multimodal models. Establishing standardized methodologies for encod -\ning ECG metadata is critical for ensuring reproducibility and improving model robustness.\n5 Conclusion\nThe manuscript provides a comprehensive survey of transformer-based methodologies \nand their evolution into LLMs for ECG analysis and diagnosis. The reviewed studies are \nsystematically categorized according to the complexity of disease diagnosis, spanning sin -\ngle-beat to multi-beat scenarios. A key contribution is the detailed analysis of overarch -\ning patterns and limitations, which reveals that CNNs are predominantly utilized for ECG \nrepresentation learning, GANs for data augmentation, and standard MHSA blocks as the \npreferred choice for capturing temporal dependencies. Notable limitations include a lack \nof novel ECG representation techniques, insufficient positional encoding formulations, \nand the absence of task-specific self-attention structures. For LLMs, limitations include \nlimited generalizability, dependency on unverified pre-existing databases, and insufficient \nmechanisms for transparency and fact-checking. Based on these findings, the discussion \nintroduces promising future directions focusing on enhanced ECG representation, refined \n1 3\n261 Page 34 of 42\nA survey of transformers and large language models for ECG diagnosis:…\npositional encodings, custom self-attention structures, and strategies to mitigate hallucina -\ntions and improve confidence estimation in LLMs. Additionally, future work will require \nclose collaboration between machine learning experts and clinical practitioners to ensure \nthat LLM-derived ECG diagnosis aligns with real-world clinical workflows and decision-\nmaking processes. Effective deployment will depend on integrating domain knowledge into \nmodel training and validating LLM-driven insights with expert feedback. Furthermore, the \nregulatory approval process for LLM-based medical diagnosis remains a critical challenge. \nEstablishing standardized evaluation frameworks, demonstrating model robustness across \ndiverse populations, and addressing ethical concerns related to LLM-driven healthcare deci-\nsions will be essential for widespread adoption.\nFunding Open Access funding provided by the Qatar National Library.\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International License, \nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as \nyou give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons \nlicence, and indicate if changes were made. The images or other third party material in this article are \nincluded in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. \nIf material is not included in the article’s Creative Commons licence and your intended use is not permitted \nby statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the \ncopyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\nGustafsson S, Gedon D, Lampa E, Ribeiro AH, Holzmann MJ, Schön TB, Sundström J (2022) Development \nand validation of deep learning ecg-based prediction of myocardial infarction in emergency department \npatients. Sci Rep 12(1):19615\nvan Klei WA, Bryson GL, Yang H, Kalkman CJ, Wells GA, Beattie WS (2007) The value of routine preop-\nerative electrocardiography in predicting myocardial infarction after noncardiac surgery. Annals of surg \n246(2):165–170\nMilstein NS, Musat DL, Allred J, Seiler A, Pimienta J, Oliveros S, Bhatt AG, Preminger M, Sichrovsky T, \nShaw RE et al (2020) Detection of atrial fibrillation using an implantable loop recorder following cryp-\ntogenic stroke: implications for post-stroke electrocardiographic monitoring. J Int Card Electrophys \n57:141–147\nBouzid Z, Al-Zaiti SS, Bond R, Sejdić E (2022) Remote and wearable ecg devices with diagnostic abilities in \nadults: a state-of-the-science scoping review. Heart Rhythm 19(7):1192–1201\nHa AC, Verma S, Mazer CD, Quan A, Yanagawa B, Latter DA, Yau TM, Jacques F, Brown CD, Singal RK et \nal (2021) Effect of continuous electrocardiogram monitoring on detection of undiagnosed atrial fibril -\nlation after hospitalization for cardiac surgery: a randomized clinical trial. JAMA Netw Open 4(8):e2 \n121 867-e2 121 867\nDickinson DF (2005) The normal ecg in childhood and adolescence. Heart 91(12):1626–1630\nRijnbeek PR, Van Herpen G, Bots ML, Man S, Verweij N, Hofman A, Hillege H, Numans ME, Swenne CA, \nWitteman JC et al (2014) Normal values of the electrocardiogram for ages 16–90 years. J Electrocard \n47(6):914–921\nKumari L, Sai YP et al (2022) Classification of ecg beats using optimized decision tree and adaptive boosted \noptimized decision tree. Sig, Image and Video Process 16(3):695–703\nMert A, Kılıç N, Akan A (2014) Evaluation of bagging ensemble method with time-domain feature extraction \nfor diagnosing of arrhythmia beats. Neural Compt Appl 24:317–326\nShi H, Wang H, Huang Y , Zhao L, Qin C, Liu C (2019) A hierarchical method based on weighted extreme \ngradient boosting in ecg heartbeat classification. Comp Methods and Prog Biomed 171:1–10\nRashed-Al-Mahfuz M, Moni MA, Lio’ P, Islam SMS, Berkovsky S, Khushi M, Quinn JM (2021) Deep \nconvolutional neural networks based ecg beats classification to diagnose cardiovascular conditions. \nBiomed Eng Lett 11:147–162\n1 3\nPage 35 of 42 261\nM. Y. Ansari et al.\nMakimoto H, Höckmann M, Lin T, Glöckner D, Gerguri S, Clasen L, Schmidt J, Assadi-Schmidt A, Bejinariu \nA, Müller P et al (2020) Performance of a convolutional neural network derived from an ecg database \nin recognizing myocardial infarction. Sci Rep 10(1):8445\nKarthiga M, Santhi V , Sountharrajan S (2022) Hybrid optimized convolutional neural network for efficient \nclassification of ecg signals in healthcare monitoring. Biomed Sig Process Control 76:103731\nPeng H, Chang X, Yao Z, Shi D, Chen Y (2024) A deep learning framework for ecg denoising and classifica-\ntion. Biomed Sig Process Control 94:106441\nJi C, Wang L, Qin J, Liu L, Han Y , Wang Z (2024) Msgformer: a multi-scale grid transformer network for \n12-lead ecg arrhythmia detection. Biomed Sig Process Control 87:105499\nWang Z, Pan X, Mei Z, Xu Z, Lv Y , Zhang Y , Guan C (2024) Ecgan-assisted rest-net based on fuzziness for \nosa detection. IEEE Trans Biomed Eng 71(8):2518–2527\nLiu K, Liu T, Wen D, Zang M, Zhou S, Liu C (2024) Srtnet: Scanning, reading, and thinking network for \nmyocardial infarction detection and localization. Expert Systems with Applications 240:122402\nQiu J, Zhu J, Liu S, Han W, Zhang J, Duan C, Rosenberg MA, Liu E, Weber D, Zhao D (2023)“Automated \ncardiovascular record retrieval by multimodal learning between electrocardiogram and clinical report,” \nin Proceedings of the 3rd Machine Learning for Health Symposium ser. Proceedings of Machine Learn-\ning Research, (225), 480–497\nThapa S, Howlader K, Bhattacharjee S et al. (2024) “More: Multi-modal contrastive pre-training with trans-\nformers on x-rays, ecgs, and diagnostic report,” arXiv preprint arXiv:2410.16239\nGuo M, Zhou Y , Tang S (2024) “Multimodal models for comprehensive cardiac diagnostics via ecg inter -\npretation,” in 2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE, \npp. 5756–5763\nYu H, Guo P, Sano A (2023) “Zero-shot ecg diagnosis with large language models and retrieval-augmented \ngeneration,” in Proceedings of the 3rd Machine Learning for Health Symposium , ser. Proceedings of \nMachine Learning Research, vol. 225, 10 Dec, pp. 650–663\nChua CE, Clara NLY , Furqan MS, Kit JLW, Makmur A, Tham YC, Santosa A, Ngiam KY (2024) “Integra-\ntion of customised llm for discharge summary generation in real-world clinical settings: a pilot study on \nrussell gpt,” The Lancet Regional Health–Western Pacific, vol. 51\nGallifant J, Afshar M, Ameen S, Aphinyanaphongs Y , Chen S, Cacciamani G, Demner-Fushman D, Dligach \nD, Daneshjou R, Fernandes C et al. (2025) “The tripod-llm reporting guideline for studies using large \nlanguage models,” Nature Medicine, pp. 1–10\nHan C, Zhou Y , Que W, Li Z, Shi L (2024) “An overview of algorithms for myocardial infarction diagnostics \nusing ecg signals: Advances and challenges,” IEEE Transactions on Instrumentation and Measurement,\nMaron BJ, Desai MY , Nishimura RA, Spirito P, Rakowski H, Towbin JA, Rowin EJ, Maron MS, Sherrid MV \n(2022) Diagnosis and evaluation of hypertrophic cardiomyopathy: jacc state-of-the-art review. J Am \nColl Cardiol 79(4):372–389\nEbrahimi Z, Loni M, Daneshtalab M, Gharehbaghi A (2020) A review on deep learning methods for ecg \narrhythmia classification. Exp Syst with Appl: X 7:100033\nDehkordi NR, Dehkordi NR, Toudeshki KK, Farjoo MH (2024) Artificial intelligence in diagnosis of long \nqt syndrome: a review of current state, challenges, and future perspectives. Mayo Clin Procee: Digit \nHealth 2(1):21–31\nSalari N, Hosseinian-Far A, Mohammadi M, Ghasemi H, Khazaie H, Daneshkhah A, Ahmadi A (2022) \nDetection of sleep apnea using machine learning algorithms based on ecg signals: a comprehensive \nsystematic review. Exp Syst Appl 187:115950\nLiu X, Wang H, Li Z, Qin L (2021) Deep learning in ecg diagnosis: a review. Knowl-Based Syst 227:107187\nNezamabadi K, Sardaripour N, Haghi B, Forouzanfar M (2022) Unsupervised ecg analysis: a review. IEEE \nRev Biomed Eng 16:208–224\nAnsari MY , Qaraqe M, Righetti R, Serpedin E, Qaraqe K (2024) Enhancing ecg-based heart age: impact of \nacquisition parameters and generalization strategies for varying signal morphologies and corruptions. \nFront Cardiovas Med 11:1424585\nWasimuddin M, Elleithy K, Abuzneid A-S, Faezipour M, Abuzaghleh O (2020)“Stages-based ecg signal \nanalysis from traditional signal processing to machine learning approaches: A survey,” IEEE Access, \n(8), 177 782–177 803\nAnsari MY , Qaraqe M, Charafeddine F, Serpedin E, Righetti R, Qaraqe K (2023) “Estimating age and gender \nfrom electrocardiogram signals: A comprehensive review of the past decade,” Artificial Intelligence in \nMedicine, p. 102690\nYokota A, Kabutoya T, Hoshide S, Kario K (2021) Automatically assessed p-wave predicts cardiac events \nindependently of left atrial enlargement in patients with cardiovascular risks: the japan morning surge-\nhome blood pressure study. J Clin Hypertension 23(2):301–308\n1 3\n261 Page 36 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nRasmussen MU, Kumarathurai P, Fabricius-Bjerre A, Larsen BS, Domínguez H, Davidsen U, Gerds TA, \nKanters JK, Sajadieh A (2020) P-wave indices as predictors of atrial fibrillation. Annals of Noninvasive \nElectrocard 25(5):e12751\nWu S, Cai M, Zheng R, Wang S, Jiang L, Xu L, Shi R, Xiao F, Ellenbogen KA, Cha Y et al (2021) Impact of \nqrs morphology on response to conduction system pacing after atrioventricular junction ablation. ESC \nHeart Failure 8(2):1195–1203\nPelliccia A, Tatangelo M, Borrazzo C, Zampaglione D, Mango F, Fedele E, Lanzillo C, Martino A, Crescenzi \nC, Maestrini V et al (2023) Low qrs voltages and left ventricular hypertrophy: a risky association. Eur \nJ Prev Cardiol 30(11):1132–1138\nLuo G, Li Q, Duan J, Peng Y , Zhang Z (2020) The predictive value of fragmented qrs for cardiovascular \nevents in acute myocardial infarction: a systematic review and meta-analysis. Front Phys 11:1027\nLi R, Zhao X, Gong Y , Zhang J, Dong R, Xia L (2021) A new method for detecting myocardial ischemia \nbased on ecg t-wave area curve (twac). Front Phys 12:660232\nD’Ascenzi F, Anselmi F, Adami PE, Pelliccia A (2020) Interpretation of t-wave inversion in physiological and \npathological conditions: current state and future perspectives. Clin Cardiol 43(8):827–833\nGillioz A, Casas J, Mugellini E, Abou Khaled O (2020) “Overview of the transformer-based models for nlp \ntasks,” in 2020 15th Conference on computer science and information systems (FedCSIS) . IEEE, pp. \n179–183\nTetko IV , Karpov P, Van Deursen R, Godin G (2020) State-of-the-art augmented nlp transformer models for \ndirect and single-step retrosynthesis. Nat Commun 11(1):5575\nYaqoob M, Ishaq M, Ansari MY , Konagandla VRS, Tamimi TA, Tavani S, Corradetti A, Seers TD (2024) \nGeocrack: a high-resolution dataset for segmentation of fracture edges in geological outcrops. Sci Data \n11(1):1–13\nYaqoob M, Ishaq M, Ansari MY , Qaiser Y , Hussain R, Rabbani HS, Garwood RJ, Seers TD (2025) Advanc-\ning paleontology: a survey on deep learning methodologies in fossil image analysis. Artif Intell Rev \n58(3):83\nYaqoob M, Ansari MY , Ishaq M, Jayachandran ISAJ, Hashim M, Seers TD (2025) “Microcrystalnet: An \nefficient and explainable convolutional neural network for microcrystal classification using scanning \nelectron microscope petrography,” IEEE Access\nDahmani H, Yaqoob M, Ansari MY , Flushing EF (2025) “Thermal homography in photovoltaic panels: \nEvaluating deep learning and feature-based methods,” in, IEEE Texas Power and Energy Conference \n(TPEC). IEEE 2025:1–6\nYaqoob M, Ansari MY , Ishaq M, Ashraf U, Pavuluri S, Rabbani A, Rabbani HS, Seers TD (2025) “Fluidnet-\nlite: Lightweight convolutional neural network for pore-scale modeling of multiphase flow in heteroge-\nneous porous media,” Advances in Water Resources, p. 104952\nDong L, Xu S, Xu B (2018) “Speech-transformer: a no-recurrence sequence-to-sequence model for speech \nrecognition,” in, IEEE international conference on acoustics, speech and signal processing (ICASSP). \nIEEE 2018:5884–5888\nKarita S, Chen N, Hayashi T, Hori T, Inaguma H, Jiang Z, Someki M, Soplin NEY , Yamamoto R, Wang X \n(2019) “A comparative study on transformer vs rnn in speech applications,” in, et al IEEE automatic \nspeech recognition and understanding workshop (ASRU). IEEE 2019:449–456\nAnsari MY , Yang Y , Meher PK, Dakua SP (2023) Dense-psp-unet: a neural network for fast inference liver \nultrasound segmentation. Comp Biol Med 153:106478\nShamshad F, Khan S, Zamir SW, Khan MH, Hayat M, Khan FS, Fu H (2023) Transformers in medical imag-\ning: a survey. Med Image Analy 88:102802\nAnsari MY , Mangalote IAC, Meher PK, Aboumarzouk O, Al-Ansari A, Halabi O, Dakua SP (2024) \n“Advancements in deep learning for b-mode ultrasound segmentation: A comprehensive review,” IEEE \nTransactions on Emerging Topics in Computational Intelligence\nLi J, Chen J, Tang Y , Wang C, Landman BA, Zhou SK (2023) Transforming medical imaging with transform-\ners? a comparative review of key properties, current progresses, and future perspectives. Med Image \nAnaly 85:102762\nAnsari MY , Yang Y , Balakrishnan S, Abinahed J, Al-Ansari A, Warfa M, Almokdad O, Barah A, Omer A, \nSingh A V et al (2022) A lightweight neural network with multiscale feature enhancement for liver ct \nsegmentation. Sci Rep 12(1):14153\nAkhtar Y , Dakua SP, Abdalla A, Aboumarzouk OM, Ansari MY , Abinahed J, Elakkad MSM, Al-Ansari A \n(2021) Risk assessment of computer-aided diagnostic software for hepatic resection. IEEE Trans Radiat \nPlasma Med Sci 6(6):667–677\nAnsari MY , Abdalla A, Ansari MY , Ansari MI, Malluhi B, Mohanty S, Mishra S, Singh SS, Abinahed J, Al-\nAnsari A et al (2022) Practical utility of liver segmentation methods in clinical surgeries and interven -\ntions. BMC Med Imag 22(1):97\n1 3\nPage 37 of 42 261\nM. Y. Ansari et al.\nAnsari MY , Qaraqe M (2023) Mefood: a large-scale representative benchmark of quotidian foods for the \nmiddle east. IEEE Access 11:4589–4601\nZhang M, Qiu L, Chen Y , Yang S, Zhang Z, Wang L (2023) A conv-transformer network for heart rate estima-\ntion using ballistocardiographic signals. Biomed Sig Process Control 80:104302\nLih OS, Jahmunah V , Palmer EE, Barua PD, Dogan S, Tuncer T, García S, Molinari F, Acharya UR (2023) \nEpilepsynet: novel automated detection of epilepsy using transformer model with eeg signals from 121 \npatient population. Comp Biol Med 164:107312\nAfsa I, Ansari MY , Paul S, Halabi O, Alataresh E, Shah J, Hamze A, Aboumarzouk O, Al-Ansari A, Dakua \nSP (2024) “Development and validation of a class imbalance-resilient cardiac arrest prediction frame -\nwork incorporating multiscale aggregation, ica and explainability,” IEEE Transactions on Biomedical \nEngineering\nSalloum R, Kuo C-CJ (2017) “Ecg-based biometrics using recurrent neural networks,” in 2017 IEEE Interna-\ntional Conference on Acoustics, Speech and Signal Processing (ICASSP).IEEE, pp. 2062–2066\nHou B, Yang J, Wang P, Yan R (2019) Lstm-based auto-encoder model for ecg arrhythmias classification. \nIEEE Trans Instrumen Measur 69(4):1232–1240\nTakase S, Kobayashi S (2020) All word embeddings from one embedding. Adv Neural Inf Process Syst \n33:3775–3785\nSu J, Ahmed M, Lu Y , Pan S, Bo W, Liu Y (2024) Roformer: enhanced transformer with rotary position \nembedding. Neurocomputing 568:127063\nVaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser Lu, Polosukhin I (2017) “Atten-\ntion is all you need,” in Advances in Neural Information Processing Systems, vol. 30\nV oita E, Talbot D, Moiseev F, Sennrich R, Titov I (2019) “Analyzing multi-head self-attention: Specialized \nheads do the heavy lifting, the rest can be pruned,” arXiv preprint arXiv:1905.09418\nGeva M, Schuster R, Berant J, Levy O (2020) “Transformer feed-forward layers are key-value memories,” \narXiv preprint arXiv:2012.14913\nEl-Ghaish H, Eldele E (2024) Ecgtransform: empowering adaptive ecg arrhythmia classification framework \nwith bidirectional transformer. Biomed Sig Process Control 89:105714\nMoody GB, Mark RG (2001) The impact of the mit-bih arrhythmia database. IEEE Eng Med Biol Magazine \n20(3):45–50\nBousseljot R, Kreiseler D, Schnabel A (1995) “Nutzung der ekg-signaldatenbank cardiodat der ptb über das \ninternet,”\nIslam MR, Qaraqe M, Qaraqe K, Serpedin E (2024) Cat-net: convolution, attention, and transformer based \nnetwork for single-lead ecg arrhythmia classification. Biomed Sig Process Control 93:106211\nTihonenko V , Khaustov A, Ivanov S, Rivin A et al. (2007) “St.-petersburg institute of cardiological technics \n12-lead arrhythmia database,” Dataset on physionet. org\nBusia P, Scrugli MA, Jung VJ-B, Benini L, Meloni P (2024) “A tiny transformer for low-power arrhythmia \nclassification on microcontrollers,” IEEE Transactions on Biomedical Circuits and Systems\nLiu Q, Feng Y , Xu H, Li J, Lin Z, Li S, Qiu S, Wu X, Ma Y , Xu Y et al (2024) Psc-net: integration of convo-\nlutional neural networks and transformers for physiological signal classification. Biomed Sig Process \nControl 91:106040\nAlbrecht P (1983) “St segment characterization for long term automated ecg analysis,” Ph.D. dissertation, \nMassachusetts Institute of Technology, Department of Electrical Engineering...,\nDin S, Qaraqe M, Mourad O, Qaraqe K, Serpedin E (2024) Ecg-based cardiac arrhythmias detection through \nensemble learning and fusion of deep spatial-temporal and long-range dependency features. Artif Intell \nMed 150:102818\nChon S, Ha K-W, Park S, Jung S (2023) “An ecg beat classification method using multi-kernel resnet with \ntransformer,” in 2023 IEEE International Conference on Big Data and Smart Computing (BigComp) . \nIEEE, pp. 140–144\nHu S, Cai W, Gao T, Zhou J, Wang M (2021) Robust wave-feature adaptive heartbeat classification based \non self-attention mechanism using a transformer model. Physiological Measurement 42(12):125001\nZhu J, Feng Y , Liu Q, Xu H, Miao Y , Lin Z, Li J, Liu H, Xu Y , Li F (2024) “An improved convnext with \nmultimodal transformer for physiological signal classification,” IEEE Access\nXia Y , Xu Y , Chen P, Zhang J, Zhang Y (2023) Generative adversarial network with transformer generator for \nboosting ecg classification. Biomed Sig Process Control 80:104276\nXia Y , Xiong Y , Wang K (2023) A transformer model blended with cnn and denoising autoencoder for inter-\npatient ecg arrhythmia classification. Biomed Sig Process Control 86:105271\nGuan J, Wang W, Feng P, Wang X, Wang W (2021) “Low-dimensional denoising embedding transformer \nfor ecg classification,” in ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and \nSignal Processing (ICASSP). IEEE, pp. 1285–1289\nTao Y , Xu B, Zhang Y (2024) “Refined self-attention transformer model for ecg-based arrhythmia detection,” \nIEEE Transactions on Instrumentation and Measurement\n1 3\n261 Page 38 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nWu W, Huang Y , Wu X (2024) Srt: improved transformer-based model for classification of 2d heartbeat \nimages. Biomed Sig Process Control 88:105017\nWang Y , Yang G, Li S, Li Y , He L, Liu D (2023) Arrhythmia classification algorithm based on multi-head \nself-attention mechanism. Biomed Sig Process Control 79:104206\nMeng L, Tan W, Ma J, Wang R, Yin X, Zhang Y (2022) Enhancing dynamic ecg heartbeat classification with \nlightweight transformer model. Artif Intell Med 124:102236\nAlday EAP, Gu A, Shah AJ, Robichaux C, Wong A-KI, Liu C, Liu F, Rad AB, Elola A, Seyedi S et al (2020) \nClassification of 12-lead ecgs: the physionet/computing in cardiology challenge 2020. Physiol Measur \n41(12):124003\nZou C, Müller A, Martens E, Müller P, Rückert D, Steger A, Becker M, Wolfgang U (2023) “Self-supervised \nlearning for atrial fibrillation detection with ecg using cnntransformer,” in 2023 IEEE International \nConference on Bioinformatics and Biomedicine (BIBM). IEEE, pp. 807–812\nPratiher S, Srivastava A, Priyatha YB, Ghosh N, Patra A (2022) “A dilated residual vision transformer for \natrial fibrillation detection from stacked time-frequency ecg representations,” in ICASSP 2022-2022 \nIEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) .IEEE, pp. \n1121–1125\nClifford GD, Liu C, Moody B, Li-wei HL, Silva I, Li Q, Johnson A, Mark RG (2017)“Af classification from \na short single lead ecg recording: The physionet/computing in cardiology challenge 2017,” in 2017 \nComputing in Cardiology (CinC).IEEE, pp. 1–4\nReyna MA, Sadr N, Alday EAP, Gu A, Shah AJ, Robichaux C, Rad AB, Elola A, Seyedi S, Ansari S (2021) \n“Will two do? varying dimensions in electrocardiography: the physionet, computing in cardiology chal-\nlenge 2021,” in, et al Computing in Cardiology (CinC), vol. 48. IEEE 2021:1–4\nYang M-U, Lee D-I, Park S (2022) Automated diagnosis of atrial fibrillation using ecg component-aware \ntransformer. Comp Biol Med 150:106115\nZheng J, Guo H, Chu H (2022) “A large scale 12-lead electrocardiogram database for arrhythmia study (ver-\nsion 1.0. 0),” PhysioNet 2022Available online httpphysionet orgcontentecg arrhythmia10 0accessed \non, vol. 23,\nWang B, Liu C, Hu C, Liu X, Cao J (2021) “Arrhythmia classification with heartbeat-aware transformer,” \nin ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing \n(ICASSP).IEEE, pp. 1025–1029\nChe C, Zhang P, Zhu M, Qu Y , Jin B (2021) Constrained transformer network for ecg signal processing and \narrhythmia classification. BMC Med Inf Dec Making 21(1):184\nKalyakulina A, Yusipov I, Moskalenko V , Nikolskiy A, Kosonogov K, Zolotykh N, Ivanchenko M (2020) \n“Lobachevsky university electrocardiography database,” Type: Dataset. Available online: https://physi-\nonet. org/content/ludb/1.0. 0/(accessed on 10 July 2021)\nWang Z, Pan X, Mei Z, Xu Z, Lv Y , Zhang Y , Guan C (2024) “Ecgan-assisted rest-net based on fuzziness for \nosa detection,” IEEE Transactions on Biomedical Engineering\nPenzel T, Moody GB, Mark RG, Goldberger AL, Peter JH (2000) “The apnea-ecg database,” in Computers \nin Cardiology, V ol. 27 (Cat. 00CH37163). IEEE 2000:255–258\nWei C, Kuang H, Ma X, Liu X (2024) “Msaf-transformer: A multi-scale attentive feature network for sleep \napnea prediction based on single lead ecg signal,\" in, IEEE 6th Advanced Information Management, \nCommunicates, Electronic and Automation Control Conference (IMCEC), vol. 6. IEEE 2024:1009–1013\nHu S, Wang Y , Liu J, Yang C (2023) “Personalized transfer learning for single-lead ecg-based sleep apnea \ndetection: exploring the label mapping length and transfer strategy using hybrid transformer model,” \nIEEE Transactions on Instrumentation and Measurement\nHeneghan C (2011)“St. vincent’s university hospital/university college dublin sleep apnea database,” Vin-\ncent’ s university hospital/University College Dublin sleep apnea database\nLi C, Shi Z, Zhou L, Zhang Z, Wu C, Ren X, Hei X, Zhao M, Zhang Y , Liu H et al. (2023) “Tfformer: A time \nfrequency information fusion based cnn-transformer model for osa detection with single-lead ecg,” \nIEEE Transactions on Instrumentation and Measurement\nShi Y , Cao Z, Xie Y , Yuan Y , Chen X, Su Y , Niu X, Liu H, Yin L, Zhao B et al (2023) Association between \nobstructive sleep apnea and thyroid function: a 10-year retrospective study. Sleep Med 103:106–115\nFayyaz H, Strang A, Beheshti R (2023) “Bringing at-home pediatric sleep apnea testing closer to reality: \nA multi-modal transformer approach,” in Machine Learning for Healthcare Conference . PMLR, pp. \n167–185\nLee H, Li B, DeForte S, Splaingard ML, Huang Y , Chi Y , Linwood SL (2022) A large collection of real-world \npediatric sleep studies. Sci Data 9(1):421\nRedline S, Amin R, Beebe D, Chervin RD, Garetz SL, Giordani B, Marcus CL, Moore RH, Rosen CL, Arens \nR et al (2011) The childhood adenotonsillectomy trial (chat): rationale, design, and challenges of a \nrandomized controlled trial evaluating a standard surgical procedure in a pediatric population. Sleep \n34(11):1509–1517\n1 3\nPage 39 of 42 261\nM. Y. Ansari et al.\nLiu H, Cui S, Zhao X, Cong F (2023) Detection of obstructive sleep apnea from single-channel ecg signals \nusing a cnn-transformer architecture. Biomed Sig Process Control 82:104581\nHu S, Cai W, Gao T, Wang M (2022) A hybrid transformer model for obstructive sleep apnea detection based \non self-attention mechanism using single-lead ecg. IEEE Trans Instrumen Measur 71:1–11\nLi B, Wei W, Ferreira A, Tan S (2018) Rest-net: diverse activation modules and parallel subnets-based cnn \nfor spatial image steganalysis. IEEE Sig Process Lett 25(5):650–654\nWahid JA, Mingliang X, Ayoub M, Husssain S, Li L, Shi L (2024) A hybrid resnet-vit approach to bridge the \nglobal and local features for myocardial infarction detection. Sci Rep 14(1):4359\nZhang L, Su X, Zheng W (2023) “Msfnet: Multi-stage fusion network for myocardial infarction clas -\nsification,” in 2023 4th International Conference on Computer Engineering and Intelligent Control \n(ICCEIC). IEEE, pp. 424–427\nWagner P, Strodthoff N, Bousseljot R-D, Kreiseler D, Lunze FI, Samek W, Schaeffter T (2020) Ptb-xl, a large \npublicly available electrocardiography dataset. Sci Data 7(1):1–15\nShan C, Zhao J, Qiu Z, Wei F, Yuan Z (2022) “Mobi-trans: A hybrid network with attention mechanism \nfor myocardial infarction localization,” in 2022 International Joint Conference on Neural Networks \n(IJCNN). IEEE, pp. 1–8\nLiu T, Si Y , Yang W, Huang J, Yu Y , Zhang G, Zhou R (2022) Inter-patient congestive heart failure detection \nusing ecg-convolution-vision transformer network. Sensors 22(9):3283\nGoldberger AL, Amaral LA, Glass L, Hausdorff JM, Ivanov PC, Mark RG, Mietus JE, Moody GB, Peng C-K, \nStanley HE (2000) “Physiobank, physiotoolkit, and physionet: components of a new research resource \nfor complex physiologic signals,” circulation, vol. 101, no. 23, pp. e215–e220\nPimentel MA, Johnson AE, Charlton PH, Birrenkott D, Watkinson PJ, Tarassenko L, Clifton DA (2016) \nToward a robust estimation of respiratory rate from pulse oximeters. IEEE Trans Biomed Eng \n64(8):1914–1923\nFu G, Zheng J, Abudayyeh I, Ani C, Rakovski C, Ehwerhemuepha L, Lu H, Guo Y , Liu S, Chu H et al. (2024) \n“Cardiogpt: An ecg interpretation generation model,” IEEE Access\nVaid A, Jiang J, Sawant A, Lerakis S, Argulian E, Ahuja Y , Lampert J, Charney A, Greenspan H, Narula J et \nal (2023) A foundational vision transformer improves diagnostic performance for electrocardiograms. \nNPJ Digi Med 6(1):108\nWang X, Li J, Wang X, (2023) “Multi-feature fusion network of ecg and vcg for coronary artery disease \ndetection,” in Proceedings of the 2023 4th International Conference on Computing, Networks and Inter-\nnet of Things, pp. 164–169\nRyu JS, Lee S, Chu Y , Ahn M-S, Park YJ, Yang S (2023) Coat-mixer: self-attention deep learning framework \nfor left ventricular hypertrophy using electrocardiography. Plos one 18(6):e0286916\nBehinaein B, Bhatti A, Rodenburg D, Hungler P, Etemad A (2021) “A transformer architecture for stress \ndetection from ecg,” in Proceedings of the 2021 ACM International Symposium on Wearable Comput-\ners, pp. 132–134\nSchmidt P, Reiss A, Duerichen R, Marberger C, Van Laerhoven K (2018)“Introducing wesad, a multimodal \ndataset for wearable stress and affect detection,” in Proceedings of the 20th ACM international confer-\nence on multimodal interaction, pp. 400–408\nKoldijk S, Sappelli M, Verberne S, Neerincx MA, Kraaij W (2014) “The swell knowledge work dataset for \nstress and user modeling research,” in Proceedings of the 16th international conference on multimodal \ninteraction, pp. 291–298\nOh J, Lee G, Bae S, Kwon J-m, Choi E (2024) “Ecg-qa: A comprehensive question answering dataset com -\nbined with electrocardiogram,” Advances in Neural Information Processing Systems, vol. 36,\nOh J, Lee G, Bae S, Kwon J-m, Choi E (2023) “Ecg-qa: A comprehensive question answering dataset com -\nbined with electrocardiogram,” in Advances in Neural Information Processing Systems, A. Oh, T. Neu-\nmann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds., vol. 36.Curran Associates, Inc., pp. \n66 277–66 288. [Online]. Available:  h t t p s :   /  / p r o c e e d i n g  s .  n e u r i  p  s .  c c  / p a p  e  r _ fi    l e s /  p a  p e r  /  2 0 2 3  /  fi  l  e / d 0 b  6 7 3 \n4 9  d d 1 6 b 8  3 b 2 c  f 6 1 6 7  f b 4 e  2  b e 5 0 -   P a p e  r - D a  t a s e  t s _ a n d _ B e n  c h m a r k s . p d f\nXu H, Han L, Yang Q, Li M, Srivastava M (2024) “Penetrative ai: Making llms comprehend the physical \nworld,” in Proceedings of the 25th International Workshop on Mobile Computing Systems and Applica-\ntions, pp. 1–7\nYu H, Guo P, Sano A (2024) “Ecg semantic integrator (esi): A foundation ecg model pretrained with llm-\nenhanced cardiological text,” arXiv preprint arXiv:2405.19366,\nZheng J, Chu H, Struppa D, Zhang J, Yacoub SM, El-Askary H, Chang A, Ehwerhemuepha L, Abudayyeh \nI, Barrett A et al (2020) Optimal multi-stage arrhythmia classification approach. Sci Rep 10(1):2898\nGow B, Pollard T, Nathanson LA, Johnson A, Moody B, Fernandes C, Greenbaum N, Berkowitz S, \nMoukheiber D, Eslami P et al. (2023) “Mimic-iv-ecg-diagnostic electrocardiogram matched subset,” \nType: dataset\n1 3\n261 Page 40 of 42\nA survey of transformers and large language models for ECG diagnosis:…\nWan Z, Liu C, Wang X, Tao C, Shen H, Peng Z, Fu J, Arcucci R, Yao H, Zhang M (2024) “Electrocardiogram \ninstruction tuning for report generation,” arXiv preprint arXiv:2403.04945\nLiu C, Wan Z, Ouyang C, Shah A, Bai W, Arcucci R (2024) “Zero-shot ecg classification with multimodal \nlearning and test-time clinical knowledge enhancement,” arXiv preprint arXiv:2403.06659\nLiu F, Liu C, Zhao L, Zhang X, Wu X, Xu X, Liu Y , Ma C, Wei S, He Z et al (2018) An open access database \nfor evaluating the algorithms of electrocardiogram rhythm and morphology abnormality detection. J \nMed Imaging and Health Inf 8(7):1368–1373\nChen C, Li L, Beetz M, Banerjee A, Gupta R, Grau V (2024) “Large language model-informed ecg dual \nattention network for heart failure risk prediction,” arXiv preprint arXiv:2403.10581\nSudlow C, Gallacher J, Allen N, Beral V , Burton P, Danesh J, Downey P, Elliott P, Green J, Landray M et \nal (2015) Uk biobank: an open access resource for identifying the causes of a wide range of complex \ndiseases of middle and old age. PLoS Med 12(3):e1001779\nStrodthoff N, Mehari T, Nagel C, Aston PJ, Sundar A, Graff C, Kanters JK, Haverkamp W, Dössel O, Loewe \nA et al (2023) Ptb-xl+, a comprehensive electrocardiographic feature dataset. Sci Data 10(1):279\nZerveas G, Jayaraman S, Patel D, Bhamidipaty A, Eickhoff C (2021) “A transformer-based framework for \nmultivariate time series representation learning,” in Proceedings of the 27th ACM SIGKDD conference \non knowledge discovery & data mining, pp. 2114–2124\nLi C, Yang J, Zhang P, Gao M, Xiao B, Dai X, Yuan L, Gao J (2021) “Efficient self-supervised vision trans-\nformers for representation learning,” arXiv preprint arXiv:2106.09785\nWu Y , Daoudi M, Amad A (2024) Transformer-based self-supervised multimodal representation learning for \nwearable emotion recognition. IEEE Trans Aff Comp 15(1):157–172\nEldele E, Ragab M, Chen Z, Wu M, Kwoh CK, Li X, Guan C (2021) “Time-series representation learning via \ntemporal and contextual contrasting,” arXiv preprint arXiv:2106.14112\nZhang W, Yang L, Geng S, Hong S (2023) “Self-supervised time series representation learning via cross \nreconstruction transformer,” IEEE Transactions on Neural Networks and Learning Systems, pp. 1–10\nLiu X, Yu H-F, Dhillon I, Hsieh C-J (2020) “Learning to encode position for transformer with continuous \ndynamical model,” in Proceedings of the 37th International Conference on Machine Learning, vol. 119. \nPMLR, 13–18 Jul, pp. 6327–6335\nKe G, He D, Liu T-Y ( 2020) “Rethinking positional encoding in language pre-training,” in International \nConference on Learning Representations\nKenton JDM-WC, Toutanova LK (2019) “Bert: Pre-training of deep bidirectional transformers for language \nunderstanding,” in Proceedings of naacL-HLT, vol. 1,, p. 2\nLan Z, Chen M, Goodman S, Gimpel K, Sharma P, Soricut R (2019) “Albert: A lite bert for self-supervised \nlearning of language representations,” in International Conference on Learning Representations\nClark K, Luong M-T, Le QV , Manning CD (2020) “Electra: Pre-training text encoders as discriminators \nrather than generators,” in International Conference on Learning Representations\nDai Z, Yang Z, Yang Y , Carbonell JG, Le Q, Salakhutdinov R (2019) “Transformer-xl: Attentive language \nmodels beyond a fixed-length context,” in Proceedings of the 57th Annual Meeting of the Association \nfor Computational Linguistics, pp. 2978–2988\nHuang Z, Liang D, Xu P, Xiang B (2020) “Improve transformer models with better relative position embed-\ndings,” arXiv preprint arXiv:2009.13658,\nRaffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M, Zhou Y , Li W, Liu PJ (2020) Exploring the \nlimits of transfer learning with a unified text-to-text transformer. J Mach Learn Res 21(140):1–67\nChild R, Gray S, Radford A, Sutskever I (2019) “Generating long sequences with sparse transformers,” arXiv \npreprint arXiv:1904.10509\nGuo Q, Qiu X, Liu P, Shao Y , Xue X, Zhang Z (2019) “Star-transformer,” in Proceedings of the 2019 Con-\nference of the North American Chapter of the Association for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long and Short Papers) . Association for Computational Linguistics, \nJun. pp. 1315–1325\nBeltagy I, Peters ME, Cohan A (2020) “Longformer: The long-document transformer,” arXiv preprint \narXiv:2004.05150\nGuo M, Zhang Y , Liu T (2019) Gaussian transformer: a lightweight approach for natural language inference. \nProcee AAAI Conf Artif Intell 33(01):6489–6496\nWang S, Li BZ, Khabsa M, Fang H, Ma H (2020) “Linformer: Self-attention with linear complexity,” arXiv \npreprint arXiv:2006.04768\nPoli M, Massaroli S, Nguyen E, Fu DY , Dao T, Baccus S, Bengio Y , Ermon S, Ré C (2023) “Hyena hierarchy: \nTowards larger convolutional language models,” in International Conference on Machine Learning . \nPMLR, pp. 28 043–28 078\nFedus W, Zoph B, Shazeer N (2022) Switch transformers: scaling to trillion parameter models with simple \nand efficient sparsity. J Mach Learn Res 23(120):1–39\n1 3\nPage 41 of 42 261\nM. Y. Ansari et al.\nXin J, Tang R, Lee J, Yu Y , Lin J (2020) “Deebert: Dynamic early exiting for accelerating bert inference,” \narXiv preprint arXiv:2004.12993\nDziri N, Milton S, Yu M, Zaiane O, Reddy S (2022) “On the origin of hallucinations in conversational \nmodels: Is it the datasets or the models?” in Annual Conference of the North American Chapter of the \nAssociation for Computational Linguistics\nHernandez D, Brown T, Conerly T, DasSarma N, Drain D, El-Showk S, Elhage N, Hatfield-Dodds Z, \nHenighan T, Hume T et al., (2022) “Scaling laws and interpretability of learning from repeated data,” \narXiv preprint arXiv:2205.10487\nZhou C, Liu P, Xu P, Iyer S, Sun J, Mao Y , Ma X, Efrat A, Yu P, Yu L et al. (2024) “Lima: Less is more for \nalignment,” Advances in Neural Information Processing Systems, vol. 36,\nZhao H, Chen H, Yang F, Liu N, Deng H, Cai H, Wang S, Yin D, Du M (2024)“Explainability for large \nlanguage models: A survey,” ACM Trans. Intell. Syst. Technol., vol. 15, no. 2, feb. [Online]. Available: \nhttps://doi.org/10.1145/3639372\nXiong M, Hu Z, Lu X, LI Y , Fu J, He J, Hooi B (2024) “Can LLMs express their uncertainty? an empirical \nevaluation of confidence elicitation in LLMs,” in The Twelfth International Conference on Learning \nRepresentations, [Online]. Available: https://openreview.net/forum?id=gjeQKFxFpZ\nDuan J, Cheng H, Wang S, Zavalny A, Wang C, Xu R, Kailkhura B, Xu K (2024) “Shifting attention to \nrelevance: Towards the predictive uncertainty quantification of free-form large language models,” in \nProceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: \nLong Papers). Bangkok, Thailand: Association for Computational Linguistics, Aug. pp. 5050–5063. \n[Online]. Available: https://aclanthology.org/2024.acl-long.276\nXu M, Song C, Tian Y , Agrawal N, Granqvist F, van Dalen R, Zhang X, Argueta A, Han S, Deng Y , Liu L, \nWalia A, Jin A (2023) “Training large-vocabulary neural language models by private federated learning \nfor resource-constrained devices,” in ICASSP 2023 - 2023 IEEE International Conference on Acoustics, \nSpeech and Signal Processing (ICASSP), pp. 1–5\nYao Z, Xu Y , Xu H, Liao Y , Xie Z (2025) “Efficient deployment of large language models on resource-\nconstrained devices,” arXiv preprint arXiv:2501.02438\nAnsari Y , Mourad O, Qaraqe K, Serpedin E (2023) Deep learning for ecg arrhythmia detection and classifica-\ntion: an overview of progress for period 2017–2023. Front Physiol 14:1246746\nPublisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nAuthors and Affiliations\nMohammed Yusuf Ansari1,2 · Mohammed Yaqoob1 · Mohammed Ishaq1 · \nEduardo Feo Flushing2 · Iffa Afsa changaai Mangalote3 · Sarada Prasad Dakua3 · \nOmar Aboumarzouk3 · Raffaella Righetti1 · Marwa Qaraqe4\n \r Mohammed Yusuf Ansari\nma1@tamu.edu\n1 Department of Electrical and Computer Engineering, Texas A&M University, College Station, \nTX, USA\n2 Carnegie Mellon University in Qatar, Doha, Qatar\n3 Department of Surgery/Clinical Advancements Department, Hamad General Hospital, Hamad \nMedical Corporation, Doha, Qatar\n4 College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar\n1 3\n261 Page 42 of 42"
}