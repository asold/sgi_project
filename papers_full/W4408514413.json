{
  "title": "Towards an automated workflow in materials science for combining multi-modal simulation and experimental information using data mining and large language models",
  "url": "https://openalex.org/W4408514413",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2910799783",
      "name": "Balduin Katzer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5095902911",
      "name": "Steffen Klinder",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2033621972",
      "name": "Katrin Schulz",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2078363366",
    "https://openalex.org/W2029515855",
    "https://openalex.org/W2972418846",
    "https://openalex.org/W3208687975",
    "https://openalex.org/W3022530152",
    "https://openalex.org/W3113317199",
    "https://openalex.org/W4402459571",
    "https://openalex.org/W4220850924",
    "https://openalex.org/W4387443463",
    "https://openalex.org/W6852994313",
    "https://openalex.org/W6839567236",
    "https://openalex.org/W4367627709",
    "https://openalex.org/W4378384209",
    "https://openalex.org/W4399377978",
    "https://openalex.org/W4394828356",
    "https://openalex.org/W4224020136",
    "https://openalex.org/W6868985290",
    "https://openalex.org/W4390966669",
    "https://openalex.org/W4353034336",
    "https://openalex.org/W6869780876",
    "https://openalex.org/W4385671288",
    "https://openalex.org/W4401845100",
    "https://openalex.org/W4387773384",
    "https://openalex.org/W4397004462",
    "https://openalex.org/W2970771982",
    "https://openalex.org/W6864941005",
    "https://openalex.org/W4404080871",
    "https://openalex.org/W4389686182",
    "https://openalex.org/W4392002118",
    "https://openalex.org/W6870146845",
    "https://openalex.org/W6862622390",
    "https://openalex.org/W4402269933",
    "https://openalex.org/W3033206095",
    "https://openalex.org/W2034791023",
    "https://openalex.org/W4292239517",
    "https://openalex.org/W4387536790",
    "https://openalex.org/W4388067701",
    "https://openalex.org/W2945622475",
    "https://openalex.org/W3032405055",
    "https://openalex.org/W3106533158",
    "https://openalex.org/W4396883248",
    "https://openalex.org/W4311000022",
    "https://openalex.org/W2333869716",
    "https://openalex.org/W6870062668",
    "https://openalex.org/W4399322952",
    "https://openalex.org/W4391846075",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4378188762",
    "https://openalex.org/W4366330503",
    "https://openalex.org/W2606555609",
    "https://openalex.org/W3157854021",
    "https://openalex.org/W4400446804",
    "https://openalex.org/W4386228584",
    "https://openalex.org/W4239019441",
    "https://openalex.org/W3008374555",
    "https://openalex.org/W4401722919",
    "https://openalex.org/W4388927959",
    "https://openalex.org/W4360976356",
    "https://openalex.org/W4394707752",
    "https://openalex.org/W4399813510",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4389519239",
    "https://openalex.org/W4401813696",
    "https://openalex.org/W3100221827",
    "https://openalex.org/W4322760121"
  ],
  "abstract": null,
  "full_text": "Towards an automated workflow in materials science for combining multi-modal\nsimulative and experimental information using data mining and large language models\nBalduin Katzera,b,‚àó, Steffen Klindera, Katrin Schulza,b,‚àó\naKarlsruhe Institute of Technology (KIT), Institute for Applied Materials (IAM), Kaiserstr. 12, Karlsruhe, 76131, Germany\nbKarlsruhe University of Applied Sciences (HKA), Moltkestr. 30, Karlsruhe, 76133, Germany\nAbstract\nTo retrieve and compare scientific data of simulations and experiments in materials science, data needs to be easily accessible and\nmachine readable to qualify and quantify various materials science phenomena. The recent progress in open science leverages the\naccessibility to data. However, a majority of information is encoded within scientific documents limiting the capability of finding\nsuitable literature as well as material properties. This manuscript showcases an automated workflow, which unravels the encoded\ninformation from scientific literature to a machine readable data structure of texts, figures, tables, equations and meta-data, using\nnatural language processing and language as well as vision transformer models to generate a machine-readable database. The\nmachine-readable database can be enriched with local data, as e.g. unpublished or private material data, leading to knowledge\nsynthesis. The study shows that such an automated workflow accelerates information retrieval, proximate context detection and\nmaterial property extraction from multi-modal input data exemplarily shown for the research field of microstructural analyses of\nface-centered cubic single crystals. Ultimately, a Retrieval-Augmented Generation (RAG) based Large Language Model (LLM)\nenables a fast and efficient question answering chat bot.\nKeywords: Natural Language Processing (NLP), Large Language Model (LLM), Vision Transformer (ViT) Model, Data Mining,\nMaterials Science, Plasticity, Microstructure\n1. Introduction\nUnderstanding physical processes in materials and material\nmicrostructures is of fundamental importance in facilitating\ntheir use in engineering applications. However, analyzing the\nincreasing amount of existing scientific knowledge and extract-\ning the relevant information for a desired research project is a\nchallenging task. Especially, combining information from ex-\nperiments, simulations and theory is of great significance as dif-\nferent aspects are considered at each discipline that together,\nultimately, form a holistic picture [1, 2, 3, 4]. Machine learn-\ning (ML) and artificial intelligence (AI) have been recently used\nas advanced computational tools to accelerate the physical un-\nderstanding in materials science research [3, 5, 6, 4, 7]. Recent\nprogress in these computational methods enabled AI-assisted\nmodels with the ability to extrapolate beyond their data basis\nand generate novel materials science approaches, called gen-\nerative AI (genAI) [8, 9]. Applying genAI leads for exam-\nple to a novel design of crystalline materials [10], of molecule\nproperties [11] and of architected materials [12]. A funda-\nmental deep learning architecture of many genAI models is\nthe transformer architecture, which possesses a self-attention\nmechanism leading to contextual awareness of data [13]. This\ntransformer model is the foundation of the Large Language\n‚àóCorresponding author.\nEmail addresses: balduin.katzer@kit.edu (Balduin Katzer),\nkatrin.schulz@kit.edu (Katrin Schulz)\nModel (LLM), which is a context-aware genAI model for natu-\nral language processing (NLP) such as Generative Pre-Trained\nTransformer (GPT) [14, 15]. The performance of transformer\nmodels are particularly characterized by the quality and the\namount of data for pre-training leading to more powerful LLMs\nover the past years [15]. Based on this progress, materials sci-\nence research has become more accessible due to the sole use\nof natural language input. For example, in additive manufactur-\ning, novel material designs and entire manufacturing processes\nare derived by LLMs [16, 17]. A variety of other example us-\nages for LLMs in materials science are showcased in a study\nof Jablonka et al. [18] including knowledge discovery, property\nprediction as well as advances in user-model interfaces.\nTo enable a more accelerated and tailored investigation to\na domain-specific research area, LLMs are seen to have great\npotential. In particular, two main strategies have been de-\nveloped for LLMs for this task, fine-tuning and Retrieval-\nAugmented Generation (RAG) [19]. Fine-tuning of a LLM\nbases on additional model training with domain-specific data\nfitting the model parameters to its specific task. This procedure\nleads to several mechanics and materials science LLMs such\nas MechGPT [20] and ProtAgent [21] or to scientific LLMs in\ngeneral like SciBERT [22]. In contrast, RAG is a method to\nretrieve the relevant information from a user-specific database\nwithout modifying the transformer model itself, while being\nmore context-aware but less generalizable [23]. For utilizing\nRAG, various machine-readable databases could be considered\nfrom which information is retrieved. However, natural language\nPreprint submitted to arXiv February 24, 2025\narXiv:2502.14904v1  [cond-mat.mtrl-sci]  18 Feb 2025\n1980 1990 2000 2010 2020\nYear\n101\n102\n103\n104\n105\nNumber of Publications [-]\nQuery: ‚Äômaterials science‚Äô\nQuery: ‚Äômaterials science‚Äô, ‚Äôadditive manufacturing‚Äô\nQuery: ‚Äômaterials science‚Äô, ‚Äômicrostructure‚Äô, ‚Äôdislocation‚Äô\nDoubled every 8 years\nDoubled every 2 years\nFigure 1: Number of publications in material science during the past 50 years\nfor different queries based on data from dimension.ai [26].\ndatabases are employed most frequently [24, 25].\nGenerating such a database of high relevance for a specific\nresearch area is challenging and tedious. The data can originate\nfrom various sources such as scientific literature or user specific\ndata. As an example, the highly increasing amount of scientific\nliterature in materials science is depicted in Fig. 1. It shows the\nnumber of scientific publications for different keyword queries\nbased on the dimension.ai [26] database within the last 50 years.\nA general trend in scientific research can be deducted, e.g., the\nnumber of scientific literature doubles every eight years for ma-\nterials science in general, whereas it doubles every two years\nfor research in additive manufacturing in materials science in-\ndicated by the dashed and dotted lines. To incorporate the in-\ncreasing amount of data, workflows have been developed to au-\ntomatize database generations from scientific literature [27] and\nLLMs have been used to extract accurate information from doc-\numents [28]. For example, a RAG based LLM is utilized for\nadditive manufacturing to answer user-defined questions from\nliterature data [17], or in another example, user-specific data in\nthe form of electronic lab notebooks is utilized for question-\nanswering in a LLM workflow [29]. However, most of the pre-\nvious approaches focus purely on databases generated from text\ndata without using the richness of multi-modal data sources.\nBut recent progress in transformer model approaches lead to\nthe generation of a Large Multi-modal Model (LMM), which is\ncapable of contextualizing multi-modal input such as audio or\nimages [14, 30, 31, 32]. Thus, workflows are required, which\ngenerate multi-modal databases and are capable of processing\nmulti-modal data within the LLM.\nThis study proposes an automated workflow, which in-\ncorporates multi-modal data from scientific literature as well\nas multi-modal user-specific data to deduct a multi-modal\ndatabase, which is subsequently utilized for a RAG based\nLLM for question-answer prompting. This work addresses\nthe challenge of automatically and accurately identifying the\nmost suitable scientific research related to the research do-\nmain of dislocation-microstructure based materials science. In\nthis domain, di fferent length scales need to be covered by re-\nsearchers‚Äô investigations leading to various materials science\ntheories, each evaluated by a multitude of simulative and ex-\nperimental methods [33]. This workflow tackles the search for\nsimulations, experiments, or theories that can be taken into ac-\ncount to support and compare user-defined research questions.\nThis study attempts to aid the researcher‚Äôs need for a quick and\naccurate retrieval of suitable research data. The following key\nresearch questions are addressed:\n1. To what extent is a data-driven workflow and a domain-\nspecific RAG based LLM able to detect and represent most\nsuitable scientific features based on user-specific queries?\n2. What are the current limitations of the automatized multi-\nmodal workflow, i.e., to what extent does the domain-\nspecific RAG based LLM reply accurate results and what\nis the reason for inaccurate results?\nThe manuscript is structured as follows: Section 2 introduces\nthe data mining tools, the user-specific data as well as the trans-\nformer models. Section 3 displays the results of the workflow.\nThe current limitations as well as the accuracy of the results are\ndiscussed in Section 4. Section 5 gives a summary and outlook\nof the automated workflow and the RAG based LLM approach.\n2. Methods\nThis study introduces a method, which enables an auto-\nmated workflow to query and process literature in the do-\nmain of materials science in combination with local user-\nspecific data from experiments, simulations or theory. Using\na Retrieval-Augmented Generation (RAG) based Large Lan-\nguage Model (LLM), the objective is to provide a faster and\nmore accurate retrieval of information. The schematic of the\nworkflow is shown in Fig. 2. The top left box represents the col-\nlection of relevant scientific literature resulting from conduct-\ning a query for a desired research question within a literature\ndatabase. This query identifies possible publication candidates\nbased on keyword matching. Subsequently, full-text documents\nfor each candidate of interest are deciphered and structured into\nvarious document entities like texts, equations, images, tables,\nand meta-data including, e.g., the authors, the title, or the doi.\nA transformation is performed through a pipeline of machine\nlearning models that includes layout detection, data cleaning,\nand optical character recognition (OCR). In Fig. 2, the bot-\ntom left box illustrates the process of generating a structured\ndatabase from the local and user-specific experimental, simu-\nlative, or theoretical data. In the next step, the structured data\nfrom the literature and the local data from the user are com-\nbined into a user-specific database. Ultimately, an LLM chat\nbot is created which retrieves information from the combined\ndatabase to answer user-specific questions by taking into ac-\ncount literature as well as local information and results. The\nautomated workflow is exemplarily established in the follow-\ning for the field of dislocation-microstructure based materials\nscience.\n2\nDatabase of scientific literaturePublicationsof interest\nOptical Character Recognition (OCR)\nPaper 1Paper 2‚Ä¶ MetadataPDF\nAuthor: {}Title: {}Equations: {}Images: {}Tables: {}‚Ä¶\nDecipheredpublication\nQuery Large Language ModelPrompt\nInput of scientific literature\nInput of local data\nChat BotMINDQUEST\nRetrieval-Augmented Generation (RAG) based LargeLanguageModel(LLM)\nTheory\nSimulationExperimentEquations: {}Images: {}Raw data: {}Code: {}‚Ä¶\nDecipheredlocal data\nData generation\nExperimental, simulative and theoretical data\nVision Transformer (ViT) Model & OCR\nUser-specific database from scientific literature and local data\nFigure 2: Automated workflow to generate a Retrieval-Augmented Generation (RAG) based Large Language Model (LLM) using a multi-modal database.\n2.1. Data mining from literature via OCR models\nMost scientific literature is provided to its community by\nPDF documents. In materials science, each document is\nrich in information including multi-modal information in var-\nious forms such as texts, equations, figures or tables. How-\never, the machine readability of PDF documents is limited.\nThus, each document needs to be deciphered into a machine-\nreadable structured dataset to provide better accessibility. Re-\ncent progress in OCR models enable the transformation of PDF\ndocuments into machine-readable markup language incorporat-\ning tables, equations and images. Table 1 shows the compari-\nson of the OCR models pypdfium21, nougat2 [34] and marker3\nwith respect to their capability to properly extract equations,\nimages, tables and text. pypdfium2 is a fast OCR model, how-\never, unable to correctly depict equations and prone to errors in\ngeneral. nougat and marker are more advanced machine learn-\ning OCR models, which are able to convert PDF documents in-\ncorporating equations and tables with high precision, however,\nwith high computational cost. Regarding the field of applica-\ntion, marker is considered most adequate for incorporation into\nan automated workflow since it is able to extract images of the\nPDF document by incorporating the layout detection toolsurya.\nHere, marker detects each image within each document leading\nto a set of image data in addition to the markdown file for each\nmanuscript. This is, e.g., particularly important for the incorpo-\nration of experimental or simulation results often presented as\nimages or diagrams. An interface of marker can then be used\n1https://github.com/pypdfium2-team/pypdfium2\n2https://facebookresearch.github.io/nougat\n3https://github.com/VikParuchuri/marker\nto couple it again with pypdfium2 and nougat to harmonize ac-\ncuracy and speed of the OCR.\nTable 1: Comparison of multi-modal OCR capabilities across three di fferent\nmodels (pypdfium2, nougat, marker) to recognize and process di fferent types\nof content in documents. marker shows the broadest capabilities, handling text,\ntables, equations, and images, while the other models have limitations.\nOCR model Text Tables Equations Images\npypdfium2 yes yes no no\nnougat yes yes yes no\nmarker yes yes yes yes\n2.2. User-specific microstructure simulation data\nThe present workflow aims to incorporate local user-specific\ndata into the retrieval database. This study exemplarily ex-\namines local data from microstructure simulations of single-\ncrystalline aluminum employing two di fferent simulation ap-\nproaches that consider di fferent length scales for the resolu-\ntion of microstructural defect structures. The Discrete Dislo-\ncation Dynamics (DDD) approach resolves the dynamics of the\nevolution of the dislocation microstructure during plastic de-\nformation at a discrete level showing individual atomistic de-\nfects [35, 36, 37, 38]. The Continuum Dislocation Dynam-\nics (CDD) approach models the microstructure evolution in a\nhomogenized form by using continuum fields for the disloca-\ntion density [39, 40, 41, 42]. For this study, 2D images are gen-\nerated from three-dimensional DDD and CDD data. A set of\nexample images are depicted in Fig. 3. Additionally, each dis-\nlocation microstructure image is enriched by a set of features\nproviding additional data for image interpretation and contex-\n3\ntualization, e.g., including information about the material, the\nsimulation set-up or the strain state.\nFigure 3: Example images of a DDD and a CDD microstructure (given as 2d\nslice of a 3d material system) including metadata information about the simu-\nlation features.\n2.3. Transformer models\nTransformer models capture contextual relationships within\ndata, e.g., for natural language tasks as well as for visual tasks.\nThe models utilize embeddings to map semantic and visual in-\nformation into a latent space. From this latent space, the prox-\nimity between the data can be retrieved. The proposed work-\nflow considers three types of transformer models: Embeddings\nmodels (EM), large language models (LLM), and vision trans-\nformer (ViT) models.\nThe embedding model identifies the relevant information\nfrom a fragment of text and generates a n-dimensional embed-\nding vector. This approach employs the all-minilm model with\n22B parameters, which is a light-weight and fast embedding\nmodel, and based on the Bidirectional Encoder Representations\nfrom Transformers (BERT) architecture [44]. The large lan-\nguage model is able to generate text from user-specific queries\nby learning statistical relationships of natural language data.\nHere, the foundation language model from Meta AILLaMA 3.2\nwith 3B parameters is considered. LLaMA is chosen due to its\nhigh performance and its precise contextual analysis compared\nto other LLM models such as BERT [45]. The vision trans-\nformer model is able to generate text based on images by gen-\nerating an embedding vector from patches of an image. In this\nstudy, the Large Language and Vision Assistant model LLaVA\nwith 7B parameters is considered [46]. The model is applied\nby the ollama4 framework. Furthermore, OpenAI‚Äôs generative\npre-trained transformer ChatGPT-4o5 is used for comparison\nbetween the considered LLM and ViT models due to its ability\nto directly transform PDF documents into text.\n4https://ollama.com (Oct 2024)\n5https://chatgpt.com (Oct 2024)\nTable 2: Regular expression operators for identifying document entities in-\ncluding headings, paragraphs, equations, tables, figures, codes or citations,\nwhich enables further structuring of the markdown data into more distinct con-\nstituents.\nDocument entity Regular expression operators\nHeading ^#{1,6} .*\nParagraph (.*\\n)+\nEquation $.*?$ (inline) and $$.*?$$ (block)\nTable ^\\.*?$\nFigure !\\[.*?\\]\\(.*?\\)\nCode Block ‚Äò.*?‚Äò (inline) or ‚Äò‚Äò‚Äò.*?‚Äò‚Äò‚Äò (block)\nCitation \\[.*?\\]\\(.*?\\)\n3. Results\n3.1. Generation of a multi-modal machine-readable database\nThe first step towards an automated workflow is the gener-\nation of a multi-modal machine-readable database for experi-\nmental and simulative materials science data. Thus, the main\nobjective is deciphering any input data of interest such as scien-\ntific literature or user-specific data to a given machine-readable\noutput format.\n3.1.1. Finding relevant literature candidates\nTo find the relevant scientific literature that applies to a cer-\ntain research topic, a keyword-based initial screening is car-\nried out to find the relevant publication candidates. There-\nfore, the Semantic Scholar API 6 is used, which searches\nfor keyword matches in the metadata, the title, and the ab-\nstract. This study focuses on the retrieval of the most suit-\nable scientific literature for dislocation-based plasticity of sin-\ngle crystalline face-centered cubic (fcc) materials. Thus,\nthe following keywords are considered for the screening\nquery in the Semantic Scholar database: \"dislocation\",\n\"plasticity\", (\"face-centered cubic\" or \"fcc\") and\n\"single crystal\". This query yields ‚âà2000 scientific pub-\nlication candidates. Due to license limitations and the lack of\ndigitization of the earlier literature, this query led to‚âà1200 full-\ntext PDF documents, which is the corpus of the domain-specific\nliterature of all subsequent analyses.\n3.1.2. Example of machine-readable data (re-)construction\nThe considered corpus of scientific literature consists of full-\ntext PDF documents. The generation of a machine-readable\ndatabase from these documents is performed applying the OCR\nmodels introduced in Section 2.1. Applying marker leads to a\nmarkdown file and a set of images for each PDF document. An\nexample of a layout analysis of parts of a PDF document con-\nsisting of text, equations, tables, and figures is provided in Ap-\npendix A. This example demonstrates how the OCR model ac-\ncurately deciphers the PDF document into various document\nentities. Based on the generated machine-readable markdown\nfile, the data is further subdivided into equations, tables, texts\n6https://www.semanticscholar.org/product/api (Oct 2024)\n4\n5\nThe CPFE implementation discussed above is versatile and allows simulating both 2D and 3D real polycrystalline structures obtained using e.g. EBSD or randomly distributed grains or statistically equivalent grain structures modelled using V oronoi tessellations [46, 52].\n2.2. Discrete dislocation plasticity formulation\nThe plane strain, isotropic, quasi-static DDP formulation of Van der Giessen and Needleman [53] is used here. A fcc crystal structure is assumed, with the plane of the simulation taken perpend icular to the 101[ ] crystal direction to satisfy the plane strain constraint, 033 13 23Œµ ŒµŒµ== = . Slip planes are lines in the planar formulation, defined by the intersection of the slip planes with the plane of the simulation, and dislocations are confined to glide along those lines. The material is assumed to be initially dislocation-free; all dislocations originate from Frank‚ÄìRead sources. The plane of the simulation is that which intersects the pure edge segments of the incipient loop originating from a Frank‚ÄìRead source, and the screw parts of the loop are effectively pinned by the plane strain condition and the planar loading, as depicted in figure¬†1. In 2D, the trapped dislocation line of the Frank‚ÄìRead source is perpendicular to the simulation plane, hence is a point, and the dislocation loop originating from the source is a dipole of straight line edge dislocations with Burgers vector b. The applied loading is such that the glide component of the Peach‚ÄìKoehler force is large on the edge segments of the dis-location loop, and small on the screw segments, hence the latter are effectively pinned and the loop expands via the edge segments.Boundary conditions are satisfied using the superposition principle first employed by Lubarda et al [54], and Van der Giessen and Needleman [53] (see figure¬†2 and equation¬†(8)). Displacement, stress and strain are decomposed into the infinite medium dislocation fields (Àú) and a correction (^) that ensures the boundary conditions are satisfied; the former is obtained via the superposition of known analytical fields and the latter is obtained via a finite element solution of a problem where singularities are absent and the effect of the dislocations is medi-ated by the corrected boundary conditions.\nuu uœÉœÉ œÉ\nŒµŒµ Œµ\n=+=+\n=+/tildenosp2char\n/tildenosp2char\n/circumflexnosp2char\n/circumflexnosp2char\n/circumflexnosp2char/tildenosp2char (8)\nPoint Frank‚ÄìRead sources are randomly distributed on the slip planes (lines) to a certain den-sity. Source strengths nuc¬†œÑ are taken from a normal distribution with specified mean and stand-ard deviation; the latter captures the effect of the statistical distribution of trapped dislocation \nTable 1. CPFE material parameters used in the tension and indentation problem solved with the proposed coupling method.\nParameter name Symbol Unit Value\nYoung‚Äôs Modules E GPa 70\nPoisson ratio œÖ ‚Äî 0.33\nGrain orientation œÜ Degrees 0\nCritical resolved shear stressœÑc MPa 9\nZener‚Äôs factor Z ‚Äî 1\nHardening parameters\nHF MPa 98\nHR MPa 45\nHexp ‚Äî 1525\nq ‚Äî 1.01\nY Xu et alModelling Simul. Mater. Sci. Eng. 24 (2016) 045007\n6\nline lengths in the material. All sources nucleate dipoles with Burgers vector b at the equilib-rium spacing, Lnuc, given by:\nL b\n21nuc nuc()\n¬µ\nœÄŒΩ œÑ= ‚àí (9)\nwhere ¬µ is the shear modulus and ŒΩ is Poisson‚Äôs ratio, which corresponds to an exact balance between the resolved shear stress and the dislocation line tension. This occurs when the nucle-ation stress nucœÑ  is reached and maintained for the nucleation timetnuc¬† ; the latter is the time taken for the loop to reach its unstable configuration (Benzerga [55]). This in general depends on the applied stress, but is relatively insensitive to stress at low stresses, hence is taken to be a constant 10 ns in these simulations.The Ith dislocation glides with velocity VI ¬†() according to a linear mobility law:\nV f\nBI I\n¬†() ()\n= (10)\nFigure 1. An edge dislocation dipole nucleated from a Frank‚ÄìRead source in the plane of the simulation.\nFigure 2. The linear superposition scheme.\nY Xu et alModelling Simul. Mater. Sci. Eng. 24 (2016) 045007\nTable 1. CPFE material parameters used in the tension and indentation problem solved with the proposedcoupling method.\nThe CPFE implementation discussed above is versatile and allows simulating both 2D and 3D real polycrys-talline structures obtained using e.g. EBSD or randomly distributed grains or statistically equivalent grainstructures modelled using Voronoi tessellations [46, 52].\n2.2. Discrete dislocation plasticity formulation\nThe plane strain, isotropic, quasi-static DDP formulation of Van der Giessen and Needleman [53] is used here.A fcc crystal structure is assumed, with the plane of the simulation taken perpendicular to the [101] crystaldirection to satisfy the plane strain constraint, E33 = E23 = 0. Slip planes are lines in the planar formulation,defined by the intersection of the slip planes with the plane of the simulation, and dislocations are confinedto glide along those lines. The material is assumed to be initially dislocation-free; all dislocations originatefrom Frank-Read sources. The plane of the simulation is that which intersects the pure edge segments of theincipient loop originating from a Frank-Read source, and the screw parts of the loop are effectively pinnedby the plane strain condition and the planar loading, as depicted in figure 1. In 2D, the trapped dislocationline of the Frank-Read source is perpendicular to\nthe simulation plane, hence is a point, and the dislocation loop originating from the source is a dipole ofstraight line edge dislocations with Burgers vector b. The applied loading is such that the glide componentof the Peach-Koehler force is large on the edge segments of the dislocation loop, and small on the screwsegments, hence the latter are effectively pinned and the loop expands via the edge segments.\nBoundary conditions are satisfied using the superposition principle first employed by Lubarda et al [54], andVan der Giessen and Needleman [53] (see figure 2 and equation (8)). Displacement, stress and strain aredecomposed into the infinite medium dislocation fields (-) and a correction (^) that ensures the boundaryconditions are satisfied; the former is obtained via the superposition of known analytical fields and the latteris obtained via a finite element solution of a problem where singularities are absent and the effect of thedislocations is mediated by the corrected boundary conditions.\nPoint Frank-Read sources are randomly distributed on the slip planes (lines) to a certain density. Sourcestrengths Thic are taken from a normal distribution with specified mean and standard deviation; the lattercaptures the effect of the statistical distribution of trapped dislocation\n5\nFigure 1. An edge dislocation dipole nucleated from a Frank-Read source in the plane of the simulation.\nFigure 2. The linear superposition scheme.\nline lengths in the material. All sources nucleate dipoles with Burgers vector b at the equilibrium spacing,Lnuc, given by:\nwhere u is the shear modulus and v is Poisson‚Äôs ratio, which corresponds to an exact balance between theresolved shear stress and the dislocation line tension. This occurs when the nucleation stress Thuc is reachedand maintained for the nucleation time tme; the latter is the time taken for the loop to reach its unstableconfiguration (Benzerga [55]). This in general depends on the applied stress, but is relatively insensitive tostress at low stresses, hence is taken to be a constant 10 ns in these simulations.\nThe Ith dislocation glides with velocity V(() according to a linear mobility law:\nÔøø\n1\nùë¢= ÃÑ ùë¢+ ÃÑ ùë¢\nùúé= ÃÑ ùúé+ ÃÑ ùúé (8)\nùúÄ=ÃÑùúÄ+ÃÑùúÄ\nùêønuc= ùúáùëè\n2ùúã(1‚àíùúà)ùúènuc\n(9)\nùëâ(ùêº)=ùëì(ùêº)\nùêµ (10)\n1\nParameter name Symbol Unit Value\nYoung‚Äôs Modules E GPa 70Poisson ratio U 0.33Grain orientation 0 Degrees 0Critical resolved shear stress TcMPa 9Zener‚Äôs factor ZHF MPa 98HR MPa ÔøøÔøøHardening parametersHexp 1525g 1.01\n1\nAuthor, Year, Journal, DOI, ‚Ä¶\nOCR\nDocument Markdown TextEquations\nMeta-Data\nImages\nTables\nFigure 4: Example for deciphering full-text PDF document into structured database entities. Each document is subdivided into the following entities: markdown\ntext, meta-data, equations, tables and images. (here, [43] reproduced with permission from IOP Publishing under a Creative Commons License)\nand metadata as shown in Fig. 4. The entities of the docu-\nment are generated by regular expression operations depicted\nin Tab. 2 such as headings, equations, figures, or code blocks.\nThis keeps the structure of the document in a logical form.\n3.1.3. Text generation from images via visual transformers\nVision transformer models such as ChatGPT-4o and LLaVA\nas introduced in Section 2.3 enable the transformation of im-\nages into descriptive text. In materials science, images are key\nfor many fundamental research results. They are a significant\npart of the literature corpus as well as of local user-specific data,\ni.e. microstructural simulation results in this study. The applied\nmodels identify and decode the visual features of an image into\na natural language description. The role and prompt considered\nby the ViT model for the transformation of each image is shown\nin Appendix B.\nAn example of the transformation of a domain-specific image\ninto natural language is shown in Fig. 5. It illustrates the com-\nparison of the natural language description given by ChatGPT-\n4o and LLaVA. It appears that both models describe the image\nin reasonable detail, including indexing, labeling, axis annota-\ntion, and graph description. This leads to the conclusion that\nboth ViT models demonstrate the capability to accurately de-\nscribe images related to the domain of materials science as text.\nBased on the fact that onlyLLaVA is open source, it has been in-\ntegrated into the present workflow. Subsequently, in this study,\neach image - from the publication database as well as local data\n- is transformed into a natural language description and inte-\ngrated into the markdown file.\n3.1.4. Storage in vector database\nTo efficiently store and retrieve textual data, a vector database\nis utilized in conjunction with a BERT-based embedding model\nas introduced in Section 2.3. Therefore, each markdown docu-\nment is split into chunks of text of nchunk = 500 characters. For\neach text chunk, a numeric vector embedding is generated by\nusing the all-minilm embedding model. Additionally, a docu-\nment ID for each document and a chunk ID for each text chunk\nare created. This ensures a unique, reproducible ID for each\ntext chunk and each document, enabling consistent information\nretrieval. Subsequently, the text chunks, the IDs as well as the\nembeddings are stored in a vector database. This setup enables\nsemantic search to query the database with natural language in-\nputs and retrieve relevant results based on an embedding vector\nsimilarity metric. This study employs the squared euclidean\ndistance (L2)\nd =\nnX\ni=1\n(Ai ‚àí Bi)2. (1)\nUltimately, the vector database in combination with the em-\nbedding vectors leverages the search for the most suitable text\nchunks with respect to a envisaged query.\nFig. 6 shows results for the landscape of the corpus of con-\nsidered literature with respect to di fferent domain-specific fea-\ntures. A plot of the two-dimensional t-distributed stochastic\nneighbor embedding (t-SNE) is depicted, where individual text\nchunks are mapped in a two-dimensional space. Each text\nchunk is color-coded to indicate its proximity to experimental\nor simulation setups. The clustering of simulation and exper-\nimental data in the t-SNE landscape illustrates the proximity\nprovided by the textual representation.\n3.2. A RAG based LLM\nIn this work, a RAG based LLM is employed by retrieving\nthe most similar data from the vector database introduced in\nSection 3.1 and by employing a question-answer chat bot.\n3.2.1. Query information from vector database\nTo extract information from the generated vector database\nincluding literature as well as local data, database queries are\n5\n(a) Image\nThe image contains two graphs, labeled (a) and (b), which describe material\nbehavior under mechanical deformation. Graph (a) shows the relationship\nbetween dislocation density and engineering strain, while Graph (b) depicts\nstress versus engineering strain.\nIn Graph (a), the x-axis represents engineering strain ( Œµ = U/L), ranging\nfrom 0 to 0.0015, and the y-axis represents dislocation density ( œÅ), measured\nin ¬µm‚àí2, ranging from 0 to 16. Three curves are displayed, corresponding\nto different models: ‚ÄúDiscrete dislocation plasticity‚Äù (blue), ‚ÄúFully coupled‚Äù\n(green), and ‚ÄúNo iterations‚Äù (red). The blue curve exhibits the highest dislo-\ncation density across all strains, with several rapid increases at higher strains,\nsuggesting active dislocation generation. The green curve shows moderate\ngrowth, while the red curve represents the lowest dislocation density, indicating\nlimited dislocation activity. These results suggest that the discrete dislocation\nplasticity model captures a more detailed and realistic depiction of disloca-\ntion interactions under strain, while the other models simplify the mechanical\nresponse.\nGraph (b) plots stress (œÉ11, in MPa) on the y-axis, ranging from 0 to 45 MPa,\nagainst engineering strain ( Œµ), which is again plotted on the x-axis over the\nrange 0 to 0.0015. The stress-strain response is shown for the same three\nmodels. The blue curve (discrete dislocation plasticity) exhibits the highest\nstress values across all strains, indicating a more robust response. The green\ncurve (fully coupled) shows slightly lower stresses, while the red curve (no\niterations) presents the lowest stress response, indicating a simplified mechan-\nical model. At small strains ( Œµ <0.0005), the differences between the models\nare minimal, but they diverge significantly as strain increases. The inset di-\nagram in Graph (b) illustrates the spatial distribution of normalized resolved\nshear stress ( œÑxy/œÑy) in a microstructure. The color map ranges from blue\n(œÑxy/œÑy = 0) to red ( œÑxy/œÑy = 2), highlighting regions of high shear stress,\nwhich are potential sites for intense dislocation activity or failure initiation.\nOverall, the discrete dislocation plasticity model demonstrates superior per-\nformance in capturing both dislocation dynamics (Graph a) and the stress re-\nsponse (Graph b), making it more representative of real material behavior.\nThe fully coupled and no iterations models simplify the mechanical response,\nresulting in lower stress and dislocation densities. The graphs highlight the\nimportance of incorporating dislocation-level details for accurate material\nmodeling, especially at higher strains where plastic deformation mechanisms\ndominate. Abrupt increases in dislocation density for the discrete dislocation\nplasticity model at higher strains, as seen in Graph (a), may indicate strain-\nhardening effects or sudden activation of dislocation sources. Additionally, the\ninset in Graph (b) underscores the significance of localized stress concentra-\ntions in understanding failure mechanisms.\n(b) ChatGPT-4o\nThe image consists of two parts: (a) and (b).\nPart (a) is a graph that shows the dislocation density as a function of engi-\nneering strain for di fferent simulation scenarios. The x-axis represents the\nengineering strain (Œµ= U/L), and the y-axis represents the dislocation density\n(in ¬µm‚àí2). There are three curves in the graph, each representing a di ffer-\nent simulation scenario: ‚ÄúDiscrete dislocation plasticity‚Äù (blue curve), ‚ÄúFully\ncoupled‚Äù (red curve), and ‚ÄúNo iterations‚Äù (green curve). The ‚ÄúDiscrete dis-\nlocation plasticity‚Äù curve shows a fluctuating increase in dislocation density\nas the strain increases, indicating the formation and movement of dislocations\nwithin the material. The ‚ÄúFully coupled‚Äù curve also shows an increase in dis-\nlocation density but with a smoother trend, suggesting a more stable simulation\nmodel. The ‚ÄúNo iterations‚Äù curve shows a relatively flat trend, indicating that\nno dislocations are formed or moved in this scenario.\nPart (b) is another graph that shows the stress ( œÉ, in MPa) as a function of\nengineering strain for the same three simulation scenarios. The x-axis repre-\nsents the engineering strain ( Œµ = U/L), and the y-axis represents the stress\n(in MPa). The graph also includes a color-coded map in the bottom left cor-\nner, which represents the distribution of the stress component œÉ11 (in MPa)\nacross the material. The color scale ranges from blue (low stress) to red (high\nstress). The ‚ÄúDiscrete dislocation plasticity‚Äù curve shows a sharp increase\nin stress as the strain increases, indicating the onset of plastic deformation.\nThe ‚ÄúFully coupled‚Äù curve shows a similar trend but with a slightly lower\nstress value, suggesting a more accurate simulation model. The ‚ÄúNo itera-\ntions‚Äù curve shows a relatively flat trend, indicating that no stress is developed\nin this scenario.\nThe scientific context of the image is related to the study of plastic deforma-\ntion mechanisms in materials. Dislocation density and stress-strain behavior\nare key indicators of the material‚Äôs ability to deform plastically. The ‚ÄúDis-\ncrete dislocation plasticity‚Äù scenario represents a simulation model that takes\ninto account the formation and movement of dislocations within the material,\nwhich is a common mechanism of plastic deformation. The ‚ÄúFully coupled‚Äù\nscenario represents a more advanced simulation model that couples the dis-\nlocation dynamics with the stress-strain behavior, providing a more accurate\nrepresentation of the material‚Äôs behavior under load. The ‚ÄúNo iterations‚Äù sce-\nnario represents a simulation model that does not take into account the dislo-\ncation dynamics, resulting in a simplified and less accurate representation of\nthe material‚Äôs behavior.\nIn summary, the image provides a detailed comparison of the dislocation den-\nsity and stress-strain behavior of a material under different simulation scenar-\nios. The ‚ÄúDiscrete dislocation plasticity‚Äù scenario shows a more realistic rep-\nresentation of the material‚Äôs behavior, with a fluctuating increase in dislocation\ndensity and a sharp increase in stress. The ‚ÄúFully coupled‚Äù scenario shows a\nmore accurate representation of the material‚Äôs behavior, with a smoother in-\ncrease in dislocation density and a slightly lower stress value. The ‚ÄúNo it-\nerations‚Äù scenario shows a simplified and less accurate representation of the\nmaterial‚Äôs behavior, with a relatively flat trend in both dislocation density and\nstress. The color-coded map in part (b) provides a visual representation of the\nstress distribution across the material, with red indicating high stress and blue\nindicating low stress.\n(c) LLaVA\nFigure 5: (a) Example of a figure description using an image from [43] (reproduced with permission from IOP Publishing under a Creative Commons License) with\nthe corresponding image description by the (b) ChatGPT-4o and (c) LLaVA Vision Transformer model. Both models demonstrate their capability to process and\ninterpret visual input into accurate textual descriptions enabling the substitution of images with the corresponding textual representations.\nformulated and performed. An embedding vector is gener-\nated for each query leading to retrieve the most proximate text\nchunks based on the similarity metrics. Fig. 7 shows a two-\ndimensional t-SNE plot of the text chunks of the scientific lit-\nerature as well as of the exemplarily chosen query ‚ÄùExtract the\ndiscrete dislocation dynamics models‚Äù based on the vector em-\nbeddings from the employed embedding model. All text chunks\nare depicted colored based on their proximity to the considered\nkeyword ‚Äùdislocation dynamics‚Äù determined by the normalized\nnumber of occurrences of the keyword within each text chunk.\nThe black marker indicates the first and second t-SNE of the\nquery embedding. The result illustrates a closer proximity of\nthe query to the text chunks, which are more related to dislo-\ncation dynamics, compared to text chunks, which are less re-\nlated to dislocation dynamics. In Fig. 8, a two-dimensional\nt-SNE plot shows literature data form the literature corpus as\nwell as local data from 240 dislocation microstructure images\nas shown in Fig. 3. In (a), all data is color-coded based on\nthe proximity to the keywords ‚Äùdislocation‚Äù, ‚Äùmicrostructure‚Äù\nand ‚Äùsimulation‚Äù, whereas in (b) the color code represents the\nproximity to the keyword ‚Äùexperiment‚Äù. It shows that the local\ndata from the microstructural images cluster within the t-SNE\nwhereas the literature data is largely distributed. An exemplar-\nily query is chosen as follows: ‚ÄùPlease provide a 2D dislocation\nmicrostructure image with a dislocation network consisting of\nvarious fcc slip systems from a discrete dislocation dynamics\n(DDD) simulation‚Äù. It shows that the query is most proximate\nto the considered local data, and tends to be proximate to liter-\nature data, which is closer to the considered keywords. Litera-\nture data points, which are proximate to the exemplarily query\ncan be considered for further evaluation, e.g., if data from other\nsimulations should be utilized as shown by the colored data in\nFig. 8 (a), or if data from experiments should be utilized as\nshown by the colored data in Fig. 8 (b), where only a few data\npoints are proximate to the query.\n3.2.2. The MINDQUEST chat bot\nThis work introduces the RAG based LLM chat bot\nMINDQUEST (Modeling INnovation and Discovery through\nQuerying Experiment, Simulation, and Theory) for a user-\nfriendly question-answer platform for employing the workflow.\nThe user interface is depicted in Fig. 9. The settings are mod-\nifiable for the embedding as well as the large language model.\nDatabases as well as chat histories can be loaded and reset. The\nconsidered role and prompt of the RAG based LLM model is\nshown in Appendix C. Here, a keyword matching can be in-\ncluded to limit the range of potential text chunk candidates as\nwell as a threshold parameter nres defining the number of text\nchunks that are provided as candidates. Information about the\norigin of the document origin can be retrieved as well from\n6\n100\n 50\n 0 50 100\nFirst t-SNE\n100\n50\n0\n50\n100\n150\nSecond t-SNE\nExperiment Simulation\nProximity\nFigure 6: The t-SNE landscape of the scientific literature with colors indicating\nthe proximity of each text chunk to either experimental or simulation-related\nresearch.\nthe chat bot by the retrieval of the document id to give the\nuser the possibility to quickly access and review the results in\nthe context of the original document. This allows for back-\ntracking where the retrieved information originates from. Ulti-\nmately, MINDQUEST provides user-specific information about\nthe generated database. A question-answer example is shown\nin Appendix D.\n4. Discussion\nThe introduced automated workflow provides an enhanced\napproach for a systematic analysis of full-text documents in\ncombination with user-specific local data from, e.g., experi-\nments, simulation, and theory. The study comprises the gen-\neration of a multi-modal database and the creation of Retrieval-\nAugmented Generation based Large Language Model applied\nto the research field of dislocation-based plasticity of single\ncrystalline face-centered cubic materials. The selected op-\ntical character recognition and transformer models generate\nmachine-readable data from natural language as well as visual\ninput. By querying the database, the most proximate data is re-\ntrieved using embedding vectors represented in the latent space\nand providing fast and accurate information about the content\nof the considered data.\nThe evaluation of the OCR model shows that full-text\nPDF documents are accurately transformed and structured into\nmachine-readable markdown text as shown in Fig. 4. The trans-\nformed data is then applicable for subsequent analyses as shown\nby the proximity measure in Fig. 6 and for subsequent process-\ning to query most relevant data in the database as shown in Sec-\ntion 3.2. However, this approach depends on the accuracy of\n100\n 50\n 0 50 100\nFirst t-SNE\n100\n50\n0\n50\n100\n150\nSecond t-SNE\nQuery: \"Extract the discrete dislocation dynamics models\"\n     0          1           \nDislocation dynamics\nFigure 7: An example t-SNE landscape for querying the considered scientific\nliterature. The color coding indicates the proximity of each text chunk to dislo-\ncation dynamics. Additionally, the black marker highlights the proximity of an\nexemplarily chosen query with respect to the text chunks based on the vector\nembedding of the query derived from the employed embedding model.\nthe utilized layout detection for accurate subdivision into var-\nious document entities as shown in Appendix A. Further im-\nprovements could yield more precise layout detection, since\nlimitations are observed for very nested document structures.\nFor example in Fig. A.1, inaccuracies arise in the assignment\nof captions to figures and tables, where in some cases the cap-\ntion can be embedded in the figure layout and in other cases\nas additional text layout. In addition, the accuracy measure for\nthe layout detection as well as the markdown text generation\nhas been done manually by visual inspection. Furthermore, the\ndefinition of an automated evaluation schema that includes an\naccuracy metric for layout detection and OCR could be useful.\nFor example, defining an accuracy metric for document layout\npredictions of unlabeled data could be included based on semi-\nsupervised learning methods [47]. The measurement of the ac-\ncuracy of the OCR for each PDF document is complex. Natural\nlanguage reasoning and evaluation could be accomplished fol-\nlowing ideas of using another LLM as an evaluator [48, 49].\nThe approach presented in this work demonstrates that it\nenables to retrieve proximate results based on user-specific\nqueries for dislocation microstructures of materials, as demon-\nstrated by Fig. 7 and Fig. 8. The example queries show the most\nrelevant data as indicated by the proximity to the color-coded\ndata clusters. Fig. 8 shows that querying within the literature\nas well as local data yields accurate but distinguishable results\nbetween local and literature data as well as between simula-\ntive and experimental data enabling information retrieval from\nboth data sources. The clustering of local data in Fig. 8 arises\nfrom the selected local data obtained through microstructure\n7\n150\n 100\n 50\n 0 50 100 150\nFirst t-SNE\n150\n100\n50\n0\n50\n100\n150\nSecond t-SNE\nLiterature data\nLocal data\nQuery\n     0          1      \nProximity to dislocation mictrostructure simulations\n(a) Proximity to dislocation microstructure simulations\n150\n 100\n 50\n 0 50 100 150\nFirst t-SNE\n150\n100\n50\n0\n50\n100\n150\nSecond t-SNE\nLiterature data\nLocal data\nQuery\n     0          1      \nProximity to experiments (b) Proximity to experiments\nFigure 8: An example t-SNE landscape for querying the entire database including literature as well as local data. In (a) the color coding indicates the proximity of\neach text chunk to dislocation microstructure simulations, whereas in (b) the color coding indicates the proximity of each text chunk to experiments. The markers‚ñ≤\nand ‚ñº indicate literature data and local data, respectively. The marker ‚Ä¢ highlights the proximity of an exemplarily chosen query: ‚ÄùPlease provide a 2D dislocation\nmicrostructure image with a dislocation network consisting of various fcc slip systems from a discrete dislocation dynamics (DDD) simulation‚Äù.\nsimulations and the corresponding meta-data. In contrast to the\nmore extensive literature data, the user-specific local data has\na much higher degree of natural language similarity resulting\nin a strong proximity of the query to the search for microstruc-\nture images. The integration of a more extensive local database\ninto the workflow is planned for future applications. However,\nunlike the reliance on additional data, contamination by irrel-\nevant data exists as shown in Fig. 7 by more transparent data\npoints proximate to the exemplarily chosen query. Thus, RAG\ncan be a limiting factor for the workflow if queries result in\ntoo inaccurate or too few data candidates. In addition, it has to\nbe carefully considered to query within the scope of the user-\ndefined research data only to grant reasonable results. Since this\napproach uses a task delimited database aiming at specific and\ncustomized question-answering for materials science, the RAG\nbased LLM MINDQUEST requires only few computational re-\nsources. Integrating a materials science ontology could lead to\nimproved knowledge extraction from the text, which could be\na worthwhile future study. In general, the choice of the con-\nsidered user-defined database yields the trade-off between spe-\ncialization and generalizability, since it is defined by its size. In\nthis study, the generated multi-modal database is transformed\ninto natural language only as demonstrated by the accurate tex-\ntual descriptions by the visual transformer models as shown\nin Fig. 5 yielding to a lightweight design and enabling simple\nadaptability for other users. Future work could complement the\nmulti-modal transformation by a direct application of LMMs,\nwhich process various forms of multi-modal input data immedi-\nately potentially accelerating materials science research similar\nto text-only language models [50].\n5. Conclusion\nThe paper presents an automated workflow for combining\nmulti-modal data based on natural language processing (NLP)\nand large language modeling (LLM), showcasing the potential\nto identify proximity within materials science data. The pro-\nposed workflow enables researchers to query and process ma-\nterial science data more accurately and e fficiently, while pre-\nserving traceability of the extracted information to its original\ndata source. This study explores the similarity and proximity\nof data from literature as well as local data for the use-case of\ndislocation microstructures in materials. The main findings of\nthis work are:\n‚Ä¢ A Retrieval-Augmented Generation (RAG) based Large\nLanguage Model (LLM) enabling fast and accurate ques-\ntion answering from a materials science database.\n‚Ä¢ The generation of a use-case specific materials science\ndatabase including information from textual, mathemati-\ncal, visual and tabular data as well as metadata by applying\nOptical Character Recognition (OCR) on scientific publi-\ncations as well as local data.\n‚Ä¢ An evaluation of contextual proximity of materials science\nqueries on experimental and simulative data showcasing\nfast and accurate retrieval of data similarities.\n8\nWelcome to MINDQUEST\nModeling INnovation and Discovery through Querying Experiment, Simulation, and Theory\nExample query: What is a dislocation? 'text:raw' keywords:['dislocation dynamics', 'dislocation interactions']\n**Welcome to the **MINDQUEST**** chatbot! I'm delighted to assist you with any material science-related queries or questions related\nto natural language processing. Feel free to ask me anything, and I'll do my best to provide helpful insights and answers based on the\nuploaded documents. If you're ready to get started, please upload your documents for our conversation.\nYour message\nDeploy\nMINDQUEST\nÓÇ∑ÓÇ∑ Chat Bot\nModel settings\nÔîÄ Embedding Model\nÓ£¢ Large Language Model\nDatabase\nLoad database\nReset database\nChat\nLoad chat history\nReset chat history\nFigure 9: User interface of MINDQUEST, a RAG-based LLM chat bot, which enables querying within a multi-modal user-specific materials science database.\nCRediT authorship contribution statement\nBalduin Katzer: Conceptualization, Data curation, Formal\nanalysis, Investigation, Methodology, Visualization, Writing ‚Äì\noriginal draft. Steffen Klinder: Data curation, Formal analy-\nsis, Investigation, Validation. Katrin Schulz: Conceptualiza-\ntion, Funding acquisition, Project administration, Supervision,\nValidation, Writing ‚Äì original draft.\nDeclaration of competing interest\nThe authors declare that there are no competing interests.\nData availability\nData will be made available on reasonable request.\nAcknowledgment\nWe gratefully acknowledge the financial support of this work\nin the context of the German Research Foundation (DFG)\nproject SCHU 3074 /4-1 and the funding by the Carl-Zeiss-\nStiftung. The simulations were performed on the HoreKa su-\npercomputer funded by the Ministry of Science, Research and\nthe Arts Baden-W ¬®urttemberg and by the Federal Ministry of\nEducation and Research. B.K. thanks Natalia Pieton from\nFraunhofer IEG for initial discussions of this research idea.\nAppendix A. Layout detection evaluation\nAn example of the layout detection tool surya from the\nmarker OCR model is depicted in Fig. A.1. It demonstrates the\ncapability to identify various entities of multi-modal input data\nfrom PDF documents, which allows for structuring the data into\ndocument entities such as text, tables, figures and equations.\nAppendix B. Role and prompt of vision transformer model\nThe following role and prompt are applied to the vision trans-\nformer model to transform the visual input data into an accurate\ntextual description:\nYou are a materials science expert with expertise in interpreting sci-\nentific data, graphs, and visualizations, and your task is to provide\nprecise and detailed descriptions of the image content, including any\ngraphs, charts, diagrams, or illustrations. For graphs, identify the\naxes, units, and key variables, explain the trends, data points, and sig-\nnificant regions or markers, and specify any labeled features such as\ncurves, lines, or points of interest and their relevance to the material\nproperties or scientific context. For diagrams, explain the structure,\ncomponents, or processes shown and their role in the material or sci-\nentific system. For scientific context, relate the visual information to\nthe material science concepts it represents, such as stress-strain be-\nhavior, plastic deformation mechanisms, or crystal structure, and en-\nsure that the explanation is precise, avoiding vague language, while\nmaking it accessible to someone familiar with material science ter-\nminology. Include any labeled information, such as annotations, leg-\nends, or scales, to provide a comprehensive description, mention any\nobserved anomalies, deviations, or patterns that may be significant in\ninterpreting the material behavior or experimental results, and use a\nlogical flow in the explanation, starting with general observations be-\nfore delving into specific details.\nAppendix C. Role and prompt of large language model\nThe following role and prompt are applied to the large lan-\nguage model to analyze and process textual input data from the\nconsidered materials science database:\nYou are a highly specialized assistant with expertise in material sci-\nence natural language processing, specifically designed to assist users\nwith their queries. Your core principles are precision, honesty, and\nadherence to the provided context. You do not speculate or mention\nyour role. Greet users with: ‚ÄùWelcome to the MINDQUEST chatbot!\nI‚Äôm here to assist you with your material science-related questions.\n9\nFigure A.1: An example of the layout detection tool surya from the marker OCR model structuring the data into text, sections, tables, figures and equations (here,\n[43] reproduced with permission from IOP Publishing under a Creative Commons License).\nUpload your documents, and I‚Äôll do my best to provide precise and\nhelpful insights based on their content. Let‚Äôs get started!‚Äù When re-\nsponding to prompts, use only the provided information and conversa-\ntion history. If no data is provided, give the most appropriate answer\nbased on your knowledge but explicitly state that this information is\nnot retrieved from the provided database or uploaded documents. If\nthe data is incomplete or insu fficient, recommend uploading relevant\nMarkdown files for additional context. Always stay concise, focused,\nand factual, ensuring your responses are strictly within the scope of\nthe available data or clearly distinguish when external knowledge is\napplied.\nAppendix D. Example ofMINDQUEST chat bot\nQuestion 1: What is the di fference between molecular dy-\nnamics (MD) and discrete dislocation dynamics (DDD) sim-\nulations?\nAnswer 1:Molecular Dynamics (MD) and Discrete Dislocation Dy-\nnamics (DDD) are two distinct computational methods used to sim-\nulate the behavior of materials at di fferent scales. MD simulations\nare a type of molecular mechanics simulation that models the motion\nof atoms or molecules in a system. It is based on Newton‚Äôs laws of\nmotion and uses classical mechanics to describe the interactions be-\ntween particles. MD simulations are typically used to study the dy-\nnamics of small systems, such as molecules, nanoparticles, or bulk\nmaterials at the atomic scale. In an MD simulation, the positions and\nvelocities of individual atoms are updated at each time step using nu-\nmerical integration methods, such as Verlet integration or leapfrog al-\ngorithms. The interactions between atoms are described by potential\nenergy functions, such as Lennard-Jones or Morse potentials, which\ncapture the chemical bonding and interactions between atoms. DDD\nsimulations, on the other hand, are a type of computational model that\ndescribes the behavior of dislocations in materials. Dislocations are\nline defects in the crystal structure of a material that can move under\nstress, leading to plastic deformation or strain hardening. DDD simu-\nlations aim to capture the dynamics of dislocation motion and interac-\ntions with the surrounding material. In a DDD simulation, the mate-\nrial is discretized into a lattice of nodes, each representing a point in\nspace. Dislocations are modeled as line defects that can move through\nthe lattice, interacting with other dislocations and the surrounding ma-\nterial. The motion of dislocations is described using a set of equations\nthat balance the forces acting on them, such as stress, friction, and\nelastic interactions.\n**Key differences**:\n1. **Scale**: MD simulations are typically used to study small sys-\ntems at the atomic scale, while DDD simulations focus on larger sys-\ntems, such as bulk materials or engineering structures.\n2. **Time scale**: MD simulations can capture short-time dynam-\n10\nics (e.g., picosecond timescales), while DDD simulations often require\nlonger simulation times (e.g., milliseconds or seconds) to capture the\nlong-term behavior of dislocations.\n3. **Mechanisms**: MD simulations rely on classical mechanics\nand potential energy functions, whereas DDD simulations use a set of\nequations that balance forces acting on dislocations, including stress,\nfriction, and elastic interactions.\n4. **Complexity**: DDD simulations are generally more complex\nthan MD simulations due to the need to model the interactions be-\ntween dislocations and the surrounding material. In summary, while\nboth MD and DDD simulations aim to understand the behavior of ma-\nterials at different scales, they employ distinct approaches and mathe-\nmatical frameworks to capture the underlying physics.\nQuestion 2:What is the key concept of dislocation densities?\nAnswer 2:The key concepts are:\n1. **Dislocation Density:** The number of dislocations per unit vol-\nume of material.\n2. **Geometrically Necessary Dislocation (GND) Density:** The\nminimum dislocation density required to span the two endpoints of a\ndislocation line segment.\n3. **Statistically Stored Dislocation (SSD) Density:** A measure of\nthe dislocation density that is independent of the deformation state, but\nis randomly introduced and distributed in the material.\n4. **Total Dislocation Density:** The sum of GND and SSD densities.\nThe key points are:\n1. Dislocation density can be a ffected by various factors, including\ngrain size, strain rate, and temperature.\n2. Geometrically necessary dislocation density increases with increas-\ning strain and decreasing grain size.\n3. Statistically stored dislocation density is independent of the defor-\nmation state, but is randomly introduced and distributed in the mate-\nrial.\n4. The total dislocation density is a sum of GND and SSD densities.\nReferences\n[1] T. M. Pollock, R. LeSar, The feedback loop between theory, simulation\nand experiment for plasticity and property modeling, Current Opinion in\nSolid State and Materials Science 17 (1) (2013) 10‚Äì18. doi:10.1016/\nj.cossms.2013.03.003.\n[2] J. J. de Pablo, B. Jones, C. L. Kovacs, V . Ozolins, A. P. Ramirez, The\nmaterials genome initiative, the interplay of experiment, theory and com-\nputation, Current Opinion in Solid State and Materials Science 18 (2)\n(2014) 99‚Äì117. doi:10.1016/j.cossms.2014.02.003.\n[3] J. Wei, X. Chu, X. Sun, K. Xu, H. Deng, J. Chen, Z. Wei, M. Lei, Machine\nlearning in materials science, InfoMat 1 (3) (2019) 338‚Äì358. doi:10.\n1002/inf2.12028.\n[4] K. Choudhary, B. DeCost, C. Chen, A. Jain, F. Tavazza, R. Cohn, C. W.\nPark, A. Choudhary, A. Agrawal, S. J. L. Billinge, E. Holm, S. P. Ong,\nC. Wolverton, Recent advances and applications of deep learning methods\nin materials science, npj Computational Materials 8 (1) (Apr. 2022).doi:\n10.1038/s41524-022-00734-6 .\n[5] D. Morgan, R. Jacobs, Opportunities and challenges for machine learning\nin materials science, Annual Review of Materials Research 50 (1) (2020)\n71‚Äì103. doi:10.1146/annurev-matsci-070218-010015 .\n[6] K. Guo, Z. Yang, C.-H. Yu, M. J. Buehler, Artificial intelligence and ma-\nchine learning in design of mechanical materials, Materials Horizons 8 (4)\n(2021) 1153‚Äì1172. doi:10.1039/d0mh01451f.\n[7] A. Jain, Machine learning in materials research: Developments over the\nlast decade and challenges for the future, Current Opinion in Solid State\nand Materials Science 33 (2024) 101189. doi:10.1016/j.cossms.\n2024.101189.\n[8] A. S. Fuhr, B. G. Sumpter, Deep generative models for materials discov-\nery and machine learning-accelerated innovation, Frontiers in Materials 9\n(Mar. 2022). doi:10.3389/fmats.2022.865270.\n[9] Z. Wang, A. Chen, K. Tao, Y . Han, J. Li, Matgpt: A vane of materials\ninformatics from past, present, to future, Advanced Materials 36 (6) (Dec.\n2023). doi:10.1002/adma.202306733.\n[10] Y . Zhao, E. M. D. Siriwardane, Z. Wu, N. Fu, M. Al-Fahdi, M. Hu,\nJ. Hu, Physics guided deep learning for generative design of crystal mate-\nrials with symmetry constraints, npj Computational Materials 9 (1) (Mar.\n2023). doi:10.1038/s41524-023-00987-9 .\n[11] M. Manica, J. Born, J. Cadow, D. Christofidellis, A. Dave, D. Clarke,\nY . G. N. Teukam, G. Giannone, S. C. Ho ffman, M. Buchan, V . Chen-\nthamarakshan, T. Donovan, H. H. Hsu, F. Zipoli, O. Schilter, A. Kishi-\nmoto, L. Hamada, I. Padhi, K. Wehden, L. McHugh, A. Khrabrov, P. Das,\nS. Takeda, J. R. Smith, Accelerating material design with the generative\ntoolkit for scientific discovery, npj Computational Materials 9 (1) (May\n2023). doi:10.1038/s41524-023-01028-1 .\n[12] A. J. Lew, K. Jin, M. J. Buehler, Designing architected materials for\nmechanical compression via simulation, deep learning, and experimen-\ntation, npj Computational Materials 9 (1) (May 2023). doi:10.1038/\ns41524-023-01036-1 .\n[13] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, I. Polosukhin, Attention is all you need (2017). doi:10.\n48550/ARXIV.1706.03762.\n[14] G. Lei, R. Docherty, S. J. Cooper, Materials science in the era of large\nlanguage models: a perspective, Digital Discovery 3 (7) (2024) 1257‚Äì\n1272. doi:10.1039/d4dd00074a.\n[15] G. Yenduri, M. Ramalingam, G. C. Selvi, Y . Supriya, G. Srivastava,\nP. K. R. Maddikunta, G. D. Raj, R. H. Jhaveri, B. Prabadevi, W. Wang,\nA. V . Vasilakos, T. R. Gadekallu, Gpt (generative pre-trained trans-\nformer)‚Äî a comprehensive review on enabling technologies, potential\napplications, emerging challenges, and future directions, IEEE Access 12\n(2024) 54608‚Äì54649. doi:10.1109/access.2024.3389497.\n[16] Y .-C. Hsu, Z. Yang, M. J. Buehler, Generative design, manufacturing, and\nmolecular modeling of 3d architected materials based on natural language\ninput, APL Materials 10 (4) (Apr. 2022). doi:10.1063/5.0082338.\n[17] A. Chandrasekhar, J. Chan, F. Ogoke, O. Ajenifujah, A. Barati Fari-\nmani, Amgpt: A large language model for contextual querying in ad-\nditive manufacturing, Additive Manufacturing Letters 11 (2024) 100232.\ndoi:10.1016/j.addlet.2024.100232.\n[18] K. M. Jablonka, Q. Ai, A. Al-Feghali, S. Badhwar, J. D. Bocarsly, A. M.\nBran, S. Bringuier, L. C. Brinson, K. Choudhary, D. Circi, S. Cox, W. A.\nde Jong, M. L. Evans, N. Gastellu, J. Genzling, M. V . Gil, A. K. Gupta,\nZ. Hong, A. Imran, S. Kruschwitz, A. Labarre, J. L ¬¥ala, T. Liu, S. Ma,\nS. Majumdar, G. W. Merz, N. Moitessier, E. Moubarak, B. Mouri Àúno,\nB. Pelkie, M. Pieler, M. C. Ramos, B. Rankovi ¬¥c, S. G. Rodriques, J. N.\nSanders, P. Schwaller, M. Schwarting, J. Shi, B. Smit, B. E. Smith,\nJ. Van Herck, C. V ¬®olker, L. Ward, S. Warren, B. Weiser, S. Zhang,\nX. Zhang, G. A. Zia, A. Scourtas, K. J. Schmidt, I. Foster, A. D. White,\nB. Blaiszik, 14 examples of how llms can transform materials science\nand chemistry: a reflection on a large language model hackathon, Digital\nDiscovery 2 (5) (2023) 1233‚Äì1250. doi:10.1039/d3dd00113j.\n[19] S. Yu, N. Ran, J. Liu, Large-language models: The game-changers for\nmaterials science research, Artificial Intelligence Chemistry 2 (2) (2024)\n100076. doi:10.1016/j.aichem.2024.100076.\n[20] M. J. Buehler, Mechgpt, a language-based strategy for mechanics and\nmaterials modeling that connects knowledge across scales, disciplines,\nand modalities, Applied Mechanics Reviews 76 (2) (Jan. 2024). doi:\n10.1115/1.4063843.\n[21] A. Ghafarollahi, M. J. Buehler, Protagents: protein discovery via large\nlanguage model multi-agent collaborations combining physics and ma-\nchine learning, Digital Discovery 3 (7) (2024) 1389‚Äì1409. doi:10.\n1039/d4dd00013g.\n[22] I. B. . K. L. . A. Cohan, Scibert: A pretrained language model for sci-\nentific text, in: Proceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th International Joint Con-\nference on Natural Language Processing (EMNLP-IJCNLP), Association\nfor Computational Linguistics, 2019. doi:10.18653/v1/d19-1371.\n[23] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal,\n11\nH. K ¬®uttler, M. Lewis, W.-t. Yih, T. Rockt ¬®aschel, S. Riedel, D. Kiela,\nRetrieval-augmented generation for knowledge-intensive nlp tasks\n(2020). doi:10.48550/ARXIV.2005.11401.\n[24] L. Foppiano, G. Lambard, T. Amagasa, M. Ishii, Mining experimental\ndata from materials science literature with large language models: an\nevaluation study, Science and Technology of Advanced Materials: Meth-\nods 4 (1) (Jul. 2024). doi:10.1080/27660400.2024.2356506.\n[25] M. H. Prince, H. Chan, A. Vriza, T. Zhou, V . K. Sastry, Y . Luo, M. T.\nDearing, R. J. Harder, R. K. Vasudevan, M. J. Cherukara, Opportuni-\nties for retrieval and tool augmented large language models in scien-\ntific facilities, npj Computational Materials 10 (1) (Nov. 2024). doi:\n10.1038/s41524-024-01423-2 .\n[26] Digital science. (2018-) dimensions [software] available from\nhttps://app.dimensions.ai. accessed on 2024-07-11, under licence agree-\nment., https://app.dimensions.ai/discover/publication.\n[27] L. P. J. Gilligan, M. Cobelli, V . Taufour, S. Sanvito, A rule-free work-\nflow for the automated generation of databases from scientific litera-\nture, npj Computational Materials 9 (1) (Dec. 2023). doi:10.1038/\ns41524-023-01171-9 .\n[28] M. P. Polak, D. Morgan, Extracting accurate materials data from re-\nsearch papers with conversational language models and prompt engi-\nneering, Nature Communications 15 (1) (Feb. 2024). doi:10.1038/\ns41467-024-45914-8 .\n[29] M. Jalali, Y . Luo, L. Caulfield, E. Sauter, A. Nefedov, C. W¬®oll, Large lan-\nguage models in electronic laboratory notebooks: Transforming materials\nscience research workflows, Materials Today Communications 40 (2024)\n109801. doi:10.1016/j.mtcomm.2024.109801.\n[30] M. J. Buehler, Accelerating scientific discovery with generative knowl-\nedge extraction, graph-based representation, and multimodal intelligent\ngraph reasoning, Machine Learning: Science and Technology 5 (3) (2024)\n035083. doi:10.1088/2632-2153/ad7228.\n[31] M. J. Buehler, Cephalo: Multi-modal vision-language models for bio-\ninspired materials analysis and design, Advanced Functional Materials\n34 (49) (Sep. 2024). doi:10.1002/adfm.202409531.\n[32] C. Picard, K. M. Edwards, A. C. Doris, B. Man, G. Giannone, M. F. Alam,\nF. Ahmed, From concept to manufacturing: Evaluating vision-language\nmodels for engineering design (2023). doi:10.48550/ARXIV.2311.\n12668.\n[33] N. Bertin, R. B. Sills, W. Cai, Frontiers in the simulation of dislocations,\nAnnual Review of Materials Research 50 (1) (2020) 437‚Äì464. doi:10.\n1146/annurev-matsci-091819-015500 .\n[34] L. Blecher, G. Cucurull, T. Scialom, R. Stojnic, Nougat: Neural optical\nunderstanding for academic documents (2023). doi:10.48550/ARXIV.\n2308.13418.\n[35] D. Weygand, L. Friedman, E. van der Giessen, A. Needleman, Discrete\ndislocation modeling in three-dimensional confined volumes, Materials\nScience and Engineering: A 309-310 (2001) 420‚Äì424. doi:10.1016/\ns0921-5093(00)01632-4.\n[36] B. Katzer, K. Zoller, D. Weygand, K. Schulz, Identification of dislocation\nreaction kinetics in complex dislocation networks for continuum model-\ning using data-driven methods, Journal of the Mechanics and Physics of\nSolids (2022) 105042doi:10.1016/j.jmps.2022.105042.\n[37] S.-H. Lee, K. Schulz, A data-based derivation of the internal stress in\nthe discrete-continuum transition regime of dislocation based plasticity,\nInternational Journal of Plasticity 170 (2023) 103771. doi:10.1016/j.\nijplas.2023.103771.\n[38] B. Katzer, D. Betsche, K. B ¬®ohm, D. Weygand, K. Schulz, A graph\ndatabase for feature characterization of dislocation networks, Scripta\nMaterialia 240 (2024) 115841. doi:10.1016/j.scriptamat.2023.\n115841.\n[39] K. Schulz, L. Wagner, C. Wieners, A mesoscale continuum approach of\ndislocation dynamics and the approximation by a runge-kutta discontinu-\nous galerkin method, International Journal of Plasticity 120 (2019) 248‚Äì\n261. doi:10.1016/j.ijplas.2019.05.003.\n[40] M. Sudmanns, J. Bach, D. Weygand, K. Schulz, Data-driven explo-\nration and continuum modeling of dislocation networks, Modelling and\nSimulation in Materials Science and Engineering 28 (6) (2020) 065001.\ndoi:10.1088/1361-651x/ab97ef.\n[41] K. Zoller, S. Kal ¬¥acska, P. D. Isp¬¥anovity, K. Schulz, Microstructure evolu-\ntion of compressed micropillars investigated by in situ HR-EBSD analysis\nand dislocation density simulations, Comptes Rendus. Physique 22 (S3)\n(2021) 267‚Äì293. doi:10.5802/crphys.55.\n[42] B. Katzer, D. Betsche, F. von Hoegen, B. Jochum, K. B ¬®ohm, K. Schulz,\nCombining simulation and experimental data via surrogate modelling of\ncontinuum dislocation dynamics simulations, Modelling and Simulation\nin Materials Science and Engineering 32 (5) (2024) 055026. doi:10.\n1088/1361-651x/ad4b4c.\n[43] Y . Xu, D. S. Balint, D. Dini, A method of coupling discrete dislocation\nplasticity to the crystal plasticity finite element method, Modelling and\nSimulation in Materials Science and Engineering 24 (4) (2016) 045007.\ndoi:10.1088/0965-0393/24/4/045007.\n[44] W. Wang, F. Wei, L. Dong, H. Bao, N. Yang, M. Zhou, Minilm: Deep self-\nattention distillation for task-agnostic compression of pre-trained trans-\nformers (2020). doi:10.48550/ARXIV.2002.10957.\n[45] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,\nT. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez,\nA. Joulin, E. Grave, G. Lample, Llama: Open and e fficient foundation\nlanguage models (2023). doi:10.48550/ARXIV.2302.13971.\n[46] H. Liu, C. Li, Q. Wu, Y . J. Lee, Visual instruction tuning (2023). doi:\n10.48550/ARXIV.2304.08485.\n[47] A. Banerjee, S. Biswas, J. Llad ¬¥os, U. Pal, Semidocseg: harnessing semi-\nsupervised learning for document layout analysis, International Journal\non Document Analysis and Recognition (IJDAR) 27 (3) (2024) 317‚Äì334.\ndoi:10.1007/s10032-024-00473-y .\n[48] T. Kocmi, C. Federmann, Large language models are state-of-the-art\nevaluators of translation quality (2023). doi:10.48550/ARXIV.2302.\n14520.\n[49] J. Wang, Y . Liang, F. Meng, Z. Sun, H. Shi, Z. Li, J. Xu, J. Qu, J. Zhou,\nIs chatgpt a good nlg evaluator? a preliminary study (2023). doi:10.\n48550/ARXIV.2303.04048.\n[50] J. Choi, B. Lee, Accelerating materials language processing with large\nlanguage models, Communications Materials 5 (1) (Feb. 2024). doi:\n10.1038/s43246-024-00449-9 .\n12",
  "topic": "Workflow",
  "concepts": [
    {
      "name": "Workflow",
      "score": 0.8262344598770142
    },
    {
      "name": "Materials science",
      "score": 0.6804905533790588
    },
    {
      "name": "Modal",
      "score": 0.638458251953125
    },
    {
      "name": "Data mining",
      "score": 0.3965158462524414
    },
    {
      "name": "Computer science",
      "score": 0.3151671886444092
    },
    {
      "name": "Database",
      "score": 0.19651535153388977
    },
    {
      "name": "Composite material",
      "score": 0.06745338439941406
    }
  ],
  "institutions": []
}