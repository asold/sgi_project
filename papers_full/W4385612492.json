{
  "title": "Efficient and accurate sequence generation with small-scale protein language models",
  "url": "https://openalex.org/W4385612492",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5092602131",
      "name": "Yaiza Serrano",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2970680934",
      "name": "Sergi Roda",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2570508278",
      "name": "Víctor Guallar",
      "affiliations": [
        "Institució Catalana de Recerca i Estudis Avançats",
        "Universitat Politècnica de Catalunya",
        "Barcelona Supercomputing Center"
      ]
    },
    {
      "id": "https://openalex.org/A2538704935",
      "name": "Alexis Molina",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5092602131",
      "name": "Yaiza Serrano",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2970680934",
      "name": "Sergi Roda",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2570508278",
      "name": "Víctor Guallar",
      "affiliations": [
        "Institució Catalana de Recerca i Estudis Avançats",
        "Universitat Politècnica de Catalunya",
        "Barcelona Supercomputing Center"
      ]
    },
    {
      "id": "https://openalex.org/A2538704935",
      "name": "Alexis Molina",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2519539312",
    "https://openalex.org/W3002774878",
    "https://openalex.org/W3189576964",
    "https://openalex.org/W2993866869",
    "https://openalex.org/W2973037624",
    "https://openalex.org/W2047199560",
    "https://openalex.org/W2996266725",
    "https://openalex.org/W3049656208",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3177500196",
    "https://openalex.org/W4205773061",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W2909727437",
    "https://openalex.org/W4288066876",
    "https://openalex.org/W2973049837",
    "https://openalex.org/W3186612807",
    "https://openalex.org/W3001279689",
    "https://openalex.org/W2943495267",
    "https://openalex.org/W4280491725",
    "https://openalex.org/W4283733033",
    "https://openalex.org/W4383550741",
    "https://openalex.org/W4317374308",
    "https://openalex.org/W2102461176",
    "https://openalex.org/W2884001105",
    "https://openalex.org/W2143210482",
    "https://openalex.org/W2112837356",
    "https://openalex.org/W2950954328",
    "https://openalex.org/W2048322438",
    "https://openalex.org/W4309506674",
    "https://openalex.org/W2140679639",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W3081168214",
    "https://openalex.org/W3129831491",
    "https://openalex.org/W2050077513",
    "https://openalex.org/W4327550249",
    "https://openalex.org/W3177828909",
    "https://openalex.org/W2031168104",
    "https://openalex.org/W2330799739",
    "https://openalex.org/W2129153475",
    "https://openalex.org/W1985588649",
    "https://openalex.org/W2133641393",
    "https://openalex.org/W2949223833",
    "https://openalex.org/W2144288821",
    "https://openalex.org/W2147993766",
    "https://openalex.org/W4281758439",
    "https://openalex.org/W4378509449"
  ],
  "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities in understanding contextual relationships, outperforming traditional methodologies in downstream tasks such as text generation and sentence classification. This success has been mirrored in the realm of protein language models (pLMs), where proteins are encoded as text via their amino acid sequences. However, the training of pLMs, which involves tens to hundreds of millions of sequences and hundreds of millions to billions of parameters, poses a significant computational challenge. In this study, we introduce a Small-Scale Protein Language Model (SS-pLM), a more accessible approach that requires training on merely millions of representative sequences, reducing the number of trainable parameters to 14.8M. This model significantly reduces the computational load, thereby democratizing the use of foundational models in protein studies. We demonstrate that the performance of our model, when fine-tuned to a specific set of sequences for generation, is comparable to that of larger, more computationally demanding pLM.",
  "full_text": null,
  "topic": "Language model",
  "concepts": [
    {
      "name": "Language model",
      "score": 0.7246811389923096
    },
    {
      "name": "Computer science",
      "score": 0.69766765832901
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.6149131059646606
    },
    {
      "name": "Sentence",
      "score": 0.6129501461982727
    },
    {
      "name": "Scale (ratio)",
      "score": 0.5500069856643677
    },
    {
      "name": "Sequence (biology)",
      "score": 0.512871265411377
    },
    {
      "name": "Artificial intelligence",
      "score": 0.45643723011016846
    },
    {
      "name": "Natural language processing",
      "score": 0.4328809976577759
    },
    {
      "name": "Realm",
      "score": 0.41969186067581177
    },
    {
      "name": "Biology",
      "score": 0.1422613263130188
    },
    {
      "name": "Programming language",
      "score": 0.14078658819198608
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Genetics",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2799803557",
      "name": "Barcelona Supercomputing Center",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I11932220",
      "name": "Institució Catalana de Recerca i Estudis Avançats",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I9617848",
      "name": "Universitat Politècnica de Catalunya",
      "country": "ES"
    }
  ]
}