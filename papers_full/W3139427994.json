{
    "title": "A Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers",
    "url": "https://openalex.org/W3139427994",
    "year": 2021,
    "authors": [
        {
            "id": null,
            "name": "Martin-Gutierrez, David",
            "affiliations": [
                "Universidad Politécnica de Madrid"
            ]
        },
        {
            "id": null,
            "name": "Hernandez-Penaloza, Gustavo",
            "affiliations": [
                "Universidad Politécnica de Madrid"
            ]
        },
        {
            "id": null,
            "name": "Hernandez, Alberto Belmonte",
            "affiliations": [
                "Universidad Politécnica de Madrid"
            ]
        },
        {
            "id": "https://openalex.org/A2921472308",
            "name": "Alvarez Federico",
            "affiliations": [
                "Universidad Autónoma de Madrid"
            ]
        },
        {
            "id": "https://openalex.org/A4224913905",
            "name": "Lozano-Diez, Alicia",
            "affiliations": [
                "Universidad Politécnica de Madrid"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6734560207",
        "https://openalex.org/W6769627184",
        "https://openalex.org/W6766093455",
        "https://openalex.org/W6766257885",
        "https://openalex.org/W3045661091",
        "https://openalex.org/W2197429038",
        "https://openalex.org/W6674330103",
        "https://openalex.org/W2912652191",
        "https://openalex.org/W2999057584",
        "https://openalex.org/W6701650085",
        "https://openalex.org/W6766431954",
        "https://openalex.org/W4289253852",
        "https://openalex.org/W2263846226",
        "https://openalex.org/W6768392504",
        "https://openalex.org/W6755207826",
        "https://openalex.org/W2252215182",
        "https://openalex.org/W3095319910",
        "https://openalex.org/W6784219820",
        "https://openalex.org/W2962712142",
        "https://openalex.org/W2769951052",
        "https://openalex.org/W2900946789",
        "https://openalex.org/W2963806301",
        "https://openalex.org/W6752788575",
        "https://openalex.org/W2937269099",
        "https://openalex.org/W3039554467",
        "https://openalex.org/W2999639446",
        "https://openalex.org/W6751212204",
        "https://openalex.org/W2943595643",
        "https://openalex.org/W2072715695",
        "https://openalex.org/W2949303037",
        "https://openalex.org/W6763485134",
        "https://openalex.org/W3037924975",
        "https://openalex.org/W2997788455",
        "https://openalex.org/W2890498216",
        "https://openalex.org/W2990592856",
        "https://openalex.org/W2920898473",
        "https://openalex.org/W6638667902",
        "https://openalex.org/W2941002834",
        "https://openalex.org/W6773946081",
        "https://openalex.org/W3042631625",
        "https://openalex.org/W2910363199",
        "https://openalex.org/W2907352650",
        "https://openalex.org/W6728346077",
        "https://openalex.org/W2963614864",
        "https://openalex.org/W2963062084",
        "https://openalex.org/W2095705004",
        "https://openalex.org/W3137695714",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2800016038",
        "https://openalex.org/W2595521492",
        "https://openalex.org/W3098249847",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W3029869744",
        "https://openalex.org/W4302375066",
        "https://openalex.org/W2965154709",
        "https://openalex.org/W2573614998",
        "https://openalex.org/W2949117887",
        "https://openalex.org/W3102083609",
        "https://openalex.org/W2946119234",
        "https://openalex.org/W2964862362",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W3094319843",
        "https://openalex.org/W2965390613",
        "https://openalex.org/W3007508788",
        "https://openalex.org/W2980282514",
        "https://openalex.org/W3082274269",
        "https://openalex.org/W1836465849",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W3106311261",
        "https://openalex.org/W2963304263",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W3166902147",
        "https://openalex.org/W2531002484",
        "https://openalex.org/W2880875857"
    ],
    "abstract": "© 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "full_text": "Received February 14, 2021, accepted March 14, 2021, date of publication March 24, 2021, date of current version April 14, 2021.\nDigital Object Identifier 10.1 109/ACCESS.2021.3068659\nA Deep Learning Approach for Robust Detection\nof Bots in Twitter Using Transformers\nDAVID MARTÍN-GUTIÉRREZ\n 1, (Member, IEEE),\nGUSTAVO HERNÁNDEZ-PEÑALOZA\n 1, (Member, IEEE),\nALBERTO BELMONTE HERNÁNDEZ\n 1, (Member, IEEE),\nALICIA LOZANO-DIEZ\n 2, AND FEDERICO ÁLVAREZ\n1, (Member, IEEE)\n1Visual Telecommunication Applications Group, Signals, Systems and Radio Communications (SSR) Department, Universidad Politécnica de Madrid,\n28040 Madrid, Spain\n2AUDIAS–Audio Data Intelligence and Speech, Universidad Autónoma de Madrid, 28049 Madrid, Spain\nCorresponding author: David Martín-Gutiérrez (dmz@gatv.ssr.upm.es)\nThis work was supported by the H2020 European Project: FAke News discovery and propagation from big Data ANalysis and artiﬁcial\nintelliGence Operations (FANDANGO) under Grant 780355.\nABSTRACT During the last decades, the volume of multimedia content posted in social networks has\ngrown exponentially and such information is immediately propagated and consumed by a signiﬁcant\nnumber of users. In this scenario, the disruption of fake news providers and bot accounts for spreading\npropaganda information as well as sensitive content throughout the network has fostered applied research\nto automatically measure the reliability of social networks accounts via Artiﬁcial Intelligence (AI). In this\npaper, we present a multilingual approach for addressing the bot identiﬁcation task in Twitter via Deep\nlearning (DL) approaches to support end-users when checking the credibility of a certain Twitter account.\nTo do so, several experiments were conducted using state-of-the-art Multilingual Language Models to\ngenerate an encoding of the text-based features of the user account that are later on concatenated with the\nrest of the metadata to build a potential input vector on top of a Dense Network denoted as Bot-DenseNet.\nConsequently, this paper assesses the language constraint from previous studies where the encoding of the\nuser account only considered either the metadata information or the metadata information together with some\nbasic semantic text features. Moreover, the Bot-DenseNet produces a low-dimensional representation of the\nuser account which can be used for any application within the Information Retrieval (IR) framework.\nINDEX TERMSArtiﬁcial intelligence, bot detector, deep learning, feature representation, language models,\nmisinformation detection, social media mining, transfer learning, transformers.\nI. INTRODUCTION & MOTIVATION\nIn recent years, social media platforms such as Twitter or\nFacebook have gained a large level of both popularity and\ninﬂuence among millions of users due to the beneﬁts of pub-\nlishing, propagating and exchanging large volumes of multi-\nmedia content along the network. Therefore, these platforms\nallow users to establish a digital community as remarked\nin [22], which has made possible not only to discover and\nembrace new relationships but to maintain and boost existing\nones.\nOn the other hand, due to both the great inﬂuence these\nplatforms have on the lifestyle of people and its evolving\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Weiping Ding\n.\nas a potential communication tool, they have exponentially\npromoted its attraction for marketing and commercial pur-\nposes by analysing the behaviour and opinion of users in\ndifferent topics or events such as political elections. Conse-\nquently, numerous research studies have been fostered in the\nsocial media ﬁeld with different purposes including sentiment\nanalysis [35], trafﬁc control [48], or consumer behaviour\nmining [4].\nHowever, the considerable growth of social media plat-\nforms has also provoked the desire of altering people’s opin-\nion in certain topics by spreading propaganda or bias infor-\nmation. Many of these controlling procedures are carried\nout by Bots which are widely described in numerous inves-\ntigations [31], [32], [40] such as automatic systems which\nare capable of generating and spreading multimedia content\nVOLUME 9, 2021 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 54591\nD. Martín-Gutiérrezet al.: Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers\nthroughout the network without the supervision of a human\nbeing.\nFurthermore, with the disruptive growth of Artiﬁcial\nIntelligence (AI) algorithms, the identiﬁcation of bots or\nnon-reliable sources has become a crucial challenge to be\ninvestigated. It raised many studies and publications with\nthe goal of building robust automatic systems to improve\nthe quality of experience of consumers in such platforms\nby reducing their privacy risks as well as increasing the\ntrustworthiness on the platform itself at the same time.\nTherefore, this paper aims to contribute to the state-of-the-\nart in this ﬁeld by proposing a novel method for automatically\n(i) encoding an input user account as a low-dimensional\nfeature vector independently of its language,\n(ii) identifying the input encoding vector as a suspicious bot\naccount with a certain probability throughout a Deep\nNeural Network (DNN) referred as Bot-DenseNet.\n(iii) generating a low-dimensional embedding which rep-\nresents the original input encoding vector of the user\naccount and which can be used for any other purpose\nrelated to Information Retrieval (IR).\nMore speciﬁcally, our study is focused on identifying Bot\naccounts in Twitter by considering three main aspects of the\naccount: its activity level, popularity and proﬁle information.\nThe global set of features can be separated into two modal-\nities including metadata and text-based descriptors, where\nthe latter set is encoded via novel Language Model Embed-\ndings (LME) to mitigate the language constraint suffered in\nprevious studies.\nThe remainder of this paper is organized as follows: in\nSection II, previous studies and investigations within the Bot\nidentiﬁcation framework are described. Section III outlines\nthe main components involved in the proposed multilingual\napproach including Section III-A to describe the generation\nof the input encoding vector and Section III-B which summa-\nrizes the proposed architecture of the proposed Bot-DenseNet\nmodel. Afterwards, Section IV presents the distinct experi-\nments conducted as well as the outcomes and breakthroughs\nreached. Finally, the general conclusions and future work are\nsummarized in Section V.\nII. RELATED WORK\nRecently, AI techniques including Deep Learning (DL) and\nMachine Learning (ML) methods have gained popularity and\ninterest in many applied research and industry services related\nto social media analysis where, sentiment analysis and text\nclassiﬁcation have been the central focus of these inves-\ntigations specially for searching engines or recommender\nsystems.\nMore speciﬁcally, the essence of sentiment analysis con-\nsists in extracting an aspect term of an input sentence to deter-\nmine its polarity as positive, neutral and negative as authors\nremark in [8] and it is generally solved as a multi-class clas-\nsiﬁcation problem. Moreover, sentiment analysis has widely\nbeen used in numerous studies for both reviews and user\nopinions analysis in online commercial platforms [16], [47]\nand user behaviour mining in social media platforms such as\nTwitter [6], [29], [37], [42].\nFurthermore, the continuous growth of the social media\nplatforms such as Twitter or Facebook in the last decade along\nwith the considerable propagation of non-trusted information\nthroughout them, have raised applied research to automati-\ncally identify these non-trusted sources which in many cases\ncorrespond to non-human or Bot accounts. One of the ﬁrst\nstudies in this ﬁeld was proposed by [9] and it was based\non a random forest approach to classify bots and non-bots\naccounts using a manually annotated dataset with around\n2000 samples. In 2016, BotOrNot was proposed in [12] as\na service to automatically detect bots in Twitter using sim-\nilarities between characteristics of social bots. This model\nhas inspired posterior investigations in this ﬁeld that even\nemployed this service to automatically annotate data from\nTwitter.\nIn [11], authors annotated more than 8000 accounts and\nproposed a classiﬁer which achieved a considerable level of\naccuracy for such set of samples. Additionally, [38] presented\na model for Twitter bot detection based on a large number of\nmetadata from the account to perform the classiﬁcation.\nMore recently, several scientiﬁc studies have incorpo-\nrated more annotated samples to support this research such\nas [27], [44], [45] including some procedures for achieving\nbetter level of accuracy by strategically selecting a subset of\ntraining samples that better generalize the problem. In [22],\na language-agnostic approach is employed to identify poten-\ntial features to distinguish between human and bot accounts.\nThe model is then trained and validated using over 8000 sam-\nples distributed in an unbalanced fashion and its performance\nreaches an accuracy of 98%.\nMoreover, authors in [32] proposed a 2D Convolutional\nNetwork model based on user-generated contents for detect-\ning bots from human accounts including its gender (male,\nfemale account) covering both Spanish and English lan-\nguages. A similar goal is explored by authors in [40], where\nboth Word and Character N-Grams are employed as main\nfeatures to perform the classiﬁcation.\nA different manner of addressing the problem was recently\nproposed by authors in [5], where novel altmetrics data to\ninvestigate social networks are analysed and they are used to\ntrain a Graph Convolutional Network (GCN) which reaches\nover 70% of accuracy in this task. On the other hand, authors\nin [34] presented a novel one-class classiﬁer to enhance Twit-\nter bot detection without any requiring previous information\nabout them.\nMost of the aforementioned approaches were limited due\nto lack of large volumes of annotated data for this speciﬁc\ntask by the time their experiments were conducted. This\nproblem is also remarked in [45] and thus, this paper has\nconsidered all the available public datasets in the current days\nin order to build the system with the most updated, newest and\nrelevant state-of-the-art annotated data from Twitter. Addi-\ntionally, although many approaches employ both metadata\n54592 VOLUME 9, 2021\nD. Martín-Gutiérrezet al.: Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers\nand text-based features from the user accounts, the text-based\nfeatures are either extracted at a lexical level or they only\ncover a limited number of languages such as Spanish or\nEnglish.\nUnlike previous studies, our proposed model encodes all\nthe text-based features of an input user account via novel\nmultilingual Language Models (LM) including transformer\nmodels such as the so-called BERT [14] or Contextual string\nembeddings proposed in [2]. Thus, by concatenating both\nthe metadata set of features along with the output vector\nprovided by these LMs, an input vector of the user account\nis obtained. Finally, this paper proposes a Dense-based\nDL model to produce both the ﬁnal decision of the account\nand a low-dimensional embedding of the user based on the\naforementioned input vector.\nIII. A MULTILINGUAL APPROACH FOR USER ACCOUNT\nENCODING VIA TRANSFORMERS\nAs it was introduced in previous sections, our system con-\nsists in a multilingual approach capable of better identify\nsuspicious Twitter accounts based on a set of features inde-\npendently of the language of the account. More speciﬁcally,\nthe methodology of building the whole system can be dis-\ntributed in two separate processes: (i) a preprocessing stage\nwhere a multilingual input vector of the user account is gen-\nerated and (ii) a ﬁnal decision system for identifying whether\nthe account has a normal or abnormal behaviour according\nto existence patterns in the input vector generated during the\nﬁrst stage.\nMoreover, the former process is responsible for retrieving\na large collection of annotated Twitter accounts in a binary\nfashion, where the positive class indicates that the account is\nBot whereas the negative class means that it belongs to the\nhuman account category. Subsequently, several features were\ncollected from each Twitter account to enhance some relevant\naspects including:(i) Level of activity, (ii) Level of popularity,\n(iii) Proﬁle information.\nFinally, this ﬁrst stage ends by combining all the features to\ngenerate an input vector with both textual and metadata infor-\nmation for each Twitter account. Section III-A describes the\nfull process to provide all the details of the implementation.\nThe latter process, described in Section III-B, is in charged\nof automatically identifying patterns in the input encoding\nvector to properly distinguish between bots and human Twit-\nter accounts via Deep Neural Networks (DNNs). Moreover,\nthis process automatically obtains a low-dimensional feature\nrepresentation of the input vector which can be used for any\nIR purpose in a more efﬁcient way due to its low-dimensional\nnature.\nA. MULTILINGUAL USER ENCODING VIA TRANSFORMERS\nAs introduced in Section III, a ﬁrst process is needed to\ncombine distinct relevant aspects from Twitter accounts to\nbuild a solid multilingual encoding representation which\ncan be used as potential inputs for classiﬁcation purposes\nthroughout DNNs.\nIn Figure 1, an illustrative block diagram of this process\nis presented to show the different tools and stages needed to\nachieve the objectives of this ﬁrst phase of the system.\nMore speciﬁcally, a ﬁrst stage to retrieve all the data from\nthe set of users U is performed via Twitter API. 1 Subse-\nquently, each account is represented as a vector considering\ntwo modalities: text-based and metadata features. The former\nset is passed through a multilingual pre-trained LM model to\nobtain a feature vector representation of the text information\nincluding the description, the username of the account as well\nas the language of the account. The latter set of features is\ndirectly passed forward to the ﬁnal stage which is a concate-\nnation of both modalities into a single feature vector x, which\nencodes the information of an input user account.\n1) DATASET GENERATION\nThere are several public datasets to address the bot iden-\ntiﬁcation problem from a binary classiﬁcation perspective\nas the ones presented in Table 1. Moreover, some of these\ndatasets were already used to train and evaluate the so-called\nBotometer (formerly BotOrNot) service proposed by [12].\nHowever, as authors described in [7], [28], the generation\nof bot accounts continuously changes over time and addi-\ntionally, some of the provided accounts have been already\nsuspended by Twitter. Thus, a preprocessing is needed to\nimprove the usability of this large collection of datasets by\nremoving the identiﬁers those accounts that were already\nremoved by Twitter. This aspect is also critical since several\nprevious Bot detectors have not been updated with the new\ntendencies and features that bots accounts may currently\nhave, so that, they are no longer as reliable as they used to be.\nOn the other hand, due to policy restriction terms from\nTwitter, the datasets only contain the identiﬁer of the Twit-\nter account but not any signiﬁcant feature. Consequently,\nan additional data crawling process via the Twitter API is\nperformed to gather further information about the available\naccounts which is needed for the analysis. As introduced in\nSection III, the following information is collected:\n• Popularity features including total number of both\nfriends and followers,\n• Activity features including the following ﬁelds: creation\ndate, average tweets per day, tweets & favourites counts,\naccount age.\n• Proﬁle information features including: screen name,\ndescription, language, location, veriﬁed indicator,\ndefault proﬁle indicator.\nAfter crawling and preprocessing the data, the ﬁnal com-\nplete dataset is composed of 37438 Twitter accounts, where\n25013 were annotated as human accounts and the remaining\n12425 are bots.\n2) INPUT USER ENCODING GENERATION\nThe crucial part of this ﬁrst stage lies in the generation of an\nuser encoding vector based on the aforementioned collection\n1https://developer.twitter.com/en/docs/twitter-api\nVOLUME 9, 2021 54593\nD. Martín-Gutiérrezet al.: Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers\nFIGURE 1. A block diagram regarding the process of extracting multilingual encoding representations of user accounts in Twitter.\nTABLE 1. List of datasets employed when conducting the experiments of\nthis study.\nof features to serve as input of the proposed deep learn-\ning model. In previous related studies [7], [12], [13], [20],\nthe proposed solutions had two main constraints: 1) either\nthey were metadata-oriented approaches so that, the tex-\nt-based features were extracted at a semantic-level in terms\nof Natural Language Processing, or 2) they employed more\nadvanced NLP procedures based on N-grams or DL solutions\nbut they only supported a limited number of languages when\nperforming the analysis.\nHowever, our proposal addresses the aforementioned con-\nstraints by combining relevant metadata features along with\npowerful models capable of transforming text-based features\ninto vectors independently of the language of the input text.\nMore speciﬁcally, given an input set of Users U =\n{u1, u2, . . . ,um}, a certain user account is represented as\nui = [ut\ni , uz\ni ] ∀i = 1, . . . ,m where ut\ni indicates its\ntext-based feature vector whereas uz\ni represents the remain-\ning metadata-based vector. Our proposed solution employs\na mapping function f (u) to generate a new set of Users\n˙U ={˙u1, ˙u2, . . . ,˙um}, where ˙ui =f (ui) =g(ut\ni ) ||h(uz\ni ).\nIn this case, we denote ||to indicate a concatenation operation\nbetween this pair of vectors. The reason behind using a con-\ncatenation layer at the end of this process lies in the fact that\nthe system only consider information coming from the same\ntarget object: the user account. Other alternatives widely used\nin Collaborative Recommender Systems such as computing\nthe outer product [19] were not consider for this approach\nsince in those scenarios, the information from the embeddings\ncomes from two different sources: Users and Items, and the\ngoal of the outer product is thus, to catch similarities and\ndiscrepancies between this two sets.\n3) ENCODING TEXT-BASED FEATURES\nRegarding the generation of the text-based vector from an\ninput user account ui, a certain function g(u) is needed. Dif-\nferent state-of-the-art sentence-level encoders from several\nNLP frameworks were explored and investigated. In par-\nticular, the so-called Flair framework described in [2]\nwas employed to combine state-of-the-art Word Embed-\ndings (WE) and Transformers [39], [43] for extracting robust\ndocument embeddings from the text-based features. More\nprecisely, the following main families of embeddings have\nbeen employed in this study:\n(i) Contextual string embeddings [3] which are trained\nwithout any explicit notion of words and therefore,\nwords are modelled as sequences of characters. More-\nover, words are contextualized by the surrounding text.\nThe employed model was trained using the so-called\nJW300 Dataset described in [1]. In this study, both\nmulti-forward and multi-backward embeddings are\nused. The dimension of their outputs is equal to 2048.\n(ii) BERT (Bidirectional Encoder Representations from\nTransformers) embeddings which were proposed and\ndeveloped by [14] and are based on a bidirectional\n54594 VOLUME 9, 2021\nD. Martín-Gutiérrezet al.: Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers\ntransformer architecture [39], [43]. In this study, the so-\ncalled bert-base-multilingual-cased has been employed.\n(iii) RoBERTa which is an adaptive version of the BERT\nembedding where the goal is to improve the performance\nin longer sequences, or when there are vast volumes\nof data as [41] suggests. In this case, we employed the\nso-called roberta-large-mnli pre-trained model.\nFurthermore, several experiments were conducted consid-\nering three different solutions. The ﬁrst approach is based on\nusing one or multiple stacked embeddings similarly to the\napproach proposed by [25] so that, all the text-based features\nfrom the user account are encoded at a sentence-level rep-\nresentation. Subsequently, a document-level representation is\ncomputed via a Pooling model, where an average of all the\nstacked sentence-level embeddings was calculated.\nThe second approach regards the training of a Long\nShort-Term Memory (LSTM) recurrent network over all the\nword embeddings used to generate the sentence-level encod-\ning. Finally, the last approach directly uses an intermediate\nlayer from a pre-trained Transformer model, to produce the\ndocument-level embedding.\nMoreover, both the multilingual BERT transformer\npre-trained model named as BERT-base-multilingual-cased\nand the RoBERTa pre-trained model named as roberta-large-\nmnli have been employed. More speciﬁcally, the former gen-\nerates a 768-dimensional embedded vector whereas the latter\nproduces a 1024 embedded representation. All the details of\nthe aforementioned pre-trained models can be found at the\nofﬁcial Hugging Face repository. 2\n4) ENCODING METADATA-BASED FEATURES\nOn the other hand, all the corresponding metadata features\nfrom an input user account are properly preprocessed and\nencoded throughout function h(uz\ni ) to be interpreted by neu-\nral networks. In addition, they are concatenated along with\nthe aforementioned text-based features as it is remarked in\nSection III-A.\nIn particular, this set of features includes all the information\nrelated to both the popularity and the activity of the user\naccount.\nB. BOT-DenseNet\nOnce the set of input user vectors denoted by ˙U is obtained,\na second process is required to automatically identify an\naccount as bot or human.\nTo address this goal, we propose a Deep Fully-connected-\nbased neural network named as Bot-DenseNet, which is capa-\nble of ﬁnding robust decision boundaries based on hidden\npatterns of the input vectors to better recognize bot accounts\nin Twitter. The details of the model implementation including\nclassical parameters in neural networks such as activation\nfunctions, number of neurons in the hidden layers or the\nselected optimizers to perform the backpropagation and the\nGradient Descent algorithm are summarized in Table 2. One\n2https://huggingface.co/transformers/\nTABLE 2. List of parameters involved in the design of theBot-DenseNet\nmodel. # indicates the total number.\nof the main differences from previous studies is the incorpora-\ntion of the so-called Scaled Exponential Linear Unit (SELU)\nsimilarly to the approach proposed at [23] which obtains\nbetter results than the classical ReLU activation function.\nOn the other hand, the architecture of the system, presented\nin Figure 2, is composed of a set of blocks including Dense +\nBatch Normalization +Activation +Dropout layers in a\nsequential fashion as usual in general dense-based models.\nFurthermore, the inclusion of a Batch Normalization layer\nwithin the architecture lies in previous studies such as the one\ndescribed in [10], [21], where authors proved that the training\nperformance indeed improves when using such normalization\nsince this layer provides many beneﬁts including a faster\nconvergence as it allows to employ higher learning rates\nduring the Gradient descent algorithm.\nThe aforementioned hyper-parameters were carefully\nselected after conducting several heuristic experiments in\norder to design a model with the best performance in terms\nof F1-score.\nIV. EXPERIMENTAL RESULTS\nOne of the main objectives of this paper relies on analysing,\nvia an ablation study, different input feature vectors based\non Transformers as well as additional novel approaches to\ninvestigate the performance of the same DNN model.\nMoreover, The DL architecture was trained in the classical\nsupervised learning fashion considering a binary classiﬁ-\ncation where the Positive class refers to Bots whereas the\nNegative corresponds to Human accounts.\nDue to the unbalanced constraint of the dataset, two main\nsteps have been followed: (i) the so-called Stratify sampling\nupdated in [26] has been employed to force having samples\nfrom both classes during the training and evaluation of the\nsystem, (ii) the F1-score metric as the main measurement of\nthe performance of the system since it balances both precision\nand recall metrics in a single value and provides more realistic\ninformation about the capability of the model to detect both\nPositive and Negative classes than the classical accuracy\nmetric.\nMoreover, to mitigate the classical overﬁtting problem,\nwhich happens when the neural network is not capable of\ngeneralizing properly for unseen samples, two main widely\nused techniques have been incorporated: (i) Dropout ﬁrstly\nproposed in [36], which pursues the aim of deactivating some\nVOLUME 9, 2021 54595\nD. Martín-Gutiérrezet al.: Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers\nFIGURE 2. A block diagram representation of the proposed architectureBot-DenseNet, where the yellow block indicates the input layer, the blue one\nregards the hidden layers and finally, the green one indicates the output layer.\nTABLE 3. Outcomes of the experiments conducted to train ourBot-DenseNet using different input feature vectors which were generated as the\nconcatenation of both a metadata feature vector and a text embedding.\nneurons randomly at each epoch with a certain probability;\n(ii) Early Stopping, fully described in [46], which attempts\nto stop the training process whenever the performance on the\nvalidation set has no longer improved in a certain number of\nepochs. Therefore, a hyper-parameter is required to indicate\nthe number of consecutive epochs with no improvements in\nthe loss function or in the metrics considering the validation\nset, and it is usually named as patience.\nA. TRAINING & VALIDATING BOT-DenseNet\nThe aim of these experiments is to ﬁnd the most appropriate\ntext embedding to be added on top of the Bot-DenseNet along\nwith the remaining metadata feature vector in order to ﬁnd\noptimal decision boundaries for downstream tasks such as the\none presented in this paper.\nThe outcomes obtained during the training and valida-\ntion stages for all the possible input feature vectors are\nsummarized in Table 3. Since the dataset is not balanced,\nthe F1-score metric has a crucial role in the evaluation of\nthe system in order to objective measure the performance of\nidentifying bots in a social network such as Twitter where\nonly a few accounts from the total set of accounts belong\nindeed to the bot category as it is described in previous\nstudies [7], [27], [34]. In particular, since the model is\ntrained using an Early-Stopping callback to stop the pro-\ncess in the epoch when the loss function in the validation\nset is no longer decreasing, the F1-score was computed\nby using both the recall and the precision at this speciﬁc\nepoch.\nMoreover, in Table 3, each row indicates the pre-trained\nLM employed such as Flair, BERT, RoBERTa etc., as well\nas the approach followed to generate the ﬁnal input user\nencoding (via Pooling, bidirectional LSTM or directly the\nembedding obtained from an intermediate layer of the Trans-\nformer model). In particular, the results presented in Table 3\nreﬂect that when combining the text embeddings directly\nextracted from intermediate layers of the Transformers along\nwith the metadata features, the proposed model Bot-DenseNet\nachieves higher scores in terms of F1-score in both training\nand validation sets. On the other hand, when using either\nPooling or LSTMs to produce the ﬁnal text embeddings,\nthe F1-score metric in the training phase is higher than in\nthe validation phase which indicates that the model is suf-\nfering from overﬁtting. As a result, this issue may provoke\na decrease in the performance of the system when analysing\nunseen observations in future predictions.\nB. SELF-SUPERVISED USER EMBEDDING\nOur proposed model is capable of identifying suspicious\nTwitter accounts based on a robust set of input features.\nHowever, as it is well-known in the Deep Learning frame-\nwork, intermediate layers are usually an adequate embedded\nrepresentation of the inputs which can be employed in other\ndownstream tasks such as text classiﬁcation or similarity\nanalysis in a more efﬁcient way due to their low-dimensional\nnature. Thus, after training our proposed model, it produces\na relevant representation of an input Twitter account in a\nself-supervised fashion since such representation was auto-\nmatically learned by the intermediate hidden layers. Hence,\nBot-DenseNet can also be used to encode any user account\nas a 256-dimensional vector throughout its last intermediate\nlayer. To better visualize the ﬁnal embeddings obtained by\nthe last layers of the different models, a 2D projected repre-\nsentation of them were computed using the so-called T-SNE\nalgorithm, updated in [30] with a level of perplexity equal\nto 80.\nMore speciﬁcally, Figure 3 includes the embeddings as\na result of training the model using directly the pre-trained\nTransformers models whereas Figure 4 shows the outcomes\nwhen using different combinations of Word Embeddings\nalong with either Pooling or LSTMs on top of them to pro-\nduce the ﬁnal text vector.\n54596 VOLUME 9, 2021\nD. Martín-Gutiérrezet al.: Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers\nTABLE 4. An ablation study by comparing the complexity of the model in terms of both the feature vector length, the total number of parameters to be\ntrained as well as the F1-score achieved during the validation phase.\nMoreover, Figure 3 remarks the potential of Transformers\nin any downstream NLP tasks such the one presented in this\npaper where their intermediate layers have been employed\nto obtain robust representations of the text-based features of\nthe user accounts. As a consequence, they have increased the\ncapability of Bot-DenseNet to better distinguish between bots\nand human accounts in a more efﬁcient manner.\nFurthermore, Figure 3 shows that the boundaries deter-\nmined by both BERT and RoBERTa transformers without any\nadditional step to generate a text encoding (neither Pooling\nnor LSTMs) are simpler and more adequate than the ones\nprovided by combining different text embeddings which is\nsummarized in Figure 4. This fact is also presented in the\nF1-score metrics from Table 3, where it is clear that these\ntwo solutions are the ones which are not overﬁtting the data\nand thus, they are more suitable to be employed as top of our\nproposed Bot-DenseNet model.\nC. DECISION MAKING CRITERIA FOR BOT-DenseNet\nAfter conducting the aforementioned experiments, a ﬁnal\ndecision to select the best conﬁguration of the model\nis required. To do so, the following criteria have been\nconsidered:(i) The performance of the model in terms of\nF1-score in both training and validation to provide an objec-\ntive criteria when making the ﬁnal decision; (ii) The simplic-\nity of the model in terms of both trainable parameters and the\nlength of the input feature vector as it is remarked in Table 4;\n(iii) The simplicity of the ﬁnal decision boundaries to distin-\nguish between Bot and Human accounts which is assessed\nby observing the low-dimensional embeddings distribution\nin a TSNE projection. This aspect arises as crucial in order\nto propose a robust model capable of generalizing in future\napplications.\nThus, considering these elements for making the ﬁnal deci-\nsion both Table 4 as well as Figure 3 have been analysed to\nprovide an objective decision.\nFirstly, regarding performance, the best model is the one\nthat uses the so-called RoBERTa Transfomer on top of it\naccording to the F1-score achieved during the validation\nphase. Secondly, when it comes to simplicity, it is noticed\nthat the best approaches are the ones that have employed\nLSTMs during the generation of the input vectors but they\nhave achieved considerable lower results in terms of F1-score\nFIGURE 3. 2D projected representations of the embeddings obtained\nafter training the proposed DL modelBot-DenseNet using as inputs the\npre-trained embeddings from both BERT and RoBERTa models.\nand therefore, they were discarded from the further analy-\nsis. On the other hand, the family of approaches that have\nemployed a Pooling procedure are the ones with the highest\nlevel of complexity in terms of trainable parameters as well\nthe lowest performance based on the F1-score, thus, they were\ndirectly discarded from the ﬁnal decision.\nRegarding simplicity in terms of the samples distribution\nafter applying the TSNE method, Figures 4 and 3 shows that\nthe boundaries achieved when using Transformers as part of\nthe input feature vector are more suitable and simpler than the\nrest of conﬁgurations.\nVOLUME 9, 2021 54597\nD. Martín-Gutiérrezet al.: Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers\nFIGURE 4. A set of 2D projected representations of the embeddings obtained in the proposedBot-DenseNet via the so-called TSNE algorithm\nusing a value of perplexity equal to 80.\nConsequently, the ﬁnal model uses the so-called RoBERTa\ntransformer on top of it since it provides a remarkable\ntrade-off between precision and simplicity, which are critical\naspects to be considered when implementing Deep Learning\nmodels\nFinally, Table 5 shows a comparison between our pro-\nposed DL architecture in comparison with previous studies\nin terms of both the performance throughout the F1-score\nmetric, the learning approach as well as the capability of\nincorporating language-dependent features. This comparison\nenhances our proposed method in the following aspects:\n(i) Language-dependent features throughout the analysis of\ntext descriptors via Transformers to improve the input feature\nvector and thus, the robustness of the system when facing\nnon-English languages. (ii) Hybrid learning, since it pro-\nduces embeddings throughout its intermediate hidden layers\n(unsupervised learning) once the model has been trained\nusing a limited set of annotated data (supervised learning).\n54598 VOLUME 9, 2021\nD. Martín-Gutiérrezet al.: Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers\nTABLE 5. A comparison of previous studies along with the proposed\nBot-Dense model in terms of F1-Score, learning approach as well as its\ncapability for analysing text features from multiple languages.\n(iii) Promising scoring metrics in comparison with latest\nstudies.\nAll the details of the implementation as well as the code\nfor re-training or testing the proposed system can be found\nat this Github repository. More speciﬁcally, a Python library\nnamed as User2Vec was released to foster further research in\nthis ﬁeld.\nV. CONCLUSION & FUTURE WORK\nIn this paper, a robust solution for detecting Bots in Twitter\naccounts has been described. In particular, this study has\ntaken advantage of Transfer learning techniques via pow-\nerful state-of-the-art NLP models such as Transformers to\nextract compact multilingual representations of the text-based\nfeatures associated with user accounts. By doing so, several\nconstraints presented in previous studies related to process\ntext-based features to improve the input feature vector from\nmultiple languages were mitigated.\nFurthermore, by employing the text encodings along with\nadditional metadata on top of a dense-based neural network,\na ﬁnal classiﬁer named as Bot-DenseNet has been trained and\nvalidated using a large set of samples collected via the Twitter\nAPI. More speciﬁcally, several experiments were conducted\nusing different combinations of Word Embeddings, docu-\nment embeddings (Pooling and LSTMs) and Transformers\nto obtain a single vector regarding the text-based features\nof the user account. Subsequently, a detailed comparison of\nthe performance of the proposed classiﬁer when using these\napproaches of Language Models as part of the input has been\npresented to investigate which input vector provides the best\nresult in terms of performance simplicity in the generation of\ndecision boundaries and feasibility.\nIn particular, the comparison of these experiments sug-\ngested that the Bot-DenseNet achieves the most adequate\ntrade-off between performance and feasibility when using the\nso-called RoBERTa Transformer as part of the input feature\nvector.\nConsequently, this paper provides two main contribu-\ntions to the scientiﬁc community including a DL model for\nautomatically detecting bots as well as a robust manner of\nrepresenting any Twitter account as a low-dimensional fea-\nture vector throughout an intermediate layer of the aforemen-\ntioned model. Moreover, this compact representation of the\nTwitter account can be used as a baseline for recommender\nor search engines, similarity analysis or any other application\nrelated with social media mining.\nFinally, this study also remarks the outstanding perfor-\nmance of novel Transformers in downstream NLP tasks as\nthe one presented, by providing a more robust input vector\nwhich leads the ﬁnal classiﬁer model to be more capable\nof extracting relevant low-level features from it. As Future\nwork, the latest Transformers such as the GPT-3 [17] and\nT5 [33] will be considered for generating the input vector\nof the proposed DL model in order to compare the perfor-\nmance with the work described on this paper. Moreover,\nnovel approaches such the one described by authors in [24]\nto automatically generate non-parametric Two-Sample tests\nbased on the so-called Maximum Mean Discrepancy (MMD)\n[18], will be considered once all the user embeddings are\ngenerated, to ﬁnd discrepancies and similarities between the\ndistributions of both bots and non-bots embeddings.\nREFERENCES\n[1] Ž. Agić and I. Vulić, ‘‘JW300: A wide-coverage parallel corpus for low-\nresource languages,’’ in Proc. 57th Annu. Meeting Assoc. Comput. Linguis-\ntics. Florence, Italy: Association for Computational Linguistics, Jul. 2019,\npp. 3204–3210.\n[2] A. Akbik, T. Bergmann, D. Blythe, K. Rasul, S. Schweter, and A. V ollgraf,\n‘‘FLAIR: An easy-to-use framework for state-of-the-art NLP,’’ in Proc.\nConf. North Amer. Chapter Assoc. Comput. Linguistics, Demonstrations,\n2019, pp. 54–59.\n[3] A. Akbik, D. Blythe, and R. V ollgraf, ‘‘Contextual string embeddings for\nsequence labeling,’’ in Proc. 27th Int. Conf. Comput. Linguistics, 2018,\npp. 1638–1649.\n[4] A. S. M. Alharbi and E. de Doncker, ‘‘Twitter sentiment analysis with\na deep neural network: An enhanced approach using user behavioral\ninformation,’’Cogn. Syst. Res., vol. 54, pp. 50–61, May 2019.\n[5] N. R. Aljohani, A. Fayoumi, and S.-U. Hassan, ‘‘Bot prediction on social\nnetworks of Twitter in altmetrics using deep graph convolutional net-\nworks,’’Soft Comput., vol. 24, pp. 11109–11120, Jan. 2020.\n[6] M. Arora and V . Kansal, ‘‘Character level embedding with deep convo-\nlutional neural network for text normalization of unstructured data for\nTwitter sentiment analysis,’’Social Netw. Anal. Mining, vol. 9, no. 1, p. 12,\nDec. 2019.\n[7] A. Balestrucci, R. De Nicola, O. Inverso, and C. Trubiani, ‘‘Identiﬁcation\nof credulous users on Twitter,’’ in Proc. 34th ACM/SIGAPP Symp. Appl.\nComput., Apr. 2019, pp. 2096–2103.\n[8] A. Bhoi and S. Joshi, ‘‘Various approaches to aspect-based senti-\nment analysis,’’ 2018, arXiv:1805.01984. [Online]. Available: http://arxiv.\norg/abs/1805.01984\n[9] Z. Chu, S. Gianvecchio, H. Wang, and S. Jajodia, ‘‘Detecting automation of\nTwitter accounts: Are you a human, bot, or cyborg?’’ IEEE Trans. Depend.\nSec. Comput., vol. 9, no. 6, pp. 811–824, Nov./Dec. 2012.\n[10] T. Cooijmans, N. Ballas, C. Laurent, Ç. Gülçehre, and A. Courville,\n‘‘Recurrent batch normalization,’’ 2016, arXiv:1603.09025. [Online].\nAvailable: http://arxiv.org/abs/1603.09025\n[11] S. Cresci, R. Di Pietro, M. Petrocchi, A. Spognardi, and M. Tesconi,\n‘‘The paradigm-shift of social spambots: Evidence, theories, and tools for\nthe arms race,’’ in Proc. 26th Int. Conf. World Wide Web Companion, 2017,\npp. 963–972.\n[12] C. A. Davis, O. Varol, E. Ferrara, A. Flammini, and F. Menczer,\n‘‘BotOrNot: A system to evaluate social bots,’’ in Proc. 25th Int. Conf.\nCompanion World Wide, 2016, pp. 273–274.\n[13] A. Davoudi, A. Z. Klein, A. Sarker, and G. Gonzalez-Hernandez, ‘‘Towards\nautomatic bot detection in twitter for health-related tasks,’’ AMIA Summits\nTransl. Sci. Proc., vol. 2020, p. 136, May 2020.\n[14] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‘‘BERT: Pre-training\nof deep bidirectional transformers for language understanding,’’ 2018,\narXiv:1810.04805. [Online]. Available: http://arxiv.org/abs/1810.04805\n[15] J. Diesner, E. Ferrari, and G. Xu, in Proc. IEEE/ACM Int. Conf. Adv.\nSocial Netw. Anal. Mining. Sydney, NSW, Australia: ACM, Aug. 2017.\n[Online]. Available: https://dblp.org/rec/bib/conf/asunam/2017, doi:\n10.1145/3110025.\n[16] C. D. Santos and M. Gatti, ‘‘Deep convolutional neural networks for senti-\nment analysis of short texts,’’ in Proc. 25th Int. Conf. Comput. Linguistics\n(COLING), 2014, pp. 69–78.\n[17] L. Floridi and M. Chiriatti, ‘‘GPT-3: Its nature, scope, limits, and conse-\nquences,’’Minds Mach., vol. 30, pp. 681–694, Nov. 2020.\nVOLUME 9, 2021 54599\nD. Martín-Gutiérrezet al.: Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers\n[18] R. Gao, F. Liu, J. Zhang, B. Han, T. Liu, G. Niu, and M. Sugiyama,\n‘‘Maximum mean discrepancy is aware of adversarial attacks,’’ 2020,\narXiv:2010.11415. [Online]. Available: http://arxiv.org/abs/2010.11415\n[19] X. He, X. Du, X. Wang, F. Tian, J. Tang, and T.-S. Chua, ‘‘Outer product-\nbased neural collaborative ﬁltering,’’ 2018, arXiv:1808.03912. [Online].\nAvailable: http://arxiv.org/abs/1808.03912\n[20] J. Im, E. Chandrasekharan, J. Sargent, P. Lighthammer, T. Denby,\nA. Bhargava, L. Hemphill, D. Jurgens, and E. Gilbert, ‘‘Still out there:\nModeling and identifying Russian troll accounts on Twitter,’’ in Proc. 12th\nACM Conf. Web Sci., Jul. 2020, pp. 1–10.\n[21] S. Ioffe and C. Szegedy, ‘‘Batch normalization: Accelerating deep network\ntraining by reducing internal covariate shift,’’ 2015, arXiv:1502.03167.\n[Online]. Available: http://arxiv.org/abs/1502.03167\n[22] J. Knauth, ‘‘Language-agnostic Twitter-bot detection,’’ in Proc. Int. Conf.\nRecent Adv. Natural Lang. Process. (RANLP), 2019, pp. 550–558.\n[23] Z. Lin, S. Mu, F. Huang, K. A. Mateen, M. Wang, W. Gao, and\nJ. Jia, ‘‘A uniﬁed matrix-based convolutional neural network for ﬁne-\ngrained image classiﬁcation of wheat leaf diseases,’’ IEEE Access, vol. 7,\npp. 11570–11590, 2019.\n[24] F. Liu, W. Xu, J. Lu, G. Zhang, A. Gretton, and D. J. Sutherland,\n‘‘Learning deep Kernels for non-parametric two-sample tests,’’ 2020,\narXiv:2002.09116. [Online]. Available: http://arxiv.org/abs/2002.09116\n[25] Y . Liu, P. Dmitriev, Y . Huang, A. Brooks, and L. Dong, ‘‘An eval-\nuation of transfer learning for classifying sales engagement emails at\nlarge scale,’’ 2019, arXiv:1905.01971. [Online]. Available: http://arxiv.\norg/abs/1905.01971\n[26] P. Lynn, ‘‘The advantage and disadvantage of implicitly stratiﬁed\nsampling,’’ Methods, Data, Analyses, vol. 13, no. 2, p. 14,\n2019.\n[27] M. Mazza, S. Cresci, M. Avvenuti, W. Quattrociocchi, and M. Tesconi,\n‘‘RTbust: Exploiting temporal patterns for botnet detection on Twitter,’’ in\nProc. 10th ACM Conf. Web Sci., 2019, pp. 183–192.\n[28] A. Minnich, N. Chavoshi, D. Koutra, and A. Mueen, ‘‘BotWalk:\nEfﬁcient adaptive exploration of Twitter bot networks,’’ in Proc.\nIEEE/ACM Int. Conf. Adv. Social Netw. Anal. Mining , Jul. 2017,\npp. 467–474.\n[29] U. Naseem, I. Razzak, K. Musial, and M. Imran, ‘‘Transformer based deep\nintelligent contextual embedding for Twitter sentiment analysis,’’ Future\nGener. Comput. Syst., vol. 113, pp. 58–69, Dec. 2020.\n[30] M. Orliński and N. Jankowski, ‘‘Fast t-SNE algorithm with forest of\nbalanced LSH trees and hybrid computation of repulsive forces,’’ Knowl.-\nBased Syst., vol. 206, Oct. 2020, Art. no. 106318.\n[31] J. Pizarro, ‘‘Using N-grams to detect bots on Twitter,’’ in Proc. CLEF ,\nWorking Notes, 2019, pp. 1–10.\n[32] M. Polignano, M. G. de Pinto, P. Lops, and G. Semeraro, ‘‘Identiﬁcation\nof bot accounts in Twitter using 2D CNNs on user-generated contents,’’ in\nProc. CLEF , Working Notes, 2019, pp. 1–11.\n[33] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y . Zhou,\nW. Li, and P. J. Liu, ‘‘Exploring the limits of transfer learning with a uniﬁed\ntext-to-text transformer,’’J. Mach. Learn. Res., vol. 21, no. 140, pp. 1–67,\n2020.\n[34] J. Rodríguez-Ruiz, J. I. Mata-Sánchez, R. Monroy, O. Loyola-González,\nand A. López-Cuevas, ‘‘A one-class classiﬁcation approach for bot detec-\ntion on Twitter,’’ Comput. Secur., vol. 91, Apr. 2020, Art. no. 101715.\n[35] K. Shuang, H. Guo, Z. Zhang, J. Loo, and S. Su, ‘‘A word-building method\nbased on neural network for text classiﬁcation,’’ J. Exp. Theor. Artif. Intell.,\nvol. 31, no. 3, pp. 455–474, May 2019.\n[36] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and\nR. Salakhutdinov, ‘‘Dropout: A simple way to prevent neural networks\nfrom overﬁtting,’’ J. Mach. Learn. Res., vol. 15, no. 1, pp. 1929–1958,\n2014.\n[37] D. Stojanovski, G. Strezoski, G. Madjarov, and I. Dimitrovski,\n‘‘Twitter sentiment analysis using deep convolutional neural network,’’\nin Proc. Int. Conf. Hybrid Artif. Intell. Syst. Springer, 2015,\npp. 726–737. [Online]. Available: https://scholar.googleusercontent.\ncom/scholar.bib?q=info:HnIU7VyTzLUJ:scholar.google.com/& output=\ncitation&scisdr=CgXc4k0kELTt-pJoVlM:AAGBfm0AAAAAYGxtTlO0\nqf0SoEojztYZqYNU1uzAmqAp&sci sig=AAGBfm0AAAAAYGxtTlfX\nvsJzQ3eCFjVQwVDi0pipTQma&scisf=4&ct=citation&cd=-1&hl=es\n[38] O. Varol, E. Ferrara, C. A. Davis, F. Menczer, and A. Flammini,\n‘‘Online human-bot interactions: Detection, estimation, and charac-\nterization,’’ 2017, arXiv:1703.03107. [Online]. Available: http://arxiv.\norg/abs/1703.03107\n[39] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, ‘‘Attention is all you need,’’ in Proc. Adv.\nNeural Inf. Process. Syst., 2017, pp. 5998–6008.\n[40] I. V ogel and P. Jiang, ‘‘Bot and gender identiﬁcation in Twitter using word\nand character N-grams,’’ in Proc. CLEF , Working Notes, 2019, pp. 1–9.\n[41] B. Wang and C.-C. J. Kuo, ‘‘SBERT-WK: A sentence embedding method\nby dissecting bert-based word models,’’ 2020, arXiv:2002.06652. [Online].\nAvailable: http://arxiv.org/abs/2002.06652\n[42] L. Wang, J. Niu, and S. Yu, ‘‘SentiDiff: Combining textual information and\nsentiment diffusion patterns for Twitter sentiment analysis,’’ IEEE Trans.\nKnowl. Data Eng., vol. 32, no. 10, pp. 2026–2039, Oct. 2020.\n[43] T. Wolf et al., ‘‘HuggingFace’s transformers: State-of-the-art natu-\nral language processing,’’ 2019, arXiv:1910.03771. [Online]. Available:\nhttp://arxiv.org/abs/1910.03771\n[44] K. Yang, O. Varol, C. A. Davis, E. Ferrara, A. Flammini, and F. Menczer,\n‘‘Arming the public with artiﬁcial intelligence to counter social bots,’’\nHum. Behav. Emerg. Technol., vol. 1, no. 1, pp. 48–61, Jan. 2019.\n[45] K.-C. Yang, O. Varol, P.-M. Hui, and F. Menczer, ‘‘Scalable and generaliz-\nable social bot detection through data selection,’’ in Proc. AAAI Conf. Artif.\nIntell., vol. 34, 2020, pp. 1096–1103.\n[46] C. Zhang, S. Bengio, M. Hardt, B. Recht, and O. Vinyals,\n‘‘Understanding deep learning requires rethinking generalization,’’ 2016,\narXiv:1611.03530. [Online]. Available: http://arxiv.org/abs/1611.03530\n[47] S. Zhang, X. Xu, Y . Pang, and J. Han, ‘‘Multi-layer attention based\nCNN for target-dependent sentiment classiﬁcation,’’ Neural Process. Lett.,\nvol. 51, no. 3, pp. 2089–2103, Jun. 2020.\n[48] J. Zhu, C. Huang, M. Yang, and G. P. Cheong Fung, ‘‘Context-based pre-\ndiction for road trafﬁc state using trajectory pattern mining and recurrent\nconvolutional neural networks,’’Inf. Sci., vol. 473, pp. 190–201, Jan. 2019.\nDAVID MARTÍN-GUTIÉRREZ (Member, IEEE)\nwas born in Madrid, Spain, in 1993. He received\nthe bachelor’s degree in audio-visual system engi-\nneering from Carlos III University, in 2016, and the\nmaster’s degree in signal processing and machine\nlearning from Universidad Politécnica de Madrid,\nin 2019, where he is currently pursuing the Ph.D.\ndegree in multimodal feature learning.\nFrom 2016 to 2017, he was a Software Devel-\noper with Everis S.L and later on as a Data Fusion\nEngineer with Ixion Industry and Aerospace. Since 2017, he has been work-\ning as the Research Scientist and the Data Scientist with the Visual Telecom-\nmunications Applications Research Group developing artiﬁcial intelligent\nalgorithms related to multimedia content in several national and EU projects.\nGUSTAVO HERNÁNDEZ-PEÑALOZA (Mem-\nber, IEEE) received the Telecom Engineering\ndegree from Universidad Santo Tomás, in 2007,\nthe Master of Science degree in telecommuni-\ncation technologies, system and networks from\nUniversidad Politécnica de Valencia (UPV),\nin 2009, and the Master of Business Administra-\ntor (M.B.A.) and the Ph.D. degree (cum laude)\nfrom Universidad Politécnica de Madrid (UPM),\nin 2019. He is currently working as a Postdoctoral\nFellow with UPM. From 2010 to 2013, he was an Associate Research Fellow\nwith Universidad de Valencia (UV). His main research interest includes\nartiﬁcial intelligence (AI) applied to healthcare. He has been involved in mul-\ntiple National and European funded projects in technical and management\nactivities.\n54600 VOLUME 9, 2021\nD. Martín-Gutiérrezet al.: Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers\nALBERTO BELMONTE HERNÁNDEZ(Member,\nIEEE) received the degree in telecommunication\nengineering, the master’s degree in communica-\ntion systems, and the Ph.D. degree (cum laude)\nfrom Universidad Politécnica de Madrid (UPM),\nin 2014, 2016, and 2020, respectively. He is cur-\nrently an Assistant Professor in several subjects.\nSince 2016, he has been with the Visual Telecom-\nmunications Applications Group (GATV), UPM.\nHe is actively working on artiﬁcial intelligent\napplied to multimedia content and sensors for pattern detection, recognition,\nand fusion. He has been developing technical parts in national and EU\nprojects.\nALICIA LOZANO-DIEZ received the double\ndegree in computer science engineering and math-\nematics, the master’s degree in research and inno-\nvation in ICT, and the Ph.D. degree (cum laude)\nfrom Universidad Autónoma de Madrid (UAM),\nSpain, in 2012, 2013, and 2018, respectively. She\nwas an Assistant Professor with UAM. Since 2012,\nshe has been with the Audias Research Group,\nUAM. During the Ph.D. degree, she interned at\nthe Speech Group (Speech@FIT) with the Brno\nUniversity of Technology (BUT), Czech Republic, and with the SRI Inter-\nnational (STAR Lab), USA. Her research interests include deep neural\nnetworks (DNN) for automatic language and speaker recognition. In 2019,\nshe got the H2020 Marie Curie funding for the project ‘‘Robust End-To-End\nSPEAKER Recognition Based on Deep Learning and Attention Models’’\nand joined the Speech@FIT (BUT) as a Postdoctoral Researcher, and will\nresume to her position at UAM in 2021.\nFEDERICO ÁLVAREZ(Member, IEEE) received\nthe Telecom Engineering degree (Hons.) and\nthe Ph.D. degree (cum laude) from Universidad\nPolitécnica de Madrid (UPM), in 2003 and 2009,\nrespectively. He is currently working as an Assis-\ntant Professor with UPM. Since 2003, he has\nbeen working for the research group with the\nVisual Telecommunications Applications Group\n(GATV), UPM. He is the author and a coauthor\nof more than 60 articles and several books, book\nchapters, and patents in the ﬁeld of ICT networks and audiovisual tech-\nnologies. He has been participating with different managerial and technical\nresponsibilities in several national and EU projects, being coordinator of\nﬁve EU projects in the last six years. He had participated in national and\ninternational standardization for a DVB, CENELEC TC206, and so on. He is\nalso a member of the Program Committee of several scientiﬁc conferences.\nVOLUME 9, 2021 54601"
}