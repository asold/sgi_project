{
  "title": "URLTran: Improving Phishing URL Detection Using Transformers",
  "url": "https://openalex.org/W3167402552",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2562753520",
      "name": "Pranav Maneriker",
      "affiliations": [
        "The Ohio State University"
      ]
    },
    {
      "id": "https://openalex.org/A2160045087",
      "name": "Jack W. Stokes",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A3169219430",
      "name": "Edir Garcia Lazo",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2396618571",
      "name": "Diana Carutasu",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A1931973325",
      "name": "Farid Tajaddodianfar",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4225463089",
      "name": "Arun Gururajan",
      "affiliations": [
        "Amazon (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2562753520",
      "name": "Pranav Maneriker",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2160045087",
      "name": "Jack W. Stokes",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3169219430",
      "name": "Edir Garcia Lazo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2396618571",
      "name": "Diana Carutasu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1931973325",
      "name": "Farid Tajaddodianfar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4225463089",
      "name": "Arun Gururajan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3005725208",
    "https://openalex.org/W3105604018",
    "https://openalex.org/W2933138175",
    "https://openalex.org/W2964054038",
    "https://openalex.org/W2799194071",
    "https://openalex.org/W6766673545",
    "https://openalex.org/W6685053522",
    "https://openalex.org/W2964046515",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2957266847",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W3118485687",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W3035231859",
    "https://openalex.org/W6779580516",
    "https://openalex.org/W3034835156",
    "https://openalex.org/W6640425456",
    "https://openalex.org/W2963545917",
    "https://openalex.org/W2012481173",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W3015534721",
    "https://openalex.org/W6732691979",
    "https://openalex.org/W2270070752",
    "https://openalex.org/W2963635116",
    "https://openalex.org/W2996599509",
    "https://openalex.org/W6727690538",
    "https://openalex.org/W2962818281",
    "https://openalex.org/W3027172182",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3030163527",
    "https://openalex.org/W2971252690",
    "https://openalex.org/W2964047576",
    "https://openalex.org/W2803751389",
    "https://openalex.org/W2962784628",
    "https://openalex.org/W2580641941",
    "https://openalex.org/W2525778437",
    "https://openalex.org/W2964121744",
    "https://openalex.org/W1945616565",
    "https://openalex.org/W2121879602",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W3034549508",
    "https://openalex.org/W2787538540",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2046166587"
  ],
  "abstract": "Browsers often include security features to detect phishing web pages. In the past, some browsers evaluated an unknown URL for inclusion in a list of known phishing pages. However, as the number of URLs and known phishing pages continued to increase at a rapid pace, browsers started to include one or more machine learning classifiers as part of their security services that aim to better protect end users from harm. While additional information could be used, browsers typically evaluate every unknown URL using some classifier in order to quickly detect these phishing pages. Early phishing detection used standard machine learning classifiers, but recent research has instead proposed the use of deep learning models for the phishing URL detection task. Concurrently, text embedding research using transformers has led to state-of-the-art results in many natural language processing tasks. In this work, we perform a comprehensive analysis of transformer models on the phishing URL detection task. We consider standard masked language model and additional domain-specific pre-training tasks, and compare these models to fine-tuned BERT and RoBERTa models. Combining the insights from these experiments, we propose URLTran which uses transformers to significantly improve the performance of phishing URL detection over a wide range of very low false positive rates (FPRs) compared to other deep learning-based methods. For example, URLTran yields a true positive rate (TPR) of 86.80% compared to 71.20% for the next best baseline at an FPR of 0.01%, resulting in a relative improvement of over 21.9%. Further, we consider some classical adversarial black-box phishing attacks such as those based on homoglyphs and compound word splits to improve the robustness of URLTran. We consider additional fine tuning with these adversarial samples and demonstrate that URLTran can maintain low FPRs under these scenarios.",
  "full_text": "URLTran: Improving Phishing URL Detection Using\nTransformers\nPranav Maneriker‚àó‚Ä†\nmaneriker.1@osu.edu\nThe Ohio State University\nJack W. Stokes‚Ä†\njstokes@microsoft.com\nMicrosoft\nEdir Garcia Lazo\nedirga@microsoft.com\nMicrosoft\nDiana Carutasu\ndicaruta@microsoft.com\nMicrosoft\nFarid Tajaddodianfar‚Ä°\nf.tajad@gmail.com\nAmazon\nArun Gururajan\nargurura@microsoft.com\nMicrosoft\nABSTRACT\nBrowsers often include security features to detect phishing web\npages. In the past, some browsers evaluated an unknown URL for\ninclusion in a list of known phishing pages. However, as the number\nof URLs and known phishing pages continued to increase at a rapid\npace, browsers started to include one or more machine learning\nclassifiers as part of their security services that aim to better protect\nend users from harm. While additional information could be used,\nbrowsers typically evaluate every unknown URL using some classi-\nfier in order to quickly detect these phishing pages. Early phishing\ndetection used standard machine learning classifiers, but recent\nresearch has instead proposed the use of deep learning models for\nthe phishing URL detection task. Concurrently, text embedding\nresearch using transformers has led to state-of-the-art results in\nmany natural language processing tasks. In this work, we perform a\ncomprehensive analysis of transformer models on the phishing URL\ndetection task. We consider standard masked language model and\nadditional domain-specific pre-training tasks, and compare these\nmodels to fine-tuned BERT and RoBERTa models. Combining the\ninsights from these experiments, we propose URLTran which uses\ntransformers to significantly improve the performance of phishing\nURL detection over a wide range of very low false positive rates\n(FPRs) compared to other deep learning-based methods. For exam-\nple, URLTran yields a true positive rate (TPR) of 86.80% compared\nto 71.20% for the next best baseline at an FPR of 0.01%, resulting in\na relative improvement of over 21.9%. Further, we consider some\nclassical adversarial black-box phishing attacks such as those based\non homoglyphs and compound word splits to improve the robust-\nness of URLTran. We consider additional fine tuning with these\nadversarial samples and demonstrate that URLTran can maintain\nlow FPRs under these scenarios.\n1 INTRODUCTION\nPhishing occurs when a malicious web page is created to mimic\nthe legitimate login page used to access a popular online service\nfor the purpose of harvesting the user‚Äôs credentials or a web page\nwhose purpose is to input credit card or other payment information.\nTypical phishing targets include online banking services, web-based\nemail portals, and social media web sites. Attackers use several\ndifferent methods to direct the victim to the phishing site in order to\n‚àóWork done while the author was an intern at Microsoft Research.\n‚Ä†Both authors contributed equally to this research.\n‚Ä°Work done while the author was employed at Microsoft.\nlaunch the attack. In some cases, they may send the user a phishing\nemail containing the URL (Uniform Resource Locator) of a phishing\npage. Attackers may also use search engine optimization techniques\nto rank phishing pages high in a search result query. Modern email\nplatforms use various machine learning models to detect phishing\nweb page attacks. In this work, we propose a new deep learning\nmodel that analyzes URLs and is based on transformers which have\nshown state-of-the-art performance in many important natural\nlanguage processing tasks.\nIn order to prevent users from inadvertently uploading personal\ninformation to the attackers, web browsers provide additional se-\ncurity services to identify and block or warn a user from visiting\na known phishing page. For example, Google‚Äôs Chrome browser\nutilizes their Safe Browsing technology [12] and Microsoft‚Äôs Edge\nbrowser includes Windows Defender SmartScreen [24]. In a related\nattack which is also addressed by these services, malicious URLs\nmay point to a web page hosted by a misconfigured or unpatched\nserver with the goal of exploiting browser vulnerabilities in order to\ninfect the user‚Äôs computer with malware (i.e., malicious software).\nSuccessful phishing web page detection includes a number of sig-\nnificant challenges. First, there is a huge class imbalance associated\nwith this problem. The number of phishing pages on the internet is\nvery small compared to the total number of web pages available to\nusers. Second, phishing campaigns are often short-lived. In order\nto avoid detection, attackers may move the login page from one\nsite to another multiple times per day. Third, phishing attacks con-\ntinue to be a persistent problem. The number of known phishing\nsites continues to increase over time. Therefore, blocking phishing\nattacks only using a continuously growing list of known phishing\nsites often fails to protect users in practice.\nPopular web browsers may render hundreds of millions or even\nbillions of web pages each day. In order to be effective, any phishing\nor malicious web page detection must be fast. For this reason, sev-\neral researchers [3, 21, 37] have proposed detecting both phishing\nand malcious web pages based solely on analyzing the URL itself.\nWith the proliferation and ease of access to phishing kits sold on\nthe black market as well as the phishing as a service offerings, it has\nbecome easy for attackers with little expertise to deploy phishing\nsites and initiate such attacks. Consequently, phishing is currently\non the rise and costing over $57 million from more than 114,000\nvictims in the US last year according to a recent FBI report [ 26].\nThe number of phishing attacks rose in Q3 of 2019 to a high level\nnot seen since late 2016 [13]. As phishing is proving to be more and\narXiv:2106.05256v3  [cs.CR]  27 Aug 2021\nManeriker et al.\nmore fruitful, the attacks have become increasingly sophisticated.\nAt the same time, the lifespan of phishing URLs has continued to\ndrop dramatically ‚Äì from 10+ hours to minutes [47].\nGiven the significant repercussions of visting a phishing or mali-\ncious web page, the detection of these URLs has been an active area\nof research [32]. In some cases, researchers have proposed the use\nof classic natural language processing methods to detect malicious\nURLs [3]. Recently, others have begun to use deep learning models\nto detect these URLs. URLNet [21] is a deep convolutional neural\nnetwork (CNN) and includes separate character and word-level\nmodels for the malicious URL detection task. The Texception [37]\nmodel, which is used to detect phishing URLs, extends some of the\nideas in URLNet by including small kernels which can be deployed\nin a wide variety of configurations in terms of width, depth or both.\nRecently, semi-supervised machine learning methods have been\nused to create text embeddings that offer state-of-the-art results in\nmany natural language processing tasks. The key idea in these ap-\nproaches is the inclusion of a transformer model [39]. BERT [7, 31]\nutilizes transformers to offer significant improvements in several\nnatural language processing (NLP) tasks. GPT [1], GPT-2 [29], and\nGPT-3 [5] have also followed a similar approach. The semantics\nand syntax of natural language are more complex than URLs, which\nmust follow a strict syntax specification [2]. However, recent work\nusing transformers has also demonstrated that these models can be\napplied to tasks involving data with more strict syntactic structures.\nThese include tabular data [44], python source code [17] and SQL\nqueries [40]. The success of these approaches further motivates us\nto apply transformers on URLs.\nIn this paper, we compare two settings: 1) we pre-train and fine-\ntune an existing transformer architecture using only URL data, and\n2) we fine-tune publicly available pre-trained transformer models.\nIn the first approach, we apply the commonly used Cloze-style\nmasked language modeling objective [38] on the BERT architecture.\nIn the second approach, we fine-tune BERT [7] and RoBERTa [22]\non the URL classification task. Each of these systems forms an\nexample of a URLTran model. URLTran_BERT is the best perform-\ning model obtained from these approaches. Finally, we simulate\ntwo common black-box phishing attacks by perturbing URLs in\nour data using unicode-based homoglyph substitutions [ 41] and\ninserting ‚Äò-‚Äô characters between sub-words in a compound URL\n(e.g., ‚Äòbankofamerica.com‚Äô ‚Üí‚Äòbank-of-america.com‚Äô), along with a\nperturbation scenario under which the parameters are reordered\nand the URL label remains unchanged to improve the robustness\nof URLTran.\nResults on a large corpus of phishing and benign URLs show that\ntransformers are able to significantly outperform recent state-of-\nthe-art phishing URL detection models (URLNet, Texception) over\na wide range of low false positive rates where such a phishing URL\ndetector must operate. At a false positive rate of 0.01%, URLTran\nincreases the true positive rate from 71.20% for the next best baseline\n(URLNet) to 86.80% (21.9% relative increase). Thus, browser safety\nservices, such Google‚Äôs Safe Browsing and Microsoft‚Äôs SmartScreen,\nmay potentially benefit using the proposed URLTran system for\nthe detection of phishing web pages.\nThis paper offers the following contributions:\n‚Ä¢Borrowing from recent advances in many natural language\nprocessing tasks, we propose the use of transformers to im-\nprove the detection of phishing URLs.\n‚Ä¢We build URLTran, a large-scale system with production\ndata and labels and demonstrate that transformers do offer a\nsignificant performance improvement compared to previous\nrecent deep learning solutions over a wide range of very low\nfalse positive rates.\n‚Ä¢We analyze the impact of various design choices in terms\nof hyperparameters, pre-training tasks, and tokenizers to\ncontribute to an improved model.\n‚Ä¢We analyze the adversarially generated URLs from the sys-\ntem to understand the limitations of URLTran.\n2 PHISHING URL DATA\nThe datasets used for training, validation and testing were collected\nfrom Microsoft‚Äôs Edge and Internet Explorer production browsing\ntelemetry during the summer of 2019. The schema for all three\ndatasets is similar and consists of the browsing URL and a boolean\ndetermination of whether the URL has been identified as phishing\nor benign.\nSix weeks of historical data were collected overall out of which\nfour weeks of data were used for the training set, one week for the\nvalidation and one week for the test set.\nDue to the highly unbalanced nature of the datasets (roughly 1 in\n50 thousand URLs is a phishing URL), down-sampling of the benign\nset was necessary and resulted in a ratio of 1:20 (phishing versus\nbenign) for both the training and validation sets. The resulting\ndatasets had the corresponding total sizes of 1,039,413 records for\ntraining and 259,854 thousand for validation. The test set used for\nevaluating the models consists of 1,784,155 records, of which 8,742\nare phishing URLs and the remaining 1,775,413 are benign.\nThe labels included in this study correspond to those used to\ntrain production classifiers. Phishing URLs are manually confirmed\nby analysts including those which have been reported as suspicious\nby end user feedback. Other manually confirmed URLs are also\nlabeled as phishing when they are included and manually verified\nin known phishing URL lists including Phishtank. 1\nBenign URLs are those which correspond to web pages which\nare known to not be involved with a phishing attack. In this case,\nthese sites have been manually verified by analysts using manual\nanalysis. In other cases, benign URLs can be confirmed by thorough\n(i.e., production grade) off-line automated analysis which is not an\noption for real-time detection required by the browser. None of\nthe benign URLs have been included in known phishing lists or\nhave been reported as phishing pages by users and later verified by\nanalysts. Although these last two criteria are not sufficient to add\nan unknown URL to the benign list. It is important to note that all\nURLs labeled as benign correspond to web pages that have been\nvalidated. They are not simply a collection of unknown URLs, i.e.,\nones which have not been previously detected as phishing sites.\n1The total of 73,705 valid phishing URLs is significantly larger than the number of\nphishing URLs reported by Phishtank (http://phishtank.org/stats.php).\nURLTran: Improving Phishing URL Detection Using Transformers\nToken Encoding\nToken\nEnc\nW0\nP0 \nToken\nEnc\nW1\nP1 \nToken\nEnc\nWTm\nPTm \nFully Connected Layer\n+ +\n...\n+\nx L\nScore\nTransformer Layer\nhttp://secure.bankofamerica.com/login/sign-in/singOnV2Screen.go\nTokenize\nFigure 1: URLTran phishing URL detection model.\n3 METHODOLOGY\nURLTran seeks to use recent advances in natural language pro-\ncessing to improve the task of detecting phishing URLs. Building\nURLTran employs a two-pronged approach towards adapting trans-\nformers for the task of phishing URL detection. First, state-of-the-art\ntransformer models, BERT [7] and RoBERTa [22], are fine-tuned,\nstarting from publicly available vocabularies and weights and across\ndifferent hyperparameter settings and resulting in URLTran_BERT\nand URLTran_RoBERTa, respectively. Second, domain-specific vo-\ncabularies are built using different tokenization approaches, and a\ndomain specific transformer (URLTran_CustVoc) is first pre-trained\nand then fine-tuned on the task.\nThe general architecture of all the explored models takes a three\nstage approach for inference shown in Figure 1. It first uses a sub-\nword tokenizer to extract tokens from a URL. Next, a transformer\nmodel generates an embedding vector for the unknown URL. Fi-\nnally, a classifier predicts a score indicating whether or not the\nunknown URL corresponds to a phishing web page.\nIn the following sections, we first provide briefly summarize the\ntransformer model architecture, followed by the training tasks used\nto train the model, and end with a description of the adversarial\nsettings under which the best URLTran model is evaluated and then\ntrained with adversarial examples to improve its robustness.\n3.1 Architecture\nWe describe the tokenization schemes and overall architecture for\nclassification in this section, skipping a detailed description of trans-\nformer models for brevity. Interested readers can review the trans-\nformer [39], BERT [7], or RoBERTa [22] papers for details of the\ninternal structure of transformer layers.\n3.1.1 Tokenization. The raw input to the URLTran model is the\nURL, which can be viewed as a text sequence. The first step in the\nphishing URL detection task involves converting this input URL\ninto a numerical vector which can be further processed by a classic\nmachine learning or deep learning model.\nPrevious URL detection models [3] extracted lexical features by\nfirst splitting the URL with a set of important delimiters (e.g., ‚Äò=‚Äô,\n‚Äò/‚Äô, ‚Äò?‚Äô, ‚Äò. ‚Äô, ‚Äò ‚Äô) and then creating a sparse binary features based on\nthese tokens. Recent deep learning-based URL detection models [21,\n37] instead include separate word-level and character-level CNNs\nwhere the character-level CNNs span different lengths of character\nsubsequences.\nInstead of these approaches, we experiment with multiple sub-\nword tokenization schemes in URLTran. Subword models have seen\nincreased adoption in different tasks in NLP, including machine\ntranslation [34], word analogy [4], and question answering [ 46].\nWhile using full-length words reduces the input representation\nlength (number of tokens) allowing more input to be processed by\na fixed-length model, using a subword model can provide morpho-\nlogical insights to improve inference. For example, a full-length\nmodel would consider ‚Äòbankofamerica‚Äô and ‚Äòbankofcanada‚Äô as com-\npletely unrelated tokens, whereas a subword model can recognize\nthe shared subword ‚Äòbank‚Äô to correlate URLs belonging to the two\nbanks. Important character subsequences, including prefixes and\nsuffixes can also provide relevant information while being more\nrobust to polymorphic attacks.\nIn particular, for URLTran_BERT and URLTran_RoBERTa, we\nuse the existing word piece [7, 42] and Byte Pair Encoding (BPE)\nmodels [22, 29] , respectively. In addition to these, custom character-\nlevel and byte-level BPE vocabularies are created using the training\nURL data to have a domain specific vocabulary for URLTran_CustVoc\nwith two different vocabulary sizes, 1K and 10K. The BPE models\nattempt to find a balance of using both character subsequences and\nfull words.\nThe BPE models first break the ùëöùë°‚Ñé URL, ùë¢ùëö, into a sequence\nof text tokens, TOKùëö, where the individual tokens may represent\nentire words or subwords [33, 35, 42]. Following the notation in [7],\nthe token sequence is formed as:\nTOKùëö = Tokenizer(ùë¢ùëö) (1)\nwhere TOKm is of length ùëáùëö positions and consists of individual\ntokens ùëáùëúùëòùë° at each position index ùë°. For example, the BERT word-\npiece token sequence generated from the URL of a popular banking\nlogin page,\nùë¢ùëö = secure.bankofamerica.com/login/sign-in/signOnV2Screen.go\nis shown in Table 1. The wordpiece model includes special text\ntokens specified by (##) which build upon the previous token in\nthe sequence. In the example in Table 1, ‚Äò##of‚Äô means that it occurs\nafter a previous token (‚Äòbank‚Äô), and it is distinguished from the\nmore common, separate token ‚Äòof‚Äô.\n3.1.2 Classifier. The final encoding produced by the transformer\nmodel can be used for a variety of downstream NLP tasks such as\nlanguage understanding, language inference, and question answer-\ning, and text classification. We use the transformer embeddings for\ntwo tasks: pre-training masked language models, and fine-tuning\nfor classification of phishing URLs. Both of these tasks require a\nfinal classification layer, which can be applied to multiple tokens\nfor masked token prediction, and a pooled representation for clas-\nsification. The transformer models that we train use a single, dense\ntwo-class classification layer, which is applied to a special pooled to-\nken (‚Äò[CLS]‚Äô) for classification. A dense layer having vocab_size\nclasses is used for predicting the masked token for the masked\nlanguage modeling task during pre-training:\nManeriker et al.\nURL (ùë¢ùëö) secure.bankofamerica.com/login/sign-in/signOnV2Screen.go\nToken Sequence (TOKm) { ‚Äòsecure‚Äô, ‚Äò. ‚Äô, ‚Äòbank‚Äô, ‚Äò##of‚Äô, ‚Äò##ame‚Äô, ‚Äò##rica‚Äô, ‚Äò. ‚Äô, ‚Äòcom‚Äô, ‚Äò/‚Äô, ‚Äòlog‚Äô, ‚Äò##in‚Äô, ‚Äò/‚Äô,\n‚Äòsign‚Äô, ‚Äò-‚Äô, ‚Äòin‚Äô, ‚Äò/‚Äô, ‚Äòsign‚Äô, ‚Äò##on‚Äô, ‚Äò##v‚Äô, ‚Äò##2‚Äô, ‚Äò##screen‚Äô, ‚Äò. ‚Äô, ‚Äògo‚Äô }\nTable 1: Example of the wordpiece token sequence extraction from a popular banking web page.\nsùëö = Wxùëö +b. (2)\nIn (2), W and b are the weight matrix and bias vector, respectively,\nfor the final dense linear layer. sm is the score which predicts if\nthe URL um corresponds to a phishing web page when performing\nclassification and is the sequence of masked token probability score\nvectors when performing masked language modeling for input\ntoken xm.\n3.2 Training\n3.2.1 Masked Language Modeling (MLM). The MLM task is com-\nmonly used to perform pre-training for transformers. In this task,\na random subset of tokens is replaced by a special ‚Äò[MASK]‚Äô token.\nThe training objective for the task is the cross-entropy loss cor-\nresponding to predicting the correct tokens at masked positions.\nThe intuition for using this task for URLs is that specific query\nparameters and paths are generally associated with non-phishing\nURLs and therefore predicting masked tokens would help to un-\ncover these associations. Similar intuitions derived from the cloze\ntask [38] motivate the usage of MLMs for pre-training natural lan-\nguage models. Following the MLM hyperparameter settings for\nBERT, 15% of the tokens were uniformly selected for masking, of\nwhich 80% are replaced, 10% were left unchanged, and 10% were\nreplaced by a random vocabulary token at each iteration. Dynamic\nmasking [22] was used, i.e., different tokens masked from the same\nsequence across iterations. The training subset of the full dataset\nwas used for pre-training to prevent any data leakage.\n3.2.2 Fine Tuning. For URLTran_BERT and URLTran_RoBERTa,\nall of the initial parameters derived using a large, internal natural\nlanguage corpus generated by their respective authors, were used.\nFor URLTran_CustVoc, following the completion of the MLM pre-\ntraining step, the learned weights were used as initialization values.\nNext, URLTran‚Äôs model parameters were further improved using\na second ‚Äúfine-tuning‚Äù training process which depends upon the\nerror signal from the URL classification task and gradients based\non gradient descent using the Adam [18] optimizer with the cross-\nentropy loss.\n3.3 Adversarial Attacks and Data\nAugmentation\nPhishing URL attacks can occur on short-lived domains and URLs\nwhich have small differences from existing, legitimate domains. We\nsimulate two attack scenarios by constructing examples of such\nadversaries based on modifying benign URLs. Note that these gen-\nerated domains do not actually exist in the pre-existing training\nand testing data, but are based upon frequently observed phishing\nattack patterns. We also utilize a reordering-based augmentation,\nwhich is used is used to generate benign perturbations for evaluat-\ning adversarial attacks.\n3.3.1 Homoglyph Attack. We generate domains that appear nearly\nidentical to legitimate URLs by substituting characters with other\nunicode characters that are similar in appearance. This attack strat-\negy is commonly referred to as a homoglyph attack [10, 43], and we\nimplement this strategy using the python library homoglyphs2. In\nparticular, given a URL, we first extract the domain. For a randomly\nselected character in the domain, we check for one unicode (utf-\n8) Latin or Cyrillic character that is a homoglyph for it. We only\nperturb one character to minimize the probability that such a URL\nwould we be identified as phishing by the user. We then replace\nthe character by its homoglyph to construct a new URL. The URLs\ngenerated from this strategy are labeled as phishing.\n3.3.2 Compound Attack. An alternative way to construct new\nphishing URLs is by splitting domains into sub-words (restricted\nto English) and then concatenating the sub-words with an inter-\nmediate hyphen. For example, ‚Äòbankofamerica.com‚Äô ‚Üí‚Äòbank-of-\namerica.com‚Äô. To implement this, we leverage theenchant dictio-\nnary3. Consider a URL with domainùëëhaving |ùëë|= ùëõcharacters. Let\nD denote the enchant English dictionary. Let ùê∂(ùëë,ùëñ,ùëó )denote the\nfunction that returns True if ùëë[ùëñ...ùëó ]can be split into one or more\nparts, each of which is a word in the dictionary D. The compound\nword problem can be formulated recursively as\nùê∂(ùëë,ùëñ,ùëó )=\nÔ£±Ô£¥Ô£¥Ô£¥ Ô£≤\nÔ£¥Ô£¥Ô£¥Ô£≥\nTrue, ùëë [ùëñ...ùëó ]‚àà D\nTrue ‚àÉùëò,ùê∂(ùëë,ùëñ,ùëò )and ùê∂(ùëë,ùëò +1,ùëó )\nFalse otherwise\n(3)\nUsing this recursive definition, we implement a dynamic program-\nming algorithm that can compute whether a domain can be split\nand the corresponding splits. These splits are then concatenated\nwith hyphens between the discovered words. Note that the base\ncase check ùëë[ùëñ...ùëó ]‚àà D is performed in a case insensitive manner\nto ensure that the dictionary checks do not miss proper nouns.\n3.3.3 Parameter Reordering. Data augmentation using invariants,\ncontextual replacement, and reward-based learning [ 14, 20] has\nbeen used to improve classifiers in the text domain. These can\nbe extended to augment data in the URL domain. As the query\nparameters of a URL are interpreted as a key-value dictionary, this\naugmentation incorporates permutation invariance. An example of\na URL and permutation is provided in Figure 2. We use this approach\nto generate benign examples. Reordering the parameters still results\nin a valid URL, i.e., parameter reordering does not represent a\nphishing attack, and therefore we do not modify the URL‚Äôs label.\n2https://pypi.org/project/homoglyphs/\n3https://pypi.org/project/pyenchant/\nURLTran: Improving Phishing URL Detection Using Transformers\nsecure.bankofamerica.com/activate.go?type=credit&channel=desktop\nsecure.bankofamerica.com/activate.go?channel=desktop&type=credit\nFigure 2: An example of parameter reordering\n3.3.4 Adversarial Attack Data. The approach we use for gener-\nating data for an adversarial attack includes generating separate\naugmented training, validation and test datasets based on their\noriginal dataset [11]. For each URL processed in these datasets, we\ngenerate a random number. If it is less than 0.5, we augment the\nURL, or otherwise, we include it in its original form. For URLs which\nare to be augmented, we modify it using either a homoglyph attack,\na compound attack or parameter reordering with equal probability.\nIf a URL has been augmented, we also include the original URL in\nthe augmented dataset.\n4 NUMERICAL EVALUATION\nIn this section, we present the numerical evaluation of the different\napproaches presented in the previous sections. We then compare\nURLTran to several recently proposed baselines. We also report the\nthe model‚Äôs training and inference times. Finally, we analyze the\nrobustness of the model to generated phishing URLs.\nSetup. The hyperparameter settings for all models are provided in\nAppendix A. In our experiments, we set the hyperparameters for\npreviously published models according to their settings in the orig-\ninal paper. For evaluating URLTran_CustVoc, we vary the number\nof layers between {3,6,12}, vary the number of tokens per input\nURL sequence between {128,256}, and use both a byte-level and\ncharacter-level BPE tokenizer with 1K- and 10K-sized vocabularies.\nWe randomly pick 15 hyperparameter combinations among these\nsettings and present the results for these. The Adam optimizer [19]\nis used in both pre-training and fine-tuning, with the triangular\nscheduler [36] used for fine-tuning.\nAll training and inference experiments were conducted using\nPyTorch [9] version 1.2 with NVIDIA Cuda 10.0 and Python 3.6.\nThe experiments were performed by extending the Hugging Face\nand Fairseq PyTorch implementations found on GitHub [ 16, 27].\nThe large class imbalance makes accuracy a poor metric of model\nperformance. We evaluated all the models using the true positive\nrate (TPR) at low false positive rate (FPR) thresholds. We used\nthe receiver operating characteristics (ROC) curve to compute this\nmetric.\nBaselines.\nTo evaluate the performance of our models, we compared them\nto two baseline URL detection models: URLNet and Texception.\nURLNet [21] is a CNN-based model which was recently proposed\nfor the task of detecting URLs which identify malicious web sites.\nIn our baseline, we have completely trained and tested the URLNet\nmodel for the detection of phishing URLs. Texception [ 37] is an-\nother deep learning URL detection model which has been proposed\nfor the task of identifying phishing URLs. It is important to note\nthat Tajaddodianfar et. al. [37] compared Texception to a Logistic\nRegression-based model and found that Texception offered better\nseq_len\n128 256\n0.992\n0.994\n0.996\n0.998AUROC\ntokenizer\nbyte sent\nvocab_size\n1000 10000\nlayers\n1 2 3\n(a) Area under ROC vs hyperparameters\nseq_len\n128 256\n0.000\n0.200\n0.400\n0.600\n0.800TPR@0.01%\ntokenizer\nbyte sent\nvocab_size\n1000 10000\nlayers\n1 2 3\n(b) TPR@FPR = 0.01% vs hyperparmeters\nFigure 3: Variance in quality of URLTran_CustVoc across dif-\nferent hyperparameter settings\nperformance. Thus, we did not repeat that baseline experiment in\nthis work.\nURLTran_CustVoc.Transformers typically require large amounts\nof pre-training data (e.g., BERT [7] used a corpus of ‚âà3.3 B tokens).\nHowever, this data is derived from text articles, which are struc-\ntured differently from URLs. We also trained the URLTran_CustVoc\nmodel based soley on the URL data found in our datasets to com-\npare the results of finetuning using standard BERT and RoBERTa\npretrained models to models pretrained from the URL data. The\ndifference in dataset size and data domain make it important to\nunderstand the impact of different hyperparameters used when\ntraining transformers from scratch. We compare runs across differ-\nent hyperparameters on the basis of area under ROC (AUROC) and\nTPR@0.01% FPR. Figure 3 demonstrates that the training is not very\nsensitive to sequence length. Smaller byte-level vocabularies tend\nto be better overall, but at low FPR, the difference is not significant.\nFinally, we found that the 3 layer model generalized the best. We\nhypothesize that the better performance of the model with fewer\nlayers is because of limited pre-training data and epochs. In the\nnext few sections, we validate this hypothesis by evaluating fine-\ntune models that have have longer pre-training (URLTran_BERT,\nURLTran_RoBERTa) and that are tuned on a larger, adversarial\ndataset.\nModel Performance. We next analyze the performance of the\nbest parameters of all the proposed transformer variants. To under-\nstand how these models compare at very low FPRs where detection\nManeriker et al.\n0\n25\n50\n75\n100\n0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2\nFalse Positive Rate (%)\nTrue Positive Rate (%)\nTexception\nURLNet\nURLTran_BERT\nURLTran_CustVoc\nURLTran_RoBERTa\nFigure 4: Receiver operating characteristic curve indicating\nthe performance of the URLTran and several baseline mod-\nels zoomed into a maximum of 2% false positive rate.\n0\n25\n50\n75\n100\n0.001 0.01 0.1 1 10\nFalse Positive Rate (%)\nTrue Positive Rate (%)\nTexception\nURLNet\nURLTran_BERT\nURLTran_CustVoc\nURLTran_RoBERTa\nFigure 5: Zoomed in receiver operating characteristic curve\nwith a log x-axis.\nthresholds must be set to operate in a production environment,\nwe first plot the ROC curves on a linear x-axis zoomed into a 2%\nmaximum FPR in Figure 4. We also re-plot these ROC curves on\na log x-axis in the semilog plot in Figure 5. These results indicate\nthat all variants of URLTran offer a significantly better true pos-\nitive rate over a wide range of extremely low FPRs. In particular,\nURLTran matches or exceeds the TPR of URLNet for the FPR range\nof 0.001% - 0.75%. The result is very important because phishing\nURL detection models must operate at very low FPRs (e.g., 0.01%) in\norder to minimize the number of times the security service predicts\nthat a benign URL is a phishing site (i.e., a false positive). In prac-\ntice, the browser manufacturer selects the desired FPR and tries to\ndevelop new models which can increase the TPR for the selected\nFPR value. Note that TPR@FPR is the standard metric commonly\nused both in production settings and in prior art such as Texception\nand URLNet.\nIn addition to the ROC curve analysis, we also summarize a\nnumber of key performance metrics in Table 2. In the table, ‚ÄòF1‚Äô is\nthe F1 score, and ‚ÄòAUC‚Äô is the area under the model‚Äôs ROC curve.\nThe proposed URLTran model outperforms both Texception and\n0\n25\n50\n75\n100\n0.001 0.01 0.1 1 10\nFalse Positive Rate (%)\nTrue Positive Rate (%)\nAdvAttack\nAdvTraining\nURLTran_BERT\nFigure 6: ROC curve for URLTran_BERT when under adver-\nsarial attack, and adversarial robustness after augmented\ntraining\nURLNet for all of these metrics. In particular, we note that at an\nFPR of 0.01%, URLTran_BERT has a TPR of 86.80% compared to\n71.20% for URLNet and 52.15% for Texception.\nTraining and Inference Times. The total time required to train\nthe best URLTran_BERT model was 4:57:11 on an NVIDIA V100.\nInference required 0:10::44 to complete for an average of 0.36096\nmilliseconds per sample.\nAdversarial Evaluation. To understand URLTran‚Äôs robustness to\nadversarial attacks, we first compared the low FPR regions of the\nROC curve of the unprotected model tested with the original test\nset to the test set which includes adversarial samples (AdvAttack)\ngenerated through the methods described in Section 3.3 (Figure 6).\nThere is a significant drop in performance of URLTran_BERT when\nattacked with adversarial URLs. Next, we consider the scenario\nwhere attack strategies are incorporated into the training data\n(AdvTraining). On the addition of adversarial attack patterns to\nthe training, the model is able to the adapt to novel attacks, and\neven outperform the unprotected version of URLTran. These results\ndemonstrate that URLTran can adapt to novel attacks. Further, as\nnew attack strategies are recognized (e.g., homoglyph), a robust\nversion of URLTran can be trained to recognize similar patterns in\nunseen test data.\nURLTran: Improving Phishing URL Detection Using Transformers\nModel Accuracy (%) Precision (%) Recall (%) TPR@FPR=0.01% F1 AUC\nTexception 99.6594 99.7562 99.6594 52.1505 0.9969 0.9977\nURLNet 99.4512 99.7157 99.4512 71.1965 0.9954 0.9988\nURLTran_CustVoc 99.5983 99.7615 99.5983 81.8577 0.9965 0.9992\nURLTran_RoBERTa 99.6384 99.7688 99.6384 82.0636 0.9968 0.9992\nURLTran_BERT 99.6721 99.7845 99.6721 86.7994 0.9971 0.9993\nTable 2: Comparison of different performance metrics for URLTran and the two baseline models\n5 RELATED WORK\nThe URLTran system is most closely related to phishing and mali-\ncious URL detection models which have been previously proposed\nin the literature. In this section, we describe related work for deep\nlearning-base text embeddings in general. These models have been\nderived for various natural language processing tasks. We then\nreview related work in phishing and malicious web page detection\nusing the web page‚Äôs URL which builds upon the previous text\nembedding models proposed in the NLP domain. In particular, we\nfocus on two recent, deep learning URL detection models, URLNet\nand Texception, which helped to inspire this work.\nText Embeddings. Deep learning models for text embeddings have\nbeen an active area of research recently. One form of models called\na character-level CNN learns a text embedding from individual\ncharacters, and these embeddings are then processed using a se-\nquential CNN and one or more dense layers depending on the task.\nRecent examples of character-level CNNs include [6, 45]. In partic-\nular, Conneau et al. [6] investigated very deep architectures for the\npurpose of classifying natural language text. Typically, these mod-\nels are trained in an end-to-end fashion instead of from manually\nengineered features.\nTransformers were introduced by Vaswani et al. [ 39] in the\ncontext of neural machine translation. A number of models used\ntransformers for other natural language processing tasks including\nBERT [7, 31], GPT [1], GPT-2 [29], and GPT-3 [5]. RoBERTa [23]\nused careful optimization of the BERT parameters and training\nmethodology to offer further improvements.\nAdversarial Attacks on Text. Adversarial example generation\nhas been a focus of some recent work on understanding the robust-\nness of various text classification tasks. The examples generated\nusing these approaches aim to impose certain semantic constraints\nwithout modifying the label of the underlying text. White-box\nattacks (e.g., Hotflip [8]) require access to the internals of the clas-\nsification model used, such as the gradient on specific examples.\nThe attack framework proposed in our work is more in line with\nblack-box attack frameworks such as DeepWordBug [10] and Tex-\ntAttack [25] where the construction of adversarial data is motivated\nby a threat model but independent of the classifier used. We spe-\ncialize this attack scheme for the URL context.\nURL-Based Phishing and Malicious Web Page Detection. Pre-\nvious related work on the detection of phishing and malicious web\npages based on the page‚Äôs URL has progressed in parallel. We next\nreview some important systems in chronological order.\nEarly phishing page detection based on URLs followed conven-\ntional deep learning approaches. A summary of these methods is\nincluded in [32]. Blum et al. [3] proposed using confidence weighted,\nonline learning using a set of lexical features which are extracted\nfrom the URL. To extract these features, the URL is first split us-\ning the following delimiters: ‚Äò?‚Äô, ‚Äò=‚Äô, ‚Äò/‚Äô, ‚Äò. ‚Äô, and ‚Äò ‚Äô. Next, individual\nfeatures are set based on the path, domain, and protocol.\nLe et al. [21] proposed the URLNet model whose task is to detect\nURLs which are references to malicious web pages found on the\nInternet. URLNet processes a URL using a character-level Convo-\nlutional Neural Network (CNN) and a word-level CNN. For the\ncharacter-level CNN, the URL is first tokenized by each of the char-\nacters.\nInspired by the Xception deep object recognition model for im-\nages, Texception [37] also uses separate character-level and word-\nlevel CNNs like URLNet. However, Texception‚Äôs CNN kernels form\ndifferent size text windows in both the character and word levels.\nMultiple Texception blocks and Adaptive Max Pooling layers can\nbe combined in different model configurations in terms of both\ndepth and width. In addition, Texception utilizes contextual word\nembeddings in the form of either FastText or Word2Vec to convert\nthe URL into the input embedding vector.\nAnother CNN-based phishing detection model was proposed by\nYerima and Alzaylaee [43]. Using the page‚Äôs content, the authors\ncreate a 31-dimensional feature vector for each web page in their\ndataset and train a CNN based on this feature vector. URLTran\ndiffers from this work because it only processes the URL instead of\nextracting the page content which will be much slower for inference.\nOther work has proposed using LSTMs (i.e., recurrent sequential\nmodels) for phishing and malicious URL detection including [28,\n30]. Processing LSTMs is expensive in terms of computation and\nmemory for long URLs which makes them impractical for large-\nscale production. In [15], Huang et al. also investigate using capsule\nnetworks for detecting phishing URLs.\n6 CONCLUSION\nWe have proposed a new transformer-based system called URLTran\nwhose goal is to predict the label of an unknown URL as either one\nwhich references a phishing or a benign web page. Transformers\nhave demonstrated state-of-the-art performance in many natural\nlanguage processing tasks, and this paper seeks to understand if\nthese methods can also work well in the cybersecurity domain.\nIn this work, we demonstrate that transformers which are fine-\ntuned using the standard BERT tasks also work remarkably well for\nthe task of predicting phishing URLs. Instead of extracting lexical\nfeatures or using CNNs kernels which span multiple characters\nand words, which are both common in previously proposed URL\ndetection models, our system uses the BPE tokenizers for this task.\nNext, transformers convert the token sequence to an embedding\nManeriker et al.\nvector which can then be used as input to a standard, dense linear\nlayer. Results indicate that URLTran is able to significantly outper-\nform recent baselines, particularly over a wide range of very low\nfalse positive rates. We also demonstrate that transformers can be\nmade robust to novel attacks under specific threat models when we\nadversarially augment the training data used for training them.\nREFERENCES\n[1] R Alec, N Karthik, S Tim, and S Ilya. 2018.Improving language understanding with\nunsupervised learning . Technical Report. Tech. Rep., Technical report, OpenAI.\n[2] Tim Berners-Lee, Roy T. Fielding, and Larry M Masinter. 2005. Uniform Resource\nIdentifier (URI): Generic Syntax. RFC 3986. https://doi.org/10.17487/RFC3986\n[3] Aaron Blum, Brad Wardman, Thamar Solorio, and Gary Warner. 2010. Lexical\nfeature based phishing URL detection using online learning. Proceedings of the\nWorkshop on Artificial Intelligence and Security 1, 1 (2010), 1‚Äì37.\n[4] Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. En-\nriching Word Vectors with Subword Information. Transactions of the Association\nfor Computational Linguistics 5 (2017), 135‚Äì146. https://doi.org/10.1162/tacl_a_\n00051\n[5] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al . 2020. Language models are few-shot learners. arXiv preprint\narXiv:2005.14165 (2020).\n[6] Alexis Conneau, Holger Schwenk, Yann Le Cun, and Loic Barrault. 2017.\nVery Deep Convolutional Networks for Text Classification . Technical Report.\narXiv:1606.01781v2 https://arxiv.org/pdf/1606.01781.pdf\n[7] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:\nPre-training of Deep Bidirectional Transformers for Language Understanding. In\nProceedings of the 2019 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, Volume 1 (Long and\nShort Papers) . 4171‚Äì4186.\n[8] Javid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou. 2018. HotFlip: White-\nBox Adversarial Examples for Text Classification. In Proceedings of the 56th\nAnnual Meeting of the Association for Computational Linguistics (Volume 2: Short\nPapers). 31‚Äì36.\n[9] Facebook. [n.d.]. PyTorch - From Research to Production. https://pytorch.org/\n[10] J. Gao, J. Lanchantin, M. L. Soffa, and Y. Qi. 2018. Black-Box Generation of\nAdversarial Text Sequences to Evade Deep Learning Classifiers. In 2018 IEEE\nSecurity and Privacy Workshops (SPW) . 50‚Äì56. https://doi.org/10.1109/SPW.2018.\n00016\n[11] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and\nHarnessing Adversarial Examples. (dec 2014). arXiv:1412.6572 http://arxiv.org/\nabs/1412.6572\n[12] Google. [n.d.]. Making the world‚Äôs information safely accessible. https://\nsafebrowsing.google.com/\n[13] HelpNetSecurity. [n.d.]. Phishing attacks at highest level in three years. https:\n//www.helpnetsecurity.com/2019/11/07/phishing-attacks-levels-rise/\n[14] Zhiting Hu, Bowen Tan, Russ R Salakhutdinov, Tom M Mitchell, and Eric P Xing.\n2019. Learning data manipulation for augmentation and weighting. In Advances\nin Neural Information Processing Systems . 15764‚Äì15775.\n[15] Yongjie Huang, Jinghui Qin, and Wushao Wen. 2019. Phishing URL Detection\nVia Capsule-Based Neural Network. In 2019 IEEE 13th International Conference\non Anti-counterfeiting, Security, and Identification (ASID) . IEEE, 22‚Äì26.\n[16] HuggingFace. [n.d.]. Transformers - State-of-the-art Natural Language Processing\nfor PyTorch and TensorFlow 2.0. https://github.com/huggingface/transformers\n[17] Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, and Kensen Shi. 2020.\nLearning and Evaluating Contextual Embedding of Source Code. In International\nConference on Machine Learning .\n[18] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-\nmization. arXiv preprint arXiv:1412.6980 (2014).\n[19] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Opti-\nmization. In 3rd International Conference on Learning Representations, ICLR 2015,\nSan Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings , Yoshua Bengio\nand Yann LeCun (Eds.). http://arxiv.org/abs/1412.6980\n[20] Sosuke Kobayashi. 2018. Contextual Augmentation: Data Augmentation by\nWords with Paradigmatic Relations. In Proceedings of the 2018 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies, Volume 2 (Short Papers) . 452‚Äì457.\n[21] Hung Le, Quang Pham, Doyen Sahoo, and Steven C H Hoi. 2018.URLNet: Learning\na URL Representation with Deep Learning for Malicious URL Detection . Technical\nReport. arXiv:1802.03162v2 https://doi.org/10.475/123{_}4\n[22] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer\nLevy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A\nrobustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692\n(2019).\n[23] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer\nLevy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A\nRobustly Optimized BERT Pretraining Approach. CoRR abs/1907.11692 (2019).\narXiv:1907.11692 http://arxiv.org/abs/1907.11692\n[24] Microsoft. [n.d.]. Microsoft Defender SmartScreen. https://docs.\nmicrosoft.com/en-us/windows/security/threat-protection/microsoft-defender-\nsmartscreen/microsoft-defender-smartscreen-overview\n[25] John Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby, Di Jin, and Yanjun Qi. 2020.\nTextAttack: A Framework for Adversarial Attacks, Data Augmentation, and\nAdversarial Training in NLP. In Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System Demonstrations . 119‚Äì126.\n[26] Federal Bureau of Investigation. [n.d.]. 2019 Internet Crime Report. https:\n//pdf.ic3.gov/2019_IC3Report.pdf\n[27] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng,\nDavid Grangier, and Michael Auli. 2019. fairseq: A Fast, Extensible Toolkit for\nSequence Modeling. In Proceedings of NAACL-HLT 2019: Demonstrations .\n[28] Yongfang Peng, Shengwei Tian, Long Yu, Yalong Lv, and Ruijin Wang. 2019.\nA Joint Approach to Detect Malicious URL Based on Attention Mechanism.\nInternational Journal of Computational Intelligence and Applications 18, 03 (2019),\n1950021.\n[29] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya\nSutskever. 2019. Language Models are Unsupervised Multitask Learners . Technical\nReport. Tech. Rep., Technical report, OpenAI. https://d4mucfpksywv.cloudfront.\nnet/better-language-models/language-models.pdf\n[30] F. Ren, Z. Jiang, and J. Liu. 2019. A Bi-Directional LSTM Model with Attention\nfor Malicious URL Detection. In 2019 IEEE 4th Advanced Information Technology,\nElectronic and Automation Control Conference (IAEAC) , Vol. 1. 300‚Äì305.\n[31] Anna Rogers, Olga Kovaleva, and Anna Rumshisky. 2020. A primer in bertology:\nWhat we know about how bert works. arXiv preprint arXiv:2002.12327 (2020).\n[32] Doyen Sahoo, Chenghao Liu, and Steven C. H. Hoi. 2017. Malicious URL Detection\nusing Machine Learning: A Survey. 1, 1 (2017), 1‚Äì37. arXiv:1701.07179 http:\n//arxiv.org/abs/1701.07179\n[33] Mike Schuster and Kaisuke Nakajima. 2012. Japanese and Korean voice search.\nIEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n(2012), 5149‚Äì5152.\n[34] Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural Machine\nTranslation of Rare Words with Subword Units. InProceedings of the 54th Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers) .\n1715‚Äì1725.\n[35] Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural machine\ntranslation of rare words with subword units. Annual Meeting of the Association\nfor Computational Linguistics (ACL) (2016), 1715‚Äì1725.\n[36] Leslie N Smith. 2017. Cyclical learning rates for training neural networks. In\n2017 IEEE Winter Conference on Applications of Computer Vision (WACV) . IEEE,\n464‚Äì472.\n[37] Farid Tajaddodianfar, Jack W. Stokes, and Arun Gururajan. 2020. Texception: A\nCharacter/Word-Level Deep Learning Model for Phishing URL Detection. IEEE\nInternational Conference on Acoustics, Speech and Signal Processing (ICASSP) (2020),\n2857‚Äì2861.\n[38] Wilson L Taylor. 1953. ‚ÄúCloze procedure‚Äù: A new tool for measuring readability.\nJournalism quarterly 30, 4 (1953), 415‚Äì433.\n[39] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information processing systems . 5998‚Äì6008.\n[40] Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and Matthew\nRichardson. 2020. RAT-SQL: Relation-Aware Schema Encoding and Linking for\nText-to-SQL Parsers. In Proceedings of the 58th Annual Meeting of the Association\nfor Computational Linguistics . Association for Computational Linguistics, Online,\n7567‚Äì7578. https://doi.org/10.18653/v1/2020.acl-main.677\n[41] Jonathan Woodbridge, Hyrum S Anderson, Anjum Ahuja, and Daniel Grant.\n2018. Detecting homoglyph attacks with a siamese neural network. In 2018 IEEE\nSecurity and Privacy Workshops (SPW) . IEEE, 22‚Äì28.\n[42] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi,\nWolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff\nKlingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan\nGouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian,\nNishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick,\nOriol Vinyals, Gregory S. Corrado, Macduff Hughes, and Jeffrey Dean. 2016.\nGoogle‚Äôs Neural Machine Translation System: Bridging the Gap between Human\nand Machine Translation. ArXiv abs/1609.08144 (2016).\n[43] Suleiman Y Yerima and Mohammed K Alzaylaee. 2020. High Accuracy Phishing\nDetection Based on Convolutional Neural Networks. In 2020 3rd International\nConference on Computer Applications & Information Security (ICCAIS) . IEEE, 1‚Äì6.\n[44] Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020.\nTaBERT: Pretraining for Joint Understanding of Textual and Tabular Data.\nIn Proceedings of the 58th Annual Meeting of the Association for Computa-\ntional Linguistics . Association for Computational Linguistics, Online, 8413‚Äì8426.\nhttps://doi.org/10.18653/v1/2020.acl-main.745\nURLTran: Improving Phishing URL Detection Using Transformers\n[45] Xiang Zhang, Junbo Zhao, and Yann Lecun. 2015. Character-level Convolutional\nNetworks for Text. (2015), 1‚Äì9. arXiv:arXiv:1502.01710\n[46] Zhuosheng Zhang, Hai Zhao, Kangwei Ling, Jiangtong Li, Zuchao Li, Shexia He,\nand Guohong Fu. 2019. Effective subword segmentation for text comprehension.\nIEEE/ACM Transactions on Audio, Speech, and Language Processing 27, 11 (2019),\n1664‚Äì1674.\n[47] zvelo. [n.d.]. The Rise of Single-Use Phishing URLs and the Need for Zero-\nSecond Detection. https://zvelo.com/single-use-phishing-urls-need-zero-\nsecond-detection/\nA HYPERPARAMETER SETTINGS\nFor reproducibility, this appendix provides the hyperparameter set-\ntings for the three variants of the proposed URLTran model as well\nas those for two baseline models. Tables 3 and 4 list the hyperpa-\nrameters for the URLNet and Texception models that we use as\nbaselines in our study. The hyperparameter settings for the best\nperforming URLTran_BERT model are provided in Table 5. In addi-\ntion, the best hyperparameter settings for the URLTran_RoBERTa\nand URLTran_CustVoc are given in Tables 6 and 7, respectively.\nParameter Value\nmax_len_words 200\nmax_len_chars 1000\nmax_len_subwords 20\nmin_word_freq 1\ndev_pct 0.001\ndelimit_mode 1\nemb_dim 32\nfilter_sizes [3,4,5,6]\ndefault_emb_mode char + wordCNN\nnb_epochs 5\ntrain_batch_size 128\ntrain_l2_reg_lambda 0.0\ntrain_lr 0.001\nTable 3: Hyperparameters used for URLNet.\nParameter Value\nCharacters\nBranch\nembedding dimension 32\nnumber of blocks 1\nblock filters [2,3,4,5]\nAdaptive MaxPool output 32,32\nmaximum characters 1000\nWords\nBranch\nembedding dimension 32\nnumber of blocks 1\nblock filters [1,3,5]\nAdaptive MaxPool output 32,16\nmaximum words 50\nFastText\nModel\nminimum words to include 50\nvocabulary size 120000\nwindow size 7\nn-grams 2-6\nembedding dimension 32\nepochs trained 30\nTable 4: Hyperparameters used for Texception.\nManeriker et al.\nParameter Value\nattention probs dropout prob 0.1\nhidden act gelu\nhidden dropout prob 0.1\nhidden size 768\ninitializer range 0.02\nintermediate size 3072\nlayer norm eps 1e-12\nmax position embeddings 512\nnum attention heads 12\nnum hidden layers 12\ntype vocab size 2\nvocab size 30522\nbert model bert-base-uncased\nmax seq length 128\ntrain batch size 32\nlearning rate 2e-5\nnum train epochs 10\nTable 5: Hyperparameters used for training the proposed\nHuggingface-based URLTran_BERT model.\nParameter Value\nNumber of Layers 12\nHidden size 768\nFFN inner hidden size 3072\nAttention heads 12\nAttention head size 64\nDropout 0.1\nAttention Dropout 0.1\nWarmup Steps 508\nPeak Learning Rate 1e-4\nBatch Size 2k\nMax Epochs 10\nLearning Rate Decay Linear\nAdam ùúñ 1e-6\nAdam ùõΩ1 0.9\nAdam ùõΩ2 0.98\nGradient Clipping 0.0\nTokens per sample 256\nTable 6: Hyperparameters used for fine-tuning the proposed\nFairseq-based URLTran_RoBERTa model.\nParameter Value\nNumber of Layers 3\nHidden size 768\nFFN inner hidden size 3072\nAttention heads 12\nAttention head size 64\nDropout 0.1\nAttention Dropout 0.1\nTokens per sample 128\nPeak Learning Rate 1e-4\nBatch Size 2k\nTokenizer Type Byte BPE\nWeight Decay 0.01\nMax Epochs 30\nLearning Rate Decay reduce\non plateau\nLR Shrink 0.5\nAdam ùúñ 1e-6\nAdam ùõΩ1 0.9\nAdam ùõΩ2 0.98\nGradient Clipping 0.0\nLearning Rate 1e-4\nvocab size 10000\nParameter Value\nLearning Rate 1e-4\nBatch Size 2k\nMax Epochs 10\nLearning LinearRate Decay\nWarmup ratio 0.06\nTable 7: Hyperparameters used for pre-training (left) and\nfine-tuning (right) the proposed URLTran_CustVoc model.",
  "topic": "Phishing",
  "concepts": [
    {
      "name": "Phishing",
      "score": 0.9178156852722168
    },
    {
      "name": "Computer science",
      "score": 0.7502701282501221
    },
    {
      "name": "Machine learning",
      "score": 0.5815407633781433
    },
    {
      "name": "Classifier (UML)",
      "score": 0.5405517816543579
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5377166271209717
    },
    {
      "name": "Transformer",
      "score": 0.4599986970424652
    },
    {
      "name": "World Wide Web",
      "score": 0.3078213334083557
    },
    {
      "name": "The Internet",
      "score": 0.209648996591568
    },
    {
      "name": "Engineering",
      "score": 0.10292074084281921
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I52357470",
      "name": "The Ohio State University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210164937",
      "name": "Microsoft Research (United Kingdom)",
      "country": "GB"
    }
  ],
  "cited_by": 7
}