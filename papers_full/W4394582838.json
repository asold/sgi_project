{
    "title": "Building Customized Chatbots for Document Summarization and Question Answering using Large Language Models using a Framework with OpenAI, Lang chain, and Streamlit",
    "url": "https://openalex.org/W4394582838",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A4378131371",
            "name": "Sangita Pokhrel",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3128804627",
            "name": "Swathi Ganesan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5095043336",
            "name": "Tasnim Akther",
            "affiliations": [
                "York St John University"
            ]
        },
        {
            "id": "https://openalex.org/A5092733752",
            "name": "Lakmali Karunarathne",
            "affiliations": [
                "York St John University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4236487888",
        "https://openalex.org/W4387007686",
        "https://openalex.org/W2093894952",
        "https://openalex.org/W4385624020",
        "https://openalex.org/W4385287322",
        "https://openalex.org/W4387373540",
        "https://openalex.org/W4389924421",
        "https://openalex.org/W4401042394",
        "https://openalex.org/W4313428540",
        "https://openalex.org/W4388234781",
        "https://openalex.org/W4308654855",
        "https://openalex.org/W3101918863",
        "https://openalex.org/W4389544300",
        "https://openalex.org/W4388938052",
        "https://openalex.org/W4392008384",
        "https://openalex.org/W4393065920"
    ],
    "abstract": "This research presents a comprehensive framework for building customized chatbots empowered by large language models (LLMs) to summarize documents and answer user questions. Leveraging technologies such as OpenAI, LangChain, and Streamlit, the framework enables users to combat information overload by efficiently extracting insights from lengthy documents. This study discussed the framework's architecture, implementation, and practical applications, emphasizing its role in enhancing productivity and facilitating information retrieval. Through a step-by-step guide, this research has demonstrated how developers can utilize the framework to create end-to-end document summarization and question-answering applications.",
    "full_text": "Journal of Information Technology and Digital World (ISSN: 2582-418X)  \nwww.irojournals.com/itdw/    \n \n \nJournal of Information Technology and Digital World, March 2024, Volume 6, Issue 1, Pages 70-86 70 \nDOI: https://doi.org/10.36548/jitdw.2024.1.006 \nReceived: 04.02.2024. received in revised form: 06.03.2024, accepted: 22.03.2024, published: 07.04.2024 \n© 2024 Inventive Research Organization. This is an open access article under the Creative Commons Attribution-NonCommercial International (CC BY-NC 4.0) License \n \nBuilding Customized Chatbots for \nDocument Summarization and Question \nAnswering using Large Language Models \nusing a Framework with OpenAI, Lang \nchain, and Streamlit \nSangita Pokhrel1, Swathi Ganesan2, Tasnim Akther3, Lakmali \nKarunarathne4 \n1,2,4Computer Science and Data Science, York St John University, London, United Kingdom \n3Department of Library and Learning Services, York St John University, London, United \nKingdom \nE-mail: 1s.pokhrel@yorksj.ac.uk, 2s.ganesan@yorksj.ac.uk, 3t.akther@yorksj.ac.uk, 4l.karunarathne@yorksj.ac.uk \nAbstract \nThis research presents a comprehensive framework for building customized chatbots \nempowered by large language models (LLMs) to summarize documents and answer user \nquestions. Leveraging technologies such as OpenAI, LangChain, and Streamlit, the framework \nenables users to combat information overload by efficiently extracting insights from lengthy \ndocuments. This study discussed the framework's architecture, implementation, and practical \napplications, emphasizing its role in enhancing productivity and facilita ting information \nretrieval. Through a step -by-step guide, this research has demonstrated how developers can \nutilize the framework to create end -to-end document summarization and question -answering \napplications. \n                                                                                                                                         Sangita Pokhrel, Swathi Ganesan, Tasnim Akther, Lakmali Karunarathne  \n \nJournal of Information Technology and Digital World, March 2024, Volume 6, Issue 1 71 \n \n \nKeywords: Langchain, PDF Summarizer, Streamlit, OpenAI APIs, ChatBots, Large Language \nModels \n Introduction \nIn an era typified by the exponential growth of digital information, the capacity to \nrapidly extract important insights from huge amounts of text has become paramount. Chatbots, \ndeveloped using artificial intelligence (AI) and natural language processing (NLP) technology, \nhave emerged as adaptable solutions capable of tackling this difficulty. With applications \nranging from customer service to educational help, chatbots offer various paths for automating \ntasks such as document summarizing, and question answering, hence boosting productivity and \nknowledge retrieval [1]. \nLarge language models (LLMs) represent the main element of recent breakthroughs in \nNLP, as they transform  the way machines interpret and generate human -like text. These \nmodels, trained on vast datasets, demonstrate exceptional capabilities in comprehending and \ncreating natural language, making them perfect candidates for powering specialized chatbots \nto document summarization and question-answering tasks [2]. The value of LLMs in NLP tasks \ncannot be emphasized since they enable chatbots to analyze and synthesize complicated textual \ninformation with unparalleled accuracy and efficiency [3]. The rationale for designing \ncustomized chatbots for document summarizing and question -answering originates from the \ninherent challenges caused by information overload. As the volume of digital information \ncontinues to rise dramatically, individuals and organizations are flooded with massive amounts \nof textual data, making it increasingly difficult to extract meaningful insights promptly. \nCustomized chatbots equipped with document summarizing and question -answering \ncapabilities offer a solution to this di fficulty, enabling users to effectively explore and derive \nmeaningful insights from vast quantities of text [4]. \nOpenAI's GPT models, in particular, have gained notable attention in the field of NLP \nbecause of their capacity to provide logical and contextually relevant text. Exclusively pre-\ntrained on vast amounts of text data, these models stand as the backbone of this platform  , \nproviding the core language understanding capabilities necessary for document summarizing, \nand question-answering activities [5].On the other hand, LangChain enhances the capabilities \nBuilding Customized Chatbots for Document Summarization and Question Answering using Large Language Models using a Framework with OpenAI, Lang \nchain, and Streamlit \nISSN: 2582-418X  72 \n \n \nof OpenAI's GPT models by offering a framework for performing linguistic processing tasks \nefficiently. With its modular architecture and wide support for diverse NLP activities, \nLangChain supports the integration of language models into chatbot application s effortlessly \n[6]. Streamlit serves as the user interface foundation for our proposed framework, enabling \ndevelopers to design intuitive and interactive interfaces for chatbots. With its simplicity and \nversatility, Streamlit has improved the creation and deployment of chatbot apps, allowing users \nto interact seamlessly with the system [7]. \nIn this research, a comprehensive architecture for constructing customized chatbots \nempowered by LLMs to handle the aforementioned difficulties has been presented. Leveraging \nstate-of-the-art technologies such as OpenAI's GPT (Generative Pretrained Transformer) \nmodels, LangChain, and Streamlit, this framework offers a versatile solution for developers \nand researchers seeking to harness the power of LLMs for document summarization and \nquestion-answering tasks. By integrating these frameworks, this technique supports the \nseamless construction  and deployment of chatbots capable of parsing, summarizing, and \nanswering queries based on textual input. \n Background Study \nIn this research review, the progress of NLP technology and the essential role of LLMs \nin redefining the capabilities of chatbots  has been examined along with the  importance of \npersonalized chatbots that can summarise documents and answer questions to address the \ndifficulties caused by an excessive amount of information. The article [1] utilized extractive \nsummarizers to refine the main components of research papers, aiming to address information \noverload in the scientific literature. Through experiments, they found that enhancements \nconsidering the text's sophisticated structure improved summarization, especially for languages \nlacking refined NLP tools. This approach helped overcome challenges in extracting relev ant \ninsights from vast amounts of scientific text, emphasizing the need for deep text understanding \nfor high-quality summaries. [2] explored conversational interfaces, specifically chatbots, in the \ncontext of AI ethics. The study  explored the differences between scenario -based and large \nlanguage model  (LLM)-based chatbots in generating recommendations and discussed the \nethical implications of LLM -based recommendations. By comparing their characteristics and \nlimitations, the study highlighted concerns such as transparency, fairness, privacy, and \n                                                                                                                                         Sangita Pokhrel, Swathi Ganesan, Tasnim Akther, Lakmali Karunarathne  \n \nJournal of Information Technology and Digital World, March 2024, Volume 6, Issue 1 73 \n \n \naccountability. This study concluded by stressing the importance of ethical considerations in \ndeveloping and evaluating conversational AI systems, urging further research and industry \nefforts to implement ethical practices. \nThe researcher [3] employed machine learning to develop an evolving connectionist \ntext summarizer, aiming to address challenges in automatic text summarization. By \nacknowledging the dynamic nature of linguistic attributes, the authors found that adaptive \nstructures in connectionist architectures enhanced summarization effectiveness. This approach \novercame limitations in modeling evolving systems, emphasizing the importance of language-\nindependent strategies for accurate text summarization. \nThe rapid evolution of automatic text summarization technology in response to the \nexponential growth of online content has been investigated in [4]. It emphasized the importance \nof these summarizers in efficiently managing vast amounts of information by condensing it \ninto concise yet comprehensive summaries while preserving the original meaning. This study \nexplored both extractive and abstractive text summarization methods, highlighting the role of \nnatural language processing  (NLP) techniques and modern approaches such as Google's \nPEGASUS model. A detailed analysis of the proposed PEGASUS method was presented, and \nits architecture and sequence-to-sequence learning approach  \nRe discussed. The results  showcased the model's ability to generate accurate and \nhuman-like summaries across various dimensions. The paper concludes by emphasizing the \nsignificance of automatic text summarization tools in meeting the increasing demand for \naccessible and user -friendly solutions, especially in the mobile domain, and proposes future \ndirections for their development to cater to a wider audience. The authors of [8] developed a \ncontent generation tool utilizing the OpenAI language model, specifically GPT-3, as an API to \nstreamline content creation for businesses and individuals. Powered by advanced machine \nlearning algorithms, including a recurrent neural network (RNN) architecture, the tool aimed \nto efficiently produce high -quality content across various platforms. With a user -friendly \ndashboard, it offered a range of features , such as Facebook ads, LinkedIn posts, Amazon \nproduct descriptions, and blogs. Addressing t he challenges of limited writing skills and time \nconstraints, the tool emphasized its efficacy in simplifying content creation across multiple \nplatforms, highlighting its value in assisting users with diverse content generation needs. \nBuilding Customized Chatbots for Document Summarization and Question Answering using Large Language Models using a Framework with OpenAI, Lang \nchain, and Streamlit \nISSN: 2582-418X  74 \n \n \nThe study of [9] introduced LangChain, a query system utilizing LLMs for efficient \ninformation retrieval from PDF documents. By employing natural language processing \nalgorithms and Streamlit, the authors found that LangChain streamlined the querying process \nand enhanced information retrieval. This approach overcame challenges in extracting relevant \ninformation from PDFs, offering a valuable tool for efficient data access. The authors of [10] \nexplored a new approach to text summarization models by considering large language models \n(LLMs) like GPT-3.5 as reference or gold-standard oracles. They investigated the implications \nof using LLMs as references for model training and evaluation practices. The research \ninvestigated two LLM-based methods for evaluating summary quality, namely GPTScore and \nGPTRank, in conjunction with contrastive learning training techniques leveraging LLM -\nguided signals. Experiments conducted on CNN/DailyMail and XSum data sets demonstrated \nthat smaller summarization models could attain comparable performance to LLMs when \nevaluated using LLM-based criteria. \nNonetheless, human evaluation revealed a disparity, suggesting that despite \nenhancements from the proposed training methods, smaller models have not yet reached the \nperformance level of LLMs.  The research highlighted the risks as well as the benefits of the \nLLM-as-reference setting, emphasizing the importance of further examination and \nimprovement. It contributed by demonstrating empirical improvements in smaller models \ntrained with LLM references and contrastive learning, while also revealing limitations in LLM-\nbased training and evaluation methods.  \nIn their study outlined in reference [6], researchers explored the utilization of LLMs for \nrapid application development, centering on LangChain, an accessible open -source software \nlibrary.Highlighting LLMs like OpenAI's ChatGPT, renowned for tasks such as essay writing \nand code generation, the research underscored LangChain's modular structure. By showcasing \npractical examples across autonomous agents, chatbots, and document -based question \nanswering, the study illuminated LangChain's prowess in acceleratin g application \ndevelopment. It emphasized the revolutionary impact of LLMs in the AI landscape and \npositioned LangChain as a pivotal tool in streamlining the development process, fostering \nongoing exploration and innovation in the domain. The research of [11] investigated the \nproblem-solving capabilities of  LLMs like LaMDA, OPT, and GPT-3 in math word problems. \nUsing the SVAMP dataset, GPT-3's “davinci-002” model showed robust performance on both \n                                                                                                                                         Sangita Pokhrel, Swathi Ganesan, Tasnim Akther, Lakmali Karunarathne  \n \nJournal of Information Technology and Digital World, March 2024, Volume 6, Issue 1 75 \n \n \nsymbolic and numeric  problems, with a two -step approach improving accuracy in the \nnumerical test set. Specific prompting techniques enhanced the model's ability to explain its \nthought process and solve complex problems. The study suggested that large LLMs can \neffectively solve symbolic math problems but highlights room for improvement.  \nResearchers of [12]  by integrating an external knowledge management module aimed \nto enhance the Large Language Models (LLMs) like ChatGPT, enabling access to data from \nvector databases and the Internet. Focused on raising awareness about blockchain technology \nin Kazakhstan, a chatbot prototype was developed using the double diamond design process, \nincorporating frontend and backend layers with components like Prompt Templates, Chains, \nMemory, Models, and Agents. Python and OpenAI's GPT-3.5 were chosen for their versatility \nin natural language processing. Semantic and web search integration improved the chatbot's \nability to provide real -time, accurate information. The study concluded that the developed \nchatbot system holds promise in improving citizen awareness, with future re search aiming to \nadapt the architecture for the Kazakh language.   \nIn the paper [13], they have introduced an approach for abstractive text summarization \napplying deep learning, aiming for precise and coherent summaries without redundancy. It \nemployed an Encoder-decoder architecture with Bi-LSTM and attention mechanisms to reduce \nrepetition as well as to enhance the contextual phrase generation. The model focused on multi-\nsentence summarization using the Double Attention Pointer Network and employed data \nprocessing methods such as cleansing, padding, and tokenizing. The proposed model, utilizing \nT5 for conditional generation and evaluated using R OUGE scores, shows c ompetitive \nperformance compared to the SASSBOOK TOOL with Daily Mail dataset  and CNN , \nachieving a ROUGE score of 71%. The paper concluded that the proposed algorithm yields \npromising outcomes, outperforming existing methods  in terms of semantic and syntactic \nstructure, and suggests future work to enhance the system by including the  paraphrasing \nmethod that has a abstractive summarizer.  \nArticle [14] presented extractive text summarization as a solution to data overload \nacross various domains. It investigated the use of Elmo embedding for generating summaries \nefficiently. Preprocessing involved text splitting, punctuation removal, tokenizing, stop word  \nremoval, and lemmatizing. Elmo embedding converted text into vectors, capturing context -\nBuilding Customized Chatbots for Document Summarization and Question Answering using Large Language Models using a Framework with OpenAI, Lang \nchain, and Streamlit \nISSN: 2582-418X  76 \n \n \ndependent aspects. Sentences were scored using cosine similarity, and the top five formed the \nsummary. Elmo embedding facilitated accurate summary generation. Future work includes \nimproving summarization for multiple documents and enhancing speed and accuracy.  \n[15] The proposal suggests integrating LLMs, including GPT-based technologies, into \nmultiagent systems (MASs) to improve the communication and decision-making capabilities. \nA novel agent architecture, that is based on the MAPE-K model, has been devised to enhance \nconversational features, reasoning, and decision -making abilities.  Through a marketplace \nscenario, integration showcased the potential to revolutionize agent interactions and problem -\nsolving capabilities within MASs. Challenges such as  computational o verhead and \ninterpretability of decisions were acknowledged for future improvement. [16] created a web \napplication that aimed to create concise summaries of YouTube video transcripts using NLP \ntechniques and the Flask framework to overcome challenges in accessing video content \nefficiently. By providing features such as translation and text-to-speech, the authors found that \nthe summarizer improved user accessibility to video content, overcoming challenges in \nunderstanding lengthy videos. \nIn reference [17], an innovative system has been introduced to address limitations in \ncurrent technologies for building large -scale model applications. This system integrates the \nLangChain framework, enabling seamless connectivity between AI models like ChatGLM-6B \nand local data sources.  Additionally, the system incorporated the Rasa framework, which \nenhanced the ability to perform tasks such as  intent classification and entity recognition. By \nleveraging these frameworks, the system improved text generation  efficiency, enabling more \neffective applications in various contexts, such as cloud network monitoring and scheduling \nsystems. \nFrom the literature review, it is evident that the integration of AI and NLP technologies, \nparticularly through large language models (LLMs), offers promising solutions for addressing \ninformation overload. Chatbots powered by these technologies excel in tasks such as document \nsummarization and question answering, demonstrating their efficiency in managing vast \namounts of digital information across various domains. \n \n \n                                                                                                                                         Sangita Pokhrel, Swathi Ganesan, Tasnim Akther, Lakmali Karunarathne  \n \nJournal of Information Technology and Digital World, March 2024, Volume 6, Issue 1 77 \n \n \n Framework Architecture \nOpenAI is a research organization dedicated to advancing artificial intelligence \ntechnologies for the betterment of society that conducts research across diverse domains in AI, \nincluding NLP,  robotics, reinforcement learning, and beyond. A primary objective is to create \nAI systems capable of executing a diverse array of tasks with human-like intelligence. They've \nengineered AI systems capable of significant projects, including the creation of large -scale \nlanguage models like the GPT (Generative Pre -Trained Transformer) series, which can \ngenerate text resembling human language based on input data. These models have applications \nin natural language comprehension, text generation, translation, etc. The framework of the \nsystem is to develop a web application that summarizes the pdf using the Streamlit, Langchain, \nand OpenAI APIs in which the architecture of the model can be seen in figure 1. \n \nFigure 1. Architecture of the Model \nInitially, the PDF document is uploaded into the system, followed by the importation \nof the PdfReader class from the PyPDF2 module. This Python library facilitates working with \nPDF files, allowing tasks like reading, manipulation, and text extraction from PDF documents.  \nThe whole document will be split into chunks, creating an embedding from each chunk, \nand all the chunks will be stored in the vector database. In the context of data processing, a \nchunk is the segment of the data that has been divided from a larger dataset. It is often employed \nto break down into more manageable units for processing, anal ysis, or storage. Embeddings \nare quantitative representations of data that encapsulate its semantic meaning. In natural \n\nBuilding Customized Chatbots for Document Summarization and Question Answering using Large Language Models using a Framework with OpenAI, Lang \nchain, and Streamlit \nISSN: 2582-418X  78 \n \n \nlanguage processing (NLP), word embeddings are frequently employed to depict words as \nvectors within a high -dimensional space. This representation arranges words with akin \nmeanings closer together in the vector space. These embeddings can be generated thro ugh \ndiverse techniques, including Word2Vec, GloVe, or deep learning models like transformers.  \nIn this paper, we utilized the OpenAI embeddings class from the LangChain embeddings. \nOpenAI module. It is a part of the LangChain  package and provides embedding s based on \nOpenAI’s language models for text data. A vector store, also known as a knowledge base, is a \nrepository where embeddings or vectors representing data are stored. The embeddings \ngenerated from the extracted data are stored in a vector store, which acts as a repository of \nknowledge that the system can reference during the search process. This vector store facilitates \nsemantic search and retrieval of relevant information based on user queries. \nWhen the user asks a question i.e prompt, it performs a semantic search in the vector \nstore and searches for the chunks to find the ranked results. Based on the large language model, \nthe OpenAI API has been integrated at the backend , which answers the user. If the user is \nsatisfied with the answer, they can use it ; if not, the user will ask with a more detailed \ncustomized prompt and wait for the specific answer. The figure 2 defines the proposed system \nblock diagram. \n \nFigure 2. Proposed Block Diagram \nThe OpenAI API serves as a gateway to cutting-edge language processing capabilities, \nenabling access to advanced LLMs such as GPT-3, GPT-3.5, and GPT-4. These models excel \nin generating high-quality text across various styles and tones, simplifying tasks such as content \n\n                                                                                                                                         Sangita Pokhrel, Swathi Ganesan, Tasnim Akther, Lakmali Karunarathne  \n \nJournal of Information Technology and Digital World, March 2024, Volume 6, Issue 1 79 \n \n \ncreation, summarization, and script generation. LangChain, an open -source library, \ncomplements the OpenAI API by seamlessly integrating with other natural language \nprocessing (NLP) tools, facilitating the creation of robust pipelines for tasks such as data  \ncleaning and summarization. Streamlit further enhances this ecosystem by simplifying the \ndevelopment of interactive web applications, allowing users to present outputs generated by \nOpenAI and LangChain with minimal coding requirements. Together, these too ls empower \nusers to leverage advanced language processing capabilities, streamline workflows, and \nefficiently create professional-looking applications. \n Results and Implementation \nThe open AI API secret key was created from the OpenAI website and saved in an \nenvironment that needs to be treated like the password and avoid sharing it publicly. Once the \nsecret key has been created (shown in Figure 3), it can be used for accessing the OpenAI API \nand integrate it into our application, projects, and research. \n \n \nFigure 3. Creating the OpenAI API Key \nThe web application was designed using Streamlit, which is a promising open -source \nPython library that enables developers to build interfaces most easily. It simplifies the process \nof creating interactive and customizable web-based user interfaces (UIs) directly from Python \nscripts without needing knowledge of web development languages such as HTML, CSS, or \nJavaScript. Users can create interactive components such as sliders, buttons, text inputs, and \ndata visualizations with only a few lines of code [18]. \n\nBuilding Customized Chatbots for Document Summarization and Question Answering using Large Language Models using a Framework with OpenAI, Lang \nchain, and Streamlit \nISSN: 2582-418X  80 \n \n \n \n \nFigure 4. Interface of the Application \nFigure 4 shows the interface of our web application , where the information has been \nkept on the left side of the web and the ask about your pdf has been the main target where it \ntakes pdf files. This whole system has been integrated with Streamlit, long-chain, and OpenAI \nlarge language models. When people are trying to save time and quickly want to receive a \nresponse from that pdf, they can simply ask the chatbot any questions , and answers can be \nobtained by searching in the pdf. \n \n \nFigure 5. Uploading the pdf \nInitially, the script verifies whether a PDF file has been uploaded (i.e., checks if the \nvariable ‘pdf’ is None). Upon confirmation of an uploaded PDF file, it instantiates a PdfReader \nobject to access the contents of the PDF (shown in figure 5). It iterates through  PDF document \nto retrieve the text from each page. Finally, it concatenates the extracted text from all pages \ninto a unified string variable. \n\n                                                                                                                                         Sangita Pokhrel, Swathi Ganesan, Tasnim Akther, Lakmali Karunarathne  \n \nJournal of Information Technology and Digital World, March 2024, Volume 6, Issue 1 81 \n \n \n \n \nFigure 6. Q/A Chatbot for Question-Answering \n \nOnce the PDF is uploaded, the question-answering chatbot is initialized and a question \nfrom the user about the PDF is asked (as shown in figure 6). \nThe prompt given by the user is: \nPrompt 1 \nFrom the given pdf file \n'Self-Adaptive_Large_Language_Model_LLM-Based_Multiagent_Systems', please \nsummarize the pdf in approximately 200 words including all the details that have been \ndiscussed in the paper (shown in figure 7). \nResults \nThis paper presents a novel method for overseeing multiagent systems (MASs) within \nautonomic computing. This method entails incorporating large language models (LLMs), \nparticularly GPT -based technologies, into MASs to enhance communication and the \nadaptability of agents. Additionally, this paper introduces a fresh architecture for LLM/GPT -\nbased agents founded in the MAPE -K model, fostering system adaptability within dynamic \nenvironments. To assess this approach, a simplified marketplace scenario served as a testbed, \nwhere autonomous agents utilized embedded LLMs to make decisions and exhibit self -\nadaptation. The future work will include  establishing individual OpenAI accounts for each \n\nBuilding Customized Chatbots for Document Summarization and Question Answering using Large Language Models using a Framework with OpenAI, Lang \nchain, and Streamlit \nISSN: 2582-418X  82 \n \n \nagent and investigating alternative application scenarios. overall, this paper proposes for a \nparadigm shift in MAS self-adaptation and indicates further research prospects to evaluate the \nviability of LLMs in increasingly intricate MAS scenarios. \n \n \n \n \n \n \n \n \n \nFigure 7. Responses Generated by the Model \nPrompt 2: What is the Self-adaptive Large Language Model? \nResult: A self-adaptive large language model (LLM) is a type of technology that is integrated \ninto multiagent systems (MASs) to enhance communication and adaptability. It uses cutting -\nedge large language models, such as GPT -4, to enable agents to adapt to complex  tasks and \nreact intelligently to changing situations. This technology is based on the MAPE -K model, \nwhich is known for its ability to support system adaptations in response to dynamic \nenvironments (shown in figure 8). \n\n                                                                                                                                         Sangita Pokhrel, Swathi Ganesan, Tasnim Akther, Lakmali Karunarathne  \n \nJournal of Information Technology and Digital World, March 2024, Volume 6, Issue 1 83 \n \n \n \n \nFigure 8. Results for Prompt 2 \nThe original paper  described a self -adaptive LLM -based multiagent system [15] in \nwhich researchers proposed the development of a novel LLM/GPT-based agent architecture \nalong with the reasoning and decision-making capacities of these models. \nOur experimental evaluation involved diverse documents covering various domains, \nwhere this system demonstrated significant effectiveness on pdf summary. This system \nefficiently got the key information from documents into concise summaries, surpassing \ntraditional methods. The question -answering chatbot exhibited rapid responses within a few \nseconds per query with great user satisfaction. It first fetches documents from a retriever and \nsubsequently employs a question-answering chain to respond to queries based on the retrieved \ndocuments. Specifically, this system utilized the ‘stuff’ document chain type, wherein a list of \ndocuments is incorporated into a prompt, which is then processed by a Large Language Model \n(LLM). Semantic search enhances search engine ca pabilities by understanding the intent and \ncontext of search queries, leading to more accurate and relevant search results.  \n Limitations and Discussions \nThe framework has some limitations where it relies on pre -trained language models, \nlike OpenAI’s GPT models, which may not always understand specialized topics well or \nsummarize complex documents accurately. While these models excel in generating human-like \ntext, their summarization performance can be hindered by documents outside their training data \n\nBuilding Customized Chatbots for Document Summarization and Question Answering using Large Language Models using a Framework with OpenAI, Lang \nchain, and Streamlit \nISSN: 2582-418X  84 \n \n \nscope. Additionally, dependence on cloud -based APIs like OpenAI raises concerns regarding \ndata privacy, security, and long -term service availability. Hence, careful consideration and \npotential fine-tuning are essential to ensure the chatbot’s robustness and reliability, particularly \nin diverse and specialized domains. \n Conclusion and Future Recommendations \nIn conclusion, this research concludes with an in -depth approach to developing \npersonalized chatbots derived from large language models (LLMs), emphasizing question \nresponse and document summarization  by integrating technologies such as  Streamlit, \nLangChain, and OpenAI, the framework effectively addresses the issue of information \noverload by facilitating the extraction of insights from documents. This research shows how \ndevelopers can use the framework to build end-to-end applications for question-answering and \ndocument summarization by offerin g a step -by-step tutorial. The integration of OpenAI’s \nadvanced language models, LangChain’s efficient NLP processing, and Streamlit’s user -\nfriendly interface design offer a versatile solution for researchers and developers seeking to \nharness the power of LLMs for text-based tasks.  \nFuture recommendations include fine-tuning the model, integrating adaptive generative \nAI models, and expanding the capabilities of customized chatbots with a wider range of \nfeatures. This framework has the potential to revolutionize the way users interact with and \nderive insights from textual data, enhancing productivity and facilitating knowledge retrieval \nacross various domains. \nReferences \n[1] Balage Filho, Pedro Paulo, TA Salgueiro Pardo, and M. das Gracas Volpe Nunes. \n\"Summarizing scientific texts: Experiments with extractive summarizers.\" In  Seventh \nInternational Conference on Intelligent Systems Design and Applications (ISDA 2007), \npp. 520-524. IEEE, 2007. \n[2] Bang, Junseong, Byung-Tak Lee, and Pangun Park. \"Examination of Ethical Principles \nfor LLM -Based Recommendations in Conversational AI.\" In  2023 International \nConference on Platform Technology and Service (PlatCon), pp. 109-113. IEEE, 2023. \n                                                                                                                                         Sangita Pokhrel, Swathi Ganesan, Tasnim Akther, Lakmali Karunarathne  \n \nJournal of Information Technology and Digital World, March 2024, Volume 6, Issue 1 85 \n \n \n[3] Prasad, Rajesh S., U. V. Kulkarni, and Jayashree R. Prasad. \"Machine learning in \nevolving connectionist text summarizer.\" In  2009 3rd International Conference on \nAnti-counterfeiting, Security, and Identification in Communication, pp. 539-543. IEEE, \n2009. \n[4] Nalini, N., Agrim Narayan, Akshay Mambakkam Sridharan, and Arkon Pradhan. \n\"Automated Text Summarizer Using Google Pegasus.\" In  2023 International \nConference on Smart Systems for applications in Electrical Sciences (ICSSES), pp. 1 -\n4. IEEE, 2023. \n[5] Patil, Dinesh D., Dhanraj R. Dhotre, Gopal S. Gawande, Dipali S. Mate, Mayura V. \nShelke, and Tejaswini S. Bhoye. \"Transformative trends in generative ai: Harnessing \nlarge language models for natural language understanding and \ngeneration.\" International Jou rnal of Intelligent Systems and Applications in \nEngineering 12, no. 4s (2024): 309-319. \n[6] Topsakal, Oguzhan, and Tahir Cetin Akinci. \"Creating large language model \napplications utilizing langchain: A primer on developing llm apps fast.\" In International \nConference on Applied Engineering and Natural Sciences, vol. 1, no. 1, pp. 1050-1056. \n2023. \n[7] Monks, Thomas, and Alison Harper. \"Improving the usability of open health service \ndelivery simulation models using Python and web apps.\"  NIHR Open Research  3 \n(2023). \n[8] Pokhrel, Sangita, and Shiv Raj Banjade. \"AI Content Generation Technology based on \nOpen AI Language Model.\" Journal of Artificial Intelligence and Capsule Networks 5, \nno. 4 (2023): 534-548. \n[9] S, Adith Sreeram A, and Pappuri Jithendra Sai. “An Effective Query System Using \nLLMS and Langchain.” International Journal of Engineering Research & Technology, \nJuly 4, 12(6), 2023. 367 -369 \n[10] Liu, Yixin, Alexander R. Fabbri, Pengfei Liu, Dragomir Radev, and Arman Cohan. \"On \nlearning to summarize with large language models as references.\"  arXiv preprint \narXiv:2305.14239 (2023). \nBuilding Customized Chatbots for Document Summarization and Question Answering using Large Language Models using a Framework with OpenAI, Lang \nchain, and Streamlit \nISSN: 2582-418X  86 \n \n \n[11] Gaur, Vedant, and Nikunj Saunshi. \"Symbolic math reasoning with language models.\" \nIn 2022 IEEE MIT Undergraduate Research Technology Conference (URTC), pp. 1-5. \nIEEE, 2022. \n[12] Mansurova, Aigerim, Aliya Nugumanova, and Zhansaya Makhambetova. \n\"Development of a question -answering chatbot for blockchain domain.\"  Scientific \nJournal of Astana IT University (2023): 27-40. \n[13] Shibi, Krithick, R. Kingsy Grace, and M. Sri Geetha. \"Abstractive Summarizer using \nBi-LSTM.\" In  2022 International Conference on Edge Computing and Applications \n(ICECAA), pp. 1605-1609. IEEE, 2022. \n[14] Gupta, Hritvik, and Mayank Patel. \"Study of extractive text summarizer using the elmo \nembedding.\" In  2020 Fourth International Conference on I -SMAC (IoT in Social, \nMobile, Analytics and Cloud)(I-SMAC), pp. 829-834. IEEE, 2020. \n[15] Nascimento, Nathalia, Paulo Alencar, and Donald Cowan. \"Self -adaptive large \nlanguage model (llm) -based multiagent systems.\" In  2023 IEEE International \nConference on Autonomic Computing and Self -Organizing Systems Companion \n(ACSOS-C), pp. 104-109. IEEE, 2023. \n[16] Kumar, Jitender, Ritu Vashistha, Roop Lal, and Dhrumil Somanir. \"YouTube \nTranscript Summarizer.\" In  2023 14th International Conference on Computing \nCommunication and Networking Technologies (ICCCNT), pp. 1-4. IEEE, 2023. \n[17] Duan, Zhihua. \"Application development exploration and practice based on \nLangChain+ ChatGLM+ Rasa.\" In  2023 2nd International Conference on Cloud \nComputing, Big Data Application and Software Engineering (CBASE), pp. 282 -285. \nIEEE, 2023 \n[18] pokhrel, Sangita. “LLM Based PDF Summarizer and Q/A App Using OpenAI, \nLangChain, and Streamlit.” Medium, February 26, 2024. \nhttps://medium.com/@sangitapokhrel911/llm-based-pdf-summarizer-and-q-a-app-\nusing-openai-langchain-and-streamlit-807b9b133d9c.  \n "
}