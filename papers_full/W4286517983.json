{
    "title": "Arabic Language Modeling Based on Supervised Machine Learning",
    "url": "https://openalex.org/W4286517983",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A4286538958",
            "name": "Omayma Mahmoudi",
            "affiliations": [
                "Mohamed I University"
            ]
        },
        {
            "id": "https://openalex.org/A2728583435",
            "name": "Mouncef Filali Bouami",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4286538960",
            "name": "Mustapha Badri",
            "affiliations": [
                "Mohamed I University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2945928904",
        "https://openalex.org/W4200177521",
        "https://openalex.org/W6752612501",
        "https://openalex.org/W2972418846",
        "https://openalex.org/W4239510810",
        "https://openalex.org/W2139212933",
        "https://openalex.org/W6824508966",
        "https://openalex.org/W6672681305",
        "https://openalex.org/W3154741768",
        "https://openalex.org/W3124863924",
        "https://openalex.org/W3213218849",
        "https://openalex.org/W2749526674",
        "https://openalex.org/W2976159681",
        "https://openalex.org/W3105625590",
        "https://openalex.org/W3159506165",
        "https://openalex.org/W3005922161",
        "https://openalex.org/W6659725491",
        "https://openalex.org/W2123760808",
        "https://openalex.org/W2101644390",
        "https://openalex.org/W3006942207",
        "https://openalex.org/W2803113975",
        "https://openalex.org/W1538449476",
        "https://openalex.org/W4200210418",
        "https://openalex.org/W4248802305",
        "https://openalex.org/W4256049924",
        "https://openalex.org/W1993576948",
        "https://openalex.org/W2419499132",
        "https://openalex.org/W2037450062",
        "https://openalex.org/W2088794999",
        "https://openalex.org/W2900120080"
    ],
    "abstract": "Misinformation and misleading actions have appeared as soon as COVID-19 vaccinations campaigns were launched, no matter what the country‚Äôs alphabetization level or growing index is. In such a situation, supervised machine learning techniques for classification appears as a suitable solution to model the value &amp; veracity of data, especially in the Arabic language as a language used by millions of people around the world. To achieve this task, we had to collect data manually from SM platforms such as Facebook, Twitter and Arabic news websites. This paper aims to classify Arabic language news into fake news and real news, by creating a Machine Learning (ML) model that will detect Arabic fake news (DAFN) about COVID-19 vaccination. To achieve our goal, we will use Natural Language Processing (NLP) techniques, which is especially challenging since NLP libraries support for Arabic is not common. We will use NLTK package of python to preprocess the data, and then we will use a ML model for the classification.",
    "full_text": "Arabic Language Modeling Based on Supervised Machine Learning \nOmayma Mahmoudi*, Mouncef Filali Bouami, Mustapha Badri \nLaboratory of Applied Mathematics and Information Systems, Mohammed Premier University in Oujda, Multidisciplinary \nFaculty of Nador, Nador 60000, Morocco \nCorresponding Author Email: mahmoudi.omayma@ump.ac.ma\nhttps://doi.org/10.18280/ria.360315 ABSTRACT \nReceived: 31 May 2022 \nAccepted: 22 June 2022 \nMisinformation and misleading actions have appeared as soon as COVID-19 vaccinations \ncampaigns were launched, no matter what the country‚Äôs alphabetization level or growing \nindex is. In such a situation, supervised machine learning techniques for classification \nappears as a suitable solution to model the value & veracity of data, especially in the Arabic \nlanguage as a language used by millions of people around the world. To achieve this task, \nwe had to collect data manually from SM platforms such as Facebook, Twitter and Arabic \nnews websites. This paper aims to classify Arab ic language news into fake news and real \nnews, by creating a Machine Learning (ML) model that will detect Arabic fake news \n(DAFN) about COVID-19 vaccination. To achieve our goal, we will use Natural Language \nProcessing (NLP) techniques, which is especially  challenging since NLP libraries support \nfor Arabic is not common. We will use NLTK package of python to preprocess the data, \nand then we will use a ML model for the classification. \nKeywords: \nmachine learning, Arabic natural language \nprocessing, fake news, real news, C OVID-\n19, vaccination \n1. INTRODUCTION\nThe emergence of social networks facilitated \ncommunication between people and the dissemination of news \nin general. It allowed the generation and the exchange of ideas \nthrough publications and comments until it became one of the \npowerful tools that helped disseminate and transmit \ninformation, especially Fake News [1]. There are two types of \nFake News [2]: \nThe first type is misinformation, which is unint ended, so \nthat a person can share information according to their ideas \nand the point of view. As for disinformation, it's role is to \ndeliberately propagate deceptive information to mislead and \nharm people. In both cases, misinformation negatively affects \npeople's experiences and decisions. \nThrough our work, we have exposed misinformation about \ncoronavirus vaccine as they have a serious impact on the \nhealth of individuals. There are many studies [2] in multiple \nlanguages in this field, especially in English. This is in contrast \nto the Arabic language, where the use of ML to detect false \nnews is uncommon, despite Arabic being one of the world's \nmost widely spoken languages. That's why, we decided to do \ngeneral processing of Arabic text. \nAmong the challenges that we have faced in this work is the \nlack of any data in news about the information related to \ncoronavirus vaccines in Arabic, which we had to collect from \nvarious social networks and websites, where we were able to \ncollect 1,000 pieces of information. \nThen, comes the role of NLP, a relevant artificial \nintelligence (AI) subdomain [3], able to reconstruct the spoken \nor written human language using computational methods. \nIn this work, we will focus on Arabic natural language \nprocessing (ANLP). Arabic, a language we master as a mother \ntongue, contains some challenging specificities because of its \ncomplexity and lexical variations . ML simulates behavior \nthrough the use of  learning algorithms that are adopted from \nvast amounts of data [4] that the computer learns and improves. \nAs a result, the term ‚Äúlearning‚Äù was coined. where \"learns\" \nfrom data and extracts information from it. ML engines, on the \nother hand, are algorithms [4]. \nThe social media interactions around COVID -19 \nvaccination campaigns are a representative example of a rising \nphenomenon on the internet: misinformation, and we believe \nit represents a real benchmark for the method deployed in this \npaper. NLP is appli ed for preprocessing the datasets with the \naim of using ML to deduce which of the four algorithms: SVM \n[5, 6], Random Forest (RF) [7], Logistic Regression [8, 9], and \nGradient Boosting [10] provides the best results. \nWhere they all excelled, RF has the hig hest proportion of \nF1-score ML classifiers with 91%. \nThis work is structured as follows. The related works are \ndescribed in the second section and the ANLP approach is \npresented in the third section. The main topic of the fourth \nsection is ML, as well as s ome of its algorithms. The fifth \nsection presents our methodology and results. The final section \ndiscusses the consequences of the detection of the Arabic \nmisinformation and the conclusion. \n2. RELATED WORKS\nSome studies classify misinformation detection as a hearsay \nresolution action with a multi -component model, such as \nmisinformation identification, tracking, and stance \ncategorization, which all assist in evaluating the veracity of \ndisinformation. misinformation approaches can differ based \non the data they're wanting (SM news such as comments, posts, \nand stories vs. large website articles), the ML algorithm used \nand the Language of preference. Some studies focus solely on \nthe main tweet or post, while others look at other aspect of the \nRevue d'Intelligence Artificielle \nVol. 36, No. 3, June, 2022, pp. 467-473 \nJournal homepage: http://iieta.org/journals/ria \n467\n\n \ninformation, such as  the conversation, responses, stories, and \ncomments. \nAl-Yahya et al. [11]  compared and evaluated the \nperformance of NN and transformer -based language models \nfor AFND. They also conducted a thorough investigation into \nthe likely causes of the disparities in  performance outcomes \nproduced by the various techniques. The results revealed that \ntransformer-based models beat NN, with the best transformer-\nbased model (QARiB) receiving 0.95 F1 -score and the best \npercentage among neural networks (GRU) receiving 0.83.  \nAs for de Oliveira  et al. [12], they investigated data \npreprocessing methods in natural language, routing, \ndimensionality reduction, ML, and assessing the quality of \ninformation retrieval. They also developed a definition to \ncontextualize misinformation a nd then discussed research \ninitiatives and opportunities.  \nBangyal et al. [13] started with data preprocessing using \nNLP, then applied a semantic model with TF -IDF weighting \nto describe the data, like with most research. They used eight \nmachine learning me thods for performance evaluation, \nincluding NB, Adaboost, CN, RF, LR, DT, NN, and SVM, as \nwell as deep learning algorithms: RNN, CNN, GRU, and \nLSTM. They then trained and validated the rating model based \non the results, and then tested it on a batch of unc lassified \nCOVID-19 fake news to forecast the sentiment category for \neach one. \nResearch paper [2] provided a conventional AFND \narchitecture based on textual features only. where the \nfollowing deep learning models were employed to evaluate the \nperformance: C NN, LSTM, BLSTM, CNN + LSTM, and \nCNN + BLSTM. The studies used three data sets, each of \nwhich contained the textual content of Arabic news stories. So, \nwhen using both basic training modes and repetition in the \ntraining process, the BLSTM model surpasses t he other \nmodels in terms of accuracy rate.  \nBased on our review of relevant works in the field of DAFN, \nit is clear that there is a limited amount of work in this area, \nthus, more research, investigation, and diversity are required. \nThat is why we chose th is topic to develop and cover the \nmajority of its aspects. \nIn Table 1, we summarize the previous works using the \ndifferent models. \n \nTable 1. Comparative table of previous works \n \nPrevious studies Models used Best \nresult \nAl-Yahya et al. \n[11] QARiB, GRU 0.95 \nBangyal et al. [13] CN, RF, LR, DT, NN, SVM, \nRNN, CNN, GRU, LSTM 0.97 \nKhalil et al. [2] CNN, LSTM, BLSTM, \nCNN+LSTM, CNN+BLSTM. 0.83 \n \n \n3. ARABIC NATURAL LANGUAGE PROCESSING \n \nToday, one of the most active areas of research in data \nscience is NLP [14]. It is a field at the intersection of ML and \nlinguistics. Its purpose is to extract information and meaning \nfrom textual content. \nNLP is used in a variety of ways in our daily lives, including: \ntext translation [15] (DeepL, for example), spell checker [16], \nautomatic content summary [17], speech synthesis [18], text \nclassification [19], opinion/sentiment analysis [20], prediction \nof the next word on a smartphone [21], named entity extraction \nfrom the text [22], etc. \nMost of the resources available today are in English, which \nimplies that most pre -trained models are also specific to the \nEnglish language. The method of pre -processing each \nlanguage differs from the other, since the Arabic language is \none of the rich languages.  That‚Äôs why, we have adopted i t in \nthis work. \nAmong the steps of the Arabic language pre-processing are: \ntokenization, punctuation and special characters removal, \nStopword removal, spell checking, named entity recognition \nand stemming. \nTo understand the steps of natural language pre -processing \nmore closely, we extracted a sentence from the dataset. Where \nwe applied all the steps mentioned earlier.  \nAs shown in Figure 1: \n \n \n \nFigure 1. The Implementation of the different steps of ANLP \n \n‚Ä¢ Tokenization: used to divide the sentence into terms [23]. \n‚Ä¢ Removal of punctuation and special characters: Used to \ndelete special characters and punctuation (The number \n10000 has disappeared). \n‚Ä¢ Stopword removal [24]: we also remove the empty words \n(we no longer see the words \"Ÿàand), \"ÿßŸÑŸâ\" to)). \n‚Ä¢ Spell-checking: its role is to check spelling. \n‚Ä¢ Named entity recognition: name entities are also removed \n((Bombay)\" ÿ®ŸàŸÖÿ®ÿßŸähas disappeared). \n‚Ä¢ Stemming [25]: consists in cutting the end of the words in \norder to keep only the root of the word. \n  \n468\n \nSo far, we have only standardized the terms, which is \ninsufficient for implementing ML techniques for classification, \nso it must first be converted into data that can be \nmathematically operated on. in this step, we finally manage to \ntransform our words, now in the form of tokens, into numbers. \nThere are several encoding methods, and each method has a \ndifferent principle, such as binary, Bag-of-Words (BoW), and \nterm frequency -inverse document frequency (TF -IDF) [26 , \n27]. \nTo know how each vectorization pattern works, we have got \nTable 2, it consists of 3 sentences in the Arabic language. Each \nsentence is considered news [12]. \n \n3.1 Binary vector space model \n \nIs the simplest vectorization model, in which a binary value \nhas been allocated to each vector (With a value of 1 indicating \nthat the phrase appeared in the document and a value of 0 \nindicating that it did not). As shown in Table 3, this \nrepresentation method is inadequate in terms of semantics \nbecause it provides no in sights into the role of a word for the \nset of texts. However, because it facilitates the generation of \nbinary comparison masks, this representation paradigm is very \nbeneficial for algorithms that processing techniques are \napplied to textual data. Furthermore, only a few computational \nresources are needed for this paradigm [12]. \nThe BoW method consists of using the entire corpus of data \nto encode the sentences. As we know that our corpus of data  \nwill never change, we will use it as a reference base to create \nencodings for the sentences. The idea is to count the number \nof times each word in the corpus appears in each of the \ndocuments, as shown in Table 4. \nMathematically expressed as follows. \nVd=[W1, W2,....., Wn-1, Wn] (1) \n \nwhere, Vd is the weight vecto r w for each sentence in the \ndocument d up to the n-the term. \nEach phrase entry relates to the count of the phrase entry \nthat corresponds to it. For example, in the first sentence (which \nrepresents sentence T1), the first two inputs are \"1,0\": \nThe first input corresponds to the word \"ŸÜÿµÿßÿ¶ÿ≠Tips) which \nis the first word of the sentence, and its value is \"1\" because \n\"ŸÜÿµÿßÿ¶ÿ≠Tips) appears once in the first sentence of T1. \nThe second input matches the word \"ŸÖÿ±ÿ∂ŸâPatients), \nwhich is the second word in the l ist, and its value is \"1\" \nbecause \"ŸÖÿ±ÿ∂ŸâPatients) occurs once in the third sentence of \nT3. \nThe TF -IDF is a measurement that allows, from a set of \ntexts, to know the relative importance of each word. This \nstatistical assessment allows you to assess the si gnificance of \na term in a document in comparison to a collection or a corpus. \nThe weight grows respect to the amount of times the term \nappears in the document. It differs as well depending on how \nfrequently the word appears in the corpus. \nMathematically, the equation is: \n \nùëæùíä,ùíã=ùíïùíáùíä,ùíã√óùê•ùê®ùê†(ùëµ/ùíÖùíáùíä) (2) \n \nwhere, ùë°ùëìùëñ=Number of occurrences of i in j; ùëëùëìùëñ=Number of \ndocuments containing i; N=Total number of documents. \nThe TF -IDF can be used to assess a document term's \nsemantic relevance in relation to the entire collection. As \nshown in Table 5, the number of rows and columns is the same \nas in the BoW model. The TF -ISF is a variant of the original \nTF-IDF that is commonly  used in summarizing texts at the \nsentence level rather than the document level.\n \nTable 2. A toy example for vectorization techniques. \n \n Arabic example English meaning \nText 1 (T1) 'ŸÜÿµÿßÿ¶ÿ≠', ' ÿ™ÿπÿ≤Ÿäÿ≤', 'ŸÖŸÜÿßÿπÿ©',' ÿ∂ÿØ','ŸÉŸàÿ±ŸàŸÜÿß',' ÿ™ÿ¨ŸÜÿ®','ÿßŸÑÿ¥ÿßÿ¶ÿπÿ©'  Tips', 'boost', 'immunity', 'against', 'corona', 'avoid', 'rumour' \nText 2 (T2) 'ÿßŸÑÿ¥ÿßÿ¶ÿπÿ©', ' ÿ≠ÿµŸÑ', 'ŸÑŸÇÿßÿ≠', ' ŸÉŸàÿ±ŸàŸÜÿß'  Rumours', 'happened', 'vaccine', 'corona' \nText 3 (T3) 'ŸÖÿ±ÿ∂Ÿâ', 'ŸÉŸàÿ±ŸàŸÜÿß', ' ÿ≠ÿµŸÑ', 'ŸÑŸÇÿßÿ≠'  Patients‚Äô, ‚ÄòCorona‚Äô, ‚ÄòHappened‚Äô, ‚ÄòVaccine‚Äô \n \nTable 3. The binary model vector representation of the sample corpus displayed in Table 2  \n \nTerms in Ar. ŸÜÿµÿßÿ¶ÿ≠ ŸÖÿ±ÿ∂Ÿâ ŸÖŸÜÿßÿπÿ©  ÿ∂ÿØ  ŸÉŸàÿ±ŸàŸÜÿß  ÿ™ÿ¨ŸÜÿ® ÿ¥ÿßÿ¶ÿπÿ© ŸÑŸÇÿßÿ≠ ÿ≠ÿµŸÑ \nCorr. Trans. to Eng. Tips Patients immunity against corona avoid rumor vaccine Happened \nT1 1 0 1 1 1 1 1 0 0 \nT2 0 0 0 0 1 0 1 1 1 \nT3 0 1 0 0 1 0 0 1 1 \n \nTable 4. BoW model representation of the collection apparent in Table 2 \n \nTerms in Ar. ŸÜÿµÿßÿ¶ÿ≠ ŸÖÿ±ÿ∂Ÿâ ŸÖŸÜÿßÿπÿ©  ÿ∂ÿØ  ŸÉŸàÿ±ŸàŸÜÿß  ÿ™ÿ¨ŸÜÿ® ÿ¥ÿßÿ¶ÿπÿ© ŸÑŸÇÿßÿ≠ ÿ≠ÿµŸÑ \nCorr. Trans. to Eng. Tips Patients immunity against corona avoid rumor vaccine Happened \nT1 1 0 1 1 1 1 1 0 0 \nT2 0 0 0 0 1 0 1 1 1 \nT3 0 1 0 0 1 0 0 1 1 \n \nTable 5. The TF-IDF model was used to represent the sample corpus in Table 2 \n \nTerms in Ar. ŸÜÿµÿßÿ¶ÿ≠ ŸÖÿ±ÿ∂Ÿâ ŸÖŸÜÿßÿπÿ©  ÿ∂ÿØ  ŸÉŸàÿ±ŸàŸÜÿß  ÿ™ÿ¨ŸÜÿ® ÿ¥ÿßÿ¶ÿπÿ© ŸÑŸÇÿßÿ≠ ÿ≠ÿµŸÑ \nCorr. Trans. to Eng. Tips Patients immunity against corona avoid rumor vaccine happened \nT1 0,60 0 0.73 0,90 0,90 0,73 0,60 0 0 \nT2 0 0 0 0 0,70 0 0,60 0,89 0,67 \nT3 0 0,80 0 0 0,93 0 0 0,78 0,81 \n  \n469\n \n4. MACHINE LEARNING \n \nML is a vital part of the rapidly expanding field of data \nscience [4]. Using statistical methods [28], algorithms are \ntaught to classify or predict data and identify key insights in \ndata mining projects [29]. These findings are then used to \ninform decisions made within applications and businesses, \nwith the goal of influencing key growth metrics. \nThere are two principal types of ML classifiers: \n(1) Supervised learning is an automatic learning technique \n(ALT) where the aim is to automatically produce rules from a \nlearning database containing \"examples\" (generally cases that \nhave already been verified and processed). \n(2) Unsupervised Learning  identifies clusters or groups \nbased on unlabeled data, with very little human intervention. \nIts capacity to find difference and similarity in data makes it \nan excellent categorization tool. \n \n4.1 Random forest classifier \n \nRF is a ML, d eep learning, and artificial intelligence \nlearning model that is used to make predictions. It is made up \nof several decision trees, each of which is focused on a \ndifferent aspect of the problem. Each produces an estimate, \nand the overall estimate is determ ined by the assembly of the \ndecision trees, where the analysis is performed. Subsets of \ndecision trees are randomly assigned to each model [30]. \nA RF operates on the bagging principle. The first step is to \nsplit of a dataset into subgroups (decision trees), after which a \ntraining model is proposed for each group. Finally, the \noutcomes of these trees are combined to produce the most \nreliable prediction. The final result can be determined in one \nof two ways. The mean of the forecasts obtained is calculated \nin a regression RF. As a result, all of the decision tree \npredictions are taken into account. It can also make a \nreasonable prediction without hyper -parameter tuning, as we \nwill see in the GridSearchCV section. \n \n4.2 GridSearchCV [31] \n \nWhen creating a RF, the number of decision trees and \nvariables must be previously established. The grid search is \nused to test several parameters and find the one that is most \nuseful. As a result, it's an optimization tool that's particularly \nuseful for determining the best p arameters for a forest of \ndecision trees. So, the Grid search is a hyper -parameter \noptimization method that allows us to test a series of \nparameters and compare performance to determine the best \nsetting. \nThe Grid Search is one of the simplest ways to test the \nparameters of a model among several options. For each \nparameter, we select a set of values to investigate. \n \n \n5. METHODOLOGY & RESULT \n \nAs mentioned earlier, the goal of this research is to develop \nan automated classification model to classify Arabic fake news \n(AFN) based on an analysis of the Arabic text using NLP and \nsupervised ML techniques. News articles containing any \nincorrect information are classified as \"fake,\" while articles \ncontaining all verified (correct) information are classified as \n\"real.\" \nBecause there are no AFN records about COVID -19 \nvaccination, we collected the data using hashtags and applied \nthe ANLP method. \nMethodological approach is composed of four basic steps. \nLike any ML model, we need a dataset to train a model to \npredict the class  of data in the test database. The raw AFN \ndataset is the fruit of a collection and preparation work. Each \npiece of information was transformed into a feature vector and \nsaved to an xlsx file. To our knowledge, and based on our \nresearch, a public dataset f or AFN containing both fake and \nreal news with enough characteristics does not exist. We then \nmerged two collected databases \"Getting Real about AFN \" \ncontaining false and real news about the vaccination of \nCOVID-19 and \"All the news\" containing the real news. These \ndatabases were obtained after collecting them from several \nsites and SM. Getting Real about AFN: It contains text and \nmetadata extracted from SM (Facebook, Instagram,) and \nwebsites. To collect the dataset, we used the following \nhashtags present in Table 6: \n \nTable 6. List of hashtags used to collect the dataset \n \n# Hashtags English Translation \n1 ŸÑŸÇÿßÿ≠# Corona vaccine \n2 ŸÑŸÇÿßÿ≠# Corona virus vaccine \n3 ŸÑŸÇÿßÿ≠# New Corona vaccine \n4 ŸÑŸÇÿßÿ≠19# COVID 19 vaccine \n5 ŸÑŸÇÿßÿ≠ÿßŸäÿ≤ÿ±#  Pfizer vaccine \n \n5.1 Data pre-processing \n \nIn order to create a NLP model, the first step is cleaning the \ndata. The dataset can have unnecessary characters and missing \nvalues. \n \n5.2 Data cleaning \n \n‚Ä¢ Deleting unnecessary characters: delete the following \ncharacters from text column: #.][! ()\"\". \n‚Ä¢ Deleting punctuations. \n‚Ä¢ Text correction. \n‚Ä¢ Deleting repeating characters [13]. \n \n5.3 Tokenizing \n \nThe purpose of tokenization is to break up text into smaller \nentities called tokens. The definition of what a token is, varies \ndepending on the tokenizer used. A token can be a word, a \ncharacter, or a sub -word. Tokenization is a fundamental step \nin every ANLP operation. Given the different existing \nlinguistic structures, tokenization is different in each language. \n \n5.4 Stopwords \n \nIt's common to remove Stopwords. Stopwords are \nconsidered common words in the language, but they do not \nhave important information. Arabic Stopwords contain ¬´ŸÑŸÉŸÜ\n\"ŸÖŸÜ \" \"Ÿà\", \"ŸÅ \",\"ŸÑ ¬ª  in English (\"But \", \"of\", \"and\", \"q\", \"for \"). \nSome words like ¬´  ŸÉŸäŸÅ¬´  ¬´ in English ( \"How\", \"and\") \n(have extremely high recurrence in all Arabic texts and \nprovide no meaning as our model will use to make predictions. \nRemoving them will reduce noise and let our model focus only \non the relevant words. To do this, we will us e a list and close \n470\n \non all articles by deleting all the words that appear in the list \n[32]. \n \n5.5 Stemming \n \nStemming consists of reducing a word to its ‚Äúroot‚Äù form. \nThe purpose of stemming is to group many variations of a \nword together as a single word. For example, once we apply a \nstemming to \" ŸäŸÉÿ™ÿ®ŸàŸÜ they write) or \"ŸÉÿ™ÿ®Wrote), the \nresulting word is the same. This makes it possible in particular \nto reduce the size of the vocabulary in BoW or TF -IdF type \napproaches. \nOne of the best-known stemmers is the Snowball Stemmer. \nThis stemmer is available in Arabic language. \n \n5.6 Data vectorization \n \nThe majority of ALT do not use text directly, but instead a \ndigital vector converts the text to a digital vector based. We \nuse the \"bag -of-words\" method to calculate the frequency of \neach term [13]. \n \n5.7 Model evaluation and testing \n \n \n \nFigure 2. Research methodology \n \nFor training and evaluating our model, we use performance \nmeasures. Then, we test the model  with a set of test data \nrepresenting a set of unclassified AFN for  COVID-19 \nvaccination, to predict the misinformation class of each \ndataset. \nWe calculated five metrics to evaluate performance. \nPrecision is the percentage of related cases among all \nrecovered occurrences, and recall basically divides the sum of \nthe recovered relative documents. The F1 counts the average \nrecall and precision score. Also, the confusion matrix which is \na measurement of various parameters used to evaluate the \nperformance of the classification algorithm [13]. \nFour different classifiers were used to analyze false \ninformation about COVID -19 vaccination. Which are: RF, \nSVM, LR, and GB. According to the results of this search, we \nfind RF classifiers and logistic regression performance better \nthan other learning methods as they achieved a very high \naccuracy of 91%. \nThe Figure 2, presents the structure of the classification \nsystem [13]. \nTo evaluate the performance of the model, we will run the \ntests on a different set of tests to estimate the performance of \nthe generalized model. \n \n5.8 Evaluation metrics for ML algorithms \n \nEvaluating ML algorithms is capital in the sense that a \nmodel may produce satisfactory results when tested against a \nmetric such as accuracy score, but it may produce poor results \nwhen tested against other metrics. For example, logarithmic \nloss or any other metric of this type. The majority of the time, \nwe utilize classification accuracy to evaluate the performance \nof our model; nevertheless, this is insufficient to fully analyze \nour model. This paragraph will go over the various types of \nevaluation metrics that are available [33]. \nClassification Accuracy : Classification when we use the \nterm \"accuracy,\" we usually mean \"accuracy.\" It is the \nproportion of correct predictions to total sample count. It only \nworks properly if each class has an equal number of samples. \nLogarithmic Loss:  Logarithmic Loss, also kno wn as Log \nLoss, works by penalizing incorrect classifications. It is \neffective for multi -class classification. When employing Log \nLoss, the classifier must give a probability to each class for \neach sample.  \nThere is no upper bound to Log Loss, and it exist s in the \nrange [0, ‚àû). A smaller Log Loss suggests more precision, \nwhile a higher Log Loss indicates lesser accuracy. \nIn general, minimizing Log Loss improves the classifier's \nperformance. \nConfusion Matrix: is produces a matrix as an output, which \ndescribes the model's overall performance. Let's pretend we're \ndealing with a binary classification problem. We have some \nsamples that fall into one of two categories: yes or no. We also \nhave our own classifier that predicts the class of an input \nsample. \nThere are 4 important terms: \n(1) TP: (true positive) Correctly predicted the value as \npositive.  \n(2) TN: (true negative) Correctly predicted the value as \nnegative. \n(3) FP: (false positive) I mistakenly classified the value as \npositive, but they are actually negative. \n(4) FN: (false negative) I mistakenly classified the value as \nnegative, but they are actually positive. Various evaluation \nmetrics are displayed in Table 7 [33]. \nThe following Table 8 shows the four classification models \nselected for this work, representing a variety of machine \nlearning techniques and have been confirmed utilizing metrics \nF1-score, we have obtained the following results: \nFrom the previous Table 8, we can see that the results are \ntoo close, so actually any choice would be great. W e have \ndecided to use the RF Classifier since it got the highest cross \nvalidation F1 score. \n \n \n \n \n471\n \nTable 7. Evaluation metrics \n \nMetric Equation Explanation \nAccuracy (acc) ùëáùëÉ +ùëáùëÅ\nùëáùëÉ +ùëáùëÅ+ùêπùëÉ+ùêπùëÅ The percentage of correctly classified observations. \nPrecision (P) ùëáùëÉ\nùëáùëÉ+ùêπùëÉ The percentage of positive classes correctly classified from a set of observations predicted to be positive. \nRecall (R) ùëáùëÉ\nùëáùëÉ +ùëáùëÅ The percentage of positive classes that were correctly classified from the total number of observations. \nF1 Score 2‚àóùëÉ‚àóùëÖ\nùëÉ +ùëÖ  The harmonic mean of precision and recall metrics \n \nTable 8. Model selection \n \nAlgorith. Fold 1 Fold 2 Fold 3 Fold 4 Fold 5 Mean \nRF Classifier 0.9085 0.9085 0.9085 0.9085 0.9085 0.9185 \nLR 0.9111 0.9005 0.9247 0.9155 0.9159 0.9135 \nGradient Boosting Classifier 0.9000 0.8795 0.9209 0.9234 0.9214 0.9090 \nLinear SVM 0.9039 0.8907 0.9180 0.9080 0.9000 0.9041 \n \nAfter tuning our model using GridSearchCV, we have \ntested multiple values for each parameter, and finally we have \nobtained the following optimized parameter. As shown in \nFigure 3: \n \n \n \nFigure 3. RF Parameters \n \nFigure 4 present the following findings after training the \nmodel: \n \n \n \nFigure 4. Model report \n \nThe average mean cross validation score is not enough to \ndecide whether the model is good or not. In order to decide \nthat, we have to use evaluation metrics: The F1-score obtained \non our test set is 0.9.  The recall obtained on our test set is 1 \nand the accuracy obtained: 0.86. \n \n \n6. COMPARATIVE DISCUSSION \n \nThe results of all of the ML models that were tested can be \nfound in the Table 7 . On a vast set of data for COVID -19 \nvaccine AFND, we tested various models using the cross -\nvalidation in the training -test proc ess. Although certain \nclassifiers outperformed other ML classifiers in terms of F1-\nscore, they all performed admirably. RF has the most F1-score \nML classifiers, with 91%. 90% was attained using logistic \nregression and support vector machines. \n \n \n7. CONCLUSIONS \n \nThe pace of information sharing has increased \nexponentially Throughout the previous decade thanks to the \nrapid adoption of SM platforms such as Facebook, Twitter and \nInstagram. Besides, this fast information growth, comes with \nside effects suc h as sharing AFN. Users are creating, \nconsuming and sharing more information every day. The \ninformation could be real or not. AFN classification is a \nchallenging research area, especially for languages that have \nfew or no support at all of NLP libraries. In this paper, we have \nexplored the methods and explained the pipeline we have used \nto create a ML model that would classify textual data to fake \nor real ones. We have trained the model using data that we \ncollected manually from SM. In order to create the m odel, we \nhave used python programming language and its libraries, and \nwe have used four supervised learning models: Gradient \nBoosting and Support Virtual Machine. Finally, we have tuned \nits parameters using GridSearchCV. The model could be \nfurther improved by training it on more data, since our dataset \nis imbalanced. Getting more misinformation would help the \nmodel by getting more accurate results. We have talked about \nANLP and its methods. Then we explained how we would \napply those methods on our Arabic da taset. Finally, we have \ngone through the implementation and the results of the \napplication. \nWe hope to use a bigger and more complicated dataset in \nthe future, and It's also possible to increase the number of \nlabels. Other languages can be included by usin g special \ncharacters and numeric values. Emoticons, which are \nfrequently used in SM largely to represent expressions, would \nbe useful to include. \n \n \nREFERENCES  \n \n[1] Bondielli, A., Marcelloni , F. (2019). A survey on fake \nnews and rumour detection techniques. Information \nSciences, 497: 38-55. \nhttps://doi.org/10.1016/j.ins.2019.05.035 \n[2] Khalil, A., Jarrah, M., Aldwairi, M., Jararweh, Y. (2021). \nDetecting Arabic fake news using machine learning. In  \n2021 Second International Conference on Intelligent \nData Science Technologies and Applications (IDSTA), \npp. 171-177. https://doi.org/10.32604/cmc.2022.021449 \n[3] Chopra, A., Prashar, A., Sain, C. (2013). Natural \nlanguage processing. International Journal of \nTechnology Enhancements and Emerging Engineering \nresearch, 1(4): 131-134. \n472\n \n[4] Wei, J., Chu, X., Sun, X. Y., Xu, K., Deng, H.X., Chen, \nJ., Wei, Z., Lei, M. (2019). Machine learning in materials \nscience. InfoMat, 1(3): 338 -358. \nhttps://doi.org/10.1002/inf2.12028 \n[5] Cortes, C., Vapnik, V. (1995). Support-vector networks. \nMachine Learning, 20: 273 -297. \nhttps://doi.org/10.1007/BF00994018 \n[6] Burges, C .J.C. (1998). A tutorial on support vector \nmachines for pattern recognition. Data Mining and \nKnowledge Discovery volume, 2: 1 21-167. \nhttps://doi.org/10.1023/A:1009715923555 \n[7] Rigatti, S.J. (2017). Random forest. Journal of Insurance \nMedicine, 47(1): 31-39. \n[8] Wright, R.E. (1995). Logistic regression. In L. G. Grimm, \n& P. R. Yarnold (Eds.), Reading and Understanding \nMultivariate Stati stics (pp. 217 -244). Washington DC: \nAmerican Psychological Association. \n[9] LaValley, M.P. (2008). Logistic regression. Circulation \n2008; 117: 2395-2399. \nhttps://doi.org/10.1161/CIRCULATIONAHA.106.6826\n58 \n[10] Natekin, A., Knoll, A. (2013). Gradient boosting \nmachines, a tutorial. Frontiers in neurorobotics, 7: 21. \n[11] Al-Yahya, M., Al-Khalifa, H., Al-Baity, H., AlSaeed, D., \nEssam, A. (2021). Arabic fake news detection: \ncomparative study of neural networks and transformer -\nbased approaches. Complexity , 2021: 5516945 . \nhttps://doi.org/10.1155/2021/5516945 \n[12] de Oliveira, N.R., Pisa, P.S., Lopez, M.A., de Medeiros, \nD.S.V., Mattos, D.M. (2021). Identifying fake news on \nsocial networks based on natural language processing: \ntrends and challenges. Information, 12(1): 38. \nhttps://doi.org/10.3390/info12010038 \n[13] Bangyal, W.H., Qasim, R., Ahmad, Z., Dar, H., Rukhsar, \nL., Aman, Z., Ahmad, J. (2021). Detection of fake news \ntext classification on COVID -19 using deep learning \napproaches. Computational and Mathematical Methods \nin Medicine , 2021: 5514220. \nhttps://doi.org/10.1155/2021/5514220 \n[14] Chong, M., Specia, L., Mitkov, R. (2010). Using natural \nlanguage processing for automatic detection of \nplagiarism. In Proceedings of the 4th International \nPlagiarism Conference (IPC-2010). \n[15] Evans, J.A., A ceves, P. (2016). Machine translation: \nMining text for social theory. Annual Review of \nSociology, 42: 21 -50. https://doi.org/10.1146/annurev-\nsoc-081715-074206 \n[16] Altarawneh, R. (2017).  Spelling detection errors \ntechniques in NLP: A survey. Jordan ‚Äì Alsalt, 172: 1-5. \n[17] Garbade, M.J. (2018). A quick introduction to text \nsummarization in machine learning. Towards Data \nScience. \n[18] Ning, Y., He, S., Wu, Z.Y., Xing, C.X., Zhang, L.J. \n(2019). A review of deep learning based speech synthesis. \nApplied Sciences,  9(19): 4050 . \nhttps://doi.org/10.3390/app9194050 \n[19] Kowsari, K., Jafari Meimandi, K., Heidarysafa, M., \nMendu, S., Barnes, L., Brown, D. (2019). Text \nclassification algorithms: A survey. Information, 10(4): \n150. https://doi.org/10.3390/info10040150 \n[20] Kastrati, Z., Dalipi, F. , Imran, A. S., Pireva Nuci, K., \nWani, M.A. (2021). Sentiment analysis of students‚Äô \nfeedback with NLP and deep learning: A systematic \nmapping study. Applied Sciences, 11(9): 3986.  \nhttps://doi.org/10.3390/app11093986 \n[21] Hard, A., Rao, K., Mathews, R., et al. (2018). Federated \nlearning for mobile keyboard prediction. arXiv preprint \narXiv:1811.03604. https://arxiv.org/abs/1811.03604. \n[22] Al-Smadi, M., Al -Zboon, S., Jararweh, Y., Juola, P. \n(2020). Transfer learning for Arabic named entity \nrecognition with deep neural networks. I EEE Access, 8: \n37736-37745. \nhttps://doi.org/10.1109/ACCESS.2020.2973319 \n[23] Webster, J.J., Kit, C. (1992). Tokenizatio n as the initial \nphase in NLP. In COLING 1992 volume 4: The 14th \ninternational conference on computational linguistics. \n[24] Al-Shalabi, R., Kanaan, G., Jaam, J. M., Hasnah, A., \nHilat, E. (2004). Stop-word removal algorithm for Arabic \nlanguage. In Proceedings. 2004 International Conference \non Information and Communication Technologies: From \nTheory to Applications. \nhttps://doi.org/10.1109/ICTTA.2004.1307875 \n[25] Pande, B.A., Dhami, H.S. (2011). Application of natural \nlanguage processing tools in stemming. Internationa l \nJournal of Computer Applications, 27(6): 14-19. \n[26] Shahmirzadi, O., Lugowski, A., Younge, K. (2019). Text \nsimilarity in vector space models: a comparative study. \nIn 2019 18th IEEE international conference on machine \nlearning and applications (ICMLA), pp. 65 9-666. \nhttps://doi.org/10.1109/ICMLA.2019.00120 \n[27] Walkowiak, T., Datko, S., Maciejewski, H. (2018). Bag-\nof-words, bag -of-topics and word -to-vec based subject \nclassification of text documents in polish -a comparative \nstudy. In International Conference on Dependability and \nComplex Systems, pp. 526 -535. \nhttps://doi.org/10.1007/978-3-319-91446-6_49 \n[28] Boulesteix, A.L., Schmid, M. (2014). Machine learning \nversus statistical modeling. Biometrical Journal, 56(4): \n588-593. https://doi.org/10.1002/bimj.201300226 \n[29] Raval, K.M. (2012). Data mining techniques. Gujarat ‚Äì \nIndia. \n[30] Mbaabu, O. (2020). Introduction to random forest in \nmachine learning. https://www.section.io/engineering -\neducation/introduction-to-random-forest-in-machine-\nlearning. \n[31] Kartini, D., Nugrahadi, D. T., Farmadi , A. (2021). \nHyperparameter tuning using GRIDSEARCHCV on the \ncomparison of the activation function of the ELM \nmethod to the classification of pneumonia in toddlers. In \n2021 4th International Conference of Computer and \nInformatics Engineering (IC2IE), pp. 3 90-395. \nhttps://doi.org/10.1109/IC2IE53219.2021.9649207 \n[32] Khanna, C.  (2021). Text pre -processing: Stop words \nremoval using  different libraries.  \nhttps://towardsdatascience.com/text-pre-processing-\nstop-words-removal-using-different-libraries-\nf20bac19929a/, accessed on Jul. 15, 2022.  \n[33] Brownlee, J . (2020). Tour of  evaluation metrics for \nimbalanced classification . Machine Learning Mastery. \nhttps://machinelearningmastery.com/tour-of-evaluation-\nmetrics-for-imbalanced-classification/. \n \n473"
}