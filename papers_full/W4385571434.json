{
  "title": "KWJA: A Unified Japanese Analyzer Based on Foundation Models",
  "url": "https://openalex.org/W4385571434",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2101314722",
      "name": "Nobuhiro Ueda",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A2515332104",
      "name": "Kazumasa Omura",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A1722717902",
      "name": "Takashi Kodama",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A2854659833",
      "name": "Hirokazu Kiyomaru",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A2096275950",
      "name": "Yugo Murawaki",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A2047746676",
      "name": "Daisuke Kawahara",
      "affiliations": [
        "Waseda University"
      ]
    },
    {
      "id": "https://openalex.org/A112209514",
      "name": "Sadao Kurohashi",
      "affiliations": [
        "Kyoto University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3155584966",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W3166523559",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W3122890974",
    "https://openalex.org/W3214257389",
    "https://openalex.org/W1902237438",
    "https://openalex.org/W2962883855",
    "https://openalex.org/W3018647120",
    "https://openalex.org/W2891475925",
    "https://openalex.org/W2964198424",
    "https://openalex.org/W3037109418",
    "https://openalex.org/W3031430352",
    "https://openalex.org/W4205086899",
    "https://openalex.org/W2989539713",
    "https://openalex.org/W1472981785",
    "https://openalex.org/W2110737727",
    "https://openalex.org/W3118109417",
    "https://openalex.org/W2880875857",
    "https://openalex.org/W4235588077",
    "https://openalex.org/W2911498515",
    "https://openalex.org/W2970744242",
    "https://openalex.org/W2130942839",
    "https://openalex.org/W2943552823",
    "https://openalex.org/W2963021447",
    "https://openalex.org/W3035143114",
    "https://openalex.org/W2515447957",
    "https://openalex.org/W827795486",
    "https://openalex.org/W165283731",
    "https://openalex.org/W102026425",
    "https://openalex.org/W2574640638",
    "https://openalex.org/W2108131731"
  ],
  "abstract": "Nobuhiro Ueda, Kazumasa Omura, Takashi Kodama, Hirokazu Kiyomaru, Yugo Murawaki, Daisuke Kawahara, Sadao Kurohashi. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations). 2023.",
  "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 3: System Demonstrations, pages 538‚Äì548\nJuly 10-12, 2023 ¬©2023 Association for Computational Linguistics\nKWJA: A Unified Japanese Analyzer Based on Foundation Models\nNobuhiro Ueda1, Kazumasa Omura 1, Takashi Kodama 1,\nHirokazu Kiyomaru1, Yugo Murawaki 1, Daisuke Kawahara 2, Sadao Kurohashi 1\n1 Kyoto University, Kyoto, Japan,\n2 Waseda University, Tokyo, Japan\n{ueda,omura,kodama,kiyomaru,murawaki,kuro}@nlp.ist.i.kyoto-u.ac.jp,\ndkw@waseda.jp\nAbstract\nWe present KWJA, a high-performance uni-\nfied Japanese text analyzer based on founda-\ntion models. KWJA supports a wide range of\ntasks, including typo correction, word segmen-\ntation, word normalization, morphological anal-\nysis, named entity recognition, linguistic fea-\nture tagging, dependency parsing, PAS analysis,\nbridging reference resolution, coreference reso-\nlution, and discourse relation analysis, making\nit the most versatile among existing Japanese\ntext analyzers. KWJA solves these tasks in a\nmulti-task manner but still achieves competi-\ntive or better performance compared to exist-\ning analyzers specialized for each task. KWJA\nis publicly available under the MIT license at\nhttps://github.com/ku-nlp/kwja.\n1 Introduction\nEnd-to-end neural network-based models have be-\ncome mainstream for many NLP tasks including\nmachine translation (Sutskever et al., 2014; Luong\net al., 2015; Vaswani et al., 2017) and dialogue re-\nsponse generation (Serban et al., 2015; Roller et al.,\n2020). However, end-to-end models are not always\nthe best means of developing an NLP application\nbecause exploratory tasks, such as information anal-\nysis and causal analysis, inherently require manual\ntrial-and-error processes. We believe that for such\ntasks, text analysis still plays an important role.\nText analysis, including morphological analy-\nsis, dependency parsing, predicate-argument struc-\nture (PAS) analysis, and discourse relation analysis,\nsaw shifts in model architectures. Recent studies\ndemonstrate that foundation models (Bommasani\net al., 2021) drastically improve the performance in\ndependency parsing (Zhou and Zhao, 2019), PAS\nanalysis (Ueda et al., 2020; Umakoshi et al., 2021),\nand discourse relation analysis (Kishimoto et al.,\n2020; Kiyomaru and Kurohashi, 2021). Moreover,\nimprovements on foundation models tend to have\na greater impact on performance than incremental\nimprovements tailored to individual tasks (Bom-\nmasani et al., 2021).\nIn this study, we design and build a unified\nJapanese text analyzer, KWJA, 1,2 in view of the\nfact that recent high-performance text analysis mod-\nels are all based on foundation models. KWJA sup-\nports a wide variety of text analysis tasks: typo\ncorrection, word segmentation, word normaliza-\ntion, morphological analysis, named entity recogni-\ntion, linguistic feature tagging, dependency parsing,\nPAS analysis, bridging reference resolution, coref-\nerence resolution, and discourse relation analysis\n(Figure 1, Table 1).\nOur emphasis is on usability in addition to per-\nformance. KWJA provides a single command to\nperform a variety of text analyses, collapsing the\npainstaking steps previously needed to obtain the\nsame result, namely, installing and combining mul-\ntiple text analyzers, one for each task.\nThe design policy of KWJA is to minimize the\namount of code and hand-written rules by max-\nimally exploiting the power of foundation mod-\nels. This is a drastic departure from the traditional\nJapanese analysis suite, including the morphologi-\ncal analyzers JUMAN (Kurohashi et al., 1994)3 and\nJuman++ (Tolmachev et al., 2018)4 and the depen-\ndency parser KNP (Kurohashi and Nagao, 1994),5\nwhich rely heavily on manually constructed dic-\ntionaries, rules, and features. Such lexical knowl-\nedge is context insensitive and suffers from limited\ncoverage. Motivated by the observation that foun-\ndation models learn massive knowledge through\npre-training on large raw corpora, we narrow our\nefforts to supervised learning from relatively small\nannotated corpora. This approach enables us to sup-\nport a new task just by constructing an annotated\n1Kyoto-Waseda Japanese Analyzer.\n2Video demo: https://youtu.be/p2x_IrSmS20\n3https://github.com/ku-nlp/juman\n4https://github.com/ku-nlp/jumanpp\n5https://github.com/ku-nlp/knp\n538\n‡≥îŒò‡©ñŒïÕ©8PSE4FHNFOUBUJPO8PSE/PSNBMJ[BUJPO\n.PSQIPMPHJDBM\"OBMZTJT\n%JTDPVSTF\u00013FMBUJPO\u0001\"OBMZTJT\n·ªô5ZQP$PSSFDUJPO‡≥îÕ∏‡©ñŒïÕ©‡≥îÕ∏‡©ñŒïÕ©DIBSBDUFSTDPSSFDUFEDIBSBDUFSTXPSET #\u0000S-ID:1\u0000kwla:1.0.0*\u00001D+\u00001D\u0000<NE:DATE:‰ªä‚Ωá><‰Ωì‚æî><ÊôÇÈñì>‰ªä‚Ωá‰ªä‚Ωá‰ªä‚ΩáÂêçË©û6\u0000ÊôÇÁõ∏ÂêçË©û10\u0000*\u00000\u0000*\u00000\u0000<Âü∫Êú¨Âè•-‰∏ªËæû>„ÅØ„ÅØ„ÅØÂä©Ë©û9\u0000ÂâØÂä©Ë©û2\u0000*\u00000\u0000*\u00000*\u0000-1D+\u0000-1D\u0000<reltype=‚Äú„Ç¨‚Äù\u0000target=‚Äú‰ªä‚Ωá\"\u0000sid=\"1\"\u0000id=‚Äù0\"/><‚Ω§‚æî:Âà§><‰Ωì‚æî><ÊôÇÂà∂:‚æÆÈÅéÂéª><ÁØÄ-‰∏ªËæû><ÁØÄ-Âå∫Âàá><„É¨„Éô„É´:C><Áä∂ÊÖãËø∞Ë™û>Êô¥„ÇåÊô¥„ÇåÊô¥„ÇåÂêçË©û6\u0000ÊôÆÈÄöÂêçË©û1\u0000*\u00000\u0000*\u00000\u0000<Âü∫Êú¨Âè•-‰∏ªËæû><‚Ω§‚æîË°®Ë®òÂÖàÈ†≠><‚Ω§‚æîË°®Ë®òÊú´Â∞æ>„Å†„Å†„Å†Âà§ÂÆöË©û4\u0000*\u00000\u0000Âà§ÂÆöË©û25\u0000Âü∫Êú¨ÂΩ¢2EOS\nBOBMZ[FE\u0001UFYU\n·ªô ·ªô·ªô\n1. Typo Module2. Character Module3. Word Module\nIt‚Äôz sunny todayIt‚Äôs sunny todayIt  ‚Äô  s  sunny  today\nFigure 1: A flowchart of the analysis process in KWJA. KWJA consists of the typo module, character module, and\nword module. An input text is processed through each module.\nAnalysis Component Input Output Unit Output\nTypo Correction characters character corrected characters\nWord Segmentation corrected charactersword words\nWord Normalization word normalized words\nMorphological Analysis\nwords\nword POS, conjugation, lemma, and reading\nNamed Entity Recognition word named entity spans and categories\nLinguistic Feature Tagging word word features\nbase phrase base phrases features\nDependency Parsing word dependency tree and dependency types\nbase phrase dependency tree and dependency types\nPAS Analysis base phrase predicates and their arguments\nBridging Reference Resolution base phrase anaphors and their referents\nCoreference Resolution base phrase coreferring mentions\nDiscourse Relation Analysis clause discourse relations\nTable 1: Input and output of each analysis component. A base phrase is a unit consisting of a single independent\nword and its ancillary words (Hangyo et al., 2012). We group the components into three blocks (separated by\nhorizontal lines) for multi-task learning.\ncorpus for the task.\nKWJA reorganizes text analysis tasks into a\ndozen of components, as shown in Table 1, on\nthe ground of task independence and the units of\ninputs and outputs. A notable difference from con-\nventional morphological analysis is that while it is\nusually defined as the joint task of word segmenta-\ntion, part-of-speech (POS) tagging, and the tagging\nof lexical information, such as lemmas and read-\nings, we divide the task into word segmentation\nand the remaining tasks. For convenience, we refer\nto the latter as morphological analysis.\nEach analysis component utilizes a fine-tuned\nTransformer. As Transformer consumes a consider-\nable amount of computational resources, we resort\nto multi-task learning to reduce the model parame-\nters. We group the components into three modules:\nthe typo module, character module, and word mod-\nule. Within each module, analysis components\nshare most of their model parameters and run con-\ncurrently. Consequently, KWJA executes all the\ncomponents in three steps (Figure 1).\nAlthough KWJA is extremely slow for users\nwho only need word segmentation, it is the most\npractical choice for advanced text analysis, for\nwhich, after all, only Transformer achieves state-of-\nthe-art performance. KWJA is publicly available\nunder the MIT license at https://github.com/\nku-nlp/kwja.\n2 Related Work\nTraditionally, Japanese text analysis tasks have\nbeen tackled individually, with separate analyzers\nfor each task. Juman++ (Tolmachev et al., 2018)\nand Mecab (Kudo et al., 2004) are examples of mor-\nphological analyzers, while KNP (Kurohashi and\nNagao, 1994) is a dependency parser. Juman++ and\nMecab segment Japanese text into words and assign\nlexical information to each word using manually\nconstructed dictionaries. KNP assigns dependency\nrelations between phrases using linguistic features\nobtained from Juman++ and external dictionaries.\nIn addition to dependency parsing, KNP handles\nnamed entity recognition, linguistic feature tagging,\nand PAS analysis. KWJA, however, supports an\neven broader range of tasks.\nThe Universal Dependencies (UD)\nproject (Nivre et al., 2020) standardizes the\n539\nannotation of dependency structures across\nlanguages. While their focus is on dependency\nrelations, the UD guidelines define word units,\nPOS tags, and other linguistic features. The tasks\nsupported by major UD-based analyzers, UD-\nPipe (Straka et al., 2016), spaCy,6 and Stanza (Qi\net al., 2020), are sentence segmentation, word\nsegmentation, POS tagging, lemmatization, and\ndependency parsing.7 In other words, higher-level\ntasks such as PAS analysis and discourse relation\nanalysis are out of the scope of these analyzers.\nA major advantage of UD-based analyzers is\nthat they can handle multiple languages. This is\ndone at the expense of ignoring language-specific\nfeatures (Kanayama et al., 2018). For the purpose\nof pioneering task design, it is reasonable to focus\non a single language.\nGiNZA8 is also a UD-based analyzer but special-\nizes in Japanese. GiNZA supports morphological\nanalysis, dependency parsing, and named entity\nrecognition. GiNZA v5 improved the dependency\nparsing performance by utilizing the foundation\nmodel ELECTRA.\nKachako (Kano, 2013) and Jigg (Noji and Miyao,\n2016) have been proposed as frameworks for com-\nbining existing analysis tools to form a pipeline.\nThese works aim to improve the usability of exist-\ning analysis tools. In contrast, our goal is to design\nand build a unified analyzer itself.\n3 Resources\nThis section presents the model and data resources\nused when training the modules in KWJA.\n3.1 Foundation Models\nAs a foundation model, we adopt DeBERTa (He\net al., 2021), which has shown high performance\nin the SuperGLUE language understanding bench-\nmark (Wang et al., 2019). We pre-trained character-\nlevel9 and word-level10 DeBERTa V2 large models\non Japanese texts. The typo and character module\nemploys the character-level model, and the word\nmodule employs the word-level model.\n6https://spacy.io\n7Using extra resources, spaCy and Stanza support named\nentity recognition in some languages.\n8https://github.com/megagonlabs/ginza\n9https://huggingface.co/ku-nlp/\ndeberta-v2-large-japanese-char-wwm\n10https://huggingface.co/ku-nlp/\ndeberta-v2-large-japanese\n3.2 Annotated Corpora\nWe use the Japanese Wikipedia Typo Dataset\n(JWTD v2, Tanaka et al., 2021) to train a typo\ncorrection model. JWTD was created by mining\ntypos from the edit history of Japanese Wikipedia.\nWe use the Kyoto University Text Corpus (KC,\nKurohashi and Nagao, 1998), 11 the Kyoto Uni-\nversity Web Document Leads Corpus (KWDLC,\nHangyo et al., 2012),12 and the Annotated Fuman\nKaitori Center Corpus (Fuman)13 to train models\nfor tasks other than typo correction. Note that as for\ndiscourse relation analysis, we use only KWDLC\nbecause the other two corpora do not have dis-\ncourse relation annotations.\n4 Architecture\nEach analysis component of KWJA uses a\nTransformer-based (Vaswani et al., 2017) founda-\ntion model. We add two layers of feed-forward\nneural networks for each task and fine-tune the\nwhole model.\nKWJA formulates the text analysis tasks as a se-\nquence labeling task, word selection task, or word\nrelation classification task. A sequence labeling\ntask assigns a label to each character or word in a\ntext. Figure 2 shows an example of solving named\nentity recognition as a sequence labeling task. In a\nword selection task, a word is selected from a text\nfor each given word in the text. Figure 3 shows an\nexample of solving dependency parsing as a word\nselection task. A word relation classification task\nassigns a label to each word pair in a text.\nTo reduce computational time and space, the\nmodel parameters of the analyzer are shared as\nmuch as possible through multi-task learning. The\ntasks in each block separated by the horizontal\nlines in Table 1 are the unit of multi-task learning.\nMulti-task learning is not possible for the pair of\nword segmentation and morphological analysis, for\nexample, because the latter‚Äôs input depends on the\nformer‚Äôs output. In this study, we perform multi-\ntask learning for tasks in each block. Thus, KWJA\nconsists of three modules corresponding to each\nblock. These modules are referred to as the typo,\ncharacter, and word modules, respectively.\nWhile morphological analysis and dependency\nparsing use a sentence as the smallest unit of anal-\nysis, PAS analysis and discourse relation analysis\n11https://github.com/ku-nlp/KyotoCorpus\n12https://github.com/ku-nlp/KWDLC\n13https://github.com/ku-nlp/AnnotatedFKCCorpus\n540\nB-ORGO OB-DATEI-DATEO OB-MONI-MONI-MONO O\n'PVOEBUJPO\u0001.PEFM\u0001\t%F#&35B\n[CLS]Toyotaannoun-cedonSep##.31toinvest730billionyeninEVs[SEP]\nFigure 2: An example of solving named entity recognition as a sequence labeling task.\n'PVOEBUJPO\u0001.PEFM\u0001\t%F#&35B\n[CLS]I visitedKyoto##,a cityinJapan##, and saw‚Ä¶[SEP][ROOT]\nSoftmaxùëÉ(ùë§!|ùë§\")ùë†(ùë§!,ùë§\")\nùë§\"\n2.6 0.88.3 5.52.31.5FFNFFNFFN FFNFFNFFN FFNFFN FFN FFN‚Ä¶7.4 1.2 0.90.000.000.67 0.040.000.00 ‚Ä¶0.28 0.00 0.00\nFigure 3: An example of solving dependency parsing as a word selection task.\nrequire document-level processing. In this study,\nwe apply document-level processing for all tasks\nto perform multi-task learning. With this formula-\ntion, obtaining sentence boundaries becomes less\nimportant. Thus, we only use simple rules based\non regular expressions for sentence segmentation.\n5 Analysis Components\nKWJA consists of eleven analysis components be-\nlonging to three modules. In this section, we de-\nscribe the details of each component, including its\ndefinition, formulation, and evaluation.\n5.1 Typo Module\n5.1.1 Typo Correction\nTypo correction is the task of detecting and cor-\nrecting typos in a text. Tanaka et al. (2021) used a\npre-trained seq2seq model to convert input text to\ntypo-corrected text. While seq2seq models enable\nflexible typo correction, they are at risk of grossly\ndeviating from the input text.\nTo reduce the risk, we take a conservative ap-\nproach; we formulate the task as a sequence label-\ning task where two edit operations (Malmi et al.,\n2019) are assigned to each character. Specifically,\nfor each character in an input text, the model (1)\nchooses one from {KEEP, DELETE, REPLACE:x} and\n(2) predicts INSERT:x. REPLACE:x is an operation\nof replacing the character with x. INSERT:x in-\nserts x before the character (x can be null). Follow-\ning Tanaka et al. (2021), we use the F1 score of\ncharacter-level minimum edits for evaluation.\n5.2 Character Module\n5.2.1 Word Segmentation\nWord segmentation is the task of splitting a text\ninto words. We formulate the task as a character-\nlevel sequence labeling task. This task assigns a\nB (Begin) or I (Inside) label to each character in a\ntext. The evaluation metric is the F1 score for word\nspans.\n5.2.2 Word Normalization\nWord normalization is the task of normalizing non-\nstandard notations such as ‚ÄúThank youuuuu‚Äù in\nplace of ‚ÄúThank you.‚Äù As with typo correction,\nwe formulate the task as a sequence labeling task\nwhere a normalization operation is assigned to each\ncharacter. The list of normalization operations is\nshown in Appendix A. The evaluation metric is\nthe micro-averaged F1 score over labels other than\nKEEP, given that KEEP overwhelms the others.\n5.3 Word Module\n5.3.1 Morphological Analysis\nIn this study, we refer to morphological analysis\nas the task of assigning a POS, a sub-POS, a con-\njugation type, a conjugation form, a lemma, and a\nreading to each word. We formulate the first four\ntasks as word-level sequence labeling tasks. A post-\n541\nprocessing code is used to generate the lemma of\na word by looking up its normalized surface form,\nconjugation type, and conjugation form in the con-\njugation table. We also formulate the task of as-\nsigning readings as a sequence labeling task, where\nthe label set is the subword vocabulary defined in a\npre-trained model. This is somewhat complicated\nbecause we have to preprocess the training data to\nsplit a reading into two or more if the correspond-\ning word is split into multiple subwords. To do this,\nwe perform alignment of character sequences of\nwords and readings in accordance with subwords.\n5.3.2 Named Entity Recognition\nNamed entity recognition is the task of identifying\nnamed entities in a text. We formulate the task\nas a word-level sequence labeling task. Following\nAkbik et al. (2018), we add a CRF layer on top\nof a foundation model. Named entities have the\neight categories defined in the IREX CRL named\nentity data (Sekine and Isahara, 2000). The evalua-\ntion metric is the micro-averaged F1 score over the\nnamed entity categories.\n5.3.3 Linguistic Feature Tagging\nLinguistic feature tagging is the task of assigning\nvarious linguistic features to each word or base\nphrase.14 We formulate the task as a word-level\nsequence labeling task. Base phrase linguistic\nfeatures are assigned to the head word of each\nbase phrase. The evaluation metric is the macro-\naveraged F1 score over the features.\nAs the existing corpora do not have manually\nannotated linguistic features, we assign silver fea-\ntures using a rule-based Japanese linguistic feature\ntagger, KNP (Kurohashi and Nagao, 1994). In the\nfuture, we will manually correct some of the fea-\ntures and use them as gold data. All the features\nwe used are listed in Appendix B.\n5.3.4 Dependency Parsing\nIn this study, dependency parsing consists of two\nsub-tasks; one recognizes syntactic dependencies\nbetween words, and the other identifies their de-\npendency types. We formulate the former task as a\nword selection task, following Zhang et al. (2017),\nand the latter task as a word relation classification\ntask. As the evaluation metric, we use the Labeled\nAttachment Score (LAS) for base phrases.\n14A unit consisting of a single independent word and its\nancillary words. One or more base phrases make up a phrase.\n5.3.5 PAS Analysis, Bridging Reference\nResolution, and Coreference Resolution\nPAS analysis, bridging reference resolution, and\ncoreference resolution are the tasks of recognizing\nsemantic relations between base phrases. PAS anal-\nysis finds arguments corresponding towho did/does\nwhat to whom for a predicate. Bridging reference\nresolution finds nouns that complement the essen-\ntial information of another noun. Coreference res-\nolution finds a set of nouns that refer to the same\nreal-world entity.\nFollowing Ueda et al. (2020), we formulate all\nthe tasks as a word selection task. In PAS analysis,\nwe focus on four cases: nominative, accusative,\ndative, and nominative-2.15\n5.3.6 Discourse Relation Analysis\nDiscourse relation analysis is the task of recogniz-\ning discourse relations between clauses. Following\nKawahara et al. (2014), we assign a label to each\nclause pair in a text. Note that clauses are identified\nwith linguistic feature tagging.\nWe target the following discourse relations:\nCAUSE /REASON , PURPOSE , CONDITION , JUS-\nTIFICATION , CONTRAST , and CONCESSION . In\naddition, we introduce a special relation NORELA -\nTION , which indicates none of the above relations\nis applicable, and formulate the task as a seven-\nway word relation classification task. We use the\nmicro-averaged F1 score of the labels other than\nNORELATION as the evaluation metric.\n6 Experiments and Discussion\nIn this section, we investigate the performance of\neach analysis component through fine-tuning foun-\ndation models.\n6.1 Experimental Settings\nWe trained models on all the training data of KC,\nKWDLC, and Fuman, and evaluated the perfor-\nmance per corpus. The details of the experimental\nsettings are described in Appendix C.\n6.2 Results\nThe result of each task is shown in Table 2. Over-\nall, the performance of KWJA was comparable to\nSOTA and was sufficient for practical use. How-\never, the F1 score of word normalization was 33.3,\nwhich was remarkably lower than those of the other\n15Nominative-2 is used for a common Japanese construction\nin which a predicate has two nominative arguments.\n542\nTask Corpus Metric Reference SOTA KWJA\nTypo Correction JWTD F1 Tanaka et al. (2021) 77.6 83.1¬±0.3\nWord Segmentation KC F1 Tolmachev et al. (2020) 99.5 99.3¬±0.1\nWord Normalization all F1 ‚Äî ‚Äî 33.3¬±0.0\nMorphological\nAnalysis\nPOS KC F1 Tolmachev et al. (2020) 99.1 99.7¬±0.1\nsub-POS KC F1 Tolmachev et al. (2020) 97.8 99.0¬±0.1\nconjugation typeall F1 ‚Äî ‚Äî 99.3¬±0.3\nconjugation formall F1 ‚Äî ‚Äî 99.5¬±0.2\nreading all Accuracy ‚Äî ‚Äî 95.8¬±0.7\nNamed Entity Recognition all F1 ‚Äî ‚Äî 84.3¬±4.0\nLinguistic Feature\nTagging\nword all F1 ‚Äî ‚Äî 98.6¬±0.1\nbase phrase all F1 ‚Äî ‚Äî 88.3¬±3.1\nDependency Parsing KC LAS Kawahara and Kurohashi (2006)90.4 92.7¬±0.4\nPAS Analysis all F1 Ueda et al. (2020) 77.4 75.9¬±1.5\nBridging Reference Resolution all F1 Ueda et al. (2020) 64.3 65.8¬±1.6\nCoreference Resolution all F1 Ueda et al. (2020) 67.4 77.7¬±0.9\nDiscourse Relation Analysis KWDLC F1 Omura and Kurohashi (2022) 51.9 41.7¬±0.9\nTable 2: The performance of KWJA on each task in comparison to the state-of-the-art (SOTA). We fine-tuned KWJA\nwith 3 different random seeds and report the mean and standard deviation of the performance. ‚Äú‚Äî‚Äù indicates that no\nprevious studies reported the performance on the corpora we used. ‚Äúall‚Äù indicates KC, KWDLC, and Fuman corpus,\nand the metric is the macro-average of them.\ntasks. Moreover, PAS analysis and discourse rela-\ntion analysis scores were more than 1 point lower\nthan SOTA.\n6.3 Discussion\nWe discuss word normalization, PAS analysis, and\ndiscourse relation analysis in the following sec-\ntions. Section 6.3.3 compares the analysis speed of\nKWJA with existing Japanese analyzers.\n6.3.1 Word Normalization\nThe F1 score of word normalization, 33.3, was\nstrinkingly low. We attribute the poor performance\nto the highly unbalanced label distribution. Word\nnormalization mainly targets informal texts, and\nthere were very few examples with labels other\nthan KEEP in the annotated corpora. We generated\npseudo training data by applying denormalization\nrules to randomly selected words. Even with the\npseudo-data, the percentage of labels other than\nKEEP was less than 0.1%, however. We plan to\nexpand training data by specifically targeting low-\nfrequency phenomena.\nAnalyzer Time\nJuman++ & KNP 1.1min\nJuman++ & KNP (w/ PAS analysis) 18.4min\nKWJA (ours) 2.7min\nTable 3: Time spent by KWJA to analyze 1k sentences,\nwith comparison to Juman++ (Tolmachev et al., 2018)\nand KNP (Kurohashi and Nagao, 1994).\n6.3.2 PAS Analysis and Discourse Relation\nAnalysis\nWe hypothesized that the low performance of PAS\nanalysis and discourse relation analysis was due to\nmulti-task learning, in which the model‚Äôs capability\nwas allocated to the other tasks. To test this hypoth-\nesis, we trained the model separately for each task\nusing single-task learning. The F1 score of PAS\nanalysis was 79.3 ¬±1.0, and that of discourse re-\nlation analysis was 55.3 ¬±3.6. Both scores were\nsignificantly higher, confirming the hypothesis. We\nplan to adjust the loss weights and provide an op-\ntion to use models trained with single-task learning.\nAppendix D shows the results of single-task learn-\ning for all tasks in the word module.\n543\n6.3.3 Speed of Analysis\nWe compared KWJA with the existing Japanese\nanalyzers, Juman++ (Tolmachev et al., 2018) and\nKNP (Kurohashi and Nagao, 1994), in terms of\nspeed of analysis. For KWJA, we performed all\nthe tasks it supports. Juman++ supports word seg-\nmentation and morphological analysis while KNP\nsupports named entity recognition, linguistic fea-\nture tagging, dependency parsing, and optionally,\nPAS analysis. We used 1k sentences randomly\nsampled from the Japanese portion of the CC-100\ncorpus (Wenzek et al., 2020). We used an NVIDIA\nTITAN V 12GB GPU to run KWJA.\nTable 3 shows the results. We can see that KWJA\nwas considerably faster than Juman++ and KNP\neven though KWJA performed a larger number of\ntasks.\n7 Conclusion\nIn this study, we designed and built a unified\nJapanese text analyzer, KWJA, on top of founda-\ntion models. KWJA supports typo correction, word\nsegmentation, word normalization, morphological\nanalysis, named entity recognition, linguistic fea-\nture tagging, dependency parsing, PAS analysis,\nbridging reference resolution, coreference resolu-\ntion, and discourse relation analysis in a unified\nframework. Users can quickly obtain analysis re-\nsults by inputting a text and specifying the desired\nlevel of analysis.\nOne of the advantages of KWJA is its simplified\ndesign, thanks to the use of foundation models. Var-\nious analysis tasks, previously solved separately,\nare now performed only with three modules. For\nfurther simplification, we plan to solve all the anal-\nysis tasks with a character-level foundation model.\nLimitations\nAs KWJA is based on a large Transformer model,\nthe analysis in an environment without GPUs is\nexpected to be slow. Even in environments with\nGPUs, when we need only a specific task (e.g.,\nword segmentation), existing analyzers might be\nfaster with little difference in accuracy.\nThe experiments showed that multi-task learning\ndecreased accuracy in PAS analysis and discourse\nrelation analysis. This fact may be true for other\ntasks as well. Therefore, when very high analysis\naccuracy is required for a particular task, using a\nmodel trained only on that task is recommended\ninstead of KWJA.\nAcknowledgements\nThe pre-training of foundation models used in this\nwork was supported by the Joint Usage/Research\nCenter for Interdisciplinary Large-scale Informa-\ntion Infrastructures (JHPCN) through General Col-\nlaboration Project no. jh221004 and jh231006,\n‚ÄúDeveloping a Platform for Constructing and Shar-\ning of Large-Scale Japanese Language Models.‚Äù\nAs for the computing environment, we used the\nmdx: a platform for the data-driven future.\nReferences\nAlan Akbik, Duncan Blythe, and Roland V ollgraf. 2018.\nContextual String Embeddings for Sequence Label-\ning. In Proceedings of the 27th International Con-\nference on Computational Linguistics, pages 1638‚Äì\n1649, Santa Fe, New Mexico, USA. Association for\nComputational Linguistics.\nRishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ\nAltman, Simran Arora, Sydney von Arx, Michael S.\nBernstein, Jeannette Bohg, Antoine Bosselut, Emma\nBrunskill, Erik Brynjolfsson, Shyamal Buch, Dallas\nCard, Rodrigo Castellon, Niladri Chatterji, Annie\nChen, Kathleen Creel, Jared Quincy Davis, Dora\nDemszky, Chris Donahue, Moussa Doumbouya,\nEsin Durmus, Stefano Ermon, John Etchemendy,\nKawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor\nGale, Lauren Gillespie, Karan Goel, Noah Goodman,\nShelby Grossman, Neel Guha, Tatsunori Hashimoto,\nPeter Henderson, John Hewitt, Daniel E. Ho, Jenny\nHong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil\nJain, Dan Jurafsky, Pratyusha Kalluri, Siddharth\nKaramcheti, Geoff Keeling, Fereshte Khani, Omar\nKhattab, Pang Wei Koh, Mark Krass, Ranjay Kr-\nishna, Rohith Kuditipudi, Ananya Kumar, Faisal Lad-\nhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle\nLevent, Xiang Lisa Li, Xuechen Li, Tengyu Ma,\nAli Malik, Christopher D. Manning, Suvir Mirchan-\ndani, Eric Mitchell, Zanele Munyikwa, Suraj Nair,\nAvanika Narayan, Deepak Narayanan, Ben Newman,\nAllen Nie, Juan Carlos Niebles, Hamed Nilforoshan,\nJulian Nyarko, Giray Ogut, Laurel Orr, Isabel Pa-\npadimitriou, Joon Sung Park, Chris Piech, Eva Porte-\nlance, Christopher Potts, Aditi Raghunathan, Rob\nReich, Hongyu Ren, Frieda Rong, Yusuf Roohani,\nCamilo Ruiz, Jack Ryan, Christopher R√©, Dorsa\nSadigh, Shiori Sagawa, Keshav Santhanam, Andy\nShih, Krishnan Srinivasan, Alex Tamkin, Rohan\nTaori, Armin W. Thomas, Florian Tram√®r, Rose E.\nWang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai\nWu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan\nYou, Matei Zaharia, Michael Zhang, Tianyi Zhang,\nXikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn\nZhou, and Percy Liang. 2021. On the Opportunities\nand Risks of Foundation Models.\nMasatsugu Hangyo, Daisuke Kawahara, and Sadao\nKurohashi. 2012. Building a Diverse Document\n544\nLeads Corpus Annotated with Semantic Relations.\nIn Proceedings of the 26th Pacific Asia Conference\non Language, Information, and Computation, pages\n535‚Äì544, Bali, Indonesia. Faculty of Computer Sci-\nence, Universitas Indonesia.\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and\nWeizhu Chen. 2021. DeBERTa: Decoding-Enhanced\nBERT with Disentangled Attention. In International\nConference on Learning Representations.\nHiroshi Kanayama, Na-Rae Han, Masayuki Asahara,\nJena D. Hwang, Yusuke Miyao, Jinho D. Choi, and\nYuji Matsumoto. 2018. Coordinate Structures in Uni-\nversal Dependencies for Head-final Languages. In\nProceedings of the Second Workshop on Universal\nDependencies (UDW 2018), pages 75‚Äì84, Brussels,\nBelgium. Association for Computational Linguistics.\nYoshinobu Kano. 2013. Kachako: A Hybrid-Cloud\nUnstructured Information Platform for Full Automa-\ntion of Service Composition, Scalable Deployment\nand Evaluation - Natural Language Processing as an\nExample. In Service-Oriented Computing - ICSOC\n2012 Workshops - ICSOC 2012, International Work-\nshops ASC, DISA, PAASC, SCEB, SeMaPS, WESOA,\nand Satellite Events, Shanghai, China, November\n12-15, 2012, Revised Selected Papers, volume 7759\nof Lecture Notes in Computer Science, pages 72‚Äì84.\nSpringer.\nDaisuke Kawahara and Sadao Kurohashi. 2006. A\nFully-Lexicalized Probabilistic Model for Japanese\nSyntactic and Case Structure Analysis. In Proceed-\nings of the Human Language Technology Conference\nof the NAACL, Main Conference , pages 176‚Äì183,\nNew York City, USA. Association for Computational\nLinguistics.\nDaisuke Kawahara, Yuichiro Machida, Tomohide Shi-\nbata, Sadao Kurohashi, Hayato Kobayashi, and Man-\nabu Sassano. 2014. Rapid Development of a Corpus\nwith Discourse Annotations using Two-stage Crowd-\nsourcing. In Proceedings of COLING 2014, the\n25th International Conference on Computational Lin-\nguistics: Technical Papers, pages 269‚Äì278, Dublin,\nIreland. Dublin City University and Association for\nComputational Linguistics.\nYudai Kishimoto, Yugo Murawaki, and Sadao Kuro-\nhashi. 2020. Adapting BERT to Implicit Discourse\nRelation Classification with a Focus on Discourse\nConnectives. In Proceedings of the 12th Language\nResources and Evaluation Conference, pages 1152‚Äì\n1158, Marseille, France. European Language Re-\nsources Association.\nHirokazu Kiyomaru and Sadao Kurohashi. 2021. Con-\ntextualized and Generalized Sentence Representa-\ntions by Contrastive Self-Supervised Learning: A\nCase Study on Discourse Relation Analysis. In Pro-\nceedings of the 2021 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies, pages\n5578‚Äì5584, Online. Association for Computational\nLinguistics.\nTaku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.\n2004. Applying conditional random fields to\nJapanese morphological analysis. In Proceedings of\nthe 2004 Conference on Empirical Methods in Natu-\nral Language Processing, pages 230‚Äì237, Barcelona,\nSpain. Association for Computational Linguistics.\nSadao Kurohashi and Makoto Nagao. 1994. KN\nParser: Japanese Dependency/Case Structure Ana-\nlyzer. In Proceedings of the International Workshop\non Sharable Natural Language Resources, pages 48‚Äì\n55.\nSadao Kurohashi and Makoto Nagao. 1998. Building a\nJapanese Parsed Corpus while Improving the Parsing\nSystem. In Proceedings of the NLPRS, pages 719‚Äì\n724.\nSadao Kurohashi, Toshihisa Nakamura, Yuji Mat-\nsumoto, and Makoto Nagao. 1994. Improvements of\nJapanese Morphological Analyzer JUMAN. In Pro-\nceedings of the International Workshop on Sharable\nNatural Language Resources, pages 22‚Äì38.\nThang Luong, Hieu Pham, and Christopher D. Man-\nning. 2015. Effective Approaches to Attention-based\nNeural Machine Translation. ArXiv, abs/1508.04025.\nEric Malmi, Sebastian Krause, Sascha Rothe, Daniil\nMirylenka, and Aliaksei Severyn. 2019. Encode, Tag,\nRealize: High-Precision Text Editing. In Proceed-\nings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 5054‚Äì5065, Hong\nKong, China. Association for Computational Linguis-\ntics.\nJoakim Nivre, Marie-Catherine de Marneffe, Filip Gin-\nter, Jan Haji Àác, Christopher D. Manning, Sampo\nPyysalo, Sebastian Schuster, Francis Tyers, and\nDaniel Zeman. 2020. Universal Dependencies v2:\nAn Evergrowing Multilingual Treebank Collection.\nIn Proceedings of the 12th Language Resources and\nEvaluation Conference, pages 4034‚Äì4043, Marseille,\nFrance. European Language Resources Association.\nHiroshi Noji and Yusuke Miyao. 2016. Jigg: A\nFramework for an Easy Natural Language Process-\ning Pipeline. In Proceedings of ACL-2016 System\nDemonstrations, pages 103‚Äì108, Berlin, Germany.\nAssociation for Computational Linguistics.\nKazumasa Omura and Sadao Kurohashi. 2022. Im-\nproving Commonsense Contingent Reasoning by\nPseudo-data and Its Application to the Related Tasks.\nIn Proceedings of the 29th International Confer-\nence on Computational Linguistics, pages 812‚Äì823,\nGyeongju, Republic of Korea. International Commit-\ntee on Computational Linguistics.\nPeng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, and\nChristopher D. Manning. 2020. Stanza: A Python\nNatural Language Processing Toolkit for Many Hu-\nman Languages. In Proceedings of the 58th Annual\n545\nMeeting of the Association for Computational Lin-\nguistics: System Demonstrations , pages 101‚Äì108,\nOnline. Association for Computational Linguistics.\nStephen Roller, Emily Dinan, Naman Goyal, Da Ju,\nMary Williamson, Yinhan Liu, Jing Xu, Myle Ott,\nKurt Shuster, Eric Michael Smith, Y .-Lan Boureau,\nand Jason Weston. 2020. Recipes for Building an\nOpen-Domain Chatbot. In Conference of the Euro-\npean Chapter of the Association for Computational\nLinguistics.\nSatoshi Sekine and Hitoshi Isahara. 2000. IREX: IR\n& IE Evaluation Project in Japanese. In Proceed-\nings of the Second International Conference on Lan-\nguage Resources and Evaluation (LREC‚Äô00), Athens,\nGreece. European Language Resources Association\n(ELRA).\nIulian Serban, Alessandro Sordoni, Yoshua Bengio,\nAaron C. Courville, and Joelle Pineau. 2015. Build-\ning End-To-End Dialogue Systems Using Generative\nHierarchical Neural Network Models. In AAAI Con-\nference on Artificial Intelligence.\nMilan Straka, Jan HajiÀác, and Jana Strakov√°. 2016. UD-\nPipe: Trainable Pipeline for Processing CoNLL-U\nFiles Performing Tokenization, Morphological Anal-\nysis, POS Tagging and Parsing. In Proceedings\nof the Tenth International Conference on Language\nResources and Evaluation (LREC‚Äô16), pages 4290‚Äì\n4297, Portoro≈æ, Slovenia. European Language Re-\nsources Association (ELRA).\nIlya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Se-\nquence to Sequence Learning with Neural Networks.\nAdvances in neural information processing systems,\n27.\nYu Tanaka, Yugo Murawaki, Daisuke Kawahara, and\nSadao Kurohashi. 2021. Building a Japanese Typo\nDataset and Typo Correction System Based on\nWikipedia‚Äôs Revision History. Journal of Natu-\nral Language Processing , 28(4):995‚Äì1033. (in\nJapanese).\nArseny Tolmachev, Daisuke Kawahara, and Sadao Kuro-\nhashi. 2018. Juman++: A Morphological Analy-\nsis Toolkit for Scriptio Continua. In Proceedings\nof the 2018 Conference on Empirical Methods in\nNatural Language Processing: System Demonstra-\ntions, pages 54‚Äì59, Brussels, Belgium. Association\nfor Computational Linguistics.\nArseny Tolmachev, Daisuke Kawahara, and Sadao Kuro-\nhashi. 2020. Design and Structure of The Juman++\nMorphological Analyzer Toolkit. Journal of Natural\nLanguage Processing, 27(1):89‚Äì132.\nNobuhiro Ueda, Daisuke Kawahara, and Sadao Kuro-\nhashi. 2020. BERT-based Cohesion Analysis of\nJapanese Texts. In Proceedings of the 28th Inter-\nnational Conference on Computational Linguistics,\npages 1323‚Äì1333, Barcelona, Spain (Online). Inter-\nnational Committee on Computational Linguistics.\nMasato Umakoshi, Yugo Murawaki, and Sadao Kuro-\nhashi. 2021. Japanese Zero Anaphora Resolution\nCan Benefit from Parallel Texts Through Neural\nTransfer Learning. In Findings of the Association\nfor Computational Linguistics: EMNLP 2021, pages\n1920‚Äì1934, Punta Cana, Dominican Republic. Asso-\nciation for Computational Linguistics.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz\nKaiser, and Illia Polosukhin. 2017. Attention is All\nyou Need. In Advances in Neural Information Pro-\ncessing Systems, volume 30. Curran Associates, Inc.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Aman-\npreet Singh, Julian Michael, Felix Hill, Omer Levy,\nand Samuel Bowman. 2019. SuperGLUE: A Stickier\nBenchmark for General-Purpose Language Under-\nstanding Systems. In Advances in Neural Informa-\ntion Processing Systems, volume 32. Curran Asso-\nciates, Inc.\nGuillaume Wenzek, Marie-Anne Lachaux, Alexis Con-\nneau, Vishrav Chaudhary, Francisco Guzm√°n, Ar-\nmand Joulin, and Edouard Grave. 2020. CCNet: Ex-\ntracting High Quality Monolingual Datasets from\nWeb Crawl Data. In Proceedings of the Twelfth Lan-\nguage Resources and Evaluation Conference, pages\n4003‚Äì4012, Marseille, France. European Language\nResources Association.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,\nJoe Davison, Sam Shleifer, Patrick von Platen, Clara\nMa, Yacine Jernite, Julien Plu, Canwen Xu, Teven\nLe Scao, Sylvain Gugger, Mariama Drame, Quentin\nLhoest, and Alexander Rush. 2020. Transformers:\nState-of-the-Art Natural Language Processing. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38‚Äì45, Online. Association\nfor Computational Linguistics.\nXingxing Zhang, Jianpeng Cheng, and Mirella Lapata.\n2017. Dependency Parsing as Head Selection. In\nProceedings of the 15th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Volume 1, Long Papers , pages 665‚Äì676,\nValencia, Spain. Association for Computational Lin-\nguistics.\nJunru Zhou and Hai Zhao. 2019. Head-Driven Phrase\nStructure Grammar Parsing on Penn Treebank. In\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 2396‚Äì\n2408, Florence, Italy. Association for Computational\nLinguistics.\nA Word Normalization Operations\nWe define six types of normalization operations as\nfollows:\nKEEP Keep the original character.\n546\nDELETE Delete the character.\nVOICED Replace voiced or semi-voiced charac-\nter with voiceless character (e.g., ‚Äú „Åå ‚Äù (ga)\n‚Üí‚Äú „Åã‚Äù (ka), ‚Äú „Å±‚Äù (pa) ‚Üí‚Äú „ÅØ‚Äù (ha)). This\nreverts rendaku, the voicing of the initial con-\nsonant of a non-initial word of a compound.\nSMALL Replace a small character with the large\ncharacter (e.g., ‚Äú „Å™„ÅÅ‚Äù ‚Üí‚Äú „Å™„ÅÇ‚Äù).\nPROLONG Replace prolonged sound mark with\nits equivalent hiragana or katakana (e.g., ‚Äú\n„ÇÇ„Éº„Çå„Å§ ‚Äù ( moRretsu) ‚Üí ‚Äú „ÇÇ„ÅÜ„Çå„Å§ ‚Äù\n(mouretsu)).\nPROLONG-E Replace a prolonged sound mark\nwith ‚Äú „Åà‚Äù (e) (e.g., ‚Äú „Å≠„Éº‚Äù (neR) ‚Üí‚Äú „Å≠„Åà\n‚Äù (nee)).\nB Word and Base Phrase Features\nKWJA assigns the following linguistic fea-\ntures.16,17 ‚Ä† indicates that the feature is to be cor-\nrected manually in the future.\nWord Features\n‚Ä¢ base phrase head ‚Ä†\n‚Ä¢ base phrase end ‚Ä†, phrase end‚Ä†\n‚Ä¢ declinable head or end\nBase Phrase Features\n‚Ä¢ verbal (verb, adjective, copula)‚Ä†, nominal‚Ä†\n‚Ä¢ stative predicate, active predicate\n‚Ä¢ nominal predicate (verb, adjective) ‚Ä†\n‚Ä¢ modality‚Ä†, tense‚Ä†, negation‚Ä†, potential expres-\nsion, honorific, time\n‚Ä¢ modification\n‚Ä¢ SM-subject\n‚Ä¢ verbal level\n‚Ä¢ dependency:genitive\n‚Ä¢ clause head ‚Ä†, clause end‚Ä†,\nclause end:adnominal,\nclause end:complement, clause functional\n16https://github.com/ku-nlp/knp/blob/master/\ndoc/knp_feature.pdf\n17https://github.com/ku-nlp/KWDLC/blob/master/\ndoc/clause_feature_manual.pdf\nC Training Details\nWe trained each module with hyper-parameters\nshown in Table 4. During training, we evaluated\na score averaged over tasks on the validation set\nat the end of each epoch and picked the model\nwith the highest score. When training the word\nmodule, the ground-truth word segmentation was\nused as input. We trained each module three times\nwith different random seeds. Single training runs\nof the typo, character, and word modules took 38\nhours, 2.5 hours, and 5.8 hours on four Tesla V100-\nSXM2-32GB GPUs, four TITAN X 12GB GPUs,\nand two Tesla V100-SXM2-32GB GPUs, respec-\ntively. The transformers package (Wolf et al.,\n2020) was used for implementation.\nD Single-task Learning Results\nTable 5 shows the results of single-task learning.\nWe trained each task in the word module separately\nin a single-task manner. Note that the training of\nPOS, sub-POS, conjugation type, and conjugation\nform tasks was performed in a multi-task manner\nas before because these tasks had already achieved\nenough performance.\n547\nHyper-parameter Typo Module Character Module Word Module\nMaximum Sequence Length 256 512 256\nDropout 0.1 0.1 0.1\nBatch Size 352 32 16\nMaximum Training Epochs 20 20 20\nEarly Stopping Patience 3 3 3\nWarmup Steps 1k 2k 100\nMaximum Learning Rate 2e-5 2e-5 1e-4\nLearning Rate Decay Cosine Cosine Cosine\nOptimizer AdamW AdamW AdamW\nAdamW œµ 1e-6 1e-6 1e-6\nAdamW Œ≤1 0.9 0.9 0.9\nAdamW Œ≤2 0.99 0.99 0.99\nWeight Decay 0.01 0.01 0.01\nGradient Clipping 0.5 0.5 0.5\nTable 4: Hyper-parameters for training each module.\nTask Corpus Metric KWJA (multi) KWJA (single)\nMorphological\nAnalysis\nPOS all F1 99.4¬±0.1 99.4¬±0.1\nsub-POS all F1 98.7¬±0.1 98.7¬±0.0\nconjugation type all F1 99.3¬±0.3 99.5¬±0.0\nconjugation form all F1 99.5¬±0.2 99.6¬±0.0\nreading all Accuracy 95.8¬±0.7 96.2¬±0.0\nNamed Entity Recognition all F1 84.3¬±4.0 77.9¬±4.2\nLinguistic Feature\nTagging\nword all F1 98.6¬±0.1 98.5¬±0.1\nbase phrase all F1 88.3¬±3.1 92.4¬±0.1\nDependency Parsing all LAS 93.6¬±0.3 93.5¬±0.3\nPAS Analysis all F1 75.9¬±1.5 79.3¬±1.0\nBridging Reference Resolution all F1 65.8¬±1.6 65.2¬±1.6\nCoreference Resolution all F1 77.7¬±0.9 77.6¬±1.2\nDiscourse Relation Analysis KWDLC F1 41.7¬±0.9 55.3¬±3.6\nTable 5: The performance of KWJA on each task in single-task learning (single) compared to that in multi-task\nlearning (multi). We fine-tuned KWJA with three different random seeds. We report the mean and standard\ndeviation of the performance. ‚Äúall‚Äù indicates KC, KWDLC, and Fuman corpus, and the metric is the macro-average\nof them.\n548",
  "topic": "Foundation (evidence)",
  "concepts": [
    {
      "name": "Foundation (evidence)",
      "score": 0.5950819849967957
    },
    {
      "name": "Computer science",
      "score": 0.5844208002090454
    },
    {
      "name": "Spectrum analyzer",
      "score": 0.5531531572341919
    },
    {
      "name": "Volume (thermodynamics)",
      "score": 0.4730585813522339
    },
    {
      "name": "Software engineering",
      "score": 0.3338458836078644
    },
    {
      "name": "History",
      "score": 0.13293400406837463
    },
    {
      "name": "Telecommunications",
      "score": 0.11998271942138672
    },
    {
      "name": "Archaeology",
      "score": 0.07496482133865356
    },
    {
      "name": "Physics",
      "score": 0.06212577223777771
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ]
}