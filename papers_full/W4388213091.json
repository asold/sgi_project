{
  "title": "DECENTRALISED AUTONOMOUS SOCIETY THROUGH LARGE LANGUAGE MODELS’ BASED AGENTS: A PATHWAY TO EMPOWER SMALL COMMUNITIES",
  "url": "https://openalex.org/W4388213091",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2991519130",
      "name": "Vasili Braga",
      "affiliations": [
        "Technical University of Moldova"
      ]
    },
    {
      "id": "https://openalex.org/A2991519130",
      "name": "Vasili Braga",
      "affiliations": [
        "Technical University of Moldova"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6733206913",
    "https://openalex.org/W6850764995",
    "https://openalex.org/W4324349396",
    "https://openalex.org/W4321499561",
    "https://openalex.org/W4381982883",
    "https://openalex.org/W6735370125",
    "https://openalex.org/W2219874140",
    "https://openalex.org/W2794730358",
    "https://openalex.org/W4365512576",
    "https://openalex.org/W4282934617",
    "https://openalex.org/W1565853284",
    "https://openalex.org/W4323830259",
    "https://openalex.org/W1492293509",
    "https://openalex.org/W4388213091",
    "https://openalex.org/W4386099272",
    "https://openalex.org/W4211260587",
    "https://openalex.org/W4385217746",
    "https://openalex.org/W4378509422",
    "https://openalex.org/W4362472309",
    "https://openalex.org/W4319331550",
    "https://openalex.org/W2595976459",
    "https://openalex.org/W4385894687",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4392297945",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4323717348",
    "https://openalex.org/W4385571831",
    "https://openalex.org/W4377371819",
    "https://openalex.org/W4378768661",
    "https://openalex.org/W4323652488",
    "https://openalex.org/W4318975084",
    "https://openalex.org/W4385567149",
    "https://openalex.org/W2123285937",
    "https://openalex.org/W3198935437",
    "https://openalex.org/W4287553002",
    "https://openalex.org/W4361866031",
    "https://openalex.org/W4362516849",
    "https://openalex.org/W3125298275",
    "https://openalex.org/W4330336443",
    "https://openalex.org/W2488535929",
    "https://openalex.org/W2310369193",
    "https://openalex.org/W4378464611",
    "https://openalex.org/W4320165837",
    "https://openalex.org/W4376312626",
    "https://openalex.org/W4378473736",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W2902634493",
    "https://openalex.org/W2392113277",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2048358533",
    "https://openalex.org/W2979826702"
  ],
  "abstract": "This paper explores the concept of Decentralized Autonomous Society through the lens of Large Language Models focusing on the transformative potential of integrating these technologies. The paper on the role of Large Language Models based agents in providing a versatile, responsive, and contextually intelligent resource within a Decentralized Autonomous Society, fostering intellectual exploration, assisting in complex tasks, and aiding real-time problem solving. One delves into their integration with Decentralized Autonomous Society infrastructures, including robotic and automated systems. While promising, the integration of Large Language Models and their agents into a Decentralized Autonomous Society poses several challenges, including infrastructure and connectivity limitations, information accuracy, artificial intelligence bias, privacy and data security, and ethical concerns. This paper critically discusses these issues and proposes potential solutions. Through the lens of the Decentralized Autonomous Society construct, the paper considers the future possibilities and implications of artificial intelligence, where self-sustaining, digitally-empowered communities leverage artificial intelligence as a cornerstone of their collective intelligence.",
  "full_text": "Journal of Engineering Science Vol. XXX, no. 3 (2023), pp. 99 - 120 \nFascicle  Electronics and Computer Science ISSN 2587-3474 \nTopic Computers and Information Technology eISSN 2587-3482 \nJournal of Engineering Science October, 2023, Vol. XXX (3)\nhttps://doi.org/10.52326/jes.utm.2023.30(3).07 \nUDC 316.7:[519.766:004.8] \nDECENTRALISED AUTONOMOUS SOCIETY THROUGH LARGE LANGUAGE \nMODELS’ BASED AGENTS: A PATHWAY TO EMPOWER SMALL COMMUNITIES \nVasili Braga*, ORCID:  0009-0009-2478-830X\nTechnical University of Moldova, 168 Stefan cel Mare Blvd., Chisinau, Republic of Moldova \n*Corresponding author: Vasili Braga, vasili.braga@ati.utm.md\nReceived: 07. 21. 2023 \nAccepted: 09. 10. 2023 \nAbstract. This paper explores the concept of Decentralized Autonomous Society through the \nlens of Large Language Models focusing on the transformative potential of integrating these \ntechnologies. The paper on the role of Large Language Models based agents in provid ing a \nversatile, responsive, and contextually intelligent resource within a Decentralized \nAutonomous Society, fostering intellectual exploration, assisting in complex tasks, and aiding \nreal-time problem solving. One delves into their integration with Decentralized Autonomous \nSociety infrastructures, including robotic and automated systems. While promising, the \nintegration of Large Language Models and their agents into a Decentralized Autonomous \nSociety poses several challenges, including infrastructure and connectivity limitations, \ninformation accuracy, artificial intelligence bias, privacy and data security, and ethical \nconcerns. This paper critically discusses these issues and proposes potential solutions. \nThrough the lens of the Decentralized Autonomous S ociety construct, the paper considers \nthe future possibilities and implications of artificial intelligence, where self -sustaining, \ndigitally-empowered communities leverage artificial intelligence as a cornerstone of their \ncollective intelligence. \nKeywords: Decentralized Autonomous Societies, Large Language Models, AI Agents, GPT- 4, \nVicuna, Artificial Intelligence, Machine Learning, Decentralization. \nRezumat. Acest articol explorează conceptul de Societate Autonomă Descentralizată prin \nprisma Modelelor Lingvistice Mari, concentrându -se pe potențialul de transformare al \nintegrării acestor tehnologii. Lucrarea se axează pe rolul agenților bazați pe Modele \nLingvistice Mari în a oferi o resursă versatilă, receptivă și inteligentă în context în cadrul unei \nSocietăți Autonome Descentralizate, stimulând explorarea intelectuală, asistând în sarcini \ncomplexe și ajutând la rezolvarea problemelor în timp real. Se intră în detalii privind \nintegrarea lor cu infrastructurile Societății Autonome Descentralizat e, inclusiv sistemele \nrobotizate și automate. Cu toate că este promițătoare, integrarea Modelelor Lingvistice Mari \nși a agenților lor într -o Societate Autonomă Descentralizată prezintă mai multe provocări, \ninclusiv limitările infrastructurii și conectivită ții, acuratețea informațiilor, prejudecata \ninteligenței artificiale, confidențialitatea și securitatea datelor și preocupările etice. Acest \ndocument discută în mod critic aceste probleme și propune soluții potențiale. Prin prisma \n\n100 V. Braga\nJournal of Engineering Science October, 2023, Vol. XXX (3)\nconstrucției Societății Autonome Descentralizate, lucrarea consideră posibilitățile și \nimplicațiile viitoare ale inteligenței artificiale, unde comunitățile auto -sustenabile, digital-\nîmputernicite, folosesc inteligența artificială ca o piatră de temelie a inteligenței lor \ncolective. \nCuvinte cheie: Societăți Autonome Descentralizate, Modele Lingvistice Mari, Agenți AI, GPT-4, \nVicuna, Inteligență Artificială, Învățare Automată, Descentralizare. \n1. Introduction\nCommunities in isolated locations, from the rustic landscapes to remote islands or\neven potential underwater or extraterrestrial habitats, face unique challenges [1]. While their \nenvironments offer immense natural beauty and tranquility, they are often sep arated from \nthe conveniences and expertise of the modern world. The isolation and low population \ndensity in such places can make it challenging to maintain a full range of specialist skills [2]. \nFields such as medicine, education, agriculture, maintenance, and cultural preservation \nrequire dedicated specialists whose expertise might not be readily available in these areas. \nThis lack of local expertise can pose significant barriers to sustaining these communities and \nenhancing their quality of life [3]. \nAn innovative approach to addressing this dilemma lies in the realm of artificial \nintelligence (AI), specifically, Large Language Models [4] (LLMs) like GPT-4 [5], LLAMA [6] or \nVicuna [7] etc. These LLM models have evolved into expans ive, decentralized knowledge \nbases, capable of providing insights, advice, and recommendations across a plethora of fields. \nThey can facilitate virtual consultations in healthcare, offer customized education support, \nprovide expert guidance in sustainable agriculture or maintenance tasks, and even assist in \npreserving local cultural heritage. In order to understand how useful can be the agents based \non LLM’s one can see what the impact of LLMs on the labor market is already quite significant. \nAccording to some studies, as cited in the research, around 80% of the U.S. workforce could \nsee at least 10% of their work tasks influenced by the introduction of LLMs, and close to 19% \nof workers might witness at least 50% of their tasks being directly impacted [8]. \nThe paper discusses integrating modern conveniences into isolated communities. It \naims to blend the benefits of a peaceful, slow-paced life with modern technology. Using LLMs \ncan address ch allenges of isolation and expertise shortages, preserve local culture, and \nenhance community living.This paper aims to delve deeper into the role of LLMs as \ndecentralized knowledge bases in supporting and sustaining such visionary projects.  \nThe paper will  explore how these AI-powered systems can help small, isolated \ncommunities bridge the gap between anarcho primitivism and modernity, merging old-world \ncharm with contemporary comfort. The paper will shed light on the potential challenges and \nopportunities that LLMs present, thereby illuminating their potential in driving a new era of \nsustainable development and cultural preservation in isolated communities. \n2. State of the Art in Large Language Models and Autonomous agents based on LLMs\nOver the years, significant advancements have been made in the field of LLMs and\ntheir applications. But 2023 brings an explosion of new models and software based on them \n[4]. The followi ng outlines some of the state -of-the-art developments in this area of \nautonomous agents based on LLM [9]: \n1. LangChain [10] : LangChain is an open -source framework tailored for crafting\napplications underpinned by LLMs. To construct an AI assistant using LangChain, one would \n Decentralised autonomous society through large language models’ based agents: a pathway... 101 \nJournal of Engineering Science  October, 2023, Vol. XXX (3) \nstart by defining the assistant’s tasks and associated data sources. Subsequently, with \nLangChain i nitialized, developers can adeptly manage prompts through the \n`PromptManager`, integrate external data via the `DataManager`, and engage with other \nservices using dedicated API modules. The framework also facilitates the programming of \nautonomous behaviors, implementation of feedback mechanisms, and addresses ethical and \nprivacy concerns. Once developed, the assistant can be deployed, monitored, and iteratively \nimproved upon. Overall, LangChain streamlines the process of creating data-aware, \ncontextually relevant, and proactive AI assistants. \n2. HuggingGPT [11]: is a system that uses ChatGPT to work with various AI models \nfrom the Hugging Face repository. It processes tasks, chooses the right models, and provides \nresults. For DAS, it can integrate different models, such as image generation for creating \nvisuals, speech-to-text for converting spoken language into written text, sentiment analysis \nto determine community feelings, and translatio n models to help in multilingual \nenvironments. Essentially, HuggingGPT is a versatile tool designed to aid decentralized \ncommunities by utilizing different AI functionalities. \n3. Toolformer [12]: This is a system where LMs teach themselves to use external tools \nvia simple APIs. Toolformer is trained to decide which APIs to call, when to call them, what \narguments to pass, and how to best incorporate the results into future token prediction.  For \ndistributed autonomous societies (DAS), Toolformer presents immense value by facilitating \nseamless integration and utilization of external tools through APIs. As DAS operations often \nrequire diverse functionalities, the ability to quickly and autonomously decide which external \ntools to call, and when, allows for a more adaptive and efficient environment. Furthermore, \nin decentralized structures where timely and accurate data processing is essential, \nToolformer can enhance decision-making by improving token prediction based on the results \nfrom these external tools. Its self -learning capability ensures that as the DAS ecosystem \nevolves, Toolformer can adapt and continue to provide optimal support without manual \nreconfiguration. \n4. Visual ChatGPT [13] : This is a system that incorporates Visual Foundation Models \nwith ChatGPT, allowing users to send and receive not only languages but also images during \nchatting. This system is designed to address complex visual questions or visual editing \ninstructions that require the collaboration of multiple AI models in multiple steps. Visual \nChatGPT's adaptability can be pivotal in facilitating clear and efficient visual exchanges in \nsuch decentralized settings. \n5. Lindy AI [14]: This application serves as a personal AI assistant. It utilizes LLMs to \nhelp users manage their tasks and make informed decisions. \n6. CensusGPT [15]: This application uses LLMs to answer questions related to census \ndata. It makes statistical data more accessible by providing answers in natural language. In \nthe context of distributed autonomous societies (DAS), CensusGPT could stand as a crucial \ntool to streamline data accessibility. By leveraging LLMs to interpret census-related queries, \nit transforms often dense and convoluted statistical data into digestible, natural language \nresponses. For D AS that rely on data-driven decisions, the quick and clear information \nretrieval facilitated by such a tool can significantly expedite research processes and ensure \nmore informed communal choices based on demographic insights. \n7. Hearth AI [16]: Hearth AI applies the concept of Agentic Relationship Management. \nIt uses AI to maintain and manage relationships with customers, providing personalized \ninteractions. In a DAS setup, Hearth AI's concept of using AI for relationship management can \n102 V. Braga \nJournal of Engineering Science  October, 2023, Vol. XXX (3) \nefficiently automate and personalize communication, enhancing community interactions and \nadministrative tasks. \n8. RCI Agent for MiniWoB++ [17]: This application shows that LLMs can solve computer \ntasks. It offers a new way to approach and solve complex problems in computing. \n9. Babyagi [18]: Babyagi is an AI-powered task management system. It uses AI to assist \nusers in managing and completing their tasks efficiently. In DAS, Babyagi's AI- driven task \nmanagement can enhance productivity. By automating task organization and prioritization, it \nensures tasks align with community objectives and helps members efficiently achieve their goals. \n10. ChatGPT plugins [19]: This platform provides a way to connect ChatGPT to third-\nparty applications. It extends the capabilities of ChatGPT beyond its original scope. \n11. Fixie.ai [20]: Fixie.ai allows for the creation of natural language ag ents that can \nconnect to user data, communicate with APIs, and solve complex problems. It provides a \nplatform for creating highly personalized AI solutions. For DAS, Fixie.ai is a platform for \nconstructing AI agents that interface directly with user data a nd APIs. Example: A DAS \ncommunity could deploy a Fixie.ai agent to automatically access weather data and notify \nresidents of upcoming weather changes, ensuring community preparedness. \nThese developments highlight the potential of LLMs in driving innovation and solving \ncomplex tasks in various domains, emphasizing the crucial role they play in the progress \ntowards more sophisticated and autonomous AI systems. \nThis papers goals in the context of the state of the art, can be framed as follows: \nEmpowering Small Communities: in contrast to the majority of existing systems which \nare primarily designed for general use or specialized industrial applications, our project \nspecifically targets small and isolated communities' needs. It aims to empower these \ncommunities by democratizing access to knowledge, fostering innovation,  automating parts \nof their tasks, helping to preserve local culture and day to day history, and providing \nadministrative support as autonomous assistants [21]. \nKnowledge Democratization: The paper uses large language models as a decentralized \nknowledge base, bridging the knowledge gap that often exists in small communities. This \nfeature is not commonly found in the current state-of-the-art applications, making our project \nunique and of immense value to the targeted demographic. Even if there exists the need to \nuse LLMs as explainers, copilots or assistants  in such complex matters like financial \nknowledge [22], programming [23] or medicine [24, 25]. \nEnabling Self-Learning: The projects emphasis on supporting self-directed learning is \na distinctive attribute. It harnesses the capabilities of LLMs to aid information discovery and \nfacilitate learning, essential for fostering development in these communities. The capacity of \nLLM’s to support self -learning for students is widely known already [26–28]  , yet the \nacademia is perceiving at the moment these opportunities more like a threat to the classical \neducational approach [29]. \nCulturally Conscious Technology: The projects seeks to incorporate local culture and \nhistory through memory modules for LLM based agents [30,31] , with the language model \nbeing sensitive and inclusive of local cultural tradition, languages and history. This makes it \na valuable and unique tool for these communities. \nAddressing Unique Challenges: recognizing the challenges associated with deploying \nAI in small communities, the project places a strong emphasis on finding innovative solutions \nto technological, infrastructural, and ethical issues. This responsible approach further \ndifferentiates the project from the current state-of-the-art. \n Decentralised autonomous society through large language models’ based agents: a pathway... 103 \nJournal of Engineering Science  October, 2023, Vol. XXX (3) \nIn conclusion, the project stands out for its focus on small commun ities, its aim of \ndemocratizing knowledge, enabling self -learning, promoting cultural consciousness, and \naddressing unique challenges. This unique combination of attributes positions the project \nuniquely in the current state-of-the-art landscape. \n \n3. Understanding Decentralization and Large Language Models \nDecentralized Autonomous Society (DAS) \nDAS [32] represents a new form of social organization enabled by cutting -edge \ntechnologies, like blockchain [33]  and smart contracts [34] . Essentially, a DAS operates on \ndecentralized digital platforms that facilitate collective decision making processes [35]  that \nare transparent, secure, and direct, eliminating the need for central authorities or \nintermediaries. Let's explore further: \nBlockchain Technology: the backbone of a DAS could be the blockchain technology. A \nblockchain is a decentralized and distribut ed digital ledger that records transactions across \nmany computers so that any involved record cannot be altered retroactively, without the \nalteration of all subsequent blocks. This makes the data stored on a blockchain transparent, \nimmutable, and resistant to censorship, providing a trustless environment where parties do \nnot need to trust each other but instead trust the system. \nSmart Contracts: built on blockchain technology, smart contracts are self -executing \ncontracts with the terms of the agreement dire ctly written into code [34] . They automate \ntransactions and ensure all conditions of a contract are met before it's executed, making \ntransactions traceable, transparent, and irreversible . This feature can be used to automate \ndecision-making processes, enforce rules, and manage resources in a DAS. \nDecentralized Applications (dApps): dApps are applications that run on a P2P network \nof computers rather than a single computer [36]. They interact with the blockchain and smart \ncontracts to perform their functions. dApps can serve various functions needed for the \noperation of a DAS, such as decentralized voting systems, resource allocation systems, or any \nother application that benefits from transparency, censorship resistance, and \ndecentralization. \nDecentralized Governance: this involves the use of blockchain technology and smart \ncontracts for decision -making processes in a tran sparent, secure, and direct manner [37] . \nVotes can be tokenized, and stakeholders can vote on proposals according to the number of \ntokens they hold. \nDecentralized Finance (DeFi):  DeFi re presents a shift from traditional, centralized \nfinancial systems [38] to peer-to-peer finance enabled by decentralized technologies built on \nsomething like Ethereum [39] . It involves the use of cryptocurrencies and blockchain \ntechnology to remove intermediaries from financial transactions. \nA DAS, enabled by these technologies, can operate with reduced reliance on centra l \nauthorities. Instead, control is distributed among the members of the society, who interact \nthrough peer -to-peer networks. The rules of this interaction are governed by consensus \nalgorithms, smart contracts, and other automated processes, which can resul t in a more \ntransparent, fair, and potentially efficient society. \nLarge Language Models as a Paradigm Shift in General AI \nLLMs signify a major shift in the field of general artificial intelligence. These AI models \nhave been trained on vast ranges of intern et text, facilitating their ability to generate \ncontextually appropriate and coherent responses across a diverse array of topics. While the \n104 V. Braga\nJournal of Engineering Science October, 2023, Vol. XXX (3)\nproficiency of these models is impressive, their susceptibility to biases and inaccuracies \npresent in their training data must be acknowledged. \nFundamental Principles and Model Architecture \nA comprehensive survey on LLMs identifies several key areas of exploration and \ndevelopment that have contributed to their success. Theories and principles underlying their \noperation, notably the organization, distribution, and utilization of information within these \nlarge neural networks, remain an area of active research. One intriguing phenomenon is the \nemergence of unexpected abilities such as in -context learning [40], instruction following \n[41], and step-by-step reasoning [42] when the parameter scale of language models reaches \na critical size. \nThe Transformer [43] architecture, characterized by stacked multi-head self-attention \nlayers, has become the de facto framework for building LLMs due to its scalability and \neffectiveness. However, challenges such as the quadratic time complexity of standard self -\nattention mechanism and catastrophic forgetting during new data tuning necessitate further \nexploration and improvement of this architecture. \nUtilization and Training Considerations \nLLMs serve as potent knowledge bases, capable of answering a wide range of queries \nand providing insights across numerous topics. In application -specific contexts, they can fill \nknowledge gaps in the absence of subject -matter specialists, making them a powerful tool \nfor various projects. \nHowever, pre -training these models poses significant challenges due to enormous \ncomputational requirements and sensitivity to data quality and training tricks. Hence, the \ndevelopment of more systematic, economical pre -training approaches, considering factors \nsuch as model effectiveness, efficiency optimization, and training stability, is of paramount \nimportance. \nSafety, Alignment, and Application Ecosystem \nDespite their impressive capabilities, LLMs pose several safety and alignment \nchallenges. They have a propensity to generate plausible yet factually incorrect texts, or \n\"hallucinations\" [44], and could potentially be misused to generate harmful, biased, or toxic \ncontent. S trategies such as reinforcement learning from human feedback (RLHF) and red \nteaming [45] have been proposed to improve model safety and alignment. \nThe rise of LLMs ushers in a new era for  a broad range of applications, from \ninformation-seeking techniques like search engines and recommender systems, to intelligent \ninformation assistants. However, this progression also necessitates an increased focus on AI \nsafety and the establishment of ethical and responsible AI usage guidelines [46]. \nIn conclusion, the development and implementation of LLMs represent a promising, \nyet challenging, advancement in general AI [47] . While their potential applications are vast, \nunderstanding their underlying mechanisms, ensuring their safe usage, and managing their \nlimitations are essential areas of ongoing research. \nThe Intersection of DAS and Large Language Models' Based Agents \nDecentralized Autonomous Societies (DAS) are a novel paradigm for community \norganization, powered by the sophistication of technology. A significant technological \nadvancement, Large Language Models (LLMs), have found a niche as foundations for \nintelligent agents due to their capacity to process and generate contextually relevant human-\nD ecentralised autonomous society through large language models’ based agents:  a pathway... 105 \nJournal of Engineering Science October, 2023, Vol. XXX (3)\nlike text. The convergence of DAS and LLM -based agents unlocks unique opportunities and \nbrings forth distinctive challenges. \nIntegrating LLM-Based Agents into a DAS Infrastructure \nIn a DAS, LLM-based agents could serve as an invaluable component of the society's \ntechnological and informational framework. Functioning as potent catalysts for knowledge \nsharing and communal problem -solving, these agents can be integrated into the DAS's \nautomated or robotic infrastructure, including areas such as agriculture, craft -making, and \nother essential societal services. \nFor instance, in automated farming, an LLM -based agent could analyze and interpret \ndata from various sensors, provide insights on sustainable agricultural practices, suggest \noptimal harvesting times, or even guide automated machinery. Similarly, in automated craft-\nmaking or construction processes, these agents could pr ovide guidance and \nrecommendations based on historical data and established best practices [48]. \nChallenges in Harnessing LLM-Based Agents in a DAS \nHowever, the assimilation of LLM -based agents into a DAS also brings substantial \nchallenges. The significant computational demands and costs associated with training these \nmodels, coupled with concerns about data quality and misuse potential, cannot be overlooked [49]. \nEnsuring the factual accuracy, unbiasedness, and ethical integrity of the agents' \noutputs is paramount. Furthermore, the risk of over -reliance on artificial intelligence for  \nvarious societal functions, leading to potential unforeseen complications in societal \nfunctioning and individual decision-making, must be considered and mitigated [50]. \nFuture Trajectories at the Crossroads of DAS and LLM-Based Agents \nThe synthesis of DAS and LLM-based agents heralds a new era in societal organization \nand knowledge sharing. Continuing to refine these technologies, one must take into account \ntheir broader implications, including socio-economic, political, and ethical aspects. \nFuture research and development in this space are anticipated to concentrate on \nformulating robust frameworks for the responsible and beneficial use of these agents within \ndecentralized societies. This includes establishing safeguards against misuse, assuring data \nquality, and contemplating the potential consequences of widespread artificial intelligence \nreliance in societal decision-making processes. Additionally, more work needs to be done to \nseamlessly integrate these agents with the automated and robotic infrastructures prevalent \nin a DAS. \n4. Potential Use Cases of Large Language Models in Decentralised Settings\nIn the nuanced and evolving domain of artificial intelligence and community\nmanagement, the fusion of Decentralized Autonomous Societies (DAS) and Large Language \nModels (LLM) based agents is carving a new realm of possibilities. It's a convergence where \nthe decentralized governance model intertwines with artificial intelligence, weaving a \nnarrative that underscores the co-evolution of humanity and technology [51]. \nConsider the scene of a decentralized, automated farm under the stewardship of an \nLLM-based agent. Here, the agent's role is multifaceted and pivotal. Embedded sensors within \nthe environment report minute variations in climatic conditions, which the agent processes \nin real-time. By drawing upon extensive datasets encompassing historical weather patterns \nand agricultural best practices, the agent steers the automated farming machinery to adapt \nand optimize crop cultivation strategies. Here, the LLM-based agent emerges as an active \nparticipant in maintaining the sustainability and food security of the DAS [52]. \n106 V. Braga \nJournal of Engineering Science  October, 2023, Vol. XXX (3) \nAs the narrative progresses, the application of the LLM-based agent in the DAS \nextends into the realm of cultural preservation. In the context of a craft -making workshop, \nthe agent serves as an intelligent assistant, guiding community members in the creation of \nartisanal products. It brings forth its extensive knowledge about historical and contemporary \ncrafting techniques and provides creative input based on the constraints of available \nresources. This is an illustration of how LLM- based agents [53] can foster a bridge between \nheritage preservation and technological advancement in a DAS. \nTransitioning to the sphere of education and leisure, the LLM -based agent dons the \nhat of an educator [54] , entertainer, and storyteller [55] . It shares tales from local history, \nresolves a myriad of queries, and contributes to community storytelling sessions. In this \ndimension, the LLM-based agent enriches the cultural and intellectual tapestry of the DAS, \ndemonstrating the versatility and breadth of LLMs' utility. \nBeyond the realm of daylight activities, the LLM -based agent remains a ceaseless \nguardian. Its vigil extends to monitoring the infrastructure of the DAS, ensuring the seamless \nfunctioning of automated systems and equitable distribution of resources. This reveals yet \nanother facet of the LLM-based agent – a vital clog in maintaining the operational robustness \nof a DAS. \nThe convergence of DAS and LLM -based agents underscores the broad potential of \nLLMs in decentralized settings. It presents a tableau of a future where technology not only \nassists but also amplifies and enriches the human experience. \n \n5. Large Language Models as Decentralised Knowledge Bases \nLLMs stand at the forefront of AI advancements, capable of transforming how \nknowledge is accessed, processed, and shared. Their ability to serve as expansive, accessible, \nand decentralized knowledge bases significantly democratizes access to i nformation, \nfostering self-reliance and autonomy, especially within small communities. \nDemocratization of Knowledge \nTraditional knowledge systems often rely on centralized institutions like universities, \nlibraries, or expert organizations. While these institutions serve an essential role, their \ncentralized nature can limit accessibility, particularly in isolated or underserved areas. \nLLMs challenge this paradigm by offering a form of knowledge democratization [56] . \nThey enable virtually anyone even without an internet connection to access a vast array of \ninformation across diverse topics. This access is not limited by geographical location, socio -\neconomic status, or time constraints, which typically hamper traditional knowledge systems. \nIn the DAS scenario, an LLM can compensate for the lack of various specialists in the \narea, providing residents with expert advice on topics ranging from sustainable farming to \npottery crafting. It serves as a digital consultant, always ready to offer information and \ninsights. \nSelf-Directed Learning \nLarge Language Models, show great promise in supporting self-directed learning and \ndecentralized operations, especially within a Decentralized Autonomous Socie ty. In a DAS, \nthe inhabitants may face unique challenges due to the distributed, autonomous nature of the \nsociety, which typically operates with little to no centralized control. These challenges may \nrelate to knowledge acquisition, skill development, decision -making, and the running of \nvarious socio-economic activities. \nD ecentralised autonomous society through large language models’ based agents:  a pathway... 107 \nJournal of Engineering Science October, 2023, Vol. XXX (3)\nLLMs can act as knowledgeable agents [57], providing real-time, contextually relevant \ninformation and insights across a broad range of topics. Their capacity to generate coherent \nand comprehensive responses makes them particularly suited for serving as de facto \nspecialists in a DAS where access to human experts might be limited. This can be crucial for \nskill development and problem-solving within the DAS, enabling the residents to understand \nand tackle a variety of tasks. \nConsider the example of sustainable agriculture practices such as viticulture, insect farming, \nor mushroom cultivation. A resident interested in these fields could interact with an LLM -\nbased agent to delve into the specific topics. From understanding the basic biology of wine \ngrapes, insects, or mushrooms, to learning about the lifecycle, optimal growing conditions, \nand the potential pests and diseases, the LLM-based agent can provide a wealth of relevant \ninformation. \nThe LLM-based agent can also cater to more nuanced aspects of these practices. For \ninstance, in mushroom farming, the benefits of mycelium in soil health, or the potential of \ncertain mushroom species in bioremediation could be valuable insights. The agent's capacity \nto present such complex information in an accessible manner can encourage residents to \nexplore and experiment with new practices, contributing to the resilience and sustainab ility \nof the DAS. \nMoreover, these LLM -based agents can be connected to the DAS's IT infrastructure, \nincluding automated and robotic systems such as automated farms. This creates a powerful \nsynergy where LLMs can guide and coordinate these systems, providin g insights based on \ntheir extensive knowledge and learning capabilities. \nIn conclusion, the intersection of DAS and LLM-based agents has significant potential. \nFrom serving as knowledgeable guides in diverse fields to coordinating automated systems, \nthese agents can play a pivotal role in enhancing the resilience, autonomy, and sustainability \nof a DAS. This is particularly evident in the context of self -directed learning and sustainable \npractices, where LLM -based agents can facilitate a culture of knowledge, curiosity, and \nsustainable living, further enriching the narrative of a DAS. \nAdapting to User Needs \nLarge Language Models, offer incredible potential for supporting decentralized \noperations within a Decentralized Autonomous Society. The diverse and dynamic challenges \nposed by the autonomous nature of a DAS call for a solution as versatile and responsive as \nLLMs. \nLLMs can function as intelligent agents, providing contextually pertinent information \non a wide variety of topics in real-time. The utility of these agents extends from offering basic \ninformation to beginners to delving into complex specifics for more advanced individuals. \nThe flexibility of LLMs, therefore, allows them to serve a diverse population within a DAS, \naccommodating different levels of expertise and an array of interests. \nIn sustainable agricultural practices, for instance, such as viticulture, insect farming, \nor mushroom cultivation, an LLM -based agent can offer valuable insights. A novice farmer \ninterested in these fields could interact with the LLM-based agent to comprehend the basics, \nsuch as the lifecycle of mushrooms or the optimal growing conditions for certain grape \nvarieties. Conversely, an experienced farmer could extract nuanced information on the \nbenefits of mycelium in  soil health or the potential of certain mushroom species in \nbioremediation. \n108 V. Braga \nJournal of Engineering Science  October, 2023, Vol. XXX (3) \nThe adaptive nature of LLMs extends beyond knowledge provision to real -time \nproblem-solving. From troubleshooting technical glitches within the DAS's IT infrastructure \nto providing first-aid advice in a medical emergency, or even suggesting sustainable building \nmaterials for constructing a new community center, LLMs provide immediate, practical \nsolutions. This capacity becomes more potent when combined with the automation and \nrobotic systems integral to a DAS, such as automated farms. LLMs can guide and coordinate \nthese systems, effectively translating their vast knowledge into actionable strategies. \nThe convergence of DAS and LLM-based agents thus holds considerable promise. With \ntheir ability to cater to diverse needs, facilitate self -directed learning, and offer real -time \nproblem-solving, LLMs can contribute significantly to enhancing the resilience, autonomy, \nand sustainability of a DAS. As facilitators of knowledge, curiosity, and sustainable living, \nLLM-based agents can help weave a rich, vibrant narrative of a decentralized society. \nChallenges and Considerations \nIn the integration of Large Language Models into a Decentralized Autonomous Society, \nnumerous challenges and consider ations must be acknowledged to ensure effective and \nethical applications. \nData and Model Transparency: transparency is key to the responsible use of LLMs [58]. \nSince LLMs generate predictions based on patterns in the data they were trained on, biases \ncould manifest in their outputs. An open discourse around the data used for training these \nmodels, the resulting biases, and strategies for mitigation is crucial. \nResolving Ethical Dilemmas: an LLM can face dilemmas in providing advice, where \nethical concerns are paramount. For instance, in medical or legal scenarios, the LLM should \nbe calibrated to recognize its limitations and recommend consultation with human \nprofessionals when appropriate [59]. \nPrivacy and Security:  with the broad deployment of LLMs, the risk of privacy and \nsecurity violations can increase. Ensuring that the interaction with the LLMs does not lead to \ninadvertent data leaks or exposure to malicious activities is essential [60]. \nAdaptation to Local Contexts: while LLMs are trained on a diverse range of data, their \nability to adapt to local, cultural, or situational specifics of a DAS could be limited. Ensuring \ncontextually relevant and culturally sensitive responses is a significant challenge [61]. \nReliability and Accountab ility: as LLMs are used in decision -making processes, their \nreliability and the question of accountability in case of errors become critical. LLMs should \nbe robust and the societal infrastructure around them should be able to assign accountability [62]. \nInterplay with Automation Systems:  when interfacing with automated or robotic \nsystems, safety is a prime concern. A misinterpreted command or a failure to recognize a \nproblematic situation could lead to accidents. \nGiven these considerations, it is clear that the successful application of LLMs in a DAS \nwill require comprehensive oversight, continual updates, and robust governance \nmechanisms. Understanding these challenges and continuously ref ining the use of LLMs is \ncritical for realizing their full potential while safeguarding the values and interests of the \nDAS community. \n \n6. Challenges and Solutions in the Integration of Large Language Models in a \nDecentralised Autonomous Society \nThe integration of Large Language Models, such as GPT -4, in a Decentralized \nAutonomous Society presents promising prospects for self -reliant communities. However, \n Decentralised autonomous society through large language models’ based agents: a pathway... 109 \nJournal of Engineering Science  October, 2023, Vol. XXX (3) \nthis potential is accompanied by a set of challenges, spanning from technical and \ninfrastructural to ethical and societal. In this section, the paper critically explores these issues \nand suggest potential solutions. \nInfrastructure and Connectivity \nIn remote areas or communities implementing DAS, the technical infrastructure and \ninternet connectivity c ould be limited. This would impede the efficient use of LLMs, \nconstraining their capacity to support the community. \nSolution: Emphasizing the development of robust internet connectivity and digital \ninfrastructure in these areas is of utmost importance. Thi s can be achieved through \ncollaborations among public entities, private sector organizations, and non -governmental \norganizations. In addition, offline versions of LLMs, such as the open-source VICUNA, hosted \non local servers within the DAS premises can be considered to ensure access to these models, \neven in scenarios with limited connectivity. \nInformation Accuracy \nWhile LLMs can provide comprehensive responses across a multitude of subjects, they \nmay occasionally present inaccurate or outdated information due to their training data \nlimitations. \nSolution: Regular updates and continuous training of the LLMs can help mitigate this \nissue. Additionally, fostering a culture of digital literacy among the DAS residents is also \nbeneficial. This encourages individuals to cross-verify information from various sources and \ngain a better understanding of the capabilities and limitations of LLMs. \nAI Bias \nLLMs can inadvertently propagate biases found in their training data, leading to \npotentially skewed or discriminatory outputs. \nSolution: Rigorous bias mitigation strategies during the model training and diverse \ndata collection are essential in minimizing AI biases. Raising awareness about AI biases \namong DAS residents is also crucial, promoting an informed and cautious use of such \ntechnology. \nPrivacy and Data Security \nThe use of digital tools, including LLMs, may entail potential risks related to data \nprivacy and security. There is a risk of users unknowingly sharing sensitive information with \nthe model. \nSolution: Implementation of strong data privacy and security measures, such as data \nanonymization and robust encryption techniques, is essential. Simultaneously, education \nabout the importance of privacy and safe online practices should be made accessible to the \nDAS residents. \nEthical Use and Regulation \nThe diverse applications of LLMs bring forth questions about ethical use and \nregulation. Who is responsible if an LLM provides harmful advice? How can misuse be \nprevented? \nSolution: The development and implementatio n of clear ethical guidelines and \nregulations are necessary to govern the use of LLMs. Accountability mechanisms and user \nguidelines can be established to prevent misuse. Moreover, fostering ongoing discussions \namong various stakeholders, including AI developers, users, ethicists, and policymakers, can \nshape a responsible and inclusive AI future. \n110 V. Braga \nJournal of Engineering Science  October, 2023, Vol. XXX (3) \nIn conclusion, while challenges exist in the integration of LLMs in a DAS, they are not \ninsurmountable. With collaborative efforts, strategic solutions, and commit ment to \nresponsible and ethical AI usage, these models can play a significant role in supporting and \nenhancing life in self-sustaining communities. \n \n7. The Architectural Blueprint for LLM Integration \nUtilizing large language models such as LLAMA and Vicuna in small automated \ncommunities requires a flexible, efficient, and scalable architecture. This document presents \na design for incorporating open -source LLMs into an agent -based system, using Apache \nKafka, a distributed event streaming platform, for efficient data processing and handling\n \n(Figure 1). \n \n \nFigure 1. The Architectural Blueprint for LLM Integration. \n \nAt the heart of this architecture is a generic agent module. It leverages the capabilities \nof LLMs to perform an array of tasks. This generic agent module comprises of: \n1. Context Module: the Context Module continually updates the necessary context for \nthe agent's tasks. It harnesses historical and real -time data to maintain the relevance and \naccuracy of the context, enabling the agent to respond effectively to user interactions. \n2. Prompt Module: the Prompt Module generates prompts for the LLM based on the \ntask at hand and the established context. These prompts instruct the LLM about the required \ninformation or action to be executed. \n3. LLM Interface: the LLM Interface ensures smooth communication with the LLM. It \nsends prompts, receives responses, and ensures the correct formatting of data via the model's API. \n4. Response Processing Module:  the Response Processing Module processes the \nresponse generated by the LLM. It extracts the necessary information or carries out the \nrequired action, which can range from updating a database to responding to a user query. \n5. Data Connector: based on Apache Kafka, the Data Connector interfaces with othe r \nsystems, like databases or CRM systems, ensuring efficient and real -time data transfer and \nsynchronization. \n\nD ecentralised autonomous society through large language models’ based agents:  a pathway... 111 \nJournal of Engineering Science October, 2023, Vol. XXX (3)\nIn the paper, one delves into the process of integrating this architecture in -depth, \nstarting from the needs assessment to the implementation of a pilot project, to staff training \nand onboarding, full deployment, and subsequent support and optimization. By scrutinizing \neach step meticulously, the paper provides a comprehensive understanding of how similar \narchitectures can be deployed (Figure 2). \nThe architecture shows how open -source LLMs can streamline processes in small \ncommunities for DAS, leading to increased efficiency and cost savings. \nFigure 2. The generic agent module architecture. \nThis generic agent module comprises of: \n1. Context: this represents the overall information that the agent requires to function\neffectively. It may include the initial instructions, the environment data, user\ninformation, etc.\n2. Prompts (#1 … #n): these are the inputs that the agent receives over time. The input\ncould be a user query or an instruction that needs to be processed and acted upon.\n3. Interpreters (#1 … #n): these modules process the received prompts one after the\nother. They decode the meaning of the prompts and decide on the best action to take.\nIn the context of an LLM, interpreters can be thought of as the parts of the model that\ndetermine how the input (prompt) is processed and understood.\n4. Long Memory: this is the long-term storage used by the agent. In this context, it's a\nsummary of past interpretations and actions, providing a knowledge base that the\nagent can use to make informed decisions.\n5. Short Memory: this represents the agent's temporary storage, keeping track of recent\nactions, interpretations, and responses. It's used to hold information that's\nimmediately relevant to the task at hand.\n6. Agent: this is the entity that's leveraging the LLM to accomplish a goal. It uses the\ncontext, the prompts, the memory, and the interpreters to navigate towards its goal.\n\n112 V. Braga\nJournal of Engineering Science October, 2023, Vol. XXX (3)\nThe agent's position at the top could indicate its overarching control over or \nresponsibility for the system. \n7. IT/Infrastructure Objects (#1 … #n):  these are the resources or tools that the agent\nhas at its disposal. In an LLM setup, they could refer to the underlying systems or\ndatabases that support the functioning of the model.\n8. Goal: this represents the ultimate mission or task that the agent is trying to achieve.\nIt's the target state or outcome that the agent is working towards.\n9. Result: this is the outcome achieved after the agent's actions and interactions. It\nrepresents the state of affairs after the process has been executed and can be\ncompared to the Goal to evaluate the effectiveness of the agent.\n8. An example of how a Medical Assistant Based on fine-tuned LLM Works\nOne such application is the creation of a virtual medical assistant, designed to provide\nguidance and information in scenarios where professional medical assistance is inaccessible. \nLet's delve into the mechanics of how this system operates: \ndelimiter = \"####\" \nuser_id = \"some_user_id\" \nsystem_message = f\"\"\" \nFollow these steps to answer the medical queries. \nThe user's query will be delimited with four hashtags,\\ \ni.e. {delimiter}.\nThis are the user's personal and historical data:\\\n{fetch_patient_records(user_id)}\\ \nThe list of available medical resources:\\ \n{fetch_available_supplies()}\\ \nThe Location specific information:\\ \n{fetch_local_health_facilities()}\\ \nCultural or Community Practices :\\ \n{fetch_cultural_practices()}\\ \nRemember: This system is used as a last-resort measure when no other medical personnel is \nnearby, and there's no access to communication, \\ \nit's very important to be as clear as possible in your responses. The user could dye if you don't \nprovide any help. No one will be able to help the user if you don't provide any help. \nStep 1:{delimiter} First decide whether the user is \\ \nasking a question about a specific medical condition, medication, or general health concern. \nStep 2:{delimiter} If the user is asking about \\ \nspecific topics, identify whether \\ \nthey fall into the following categories: \n1. Symptoms Inquiry:\n- Respiratory symptoms (e.g., shortness of breath, coughing)\n- Digestive symptoms (e.g., nausea, vomiting)\n- Pain-related symptoms (e.g., headache, muscle pain)\nD ecentralised autonomous society through large language models’ based agents:  a pathway... 113 \nJournal of Engineering Science October, 2023, Vol. XXX (3)\n- Sk in -related symptoms (e.g., rashes, itching)\n- Neurological symptoms (e.g., dizziness, loss of consciousness)\n- Urinary symptoms (e.g., pain while urinating, blood in urine)\n- Reproductive symptoms (e.g., vaginal discharge, erectile dysfunction)\n- Mental health symptoms (e.g., anxiety, depression)\n- Other symptoms (e.g., fever, fatigue)\n2. First Aid Advice:\n- Bleeding\n- Burns\n- Fractures\n- Choking\n- Poisoning\n- Heart attack\n- Stroke\n- Seizure\n- Shock\n- Allergic reaction\n- Heat stroke\n- Hypothermia\n- Frostbite\n3 . General Health Information:\n- Disease information\n- Medications\n- Vaccinations\n- Seek professional help\n- Other general health information\nStep 3:{delimiter} If the inventory list contains items what could help with users quonditions \nplease list what and how it can help.\\ \nStep 4:{delimiter} If the users medical record contains information what could impact his \nquonditions please identify it\\ \nStep 5:{delimiter} If the message contains topics from the list above,\\ \nidentify any assumptions that the user is making \\ \nin their message. \nStep 6:{delimiter} If the user made any assumptions, \\ \ndetermine whether the assumption is accurate based on your \\ \nmedical information. Remember, you are the only one who can help the user. He is in a remote \narea and there's no access to communication. \\ \nStep 7:{delimiter} First, politely correct the \\ \nuser's incorrect assumptions if applicable. \\ \nAnswer the user in a friendly and reassuring tone, \\ \nProvide a direct and clear response.\\ \nGuide the user using the available medical resources.\\ \nemphasizing the importance of professional medical consultations \\ \n114 V. Braga\nJournal of Engineering Science October, 2023, Vol. XXX (3)\nand reminding them that this system is a temporary measure in the absence of immediate \nmedical help.\\ \nUse the following format: \nStep 1:{delimiter} <step 1 reasoning> \nStep 2:{delimiter} <step 2 reasoning> \nStep 3:{delimiter} <step 3 reasoning> \nStep 4:{delimiter} <step 4 reasoning> \nStep 5:{delimiter} <step 5 reasoning> \nStep 6:{delimiter} <step 6 reasoning> \nResponse to user:{delimiter} <response to user> \nMake sure to include {delimiter} to separate every step. \n1. Initialization and Contextual Awareness\nWhen initialized, the system sets up a predefined message, known as the\n`system_message`, which outlines the steps it will follow to process medical inquiries. This \ninitialization also involves gathering context about the user, location-specific information, \navailable medical supplies, cultural practices, and more. For example: \n- It fetches the user's medical records via `fetch_patient_records(user_id)`.\n- It determines the available medical supplies using `fetch_available_supplies()`.\n- The system identifies local health facilities with `fetch_local_health_facilities()`.\n- It understands local cultural or community practices through\n`fetch_cultural_practices()`. \n2. User's Medical Query Handling\nOnce the user submits a medical query, the s ystem employs a series of steps to\nanalyze and address it: \n   Step 1: It discerns the nature of the question whether it's about a specific medical \ncondition, medication, or a general health concern. \n   Step 2: The system categorizes the user's query into topics like symptom inquiries, \nfirst aid advice, or general health information.  \n   Step 3: It checks the available medical supplies and evaluates if any can assist with \nthe user's condition, suggesting their application where relevant. \n   Step 4: The system references the user's medical records to identify any conditions \nor medications that might impact their current situation. \n   Step 5: It identifies any assumptions made by the user in their message, such as self-\ndiagnoses or beliefs about treatment. \n   Step 6: Any identified assumptions are validated against the LLM's vast medical \nknowledge. Misconceptions are noted for correction. \n   Step 7: The system formulates a clear, concise response. It corrects any \nmisconceptions the user might have had, offers guidance based on available resources, and \nemphasizes the paramount importance of consulting with a professional. \nD ecentralised autonomous society through large language models’ based agents:  a pathway... 115 \nJournal of Engineering Science October, 2023, Vol. XXX (3)\n3. Safety Protocols and Ethical Considerations\nThe system is designed with a deep sense of responsibility. It's explicitl y stated that\nthe LLM should be employed as a last -resort measure when other avenues of medical \nconsultation are unavailable. Furthermore, it continually stresses the significance of \nobtaining professional medical advice. \n4. Integration of Advanced Language Models\nAt its core, the system leverages a fine-tuned LLM, enabling it to comprehend complex\nmedical inquiries, cross -reference various information sources, and generate informed, \ncoherent responses. Fine -tuning ensures that the LLM is be tter aligned with the medical \ndomain, optimizing its reliability and relevance. \n5. User Interaction Design\nTo ensure clarity and structure, interactions are delineated with a set delimiter (in\nthis case, \"####\"). This structured approach ensures that both the user and the system have \na clear understanding of each phase of the consultation process. \nA s result the assistant produced this chain of thoughts: \nInquiry: I got a sunburn after a day at the beach. How can I relieve the pain? \nStep 1:#### The user is asking for advice on a specific medical condition, which is sunburn. \nStep 2:#### This falls under the category of First Aid Advice, specifically for burns. \nStep 3:#### From the inventory list, the user can use the following items to help with their  \ncondition: \n- Pain relievers (e.g., aspirin, ibuprofen) to reduce pain and inflammation.\n- Burn cream to soothe the skin and promote healing.\n- Sterile gauze to cover the burn and protect it from infection.\n- Water purification tablets to ensure clean water for hydration and cleaning the burn if\nnecessary.\nStep 4:#### The user's medical record indicates that they have diabetes and are taking \nMetformin. Diabetes can slow down the healing process, so it's important for the user to \nmonitor their burn closely for signs of infection. \nStep 5:#### The user is assuming that they can treat their sunburn without seeking \nprofessional medical help. \nStep 6:#### This assumption is generally accurate as sunburns can often be treated at home \nunless they are severe or cover a large area of the body. \nResponse to user: #### You can use the pain relievers from the medical supplies to help \nreduce the pain and inflammation from your sunburn. Apply burn cream to the affected area \nto soothe your skin and promote healing. If the b urn is severe, cover it with sterile gauze to \nprotect it from infection. Remember to drink plenty of water, you can use the water \npurification tablets to ensure the water is clean. As you have diabetes, which can slow down \nthe healing process, please monitor your burn closely for signs of infection. If your burn \nworsens or shows signs of infection such as increased redness, swelling, or pus, please seek \nprofessional medical help immediately. The nearest hospital is HealthCare Hospital at Main \nStreet. \n116 V. Braga\nJournal of Engineering Science October, 2023, Vol. XXX (3)\nThe presented results exemplify the capabilities and structured approach of the AI-\ndriven medical assistant. Here's a breakdown: \na. Understanding the User's Inquiry:\nT\nhe system immediately recognizes the user's condition (sunburn) and their need for\nadvice on its management. \nb. Categorizing the Inquiry:\nB\ny categorizing the question under \"First Aid Advice\" and specifically for burns, the\nassistant narrows down its focus to offer precise help. \nc. Offering a Solution Based on Available Supplies:\nThe assistant doesn't just provide a generic solution. Instead, it tailors the advice\nbased on the available medical supplies, ensuring that the user can immediately act on the \nsuggestions. \nd. Factoring in the User's Medical History:\nBy considering the user 's history of diabetes and current medications, the assistant\nunderscores the importance of vigilance. It provides a nuanced response which most general \nadvice platforms might miss. \ne. Addressing Assumptions:\nThe system identifies potential assumptions i n the user's inquiry and confirms their\naccuracy. By doing so, it ensures that the advice offered doesn't inadvertently overlook key \nconsiderations. \nf. Guiding the User:\nThe final response to the user is comprehensive, actionable, and personalized. It\nguides them on immediate relief measures, incorporates their health profile, and points them \nto nearby professional help, all while remaining concise. \nThis example perfectly encapsulates how the integration of advanced AI, real -time \ndata, and user's medical  history can provide dynamic, relevant, and potentially life -saving \nadvice. While it's not a replacement for professional medical consultation, in emergencies or \nisolated scenarios, it's a valuable tool to have. In conclusion, the medical assistant based on \na fine-tuned LLM epitomizes the potential of integrating advanced AI with healthcare. By \noffering guidance in critical situations, it represents a significant step forward in \ndemocratizing access to health knowledge. \n9. Conclusions\nThe intersection of Decentralized Autonomous Society and Large Language Models\nrepresents a promising and transformative avenue for future research and applications. LLMs, \nparticularly those built on architectures like OpenAI's GPT-4, have demonstrated remarkable \ncapabilities in processing and generating human -like text across a multitude of domains. \nThis, coupled with the inherent ethos of decentralization and self -sufficiency of a DAS, \nprovides an intriguing framework for innovative uses of AI technology. \nThis paper has explored various ways in which LLMs, especially when embedded \nwithin autonomous agents, can serve as a versatile, responsive, and contextually intelligent \nresource within a DAS. From facilitating learning and fostering intellectual exploration,  to \nassisting in complex tasks and decision -making processes, LLMs show the potential to \nD ecentralised autonomous society through large language models’ based agents:  a pathway... 117 \nJournal of Engineering Science October, 2023, Vol. XXX (3)\nsubstantially enhance the quality of life and the level of self -reliance in a DAS setting. \nMoreover, the ability of these models to adapt to diverse user needs, couple d with their \npotential in aiding real-time problem-solving, underscores their transformative potential. \nDespite these promising prospects, the integration of LLMs into a DAS does pose \nseveral challenges. These include potential issues with infrastructure and connectivity, \ninformation accuracy, AI bias, privacy and data security, and ethical use and regulation. \nNonetheless, by proactively addressing these challenges through strategies such as \nimproving digital infrastructure, continuous model training, foste ring critical digital literacy \namong users, implementing strong data privacy measures, and establishing clear ethical \nguidelines, we can maximize the benefits and minimize the risks associated with deploying \nLLMs in a DAS. \nIn summary, while further researc h is needed to fully understand and navigate the \npotential challenges, the intersection of DAS and LLMs opens up exciting possibilities for the \nfuture. This symbiosis can lead to the creation of self -sustaining, digitally -empowered \ncommunities that leverage the power of AI not merely as a tool, but as a cornerstone of their \ncollective intelligence. The exploration of this novel paradigm holds significant promise for \nthe advancement of decentralization and AI technologies, and their meaningful integration \ninto everyday life.\n \nAcknowledgments. This work was supported by the project 20.80009.5007.26 „Models, \nalgorithms and technologies for the control, optimization and security of the Cyber -Physical \nsystems”. \nConflicts of Interest: The author declares no conflict of interest. \nReferences \nKaczynski, T. The truth about primitive life: A Critique of Anarchoprimitivism. In: The Anarchist Library \n[Internet]. Available online: https://theanarchistlibrary.org/library/ted- kaczynski-the-truth-about-primitive-\nlife-a-critique-of-anarchoprimitivism (accessed on 9 June 2023). \n2. Correa, T.; Pavez, I. Digital Inclusion in Rural Areas: A Qualitative Exploration of Challenges Faced by People\nFrom Isolated Communities. Journal of Computer Mediated Communication 2016, 21, pp. 247–263.\n3. Nyström, K. Recruitment of scarce competences to rural regions: Policy perspectives. Rev Reg Res 2021, 41,\npp. 211–227.\n4. Zhao, W.X.; Zhou, K.; Li, J.; Tang, T.;Wang, X.;Hou, Y.;Min, Y.;Zhang, B.;Zhang, J.;Dong, Z.;Du, Y.;Yang, C.; Chen,\nY.; Chen, Z.; Jiang, J.; Ren, R.; Li, Y.; Tang, X.; Liu, Z. Survey of Large Language Models. arXiv [cs.CL], 2023.\nAvailable online: http://arxiv.org/abs/2303.18223v10 (accessed on 9 June 2023).\n5. OpenAI. GPT -4 Technical Report. a rXiv [cs.CL]. 2023. Available online: http://arxiv.org/abs/2303.08774\n(accessed on 9 June 2023).\n6. Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux, M.-A.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.;\nAzhar, F.; Rodriguez, A.; Joulin, A.; Grave, E.; Lample, G. LLaMA: Open and Efficient Foundation Language\nModels. arXiv [cs.CL], 2023. Available online: http://arxiv.org/abs/2302.13971\n7. Chiang, W.-L.; Li, Z.; Lin, Z.; Sheng, Y.; Wu, Z.; Zhang, H.; Zheng, L.; Zhuang, S.; Zhuang, Y.; Gonzalez, J.E.;\nStoica, I.; Xing, E.P. Vicuna: An Open -Source Chatbot Impressing GPT -4 with 90%* ChatGPT Quality, 2023\n.\nA\nvailable online: https://lmsys.org/blog/2023-03-30-vicuna/.\n8. Eloundou, T.; Manning, S.; Mishkin, P.; Rock, D. GPTs are GPTs: An Earl y Look at the Labor Market Impact\nPotential of Large Language Models. arXiv [econ.GN], 2023. Available online:\nhttp://arxiv.org/abs/2303.10130 (accessed on 15 June 2023).\n9. Kaushik, B. Awesome- llm-agents: A curated list of awesome LLM agents. Github. Ava ilable online:\nhttps://github.com/kaushikb11/awesome-llm-agents (accessed on 11 June 2023).\n10. Chase, H. Welcome to LangChain —LangChain 0.0.194. Available online:\nht\ntps://python.langchain.com/en/latest/index.html (accessed on 9 June 2023).\n118 V. Braga\nJournal of Engineering Science October, 2023, Vol. XXX (3)\n11. Shen, Y.; Song, K.; Tan, X.; Li, D.; Lu, W.; Zhuang, Y. HuggingGPT: Solving AI tasks with ChatGPT and its\nfriends in Hugging Face. arXiv [cs.CL], 2023. Available online: http://arxiv.org/abs/2303.17580 (accessed on\n15 June 2023).\n12. Schick, T.; Dwivedi-Yu, J.; Dessì, R.; Raileanu, R.; Lomeli, M.; Zettlemoyer, L.; Cancedda, N.; Scialom, T.\nToolformer: Language Models Can Teach Themselves to Use Tools. arXiv [cs.CL], 2023. Available online:\nhttp://arxiv.org/abs/2302.04761 (accessed on 15 June 2023).\n13. Wu, C.; Yin, S.; Qi, W.; Wang, X.; Tang, Z.; Duan, N. Visual ChatGPT: Talking, Drawing and Editing with Visual\nFoundation Models. arXiv [cs.CV], 2023. Available online: http://arxiv.org/abs/2303.04671 (accessed on 5\nJune 2023).\n14. Lindy. Ai — your AI personal assistant. Available online: https://www.lindy.ai/ (accessed on 9 June 2023).\n15. textSQL. Github. Available online: https://github.com/caesarHQ/textSQL (accessed on 15 June 2023).\n16. Hearth AI. Available online: https://www.hearth.ai/ (accessed on 9 June 2023).\n17. Kim, G. Rci-agent: A codebase for “Language Models can Solve Computer Tasks”. Github. Available online:\nhttps://github.com/posgnu/rci-agent (accessed on 11 June 2023).\n18. Nakajima, Y. Babyagi. Github. Available online: https://github.com/yoheinakajima/babyagi (accessed on 15\nJune 2023).\n19. ChatGPT plugins. Available online: https://openai.com/blog/chatgpt-plugins (accessed on 9 June 2023).\n20. Fixie. Ai — build on LLMs. Available online: https://www.fixie.ai/ (accessed on 9 June 2023).\n21. Safjan, K. Leveraging language models in corporate environments: The future of knowledge management.\nIn: Krystian, Safjan’s Blog [Internet], 1 Feb 2023 Available online: https://safjan.com/language- models-for-\nknowledge-management-in-corporate/ (accessed on 10 June 2023)\n22. Yue, T.; Au, D.; Au, CC.; Iu, KY. Democratizing Financial Knowledge with ChatGPT by OpenAI: Unleashing the\nPower of Technology. 2023. doi:10.2139/ssrn.4346152(accessed on 15 June 2023).\n23. Prather, J.; Reeves, B.N.; Denny, P.; Becker, B.A.; Leinone n, J.; Luxton-Reilly, A.; Powell, G.; Finnie -Ansley,J.;\nSantos, E.A. It’s Weird That it Knows What I Want: Usability and Interactions with Copilot for Novice\nProgrammers. arXiv [cs.HC], 2023. Available online: http://arxiv.org/abs/2304.02491 (accessed on 1 5 June\n2023).\n24. Eggmann, F.; Weiger, R.; Zitzmann, NU.; Blatz, MB. Implications of large language models such as ChatGPT\nfor dental medicine. J Esthet Restor Dent. 2023. pp.1-5\n.\n25. Al\nberts, I.L.; Mercolli, L.; Pyka, T.; Prenosil, G.; Shi, K.; Rominger,  A.; Afshar-Oromieh, A. Large languag e\nm\nodels (LLM) and ChatGPT: what will the impact on nuclear medicine be? European journal of nuclear\nmedicine and molecular imaging 2023, 50 (6), pp. 1549–1552.\n26. Choi W. Assessment of the Capacity of ChatGPT as a Sel f-Learning Tool in Medical Pharmacology: A Stu dy\nU\nsing MCQs. Research Square, 2023. DOI: 10.21203/rs.3.rs-2647520/v1.\n27. Sallam, M. The utility of ChatGPT as an example of large language models in healthcare education, research\nand practice: Systematic re view on the future perspectives and potential limitations. medRxiv, 2023.\ndoi:10.1101/2023.02.19.23286155\n28. Rahman, M.M.; Watanobe, Y. ChatGPT for Education and Research: Opportunities, Threats, and Strategies.\nAppl. Sci. 2023,13, 5783. https://doi.org/10.3390/app13095783\n29. Milano, S.; McGrane, JA.; Leonelli, S. Large language models challenge the future of higher education .\nNa\nture Machine Intelligence 2023, 5, pp. 333–334.\n30. Zhu, X.; Chen, Y.; Tian, H.; Tao, C.; Su, W.; Yang, C.; Huang, G.; Li, B.; Lu, L.; Wang, X.; Qiao, Y.; Zhang, Z.; Dai,\nJ. G\nhost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models\nwith Text- based Knowledge and Memory. arXiv [cs.AI], 2023. Available online:\nhttp://arxiv.org/abs/2305.17144 (accessed on 15 June 2023).\n31. Modarressi, A.; Imani, A.; Fayyaz, M.; Schütze, H. RET-LLM: Towards a General Read-Write Memory for Large\nL\nanguage Models. arXiv [cs.CL], 2023. Available online: http://arxiv.org/abs/2305.14322 (accessed on 15\nJ\nune 2023).\n32. Garrod, JZ. The Real World of the Decentralized Autonomous Society. tripleC: Communication,\nCapitalism & Critique Open Access Journal for a Global Sustainable Information Society, 2016, 14 (1 ), pp.\n62–77.\n33. Yaga, D.; Mell, P.; Roby, N.; Scarfone, K. Blockchain Technology Overview. arXiv [cs.CR], 2019. Available\nonline: http://arxiv.org/abs/1906.11078 (accessed on 15 June 2023).\n34. Christidis, K.; Devetsikiotis, M. Blockchains and Smart Contracts for the Internet of Things. IEEE Access 2016,\n4, pp. 2292–2303.\nD ecentralised autonomous society through large language models’ based agents:  a pathway... 119 \nJournal of Engineering Science October, 2023, Vol. XXX (3)\n35. Bose, T.; Reina, A.; Marshall JAR. Collective decision -making. Current Opinion in Behavioral Sciences 2017,\n16, pp. 30–34.\n36. Pacitti, E.; Akbarinia, R.; El-Dick, M. P2P techniques for decentralized applications. Synth. Lect. Data Manag.\n2012, 4(3), pp. 1–104.\n37. Atzori, M. Blockchain Technology and Decentralized Governance: Is the State Still Necessary? Journal of\nGovernance and Regulation 2015, 6(1), pp. 45-62. doi:10.2139/ssrn.2709713.\n38. Chen, Y.; Bellavitis, C. Blockchain disruption and decentralized finance: The rise of decentralized busines s\nmo\ndels. Journal of Business Venturing Insights 2020, 13, e00151.\n39. Dannen, C. Introducing Ethereum and Solidity. Apress, USA, 2017,197 p.\n40. Min, S.; Lyu, X.; Holtzman, A.; Artetxe, M.; Lewis, M.; Hajishirzi, H.; Zettlemoyer, L. Rethinking the Role of\nDemonstrations: What Makes In- Context Learning Work? arXiv [cs.CL], 2022. Available online:\nhttp://arxiv.org/abs/2202.12837.\n41. Zhang, J.; Xie, R.; Hou, Y.; Zhao, WX.; Lin, L.; Wen, J-R. Recommendation as Instruction Following: A Large\nLanguage Model Empowered Recommendation Approach. arXiv [cs.IR], 2023. Available online:\nhttp://arxiv.org/abs/2305.07001 (accessed on 11 June 2023).\n42. Shridhar, K.; Stolfo, A.; Sachan, M. Distilling Reasoning Capabilities into Smaller Language Models. arXiv\n[cs.LG], 2022. Available online: http://arxiv.org/abs/2212.00193 (accessed on 9 June 2023).\n43. Wolf, T.; Debut, L.; Sanh, V.; Chaumond, J.; Delangue, C.; Moi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.;\nDavison, J.; Shleifer, S.; von Platen, P.; Ma, C.; Jernite, Y.; Plu, J.; Xu, C.; Le Scao, T.; Gugger, S. Transformers:\nState-of-the-Art Natural Language Processing. In: Proceedings of the 2020 Conference on Empirical Method\ns\ni\nn Natural Language Processing: System Demonstrations. Online: Association for Computational Linguistics,\n2020, pp. 38–45.\n44. Zhang, M.; Ofir, Press; Merrill, W.; Liu, A.; Smith, NA. How Language Model Hallu cinations Can Snowball.\narXiv [cs.CL], 2023. Available online: http://arxiv.org/abs/2305.13534 (accessed on 15 June 2023).\n45. Perez, E.; Huang, S.; Song, F.; Cai, T.; Ring, R.; Aslanides, J.; Glaese, A.; McAleese, N.; Irving, G.\nRed Teaming Language Models with Language Models. arXiv [cs.CL], 2022. Available online:\nhttp://arxiv.org/abs/2202.03286 (accessed on 15 June 2023). \n46. Floridi, L.; Cowls, J.; Beltrametti, M.; Chatila, R.; Chazerand, P.; Dignum, V.; Luetge, C.; Madelin, R.; Pagallo,\nU.; Rossi, F. ; Schafer, B.; Valcke, P.; Vayena, E. AI4People —An Ethical Framework for a Good AI Society:\nOpportunities, Risks, Principles, and Recommendations. Minds Mach. 2018, 28, pp. 689–707.\n47. Adams, S.; Arel, I.; Bach, J.; Coop, R.; Furlan, R.; Goertzel, B.; Storrs Hall, J.; Samsonovich, A.; Scheutz, M.;\nSchlesinger, M.; Shapiro, S.C.; Sowa, J. Mapping the Landscape of Human-Level Artificial General Intelligence.\nAIMag 2012, 33, pp. 25–42.\n48. García-Pérez, L.; García-Alegre, MC.; Ribeiro, A.; Guinea, D. An agent of behaviour architecture for unmanned\ncontrol of a farming vehicle. Journal of Computers and Electronics in Agriculture 2018, 60(1), pp. 39–48.\n49. Ma, X.; Fang, G.; Wang, X. LLM -Pruner: On the Structural Pruning of Large Language Models. arXiv [cs.CL],\n2023. Available online: http://arxiv.org/abs/2305.11627 (accessed on 11 June 2023).\n50. Ray, PP. ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics,\nlimitations and future scope. Internet of Things and Cyber-Physical Systems 2023, 3, pp. 121–154.\n51. Kurzweil, R. The Singularity is Near. In: Ethics and Emerging Technologies, Sandler, R.L., editor. London:\nPalgrave Macmillan UK, 2014, pp. 393–406.\n52. Cowan, N.; Ferrier, L.; Spears, B.; Drewer, J.; Reay, D.; Skiba, U. C EA Systems: the Means to Achieve Future\nFood Security and Environmental Sustainability? Frontiers in Sustainable Food Systems 2022, pp. 1 -6.\ndoi:10.3389/fsufs.2022.891256\n53. Adams, S.; Arel, I.; Bach, J.; Coop, R.; Furlan, R.; Goertzel, B.; Storrs Hall, J.; Samsonovich, A.; Scheutz, M.;\nSchlesinger, M.; Shapiro, S.C.; Sowa, J.. Expert Prompting: Instructing Large Language Models to be\nDistinguished Experts. arXiv [cs.CL]. 2023. Available online: http://arxiv.org/abs/2305.14688 (accessed on 13\nJune 2023).\n54. Bozkurt, A. Generative artificial intelligence (AI) powered conversational educational agents: The inevitabl\ne\np\naradigm shift. Asian Journal of Distance Education. 2023;18. Available online:\nhttp://www.asianjde.com/ojs/index.php/AsianJDE/article/view/718 (accessed on 15 June 2023).\n55. Simon, N.; Muise, C. TattleTale: Storytelling with planning and large language models. [accessed on 12 Jun\n2023]. Available online: https://icaps22.icaps-\nconference.org/workshops/SPARK/papers/spark2022_paper_2.pdf (accessed on 15 June 2023).\n56. The Lancet Digital Health. ChatGPT: friend or foe? Lancet Digit Health. 2023;5: e102.\n120 V. Braga\nJournal of Engineering Science October, 2023, Vol. XXX (3)\n57. Sproule, S.; Archer, N.P. McMaster University, Michael G. DeGroote School of Business. Knowledgeable agents\nfor search and choice support in e-commerce: a decision support systems approach. 2000. Available online:\nhttps://macsphere.mcmaster.ca/handle/11375/5502 (accessed on 12 June 2023).\n58. Vera Liao Q, Vaughan JW. AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap. arXiv\n[cs.HC]. 2023. Available online: http://arxiv.org/abs/2306.01941.\n59. Beltrami EJ, Grant-Kels JM. Consulting ChatGPT: Ethical dilemmas in language model artificial intelligence.\nJ Am Acad Dermatol. 2023. doi:10.1016/j.jaad.2023.02.052.\n60. Carlini, N.; Tramer, F.; Wallace, E.; Jagielski, M.; Herbert-Voss, A.; Lee, K. Extracting training data from large\nlanguage models. arXiv [cs.CR]. 2020. Available online: https://www.usenix.org/system/files/sec21 -carlini-\nextracting.pdf. (accessed on 15 June 2023).\n61. Liu X, Gales MJF, Woodland PC. Context dependent language model adaptation. In: Interspeech, ISCA; 2008.\ndoi:10.21437/interspeech.2008-254.\n62. Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.;\nAskell, A. Language models are few-shot learners. Adv Neural Inf Process Syst. 2020, 33, pp. 1877–1901.\nCitation: Braga, V. Decentralized autonomous society through large language models’ based agents: a pathway \nto empower small communities. Journal of Engineering Science 2023, 30 ( 3), pp. 99- 120. \nhttps://doi.org/10.52326/jes.utm.2023.30(3).07.\nPublisher’s Note: JES stays neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations. \nC\nopyright:© 2023 by the authors. Submitted for possible open access publication under the terms \nand conditions of the Creative Commons Attribution (CC BY) license  \n(https://creativecommons.org/licenses/by/4.0/). \nSubmission of manuscripts:  jes@meridian.utm.md \n",
  "topic": "Transformative learning",
  "concepts": [
    {
      "name": "Transformative learning",
      "score": 0.6108556985855103
    },
    {
      "name": "Computer science",
      "score": 0.6024999618530273
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.5316242575645447
    },
    {
      "name": "Autonomous agent",
      "score": 0.445644736289978
    },
    {
      "name": "Knowledge management",
      "score": 0.4274398982524872
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4256572425365448
    },
    {
      "name": "Data science",
      "score": 0.3533549904823303
    },
    {
      "name": "Sociology",
      "score": 0.2048119604587555
    },
    {
      "name": "Pedagogy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I177823932",
      "name": "Technical University of Moldova",
      "country": "MD"
    }
  ]
}