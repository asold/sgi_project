{
  "title": "Customized GPT-4V(ision) for radiographic diagnosis: can large language model detect supernumerary teeth?",
  "url": "https://openalex.org/W4410583412",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A4223952741",
      "name": "Enes Mustafa AŞAR",
      "affiliations": [
        "Selçuk University"
      ]
    },
    {
      "id": "https://openalex.org/A4291673319",
      "name": "İrem İpek",
      "affiliations": [
        "Fırat University"
      ]
    },
    {
      "id": null,
      "name": "Kübra Bi̇lge",
      "affiliations": [
        "Fırat University"
      ]
    },
    {
      "id": "https://openalex.org/A4223952741",
      "name": "Enes Mustafa AŞAR",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4291673319",
      "name": "İrem İpek",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Kübra Bi̇lge",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4367556998",
    "https://openalex.org/W3023997891",
    "https://openalex.org/W4324304837",
    "https://openalex.org/W4384824783",
    "https://openalex.org/W4392764290",
    "https://openalex.org/W3189621102",
    "https://openalex.org/W4281733456",
    "https://openalex.org/W3033972758",
    "https://openalex.org/W4283260031",
    "https://openalex.org/W4200220400",
    "https://openalex.org/W4391466322",
    "https://openalex.org/W4406544420",
    "https://openalex.org/W3102090163",
    "https://openalex.org/W2883574295",
    "https://openalex.org/W4387227525",
    "https://openalex.org/W4387662377",
    "https://openalex.org/W2999494042",
    "https://openalex.org/W4390794538",
    "https://openalex.org/W4395064238",
    "https://openalex.org/W4407133252",
    "https://openalex.org/W4407984824",
    "https://openalex.org/W4400663251",
    "https://openalex.org/W4392746026",
    "https://openalex.org/W4392621058",
    "https://openalex.org/W4388774693",
    "https://openalex.org/W4403538040",
    "https://openalex.org/W3195009539",
    "https://openalex.org/W3216339168",
    "https://openalex.org/W4295758812",
    "https://openalex.org/W4400456285",
    "https://openalex.org/W4390277067"
  ],
  "abstract": "These findings highlight the diagnostic potential of customized GPT models in dental radiology. Future research should focus on multicenter validation, seamless clinical integration, and cost-effectiveness to support real-world implementation.",
  "full_text": "Aşar et al. BMC Oral Health          (2025) 25:756  \nhttps://doi.org/10.1186/s12903-025-06163-3\nRESEARCH Open Access\n© The Author(s) 2025. Open Access This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 \nInternational License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if \nyou modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or \nparts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To \nview a copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/.\nBMC Oral Health\nCustomized GPT-4V(ision) for radiographic \ndiagnosis: can large language model detect \nsupernumerary teeth?\nEnes Mustafa Aşar1*  , İrem İpek2   and Kübra Bi̇lge3   \nAbstract \nBackground With the growing capabilities of language models like ChatGPT to process text and images, this study \nevaluated their accuracy in detecting supernumerary teeth on periapical radiographs. A customized GPT-4V model \n(CGPT-4V) was also developed to assess whether domain-specific training could improve diagnostic performance \ncompared to standard GPT-4V and GPT-4o models.\nMethods One hundred eighty periapical radiographs (90 with and 90 without supernumerary teeth) were evaluated \nusing GPT-4 V, GPT-4o, and a fine-tuned CGPT-4V model. Each image was assessed separately with the standardized \nprompt “Are there any supernumerary teeth in the radiograph above?” to avoid contextual bias. Three dental experts \nscored the responses using a three-point Likert scale for positive cases and a binary scale for negatives. Chi-square \ntests and ROC analysis were used to compare model performances (p < 0.05).\nResults Among the three models, CGPT-4 V exhibited the highest accuracy, detecting supernumerary teeth cor-\nrectly in 91% of cases, compared to 77% for GPT-4o and 63% for GPT-4V. The CGPT-4V model also demonstrated \na significantly lower false positive rate (16%) than GPT-4V (42%). A statistically significant difference was found \nbetween CGPT-4V and GPT-4o (p < 0.001), while no significant difference was observed between GPT-4V and CGPT-4V \nor between GPT-4V and GPT-4o. Additionally, CGPT-4V successfully identified multiple supernumerary teeth in radio-\ngraphs where present.\nConclusions These findings highlight the diagnostic potential of customized GPT models in dental radiology. Future \nresearch should focus on multicenter validation, seamless clinical integration, and cost-effectiveness to support real-\nworld implementation.\nKeywords Artificial intelligence, ChatGPT-4V, Supernumerary Teeth, Periapical Radiography\nBackground\nWith technological advancements, artificial intelligence \n(AI) models have become more active in various aspects \nof daily life. AI also has numerous applications in the \nhealthcare sector [1]. The use of AI is increasing, espe -\ncially in areas such as diagnosis, mortality and morbid -\nity risk assessment, outbreak prediction and surveillance, \nhealth policy development, and strategic planning [2].\nPublished in 2022 by OpenAI, ChatGPT (Chat Gen -\nerating Pre-Trained Transducer), a chat-based AI, has \nbeen widely used in many fields since then [3]. The use of \n*Correspondence:\nEnes Mustafa Aşar\nenesmustafasar@gmail.com\n1 Department of Pediatric Dentistry, Faculty of Dentistry, Selçuk University, \nKonya, Turkey\n2 Department of Pediatric Dentistry, Faculty of Dentistry, Firat University, \nElazig, Turkey\n3 Department of Restorative Dentistry, Faculty of Dentistry, Firat \nUniversity, Elazig, Turkey\nPage 2 of 14Aşar et al. BMC Oral Health          (2025) 25:756 \nthese language models in the health sector also increases \ndaily [4]. With the GPT-4V(ision) update, the ability \nto evaluate visual data has been added to ChatGPT, the \nchat-based AI [5]. With this update, new work on image \nanalysis, such as the analysis and interpretation of dental \nradiographs, has been opened up [6, 7]. The development \nof these AI-based technologies facilitates physicians in \nimage analysis and diagnosis, one of the main tasks of \nradiologists [8]. In medicine and dentistry, radiographic \nevaluations are vital for planning treatments and diagno -\nsis [9]. In addition, ChatGPT Plus users can create cus -\ntomizable GPT models for special uses.\nSupernumerary teeth are found most among incisors \nin the maxillary region. Since they are asymptomatic, \nthey are usually detected incidentally on radiographs \n[10]. These supernumerary teeth may cause complica -\ntions such as delayed eruption, root resorption of neigh -\nboring teeth, cyst formation, infections, and impairment \nof orthodontic movements during the mixed denti -\ntion period in children [11]. The asymptomatic nature \nof supernumerary teeth increases their potential to be \noverlooked. This may prevent possible treatment options \nand prevention of possible pathologies. Some studies \nhave explored using deep learning systems for detect -\ning supernumerary teeth [10, 12]. However, no stud -\nies have investigated the application of large language \nmodel-based AI systems, such as ChatGPT, to detect \nsupernumerary teeth. This study examines the capability \nof ChatGPT-based AI language models to detect super -\nnumerary teeth in periapical radiographs. Additionally, \nit evaluates the potential enhancement of interpretative \naccuracy in a customized GPT-4V-based model (CGPT-\n4V) for radiographic image analysis.\nMethods\nThis research was conducted with the approval of the \nSelcuk University Faculty of Dentistry Non-Invasive \nClinical Research Ethics Committee in Turkey (Decision \nNo:2024/68).\nThis study’s sample size was statistically determined \nbased on an effect size of 0.25, a significance level of 5% \n(α = 0.05), and a statistical power of 80% (1 − β = 0.80), \nyielding a test power of p = 0.870616. The analysis deter -\nmined that the minimum required sample size was 157 \nradiographs.\nThis study evaluated the success of different GPT \nmodels (GPT-4V, GPT-4o, and CGPT-4V) in detecting \nsupernumerary teeth in dental radiographs. The GPT \nPlus subscription allows the creation of customized GPT \nmodels, which can provide a more specific and consist -\nent response in the customized area. In this study, a \ncustomized GPT model was trained for the detection of \nsupernumerary teeth.\nCGPT‑4V Creation\nIn this study, a CGPT-4V model called ‘GPT Model for \nSupernumerary Tooth Detection’ was created. During \nthe training process, reference guides on the subject in \nliterature were sent to this model. The CGPT-4V model \nwas instructed to study, learn and analyze the guidelines \nsent. It was instructed to use these articles as references \nwhen generating responses to the questions asked. The \nCGPT-4V model was customized in terms of its ability to \ndetect and interpret supernumerary teeth, with the aim \nof obtaining more consistent responses about supernu -\nmerary teeth on dental radiographs. The customization \nwas carried out by three dentistry specialists, each with \nmore than three years of clinical and academic experi -\nence. They worked together to ensure that all images \nwere annotated consistently and accurately before being \nused in the model training. After the chat-based train -\ning, visual-based training of the CGPT-4V model was \nprovided using dental radiographs. Microsoft Designer \napplication (web version, accessed on a Windows 11 \noperating system) was used in this process. Dental radio -\ngraphs were opened with the Microsoft Designer appli -\ncation. Using the pencil tool on Microsoft Designer, the \nborders of all teeth on the radiograph were drawn. Dur -\ning drawing, non-supernumerary regular teeth were out -\nlined in green, and supernumerary teeth were outlined in \nred using a pencil tool. In addition, the names of all exist-\ning teeth were written on them using the application text \ntool. For supernumerary teeth, “supernumerary tooth” \ninformation was added as text. These annotations were \nperformed in consensus by the three experts to ensure \nstandardization and calibration. The distinction between \nnormal and supernumerary teeth was based on estab -\nlished clinical definitions, and all supernumerary teeth \nused in training were mesiodens located in the anterior \nmaxillary region. Similarly, all radiographs for customiza-\ntion were edited and sent to the CGPT-4V model. There \nwas a limit to uploading only 20 images to the system for \ntraining. Due to this limitation, 10 dental radiographs \ncontaining supernumerary teeth and 10 dental radio -\ngraphs without supernumerary teeth were sent to the sys-\ntem. While the dental radiographs were uploaded to the \nsystem, the relevant radiographs were described in the \nchat section. These explanations helped the CGPT-4V \nmodel to understand the red and green lines (Fig.  1). In \nthis way, 20 radiographs not used in the study were used \nto train the model on images. And AI was prevented from \ngiving a biased response by recognizing the same radio -\ngraph. During the training process, incorrect responses \ngenerated by the model were analyzed, and errors were \nPage 3 of 14\nAşar et al. BMC Oral Health          (2025) 25:756 \n \ncorrected through interactive feedback in the chat inter -\nface. The system’s configuration was optimized based on \nresponses to a set of test scenarios; however, these sce -\nnarios were not included in the final analysis. Due to the \nnature of the GPT Builder interface, traditional fine-tun -\ning parameters such as learning rate, number of epochs, \nor optimizer choice could not be defined. The customiza-\ntion was based on annotated image uploads and textual \nguidance through a chat interface.\nRadiographic dataset\nA total of 180 periapical radiographs were used in this \nstudy. The radiographs were divided into two groups:\n1. Radiographs containing supernumerary teeth (n=90): \nIn this group, the presence of supernumerary teeth \nwas confirmed by expert clinicians,\n2. Radiographs without supernumerary teeth (n=90): In \nthis group, the absence of supernumerary teeth was \nverified through expert evaluation.\nGPT models used in this study\nThe following GPT models were used in this study:\n1. GPT-4V Model: A multimodal AI model capable of \nprocessing both text and images (OpenAI, San Fran -\ncisco, USA, 2023 version).\n2. GPT-4o Model:An optimized version of GPT-4 with \nenhanced speed and efficiency, providing improved \nnatural language understanding and reasoning abili -\nties (OpenAI, San Francisco, USA, 2024 version). \n3. Customized GPT-4V-based Model: A fine-tuned ver -\nsion of GPT-4V specifically trained on dental radio -\nFig. 1 Labeled periapical radiograph: Supernumerary Tooth (Red) and Normal Teeth (Green)\nPage 4 of 14Aşar et al. BMC Oral Health          (2025) 25:756 \ngraphs to enhance the accuracy of supernumerary \ntooth detection (OpenAI, San Francisco, USA, 2024 \nversion, Fine-tuned in 2024). \nStandardization and preparation of radiographic prompts\nAll radiographs were fully anonymized before use, with \nno patient identifiers or metadata retained. Images \nwere retrieved from the institution’s secure PACS sys -\ntem and used solely for research. The AI models did \nnot store data, and memory functions were disabled to \nensure privacy.\nAll radiographs sent to the models in this study were \nstandardized in JPEG format and at consistent scales. \nAlthough no additional pixel-based standardization \nwas applied during image processing, all radiographs \nwere originally archived in 470 ×  620-pixel resolution at \n150 dpi in our institution’s Picture Archiving and Com -\nmunication System (PACS) and were used in that con -\nsistent format to ensure comparable diagnostic quality. \nThe radiographs included in the study were uploaded \nto the chat section as additional files.\" Are there any \nsupernumerary teeth in the radiograph above?\"was \nadded under the submitted radiographs. This question \nwas asked with the exact wording in all radiographs to \nensure standardization. Image selection was conducted \nby three dentistry specialists based on the presence or \nabsence of mesiodens and overall image quality. All \ndental radiographs were evaluated in a different chat \nsession to prevent contextual learning. This process \nwas systematically repeated for all 180 radiographs \nin three different GPT models: GPT-4V, GPT-4o, and \nCGPT-4V. Additionally, to prevent the GPT models \nfrom retaining previously asked images and responses, \nthe ‘Memory’ feature was disabled. By resetting the \nsession for each image and disabling memory storage, \npotential biases caused by model memory retention \nwere minimized, ensuring an independent evaluation of \neach radiograph.\nInclusion and exclusion criteria\nInclusion criteria:\nPeriapical radiographs of patients with or without \nmesiodens.\nRadiographs selected by three expert dentists based on \ndiagnostic clarity.\nImages showing clearly visible crowns and roots, and \nsufficient contrast, without motion or exposure artifacts.\nRadiographs acquired using digital intraoral sensors \nwith typical exposure ranges and consistent positioning \nprotocols.\nExclusion criteria:\nRadiographs with artifacts, distortions, or low resolu -\ntion affect diagnostic interpretation.\nCases with impacted or partially erupted teeth that \ncould obscure the identification of supernumerary \nteeth.\nRadiographs of patients with significant craniofacial \nanomalies or syndromes affecting dental development.\nEvaluating GPT responses\nResponses were evaluated by three expert dentists \n(E.M.A., İ.İ., K.B.), each with at least three years of clin -\nical experience in dentistry and routine involvement \nin radiographic interpretation. A Likert scale was used \nto assess response accuracy, and in cases of disagree -\nment, evaluations were discussed until a consensus was \nreached [13].\n• Radiographs containing supernumerary teeth were \nassessed using a three-point Likert scale. \nIf the response indicated that no supernumer -\nary tooth was present, it was considered incorrect \nand assigned a score of 0. (Incorrect response: Score \n0,Fig. 2).\nIf the response correctly identified the presence of a \nsupernumerary tooth but lacked specific localization \ndetails, it was considered partially correct and assigned \na score of 1. (Partially correct response: Score 1,Fig. 3 ).\nIf the response correctly identified the presence of a \nsupernumerary tooth and also provided detailed localiza -\ntion and positioning within the radiograph, it was consid-\nered fully correct and assigned a score of 2. (Fully correct \nresponse: Score 2,Fig. 4).\n• Radiographs without supernumerary teeth were \nassessed using a binary Likert scale to evaluate diag -\nnostic accuracy.\nIf the response incorrectly indicated the presence of a \nsupernumerary tooth, it was categorized as a false posi -\ntive and assigned a score of 0. (False Positive-Incorrect \nresponse: Score 0,Fig. 5).\nIf the response correctly identified the absence of a \nsupernumerary tooth, it was categorized as a true nega -\ntive and assigned a score of 1. (True Negative-Correct \nresponse: Score 1, Fig. 6).\nStatistical analysis\nThe data obtained from the study were analyzed \nusing SPSS 23.0 (Statistical Package for the Social Sci -\nences, Version 23). The chi-square test was used for the \nPage 5 of 14\nAşar et al. BMC Oral Health          (2025) 25:756 \n \nevaluation of categorical data, with a significance level \nset at 0.05. In addition, diagnostic performance metrics, \nincluding sensitivity, specificity, and area under the ROC \ncurve (AUC), were calculated for each model. ROC curve \nanalysis was performed to evaluate the models’overall \ndiscriminative ability.\nResults\nBased on the methodology outlined above, the following \nsection presents the findings from the evaluation of the \nthree GPT models.\nFrequency distribution of responses for radiographs \nwith supernumerary teeth\nTable 1 summarizes the distribution of response types \nacross the three GPT models. When combining par -\ntially and fully correct responses, the overall accuracy \nrates were 63% for GPT-4V, 77% for GPT-4o, and 91% for \nCGPT-4V. Among the models, CGPT-4V exhibited the \nhighest rate of fully correct answers and the lowest num -\nber of incorrect classifications, indicating a more con -\nsistent diagnostic performance. While GPT-4V showed \nthe weakest accuracy, GPT-4o displayed moderate per -\nformance with a relatively high number of fully correct \nresponses.\nFrequency distribution of responses for radiographs \nwithout supernumerary teeth\nIn radiographs without supernumerary teeth, GPT-4V, \nGPT-4o, and CGPT-4V incorrectly identified the pres -\nence of supernumerary teeth in 42%, 16%, and 16% of \ncases, respectively. Both GPT-4o and CGPT-4V correctly \nrecognized the absence of supernumerary teeth in 84% of \ncases. Compared to GPT-4V, the other models exhibited \ngreater accuracy in analyzing radiographs without super -\nnumerary teeth. All frequency values are presented in \nTable 1.\nThe analysis of GPT model responses to radiographs \nwith supernumerary teeth revealed a statistically sig -\nnificant difference between CGPT-4V and GPT-4o (p < \n0.001). This statistically significant difference indicates \nthat CGPT-4V may offer more consistent diagnostic \nsupport in clinical practice compared to GPT-4o, par -\nticularly in detecting supernumerary teeth with greater \nFig. 2 Example of an incorrect response by CGPT-4V in supernumerary tooth detection \nPage 6 of 14Aşar et al. BMC Oral Health          (2025) 25:756 \nreliability. No significant difference was detected between \nGPT-4V and CGPT-4V (p = 0.099) or between GPT-4V \nand GPT-4o (p = 0.175). The superior performance of the \nCGPT-4V model in detecting supernumerary teeth com -\npared to GPT-4o was statistically significant.\nThe analysis of all GPT model’s responses to radio -\ngraphs without supernumerary teeth showed no statis -\ntically significant differences between the groups. All \nstatistical p values   are shown in Table 2.\nThe performance of all three GPT models in detecting \nsupernumerary teeth was further evaluated by ROC anal-\nysis. Table  3 and Fig.  7 show that the CGPT-4V model \noutperformed the other two models. CGPT-4V showed \nthe highest sensitivity (0.91) and successfully detected \nsupernumerary teeth. Its high specificity (0.84) showed \nthat it could avoid false positive detection in most neg -\native cases. Finally, the AUC value for CGPT-4V was \n0.878, indicating a successful discriminative power of \nthe model. The GPT-4o model showed a good diagnostic \nperformance, achieving 0.77 sensitivity and 0.84 specific -\nity with an AUC of 0.806. However, its slightly lower sen-\nsitivity compared to CGPT-4V suggests it missed more \npositive cases. The GPT-4V model performed poor -\nest among the three models with a sensitivity of 0.63, \nspecificity of 0.58, and AUC of 0.606. According to these \nresults, although GPT-4V has basic visual interpreta -\ntion capability, it showed poor optimization in terms of \nreliable use. All these findings show that customization \nimproves the GPT model’s performance and reduces \nfalse positive and false negative detections.\nDiscussion\nThis study aimed to evaluate whether domain-specific \nfine-tuning can improve the diagnostic accuracy in \ndetecting supernumerary teeth on periapical radio -\ngraphs of GPT-based models in detecting supernu -\nmerary teeth in periapical radiographs. The results \nshowed that the performance of the CGPT-4V model \nsignificantly improved compared to the general-pur -\npose GPT-4o model, supporting the potential role of \ncustomized AI models in dental diagnostic applica -\ntions. However, no significant difference was found \nbetween CGPT-4V and GPT-4V, indicating that the \nbenefits of fine-tuning may vary depending on the \nFig. 3  Example of a partially correct response by CGPT-4V in supernumerary tooth detection \nPage 7 of 14\nAşar et al. BMC Oral Health          (2025) 25:756 \n \navailable capacity of the base model. GPT-4o is a versa -\ntile model that supports text, visual, and audio inputs. \nGPT-4o was developed after GPT-4V with a completely \nnew architecture to produce faster and more practical \nresponses. CGPT-4V is a tweaked version of GPT-4V \nfor specific tasks such as supernumerary tooth detec -\ntion. The GPT-4V model first powered visual analysis. \nAlthough this model runs slower than GPT-4o, it can \nbe more stable and reliable regarding visual interpre -\ntation. Therefore, GPT-4o may have underperformed \nGPT-4V and CGPT-4V in visually oriented tasks. Addi -\ntionally, the limited training dataset used in our study \nmay not have fully revealed the potential effects of fine-\ntuning in CGPT-4V, which may be why CGPT-4V and \nGPT-4V exhibited similar performance.\nAlthough all radiographs used in this study contained \nonly mesiodens-type supernumerary teeth, the question \nwas deliberately phrased in a broader context to evaluate \nthe AI models’general understanding of supernumerary \nteeth. Therefore, all radiographs were presented with \nthe standardized question: ‘ Are there any supernumer -\nary teeth in the radiograph above?’ While mesiodens are \nalways classified as supernumerary teeth, not all super -\nnumerary teeth are mesiodens. This wording was chosen \nto assess whether the models could correctly interpret \nthe term ‘supernumerary’ and still identify mesiodens \naccurately. The results indicate that despite the general -\nized phrasing of the question, the models were able to \nrecognize and correctly classify mesiodens within the \nresponses.\nThis study utilized periapical radiographs due to the \nlimited assessment capabilities of GPT-based AI models \nobserved in previous studies involving panoramic radio -\ngraphs [7]. The presence of deciduous teeth in panoramic \nradiographic images during the mixed dentition period \nand permanent tooth germs under the deciduous teeth \nmay lead to the perception or misinterpretation of these \nFig. 4  Example of a fully correct response by CGPT-4V in supernumerary tooth detection\nPage 8 of 14Aşar et al. BMC Oral Health          (2025) 25:756 \nteeth as supernumerary. This situation has influenced the \nuse of dental periapical radiographs in this study.\nThe radiographs for this study were retrieved from \nthe PACS of the Department of Pediatric Dentistry at \nSelçuk University Faculty of Dentistry. Since GPT mod -\nels have potential access to open-access radiographs and \ncases on the web, there was a risk that previously learned \nimages could introduce bias into the evaluation process. \nTo eliminate this possibility, no radiographs from open-\naccess sources were used. To protect confidential data, \nall radiographs remained private and were neither stored \nnor learned by the AI assistant. The memory feature was \ndisabled to prevent any retention or recall of previously \nprocessed images, ensuring that each evaluation was con-\nducted independently. Thus, the radiograms in this study \nwere not previously detected by AI, so a more objective \nevaluation was made.\nComparison with previous studies\nAI is frequently used in dentistry, especially in oral and \nmaxillofacial radiology [14]. AI methods, such as deep \nlearning and Convolutional neural networks, are used \nin image classification, perception, and segmentation \n[15]. In one study, a neural network-based AI method \nwas evaluated to support the diagnosis of osteoporo -\nsis in panoramic radiographs, assisting dentists in early \nFig. 5  False positive detection of a supernumerary tooth by GPT-4V \nPage 9 of 14\nAşar et al. BMC Oral Health          (2025) 25:756 \n \ndiagnosis [16]. AI has also been used to evaluate various \nperiapical pathologies on computed tomography, periapi-\ncal radiographs, and panoramic radiographs [17–19]. The \nmost important point in AI analyses is that they facilitate \nthe diagnosis of cysts and tumors, where early diagnosis \nand treatment are very valuable [14, 20].\nThere are a limited number of studies on the use of \nCGPT. Gorelik et al. [21] used the CGPT model to man -\nage pancreatic cystic lesions and reported successful \nresults. Zhao et al. [22] demonstrated the superior accu -\nracy and explanatory capacity of the CGPT model in \nthe Chinese Nursing Licensing Examination Kiyomiya \net  al. [23] trained the CGPT model with drug package \ninserts and demonstrated its benefits for consumers and \npatients. Our study is the first study conducted to detect \nsupernumerary teeth with the CGPT-4V model. The \nresults of our study were like previous studies in the lit -\nerature in favor of the superiority of the CGPT model. \nHowever, using limited visual data during training may \nhave limited the model’s success. Further studies to \nincrease the success of CGPT models and the efficiency \nof diagnosis in the health field will be vital, especially in \ncases where early diagnosis is important.\nChat-based AI to analyze and interpret visual data has \npaved the way for new studies in many areas, including \nradiographic and pathological examinations in medicine \nand dentistry. In light of these advancements, a limited \nnumber of studies have investigated ChatGPT’s ability \nFig. 6  True negative detection of a supernumerary tooth by GPT-4o \nPage 10 of 14Aşar et al. BMC Oral Health          (2025) 25:756 \nto generate diagnoses based on radiological findings by \nprocessing visual radiographs within the system [7, 20]. \nevaluated the diagnostic accuracy of the GPT-4V model \nusing 52 radiographic images. They reported that when \nimages were presented without any contextual clues, \nGPT-4V demonstrated lower success rates. Wu et  al. \n[24] employed images from diverse cases across multiple \ndomains for multimodal medical diagnosis. According to \nthis and similar studies, while GPT-4V can differentiate \nmedical imaging modalities and anatomical structures, \nit still has difficulties in accurately pinpointing specific \nlocations within radiological images [24–26]. Hirosawa \net al. [27] found that incorporating visual data improved \ndiagnostic accuracy; however, GPT-4V remains lim -\nited in performing comprehensive visual analysis. Noda \net al. [28] demonstrated that although visual-based ques -\ntions resulted in higher accuracy rates than text-based \nones, the overall success was still quite restricted. Sen -\nkaiahliyan et  al. [29] explored various medical imaging \nmodalities, including clinical photographs and electro -\ncardiograms, using GPT-4V. Although the model could \ndescribe the images, it was insufficient for accurate diag -\nnosis and clinical decision-making. Similarly, Huppertz \net  al. [30] reported that GPT-4V is not yet capable of \nreliably interpreting radiological images. Unlike previous \nstudies utilizing GPT-4V, our study involved direct ques -\ntioning after radiographic images were uploaded into \nthe model. We did not evaluate the model’s performance \nwithout providing radiographs, as our primary goal was \nto determine its effectiveness in detecting supernumerary \nteeth. The more standardized approach and the focus on \nspecific questions may have contributed to the improved \naccuracy observed in our study. Another key differ -\nence between our study and previous works is the com -\nparative analysis of different GPT models. While prior \nresearch examined the capabilities of GPT-4V with and \nwithout image processing features, this study evaluated \nthe impact of model customization alongside standard \nGPT-4V and GPT-4o models. The results revealed that, \nalthough CGPT-4V achieved significantly better per -\nformance than GPT-4o, its diagnostic accuracy was not \nsignificantly different from that of GPT-4V. This suggests \nthat while customization can refine AI-driven diagnostic \nTable 1 Frequency distribution of responses for all radiographs\nFrequency distribution of responses for radiographs with \nsupernumerary teeth\nModel Responses Frequency Percent\nGPT-4V Incorrect: Score 0 33 37\nPartially correct: Score 1 24 26\nFully correct: Score 2 33 37\nTotal 90 100\nGPT-4o Incorrect: Score 0 21 23\nPartially correct: Score 1 20 22\nFully correct: Score 2 49 55\nTotal 90 100\nCGPT-4V Incorrect: Score 0 8 9\nPartially correct: Score 1 17 19\nFully correct: Score 2 65 72\nTotal 90 100\nFrequency Distribution of Responses for Radiographs Without Supernu-\nmerary Teeth\nModel Responses Frequency Percent\nGPT-4V Incorrect: Score 0 38 42\nCorrect: Score 1 52 58\nTotal 90 100\nGPT-4o Incorrect: Score 0 14 16\nCorrect: Score 1 76 84\nTotal 90 100\nCGPT-4V Incorrect: Score 0 14 16\nCorrect: Score 1 76 84\nTotal 90 100\nTable 2 Comparison of response classifications of all GPT \nmodels\n* p < 0.05\nGPT Models chi‑square (χ2) p‑value\nWith Super-\nnumerary \nTeeth\nGPT-4V vs GPT-4o 6.33 0.175\nGPT-4V vs CGPT-4V 7.80 0.099\nGPT-4o vs CGPT-4V 33.04 p < 0.001*\nWithout \nSupernumer-\nary Teeth\nGPT-4V vs GPT-4o 2.02 0.156\nGPT-4V vs CGPT-4V 2.32 0.127\nGPT-4o vs CGPT-4V 0.07 0.796\nTable 3 ROC-based performance comparison of GPT models in supernumerary-tooth detection\nTP/FP/TN/FN: True-Positive, False-Positive, True-Negative, False-Negative, AUC  Area under the ROC curve\nModel TP TN FP FN Specificity Sensitivity AUC \nGPT-4V 57 52 38 33 0.58 0.63 0.606\nGPT-4o 69 76 14 21 0.84 0.77 0.806\nCGPT-4V 82 76 14 8 0.84 0.91 0.878\nPage 11 of 14\nAşar et al. BMC Oral Health          (2025) 25:756 \n \nperformance, the extent of improvement may depend \non the pre-trained model’s baseline capabilities and the \nquality of fine-tuning data.\nSeveral studies have investigated the use of AI for \ndetecting mesiodens [31–33]. Ahn et al. [31] applied deep \nlearning techniques to mesiodens detection and found \nthat deep learning models demonstrated high accuracy in \nclassifying mesiodens on panoramic radiographs. Their \nresults indicated that AI could provide rapid and accessi -\nble diagnostic support for clinicians with limited experi -\nence. Jeon et al. [33] tested three different deep learning \nmodels on periapical radiographs and reported accuracy \nrates exceeding 97%. Similarly, Ha et al. [32] showed that \ndeep learning approaches could effectively detect mesi -\nodens on panoramic radiographs. Unlike deep learning, \nchatbot-based AI language models like ChatGPT do not \nrequire specialized training for specific tasks, and no \nprevious study has explored their potential in mesiodens \ndetection. This study evaluates the feasibility of using \nchatbot-based AI models as a faster and more accessi -\nble alternative to deep learning in mesiodens detection. \nDespite no prior training, GPT models detected mesi -\nodens with an accurate rate of up to 80%, which further \nimproved to 91% after a brief training period. Addition -\nally, in certain periapical radiographs containing two \nsupernumerary teeth, both were successfully identified \n(Fig. 3). Although the accuracy rates observed were high, \nthey did not reach the performance levels of deep learn -\ning models. This could be attributed to the fact that GPT \nmodels are not specifically trained for this task. How -\never, considering that even minimal training significantly \nimproved accuracy, these findings suggest that GPT \nmodels hold diagnostic potential and can be further cus -\ntomized for use in dental applications. Future collabora -\ntions with institutions could lead to the development of \ncustomized GPT models for assisting dental profession -\nals, and further research in this area will contribute to \nadvancing AI-driven diagnostic tools in dentistry.\nSilva et al. [7 ] explored the use of ChatGPT in diag -\nnosing radiolucent lesions and differentiating them \non panoramic radiographs. Their findings revealed \nthat ChatGPT-3.5 exhibited inconsistent and limited \nperformance. Additionally, a key takeaway from this \nstudy was the prompt-dependent nature of ChatGPT’s \nresponses [7 ]. Other studies have also shown that dif -\nferent amounts of text input can impact results, even \nwhen analyzing identical images [26, 34, 35]. Given \nthat our study aimed to compare GPT language mod -\nels, we ensured that text inputs remained standard -\nized and concise. To minimize variability in responses, \nno additional contextual information was provided, \nand only the predefined question was posed. Thus, \nFig. 7  ROC curves of GPT-4V, GPT-4o, and CGPT-4V models for supernumerary tooth detection\nPage 12 of 14Aşar et al. BMC Oral Health          (2025) 25:756 \nthe same standardized question was applied across all \nradiographs without alteration. In our study, in peri -\napical radiographs without supernumerary teeth, the \nfalse positive detection rate was slightly higher in GPT-\n4V (%42), GPT-4o (%16), and CGPT-4V (%16) models, \nalthough still relatively low. This observation suggests \nthat the positive phrasing of the question ‘ Are there any \nsupernumerary teeth in the radiograph above?’ may \nhave influenced the responses when applied to radio -\ngraphs without supernumerary teeth. Alternatively, a \nmore open-ended question, such as ‘What do you think \nabout the presence or absence of supernumerary teeth?’ \ncould have been used to explore potential differences in \nmodel responses. However, to ensure standardization \nacross all models and maintain consistent evaluation \nconditions, the original question format was retained. \nCompared to the study by Silva et al., our study yielded \nmore clinically successful results. This may be due to \nthe use of less complex periapical radiographs and the \nenhanced performance of GPT Plus language models \nover the GPT-3.5 model.\nClinical implications\nThe findings of this study show that domain-specific \nfine-tuning can improve the diagnostic performance of \nAI models such as CGPT-4V and make them promis -\ning supportive tools in dental radiology. The CGPT-4V \nmodel exhibited high accuracy in mesiodens detection, \ndemonstrating that when properly customized, AI-based \nlanguage models can offer early diagnosis support, espe -\ncially to clinicians with limited experience.\nThese models should be integrated into clinical practice \ncautiously, as they may give erroneous results and require \nphysician supervision. Especially in busy clinics, such \nmodels can help dentists use their time more efficiently \nby detecting possible anomalies in the initial evaluation \nof radiographs. For example, early detection of mesiodens \nin pediatric dentistry can directly influence treatment \nplanning and outcomes. Another important issue in the \nuse of these models is data privacy concerns. All patient \ndata submitted to the system must be anonymized to \ncomply with data privacy regulations such as the Gen -\neral Data Protection Regulation (GDPR) and the Health \nInsurance Portability and Accountability Act (HIPAA). \nFinally, multicenter validation studies will enable the reli-\nability of these models to be tested in different clinical \nsettings and with large patient groups. These efforts will \nincrease confidence in AI and contribute to the efficient \nand responsible use of these systems in dentistry.\nLimitations and future directions\nDue to platform limitations, the training process was \nrestricted to 20 images, which may affect the generaliz -\nability and performance of the model when applied to \nlarger or more complex datasets. Although the CGPT-4V \nmodel enhances diagnostic performance, the small data \npopulation may lead to over-similarity in study results. \nThe focus of this study on a single type of anomaly (mesi -\nodens) limits its applicability to a broader range of den -\ntal pathologies. Future work should collaborate with AI \ndevelopers such as OpenAI to develop more generaliz -\nable CGPT models trained on large-scale radiographic \nand pathological data, especially for critical conditions \nsuch as tumors, and validate them in multicenter clinical \ndatasets.\nDuring routine dental treatments, clinicians may over -\nlook asymptomatic anomalies due to a focus on specific \ntreatment areas. Integrating AI tools into diagnostic \nworkflows could aid in the early detection of such pathol-\nogies, and even simple GPT-based models, when prop -\nerly developed with clinical collaboration, can potentially \nplay a life-saving role.\nConclusions\nThis study demonstrated that GPT-based models can \ndetect supernumerary teeth on periapical radiographs \nwith varying levels of accuracy. Among the models \ntested, the customized CGPT-4V model achieved the \nhighest diagnostic performance, significantly outper -\nforming GPT-4o.\nThis work has demonstrated the effectiveness of cus -\ntomizing language models such as GPT for supernu -\nmerary teeth. However, future studies need to consider \nsome important points for broad clinical applications of \nthese results. First, multicenter studies with extensive \nand diversified data sets are needed to test the model’s \naccuracy in different patient groups and radiographic \nconditions. Secondly, such AI systems should not inter -\nrupt the physician’s decision-making process and should \nbe assessed to determine how they can be integrated \nwith existing clinical software. Finally, it should be inves -\ntigated whether these models offer benefits in terms of \ntime savings, increased accuracy, and economic support. \nInvestigating these three areas will pave the way for effec-\ntive integration of AI models out of experimental applica-\ntions and into daily clinical practice.\nAbbreviations\nAI  Artificial Intelligence\nChatGPT  Chat Generating Pre-Trained Transducer\nGPT-4o  GPT-4o Model\nGPT-4o  GPT-4V Model\nCGPT-4V  Customized GPT-4V-based Model\nAUC   Area Under the Curve\nPage 13 of 14\nAşar et al. BMC Oral Health          (2025) 25:756 \n \nROC  Receiver Operating Characteristic\nPACS  Picture Archiving and Communication System\nAcknowledgements\nNot applicable.\nClinical trial number\nNot applicable.\nAuthors’ contributions\nEMA conceptualized the manuscript. EMA and II carried out methodology; \nKB carried out data analysis, drafted and edited the manuscript. All authors \nsubsequently revised the drafts. All authors read and approved of the final \nmanuscript.\nFunding\nThe authors received no financial support for the research, and authorship of \nthis article.\nData availability\nDue to institutional data protection policies, the datasets generated and/or \nanalyzed during the current study are not publicly available but are available \nfrom the corresponding author upon reasonable request.\nDeclarations\nEthics approval and consent to participate\nAll procedures in this study were performed in accordance with the ethical \nstandards of the Selcuk University Faculty of Dentistry Non-Invasive Clinical \nResearch Ethics Committee in Turkey (Decision No:2024/68) and with the \n1964 Helsinki Declaration and its later amendments or comparable ethical \nstandards. \nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare no competing interests.\nReceived: 14 March 2025   Accepted: 12 May 2025\nReferences\n 1. Alhaidry HM, Fatani B, Alrayes JO, Almana AM, Alfhaed NK. ChatGPT in \ndentistry: a comprehensive review. Cureus. 2023;15(4):1–8.\n 2. Schwalbe N, Wahl B. Artificial intelligence and the future of global \nhealth. The Lancet. 2020;395(10236):1579–86.\n 3. OpenAI T: Chatgpt: Optimizing language models for dialogue. OpenAI. \nIn.; 2022.\n 4. Biswas SS. Role of chat gpt in public health. Ann Biomed Eng. \n2023;51(5):868–9.\n 5. GPT-4V(ision) System Card [https:// openai. com/ index/ \ngpt- 4v- system- card/]\n 6. Mago J, Sharma M. The potential usefulness of ChatGPT in oral and \nmaxillofacial radiology. Cureus. 2023;15(7):1–12.\n 7. Silva TP , Andrade-Bortoletto MFS, Ocampo TSC, Alencar-Palha C, \nBornstein MM, Oliveira-Santos C, Oliveira ML. Performance of a com-\nmercially available Generative Pre-trained Transformer (GPT) in describ -\ning radiolucent lesions in panoramic radiographs and establishing \ndifferential diagnoses. Clin Oral Investig. 2024;28(3):204.\n 8. Bilgir E, Bayrakdar İŞ, Çelik Ö, Orhan K, Akkoca F, Sağlam H, Odabaş A, \nAslan AF, Ozcetin C, Kıllı M. An artifıcial ıntelligence approach to auto -\nmatic tooth detection and numbering in panoramic radiographs. BMC \nMed Imaging. 2021;21:1–9.\n 9. Michael ESoRcmoBAPB-TRGBBCCRAF. The role of radiologist in the \nchanging world of healthcare: a White Paper of the European Society of \nRadiology (ESR). Insights Imaging. 2022;13(1):100.\n 10. Kuwada C, Ariji Y, Fukuda M, Kise Y, Fujita H, Katsumata A, Ariji E. Deep \nlearning systems for detecting and classifying the presence of impacted \nsupernumerary teeth in the maxillary incisor region on panoramic radio-\ngraphs. Oral Surg Oral Med Oral Pathol Oral Radiol. 2020;130(4):464–9.\n 11. Kim J, Hwang JJ, Jeong T, Cho B-H, Shin J. Deep learning-based identifica-\ntion of mesiodens using automatic maxillary anterior region estima-\ntion in panoramic radiography of children. Dentomaxillofac Radiol. \n2022;51(7):20210528.\n 12. Mine Y, Iwamoto Y, Okazaki S, Nakamura K, Takeda S, Peng TY, Mitsuhata \nC, Kakimoto N, Kozai K, Murayama T. Detecting the presence of supernu-\nmerary teeth during the early mixed dentition stage using deep learning \nalgorithms: A pilot study. Int J Paediatr Dent. 2022;32(5):678–85.\n 13. Freire Y, Santamaría Laorden A, Orejas Pérez J, Gómez Sánchez M, \nDíaz-Flores García V, Suárez A. ChatGPT performance in prosthodontics: \nAssessment of accuracy and repeatability in answer generation. J Pros-\nthet Dent. 2024;131(4):659. e651-659. e656.\n 14. Dang RR, Kadaikal B, Abbadi SE, Brar BR, Sethi A, Chigurupati R. The cur-\nrent landscape of artificial intelligence in oral and maxillofacial surgery–a \nnarrative review. Oral Maxillofac Surg. 2025;29(1):1–11.\n 15. Heo M-S, Kim J-E, Hwang J-J, Han S-S, Kim J-S, Yi W-J, Park I-W. Artificial \nintelligence in oral and maxillofacial radiology: what is currently possible? \nDentomaxillofac Radiol. 2021;50(3):20200375.\n 16. Lee J-S, Adhikari S, Liu L, Jeong H-G, Kim H, Yoon S-J. Osteoporosis \ndetection in panoramic radiographs using a deep convolutional neural \nnetwork-based computer-assisted diagnosis system: a preliminary study. \nDentomaxillofac Radiol. 2019;48(1):20170344.\n 17. Katsumata A. Deep learning and artificial intelligence in dental diagnostic \nimaging. Jpn Dent Sci Rev. 2023;59:329–33.\n 18. Lee H-S, Yang S, Han J-Y, Kang J-H, Kim J-E, Huh K-H, Yi W-J, Heo M-S, Lee \nS-S. Automatic detection and classification of nasopalatine duct cyst \nand periapical cyst on panoramic radiographs using deep convolu-\ntional neural networks. Oral Surg Oral Med Oral Pathol Oral Radiol. \n2024;138(1):184–95.\n 19. Orhan K, Bayrakdar I, Ezhov M, Kravtsov A, Özyürek T. Evaluation of \nartificial intelligence for detecting periapical pathosis on cone-beam \ncomputed tomography scans. Int Endod J. 2020;53(5):680–9.\n 20. Xu L, Qiu K, Li K, Ying G, Huang X, Zhu X. Automatic segmentation of \nameloblastoma on ct images using deep learning with limited data. BMC \nOral Health. 2024;24(1):55.\n 21. Gorelik Y, Ghersin I, Arraf T, Ben-Ishay O, Klein A, Khamaysi I. Using a cus-\ntomized GPT to provide guideline-based recommendations for manage-\nment of pancreatic cystic lesions. Endosc Int Open. 2024;12(04):E600–3.\n 22. Zhao Q, Wang H, Wang R, Cao H. Deriving insights from enhanced \naccuracy: Leveraging prompt engineering in custom GPT for assessing \nChinese Nursing Licensing Exam. Nurse Educ Pract. 2025;84: 104284.\n 23. Kiyomiya K, Aomori T, Ohtani H. Medication counseling for OTC drugs \nusing customized ChatGPT-4: Comparison with ChatGPT-3.5 and \nChatGPT-4o. Digit Health. 2025;11:20552076251323810.\n 24. Wu C, Lei J, Zheng Q, Zhao W, Lin W, Zhang X, Zhou X, Zhao Z, Zhang Y, \nWang Y: Can gpt-4v (ision) serve medical applications? case studies on \ngpt-4v for multimodal medical diagnosis. arXiv preprint arXiv:231009909 \n2023.\n 25. Liu Y, Li Y, Wang Z, Liang X, Liu L, Wang L, Cui L, Tu Z, Wang L, Zhou L. A \nsystematic evaluation of GPT-4V’s multimodal capability for chest X-ray \nimage analysis. Meta Radiol. 2024;2(4): 100099.\n 26. Yan Z, Zhang K, Zhou R, He L, Li X, Sun L: Multimodal chatgpt for \nmedical applications: an experimental study of gpt-4v. arXiv preprint \narXiv:231019061 2023.\n 27. Hirosawa T, Harada Y, Tokumasu K, Ito T, Suzuki T, Shimizu T. Evaluating \nChatGPT-4’s diagnostic accuracy: impact of visual data integration. JMIR \nMed Inform. 2024;12(1): e55627.\n 28. Noda M, Ueno T, Koshu R, Takaso Y, Shimada MD, Saito C, Sugimoto H, \nFushiki H, Ito M, Nomura A. Performance of GPT-4V in answering the \nJapanese otolaryngology board certification examination questions: \nevaluation study. JMIR Med Educ. 2024;10: e57054.\n 29. Senkaiahliyan S, Toma A, Ma J, Chan A-W, Ha A, An KR, Suresh H, Rubin \nB, Wang B: GPT-4V (ision) unsuitable for clinical care and education: a \nclinician-evaluated assessment. arXiv preprint arXiv:240312046 2023.\n 30. Huppertz MS, Siepmann R, Topp D, Nikoubashman O, Yüksel C, Kuhl \nCK, Truhn D, Nebelung S. Revolution or risk?—Assessing the potential \nPage 14 of 14Aşar et al. BMC Oral Health          (2025) 25:756 \nand challenges of GPT-4V in radiologic image interpretation. Eur Radiol. \n2025;35(3):1111–21.\n 31. Ahn Y, Hwang JJ, Jung Y-H, Jeong T, Shin J. Automated mesiodens classifi-\ncation system using deep learning on panoramic radiographs of children. \nDiagnostics. 2021;11(8):1477.\n 32. Ha E-G, Jeon KJ, Kim YH, Kim J-Y, Han S-S. Automatic detection of mesi-\nodens on panoramic radiographs using artificial intelligence. Sci Rep. \n2021;11(1):23061.\n 33. Jeon KJ, Ha E-G, Choi H, Lee C, Han S-S. Performance comparison of three \ndeep learning models for impacted mesiodens detection on periapical \nradiographs. Sci Rep. 2022;12(1):15402.\n 34. Suh PS, Shim WH, Suh CH, Heo H, Park CR, Eom HJ, Park KJ, Choe J, Kim \nPH, Park HJ. Comparing diagnostic accuracy of radiologists versus GPT-4V \nand Gemini Pro Vision using image inputs from diagnosis please cases. \nRadiology. 2024;312(1): e240273.\n 35. Waisberg E, Ong J, Masalkhi M, Zaman N, Sarker P , Lee AG, Tavakkoli A. \nGPT-4 and medical image analysis: strengths, weaknesses and future \ndirections. J Med Artif Intell. 2023;6:1–6.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub-\nlished maps and institutional affiliations.",
  "topic": "Medicine",
  "concepts": [
    {
      "name": "Medicine",
      "score": 0.9352062940597534
    },
    {
      "name": "Supernumerary",
      "score": 0.8550608158111572
    },
    {
      "name": "Oral and maxillofacial surgery",
      "score": 0.806157112121582
    },
    {
      "name": "Radiography",
      "score": 0.618547797203064
    },
    {
      "name": "Dentistry",
      "score": 0.6149587035179138
    },
    {
      "name": "Orthodontics",
      "score": 0.48946964740753174
    },
    {
      "name": "Supernumerary tooth",
      "score": 0.45570147037506104
    },
    {
      "name": "Radiology",
      "score": 0.39097896218299866
    },
    {
      "name": "Medical physics",
      "score": 0.3208271563053131
    }
  ]
}