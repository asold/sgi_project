{
    "title": "Process Modeling with Large Language Models",
    "url": "https://openalex.org/W4392781032",
    "year": 2024,
    "authors": [
        {
            "id": null,
            "name": "Kourani, Humam",
            "affiliations": [
                "RWTH Aachen University",
                "Fraunhofer Institute for Applied Information Technology"
            ]
        },
        {
            "id": "https://openalex.org/A4221847346",
            "name": "Berti, Alessandro",
            "affiliations": [
                "RWTH Aachen University",
                "Fraunhofer Institute for Applied Information Technology"
            ]
        },
        {
            "id": "https://openalex.org/A4287190568",
            "name": "Schuster, Daniel",
            "affiliations": [
                "RWTH Aachen University",
                "Fraunhofer Institute for Applied Information Technology"
            ]
        },
        {
            "id": "https://openalex.org/A4221537950",
            "name": "van der Aalst, Wil M. P.",
            "affiliations": [
                "Fraunhofer Institute for Applied Information Technology",
                "RWTH Aachen University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4319877694",
        "https://openalex.org/W4390704391",
        "https://openalex.org/W4379507314",
        "https://openalex.org/W4309623083",
        "https://openalex.org/W4390041933",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W207431025",
        "https://openalex.org/W4390694561",
        "https://openalex.org/W3089448520",
        "https://openalex.org/W4386321037",
        "https://openalex.org/W4387469928",
        "https://openalex.org/W4386315383",
        "https://openalex.org/W2620170772",
        "https://openalex.org/W3187134297",
        "https://openalex.org/W4387819628",
        "https://openalex.org/W4306955967",
        "https://openalex.org/W4230145224",
        "https://openalex.org/W4390189053",
        "https://openalex.org/W4386321380",
        "https://openalex.org/W25364003",
        "https://openalex.org/W4378473736",
        "https://openalex.org/W4308244910"
    ],
    "abstract": null,
    "full_text": "Process Modeling With Large Language Models\nHumam Kourani1,2 , Alessandro Berti1,2 , Daniel Schuster1,2 , and Wil M. P.\nvan der Aalst1,2\n1 Fraunhofer Institute for Applied Information Technology FIT, Sankt Augustin,\nGermany\n2 RWTH Aachen University, Aachen, Germany\n{humam.kourani, alessandro.berti, daniel.schuster,\nwil.van.der.aalst}@fit.fraunhofer.de\nAbstract. In the realm of Business Process Management (BPM), pro-\ncess modeling plays a crucial role in translating complex process dy-\nnamics into comprehensible visual representations, facilitating the un-\nderstanding, analysis, improvement, and automation of organizational\nprocesses. Traditional process modeling methods often require extensive\nexpertise and can be time-consuming. This paper explores the integra-\ntion of Large Language Models (LLMs) into process modeling to enhance\nthe accessibility of process modeling, offering a more intuitive entry point\nfor non-experts while augmenting the efficiency of experts. We propose a\nframework that leverages LLMs for the automated generation and itera-\ntive refinement of process models starting from textual descriptions. Our\nframework involves innovative prompting strategies for effective LLM\nutilization, along with a secure model generation protocol and an error-\nhandling mechanism. Moreover, we instantiate a concrete system extend-\ning our framework. This system provides robust quality guarantees on\nthe models generated and supports exporting them in standard model-\ning notations, such as the Business Process Modeling Notation (BPMN)\nand Petri nets. Preliminary results demonstrate the framework’s ability\nto streamline process modeling tasks, underscoring the transformative\npotential of generative AI in the BPM field.\nKeywords: Process Modeling· Business Process Management· Gener-\native AI· Large Language Models\n1 Introduction\nProcess modeling is an essential aspect of Business Process Management (BPM),\nserving as a comprehensive toolkit for understanding, documenting, analyzing,\nand improving complex business operations. Business process modeling covers\nseveral formats – from textual representations to visual diagrams and executable\nmodels – thus facilitating a multifaceted approach to capturing organizational\nprocesses.\nBusiness process modeling encompasses several key perspectives, each fo-\ncusing on different process aspects. Traditionally, these perspectives include the\narXiv:2403.07541v2  [cs.SE]  8 Apr 2024\n2 H. Kourani et al.\ncontrol-flow perspective, which outlines the flow of activities and their dependen-\ncies; thedata perspective, focusing on how data is generated, manipulated, and\nconsumed throughout the process; theresource perspective, detailing the human\nand system resources involved in the process execution; and theoperational per-\nspective, which describes the operational rules and execution semantics. In this\npaper, we focus on enhancing the control-flow perspective of process modeling\nas the control-flow establishes the basic structure upon which the data, resource,\nand operational perspectives are built.\nBusiness process modeling traditionally involves extensive manual effort and\ndeep knowledge of complex process modeling languages like BPMN (Business\nProcess Model and Notation) [28] or Petri nets [25]. Additionally, process mod-\nels often necessitate ongoing updates to reflect process changes. These challenges\ncreate significant barriers to entry for users without expertise in modeling lan-\nguages, underscoring the need for new, streamlined process modeling method-\nologies.\nThe advent of Large Language Models (LLMs) such as GPT-4 [22] and Gem-\nini [8] introduces a promising solution for enhancing the efficiency and accessibil-\nity of process modeling. Trained on diverse and extensive datasets, these LLMs\nshow advanced capabilities in performing different tasks, ranging from coherent\nand contextually relevant text generation to solving complex problem-solving\nqueries and generating executable code [18,26,30]. Their ability to understand\nandprocesscomplextextualinformationinnaturallanguagemakesLLMspartic-\nularly well-suited for process modeling and other tasks that require generating\nand refining structured outputs directly from textual descriptions. Therefore,\nleveraging LLMs in process modeling heralds a transformative shift, potentially\nreducing the dependence on manual effort and specialized knowledge.\nOur paper introduces a novel framework that utilizes the power of LLMs to\nautomate the generation of process models. It incorporates advanced techniques\nin prompt engineering, error handling, and code generation to transform textual\nprocess descriptions into process models illustrating the described processes.\nAdditionally, our framework features an interactive feedback loop, allowing for\nrefining the generated models based on the user’s feedback. To demonstrate the\nfeasibility and practical application of our framework, we implement a concrete\nsystemthatinstantiatesit.ThissystemleveragesthePartiallyOrderedWorkflow\nLanguage (POWL) [16] for the intermediate process representation, providing\nrobust guarantees on the quality of the generated models. The generated POWL\nmodels can then be viewed and exported in standard modeling notations such\nas BPMN and Petri nets. We integrate the implemented system with state-of-\nthe-art LLMs, showing the framework’s ability to streamline process modeling\nand underscoring the potential of generative AI in revolutionizing BPM.\nThe remainder of this paper is structured as follows. In Section 2, we discuss\nrelated work. Section 3 outlines our LLM-based process modeling framework.\nSection 4 evaluates the integration of our framework with state-of-the-art LLMs.\nIn Section 5, we discuss the limitations of our framework and propose ideas for\nfuture work. Finally, Section 6 concludes the paper.\nProcess Modeling With Large Language Models 3\n2 Related Work\nAn overview of various approaches for extracting process information from text\nis provided in [1]. While [6] leverages Natural Language Processing (NLP) and\ntext mining techniques to derive process models from text, [11] combines NLP\nwith computational linguistics techniques to generate BPMN models. In [23],\nthe authors employ NLP techniques to extract structured relationship represen-\ntations, termedfact types, from text, and the derived fact types are subsequently\ntransformed into BPMN components. The BPMN Sketch Miner [13] leverages\nprocess mining [24] to generate BPMN models starting from text in adomain-\nspecific language. Commercial vendors are integrating AI into process modeling,\ne.g., Process Talks (https://processtalks.com) provides an AI-powered sys-\ntem for creating process models starting from textual descriptions.\nThe integration of LLMs in BPM has been explored recently. Several studies\n[4,27] delve into the potential applications and challenges of employing LLMs for\nBPM tasks. In [21], limitations of using GPT-4 in conceptual modeling are dis-\ncussed. LLMs are evaluated on various process mining tasks in [3]. The proposed\napproach in [5] employs BERT [7] for the classification and analysis of process\nexecution logs, aiming to improve process monitoring and anomaly detection.\nIn [14], the authors explore the novel concept of conversational modeling with\nLLMs,proposingamethodforgeneratingprocessmodelsthroughdialogue-based\ninteractions. The paper [12] demonstrates the capability of LLMs to translate\ntextual descriptions into procedural and declarative process model constraints.\nFinally, [10] investigate the broader implications of LLMs in conceptual model-\ning, suggesting potential applications beyond traditional BPM tasks.\n3 LLM-Based Process Modeling Framework\nIn this section, we detail our framework that leverages the power of LLMs for\ngeneratingprocessmodelsstartingfromprocessdescriptionsinnaturallanguage.\n3.1 Framework Overview\nFigure 1 provides a schematic overview of our proposed framework. First, users\ninput a textual description of a process in natural language. Upon receiving the\ntextual description, we incorporate additional information to craft a compre-\nhensive prompt (the employed prompt engineering techniques are detailed in\nSection 3.3). This prompt is designed to guide the LLM to generate executable\ncode that can be used for the generation of process models (the selection of the\nmodeling language used for process representation is discussed in Section 3.2).\nThe code generation step leverages a set of functions we designed to facilitate\nthe creation of process models. After the prompt is generated, it is dispatched to\nthe LLM. Note that the framework is independent of the selected LLM; it can be\nintegrated with any advanced LLM that offers a large context window and code\ngeneration capabilities. After receiving the LLM’s response, we extract the code\n4 H. Kourani et al.\nFig.1: LLM-based process modeling framework.\nsnipped from the response and try to execute it (cf. Section 3.4). In instances\nwhere the code extraction or execution encounters errors, we employ an error-\nhandling mechanism that involves sending a refined prompt back to the LLM,\nexploiting LLMs’ self-refinement capabilities to fix the error (cf. Section 3.5).\nUpon successful code execution and process model generation, users can view or\nexport the model using established process modeling notations, such as BPMN\nand Petri nets. Moreover, the framework incorporates an interactive feedback\nloop. Users can provide feedback on the generated model, which is subsequently\nintegrated into the model. This feature enables the continuous optimization and\nrefinement of the generated process model.\n3.2 Process Representation\nTo better explain the different stages within our framework, we instantiate a\nconcrete system that utilizes the Partially Ordered Workflow Language (POWL)\n[16] for intermediate process representation. The foundational principles of our\nframework allow for the integration with other modeling languages tailored to\nthe requirements of process modeling. In this section, we motivate our choice of\nthe POWL language.\nOur aim is to generate process models in standard notations familiar to most\nprofessionals in the business process management field, such as BPMN and Petri\nnets. However, such modeling languages are complex with a high potential for\nquality issues. For example, it is possible to generate Petri nets or BPMN models\nwith dead parts that can never be reached. Therefore, the concept ofsoundness\nProcess Modeling With Large Language Models 5\nis introduced, and many approaches for the automated discovery of process mod-\nels use process modeling languages that guarantee soundness (e.g., [15,17]). Our\nsystem for process modeling employs POWL for intermediate process representa-\ntion, and the generated POWL models are then transformed into BPMN or Petri\nnets. A POWL model is a partially ordered graph extended with control-flow op-\nerators for modeling choice and loop structures. POWL represents a subclass of\nPetri nets that allow for the generation of hierarchical models where sub-models\nare combined to generate larger ones.\nWe have selected POWL as an intermediate process representation due to\nthe following reasons:\n– Soundness Guarantees: Unlike BPMN models or Petri nets, POWL inher-\nently ensures soundness.\n– Simplicity: POWL’s hierarchical nature enables a simplified model genera-\ntion by recursively generating models and combining them into larger ones.\nMoreover, POWL allows for combining sub-models as partial orders under\nthe assumption that tasks are inherently parallel unless explicitly defined\notherwise. This assumption of concurrent task execution mirrors the dynam-\nics of numerous real-life processes, and it facilitates the generation of process\nmodels as the order of concurrent elements does not need to be specified.\n– Expressive Power:WhilePOWLandprocesstrees[17]bothguaranteesound-\nness, POWL supports a broader range of process structures [16]. POWL al-\nlows for modeling intricate, non-hierarchical dependencies while maintaining\nthe quality guarantees of hierarchical process modeling languages.\n3.3 Prompt Engineering\nThis section discusses the prompting strategies we employ to effectively utilize\nLLMs for process modeling. We guide the LLM toward a precise comprehension\nof the provided process descriptions and the subsequent generation of the tar-\ngeted process models. These strategies aim to leverage the inherent capabilities\nof LLMs without the need for retraining or adjustments.\nThe following prompting strategies are employed within our process modeling\nframework:\n– Role Prompting:This strategy involves assigning a specific role to the LLM\nto guide its responses or behavior in a particular direction [29]. We imple-\nmented role prompting by instructing the LLM to act as an expert in process\nmodeling, familiar with common process constructs. The LLM is also tasked\nto assume the role of a process owner and to use its expertise in the context\nof the process to fill in any gaps in the provided process description.\n– Knowledge Injection: This strategy involves providing the LLM with new,\nspecific information or context that it may not have been exposed to during\nits initial training [19]. We provide comprehensive knowledge about POWL,\noffering detailed insights into its hierarchical structure and the semantics of\nthe different POWL components. Moreover, our framework leverages LLM\n6 H. Kourani et al.\nListing 1.1: Injecting the LLM with knowledge about POWL. Lines that extend\nbeyond the displayed text are abbreviated with “...” to keep it compact.\nUse the following knowledge about the POWL modeling language : A POWL ...\nProvide the Python code that recursively generates a POWL model . Save the ...\nAssume the class ModelGenerator is properly implemented and can be ...\nModelGenerator provides the functions described below :\n- activity ( label ) generates an activity . It takes 1 string argument , ...\n- xor (* args ) takes n >= 2 arguments , which are the submodels . Use it to ...\n- loop (do , redo ) takes 2 arguments , which are the do and redo parts . Use ...\n- partial_order ( dependencies ) takes 1 argument , which is a list of ...\nNote : for any powl model , you can call powl . copy () to create another ...\ncapabilities in generating executable code [26] by instructing the LLM to\ngenerate Python code that utilizes a predefined set of functions we designed\nfor the safe generation of POWL models. We provide a detailed explanation\nof these predefined methods and how they can be used to generate POWL\nmodels. Listing 1.1 illustrates the injected knowledge about POWL.\n– Few-Shots Learning:This method involves training the LLM on solving the\ntask by providing several example pairs of input and expected output [9].\nThis enhances the LLM’s ability to generate POWL models starting from\nprocess descriptions. For instance, Listing 1.2 shows one the examples we\nuse for training. This example shows how to generate a POWL model for\nthe bicycle manufacturing process from [2].\n– Negative Prompting:Negative prompting refers to instructing the LLM by\nspecifying what it should avoid in its response [20]. We implement negative\nprompting by instructing the LLM to avoid common errors that can occur\nusing our predefined methods for generating POWL models (e.g., trying\nto generate partial orders that violate irreflexivity). Moreover, we extend\nour few-shot demonstrations with common mistakes that should be avoided\nduring the construction of each process. For example, a common mistake for\nthe bicycle manufacturing process (cf. Listing 1.2) is to create a local choice\nbetween two activities “reject order” and “accept order” instead of modeling\na choice between the complete paths that are taken in each case.\n3.4 Model Generation and Refinement\nAfter receiving the LLM’s response, the Python code snippet is extracted from\nthe response, which might also include additional text (e.g., intermediate rea-\nsoning steps). If the code extraction is successful, then the extracted code is\nexecuted to generate the model. Executing code generated by an LLM involves\nmultiple considerations to handle security risks and invalid results. The follow-\ning strategies are implemented to ensure a safe environment for producing valid\nprocess models:\nProcess Modeling With Large Language Models 7\nListing 1.2: POWL model generation example used for few-shots learning, ex-\ntended with instructions to avoid common errors. Lines that extend beyond the\ndisplayed text are abbreviated with “...” to keep it compact.\nProcess description for example 1:\nA small company manufactures customized bicycles . Whenever the sales ...\nProcess model for example 1:\n‘‘‘ python\nfrom utils . model_generation import ModelGenerator\ngen = ModelGenerator ()\ncreate_process = gen . activity (’ Create process instance ’)\nreject_order = gen . activity (’ Reject order ’)\naccept_order = gen . activity (’ Accept order ’)\ninform = gen . activity (’ Inform storehouse and engineering department ’)\nprocess_part_list = gen . activity (’ Process part list ’)\ncheck_part = gen . activity (’ Check required quantity of the part ’)\nreserve = gen . activity (’ Reserve part ’)\nback_order = gen . activity (’Back - order part ’)\nprepare_assembly = gen . activity (’ Prepare bicycle assembly ’)\nassemble_bicycle = gen . activity (’ Assemble bicycle ’)\nship_bicycle = gen . activity (’ Ship bicycle ’)\nfinish_process = gen . activity (’ Finish process instance ’)\ncheck_reserve = gen . xor ( reserve , back_order )\nsingle_part = gen . partial_order ( dependencies =[( check_part , check_reserve )])\npart_loop = gen . loop (do= single_part , redo = None )\naccept_poset = gen . partial_order (\ndependencies =[( accept_order , inform ),\n( inform , process_part_list ),\n( inform , prepare_assembly ),\n( process_part_list , part_loop ),\n( part_loop , assemble_bicycle ),\n( prepare_assembly , assemble_bicycle ),\n( assemble_bicycle , ship_bicycle )])\nchoice_accept_reject = gen . xor ( accept_poset , reject_order )\nfinal_model = gen . partial_order (\ndependencies =[( create_process , choice_accept_reject ),\n( choice_accept_reject , finish_process )])\n‘‘‘\nCommon errors to avoid for example 1:\ncreating a local choice between ’reject_order ’ and ’accept_order ’ instead ...\n– In order to eliminate the risk of executing unsafe code, we restrict the LLM\nto use the predefined functions we designed for the generation of POWL\nmodels. We employ a strict process to verify that the code strictly complies\nwith the prompted coding guidelines, explicitly excluding the use of external\nlibraries or constructs that may pose security threats.\n– Wedefinevalidationrulestoensurethatthecodegeneratesmodelsthatalign\nwith the POWL specifications and requirements. For example, we validate\nthat all partial orders within the generated model adhere to the transitivity\nand irreflexivity requirements.\nOur framework converts the generated POWL models into Petri nets and\nBPMNmodels.Itoffersfunctionalitiesfordisplayingandexportingthemodelsin\n8 H. Kourani et al.\nthese established notations, which are widely acknowledged within the business\nprocess management community.\nRefinement Loop.The framework supports model refinement based on user feed-\nback. Users can provide comments on the generated model, and we prompt the\nLLM to update the model accordingly. These feedback prompts are sent along\nwith the full conversation history. This interactive approach ensures continual\nimprovement and customization of the models.\n3.5 Error Handling\nDespite their advanced coding capabilities, LLMs do not always generate error-\nfree code. We employ a robust error-handling mechanism tailored to mitigate\npotential inaccuracies and ensure the reliability of the generated process models.\nRecognizing the variability in the severity and implications of errors, we\ncategorize them into two distinct groups:\n– Critical Errors: This category covers errors that significantly disrupt the\nsystem’s functionality or compromise security. These encompass execution\nfailures, security risks, and major model validation violations. Given their\npotential impact, critical errors necessitate decisive action and cannot be\noverlooked.\n– Adjustable Errors: This category includes errors related to the model’s quali-\ntative aspects, such as the reuse of submodels within the same POWL model.\nAlthough they affect the model’s precision or quality, adjustable errors are\nconsidered less critical. They can be adjusted automatically, allowing for a\ndegree of flexibility in their resolution. For example, the error of reusing\nsubmodels within the same POWL model can be automatically resolved\nby creating copies of the reused models. However, such intervention is ap-\nproached with caution to prevent significant deviations from the behavior of\nthe intended process.\nOur framework incorporates an iterative error-handling loop, engaging the\nLLM in resolving identified errors. A new prompt that details the error and re-\nquests the LLM to address it, along with the conversation history, are submitted\nto the LLM. This iterative cycle facilitates dynamic correction, leveraging the\nLLM’s capabilities to refine and improve the generated code.\nFor critical errors, the system persistently seeks resolution via the LLM up\nto a predetermined number of allowed attempts. If the LLM fails to fix the\nerror after the allowed number of attempts, the system terminates the process\nand marks the model generation as unsuccessful. In cases of adjustable errors,\nthe system initially attempts correction through iterative engagement with the\nLLM. If the LLM fails to resolve adjustable errors after several attempts, then\nthe system automatically resolves these errors.\nProcess Modeling With Large Language Models 9\n4 Evaluation\nIn this section, we evaluate our LLM-based process modeling framework. We\nintegrate the implemented system with state-of-the-art LLMs to demonstrate\nthe feasibility and practical application of our framework.\nResearch Questions\nWe structure the evaluation around the following two research questions:\n– Q1: How does our framework perform when integrated with state-of-the-art\nLLMs?\n– Q2: How does our framework’s performance compare to other LLM-based\nprocess modeling systems?\nQ1 aims to investigate the capability of our framework to leverage the latest\nadvancements in LLM technology. We used two state-of-the-art LLMs: GPT-\n4 and Gemini. We focus on the framework’s ability to generate accurate and\noptimized process models based on initial descriptions and through the iterative\nfeedback loop. The assessment considers the quality of the generated models, the\nefficiency in handling errors, and the effectiveness of integrating user feedback.\nQ2 aims to compare our process modeling framework with other existing\napproaches. Notably, we found no LLM-based techniques that directly produce\nprocess models in the literature. The closest related work is the framework pro-\nposed in [12], which utilizes LLMs to transform process descriptions in natural\nlanguage intotextual abstractionsin a pre-defined notation that captures BPMN\nbase components. We use this framework to generate process models with GPT-\n4, and we manually transform the generated textual abstractions into BPMN\nmodels for comparative analysis. We refer to this approach as the TA (Textual\nAbstraction) framework throughout this paper.\nSetup\nWe implemented an integration of our system with GPT-4 as a web application\navailable athttps://promoai.streamlit.app/. As Gemini APIs are not avail-\nable in Germany, direct integration of our framework with Gemini is not feasible;\nwe used the web interface (https://gemini.google.com/app), and we manu-\nally transferred the prompts and responses between Gemini and our framework.\nThroughout our experiments, we set a threshold of two iterations for han-\ndling adjustable errors through interaction with the LLM before automatically\nresolving them, and we set a threshold of five iterations for critical errors before\nterminating the process and marking the model generation as unsuccessful. Each\nexperiment was repeated three times to account for the non-deterministic nature\nof LLM results.\nWe used two processes for our evaluation: the process described in [16] for\nhandling orders in an online shop and the hotel service process from the PET\n10 H. Kourani et al.\nTable 1: Process description and feedback comments for the online shop process.\nInitial Process\nDescription\nConsider a process for purchasing items from an online shop. The user starts an\norder by logging in to their account. Then, the user simultaneously selects the\nitems to purchase and sets a payment method. Afterward, the user either pays or\ncompletes an installment agreement. After selecting the items, the user chooses\nbetween multiple options for a free reward. Since the reward value depends on the\npurchase value, this step is done after selecting the items, but it is independent of\nthe payment activities. Finally, the items are delivered. The user has the right to\nreturn items for exchange. Every time items are returned, a new delivery is made.\n1st Feedback Model the item selection using an activity “Add Items” that can be repeated.\n2nd Feedback The user may skip the reward selection.\nTable 2: Process description and feedback comments for the hotel process.\nInitial Process\nDescription\nThe Evanstonian is an upscale independent hotel. When a guest calls room service\nat The Evanstonian, the room-service manager takes down the order. She then\nsubmits an order ticket to the kitchen to begin preparing the food. She also gives\nan order to the sommelier (i.e., the wine waiter) to fetch wine from the cellar and\nto prepare any other alcoholic beverages. Eighty percent of room-service orders\ninclude wine or some other alcoholic beverage. Finally, she assigns the order to\nthe waiter. While the kitchen and the sommelier are doing their tasks, the waiter\nreadies a cart ( i.e., puts a tablecloth on the cart and gathers silverware ). The\nwaiter is also responsible for nonalcoholic drinks. Once the food, wine, and cart\nare ready, the waiter delivers it to the guest’s room. After returning to the room-\nservice station, the waiter debits the guest’s account. The waiter may wait to do\nthe billing if he has another order to prepare or deliver.\n1st Feedback Include an activity “prepare food”.\n2nd Feedback The guest may or may not tip the waiter after receiving the order.\nTable 3: Number of error-handling iterations needed for the initial model gen-\neration and feedback integration for each process. We use * to indicate that\nadjustable errors were resolved automatically, not through interaction with the\nLLM. We use - to mark the cases where the model generation was unsuccessful\nafter five error-handling iterations.\nProcess Step GPT-4 Gemini\nrun 1 run 2 run 3run 1 run 2 run 3\nOnline Shop\nInitial Model 2 1 2 2* 2* 2*\n1st Feedback 0 0 0 0 - -\n2nd Feedback 0 0 0 - - -\nHotel\nInitial Model 2 2* 1 5* - 3*\n1st Feedback 0 2* 0 2* - 2*\n2nd Feedback 0 2* 0 - - 2*\ndata set [2]. The process descriptions and feedback comments we used are re-\nported in Table 1 for the online shop process and in Table 2 for the hotel service\nprocess. Note that we incorporated the feedback comments into the process de-\nscription when applying the TA approach.\nIn Table 3, we report the number of error-handling iterations needed for\nthe initial model generation and feedback integration for each process. We show\nthe final models generated in the first run by both our framework and the TA\nframework: Figure 2 for the online shop process and Figure 3 for the hotel\nProcess Modeling With Large Language Models 11\n(a) BPMN generated by GPT-4 using our system.\n(b) BPMN generated by Gemini using our system.\n(c) BPMN corresponding to the textual abstraction generated by GPT-4 using TA.\nFig.2: BPMN models generated for the order handling process in the first run.\nAlthough the models generated using our system show some deviations from the\noriginal process description, the model generated by GPT-4 correctly captures\ncomplex non-hierarchical dependencies. Unlike the models generated using our\nsystem, TA led to an unsound model that is dead after the choice between paying\nand completing an installment agreement.\n(a) BPMN generated by GPT-4 using our system.\n(b) BPMN generated by Gemini using our system.\n(c) BPMN corresponding to the textual abstraction generated by GPT-4 using TA.\nFig.3: BPMN models generated for the hotel process in the first run. The model\ngeneratedbyGPT-4usingoursystemprovidesahighdegreeofconformancewith\nthe process description, significantly surpassing the model generated by Gemini.\nThe model generated using TA is unsound as the end event is not reachable after\nthe second instance of “Readies Cart”.\nprocess. All generated models, along with an example detailing the complete\nsequence of prompts and responses exchanged between our system and GPT-\n4 until generating the final model, are available underhttps://github.com/\nhumam-kourani/LLM-Process-Modeling .\n12 H. Kourani et al.\nAddressing Q1\nGPT-4 demonstrated strong performance in generating process models for both\nprocesses. GPT-4 managed to deliver the initial models by the second error-\nhandling iteration at the latest in all cases. Notably, the errors encountered\nduring the generation of the model, which were classified as adjustable errors,\nwere successfully resolved by GPT-4 in five cases. Feedback integration was\nnotably efficient, with all feedback being accurately incorporated without any\nadditional iterations for error handling in all three runs.\nThe model shown in Figure 3a provides a high degree of conformance with\nthe process description of the hotel process and the two employed feedback\ncomments, however, some parts of the model can still be improved for better\nconformance. In the second run for the online shop process, GPT-4 was able to\ndiscover an optimal model that fully conforms with the reference model from\n[16], showcasing its robust understanding and modeling capabilities. This pro-\ncess contains complex non-hierarchical dependencies between selecting the items,\nsetting a payment method, the reward selection, and the payment choice. While\nconventional hierarchical process modeling languages, such as process trees, are\nunable to capture such complex dependencies, POWL empowers our framework\nwith the capability to model these complex structures. The other models dis-\ncovered by GPT-4 show some deviations from the original process. As LLMs\ncontinue to evolve, with ongoing advancements and enhancements, we expect\nfuture models to offer more consistency in the outcomes.\nIn contrast to GPT-4, Gemini’s performance was significantly weaker. The\nquality of the models generated by Gemini is markedly inferior to those produced\nby GPT-4. Gemini struggled to properly resolve adjustable errors, and, although\nthe initial model generation was successful in five of the six cases, this was due to\nthe internal automatic error correction, not a resolution through the interaction\nwith Gemini. Furthermore, Gemini failed to integrate the feedback comments\nin most cases, leading to the generation of critical errors. These errors included\nattempting to use non-existent functions, attempting to use external libraries,\nstopping the return of Python code, and ignoring instructions from the initial\nprompt. These issues highlight Gemini’s limitations in understanding the task\nrequirements and error resolution within our framework.\nAddressing Q2\nAlthough some behaviors of the models produced by our framework deviate from\nthe initial process descriptions, all produced models are sound and executable.\nThe TA framework, in contrast, produces unsound models. For example, the\nmodel in Figure 2c shows a choice between paying or completing an installment\nagreement through an exclusive choice gateway. The process is dead afterward;\nit requires both activities to be executed to proceed through the following par-\nallel gateway. The model in Figure 3c is also unsound as the end event is not\nreachable after the second instance of “Readies Cart”. This shows the advantages\nof employing POWL as an intermediate process representation in ensuring the\nsoundness of all models produced by our framework.\nProcess Modeling With Large Language Models 13\nEvaluation Summary\nThe comparative analysis between GPT-4 and Gemini demonstrates the supe-\nrior capabilities of GPT-4 within our LLM-based process modeling framework.\nGPT-4 not only excelled in generating high-quality process models with remark-\nable efficiency but also showcased its adeptness at effectively resolving errors\nand seamlessly integrating user feedback. Our framework’s comparison with the\nTA approach highlights its superiority, particularly in producing sound and exe-\ncutable models. This shows the robustness of our methodology and the strategic\nuse of POWL as an intermediate process representation.\n5 Limitations and Future Directions\nOur approach, while pioneering in leveraging LLMs for process modeling, has\nlimitations. In this section, we outline areas for improvement and propose ideas\nfor addressing them in future work.\nExpanding Process Perspectives.Our framework addresses the control-flow per-\nspective of process modeling, omitting the data, resource, and operational per-\nspectives, which are crucial for a comprehensive understanding of business pro-\ncesses. The inherent flexibility and understanding capabilities of LLMs present\na significant potential for extending our framework to incorporate additional\nprocess perspectives.\nExtended Evaluation and User Studies.Whileourevaluationdemonstratespromis-\ning results with the datasets and process descriptions employed, we acknowledge\nthe need for a broader investigation to better assess the generalizability of the\nframework. In our future work, we aim to extend the evaluation to encompass\na more diverse set of processes and domains. Moreover, we aim to conduct a\nuser study to evaluate the framework’s usability, efficiency, and learning curve\nfor both expert and non-expert users.\nDirect BPMN Generation.Theimplementedsysteminstantiatingourframework\nutilizes POWL for intermediate process representation. A possible direction for\nfuture research is the exploration of the direct generation of BPMN models\nwithout an intermediate process representation. This approach promises to offer\ngreater flexibility in representing intricate process structures and dynamics and\nallows for the enrichment of process models with context-rich annotations. How-\never, moving away from the structured guarantees provided by POWL necessi-\ntates the development of more advanced process model generation and validation\ntechniques.\nEnhanced Interactivity. We intend to enhance the model refinement loop to\nsupport more nuanced and interactive feedback mechanisms. For example, we\naim to empower users to not only provide textual feedback on generated process\nmodels but also to manually edit the generated models.\n14 H. Kourani et al.\n6 Conclusion\nThis paper introduces a novel framework that integrates LLMs with process\nmodeling. Our framework leverages the natural language understanding and text\ngeneration capabilities of LLMs to generate and refine process models starting\nfrom textual descriptions. Our framework employs innovative prompting strate-\ngies for LLM utilization, a robust model generation protocol considering safety\nand quality aspects, and a user feedback mechanism for model refinement. While\nour framework enhances the accessibility and efficiency of process modeling, we\nrecognize that manual effort remains crucial for validating generated models\nand providing effective feedback. Through preliminary results, we demonstrated\nthe practicality and effectiveness of our framework, paving the way for future\nresearch and development.\nReferences\n1. Patrizio Bellan, Mauro Dragoni, and Chiara Ghidini. A qualitative analysis of the\nstate of the art in process extraction from text. In Giuseppe Vizzari, Matteo Pal-\nmonari, and Andrea Orlandini, editors,Proceedings of the AIxIA 2020 Discussion\nPapers Workshop co-located with the the 19th International Conference of the Ital-\nian Association for Artificial Intelligence (AIxIA2020), Anywhere, November 27th,\n2020, volume 2776 ofCEUR Workshop Proceedings, pages 19–30. CEUR-WS.org,\n2020.\n2. Patrizio Bellan, Han van der Aa, Mauro Dragoni, Chiara Ghidini, and Si-\nmone Paolo Ponzetto. PET: an annotated dataset for process extraction from nat-\nural language text tasks. In Cristina Cabanillas, Niels Frederik Garmann-Johnsen,\nand Agnes Koschmider, editors,Business Process Management Workshops - BPM\n2022 International Workshops, Münster, Germany, September 11-16, 2022, Re-\nvised Selected Papers, volume 460 ofLecture Notes in Business Information Pro-\ncessing, pages 315–321. Springer, 2022.\n3. Alessandro Berti, Daniel Schuster, and Wil M. P. van der Aalst. Abstractions,\nscenarios, and prompt definitions for process mining with LLMs: A case study. In\nJochen De Weerdt and Luise Pufahl, editors,Business Process Management Work-\nshops - BPM 2023 International Workshops, Utrecht, The Netherlands, September\n11-15, 2023, Revised Selected Papers, volume 492 of Lecture Notes in Business\nInformation Processing, pages 427–439. Springer, 2023.\n4. Kiran Busch, Alexander Rochlitzer, Diana Sola, and Henrik Leopold. Just tell me:\nPrompt engineering in business process management. In Han van der Aa, Dominik\nBork, Henderik A. Proper, and Rainer Schmidt, editors, Enterprise, Business-\nProcess and Information Systems Modeling - 24th International Conference, BP-\nMDS 2023, and 28th International Conference, EMMSAD 2023, Zaragoza, Spain,\nJune 12-13, 2023, Proceedings, volume 479 ofLecture Notes in Business Informa-\ntion Processing, pages 3–11. Springer, 2023.\n5. Song Chen and Hai Liao. Bert-log: Anomaly detection for system logs based on\npre-trained language model.Appl. Artif. Intell., 36(1), 2022.\n6. JoãoCarlosdeA.R.Gonçalves,FláviaMariaSantoro,andFernandaAraújoBaião.\nLet me tell you a story - on how to build process models.J. Univers. Comput.\nSci., 17(2):276–295, 2011.\nProcess Modeling With Large Language Models 15\n7. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT:\npre-training of deep bidirectional transformers for language understanding. In Jill\nBurstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019\nConference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN,\nUSA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 4171–4186. Asso-\nciation for Computational Linguistics, 2019.\n8. Rohan Anil et al. Gemini: A family of highly capable multimodal models.CoRR,\nabs/2312.11805, 2023.\n9. Tom B. Brown et al. Language models are few-shot learners. In Hugo Larochelle,\nMarc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin,\neditors, Advances in Neural Information Processing Systems 33: Annual Confer-\nence on Neural Information Processing Systems 2020, NeurIPS 2020, December\n6-12, 2020, virtual, 2020.\n10. Hans-Georg Fill, Peter Fettke, and Julius Köpke. Conceptual modeling and large\nlanguage models: Impressions from first experiments with ChatGPT. Enterp.\nModel. Inf. Syst. Archit. Int. J. Concept. Model., 18:3, 2023.\n11. Fabian Friedrich, Jan Mendling, and Frank Puhlmann. Process model generation\nfrom natural language text. In Haralambos Mouratidis and Colette Rolland, edi-\ntors, Advanced Information Systems Engineering - 23rd International Conference,\nCAiSE 2011, London, UK, June 20-24, 2011. Proceedings, volume 6741 ofLecture\nNotes in Computer Science, pages 482–496. Springer, 2011.\n12. Michael Grohs, Luka Abb, Nourhan Elsayed, and Jana-Rebecca Rehse. Large\nlanguage models can accomplish business process management tasks. In Jochen De\nWeerdtandLuisePufahl,editors, Business Process Management Workshops - BPM\n2023 International Workshops, Utrecht, The Netherlands, September 11-15, 2023,\nRevised Selected Papers, volume 492 of Lecture Notes in Business Information\nProcessing, pages 453–465. Springer, 2023.\n13. Ana Ivanchikj, Souhaila Serbout, and Cesare Pautasso. From text to visual BPMN\nprocess models: design and evaluation. In Eugene Syriani, Houari A. Sahraoui,\nJuan de Lara, and Silvia Abrahão, editors,MoDELS ’20: ACM/IEEE 23rd Inter-\nnational Conference on Model Driven Engineering Languages and Systems, Virtual\nEvent, Canada, 18-23 October, 2020, pages 229–239. ACM, 2020.\n14. Nataliia Klievtsova, Janik-Vasily Benzin, Timotheus Kampik, Juergen Mangler,\nand Stefanie Rinderle-Ma. Conversational process modelling: State of the art,\napplications, and implications in practice. In Chiara Di Francescomarino, Andrea\nBurattin, Christian Janiesch, and Shazia W. Sadiq, editors,Business Process Man-\nagement Forum - BPM 2023 Forum, Utrecht, The Netherlands, September 11-15,\n2023, Proceedings, volume 490 ofLecture Notes in Business Information Process-\ning, pages 319–336. Springer, 2023.\n15. Humam Kourani, Daniel Schuster, and Wil M. P. van der Aalst. Scalable discovery\nof partially ordered workflow models with formal guarantees. In5th International\nConference on Process Mining, ICPM 2023, Rome, Italy, October 23-27, 2023,\npages 89–96. IEEE, 2023.\n16. Humam Kourani and Sebastiaan J. van Zelst. POWL: partially ordered workflow\nlanguage. In Chiara Di Francescomarino, Andrea Burattin, Christian Janiesch, and\nShazia Sadiq, editors,Business Process Management - 21st International Confer-\nence, BPM 2023, Utrecht, The Netherlands, September 11-15, 2023, Proceedings,\nvolume 14159 ofLecture Notes in Computer Science, pages 92–108. Springer, 2023.\n16 H. Kourani et al.\n17. Sander J. J. Leemans.Robust Process Mining with Guarantees - Process Discovery,\nConformance Checking and Enhancement, volume 440 ofLecture Notes in Business\nInformation Processing. Springer, 2022.\n18. Junyi Li, Tianyi Tang, Wayne Xin Zhao, and Ji-Rong Wen. Pretrained language\nmodel for text generation: A survey. In Zhi-Hua Zhou, editor,Proceedings of the\nThirtieth International Joint Conference on Artificial Intelligence, IJCAI-21,pages\n4492–4499. International Joint Conferences on Artificial Intelligence Organization,\n8 2021. Survey Track.\n19. Ariana Martino, Michael Iannelli, and Coleen Truong. Knowledge injection to\ncounter large language model (LLM) hallucination. In Catia Pesquita, Hala Skaf-\nMolli, Vasilis Efthymiou, Sabrina Kirrane, Axel Ngonga, Diego Collarana, Renato\nCerqueira, Mehwish Alam, Cássia Trojahn, and Sven Hertling, editors,The Se-\nmantic Web: ESWC 2023 Satellite Events - Hersonissos, Crete, Greece, May 28 -\nJune 1, 2023, Proceedings, volume 13998 ofLecture Notes in Computer Science,\npages 182–185. Springer, 2023.\n20. Daiki Miyake, Akihiro Iohara, Yu Saito, and Toshiyuki Tanaka. Negative-prompt\ninversion: Fast image inversion for editing with text-guided diffusion models.\nCoRR, abs/2305.16807, 2023.\n21. Fabian Muff and Hans-Georg Fill. Limitations of chatgpt in conceptual modeling:\nInsights from experiments in metamodeling, 2024.\n22. OpenAI. GPT-4 technical report.CoRR, abs/2303.08774, 2023.\n23. Sholiq Sholiq, Riyanarto Sarno, and Endang Siti Astuti. Generating BPMN dia-\ngram from textual requirements.J. King Saud Univ. Comput. Inf. Sci., 34(10 Part\nB):10079–10093, 2022.\n24. Wil M. P. van der Aalst.Process Mining - Discovery, Conformance and Enhance-\nment of Business Processes. Springer, 2011.\n25. Kees M. van Hee, Natalia Sidorova, and Jan Martijn E. M. van der Werf. Business\nprocessmodelingusingPetrinets. Trans. Petri Nets Other Model. Concurr.,7:116–\n161, 2013.\n26. Andy Vidan and Lars H. Fiedler. A composable just-in-time programming frame-\nwork with LLMs and FBP. InIEEE High Performance Extreme Computing Con-\nference, HPEC 2023, Boston, MA, USA, September 25-29, 2023, pages 1–8. IEEE,\n2023.\n27. Maxim Vidgof, Stefan Bachhofner, and Jan Mendling. Large language models\nfor business process management: Opportunities and challenges. In Chiara Di\nFrancescomarino, Andrea Burattin, Christian Janiesch, and Shazia W. Sadiq, ed-\nitors, Business Process Management Forum - BPM 2023 Forum, Utrecht, The\nNetherlands, September 11-15, 2023, Proceedings, volume 490 ofLecture Notes in\nBusiness Information Processing, pages 107–123. Springer, 2023.\n28. Mark von Rosing, Stephen White, Fred Cummins, and Henk de Man. Business\nprocess model and notation - BPMN. In Mark von Rosing, Henrik von Scheel, and\nAugust-Wilhelm Scheer, editors,The Complete Business Process Handbook: Body\nof Knowledge from Process Modeling to BPM, Volume I, pages 429–453. Morgan\nKaufmann/Elsevier, 2015.\n29. Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong Zhang,\nand Zhendong Mao. Expertprompting: Instructing large language models to be\ndistinguished experts. CoRR, abs/2305.14688, 2023.\n30. Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis,\nHarris Chan, and Jimmy Ba. Large language models are human-level prompt\nengineers. InThe Eleventh International Conference on Learning Representations,\nICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023."
}