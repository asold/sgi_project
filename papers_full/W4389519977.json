{
  "title": "RegaVAE: A Retrieval-Augmented Gaussian Mixture Variational Auto-Encoder for Language Modeling",
  "url": "https://openalex.org/W4389519977",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2578222276",
      "name": "Jingcheng Deng",
      "affiliations": [
        "Chinese Academy of Sciences",
        "University of Chinese Academy of Sciences",
        "Institute of Computing Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1974895339",
      "name": "Liang Pang",
      "affiliations": [
        "Institute of Computing Technology",
        "Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2106143704",
      "name": "Huawei Shen",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Institute of Computing Technology",
        "University of Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2106240991",
      "name": "Xueqi Cheng",
      "affiliations": [
        "University of Chinese Academy of Sciences",
        "Chinese Academy of Sciences",
        "Institute of Computing Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3005742798",
    "https://openalex.org/W3119469378",
    "https://openalex.org/W4287888031",
    "https://openalex.org/W4385571551",
    "https://openalex.org/W3007672467",
    "https://openalex.org/W4287891464",
    "https://openalex.org/W2963206148",
    "https://openalex.org/W2910135751",
    "https://openalex.org/W4226082499",
    "https://openalex.org/W3156789018",
    "https://openalex.org/W4288087322",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2963456134",
    "https://openalex.org/W3098708719",
    "https://openalex.org/W2963096510",
    "https://openalex.org/W124170475",
    "https://openalex.org/W4226069413",
    "https://openalex.org/W3198963570",
    "https://openalex.org/W3124980712",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W2924334974",
    "https://openalex.org/W2963600562",
    "https://openalex.org/W4287887100",
    "https://openalex.org/W1779483307",
    "https://openalex.org/W4318719006",
    "https://openalex.org/W3099700870",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W4389520749",
    "https://openalex.org/W3001279689",
    "https://openalex.org/W2998702515",
    "https://openalex.org/W2964669873",
    "https://openalex.org/W2556467266",
    "https://openalex.org/W4280606787"
  ],
  "abstract": "Retrieval-augmented language models show promise in addressing issues like outdated information and hallucinations in language models (LMs). However, current research faces two main problems: 1) determining what information to retrieve, and 2) effectively combining retrieved information during generation. We argue that valuable retrieved information should not only be related to the current source text but also consider the future target text, given the nature of LMs that model future tokens. Moreover, we propose that aggregation using latent variables derived from a compact latent space is more efficient than utilizing explicit raw text, which is limited by context length and susceptible to noise. Therefore, we introduce RegaVAE, a retrieval-augmented language model built upon the variational auto-encoder (VAE). It encodes the text corpus into a latent space, capturing current and future information from both source and target text. Additionally, we leverage the VAE to initialize the latent space and adopt the probabilistic form of the retrieval generation paradigm by expanding the Gaussian prior distribution into a Gaussian mixture distribution. Theoretical analysis provides an optimizable upper bound for RegaVAE. Experimental results on various datasets demonstrate significant improvements in text generation quality and hallucination removal.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 2500‚Äì2510\nDecember 6-10, 2023 ¬©2023 Association for Computational Linguistics\nRegaV AE: A Retrieval-Augmented Gaussian Mixture Variational\nAuto-Encoder for Language Modeling\nJingcheng Deng1,2, Liang Pang1,‚àó\n, Huawei Shen1,2, Xueqi Cheng1,2\n1Institute of Computing Technology, Chinese Academy of Sciences\n2 University of Chinese Academy of Sciences\n{dengjingcheng23s, pangliang, shenhuawei, cxq}@ict.ac.cn\nAbstract\nRetrieval-augmented language models show\npromise in addressing issues like outdated infor-\nmation and hallucinations in language models\n(LMs). However, current research faces two\nmain problems: 1) determining what informa-\ntion to retrieve, and 2) effectively combining\nretrieved information during generation. We ar-\ngue that valuable retrieved information should\nnot only be related to the current source text but\nalso consider the future target text, given the\nnature of LMs that model future tokens. More-\nover, we propose that aggregation using latent\nvariables derived from a compact latent space\nis more efficient than utilizing explicit raw text,\nwhich is limited by context length and suscep-\ntible to noise. Therefore, we introduce Re-\ngaV AE, a retrieval-augmented language model\nbuilt upon the variational auto-encoder (V AE).\nIt encodes the text corpus into a latent space,\ncapturing current and future information from\nboth source and target text. Additionally, we\nleverage the V AE to initialize the latent space\nand adopt the probabilistic form of the retrieval\ngeneration paradigm by expanding the Gaus-\nsian prior distribution into a Gaussian mixture\ndistribution. Theoretical analysis provides an\noptimizable upper bound for RegaV AE. Ex-\nperimental results on various datasets demon-\nstrate significant improvements in text gener-\nation quality and hallucination removal. Our\ncodes is released in the link1.\n1 Introduction\nLanguage models (LMs) have achieved state-of-\nthe-art performance on many NLP tasks (Zhu et al.,\n2021; Pang et al., 2021), which reveals that they\nstore a large amount of world knowledge as im-\nplicit parameters. While this development is ex-\nciting, LMs still suffer from some problems (Li\net al., 2022): 1) performance and model parame-\nter size follow a power law relationship (Kaplan\n*Corresponding Author\n1https://github.com/TrustedLLM/RegaVAE\nModel Future Info. in Aggreg-\nationQuery Key Value\nKNN-LM /enc-37 /enc-37 /enc-34Explicit\nRAG /enc-37 /enc-37 /enc-37Explicit\nREALM /enc-37 /enc-37 /enc-37Explicit\nSPALM /enc-37 /enc-37 /enc-34Explicit\nFiD /enc-37 /enc-37 /enc-37Implicit\nEMDR2 /enc-37 /enc-37 /enc-37Implicit\nEPR /enc-37 /enc-37 /enc-37Explicit\nRe2G /enc-37 /enc-37 /enc-37Implicit\nRETRO /enc-37 /enc-37 /enc-34Implicit\nRegaV AE /enc-34 /enc-34 /enc-34Implicit\nTable 1: Differences between RegaV AE and existing\nrepresentative models. Query, Key and Value respec-\ntively indicate whether future information is contained\nin query, key and value parts. Aggregation represents\nthe aggregation method of retrieved documents and\nsource text.\net al., 2020), which results in model parameters\nhaving to grow exponentially in order to gain more\nworld knowledge; 2) difficulty in adjusting for time-\nsensitive knowledge (Lewis et al., 2020); 3) may\nproduce \"fact hallucination\" problem (Guu et al.,\n2020; Marcus, 2020).\nRecently, the advent of retrieval-augmented text\ngeneration has emerged as a novel paradigm aimed\nat addressing these pertinent issues (Borgeaud et al.,\n2022; Li et al., 2022; Shi et al., 2023). Compared\nto generative-only models, this paradigm not only\nexplicitly exploits similar texts to generate more\nfluent sentences but also leverages expertise to gen-\nerate difficult responses. Nonetheless, we contend\nthat there are two primary challenges associated\nwith current retrieval-augmented language models.\nFirstly, not only current semantic information, but\nalso future semantic information need to be consid-\nered during retrieval. Previous studies (Khandelwal\net al., 2020; Guu et al., 2020; Lewis et al., 2020)\n2500\neither directly use the entire text as key and value\nparts at the same time, and then use cosine similar-\nity (Xu et al., 2023), TF-IDF and other indicators to\nsearch, which leads to the value part is only similar\nto the source text (query), and does not necessarily\nserve the best for generator. Another way is to di-\nvide a piece of text into two parts, where the first\npart and the second part are regarded as current in-\nformation and future information, such as RETRO\n(Borgeaud et al., 2022). However, RETRO adds\nfuture information to value part, but ignores the\nfuture information in query and key, which leads to\nthe fact that candidate documents with high simi-\nlarity do not necessarily contain future information\nthat can help the generator. Secondly, explicitly\naggregating retrieved documents and source texts\nis limited by the length of the model input and\nintroduces too much noise. Implicit aggregation\nis inefficient in irregular embedding spaces, and\nretrieval vectors are not generalizable.\nTo address the above challenges, we design Re-\ngaV AE, a Retrieval-augmented language model\nbased on gaussian mixture Variational Auto-\nEncoder. Unlike previous methods that directly\nencode unlabeled corpora (Karpukhin et al., 2020;\nLewis et al., 2020) or only adding future informa-\ntion to the value part (Borgeaud et al., 2022), as\nshown in Tab. 1, our model considers future in-\nformation through a latent space, given an x, we\ndecode it into a y using a conditional V AE, which\nensures that the latent variables contain information\nfrom both source and target data. In addition, in or-\nder to implicitly aggregate the retrieved documents\nand source texts, we also use the probabilistic form\nof the retrieval generation paradigm to theoretically\nextend the prior Gaussian distribution to a Gaussian\nmixture distribution. This allows the latent space\nto satisfy continuity and uniformity, and the latent\nvector after aggregating retrieved documents and\nsource text has better representation ability. Tab. 1\nsummarizes the differences between RegaV AE and\nexisting representative methods. Overall, our con-\ntributions are as follows:\n‚Ä¢ We propose a retrieval method that implic-\nitly combines current and future information,\nwhich introduces future information into the\nquery, key, and value parts at the same time,\nso that the higher the document similarity, the\nmore helpful it is for the generator.\n‚Ä¢ We integrate the V AE and retrieval generation\nprobabilistic framework to efficiently aggre-\ngate retrieval information into the generation\nprocess. Furthermore, we derive an upper\nbound on the optimization of this framework.\n‚Ä¢ Experiments have shown that RegaV AE is\ncompetitive in generating quality, generating\ndiversity, and eliminating hallucinations.\n2 Related Work\nWe classify related studies into two categories, ex-\nplicit aggregation and implicit aggregation, accord-\ning to the way the retrieved documents and source\ntext are aggregated. Explicit aggregation refers\nto concatenating retrieved documents directly into\nsource text to construct augmented input. Implicit\naggregation refers to adding retrieved documents to\nthe generator in the form of vectors or distributions.\nExplicit Aggregation Guu et al. (2020) proposed\nan end-to-end framework REALM that achieves\nstate-of-the-art performance on three open-domain\nQA. A representative work is RAG (Lewis et al.,\n2020), which first uses DPR (Karpukhin et al.,\n2020) to retrieve relevant documents, and then\nlinks relevant documents with the source text for\nsequence-to-sequence generation. Different from\nRAG and REALM, Rubin et al. (2022) proposed\nEPR, which is a method for retrieving prompts and\ncan improve the effect of prompts. Re2G (Glass\net al., 2022) is an enhanced version of RAG, which\nimproves the quality of retrieved documents by\nintegrating multiple retrieval methods. Explicit ag-\ngregation is simple and effective, but it suffers from\nthe limitation of the input length of the language\nmodel and cannot fully utilize the large number\nof retrieved documents. In addition, it is easy to\nintroduce noise, making the model performance un-\nstable. Unlike these methods, our model implicitly\naggregates retrieved documents into the generation\nprocess.\nImplicit Aggregation FiD (Izacard and Grave,\n2021) uses a DPR to retrieve candidate documents,\nand then splices and encodes the candidate docu-\nments with the source text, and inputs them into the\ngenerator in the form of vectors. EMDR2 (Sachan\net al., 2021) is similar to FiD, and it provides an\nend-to-end framework to train both the retriever\nand the generator. However, the query, key and\nvalue parts of FiD and EMDR2 do not contain fu-\nture information, which will cause the value part to\nbe similar to the query part and not conducive to\nthe generation of future tokens. RETRO (Borgeaud\n2501\nStep2: Build Retrieval Database\nStep1: Build a Compact SpaceSourceDataVAEEncoderz~ùëÅ(0,I) VAEDecoder\nùëß*~ùëÅ(0,1)\nùëß*,ùëß+~ùê∫(œÄ)\nùë∫‚à∂Corpus DataVAEEncoderKey:ùëß\"Value:\tùëß\"\nCorpusEmbeddings\nStep3:Aggregate Retrieved Information\nTarget Data\nTarget Data\nSourceDataVAEEncoderQuery\nùëß!\"ùëß#\"ùëß$\" ùëß!\" ùëß#\"\nùëß$\"\nùëß%\nVAEDecoder\nRetrieve‚Ñõ\nùí¢\nFigure 1: Architecture of RegaV AE. Based on the training data, we first train a V AE to construct a compact latent\nspace, which ensures that the latent variable zcontains both current and future information (see ¬ß 3.1). We then\nbuild a retrieval database and then aggregate the retrieved information into the generator (see ¬ß 3.2). V AE Encoder\nand Decoder parameters are the same in all steps. In order to ensure fairness, the Corpus data and the Source data in\nthe training set are the same. Grepresents the Gaussian mixture distribution, and œÄis the corresponding parameter.\net al., 2022) and KNN-LM (Khandelwal et al.,\n2020) set key and value parts as a piece of text,\nand added the continuation and the next token of\nthis text in value part, respectively. However, they\nonly calculate the similarity between the query and\nkey while ignoring future information in value part,\nresulting in high similarity documents containing\nfuture information that may not necessarily help\nthe generator. Our model sets both key and value\nparts as latent variables of a piece of text and its\nfuture continuation, and the query encoded by the\nV AE encoder also contains future information, so\nfuture information is also taken into account when\ncalculating the similarity between query and key,\nmaking up for the shortcomings of previous stud-\nies.\n3 Methodology\nMost text generation tasks can be formulated as\na mapping from a source text x to a target text\ny: y= f(x), while retrieval-augmented text gen-\neration can be further formulated as: y= f(x,r),\nwhere ris the relevant document retrieved based\non x. Specifically, this approach generally encom-\npasses the utilization of a retriever denoted as R\nand a generator denoted as G. The retriever Rob-\ntains rfrom the retrieval source Sby the retrieval\nmetric D and x. Then r and xare fed into Gto\nobtain ythrough a predefined integration method I.\nCommonly used retrieval indexesDinclude cosine\nsimilarity, TF-IDF, etc. This paradigm can also be\nexpressed in probabilistic form:\np(y|x) =\n‚àë\nr‚ààtop-k(p(¬∑|x))\np(y|x,r)p(r|x). (1)\nNext, the framework of RegaV AE is introduced,\nwhich consists of three steps. Firstly, in order to\nconstruct a compact space, we introduce the V AE\nstructure. Since transformers based on V AE all\nsuffer from the posterior collapse (Fu et al., 2019),\nwe follow a previous study (Hu et al., 2022) which\ncombines low-rank tensor products for latent vari-\nables and decoders (see ¬ß 3.1 and step 1 in Fig. 1).\nSecondly, to introduce retrieval information into\nthe latent space, we first introduce how the retrieval\nlibrary is constructed (see step 2 in Fig. 1), and\nthen replace the prior Gaussian distribution in the\noriginal V AE with a Gaussian mixture distribution\nto derive RegaV AE (see step 3 in Fig. 1). This\nallows for deep aggregation of retrieved and input\ndocuments and simultaneously incorporates future\ninformation into query, key and value parts, which\nhelps to generate more fluent sentences (see ¬ß 3.2)\n. Finally, to train RegaV AE, we derive an optimiz-\nable upper bound on the loss function for unclosed\nsolutions (see ¬ß 3.3). Fig. 1 shows the whole frame-\nwork diagram.\n2502\n3.1 Introduce Retrieval Information into\nLatent Space\nWe consider using the V AE structure to make the\nspace compact and continuous. As a kind of gen-\nerative model, V AE estimates the intractable data\ndistribution p(x) by deriving and maximizing its\nEvidence Lower BOund (ELBO) as:\nlog p(x) ‚â•LELBO =\nEqœï(z|x)[log pŒ∏(x|z)] ‚àíKL(qœï(z|x)||p(z)), (2)\nwhere z is the latent variable. p(z) and p(z|x) is\nthe prior and posterior distribution of z, respec-\ntively. qœï(z|x) and pŒ∏(x|z) represent Encoder and\nDecoder. Œ∏and œïare corresponding parameters.\nDue to the power of the decoder, transformers\nbased on V AE usually have the problem of posterior\ncollapse. According to Hu et al. (2022), we use\na low-rank tensor product in the l-th layer of the\nmodel:\nÀúv(l)\ni = (\nr‚àë\nj=1\nW(l,j)\nv v(l)\ni ) ‚ó¶(\nr‚àë\nj=1\nW(l,j)\nz zl), (3)\nwhere zl and v(l) represent latent variable and hid-\nden variable of l-th layer respectively. v(l)\ni repre-\nsents the hidden vector of thei-th token inl-th layer.\nris a hyper-parameter, and ‚ó¶means element-wise\nmultiplication. Wv and Wz are learnable param-\neters which are shared across all positions (i) but\nnot shared with l-th layer.\nIn order not to introduce additional data, we use\nthe training set as the data for training V AE. By\noptimizing ELBO, each sample is encoded into the\nlatent space and then restored by the decoder to\nobtain a compact latent space.\n3.2 Build the RegaV AE Model\nBuild Retrieval Database With a compact latent\nspace, we use an encoder to encode xand rfrom\nSinto the latent space. The latent variables of x\nand rare denoted by zx and zr, respectively. Then\nwe store zr as key and value parts in the retrieval\ndatabase. Given a query zx, we compute the inner\nproduct of it and zr to obtain the similarity.\nD(zx,zr\ni) = cos(zx,zr\ni), (4)\nwhere zr\ni ‚àºN(¬µi,œÉ2\ni) represents the latent vector\nof the i-th retrieved sample in S. ¬µi and œÉ2\ni are\nthe corresponding mean and standard deviation,\nrespectively. Since our framework is trained end-\nto-end, the parameters of the encoder change with\neach training step, resulting in changes in the latent\nspace. Considering that it is impractical to update\nthe retrieval database in real-time, and previous\nwork (Guu et al., 2020) has shown the practicality\nof updating the index intermittently during training,\nwe follow this approach and update the index of\nretrieval database every fixed number of training\nsteps.\nAggregate Retrieved Information Inspired by\nthe retrieval-generated text generation paradigm,\nwe assume y is influenced by latent variables zx\nand zr. To obtain the ELBO of RegaV AE, we first\nmodel log p(y) as:\nlog p(y) = log\n‚à´‚à´\np(y,zr,zx)dzrdzx\n‚â•\n‚à´‚à´\nlog p(y,zr,zx)dzrdzx\n=\n‚à´‚à´\nlog q(zr,zx|x)log p(y,zr,zx)\nlog q(zr,zx|x) dzrdzx\n= Eq(zr,zx|x) log[p(y,zr,zx)\nq(zr,zx|x) ].\n(5)\nFrom the first step, the Jensen inequality can\nbe used to transform to the second step, and then\nthe expression of the desired form can be obtained.\nAccording to Bayes formula:\np(y,zr,zx) =p(y|zr,zx)p(zr,zx). (6)\nSubstituting Eq. 6 into Eq. 5:\nEq(zr,zx|x) log[p(y,zr,zx)\nq(zr,zx|x) ]\n= Eq(zr,zx|x) log[p(y|zr,zx)p(zr,zx)\nq(zr,zx|x) ]\n= Eq(zr,zx|y)[log p(y|zr,zx)]\n‚àíKL(q(zr,zx|x)||p(zr,zx)),\n(7)\nwhere KL stands for calculating the KL divergence\nbetween two distributions. Eq. 7 is the ELBO of\nRegaV AE. At this point, Eq. 7 and Eq. 2 have the\nsame form, but the latent variable z is replaced\nby zx and zr. Since each zr\ni follows a Gaussian\ndistribution, we consider using a Gaussian mixture\ndistribution to combine zx and zr. So q(zr,zx|x)\ncan be expressed as:\nq(zr,zx|x) =w0q(zx|x) +\nn‚àë\ni=1\nwiq(zr\ni|x), (8)\nwhere nrepresents the number of retrieved docu-\nments.\nwi = softmax(D(zx,zr\ni)), (9)\n2503\nwhere ‚àën\ni=0 wi = 1makes q(zr,zx|x) satisfy the\nrequirement of Gaussian mixture distribution. So\nfar, we have obtained the theoretical framework for\nintroducing retrieval information in latent space.\n3.3 Training RegaV AE\nWe can optimize RegaV AE by optimizing Eq. 7. In\nthe KL divergence term of Eq. 7, the closed-form\nsolution cannot be obtained because the two distri-\nbutions are mixed Gaussian distributions. There-\nfore, we continue to use previous research (Dilok-\nthanakul et al., 2016), that is, to optimize its upper\nbound. First we assume two Gaussian mixture dis-\ntributions as:\np=\n‚àë n\ni=1\nœÄigi, ÀÜp=\n‚àë n\ni=1\nÀÜœÄiÀÜg. (10)\nThe KL divergence between them can be ex-\npressed as:\nKL(p||ÀÜp) =\n‚à´\n(\n‚àë\ni\nœÄigi) log\n‚àë\niœÄigi‚àë\ni ÀÜœÄiÀÜgi\n‚â§\n‚à´ ‚àë\ni\nœÄigilog œÄigi\nÀÜœÄiÀÜgi\n=\n‚àë\ni\nœÄilog œÄi\nÀÜœÄi\n+\n‚àë\ni\nœÄi\n‚à´\ngilog gi\nÀÜgi\n= KL(œÄ||ÀÜœÄ) +\n‚àë\ni\nœÄiKL(gi||ÀÜgi).\n(11)\nIn the variational distribution q(zr,zx|x), the\ntrainable parameter is only wi and q(zx|x). And\nthe prior distribution p(zr,zx) is defined as:\np(zr,zx) = ÀÜw0p(zx) +\n‚àë n\ni=1\nÀÜwip(zr\ni), (12)\nwhere zx ‚àºN(0,1) and zr\ni ‚àºN(0,1). So the\nupper bound for the KL term in Eq. 7 can become:\nKL(q(zr,zx|x)||p(zr,zx)) ‚â§\n‚àë n\ni=0\nKL(wi||ÀÜwi)\n+ KL(q(zx|x)||N(0,I)) + C,\n(13)\nwhere C is a constant that has nothing to do with\nmodel parameter updates. We do not update the\nretrieval library in real time, but regularly update it\naccording to the number of training steps. In this\nsetup, wi is constant, so Eq. 13 becomes:\nKL(q(zr,zx|x)||p(zr,zx))\n‚â§KL(q(zx|x)||N(0,1)) + C. (14)\nSubstituting Eq 14 into Eq 7, we can get the final\noptimized loss function:\nL= Eq(zr,zx|y)[log p(y|zr,zx)]\n‚àíKL(q(zx|x)||N(0,1)).\n(15)\nEq. 15 can be regarded as an optimizable upper\nbound of Eq. 8. When given a dataset, we first en-\ncode the source text to obtain a retrieval database.\nThe top-k documents are then retrieved for each x\nseparately. Then the corresponding latent variables\nzx and zr are aggregated in the form of Gaussian\nmixture distribution and then input into Gto ob-\ntain the output. Finally, we use Eq. 15 to train\nRegaV AE.\n4 Experiment\nThis section provides the experimental datasets,\nexperimental settings, and experimental results.\n4.1 Datasets\nFor experiments, we employ three datasets, namely\nYelp (Yang et al., 2017), Yahoo (He et al., 2019)\nand WritingPrompts (WP) (Fan et al., 2018). As\nin previous studies (Hu et al., 2022), due to the\nlimitation of computing resources, we adopt the\nmethodology established in previous research and\nsample 100,000 data instances from the training\nset of Yelp and Yahoo for model training. This\nconsistent approach ensures a fair and equitable\nbasis for comparison across the evaluated models.\n4.2 Metrics\nGeneration Quality In the context of the text\ngeneration task, we present the evaluation metrics\nof perplexity (PPL), Self-BLEU (Zhu et al., 2018),\nDist2 (Li et al., 2016), and Activation Units (AU)\n(Burda et al., 2016). For the WritingPrompts, in ad-\ndition to PPL, we also report the metrics of BLEU\n(Papineni et al., 2002), Rouge-1, Rouge-2, Rouge-\nL (Mithun et al., 2012), and BERTScore (Zhang\net al., 2020).\nHallucination We use SelfCheckGPT (Manakul\net al., 2023) to detect hallucinations produced by\nthe model. There are four indicators in total,\nnamely SBERT, SQA, Sa\nn and Sm\nn . The higher their\nvalue, the more likely the model is hallucinating.\n4.3 Experiment Settings\nWe have chosen two distinct categories of models\nas our baselines. The first category comprises trans-\nformers based on V AE, and the second category\nconsists of retrieval-generated models. These base-\nlines provide us with a comprehensive framework\nfor evaluating and contrasting different approaches.\n2504\nModel Yelp Yahoo CostPPL‚Üì Self-BLEU‚Üì Dist2‚Üë AU‚Üë PPL‚Üì Self-BLEU‚Üì Dist2‚Üë AU‚Üë\nGPT2 22.13 65.90 17.96 - 24.17 54.06 21.07 - -\nRetrieval-augmented Language Model\nKNN-LM 39.95 - - - 62.30 - - - 8\nFiD 14.08 42.26 24.45 - 14.71 42.84 26.49 - 66\nRETRO 16.53 46.65 23.23 - 13.27 38.64 28.83 - 44\nRAG 20.68 58.53 28.16 - 17.62 48.91 24.95 - 58\nTransformers based on VAE\nOptimus 22.79 - - - 23.11 - - - -\nEmbed 19.98 65.27 15.59 6 22.18 54.15 20.80 3 -\nMemory 19.95 63.90 16.91 11 22.03 54.59 21.87 18 -\nSoftmax 20.14 64.26 16.51 13 22.35 54.49 21.65 19 -\nADA V AE 15.49 49.80 - 32 14.23 - - 32 -\nDELLA 12.35 60.02 17.63 23 11.49 48.53 21.88 21 -\nRegaV AE 8.62 36.10 28.83 52 6.99 30.74 33.03 56 60\nTable 2: Results for the Yelp and Yahoo. For transformers based on V AE, results of Optimus are directly copied\nfrom the original paper with Œª = 0.5. The activation threshold of AU is 0.2. For retrieval-augmented language\nmodels, RETRO, FiD and RAG are reproduced by ourselves under the same parameter size. KNN-LM employs the\ntraining set data as the retrieval corpus. In addition, to ensure fairness, all retrieval sources are training sets. The\nCost column provides an indication of the temporal investment(h) required for training the respective model on an\nA40-48G GPU.\nTransformers based on V AEFor a comprehen-\nsive comparison, we choose Optimus (Li et al.,\n2020) and ADA V AE (Tu et al., 2022) as the base-\nline models, along with four distinct paradigms:\nEmbed (Li et al., 2020), Memory (Fang et al.,\n2021), Softmax (Wang and Wan, 2019) and\nDELLA (Hu et al., 2022). Optimus is a large-scale\nmodel based on V AE that utilizes a pre-trained\nBERT model as its encoder and a pre-trained GPT-\n2 model as its decoder. In order to ensure the fair-\nness of the evaluation, RegaV AE uses the same\npre-trained language model as Embed, Memory,\nSoftmax and DELLA. This selection facilitates a\nrigorous and unbiased comparative analysis across\nthese models.\nRetrieval-augmented Language Model Ac-\ncording to the division method of related work,\nwe select representative works from different cate-\ngories of retrieval-augmented language models as\nbaselines. Specifically, RAG, FiD, and RETRO rep-\nresent models with explicit aggregation, implicit\naggregation without future information, and im-\nplicit aggregation with only future information in\nvalue part, respectively.\nOur Model Consistent with prior research, we\nadopt the GPT2 model as the underlying backbone\nnetwork for our experimentation. The dimension of\nthe hidden variable is set to 32, and KL annealing\n(Fu et al., 2019) is implemented to mitigate the is-\nsue of KL term disappearance. The learning rate is\nfixed at 5√ó10‚àí5 to ensure stable training. Our train-\ning procedure entails an initial 10 epoch training\nphase on the original DELLA model to establish\na robust initial V AE space. Subsequently, we con-\nduct approximately fifteen epochs of training on\nthe RegaV AE model until it achieves convergence.\nTo make the training process more efficient, we\nprecomputed document embeddings for the train-\ning dataset and created a FAISS index (Johnson\net al., 2021) for fast similarity searches. We use the\nbert_score library 2 to calculate the BERTScore\nfor our models and baselines.\n4.4 Automatic Evaluation\nText Generation Tab. 2 presents the results at-\ntained by RegaV AE model on text generation\ndatasets. Compared to the three baseline mod-\nels for retrieval augmentation, our model achieves\nsubstantial improvements in all metrics, and per-\nforms particularly well in generating quality met-\nrics. The enhanced PPL, Self-BLEU, and Dist2\nscores demonstrate that latent variables, which con-\ntain both source and target information, combined\n2https://github.com/Tiiiger/bert_score\n2505\nModel PPL ‚Üì BLEU‚Üë R1‚Üë R2‚Üë RL‚Üë BERTScore‚Üë Self-BLEU‚Üì Dist2‚Üë\nGPT2 - 27.89 27.72 7.96 14.30 78.12 53.78 22.99\nEmbed - 39.67 36.17 7.96 15.78 81.64 64.55 14.31\nMemory - 40.79 36.13 8.04 16.16 81.68 67.56 12.90\nSoftmax - 41.04 36.14 8.12 16.30 81.75 67.02 13.08\nDELLA 2.16 41.39 35.46 8.78 17.20 81.77 56.28 20.91\nRegaV AE 1.18 43.83 32.21 9.62 30.57 84.31 52.70 23.28\nTable 3: Results for the WritingPrompts. R1, R2 and RL represent Rouge-1, Rouge-2 and Rouge-L, respectively.\nThe results for GPT2, EMbed, Memory and softmax are from the DELLA paper.\nModel SBERT‚Üì SQA‚Üì Sa\nn‚Üì Sm\nn ‚Üì\nFiD 8.27 37.99 4.96 6.31\nRETRO 7.94 39.84 4.89 5.78\nRAG 8.52 38.78 5.04 5.76\nDELLA 8.41 40.01 5.21 5.30\nRegaV AE 8.01 37.82 4.42 4.89\nTable 4: Hallucination evaluation results on the Yelp\ndataset.\nModel Flu. ‚Üë Coh.‚Üë Div.‚Üë Hal.‚Üë\nFiD 3.64 2.96 3.17 3.83\nRETRO 3.33 3.11 3.32 4.01\nRAG 3.15 2.73 3.25 3.99\nDELLA 3.67 3.31 3.15 3.90\nRegaV AE 3.78 3.21 3.47 4.11\nTable 5: Human evaluation results on the Yelp dataset.\nwith the extension to Gaussian mixture priors, ef-\nfectively enhances the fluency and diversity of the\ngenerated text. This empirical validation corrobo-\nrates the theoretical strength of our model.\nNotably, in comparison to the transformer-based\nV AE model, RegaV AE with retrieval demonstrates\nsuperior performance in terms of both generative\ndiversity and quality. This enhancement can be at-\ntributed to the utilization of a Gaussian mixture dis-\ntribution, which offers the ability to capture multi-\nmodal distributions more effectively than a single\nGaussian distribution. Leveraging the source data,\nRegaV AE retrieves auxiliary latent variables that\nfacilitate the generation of the target data, thereby\nyielding improved text generation outcomes. Fur-\nthermore, the significant improvement in the AU\nvalue indicates that the aggregation we employ pos-\nitively contributes to the generative process of de-\ncoder. This alleviates the problem of collapsing at\nthe rear of the model to a considerable extent.\nHallucination Evaluation We evaluate halluci-\nnations of RegaV AE on the Yelp dataset. Specif-\nically, we sample the text generated by the same\nlatent variable three times, and then feed the sam-\npling results into SelfCheckGPT to obtain evalu-\nation scores. The results are shown in the Tab. 4.\nFrom the experimental results, it can be seen that\nthe text generated by RegaV AE is the least halluci-\nnatory compared with other models.\n4.5 Human Evaluation\nIn addition to automated evaluation, we conducted\na human evaluation to assess and compare the per-\nformance of baseline models against our proposed\nmethod. Five professionals with expertise in the\ndomain were enlisted to participate in the manual\nevaluation process. Each evaluator was tasked with\nrating the attributes of fluency (Flu.), coherence\n(Coh.), diversity (Div.), and hallucination (Hal.) on\na scale ranging from 1 to 5. A rating of 1 denoted\nvery low performance, while a rating of 5 indicated\nvery high performance. A total of 50 test samples\nwere randomly selected and evaluated across dif-\nferent models. The final human evaluation result\nwas obtained by averaging the scores provided by\nthe evaluators.\nTab. 5 presents the outcomes of human evalu-\nation conducted on the Yelp dataset. RegaV AE\noutperforms the baseline models in almost all di-\nmensions, demonstrating superior performance in\ncomparison. To further establish the correlation\nbetween human and automated evaluation results,\nwe calculated the Pearson correlation coefficient\nand presented the corresponding values in Tab. 6.\nThe results obtained from human evaluation align\nclosely with those derived from partially automated\nevaluation metrics. For example, the correlation\nbetween the human evaluation metrics (Flu., Coh.)\nassociated with PPL and PPL itself is nearly identi-\ncal.\n2506\n5 10 25 50 100\nNumbel of neighbors\n7.0\n7.5\n8.0\n8.5\n9.0\n9.5PPL\nYelp\nYahoo\nWP\n1.2\n1.4\n1.6\n1.8\nFigure 2: Performance of RegaV AE on test sets as a\nfunction of the number of retrieved neighbors. The\nbrown broken line corresponds to the scale on the right.\nInputSource:OurDamselinDistress,uponseeingherknightinshiningarmortryandfailcountlesstimes,appreciatestheeffortbutdecidestojustgetthejobdoneherself.\nTarget:Everyonestoodatthedoorwithwideopeneyes.\"*CURSED''theymuttered,pointingupanddownthepathleadingintotheirassignedhalls.Whathappened?Hemadehiswaythroughbushesandforeststothehall.Hehadbeenwearinghisarmourproudlyforthiswholewalk...Infact,thelightmadehishairstandoutstarkly.Finally,hediscoveredthecurse.\"Istillfail,dearElizabeth\",hewalkedbackthroughthebushestothedoor.RetrievedTop-1Youareaminorcharacter/namelessminioninafictionalstory,duringabattlebetweengoodvsbad,youaccidentallykilledtheprotagonist/antagonist.\nWhathappensnext?‚Ä¶Hemovedthroughaseriesofbushesandsmalltreesbeforehappeninguponasitethathorrifiedhim.‚Ä¶Rickscrambledtohisfeetandbackthroughthebrushtohisdugout.‚Ä¶\nGeneratedText\nUnseenforthedecoderSeenforthedecoderSpani Spani+1\nWordsoverlapwithunseenfuture\nFigure 3: Generation examples of RegaV AE from test\nset of WritingPrompts. Green font and brown font rep-\nresent the future information of the retrieved document\nand the relevant text generated by RegaV AE, respec-\ntively.\n5 Analysis\nTo further analyze RegaV AE, we explore the im-\npact of the number of retrieved neighbors, different\nmodel structures on the model performance. We\nalso give a case to verify the model performance.\n5.1 Number of Retrieved Neighbors\nFig .2 depicts the performance trends in relation to\nthe number of retrieved neighbors. Notably, as the\nnumber of retrieved neighbors increases from 5 to\n100, we observed a reduction in PPL by 0.64 on\nthe Yelp dataset and 0.69 on the Yahoo dataset, and\nPPL on the WP dataset is reduced by 0.59. This\nupward trend proves that implicit aggregation meth-\nods can effectively filter noise compared to explicit\naggregation methods, and moreover, aggregations\nusing Gaussian mixture distributions are effective\nfor retrieving documents and source texts.\nCorp-value Flu. Coh. Div. Hal.\nPPL 940.02 860.07 400.51 260.68\nSelf-BLEU 510.37 190.76 660.23 350.57\nDist2 220.73 570.31 670.21 580.30\nTable 6: Correlation between human and automated\nevaluation results. The order in which the model results\nwere used to calculate the correlation coefficient is: FiD,\nRETRO, RAG, DELLA, and RegaV AE. The correlation\ncoefficients have been processed with absolute value\nand amplified by a factor of one hundred from their\noriginal values.\nModel PPL ‚Üì Self-BLEU‚Üì Dist2‚Üë\nOurs 8.62 36.10 28.83\nAggregation Method\nw/o V AE & R 17.95 53.24 16.46\nw/o V AE 20.13 62.48 17.04\nRetrieval Method\nbase+BM25 13.49 55.37 20.72\nbase+DPR 12.58 58.46 20.54\nTable 7: Results of ablation experiments on the Yelp\ndataset. w/o V AErepresents the removal of V AE space,\nand w/o V AE & Rrepresents the removal of V AE space\nand retrieval operations. base represents the RegaV AE\nthat removes the retrieval.\n5.2 Ablation Experiment\nTo evaluate the effectiveness of the model struc-\nture, we conducted ablation experiments involving\nretrieval and aggregation, as depicted in Tab. 7.\nWhen we excluded the V AE structure, there was a\nnotable decline in the performance of RegaV AE. In-\nterestingly, we observed that the model augmented\nwith retrieval performed even worse than the model\nwithout retrieval when the V AE structure was ab-\nsent. We speculate that the retrieved variables in\nthis particular scenario reside in a space that fails to\nmeet the requirements of uniformity and continuity.\nAs a result, the model struggled to generate valid\nsamples based on cosine similarity, introducing\nunwanted noise instead.\nCompared with other retrieval methods, it can\nbe seen that the performance of traditional retrieval\nmethods is obviously insufficient. This discrepancy\ncan be attributed to our approach incorporating\nfuture information into key, value, and query parts\nsimultaneously, thus taking future information into\naccount in both retrieval and generation phases,\nfurther validating our motivation.\n2507\n5.3 Case Study\nWe present a compelling example to examine the\nquality of RegaV AE-generated text and explore the\nintegration of retrieval information into the gener-\nated content, as illustrated in Fig. 3.\nThrough our observations, we have noted that\nthe text produced by RegaV AE demonstrates a re-\nmarkable ability to establish a coherent connection\nwith the source text while being vivid and specific.\nMoreover, despite encoding only the retrieved doc-\nument into the latent space and subsequently inte-\ngrating it into the generation process, it is evident\nthat RegaV AE-generated text effectively incorpo-\nrates future information from the retrieved docu-\nment.\n6 Conclusion\nIn this paper, we summarize two major challenges\nof existing retrieval-augmented language model\nmethods, and propose RegaV AE to address them.\nWe find that RegaV AE outperforms traditional re-\ntrieval generative models in terms of both gener-\native quality and reduce hallucinations. In addi-\ntion, ablation experiments and three analysis exper-\niments verify the correctness of the model motiva-\ntion. In future work, we will consider migrating\nRegaV AE to large language models.\nLimitations\nAt present, almost all large language models are\npre-trained on large-scale corpus, and due to the\nlimitation of computing resources, we cannot pre-\ntrain RegaV AE on large-scale corpus, which will\nlead to performance degradation.\nFurthermore, the model is not stable to train due\nto the posterior collapse problem. Even if we adopt\na low-rank tensor product, this problem still cannot\nbe completely solved.\nEthics Statement\nWe honor and support the EMNLP code of Ethics.\nThis paper mainly studies the use of retrieval gen-\neration to eliminate the illusion in the language\nmodel and make the generated text more fluent.\nOur method can introduce canonical text to make\nlanguage models more reliable. In addition, the\ndata sets used in this article are all open source and\ndo not involve any privacy or ethical issues.\nAcknowledgement\nThis work was supported by the National Key\nR&D Program of China (2022YFB3103700,\n2022YFB3103704), the National Natural Science\nFoundation of China (NSFC) under Grants No.\n62276248, and the Youth Innovation Promotion\nAssociation CAS under Grants No. 2023111.\nReferences\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,\nTrevor Cai, Eliza Rutherford, Katie Millican, George\nvan den Driessche, Jean-Baptiste Lespiau, Bogdan\nDamoc, Aidan Clark, Diego de Las Casas, Aurelia\nGuy, Jacob Menick, Roman Ring, Tom Hennigan,\nSaffron Huang, Loren Maggiore, Chris Jones, Albin\nCassirer, Andy Brock, Michela Paganini, Geoffrey\nIrving, Oriol Vinyals, Simon Osindero, Karen Si-\nmonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre.\n2022. Improving language models by retrieving from\ntrillions of tokens. In International Conference on\nMachine Learning, ICML 2022, 17-23 July 2022, Bal-\ntimore, Maryland, USA, volume 162 of Proceedings\nof Machine Learning Research , pages 2206‚Äì2240.\nPMLR.\nYuri Burda, Roger B. Grosse, and Ruslan Salakhutdinov.\n2016. Importance weighted autoencoders. In 4th In-\nternational Conference on Learning Representations,\nICLR 2016, San Juan, Puerto Rico, May 2-4, 2016,\nConference Track Proceedings.\nNat Dilokthanakul, Pedro A. M. Mediano, Marta Gar-\nnelo, Matthew C. H. Lee, Hugh Salimbeni, Kai\nArulkumaran, and Murray Shanahan. 2016. Deep\nunsupervised clustering with gaussian mixture varia-\ntional autoencoders. CoRR, abs/1611.02648.\nAngela Fan, Mike Lewis, and Yann N. Dauphin. 2018.\nHierarchical neural story generation. In Proceedings\nof the 56th Annual Meeting of the Association for\nComputational Linguistics, ACL 2018, Melbourne,\nAustralia, July 15-20, 2018, Volume 1: Long Papers,\npages 889‚Äì898. Association for Computational Lin-\nguistics.\nLe Fang, Tao Zeng, Chaochun Liu, Liefeng Bo, Wen\nDong, and Changyou Chen. 2021. Transformer-\nbased conditional variational autoencoder for\ncontrollable story generation. arXiv preprint\narXiv:2101.00828.\nHao Fu, Chunyuan Li, Xiaodong Liu, Jianfeng Gao,\nAsli Celikyilmaz, and Lawrence Carin. 2019. Cycli-\ncal annealing schedule: A simple approach to mit-\nigating KL vanishing. In Proceedings of the 2019\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, NAACL-HLT 2019, Min-\nneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long\nand Short Papers), pages 240‚Äì250. Association for\nComputational Linguistics.\n2508\nMichael R. Glass, Gaetano Rossiello, Md. Faisal Mah-\nbub Chowdhury, Ankita Naik, Pengshan Cai, and\nAlfio Gliozzo. 2022. Re2g: Retrieve, rerank, gen-\nerate. In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, NAACL 2022, Seattle, WA, United States,\nJuly 10-15, 2022, pages 2701‚Äì2715. Association for\nComputational Linguistics.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\npat, and Ming-Wei Chang. 2020. REALM: retrieval-\naugmented language model pre-training. CoRR,\nabs/2002.08909.\nJunxian He, Daniel Spokoyny, Graham Neubig, and\nTaylor Berg-Kirkpatrick. 2019. Lagging inference\nnetworks and posterior collapse in variational autoen-\ncoders. In 7th International Conference on Learning\nRepresentations, ICLR 2019, New Orleans, LA, USA,\nMay 6-9, 2019. OpenReview.net.\nJinyi Hu, Xiaoyuan Yi, Wenhao Li, Maosong Sun, and\nXing Xie. 2022. Fuse it more deeply! A variational\ntransformer with layer-wise latent variable inference\nfor text generation. In Proceedings of the 2022\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, NAACL 2022, Seattle, WA,\nUnited States, July 10-15, 2022, pages 697‚Äì716. As-\nsociation for Computational Linguistics.\nGautier Izacard and Edouard Grave. 2021. Leveraging\npassage retrieval with generative models for open do-\nmain question answering. In Proceedings of the 16th\nConference of the European Chapter of the Associ-\nation for Computational Linguistics: Main Volume,\nEACL 2021, Online, April 19 - 23, 2021, pages 874‚Äì\n880. Association for Computational Linguistics.\nJeff Johnson, Matthijs Douze, and Herv√© J√©gou. 2021.\nBillion-scale similarity search with gpus. IEEE\nTrans. Big Data, 7(3):535‚Äì547.\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B.\nBrown, Benjamin Chess, Rewon Child, Scott Gray,\nAlec Radford, Jeffrey Wu, and Dario Amodei. 2020.\nScaling laws for neural language models. CoRR,\nabs/2001.08361.\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\nS. H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen,\nand Wen-tau Yih. 2020. Dense passage retrieval for\nopen-domain question answering. In Proceedings of\nthe 2020 Conference on Empirical Methods in Nat-\nural Language Processing, EMNLP 2020, Online,\nNovember 16-20, 2020, pages 6769‚Äì6781. Associa-\ntion for Computational Linguistics.\nUrvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke\nZettlemoyer, and Mike Lewis. 2020. Generalization\nthrough memorization: Nearest neighbor language\nmodels. In 8th International Conference on Learning\nRepresentations, ICLR 2020, Addis Ababa, Ethiopia,\nApril 26-30, 2020. OpenReview.net.\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\ntus, Fabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih,\nTim Rockt√§schel, Sebastian Riedel, and Douwe\nKiela. 2020. Retrieval-augmented generation for\nknowledge-intensive NLP tasks. In Advances in Neu-\nral Information Processing Systems 33: Annual Con-\nference on Neural Information Processing Systems\n2020, NeurIPS 2020, December 6-12, 2020, virtual.\nChunyuan Li, Xiang Gao, Yuan Li, Baolin Peng, Xiujun\nLi, Yizhe Zhang, and Jianfeng Gao. 2020. Optimus:\nOrganizing sentences via pre-trained modeling of a\nlatent space. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Process-\ning, EMNLP 2020, Online, November 16-20, 2020,\npages 4678‚Äì4699. Association for Computational\nLinguistics.\nHuayang Li, Yixuan Su, Deng Cai, Yan Wang, and\nLemao Liu. 2022. A survey on retrieval-augmented\ntext generation. CoRR, abs/2202.01110.\nJiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,\nand Bill Dolan. 2016. A diversity-promoting ob-\njective function for neural conversation models. In\nNAACL HLT 2016, The 2016 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nSan Diego California, USA, June 12-17, 2016, pages\n110‚Äì119. The Association for Computational Lin-\nguistics.\nPotsawee Manakul, Adian Liusie, and Mark J. F. Gales.\n2023. Selfcheckgpt: Zero-resource black-box hal-\nlucination detection for generative large language\nmodels.\nGary Marcus. 2020. The next decade in AI: four\nsteps towards robust artificial intelligence. CoRR,\nabs/2002.06177.\nShamima Mithun, Leila Kosseim, and Prasad Perera.\n2012. Discrepancy between automatic and manual\nevaluation of summaries. In Proceedings of Work-\nshop on Evaluation Metrics and System Comparison\nfor Automatic Summarization@NACCL-HLT 2012,\nMontr√®al, Canada, June 2012, 2012 , pages 44‚Äì52.\nAssociation for Computational Linguistics.\nLiang Pang, Yanyan Lan, and Xueqi Cheng. 2021.\nMatch-ignition: Plugging pagerank into transformer\nfor long-form text matching. In CIKM ‚Äô21: The 30th\nACM International Conference on Information and\nKnowledge Management, Virtual Event, Queensland,\nAustralia, November 1 - 5, 2021, pages 1396‚Äì1405.\nACM.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics, July 6-12, 2002, Philadelphia,\nPA, USA, pages 311‚Äì318. ACL.\n2509\nOhad Rubin, Jonathan Herzig, and Jonathan Berant.\n2022. Learning to retrieve prompts for in-context\nlearning. In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, NAACL 2022, Seattle, WA, United States,\nJuly 10-15, 2022, pages 2655‚Äì2671. Association for\nComputational Linguistics.\nDevendra Singh Sachan, Siva Reddy, William L. Hamil-\nton, Chris Dyer, and Dani Yogatama. 2021. End-to-\nend training of multi-document reader and retriever\nfor open-domain question answering. In Advances\nin Neural Information Processing Systems 34: An-\nnual Conference on Neural Information Processing\nSystems 2021, NeurIPS 2021, December 6-14, 2021,\nvirtual, pages 25968‚Äì25981.\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon\nSeo, Rich James, Mike Lewis, Luke Zettlemoyer, and\nWen-tau Yih. 2023. REPLUG: retrieval-augmented\nblack-box language models. CoRR, abs/2301.12652.\nHaoqin Tu, Zhongliang Yang, Jinshuai Yang, and\nYongfeng Huang. 2022. Adavae: Exploring adap-\ntive gpt-2s in variational auto-encoders for language\nmodeling. arXiv preprint arXiv:2205.05862.\nTianming Wang and Xiaojun Wan. 2019. T-CV AE:\ntransformer-based conditioned variational autoen-\ncoder for story completion. In Proceedings of the\nTwenty-Eighth International Joint Conference on Ar-\ntificial Intelligence, IJCAI 2019, Macao, China, Au-\ngust 10-16, 2019, pages 5233‚Äì5239. ijcai.org.\nShicheng Xu, Liang Pang, Huawei Shen, and Xueqi\nCheng. 2023. BERM: training the balanced and ex-\ntractable representation for matching to improve gen-\neralization ability of dense retrieval. In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\nACL 2023, Toronto, Canada, July 9-14, 2023, pages\n6620‚Äì6635. Association for Computational Linguis-\ntics.\nZichao Yang, Zhiting Hu, Ruslan Salakhutdinov, and\nTaylor Berg-Kirkpatrick. 2017. Improved variational\nautoencoders for text modeling using dilated con-\nvolutions. In Proceedings of the 34th International\nConference on Machine Learning, ICML 2017, Syd-\nney, NSW, Australia, 6-11 August 2017, volume 70 of\nProceedings of Machine Learning Research, pages\n3881‚Äì3890. PMLR.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Evalu-\nating text generation with BERT. In8th International\nConference on Learning Representations, ICLR 2020,\nAddis Ababa, Ethiopia, April 26-30, 2020. OpenRe-\nview.net.\nYaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan\nZhang, Jun Wang, and Yong Yu. 2018. Texygen: A\nbenchmarking platform for text generation models.\nIn The 41st International ACM SIGIR Conference on\nResearch & Development in Information Retrieval,\nSIGIR 2018, Ann Arbor, MI, USA, July 08-12, 2018,\npages 1097‚Äì1100. ACM.\nYunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen,\nand Xueqi Cheng. 2021. Adaptive information seek-\ning for open-domain question answering. In Proceed-\nings of the 2021 Conference on Empirical Methods\nin Natural Language Processing, EMNLP 2021, Vir-\ntual Event / Punta Cana, Dominican Republic, 7-11\nNovember, 2021, pages 3615‚Äì3626. Association for\nComputational Linguistics.\n2510",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8000134229660034
    },
    {
      "name": "Language model",
      "score": 0.7295970916748047
    },
    {
      "name": "Encoder",
      "score": 0.664476752281189
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.5810999870300293
    },
    {
      "name": "Gaussian",
      "score": 0.5775600671768188
    },
    {
      "name": "Artificial intelligence",
      "score": 0.47308021783828735
    },
    {
      "name": "Probabilistic logic",
      "score": 0.43266165256500244
    },
    {
      "name": "Latent variable",
      "score": 0.4323521852493286
    },
    {
      "name": "Mixture model",
      "score": 0.43071386218070984
    },
    {
      "name": "Context (archaeology)",
      "score": 0.4229617118835449
    },
    {
      "name": "Noise (video)",
      "score": 0.41627490520477295
    },
    {
      "name": "Algorithm",
      "score": 0.3232607841491699
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Image (mathematics)",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I19820366",
      "name": "Chinese Academy of Sciences",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210090176",
      "name": "Institute of Computing Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210165038",
      "name": "University of Chinese Academy of Sciences",
      "country": "CN"
    }
  ],
  "cited_by": 1
}