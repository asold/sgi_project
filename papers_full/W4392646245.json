{
    "title": "A Generalizable Architecture for Explaining Robot Failures Using Behavior Trees and Large Language Models",
    "url": "https://openalex.org/W4392646245",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5094114769",
            "name": "Christian Tagliamonte",
            "affiliations": [
                "University of Massachusetts Lowell"
            ]
        },
        {
            "id": "https://openalex.org/A5094114770",
            "name": "Daniel Maccaline",
            "affiliations": [
                "University of Massachusetts Lowell"
            ]
        },
        {
            "id": "https://openalex.org/A2792025534",
            "name": "Gregory LeMasurier",
            "affiliations": [
                "University of Massachusetts Lowell"
            ]
        },
        {
            "id": "https://openalex.org/A115698233",
            "name": "Holly A. Yanco",
            "affiliations": [
                "University of Massachusetts Lowell"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6778883912",
        "https://openalex.org/W3134655704",
        "https://openalex.org/W2010158189",
        "https://openalex.org/W3180252218",
        "https://openalex.org/W3198991573",
        "https://openalex.org/W4362693613",
        "https://openalex.org/W2789347656",
        "https://openalex.org/W4392633429",
        "https://openalex.org/W2123344105",
        "https://openalex.org/W4386500227",
        "https://openalex.org/W3010330353",
        "https://openalex.org/W4238869533",
        "https://openalex.org/W2796154788",
        "https://openalex.org/W4388182168",
        "https://openalex.org/W3149166261",
        "https://openalex.org/W4236965008",
        "https://openalex.org/W4292779060"
    ],
    "abstract": "As robots are more commonly being deployed in shared human-robot environments, the need for robots to communicate their failures and answer questions about them becomes increasingly important. This paper describes a generalizable architecture, using Behavior Trees and Large Language Models, to generate explanations and answer follow up questions. We compare responses from our new system to those from existing templated systems, and find that our system produces comparable and accurate results. Finally, we propose a set of user studies to evaluate the effectiveness and understandability of our new explanation architecture.",
    "full_text": null
}