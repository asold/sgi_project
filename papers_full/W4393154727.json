{
  "title": "TCI-Former: Thermal Conduction-Inspired Transformer for Infrared Small Target Detection",
  "url": "https://openalex.org/W4393154727",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5101579766",
      "name": "Tianxiang Chen",
      "affiliations": [
        "Alibaba Group (China)",
        "Chinese Academy of Sciences",
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5113096873",
      "name": "Zhentao Tan",
      "affiliations": [
        "Alibaba Group (China)",
        "Chinese Academy of Sciences",
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5045938154",
      "name": "Qi Chu",
      "affiliations": [
        "Chinese Academy of Sciences",
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5024996713",
      "name": "Yue Ivan Wu",
      "affiliations": [
        "Alibaba Group (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5100780866",
      "name": "Bin Liu",
      "affiliations": [
        "Chinese Academy of Sciences",
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5064573190",
      "name": "Nenghai Yu",
      "affiliations": [
        "Chinese Academy of Sciences",
        "University of Science and Technology of China"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6638439052",
    "https://openalex.org/W4286630479",
    "https://openalex.org/W4385765253",
    "https://openalex.org/W4386158777",
    "https://openalex.org/W4372184688",
    "https://openalex.org/W3089723045",
    "https://openalex.org/W3112367891",
    "https://openalex.org/W3174738881",
    "https://openalex.org/W4384519474",
    "https://openalex.org/W2918460136",
    "https://openalex.org/W3171950886",
    "https://openalex.org/W2791312173",
    "https://openalex.org/W4312827004",
    "https://openalex.org/W2734349601",
    "https://openalex.org/W3088317060",
    "https://openalex.org/W3010079414",
    "https://openalex.org/W4226043641",
    "https://openalex.org/W3175515048",
    "https://openalex.org/W2593463961",
    "https://openalex.org/W2912919760",
    "https://openalex.org/W4304084055",
    "https://openalex.org/W4283785001",
    "https://openalex.org/W4304092528",
    "https://openalex.org/W4313065862",
    "https://openalex.org/W4362500629",
    "https://openalex.org/W4372260328",
    "https://openalex.org/W3118934234",
    "https://openalex.org/W3118249006",
    "https://openalex.org/W4372259885",
    "https://openalex.org/W4313007769",
    "https://openalex.org/W3202696561",
    "https://openalex.org/W4379382445",
    "https://openalex.org/W4302187931",
    "https://openalex.org/W3211571144",
    "https://openalex.org/W4205154121"
  ],
  "abstract": "Infrared small target detection (ISTD) is critical to national security and has been extensively applied in military areas. ISTD aims to segment small target pixels from background. Most ISTD networks focus on designing feature extraction blocks or feature fusion modules, but rarely describe the ISTD process from the feature map evolution perspective. In the ISTD process, the network attention gradually shifts towards target areas. We abstract this process as the directional movement of feature map pixels to target areas through convolution, pooling and interactions with surrounding pixels, which can be analogous to the movement of thermal particles constrained by surrounding variables and particles. In light of this analogy, we propose Thermal Conduction-Inspired Transformer (TCI-Former) based on the theoretical principles of thermal conduction. According to thermal conduction differential equation in heat dynamics, we derive the pixel movement differential equation (PMDE) in the image domain and further develop two modules: Thermal Conduction-Inspired Attention (TCIA) and Thermal Conduction Boundary Module (TCBM). TCIA incorporates finite difference method with PMDE to reach a numerical approximation so that target body features can be extracted. To further remove errors in boundary areas, TCBM is designed and supervised by boundary masks to refine target body features with fine boundary details. Experiments on IRSTD-1k and NUAA-SIRST demonstrate the superiority of our method.",
  "full_text": "TCI-Former: Thermal Conduction-Inspired Transformer for Infrared Small\nTarget Detection\nTianxiang Chen1,2,3*, Zhentao Tan1,2,3, Qi Chu1,3‚Ä† , Yue Wu2, Bin Liu1,3, Nenghai Yu1,3\n1School of Cyber Science and Technology, University of Science and Technology of China\n2Alibaba Group\n3Key Laboratory of Electromagnetic Space Information, Chinese Academy of Sciences\n{txchen,tzt}@mail.ustc.edu.cn, matthew.wy@alibaba-inc.com, {qchu, flowice, ynh}@ustc.edu.cn\nAbstract\nInfrared small target detection (ISTD) is critical to national\nsecurity and has been extensively applied in military areas.\nISTD aims to segment small target pixels from background.\nMost ISTD networks focus on designing feature extraction\nblocks or feature fusion modules, but rarely describe the\nISTD process from the feature map evolution perspective.\nIn the ISTD process, the network attention gradually shifts\ntowards target areas. We abstract this process as the direc-\ntional movement of feature map pixels to target areas through\nconvolution, pooling and interactions with surrounding pix-\nels, which can be analogous to the movement of thermal\nparticles constrained by surrounding variables and particles.\nIn light of this analogy, we propose Thermal Conduction-\nInspired Transformer (TCI-Former) based on the theoreti-\ncal principles of thermal conduction. According to thermal\nconduction differential equation in heat dynamics, we de-\nrive the pixel movement differential equation (PMDE) in the\nimage domain and further develop two modules: Thermal\nConduction-Inspired Attention (TCIA) and Thermal Conduc-\ntion Boundary Module (TCBM). TCIA incorporates finite\ndifference method with PMDE to reach a numerical approx-\nimation so that target body features can be extracted. To fur-\nther remove errors in boundary areas, TCBM is designed and\nsupervised by boundary masks to refine target body features\nwith fine boundary details. Experiments on IRSTD-1k and\nNUAA-SIRST demonstrate the superiority of our method.\nIntroduction\nInfrared small target detection (ISTD) is challenging be-\ncause targets are so small that may easily get ignored by\ngeneric segmentation networks. Besides, infrared images are\nof low contrast and low quality, which also bring challenges\nto this task. Since generic segmentation networks fail to per-\nform well on this task, we hope to explore a new perspective\nand design a precise and explainable method for ISTD.\nISTD methods are generally categorized into traditional\nmethods and deep-learning-based methods. In early stages,\nfor lack of public ISTD dataset, researchers are limited to\ntraditional methods (Sun, Yang, and An 2020; Marvasti,\nMosavi, and Nasiri 2018; Zhang and Peng 2019; Han et al.\n*Work done during an internship at Alibaba Group.\n‚Ä†Qi Chu is the corresponding author.\nCopyright ¬© 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n‚Ä¶\nImage Field\nThermal Field\nFeature Map Evolution\nfrom coarse to fine\nThermal Conduction Direction\nWarm Surface Cold Surface ùë¶\nùë•\nùëß\nùëëùë•ùëëùë¶\nùëëùëß\nùëëùëÑùë• ùëëùëÑùë•+ùëëùë•\nùë¶\nùë•\nùëëùëÉùë•\nùëëùë¶\nùëëùë•\n ùëëùëÉùë•+ùëëùë•\nFigure 1: Conversion process between the image field and\nthe thermal field.The feature map evolution process in the\nimage field can be analogous to the thermal conduction pro-\ncess in the thermal field. The upper part depicts the image\nfield and presents the from-coarse-to-fine feature map evo-\nlution in the ISTD process. The upper right corner shows\nthe change of pixel value in a 2-D image micro-element.\nThe lower part shows the thermal conduction process of a 3-\nD micro-element in the thermal field, where thermal energy\nis conducted spontaneously from high-temperature areas to\nlow-temperature areas.\n2019). However, these methods relying so much on prior\nknowledge and handcraft features that inevitably suffer very\nlimited performances on images with characteristics incon-\nsistent with the model assumptions.\nRecent years have witnessed the research focus of ISTD\nshifting to deep-learning-based methods. Deep-learning-\nbased methods improve the ISTD performance by a large\nmargin and can be further classidied into CNN-based meth-\nods (Chen et al. 2023c; Dai et al. 2021b,a; Zhang et al.\n2021; Wang, Zhou, and Wang 2019; Li et al. 2022a; Zhang\net al. 2021, 2022d; Zhu et al. 2023; Weng et al. 2023; Du,\nWang, and Cao 2023) and hybrid methods (methods com-\nbining ViT and CNN) (Wang et al. 2022a; Qi et al. 2022;\nChen et al. 2023b; Liu et al. 2021; Zhang et al. 2022a; Chen\net al. 2023a). However, despite different module designs,\nthese methods rarely explore a new perspective to look at\nISTD, which helps constructing an explainable ISTD net-\nwork and proposing a potential future research direction. To\nthis end, we propose to understand the feature map evolution\nprocess of ISTD from the perspective of thermal conduction.\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n1201\nIn thermodynamics, micro-elements with different heat\nexhibit different distribution over time in a closed system.\nInfluenced by the heat source and other external factors, heat\nwill spontaneously be conducted from warm areas to cold\nareas. Similarly, the ISTD process can be regarded as a se-\nries of feature maps that change over time constrained by an\nobjective function. The intuitive analogy between ISTD and\nthermal dynamics is shown in Fig. 1. The upper part shows\nthe feature map evolution process during ISTD, which is\na from-coarse-to-fine process gradually highlighting targets\nusing the adjacent pixel information. Specifically, in con-\nvolution operations, pixels are determined by multiple ad-\njacent pixels of the previous layer. During ISTD process,\nthe micro-elements with different pixel values in the im-\nage move under the constraints of an objective function un-\ntil some micro-elements with high pixel values gather near\nsmall target areas. In this way, the small targets gradually\nget highlighted. The three consecutive images in the upper\nright part visualize this process. The lower part describes\nthe spontaneous thermal conduction from high-temperature\nto low-temperature areas. The bottom right image shows the\ninflow and outflow of the thermal energy in a 3-D micro-\nelement. The two processes are essentially very similar, so\nsome thermodynamic theories can be transferred to ISTD.\nThe most related work of our paper is (Zhang et al. 2022b),\nwhich understands super resolution from thermodynamics\nperspective, but our task, network modules and the way of\nanalogizing thermal field to image field (the pixel movement\nof ISTD is directed to target areas, but for super resolution it\nis unordered) are all different.\nIn this paper, we explore a novel research routine by\nanalogizing the pixel movement during ISTD process as\nthermal conduction in thermodynamics and propose TCI-\nFormer. Based on the thermal conduction differential equa-\ntion, we derive the pixel movement differential equation\n(PMDE) in the image domain for ISTD. Our PMDE builds\na spatial‚Äìtemporal constraint to guide the pixel flow direc-\ntion, so we design our network based on it. On the one hand,\nwe apply the finite difference method to PMDE and pro-\npose thermal conduction-inspired attention (TCIA) to help\nextracting the main body features of targets. On the other\nhand, only focusing on main body areas of targets inevitably\ncauses errors in segmenting target boundary areas, so we de-\nvise thermal conduction boundary module (TCBM) to refine\ntarget body features with fine boundary details.\nOur contributions can be summarized in three folds:\n‚Ä¢ We are the first to realize the intrinsic consistency be-\ntween thermal micro-elements and the image pixels dur-\ning feature map evolution in ISTD, where the change of\nheat distribution over time is analogous to the change of\npixel values due to pixel movement in consecutive fea-\nture map series. We transfer heat conduction theories into\nthe ISTD network design and propose TCI-Former.\n‚Ä¢ Inspired by the thermal conduction differential equa-\ntion, we derive our pixel movement differential equation\n(PMDE) to establish a link between spatial and temporal\ninformation of pixel values during ISTD process.\n‚Ä¢ We incorporate the finite difference method to PMDE\nand propose thermal conduction-inspired attention\n(TCIA) to extract target main body features but brings\nslight errors to target boundary areas. As complement,\nthermal conduction boundary module (TCBM) is also\ndevised to supplement the target body features with fine\nboundary details to make up for the errors.\n‚Ä¢ Our method outperforms others on IRSTD-1k and\nNUAA-SIRST in terms of evaluation metrics.\nRelated Work\nInfrared Small Target Detection Networks\nISTD networks are generally classified into CNN-based and\nhybrid types. CNN-based networks mainly extract local fea-\ntures. Dai et al. (Dai et al. 2021a) released the first public\nISTD dataset and proposed asymmetric contextual modula-\ntion for cross-layer feature fusion. They then proposed Al-\ncNet (Dai et al. 2021b) to preserve local features of small\ntargets. Wang et al. were the first to apply GAN to ISTD and\nproposed MDvsFA (Wang, Zhou, and Wang 2019), which\nachieved a trade-off between missed detection and false\nalarm. DNANet (Li et al. 2022a) devised a dense nested in-\nteractive module (DNIM) to progressively interact different\nlevel features. ISNet (Zhang et al. 2022d) designed a simple\nTaylor finite difference-inspired block and a two-orientation\nattention aggregation module to detect targets.\nHowever, only local features are insufficient to detect all\ninfrared targets because the low contrast background makes\nmany small targets unclear to find. Therefore, researchers\nturn to hybrid methods (Chen, Wang, and Tan 2022; Wang\net al. 2022a; Zhang et al. 2022a) by combining ViT with\nCNN to complement local features with global dependen-\ncies. For example, Chen et al. novelly built a ViT-CNN struc-\nture based on fluid dynamics for shape-aware ISTD.\nThe above ISTD networks focus on building either feature\nextraction blocks or fusion modules, none of them provide a\nnew understanding of ISTD from the feature map evolution\nperspective. In this paper, we open a novel research perspec-\ntive by abstracting the directional movement of pixels with\nhigh pixel values to target areas in the ISTD process as heat\nconduction from warm to cold areas in thermodynamics.\nThermal Conduction Differential Equation\nThermal conduction studies the law of thermal energy trans-\nfer due to temperature difference. Wherever there exists a\ntemperature difference, there is a spontaneous conduction\nof thermal energy from a high-temperature object to a low-\ntemperature object, or from a high-temperature object part\nto a low-temperature part (Borgnakke and Sonntag 2022).\nAs the basic law of thermal conduction, thermal con-\nduction differential equation indicates that the heat passing\nthrough a given section in unit time is proportional to the rate\nof temperature change and the area of the section perpendic-\nular to the direction of the section. It is the mathematical\nexpression of the differential form of the temperature dis-\ntribution in the thermal conduction temperature field. The\nthermal conduction direction is opposite to the temperature\nincrease direction. The equation is established according to\nthe heat conservation law and Fourier law. The law of heat\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n1202\nconservation can be expressed as ‚àÜQ = ‚àÜE + Qf , where\nQ is the difference between the thermal energy imported and\nexported from an object.‚àÜE is the increment of internal en-\nergy of the object. Qf is the heat of formation of the inter-\nnal heat source in the object. The Fourier law describes the\nrelationship between thermal conductivity and temperature\ngradient, which is described as q = ‚àíŒª‚àÇT\n‚àÇn , where ‚àÇT\n‚àÇn is the\ntemperature gradient and Œª is the thermal conduction coeffi-\ncient. Rewrite heat conservation equation into the differen-\ntial form of unit time and space and plug the Fourier Law\ninto the heat conservation equation, we can get the thermal\nconduction differential equation as follows:\n‚àÇT\n‚àÇt = Œª\nœÅc(‚àÇ2T\n‚àÇx2 + ‚àÇ2T\n‚àÇy2 + ‚àÇ2T\n‚àÇz2 ) + qv\nœÅc, (1)\nwhere qv is the heat of formation of the internal heat source\nin an object in per unit volume and time.\nPixel Movement Differential Equation\n(PMDE)\nIn a unit of time, the thermal change of a micro-element can\nbe expressed as: [the difference between the imported and\nexported heat] + [the thermal energy generated by the inter-\nnal heat source] = [the increase in thermodynamic energy].\nThe difference between the imported and exported heat cor-\nresponds to the feature map pixel value difference between\ninflow and outflow (‚àÜP f ). The thermal energy generated\nby the internal heat source corresponds to the change in\nthe pixel‚Äôs own value (‚àÜP s). The total increase in thermo-\ndynamic energy corresponds to the overall change in pixel\nvalue (‚àÜP). Accordingly, in the image field we have:\n[‚àÜPf ] + [‚àÜPs] = [‚àÜP]. (2)\nSimilar to the derivation of TCDE, the Pixel Movement Dif-\nferential Equation (PMDE) can be derived as follows.\nPixel Value Difference between Inflow and Outflow\nWithin dt, we denote the pixel values flowing into the micro-\nelement along the x-axis and y-axis as dPx and dPy, respec-\ntively. Similarly, there are also pixel values flowing out of\nthe micro-element along both axes, which we describe as\ndPx+dx and dPy+dy, respectively. Subsequently, according\nto the relationship between the difference and the derivative,\nand combine the pixel value difference in thex-direction and\nthe pixel value difference in the y-direction to get the whole\nvalue difference\ndPx = pxdydt, dPy = pydxdt,\ndPx+dx = px+dxdydt = (px+‚àÇpx\n‚àÇx dx)dydt,\ndPy+dy = py+dydxdt = (px+‚àÇpy\n‚àÇy dy)dxdt,\n‚àÜPf = dPx+dx ‚àí dPx+dPy+dy ‚àí dPy\n= ‚àí(‚àÇpx\n‚àÇx + ‚àÇpy\n‚àÇy )dxdydt,\n(3)\nwhere dpx, dpy, dpx+dx, dpy+dy are respectively the inflow\nand outflow pixel value intensity along thex-axis and y-axis,\nwhich measure the pixel values flowing in and out within\nper unit area and per unit time. According to the Fourier law\nin thermodynamics (Borgnakke and Sonntag 2022), which\ncharacterizes the relationship between the heat flow and the\nmicro-element temperature gradient in the heat conduction\nprocess, dpx, dpy can be calculated as follows:\ndpx = ‚àíŒª‚àÇP\n‚àÇx , dpy = ‚àíŒª‚àÇP\n‚àÇy . (4)\nChange in Pixel‚Äôs Own Value\nFor each pixel in the infrared image, its own pixel value\nchanges over time and follows Ps = psdxdydt. ps rep-\nresents pixel intensity, which is the pixel value generated\nwithin per unit area and time. Ps is the increase of the im-\nage micro-element‚Äôs pixel value due to its internal points‚Äô\nspontaneous pixel value changes. Here we only consider the\neffect of the difference between the imported and exported\npixel values, so pixel value of each point is fixed and will\nnot change, which means ps = 0.\nOverall Change in Pixel Value\nAccording to the correspondence between the variables in\nimage field and heat conduction field, we can get the rela-\ntionship between the pixel value change rate ( ‚àÇP\n‚àÇt ) and the\noverall pixel value change ‚àÜP during feature map evolu-\ntion. The change in the micro-element‚Äôs pixel value can be\nexpressed as:\n‚àÜP = a‚àÇP\n‚àÇt dxdydt, (5)\nwhere a is a constant. From Eq.(2) to Eq.(5), we can get the\nrelationship between the pixel value change rate and gradi-\nent during the ISTD process, which is the final expression of\npixel movement differential equation (PMDE):\n‚àÇP\n‚àÇt = Œ±(‚àÇ2P\n‚àÇx2 + ‚àÇ2P\n‚àÇy2 ), (6)\nwhere Œ± = (Œª/a). PMDE builds the link between spatial\nand temporal information of pixel values in an image. In the\nnext section we will use the equation to devise two modules\nwhich respectively focus on target body and boundary parts\nto reflect the flow of pixels.\nMethodology\nOverall Architecture\nThe overview of our TCI-Former is displayed in Fig. 2. TCI-\nFormer has a U-Net-like encoder-decoder structure, where\nthe encoder is composed of several Thermal Conduction-\nInspired Transformer (TCIT) blocks stacked sequentially\nwhile the decoder is built upon three plain deconvolu-\ntion layers following the common practice. Skip connec-\ntions are added between the corresponding encoder and de-\ncoder layers for cross-layer feature fusion. A fully convo-\nlutional segmentation head is connected after the decoder\nto offer the final predictions. The added circle in the stage\nblocks denotes the position coding operation for the input\ntokens. Specifically, each TCIT block contains a Thermal\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n1203\nInput\n3√óH√óW\nOutput\nTCIT \nBlock\n√ó3\nStage 1\nTCIT \nBlock\n√ó4\nStage 2\nTCIT \nBlock\n√ó8\nStage 3\nTCIT \nBlock\n√ó3\nStage 4\nPatch Emb\nPatch Emb\nPatch Emb Head\n√ó4 √ó2 √ó2 √ó2\n16√óH/4 √óW/4\n32√óH/8 √óW/8\n64√óH/16 √óW/16\n√ó2 √ó2 √ó2\n√ó4\nStem Block\nDeconv\nUp-Sampling\nDown-Sampling\nTCIA\nAdd & Norm\nFeed\nForward\nAdd & Norm\nTCBM\nThermal Conduction-\nInspired Attention\nTCBM\nTCIA\nThermal Conduction-\nBoundary Module\nLaplace\n3√ó3Couv\nBN\nReLu\n3√ó3Couv\nBN\nFigure 2: Overall architecture of our TCI-Former with an encoder-decoder structure. The encoder is composed of several\nTCIT blocks. Each TCIT block contains two key components: Thermal Conduction-Inspired Attention (TCIA) and Thermal\nConduction Boundary Module (TCBM), which are both devised based on our derived pixel movement differential equation\n(PMDE). PMDE is inspired by the thermal conduction differential equation (TCDE) in heat dynamics.\nConduction-Inspired Attention (TCIA) and a Thermal Con-\nduction Boundary Module (TCBM). The TCIT has a paral-\nlel structure of global attention and convolution to assemble\ntheir merits of modelling local and global information simul-\ntaneously. The global attention structure of TCIT block is\nTCIA, which concentrates on target body information from\nhorizontal and vertical directions in the same way as thermal\nconduction. The convolutional structure of TCIT is TCBM,\nwhich refines target body features with boundary details.\nThermal Conduction-Inspired Attention\nThe finite difference method is a numerical ODE solver. We\napply the method to our PMDE to extract the target main\nbody feature, which can be regarded as an approximation\nof the whole target feature. Thus, we propose TCIA to ex-\nplore the rule of target body feature extraction during feature\nmap evolution. Here we use the second-order finite differ-\nence equation, which is expressed as:\n‚àÇ2Pt\ni,j\n‚àÇx2 = Pt\ni+1,j ‚àí 2Pt\ni,j + Pt\ni‚àí1,j\n(‚àÜx)2 ,\n‚àÇ2Pt\ni,j\n‚àÇy2 = Pt\ni,j+1 ‚àí 2Pt\ni,j + Pt\ni,j‚àí1\n(‚àÜy)2 ,\n(7)\nwhere Pt\ni,j is the pixel value in position (i, j) in the t-th\nfeature map layer. Applying Eq.(7) to Eq.(6) we have\nPt+1\ni,j ‚àí Pt\ni,j = Œ±(Pt\ni+1,j ‚àí 2Pt\ni,j + Pt\ni‚àí1,j\n(‚àÜx)2 +\nPt\ni,j+1 ‚àí 2Pt\ni,j + Pt\ni,j‚àí1\n(‚àÜy)2 ).\n(8)\nDefining ‚àÜx = ‚àÜy , we can get the final expression of the\ntarget main body part feature extraction rule as follows:\nPt+1\ni,j = Œ≥(Pt\ni+1,j +Pt\ni‚àí1,j +Pt\ni,j+1 +Pt\ni,j‚àí1 ‚àí4Pt\ni,j)+Pt\ni,j,\n(9)\nwhere Œ≥ denotes Œ±\n‚àÜx‚àÜy . Eq.(9) describes that the pixel value\nat a certain position in a certain feature map layer is deter-\nmined by its surrounding pixels in x and y axis of its former\nlayer feature map.\nBased on Eq.(9), we devise TCIA to extract the main body\nfeatures of small targets during feature map evolution. Fig. 3\nshows the structure of TCIA. The input of TCIA is Pt and\nthe output is Œ≥(Pt\ni+1,j + Pt\ni‚àí1,j + Pt\ni,j+1 + Pt\ni,j‚àí1 ‚àí 4Pt\ni,j),\nwhich is obtained through horizontal and vertical conduc-\ntion attentions ‚àÜy and ‚àÜx to aggregate surrounding pixel\ninformation of the former layer before element-wise ad-\ndition with Pt. The channel of Pt ‚àà RC√óH√óW is di-\nvided into four groups before shifting each channel group\nto different directions by +1 or ‚àí1. In this way, the recep-\ntive field of Pt after spatial shift is rhombic, which corre-\nsponds to Pt\ni+1,j + Pt\ni‚àí1,j + Pt\ni,j+1 + Pt\ni,j‚àí1. We can get\nPt\ni+1,j + Pt\ni‚àí1,j + Pt\ni,j+1 + Pt\ni,j‚àí1 ‚àí 4Pt\ni,j through resid-\nual operation and then linearly project this term into Q, K,\nV . The horizontal conduction ‚àÜy is implemented by tak-\ning average of query feature map on the horizontal direc-\ntion. In the same way, the vertical conduction ‚àÜx squeezes\nquery feature map on the vertical direction. The same op-\nerations are also conducted upon K and V , so we can get\nQh, Kh ‚àà RH√óCqk , Vh ‚àà RH√óCv and Qv, Kv ‚àà RW√óCqk ,\nVv ‚àà RW√óCv . Each of the two conduction attentions re-\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n1204\nTCIA\nAdd & Norm\nFeed\nForward\nAdd & Norm\nK\nV\nQ\nHorizontal\nConduction\n‚àÜy\nVertical\nConduction\n‚àÜx\nMHA\nMHA\n1√ó1Couv\nQh\nKh\nVh\nQv\nKv\nVv\n√ó‚àí4\nùëÉùë°\nGroup&\nSpatial \nShift\nThermal Conduction Inspired Attention (TCIA)\nQv:1√óW√óCqk\nKv:1√óW√óCqk\nQh:H√ó1√óCqk\nKh: H√ó1√óCqk\nVh:H√ó1√óCv\nVv:1√óW√óCv\nSpatial ShiftGroup\nH\nW\nC Pt\nReceptive \nFieldPi+1,j\nt +Pi‚àí1,j\nt\n+Pi,j+1\nt +Pi,j‚àí1\nt\nùëÉùë°+1\nFigure 3: Overall architecture of our proposed Thermal\nConduction-Inspired Attention (TCIA), which is devised\nbased on finite difference method and PMDE derived from\nthe TCDE in heat dynamics.\nserves the global information to a single axis, so that each\nposition on the feature map propagates information only on\ntwo squeezed x-axis and y-axis features. Then the Q, K, V\nvectors are fed into multi-head attentions and then added to-\ngether for horizontal and vertical feature aggregation to real-\nize the Œ≥(Pt\ni+1,j +Pt\ni‚àí1,j +Pt\ni,j+1+Pt\ni,j‚àí1‚àí4Pt\ni,j) term. For\nthe last term Pt\ni,j in Eq.(9), it is added through the residual\nand layer norm operation in the transformer block. In this\nway, the TCIA based on Eq.(9) is realized.\nThermal Conduction Boundary Module\nTCIA helps extracting target body features, but the features\nextracted by TCIA branch alone are not fine enough in near\nboundary regions because the finite difference method used\nin TCIA is a numerical method, which inevitably brings\nsmall errors. A certain degree of dispersion exists due to nu-\nmerical uncertainty during pixel value movement. To solve\nthis, we need to refine the coarse target body features with\nfine boundary details to make up for the uncertain errors. We\nnotice that our PMDE itself has already contained bound-\nary information (second-order derivative terms), so to ex-\ntract target boundary features we design Thermal Conduc-\ntion Boundary Module (TCBM) based on PMDE. The dif-\nferential form of Eq.(6) can be described as:\nPt+‚àÜt ‚àí Pt = ‚àÜtŒ±(‚àÇ2P\n‚àÇx2 + ‚àÇ2P\n‚àÇy2 .) (10)\nDuring ISTD, the extracted feature maps are arranged in\na chronological order. The PMDE establishes the relation-\nship between the change of pixel value in temporal domain\n(Pt+‚àÜt ‚àí Pt) and 2-D spatial domain ( ‚àÇ2Pt\n‚àÇx2 , ‚àÇ2Pt\n‚àÇy2 ) during\nfeature extraction. Defining the time step‚àÜt as 1, we can ex-\nplore the boundary feature evolution rule between two con-\nsecutive feature maps. The specific expression of PMDE can\nbe rewritten as:\nPt+1 ‚àí Pt = hŒ±(‚àÇ2Pt\n‚àÇx2 + ‚àÇ2Pt\n‚àÇy2 ), (11)\nwhere t means the t-th residual calculation. h is the step size\nbetween the t-th and t+1-th residual calculation. The TCBM\napplies spatial information to make up for the lack of bound-\nary refinements during feature extraction in the encoder. The\nright side of Eq.(11) is the second derivative of Pt in the x-\nand y-directions, respectively. Thus, with this item, we ob-\ntain the spatial information which can be used as the residual\nsupplementary for time information, that is, the information\nin the forward extraction process.‚àÇ2Pt\n‚àÇx2 and ‚àÇ2Pt\n‚àÇy2 have larger\nvalue at boundary areas, therefore TCBM is sensitive to tar-\nget boundaries and can play a complementary role to the\ntarget body features. Our TCBM incorporates a Laplace op-\nerator into a residual block, where the Laplace operator is\nused to realize the ‚àÇ2Pt\n‚àÇx2 and ‚àÇ2Pt\n‚àÇy2 terms.\nLoss Function\nDice loss (Sudre et al. 2017) measures the difference be-\ntween a mask prediction and the ground truth. It can also\nrelieve sample imbalance problem and is defined as:\nLdice = 1 ‚àí 2|X ‚à© Y |\n|X| + |Y |, (12)\nwhere X denotes the mask prediction and Y is the ground\ntruth. Our final loss function LFinal includes LSeg as the\nmain loss function and Target Boundary loss (L TB ) and\nInterior Body loss (L IB ) as two auxiliary loss functions.\nLFinal is calculated as:\nLFinal = Lhyb\nSeg + Lhyb\nTB + Lhyb\nIB . (13)\nLIB and LSeg share the same Y as the ground truth mask,\nwhile the X of LIB is the segmentation head output from\nthe TCIA encoder branch, and the X of LSeg is the final\nprediction output. The X of LTB is the segmentation head\noutput from the TCBM encoder branch, and the Y of LTB\nis the boundary mask label.\nExperiments\nExperimental Settings\nDatasets. We choose NUAA-SIRST (Dai et al. 2021a)\nand IRSTD-1k (Zhang et al. 2022d) as our experimental\ndatasets. NUAA-SIRST contains 427 infrared images of var-\nious sizes while IRSTD-1k consists of 1,000 real infrared\nimages of 512 √ó 512 in size. IRSTD-1k is a more difficult\nISTD dataset with richer scenarios. For each dataset, we use\n80% of images as training set and 20% as test set.\nEvaluation Metrics. We compare our TCI-Former with\nother SOTA methods in terms of both pixel-level and object-\nlevel evaluation metrics. The pixel-level metrics include In-\ntersection over Union (IoU ) and Normalized Intersection\nover Union (nIoU ), while the object-level metrics include\nProbability of Detection (Pd) and False-Alarm Rate (Fa).\nIoU measures the accuracy of detecting the accuracy of\ndetecting the corresponding object in a given dataset. nIoU\nis the normalization of IoU , which can make a better bal-\nance between structural similarity and pixel accuracy of in-\nfrared small targets. IoU and nIoU are defined as:\nIoU = Ai\nAu\n, nIoU= 1\nN\nNX\ni=1\n( T P[i]\nT[i] + P[i] ‚àí T P[i]), (14)\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n1205\nImage GTACM AlcNet DNANet ISNetIAANet Ours\nIncomplete Detection Target Location Magnified PredPrediction\nImage GTACM AlcNet DNANet ISNetIAANet Ours\nFigure 4: Result visualization of different ISTD methods.\nImage GTOurs\n Image GTTCIA TCBM Ours\nTCIA TCBM\n(a)\n(b)\nTarget Location Magnified PredictionPrediction\nImage De:stage1En:stage1 En:stage2 En:stage3 De:stage3En:stage4 De:stage2\nFigure 5: Visualization of (a) TCIA and TCBM branch out-\nputs and (b) intermediate stage feature map evolution.\nwhere Ai and Au are the areas of intersection region and\nunion region between the prediction and ground truth, re-\nspectively. N is the total number of samples, T P[.] is the\nnumber of true positive pixels, T[.] and P[.] is the number\nof ground truth and predicted positive pixels.\nPd calculates the ratio of the number of correctly pre-\ndicted targets Npred to all targets Nall. Fa refers to the ratio\nof falsely predicted target pixels Nfalse to all the pixels in\nthe infrared imageNall. Pd and Fa are calculated as follows:\nPd = Npred\nNall\n, Fa = Nfalse\nNall\n. (15)\nOptimization. The algorithm is implemented in Pytorch,\nwith Adaptive Gradient (AdaGrad) as the optimizer with the\ninitial learning rate set to 0.05 and weight decay coefficient\nset to 0.0004. A Titan XP GPU is used for training, with\nbatch size set to 4. Training on SIRST and IRSTD-1k takes\n800 epochs and 600 epochs respectively.\nComparison with SOTA Methods\nQuantitative Comparisons. We select some SOTA ISTD\nmethods for comparison. As shown in Table 1, our TCI-\nFormer performs the best in terms of pixel-level and object-\nlevel metrics on both datasets.\nFor the pixel-level metrics (IoU, nIoU ), the deep-\nlearning methods generally surpass the traditional methods\nbecause deep-learning methods do not rely heavily on prior\nknowledge and handcraft features as traditional methods do.\nHowever, deep-learning methods lay insufficient emphasis\non target edges, causing limited IoU and nIoU . Our TCI-\nFormer achieves the best performance on both IoU and\nnIoU , meaning that our method achieves the best shape-\naware segmentation performance thanks to our TCBM.\nFor the object-level metrics (P d, Fa), how to reach a\ntrade-off between Pd and Fa is challenging because the two\nmetrics are mutually exclusive. Traditional methods fail to\nbalance the two metrics but deep-learning methods make it.\nOur TCI-Former achieves the best object-level metrics re-\nsults except that our Fa is second only to RKformer (Zhang\net al. 2022a) in NUAA-SIRST. However, our Fa signifi-\ncantly outperforms it in IRSTD-1k, which is a more difficult\nISTD dataset with richer scenarios. The results demonstrate\nthat our method can learn better representations to find the\nsmall targets covered by low contrast and noisy background\nowing to our TCIA, which mimics thermal conduction to\nextract target main body features.\nVisual Comparisons. Visual results with closed-up views\nof different methods is shown in Fig. 4. As shown in Fig. 4,\nmost CNN-based methods suffer incomplete detection for\nlack of extracting global contexts. Hybrid method gener-\nally outperforms CNN-based methods with fewer severely\nincomplete detection cases, but still cannot predict ac-\ncurate target shapes. Compared with other methods, our\nmethod significantly curtails bad cases and achieves better\nboundary-aware segmentation of small targets. This is be-\ncause our network can not only extract target body features\nlike thermal conduction, but also refine body features with\nfine boundary information.\nTo demonstrate the target body location effect of TCIA\nand boundary refinement effect of TCBM, we visualize\nthe segmentation head outputs of TCIA branch and TCBM\nbranch in Fig. 5 (a). To present the from-coarse-to-fine fea-\nture map evolution process, we visualize intermediate fea-\nture maps of all stages in encoder (En: stage1,2,3,4) and de-\ncoder (De: stage3,2,1) in Fig. 5 (b). We can find that the\nsmall target areas gradually get highlighted like heat con-\nducted from warm to cold areas from the decoder stage 3,2,1\nfeature maps, which complies with our analogy.\nAblation Study\nImpact of Each Module. The ablation study of TCIA and\nTCBM is shown in Table 2. The baseline uses basic pyramid\nViT (Wang et al. 2022b) as encoder. Table 2 demonstrates\nthe positive effects of both designs and combining them to-\ngether brings the best results, implying that they are comple-\nmentary to each other. The reason is that ViT block equipped\nwith TCIA can extract main target body features from sur-\nrounding areas in orthogonal directions, while TCBM in par-\nallel refines the coarse body features with boundary details\nto improve detection performance.\nImpact of TCIA. To ablate TCIA, we compare our TCIA\nwith multi-head self-attention (MHSA) (Wang et al. 2022b),\ncross-shaped window self-attention (CSWSA) (Dong et al.\n2022) and the multi-head relation attention (MHRA) (Li\net al. 2022b). As shown in Table 3, our TCIA outperforms\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n1206\nMethod Type NUAA-SIRST IRSTD-1k\nIoU ‚Üë nIoU ‚Üë Pd ‚Üë Fa ‚Üì IoU ‚Üë nIoU ‚Üë Pd ‚Üë Fa ‚Üì\nPSTNN (Zhang and Peng 2019) Trad 22.40 22.35 77.95 29.11 24.57 17.93 71.99 35.26\nMSLSTIPT (Sun, Yang, and An 2020) Trad 10.30 9.58 82.13 1131 11.43 5.93 79.03 1524\nMDvsFA (Wang, Zhou, and Wang 2019) CNN 60.30 58.26 89.35 56.35 49.50 47.41 82.11 80.33\nACM (Dai et al. 2021a) CNN 72.33 71.43 96.33 9.325 60.97 58.02 90.58 21.78\nAlcNet (Dai et al. 2021b) CNN 74.31 73.12 97.34 20.21 62.05 59.58 92.19 31.56\nDNANet (Li et al. 2022a) CNN 75.27 73.68 98.17 13.62 69.01 66.22 91.92 17.57\nDim2Clear (Zhang et al. 2023) CNN 77.20 75.20 99.10 6.72 66.3 64.2 93.7 20.9\nFC3-Net (Zhang et al. 2022c) CNN 74.22 72.64 99.12 6.569 64.98 63.59 92.93 15.73\nIAANet (Wang et al. 2022a) Hybrid 75.31 74.65 98.22 35.65 59.82 58.24 88.62 24.79\nRKformer (Zhang et al. 2022a) Hybrid 77.24 74.89 99.11 1.580 64.12 64.18 93.27 18.65\nISNet (Zhang et al. 2022d) CNN 80.02 78.12 99.18 4.924 68.77 64.84 95.56 15.39\nTCI-Former Hybrid 80.79 79.85 99.23 4.189 70.14 67.69 96.31 14.81\nTable 1: Quantitative results of different methods on NUAA-SIRST and IRSTD-1k. The figures in bold and underline mark the\nhighest and the second highest ones in each column.\nMethod IoU ‚Üë nIoU ‚Üë Pd ‚Üë Fa ‚Üì\nBaseline 62.82 60.59 92.97 26.37\n+TCIA 67.26 65.03 94.55 19.83\n+TCIA+TCBM 70.14 67.69 96.31 14.81\nTable 2: Ablation study of each module on IRSTD-1k.\nMethod IoU ‚Üë nIoU ‚Üë Pd ‚Üë Fa ‚Üì\nMHSA 66.73 64.69 94.05 19.22\nCSWSA 68.23 66.05 95.36 17.41\nMHRA 68.86 66.87 95.74 16.76\nTCIA 70.14 67.69 96.31 14.81\nTable 3: Ablation study of TCIA on IRSTD-1k.\nothers in all metrics, showing better small target location\nability. The reason is that in TCIA the spatial shift operation\nenables the encoder block to be more aware of boundaries,\nwhich helps extracting more complete target body features.\nThe superiority of TCIA demonstrates our analogy between\nISTD process and thermal conduction process is effective.\nImpact of TCBM. In Table 4 we compare TCBM\n(Laplace+Resblock) with basic Resblock and basic Res-\nblock with Roberts operator to examine the boundary feature\nextraction effect of different designs. Our TCBM delivers\nthe best result, because (1) edge operators help basic Res-\nblock to extract edges and (2) the edges extracted by Roberts\noperator is thick and less accurate.\nModel Complexity Analysis\nWe also compare the model complexity of different methods\nin terms of parameter number (M), FLOPs (G) and inference\ntime (s), as shown in Table 5. Compared with other methods,\nour method doesn‚Äôt have many parameters and has accept-\nable FLOPs and inference time. This is because we squeeze\nthe dimensions of q, k, vbefore attention operations in our\nMethod IoU ‚Üë nIoU ‚Üë Pd ‚Üë Fa ‚Üì\nResBlock 68.93 66.62 95.90 16.35\nRoberts+ResBlock 69.51 67.38 96.02 15.70\nTCBM 70.14 67.69 96.31 14.81\nTable 4: Ablation study of TCBM on IRSTD-1k.\nMethod Param FLOPs Inf\nACM (Dai et al. 2021a) 0.52 2.02 0.01\nDNANet (Li et al. 2022a) 4.7 56.34 0.15\nIAANet (Wang et al. 2022a) 14.05 18.13 0.29\nRKformer (Zhang et al. 2022a) 29.00 24.73 0.08\nTCI-Former 3.66 5.87 0.04\nTable 5: Comparison of the model parameters (M), FLOPs\n(G) and inference time (s) of different methods.\nTCIA, which reduces model parameters and improves effi-\nciency. Our model reach a general balance among different\nmodel complexity indicators.\nConclusion\nMotivated by the analogy of pixel movement during ISTD\nprocess and thermal conduction in thermodynamics, we pro-\npose TCI-Former for ISTD. We first derive PMDE for the\nimage domain from thermodynamic equation. We then ap-\nply finite difference method to PMDE and devise TCIA and\nembed it into encoder block to extract target main body fea-\ntures by simulating the thermal conduction process. We also\npropose TCBM based on PMDE to parallelly refine the tar-\nget body features with fine boundary details. Experiments\non NUAA-SIRST and IRSTD-1k prove the superiority of\nTCI-Former, which explores a new research routine.\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n1207\nAcknowledgments\nThis work is supported by the National Natural Science\nFoundation of China (No.62121002, No. 62272430, No.\nU20B2047) and the Fundamental Research Funds for the\nCentral Universities.\nReferences\nBorgnakke, C.; and Sonntag, R. E. 2022. Fundamentals of\nthermodynamics. John Wiley & Sons.\nChen, G.; Wang, W.; and Tan, S. 2022. IRSTFormer: A Hi-\nerarchical Vision Transformer for Infrared Small Target De-\ntection. Remote Sensing, 14(14): 3258.\nChen, T.; Chu, Q.; Liu, B.; and Yu, N. 2023a. Fluid\ndynamics-inspired network for infrared small target detec-\ntion. In Proceedings of the Thirty-Second International Joint\nConference on Artificial Intelligence, 590‚Äì598.\nChen, T.; Chu, Q.; Tan, Z.; Liu, B.; and Yu, N. 2023b. ABM-\nNet: Coupling Transformer with CNN Based on Adams-\nBashforth-Moulton Method for Infrared Small Target Detec-\ntion. In 2023 IEEE International Conference on Multimedia\nand Expo (ICME), 1901‚Äì1906. IEEE.\nChen, T.; Chu, Q.; Tan, Z.; Liu, B.; and Yu, N. 2023c.\nBAUENet: Boundary-Aware Uncertainty Enhanced Net-\nwork for Infrared Small Target Detection. In ICASSP 2023-\n2023 IEEE International Conference on Acoustics, Speech\nand Signal Processing (ICASSP), 1‚Äì5. IEEE.\nDai, Y .; Wu, Y .; Zhou, F.; and Barnard, K. 2021a. Asymmet-\nric contextual modulation for infrared small target detection.\nIn Proceedings of the IEEE/CVF Winter Conference on Ap-\nplications of Computer Vision, 950‚Äì959.\nDai, Y .; Wu, Y .; Zhou, F.; and Barnard, K. 2021b. Atten-\ntional local contrast networks for infrared small target detec-\ntion. IEEE Transactions on Geoscience and Remote Sens-\ning, 59(11): 9813‚Äì9824.\nDong, X.; Bao, J.; Chen, D.; Zhang, W.; Yu, N.; Yuan, L.;\nChen, D.; and Guo, B. 2022. Cswin transformer: A general\nvision transformer backbone with cross-shaped windows. In\nProceedings of the IEEE/CVF Conference on Computer Vi-\nsion and Pattern Recognition, 12124‚Äì12134.\nDu, S.; Wang, K.; and Cao, Z. 2023. BPR-Net: Balancing\nPrecision and Recall for Infrared Small Target Detection.\nIEEE Transactions on Geoscience and Remote Sensing.\nHan, J.; Liu, S.; Qin, G.; Zhao, Q.; Zhang, H.; and Li, N.\n2019. A local contrast method combined with adaptive back-\nground estimation for infrared small target detection. IEEE\nGeoscience and Remote Sensing Letters, 16(9): 1442‚Äì1446.\nLi, B.; Xiao, C.; Wang, L.; Wang, Y .; Lin, Z.; Li, M.; An,\nW.; and Guo, Y . 2022a. Dense nested attention network for\ninfrared small target detection. IEEE Transactions on Image\nProcessing.\nLi, K.; Wang, Y .; Zhang, J.; Gao, P.; Song, G.; Liu, Y .;\nLi, H.; and Qiao, Y . 2022b. Uniformer: Unifying convolu-\ntion and self-attention for visual recognition. arXiv preprint\narXiv:2201.09450.\nLiu, F.; Gao, C.; Chen, F.; Meng, D.; Zuo, W.; and\nGao, X. 2021. Infrared Small-Dim Target Detection with\nTransformer under Complex Backgrounds. arXiv preprint\narXiv:2109.14379.\nMarvasti, F. S.; Mosavi, M. R.; and Nasiri, M. 2018. Flying\nsmall target detection in IR images based on adaptive toggle\noperator. IET Computer Vision, 12(4): 527‚Äì534.\nQi, M.; Liu, L.; Zhuang, S.; Liu, Y .; Li, K.; Yang, Y .; and Li,\nX. 2022. FTC-Net: Fusion of Transformer and CNN Fea-\ntures for Infrared Small Target Detection. IEEE Journal of\nSelected Topics in Applied Earth Observations and Remote\nSensing, 15: 8613‚Äì8623.\nSudre, C. H.; Li, W.; Vercauteren, T.; Ourselin, S.; and\nJorge Cardoso, M. 2017. Generalised dice overlap as a deep\nlearning loss function for highly unbalanced segmentations.\nIn Deep learning in medical image analysis and multimodal\nlearning for clinical decision support, 240‚Äì248. Springer.\nSun, Y .; Yang, J.; and An, W. 2020. Infrared dim and small\ntarget detection via multiple subspace learning and spatial-\ntemporal patch-tensor model. IEEE Transactions on Geo-\nscience and Remote Sensing, 59(5): 3737‚Äì3752.\nWang, H.; Zhou, L.; and Wang, L. 2019. Miss detection vs.\nfalse alarm: Adversarial learning for small object segmen-\ntation in infrared images. In Proceedings of the IEEE/CVF\nInternational Conference on Computer Vision, 8509‚Äì8518.\nWang, K.; Du, S.; Liu, C.; and Cao, Z. 2022a. Interior\nAttention-Aware Network for Infrared Small Target Detec-\ntion. IEEE Transactions on Geoscience and Remote Sens-\ning, 60: 1‚Äì13.\nWang, W.; Xie, E.; Li, X.; Fan, D.-P.; Song, K.; Liang, D.;\nLu, T.; Luo, P.; and Shao, L. 2022b. Pvt v2: Improved base-\nlines with pyramid vision transformer. Computational Vi-\nsual Media, 8(3): 415‚Äì424.\nWeng, Z.; Li, P.; Zhuang, X.; Yan, X.; Gong, L.; Xie, H.; and\nWei, M. 2023. ifUNet++: Iterative Feedback UNet++ for In-\nfrared Small Target Detection. In ICASSP 2023-2023 IEEE\nInternational Conference on Acoustics, Speech and Signal\nProcessing (ICASSP), 1‚Äì5. IEEE.\nZhang, L.; and Peng, Z. 2019. Infrared small target detection\nbased on partial sum of the tensor nuclear norm. Remote\nSensing, 11(4): 382.\nZhang, M.; Bai, H.; Zhang, J.; Zhang, R.; Wang, C.; Guo, J.;\nand Gao, X. 2022a. RKformer: Runge-Kutta Transformer\nwith Random-Connection Attention for Infrared Small Tar-\nget Detection. In Proceedings of the 30th ACM International\nConference on Multimedia, 1730‚Äì1738.\nZhang, M.; Wu, Q.; Guo, J.; Li, Y .; and Gao, X. 2022b. Heat\ntransfer-inspired network for image super-resolution recon-\nstruction. IEEE Transactions on neural networks and learn-\ning systems.\nZhang, M.; Yue, K.; Zhang, J.; Li, Y .; and Gao, X. 2022c.\nExploring Feature Compensation and Cross-level Correla-\ntion for Infrared Small Target Detection. In Proceedings\nof the 30th ACM International Conference on Multimedia ,\n1857‚Äì1865.\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n1208\nZhang, M.; Zhang, R.; Yang, Y .; Bai, H.; Zhang, J.; and Guo,\nJ. 2022d. ISNet: Shape Matters for Infrared Small Target\nDetection. In Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition, 877‚Äì886.\nZhang, M.; Zhang, R.; Zhang, J.; Guo, J.; Li, Y .; and Gao,\nX. 2023. Dim2Clear network for infrared small target detec-\ntion. IEEE Transactions on Geoscience and Remote Sens-\ning, 61: 1‚Äì14.\nZhang, T.; Cao, S.; Pu, T.; and Peng, Z. 2021. AGPCNet:\nAttention-Guided Pyramid Context Networks for Infrared\nSmall Target Detection. arXiv preprint arXiv:2111.03580.\nZhu, J.; Chen, S.; Li, L.; and Ji, L. 2023. Sanet: Spatial\nAttention Network with Global Average Contrast Learning\nfor Infrared Small Target Detection. In ICASSP 2023-2023\nIEEE International Conference on Acoustics, Speech and\nSignal Processing (ICASSP), 1‚Äì5. IEEE.\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n1209",
  "topic": "Infrared",
  "concepts": [
    {
      "name": "Infrared",
      "score": 0.6628934144973755
    },
    {
      "name": "Thermal infrared",
      "score": 0.5901786684989929
    },
    {
      "name": "Thermal conduction",
      "score": 0.575761079788208
    },
    {
      "name": "Materials science",
      "score": 0.4728824496269226
    },
    {
      "name": "Transformer",
      "score": 0.4669422209262848
    },
    {
      "name": "Thermal",
      "score": 0.4229973256587982
    },
    {
      "name": "Optoelectronics",
      "score": 0.32491278648376465
    },
    {
      "name": "Electrical engineering",
      "score": 0.2873300015926361
    },
    {
      "name": "Physics",
      "score": 0.16944760084152222
    },
    {
      "name": "Optics",
      "score": 0.15536585450172424
    },
    {
      "name": "Composite material",
      "score": 0.1470697522163391
    },
    {
      "name": "Voltage",
      "score": 0.13974037766456604
    },
    {
      "name": "Engineering",
      "score": 0.13316437602043152
    },
    {
      "name": "Thermodynamics",
      "score": 0.08537471294403076
    }
  ]
}