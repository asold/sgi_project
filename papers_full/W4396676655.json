{
  "title": "Evaluating large language models for annotating proteins",
  "url": "https://openalex.org/W4396676655",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2103361764",
      "name": "Rosario Vitale",
      "affiliations": [
        "Consejo Nacional de Investigaciones Científicas y Técnicas"
      ]
    },
    {
      "id": "https://openalex.org/A2051111755",
      "name": "Leandro A Bugnon",
      "affiliations": [
        "Consejo Nacional de Investigaciones Científicas y Técnicas"
      ]
    },
    {
      "id": null,
      "name": "Emilio Luis Fenoy",
      "affiliations": [
        "Consejo Nacional de Investigaciones Científicas y Técnicas"
      ]
    },
    {
      "id": "https://openalex.org/A2308529935",
      "name": "Diego H. Milone",
      "affiliations": [
        "Consejo Nacional de Investigaciones Científicas y Técnicas"
      ]
    },
    {
      "id": "https://openalex.org/A2251260371",
      "name": "Georgina Stegmayer",
      "affiliations": [
        "Consejo Nacional de Investigaciones Científicas y Técnicas"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4309506674",
    "https://openalex.org/W2055043387",
    "https://openalex.org/W2161880345",
    "https://openalex.org/W3095583226",
    "https://openalex.org/W4213112325",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W2791796577",
    "https://openalex.org/W4223644783",
    "https://openalex.org/W4320731502",
    "https://openalex.org/W6636510571",
    "https://openalex.org/W2395579298",
    "https://openalex.org/W3157437194",
    "https://openalex.org/W4283588627",
    "https://openalex.org/W3177500196",
    "https://openalex.org/W4220991280",
    "https://openalex.org/W4319986496",
    "https://openalex.org/W3042645205",
    "https://openalex.org/W2165698076",
    "https://openalex.org/W4224316211",
    "https://openalex.org/W4311440935",
    "https://openalex.org/W4360752063",
    "https://openalex.org/W4323348670",
    "https://openalex.org/W6637298292",
    "https://openalex.org/W2036963181",
    "https://openalex.org/W1649754194",
    "https://openalex.org/W4280547045",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6798272402",
    "https://openalex.org/W4327550249",
    "https://openalex.org/W2949342052",
    "https://openalex.org/W2138122982",
    "https://openalex.org/W2787894218",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W4212774754",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2009086942",
    "https://openalex.org/W4207080468"
  ],
  "abstract": "Abstract In UniProtKB, up to date, there are more than 251 million proteins deposited. However, only 0.25% have been annotated with one of the more than 15000 possible Pfam family domains. The current annotation protocol integrates knowledge from manually curated family domains, obtained using sequence alignments and hidden Markov models. This approach has been successful for automatically growing the Pfam annotations, however at a low rate in comparison to protein discovery. Just a few years ago, deep learning models were proposed for automatic Pfam annotation. However, these models demand a considerable amount of training data, which can be a challenge with poorly populated families. To address this issue, we propose and evaluate here a novel protocol based on transfer learningṪhis requires the use of protein large language models (LLMs), trained with self-supervision on big unnanotated datasets in order to obtain sequence embeddings. Then, the embeddings can be used with supervised learning on a small and annotated dataset for a specialized task. In this protocol we have evaluated several cutting-edge protein LLMs together with machine learning architectures to improve the actual prediction of protein domain annotations. Results are significatively better than state-of-the-art for protein families classification, reducing the prediction error by an impressive 60% compared to standard methods. We explain how LLMs embeddings can be used for protein annotation in a concrete and easy way, and provide the pipeline in a github repo. Full source code and data are available at https://github.com/sinc-lab/llm4pfam",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7888116836547852
    },
    {
      "name": "UniProt",
      "score": 0.776344895362854
    },
    {
      "name": "Annotation",
      "score": 0.7524881362915039
    },
    {
      "name": "Pipeline (software)",
      "score": 0.6090934872627258
    },
    {
      "name": "Artificial intelligence",
      "score": 0.49901390075683594
    },
    {
      "name": "Hidden Markov model",
      "score": 0.49516597390174866
    },
    {
      "name": "Protocol (science)",
      "score": 0.46276751160621643
    },
    {
      "name": "Named-entity recognition",
      "score": 0.4540404677391052
    },
    {
      "name": "Protein sequencing",
      "score": 0.44003167748451233
    },
    {
      "name": "Machine learning",
      "score": 0.42479202151298523
    },
    {
      "name": "Task (project management)",
      "score": 0.3992918133735657
    },
    {
      "name": "Natural language processing",
      "score": 0.3595789074897766
    },
    {
      "name": "Programming language",
      "score": 0.12505924701690674
    },
    {
      "name": "Peptide sequence",
      "score": 0.10998943448066711
    },
    {
      "name": "Biology",
      "score": 0.10840749740600586
    },
    {
      "name": "Gene",
      "score": 0.08746743202209473
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Pathology",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Alternative medicine",
      "score": 0.0
    }
  ]
}