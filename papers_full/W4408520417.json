{
  "title": "Large language models can consistently generate high-quality content for election disinformation operations",
  "url": "https://openalex.org/W4408520417",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5107940908",
      "name": "Angus R. Williams",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5107124353",
      "name": "Liam Burke-Moore",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5109779958",
      "name": "Ryan Sze-Yin Chan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4281094490",
      "name": "Florence E Enock",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2345325025",
      "name": "Federico Nanni",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5094282474",
      "name": "Tvesha Sippy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2323615101",
      "name": "Yi-Ling Chung",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2936281889",
      "name": "Evelina Gabašová",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4281349537",
      "name": "Kobi Hackenburg",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2001789594",
      "name": "Jonathan Bright",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4401042604",
    "https://openalex.org/W4389767727",
    "https://openalex.org/W3203399128",
    "https://openalex.org/W4387801479",
    "https://openalex.org/W4391632220",
    "https://openalex.org/W3032046549",
    "https://openalex.org/W4386572529",
    "https://openalex.org/W4391985880",
    "https://openalex.org/W4391801057",
    "https://openalex.org/W4399426804",
    "https://openalex.org/W4399911941",
    "https://openalex.org/W4323347737",
    "https://openalex.org/W4307934016",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W3212496002",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W6858023062",
    "https://openalex.org/W4390041933",
    "https://openalex.org/W4392822465",
    "https://openalex.org/W4405621269",
    "https://openalex.org/W6852874933",
    "https://openalex.org/W4386499643",
    "https://openalex.org/W4206828928",
    "https://openalex.org/W4401042900",
    "https://openalex.org/W1837843568",
    "https://openalex.org/W4296413526",
    "https://openalex.org/W4404173792",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3121596465",
    "https://openalex.org/W3125182500",
    "https://openalex.org/W4399528455",
    "https://openalex.org/W4380353763"
  ],
  "abstract": "Advances in large language models have raised concerns about their potential use in generating compelling election disinformation at scale. This study presents a two-part investigation into the capabilities of LLMs to automate stages of an election disinformation operation. First, we introduce DisElect, a novel evaluation dataset designed to measure LLM compliance with instructions to generate content for an election disinformation operation in localised UK context, containing 2,200 malicious prompts and 50 benign prompts. Using DisElect, we test 13 LLMs and find that most models broadly comply with these requests; we also find that the few models which refuse malicious prompts also refuse benign election-related prompts, and are more likely to refuse to generate content from a right-wing perspective. Secondly, we conduct a series of experiments ( N = 2 , 340) to assess the “humanness” of LLMs: the extent to which disinformation operation content generated by an LLM is able to pass as human-written. Our experiments suggest that almost all LLMs tested released since 2022 produce election disinformation operation content indiscernible by human evaluators over 50% of the time. Notably, we observe that multiple models achieve above-human levels of humanness . Taken together, these findings suggest that current LLMs can be used to generate high-quality content for election disinformation operations, even in hyperlocalised scenarios, at far lower costs than traditional methods, and offer researchers and policymakers an empirical benchmark for the measurement and evaluation of these capabilities in current and future models.",
  "full_text": null,
  "topic": "Disinformation",
  "concepts": [
    {
      "name": "Disinformation",
      "score": 0.9827717542648315
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5512548089027405
    },
    {
      "name": "Computer science",
      "score": 0.5428412556648254
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.4794867932796478
    },
    {
      "name": "Computer security",
      "score": 0.3734220862388611
    },
    {
      "name": "Social media",
      "score": 0.3552526831626892
    },
    {
      "name": "Internet privacy",
      "score": 0.3512004613876343
    },
    {
      "name": "World Wide Web",
      "score": 0.16253769397735596
    },
    {
      "name": "Biology",
      "score": 0.12195876240730286
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210128584",
      "name": "The Alan Turing Institute",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I40120149",
      "name": "University of Oxford",
      "country": "GB"
    }
  ],
  "cited_by": 5
}