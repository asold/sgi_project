{
  "title": "Using Related Languages to Enhance Statistical Language Models",
  "url": "https://openalex.org/W2474547741",
  "year": 2016,
  "authors": [
    {
      "id": "https://openalex.org/A5057417152",
      "name": "Anna Currey",
      "affiliations": [
        "Saarland University"
      ]
    },
    {
      "id": "https://openalex.org/A5047533259",
      "name": "Alina Karakanta",
      "affiliations": [
        "Saarland University"
      ]
    },
    {
      "id": "https://openalex.org/A5057722634",
      "name": "Jon Dehdari",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W273093436",
    "https://openalex.org/W2160817315",
    "https://openalex.org/W4629839",
    "https://openalex.org/W1526974435",
    "https://openalex.org/W2250300493",
    "https://openalex.org/W1974967573",
    "https://openalex.org/W4255764218",
    "https://openalex.org/W2097661835",
    "https://openalex.org/W22168010",
    "https://openalex.org/W72691019",
    "https://openalex.org/W2950186769",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2124807415",
    "https://openalex.org/W2163108352",
    "https://openalex.org/W2117717100",
    "https://openalex.org/W2119202242",
    "https://openalex.org/W2134800885",
    "https://openalex.org/W2097927681",
    "https://openalex.org/W4242239371",
    "https://openalex.org/W2250629652",
    "https://openalex.org/W2161563551",
    "https://openalex.org/W2167490942",
    "https://openalex.org/W2137387514",
    "https://openalex.org/W1631260214",
    "https://openalex.org/W1934041838",
    "https://openalex.org/W2408655637",
    "https://openalex.org/W222053410",
    "https://openalex.org/W2137698233",
    "https://openalex.org/W2595715041"
  ],
  "abstract": "The success of many language modeling methods and applications relies heavily on the amount of data available.This problem is further exacerbated in statistical machine translation, where parallel data in the source and target languages is required.However, large amounts of data are only available for a small number of languages; as a result, many language modeling techniques are inadequate for the vast majority of languages.In this paper, we attempt to lessen the problem of a lack of training data for low-resource languages by adding data from related high-resource languages in three experiments.First, we interpolate language models trained on the target language and on the related language.In our second experiment, we select the sentences most similar to the target language and add them to our training corpus.Finally, we integrate data from the related language into a translation model for a statistical machine translation application.Although we do not see many significant improvements over baselines trained on a small amount of data in the target language, we discuss some further experiments that could be attempted in order to augment language models and translation models with data from related languages.",
  "full_text": "Proceedings of NAACL-HLT 2016, pages 116–123,\nSan Diego, California, June 12-17, 2016.c⃝2016 Association for Computational Linguistics\nUsing Related Languages to Enhance Statistical Language Models\nAnna Currey, Alina Karakanta\nDepartment of Computational Linguistics, Saarland University, Saarbr¨ucken, Germany\namscurrey@gmail.com, alinak@coli.uni-saarland.de\nAbstract\nThe success of many language modeling\nmethods and applications relies heavily on the\namount of data available. This problem is fur-\nther exacerbated in statistical machine trans-\nlation, where parallel data in the source and\ntarget languages is required. However, large\namounts of data are only available for a small\nnumber of languages; as a result, many lan-\nguage modeling techniques are inadequate for\nthe vast majority of languages. In this paper,\nwe attempt to lessen the problem of a lack of\ntraining data for low-resource languages by\nadding data from related high-resource lan-\nguages in three experiments. First, we interpo-\nlate language models trained on the target lan-\nguage and on the related language. In our sec-\nond experiment, we select the sentences most\nsimilar to the target language and add them\nto our training corpus. Finally, we integrate\ndata from the related language into a transla-\ntion model for a statistical machine translation\napplication. Although we do not see many sig-\nniﬁcant improvements over baselines trained\non a small amount of data in the target lan-\nguage, we discuss some further experiments\nthat could be attempted in order to augment\nlanguage models and translation models with\ndata from related languages.\n1 Introduction\nStatistical language modeling methods are an essen-\ntial part of many language processing applications,\nincluding automatic speech recognition (Stolcke,\n2002), machine translation (Kirchhoff and Yang,\n2005), and information retrieval (Liu and Croft,\n2005). However, their success is heavily dependent\non the availability of suitably large text resources for\ntraining (Chen and Goodman, 1996). Such data can\nbe hard to obtain, especially for low-resource lan-\nguages. This problem is especially acute when lan-\nguage modeling is used in statistical machine trans-\nlation, where a lack of parallel resources for a lan-\nguage pair can be a signiﬁcant detriment to quality.\nOur goal is to exploit a high-resource language\nto improve modeling of a related low-resource lan-\nguage, which is applicable to cases where the tar-\nget language is closely related to a language with a\nlarge amount of text data available. For example,\nlanguages that are not represented in the European\nParliament, such as Catalan, can be aided by related\nlanguages that are, such as Spanish. The data avail-\nable from the related high-resource language can be\nadapted in order to add to the translation model or\nthe language model of the target language. This pa-\nper is an initial attempt at using minimally trans-\nformed data from a related language to enhance lan-\nguage models and increase parallel data for SMT.\n2 Background and Previous Work\n2.1 Domain Adaptation\nThis problem can be seen as a special case of domain\nadaptation, with the in-domain data being the data in\nthe target language and the out-of-domain data be-\ning the data in the related language (Nakov and Ng,\n2012). Domain adaptation is often used to leverage\nresources for a speciﬁc domain, such as biomedi-\ncal text, from more general domains like newswire\ndata (Dahlmeier and Ng, 2010). This idea can be\napplied to SMT, where data from the related lan-\n116\nguage can be adapted to look like data from the low-\nresource language. It has been shown that training\non a large amount of adapted text signiﬁcantly im-\nproves results compared to training on a small in-\ndomain corpus or training on unadapted data (Wang\net al., 2012). In this paper, we apply two particular\ndomain adaptation approaches. First, we interpolate\nlanguage models from in-domain and out-of-domain\ndata, following Koehn and Schroeder (2007). We\nalso attempt to select the best out-of-domain data us-\ning perplexity, similar to what was done in Gao et al.\n(2002).\n2.2 Machine Translation\nIn contrast to transfer-based and word-based ma-\nchine translation, for statistical machine translation,\nquality is heavily dependent on the amount of par-\nallel resources. Given the difﬁculty of obtaining\nsufﬁcient parallel resources, this can be a prob-\nlem for many language pairs. For those cases, a\nthird language can be used as a pivot. The pro-\ncess of using a third language as a bridge instead\nof directly translating is called triangulation (Singla\net al., 2014). Character-level translation combined\nwith word-level translation has also been shown to\nbe an improvement over phrase-based approaches\nfor closely related languages (Nakov and Tiede-\nmann, 2012). Similarly, transliteration methods us-\ning cognate extraction (Nakov and Ng, 2012) and\nbilingual dictionaries (Kirschenbaum and Wintner,\n2010) can be used to aid the low-resource language.\n3 Experimental Framework\n3.1 Choice of Languages\nFor the purpose of our experiments, we treat Spanish\nas if it were a low-resource language and test Span-\nish language models and English-Spanish transla-\ntions. We use Italian and Portuguese as the closely-\nrelated languages. Using these languages for our ex-\nperiments allows us to compare the results to the lan-\nguage models and machine translations that can be\ncreated using large corpora.\nSpanish, Portuguese, and Italian all belong to\nthe Romance family of Indo-European languages.\nSpanish has strong lexical similarity with both Por-\ntuguese (89%) and Italian (82%) (Lewis, 2015).\nAmong major Romance languages, Spanish and\nPortuguese have been found to be the closest pair in\nautomatic corpus comparisons (Ciobanu and Dinu,\n2014) and in comprehension studies (V oigt and\nGooskens, 2014), followed by Spanish and Italian.\n3.2 Data\nWe used the Europarl corpus (Koehn, 2005) for\ntraining and testing. In order to use the data in our\nexperiments, we tokenized 1 the corpus, converted\nall words to lowercase, and collapsed all numeri-\ncal symbols into one special symbol. Finally, we\ntransliterated the Italian and Portuguese corpora to\nmake them more Spanish-like; this process is de-\nscribed in section 3.3.\nThe data that was used to train, test and develop is\nsplit as follows: 10% of the Spanish data (196,221\nsentences) was used for testing, 10% for develop-\nment, and the remaining 80% (1,569,771 sentences)\nfor training. The Italian and Portuguese corpora\nwere split similarly and training sizes for the models\nvaried between 30K and 1,523,304 and 1,566,015\nsentences for Italian and Portuguese, respectively.\n3.3 Transliteration\nIn order to use Italian and Portuguese data to\nmodel Spanish, we ﬁrst transliterated the Italian\nand Portuguese training corpora using a naive rule-\nbased transliteration method consisting of word-\nlevel string transformations and a small bilingual\ndictionary. For the bilingual dictionary, the 200 most\ncommon words were extracted from the Italian and\nthe Portuguese training corpora and manually given\nSpanish translations. In translating to Spanish, an ef-\nfort was made to keep cognates where possible, and\nto use the most likely or common meanings.\nTable 1 gives translations used for the ten most\ncommon Italian words in the data. Even in this small\nsample, there is a problematic translation. The Ital-\nian preposition per can be translated to por or para.\nIn keeping with the desire to use a small amount\nof data, we brieﬂy read the Italian texts to ﬁnd the\ntranslation we felt was more likely (para), and chose\nthat as the translation for all instances of per in the\ntraining set. We also veriﬁed that para was more\nlikely in the Spanish training text overall than por.\n1We used the Tok-tok tokenizer by Jon Dehdari:\nhttps://github.com/jonsafari/tok-tok\n117\nItalian Spanish Gloss\ndi de of\ne y and\nche que that\nla la the (f. sg.)\nin en in\nil el the (m. sg.)\nper para for\na a to\n`e es is\nun un a (m. sg.)\nTable 1:Sample Italian-Spanish translations.\nThe rule-based component of the transliteration\nconsisted of handwritten word-initial, word-ﬁnal,\nand general transformation rules. We applied ap-\nproximately ﬁfty such rules per language to the data.\nIn order to come up with the rules, we examined\nthe pan-Romance vocabulary list compiled by Euro-\nComRom (Klein, 2002); however, such rules could\nbe derived by an expert with knowledge of the rel-\nevant languages with relatively little effort. Char-\nacter clusters that were impossible in Spanish were\nconverted to their most common correspondence in\nSpanish (in the word list). We also identiﬁed certain\nstrings that had consistent correspondences in Span-\nish and replaced them appropriately. These rules\nwere applied to all words in the Italian and Por-\ntuguese training data except for those that were in\nthe bilingual dictionary. See table 2 for examples of\nstring transformation rules used for the Italian case.\nType Original Translit. Example\ninitial sp esp Spagna\ninitial qua cua qualit`a\ninitial st est stare\nﬁnal ssioni siones impressioni\nﬁnal are ar stare\nﬁnal t`a dad qualit`a\ngeneral gn ˜n Spagna\ngeneral vv v improvviso\ngeneral `o o per`o\nTable 2:Sample Italian-Spanish transliterations.\nItalian text\nLa difﬁcolt`a di conciliare questi obiettivi risiede\nnel fatto che le logiche di questi settori sono\ncontraddittorie.\nTransliteration into Spanish\nLa diﬁcoldad de conciliar estos obietivos risiede\nen el hecho que las logique de estos setores son\ncontraditorie.\nTable 3:Example of transliterated text using our approach.\n4 Experiments\n4.1 Experiment 1: Language Model\nInterpolation\nOur ﬁrst experiment attempted to use language mod-\nels trained on the transliterated data to increase the\ncoverage of a language model based on Spanish\ndata; this was modeled after Koehn and Schroeder\n(2007). The language models in this experiment\nwere trigram models with Good-Turing smoothing\nbuilt using SRILM (Stolcke, 2002).\nAs baselines, we trained Spanish ( es) LMs on a\nsmall amount (30K sentences) and a large amount\n(1.5M sentences) of data. We also trained language\nmodels based on 30K transliterated and standard\nItalian (it) and Portuguese ( pt) sentences. All were\ntested on the Spanish test set. Table 4 shows the per-\nplexity for each of the baselines. As expected, more\nSpanish training data led to a lower perplexity. How-\never, the transliterated Italian and Portuguese base-\nlines yielded better perplexity with less data. Note\nalso the strong effect of transliteration.\nLanguage Train Size PP\nes 30K 93.49\nes 1.5M 55.84\nit 30K 1683.31\nit translit. 30K 96.21\nit translit. 1.5M 207.60\npt 30K 1877.23\npt translit. 30K 151.06\npt translit. 1.5M 251.53\nTable 4:Baseline results for experiment 1.\nIn the experiment, we interpolated LMs trained\non different amounts of transliterated data with the\nLM trained on 30K Spanish sentences. We used\n118\nSRILM’s compute-best-mix tool to determine the\ninterpolation weights of the models. This parame-\nter was trained on the Spanish development set.\nTable 5 shows the results for the interpolation\nof the Spanish LM with Italian and Portuguese,\nboth separately and simultaneously. The lambda\nvalues are the weights given to each of the lan-\nguage models. None of the interpolated combi-\nnations improves on the perplexity of the small-\nest Spanish baseline. The best results for interpo-\nlated language models are achieved when combin-\ning the 30K-sentence Spanish model with the 1.5M-\nsentence Portuguese model, which almost reaches\nthe perplexity level of the Spanish-only model. As a\ncomparison, we also interpolated two separate lan-\nguage models, each trained on 30K Spanish sen-\ntences; the weight for these models was close to 0.5.\nIn the best-performing language model mix that\nused all three languages, Portuguese was weighted\nwith a lambda of about 0.17, whereas Italian was\nonly weighted with 0.016. That shows that Por-\ntuguese, in this setup, is a better model of Spanish.\nAn open question has to do with the performance\nof the Portuguese language model in the experiment\ncompared to the baselines. In table 4, we see that\nthe language model does signiﬁcantly worse when\ntrained on more Portuguese data. However, the in-\nterpolation of the Spanish and Portuguese language\nmodels yields a lower perplexity when trained on a\nlarge amount of Portuguese data. Since the data was\nidentical in the baselines and experiments, further\nexploration is needed to understand this behavior.\n4.2 Experiment 2: Corpus Selection\nFor our second experiment, our goal was to se-\nlect the most “Spanish-like” data from our Italian\nand Portuguese corpora. We concatenated this data\nwith the Spanish sentences in order to increase the\namount of training data for the language model. This\nis similar to what was done by Gao et al. (2002).\nFirst, we trained a language model on our small\nSpanish corpus. This language model was then\nqueried on a concatenation of the transliterated Ital-\nian and Portuguese data. The sentences in this cor-\npus were ranked according to their perplexity in the\nSpanish LM. We selected the best 30K and 5K sen-\ntences, which were then concatenated with the Span-\nish data to form a larger corpus. Finally, we used\nKenLM (Heaﬁeld, 2011) to create a trigram lan-\nguage model with Kneser-Ney smoothing (Kneser\nand Ney, 1995) on that data. We also ran the same\nexperiment on Italian and Portuguese separately.\nTable 6 gives the results from these experiments.\nThis table shows that the mixed-language models\nfor each language performed better when they had\na lower amount of non-Spanish data. This indicates\nthat it is better to simply use a small amount of\ndata in the low-resource language, rather than try-\ning to augment it with the transliterated data from\nrelated languages. Using a smaller amount of the\nSpanish data, having a different strategy for select-\ning the non-Spanish data, using a different translit-\neration method, or using Italian and Portuguese data\nthat was not a direct translation of the Spanish data\nmay have all led to improvements. It is also inter-\nesting to note that the language models based on\nthe corpus containing only Portuguese performed al-\nmost as well as those based on the corpus containing\nPortuguese and Italian. This indicates that the Por-\ntuguese data likely had more Spanish-like sentences\nthan the Italian data. As mentioned in section 3.1,\nPortuguese is more similar to Spanish, so this makes\nintuitive sense. However, it is surprising given the\nresults in table 4, which shows that the Italian-only\nlanguage models performed better on Spanish data\nthan the Portuguese-only language models.\n4.3 Experiment 3: Statistical Machine\nTranslation\nLastly, we experimented with translation models in\norder to see if our approach yielded similar results.\nFor our baseline, we used a small parallel corpus\nof 30K English-Spanish ( en-es) sentences from the\nEuroparl corpus (Koehn, 2005). The data was pre-\nprocessed as described in section 3.2. Since SMT\nsystems are often trained on large amounts of data,\nwe expected poor coverage with this dataset. How-\never, this size would be representative of the amount\nof data available for low-resource languages.\nWe used Moses (Koehn et al., 2007) to train our\nphrase-based SMT system on the above mentioned\nparallel corpus (en-es). We also trained a language\nmodel of 5M words of Spanish data from the same\nsource, making sure that this data was strictly dis-\ntinct from our parallel data. The language model\nwas trained using KenLM (Heaﬁeld, 2011). The\n119\nLanguages Sentences PP Lambda es Lambda it Lambda pt\nes + es 30K + 30K 86.59 0.502\nes + it 30K + 30K 95.19 0.9818 0.0182\nes + it 30K + 100K 96.08 0.9716 0.0284\nes + it 30K + 200K 96.49 0.9648 0.0352\nes + it 30K + 1.5M 96.91 0.9493 0.0507\nes + pt 30K + 30K 95.51 0.9340 0.0660\nes + pt 30K + 100K 95.93 0.8939 0.1061\nes + pt 30k + 200K 95.71 0.8709 0.1291\nes + pt 30k + 1.5M 93.52 0.8170 0.1830\nes + it + pt 30K + 30K + 30K 95.52 0.9298 0.0093 0.0608\nes + it + pt 30K + 100K + 100K 95.94 0.8882 0.0126 0.0991\nes + it + pt 30K + 200K + 200K 95.72 0.8655 0.0137 0.1207\nes + it + pt 30K + 1.5M + 1.5M 93.53 0.8106 0.0161 0.1731\nTable 5:Results of interpolated language models and optimal lambda values.\nLanguages Sentences PP\nes 30K 84.57\nes + it 30K + 5K 85.78\nes + it 30K + 30K 94.10\nes + pt 30K + 5K 85.11\nes + pt 30K + 30K 90.31\nes + it/pt 30K + 5K 85.13\nes + it/pt 30K + 30K 90.24\nTable 6:Results for the corpus selection experiment.\nweights were set by optimizing BLEU using MERT\non a separate development set of 2,000 sentences\n(English-Spanish). After decoding, we detokenized\nand evaluated the output. For the evaluation, we\nused a clean Spanish test set of 2,000 sentences\nfrom the same source. As an automatic evaluation\nmeasure, we used BLEU (Papineni et al., 2002) for\nquantitative evaluation.\nFor our experiments, we used Italian and Por-\ntuguese as auxiliary languages. We created two cor-\npora of 30K sentences each from the Europarl cor-\npus, en-it and en-pt. We ﬁrst tokenized and translit-\nerated the training corpus of the related language\nas described in section 3.3. Then, we concatenated\nthe resulting corpora with our baseline corpus and\ntrained our model. This is similar to what was done\nby Nakov and Ng (2012), although we attempt to\ntranslate into the low-resource language. We ﬁrst\nexperimented with each auxiliary language indepen-\ndently and then with both languages. In total we\nconducted the following experiments:\n• English-Spanish ( en-es) + English-Italian\ntransliterated (en-esit)\n• English-Spanish (en-es) + English-Portuguese\ntransliterated (en-espt)\n• English-Spanish ( en-es) + English-Italian\ntransliterated ( en-esit) + English-Portuguese\ntransliterated (en-espt)\nIn this experiment, we expected to observe some\nimprovements compared to the language modeling\nexperiments, as the mistakes in the transliterated\noutput could be ﬁltered out by the language model\ncontaining clean Spanish data. Moreover, we exam-\nined whether it is possible to have gains from using\nmultiple related languages simultaneously.\nLanguages Sentences BLEU p-value\nen-es (Baseline) 30K 0.3360\nen-es + en-esit 30K + 30K 0.3357 0.22\nen-es + en-espt 30K + 30K 0.3349 0.08\nen-es + en-esit +\nen-espt\n30K + 30K\n+ 30K 0.3384 0.041\nTable 7: BLEU scores obtained for the different training sets\nand their sizes.\nTable 7 shows the BLEU scores for the experi-\nments. To determine whether our results were sig-\nniﬁcant we used the bootstrap resampling method\n120\n(Koehn, 2004), which is part of Moses. There were\nno signiﬁcant improvements in BLEU score when\nonly one auxiliary language was used. Nonetheless,\nwe observed a signiﬁcant improvement when data\nfrom both Italian and Portuguese is used. This may\nbe an indication that more out-of domain data, when\nused in the translation model and sufﬁciently trans-\nformed, can actually improve performance.\nOne open question at this point is whether the im-\nprovement was caused by the contribution of more\nthan one language or simply by the increase in train-\ning data. It is possible that a similar improvent could\nbe achieved by increasing the data of one language\nto 60K. However, in order to support our conjecture,\nit will be necessary to conduct experiments with dif-\nferent sizes and combinations of data from the re-\nlated languages.\n5 Discussion\nWe observed that a closely-related language cannot\nbe used to aid in modeling a low-resource language\nwithout being properly transformed. Although our\nnaive rule-based transliteration method strongly im-\nproved over the non-transliterated closely-related\nlanguage data, it performed worse than even a small\namount of target language data. In addition, adding\nmore data from the related language caused the\nmodels to do worse; this may be because there were\nmore words in the data that were not translated\nusing the 200-word dictionary, so there was more\nnoise from the rule-based transliterations in the data.\nThus, we were not successful in using data from a\nrelated language to improve language modeling for\na low-resource language.\nFor statistical machine translation, our results\nshow gains from augmenting the translation mod-\nels of a low-resource language with transliterated\nrelated-language data. We expect that by taking\nadvantage of more sophisticated transliteration and\ninterpolation methods as well as larger amounts of\ndata from the closely-related language(s), larger im-\nprovements in BLEU can be achieved.\n6 Future Work\nWe plan on experimenting with more sophisticated\nways of transforming related language data, includ-\ning unsupervised and semi-supervised translitera-\ntion methods. We would particularly like to exper-\niment with neural network machine transliteration\nusing a character-based LSTM network. This could\nbe developed based on small parallel texts or lists of\nbilingual cognates of varying sizes. We could also\nuse existing transliteration modules integrated in the\nSMT system (Durrani et al., 2014). In addition, we\nhope to explore using bilingual dictionaries without\ntransliteration, as well as using phonological tran-\nscription as an intermediary between the two related\nlanguages. Finally, it would be beneﬁcial to examine\nthe contribution of each of the rules in our rule-based\nsystem separately.\nA relatively simple modiﬁcation to our experi-\nments would be to use more data in creating the\ntranslation model (in experiment 3). While we found\nthat using more of the high-resource language data\nin the language models yielded higher perplexity,\nthe same did not carry over to BLEU scores, espe-\ncially since we saw a slight improvement in BLEU\nscore when using both Portuguese and Italian data.\nA similar option would be to select the best Italian\nand Portuguese data (as was done in experiment 2)\nfor use in the translation model, instead of selecting\nrandom sentences.\nIn statistical machine translation, it would be in-\nteresting to explore methods of using data from re-\nlated languages while preserving the reliable infor-\nmation from the low-resource language. One idea\ncould be methods for interpolating phrase tables for\nthe transliterated corpora as well as setting optimal\nweights for each of them, similar to the approach of\nSennrich (2012). We would also like to improve the\ntranslation model coverage by ﬁlling up the phrase\ntable for a low-resource language with data from a\nrelated language while keeping the useful data from\nthe low-resource language (Bisazza et al., 2011) or\nby using the related languages as a back-off (Yang\nand Kirchhoff, 2006).\nFinally, a weakness of our language modeling ex-\nperiments was that we used almost parallel data be-\ntween the related and the target languages. Hence,\nthe related language was not likely to increase the\nvocabulary coverage of the models; instead, it just\nadded misspellings of the target language words. In\nthe future, we would like to run experiments with\ndata from the related languages that is strictly dis-\ntinct from the data of the low-resource language.\n121\nReferences\nArianna Bisazza, Nick Ruiz, and Marcello Federico.\n2011. Fill-up versus interpolation methods for phrase-\nbased SMT adaptation. In IWSLT, pages 136–143.\nStanley F Chen and Joshua Goodman. 1996. An empir-\nical study of smoothing techniques for language mod-\neling. In Proceedings of the 34th Annual Meeting of\nthe Association for Computational Linguistics , pages\n310–318. Association for Computational Linguistics.\nAlina Maria Ciobanu and Liviu P Dinu. 2014. On the\nRomance languages mutual intelligibility. In Proceed-\nings of the 9th International Conference on Language\nResources and Evaluation, LREC, pages 3313–3318.\nDaniel Dahlmeier and Hwee Tou Ng. 2010. Domain\nadaptation for semantic role labeling in the biomedical\ndomain. Bioinformatics, 26(8):1098–1104.\nNadir Durrani, Hieu Hoang, Philipp Koehn, and Hassan\nSajjad. 2014. Integrating an unsupervised translitera-\ntion model into statistical machine translation. EACL\n2014, page 148.\nJianfeng Gao, Joshua Goodman, Mingjing Li, and Kai-\nFu Lee. 2002. Toward a uniﬁed approach to statistical\nlanguage modeling for Chinese. ACM Transactions\non Asian Language Information Processing (TALIP) ,\n1(1):3–33.\nKenneth Heaﬁeld. 2011. KenLM: Faster and smaller\nlanguage model queries. In Proceedings of the Sixth\nWorkshop on Statistical Machine Translation , pages\n187–197. Association for Computational Linguistics.\nKatrin Kirchhoff and Mei Yang. 2005. Improved lan-\nguage modeling for statistical machine translation. In\nProceedings of the ACL Workshop on Building and\nUsing Parallel Texts, pages 125–128. Association for\nComputational Linguistics.\nAmit Kirschenbaum and Shuly Wintner. 2010. A gen-\neral method for creating a bilingual transliteration dic-\ntionary. In LREC.\nHorst G Klein. 2002. Eurocom-Rezeptive\nMehrsprachigkeit und Neue Medien.\nReinhard Kneser and Hermann Ney. 1995. Improved\nbacking-off for m-gram language modeling. In Acous-\ntics, Speech, and Signal Processing, 1995. ICASSP-\n95., 1995 International Conference on , volume 1,\npages 181–184. IEEE.\nPhilipp Koehn and Josh Schroeder. 2007. Experiments in\ndomain adaptation for statistical machine translation.\nIn Proceedings of the Second Workshop on Statistical\nMachine Translation, pages 224–227. Association for\nComputational Linguistics.\nPhilipp Koehn, Hieu Hoang, Alexandra Birch, Chris\nCallison-Burch, Marcello Federico, Nicola Bertoldi,\nBrooke Cowan, Wade Shen, Christine Moran, Richard\nZens, et al. 2007. Moses: Open source toolkit for\nstatistical machine translation. In Proceedings of the\n45th annual meeting of the ACL on interactive poster\nand demonstration sessions, pages 177–180. Associa-\ntion for Computational Linguistics.\nPhilipp Koehn. 2004. Statistical signiﬁcance tests for\nmachine translation evaluation. In Dekang Lin and\nDekai Wu, editors, Proceedings of EMNLP 2004 ,\npages 388–395, Barcelona, Spain, July. Association\nfor Computational Linguistics.\nPhilipp Koehn. 2005. Europarl: A parallel corpus for sta-\ntistical machine translation. In MT Summit, volume 5,\npages 79–86. Citeseer.\nM. Paul Lewis, editor. 2015. Ethnologue: Languages of\nthe World. SIL International, Dallas, TX, USA, eigh-\nteenth edition.\nXiaoyong Liu and W Bruce Croft. 2005. Statistical lan-\nguage modeling for information retrieval. Annual Re-\nview of Information Science and Technology, 39(1):1–\n31.\nPreslav Nakov and Hwee Tou Ng. 2012. Improving\nstatistical machine translation for a resource-poor lan-\nguage using related resource-rich languages. Journal\nof Artiﬁcial Intelligence Research, pages 179–222.\nPreslav Nakov and J ¨org Tiedemann. 2012. Combin-\ning word-level and character-level models for machine\ntranslation between closely-related languages. In Pro-\nceedings of the 50th Annual Meeting of the Association\nfor Computational Linguistics: Short Papers-Volume\n2, pages 301–305. Association for Computational Lin-\nguistics.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. BLEU: a method for automatic eval-\nuation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics , pages 311–318. Association for\nComputational Linguistics.\nRico Sennrich. 2012. Perplexity minimization for trans-\nlation model domain adaptation in statistical machine\ntranslation. In Proceedings of the 13th Conference of\nthe European Chapter of the Association for Compu-\ntational Linguistics , pages 539–549. Association for\nComputational Linguistics.\nKaran Singla, Nishkarsh Shastri, Megha Jhunjhunwala,\nAnupam Singh, Srinivas Bangalore, and Dipti Misra\nSharma. 2014. Exploring system combination ap-\nproaches for Indo-Aryan MT systems. LT4CloseLang\n2014, page 85.\nAndreas Stolcke. 2002. SRILM - an extensible language\nmodeling toolkit. In Proceedings of the 7th Inter-\nnational Conference on Spoken Language Processing\n(ICSLP 2002).\nStefanie V oigt and Charlotte Gooskens. 2014. Mutual\nintelligibility of closely related languages within the\n122\nRomance language family. Language Contact: The\nState of the Art, page 103.\nPidong Wang, Preslav Nakov, and Hwee Tou Ng. 2012.\nSource language adaptation for resource-poor machine\ntranslation. In Proceedings of the 2012 Joint Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and Computational Natural Language Learn-\ning, pages 286–296. Association for Computational\nLinguistics.\nMei Yang and Katrin Kirchhoff. 2006. Phrase-based\nbackoff models for machine translation of highly in-\nﬂected languages. In EACL, pages 3–7.\n123",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7943896651268005
    },
    {
      "name": "Natural language processing",
      "score": 0.5047615766525269
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4311278164386749
    },
    {
      "name": "Programming language",
      "score": 0.39112019538879395
    }
  ]
}