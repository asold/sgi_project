{
  "title": "Enhancing hepatopathy clinical trial efficiency: a secure, large language model-powered pre-screening pipeline",
  "url": "https://openalex.org/W4411307454",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5065249642",
      "name": "Xiongbin Gui",
      "affiliations": [
        "Guangxi University of Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A5038754214",
      "name": "Hanlin Lv",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5101644415",
      "name": "Xiao Wang",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5093889367",
      "name": "Longting Lv",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5111200041",
      "name": "Yi Xiao",
      "affiliations": [
        "Guangxi University of Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A5100436176",
      "name": "Lei Wang",
      "affiliations": [
        "BGI Group (China)",
        "Center for Life Sciences"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2144187699",
    "https://openalex.org/W2137767404",
    "https://openalex.org/W2758723248",
    "https://openalex.org/W2116972869",
    "https://openalex.org/W3001688612",
    "https://openalex.org/W3011079674",
    "https://openalex.org/W3012073911",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W2941773520",
    "https://openalex.org/W4392193048",
    "https://openalex.org/W4393339911",
    "https://openalex.org/W4388022708",
    "https://openalex.org/W4401042843",
    "https://openalex.org/W4377009978",
    "https://openalex.org/W6870095337",
    "https://openalex.org/W4385889719",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4400435090",
    "https://openalex.org/W4399795224",
    "https://openalex.org/W6856800273",
    "https://openalex.org/W6856398428",
    "https://openalex.org/W4399837985",
    "https://openalex.org/W4404486407",
    "https://openalex.org/W4394975332",
    "https://openalex.org/W4384008891",
    "https://openalex.org/W4403720177"
  ],
  "abstract": "This data-secure and time-efficient pipeline shows high precision and achieves good recall in hepatopathy trials, providing promising solutions for streamlining clinical trial workflows. Its efficiency, adaptability, and balanced performance profile make it suitable for improving patient recruitment. And its capability to function in resource-constrained environments further enhances its utility in clinical settings.",
  "full_text": "RESEARCH Open Access\n© The Author(s) 2025. Open Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International \nLicense, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate \ncredit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. \nYou do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party \nmaterial in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material \nis not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted \nuse, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p : /  / c r e a  t i v e c o  m m o n  s . o r g  / l i c e  n s \ne s / b  y - n c  - n d / 4 . 0 /.\nGui et al. BioData Mining           (2025) 18:42 \nhttps://doi.org/10.1186/s13040-025-00458-5\n†Xiongbin Gui and Hanlin Lv \ncontributed equally to this \nwork.\n*Correspondence:\nYi Xiao\n6128239@qq.com\nLei Wang\nwanglei12@genomics.cn\n1The First Affiliated Hospital of \nGuangxi University of Chinese \nMedicine, Nanning 530023, China\n2Institute of Biointellgence \nTechnology, BGI Research,  \nWuhan 430074, China\n3Guangdong Bigdata Engineering \nTechnology Research Center for Life \nSciences, BGI Research,  \nShenzhen 518083, China\nEnhancing hepatopathy clinical trial efficiency: \na secure, large language model-powered pre-\nscreening pipeline\nXiongbin Gui1†, Hanlin Lv2†, Xiao Wang2, Longting Lv2, Yi Xiao1* and Lei Wang2,3*\nBioData Mining\nAbstract\nBackground Recruitment for cohorts involving complex liver diseases, such as \nhepatocellular carcinoma and liver cirrhosis, often requires interpreting semantically \ncomplex criteria. Traditional manual screening methods are time-consuming and \nprone to errors. While AI-powered pre-screening offers potential solutions, challenges \nremain regarding accuracy, efficiency, and data privacy.\nMethods We developed a novel patient pre-screening pipeline that leverages clinical \nexpertise to guide the precise, safe, and efficient application of large language models. \nThe pipeline breaks down complex criteria into a series of composite questions \nand then employs two strategies to perform semantic question-answering through \nelectronic health records: (1) Pathway A, Anthropomorphized Experts’ Chain of Thought \nstrategy; and (2) Pathway B, Preset Stances within an Agent Collaboration strategy, \nparticularly in managing complex clinical reasoning scenarios. The pipeline is evaluated \non key metrics including precision, recall, time consumption, and counterfactual \ninference—at both the question and criterion levels.\nResults Our pipeline achieved a notable balance of high precision (e.g., 0.921, criteria \nlevel) and good overall recall (e.g., ~ 0.82, criteria level), alongside high efficiency (0.44s \nper task). Pathway B excelled in high-precision complex reasoning (while exhibiting \na specific recall profile conducive to accuracy), whereas Pathway A was particularly \neffective for tasks requiring both robust precision and recall (e.g., direct data extraction), \noften with faster processing times. Both pathways achieved comparable overall \nprecision while offering different strengths in the precision-recall trade-off. The pipeline \nshowed promising precision-focused results in hepatocellular carcinoma (0.878) and \ncirrhosis trials (0.843).\nConclusions This data-secure and time-efficient pipeline shows high precision \nand achieves good recall in hepatopathy trials, providing promising solutions \nfor streamlining clinical trial workflows. Its efficiency, adaptability, and balanced \nperformance profile make it suitable for improving patient recruitment. And its \ncapability to function in resource-constrained environments further enhances its utility \nin clinical settings.\nPage 2 of 15\nGui et al. BioData Mining           (2025) 18:42 \nBackground\nIn hepatology, the complexity of chronic diseases like cirrhosis, liver failure, and hepa -\ntocellular carcinoma demands meticulous patient selection for clinical research [ 1]. \nClinicians must navigate extensive electronic health records (EHRs) to identify patients \nwith specific diagnoses or treatments [ 2], such as esophageal varices or those undergo -\ning Transjugular Intrahepatic Portosystemic Shunt (TIPS). The challenge deepens when \nbroader categories like autoimmune diseases or prior beta-blocker therapy are involved, \nrequiring comprehensive evaluation [ 3]. Additionally, determining whether liver cancer \nis primary or secondary, identifying the causes of liver failure or cirrhosis, or recognizing \nsymptoms like jaundice adds further layers of complexity, necessitating detailed analysis \nand clinical insight. These tasks expose the limits of current methods. While traditional \nmanual screening and automated approaches have attempted to address these chal -\nlenges, they fall short in key areas [4].\nBidirectional Encoder Representations from Transformers (BERT)-based tools have \nbeen used for subject matching across various diseases while struggling with general -\nizability [4–7]. Large language models (LLMs), with their superior contextual semantic \nunderstanding, offer a promising avenue to overcome these limitations [ 8, 9]. Domain-\nspecific LLMs, fine-tuned on medical corpora or using knowledge graph embeddings, \nperform well in clinical text summarization [ 10, 11], note generation [12, 13], and medi-\ncal question answering [14]. However, EHR security policies commonly necessitate local \nLLM deployment, precluding the use of non-open-source models like Chat Generative \nPre-Trained Transformer (ChatGPT), Gemini, or Claude. Additionally, we believe the \nprimary challenge lies in the need for strategic support in complex reasoning rather than \nin domain-specific knowledge [ 15]. Thus, both domain-specific and general LLMs start \nfrom a similar point. Moreover, domain-specific LLMs’ extensive IT resource demands \noften exceed institutional capacities. Therefore, this study focuses on locally deployed \ngeneral open-source LLMs for practical reasons.\nOpen-source LLMs often face criticism in professional reasoning tasks for non-fac -\ntual hallucination and imbalanced attention focus [16]. To address these issues, effective \nstrategies have been engineered across various domains, including (1) Chain of Thought \n(CoT) prompting; (2) Agent-Collaboration (Agent-Collab) frameworks.\nCoT prompting and extensions  CoT prompting is a powerful method by breaking \ndown complex tasks into a series of intermediate steps [ 17]. Traditional “Let’s think step \nby step” approaches with few-shot learning cannot meet our complex reasoning needs. \nA typical approach involves using prompt engineering techniques to guide the model in \nexhibiting a thought process consistent with a benchmark individual. In this study, we \nintroduce “ Anthropomorphized Experts’ CoT” inspired by AI biomimicry. This method \nemulates human expert reasoning, derived from interviews and summarized into concise \nsteps. The principle is to break down complex thought processes into simple, manageable \nsteps.\nKeywords Patient recruitment, Electronic health records, Natural language processing, \nLiver disease, Eligibility criteria\nPage 3 of 15\nGui et al. BioData Mining           (2025) 18:42 \nAgent-collab frameworks  Leveraging the capabilities of LLMs in agent mode, where \nindependent agents collaborate, converse, and debate within an Agent-Collab frame -\nwork, has consistently been of interest. Compared to the consultative question-and-\nanswer model, the Agent-Collab architecture with debating agents excels in all aspects \n[18]. The Agent-Collab framework typically requires: 1) defining agent roles, and 2) set -\nting the number of dialogue rounds. Roles can be specified or predefined. In this study, \nwe employed a Counterfactual Debating with Preset Stances method, which has shown \nhigh consistency in existing research and indicates that two dialogue rounds yield the \nbest results [ 19]. The Agent-Collab framework can simulate a ‘mock trial’ scenario to \nidentify and rectify potential errors or biases in interpretation, ensuring a more accurate \nand comprehensive assessment of patient eligibility. Methods such as self-critique and \nreflection are also employed to confront the inherent biases of LLMs, compelling them to \nconsider alternative perspectives and generate more accurate outcomes.\nTo address domain knowledge gaps in locally deployed models, we use powerful non-\nopen-source LLMs to enhance non-sensitive inclusion/exclusion criteria. Building on \nthese advancements, our pipeline transforms complex logical issues into manageable \nsemantic tasks, creating a robust framework for patient pre-screening from admission \nnotes.\nMethods\nData preparation\nThe EHR data used in this study, specifically narrative admission notes, typically \nincluded sections such as chief complaint, history of present illness and past medi -\ncal history (a sample note is provided in Supplemental Material S1). These data were \nobtained from the First Affiliated Hospital of Guangxi University of Chinese Medicine \n(FAHGUCM). The dataset comprised over 16,000 anonymized admission notes from the \nHepatology Department collected over the past 10 years. For detailed analysis, we ran -\ndomly selected 4,000 records, which was representative of the overall dataset in terms of \nthe distribution of hepatopathy and associated clinical presentations.\nWe manually reviewed the inclusion and exclusion criteria of six real-world clinical \ntrials on hepatopathy, and carefully selected 58 criteria assessable using information \ntypically documented in admission notes. These criteria primarily focused on general \nhealth, medical history, and prior treatments, excluding those requiring specific labo -\nratory results or specialized examinations not routinely captured in admission notes \n(details in Supplemental Table S2). These trials addressed various liver conditions, \nincluding chronic liver failure (ChiCTR2100044187 [ 20]), cirrhosis (NCT04353193 [ 21], \nNCT04850534 [22], NCT03911037 [ 23], NCT01311167 [ 24]), and hepatocellular carci -\nnoma (NCT04021056 [25]).\nWe deployed four LLMs within an intranet security environment: Qwen1.5-7B-Chat-\nGPTQ-Int4 [26] (QWEN1.5), Baichuan2-13B-Chat [ 27] (BAICHUAN), ChatGLM3-6B \n[28] (GLM) and Qwen2-7B-Instruct-GPTQ-Int4 [ 26] (QWEN2). The experiments were \nconducted on Lenovo ST650V2 servers equipped with four NVIDIA GeForce RTX 3090 \nTurbo GPUs.\nPage 4 of 15\nGui et al. BioData Mining           (2025) 18:42 \nPipeline design\nThe core of our approach is a multi-strategy pipeline designed to systematically process \nnarrative admission notes, extracting relevant clinical information and applying logical \nreasoning. The architecture is detailed in Fig. 1.\nCriteria conversion We employed an external-CoT strategy, leveraging advanced non-\nopen-source LLMs (OpenAI ChatGPT-4o, Google Gemini Advanced, and Anthropic \nClaude 3.5 Sonnet) to decompose complex eligibility criteria into simpler and manage -\nable questions. Each LLM generated question sets from a standardized prompt template \n(see Supplemental Material S2-S5), which were subsequently integrated and refined using \nChatGPT-4o to produce a comprehensive, non-redundant, and conflict/ambiguity-free \nfinal question set.\nQuestion-based assessment We employed two distinct pathways to address the decom-\nposed questions.\nPathway A: anthropomorphized experts’ CoT\nWe conducted interviews with key individuals to summarize their thought processes, \nwhich were then used to develop the corresponding CoT. Each LLM, prompted to act in \nFig. 1 Comparison of two pathways for criteria identification. ( A) shows the complete pre-screening process, \nincluding criteria conversion and question-based assessment. (B) and (D) depict Pathway A: Anthropomorphized \nExperts’ Chain of Thought (CoT), which models the opinions of three real-world operators to create a CoT that \naligns with inclusion and exclusion criteria. ( C) and ( E) illustrate Pathway B: Preset Stance Agent-Collab, where \nagents’ stances are preset, followed by a voting and arbitration process to determine final answers\n \nPage 5 of 15\nGui et al. BioData Mining           (2025) 18:42 \nan independent role illustrated in Fig.  1(D), analyzed EHR content and provided assess -\nments for corresponding questions: (1) Clinical Research Coordinator (CRC): Focused \non identifying relevant EHR domains using empirical knowledge, followed by targeted \ndata extraction. Employed nuanced terminology comprehension beyond basic key -\nword matching; (2) Junior Doctor (JD): Conducted comprehensive EHR chart review, \nextracted pertinent information, and generated inferential responses to clinical issues; \n(3) Information Engineer (IE): Prioritized extracting key terminology from questions, \nperformed global matching within EHR text, and analyzed semantic negations in identi -\nfied regions. Additionally, we experimented with a majority vote approach, aggregating \nresponses from the three professional perspectives. Specifically, “yes” votes formed one \ncategory, while “no” and “uncertain” votes were combined into another.\nPathway B: preset stance agent-collab\nWe proposed an Agent-Collab framework simulating a mock trial, wherein three agents \nwith distinct roles and stances independently evaluate questions. To enhance efficiency, \nthe evaluation process is limited to a maximum of two rounds. (1) Agent A (Positive \nAssumption) - “Proponent”: Begins with a positive stance (e.g., assuming the patient \nmeets the criteria specified in the question) and conducts a thorough analysis of the \nadmission note to support this assumption, providing a conclusion with supporting \nevidence; (2) Agent B (Negative Assumption) - “Opponent”: Adopts a negative stance \n(e.g., assuming the patient does not meet the criteria in the question) and performs an \nindependent analysis of the same admission note, offering a conclusion with support -\ning reasoning and evidence; (3) Agent C (Adjudicator) - “Judge”: Acts as the adjudica -\ntor, reviewing the conclusions and reasoning from Agents A and B. If both agents agree, \nAgent C delivers the consensus conclusion. In the case of disagreement, Agent C identi -\nfies inconsistencies and prompts a second, more detailed evaluation round, ultimately \nproviding a final judgement on the question.\nEvaluation metrics\nTo establish a robust gold standard for all performance evaluations at the question level, \nclinical experts manually reviewed and annotated the converted question sets from \n4,000 admission notes. Specifically, three board-certified junior clinicians—each with \nthree years of standardized residency training in hepatology—independently anno -\ntated the dataset. The annotation process was conducted prior to pipeline execution. \nAll annotators were blinded to the outputs of the pipeline and to each other’s annota -\ntions. For each item, we adopted a majority voting strategy to determine the final ground \ntruth label. Against this gold standard, the pipeline’s performance was assessed at both \nthe question and criterion levels using several key metrics. For determining the effec -\ntiveness of patient identification in the context of clinical trial pre-screening, precision \n(the proportion of identified patients who were truly eligible) and recall (the propor -\ntion of truly eligible patients who were successfully identified) were considered critical \nindicators. Accordingly, F1 score and accuracy were also calculated based on these gold \nstandard annotations. At the criterion level, we aggregated answers to questions using \npredefined logical rules (detailed in the Supplemental Material S6). We conducted an \nadvanced evaluation of the pipeline, including a counterfactual inference analysis [ 29], \nby manually reviewing outputs that deviated from the gold standard. Additionally, \nPage 6 of 15\nGui et al. BioData Mining           (2025) 18:42 \nprocessing time was measured to verify the pipeline’s scalability and efficiency for large-\nscale pre-screenings.\nWe categorized the questions into relevant clinical domains and further classified \nthem based on reasoning complexity into two types: Classification and Direct Match. \nSpecifically, Direct Match tasks typically involved identifying explicitly stated keywords \nor entities from the text, whereas Classification tasks required inferring an answer based \non broader contextual information or synthesizing multiple pieces of textual evidence. \nThis approach allowed us to analyze performance across different clinical domains and \ntask types, providing deeper insight into the pipeline’s strengths and limitations.\nEthical approval and consent to participate  The study was approved by the Ethics \nCommittee of FAHGUCM (Ref. No. 2020-046-02). The requirement for informed con -\nsent was waived by the Ethics Committee due to the observational nature of the study, \nand all data were de-identified and anonymized.\nResults\nWe automatically generated 87 questions from 58 original criteria, simplifying complex \nreasoning into straightforward semantic tasks (mapping logic in Supplemental Table \nS1). The connection between these criteria and specific trials is detailed in Supplemental \nTable S2. Various prompt templates were used throughout the pipeline, as outlined in \nSupplemental Materials S2-S5.\nQuestion level assessment\nAt the question level, both pathways demonstrated robust pre-screening performance \n(Table 1). Pathway A (majority vote) achieved a precision of 0.877 and recall of 0.822. \nPathway B yielded a slightly higher precision (0.892) but lower recall (0.793). While \nPathway B’s overall precision gain was modest and its general recall lower, its advantages \nin specific complex reasoning tasks—particularly in reliability (see Counterfactual Infer -\nence section) and achieving a targeted precision-recall balance in those contexts—are \nnoteworthy (task-specific performance detailed below; corresponding recall data in Sup-\nplemental Table S3). Notably, Pathway A’s JD role achieved the highest individual recall \n(0.884, Table 1), consistent with its design for comprehensive data retrieval.\nBoth pathways demonstrated high annotation consistency, exceeding 97% across all \nroles and strategies (Fig.  2). Additionally, as shown in Fig.  3, a substantial proportion of \nresponses achieved precision above 0.85, with 63.2% for Pathway B and 71.3% for Path -\nway A’s majority vote.\nPerformance across clinical categories and task complexities is detailed in Table 2 (pre-\ncision) and Supplemental Table S3 (recall). Pathway A (CRC role) showed high precision \nin direct match tasks (Table  2), maintaining a strong precision-recall balance (Supple -\nmental Table S3).\nTable 1 Question level overall performance\nPathway/Role Precision Recall F1 Accuracy\nPathway A -Role-CRC 0.827 0.804 0.780 0.978\nPathway A -Role-JD 0.725 0.884 0.758 0.971\nPathway A -Role-IE 0.818 0.802 0.774 0.977\nPathway A - Majority Vote 0.877 0.822 0.814 0.979\nPathway B 0.892 0.793 0.809 0.972\nPage 7 of 15\nGui et al. BioData Mining           (2025) 18:42 \nIn complex reasoning tasks such as ‘Symptom and Event’ and ‘Etiology and Pathol -\nogy’ (classification), Pathway B exhibited higher precision (0.847 and 0.921 respec -\ntively, Table 2) but lower recall (0.775 for ‘Symptom and Event’ and 0.722 for ‘Etiology \nand Pathology (classification)’ , Supplemental Table S3) compared to Pathway A’s JD role, \nFig. 3 Precision across questions for varying pathways. This figure shows question-level precision for each strat -\negy: ( A) Pathway A- Role-CRC, ( B) Pathway A- Role-JD, ( C) Pathway A- Role-IE, ( D) Pathway A-majority vote and \n(E) Pathway B. Questions are ordered by increasing precision along the X-axis, with precision values on the Y-axis. \nVertical dashed lines indicate questions with a precision of 0.85\n \nFig. 2 Heatmap of annotation consistency across admission records. Rows correspond to questions and columns \nto admission records. Each cell indicates whether the answer is consistent (white) or inconsistent (gray) based on \nexpert annotations. Panels (A) through (E) show results for different pathways: ( A) Pathway A-Role-CRC, (B) Path-\nway A- Role-JD, (C) Pathway A- Role-IE, (D) Pathway A-majority vote, and (E) Pathway B\n \nPage 8 of 15\nGui et al. BioData Mining           (2025) 18:42 \nwhich achieved specific recalls of 0.901 and 0.922 in these respective tasks (Supplemen -\ntal Table S3).\nThis highlights a key precision-recall trade-off for complex scenarios: Pathway A (e.g., \nJD) may be preferred for maximizing patient identification (higher recall), while Path -\nway B offers higher precision and reliability (see Counterfactual Inference) for identified \npositive cases in ambiguous contexts.\nCriterion level performance\nWhen individual question responses were aggregated to the criterion level, the over -\nall performance of each pathway was detailed in Table  3. Pathway A (majority vote) \nachieved a precision of 0.922 and a recall of 0.819. Pathway B demonstrated comparable \nprecision at 0.920 but a lower recall of 0.785.\nThese results indicate that while both pathways are highly precise at the criterion level, \nPathway A’s majority vote strategy was more effective in capturing a larger proportion \nof criteria-meeting patients due to its higher recall. The F1 scores (Pathway A: 0.835, \nPathway B: 0.820) also reflect this balance. The choice between pathways at the criterion \nlevel would therefore depend on the relative importance placed on maximizing patient \ncapture (favoring Pathway A) versus achieving the highest possible precision for positive \nidentifications (where both are strong, but Pathway B’s strengths in handling complex \nconstituent questions, as discussed at the question level, might be a factor for criteria \ninvolving such questions).\nCounterfactual inference\nWe evaluated counterfactual inference rates across the pathways. Pathway B had the \nlowest rate at 0.25%, indicating strong consistency. In Pathway A, the rates varied among \nTable 2 Precision across clinical categories and task types\nCategory / Task Type Pathway A \n-Role-CRC\nPathway A \n-Role-JD\nPathway A \n-Role-IE\nPathway A - \nMajority Vote\nPath-\nway \nB\nDiagnosis 0.865 0.769 0.854 0.915 0.894\n Classification 0.788 0.713 0.779 0.904 0.892\n Direct Match 0.913 0.804 0.899 0.922 0.896\nEtiology and Pathology 0.797 0.659 0.789 0.869 0.910\n Classification 0.759 0.594 0.737 0.876 0.921\n Direct Match 0.853 0.756 0.867 0.859 0.895\nSymptom and Event 0.637 0.512 0.635 0.726 0.847\n Classification 0.637 0.512 0.635 0.726 0.847\nIntervention 0.812 0.721 0.806 0.837 0.892\n Classification 0.740 0.627 0.740 0.774 0.880\n Direct Match 0.920 0.862 0.905 0.933 0.909\nOverall Average 0.827 0.725 0.818 0.877 0.892\nTable 3 Criterion level overall performance\nPathway/Role Precision Recall F1 Accuracy\nPathway A -Role-CRC 0.893 0.808 0.818 0.974\nPathway A -Role-JD 0.787 0.868 0.807 0.965\nPathway A -Role-IE 0.887 0.803 0.814 0.972\nPathway A - Majority Vote 0.922 0.819 0.835 0.975\nPathway B 0.920 0.785 0.820 0.964\nPage 9 of 15\nGui et al. BioData Mining           (2025) 18:42 \nroles, with CRC at 0.82%, IE at 0.93%, and JD at 1.78%. The majority vote approach effec-\ntively reduced Pathway A’s overall counterfactual inference rate to 0.77%, demonstrating \nthe benefit of collective decision-making in minimizing errors.\nPathway B exhibited the lowest counterfactual inference rate (0.25%), a significant \nadvantage for trustworthiness. This ensures that patients identified via Pathway B (often \nchosen for its precision in specific complex tasks, despite its focused recall in those tasks \nas per Supplemental Table S3) are more reliably accurate.\nTime consumption\nTo evaluate efficiency, we measured the time spent on question assessment using an \noptimal concurrency level of 3 to balance speed and resource use. Pathway A showed \nsignificantly faster processing times, averaging 0.588 s per question for CRC, 0.395 s for \nJD, and 0.340 s for IE. In contrast, Pathway B took an average of 2.570 s per question \n(Fig. 4).\nSupplemental Fig.  1 illustrates the variability in processing times for both pathways \nacross different questions. Pathway B exhibited a wider range due to the possibility of a \nsecond evaluation round. Overall, our pipeline demonstrated efficient and manageable \nprocessing times. With further optimization, Pathway A could potentially process a sin -\ngle patient’s eligibility in approximately 10 s.\nAdditional research\nWe also conducted a preliminary evaluation of other locally deployed LLMs (QWEN1.5, \nBAICHUAN, and GLM) on a subset of the data. QWEN1.5 generally outperformed the \nFig. 4 Processing time across pathways. This figure illustrates the distribution of processing times for different \nstrategies: Pathway A- Role-CRC, Pathway A- Role-JD, Pathway A- Role-IE, and Pathway B\n \nPage 10 of 15\nGui et al. BioData Mining           (2025) 18:42 \nother models. BAICHUAN showed a tendency for over-inference, while GLM faced \nchallenges with constraint adherence.\nFurthermore, we compared the performance of QWEN1.5 and QWEN2 when \ndeployed locally. Interestingly, QWEN1.5 outperformed QWEN2, despite the lat -\nter’s enhancements in reasoning capabilities. This discrepancy might be attributed to \nQWEN2’s conservative approach, leading to a higher rate of false negatives, or the lack \nof prompt adaptation for QWEN2 in our specific setting.\nDiscussion\nPrinciple findings\nIn this study, the pipeline combined anthropomorphized experts’ CoT with a preset \nstance Agent-Collab strategy and a locally deployed LLM, effectively addressing the chal-\nlenges in clinical trial pre-screening for hepatology by achieving by achieving a notable \nbalance of high precision in critical areas and acceptable recall, alongside improved effi -\nciency. Notably, the entire pipeline operated on a single consumer-grade server within a \nfully air-gapped data, internet-isolated environment.\nIn conclusion, we propose a hybrid approach for clinical application, considering the \nprecision-recall profiles:: (1) For non-inferential recognition tasks involving explicit \ndiagnoses and interventions (i.e., Direct Match tasks), pathway A with majority vote \nis recommend, offering a strong balance of high precision (typically > 0.85 as shown in \nTable 2) and high recall (typically > 0.80 as shown in Supplemental Table S3) for these \ntasks; (2) For tasks requiring complex reasoning (i.e., Classification tasks), Pathway B is \nmore suitable, providing excellent precision (generally in the 0.85–0.92 range accord -\ning to Table 2), ensuring high reliability of positive identifications, alongside a moderate \nrecall profile (around 0.65–0.78 based on Supplemental Table S3) that highlights a clear \nprecision-recall trade-off for these demanding tasks.\nEffective hepatopathy pre-screening in secure environments\nThe pipeline demonstrated notable overall performance at the criterion level, which was \nachieved within a secure environment with limited resources. For instance, Pathway A \n(majority vote) achieved an F1-score of 0.835, supported by its precision of 0.922 and \nrecall of 0.819 (Table  3). Additionally, we assessed the trial-level precision (aggregation \nrules detailed in Supplemental Material S7), achieving an average of 0.72, considering \nthe limitations of admission notes in determining patient eligibility. Despite these con -\nstraints, the pipeline achieved higher precision in hepatocellular carcinoma (0.878) and \ncirrhosis trials (0.843), indicating its potential utility in hepatopathy trials. Compared to \nsimilar studies in Table 4, our pipeline showed competitive or superior performances in \nboth precision and recall, even when using a closed-source LLM. Notably, compared to \nthe included traditional non-LLM baselines, our LLM-driven pathways indicated clear \nadvantages in key metrics such as precision (e.g., Pathway A: 0.922 vs. 0.540 rule-based; \nPathway B: 0.920 vs. 0.737 hybrid) and recall (Pathway B: 0.785 vs. 0.560 hybrid). While \nacknowledging potential variations across studies, these findings underscore the prom -\nise of our LLM strategies for applications valuing secure, local deployment with open-\nsource models in resource-limited clinical settings.\nFor tasks such as identifying hepatocellular carcinoma, cirrhosis, or specific interven -\ntions like TIPS (largely Direct Match tasks), the CoT-based approach (e.g., Pathway A \nPage 11 of 15\nGui et al. BioData Mining           (2025) 18:42 \n- Majority Vote) delivered high precision (typical around 0.92, which compares favorably \nto reported manual annotation performance [ 30]) and also demonstrated good recall \n(e.g., typically > 0.85 for these tasks, as shown in Supplemental Table S3), contributing to \nboth accuracy and comprehensive capture for these straightforward recognition tasks. \nThis was achieved with minimal processing time (a typical of 0.44 s per task, verse tra -\nditional manual annotation which take over 10 s per task, representing a 95% reduction \n[34]). For more complex tasks, such as determining the etiology of liver failure, assess -\ning whether liver cancer is primary, identifying systemic diseases, or verifying HBV anti -\nviral treatment (largely Classification tasks), the Agent-Collab framework (Pathway B) \nachieved high precision (generally in the 0.85–0.92 range, as detailed in Table  2). It is \nimportant to consider that this high precision in complex scenarios was accompanied \nby a moderate recall profile (around 0.65–0.78 for Pathway B in these tasks, according to \nSupplemental Table S3), illustrating a clear precision-recall trade-off where this pathway \nprioritizes the accuracy of positive identifications in such nuanced scenarios. By lever -\naging externally defined logic—derived from advanced LLMs or clinical experts—this \ndual-pathway approach supported the method’s efficiency and adaptability, demonstrat-\ning its capability in handling a wide range of clinical scenarios in hepatopathy research \nby permitting an informed choice based on the desired precision-recall emphasis.\nClinical expertise guides LLM applications to address complex challenges\nResearchers often view new technologies and standard clinical practices separately. In \nthis study, we integrated proven clinical methods with advanced technologies to effec -\ntively address complex problems, yielding promising results in terms of both precision \nand recall, as well as their balance.\nPathway A’s anthropomorphized experts guided the LLM from general semantic \nunderstanding to targeted entity recognition, a critical feature for enhancing the per -\nformance of weaker open-source LLMs. Meanwhile, Pathway B’s preset stance Agent-\nCollab strategy effectively managed complex and semantically disordered texts, leading \nto highly precise outputs in such scenarios (as shown in Table  2), though this was often \nbalanced with a moderate recall profile that prioritized the certainty of identified \ncases (Supplemental Table S3). By combining advanced LLM capabilities with clinical \nTable 4 Performance comparison of related research\nResearch Data Size Model Strategy Precision Recall\nOur pathway A 4,000 patients QWEN 2.0 CoT 0.922 0.891\nOur pathway B 4,000 patients QWEN 2.0 Agent Collab 0.920 0.785\nThai et al., 2024 [15] 1,436 patients ChatGPT 4 Automatic Cohort \nRetrieval\n0.794 0.471\nJin et al., 2024 [30] 183 synthetic patients ChatGPT 3.5 TrialGPT 0.672 0.792 \naverage\nNievas et al., 2023 [31] 4,678 patient-trial pairs ChatGPT 3.5\nChatGPT 4\nLLAMA 70B\nCoT Predicting 0.603\n0.701\n0.541\n0.727\n0.745\n0.645\nKusa et al., 2023 [32] 125 topics (patient \nnotes)\nBERT Supervised \nLearning\n0.456 NA\nTissot et al., 2020 [7], \nBenchmark\n395 patients Rule-based Bio-Yodie, Se-\nmEHR, ConText\n0.540 0.898\nGhosh et al., 2024 [33], \nBenchmark\n72 patient-trial pairs Hybrid (NLP , \nRegex, expert \nrules)\nSciSpacy, Deep-\nPhe, BERN2\n0.737 0.560\nPage 12 of 15\nGui et al. BioData Mining           (2025) 18:42 \nexpertise, both strategies showed potential for improving the overall effectiveness (con -\nsidering both precision and recall) of complex clinical assessments (Fig. 5).\nPathway B demonstrated notable precision in complex reasoning and nuanced catego-\nrization tasks (Table  2), which, while ensuring high-certainty identification, was asso -\nciated with a moderate recall profile (Supplemental Table S3). In contrast, Pathway A \n(particularly its CRC and IE roles) excelled in direct recognition tasks (Direct Match \ntasks), achieving a strong balance of both high precision and good recall (as detailed in \nTable 2 and Supplemental Table S3 respectively). This fundamental difference in their \nprecision-recall characteristics highlights their complementary strengths: Pathway B is \nparticularly suited for complex scenarios where the accuracy of positive identifications is \nparamount, supported by its lower counterfactual inference rates. Conversely, Pathway \nA provides a efficient solution with robust overall performance (e.g., comparable overall \nprecision for majority vote to Pathway B, Tables 1 and 3, but with better recall for direct \nmatch tasks) and lower resource consumption, making it a practical choice when broad \ncapture and efficiency, especially for simpler tasks, are prioritized.\nExploratory insights on pipeline adaptability in traditional Chinese medicine\nNotably, our dataset, which comes from FAHGUCM in China, a regionally influential \nhospital in hepatopathy (annual outpatient visits reach 50,000, with around 5,000 inpa -\ntient admissions). This dataset integrates both Traditional Chinese Medicine (TCM) and \nWestern medicine, included expressions influenced by TCM. While not being the pri -\nmary focus of our evaluation, these expressions were also tested, and preliminary results \nsuggested that the pipeline can adapt to these diverse medical terminologies. Some nat -\nural language expressions in the recorded texts reflect a TCM influence. Although these \nexpressions were not involved in the nano-ranking Q&A, we experimented with incor -\nporating some TCM phrasing in our tests. For example, we used criterion like “whether \nthe patient has insomnia” , and the corpus was “ 患者寐差” (poor sleep quality) or “ 卧\n不安寐” (lie unable to sleep) instead of the more commonly seen “ 患者存在失眠情况” \n(the patient has insomnia condition). The recognition performance was satisfactory, \nFig. 5 Decomposition and answer example for complex questions. This figure demonstrates how decomposing \nthe complex question “Has the patient been diagnosed with primary liver cancer?” into four sub-questions im -\nproves model performance, leading to a final “Yes” determination based on rule-based criteria\n \nPage 13 of 15\nGui et al. BioData Mining           (2025) 18:42 \nsuggesting potential applicability in this area. However, we did not conduct systematic \nand rigorous testing on these variations.\nLimitations\nFirstly, the information within admission notes is limited, focusing on key sections like \nchief complaints, current disease history, and past medical history. Our gold standard \nwas also derived from these notes. While this ensures a fair evaluation of the pipeline \nagainst expert interpretation of these specific documents, the inherent scope of admis -\nsion notes means that the reported performance metrics reflect fidelity to this data \nsource rather than an absolute measure against more comprehensive patient records. \nTo address this, we selected criteria from multiple clinical trials related to hepatopathy \nand manually filtered them to ensure relevance to our dataset. Secondly, the data in this \nstudy were sourced from a single, regionally influential hepatology center. While cov -\nering multiple liver diseases, this may limit the generalizability of our findings. Further \nexternal validation is needed to ensure its applicability in other clinical settings. Fur -\nthermore, some criteria have limited number of positive instances, making recall sensi -\ntive to misclassifications, which should be considered when interpreting these specific \nrecall figures. Additionally, while this study evaluated two distinct strategic pathways, a \ndetailed component-wise analysis or ablation study for complex Pathway B, which could \nfurther elucidate the specific contributions of its individual elements (e.g., agent roles or \ndebate mechanisms), was not performed as part of this initial investigation.\nDespite these limitations, our approach provides valuable insights into the use of lim -\nited EHR data for clinical trial matching. By focusing on likely available data points, we \nenhance the real-world applicability of our analysis. This focused methodology also \nfacilitates scalability to other settings with similar data limitations. Future work should \naim to enhance data collection in EHR systems, improve model robustness for incom -\nplete data, and explore more granular analyses of complex model architectures to opti -\nmize their design. Expanding this approach to other medical domains also remains a key \nfuture direction.\nConclusions\nWe have developed an effective patient pre-screening strategy, showing high precision \nand achieving good recall in hepatopathy trials. Designed to operate efficiently in envi -\nronments with limited IT resources and stringent security requirements, our pipeline \ncombines different approaches to achieve precision, recall and efficiency across various \nclinical tasks. This cost-effective and adaptable solution has the potential to enhance the \npre-screening process and improve patient recruitment in clinical trials by aiming for a \ncomprehensive and reliable initial screen.\nSupplementary Information\nThe online version contains supplementary material available at https://doi.org/10.1186/s13040-025-00458-5.\nSupplementary Material 1\nSupplementary Material 2\nSupplementary Material 3\nPage 14 of 15\nGui et al. BioData Mining           (2025) 18:42 \nAcknowledgements\nWe sincerely thank the China National GeneBank for their technical support. We also appreciate the support from RUIYI’s \nClinical Multi-omics Data Research Workstation for our research.\nAuthor contributions\nX.G.: Conceptualization, Methodology, Writing - Original Draft, Formal Analysis. H.L.: Methodology, Formal Analysis, \nSoftware, Writing - Review & Editing. X.W.: Data Curation, Validation, Visualization, Supervision. L.L.: Investigation, Project \nAdministration, Writing - Review & Editing. Y.X.: Conceptualization, Funding Acquisition, Writing - Review & Editing, \nSupervision. L.W.: Methodology, Project Administration, Writing - Review & Editing, Supervision.\nFunding\nThis study was supported by the Second Batch of National TCM Clinical Research Base Construction Units (No. 131 \n[2018], issued by the National Administration of Traditional Chinese Medicine).\nData availability\nThe data analyzed in this study are not publicly available due to privacy or ethical restrictions but can be obtained from \nthe corresponding author upon reasonable request.\nDeclarations\nEthics approval\nThe study was approved by the First Affiliated Hospital of Guangxi University of Chinese Medicine (approved Ref. No. \n2020-046-02).\nPatient consent statement\nThe requirement for informed consent was waived by the Ethics Committee of the First Affiliated Hospital of Guangxi \nUniversity of Chinese Medicine, due to the retrospective nature of the study, and all clinical data were de-identified and \nanonymized.\nCompeting interests\nThe authors declare no competing interests.\nReceived: 27 March 2025 / Accepted: 9 June 2025\nReferences\n1. Aithal GP , Palaniyappan N, China L, et al. Guidelines on the management of Ascites in cirrhosis. Gut. 2021;70(1):9–29.: \n10.1136/gutjnl-2020-321790 [published Online First: 2020/10/18].\n2. Hersh WR, Weiner MG, Embi PJ, et al. Caveats for the use of operational electronic health record data in comparative \neffectiveness research. Med Care. 2013;51(8 Suppl 3):S30–7. https://doi.org/10.1097/MLR.0b013e31829b1dbd. [published \nOnline First: 2013/06/19].\n3. Escudie JB, Rance B, Malamut G, et al. A novel data-driven workflow combining literature and electronic health records to \nestimate comorbidities burden for a specific disease: a case study on autoimmune comorbidities in patients with Celiac \ndisease. BMC Med Inf Decis Mak. 2017;17(1):140. https://doi.org/10.1186/s12911-017-0537-y. [published Online First: \n2017/10/01].\n4. Ni Y, Wright J, Perentesis J, et al. Increasing the efficiency of trial-patient matching: automated clinical trial eligibility pre-\nscreening for pediatric oncology patients. BMC Med Inf Decis Mak. 2015;15:28.  h t t p s : / / d o i . o r g / 1 0 . 1 1 8 6 / s 1 2 9 1 1 - 0 1 5 - 0 1 4 9 - 3     \n. [published Online First: 2015/04/17].\n5. Beck JT, Rammage M, Jackson GP , et al. Artificial intelligence tool for optimizing eligibility screening for clinical trials in a \nlarge community Cancer center. JCO Clin Cancer Inf. 2020;4:50–9. https://doi.org/10.1200/CCI.19.00079. [published Online \nFirst: 2020/01/25].\n6. Hassanzadeh H, Karimi S, Nguyen A. Matching patients to clinical trials using semantically enriched document representa-\ntion. J Biomed Inf. 2020;105:103406. https://doi.org/10.1016/j.jbi.2020.103406. [published Online First: 2020/03/15].\n7. Tissot HC, Shah AD, Brealey D, et al. Natural Language processing for mimicking clinical trial recruitment in critical care: A \nSemi-Automated simulation based on the leopards trial. IEEE J Biomed Health Inf. 2020;24(10):2950–59.  h t t p s : / / d o i . o r g / 1 0 . \n1 1 0 9 / J B H I . 2 0 2 0 . 2 9 7 7 9 2 5     . [published Online First: 2020/03/10].\n8. Lee P , Bubeck S, Petro JJNEJM. Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine. 2023;388(13):1233–39.\n9. Lee P , Goldberg C, Kohane I. The AI revolution in medicine: GPT-4 and beyond: Pearson, 2023.\n10. Van Veen D, Van Uden C, Blankemeier L, et al. Adapted large Language models can outperform medical experts in clinical \ntext summarization. Nat Med. 2024;30(4):1134–42. https://doi.org/10.1038/s41591-024-02855-5. [published Online First: \n2024/02/28].\n11. Devarakonda MV, Mohanty S, Sunkishala RR, Mallampalli N, Liu XJJ. Clinical trial recommendations using Semantics-Based \ninductive inference and knowledge graph embeddings. 2024;154:104627.\n12. Van Veen D, Van Uden C, Blankemeier L et al. Clinical text summarization: Adapting large language models can outper-\nform human experts. 2023.\n13. Yuan D, Rastogi E, Naik G et al. A Continued Pretrained LLM Approach for Automatic Medical Note Generation. 2024.\n14. Singhal K, Tu T, Gottweis J et al. Towards Expert-Level Medical Question Answering with Large Language Models. 2023.  h t t \np s :  / / u i .  a d s a b s  . h a r  v a r d .  e d u / a  b s / 2 0 2  3 a r X  i v 2 3 0 5 0 9 6 1 7 S (accessed May 01, 2023).\n15. Thai DN, Ardulov V, Mena JU et al. ACR: A Benchmark for Automatic Cohort Retrieval. 2024.\n16. Zhu Y, Yuan H, Wang S et al. Large language models for information retrieval: A survey. 2023.\nPage 15 of 15\nGui et al. BioData Mining           (2025) 18:42 \n17. Wei J, Wang X, Schuurmans D et al. Chain-of-Thought prompting elicits reasoning in large Language models. 2023 doi: \nhttps://doi.org/10.48550/arXiv.2201.11903\n18. Kenton Z, Siegel NY, Kramár J et al. On scalable oversight with weak LLMs judging strong LLMs. 2024.\n19. Fang Y, Li M, Wang W, Lin H. Feng FJapa. Counterfactual Debating with Preset Stances for Hallucination Elimination of \nLLMs. 2024.\n20. ChiCTR2100044187. Secondary ChiCTR2100044187.  h t t p s :  / / w w w  . c h i c t  r . o r  g . c n /  h v s h o  w p r o j e  c t . h  t m l ? i d = 9 7 3 7 1 & v = 1 . 6\n21. NCT04353193. Secondary NCT04353193. https://clinicaltrials.gov/study/NCT04353193\n22. NCT04850534. Secondary NCT04850534. https://clinicaltrials.gov/study/NCT04850534\n23. NCT03911037. Secondary NCT03911037. https://clinicaltrials.gov/study/NCT03911037\n24. NCT01311167. Secondary NCT01311167. https://clinicaltrials.gov/study/NCT01311167\n25. NCT04021056. Secondary NCT04021056. https://clinicaltrials.gov/study/NCT04021056\n26. Bai J, Bai S, Chu Y et al. Qwen Technical Report. 2023.  h t t p s :  / / u i .  a d s a b s  . h a r  v a r d .  e d u / a  b s / 2 0 2  3 a r X  i v 2 3 0 9 1 6 6 0 9 B (accessed \nSeptember 01, 2023).\n27. Yang A, Xiao B, Wang B et al. Baichuan 2: Open Large-scale Language Models. 2023.  h t t p s :  / / u i .  a d s a b s  . h a r  v a r d .  e d u / a  b s / 2 0 2  \n3 a r X  i v 2 3 0 9 1 0 3 0 5 Y (accessed September 01, 2023).\n28. GLM T, Zeng A, Xu B et al. ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools. 2024.\n29. Ji Z, Lee N, Frieske R, et al. Surv Hallucination Nat Lang Generation. 2023;55(12):1–38.\n30. Jin Q, Wang Z, Floudas CS et al. Matching patients to clinical trials with large language models. 2023.\n31. Nievas M, Basu A, Wang Y, Singh HJJAMIA. Distilling large language models for matching patients to clinical trials. \n2024:ocae073.\n32. Kusa W, Mendoza ÓE, Knoth P , Pasi G, Hanbury AJJ. Effective matching of patients to clinical trials using entity extraction \nand neural re-ranking. 2023;144:104444.\n33. Ghosh S, Abushukair HM, Ganesan A, Pan C, Naqash AR, Lu K. (2024). Harnessing explainable artificial intelligence \nfor patient-to-clinical-trial matching: A proof-of-concept pilot study using phase I oncology trials. PLoS ONE, 19(10), \ne0311510.\n34. Wei Q, Franklin A, Cohen T, Xu H. Clinical text annotation - what factors are associated with the cost of time? AMIA Annu \nSymp Proc. 2018;2018:1552–60. published Online First: 2019/03/01.\nPublisher’s note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
  "topic": "Pipeline (software)",
  "concepts": [
    {
      "name": "Pipeline (software)",
      "score": 0.680171012878418
    },
    {
      "name": "Computer science",
      "score": 0.6602619886398315
    },
    {
      "name": "Data science",
      "score": 0.3262152671813965
    },
    {
      "name": "Programming language",
      "score": 0.17450478672981262
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210113348",
      "name": "Guangxi University of Chinese Medicine",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I100135526",
      "name": "BGI Group (China)",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210160507",
      "name": "Center for Life Sciences",
      "country": "CN"
    }
  ],
  "cited_by": 1
}