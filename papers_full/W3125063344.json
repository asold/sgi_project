{
  "title": "Generating novel protein sequences using Gibbs sampling of masked language models",
  "url": "https://openalex.org/W3125063344",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2130580378",
      "name": "Sean R. Johnson",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3041687190",
      "name": "Sarah Monaco",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5098004628",
      "name": "Kenneth Massie",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3084865755",
      "name": "Zaid Syed",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2130580378",
      "name": "Sean R. Johnson",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3041687190",
      "name": "Sarah Monaco",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5098004628",
      "name": "Kenneth Massie",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3084865755",
      "name": "Zaid Syed",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2767044445",
    "https://openalex.org/W3114990254",
    "https://openalex.org/W2902111471",
    "https://openalex.org/W3030163527",
    "https://openalex.org/W3035317912",
    "https://openalex.org/W3040739508",
    "https://openalex.org/W3015572436",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3112830812",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2951433247",
    "https://openalex.org/W2971803505",
    "https://openalex.org/W2943495267",
    "https://openalex.org/W3044778276",
    "https://openalex.org/W2997234557",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W3015531900",
    "https://openalex.org/W3088059392",
    "https://openalex.org/W2911109671",
    "https://openalex.org/W2980789587",
    "https://openalex.org/W3163435021",
    "https://openalex.org/W2011301426",
    "https://openalex.org/W2971227267",
    "https://openalex.org/W2949342052",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W3111174583",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2951599627",
    "https://openalex.org/W3002639525",
    "https://openalex.org/W2919834395",
    "https://openalex.org/W3158236124"
  ],
  "abstract": "Abstract Recently developed language models (LMs) based on deep neural networks have demonstrated the ability to generate fluent natural language text. LMs pre-trained on protein sequences have shown state of the art performance on a variety of downstream tasks. Protein LMs have also been used to generate novel protein sequences. In the present work we use Gibbs sampling of BERT-style LMs, pre-trained on protein sequences using the masked language modeling task, to generate novel protein sequences. We evaluate the quality of the generated sequences by comparing them to natural sequences from the same family. In particular, we focus on proteins from the chorismate mutase type II family, which has been used in previous work as an example target for protein generative models. We find that the Gibbs sampling process on BERT-style models pretrained on millions to billions of protein sequences is able to generate novel sequences that retain key features of related natural sequences. Further, we find that smaller models fine-tuned or trained from scratch on family-specific data are able to equal or surpass the generation quality of large pre-trained models by some metrics. The ability to generate novel natural-like protein sequences could contribute to the development of improved protein therapeutics and protein-catalysts for industrial chemical production.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6799682378768921
    },
    {
      "name": "Gibbs sampling",
      "score": 0.599327802658081
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5425165295600891
    },
    {
      "name": "Task (project management)",
      "score": 0.46473053097724915
    },
    {
      "name": "Machine translation",
      "score": 0.4473968744277954
    },
    {
      "name": "Machine learning",
      "score": 0.3898411691188812
    },
    {
      "name": "Natural language processing",
      "score": 0.34240639209747314
    },
    {
      "name": "Bayesian probability",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I130701444",
      "name": "Georgia Institute of Technology",
      "country": "US"
    }
  ]
}