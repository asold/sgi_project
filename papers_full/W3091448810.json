{
  "title": "A Semi-Supervised Autoencoder With an Auxiliary Task (SAAT) for Power Transformer Fault Diagnosis Using Dissolved Gas Analysis",
  "url": "https://openalex.org/W3091448810",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A5069917187",
      "name": "Sunuwe Kim",
      "affiliations": [
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A5055579210",
      "name": "Soo-Ho Jo",
      "affiliations": [
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A5091850759",
      "name": "Wongon Kim",
      "affiliations": [
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A5100413205",
      "name": "Jongmin Park",
      "affiliations": [
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A5086147595",
      "name": "Jin Gyo Jeong",
      "affiliations": [
        "Korea Electric Power Corporation (South Korea)",
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A5050787509",
      "name": "Yeongmin Han",
      "affiliations": [
        "Korea Electric Power Corporation (South Korea)"
      ]
    },
    {
      "id": "https://openalex.org/A5103065489",
      "name": "Daeil Kim",
      "affiliations": [
        "Korea Electric Power Corporation (South Korea)"
      ]
    },
    {
      "id": "https://openalex.org/A5084771659",
      "name": "Byeng D. Youn",
      "affiliations": [
        null,
        "Seoul National University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2747648188",
    "https://openalex.org/W2737897717",
    "https://openalex.org/W2340811421",
    "https://openalex.org/W2100389565",
    "https://openalex.org/W3015353599",
    "https://openalex.org/W2770787014",
    "https://openalex.org/W2601590138",
    "https://openalex.org/W2954154461",
    "https://openalex.org/W2978410457",
    "https://openalex.org/W2770049107",
    "https://openalex.org/W2080850431",
    "https://openalex.org/W2012276257",
    "https://openalex.org/W2781700481",
    "https://openalex.org/W2924922918",
    "https://openalex.org/W2724730420",
    "https://openalex.org/W2164877242",
    "https://openalex.org/W2889957900",
    "https://openalex.org/W2126857563",
    "https://openalex.org/W2041512177",
    "https://openalex.org/W2415033110",
    "https://openalex.org/W2965358732",
    "https://openalex.org/W2163214087",
    "https://openalex.org/W6685562342",
    "https://openalex.org/W3005474703",
    "https://openalex.org/W2773549135",
    "https://openalex.org/W2926357201",
    "https://openalex.org/W2610069517",
    "https://openalex.org/W2084277209",
    "https://openalex.org/W2767031373",
    "https://openalex.org/W2074910498",
    "https://openalex.org/W2015025818",
    "https://openalex.org/W2515319207",
    "https://openalex.org/W2153375913",
    "https://openalex.org/W2117078830",
    "https://openalex.org/W2123958476",
    "https://openalex.org/W2127761407",
    "https://openalex.org/W2084575229",
    "https://openalex.org/W1554132173",
    "https://openalex.org/W2153797789",
    "https://openalex.org/W2021009631",
    "https://openalex.org/W2913950581",
    "https://openalex.org/W3015975460",
    "https://openalex.org/W2148714802",
    "https://openalex.org/W2920008224",
    "https://openalex.org/W2730619644",
    "https://openalex.org/W3008024556",
    "https://openalex.org/W1995094777",
    "https://openalex.org/W2241510067",
    "https://openalex.org/W3026876342",
    "https://openalex.org/W2925289689",
    "https://openalex.org/W2025768430",
    "https://openalex.org/W2020200728",
    "https://openalex.org/W2242427765",
    "https://openalex.org/W2176412452",
    "https://openalex.org/W2963285578"
  ],
  "abstract": "This paper proposes a semi-supervised autoencoder with an auxiliary task (SAAT) to extract a health feature space for power transformer fault diagnosis using dissolved gas analysis (DGA). The health feature space generated by a semi-supervised autoencoder (SSAE) not only identifies normal and thermal/electrical fault types, but also presents the underlying characteristics of DGA. In the proposed approach, by adding an auxiliary task that detects normal and fault states in the loss function of SSAE, the health feature space additionally enables visualization of health degradation properties. The overall procedure of the new approach includes three key steps: 1) preprocessing DGA data, 2) extracting two health features via SAAT, and 3) visualizing the two health features in two-dimensional space. In this paper, we test the proposed approach using massive unlabeled/labeled Korea Electric Power Corporation (KEPCO) databases and IEC TC 10 databases. To demonstrate the effectiveness of the proposed approach, four comparative studies are conducted with these datasets; the studies examined: 1) the effectiveness of an auxiliary detection task, 2) the effectiveness of the visualization method, 3) conventional fault diagnosis methods, and 4) the state-of-the-art, semi-supervised deep learning algorithms. By examining several evaluation metrics, these comparative studies confirm that the proposed approach outperforms SSAE without the auxiliary task, existing methods, and state-of-the-art deep learning algorithms, in terms of defining health degradation performance. We expect that the proposed SAAT-based health feature space approach will be widely applicable to intuitively monitor the health state of power transformers in the real world.",
  "full_text": "Received September 10, 2020, accepted September 27, 2020, date of publication September 30, 2020,\ndate of current version October 9, 2020.\nDigital Object Identifier 10.1 109/ACCESS.2020.3027830\nA Semi-Supervised Autoencoder With an\nAuxiliary Task (SAAT) for Power Transformer\nFault Diagnosis Using Dissolved Gas Analysis\nSUNUWE KIM1, SOO-HO JO\n 1, WONGON KIM1, JONGMIN PARK1, JINGYO JEONG1,2,\nYEONGMIN HAN2, DAEIL KIM2, AND BYENG DONG YOUN\n1,3, (Member, IEEE)\n1Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul 08826, South Korea\n2Department of Transmission & Substation Operation, Korea Electric Power Corporation (KEPCO), Naju 58322, South Korea\n3OnePredict Inc., Seoul 08826, South Korea\nCorresponding author: Byeng Dong Youn (bdyoun@snu.ac.kr)\nThis work was supported in part by the 2017 Open Research and Development Program of Korea Electric Power\nCorporation (KEPCO) under Grant R17tH02, and in part by the National Research Foundation of Korea (NRF)\ngrant funded by the Ministry of Science and ICT (MSIT), Korea Government under Grant 2020R1A2C3003644.\nABSTRACT This paper proposes a semi-supervised autoencoder with an auxiliary task (SAAT) to extract\na health feature space for power transformer fault diagnosis using dissolved gas analysis (DGA). The\nhealth feature space generated by a semi-supervised autoencoder (SSAE) not only identiﬁes normal and\nthermal/electrical fault types, but also presents the underlying characteristics of DGA. In the proposed\napproach, by adding an auxiliary task that detects normal and fault states in the loss function of SSAE,\nthe health feature space additionally enables visualization of health degradation properties. The overall\nprocedure of the new approach includes three key steps: 1) preprocessing DGA data, 2) extracting two\nhealth features via SAAT, and 3) visualizing the two health features in two-dimensional space. In this\npaper, we test the proposed approach using massive unlabeled/labeled Korea Electric Power Corporation\n(KEPCO) databases and IEC TC 10 databases. To demonstrate the effectiveness of the proposed approach,\nfour comparative studies are conducted with these datasets; the studies examined: 1) the effectiveness of an\nauxiliary detection task, 2) the effectiveness of the visualization method, 3) conventional fault diagnosis\nmethods, and 4) the state-of-the-art, semi-supervised deep learning algorithms. By examining several\nevaluation metrics, these comparative studies conﬁrm that the proposed approach outperforms SSAE without\nthe auxiliary task, existing methods, and state-of-the-art deep learning algorithms, in terms of deﬁning health\ndegradation performance. We expect that the proposed SAAT-based health feature space approach will be\nwidely applicable to intuitively monitor the health state of power transformers in the real world.\nINDEX TERMS Semi-supervised autoencoder, health feature space, fault diagnosis, power transformer,\ndissolved gas analysis.\nI. INTRODUCTION\nPower transformers are important components of distribution\nand transmission lines of power grid systems. For stable\noperation of transformers, insulation materials are used to\nprevent heat transfer and electrical discharge [1]. Although\ntransformers are manufactured to meet reliable design con-\nditions, uncertainties in operation can cause transformers to\noperate in an unexpected way. Thus, to prevent catastrophic\nsocial, economic, and energy efﬁciency losses, prognostics\nand health management techniques have attracted attention\nin recent decades [2]–[4].\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Rajesh Kumar.\nDissolved gas analysis (DGA) has been widely used to\ndiagnose oil-ﬁlled transformers [5]. When insulation mate-\nrials are continuously exposed to electrical and thermal\nstresses, combustible gases (e.g., H 2, C 2H2, C 2H4, and so\non) are decomposed from the insulation materials and then\ndissolved in the oil [6]. Via on/ofﬂine measurement of these\ndissolved gases, DGA can diagnose (e.g., detect and iden-\ntify) the health state of the transformers. In this study, fault\ndetection refers to the binary classiﬁcation of normal and\nfault states, fault identiﬁcation indicates multi-classiﬁcation\nof normal and electrical/thermal fault types.\nFault diagnosis methods using DGA are divided into\ntwo categories: rule-based methods and artiﬁcial intelligence\n(AI)-based methods. In rule-based methods, concentrations\nVOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 178295\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nand/or ratios of gases are used for fault identiﬁcation based\non human-experienced thresholds. Examples of rule-based\nmethods include the IEC ratios method [7], the Rogers\nratios method [8], and the Doernenburg ratios method [9].\nIn addition, Duval ratio methods provide two-dimensional\n(2D) graphics (e.g., Duval triangle and pentagon) which are\nintuitive for classifying fault types [6], [10], [11]. However,\nrule-based methods have relatively low accuracy and incon-\nsistent diagnosis results due to insufﬁcient mathematical\ncomputation and their empirical handcrafted thresholds [12].\nIn recent years, AI-techniques have been incorporated\nin power transformer fault diagnosis to improve accuracy.\nAI techniques include fuzzy logic [13]–[15], support vector\nmachine [16], [17], artiﬁcial neural network, and multilayer\nperceptron [18]–[21]. To select optimal features and address\nimbalanced problems of DGA data, a genetic algorithm\napproach [22]–[25] and an adaptive over-sampling method\n[26], [27] have been applied, respectively. Despite some\nachievements using such supervised learning approaches,\nthese studies take only labeled DGA datasets into account.\nIn other prior work, a semi-supervised learning approach\nusing a low-dimensional scaling was developed to con-\nsider unlabeled DGA data [28]. However, this approach\nhas difﬁculty performing health feature selection for unla-\nbeled datasets. Motivated by this challenge, several additional\nmethods for extracting health features have been reported.\nA principal component analysis with fuzzy C-means method\nwas presented as an unsupervised feature extraction method\nin [29], [30]. Besides, self-organizing maps (SOM) of unsu-\npervised neural network methods extracted feature maps of\nseveral fault types [31], [32]. Further, deep learning tech-\nniques, such as by sparse autoencoder [33] and deep belief\nnetwork [34], have been used to extract high-level health\nfeatures by unsupervised greedy layer wise training with deep\nhierarchical hidden layers.\nWhile these advances have been signiﬁcant, AI-based\napproaches have the following three limitations. First, despite\nthe necessity of a large amount of DGA data to represent\ngeneralized diagnosis results, it is difﬁcult to obtain the large\namount of required DGA data in real-world applications.\nSigniﬁcant ﬁnancial cost is required to periodically maintain\nall transformers and measure DGA data in the ﬁeld. Second,\nmost previous studies have focused on fault detection and\nidentiﬁcation features; little effort has been made to analyze\nthe health degradation features. If degradation features are\nnewly developed, it is worth pointing out that they enable to\nexhibit the monotonic health state transition from normal to\nfault, thus potentially estimating health states for unlabeled\ndata or diagnosing fault states in advance. Lastly, visualiza-\ntion of the monotonic health state transition in 2D space has\nye be addressed by other research. Since 2D graphics provide\nthe most obvious and readable space representation for the\nhuman eye, a 2D health feature space (HFS) can intuitively\nshow diagnosis results [35].\nThus, in this paper, we propose a novel semi-supervised\nautoencoder with an auxiliary task (SAAT) to extract an\nHSF, considering a large amount of DGA data. The pro-\nposed SAAT approach comes from a semi-supervised autoen-\ncoder (SSAE) that can simultaneously learn unsupervised\nand supervised tasks with shared hidden layers. Unsupervised\nand supervised tasks play roles in the representative health\nfeature extraction and the fault identiﬁcation, respectively.\nHere, by putting an auxiliary task (fault detection) in the\nloss function of SSAE, the trained shared parameters provide\nthe health features, which additionally enable representation\nof the health degradation properties. By structuring the two\nnodes in the end of the shared hidden layers, two health\nfeatures can be directly visualized into 2D space without an\nadditional dimension reduction. In this paper, a large amount\nof DGA data, provided by Korea Electric Power Corporation\n(KEPCO), is considered. In addition, IEC TC 10 databases\nare used for validation tests. To the best of the authors’\nknowledge, the contributions of this work can be summarized\nas follows:\n1. This is the ﬁrst attempt to diagnose real-world power\ntransformers using a large amount of DGA data.\n2. The proposed SAAT has the ability to represent health\ndegradation properties as well as to identify normal\nand thermal/electrical fault types.\n3. By directly visualizing health features without transfor-\nmation or dimension reduction, the proposed 2D HFS\ncan pictorially demonstrate the monotonic health state\ntransition of transformers.\nThe rest of paper is organized as follows. Section II\ndescribes the background of SAAT. Sections III and IV\ndemonstrate the proposed method and experimental results,\nrespectively. Finally, the conclusions and future works of this\nstudy are outlined in Section V.\nII. BACKGROUND OF A SEMI-SUPERVISED\nAUTOENCODER WITH AN AUXILIARY TASK\nTwo basic algorithms (i.e., an autoencoder (AE) and a\nsoftmax classiﬁer (SC)) of the proposed SAAT are described\nin Sections II.A and II.B, respectively. In Section II.C, SSAE\nis explained in terms of the AE and the SC.\nA. AUTOENCODER: UNSUPERVISED FEATURE\nEXTRACTION\nAn AE, a well-known unsupervised neural network, consists\nof an encoder part and a decoder part with a hidden layer,\nas shown in Fig. 1 (a) [36]–[39]. For given training samples\nx ={x (1), x(2),··· ,x(N)}where N is the number of samples\nand x(m) ∈Rd (m =1,2,··· ,N), an encoder function f en\ncompresses the dimension of the training samples from Rd\nto Rd′\n(d > d′) with a set of encoder parameters θen (i.e., a\nweight matrix Wen ∈Rd′×d and a bias vector ben ∈Rd′\n), as:\nf en\n(\nx(m)\ni\n)\n=h(m)\nj =σAE\n(\nW en\nji x(m)\ni +ben\nj\n)\n(1)\nwhere σAE is an activation function, such as a sigmoid,\na rectiﬁed linear unit (ReLU), and an exponential linear\nunit (ELU) that transforms x(m) into a representative feature\nvector h(m) ∈Rd′\nwith θen. Then, in the decoder part, h(m)\n178296 VOLUME 8, 2020\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nFIGURE 1. Architectures of AE, SC, and SSAE: (a) pre-training in the AE; (b) fine-tuning in the SC with initialized\nparameters; and (c) simultaneous learning of the supervised and unsupervised learning parts in SSAE.\nis reconstructed to ˆx(m) ∈ Rd by a decoder function f de,\nwith a set of decoder parameters θde (i.e., a weight matrix\nWde ∈Rd×d′\n, and a bias vector bde ∈Rd ) as:\nf de\n(\nh(m)\nj\n)\n=ˆx(m)\nk =σAE\n(\nW de\nkj h(m)\nj +bde\nk\n)\n(2)\nwhere σAE transforms h(m) into ˆx(m).\nIn general, the loss function LAE is the mean square error\nbetween x(m) and ˆx(m) as:\nLAE\n(\nθen,θde\n)\n= 1\n2N\nN∑\nm=1\nˆx(m) −x(m)\n\n\n2\n= 1\n2N\nN∑\nm=1\nL(m)\nAE (3)\nwhere L(m)\nAE represents the m-th loss function. To minimize\nLAE, the parameters θAE = {θen, θde}are updated using\na backpropagation method with mini-batch gradient descent\nalgorithms. Using chain rules, the procedure of the parameter\nupdate is organized as:\nθde\nkj ←θde\nkj −η∂L(m)\nAE\n∂θde\nkj\n(\n∂L(m)\nAE\n∂θde\nkj\n=δde\nk\n∂z(m)\nk\n∂θde\nkj\n=δde\nk h(m)\nj\n)\n(4)\nθen\nji ←θen\nji −η∂L(m)\nAE\n∂θen\nji\n(\n∂L(m)\nAE\n∂θen\nji\n=δen\nj\n∂z(m)\nj\n∂θen\nji\n=δen\nj x(m)\ni\n)\n(5)\nwhere ηis a learning rate; z(m)\nk , δde\nk , z(m)\nj , and δen\nj are deﬁned,\nrespectively, as:\nz(m)\nk =W de\nkj h(m)\nj +bde\nk (6)\nδde\nk ≡∂L(m)\n∂z(m)\nk\n=σAE′(\nz(m)\nk\n)∂L(m)\n∂x(m)\nk\n(7)\nz(m)\nj =W en\nji x(m)\ni +ben\nj (8)\nδen\nj ≡∂L(m)\nAE\n∂z(m)\nj\n=\n∑\nk\n∂L(m)\nAE\n∂z(m)\nk\n∂z(m)\nk\n∂z(m)\nj\n=σAE′(\nz(m)\nj\n)∑\nk\nθde\nkj δk\n(9)\nδde\nk and δen\nj are errors in the decoder layer and the encoder\nlayer, respectively. This process is called pre-training.\nUsing the optimized θAE derived through (4) to (9), AE can\nextract h(m). Please note that the number of hidden layers in\nthe encoder and the decoder can be extended.\nB. SOFTMAX CLASSIFIER: SUPERVISED CLASSIFICATION\nSC has been widely used for the purpose of classifying\nmulti-classes by utilizing the extracted high-level features\nin AI-based algorithms [33], [34], [38]. When incorporat-\ning the SC into the AE, h(m) can be the input data of a\nsoftmax function, as shown in Fig. 1 (b). Training samples\nare a set of ordered pairs (x (m),y(m)) as {(x(1), y(1)), (x (2),\ny(3)),··· ,(x(N), y(N))}where y(m) ∈ {1,2,··· ,C}is a\nvirtual discrete number of a target label that corresponds to\nx(m). y(m) is a one-hot encoding vector that has C classes,\nexpressed as y(m) =(y(m)\n1 , y(m)\n2 ,··· ,y(m)\nC ). Using the softmax\nfunction q, the probability of each element in y(m) can be\ncalculated with respect to θen∗and θcl (i.e., a weight matrix\nWcl ∈RC×d′\n, and a bias vector bcl ∈RC ), as follows:\nˆy(m)\nn =P\n(\ny(m) =n|f en\n(\nx(m)\n)\n;θen∗,θcl\n)\n=q\n(\nz(m)\nn\n)\n=\nexp\n(\nz(m)\nn\n)\nC∑\nn=1\nexp\n(\nz(m)\nn\n) (10)\nwhere z(m)\nn is deﬁned as\nz(m)\nn =W cl\nnj h(m)\nj +bcl\nn (11)\nNote that n means the n-th element in y(m), as well as the\nnumber n in {1,2,··· ,C}. ˆy(m)\nn should satisfy ˆy(m)\nn ∈[0,1]\nand\nC∑\nn=1\nˆy(m)\nn =1.\nFor the best classiﬁcation performance, it is worth noting\nthat ﬁnding optimized parameters θen∗and θcl is an essential\nprocedure to match ˆy(m) with y(m). To minimize the discrep-\nancy between y(m) and ˆy(m), the cross-entropy loss function\nLcl has been widely used as [2]:\nLcl\n(\nθen∗\n,θclass\n)\n=−1\nN\nN∑\nm=1\ny(m)log\n(\nˆy(m)\n)\n(12)\nVOLUME 8, 2020 178297\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nLikewise, θen∗ and θcl are updated by mini-batch gradient\ndescent algorithms as:\nθcl\nnj ←θcl\nnj −η∂L(m)\ncl\n∂θcl\nnj\n(\n∂L(m)\ncl\n∂θcl\nnj\n=δcl\nn\n∂z(m)\nn\n∂θcl\nnj\n=δcl\nn h(m)\nj\n)\n(13)\nθen∗\nji ←θen∗\nji −η∂L(m)\ncl\n∂θen∗\nji\n(\n∂L(m)\ncl\n∂θen∗\nji\n=δen∗\nj\n∂z(m)\nj\n∂θen∗\nji\n=δen∗\nj x(m)\ni\n)\n(14)\nwhere z(m)\nn , δcl\nn , and δen∗\nj are deﬁned, respectively, as:\nz(m)\nn =W cl\nnj h(m)\nj +bcl\nn (15)\nδcl\nn ≡∂L(m)\ncl\n∂z(m)\nn\n=σcl′(\nz(m)\nn\n)∂L(m)\ncl\n∂ˆy(m)\nk\n(16)\nδen∗\nj ≡∂L(m)\ncl\n∂z(m)\nj\n=\n∑\nn\n∂L(m)\ncl\n∂z(m)\nn\n∂z(m)\nn\n∂z(m)\nj\n=σcl′(\nz(m)\nj\n)∑\nn\nθcl\nnj δcl\nn\n(17)\nThis process is called ﬁne-tuning. Using the feature\nextraction developed through the pre-training in the AE,\nthe classiﬁcation accuracy can be dramatically enhanced,\nas compared with SC in the absence of AE.\nC. SEMI-SUPERVISED AUTOENCODER\nDisjoint learning between the pre-training and the ﬁne-tuning\n– by sequentially performing AE and SC – can lead to\nthe extraction of features that are uncorrelated with the tar-\nget information of the labeled data or to distortion of the\nunderlying characteristics of the input training samples [40].\nWith this motivation, SSAE has been proposed, as shown in\nFig. 1 (c). Compared with the previous sequentially executed\ntraining process, SSAE achieves extraction of high-level fea-\ntures that are highly correlated with both the input data x and\nthe labeled information y, by simultaneously optimizing θAE\nand θcl [35], [40]–[43].\nA loss function LSSAE of SSAE is a summation of the two\nloss functions presented in (3) and (12) with a weight αas:\nLSSAE\n(\nθshd,θde,θcl\n)\n=αLAE\n(\nθshd,θde\n)\n+(1 −α)Lcl\n(\nθshd,θcl\n)\n(18)\nwhere the shared parameters θshd, which play the same role\nas θen in AE, are simultaneously optimized when training the\nrepresentative feature extraction task of AE and the classiﬁ-\ncation task of SC. For example, the procedure to update the\nparameters to minimize LSSAE is demonstrated as:\nθshd\nji ←θshd\nji −η∂L(m)\nSSAE\nθshd\nji\n×\n(\n∂L(m)\nSSAE\nθshd\nji\n=αδAE\nj x(m)\ni +(1 −α)δcl\nj x(m)\ni\n)\n(19)\nwhere δAE\nj and δcl\nj are equal to (9) and (16), respectively.\nFinally, the shared hidden layers with θshd are able to\nconcurrently extract representative features of x in the unsu-\npervised learning and the labeled information of y in the\nsupervised learning. For power transformer fault diagnosis,\nit can be inferred that SSAE enables identiﬁcation of the\nthermal/electrical fault types and normal state, as well as\nextraction of high-level features with a large amount of\nreal-world DGA data.\nIII. PROPOSED METHOD\nThis section demonstrates the proposed SAAT method.\nSection III.A presents the input DGA data preprocessing\napproach. Section III.B describes SAAT-based fault diagnosis\nmethod, including the role of the auxiliary detection task,\nthe architecture of SAAT, and HFS visualization. The overall\nprocedure is demonstrated in Fig. 2.\nA. INPUT DGA DATA PREPROCESSING\nIn the ﬁeld of AI, normalizing raw input data and balancing\nimbalanced data are essential steps to avoid overﬁtting prob-\nlems and to enable better classiﬁcation performance [28].\nFurthermore, from the viewpoint of power transformer fault\ndiagnosis, handcrafted features of dissolved gas ratios, which\nwere previously studied in rule-based methods, have been\nincorporated into AI-based methods to enhance the diagnosis\nperformance [28]. Details of each preprocessing step are\ndescribed as follows.\n1) SCALING OF INDUSTRIAL DGA DATA\nDissolved gas concentrations have signiﬁcantly skewed dis-\ntributions because their concentrations tend to dramatically\nincrease in a fault state, as compared with those in a normal\nstate. For example, the gas concentrations changed from a\nfew ppm (parts per million) to thousands of ppm in previous\nstudies [28]. Thus, the input DGA data is transformed into\na logarithmic scale. Further, to keep numerical operations\n(e.g., stochastic gradient descent) stable, the logarithmic-scaled\nDGA data is normalized from zero (min) to one (max).\n2) BALANCING OF IMBALANCED INDUSTRIAL DGA DATA\nSince real-world industrial transformers have highly imbal-\nanced data between normal and fault states, this imbalance\ncould disturb AI-based methods [28]. For example, if fault\ndatasets occupy only 1 % among the training datasets, most\nAI-based algorithms will be more focused on the classi-\nﬁcation of major normal datasets. Thus, an accuracy of\n99 % would be obtained by ignoring the minor – but crit-\nical – fault datasets and classifying all datasets as nor-\nmal. To address these imbalance problems, oversampling\ntechniques are applied into the fault datasets [28].\n3) COMBINING ADDITIONAL FEATURES RELATED TO GAS\nRATIOS\nWe consider six combustible gases (i.e., H 2, C 2H2, C 2H4,\nC2H6, CH 4, and CO). Each of the combustible gases\nis denoted as DGA i where i ranges from one to six.\nNormalized DGA i in the logarithmic scale is expressed as\nminimax(log([DGAi])). In rule-based methods, it is well\n178298 VOLUME 8, 2020\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nFIGURE 2. Overall procedures of the proposed SAAT-based fault diagnosis method.\nknown that the absolute values of gas concentrations can\nbe useful for the fault detection; however, it is desir-\nable to investigate the ratio-like relationships between the\ngas concentrations for fault identiﬁcation [28]. Therefore,\nwe consider six ratios of gas concentration DGA i to\ntotal gas concentration ∑\niDGAi in the logarithmic scale,\nas log([DGA i]/[∑\niDGAi]). Further, three ratios, developed\nby Duval triangle methods, are considered; these features are\nwidely used in diagnosing transformer fault types [44], [45].\nThe total preprocessed input data lies in 15 dimensions.\nB. SAAT-BASED FAULT DIAGNOSIS METHOD\nThe main concern of rule-based approaches is to monitor\nfault types. Since they do not take the normal state into\naccount, it is difﬁcult to visualize the overall health degrada-\ntion properties. Further, in AI-based approaches, only a few\nprior studies have been devoted to investigating health degra-\ndation features. Since trends of measured dissolved gases\npresent nonlinear properties over time while the health state is\nmonotonically degraded, it is desirable to extract new health\nfeatures that could also represent the monotonic health state\ntransition from normal to fault.\nMoreover, as it requires a tremendous cost to perform\nthorough visual inspection to recognize incipient faults every\ntime, most DGA data in industrial ﬁelds is unlabeled. Since\nsparse, fault-labeled data results in limitations in the ability\nto conﬁrm reliable quantitative results, additional qualita-\ntive methods have been developed, such as high-level fea-\nture visualization in 2D space using unsupervised dimension\nreduction algorithms (e.g., t-stochastic neighbor embedding\n(t-SNE) and self-organizing map (SOM)) [2], [31]. However,\nit is worth noting that some key information associated with\nfault diagnosis can be lost during the dimension reduction\nprocedure. Moreover, since both t-SNE and SOM have the\nFIGURE 3. Conceptual diagrams of the health feature space: (a) fault\nidentification task case in SSAE and (b) fault detection task case in SSAE.\nability to cluster the neighboring data, the correlation between\nhigh-level features cannot be guaranteed [31], [32], [46].\nThus, we propose a SAAT that an auxiliary detection\ntask, which is inserted into the loss function of SSAE, that\ncan achieve health degradation feature extraction. Further,\nSAAT-based fault diagnosis model can directly visualize the\ntwo high-level features in 2D, called the HFS, without addi-\ntional dimension reduction, while representing not only the\nfault identiﬁcation but also the health degradation properties.\nDetails are described as follows.\n1) ROLES OF THE AUXILIARY DETECTION TASK\nSince the fault identiﬁcation task in the supervised learning\npart of SSAE recognizes the three classes as independent\nclasses, it is not aware of whether both classes of electri-\ncal/thermal fault types are involved in fault states. Thus,\nthe only identiﬁcation task can lose the underlying char-\nacteristics of the fault detection. For example, when envis-\naging a 2D feature space, there could be two independent\ndirections that represent the health state transition, as shown\nin Fig. 3 (a); this is against the physical phenomenon of\nmonotonic health degradation. Here, it is important to note\nthat the fault detection task has the potential to present the\nVOLUME 8, 2020 178299\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nmonotonic state transition in a single direction, as shown in\nFig. 3 (b). An auxiliary detection task, which can tie the two\nclasses of electrical/thermal fault states into one fault state,\nis thus newly added. The proposed SAAT method has three\ntasks: 1) unsupervised learning to represent the input data\ncharacteristics, 2) supervised learning for fault identiﬁcation,\nand 3) supervised learning for auxiliary detection.\nThe parameters θSAAT of the proposed SAAT are as:\nθSAAT =\n{\nθshd,p,θiden, θde,q,θaux\n}\n(20)\nwhere θshd,p, θiden, θde,q, and θaux are shared parameters,\nidentiﬁcation parameters, decoder parameters, and auxiliary\ndetection parameters, respectively. Superscripts p and q stand\nfor the p-th and q-th hidden layers in the shared network and\nthe decoder, respectively. When training the tasks, the back-\npropagation method is used to optimize the parameters. In this\nstudy, this method transmits errors between key information\n(e.g., labeled information of electrical/thermal fault types and\nnormal state for the identiﬁcation task) and the output layer\nin each task, backward to each layer in the shared network.\nTraining each task is simultaneously executed with by opti-\nmizing θshd,p. Hence, θshd,p would possess all information of\noutput layers, θiden, θde,q, and θaux.\nA loss function LSAAT of the proposed SAAT is deﬁned\nas:\nLSAAT\n(\nθSAAT\n)\n=βLSSAE\n(\nθshd,p,θiden,θde,q\n)\n+(1 −β)Laux\n(\nθshd,p,θaux\n)\n+0.5λ\nθSAAT\n\n2\n(21)\nwhere LSSAE is similar to (18); the differences are that the\nnumber of layers are much more in (21) and θcl in (18)\nis changed to θiden. The loss function Laux of the auxiliary\ndetection task is newly proposed in (21). A hyperparameter\nβis the weight between LSSAE and Laux. In addition, to avoid\noverﬁtting problems, a L2 regularization term 0.5λ||θ SAAT||2\nis put in (21) with a hyperparameter λ[47]–[49].\nSAAT can be trained by updating θSAAT to minimize\nLSAAT. For example, in the case of θshd,end that are parameters\nin the end of the shared hidden layers and directly related\nto health feature extraction, the procedure of updating the\nparameters is demonstrated as:\nθshd,end\nji ←θshd,end\nji −η ∂L(m)\nSAAT\n∂θshd,end\nji\n(22)\nSimilar to (19), the second term in the right-hand side of (22)\ncan be decomposed as:\n∂L(m)\nSAAT\n∂θshd,end\nji\n=βδSSAE,end\nj hshd,end\ni +(1 −β)δaux\nj hshd,end\ni\n+λθshd,end\nji (23)\nwhere hshd,end\ni are high-level features obtained at the end\nof the shared hidden layers. Here, δSSAE,end\nj and δaux\nj are\nexpressed, respectively, as:\nδSSAE,end\nj =α×σde′(\nzj\n)∑\nk\nθde,1\nkj δde,1\nk\n+(1 −α)×σiden′(\nzj\n)∑\nk′\nθiden\nk′j δiden\nk′ (24)\nδaux\nj =σaux′(\nzj\n)∑\nk′′\nθaux\nk′′j δaux\nk′′ (25)\nwhere k, k’, and k’’ are dimensions of output nodes in the\nﬁrst layer of the decoder, fault identiﬁcation, and auxiliary\ndetection tasks, respectively. By inserting (24) and (25) into\n(23), θshd,end are updated as (22). Finally, high-level features\nobtained by the proposed SAAT could play roles in exhibiting\nboth fault identiﬁcation and health degradation.\n2) ARCHITECTURE OF THE PROPOSED SAAT\nAs shown in Fig. 4, the proposed SAAT consists of three\nshared hidden layers, three decoder hidden layers, and one\nhidden layer for each supervised task. Activation functions of\nall hidden layers, except for the supervised tasks, are ELUs;\nthis function has the advantages of not only increasing com-\nputational learning speeds in deep neural networks [50]–[52]\nbut also achieving robust optimization in backpropagation\nmethods. Activation functions of the output hidden layers in\ncases of fault identiﬁcation and auxiliary detection tasks are\nthe SC and the logistic regression for binary classiﬁcation,\nrespectively. Detailed parameters in SAAT architecture are\nsummarized in Table I. Both the number of epochs and batch\nsize are set as 200. α, β, λ, and ηare set as 0.25, 0.4, 0.0001,\nand 0.001, respectively.\nNote that we consider a compressed-type structure in the\nshared hidden layers. For the purpose of extracting only two\nhigh-level health features hHF ∈R2 that could be directly\nvisualized in the 2D space, the end of the shared hidden layer\nis set as having two nodes. These two nodes are connected\nwith the three tasks.\n3) HEALTH FEATURE SPACE VISUALIZATION\nFig. 5 depicts interpretation schemes for HFS. HFS is directly\nvisualized into 2D space (x -y plane); the features are denoted\nas ‘Health Feature 1 (HF1)’ and ‘Health Feature 2 (HF2)’,\nrespectively. x- and y-axes correspond to HF1 and HF2,\nrespectively. Here, to show the degree of health degradation,\nthe extracted health features are arranged to increase over\ntime.\nIt is expected that hHF for the training/test datasets can\nbe visualized with a set of four dots, as shown in Fig. 5.\nFurther, from the fault identiﬁcation task, the identiﬁcation\ndecision boundaries can be obtained and visualized. It is\nimportant to emphasize that the decision boundaries in 2D\nHFS have the following merits: 1) health states or fault types\ncan be determined for the labeled data and 2) the classes\nfor the unlabeled data can be predicted (pseudo-labeled) by\ninvestigating to which health state region the unlabeled data\nbelongs.\n178300 VOLUME 8, 2020\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nFIGURE 4. Architecture of the proposed SAAT: colors with orange, gray, and green in the shared hidden layers stand for the\nfeatures related to the fault identification, representative characteristics of DGA data, and health degradation (or health\nstate transition).\nTABLE 1. Parameters in the architecture of the proposed SAAT.\nMoreover, thanks to the auxiliary detection task, the mono-\ntonic health state transition from normal to fault will be\nobserved in 2D HFS. In real-world applications, normal\ntransformers gradually degrade as time passes. Then, one\nof the thermal/electrical fault types will occur at a certain\npoint. From this physical interpretation, the monotonic trend\nof the two health features in 2D HFS can be shown up to\na certain point; it tends to be slightly separated into one\nof two ways toward the thermal or electrical fault regions,\nwhich are divided by the decision boundaries. Therefore, it is\nworth noting that the proposed 2D HFS also enables intuitive\nvisualization of the historical health degradation information\nin terms of 1) the monotonicity between the health features\nand 2) the monotonic health state transition.\n4) OVERALL PROCEDURES OF THE PROPOSED SAAT-BASED\nFAULT DIAGNOSIS METHOD\nFig. 2 illustrates the ﬂowchart of the proposed SAAT-based\nfault diagnosis method. The ﬁrst step is to organize the col-\nlected DGA data into four groups: an unlabeled DGA dataset\n{Xun}, a labeled DGA dataset {Xla}, and labeled information\ndatasets {Yiden}and {Yaux}for the supervised tasks. After pre-\nprocessing, the input DGA datasets are denoted as {Xun∗}and\n{Xla∗}. To train SAAT model and evaluate its performance,\ndatasets, {Xun∗}, {Xla∗}, {Yiden}and {Yaux}are randomly\nseparated into training datasets and test datasets.\nThe next step is to construct and stabilize SAAT-based\nfault diagnosis model using the training datasets. Parameters\nin SAAT are randomly initialized. For given parameters,\nVOLUME 8, 2020 178301\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nFIGURE 5. Visualization scheme of HFS with labeled and unlabeled data.\nLiden, LAE, and Laux are calculated. With the given batch\nsize, the backpropagation method in the mini-batch gradi-\nent descent method can train SAAT model by repetitively\nupdating parameters. In addition, loss function calculation\nand parameter updates are iteratively implemented until\nsatisfying the given maximum epoch.\nAfter completing the training process, the health states\nof the unlabeled test datasets are pseudo-labeled by the\ndecision boundaries obtained in the fault identiﬁcation task.\nFurthermore, several evaluation metrics are calculated as\ndiagnosis results for the labeled and pseudo-labeled test\ndatasets. Finally, by directly visualizing hHF in 2D space,\nthe diagnosis results can be pictorially monitored.\nIV. PERFORMANCE EVALUATION OF THE PROPOSED\nMETHOD\nThis section is devoted to performance evaluation of the\nproposed SAAT method. Section IV.A presents a description\nof datasets provided by KEPCO and implementation of the\nproposed method. In Section IV.B, the experimental setup is\ndemonstrated. Lastly, the experimental results and discussion\nare covered in Section IV.C.\nA. DATA DESCRIPTION AND IMPLEMENTATION\nDGA data provided by KEPCO was obtained for three\ndecades, from 1980 to 2018. KEPCO measured nine gases\n(i.e., H2, C2H2, C2H4, C2H6, CH4, C3H8, CO, CO 2 and N2).\nAmong them, six combustible gases (H 2, C2H2, C2H4, C2H6,\nCH4 and CO) were studied in this work. Note that these\ngases are also included in the IEC TC 10 database, which\nis one representative open data set of dissolved gases [53].\nKEPCO’s DGA data can be divided into unlabeled data and\nlabeled data. Health states of the transformers are deﬁned\nfrom Table II, which summarizes the human-experienced\nthresholds of gases used in KEPCO. The company labeled\nthe transformers as normal when the concentrations of all\ngases were less than corresponding thresholds. On the other\nTABLE 2. KEPCO maintenance standards for power transformers.\nhand, electrical/thermal fault types were labeled after visual\ninspection when actual failures occurred.\nWe obtain 110,000 normal data, categorized into 73\nthermal fault data, and 48 electrical fault data as similar\nto IEC TC 10 fault types. As an example, historical DGA\ndata for four samples of KEPCO is listed in Table III. Next,\nunlabeled data was obtained from cases where some gas\nconcentrations were over the threshold values but visual\ninspection was not executed. The number of unlabeled data\nis 24,405. Note that the amount of DGA data used in this\nstudy is much larger than that used in previous studies\n(e.g., 4,642 DGA dataset in [34] and 3,000 DGA dataset in\n[54]). To validate the effectiveness of the proposed SAAT,\ntwo test datasets are examined: 1) 20% of KEPCO datasets\nand 2) IEC TC 10 datasets. It should be noted that 100 electri-\ncal/thermal faults were selected in the IEC TC 10 databases.\nEven though the transformer speciﬁcations of the IEC TC\n10 and KEPCO datasets are different, the scale of DGA data\nin the KEPCO databases is comparable to that in the IEC\nTC 10 databases. The difference between the two datasets is\nthat only DGA data for fault states is provided in the IEC TC\n10 databases.\nThe implementation of the proposed approach was\nexecuted on a desktop computer equipped with an Intel Core\ni7-6700K processor (4.00 GHz), 32 gigabytes of RAM, and\nan NVIDIA GeForce GTX 1080 graphics card (3072 CUDA\n178302 VOLUME 8, 2020\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nTABLE 3. Historical DGA data of four samples provided by KEPCO.\ncores, 24 gigabytes of GDDR5 memory). The training of the\nproposed SAAT was conducted with the NVIDIA graphics\ncard, while the other tasks (e.g., DGA data loading, fault\nclassiﬁcation and identiﬁcation, and HFS extraction) were\nconducted with the Intel processor. The computer was con-\ntrolled by Windows 10 and Python version 3.7. Computa-\ntional times for each step were as follows: 1) loading the\n110,000 DGA and preprocessing the dataset took 20 sec with\nthe Intel processor, 2) training the proposed method SAAT\nconsumed 61 sec, and 3) extracting the HFS took 15 sec.\nThus, the overall computational time took 96 sec.\nB. A BRIEF OUTLINE OF FOUR COMPARATIVE STUDIES\nAND QUANTATITIVE EVALUATION METRICS\nThe ﬁrst comparative study aims to validate the effectiveness\nof the auxiliary detection task in SSAE-based fault diagnosis\nmodel. We consider the following two models: 1) SSAE-DU\nand 2) SSAE-IU. Notations ‘D’, ‘I’, and ‘U’ stand for ‘fault\ndetection task’, ‘fault identiﬁcation task’, and ‘representative\nfeature extraction task’, respectively. Here, SSAE-DI is not\nconsidered, since a large portion of DGA data is unlabeled.\nNext, the validity of the proposed visualization method is\nelucidated in the second study. The following comparative\nmethods are considered: 1) t-SNE and 2) SOM. Depending\non how the high-level features hHF in SAAT are visualized,\nwe investigate whether the monotonic health state transition\ncan be represented in each method. In the third comparative\nstudy, we compared SAAT with existing methods to demon-\nstrate the superior diagnosis performance of the proposed\nSAAT approach. Here, existing methods that can perform\nthe unsupervised task were considered, such as principal\ncomponent analysis (PCA) [29], sparse autoencoder (SAE)\n[33], and deep belief network (DBN) [34]. Finally, the diag-\nnosis performance of state-of-the-art, semi-supervised deep\nlearning algorithms – such as a semi-supervised variational\nautoencoder (SV AE) and semi-supervised generative adver-\nsarial network (SGAN) – are described in the last comparative\nstudy. To perform a one-to-one comparison, SGAN and the\nSV AE have the same three tasks as the proposed SAAT.\nWe set parameters in SAE, DBN, SV AE, and SGAN, such as\nhyperparameters, layer and node sizes, activation functions\nin each layer, and the regularization terms, to be the same as\nthose in the proposed SAAT.\nWhen the given data suffers from imbalanced problems\n(e.g. the amount of data from the normal state is more than\n1000 times that of the fault state, as in this study), several\nmetrics are required to investigate the fault detection and\nidentiﬁcation performance. For the detection task, the fol-\nlowing three metrics are under consideration [55]: positive\npredictive value (PPV), fault detection rate (FDR), and bal-\nanced accuracy rate (BAR). For the fault identiﬁcation task\n[28], standard accuracy (I-Acc) is considered. With the con-\nfusion matrix presented in Table IV, these four metrics can be\nmathematically expressed as:\nPPV =\n2∑\ni=1\n2∑\nj=1\nCij\n/ 2∑\ni=1\n3∑\nj=1\nCij (26)\nFDR =\n2∑\ni=1\n2∑\nj=1\nCij\n/ 3∑\ni=1\n2∑\nj=1\nCij (27)\nBAR =0.5\n\n\n2∑\ni=1\n2∑\nj=1\nCij\n/ 3∑\ni=1\n2∑\nj=1\nCij +C33\n/ 3∑\ni=1\nCi3\n\n\n(28)\nI-Acc =\n2∑\ni=1\nCii\n/ 2∑\ni=1\n2∑\nj=1\nCij (29)\nIn addition, as the quantitative evaluation metrics of health\ndegradation performance in HFS, the following three metrics\nVOLUME 8, 2020 178303\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nTABLE 4. A confusion matrix for fault detection and identification\nevaluation metrics.\nare under consideration [56]: 1) the trendability (Tre) of each\nhealth feature in terms of time, 2) the consistency (Con)\nbetween health features in HFS, and 3) the monotonic cor-\nrelation coefﬁcient (MCC) between health features in HFS.\nThese metrics can be mathematically expressed as:\nTre =\nK\nK∑\nk=1\nHFk tk −\nK∑\nk=1\nHFk\nK∑\nk=1\ntk\n√\nK\nK∑\nk=1\nHF2\nk −\n( K∑\nk=1\nHFk\n)2√\nK\nK∑\nk=1\nt2\nk −\n( K∑\nk=1\ntk\n)2\n(30)\nCon =\nK∑\nk=1\n(\nHF1k −HF1Con\n)(\nHF2k −HF2Con\n)\n√\nK∑\nk=1\n(\nHF1k −HF1Con\n)2 (\nHF2k −HF2Con\n)2\n(31)\nMCC =\nN∑\nn=1\n(\nHF1n −HF1MCC\n)(\nHF2n −HF2MCC\n)\n√\nN∑\nk=1\n(\nHF1n −HF1MCC\n)2 (\nHF2n −HF2MCC\n)2\n(32)\nwhere K and N are the number of measured time points\nand that of points in HFS, respectively; HF1 k (or HF2k ) and\nHF1n (HF2n) are health features at the time tk and those at a\ncertain point n in HFS, respectively; HF1Con (or HF2Con) and\nHF1MCC (or HF2MCC) are mean values of the health features\nat all times and those at all points in HFS, respectively.\nFor one given sample, Tre aims at investigating the health\ndegradation properties (or monotonic health state transition)\nin the time domain and Con shows the correlation between\nhealth features. On the other hand, MCC represents the degree\nof the linearity between two health features for all samples,\nwhich are scattered in HFS. These metrics are bounded from\n-1 to 1; these bounds in Tre and Con mean that the features are\nthe strongest negative or positive linear correlation with time,\nrespectively; those in MCC mean the highest monotonicity\nin the space. Please note that our IEC TC 10 datasets are\nonly used for the I-Acc, since they do not have any historical\ninformation or normal state data.\nC. EXPERIMENTAL RESULTS AND DISCUSSION\n1) COMPARATIVE STUDY 1: EFFECTIVENESS OF THE\nAUXILIARY DETECTION TASK\nThe ﬁrst comparative study is to investigate the effective-\nness of the auxiliary detection task in SSAE-based fault\ndiagnosis model. Table V summarizes the quantitative results\nof the fault detection and identiﬁcation for SAAT, SSAE-DU,\nand SSAE-IU. For PPVs, SAAT shows the best fault detec-\ntion performance, which reaches up to 92.8%, as compared\nwith the others. FDRs of both SAAT and SSAE-IU are\n100%, while that of SSAE-DU is 97.9%. For BARs, three\ndiagnosis models exhibit more than 99%. It can be found\nthat SAAT and SSAE-IU show better fault detection perfor-\nmance than SSAE-DU, although SAAT and SSAE-IU use the\nfault identiﬁcation task that does not recognize whether\nthe classes of the electrical/thermal fault types belong to\nthe fault state. This can be interpreted from the number\nof classes; since SAAT and SSAE-IU have more classes\nto identify the fault types, they have more opportunities to\nimpose more weights into the two classes (electrical/thermal\nfault types) in the fault identiﬁcation task than one class\n(fault state) in the fault detection task. In the case of the fault\nidentiﬁcation performance, both SAAT and SSAE-IU show\nI-Acc of 100% for KEPCO datasets. It is worth pointing\nout that SSAE-DU cannot calculate I-Acc due to the lack of\nfault type information. For the IEC TC 10 datasets, SAAT\npresents a slightly better performance of 95.7% than that\nof SSAE-IU.\nIn terms of qualitative results, Figs. 6 (a) and (b) present\nHFSs that correspond to SSAE-IU and SSAE-DU, respec-\ntively. With the obtained decision boundaries, the results of\nthe fault detection and/or identiﬁcation can be visualized.\nHowever, it should be emphasized that Fig. 6 (a) cannot illus-\ntrate the monotonicity between health features and monotonic\nhealth state transition, as we expected in Fig. 3 (a). To support\nthis interpretation, Figs. 6 (a) and (d) show the trends of health\nfeatures for four samples, which are presented in Table III,\nin HFS, and in the time domain, respectively. As shown in\nFig. 6 (a), two independent ways for the health state transition\nare observed. Moreover, Fig. 6 (d) presents that HF1s of\nthe thermal faults (No. 3 and 4) tend to decrease, while\nHF2s gradually increases. Since these opposite trends are\ncontradictory to the physical phenomenon, it is difﬁcult for\nthe two health features of SSAE-IU to represent the health\ndegradation. For SSAE-DU, Fig. 6 (b) depicts the monotonic\nhealth state transition, as well as the high linearity between\nhealth features, as we expected in Fig. 3 (b). Further, from\nFig. 6 (e), it can be found that both health features steadily\nincrease. This implies that the fault detection task has the\nability to present the health degradation features; however,\nas presented in Table V, the fault identiﬁcation performance\ncannot be evaluated.\nIn summary, HFSs of SSAE-IU and SSAE-DU indi-\ncate that SSAE-IU can extract adequate health identiﬁca-\ntion features, while SSAE-DU can extract adequate health\ndegradation features. Therefore, by adding the auxiliary\ndetection task into the loss function of SSAE-IU, HFS of\nSAAT, shown in Fig. 6 (c), enables pictorial visualization\nnot only of the health identiﬁcation results but also of the\nslightly separated monotonic health state transition from nor-\nmal to each fault type. Furthermore, from four samples in\n178304 VOLUME 8, 2020\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nTABLE 5. Fault diagnosis performance of SAAE-IU, SSAE-DU, and the proposed SAAT.\nFIGURE 6. Results of comparative study 1: HFSs in (a) SSAE-IU, (b) SSAE-DU, and (c) the proposed SAAT; the trends of two health features with time for\nfour samples in (d) SSAE-IU, (e) SSAE-DU, and (f) the proposed SAAT.\nFigs. 6 (c) and (f), it can be seen that SAAT can successfully\nrealize the representation of the health degradation properties\nin HFS. We devise a strict meaning of HFS as 2D space\nthat can provide important information about both the health\nidentiﬁcation and health degradation.\nTable VI summarizes the quantitative results of the health\ndegradation. In the case of SSAE-IU, it can be conﬁrmed\nthat Tres of HF1 for the thermal fault have a negative sign,\ndespite the health degradation properties. Therefore, unlike\nthe results of SSAE-DU and SAAT, Cons for the electrical\nfault in SSAE-IU become the negative sign. These results\nare consistent with the intuitive interpretation from Fig. 6.\nIn addition, MCCs of 0.96 and 0.88 for SSAE-DU and SAAT\nare much closer to 1 than that of the 0.69 result for SSAE-\nIU. Thus, MCC, which stands for the monotonicity between\nhealth features, can indirectly represent the health degrada-\ntion performance of the health state transition in the time\ndomain. Thus, it can be concluded that the auxiliary detection\ntask signiﬁcantly improves the health degradation perfor-\nmance that would otherwise be a challenge for SSAE-IU to\nrepresent.\n2) COMPARATIVE STUDY 2: EFFECTIVENESS OF THE\nVISUALIZATION METHOD\nThe second comparative study is to investigate the effec-\ntiveness of the visualization method in the proposed SAAT\napproach. Here, there are two important points of emphasis.\nFirst, the feature spaces of t-SNE and SOM are obtained\nfrom the same values of HF1 and HF2 that were used when\nobtaining HFS in Fig. 6 (c). Second, since two high-level\nfeatures obtained from two nodes are visualized in 2D,\nissues of the dimension reduction do not exist in t-SNE\nor SOM.\nFigs. 7 (a) and (b) illustrate the obtained feature spaces that\ncorrespond to t-SNE and SOM, respectively. In Fig. 7 (a),\nboth electrical and thermal faults are well clustered. However,\nit can be conﬁrmed that the monotonic health state transition\nfrom normal to fault is not observed. The results of the\nsamples (No. 1 to 4) do not show any speciﬁc trend. These\nobservations are attributed to the characteristics of t-SNE.\nt-SNE converts similarities between the given high-level\nfeatures into joint probabilities and tries to minimize the\nKullback-Leibler divergence between the joint probabilities\nVOLUME 8, 2020 178305\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nTABLE 6. Health degradation performance of SSAE-IU, SSAE-DU and the proposed SAAT.\nFIGURE 7. Results of comparative study 2: HFSs in (a) t-sNE and (b) SOM.\nof the original features and converted features. During this\nprocess, the historical health degradation information in fea-\ntures can be signiﬁcantly lost or distorted; thus, t-SNE is not\nsuitable for representing the health degradation properties.\nIn Fig. 7 (b), the color map presents the results of the clus-\ntering. Since SOM has the ability to map an ordered pair of\nthe given high-level features HF1 and HF2 into a grid space,\na certain point in the grid space can represent a grouping of\nsimilar features. The color close to one (white), indicates that\nthe grid region consists of distinguishable features. On the\nother hand, the color close to zero (black), means that the grid\nregion is clustered with similar features. It can be seen that in\nthe feature space for SOM it is difﬁcult to distinguish the fault\nstates from the normal state. SOM is not suitable even for fault\ndetection and identiﬁcation before investigating the health\ndegradation characteristics of the transformers. Therefore,\nit can be concluded that the proposed direct visualization\nmethod enables depiction of both fault diagnosis results and\nmonotonic health state transition; it is otherwise a challenge\nfor t-SNE and SOM to represent these results.\n3) COMPARATIVE STUDY 3: CONVENTIONAL FAULT\nDIAGNOSIS METHODS\nNext, we compare the fault diagnosis performance of con-\nventional methods with those of the proposed SAAT. PCA,\nSAE, and DBN consider SC in the fault identiﬁcation task.\nFor PCA, extracted features from the unsupervised PCA\nalgorithms are used to obtain diagnosis results. For SAE and\nDBN, sequential learning approaches are used; the meth-\nods of Restricted Boltzmann Machines and AE are under\nconsideration in the pre-training part of SAE and DBN,\nrespectively.\nTable VII presents the quantitative results of fault detection\nand identiﬁcation for PCA, SAE and DBN. It can be seen\nthat PCA exhibits the worst diagnosis performance among\nthe four models. Unlike other conventional and proposed\nmethods, PCA is based on a fully unsupervised learning\napproach. The lack of labeled information makes it difﬁcult\nto guarantee that the extracted features have correlation and\nconsistency with the target labeling, thus worsening the detec-\ntion and identiﬁcation performance. Except for PPV, it can be\nseen that SAAT, SAE, and DBN show quite similar diagnosis\nperformance; however, PPV of 92.8% in SAAT is much\nhigher than those of 86.6% and 55.7% for SAE and DBN,\nrespectively. These results indicate two important ﬁndings.\nFirst, from the viewpoint of fault identiﬁcation results, it can\nbe regarded that SAE and DBN were trained correctly in this\nstudy, because the results show reasonably high performance,\nas presented in previous studies [33], [34]. Second, although\nthe ﬁrst result satisﬁes the existing performance, since SAE\n178306 VOLUME 8, 2020\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\nTABLE 7. Fault diagnosis and health degradation performance for conventional methods and state-of-the-art methods.\nFIGURE 8. Results of comparative study 3: HFSs in (a) PCA, (b) SAE, and (c) DBN.\nFIGURE 9. Results of comparative study 4: HFSs in (a) SVAE and (b) SGAN.\nand DBN are prone to Type I error (i.e., estimating truly\nnormal data as a fault), they could frequently raise a false\nalarm, which would be a vulnerability in terms of fault detec-\ntion performance.\nFor qualitative results, Figs. 8 (a) to (c) present HFSs\nthat correspond to PCA, SAE, and DBN, respectively.\nFig. 8 (a) depicts that several normal points are misdiag-\nnosed into fault regions; thus, the poor diagnosis perfor-\nmance of PCA can be conﬁrmed. This is consistent with\nthe quantitative results of fault detection and identiﬁcation.\nIn Figs. 8 (b) and (c), it can be seen that SAE and DBN can\nwell classify the three classes; however, it is worth noting\nthat they have difﬁculty representing the overall monotonicity\nbetween health features. The directions from the normal to\nthe two fault regions are independent. This interpretation\ncan be strengthened through the quantitative results of the\nhealth degradation, as shown in Table VII. MCC of 0.88 in\nSAAT is much closer to 1 than those of 0.00, 0.41 and\n0.42 in PCA, SAE and DBN, respectively. Therefore, it can\nbe concluded that the proposed SAAT approach outperforms\nconventional methods, with respect to the representation of\nhealth degradation in HFS.\nVOLUME 8, 2020 178307\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\n4) COMPARATIVE STUDY 4: STATE-OF-THE-ART\nSEMI-SUPERVISED DEEP LEARNING\nLastly, we investigate whether the auxiliary detection task\ncan be useful not only for SSAE method but also with other\nstate-of-the-art, semi-supervised deep learning methods. The\nauxiliary detection task is added to the classiﬁer part in\nSV AE and to the discriminator part in SGAN, respectively.\nTable VII presents the quantitative results of fault detection\nand identiﬁcation for SV AE and SGAN. Except for PPV, it\ncan be seen that SV AE, SGAN, and SAAT show quite similar\ndiagnosis performance; however, PPVs of 92.8% in SAAT\nand 92.6% in SV AE are much higher than that of 6.10% in\nSGAN. This indicates the following two messages: 1) SGAN\nis prone to Type I error, since it could be unstable when\noptimizing parameters under an adversarial learning process,\nand 2) SV AE with the auxiliary detection task exhibits the\nbest performance for fault detection and identiﬁcation.\nAs qualitative results, Figs. 9 (a) and (b) present HFSs that\ncorrespond to SV AE and SGAN, respectively. In Fig. 9 (a),\nit can be seen that SV AE can well classify the three classes; it\nis worth pointing out that it is difﬁcult to represent the overall\nmonotonicity between health features, since the distribution\nof the latent space of SV AE follows the Gaussian distribution.\nThe directions from normal to the two fault regions are inde-\npendent. In Fig. 9 (b), it can be seen that SGAN misdiagnoses\nthe normal points in the fault regions; thus, the poor diagnosis\nperformance of SGAN can be conﬁrmed and monotonicity\nbetween health features is not observed due to the unstable\nparameter optimization procedure. The quantitative results of\nthe health degradation are summarized in Table VII. MCC\nof 0.88 in SAAT is much closer to 1 than those of 0.44 and\n0.05 in SV AE and SGAN, respectively. Therefore, it can\nbe concluded that the auxiliary detection task can be well\nexecuted only for SSAE-based fault diagnosis model.\nV. CONCLUSION\nIn this study, a semi-supervised autoencoder with an auxiliary\ntask (SAAT) was newly proposed to diagnose industrial\npower transformers using dissolved gas analysis (DGA). The\nmethod was tested using a large amount of DGA datasets\nprovided by Korea Electric Power Corporation (KEPCO).\nThe proposed idea consists of three main steps: 1) pre-\nprocessing DGA data, 2) extracting two health features by\nSAAT method, and 3) visualizing the two health features\ninto two-dimensional space, a so-called health feature space\n(HFS). We evaluated the fault diagnosis and health degrada-\ntion performance of the proposed approach in four compara-\ntive studies. The ﬁrst study investigated the effectiveness of\nthe auxiliary detection task in a semi-supervised autoencoder\n(SSAE)-based fault diagnosis model. The quantitative results\nof the fault detection and identiﬁcation show that SAAT\nachieves over 90% performance in all metrics. Qualitative\nresults of HFS show that SAAT represented the integrated\ncharacteristics of fault identiﬁcation features in SSAE-IU and\nhealth degradation features in SSAE-DU. In the second com-\nparative study, the proposed method of directly visualizing\nheath features without transformation or dimension reduc-\ntion intuitively illustrates the health degradation proper-\nties as compared with conventional visualization methods\n(t-stochastic neighbor embedding (t-SNE) and self-organizing\nmap (SOM)). In the third study, SAAT outperformed all\nconventional fault diagnosis methods (principal component\nanalysis (PCA), sparse autoencoder (SAE), and deep belief\nnetwork (DBN)) in terms of both quantitative and qualitative\nresults of the health degradation performance. The last study\ninvestigated whether the auxiliary detection task can be useful\nnot only for SSAE method but also for other state-of-the-art,\nsemi-supervised deep learning methods (semi-supervised\nvariational autoencoder (SV AE) and semi-supervised gen-\nerative adversarial network (SGAN)). It was found that the\nauxiliary detection task can be well executed only for SSAE-\nbased fault diagnosis model. Therefore, these experimental\nresults examining real-world DGA datasets conﬁrm that the\nauxiliary detection task in SSAE provides the opportunity\nto investigate not only fault identiﬁcation but also health\ndegradation; further, HFS helps to intuitively monitor the\nhealth state of power transformers.\nFuture research is suggested, as follows. First, the\nprediction of health state and/or remaining useful life of\nindustrial power transformers should be performed using the\nproposed SAAT and its performance should be evaluated.\nSecond, the proposed SAAT method should be veriﬁed with\nother systems where the health degradation is an important\nissue, (e.g., batteries and rotary machinery). Finally, more\ndetailed fault types should be investigated, such as partial\ndischarge faults, electrical faults of low and high discharge,\nand thermal faults of low, medium and high level.\nACKNOWLEDGMENT\n(Sunuwe Kim and Soo-Ho Jo co-ﬁrst authors.)\nREFERENCES\n[1] C. Aj, M. A. Salam, Q. M. Rahman, F. Wen, S. P. Ang, and\nW. Voon, ‘‘Causes of transformer failures and diagnostic methods—\nA review,’’ Renew. Sustain. Energy Rev. , vol. 82, pp. 1442–1456,\nFeb. 2018.\n[2] H. Kim and B. D. Youn, ‘‘A new parameter repurposing method for\nparameter transfer with small dataset and its application in fault diagno-\nsis of rolling element bearings,’’ IEEE Access, vol. 7, pp. 46917–46930,\n2019.\n[3] S.-H. Jo, B. Seo, H. Oh, B. D. Youn, and D. Lee, ‘‘Model-based fault\ndetection method for coil burnout in solenoid valves subjected to dynamic\nthermal loading,’’ IEEE Access, vol. 8, pp. 70387–70400, 2020.\n[4] M. Dong, H. Zheng, Y. Zhang, K. Shi, S. Yao, X. Kou, G. Ding, and\nL. Guo, ‘‘A novel maintenance decision making model of power transform-\ners based on reliability and economy assessment,’’ IEEE Access, vol. 7,\npp. 28778–28790, 2019.\n[5] E. Li, L. Wang, and B. Song, ‘‘Fault diagnosis of power transformers with\nmembership degree,’’ IEEE Access, vol. 7, pp. 28791–28798, 2019, doi:\n10.1109/ACCESS.2019.2902299.\n[6] M. Duval, ‘‘A review of faults detectable by gas-in-oil analysis in\ntransformers,’’ IEEE Elect. Insul. Mag., vol. 18, no. 3, pp. 8–17,\nMay 2002.\n[7] Mineral Oil-Filled Electrical Equipment in Service. Guidance on the Inter-\npretation of Dissolved and Free Gases Analysis [Electronic Resource] B.\nEN, document 60599: 2016, 2016.\n[8] IEEE Guide for the Interpretation of Gases Generated in Oil-Immersed\nTransformers, standard C57.104-1991, Piscataway, NJ, USA, 2009.\n178308 VOLUME 8, 2020\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\n[9] E. Dornenburg and W. Strittmatter, ‘‘Monitoring oil-cooled transform-\ners by gas-analysis,’’ Brown Boveri Rev., vol. 61, no. 5, pp. 238–247,\n1974.\n[10] M. Duval, ‘‘The duval triangle for load tap changers, non-mineral oils and\nlow temperature faults in transformers,’’ IEEE Elect. Insul. Mag., vol. 24,\nno. 6, pp. 22–29, Nov. 2008.\n[11] D.-E.-A. Mansour, ‘‘Development of a new graphical technique for dis-\nsolved gas analysis in power transformers based on the ﬁve combustible\ngases,’’IEEE Trans. Dielectr. Electr. Insul., vol. 22, no. 5, pp. 2507–2512,\nOct. 2015, doi: 10.1109/TDEI.2015.004999.\n[12] V. Miranda and A. R. G. Castro, ‘‘Improving the IEC table for trans-\nformer failure diagnosis with knowledge extraction from neural networks,’’\nIEEE Trans. Power Del., vol. 20, no. 4, pp. 2509–2516, Oct. 2005, doi:\n10.1109/TPWRD.2005.855423.\n[13] R. Naresh, V. Sharma, and M. Vashisth, ‘‘An integrated neural\nfuzzy approach for fault diagnosis of transformers,’’ IEEE Trans.\nPower Del., vol. 23, no. 4, pp. 2017–2024, Oct. 2008, doi:\n10.1109/TPWRD.2008.2002652.\n[14] H.-T. Yang, C.-C. Liao, and J.-H. Chou, ‘‘Fuzzy learning vector quan-\ntization networks for power transformer condition assessment,’’ IEEE\nTrans. Dielectr. Electr. Insul., vol. 8, no. 1, pp. 143–149, Mar. 2001, doi:\n10.1109/94.910437.\n[15] Q. Su, C. Mi, L. L. Lai, and P. Austin, ‘‘A fuzzy dissolved gas analysis\nmethod for the diagnosis of multiple incipient faults in a transformer,’’\nIEEE Trans. Power Syst., vol. 15, no. 2, pp. 593–598, May 2000, doi:\n10.1109/59.867146.\n[16] K. Bacha, S. Souahlia, and M. Gossa, ‘‘Power transformer fault diagnosis\nbased on dissolved gas analysis by support vector machine,’’ Electr. Power\nSyst. Res., vol. 83, no. 1, pp. 73–79, Feb. 2012.\n[17] R. J. Liao, J. P. Bian, L. J. Yang, S. Grzybowski, Y. Y. Wang, and\nJ. Li, ‘‘Forecasting dissolved gases content in power transformer oil based\non weakening buffer operator and least square support vector machine-\nMarkov,’’IET Gener., Transmiss. Distrib., vol. 6, no. 2, pp. 142–151, 2012,\ndoi: 10.1049/iet-gtd.2011.0165.\n[18] H. Wu, X. Li, and D. Wu, ‘‘RMP neural network based dissolved gas\nanalyzer for fault diagnostic of oil-ﬁlled electrical equipment,’’ IEEE\nTrans. Dielectr. Electr. Insul., vol. 18, no. 2, pp. 495–498, Apr. 2011, doi:\n10.1109/TDEI.2011.5739454.\n[19] M. H. Wang, ‘‘Extension neural network for power transformer incipient\nfault diagnosis,’’ IEE Proc. Gener., Transmiss. Distrib., vol. 150, no. 6,\npp. 679–685, Nov. 2003, doi: 10.1049/ip-gtd:20030901.\n[20] Y.-C. Huang, ‘‘Evolving neural nets for fault diagnosis of power transform-\ners,’’IEEE Trans. Power Del., vol. 18, no. 3, pp. 843–848, Jul. 2003, doi:\n10.1109/TPWRD.2003.813605.\n[21] Z. Wang, Y. Liu, and P. J. Grifﬁn, ‘‘A combined ANN and expert system\ntool for transformer fault diagnosis,’’ IEEE Trans. Power Del., vol. 13,\nno. 4, pp. 1224–1229, 1998, doi: 10.1109/61.714488.\n[22] T. Kari, W. Gao, A. Tuluhong, Y. Yaermaimaiti, and Z. Zhang, ‘‘Mixed\nkernel function support vector regression with genetic algorithm for fore-\ncasting dissolved gas content in power transformers,’’ Energies, vol. 11,\nno. 9, p. 2437, Sep. 2018.\n[23] J. Li, Q. Zhang, K. Wang, J. Wang, T. Zhou, and Y. Zhang, ‘‘Optimal\ndissolved gas ratios selected by genetic algorithm for power transformer\nfault diagnosis based on support vector machine,’’ IEEE Trans. Dielectr.\nElectr. Insul., vol. 23, no. 2, pp. 1198–1206, Apr. 2016.\n[24] T. Hiroyasu, T. Shiraishi, T. Yoshida, and U. Yamamoto, ‘‘A feature\ntransformation method using genetic programming for two-class classi-\nﬁcation,’’ in Proc. IEEE Symp. Comput. Intell. Data Mining (CIDM),\nDec. 2014, pp. 234–240.\n[25] A. Shintemirov, W. Tang, and Q. H. Wu, ‘‘Power transformer fault clas-\nsiﬁcation based on dissolved gas analysis by implementing bootstrap and\ngenetic programming,’’ IEEE Trans. Syst., Man, Cybern., C, Appl. Rev.,\nvol. 39, no. 1, pp. 69–79, Jan. 2009.\n[26] V. Tra, B.-P. Duong, and J.-M. Kim, ‘‘Improving diagnostic performance\nof a power transformer using an adaptive over-sampling method for\nimbalanced data,’’ IEEE Trans. Dielectr. Electr. Insul., vol. 26, no. 4,\npp. 1325–1333, Aug. 2019, doi: 10.1109/TDEI.2019.008034.\n[27] Y. Cui, H. Ma, and T. Saha, ‘‘Improvement of power transformer insu-\nlation diagnosis using oil characteristics data preprocessed by SMOTE-\nBoost technique,’’ IEEE Trans. Dielectr. Electr. Insul., vol. 21, no. 5,\npp. 2363–2373, Oct. 2014, doi: 10.1109/TDEI.2014.004547.\n[28] P. Mirowski and Y. LeCun, ‘‘Statistical machine learning and dissolved\ngas analysis: A review,’’ IEEE Trans. Power Del., vol. 27, no. 4,\npp. 1791–1799, Oct. 2012.\n[29] R. M. A. Velásquez and J. V. M. Lara, ‘‘Principal components analysis\nand adaptive decision system based on fuzzy logic for power transformer,’’\nFuzzy Inf. Eng., vol. 9, no. 4, pp. 493–514, Dec. 2017.\n[30] T. Kari and W. Gao, ‘‘Power transformer fault diagnosis using FCM\nand improved PCA,’’ J. Eng., vol. 2017, no. 14, pp. 2605–2608,\nJan. 2017.\n[31] S. Misbahulmunir, V. K. Ramachandaramurthy, and Y. H. M. Thay-\noob, ‘‘Improved self-organizing map clustering of power transformer dis-\nsolved gas analysis using inputs pre-processing,’’ IEEE Access, vol. 8,\npp. 71798–71811, 2020.\n[32] K. F. Thang, R. K. Aggarwal, A. J. McGrail, and D. G. Esp,\n‘‘Analysis of power transformer dissolved gas data using the self-\norganizing map,’’ IEEE Trans. Power Del., vol. 18, no. 4, pp. 1241–1248,\nOct. 2003.\n[33] L. Wang, X. Zhao, J. Pei, and G. Tang, ‘‘Transformer fault diagnosis\nusing continuous sparse autoencoder,’’ SpringerPlus, vol. 5, no. 1, p. 448,\nDec. 2016.\n[34] J. Dai, H. Song, G. Sheng, and X. Jiang, ‘‘Dissolved gas analysis of\ninsulating oil for power transformer fault diagnosis with deep belief net-\nwork,’’IEEE Trans. Dielectr. Electr. Insul., vol. 24, no. 5, pp. 2828–2835,\nOct. 2017, doi: 10.1109/TDEI.2017.006727.\n[35] D. C. Ferreira, F. I. Vazquez, and T. Zseby, ‘‘Extreme dimensionality\nreduction for network attack visualization with autoencoders,’’ in Proc. Int.\nJoint Conf. Neural Netw. (IJCNN), Jul. 2019, pp. 1–10.\n[36] X. Li, H. Jiang, K. Zhao, and R. Wang, ‘‘A deep transfer nonnegativity-\nconstraint sparse autoencoder for rolling bearing fault diagnosis with few\nlabeled data,’’ IEEE Access, vol. 7, pp. 91216–91224, 2019.\n[37] H. Shao, H. Jiang, H. Zhao, and F. Wang, ‘‘A novel deep autoencoder\nfeature learning method for rotating machinery fault diagnosis,’’ Mech.\nSyst. Signal Process., vol. 95, pp. 187–204, Oct. 2017.\n[38] Y. Qi, C. Shen, D. Wang, J. Shi, X. Jiang, and Z. Zhu, ‘‘Stacked sparse\nautoencoder-based deep network for fault diagnosis of rotating machin-\nery,’’IEEE Access, vol. 5, pp. 15066–15079, 2017.\n[39] J. Dai, H. Song, G. Sheng, and X. Jiang, ‘‘Cleaning method for status moni-\ntoring data of power equipment based on stacked denoising autoencoders,’’\nIEEE Access, vol. 5, pp. 22863–22870, 2017.\n[40] W. Haiyan, Y. Haomin, L. Xueming, and R. Haijun, ‘‘Semi-supervised\nautoencoder: A joint approach of representation and classiﬁcation,’’ in\nProc. Int. Conf. Comput. Intell. Commun. Netw. (CICN), Dec. 2015,\npp. 1424–1430.\n[41] P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol, ‘‘Extracting and\ncomposing robust features with denoising autoencoders,’’ in Proc. 25th Int.\nConf. Mach. Learn. (ICML), 2008, pp. 1096–1103.\n[42] M. Chen, Y. Yao, J. Liu, B. Jiang, L. Su, and Z. Lu, ‘‘A novel approach\nfor identifying lateral movement attacks based on network embedding,’’ in\nProc. IEEE Intl Conf Parallel Distrib. Process. Appl., Ubiquitous Com-\nput. Commun., Big Data Cloud Comput., Social Comput. Netw., Sus-\ntain. Comput. Commun. (ISPA/IUCC/BDCloud/SocialCom/SustainCom),\nDec. 2018, pp. 708–715.\n[43] F. Zhuang, D. Luo, X. Jin, H. Xiong, P. Luo, and Q. He, ‘‘Representation\nlearning via semi-supervised autoencoder for multi-task learning,’’ in Proc.\nIEEE Int. Conf. Data Mining, Nov. 2015, pp. 1141–1146.\n[44] M.-T. Yang and L.-S. Hu, ‘‘Intelligent fault types diagnostic system for\ndissolved gas analysis of oil-immersed power transformer,’’ IEEE Trans.\nDielectr. Electr. Insul., vol. 20, no. 6, pp. 2317–2324, Dec. 2013, doi:\n10.1109/TDEI.2013.6678885.\n[45] S. Souahlia, K. Bacha, and A. Chaari, ‘‘MLP neural network-based deci-\nsion for power transformers fault diagnosis using an improved combination\nof rogers and doernenburg ratios DGA,’’ Int. J. Electr. Power Energy Syst.,\nvol. 43, no. 1, pp. 1346–1353, Dec. 2012.\n[46] X. Wu, Y. He, and J. Duan, ‘‘A deep parallel diagnostic method for\ntransformer dissolved gas analysis,’’ Appl. Sci., vol. 10, no. 4, p. 1329,\nFeb. 2020.\n[47] F. Zhang, J. Yan, P. Fu, J. Wang, and R. X. Gao, ‘‘Ensem-\nble sparse supervised model for bearing fault diagnosis in smart\nmanufacturing,’’ Robot. Comput.-Integr. Manuf., vol. 65, Oct. 2020,\nArt. no. 101920.\n[48] S. Nagpal, M. Singh, R. Singh, and M. Vatsa, ‘‘Regularized deep learn-\ning for face recognition with weight variations,’’ IEEE Access, vol. 3,\npp. 3010–3018, 2015.\n[49] F. Li, J. M. Zurada, Y. Liu, and W. Wu, ‘‘Input layer regulariza-\ntion of multilayer feedforward neural networks,’’ IEEE Access, vol. 5,\npp. 10979–10985, 2017.\nVOLUME 8, 2020 178309\nS. Kimet al.: SAAT for Power Transformer Fault Diagnosis Using DGA\n[50] D.-A. Clevert, T. Unterthiner, and S. Hochreiter, ‘‘Fast and accurate\ndeep network learning by exponential linear units (ELUs),’’\n2015, arXiv:1511.07289. [Online]. Available: http://arxiv.org/\nabs/1511.07289\n[51] L. Yang, W. Chen, W. Liu, B. Zha, and L. Zhu, ‘‘Random noise attenuation\nbased on residual convolutional neural network in seismic datasets,’’ IEEE\nAccess, vol. 8, pp. 30271–30286, 2020.\n[52] H. Shao, H. Jiang, Y. Lin, and X. Li, ‘‘A novel method for intelligent fault\ndiagnosis of rolling bearings using ensemble deep auto-encoders,’’ Mech.\nSyst. Signal Process., vol. 102, pp. 278–297, Mar. 2018.\n[53] M. Duval and A. dePabla, ‘‘Interpretation of gas-in-oil analysis using new\nIEC publication 60599 and IEC TC 10 databases,’’ IEEE Elect. Insul. Mag.,\nvol. 17, no. 2, pp. 31–41, Mar. 2001.\n[54] M. Noori, R. Effatnejad, and P. Hajihosseini, ‘‘Using dissolved gas analysis\nresults to detect and isolate the internal faults of power transformers by\napplying a fuzzy logic method,’’ IET Gener., Transmiss. Distrib., vol. 11,\nno. 10, pp. 2721–2729, Jul. 2017, doi: 10.1049/iet-gtd.2017.0028.\n[55] S. M. Frank, G. Lin, X. Jin, R. Singla, A. Farthing, L. Zhang, and\nJ. Granderson, ‘‘Metrics and methods to assess building fault detection and\ndiagnosis tools,’’ Nat. Renew. Energy Lab., Golden, CO, USA, Tech. Rep.,\n2019, pp. 11–14.\n[56] Y. Lei, N. Li, L. Guo, N. Li, T. Yan, and J. Lin, ‘‘Machinery health prognos-\ntics: A systematic review from data acquisition to RUL prediction,’’ Mech.\nSyst. Signal Process., vol. 104, pp. 799–834, May 2018.\nSUNUWE KIM received the B.S. degree from\nKorea University, Seoul, South Korea, in 2014.\nHe is currently pursuing the Ph.D. degree in\nmechanical and aerospace engineering from Seoul\nNational University, Seoul. His research inter-\nest includes prognostics and health management\nfor power transformers. He received an award\nas the PHM Society Data Challenge Competition\nWinner, in 2015.\nSOO-HO JOreceived the B.S. degree from Seoul\nNational University, Seoul, South Korea, in 2016,\nwhere he is currently pursuing the Ph.D. degree\nin mechanical and aerospace engineering. His cur-\nrent research interests include piezoelectric vibra-\ntion energy harvesting and elastic metamaterials.\nHe was a recipient of the Bronze Prize from\nthe KSME-SEMES Open Innovation Challenge,\nin 2016, the Best Paper Award from the KSME,\nin 2018 and 2020, the 2nd Place Winner in the\nStudent Paper Competition of the KSME, in 2018, the Best Paper Award\nfrom the KSNVE, in 2019, and the 2nd Place Winner in the PHM Society\nData Challenge Competition, in 2019.\nWONGON KIM received the B.S. degree from\nHanyang University, Seoul, South Korea, in 2015.\nHe is currently pursuing the Ph.D. degree in\nmechanical and aerospace engineering with Seoul\nNational University, Seoul. His current research\ninterests include model veriﬁcation and validation\n(V&V) and digital twins.\nJONGMIN PARK received the B.S. degree from\nSeoul National University, Seoul, South Korea,\nin 2017, where he is currently pursuing the Ph.D.\ndegree in mechanical and aerospace engineering.\nHis current research interests include prognostics\nand health management for rolling element bear-\nings and gas insulated switchgear. He received an\naward as the PHM Asia Paciﬁc Data Challenge\nWinner, in 2017 and 2019.\nJINGYO JEONG received the B.S. and M.S.\ndegrees from Hanyang University, Seoul, South\nKorea, in 1998 and 2004, respectively. He is\ncurrently pursuing the Ph.D. degree in mechan-\nical engineering with Seoul National University,\nSeoul. He is also a Senior Manager with the\nDepartment of Transmission & Substation Opera-\ntion, Korea Electric Power Corporation (KEPCO),\nNaju, South Korea. His current research interest\nincludes PHM for power transmission systems.\nYEONGMIN HAN received the B.S. degree in\nelectrical engineering from Konkuk University,\nSeoul, South Korea, in 2004, and the M.S. degree\nin electrical engineering from Korea University,\nSeoul, in 2018. He is a Senior Manager with the\nDepartment of Transmission & Substation Opera-\ntion, Korea Electric Power Corporation (KEPCO),\nNaju, South Korea.\nDAEIL KIM received the B.S. degree from Dong\nSeoul University, Seoul, South Korea. He is a\nSenior Manager with the Department of Transmis-\nsion & Substation Operation, Korea Electric Power\nCorporation (KEPCO), Naju, South Korea.\nBYENG DONG YOUN(Member, IEEE) received\nthe B.S. degree in mechanical engineering from\nInha University, Incheon, South Korea, in 1996,\nthe M.S. degree in mechanical engineering from\nthe Korea Advanced Institute of Science and Tech-\nnology, Daejeon, South Korea, in 1998, and the\nPh.D. degree in mechanical engineering from The\nUniversity of Iowa, Iowa City, IA, USA, in 2001.\nHe is currently a Full Professor of Mechani-\ncal Engineering with Seoul National University\n(SNU), and the Founder and CEO of OnePredict, Inc. His current research\ninterests include prognostics and health management (PHM), engineering\ndesign under uncertainty, and energy harvester design. His dedication and\nefforts in research have garnered substantive peer recognition, resulting\nin many notable awards, including the Commendation of Prime Minister,\nin 2019, the Shin Yang Academic Award from Seoul National University,\nin 2017, the IEEE PHM Competition Winner, in 2014, and the PHM Society\nData Challenge Winners, in 2014, 2015, 2017, and 2019.\n178310 VOLUME 8, 2020",
  "topic": "Autoencoder",
  "concepts": [
    {
      "name": "Autoencoder",
      "score": 0.7906200289726257
    },
    {
      "name": "Dissolved gas analysis",
      "score": 0.7584553956985474
    },
    {
      "name": "Computer science",
      "score": 0.7364203929901123
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5910118222236633
    },
    {
      "name": "Preprocessor",
      "score": 0.5377727746963501
    },
    {
      "name": "Data mining",
      "score": 0.5136046409606934
    },
    {
      "name": "Transformer",
      "score": 0.4957800805568695
    },
    {
      "name": "Deep learning",
      "score": 0.46658116579055786
    },
    {
      "name": "Visualization",
      "score": 0.46560078859329224
    },
    {
      "name": "Feature extraction",
      "score": 0.4415290951728821
    },
    {
      "name": "Machine learning",
      "score": 0.4215957820415497
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.3713236153125763
    },
    {
      "name": "Engineering",
      "score": 0.14453023672103882
    },
    {
      "name": "Transformer oil",
      "score": 0.07248303294181824
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I139264467",
      "name": "Seoul National University",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I198972184",
      "name": "Korea Electric Power Corporation (South Korea)",
      "country": "KR"
    }
  ],
  "cited_by": 30
}