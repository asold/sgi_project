{
  "title": "ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction",
  "url": "https://openalex.org/W4389519899",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5102676490",
      "name": "Yaorui Shi",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2128853312",
      "name": "An Zhang",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2596605561",
      "name": "En-zhi Zhang",
      "affiliations": [
        "Hokkaido University"
      ]
    },
    {
      "id": "https://openalex.org/A2051269448",
      "name": "Zhiyuan Liu",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2099081116",
      "name": "Xiang Wang",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3189262114",
    "https://openalex.org/W3181403764",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4243716178",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2964015378",
    "https://openalex.org/W3201083857",
    "https://openalex.org/W4253877692",
    "https://openalex.org/W2177317049",
    "https://openalex.org/W3169208069",
    "https://openalex.org/W2998367408",
    "https://openalex.org/W29374554",
    "https://openalex.org/W4386065596",
    "https://openalex.org/W2994678679",
    "https://openalex.org/W4320005767",
    "https://openalex.org/W3109892317",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W2765323781",
    "https://openalex.org/W4231645939",
    "https://openalex.org/W3209726219",
    "https://openalex.org/W3093934881",
    "https://openalex.org/W3146384714",
    "https://openalex.org/W4283687058",
    "https://openalex.org/W4365597205",
    "https://openalex.org/W4296001058",
    "https://openalex.org/W4292779060"
  ],
  "abstract": "Predicting chemical reactions, a fundamental challenge in chemistry, involves forecasting the resulting products from a given reaction process. Conventional techniques, notably those employing Graph Neural Networks (GNNs), are often limited by insufficient training data and their inability to utilize textual information, undermining their applicability in real-world applications. In this work, we propose **ReLM**, a novel framework that leverages the chemical knowledge encoded in language models (LMs) to assist GNNs, thereby enhancing the accuracy of real-world chemical reaction predictions. To further enhance the model‚Äôs robustness and interpretability, we incorporate the confidence score strategy, enabling the LMs to self-assess the reliability of their predictions. Our experimental results demonstrate that ReLM improves the performance of state-of-the-art GNN-based methods across various chemical reaction datasets, especially in out-of-distribution settings. Codes are available at https://github.com/syr-cn/ReLM.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 5506‚Äì5520\nDecember 6-10, 2023 ¬©2023 Association for Computational Linguistics\nReLM: Leveraging Language Models for Enhanced\nChemical Reaction Prediction\nYaorui Shi‚Ä° An Zhang¬ß‚àó Enzhi Zhang¬∂ Zhiyuan Liu¬ß Xiang Wang‚Ä°‚Ä†\n‚Ä°University of Science and Technology of China\n¬ßNational University of Singapore, ¬∂Hokkaido University\nyaoruishi@gmail.com, anzhang@u.nus.edu,\nenzhi.zhang.n6@elms.hokudai.ac.jp,\nacharkq@gmail.com, xiangwang1223@gmail.com\nAbstract\nPredicting chemical reactions, a fundamental\nchallenge in chemistry, involves forecasting the\nresulting products from a given reaction pro-\ncess. Conventional techniques, notably those\nemploying Graph Neural Networks (GNNs),\nare often limited by insufficient training data\nand their inability to utilize textual informa-\ntion, undermining their applicability in real-\nworld applications. In this work, we propose\nReLM, a novel framework that leverages the\nchemical knowledge encoded in language mod-\nels (LMs) to assist GNNs, thereby enhancing\nthe accuracy of real-world chemical reaction\npredictions. To further enhance the model‚Äôs\nrobustness and interpretability, we incorporate\nthe confidence score strategy, enabling the LMs\nto self-assess the reliability of their predic-\ntions. Our experimental results demonstrate\nthat ReLM improves the performance of state-\nof-the-art GNN-based methods across various\nchemical reaction datasets, especially in out-\nof-distribution settings. Codes are available at\nhttps://github.com/syr-cn/ReLM.\n1 Introduction\nPre-trained language models (LMs) possess a vast\nreserve of knowledge, coupled with impressive ca-\npabilities for logical inference (Brown et al., 2020;\nOpenAI, 2023; Taylor et al., 2022; Chowdhery\net al., 2022; Touvron et al., 2023; Chiang et al.,\n2023). These advantages render LMs useful for\nquestion-answering tasks, such as scientific inquiry\nand chemical inference (Bran et al., 2023; Shao\net al., 2023). However, due to LMs‚Äô black-box\nnatures, distinguishing whether the answers stem\nfrom their inherent knowledge or are arbitrarily\ngenerated poses a significant challenge. Further-\nmore, recent studies indicate that LMs struggle\n‚àóCorresponding author\n‚Ä†Xiang Wang is also affiliated with Institute of Artificial\nIntelligence, Institute of Dataspace, Hefei Comprehensive\nNational Science Center.\nwith the graph structures of molecules in chemistry-\nrelated tasks (Bran et al., 2023).\nRecently, graph neural networks (GNNs) have\nbeen widely used to address chemical reaction prob-\nlems due to their ability to handle complex graph\nstructures inherent in chemical compounds (He\net al., 2022; Somnath et al., 2021; Sacha et al.,\n2021). However, GNN-based methods often suffer\nfrom limited and biased training data, resulting in\npoor performance in real-world applications that\ninvolve diverse reaction mechanisms. This is ex-\nemplified by the unsatisfactory performance of Lo-\ncalRetro (Chen and Jung, 2021) on Imidazo and\nNiCOlit (see results in Table 1), especially when\nencountering new reaction types absent in the train-\ning set. In addition, it is difficult for GNNs to\neffectively leverage the textual information ( e.g.,\nreaction conditions) that could be derived from\nreaction descriptions. Identical reactants gas can\nyield different products depending on the catalyst\nused. An illustrative example is provided in Ap-\npendix C.1.\nA crucial question arises: can we develop a\nchemical reaction framework that synergistically\nintegrates the advantages of both GNNs and LMs?\nIn this work, we propose ReLM, a novel frame-\nwork designed to conduct chemical reaction predic-\ntion by utilizing both pre-trained LMs and GNNs.\nReLM enhances the prediction accuracy in out-of-\ndistribution (OOD) scenarios by utilizing graph\nstructure understanding of GNNs and the natural\nlanguage understanding capabilities of LMs. More\nspecifically, ReLM employs GNNs to generate sev-\neral high-probability candidate products. These\nproducts, along with appropriate in-context exam-\nples and descriptions of the reaction conditions, are\nthen fed into the LMs to facilitate accurate chemi-\ncal reaction prediction (as depicted in Figure 1). To\nfurther improve the robustness and interpretability\nof ReLM, we propose a prompting technique called\nthe confidence score strategy (CSS). Harnessing\n5506\n+ \t\"\t\nGNN\nCandidateProducts Top-2\nTop-3\nTop-1‚Ä¶\nLanguage Model\n[IUPAC name]<SMILES > Answer: Confidence Score: 9/10\nPlease answer the questions below and rate your confidence score.\n+ \t\n+ \t\n+ \t\nSimilarReactions\nQ: What do [prop-2-ynoic acid ] <C#CC(=O)O > and [1-bromo-3-methylbut-2-ene] <CC(=CCBr)C> produce {‚àÜwhen heated}?\nTrueAnswer: B (8/10)In-context example ùëÑ# TrueAnswer: A (9/10)In-context example ùëÑ\" FalseAnswer: B (2/10)In-context example ùëÑ!\n[but-2-enyl prop-2-ynoate]<CC=CCOC(=O)C#C>[butyl acetate]<CCCCOC(=O)C>[3-methylbut-2-enyl prop-2-ynoate]<CC(=CCOC(=O)C#C)C>\nABC\n{Reactioncondition}TargetReaction C?\nFigure 1: The overall framework of ReLM. The ReLM encompasses three key inputs for the language models:\nsimilar reactions (grey box), the target reaction along with its conditions (yellow box), and candidate products\ngenerated by GNNs (green box). Specifically, we select in-context examples with various confidence scores from\nthe training samples that are nearest to the target reaction query. Additionally, we choose the K-candidate products\nwith the highest likelihood as predicted by the GNN.\nthe intrinsic self-criticism capacity of LMs, CSS\nboosts the model‚Äôs performance without involving\nsignificant computational costs (see Table 5). Ex-\ntensive experiments on real-world Open Reaction\nDatabase (ORD) (Kearnes et al., 2021) demonstrate\nthat ReLM achieves significant improvement over\nstate-of-the-art GNN-based methods.\n2 Background\nChemical Reaction Analysis. Recent studies\nutilize language models (LMs) for molecule anal-\nysis, relying solely on Simplified Molecular Input\nLine Entry System (SMILES) as input for molec-\nular representation learning (Irwin et al., 2022;\nChithrananda et al., 2020; Fabian et al., 2020).\nHowever, SMILES only provides one-dimensional\nlinearizations of molecular structures, meaning that\nmolecules with identical SMILES may exhibit en-\ntirely different properties (Wang et al., 2022). In\ncontrast, GNN-based approaches take the structure\nof molecular graphs into consideration and have\nshown remarkable performance in in-distribution\nchemical reaction prediction tasks (Somnath et al.,\n2021; Dai et al., 2019).\nA chemical reaction between reactant set R =\n{r1,r2,¬∑¬∑¬∑} and product set P = {p1,p2,¬∑¬∑¬∑} can\nbe defined as:\nr1,r2,¬∑¬∑¬∑‚Üí p1,p2,¬∑¬∑¬∑. (1)\nFollowing the evaluation protocol established by\nWang et al., we can consider reaction prediction as\na task of ranking products within a predetermined\nproduct corpus C= {P1,P2,¬∑¬∑¬∑}. This evaluation\nprotocol ensures that Pi ‚ààC holds for all reactions\nRi ‚ÜíPi in the tests.\nGiven a query with reactants R, the model is\nrequired to search across the product corpus to\nidentify the most probable product. The likelihood\nbetween reactants and products is estimated using\nL2 distance between their corresponding molecular\nembeddings:\nD(R,P‚Ä≤) =‚à•\n‚àë\nr‚ààR\nG(r|Œ∏) ‚àí\n‚àë\np‚ààP‚Ä≤\nG(p|Œ∏)‚à•2 (2)\nwhere Ris the given set of reactant molecules in\na reaction, P‚Ä≤ ‚ààC is a product set from the cor-\npus, and G(¬∑|Œ∏) stands for the GNN model with\nparameter Œ∏.\nPrompting Strategies. Instead of directly ap-\nplying in-context learning to real-world tasks, some\nstudies use prompting strategies for better perfor-\nmance (Shao et al., 2023; Bran et al., 2023). A\ncommonly used strategy is instructing the language\nmodel to provide responses in a formalized for-\nmat (e.g., JSON or YAML). By using appropri-\nate prompts, the thought process of an LM can\nbe elicited using structured key-value pairs. Yang\net al. develop the Multi-Query Ensemble Strat-\negy (MES), which enhances the robustness of LMs.\nThis strategy involves iteratively querying an LM\nwith diverse in-context examples, conducting the\ninference process multiple times, and ultimately\nusing a majority vote to determine the outcome.\n3 Methodology\nIn this section, we propose ReLM, a framework\ncombining graph neural networks (GNNs) and lan-\nguage models (LMs) for chemical reaction anal-\nysis. ReLM employs GNNs to generate answer\ncandidates and in-context examples, then utilizes\nLMs for analysis in the form of multiple-choice\n5507\nquestions. We also propose the confidence score\nstrategy, a generic prompting strategy to improve\nthe reliability of LMs.\n3.1 Context Generation\nAnswer Candidates. The prompt for language\nmodels can be formulated with input reactants R,\nreaction condition c, and a set of answer candidates\nÀÜP generated by GNN encoder.\nThe process of answer candidates generation can\nbe succinctly described as data retrieval directed\nby a pre-trained GNN model.\nLeveraging insights from the field of chemistry,\nchemical equations encapsulate the conservation\nof matter, charge, and various chemical properties.\nThis implies a level of correspondence in the latent\nrepresentations of the molecules on both sides of\nthe equation. Therefore, for a specific set of re-\nactants R, we employ the distance measurement\nfunction defined in Equation (2) to filter out those\nproduct sets Pj ‚ààC that exhibit the highest simi-\nlarity to Rin the latent space.\nFormally, the answer candidates are generated\nby selecting the top-K products with the highest\nsimilarity from the candidate pool C:\nÀÜPR = TopK\nPj‚ààC\n‚àíD(R,Pj) (3)\nwhere ÀÜPR is the set of answer candidates for\nreactants R, and D is the GNN-based similarity\nmeasurement defined in Equation (2).\nIn-context Examples. Besides the reaction in-\nformation, the choice of in-context examples is also\ncrucial for LM‚Äôs few-shot learning performance. To\nacquire in-context examples that imply a reaction\nmechanism similar to the given reaction sample,\nwe use the answer-aware example selection strat-\negy proposed by Shao et al. (2023). Specifically,\nfor a given test sample, we choose top-N nearest\nneighbors from the training set based on the simi-\nlarity of their reactants in the latent space, and use\nthe N training samples as in-context examples:\nT = argTopN\ni‚àà{1,2,...,M}\nhT\nRhR‚Ä≤\ni\n‚à•hR‚à•2‚à•hR‚Ä≤\ni\n‚à•2\n(4)\nwhere M is the size of the training set, hR =‚àë\nr‚ààR G(r|Œ∏) is the sum of all reactant representa-\ntions, and T denotes the index set of the selected\ntraining samples. With the ground truth products\nai of each training sample, the in-context examples\nare defined as:\nE= {(R‚Ä≤\ni,c‚Ä≤\ni,a‚Ä≤\ni,ÀÜPR‚Ä≤\ni\n)|i‚ààT} (5)\nWith reaction information {R,c, ÀÜPR}and in-\ncontext examples E, the product prediction prob-\nlem can be formulated as a single select multiple\nchoice question. We input this question into the\npre-trained language model, and the answer gener-\nated by the model is regarded as the output of our\napproach:\nÀÜP = argmax\nP‚ààÀÜPR\npLM(P|{R,c, E}) (6)\nhere pLM(A|P) is the probability distribution of\nanswer Ain a language model given prompt Pas\ninput. To feed molecules into language models,\nwe use both IUPAC names and SMILES string to\nrepresent molecules. In Appendix C.2, we present\na detailed, step-by-step example of the context gen-\neration process.\n3.2 Confidence Score Strategy\nBesides prompting language models for chemical\nreaction prediction, we propose a universal prompt-\ning strategy named the confidence score strategy,\nwhich can be seamlessly transferred to any prompt-\nbased language model application.\nDuring inference, we ask the language model\nto report its confidence score (an integer number\nbetween 1 and 9) based on its understanding and\nfamiliarity with the given multi-choice question.\nTo help the language model better understand how\nthis score works, we also introduce the confidence\nscore in the context prompt. For each in-context\nexample, a random integer in {8,9}is chosen as\nthe confidence score, which is then combined with\nthe ground truth answer to form the prompt.\nNevertheless, the above random generation be-\nhavior can easily lead to a misunderstanding of\nthe meaning of confidence scores by the language\nmodels, resulting in a degradation where the model\nonly generates higher scores. Hence, we deliber-\nately distort the answer of an in-context example\nto an incorrect one and assign it to a lower confi-\ndence score (e.g., a random integer in{1,2}). Thus,\nEquation 5 can be rewritten as:\nÀúE= {(R‚Ä≤\ni,c‚Ä≤\ni, Àúai‚Ä≤,Àúsi‚Ä≤,ÀÜPR‚Ä≤\ni\n)|i‚ààT} (7)\nwhere Àúai‚Ä≤ is the perturbed answer and Àúsi‚Ä≤ is the\ncorresponding confidence score. By asking for\nthe confidence score, we let the language model\n5508\nimplicitly self-critique its answers during inference.\nIn Appendix D, we verify that the confidence score\nstrategy can be comprehended by language models.\n3.3 Fine-grained Confidence Score Strategy\nTo achieve a more detailed analysis of confidence\nand enhance the language model‚Äôs fine-grained in-\nterpretability, we also attempt to generate confi-\ndence scores for each answer candidate instead\nof a singular overall score. Subsequently, these\ncandidates are re-ranked based on their respective\nconfidence scores, selecting the one with the high-\nest confidence as the definitive answer. We refer\nto this methodology as the fine-grained confidence\nscore strategy. Please see more experimental re-\nsults and analysis in Section 4.4 and Appendix B.4\n.\n4 Experimental Results\nWe aim to answer the following research questions:\nRQ1: Can ReLM improve the reaction predic-\ntion capability of graph neural networks on both\nout-of-distribution and in-distribution data?\nRQ2: Does the confidence strategy enhance the\naccuracy of ReLM?\nRQ3: How does confidence score strategy influ-\nence the inference process of language models?\n4.1 Experiment Setup\nBaselines. Two popular GNN chemical reaction\nanalysis methods, MolR (Wang et al., 2022) and\nLocalRetro (Chen and Jung, 2021), are selected as\nGNN backbones. For language models, we test\nGPT-3.5 (Brown et al., 2020) and Vicuna (Chiang\net al., 2023). See more details in Appendix B.1.\nDatasets. We utilize the USPTO dataset to train\nthe GNN backbones. For evaluation, four datasets\nfrom the Open Reaction Database (ORD) (Kearnes\net al., 2021) are utilized as the testbed for our exper-\niments. The ORD contains diverse real-world reac-\ntion records from open-source projects and chem-\nical literature. Notably, its utility for GNN-based\nchemical reaction predictions remains largely un-\nderexplored.\n4.2 The OOD Capability of ReLM (RQ1)\nMotivation. To evaluate the model‚Äôs generaliza-\ntion ability, a comparison is made between our\nmethod and GNN baselines on the ORD dataset.\nNatural language descriptions of reactions, sourced\nfrom the ORD database, are utilized to enhance the\nquality of the prompts.\nResults. In Table 1 and Table 5 (see Appendix\nB.3), we present the average accuracy of ReLM\non the ORD dataset. ReLM improves the perfor-\nmance of GNN backbones across all test datasets.\nAs ReLM utilizes the top-K candidates provided\nby the GNN, the theoretical upper bound of our\napproach is constrained by the hit@ K accuracy\nof the GNN backbones. These upper bounds are\nalso delineated in tables. To assess the stability\nof ReLM, we examine its accuracy under varying\nK-values and degrees of in-context randomness.\nDetailed results can be found in Appendices B.6\nand B.7.\nApart from the evaluation on out-of-distribution\ndatasets, we also run experiments under indepen-\ndent and identically distributed (i.i.d.) conditions.\nRefer to Appendix B.5 for more results.\n4.3 Effectiveness of Confidence Score Strategy\n(RQ2)\nMotivation. The Confidence Score Strategy pro-\nposed in this paper is a generalizable prompt-\ning method. To verify the effectiveness of this\nstrategy, we conduct comparative experiments\nagainst other prompting strategies specifically tai-\nlored for multiple-choice questions. The baseline\nstrategies include the Multiple-Ensemble Strategy\n(MES)(Yang et al., 2022), the JSON Strategy, and\na control group that does not employ any strategy.\nMES necessitates multiple runs of the inference by\nthe language model (10 times in our experiments).\nA majority vote is conducted based on these re-\nsults, and the most frequently occurring answer\nis selected as the final outcome. By JSON strat-\negy, we refer to the strategy that asks the language\nmodels to present their understanding of reaction\nprecursors, reaction mechanisms, and its inferring\nprocess. Under this strategy, the language model is\nrequired to output all the above information along\nwith its answer in a machine-readable format.\nResults. In Table 2, we compare the overall accu-\nracy (Acc), number of input tokens (#Token), and\naverage inference time (Time/s) for each prompt-\ning strategy. Clearly, both the MES and JSON\nstrategies enhance the model‚Äôs performance, albeit\nwith non-negligible time costs. Conversely, our\nproposed Confidence Score Strategy (CSS) promi-\nnently improves the accuracy without imposing a\nnoticeable computational burden on the language\nmodel. See Appendix B.8 for comparison with\nmore prompting strategies.\n5509\nTable 1: Accuracy on out-of-distribution settings.\nImidazo NiCOlit Rexgen-30k Rexgen-40kK=3 K=4 K=3 K=4 K=3 K=4 K=3 K=4\nMolR (Wang et al., 2022)0.513 0 .513 0.437 0 .437 0.471 0 .471 0.448 0 .448ReLM (MolR + Vicuna)0.914+78.18% 0.878+71.07% 0.510+16.69% 0.523+19.70% 0.498+5.57% 0.499+5.84% 0.473+5.33% 0.473+5.31%\nReLM (MolR + GPT-3.5)0.865+68.53% 0.815+58.88% 0.443+1.37% 0.478+9.37% 0.486+3.12% 0.458‚àí2.82% 0.450+0.26% 0.467+4.05%\nUpper Bound 0.945 0 .979 0.640 0 .679 0.584 0 .611 0.562 0 .586\nLocalRetro (Chen and Jung, 2021)0.023 0 .023 0.086 0 .086 0.279 0 .279 0.245 0 .245ReLM (LocalRetro + Vicuna)0.023+0.00% 0.037+55.55% 0.173+99.07% 0.184+112.15% 0.325+16.47% 0.329+17.96% 0.295+20.29% 0.298+21.29%\nReLM (LocalRetro + GPT-3.5)0.031+33.33% 0.037+55.55% 0.224+157.71% 0.254+192.22% 0.348+24.64% 0.364+30.37% 0.308+25.44% 0.316+28.70%\nUpper Bound 0.033 0 .046 0.323 0 .340 0.409 0 .440 0.374 0 .406\nTable 2: Comparison of different prompting strategies\nwithin ReLM.\nRexgen-30k Rexgen-40kAcc #Token Time/sAcc #Token Time/s\nMolR + Vicuna w/o strategy0.472 940.6 2.19 0.449 942.3 2.19MolR + Vicuna JSON0.456 1087.4 27.0 0.422 1091.6 27.5MolR + Vicuna MES0.490 9402.0 22.2 0.463 9412.3 22.4MolR + Vicuna CSS0.497 991.6 1 .5 0.473 993.3 1 .5\nMolR + GPT-3.5 w/o strategy0.464 956.6 2.09 0.420 966.4 1.63MolR + GPT-3.5 JSON0.456 1087.4 27.0 0.422 1091.6 27.5MolR + GPT-3.5 MES0.476 9564.1 18.9 0.426 9661.6 18.4MolR + GPT-3.5 CSS0.486 1007.6 1.6 0.450 1017.4 2.0\nTable 3: Rank Correlation between ReLM‚Äôs fine-grained\nconfidence score and MolR‚Äôs candidates ranking.\nImidazo NiCOlit rexgen-30k rexgen-40k\nœÅ 0.363 0.359 0.346 0.347\nœÅ+ 0.469 0.429 0.388 0.397\nœÅ‚àí 0.243 0.227 0.199 0.174\nIt is noteworthy that ReLM achieves competitive\nor even superior results regardless of the prompting\nstrategy employed for the language model. These\nresults suggest that our reaction prediction method\nmaintains a high level of robustness irrespective of\nthe prompting techniques used.\n4.4 Interpretability of Confidence Scores\n(RQ3)\nMotivations. With more detailed confidence infor-\nmation, we aim to interpretably analyze the differ-\nences between language models and graph neural\nnetworks during decision-making processes, and\ninvestigate the reasons behind the performance en-\nhancement brought by LMs. We employ Spear-\nman‚Äôs rank correlation coefficient as the metric to\nascertain how the ranking produced by the LM cor-\nrelates with the original rankings from the GNN\nmodel.\nResults. For the evaluation of the fine-grained\nconfidence score strategy mentioned in Section 3.3,\nwe use MolR as the GNN backbone, Vicuna as\nthe language model, and K = 4. In Table 3, the\nsymbol œÅdenotes the rank correlation derived from\nReLM and MolR across all test samples. On the\nother hand, œÅ+ and œÅ‚àírepresent this correlation\nwhen MolR‚Äôs predictions are correct and incorrect\nrespectively.\nThis correlation sheds light on the consistency\nbetween these two models in their decision-making\nprocesses. The overall rankings of the ReLM ex-\nhibit a positive correlation with the rankings of the\nMolR, implying that the ReLM concurs with most\nof the MolR‚Äôs judgments.\nMoreover, the ReLM concurs with the MolR\nwhen it‚Äôs correct, and makes contradictory choices\nwhen it errs. This suggests that the ReLM is able\nto make informed judgments, diverging from the\nMolR when it believes the MolR is wrong. Ad-\nditional results under the fine-grained confidence\nscore strategy are in Appendix B.4. For further\nstatistical analysis pertaining to confidence scores,\nrefer to Appendix D.\n5 Conclusion\nDespite the great success of molecular structure\nunderstanding, today‚Äôs GNN-based reaction pre-\ndiction methods are still far from being able to\ndo real-world reaction analysis. In this work, we\nproposed ReLM, an in-context prompting method\nthat utilizes both language models and graph neu-\nral networks for chemical reaction prediction. Ex-\ntensive experiments demonstrate the remarkable\nimprovement of ReLM on various datasets indeed\ncomes from the reasoning ability and self-criticism\nof LMs.\nLimitations\nThe limitations of ReLM are in two aspects, which\nwill be addressed in future work. Firstly, ReLM\nfocuses solely on chemical reaction prediction,\nneglecting other essential tasks in chemical reac-\ntion analysis such as retrosynthesis planning and\nyield prediction. Secondly, the performance gains\nachieved by ReLM are hindered by the drawbacks\nof backbone GNNs. The accuracy improvement\nis restricted by the hit@Kmetric of GNN models,\nleading to only marginal advancements on specific\ndatasets, as demonstrated in Table 1. We believe\n5510\nour ReLM sheds light on chemical reaction pre-\ndiction tasks and will inspire more work in this\nresearch line.\nAcknowledgements\nThis research is supported by the National Natural\nScience Foundation of China (9227010114), the\nUniversity Synergy Innovation Program of Anhui\nProvince (GXXT-2022-040), and the NExT Re-\nsearch Center.\nReferences\nAndres M Bran, Sam Cox, Andrew D White, and\nPhilippe Schwaller. 2023. Chemcrow: Augmenting\nlarge-language models with chemistry tools. arXiv\npreprint arXiv:2304.05376.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In\nNeurIPS.\nShuan Chen and Yousung Jung. 2021. Deep retrosyn-\nthetic reaction prediction using local reactivity and\nglobal attention. JACS Au, 1(10):1612‚Äì1620.\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,\nZhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan\nZhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion\nStoica, and Eric P. Xing. 2023. Vicuna: An open-\nsource chatbot impressing gpt-4 with 90%* chatgpt\nquality.\nSeyone Chithrananda, Gabriel Grand, and Bharath\nRamsundar. 2020. Chemberta: Large-scale self-\nsupervised pretraining for molecular property pre-\ndiction.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, et al. 2022. Palm: Scaling\nlanguage modeling with pathways. arXiv preprint\narXiv:2204.02311.\nConnor W Coley, Wengong Jin, Luke Rogers, Timo-\nthy F Jamison, Tommi S Jaakkola, William H Green,\nRegina Barzilay, and Klavs F Jensen. 2019. A\ngraph-convolutional neural network model for the\nprediction of chemical reactivity. Chemical science,\n10(2):370‚Äì377.\nHanjun Dai, Chengtao Li, Connor W. Coley, Bo Dai,\nand Le Song. 2019. Retrosynthesis prediction with\nconditional graph logic network. In NeurIPS.\nJian Du, Shanghang Zhang, Guanhang Wu, Jos√©\nM. F. Moura, and Soummya Kar. 2017. Topol-\nogy adaptive graph convolutional networks. CoRR,\nabs/1710.10370.\nBenedek Fabian, Thomas Edlich, H√©l√©na Gaspar, Mar-\nwin Segler, Joshua Meyers, Marco Fiscato, and Mo-\nhamed Ahmed. 2020. Molecular representation learn-\ning with language models and domain-relevant auxil-\niary tasks.\nJiyan He, Keyu Tian, Shengjie Luo, Yaosen Min, Shuxin\nZheng, Yu Shi, Di He, Haiguang Liu, Nenghai Yu,\nLiwei Wang, Ji Wu, and Tie-Yan Liu. 2022. Masked\nmolecule modeling: A new paradigm of molecular\nrepresentation learning for chemistry understanding.\nRoss Irwin, Spyridon Dimitriadis, Jiazhen He, and\nEsben Jannik Bjerrum. 2022. Chemformer: a\npre-trained transformer for computational chem-\nistry. Machine Learning: Science and Technology,\n3(1):015022.\nSteven M Kearnes, Michael R Maser, Michael Wleklin-\nski, Anton Kast, Abigail G Doyle, Spencer D Dreher,\nJoel M Hawkins, Klavs F Jensen, and Connor W Co-\nley. 2021. The open reaction database. Journal of the\nAmerican Chemical Society, 143(45):18820‚Äì18826.\nSunghwan Kim, Paul A Thiessen, Evan E Bolton, Jie\nChen, Gang Fu, Asta Gindulyte, Lianyi Han, Jane He,\nSiqian He, Benjamin A Shoemaker, et al. 2016. Pub-\nchem substance and compound databases. Nucleic\nacids research, 44(D1):D1202‚ÄìD1213.\nThomas N. Kipf and Max Welling. 2017. Semi-\nsupervised classification with graph convolutional\nnetworks. In 5th International Conference on Learn-\ning Representations.\nDaniel Mark Lowe. 2012. Extraction of chemical struc-\ntures and reactions from the literature. Ph.D. thesis,\nUniversity of Cambridge.\nOpenAI. 2023. Gpt-4 technical report.\nKohulan Rajan, Achim Zielesny, and Christoph Stein-\nbeck. 2021. Stout: Smiles to iupac names using neu-\nral machine translation. Journal of Cheminformatics,\n13(1):1‚Äì14.\nMikolaj Sacha, Mikolaj Blaz, Piotr Byrski, Pawel\nDabrowski-Tumanski, Mikolaj Chrominski, Rafal\nLoska, Pawel Wlodarczyk-Pruszynski, and Stanislaw\nJastrzebski. 2021. Molecule edit graph attention net-\nwork: Modeling chemical reactions as sequences of\ngraph edits. J. Chem. Inf. Model., 61(7):3273‚Äì3284.\nPhilippe Schwaller, Benjamin Hoover, Jean-Louis Rey-\nmond, Hendrik Strobelt, and Teodoro Laino. 2021.\nExtraction of organic chemistry grammar from un-\nsupervised learning of chemical reactions. Science\nAdvances, 7(15):eabe4166.\n5511\nZhenwei Shao, Zhou Yu, Meng Wang, and Jun Yu. 2023.\nPrompting large language models with answer heuris-\ntics for knowledge-based visual question answering.\nIn Proceedings of the IEEE/CVF Conference on Com-\nputer Vision and Pattern Recognition, pages 14974‚Äì\n14983.\nVignesh Ram Somnath, Charlotte Bunne, Connor W.\nColey, Andreas Krause, and Regina Barzilay. 2021.\nLearning graph models for retrosynthesis prediction.\nIn NeurIPS.\nRoss Taylor, Marcin Kardas, Guillem Cucurull, Thomas\nScialom, Anthony Hartshorn, Elvis Saravia, Andrew\nPoulton, Viktor Kerkez, and Robert Stojnic. 2022.\nGalactica: A large language model for science. arXiv\npreprint arXiv:2211.09085.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timoth√©e Lacroix,\nBaptiste Rozi√®re, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al. 2023. Llama: Open and effi-\ncient foundation language models. arXiv preprint\narXiv:2302.13971.\nHongwei Wang, Weijiang Li, Xiaomeng Jin,\nKyunghyun Cho, Heng Ji, Jiawei Han, and\nMartin D. Burke. 2022. Chemical-reaction-aware\nmolecule representation learning. In ICLR.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R√©mi Louf, Morgan Funtowicz,\nand Jamie Brew. 2019. Huggingface‚Äôs transformers:\nState-of-the-art natural language processing. CoRR,\nabs/1910.03771.\nZhengyuan Yang, Zhe Gan, Jianfeng Wang, Xiaowei\nHu, Yumao Lu, Zicheng Liu, and Lijuan Wang. 2022.\nAn empirical study of gpt-3 for few-shot knowledge-\nbased vqa. In Proceedings of the AAAI Conference\non Artificial Intelligence , volume 36, pages 3081‚Äì\n3089.\nShuangjia Zheng, Jiahua Rao, Zhongyue Zhang, Jun\nXu, and Yuedong Yang. 2019. Predicting retrosyn-\nthetic reactions using self-corrected transformer neu-\nral networks. Journal of chemical information and\nmodeling, 60(1):47‚Äì55.\n5512\nA Datasets\nThe USPTO dataset used in Section 4 contains\napproximately 479k reaction samples, which are\ncollected by Lowe (2012) and cleaned by Zheng\net al. (2019).\nWe conduct our evaluation on four datasets ex-\ntracted from Open Reaction Database (Kearnes\net al., 2021). Considering there‚Äôs an overlap\nbetween the two Rexgen datasets and USPTO,\nwe exclude all reaction records in Rexgen-30k\nand Rexgen-40k that resulted in products already\npresent in the training set. This operation ensures\nthat the target products of test reactions have never\nbeen encountered during the training phase, impos-\ning higher demands on the model‚Äôs generalization\nability.\nThe datasets, Imidazo and NiCOlit, encompass\na wealth of textual descriptions of chemical reac-\ntions, which can be leveraged by language models\nfor inferential purposes (refer to Section 4.2). The\ncontents of the datasets utilized in this study are\nsummarized in Table 4. Additionally, we provide\na representation of some examples pertaining to\nreaction type and reaction condition information\ncontained within these datasets, as depicted in Fig-\nure 2.\nB Experiments\nB.1 Experiments Settings\nGNN models. For MolR (Wang et al., 2022), we\nuse the pre-trained checkpoints provided by its\nauthors on their GitHub repository. The check-\npoint model is trained on the USPTO dataset for 20\nepochs with a batch size of4096 and a learning rate\nof 1 √ó10‚àí4. Specifically, we use a 2-layer TAG\n(Du et al., 2017) as the GNN encoder, as it has\ndemonstrated superior performance in experiments\nof MolR. For LocalRetro (Chen and Jung, 2021),\nwe train the model on the USPTO reaction predic-\ntion dataset. Following the experimental settings\nof Chen and Jung, we use a 6-layer GCN (Kipf and\nWelling, 2017) as the backbone GNN and train it\nfor 50 epochs with a batch size of 16. The training\nprocess employs an Adam optimizer with a learn-\ning rate of 1 √ó10‚àí4 and weight decay of 1 √ó10‚àí6.\nDuring the Evaluation phase, we use 256 as batch\nsize for both MolR and LocalRetro.\nLanguage models. Training is not performed\nfor the language model backbones due to the high\ntraining cost of LMs. We interact with GPT-3.5\nthrough the OpenAI API, while for Vicuna, we\nemploy the model released by its authors on Hug-\ngingFace (Wolf et al., 2019). It‚Äôs worth noticing\nthat due to the substantial financial costs associ-\nated with accessing GPT-3.5, we only use random\nsubsets of size 500 of the test datasets when using\nGPT-3.5 as the backbone language model.\nHyperparameters. There are two important\nhyperparameters in our approach, the number of\nin-context examples N (see Equation 4) and the\nnumber of answer candidates K(see Equation 3).\nFor the number of answer candidates, we try K =\n3, 4, and 5. For the number of in-context examples,\nwe use a constant number N = 3throughout our\nexperiments.\nB.2 Implementation Details\nFor the speed test demonstrated in Table 2, we test\nall the involved methods on a single NVIDIA RTX\nA500 graphic card. For token count computation,\nwe use tiktoken, a fast open-source byte pair en-\ncoding tokenizer that can be used with OpenAI‚Äôs\nmodels. For fair comparisons, we also use this tok-\nenizer to count the token usage of Vicuna (Chiang\net al., 2023) in Section 4.3, even though it‚Äôs not\ndeveloped by OpenAI.\nThe training of LocalRetro requires atom-wise\nmatching between reactants and products, but the\ntraining dataset used by us does not contain such\ndata. We thus preprocess the training dataset with\nRxnmapper (Schwaller et al., 2021) to meet this\nrequirement.\nBesides, as shown in Figure 1, we use IUPAC\nnames along with SMILES to represent molecules\nin prompt design. However, the datasets only con-\ntain the SMILES expression of molecules. We\nleverage the database of PubChem (Kim et al.,\n2016) and open-source tool STOUT (Rajan et al.,\n2021) to perform the conversion from SMILES\nstrings to IUPAC names.\nB.3 Ablation Study of Reaction Conditions.\nTable 5 displays the results of ablation studies\non descriptive reaction information. Incorporat-\ning reaction conditions (e.g., reaction temperature\nand catalysts) and reaction type information in\nthe prompts leads ReLM to achieve higher per-\nformance gains than compared to only reactant\ninformation.\n5513\nTable 4: Statistics of the Four Datasets in the Open Reaction Database\nName Size Description Reaction SMARTS Reaction Type Reaction Condition\nImidazo 384 Three-component reaction approach towards diverse imidazopyridines reactions./enc-34 /enc-34 /enc-34\nNiCOlit 1762 Nickel-catalyzed cross-couplings reactions. /enc-34 /enc-34 /enc-37\nRexgen-30k 7700 Test data used by Rexgen (Coley et al., 2019). /enc-34 /enc-37 /enc-37\nRexgen-40k 10235 Validation data used by Rexgen (Coley et al., 2019). /enc-34 /enc-37 /enc-37\nFigure 2: Examples of reaction type and condition in Imidazo and NiColit.\nTable 5: Ablation study of textual reaction information.\nImidazo NiCOlitGPT-3.5 VicunaGPT-3.5 Vicuna\nMolR (Wang et al., 2022)0.513 0.513 0.437 0.437ReLM (MolR) 0.812 0.765 0.412 0.521+ reaction type 0.822 0.903 0.478 0.523+ reaction type and condition0.864 0.914 - -\nTable 6: Accuracies with multiple confidence strategy.\nImidazo NiCOlit rexgen-30k rexgen-40k\nMolR 0.513 0.437 0.471 0.449\nReLLM 0.870 0.507 0.449 0.421\nB.4 Accuracy of fine-grained Confidence\nScore Strategy.\nIn this section, we test the performance of the fine-\ngrained confidence score strategy (introduced in\nSection3.3). Table 6 displays the accuracies of\nboth the ReLM and GNN models when using the\nmultiple-CSS strategy. Although ReLM‚Äôs perfor-\nmance does not surpass that of the original CSS\nstrategy, it offers a greater degree of interpretabil-\nity.\nB.5 Evaluation on In-distribution Dataset\nThe experiments in Section 4.2 demonstrate the\npowerful out-of-distribution performance of ReLM.\nWe also conducted experiments under the indepen-\ndently and identically distributed (i.i.d.) setting\non the test set of USPTO-479k. The results are\nshown in Table 7. This part of the experiment was\nconducted on the test set of USPTO-479k, using\nTable 7: Evaluation on the test set of USPTO.\nMolR LocalRetro\nMolR 0.882 0.5663\nReLM (MolR+Vicuna)0.871 0.6273\nUpper Bound 0.9527 0.7583\nVicuna as the language model and MolR as the\nGNN backbone, with K = 4. Due to the exten-\nsive size of the USPTO dataset, we do not conduct\nexperiments under all experimental settings.\nIn Table 7, it can be observed that GNN meth-\nods have solely achieved considerable performance\nin in-distribution scenarios, thus the performance\nenhancements provided by ReLM are limited in\nthis circumstance. Furthermore, the lack of reac-\ntion type and condition information in the USPTO\ndataset also presents inference difficulties for the\nlanguage model. Despite these challenges, ReLM\nstill exhibited a certain capacity to select the cor-\nrect answers from the options, without exhibiting\nsignificant performance deterioration.\nB.6 Effect of Different K-Values\nGiven that the accuracy upper bound of ReLM is\ndetermined by the number of answer candidates,\nit is necessary to evaluate the performance of the\nmodel under different K levels. In this section,\nwe conduct experiments across a wider range of\nK values. The results are presented in Figure 3\nusing MolR as the GNN backbone and Vicuna as\nthe language model. It can be observed in the table\nthat ReLM‚Äôs performance remains relatively stable\n5514\nFigure 3: Accuracy under different Kvalues\nTable 8: Accuracy over fixed and randomized in-context\nconfidence scores.\nImidazo NiCOlit rexgen-30k rexgen-40k\nGNN only (MolR) 51.30% 43.70% 47.13% 44.89%Fixed: {1} and {9} 91.93% 53.94% 48.65% 45.62%Randomized: {1,2} and {8,9}87.76% 52.32% 49.88% 47.27%Randomized: {1,2,3} and {7,8,9}91.41% 53.78% 48.51% 45.52%\nas Kincreases across a wide range of values (e.g.\nK = 2‚àº7), and at some point, the performance\ngets better as K increases. However, with very\nlarge Kvalues (e.g. K ‚â•10), the accuracy of the\nmodel exhibited a noticeable decrease.\nThis drop in accuracy with extremely large K\nvalues is likely because the candidates become\noverly saturated with implausible options, making\nit more difficult for the language model to discern\nthe correct answer. Since there could be at most\none ground truth candidate, increasing K means\nadding more distracting and unlikely candidates.\nWhile the model is robust to these distractors up to\na point, at some threshold of implausible options\nthe task does become more challenging.\nB.7 Influence of In-context Randomness\nIn Section 3.1 we introduce the generation process\nof in-context examples. For each in-context exam-\nple, we choose a random integer within {8,9}(or\n{1,2}) as its confidence score. This intuitive ran-\ndom selection aims to faithfully mimic human be-\nhavior when answering the multiple-choice chem-\nistry question. In this section, we demonstrate the\nefficacy of this strategy through comparative exper-\niments.\nIn Table 8 we show the performance of ReLM\nunder different levels of in-context randomness.\nThe experiments are carried out using K = 4, Vi-\ncuna as the language model, and MolR as the GNN.\nTable 9: ReLM with other strategies.\nImidazo NiCOlit rexgen-30k rexgen-40k\nMolR 0.513 0.437 0.471 0.449\nZero-shot 0.870 0.446 0.301 0.286\nFew-shot CoT0.781 0.305 0.267 0.244\nZero-shot CoT0.844 0.415 0.318 0.302\nCSS 0.878 0.523 0.499 0.473\nUpper Bound0.979 0.679 0.611 0.587\nIn the table, we can observe that using varying\nconfidence scores causes slight fluctuations in ex-\nperimental outcomes, though the degree varies by\ndataset. This further demonstrates that the effective-\nness of our ReLM lies not in the details of prompt\ndesign. Instead, it stems from our main idea of\namalgamation of the molecular modeling ability\ninherent to GNNs with the vast reaction knowledge\nof the language model.\nB.8 Comparison with More Prompting\nStrategies\nIn addition to the prompting strategies in Section\n4.3, we also included Zero-shot, Few-shot CoT,\nand Zero-Shot CoT as baseline prompting methods.\nTable B.8 shows the experimental results of these\nmethods.\nWe observe that all prompt designs offer some\nbenefits. However, our original confidence score\napproach still outperforms these baselines. Specifi-\ncally, as shown in the case studies in Section C.3,\nthe language model‚Äôs CoT analysis may not pro-\nvide additional insightful information regarding\nthe reaction mechanism. At this stage, incorporat-\ning additional analytical steps may introduce more\nmolecular structures, exacerbating the language\nmodel‚Äôs comprehension difficulties. Further step-\nby-step elucidation of the reaction process likely\nnecessitates incorporating more domain knowledge\nof chemical reactions.\nC Case Studies\nC.1 Importance of Reaction Condition\nPrevious GNN-based reaction analysis models\ncould only process molecular graphs and were un-\nable to utilize the abundant information contained\nwithin chemical reaction conditions. However,\nmany chemical reaction conditions exert profound\ninfluences on the reaction mechanisms, determin-\ning the direction of synthesis. In this section, we\nillustrate the importance of reaction conditions to\nreaction outcomes through an example from the\nImidazo dataset.\n5515\nIn Figure 4, we report the answers from GNN\nand ChatGPT to two chemical reaction problems\ninvolving the same reactants. The only difference\nbetween these two problems is that problem 2 does\nnot include reaction conditions and types. Question\n1 is the target reaction given the correct catalyst,\nwhile Question 2 omits the important catalyst. For\nGNN, it incorrectly predicts ‚ÄôB‚Äô as the answer for\nboth questions. In contrast, the language model ac-\ncurately identifies option ‚ÄôC‚Äô for Question 1, which\naligns with the ground truth. However, for Ques-\ntion 2, the language model predict a product that\nwas not present in the candidate pool.\nIn reality, this organic reaction involves three\ncomponents - an aldehyde, an amine, and an iso-\ncyanide. Without an added catalyst, the combina-\ntion of these three reactants undergoes a Passerini\nreaction, which is a type of multi-component\ncondensation. Nevertheless, in the presence of\nthe trifluoroacetic acid catalyst, the reaction pro-\nceeds via an imidazopyridine formation mecha-\nnism. This leads to the major product being\n‚ÄôC‚Äô, 3-[3-(cyclohexylamino)-6-methylimidazo[1,2-\na]pyridin-2-yl]benzene-1,2-diol.\nThese case studies clearly demonstrate that iden-\ntical reactants yield different products under dif-\nferent reaction conditions, further reinforcing our\ndriving hypothesis: the incorporation of reaction\ntype and condition boosts the predictive accuracy\nof ReLM.\nC.2 Illustration of Inferring Process\nIn Section 4.2, we mentioned that the accuracy up-\nper limit of ReLM is determined by the hit@ K\nmetric of the backbone GNN model. In this sec-\ntion, we furnish an illustrative example to elucidate\nour proposed methodology more comprehensively.\nFigure 5 provides a step-by-step demonstration of\nour method when K = 4. The in-context examples\nhave been omitted for brevity.\nC.3 Examples of Prompting Strategies\nIn Section 4.3 we compare the confidence score\nstrategy with other prompting strategies. In Figure\n6, we use an example from the NiCOlit dataset\nto further demonstrate the difference between the\ninvolved prompting strategies.\nD Statistical Analysis\nIn this paper, we posit that language models possess\nthe capability to comprehend confidence scores and\nassign corresponding scores based on their famil-\niarity with the questions. In this section, we elu-\ncidate this claim by presenting the distribution of\nthese scores across a large number of samples, that\nconfidence scores can indicate ReLM‚Äôs degree of\ncomprehension of the queries.\nWe illustrate the distribution of confidence\nscores using the Rexgen-40 dataset, employing Vi-\ncuna + MolR as backbones. The results are pre-\nsented in Figure 7. Confidence scores of ReLM\nexhibit significantly different distributions between\ncorrect and incorrect answers. For incorrect ReLM\nchoices, the proportion of high confidence scores\n(7 ‚àº9) decreased from 82.3% to 51.2%, while\nthat of low confidence scores ( 1 ‚àº3) increased\nfrom 4.4% to 22.7%.\nAdditionally, we designed experiments to com-\npare the accuracy of the large model at different\nconfidence levels. We divide the datasets into two\nparts based on the model‚Äôs output confidence and\ncalculate the accuracy separately. The results are\nshown in Table 10. The \"High Conf.\" column rep-\nresents the model‚Äôs accuracy on the subset with\nhigher confidence, and the \"Low Conf.\" column\nrepresents the accuracy on the part with lower con-\nfidence. For all control groups, ReLM‚Äôs accuracy\non high-confidence samples is significantly higher\nthan those with lower confidence (p-value ¬´ 0.05).\n5516\nTable 10: Accuracy under high/low confidence levels. The \"High Conf.\" column represents the accuracy of the\nmodel on the subset with higher confidence, and the \"Low Conf.\" column represents the lower ones. ReLM‚Äôs\naccuracy on high-confidence samples is significantly higher than those with lower confidence (p-value ¬´ 0.05).\nRexgen-30k Rexgen-40k\nk=3 k=4 k=3 k=4\nMolR 0.471 0.471 0.448 0.448\nReLM (MolR + Vicuna) High Conf. 0.500¬±0.235 0.502¬±0.2340.477¬±0.229 0.478¬±0.229\nLow Conf. 0.361¬±0.300 0.329¬±0.3050.330¬±0.291 0.288¬±0.293\nReLM (MolR + GPT-3.5)High Conf. 0.525¬±0.201 0.525¬±0.2570.499¬±0.160 0.510¬±0.198\nLow Conf. 0.438¬±0.268 0.333¬±0.3130.400¬±0.245 0.440¬±0.254\nLocalRetro 0.279 0.279 0.245 0.245\nReLM (LocalRetro + Vicuna)High Conf. 0.330¬±0.163 0.332¬±0.1900.299¬±0.151 0.302¬±0.178\nLow Conf. 0.235¬±0.203 0.213¬±0.2200.238¬±0.181 0.190¬±0.203\nReLM (LocalRetro + GPT-3.5)High Conf. 0.368¬±0.130 0.405¬±0.1320.321¬±0.117 0.337¬±0.150\nLow Conf. 0.248¬±0.203 0.270¬±0.2190.200¬±0.181 0.262¬±0.193\n5517\nFigure 4: The answers from GNN and ChatGPT to two similar chemical reaction problems. The only difference\nbetween these two questions is the existence of reaction conditions. The GNN incorrectly predicts ‚ÄôB‚Äô as the answer\nfor both questions. In contrast, the language model accurately identifies ‚ÄôC‚Äô as the answer for the first problem, but\nfails to predict the second question. These case studies demonstrate that identical reactants yield different products\nunder different reaction conditions.\n5518\nFigure 5: The step-by-step illustration of the inferring process. The test case is from the Imidazo dataset.\n5519\nFigure 6: Illustration of different prompting strategies. The in-context examples in the few-shot CoT and Confidence\nScore strategies have been omitted for brevity.\nFigure 7: Distribution of Confidence Scores on Rexgen-40 dataset.\n5520",
  "topic": "Interpretability",
  "concepts": [
    {
      "name": "Interpretability",
      "score": 0.9012512564659119
    },
    {
      "name": "Computer science",
      "score": 0.7702304124832153
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.6619894504547119
    },
    {
      "name": "Machine learning",
      "score": 0.5466381907463074
    },
    {
      "name": "Artificial intelligence",
      "score": 0.47513583302497864
    },
    {
      "name": "Reliability (semiconductor)",
      "score": 0.4536237120628357
    },
    {
      "name": "Chemical process",
      "score": 0.45243245363235474
    },
    {
      "name": "Chemistry",
      "score": 0.12359720468521118
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Organic chemistry",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Power (physics)",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I126520041",
      "name": "University of Science and Technology of China",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I165932596",
      "name": "National University of Singapore",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I205349734",
      "name": "Hokkaido University",
      "country": "JP"
    }
  ],
  "cited_by": 6
}