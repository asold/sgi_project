{
  "title": "The Curious Case of Hallucinatory (Un)answerability: Finding Truths in the Hidden States of Over-Confident Large Language Models",
  "url": "https://openalex.org/W4389518688",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3152717851",
      "name": "Aviv Slobodkin",
      "affiliations": [
        "Bar-Ilan University"
      ]
    },
    {
      "id": "https://openalex.org/A2517553135",
      "name": "Omer Goldman",
      "affiliations": [
        "Bar-Ilan University"
      ]
    },
    {
      "id": "https://openalex.org/A2990253534",
      "name": "Avi Caciularu",
      "affiliations": [
        "Bar-Ilan University",
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A356610775",
      "name": "Ido Dagan",
      "affiliations": [
        "Bar-Ilan University"
      ]
    },
    {
      "id": "https://openalex.org/A2889907260",
      "name": "Shauli Ravfogel",
      "affiliations": [
        "Bar-Ilan University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4389520380",
    "https://openalex.org/W3159900299",
    "https://openalex.org/W3190126809",
    "https://openalex.org/W4402683869",
    "https://openalex.org/W4385572928",
    "https://openalex.org/W3196731672",
    "https://openalex.org/W3171002765",
    "https://openalex.org/W4309217888",
    "https://openalex.org/W4285309972",
    "https://openalex.org/W3034292689",
    "https://openalex.org/W4296713955",
    "https://openalex.org/W4312205996",
    "https://openalex.org/W3184144760",
    "https://openalex.org/W2964204621",
    "https://openalex.org/W4285429195",
    "https://openalex.org/W3104939451",
    "https://openalex.org/W3176477796",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W1983599491",
    "https://openalex.org/W4287887161",
    "https://openalex.org/W3099524945",
    "https://openalex.org/W4389520749",
    "https://openalex.org/W4284668485",
    "https://openalex.org/W2912924812",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W4385573190",
    "https://openalex.org/W4327811009",
    "https://openalex.org/W4306313145",
    "https://openalex.org/W4389524407",
    "https://openalex.org/W4389523771",
    "https://openalex.org/W4205649227",
    "https://openalex.org/W4386566737",
    "https://openalex.org/W2970862333",
    "https://openalex.org/W4294955582",
    "https://openalex.org/W2963323070",
    "https://openalex.org/W4225595179",
    "https://openalex.org/W4367701241",
    "https://openalex.org/W4206637810",
    "https://openalex.org/W3162404768",
    "https://openalex.org/W4385571050",
    "https://openalex.org/W3199958362",
    "https://openalex.org/W2970820321",
    "https://openalex.org/W4285595056",
    "https://openalex.org/W3198963017",
    "https://openalex.org/W3035241006",
    "https://openalex.org/W4377865297",
    "https://openalex.org/W2949961827",
    "https://openalex.org/W4205384019",
    "https://openalex.org/W4312091849",
    "https://openalex.org/W2963748441",
    "https://openalex.org/W2515741950",
    "https://openalex.org/W4306892733",
    "https://openalex.org/W3102657423",
    "https://openalex.org/W2970641574"
  ],
  "abstract": "Large language models (LLMs) have been shown to possess impressive capabilities, while also raising crucial concerns about the faithfulness of their responses. A primary issue arising in this context is the management of (un)answerable queries by LLMs, which often results in hallucinatory behavior due to overconfidence. In this paper, we explore the behavior of LLMs when presented with (un)answerable queries. We ask: do models represent the fact that the question is (un)answerable when generating a hallucinatory answer? Our results show strong indications that such models encode the answerability of an input query, with the representation of the first decoded token often being a strong indicator. These findings shed new light on the spatial organization within the latent representations of LLMs, unveiling previously unexplored facets of these models. Moreover, they pave the way for the development of improved decoding techniques with better adherence to factual generation, particularly in scenarios where query (un)answerability is a concern.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 3607–3625\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nThe Curious Case of Hallucinatory (Un)answerability: Finding Truths in\nthe Hidden States of Over-Confident Large Language Models\nAviv Slobodkin1, Omer Goldman1, Avi Caciularu1,2, Ido Dagan1, Shauli Ravfogel1\n1Bar-Ilan University 2Google Research\n{lovodkin93, omer.goldman, shauli321}@gmail.com\navica@google.com\ndagan@cs.biu.ac.il\nAbstract\nLarge language models (LLMs) have been\nshown to possess impressive capabilities, while\nalso raising crucial concerns about the faith-\nfulness of their responses. A primary issue\narising in this context is the management of\n(un)answerable queries by LLMs, which of-\nten results in hallucinatory behavior due to\noverconfidence. In this paper, we explore\nthe behavior of LLMs when presented with\n(un)answerable queries. We ask: do mod-\nels represent the fact that the question is\n(un)answerable when generating a hallucina-\ntory answer? Our results show strong indica-\ntions that such models encode the answerability\nof an input query, with the representation of the\nfirst decoded token often being a strong indica-\ntor. These findings shed new light on the spatial\norganization within the latent representations of\nLLMs, unveiling previously unexplored facets\nof these models. Moreover, they pave the way\nfor the development of improved decoding tech-\nniques with better adherence to factual gen-\neration, particularly in scenarios where query\n(un)answerability is a concern.1\n1 Introduction\nModern large language models (LLMs) have been\ntantalizing the NLP community in the last couple\nof years (Brown et al., 2020; Chen et al., 2021;\nChung et al., 2022), demonstrating great potential\nfor both research and commercial use, but these\nmodels are of course not problem-free. Among\ntheir unfavorable behaviors it is possible to find\ntoxicity (Welbl et al., 2021; Deshpande et al., 2023),\nbias (Nadeem et al., 2021; Abid et al., 2021), and\nhallucination (Manakul et al., 2023; Ji et al., 2023).\nOne of the settings in which LLMs are notori-\nously prone to hallucinate is when presented with\n(un)answerable questions (Sulem et al., 2021; Asai\n1Our code is publicly available at https://github.com/\nlovodkin93/unanswerability\n(a) SQuAD\n(b) NQ\n(c) MuSiQue\nFigure 1: 3D PCA projection of the last hidden layer’s\nembedding of Flan-UL2 on each of the three bench-\nmarks. The left images show the embeddings with\nthe regular prompt, and the right ones — with a hint-\nincluding prompt. Blue and red dots are examples\ncorrectly detected by the model as answerable and\n(un)answerable, respectively, while the pink dots are\nfor (un)answerable examples that the model provided\nanswers to. The figures show the good separability be-\ntween the three groups.\nand Choi, 2021; Amayuelas et al., 2023). Recent\nworks in this setting, which is the focus of this\nwork, suggested using models’ confidence as an\nindication of answerability (Yin et al., 2023), and\nsome suggested further finetuning to enhance the\nprobability of detecting (un)answerable questions\n3607\n(Jiang et al., 2021; Kadavath et al., 2022). We, how-\never, ask whether models already represent ques-\ntions’ (un)answerablility when producing answers,\nand find strong evidence for a positive answer.\nSpecifically, by experimenting with three QA\ndatasets (Rajpurkar et al., 2018; Kwiatkowski et al.,\n2019; Trivedi et al., 2022), we observe a substan-\ntial increase in performance for (un)answerable\nquestions (up to 80%) simply by incorporating\nto the prompt the possibility of (un)answerability.\nWe further show that, even in the absence of\nguidance in the prompt, the fact that the ques-\ntion is (un)answerable is decodable from the\nmodel’s representations. This is done by two meth-\nods: first, we find that the beam of decoded re-\nsponses for (un)answerable queries often contains\na response recognizing their (un)answerability;\nsecond, we demonstrate that the fact that the\nquestion is (un)answerable is easily decodable\nfrom the model’s representations and that there\nis a linear separation between representations of\n(un)answerable and (un)answerable questions (see\nFigure 1). The existence of the answerability\nsubspace is largely independent of the specific\nQA dataset used, in the sense that an answerabil-\nity classifier trained over representations of ques-\ntions from one dataset can successfully classify\n(un)answerable questions from other datasets as\nwell. In addition to providing illuminating insights\ninto the internal mechanics of LLMs, these find-\nings also open up new avenues for better decod-\ning methods (Meister et al., 2020; Wiher et al.,\n2022) to improve performance in general and on\n(un)answerable questions in particular.\n2 Related Work\nIn previous research, (un)answerable questions\nwere used to evaluate reasoning capabilities (Ra-\njpurkar et al., 2018; Ferguson et al., 2020;\nKwiatkowski et al., 2019; Trivedi et al., 2022).\nIt was SQuAD v2 (Rajpurkar et al., 2018)\nthat provided the first reading comprehension\ndataset for validating models’ ability to deal\nwith (un)answerability, by introducing questions\nthat cannot be addressed from the given context.\nKwiatkowski et al. (2019) followed the same line\nand included about a third of (un)answerable ques-\ntions in their NATURAL QUESTIONS (NQ), an\nannotated open-domain QA dataset. Recently,\nMuSiQue (Trivedi et al., 2022) was introduced as a\nchallenging multi-hop QA benchmark that consists\nof (un)answerable questions, in which supporting\nparagraphs have been intentionally removed from\nthe context. Our experiments use these datasets to\ndemonstrate the effectiveness of our approach to\nidentify (un)answerability.\n(Un)answerability capabilities in LLMs were\nmainly studied by using few-shot prompting (Kand-\npal et al., 2022; Weller et al., 2023). Moreover, sev-\neral works have recently shown that LLMs become\neasier to steer with natural language prompts either\nas they become larger (Mishra et al., 2022a; Kand-\npal et al., 2022; Carlini et al., 2023) or as they are\nexposed to larger instruction tuning data (Mishra\net al., 2022b; Chung et al., 2022; Wan et al.,\n2023a), and as a consequence, it might improve the\n(un)answerability capabilities of the model. Specif-\nically, in this work, we utilize prompt manipulation\nin order to systematically reveal to the model the\noption of avoiding answering hard questions. Auto-\nmatic prompt tuning can be also used for improving\n(un)answerability capabilities, without the need for\nmanual handcrafting prompts. Liao et al. (2022) in-\ntroduced a prompt tuning-based strategy to mitigate\n(un)answerable questions, by mapping questions\ninto their proper, specific templates.\nOther works tried to manipulate the model pre-\ndictions towards better (un)answerability via using\ndata augmentation (Zhu et al., 2019), and Asai and\nChoi (2021) provided an in-depth analysis of the\nability to detect (un)answerability in LMs, where\nthe case study is the data which is fed to the model.\nFurthermore, recent studies have suggested uti-\nlizing recent advances in white-box model inter-\npretability (Geva et al., 2022b; Li et al., 2022;\nMallen et al., 2022; Mickus et al., 2022; Meng\net al., 2023; Geva et al., 2023) and probing (Adi\net al., 2017; Conneau et al., 2018; V oita et al., 2019;\nSlobodkin et al., 2021) for manipulating the model\npredictions and analyzing when LLMs struggle to\nanswer questions. Recent works also tried to use\nbeam search decoding to manipulate the generated\noutputs by using the information encapsulated in\nseveral beams (Meister et al., 2020; Leblond et al.,\n2021; Slobodkin et al., 2023; Wan et al., 2023b).\nFinally, early exiting in language models (Schwartz\net al., 2020; Schuster et al., 2022; Din et al., 2023)\nand model prediction calibration (Desai and Dur-\nrett, 2020; Jiang et al., 2021; Dhuliawala et al.,\n2022; Geva et al., 2022a) are strongly related to our\nwork, as they suggest to analyze and improve the\nmodel predictions and output distribution.\n3608\nFigure 2: Combinations of prompt variants in this work.\nIn addition to some basic instructions, our prompts can\nalso have a \"hint\" to the possibility of (un)answerability,\nas well as 2 exemplars.\n3 Method\nWe posit the hypothesis that, despite the inclination\nof LLMs to produce answers to (un)answerable\nqueries, they do encode the (un)answerability of\nsuch queries within their latent representations. We\nexamine this hypothesis by undertaking three dis-\ntinct experimental approaches: (1) prompt manipu-\nlation, (2) beam scrutiny, and (3) probing (includ-\ning identification and erasure of an answerability\nsubspace).\n3.1 Prompt Manipulation\nFirst, we ask whether the model’s ability to iden-\ntify (un)answerable questions is sensitive to the\nexact wording of the prompt. Specifically, we ask\nwhether merely raising the option of unasnwerabil-\nity makes the model less susceptible to hallucina-\ntion. To that end, we experiment with two types\nof prompts. The first type is designed to merely\nguide the model towards addressing a question.\nThe second type, however, is more instructive in its\napproach. Besides guiding the model, it provides\nan advised course of action for scenarios where\nthe question at hand is (un)answerable, hence indi-\nrectly hinting at the potential for (un)answerability.\nOur experimental setup encompasses both zero-\nshot and few-shot prompts, with the latter in-\nvolving the integration of two exemplars in the\nprompt. In the standard prompt setup, both exem-\nplars are answerable. However, within the hinting\nprompt framework, one exemplar is designed to be\n(un)answerable. Figure 2 demonstrates all variants.\n3.2 Beam Relaxation\nRecall that the output of LMs is usually decoded\nwith algorithms such as beam search. We aim to ex-\namine whether we can endow this algorithm with\na bias towards unanwerability. Focusing on the\nzero-shot setting, we gradually increase the beam\nsize. Then, instead of automatically choosing the\nhighest-probability answer from the final set of k\noptions, we search for a reply within the final k op-\ntions that signifies (un)answerability (Appendix A).\nIf such an answer is discovered, we substitute the\ntop-beam answer with \"unanswerable\".\n3.3 Identifying an Answerability Subspace\nIn a subsequent set of experiments, our objective\nis to find evidence for (un)answerability encod-\ning directly in the embedding space of the mod-\nels, by probing the models’ last hidden layer. For\neach task, each model is prompted with a bal-\nanced trainset comprising 400 answerable and 400\n(un)answerable examples. Then, for each instance,\nwe take the embedding from the final hidden layer\nof the first generated token and train a linear clas-\nsifier, using logistic regression, to predict answer-\nability.2 Subsequently, we assess the performance\nof each classifier on the corresponding test set. As\na baseline, we also conduct similar experiments\nusing the initial (non-contextual) embedding layer,\nwhich should not encode whether the question is\nanswerable or not. Our core objective within this\nexperimental setup is to ascertain whether a basic\nlinear classifier, trained on a modestly sized dataset,\nsuffices to effectively discriminate between answer-\nable and (un)answerable queries.\n3.4 Erasing the Answerability Subspace\nUpon identifying a linear subspace that corre-\nsponds to (un)answerability, a natural question to\nask is whether that subspace has a behavioral rele-\nvance, i.e., whether it is being used by the model\nwhen producing text. Importantly, this is differ-\nent than mere encoding of the information, as the\ninformation can be present in the representation\nand at the same time be irrelevant to the model’s\nbehavior (Hewitt and Liang, 2019; Elazar et al.,\n2021; Ravfogel et al., 2021). Recent work on lin-\near concept erasure (Ravfogel et al., 2020, 2022b;\nBelrose et al., 2023) have proposed a set of meth-\nods to erase arbitrary linearly-encoded concepts\nfrom neural representations, following the intuition\nthat by erasing a subspace that encodes the concept\nand examining the effect on the model’s output,\n2We also experimented with averaging across all the gen-\nerated tokens’ embeddings, which was found to yield inferior\nperformance on a designated development set.\n3609\nAnswerable(Un)answerable\nSQuAD 5928 5945\nNQ 3489 7719\nMuSiQue 1950 1316\nTable 1: Number of extracted answerable and\n(un)answerable questions per dataset in our test set.\nwe can verify that the subspace we identify is be-\nhaviorally meaningful, opening an avenue for per-\nforming interventions in that subspace in order to\nmodify the model’s behavior. These methods start\nwith the original representations alongside binary\nlabels (e.g., representations of the text alongside\nbinary gender annotations for each text), and re-\nturn a new representation which is linearly guarded\nin the sense that any linear classifier trying to re-\ncover the concept from the representation will fail.\nWhile linear erasure has its limitations (Ravfogel\net al., 2022a), it has been proven to be an effective\nmethod for intervening in the latent representations\nof black-box models.\nWe use the recently proposed method of Bel-\nrose et al. (2023) which provides a closed-form\nsolution for the concept-erasure objective. Con-\ncretely, given a binary concept (answerability), the\nmethod provides a projection matrix that minimally\nchanges the representations (in the L2 sense) while\nat the same time guarantees the inability to lin-\nearly predict the answerability from the modified\nrepresentations. We fit the method over the last-\nlayer representations of the training instances from\nFlan-UL2, particularly when these instances are\nprompted with regular queries from the SQuAD\nbenchmark (refer to §3.3). Then, during inference,\nthe concept-erasing projection matrix is applied in\nthe first generation step, specifically for the test set\nwithin the same model-dataset pairing. Our goal is\nto inspect whether removing the linear separation\nthat exists in the latent space of the model between\nanswerable and (un)answerable questions changes\nthe behavior of the model.\n4 Experimental Setup\nOur experiments focus on several language models\nand on three benchmarks.\nBenchmarks We consider three QA benchmarks,\nincorporating (un)answerable questions, in a read-\ning comprehension setting where models are tasked\nwith responding to a question within a given con-\ntext. For each benchmark, we use the entire de-\nvelopment set to construct our testing dataset. Ad-\nditionally, for the probing experiments involving\nthe training of linear classifiers on the models’ em-\nbeddings, sample 1000 instances from each bench-\nmark’s trainset, evenly distributed between answer-\nable and (un)answerable instances. Of these, we\nreserve 800 instances for the training of classifiers,\nwith the remaining instances forming the develop-\nment set for these classifiers. Below, we describe\nhow we associate asnwerable questions with para-\ngraphs that contain the answer, and how we as-\nsociate (un)answerable questions with challenging\nparagraphs (that do not contain the answer, but may\nbe topically similar to the question).\nOur first benchmark is SQuAD 2.0 (Rajpurkar\net al., 2018), a reading comprehension dataset, com-\nposed of manually-curated question-answer pairs\nalongside (un)answerable questions, each derived\nfrom a single paragraph.\nThe second benchmark we explore is NATURAL\nQUESTIONS (NQ; Kwiatkowski et al., 2019), a\ndataset accumulated from user-generated queries\non the Google search engine. Each item within the\ndataset consists of a question, a retrieved article, a\nselected paragraph from the article (referred to as\nthe “long answer”), and a short answer inferable\nfrom the paragraph. Despite its potential to test QA\nsystems with a retrieval component, our interest\nlies exclusively in the question-answering setting,\nhence we utilize the \"long answer\" as the context,\nassuming an oracle retrieval system. For the formu-\nlation of answerable instances, we select cases with\nboth a long and a short answer, using the former\nas the context and the latter as the response. For\nthe (un)answerable questions, we pair each query\nwith a paragraph from the sourced passage that has\nnot been annotated as the \"long answer\". In order\nto create a challenging dataset, we select the para-\ngraph that is closest in meaning to the question. To\nachieve this, we encode both the question and all\npotential paragraphs using a sentence-transformer\n(Sentence-Bert; Reimers and Gurevych, 2019) and\nselect the paragraph that exhibits the highest cosine-\nsimilarity score.\nOur final benchmark is the MuSiQue dataset\n(Trivedi et al., 2022), a multi-hop dataset featur-\ning both answerable and (un)answerable questions.\nEach instance consists of a question, several candi-\ndate paragraphs, an answer, and a decomposition\nof the question into its single-hop sub-questions.\nAdditionally, each sub-question is paired with a\nparagraph that has its answer, with all those align-\n3610\nSQuAD NQ MuSiQue\nFlan-T5xxl Regular 37.3 5.7 8.2\n(11B) +hint 91.5 85.6 74.7\nFlan-UL2 Regular 46.3 13.8 6.8\n(20B) +hint 92.3 83.9 67.3\nOPT-IML Regular 43.9 21.8 17.1\n(30B) +hint 85.4 85.3 54.1\n(a) Zero-shot\nSQuAD NQ MuSiQue\nFlan-T5xxl\n(11B)\nRegular 52.6\n(11.7)\n8.6\n(2.1)\n13.6\n(4.9)\n+ hint 91.2\n(1.0)\n85.8\n(0.5)\n75.4\n(1.4)\nFlan-UL2\n(20B)\nRegular 67.7\n(4.0)\n20.6\n(1.8)\n14.5\n(4.9)\n+ hint 92.5\n(0.1)\n83.7\n(0.1)\n72.1\n(0.6)\nOPT-IML\n(30B)\nRegular 10.0\n(1.2)\n11.1\n(2.1)\n4.9\n(1.0)\n+ hint 79.3\n(0.3)\n85.0\n(1.5)\n27.5\n(8.0)\n(b) Few-shot\nTable 2: F1 scores over the (un)answerability classifica-\ntion task in both zero-shot and few-shot setting. Each\nmodel is prompted with a regular prompt and with a\nprompt that hints at the possibility of (un)answerability\n(“+hint”). In the few-shot setting, results are averaged\nacross three variations of in-context-learning examples\n(with standard deviation in brackets). Bold marks the\nbetter prompting method.\ning paragraphs concatenated and used as context.\nConversely, for the (un)answerable queries, the ab-\nsence of such alignment for some sub-questions is\nobserved. For these (un)answerable instances, we\nidentify the paragraph most closely linked to each\nof the unanswered single-hop questions, using a\nprocess akin to the approach with the NQ bench-\nmark. These identified paragraphs are then aggre-\ngated, together with the paragraphs corresponding\nto the other single-hop questions, to form the con-\ntext for the (un)answerable queries. Table 1 details\nthe full statistics of our test sets across all three\nbenchmarks. These test sets are obtained from the\ndevelopment set of each respective benchmark.\nEvaluation The main task over which we eval-\nuate models is the (un)answerability classifica-\ntion task. When evaluating QA models over this\ntask we only examine whether they tried to an-\nswer, i.e., we count every example for which the\nmodel provides an answer as an instance of answer-\nability prediction, and each example for which the\nmodel did not provide an answer as an instance\nof un-answerability prediction, 3. Note that this\nevaluation does not consider the correctness of the\nanswers provided. The metric associated with this\ntask is the F1 score, with \"unanswerable\" consid-\nered the positive label. Linear classifiers (§3.3) are\nalso evaluated over the (un)answerability classifi-\ncation task, as the classifier is trained to predict\nwhether or not the question is answerable, based\non the hidden representations of the LM.\nAdditionally, in order to make sure that our meth-\nods do not hinder the performance of the models\nover their primary task, we evaluate them over the\nQA task as well, using the splits provided by the\ntasks’ designers. We report the commonly used\nmetrics: exact match (EM) and (token-wise) F1\nscores (Rajpurkar et al., 2016).\nLanguage Models We evaluate three instruction-\nfinetuned large language models: namely, the ’xxl’\nvariant of the Flan-T5 model (Flan-T5xxl; Chung\net al., 2022), the Flan-UL2 model (Chung et al.,\n2022), and the OPT-IML model (Iyer et al., 2023).\n5 Results\n5.1 Prompt Manipulation\n5.1.1 Zero-Shot Scenario\nTable 2a presents the results in the zero-shot set-\nting (the model was not provided with question-\nanswer examples). It shows that the detection of\n(un)answerable questions is substantially improved\nupon the integration of a hint towards the possibility\nof (un)answerability into the prompts, with gains\nas high as 80 points. It can also be observed that,\nwithout a hint, the ability to discern (un)answerable\nqueries tends to be superior in larger models. In-\nterestingly, the introduction of the hint appears to\nmitigate the impact of model size, as evidenced by\nthe smaller Flan-T5xxl surpassing its larger coun-\nterparts in two out of three benchmark evaluations.\nAdditionally, Table 3a displays the models’ ex-\nact match and token-wise F1 scores over the QA\ntask where the model is tasked with both detecting\n(un)answerable questions and provide a correct an-\nswer to the answerable ones. It reveals a notable\nenhancement in the quality of generated responses\nwhen prompted with a hint, in some cases resulting\nin improvements of over 50 points (on both met-\n3After analyzing the models’ responses, we curated a list\nof answers that signify abstaining from answering. See Ap-\npendix A for further details.\n3611\nSQuAD NQ MuSiQue\nEM F1 EM F1 EM F1\nFlan-T5xxl Regular 55.4 58.6 22.5 27.0 41.2 48.5\n(11B) +hint 86.5 89.6 73.3 77.0 63.5 70.5\nFlan-UL2 Regular 59.5 62.3 21.7 27.3 35.3 43.4\n(20B) +hint 87.8 90.5 70.5 74.5 55.3 62.2\nOPT-IML Regular 57.8 60.6 29.0 33.0 37.3 44.4\n(30B) +hint 81.2 83.5 73.9 76.7 47.7 54.5\n(a) Zero-shot\nSQuAD NQ MuSiQue\nEM F1 EM F1 EM F1\nFlan-T5xxl\n(11B) Regular61.8(6.1) 65.2(5.7) 23.8(1.4) 28.2(1.3) 41.3(2.9) 48.9(2.9)\n+ hint 86.0(1.6) 89.2(1.4) 73.6(0.4) 77.3(0.3) 62.9(2.7) 69.9(2.6)\nFlan-UL2(20B) Regular69.8(2.0) 73.0(2.2) 26.1(1.5) 31.2(1.4) 40.0(3.4) 47.5(3.0)\n+ hint 87.9(0.4) 90.7(0.3) 70.7(0.2) 74.9(0.2) 60.1(0.2) 67.4(0.2)\nOPT-IML(30B) Regular44.2(0.6) 47.5(0.6) 24.5(0.7) 28.4(0.7) 31.7(1.3) 39.2(1.4)\n+ hint 74.5(0.5) 76.6(0.8) 73.6(2.2) 75.9(1.9) 36.7(2.3) 44.3(2.3)\n(b) Few-shot\nTable 3: Exact match (EM) and (token) F1 scores over\nthe QA task in zero-shot and few-shot setting. For each\nmodel, there are two prompt variants: regular and with\na hint of the possibility of (un)answerability. In the\nfew-shot setting, results are averaged across three vari-\nations of in-context-learning examples (with standard\ndeviation in brackets). Bold marks the better prompting\nmethod.\nrics). The improvement over the QA task arises in\nlarge part from models giving the correct response\nto (un)answerable questions. We observe an aver-\nage drop of 8.3% in F1 and 7.1% in exact match\nover answerable questions in a zero-shot setting\nwhen providing the hint (see Appendix B for all\nthe results over answerable questions).\n5.1.2 Few-Shot Scenario\nTable 2b provides an exhaustive overview of the\nresults in the few-shot setting. In order to miti-\ngate the impact of the chosen examples, we ex-\nperiment with three variants of in-context exam-\nples for each benchmark, and report the average\nresults, as well as the standard deviation.4 Mirror-\ning the trend seen in the zero-shot scenario, when\nthe prompts encapsulate a hint towards the poten-\ntial of (un)answerability, there is a significant im-\nprovement in the identification of (un)answerable\nqueries. This trend is further corroborated by Ta-\nble 3b, which reports the exact match and token-\nwise F1 scores of the models over the QA task. See\n4See Appendix F for further details.\nSQuAD\nNQ\nMuSiQue\nFigure 3: F1 over the (un)answerability classification\ntask with beam relaxation. In this setting, the models\nwere considered successful iff a reply acknowledging\nthe (un)answerability of a question was found anywhere\nin the beam. The horizontal lines show the F1 for the\nusual metric, i.e., successful classification only if the\ncorrect reply was on the top of the beam.\nAppendix D for a comparison of the two possible\nhints: in the instructions, and as an (un)answerable\nexample.\n5.2 Beam Relaxation\nFigure 3 illustrates the models’ ability to detect\n(un)answerable queries, when gradually increas-\ning the beam size. Although the increase in beam\nsize yields a negligible impact on the final, most\nprobable response (as depicted by the horizontal\nlines in Figure 3), it shows better recognition of\n(un)answerability. This is illustrated by a consis-\ntent increase in the presence of (un)answerability-\nacknowledging responses5 within one of the beams\n5Please refer to Appendix A for a comprehensive overview\nof such responses.\n3612\n(a) SQuAD\n(b) NQ\n(c) MuSiQue\nFigure 4: 3D PCA projection of the last hidden layer’s\nembedding of the Flan-T5xxl model on each of the three\nbenchmarks. The left images show the embeddings with\nthe regular prompt, and the right ones - with the prompt\nwith a hint.\n(signified by the height of the bars). This observa-\ntion underscores the notion that beneath the facade\nof overconfidence expressed by these models, the\nmodels do encode their inability to respond to cer-\ntain queries. Importantly, we find that this approach\nhas very little negative impact on the answerable\nquestions, with only a slight degradation in the\nexact match and F1 scores (see Appendix E for\nfurther details).\nNotably, we conjecture that the observed de-\ncrease in performance on the NQ and MuSiQue\nbenchmarks, compared to SQuAD, can be at-\ntributed to two main factors: distribution shift and\na more challenging task environment. One con-\ntributing factor is the non-conventional format of\nqueries in NQ; unlike the typical question format\nfound in datasets like SQuAD, NQ queries do not\nalways adhere to this pattern. Language models\n(LLMs) primarily trained on question-answering\ndatasets, like SQuAD, might struggle with this dis-\ntribution shift, leading to a decline in their perfor-\nmance when faced with non-question-formatted\n(a) SQuAD\n(b) NQ\n(c) MuSiQue\nFigure 5: 3-D PCA projection of the last hidden layer’s\nembedding of the OPT-IML model on each of the three\nbenchmarks. The left images show the embeddings with\nthe regular prompt, and the right ones - with the prompt\nwith a hint.\nqueries.\nIn addition, the MuSiQue dataset introduces a\nsignificant challenge by requiring multi-hop reason-\ning. There are limited datasets available on which\nmodels can be trained for such complex tasks, and\neven fewer with (un)answerable questions. This\nscarcity, coupled with the demand for multi-hop\nreasoning, amplifies the difficulty of MuSiQue.\nThis high complexity is further highlighted by the\ndiminished performance of models, even when re-\nsponding to answerable questions, as evident in\nTables 6 and 9 in Appendices B and E, respectively.\nThis drop in performance shows how challenging\nthese benchmarks are, especially when compared\nto easier ones like SQuAD.\n5.3 Identifying an Answertability Subspace\nWe report the performance of the linear classifiers\nin Table 4. Notably, when considering the stan-\n3613\nSQuAD NQ MuSiQue\nModel 1st\nlayer lastlayer 1st\nlayer lastlayer 1st\nlayer lastlayer\nFlan-T5xxl regular 40.1 89.9 23.0 86.1 47.4 77.5\n(11B) +hint 40.0 89.4 26.6 86.2 38.6 77.3\nFlan-UL2 regular 39.4 90.4 42.2 87.3 15.1 78.3\n(20B) +hint 39.6 89.9 41.5 87.9 41.6 78.3\nOPT-IML regular 48.4 82.8 40.8 85.5 45.6 75.5\n(30B) +hint 48.4 83.9 45.3 86.2 45.6 84.9\nTable 4: F1 scores of (un)answerability classification of\nthe linear classifier trained for each model-dataset pair,\nonce with the regular prompt and once with the prompt\nthat hints at the possibility of (un)answerability. For\neach model, we classify once based on the first layer\nand once based on the last layer of the first generated\ntoken.\ndard prompt, the F1 of the probe is above 75%\nfor all models and datasets. Furthermore, we find\nthat hinting to the possibility of (un)answerability\nonly marginally improves the ability to correctly\nclassify queries from the representations within\nthe models. These suggest the existence of an\n’(un)answerability’ linear subspace.\nVisuazliation. To examine this hypothesis, we\nperform a PCA projection of the embedding of\nthe final hidden layer of the first generated token\nonto a 3-D plane. Figures 1, 4, 5 display the re-\nsults for the Flan-UL2, Flan-T5xxl and OPT-IML\nmodels, respectively. Consistent with our hypothe-\nsis, it can be observed that (un)answerable queries,\nwhich were correctly identified as such by the\nmodel (depicted by red dots in the figures), are\ndistinctly separate from the answerable queries\n(represented by blue dots in the figures). This\nseparation becomes especially pronounced in the\ncontext where the prompt incorporated a hint (as\nillustrated in the right subfigures). Importantly,\nwe find that (un)answerable questions, which the\nmodels failed to recognize as such and instead\ngenerated a hallucinated response (indicated by\npink dots in the figures), appear to reside within\na separate linear subspace. This finding demon-\nstrates that, notwithstanding the overconfidence\nexhibited by these models, they intrinsically pos-\nsess the capacity to distinguish (un)answerable\nqueries. This intrinsic capability is particularly\nevident given that the subspace corresponding\nto hallucinated (un)answerable questions (pink)\nseems to be positioned between that of the answer-\nable queries (blue) and that of correctly identified\n(un)answerable queries (red). This positioning is\nsuggestive of the models’ inherent uncertainty.\nFlan-T5xxl\nFlan-UL2\nOPT-IML\nFigure 6: F1 scores of (un)answerability classification,\nas determined by a linear classifier trained for each\nmodel-dataset pair, and tested on the other benchmarks.\nWithin each heatmap, the column designates the dataset\nused for training, while the row illustrates the dataset\non which the classifier was tested.\nTrasnfer Between Datasets. In Figure 6 we\npresent the transferability of the (un)answerability\nclassifier trained on a given dataset to other datasets.\nWhile performance deteriorates, the F1 scores are\nstill well above the F1 scores we calculated over\nthe uncontextualized first layer. This suggests that,\nto a large degree, the probes identify an abstract\n(un)answerability subspace beyond dataset-specific\nshallow features.\n3614\nAll Answerable\nk-beam Type EM F1 EM F1\nRegular w\\o erasure 60.2 63.8 87.1 94.1\nwith erasure 50.2 55.1 82.0 91.8\nRelaxed w\\o erasure 60.9 64.4 87.1 94.1\nwith erasure 50.8 55.7 82.0 91.8\nTable 5: Exact match (EM) and F1 scores of all ques-\ntions and of answerable questions in the zero-shot set-\nting for the Flan-UL2 model on the SQuAD benchmark\nwith a beam size of 3. The results demonstrate the per-\nformance before and after the application of the concept\nerasure, for the regular k-beam decoding approach, and\nthe relaxed variant.\n5.4 Erasing the Answerability Subspace\nRecall that if the subspaces we found are causally\nrelated to the predictions of the model, we expect\nthat erasing them would deteriorate the model’s per-\nformance in the answerability task. Indeed, when\nlinearly erasing the answerability subspace from\nthe first token representation of Flan-UL2, we see\nthe F1 score over the (un)answerability classifica-\ntion task decreasing from 50.1 to 31.2 with regular\nbeam, and from 65.4 to 32.7 with beam relaxation.\nThis trend is also evident from the results on the\nQA task presented in Table 5, as well as when pro-\njecting the embeddings on a 3-D plane using PCA,\nas depicted in Figure 7. This suggests that the\nanswerability subspace is influencing the model’s\nbehavior in the context of the answerability task.\n6 Conclusion\nWe found ample evidence for LM’s ability to en-\ncode the (un)answerability of questions, despite the\nfact that models tend to be over-confident and gen-\nerate hallucinatory answers when presented with\n(un)answerable questions. We also showed that this\ndiscrepancy between model output and its hidden\nstates is mitigated by simply adding the option of\n(un)answerability to the prompt.\nThe evidence we found includes the existence\nof a reply acknowledging the (un)answerability in\na beam of decoded answers, meaning that even\nthough the models’ best-assessed answer is halluci-\nnatory, the true answer is not lagging too far behind.\nWe also showed that the models’ representations\nafter encoding the question and before decoding\nthe answer are highly influenced by the answerabil-\nity of the question or lack thereof, with answerable\nand (un)answerable questions being linearly sep-\narable in the embedding space. We conclude that\nBefore Erasure\n After Erasure\nFigure 7: 3-D PCA projection of the last hidden layer’s\nembedding of the Flan-UL2 model on the SQuAD\ndataset, without performing erasure (left) and after\n(right).\nthe problem of answered (un)answerable questions\ncan be mended with either better prompting, better\ndecoding, or simple auxiliary classification models.\n7 Limitations\nWe focus on a few datasets and models. Despite\nthe effort to experiment with several models, future\nwork should experiment with different models, and\nin particular, examine the relation between the abil-\nity to encode (un)answerability and model scale.\nWe also do not compare the different approaches\nexplored in this paper, which we leave as an in-\nteresting future research direction. Our focus on\nlinear probing and linear erasure stems from the\navailability of existing methods from this family,\nbut deep LMs are highly nonlinear and may encode\nthe information we are interested in in a nonlinear\nmanner. As such, our results should only be inter-\npreted as a lower bound for the identification of\n(un)answerability. Lastly, our experiments focused\non (un)answerability in a given context. Future\nwork should also explore the phenomenon in the\nopen-domain setting.\n8 Ethics Statement\nModel hallucination, in general, can have real-\nworld implications when models are incorporated\nin, e.g., search engines or other applications. Our\nstudy focuses on the ability to discern a specific\ntype of hallucination in a selected set of models\nand datasets. It should not be taken as a general\nsolution to the problem of hallucination in the QA\nsetting, but rather as preliminary research on po-\ntential techniques for mitigating the problem of\nhallucination.\n3615\nReferences\nAbubakar Abid, Maheen Farooqi, and James Zou. 2021.\nPersistent anti-muslim bias in large language models.\nIn Proceedings of the 2021 AAAI/ACM Conference\non AI, Ethics, and Society, pages 298–306.\nYossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi,\nand Yoav Goldberg. 2017. Fine-grained analysis of\nsentence embeddings using auxiliary prediction tasks.\nIn International Conference on Learning Representa-\ntions (ICLR).\nAlfonso Amayuelas, Liangming Pan, Wenhu Chen, and\nWilliam Wang. 2023. Knowledge of knowledge: Ex-\nploring known-unknowns uncertainty with large lan-\nguage models.\nGalen Andrew and Jianfeng Gao. 2007. Scalable train-\ning of L1-regularized log-linear models. In Proceed-\nings of the 24th International Conference on Machine\nLearning, pages 33–40.\nAkari Asai and Eunsol Choi. 2021. Challenges in\ninformation-seeking QA: Unanswerable questions\nand paragraph retrieval. In Proceedings of the 59th\nAnnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 1492–1504, Online. Association\nfor Computational Linguistics.\nNora Belrose, David Schneider-Joseph, Shauli Ravfogel,\nRyan Cotterell, Edward Raff, and Stella Biderman.\n2023. Leace: Perfect linear concept erasure in closed\nform. arXiv preprint arXiv:2306.03819.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners.\nNicholas Carlini, Daphne Ippolito, Matthew Jagielski,\nKatherine Lee, Florian Tramer, and Chiyuan Zhang.\n2023. Quantifying memorization across neural lan-\nguage models. In The Eleventh International Confer-\nence on Learning Representations.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-\nplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, Alex Ray, Raul Puri, Gretchen\nKrueger, Michael Petrov, Heidy Khlaaf, Girish Sas-\ntry, Pamela Mishkin, Brooke Chan, Scott Gray,\nNick Ryder, Mikhail Pavlov, Alethea Power, Lukasz\nKaiser, Mohammad Bavarian, Clemens Winter,\nPhilippe Tillet, Felipe Petroski Such, Dave Cum-\nmings, Matthias Plappert, Fotios Chantzis, Eliza-\nbeth Barnes, Ariel Herbert-V oss, William Hebgen\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie\nTang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\nWilliam Saunders, Christopher Hesse, Andrew N.\nCarr, Jan Leike, Josh Achiam, Vedant Misra, Evan\nMorikawa, Alec Radford, Matthew Knight, Miles\nBrundage, Mira Murati, Katie Mayer, Peter Welinder,\nBob McGrew, Dario Amodei, Sam McCandlish, Ilya\nSutskever, and Wojciech Zaremba. 2021. Evaluating\nlarge language models trained on code.\nHyung Won Chung, Le Hou, Shayne Longpre, Barret\nZoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, Al-\nbert Webson, Shixiang Shane Gu, Zhuyun Dai,\nMirac Suzgun, Xinyun Chen, Aakanksha Chowdh-\nery, Alex Castro-Ros, Marie Pellat, Kevin Robinson,\nDasha Valter, Sharan Narang, Gaurav Mishra, Adams\nYu, Vincent Zhao, Yanping Huang, Andrew Dai,\nHongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Ja-\ncob Devlin, Adam Roberts, Denny Zhou, Quoc V . Le,\nand Jason Wei. 2022. Scaling instruction-finetuned\nlanguage models.\nAlexis Conneau, German Kruszewski, Guillaume Lam-\nple, Loïc Barrault, and Marco Baroni. 2018. What\nyou can cram into a single $&!#* vector: Probing\nsentence embeddings for linguistic properties. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 2126–2136, Melbourne, Aus-\ntralia. Association for Computational Linguistics.\nShrey Desai and Greg Durrett. 2020. Calibration of\npre-trained transformers. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 295–302, Online.\nAssociation for Computational Linguistics.\nAmeet Deshpande, Vishvak Murahari, Tanmay Rajpuro-\nhit, Ashwin Kalyan, and Karthik Narasimhan. 2023.\nToxicity in chatgpt: Analyzing persona-assigned lan-\nguage models.\nShehzaad Dhuliawala, Leonard Adolphs, Rajarshi Das,\nand Mrinmaya Sachan. 2022. Calibration of machine\nreading systems at scale. In Findings of the Asso-\nciation for Computational Linguistics: ACL 2022,\npages 1682–1693, Dublin, Ireland. Association for\nComputational Linguistics.\nAlexander Yom Din, Taelin Karidi, Leshem Choshen,\nand Mor Geva. 2023. Jump to conclusions: Short-\ncutting transformers with linear transformations.\narXiv preprint arXiv:2303.09435.\nYanai Elazar, Shauli Ravfogel, Alon Jacovi, and Yoav\nGoldberg. 2021. Amnesic probing: Behavioral expla-\nnation with amnesic counterfactuals. Transactions of\nthe Association for Computational Linguistics, 9:160–\n175.\nJames Ferguson, Matt Gardner, Hannaneh Hajishirzi,\nTushar Khot, and Pradeep Dasigi. 2020. IIRC: A\ndataset of incomplete information reading compre-\nhension questions. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\n3616\nProcessing (EMNLP), pages 1137–1147, Online. As-\nsociation for Computational Linguistics.\nMor Geva, Jasmijn Bastings, Katja Filippova, and Amir\nGloberson. 2023. Dissecting recall of factual asso-\nciations in auto-regressive language models. arXiv\npreprint arXiv:2304.14767.\nMor Geva, Avi Caciularu, Guy Dar, Paul Roit, Shoval\nSadde, Micah Shlain, Bar Tamir, and Yoav Goldberg.\n2022a. LM-debugger: An interactive tool for inspec-\ntion and intervention in transformer-based language\nmodels. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing:\nSystem Demonstrations, pages 12–21, Abu Dhabi,\nUAE. Association for Computational Linguistics.\nMor Geva, Avi Caciularu, Kevin Wang, and Yoav Gold-\nberg. 2022b. Transformer feed-forward layers build\npredictions by promoting concepts in the vocabulary\nspace. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Process-\ning, pages 30–45, Abu Dhabi, United Arab Emirates.\nAssociation for Computational Linguistics.\nJohn Hewitt and Percy Liang. 2019. Designing and in-\nterpreting probes with control tasks. In Proceedings\nof the 2019 Conference on Empirical Methods in Nat-\nural Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 2733–2743.\nSrinivasan Iyer, Xi Victoria Lin, Ramakanth Pasunuru,\nTodor Mihaylov, Daniel Simig, Ping Yu, Kurt Shuster,\nTianlu Wang, Qing Liu, Punit Singh Koura, Xian Li,\nBrian O’Horo, Gabriel Pereyra, Jeff Wang, Christo-\npher Dewan, Asli Celikyilmaz, Luke Zettlemoyer,\nand Ves Stoyanov. 2023. Opt-iml: Scaling language\nmodel instruction meta learning through the lens of\ngeneralization.\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan\nSu, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea\nMadotto, and Pascale Fung. 2023. Survey of halluci-\nnation in natural language generation. ACM Comput-\ning Surveys, 55(12):1–38.\nZhengbao Jiang, Jun Araki, Haibo Ding, and Graham\nNeubig. 2021. How can we know when language\nmodels know? on the calibration of language models\nfor question answering. Transactions of the Associa-\ntion for Computational Linguistics, 9:962–977.\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom\nHenighan, Dawn Drain, Ethan Perez, Nicholas\nSchiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli\nTran-Johnson, Scott Johnston, Sheer El-Showk,\nAndy Jones, Nelson Elhage, Tristan Hume, Anna\nChen, Yuntao Bai, Sam Bowman, Stanislav Fort,\nDeep Ganguli, Danny Hernandez, Josh Jacobson,\nJackson Kernion, Shauna Kravec, Liane Lovitt, Ka-\nmal Ndousse, Catherine Olsson, Sam Ringer, Dario\nAmodei, Tom Brown, Jack Clark, Nicholas Joseph,\nBen Mann, Sam McCandlish, Chris Olah, and Jared\nKaplan. 2022. Language models (mostly) know what\nthey know.\nNikhil Kandpal, Haikang Deng, Adam Roberts, Eric\nWallace, and Colin Raffel. 2022. Large language\nmodels struggle to learn long-tail knowledge. arXiv\npreprint arXiv:2211.08411.\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\nfield, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\nton Lee, Kristina Toutanova, Llion Jones, Matthew\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natural\nQuestions: A Benchmark for Question Answering\nResearch. Transactions of the Association for Com-\nputational Linguistics, 7:453–466.\nRémi Leblond, Jean-Baptiste Alayrac, Laurent Sifre,\nMiruna Pislar, Lespiau Jean-Baptiste, Ioannis\nAntonoglou, Karen Simonyan, and Oriol Vinyals.\n2021. Machine translation decoding beyond beam\nsearch. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 8410–8434, Online and Punta Cana, Domini-\ncan Republic. Association for Computational Lin-\nguistics.\nBelinda Li, Jane Yu, Madian Khabsa, Luke Zettlemoyer,\nAlon Halevy, and Jacob Andreas. 2022. Quantify-\ning adaptability in pre-trained language models with\n500 tasks. In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, pages 4696–4715, Seattle, United States.\nAssociation for Computational Linguistics.\nJinzhi Liao, Xiang Zhao, Jianming Zheng, Xinyi Li, Fei\nCai, and Jiuyang Tang. 2022. Ptau: Prompt tuning for\nattributing unanswerable questions. In Proceedings\nof the 45th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval,\nSIGIR ’22, page 1219–1229, New York, NY , USA.\nAssociation for Computing Machinery.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi\nDas, Hannaneh Hajishirzi, and Daniel Khashabi.\n2022. When not to trust language models: Inves-\ntigating effectiveness and limitations of paramet-\nric and non-parametric memories. arXiv preprint\narXiv:2212.10511.\nPotsawee Manakul, Adian Liusie, and Mark J. F. Gales.\n2023. Selfcheckgpt: Zero-resource black-box hal-\nlucination detection for generative large language\nmodels.\nClara Meister, Ryan Cotterell, and Tim Vieira. 2020. If\nbeam search is the answer, what was the question?\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 2173–2185, Online. Association for Computa-\ntional Linguistics.\nKevin Meng, Arnab Sen Sharma, Alex J Andonian,\nYonatan Belinkov, and David Bau. 2023. Mass-\nediting memory in a transformer. In The Inter-\nnational Conference on Learning Representations\n(ICLR).\n3617\nTimothee Mickus, Denis Paperno, and Mathieu Con-\nstant. 2022. How to dissect a Muppet: The struc-\nture of transformer embedding spaces. Transactions\nof the Association for Computational Linguistics,\n10:981–996.\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, Yejin\nChoi, and Hannaneh Hajishirzi. 2022a. Reframing\ninstructional prompts to GPTk’s language. In Find-\nings of the Association for Computational Linguistics:\nACL 2022, pages 589–612, Dublin, Ireland. Associa-\ntion for Computational Linguistics.\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, and\nHannaneh Hajishirzi. 2022b. Cross-task generaliza-\ntion via natural language crowdsourcing instructions.\nIn Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 3470–3487, Dublin, Ireland.\nAssociation for Computational Linguistics.\nMoin Nadeem, Anna Bethke, and Siva Reddy. 2021.\nStereoSet: Measuring stereotypical bias in pretrained\nlanguage models. In Proceedings of the 59th Annual\nMeeting of the Association for Computational Lin-\nguistics and the 11th International Joint Conference\non Natural Language Processing (Volume 1: Long\nPapers), pages 5356–5371, Online. Association for\nComputational Linguistics.\nPranav Rajpurkar, Robin Jia, and Percy Liang. 2018.\nKnow what you don’t know: Unanswerable ques-\ntions for SQuAD. In Proceedings of the 56th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 2: Short Papers), pages 784–789,\nMelbourne, Australia. Association for Computational\nLinguistics.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. SQuAD: 100,000+ questions for\nmachine comprehension of text. In Proceedings of\nthe 2016 Conference on Empirical Methods in Natu-\nral Language Processing, pages 2383–2392, Austin,\nTexas. Association for Computational Linguistics.\nShauli Ravfogel, Yanai Elazar, Hila Gonen, Michael\nTwiton, and Yoav Goldberg. 2020. Null it out: Guard-\ning protected attributes by iterative nullspace projec-\ntion. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n7237–7256.\nShauli Ravfogel, Yoav Goldberg, and Ryan Cotterell.\n2022a. Linear guardedness and its implications.\narXiv preprint arXiv:2210.10012.\nShauli Ravfogel, Grusha Prasad, Tal Linzen, and Yoav\nGoldberg. 2021. Counterfactual interventions re-\nveal the causal effect of relative clause representa-\ntions on agreement prediction. In Proceedings of\nthe 25th Conference on Computational Natural Lan-\nguage Learning, pages 194–209.\nShauli Ravfogel, Michael Twiton, Yoav Goldberg, and\nRyan D Cotterell. 2022b. Linear adversarial concept\nerasure. In International Conference on Machine\nLearning, pages 18400–18421. PMLR.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing. Associa-\ntion for Computational Linguistics.\nTal Schuster, Adam Fisch, Jai Gupta, Mostafa Dehghani,\nDara Bahri, Vinh Q. Tran, Yi Tay, and Donald Met-\nzler. 2022. Confident adaptive language modeling.\nIn Advances in Neural Information Processing Sys-\ntems (NeurIPS).\nRoy Schwartz, Gabriel Stanovsky, Swabha\nSwayamdipta, Jesse Dodge, and Noah A. Smith.\n2020. The right tool for the job: Matching model and\ninstance complexities. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 6640–6651, Online. Association\nfor Computational Linguistics.\nAviv Slobodkin, Avi Caciularu, Eran Hirsch, and Ido\nDagan. 2023. Dont add, dont miss: Effective content\npreserving generation from pre-selected text spans.\nAviv Slobodkin, Leshem Choshen, and Omri Abend.\n2021. Mediators in determining what processing\nBERT performs first. In Proceedings of the 2021\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 86–93, Online. Asso-\nciation for Computational Linguistics.\nElior Sulem, Jamaal Hay, and Dan Roth. 2021. Do we\nknow what we don’t know? studying unanswerable\nquestions beyond SQuAD 2.0. In Findings of the\nAssociation for Computational Linguistics: EMNLP\n2021, pages 4543–4548, Punta Cana, Dominican Re-\npublic. Association for Computational Linguistics.\nHarsh Trivedi, Niranjan Balasubramanian, Tushar Khot,\nand Ashish Sabharwal. 2022. MuSiQue: Multi-\nhop questions via single-hop question composition.\nTransactions of the Association for Computational\nLinguistics.\nElena V oita, Rico Sennrich, and Ivan Titov. 2019. The\nbottom-up evolution of representations in the trans-\nformer: A study with machine translation and lan-\nguage modeling objectives. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 4396–4406, Hong Kong,\nChina. Association for Computational Linguistics.\nAlexander Wan, Eric Wallace, Sheng Shen, and Dan\nKlein. 2023a. Poisoning language models during\ninstruction tuning. arXiv preprint arXiv:2305.00944.\nDavid Wan, Mengwen Liu, Kathleen McKeown,\nMarkus Dreyer, and Mohit Bansal. 2023b.\nFaithfulness-aware decoding strategies for abstractive\nsummarization. arXiv preprint arXiv:2303.03278.\n3618\nJohannes Welbl, Amelia Glaese, Jonathan Uesato,\nSumanth Dathathri, John Mellor, Lisa Anne Hen-\ndricks, Kirsty Anderson, Pushmeet Kohli, Ben Cop-\npin, and Po-Sen Huang. 2021. Challenges in detox-\nifying language models. In Findings of the Associ-\nation for Computational Linguistics: EMNLP 2021,\npages 2447–2469, Punta Cana, Dominican Republic.\nAssociation for Computational Linguistics.\nOrion Weller, Marc Marone, Nathaniel Weir, Dawn\nLawrie, Daniel Khashabi, and Benjamin Van Durme.\n2023. \" according to...\" prompting language mod-\nels improves quoting from pre-training data. arXiv\npreprint arXiv:2305.13252.\nGian Wiher, Clara Meister, and Ryan Cotterell. 2022.\nOn decoding strategies for neural text generators.\nTransactions of the Association for Computational\nLinguistics, 10:997–1012.\nZhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu,\nXipeng Qiu, and Xuanjing Huang. 2023. Do large\nlanguage models know what they don’t know?\nHaichao Zhu, Li Dong, Furu Wei, Wenhui Wang, Bing\nQin, and Ting Liu. 2019. Learning to ask unanswer-\nable questions for machine reading comprehension.\nIn Proceedings of the 57th Annual Meeting of the As-\nsociation for Computational Linguistics, pages 4238–\n4248, Florence, Italy. Association for Computational\nLinguistics.\n3619\nA (Un)answerability-Recognizing\nResponses\nAfter analyzing the responses generated by the dif-\nferent models in this work, we curated a list of\nanswers that signify abstention from answering,\nwhich we used to identify responses that signify\n(un)answerability. This includes: “Unanswerable”,\n“N/A”, “I don’t know”, “IDK”, “Not known”, “An-\nswer not in context”, “Unknown”, “No answer”,\n“It is unknown”, “None of the above”, “None of the\nabove choices”, “The answer is unknown”, along\nwith their corresponding versions in lowercase.\nB Performance on the Answerable\nInstances\nTable 6 show the exact match and F1 scores of\neach model over the QA task only on the answer-\nable questions of each benchmark, in the zero-shot\nsetting and the few-shot setting. Note that although\nthe addition of the hint hinders the models’ per-\nformance, the drop over the answerable questions\nis small for the most part and outbalanced by the\nimprovement of detection of (un)answerable ques-\ntions, leading to the overall improvement shown in\nTable 3.\nC Prompt Variant Tuning\nIn our work, we experiment with three variants of\nthe prompt containing a hint of the possibility of\n(un)answerability. These are:\n1. Given the following passage and question, an-\nswer the question. If it cannot be answered\nbased on the passage, reply \"unanswerable\".\n2. Given the following passage and question, an-\nswer the question. If you don’t know the an-\nswer, reply \"IDK\".\n3. Given the following passage and question, an-\nswer the question. If there is no correct an-\nswer, reply \"N/A\".\nWe run all three variants on a separate develop-\nment set6, to decide which prompt to use for each\nmodel and dataset. Table 7 shows the results of all\nthree variants on our development set. Based on\nthese results, we decide to use the first variant in\nour experiments on the SQuAD and NQ datasets\n6The development set consists of 200 answerable and 200\n(un)answerable instances, extracted from the train set of each\nrespective benchmark.\nSQuAD NQ MuSiQue\nEM F1 EM F1 EM F1\nFlan-T5xxl Regular88.0 94.3 65.5 80.0 66.1 78.4\n(11B) +hint 86.2 92.3 56.3 68.2 61.2 72.9\nFlan-UL2 Regular89.0 94.7 53.1 71.2 56.7 70.1\n(20B) +hint 87.8 93.2 54.3 67.0 52.1 63.6\nOPT-IML Regular87.6 93.2 66.1 78.9 56.1 67.9\n(30B) +hint 80.2 84.9 53.9 63.0 52.0 63.3\n(a) Zero-shot\nSQuAD NQ MuSiQue\nEM F1 EM F1 EM F1\nFlan-T5xxl\n(11B) Regular87.4(1.9) 94.2(1.1) 66.3(1.9) 80.3(1.6) 64.2(3.1) 76.9(3.0)\n+ hint 84.6(2.8) 91.1(2.4) 55.5(5.1) 67.3(5.5) 57.4(5.4) 69.1(5.3)\nFlan-UL2(20B) Regular88.3(0.7) 94.6(0.3) 58.3(2.5) 74.7(2.1) 61.7(3.8) 74.2(3.2)\n+ hint 87.1(1.0) 92.7(0.6) 59.0(0.1) 72.4(0.2) 56.4(0.8) 68.6(0.7)\nOPT-IML(30B) Regular83.0(0.5) 89.6(0.4) 65.2(0.7) 77.8(0.8) 51.4(1.8) 63.9(2.0)\n+ hint 69.6(5.0) 73.8(5.7) 48.8(3.2) 56.3(4.3) 50.3(1.3) 63.0(1.2)\n(b) Few-shot\nTable 6: Exact match (EM) and F1 scores over the\nQA task only for answerable questions in zero-shot and\nzero-shot setting. For each model, there are two prompt\nvariants: regular and with a hint of the (un)answerability.\nIn the few-shot setting, results are averaged across three\nvariations of in-context-learning examples (with stan-\ndard deviation in brackets). Bold marks the better\nprompting method.\nSQuAD NQ MuSiQueModel Prompt Variant Exact F1 Exact F1 Exact F1\nFlan-T5-xxl 1 85.0 89.4 63.0 71.5 59.0 66.1(11B) 2 60.5 67.2 52.5 61.2 37.5 44.93 78.0 84.2 61.5 69.6 67.0 73.1\nFlan-UL2 1 84.0 90.0 60.5 69.0 56.0 63.5(20B) 2 74.5 80.5 55.0 63.6 48.5 56.23 80.5 86.8 59.5 67.4 63.0 69.5\nOPT-IML 1 82.0 86.6 69.0 74.2 46.5 52.9(30B) 2 59.0 65.2 52.5 58.3 39.5 46.33 65.5 71.6 57.5 63.5 60.0 63.9\nTable 7: Exact match and (token) F1 scores in the zero-\nshot setting for three variants of the prompt containing\na hint of the possibility of (un)answerability, on our\ndevelopment set.\n(on all models), and the third variant in our experi-\nments on the MuSiQue dataset (on all models).\nD Impact of Hint Placement\nTo gain a deeper understanding of the circum-\nstances under which the addition of a hint in the\nfew-shot scenario is most beneficial, we conduct\ntwo ablations on the prompts. In one we gave a hint\nonly in the instructions with all examples answer-\nable, while in the other we gave special instructions\nbut one of the two examples was (un)answerable.\n3620\nSQuAD NQ MuSiQue\nFlan-T5xxl\n(11B)\nRegular 52.6\n(11.7)\n8.6\n(2.1)\n13.6\n(4.9)\n+hint (E&I) 91.2\n(1.0)\n85.8\n(0.5)\n75.4\n(1.4)\n+hint (I) 91.1\n(1.0)\n85.0\n(0.2)\n74.2\n(1.3)\n+hint (E) 88.7\n(2.1)\n81.9\n(0.8)\n51.3\n(7.2)\nFlan-UL2\n(20B)\nRegular 67.7\n(4.0)\n20.6\n(1.8)\n14.5\n(4.9)\n+hint (E&I) 92.5\n(0.1)\n83.7\n(0.1)\n72.1\n(0.6)\n+hint (I) 92.3\n(0.1)\n82.3\n(0.1)\n71.3\n(1.0)\n+hint (E) 92.0\n(0.1)\n79.7\n(0.6)\n59.0\n(1.7)\nOPT-IML\n(30B)\nRegular 10.0\n(1.2)\n11.1\n(2.1)\n4.9\n(1.0)\n+hint (E&I) 79.3\n(0.3)\n85.0\n(1.5)\n27.5\n(8.0)\n+hint (I) 75.0\n(1.8)\n81.9\n(1.1)\n14.1\n(4.2)\n+hint (E) 58.1\n(1.4)\n61.0\n(6.9)\n8.4\n(3.7)\nTable 8: F1 scores over the (un)answerability classifica-\ntion task in few-shot setting. Each model is prompted\nwith a regular prompt, and with three types of hint-\nincluding prompts: only in the instructions (“+hint (I)”),\nonly in the exemplars (“+hint (E)”) and in both (“+hint\n(E&I)”). Results are averaged across three variations of\nin-context-learning examples (with standard deviation\nin brackets). Bold marks the better prompting method.\nAs per the data presented in Table 8, it is evident\nthat the inclusion of a hint within the instructions\nis considerably more advantageous compared to\nits addition within the exemplars. Indeed, once a\nhint is incorporated within the instructions, further\ninclusion within the exemplars has a minimal im-\npact on the results, with OPT-IML being the sole\nexception.\nE Impact of the Relaxed Beam Search\nDecoding on the Answerable Queries\nTable 9 associated exclusively with each model on\nanswerable questions, evaluated under the frame-\nwork of our beam inspection experiments (see Sec-\ntion §3.2). Two decoding approaches were em-\nployed: a conventional beam-search decoding and\nits relaxed variant where the top answers are sup-\nplanted by an (un)answerability-recognizing re-\nsponse if it emerges within the beam. Our findings\nsuggest a marginal impact of the adapted beam-\nsearch on answerable queries, with a maximal re-\nduction of 7.7 and 8.7 points observed in the exact\nmatch and F1 scores respectively, when compared\nto its regular counterpart. Like in Appendix B,\nthese results point to the fact that any improvement\nachieved in §5.2 indeed stems from better treatment\nof (un)answerable questions.\nF In-Context-Learning Variants\nIn order to mitigate the effect of the chosen in-\ncontext examples in the few-shot setting, we ex-\nperiment with 3 variants of in-context examples,\nand average their scores. Figure 8, Figure 9, and\nFigure 10 show the different in-context examples\nvariants for the SQuAD, NQ, and MuSiQue tasks,\nrespectively.\n3621\nSQuAD NQ MuSiQue\nModel Beam size Regular Relaxed Regular Relaxed Regular Relaxed\nFlan-T5xxl 1 88.0 88.0 65.5 65.5 66.1 66.1\n(11B) 3 81.0 80.7 60.5 59.3 59.8 58.9\n5 81.1 80.4 59.6 57.1 60.3 58.2\n7 81.8 80.5 60.4 56.3 61.2 58.6\nFlan-UL2 1 89.0 89.0 53.1 53.1 56.7 56.7\n(20B) 3 79.4 77.4 48.4 47.8 53.4 49.1\n5 79.2 76.6 48.0 46.0 55.8 50.7\n7 79.7 75.9 48.1 44.4 57.3 51.4\nOPT-IML 1 87.6 87.6 66.1 66.1 56.1 56.1\n(30B) 3 82.4 79.4 64.7 63.0 50.6 48.0\n5 83.0 76.8 64.6 60.2 51.3 46.5\n7 83.6 78.6 64.4 56.8 52.4 44.6\n(a) Exact Match\nSQuAD NQ MuSiQue\nModel Beam size Regular Relaxed Regular Relaxed Regular Relaxed\nFlan-T5xxl 1 94.3 94.3 80.0 80.0 78.4 78.4\n(11B) 3 91.4 91.1 77.6 76.3 74.3 73.3\n5 91.6 90.8 76.9 74.1 74.9 72.6\n7 91.7 90.3 77.3 72.7 75.0 71.9\nFlan-UL2 1 94.7 94.7 71.2 71.2 70.1 70.1\n(20B) 3 90.4 88.3 67.2 66.6 70.7 65.8\n5 90.3 87.5 67.1 64.7 72.2 65.4\n7 90.6 86.4 66.8 62.2 72.9 65.5\nOPT-IML 1 93.2 93.2 78.9 78.9 67.9 67.9\n(30B) 3 90.3 87.3 77.3 75.5 63.0 60.2\n5 90.6 84.2 76.9 72.0 63.3 57.8\n7 91.0 85.7 76.7 68.1 64.2 55.5\n(b) F1\nTable 9: Exact match (top table) and F1 (bottom table) scores of answerable questions in the zero-shot setting\nfor different beam sizes. The results demonstrate the performance of two decoding approaches: the conventional\nbeam-search method (\"regular\"), and a modified relaxed beam-search variant (\"w\\textbackslash relax.\"). In the latter\ntechnique, the highest-ranking response is substituted by an (un)answerability-recognizing response, in cases where\nsuch a response is present within the breadth of the beam.\n3622\nAnswerable Example1:\nPassage: Madonna released the Material Girl clothing line, which she designed with her daughter, Lourdes. The 1980s inspired clothing line,\nborrowed from Madonna\\’s punk-girl style when she rose to fame in the 1980s, was released under the Macy\\’s label. Madonna also opened a\nseries of fitness centers around the world named Hard Candy Fitness. In November 2011, Madonna and MG Icon announced the release of a\nsecond fashion brand called Truth or Dare by Madonna to include footwear, underclothing, and accessories. She also directed her second\nfeature film, W.E., a biographic about the affair between King Edward VIII and Wallis Simpson; it was co-written with Alek Keshishian.\nCritical and commercial response to the film was negative. Madonna contributed the ballad \"Masterpiece\" for the film\\’s soundtrack, which\nwon her a Golden Globe Award for Best Original Song.\nQuestion: Material Girl clothing line is released under which brand?\nAnswer: Macy’s.\nAnswerable Example2:\nPassage: In 1919 Father James Burns became president of Notre Dame, and in three years he produced an academic revolution that brought the school\nup to national standards by adopting the elective system and moving away from the university\\’s traditional scholastic and classical\nemphasis. By contrast, the Jesuit colleges, bastions of academic conservatism, were reluctant to move to a system of electives. Their\ngraduates were shut out of Harvard Law School for that reason. Notre Dame continued to grow over the years, adding more colleges, programs,\nand sports teams. By 1921, with the addition of the College of Commerce, Notre Dame had grown from a small college to a university with\nfive colleges and a professional law school. The university continued to expand and add new residence halls and buildings with each\nsubsequent president.\nQuestion: Over how many years did the change to national standards undertaken at Notre Dame in the early 20th century take place?\nAnswer: three years.\nUn-answerable Example:\nPassage: The descendants of Rollo\\’s Vikings and their Frankish wives would replace the Norse religion and Old Norse language with Catholicism\n(Christianity) and the Gallo-Romance language of the local people, blending their maternal Frankish heritage with Old Norse traditions and\ncustoms to synthesize a unique \"Norman\" culture in the north of France. The Norman language was forged by the adoption of the indigenous\nlangue d’oil branch of Romance by a Norse-speaking ruling class, and it developed into the regional language that survives today.\nQuestion: What was replaced with the Norse religion?\nAnswer: unanswerable.\nVariant1\nAnswerable Example1:\nPassage: In November 2013 MGM and the McClory estate formally settled the issue with Danjaq, LLC-sister company of Eon Productions-with MGM\nacquiring the full copyright film rights to the concept of Spectre and all of the characters associated with it. With the acquisition of\nthe film rights and the organisation’s re-introduction to the series’ continuity, the SPECTRE acronym was discarded and the organisation\nreimagined as \"Spectre\".\nQuestion: Which two parties settled the issue in November 2003?\nAnswer: MGM and the McClory estate.\nAnswerable Example2:\nPassage: Genome composition is used to describe the make up of contents of a haploid genome, which should include genome size, proportions of\nnon-repetitive DNA and repetitive DNA in details. By comparing the genome compositions between genomes, scientists can better understand\nthe evolutionary history of a given genome.\nQuestion: What aspect of a genome can genome compositions help researchers in learning about?\nAnswer: evolutionary history.\nUn-answerable Example:\nPassage: The story focuses on series protagonist Link, who tries to prevent Hyrule from being engulfed by a corrupted parallel dimension known as\nthe Twilight Realm. To do so, he takes the form of both a Hylian and a wolf, and is assisted by a mysterious creature named Midna. The game\ntakes place hundreds of years after Ocarina of Time and Majora’s Mask, in an alternate timeline from The Wind Waker.\nQuestion: What land does Ocarina serve to protect?\nAnswer: unanswerable.\nVariant2\nAnswerable Example1:\nPassage: Thomas Newman returned as Spectre’s composer. Rather than composing the score once the film had moved into post-production, Newman\nworked during filming. The theatrical trailer released in July 2015 contained a rendition of John Barry’s On Her Majesty’s Secret Service\ntheme. Mendes revealed that the final film would have more than one hundred minutes of music. The soundtrack album was released on 23\nOctober 2015 in the UK and 6 November 2015 in the USA on the Decca Records label.\nQuestion: Who wrote the music for Spectre?\nAnswer: Thomas Newman.\nAnswerable Example2:\nPassage: Between 64 and 104 major aftershocks, ranging in magnitude from 4.0 to 6.1, were recorded within 72 hours of the main quake. According\nto Chinese official counts, \"by 12:00 CST, November 6, 2008 there had been 42,719 total aftershocks, of which 246 ranged from 4.0 MS to 4.9\nMS, 34 from 5.0 MS to 5.9 MS, and 8 from 6.0 Ms to 6.4 MS; the strongest aftershock measured 6.4 MS.\" The latest aftershock exceeding M6\noccurred on August 5, 2008.\nQuestion: What do the Chinese say is the total number of shocks after the quake?\nAnswer: 42,719.\nUn-answerable Example:\nPassage: Both the number of base pairs and the number of genes vary widely from one species to another, and there is only a rough correlation\nbetween the two (an observation known as the C-value paradox). At present, the highest known number of genes is around 60,000, for the\nprotozoan causing trichomoniasis (see List of sequenced eukaryotic genomes), almost three times as many as in the human genome.\nQuestion: What is the highest known number of species?\nAnswer: unanswerable.\nVariant3\nFigure 8: The three variants of in-context examples for the SQuAD prompts. For the regular prompts, we use the\ntwo answerable examples, whereas for the prompts hinting at the possibility of (un)answerability, we use the first\nanswerable example and the (un)answerable examples. Additionally, for the other prompt variants, we replace the\n\"unanswerable\" answer of the (un)answerable example with \"IDK\" and \"N/A\", accordingly.\n3623\nAnswerable Example1:\nPassage: Hypoxia differs from hypoxemia and anoxemia in that hypoxia refers to a state in which oxygen supply is insufficient , whereas hypoxemia\nand anoxemia refer specifically to states that have low or zero arterial oxygen supply . Hypoxia in which there is complete deprivation of\noxygen supply is referred to as anoxia .\nQuestion: a medical term which means a deficiency but not a total lack of oxygen ?\nAnswer: hypoxia.\nAnswerable Example2:\nPassage: South Africa have played at six of the eight Rugby World Cup tournaments , having been unable to compete in the first two tournaments\ndue to a sports boycott during the apartheid era . Following the end of apartheid , they hosted the 1995 Rugby World Cup and won the\ntournament , and were champions again at the 2007 tournament in France . With two tournament wins , they are one of the three best\nperforming teams , along with Australia who have also won twice , and New Zealand with three wins , the only team to do better .\nQuestion: when did south africa first win the rugby world cup ?\nAnswer: 1995.\nUn-answerable Example:\nPassage: The Act of Settlement is an Act of the Parliament of England that was passed in 1701 to settle the succession to the English and Irish\ncrowns on Protestants only . The next Protestant in line to the throne was the Electress Sophia of Hanover , a granddaughter of James VI of\nScotland and I of England . After her the crowns would descend only to her non-Roman Catholic heirs .\nQuestion: The next Roman in line to the throne ?\nAnswer: unanswerable.\nVariant1\nAnswerable Example1:\nPassage: Louise Joy Brown ( born 25 July 1978 ) is an English woman known for being the first human to have been born after conception by in\nvitro fertilisation , or IVF .\nQuestion: when was the first in vitro baby born ?\nAnswer: 25 July 1978.\nAnswerable Example2:\nPassage: The 2018 College Football Playoff National Championship was a college football bowl game that determined the national champion in the\nNCAA Division I Football Bowl Subdivision for the 2017 season . The Alabama Crimson Tide defeated the Georgia Bulldogs 26 -- 23 in overtime\n. Alabama overcame a 13 -- 0 deficit at halftime . Tua Tagovailoa and Da’Ron Payne were respectively named the offensive and defensive\nplayers of the game .\nQuestion: who won the college football national championship tonight ?\nAnswer: The Alabama Crimson Tide.\nUn-answerable Example:\nPassage: The Ranch is an American comedy web television series starring Ashton Kutcher , Danny Masterson , Debra Winger , Elisha Cuthbert , and\nSam Elliott that debuted in 2016 on Netflix . The show takes place on the fictional Iron River Ranch in the fictitious small town of\nGarrison , Colorado ; detailing the life of the Bennetts , a dysfunctional family consisting of two brothers , their rancher father , and\nhis divorced wife and local bar owner . While the opening sequence shows scenes from Ouray , Colorado and surrounding Ouray County , The\nRanch is filmed on a sound stage in front of a live audience in Burbank , California . Each season consists of 20 episodes broken up into\ntwo parts , each containing 10 episodes .\nQuestion: when does the next series of the ranch come out ?\nAnswer: unanswerable.\nVariant2\nAnswerable Example1:\nPassage: \"Fool ( If You Think It ’s Over ) \" is the title of a popular song originally publicly released in 1978 by the British singer -\nsongwriter Chris Rea . Rea also wrote the words and composed the music of the song , which appears on his 1978 debut album , Whatever\nHappened to Benny Santini ? . The single ’s charting success in the USA earned him a Grammy nomination as Best New Artist in 1979 .\nQuestion: who sang fool if you think it over ?\nAnswer: Chris Rea.\nAnswerable Example2:\nPassage: The Mississippi Freedom Democratic Party ( MFDP ) was an American political party created in 1964 as a branch of the populist Freedom\nDemocratic organization in the state of Mississippi during the Civil Rights Movement . It was organized by African Americans and whites\nfrom Mississippi to challenge the legitimacy of the regular Mississippi Democratic Party , which allowed participation only by whites ,\nwhen African Americans made up 40 percent of the state population .\nQuestion: why did the mississippi freedom democratic party emerge at the democratic party convention in 1964 ?\nAnswer: to challenge the legitimacy of the regular Mississippi Democratic Party , which allowed participation only by whites , when African\nAmericans made up 40 percent of the state population.\nUn-answerable Example:\nPassage: Owing in part to the way in which the United Kingdom , and Northern Ireland , came into being , there is no legally defined term to\ndescribe what Northern Ireland ’ is ’ . There is also no uniform or guiding way to refer to Northern Ireland amongst the agencies of the UK\ngovernment . For example , the websites of the Office of the Prime Minister of the United Kingdom and the UK Statistics Authority describe\nthe United Kingdom as being made up of four countries , one of these being Northern Ireland . Other pages on the same websites refer to\nNorthern Ireland specifically as a ‘‘ province \" as do publications of the UK Statistics Authority . The website of the Northern Ireland\nStatistics and Research Agency also refers to Northern Ireland as being a province as does the website of the Office of Public Sector\nInformation and other agencies within Northern Ireland . Publications of HM Treasury and the Department of Finance and Personnel of the\nNorthern Ireland Executive , on the other hand , describe Northern Ireland as being a ‘‘ region of the UK \" . The UK ’s submission to the\n2007 United Nations Conference on the Standardization of Geographical Names defines the UK as being made up of two countries ( England and\nScotland ) , one principality ( Wales ) and one province ( Northern Ireland ) .\nQuestion: why is northern ireland not part of ireland ?\nAnswer: unanswerable.\nVariant3\nFigure 9: The three variants of in-context examples for the NQ prompts. For the regular prompts, we use the\ntwo answerable examples, whereas for the prompts hinting at the possibility of (un)answerability, we use the first\nanswerable example and the (un)answerable examples. Additionally, for the other prompt variants, we replace the\n\"unanswerable\" answer of the (un)answerable example with \"IDK\" and \"N/A\", accordingly.\n3624\nAnswerable Example1:\nPassage: Paragraph 1: South Africa have played at six of the eight Rugby World Cup tournaments, having been unable to compete in the first two\ntournaments due to a sports boycott during the apartheid era. Following the end of apartheid, they hosted the 1995 Rugby World Cup and won\nthe tournament. Paragraph 2: With two tournament wins, South Africa is one of the three best performing teams, along with Australia who\nhave also won twice, and New Zealand with three wins, the only team to do better.\nQuestion: How many times did the winner of the 1995 Rugby World Cup win in total?\nAnswer: two times.\nAnswerable Example2:\nPassage: Paragraph 1: Barack Obama is an American politician who served as the 44th president of the United States from 2009 to 2017. Pargaraph\n2: Obama married Michelle on October 3, 1992, after being engaged for almost a year. Paragraph 3: Barack Obama was born in Honolulu,\nHawaii. After graduating from Columbia University in 1983, he worked as a community organizer in Chicago.\nQuestion: What is the name of the wife of the American president who was born in Hawaii?\nAnswer: Michelle.\nUn-answerable Example:\nPassage: Paragraph 1: Barack Obama is an American politician who served as the 44th president of the United States from 2009 to 2017. Pargaraph\n2: Obama married Michelle on October 3, 1992, after being engaged for almost a year.\nQuestion: What is the name of the wife of the American president who was born in New York?\nAnswer: unanswerable.\nVariant1\nAnswerable Example1:\nPassage: Paragraph 1: Kaya toast is a well-known snack in Singapore. Kaya toast is prepared with kaya (coconut jam), a topping of sugar, coconut\nmilk and eggs, pandan, and sometimes margarine or butter. Kaya is generally served on toast, and also sometimes on crackers. It is\nconsidered a breakfast staple, and remains popular in Singapore. The dish is sometimes dipped into soft-boiled egg with a little dark soy\nsauce and white pepper. Paragraph 2: A justice of the peace in Singapore derives his powers from statute law. He is appointed by the\nPresident of the Republic of Singapore, under the provisions of section 11 (l) of the Subordinate Courts Act (Cap. 321). The President may\nrevoke the appointment of any justice of the peace. A newly appointed justice of the peace is required by section 17 of the Subordinate\nCourts Act, to take the oath of office and allegiance as set out in the schedule to the Subordinate Courts Act, before exercising the\nfunctions of his office.\nQuestion: How do you become a justice of peace in the country where Kaya toast is popular?\nAnswer: appointed by the President of the Republic of Singapore.\nAnswerable Example2:\nPassage: Paragraph 1: Mount Henry is located in the Lewis Range, Glacier National Park in the U.S. state of Montana. Mount Henry is just south of\nAppistoki Peak in the Two Medicine region of the park. Paragraph 2: KJRZ-LP (105.3 FM) was a radio station in Libby, Montana. It was owned\nand operated by the Libby Area Chamber of Commerce. Paragraph 3: The Lewis Range is a mountain range located in the Rocky Mountains of\nnorthern Montana, United States and extreme southern Alberta, Canada. It was formed as a result of the Lewis Overthrust, a geologic thrust\nfault resulted in the overlying of younger Cretaceous rocks by older Proterozoic rocks. The range is located within Waterton Lakes National\nPark in Alberta, Canada and Glacier National Park and the Bob Marshall Wilderness Complex in Montana, United States. The highest peak is\nMount Cleveland at .\nQuestion: In what mountain group is the range of which Mount Henry from the state where KJRZ-LP is located is part?\nAnswer: Rocky Mountains.\nUn-answerable Example:\nPassage: Paragraph 1: WODS (103.3 MHz) - known on-air as 103.3 AMP Radio - is a commercial FM radio station in Boston, Massachusetts. WODS airs a\nTop 40 (CHR) radio format, and is owned by Entercom. Its studios and offices are located on Leo M. Birmingham Parkwary in Brighton.\nParagraph 2: The Embassy of the United States to the Republic of Indonesia is located in Jakarta just south of the Monas at Jalan Medan\nMerdeka Selatan. Paragraph 3: Westminster College is a private liberal arts college located in the Sugar House neighborhood of Salt Lake\nCity, Utah, United States. The college comprises four schools: the School of Arts and Sciences, the Bill and Vieve Gore School of Business,\nthe School of Education, and the School of Nursing and Health Sciences. It is the only accredited liberal arts college in the state of\nUtah. Paragraph 4: The Shorter House is located at the end of Andrews Road in Thompson Ridge, a hamlet in the Town of Crawford in Orange\nCounty, New York, United States. It is a late 18th-century building later modified in the Greek Revival style.\nQuestion: What is the business category of Crawford House, located in the same city as WODS and the same state as Wellesley College in Mona Lisa\nSmile?\nAnswer: unanswerable.\nVariant2\nAnswerable Example1:\nPassage: Paragraph 1: Meet Me in St. Louis is a musical film made by Metro - Goldwyn - Mayer and released in 1944. Divided into a series of\nseasonal vignettes, starting with Summer 1903, it relates the story of a year in the life of the Smith family in St. Louis, leading up to\nthe opening of the Louisiana Purchase Exposition (more commonly referred to as the World\\’s Fair) in the spring of 1904. The picture stars\nJudy Garland, Margaret O\\’Brien, Mary Astor, Lucille Bremer, Tom Drake, Leon Ames, Marjorie Main, June Lockhart, and Joan Carroll.\nParagraph 2: Gracie is a 2007 American sports drama film directed by Davis Guggenheim. It stars Carly Schroeder as Gracie Bowen, Dermot\nMulroney as Bryan Bowen, Elisabeth Shue as Lindsay Bowen, Jesse Lee Soffer as Johnny Bowen, and Andrew Shue as Coach Owen Clark. Paragraph\n3: He was born Philip Davis Guggenheim in St. Louis, Missouri, United States, the son of Marion Davis and film director and producer\nCharles Guggenheim. His father was Jewish, whereas his mother was Episcopalian. He graduated from the Potomac School (McLean, Virginia)\n(1979), from Sidwell Friends School (1982), and from Brown University (1986).\nQuestion: When does Meet Me in the birthplace of Gracie’s director take place?\nAnswer: starting with Summer 1903.\nAnswerable Example2:\nPassage: Paragraph 1: The city has a Mayor and is one of the 16 cities and towns in England and Wales to have a ceremonial sheriff who acts as a\ndeputy for the Mayor. The current and 793rd Mayor of Southampton is Linda Norris. Catherine McEwing is the current and 578th sherriff. The\ntown crier from 2004 until his death in 2014 was John Melody, who acted as master of ceremonies in the city and who possessed a cry of 104\ndecibels. Paragraph 2: John May (born 26 September 1849 in Southampton, Hampshire; date of death unknown) was an English cricketer. May was\na right-handed batsman who was a right-arm fast bowler.\nQuestion: Who is the current mayor of the birthplace of John May?\nAnswer: Linda Norris.\nUn-answerable Example:\nPassage: Paragraph 1: Imran Khan has held the office of Prime Minister since 18 August 2018, following the outcome of nationwide general\nelections held on 25 July 2018. Paragraph 2: Hampi, also referred to as the Group of Monuments at Hampi, is a UNESCO World Heritage Site\nlocated in east - central Karnataka, India. It became the centre of the Hindu Vijayanagara Empire capital in the 14th century. Chronicles\nleft by Persian and European travellers, particularly the Portuguese, state Hampi was a prosperous, wealthy and grand city near the\nTungabhadra River, with numerous temples, farms and trading markets. By 1500 CE, Hampi - Vijayanagara was the world\\’s second - largest\nmedieval - era city after Beijing, and probably India\\’s richest at that time, attracting traders from Persia and Portugal. The\nVijayanagara Empire was defeated by a coalition of Muslim sultanates; its capital was conquered, pillaged and destroyed by sultanate armies\nin 1565, after which Hampi remained in ruins. Paragraph 3: As of June 2018, the Government of Karnataka consists of 27 ministers including\nChief Minister and a Deputy Chief Minister. Paragraph 4: Thekkady (Idukki district) is the location of the Periyar National Park, which is\nan important tourist attraction in the Kerala state of India.\nQuestion: As of 2018, who is the minister of the state where hampi tourist place is located?\nAnswer: unanswerable.\nVariant3\nFigure 10: The three variants of in-context examples for the MuSiQue prompts. For the regular prompts, we use the\ntwo answerable examples, whereas for the prompts hinting at the possibility of (un)answerability, we use the first\nanswerable example and the (un)answerable examples. Additionally, for the other prompt variants, we replace the\n\"unanswerable\" answer of the (un)answerable example with \"IDK\" and \"N/A\", accordingly.\n3625",
  "topic": "Context (archaeology)",
  "concepts": [
    {
      "name": "Context (archaeology)",
      "score": 0.597777783870697
    },
    {
      "name": "Representation (politics)",
      "score": 0.5311112999916077
    },
    {
      "name": "Computer science",
      "score": 0.500004768371582
    },
    {
      "name": "Security token",
      "score": 0.4410806894302368
    },
    {
      "name": "Cognitive science",
      "score": 0.36085325479507446
    },
    {
      "name": "Psychology",
      "score": 0.2903614938259125
    },
    {
      "name": "Political science",
      "score": 0.16834843158721924
    },
    {
      "name": "History",
      "score": 0.15678387880325317
    },
    {
      "name": "Computer security",
      "score": 0.09936639666557312
    },
    {
      "name": "Politics",
      "score": 0.09135431051254272
    },
    {
      "name": "Law",
      "score": 0.08432716131210327
    },
    {
      "name": "Archaeology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I13955877",
      "name": "Bar-Ilan University",
      "country": "IL"
    },
    {
      "id": "https://openalex.org/I1291425158",
      "name": "Google (United States)",
      "country": "US"
    }
  ],
  "cited_by": 7
}