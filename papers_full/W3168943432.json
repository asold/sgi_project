{
    "title": "Fraud Detection in Online Product Review Systems via Heterogeneous Graph Transformer",
    "url": "https://openalex.org/W3168943432",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A5085461818",
            "name": "Songkai Tang",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A5019491931",
            "name": "Luhua Jin",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A5030803449",
            "name": "Fan Cheng",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2064058256",
        "https://openalex.org/W3035298482",
        "https://openalex.org/W2136891251",
        "https://openalex.org/W3081300507",
        "https://openalex.org/W2988801199",
        "https://openalex.org/W3011667710",
        "https://openalex.org/W6637178625",
        "https://openalex.org/W6720006811",
        "https://openalex.org/W6726873649",
        "https://openalex.org/W6738964360",
        "https://openalex.org/W2911286998",
        "https://openalex.org/W6758577623",
        "https://openalex.org/W6786679236",
        "https://openalex.org/W3022945404",
        "https://openalex.org/W2963415211",
        "https://openalex.org/W2970127247",
        "https://openalex.org/W3021651554",
        "https://openalex.org/W3068123808",
        "https://openalex.org/W3009901425",
        "https://openalex.org/W2984239289",
        "https://openalex.org/W2945996535",
        "https://openalex.org/W2897862648",
        "https://openalex.org/W2079450376",
        "https://openalex.org/W2982648802",
        "https://openalex.org/W2965857891",
        "https://openalex.org/W2789042518",
        "https://openalex.org/W2112213600",
        "https://openalex.org/W3012871709",
        "https://openalex.org/W2783466287",
        "https://openalex.org/W2808771744",
        "https://openalex.org/W1662382123",
        "https://openalex.org/W3102969158",
        "https://openalex.org/W2964015378",
        "https://openalex.org/W4297733535",
        "https://openalex.org/W2912415363",
        "https://openalex.org/W4294558607",
        "https://openalex.org/W3099825604",
        "https://openalex.org/W3099064659",
        "https://openalex.org/W3108818925",
        "https://openalex.org/W2964321699"
    ],
    "abstract": "In online product review systems, users are allowed to submit reviews about their purchased items or services. However, fake reviews posted by fraudulent users often mislead consumers and bring losses to enterprises. Traditional fraud detection algorithm mainly utilizes rule-based methods, which is insufficient for the rich user interactions and graph-structured data. In recent years, graph-based methods have been proposed to handle this situation, but few prior works have noticed the camouflage fraudster&amp;#x2019;s behavior and inconsistency heterogeneous nature. Existing methods have either not addressed these two problems or only partially, which results in poor performance. Alternatively, we propose a new model named Fraud Aware Heterogeneous Graph Transformer (FAHGT), to address camouflages and inconsistency problems in a unified manner. FAHGT adopts a type-aware feature mapping mechanism to handle heterogeneous graph data, then implementing various relation scoring methods to alleviate inconsistency and discover camouflage. Finally, the neighbors&amp;#x2019; features are aggregated together to build an informative representation. FAHGT shows a remarkable performance gain compared to several baselines on different datasets.",
    "full_text": "Received April 21, 2021, accepted May 12, 2021, date of publication May 31, 2021, date of current version December 28, 2021.\nDigital Object Identifier 10.1 109/ACCESS.2021.3084924\nFraud Detection in Online Product Review\nSystems via Heterogeneous Graph Transformer\nSONGKAI TANG\n , (Graduate Student Member, IEEE),\nLUHUA JIN, (Graduate Student Member, IEEE), AND FAN CHENG\n, (Member, IEEE)\nDepartment of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai 200240, China\nCorresponding author: Fan Cheng (chengfan@sjtu.edu.cn)\nThis work was supported in part by the NSFC under Grant 61701304, in part by the Shanghai Sailing Program under Grant 17YF1410100,\nand in part by the Program for Professor of Special Appointment, Eastern Scholar at Shanghai Institutions of Higher Learning.\nABSTRACT In online product review systems, users are allowed to submit reviews about their purchased\nitems or services. However, fake reviews posted by fraudulent users often mislead consumers and bring losses\nto enterprises. Traditional fraud detection algorithm mainly utilizes rule-based methods, which is insufﬁcient\nfor the rich user interactions and graph-structured data. In recent years, graph-based methods have been\nproposed to handle this situation, but few prior works have noticed the camouﬂage fraudster’s behavior and\ninconsistency heterogeneous nature. Existing methods have either not addressed these two problems or only\npartially, which results in poor performance. Alternatively, we propose a new model named Fraud Aware\nHeterogeneous Graph Transformer (FAHGT), to address camouﬂages and inconsistency problems in a\nuniﬁed manner. FAHGT adopts a type-aware feature mapping mechanism to handle heterogeneous graph\ndata, then implementing various relation scoring methods to alleviate inconsistency and discover camouﬂage.\nFinally, the neighbors’ features are aggregated together to build an informative representation. FAHGT shows\na remarkable performance gain compared to several baselines on different datasets.\nINDEX TERMS Fraud detection, graph neural network, data mining.\nI. INTRODUCTION\nInternet services have brought human beings with\ne-commerce, social networking, and entertainment plat-\nforms, which not only facilitate information exchange but\nalso provide chances to fraudsters. Fraudsters disguise\nthemselves as ordinary users to publish spam informa-\ntion [1] or collect user privacy, compromising the inter-\nest of both platforms and users. In addition, multiple\nentities on the Internet are connected with multiple rela-\ntionships. Traditional machine learning algorithms cannot\nhandle this complicated heterogeneous graph data well.\nThe current approach is to model the data as a heteroge-\nneous information network so that similarities in charac-\nteristics and structure of fraudsters can be discovered. Due\nto its effectiveness in learning node representations and\ndiscovering structure pattern, graph neural networks have\nbeen drawn attention in fraud detection domain including\nproduct review [2]–[5], mobile application distribution [6],\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Szidónia Lefkovits\n.\ncybercrime identiﬁcation [7] and ﬁnancial services [8], [9].\nHowever, most existing GNN based solutions just directly\napply homogeneous GNNs, ignoring the underlying het-\nerogeneous graph nature and camouﬂage node behaviors.\nThis problem has drawn great attention with many solutions\nproposed [4], [5], [10]. GraphConsis [4] found that there\nare three inconsistency problems in fraud detection and\nCAREGNN [5] further proposed two camouﬂage behaviors.\nThese problems could be summarized as follows:\n• Camouﬂage: Previous work showed that crowd work-\ners could adjust their behavior to alleviate their\nsuspicion via connecting to benign entities like con-\nnecting to highly reputable users, disguise fraudulent\nURLs with special characters [3], [6], or generate\ndomain-independent fake reviews via generative lan-\nguage model [11] to conceal their suspicious activities.\n• Inconsistency: Two users with distinct interests could\nbe connected via reviewing a common product such as\nfood or movies. Direct aggregation makes GNNs hardly\ndistinguish the unique semantic user pattern. Also, if a\nuser is suspicious, then the other one should be more\n167364 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 9, 2021\nS. Tanget al.: Fraud Detection in Online Product Review Systems via HGT\nlikely to be distrustful if they are connected by common-\nactivity relation since fraudulent users tend to generate\nspam content in the same short period.\nTo address the above two problems, many methods have\nbeen proposed. GraphConsis addresses the inconsistency\nproblem by computing the similarity score between node\nembeddings, which cannot distinguish nodes with differ-\nent types. CAREGNN enhances GNN-based fraud detectors\nagainst camouﬂaged fraudsters by reinforcement learning-\nbased neighbor selector and relation aware aggregator. Its\nperformance still suffers from the heterogeneous graph.\nIn this paper, we introduce the Fraud Aware Heterogeneous\nGraph Transformer(FAHGT), where we propose heteroge-\nneous mutual attention to address the inconsistency prob-\nlem and design a label-aware neighbor selector to solve\nthe camouﬂage problem. Both are implemented in a uniﬁed\nmanner called the ‘‘score head mechanism’’. We demon-\nstrate the fraud detection performance of FAHGT on many\nreal-world datasets. It is veriﬁed that FAHGT can con-\nsiderably improve F1 score, KS and AUC over several\nbaselines.\nThe advantages of FAHGT can be summarized as follows:\n• Heterogeneity: FAHGT is able to handle heterogeneous\ngraphs with multi-relation and multi-node type without\ndesigning meta-path manually.\n• Focus: FAHGT attentively selects neighbors given\na noise graph from real-world data. The selected\nneighbors are either informative for feature aggrega-\ntion or risky for fraud detection.\n• Efﬁciency: FAHGT admits a low computational com-\nplexity via a parallelizable multi-head mechanism in\nrelation scoring and feature aggregation.\n• Flexibility: FAHGT injects domain knowledge by intro-\nducing a ﬂexible relation scoring mechanism. The score\nof a relation connecting two nodes not only comes\nfrom direct feature interaction but is also constrained by\ndomain knowledge.\nII. RELATED WORK\nA. GRAPH NEURAL NETWORKS\nThe Graph Neural Network is a generalization of CNN to\ngraphs [12]. The initial graph convolution idea in the spectral\ndomain is inspired by the Fourier transformation in signal\nprocessing [13]. Then, ChebNet [14] and GCN [15] are\nproposed to improve efﬁciency by using approximation. For\nGNNs on spatial domain, GraphSAGE [16] learns the node\nrepresentation by iterative aggregation in a sampled node tree.\nGAT [17] further proposes to learn in the spatial domain by\ncomputing different importance of neighbor nodes via the\nmasked self-attention mechanism.\nIn recent years, lots of heterogeneous GNN based meth-\nods have been developed. HAN [18], HAHE [19], and\nDeepHGNN [20] transforms a heterogeneous graph into\nseveral homogeneous graphs based on handcrafted meta-\npaths, applies GNN separately on each graph, and aggre-\ngates the output representations by attention mechanism.\nGraphInception [21] constructs meta-paths between nodes\nwith the same object type. HetGNN [22] ﬁrst samples a\nﬁxed number of neighbors via random walk strategy. Then it\napplies a hierarchical aggregation mechanism for intra-type\nand inter-type aggregation. HGT [23] extends transformer\narchitecture to heterogeneous graphs. They directly calculate\nattention scores for all the neighbors of a target node and\nperform aggregation accordingly without considering domain\nknowledge.\nB. GRAPH BASED FRAUD DETECTION\nRecently, many graph-based fraud detectors have proposed\nsince suspicion between entities could be well captured. [24]\nﬁrstly build a spam detection graph model with iterative\ncomputation framework while NetWalk [25] extends fraud\ndetection to dynamic networks. For industrial applications,\n[26] design graph-based system for suspicious users identiﬁ-\ncation and [9] proposes embedding-based malicious account\ndetector in Alibaba.com.\nTo apply neural network to graph data, many GNN-based\nfraud detectors constructs graph without edge type\ninformation for applying homogeneous graph neural net-\nworks. Fdgars [2] and GraphConsis [4] ignores relation\ntype information and constructs a single homogeneous graph\nfor neighborhood information aggregation. GeniePath [27]\nfurther proposes to learn adaptive receptive ﬁelds and select\nneighbor nodes effectively.\nFor type-aware graph fraud detectors, their main solu-\ntion is to build multiple homogeneous graphs based on\nedge type information of the original graph then per-\nform type-independent node level aggregation and graph\nlevel concatenation. GEM [9] learns weighting parameters\nfor different homogeneous subgraph. Player2Vec [7] and\nSemiGNN [8] both adopt attention mechanism in feature\naggregation and SemiGNN further leverages a structure\nloss to guarantee the node embeddings homophily. Some\nworks directly aggregate heterogeneous information in the\ngraph. For instance, under a user-review-item heterogeneous\ngraph, GAS [3] learns type-speciﬁc node embedding for\naggregation.\nAmong the above works, few works [4]–[6] have acknowl-\nedged the camouﬂage behaviors and propose their solution,\nas stated in [5]. All these works can only handle a multi-\nrelation graph, where all nodes are considered to be the same\ntype. ASA [6] creates static features for directly aggregating\nmessages in each homogeneous graph. GraphConsis [4] is\ntrained in an unsupervised manner and results in inferior\nperformances. CAREGNN [5] cannot handle multiple node\ntypes and requires a computational expensive reinforcement\nlearning process. In addition, xFraud [28] takes node types\ninto consideration, but their work does not uncover the cam-\nouﬂage behaviors of fraudsters.\nOur model could handle heterogeneous graphs with multi-\nnode types and overcome those shortcomings by using an\nefﬁcient score head attention architecture.\nVOLUME 9, 2021 167365\nS. Tanget al.: Fraud Detection in Online Product Review Systems via HGT\nIII. PROBLEM DEFINITION\nA. HETEROGENEOUS GRAPH\nFollowing [23], a heterogeneous graph is deﬁned as\nG =(V,E,A,R), where V is the set of nodes, A represents\nthe set of node types and τ(v) :V →A is the node type\nmapping function. Also, E is the set of edges, E represents\nthe set of edge types and φ(e) :E →R is the edge type\nmapping function.\nB. GRAPH-BASED FRAUD DETECTION\nGiven a set of nodes V, the node feature matrix X and\nits corresponding graph G, our aim is to justify the node’s\nsuspicious Y by ﬁnding an optimal detector f such that Y =\nf (X,G). Y ∈{0, 1}, where 1 stands for suspicious users and\n0 stands for benign users. The detector f is trained based on\nthe node with label information and all node features in a\nsemi-supervised manner. For example, the node could be an\naccount in a transaction system or a user in a social network.\nThe edges could be transactions between accounts or contacts\nbetween users. The suspicious label could be determined by\nwhether a user has posted spam content.\nIV. OUR MODEL\nA. OVERVIEW\nIn general, the Fraud Aware Heterogeneous Graph Trans-\nformer(FAHGT) resorts to the aggregation-based GNN\nlayer [23] deﬁned as follows:\nHl [t] ← Aggregate\n∀s∈N(t),∀e∈E(s,t)\n(\nScore(s,e,t) ·Feature(s,e,t)\n)\n(1)\nwhere t is the target node and N(t) is the set of neighbors\nof t. All its neighbors s ∈N(t) might belong to different node\ntype. The following paragraphs provides deﬁnitions for basic\noperators in (1):\n• Score: estimates the importance of each triplet (s, e,t);\n• Feature: extracts the feature from the source node s;\n• Aggregate: can be functions of sum, mean, max or con-\ncatenation operation, which aggregates the neighbor-\nhood feature by the score.\nFor example, Heterogeneous Graph Transformer (HGT) [23]\nadopts a meta triplet speciﬁc attention mechanism as Score,\nuses the type aware mapping for calculating Feature, and\nuses weighted average operation for the Aggregate step.\nOur FAHGT model subsumes HGT model. Fig. 1 shows\nthe overall architecture of FAHGT. FAHGT consists of three\nmodules: (1) meta relation scoring; (2) feature node projec-\ntion; (3) aggregation.\nB. META RELATION SCORING\nThe Score operator evaluates the importance of each meta\nrelations, i.e., the ⟨τ(s),φ(e),τ(t)⟩triplets. The original\nHGT model implemented Score via introducing a meta triplet\nspeciﬁc attention mechanism, which cannot distinguish cam-\nouﬂage user behaviour. Our model generalizes Score by\ninjecting domain knowledge, leading to a more ﬂexible and\npowerful architecture. The Score operator consists of h score\nheads and is deﬁned as follows:\nScore(s,e,t) =Softmax\n∀s∈N(t)\n(\n∥\ni:i∈{1,2,...,h}\nSHi(s,e,t)\n)\n(2)\n∑\n∀s∈N(t)\nSHi(s,e,t) =1, 1 ≤i ≤h (3)\nwhere SHi denotes the i-th score head and ∥is the concatenate\noperation. The Softmax function is conducted for each i-th\nscore head over neighbor nodes for score normalization. Two\ntypes of scoring heads (SH) are introduced here, i.e., hetero-\ngeneous mutual attention (HA) head and label aware similar-\nity (LS) head:\n1) HETEROGENEOUS MUTUAL ATTENTION\nHeterogeneous mutual attention is adopted from HGT [23].\nThe i-th HA head is obtained from the triplet ( s,e,t) as\nfollows:\nSHi\nHA(s,e,t) =\n(\nKi(s) PS\nφ(e) Qi(t)T\n)\n·µ⟨τ(s),φ(e),τ(t)⟩\n√\nd\n(4)\nKi(s) =Hl−1[s]Ui\nτ(s)\nQi(t) =Hl−1[t]V i\nτ(t)\nwhere the input Hl−1[·] is of dimension d, Ui\nτ(s) ∈Rh×d\nh\nprojects the representation of τ(s)-type source node s into\nthe i-th vector Ki(s) ∈R\nd\nh . Similarly, V i\nτ(t) is operated on\nthe representation of the target node. PS\nφ(e) ∈ R\nd\nh ×d\nh is to\nbe learned to generate different representations for different\nedge type φ(e). µ ∈ R|A|×|R|×|A| serves as the global\nimportance of each meta relation triplet ⟨τ(s),φ(e),τ(t)⟩.\nThe designed HA relieves the aggregation-based GNN\nmodel from inconsistency problem via utilizing the speciﬁc\ntype information of nodes and edges.\n2) LABEL AWARE SCORING\nInspired by [5] and [29], we choose a single layer neural\nnetwork for soft node label prediction and the L1 distance\nfor measuring their label similarity. Speciﬁcally, if we have\nτ(s) =τ(t) =User, we set:\nSHi\nLS(s,·,t)=1−\nσ\n(\nMLPi\nLS(X[s])\n)\n−σ\n(\nMLPi\nLS(X[t])\n)\n1\n(5)\nwhere σ denotes the sigmoid function. The input of MLPLS\nis the original node features, and the output of MLPLS is\npassed into sigmoid function σ to generate the positive label\nprobability. For nodes whose fraud label is undeﬁned like\nproduct node, we manually set the score SHi\nLS(s,·,t) to 0.5.\nThe designed LS actively selects optimal neighbors by\nconsidering its fraud behavior. An edge connecting two sus-\npicious user nodes will be assigned a higher score in aggrega-\ntion, which enables fraud-aware node embedding generation.\nFinally, we gather h score heads together from its neighbors\nN(t) for each triplet. It should be noted that different types\n167366 VOLUME 9, 2021\nS. Tanget al.: Fraud Detection in Online Product Review Systems via HGT\nFIGURE 1. FAHGT Architecture.Different colors denote different node types.Hl−1[·] denotes the node feature\nlearned of (l− 1)-th layer. In each layer, the relation is scored bySH(·) and the feature is projected byFH(·). Then,\nprojected neighbor node features with different types are aggregated into thel-th layer’s representationHl [·]. The\nFAHGT layer can be stacked and the output of the final layer could be used for prediction.\nof score heads can be used interchangeably. For example,\nthree HA heads and one LS head can be used in one model.\nIf only HA heads are used, the FAHGT model reduces\nto the HGT model. In this manner, feature-based atten-\ntion and label-based similarity could cooperate in a uniﬁed\nframework.\nC. FEATURE NODE PROJECTION\nFollowing [23], for the triplet (s, e,t), we calculate its multi-\nhead Feature by considering its type information:\nFeature(s,e,t) = ∥\ni:i∈{1,2,...,h}\nFHi(s,e,t) (6)\nFHi(s,e,t) =Hl−1[s]W i\nτ(s)PF\nφ(e) (7)\nwhere the input Hl−1[·] is of dimension d. W i\nτ(s) ∈Rd×d\nh\nprojects the representation of source node s into τ(s)-type\nsubspace, followed by projection of PF\nφ(e) ∈R\nd\nh ×d\nh for incor-\nporating the edge dependency. The ﬁnal step is to concatenate\nall h feature heads to get the Feature(s,e,t).\nD. AGGREGATION AND OPTIMIZATION\nAfter meta relation scoring and feature node projection,\nwe perform message passing from the source nodes to the\ntarget node. Following [23], we aggregate node feature with\nrelation score, and get the aggregated representation ˜Hl [t] as:\n˜Hl [t] = ⊕\n∀s∈N(t)\n(\nScore(s,e,t) ·Feature(s,e,t)\n)\n(8)\nThe representation ˜Hl [t] of target node t is then projected\nback to its origin τ(t)-type feature subspace via a linear\nprojection Aτ(t) and residual connection, following [23]:\nHl [t] =σ\n(˜Hl [t]\n)\nAτ(t) +Hl−1[t]. (9)\nIn this way, we get the l-th layer’s output Hl [t] for the target\nnode t.\nThe FAHGT layer can be stacked many times for incor-\nporating distant node information. For each node v, its ﬁnal\nembedding z[v] =HL [v] can be used for prediction task. The\nloss of node label prediction and soft label similarity can be\nVOLUME 9, 2021 167367\nS. Tanget al.: Fraud Detection in Online Product Review Systems via HGT\nTABLE 1. Statistics of dataset.\nTABLE 2. Detail of user node feature.\ndeﬁned as two cross-entropy function, following [5]:\nLGNN =\n∑\nv∈Vlabeled\n−log (yv ·σ(MLPGNN(z[v]))) (10)\nLLS =\n∑\nv∈Vlabeled\n−log(yv ·σ(MLPLS(X[v]))) (11)\nLFAHGT =LGNN +λLSLLS +λReg||2||2 (12)\nwhere Vlabeled ⊂V is the set of labeled nodes, ||2||2 is the\nL2-norm of all model parameters, λLS and λReg are weighting\nparameters. The whole model is trained in a semi-supervised\nmanner.\nV. EXPERIMENTS\nIn this section, we aim to present four research ﬁndings:\n• Heterogeneous graph construction from real world fraud\ndata;\n• Performance evaluation among popular general graph\nneural networks and fraud detectors;\n• Hyper-parameter sensitivity study and model efﬁciency\nevaluation;\n• Visual evidence of model’s risk analyzing ability.\nA. EXPERIMENTAL SETUP\n1) DATASET\nThe Amazon review dataset [30] is used for training and\nevaluating models. We select three categories from dataset:\nBaby (BB), Music Instruments (MI), and Automotive (AM).\nSimilar to [5], we consider users received at least 20 votes\nas labeled. Fraudulent users have less than 20% helpful votes\nand benign users have more than 80% helpful votes. We also\nadopt the node feature transformation and edge construction\nfrom [5]. The user and product are regarded as a node in\nthe graph. We take 24 handcrafted features as the user node\nfeatures and 50 handcrafted features as the product node\nfeature described in Table 2 and 3. The edges between nodes\nare built from both underlying distribution of data and domain\nknowledge:\n• U-P: User with its reviewed product.\n• U-A-U: Two users with one or more identical rating in\n7 days.\n• U-S-U: Two users with top 5% review text TF-IDF\nscore.\nTable 1 shows the dataset statistics.\n2) BASELINES\nThe performance of FAHGT in fraud detection is veriﬁed\nby comparing it with various GNN baselines and popular\ngraph based fraud detectors. For general graph neural net-\nworks, we select GCN [15], GAT [17], GraphSAGE [16],\nGeniePath [16]. For popular GNN-based fraud detec-\ntors, we select SemiGNN [8], GraphConsis [4] and\nCAREGNN [5]. GCN, GAT, GraphSAGE, and GeniePath are\nrun on homogeneous graphs. SemiGNN, GraphConsis, and\nGeniePath consider edge types in their approaches, and node\ntypes are not considered but equally treated. We also include\ntwo variants of our model for ablation study. FAHGT-l\n(LAGCN) [29] ﬁlters noise neighbor node effectively, but\nis not able to learn informative representation from a graph\nwith different node type and edge type. FAHGT-h(HGT) [23]\n167368 VOLUME 9, 2021\nS. Tanget al.: Fraud Detection in Online Product Review Systems via HGT\nTABLE 3. Detail of product node feature.\nhandles heterogeneous graph but lacks the ability to discover\ncamﬂouge behavior.\n3) EXPERIMENTAL SETTING\nTable 1 indicates that the amount of fraudsters is rare com-\npared to the whole users in all three datasets and the dense\nedge connections form a large-scale graph. To improve train-\ning efﬁciency, we sample a small batch of the labeled node\nwith its k-hop subgraph. Under each batch, the number of\npositive instances and negative instances is kept equally.\nWe use 64 as the embedding size throughout all neural\nnetwork baselines. All GNNs keep 2 layers of receptive ﬁelds\nand we use ﬁxed neighborhood sample sizes of 25 and 10 fol-\nlowing [16]. For model parameter optimization, we use a uni-\nﬁed optimizer (Adam), training fraction (40%), learning rate\n(1e-3), training epochs (500), and L2 regularization weight\n(λReg =0.001) for all models. For CAREGNN, we set the RL\naction step size as 0.02. In our proposed FAHGT, we set the\nsimilarity loss weight (λ LS) as 2. The sensitivity of the layer\nnumbers, embedding size, and training fraction are studied in\nsection V-C.\n4) IMPLEMENTATION\nWe implement all models in PyTorch 1.7, PyTorch Geometric\n1.7, and Python 3.8. GCN, GAT, GeniePath, GraphSAGE,\nSemiGNN, and GraphConsis are implemented following the\noriginal paper. For the CAREGNN, we use the source code 1\nprovided by the authors. All models are running on an Ubuntu\nserver with 4 NVIDIA 1080 Ti GPUs.\n5) EVALUATION METRIC\nSince the imbalanced nature of all three datasets, and positive\ninstances should be paid more attention in the fraud detection\ndomain, we utilize Macro F1 (F1), Kolmogorov Smirnov\nTest (KS), and ROC-AUC (AUC) to evaluate the overall\nperformance of all classiﬁers like previous works [5], [32].\n• F1: Macro F1-score consider the same importance for\neach class. A high the F1 score indicates a good perfor-\nmance of a classiﬁer.\n• KS: The Kolmogorov-Smirnov Test measures the simi-\nlarity between predicted and observed data. A high KS\nscore indicates a strong risk measuring ability.\n• AUC: The Area Under the Curve (AUC) measures the\nperformance of model at distinguishing between the\npositive and negative instances.\n1https://github.com/YingtongDou/CARE-GNN\nB. OVERALL EVALUATION\n1) EXPRESSIVE POWER OF DATA HETEROGENEITY\nTable 4 shows the performance of FAHGT and various base-\nlines on three datasets. We observe that FAHGT outperforms\nother baselines under all of the metrics. The poor result of\nlogistic regression (LR) indicates that graph structure and\nneighbor features both are useful in fraudster prediction.\nThe performances of four homogeneous GNN baselines from\nGCN to GeniePath are comparable to multi-relation methods.\nThis result implies that previous state-of-the-art graph-based\nsolution are not applicable for heterogeneous graph data.\nDirect node features aggregation with types information may\nintroduce noises, resulting in degraded performance. FAHGT\nand its variants aggregate information from the nodes with\ntype-aware and label-aware scoring, which could discover\ncamouﬂage behaviors by unrelated neighbor ﬁltering and\nextract heterogeneous graph information.\n2) MODEL VARIANTS\nFAHGT and its variants with different score head combina-\ntions is also reported in Table 4. FAHGT-l(LAGCN) only uses\nthe label head and FAHGT-h(HGT) only uses the attention\nhead.\nThe experiment result shows that our model outperforms\nmost of GNN-based fraud detectors in most metrics and\ndatasets, which reveals that current graph fraud detection\napproaches suffer from inconsistency problems when deal-\ning with heterogeneous graph data. While GraphConsis and\nCAREGNN also use similarity measure to discover node\ncamouﬂage, both of them shows unstable performance com-\nparing with our FAHGT-l(LAGCN) model. In addition, on the\nBaby dataset, we observe that GraphSAGE shows compa-\nrable performance with FAHGT-l(LAGCN) and FAHGT-\nh(HGT). The reason for this phenomenon may be that\nthe number of U-S-U relations between users in the Baby\ndataset is relatively high, making it easier to ﬁnd fraudulent\nusers who tend to post similar reviews. In such a situation,\nthe FAHGT-l(LAGCN) and FAHGT-h(HGT) both show rel-\natively ordinary performance due to parameter overﬁtting.\nThat is, both attention and score head will become neces-\nsary in scoring meta relation. Combining both of them results\nin a better performance.\nC. HYPER-PARAMETER SENSITIVITY\nFrom Fig. 2, we observe that two-layer FAHGT usually per-\nforms better than one-layer FAHGT, but three-layer FAHGT\nbarely improves the performance. This may due to the\nover-smooth problem in a larger receptive ﬁeld. Therefore,\nVOLUME 9, 2021 167369\nS. Tanget al.: Fraud Detection in Online Product Review Systems via HGT\nTABLE 4. Overall result.\nFIGURE 2. Performance comparison under different layers.\nFIGURE 3. Performance comparison under different embedding Size.\nthe two-layer model can achieve better classiﬁcation per-\nformance with reduced training complexity. Fig. 3 presents\nFAHGT’s performance under different embedding sizes.\nWith larger embedding sizes, the regularization constraints\non model parameters are slightly stronger and we do not\nﬁnd signiﬁcant differences in terms of classiﬁcation metrics.\nFig. 4 demonstrates the performance of FAHGT under differ-\nent training fractions. The increasing training fraction of data\nshow little improvement in performance, which is consistent\nwith observation in [5].\nD. DISCUSSION\nFrom Fig. 5, we can see that the training process of FAHGT\ntakes only 4 seconds per epoch on average for each dataset,\nwith an effective performance gain and comparable efﬁciency\ncomparing to other baselines. The computational efﬁciency\nof FAHGT comes from the carefully designed scoring mecha-\nnism, which computes neighbor ﬁltering and relation weight-\ning in a parallelized manner.\nWe also provide details of model prediction via plotting\nROC and KS curves. Fig. 6 shows ROC curves of FAHGT\n167370 VOLUME 9, 2021\nS. Tanget al.: Fraud Detection in Online Product Review Systems via HGT\nFIGURE 4. Performance comparison under different training fraction.\nFIGURE 5. Training time per epoch for each model.\nFIGURE 6. ROC-AUC curve on three datasets.\non different dataset. All the curves indicate that FAHGT\ncan maintain stable performance for fraudster detection.\nFig. 7a–7c report the KS curves of FAHGT on three datasets.\nThose ﬁgures demonstrate the power of our models of distin-\nguishing suspicious users from benign users.\nVI. CONCLUSION\nWe present FAHGT, a novel heterogeneous graph neural\nnetwork for fraudulent user detection in online review sys-\ntems. To handle inconsistent features, we adopt heteroge-\nneous mutual attention for automatic meta path construction.\nVOLUME 9, 2021 167371\nS. Tanget al.: Fraud Detection in Online Product Review Systems via HGT\nFIGURE 7. KS curve on three datasets.\nTo detect camouﬂage behaviors, we design the label aware\nscoring to ﬁlter noisy neighbors. Two neural modules are\ncombined in a uniﬁed manner called ‘‘score head mecha-\nnism’’ and both contribute to edge weight computation in\nﬁnal feature aggregation. Experiment results on real-world\nbusiness datasets validate the excellent effect on fraud detec-\ntion of FAHGT. The hyper-parameter sensitivity and visual\nanalysis further show the stability and efﬁciency of our\nmodel. In summary, FAHGT is capable of alleviating incon-\nsistency and discover camouﬂage and thus achieves state-of-\nart performance in most scenarios. In the future, we plan to\nextend our model in handing dynamic graphs data and incor-\nporate fraud detection into other areas, such as robust item\nrecommendation in E-commerce or loan default prediction\nin ﬁnancial services.\nREFERENCES\n[1] V . S. Tseng, J. Ying, C. Huang, Y . Kao, and K. Chen, ‘‘Fraudetector:\nA graph-mining-based framework for fraudulent phone call detection,’’\nin Proc. 21th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining,\nSydney, NSW, Australia, L. Cao, C. Zhang, T. Joachims, G. I. Webb,\nD. D. Margineantu, and G. Williams, Eds., Aug. 2015, pp. 2157–2166, doi:\n10.1145/2783258.2788623.\n[2] J. Wang, R. Wen, C. Wu, Y . Huang, and J. Xion, ‘‘FdGars: Fraudster\ndetection via graph convolutional networks in online app review system,’’\nin Proc. Companion Proc. World Wide Web Conf., May 2019, pp. 310–316.\n[3] A. Li, Z. Qin, R. Liu, Y . Yang, and D. Li, ‘‘Spam review detection with\ngraph convolutional networks,’’ in Proc. 28th ACM Int. Conf. Inf. Knowl.\nManage., Nov. 2019, pp. 2703–2711.\n[4] Z. Liu, Y . Dou, P. S. Yu, Y . Deng, and H. Peng, ‘‘Alleviating the incon-\nsistency problem of applying graph neural network to fraud detection,’’\nin Proc. 43rd Int. ACM SIGIR Conf. Res. Develop. Inf. Retr., Jul. 2020,\npp. 1569–1572.\n[5] Y . Dou, Z. Liu, L. Sun, Y . Deng, H. Peng, and P. S. Yu, ‘‘Enhancing graph\nneural network-based fraud detectors against camouﬂaged fraudsters,’’ in\nProc. 29th ACM Int. Conf. Inf. Knowl. Manage., Oct. 2020, pp. 315–324.\n[6] R. Wen, J. Wang, C. Wu, and J. Xiong, ‘‘ASA: Adversary situation\nawareness via heterogeneous graph convolutional networks,’’ in Proc.\nCompanion Web Conf., Apr. 2020, pp. 674–678.\n[7] Y . Zhang, Y . Fan, Y . Ye, L. Zhao, and C. Shi, ‘‘Key player identiﬁcation\nin underground forums over attributed heterogeneous information network\nembedding framework,’’ in Proc. 28th ACM Int. Conf. Inf. Knowl. Man-\nage., Nov. 2019, pp. 549–558.\n[8] D. Wang, Y . Qi, J. Lin, P. Cui, Q. Jia, Z. Wang, Y . Fang, Q. Yu, J. Zhou, and\nS. Yang, ‘‘A semi-supervised graph attentive network for ﬁnancial fraud\ndetection,’’ in Proc. IEEE Int. Conf. Data Mining (ICDM), Nov. 2019,\npp. 598–607.\n[9] Z. Liu, C. Chen, X. Yang, J. Zhou, X. Li, and L. Song, ‘‘Heterogeneous\ngraph neural networks for malicious account detection,’’ in Proc. 27th ACM\nInt. Conf. Inf. Knowl. Manage., Oct. 2018, pp. 2077–2085.\n[10] Y . Dou, G. Ma, P. S. Yu, and S. Xie, ‘‘Robust spammer detection by Nash\nreinforcement learning,’’ in Proc. 26th ACM SIGKDD Int. Conf. Knowl.\nDiscovery Data Mining, Aug. 2020, pp. 924–933.\n[11] P. Kaghazgaran, M. Alﬁﬁ, and J. Caverlee, ‘‘Wide-ranging review manip-\nulation attacks: Model, empirical study, and countermeasures,’’ in Proc.\n28th ACM Int. Conf. Inf. Knowl. Manage., Nov. 2019, pp. 981–990.\n[12] Z. Zhang, P. Cui, and W. Zhu, ‘‘Deep learning on graphs: A sur-\nvey,’’IEEE Trans. Knowl. Data Eng., early access, Mar. 17, 2020, doi:\n10.1109/TKDE.2020.2981333.\n[13] J. Bruna, W. Zaremba, A. Szlam, and Y . LeCun, ‘‘Spectral networks and\nlocally connected networks on graphs,’’ 2013, arXiv:1312.6203. [Online].\nAvailable: http://arxiv.org/abs/1312.6203\n[14] M. Defferrard, X. Bresson, and P. Vandergheynst, ‘‘Convolutional neu-\nral networks on graphs with fast localized spectral ﬁltering,’’ in Proc.\nNeurIPS, 2016, pp. 3844–3852.\n[15] T. Kipf and M. Welling, ‘‘Semi-supervised classiﬁcation with graph con-\nvolutional networks,’’ in Proc. ICLR, 2017, pp. 1–14.\n[16] W. Hamilton, Z. Ying, and J. Leskovec, ‘‘Inductive representation learning\non large graphs,’’ in Proc. NeurIPS, 2017, pp. 1024–1034.\n[17] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y . Bengio,\n‘‘Graph attention networks,’’ in Proc. ICLR, 2017, pp. 1–12.\n[18] X. Wang, H. Ji, C. Shi, B. Wang, Y . Ye, P. Cui, and P. S. Yu, ‘‘Het-\nerogeneous graph attention network,’’ in Proc. World Wide Web Conf.,\nMay 2019, pp. 2022–2032.\n[19] S. Zhou, J. Bu, X. Wang, J. Chen, and C. Wang, ‘‘HAHE: Hierar-\nchical attentive heterogeneous information network embedding,’’ 2019,\narXiv:1902.01475. [Online]. Available: http://arxiv.org/abs/1902.01475\n[20] S. Wang, Z. Chen, D. Li, Z. Li, L.-A. Tang, J. Ni, J. Rhee, H. Chen,\nand P. S. Yu, ‘‘Attentional heterogeneous graph neural network: Applica-\ntion to program reidentiﬁcation,’’ in Proc. SIAM Int. Conf. Data Mining.\nPhiladelphia, PA, USA: SIAM, 2019, pp. 693–701.\n[21] Y . Zhang, Y . Xiong, X. Kong, S. Li, J. Mi, and Y . Zhu, ‘‘Deep collective\nclassiﬁcation in heterogeneous information networks,’’ in Proc. World\nWide Web Conf. World Wide Web (WWW), 2018, pp. 399–408.\n[22] C. Zhang, D. Song, C. Huang, A. Swami, and N. V . Chawla, ‘‘Heteroge-\nneous graph neural network,’’ in Proc. KDD, 2019, pp. 793–803.\n[23] Z. Hu, Y . Dong, K. Wang, and Y . Sun, ‘‘Heterogeneous graph transformer,’’\nin Proc. Web Conf., Apr. 2020, pp. 2704–2710.\n[24] G. Wang, S. Xie, B. Liu, and P. S. Yu, ‘‘Review graph based online store\nreview spammer detection,’’ in Proc. IEEE 11th Int. Conf. Data Mining,\nDec. 2011, pp. 1242–1247.\n[25] W. Yu, W. Cheng, C. C. Aggarwal, K. Zhang, H. Chen, and W. Wang,\n‘‘NetWalk: A ﬂexible deep embedding approach for anomaly detection\nin dynamic networks,’’ in Proc. 24th ACM SIGKDD Int. Conf. Knowl.\nDiscovery Data Mining, Jul. 2018, pp. 2672–2681.\n[26] S. Kumar, B. Hooi, D. Makhija, M. Kumar, C. Faloutsos, and\nV . S. Subrahmanian, ‘‘REV2: Fraudulent user prediction in rating plat-\nforms,’’ in Proc. 11th ACM Int. Conf. Web Search Data Mining, Feb. 2018,\npp. 333–341.\n[27] Z. Liu, C. Chen, L. Li, J. Zhou, X. Li, L. Song, and Y . Qi, ‘‘GeniePath:\nGraph neural networks with adaptive receptive paths,’’ in Proc. AAAI,\n2019, pp. 4424–4431.\n[28] S. X. Rao, S. Zhang, Z. Han, Z. Zhang, W. Min, Z. Chen, Y . Shan,\nY . Zhao, and C. Zhang, ‘‘xFraud: Explainable fraud transaction detection\non heterogeneous graphs,’’ CoRR, vol. abs/2011.12193, 2020. [Online].\nAvailable: https://arxiv.org/abs/2011.12193\n[29] H. Chen, Y . Xu, F. Huang, Z. Deng, W. Huang, S. Wang, P. He,\nand Z. Li, ‘‘Label aware graph convolutional network–not all edges\ndeserve your attention,’’ 2019, arXiv:1907.04707. [Online]. Available:\nhttp://arxiv.org/abs/1907.04707\n167372 VOLUME 9, 2021\nS. Tanget al.: Fraud Detection in Online Product Review Systems via HGT\n[30] J. J. McAuley and J. Leskovec, ‘‘From amateurs to connoisseurs: Modeling\nthe evolution of user expertise through online reviews,’’ in Proc. 22nd Int.\nConf. World Wide Web (WWW), 2013, pp. 897–908.\n[31] S. Zhang, H. Yin, T. Chen, Q. V . N. Hung, Z. Huang, and L. Cui, ‘‘GCN-\nbased user representation learning for unifying robust recommendation and\nfraudster detection,’’ inProc. 43rd Int. ACM SIGIR Conf. Res. Develop. Inf.\nRetr., Jul. 2020, pp. 689–698.\n[32] S. Rayana and L. Akoglu, ‘‘Collective opinion spam detection: Bridging\nreview networks and metadata,’’ in Proc. 21th ACM SIGKDD Int. Conf.\nKnowl. Discovery Data Mining, Aug. 2015, pp. 985–994.\nSONGKAI TANG (Graduate Student Member,\nIEEE) was born in Hunan, China, in 1998.\nHe received the B.S. degree from Shanghai Jiao\nTong University, Shanghai, China, in 2019, where\nhe is currently pursuing the M.S. degree in com-\nputer science and technology.\nIn 2018, he was a Data Engineer Intern with\nthe Computing Advertising Department, CooTek,\nShanghai. From 2019 to 2020, he was an Algo-\nrithm Engineer Intern with the Anti-Fraud Depart-\nment, 360 DigiTech Inc., Shanghai. His research interests include graph\nneural networks, fraud detection, and recommender systems.\nLUHUA JIN (Graduate Student Member, IEEE)\nwas born in Shanghai, China, in 1996. He received\nthe B.S. degree from Shanghai Jiao Tong Uni-\nversity, Shanghai, in 2019, where he is currently\npursuing the M.S. degree in computer technology.\nFrom 2019 to 2020, he was an Intern with\nthe Algorithm Department, 360 DigiTech Inc.,\nShanghai. His research interests include natural\nlanguage processing, tabular data processing, and\nnormalization theory.\nFAN CHENG(Member, IEEE) received the bach-\nelor’s degree in computer science and engineering\nfrom Shanghai Jiao Tong University, in 2007, and\nthe Ph.D. degree in information engineering from\nThe Chinese University of Hong Kong, in 2012.\nFrom 2012 to 2014, he was a Postdoctoral Fellow\nwith the Institute of Network Coding, The Chinese\nUniversity of Hong Kong. Since 2015, he has been\na Research Fellow with the Department of Electri-\ncal and Computer Engineering, NUS, Singapore.\nHe is currently an Associate Professor with the Department of Computer\nScience and Engineering, Shanghai Jiao Tong University.\nVOLUME 9, 2021 167373"
}