{
  "title": "Adapting transformer-based language models for heart disease detection and risk factors extraction",
  "url": "https://openalex.org/W4393932132",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2550542798",
      "name": "Essam H. Houssein",
      "affiliations": [
        "Minia University"
      ]
    },
    {
      "id": "https://openalex.org/A3205841765",
      "name": "Rehab E. Mohamed",
      "affiliations": [
        "Minia University"
      ]
    },
    {
      "id": "https://openalex.org/A1998986688",
      "name": "Gang Hu",
      "affiliations": [
        "Xi'an University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2098303552",
      "name": "Abdelmgeid A. Ali",
      "affiliations": [
        "Minia University"
      ]
    },
    {
      "id": "https://openalex.org/A2550542798",
      "name": "Essam H. Houssein",
      "affiliations": [
        "Minia University"
      ]
    },
    {
      "id": "https://openalex.org/A3205841765",
      "name": "Rehab E. Mohamed",
      "affiliations": [
        "Minia University"
      ]
    },
    {
      "id": "https://openalex.org/A1998986688",
      "name": "Gang Hu",
      "affiliations": [
        "Xi'an University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2098303552",
      "name": "Abdelmgeid A. Ali",
      "affiliations": [
        "Minia University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2913705661",
    "https://openalex.org/W2899736836",
    "https://openalex.org/W3025578374",
    "https://openalex.org/W2768092558",
    "https://openalex.org/W4214644841",
    "https://openalex.org/W2139521168",
    "https://openalex.org/W2885828205",
    "https://openalex.org/W3177034450",
    "https://openalex.org/W2114388055",
    "https://openalex.org/W2547728652",
    "https://openalex.org/W2124972954",
    "https://openalex.org/W2168924589",
    "https://openalex.org/W2151477381",
    "https://openalex.org/W2972984751",
    "https://openalex.org/W4226269719",
    "https://openalex.org/W3198196226",
    "https://openalex.org/W2165698076",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2963626623",
    "https://openalex.org/W2396881363",
    "https://openalex.org/W2944400536",
    "https://openalex.org/W1019512417",
    "https://openalex.org/W283797413",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W2963716420",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W833343209",
    "https://openalex.org/W1964625659",
    "https://openalex.org/W1081873870",
    "https://openalex.org/W1451372127",
    "https://openalex.org/W2187005605",
    "https://openalex.org/W1126062418",
    "https://openalex.org/W2159636537",
    "https://openalex.org/W2133990480",
    "https://openalex.org/W2153635508",
    "https://openalex.org/W2123442489",
    "https://openalex.org/W3004227146",
    "https://openalex.org/W3048989076",
    "https://openalex.org/W3124523525",
    "https://openalex.org/W3122886537",
    "https://openalex.org/W2889877784",
    "https://openalex.org/W3003943678",
    "https://openalex.org/W2939470209",
    "https://openalex.org/W3007060302",
    "https://openalex.org/W2963354094",
    "https://openalex.org/W2114039834",
    "https://openalex.org/W2971668428",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W3035375600",
    "https://openalex.org/W3034328552",
    "https://openalex.org/W3105063288",
    "https://openalex.org/W2985884876",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W6800751262",
    "https://openalex.org/W2971258845",
    "https://openalex.org/W2970771982",
    "https://openalex.org/W3100452049",
    "https://openalex.org/W2893364991",
    "https://openalex.org/W1656216251",
    "https://openalex.org/W942379102",
    "https://openalex.org/W1737136247",
    "https://openalex.org/W3111112601",
    "https://openalex.org/W3035204084",
    "https://openalex.org/W4241818541",
    "https://openalex.org/W2912042784",
    "https://openalex.org/W1034019924"
  ],
  "abstract": "Abstract Efficiently treating cardiac patients before the onset of a heart attack relies on the precise prediction of heart disease. Identifying and detecting the risk factors for heart disease such as diabetes mellitus, Coronary Artery Disease (CAD), hyperlipidemia, hypertension, smoking, familial CAD history, obesity, and medications is critical for developing effective preventative and management measures. Although Electronic Health Records (EHRs) have emerged as valuable resources for identifying these risk factors, their unstructured format poses challenges for cardiologists in retrieving relevant information. This research proposed employing transfer learning techniques to automatically extract heart disease risk factors from EHRs. Leveraging transfer learning, a deep learning technique has demonstrated a significant performance in various clinical natural language processing (NLP) applications, particularly in heart disease risk prediction. This study explored the application of transformer-based language models, specifically utilizing pre-trained architectures like BERT (Bidirectional Encoder Representations from Transformers), RoBERTa, BioClinicalBERT, XLNet, and BioBERT for heart disease detection and extraction of related risk factors from clinical notes, using the i2b2 dataset. These transformer models are pre-trained on an extensive corpus of medical literature and clinical records to gain a deep understanding of contextualized language representations. Adapted models are then fine-tuned using annotated datasets specific to heart disease, such as the i2b2 dataset, enabling them to learn patterns and relationships within the domain. These models have demonstrated superior performance in extracting semantic information from EHRs, automating high-performance heart disease risk factor identification, and performing downstream NLP tasks within the clinical domain. This study proposed fine-tuned five widely used transformer-based models, namely BERT, RoBERTa, BioClinicalBERT, XLNet, and BioBERT, using the 2014 i2b2 clinical NLP challenge dataset. The fine-tuned models surpass conventional approaches in predicting the presence of heart disease risk factors with impressive accuracy. The RoBERTa model has achieved the highest performance, with micro F1-scores of 94.27%, while the BERT, BioClinicalBERT, XLNet, and BioBERT models have provided competitive performances with micro F1-scores of 93.73%, 94.03%, 93.97%, and 93.99%, respectively. Finally, a simple ensemble of the five transformer-based models has been proposed, which outperformed the most existing methods in heart disease risk fan, achieving a micro F1-Score of 94.26%. This study demonstrated the efficacy of transfer learning using transformer-based models in enhancing risk prediction and facilitating early intervention for heart disease prevention.",
  "full_text": "Adapting transformer‑based language \nmodels for heart disease detection and risk \nfactors extraction\nEssam H. Houssein1*, Rehab E. Mohamed1, Gang Hu2 and Abdelmgeid A. Ali1 \nAbstract \nEfficiently treating cardiac patients before the onset of a heart attack relies on the pre-\ncise prediction of heart disease. Identifying and detecting the risk factors for heart \ndisease such as diabetes mellitus, Coronary Artery Disease (CAD), hyperlipidemia, \nhypertension, smoking, familial CAD history, obesity, and medications is critical \nfor developing effective preventative and management measures. Although Elec-\ntronic Health Records (EHRs) have emerged as valuable resources for identifying these \nrisk factors, their unstructured format poses challenges for cardiologists in retrieving \nrelevant information. This research proposed employing transfer learning techniques \nto automatically extract heart disease risk factors from EHRs. Leveraging transfer learn-\ning, a deep learning technique has demonstrated a significant performance in various \nclinical natural language processing (NLP) applications, particularly in heart disease risk \nprediction. This study explored the application of transformer-based language models, \nspecifically utilizing pre-trained architectures like BERT (Bidirectional Encoder Represen-\ntations from Transformers), RoBERTa, BioClinicalBERT, XLNet, and BioBERT for heart dis-\nease detection and extraction of related risk factors from clinical notes, using the i2b2 \ndataset. These transformer models are pre-trained on an extensive corpus of medical \nliterature and clinical records to gain a deep understanding of contextualized language \nrepresentations. Adapted models are then fine-tuned using annotated datasets specific \nto heart disease, such as the i2b2 dataset, enabling them to learn patterns and rela-\ntionships within the domain. These models have demonstrated superior performance \nin extracting semantic information from EHRs, automating high-performance heart dis-\nease risk factor identification, and performing downstream NLP tasks within the clinical \ndomain. This study proposed fine-tuned five widely used transformer-based models, \nnamely BERT, RoBERTa, BioClinicalBERT, XLNet, and BioBERT, using the 2014 i2b2 clini-\ncal NLP challenge dataset. The fine-tuned models surpass conventional approaches \nin predicting the presence of heart disease risk factors with impressive accuracy. The \nRoBERTa model has achieved the highest performance, with micro F1-scores of 94.27%, \nwhile the BERT, BioClinicalBERT, XLNet, and BioBERT models have provided competi-\ntive performances with micro F1-scores of 93.73%, 94.03%, 93.97%, and 93.99%, \nrespectively. Finally, a simple ensemble of the five transformer-based models has been \nproposed, which outperformed the most existing methods in heart disease risk fan, \nachieving a micro F1-Score of 94.26%. This study demonstrated the efficacy of transfer \nOpen Access\n© The Author(s) 2024. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits \nuse, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original \nauthor(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third \nparty material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the mate-\nrial. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// \ncreat iveco mmons. org/ licen ses/ by/4. 0/.\nRESEARCH\nHoussein et al. Journal of Big Data           (2024) 11:47  \nhttps://doi.org/10.1186/s40537‑024‑00903‑y\nJournal of Big Data\n*Correspondence:   \nessam.halim@mu.edu.eg\n1 Faculty of Computers \nand Information, Minia \nUniversity, Minia, Egypt\n2 Department of Applied \nMathematics, Xi’an University \nof Technology, Xi’an 710054, \nChina\nPage 2 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \nIntroduction\nHeart disease, chronic respiratory disease, and diabetes are among the many non-com -\nmunicable diseases associated with the modern lifestyle. One of the highest death rates \nis caused by heart disease [1]. Heart disease is a term used to describe abnormalities of \nthe heart. It is regarded as one of the world’s most powerful killers, surpassing Alzhei -\nmer’s and cancer in power. The prevention of heart disease has become a serious issue \nin today’s world that needs to be addressed. It is estimated that one American dies of \nheart disease every 30 s [2]. Each year, 647,000 Americans suffer from heart disease [3]. \nApproximately 17.8 million deaths were caused by heart disease worldwide in 2017, an \nincrease of 21.2% compared to 2007 [4]. In addition, heart disease can increase the need \nfor hospital treatment by acting as a risk factor for other diseases. For example, they \nhave been associated with a poor prognosis in the setting of COVID-19, threatening the \nability of healthcare systems around the world [5]. Half of those who have a heart attack \nare not ’at risk’ . These concerns require automatic prediction of heart disease and earlier \nidentification, which is a critical issue. It is essential to prevent this life-threatening dis -\nease before it leads to millions of deaths. It is important to identify various risk factors \nto diagnose and prevent this disease earlier, such as Coronary Artery Disease (CAD), \nDiabetes, Hypertension, Hyperlipidemia, Smoking, Medications, Family history of CAD, \nand Obesity [6–9].\nAll other heart risk factors must be identified with indicators and temporal features, \nexcept CAD in the family and smoking status. Each characteristic of the indicator indi -\ncates the clinical significance of the risk factor. A significant difficulty in the field of heart \ndisease detection and prevention is the identification of risk factors reported in clinical \nnotes.\nThat means it is a difficult problem in clinical data analysis to create a fully automated \nmethod to predict heart disease from EHR [10, 11]. Natural language used in clinical \nnarratives stored in EHRs is sometimes described as idiosyncratic, with considerable \nvariability in format and quality [12]. Structured data are commonly created for admin -\nistrative purposes only in electronic health records, so the data are biased toward diag -\nnoses and procedures that are relevant to billing purposes. Unstructured clinical notes \nare the most in-depth source of data, but semantic labeling is not common because it \nrequires advanced planning and analysis [13]. Although unstructured data has numer -\nous uses, there is a growing need to unlock them for primary and secondary purposes \n[14]. Secondary use of such data can include supporting observational studies, such as \ncohorts, cross-sections, and case–control research [15]. By developing systems for ana -\nlyzing narrative clinical notes to register patients according to selection criteria, sam -\npling bias could be reduced [16]. Using NLP techniques, we can convert the meaning of \nhuman language into machine-readable representations that can be used for secondary \npurposes. NLP models from the general domain cannot be easily applied to clinical text \nlearning using transformer-based models in enhancing risk prediction and facilitating \nearly intervention for heart disease prevention.\nKeywords: Coronary artery disease, Electronic health records, Natural language \nprocessing, Bidirectional encoder representations from transformers, Heart disease, \nTransformer-based models\nPage 3 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \ndue to significant linguistic differences since it is likely to be simple terms, often referred \nto as the telegraphic style. Developing these systems for the clinical field is challenging \nbecause there are few publicly accessible annotated clinical narrative datasets. During \nthe big data revolution, neural networks (NNs) were trained to model a variety of human \nlanguages with high accuracy as a result of the availability of large amounts of data in the \ngeneral domain, but there has not been the same in small data scenarios, where models \nare often trained from scratch. Consequently, transfer learning methods have become \nincreasingly popular, allowing previously trained models to be applied in new contexts \nwith minimal annotation and labeling [17].\nTransfer learning is a deep learning technique that refers to the process of adapting \na model originally pre-trained for a specific task and is used as a basis for training a \nmodel to perform a different task using a new dataset [18, 19]. Although transfer learn -\ning has received much research in the field of medical image analysis, its application to \ntext-clinical data is still lacking. Therefore, this scoping study aimed to investigate the \nfeasibility of applying transfer learning to non-image data in the clinical text. Many of \nthe most recent advances in generalizable and adaptable techniques are based on trans -\nfer learning. When data is scarce, knowledge of fields, tasks, or languages with large data \nis applied [20]. Several clinical studies highlighted the potential of transfer learning to \nreuse models in a wide range of prediction tasks, data types, and even species. Trans -\nfer learning was apparent to be particularly effective when applied to smaller datasets, \nrather than when machine learning algorithms were trained from scratch in terms of \nprediction [18].\nDifferent methods can be used to transfer knowledge from a large dataset depending \non the availability of the data source, task labels, and reused data [21]. Feature repre -\nsentation transfer is one of the most common methods in which an input representa -\ntion strategy that is trained unsupervised on a large dataset is transferred to a smaller \nannotated sample [21]. However, Goodfellow et al. [22] suggest that the application of \nthis strategy has decreased since deep learning provides human intervention with large \nlabeled datasets, while Bayesian methods perform better when small data are available. \nMikolov et al. [23] promoted feature representation transfer in the NLP area, by releas -\ning word2vec embeddings trained on approximately 100 billion words extracted from a \nGoogle News corpus. However, this model has a low coverage rate for clinical text due \nto uncommon words and misspellings, prompting the search for other input representa-\ntion strategies [24]. Bojanowski et al. The [25] suggested including sub-word informa -\ntion in word vectors to accommodate morphology. Although deep learning has become \ncommon for text classification, Joulin et  al. [26] have developed fastText, a quick and \naccurate application of multinomial logistic regression that makes text classification on \na large scale possible. More recently, the National Center for Biotechnology Information \ndeveloped BioWordVec, which was trained using fastText on more than 30 million docu-\nments from the MIMIC-III (Medical Information Mart for Intensive Care) [27] and the \nPubMed clinical dataset. When combined, these tools can facilitate the transfer of learn-\ning from the large data domain to the clinical field by addressing the unique challenges \nposed by clinical settings [28, 29].\nMotivation There is promise in the detection of heart disease risk factors using \ntransformer-based models based on transfer learning approaches to learn bidirectional \nPage 4 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \nrelationships in EHR. We proposed a heart disease risk factor identification model by \ncomparing five transformer-based models using EHR data. We modeled the task as \nNER task according to [30, 31]. The study uses several statistical criteria and evaluation \nmeasurements to support these findings. The evaluation included measures of precision, \nrecall, and F1 at the micro-level when comparing the results of the fine-tuned trans -\nformer-based models to the document-level gold standard. The primary contributions of \nthis paper can be summarized as follows: \n1. Developing a model that identifies heart disease risk factors in EHRs using transfer \nlearning models.\n2. In this study, we explored transfer learning using openly available biomedical contex-\ntual embeddings.\n3. Implement a transfer learning technique that could effectively use these embeddings \nto identify risk factors for heart disease.\n4. The fine-tuned transformer-based models outperformed the 2014 i2b2/UTHealth \nshared task systems and models.\n5. In this study, we applied five transformer-based models, which are contextual \nembeddings of BERT [32], BioBERT [33], BioClinicalBERT [34], RoBERTa [35], and \nXLNet [36] contextual embeddings.\n6. Ensembling strategies help improve the performance of all eight risk factors extrac -\ntion challenging.\nThe remaining sections of the paper are structured as follows, Section \"Related work\", \nprovides a literature review of several recent related works on the 2014 i2b2UTHealth \nshared task track 2 and adaptation of transfer learning in clinical EHR. Section \"Mate -\nrials and methods \", demonstrates the objectives of the proposed task, the description \nof the dataset, the description of the research problem, the pre-processing steps, the \ntransfer learning models, and the transformer-based models. Pre-training and fine-tun -\ning process. Section \"Experimental results and simulations \", shows the evaluation and \nresults of the proposed study. Finally, the conclusion and future works are discussed in \nSection \"Conclusion and future work\".\nRelated work\nThe proposed study is motivated by the challenges of the 2014 i2b2/UTHealth heart \ndisease risk factor detection task, as well as some previous Information Extraction (IE) \nresearch in the clinical domain with the adaptation of transfer learning techniques.\nTrack 2 of the 2014 i2b2/UTHealth shared task\nThe National Center (https://www.i2b2.org/) for Biomedical Computing has organized \nthe Informatics for Integrating Biology and Bedside (i2b2) (https:// www. i2b2. org/) Chal-\nlenges since 2006 to encourage NLP study in the health domain. Track 2 of the 2014 \ni2b2/UTHealth shared task proposed the challenge of text classification in the clinical \ndomain with limited data and requested the participating teams to categorize patients \nbased on eight risk factors for heart disease: CAD, diabetes, hypertension, hyperlipi -\ndemia, obesity, smoking, medications, and family history.\nPage 5 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \nThe teams investigated a wide range of approaches, from rule-based to hybrid, using \na wide variety of feature combinations and machine learning methods [30]. Participants \ncould not clearly agree on the optimal approach to the challenging task because so many \ndifferent hybrid systems were proposed. Most teams had discovered a challenging issue \nwith the encoded pseudo-tables and heart disease risk indicators in clinical notes, which \nled to low F1 scores. Using SVM models based on custom-built lexica, the best team \nparticipating in 2014 achieved an F1-score of 0.9276 after reannotating a large portion of \nthe training corpus [37].\nA preprocessing step was performed to extract headings from sections, negation \nmarkers, modalities, and other output using the ConText tool [38], but no other syntac -\ntic or semantic signals were used. They demonstrated that other automated systems can \nbe improved with fine-grained annotations.\nKotfila and Uzuner [39] investigated the effectiveness of SVM classifiers trained on the \nshared dataset by comparing the size of training data, features, weighting schemes, and \nkernels.\nThe authors indicated that limited feature spaces with lowercase alphabetic tokens \nwere equivalent to combinations of lexically normalized tokens and extracted seman -\ntic concepts using MetaMap [40], and linear kernels were not significantly less effective \nthan radial kernels.\nFurthermore, they demonstrated that the use of SVM models may not require large \ncorpora to achieve high efficiency.\nChen et al. [41] developed a hybrid pipeline system with three modules for tag extrac -\ntion to extract tags based on phrases, logic, and discourse, as well as a module for identi -\nfying time attributes with temporal indicators using SVM.\nThe system achieved significant efficiency among Information Extraction (IE) sys -\ntems that do not require more annotations by treating phrase-based tagging as a Name \nEntity Recognition (NER) task and identifying time attributes as a temporal relationship \nextraction task.\nIn addition, Urbain [42] has used various techniques such as conditional random \nfields (CRFs) to identify risk factors, regular expressions to identify time attributes, and \na semantic distribution model to classify specific risk factors. Torii et al. [43] have devel -\noped three classifiers for various identifications: a general classifier, a smoking status \nclassifier, and a sequence labeling-based classifier, using hot-spot features (phrases anno-\ntated as risk factor evidence) in conjunction with several open machine learning tools \nsuch as MedEx [44], Weka [45], LibSVM [46] and Stanford NER [47].\nRelated work in transfer learning and domain adaptation for NLP of EHRs\nSeveral studies have proposed applications that applied text-based transfer learn -\ning. These applications have proposed the prediction of morbidity, mortality, and \nadverse events from oncological radiation [48– 50], and the assessment of the risk of \npsychological stressors, diseases, and drug abuse [51– 54]. Transfer learning methods \nhave been applied to the clinical domain by sequentially training several tasks. The \nresearchers pre-trained a convolutional neural network (CNN) in PubMed-indexed \nbiomedical articles to identify medical subject headings and then transferred this \nmodel to predict International Classification of Diseases (ICD) codes in EHRs [55]. \nPage 6 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \nA similar approach uses unlabeled data from three institutions and applies self-train -\ning and transfer learning to classify radiological reports using a small labeled data set \n[56]. Pre-trained word embeddings are commonly transferred to downstream tasks, \nsuch as applying medical embeddings to NER in the clinical domain [57]. Embed -\ndings have been trained in both the general and clinical domains, and as a result, \nmany methods have been developed to adapt embeddings, such as concatenation and \nfine-tuning [58]. Another proposed method pre-trained embeddings on the relation \nextraction task of the 2009 i2b2 challenge [59] and then transferred them to NNs for \nthe extraction of clinical terms in the shared dataset [60].\nPre-trained transformers methods Transfer learning with transformer-based \nmodels has become a standard approach in NLP due to its effectiveness and effi -\nciency in leveraging pre-existing knowledge for various downstream tasks. Recently, \ntransformer architectures [33] (e.g., BERT) applying self-attention mechanisms [61] \nhave achieved the best results on many NLP tasks [62, 63]. A transformer-based \nNLP model has achieved significant performance in several areas, such as NER [64, \n65], relation extraction [66, 67], sentence similarity [68, 69], natural language infer -\nence [69, 70], and question answering [69, 71–73]. Transformer training involves two \nphases: (1) pretraining, where the language model is learned based on self-supervised \ntraining on a large unlabeled dataset; and (2) fine-tuning when the pre-trained model \nis applied to labeled training data to address specific tasks. Fine-tuning is the pro -\ncess of applying a pre-trained language model to address several NLP tasks, which is \nknown as transfer learning. Transfer learning is a technique for transferring knowl -\nedge from one task to another [74]. The sample space for human language is enor -\nmous; there are an infinite number of possible permutations of tokens, sentences, and \ntheir grammar and meaning. According to recent studies, the emergence and homog -\nenization of large transformer models trained on large text data have been signifi -\ncantly superior to previous NLP models [74].\nBiomedical models based on BERT include BioBERT [33], BlueBERT [75], and Clin -\nicalBERT [34]. These models use a continuous pretraining method, initializing the \nmodel weights using weights from BERT pre-trained on Book Corpus and Wikipe -\ndia while using the same vocabulary. Pre-training from scratch using domain-specific \ncorpora and vocabulary improves the performance of models SciBERT [76], PubMed -\nBERT [77], and Biolm [78].\nThe BERT model has been applied to the scientific, clinical, and biomedical \ndomains. BERT is pre-trained in PubMed and PubMed Central articles in BioBERT \n[33]. In BlueBERT [75], BERT is pre-trained on PubMed, PMC, and MIMIC III data \n[27]. ClinicalBERT [34] is pre-trained in MIMIC III data using BioBERT weights, \nwhile SciBERT [76], PubMedBERT [77] and Bio-lm [78] train BERT with domain-\nspecific data. SciBERT pre-trained on Semantic Scholar data. PubMed and PMC data \nare used to pretrain PubMedBERT. PubMed, PMC, and MIMIC III are used to pre-\ntrain Bio-lm data [78]. BlueBERT and PubMedBERT have launched benchmarks for \nbiomedical NLP-BLUE (Biomedical Language Understanding Evaluation) and BLURB \n(Biomedical Language Understanding & Reasoning Benchmark). Table  1 summarizes \nthe state-of-the-art transformer-based models with their pre-trained dataset and \ntraining weights.\nPage 7 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \nMaterials and methods\nObjective task\nWe proposed a high-performance heart disease risk factor identification model, so we \nturned to open source NLP frameworks as part of our work to bring together clinical \ndecision support functionalities and note taking interfaces. We modeled the task as a \nNER task according to [30, 31] and explored transfer learning using openly available \nbiomedical contextual embeddings. Our main objective was to get a transfer learning \nprocess working with these embeddings. The context in which this is performed is as \nfollows: \n1. In this study, we examined transfer learning models that employed BERT [32], \nBioBERT[33], BioClinicalBERT [34], RoBERTa [35], and XLNet [36] contextual \nembeddings pre-trained on PubMed abstracts [79] which are the best deep language \nmodels that based on encoder-decoder transformer architectures  [61] and have been \npre-trained on massive unstructured text datasets.\n2. Our research examines embedding-specific methods in order to improve perfor -\nmance, including language-model finetuning, scalar mix, and aggregation of subword \ntokens.\n3. We develop a model for the identification of heart disease risk factors based on the \nperformance of transfer learning models. Risk factors can be extracted more effec -\ntively with sentence enhancement at prediction time. Furthermore, it allows for a \nbetter understanding of the behavior of the embeddings. Ensembling strategies helps \nimprove the performance of all eight risk factors that make extraction challenging.\nHypothesis\nWe proposed that transfer learning methods are deep learning methods using a pre-\ntraining/fine-tuning learning architecture. Transfer learning methods have superior \nperformance for heart disease risk factors prediction, and pre-trained embeddings can \nenhance classification efficiency in the clinical domain.\nWe proposed systematically investigating five widely used transformer-based models, \nincluding BERT, BioBERT, BioClinicalBERT, RoBERTa, and XLNet, to develop a model \nfor the detection of heart disease risk factors that can identify diseases, risk factors, \nmedications, and the time of occurrence.\nTable 1 The recent pre-trained transformers models\nModel Pre-trained dataset The training weights References\nBERT model Book Corpus Wikipedia – [33]\nBioBERT model PubMed PubMed Central articles BERT weights [33]\nBlueBERT model PubMed PMC MIMIC III data BERT weights [75]\nClinicalBERT model MIMIC III data BioBERT weights [34]\nSciBERT model Semantic Scholar data BERT weights [76]\nPubMedBERT model PubMed PMC data BERT weights [77]\nBio-lm model PMC PubMed MIMIC III BERT weights [78]\nPage 8 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \nDataset\nThe proposed model uses a data set provided by Partners HealthCare [http:// www. partn \ners. orghttps:// www. i2b2. org/ NLP/ Heart Disea se/], which includes clinical notes and \ndischarge summaries. The shared task dataset includes 1304 patient records that iden -\ntify 296 diabetics with heart disease risk factors and temporal attributes based on DCT. \nAccording to the challenge provider, the dataset is divided into a training set with 60% of \nthe records (790 records) and a test set with 40% of the records (514 records). The organ-\nizers of the i2b2 NLP shared task provided two annotated datasets, namely SET1 and \nSET2, for development and training purposes. SET1 contained 521 de-identified clinical \nnotes, while SET2 consisted of 269 de-identified notes. Therefore, a combined total of \n790 documents were accessible for training. The test set consisted of 514 de-identified \nclinical notes. The document annotation guidelines for annotating data can be used to \nidentify the presence of diseases (including CAD, diabetes, and heart disease), eight rele-\nvant evidence risk factors (including hyperlipidemia, hypertension, obesity, smoking sta-\ntus, and family history), and associated medications. There are a number of indicators to \ndetermine whether there is a disease or risk factor in the patient at the time of the DCT \n(before, during, or after). Table  2 provides a summary of the tag types and their cor -\nresponding attribute values provided in the challenge data. There were two versions of \nthe data released by the challenge organizers: complete and gold. Each clinical record in \nthe Gold version is presented in XML format, and XML tags are used to annotate target \nconcepts that are mentioned anywhere in the record (such as <DIABETES time=’’before \nDCT’ indicator=’’mention’ >) if they are present. Additionally, the complete version \nincludes evidence annotations made by three clinicians in the text segments. Therefore, \nin this data set, each concept annotated at the document level is linked to the relevant \ntext segment at the record level to provide evidence of heart disease (e.g., < DIABETES \nstart = ’’4401’ end = ’4422’ text = ’’HbA1c 03/05/2074 6.6’ time = ’during DCT’ indica -\ntor = ’A1C’ >). Figure 1 shows an example of the tag extracted from training data (220–\n05.xml) in both versions, together with its evidence in the text field.\nResearch problem description\nThe research problem identified each type of tag as follows: First, identify the available \nevidence by its type and indicator. Then identify the time attribute (if it exists).\nRisk factor tags can be categorized into three groups by analyzing the evidence of the \ntag based on the terminology used by Chen et al. [30]: \n1. Phrase-based risk factors are identified by detecting relevant phrases in the clinical \nnote, such as ’diabetes’ or the name of a specific drug.\nFig. 1 Example of a sample of the Heart Disease Risk Factor Tags included in the complete and gold versions\nPage 9 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \n2. Logic-based risk factors are based on the analysis of the detected relevant phrase; for \nexample, determining whether or not high blood pressure is a risk factor requires \nlocating a blood pressure measurement and comparing the numbers.\n3. Discourse-based risk factors that require sentence parsing because they are embed -\nded in clinical text fragments, such as the identification of family history or smoking \nstatus.\nAfter classifying all tags into the three groups shown in Table  3, we presented a \nstandard organizing principle for each category. The following Fig.  2 illustrates the \nproposed model modules, which include pre-processing, tag extraction, identifying \ntime attributes, and post-processing. Initially, the preprocessing module detected \nsentence boundaries and tokenized the clinical notes in the raw data file. Then, \nthe tag extraction module identified the type and indicator of the tag in each of the \nthree categories in Table  3. Next, the module for identifying time attributes deter -\nmined whether or not there was evidence for the time attribute. Fine-tuning of the \nTable 2 A summary of the shared task dataset’s risk factor tags\nAnnotation‑level training and testing set sizes, as well as indicators for each heart risk factor\nRisk factor tags Indicator Time\nBefore DCT During DCT After DCT\n(a) Tag: CAD Indicator Mention\nEvent\nSymptom\n260\n224\n54\n261\n20\n24\n259\n2\n3\n(b) Tag: Diabetes indicator Mention\nGlucose\nA1C\n518\n16\n89\n524\n9\n21\n518\n0\n0\n(c) Tag: Hyperlipdemia indicator High LDL\nHigh chol.\nMention\n23\n5\n340\n10\n1\n340\n0\n0\n340\n(d) Tag: Hypertension indicator High bp\nMention\n41\n523\n322\n521\n0\n519\n(e) Tag: Obese indicator DMI\nMention\n3\n133\n15\n147\n2\n133\n(f ) Tag: Medication type (type1) Thienopyridine\nStatin\nThiazolidinedione\nAspirin\nMetformin\nInsulin\nFibrate\nEzetimibe\nDiuretic\nAnti diabetes\nARB\nSulfonylureas\nDPP4 inhibitors\nACE inhibitor\n97\n436\n43\n424\n187\n204\n22\n12\n113\n1\n98\n159\n1\n326\n98\n427\n41\n6\n176\n218\n20\n12\n99\n1\n93\n155\n0\n318\n97\n438\n40\n424\n181\n212\n22\n12\n106\n1\n97\n157\n0\n323\n(g) Tag: Family_history indicator Not present\nPresent\nNA NA 768\n22\n(g) Tag: Smoker status Current\nEver\nNever\nPast\nUnknown\nNA NA 58\n9\n184\n149\n371\nPage 10 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \nproposed transformer-based models. For evaluation, the post-processing module \ntransformed the tags from the complete version to gold version tags.\nPreprocessing\nPreprocessing involves first splitting full-text clinical records into separate sen -\ntences. Using Metamap [40], tokens and sentences from clinical notes were assigned \nto concepts. The next step is to tokenize the sentence and add context-sensitive fea -\ntures to each token and occurrence of the token. Meanwhile, we applied Splitta [80], \nan open-source machine learning model, to split sentences. As soon as a token or \nsentence is mapped to one of the targeted concepts (such as disease or syndrome, \nfamily group, smoke, etc.), its sentence is identified as one of the candidates for fur -\nther processing. The annotation set is processed using Metamap to identify the tar -\nget concepts.\nTable 3 Examples of evidence types for risk factors\nEvidence category Risk factor indicator Example\nPhrase-based indicators - CAD: mention\n- Medication\n- ’Coronary arteriosclerosis’ , ’CAD’ , ’3-vessel coronary \nartery disease’\n- ’Insulin 70/30 HUMAN 70-30’ , ’lisinopril’ , ’Zestril \n(LISINOPRIL)’\nLogic-based indicators - Diabetes: alc\n-Hyperlimidemia: high LDL\n- ’hgba1c 7.3%’ , ’last 1/2137’ hgba1c 7.3%\n- ’Her last LDL was over 100’ , ’Cholesterol-LDL \n12/15/2105 110\nDiscourse-based indicators - CAD: event\n- Smoker: current\n- ’s/p ant SEMI + stent LAD’ , ’s/p ant SEMI + stent LAD \n2/67’ , ’MI in 2092’\n- ’Has smoked 1/2ppd for 35 years, ‘Tobacco abuse’\nFig. 2 The proposed model for heart disease risk factor identification by fine-tuning transformer-based \nmodels\nPage 11 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \nThe proposed model for identifying heart disease risk factors based on transfer learning \nmodels\nThis study aimed to systematically investigate five widely used transformer-based mod -\nels, including BERT, BioClinicalBERT, RoBERTa, BioBERT, and XLNet to detect risk fac-\ntors for heart disease by identifying diseases, risk factors, medications, and the time of \noccurrence. \n1. BERT model was pre-trained by masked language modeling, and then the next sen -\ntence prediction was used to optimize it. The number of transformer layers is 12, \nwith a hidden layer of size 768, and the number of attention heads is 8 in the base \nmodel architecture using 110 million parameters.\n2. RoBERTa model (A Robustly Optimized BERT Pretraining Approach) is a trans -\nformer-based model based on the BERT’s architecture but is pre-trained using a \ndynamic masked language modeling approach and optimized by removing the next \nsentence prediction.\n3. BioClinicalBERT model is based on the BERT architecture but is pre-trained on a \nlarge data set of biomedical and clinical texts, including EHR and biomedical texts. \nThis allows the model to capture the specific language and terminology used in these \ndomains. BioClinicalBERT also incorporates additional inputs, such as segment \nlabels to indicate the source of each token (e.g. medication, diagnosis, test result), \nand position labels to indicate the position of each token within a segment.\n4. BioBERT model was pre-trained on a large corpus of biomedical text, including bio -\nmedical research articles, clinical notes, and EHRs. This pre-training process allows \nthe model to learn the patterns and structures of biomedical language, which can \nthen be fine-tuned for specific downstream tasks, such as NER, text classification, \nand question answering. One of the main advantages of BioBERT is its ability to han-\ndle the complex and domain-specific language used in the biomedical field, which \ncan often be challenging for traditional NLP models. Additionally, BioBERT has \nachieved state-of-the-art performance on several biomedical language processing \nbenchmarks, demonstrating its effectiveness in various tasks.\n5. XLNet model is based on the transformer architecture, which has been used in other \nsuccessful language models such as BERT. However, XLNet introduces a new train -\ning objective called permuted language modeling, which differs from the masked lan-\nguage modeling used in BERT to predict tokens in a randomly permuted sequence of \nthe input.\nFine-tuning the previous models, they can then be trained on the pre-processed \ndata to detect the risk factor for heart disease as shown in Fig.  2. This involves fine-\ntuning the model’s weights to optimize its accuracy. Feature extraction: Once the \nmodel is trained, it can be used to extract meaningful features from new EHRs. By \nanalyzing the text of the records and extracting meaningful features using fine-tuned \ntransformer-based models, the model can predict the risk factor for heart disease \nwith a high degree of accuracy. Validation and Testing: To ensure that the model is \naccurate and generalizable, it is important to validate and test it on diverse datasets. \nThis involves evaluating the model’s performance on a validation dataset and testing \nPage 12 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \nit on a separate test dataset to assess its accuracy and generalizability. Deployment: \nOnce the model is validated and tested, it can be deployed to identify heart disease \nrisk factors from EHRs in real-world settings. This may involve integrating the model \ninto EHR systems or developing a standalone application that can analyze EHR data \nand provide risk assessments to healthcare providers.\nTransformer-based models incorporate two processes, the pre-training process \nand the fine-tuning process. The Pretraining Process: Previous research [33] demon -\nstrated that pretraining on a clinical dataset improved the clinical concept extraction \nefficiency; therefore, we investigated both general models pre-trained with a general \nEnglish data set and clinical models pre-trained with a clinical data set for each of \nthe 5 transformer-based models. We employed state-of-the-art transformer-based \nmodels pre-trained on general English domain datasets, such as bert-base-uncased \n(BERT-general), RoBERTa-base (RoBERTa-general), and XLNet. We used clinical \ntransformer-based models that were pre-trained using the MIMIC-III [27] dataset, \nwhich contains clinical notes, such as BioBERT and BioClinicalBERT.\nThe Fine-tuning Process: To predict heart disease risk factors from clinical con -\ncepts annotated in the training dataset, we built upon transformer-based models pre-\ntrained on the MIMIC data by adding a linear classification layer. It will be necessary \nto optimize the classification layer parameters and the transformer-based models to \nachieve significant results from the extraction of clinical concepts.\nExperimental results and simulations\nIn this section, we describe in detail the weighted-averaged proposed model results \nthat are achieved by the fine-tuned transformer-based models compared to the most \nrecent systems and models from the 2014 i2b2 shared task, as shown in Table 4 .\nTable 4 illustrated a comparison between the fine-tuned transformer-based models’ \nresults and the top-ranked systems [37, 41, 81] which use a hybrid of knowledge-and \nTable 4 The weighted-averaged evaluation results of fine-tuned transformer-based models and the \nmost recent models and systems from 2014 i2b2 shared task\nBold indicates the best value\nModel Precision Recall F1-score Micro \nF1-score \n(Accuracy\nBERT 0.9251 0.9373 0.9284 0.9373\nRoBERTa 0.9390 0.9427 0.9394 0.9427\nBioBERT 0.9337 0.9399 0.9357 0.9399\nBioClinicalBERT 0.9338 0.9403 0.9357 0.9403\nXLNet 0.9361 0.9397 0.9371 0.9397\nRoberts et al. [37] 0.9625 0.8951 0.9276 0.9276\nChen et al. [41] 0.9436 0.9106 0.9268 0.9268\nCormack et al. [82] 0.9375 0.8975 0.9171 0.9171\nYang and Garibaldi [81] 0.9488 0.8847 0.9156 0.9156\nKhalifa and Meystre [83] 0.8951 0.8552 0.8747 0.8747\nChokkwijitkul et al. [10] 0.9180 0.8983 0.9081 0.9081\nPage 13 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \ndata-driven techniques, and systems [10, 82, 83] that only use knowledge-driven tech -\nniques, such as lexicon and rule-based classifiers.\nEvaluation metrics\nThe performance of the proposed model using transformer-based models was evaluated \nbased on the evaluation script provided by the shared task organizers. We used recall, \nprecision, and the F1-measure as primary measurements. Both macro and micro-aver -\nages are included in the overall averages. Micro-averages are provided for each class \nindicator pair [The official evaluation script: https:// github. com/ kotfic/ i2b2_ evalu ation_ \nscrip ts].\nResults and discussion\nWe applied transfer learning to develop a model that detects risk factors for heart dis -\nease from clinical texts over time using the 2014 i2b2 clinical NLP challenge dataset. \nThe most recent models chosen for fine-tuning in the classification task included five \ntransformer-based models: BERT, BioBERT, RoBERTa, BioClinicalBERT, and XLNet. \nOur objective was to identify diseases, risk factors, medications, and time factors based \non DCT. First, the proposed transformer-based models retrieved these risk indicators \nand then determined their temporal attributes.\nData augmentation is applied to the i2b2 dataset for heart disease risk factor detection \nfrom EHR by generating variations of the existing data to increase the size of the train -\ning set. Data augmentation can help prevent overfitting and improve the generalization \nof the pre-trained models. The augmented data is validated to ensure semantic integ -\nrity. Then the original dataset is integrated with the augmented data to generate a new \ntraining set. The annotation process for risk factors is applied to the new training set. \nThe training process is performed on the new augmented dataset, then the fine-tuned \nmodels are validated using a validation set and finally tested using a test dataset to assess \ntheir performance.\nThe data augmentation is performed to address the issue of under-representation of \na specific class and to ensure adequate representation of the minority class, in this case, \nthe ’glucose’ class in the Diabetes-Indicator classification. When a particular class is \nunder-represented in a dataset, it can lead to imbalanced training data, potentially caus -\ning the model to struggle in accurately learning and predicting the minority class.\nTo address this challenge, data augmentation techniques are employed. In this context, \ndata augmentation involves duplicating instances belonging to the minority class within \nthe training set. By creating additional copies of the minority class samples, the aug -\nmented dataset now contains more instances representing the under-represented class.\nAfter performing data augmentation and adding duplicated instances, the next step \ndescribed is shuffling the entire training set. Shuffling the data ensures that the dupli -\ncated examples of the minority class are evenly distributed throughout the training data. \nThis process helps to promote a more balanced representation by preventing the model \nfrom encountering batches or patterns that are biased towards the majority class.\nBy employing data augmentation and shuffling, the training data is modified to have \na more balanced representation of the minority class, such as ’glucose’ in this case. This \nPage 14 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \napproach aims to improve the model’s ability to learn and generalize well for all classes, \nincluding the under-represented class.\nAfter developing and fine-tuning the NLP techniques and transformer-based models \nusing the training corpus (SET1 and SET2), they were applied to the testing corpus and \nthe results were compared to the shared task organizers for analysis. The outputs of the \ntransformer-based models were compared with the primary metric of the i2b2 challenge \nevaluation script provided by the shared task organizers, and all extracted tags are clas -\nsified as true positive (i.e., the result matches the primary metric), false positive (i.e., the \nresult does not match the primary measure), or false negative. The tables below show the \nresults for each class of risk factors and their indicators.\nWe used the filter option provided by the evaluation script to determine the results for \neach class of risk factors. Using the option Conjunctive, it is also possible to determine \nspecific risk factors and their attribute value indicators, such as the tag CAD and the \nattribute value of indicator = ’mention’ .\nAccording to the annotation standard, we give the results for each disease category \nseparately, for general mention and disease-specific indicators. Results for the SMOK -\nING category are reported as status only, while results for the MEDICATION categories \nare combined and are accurately identified on the EHRs. For each heart disease risk fac -\ntor class, the results in the tables below were generated for all temporal information tags \nand an attempt was made to categorize the (before, during, and after) DCT results.\nThe best-performing model in most cases for risk factor identification was RoBERTa \nwith F-measure of 93.94%, a precision of 93.90%, and a recall of 94.27% at the weighted-\naveraged level. According to the BERT prevailed in cases with higher numbers of cat -\negories with micro -precision, -recall, and -F1-scores of 92.51%, 93.73%, and 92.84%, \nrespectively. BioBERT obtained -precision, -recall, and -F1-scores of 93.37%, 93.99%, \nand 93.57%, respectively in identifying risk factors. BioClinicalBERT attained a precision \nof 93.38%, recall of 94.03%, and F1-measure of 93.57% at the weighted-averaged level. \nXLNet achieved an F-measure of 93.71%, a recall of 93.97%, and a precision of 93.61% at \nthe weighted level.\nFurthermore, the best results achieved at the risk indicator level by applying the \nBioBERT model to identify hypertension, diabetes, and SMOKER were 0.91, 0.83, and \n0.90, respectively, using micro-averaged F1-measures. The BERT model performs best \non Hypertension (0.90), Smoker (0.88), and FamilyHist (0.88). BioClinicalBERT per -\nforms best on Hypertension (0.92), Smoker (0.94), and FamilyHist (0.88). RoBERTa \nperforms best on Hypertension (0.92), Smoker (0.90), and FamilyHist (0.88). XLNET \nperforms best on Hypertension (0.91), Smoker (0.90), and FamilyHist (0.88). The FAM -\nILY_HIST is a simple task because there are few records containing evidence of family \nmembers who have been diagnosed with CAD.\nIt is shown in Tables 5, 6, 7, and 8 how BERT, RoBERTa, BioClinicalBERT, and XLNet \nperformed on the i2b2 test data with respect to F1-measure, Recall, and Precision at \nthe risk indicator level. The overall performance of the transformer-based models at the \nlevel of time attributes associated with the presentation of the risk indicator based on \nDCT is shown in Tables 9, 10, 11 and 12. Table 13 shows the overall performance of the \neight risk factor categories based on the i2b2 test data. Figure  3 shows the F1-Plot curve \nof five transformer-based models using the final dataset after the augmentation process.\nPage 15 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \nIn this study, we evaluated model-ensembling techniques for improving the proposed \nrisk factor detection model’s performance for heart disease. The provided predictions are \nbased on ensembling fine-tuned transformer-based models, which achieved F1-scores of \n94.26%. The overall F1-scores for five different ensemble models are shown in Table  14. \nThe ensemble model provides the best performance in all risk factor detections, demon -\nstrating the efficiency of the technique. We proposed to ensemble the five transformer-\nbased models to get the benefits of each model in the word embedding technique. The \nreason to use an ensemble of five transformer-based models is to apply the performance \nof different models. Every model within the ensemble can be particularly good at han -\ndling particular kinds of datasets or capturing various linguistic patterns based on a pre -\ntraining dataset. We might be able to improve overall performance and get more reliable \nresults by integrating their outputs. Furthermore, ensembles can provide a type of model \naveraging that decreases overfitting and improves generalization. Therefore, the ensem -\nble approach has a powerful improvement in many NLP tasks [84].\nThe optimized hyperparameters of the most recent models chosen for fine-tuning are \npresented in Table 15.\nError analysis\nWe classified the risk factors into one of three groups, as mentioned in Table  3, \ndetermining the type of evidence for each risk factor. Evaluation of the test dataset \nprovided by the shared task organizers showed that the proposed model based on \ntransformer-based models performed effectively, with the best micro F1-score being \nFig. 3 The F1-plot of the train- and validation-learning curves of five transformer-based models using the \nfinal dataset\nPage 16 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \n94.27% using RoBERTa model. Despite using fewer annotations, the fine-tuned trans -\nformer-based models performed better than the highest performing system partici -\npating in the shared task. Although the efficiency of the fine-tuned transformer-based \nmodels was exceptional, they did not achieve significant results with several types of \ntags, such as obesity, CAD, and smoking status.\nDiscourse-based indicators evidence had an unusually large number of negative \nsamples (not an indicator) for the two types of tags that contain the most discourse-\nbased indicators (CAD and smoking status). An example would be the number of \nnegative samples of CAD: events. The results may have been poor due to the large \nnumber of negative samples. There are only 2.4% of obesity status tags in the test data \nset. Due to the class imbalance issue associated with transfer learning techniques, \ntheir low frequency makes them challenging to recognize. The summary report of the \ni2b2 2014 challenge reveals that other participating systems also had similar results \nwith these three types of tags.\nIn terms of disease indicators, hyperlipidemia had the lowest recall, and obesity \nhad the lowest precision. Due to inaccurate chunking, some clinical notes containing \nhyperlipidemia indicators appearing as ’high cholesterol’ , ’elevated lipids’ , and ’elevated \nserum cholesterol’ failed to be recognized by our proposed model. Furthermore, our \nTable 5 BERT evaluation metrics for each risk factor indicator\nBold indicates the best value\nRisk Factor Indicator Precision Recall F1-score Support\nCAD Mention 0.84 0.93 0.88 260\nEvent 0.71 0.76 0.74 250\nTest 0.89 0.12 0.21 68\nSymptom 0.89 0.80 0.84 94\nDiabetes Mention 0.98 1.00 0.99 693\nA1c 0.67 0.92 0.77 65\nGlucose 1.00 0.07 0.13 42\nHypertension Mention 1.00 0.99 0.99 548\nHigh bp 0.98 0.99 0.98 212\nObese Mention 0.93 1.00 0.97 127\nObese_BMI 0.00 0.00 0.00 9\nHyperlipidemia Mention 0.98 1.00 0.99 240\nHigh chol. 0.00 0.00 0.00 8\nHigh LDL 0.85 0.74 0.79 31\nSmoker Smoker_never 0.93 0.96 0.94 115\nSmoker_ever 0.00 0.00 0.00 3\nSmoker_current 0.00 0.00 0.00 39\nSmoker_past 0.78 0.85 0.81 123\nSmoker_unknown 0.99 0.97 0.98 203\nMedication 0.89 0.68 0.77 7225\nFamily history NA 0.0000 0.0000 0.0000 13\nWeighted average 0.9251 0.9373 0.9284 42946\nMacro average 0.3144 0.2846 0.2736 42946\nMicro average 0.9373 42946\nAccuracy 0.9373 42946\nPage 17 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \ndictionary lookup module did not contain the associated ICD codes for some of these \nitems.\nIn the testing corpus, there were at least two instances in which hyperlipidemia was \nmentioned directly following a word without a space, such as ‘hemodialysis Hyperlipi -\ndemia’ , which our proposed model failed to recognize. As a result of including the con -\ncept of ‘overweight’ in the Unified Medical Language System (UMLS) in the list of ICD \ncodes for obesity, we experienced low precision. Although the obesity indicator ‘over -\nweight’ appeared in one record of the training dataset, this generated a large number \nof false positives. Additionally, our proposed model generated false positives when the \n‘obese’ indicator was used as a mention instead of the ‘obesity’ indicator (e.g., ‘abdomen \nis moderately obese’ and ‘abdomen is slightly obese’). Regular expressions at the lexical \nlevel were not always effective in addressing other indicators of disease and risk factors.\nThe following issues are associated with heart disease indicators:\n– Many different lexical forms and acronyms are used to refer to the same set of labo -\nratory indicators for heart disease. In the case of diabetes and hypertension, regu -\nlar expressions are applied to determine blood glucose and pressure levels. Blood \npressure can be stated using BP and b/p, and glucose levels can be described using \nBG, BS, FS and FG. This is an example of some of the shortcomings of our proposed \nTable 6 RoBERTa Evaluation Metrics for each risk factor indicator\nBold indicates the best value\nRisk factor Indicator Precision Recall F1-score Support\nCAD Mention 0.82 0.79 0.81 228\nEvent 0.72 0.70 0.71 278\nTest 0.00 0.00 0.00 70\nSymptom 0.90 0.39 0.54 95\nDiabetes Mention 0.92 0.99 0.95 549\nA1c 0.89 0.79 0.84 71\nGlucose 0.00 0.00 0.00 40\nHypertension Mention 0.99 0.97 0.98 525\nHigh bp 0.93 0.99 0.96 210\nOBESE Mention 0.95 1.00 0.97 115\nObese_BMI 0.00 0.00 0.00 6\nHyperlipidemia Mention 0.87 0.99 0.93 232\nHigh chol. 0.00 0.00 0.00 7\nHigh LDL 0.50 0.10 0.17 30\nSmoker Smoker_never 0.80 0.72 0.76 114\nSmoker_ever 0.00 0.00 0.00 3\nSmoker_current 0.00 0.00 0.00 37\nSmoker_unknown 0.93 0.90 0.91 202\nSmoker_past 0.85 0.59 0.69 121\nMedication 0.87 0.74 0.80 7329\nFamily history 0.2000 0.0769 0.1111 13\nWeighted average 0.9390 0.9427 0.9394 42946\nMacro average 0.4195 0.4037 0.3915 42946\nMicro average 0.9427 42946\nAccuracy 0.9427 42946\nPage 18 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \nmodel, and it would be necessary to develop an integrated approach to address this \nproblem to achieve improved accuracy.\n– The numerical results of a laboratory must be extracted accurately. After the pro -\nposed model has found the matching terms for laboratory or test indicators, the \nmodel must extract the numerical values associated with those terms and compare \nthem with threshold levels that indicate an abnormality. When the numbers follow \nthe term and are expressed as a single unit, like in ’GLU 230(H)’ , it may be easy to \nextract them. There are, however, some phrases that may be more difficult to detect, \nsuch as ‘FS in the AM ∼ 90–180’; now 80–175, mostly 90–180’ . This example is a case \nwhere ‘_’ is used to indicate value ranges, and several units can be denoted by using \ntime and frequency terms such as ‘now’ and ‘mostly’ .\n– Training data sparsity: Sometimes, there were not enough training examples avail -\nable to allow an adequate generalization of the proposed model. In the case of the \ncholesterol indicator for hyperlipidemia, there were only nine annotations available \nin the entire set of 790 training sets. For the LDL indicator, there were approximately \n33 annotations.\n– Analysis of complex time attributes: Another issue with our proposed model is that \nindicators for laboratory tests require additional analysis for temporal information. \nTable 7 BioClinicalBERT Evaluation Metrics for each risk factor indicator\nBold indicates the best value\nRisk Factor Indicator Precision Recall F1-score Support\nCAD Mention 0.86 0.92 0.88 259\nEvent 0.80 0.81 0.80 258\nTest 0.93 0.42 0.57 65\nSymptom 0.85 0.80 0.82 99\nDiabetes Mention 0.99 0.99 0.99 601\nA1c 0.75 0.92 0.83 66\nGlucose 1.00 0.38 0.55 40\nHypertension Mention 1.00 0.99 1.00 602\nHigh bp 0.99 1.00 0.99 206\nOBESE Mention 0.96 1.00 0.98 117\nObese_BMI 0.00 0.00 0.00 5\nHyperlipidemia Mention 0.97 0.99 0.98 286\nHigh chol. 0.00 0.00 0.00 10\nHigh LDL 0.79 0.79 0.79 29\nSmoker Smoker_never 0.94 0.95 0.94 114\nSmoker_ever 0.00 0.00 0.00 3\nSmoker_current 0.00 0.00 0.00 40\nSmoker_past 0.88 0.77 0.82 122\nSmoker_unknown 0.99 0.99 0.99 202\nMedication 0.88 0.74 0.80 7253\nFamily history 0.0000 0.0000 0.0000 13\nWeighted average 0.9338 0.9403 0.9357 42946\nMacro average 0.3715 0.3614 0.3505 42946\nMicro average 0.9403 42946\nAccuracy  0.9403  42946\nPage 19 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \nThere are various time-attribute values used in the annotations of most laboratory \ntests and vital signs; in contrast, the time-attribute value ’continuing’ is primar -\nily used in the annotation of chronic disease mention (i.e. during, before, and after \nDCT). As an example, glucose and A1c tests were typically performed on a previ -\nous visit and are therefore labelled ’during DCT’ . BP is often taken at the time of the \npatient’s visit and labeled ‘during DCT’ .\nConclusion and future work\nIn conclusion, we developed a model to identify heart disease risk factors and dem -\nonstrated that transfer learning can be effectively applied to detect heart disease \nrisk factors and the time they are presented in EHRs. Our research highlighted that \nthe application of transfer learning has increased dramatically in recent years. Sev -\neral studies have identified and demonstrated the significant role of transfer learning \nbased on transformers in the extraction of clinical concepts from clinical notes and \nother clinical NLP tasks through fine-tuning. Using the shared dataset of heart dis -\nease risk factors i2b2, transformer-based models outperformed conventional models \nin terms of precision in predicting the presence of risk factors. Furthermore, it identi -\nfied novel risk factors that were not captured by traditional models. Our experiments \nTable 8 XLNET Evaluation Metrics for each risk factor indicator\nBold indicates the best value\nRisk Factor Indicator Precision Recall F1-score Support\nCAD Mention 0.93 0.92 0.92 301\nEvent 0.69 0.78 0.73 241\nTest 0.00 0.00 0.00 63\nSymptom 0.94 0.49 0.64 94\nDiabetes Mention 0.93 0.99 0.96 530\nA1c 0.91 0.81 0.86 75\nGlucose 0.00 0.00 0.00 40\nObese Mention 0.94 1.00 0.97 114\nObese_BMI 0.00 0.00 0.00 7\nHypertension Mention 0.99 0.99 0.99 515\nHigh bp 0.97 0.98 0.97 205\nHyperlipidemia Mention 0.86 1.00 0.93 221\nHigh chol. 0.00 0.00 0.00 7\nHigh LDL 0.00 0.00 0.00 28\nSmoker Smoker_never 0.80 0.72 0.76 114\nSmoker_ever 0.00 0.00 0.00 3\nSmoker_current 0.00 0.00 0.00 37\nSmoker_past 0.85 0.59 0.69 121\nSmoker_unknown 0.93 0.90 0.91 202\nMedication 0.87 0.76 0.81 7352\nFamily history 0.2000 0.0769 0.1111 13\nWeighted average 0.9361 0.9397 0.9371 42946\nMacro average 0.3988 0.3848 0.3772 42946\nMicro average 0.9397 42946\nAccuracy 0.9397 42946\nPage 20 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \ninvestigate the effectiveness of the five models (BERT, RoBERTa, BioBERT, BioClin -\nicalBERT, XlNet, and BioBERT) in terms of the extraction of risk factors for heart \ndisease. The RoBERTa model achieved state-of-the-art performance with micro \nF1-scores of 94.27%, while the BERT, BioClinicalBERT, XlNet, and BioBERT mod -\nels have provided significant performance with micro F1-scores of 93.73%, 94.03%, \n93.97%, and 93.99%, respectively. The results showed that a simple ensemble of the \nfive transformer-based models is an effective strategy that significantly improved the \nperformance of the proposed heart disease risk factor identification model with a \nmicro F1-score of 94.26%. Using transformer-based models, our study demonstrated \nthe effectiveness of transfer learning to improve the prediction of heart disease risk.\nAs part of our future work, we will focus on analyzing embedding-specific issues \nsuch as misclassification as well as the incorporation of fine-tuning processes into \nother clinical NLP tasks.\nTable 9 BERT Evaluation Metrics for each risk factor indicator based on time attribute Identification\nBold indicates the best value\nRisk factor Time attribute Precision Recall F-Score Support\nCAD Before_DCT 0.78 0.93 0.85 462\nDuring_DCT 0.00 0.00 0.00 94\nAfter_DCT 0.67 0.63 0.65 116\nDiabetes During_DCT 0.49 0.33 0.39 134\nBefore_DCT 0.78 0.85 0.81 557\nAfter_DCT 0.00 0.00 0.00 109\nHypertension Before_DCT 0.00 0.00 0.00 33\nDuring_DCT 0.79 0.87 0.83 363\nAfter_DCT 0.89 0.79 0.84 364\nObese Before_DCT 0.00 0.00 0.00 35\nDuring_DCT 0.89 0.75 0.82 65\nAfter_DCT 0.73 0.67 0.70 36\nMedication Before_DCT 0.62 0.42 0.50 910\nDuring_DCT 0.67 0.34 0.45 785\nAfter_DCT 0.61 0.26 0.36 715\nHyperlipidemia Before_DCT 0.00 0.00 0.00 85\nDuring_DCT 0.66 0.95 0.78 160\nAfter_DCT 0.00 0.00 0.00 34\nWeighted average 0.9251 0.9373 0.9284 42946\nMacro average 0.3144 0.2846 0.2736 42946\nMicro average 0.9373 42946\nAccuracy 0.9373 42946\nPage 21 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \nTable 10 RoBERTa Evaluation Metrics for each risk factor indicator based on time attribute \nIdentification\nBold indicates the best value\nRisk factor Time attribute Precision Recall F-Score Support\nCAD Before_DCT 0.78 0.89 0.83 436\nDuring_DCT 0.67 0.44 0.53 201\nAfter_DCT 0.00 0.00 0.00 34\nDiabetes During_DCT 0.00 0.00 0.00 107\nBefore_DCT 0.67 0.58 0.62 288\nAfter_DCT 0.65 0.64 0.65 265\nHypertension Before_DCT 0.76 0.82 0.79 159\nDuring_DCT 0.91 0.95 0.93 521\nAfter_DCT 0.00 0.00 0.00 55\nObese Before_DCT 0.77 0.41 0.54 41\nDuring_DCT 0.80 0.11 0.20 36\nAfter_DCT 0.00 0.00 0.00 44\nMedication Before_DCT 0.68 0.51 0.58 995\nDuring_DCT 0.58 0.43 0.50 722\nAfter_DCT 0.62 0.45 0.52 727\nHyperlipidemia Before_DCT 1.00 0.11 0.20 88\nDuring_DCT 0.81 0.57 0.67 77\nAfter_DCT 0.82 0.73 0.77 104\nWeighted average 0.9390 0.9427 0.9394 42946\nMacro average 0.4195 0.4037 0.3915 42946\nMicro average 0.9427 42946\nAccuracy 0.9427 42946\nPage 22 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \nTable 11 BioClinicalBERT Evaluation Metrics for each risk factor indicator based on time attribute \nIdentification\nBold indicates the best value\nRisk factor Time attribute Precision Recall F-Score Support\nCAD Before_DCT 0.83 0.81 0.82 422\nDuring_DCT 0.00 0.00 0.00 82\nAfter_DCT 0.64 0.92 0.76 177\nDiabetes During_DCT 0.61 0.66 0.63 267\nBefore_DCT 0.72 0.75 0.73 329\nAfter_DCT 0.50 0.02 0.03 111\nHypertension Before_DCT 0.76 0.79 0.77 186\nDuring_DCT 0.89 0.95 0.92 452\nAfter_DCT 0.80 0.59 0.68 170\nObese Before_DCT 0.00 0.00 0.00 13\nDuring_DCT 0.00 0.00 0.00 47\nAfter_DCT 0.53 0.63 0.57 62\nMedication Before_DCT 0.58 0.57 0.58 1002\nDuring_DCT 0.39 0.08 0.13 609\nAfter_DCT 0.67 0.42 0.52 808\nHyperlipidemia Before_DCT 0.81 0.75 0.78 151\nDuring_DCT 0.71 0.71 0.71 141\nAfter_DCT 0.00 0.00 0.00 33\nWeighted average 0.9338 0.9403 0.9357 42946\nMacro average 0.3715 0.3614 0.3505 42946\nMicro average 0.9403 42946\nAccuracy 0.9403 42946\nPage 23 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \nTable 12 XLNET Evaluation Metrics for each risk factor indicator based on time attribute \nIdentification\nBold indicates the best value\nRisk factor Time attribute Precision Recall F-Score Support\nCAD Before_DCT 0.80 0.83 0.81 406\nDuring_DCT 0.78 0.61 0.69 222\nAfter_DCT 0.66 0.63 0.65 71\nDiabetes During_DCT 0.67 0.49 0.57 272\nBefore_DCT 0.72 0.57 0.64 209\nAfter_DCT 0.49 0.39 0.44 164\nHypertension Before_DCT 0.70 0.64 0.67 116\nDuring_DCT 0.89 0.95 0.92 553\nAfter_DCT 0.10 0.08 0.09 51\nObese Before_DCT 0.46 0.32 0.38 41\nDuring_DCT 0.77 0.52 0.62 69\nAfter_DCT 0.00 0.00 0.00 11\nMedication Before_DCT 0.67 0.51 0.58 863\nDuring_DCT 0.54 0.36 0.43 695\nAfter_DCT 0.67 0.61 0.64 894\nHyperlipidemia Before_DCT 1.00 0.02 0.05 82\nDuring_DCT 0.75 0.72 0.73 65\nAfter_DCT 0.88 0.81 0.84 109\nWeighted average 0.9361 0.9397 0.9371 42946\nMacro average 0.3988 0.3848 0.3772 42946\nMicro average 0.9397 42946\nAccuracy 0.9397 42946\nTable 13 Transformer Models\nModel/risk factor BERT BioBERT BioClinical Bert RoBERTa XLNET\nDiabetes 0.82 0.83 0.80 0.75 0.75\nHypertension 0.90 0.91 0.92 0.92 0.91\nCAD 0.77 0.78 0.79 0.71 0.77\nMedication 0.77 0.80 0.80 0.80 0.81\nSmoker 0.88 0.90 0.94 0.90 0.90\nObese 0.81 0.81 0.71 0.70 0.74\nHyperlipidemia 0.78 0.80 0.83 0.75 0.77\nFamilyHist 0.88 0.88 0.88 0.88 0.88\nF-score (micro) 0.9373 0.9399 0.9403 0.9427 0.9397\nTable 14 Ensembles\nBold indicates the best value\nAll Ensembles (BERT+BioBERT+BioClinic\nalBERT+RoBERTa+XLNet)\nPrecision Recall F1-score Support\nMacro average 0.3218 0.3330 0.3129 42946\nWeighted average 0.9337 0.9426 0.9366 42946\nAccuracy 0.9426 42946\nPage 24 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \nAcknowledgements\nThe authors would like to thank the Science, Technology & Innovation Funding Authority (STDF) in cooperation with the \nEgyptian Knowledge Bank (EKB).\nAuthor contributions\nE.H.H., participated in the supervision, sorting of the experiments and analyzed the results, E.H.H., R.E.M., and G.H., \nperformed the experiments, visualization, formal analysis, discussed/analyzed the results and wrote the article. A.A.A., \nparticipated in the supervision. All authors approved the work in this article.\nFunding\nOpen access funding provided by The Science, Technology & Innovation Funding Authority (STDF) in cooperation with \nThe Egyptian Knowledge Bank (EKB).\nAvailability of data and materials\nThe data sets provided during the current study are available: http:// www. partn ers. org and https:// www. i2b2. org/ NLP/ \nHeart Disea se/.\nDeclarations\nEthics approval and consent to participate\nThis article does not contain any studies with human participants or animals carried out by any of the authors.\nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare that there is no Competing interests.\nReceived: 9 July 2023   Accepted: 14 March 2024\nReferences\n 1. World Health Organization et al. Global status report on noncommunicable diseases 2014. Number WHO/NMH/\nNVI/15.1. World Health Organization. 2014.\n 2. Herron MP . Cdc national vital statistics reports. Deaths: Leading Causes for 2017. Statistics. 2017;66:5.\n 3. Benjamin EJ, Muntner P , Alonso A, Bittencourt MS, Callaway CW, Carson AP , Chamberlain AM, Chang AR, Cheng S, \nDas SR, et al. Heart disease and stroke statistics-2019 update: a report from the American heart association. Circula-\ntion. 2019;139(10):e56–528.\n 4. Roth GA, Abate D, Abate KH, Abay SM, Abbafati C, Abbasi N, Abbastabar H, Abd-Allah F, Abdela J, Abdelalim A, et al. \nGlobal, regional, and national age-sex-specific mortality for 282 causes of death in 195 countries and territories, \n1980–2017: a systematic analysis for the global burden of disease study 2017. Lancet. 2018;392(10159):1736–88.\n 5. Zhao M, Wang M, Zhang J, Ye J, Yao X, Wang Z, Ye D, Liu J, Wan J. Advances in the relationship between coronavirus \ninfection and cardiovascular diseases. Biomed Pharmacother. 2020;127: 110230.\n 6. Hajar R. Risk factors for coronary artery disease: historical perspectives. Heart Views. 2017;18(3):109.\n 7. U.S. Department of Health and Human Services. National institute of diabetes and digestive and kidney diseases. \n2021. https:// www. niddk. nih. gov/ health- infor mation/ diabe tes. Accessed 27 Nov 2021.\n 8. National Heart Lung and Blood Institute. Coronary heart disease | nhlbi, nih. 2016. https:// www. nhlbi. nih. gov/ \nhealth- topics/ coron ary- heart- disea se. Accessed 27 Nov 2021.\n 9. Dokken BB. The pathophysiology of cardiovascular disease and diabetes: beyond blood pressure and lipids. Diabe-\ntes Spectr. 2008;21(3):160–5.\nTable 15 Hyperparameters optimized via training\nHyperparameter BERT RoBERTa BioBERT BioClinicalBERT XLNet\nHidden size 768 768 768 768 144\nNumber of layers 12 12 12 13 6\nNumber of attention heads 12 12 12 12 6\nFeed-forward layer hidden size 128 128 128 128 128\nLearning rate 1 × 10−6 5 × 10−7 5 × 10−5 5 × 10−6 5 × 10−6\nBatch size 16 16 16 16 16\nDropout 0.5 0.1 0.1 0.4 0.4\nPage 25 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \n 10. Chokwijitkul T, Nguyen A, Hassanzadeh H, Perez S. Proceedings of the identifying risk factors for heart disease in \nelectronic medical records: a deep learning approach. In: Demner-Fushman D, Cohen KB, Ananiadou S, Tsujii J, edi-\ntors. BioNLP 2018 workshop. Melbourne: Association for Computational Linguistics; 2018. p. 18–27.\n 11. Zhan X, Humbert-Droz M, Mukherjee P , Gevaert O. Structuring clinical text with AI: old versus new natural language \nprocessing techniques evaluated on eight common cardiovascular diseases. Patterns. 2021;2(7): 100289.\n 12. Meystre SM, Savova GK, Kipper-Schuler KC, Hurdle JF. Extracting information from textual documents in the elec-\ntronic health record: a review of recent research. Yearb Med Inform. 2008;17(01):128–44.\n 13. Hebal F, Nanney E, Christine Stake ML, Miller GL, Barsness KA. Automated data extraction: merging clinical care with \nreal-time cohort-specific research and quality improvement data. J Pediatr Surg. 2017;52(1):149–52.\n 14. Safran C, Meryl Bloomrosen W, Hammond E, Labkoff S, Markel-Fox S, Tang PC, Detmer DE. Toward a national frame-\nwork for the secondary use of health data: an American medical informatics association white paper. J Am Med \nInform Assoc. 2007;14(1):1–9.\n 15. Mann CJ. Observational research methods. Research design ii: cohort, cross sectional, and case-control studies. \nEmerg Med J. 2003;20(1):54–60.\n 16. Geneletti S, Richardson S, Best N. Adjusting for selection bias in retrospective, case-control studies. Biostatistics. \n2009;10(1):17–31.\n 17. Oleynik M, Kugic A, Kasáč Z, Kreuzthaler M. Evaluating shallow and deep learning strategies for the 2018 n2c2 \nshared task on clinical text classification. J Am Med Inform Assoc. 2019;26(11):1247–54.\n 18. Ebbehoj A, Thunbo MØ, Andersen OE, Glindtvad MV, Hulman A. Transfer learning for non-image data in clinical \nresearch: a scoping review. PLOS Digit Health. 2022;1(2): e0000014.\n 19. Alyafeai Z, AlShaibani MS, Ahmad I. A survey on transfer learning in natural language processing. 2020. arXiv pre-\nprint arXiv: 2007. 04239.\n 20. Laparra E, Mascio A, Velupillai S, Miller T. A review of recent work in transfer learning and domain adaptation for \nnatural language processing of electronic health records. Yearb Med Inform. 2021;30(01):239–44.\n 21. Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Trans Knowl Data Eng. 2010;22(10):1345–59.\n 22. Goodfellow I, Bengio Y, Courville A. Deep learning. Cambridge: MIT press; 2016.\n 23. Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector \nspace. 2013. arXiv preprint arXiv: 1301. 3781.\n 24. Arnold S, Gers FA, Kilias T, Löser A. Robust named entity recognition in idiosyncratic domains. 2016. arXiv pre -\nprint arXiv: 1608. 06757.\n 25. Bojanowski P , Grave E, Joulin A, Mikolov T. Enriching word vectors with subword information. Trans Assoc Com-\nput Linguist. 2017;5:135–46.\n 26. Joulin A, Grave E, Bojanowski P , Mikolov T. Bag of tricks for efficient text classification. arXiv preprint. 2016. arXiv:  \n1607. 01759.\n 27. Johnson AEW, Pollard TJ, Shen L, Lehman LH, Feng M, Ghassemi M, Moody B, Szolovits P , Celi LA, Mark RG. \nMimic-iii, a freely accessible critical care database. Sci Data. 2016;3(1):1–9.\n 28. Zhang Y, Chen Q, Yang Z, Lin H, Zhiyong L. Biowordvec, improving biomedical word embeddings with subword \ninformation and mesh. Sci Data. 2019;6(1):52.\n 29. Chen Q, Peng Y, Lu Z. Biosentvec: creating sentence embeddings for biomedical texts. In: Chen Q, editor. 2019 \nIEEE International Conference on Healthcare Informatics (ICHI). Xi’an: IEEE; 2019. p. 1–5.\n 30. Stubbs A, Kotfila C, Hua X, Uzuner Ö. Identifying risk factors for heart disease over time: overview of 2014 i2b2/\nuthealth shared task track 2. J Biomed Inform. 2015;58:S67–77.\n 31. Stubbs A, Uzuner Ö. Annotating risk factors for heart disease in clinical narratives for diabetic patients. J Biomed \nInform. 2015;58:S78–91.\n 32. Devlin J, Chang MW, Lee K, Toutanova K. Bert: pre-training of deep bidirectional transformers for language \nunderstanding. arXiv preprint. 2018. arXiv: 1810. 04805.\n 33. Lee J, Yoon W, Kim S, Kim D, Kim S, So CH, Kang J. Biobert: a pre-trained biomedical language representation \nmodel for biomedical text mining. Bioinformatics. 2020;36(4):1234–40.\n 34. Alsentzer E, Murphy JR, Boag W, Weng WH, Jin D, Naumann T, McDermott M. Publicly available clinical bert \nembeddings. 2019. arXiv preprint arXiv: 1904. 03323.\n 35. Liu Y, Ott M, Goyal N, Du J, Joshi M, Chen D, Levy O, Lewis M, Zettlemoyer L, Stoyanov V. Roberta: A robustly \noptimized bert pretraining approach. 2019. arXiv preprint arXiv: 1907. 11692.\n 36. Yang Z, Dai Z, Yang Y, Carbonell J, Salakhutdinov RR, Le QV. Xlnet: generalized autoregressive pretraining for \nlanguage understanding. Adv Neural Inform Process Syst. 2019:32.\n 37. Roberts K, Shooshan SE, Rodriguez L, Abhyankar S, Kilicoglu H, Demner-Fushman D. The role of fine-\ngrained annotations in supervised recognition of risk factors for heart disease from EHRs. J Biomed Inform. \n2015;58:S111–9.\n 38. Harkema H, Dowling JN, Thornblade T, Chapman WW. Context: an algorithm for determining negation, experi-\nencer, and temporal status from clinical reports. J Biomed Inform. 2009;42(5):839–51.\n 39. Kotfila C, Uzuner Ö. A systematic comparison of feature space effects on disease classifier performance for \nphenotype identification of five diseases. J Biomed Inform. 2015;58:S92–102.\n 40. Aronson AR. Effective mapping of biomedical text to the umls metathesaurus: the metamap program. In: Aron-\nson AR, editor. Proceedings of the AMIA Symposium. Bethesda: American Medical Informatics Association; 2001. \np. 17.\n 41. Chen Q, Li H, Tang B, Wang X, Liu X, Liu Z, Liu S, Wang W, Deng Q, Zhu S, et al. An automatic system to identify heart \ndisease risk factors in clinical texts over time. J Biomed Inform. 2015;58:S158–63.\n 42. Urbain J. Mining heart disease risk factors in clinical text with named entity recognition and distributional semantic \nmodels. J Biomed Inform. 2015;58:S143–9.\n 43. Torii M, Fan J, Yang W, Lee T, Wiley MT, Zisook DS, Huang Y. Risk factor detection for heart disease by applying text \nanalytics in electronic medical records. J Biomed Inform. 2015;58:S164–70.\nPage 26 of 27Houssein et al. Journal of Big Data           (2024) 11:47 \n 44. Hua X, Stenner SP , Doan S, Johnson KB, Waitman LR, Denny JC. Medex: a medication information extraction system \nfor clinical narratives. J Am Med Inform Assoc. 2010;17(1):19–24.\n 45. Hall M, Frank E, Holmes G, Pfahringer B, Reutemann P , Witten IH. The weka data mining software: an update. ACM \nSIGKDD Explorat Newsl. 2009;11(1):10–8.\n 46. Chang C-C, Lin C-J. Libsvm: a library for support vector machines. ACM Trans Intell Syst Technol (TIST). \n2011;2(3):1–27.\n 47. Manning CD, Surdeanu M, Bauer J, Finkel JR, Bethard S, McClosky D. The stanford corenlp natural language process-\ning toolkit. In: Manning CD, editor. Proceedings of 52nd annual meeting of the association for computational \nlinguistics: system demonstrations. Association for Computational Linguistics: Baltimore; 2014. p. 55–60.\n 48. Li Y, Rao S, Solares JRA, Hassaine A, Ramakrishnan R, Canoy D, Zhu Y, Rahimi K, Salimi-Khorshidi G. Behrt: transformer \nfor electronic health records. Sci Rep. 2020;10(1):1–12.\n 49. Si Y, Roberts K. Patient representation transfer learning from clinical notes based on hierarchical attention network. \nAMIA Summits Transl Sci Proc. 2020;2020:597.\n 50. Syed K, William Sleeman IV, Hagan M, Palta J, Kapoor R, Ghosh P . Automatic incident triage in radiation oncology \nincident learning system. Healthcare. 2020;8:272.\n 51. Dai H-J, Chu-Hsien S, Lee Y-Q, Zhang Y-C, Wang C-K, Kuo C-J, Chi-Shin W. Deep learning-based natural language \nprocessing for screening psychiatric patients. Front Psychiatry. 2021;11: 533949.\n 52. Al-Garadi MA, Yang Y-C, Cai H, Ruan Y, O’Connor K, Graciela G-H, Perrone J, Sarker A. Text classification models for the \nautomatic detection of nonmedical prescription medication use from social media. BMC Med Inform Decis Mak. \n2021;21(1):1–13.\n 53. Jingcheng D, Zhang Y, Luo J, Jia Y, Wei Q, Tao C, Hua X. Extracting psychiatric stressors for suicide from social media \nusing deep learning. BMC Med Inform Decis Mak. 2018;18:77–87.\n 54. Howard D, Maslej MM, Lee J, Ritchie J, Woollard G, French L. Transfer learning for risk classification of social media \nposts: model evaluation study. J Med Internet Res. 2020;22(5): e15371.\n 55. Rios A, Kavuluru R. Neural transfer learning for assigning diagnosis codes to EMRs. Artif Intell Med. 2019;96:116–22.\n 56. Hassanzadeh H, Kholghi M, Nguyen A, Chu K. Clinical document classification using labeled and unlabeled data \nacross hospitals. In: Hassanzadeh H, editor. AMIA annual symposium proceedings, vol. 2018. Bethesda: American \nMedical Informatics Association; 2018. p. 545.\n 57. Ji B, Li S, Jie Yu, Ma J, Tang J, Qingbo W, Tan Y, Liu H, Ji Y. Research on Chinese medical named entity recognition \nbased on collaborative cooperation of multiple neural network models. J Biomed Inform. 2020;104: 103395.\n 58. Newman-Griffis D, Zirikly A. Embedding transfer for low-resource medical named entity recognition: a case study on \npatient mobility. 2018. arXiv preprint arXiv: 1806. 02814.\n 59. Uzuner Ö, Solti I, Cadag E. Extracting medication information from clinical text. J Am Med Inform Assoc. \n2010;17(5):514–8.\n 60. Gligic L, Kormilitzin A, Goldberg P , Nevado-Holgado A. Named entity recognition in electronic health records using \ntransfer learning bootstrapped neural networks. Neural Netw. 2020;121:132–9.\n 61. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser Ł, Polosukhin I. Attention is all you need. Adv \nNeural Inform Process Syst. 2017:30.\n 62. Wang A, Singh A, Michael J, Hill F, Levy O, Bowman SR. Glue: a multi-task benchmark and analysis platform for natu-\nral language understanding. 2018. arXiv preprint arXiv: 1804. 07461.\n 63. Tay Y, Dehghani M, Bahri D, Metzler D. Efficient transformers: a survey. 2020. arxiv.  arXiv preprint arXiv: 2009. 06732.\n 64. Yu J, Bohnet B, Poesio M. Named entity recognition as dependency parsing. 2020. arXiv preprint arXiv: 2005. 07150.\n 65. Li X, Sun X, Meng Y, Liang J, Wu F, Li J. Dice loss for data-imbalanced NLP tasks. 2019. arXiv preprint arXiv: 1911. 02855.\n 66. Benfeng X, Wang Q, Lyu Y, Zhu Y, Mao Z. Entity structure within and throughout: modeling mention dependencies \nfor document-level relation extraction. Proc AAAI conf Artif Intelli. 2021;35:14149–57.\n 67. Wang J, Lu W. Two are better than one: joint entity and relation extraction with table-sequence encoders. 2020. \narXiv preprint arXiv: 2010. 03851.\n 68. Jiang H, He P , Chen W, Liu X, Gao J, Zhao T. Smart: robust and efficient fine-tuning for pre-trained natural language \nmodels through principled regularized optimization. 2019. arXiv preprint arXiv: 1911. 03437.\n 69. Raffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M, Zhou Y, Li W, Liu PJ. Exploring the limits of transfer learn-\ning with a unified text-to-text transformer. J Mach Learn Res. 2020;21(1):5485–551.\n 70. Zhang Z, Yuwei W, Zhao H, Li Z, Zhang S, Zhou X, Zhou X. Semantics-aware bert for language understanding. Proc \nAAAI Conf Artif Intell. 2020;34:9628–35.\n 71. Lan Z, Chen M, Goodman S, Gimpel K, Sharma P , Soricut R. Albert: A lite bert for self-supervised learning of language \nrepresentations. 2019. arXiv preprint arXiv: 1909. 11942.\n 72. Zhang Z, Yang J, Zhao H. Retrospective reader for machine reading comprehension. Proc AAAI Conf Artif Intell. \n2021;35:14506–14.\n 73. Garg S, Thuy V, Moschitti A. Tanda: Transfer and adapt pre-trained transformer models for answer sentence selection. \nProc AAAI Conf Artif Intell. 2020;34:7780–8.\n 74. Bommasani R, Hudson DA, Adeli E, Altman R, Arora S, von Arx S, Bernstein MS, Bohg J, Bosselut A, Brunskill E et al. On \nthe opportunities and risks of foundation models. 2021. arXiv preprint arXiv: 2108. 07258.\n 75. Peng Y, Yan S, Lu Z. Transfer learning in biomedical natural language processing: an evaluation of bert and elmo on \nten benchmarking datasets. 2019. arXiv preprint arXiv: 1906. 05474.\n 76. Beltagy I, Lo K, Cohan A. Scibert: a pretrained language model for scientific text. arXiv preprint. 2019. arXiv: 1903. \n10676.\n 77. Yu G, Tinn R, Cheng H, Lucas M, Usuyama N, Liu X, Naumann T, Gao J, Poon H. Domain-specific language model \npretraining for biomedical natural language processing. ACM Trans Comp Healthc (HEALTH). 2021;3(1):1–23.\n 78. Lewis P , Ott M, Du J, Stoyanov V. Pretrained language models for biomedical and clinical tasks: understanding and \nextending the state-of-the-art. In: Rumshisky A, Roberts K, Bethard S, Naumann T, editors. Proceedings of the 3rd \nClinical Natural Language Processing Workshop. Stroudsburg: Association for Computational Linguistics; 2020. p. \n146–57.\nPage 27 of 27\nHoussein et al. Journal of Big Data           (2024) 11:47 \n \n 79. Fiorini N, Leaman R, Lipman DJ, Zhiyong L. How user intelligence is improving pubmed. Nat biotechnol. \n2018;36(10):937–45.\n 80. Gillick D. Sentence boundary detection and the problem with the us. In: Gillick D, editor. Proceedings of human \nlanguage technologies: the 2009 annual conference of the North American Chapter of the Association for Compu-\ntational Linguistics, Companion Volume: Short Papers. Boulder: Association for Computational Linguistics; 2009. p. \n241–4.\n 81. Yang H, Garibaldi JM. A hybrid model for automatic identification of risk factors for heart disease. J Biomed Inform. \n2015;58:S171–82.\n 82. Cormack J, Nath C, Milward D, Raja K, Jonnalagadda SR. Agile text mining for the 2014 i2b2/uthealth cardiac risk \nfactors challenge. J Biomed Inform. 2015;58:S120–7.\n 83. Khalifa A, Meystre S. Adapting existing natural language processing resources for cardiovascular risk factors identifi-\ncation in clinical notes. J Biomed Inform. 2015;58:S128–32.\n 84. Kumar Vivek, Recupero Diego Reforgiato, Riboni Daniele, Helaoui Rim. Ensembling classical machine learning and \ndeep learning approaches for morbidity identification from clinical notes. IEEE Access. 2020;9:7107–26.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.797360897064209
    },
    {
      "name": "Transformer",
      "score": 0.5321003198623657
    },
    {
      "name": "Artificial intelligence",
      "score": 0.39060136675834656
    },
    {
      "name": "Machine learning",
      "score": 0.3608967661857605
    },
    {
      "name": "Natural language processing",
      "score": 0.36052292585372925
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I89466785",
      "name": "Minia University",
      "country": "EG"
    },
    {
      "id": "https://openalex.org/I4210131919",
      "name": "Xi'an University of Technology",
      "country": "CN"
    }
  ],
  "cited_by": 10
}