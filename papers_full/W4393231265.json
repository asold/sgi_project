{
  "title": "Knowledge sharing in manufacturing using LLM-powered tools: user study and model benchmarking",
  "url": "https://openalex.org/W4393231265",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4295965247",
      "name": "Samuel Kernan Freire",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2108208485",
      "name": "Chaofan Wang",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3114474685",
      "name": "Mina Foosherian",
      "affiliations": [
        "Bremer Institut für Produktion und Logistik GmbH"
      ]
    },
    {
      "id": "https://openalex.org/A2085910433",
      "name": "Stefan Wellsandt",
      "affiliations": [
        "Bremer Institut für Produktion und Logistik GmbH"
      ]
    },
    {
      "id": "https://openalex.org/A2096513576",
      "name": "Santiago Ruíz Arenas",
      "affiliations": [
        "Universidad EAFIT"
      ]
    },
    {
      "id": "https://openalex.org/A2226758187",
      "name": "Evangelos Niforatos",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4295965247",
      "name": "Samuel Kernan Freire",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2108208485",
      "name": "Chaofan Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3114474685",
      "name": "Mina Foosherian",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2085910433",
      "name": "Stefan Wellsandt",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096513576",
      "name": "Santiago Ruíz Arenas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2226758187",
      "name": "Evangelos Niforatos",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2948715311",
    "https://openalex.org/W4321351832",
    "https://openalex.org/W4313890603",
    "https://openalex.org/W4324316215",
    "https://openalex.org/W4392669753",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4383648582",
    "https://openalex.org/W4378509449",
    "https://openalex.org/W6600444894",
    "https://openalex.org/W2790113577",
    "https://openalex.org/W2730139424",
    "https://openalex.org/W6790003725",
    "https://openalex.org/W2408408053",
    "https://openalex.org/W4385572901",
    "https://openalex.org/W2948947170",
    "https://openalex.org/W4387356888",
    "https://openalex.org/W4390723197",
    "https://openalex.org/W4384520874",
    "https://openalex.org/W4366598232",
    "https://openalex.org/W4307810537",
    "https://openalex.org/W6777615688",
    "https://openalex.org/W4296414573",
    "https://openalex.org/W3194459689",
    "https://openalex.org/W2012876788",
    "https://openalex.org/W3128032792",
    "https://openalex.org/W4318145485",
    "https://openalex.org/W3084444049",
    "https://openalex.org/W2925294513",
    "https://openalex.org/W4378509386",
    "https://openalex.org/W1605480920",
    "https://openalex.org/W4213145388",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4323709074",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4310829037",
    "https://openalex.org/W4383648142",
    "https://openalex.org/W4389519321",
    "https://openalex.org/W4391453730",
    "https://openalex.org/W4324108774",
    "https://openalex.org/W6809646742",
    "https://openalex.org/W3198679462",
    "https://openalex.org/W4385436516",
    "https://openalex.org/W4387567460",
    "https://openalex.org/W4380352301",
    "https://openalex.org/W4386269388",
    "https://openalex.org/W4221141536",
    "https://openalex.org/W3205172848",
    "https://openalex.org/W4376850363",
    "https://openalex.org/W4388514559",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W6856938723",
    "https://openalex.org/W11208535",
    "https://openalex.org/W4238846128",
    "https://openalex.org/W4380575774",
    "https://openalex.org/W4225937285"
  ],
  "abstract": "Recent advances in natural language processing enable more intelligent ways to support knowledge sharing in factories. In manufacturing, operating production lines has become increasingly knowledge-intensive, putting strain on a factory's capacity to train and support new operators. This paper introduces a Large Language Model (LLM)-based system designed to retrieve information from the extensive knowledge contained in factory documentation and knowledge shared by expert operators. The system aims to efficiently answer queries from operators and facilitate the sharing of new knowledge. We conducted a user study at a factory to assess its potential impact and adoption, eliciting several perceived benefits, namely, enabling quicker information retrieval and more efficient resolution of issues. However, the study also highlighted a preference for learning from a human expert when such an option is available. Furthermore, we benchmarked several commercial and open-sourced LLMs for this system. The current state-of-the-art model, GPT-4, consistently outperformed its counterparts, with open-source models trailing closely, presenting an attractive option given their data privacy and customization benefits. In summary, this work offers preliminary insights and a system design for factories considering using LLM tools for knowledge management.",
  "full_text": "TYPE Brief Research Report\nPUBLISHED /two.tnum/seven.tnum March /two.tnum/zero.tnum/two.tnum/four.tnum\nDOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nOPEN ACCESS\nEDITED BY\nDavid Romero,\nMonterrey Institute of Technology and Higher\nEducation (ITESM), Mexico\nREVIEWED BY\nElena Bellodi,\nUniversity of Ferrara, Italy\nAnisa Rula,\nUniversity of Brescia, Italy\n*CORRESPONDENCE\nSamuel Kernan Freire\ns.kernanfreire@tudelft.nl\nRECEIVED /one.tnum/two.tnum September /two.tnum/zero.tnum/two.tnum/three.tnum\nACCEPTED /one.tnum/four.tnum March /two.tnum/zero.tnum/two.tnum/four.tnum\nPUBLISHED /two.tnum/seven.tnum March /two.tnum/zero.tnum/two.tnum/four.tnum\nCITATION\nKernan Freire S, Wang C, Foosherian M,\nWellsandt S, Ruiz-Arenas S and Niforatos E\n(/two.tnum/zero.tnum/two.tnum/four.tnum) Knowledge sharing in manufacturing\nusing LLM-powered tools: user study and\nmodel benchmarking.\nFront. Artif. Intell./seven.tnum:/one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum.\ndoi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nCOPYRIGHT\n© /two.tnum/zero.tnum/two.tnum/four.tnum Kernan Freire, Wang, Foosherian,\nWellsandt, Ruiz-Arenas and Niforatos. This is\nan open-access article distributed under the\nterms of the\nCreative Commons Attribution\nLicense (CC BY) . The use, distribution or\nreproduction in other forums is permitted,\nprovided the original author(s) and the\ncopyright owner(s) are credited and that the\noriginal publication in this journal is cited, in\naccordance with accepted academic practice.\nNo use, distribution or reproduction is\npermitted which does not comply with these\nterms.\nKnowledge sharing in\nmanufacturing using\nLLM-powered tools: user study\nand model benchmarking\nSamuel Kernan Freire /one.tnum*, Chaofan Wang /one.tnum, Mina Foosherian /two.tnum,\nStefan Wellsandt/two.tnum, Santiago Ruiz-Arenas /three.tnumand\nEvangelos Niforatos/one.tnum\n/one.tnumFaculty of Industrial Design Engineering, Delft University of Te chnology, Delft, Netherlands,\n/two.tnumBIBA—Bremer Institut für Produktion und Logistik GmbH, Bremen, Ge rmany, /three.tnumGrupo de Investigación\nen Ingeniería de Diseño (GRID), Universidad EAFIT - Escuela de Administración, Finanzas e Instituto\nTecnológico, Medellin, Colombia\nRecent advances in natural language processing enable more inte lligent ways to\nsupport knowledge sharing in factories. In manufacturing, oper ating production\nlines has become increasingly knowledge-intensive, putting s train on a factory’s\ncapacity to train and support new operators. This paper introdu ces a Large\nLanguage Model (LLM)-based system designed to retrieve inf ormation from\nthe extensive knowledge contained in factory documentation and k nowledge\nshared by expert operators. The system aims to eﬃciently answer queries from\noperators and facilitate the sharing of new knowledge. We condu cted a user\nstudy at a factory to assess its potential impact and adoption, eli citing several\nperceived beneﬁts, namely, enabling quicker information ret rieval and more\neﬃcient resolution of issues. However, the study also highligh ted a preference\nfor learning from a human expert when such an option is available . Furthermore,\nwe benchmarked several commercial and open-sourced LLMs for this system.\nThe current state-of-the-art model, GPT-/four.tnum, consistently outperformed its\ncounterparts, with open-source models trailing closely, prese nting an attractive\noption given their data privacy and customization beneﬁts. In s ummary, this work\noﬀers preliminary insights and a system design for factories co nsidering using\nLLM tools for knowledge management.\nKEYWORDS\nnatural language interface, benchmarking, Large Language Models, factory, industrial\nsettings, industry /five.tnum./zero.tnum, knowledge sharing, information retrieval\n/one.tnum Introduction\nHuman-centric manufacturing seeks to harmonize the strengths of humans and\nmachines, aiming to enhance creativity, human wellbeing, problem-solving abilities, and\noverall productivity within factories (\nMay et al., 2015 ; Fantini et al., 2020 ; Alves et al.,\n2023). Despite these advancements, a signiﬁcant challenge persists in eﬀectively managing\nand utilizing the vast knowledge generated within these manufacturing environments,\nsuch as issue reports and machine documentation (\nGröger et al., 2014 ). This knowledge\nis crucial for optimizing operations, yet it remains largely untapped due to the diﬃculties\nin processing and interpreting the disconnected, sometimes unstructured, technical\ninformation it contains (\nEdwards et al., 2008 ; Leoni et al., 2022 ).\nFrontiers in Artiﬁcial Intelligence /zero.tnum/one.tnum frontiersin.org\nKernan Freire et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nTraditionally, leveraging this knowledge has been cumbersome,\nwith operators choosing to use personal smartphones over\noﬃcial procedures (\nRichter et al., 2019 ) and AI unable to\nhandle the complexity of the data ( Edwards et al., 2008 ).\nHowever, recent Large Language Models (LLMs) like GPT-4 show\npromise in addressing these challenges. LLMs can eﬀectively\ninterpret, summarize, and retrieve information from vast text-\nbased datasets (\nLewis et al., 2020 ) while concurrently aiding the\ncapture of new knowledge ( Kernan Freire et al., 2023b ). These\ncapabilities could signiﬁcantly support operators in knowledge-\nintensive tasks, making it easier to access relevant information,\nshare new knowledge, and make informed decisions rapidly.\nWhile LLMs oﬀer promising capabilities, their application\nin manufacturing is not straightforward. The speciﬁc, dynamic\nknowledge required in this domain poses unique challenges (\nFeng\net al., 2017 ). For instance, a foundational LLM may have limited\nutility in a factory setting without signiﬁcant customization, such\nas ﬁne-tuning or incorporating speciﬁc context information into\nits prompts (\nWang Z. et al., 2023 ). Additionally, the practical and\nsocio-technical risks and challenges of deploying LLMs in such\nenvironments remain largely unexplored—factors key to human-\ncentered AI (\nShneiderman, 2022 ). Concerns include the accuracy\nof the information provided, the potential for “hallucinated\"\nanswers (\nZuccon et al., 2023 ), and the need for systems that can\nadapt to the highly specialized and evolving knowledge base of a\nspeciﬁc manufacturing setting (\nFeng et al., 2017 ).\nIn response to these challenges, we developed an LLM-powered\ntool to leverage factory documents and issue analysis reports to\nanswer operators’ queries. Furthermore, the tool facilitates the\nanalysis and reporting of new issues. This tool demonstrates the\nfeasibility of using LLMs to enhance knowledge management\nin manufacturing settings. To understand its eﬀectiveness and\npotential, we conducted a user study in a factory environment,\nevaluating the system’s usability, user perceptions, adoption, and\nimpact on factory operations.\nOur approach also addresses the lack of speciﬁc benchmarks\nfor evaluating LLMs in manufacturing. We benchmarked several\nLLMs, including both closed and open-source models, recognizing\nthat the standard benchmarks\n/one.tnumprimarily focus on general\nknowledge and reasoning. As such, they may not adequately\nreﬂect the challenges of understanding manufacturing-speciﬁc\nterminology and concepts. This benchmarking focused on their\nability to utilize factory-speciﬁc documents and unstructured\nissue reports to provide factual and complete answers to\noperators’ queries.\n/two.tnum Background\nIn this section, we address the topic of industry 5.0, LLM-\npowered tools for knowledge management, benchmarking LLMs,\nand the research questions informing this work.\n/one.tnumhttps://huggingface.co/spaces/HuggingFaceH/four.tnum/open_llm_leaderboard\n(accessed February /two.tnum/six.tnum, /two.tnum/zero.tnum/two.tnum/four.tnum).\n/two.tnum./one.tnum Human-centered manufacturing\nIndustry 5.0, the latest phase of industrial development, places\nhuman beings at the forefront of manufacturing processes,\nemphasizing their skills, creativity, and problem-solving\nabilities (\nXu et al., 2021 ; Maddikunta et al., 2022 ; Alves et al.,\n2023). Human-centered manufacturing in Industry 5.0 focuses on\nproviding a work environment that nurtures individuals’ creativity\nand problem-solving capabilities (\nMaddikunta et al., 2022 ). It\nencourages workers to think critically, innovate, and continuously\nlearn. With machines handling repetitive and mundane tasks,\nhuman workers can dedicate their time and energy to more\ncomplex and intellectually stimulating activities. This shift could\nenhance job satisfaction and promote personal and professional\ngrowth, as workers could acquire new skills and engage in higher-\nlevel decision-making (\nXu et al., 2021 ; Alves et al., 2023 ). Emphasis\non human-machine collaboration and the continuous emergence\nand reﬁnement of technology increases the need for adequate\nhuman-computer interaction (\nBrückner et al., 2023 ). One of the\napproaches to address this topic is using conversational AI to assist\nhumans in manufacturing (\nWellsandt et al., 2021 ).\n/two.tnum./two.tnum LLM-powered knowledge\nmanagement tools\nTraining Large Language Models (LLMs) on numerous, diverse\ntexts results in the embedding of extensive knowledge (\nZhao\net al., 2023 ). LLMs can also adeptly interpret complex\ninformation ( Jawahar et al., 2019 ), general reasoning ( Wei\net al., 2022a ), and aiding knowledge-intensive decision-making.\nConsequently, researchers have been exploring applying LLM-\npowered tools in domain-speciﬁc tasks (\nWen et al., 2023 ; Xie T.\net al., 2023 ; Zhang W. et al., 2023 ).\nDespite their potential beneﬁts, the responses generated by\nLLMs may have two potential issues: (1) outdated information\noriginating from the model’s training date, and (2) inaccuracies in\nfactual representation, known as “hallucinations” (\nBang et al., 2023 ;\nZhao et al., 2023 ). To address these challenges and leverage the\ncapabilities of LLMs in domain-speciﬁc knowledge-intensive tasks,\nseveral techniques can be used, such as chain-of-thought (\nWei et al.,\n2022b), few-shot prompting ( Brown et al., 2020 ; Gao et al., 2021 ),\nand retrieval augmented generation ( Lewis et al., 2020 ).\nUsing few-shot prompting to retrieve information across\ndiverse topics, Semnani et al. (2023) introduced an open-domain\nLLM-powered chatbot called WikiChat. WikiChat utilizes a 7-stage\npipeline of few-shot prompted LLM that suggests facts veriﬁed\nagainst Wikipedia, retrieves additional up-to-date information,\nand generates coherent responses. They used a hybrid human-\nand-LLM method to evaluate the chatbot on diﬀerent topics\nfor factuality, alignment with real-worth truths and veriﬁable\nfacts, and conversationality. This compound metric scores how\ninformational, natural, non-repetitive, and temporally correct\nthe response is. Their solution signiﬁcantly outperforms GPT-\n3.5 in factuality, with an average improvement of 24.4% while\nstaying on par in conversationality. Others have explored the\ncapabilities of LLMs in domain-speciﬁc tasks such as extracting\nFrontiers in Artiﬁcial Intelligence /zero.tnum/two.tnum frontiersin.org\nKernan Freire et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nstructured data from unstructured healthcare texts ( Tang et al.,\n2023), providing medical advice ( Nov et al., 2023 ), simplifying\nradiology reports ( Jeblick et al., 2023 ), Legal Judgement Prediction\nfrom multilingual legal documents ( Trautmann et al., 2022 ), and\nscientiﬁc writing ( Alkaissi and McFarlane, 2023 ).\nSeveral manufacturers are cautiously adopting LLMs,\nwhile seeking solutions to mitigate their associated risks. For\nexample,\n/two.tnumused AI with ChatGPT integrated through Azure\nOpenAI Service to enhance quality management and process\noptimization in vehicle production. This AI-driven approach\nsimpliﬁes complex evaluations for quality engineers through\ndialogue-based queries.\nXia et al. (2023) demonstrated how\nusing in-context learning and injecting task-speciﬁc knowledge\ninto an LLM can streamline intelligent planning and control of\nproduction processes.\nKernan Freire et al. (2023a) built a proof of\nconcept for bridging knowledge gaps among workers by utilizing\ndomain-speciﬁc texts and knowledge graphs.\nWang X. et al.\n(2023) conducted a systematic test of ChatGPT’s responses to\n100 questions from course materials and industrial documents.\nThey used a zero-shot method and examined the responses’\ncorrectness, relevance, clarity, and comparability. Their results\nsuggested areas for improvement, including low scores when\nresponding to critical analysis questions, occasional non-factual or\nout-of-manufacturing scope responses, and dependency on query\nquality. Although\nWang X. et al. (2023) provides a comprehensive\nreview of ChatGPT’s abilities to answer questions related to\nmanufacturing; it did not include the injection of task-speciﬁc\nknowledge into the prompts.\nTo improve the performance of an LLM for domain-speciﬁc\ntasks, relevant context information can be automatically injected\nalong with a question prompt. This technique, known as Retrieval\nAugmented Generation (RAG), involves searching a corpus for\ninformation relevant to the user’s query and inserting it into a query\ntemplate before sending it to the LLM (\nLewis et al., 2020 ). Using\nRAG also enables further transparency and explainability of the\nLLM’s response. Namely, users can check the referenced documents\nto verify the LLM’s response. Factories will likely have a large\ncorpus of knowledge available in natural language, such as standard\nwork instructions or machine manuals. Furthermore, factory\nworkers continually add to the pool of available knowledge through\n(issue) reports. Until recently, these reports were considered\nunusable by AI natural language processing due to quality issues\nsuch as poorly structured text, inconsistent terminology, or\nincompleteness (\nEdwards et al., 2008 ; Müller et al., 2021 ). However,\nthe leap in natural language understanding that LLMs, such as\nChatGPT, have brought about can overcome these issues.\n/two.tnum./three.tnum Evaluating LLMs\nLarge Language Model evaluation requires the deﬁnition of\nevaluation criteria, metrics, and datasets associated with the\nsystem’s main tasks. There are two types of LLM evaluations:\nintrinsic and extrinsic evaluation. Intrinsic evaluation focuses\non the internal properties of a Language Model (\nWei et al.,\n/two.tnumhttps://group.mercedes-benz.com/innovation/digitalisation/industry-\n/four.tnum-/zero.tnum/chatgpt-in-vehicle-production.html(accessed February /two.tnum/six.tnum, /two.tnum/zero.tnum/two.tnum/four.tnum).\n2023). It means the patterns and language structures learned\nduring the pre-training phase. Extrinsic evaluation focuses on the\nmodel’s performance in downstream tasks, i.e., in the execution\nof speciﬁc tasks that make use of the linguistic knowledge gained\nupstream, like code completion (\nXu et al., 2022 ). Despite extrinsic\nevaluation being computationally expensive, only conducting\nintrinsic evaluation is not comprehensive, as it only tests the\nLLMs capability for memorization (\nJang et al., 2022 ). Here, we\nfocus on extrinsic evaluation as we are primarily interested in the\nperformance of LLM-based tools for speciﬁc real-world tasks.\nExtrinsic evaluation implies assessing the systems’s\nperformance in tasks such as question answering, translation,\nreading comprehension, and text classiﬁcation, among\nothers (\nKwon and Mihindukulasooriya, 2022 ). Existing\nbenchmarks such as LAMBADA, HellaSwag, TriviaQA, BLOOM,\nGalactica, ClariQ and MMLU, among others, are widely reported\nin the literature for comparing language models. Likewise, domain-\nspeciﬁc Benchmarks for tasks such as medical (\nSinghal et al., 2023 ),\nfairness evaluation ( Zhang J. et al., 2023 ), ﬁnance ( Xie Q. et al.,\n2023), robot policies ( Liang et al., 2022 ), and 3D printing code\ngeneration ( Badini et al., 2023 ) can also be found. Experts also\nevaluate the performance of large-language models (LLMs) in\nspeciﬁc downstream tasks, such as using physicians to evaluate the\noutput of medical speciﬁc LLMs (\nSinghal et al., 2023 ).\nLLM benchmarks range from speciﬁc downstream tasks to\ngeneral language tasks. However, to our knowledge, LLMs have not\nbeen benchmarked for answering questions in the manufacturing\ndomain based on context material, a technique known as Retrieval\nAugmented Generation (\nLewis et al., 2020 ). Material such as\nmachine documentation, standard work instructions, or issue\nreports will contain domain jargon and technical information that\nLLMs may struggle to process. Furthermore, the text in an issue\nreport may pose additional challenges due to abbreviations, poor\ngrammar, and formatting (\nEdwards et al., 2008 ; Oruç, 2020; Müller\net al., 2021 ). Therefore, as part of this work, we benchmarked\nseveral LLMs on their ability to answer questions based on\nfactory manuals and unstructured issue reports. Furthermore, we\nconducted a user study with factory operators and managers to\nassess the potential beneﬁts, risks and challenges. The following\nresearch questions informed our study:\n1. What are the perceived beneﬁts, challenges, and risks of using\nLarge Language Models for information retrieval and knowledge\nsharing for factory operators?\n2. How do Large Language Models compare in performance\nwhen answering factory operators’ queries based on factory\ndocumentation and unstructured issue reports? We consider\nperformance as the factuality, completeness, hallucinations, and\nconciseness of the generated response.\n/three.tnum System\nWe built a fully functional system to assess the potential\nof using LLMs for information retrieval and knowledge sharing\nfor factory operators. Beneﬁting from LLMs’ in-context learning\ncapabilities, we use this to supply an LLM with information in the\nform of factory manuals, and issue reports relevant to the user’s\nquestion, a technique known as Retrieval Augmented Generation\nFrontiers in Artiﬁcial Intelligence /zero.tnum/three.tnum frontiersin.org\nKernan Freire et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nFIGURE /one.tnum\nThe steps of Retrieval Augmented Generation (RAG) from user quer y\nto response.\n(RAG) ( Lewis et al., 2020 ), see Figure 1. As noted by Wei et al.\n(2022a), training LLMs using a prompt packed with query-related\ninformation can yield substantial performance enhancement. Users\ncan ask questions in the chat box by typing or using voice input.\nThe response is displayed at the top of the page, and the document\nchunks used for the answer can be checked at the bottom (see\nFigure 2).\n/three.tnum./one.tnum Tool dependencies\nThe tool was constructed utilizing two innovative\ntechnologies—Gradio and LlamaIndex. Gradio, a tool developed\nby\nAbid et al. (2019), serves as the backbone for both our front\nand back ends. Primarily used to simplify the development and\ndistribution of machine learning applications, Gradio allows the\nquick creation of intuitive, user-friendly web interfaces for machine\nlearning models.\nAdditionally, we use LlamaIndex, created by\nLiu (2022), for\nretrieving the context material in response to the user queries and\nhandling the queries to the LLM. LlamaIndex, initially known as\nGPT Index, is a cutting-edge data framework designed for the\neﬃcient handling and accessibility of private or domain-speciﬁc\ndata in LLMs applications.\nSince the factory documents can be long, they may overﬂow\nthe LLM’s context window or result in unnecessary computational\ndemand. To overcome this, we segment the materials into\nmanageable chunks, each comprising ∼ 400 tokens. This method\neﬀectively incorporates the materials into the LLM prompt without\ncompromising the conversation ﬂow. Following the segmentation,\neach document chunk is processed through LlamaIndex using the\nOpenAI Embedding API.\n/three.tnumUtilizing the “text-embedding-ada-002”\nmodel, LlamaIndex transforms each chunk into a corresponding\nembedding vector. These resulting vectors are then securely stored,\nready for future retrieval and use.\n/three.tnum./two.tnum Knowledge base construction\nOur experiment incorporates two distinct types of domain-\nspeciﬁc data: factory manuals and shared knowledge from\nfactory workers. Factory manuals outline information on machine\noperation, safety protocols, quality assurance, and more. These\nresources, provided by factory management teams, initialize the\nknowledge base for each speciﬁc factory. The materials come in\nvarious formats, including PDF, Word, and CSV ﬁles.\nIn addition to the factory manuals, we integrate issue analysis\nreports from factory workers. This information is gathered from\nthe production line, utilizing the ﬁve-why process, an iterative root-\ncause analysis technique (\nSerrat, 2017 ) (right side of Figure 2).\nThe ﬁve-why technique probes into cause-and-eﬀect relationships\nunderlying speciﬁc problems by repeatedly asking “Why?\" until the\nroot cause is revealed, typically by the ﬁfth query. This process\nenables us to gather real-world issues encountered on production\nlines, which may not be covered in the factory manuals. Upon\nentering all required information, including one or more “whys”,\nthe operator presses “check”, triggering a prompt to the LLM that\nperforms a logical check of the entered information and checks for\ninconsistencies with previously reported information. The operator\ncan revise the entered information and submit it as is. Then, the\nsubmitted report will be added to a queue for expert operators to\ncheck before it is added to the knowledge base.\n/three.tnum./three.tnum Query construction\nTo retrieve the document data relevant to speciﬁc user queries,\nwe employ the same embedding model, “text-embedding-ada-002”\nto generate vector representations of these queries. By leveraging\nthe similarity calculation algorithm provided by LlamaIndex, we\ncan identify and retrieve the top-K most similar segmented\ndocument snippets related to the user query. This allows us to\nconstruct pertinent LLM queries. Once the snippets are retrieved,\nthey are synthesized into the following query template based on the\ntemplates used by LlamaIndex\n/four.tnum:\nYou are an assistant that assists detergent production line\noperators with decision support and advice based on a\nknowledge base of standard operating procedures, single point\nlessons (SPL), etc. We have provided context information below\nfrom relevant documents and reports.\n[Retrieved Document Snippets]\nGiven this information, please answer the following question:\n[Query]\n/three.tnumhttps://api.openai.com/v/one.tnum/embeddings(accessed February /two.tnum/six.tnum, /two.tnum/zero.tnum/two.tnum/four.tnum).\n/four.tnumhttps://docs.llamaindex.ai (accessed February /two.tnum/six.tnum, /two.tnum/zero.tnum/two.tnum/four.tnum).\nFrontiers in Artiﬁcial Intelligence /zero.tnum/four.tnum frontiersin.org\nKernan Freire et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nFIGURE /two.tnum\nThe main screens for the tool’s interface are the chat interface and issue analysis screen. The “relevant document sections” part is blurred for\nconﬁdentiality as it shows the title of a company’s document and it s content.\nIf the provided context does not include relevant information\nto answer the question, please do not respond.\nHowever, considering our data originates from two distinct\nsources—factory manuals and shared tactical knowledge—we have\ndecided to segregate these into two separate LLM queries. This\napproach is designed to prevent potential user confusion from\ncombining data from both sources into a single query.\n/four.tnum User study in the ﬁeld\nWe conducted a user study on the system to uncover perceived\nbeneﬁts, usability issues, risks, and barriers to adoption. The study\ncomprised four tasks: (1) ask the system several questions about\nhow to solve a speciﬁc production issue and/or perform a standard\nprocedure, (2) complete a “yellow tag” (issue analysis report) based\non a recent issue, (3) request a logical check of the completed report,\nand ﬁnally, (4) upload new documents to the system. After each\ntask, they were asked to provide feedback. Then, after completing\nall tasks, the participants were posed several open questions\nabout the system’s beneﬁts, risks, and barriers to adoption.\nFinally, demographic information, such as age, gender, and role,\nwas collected.\n/four.tnum./one.tnum Participants\nWe recruited N = 9 participants from a detergent factory, of\nwhich n = 4 were managers (P1-4), and n = 5 were operators (P5-\n9). Of the nine participants, n = 3 were women, and n = 6 were\nmen. Participant age was distributed over three brackets, namely\nn = 2 were 30–39, n = 4 were 40–49, and n = 3 were 50–59.\n/four.tnum./two.tnum Qualitative analysis\nAn inductive thematic analysis (\nGuest et al., 2011 ) of the\nanswers to the open questions resulted in six themes discussed\nbelow.\n• Usability: the theme of usability underlines the system’s ease of\nuse and the need for clear instructions. Users mentioned the\nnecessity for a “user-friendly” (P2) interface and highlighted\nthe importance of having “more instructions and more details\nneed to be loaded” (P1) to avoid confusion. This indicates a\ndesire for intuitive navigation that could enable workers to use\nthe system eﬀectively without extensive training or referencing\nexternal help. The feedback suggests that the system already\nFrontiers in Artiﬁcial Intelligence /zero.tnum/five.tnum frontiersin.org\nKernan Freire et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nworks well, as reﬂected in statements like “Easy-to-use system”\n(P3) and the system “works well” (P7).\n• Access to information : users appreciated the “ease of having\ninformation at hand” (P1), facilitating immediate access to\nnecessary documents. However, there is a clear call for\nimprovements, such as the ability to “Include the possibility\nof opening IO, SPL, etc. in pdf format for consultation”\n(P3). This theme is supported by requests for direct links\nto full documents, suggesting that while “the list of relevant\ndocuments from which information is taken is excellent”\n(P4), the ability to delve deeper into full documents would\nsigniﬁcantly enhance the user experience.\n• Eﬃciency : users value the “greater speed in carrying out some\nsmall tasks” (P3). However, there are concerns about the\nsystem’s eﬃciency when it does not have the answer, leading\nto “wasting time looking for a solution to a problem in case\nit is not reported in the system’s history” (P3). Statements like\n“quick in responses” (P3) contrast with the need for questions\nto be “too speciﬁc to have a reliable answer” (P7), indicating\ntension between the desire for quick solutions and the system’s\nlimitations.\n• Adoption: users highlight several factors aﬀecting adopting\nthe new system. It includes challenges such as “awareness and\ntraining of operators [might hinder adoption]” (P3) and the\nneed for “acceptance by all employees” (P4), which indicates\nthat the system’s success is contingent on widespread user\nbuy-in. The generational divide is also noted: “That older\noperators use it [on what may hinder adoption]” (P7) suggests\nthat demographic factors may inﬂuence the acceptance of new\ntechnology.\n• Safety: a manager expressed apprehension that “if the\nresponses are not adequate, you risk safety” (P1), emphasizing\nthe critical nature of reliable information in a high-risk factory\nsetting. Beyond information being outdated or useless, the\npossibility of “hallucinated” responses leading to dangerous\nsituations in a factory that processes chemicals is especially\nconcerning.\n• Traditional vs. novel : there is a noticeable preference\nfor established practices among some users. For instance,\n“It’s faster and easier to ask an expert colleague working\nnear me rather than [the system]” (P8) captures the\nreliance on human expertise over the assistant system.\nThis tension is further demonstrated by the sentiment that\n“Operators may beneﬁt more from traditional information\nretrieval systems” (P9), suggesting a level of skepticism or\ncomfort with the status quo that the new system needs\nto overcome.\n/five.tnum LLM benchmarking\nIn our benchmarking experiment, we evaluated various\ncommercial and open-source LLMs, including OpenAI’s ChatGPT\n(GPT-3.5 and GPT-4 from July 20th 2023), Guanaco 65B and\n35B variants (\nDettmers et al., 2023 ) based on Meta’s Llama\n(Large Language Model Meta AI) ( Touvron et al., 2023 ), Mixtral\n8x7b ( Jiang et al., 2024 ), Llama 2 ( Touvron et al., 2023 ), and\none of its derivatives, StableBeluga2 /five.tnum. This selection represents\nthe state-of-the-art closed-sourced models (e.g., GPT-4) and open-\nsource models (e.g., Llama 2). We included the (outdated) Guanaco\nmodels to demonstrate the improvements in the open-source\nsphere over the past year.\nWe used a web UI for LLMs\n/six.tnumto load and test the Mixtral 8x7B,\nGuanaco models, and the StableBeluga2. The models were loaded\non a pair of Nvidia A6000s with NVlink and a total Video Random\nAccess Memory (VRAM) capacity of 96 GB. The 65B model was\nrun in 8-bit mode to ﬁt in the available VRAM. We used the llama-\nprecise parameter preset and ﬁxed zero seed for reproducibility.\nLlama 2 was evaluated using the demo on huggingface.\n/seven.tnum\nTo rigorously assess the models, we prepared 20 questions of\nvarying complexity based on two types of context material: half\nfrom operating manuals and half from unstructured issue reports.\nThe operating manuals included excerpts from actual machine\nmanuals and standard operating procedures, while the informal\nissue reports were free-text descriptions of issues we had previously\ncollected from operators. The model prompt was constructed using\nthe above template (3.3). Ultimately, the diﬃculty of a question is\na combination of the question’s complexity and the clarity of the\nsource material. Simple questions include retrieving a single piece\nof information clearly stated in the context material, for example,\n“At what temperature is relubrication necessary for the OKS 4220\ngrease?\". Conversely, diﬃcult questions require more reasoning\nor comprise multiple parts, for example, “What should I do if\nthe central turntable is overloaded?\" which has a nuanced answer\ndependent on several factors not clearly articulated in the context\nmaterial.\nIn addition to measuring response length in words, every\nresponse is manually scored on factuality, completeness, and\nhallucinations as deﬁned below:\n• Factuality: responses align with the facts in the context\nmaterial.\n• Completeness: responses contain all the information relevant\nto the question in the context material.\n• Hallucinations: response appears grammatically and\nsemantically coherent but is not based on the context\nmaterial.\nThe following scoring protocol is applied: one is awarded\nfor a completely factual, complete, or hallucinated response. In\ncontrast, a score of 0.5 is awarded for a slightly nonfactual,\nincomplete, or hallucinated response (e.g., the response includes\nfour out of the ﬁve correct steps). Otherwise, a score of zero is\nawarded. Therefore, wrong answers are penalized heavily. If the\nmodel responds by saying it cannot answer the question and does\nnot make any attempt to do so, it is scored zero for factuality\nand completeness, but no score is given for hallucination. As\n/five.tnumhttps://huggingface.co/stabilityai/StableBeluga/two.tnum(accessed February /two.tnum/six.tnum,\n/two.tnum/zero.tnum/two.tnum/four.tnum).\n/six.tnum\nhttps://github.com/oobabooga/text-generation-webui/tree/main\n(accessed February /two.tnum/six.tnum, /two.tnum/zero.tnum/two.tnum/four.tnum).\n/seven.tnum\nhttps://huggingface.co/meta-llama/Llama-/two.tnum-/seven.tnum/zero.tnumb-chat-hf(accessed\nFebruary /two.tnum/six.tnum, /two.tnum/zero.tnum/two.tnum/four.tnum).\nFrontiers in Artiﬁcial Intelligence /zero.tnum/six.tnum frontiersin.org\nKernan Freire et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nFIGURE /three.tnum\nBenchmark of seven LLMs for generating answers based on factory ma terials.\nTABLE /one.tnumModel benchmarking scores (out of /one.tnum/zero.tnum/zero.tnum) and average response length.\nModel Factuality Completeness Hallucinations Words\nGPT-4 97.5 95 0 69\nStableBeluga2 95 92.5 7.5 58\nMixtral 8x7B 92.5 92.5 2.5 66\nGPT-3.5 90 90 5 89\nLlama 2 77.5 82.5 13 128\nGuanaco 65B 55 39.5 65 131\nGuanaco 33b 27.5 27.5 65.6 190\nsuch, the ﬁnal score for hallucination is calculated as follows:\ncorrected score = score\n20− number of unanswered questions × 100\nAs shown in Figure 3 and Table 1, GPT-4 outperforms\nother models regarding factuality, completeness, and lack of\nhallucinations but is closely followed by StableBeluga2 and GPT-\n3.5. The Guanaco models, based on Llama 1, perform signiﬁcantly\nworse. The conciseness of the responses showed a similar pattern,\nexcept that StableBeluga2 produced the shortest answers (58\nwords), followed closely by Mixtral 8x7B (66 words) and GPT-4 (69\nwords).\n/six.tnum Discussion\n/six.tnum./one.tnum GPT-/four.tnum is the best, but open-source\nmodels follow closely\nGPT-4 performs best across all measures but is closely followed\nby StableBeluga2, Mixtral 8x7B, and GPT-3.5. Compared to GPT-\n4, the cost per input token for GPT-3.5 is signiﬁcantly lower.\n/eight.tnum\nHowever, the higher costs of GPT-4 are partially counteracted by its\n/eight.tnumhttps://openai.com/pricing#language-models (accessed February /two.tnum/six.tnum,\n/two.tnum/zero.tnum/two.tnum/four.tnum).\nconcise yet complete responses. If longer, more detailed responses\nwere desired (e.g., for training purposes), the prompt could be\nadjusted. We observed that the less powerful models, such as GPT-\n3.5 and Llama 2, tended to be wordier and include additional details\nthat were not directly requested. In contrast, GPT-4, StableBeluga2,\nand Mixtral 8x7B generated more concise responses.\nThe latest generation of open-source models, such as Mixtral\n8x7B and Llama 2 variants, such as StableBeluga2, demonstrates a\nclear jump forward relative to their predecessors based on Llama-\n1, which were more prone to hallucinations and exhibited poorer\nreasoning abilities over the context material. While open-source\nmodels like StableBeluga2 and Mixtral 8x7B do not score as high as\nGPT-4, they ensure better data security, privacy, and customization\nif hosted locally. This can be a crucial consideration for companies\nwith sensitive data or unique needs.\n/six.tnum./two.tnum The tool is beneﬁcial but inferior to\nhuman experts\nUsers appreciate the system’s functionality and see it as a tool\nfor modernizing factory operations and speeding up operations.\nThey are keen on improvements to be made for better user\nFrontiers in Artiﬁcial Intelligence /zero.tnum/seven.tnum frontiersin.org\nKernan Freire et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nexperience and utility, especially in the areas of content, feature\nenhancements, and user training. However, they express concerns\nabout potential safety risks and the eﬃcacy of information retrieval\ncompared to consulting expert personnel. While these concerns\nare understandable, the tool was not designed to replace human-\nhuman interactions; instead, it can be used when no human experts\nare present or when they do not know or remember how to solve a\nspeciﬁc issue. This would come into play during the night shift at\nthe factory where we conducted the user study as a single operator\noperates a production line, leaving limited options for eliciting help\nfrom others.\n/six.tnum./three.tnum Limitations and future work\nWe used the same prompt for all LLMs; however, it is\npossible that some of the LLMs would perform better with a\nprompt template developed explicitly for it. For consistency, we\nmatched the LLMs’ hyperparameters (e.g., temperature) as closely\nas possible across all the tested models, except for Llama 2, as\nwe did not have access to the presets as we did not host it\nlocally. Our model benchmarking procedure involved 20 questions,\nand a singular coder assessed the responses. This introduces the\npotential for bias, and the limited number of questions may not\ncover the full spectrum of complexities in real-world scenarios.\nTo mitigate these shortcomings, we varied query complexity and\nsource material types.\nThe study’s design did not include a real-world evaluation\ninvolving end users operating the production line, as this was\nconsidered too risky for our industry partner. Such an environment\nmight present unique challenges and considerations not addressed\nin this research, such as time pressure. Yet, by involving operators\nand managers and instructing them to pose several questions based\non their actual work experience, we could still evaluate the system\nand collect valid feedback.\nThese limitations suggest directions for future research, for\nexample, longitudinal studies where operators use the tool during\nproduction line operations and more comprehensive prompt\nand model customization. Longitudinal studies will be key to\nunderstanding the real-world impact on production performance,\noperator wellbeing, and cognitive abilities.\n/seven.tnum Conclusion\nThe results demonstrated GPT-4’s superior performance\nover other models regarding factuality, completeness, and\nminimal hallucinations. Interestingly, open-source models like\nStableBeluga2 and Mixtral 8x7B followed close behind. The user\nstudy highlighted the system’s user-friendliness, speed, and logical\nfunctionality. However, improvements in the user interface and\ncontent speciﬁcity were suggested, along with potential new\nfeatures. Beneﬁts included modernizing factory operations and\nspeeding up speciﬁc tasks, though concerns about safety, eﬃciency,\nand inferiority to asking human experts were raised.\nData availability statement\nThe raw data supporting the conclusions of this article will be\nmade available by the authors, without undue reservation.\nEthics statement\nThe studies involving humans were approved by Human\nResearch Ethics Committee (HREC) from TU Delft. The\nstudies were conducted in accordance with the local\nlegislation and institutional requirements. The participants\nprovided their written informed consent to participate in\nthis study.\nAuthor contributions\nSK: Writing – original draft, Visualization, Software, Project\nadministration, Methodology, Investigation, Formal analysis, Data\ncuration, Conceptualization. CW: Writing – original draft,\nSoftware, Methodology, Conceptualization. MF: Writing – original\ndraft. SW: Writing – original draft. SR-A: Writing – original\ndraft. EN: Writing – review & editing, Supervision, Methodology,\nConceptualization.\nFunding\nThe author(s) declare ﬁnancial support was received for\nthe research, authorship, and/or publication of this article.\nThis work was supported by the European Union’s Horizon\n2020 research and innovation program via the project COALA\n“COgnitive Assisted agile manufacturing for a LAbor force\nsupported by trustworthy Artiﬁcial Intelligence” (Grant\nagreement 957296).\nConﬂict of interest\nThe authors declare that the research was conducted\nin the absence of any commercial or ﬁnancial relationships\nthat could be construed as a potential conﬂict\nof interest.\nPublisher’s note\nAll claims expressed in this article are solely those\nof the authors and do not necessarily represent those of\ntheir aﬃliated organizations, or those of the publisher,\nthe editors and the reviewers. Any product that may be\nevaluated in this article, or claim that may be made by\nits manufacturer, is not guaranteed or endorsed by the\npublisher.\nFrontiers in Artiﬁcial Intelligence /zero.tnum/eight.tnum frontiersin.org\nKernan Freire et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nReferences\nAbid, A., Abdalla, A., Abid, A., Khan, D., Alfozan, A., and Zou, J .\n(2019). Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild .\ndoi: 10.48550/arXiv.1906.02569\nAlkaissi, H., and McFarlane, S. I. (2023). Artiﬁcial hallucinat ions in chatgpt:\nimplications in scientiﬁc writing. Cureus 15:e35179. doi: 10.7759/cureus.35179\nAlves, J., Lima, T. M., and Gaspar, P. D. (2023). Is industry 5.0 a human-centred\napproach? A systematic review. Processes 11. doi: 10.3390/pr11010193\nBadini, S., Regondi, S., Frontoni, E., and Pugliese, R. (2023 ). Assessing the\ncapabilities of chatgpt to improve additive manufacturing trou bleshooting. Adv. Ind.\nEng. Polym. Res . 6, 278–287. doi: 10.1016/j.aiepr.2023.03.003\nBang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., et al. (2023). A\nmultitask, multilingual, multimodal evaluation of chatgpt on reas oning, hallucination,\nand interactivity. arXiv. doi: 10.18653/v1/2023.ijcnlp-main.45\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhar iwal, P., et al. (2020).\n“Language models are few-shot learners, ” in Advances in Neural Information Processing\nSystems, Vol. 33 , eds H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin (R ed\nHook, NY: Curran Associates, Inc.), 1877–1901.\nBrückner, A., Hein, P., Hein-Pensel, F., Mayan, J., and Wölke, M. (2023). “Human-\ncentered hci practices leading the path to industry 5.0: a syste matic literature review, ”\nin HCI International 2023 Posters , eds C. Stephanidis, M. Antona, S. Ntoa, and G.\nSalvendy (Cham: Springer Nature Switzerland), 3–15.\nDettmers, T., Pagnoni, A., Holtzman, A., and Zettlemoyer, L. ( 2023). Qlora: Eﬃcient\nFinetuning of Quantized Llms . doi: 10.48550/arXiv.2305.14314\nEdwards, B., Zatorsky, M., and Nayak, R. (2008). Clustering a nd classiﬁcation of\nmaintenance logs using text data mining. Data Mining Anal . 87, 193–199.\nFantini, P., Pinzone, M., and Taisch, M. (2020). Placing the o perator at the centre\nof industry 4.0 design: modelling and assessing human activit ies within cyber-physical\nsystems. Comp. Ind. Eng . 139:105058. doi: 10.1016/j.cie.2018.01.025\nFeng, S. C., Bernstein, W. Z., Thomas Hedberg, J., and Feeney , A. B. (2017).\nToward knowledge management for smart manufacturing. J. Comp. Inf. Sci. Eng . 17:3.\ndoi: 10.1115/1.4037178\nGao, T., Fisch, A., and Chen, D. (2021). “Making pre-trained la nguage models\nbetter few-shot learners, ” in Proceedings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th International Joint Con ference on Natural\nLanguage Processing (Volume 1: Long Papers) (Association for Computational\nLinguistics), 3816–3830.\nGröger, C., Schwarz, H., and Mitschang, B. (2014). “The manuf acturing\nknowledge repository - consolidating knowledge to enable holisti c process knowledge\nmanagement in manufacturing, ” in Proceedings of the 16th International Conference\non Enterprise Information Systems (SCITEPRESS - Science and and Technology\nPublications), 39–51. doi: 10.5220/0004891200390051\nGuest, G., MacQueen, K. M., and Namey, E. E. (2011). Applied thematic analysis.\nThousand Oaks, CA: Sage Publications.\nJang, J., Ye, S., Lee, C., Yang, S., Shin, J., Han, J., et al. (20 22). Temporalwiki: a\nlifelong benchmark for training and evaluating ever-evolving la nguage models. arXiv.\ndoi: 10.18653/v1/2022.emnlp-main.418\nJawahar, G., Sagot, B., and Seddah, D. (2019). “What does BERT learn about the\nstructure of language?, ” in Proceedings of the 57th Annual Meeting of the Association\nfor Computational Linguistics (Florence. Association for Computational Linguistics),\n3651–3657.\nJeblick, K., Schachtner, B., Dexl, J., Mittermeier, A., Stübe r, A. T., Topalis, J., et\nal. (2023). ChatGPT makes medicine easy to swallow: an exploratory case study on\nsimpliﬁed radiology reports. Eur. Radiol. 1–9. doi: 10.1007/s00330-023-10213-1\nJiang, A. Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B. , Bamford, C., et al.\n(2024). Mixtral of Experts . doi: 10.48550/arXiv.2401.04088\nKernan Freire, S., Foosherian, M., Wang, C., and Niforatos, E. (2023a). “Harnessing\nlarge language models for cognitive assistants in factories, ” in Proceedings of the 5th\nInternational Conference on Conversational User Interfaces, CUI ’23 (New York, NY:\nAssociation for Computing Machinery). doi: 10.1145/357188 4.3604313\nKernan Freire, S., Wang, C., Ruiz-Arenas, S., and Niforatos , E. (2023b). “Tacit\nknowledge elicitation for shop-ﬂoor workers with an intelligent a ssistant, ” inExtended\nAbstracts of the 2023 CHI Conference on Human Factors in Computing Systems , 1–7.\nKwon, B. C., and Mihindukulasooriya, N. (2022). “An empirical study\non pseudo-log-likelihood bias measures for masked language mode ls using\nparaphrased sentences, ” in TrustNLP 2022 - 2nd Workshop on Trustworthy Natural\nLanguage Processing, Proceedings of the Workshop (New York, NY), 74–79.\ndoi: 10.1145/3544549.3585755\nLeoni, L., Ardolino, M., El Baz, J., Gueli, G., and Bacchetti, A. ( 2022). The\nmediating role of knowledge management processes in the eﬀecti ve use of artiﬁcial\nintelligence in manufacturing ﬁrms. Int. J. Operat. Prod. Manag . 42, 411–437.\ndoi: 10.1108/IJOPM-05-2022-0282\nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., et al. (2020).\n“Retrieval-augmented generation for knowledge-intensive n lp tasks, ” in Proceedings of\nthe 34th International Conference on Neural Information Processing Sys tems, NIPS’20\n(Red Hook, NY: Curran Associates Inc.).\nLiang, J., Huang, W., Xia, F., Xu, P., Hausman, K., Ichter, B. , et al.\n(2022). Code as Policies: Language Model Programs for Embodied Control .\ndoi: 10.48550/arXiv.2209.07753\nLiu, J. (2022). LlamaIndex. Available online at: https://github.com/jerryjliu/llama_\nindex\nMaddikunta, P. K. R., Pham, Q.-V., B, P., Deepa, N., Dev, K., Ga dekallu, T. R., et\nal. (2022). Industry 5.0: a survey on enabling technologies and potential applications. J.\nInd. Inf. Integr . 26:100257. doi: 10.1016/j.jii.2021.100257\nMay, G., Taisch, M., Bettoni, A., Maghazei, O., Matarazzo, A. , and Stahl,\nB. (2015). A new human-centric factory model. Proc CIRP 26, 103–108.\ndoi: 10.1016/j.procir.2014.07.112\nMüller, M., Alexandi, E., and Metternich, J. (2021). Digital sh op ﬂoor\nmanagement enhanced by natural language processing. Procedia CIRP 96, 21–26.\ndoi: 10.1016/j.procir.2021.01.046\nNov, O., Singh, N., and Mann, D. (2023). Putting Chatgpt’s Medical Advice to the\n(Turing) Test. doi: 10.48550/arXiv.2301.10035\nOruç, O. (2020). A semantic question answering through heter ogeneous data source\nin the domain of smart factory. Int. J. Nat. Lang. Comput . 9.\nRichter, S., Waizenegger, L., Steinhueser, M., and Richter , A. (2019). Knowledge\nmanagement in the dark: the role of shadow IT in practices in man ufacturing. IJKM.\n15, 1–19. doi: 10.4018/IJKM.2019040101\nSemnani, S. J., Yao, V. Z., Zhang, H. C., and Lam, M. S. (2023). Wikichat: A Few-Shot\nLlm-Based Chatbot Grounded With Wikipedia . doi: 10.48550/arXiv.2305.14292\nSerrat, O. (2017). The Five Whys Technique. Knowledge Solutions: Tools, Methods,\nand Approaches to Drive Organizational Performance , 307–310.\nShneiderman, B. (2022). Human-Centered AI. Oxford: Oxford University Press.\nSinghal, K., Azizi, S., Tu, T., Mahdavi, S. S., Wei, J., Chung, H. W., et al.\n(2023). Large language models encode clinical knowledge. Nature 620, 172–180.\ndoi: 10.1038/s41586-023-06291-2\nTang, R., Han, X., Jiang, X., and Hu, X. (2023). Does Synthetic Data Generation of\nLlms Help Clinical Text Mining ? doi: 10.48550/arXiv.2303.04360\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei,\nY., et al. (2023). Llama 2: Open Foundation And ﬁne-Tuned Chat Models .\ndoi: 10.48550/arXiv.2307.09288\nTrautmann, D., Petrova, A., and Schilder, F. (2022). Legal Prompt Engineering for\nMultilingual Legal Judgement Prediction . doi: 10.48550/arXiv.2212.02199\nWang, X., Anwer, N., Dai, Y., and Liu, A. (2023a). Chatgpt for d esign,\nmanufacturing, and education. Proc. CIRP 119, 7–14. doi: 10.1016/j.procir.2023.04.001\nWang, Z., Yang, F., Zhao, P., Wang, L., Zhang, J., Garg, M., et al. (2023b).\nEmpower large language model to perform better on industrial dom ain-speciﬁc\nquestion answering. arXiv. doi: 10.18653/v1/2023.emnlp-industry.29\nWei, C., Wang, Y.-C., Wang, B., and Kuo, C. C. J. (2023). An Overview on Language\nModels: Recent Developments and Outlook . doi: 10.1561/116.00000010\nWei, J., Tay, Y., Bommasani, R., Raﬀel, C., Zoph, B., Borgeaud, S., et al. (2022a).\nEmergent Abilities of Large Language Models . doi: 10.48550/arXiv.2303.05759\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, b., Xia , F., et al. (2022b).\n“Chain-of-thought prompting elicits reasoning in large languag e models, ” inAdvances\nin Neural Information Processing Systems, Vol. 35 , eds S. Koyejo, S. Mohamed, A.\nAgarwal, D. Belgrave, K. Cho, and A. Oh (Red Hook, NY: Curran Ass ociates, Inc.),\n24824–24837.\nWellsandt, S., Hribernik, K., and Thoben, K.-D. (2021). “Anat omy of a digital\nassistant, ” in Advances in Production Management Systems. Artiﬁcial Intelligence for\nSustainable and Resilient Production Systems , eds A. Dolgui, A. Bernard, D. Lemoine,\nG. von Cieminski, and D. Romero (Cham: Springer International Publishing),\n321–330.\nWen, C., Sun, X., Zhao, S., Fang, X., Chen, L., and Zou, W.\n(2023). Chathome: development and evaluation of a domain-speci ﬁc\nlanguage model for home renovation. ArXiv. doi: 10.48550/arXiv.2307.1\n5290\nXia, Y., Shenoy, M., Jazdi, N., and Weyrich, M. (2023). Towar ds autonomous\nsystem: ﬂexible modular production system enhanced with large lan guage model\nagents. arXiv. doi: 10.1109/ETFA54631.2023.10275362\nXie, Q., Han, W., Zhang, X., Lai, Y., Peng, M., Lopez-Lira, A., et al. (2023a). Pixiu:\nA large language model, instruction data and evaluation benchma rk for ﬁnance. arXiv.\ndoi: 10.48550/arXiv.2306.05443\nFrontiers in Artiﬁcial Intelligence /zero.tnum/nine.tnum frontiersin.org\nKernan Freire et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/two.tnum/nine.tnum/three.tnum/zero.tnum/eight.tnum/four.tnum\nXie, T., Wan, Y., Huang, W., Yin, Z., Liu, Y., Wang, S., et al. (2 023b).\nDarwin series: domain speciﬁc large language models for natural science. arXiv.\ndoi: 10.48550/arXiv.2308.13565\nXu, F. F., Alon, U., Neubig, G., Hellendoorn, V. J., and Hel, V. J. (2 022). A systematic\nevaluation of large language models of code. arXiv. doi: 10.48550/arXiv.2202.13169\nXu, X., Lu, Y., Vogel-Heuser, B., and Wang, L. (2021). Industr y 4.0 and\nindustry 5.0—inception, conception and perception. J. Manuf. Syst . 61, 530–535.\ndoi: 10.1016/j.jmsy.2021.10.006\nZhang, J., Chen, Y., Niu, N., and Liu, C. (2023a). A preliminary evaluation of chatgpt\nin requirements information retrieval. arXiv. doi: 10.2139/ssrn.4450322\nZhang, W., Liu, H., Du, Y., Zhu, C., Song, Y., Zhu, H., et al. (20 23b). Bridging\nthe information gap between domain-speciﬁc model and genera l llm for personalized\nrecommendation. arXiv. doi: 10.48550/arXiv.2311.03778\nZhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., et al. (2023). A Survey of\nLarge Language Models . doi: 10.48550/arXiv.2303.18223\nZuccon, G., Koopman, B., and Shaik, R. (2023). “Chatgpt hallucina tes when\nattributing answers, ” in Proceedings of the Annual International ACM SIGIR\nConference on Research and Development in Information Retrieval in the Asia Paciﬁc\nRegion, SIGIR-AP ’23 (New York, NY: Association for Computing Machinery),\n46–51.\nFrontiers in Artiﬁcial Intelligence /one.tnum/zero.tnum frontiersin.org",
  "topic": "Factory (object-oriented programming)",
  "concepts": [
    {
      "name": "Factory (object-oriented programming)",
      "score": 0.7300839424133301
    },
    {
      "name": "Personalization",
      "score": 0.6594691872596741
    },
    {
      "name": "Computer science",
      "score": 0.6457977294921875
    },
    {
      "name": "Benchmarking",
      "score": 0.6233835816383362
    },
    {
      "name": "Knowledge management",
      "score": 0.5129327774047852
    },
    {
      "name": "Documentation",
      "score": 0.5066667199134827
    },
    {
      "name": "Knowledge sharing",
      "score": 0.4805610477924347
    },
    {
      "name": "World Wide Web",
      "score": 0.16512176394462585
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Business",
      "score": 0.0
    },
    {
      "name": "Marketing",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98358874",
      "name": "Delft University of Technology",
      "country": "NL"
    },
    {
      "id": "https://openalex.org/I4387156409",
      "name": "Bremer Institut für Produktion und Logistik GmbH",
      "country": null
    },
    {
      "id": "https://openalex.org/I862322245",
      "name": "Universidad EAFIT",
      "country": "CO"
    }
  ]
}