{
  "title": "Performance of a commercially available Generative Pre-trained Transformer (GPT) in describing radiolucent lesions in panoramic radiographs and establishing differential diagnoses",
  "url": "https://openalex.org/W4392764290",
  "year": 2024,
  "authors": [
    {
      "id": null,
      "name": "Silva, Thaísa Pinheiro",
      "affiliations": [
        "Universidade Estadual de Campinas (UNICAMP)"
      ]
    },
    {
      "id": null,
      "name": "Andrade-Bortoletto, Maria Fernanda Silva",
      "affiliations": [
        "Universidade Estadual de Campinas (UNICAMP)"
      ]
    },
    {
      "id": null,
      "name": "Ocampo, Thaís Santos Cerqueira",
      "affiliations": [
        "Universidade Estadual de Campinas (UNICAMP)"
      ]
    },
    {
      "id": null,
      "name": "Alencar-Palha, Caio",
      "affiliations": [
        "Universidade Estadual de Campinas (UNICAMP)"
      ]
    },
    {
      "id": null,
      "name": "Bornstein, Michael M.",
      "affiliations": [
        "University of Basel"
      ]
    },
    {
      "id": null,
      "name": "Oliveira-Santos, Christiano",
      "affiliations": [
        "University of Louisville"
      ]
    },
    {
      "id": null,
      "name": "Oliveira, Matheus L.",
      "affiliations": [
        "University of Basel",
        "Universidade Estadual de Campinas (UNICAMP)"
      ]
    },
    {
      "id": null,
      "name": "Silva, Thaísa Pinheiro",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Andrade-Bortoletto, Maria Fernanda Silva",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Ocampo, Thaís Santos Cerqueira",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Alencar-Palha, Caio",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Bornstein, Michael M.",
      "affiliations": [
        "University of Basel",
        "Universitäres Zentrum für Zahnmedizin Basel"
      ]
    },
    {
      "id": null,
      "name": "Oliveira-Santos, Christiano",
      "affiliations": [
        "University of Louisville"
      ]
    },
    {
      "id": null,
      "name": "Oliveira, Matheus L.",
      "affiliations": [
        "Universitäres Zentrum für Zahnmedizin Basel",
        "University of Basel"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4377289093",
    "https://openalex.org/W4281733456",
    "https://openalex.org/W2558416530",
    "https://openalex.org/W2955598391",
    "https://openalex.org/W4205239279",
    "https://openalex.org/W2104605421",
    "https://openalex.org/W2044923813",
    "https://openalex.org/W1972582207",
    "https://openalex.org/W2150458287",
    "https://openalex.org/W2098688358",
    "https://openalex.org/W2005916676",
    "https://openalex.org/W3043151376",
    "https://openalex.org/W4385563632",
    "https://openalex.org/W4283791207",
    "https://openalex.org/W2899380081",
    "https://openalex.org/W3154247191",
    "https://openalex.org/W4376640216",
    "https://openalex.org/W4391348997",
    "https://openalex.org/W4320920036",
    "https://openalex.org/W4386710076",
    "https://openalex.org/W2005393003"
  ],
  "abstract": "Abstract Objectives To evaluate the performance of a commercially available Generative Pre-trained Transformer (GPT) in describing and establishing differential diagnoses for radiolucent lesions in panoramic radiographs. Materials and methods Twenty-eight panoramic radiographs, each containing a single radiolucent lesion, were evaluated in consensus by three examiners and a commercially available ChatGPT-3.5 model. They provided descriptions regarding internal structure (radiodensity, loculation), periphery (margin type, cortication), shape, location (bone, side, region, teeth/structures), and effects on adjacent structures (effect, adjacent structure). Diagnostic impressions related to origin, behavior, and nature were also provided. The GPT program was additionally prompted to provide differential diagnoses. Keywords used by the GPT program were compared to those used by the examiners and scored as 0 (incorrect), 0.5 (partially correct), or 1 (correct). Mean score values and standard deviation were calculated for each description. Performance in establishing differential diagnoses was assessed using Rank-1, -2, and − 3. Results Descriptions of margination, affected bone, and origin received the highest scores: 0.93, 0.93, and 0.87, respectively. Shape, region, teeth/structures, effect, affected region, and nature received considerably lower scores ranging from 0.22 to 0.50. Rank-1, -2, and − 3 demonstrated accuracy in 25%, 57.14%, and 67.85% of cases, respectively. Conclusion The performance of the GPT program in describing and providing differential diagnoses for radiolucent lesions in panoramic radiographs is variable and at this stage limited in its use for clinical application. Clinical relevance Understanding the potential role of GPT systems as an auxiliary tool in image interpretation is imperative to validate their clinical applicability.",
  "full_text": "RESEARCH\nClinical Oral Investigations (2024) 28:204\nhttps://doi.org/10.1007/s00784-024-05587-5\nIntroduction\nChatGPT (Chat Generative Pre-trained Transformer), a free \nservice that became available towards the end of 2022, con-\nsists of an artificial intelligence (AI) language model with \nan extensive database that covers various subjects. This AI \nchatbot has the capability to perform several tasks, such as \ncreating spreadsheets for different types of data, generating \nanalogies, outlining research topics, and providing study \nnotes based on a given topic. In addition to those inter -\nesting functionalities, this tool has the ability to generate \nimage descriptions from hyperlinks when provided with \nspecific prompts, which holds potential significance in the \nfield of dentomaxillofacial radiology (DMFR) [ 1]. To date, \n \r Matheus L. Oliveira\nmatheus.limadeoliveira@unibas.ch\n1 Department of Oral Diagnosis, Division of Oral Radiology, \nPiracicaba Dental School, University of Campinas, \nPiracicaba, Sao Paulo 13414-903, Brazil\n2 Department of Oral Health & Medicine, University Center \nfor Dental Medicine Basel UZB, University of Basel,  \nBasel 4058, Switzerland\n3 Department of Diagnosis and Oral Health, University of \nLouisville School of Dentistry, Louisville, KY 40202, USA\nAbstract\nObjectives To evaluate the performance of a commercially available Generative Pre-trained Transformer (GPT) in describ-\ning and establishing differential diagnoses for radiolucent lesions in panoramic radiographs.\nMaterials and methods Twenty-eight panoramic radiographs, each containing a single radiolucent lesion, were evaluated \nin consensus by three examiners and a commercially available ChatGPT-3.5 model. They provided descriptions regarding \ninternal structure (radiodensity, loculation), periphery (margin type, cortication), shape, location (bone, side, region, teeth/\nstructures), and effects on adjacent structures (effect, adjacent structure). Diagnostic impressions related to origin, behavior, \nand nature were also provided. The GPT program was additionally prompted to provide differential diagnoses. Keywords \nused by the GPT program were compared to those used by the examiners and scored as 0 (incorrect), 0.5 (partially correct), \nor 1 (correct). Mean score values and standard deviation were calculated for each description. Performance in establishing \ndifferential diagnoses was assessed using Rank-1, -2, and − 3 .\nResults Descriptions of margination, affected bone, and origin received the highest scores: 0.93, 0.93, and 0.87, respectively. \nShape, region, teeth/structures, effect, affected region, and nature received considerably lower scores ranging from 0.22 to \n0.50. Rank-1, -2, and − 3 demonstrated accuracy in 25%, 57.14%, and 67.85% of cases, respectively.\nConclusion The performance of the GPT program in describing and providing differential diagnoses for radiolucent lesions \nin panoramic radiographs is variable and at this stage limited in its use for clinical application.\nClinical relevance Understanding the potential role of GPT systems as an auxiliary tool in image interpretation is imperative \nto validate their clinical applicability.\nKeywords Artificial intelligence · Generative pre-trained transformer · Differential diagnosis · Panoramic radiography\nReceived: 11 January 2024 / Accepted: 25 February 2024 / Published online: 9 March 2024\n© The Author(s) 2024\nPerformance of a commercially available Generative Pre-trained \nTransformer (GPT) in describing radiolucent lesions in panoramic \nradiographs and establishing differential diagnoses\nThaísa Pinheiro Silva1  · Maria Fernanda Silva Andrade-Bortoletto1  · Thaís Santos Cerqueira Ocampo1  · \nCaio Alencar-Palha1  · Michael M. Bornstein2  · Christiano Oliveira-Santos3  · Matheus L. Oliveira1,2\n1 3\nClinical Oral Investigations (2024) 28:204\nthe scientific literature includes numerous review papers \nand editorial letters, yet a notable gap exists in the form of \nempirical studies assessing the performance of a commer -\ncially available tool such as ChatGPT [2].\nImage analysis and description are among the primary \nresponsibilities of radiologists, carrying significant indi -\nrect impact on patients’ treatments [ 3]. Radiologists face \nnumerous challenges in interpreting medical images. The \ncomplexity and variability of imaging modalities in DMFR \nencompass a wide range of two and three-dimensional \nimages, including periapical radiography, panoramic views, \nand cone-beam computed tomography. Each modality \npresents unique challenges in analysis and diagnosis [ 4]. \nAdditionally, the volume of imaging examinations has sig -\nnificantly increased over time, leading to a heavier work -\nload. Subjective interpretation and variability in image \ndescriptions can hinder effective communication among \nhealthcare professionals, potentially compromising patient \ncare [5–7].\nPanoramic radiography is a two-dimensional image \nmodality that enables visualization of the teeth in the \nupper and lower jaws, and the surrounding structures of \nthe maxillofacial complex. By providing broad views at a \nrelatively low radiation dose and relatively low cost, pan -\noramic radiography is widely available and often used for \nthe evaluation, diagnosis, and monitoring of jaw lesions \n[8]. Radiolucent lesions are the most prevalent type, and \ninterpreting and describing them can be challenging, either \ndue to the non-specific clinical presentation or the inherent \nlimitations of this imaging modality, such as image blurring, \ndistortion, and superimposition of structures [9–14].\nPanoramic radiography is a commonly employed \nimaging technique to evaluate lesions within the maxillo -\nfacial complex. Additionally, acknowledging the poten -\ntial application of commercially available GPT programs \nas auxiliary instruments in image analysis – encompass -\ning the provision of supplementary insights, generation \nof descriptive narratives, and presentation of differential \ndiagnose – emphasizes the importance of their role. Con -\nsequently, it is crucial for GPT programs to demonstrate \naccuracy to fulfill their intended functions for image \ndiagnosis in dental medicine effectively.\nMaterials and methods\nSample selection\nA search for panoramic radiographs was conducted on the \nopen-access websites Radiopaedia.org ( https://radiopae-\ndia.org/) and CDI Peru ( https://cdi.com.pe/), which pro -\nvide well-documented clinical cases. The inclusion criteria \nwere clinical cases with panoramic radiographs displaying \npermanent dentition and a single radiolucent lesion in the \nmaxilla or mandible, with histopathological confirmation \nor a probable differential diagnosis, and presenting specific \nhyperlinks that redirected to the corresponding isolated pan-\noramic radiograph (i.e., not the full webpage with textual \ninformation). Blurry, cropped, or edited panoramic radio -\ngraphs containing annotations such as arrows, circles, lines, \nor texts were not included in this study. This resulted in a \ntotal of 28 panoramic radiographs included for further anal-\nysis (Annex 1).\nReference standard description and diagnostic \nimpressions\nThree experienced oral and maxillofacial radiologists \nevaluated all panoramic radiographs in consensus and \ndescribed the radiographic aspects of the lesions accord -\ning to the following parameters: internal structure \n(radiodensity and loculation), periphery (margin type \nand cortication), shape, location (bone, side, region, and \ntooth/structure), and effect on adjacent structures (effect \nand adjacent structure). Then, based on the descriptions, \nthe examiners determined their impressions, as follows: \norigin (odontogenic or non-odontogenic), behavior \n(benign or malignant), and nature (inflammatory, dys -\nplastic, cystic, or tumoral/neoplastic). Figure 1 depicts \nthe predetermined standardized topics and parameters \nused in the descriptions, along with the corresponding \nkeywords employed by the examiners to describe the \nlesions in all panoramic radiographs.\nDescription based on the commercially available \nGPT program\nUsing the free online ChatGPT program (GPT-3.5 model) \navailable at https://chat.openai.com , three prompts were \nsubmitted accompanied by the hyperlink of each indi -\nvidual panoramic radiograph: (1) Description: “Please \ndescribe the radiographic aspects of the lesion in this \npanoramic radiograph according to the following top -\nics: internal structure, unilocular or multilocular, periph -\nery, shape, location, and effect on adjacent structures.“, \n(2) Impressions: “Based on the previous radiographic \naspects, what are your impressions of the lesion regard -\ning its origin, behavior, and nature?“, and (3) Differential \ndiagnoses: “What are the likely differential diagnoses, \nin order of priority, based on the radiographic features \nnoted in the previous panoramic radiograph?”. All out -\nput responses generated by the GPT program were care -\nfully reviewed by the same three experienced oral and \nmaxillofacial radiologists in consensus, who identified \n1 3\n204 Page 2 of 9\nClinical Oral Investigations (2024) 28:204\nand extracted the keywords employed by the program to \ndescribe the lesions.\nDescription performance scoring of the \ncommercially available GPT\nThe performance of the GPT program in describing the \nlesions in the panoramic radiographs was scored by con -\nfronting the extracted keywords with those determined \nby the reference standard established by the radiologists. \nWhen the keywords for each parameter employed by the \nGPT program matched those from the reference standard, \nthe description was considered correct and a score of 1 \nwas assigned. When the keyword employed by the GPT \nprogram was similar but not identical to the reference \nstandard, the description was considered partially cor -\nrect and a score of 0.5 was assigned. Finally, when the \nkeyword employed by the GPT program was different or \nwhen more than one keyword was described for the same \nlesion, with one being correct and the other(s) incorrect, \nthe description was considered to be incorrect and a score \nof 0 was assigned. Figure 2 illustrates the application of \nthe scoring method for evaluating the GPT program’s \nperformance in describing a representative radiolucent \nlesion.\nMeans and standard deviations were calculated from \nthe scores obtained for each addressed parameter of all \npanoramic radiographs. The scores were also divided into \ntwo groups based on the extension of the lesion (span -\nning one or two/three regions) and presented in the form \nof a bar chart.\nGPT program’s rank-n differential diagnoses\nRank-1, Rank-2, and Rank-3 were manually computed to \nevaluate the performance of the GPT program’s differen -\ntial diagnosis in comparison to the confirmed or probable \ndiagnoses of each case. Rank-n accuracy is defined as the \npercentage of finding the n th matching target [ 15, 16]. For \ninstance, Rank-3 accuracy is the percentage of cases in \nwhich the correct diagnosis was included in the top three \nmost likely differential diagnoses.\nResults\nThe GPT program’s description performance varied consid-\nerably among each parameter assessed. The highest mean \nscore values (i.e., above 0.80) were 0.93 for margin type \nand affected bone, and 0.87 for origin. These parameters \nalso demonstrated to be more consistently described by \nthe GPT program, as evidenced by their relatively lower \nstandard deviation values. Conversely, shape, region, teeth/\nstructures, effect, affected region, and nature showed con -\nsiderably lower mean score values, ranging from 0.22 to \n0.50, along with higher standard deviation values, reflecting \nFig. 1 Predetermined topics, parameters and keywords addressed by the examiners to describe the lesions in all panoramic radiographs\n \n1 3\nPage 3 of 9 204\nClinical Oral Investigations (2024) 28:204\nprogram exhibited divergent performance (output mostly \ncorrect vs. incorrect).\nThe performance of the GPT program in describing \nradiolucent lesions in panoramic radiographs did not exhibit \na consistent pattern when the lesion spanned one or two/\nthree regions. Overall, slight differences in description \nperformance were observed in the following parameters: \ncortication, shape, teeth/structures, affected region and ori -\ngin. However, it was not possible to establish a pattern of \ngreater variability in the response pattern. Finally, the param-\neters radiodensity, loculation, cortication, side, and behavior \npresented intermediate performance with mean score val -\nues ranging from 0.61 to 0.77 and also revealing a highly \nvariable standard deviation (Table 1). The overall perfor -\nmance of the GPT program in describing radiolucent lesions \nin panoramic radiographs, with all parameters considered, \nrevealed a mean score value of 0.56, and a standard devia -\ntion of 0.48. Figure 3 illustrates two cases where the GPT \nFig. 2 Example of application of the scoring method for evaluating the GPT program’s performance in describing a representative radiolucent \nlesion. 1, correct; 0.5, partially correct; 0 incorrect\n \n1 3\n204 Page 4 of 9\nClinical Oral Investigations (2024) 28:204\neffect, behavior, and nature showed the largest differences \nin performance considering the extension of the lesion, with \nlesions spanning one region generally being more accurately \ndescribed than those spanning two/three regions (Fig. 4).\nRegarding the GPT program’s performance in estab -\nlishing differential diagnoses, as shown in Table 2, seven \ncases (25%) were accurately predicted as the first diagnostic \nhypothesis, while 16 cases (57.14%) and 19 cases (67.85%) \nwere accurately predicted within the first two and the first \nthree diagnostic hypotheses, respectively. In nine cases \n(32.14%), the GPT program did not succeed in accurately \npredicting them within the three diagnostic hypotheses.\nDiscussion\nChatGPT is a recently launched powerful chatbot that \nhas the potential to answer questions and respond to \ncommands in an impressively short time with well-\nstructured and well-written sentences, which can \nhigher performance based on the extension of the lesion. \nRadiodensity, loculation, margin type, bone, side, region, \nTable 1 Mean score values and standard deviation (SD) of the GPT \nprogram’s performance in describing radiolucent lesions in panoramic \nradiographs, as a function of the assessed topic and parameter\nTopic Parameter Mean SD\nDescription Internal \nStructure\nRadiodensity 0.75 0.44\nLoculation 0.61 0.50\nPeriphery Margin type 0.93 0.22\nCortication 0.73 0.29\nShape Shape 0.43 0.50\nLocation Affected bone 0.93 0.26\nSide 0.68 0.48\nRegion 0.34 0.39\nTeeth/Structures 0.32 0.46\nEffect on \nAdjacent \nStructures\nEffect 0.32 0.47\nAffected region 0.22 0.39\nImpressions Origin 0.87 0.35\nBehavior 0.77 0.43\nNature 0.50 0.49\nTotal 0.56 0.48\nFig. 3 Representative panoramic radiographs and their corresponding divergent outputs from the GPT program, leading to a higher score (mostly \ncorrect output) in the top image and a lower score (mostly incorrect output) in the bottom image\n \n1 3\nPage 5 of 9 204\nClinical Oral Investigations (2024) 28:204\nimaging modality, limitations, and indications, rather \nthan providing an actual description of the lesion of \ninterest in the image. This reveals that the responses \ngenerated by this GPT program are strongly prompt-\ndependent. Importantly, the present study focused on \na customary clinical scenario when a radiologist or a \nclinician asks for the opinion of colleagues when spot-\nting a lesion. If the intention was to evaluate the ability \nof the GPT program to spot the lesion, then the prompt \nwould have to be specific for that purpose.\nThe studied GPT program provided incomplete and unspe -\ncific information in many cases, and this was negatively \nconsidered in the scoring system for the description perfor -\nmance. There were instances when an effect on the adjacent \nstructure, such as cortical thinning, was mentioned without \nindicating the location. In some other circumstances, corti -\ncal thinning was described as affecting the buccal or lingual \nplates, despite the two-dimensional nature of panoramic \nradiography, which hinders the proper visualization of these \nstructures. Such inconsistencies certainly led to variable \nand inconsistent results seen in the present investigation. \nApproximately 46% of the responses exhibited contradic -\ntions. For example, some lesions were described as both \n“corticated” and “aggressive due to its diffuse borders”. \nThis behavior raises the hypothesis that the GPT program \nused may not perform a detailed evaluation of the image. \nInstead, it may rely on general patterns and commonly \navailable information regarding radiolucent lesions in pan -\noramic radiographs.\nstrongly convince or persuade readers of its accuracy \nand reasoning. Among a large list of capabilities, this \nopenly available GPT program describes radiographic \nlesions in a coherent structure when provided with \na hyperlink to a radiographic image and specifically \nasked to do so. Within the methodological design and \nlimitations of the present study, the GPT program \nshowed a limited and highly variable performance in \ndescribing and establishing differential diagnoses for \nradiolucent lesions in panoramic radiographs. Such \nvariability raises questions about the GPT program’s \nreliability and suitability for clinical application at this \ntime.\nSpecificity was a relevant aspect that had to be taken \ninto consideration during the development of the \nthree prompts for the present study, as observed in \npilot studies (data not shown), due to limitations in \nthe studied GPT program. The prompts had to clearly \nspecify the imaging modality and acknowledge the \npresence of a lesion, otherwise, the GPT program \nwould generate responses focused on explaining the \nTable 2 Absolute number and relative percentage of cases of the GPT \nprogram’s performance in predicting rank-1, -2, -3 differential diag -\nnoses, and cases in which no correct differential diagnosis was estab -\nlished\nRank-n Prediction Performance\nNumber of cases Percentage of cases\nRank-1 7 25.00\nRank-2 16 57.14\nRank-3 19 67.86\nNone 9 32.14\nFig. 4 Mean score values of the GPT program’s performance in describing radiolucent lesions in panoramic radiographs, as a function of the \nassessed topic and parameter and the extension of the lesion (one or two/three regions)\n \n1 3\n204 Page 6 of 9\nClinical Oral Investigations (2024) 28:204\na collective consensus for the responsible implementation \nof GPT programs in DMFR.\nThe scientific literature has consistently indicated strong \nperformance when using deep learning-based AI technolo -\ngies for tasks encompassing the reading and interpretation of \nradiographic images in dental medicine. Examples include \nthe assessment of root morphology of the mandibular first \nmolar, automatic classification of odontogenic keratocysts \nand ameloblastomas, differential diagnosis of lingual man -\ndibular bone depression (e.g. Stafne defect) from true path-\nological radiolucent cysts or tumors, and classification and \nlocalization of odontogenic lesions [19–22].\nIt is imperative to recognize that, unlike convolutional \nneural networks (CNNs), ChatGPT primarily functions \nas a language model, and while its capabilities have been \nextended to include image handling, it may not be as spe -\ncialized as traditional image-centric models. In the domain \nof oral radiology, traditional research often leverages CNNs \nfor image analysis, which typically involves specialized \nimage-processing models adept at detecting patterns and \nfeatures within radiographic images. In contrast, ChatGPT \nemploys a distinctive approach with the possibility of gener-\nating natural language descriptions related to these images. \nIt has the potential to furnish contextual information, expla-\nnations, or summaries based on visual content [ 1], present-\ning a complementary perspective to the image-focused \nmethodologies, which are commonly used in the field of \noral radiology. Furthermore, previous studies have sug -\ngested that ChatGPT-3, -3.5 and − 4 can accurately estab -\nlish differential diagnosis, which contrasts with the results \nhighlighted in the present study [ 23, 24]. This discrepancy \nmay be attributed to the fact that the prompts employed in \nthose studies utilizing ChatGPT comprised short clinical \ntextual descriptions, in contrast to the methodology adopted \nin the present investigation, which utilized hyperlinks redi -\nrecting to specific panoramic images. Evidently, the lack \nof transparency regarding the training data and methodolo -\ngies utilized in ChatGPT’s development poses challenges \nin fully understanding its capabilities and potential biases. \nFurthermore, the absence of a dedicated training process \nusing task-specific medical image data is a relevant limita -\ntion of the present investigation that merits consideration.\nThe deployment of external AI tools as diagnostic aids \nnecessitates careful consideration of data privacy and secu-\nrity concerns. Due to potential risks associated with upload-\ning sensitive data, such as patient images, to public servers, \nthe need for robust protective measures has to be consid -\nered. In alignment with these concerns, we emphasize the \nimportance of implementing stringent security protocols \nwhen integrating AI technologies into clinical applica -\ntions. While our current study utilized publicly available \npanoramic radiographs, we acknowledge that real-world \nSurprisingly, some cases were very well described, point-\ning to highly specific anatomical references, such as the \ncement-enamel junction. One hypothesis for the success in \ndescribing such cases is the potential redirection from the \nhyperlink to the online platform from which the case was \ntaken, or the potential extraction of the identification of the \nlesion from the hyperlink. This might have led this GPT \nprogram to use more common characteristics associated \nwith that specific lesion. Another hypothesis for the accu -\nrate descriptions is that possibly the GPT program works \nbased on prevalence. Considering that the sample in this \nstudy consisted of benign radiolucent lesions, characteris -\ntics like density, margination, and affected bone are more \npredictable, increasing the chances of a good performance \nby guessing the most common presentation. However, for \nother characteristics that exhibit greater variation from one \nlesion to another, such as the affected region, relationship \nwith teeth or structures, effects, and the location of those \neffects, prevalence-based assumptions become more chal -\nlenging. As a result, lower mean score values with a wider \nstandard deviation were observed for these characteristics.\nIrrespective of the responses generated by the GPT pro -\ngram used, it is worth mentioning that all of them ended \nwith a sentence emphasizing the importance of a radiologist \nproviding the final description and confirming the diagnosis \nof the lesion through histopathological examination. Despite \nthe nicely structured and apparently convincing responses, \nthis highlights that the present GPT program recognizes its \nlimited reliability when generating responses or handling \nopen questions, and stresses that the responsibility for veri-\nfying and confirming the appropriate course of action based \non the information provided still lies with the radiologist.\nRegarding the present GPT program’s performance in \nestablishing differential diagnoses, it’s important to high -\nlight that it can achieve a high accuracy solely based on \nthe prevalence reported in the literature, without the need \nto interpret the actual image. Furthermore, since GPT is an \nartificial intelligence-based tool, it is in a constant process of \nlearning and evolution [1]. Therefore, it is expected to have \nthe potential for improvement, particularly in enhancing its \nperformance in the aspects studied in the current research.\nThe advent of AI, demonstrated by the remarkable capa-\nbilities of GPT programs like ChatGPT and ClinicGPT [17], \nhas introduced transformative possibilities and challenges \nto the field of DMFR. As part of our community may strug-\ngle with the integration of AI, it is evident that this tech -\nnology holds huge potential for reshaping both education \nand practice [ 18]. Nevertheless, this evolution comes with \nan inherent set of challenges. Many radiologists, tradition -\nally untrained in GPT-based practice, must dedicate them -\nselves to assess this application effectively. Furthermore, \nethical and legal considerations are significant, demanding \n1 3\nPage 7 of 9 204\nClinical Oral Investigations (2024) 28:204\nto the interpretation of data; reviewed the manuscript critically for im-\nportant intellectual content; approved the version to be published; and \nagree to be accountable for all aspects of the work in ensuring that \nquestions related to the accuracy or integrity of any part of the work \nare appropriately investigated and resolved: M. F. (A) B., T. O., C. A., \nM. (B) and (C) O.\nFunding Open access funding provided by University of Basel\nThis study was financed in part by the Coordenação de Aperfeiçoa -\nmento de Pessoal de Nível Superior – Brasil (CAPES) – Finance Code \n001.\nData availability No datasets were generated or analysed during the \ncurrent study.\nDeclarations\nEthics approval and consent to participate Not applicable.\nConflict of interest  The authors declare that they have no conflict of \ninterest.\nCompeting interests The authors declare no competing interests.\nOpen Access   This article is licensed under a Creative Commons \nAttribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the \nsource, provide a link to the Creative Commons licence, and indicate \nif changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless \nindicated otherwise in a credit line to the material. If material is not \nincluded in the article’s Creative Commons licence and your intended \nuse is not permitted by statutory regulation or exceeds the permitted \nuse, you will need to obtain permission directly from the copyright \nholder. To view a copy of this licence, visit http://creativecommons.\norg/licenses/by/4.0/.\nReferences\n1. ChatGPT (2023) : Optimizing Language Models for Dialogue. \nhttps://openai.com/blog/chatgpt/ (accessed 30\n2. Ocampo TSC, Silva TP, Alencar-Palha C, Haiter-Neto F, Oliveira \nML (2023) ChatGPT and scientific writing: a reflection on the \nethical boundaries. Imaging Sci Dent 53:175–176. https://doi.\norg/10.5624/isd.20230085Epub 2023 May 19. PMID: 37405199; \nPMCID: PMC10315235\n3. European Society of Radiology (ESR) (2022) The role of radi -\nologist in the changing world of healthcare: a White Paper \nof the European Society of Radiology (ESR). Insights Imag -\ning 13 :100. Published 2022 Jun 4. https://doi.org/10.1186/\ns13244-022-01241-4\n4. White SC, Pharoah MJ (2015) Radiologia oral: Princípios E \nInterpretação, 7 edn. Mosby, St. Louis\n5. Ruutiainen AT, Durand DJ, Scanlon MH, Itri JN (2013) Increased \nerror rates in preliminary reports issued by radiology residents \nworking more than 10 consecutive hours overnight. AcadRadiol \n20:305–311\n6. Hanna TN, Shekhani H, Lamoureux C et al (2017) Emergency \nradiology practice patterns: shifts, schedules, and job satisfaction. \nJ Am Coll Radiol 14:345–352\nclinical scenarios demand heightened attention to privacy \nand accountability, aligning with national requirements for \nmedical patient data protection laws.\nTo the best of the author’s knowledge, the present study \nis the first to evaluate the performance of a commercially \navailable GPT program in describing and establishing dif -\nferential diagnoses of lesions based on radiographic images. \nThis limitation severely restricts the possibility of making \ndirect comparisons with previous studies. Furthermore, the \ncurrent research study evaluated panoramic radiographs \nfrom freely available clinical data repositories on online \nplatforms, focusing specifically on the presence of radio -\nlucent lesions. Our sample size was limited by our strict \ninclusion criteria, which was necessary to mitigate poten -\ntial bias from hyperlinks to images embedded on a website \ncontaining all textual information and graphic annotations. \nFurther studies utilizing images from the same databases, \nfollowing the same quality control procedures, and includ -\ning radiopaque and mixed lesions are encouraged for a more \ncomprehensive analysis. In addition, considering that the \nGPT program model used when this study was conceived \nonly allowed reading images through their hyperlinks (GPT-\n3.5 model), future research assessing the performance of the \nlatest update of this transformer dating back to September \n2023 are encouraged. This latest program model allows \nfor image uploads directly to the system. This is important \nbecause the method through which AI-based language mod-\nels extract data may differ. Furthermore, this also sheds light \non the inherent limitation of studies assessing rapidly evolv-\ning systems, as the one assessed herein, as evidence-based \nconclusions are more likely exposed to the risk of becoming \noutdated shortly. Conversely, the significance of such stud-\nies relies on the possibility of reliably tracking their techno-\nlogical evolution process.\nConclusion\nUp to the point in time this study was conducted, the perfor-\nmance of the ChatGPT-3.5 model in describing radiolucent \nlesions in panoramic radiographs and establishing differen -\ntial diagnoses is variable and limited and is unsuitable for \nclinical application.\nSupplementary information  The online version contains \nsupplementary material available at https://doi.org/10.1007/s00784-\n024-05587-5.\nAuthor contributions Made substantial contributions to the concep -\ntion or design of the work; drafted the manuscript; revised the manu -\nscript; approved the version to be published; and agree to be account -\nable for all aspects of the work in ensuring that questions related to the \naccuracy or integrity of any part of the work are appropriately investi-\ngated and resolved: T. P. S. and M. L. O.Made substantial contributions \n1 3\n204 Page 8 of 9\nClinical Oral Investigations (2024) 28:204\n18. Islam NM, Laughter L, Sadid-Zadeh R, Smith C, Dolan TA, \nCrain G, Squarize CH (2022) Adopting artificial intelligence in \ndental education: A model for academic leadership and innova -\ntion. J Dent Educ. ; 86:1545–1551. doi: 10.1002/jdd.13010. Epub \n2022 Jul 3. PMID: 35781809\n19. Hiraiwa T, Ariji Y , Fukuda M, Kise Y , Nakata K, Katsumata A, \nFujita H, Ariji E (2019) A deep-learning artificial intelligence \nsystem for assessment of root morphology of the mandibular \nfirst molar on panoramic radiography. Dentomaxillofac Radiol \n48:20180218. https://doi.org/10.1259/dmfr.20180218\n20. Bispo MS, Pierre Júnior MLGQ, Apolinário AL Jr, Santos D, \nJunior JN, Neves BC, Crusoé-Rebello FS (2021) Computer tomo-\ngraphic differential diagnosis of ameloblastoma and odontogenic \nkeratocyst: classification using a convolutional neural network. \nDentomaxillofac Radiol 50:20210002. https://doi.org/10.1259/\ndmfr.20210002\n21. Ha EG, Jeon KJ, Lee C, Kim HS, Han SS (2023) Development \nof deep learning model and evaluation in real clinical practice of \nlingual mandibular bone depression (Stafne cyst) on panoramic \nradiographs. Dentomaxillofac Radiol 52:20220413. https://doi.\norg/10.1259/dmfr.20220413\n22. Kang J, Le VNT, Lee DW, Kim S (2024) Diagnosing oral and \nmaxillofacial diseases using deep learning. Sci Rep 14:2497. \nhttps://doi.org/10.1038/s41598-024-52929-0\n23. Hirosawa T, Harada Y , Yokose M, Sakamoto T, Kawamura R, Shi-\nmizu T (2023) Diagnostic accuracy of Differential-diagnosis lists \ngenerated by Generative Pretrained Transformer 3 Chatbot for \nClinical vignettes with Common Chief complaints: a pilot study. \nInt J Environ Res Public Health 20:3378. https://doi.org/10.3390/\nijerph20043378\n24. Hirosawa T, Kawamura R, Harada Y , Mizuta K, Tokumasu K, \nKaji Y , Suzuki T, Shimizu T (2023) ChatGPT-Generated Differen-\ntial diagnosis lists for Complex Case-Derived Clinical vignettes: \ndiagnostic accuracy evaluation. JMIR Med Inf 11:48808. https://\ndoi.org/10.2196/48808\nPublisher’s Note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional affiliations. \n7. Patlas MN, Katz DS, Scaglione S (2019) Errors in emergency and \ntrauma radiology. Springer, Berlin\n8. Różyło-Kalinowska I (2021) Panoramic radiography in dentistry. \nClin Dent Rev 5:26. https://doi.org/10.1007/s41894-021-00111-4\n9. Koivisto T, Bowles WR, Rohrer M (2012) Frequency and dis -\ntribution of radiolucent jaw lesions: a retrospective analysis of \n9,723 cases. J Endod 38:729–732. https://doi.org/10.1016/j.\njoen.2012.02.028\n10. Flint DJ, Paunovich E, Moore WS, Wofford DT, Hermesch \nCBA (1998) Diagnostic comparison of panoramic and intraoral \nradiographs. Oral Surg Oral Med Oral Pathol Oral Radiol Endod \n85:731–735\n11. Akkaya N, Kansu O, Kansu H, Cagirankaya LB, Arslan U (2006) \nComparing the accuracy of panoramic and intraoral radiogra -\nphy in the diagnosis of proximal caries. Dentomaxillofac Radiol \n35:170–174\n12. Akarslan ZZ, Akdevelioğlu M, Güngör K, Erten H (2008) A com-\nparison of the diagnostic accuracy of bitewing, periapical, unfil -\ntered and filtered digital panoramic images for approximal caries \ndetection in posterior teeth. Dentomaxillofac Radiol 37:458–463\n13. Dunfee BL, Sakai O, Pistey R, Gohel A (2006) Radiologic and \npathologic characteristics of benign and malignant lesions of the \nmandible. Radiographics 26:1751–1768. https://doi.org/10.1148/\nrg.266055189\n14. Devenney-Cakir B, Subramaniam RM, Reddy SM, Imsande H, \nGohel A, Sakai O (2011) Cystic and cystic-appearing lesions of \nthe mandible: review. AJR Am J Roentgenol 196:WS66–WS77. \nhttps://doi.org/10.2214/AJR.09.7216\n15. Fan F, Ke W, Wu W, Tian X, Lyu T, Liu Y et al (2020) Automatic \nhuman identification from panoramic dental radiographs using \nthe convolutional neural network. Forensic Sci Int 314:110416. \nhttps://doi.org/10.1016/j.forsciint.2020.110416\n16. Simonyan K, Zisserman A Very deep convolutional networks for \nlarge-scale image recognition. arXiv preprint arXiv:1409.1556 \n2014\n17. Zhou KX (2023) Introducing ClinicGPT: A custom large lan -\nguage model for institutional dental clinics. J Dent Educ. Aug 4. \ndoi: 10.1002/jdd.13348. Epub ahead of print. PMID: 37539925\n1 3\nPage 9 of 9 204",
  "topic": "Radiodensity",
  "concepts": [
    {
      "name": "Radiodensity",
      "score": 0.8274338841438293
    },
    {
      "name": "Medical diagnosis",
      "score": 0.7177867889404297
    },
    {
      "name": "Radiography",
      "score": 0.7047814130783081
    },
    {
      "name": "Medicine",
      "score": 0.4963992238044739
    },
    {
      "name": "Dentistry",
      "score": 0.38156384229660034
    },
    {
      "name": "Medical physics",
      "score": 0.37775564193725586
    },
    {
      "name": "Orthodontics",
      "score": 0.34201914072036743
    },
    {
      "name": "Radiology",
      "score": 0.29702430963516235
    }
  ]
}