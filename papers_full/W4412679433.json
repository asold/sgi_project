{
    "title": "Uncover This Tech Term: Application Programming Interface for Large Language Models",
    "url": "https://openalex.org/W4412679433",
    "year": 2025,
    "authors": [
        {
            "id": null,
            "name": "Park, Chae Ri",
            "affiliations": [
                "Asan Medical Center"
            ]
        },
        {
            "id": null,
            "name": "Heo, Hwon",
            "affiliations": [
                "Asan Medical Center"
            ]
        },
        {
            "id": null,
            "name": "Suh, Chong Hyun",
            "affiliations": [
                "University of Ulsan",
                "Asan Medical Center",
                "Ulsan College"
            ]
        },
        {
            "id": null,
            "name": "Shim, Woo Hyun",
            "affiliations": [
                "Asan Medical Center",
                "Ulsan College",
                "University of Ulsan"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3136802113",
        "https://openalex.org/W4398201223",
        "https://openalex.org/W4402891242",
        "https://openalex.org/W4402891150",
        "https://openalex.org/W3163926797"
    ],
    "abstract": null,
    "full_text": "793\nCopyright © 2025 The Korean Society of Radiology\nKeywords: API; Large language models; AI\nWhat is an API?\nAn application programming interface (API) is a set \nof rules that allows different software applications to \ncommunicate easily with each other. When one program \nneeds to obtain data or use certain functionalities from \nanother program, it simply makes a “request” according to \nthe predefined format of the API. The second program then \nprocesses this request and provides the desired “response” \nor “service.” A key benefit here is that the requesting \napplication does not need to understand exactly how the \nother system internally operates [1,2].\nTo illustrate this intuitively, we consider the analogy \nof dining at a restaurant. A customer (the user) selects \ndishes from a menu (available services or functions) and \ncommunicates their request to a waiter (the API). The \nwaiter then delivers this request to a specific station or \nsection in the kitchen (representing the endpoint, exact \nlocation, or resource where the request is processed by \nUncover This Tech Term: Application Programming \nInterface for Large Language Models\nChae Ri Park1, Hwon Heo1, Chong Hyun Suh2, Woo Hyun Shim1,2\n1Convergence Medicine Research Center, Asan Institute for Life Sciences, Asan Medical Center, University of Ulsan College of Medicine, Seoul, \nRepublic of Korea\n2Department of Radiology and Research Institute of Radiology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, Republic of Korea\nthe service provider). The kitchen staff prepares dishes \n(responses or results), which the waiter then serves to \nthe customer. The key point is that the customer does not \nneed to know how the kitchen staff prepares the food; \nthe customer merely places an order based on the menu, \nand the waiter (API) handles all internal interactions and \ncomplexities [3].\nSimilarly, an API establishes standardized formats \nfor requests and responses. By abstracting internal \ncomplexities, APIs allow users or client applications to \neasily obtain desired outcomes without understanding the \nunderlying processes [4,5]. \nWeb-Based Interface vs. API Access for LLMs\nWeb-Based Interface\nA web-based interface is an easy and common way to \ninteract with large language models (LLMs) such as ChatGPT \n(chat.openai.com) or Gemini (gemini.google.com). Users \ntype their questions directly on a website and instantly \nreceive answers. Because it does not require the installation \nof software or programming skills, it is particularly helpful \nfor beginners and non-technical users who want quick \naccess or to perform basic tasks.\nHowever, web interfaces have several limitations. Users \nmust manually submit each query, which makes it difficult \nto automate tasks or process large datasets. Customization \noptions, such as adjusting the temperature to control \nresponse randomness (stochasticity) or setting the response \nlength, are also often limited. Additionally, web interfaces \nautomatically retain conversation history within a chat \nsession; therefore, earlier interactions can unintentionally \naffect subsequent responses. Even logging out may \nKorean J Radiol 2025;26(8):793-796\neISSN 2005-8330\nhttps://doi.org/10.3348/kjr.2025.0360\nEditorial | Uncover This Tech Term\nReceived: March 26, 2025   Revised: May 11, 2025\nAccepted: May 18, 2025\nCorresponding author: Woo Hyun Shim, PhD, Convergence \nMedicine Research Center, Asan Institute for Life Sciences, \nDepartment of Radiology and Research Institute of Radiology, \nAsan Medical Center, University of Ulsan College of Medicine, 88 \nOlympic-ro 43-gil, Songpa-gu, Seoul 05505, Republic of Korea\n• E-mail: swh@amc.seoul.kr\nThis is an Open Access article distributed under the terms of \nthe Creative Commons Attribution Non-Commercial License \n(https://creativecommons.org/licenses/by-nc/4.0) which permits \nunrestricted non-commercial use, distribution, and reproduction in \nany medium, provided the original work is properly cited. \n794\nPark et al.\nhttps://doi.org/10.3348/kjr.2025.0360 kjronline.org\nnot guarantee session independence due to potential \n“intersession memory” mechanisms designed to provide \nmore personalized responses based on the user’s prior \ninteractions. \nAPI Access\nAPI access involves sending individual API calls directly \nto an LLM server using programming code. Each API call \nis independent by default, which means that it does not \nautomatically retain any memory of prior interactions. \nUsers who wish to maintain continuity across multiple \nAPI calls (i.e., create a session) must include a history \nof prior exchanges in each request. This allows users to \ncreate session-like experiences. The API approach enables \nautomated batch processing of large datasets, for example, \nby repeatedly extracting specific information from a large \ncollection of text documents. In addition, users can precisely \ncontrol model parameters, such as the model version \n(e.g., GPT-4o or GPT-4.5), temperature (which adjusts the \nrandomness of responses), and response formats (e.g., JSON \nor free text). This capability facilitates tasks that require \ncustomized data analysis, precise information extraction, or \nintegration with existing systems and research workflows. \nFurthermore, API access may allow fine-tuning–customizing \na model’s behavior to suit specific tasks.\nAPI usage requires an initial setup that includes \nprogramming skills and infrastructure preparation. Pricing \ntypically follows a usage-based model calculated using the \ntoken or request volume, whereas web-based interfaces \noften use time-based subscription plans. Table 1 compares \nweb-based interfaces and API access, highlighting \ndifferences in accessibility, control, and customization. \nSome hands-on experience with LLM APIs can be gained \nusing sample codes available from Google Colab at \nhttps://colab.research.google.com/drive/15R27_n1Qk0W_\nl3IRgeOOAkpdx7HpEYww.\nRemote Server API vs. Local/Institutional API: \nSignificance in the Medical Environment\nIn medical applications of LLMs, the location and method \nof patient data processing are critical because of strict \nregulations such as the Medical Services Act and Personal \nInformation Protection Act. These laws may restrict data \ntransfer to external entities, making a choice between \nremote (public) and local/institutional APIs a matter of \ncareful consideration.\nRemote Server (Public) API\nThis approach sends data to external LLM providers (e.g., \nOpenAI and Google) and returns the processed results. It \noffers low setup costs and access to cutting-edge models, \nbut raises legal and ethical issues regarding breaches of \nsecurity involving sensitive patient data or the provision \nof such data to third parties without patient consent. \nInstitutional network policies may block API access and \ncosts can increase substantially with usage.\nLocal/Institutional API\nThis approach involves hosting and managing an LLM \non servers within the hospital or internal network of the \nresearch institution. By keeping patient data on-site, this \nmethod enhances data security, ensures compliance with \nprivacy regulations, and facilitates seamless integration \nwith existing medical information systems and research \nworkflows.\nLocal or institutionally hosted APIs are generally \nfeasible with open-source LLMs, such as LLaMA, Mistral, or \nDeepSeek, which can be configured to run entirely within \nthe internal infrastructure without requiring an internet \nconnection, thereby ensuring data security. Although \ncommercial models (such as GPT and Gemini) are typically \naccessed via cloud services, some institutions may negotiate \nspecial agreements with providers for dedicated or on-\npremise deployment. Such arrangements are usually limited \nto organizations with substantial technical resources and \nstrict security requirements.\nThis approach requires significant initial investments \nin hardware, substantial technical expertise, and ongoing \nresources for model maintenance, security management, and \nsoftware updates.\nLocal/Institutional API: \nBrief Overview of Implementation \nHardware Preparation\nDeploying a local API requires the selection of suitable \nhardware, typically GPU-equipped servers, with specifications \nthat depend on the size of the model. Hardware \nrecommendations can be found on the Hugging Face models \nand LLM Leaderboard (https://huggingface.co/models).\nSoftware Installation\nThe software setup for the local LLMs depends on the model \nand its complexity. Traditionally, this involves downloading \n795\nAPI for LLMs\nhttps://doi.org/10.3348/kjr.2025.0360kjronline.org\nmodel files and configuring them using command line tools or \nDocker. New platforms such as Ollama (https://ollama.com) \nand LM Studio (https://lmstudio.ai) simplify this process \nwith user-friendly interfaces, thus reducing complexity and \nmaking local LLM deployment accessible, even for institutions \nwith limited technical expertise. \nAPI Server Configuration\nAfter deploying an LLM, an internal API server is configured \nto provide secure access within the institutional network. This \nusually involves implementing standardized communication \nprotocols such as Representational State Transfer (RESTful) \nAPIs or remote procedure call (gRPC), which enable efficient \nrequest handling and response delivery. \n• RESTful APIs: A widely used protocol that uses HTTP \nmethods (GET and POST) and exchanges data in formats \nsuch as JSON.\n• gRPC: A high-performance protocol using HTTP/2 that \nis, ideal for fast real-time communication.\nCONCLUSION\nLLMs are expected to play an important role in clinical \nresearch [6,7]. Compared to web interfaces, APIs offer \ngreater flexibility, control, and secure data management, \nmaking them a valuable tool for leveraging LLM capabilities. \nAs LLM agents advance, the distinction between web \ninterfaces and API access gradually diminishes.\nConflicts of Interest\nChong Hyun Suh, a Assistants to the Editor of the Korean \nJournal of Radiology, was not involved in the editorial \nevaluation or decision to publish this article. The remaining \nauthor has declared no conflicts of interest.\nAuthor Contributions\nConceptualization: Woo Hyun Shim. Data curation: Chae Ri \nPark, Hwon Heo. Formal analysis: Woo Hyun Shim. Funding \nacquisition: Woo Hyun Shim. Investigation: Chae Ri Park, \nWoo Hyun Shim. Methodology: Hwon Heo, Woo Hyun Shim. \nProject administration: Woo Hyun Shim. Resources: Chae \nTable 1. Comparison between web-based interface and API access for LLM use\nCategory Web-based interface API access\nAccessibility Requires only a web browser; no installation or \nprogramming needed. Provides an intuitive UI/UX\nRequires direct API calls via programming. Initial setup \nincludes authentication and API key configuration\nSession and history \nmanagement\nAutomatically saves conversation history but has \nlimited integration with external systems\nNo built-in session management; each API call is \nindependent. To simulate a session, users must include \nprior prompts and responses in each request\nParameter control Some settings (e.g., response style, output length) are \nadjustable through the interface, but detailed control \nover advanced model parameters may be limited\nAllows fine-grained control over various parameters \n(e.g., model version, temperature, top-p, response \nformat)\nBatch processing/\nautomation\nManual input for each query, but AI agents (e.g., \nChatGPT, Gemini) can automate tasks\nOptimized for repetitive tasks and large-scale data \nprocessing; supports automated pipelines\nSecurity and data \nprivacy\nProcesses user input on external servers with limited \ntransparency in data handling; may not be suitable \nfor sensitive information\nLLM APIs can operate within a controlled environment \n(on-premises, private cloud) or on external servers. \nLocal or on-premises deployment ensures full data \ncontrol, while public API usage may involve data \ntransmission risks\nCost structure Typically offers free trials or subscription-based plans, \nwith minimal additional costs for usage\nPrimarily usage-based pricing (pay-as-you-go); costs \nincrease based on token usage and API call volume\nError handling and \nrecovery\nErrors require manual refresh or retry Supports error handling through API response codes and \nbackoff mechanisms, improving system stability\nVersion management Always uses the latest model, making it difficult to \nmaintain a fixed version over time\nAllows selection of specific model versions, enabling \nlong-term stability and controlled upgrades\nIntegration and \ncustomization\nLimited to predefined web UI functionality; restricted \nsystem integration\nEasily integrates with existing research pipelines and \ninstitutional systems (e.g., hospital systems). Allows \nfull customization of applications\nAPI = application programming interface, LLM = large language model, UI = user interface, UX = user experience\n796\nPark et al.\nhttps://doi.org/10.3348/kjr.2025.0360 kjronline.org\nRi Park, Woo Hyun Shim. Software: Hwon Heo, Woo Hyun \nShim. Supervision: Chong Hyun Suh, Hwon Heo, Woo Hyun \nShim. Validation: Chong Hyun Suh, Hwon Heo. Visualization: \nChae Ri Park, Woo Hyun Shim. Writing—original draft: Chae \nRi Park, Woo Hyun Shim. Writing—review & editing: all \nauthors.\nORCID IDs\nChae Ri Park\nhttps://orcid.org/0000-0001-8361-5729\nHwon Heo\nhttps://orcid.org/0000-0002-6103-4680\nChong Hyun Suh\nhttps://orcid.org/0000-0002-4737-0530\nWoo Hyun Shim\nhttps://orcid.org/0000-0002-1532-5970\nFunding Statement\nThis study was supported by a grant (20241P0060-1) from \nthe Asan Institute for Life Sciences, Asan Medical Center, \nSeoul, Korea.\nREFERENCES\n1. Garimella M. The art of API design: best practices for modern \nsoftware development. Int J Eng Tech Res 2024;9:229-239\n2. Knoche H, Hasselbring W. Continuous API evolution in \nheterogenous enterprise software systems [accessed on \nMay 11, 2021]. Available at: http://doi.org/10.1109/\nICSA51549.2021.00014\n3. Raatikainen M, Kettunen E, Salonen A, Komssi M, Mikkonen T, \nLehtonen T. State of the practice in application programming \ninterfaces (APIs): a case study. In: Biffl S, Navarro E, Löwe W, \nSirjani M, Mirandola R, Weyns D, eds. Software architecture. \nECSA 2021. Lecture notes in computer science (vol 12857). \nCham: Springer, 2021:191-206\n4. Kotstein S, Bogner J. Which RESTful API design rules are \nimportant and how do they improve software quality? A Delphi \nstudy with industry experts. arXiv [Preprint]. 2021 [accessed \non July 30,  2021]. Available at: https://doi.org/10.48550/\narXiv.2108.00033\n5. Lercher A, Glock J, Macho C, Pinzger M. Microservice API \nevolution in practice: a study on strategies and challenges. J \nSyst Softw 2024;215:112110\n6. Lee JH, Shin J. How to optimize prompting for large language \nmodels in clinical research. Korean J Radiol 2024;25:869-873\n7. Park SH, Suh CH, Lee JH, Kahn CE, Moy L. Minimum reporting \nitems for clear evaluation of accuracy reports of large language \nmodels in healthcare (MI-CLEAR-LLM). Korean J Radiol \n2024;25:865-868"
}