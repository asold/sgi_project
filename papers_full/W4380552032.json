{
  "title": "Empowering Molecule Discovery for Molecule-Caption Translation with Large Language Models: A ChatGPT Perspective",
  "url": "https://openalex.org/W4380552032",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2358615348",
      "name": "Li Jiatong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2223928583",
      "name": "Liu Yun-qing",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2643408872",
      "name": "Fan Wen-qi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4226361612",
      "name": "Wei, Xiao-Yong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1896362166",
      "name": "Liu Hui",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2350772420",
      "name": "Tang, Jiliang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1935408072",
      "name": "Li Qing",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4365597205",
    "https://openalex.org/W4241677786",
    "https://openalex.org/W2999242200",
    "https://openalex.org/W4220699355",
    "https://openalex.org/W4385764461",
    "https://openalex.org/W4389888290",
    "https://openalex.org/W2338373933",
    "https://openalex.org/W2986232138",
    "https://openalex.org/W1987869189",
    "https://openalex.org/W4207035044",
    "https://openalex.org/W4212837331",
    "https://openalex.org/W4226282856",
    "https://openalex.org/W2101746535",
    "https://openalex.org/W3207373390",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4387874094",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3211951295",
    "https://openalex.org/W4252076394",
    "https://openalex.org/W2931503046",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4320086632",
    "https://openalex.org/W3093934881",
    "https://openalex.org/W4287891464",
    "https://openalex.org/W1975147762",
    "https://openalex.org/W2982893348",
    "https://openalex.org/W4386728933",
    "https://openalex.org/W1984994707",
    "https://openalex.org/W4316036243",
    "https://openalex.org/W4323065907",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W3043096321",
    "https://openalex.org/W4289595467",
    "https://openalex.org/W4377096651",
    "https://openalex.org/W4385572894",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4295846611",
    "https://openalex.org/W3209056694",
    "https://openalex.org/W4366850747"
  ],
  "abstract": "Molecule discovery plays a crucial role in various scientific fields, advancing the design of tailored materials and drugs. However, most of the existing methods heavily rely on domain experts, require excessive computational cost, or suffer from sub-optimal performance. On the other hand, Large Language Models (LLMs), like ChatGPT, have shown remarkable performance in various cross-modal tasks due to their powerful capabilities in natural language understanding, generalization, and in-context learning (ICL), which provides unprecedented opportunities to advance molecule discovery. Despite several previous works trying to apply LLMs in this task, the lack of domain-specific corpus and difficulties in training specialized LLMs still remain challenges. In this work, we propose a novel LLM-based framework (MolReGPT) for molecule-caption translation, where an In-Context Few-Shot Molecule Learning paradigm is introduced to empower molecule discovery with LLMs like ChatGPT to perform their in-context learning capability without domain-specific pre-training and fine-tuning. MolReGPT leverages the principle of molecular similarity to retrieve similar molecules and their text descriptions from a local database to enable LLMs to learn the task knowledge from context examples. We evaluate the effectiveness of MolReGPT on molecule-caption translation, including molecule understanding and text-based molecule generation. Experimental results show that compared to fine-tuned models, MolReGPT outperforms MolT5-base and is comparable to MolT5-large without additional training. To the best of our knowledge, MolReGPT is the first work to leverage LLMs via in-context learning in molecule-caption translation for advancing molecule discovery. Our work expands the scope of LLM applications, as well as providing a new paradigm for molecule discovery and design.",
  "full_text": "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 1\nEmpowering Molecule Discovery for\nMolecule-Caption Translation with Large\nLanguage Models: A ChatGPT Perspective\nJiatong Li, Yunqing Liu, Wenqi Fan, Xiao-Y ong Wei, Hui Liu, Jiliang Tang, and Qing Li\nAbstract—Molecule discovery plays a crucial role in various scientific fields, advancing the design of tailored materials and drugs, which\ncontributes to the development of society and human well-being. Specifically, molecule-caption translation is an important task for\nmolecule discovery, aligning human understanding with molecular space. However, most of the existing methods heavily rely on domain\nexperts, require excessive computational cost, or suffer from sub-optimal performance. On the other hand, Large Language Models\n(LLMs), like ChatGPT, have shown remarkable performance in various cross-modal tasks due to their powerful capabilities in natural\nlanguage understanding, generalization, and in-context learning (ICL), which provides unprecedented opportunities to advance molecule\ndiscovery. Despite several previous works trying to apply LLMs in this task, the lack of domain-specific corpus and difficulties in training\nspecialized LLMs still remain challenges. In this work, we propose a novel LLM-based framework (MolReGPT) for molecule-caption\ntranslation, where an In-Context Few-Shot Molecule Learning paradigm is introduced to empower molecule discovery with LLMs like\nChatGPT to perform their in-context learning capability without domain-specific pre-training and fine-tuning. MolReGPT leverages the\nprinciple of molecular similarity to retrieve similar molecules and their text descriptions from a local database to enable LLMs to learn the\ntask knowledge from context examples. We evaluate the effectiveness of MolReGPT on molecule-caption translation, including molecule\nunderstanding and text-based molecule generation. Experimental results show that compared to fine-tuned models, MolReGPT\noutperforms MolT5-base and is comparable to MolT5-large without additional training. To the best of our knowledge, MolReGPT is the\nfirst work to leverage LLMs via in-context learning in molecule-caption translation for advancing molecule discovery. Our work expands\nthe scope of LLM applications, as well as providing a new paradigm for molecule discovery and design. Notably, our implementation is\navailable at: https://github.com/phenixace/MolReGPT\nIndex Terms—Drug Discovery, Large Language Models (LLMs), In-context Learning, Retrieval Augmented Generation.\n✦\n1 I NTRODUCTION\nAs the foundation of chemical compounds, molecules are\ncomposed of two or more atoms that are chemically bonded\ntogether, denoting their unique chemical properties dictated\nby their specific structures [1]. With a comprehensive\nunderstanding of molecules, scientists can effectively design\nmaterials, drugs, and products with tailored characteristics\nand functionalities, impacting a variety of crucial fields such\nas chemistry [2], pharmacology [3], and material science [4].\nRecently, computational technologies such as artificial\nintelligence (AI) have emerged as powerful tools to expedite\nthe discovery of new molecules [5]. Specifically, molecules\ncan be represented as simplified molecular-input line-entry\nsystem ( SMILES) strings [6], illustrated in Figure 1 (a),\nwhich can be effectively processed by deep sequence models\nlike Recurrent Neural Networks [7] and Transformers [8].\nThese AI-powered models enable researchers to understand\nmolecular properties and functionalities and thus create\npromising compounds in a more efficient and cost-effective\n• J. Li, Y. Liu, W. Fan, X. Wei, and Q. Li are with the Department\nof Computing, The Hong Kong Polytechnic University. E-mail:\n{jiatong.li, yunqing617.liu}@connect.polyu.hk, wenqifan03@gmail.com,\nx1wei@polyu.edu.hk, csqli@comp.polyu.edu.hk.\n• J. Tang and H. LIu are with Michigan State University. E-mail:\ntangjili@msu.edu and liuhui7@msu.edu.\n(Corresponding authors: Yunqing Liu and Qing Li.)\nmanner. For example, in order to generate new molecules\nand better comprehend them, a novel task that translates\nbetween molecules and natural language has been proposed\nby using language models like Text2Mol [9] and MolT5 [10].\nIt consists of two sub-tasks: molecule captioning (Mol2Cap)\nand text-based molecule generation (Cap2Mol). As shown\nin Figure 1 (b-c), the goal of Mol2Cap is to generate a text\ncaption describing molecule features (e.g. structures and char-\nacteristics). Specifically, the text caption first demonstrates the\nmolecule structure by describing functional group positions\nand the according IUPAC name. Then, the characteristics\nof the molecule will be discussed, including the family\nthat it belongs to and the chemical features that affect its\npractical use. On the other hand, Cap2Mol aims to generate\nthe corresponding molecule (i.e., SMILES string) based on\nthe given text caption, where the structure and feature\ninformation of the molecules could be used to infer the\nSMILES representation of the molecule. For example, given\nthe molecule ”CCCCCCCCCCCCCCCCCCCCCCCCCCCCC”,\nits caption writes ”The molecule is a straight-chain alkane\ncomprising of 29 carbon atoms. It has a role as a plant metabolite\nand a volatile oil component” , where ”straight-chain alkane” and\n”29 carbon atoms” directly describe the molecule structure,\nwhile the last sentence shows the functions of the molecule.\nDespite the impressive progress that has been made in\nthe molecule-caption translation task [9]–[11], the majority of\nexisting advanced approaches still suffer from several limita-\narXiv:2306.06615v2  [cs.CL]  22 Apr 2024\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 2\nPhenol \nC1(O)=CC=C\nC=C1\nMolecule \nGraph: \nSMILES \nString: \nChemical \nFormula:  \n(a) Molecule Representations.\nThe molecule\nis...[Structure]...\n[Property]...\nC1(O)=CC=CC=C1\nAI \n(b) Molecule Captioning.\nThe molecule\nis...[Structure]...\n[Property]...\nC1(O)=CC=CC=C1\nAI \n(c) Text-based Molecule Gener-\nation.\n  Please show me a description of this molecule:\n\"C1=CC=C(C=C1)OC2=CC=CC=C2\"\n  The molecule is an aromatic ether in which the\noxygen is attached to two phenyl substituents.\nIt has been found in muscat grapes and vanilla.\nIt has a role as a plant metabolite.\nChatGPT \n(a) Molecule Captioning\n  Help me generate a molecule based on the\ngiven description: \n\"\nThe molecule is a quinolinemonocarboxylate that\nis the conjugate base of xanthurenic acid,\nobtained by deprotonation of the carboxy group.\nIt has a role as an animal metabolite. It is a\nconjugate base of a xanthurenic acid.\n\"\n  C1=CC2=C(C(=C1)[O-])NC(=CC2=O)C(=O)O\n(b) Text-based Molecule Generation (d) Empowering ChatGPT with\nmolecule captioning and text-based\nmolecule generation abilities.\nFigure 1: An illustration of molecule-caption translation.\n(a) Representations of a molecule. (b) Molecule captioning\n(Mol2Cap) aims to generate a text caption describing the\nfeatures of the molecule. (c) Text-based molecule generation\n(Cap2Mol) generates a corresponding molecule to the\ngiven caption. (d) Large language models (e.g., ChatGPT)\ncan perform Mol2Cap and Cap2Mol with well-designed\nprompts.\ntions. First, the design of model architectures heavily relies\non the labour of domain experts, which can significantly\nlimit the development of AI-powered molecule discovery.\nSecond, most existing methods follow the pre-train&fine-\ntuning paradigm for molecule-caption translation, putting\ndemanding requirements on computational and domain\nresources. Third, existing approaches such as Text2Mol and\nMolT5 fall short in their inability to generalize to unseen\nexamples. Therefore, it is desired to design a novel paradigm\nfor molecule-caption translation.\nRecently, Large Language Models ( LLMs), scaling up\ntheir weights to the billion level, have achieved tremen-\ndous success not only in the field of Natural Language\nProcessing (NLP) but also in some cross-modal areas\nlike computer vision [12], recommender systems [13], and\nmolecule discovery [10]. Meanwhile, in addition to the\nimpressive capabilities in natural language understanding\nand generation, LLMs also demonstrate their powerful\ngeneralization and reasoning capabilities [14], [15], which\ncan generalize to other unseen tasks via in-context learning\nwithout the necessity of being fine-tuned, largely reducing\ncomputational cost. Therefore, LLMs provide unprecedented\npotential to advance molecule discovery, specifically the task\nof molecule-caption translation.\nAlthough building specific LLMs in molecule discovery\nhas immense potential for advancing scientific research, we\nalso face significant challenges. First, due to privacy and\nsecurity concerns, many advanced large language models\n(e.g., GPT-3.5 and GPT-4) are not publicly available, where\nLLMs’ architectures and parameters are not released publicly\nfor fine-tuning in downstream tasks. Second, owing to their\ncomplex architectures and the extensive data required,\ntraining advanced LLMs requires significant computing\nresources and domain corpus, leading to high costs and\nsubstantial energy consumption. For instance, it has been\nreported that the cost of one single training session for GPT-3\nexceeds 1 million US dollars. As a result, it is very challenging\nfor us to re-design our own LLMs with pre-training and fine-\ntuning in specific downstream tasks. At last , it still lacks\nproper guidelines/paradigms for scientific researchers to\nmake use of powerful LLMs like ChatGPT to enhance their\nown study in molecule discovery.\nTo address such challenges, as the early exploration\nattempt to take advantage of the powerful capabilities of\nLLMs in the molecule discovery field, in this work, we\npropose a novel solution to teach LLMs with specific in-\ncontext examples for translating between molecules and\nnatural language, as illustrated in Figure 1 (d). More\nspecifically, inspired by the latest ChatGPT, a retrieval-\nbased In-Context Few-Shot Molecule Learning paradigm\nis developed to conduct two sub-tasks (i.e., Mol2Cap and\nCap2Mol) without fine-tuning the LLMs, where n similar\nmolecule-caption pairs are retrieved as context instances\nunder the guidance of molecular similarity, including BM25-\nbased caption retrieval and Morgan Fingerprints-based\nmolecule retrieval. Experiments show that MolReGPT (GPT-\n4-0314) achieves Text2Mol scores of 0.585 in Mol2Cap and\n0.593 in Cap2Mol, showing comparable performance to\nMolT5-large in Mol2Cap and even outperforming MolT5-\nlarge in Cap2Mol without any fine-tuning steps, increasing\nthe Text2Mol metric by 0.5% and 6%, respectively.\nOur major contributions are summarized as follows:\n• We introduce a principle strategy based on LLMs, In-\nContext Few-Shot Molecule Learning, to perform transla-\ntion between molecules and natural language for molecule\ndiscovery. To the best of our knowledge, we are the first to\nemploy the in-context learning ability of LLMs in molecule-\ncaption translation. Our work expands the application\nscope of LLMs and provides valuable insights into how\nthese LLMs can be adapted for specific scientific tasks.\n• We develop a novel framework (MolReGPT) to empower\nLLMs like ChatGPT for scientific purposes without being\npre-trained or fine-tuned on domain-specific corpora. By\nenabling LLMs to understand and generate meaningful\nmolecular descriptions and molecule structures, we pave\nthe way for AI-assisted drug discovery and design.\nMolReGPT has the potential to accelerate the development\nof new pharmaceuticals and improve the efficiency of\nmolecular research.\n• We conduct comprehensive experiments on a real-world\ndataset with molecule-caption pairs to demonstrate the\neffectiveness and mechanisms of the proposed method on\nMol2Cap and Cap2Mol tasks. The results show that our\nmethod could enable GPT4-0314 to achieve comparable\nperformance to MolT5-large.\n2 R ELATED WORK\nMolecule Discovery . In recent decades, AI-powered ap-\nproaches have emerged as mainstream techniques to rev-\nolutionize the process of molecule discovery [16], [17].\nexisting studies have explored advanced deep representation\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 3\nmethods from other fields, including Convolutional Neural\nNetwork (CNN) [18], [19], Recurrent Neural Network\n(RNN) [20], [21], and Transformer [22], [23]. More recently,\nas a new task in molecule discovery, Text2Mol [9] is\nintroduced to retrieve molecules using natural language\ndescriptions as search queries, in which a paired dataset\nof molecules and their corresponding text descriptions are\nconstructed, enabling the learning of a shared semantic\nembedding space for retrieval. KV-PLM [24] develops a\nknowledgeable machine reading system pre-trained on a\ndomain corpus, in which SMILES strings are inserted and\nlink molecule structures with biomedical text. What’s more,\na self-supervised learning framework MolT5 [10] is proposed\nto pre-train on a substantial volume of unlabeled language\ntext and SMILES strings, enhancing the molecule-caption\ntranslation task, such as molecule captioning and text-based\nmolecule generation. MoMu [11] bridges molecular graphs\nand natural language by pre-training molecular graphs and\ntheir semantically related text data through comparative\nlearning.\nLarge Language Models (LLMs). LLMs have been a trending\ntopic in recent years, with numerous studies exploring their\ncapabilities and potential applications. One of the most well-\nknown LLMs is the GPT family [25]–[27], which has played\na critical role in advancing the field of generative language\nmodels. As a representative of the GPT family, ChatGPT is\nspecifically fine-tuned for conversational purposes, which\ncan generate impressively human-like responses [28]. In\naddition, other LLMs, such as LaMDA [29], PaLM [30], and\nVicuna [31], also show a decent performance.\nIn addition to NLP tasks, LLMs have also shown\nremarkable potential in various molecule discovery tasks,\nsuch as molecule understanding [32], [33]. For instance,\nChemBERTa [34] leverages pre-training on an extensive\ncorpus of chemical texts, enabling it to comprehend the\nstructure and properties of chemical compounds. Another\nnotable example is MoleculeSTM [35], which employs in-\ncontext learning in conjunction with LLMs. This approach\nfacilitates a deeper understanding of the relationships\nbetween chemical structures and their corresponding textual\ndescriptions. Furthermore, ChemGPT [36] represents a vari-\nant of the GPT model specifically trained on chemical data.\nThrough well-designed instructions, ChemGPT is capable\nof generating novel chemical structures and accurately\npredicting their properties. MolT5 [10] shows that LLMs can\nperform the cross-modal transition task between molecule\nand text (i.e. molecule captioning task and text-based\nmolecule generation task), which is one of the most closely\nrelated attempts to ours. Besides, it should be noted that\nMolT5 still needs to be pre-trained on domain corpus and\nfurther fine-tuned for translating between molecules and\nnatural language, leading to huge computational costs and\nharsh data requirements.\n3 M OLREGPT\nDue to the huge computation and domain data labelling\ncosts, training or fine-tuning LLMs on the domain-specific\ncorpus in molecule discovery is often infeasible in practice.\nTo address such limitations, we investigate leveraging the\ngreat capabilities of LLMs without changing the LLMs,\nwhere we propose a novel framework ( MolReGPT) to equip\nChatGPT with the ability of molecule-caption translation\nfor molecule discovery. Specifically, in order to improve\nthe quality of prediction, an In-Context Few-Shot Molecule\nLearning paradigm is introduced to teach ChatGPT to\nlearn the molecule-caption translation task from context\nexamples. The framework of MolReGPT is shown in Figure\n2, consisting of four main stages: Molecule-Caption Retrieval,\nPrompt Management, In-Context Few-Shot Molecule Learning ,\nand Generation Calibration, following the workflow of pre-\nprocessing, querying, and post-processing.\n3.1 Molecule-Caption Retrieval\nIn order to teach LLMs to handle the molecule-caption\ntranslation task without fine-tuning LLMs, we propose\nin-context few-shot molecule learning to guide LLMs to\nlearn how to translate between molecules and text captions.\nNormally, in-context learning requires n random examples\nselected from human-annotated datasets (i.e., molecule-\ncaption pair database), providing a general task instruction to\nLLMs. However, random examples often provide insufficient\nknowledge regarding the associations between natural\nlanguage and molecules, as they fail to provide useful\ninformation for the detailed descriptions of functional groups\nand molecule features. To mitigate this issue, we propose\nincorporating retrieval methods into the selection of context\nexamples to complement the lack of task-specific knowledge\nin LLMs, specifically through the stage of Molecule-Caption\nRetrieval. These retrieval strategies are motivated by the\nsimilar property principle, in which molecules similar in\nstructures tend to exhibit similar characteristics [37]. Namely,\nsimilar captions containing the descriptions of molecule\nstructures and properties are used to describe similar\nmolecules. Therefore, via these most similar molecules\nor captions, we could utilize the corresponding molecule-\ncaption pairs as context examples to guide LLMs.\nNotably, the SMILES representation of molecules, as a\nsequence structure, can hardly reveal the actual 2-D graph\ntopology of molecules. Hence, domain-specific methods are\nrequired for better molecular similarity calculation during\nthe retrieval stage. Specifically, given a SMILES string\nrepresentation for Mol2Cap task, we introduce using Morgan\nFingerprints (i.e., a molecular structures representation) [38]\nto calculate molecular similarity using Dice similarity for\nmolecule retrieval. Meanwhile, in Cap2Mol task, we are\nmore focused on the details in the text captions (e.g., IUPAC\nnames and functional group positions). Thus, BM25 caption\nretrieval, which is widely used in information retrieval [39],\nis proposed to compute similarity scores between captions\nof molecules.In both sub-tasks, top-n molecule-caption pair\nexamples are retrieved to serve as context examples in the\nsystem prompt. Next, we will detail Morgan Fingerprints-\nbased molecule retrieval and BM25-based caption retrieval.\n3.1.1 Morgan Fingerprints-based Molecule Retrieval.\nMolecular fingerprints are numerical representations of the\nchemical structures of molecules, which can be used for\nvarious computational objectives [38], such as similarity\nsearching, property prediction, and cluster analysis. One of\nthe most representative molecular fingerprints is the Morgan\nFingerprints (Morgan FTS).\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 4\nGiven the SMILES representation of a molecule, your job is topredict the caption of the molecule. The molecule caption is a\nsentence that describes the molecule, which mainly describes themolecule's structures, properties, and production.\nExample i: \nInstruction: Given the SMILES representation of amolecule, predict the caption of the molecule. \nInput: [Molecule Place Holder]\n……\nYour output should be: \n{\"caption\": \"[Caption Place Holder]\"} \nYour response should only be in the JSON format above; THERE SHOULD BE NO OTHER CONTENT INCLUDED IN YOUR\nRESPONSE. \nGiven the caption of a molecule, your job is to predict the SMILESrepresentation of the molecule. The molecule caption is a sentence thatdescribes the molecule, which mainly describes the molecule's structures,\nproperties, and production. You can infer the molecule SMILESrepresentation from the caption.\nExample i: \nInstruction: Given the caption of a molecule,predict the SMILES representation of themolecule. \nInput: [Caption Place Holder]\n…… \nYour output should be: \n{\"molecule\": \"[Molecule Place Holder]\"} \nRole Identification\nTask\nDescription\nExamples\nOutput\nInstruction\n# 2: Prompt Management\n# 1: Molecule-Caption Retrieval # 3: In-Context Few-Shot Molecule Learning\n# 4: Generation Calibration\nSystem Prompt Molecule Captioning Task\n (Mol2Cap Prompt)\nText-based Molecule Generation Task\n(Cap2Mol Prompt)\nInput Retriever Top-n Examples\nMol Cap \nMol Cap \nMol Cap \nMol Cap \nMol Cap \nBM25\nMorgan\nFingerprints\nMol Cap Mol Cap \nMol Cap Mol Cap \nMol Cap Mol Cap \nMol Cap Mol Cap \nMol Cap Score \nMol Cap Score \nMol Cap Score \nMol Cap Score \nMol Cap Score \nMol Cap Score \nMol Cap Score \nMol Cap Score \nDatabase\nRanks\nDice\nSimilarity\nBM25\nScore\nMol Cap\nMol Cap\nOriginal Response Revised Response\nSystem Prompt\nUser Input Prompt\nValid Response\nGeneration\nCalibration\nRole IdentificationTask Description Output InstructionExamples\nExit\nRe-query\nThe molecule is a nitrilethat is acetonitrile whereone of the methylhydrogens is substitutedby a phenyl group. It hasa role as a pheromone andan animal metabolite. It isa nitrile and a member ofbenzenes. It derivesfrom an acetonitrile.\nThe molecule is a nitrilethat is acetonitrile\nwhere one of themethyl hydrogens issubstituted by a 2-thienyl group. It is anitrile and a member ofthiophenes. It derives\nfrom an acetonitrile.\nC1=CC=C(C=C1)CC#N\nC1=CSC(=C1)CC#N\n“Input:\n[Place_Holder]\\n\"\nQuery\nChatGPT as Example\nServe as\nContext\n{\"caption\":[Caption_Place_Holder]}{\"molecule\": [Molecule_Place_Holder]}\n[0,0,...,1,\n0,...1,....]\n[The, molecule,\n..., 2,\nmethylphenyl,\n..., acetonitrile]\nFailed\nMaximum\nError Allowance\nPassed\nFormat\nCheck\nFormat\nCorrection\n{\"caption\":The molecule is an\narylacetonitrile carrying a\nmethyl substituent at the 4-\nposition. It has been isolated\nfrom the flower oils of Iris\npallida. It is an\narylacetonitrile and a\nmember of benzenes. It\nderives from a propionitrile.}\nThe molecule is anarylacetonitrile carrying amethyl substituent at the 4-position. It has been isolatedfrom the flower oils of Irispallida. It is anarylacetonitrile and amember of benzenes. Itderives from a propionitrile.\n{\"molecule\":\nCC(C#N)C1=CC=CC=C1C}\nCap2Mol Task\nCC(C#N)C1=CC=CC=C1C\nMol2Cap Task\nMolecule\nCC1=CC=CC=C1CC#N\nCaption\nThe molecule is a nitrile that\nis acetonitrile where one of\nthe methyl hydrogens is\nsubstituted by a 2-\nmethylphenyl group. It\nderives from an acetonitrile.\nMolecule Captioning Task\nText-based Molecule Generation Task\nExample 1\nExample n\nLLMs\nYou are now working as an excellent expert in chemisrty and molecule discovery. \nFigure 2: The workflow of MolReGPT. MolReGPT consists of four main stages. In stage 1, Molecule-Caption Retrieval is\nemployed to find n best-matched examples from the local database. Then, in stage 2, Prompt Management helps construct\nthe system prompt with the retrieved molecule-caption pairs. Following this, LLMs perform In-Context Few-Shot Molecule\nLearning based on the provided system prompt and user input prompt. Finally, Generation Calibration ensures the desired\noutput.\nC1=CC=C2C(=C1)C(=O)C3=C\n(C2=O)C=C(C=C3)C(=O)[O-]\nC1=CC2=C(C(=C1)[O-])\nNC(=CC2=O)C(=O)O\nSimilarity Map\nMorgan Fingerprints DiceSimilarity: 0.4043 \nMolecule 2Molecule 1\n[0,0,...,1,...,1,...] [0,0,...,1,...,0,...]\nFigure 3: Illustrations of Morgan Fingerprints and Dice\nSimilarity. The two molecules will first be transformed\ninto the Morgan Fingerprints. Then, Dice similarity will be\ncalculated. The green colour corresponds to sub-structures\nthat contribute positively to the similarity score between the\nmolecules, while the purple colour represents sub-structures\nthat contribute negatively or have differences between the\nmolecules.\nThe key idea behind Morgan FTS is to capture the\npresence or absence of specific sub-structures or chemical\nfragments in a molecule. Morgan FTS follows a variant of\nthe Morgan algorithm [38], which encodes the structural\ninformation of a molecule by representing its connectivity\npatterns in a circular manner. Morgan FTS is then generated\nby iteratively expanding a set of atoms from a central atom\nin the molecule, capturing the neighbouring atoms and their\nbond types at each expansion step. The process continues\nuntil a pre-defined radius is reached. The result is a binary\nbit vector, where each bit represents the presence or absence\nof a particular substructure.\nWhat’s more, Morgan FTS has several advantages\nover other types of fingerprints, including their ability\nto handle molecules of varying sizes, resistance to small\nstructural changes, and effectiveness in capturing structural\nsimilarities between molecules. Subsequently, we apply\nDice similarity [40] to measure the similarity between the\ninput molecule and the molecules in the local database.\nMathematically, it can be expressed as:\nDice(A, B) =(2 ∗ |A ∩ B|)\n|A| + |B| , (1)\nwhere A and B are the Morgan Fingerprints of two molecules.\n|A| and |B| represent the cardinality (i.e., number of sub-\nstructures) of A and B. |A ∩ B| denotes the number of sub-\nstructures that are common to both A and B. Dice similarity\nranges from 0 to 1. The Dice similarity is particularly useful\nwhen dealing with imbalanced datasets or focusing on the\nagreement between positive instances (i.e., sub-structures\npresent in both sets) rather than the overall agreement. As\nshown in Figure 3, the similarity map explains how Morgan\nFTS measures the similarities and differences between the\ntwo molecules.\nCompared to existing molecule embedding methods,\nMorgan FTS together with Dice similarity provides a\ndistinctive advantage by explicitly indicating the similarities\nin detailed molecular structures, as these structures are\nusually directly stated in the molecule captions [41].\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 5\n3.1.2 BM25-based Caption Retrieval.\nBM25 is one of the most representative ranking approaches\nin information retrieval for calculating the relevance of the\ndocuments to the given query. The idea is based on the\nterm frequency-inverse document frequency (TF-IDF), which\nmeasures how often a term appears in a document (i.e.,\ncaption) and how rare it is in the corpus of documents (i.e.,\nthe local database) [42]. In addition, BM25 considers the\ncaption’s length and the position of the query terms in the\ncaption.\nIn the Cap2Mol task, we use the input caption as the\nquery sentence, while the captions in the local database (i.e.,\nthe training set), are served as the corpus of documents,\nwhere each caption represents a document. Mathematically,\nthe formula of BM25 can be defined as follow:\nscore(Q,D) =\nNX\ni=1\nIDF(qi)∗ f(qi, D) ∗ (k1 + 1)\nf(qi,D)+k1 ∗( 1−b+b∗ |D|\navgdl)\n, (2)\nwhere D is the caption corpus and Q is the query caption. N\nis the number of query terms in the query caption, qi is the\ni-th query term, IDF (qi) is the inverse document frequency\nof qi, f(qi, D) is the term frequency of qi in D, k1 and b\nare tuning parameters, |D| is the length of D, and avgdl\nis the average caption length in the corpus. In Cap2Mol\ntask, as we discussed, structure details usually bring more\ninformation gain to the prediction of the molecule SMILES\nrepresentations, while such details are difficult to capture\nat the semantic level. In this case, BM25 caption retrieval is\napplied to calculate the similarity scores between captions\nat the token level so that the relevant molecule structures\ndescribed by captions can be learnt via molecule-caption\npairs.\n3.2 Prompt Management\nSystem prompts and user input prompts are two important\nparts to enable the in-context learning ability of LLMs. User\nprompts are usually more complex and contain essential\ninstructions for task solving and format formalization, where\nuser prompts are defined to formalize the user inputs. To\nhelp LLMs understand the task and generate desired outputs,\nPrompt Management is proposed to design the system\nprompt templates, which are further completed with the\ncontext examples. As shown in stage 2 of Figure 2, the system\nprompts consist of the following four parts:\n• Role Identification aims to help LLMs identify the role of\nexperts in the chemistry and molecule discovery domain.\nBy establishing this role, LLMs are encouraged to generate\nresponses aligning with the expected expertise.\n• Task Description provides a comprehensive explanation\nof the task’s content, ensuring that LLMs have a clear\nunderstanding of the specific task they need to address. It\nalso includes critical definitions to clarify terms or concepts\nthat are specialized in the molecule-caption translation\ntask.\n• Context Examples serves as the evidence for the molecule-\ncaption translation task, allowing LLMs to leverage the\ninformation contained within the molecule-caption pairs\nvia in-context learning to generate better responses.\n• Output Instruction specifies the desired format for the\nresponse. Here, we restrict the output to a JSON format for\nfurther processing or analysis.\n3.3 In-Context Few-Shot Molecule Learning\nRecently, as an alternative to fine-tuning, in-context learn-\ning provides great opportunities to teach LLMs to make\npredictions based on a few context examples. In this work,\nwe introduce In-Context Few-Shot Molecule Learning to\nperform the Mol2Cap and Cap2Mol tasks without fine-tuning\nLLMs and analyse the underlying mechanism. This stage is\nto utilize both the system prompt and user input prompt\nto query the LLMs. In particular, the combination of the\nsystem prompt and user input prompt provides LLMs with\na clear guideline via in-context learning; the system prompt\nestablishes domain expertise for molecule-caption translation,\nwhile the user prompt narrows the focus and directs the\nmodel’s attention to the specific user input. As a result, LLMs\ncan learn how to perform the molecule-caption translation\nfrom the given task context, without the necessity to modify\ntheir parameters.\nThe formulas below describe the differences between\nfine-tuning, prompting, and In-context Few-Shot Molecule\nLearning. Let M be the large language model, m be the\nmolecule, c be the corresponding molecule caption, and θ be\nthe parameters of the LLM.\nFine-tuning process for the Mol2Cap and Cap2Mol task aims\nto help LLMs learn the translation probability between the\nmolecule and its text caption:\nc = L(m; θ∗\nm), (3)\nm = L(c; θ∗\nc ), (4)\nwhere θ∗\nm and θ∗\nc are the updated parameters after being\nfine-tuned on the entire training set ( θ∗\nm for Mol2Cap and θ∗\nc\nfor Cap2Mol).\nPrompting uses prompts to wrap the inputs and guide the\ngeneration of LLMs without changing the parameters. It can\nbe defined as:\nc = L(pm(m); θ), (5)\nm = L(pc(c); θ), (6)\nwhere pm(·) and pc(·) are the Prompt Management templates\nthat transform the original user input (molecules pm or\ncaptions pc) into system prompts with the user input prompts\nfor querying LLMs, and θ is the original parameters without\nbeing fine-tuned.\nIn-Context Few-Shot Molecule Learning targets the align-\nment between text and molecule structures. Our method can\nbe formulated as:\nc = L(pm(m)||Tm→c; θ), (7)\nm = L(pc(c)||Tc→m; θ), (8)\nwhere Tm→c = (m1 → c1)||(m2 → c2)||...||(mn → cn)\nand Tc→m = (c1 → m1)||(c2 → m2)||...||(cn → mn) are the\nretrieved context examples for the Mol2Cap and Cap2Mol\ntask. Here, (ci → mi) denotes the i-th retrieved example that\nillustrates how to transfer from caption ci to the molecule mi,\nwhile (mi → ci) represents the alignment from the molecule\nmi to its caption ci, where i ∈ [1, n]. Notably, θ is still the\noriginal parameter of LLMs without any modification.\nThrough the way of learning the molecule-caption\ntranslation from context examples, LLMs can grasp the\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 6\nalignment between text description and the molecule\nstructures it implies. Compared to fine-tuning, our method\ndoes not require additional model training. Compared to\nprompting, our method is more explainable and robust due\nto the in-context learning process.\n3.4 Generation Calibration\nDespite specifying the desired output format, LLMs (e.g.,\nChatGPT) can occasionally produce unexpected responses,\nincluding incorrect output formats and denial of answering.\nTo address these issues, a generation calibration mechanism\nis introduced to validate the response from LLMs.\nIn Generation Calibration, we first check the format\nof original responses. If the format is not correct, several\npre-defined format correction strategies, such as Regular\nMatching, are introduced to correct the format and extract\nthe desired output from the response. If the original response\npasses the format check or can be calibrated, it is considered\nvalid and accepted as a final response. However, if the\noriginal response fails the format check and cannot be\ncorrected within the predefined strategies, we initiate re-\nqueries. Notably, there is a special case for re-queries. When\nthe original response reports the “Exceed Maximum Input\nLength Limitation” error, we will remove the longest example\nin the re-query phase until the query length meets the length\nlimitation. The re-query process involves making additional\nqueries to the LLMs until a valid response is obtained or\nuntil the maximum error allowance is reached to ensure that\nthe system does not get stuck in an endless loop.\n4 E XPERIMENT\nIn this section, we aim to evaluate the effectiveness of\nour proposed MolReGPT by conducting comprehensive\nexperiments on molecule-caption translation task.\n4.1 Experimental Settings\nWe first introduce the basic experimental settings. In this\nwork, we use ChatGPT through the OpenAI API 1 with\nbackend model GPT-3.5-turbo and GPT-4-0314, which\ncan not be fine-tuned in our tasks. To assure the model\nagnosticism of MolReGPT, we also apply an extra open-\nsource LLM, Llama-2-7b-chat-hf (i.e., Llama-2-7B) [43], for\ncomparison. Notably, due to the input length limitation and\nhardware limitation, we could only apply 2-shot MolReGPT\nto this model. Besides, we will provide an overview of the\ndata and metrics employed in this section.\nDataset. The research on molecule-caption translation is\nstill in the early stage, and there is only one public dataset\nChEBI-20 [9], which contains 33,010 molecule-caption pairs.\nTo ensure consistency, we adhere to the data split process\nas used in MolT5 [10], dividing the dataset into 80/10/10%\ntrain/validation/test splits. For our method evaluation, we\nfocus on the test split while utilizing the training set as\nthe local database to retrieve n-shot examples for in-context\nlearning.\nEvaluation Metrics. In terms of evaluation metrics, we align\nwith the metrics adopted in MolT5 [10]. By adopting these\n1. https://openai.com/blog/openai-api\nmetrics, we ensure consistency and enable a fair assessment\nof the performance of our method.\nBaselines. Specifically, the following baselines are selected\nfor performance evaluation. Most of these baselines are only\nfine-tuned on ChEBI-20 because of their limited maximum\ninput length and poor reasoning capabilities.\n• Transformer [44]. This method is the most representative\nlanguage architecture to process natural language. A\nvanilla Transformer model with six encoder and decoder\nlayers, directly trained on ChEBI-20. Notably, this model is\nnot pre-trained.\n• T5 [45]. T5 is pre-trained on the Colossal Clean Crawled\nCorpus (C4), but no domain knowledge is specifically fed\nfor pre-training. In this work, T5-base and T5-large are\ndirectly fine-tuned on ChEBI-20.\n• MolT5 [10]. MolT5 models are pre-trained on both\nlanguage texts and SMILES strings. More specifically,\nMolT5-base and MolT5-large were pre-trained on the\nColossal Clean Crawled Corpus (C4) and ZINC-15 datasets\nand further fine-tuned on ChEBI-20.\n4.2 Performance Comparison\nWe present the results of the molecule-caption translation\ntask, incorporating both quantitative analysis and detailed\nexamples for comparison.\nMolecule Captioning (Mol2Cap). Table 1 illustrates the\nperformance comparison of 10-shot MolReGPT (GPT-3.5-\nturbo) and 10-shot MolReGPT (GPT-4-0314) with the baseline\nmodels for Mol2Cap task, offering an overview of the results.\nNotably, our method can achieve better BLEU scores and\ncomparable ROUGE scores to MolT5-base when using GPT-\n3.5-turbo as the backend model. Meanwhile, when using\nGPT-4-0314 as the backend model, MolReGPT can obtain\nbetter BLEU and Text2Mol scores than MolT5-large without\nbeing fine-tuned on ChEBI-20 dataset. Furthermore, we\nobtain the following observations:\n• With the instruction of 10-shot MolReGPT, GPT-3.5-turbo\nachieves significantly improved results that gain an\nimprovement of 59% to the zero-shot case and 2.4% to\nMolT5-base under the Text2Mol metric, which indicates\nthat our proposed method can teach ChatGPT to effectively\nlearn the Mol2Cap task via in-context learning.\n• Restricted by the number of examples, MolReGPT only\ngains limited insights from the distribution of molecule\ncaptions (e.g., vocabulary and grammar). The LLMs’ pre-\ndictions for captions heavily rely on their internal factual\nknowledge and the contextual information provided by\nthe system prompt. Thus, such vocabulary and grammar\npatterns may not be as apparent and can not be captured\nfrom the selected n examples. As a result, although our\n10-shot MolReGPT (GPT-4-0314) achieves a 0.593 Text2Mol\nscore, which is higher than MolT5-large’s 0.554. MolReGPT,\nin turn, gets lower ROUGE scores compared to MolT5.\nHowever, it is crucial to note that captions generated by 10-\nshot MolReGPT with lower ROUGE scores are not entirely\nincorrect. In fact, the highest Text2Mol score serves as a\nreliable indicator of the generation quality and highlights\nthe better relevance between the generated molecules and\nthe molecule captions.\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 7\nMethods BLEU-2↑ BLEU-4↑ ROUGE-1 ↑ ROUGE-2 ↑ ROUGE-L ↑ METEOR ↑ Text2Mol↑\nTransformer [10] 0.061 0.027 0.204 0.087 0.186 0.114 0.057\nGPT-3.5-turbo (zero-shot) 0.103 0.050 0.261 0.088 0.204 0.161 0.352\nLLama-2-7B (zero-shot) 0.094 0.039 0.169 0.054 0.142 0.175 0.153\nLLama-2-7B (2-shot MolReGPT) 0.489 0.409 0.535 0.374 0.472 0.495 0.466\nT5-base [10] 0.511 0.423 0.607 0.451 0.550 0.539 0.523\nMolT5-base [10] 0.540 0.457 0.634 0.485 0.578 0.569 0.547\nGPT-3.5-turbo (10-shot MolReGPT) 0.565 0.482 0.623 0.450 0.543 0.585 0.560\nT5-large [10] 0.558 0.467 0.630 0.478 0.569 0.586 0.563\nMolT5-large [10] 0.594 0.508 0.654 0.510 0.594 0.614 0.582\nGPT-4-0314 (10-shot MolReGPT) 0.607 0.525 0.634 0.476 0.562 0.610 0.585\nTable 1: The performance of Mol2Cap on ChEBI-20. Experimental results for Transformer, T5-base, MolT5-base, T5-large,\nand MolT5-large are retrieved from [10]. Due to the input length limitation, we apply 2-shot MolReGPT to llama-2-7B and\n10-shot MolReGPT to GPT models. The best scores are in bold, and the second-best scores are underlined.\nMethod BLEU↑ EM↑ Levenshtein↓ MACCS FTS↑ RDK FTS↑ Morgan FTS↑ FCD↓ Text2Mol↑ Validity↑\nTransformer [10] 0.499 0.000 57.66 0.480 0.320 0.217 11.32 0.277 0.906\nGPT-3.5-turbo (zero-shot) 0.489 0.019 52.13 0.705 0.462 0.367 2.05 0.479 0.802\nLLama-2-7B (zero-shot) 0.104 0.000 84.18 0.243 0.119 0.089 42.01 0.148 0.631\nLLama-2-7B (2-shot MolReGPT) 0.693 0.022 36.77 0.808 0.717 0.609 4.90 0.149 0.761\nT5-base [10] 0.762 0.069 24.950 0.731 0.605 0.545 2.48 0.499 0.660\nMolT5-base [10] 0.769 0.081 24.458 0.721 0.588 0.529 2.18 0.496 0.772\nGPT-3.5-turbo (10-shot MolReGPT)0.790 0.139 24.91 0.847 0.708 0.624 0.57 0.571 0.887\nT5-large [10] 0.854 0.279 16.721 0.823 0.731 0.670 1.22 0.552 0.902\nMolT5-large [10] 0.854 0.311 16.071 0.834 0.746 0.684 1.20 0.554 0.905\nGPT-4-0314 (10-shot MolReGPT) 0.857 0.280 17.14 0.903 0.805 0.739 0.41 0.593 0.899\nTable 2: Cap2Mol results on ChEBI-20. Experimental results for Transformer, T5-base, MolT5-base, T5-large, and MolT5-large\nare retrieved from [10]. Due to the input length limitation, we apply 2-shot MolReGPT to llama-2-7B and 10-shot MolReGPT\nto GPT models. The best scores are in bold, and the second-best scores are underlined.\nConsidering the model agnosticism, MolReGPT increases\nthe caption generation performance consistently across the\nthree different models. This is particularly evident with\nLlama-2-7B, as it possesses a different model structure. As\ndepicted in Table 1, Llama-2-7B achieves 0.409 BLEU-4 score\nand 0.466 Text2Mol score without further fine-tuning, which\nis close to the performance of T5-base. This denotes that\nMolReGPT is not dependent on specific models but is a\ngeneral method that could be applicable to a broad spectrum\nof LLMs.\nFigure 4 compares our predicted captions with the ground\ntruth. It is clear that our prediction is quite close to the ground\ntruth, stating accurate details of molecule structures and\ngiving solid predictions of molecule properties. However, it\ncan also be seen that our results have some slight differences\nin the narrative order, which might influence the translation\nscores like BLEU and ROUGE. In Contrast, although MolT5-\nlarge achieves higher ROUGE scores, the generated captions\nstill make many fact and typo errors, contributing to a\nlower Text2Mol score. Besides, Transformer could hardly\ngenerate correct or valid results. For molecule 2 and 3, it\neven generates the same results, which means that the model\nis not sensitive to the input.\nText-based Molecule Generation (Cap2Mol). Results of\nthe text-based molecule generation task are presented in\nTable 2. Comparing all these baselines, 10-shot MolReGPT\nsignificantly enhances the capabilities of GPT-3.5-turbo and\nGPT-4-0314, leading to improved overall performance. In the\nText2Mol metric, MolReGPT helps GPT-3.5-turbo and GPT-4-\n0314 gain a significant 15% and 20% increase, respectively,\ncompared to MolT5-base. What’s more, GPT-4-0314 even\nachieves a 7% improvement compared to MolT5-large.\nConsidering the fingerprint scores, our 10-shot MolReGPT\n(GPT-4-0314) even gets an average of 8.1% improvement\ncompared to MolT5-large. More importantly, MolReGPT also\nsignificantly enhances the molecule generation capabilities\nof Llama-2-7B, elevating the BELU score from 0.104 to 0.693.\nGiven that Llama-2-7B was trained on a distinct corpus and\npossesses a different model architecture, it could further\ndemonstrate the model-agnostic nature of our approach.\nFigure 5 compares our predicted molecules with the\nground truth. It can be seen that our generated molecules are\nquite close to the ground truth in the molecular configuration.\nFor molecule 1, both MolT5-large and MolReGPT generate\nthe exact correct molecule, but the 2D graph is slightly\ndifferent to the ground truth due to the sequence order\nof the SMILES string. For molecule 2, MolT5-large misses\nseveral key structures, while MolReGPT generates the correct\nrepresentation. For molecule 3, MolT5-large fails to generate\nthe correct configuration, while MolReGPT generates the\ncorrect chemical bonds but misses the correct number of\ncarbon atoms.\nBesides, in Figure 6, we propose a practical scenario\nwhere a scientist aims to obtain molecules with desired\nstructures and properties. In the past, scientist needs to\napply domain knowledge to figure out a possible molecule\ncandidate. Then, experiments are required to verify its\nproperties. Now, with the help of MolReGPT, the scientist\ncould formalize the requirements via molecule captions and\nask MolReGPT to generate the desired molecules. To be\nmore specific, we list two examples here. Molecule 1 has\nfive benzene rings and several hydrophobic groups as its\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 8\nTransformerMolT5-large Ours Ground Truth\nthe molecule is the\nstable isotope of\nhelium with\nrelative atomic\nmass 3. 016029.\nthe least abundant\n( 0. 000137 atom\npercent ) isotope\nof naturally\noccurring helium.\nThe molecule is a hydrate\nthat is the monohydrate form\nof lithium chloride. It has a\nrole as an EC 5.3.3.5\n(cholestenol Delta-isomerase)\ninhibitor. It contains a lithium\ndichloride.\nThe molecule is a lithium\ncitrate(3-) salt formed by the\ncombination of three lithium\ncations and one citrate(3-)\nanion. It has a role as a mood\nstabilizer and an\nanticonvulsant. It consists of\nlithium and a 3-carboxy-2-\n(carboxymethyl)-2-\nhydroxypropanoate.\nThe molecule is a lithium\nsalt that is the anhydrous\nform of the trilithium salt\nof citric acid. The\ntetrahydrate form is used\nas a source of lithium for\nthe treatment of anxiety\ndisorders, bipolar\ndisorder, and depression.\nIt contains a citrate(3-).\nInput\nthe molecule is the\nstable isotope of\nmolybdenum with\nrelative atomic mass\n94. 905842, 15. 9\natom percent natural\nabundance and\nnuclear spin 1 / 2.\nThe molecule is a glycosyl alditol\nderivative consisting of 2-\nacetamido-2-deoxy-D-\nglucopyranose, D-\ngalactopyranose and 2-\nacetamido-2-deoxy-D-galactitol\nresidues joined in sequence by\n(1->3) glycosidic bonds. It is a\nglycosyl alditol derivative, a\nmember of acetamides and a\npartially-defined glycan. It\nderives from a N-acetyl-D-\ngalactosaminitol.\nThe molecule is an\namino trisaccharide in\nwhich an N-acetyl-D-\ngalactosamine and an L-\nfucose link beta(1->3)\nand alpha(1->2)\nrespectively to beta-D-\ngalactose. It has a role\nas an epitope. It is an\namino trisaccharide and\na galactosamine\noligosaccharide.\nThe molecule is a\nbranched amino\ntrisaccharide consisting\nof D-galactose having an\nalpha-L-fucosyl residue\nat the 2-position and an\nN-acetyl-alpha-D-\ngalactosaminyl residue at\nthe 3-position. It is a\ngalactosamine\noligosaccharide and an\namino trisaccharide.\nthe molecule is the\nstable isotope of\nmolybdenum with\nrelative atomic mass\n94. 905842, 15. 9\natom percent natural\nabundance and\nnuclear spin 1 / 2.\nThe molecule is a\nmethylbutyric acid comprising\na butyric acid core carrying a\n2-methyl substituent.\nProduced from amino acid\nleucine during nutrient\nstarvation in bacteria. It has\na role as a bacterial\nmetabolite and a human\nmetabolite. It is a conjugate\nacid of a 2-methylbutyrate.\nThe molecule is a\nmethylbenzoic acid with a\nmethyl group in the meta-\nposition. It is an aromatic\ncarboxylic acid and a\nderivative of both toluene and\nbenzoic acid. It is a conjugate\nacid of a m-toluic acid.\nThe molecule is a\nmethylbenzoic acid\ncarrying a methyl\nsubstituent at position 3.\nIt has a role as a human\nxenobiotic metabolite. It\nis a conjugate acid of a\nm-toluate.\n1 \n2 \n3 \nFigure 4: Examples of molecule captions generated by different models, where SMILES strings are converted to molecule\ngraphs for better visualization. Based on the same input molecule graph, our MolReGPT (10-shot GPT-4-0314) can generate\naccurate and natural captions to describe the structure, properties, and even the functions of the molecule. In contrast,\nTransformer generates meaningless captions that are far from the ground truth. Captions generated by MolT5-large seem\nbetter but still have some typo errors.\nunique pattern, while molecule 2 has two benzene rings\nand several hydrophilic groups. By counting the number\nof benzene rings, we can easily find that MolT5 generates\n3 benzene rings in molecule 1, which is incorrect. Besides,\nthe functional groups generated by MolT5 in both molecule\n1 and molecule 2 also miss-match the requirements given\nin the captions. Remarkably, these impressive results are\nachieved without additional fine-tuning steps.\nFurthermore, the original weights of T5 are primarily\nfor natural language, which means it has to be fine-\ntuned separately to fit the two sub-tasks in this study.\nUnfortunately, MolT5 does not tackle this issue, as it\ncontinues to treat the two sub-tasks of the molecule-caption\ntranslation task separately. Switching between the two sub-\ntasks in MolT5 requires using a different model class and\nreloading the weights, making it technically inefficient. In\ncontrast, MolReGPT enables a single foundation LLM to\nsolve both the two sub-tasks simultaneously, providing\na comprehensive solution for LLMs to address molecule-\nrelated tasks.\n4.3 Ablation Study\nIn addition to the experiments above, we also perform\nablation studies to analyze the critical factors that influence\nthe performance of MolReGPT. Note that we select GPT-3.5-\nturbo as the backend model.\n4.3.1 Impact of Retrieval Strategies.\nRetrieval strategies play a key role in guiding LLMs to\nperform molecule-caption translation tasks for MolReGPT.\nMore similar examples are retrieved, and more valuable\ninformation could be contained for In-Context Few-Shot\nMolecule Learning. For Mol2Cap and Cap2Mol, we choose\nthree different retrieval strategies for comparison. The\ndetailed results are shown in Table 3 and Table 4. We\nshow that in both sub-tasks, compared to random selection,\nthe other retrieval strategies used in this paper can help\nimprove n-shot generation results. Thus, thoughtful selection\nof retrieval strategies plays a key role in MolReGPT.\nIn Mol2Cap task, we compare the performance of\nthree retrieval strategies: Random, BM25, and Morgan FTS\n(adopted in MolReGPT). The Random strategy involves\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 9\nThe molecule is a\npyrazolopyridazine that is\npyrazolo[1,5-b]pyridazine\nsubstituted by a 2-[3-(morpholin-\n4-yl)anilino]pyrimidin-4-yl group\nat position 3 and an ethoxy group\nat position 6. It is an\naminopyrimidine, a member of\nmorpholines, a secondary amino\ncompound, a tertiary amino\ncompound, a pyrazolopyridazine\nand an aromatic ether.\nThe molecule is a member of\nthe class of pyridines that is\n3-hydroxypyridine in which\nthe hydroxy hydrogen has\nbeen replaced by a sulfo\ngroup. It is an aryl sulfate and\na member of pyridines. It\nderives from a 3-pyridinol. It\nis a conjugate acid of a 3-\nhydroxypyridine sulfate(1-).\nTransformerMolT5-large Ours Ground TruthInput\n1 \n2 \n3 \nThe molecule is a long chain\nfatty primary alcohol that\nis octadecanol containing\nthree double bonds located\nat positions 9, 12 and 15. It\nhas a role as an\nantibacterial agent.\nFigure 5: Examples of molecules generated by different models, where SMILES strings are converted to molecule graphs for\nbetter visualization. Based on the same input caption, our MolReGPT (10-shot GPT-4-0314) can generate accurate molecule\ngraphs described by the caption. In contrast, Transformer generates quite different molecules compared to the ground truth.\nCompared to Transformer, molecules generated by MolT5-large are closer to the ground truth but still miss so many details.\n1 \n2 \nInput MolT5 Ours \nThe molecule contains\nfive benzene rings and\na couple of hydrophobic\ngroups. The molecule\ncan make hard\nmaterials. The main\nfunction of the molecule\nis to strengthen the\nwings of the areo planes\nThe molecule contains\ntwo benzene rings and a\nfew hydrophilic groups.\nThe main function of\nthe molecule is to cure\ncold.\nBenzene \nHydrophobic \n Group \nHydrophilic \n Group \nFigure 6: Illustrations of molecule graphs generated by MolT5 and our MolReGPT (GPT-3.5-turbo), given customized inputs.\nNotably, the key points in Example 1 highlight the five benzene rings and hydrophobic groups in the structure, which are\ncorrectly generated by our MolReGPT. In contrast, the results of MolT5 generate the incorrect number of benzene rings\nand contain a few hydrophilic groups. In example 2, both generations give the correct number of benzene rings, while\nMolReGPT generates more hydrophilic groups, which are closer to our input caption.\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 10\nMethod BLEU-2 ↑ BLEU-4 ↑ ROUGE-1 ↑ ROUGE-2 ↑ ROUGE-L ↑ METEOR ↑ Text2Mol ↑\nzero-shot 0.103 0.050 0.261 0.088 0.204 0.161 0.352\n1-shot (random) 0.236 0.131 0.335 0.135 0.257 0.253 0.372\n1-shot (BM25) 0.243 0.150 0.350 0.156 0.278 0.262 0.394\n1-shot (Morgan FTS) 0.506 0.416 0.547 0.372 0.473 0.499 0.529\n2-shot (random) 0.273 0.158 0.357 0.154 0.278 0.284 0.371\n2-shot (BM25) 0.287 0.188 0.380 0.185 0.307 0.297 0.397\n2-shot (Morgan FTS) 0.547 0.460 0.592 0.425 0.520 0.559 0.548\n5-shot (random) 0.297 0.178 0.376 0.173 0.300 0.305 0.366\n5-shot (BM25) 0.311 0.213 0.398 0.205 0.327 0.317 0.405\n5-shot (Morgan FTS) 0.562 0.478 0.609 0.446 0.540 0.583 0.559(6)\n10-shot (random) 0.295 0.181 0.389 0.185 0.310 0.329 0.369\n10-shot (BM25) 0.326 0.227 0.413 0.221 0.342 0.333 0.408\n10-shot (Morgan FTS) 0.565 0.482 0.623 0.450 0.543 0.585 0.559(8)\nTable 3: N-shot Molecule Captioning results on ChEBI-20 dataset with the backend model, GPT-3.5-turbo. The best scores\nare in bold, and the second-best scores are underlined.\nMethod BLEU↑ EM↑ Levenshtein↓ MACCS FTS↑ RDK FTS↑ Morgan FTS↑ FCD↓ Text2Mol↑ Validity↑\nzero-shot 0.489 0.019 52.13 0.705 0.462 0.367 2.05 0.479 0.802\n1-shot (random) 0.525 0.027 51.86 0.716 0.475 0.373 1.67 0.482 0.821\n1-shot (SentenceBert) 0.687 0.066 35.89 0.796 0.609 0.511 0.85 0.541 0.839\n1-shot (BM25) 0.706 0.074 33.38 0.799 0.620 0.526 0.84 0.540 0.842\n2-shot (random) 0.529 0.026 49.87 0.720 0.479 0.380 1.71 0.483 0.824\n2-shot (SentenceBert) 0.642 0.048 40.98 0.770 0.560 0.463 1.01 0.557 0.841\n2-shot (BM25) 0.748 0.101 28.89 0.827 0.668 0.578 0.67 0.519 0.860\n5-shot (random) 0.552 0.028 49.26 0.720 0.476 0.382 1.60 0.481 0.832\n5-shot (SentenceBert) 0.758 0.095 28.34 0.824 0.659 0.568 0.71 0.558 0.871\n5-shot (BM25) 0.771 0.121 26.78 0.836 0.686 0.599 0.60 0.564 0.882\n10-shot (random) 0.564 0.029 49.11 0.723 0.486 0.386 1.46 0.484 0.846\n10-shot (SentenceBert) 0.767 0.098 27.46 0.831 0.672 0.585 0.63 0.562 0.890\n10-shot (BM25) 0.790 0.139 24.91 0.847 0.708 0.624 0.57 0.571 0.887\nTable 4: N-shot Molecule Generation results on ChEBI-20 dataset with the backend model, GPT-3.5-turbo. The best scores\nare in bold, and the second-best scores are underlined.\nretrieving n random examples, while BM25 applies a\ncharacter-level BM25 algorithm to the molecule SMILES\nrepresentations. As shown in Table 3, among the three\nstrategies, Morgan FTS shows the best performance when n\nis fixed, outperforming BM25 by 37% in the Text2Mol metric.\nBesides, the ROUGE-L score achieved by Morgan FTS is\nalmost doubled compared to the Random or BM25 strategies.\nThe use of Morgan FTS with Dice similarity shows a better\nestimation of the structural similarity between molecules by\ncomparing unique structural features like functional groups.\nThese features are usually revealed in molecule captions\nwith detailed descriptions. In this case, retrieving similar\nmolecules by Morgan FTS could effectively guide the LLM\nto learn the associations between molecule structures and\ncaption descriptions, resulting in more accurate and desired\noutputs.\nIn Cap2Mol task, we also employ these retrieval strate-\ngies: Random, SentenceBert, and BM25 (adopted in Mol-\nReGPT). The Random strategy still retrieves n random\nexamples, while SentenceBert encodes captions as numerical\nvectors to compute their semantic similarity. As shown in\nTable 4, BM25 is the best one in the Cap2Mol task, despite\nthe fact that SentenceBert has outperformed BM25 in many\nclassical NLP text retrieval datasets. When n changes from\n1 to 10, BM25 always achieves better BLEU, Exact Match,\nLevenshtein, and fingerprint scores than SentenceBert. The\ninput molecule captions tend to use phrases with dashes\n(-) like ”2-methylphenyl” to connect the structure details of\nthe molecule. Understanding such phrases plays a crucial\nrole in generating correct molecule structures. In this case,\nretrieving similar texts while precisely matching these details\nsignificantly contributes to performance improvement. In\ncontrast, SentenceBert, as a neural method, encodes an entire\ncaption into a 1-D embedding vector, focusing more on\nsemantic similarity rather than specific details. Consequently,\nBM25 is better than SentenceBert in the Cap2Mol task.\n4.3.2 Impact of Example Number for In-Context Learning.\nIn this subsection, we study how the number of examples\ncontained in the system prompt through in-context learning\naffects the performance.\nIn the zero-shot scenario, where no extra examples are\nincluded in the prompt for guiding LLMs for learning the\nmolecule-caption translation task, we utilize two special\nspans, ‘[MOLECULE MASK]’ and ‘[CAPTION MASK]’, to\ninform the LLMs of the desired output format.\nAfter analyzing the zero-shot results of GPT-3.5-turbo\nin Tables 3 and 4, we can observe that SMILES strings are\nincluded in its pre-training corpus because it can generate\nbasically valid SMILES representations of molecules based\non zero-shot prompts, achieving a 0.802 validity score and\na 0.479 Text2Mol score in molecule generation. However,\nit is important to note that the zero-shot results exhibit a\nperformance level similar to a vanilla Transformer model.\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 11\nThis observation provides evidence that GPT-3.5-turbo is not\nspecifically trained on ChEBI-20, thereby alleviating concerns\nregarding potential information leakage.\nFor Few-shot Performance, Table 3 and Table 4 list the\ncomprehensive details of the experimental results.Normally,\nthe performance improves as the number of examples,\ndenoted as n, increases, as more examples provide additional\nknowledge for the task. However, due to the input length\nlimitation of LLMs, it is impossible to contain a large number\nof examples in the system prompt. Therefore, for few-shot\nscenarios, we choose four different values 1, 2, 5, and 10.\nTables 3 and 4 illustrate that performance generally im-\nproves as n increases through in-context learning. Significant\nperformance enhancements are observed as n changes from 0\nto 10. Taking Morgan FTS and BM25 as examples, in caption\ngeneration, we see remarkable increases from 0.050 to 0.482,\n0.204 to 0.543, and 0.352 to 0.560 in BLEU-4, ROUGE-L,\nand Text2Mol scores, respectively. Besides, BM25 improves\nmolecule generation from 0.489 to 0.790 in the BLEU score\nand 0.479 to 0.571 in the Text2Mol score.\nBesides, it is worth noticing that when n increases from 5\nto 10, the Text2Mol metrics almost keep the same, which can\nbe the problem of the maximum input length limitation of\nLLMs. To fit the input length limitation, we would remove\nthe longest examples to degrade the n-shot to (n-1)-shot\ngeneration for re-queries. As n increases, there is a higher\npossibility of exceeding the input length limitation. In this\ncase, unless the maximum input length of the LLM is\nexpanded, the performance will finally converge when n\ncontinues to grow.\n5 C ONCLUSION\nIn this work, we propose MolReGPT, a general retrieval-\nbased in-context learning paradigm that empowers molecule\ndiscovery with LLMs like ChatGPT via In-Context Few-Shot\nMolecule Learning. Our method is focused and evaluated on\nthe task of molecule-caption translation, including molecule\ncaptioning (Mol2Cap) and text-based molecule generation\n(Cap2Mol). MolReGPT leverages the molecular similarity\nprinciple to retrieve examples from a local database, guiding\nLLMs to generate predictions without being fine-tuned.\nSpecifically, BM25 caption retrieval is applied to obtain\nsimilar molecule captions, while Morgan Fingerprints and\nDice similarity are adopted to retrieve similar molecules.\nExperimental results show that our proposed MolReGPT\ncan empower ChatGPT to achieve 0.585 and 0.593 Text2Mol\nscores in Mol2Cap and Cap2Mol, respectively. Compared\nto MolT5-large, our MolReGPT equips GPT-4-0314 with the\nability to achieve comparable performance in Mol2Cap task\nand even outperform MolT5-large in Cap2Mol task without\nany fine-tuning steps. To conclude, MolReGPT provides a\nnovel and versatile paradigm to deploy LLMs in molecule\ndiscovery through in-context learning, which greatly reduces\nthe cost of domain transfer and explores the potential of\nLLMs in molecule discovery.\n6 B ROADER IMPLICATION & FUTURE DIRECTIONS\nOur work has demonstrated the effectiveness of the Mol-\nReGPT framework across various LLMs. Compared to the\nexisting methods, MolReGPT does not require additional\npre-training or fine-tuning, yet it enables powerful LLMs like\nGPT-4 to achieve comparable and even superior performance.\nThe integration of LLMs and biomolecular science represents\na paradigm shift in molecule discovery. As illustrated in\nFigure 6, fine-tuned methods tend to fail to meet the\nrequirements in customized inputs, while MolReGPT shows\na better generalization potential. These unique features make\nour method more convenient and practical for chemists to\nadopt and use in their work. We hope that MolReGPT could\nenable a wider range of scientific researchers to leverage the\npower of LLMs in their work, ultimately contributing to the\nadvancement of scientific research and discovery.\nFor future work, there are still several areas that\nrequire further exploration and improvement. Firstly, the\nperformance of LLMs is intricately related to the prediction\nquality of MolReGPT. Thus, with the advancement of more\npowerful LLMs, our methods could potentially yield even\nbetter results in the future. Secondly, we could develop\nbetter retrieval algorithms that could help refine the context\nexamples. For example, we could combine BM25 caption\nretrieval with chemical LLMs and apply Graph Neural\nNetworks for molecular similarity to improve the retrieval\nquality. Lastly, we anticipate that our work will not only\nmake LLMs more accessible for scientific researchers in the\nfield of chemistry, thereby benefiting drug discovery, but also\ninspire the AI community to consider the alignment between\nmolecular and text space.\nREFERENCES\n[1] J. Xu, Y. Li, J. Yang, S. Zhou, and W. Situ, “Plasma etching\neffect on the molecular structure of chitosan-based hydrogels\nand its biological properties,” International Journal of Biological\nMacromolecules, p. 123257, 2023.\n[2] Y. Weng, B. Ding, Y. Liu, C. Song, L.-Y. Chan, and C.-W. Chiang,\n“Late-stage photoredox c–h amidation of n-unprotected indole\nderivatives: Access to n-(indol-2-yl) amides,” Organic Letters, vol. 23,\nno. 7, pp. 2710–2714, 2021.\n[3] B. Ding, Y. Weng, Y. Liu, C. Song, L. Yin, J. Yuan, Y. Ren, A. Lei,\nand C.-W. Chiang, “Selective photoredox trifluoromethylation\nof tryptophan-containing peptides,” European Journal of Organic\nChemistry, vol. 2019, no. 46, pp. 7596–7605, 2019.\n[4] A. Higuchi, T.-C. Sung, T. Wang, Q.-D. Ling, S. S. Kumar, S.-T.\nHsu, and A. Umezawa, “Material design for next-generation mrna\nvaccines using lipid nanoparticles,” Polymer Reviews, vol. 63, no. 2,\npp. 394–436, 2023.\n[5] F. Urbina and S. Ekins, “The commoditization of ai for molecule\ndesign,” Artificial Intelligence in the Life Sciences , vol. 2, p. 100031,\n2022.\n[6] D. Weininger, “Smiles, a chemical language and information system.\n1. introduction to methodology and encoding rules,” Journal of\nchemical information and computer sciences, vol. 28, no. 1, pp. 31–36,\n1988.\n[7] J. Ar ´us-Pous, S. V . Johansson, O. Prykhodko, E. J. Bjerrum,\nC. Tyrchan, J.-L. Reymond, H. Chen, and O. Engkvist, “Randomized\nsmiles strings improve the quality of molecular generative models,”\nJournal of cheminformatics, vol. 11, no. 1, pp. 1–13, 2019.\n[8] S. Honda, S. Shi, and H. R. Ueda, “Smiles transformer: Pre-trained\nmolecular fingerprint for low data drug discovery,” arXiv preprint\narXiv:1911.04738, 2019.\n[9] C. Edwards, C. Zhai, and H. Ji, “Text2mol: Cross-modal molecule\nretrieval with natural language queries,” in Proceedings of the 2021\nConference on Empirical Methods in Natural Language Processing , 2021,\npp. 595–607.\n[10] C. Edwards, T. Lai, K. Ros, G. Honke, K. Cho, and H. Ji,\n“Translation between molecules and natural language,” in\nProceedings of the 2022 Conference on Empirical Methods in\nNatural Language Processing. Abu Dhabi, United Arab Emirates:\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 12\nAssociation for Computational Linguistics, Dec. 2022, pp. 375–413.\n[Online]. Available: https://aclanthology.org/2022.emnlp-main.26\n[11] B. Su, D. Du, Z. Yang, Y. Zhou, J. Li, A. Rao, H. Sun, Z. Lu,\nand J.-R. Wen, “A molecular multimodal foundation model\nassociating molecule graphs with natural language,” arXiv preprint\narXiv:2209.05481, 2022.\n[12] D. Zhu, J. Chen, X. Shen, X. Li, and M. Elhoseiny, “Minigpt-4:\nEnhancing vision-language understanding with advanced large\nlanguage models,” arXiv preprint arXiv:2304.10592, 2023.\n[13] K. Bao, J. Zhang, Y. Zhang, W. Wang, F. Feng, and X. He, “Tallrec:\nAn effective and efficient tuning framework to align large language\nmodel with recommendation,” arXiv preprint arXiv:2305.00447 ,\n2023.\n[14] O. Rubin, J. Herzig, and J. Berant, “Learning to retrieve prompts for\nin-context learning,” in Proceedings of the 2022 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, 2022, pp. 2655–2671.\n[15] S. Min, M. Lewis, L. Zettlemoyer, and H. Hajishirzi, “Metaicl:\nLearning to learn in context,” in Proceedings of the 2022 Conference\nof the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, 2022, pp. 2791–2809.\n[16] W. Hu, Y. Liu, X. Chen, W. Chai, H. Chen, H. Wang, and G. Wang,\n“Deep learning methods for small molecule drug discovery: A\nsurvey,” IEEE Transactions on Artificial Intelligence, 2023.\n[17] W. Fan, C. Liu, Y. Liu, J. Li, H. Li, H. Liu, J. Tang, and Q. Li,\n“Generative diffusion models on graphs: Methods and applications,”\narXiv preprint arXiv:2302.02591, 2023.\n[18] S.-P . Peng and Y. Zhao, “Convolutional neural networks for the\ndesign and analysis of non-fullerene acceptors,” Journal of Chemical\nInformation and Modeling, vol. 59, no. 12, pp. 4993–5001, 2019.\n[19] N. Q. K. Le, E. K. Y. Yapp, Y.-Y. Ou, and H.-Y. Yeh, “imotor-cnn:\nIdentifying molecular functions of cytoskeleton motor proteins\nusing 2d convolutional neural network via chou’s 5-step rule,”\nAnalytical biochemistry, vol. 575, pp. 17–26, 2019.\n[20] F. Grisoni, M. Moret, R. Lingwood, and G. Schneider, “Bidirectional\nmolecule generation with recurrent neural networks,” Journal of\nchemical information and modeling, vol. 60, no. 3, pp. 1175–1183, 2020.\n[21] S. Amabilino, P . Pog´any, S. D. Pickett, and D. V . Green, “Guidelines\nfor recurrent neural network transfer learning-based molecular\ngeneration of focused libraries,” Journal of Chemical Information and\nModeling, vol. 60, no. 12, pp. 5699–5713, 2020.\n[22] V . Bagal, R. Aggarwal, P . Vinod, and U. D. Priyakumar, “Molgpt:\nmolecular generation using a transformer-decoder model,” Journal\nof Chemical Information and Modeling, vol. 62, no. 9, pp. 2064–2076,\n2021.\n[23] J. Wang, C.-Y. Hsieh, M. Wang, X. Wang, Z. Wu, D. Jiang,\nB. Liao, X. Zhang, B. Yang, Q. He et al. , “Multi-constraint\nmolecular generation based on conditional transformer, knowledge\ndistillation and reinforcement learning,” Nature Machine Intelligence,\nvol. 3, no. 10, pp. 914–922, 2021.\n[24] Z. Zeng, Y. Yao, Z. Liu, and M. Sun, “A deep-learning\nsystem bridging molecule structure and biomedical text with\ncomprehension comparable to human professionals,” Nature\ncommunications, vol. 13, no. 1, p. 862, 2022.\n[25] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever et al. ,\n“Improving language understanding by generative pre-training,”\nOpenAI, 2018.\n[26] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever et al.,\n“Language models are unsupervised multitask learners,” OpenAI\nblog, vol. 1, no. 8, p. 9, 2019.\n[27] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P . Mishkin,\nC. Zhang, S. Agarwal, K. Slama, A. Ray et al., “Training language\nmodels to follow instructions with human feedback,” Advances\nin Neural Information Processing Systems, vol. 35, pp. 27 730–27 744,\n2022.\n[28] OpenAI, “Introducing chatgpt,” 2022, https://openai.com/blog/\nchatgpt.\n[29] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, A. Kulshreshtha,\nH.-T. Cheng, A. Jin, T. Bos, L. Baker, Y. Duet al., “Lamda: Language\nmodels for dialog applications,” arXiv preprint arXiv:2201.08239 ,\n2022.\n[30] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra,\nA. Roberts, P . Barham, H. W. Chung, C. Sutton, S. Gehrmann\net al., “Palm: Scaling language modeling with pathways,” arXiv\npreprint arXiv:2204.02311, 2022.\n[31] W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng,\nS. Zhuang, Y. Zhuang, J. E. Gonzalez et al. , “Vicuna: An open-\nsource chatbot impressing gpt-4 with 90%* chatgpt quality,” See\nhttps://vicuna. lmsys. org (accessed 14 April 2023) , 2023.\n[32] A. M. Bran, S. Cox, A. D. White, and P . Schwaller, “Chemcrow:\nAugmenting large-language models with chemistry tools,” arXiv\npreprint arXiv:2304.05376, 2023.\n[33] A. D. White, “The future of chemistry is language,” Nature Reviews\nChemistry, pp. 1–2, 2023.\n[34] S. Chithrananda, G. Grand, and B. Ramsundar, “Chemberta: Large-\nscale self-supervised pretraining for molecular property prediction,”\narXiv preprint arXiv:2010.09885, 2020.\n[35] S. Liu, W. Nie, C. Wang, J. Lu, Z. Qiao, L. Liu, J. Tang, C. Xiao, and\nA. Anandkumar, “Multi-modal molecule structure-text model for\ntext-based retrieval and editing,” arXiv preprint arXiv:2212.10789,\n2022.\n[36] N. Frey, R. Soklaski, S. Axelrod, S. Samsi, R. Gomez-Bombarelli,\nC. Coley, and V . Gadepally, “Neural scaling of deep chemical\nmodels,” chemrxiv, 2022.\n[37] Z. Wang, L. Liang, Z. Yin, and J. Lin, “Improving chemical similarity\nensemble approach in target prediction,” Journal of cheminformatics,\nvol. 8, pp. 1–10, 2016.\n[38] D. Butina, “Unsupervised data base clustering based on daylight’s\nfingerprint and tanimoto similarity: A fast and automated way to\ncluster small and large data sets,” Journal of Chemical Information\nand Computer Sciences, vol. 39, no. 4, pp. 747–750, 1999.\n[39] S. Robertson, H. Zaragoza et al. , “The probabilistic relevance\nframework: Bm25 and beyond,” Foundations and Trends ® in\nInformation Retrieval, vol. 3, no. 4, pp. 333–389, 2009.\n[40] L. R. Dice, “Measures of the amount of ecologic association between\nspecies,” Ecology, vol. 26, no. 3, pp. 297–302, 1945.\n[41] D. E. Coupry and P . Pog´any, “Application of deep metric learning\nto molecular graph similarity,” Journal of Cheminformatics, vol. 14,\nno. 1, pp. 1–12, 2022.\n[42] A. Aizawa, “An information-theoretic perspective of tf–idf\nmeasures,” Information Processing & Management , vol. 39, no. 1,\npp. 45–65, 2003.\n[43] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,\nT. Lacroix, B. Rozi`ere, N. Goyal, E. Hambro, F. Azhar et al., “Llama:\nOpen and efficient foundation language models,” arXiv preprint\narXiv:2302.13971, 2023.\n[44] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,”\nAdvances in neural information processing systems , vol. 30, 2017.\n[45] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena,\nY. Zhou, W. Li, and P . J. Liu, “Exploring the limits of transfer\nlearning with a unified text-to-text transformer,” The Journal of\nMachine Learning Research, vol. 21, no. 1, pp. 5485–5551, 2020.\nJiatong Li is currently a PhD student of the\nDepartment of Computing (COMP), The Hong\nKong Polytechnic University (funded by HKPFS).\nBefore joining the PolyU, he received my Master’s\ndegree of Information Technology (with Distinc-\ntion) from the University of Melbourne, under the\nsupervision of Dr. Lea Frermann. In 2021, he got\nhis bachelor’s degree in Information Security from\nShanghai Jiao Tong University. His interest lies\nin Natural Language Processing, Drug Discovery,\nand Recommender Systems. He has published\ninnovative works in top-tier conferences such as IJCAI and ACL. For\nmore information, please visit https://phenixace.github.io/.\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 13\nYunqing Liu is currently a PhD student of\nthe Department of Computing (COMP), Hong\nKong Polytechnic University (PolyU), under the\nsupervision of Dr. Wenqi Fan. Before joining\nthe PolyU, he received his Master’s degree in\nComputer Science from the University of Edin-\nburgh (M.Sc. in Computer Science), under the\nsupervision of Dr. Elizabeth Polgreen. In 2020, he\ngot his bachelor’s degrees from Wuhan University\n(B.Sc. in Chemistry and B.Eng. in Computer\nScience and Technology). His research interest\nincludes Drug Discovery, Graph Neural Networks, and Natural Language\nProcessing. He has published innovative works in top-tier conferences\nand journals such as IJCAI, EACL, EurJOC and Organic Letters. For\nmore information, please visit https://liuyunqing.github.io/.\nWenqi Fanis a research assistant professor of\nthe Department of Computing at The Hong Kong\nPolytechnic University (PolyU). He received his\nPh.D. degree from the City University of Hong\nKong (CityU) in 2020. From 2018 to 2020, he\nwas a visiting research scholar at Michigan State\nUniversity (MSU). His research interests are in\nthe broad areas of machine learning and data\nmining, with a particular focus on Recommender\nSystems, Graph Neural Networks, and Trust-\nworthy Recommendations. He has published\ninnovative papers in top-tier journals and conferences such as TKDE,\nTIST, KDD, WWW, ICDE, NeurIPS, SIGIR, IJCAI, AAAI, RecSys, WSDM,\netc. He serves as top-tier conference (senior) program committee\nmembers and session chairs (e.g., ICML, ICLR, NeurIPS, KDD, WWW,\nAAAI, IJCAI, WSDM, etc.), and journal reviewers (e.g., TKDE, TIST,\nTKDD, TOIS, TAI, etc.). More information about him can be found at\nhttps://wenqifan03.github.io.\nXiao-yong Wei is a visiting professor of the\nDepartment of Computing, The Hong Kong Poly-\ntechnic University. He has been a professor\nand the head of the Department of Computer\nScience, Sichuan University of China since 2010.\nHe received his Ph.D. in Computer Science\nfrom the City University of Hong Kong and\nhas worked as a postdoctoral fellow in the\nUniversity of California, Berkeley. His research\ninterests include Multimedia Computing, Health\nComputing, Machine Learning, and Large-Scale\nData Mining. He is a senior member of IEEE, and has served as\nan associate editor of Interdisciplinary Sciences: Computational Life\nSciences since 2020, the program chair of ICMR 2019, ICIMCS 2012,\nand the technical committee member of over 20 conferences such as\nICCV, CVPR, ACM MM, ICME, and ICIP .\nHui Liu received her PhD degree in Electrical\nEngineering from Southern Methodist University\nin 2015. Her research interests include trust-\nworthy AI, designing data mining algorithms for\nwireless communication of smart devices, and\napplying machine learning and data mining in\nwireless communications. She has more than\n7-year research experience in data science on\nmobile data.\nJiliang Tangis a University Foundation Profes-\nsor in the computer science and engineering\ndepartment at Michigan State University since\n2022. He was an associate professor (2021-\n2022) and an assistant professor (2016-2021)\nin the same department. Before that, he was a\nresearch scientist in Y ahoo Research and got\nhis PhD from Arizona State University in 2015\nunder Dr. Huan Liu. His research interests include\ngraph machine learning, trustworthy AI and their\napplications in education and biology. He was\nthe recipient of various awards including 2022 AI’s 10 to Watch, 2022\nIAPR J. K. AGGARWAL Award, 2022 SIAM/IBM Early Career Research\nAward, 2021 IEEE ICDM Tao Li Award, 2021 IEEE Big Data Security\nJunior Research Award, 2020 ACM SIGKDD Rising Star Award, 2020\nDistinguished Withrow Research Award, 2019 NSF Career Award, and 8\nbest paper awards (or runner-ups). His dissertation won the 2015 KDD\nBest Dissertation runner up and Dean’s Dissertation Award. He serves as\nconference organizers (e.g., KDD, SIGIR, WSDM and SDM) and journal\neditors (e.g., TKDD, TOIS and TKDE). He has published his research\nin highly ranked journals and top conference proceedings, which have\nreceived tens of thousands of citations with h-index 82 (Google Scholar)\nand extensive media coverage. More details about him can be found at\nhttps://www.cse.msu.edu/∼tangjili/.\nQing Lireceived the B.Eng. degree from Hunan\nUniversity, Changsha, China, and the M.Sc. and\nPh.D. degrees from the University of Southern\nCalifornia, Los Angeles, all in computer science.\nHe is currently a Chair Professor (Data Science)\nand the Head of the Department of Computing,\nthe Hong Kong Polytechnic University. He is\na Fellow of IEEE and IET, a member of ACM\nSIGMOD and IEEE Technical Committee on Data\nEngineering. His research interests include object\nmodeling, multimedia databases, social media,\nand recommender systems. He has been actively involved in the research\ncommunity by serving as an associate editor and reviewer for technical\njournals, and as an organizer/co-organizer of numerous international\nconferences. He is the chairperson of the Hong Kong Web Society, and\nalso served/is serving as an executive committee (EXCO) member of\nIEEE-Hong Kong Computer Chapter and ACM Hong Kong Chapter. In\naddition, he serves as a councilor of the Database Society of Chinese\nComputer Federation (CCF), a member of the Big Data Expert Committee\nof CCF , and is a Steering Committee member of DASFAA, ER, ICWL,\nUMEDIA, and WISE Society.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6046613454818726
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.5930061340332031
    },
    {
      "name": "Context (archaeology)",
      "score": 0.48577407002449036
    },
    {
      "name": "Translation (biology)",
      "score": 0.45738711953163147
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37317153811454773
    },
    {
      "name": "Data science",
      "score": 0.36871951818466187
    },
    {
      "name": "Natural language processing",
      "score": 0.3297792375087738
    },
    {
      "name": "Chemistry",
      "score": 0.2164323925971985
    },
    {
      "name": "Geography",
      "score": 0.15179312229156494
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Messenger RNA",
      "score": 0.0
    }
  ]
}