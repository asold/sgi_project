{
  "title": "Towards a Language Model for Temporal Commonsense Reasoning",
  "url": "https://openalex.org/W3216327107",
  "year": 2021,
  "authors": [
    {
      "id": null,
      "name": "Ochanomizu University, Japan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2128917267",
      "name": "Mayuko Kimura",
      "affiliations": [
        "Ochanomizu University"
      ]
    },
    {
      "id": "https://openalex.org/A4316237531",
      "name": "Lis Kanashiro Pereira",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Ochanomizu University, Japan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1982119413",
      "name": "Ichiro Kobayashi",
      "affiliations": [
        "Ochanomizu University"
      ]
    },
    {
      "id": null,
      "name": "Ochanomizu University, Japan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2963159690",
    "https://openalex.org/W4287813862",
    "https://openalex.org/W2970780738",
    "https://openalex.org/W3034238904",
    "https://openalex.org/W2963797084",
    "https://openalex.org/W2971236147",
    "https://openalex.org/W3113303810",
    "https://openalex.org/W4322614701",
    "https://openalex.org/W1967936132",
    "https://openalex.org/W3034602344",
    "https://openalex.org/W2157275230",
    "https://openalex.org/W3035507081",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2945290257"
  ],
  "abstract": "Temporal commonsense reasoning is a challenging task as it requires temporal knowledge usually not explicitly stated in text.In this work, we propose an ensemble model for temporal commonsense reasoning.Our model relies on pre-trained contextual representations from transformer-based language models (i.e., BERT), and on a variety of training methods for enhancing model generalization: 1) multistep fine-tuning using carefully selected auxiliary tasks and datasets, and 2) a specifically designed temporal task-adaptive pre-trainig task aimed to capture temporal commonsense knowledge.Our model greatly outperforms the standard fine-tuning approach and strong baselines on the MC-TACO dataset.",
  "full_text": null,
  "topic": "Commonsense reasoning",
  "concepts": [
    {
      "name": "Commonsense reasoning",
      "score": 0.8686190843582153
    },
    {
      "name": "Computer science",
      "score": 0.8142536878585815
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6491008996963501
    },
    {
      "name": "Language model",
      "score": 0.6382299661636353
    },
    {
      "name": "Task (project management)",
      "score": 0.6322147250175476
    },
    {
      "name": "Transformer",
      "score": 0.5963394641876221
    },
    {
      "name": "Generalization",
      "score": 0.5944716930389404
    },
    {
      "name": "Commonsense knowledge",
      "score": 0.5882547497749329
    },
    {
      "name": "Natural language processing",
      "score": 0.5056023597717285
    },
    {
      "name": "Question answering",
      "score": 0.44360655546188354
    },
    {
      "name": "Machine learning",
      "score": 0.35645148158073425
    },
    {
      "name": "Knowledge representation and reasoning",
      "score": 0.16956967115402222
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ]
}