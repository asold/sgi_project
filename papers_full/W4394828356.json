{
    "title": "GPT (Generative Pre-Trained Transformer)— A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions",
    "url": "https://openalex.org/W4394828356",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2958723540",
            "name": "Gokul Yenduri",
            "affiliations": [
                "SRM University",
                "VIT-AP University"
            ]
        },
        {
            "id": "https://openalex.org/A2139998127",
            "name": "M. Ramalingam",
            "affiliations": [
                "Vellore Institute of Technology University"
            ]
        },
        {
            "id": "https://openalex.org/A2983330575",
            "name": "G, Chemmalar Selvi",
            "affiliations": [
                "Vellore Institute of Technology University"
            ]
        },
        {
            "id": "https://openalex.org/A2341261936",
            "name": "Supriya Y",
            "affiliations": [
                "Vellore Institute of Technology University"
            ]
        },
        {
            "id": "https://openalex.org/A2135489550",
            "name": "Gautam Srivastava",
            "affiliations": [
                "Brandon University"
            ]
        },
        {
            "id": "https://openalex.org/A2745617533",
            "name": "Praveen Kumar Reddy Maddikunta",
            "affiliations": [
                "Vellore Institute of Technology University"
            ]
        },
        {
            "id": "https://openalex.org/A2225382158",
            "name": "G, Deepti Raj",
            "affiliations": [
                "Vellore Institute of Technology University"
            ]
        },
        {
            "id": "https://openalex.org/A2060844200",
            "name": "Rutvij H. Jhaveri",
            "affiliations": [
                "Pandit Deendayal Petroleum University"
            ]
        },
        {
            "id": "https://openalex.org/A2225264775",
            "name": "B. Prabadevi",
            "affiliations": [
                "Vellore Institute of Technology University"
            ]
        },
        {
            "id": "https://openalex.org/A2099866232",
            "name": "Weizheng Wang",
            "affiliations": [
                "City University of Hong Kong"
            ]
        },
        {
            "id": "https://openalex.org/A2239634948",
            "name": "Athanasios V Vasilakos",
            "affiliations": [
                "University of Agder"
            ]
        },
        {
            "id": "https://openalex.org/A2593576678",
            "name": "Thippa Reddy Gadekallu",
            "affiliations": [
                "Chitkara University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3198659451",
        "https://openalex.org/W2892009249",
        "https://openalex.org/W4320495408",
        "https://openalex.org/W4323655724",
        "https://openalex.org/W3011574394",
        "https://openalex.org/W6851275520",
        "https://openalex.org/W6851125442",
        "https://openalex.org/W3004304303",
        "https://openalex.org/W6851077998",
        "https://openalex.org/W4363678768",
        "https://openalex.org/W4313334409",
        "https://openalex.org/W2783378158",
        "https://openalex.org/W4321786597",
        "https://openalex.org/W4323343445",
        "https://openalex.org/W3213472637",
        "https://openalex.org/W6873894026",
        "https://openalex.org/W6850526593",
        "https://openalex.org/W4214504786",
        "https://openalex.org/W4321106177",
        "https://openalex.org/W4382361534",
        "https://openalex.org/W6850627172",
        "https://openalex.org/W3122241445",
        "https://openalex.org/W4313384047",
        "https://openalex.org/W6846868997",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W6851355582",
        "https://openalex.org/W2922709902",
        "https://openalex.org/W4313558932",
        "https://openalex.org/W3211525823",
        "https://openalex.org/W6848955424",
        "https://openalex.org/W4366808937",
        "https://openalex.org/W4320015904",
        "https://openalex.org/W6850182213",
        "https://openalex.org/W6849829545",
        "https://openalex.org/W4318716950",
        "https://openalex.org/W6850936240",
        "https://openalex.org/W4327519588",
        "https://openalex.org/W4327520012",
        "https://openalex.org/W4320496617",
        "https://openalex.org/W3201024510",
        "https://openalex.org/W6762439315",
        "https://openalex.org/W3207503791",
        "https://openalex.org/W4322217015",
        "https://openalex.org/W3203887518",
        "https://openalex.org/W4323355853",
        "https://openalex.org/W4321203765",
        "https://openalex.org/W4385175044",
        "https://openalex.org/W4366967540",
        "https://openalex.org/W6838259788",
        "https://openalex.org/W4291972732",
        "https://openalex.org/W4285217780",
        "https://openalex.org/W4310007426",
        "https://openalex.org/W6848541482",
        "https://openalex.org/W4226426358",
        "https://openalex.org/W4360584379",
        "https://openalex.org/W3130493776",
        "https://openalex.org/W2884274735",
        "https://openalex.org/W4313856022",
        "https://openalex.org/W2897214019",
        "https://openalex.org/W4245793348",
        "https://openalex.org/W4366549000",
        "https://openalex.org/W4323256756",
        "https://openalex.org/W4324290231",
        "https://openalex.org/W6850668563",
        "https://openalex.org/W6838410229",
        "https://openalex.org/W4322757547",
        "https://openalex.org/W6848711891",
        "https://openalex.org/W4361770419",
        "https://openalex.org/W6787796642",
        "https://openalex.org/W2790808809",
        "https://openalex.org/W4220992614",
        "https://openalex.org/W4292199287",
        "https://openalex.org/W4220967417",
        "https://openalex.org/W3174167596",
        "https://openalex.org/W2937307539",
        "https://openalex.org/W2213443318",
        "https://openalex.org/W2964677890",
        "https://openalex.org/W4220681836",
        "https://openalex.org/W2578240541",
        "https://openalex.org/W4365794756",
        "https://openalex.org/W6849088423",
        "https://openalex.org/W3171832821",
        "https://openalex.org/W4362506406",
        "https://openalex.org/W4309721255",
        "https://openalex.org/W4385456320",
        "https://openalex.org/W4372287512",
        "https://openalex.org/W4312688968",
        "https://openalex.org/W2937764832",
        "https://openalex.org/W2893693469",
        "https://openalex.org/W4362466759",
        "https://openalex.org/W7025092095",
        "https://openalex.org/W4367624800",
        "https://openalex.org/W3199704160",
        "https://openalex.org/W6849998897",
        "https://openalex.org/W4321366197",
        "https://openalex.org/W7053164774",
        "https://openalex.org/W4319831789",
        "https://openalex.org/W6800751262",
        "https://openalex.org/W3207559276",
        "https://openalex.org/W3118271039",
        "https://openalex.org/W4385988359",
        "https://openalex.org/W4361988710",
        "https://openalex.org/W2981854649",
        "https://openalex.org/W4281707272",
        "https://openalex.org/W4360620450",
        "https://openalex.org/W4387024651",
        "https://openalex.org/W3095319910",
        "https://openalex.org/W2993810765",
        "https://openalex.org/W6848100155",
        "https://openalex.org/W3143945924",
        "https://openalex.org/W3094127673",
        "https://openalex.org/W4385795484",
        "https://openalex.org/W4294017628",
        "https://openalex.org/W6848880756",
        "https://openalex.org/W3181414820",
        "https://openalex.org/W3082757774",
        "https://openalex.org/W3165489876",
        "https://openalex.org/W7051662300",
        "https://openalex.org/W3153281824",
        "https://openalex.org/W6850619096",
        "https://openalex.org/W4382498938",
        "https://openalex.org/W4284676027",
        "https://openalex.org/W4323256981",
        "https://openalex.org/W4366596588",
        "https://openalex.org/W3125358881",
        "https://openalex.org/W4323848232",
        "https://openalex.org/W4366498198",
        "https://openalex.org/W4365512576",
        "https://openalex.org/W6779016856",
        "https://openalex.org/W4287855173",
        "https://openalex.org/W1598517837",
        "https://openalex.org/W4318263917",
        "https://openalex.org/W4379410101",
        "https://openalex.org/W4311430511",
        "https://openalex.org/W2053973149",
        "https://openalex.org/W4238707867",
        "https://openalex.org/W1967537161",
        "https://openalex.org/W2050556626",
        "https://openalex.org/W4353016766",
        "https://openalex.org/W4324304837",
        "https://openalex.org/W6790277608",
        "https://openalex.org/W3088082662",
        "https://openalex.org/W4312841684",
        "https://openalex.org/W3210757389",
        "https://openalex.org/W6789879579",
        "https://openalex.org/W4306317012",
        "https://openalex.org/W6880654322",
        "https://openalex.org/W3005249048",
        "https://openalex.org/W3175052898",
        "https://openalex.org/W6784723893",
        "https://openalex.org/W4318975084",
        "https://openalex.org/W6773248361",
        "https://openalex.org/W6776218486",
        "https://openalex.org/W6772715161",
        "https://openalex.org/W3139390182",
        "https://openalex.org/W4360857188",
        "https://openalex.org/W6999384112",
        "https://openalex.org/W6799931069",
        "https://openalex.org/W4285798540",
        "https://openalex.org/W4285741590",
        "https://openalex.org/W4225353277",
        "https://openalex.org/W4200057797",
        "https://openalex.org/W6799064937",
        "https://openalex.org/W4322719791",
        "https://openalex.org/W4312463400",
        "https://openalex.org/W4388189161",
        "https://openalex.org/W4307475428",
        "https://openalex.org/W3158360872",
        "https://openalex.org/W6761100157",
        "https://openalex.org/W3191453585",
        "https://openalex.org/W2944839767",
        "https://openalex.org/W6792279967",
        "https://openalex.org/W4389612580",
        "https://openalex.org/W2473418344",
        "https://openalex.org/W4233585739",
        "https://openalex.org/W4321472057",
        "https://openalex.org/W3026555355",
        "https://openalex.org/W4287331814",
        "https://openalex.org/W3000027512",
        "https://openalex.org/W4318765555",
        "https://openalex.org/W4312892277",
        "https://openalex.org/W4313598433",
        "https://openalex.org/W4330337479",
        "https://openalex.org/W4321153003",
        "https://openalex.org/W4315704987",
        "https://openalex.org/W4386165948",
        "https://openalex.org/W4287802874",
        "https://openalex.org/W4324299536",
        "https://openalex.org/W4320063358",
        "https://openalex.org/W4361024861",
        "https://openalex.org/W3033254023",
        "https://openalex.org/W3088409176",
        "https://openalex.org/W2611369375",
        "https://openalex.org/W4360836968",
        "https://openalex.org/W4389437528",
        "https://openalex.org/W3118258778",
        "https://openalex.org/W4313348432",
        "https://openalex.org/W4324027515",
        "https://openalex.org/W3195577433",
        "https://openalex.org/W4330336443",
        "https://openalex.org/W4311408938",
        "https://openalex.org/W4280504808",
        "https://openalex.org/W3195235061",
        "https://openalex.org/W4288363925",
        "https://openalex.org/W3126041111",
        "https://openalex.org/W4353007316",
        "https://openalex.org/W4360891289",
        "https://openalex.org/W4353115070",
        "https://openalex.org/W4243640523",
        "https://openalex.org/W4403863303",
        "https://openalex.org/W4287900772"
    ],
    "abstract": "The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.",
    "full_text": "Digital Object Identifier\nGPT (Generative Pre-trained\nTransformer) – A Comprehensive Review\non Enabling Technologies, Potential\nApplications, Emerging Challenges, and\nFuture Directions\nGokul Yenduri1, Ramalingam M2, Chemmalar Selvi G2, Supriya Y2, Gautam Srivastava3,\nPraveen Kumar Reddy Maddikunta2, Deepti Raj G2, Rutvij H Jhaveri4, Prabadevi B2,\nWeizheng Wang5, Athanasios V. Vasilakos6 and Thippa Reddy Gadekallu7,8\n1School of Computer Science and Engineering, VIT-AP University, Amaravati, Andhra Pradesh-522237, India.(e-mail:yenduri.gokul@gmail.com )\n2School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Tamil Nadu, India (e-mail: ramalingam.m@vit.ac.in,\nchemmalarselvi.g@vit.ac.in, praveenkumarreddy@vit.ac.in, prabadevi.b@vit.ac.in, supriya.2020@vitstudent.ac.in, deeptiraj.g2020@vitstudent.ac.in)\n3Dept. of Math and Computer Science, Brandon University, Canada (e-mail: srivastavag@brandonu.ca)\n4Department of Computer Science and Engineering, School of Technology, Pandit Deendayal Energy University, India, (Email: rutvij.jhaveri@sot.pdpu.ac.in)\n5Department of Computer Science, City University of Hong Kong, Hong Kong SAR, China, (E-mail: weizheng.wang@ieee.org\n6Center for AI Research (CAIR),University of Agder(UiA), Grimstad, Norway, (Email: thanos.vasilakos@uia.no)\n7Center of Research Impact and Outcome, Chitkara University, Punjab, India\n8Division of Research and Development, Lovely Professional University, Phagwara 144401, India. (Email: thippareddy@ieee.org)\nCorresponding author: Chemmalar Selvi G (e-mail: chemmalarselvi.g@vit.ac.in).\nABSTRACT The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the\ndomain of natural language processing, which is propelling us toward the development of machines that\ncan understand and communicate using language in a manner that closely resembles that of humans. GPT\nis based on the transformer architecture, a deep neural network designed for natural language processing\ntasks. Due to their impressive performance on natural language processing tasks and ability to effectively\nconverse, GPT have gained significant popularity among researchers and industrial communities, making\nthem one of the most widely used and effective models in natural language processing and related fields,\nwhich motivated to conduct this review. This review provides a detailed overview of the GPT, including\nits architecture, working process, training procedures, enabling technologies, and its impact on various\napplications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore,\nwe discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive\nunderstanding of GPT, its enabling technologies, their impact on various applications, emerging challenges,\nand potential solutions.\nINDEX TERMS Generative Pre-trained Transformer, Natural language processing, Artificial Intelligence\nI. INTRODUCTION\nLanguage is the cornerstone of human communication and\nplays a vital role in shaping our interactions with the world.\nWith the advent of NLP, it has revolutionized the way we\ninteract with machines. NLP has become a game-changer\nin the world of communication, enabling humans to interact\nwith machines in a more natural way. The evolution of\nNLP has been fueled by the exponential growth of textual\ndata in the internet. Over the years, NLP has witnessed a\nsignificant transformation from simple rule-based systems to\ncomplex deep learning-based models. Despite the advances,\nnatural language understanding and generation have long\nbeen a challenging problem in the field of NLP, largely due\nto the complex nature of human language. However, recent\nadvancements have paved the way for the new approaches\nto tackle these challenges. One such breakthrough in NLP,\nis the development of the GPT [1]. GPT became famous\nafter the launch of ChatGPT by OpenAI, a research company\n[2] that focuses on developing AI technologies. GPT is a\ndeep learning model that is pre-trained on large corpora of\nVOLUME 4, 2016 1\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nTABLE 1: List of key acronyms only if it is repeated\nAcronyms Description\nAI Artificial Intelligence\nAR Augmented Reality\nBERT Bidirectional Encoder Representations from Transformers\nBGN Boneh–Goh–Nissim\nCNN ConvolutionalNeural Network\nDAP Data Access Point\nDLT Decentralized Ledger Technology\nDL Deep Learning\nDRL Deep Reinforcement Learning\nDR Demand response\nEC Edge Computing\nEU End User\nEAPs Energy Access Points\n5G Fifth-Generation\n4G Fourth-Generation\nGPT Generative Pre-trained Transformer\nGPU Graphics Processing Unit\nHPC High Performance Computing\nHCI Human Computer Interaction\nIoT Internet of Things\nML Machine Learning\nNLP Natural Language Processing\nNPC Non Playable Character\nPLM Pre-trained Language Models\nPTM Pre-Trained Models\nRNN Recurrent Neural Network\n6G Sixth-Generation\nTL Transfer Learning\nVU Virtual Reality\ntext data and can be fine-tuned for specific tasks like lan-\nguage generation, sentiment analysis, language modelling,\nmachine translation, and text classification. The transformer\narchitecture used in GPT is a significant advancement over\nprevious approaches to NLP, such as RNN and CNN. It uses\na self-attention mechanism to allow the model to consider\nthe context of the entire sentence when generating the next\nword, which improved the model’s ability to understand and\ngenerate language. The decoder is responsible for generating\nthe output text based on the input representation [3].\nGPT can perform a wide range of tasks in NLP. One of\nits key strengths is in natural language understanding (NLU),\nwhere it can analyze and comprehend the meaning of text,\nincluding identifying entities and relationships in sentences.\nIt’s also proficient in natural language generation (NLG),\nwhich means it can create text output, such as writing creative\ncontent or answering questions in a comprehensive and infor-\nmative way. Alternatively, GPT is also code generator, where\nit can write programming code in various languages, such as\nPython or JavaScript. GPT can also be utilized for question\nanswering, which means it can provide summaries of factual\ntopics or create stories based on the input text. Additionally,\nGPT can summarize a piece of text, such as providing a\nbrief overview of a news article or research paper, and it can\nbe used for translation, which makes it possible to translate\ntext from one language to another. Overall, GPT’s ability to\nperform a wide range of NLP tasks with high accuracy and\nprecision, makes it an invaluable tool for various industries,\nincluding finance, healthcare, marketing, and more. As NLP\ntechnology continues to advance, we can expect GPT and\nother language models to become even more sophisticated\nand powerful, enabling us to communicate with machines\nmore naturally and effectively.\nA. MOTIVATION\nGPT has become a transformative technology in the field of\nNLP, enabling the rapid development and growth of a wide\nrange of industries and applications. Despite its wide adop-\ntion and numerous potential applications, there is still much\nto be explored and understood about GPT’s capabilities.\nAlthough there are studies on GPT in the literature related\nto academia and libraries [4], education [5], GPT models [6],\nbanking and corporate communication [7], advancements in\nchatGPT and its version [8], and on generative AI’s [9], no\nexisting reviews are dedicated to providing a comprehensive\nsurvey on GPT. Therefore, there is a need for a compre-\nhensive review that focuses on GPT’s architecture, enabling\ntechnologies, potential applications, emerging challenges,\ninteresting projects and future directions. These limitations\nmotivated us to conduct this review. Hence, this review will\nnot only help researchers and practitioners in this field to\ngain a better understanding of GPT but also provide valuable\ninsights into its potential applications and major limitations\nwhen conducting the research.\nB. RELATED SURVEYS AND CONTRIBUTIONS\nThe GPT model is a type of DL model that uses self-\nsupervised learning to pre-train massive amounts of text\ndata, enabling it to generate high-quality language output.\nThe recent advancements in GPT model research can be\nattributed to the continual improvement of its architecture,\nincreased availability of computing power, and the develop-\nment of novel techniques to fine-tune the model for specific\ntasks. These advancements have led to the creation of larger\nand more powerful GPT models, enabling them to perform\na wider range of NLP tasks with unprecedented accuracy\nand fluency. These GPT models have demonstrated great\npotential in transforming various industries like healthcare\n[10], customer service [11], financial industry [12] and so\non. These applications are enabled by the generation of\nhigh-quality and diverse data like large-scale corpora of text\ndata with different fast-growing enabling technologies [13],\n[14]. There are numerous survey papers published to provide\na comprehensive overview of the latest developments in\nGPT models, insights into the different architectures, training\nmethods, evaluation metrics, and highlight the challenges and\nfuture directions of this field. This literature survey aims to\nreview and analyze the key findings and contributions of\nthe most recent survey papers published on GPT models, to\nprovide a comprehensive and up-to-date understanding of the\nstate-of-the-art in this exciting and rapidly evolving field.\nLund et al. [4] presents the potential effects of AI and GPT\nmodels, specifically ChatGPT, on academia and libraries.\nThey discussed the capabilities of ChatGPT in generating\nhuman-like responses and its potential applications. They ex-\namine how AI-powered chatbots and virtual assistants based\non GPT models can enhance student learning experiences,\nassist with research tasks, and improve library services. They\n2 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nalso address concerns regarding data privacy, biases, and the\nneed for ethical guidelines. Overall, this survey paper high-\nlighted the transformative potential of AI and GPT models\nwhile emphasizing the importance of responsible deployment\nand human oversight.\nKasneci et al. [5] have reviewed the potential opportunities\nand challenges of using large language models, specifically\nChatGPT, for educational purposes. They highlighted the\nbenefits and limitations of using such models by discussing\ntheir implications for teaching and learning. In addition,\na defined strategy and pedagogical approach with a heavy\nfocus on critical thinking and fact-checking are required\nwhile using such large language models in educational in-\nstitution. Thus, they concluded the paper by highlighting the\nkey technical challenges like copyright issues, biased content\ncreation, user dependency, privacy and security, and high-\ncost language models when such language models are used\nin the educational sector.\nQiu et al. [6] presented an exhaustive survey of various\ntypes of GPT models by detailing their working architecture.\nThey discussed the evolution of pre-training methods for\nNLP, from language modelling to TL and pre-training on\nlarge-scale corpora. It also reviews the different types of\nGPT models, including word embeddings, contextual em-\nbeddings, and transformer-based models, and discusses their\napplications in various NLP tasks such as text classification,\nNamed Entity Recognition, and machine translation. They\nhighlighted the benefits of GPT’s models for the NLP do-\nmain, such as its ability to improve model performance with\nlimited annotated data, reduce the need for task-specific fea-\nture engineering, and enable TL across multiple tasks. They\ndiscussed the major challenges and limitations of PTMs, such\nas the risk of bias and the lack of interpretability.\nGeorge et al. [7] studied the potential impact of GPT-\n4, the next iteration of GPT models, on communication\nwithin corporate environments. They discussed how GPT-\n4 can revolutionize business communication by enabling\nmore efficient and effective interactions. They explore var-\nious applications of GPT-4 in corporate settings, such as\nautomating customer support through AI chatbots that can\nprovide personalized responses and resolve queries in real-\ntime. They also addressed potential challenges and consid-\nerations associated with implementing GPT-4 in corporate\nsettings. These include concerns about data security, privacy,\nand the need for human oversight to ensure accurate and\nethical communication. Thus, they concluded by emphasiz-\ning the transformative potential of GPT-4 in revolutionizing\nbusiness communication to fully harness the benefits of GPT-\n4 while addressing any potential risks or limitations.\nZhang et al. [8] presents an extensive survey of generative\nAI and evaluates the capabilities of the ChatGPT models, par-\nticularly from GPT-4 to GPT-5. They provided an overview\nof generative AI, highlighting its significance in generating\nrealistic and creative outputs across various domains and\nevaluate their advancements over previous iterations. They\nanalyze the architectural improvements, model size, training\ntechniques, and dataset considerations employed in GPT-4\nand GPT-5. In addition to it, they presented a comprehensive\ncomparison of ChatGPT with other state-of-the-art genera-\ntive AI models, such as OpenAI’s DALL-E and CLIP. Finally,\nthey concluded with valuable insights into the capabilities\nand limitations of these models and highlights the broader\nlandscape of generative AI.\nZaib et al. [9] provides a survey on the latest advance-\nments in GPTS and PTMs for conversational AI applica-\ntions. They focused on PLMs and their approaches while\nbuilding dialogue-based systems. They also highlighted the\npotential use of transformer-based models such as BERT\nand GPT, which have demonstrated good performance in\nunderstanding NLP generation, and dialogue management.\nThus, they concluded with the significant challenges in the\nfield of developing conversational AI systems using PLMs\nand GPTs.\nThus, the comparison of existing surveys on GPT models\nhighlighting the growing importance of these models in key\nareas of NLP and other related fields are discussed here.\nHence, this is the first-of-its-kind survey that presents the\nextensive information, by comparing existing surveys with\nour survey and summarized in Table 2.\nC. SYSTEMATIC LITERATURE SURVEY\nIn this review of GPT, we conducted a thorough literature\nreview using various reputable sources. Our search was pri-\nmarily focused on peer-reviewed journals, and high-quality\narticles from reputed national and international conferences,\nseminars, books, symposiums, and journals. To ensure the\ncredibility of our sources, we referred to well-known archives\nsuch as Google Scholar and arXiv, and publications from top\ndatabases like IEEE, Springer, Elsevier, Taylor & Francis,\nand Wiley. To identify relevant GPT references and publica-\ntions, we used keywords such as NLPGPT, GPT architecture,\nDL for GPT, Pretraining GPT, Fine-tuning AI GPT and\nGPT vertical applications. We then screened all the retrieved\narticles based on their titles, excluding any papers with poor-\nquality material. Next, we reviewed the abstracts of the re-\nmaining articles to determine their contributions. In the final\nstep of our literature review, we extracted the necessary data\nfor our analysis. By following these phases, we ensured that\nour study was based on high-quality and credible sources.\nD. PAPER ORGANIZATION\nThe structure of this paper’s organization is illustrated in Fig.\n1. Section 2 presents the preliminaries of GPT models such\nas the definition of GPT, its evolution and architecture, how it\nworks and presents the comparison of various GPT models.\nSection 3 discusses the key enabling technologies for GPT\nmodels. The impact of GPT models in various applications\nare presented in Section 4. In Section 5, we highlighted some\nof the exciting GPT projects that are currently developed.\nSection 6 includes open issues, other technical challenges\nand future research directions in the field of GPT. Finally,\nwe conclude the paper in Section 7, by summarizing the\nVOLUME 4, 2016 3\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nSECTION-1:INTRODUCTION\nMOTIVATION RELATED SURVEYS AND\nCONTRIBUTIONS\nSYSTEMATIC LITERATURE\nSURVEY\nPAPER\nORGANIZATION\nSECTION-2:PRELIMINARIES\nGPT Definitions\nEvolution of GPT GPT Architecture How does GPT work? Comparisons of GPT versions\nDefinition-1 Definition-2 Definition-3 Definition-4\nSECTION-3:ENABLING TECHNOLOGIES\nARTIFICIAL INTELLIGENCE\nCLOUD COMPUTING\nEDGE COMPUTING\n5G & BEYOND NETWORKS\nHUMAN COMPUTER INTERACTION\nBIG DATA\nSECTION-4:IMPACT OF GPT ON VARIOUS APPLICATIONS\nEducation Healthcare Industry Agriculture\nTravel and Transport\nE-Commerce\nEntertainmentLifestyleGaming\nMarketing Finance\nINTRODUCTIONIMPACT OF GPT ON APPLICATION\nCHALLENGES SUMMARY\nSiriGPT AI Dungeon Copy.ai Bond.AI Viable\nUber's Plato Research Dialogue SystemAI Channels Fireflies.AI DeepScribe\nPolyglot AI Meena\nSECTION-6:OPEN ISSUES AND OTHER TECHNICAL CHALLENGES\nSECTION-5:PROJECTS\nDomain Specific GPTs Computational requirementsExplainability and interpretabilityData Bias\nMultimodal supportRobustness Multilingual supportModel size Limited understanding\nEthical ConcernsSecurity and privacy concerns\nSECTION-7:CONCLUSION\nFIGURE 1: Organization Chart of the survey.\nkey findings and contributions of this study. The list of key\nacronyms are listed in Table 1.\nII. PRELIMINARIES\nIn this section, the evolution of GPT models, the architecture\nof GPT, working process of GPT models are discussed and\nfinally, different versions of GPT models are compared.\nA. GENERATIVE PRE-TRAINED TRANSFORMER\nThe GPT model produces enormous quantities of perti-\nnent and complicated machine-generated text from a small\namount of text as input. GPT models can be identified as a\nlanguage model that mimics human text using a DL tech-\nniques and it acts as an autoregressive model in which the\npresent value is based on the previous value [15].\n1) Definition 1\nGPTs are language models pre-trained on vast quantities of\ntextual data and can perform a wide range of language-related\ntasks [16].\n2) Definition 2\nA GPT is a language model relying on DL that can generate\nhuman-like texts based on a given text-based input. [17].\n3) Definition 3\nGPT is a language model developed by OpenAI to help give\nsystems intelligence and is used in such projects as ChatGPT\n4 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nTABLE 2: Comparison of this survey with the existing surveys\nRef. Applications Enabling Technologies Remarks\nEducation\nIndustry\nAgriculture\nHealthcare\nTransport\nE-Commerce\nEntertainment\nLifestyle\nGaming\nMarketing\nFinance\nBig Data\nAI\nCloud Computing\nEdge Computing\n5G and Beyond\nHCI\n[4] ✓ X X X X X X X X X X X ✓ ✓ ✓ X X They conducted a survey discussing capabilities of ChatGPT on\nacademia and libraries. Although, Key challenges of Chatgpt were high-\nlighted, practical implementation challenges and research directions\nwere missing.\n[5] ✓ X X X X X X X X X X X ✓ X X X X Reviewed the potential opportunities and challenges of using large\nlanguage models, specifically ChatGPT, for educational purposes. Thus,\nevolution of GPT and their preliminaries were not discussed in this\nsurvey paper.\n[6] X X X X X X X X X X X X ✓ X X X X They presented an exhaustive survey of various types of GPT models\nby detailing their working architecture with benefits and limitations of\nGPTs. However,\n[7] X X X ✓ X X X X X X X X ✓ X X X X Studied the potential impact of GPT4 in business communication and\nexplore various applications of GPT-4 in corporate settings by high-\nlighting any potential risks or limitations. But, how GPT architecture\ncan be used in corporate is not found with key enabling technologies.\n[8] X ✓ X X ✓ ✓ ✓ X X ✓ ✓ X ✓ X X X X Analyzed the architectural improvements, model size, training tech-\nniques, and dataset considerations employed in GPT-4 and GPT-5.\nHowever, preliminary details are unedr explored.\n[9] X X X X X X X X X X X X X X X X X Recent trends in language models, applications of dialogue manage-\nment, question answering NLP tasks were discussed along with chal-\nlenges and future scope of GPT. Although it covered most of the tech-\nnical aspects, the integration challenges to overcomeare not presented.\nOur Survey Paper ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Presents the evolution of GPT models, GPT architecture and its de-\ntailed working, key enabling technologies, significant advancements of\nGPT models and their potential benefits in real-life applications, GPT\nprojects, lessons learnt, open challenges and future research directions.\n[17].\nB. EVOLUTION OF GPT\nGPT models have evolved through multiple changes and\nbreakthroughs in NLP technology. These are some significant\nturning points in the growth of the GPT model: Before GPT,\nNLP models have been trained on large amounts of annotated\ndata that is related to a specific task. This had a significant\ndrawback because it was difficult to access the quantity\nof labelled data required to train the model precisely. The\nNLP models were unable to complete tasks outside of their\ntraining set since they were restricted to a particluar set of\ndata. To get around these restrictions, OpenAI offered a Gen-\nerative Language Model called GPT-1 that was created using\nunlabeled data and then given to users to fine-tune to carry\nout subsequent tasks like sentiment analysis, categorization,\nand question-answering [18]. This indicates that the model\nattempts to produce an appropriate response based on input\nand that the data used to train the model is not labelled [19].\nFig. 2 shows the timeline of the evolution of several pre-\ntrained models from Eliza, which was created in 1960, to the\nmore current 2022-ChatGPT.\nGPT-1 was the first ever model that could read the text and\nrespond to queries [20]. OpenAI released GPT-1 in 2018.\nGPT-1 was a major move forward in AI development because\nit enabled computers to comprehend textual material in a\nmore natural manner than before. This generative language\nmodel was able to learn a wide variety of connections and\ngain immense knowledge on a varied corpus of contiguous\ntext and lengthy stretches [21]. This happened after being\ntrained on a huge BooksCorpus dataset. In terms of design,\nGPT-1 employs a 12-layer decoder architecture transformer\nwith a self-attention system for training. GPT-1’s capacity to\nexecute zero-shot performance on different tasks was one of\nits major success as a result of its pre-training. This ability\ndemonstrated that generative language modelling can be used\nto generalize the model when combined with a successful\npretraining idea. With TL as its foundation, GPT models\nevolved into a potent tool for performing NLP tasks with\nminimal fine-tuning [22]. It paved the way for other models\nto progress even more in generative pre-training using larger\ndatasets and parameters. [18].\nTo create a better language model later in 2019, OpenAI\ncreated a GPT-2 using a bigger dataset and more parameters.\nThe model design and execution of GPT-2 are some of the\nkey advancements [23]. With 1.5 billion parameters, it has\n10 times the size of GPT-1 (117 million parameters), and it\nhas 10 times as many parameters and data [21]. By using\nonly the raw text as input and utilizing little to no training ex-\namples, it is effective in terms of resolving various language\ntasks related to translation, summarization, etc. Evaluation of\nGPT-2 on various downstream task datasets revealed that it\nexcelled by substantially increasing accuracy in recognizing\nlong-distance relationships and predicting sentences [24].\nThe most recent iteration of the GPT model is GPT-3. It is a\nsizable language prediction and production model created by\nOpenAI that can produce lengthy passages of the source text.\nGPT-3 eventually emerged as OpenAI’s ground-breaking AI\nlanguage software. Simply put, it is a piece of software that\ncan create lines on its own that are so distinctive they almost\nsound like they were written by a human [25]. The GPT-\n3 program is presently accessible with limited access via a\ncloud-based API, and access is required to investigate the\nutility. Since its debut, it has produced several interesting\napps. Its capacity, which is about 175 billion parameters big\nand 100 times larger than GPT-2, is a key advantage. It is\ntaught using a corpus of 500 billion words called \"Common\nCrawl\" that was gathered from a sizable content archive\nand the internet [26]. Its other noteworthy and unexpected\ncapability is its ability to carry out basic mathematical op-\nerations, write bits of code, and carry out clever tasks. As a\nresult, NLP models can help businesses by responding more\nquickly to requests and accurately keeping best practices\nwhile minimizing human mistakes [27]. Due to its intricacy\nVOLUME 4, 2016 5\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nELIZA-1960\nPattern matching &\nreplacement\nHelps human chat by\nentertaining\nchatbot to provide original\nreplies on its own\nALICE-1995\nSmarterChild-2001\nSiri -2010\nGoogle Now-2012 Alexa-2014\nAnalyze human language\n& synthesize\nBot provides the\nconversations in a\nfun manner\nintelligent\npersonal assistant\nHelps to answer the questions,\nperforms actions,  makes\nrecommendations\nIntelligent personal\nassistant\nPARRY-1970\nChatbot to provide\npsychological concepts\nRacter-1980 Jabberwacky-1990\nCHatGPT-2022\nAssist users in generating\nhuman-like text based on\ngiven input\nFIGURE 2: GPT Road Map.\nand size, many academics and writers have referred to it as\nthe ultimate black-box AI method. Due to the high cost and\ninconvenience of performing inference, as well as the billion-\nparameter size that makes it resource-intensive, it is difficult\nto put into practice in jobs [24].\nGPT-4 was named as the successor of GPT-3. In the mean-\ntime, several AI models built on GPT-3.5, an updated version\nof GPT-3, have been surreptitiously released by OpenAI [28].\nGPT-3.5 was trained on a mixture of text and code. From\nthe vast amounts of data collected from the web, which\nincludes tens and thousand of Wikipedia entries, social media\nposts, and news items, GPT 3.5 learned the relations between\nwords, sentences, and various components. It was utilized by\nOpenAI to develop several systems that have been tailored\nto complete particular jobs [26]. It collected vast amounts of\ndata from the web, including tens of thousands of Wikipedia\nentries, posts on social media, and news items, and used\nthat information to learn the relationships between sentences,\nwords, and word components [29].\nThe latest version of the GPT model by OpenAI is GPT-4\nwhich is a multimodal big language model. It was launched\non March 14, 2023, and is now accessible to the general\npublic through ChatGPT Plus in a constrained capacity. A\nwaitlist is required to gain access to the business API [10].\nUsing both public data and \"data licensed from third-party\nproviders,\" GPT-4 was pre-trained to anticipate the next coin\nas a transformer. It was then adjusted with reinforcement\nlearning based on input from humans and AI for human\nalignment and policy conformance. In comparison to GPT-\n3, which had context windows of only 4096 and 2049 tokens,\nrespectively, the group created two variants of GPT-4 with\ncontext windows of 8192 and 32768 tokens.\nC. GPT MODEL ’S ARCHITECTURE\nGPT models are based on neural networks that are used for\nNLP tasks, such as language modelling, text classification,\nand text generation.\nThe GPT model’s architecture is based on the transformer\nmodel [30]. The Transformer model uses self-attention mech-\nanisms to process input sequences of variable length, making\nit well-suited for NLP tasks. GPT simplifies the architecture\nby substituting encoder-decoder blocks with decoder blocks.\nGPT model takes the transformer model and pre-trains it on\nlarge amounts of text data using unsupervised learning tech-\nniques. The pre-training process involves predicting the next\nword in a sequence given the previous words, a task known\nas language modelling. This pre-training process enables the\nmodel to learn representations of natural language that can be\nfine-tuned for specific downstream tasks [31]. The following\nare the components of the GPT architecture.\n• Input Embedding layer: The embedding layer maps the\ninput tokens (e.g., words or subwords) to continuous\nvector representations, which can be processed by the\ntransformer blocks [32].\n• Positional encoding: Since the transformer blocks do\nnot have any notion of order or position, positional\nencoding is added to the input embeddings to provide\ninformation about the relative position of tokens. Mask-\ning: In some cases, masking may be necessary to mask\ncertain input tokens (e.g., in language modelling tasks,\nthe model should only use tokens that come before\nthe target token). Transformer blocks: GPT models are\nbased on the transformer architecture. It is designed for\nNLP tasks and has been widely used in applications\nsuch as machine translation, text classification, and text\n6 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\ngeneration. Transformers allow the model to focus on\ndifferent areas of the input while processing [33].\n• Linear and Softmax Functions: In the GPT architecture,\nthe softmax function is commonly used for classifica-\ntion tasks. The softmax function is applied to the output\nof the final layer of the model. It generates a probability\ndistribution over a set of output classes. The output of\nthe final layer is specifically converted into a set of logits\nbefore being normalized with the softmax function.\nThe normalized values obtained from the model can\nbe interpreted as the likelihood or probability that a\nparticular input belongs to each of the output classes.\nThe query, key, and value vectors for each token in the\ninput sequence are frequently calculated using linear\nfunctions in the attention mechanism. The output of the\nmulti-head attention layer is transformed using them in\nthe feedforward layers as well. The output layer also\nemploys linear functions to forecast the following token\nin the sequence [34].\n• Pre-training: Pre-training is a key component of the\nGPT architecture. In pre-training, the model is trained\non a large amount of data in an unsupervised manner\neven before fine-tuning the model for specific tasks like\nclassification and text generation.\n• Fine-tuning: Fine-tuning is the process of adapting a\npre-trained neural network model, such as GPT, to a\nnew task or dataset by further training the model on that\ntask or dataset. Fine-tuning in GPT involves adjusting\nthe parameters of the pre-trained model to optimize\nperformance on a specific downstream task, such as text\nclassification or text generation [35].\n• Language modeling: Language modelling is a key task\nin the GPT architecture. In the case of GPT, the lan-\nguage modelling task is performed during the pre-\ntraining phase of the model. In pre-training, the model is\ntrained based on a large amount of data using a language\nmodel objective. It is the task of predicting the next word\nin sequence based on the previous words. It allows the\nmodel to learn relationships between the words and their\nmeaning in the training data [36].\n• Unsupervised learning: Unsupervised learning is an\nML algorithm which enables the model to learn form\nunlabelled data without any human intervention. GPT\nmodels use unsupervised learning in the pre-training\nphase to understand the relationships between the words\nand their context in the training data [37].\nD. HOW DO GPT MODELS WORK?\nGPT models work by using a transformer which is a neural\nnetwork architecture that processes the input sequences of\nnatural language text [38]. The GPT model uses unsupervised\nlearning techniques to pre-train this transformer architecture\non a significant amount of text input [39]. The model gains\nthe ability to anticipate the subsequent word in a sequence\nbased on the preceding words during pre-training. Language\nAdd & Norm\nMulti-Head\nAttention \nSoftmax\nLinear \nAdd & Norm\nFeed\nForward \nAdd & Norm\nAdd & Norm\nMulti-Head\nAttention \nMasked Multi-\nHead\nAttention \nInput\nEmbedding \n+\nOutput\nEmbedding \n+\nInputs Outputs\nPositional\nEncoding\nPositional\nEncoding\nOutput\nProbabilities \nAdd & Norm\nFeed\nForward \nFIGURE 3: Transformer Architecture.\nmodelling is the process that enables a model to discover\nthe statistical connections between words and their context\nin training data. Fig. 5 shows the various stages of GPT\noperation. The first step entails supervised fine-tuning, the\nsecond step involves producing optimal responses to input,\nand the third step involves proximal policy optimization and\nreinforcement learning.\nThe model can be fine-tuned for particular tasks, like\ntext classification or text production, after pre-training. The\nmodel is trained on a smaller dataset that is unique to the\nwork at hand during fine-tuning, and the model’s parameters\nare changed to maximize performance on that task [8]. Fig. 3\nshows the general transformer architecture of GPT.\nWhen used for text creation, GPT models create text by\nanticipating the following word in a series based on the\npreviously created words. Depending on how it has been\nmodified, the model can produce text that is comparable to\nthe input text or that adheres to a certain theme or style. Fig. 4\nprojects the GPT model’s transformer architecture and input\ntransformations for fine-tuning different tasks.\nE. COMPARISONS OF GPT VERSIONS\nThere are several versions of GPT model, each having their\nown features and capabilities. Table 3 presents a comparison\nof various versions of the GPT model. The table presents\nthe following details like year of release of the GPT model,\nparameters, tokens generated, input type, features of each\nmodel, drawbacks of each model, and the size of each model.\nGPT is a generative model known as Generative AI (GAI)\nthat focuses on creating or generating new content, such\nVOLUME 4, 2016 7\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nTABLE 3: Comparison of different versions of the GPT model\nModel Tokens Size Parameters Dataset Year Features Input Type Drawbacks\nGPT-1 - 12-layer decoder 117M parameters Books corpus 2018 Used mostly for language mod-\nelling tasks and it is transformer\nbased\nA sequence of tokens and\nwords\nLimited Capacity, Limited Data, Cannot\nperform complex tasks, Limited applica-\ntions\nGPT-2 - 10 times the size of\nGPT-1\n1.5B parameters Downstream task\ndatasets\n2019 Text generation capabilities are\nimproved and a chance for mis-\nuse\nA sequence of tokens and\nwords\nLimited Control, Limited Data Diversity,\nExpensive computational requirements,\nRisk of improper information\nGPT-3 4096 and 2049 tokens 100 times larger than\nGPT-2\n175B parameters Common Crawl 2020 Good NLP capabilities, lan-\nguage translation, summariza-\ntion and generation of text\nA sequence of tokens and\nwords and images and tables\nLimited Control, Limited Data Diversity,\nLack of explanation, Ethical concerns\nGPT-3.5 maximum token limit\nof 4096 tokens\n96 layers similar or larger num-\nber of parameters like\nGPT-3\n- 2022 Improves user experience by de-\nlivering more precise and con-\ntextually relevant information\nThe input type typically con-\nsists of text data\nLimited resources to train,Data Bias,Lack\nof Explainability,Limited Contextual Un-\nderstanding,High Inference Latency\nGPT-4 8192 and 32768 tokens- 100T parameters - 2023 Creative and technical writing\ntasks\nA sequence of tokens and\nwords and images and tables\n-\nLayer Norm\nFeed\nForward \nText & Position\nEmbedded \n+\nLayer Norm\nMasked Multi\nSelf Attention \n+\nText\nPrediction\nTask\nClassifier Start Text Extract Transformer LinearClassification\nStart Premise Delim Transformer LinearEntailment HypothesisExtract\nStart Text 1 Delim Transformer \nLinearSimilarity \nText 2 Extract\nStart Text 2 Delim Transformer Text 1 Extract\nStart Context Delim Answer 1Extract\nStart Context Delim Answer 2Extract\nTransformer Linear\nTransformer LinearMultiple\nChoice\nStart Context Delim Answer NExtract Transformer Linear\nFIGURE 4: Transformer Architecture and Input Transformations for Fine-Tuning on Different Tasks.\nSupervised fine tuning (Step1) Reward Model (Step 2)\nProximal Policy Optimization (PPO) Reinforcement Learning  (Step 3)\nA pretrained GPT model is used,\nfine-tuned with labelers by creating\na supervised dataset. \n1\n1.1\nThe labelers then wrote an\nappropriate response to the\ninput prompt’s 1.2\nGPT model will be fine-tuned using new supervised dataset1.3\nAfter the model is trained in step 1, In this step it\ngenerates optimal responses to input \nSupervised fine tuning (SFT) model is used, inputs\nare fed to the finetuned model, several responses\nwere generated 2.1\n2\nLabeler provides a reward for each of\nthese outcomes, ranks the outcomes\nfrom best to worst 2.2 2.3\nThis data is used to\ntrain a reward model\nA new prompt is sampled from the\ntrained dataset\n3.1\n3\nThe PPO model is initialized from\nthe supervised policy\n3.2\nThe policy generates the output\n3.3\nThe reward model calculates a\nreward for the output\n3.4\nIn this step unseen input sequences are passed to the clone SFT model, pass the responses\nto the reward model for understanding, how high quality was this response for that input \nThe reward is used to update the\npolicy using PPO\n3.5\nFIGURE 5: How does GPT Work.\nHUMAN\nINSTRUCTION GPT TEXT RESULTS\nData\nInput Output\nUNIMODAL (CHATGPT)\nHUMAN\nINSTRUCTION GPT VISUAL\nRESULTSInput Output\nCROSS MODAL(STABLE DIFFUSION 2.1)\n INSTRUCTION 1\n INSTRUCTION 2\n INSTRUCTION 3\nPre-\ntraining\nPre-\ntraining\nPre-\ntraining\nTEXT RESULTS\nVISUAL\nRESULTS\nAUDIO RESULTS\nHuman\nInstructions\nMULTI-MODAL Results\nData\nData\nGPT\nInput\nOutput\nFIGURE 6: A comparison between unimodal, cross-modal, and multimodal modal GPTs.\nas images, text, music, or other forms of data. Unimodal,\nmultimodal, and cross-modal generative AI are distinct ap-\nproaches within generative AI models that involve handling\nand generating data from either a single modality or multiple\n8 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nmodalities. Unimodal generative AI focuses on generating\ndata from a single modality such as images, text, audio, or\nvideo. Multimodal generative AI involves generating data\nthat integrates information from multiple modalities at the\nsame time, aiming to create outputs from different modal-\nities. For instance, if a multimodal generative AI model\nis trained on a dataset containing both images and corre-\nsponding textual descriptions, it can generate novel image-\ntext pairs that maintain coherence and alignment between\nthe visual and textual elements. Cross-modal generative AI\nextends its capabilities by combining multiple modalities and\ninstead, focuses on generating data across different modal-\nities. It encompasses the task of generating data in one\nmodality based on inputs from a different modality. In other\nwords, it allows the generation of data in a specific modality\nusing information from a separate modality as a reference or\ninput. In general, GPT model adopts an unimodal approach,\ndesigned to generate textual outputs based on the patterns and\nstructures it has learned from the training data. Fig. 6 shows\nthe comparison between unimodal, multimodal and cross-\nmodal Generative AIs. Thus, this section describes about the\nevolution, and architecture of GPT models by comparing the\ndifferent versions of GPT models and its types.\nIII. ENABLING TECHNOLOGIES\nGPT is a convergence of several technologies. It is enabled by\nthe latest technologies like Big data, AI, Cloud Computing,\nEC, 5G and beyond networks, and HCI. In this section, we\nprovide an overview of enabling technologies related to GPT.\nThe major technologies that constitute the GPT models are\ndepicted in Fig. 7.\nA. BIG DATA\nBig data refers to the vast amounts of structured and un-\nstructured data generated by businesses, individuals, and\nmachines. The proliferation of new technologies, such as the\nIoT, has led to an explosion of data production from sources\nlike social media, sensors, and transaction-based systems\n[40].\nThe emergence of big data has revolutionized the way\norganizations approach data analysis and decision-making.\nThe training provided by this massive amount of data has\nyielded valuable insights for the use of advanced models like\nGPT in the field of NLP [41]. The GPT models utilize DL and\nbig data for natural language generation, with GPT-4 being\nthe most advanced model to date [42]. The training data for\nGPT models typically include millions or even trillions of\ndata from a diverse range of sources, such as books, articles,\nwebsites, and social media platforms. This large and diverse\ntraining data helps GPT models capture the variations in\nlanguage usage, making them more accurate and effective at\nNLP tasks. As a result, GPT models may be used for a variety\nof tasks, including question-answering, text summarization,\nand language translation [43]. Moreover, since GPT models\ncan learn from a variety of data sources, they can be tuned\nfor certain tasks and domains, making them very adaptive\nand versatile. GPT model has the potential to be utilized\nfor a variety of activities, including the creation of images\nand videos in addition to its excellent language processing\ncapabilities [44].\nWhile big data presents numerous benefits to GPT, by\nenabling the models to get trained with large amounts of data,\nit also presents several challenges [45]. GPT is trained on\na variety of data, large amounts of data, and also sensitive\ndata. Thus, ensuring data accuracy, privacy concerns, and\nethical use of data are some of the challenges that must be\nconsidered. However, with the continuous growth of avail-\nable data, GPT models will become even more advanced and\ncapable of performing increasingly complex tasks [46]. The\nfuture of big data as an enabling technology for GPT models\nis promising, with the potential to revolutionize the field\nof NLP. As technology continues to advance, organizations\nmust prioritize ethical considerations and data accuracy to\nfully harness the benefits of big data and GPT models.\nB. ARTIFICIAL INTELLIGENCE\nAI refers to the simulation of intelligent behaviour in ma-\nchines that are programmed to learn from their experience\nto reason, understand natural language, and perceive their\nenvironment [47]. AI gives machines the ability to sense their\nsurroundings, deal with what they see, handle issues, and take\naction to reach a particular objective. The importance and\ncapability of AI is growing all the time.\nAI enables GPT models to allow machines to comprehend\nand react to human language. There are several ways in which\nAI can continue to help improve GPT and make it more\npowerful and effective in its language generation capabilities\n[48].\nThe following are the several ways through which AI can\nmake GPT models more powerful:\n1) Fine tuning\n2) Dialogue generation\n3) Natural language understanding\nGPT’s model performance on particular tasks can be en-\nhanced by utilizing AI approaches. For instance, it can be\ntrained on a large corpus of text from a particular field\nsuch as legal documents or medical literature to better grasp\nand produce language in that field [4]. Considering dialogue\ngeneration, AI techniques such as reinforcement learning and\nsequence-to-sequence models can be used to enable GPT\ngenerate more natural and engaging dialogue in conversa-\ntional contexts. Similarly, AI techniques such as semantic\nparsing and named entity recognition can be used to help\nGPT better understand the meaning of language and the\nrelationships between words and phrases. This can enable it\ngenerate more accurate and coherent language [14].\nThe development and enhancement of GPT model language\nproduction capabilities depend heavily on AI, and GPT’s ca-\nVOLUME 4, 2016 9\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\npabilities will continue to be growing by continuous research\nand development in AI.\nAs GPT models become more advanced, there are growing\nconcerns about the potential for them in reinforcing biases\nand propagate harmful or offensive content [49]. Some of\nthese concerns also include bias which can lead to unintended\ndiscrimination and unfairness, lack of understanding of the\ncontext that can lead to misunderstandings or incorrect re-\nsponses, poor data quality can lead to inaccurate or biased\nmodels, ethical concerns like privacy and autonomy [50]. AI\nmodels like GPT require significant amounts of computa-\ntional power to train and run, which can have a significant\nenvironmental impact due to their high energy consumption\n[51].\nThough AI has a great deal of promise, it’s critical to be\naware of the underlying issues and make efforts to fix them\nto ensure that it is utilized responsibly and morally for GPT.\nC. CLOUD COMPUTING\nCloud computing refers to the on-demand availability of\ncomputer resources, such as storage, processing power, and\napplications, delivered over the internet [52]. The GPT\nmodel’s successes are possible not only because of algorith-\nmic evolution but also increased computational capabilities\ni.e. exponential growth in hardware (computational power,\nstorage capacity), cloud computing, and related operational\nsoftware [53]. The applications for cloud and EC working\ntogether such as natural language generation, image comple-\ntion, or virtual simulations from wearable sensors see that the\nwork is made more compute-intensive [54].\nGPT models need a lot of computational power to analyze\na lot of data, and cloud computing offers the scalability\nrequired to cope with demand spikes. Without worrying\nabout the constraints of on-premises hardware, GPT models\ncan rapidly and easily scale up or down as needed with cloud\ncomputing [55]. Cloud-based platforms like Amazon Web\nServices (AWS) or Google Cloud Platform (GCP) provide\naccess to distributed computing resources that can be used\nto train GPT. Since cloud computing provides web-based\nsolutions and thereby does not require the purchase and\nmaintenance of costly hardware, it can be a cost-effective\nchoice for a GPT model. By utilizing cloud computing, the\nGPT model can only pay for the computing resources it uses\n[56]. The other added advantage of cloud computing in GPT\nis, it gives GPT models the freedom to access computing\nresources whenever it wants, from any location in the world.\nThis makes GPT models more accessible to users by enabling\nsmooth operation across a variety of gadgets and platforms\n[57]. Cloud computing providers offer high security and\ncompliance standards, which can protect the GPT model\nand its data from online dangers. Cloud service providers\nalso possess the knowledge and tools necessary to effectively\naddress security problems and stop data leaks. Cloud-based\nstorage services, such as Amazon S3 or Google Cloud\nStorage, provide scalable and reliable storage for GPT’s data.\nDespite the advantages of cloud computing where it can\nhelp GPT models to operate more efficiently, effectively, and\nsecurely, there are also a few technological aspects where\nit creates a drawback for GPT [58]. To function properly,\nthe GPT model needs a sizable amount of computing power\nand data storage. These resources can be accessible online\nwith cloud computing. As a result, continued operation of\nthe GPT model requires a robust and dependable internet\nconnection, and any breakdown in connectivity may result\nin delays or even data loss. There are some security concerns\nwhen storing sensitive data, such as personal information or\ntrade secrets, in the cloud which can be risky if proper secu-\nrity measures are not in place [53]. While cloud computing\ncan be more cost-effective than building and maintaining an\nin-house computing infrastructure, it can still be expensive\nfor long-term use. It also suffers issues like performance\nvariability, limited availability etc.,\nD. EDGE COMPUTING\nThe rapid growth of IoT, a large amount of data from several\nIoT devices, and also cloud services have necessitated the\nemergence of a concept called EC. EC is an open AI and\ndistributed design with decentralized computational power.\nIn EC, there is a lesser need for clients and servers to\ncommunicate over long distances, which lowers latency and\nbandwidth utilization.\nInstead of depending on centralized data centers, EC entails\nbringing computing capacity and data storage closer to the\nconsumer [59].\nIn GPT, where there is a need for real-time data analy-\nsis, EC plays a major role in faster processing and better\nefficiency in producing good results [60]. GPT models are\ntypically large and complex, requiring significant processing\npower to run. By deploying GPT models on the edge de-\nvices, closer to the source of data, latency can be reduced\nin replying to users who seek information through the GPT\nmodels by eliminating the need to move data back and forth\nfrom end devices to the cloud. Since EC maintains data near\nthe periphery and away from centralized servers, it can offer\nimproved security and more privacy protections in the case of\nthe requests made by users through GPT [61]. GPT models\nutilize a lot of data for learning and thereby the cost of\ndata transfer also increases with data volume. EC can aid\nin controlling data transfer expenses. EC can also help in\nlowering the amount of bandwidth by pre-processing the data\neven before transferring it to the cloud. Particularly when\nanalyzing photos or videos, GPT models can produce a lot\nof data [62]. EC accelerators, such as graphics processing\nunits (GPUs) and field-programmable gate arrays (FPGAs),\ncan be used to speed up GPT model inference and training.\nThese accelerators can be integrated into edge devices or\nedge servers, providing more efficient processing of GPT\nmodels.\nEC and GPT models make a great combination. Comparative\nto cloud data centres, edge devices may have constrained\n10 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nKey\nenabling\ntechnologies\nBig Data\nArtificial\nIntelligence\nCloudComputing\nEdge\nComputing\n5G &\nBeyond\nHCI\nMassive data for training\nImproves model accuracy\nfor training\nFine tuningFaster data transmission\nImproved connectivity\nLower latency\nImproved input quality\nEnhanced user experience\nEnhances the usability of \nGPT models\nReduced latency\nCost effective\nSecurity and\ncompliance\nLow bandwidth usage\nProvides scalability for GPT\nmodels \nCost effective option\nSecurity and compliance \nFlexibility\nGood computational\npower\nModel Optimization\nHelps in deployment of\nvarious application\nFIGURE 7: Enabling technologies of GPT models.\ncomputation and storage capabilities [63]. This might limit\nthe scope of GPT models that can be installed on edge\ndevices in terms of size and complexity. Since GPT models\nhandle large and varied data, EC can also increase security\nrisks and data privacy concerns. Implementing EC in existing\ninfrastructure can be difficult and require significant invest-\nment in hardware, software, and networking components.\nThis can be a barrier for many organizations which are using\nthe GPT model and EC [64].\nE. 5G AND BEYOND NETWORKS\n5G networks represent the latest generation of cellular net-\nworks that promise faster data speeds, lower latency, and the\nability to connect a vast number of devices simultaneously\n[65]. 5G and beyond networks enable faster data transmission\nspeeds than previous generations of cellular networks, which\ncan help in training and deploying larger and more complex\nlanguage models. This can result in faster training times and\nbetter performance. 5G and beyond networks can provide\nlower latency than previous generations of cellular networks,\nwhich can reduce the time required for communication\nbetween GPT and other devices, such as servers or other lan-\nguage models [66]. This can improve the real-time response\nof the GPT model for applications that require quick and\naccurate language processing. 5G and beyond networks offer\nimproved connectivity options, such as increased capacity\nand more reliable connections, which can help in scaling up\nthe deployment of the GPT model for large-scale language\nprocessing tasks. With the deployment of 5G and beyond\nnetworks, EC is becoming more prevalent. This means that\na GPT model can potentially be deployed closer to the end-\nuser, reducing the latency and improving the response time\nfor applications that require real-time language processing\n[67]. Ultra-Reliable Low-Latency Communication (URLLC)\nis a key feature of 5G networks. In the context of GPT\nlanguage models, URLLC can enable real-time and reliable\ncommunication between multiple devices, such as edge\ndevices, cloud servers, and end-users [68].\nThough 5G and beyond technology offers potential ad-\nvantages to GPT models, it is also important to note that\nthe actual impacts of this technology may change depending\non how it’s implemented and used. 5G enables the access\nto uncontrolled access to the Internet,it may attract cyberse-\ncurity risks and privacy concerns [69]. Also, as GPT uses a\nlarge amount of data for analysis it could also cause privacy\nconcerns. 5G and beyond networks in GPT models need high\ninfrastructural requirements which is a costly process.\nF. HUMAN COMPUTER INTERACTION\nHCI, which is multi-faceted, concentrates on the design of\ncomputer technology and, in particular, on how people and\ncomputers communicate with each other [70].\nHCI has a greater influence over GPT models. As a\nlanguage model, GPT is designed to interact with humans\nby generating natural language responses to input text. HCI\nresearch can help designers create more effective input\nmechanisms for the GPT model, such as natural language\ninterfaces, that allow users to communicate more easily and\naccurately with the model [71]. HCI also helps in enhancing\nthe GPT model’s user experience by creating interfaces that\nare more intuitive and user-friendly. This makes it easy for\nthe users to interact with GPT models and understand their\nVOLUME 4, 2016 11\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nresponses [72]. HCI also estimates the performance of GPT\nmodels by evaluating their responses with real-time users\nand identifies the areas where the model needs improvement,\nthereby improving its reliability and accuracy. HCI enhances\nthe usability of GPT models by reducing the time and effort\nrequired for the users to interact with [73].\nWhile HCI can be incredibly helpful in improving the\ndesign and usability of GPT models, there are also some\npotential drawbacks to consider. If the research is not con-\nducted with a diverse group of users, HCI can introduce\nbiases into the design of the GPT model. HCI techniques\ncan be expensive and time-consuming. As GPT models be-\ncome more complex, it may become more difficult to design\ninterfaces and input mechanisms that are both effective and\nuser-friendly [74]. HCI may not always be able to provide\nthe necessary insights or feedback to drive improvements\nin GPT models. There are also ethical concerns around the\nuse of GPT models, including issues related to privacy, bias,\nand the potential misuse of the technology [75]. As GPT\nmodels become more complex, it may become more difficult\nto design interfaces and input mechanisms that are both\neffective and user-friendly.\nIV. IMPACT OF GPT MODELS ON VARIOUS\nAPPLICATIONS\nGPTs have made significant progress, and its impact is be-\ning felt across various industries like education, healthcare,\nindustry, agriculture, travel and transport, e-commerce, en-\ntertainment, lifestyle, gaming, marketing, and finance. This\nsection provides valuable insights on the impact of the GPT\nmodels in the aforementioned applications as depicted in Fig.\n8.\nA. EDUCATION\n1) Introduction\nEducation has been around for centuries, with traditional ed-\nucation being the most common form. Traditional education\ninvolves a teacher imparting knowledge to a group of stu-\ndents in a physical classroom. While successful, traditional\neducation can be restrictive and inflexible, limiting students’\nability to learn at their own pace and in their preferred style.\nIt can also be limited by geography, as students need to be\nphysically present in a classroom to learn. Technology has\nemerged as a solution to some of these issues, allowing for\npersonalized learning experiences and more engaging, acces-\nsible resources. Online learning platforms, digital textbooks,\nand multimedia tools offer students access to a vast array of\nresources from anywhere in the world. Technology can also\nfacilitate collaboration and communication among students\nand teachers, leading to a more dynamic and interactive\nlearning experience. Distance learning, hybrid learning mod-\nels, and online classes are examples of how technology can\nhelp break down the barriers of traditional education, making\nlearning more flexible, efficient, and effective. By integrating\ntechnology into traditional education, we can create a more\npersonalized and effective learning experience, benefiting\nstudents worldwide.\n2) Impact of GPT in Education\nThe field of education is constantly evolving, with advance-\nments in technology playing a significant role in shaping the\nway we learn and teach. One such technology that has the\npotential to transform the education industry is GPT. As a\nlarge language model trained on a vast amount of data, GPT\ncan generate human-like text that is coherent and informative,\nmaking it a valuable tool in developing educational content\nsuch as textbooks, study guides, and course materials. Fur-\nthermore, GPT can be used to analyze and summarize com-\nplex text, which can help educators and students save time\nand increase comprehension. With its ability to support NLP\napplications and create intelligent tutoring systems, GPT has\nthe potential to revolutionize the way we learn and teach. In\nthis context, following section will explore the different ways\nin which GPT can contribute to the education industry and\ntransform the future of learning.\n• Intelligent Tutoring: Intelligent tutoring is a teaching ap-\nproach that uses AI and ML to provide personalized and\nadaptive instruction. It analyzes student performance\ndata, understands their strengths and weaknesses, and\ngenerates customized learning paths. It provides im-\nmediate feedback, personalized guidance, and remedial\nsupport. It is effective in improving learning outcomes,\nincreasing student engagement, and reducing learning\ntime. With advanced natural language processing capa-\nbilities, GPT can enhance the personalized and adaptive\ninstruction provided by intelligent tutoring systems. It\ncan analyze natural language input from students, en-\nabling intelligent tutoring systems to better understand\nand respond to their queries, needs, and preferences. It\ncan also generate personalized feedback and assessment\nbased on the individual learning progress of each stu-\ndent, helping them to identify and address their knowl-\nedge gaps and improve their performance. GPT can also\nanalyze student performance data and generate adap-\ntive learning paths that provide customized instruction\nand remediation, ensuring that each student learns at\ntheir own pace and achieves their learning objectives.\nAdditionally, it can create interactive dialogue systems\nthat simulate natural conversations between students\nand virtual tutors, making learning more engaging, in-\nteractive, and personalized [76]. The authors in [75]\nhave identified that GPT-4 model outperforms general-\npurpose GPT-3.5 model as well as GPTs (Med-PaLM,\na prompt-tuned version of Flan-PaLM 540B) specailly\ntrained on medical data. The authors have tested GPT-4\nmodels’ ability to explain medical reasoning, personal-\nize explanations to students, and interactively craft new\ncounterfactual scenarios around a medical case.\n• Learning assistance and material development: Learn-\ning materials are critical in education as they provide a\nstructured way for students to acquire knowledge and\n12 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nEducation\nHealthcare\nAgriculture\nLifestyle\nMarketing\nGaming\nEntertainment\nFinance\nIndustry\n           Travel & Transport\nE-Commerce\nContent Creation\nAutomated Assessment\nWriting Assistance\nIntelligent Tutoring\nDrug Discovery\nPatient Diagnosis\nDiesease Prediction\nPersonalized Medicine\nImproving Crop Yield\nPest Control Assistance\nIdentifying Diseases, Data\nAnalysis and Prediction\nDiet Planner\nTravel Guide and Trip Advisor\nPersonalized Cook Book\nHobby Curator\nContent Creation\nCustomer Service\nPersonalized Advertising\nForecast Analysis\nChatbot Development\nGame Content Creation\nNon Playable Character\nSolitude \nEnhanced Customer Interaction\nPersonalized Content Creation\nSentiment Analysis\nFinancial Forecasting\nTrading Strategies\nRisk prediction and Management\nSustainability\nCustomer Service\nAutomated Assitance\nLogistical Management\nIntelligent Fleet Management and\nTracking\nReal-Time Inventory Trackiing \nProof Reading\nOrder Processing\nData Analysis\nEnabling Technologies\nApplications\nBig Data\nArtificial\nIntelligence\nCloud\nComputing\nEdge Computing\n5G &\nBeyond\nHuman Computer\nInteraction\nBenefits of Integrating GPT\nFIGURE 8: The impact of GPT models on various applications.\nskills. They can be tailored to meet the needs of diverse\nlearners and make learning more engaging and effective,\nsupporting teachers to create a more dynamic and inter-\nactive learning environment. GPT can contribute to cre-\nating learning materials by automating content genera-\ntion, providing multilingual content creation, language\ncorrection, personalized content creation, conducting\ntopic research, and generating assessments. It saves\ntime and effort for educators and publishers, improves\nthe accuracy and readability of material, and makes\nlearning more engaging and effective. GPT can gen-\nerate high-quality content such as summaries, quizzes,\nand lesson plans based on specific learning objectives,\nmaking learning accessible to a wider audience. It\ncan analyze written content and provide suggestions to\nimprove grammar, punctuation, and readability. GPT\ncan also assist in research writing by suggesting ideas\nfor structure, rephrasing and organizing content, and\nidentifying gaps in research [77]. Moreover, GPT can\nalso provide personalized feedback based on individual\nlearning progress, enhancing the development of more\ncomprehensive and informative learning materials.\n• Automated Assessments: Automated assessment in ed-\nucation uses technology to evaluate students’ learning\noutcomes, providing immediate feedback and reducing\npotential bias in grading. It can also help teachers iden-\nVOLUME 4, 2016 13\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\ntify areas where students may need additional support,\nenabling them to tailor their teaching methods to better\nmeet individual needs. GPT with its advanced natural\nlanguage processing skills, can help in automated as-\nsessment by analyzing and grading student responses\nto various types of assessment questions, including es-\nsays and short answer questions. It can also provide\nfeedback to students [78], such as highlighting areas\nfor improvement and suggesting further reading or re-\nsources. GPT’s natural language processing capabilities\ncan help to identify the meaning and context of students’\nresponses, making automated assessment more accurate\nand effective. Additionally, GPT can generate person-\nalized learning materials and exercises based on stu-\ndents’ assessment results, supporting educators to create\nmore tailored and effective learning experiences. The\nauthors in [79] have used Chat GPT in evaluating the\nstudents’ assignments such as quiz style questions, and\nalso in generating relevant practice problems to improve\ncontent retention and understanding. The results were\npromising in the classroom. The authors believe that\nChat GPT has the significant ability in reducing the load\nof instructor without compromising students’ learning\noutcomes.\n• Fostering Creativity: Creativity thinking plays a vital\nrole in education by encouraging students to think\nbeyond traditional boundaries and develop innovative\nsolutions to complex problems. It helps students to\napproach learning with an open mind and a willingness\nto explore new ideas, leading to greater engagement\nand motivation. GPT’s ability to generate human-like\nresponses and creative writing can aid in improving\ncreativity. It can help improve creativity by generating\nnew and innovative ideas based on vast amounts of\ndata and information. By analyzing patterns in language\nand identifying connections between different concepts,\nGPT can suggest novel approaches to teaching and\nlearning. Additionally, GPT can also generate creative\nprompts or challenges for students, encouraging them to\nthink outside the box and approach problems in unique\nways [80]. GPT can also analyze and evaluate students’\ncreative work, providing feedback and suggestions for\nimprovement. So, GPT can be a valuable tool for pro-\nmoting and enhancing creativity among students and\nfaculty members.\n3) Challenges\nThere are several advantages to incorporating GPTs in edu-\ncation, but it is essential to acknowledge the potential limi-\ntations. While GPTs can quickly generate information, they\nmay impede students’ critical thinking and problem-solving\nskills. Furthermore, learners who benefit from personal in-\nteraction with instructors may find the lack of human in-\nvolvement disadvantageous. GPTs rely on statistical patterns,\nso they cannot provide a comprehensive understanding of\nthe material being taught [78]. Privacy concerns arise when\nusing sensitive student data in GPTs for educational pur-\nposes. Additionally, since GPTs cannot provide citations, it is\nchallenging to identify the source of information generated.\nThe cost of maintaining GPT may be prohibitive for schools\nand educational institutions with limited resources. Finally,\ndistinguishing between reliable and unreliable information\ngenerated by GPTs can be difficult, so it is necessary to have\nhuman oversight to ensure data accuracy and regulate access.\n4) Summary\nGPT offers numerous advantages in the education sector,\nincluding personalized and adaptive instruction, automated\nassessment, creative writing support, and research writing as-\nsistance. They have the potential to revolutionize teaching by\ncreating lesson plans and activities, responding to natural lan-\nguage queries, and integrating multiple digital applications.\nHowever, there are also challenges to consider, such as the\npotential negative impact on critical thinking and problem-\nsolving skills, lack of human interaction, data security and\nprivacy concerns, inability to provide full comprehension,\nlack of citations or sources, high cost of maintenance, and po-\ntential for producing unreliable information. Further research\nis needed to explore human-computer interaction and user\ninterface design to integrate GPT into educational workflows\nwhile ensuring that the information they provide is accurate\nand reliable.\nB. HEALTHCARE\n1) Introduction\nBefore technology became widespread in healthcare, health-\ncare services were primarily delivered through face-to-face\ninteractions between healthcare professionals and patients.\nTraditional healthcare faced several challenges, including\nlimited medical instruments, paper-based health records, pa-\ntients receiving care mostly in hospitals or clinics, phys-\nical travel requirements to receive medical attention, and\nlimited medical research. Despite these challenges, tradi-\ntional healthcare still provided valuable medical services\nto patients. However, with the introduction of technology,\nhealthcare has become more efficient, accessible, and per-\nsonalized, resulting in improved patient outcomes and bet-\nter overall healthcare services. Technology has become an\nessential aspect of society, as reflected in the significant\ninvestments made in this sector. Despite the advancements\nin technology, the healthcare industry still faces various new\nchallenges, including access to healthcare, high costs, per-\nsonalized medicine, data privacy and security concerns, and\nan aging population. However, technology has the potential\nto address these challenges and improve the efficiency of\nhealthcare services.\n2) Impact of GPT in healthcare\nRecent years have seen significant advancements in tech-\nnology, including in the healthcare industry. Biotechnology,\nmedical devices, and pharmaceuticals have undergone trans-\nformations through the use of cutting-edge technologies like\n14 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nDL [81] and ML [82]. Currently, the healthcare sector is\nutilizing various forms of AI techniques for medical research\nand providing medical services. One such technique is the\nGPT features of NLP, which hold immense potential for\nthe healthcare industry. GPT can help to overcome several\nchallenges in healthcare in multiple ways. For instance, it can\nbe used to develop intelligent systems that assist doctors in\nmaking accurate diagnoses and providing clinical assistance\n[83] [84]. GPT can also analyze large volumes of medical\ndata and generate reports. Furthermore, it has potential appli-\ncations in drug discovery [85] [86], personalized medicine,\npatient diagnosis, medical image analysis, analyzing elec-\ntronic health records, clinical decision support systems, and\ndisease prediction.\n• Drug Discovery: Recent AI and machine learning tech-\nniques [87] [88] are having the potential to contribute\nto the growth and development of drug discovery. GPTs\nare capable of learning new patterns and relationships\n[89] in the dataset they were trained on. This capability\ncan be used in drug discovery to aid in the identification\nand design of potential new drugs with desired proper-\nties [90]. One of the key challenges in drug discovery is\nfinding compounds that can interact with specific parts\nof the body. GPT can help in this process by learning\nthe patterns and relationships from large databases of\nknown compounds [85]. GPT can be trained on large\nsets of chemical databases to analyze chemical reactions\nand their outcomes. This can help suggest potential\ncombinations of new drugs using the analyzed data.\nThese new drugs can also be analyzed using GPT to test\ntheir efficacy and toxicity.\n• Diagnosis: GPT can be used in medical diagnosis by\nanalyzing patient data. It can help to analyze medical\nrecords and extract information such as patient demo-\ngraphics, symptoms, and medical history. This can help\nmedical professionals provide effective patient care and\nimprove outcomes. The recent release of GPT-4 has the\nability to support multimodal information, allowing it\nto analyze images as input and produce text results as\noutput [91]. It is recommended to use AI systems such\nas a GPT, as clinical support tools to assist medical\nprofessionals in diagnosing and treating patients, but\nthey should not be relied upon as the sole source of\nmedical advice or decision-making. GPT can also be\nused to identify rare diseases by analyzing patient’s\ncomplete information. The authors in [92] have used a\ngeneral-purpose GPT based on GPT-3 model for patient\ndiagnosis and triage. The model has given a triage\naccuracy of 70% which was worse than a physician. But,\nin next subsequent weeks, the accuracy has improved to\n92% which is close to the performance of a physician.\nIn diagnosis, GPT-3 model has given 88% accuracy.\nFor emergency cases, GPT-3 has given 75% accuracy\nwhereas physician has given 94%.\n• Disease prediction: GPT has great potential in disease\nprediction [93]. By analyzing large amounts of medical\ndata, including patient records, medical images, and\nclinical trials, these pre-trained language models can\nlearn patterns and make predictions about the likelihood\nof a patient developing a particular disease. For instance,\ntrained healthcare GPTs can be used to predict the\noccurrence of diseases such as diabetes, heart disease,\nand cancer by analyzing various parameters, including\nthe patient’s medical history, age, family history, and\nlifestyle. It can also be used to predict the likelihood of a\nrare disease This helps in the early detection of high-risk\npatients so that medical personnel can take necessary\nmeasures and suitable medicines to reduce the risk of\ndeveloping the disease. The medical practitioner and\nauthor in [94] have recommended using GPT-4 models’\nability of NLP in bariatric surgery.\n• Personalized medicine: The COVID-19 pandemic has\nhighlighted that not all body systems are clinically sim-\nilar. For instance, during the pandemic, medicines like\nRemdesivir and Tocilizumab have been effective for one\ncategory of patients but do not affect another category of\npatients with similar clinical metrics, as they progress\nfrom a mild or moderate level of infection to a severe\nstage [95]. This highlights the need for personalized\nmedicine in today’s world. GPT can be used to identify\nvariable patterns of data to predict or classify hidden\nor unseen patterns, which can be used for exploratory\ndata analysis. GPT provide the possibility of identify-\ning personalized medicines [96] based on the clinical,\ngenomic, and nutritional data of patients. The dietician\nand the author in [97] have observed that the utilization\nof Chat GPTs has significantly decreased obesity rates\namong patients by offering personalized recommenda-\ntions regarding nutrition plans, exercise programs, and\npsychological support. This approach allows for the\ndevelopment of customized treatment plans that cater\nto the specific needs of individuals, leading to a more\nefficient method of treating obesity with the assistance\nof Chat GPT.\n3) Challenges\nWhile GPT is a powerful language model with numerous\napplications in healthcare, it is not without its challenges.\nThe primary challenge is data bias. As GPT models are also\nlearning models, the significant drawback of biasing is also\napplicable to GPT. GPT can be susceptible to bias. If the data\nused to train the model is biased, the model will learn from\nit and replicate the bias. This leads to incorrect treatment\nand predictions. Another challenge is the transparency of the\nmodel. GPT is complex to understand and interpret. This lack\nof transparency in technology can make doctors and medical\npersonnel not believe in the predictions, which may result\nin a hesitancy to trust and adopt technology [98]. Another\nimportant concern is security and privacy issues. As it is\na model to be trained on data, there is a huge amount of\nVOLUME 4, 2016 15\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nsensitive information about the patients to be used to improve\nthe algorithm and its performance. This results in significant\nsecurity and privacy concerns related to the use of GPT\nin healthcare. The final and important challenge is limited\nclinical validation. GPT are showing promising improvement\nin various fields of healthcare, such as drug discovery, and\ndisease prediction. But still, their effectiveness and accuracy\nin medical research and clinical settings have yet to be\nvalidated. More research and clinical trials are required to\nprove that GPT can transform the medical industry with full\ntrust.\n4) Summary\nGPT have the potential to revolutionize the healthcare indus-\ntry by contributing to drug discovery, personalized medicine,\nclinical support in making decisions, diagnosis support, and\ndisease prediction. This can be helpful for human beings to\npredict the disease in advance and treat it through proper\nmedicine. However, there are significant challenges that are\nto be addressed, such as technology adoption, data bias,\nregulatory challenges, and security and privacy issues. It is\nso important to analyze and evaluate the benefits and risks\nof using GPT in healthcare and to continue to monitor their\ndevelopment and implementation.\nC. INDUSTRY\n1) Introduction\nAn important economic transition from agriculture and hand-\nicrafts to large-scale industry and automated production was\nachieved by the industrial revolution. Efficiency and produc-\ntivity were raised as a result of modern equipment, energy\nsources, and labour arrangements. New opportunities and\nchallenges have been created as a result of the quick de-\nvelopment of new technologies in both the workplace and\nother industries [99]. The utilization of big data is a well-\nknown technology-driven trend. Nowadays, companies have\naccess to enormous volumes of data that may be examined to\nuncover insightful information. Big data can help businesses\nmake wise decisions and discover areas for development.\nAI is another innovation that is changing industries. AI\nsystems have the ability to analyse complex data, automate\nprocedures, and make wise conclusions [100]. This improves\nproduction by increasing its dependability, adaptability, and\nefficiency. The process of \"digitalization,\" which includes\nincorporating digital technologies into every element of busi-\nness, is creating industries to become more flexible, effi-\ncient, and valuable. Businesses may automate tedious work,\nimprove client experiences, and streamline operations by\nimplementing digital solutions. In today’s digitally-driven\nworld, adopting technological advancements is essential for\nmaintaining competitiveness and promoting growth.\n2) Impact of GPT in Industry\nIn industrial scenarios, GPT has the potential to be applied\nas a sustainability tool, assisting businesses in evaluating and\nenhancing their sustainability goals. Companies can improve\nsupply chain tracking and query response by integrating\npre-trained transformer models like ChatGPT with supply\nchain management platforms [101]. Additionally, GPTs can\noffer modifications to the production process that might\nincrease efficiency [102]. GPT can also help users make\nknowledgeable decisions about how to use resources, allow-\ning businesses to remain competitive while reducing their\nenvironmental effect. For example, the GPT-2 model has\ndemonstrated efficacy in sentiment analysis, providing in-\nsightful data for numerous applications [103].\n• Hospitality sector In the hospitality industry, hotels\nplace a high focus on providing satisfying guest expe-\nriences. To ensure that every tourist is satisfied during\ntheir stay, this necessitates adapting to their require-\nments and preferences. Hotels may improve the guest\nexperience in a number of ways by integrating GPT into\ntheir website or mobile application. Hotels may respond\nto consumer inquiries in a timely and precise manner by\nutilizing GPT [104]. Customers do not have to wait for\nhuman assistance when looking up information about\nfacilities, booking procedures, or room availability. Cus-\ntomers’ overall satisfaction with the hotel’s services is\nincreased as a result of the large reduction in client\nwait times. GPTs can also make it easier for visitors\nwho speak multiple languages to communicate [105].\nHotels can offer a more inclusive and welcoming ex-\nperience for visitors from other countries by removing\nlinguistic obstacles. Hotels may provide their visitors\nwith immersive and engaging experiences by combining\nGPT with AR technologies. For instance, customers can\nuse their mobile devices to get AR guided tours of the\nhotel or nearby attractions, offering a distinctive and\nentertaining way to explore the surroundings and learn\nmore about the hotel’s amenities.GPTs integration into\nvarious aspects of the hospitality industry gives hotels\nthe ability to deliver streamlined, tailored, and effective\nservices, increasing client happiness and loyalty.\n• Fashion: By providing highly customized user recom-\nmendations based on personal style, brand preferences,\nand particular clothing or accessory demands, collab-\norative filtering and AI algorithms have undoubtedly\nrevolutionized the fashion business. The amount of per-\nsonalization has been further increased in this context\nby the incorporation of GPT, dramatically altering the\npurchasing experience for customers [106]. Fashion\nplatforms may analyse a significant quantity of user\ndata, such as browsing history, purchasing behaviour,\nand style preferences, using the advanced capabilities\nof GPT to produce tailored recommendations. Fash-\nion platforms can direct consumers towards clothing\noptions that fit their desire for sustainable fashion by\nincluding eco-friendly fabric selections into the system.\nGPT improve users’ general fashion knowledge and\nconfidence while enabling users to keep up with the\nmost recent trends. The image-text retrieval skills of\n16 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nGPT significantly improve visual search capability in\nfashion platforms [107]. Users may make more con-\nfident shopping decisions and minimize the need for\nreturns by visualizing how various clothing items and\naccessories would appear on them without physically\ntrying them on. The model may recommend the proper\nsize for various brands and apparel products by taking\ninto account a user’s measurements, preferred fit styles,\nand historical data. The overall purchasing experience is\nenhanced and the frustration of wrong size is decreased.\n• Sustainability: Sustainable development means address-\ning current demands without sacrificing the capacity of\nfuture generations to address their own needs. Goals\nfor sustainable development can be attained by imple-\nmenting GPTs in a variety of sectors, including man-\nufacturing and corporate operations [108]. The models\ncan estimate where energy saving measures would be\nmost useful by analyzing past data and patterns to pro-\nvide insights into energy usage, pinpoint problem areas,\nand recommend opportunities for improvement. GPTs\ncan aid in identifying sustainability-related problems,\ncreating plans and strategies to solve them, investigat-\ning brand-new sustainable activities, keeping track of\nadvancements, and conducting routine reviews. Com-\npanies can choose activities that will have the biggest\npositive impact by grading tasks and actions according\nto their impact on sustainability [109]. The models can\noptimize supply chains for decreased carbon emissions,\nminimized waste, and improved resource efficiency\nby assessing elements including transportation routes,\npackaging materials, and supplier practises [110]. This\nresults in more environmentally friendly production,\ndistribution, and sourcing procedures.\n3) Challenges\nThere are many different industrial fields where GPT models\ncan be applied; the three areas mentioned above are only a\nfew. However, for optimal use, the industrial sector needs\nto be ready to adapt to a constantly changing environment.\nPublic and corporate policies must be developed over the\nlong term to promote the use of sustainable production tech-\nniques. For enterprises, deploying pre-trained GPT models\ncan be a costly task. Continuous development and training\nare also required to accommodate new and evolving inquiries\nas client expectations change. Companies have to carefully\nassess the benefits and costs before implementing the GPT\nmodel because these continuing efforts raise the deployment\ncost [111]. For industries to fully benefit from GPT mod-\nels, it is crucial to address issues with interpretability, data\nreliance, and ethical considerations. Industry may therefore\ntake advantage of these GPT models’ advantages, make wise\ndecisions, and promote sustainable development.\n4) Summary\nGPTs have the ability to have a positive impact on society\nand business operations. They can speed up operations like\naccounting, sales, and marketing, increasing productivity.\nBut before they are widely used, ethical problems need to be\nfully investigated. Technology products will change as GPT\nmodels develop. To reap the benefits and reduce dangers, it\nis essential to solve interpretability and data concerns. GPTs\ncan have a tremendous positive impact on businesses, society,\nand the economy when they are used responsibly.\nD. AGRICULTURE\n1) Introduction\nTraditional agriculture, a time-honored practice passed down\nthrough generations, sustains civilizations with its crop cul-\ntivation and livestock rearing methods. Rooted in a deep\nconnection to nature, it emphasizes sustainability and lo-\ncal ecosystem understanding. Beyond providing sustenance\nand livelihoods, traditional agriculture preserves cultural\nheritage. However, it also faces challenges such as labor-\nintensive processes and shortages, inefficient resource utiliza-\ntion, vulnerability to pests and diseases, and limited access to\nreal-time data and environmental impact. Today, by merging\ntradition with modernity, we have the opportunity to leverage\ntechnological advancements to enhance productivity, sustain-\nability, and resilience while honoring the profound legacy of\ntraditional agriculture for future generations.\n2) Impact of GPT in Agriculture\nGPTs have the ability to overcome the challenges of agricul-\nture. It offers valuable advantages to the agriculture sector.\nIt acts as a comprehensive knowledge source, providing\ninformation on crop cultivation, pest management, and soil\nhealth. By analyzing real-time data, GPT assists farmers in\nmaking informed decisions regarding optimal planting times\nand resource allocation. It plays a crucial role in identifying\nand addressing crop diseases and pests accurately. Moreover,\nGPT enables precision farming practices by utilizing sensor\ndata and satellite imagery, ensuring precise irrigation, fer-\ntilization, and pest control. Additionally, it provides market\nanalysis and price prediction, empowering farmers to navi-\ngate market conditions and optimize pricing strategies. GPT\nalso supports farm management and planning, optimizing\ncrop rotation and resource usage. By facilitating agricultural\nresearch and innovation, GPT contributes to advancements\nin crop breeding and sustainable practices. Embracing GPT\nin agriculture enhances decision-making, efficiency, and sus-\ntainability, ultimately promoting improved productivity and\nfood security. For instance, GPT-4 can educate farmers about\nnew methods and goods and warn them of potential issues or\npossibilities by analyzing data from many sources [112].\n• Improving Crop Yields:\nWith its data analysis capabilities and real-time rec-\nommendations, GPTs plays a crucial role in enhanc-\ning crop yields. By examining historical yield data,\nweather patterns, soil conditions, and crop management\npractices, GPT identifies valuable patterns and corre-\nlations, providing insights and suggestions for optimal\nVOLUME 4, 2016 17\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\ncrop management techniques [113]. It enables precision\nfarming by integrating data from sensors, satellites, and\nIoT devices, granting timely guidance on resource allo-\ncation for improved efficiency. Additionally, GPT aids\nin the early identification and management of crop dis-\neases and pests, minimizing yield losses through precise\nand prompt recommendations. Moreover, GPT supports\ncrop breeding and genetic optimization by analyzing\ngenetic data and plant characteristics, expediting the de-\nvelopment of high-yielding and resilient crop varieties.\nTherefore, GPTs data analysis and decision support\ncapabilities significantly contribute to enhancing crop\nyields and maximizing agricultural productivity [114].\n• Pest Control:\nGPT offers significant support in the realm of pest con-\ntrol in agriculture. By analyzing extensive data on pests,\nincluding their behavior, life cycles, and characteristics,\nGPT can provide valuable insights for effective control\nmeasures. It aids in early pest detection by analyzing\nsensor data and satellite imagery, enabling proactive\ninterventions to prevent pest spread and minimize dam-\nage [115]. GPT also assists in determining suitable pest\ncontrol methods tailored to specific crops and pests,\nconsidering factors like environmental impact and sus-\ntainability. Additionally, it contributes to precision pest\ncontrol by leveraging real-time data to optimize timing\nand dosage of interventions, reducing chemical usage\nand resistance risks. It also aids in identifying natural\nenemies and beneficial organisms, promoting natural\npest control mechanisms such as habitat diversification\nand companion planting. Through GPT’s data analysis\nand recommendation capabilities, it empowers farmers\nwith informed decisions, leading to more effective and\nsustainable pest management strategies, ultimately re-\nducing crop losses and enhancing agricultural produc-\ntivity.\n• Identifying Diseases and Soil analysis:\nGPTs offer valuable assistance in disease identification\nand soil analysis within the field of agriculture. With\nits ability to analyze extensive data sets, GPT can accu-\nrately identify crop diseases by processing information\nsuch as symptoms, historical data, and disease patterns.\nThis enables timely and effective disease management\nstrategies [113]. Additionally, It plays a significant role\nin soil analysis by analyzing diverse soil-related data,\nincluding nutrient levels, pH, organic matter content,\nand soil composition. By interpreting this data, It pro-\nvides insights into soil health and fertility, empowering\nfarmers to make informed decisions regarding nutrient\nmanagement, soil amendments, and cultivation prac-\ntices. Moreover, GPT can identify complex interactions\nbetween soil conditions and crop diseases, helping farm-\ners understand the relationship and take preventive mea-\nsures accordingly. It also supports precision agriculture\npractices by integrating sensor data and satellite imagery\nto assess soil variations across fields, allowing for site-\nspecific management strategies and optimized resource\nallocation. Furthermore, it also facilitates knowledge\nsharing and collaboration by analyzing and dissem-\ninating research findings, best practices, and disease\noutbreak information among agricultural communities.\nThis collective intelligence enhances disease monitoring\nand control efforts on a broader scale.\n3) Challenges\nWhile GPT, provides significant benefits to agriculture, there\nare challenges to its implementation. GPT’s effectiveness\ndepends on the availability and quality of data, making\ninsufficient or biased data a limitation. The interpretabil-\nity of GPT’s decision-making process is challenging due\nto its black-box nature, hindering trust and understanding.\nGPT’s computational requirements and infrastructure can\nbe demanding, posing difficulties for resource-constrained\nfarmers. Language and domain-specific nuances can affect\nits performance, impacting accuracy and relevance. Ethical\nconsiderations surrounding data privacy and ownership need\ncareful attention to ensure responsible use. By addressing\nthese challenges, researchers and practitioners can unlock\nGPT’s potential while ensuring its practicality and ethical\nimplementation in agriculture.\n4) Summary\nGPT holds immense potential in agriculture, offering nu-\nmerous benefits alongside notable challenges. Its data anal-\nysis capabilities empower farmers with informed decision-\nmaking in disease identification, soil analysis, and precision\nfarming, leading to improved crop yields and sustainable\npractices. However, the effectiveness of GPT relies on data\navailability and quality, while its interpretability remains a\nchallenge due to its black-box nature. Additionally, compu-\ntational requirements, language nuances, and ethical consid-\nerations require careful attention. By addressing these chal-\nlenges, the agricultural sector can harness the full potential\nof GPT, paving the way for more productive, efficient, and\nresponsible farming practices.\nE. TRAVEL AND TRANSPORT\n1) Introduction\nHistorically, animals have been used by people as their\nmain source of transportation. But as the world’s popula-\ntion increased, the demand for more effective transportation\nsystems increased. Transportation-related technological ad-\nvancements have fundamentally changed the sector in several\nways. Business operations like order tracking, freight man-\nagement, and customer support can be streamlined by au-\ntomation employing AI-driven technologies. Companies can\nenable their employees to concentrate on more beneficial and\nprofitable duties by automating these tasks [116]. With better\ntransportation networks and logistics management systems\nthat optimize routes and reduce transit times, technological\ndevelopments also enable speedier delivery times. In terms\nof product development, technical advancement has paved\n18 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nthe way for the development of innovative vehicles, infras-\ntructure, and logistics systems, leading to the production\nof more sophisticated and effective transportation choices.\nAnother noteworthy benefit of technology advancement in\nlogistics and transportation is increased customer service.\nInquiries and problems can be handled quickly and efficiently\nby chatbots and customer support systems powered by AI,\nimproving the entire customer experience [14].\n2) Impact of GPT in Travel and Transport\nCompanies can learn about customer preferences in real\ntime by using GPTs in logistics and transportation, which\nresults in better personalization and more customer satisfac-\ntion. GPTs leverage NLP approaches to interpret customer\nrequirements and preferences, enabling customized sugges-\ntions as well as guidance in the logistics and transportation\nprocesses. The most effective routes and forms of transporta-\ntion can be recommended using GPTs, which can analyse\na large amount of data, including traffic patterns, weather\nconditions, and delivery requirements [117]. In addition,\nGPTs can be used as travel planners, allowing visitors to\nenter their travel budget, duration, and destination to create\ncustomized itineraries. For travel agencies, this personalized\napproach increases consumer satisfaction and revenue [118].\n• Logistical Management: GPTs can be quite important in\nthe context of shipping logistics. They can automate the\ncreation of shipping labels, eliminating up manual entry\nand lowering the possibility of mistakes. Additionally,\nGPTs can have access to real-time tracking data and can\nintegrate GPS data and sensors to provide businesses\nand customers with precise and up-to-date shipment\nstatus information. Companies can successfully monitor\nshipments with the use of GPTs, geographic information\nsystems (GIS), and routing algorithms [14]. Organi-\nzations can track shipments in real-time and ensure\nvisibility throughout the supply chain by utilizing GPS\ndata and sensor technology [119]. Customers can re-\nceive precise updates on their shipments using this real-\ntime information, which will improve their experience\noverall. Overall, the use of GPTs into shipping logistics\nresults in increased automation, efficiency, and client\nsatisfaction.\n• Intelligent Fleet Management and Tracking: Compa-\nnies can get real-time fleet updates by utilizing GPT\nmodels, which enables them to track vehicles quickly\nand precisely. GPT models’ underlying technology also\nsupports proactive fleet management. GPTs can identify\npossible problems or maintenance needs before they\ndevelop into expensive breakdowns or accidents by an-\nalyzing data from a variety of sources [120]. With this\nknowledge, companies may take preventative measures,\nsuch as planning maintenance or quickly fixing devel-\noping problems, ultimately saving time and money by\npreventing unintended delays. Additionally, GPTs can\nprovide clever alerts and notifications. Businesses can\nreceive alerts when vehicles arrive at specified areas by\nsetting up specific triggers, which enables better coor-\ndination and customer service [121]. For instance, busi-\nnesses can alert clients or storage facilities in advance\nof a truck’s arrival, allowing for effective unloading and\nloading procedures.\n• Real-Time Inventory Tracking: GPTs enable businesses\nto manage their inventory levels while on the road with\na cloud-based platform that makes it simple to access\ninventory data from anywhere in the world. Better in-\nventory management and decision-making are made\npossible by this real-time accessibility. This ensures that\nthe appropriate quantity of stock is accessible when\nneeded to fulfil consumer requests, while minimizing\ncarrying costs and preventing lost sales as a result of\nstockouts. GPTs can streamline inventory management\nprocedures by eliminating the need for human data entry\ninto spreadsheets, saving time and cutting overhead\ncosts [116]. With the advent of 5G technology, the\ncost of connected devices has dramatically decreased,\nmaking it more practical and affordable for businesses\nto set up and operate connected inventory monitoring\nsystems. This may make real-time inventory tracking\nsolutions more widely adopted, thereby increasing the\neffectiveness and precision of inventory management\n[122].\n• Streamlining Delivery Operations: GPTs are able to es-\ntimate traffic trends and improve routes for both drivers\nand passengers using real-time data [14]. These models\ncan produce effective routes that reduce travel times\nand enhance overall delivery performance by taking into\naccount aspects like traffic congestion, road conditions,\nand delivery schedules. Route optimization not only\nreduces travel time but also benefits the environment. In\norder to improve air quality and create a more sustain-\nable delivery process, it is possible to cut down on idle\ntimes and trip distances. Businesses may streamline op-\nerations, improve the overall customer experience, and\ncontribute to a more sustainable and environmentally\nfriendly approach to logistics by automating procedures,\noptimizing routes, and utilizing real-time data [123].\n• Tourism: GPTs have the potential to significantly im-\nprove a number of tourism-related aspects. GPTs can\noffer customized solutions that suit the individual’s\npreferences by understanding their needs and interests,\nresulting in a more pleasurable travel experience. GPTs\nare excellent at understanding and creating text that is\nhuman-like [4]. This functionality can be used in the\ntravel and tourism sector to enable chatbots or virtual\ntravel assistants to communicate with users in natural\nlanguage [124]. Trip planning and information retrieval\nare made more simple and user-friendly by the ability\nof travelers to ask questions, look for advice, and obtain\nfull details about destinations, modes of transportation,\ncustoms, and more. GPTs are capable of producing\nin-depth and interesting descriptions of tourist sites,\nattractions, lodging, restaurants etc. GPTs can provide\nVOLUME 4, 2016 19\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\ntime-efficient routes that guarantee a complete travel\nexperience [125]. Including advice on local legislation,\nemergency contacts, medical facilities, and potential\nrisks, GPTs can offer helpful information and direction\nregarding travel safety.\n3) Challenges\nPrivacy issues may occur when using sensitive data in travel\nGPTs. It is essential to manage user data sensibly and putting\nup strong security measures to safeguard private data. The\nquality of the model’s outputs is directly influenced by the\ncorrectness and completeness of the data utilized during the\ntraining phase. Ethical considerations should be taken into\naccount when creating AI-powered applications employing\nGPTs. It’s crucial to check that the models are truthful, unbi-\nased, and free from harmful presumptions or discriminatory\nprocedures [126]. Although the models contain advanced\nfeatures, they are difficult to tailor for specific use cases, need\na lot of data to train, and have built-in limitations.\n4) Summary\nEmerging GPTs have the potential to enhance productiv-\nity, communication, and the calibre of goods and services,\nwhich will benefit many aspects of people’s life. GPTs can\noffer real-time updates, effective route optimization, and\ncustomized recommendations in the travel and transportation\nindustries, enhancing the overall travel experience and in-\ncreasing operational effectiveness. Adopting them, however,\ncomes with some difficulties. As specific roles are replaced\nby automation, GPTs may result in job displacement [127].\nAdditionally, the computational and memory requirements\nfor GPTs make their deployment on compact or low-power\ndevices difficult. GPTs may not be accessible to growing\nbusinesses due to the high costs associated with obtaining\nand using them. Despite these obstacles, attempts are being\ndone to overcome them and improve the usability and value\nof GPTs for a larger range of users.\nF. E-COMMERCE\n1) Introduction\nElectronic commerce, commonly referred to as e-commerce,\nis a way for conducting economic transactions and create\nrelationships between groups of people and entities using\ndigital information processes and electronic communications\n[128]. Globally, this type of trade has experienced substantial\ngrowth, particularly in the retail sector. The preference for\ninternet shopping, especially among younger millennials, is a\nprominent trend in consumer behaviour. Mobile devices have\nconsequently taken over as the main method for carrying\nout internet transactions [129]. Therefore, it is crucial for e-\ncommerce companies to give the customer experience in their\nmobile applications top priority. The provision of brief text\nsummaries for titles and reviews is an essential component\nof this. These summaries are essential for optimizing search\nresults, helping consumers identify appropriate items, and ul-\ntimately raising customer happiness in the online purchasing\nspace [130].\n2) Impact of GPT in E-Commerce Realms\nThe e-commerce sector could significantly advance with\nthe introduction of GPTs. GPTs can be accessed by users\nor customers and are intended to answer commonly asked\nquestions and give in-depth details about many elements of\nthe e-commerce process, such as products, delivery, refunds,\nand more [106]. One of the main benefits of GPTs is their\ncapacity for quick responses, which decreases the amount of\ntime customers must wait to hear back from businesses [131].\nBy taking care of an important number of client inquiries,\nthis function not only increases customer happiness but also\nlessens the workload on support workers. Customers will\nultimately have a better purchasing experience as a result of\nbeing able to quickly acquire the information they require and\ninteract with GPTs [105].\n• Proofreading: To improve the calibre and accuracy of\nwritten content in e-commerce, GPTs can be used for\nproofreading. Written content is essential for product\ndescriptions, marketing materials, customer reviews,\nand other text-based components in the e-commerce\nsector [104]. For the purpose of projecting professional-\nism, fostering trust, and delivering a satisfying user ex-\nperience, this text must be devoid of errors, well-written,\nand grammatically correct. E-commerce companies can\nautomate the process of identifying and correcting these\nproblems by using GPTs for proofreading, which saves\ntime and effort as comparison to manual proofreading\n[132]. This can be especially helpful in situations when\nusers are writing product reviews or interacting with\ncustomer service. An improved user experience is facil-\nitated by the early detection and rectification of errors,\nwhich also helps to avoid potential misunderstandings\nor miscommunications.\n• Order Processing: GPTs are useful in many areas of\norder management and customer service because they\ncan comprehend and produce text that looks like human\nspeech. GPTs can help with handling consumer ques-\ntions about orders [133]. GPT is capable of interpreting\nthe queries, providing important details like order status,\ntracking information, and expected delivery time, as\nwell as suggesting corrections for frequent problems\n[134]. By delivering real-time information, GPTs can\nassist customers in tracking their orders. Customers can\ncustomize their purchase with the help of GPTs. GPTs\ncan help in the identification of possibly fraudulent\norders by examining past transaction data, consumer\nbehaviour patterns etc [135]. Based on a customer’s\npast purchases, browsing habits, and preferences, GPTs\ncan offer tailored product recommendations. When a\nconsumer puts a purchase, the model can examine the\ninformation and produce recommendations for related\nor supplementary products that the customer might find\ninteresting.\n20 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n• Generating titles for products: Companies can use GPTs\nto produce interesting and educational material to im-\nprove the appeal of their product listings [116]. Based\non a product’s category, brand, and special characteris-\ntics, GPTs can come up with attractive titles for it. The\nmodel can produce imaginative and memorable names\nthat aid in brand awareness and differentiation by re-\nceiving relevant information such as the characteristics\nof the product and the target market. GPTs are trained\nto produce in-depth and interesting product descriptions\n[112]. These summaries can offer a thorough summary\nthat aids clients in selecting products wisely. GPTs are\ncapable of coming up with clever and appealing captions\nfor product images. GPTs can be adjusted to better\nreflect the tone and aesthetic of a certain brand [136].\nAs a result, the brand identity is consistent and unified\nthroughout all product listings.\n• Strategy Planning: GPTs have the ability to come up\nwith original and distinctive concepts for marketing\ncampaigns [137]. The model can provide recommenda-\ntions for different campaign aspects, such as slogans,\ntaglines, themes, contests, social media strategies, and\nmore by taking into account relevant information about\nthe product, target audience, marketing objectives, and\ndesired outcomes. GPTs can help with email writing\nthat encourages readers to become partners, investors,\nor customers [138]. To increase the likelihood of a\nfavourable response or interaction, these emails can be\ncustomized to address the needs and potential bene-\nfits for the receivers. To improve their comprehension\nand production of appropriate material, GPTs can be\ntrained on domain-specific knowledge bases, such as\ne-commerce [106]. The models can offer more precise\nand situation-specific recommendations for advertising\nstrategies, product positioning, and target audience in-\nteraction because of this specialized training.\n• Data analysis: There are numerous ways to use GPTs for\ndata analysis in e-commerce. E-commerce data prepa-\nration can be aided by GPTs [24]. Data normalization,\ncleansing, and formatting are a few of the duties in-\nvolved. GPTs can produce summaries, identify signif-\nicant topics, and extract appropriate data by studying\ntextual descriptions, reviews, and consumer feedback.\nThis helps you know the data more thoroughly, iden-\ntify trends, and find insightful information. Customer\nreviews and social media comments from e-commerce\ncan be analyzed for sentiment using GPTs. The sen-\ntiment expressed in text can be evaluated using GPTs\nand categorized as either positive, negative, or neutral\n[106]. Understanding client views, recognizing product\nstrengths and deficiencies, and making data-driven de-\ncisions all benefit from this analysis, which also helps\nto increase customer happiness. Segmenting consumers\nbased on preferences, behaviours, or past purchases can\nbe aided by GPT models [139]. For the purpose of\ndetecting fraud in e-commerce transactions, GPTs can\nbe used. GPTs can support the identification of poten-\ntially fraudulent actions by examining past transaction\ndata, user behaviour patterns, and recognized fraudulent\ntendencies [140].\n3) Challenges\nWhile GPTs have a lot of potential for numerous e-commerce\napplications, they also have several drawbacks. In order to\nproduce responses, GPTs mostly rely on the context given in\nthe input text. They could, however, find it difficult to fully\nunderstand the broader context or details that are unique to\ne-commerce. GPTs provide replies using training data and\nprior knowledge. They are unable to access real-time data\nor carry out real-time calculations [141]. They might not be\nappropriate for giving current information, such as pricing,\nproduct availability, or dynamic promotional offers. GPTs\ngain their knowledge from a wealth of training data, which\nincludes text taken from the internet, which may be biased,\nstereotyped, or otherwise offensive [142]. The models may\nunintentionally provide biased or unsuitable replies if they\nare not rigorously managed and monitored, which could be\nharmful to the customer experience and brand reputation. The\nuse of ethical principles and the training data must both be\ngiven careful thought.\n4) Summary\nThe conversational interface offered by GPTs customizes the\npurchasing process and makes interactions with clients more\ninteresting and appropriate to their individual requirements.\nGPTs can also be utilized to get insightful customer feed-\nback. Businesses can learn about customers’ preferences,\nissues, and opinions regarding their products and services\nby conversing with them. In order to better serve their target\naudience, organizations can use this information to discover\nareas for improvement, increase customer happiness, and\nmake data-driven decisions. It’s essential to recognize that\nGPTs might occasionally make mistakes or give poor an-\nswers, particularly when dealing with complicated or am-\nbiguous queries. This highlights the necessity of continual\nmodel training, thorough testing, and modification to guaran-\ntee that they consistently meet consumer needs. To confirm\nthe efficacy and dependability of using GPTs specifically in\nthe e-commerce area, more research and testing are required.\nWhen implementing GPTs, it’s critical for businesses to\ntake into account the particulars of their own e-commerce\nbusinesses, their target market, and the type of the client\nenquiries. Regular monitoring and feedback analysis, along\nwith a systematic and iterative approach, can help make sure\nthat the outcomes of using GPT models are in line with the\nobjectives of e-commerce enterprises.\nG. ENTERTAINMENT\n1) Introduction\nIn the ancient days, the Entertainment meant about play-\ning games with neighbors covers all outdoor games, indoor\ngames and chatting with neighbours through telephone. As\nVOLUME 4, 2016 21\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\ndigitization has bought greater advancements in computation\nand communication, in turn access to internet is also much\neasier. This has changed the way people are entertained. as\npeople are connected and fully engaged in completing the tar-\nget for the day. And there was a radical shift from traditional\nemployment to employment in the Industrial Revolution age.\nStress and pressure are common factors hindering people of\ndifferent age groups. The different forms of entertainment\nserve as stress busters. Entertainment and mental health are\ninterrelated; the former transfers happiness, bringing har-\nmony and peace to mental health. Some common forms of\nentertainment include playing games, watching TV series\nor movies, or funny videos, shopping, debugging, coding,\nbrowsing the internet, listening to music, dancing, chatting,\npainting, crafting, reading books, cooking, and many more,\nwhich can lessen the stress carried [143]. Entertaining and\ngetting entertained is the biggest motivation and medicine\nfor all mental illnesses. Entertainment helps to improve the\nmotor skills of humans, thereby inducing a positive cognitive\neffect towards the work.\n2) Impact of GPT on the Entertainment Industry\nGPT is a potential game-changer in the entertainment field,\ndelivering endless entertainment. Since its evolution, GPT\nmodels have been adopted as an entertainer crosschecking\ntheir ability to produce content on funny and illogical ques-\ntions. GPTs entertain people in many ways, and of course,\nusing GPT itself an entertainment as it reduces the burden\nof overthinking by providing immediate feedback to queries\nin seconds [144]. The results are amazing and have been\nutilized for many purposes today. When the GPT model was\nprobed to complete a scene from the movie “Frozen,” it\nresponded with an entertaining writeup [145], [146]. Some of\nthe impacts of GPTs on Entertainment applications are given\nbelow:\n• Solitude with GPT: As the GPT itself is an entertainer,\none can feel better alone with the GPT, which helps to\ncome out of loneliness by exploring its savors [147].\nGPTs assist in providing soothing poems, mental heal-\ning quotes, and funny riddles. People with loneliness\nmay feel anxiety, especially with older ones at home. In\nthis case, GPT-4 helps people with its V oice Technology\nfeature, enabling users to input their audio [147]. In\nturn, the GPT model responds to user-specific speech\noutput using NLP algorithms embedded with it. The\nelderly can feel safe and attentive at home. GPT-4 is\nmultilingual and can understand various dialects and\naccents for personalized user experience.\n• Enhanced Customer Interaction: The advent of Chat-\nGPT and Bard has improved customer interactions on\ncontent such as movies, Over-the-Top (OTT) platforms\nlike Netflix, Hulu, Disney+ Hotstar, and prime video,\nsound recordings, song lyrics, pictorial works, comics,\njokes, memes, viral videos, and other entertaining fac-\ntors. Further, GPTs provide human-like recommenda-\ntions on user-specific fun activities based on user in-\nteractions for an immersive experience. This has dra-\nmatically improved the interactions in the engagement\nindustries. User engagement can be further improved by\nproviding dynamic and more realistic responses to user\nqueries, such as creating virtual actors for interacting\nwith real actors [148].\n• Personalized Content Creation: GPTs can help gener-\nate user-specific personalized content by analyzing the\nuser preferences and generating content like predicting\nfuture scenarios tailored to the user’s interest. GPTs\ncan be used for creating personalized, engaging, and\nhigh-quality content for online business advertising,\nideas for content generation, marketing messages for\nattracting customers, descriptions for selling products,\nand captions for social media [149]. In addition, it can\nbe used for optimizing the contents for search engines,\ni.e., GPTs will provide relevant terms for search, thereby\navoiding traffic to the web sources.\n• For the Film and TV industry: GPT-powered virtual\nassistants assist users in booking tickets and generating\ncontent and personalized recommendations using AI\nmodels. The evolution of GPT-4 with advanced NLP\nand DL algorithms helps the scriptwriter to generate\nAI-driven content without the human author named\nvirtual storytelling [150]. GPTs create interactive sto-\nries, dialogues, and characters, recommending suitable\ncharacters. Furthermore, GPTs can be used to create\ncontent for video games, voice-enabled applications,\nAR applications, and other VR experiences in virtual\nworlds [151].\n• For Social media influencers: GPTs can generate per-\nsonalized marketing ads for each customer based on\ntheir previous interactions and provides relevant sugges-\ntions for customer viewing experiences. Youtubers and\nother social media content creators will potentially ben-\nefit from generating channel content based on demand\nand realistic societal activities.\n• Realistic Gaming Interactions: GPT helps to generate\nthe players, gaming narratives, dialogues, user interface,\nand user-specific gaming recommendations and new\ngame creation. Powerful HCIs can render a better user\nexperience for game developers and players. Assistance\nto the game developers in debugging and enhancing\nthe code developed. GPT uses various NLP and AI\nalgorithms trained with massive data to predict the next\nphrase/movements and provide human-like experiences\nin 3D gaming environments. ChatGPT has been inte-\ngrated with AR and VR to provide an immersive gaming\nexperience.\n3) Challenges\nLatency is the major issue connected with rendering the\nvoice-based response to the voice input. As well, plausible\nmisinterpretations may mislead the responses, and interrup-\ntions to the relayed output are difficult. Enabling technologies\nlike EC and 5G can help overcome this issue. Also, GPTs\n22 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nmust be capable of storing the facts with audio conversations\nto relay them while conversing the other day. Furthermore,\nthe AI system must be built in such a way that it can\ncontinuously learn (lifelong machine learning) and enhance\nover time. The major ethical concern with virtual storytelling\nis the bias exposed in the training data and the obscurity of\nreproduced content on the generated stories. Another issue\nwith the generated content is plagiarism (i.e., producing\ncontent similar to the content in the published articles or\nbooks), raising disputes with intellectual property rights. In\naddition to this, the source of the content generated remains\nunexplored. The language barriers in using GPT must be\nlessened to improve user experience and utilize the features\nof GPT [112]. The implication of the user to provide inputs\nin a certain format to GPTs can be further improved by\nproviding different options in addition to voice-based inputs\nGPT4, like braille screen input for visually disabled people.\nThe user authentication can also be further enhanced to\nsafeguard user-specific content generation and avoid repeated\ncontent generation for users with similar requests. One of the\nprimary concerns with the GPTs adoption is job loss. Content\ncreators, bloggers, and poets may lose their jobs.\n4) Summary\nThe entertainment industry is the one which will be in de-\nmand always, as it is a lifeline for many individuals leading\na stressful work environment or personal life. Despite the\nstress, entertainment has become part of routine life due\nto its immersive nature, creating harmony in the mind and\nthe environment. GPTs have made a major contribution to\nenhancing the entertainment industry, but the job security of\nmany professionals in this field remains unanswered. GPTs\nmust be trained on unbiased data and ensure transparency\nin source content generation to provide a secure, robust, and\nefficient contribution to the entertainment industry. To attract\nall types of users, the multilingual capability and content\nrendering of GPTs can be further enhanced. The issues con-\nstrained by providing user inputs to GPTs can be alleviated to\nall extent. Furthermore, safer user content generation without\nplagiarism and relating facts with previous conversations can\nbe guaranteed by abiding by the storage requirements to deal\nwith a more personalized user experience.\nH. LIFESTYLE\n1) Introduction\nLifestyle, the way of our living, is one of the prominent areas\nmost people in today’s digital era of AI, are bound to and\nlook for constant improvement. The “modus vivendi” is a\nLatin expression that semantically means a way of living\nand should be understood in terms of values and attitudes.\nThese two terms manifest self, influenced by family, society,\nand global media. Directly or indirectly, these influence an\nindividual’s lifestyle. Adopted from a sociological perspec-\ntive, an individual expresses oneself through different prac-\ntices, viz., eating ways, drinking behaviours, mode of travel,\ntravelling places, costume designs, body-shaping cloth to\nwear, media preferences, education choices, job preferences,\nentertainment modes, managing leisure time, means of com-\nmunication and so [152]. In all these practices, individuals\nwould like to explore and learn about what, where, how,\nand when factors for reading sustainable development [153].\nThe concept of lifestyle is all about “how one wants to live\none’s life.” Consumerism is the act of purchasing artifacts\nfor societal status and is one of the thriving lifestyle factors.\nCertain standard indicators like job, wealth, and physical and\nmental health determine the quality of one’s life. Also, the\nchoice of a healthy lifestyle moderately determines the health\nof an individual [154]. Furthermore, few people believe that\nlifestyle reflects their socioeconomic status. Many epidemi-\nologic studies state that better lifestyles have dramatically\nreduced the risk of various chronic diseases and are the\nprimary cause for their prevention [155]. The lifestyle has\nbeen defined on different societal levels from individual,\npositional, and national to global [153]. At the global level,\nlifestyle is adopted by general world-class influencers. In\ncontrast, at the national level, the influencing factors will\nbe the government and different cultural patterns across the\ncountry. The positional level concerns influence from differ-\nent status groups, age categories, gender groups, and social\nclasses. And the individual level is influenced by a closely\nmoving group of individuals concerned about self-identity.\nThe major source of information about these influencers\nis the Internet through social media networks and personal\ndevelopment advertisements.\n2) Impact of GPT in Lifestyle\nThe most remarkable application of AI, the GPT, paves the\nway for the betterment of mankind in offering human-like in-\ntelligent conversation on all whereabouts. People will always\nprefer to interact with other peers to learn their attributes and\ntweak them for societal status. Various GPTs have flourished\nfor different lifestyle indicators, and they provide human-\nlike assistance to all queries on fine-tuning the lifestyle by\nharnessing the power of AI [156]. The advanced reasoning\ncapability of GPT-4 serves the purpose better [147].\n• Diet Planner: Free GPT applications for maintaining\na balanced diet, helping the individual with a weight\nloss diet plan, followed by a brief list of meal plans,\nrequired shopping lists, physical activity plans targeting\nparticular body parts [157], motivational messages, and\npersonalized sleeping patterns. These apps act more\nlike personalized training assistance and help to track\nprogress with visualization charts or graphs. Fitness\nlevel, available free hours, medications taken, and avail-\nable exercise equipment will be given as input to GPT.\n• Travel Guide and Trip Advisor: Harnessing AI models,\nGPT provides an individual’s travel plan itinerary based\non information like the place(multiple cities), budget,\nand the number of days. These GPTs provide local\nrecommendations on restaurants, hotels, and other at-\ntractions. RoamAround, Roamr, and VacayChatbot are\nsome of the travel planning GPTs [158].\nVOLUME 4, 2016 23\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n• Personalized Stylist and Beauty Advisor: GPTs can\nact as personalized stylists for an individual by gen-\nerating occasion-specific clothing and costume prefer-\nences. GPTs can assist in organizing wardrobes based\non seasonal outfits and provide recommendations on\ne-commerce fashion stores for purchasing favourite\nbrands. GPTs can provide tailoring design options, fab-\nric choices, and design materials. Furthermore, GPTs\ncan provide updates on a stock based on the preferred\nsearches and provide insight into fabric types suitable\nfor weather conditions that suit personal style.\n• Personalized CookBook: GPTs can serve as cooking\nassistants by recommending new curated recipes suiting\nthe family dietary plan, ingredients available, time, indi-\nvidual’s cooking skills, and new flavoured ingredients.\nChefGPT, PantryChef, and MacrosChef are some GPTs\nthat generate unique and delightful recipes [159]. Con-\nsequently, GPTs can assist in shopping list recommen-\ndations and the nutritional value of the recipe generated.\n• Hobby Curator : GPT assists an individual in identifying\none’s enjoyable leisure time activity by learning new\nskills [160]. Having a list of interests and ideas ready,\nthe GPT helps narrow down various options, instruc-\ntional videos to proceed, chatting and sharing with\nonline communities, and researching the cited hobby\nto explore more fun. Budget will also be an important\nfactor in this perspective, as learning new hobbies may\nrequire joining paid classes or courses. GPT provides\nstep-by-step instructions and guidelines to learn a new\nskill faster.\n• Dream Maker: GPTs with multimodal learning helps to\nsearch for a job based on one’s qualifications and ex-\nperience. In turn, it assists in preparing the job-specific\nresume, cover letters, training for the interviews (coding\nand technical queries), and grooming sessions and can\nredirect to the training place where knowledge can be\nacquired [161]. The futurist GPT models can assist in\nphase-by-phase questionnaires in the interview process\n3) Challenges\nThe recent version of the GPT uses both reinforcement and\nsupervised learning models so it can learn based on the inter-\naction with the user and can use existing data to derive per-\nsonalized decisions. In the context of lifestyle, GPTs offer the\nmost promising solution for almost all lifestyle influencers,\nbut the still challenging part is the trustworthiness of the data\nand copyright issues. Also, relying more on GPT as it solves\nall our problems may insipid human intelligence in upcoming\ngenerations. Though the GPT provides weight advice, it\ncan never be a substitute for the medical practitioner, as\nsome information can be misleading. Travel planning GPTs\nsometimes require users to update information in a specific\nformat and may have outdated databases. GPTs cannot access\nspecific job openings’ websites but can still provide insights\ninto acquiring them. At times, it can produce nonsensi-\ncal information [118]. Therefore, before adopting the GPT\nrecommendations fully, further instigation is recommended.\nFurthermore, developing a large multimodal learning model\nabiding huge and dynamic datasets will be costly.\n4) Summary\nGPT is a personalized assistant for improving an individual’s\nlifestyle from various prospective influencers. Generating\npersonalized recommendations alleviates an individual’s fear\nof survival in the digitized society. Individuals will be per-\nsonally trained to adapt to different cultural and technologi-\ncal shifts in the sustainable development of themselves and\nthe economy as a whole. On the other hand, more strin-\ngent recommendations may incur huge budget overruns and\nsometimes provoke the individual to misinterpret, leading\nto dreadful consequences. GPTs provide both positive and\nnegative recommendations based on the input fed. So, for the\neffective adoption of a GPT for lifestyle practices, adverse\ntraining and testing on extreme behaviours must be carried\nout. GPTs must be trained in the realistic and dynamic\nperception of individuals in real life.\nI. GAMING\n1) Introduction\nBefore the advent of technology and the gaming industry,\nentertainment was primarily centred around activities such\nas reading, listening to music, watching plays and movies,\nparticipating in sports and physical games, and socializing\nwith friends and family. People also engaged in traditional\nboard games and card games, which were often played in\ngroups and provided a fun and social way to pass the time.\nAfter technology stepped into the gaming industry, the way\ngames are created, and the experience it has given users have\ntransformed tremendously. Technology has enabled develop-\ners to create more immersive and engaging experiences for\nplayers. It has contributed in various ways, like improving\ngraphics, performance, online play, and mobile gaming. Im-\nproved GPUs and other technologies allow for more detailed\nand realistic graphics, making games more visually stunning.\nFaster processors and higher amounts of RAM allow for\nsmoother gameplay and faster loading times, reducing lag\nand improving overall performance. Technologies like AI,\nAR, and VR have created a new dimension of game develop-\nment and experience. Players can now immerse themselves in\ngaming worlds in a way that was not possible before. With the\nhelp of advanced AI techniques, game developers can create\nmore sophisticated and challenging opponents for players,\nas well as NPCs with more realistic behaviours. Technology\nhas greatly expanded the possibilities of gaming and enabled\ndevelopers to create more immersive, visually stunning, and\nengaging experiences for players.\n2) Impact of GPT in Gaming\nGPTs have the ability to contribute to all sectors, including\nthe gaming sector. GPT are not specifically designed for\ncreating and playing games, but they have the potential\nto improve the gaming experience by improving enhanced\n24 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\ndialogue and story telling, creating dynamic and personalized\ngaming worlds, generating more realistic and engaging char-\nacters [162], game content creation, chatbot development.\n• Chatbot development: GPTs have been used in gaming\nthrough the development of chatbots that use NLP to\ncommunicate with players [163]. Because it allows the\nchatbot to understand and respond to a wide range of\nuser inputs and queries related to the game. GPTs have\nbeen pre-trained on a large corpus of text data, which\nmakes them adept at NLP. It can understand and respond\nto user queries in a way that feels natural and intuitive. It\ncan also understand the context of a user’s query, which\nmeans they can provide relevant and useful responses\neven when the user’s query is ambiguous or incomplete.\nIt can also generate game-related content, such as de-\nscriptions of game characters or settings, that can help to\nenrich the user’s gaming experience. Furthermore, it can\nalso personalize the user’s experience by learning from\ntheir previous interactions with the chatbot and tailoring\nits responses accordingly.\n• Game content creation: GPTs are used in game design.\nThey are used to create game content such as levels,\nitems, and quests. If the game designer is working on\na new role-playing game, GPT can be used in creating\ncharacters to be used in the games. To generate new\ncharacter classes in the games, the developer has to\ngive inputs that contain information about the game\nenvironment, game settings, player abilities, and game\nplay mechanics. GPTs has the ability to analyze the\ntext and expectations given by the developer, and it can\ngenerate a list of potential character classes based on the\nexpectations given as text. The designer then refines the\nideas and chooses a more suitable character to develop\nfurther with unique abilities and game mechanics. The\nauthors in [164] have used GPT2 and GPT3 to pro-\ncedurally generate role-playing game with video game\ndescriptions. The resultant quest was evaluated by 349\nonline RPG players. The results concluded that one\nof the five quest descriptions was accepted for game\ndevelopment.\n• Analyze player’s ability and skill: GPTs can detect\nand analyze players’ abilities and skill levels and tailor\nthe game accordingly. This analysis helps in making\ndynamic modifications to the game environment based\non the player’s abilities and skill levels. This feature\nhelps achieve dynamic difficulty balancing. GPTs can\nalso assist in identifying the player’s intent. Thus, when\nplayers ascend to higher levels, it can assist in making\nthe games more challenging based on the player’s abili-\nties and skill levels in the previous levels\n• NPCs: NPC stands for \"Non-Player Character.\" In AI\ngames, NPCs refer to characters or entities in a game\nthat are not controlled by a player. NPCs can take on\na variety of roles within a game, such as enemies to\nfight, quest givers, merchants, or friendly characters that\nprovide helpful information. They are often controlled\nby AI algorithms that determine their behaviour and\nactions within the game world. GPTs are not specifically\ndesigned for creating NPCs, but they can be used to\ngenerate dialogue and other character interactions that\ncan be incorporated into NPCs. Additionally, It can be\nused to generate character backstories and personali-\nties, which can inform the development of NPCs. The\nauthors in [165] have trained and used GPT-2 for text\ngeneration of video games. They have trained GPT-2 on\na large corpus of video game quests and used a GPT\nmodel to generate the dialogue for quest-giver NPCs\nin role-playing games. The output has shown that GPT\ncan learn the structure and linguistic style of the games,\nand the quality of the content it has generated is high,\nmaking it a good alternative to writing new RPG quests\nby hand.\n3) Challenges\nGPTs are computationally expensive and require high com-\nputing resources to do their purpose. This means that imple-\nmenting them in a game would require powerful hardware\nand this could have an impact on the performance of the\ngames. Lack of training data: GPTs require large amounts\nof high-quality training data to be effective. In the gaming\nindustry, this could be difficult to obtain, as gaming data\nare likely to be fragmented and less structured than the\nkind of data used to train GPT models [131]. In addition,\nGPTs can perform content creation based on patterns they\nhave learned from their training data, which means that\nthey can be unpredictable. The content generated by GPT\nmay be nonsensical or inappropriate content to the game.\nIn the context of gaming, this lack of control could lead\nto undesirable or even offensive game content. GPTs can\ngenerate text based on user input, they can’t interact with the\ngame environment in the same way a human player can. This\nlimits their usefulness in gaming and may make them less\neffective than other AI technologies.\n4) Summary\nGPTs can transform the gaming industry by contributing\nto improved game dialogue creation, enhanced non-player\ncharacters, personalized gameplay, procedural content gen-\neration, chatbot generation, and analyzing players’ abilities.\nHowever, it also has potential challenges that are to be\naddressed, such as the need for high computing resources,\na lack of control over content creation, and restricted in-\nteraction with the game environment. In addition, the most\nimportant challenge in adopting a GPT model in gaming is\na lack of training data. If the challenges are addressed and\nthe gaming industry evolves with properly structured data to\ntrain a GPT model, then GPTs can revolutionize the field of\ngaming.\nJ. MARKETING\nVOLUME 4, 2016 25\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n1) Introduction\nTraditional marketing primarily relied on traditional media\nchannels, such as television, radio, newspapers, and mag-\nazines, to reach consumers. Companies used to develop\nmarketing campaigns based on demographic data, and mass\nmedia channels were used to broadcast these campaigns to\na broad audience. However, the advancements in technology\nhave brought about significant changes in the marketing in-\ndustry, and companies are increasingly integrating new mar-\nketing strategies evolved through technologies to reach and\nengage with customers. One of the significant transforma-\ntions has been the rise of digital marketing channels such as\nsocial media, search engines, Email, and mobile applications\nthat allow companies to target specific populations with pre-\ncision and provide real-time feedback on campaign perfor-\nmance, allowing for more effective and efficient marketing.\nTechnology has also given rise to marketing automation tools\nsuch as customer relationship management systems, chat-\nbots, and personalized email marketing, which have made\nmarketing more efficient and effective. Another significant\ntransformation has been the use of big data and analytics\nto better understand customer behaviour and preferences.\nThis has allowed companies to create more personalized and\ntargeted campaigns based on specific customer needs and\npreferences.\n2) Impact of GPT in Marketing\nThe marketing industry has evolved with various AI-powered\ntechniques. This revolution started in marketing by provid-\ning businesses with powerful tools for generating insights,\nautomating processes, and improving customer experiences.\nGPTs are also being used in marketing to generate engaging\nand personalized content. Some of the applications of GPT\nin marketing include content creation, customer service, and\npersonalized advertising.\n• Content creation: GPTs can contribute to marketing in\nvarious ways, such as by improving speed and efficiency\nin content creation, ensuring consistency and quality\nof content, generating personalized content, creating\nmultilingual content, and repurposing existing content.\nIt can be trained on a company’s existing marketing\nmaterials and customer data, allowing it to create new\ncontent, such as blog posts, social media updates, and\nproduct descriptions, in a fast and efficient manner.\nDespite its speed, it maintain high standards for quality\nand consistency. Moreover, GPTs [118] can generate\npersonalized content based on customer data, such as\nsearch history and past purchases. This helps create\ncontent that is relevant to the users’ desires, leading\nto better engagement and conversion rates. GPTs can\nalso generate content in various languages, allowing\nmarketers to expand their reach across regions. Copy.ai\n[166] has used GPT-3 to generate human-like text that is\noptimized for marketing purposes such as website copy,\nsocial media posts, advertisement copy, and email cam-\npaigns. This means that marketer personnel no longer\nfocus on content creation. Instead, they can spend pro-\nductive time improving the other aspects of marketing.\n• Customer service: GPTs can be trained on customer\nservice conversations and chat logs to generate more\nnatural responses, like humans. This can help business\npersonnel provide better customer service 24/7 and\nsave time and resources. It can be trained to generate\nautomated responses for frequently asked questions,\nproviding faster responses to customers and ensuring\nconsistency in the quality of replies. GPTs can also\nanalyze customers’ emotions and sentiments, enabling\nbusinesses to proactively address negative feedback.\nThis is particularly helpful in maintaining customers’\ntrust. The authors in [167] have used GPT-3 model for\nautomated drafting of responses for incoming mails.\nThey used it to understand the mail, and then soft-\nware engineering and business studies were used to\nunderstand the challenges encountered and finally, the\nresponse generated after a thorough understanding of\nthe context of the mail. The authors have concluded that\napplying GPT-3 to rationalize email communication is\nfeasible both technically and economically.\n• Personalized advertising: GPTs can generate personal-\nized content such as product descriptions, blog posts,\nand social media captions tailored to individual cus-\ntomers’ preferences and interests. This can help busi-\nnesses create content that resonates with their target\naudience, leading to higher engagement and conversion\nrates. By analyzing customer data, GPTs can segment\ncustomers according to their behaviour, interests, and\npreferences. As a result, businesses can tailor their\nmarketing campaigns to each segment and provide per-\nsonalized messaging and offers that are more likely to\nconnect with each customer group. The authors in [168]\nhave proposed a generative model to identify the name\nof the product from the product text and use this in-\nformation filter to improve the product recommendation\nbased on the product retrieval model. This method has\nbeen implemented in the dynamic product advertising\nsystem of Yahoo. It is observed that the recommenda-\ntion system has recommended the product based on the\nuser’s interest, and it was evaluated using an A/B test to\nserve similar products in an ad carousel, which can help\nthe system to explore more products efficiently.\n• Forecast analysis: Using customer data analysis, GPTs\ncan forecast future behaviour and buying patterns. This\nallows businesses to customize their marketing cam-\npaigns to each customer’s desires based on their pur-\nchase patterns, increasing the likelihood of conversion\nor purchase. The authors in [169] have used chatGPT to\nperform predictive modelling based on past data. They\nhave used the GPT model to predict the future based\non the customer’s behaviour and buying pattern. This\nprimarily helps the system to recommend the products\nto the customers as per their desires.\n26 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n3) Challenges\nGPTs are designed to generate content that imitates human\nwriting, but the content generated may not align with the\nbrand’s image or message. This lack of control can be a\npotential challenge for marketers. Another challenge that\napplies to all learning technologies is that data bias is possible\nin GPTs [138]. Based on the large dataset of text used for\ntraining, if the data is biased, it will affect the generated\ncontent, which may also exhibit the same biases. GPT is\ncomplex and difficult to interpret, making it challenging to\nexplain how the model arrived at its conclusions. This lack of\ntransparency can lead to a lack of trust in adopting GPTs,\nand marketing teams may struggle to make improvements\nin their strategies. As like every AI technology, there are\nethical concerns associated with GPT models. For instance,\nthe use of GPT in marketing could raise concerns about the\nuse of personal data and privacy, particularly if the model is\nused to generate targeted advertising or personalized content.\nTo avoid any negative consequences, companies must ensure\nthey use these models ethically and transparently.\n4) Summary\nUsing GPTs in marketing can provide various benefits, such\nas better content creation, personalized messaging, increased\nefficiency, competitive advantage, and enhanced customer\nexperience. However, this strategy also involves potential\nchallenges, such as limited control, data bias, lack of trans-\nparency, and ethical considerations. Therefore, companies\nmust consider the advantages and drawbacks of GPT adop-\ntion in marketing, and implement these models ethically\nand transparently to avoid negative outcomes. Successful\nintegration of GPTs in marketing requires proper planning,\na skilled workforce, and continuous monitoring to ensure the\ndesired results and mitigate any potential risks.\nK. FINANCE\n1) Introduction\nThe finance industry, also known as the financial sector, is a\nbroad term that encompasses a wide range of institutions and\nbusinesses that provide financial services to individuals, busi-\nnesses, and governments. The finance industry plays a critical\nrole in the global economy, facilitating the flow of funds\nbetween savers and investors, managing risk, and providing\nfinancial services and products to support economic growth.\nThe finance industry has been the leader in technology adop-\ntion in recent years, with a focus on improving efficiency,\nreducing costs, and delivering better customer experiences.\nThe adoption of technologies like big data and analytics,\nmobile and digital payments, blockchain and distributed\nledger technology, AI and ML, and cloud computing make\nthe sector more flexible, scalable, trustworthy, transparent,\nsecured, and easier to access.\n2) Impact of GPT in Finance\nGPT has greatly influenced finance by automating customer\nsupport using chatbots and virtual assistants, enhancing fraud\ndetection, offering investment insights and recommendations\nbased on financial data and news, assisting with risk as-\nsessment for investments and loans, impacting algorithmic\ntrading strategies, simplifying compliance with regulations\nby analyzing legal documents, improving credit scoring and\nloan processes, and emphasizing the importance of handling\nsensitive financial data securely and transparently.\n• Sentiment analysis: Sentiment analysis is a technique\nused in the finance industry to evaluate the sentiment of\ninvestors [170] and the general public towards specific\ncompanies, industries, or markets by analyzing news\narticles, social media posts, and other text-based sources\nof information. GPT has the potential to improve senti-\nment analysis in finance by providing more accurate and\ndetailed analyses of financial data. With sentiment anal-\nysis, the industry can predict stock prices by assessing\nthe sentiment of news articles, social media posts, and\nother sources of information about a particular company\nor industry to make informed investment decisions.\nBy utilizing sentiment analysis, GPTs can aid finan-\ncial institutions in identifying potential risks and taking\nappropriate action to mitigate them. The authors in\n[171] have investigated how incorporating a lexicalized\nontology can enhance the performance of aspect-based\nsentiment analysis by extracting indirect relationships in\nuser social data. The investigation results show that the\nanalysis has given 98% accuracy.\n• Financial forecasting: GPTs can be trained on past\nfinancial market data to predict future trends in the\nstock market, exchange rates, and other financial met-\nrics. This can help investors and financial organizations\nmake more accurate predictions and reduce their risk\nexposure. With the ability to analyze and process the\nnatural language, GPTs can be used to analyze and\ninterpret financial data, news, and other related infor-\nmation. Financial analysts and researchers can use the\nability to analyze natural language to extract insights\nfrom unstructured data like news articles, social media\ncontent, and other information that is relevant to fore-\ncasting. This can help improve the accuracy of financial\nforecasting models by providing a more comprehensive\nview of market trends and sentiments. This analysis\nmay help improve the accuracy of prediction. Financial\nanalysts can use the model to identify the relationship\nbetween the financial parameters that could change the\nmarket conditions in advance. This prediction may be\nhelpful for investors as they make investment decisions.\n• Trading strategies: GPTs can also be used to analyze\nmarket trends and historical data to develop trading\nstrategies. This can help traders make better decisions\nin terms of trading to increase their profitability. GPTs\ncan be used to identify the potential risks in trading\nportfolios. By analyzing the large volume of informa-\ntion related to trading, GPT will get the potential to\nidentify the risk parameters and provide insights into\nVOLUME 4, 2016 27\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nhow to mitigate these risks. The authors in [172] have\nused a popular GPT for stock market trend prediction.\nThe results show that the method used is simple but the\nefficiency and accuracy of the method are very effective.\nThe prediction it has made is very close to the reality.\n• Risk prediction and management:The adoption of GPT\ncan enhance the process of risk prediction and manage-\nment in several ways. It can improve data analysis by\ndetecting patterns that may pose a risk. It can also help\nin enhancing fraud detection by analyzing transaction\ndata and identifying fraudulent activity based on pat-\nterns. Additionally, GPT can be utilized to make better\nportfolio management decisions by analyzing historical\nindustry data, company financial statements, and news\narticles, as well as social media feeds. This portfolio\nmanagement process can provide valuable information\nabout the investment risk of a given organization, en-\nabling informed investment decisions and effective risk\nmanagement.\n3) Challenges\nGPTs have more challenges in the finance sector. Primarily,\nthey demand significant computational resources to train and\ndeploy, which can be expensive and time-consuming for\nfinancial organizations to implement. Another challenge is\nthat, even though GPTs are capable of producing precise\npredictions, they can be challenging to interpret, which can\npresent a problem for financial institutions seeking to com-\nprehend the reasoning behind specific predictions [173]. This\nlack of interpretability can harm risk management objec-\ntives.Implementing GPT in finance sector can be vulnerable\nto adversarial attacks, which are designed to manipulate the\nmodel’s output by injecting false data. This can be particu-\nlarly problematic for financial institutions that rely on GPTs\nfor risk management and investment decisions. It also require\nlarge amounts of training data to achieve high accuracy.\nHowever, in some cases, financial institutions may not have\naccess to sufficient data to train the model effectively. GPTs\ncan also be biased if the training data used to develop the\nmodel is biased. This can lead to inaccurate predictions and\nunintended consequences.\n4) Summary\nThe use of GPTs in the finance industry has promising ben-\nefits such as improved risk management, enhanced fraud de-\ntection, better portfolio management decisions, and increased\nefficiency. However, it also has potential challenges that need\nto be addressed, such as high computational requirements,\nthe complexity of implementation, limited interpretability,\nvulnerability to adversarial attacks, limited training data, and\nbias in training data. So, the use of GPTs in the finance\nindustry presents significant benefits but also requires careful\nconsideration of the challenges involved to ensure the effec-\ntive and secure deployment of these models.\nL. SUMMARY ON IMPACT OF GPT MODELS IN\nAPPLICATIONS\nThe impact of GPTs in various applications and challenges\nwas highlighted. GPT with its varied usage has changed the\nway people perceive facts such as content creation, enhanced\nuser interfaces, personalized learning, item tracking, self-\nawareness, market risk analysis, business forecasts and in-\ntrospection. However, there are concerns about the potential\nnegative impact of GPTs, such as the spread of fake news,\nbias in data and decision-making, not domain specific, ethical\nissues, data reliability, the complexity of implementation,\nmultimodal and multilingual support, security and privacy\nconcerns, vulnerable to data attacks, limited input data, ex-\nplainability of results, large model size, high computational\nrequirements and job loss. Despite these concerns, it is clear\nthat GPTs will continue to be a powerful tool for industries\nseeking to leverage the power of NLP and generative AI. As\nthe technology improves and new applications emerge, it will\nbe interesting to see how GPTs continue to shape the future\nof industries around the world.\nV. PROJECTS\nThis section presents the exciting projects developed us-\ning GPT model technologies for the applications mentioned\nabove. Table. 4, Table. 5 shows the different levels of such\nprojects along with different parameters to compare their\ncharacteristics leveraging the capabilities in many real-life\napplications.\nA. SIRIGPT\nSiri [174] is a smart digital assistant that allows Apple device\nusers to complete tasks in a more efficient manner, and\noften anticipates their needs before making any requests.\nSiriGPT [175] [176] is a voice-enabled assistant enabled by a\nGPT model and completely developed using shortcuts. Apple\ndevice users can use ChatGPT with an API key provided by\nOpenAI. This novel fusion offers the best of both realms,\nallowing users to use SiriGPT for voice commands and Chat-\nGPT to generate text. SiriGPT uses an optimized tokenizer,\ndeveloped by Apple, for processing natural language tasks.\nIt is to be noted that SiriGPT’s training data is not publicly\navailable because it is exclusive to Apple. However, it is\nfound that the language model is trained on distinct text\ndata from different sources such as books, news articles,\nweb pages, and other text sources. As a result, SiriGPT can\nperform various natural language tasks more accurately and\nefficiently. SiriGPT is one of the largest language models\navailable, with an immense number of parameters.\nB. AI DUNGEON\nAI Dungeon is a revolutionary online game developed by\nLatitude, which is a startup based in Utah [177]. It presented\na novel collaboration between humans and machines. This\ntop-rated adventure game is free-to-play, having both single-\nplayer and multiplayer options. It blends fantasy elements\nwith cutting-edge AI to create limitless possibilities. For\n28 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nTABLE 4: Project Summary Table.\nProject DeepScribe Meena Jukebox Uber’s plato research dialogue systemPolyglot AI SiriGPTApplicationwidely used forHealthcare Lifestyle Entertainment Transport Education Lifestyle\nPurpose Medical documentationand to improve doctor-patient association\nPersonalized product rec-ommendation Enables the original mu-sic creation both artisti-cally compelling and com-mercially viable in a vari-ety of styles and genres\nEnhances user experience using Uberrides, helps drivers and riders inscheduling rides, navigating routes, pro-viding real-time updates on traffic andweather conditions.\nenables absolute communication irre-spective of the language barrier acrossdifferent regions and cross-culturalism\nAssist with voice-based assistants\nGPT AdoptionCustomized version ofGPT’s Google’s seq2seqtransformer-based neuralnetwork architecturesimilar to Open AI’s GPT\nGPT-2 extensioncalled \"Multi-ScaleTransformers for MusicModeling\" (MST) model\nGPT-2 GPT-0, GPT-1,GPT-2,GPT-3GPT-3\nDataset Not Disclosed Meena dataset over 40 bil-lion words , 341 GB cap-tured from public domainslike Reddit and social me-dia platforms\n1.2 million songs, 600,000pieces of sheet music,45,000 MIDI files\nPersona-Chat with 160,000 conversa-tional dialogues, Cornell Movie-DialogsCorpus with 200,000 movie conver-sation, DailyDialog over 13,000 dia-logues, and\nCONLL-2003, Sentiment140 dataset,Reuters Corpus, 20 Newsgroups dataset,WMT (Workshop on Machine Trans-lation) datasets and SQuAD (StanfordQuestion Answering Dataset)\nInformation not publisized\nBuilding BlocksRecurrent Neural Networkand Attention mechanismfueled by NLP techniques\nSeq2Seq Transformer-based Architecture Transformer-basedLanguage Model andAutoregressive model\nLanguage modeling, Dialogue model-ing, Discrete latent variabe modelingand response ranking\nLanguage Identification, Named EntityRecognition (NER), Sentiment Analy-sis, Text Classification, Machine Trans-lation, Question Answering\nTransformer-based neural network ar-chitecture\nEvaluation Met-rics Bleu score, perplexityBleu score, perplexityFrechet Audio Distance(FAD) and Pitch andRhythm Similarity\nBleu score, Perplexity and Distinct n-gram accuracy, precision, recall, , F1-score,Bleu score as well as cross-entropy lossor perplexity\nPerplexity, BLEU score, F1 score,ROUGE score, Human evaluation\nAddressed Chal-lenges Reduced Transcription er-rors and enhanced patientcare\nNatural and Engaging con-versations Fresh orginical musiccontent creation anddrastically reducingthe cost and time bycreating high-qualitymusic contents, and alsoto preserve and advancemusical heritage.\ncustomer service, user experience, andoperational efficiency Multilingualism and Sentiment Analy-sis are the key challenges in NLP andPolyglot AI solved this problem by of-fering a tool for supporting morethan40 languages and pre-trained sentimentanalysis model\nLanguage understanding and genera-tion, Data scarcity, Contextual under-standing, Text summarization, Senti-ment analysis, Named entity recognition\nInput data Audio Text Audio Text Text AudioOwned By DeepScribe Google OpenAI Uber Uizard Technologies Apple\nTABLE 5: Project Summary Table (continued).\nProject AI Dungeon Copy.ai Bond AI Viable AI Channels Fireflies.aiApplicationwidely used forGaming Business and marketingFinance Business Analytics AI Industry Business\nPurpose Interactive and engagingstorytelling experience forplayers\nhelp clients create writtencontent more quickly andeasily\nTo enhance the financialwell-being of clientsprovide businesses with intelligent in-sights to help them make better deci-sions\nprovide a platform for developers, datascientists, and machine learning prac-titioners to create, deploy, and managetheir AI models\nto simplify the meeting process and re-duce the time and energy required fornote-taking and collaboration\nGPT AdoptionGPT-3 GPT-3 GPT-3 GPT-4 GPT-3 GPT-4Dataset Common Crawl, OpenAIGPT-2, and various textdatasets from Kaggle\nbooks, articles, and web-sites likely use of a combina-tion of publicly availablefinancial datasets, propri-etary data, and client data\nInformation not publisized Users’ own dataset Possible datasets: the Common V oicedataset from Mozilla having over 9,000hours of speech data in multiple lan-guagesBuilding BlocksMachine LearningModels, Text InputInterface, Game Engine,Content Database, PlayerFeedback System, CloudInfrastructure\nNLP, Language Models,Neural Networks NLP, Personalization,Conversational UserInterface, Data Analytics\nUnsupervised learning, Contextual un-derstanding, Sentiment analysis, Topicmodeling, Entity recognition\nPre-built models, Model training, Datapreparation, Collaboration Speech-to-Text Technology, NLP,Cloud Computing, Integrationtechnologies\nEvaluation Met-rics Response Coherence, Re-sponse Diversity, PlayerSatisfaction, Engagement,Realism, Novelty\nPerplexity, BLEU score,ROUGE score, F1 scoreIntent recognitionaccuracy, entity extractionaccuracy, and languagemodel perplexity\nPerplexity, Accuracy, F1 score, Wordsimilarity Accuracy, Precision and Recall, F1Score, Perplexity, User satisfactionSpeech Recognition Accuracy, NLPPerformance, Integration Performance,Task Completion Time, User Satisfac-tionAddressed Chal-lenges Narrative Generation,Content Creation,Personalization,Replayability,Accessibility, CreativeExpression\nLack of writing skills, In-consistency, Multilingualcontent creation\nPersonal financialmanagement, Customerengagement, Frauddetection and prevention\nUnderstanding unstructured data, Con-textual understanding, Visualization andexploration of data, Customization andintegration\nNatural language understanding, Scala-bility, Personalization, Integration withother systems, Maintenance and updates\nTime-consuming manual note-taking,Difficulty in capturing important details,Lack of visibility and accountability,Communication barriers\nInput data Text Text Audio and Text Text Text AudioOwned By Latitude Copy.ai Bond.AI Viable AI MiroMind AG Fireflies AI\ninstance, an individual can immerse himself in commanding\na military operation against aliens or become a renowned\ndetective investing assassination attempts on the queen of the\nfairies. Unlike traditional games with predetermined story-\nlines, this game allows users to generate unique characters\nand scenarios to interact with their characters. The game\nincorporated the GPT-3 text generator. However, it was found\nto generate unsettling narratives later on. [178].\nC. COPY.AI\nCopy.ai [179] is a renowned AI startup that was founded\nby Paul Yacoubian in 2020. Powered by GPT-3, this project\nmainly focuses on business and marketing campaigns. It\ncaters to the following use cases: (i) It assists teams in\ncreating customized sales copy, drafting extensive articles\nand pages on a bigger scale, reusing content on distinct\nplatforms, and generating product descriptions; (ii) The AI-\npowered email writer tackles the most challenging aspects\nof marketing by producing highly effective email campaigns\nthat efficiently convert leads; (iii) By creating outlines for\ncontent and crafting unique SEO-optimized blog articles\nevery month, businesses can save a significant amount of\nmoney. Moreover, it’s possible to create basic structures,\noutlines, and initial drafts in just a few minutes. This can be\nan excellent source of inspiration for writers to produce high-\nquality content; (iv) Copy.ai is a helpful tool that can quickly\nand efficiently generate social media posts. This allows rapid\nexpansion of the social media following. Moreover, it in-\ncludes various other tools, such as a headline analyzer, a\nlanguage translator, and a content rephraser.\nD. BOND.AI\nBond.AI [180] is a company that is focused on AI for\nfinancial institutions having its headquarters in Little Rock,\nArkansas. It was established by Uday Akkarajuin in 2016.\nThis innovative project offers a product, BondBot, powered\nby Empathy Engine 3.0 and ChatGPT for improving clients’\nfinancial health. It assists financial institutions and employers\nVOLUME 4, 2016 29\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nin promoting a connected financial ecosystem by providing\nvarious tools that enhance the institution’s profitability and\nclients financial well-being of its clients within a single net-\nwork. It uses customer data to generate personalized profiles\nfor each bank customer or small business by considering\ntheir behaviors, strengths, and potential requirements. This\napproach allows the platform to create tailored strategies to\nimprove clients’ financial health holistically.\nE. VIABLE\nViable [181] is a platform driven by GPT-4 that utilizes\ncutting-edge advancements in NLP and AI to provide busi-\nnesses with intelligent insights to assist in their decision-\nmaking procedures. Viable can assist companies in extracting\nactionable insights from unstructured data sources, such as\nsocial media posts, customer reviews, and survey responses.\nGPT plays a vital role in understanding the sentiment and\ncontext within the data, leading to valuable insights that\ncan greatly improve a company’s services, products, and\ncustomer satisfaction. Viable’s \"Insight Explorer\" is a unique\nfeature that enables users to interact with and visualize\ntheir data via an intuitive interface. Moreover, the platform\npresents advanced analytics features such as entity recogni-\ntion, topic modeling, and sentiment analysis. The GPT-based\ntechnology of Viable is continually growing, which provides\nthe platform to deliver more precise and insightful data.\nFurthermore, Viable provides customized integration and\nsolutions to address the unique requirements of individual\nbusinesses.\nF. AI CHANNELS\nAI Channels [182] is a platform that provides a compre-\nhensive set of tools for developers, ML experts, and data\nscientists to develop, launch, and efficiently manage their AI\nmodels. The platform offers a complete solution for creating\npersonalized AI models, from data preparation and model\ntraining to deployment and monitoring. Users can train their\nmodels using their own data or pre-trained models provided\nby AI Channels. These models can be deployed as APIs or\nDocker containers on different infrastructures, such as differ-\nent cloud platforms. Moreover, it provides a dashboard for\nmonitoring model performance and handling configurations.\nIt caters to a wide range of applications, such as computer\nvision, NLP, and speech recognition. In addition, it includes\nbuilt-in models designed for different tasks, such as image\nand text classification, object detection, and sentiment anal-\nysis. Furthermore, users can build their own models using\npopular frameworks. This platform’s primary objective is to\ndevelop and launch AI models for developers and businesses\nwithout having specialized AI skills.\nG. FIREFLIES.AI\nFireflies AI [183] is a California-based company that was\nfounded by Krish Ramineni and Sam Udotong. Fireflies AI\nsoftware is designed to ease meetings by offering unique\nfeatures of taking notes and collaborating. To save time\nand effort, the tasks are automated by employing GPT-4\ntechnology. Fireflies can be used with various video confer-\nencing platforms, such as Zoom, Google Meet, and Microsoft\nTeams. Moreover, it can transcribe meeting audio and video\ncontent in real-time. Its unique speech-to-text technology\ncan generate a searchable transcript of the meeting, which\ncan be used for later review and to recall key details along\nwith proposed actions. Additionally, the software employs\nNLP capabilities to identify important keywords and phrases\nwithin a conversation. Furthermore, it includes collaboration\ntools for task assignments and note-sharing notes. It can\nbe integrated with project management and task monitoring\ntools to automatically create tasks based on the identified\naction items discussed during the meeting. The software\ncan be configured to automatically join specific meetings or\ncapture audio only from particular speakers. It allows users\nto choose specific words and phrases to highlight in the\ntranscript, which helps them easily identify important points\nduring the later review. Thus, Fireflies AI aims at simplifying\nthe meeting process and save the time and energy required\nfor note-taking and collaboration.\nH. UBER’S PLATO RESEARCH DIALOGUE SYSTEM\nUber’s AI Lab introduced Uber’s Plato Research Dialogue\nSystem in 2020 developed by a team of researchers and\nengineers to enable intelligence in the riding experience.\nPLATO - Pre-trained Dialogue Generation Model with Dis-\ncrete Latent Variable [184]. Uber’s Plato Research Dialogue\nSystem uses GPT-2, a large-scale language model devel-\noped by OpenAI in 2019. Uber’s Plato Research Dialogue\nSystem project used several datasets to train and evaluate\ntheir conversational agents, such as Persona-Chat contains\n160,000 conversational dialogues, Cornell Movie-Dialogs\nCorpus, with 200,000 movie conversations, DailyDialog over\n13,000 dialogues, and EmpatheticDialogues over 25,000 user\ndialogues. The main components in developing the GPT-\npowered PLATO project are language modelling, dialogue\nmodelling, discrete latent variable modelling and response\nranking. The Plato Research Dialogue System was trained on\na massive corpus of text data consisting of over 40 GB of un-\ncompressed text while Bleu score, Perplexity and Distinct n-\ngram are the evaluation metrics used for training and testing\nthe PLATO project. Uber’s AI PLATO has addressed many\nkey challenges like customer service by personalizing user\nfeedback with conversational AI agent, user experience using\nthe Uber platform for scheduling rides, navigating routes,\nand providing real-time updates, and increasing operational\nefficiency by reducing the need for human customer service\nrepresentatives and enabling faster and more accurate com-\nmunication between riders, drivers, and the Uber app.\nI. JUKEBOX\nJukebox, a GPT-powered music creation, was developed in\n2020 as an extension of Open AI’s GPT language model\n[185]. Jukebox’s goal is to push the boundaries of what\nAI can accomplish in the world of music creation and to\n30 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\ninvestigate fresh applications for AI. A variation of the GPT\narchitecture, the \"Multi-Scale Transformers for Music Mod-\neling\" (MST) model, was created specifically to handle the\nintricate and multi-scale nature of musical data. Additionally,\nJukebox can produce lyrics that match the music’s tone and\nstyle. A sizable and varied dataset of musical recordings,\nlyrics, and related metadata was used to train Jukebox such\nas 1.2 million songs sourced including Lakh MIDI Dataset,\nFree Music Archive, Spotify and Tidal, 600,000 pieces of\nsheet music were sourced from IMSLP (International Music\nScore Library Project), and 45,000 MIDI files from Lakh\nMIDI Dataset and the MIDIworld collection. Faster training\ntimes and more effective use of computational resources were\nmade possible by the distributed computing setup with 2048\nTPU( Tensor Processing Unit) cores used to train the Jukebox\nmodel. Training the model required significant computational\nresources demanding faster training times by the distributed\ncomputing setup with 2048 TPU (Tensor Processing Unit)\ncores used to train the Jukebox model. A combination of\nsubjective and objective metrics was used to assess and test\nJukebox. In a large-scale subjective assessment, more than\n1,000 participants listened and rated each one individually\ndetermining the overall score for each song produced. On\nthe other side, objective assessments were conducted by\nevaluating Frechet Audio Distance (FAD) and Pitch and\nRhythm Similarity. Overall, Jukebox revolutionizes with its\nsignificant advancement in the music industry through cre-\native inspiration, music production, music education and\npreservation of music heritage.\nJ. MEENA\nGoogle’s Meena project was developed by Google Research\nTeam in 2020 for providing personalized product recom-\nmendations [186]. The primary goals of the Meena project\nempowered the lifestyle sector to enhance the user experience\nand customer service by recommending goods and services\non a personalized basis. The project designed a GPT using\nthe seq2seq transformer-based neural network architecture,\nin particular for open-domain conversational agents. The\narchitecture was pre-trained over 341 GB of text captured\nfrom Reddit and other social platforms containing over 40\nmillion words and called this massive collection as ’Meena\nDataset’. Meena was tested using the automated performance\nmetrics known as Bleu score and perplexity on a cluster of\nHPC nodes with a total of 2048 NVIDIA V100 GPUs. One\nof the biggest challenges solved Meena was building trust\nand generating reliable engaging human-like conservation\nthat typically enhances user satisfaction and personalization.\nMeena has achieved state-of-the-art performance compared\nto other open-domain chatbots and revolutionized the wide\nrange of applications in the lifestyle industry and a way\nbeyond by providing natural and engaging responses through\nvirtual assistants, customer service bots and personal shop-\npers.\nK. DEEPSCRIBE\nDeepScribe was a GPT-based medical project developed\nin 2019 by the student team at the University of Califor-\nnia by partnering with giant US-based healthcare providers\nsuch as One Medical, Stanford Medicine, Mount Sinai and\nSutter Health [187]. The DeepScribe’s technology aims at\ntranscribing medical conversation allowing doctors to treat\nthe patients rather than noting down the patient’s history,\nenhancing the doctor-patient relationship and targeting the\noverall quality of patient care. Although DeepScribe used\nthe customized variants of Open AI, the technical details\nof the GPT model used for customizing the model were\nnot disclosed which was optimized for medical transcription\ntasks.\nL. POLYGLOT AI\nPolyglot AI is a communication platform designed to gener-\nate text in multiple languages and process the data by per-\nforming several tasks such as advanced NLP techniques, text\ntranslation, and sentiment analysis. The potential features of\nPolyglot AI have been exploited in the following applica-\ntion areas such as language translation, chatbots, language\nlearning tools, content creation, customer support, and data\nanalysis across different languages and regions. Polyglot AI\nis built based on different variants of GPT models, and state-\nof-the-art language model architecture for NLP tasks, which\nuses the self-supervised learning approach.\nThe Polyglot AI was pre-trained using a large amount\nof textual data on multiple languages simultaneously in\nan unsupervised environment using a shared architecture,\nMultilingual Universal Sentence Encoder (MUSE). MUSE\ndeveloped by Google, is a pre-trained DL model used for\ncross-lingual TL, that encodes the text into common vector\nspace for multiple languages. Thus, the Polyglot language\nmodel was created with the following pre-training techniques\nas Masked Language Modeling (MLM), Translation Model-\ning Language (TML), sequence-to-sequence modelling and\ncross-lingual TL. The pre-trained language model is fine-\ntuned and evaluated by standard benchmarks and metrics\nsuch as the BLEU score (Bilingual Evaluation Understudy),\nMETEOR (Metric for Evaluation of Translation with Explicit\nORdering) or F1-score. Remarkably, Facebook used new\nPolyglot AI to translate between 100 languages [188]. Thus\nPolyglot AI enables absolute communication irrespective\nof the language barrier across different regions and cross-\nculturalism.\nThus, this section focused on several exciting real-life\nprojects which are developed and used for humankind. These\nprojects were discussed by presenting Table ?? highlighting\nthe details of the project with model architecture, datasets\nused, training and testing, and evaluation metrics involved\nwith the challenges addressed. The next section will discuss\nthe open research issues and future directions for the potential\nbenefits of GPT models.\nVOLUME 4, 2016 31\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVI. OPEN RESEARCH ISSUES AND FUTURE\nDIRECTIONS\nThis section highlights the various open research issues con-\ncerned with the implementation and adoption of sustainable\nGPT models. It also provides insights into future research\ndirections for the betterment of researchers in the field of\nGPT development. Fig. 9 outlines the many issues that can\ndevelop while using GPT models, as well as the various\nfuture approaches that need to be considered for the effective\nusage of GPT models.\nA. DOMAIN SPECIFIC GPT MODELS\nDomain-specific GPT models are mandated in almost all\napplications; developing these models is still challenging and\nan open issue within GPT. While the current GPT models\nhave been developed to understand natural language and\ngenerate content effectively, their performance may not be\nequally effective when handling specific domains, such as\nmedicine, agriculture, etc. One of the key challenges in\nadapting to a particular domain is the availability of domain-\nspecific data. It is well known that the performance of GPTs\nis directly proportional to the quality and quantity of data\nused for training the model. So, obtaining such quality data\nfor a specific domain is expensive and time-consuming, as the\ndata are heterogeneous. Also, these data accumulations may\neven make these models much larger, sometimes catastrophic\ntoo, leading to forgetting the knowledge attained during\nthe process. To overcome this issue, pre-training tasks and\ndomain-specific model generation are integrated by data aug-\nmentation [189]. Another challenge is fine-tuning the model\nto accustom to the unique characteristics and vocabulary\nof the domain. A few domain-specific GPT models have\nbeen developed and implemented despite these challenges.\nThere is a growing interest in creating more domain-specific\nGPTs for various domains. Moreover, these models will be\ntrained using the knowledge acquired from large language\nmodels specific to domains. Therefore, these models can be\nfine-tuned for specific tasks or domain-specific requirements\nwith gradually improving performance. GPT models have\nthe potential to be trained in any context, and researchers\nare exploring new approaches and methods to address these\nchallenges. Furthermore, these models will be more efficient,\nenhanced interpretability, and domain generability than the\nexisting Large language models as they are customized to\nspecific domain concerns and can provide more concise\nand informative solutions. TL can be used for developing\ndomain-specific GPT models. Domain-specific GPT models\nwere developed to summarize products based on customer\nreviews on an E-commerce site, where the language model\nis pre-trained on the Chinese-short summarization dataset\nand has obtained fine-tuned results [130]. Besides these chal-\nlenges, domain-specific models require higher computation\ncosts for the resources and time spent in pre-training and\nrelearning in downstream tasks during fine-tuning of pre-\ntrained domain-specific models. Therefore, domain-specific\nmodel development must focus on optimizing resource con-\nsumption and fine-tuning the pre-trained model to alleviate\nthe forgetting problem involved in existing models.\nB. HIGH COMPUTATIONAL REQUIREMENTS\nAs the Transformer model utilizes varied heterogeneous\ndatasets for training and learning from the knowledge ac-\nquired, one of the key challenges of GPT models is high\ncomputational resources for pre-training and inference. The\ncomputational requirement continuously increases as the\nmodels become more complex and larger. Depending on the\nsize and complexity of the model and the available resources,\nthe time required to train the model can take days, weeks, or\neven months. Moreover, the inference time for these models\nis typically slower, making it challenging to use them for\nreal-time applications. This poses a significant obstacle to\nadopting GPT models for many practical applications. De-\nspite these challenges, significant efforts are underway to\novercome them. To accommodate the increasing data size and\npre-training computational requirement, data enhancement-\nbased GPT models were developed [189] by joining the\ndownstream tasks and pertaining process by reconstructing\nthe domain-specific text before proceeding for pre-training\nand utilizing the empirical knowledge rather than learning for\nfalsy domain data. Researchers are exploring various ways\nto optimize and speed up the training and inference process,\nsuch as using specialized GPUs and TPUs. They are also de-\nveloping more efficient algorithms and attempting to reduce\nthe model size without sacrificing performance. In addition,\nChatGPT has evolved to include plugins [190] that enable\nstatistical analysis for real-time applications. By integrating\nthese plugins with the help of third-party services, ChatGPT\ncan now be used for analyzing real-time applications as well.\n1) Increasing Model size and Space Constraints\nDeveloping and training large language models, such as a\nGPT model, can be a challenging task due to significant\ntechnical and computational difficulties as discussed. The\nsize of GPT models presents a major challenge, as the\ncomputational resources required for training and inference\nincrease with the number of parameters that need to be\ntrained. As the model size increases, it also requires more\nmemory to store and manipulate parameters during training\nand inference [75]. Acquiring and processing vast amounts\nof high-quality training data is another challenge in training\nlarge language models like GPT. For instance, GPT-4, which\nis the largest GPT model to date with 1 trillion parameters,\ndemands a massive amount of computational resources, such\nas specialized hardware like GPUs and TPUs, spatial re-\nquirements, and high-speed network connections to transfer\ndata between different parts of the system. Model evaluation\nand interpretation are also critical challenges. Since large\nlanguage models like GPT are trained on a massive scale,\nunderstanding how the model makes predictions and why it\ngenerates specific outputs is difficult. Evaluating the quality\nand accuracy of the model’s output and identifying and\n32 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nFIGURE 9: Challenges and Future Directions.\naddressing biases or errors in its performance can also be\nchallenging.\nAs these and other significant efforts continue, we can\nexpect the challenge of computational resource requirements\nfor GPT models to transform into a strength in the future.\nC. EXPLAINABILITY AND INTERPRETABILITY\nExplainability and interpretability are currently major chal-\nlenges for GPTs for specific applications. Explainability\nrefers to providing a clear and understandable explanation of\nhow the model has arrived at any output. Interpretability, on\nthe other hand, refers to the ability to understand the internal\nprocesses of the model. GPT models are highly complex\nand difficult to understand and interpret due to their size\nand architecture. The outcomes and decisions of the model\nare based on previous learning and training, and the models\nlearn from vast amounts of data to make decisions. These\ndecisions may not be easily explainable to humans. This lack\nof transparency and interpretability raises concerns about the\nreliability and safety of the model, particularly in critical\napplications such as healthcare and finance. Researchers are\ncurrently conducting much research to make GPT models\nmore explainable and interpretable [191] by utilizing EX-\nplainable Artificial Intelligence (XAI) to provide explana-\ntions for the decisions arrived at, specifically to different\nusers at stake. As well, XAI models enable interpretability\nby providing detailed explanations for the internal process.\nAs GPT can generate any type of unconstrained output for\ninstance code generation for the given problem, it requires\nproper justifications and explanations for the output. So, to\nassure these codes by GPT are reliable, a metric model to\nevaluate and validate this GPT code was developed using\nNLP metrics and XAI for model interpretability [192]. Also,\nsome domain-specific GPT models of GPT-3 have evolved\nwith solutions [193] [194] to ensure that the GPT model’s\ndecisions are understandable, explainable, and trustworthy\nenough to be used for critical applications like healthcare and\nfinance.\nD. DATA BIAS\nData bias is an open issue concerned with the adoption of any\nadvancements in AI, till GPT [195]. This is also a prominent\nchallenge for GPT and other machine-learning models. It\nrefers to patterns or relationships in the data that do not\naccurately reflect the true distribution of the target population\nor domain. GPT models are trained on vast amounts of text\ndata which may contain bias in language use or cultural as-\nsumptions. Still, the source of data remains undeclared, con-\nVOLUME 4, 2016 33\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nsidering GPTs are trained using internet data which may have\nfaulty, fake, and error data, GPTs may generate biased texts\nor information imitating the training data [196]. Such biases\ncan be amplified in the model’s output, resulting in false or\nunfair results. Data bias can arise from various sources, such\nas selection bias, labelling bias, concept drift, confounding\nvariables, and changes in input data distribution over time.\nFor example, suppose a dataset used to train a GPT model is\ndominated by a particular demographic group. In that case,\nthe resulting model may be biased in its predictions towards\nthat group, leading to inaccurate or unfair predictions when\napplied to new data. This bias can have serious consequences,\nespecially in healthcare, finance, and law enforcement, where\nbiased results can significantly impact human lives. To miti-\ngate these issues, researchers have developed strategies such\nas diversifying the training data, debiasing the training data,\nmodifying the model architecture, and using post-processing\nmethods to normalize the data and create more fair and\ninclusive GPT models. The authors in [197] have made an\nin-depth analysis of the most downloaded text generation\nmodel GPT2. By examining the intersections of gender with\nreligion, sexuality, ethnicity, political affiliation, and conti-\nnental name origin, the authors evaluated prejudices associ-\nated with occupational associations among various protected\ncategories. These biases may have inaccuracies in climatic\ndata prediction or global warming [198]. Therefore, data bias\nmust be of greater concern in GPT model development as the\ndata quality of the internet is limited to avoiding producing\ndisturbing content.\nE. MULTIMODAL SUPPORT\nThe challenge of developing multimodal learning ability in\nthe GPT model remains unsolved. Multimodal support refers\nto the GPT model’s ability to process and generate text along\nwith other modalities, such as audio, images, and videos.\nGPT models have shown impressive results in generating\nhigh-quality text and NLP tasks, but it was primarily de-\nsigned for text-based tasks and cannot handle other modal-\nities. However, due to its success in text processing, users\nexpect its integration with other modalities, such as speech\nrecognition, video summarization, and image or video cap-\ntioning [199]. Several research initiatives have been proposed\nto integrate multimodal support to address this issue. One\napproach is to feed the visual and audio information with the\ncorresponding text to the model as input. The other is to han-\ndle this input modality process as a separate model and use\nthe output as input to GPT. Multimodal video captioning is\ndone using GPT in the unlabelled videos [199]. Multimodel\nlearning has been applied for information retrieval [200] and\nimage generation for illustrating the news [201] to assist the\nGPTs. However, the primary challenge in both approaches\nis effective integration, requiring architectural changes and\ntechniques to handle various modalities. Recently, OpenAI’s\nGPT4 has launched with multimodal support, enabling it to\nread images, analyze the input, and generate text as output.\nIt cannot create images as output, though. Nevertheless,\nthe field of multimodal processing is still an active area of\nresearch, and much work must be done to effectively and\nefficiently process and understand multimodal data.\nF. ROBUSTNESS\nThe robustness is a major requirement to be imposed by\nany type of GPT model, and it is a global problem for\nall learning-based prediction technologies. Robustness refers\nto the ability of the model to maintain high performance\nand accuracy even in the face of unexpected or adversarial\ninputs. Although GPT models have shown impressive per-\nformance in a wide range of NLP applications and have\nset a benchmark for high-quality text generation, they are\nstill vulnerable to certain types of errors and attacks. In\nparticular, handling adversarial inputs is a challenging task\nin GPT models. GPT models are particularly susceptible to\nadversarial attacks [202]. Adversarial inputs are specifically\ndesigned to make a learning model collapse and misbehave.\nGPT models can be highly prone to these attacks because\nthey are trained on a large volume of text. As a result, they\nmay be influenced by subtle patterns or biases in the training\ndata. If such biases or patterns exist in the data, the GPT\nmodel may amplify or perpetuate existing biases, leading to\nunfair outcomes. A few techniques may be used, such as\nadversarial training [203] [204], defensive distillation [205],\nand regularization techniques [206] such as dropout, weight\ndecay, and batch normalization, to mitigate and handle ad-\nversarial inputs. Therefore, GPT development must focus on\ndeveloping models with more robustness, enabling them to be\ntolerant of various vulnerabilities, and thus to be used reliably\nand susceptible in a wide range of applications.\nG. MULTILINGUAL SUPPORT\nWhile GPT models have demonstrated remarkable profi-\nciency in NLP tasks for individual languages, achieving\nmultilingual support remains a significant challenge. The\nprimary difficulty in developing multilingual GPT models\nlies in the significant differences in syntax, grammar, and\nvocabulary across various languages. As the number of in-\nternet users day by day increasing irrespective of literacy\nrate, multilingual support will target all types of end users.\nTo create models that can effectively process multiple lan-\nguages, researchers need to train GPT models on extensive,\ndiverse datasets that span a broad range of languages and\nlanguage families. Additionally, designing language-specific\npre-processing techniques to prepare input data for the model\nis another obstacle to overcome. Various languages possess\ndistinct writing systems, word orders, and linguistic features,\nnecessitating specialized pre-processing techniques to ensure\nthat the model can process the input data effectively. Despite\nthe challenges, researchers continue to explore new methods\nto improve the multilingual capabilities of GPT models.\nSome techniques involve training separate models for each\nlanguage or developing language-specific fine-tuning tech-\nniques. Others include developing cross-lingual TL tech-\n34 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n66\nTABLE 6: Various lessons learned and future research directions.\nSl.No Lessons Learned Open Issues Future Directions\n1. ◦ Huge volume of data usage is\ncritical\n◦ Data privacy - may unknowingly reveal sensitive\ninformation\n◦ Varied data quality - Inconsistency in quality of data\nused for training\n◦ Scalability - Models should be able to handle an\nincrease in data set size and complexity\n◦ Optimized architecture and algorithms\n◦ Cloud-based computing\n◦ Hardware advancements\n2. ◦ Importance of Proper Pre-\nprocessing of data\n◦ Data bias - Overrepresentation of certain groups or\nperspectives\n◦ Poor model performance\n◦ Reduced efficiency of the model\n◦ Continuous monitoring\n◦ Testing model for potential biases\n◦ Diversifying the training data\n3. ◦ Importance of explainability\nand interpretability\n◦ Complexity of models\n◦ Inability to explain predictions\n◦ Need of User-tailored Explanations generation\n◦ Developing Interpretable models\n◦ Lack of transparency in the data source\n◦ AI governance models can be used\n◦ Model Summaries can be provided\n◦ Techniques like LIME(Local Model-Agnostic Ex-\nplanations can be used\n◦ Uncertaining estimates can be obtained from a\nmodel\n4. ◦ Ethical concerns ◦ Data privacy and data protection\n◦ Misuse of data\n◦ Accountability and transparency concerns\n◦ Societal implications - displacing jobs and exacer-\nbating equalities\n◦ Counterfactual analysis can be used\n◦ Federated learning can be used\n◦ Ethical guidelines, Legal frameworks and regula-\ntions can be developed to avoid harmful use\n5. ◦ Lack of contextual under-\nstanding in AI systems\n◦ Possibility for ambiguous, contradictory, incorrect\nresults leads to misunderstandings\n◦ Inconsistency in responses or outputs\n◦ Lack of ability in distinguishing true and false\ninformation\n◦ Incorporation of knowledge graphs and semantic\nembeddings into the training process\n◦ Usage of attention mechanisms to focus on relevant\nparts of the input\n◦ Imparting reasoning and inference capabilities\n◦ Task or domain-based fine-tuning\n6. ◦ Pre-trained models may not\nperform well for Domain-\nspecific task\n◦ Possibility for ambiguous, contradictory, incorrect\nresults leads to misunderstandings\n◦ Inconsistency in responses or outputs\n◦ Lack of ability in distinguishing true and false\ninformation\n◦ Incorporation of knowledge graphs and semantic\nembeddings into the training process\n◦ Usage of attention mechanisms to focus on relevant\nparts of the input\n◦ Imparting reasoning and inference capabilities\n◦ Task or domain-based fine-tuning\nniques that allow the model to transfer knowledge and skills\nlearned in one language to another.\nH. LIMITED UNDERSTANDING\nGPT models have a limited understanding of context and\nmeaning, despite their ability to generate coherent text. This\nproblem arises due to issues such as a lack of semantic\nunderstanding, bias, stereotyping, and handling nuances and\nfigurative language. As a result, the outputs generated by\nthe model may contain errors or inaccuracies, even if they\nare grammatically correct. Researchers are exploring various\ntechniques to enhance the model’s contextual understanding.\nUnderstanding GPTs will be more reactive and may attract\nmore users for accurate results [207]. These methods include\nincorporating external knowledge sources like knowledge\ngraphs and ontologies into the training process, developing\ncommon sense reasoning capabilities, and improving the\nmodel’s ability to handle nuances and idiomatic expressions.\nBy enhancing the contextual understanding of GPT models,\ntheir outputs will be more accurate, relatable, sequential, less\nbiased, and more useful for a variety of applications.\nI. ETHICAL CONCERNS\nThe ethical concerns in GPT models are an active area of\ndiscussion and debate due to the potential negative impacts\nthat the use of GPTs could have on society. Although GPT\nmodels have demonstrated remarkable abilities in generat-\ning coherent and realistic text, there are concerns about\nthe perpetuation of biases and stereotypes, the possibility\nof malicious use, and the effects on employment and eco-\nnomic inequality. Some of the ethical characteristics to be\npossessed by GPT include functional Morality, operational\nmorality, abiding by the right for explanation law, improved\ntransparency with human involvement, unbiased data, and\nadhering to government regulations on data usage [195]. The\nresponsibility of developers and companies to address these\nethical concerns and ensure the ethical use of a GPT model\nis also a topic of debate. The ethical implications of GPT\nmodels are being actively researched and discussed in the\nfields of AI, computer science, and philosophy.\nJ. SECURITY AND PRIVACY CONCERNS\nGPT models raise concerns about security and privacy, par-\nticularly as they become more widespread. One of the main\nconcerns is that GPT could be used for harmful purposes,\nVOLUME 4, 2016 35\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nsuch as creating fake news or deep fakes, as it can gener-\nate text that looks real and convincing, making it difficult\nto distinguish between genuine and fake content. Another\nconcern is the potential for privacy violations when using\na GPT model. Large language models like GPT require\na significant amount of training data, which could contain\nsensitive or personal information. This raises concerns about\nprivacy and data protection as per European Union’s Gen-\neral Data Protection Act [208], particularly if the training\ndata is not properly anonymized or if the models are used\nto generate text based on user data without their explicit\nconsent. Some of the problems concerned with confiden-\ntiality related to the pre-training dataset are Data tracing,\nMembership Inference Attacks, reconstruction attacks, and\nproperty inference attacks and the vulnerabilities concerned\nwith a model encoder are hyperparameter stealing attacks\nand encoder parameter stealing attacks. Poisoning, Backdoor,\nand evasion attacks are the vulnerability related to the in-\ntegrity of self-supervised learning. Resource depletion attack\nis one major issue with data availability, which may lead to\ntremendous effects incorrect results, and may cause greater\ndeviations too [208]. Additionally, the GPT model’s ability to\ngenerate text based on user input could inadvertently disclose\nsensitive information, such as personal or financial details,\nor trade secrets. This could happen if a GPT model is used\nin an insecure environment or if it is targeted by malicious\nactors seeking to obtain sensitive information. Researchers\nand developers should focus on assuring authenticity in using\nusers’ data in case of interactive information generation\nbased on privacy data shared. These include using differential\nprivacy to protect training data privacy [209], implementing\nsecure hardware or software protocols to protect models from\ncyberattacks, and developing techniques to detect and prevent\nthe malicious use of GPT models. It’s crucial to adopt and\nfollow these measures to ensure the ethical and safe use of\nGPT models before using them in various applications.\nTherefore, GPT model development must focus on devel-\noping more robust, reliable, safest, multi-lingual, multimodal\nsupport-enabled solutions for delivering domain-specific or\nhuman-specific solutions with optimal resource utilization.\nVII. CONCLUSION\nThe impact of GPT and other large language models have\na significant and far-reaching effect. As these technologies\ncontinue to develop and advance, they have the potential\nto revolutionise how we interact with technology and one\nanother. From personalised recommendations and customer\nservice to language translation and text generation, the pos-\nsibilities are endless. However, there are potential ethical\nand societal issues that must be addressed. As we continue\nto rely more heavily on these language models, we must\nensure that we use them responsibly and with consideration\nfor the impact they have on the entire society. These chal-\nlenges include biases in the data used to train the models,\nensuring privacy and security, understanding the implications\nof human creativity, and the potential impact on employment\nand job displacement. We must continue to evaluate and\nreflect on the impact of GPT and other language models in\norder to ensure that they are being used to the benefit of\nsociety as a whole. By doing so, we can help to ensure that\nthese technologies are utilised to their utmost potential while\nminimising any negative effects they may have.\nREFERENCES\n[1] X. Han, Z. Zhang, N. Ding, Y . Gu, X. Liu, Y . Huo, J. Qiu, Y . Yao,\nA. Zhang, L. Zhang, et al., “Pre-trained models: Past, present and future,”\nAI Open, vol. 2, pp. 225–250, 2021.\n[2] “\"Introducing OpenAI\".” [Accessed on 23.03.2023].\n[3] L. Dong, S. Xu, and B. Xu, “Speech-transformer: a no-recurrence\nsequence-to-sequence model for speech recognition,” in 2018 IEEE\ninternational conference on acoustics, speech and signal processing\n(ICASSP), pp. 5884–5888, IEEE, 2018.\n[4] B. D. Lund and T. Wang, “Chatting about chatgpt: how may ai and gpt\nimpact academia and libraries?,” Library Hi Tech News, 2023.\n[5] E. Kasneci, K. Seßler, S. Küchemann, M. Bannert, D. Dementieva,\nF. Fischer, U. Gasser, G. Groh, S. Günnemann, E. Hüllermeier, et al.,\n“Chatgpt for good? on opportunities and challenges of large language\nmodels for education,” Learning and Individual Differences, vol. 103,\np. 102274, 2023.\n[6] X. Qiu, T. Sun, Y . Xu, Y . Shao, N. Dai, and X. Huang, “Pre-trained\nmodels for natural language processing: A survey,” Science China Tech-\nnological Sciences, vol. 63, no. 10, pp. 1872–1897, 2020.\n[7] A. S. George, A. H. George, T. Baskar, and A. G. Martin, “Revolu-\ntionizing business communication: Exploring the potential of gpt-4 in\ncorporate settings,” Partners Universal International Research Journal,\nvol. 2, no. 1, pp. 149–157, 2023.\n[8] C. Zhang, C. Zhang, S. Zheng, Y . Qiao, C. Li, M. Zhang, S. K. Dam,\nC. M. Thwal, Y . L. Tun, L. L. Huy, et al., “A complete survey on\ngenerative ai (aigc): Is chatgpt from gpt-4 to gpt-5 all you need?,” arXiv\npreprint arXiv:2303.11717, 2023.\n[9] M. Zaib, Q. Z. Sheng, and W. Emma Zhang, “A short survey of pre-\ntrained language models for conversational ai-a new age in nlp,” in\nProceedings of the Australasian computer science week multiconference,\npp. 1–4, 2020.\n[10] Z. Liu, X. Yu, L. Zhang, Z. Wu, C. Cao, H. Dai, L. Zhao, W. Liu, D. Shen,\nQ. Li, et al., “Deid-gpt: Zero-shot medical text de-identification by gpt-\n4,” arXiv preprint arXiv:2303.11032, 2023.\n[11] P. Rivas and L. Zhao, “Marketing with chatgpt: Navigating the ethical\nterrain of gpt-based chatbot technology,” AI, vol. 4, no. 2, pp. 375–384,\n2023.\n[12] M. Leippold, “Thus spoke gpt-3: Interviewing a large-language model on\nclimate finance,” Finance Research Letters, vol. 53, p. 103617, 2023.\n[13] M. Trajtenberg, “Ai as the next gpt: a political-economy perspective,”\ntech. rep., National Bureau of Economic Research, 2018.\n[14] D. Haluza and D. Jungwirth, “Artificial intelligence and ten societal\nmegatrends: An exploratory study using gpt-3,” Systems, vol. 11, no. 3,\np. 120, 2023.\n[15] L. J. Quintans-Júnior, R. Q. Gurgel, A. A. d. S. Araújo, D. Correia, and\nP. R. Martins-Filho, “Chatgpt: the new panacea of the academic world,”\n2023.\n[16] Q. Zhu and J. Luo, “Generative pre-trained transformer for design\nconcept generation: an exploration,” Proceedings of the Design Society,\nvol. 2, pp. 1825–1834, 2022.\n[17] “\"GPT\".” [Accessed on 25.03.2023].\n[18] M. Kosinski, “Theory of mind may have spontaneously emerged in large\nlanguage models,” arXiv preprint arXiv:2302.02083, 2023.\n[19] “\"GPT-1, GPT-2 and GPT-3 models explained\".” [Accessed on\n27.03.2023].\n[20] B. Ghojogh and A. Ghodsi, “Attention mechanism, transformers, bert,\nand gpt: Tutorial and survey,” 2020.\n[21] “\"Generative Pre-trained Transformer 3 by OpenAI\".” [Accessed on\n23.03.2023].\n[22] N. Williams, S. Ivanov, and D. Buhalis, “Algorithmic ghost in the\nresearch shell: Large language models and academic knowledge creation\nin management research,” arXiv preprint arXiv:2303.07304, 2023.\n[23] M.-T. Nguyen, P.-T. Nguyen, V .-V . Nguyen, and Q.-M. Nguyen, “Gen-\nerating product description with generative pre-trained transformer 2,” in\n36 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n2021 6th International Conference on Innovative Technology in Intelli-\ngent System and Industrial Applications (CITISIA), pp. 1–7, 2021.\n[24] V . Taecharungroj, ““what can chatgpt do?” analyzing early reactions to\nthe innovative ai chatbot on twitter,” Big Data and Cognitive Computing,\nvol. 7, no. 1, p. 35, 2023.\n[25] G. Spitale, N. Biller-Andorno, and F. Germani, “Ai model gpt-3 (dis)\ninforms us better than humans,” arXiv preprint arXiv:2301.11924, 2023.\n[26] J. Ye, X. Chen, N. Xu, C. Zu, Z. Shao, S. Liu, Y . Cui, Z. Zhou, C. Gong,\nY . Shen, et al., “A comprehensive capability analysis of gpt-3 and gpt-3.5\nseries models,” arXiv preprint arXiv:2303.10420, 2023.\n[27] J. Liu, D. Shen, Y . Zhang, B. Dolan, L. Carin, and W. Chen, “What makes\ngood in-context examples for gpt-3?,” arXiv preprint arXiv:2101.06804,\n2021.\n[28] M. Bommarito II and D. M. Katz, “Gpt takes the bar exam,” arXiv\npreprint arXiv:2212.14402, 2022.\n[29] T. Hagendorff, S. Fabi, and M. Kosinski, “Machine intuition: Uncov-\nering human-like intuitive decision-making in gpt-3.5,” arXiv preprint\narXiv:2212.05206, 2022.\n[30] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in\nneural information processing systems, vol. 30, 2017.\n[31] W. Hou and Z. Ji, “Geneturing tests gpt models in genomics,” bioRxiv,\npp. 2023–03, 2023.\n[32] S. Edunov, A. Baevski, and M. Auli, “Pre-trained language model\nrepresentations for language generation,” in Proceedings of the 2019\nConference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies, V olume 1\n(Long and Short Papers), (Minneapolis, Minnesota), pp. 4052–4059,\nAssociation for Computational Linguistics, June 2019.\n[33] A. Rahali and M. A. Akhloufi, “End-to-end transformer-based models in\ntextual-based nlp,” AI, vol. 4, no. 1, pp. 54–110, 2023.\n[34] J. R. Stevens, R. Venkatesan, S. Dai, B. Khailany, and A. Raghunathan,\n“Softermax: Hardware/software co-design of an efficient softmax for\ntransformers,” in 2021 58th ACM/IEEE Design Automation Conference\n(DAC), pp. 469–474, IEEE, 2021.\n[35] M. Bangura, K. Barabashova, A. Karnysheva, S. Semczuk, and Y . Wang,\n“Automatic generation of german drama texts using fine tuned gpt-2\nmodels,” arXiv preprint arXiv:2301.03119, 2023.\n[36] J. Savelka, A. Agarwal, C. Bogart, and M. Sakr, “Large language models\n(gpt) struggle to answer multiple-choice questions about code,” arXiv\npreprint arXiv:2303.08033, 2023.\n[37] H. Liu, Y . Cai, Z. Lin, Z. Ou, Y . Huang, and J. Feng, “Variational latent-\nstate gpt for semi-supervised task-oriented dialog systems,” IEEE/ACM\nTransactions on Audio, Speech, and Language Processing, vol. 31,\npp. 970–984, 2023.\n[38] “\"GPT-3, explained: This new language AI is uncanny, funny — and a\nbig deal\".” [Accessed on 23.03.2023].\n[39] A. Hendy, M. Abdelrehim, A. Sharaf, V . Raunak, M. Gabr, H. Matsushita,\nY . J. Kim, M. Afify, and H. H. Awadalla, “How good are gpt models\nat machine translation? a comprehensive evaluation,” arXiv preprint\narXiv:2302.09210, 2023.\n[40] S. Pramanik and S. K. Bandyopadhyay, “Analysis of big data,” in Ency-\nclopedia of Data Science and Machine Learning, pp. 97–115, IGI Global,\n2023.\n[41] A. Zaremba and E. Demir, “Chatgpt: Unlocking the future of nlp in\nfinance,” Available at SSRN 4323643, 2023.\n[42] N. Aleksi ´c, M. Arnelid, D. Lisy, A. Balachandran, M. Belfrage,\nA. Brännström, M. Busarello, S. A. Carretta, K. Cotton, S. de Heer, et al.,\n“Deep learning as a gpt and disruptor in innovation processes,”\n[43] S. Bubeck, V . Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Ka-\nmar, P. Lee, Y . T. Lee, Y . Li, S. Lundberg, et al., “Sparks of artifi-\ncial general intelligence: Early experiments with gpt-4,” arXiv preprint\narXiv:2303.12712, 2023.\n[44] D. M. Katz, M. J. Bommarito, S. Gao, and P. Arredondo, “Gpt-4 passes\nthe bar exam,” Available at SSRN 4389233, 2023.\n[45] D. O. Beerbaum, “Generative artificial intelligence (gai) ethics\ntaxonomy-applying chat gpt for robotic process automation (gai-rpa) as\nbusiness case,” Available at SSRN 4385025, 2023.\n[46] H. A. Dida, D. Chakravarthy, and F. Rabbi, “Chatgpt and big data:\nEnhancing text-to-speech conversion,” Mesopotamian Journal of Big\nData, vol. 2023, pp. 33–37, 2023.\n[47] V . Pereira, E. Hadjielias, M. Christofi, and D. Vrontis, “A systematic\nliterature review on the impact of artificial intelligence on workplace\noutcomes: A multi-process perspective,” Human Resource Management\nReview, vol. 33, no. 1, p. 100857, 2023.\n[48] M. Trajtenberg, “Artificial intelligence as the next gpt: A political-\neconomy perspective,” in The economics of artificial intelligence: An\nagenda, pp. 175–186, University of Chicago Press, 2018.\n[49] S. Tu, A. Cyphert, and S. Perl, “Limits of using artificial intelligence and\ngpt-3 in patent prosecution,” Tex. Tech L. Rev., vol. 54, p. 255, 2021.\n[50] A. Mathew, “Is artificial intelligence a world changer? a case study of\nopenai’s chat gpt,” Recent Progress in Science and Technology V ol. 5,\npp. 35–42, 2023.\n[51] R. Reed, “The theology of gpt-2: Religion and artificial intelligence,”\nReligion Compass, vol. 15, no. 11, p. e12422, 2021.\n[52] H. Akbar, M. Zubair, and M. S. Malik, “The security issues and chal-\nlenges in cloud computing,” International Journal for Electronic Crime\nInvestigation, vol. 7, no. 1, pp. 13–32, 2023.\n[53] K. D. Gupta et al., “A review of generative ai from historical perspec-\ntives,” 2023.\n[54] R. Sajja, Y . Sermet, D. Cwiertny, and I. Demir, “Platform-independent\nand curriculum-oriented intelligent assistant for higher education,” arXiv\npreprint arXiv:2302.09294, 2023.\n[55] F. Etro, “The economic consequences of the diffusion of cloud comput-\ning,” Dutta, Soumitra; Mia, Irene. The Global Information Technology\nReport, vol. 2010, 2009.\n[56] K. Y AMAOKA, K. W ATANABE, K. KISE, A. DENGEL, and S. ISHI-\nMARU, “Experience is the best teacher: Personalized vocabulary build-\ning within the context of instagram posts and sentences from gpt-3,”\n2022.\n[57] R. Ressmeyer, S. Masling, and M. Liao, ““deep faking” political twitter\nusing transfe r learning and gpt-2,” 2019.\n[58] S. Balkus and D. Yan, “Improving short text classification with aug-\nmented data using gpt-3,” arXiv preprint arXiv:2205.10981, 2022.\n[59] H. Hua, Y . Li, T. Wang, N. Dong, W. Li, and J. Cao, “Edge computing\nwith artificial intelligence: A machine learning perspective,” ACM Com-\nputing Surveys, vol. 55, no. 9, pp. 1–35, 2023.\n[60] J. Yao, S. Zhang, Y . Yao, F. Wang, J. Ma, J. Zhang, Y . Chu, L. Ji, K. Jia,\nT. Shen, A. Wu, F. Zhang, Z. Tan, K. Kuang, C. Wu, F. Wu, J. Zhou, and\nH. Yang, “Edge-cloud polarization and collaboration: A comprehensive\nsurvey for ai,” IEEE Transactions on Knowledge and Data Engineering,\npp. 1–1, 2022.\n[61] Y . Yu and S. Lee, “Measurements of the benefits of edge computing on\nautonomous driving,” in 2022 13th International Conference on Infor-\nmation and Communication Technology Convergence (ICTC), pp. 2155–\n2159, IEEE, 2022.\n[62] D. Yuan, L. Cui, M. Xie, Z. Su, et al., “Paratra: A parallel transformer\ninference framework for gpus in edge computing,”\n[63] X. Zhou, H. Liu, C. Shi, and J. Liu, Deep Learning on Edge Computing\nDevices: Design Challenges of Algorithm and Architecture. Elsevier,\n2022.\n[64] K. Li, K. Chen, S. Luo, H. Zhang, and P. Fan, “Ubinn: A communication\nefficient framework for distributed machine learning in edge computing,”\nIEEE Transactions on Network Science and Engineering, 2023.\n[65] C. Benzaïd, T. Taleb, and M. Z. Farooqi, “Trust in 5g and beyond\nnetworks,” IEEE Network, vol. 35, no. 3, pp. 212–222, 2021.\n[66] J. S. Wey and J. Zhang, “Passive optical networks for 5g transport:\nTechnology and standards,” Journal of Lightwave Technology, vol. 37,\nno. 12, pp. 2830–2837, 2019.\n[67] S. Zhang, W. Y . B. Lim, W. C. Ng, Z. Xiong, D. Niyato, X. S. Shen, and\nC. Miao, “Towards green metaverse networking: Technologies, advance-\nments and future directions,” IEEE Network, 2023.\n[68] Z. Li, M. A. Uusitalo, H. Shariatmadari, and B. Singh, “5g urllc: Design\nchallenges and system concepts,” in 2018 15th International Symposium\non Wireless Communication Systems (ISWCS), pp. 1–6, 2018.\n[69] A. Gonzalez Fanfalone et al., “The road to 5g networks: experience to\ndate and future developments,” 2019.\n[70] Y . Rogers, H. Sharp, and J. Preece, Interaction design: beyond human-\ncomputer interaction. John Wiley & Sons, 2023.\n[71] Y . Liu, M. Yu, M. Jiang, and Y . Huang, “Creative research question\ngeneration for human-computer interaction research,” 2023.\n[72] P. Hämäläinen, M. Tavast, and A. Kunnari, “Evaluating large language\nmodels in generating synthetic hci research data: a case study,” in ACM\nSIGCHI Annual Conference on Human Factors in Computing Systems,\nACM, 2023.\nVOLUME 4, 2016 37\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n[73] A. Shafeeg, I. Shazhaev, D. Mihaylov, A. Tularov, and I. Shazhaev,\n“V oice assistant integrated with chat gpt,” Indonesian Journal of Com-\nputer Science, vol. 12, no. 1, 2023.\n[74] J. Zhang, J. Pu, J. Xue, M. Yang, X. Xu, X. Wang, and F.-Y . Wang,\n“Hivegpt: Human-machine-augmented intelligent vehicles with genera-\ntive pre-trained transformer,” IEEE Transactions on Intelligent Vehicles,\n2023.\n[75] H. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz,\n“Capabilities of gpt-4 on medical challenge problems,” arXiv preprint\narXiv:2303.13375, 2023.\n[76] A. Tack and C. Piech, “The ai teacher test: Measuring the pedagogical\nability of blender and gpt-3 in educational dialogues,” arXiv preprint\narXiv:2205.07540, 2022.\n[77] A. Lecler, L. Duron, and P. Soyer, “Revolutionizing radiology with gpt-\nbased models: Current applications, future possibilities and limitations of\nchatgpt,” Diagnostic and Interventional Imaging, 2023.\n[78] D. Baidoo-Anu and L. Owusu Ansah, “Education in the era of generative\nartificial intelligence (ai): Understanding the potential benefits of chatgpt\nin promoting teaching and learning,” Available at SSRN 4337484, 2023.\n[79] A. O’Cain, B. D. Fedoruk, Z. Masri, R. Frost, and A. Alahmar, “A\nsystem for the improvement of educational assessment using intelligent\nconversational agents,” Available at SSRN 4393234, 2023.\n[80] A. Alam, “Possibilities and challenges of compounding artificial intel-\nligence in india’s educational landscape,” Alam, A.(2020). Possibilities\nand Challenges of Compounding Artificial Intelligence in India’s Ed-\nucational Landscape. International Journal of Advanced Science and\nTechnology, vol. 29, no. 5, pp. 5077–5094, 2020.\n[81] H. Chen, O. Engkvist, Y . Wang, M. Olivecrona, and T. Blaschke, “The\nrise of deep learning in drug discovery,” Drug discovery today, vol. 23,\nno. 6, pp. 1241–1250, 2018.\n[82] N. Pillai, A. Dasgupta, S. Sudaskorn, J. Fretland, and P. D. Mavroudis,\n“Machine-learning-guided early drug discovery of small molecules,”\nDrug Discovery Today, 2022.\n[83] Y . Kim, J.-H. Kim, J. M. Lee, M. J. Jang, Y . J. Yum, S. Kim, U. Shin, Y .-\nM. Kim, H. J. Joo, and S. Song, “A pre-trained bert for korean medical\nnatural language processing,” Scientific Reports, vol. 12, no. 1, pp. 1–10,\n2022.\n[84] K. S. Kalyan, A. Rajasekharan, and S. Sangeetha, “Ammu: a survey of\ntransformer-based biomedical pretrained language models,” Journal of\nbiomedical informatics, vol. 126, p. 103982, 2022.\n[85] Z. Liu, R. A. Roberts, M. Lal-Nag, X. Chen, R. Huang, and W. Tong,\n“Ai-based language models powering drug discovery and development,”\nDrug Discovery Today, vol. 26, no. 11, pp. 2593–2607, 2021.\n[86] J. Vamathevan, D. Clark, P. Czodrowski, I. Dunham, E. Ferran, G. Lee,\nB. Li, A. Madabhushi, P. Shah, M. Spitzer, et al., “Applications of\nmachine learning in drug discovery and development,” Nature reviews\nDrug discovery, vol. 18, no. 6, pp. 463–477, 2019.\n[87] E. Gawehn, J. A. Hiss, and G. Schneider, “Deep learning in drug\ndiscovery,” Molecular informatics, vol. 35, no. 1, pp. 3–14, 2016.\n[88] A. Lavecchia, “Deep learning in drug discovery: opportunities, chal-\nlenges and future prospects,” Drug discovery today, vol. 24, no. 10,\npp. 2017–2032, 2019.\n[89] F. Urbina, F. Lentzos, C. Invernizzi, and S. Ekins, “Dual use of\nartificial-intelligence-powered drug discovery,” Nature Machine Intelli-\ngence, vol. 4, no. 3, pp. 189–191, 2022.\n[90] M. H. Segler, T. Kogej, C. Tyrchan, and M. P. Waller, “Generating\nfocused molecule libraries for drug discovery with recurrent neural\nnetworks,” ACS central science, vol. 4, no. 1, pp. 120–131, 2018.\n[91] M. Ahsan, M. Rahaman, N. Anjum, et al., “From chatgpt-3 to gpt-4:\nA significant leap in ai-driven nlp tools,” Saidur and Anjum, Nishath,\nFrom ChatGPT-3 to GPT-4: A Significant Leap in AI-Driven NLP Tools\n(March 27, 2023), 2023.\n[92] D. M. Levine, R. Tuwani, B. Kompa, A. Varma, S. G. Finlayson,\nA. Mehrotra, and A. Beam, “The diagnostic and triage accuracy of the\ngpt-3 artificial intelligence model,” medRxiv, pp. 2023–01, 2023.\n[93] I. Alghanmi, L. Espinosa-Anke, and S. Schockaert, “Probing pre-\ntrained language models for disease knowledge,” arXiv preprint\narXiv:2106.07285, 2021.\n[94] H. Ali, “The potential of gpt-4 as a personalized virtual assistant for\nbariatric surgery patients,” Obesity Surgery, pp. 1–1, 2023.\n[95] D.-M. Vulturar, M. A. Neag, S. C. Vesa, A.-D. Maierean, D. Gherman,\nA. D. Buzoianu, O. H. Or ˘asan, and D.-A. Todea, “Therapeutic efficacy\nand outcomes of remdesivir versus remdesivir with tocilizumab in se-\nvere sars-cov-2 infection,” International Journal of Molecular Sciences,\nvol. 23, no. 22, p. 14462, 2022.\n[96] B. Wang, Q. Xie, J. Pei, P. Tiwari, Z. Li, et al., “Pre-trained language\nmodels in biomedical domain: A systematic survey,” arXiv preprint\narXiv:2110.05006, 2021.\n[97] S. Arslan, “Exploring the potential of chat gpt in personalized obesity\ntreatment,” Annals of Biomedical Engineering, pp. 1–2, 2023.\n[98] A. Blanchard and M. Taddeo, “Ethical challenges of using artifical\nintelligence for intelligence analysis,” Available at SSRN 4226631, 2022.\n[99] B. Balsmeier and M. Woerter, “Is this time different? how digitalization\ninfluences job creation and destruction,” Research policy, vol. 48, no. 8,\np. 103765, 2019.\n[100] F. Pesapane, M. Codari, and F. Sardanelli, “Artificial intelligence in\nmedical imaging: threat or opportunity? radiologists again at the forefront\nof innovation in medicine,” European radiology experimental, vol. 2,\npp. 1–10, 2018.\n[101] I. Carvalho and S. Ivanov, “Chatgpt for tourism: applications, benefits\nand risks,” Tourism Review, 2023.\n[102] R. S. Rathore, S. Sangwan, and O. Kaiwartya, “Towards trusted green\ncomputing for wireless sensor networks: Multi metric optimization ap-\nproach.,” Adhoc & Sensor Wireless Networks, vol. 49, 2021.\n[103] S. Shah, H. Ghomeshi, E. Vakaj, E. Cooper, and R. Mohammad, “An\nensemble-learning-based technique for bimodal sentiment analysis,” Big\nData and Cognitive Computing, vol. 7, no. 2, p. 85, 2023.\n[104] J. Salminen, C. Kandpal, A. M. Kamel, S.-g. Jung, and B. J. Jansen,\n“Creating and detecting fake reviews of online products,” Journal of\nRetailing and Consumer Services, vol. 64, p. 102771, 2022.\n[105] A. S. George and A. H. George, “A review of chatgpt ai’s impact on\nseveral business sectors,” Partners Universal International Innovation\nJournal, vol. 1, no. 1, pp. 9–23, 2023.\n[106] A. El-Ansari and A. Beni-Hssane, “Sentiment analysis for personalized\nchatbots in e-commerce applications,” Wireless Personal Communica-\ntions, vol. 129, no. 3, pp. 1623–1644, 2023.\n[107] K. Goei, M. Hendriksen, M. de Rijke, et al., “Tackling attribute fine-\ngrainedness in cross-modal fashion search with multi-level features,” in\nSIGIR 2021 Workshop on eCommerce. ACM, 2021.\n[108] S. G. Bouschery, V . Blazevic, and F. T. Piller, “Augmenting human\ninnovation teams with artificial intelligence: Exploring transformer-based\nlanguage models,” Journal of Product Innovation Management, vol. 40,\nno. 2, pp. 139–153, 2023.\n[109] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von\nArx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill, et al.,\n“On the opportunities and risks of foundation models,” arXiv preprint\narXiv:2108.07258, 2021.\n[110] J. Cowls, A. Tsamados, M. Taddeo, and L. Floridi, “The ai gambit: lever-\naging artificial intelligence to combat climate change—opportunities,\nchallenges, and recommendations,” Ai & Society, pp. 1–25, 2021.\n[111] H. Benbya, T. H. Davenport, and S. Pachidi, “Artificial intelligence in\norganizations: Current state and future opportunities,” MIS Quarterly\nExecutive, vol. 19, no. 4, 2020.\n[112] Y . Liu, T. Han, S. Ma, J. Zhang, Y . Yang, J. Tian, H. He, A. Li,\nM. He, Z. Liu, et al., “Summary of chatgpt/gpt-4 research and per-\nspective towards the future of large language models,” arXiv preprint\narXiv:2304.01852, 2023.\n[113] S. Biswas, “Importance of chat gpt in agriculture: According to chat gpt,”\nAvailable at SSRN 4405391, 2023.\n[114] M. S. Farooq, S. Riaz, A. Abid, K. Abid, and M. A. Naeem, “A survey\non the role of iot in agriculture for the implementation of smart farming,”\nIeee Access, vol. 7, pp. 156237–156271, 2019.\n[115] H. Wang, H. Wu, H. Zhu, Y . Miao, Q. Wang, S. Qiao, H. Zhao, C. Chen,\nand J. Zhang, “A residual lstm and seq2seq neural network based on\ngpt for chinese rice-related question and answer system,” Agriculture,\nvol. 12, no. 6, p. 813, 2022.\n[116] Y . K. Dwivedi, N. Kshetri, L. Hughes, E. L. Slade, A. Jeyaraj, A. K.\nKar, A. M. Baabdullah, A. Koohang, V . Raghavan, M. Ahuja, et al., ““so\nwhat if chatgpt wrote it?” multidisciplinary perspectives on opportunities,\nchallenges and implications of generative conversational ai for research,\npractice and policy,” International Journal of Information Management,\nvol. 71, p. 102642, 2023.\n[117] S. Biswas, “Prospective role of chat gpt in the military: According to\nchatgpt,” Qeios, 2023.\n[118] L. Floridi and M. Chiriatti, “Gpt-3: Its nature, scope, limits, and conse-\nquences,” Minds and Machines, vol. 30, pp. 681–694, 2020.\n38 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n[119] P. Helo and A. Shamsuzzoha, “Real-time supply chain—a blockchain\narchitecture for project deliveries,” Robotics and Computer-Integrated\nManufacturing, vol. 63, p. 101909, 2020.\n[120] R. Kadel, H. Shrestha, A. Shrestha, P. Sharma, N. Shrestha, J. Bashyal,\nand S. Shrestha, “Emergence of ai in cyber security,” International Re-\nsearch Journal of Modernization in Engineering Technology and Science,\n2022.\n[121] H. Benbya, S. Pachidi, and S. Jarvenpaa, “Special issue editorial: Arti-\nficial intelligence in organizations: Implications for information systems\nresearch,” Journal of the Association for Information Systems, vol. 22,\nno. 2, p. 10, 2021.\n[122] T. Zheng, M. Ardolino, A. Bacchetti, and M. Perona, “The applications\nof industry 4.0 technologies in manufacturing context: a systematic\nliterature review,” International Journal of Production Research, vol. 59,\nno. 6, pp. 1922–1954, 2021.\n[123] B. Rathore, “Digital transformation 4.0: Integration of artificial intel-\nligence & metaverse in marketing,” Eduzone: International Peer Re-\nviewed/Refereed Multidisciplinary Journal, vol. 12, no. 1, pp. 42–48,\n2023.\n[124] J. Bulchand-Gidumal, “Impact of artificial intelligence in travel, tourism,\nand hospitality,” in Handbook of e-Tourism, pp. 1943–1962, Springer,\n2022.\n[125] N. Gillani, R. Eynon, C. Chiabaut, and K. Finkel, “Unpacking the “black\nbox” of ai in education,” Educational Technology & Society, vol. 26,\nno. 1, pp. 99–111, 2023.\n[126] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan,\n“A survey on bias and fairness in machine learning,” ACM Computing\nSurveys (CSUR), vol. 54, no. 6, pp. 1–35, 2021.\n[127] F. T. Tschang and E. Almirall, “Artificial intelligence as augmenting\nautomation: Implications for employment,” Academy of Management\nPerspectives, vol. 35, no. 4, pp. 642–659, 2021.\n[128] V . Jain, B. Malviya, and S. Arya, “An overview of electronic commerce\n(e-commerce),” Journal of Contemporary Issues in Business and Govern-\nment| V ol, vol. 27, no. 3, p. 666, 2021.\n[129] B. Feijoo and A. García González, “Online shopping routines among\nchilean children: level of expansion and main causes,” 2020.\n[130] X. Zhang, Y . Jiang, Y . Shang, Z. Cheng, C. Zhang, X. Fan, Y . Xiao, and\nB. Long, “Dsgpt: Domain-specific generative pre-training of transformers\nfor text generation in e-commerce title and review summarization,”\nin Proceedings of the 44th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval, pp. 2146–2150,\n2021.\n[131] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al.,\n“Language models are unsupervised multitask learners,” OpenAI blog,\nvol. 1, no. 8, p. 9, 2019.\n[132] T. Eloundou, S. Manning, P. Mishkin, and D. Rock, “Gpts are gpts: An\nearly look at the labor market impact potential of large language models,”\narXiv preprint arXiv:2303.10130, 2023.\n[133] P. Maddigan and T. Susnjak, “Chat2vis: Generating data visualisations\nvia natural language using chatgpt, codex and gpt-3 large language\nmodels,” IEEE Access, 2023.\n[134] N. Jain, S. Vaidyanath, A. Iyer, N. Natarajan, S. Parthasarathy, S. Ra-\njamani, and R. Sharma, “Jigsaw: Large language models meet program\nsynthesis,” in Proceedings of the 44th International Conference on Soft-\nware Engineering, pp. 1219–1231, 2022.\n[135] A. Haleem, M. Javaid, and R. P. Singh, “An era of chatgpt as a significant\nfuturistic support tool: A study on features, abilities, and challenges,”\nBenchCouncil transactions on benchmarks, standards and evaluations,\nvol. 2, no. 4, p. 100089, 2022.\n[136] N. Brand, W. Odom, and S. Barnett, “Envisioning and understanding\norientations to introspective ai: Exploring a design space with meta.\naware,” in Proceedings of the 2023 CHI Conference on Human Factors\nin Computing Systems, pp. 1–18, 2023.\n[137] N. Dehouche, “Plagiarism in the age of massive generative pre-trained\ntransformers (gpt-3),” Ethics in Science and Environmental Politics,\nvol. 21, pp. 17–23, 2021.\n[138] B. D. Lund, T. Wang, N. R. Mannuru, B. Nie, S. Shimray, and Z. Wang,\n“Chatgpt and a new academic reality: Artificial intelligence-written re-\nsearch papers and the ethics of the large language models in scholarly\npublishing,” Journal of the Association for Information Science and\nTechnology, 2023.\n[139] M. Javaid, A. Haleem, and R. P. Singh, “Chatgpt for healthcare services:\nAn emerging stage for an innovative perspective,” BenchCouncil Trans-\nactions on Benchmarks, Standards and Evaluations, p. 100105, 2023.\n[140] P. P. Ray, “Chatgpt: A comprehensive review on background, applica-\ntions, key challenges, bias, ethics, limitations and future scope,” Internet\nof Things and Cyber-Physical Systems, 2023.\n[141] E. G. Wilcox, J. Gauthier, J. Hu, P. Qian, and R. Levy, “On the predictive\npower of neural language models for human real-time comprehension\nbehavior,” arXiv preprint arXiv:2006.01912, 2020.\n[142] R. Sridhar and D. Yang, “Explaining toxic text via knowledge enhanced\ntext generation,” in Proceedings of the 2022 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, pp. 811–826, 2022.\n[143] J. Bryant and P. V orderer, Psychology of entertainment. Routledge, 2013.\n[144] H. H. Thorp, “Chatgpt is fun, but not an author,” 2023.\n[145] S. Shahriar and K. Hayawi, “Let’s have a chat! a conversation with\nchatgpt: Technology, applications, and limitations,” arXiv preprint\narXiv:2302.13817, 2023.\n[146] M. U. Haque, I. Dharmadasa, Z. T. Sworna, R. N. Rajapakse, and\nH. Ahmad, “\" i think this is the most disruptive technology\": Exploring\nsentiments of chatgpt early adopters using twitter data,” arXiv preprint\narXiv:2212.05856, 2022.\n[147] O. AI.\n[148] opchatsgpt, “Impact of chat gpt on the entertainment industry,” Mar 2023.\n[149] “The Power of Chat GPT: Creating Personalized Marketing and Efficient\nCustomer Support. — linkedin.com.” https://www.linkedin.com/pulse/\npower-chat-gpt-creating-personalized-marketing-customer-bundhoo/.\n[Accessed 24-Apr-2023].\n[150] “Chat GPT-4 in the Film Industry: Scriptwriting, Editing,\nand More; TS2 SPACE — ts2.space.” https://ts2.space/en/\nchat-gpt-4-in-the-film-industry-scriptwriting-editing-and-more/#:\n~:text=GPT\\%2D4\\%20has\\%20the\\%20potential,and\\%20consistency\\\n%20than\\%20ever\\%20before., 2023. [Accessed 24-Apr-2023].\n[151] E. i. bd, “Chatgpt: The impact of chat gpt on the entertainment industry -\nmarch 24, 2023 educationsinbd,” Mar 2023.\n[152] A. J. Veal, “The concept of lifestyle: a review,” Leisure Studies, vol. 12,\nno. 4, pp. 233–252, 1993.\n[153] M. Jensen, “Defining lifestyle,” Environmental sciences, vol. 4, no. 2,\npp. 63–73, 2007.\n[154] P. Contoyannis and A. M. Jones, “Socio-economic status, health and\nlifestyle,” Journal of health economics, vol. 23, no. 5, pp. 965–995, 2004.\n[155] M. J. Reeves and A. P. Rafferty, “Healthy lifestyle characteristics among\nadults in the united states, 2000,” Archives of internal medicine, vol. 165,\nno. 8, pp. 854–857, 2005.\n[156] Y . H. Yeo, J. S. Samaan, W. H. Ng, P.-S. Ting, H. Trivedi, A. Vipani,\nW. Ayoub, J. D. Yang, O. Liran, B. Spiegel, et al., “Assessing the\nperformance of chatgpt in answering questions regarding cirrhosis and\nhepatocellular carcinoma,” medRxiv, pp. 2023–02, 2023.\n[157] S. S. Biswas, “Role of chat gpt in public health,” Annals of Biomedical\nEngineering, pp. 1–2, 2023.\n[158] M. Patkar, “5 Free Travel Planning AI and ChatGPT Apps to Get\nan Instant Itinerary — makeuseof.com.” https://www.makeuseof.com/\nfree-travel-planning-ai-chatgpt-apps/. [Accessed 24-Apr-2023].\n[159] “Your ai-powered personal chef.”\n[160] lechjaLearnCrafts, “Learn Crafts & Hobbies w/\nGPT Chat — lechja.com.” https://www.lechja.com/ai/\nlearn-crafts-hobbies-w-gpt-chat, 2023. [Accessed 24-Apr-2023].\n[161] “How to use chatgpt in your job search | indeed.com.”\n[162] S. Toshniwal, S. Wiseman, K. Livescu, and K. Gimpel, “Learning chess\nblindfolded,” 2021.\n[163] J. Freiknecht and W. Effelsberg, “Procedural generation of interactive\nstories using language models,” in Proceedings of the 15th International\nConference on the Foundations of Digital Games, pp. 1–8, 2020.\n[164] S. Värtinen, P. Hämäläinen, and C. Guckelsberger, “Generating role-\nplaying game quests with gpt language models,” IEEE Transactions on\nGames, pp. 1–12, 2022.\n[165] J. van Stegeren and J. Myundefinedliwiec, “Fine-tuning gpt-2 on anno-\ntated rpg quests for npc dialogue generation,” in Proceedings of the 16th\nInternational Conference on the Foundations of Digital Games, FDG ’21,\n(New York, NY , USA), Association for Computing Machinery, 2021.\n[166] P. Roetzer and M. Kaput, Marketing Artificial Intelligence: AI, Market-\ning, and the Future of Business. BenBella Books, 2022.\n[167] J. Thiergart, S. Huber, and T. Übellacker, “Understanding emails\nand drafting responses–an approach using gpt-3,” arXiv preprint\narXiv:2102.03062, 2021.\nVOLUME 4, 2016 39\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n[168] X. Bai, L. Duan, R. Tang, G. Batra, and R. Agrawal, “Improving text-\nbased similar product recommendation for dynamic product advertising\nat yahoo,” in Proceedings of the 31st ACM International Conference on\nInformation & Knowledge Management, CIKM ’22, (New York, NY ,\nUSA), p. 2883–2892, Association for Computing Machinery, 2022.\n[169] P. S. Neves, “Chat gpt ais “interview” 1, december 2022,” AIS-\nArchitecture Image Studies, vol. 3, no. 2, pp. 58–67, 2022.\n[170] X.-R. Gong, J.-X. Jin, and T. Zhang, “Sentiment analysis using autore-\ngressive language modeling and broad learning system,” in 2019 IEEE\nInternational Conference on Bioinformatics and Biomedicine (BIBM),\npp. 1130–1134, IEEE, 2019.\n[171] A. H. Sweidan, N. El-Bendary, and H. Al-Feel, “Sentence-level aspect-\nbased sentiment analysis for classifying adverse drug reactions (adrs)\nusing hybrid ontology-xlnet transfer learning,” IEEE Access, vol. 9,\npp. 90828–90846, 2021.\n[172] F. Wei and U. T. Nguyen, “Stock trend prediction using financial market\nnews and bert,” Wall Street Journal, 2018.\n[173] T. Yue, D. Au, C. C. Au, and K. Y . Iu, “Democratizing financial\nknowledge with chatgpt by openai: Unleashing the power of technology,”\nAvailable at SSRN 4346152, 2023.\n[174] “\"Siri\".” [Accessed on 25.03.2023].\n[175] “\"Siri ChatGPT\".” [Accessed on 25.03.2023].\n[176] “\"Siri ChatGPT\".” [Accessed on 25.03.2023].\n[177] “\"AI Dungeon: A text-based adventure-story game you direct (and star\nin) while the AI brings it to life.\".” [Accessed on 30.03.2023].\n[178] “\"It Began as an AI-Fueled Dungeon Game. It Got Much Darker\".”\n[Accessed on 25.03.2023].\n[179] “\"Whatever you want to ask, our chat has the answers\".” [Accessed on\n25.03.2023].\n[180] “\"Introducing, The BOND Network.\".” [Accessed on 25.03.2023].\n[181] “\"Save hundreds of hours analyzing feedback.\".” [Accessed on\n29.03.2023].\n[182] “\"ai|channels: make contact with intelligent minds\".” [Accessed on\n30.03.2023].\n[183] “\"Automate your meeting notes\".” [Accessed on 30.03.2023].\n[184] A. Papangelis, M. Namazifar, C. Khatri, Y .-C. Wang, P. Molino, and\nG. Tur, “Plato dialogue system: A flexible conversational ai research\nplatform,” arXiv preprint arXiv:2001.06463, 2020.\n[185] P. Dhariwal, H. Jun, C. Payne, J. W. Kim, A. Radford, and\nI. Sutskever, “Jukebox: A generative model for music,” arXiv preprint\narXiv:2005.00341, 2020.\n[186] D. Adiwardana, M.-T. Luong, D. R. So, J. Hall, N. Fiedel, R. Thoppilan,\nZ. Yang, A. Kulshreshtha, G. Nemade, Y . Lu, et al., “Towards a human-\nlike open-domain chatbot,” arXiv preprint arXiv:2001.09977, 2020.\n[187] M. M. van Buchem, H. Boosman, M. P. Bauer, I. M. Kant, S. A. Cammel,\nand E. W. Steyerberg, “The digital scribe in clinical practice: a scoping\nreview and research agenda,” NPJ digital medicine, vol. 4, no. 1, p. 57,\n2021.\n[188] K. Hao, “Facebook’s new polyglot ai can translate between 100 lan-\nguages,” 2020.\n[189] Y . Gan, G. Lu, Z. Su, L. Wang, J. Zhou, J. Jiang, and D. Chen, “A\njoint domain-specific pre-training method based on data enhancement,”\nApplied Sciences, vol. 13, no. 7, p. 4115, 2023.\n[190] “Chatgpt plugins,” Mar 2023.\n[191] B. Bhattarai, O.-C. Granmo, and L. Jiao, “Convtexttm: An explain-\nable convolutional tsetlin machine framework for text classification,”\nin Proceedings of the Thirteenth Language Resources and Evaluation\nConference, pp. 3761–3770, 2022.\n[192] A. Narasimhan, K. P. A. V . Rao, et al., “Cgems: A metric model for au-\ntomatic code generation using gpt-3,” arXiv preprint arXiv:2108.10168,\n2021.\n[193] J. E. Zini and M. Awad, “On the explainability of natural language\nprocessing deep models,” ACM Computing Surveys, vol. 55, no. 5, pp. 1–\n31, 2022.\n[194] R. K. Yadav, L. Jiao, O.-C. Granmo, and M. Goodwin, “An interpretable\nword sense classifier for human explainable chatbot,” in Agents and\nArtificial Intelligence: 13th International Conference, ICAART 2021,\nVirtual Event, February 4–6, 2021, Revised Selected Papers, pp. 236–\n249, Springer, 2022.\n[195] A. Chan, “Gpt-3 and instructgpt: technological dystopianism, utopi-\nanism, and “contextual” perspectives in ai ethics and industry,” AI and\nEthics, pp. 1–12, 2022.\n[196] M. Zhang and J. Li, “A commentary of gpt-3 in mit technology review\n2021,” Fundamental Research, vol. 1, no. 6, pp. 831–833, 2021.\n[197] H. R. Kirk, Y . Jun, F. V olpin, H. Iqbal, E. Benussi, F. Dreyer, A. Sht-\nedritski, and Y . Asano, “Bias out-of-the-box: An empirical analysis of in-\ntersectional occupational biases in popular generative language models,”\nAdvances in neural information processing systems, vol. 34, pp. 2611–\n2624, 2021.\n[198] S. S. Biswas, “Potential use of chat gpt in global warming,” Annals of\nbiomedical engineering, pp. 1–2, 2023.\n[199] P. H. Seo, A. Nagrani, A. Arnab, and C. Schmid, “End-to-end generative\npretraining for multimodal video captioning,” in Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\npp. 17959–17968, 2022.\n[200] W. Ji, Y . Wei, Z. Zheng, H. Fei, and T.-s. Chua, “Deep multimodal\nlearning for information retrieval,” in ACM International Conference on\nMultimedia, 2023.\n[201] V . Liu, H. Qiao, and L. Chilton, “Opal: Multimodal image generation for\nnews illustration,” in Proceedings of the 35th Annual ACM Symposium\non User Interface Software and Technology, pp. 1–17, 2022.\n[202] C. Guo, A. Sablayrolles, H. Jégou, and D. Kiela, “Gradient-\nbased adversarial attacks against text transformers,” arXiv preprint\narXiv:2104.13733, 2021.\n[203] A. Shafahi, M. Najibi, A. Ghiasi, Z. Xu, J. P. Dickerson, C. Studer,\nL. S. Davis, G. Taylor, and T. Goldstein, “Adversarial training for free!,”\nCoRR, vol. abs/1904.12843, 2019.\n[204] T. Bai, J. Luo, J. Zhao, B. Wen, and Q. Wang, “Recent advances in adver-\nsarial training for adversarial robustness,” CoRR, vol. abs/2102.01356,\n2021.\n[205] M. Verma, “Integration of ai-based chatbot(chatgpt) and supply chain\nmanagement solution to enhance tracking and queries response,” 02\n2023.\n[206] Y . Kubo and T. Trappenberg, Mitigating Overfitting Using Regularization\nto Defend Networks Against Adversarial Examples, pp. 400–405. 04\n2019.\n[207] X. Liu, Y . Zheng, Z. Du, M. Ding, Y . Qian, Z. Yang, and J. Tang, “Gpt\nunderstands, too,” arXiv preprint arXiv:2103.10385, 2021.\n[208] J. Jia, H. Liu, and N. Z. Gong, “10 security and privacy problems in self-\nsupervised learning,” arXiv preprint arXiv:2110.15444, 2021.\n[209] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar,\nand L. Zhang, “Deep learning with differential privacy,” in Proceedings\nof the 2016 ACM SIGSAC conference on computer and communications\nsecurity, pp. 308–318, 2016.\nGOKUL YENDURI received his Master’s degree\n(M.Tech., IT) from Vellore Institute of Technology\nin the year 2013. Currently, he is a senior research\nfellow at the DIVERSASIA project, co-funded by\nthe Erasmus+ programme of the European Union.\nHis areas of interest are machine learning and\npredictive analysis, software engineering, assistive\ntechnologies, and the metaverse. He has worked as\nan assistant professor in the past. He attended sev-\neral national and international conferences, work-\nshops, and guest lectures and published papers in peer-reviewed international\njournals. He is also acting as a reviewer for many prestigious peer-reviewed\ninternational journals.\nRAMALINGAM M is currently working as an As-\nsistant Professor Senior in the School of Informa-\ntion Technology and Engineering, Vellore Institute\nof Technology, Vellore, Tamil Nadu, India. He has\ncompleted his research in the field of vehicular\nAd-hoc Networks in the year 2020. Currently,\nhis areas of research include Federated Learning,\nMachine Learning, Computer Vision, Internet of\nThings, Deep Neural Networks, Blockchain and\nGenerative AI.\n40 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nCHEMMALAR SELVI G is currently working\nas an Assistant Professor Senior in the School of\nComputer Science Engineering and Information\nSystems, Vellore Institute of Technology, Vellore,\nTamil Nadu, India. She has completed her U.G.\nand P.G. from Anna University Chennai. She was\nawarded gold medal for security University Rank\nNo 1 in both U.G. and P.G. degrees. Her Ph.D. was\nin Machine Learning and Formal Concept Analy-\nsis in Cross-Domain Recommender Systems. Her\nresearch interest includes Machine and Deep Learning, Computer Vision and\nAI.\nY SUPRIYAreceived her bachelor of degree from\nG Pulla Reddy College of Engineering, Kurnool,\nIndia in 2009 and Master’s degree (M.Tech, CS)\nfrom Jawaharlal Nehru Technological University,\nIndia in the year 2018. She worked as a senior soft-\nware Engineer in TCS from 2010 to 2018 for three\nclients AMEX, Chrysler, and GE. She worked\nas a Project Associate from India for the Going\nGlobal Partnership Industry-Academia Collabora-\ntive Grant 2022–2023 funded by British Council\nfor the Project entitled “Co-Designing a Smart Curriculum and Personalized\nMethod of Delivery for Inclusive Value Added Courses”. She is currently\na Research Scholar with the School of Computer Science Engineering\nand Information Systems, Vellore Institute of Technology, Vellore, Tamil\nNadu, India. Her areas of interest are in ML, Federated Learning, and Soft\ncomputing. She attended several National and international Conferences and\nworkshops and published papers in peer-reviewed international journals.\nGAUTAM SRIVASTAVAreceived the B.Sc. de-\ngree from Briar Cliff University, USA, in 2004, the\nM.Sc. and Ph.D. degrees from the University of\nVictoria, Victoria, BC, Canada, in 2006 and 2012,\nrespectively. He then taught for three years at the\nDepartment of Computer Science, University of\nVictoria, where he was regarded as one of the top\nundergraduate professors in the computer science\ncourse instruction. From there in 2014, he joined a\ntenure-track position at Brandon University, Bran-\ndon, MB, Canada, where he is currently active in various professional and\nscholarly activities. He was promoted to the rank Associate Professor, in\n2018. He, as he is popularly known, is active in research in the field of data\nmining and big data. In his eighth-year academic career, he has published\na total of 50 papers in high-impact conferences in many countries and in\nhigh-status journals (SCI, SCIE) and has also delivered invited guest lectures\non big data, cloud computing, the Internet of Things, and cryptography at\nmany Taiwanese and Czech universities. He received the Best Oral Presenter\nAward in FSDM 2017, which was held at National Dong Hwa University\n(NDHU), Shoufeng, Taiwan, in 2017. He is an Editor of several international\nscientific research journals. He currently has active research projects with\nother academics in Taiwan, Singapore, Canada, Czech Republic, Poland, and\nUSA. He is constantly looking for collaboration opportunities with foreign\nprofessors and students.\nPRAVEEN KUMAR REDDY MADDIKUNTA\nis currently working as an Associate Professor\nSenior in the School of Information Technology\nand Engineering, VIT, Vellore, Tamil Nadu, India.\nHe obtained his B.Tech. in CSE from Jawaharlal\nNehru Technological University, India, M.Tech. in\nCSE from VIT University, Vellore, Tamil Nadu,\nIndia, and completed his Ph.D. in VIT, Vellore,\nTamil Nadu, India. He was a Visiting Professor\nwith the Guangdong University of Technology,\nChina, in 2019. He worked with IBM, Alcatel-Lucent as a software devel-\noper in 2011 and 2013. He produced more than 100 international/national\npublications.\nDEEPTI RAJ received the bachelor’s degree from\nKSRMCE, in 2009, and the master’s degree from\nGPREC, Andhra Pradesh, in 2011. She is currently\na Research Scholar with the School of Computer\nScience Engineering and Information Systems,\nVellore Institute of Technology, Vellore, Tamil\nNadu, India. She has over three years of teaching\nexperience. She has published review articles in\ninternational conferences. Her research interests\ninclude artificial intelligence, computer vision, the\nInternet of Things, and human–computer interaction.\nRUTVIJ H. JHAVERI (Senior Member, IEEE)\nreceived the Ph.D. degree in computer engineer-\ning, in 2016. He is currently an Experienced\nEducator and a Researcher with the Department\nof Computer Science and Engineering, Pandit\nDeendayal Energy University, Gandhinagar, In-\ndia. He conducted his postdoctoral research at the\nDelta-NTU Corporate Laboratory for CyberPhys-\nical Systems, Nanyang Technological University,\nSingapore. Also, he is co-investigating a funded\nproject from GUJCOST. He has more than 2100 Google Scholar citations\nwith an H-index of 23. He has authored more than 120 articles, including\nthe IEEE/ACM TRANSACTIONS and leading IEEE/ACM conferences.\nMoreover, he has several national and international patents, and copyrights\nto his name. His research interests include SDN, network security/resilience,\nthe IoT systems, and eHealth. He also possesses memberships of various\ntechnical bodies, such as ACM, CSI, ISTE, and IDES. He is a member\nof the Advisory Board of the Symbiosis Institute of Digital and Telecom\nManagement, Manav Rachna Group, and has been a member of Sandip\nUniversity, since 2022. He is an editorial board member of several Hindawi\nand Springer journals. He also served as a Committee Member for the\nSmart Village Project—Government of Gujarat at the district level, during\nthe year 2017. In 2017, he was awarded with the prestigious Pedagogical\nInnovation Award by Gujarat Technological University. He was ranked\namong top 2% scientists around the world, in 2021. Apart from serving as an\neditor/guest editor for various journals of repute, he also serves as a reviewer\nfor several international journals and an advisory/TPC member for renowned\ninternational conferences.\nVOLUME 4, 2016 41\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nPRABHADEVI B. Prabadevi is an Assistant Pro-\nfessor (Senior) in School of Information Tech-\nnology and Engineering, VIT University, India.\nShe received her Ph.D. in Information Technol-\nogy with Networking as specialization from Vel-\nlore Institute Technology, Vellore, India in 2018.\nShe completed her undergraduation and post-\ngraduation under Anna University, Chennai in\n2010 and 2012 respectively. She has published\naround 25 international journal papers and many\ninternational conference papers. She is currently working in the areas of\nDecision support systems and Machine Learning. She received an active\nresearcher award from Vellore Institute of Technology for three consecutive\nyears\nWEIZHENG WANG received the B.S. degree in\nsoftware engineering from Yangzhou University,\nYangzhou, China, in 2019, the M.S. degrees in\ncomputer science and engineering from the Uni-\nversity of Aizu, AizuWakamatsu, Japan, in 2021.\nNow he is currently a Research Associate in Uni-\nversity of Aizu and pursuing the Ph.D. degree in\ncomputer science at the City University of Hong\nKong, Hong Kong SAR, China. His research in-\nterests include applied cryptography, blockchain\ntechnology and IoT system.\nATHANASIOS V. VASILAKOS(Senior Member,\nIEEE) is with the Center for AI Research (CAIR),\nUniversity of Agder (UiA), Grimstad, Norway;\nand the College of Mathematics and Computer\nScience, Fuzhou University, Fuzhou, China. He\nis a WoS Highly Cited Researcher (HC), from\n2016 to 2021. He served or is serving as an Editor\nfor many technical journals, such as the IEEE\nTransactions on Network and Service Manage-\nment, IEEE Transactions ON Cloud Computing,\nIEEE transactions on information forensics And security, IEEE transactions\non cybernetics, ieee transactions on nanobioscience, IEEE transactions on\ninformation technology in biomedicine, ACM transactions on autonomous\nand adaptive systems, and The IEEE journal on selected areas in communi-\ncations.\nTHIPPA REDDY GADEKALLU is with Divi-\nsion of Research and development, Lovely Profes-\nsional University, Phagwara, India, as well as with\nthe Department of Electrical and Computer Engi-\nneering, Lebanese American University, Byblos,\nLebanon and with the Center of Research Impact\nand Outcome, Chitkara University, Punjab, India\nHe obtained his Bachelors in Computer Science\nand Engineering from Nagarjuna University, In-\ndia, in the year 2003, Masters in Computer Science\nand Engineering from Anna University, Chennai, Tamil Nadu, India in the\nyear 2011 and his Ph.D in Vellore Institute of Technology, Vellore, Tamil\nNadu, India in the year 2017. He has more than 14 years of experience\nin teaching. He has more than 150 international/national publications in\nreputed journals and conferences. Currently, his areas of research include\nMachine Learning, Internet of Things, Deep Neural Networks, Blockchain,\nComputer Vision. He is an editor in several publishers like Springer, Hin-\ndawi, Plosone, Scientific Reports (Nature), Wiley. He also acted as a guest\neditor in several reputed publishers like IEEE, Elsevier, Springer, Hindawi,\nMDPI. He is recently recognized as one among the top 2% scientists in the\nworld as per the survey conducted by Elsevier in the year 2021.\n42 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3389497\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/"
}