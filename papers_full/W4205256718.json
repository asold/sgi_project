{
    "title": "Fake or real news about COVID-19? Pretrained transformer model to detect potential misleading news",
    "url": "https://openalex.org/W4205256718",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A5116226660",
            "name": "Malla Sreejagadeesh",
            "affiliations": [
                "National Institute of Technology Tiruchirappalli"
            ]
        },
        {
            "id": "https://openalex.org/A2611006181",
            "name": "Alphonse P J A",
            "affiliations": [
                "National Institute of Technology Tiruchirappalli"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3102344334",
        "https://openalex.org/W3101662265",
        "https://openalex.org/W3034560014",
        "https://openalex.org/W3045460727",
        "https://openalex.org/W3110502180",
        "https://openalex.org/W3110602624",
        "https://openalex.org/W3134036592",
        "https://openalex.org/W3138371708",
        "https://openalex.org/W3017743621",
        "https://openalex.org/W3025578972",
        "https://openalex.org/W3023584357",
        "https://openalex.org/W3017579918",
        "https://openalex.org/W3044217146",
        "https://openalex.org/W3129395136",
        "https://openalex.org/W3170126135",
        "https://openalex.org/W3037623023",
        "https://openalex.org/W3156333129",
        "https://openalex.org/W2909182718",
        "https://openalex.org/W4236122429",
        "https://openalex.org/W2937423263",
        "https://openalex.org/W3030720765",
        "https://openalex.org/W2014545475",
        "https://openalex.org/W3021484963",
        "https://openalex.org/W3146189859",
        "https://openalex.org/W3155280283",
        "https://openalex.org/W3165299977",
        "https://openalex.org/W2163942188",
        "https://openalex.org/W3175127495",
        "https://openalex.org/W3158012322",
        "https://openalex.org/W4200438920",
        "https://openalex.org/W3158488293",
        "https://openalex.org/W3155963088",
        "https://openalex.org/W3166931231",
        "https://openalex.org/W2766411764",
        "https://openalex.org/W2763699126",
        "https://openalex.org/W3098106685",
        "https://openalex.org/W3153760598",
        "https://openalex.org/W6600424091",
        "https://openalex.org/W2808647806",
        "https://openalex.org/W6675354045",
        "https://openalex.org/W3105292134",
        "https://openalex.org/W3105625590",
        "https://openalex.org/W3015269808",
        "https://openalex.org/W4324148013"
    ],
    "abstract": null,
    "full_text": "Eur. Phys. J. Spec. Top. (2022) 231:3347–3356\nhttps://doi.org/10.1140/epjs/s11734-022-00436-6\nTHE EUROPEAN\nPHYSICALJOURNAL\nSPECIAL TOPICS\nRegular Article\nFake or real news about COVID-19? Pretrained\ntransformer model to detect potential misleading news\nSreeJagadeesh Mallaa and P. J. A. Alphonseb\nDepartment of Computer Applications, National Institute of Technology, Thuvakudi, Tiruchirappalli, Tamil Nadu 620015,\nIndia\nReceived 12 October 2021 / Accepted 18 December 2021 / Published online 13 January 2022\n© The Author(s), under exclusive licence to EDP Sciences, Springer-Verlag GmbH Germany, part of\nSpringer Nature 2022\nAbstract The World Health Organization declared the novel coronavirus disease 2019 a pandemic on March\n11, 2020. Along with the coronavirus pandemic, a new crisis has emerged, characterized by widespread fear\nand panic caused by a lack of information or, in some cases, outright fake messages. In these circumstances,\nTwitter is one of the most eminent and trusted social media platforms. Fake tweets, on the other hand,\nare challenging to detect and diﬀerentiate. The primary goal of this paper is to educate society about the\nimportance of accurate information and prevent the spread of fake information. This paper has investigated\nCOVID-19 fake data from various social media platforms such as Twitter, Facebook, and Instagram.\nThe objective of this paper is to categorize given tweets as either fake or real news. The authors have\ntested various deep learning models on the COVID-19 fake dataset. Finally, the CT-BERT and RoBERTa\ndeep learning models outperformed other deep learning models like BERT, BERTweet, AlBERT, and\nDistlBERT. The proposed ensemble deep learning architecture outperformed CT-BERT and RoBERTa\non the COVID-19 fake news dataset using the multiplicative fusion technique. The proposed model’s\nperformance in this technique was determined by the multiplicative product of the ﬁnal predictive values\nof CT-BERT and RoBERTa. This technique overcomes the disadvantage of these CT-BERT and RoBERTa\nmodels’ incorrect predictive nature. The proposed architecture outperforms both well-known ML and DL\nmodels, with 98.88% accuracy and a 98.93% F1-score.\n1 Introduction\nReports of Wuhan Municipal Health Commission,\nChina, have mentioned the coronavirus evolution on\nDec 31st, 2019. It was initially named SARS-CoV-2.\nLater on Jan 12th, 2020, World Health Organization\n(WHO) renamed this disease like the 2019 novel coron-\navirus (2019-nCoV). On Jan 30th, 2020, a health emer-\ngency was declared by WHO. Upon subsequent discus-\nsions on this disease outbreak, it was renamed coron-\navirus disease 2019 (COVID-19) on Feb 11th,2020. This\nCOVID-19 pandemic has tremendously aﬀected world-\nwide, and it faces an incredible threat to public health,\nfood systems, psychology, and workplace safety.\nAccording to the survey, COVID-19 is caused by\nthe SARS-CoV-2 virus, which spreads from person to\nperson, especially when they are in immediate con-\ntact. Furthermore, when people cough, sneeze, speak,\nsing, or breathe loudly, the virus can spread from an\ninfected person to close contacted people. To deal with\nthese critical pandemic situations, the government has\npromoted physical distancing by limiting close face-to-\na e-mail: malla.sree@gmail.com (corresponding author)\nb e-mail: alphonse@nitt.edu\nface contact with others. Further to reduce the disease\nspread, the government has established cantonment\nzones where positive cases have considerably increased.\nHence it is highly essential to alarm the social organiza-\ntions and government organizations to avoid the spread\nof disease to other regions that are not aﬀected. Social\nmedia has taken an active step in developing contact\nwith and through various sectors of people across the\nglobe. Especially in critical times, Twitter content indi-\nviduals can interact with each other during the lock-\ndown period, update their knowledge about the dis-\nease, and take the necessary steps to get rid of the\ndisease outbreak. During the lockdown era, precautions\nlike physical separation, wearing a mask, keeping rooms\nadequately aired, avoiding crowds, washing hands, and\ncoughing into a tissue or bent elbow were adopted. This\ninformation was updated to the public consistently by\nTwitter posts.\nThe COVID-19 pandemic has had a negative impact\non the world in a variety of areas, including pub-\nlic health, tourism, business, economics, politics, edu-\ncation, and people’s lifestyle. In the last two years,\nresearchers have paid more attention to COVID-19.\nSome researchers have concentrated on Natural Lan-\nguage Processing [ 1–3], which includes disease symp-\n123\n3348 Eur. Phys. J. Spec. Top. (2022) 231:3347–3356\nTable 1 Diﬀerent COVID-19 disease related tweets\nFake COVID-19 tweet\n Video of Muslims violating lockdown conditions in old city (Hyderabad)\n A photo shows a 19-year-old vaccine for canine coronavirus that\ncould be used to prevent the new coronavirus causing COVID-19\nReal COVID-19 tweet\n A common question: why are the cumulative outcome numbers smaller than the current outcome numbers? A: most\n States reported 1121 deaths a small rise from last Tuesday. Southern states reported 640 of those deaths\ntoms, medical reports of COVID patients, patient\nhealth conditions, information about pandemic preven-\ntions and precautions, and social media messages/tweets,\namong other things. Other researchers concentrate on\nimage processing [ 4–6], which includes patient X-ray\nanalysis to conﬁrm whether the COVID-19 is positive or\nnegative. During the COVID-19 outbreak, respiratory\nanalysis research became popular [7–10]. Deep learning\nmodels were used to categorize the respiratory sounds\nof patients in this study, yielding better results. Math-\nematical researchers are more focused on COVID-19\nstatistical reports [11–14], such as the number of cases\nidentiﬁed, the number of deaths, and the number of\npatients recovered, among other things.\nTwitter posts contain both fake and real news\n(source: COVID-19 FakeNews dataset) as shown as\nTable 1. In a real sense, all real news may not be\ninformative. For example, let us consider an accu-\nrate report containing some predictable content along\nwith COVID-19 disease information. Only COVID-19\nrelated content brings much hype to the tweet posted\nin public, and hence it is considered informative. In our\nproposed work, our objective is to highlight such infor-\nmative content from the tweets and predict the severity\nof disease in a particular location based on geolocation,\nage, gender, and time. In detail, what sort of gender\nand where the outbreak of illness tends to be serious is\nidentiﬁed within a particular period.\nThe following are the highlights of this paper.:-\n1. The ensemble transformer model with fusion vector\nmultiplication technique was addressed.\n2. The CT-BERT and RoBERTa transformers are\nutilised in a combination.\n3. The FBEDL paradigm produces signiﬁcant out-\ncomes.\n4. The dataset is based on the most recent COVID-19\nlabelled English fake tweets collection.\n5. The model has a 98.93% F1-score and a 98.88% accu-\nracy in identifying fake tweets.\nFollowing on from the discussion of related work in\nSect. 2, the Sect. 3 delves into methodology and data,\nfollowing with a discussion of the experimental results\nin Sect. 4. In Sect.4, we examine the results and look at\nthe errors, and Sect. 5 bring the paper to a conclusion.\n2 Related work\nThe authors Easwaramoorthy et al. [15] illustrated the\ntransmission rate in both times by comparing and pre-\ndicting the epidemic curves of the ﬁrst and second\nwaves of the COVID-19 pandemic. Kavitha et al. [ 16]\nhave investigated the duration of the second and third\nwaves in India and forecasts the outbreak’s future trend\nusing SIR and fractal models. Gowrisankar et al. [ 17]\nhave explained multifractal formalism on COVID-19\ndata, with the assumption that country-speciﬁc infec-\ntion rates exhibit power law growth.\nMinaee et al. [18] present a detailed quantitative anal-\nysis of over 100 DL models proposed after over 16 pop-\nular text classiﬁcation datasets. Kadhim [19] automat-\nically classiﬁed a collection of documents into one or\nmore known categories. Discussed weighing methods\nand comparison of diﬀerent classiﬁcation techniques.\nAggarwal and Zhai [ 20]h a v ep r e s e n t e das u r v e yo fa\nbroad range of text classiﬁcation algorithms and have\ntalked about classiﬁcation in the database, machine\nlearning, data mining and information retrieval com-\nmunities, as well as target marketing, medical diag-\nnosis, news group ﬁltering, and document organisa-\ntion. Kowsari et al. [ 21] have discussed diﬀerent text\nfeature extractions, dimensionality reduction methods,\nexisting algorithms and techniques, and evaluations\nmethods along with real-world problems. De Beer and\nMatthee [22] have pointed various language approaches\nlike Topic-Agnostic, machine learning and knowledge\nbased.\nUysal and Gunal [ 23] have discussed the impact of\npreprocessing on text classiﬁcation in terms of classiﬁ-\ncation accuracy, text domain, dimension reduction and\ntext language. Wenet al. [24] employ a clarity map by\nusing two-channel convolutional network and morpho-\nlogical ﬁltering. The fusion image is created by combin-\ning the clear parts of the source images. Castillo Ossa\net al. [25] have developed a hybrid model that combines\nthe population dynamics of the SIR model of diﬀeren-\ntial equations with recurrent neural network extrapola-\ntions. Wiysobunriet al. [26] have presented an ensemble\ndeep learning system based on the Max (Majority) vot-\ning scheme with VGG-19, DenseNet201, MobileNet-V2,\nResNet34, and ResNet50 for the automatic detection of\nCOVID-19 disease using chest X-ray images.\nTable 2, The identiﬁcation and classiﬁcation of\ntweets related to disaster and current disease pan-\ndemic COVID-19 have been discussed. It has covered\n123\nEur. Phys. J. Spec. Top. (2022) 231:3347–3356 3349\nTable 2 Summary for text classiﬁcation based papers\nS. no. Year Author and Paper Important discussed topic Model/technique\n1 2021 Madichetty and Sridevi\n[27]\nDetecting situational\ntweets in the aftermath\nof a disaster.\nFeature-based approach\nand Fine-tuned\nRoBERTa model.\n2 2021 Malla and Alphonse\n[28]\nDetection of useful\ninformation tweets about\nCOVID-19\nMajority voting technique,\nRoBERTa, BERTweet,\nand CT-BERT\n3 2020 Jagadeesh and\nAlphonse [1]\nIdentify and classify\ninformative COVID-19\ntweets\nRoBERTa\n4 2007 Danesh et al. [ 29] An ensemble ML model\nfor text classiﬁcation.\nNaive-Bayes, k-NN\nclassiﬁer and Racchio\nwith fusion method\n5 2021 Kranthi Kumar and\nAlphonse [30]\nImpact of respiratory\nsounds on COVID-19\ndisease identiﬁcation\nCNN\nTable 3 COVID-19 fake tweets detection papers summary\nS. no. Year Author and Paper Model Accuracy F1-score\n1 2020 Gautam et al. [ 31] XLNet + LDA 93.90 94.00\n2 2021 Shushkevich and Cardiﬀ [ 32] Ensemble model 93.90 94.00\n3 2020 Glazkova et al. [ 33] CT-BERT+ hard voting 98.50 98.69\n4 2021 Paka et al. [ 34] BERTa + BiLSTM 95.40 95.30\n5 2021 Li et al. [ 35] BiLSTM 89.00 88.00\n6 2017 Singhania et al. [ 36] 3HAN + features 96.30 96.77\n7 2021 Ahmed et al. [ 37] LSVM + TF-IDF 92.15 92.08\nthe summary of text mining and sentiment analysis-\nbased papers based on AI techniques. In this table,\nWe have represented the published year, author with\nthe cited article, the main content in that paper, and\nmodel or approach used in that paper. Machine Learn-\ning models have explained Naive Bayes and k-NN clas-\nsiﬁer for text classiﬁcation with the help of the top-\nmost frequency word features and low-level lexical fea-\ntures. Transformer pre-trained deep learning models\nCT-BERT, BERTweet, RoBERTa, and other models\noutperformed traditional machine learning models and\nneural networks (CNN)\nTable 3 has explained the summary for COVID-19\nfake news detection-based papers. As shown in the\ntable, the authors have discussed the automatic fake\nnews detection AI models (on the diﬀerent dataset)\nwith performance metrics as F1-score and accuracy.\nTransformer model papers have achieved good results\nthan other Artiﬁcial Intelligence models.\n3 Framework methodology\nDuring the COVID-19 epidemic, the FBEDL model\ndetects fake COVID-19 tweets with an accuracy of\n98.88% and an F1-score of 98.93%. Figure 1 depicts\na high-level overview of the FBEDL model. The follow-\ning subsections go over the FBEDL model in greater\ndepth: The FBEDL model’s data collection and it’s pre-\nprocessing are described in Section A and B. Section C\nand D describes the pre-trained deep learning classi-\nﬁers and section E had discussed fusion multiplication\ntechnique.\n3.1 Tweets collection and data preprocessing\nIn the COVID-19 pandemic (2020), organizers provided\nthe COVID-19 fake news English dataset [38] with the\nid, tweet, label (“Fake” and “Real”) in the tsv for-\nmat. Data is collected from the organizers of the Con-\nstraint@AAAI2021 workshop [39]. The organisers con-\nsidered only textual English contents and captured a\ngeneric corpus linked to the coronavirus epidemic using\na predetermined list of ten keywords including: COVID-\n19, cases, coronavirus, deaths, tests, new, people, num-\nber and total. The attained tweets are preprocessed\nusing the methods described below.\n3.2 Preprocessing of data\nIn Twitter information, there is a lot of noise. As a\nresult, pre-trained models may beneﬁt from data prepa-\nration. The following data preprocessing steps were\ninspired primarily by [40].\n123\n3350 Eur. Phys. J. Spec. Top. (2022) 231:3347–3356\nFig. 1 Overview of the proposed (FBEDL) ensemble deep\nlearning model\n1. Remove all English stop words and non alphanu-\nmeric characters.\n2. Remove tabs, newlines and unnecessary spaces.\n3. All links in the tweets (shown as HTTPURL) are\nreplaced with URL.\nBecause the user handles in the tweets had already\nbeen replaced by @USER, no further processing was\nrequired.\n3.3 RoBERTa\nRoBERTa [41] improves on BERT by deleting the next-\nsentence pretraining target and train with considerably\nlearning rates and huge mini-batches, as well as mod-\nifying important hyper parameters. Google announced\ntransformer method, which has improved the NLP\n(Natural Language Processing) systems using encoder\nrepresentations. RoBERTa enhanced the eﬃciency than\nBERT, which increased the beneﬁt of the masked lan-\nguage modelling objective. Furthermore, when com-\npared to the base BERT model, RoBERTa is explored\nwith higher magnitude data.\nRoBERTa is a retraining of BERT with improved\ntraining methodology, 1000% more data, and compute\npower. So it outperforms both BERT and XLNet. But\ngenerally, the text is derived from all sources of text\n(not only tweets).\nFor the given COVID-19 fake dataset, the model\nhas trained using various hyperparameter combinations\n(learning rate and batch size). The four metric parame-\nters used to evaluate the results obtained for each com-\nbination are accuracy, recall, precision and F1-score.\nThis model has been trained on the COVID-19 English\nfake dataset with batch sizes of 8, 16, and 32. How-\never, the model performs well when the batch size\nis 8 and the learning rate is 1.12e −05 as shown in\nTable 4. This results may vary from dataset to dataset.\nFinally, RoBERTa’s performance measures are accu-\nracy of 98.55, F1-score of 98.62, recall of 98.84, and\nprecision of 98.40, all of which improves the proposed\nFBEDL model’s performance.\n3.4 CT-BERT\nCT-BERT (COVID-Twitter-BERT) [40], a recent trans-\nformer based model, which has trained on a massive\ncorpus of Twitter tweets on the issue of current on\ngoing COVID-19 outbreak. This model shows a bet-\nter improvement of 05–10% when compared to its basic\nmodel, BERT-LARGE. The most substantial improve-\nments have been made to the target domain. CT-BERT\nas well as other pretrained transformer models are\ntrained on a speciﬁc target domain and can be used\nfor a variety of NLP tasks, such as mining and analy-\nsis. CT-BERT was designed with COVID-19 content in\nmind.\nCovid Twitter-BERT includes domain (COVID-19)\nas well as speciﬁc information, and it can better han-\ndle noisy texts like tweets. CT-BERT performs simi-\nlarly well on other classiﬁcation problems on COVID-\n19-related data sources, particularly on text derived\nfrom social media platforms.\nFor the given COVID-19 fake dataset, this model\nhas trained using various hyperparameter combinations\n(batch size and learning rate). As indicated in Table5,\nthe best results were obtained when the batch size was\nequal to 8 and the learning rate was equal to 1.02e-06.\nThe CT-BERT model’s results may vary from dataset\nto dataset. Finally, CT-performance BERT’s metrics\n123\nEur. Phys. J. Spec. Top. (2022) 231:3347–3356 3351\nTable 4 RoBERTa results have obtained using the test data set\nEpocs bs lr Loss TN FN FP TP Accuracy F1-score Recall Precision\n25 8 1.12e − 05 0.0780 1002 18 13 1107 98.55 98.62 98.84 98.40\nare accuracy of 98.22, F1-score of 98.32, recall of 99.02,\nand precision of 97.62, all of which improve the perfor-\nmance of the proposed FBEDL model.\n3.5 Fusion vector multiplication\nTo overcome the disadvantages of CT-BERT and\nRoBERTa models, an ensemble model is introduced.\nFor concatenation of output for internal models, fusion\ntechniques are more popular. These techniques include\nmax, min, mean, avg, sum, diﬀerence, and product\nprobability values.\nThe probability vector of a tweet is calculated using\nthe ﬁne-tuned RoBERTa model and the CT-BERT\nmodel. The multiplicative fusion technique [ 42] per-\nforms element-wise multiplication to combine both\n(array of the last layer) probability vectors into a single\nvector [27]. The predicted tweet label is based on the\ngenerated vector.\nA =\n⎡\n⎢⎢\n⎢⎣\na\n1 b1\na2 b2\n..\n..\nan bn\n⎤\n⎥⎥\n⎥⎦ (1)\nB =\n⎡\n⎢⎢\n⎢⎣\nc\n1 d1\nc2 d2\n..\n..\ncn dn\n⎤\n⎥⎥\n⎥⎦ (2)\nwhere a\ni + bi =1a n d ci + di =1\nwhere ai and bi are the probabilities of fake and real\nnews of ith tweet from RoBERTa model respectively\nand ci and di are the probabilities of fake and real\nnews of ith tweet from CT-BERT model respectively.\nConsider A is the probability vector (last layer) of the\nRoBERTa and B is the probability vector (last layer)\nof the CT-BERT. The fusion vector multiplication of\nA, B is FVM(A, B )= AB (single vector)\nFVM(A, B )=\n⎡\n⎢⎢⎢⎣\na1 ∗ c1 b1 ∗ d1\na2 ∗ c2 b2 ∗ d2\n..\n..\nan ∗ cn bn ∗ dn\n⎤\n⎥⎥⎥⎦ (3)\nFBEDL_Test(tweeti)=\n⎧\n⎨\n⎩\nFake, if ai ∗ ci >b i ∗ di\nReal, if ai ∗ ci <b i ∗ di\nNeutral, otherwise\n(4)\nAlgorithm 1 Proposed Method based on Fusion vector\nmultiplication Technique\n1: 0: COVID-19 Fake tweet.\n2: 1: COVID-19 Real News/tweet\n3: A: An array of ROBERTA model probability vector (last\nlayer).\n4: B: An array of CT-BERT model probability vector (last\nlayer).\n5: S: Size of Test dataset\n6: Input:S ,A , B\n7: Steps:\n8: for k = 1 to size of (S)\n9: Final _prediction_value = FVM(A\nk ,B k )\n10: end\n11: Output:F i n a l_prediction_value (0, 1) (ie: Fake, Real)\nwhere ai, ci are the ﬁrst column ith elements of A and\nB respectively.\nwhere bi,d i are the second column ith elements of A\nand B respectively.\nFrom Eq. ( 4), The following possible observations\nare:\n1. if ai ∗ ci >b i ∗ di then the proposed model predicts\nthe tweet as “Fake”.\n2. if ai ∗ ci <b i ∗ di then the proposed model predicts\nthe tweet as “Real”.\n3. Our proposed model is trained and tested by Fake\nnews COVID-19 dataset (ie Fake, Real). In this case\nNeutral case is very rare to occur.\n4 Results and analysis\nAll of our experiments in this paper have been com-\npleted using the Google Colaboratory (CoLab) interface\nand the Chrome browser. This section covers data sets,\nmodel parameter explanations, and performance evalu-\nations. Furthermore, the proposed solution is evaluated\nin comparison to existing methods. The Huggingface\npackage [43] has used in the implementation through\nPython. The “ktrain” package [ 44] has been used to\nﬁne-tune our baseline models.\n4.1 Fake news COVID-19 dataset\nIn the COVID-19 outbreak (2020), Constraint@AAAI\n2021 workshop organizers provided the COVID-19 fake\nnews English dataset [ 38] with the id, tweet, label\n(“Fake” and “Real”) in the form of tsv. The above\ndataset, which contains fake news collected from tweets,\n123\n3352 Eur. Phys. J. Spec. Top. (2022) 231:3347–3356\nTable 5 CT-BERT results from the test dataset\nEpocs bs lr Loss TN FN FP TP Accuracy Recall Precision F1-score\n25 8 1.02e − 06 0.0313 993 27 11 1109 98.22 99.02 97.62 98.32\nTable 6 COVID-19 fake english data set details\nFake news (COVID-19) dataSet Fake Real\nTraining data 3060 3360\nValidation data 1020 1120\nTest data 1020 1120\ninstagram posts, facebook posts, press releases, or any\nother popular media content, has a size of 10,700\nrecords. Using the Twitter API, real news was gath-\nered from potential real tweets. Oﬃcial accounts such\nas the Indian Council of Medical Research (ICMR), the\nWorld Health Organization (WHO), the Centers for\nDisease Control and Prevention (CDC), Covid India\nSeva, and others may have real tweets. They give valu-\nable COVID-19 information such as vaccine progress,\ndates, hotspots, government policies, and so on.\nThe dataset is divided into three sections: 60% for\ntrain, 20% for validation, and 20% for testing. Table 6\nillustrates the distribution of all data splits by class.\nThe dataset with 52.34% of the samples containing\nlegitimate news and 47.66% including fraudulent news.\n4.2 Experiment setup\nThe outcome of the model is dependent on the use of a\nclassiﬁer. As a result, the following classiﬁers are used\nto conduct various tests.\n1. CT-BERT transformer model.\n2. RoBERTa transformer model.\n3. Fusion vector multiplication technique.\n4.3 Performance measures\nThe model performance is evaluated using the following\nparameters: Precision, F1-score, Accuracy, and Recall.\nThese metrics have been depended on the confusion\nmatrix.\n4.3.1 Confusion matrix\nThe performance of a classiﬁcation model has been eval-\nuated by an N × N matrix, where N indicates number\nof target classes. For binary classiﬁcation N is equals\nto 2, so a 2× 2 matrix containing four values, as shown\nbelow.\nTrue Positive (TP): the expected and actual values\nare identical. The model actual result was positive and\nanticipated a positive value. True Negative (TN): the\nexpect value comparable to the real value. The model\nactual value is negative and the anticipated a nega-\ntive value. False Positive (FP): The expected value has\nincorrectly predicted. Although the actual number is\nnegative, the model projected that it would be posi-\ntive.\nFalse Negative (FN): the expected value is incorrectly\npredicted. Although the actual number was positive,\nthe model predicted that it would be negative.\n4.4 Performance analysis\nThere are three subsections in this section. The perfor-\nmance of the ML (machine learning) models are com-\npared in the ﬁrst subsection. In the second subsection,\nthe performance of the deep learning models are com-\npared. The proposed model’s performance is compared\nto existing approaches in the third subsection.\n4.4.1 Performance metrics in machine learning models\nThe Constraint@AAAI2021 workshop organisers have\nprovided baseline results for the English COVID-19\nfake dataset. Logistic Regression, Decision Tree, Gra-\ndient Boost and SVM have been considered for base-\nline results for predicting fake news tweets. The Sup-\nport Vector Machines (SVM) classiﬁer has achieved an\naccuracy of 93.32%, F1-score of 93.32%, precision of\n93.33%, and recall of 93.32%. As a result, the SVM\nclassiﬁer outperformed all metrics values as shown as\nTable 7.\n4.4.2 Deep Learning models performance metrics\nevaluation\nThe transformer pretrained deep learning models like\nDistliBERT, ALBERT, BERT, BERTweet, RoBERTa\nand CT-BERT have been considered in this subsection.\nThe MAX\n_LENGTH(tweet) has been ﬁxed to 143 in\norder to train the model’s better with the English lan-\nguage corpus. The tweets that are being tested are in\nEnglish. For training the models and learning the rate\nof values 1e−4, 1e−5, 1e−6, 1e−7, 1e−8 and tested with\nbatch sizes of 8, 16, and 32.\nCT-BERT and RoBERTa have occupied ﬁrst two\nplaces as shown in the Table 8 than the BERTweet,\nBERT, DistilBERT, and ALBERT models as exhibit in\nFig. 2a–d. They outperformed the other competitors in\nthe race, according to the experiment results, because\nthey had higher TP (true positive) and FN (false neg-\native) values. CT-BERT performed well because it has\npre-trained on a large corpus of COVID-19-related\nTwitter messages.\n123\nEur. Phys. J. Spec. Top. (2022) 231:3347–3356 3353\nTable 7 Machine learning models: results from the test data set\nModel Accuracy F1-score Precision Recall\nDecisionTree 85.37 85.39 85.47 85.37\nLogistic Regression 91.96 91.96 92.01 91.96\nSupport Vector Machine 93.32 93.32 93.33 93.32\nGradient Boost 86.96 86.96 87.24 86.96\nTable 8 Deep learning models: results from the test data set\nModel TN FN FP TP Accuracy F1-score Precision Recall\nALBERT 937 83 62 1058 93.22 93.59 94.46 92.73\nDistilBERT 988 32 20 1100 97.57 97.69 98.21 97.17\nBERT 988 32 13 1107 97.90 98.00 98.84 97.19\nBERTweet-COVID-19 992 28 16 1104 97.94 98.05 98.57 97.53\nCT-BERT 993 27 11 1109 98.22 98.32 99.02 97.62\nRoBERTa 1002 18 13 1107 98.55 98.62 98.84 98.40\nFig. 2 Deep learning\nmodels performance in\nterms of evaluation metrics\n(a)Accuracy (b)F1-score\n(c) Precision (d)Recall\n4.4.3 Ensemble deep learning models performance\nmetrics\nThis segment examined modern ensemble deep learn-\ning models. The ensemble model with BiLSTM + SVM\n+ Linear regression + Navaiy Baiyes + combination of\nLR+NB has obtained F1-score as 94% and accuracy as\n93.90%. The combination of XLNet and LDA technique\nhas given F1-score as 96.70% and accuracy as 96.60%.\nThe ensemble model using CT-BERT and hard vot-\ning technique has given better performance than other\nensemble models.\n4.5 Performance comparison: proposed model\nversus ensemble deep learning techniques\nThe proposed model (FBEDL) is evaluated in terms of\naccuracy and F1-score to the machine learning models,\ndeep learning models, and ensemble models. In com-\nparison to existing models, our FBEDL model attained\nan F1 score of 98.93% and an accuracy of 98.88%, as\nshown in Tables9 and 10 as well as Fig.3. This indicates\nthat the model was successful in distinguishing fake\ntweets/News about the COVID-19 disease outbreak.\n123\n3354 Eur. Phys. J. Spec. Top. (2022) 231:3347–3356\nTable 9 Performance comparison: proposed model versus\nexisting models\nModel F1-score Accuracy\nDecision Tree [38] 85.39 85.37\nGradient Boost [38] 86.96 86.96\nLogistic Regression [38] 91.96 91.96\nSupport Vector Machine [38] 93.32 93.32\n(Baseline)\nXLNet + LDA [31] 96.70 96.60\nEnsemble [32] 94.00 93.90\nCT-BERT + hard voting [33] 98.69 98.50\nProposed model (FBEDL) 98.93 98.88\nTable 10 FBEDL model results from the test dataset\nF1-score Accuracy Recall precision\n98.93 98.88 98.75 99.11\n5 Conclusion\nThe principal goal of this work is to demonstrate\nhow to use a novel NLP application to detect real or\nfake COVID-19 tweets. The conclusions of the paper\nassist individuals in avoiding hysteria about COVID-19\ntweets. Our ﬁndings may also aid in the improvement\nof COVID-19 therapies and public health measures.\nIn this study, a fusion technique-based ensemble deep\nlearning model is used to detect fraudulent tweets in\nthe ongoing COVID-19 epidemic. The use of fusion\nvector multiplication is designed to help our model\nbecome more entrenched. We tried various deep learn-\ning model combinations to improve model performance,\nbut COVID-Twitter BERT and RoBERTa deep learn-\ning models have achieved state-of-art performance.\nWith 98.88% accuracy and a 98.93% F1-score, the pro-\nposed model outperforms traditional machine learning\nand deep learning models.\nOne of the disadvantages of our proposed model is\nthat RoBERTa and CT-BERT are pre-trained mod-\nels with a lot of memory for corpus training (657MB\nand 1.47GB, respectively). When compared to machine\nlearning models, the models’ time complexity is likewise\nrelatively high. To boost model performance, we plan\nto apply data compression techniques\nThis research focuses on COVID-19 pandemic English\nfake tweets for the time being. Our method may be able\nto predict fake tweets about diseases that are similar in\nthe future. We can improve our results in the future by\ntraining other combinations on a sizeable COVID-19\ndataset using alternative transformer-based models.\nFig. 3 Performance: proposed model versus state-of-art models\n123\nEur. Phys. J. Spec. Top. (2022) 231:3347–3356 3355\nDeclarations\nConﬂict of interest The authors declare no competing\ninterests.\nReferences\n1. M.S. Jagadeesh, P.J.A. Alphonse, NIT _COVID-19 at\nWNUT-2020 task 2: deep learning model RoBERTa for\nidentify informative COVID-19 English tweets. In: Pro-\nceedings of the Sixth Workshop on Noisy User-generated\nText (W-NUT 2020), pp. 450–454. Association for Com-\nputational Linguistics, Online (2020). https://doi.org/\n10.18653/v1/2020.wnut-1.66\n2. Y. Prakash Babu, R. Eswari, CIA _NITT at WNUT-\n2020 task 2: classiﬁcation of COVID-19 tweets using\npre-trained language models. In: Proceedings of the\nSixth Workshop on Noisy User-generated Text (W-NUT\n2020), pp. 471–474. Association for Computational Lin-\nguistics, Online (2020). https://doi.org/10.18653/v1/\n2020.wnut-1.70\n3. M. Jamshidi, A. Lalbakhsh, J. Talla, Z. Peroutka, F.\nHadjilooei, P. Lalbakhsh, M. Jamshidi, L. La Spada, M.\nMirmozafari, M. Dehghani et al., Artiﬁcial intelligence\nand Covid-19: deep learning approaches for diagnosis\nand treatment. IEEE Access 8, 109581–109595 (2020)\n4. S. Minaee, R. Kaﬁeh, M. Sonka, S. Yazdani, G.J.\nSouﬁ, Deep-Covid: predicting Covid-19 from chest X-ray\nimages using deep transfer learning. Med. Image Anal.\n65, 101794 (2020)\n5. R. Maroldi, P. Rondi, G.M. Agazzi, M. Ravanelli, A.\nBorghesi, D. Farina, Which role for chest X-ray score\nin predicting the outcome in Covid-19 pneumonia? Eur.\nRadiol. 31(6), 4016–4022 (2021)\n6. M.A. Al-antari, C.-H. Hua, J. Bang, S. Lee, Fast deep\nlearning computer-aided diagnosis of Covid-19 based on\ndigital chest X-ray images. Appl. Intell. 51(5), 2890–\n2907 (2021)\n7. K.K. Lella, P. Alphonse, A literature review on Covid-\n19 disease diagnosis from respiratory sound data. AIMS\nBioeng. 8(2), 140–153 (2021)\n8. K.K. Lella, A. Pja, Automatic Covid-19 disease diagno-\nsis using 1D convolutional neural network and augmen-\ntation with human respiratory sound based on parame-\nters: cough, breath, and voice. AIMS Public Health8(2),\n240 (2021)\n9. L. Gattinoni, D. Chiumello, P. Caironi, M. Busana, F.\nRomitti, L. Brazzi, L. Camporota,COVID-19 Pneumo-\nnia: Diﬀerent Respiratory Treatments for Diﬀerent Phe-\nnotypes? (Springer, Berlin, 2020)\n10. J.J. Marini, L. Gattinoni, Management of Covid-19 res-\npiratory distress. JAMA 323(22), 2329–2330 (2020)\n11. M. Mandal, S. Jana, S.K. Nandi, A. Khatua, S. Adak,\nT. Kar, A model based study on the dynamics of Covid-\n19: prediction and control. Chaos Solitons Fract. 136,\n109889 (2020)\n12. A. Kumar, K.R. Nayar, S.F. Koya, Covid-19: challenges\nand its consequences for rural health care in India. Pub-\nlic Health Pract. 1, 100009 (2020)\n13. J.D. Norrie, Remdesivir for Covid-19: challenges of\nunderpowered studies. Lancet 395(10236), 1525–1527\n(2020)\n14. A. Ghosh, S. Nundy, T.K. Mallick, How India is dealing\nwith Covid-19 pandemic. Sens. Int. 1, 100021 (2020)\n15. D. Easwaramoorthy, A. Gowrisankar, A. Manimaran, S.\nNandhini, L. Rondoni, S. Banerjee, An exploration of\nfractal-based prognostic model and comparative analy-\nsis for second wave of COVID-19 diﬀusion. Nonlinear\nDyn. 106(2), 1375–1395 (2021)\n16. C. Kavitha, A. Gowrisankar, S. Banerjee, The second\nand third waves in India: when will the pandemic be\nculminated? Eur. Phys. J. Plus 136(5), 1–12 (2021)\n17. A. Gowrisankar, L. Rondoni, S. Banerjee, Can India\ndevelop herd immunity against Covid-19? Eur. Phys.\nJ. Plus 135(6), 1–9 (2020)\n18. S. Minaee, N. Kalchbrenner, E. Cambria, N. Nikzad,\nM. Chenaghlu, J. Gao, Deep learning-based text classi-\nﬁcation: a comprehensive review. ACM Comput. Surv.\n(CSUR) 54(3), 1–40 (2021)\n19. A.I. Kadhim, Survey on supervised machine learning\ntechniques for automatic text classiﬁcation. Artif. Intell.\nRev. 52\n(1), 273–292 (2019)\n20. C.C. Aggarwal, C. Zhai, A survey of text classiﬁcation\nalgorithms. in Mining Text Data, ed. by C. Aggarwal,\nC.Zhai (Springer, Boston, 2012)\n21. K. Kowsari, K. Jafari Meimandi, M. Heidarysafa, S.\nMendu, L. Barnes, D. Brown, Text classiﬁcation algo-\nrithms: a survey. Information 10(4), 150 (2019)\n22. D. De Beer, M. Matthee, Approaches to identify fake\nnews: a systematic literature review. In: International\nConference on Integrated Science, pp. 13–22. Springer\n(2020)\n23. A.K. Uysal, S. Gunal, The impact of preprocessing on\ntext classiﬁcation. Inf. Process. Manag. 50(1), 104–112\n(2014)\n24. Y. Wen, X. Yang, T. Celik, O. Sushkova, M.K. Alber-\ntini, Multifocus image fusion using convolutional neural\nnetwork. Multimed. Tools Appl. 79(45), 34531–34543\n(2020)\n25. L.F. Castillo Ossa, P. Chamoso, J. Arango-L´ opez, F.\nPinto-Santos, G.A. Isaza, C. Santa-Cruz-Gonz´alez, A.\nCeballos-Marquez, G. Hern´andez, J.M. Corchado, A\nhybrid model for Covid-19 monitoring and prediction.\nElectronics 10(7), 799 (2021)\n26. B.N. Wiysobunri, H.S. Erden, B.U. Toreyin, An ensem-\nble deep learning system for the automatic detection of\nCOVID-19 in X-ray images (2020)\n27. S. Madichetty, M. Sridevi, A neural-based approach for\ndetecting the situational information from Twitter dur-\ning disaster. IEEE Trans. Comput. Soc. Syst. (2021)\n28. S. Malla, P. Alphonse, COVID-19 outbreak: an ensem-\nble pre-trained deep learning model for detecting infor-\nmative tweets. Appl. Soft Comput.107, 107495 (2021).\nhttps://doi.org/10.1016/j.asoc.2021.107495\n29. A. Danesh, B. Moshiri, O. Fatemi, Improve text clas-\nsiﬁcation accuracy based on classiﬁer fusion methods.\nIn: 2007 10th International Conference on Information\nFusion, pp. 1–6. IEEE (2007)\n30. L. Kranthi Kumar, P.J.A. Alphonse, Automatic diag-\nnosis of Covid-19 disease using deep convolutional neu-\nral network with multi-feature channel from respiratory\n123\n3356 Eur. Phys. J. Spec. Top. (2022) 231:3347–3356\nsound data: cough, voice, and breath. Alex. Eng. J.\n(2021). https://doi.org/10.1016/j.aej.2021.06.024\n31. A. Gautam, S. Masud, et al., Fake news detection\nsystem using xlnet model with topic distributions:\nconstraint @ aaai2021 shared task. arXiv preprint\narXiv:2101.11425 (2021)\n32. E. Shushkevich, J. Cardiﬀ, Tudublin team at\nconstraint@aaai2021—covid19 fake news detection.\narXiv preprint arXiv:2101.05701 (2021)\n33. A. Glazkova, M. Glazkov, T. Trifonov, g2tmn at\nconstraint@aaai2021: exploiting ct-bert and ensem-\nbling learning for Covid-19 fake news detection. arXiv\npreprint arXiv:2012.11967 (2020)\n34. W.S. Paka, R. Bansal, A. Kaushik, S. Sengupta, T.\nChakraborty, Cross-sean: a cross-stitch semi-supervised\nneural attention model for Covid-19 fake news detec-\ntion. Appl. Soft Comput. 107, 107393 (2021)\n35. X. Li, P. Lu, L. Hu, X. Wang, L. Lu, A novel self-learning\nsemi-supervised deep learning network to detect fake\nnews on social media. Multimed. Tools Appl. (2021).\nhttps://doi.org/10.1007/s11042-021-11065-x\n36. S. Singhania, N. Fernandez, S. Rao, 3han: a deep neural\nnetwork for fake news detection. In: International Con-\nference on Neural Information Processing, pp. 572–581.\nSpringer (2017)\n37. H. Ahmed, T. Traore, S. Saad, Detection of online\nfake news using n-gram analysis and machine learn-\ning techniques. In: International Conference on Intel-\nligent, Secure, and Dependable Systems in Distributed\nand Cloud Environments, pp. 127–138. Springer (2017)\n38. P. Patwa, S. Sharma, S. Pykl, V. Guptha, G. Kumari,\nM.S. Akhtar, A. Ekbal, A. Das, T. Chakraborty, Fight-\ning an infodemic: COVID-19 fake news dataset. in\nInternational Workshop on Combating Online Hostile\nPosts in Regional Languages during Emergency Situa-\ntion (Springer, 2021), pp. 21–29\n39. P. Patwa, M. Bhardwaj, V. Guptha, G. Kumari, S.\nSharma, S. Pykl, A. Das, A. Ekbal, M.S. Akhtar, T.\nChakraborty, Overview of constraint 2021 shared tasks:\ndetecting English Covid-19 fake news and Hindi hostile\nposts. in International Workshop on Combating Online\nHostile Posts in Regional Languages during Emergency\nSituation (Springer, 2021), pp. 42–53\n40. M. M¨uller, M. Salath´ e, P.E. Kummervold, Covid-\ntwitter-bert: a natural language processing model to\nanalyse Covid-19 content on twitter. arXiv preprint\narXiv:2005.07503 (2020)\n41. Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O.\nLevy, M. Lewis, L. Zettlemoyer, V. Stoyanov, Roberta:\na robustly optimized bert pretraining approach. arXiv\npreprint arXiv:1907.11692 (2019)\n42. A. Wu Y. Han, Multi-modal circulant fusion for video-\nto-language and backward. In: IJCAI, vol. 3, p. 8 (2018)\n43. F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R.\nWeiss, V. Dubourg et al., Scikit-learn: machine learning\nin python. J. Mach. Learn. Res. 12, 2825–2830 (2011)\n44. A.S. Maiya, ktrain: a low-code library for augmented\nmachine learning. arXiv preprint arXiv:2004.10703\n[cs.LG] (2020)\n123"
}