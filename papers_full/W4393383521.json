{
    "title": "Assessing the Efficacy of Large Language Models in Health Literacy: AComprehensive Cross-Sectional Study",
    "url": "https://openalex.org/W4393383521",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A4292561262",
            "name": "Kanhai S. Amin",
            "affiliations": [
                "Yale University"
            ]
        },
        {
            "id": "https://openalex.org/A2086560915",
            "name": "Linda C. Mayes",
            "affiliations": [
                "Yale University"
            ]
        },
        {
            "id": "https://openalex.org/A2912455786",
            "name": "Pavan Khosla",
            "affiliations": [
                "Yale University"
            ]
        },
        {
            "id": "https://openalex.org/A4319516725",
            "name": "Rushabh H. Doshi",
            "affiliations": [
                "Yale University"
            ]
        },
        {
            "id": "https://openalex.org/A4292561262",
            "name": "Kanhai S. Amin",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2086560915",
            "name": "Linda C. Mayes",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2912455786",
            "name": "Pavan Khosla",
            "affiliations": [
                "Yale University"
            ]
        },
        {
            "id": "https://openalex.org/A4319516725",
            "name": "Rushabh H. Doshi",
            "affiliations": [
                "Yale University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4200581738",
        "https://openalex.org/W1485761988",
        "https://openalex.org/W2793083959",
        "https://openalex.org/W4387242076",
        "https://openalex.org/W4390123100",
        "https://openalex.org/W4388869628",
        "https://openalex.org/W3210682857",
        "https://openalex.org/W6762852586",
        "https://openalex.org/W2908590016",
        "https://openalex.org/W6665512273",
        "https://openalex.org/W2023080089",
        "https://openalex.org/W2069611505",
        "https://openalex.org/W1556640487",
        "https://openalex.org/W3215984545",
        "https://openalex.org/W3203220777",
        "https://openalex.org/W4392348982",
        "https://openalex.org/W2150943872",
        "https://openalex.org/W263747627",
        "https://openalex.org/W1545548457",
        "https://openalex.org/W2063307665",
        "https://openalex.org/W2058620209",
        "https://openalex.org/W3043437722",
        "https://openalex.org/W2947809974",
        "https://openalex.org/W2267595383",
        "https://openalex.org/W2109113024",
        "https://openalex.org/W4301370144",
        "https://openalex.org/W4362679052",
        "https://openalex.org/W2107102506",
        "https://openalex.org/W2921008746",
        "https://openalex.org/W4289340452",
        "https://openalex.org/W4379378720"
    ],
    "abstract": "Enhanced health literacy in children has been empirically linked to better health outcomes over the long term; however, few interventions have been shown to improve health literacy. In this context, we investigate whether large language models (LLMs) can serve as a medium to improve health literacy in children. We tested pediatric conditions using 26 different prompts in ChatGPT-3.5, ChatGPT-4, Microsoft Bing, and Google Bard (now known as Google Gemini). The primary outcome measurement was the reading grade level (RGL) of output as assessed by Gunning Fog, Flesch-Kincaid Grade Level, Automated Readability Index, and Coleman-Liau indices. Word counts were also assessed. Across all models, output for basic prompts such as \"Explain\" and \"What is (are),\" were at, or exceeded, the tenth-grade RGL. When prompts were specified to explain conditions from the first- to twelfth-grade level, we found that LLMs had varying abilities to tailor responses based on grade level. ChatGPT-3.5 provided responses that ranged from the seventh-grade to college freshmen RGL while ChatGPT-4 outputted responses from the tenth-grade to the college senior RGL. Microsoft Bing provided responses from the ninth- to eleventh-grade RGL while Google Bard provided responses from the seventh- to tenth-grade RGL. LLMs face challenges in crafting outputs below a sixth-grade RGL. However, their capability to modify outputs above this threshold, provides a potential mechanism for adolescents to explore, understand, and engage with information regarding their health conditions, spanning from simple to complex terms. Future studies are needed to verify the accuracy and efficacy of these tools.",
    "full_text": null
}