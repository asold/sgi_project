{
    "title": "Church: a language for generative models",
    "url": "https://openalex.org/W1890754682",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A4202102311",
            "name": "Goodman, Noah",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4286927506",
            "name": "Mansinghka, Vikash",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4221675725",
            "name": "Roy, Daniel M.",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4289466944",
            "name": "Bonawitz, Keith",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2156167480",
            "name": "Tenenbaum, Joshua B.",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W55914417",
        "https://openalex.org/W2098294295",
        "https://openalex.org/W1783388813",
        "https://openalex.org/W2157381218",
        "https://openalex.org/W1517555081",
        "https://openalex.org/W2323803659",
        "https://openalex.org/W2043416466",
        "https://openalex.org/W2117126688",
        "https://openalex.org/W128101668",
        "https://openalex.org/W3199565109",
        "https://openalex.org/W1516735103",
        "https://openalex.org/W1483822067",
        "https://openalex.org/W2166089338",
        "https://openalex.org/W2097266862",
        "https://openalex.org/W2089674328",
        "https://openalex.org/W2158190429",
        "https://openalex.org/W32064870",
        "https://openalex.org/W1551893515",
        "https://openalex.org/W1977970897",
        "https://openalex.org/W181022050",
        "https://openalex.org/W3145738572"
    ],
    "abstract": "We introduce Church, a universal language for describing stochastic generative processes. Church is based on the Lisp model of lambda calculus, containing a pure Lisp as its deterministic subset. The semantics of Church is defined in terms of evaluation histories and conditional distributions on such histories. Church also includes a novel language construct, the stochastic memoizer, which enables simple description of many complex non-parametric models. We illustrate language features through several examples, including: a generalized Bayes net in which parameters cluster over trials, infinite PCFGs, planning by inference, and various non-parametric clustering models. Finally, we show how to implement query on any Church program, exactly and approximately, using Monte Carlo techniques.",
    "full_text": "In Proc. 24th Conf. Uncertainty in Artiﬁcial Intelligence (UAI) , 220–229, 2008. This version contains minor corrections (May 31, 2008).\nChurch: a language for generative models\nNoah D. Goodman∗, Vikash K. Mansinghka∗,\nDaniel Roy, Keith Bonawitz & Joshua B. Tenenbaum\nMIT BCS/CSAIL\nCambridge, MA 02139\nAbstract\nFormal languages for probabilistic modeling\nenable re-use, modularity, and descriptive\nclarity, and can foster generic inference tech-\nniques. We introduce Church, a universal\nlanguage for describing stochastic generative\nprocesses. Church is based on the Lisp model\nof lambda calculus, containing a pure Lisp\nas its deterministic subset. The semantics of\nChurch is deﬁned in terms of evaluation his-\ntories and conditional distributions on such\nhistories. Church also includes a novel lan-\nguage construct, the stochastic memoizer,\nwhich enables simple description of many\ncomplex non-parametric models. We illus-\ntrate language features through several ex-\namples, including: a generalized Bayes net\nin which parameters cluster over trials, inﬁ-\nnite PCFGs, planning by inference, and var-\nious non-parametric clustering models. Fi-\nnally, we show how to implement query on\nany Church program, exactly and approxi-\nmately, using Monte Carlo techniques.\n1 INTRODUCTION\nProbabilistic models have proven to be an enormously\nuseful tool in artiﬁcial intelligence, machine learning,\nand cognitive science. Most often these models are\nspeciﬁed in a combination of natural and mathemat-\nical language, and inference for each new model is\nimplemented by hand. Stochastic programming lan-\nguages [e.g. 12, 14, 10] aim to tame the model-building\nprocess by giving a formal language which provides\nsimple, uniform, and re-usable descriptions of a wide\nclass of models, and supports generic inference tech-\nniques. In this paper we present the Church stochastic\n∗The ﬁrst two authors contributed equally to this work.\nprogramming language (named for computation pio-\nneer Alonzo Church), a universal language for describ-\ning generative processes and conditional queries over\nthem. Because this language is based on Church’s\nlambda calculus, expressions, which represent gener-\native models, may be arbitrarily composed and ab-\nstracted. The distinctive features of Church, and the\nmain contributions of this paper, are: 1) a Lisp-like\nlanguage speciﬁcation in which we view evaluation\nas sampling and query as conditional sampling , 2)\na stochastic memoizer, which allows separate evalua-\ntions to share generative history and enables easy de-\nscription of non-parametric probabilistic models, and,\n3) generic schemes for exact and approximate infer-\nence, which implement the query primitive, so that any\nChurch program may be run without writing special-\npurpose inference code.\n2 THE CHURCH LANGUAGE\nThe Church language is based upon a pure subset\nof the functional language Scheme [ 6], a Lisp dialect.\nChurch is a dynamically-typed, applicative-order lan-\nguage, in which procedures are ﬁrst-class and expres-\nsions are values. Church expressions describe gen-\nerative processes: the meaning of an expression is\nspeciﬁed through a primitive procedure eval, which\nsamples from the process, and a primitive procedure\nquery, which generalizes eval to sample condition-\nally. In true Lisp spirit, eval and query are ordinary\nprocedures that may be nested within a Church pro-\ngram. Randomness is introduced through stochastic\nprimitive functions; memoization allows random com-\nputations to be reused.\nChurch expressions have the form:\nexpression ::= c |x |(e1 e2 ...) |(lambda (x...) e) |\n(if e1 e2 e3) |(define x e) |(quote e)\nHere x stands for a variable (from a countable set of\narXiv:1206.3255v2  [cs.PL]  15 Jul 2014\nvariable symbols), ei for expressions, and cfor a (prim-\nitive) constant. (We often write ’e as shorthand for\n(quote e).)\nThe constants include primitive data types (nil,\nBoolean, char, integer, ﬁxed-precision real, etc.), and\nstandard functions to build data structures (notably\npair, first, and rest for lists) and manipulate basic\ntypes (e.g. and, not)1. As in most programming lan-\nguages, all primitive types are countable; real numbers\nare approximated by either ﬁxed- or ﬂoating-precision\narithmetic. A number of standard (deterministic)\nfunctions, such as the higher-order function map, are\nprovided as a standard library, automatically deﬁned\nin the global environment. Other standard Scheme\nconstructs are provided—such as (let ((a a-def )\n(b b-def ) ...) body), which introduces names that\ncan be used in body, and is sugar for nested lambdas.\nChurch values include Church expressions, and proce-\ndures; if v1...vn are Church values the list (v1...vn) is a\nChurch value. A Church environment is a list of pairs\nconsisting of a variable symbol and a value (the vari-\nable is bound to the value); note that an environment\nis a Church value. Procedures come in two types: Or-\ndinary procedures are triples, (body, args, env), of a\nChurch expression (the body), a list of variable sym-\nbols (the formal parameters, or arguments), and an\nenvironment. Elementary random procedures are or-\ndinary procedures that also have a distribution func-\ntion—a probability function that reports the probabil-\nity P( value |env, args) of a return value from evalu-\nating the body (via the eval procedure described be-\nlow) given env and values of the formal parameters 2.\nTo provide an initial set of elementary random proce-\ndures we allow stochastic primitive functions, in ad-\ndition to the usual constants, that randomly sample\na return value depending only on the current envi-\nronment. Unlike other constants, these random func-\ntions are available only wrapped into elementary ran-\ndom procedures: (fun, args, env, dist), where\ndist = P( value |env, args) is the probability func-\ntion for fun. We include several elementary random\nprocedures, such as flip which ﬂips a fair coin (or ﬂips\na weighted coin when called with a weight argument).\n1The primitive function gensym deserves special note:\n(eval ’(gensym) env) returns a procedure ( c, x, env)\nwhere c is a constant function which returns True if x is\nbound to the procedure ( c, x, env), and False otherwise.\nFurthermore it is guaranteed that (gensym (gensym))\nevaluates to False (i.e. each evaluation of gensym results\nin a unique value).\n2This deﬁnition implies that when the body of an ele-\nmentary random procedure is not a constant, its distribu-\ntion function represents the marginal probability over any\nother random choices made in evaluating the body. This\nbecomes important for implementing query.\nA Church expression deﬁnes a generative process via\nthe recursive evaluation procedure, eval. This prim-\nitive procedure takes an expression and an environ-\nment and returns a value—it is an environment model,\nshared with Scheme, of Church’s lambda calculus\n[4, 6]. The evaluation rules are given in Fig. 1. An\nevaluation history for an expression eis the sequence of\nrecursive calls to eval, and their return values, made\nby (eval ’e env). The probability of a ﬁnite eval-\nuation history is the product of the probabilities for\neach elementary random procedure evaluation in this\nhistory3. The weight of an expression in a particu-\nlar environment is the sum of the probabilities of all\nof its ﬁnite evaluation histories. An expression is ad-\nmissible in an environment if it has weight one, and\na procedure is admissible if its body is admissible in\nits environment for all values of its arguments. An ad-\nmissible expression deﬁnes a distribution on evaluation\nhistories (we make this claim precise in section 2.2).\nNote that an admissible expression can have inﬁnite\nhistories, but the set of inﬁnite histories must have\nprobability zero. Thus admissibility can be thought\nof as the requirement that evaluation of an expression\nhalts with probability one. Marginalizing this distri-\nbution over histories results in a distribution on values,\nwhich we write µ(e, env). Thus, (eval ’e env), for\nadmissible e, returns a sample from µ(e, env).\nThe procedure eval allows us to interpret Church\nas a language for generative processes, but for use-\nful probabilistic inference we must be able to sam-\nple from a distribution conditioned on some asser-\ntions (for instance the posterior probability of a hy-\npothesis conditioned on observed data). The pro-\ncedure (query ’e p env) is deﬁned to be a proce-\ndure which samples a value from µ(e, env) condi-\ntioned on the predicate procedure p returning True\nwhen applied to the value of (eval ’e env). The\nenvironment argument env is optional, defaulting to\nthe current environment. (Note that the special case\nof query when the predicate p is the constant pro-\ncedure (lambda (x) True) deﬁnes the same distri-\nbution on values as eval.) For example, one might\nwrite (query ’(pair (flip) (flip)) (lambda (v)\n(+ (first v) (last v)))) to describe the condi-\ntional distribution of two ﬂips given that at least one\nﬂip landed heads. If e or p are not admissible in\nenv the query result is undeﬁned. We describe this\nconditional distribution, and conditions for its well-\ndeﬁnedness, more formally in Theorem 2.3. In Section\n4 we consider Monte Carlo techniques for implement-\ning query.\n3However, if evaluating an elementary random proce-\ndure results in evaluating another elementary random pro-\ncedure we take only the probability of the ﬁrst, since it\nalready includes the second.\n• (eval ’c env): For constant c, return c(env).\n• (eval ’x env): Look-up symbol x in env, return the\nvalue it is bound to.\n• (eval ’(e1 e2 ...) env): Evaluate each (eval ’ei\nenv). The value of (eval ’e1 env) should be a pro-\ncedure (body, x2 ..., env2). Make env3 by extending\nenv2, binding x2 ... to the return values of e2 ....\nReturn the value of (eval body env3).\n• (eval ’(lambda (x...) e) env): Return the proce-\ndure (e, x..., env).\n• (eval ’(if e1 e2 e3) env): If (eval e1 env) re-\nturns True return the return value of (eval e2 env),\notherwise of (eval e3 env).\n• (eval ’(quote e) env): Return the expression e (as\na value).\n• (eval ’(define x e) env): Extend env by binding\nthe value of (eval ’e env) to x; return the extended\nenvironment.\nFigure 1: An informal deﬁnition of the eval procedure. If\npreconditions of these descriptions fail the constant value\nerror is returned. Note that constants represent (possibly\nstochastic) functions from environments to values—truly\n“constant” constants return themselves.\nIt can be awkward in practice to write programs using\nquery, because many random values must be explic-\nitly passed from the query expression to the predicate\nthrough the return value. An alternative is to provide\na means to name random values which are shared by\nall evaluations, building up a “random world” within\nthe query. To enable a this style of programming,\nwe provide the procedure lex-query (for “lexicalizing\nquery”) which has the form:\n(lex-query\n’((A A-deﬁnition)\n(B B-deﬁnition)\n...)\n’e ’p)\nwhere the ﬁrst argument binds a lexicon of symbols to\ndeﬁnitions, which are available in the environment in\nwhich the remaining (query and predicate) expressions\nare evaluated. In this form the predicate is an expres-\nsion, and the ﬁnal environment argument is omitted—\nthe current environment is used.\nA program in Church consists of a sequence of Church\nexpressions—this sequence is called the top level. Any\ndeﬁnitions at the top level are treated as extending the\nglobal (i.e. initial) environment, which then is used\nto evaluate the remaining top-level expressions. For\ninstance:\n(define A e1) e2\nis treated as:\n(eval ’e2 (eval ’(define A e1) global-env)).\n2.1 Stochastic Memoization\nIn deterministic computation, memoization is a tech-\nnique for eﬃcient implementation that does not aﬀect\nthe language semantics: the ﬁrst time a (purely func-\ntional) procedure is evaluated with given arguments\nits return value is recorded; thereafter evaluations of\nthat procedure with those arguments directly return\nthis value, without re-evaluating the procedure body.\nMemoization of a stochastic program can radically\nchange the semantics: if flip is an ordinary random\nprocedure (= (flip) (flip)) is True with probabil-\nity 0.5, but if flip is memoized this expression is True\nwith probability one. More generally, a collection of\nmemoized functions has a random-world semantics as\ndiscussed in [ 10]. In Section 3 we use memoization\ntogether with lex-query to describe generative pro-\ncesses involving an unknown number of objects with\npersistent features, similar to the BLOG language [ 12].\nTo formally deﬁne memoization in Church, we imagine\nextending the notion of environment to allow count-\nably many variables to be bound in an environment.\nThe higher-order procedure mem takes an admissible-\nprocedure and returns another procedure: if (eval e\nenv) returns the admissible procedure (body, args,\nenv2), then (eval ’(mem e) env) returns the mem-\noized procedure (mfune, args, env+), where:\n•env+ is env2 (notionally) extended with a symbol\nVval, for each value val, bound to a value drawn\nfrom the distribution µ((e val), env).\n•mfune is a new constant function such that mfune\napplied to the environment env+ extended with\nargs bound to val returns the value bound to\nVval.\nThis deﬁnition implies that inﬁnitely many random\nchoices may be made when a memoized random pro-\ncedure is created—the notion of admissibility must be\nextended to expressions which involve mem. In the next\nsection we describe an appropriate extension of admis-\nsibility, such that admissible expressions still deﬁne a\nmarginal distribution on values, and the conditional\ndistributions deﬁning query are well-formed.\nOrdinary memoization becomes a semantically mean-\ningful construct within stochastic languages. This sug-\ngests that there may be useful generalizations of mem,\nwhich are not apparent in non-stochastic computation.\nIndeed, instead of always returning the initial value\nor always re-evaluating, one could stochastically de-\ncide on each evaluation whether to use a previously\ncomputed value or evaluate anew. We deﬁne such a\nstochastic memoizer DPmem by using the Dirichlet pro-\ncess (DP) [20]—a distribution on discrete distributions\n(define (DP alpha proc)\n(let ((sticks (mem (lambda x (beta 1.0 alpha))))\n(atoms (mem (lambda x (proc)))))\n(lambda () (atoms (pick-a-stick sticks 1)))))\n(define (pick-a-stick sticks J)\n(if (< (random) (sticks J))\nJ\n(pick-a-stick sticks (+ J 1))))\n(define (DPmem alpha proc)\n(let ((dps (mem (lambda args\n(DP alpha\n(lambda () (apply proc args))\n)))))\n(lambda argsin ((apply dps argsin))) ))\nFigure 2: Church implementation of the Dirichlet Process,\nvia stick breaking, and DPmem. (Evaluating (apply proc\nargs) in env for args=(a1 ...) is equivalent to (eval\n’(proc a1 ...) env).)\nbuilt from an underlying base measure. For an admis-\nsible procedure e, the expression (DPmem a e) evalu-\nates in env to a procedure which samples from a (ﬁxed)\nsample from the DP with base measure µ(e, env) and\nconcentration parameter a. (When a=0, DPmem re-\nduces to mem, when a=∞, it reduces to the identity.)\nThe notion of using the Dirichlet process to cache gen-\nerative histories was ﬁrst suggested in Johnson et al.\n[5], in the context of grammar learning. In Fig. 2\nwe write the Dirichlet Process and DPmem directly in\nChurch, via a stick-breaking representation. This gives\na deﬁnition of these objects, proves that they are se-\nmantically well-formed (provided the rest of the lan-\nguage is), and gives one possible implementation.\nWe pause here to explain choices made in the lan-\nguage deﬁnition. Programs written with pure func-\ntions, those that always return the same value when\napplied to the same arguments, have a number of ad-\nvantages. It is clear that a random function cannot\nbe pure, yet there should be an appropriate general-\nization of purity which maintains some locality of in-\nformation. We believe the right notion of purity in a\nstochastic language is exchangeability: if an expression\nis evaluated several times in the same environment, the\ndistribution on return values is invariant to the order\nof evaluations. This exchangeability is exploited by\nthe Metropolis-Hastings algorithm for approximating\nquery given in Section 4.\nMutable state (or an unpleasant, whole-program\ntransformation into continuation passing style) is nec-\nessary to implement Church, both to model random-\nness and to implement mem using ﬁnite computa-\ntion. However, this statefulness preserves exchange-\nability. Understanding the ways in which other state-\nful language constructs—in particular, primitives for\nthe construction and modiﬁcation of mutable state—\nmight aid in the description of stochastic processes\nremains an important area for future work.\n2.2 Semantic Correctness\nIn this section we give formal statements of the claims\nabove, needed to specify the semantics of Church, and\nsketch their proofs. Let Church − denote the set of\nChurch expressions that do not include mem.\nLemma 2.1. If e∈Church− then the weight of e in\na given environment is well-deﬁned and ≤1.\nProof sketch. Arrange the recursive calls to eval into\na tree with an evaluation at each node and edges con-\nnecting successive applications of eval—if a node in-\ndicates the evaluation of an elementary random proce-\ndure there will be several edges descending from this\nnode (one for each possible return value), and these\nedges are labeled with their probability. A history is a\npath from root to leaf in this tree and its probability\nis the product of the labels along the path. Let Wn in-\ndicate the sum of probabilities of paths of length n or\nless. The claim is now that limn→∞Wn converges and\nis bounded above by 1. The bound follows because the\nsum of labels below any random node is 1; convergence\nthen follows from the monotone convergence theorem\nbecause the labels are non-negative.\nWe next extend the notion of admissibility to arbitrary\nChurch expressions involving mem. To compute the\nprobability of an evaluation history we must include\nthe probability of calls to mem—that is, the probabil-\nity of drawing each return value Vval. Because there\nare inﬁnitely many Vval, the probability of many histo-\nries will then be zero, therefore we pass to equivalence\nclasses of histories. Two histories are equivalent if they\nare the same up to the values bound to Vval—in par-\nticular they must evaluate all memoized procedures on\nthe same arguments with the same return values. The\nprobability of an equivalence class of histories is the\nmarginal probability over all unused arguments and\nreturn values, and this is non-zero. The weight of an\nexpression can now be deﬁned as the sum over equiv-\nalence classes of ﬁnite histories.\nLemma 2.2. The admissibility of a Church expres-\nsion in a given environment is well deﬁned, and any\nexpression e admissible in environment env deﬁnes a\ndistribution µ(e, env) on return values of (eval ’e\nenv).\nProof sketch: The proof is by induction on the number\nof times mem is used. Take as base case expressions\nwithout mem; by Lemma 2.1 the weight is well deﬁned,\nso the set of admissible expressions is also well deﬁned.\nThis function provides persistent class assignments to ob-\njects, where classes are symbols drawn from a pool with DP\nprior:\n(define drawclass (DPmem 1.0 gensym))\n(define class (mem (lambda (obj) (drawclass))))\nFor the beta-binomial model there’s a coin weight for each\nfeature/class pair, and each object has features that depend\nonly on it’s type:\n(define coin-weight\n(mem (lambda (feat obj-class) (beta 1 1))) )\n(define value\n(mem (lambda (obj feat)\n(flip (coin-weight feat (class obj))) )))\nFor a gaussian-mixture on continuous data (with known\nvariance), we just change the code for generating values:\n(define mean\n(mem (lambda (obj-class) (normal 0.0 10.0))) )\n(define cont-value\n(mem (lambda (obj)\n(normal (mean (class obj)) 1.0) )))\nThe inﬁnite relational model [ 7] with continuous data is sim-\nilar, but means depend on classes of two objects:\n(define irm-mean\n(mem (lambda (obj-class1 obj-class2)\n(normal 0.0 10.0) )))\n(define irm-value\n(mem (lambda (obj1 obj2)\n(normal (irm-mean (class obj1) (class obj2))\n1.0 ))))\nFigure 3: Church expressions for inﬁnite mixture type\nmodels, showing use of the random-world programming\nstyle in which objects have persistent properties. Func-\ntions beta and normal generate samples from these stan-\ndard distributions.\nNow, assume p = (body, args, env) is an admis-\nsible procedure with well deﬁned distribution on re-\nturn values. The return from (mem p) is well deﬁned,\nbecause the underlying measure µ(p, env) is well de-\nﬁned. It is then straightforward to show that any ex-\npression involving (mem p), but no other new memo-\nized procedures, has a well deﬁned weight. The induc-\ntion step follows.\nA subtlety in this argument comes if one wishes to ex-\npress recursive memoized functions such as:\n(define F (mem (lambda (x) (... F ...)))) .\nPrima facie this recursion seems to eliminate the\nmemoization-free base case. However, any recursive\ndeﬁnition (or set of deﬁnitions) may be re-written\nwithout recursion in terms of a ﬁxed-point combinator:\n(define F (fix ...)). With this replacement made\nwe are reduced to the expected situation—application\nof fix may fail to halt, in which case F will be inad-\nmissible, but the weight is well deﬁned.\nLemma 2.2 only applies to expressions involving mem\nfor admissible procedures—a relaxation is possible for\npartially admissible procedures in some situations.\nFrom Lemma 2.2 it is straightforward to prove:\nTheorem 2.3. Assume expression e and procedure p\nare admissible in env, and let V be a random value dis-\ntributed according to µ(e,env). If there exists a value\nv in the support of µ(e,env) and True has non-zero\nprobability under µ((p v),env), then the conditional\nprobability\nP(V=val |(eval ’(p V) env)=True)\nis well deﬁned.\nTheorem 2.3 shows that query is a well-posed proce-\ndure; in Section 4 we turn to the technical challenge\nof actually implementing query.\n3 EXAMPLE PROGRAMS\nIn this section we describe a number of example pro-\ngrams, stressing the ability of Church to express a\nrange of standard generative models. As our ﬁrst ex-\nample, we describe diagnostic causal reasoning in a\nsimple scenario: given that the grass is wet on a given\nday, did it rain (or did the sprinkler come on)? In\noutline of this might take the form of the query:\n(lex-query\n’((grass-is-wet ...)\n(rain ...)\n(sprinkler ...)\n’(rain ’day2)\n’(grass-is-wet ’day2) )\nwhere we deﬁne a causal model by deﬁning functions\nthat describe whether it rained, whether the sprin-\nkler was on, and whether the grass is wet. The func-\ntion grass-is-wet will depend on both rain and\nsprinkler—ﬁrst we deﬁne a noisy-or function:\n(define (noisy-or a astrength b bstrength baserate)\n(or (and (flip astrength) a)\n(and (flip bstrength) b)\n(flip baserate)))\nUsing this noisy-or function, and a look-up table for\nvarious weights, we can ﬁll in the causal model:\n(lex-query\n’((weight (lambda (ofwhat)\n(case ofwhat\n((’rain-str) 0.9)\n((’rain-prior) 0.3)\n..etc..)))\n(grass-is-wet (mem (lambda (day)\n(noisy-or\n(rain day) (weight ’rain-str)\n(sprinkler day) (weight ’sprinkler-str)\n(weight ’grass-baserate)))))\nThis deterministic higher-order function deﬁnes the basic\nstructure of stochastic transition models:\n(define (unfold expander symbol)\n(if (terminal? symbol)\nsymbol\n(map (lambda (x) (unfold expander x))\n(expander symbol) )))\nA Church model for a PCFG transitions via a ﬁxed multi-\nnomial over expansions for each symbol:\n(define (PCFG-productions symbol)\n(cond ((eq? symbol ’S)\n(multinomial ’((S a) (T a)) ’(0.2 0.8)) )\n((eq? symbol ’T)\n(multinomial ’((T b) (a b)) ’(0.3 0.7)) ))\n(define (sample-pcfg) (unfold PCFG-productions ’S))\nThe HDP-HMM [2] uses memoized symbols for states and\nmemoizes transitions:\n(define get-symbol (DPmem 1.0 gensym))\n(define get-observation-model\n(mem (lambda (symbol) (make-100-sided-die))))\n(define ihmm-transition\n(DPmem 1.0 (lambda (state)\n(if (flip) ’stop (get-symbol))\n(define (ihmm-expander symbol)\n(list ((get-observation-model symbol))\n(ihmm-transition symbol) ))\n(define (sample-ihmm) (unfold ihmm-expander ’S))\nThe HDP-PCFG [8] is also straightforward:\n(define terms ’( a b c d))\n(define term-probs ’(.1 .2 .2 .5))\n(define rule-type\n(mem (lambda symbol)\n(if (flip) ’terminal ’binary-production))\n(define ipcfg-expander\n(DPmem 1.0\n(lambda (symbol)\n(if (eq? (rule-type symbol) ’terminal)\n(multinomial terms term-probs)\n(list (get-symbol) (get-symbol))))\n(define (sample-ipcfg) (unfold ipcfg-expander ’S))\nMaking adapted versions of any of these models [ 5] only\nrequires stochastically memoizing unfold:\n(define adapted-unfold\n(DPmem 1.0\n(lambda (expander symbol)\n(if (terminal? symbol)\nsymbol\n(map (lambda (x)\n(adapted-unfold expander x))\n(expander symbol) )))))\nFigure 4: Some examples of “stochastic transition models”.\n(rain (mem (lambda (day)\n(flip (weight ’rain-prior)))))\n(sprinkler (mem (lambda (day)\n(flip (weight ’sprinkler-prior))))))\n’(rain ’day2)\n’(grass-is-wet ’day2) )\nNote that we have used mem to make the\ngrass-is-wet, rain, and sprinkler functions persis-\ntent. For example, (= (rain ’day2) (rain ’day2))\nis always True (it either rained on day two or not),\nthis is necessary since both the query and predicate\nexpressions will evaluate (rain ’day2).\nA Bayes net representation of this example would have\nclearly exposed the dependencies involved (though it\nwould need to be supplemented with descriptions of\nthe form of these dependencies). The Church repre-\nsentation, while more complex, lends itself to intuitive\nextensions that would be quite diﬃcult in a Bayes net\nformulation. For instance, what if we don’t know the\nBernoulli weights, but we do have observations of other\ndays? We can capture this by drawing the weights\nfrom a hyper-prior, redeﬁning the weight function to:\n...(weight (mem (lambda (ofwhat) (beta 1 1))))...\nIf we now query conditioned on observations from\nother days, we implicitly learn the weight parameters\nof the model:\n(lex-query\n’...model definitions...\n’(rain ’day2)\n’(and\n(grass-is-wet ’day1)\n(rain ’day1)\n(not (sprinkler ’day1))\n(grass-is-wet ’day2)) )\nGoing further, perhaps the probability of rain depends\non (unknown) types of days (e.g. those with cumulus\nclouds, cirrus clouds, etc.), and perhaps the probabil-\nity of the sprinkler activating depends on orthogonal\ntypes of days (e.g. Mondays and Fridays versus other\ndays). We can model this scenario by drawing the\nprior probabilities from two stochastically memoized\nbeta distributions:\n(lex-query\n’((new-rain-prob\n(DPmem 1.0 (lambda () (beta 1 1))))\n(new-sprinkler-prob\n(DPmem 1.0 (lambda () (beta 1 1))))\n(rain (mem (lambda (day)\n(flip (new-rain-prob)))))\n(sprinkler (mem (lambda (day)\n(flip (new-sprinkler-prob))))))\n...)\nWith this simple change we have extended the original\ncausal model into an inﬁnite mixture of such models,\nin which days are co-clustered into two sets of types,\nbased on their relationship to the wetness of the grass.\nIn the previous example we left the types of days im-\nplicit in the memoizer, using only the probability of\nrain or sprinkler. In Fig. 3 we have given Church im-\nplementations for several inﬁnite mixture models [see\n7] using a diﬀerent idiom—making the types into per-\nsistent properties of objects, drawn from an under-\nlying memoized gensym (recall that gensym is sim-\nply a procedure which returns a unique value on each\nevaluation). Once we have deﬁned the basic struc-\nture, class to draw latent classes for objects, it is\nstraightforward to deﬁne the latent information for\neach class (e.g. coin-weight), and the observation\nmodel (e.g. value). This basic structure may be used\nto easily describe more complicated mixture models,\nsuch as the continuous-data inﬁnite relational model\n(IRM) from [7]. Fig. 3 describes forward sampling for\nthese models; to describe a conditional model, these\ndeﬁnitions must be made within the scope of a query.\nFor instance, if we wished to query whether two ob-\njects have the same class, conditioned on observed fea-\ntures:\n(lex-query\n’((drawclass (mem 1.0 gensym))\n(class ...)\n(coin-weight ...)\n(value ...))\n’(= (class ’alice) (class ’bob))\n’(and\n(= (value ’alice ’blond) 1)\n(= (value ’bob ’blond) 1)\n(= (value ’jim ’blond) 0)))\nAnother idiom (Fig. 4) allows us to write the com-\nmon class of “stochastic transition” models, which in-\ncludes probabilistic context free grammars (PCFGs),\nhidden Markov models (HMMs), and their “inﬁnite”\nanalogs. Writing the HDP-PCFG [8] and HDP-HMM\n[2] in Church provides a compact and clear speciﬁca-\ntion to these complicated non-parametric models. If\nwe memoize unfold and use this adapted-unfold on\nPCFG transitions we recover the Adaptor Grammar\nmodel of [5]; if we similarly “adapt” the HDP-PCFG\nor HDP-HMM we get interesting new models that have\nnot been considered in the literature.\nFig. 5(top) gives an outline for using Church to repre-\nsent planning problems. This is based on the transla-\ntion of planning into inference, given in Toussaint et al.\n[21], in which rewards are transformed into the proba-\nbility of getting a single “ultimate reward”. Inference\non this representation results in decisions which soft-\nmaximizes the expected reward. Fig. 5(bottom) ﬁlls\nin this framework for a simple “red-light” game: the\nstate is a light color (red/green) and an integer po-\nsition, a “go” action advances one position forward\n(define (transition state-action)\n(pair\n(forward-model state-action)\n(action-prior) ))\n(define (terminal? symbol) (flip gamma))\n(define (reward-pred rewards)\n(flip ((/ (sum rewards) (length rewards)))))\n(lex-query\n’((first-action (action-prior))\n(final-state\n(first (unfold transition\n(pair start-state first-action) )))\n(reward-list\n(list (sp1 final-state)\n(sp2 final-state)\n..etc.. ))\n’first-action\n’(reward-pred reward-list))\n(define (forward-model s-a)\n(pair\n(if (flip 0.5) ’red-light ’green-light)\n(let ((light (first (first s-a)))\n(position (last (first s-a)))\n(action (last s-a)))\n(if (eq? action ’go)\n(if (and (eq? light ’red-light)\n(flip cheat-det))\n0\n(+ position 1))\nposition))))\n(define (action-prior) (if (flip 0.5) ’go ’stop))\n(define (sp1 state) (if (> (last state) 5) 1 0))\nFigure 5: Top: The skeleton of planning-as-inference in\nChurch (inspired by [ 21]). For simplicity, we assume an\nequal reward amount for each boolean “state property”\nthat is true. Reward is given only when the state reaches\na “terminal state”, however the stochastic termination de-\ncision given by terminal? results in an inﬁnite horizon\nwith discount factor gamma. Bottom: A speciﬁc planning\nproblem for the “red-light” game.\nexcept that going on a red light results in being sent\nback to position 0 with probability cheat-det. The\ngoal is to be past position 5 when the game ends; other\nrewards (e.g. for a staged game) could be added by\nadding sp2, sp3, and so on.\n4 CHURCH IMPLEMENTATION\nImplementing Church involves two complications be-\nyond the implementation of eval as shown in Fig. 1\n(which is essentially the same as any lexically scoped,\napplicative order, pure Lisp [ 6]). First, we must ﬁnd a\nway to implement mem without requiring inﬁnite struc-\ntures (such as the Vval). Second, we must implement\nquery by devising a means to sample from the appro-\npriate conditional distribution.\nTo implement mem we ﬁrst note that the countably\nmany Vval are not all needed at once: they can be\n/Minus0.4/Minus0.20.20.40.51.01.52.0\n/Minus0.4/Minus0.20.20.40.51.01.5\nFigure 6: Posterior\nsamples from the\ninﬁnite gaussian-\nmixture (with un-\nknown variance)\nof Section 3, using\nthe collapsed rejec-\ntion algorithm for\nquery. Two data-\nsets are shown (as\ndots) with mixture\ncomponents and\nposterior predictive\ndistribution.\ncreated as needed, extending the environment env+\nwhen they are created. (Note that this implementation\nchoices is stateful, but may be implemented easily in\nfull Scheme: the argument/return value pairs can be\nstored in an association list which grows as need.) 4\nWe now turn to query. The sampling-based semantics\nof Church allows us to deﬁne a simple rejection sampler\nfrom the conditional distribution deﬁning query; we\nmay describe this as a Church expression:\n(define (query exp pred env)\n(let ((val (eval exp env))\n(if (pred val)\nval\n(query exp pred env)))))\nThe ability to write query as a Church program—\na metacircular [ 1] implementation—provides a com-\npelling argument for Church’s modeling power. How-\never, exact sampling using this algorithm will often be\nintractable. It is straightforward to implement a col-\nlapsed rejection sampler that integrates out random-\nness in the predicate procedure (accepting or rejecting\na val with probability equal to the marginal probabil-\nity that (p val) is true). We show results in Fig. 6 of\nthis exact sampler used to query the inﬁnite gaussian-\nmixture model from Section 3.\nIn Fig. 7 we show the result of running the collapsed\nrejection query for planning in the “red-light” game,\nas shown in Fig. 5 (here gamma=0.2, cheat-det=0.7).\nThe result is intuitive: when position is near 0 there\nis little to lose by “cheating”, as position nears 5 (the\ngoal line) there is more to loose, hence the probability\nof cheating decreases; once past the goal line there is\nnothing to be gained by going, so the probability of\ncheating drops sharply. Note that the “soft-max” for-\nmulation of planning used here results in fairly random\nbehavior even in extreme positions.\n4A further optimization implements DPmem via the Chi-\nnese restaurant process representation of the DP [15].\n0 1 2 3 4 5 6\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\nPosition\nProbability of chosing action 'go'.\nFigure 7: Results from\nplanning in the “red-\nlight” game (Fig. 5),\nshowing the probability\nof “cheating” (going\nwhen the light is red)\nversus position. The\ngoal is to end the game\npast position 5.\n4.1 A Metropolis-Hastings Algorithm\nWe now present a Markov chain Monte Carlo algo-\nrithm for approximately implementing query, as we\nexpect (even collapsed) rejection sampling to be in-\ntractable in general. Our algorithm executes stochas-\ntic local search over evaluation histories, making small\nchanges by proposing changes to the return values of\nelementary random procedures. These changes are\nconstrained to produce the conditioned result, collaps-\ning out the predicate expression via its marginal prob-\nability5. The use of evaluation histories, rather than\nvalues alone, can be viewed as an extreme form of\ndata-augmentation: all random choices that lead to a\nvalue are made explicit in its history.\nThe key abstraction we use for MCMC is the computa-\ntion trace. A computation trace is a directed, acyclic\ngraph composed of two connected trees. The ﬁrst is\na tree of evaluations, where an evaluation node points\nto evaluation nodes for its recursive calls to eval. The\nsecond is a tree of environment extensions, where the\nnode for an extended environment points to the node\nof the environment it extends. The evaluation node for\neach (eval ’e env) points to the environment node\nfor env, and evaluation nodes producing values to be\nbound are pointed to by the environment extension of\nthe binding. Traces are in one-to-one correspondence\nwith equivalence classes of evaluation histories, de-\nscribed earlier6. Fig. 8 shows the fragment of a compu-\ntation trace for evaluation of the expression ((lambda\n(x) (+ x 3)) (flip)).\nFor each elementary random procedure p we need a\nMarkov chain transition kernel Kp that proposes a\nnew return value for that procedure given its cur-\nrent arguments. A generic such kernel comes from re-\n5Handling the rejection problem on chain initialization\n(and queries across deterministic programs, more gener-\nally) is a challenge. Replacing all language primitives (in-\ncluding if) with noisy alternatives and using tempering\ntechniques provides one general solution, to be explored in\nfuture work.\n6Also note that the acyclicity of traces is a direct result\nof the purity of the Church language: if a symbol’s value\nwere mutated, its environment would point to the evalu-\nation node that determined its new value, but that node\nwould have been evaluated in the same environment.\nFigure 8: A schematic computation trace.\nevaluating (eval ’(p args) env); however, a proper\nChurch standard library could frequently supply more\neﬃcient proposal kernels for particular procedures (for\ninstance a drift kernel for normal). Our requirement\nis that we are able to sample a proposal from Kp as\nwell as evaluate its transition probability qp(·|·).\nIf we simply apply Kp to a trace, the trace can be-\ncome “inconsistent”—no longer representing a valid\nevaluation history from eval. To construct a com-\nplete Metropolis-Hastings proposal from Kp, we must\nkeep the computation trace consistent, and modify the\nproposal probabilities accordingly, by recursing along\nthe trace updating values and potentially triggering\nnew evaluations. For example, if we change the value\nof flip in (if (flip) e1 e2) from False to True we\nmust: absorb the probability of (eval e2 env) in the\nreverse proposal probability, evaluate e1 and attach\nit to the trace, and include the probability of the re-\nsulting sub-trace in the forward proposal probability.\n(For a particular trace, the probability of the sub-trace\nfor expression e is the probability of the equivalence\nclass of evaluation histories corresponding to this sub-\ntrace.) The recursions for trace consistency and pro-\nposal computation are delicate but straightforward,\nand we omit the details due to space constraints 7.\nEach step of our MCMC algorithm 8 consists of apply-\ning a kernel Kp to the evaluations of a randomly chosen\nelementary random primitive in the trace, updating\nthe trace to maintain consistency (collecting appro-\npriate corrections to the proposal probability), and\napplying the Metropolis-Hastings criterion to accept\nor reject this proposal. (This algorithm ignores some\ndetails needed for queries containing nested queries,\nthough we believe these to be straightforward.)\nWe have implemented and veriﬁed this algorithm on\nseveral examples that exercise all of the recursion and\nupdate logic of the system. In Fig. 9 we have shown\nconvergence results for this algorithm running on the\nsimple “sprinkler” example of Section 3.\n7We implemented our MCMC algorithm atop the Blaise\nsystem [3], which simpliﬁes these recursively triggered ker-\nnel compositions.\n8At the time of writing we have not implemented this\nalgorithm for programs that use mem, though we believe\nthe necessary additions to be straightforward.\n0 20 40 60 80 1000\n0.2\n0.4\n0.6\n0.8\n1\n0 20 40 60 80 1000.8\n0.9\n1\n1.1\n1.2\n1.3\nNumber of samples from query.\nFigure 9: Conver-\ngence of one run\nof the MCMC al-\ngorithm on the\n“sprinkler” exam-\nple. (Each sample\nfrom query uses\n30 MCMC steps.)\nTop: The probabil-\nity of rain. Bot-\ntom: The expected\nvalue of (+ (rain)\n(sprinkler)),\nshowing explain-\ning away. The sum\nis slightly above 1.0\nbecause one cause is\nusually present, but\nboth rarely are.\n5 DISCUSSION\nWhile Church builds on many other attempts to marry\nprobability theory with computation, it is distinct in\nseveral important ways. First, Church is founded on\nthe lambda calculus, allowing it to represent higher-\norder logic and separating it from many related lan-\nguages. For example, unlike several widely used lan-\nguages grounded in propositional logic (e.g. BUGS [ 9])\nand ﬁrst-order logic (e.g. the logic programming ap-\nproaches of [ 13, 19], BLOG [ 12], and Markov logic\n[18]), generative processes in Church are ﬁrst-class ob-\njects that can be arbitrarily composed and abstracted.\nThe example programs in Section 3 illustrate the rep-\nresentational ﬂexibility of Church; while some of these\nprograms may be naturally represented in one or an-\nother existing language, we believe that no other lan-\nguage can easily represent all of these examples.\nThe stochastic functional language IBAL [ 14], based\non the functional language ML, is quite similar to\nChurch, but the two languages emphasize diﬀerent\naspects of functional programming. Other related\nwork includes non-determistic [11] and weighted non-\ndeterministic [16] extensions to Lisp. Unlike these ap-\nproaches, the semantics of Church is fundamentally\nsampling-based: the denotation of admissible expres-\nsions as distributions follows from the semantics of\nevaluation rather than deﬁning it. This semantics,\ncombined with dynamic typing (cf. static typing of\nML), permits the deﬁnition and exact implementation\nof query as an ordinary Church procedure, rather than\na special transformation applied to the distribution\ndenoted by a program. Because query is deﬁned via\nsampling, describing approximate inference is partic-\nularly natural within Church.\nA number of the more unusual features of Church as a\nstochastic programming language derive from its ba-\nsis in Lisp. Since query and eval are the basic con-\nstructs deﬁning the meaning of Church expressions, we\nhave a metacircular [17] description of Church within\nChurch. This provides clarity in reasoning about the\nlanguage, and allows self-reﬂection within programs:\nqueries may be nested within queries, and programs\nmay reason about programs. Church expressions can\nserve both as a declarative notation for uncertain be-\nliefs (via the distributions they represent) and as a\nprocedural notation for stochastic and deterministic\nprocesses (via evaluation). Because expressions are\nthemselves values, this generalizes the Lisp uniﬁca-\ntion of programs and data to a uniﬁcation of stochas-\ntic processes, Church expressions, and uncertain be-\nliefs. These observations suggest exciting new mod-\neling paradigms. For instance, eval nested within\nquery may be used to learn programs, where the prior\non programs is represented by another Church pro-\ngram. Issues of programming style then become issues\nof description length and inductive bias. As another\nexample, query nested within query may be used to\nrepresent an agent reasoning about another agent.\nOf course, Church’s representational ﬂexibility comes\nat the cost of substantially increased inference com-\nplexity. Providing eﬃcient implementations of query\nis a critical challenge as our current implementation\nis not yet eﬃcient enough for typical machine learn-\ning applications; this may be greatly aided by building\non techniques used for inference in other probabilistic\nlanguages [e.g. 10, 14, 12]. For example, in Church, ex-\nact inference by enumeration could be seen as a pro-\ngram analysis that transforms expressions involving\nquery into expressions involving only eval; identifying\nand exploiting opportunities for such transformations\nseems appealing.\nProbabilistic models and stochastic algorithms are\nﬁnding increasingly widespread use throughout artiﬁ-\ncial intelligence and cognitive science, central to areas\nas diverse as vision, planning, and natural language\nunderstanding. As their usage grows and becomes\nmore intricate, so does the need for formal languages\nsupporting model exchange, reuse, and machine exe-\ncution. We hope Church represents a signiﬁcant step\ntoward this goal.\nAcknowledgements\nThe authors would like to thank Gerry Sussman, Hal\nAbelson, Tom Knight, Brian Milch, David McAllester\nand Alexey Radul for helpful discussions. This work\nwas funded in part by a grant from NTT Communi-\ncation Sciences Laboratory.\nReferences\n[1] H. Abelson and G. Sussman. Structure and Interpre-\ntation of Computer Programs . MIT Press, 1996.\n[2] M.J. Beal, Z. Ghahramani, and C.E. Rasmussen. The\ninﬁnite hidden Markov model. NIPS 14, 2002.\n[3] K. A. Bonawitz. Composable Probabilistic Inference\nwith Blaise. PhD thesis, MIT, 2008.\n[4] A. Church. A Set of Postulates for the Foundation\nof Logic. The Annals of Mathematics , 33(2):346–366,\n1932.\n[5] M. Johnson, T. Griﬃths, and S. Goldwater. Adaptor\ngrammars: A framework for specifying compositional\nnonparametric Bayesian models. NIPS 19, 2007.\n[6] R. Kelsey, W. Clinger, and J. Rees (eds.). Revised 5\nReport on the Algorithmic Language Scheme. Higher-\nOrder and Symbolic Computation , 11(1):7–105, 1998.\n[7] C. Kemp, J.B. Tenenbaum, T.L. Griﬃths, T. Ya-\nmada, and N. Ueda. Learning systems of concepts\nwith an inﬁnite relational model. Proc. 21st Natl\nConf. Artif. Intell., AAAI Press , 2006.\n[8] P. Liang, S. Petrov, M.I. Jordan, and D. Klein. The\nInﬁnite PCFG using Hierarchical Dirichlet Processes.\nProc. EMNLP-CoNLL, 2007.\n[9] D.J. Lunn, A. Thomas, N. Best, and D. Spiegel-\nhalter. WinBUGS-A Bayesian modelling framework:\nConcepts, structure, and extensibility. Statistics and\nComputing, 10(4):325–337, 2000.\n[10] D. McAllester, B. Milch, and N. D. Goodman.\nRandom-world semantics and syntactic indepen-\ndence for expressive languages. Technical Report\nMIT-CSAIL-TR-2008-025, Massachusetts Institute of\nTechnology, 2008.\n[11] J. McCarthy. A Basis for a Mathematical Theory of\nComputation. In Computer Programming and Formal\nSystems, pages 33–70, 1963.\n[12] B. Milch, B. Marthi, S. Russell, D. Sontag, D.L. Ong,\nand A. Kolobov. BLOG: Probabilistic models with\nunknown objects. Proc. IJCAI, 2005.\n[13] S. Muggleton. Stochastic logic programs. In\nL. de Raedt, editor, Advances in Inductive Logic Pro-\ngramming, pages 254–264. IOS Press, 1996.\n[14] A. Pfeﬀer. IBAL: A probabilistic rational program-\nming language. Proc. IJCAI, 2001.\n[15] J. Pitman. Combinatorial stochastic processes, 2002.\nNotes for Saint Flour Summer School.\n[16] A. Radul. Report on the probabilistic language\nscheme. Technical Report MIT-CSAIL-TR-2007-059,\nMassachusetts Institute of Technology, 2007.\n[17] J.C. Reynolds. Deﬁnitional interpreters for higher-\norder programming. ACM Annual Conference, pages\n717–740, 1972.\n[18] M. Richardson and P. Domingos. Markov logic net-\nworks. Machine Learning, 62(1):107–136, 2006.\n[19] T. Sato and Y. Kameya. PRISM: A symbolic-\nstatistical modeling language. In International Joint\nConference on Artiﬁcial Intelligence , 1997.\n[20] J. Sethuraman. A Constructive deﬁnition of Dirichlet\npriors. Statistica Sinica, 4, 1994.\n[21] M. Toussaint, S. Harmeling, and A. Storkey. Prob-\nabilistic inference for solving (PO)MDPs. Technical\nReport EDI-INF-RR-0934, University of Edinburgh,\n2006."
}