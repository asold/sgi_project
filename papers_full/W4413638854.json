{
  "title": "AI Agents in Clinical Medicine: A Systematic Review",
  "url": "https://openalex.org/W4413638854",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5096258884",
      "name": "Alon Gorenshtein",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2682811430",
      "name": "Mahmud Omar",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1498187152",
      "name": "Benjamin S Glicksberg",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2170298636",
      "name": "GIRISH N. NADKARNI",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A5096258884",
      "name": "Alon Gorenshtein",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2682811430",
      "name": "Mahmud Omar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1498187152",
      "name": "Benjamin S Glicksberg",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2170298636",
      "name": "GIRISH N. NADKARNI",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4406152279",
    "https://openalex.org/W4394767601",
    "https://openalex.org/W4407150885",
    "https://openalex.org/W4403813762",
    "https://openalex.org/W4409210035",
    "https://openalex.org/W4400324908",
    "https://openalex.org/W4365148488",
    "https://openalex.org/W4406887664",
    "https://openalex.org/W4412853478",
    "https://openalex.org/W4410343193",
    "https://openalex.org/W6948557422",
    "https://openalex.org/W4406152291",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W6910713234",
    "https://openalex.org/W4415066917",
    "https://openalex.org/W4389984066",
    "https://openalex.org/W4411203672",
    "https://openalex.org/W4412679433",
    "https://openalex.org/W6892036744",
    "https://openalex.org/W4410430358",
    "https://openalex.org/W4391591599",
    "https://openalex.org/W6929617472",
    "https://openalex.org/W4398778637",
    "https://openalex.org/W4407203427",
    "https://openalex.org/W4405766628",
    "https://openalex.org/W4407691270",
    "https://openalex.org/W3118615836",
    "https://openalex.org/W6929335573",
    "https://openalex.org/W4401220095",
    "https://openalex.org/W4411319013",
    "https://openalex.org/W4410458608",
    "https://openalex.org/W4412461986",
    "https://openalex.org/W4403781141",
    "https://openalex.org/W4408411093",
    "https://openalex.org/W4408529625",
    "https://openalex.org/W4411100445",
    "https://openalex.org/W4412759774",
    "https://openalex.org/W4410092171",
    "https://openalex.org/W4404136861",
    "https://openalex.org/W4412709685",
    "https://openalex.org/W4412105868",
    "https://openalex.org/W4412692453",
    "https://openalex.org/W4411720284",
    "https://openalex.org/W4410176137",
    "https://openalex.org/W4409228901",
    "https://openalex.org/W4408388242",
    "https://openalex.org/W4404518047",
    "https://openalex.org/W4402626956",
    "https://openalex.org/W4413408952",
    "https://openalex.org/W4393767508",
    "https://openalex.org/W4390961916",
    "https://openalex.org/W4396718668",
    "https://openalex.org/W4415311558",
    "https://openalex.org/W4403488216",
    "https://openalex.org/W4412366315",
    "https://openalex.org/W4390962153",
    "https://openalex.org/W6966661786",
    "https://openalex.org/W4400313416",
    "https://openalex.org/W4391709247",
    "https://openalex.org/W4412888276",
    "https://openalex.org/W4392044798",
    "https://openalex.org/W6948194969",
    "https://openalex.org/W6948350236",
    "https://openalex.org/W4411842914",
    "https://openalex.org/W4415234011",
    "https://openalex.org/W4404449980",
    "https://openalex.org/W4412952090",
    "https://openalex.org/W4220962859",
    "https://openalex.org/W4401076624",
    "https://openalex.org/W4413340985",
    "https://openalex.org/W4412650765"
  ],
  "abstract": "ABSTRACT Background AI agents built on large language models (LLMs) can plan tasks, use external tools, and coordinate with other agents. Unlike standard LLMs, agents can execute multi-step processes, access real-time clinical information, and integrate multiple data sources. There has been interest in using such agents for clinical and administrative tasks, however, there is limited knowledge on their performance and whether multi-agent systems function better than a single agent for healthcare tasks. Purpose To evaluate the performance of AI agents in healthcare, compare AI agent systems vs. standard LLMs and catalog the tools used for task completion Data Sources PubMed, Web of Science, and Scopus from October 1, 2022, through August 5, 2025. Study Selection Peer-reviewed studies implementing AI agents for clinical tasks with quantitative performance comparisons. Data Extraction Two reviewers (A.G., M.O.) independently extracted data on architectures, performance metrics, and clinical applications. Discrepancies were resolved by discussion, with a third reviewer (E.K.) consulted when consensus could not be reached. Data Synthesis Twenty studies met inclusion criteria. Across studies, all agent systems outperformed their baseline LLMs in accuracy performance. Improvements ranged from small gains to increases of over 60 percentage points, with a median improvement of 53 percentage points in single-agent tool-calling studies. These systems were particularly effective for discrete tasks such as medication dosing and evidence retrieval. Multi-agent systems showed optimal performance with up to 5 agents, and their effectiveness was particularly pronounced when dealing with highly complex tasks. The highest performance boost occurred when the complexity of the AI agent framework aligned with that of the task. Limitations Heterogeneous outcomes precluded quantitative meta-analysis. Several studies relied on synthetic data, limiting generalizability. Conclusions AI agents consistently improve clinical task performance of Base-LLMs when architecture matches task complexity. Our analysis indicates a step-change over base-LLMs, with AI agents opening previously inaccessible domains. Future efforts should be based on prospective, multi-center trials using real-world data to determine safety, task matched and cost-effectiveness. Primary Funding Source This work was supported in part through the computational and data resources and staff expertise provided by Scientific Computing and Data at the Icahn School of Medicine at Mount Sinai and supported by the Clinical and Translational Science Awards (CTSA) grant UL1TR004419 from the National Center for Advancing Translational Sciences. Research reported in this publication was also supported by the Office of Research Infrastructure of the National Institutes of Health under award number S10OD026880 and S10OD030463. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. Registration PROSPERO CRD420251120318",
  "full_text": " 1  \nTitle. AI Agents in Clinical Medicine: A Systematic Review \nShort Title. Agents in Medicine \nAuthor Block. Alon Gorenshtein*,1,2 Mahmud Omar*,1,2 Benjamin S Glicksberg,1,2 \nGirish N Nadkarni†,1,2 Eyal Klang†,1,2  \nAuthor Affiliations.  \n1.The Windreich Department of Artificial Intelligence and Human Health, Mount Sinai \nMedical Center, NY, USA. \n2.The Hasso Plattner Institute for Digital Health at Mount Sinai, Mount Sinai Health \nSystem, NY, USA. \n \n* Co-first authors. These authors contributed equally. \n† Co-senior authors. These authors contributed equally. \n \nKeywords: AI agent, Agentic AI, Large language model, systematic review, AI \n \nAuthor Contributions: Conceptualization, AG, MO, EK, BSG,GN; Methodology, AG, \nMO, EK; Formal Analysis, AG, MO; Data Curation, AG, MO; Writing-Original Draft \nPreparation, AG,MO; Writing- Review & Editing, AG, MO, EK,BSG,GN; Supervision: \nEK,GN \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n 2  \nFunding. This work was supported in part through the computational and data \nresources and staff expertise provided by Scientific Computing and Data at the Icahn \nSchool of Medicine at Mount Sinai and supported by the Clinical and Translational \nScience Awards (CTSA) grant UL1TR004419 from the National Center for Advancing \nTranslational Sciences. Research reported in this publication was also supported by the \nOffice of Research Infrastructure of the National Institutes of Health under award \nnumber S10OD026880 and S10OD030463. The content is solely the responsibility of \nthe authors and does not necessarily represent the official views of the National \nInstitutes of Health.  \nCompeting interests. The authors declare that they have no competing interests. \nWord count. 3916. \nAddress correspondence to:  \nEyal Klang, MD or Girish Nadkarni, MD, MPH \n3 East 101 Street,  \nNew York, NY-10128 \neyal.klang@mssm.edu or girish.nadkarni@mountsinai.org \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 3  \nABSTRACT \nBackground: AI agents built on large language models (LLMs) can plan tasks, use \nexternal tools, and coordinate with other agents. Unlike standard LLMs, agents can \nexecute multi-step processes, access real-time clinical information, and integrate \nmultiple data sources. There has been interest in using such agents for clinical and \nadministrative tasks, however, there is limited knowledge on their performance and \nwhether multi-agent systems function better than a single agent for healthcare tasks.  \nPurpose: To evaluate the performance of AI agents in healthcare, compare AI agent \nsystems vs. standard LLMs and catalog the tools used for task completion \nData Sources: PubMed, Web of Science, and Scopus from October 1, 2022, through \nAugust 5, 2025. \nStudy Selection: Peer-reviewed studies implementing AI agents for clinical tasks with \nquantitative performance comparisons. \nData Extraction: Two reviewers (A.G., M.O.) independently extracted data on \narchitectures, performance metrics, and clinical applications. Discrepancies were \nresolved by discussion, with a third reviewer (E.K.) consulted when consensus could not \nbe reached. \nData Synthesis Twenty studies met inclusion criteria. Across studies, all agent systems \noutperformed their baseline LLMs in accuracy performance. Improvements ranged from \nsmall gains to increases of over 60 percentage points, with a median improvement of 53 \npercentage points in single-agent tool-calling studies. These systems were particularly \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 4  \neffective for discrete tasks such as medication dosing and evidence retrieval. Multi-\nagent systems showed optimal performance with up to 5 agents, and their effectiveness \nwas particularly pronounced when dealing with highly complex tasks. The highest \nperformance boost occurred when the complexity of the AI agent framework aligned \nwith that of the task. \nLimitations: Heterogeneous outcomes precluded quantitative meta-analysis. Several \nstudies relied on synthetic data, limiting generalizability. \nConclusions: AI agents consistently improve clinical task performance of Base-LLMs \nwhen architecture matches task complexity. Our analysis indicates a step-change over \nbase-LLMs, with AI agents opening previously inaccessible domains. Future efforts \nshould be based on prospective, multi-center trials using real-world data to determine \nsafety, task matched and cost-effectiveness. \nPrimary Funding Source:  This work was supported in part through the computational \nand data resources and staff expertise provided by Scientific Computing and Data at the \nIcahn School of Medicine at Mount Sinai and supported by the Clinical and Translational \nScience Awards (CTSA) grant UL1TR004419 from the National Center for Advancing \nTranslational Sciences. Research reported in this publication was also supported by the \nOffice of Research Infrastructure of the National Institutes of Health under award \nnumber S10OD026880 and S10OD030463. The content is solely the responsibility of \nthe authors and does not necessarily represent the official views of the National \nInstitutes of Health. \nRegistration: PROSPERO CRD420251120318 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 5  \nINTRODUCTION \nLarge language models (LLMs) have demonstrated expert performance on medical \nexaminations1,2,3. Recent studies have begun to implement these LLMs in clinical \nsettings, showing improvements in performance.4,5 However, clinical deployment faces \ncritical safety challenges6,7,8,9 LLMs can generate plausible but incorrect information, \nknown as hallucinations.10,11 In up to 22% of clinical interactions, LLM showed \nmisinformation errors most common in medication dosing, symptom recognition, and \ndiagnostic reasoning.12,13 These models also may lack access to current medical \nliterature and patient-specific data from electronic health records, limiting their ability to \nprovide evidence-based care.14,15  \nTo overcome these limitations, researchers have developed AI agents, LLM systems \naugmented with tools that can access external information, perform calculations, and \ncomplete multi-step clinical tasks autonomously.16–20,21,22 Unlike standard LLMs that \nprovide single responses to questions, AI agents can search medical databases, extract \ndata from patient records, calculate medication doses, and coordinate multiple \ninformation sources to answer complex clinical questions.23,24,25 \nMulti-agent systems (Agentic AI)26 take this further, using teams of specialized AI \nagents27 with an orchestration layer that collaborate like multidisciplinary care teams to \ntackle complex interdisciplinary diagnostic and treatment planning challenges.28,29,30,31 \nDespite their theoretical advantages over base LLMs, systematic evidence on the use of \nAI agents in clinical tasks is lacking. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 6  \nThis systematic review evaluates the current state of AI agents in clinical medicine, \nquantifies their performance compared with base LLMs, and identifies applications \nsuited for research and near-term integration. We also outline safeguards and design \nprinciples needed to ensure safe and effective implementation. \n \nMETHODS \nProtocol and Registration \nThis study used an established methodological framework, consistent with the extended \nPreferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) \nchecklist for systematic reviews.\n32 The study protocol was pre-registered on the \nInternational Prospective Register Reviews (PROSPERO; CRD420251120318). \nData Sources and Searches \nWe conducted a comprehensive literature search across three bibliographic databases: \nPubMed, Web of science, and Scopus, from October 1, 2022 (corresponding to the rise \nof agentic frameworks) through August 5, 2025. The search strategy combined Medical \nSubject Headings (MeSH) terms and free-text keywords across three conceptual \ndomains: (1) agentic systems (\"multi-agent\" OR \"tool-calling\" OR \"agentic AI\" OR \n\"autonomous agent\" OR \"ReAct\" OR \"LangChain\" OR \"AutoGen\"); (2) large language \nmodels (\"GPT\" OR \"Claude\" OR \"Gemini\" OR \"LLaMA\" OR \"large language model\" OR \n\"foundation model\"); and (3) clinical applications (\"clinical\" OR \"medical\" OR \n\"healthcare\" OR \"diagnosis\" OR \"treatment\" OR \"patient care\"). The full search strategy \nfor each database is provided in Supplementary Methods. We additionally performed \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 7  \nforward and backward citation searching of included studies and reviewed preprint \nservers (arXiv, medRxiv, bioRxiv) to identify articles in press. For articles that have not \nyet undergone peer review, we present a narrative analysis outside the rigorous \nsystematic review criteria. \n \nStudy Selection \nStudies were included if they met all of the following criteria: (1) described an AI agent \nsystem, defined as an LLM that autonomously determines when to call external tools, \ncoordinates multiple specialized agents, or both; (2) applied this system to a human \nhealth-related task with clinical relevance; (3) reported quantitative performance metrics \ncomparing the agentic approach to a baseline (single-pass LLM, human performance, \nor established clinical standard); (4) were published as peer-reviewed articles in \nEnglish.  \nWe excluded: (1) studies using single-pass LLMs without agentic capabilities; (2) purely \ntechnical papers without clinical applications; (3) simulation or benchmark studies \nlacking real-world validation or clinical tasks; (4) review articles, editorials, conference \nabstracts, and preprints not yet accepted for publication.   \nTwo reviewers (A.G, M.O) independently screened all titles and abstracts using \nCovidence systematic review software. Articles marked for potential inclusion by either \nreviewer underwent full-text assessment. Disagreements were resolved through \ndiscussion, with a third reviewer (E.K) providing arbitration when consensus could not \nbe reached.  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 8  \nData Extraction and Quality Assessment \nWe developed a standardized data extraction form, piloted on five randomly selected \nstudies, and refined based on extractor feedback. Two reviewers independently \nextracted data from each included study, with discrepancies resolved through \ndiscussion. Extracted variables included: \n1. Study characteristics: First author, publication year, country, clinical domain, study \ndesign, sample size, data source (real-world vs. synthetic), external validation (yes/no), \ncode availability. \nTechnical specifications: Base-LLM(s) used, AI agent framework (e.g., AutoGen, \nLangChain, CrewAI and custom)33, agent architecture type (multi-agent only, tool-calling \nonly, or combined), number of agents, number and types of tools, and consensus \nmechanism for multi-agent systems. \nPerformance metrics: Primary outcome measure, baseline comparator, absolute and \nrelative performance improvement, secondary outcomes, and subgroup analyses where \navailable. \nImplementation details: Computational requirements, runtime, and cost estimates were \nreported, and human oversight requirements were reported. \nRisk of Bias Assessment \nWe adapted the QUADAS-AI tool\n34 (Quality Assessment of Diagnostic Accuracy Studies \nfor AI) to assess risk of bias and applicability concerns. This modified instrument \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 9  \nevaluated four domains: (1) Patient/Data Selection, (2) Index Test (AI system), (3) \nReference Standard, and (4) Flow and Timing. Each domain was rated as low risk, high \nrisk, or unclear risk of bias.34 Additionally, we assessed concerns regarding applicability \nfor the first three domains. \nSpecific high-risk indicators included: use of synthetic/simulated data only, single-center \nvalidation, sample size <100, lack of external validation, unclear ground truth \nestablishment, and selective outcome reporting. Two reviewers independently assessed \neach study, with disagreements resolved through consensus discussion.  \nData Synthesis and Analysis \nGiven the heterogeneity in clinical domains, outcomes, and architectures, we did not \nconduct a meta-analysis; instead, we performed a narrative synthesis structured around \nour pre-specified research questions. We stratified analyses by: \n1) Architecture type: Studies were categorized as single AI agent using tool-calling \nonly, multi-agent only, or combined (multi-agent plus tools) based on their \nprimary implementation. \n2) Clinical domain: We grouped studies into diagnosis/prognosis, evidence \nsynthesis, treatment planning, clinical operations, genomics, and other \nspecialized applications. \n3) Complexity metrics: We analyzed relationships between performance and \nsystem complexity, defined by number of agents (for multi-agent systems) and \nnumber of tools (for tool-calling systems). \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 10\nFor studies reporting comparable outcomes, we calculated median performance \nimprovements with interquartile ranges (IQR).  \n \n \nResults \nStudy Selection \nOur search strategy across PubMed, Web of Science, and Scopus identified 6,023 \nrecords after removal of duplicates. Following title and abstract screening, 254 articles \nunderwent full-text assessment for eligibility. After applying inclusion criteria requiring \npeer-reviewed AI agent LLM implementations for clinical tasks, 20 studies met all \ncriteria and were included in the final analysis.\n35–53,54 Reasons for exclusion included: \nnon-AI agent single-pass LLM implementations (n=184), simulation or benchmark-only \nstudies without clinical validation (n=31), and studies lacking comparative performance \nmetrics (n=22) (Supplementary Figure 1.). \nOverview of the included studies  \nThe 20 included studies, published between 2024-2025, encompassed many clinical \napplications with different evaluation datasets: clinical cases (n=5, ranging from 16-302 \ncases), clinical reports/EMG interpretations (n=2, totaling 419 reports), multiple-choice \nquestions (n=2, totaling 5,120 MCQs), evidence synthesis queries (n=4, ranging from \n50-500 queries), actual patient data (n=2, 117 patients), computational vignettes (n=1, \n10,000 calculations), biological/genomic datasets (n=4, including 8 biomarker datasets, \n92 nanobodies, 1,106 gene sets, and 272 articles) (Supplementary Table 1). Sample \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 11\nsizes varied from 8 to 10,000 items. Studies were predominantly comparative designs \n(n=16, 80%), with two simulation studies validated through prospective laboratory \nexperiments (10%), one retrospective case-control study (5%), and one randomized \ncontrolled trial (5%). Clinical domains clustered around decision-support tasks: \ndiagnosis and prognosis applications dominated (n=8, 40%), particularly for rare \ndisease diagnosis, followed by evidence synthesis (n=5, 25%), treatment planning (n=3, \n15%), clinical operations (n=2, 10%), genomics applications (n=2, 10%), and medical \neducation (n=1, 5%). Agent architectures revealed three implementation patterns: \nsingle-agent tool-calling frameworks (n=8, 40%), multi-agent systems without tool \nintegration (n=5, 25%), and hybrid multi-agent plus tool-calling architectures (n=7, 35%). \nThe predominant LLM backbone was the GPT-4 family (n=15, 75%), followed by Llama-\n3 variants (n=4, 20%), Claude-3 Opus (n=4, 20%), and Gemini-1.5 (n=4, 20%), with \nmultiple studies testing several models. Notably, only one study employed prospective \nrandomized controlled trial methodology.  \nRisk of Bias \nQuality assessment using QUADAS-AI criteria revealed some methodological concerns. \nOnly 30% (6/20) of studies achieved low risk of bias across all domains. The remaining \n70% demonstrated high risk in at least one domain, with patient selection representing \nthe most problematic area (60% high risk). Other sources of bias stemmed from: \nsynthetic data dependence (n=13, 65%), single-center designs (n=20, 100%), spectrum \nbias, reference standard concerns (n=5, 25%) (Supplementary Table 1).  \nPerformance Synthesis  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 12\nOverall Performance Improvements \nAggregate performance improvements demonstrated substantial heterogeneity, with \nmedian gains of +36% over baseline LLM (range: +3.5% to +76%).  \nSingle AI Agent Tool-Calling Performance  \nSingle-agent implementations were typically deployed for narrow clinical domains to \naddress specific LLM limitations. These architectures achieved the highest median \nimprovement (+53.0%, IQR: 36.0-56.9%) (Table 2). Our analysis identifies two primary \nreasons for this performance increase: one focuses on enhancement through tools \n(independent of the AI agent framework), while the other pertains to the AI agent \nframework itself. Goodell et al., Xu et al., and Low et al. primarily achieved performance \ngains through the tools they employed. Goodell et al.'s calculation tool, which is crucial \nfor LLMs given their inherent challenges with computations\n55 improved performance by \n+59.1% in comparison to the base-LLM (Gpt-4o). Woo et al., Low et al., and Xu et al. \nshowed improved evidence gathering using domain-specific web search for oncology, \northopedics, and genomics. Web search in the studies we found was the most common \ntool implementation (n=8). In contrast, Ferber et al. observed that clinical decision-\nmaking in oncology necessitates capabilities beyond standard LLMs and tools, including \nmulti-modal interpretation of pathological biopsies, radiographic imaging, and complex \ncalculations, which led to the development of their AI agent. The AI agent surpassed \nbaseline LLM (GPT-4) performance by 56.9%.  Similarly, Pickard et al. developed an AI \nagent for biomarker discovery, yielding improved results compared to both the base-\nLLM and tool augmentation LLM. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 13\nMulti Agents performance \nOur systematic review identified two distinct multi-agent approaches. Pure multi-agent \nsystems without tools showed modest gains (+14.05%, IQR: 8.95-45.15%). Multi-agent \nsystems with tools demonstrated slightly better performance (+17.17%, IQR: 4.12-\n39.3%) with high variance (Table 2). The reason for the high variance may be as these \nmulti-agent frameworks were often applied to tasks that could have been efficiently \nmanaged by either a single agent or tool-augmented LLMs (non-AI agent framework). \nNevertheless, for the studies who showed high increased performance was particularly \nnoteworthy in more complex tasks, indicating that multi-agent systems may be more \nbeneficial in such scenarios. \nQu et al. developed a multi-agent team incorporating a fine-tuned CRISPR-Llama3 \nmodel, completing 22 gene-editing tasks on 288 benchmark test cases and achieving \nexternal validation through AI-guided knockout of four genes (TGF\nβ R1, SNAI1, BAX, \nBCL2L1). Swanson et al. created a \"virtual laboratory\" comprising specialized agents \n(PI, immunologist, machine learning specialist, etc.), successfully developing antibodies \nvalidated through wet-lab experiments. Wang 2025 developed a multi-agent system for \noncology treatment planning, achieving +4.75% improvement over standard ECHO \nauto-planning methods for lung cancer. Moreover, Ke et al. demonstrated that multi-\nagent systems can mitigate clinical decision biases, improving accuracy from 0% to \n76% on bias-containing complex cases, surpassing human physicians by 21%. Chen et \nal. similarly showed that multi-agent improved reasoning for rare disease diagnosis. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 14\nMejia et al. demonstrated managing separately different tools by advanced custom \nmulti-agent frameworks that can automate appointment scheduling by efficiently \nmatching patients with resources. However, the benefits of multi-agent systems tend to \nbe limited for tasks that are already suited for single AI agents. Gorenshtein 2025a, \nChen et al., and Altermatt et al., who utilized multi-agent systems for evidence synthesis \nand answering multiple-choice questions, showed that the improvements are primarily \nlinked to the tools implemented rather than the collaborative efforts of the agents. As \nmentioned by Altermatt et al. that simpler single-agent strategies are sufficient to \naddress most of the questions in the study.\n48 \nAgent Number and Tool Scaling Effects \nOur analysis revealed an inverted-U relationship between agent number and \nperformance, with optimal results at 4-5 agents before declining performance (β  = -\n8.815, R² = 0.162). Tool number showed a weak positive correlation with performance \n(\nβ  = 8.869, R² = 0.377). It’s important to consider that our analysis is highly limited by \ntask heterogeneity and varying comparison baselines (Supplementary Figure 2). \nMulti agent Consensus Method \nMulti-agent implementations employed various consensus mechanisms: supervisor \nagent coordination (36.36%, n=4/11), sequential processing (45.45%, n=5/11), majority \nvoting (9.09%, n=1/11), and custom approaches (9.09%, n=1/11).  \nBase-LLM vs AI agent deployment and backbone suitability \nWe analyzed models with paired baselines and AI agent variants to determine which \nLLM might be most beneficial for implementing AI agent workflows. We did not find any \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 15\nspecific LLM that would benefit significantly more from the AI agent workflow. However, \nwe observed that older models with lower performance might have greater improvement \npotential. \nWhen inspecting backbone suitability for an AI agent framework, Ferber et al. noted that \nsmaller parameter models, such as Llama-3-70B and Mixtral-8×7B, struggle to provide \naccurate timing for tool calling compared to higher preforming models like GPT-4 \n(87.5% for GPT-4 vs. 39.1% for Llama and 7.8% for Mixtral). Similarly, Goodell et al. \ndemonstrated lower performance from Llama-3-70B compared to GPT-4 as backbones \nof AI agent systems. In examining larger parameter models, Omar et al. did not observe \nany significant differences regarding the backbone of the LLM itself. Conversely, Woo et \nal. and Mejia presented conflicting findings; however, Woo et al. study was simple \nenough that the tool itself was enough to solve it, and Meija study utilized different \noutcomes, making it challenging to relate their results to this comparison (Figure 1.). \nPreprint AI agents’ frameworks \nNotable preprint studies not included in the formal analysis demonstrated advancing \ncapabilities of multi-agent frameworks. \n24,30,56,57 The Microsoft MAI-DxO framework \nachieved 85.5% diagnostic accuracy while reducing costs by 69% compared to baseline \nmodels (from $7,850 to $2,397 for comparable accuracy). 21 Li et al. reported \nprogressive performance improvements in a simulated hospital environment across 32 \ndepartments, with agents learning from sequential patient interactions. 49 Integration \nwith electronic health records was demonstrated by Shi et al., showing 29.6% \nimprovement over baseline in multi-tabular reasoning tasks.\n48 For radiological \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 16\napplications, Chen et al. implemented a modular multi-agent system achieving 79.9% \noverall diagnostic accuracy in chest X-ray interpretation (Supplementary Table 2).58 \n \nDiscussion  \nThis systematic review demonstrates that AI agents consistently improve clinical task \nperformance when architecture matches task complexity. Shown by the heterogeneity in \nperformance improvements, ranging from +3.5% to +76%, with greater enhancements \nand narrow range observed when the architecture corresponded to task complexity.  \nOur analysis indicates a step-change over base-LLMs, with AI agents opening \npreviously inaccessible domains (Figure 2.).  \nDefining AI agents in Healthcare \nThe inconsistent use of \"AI agent\" terminology in medical literature\n59,60 necessitates \nclear definitions. Based on the literature16–20,27 and our analysis, we identified the \nfollowing definitions. A true AI agent requires a minimum two of three core capabilities \nwith the first core being mandatory, while for Agentic AI (multi-agent) both the first and \nthe third core are mandatory: 1-Iterative reasoning processes (e.g., ReACT \nprompting61)-mandatory, 2-Tool selection, 3-Multi-agent collaboration. By adopting this \nterminology, we believe future clinical studies can be more accurately categorized into \nLLM, LLM utilizing tools, AI agents, and multi-agent systems (Agentic AI) (Figure 2.).  \nPractical Considerations for Implementation \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 17\nOur analysis reveals several critical factors that institutions should consider when \nimplementing AI agent systems in clinical practice. \nChoosing the Right Model Architecture \nWhile no single LLM emerged as universally superior for AI agent applications, model \nsize significantly impacts performance. Lower performance models struggled with the \ncomplex reasoning required for tool selection. For example, Ferber et al. found that \nGPT-4 achieved 87.5% accuracy in tool-calling decisions compared to only 39.1% for \nLlama-3-70B and 7.8% for Mixtral-8B. This finding contradicts recent enthusiasm for \nsmall language models (SLMs)\n62 in healthcare and suggests institutions should prioritize \nhigher performance, well-validated models for initial implementations.  \nHowever, a promising hybrid approach may reconcile cost concerns with performance \nneeds: using a  high performance \"orchestrator\" model to interpret findings and \ncoordinate tasks (deciding which tool and which agent to use), while deploying smaller, \nspecialized models (SLMs) as \"workers\" for specific functions (using the tool \nthemselves without thinking).\n63 In this architecture, the orchestrator handles complex \nreasoning and tool calling, while SLMs execute defined tasks like data extraction or \ncalculation. This approach could reduce computational costs while maintaining the \nsophisticated reasoning necessary for clinical decision-making. \nOptimal Team Size for Multi-Agent Systems \nFor institutions considering multi-agent implementations, our analysis identified a \nhighest performance for team of 4-5 agents, beyond which performance plateaus or \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 18\neven declines (Supplementary Figure 2A). This finding aligns with established \norganizational theory on optimal team sizes64 and challenges the assumption that \nadding more agents inevitably improves outcomes.65 \nTool Calling and Integration \nThe number of tools showed a modest positive correlation with performance (Figure \n2B), with web search emerging as the most consistently valuable addition (40% of the \nstudies). For clinical deployment, we found that most framework have the following core \nset of validated tools: medical literature search (RAG or web-search domains e.g. \nPubMed) for evidence-based recommendations, calculator functions for dosing and risk \nscores if needed, structured data extraction from clinical notes and current clinical \nguideline access. Additional tools can be added incrementally based on specific \nworkflow needs rather than implemented all at once. \nConsensus Mechanisms: Matching Method to Task \nWhen implementing multi-agent systems, the choice of consensus mechanism matters. \nOur analysis identified three primary approaches with different strengths: Supervisor \ncoordination (36.4% of studies): Best for hierarchical clinical decisions where one agent \nneeds final authority, Sequential processing (45.5%): Optimal for stepwise workflows \nlike diagnostic workups, Democratic voting (9.1%): Most effective for consensus-\nbuilding in ambiguous cases. Recent evidence suggests task-specific optimization: \nvoting protocols excel in diagnostic reasoning tasks (13.2% improvement over \nconsensus) by exploring multiple diagnostic pathways, while consensus methods \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 19\nperform better for factual queries (+2.8%) through cross-verification.66 Institutions \nshould match the consensus mechanism to their specific use case rather than \ndefaulting to one approach. \nImplementation Recommendations \n Based on our findings, we provide a structured approach to implementing AI agents. \nInitially, it is advisable to utilize high-performing models as the primary reasoning model, \nacting as the “orchestrator.” Additionally, it is important to limit the use of multi-agent \nsystems to no more than five specialized agents to maintain clarity and efficiency. \nInstitutions should start with essential tools, such as search functionalities, calculations, \nand data extraction capabilities and expand their toolkit as demonstrated needs arise. \nFurthermore, aligning consensus mechanisms with clinical workflows is crucial, as a \ntailored approach will be more effective than a one-size-fits-all solution. Lastly, \nconsidering hybrid architectures that strike a balance between sophisticated reasoning \nand computational efficiency, such as employing “workers” and SLM for tool-using \nagents, can enhance overall performance. These practical considerations, derived from \nour systematic analysis, provide early roadmap that will require further research to \nvalidate this approach. Institutions and researchers following this roadmap may begin \ntheir journey with AI agents while avoiding common pitfalls as identified in early \nimplementations studies. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 20\nArchitecture-Task Alignment \nIn our analysis, we observed a pattern indicating that more complex frameworks tend to \nyield better performance for intricate tasks. Based on this finding and clinical readiness \nindicators, we built upon the results a practical three-tier framework for clinicians \nconsidering the implementation of AI agents. These tiers based on three criteria: (1) \nconsistency of performance improvement across studies, (2) quality of validation data \n(real-world vs. synthetic), and (3) implementation complexity and risk. This framework \nwill help clinicians avoid both under-utilization of beneficial tools and over-engineering of \nsimple problems. \nTier 1 - Ready for Clinical Pilot Programs: Tool-augmented LLMs  for discrete, \nauditable micro-tasks (medication calculations, Hounsfield unit extraction).\n67,68 These \nshowed +53% median improvement and address specific limitations of standard LLMs, \nwith low bias in the way the tool is being implemented. They primarily rely on Base-LLM \nwithout significant modifications, suggesting a safe application in clinical practice.69,70 \nWoo et al. illustrated that sometimes, the solution lies simply in utilizing tool-augmented \nLLMs. They compared LLMs integrated with RAG to a single AI agent utilizing RAG \n(Tier-2), revealing only a 2% performance increase (+34% compared to the baseline of \nChatGPT-4) when responding to questions concerning orthopedic guidelines. \nTier 2 - Supervised Clinical Research: Single AI agents are well suited to manage \ncomplete clinical workflows (e.g., report generation, treatment recommendations, \ndifferential diagnosis development)58,71. The single AI agent show promise but require \ncareful human oversight. These systems achieved strong performance gains (Ferber et \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 21\nal. +57%, Gao et al. +17%) but rely heavily on synthetic data and lack real-world \nvalidation. We recommend these be tested in supervised research settings with \n\"human-in-the-loop\" mechanisms, allowing clinicians to review and modify outputs \nbefore implementation.72,67 This is particularly important given the ethical considerations \nof autonomous clinical decision-making.75,76 Instead, clinicians should explore, using \nreal clinical data, how iterative reasoning processes can enhance the performance of \ntool-augmented LLMs in tasks that demand more than simple tool usage \nTier 3 - Research Only: Multi-agent systems, despite theoretical appeal, showed high \nvariability, modest improvements over single agents, and in one randomized trial, \nperformed worse than physicians. Our analysis found diminishing returns beyond 4-5 \nagents and suggests these systems are often over-engineered for problems solvable \nwith simpler approaches. Reserve these for genuine interdisciplinary challenges in \ncontrolled research environments. \nThis hierarchical framework function as a three-layer framework where the clinicians \nshould always try implement their choice of model from the lower tier and move to the \nnext tier if the results aren’t sufficient (Figure 3.). By this logic the physicians will benefit \nby having a well fitted model, avoiding unnecessary computational cost or high amount \nof errors. Additionally, researchers will benefit from knowing at which clinical stage they \nshould implement the three framework provided (tool-augmented LLMs, Single AI \nagent, Multi AI agents) (Table 3, Supplementary table 3,4). \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 22\nLimitations \nThis systematic review has several limitations. First, the substantial heterogeneity in \nclinical domains, outcome metrics, and baseline comparators precluded meaningful \nquantitative meta-analysis, limiting our ability to provide precise effect estimates. \nSecond, we restricted peer-reviewed publications, though this decision enhanced \nquality assurance.  Third, the analysis of scaling effects (agent and tool number) is \nconfounded by task heterogeneity and varying comparison baselines. Further, no study \nprovides a comparison of multi-agent to single-agent. Finally, the absence of \nstandardized evaluation frameworks for AI agent systems means performance metrics \nvary widely across studies, complicating direct comparisons. \nFuture Directions-Emerging Evidence from non-peer review Literature \nWhen looking at the preprint analysis we identified further exploration beyond AI agents’ \nperformance. Microsoft AI study who showed the cost-effectiveness of reducing \nunnecessary medical tests through a multi-agent framework (MAI-DxO)\n24. Additionally \nthe integration of AI agents into hospitals and EHR.56,57,77 With Tsinghua University \ntaking the simulated AI-hospital transforming it into real-time evaluations of a hospital \noperating entirely on AI agents.\n78 Such advancements could significantly ease the \ndocumentation burden on physicians79,80 and reducing costs and time.81 Future studies \nshould explore prospective validations, create standardized clinical evaluation \nframework, explore secondary outcome, consensus, task task-architecture matching \nand ethics in AI agent\n82 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 23\nConclusions \nAI agents improve clinical task performance compared with base LLMs, particularly \nwhen architecture is matched to task complexity. Tool-augmented and single-agent \nsystems are ready for near-term deployment, while multi-agent frameworks should be \nlimited to high-complexity problems under research conditions. We define AI agents as \nsystems combining iterative reasoning with tool use and/or multi-agent collaboration to \nguide consistent study and reporting. Future work should emphasize prospective, multi-\ncenter trials with real-world data, standardized evaluation, and integration with \nelectronic health records within clear regulatory frameworks. \n \nReference \n1. Health C for D and R. Artificial Intelligence-Enabled Medical Devices. FDA. Published \nonline July 10, 2025. Accessed August 8, 2025. https://www.fda.gov/medical-\ndevices/software-medical-device-samd/artificial-intelligence-enabled-medical-devices \n2. Singhal K, Tu T, Gottweis J, et al. Toward expert-level medical question answering with large \nlanguage models. Nat Med. 2025;31(3):943-950. doi:10.1038/s41591-024-03423-7 \n3. Katz U, Cohen E, Shachar E, et al. GPT versus Resident Physicians — A Benchmark Based \non Official Board Scores. NEJM AI. 2024;1(5):AIdbp2300192. doi:10.1056/AIdbp2300192 \n4. Goh E, Gallo RJ, Strong E, et al. GPT-4 assistance for improvement of physician performance \non patient care tasks: a randomized controlled trial. Nat Med. 2025;31(4):1233-1238. \ndoi:10.1038/s41591-024-03456-y \n5. Goh E, Gallo R, Hom J, et al. Large Language Model Influence on Diagnostic Reasoning: A \nRandomized Clinical Trial. JAMA Netw Open. 2024;7(10):e2440969. \ndoi:10.1001/jamanetworkopen.2024.40969 \n6. Omar M, Soffer S, Agbareia R, et al. Sociodemographic biases in medical decision making by \nlarge language models. Nat Med. 2025;31(6):1873-1881. doi:10.1038/s41591-025-03626-6 \n7. Hager P, Jungmann F, Holland R, et al. Evaluation and mitigation of the limitations of large \nlanguage models in clinical decision-making. Nat Med. Published online July 4, 2024:1-10. \ndoi:10.1038/s41591-024-03097-1 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 24\n8. Zhao YF, Bove A, Thompson D, et al. Generative AI Is Not Ready for Clinical Use in Patient \nEducation for Lower Back Pain Patients, Even With Retrieval-Augmented Generation. AMIA \nSummits Transl Sci Proc. 2025;2025:644-653. \n9. Au Yeung J, Kraljevic Z, Luintel A, et al. AI chatbots not yet ready for clinical use. Front \nDigit Health. 2023;5:1161098. doi:10.3389/fdgth.2023.1161098 \n10. Roustan D, Bastardot F. The Clinicians’ Guide to Large Language Models: A General \nPerspective With a Focus on Hallucinations. Interact J Med Res. 2025;14:e59823. \ndoi:10.2196/59823 \n11. Omar M, Sorin V, Collins JD, et al. Multi-model assurance analysis showing large language \nmodels are highly vulnerable to adversarial hallucination attacks during clinical decision \nsupport. Commun Med. 2025;5(1):330. doi:10.1038/s43856-025-01021-3 \n12. Asgari E, Montaña-Brown N, Dubois M, et al. A framework to assess clinical safety and \nhallucination rates of LLMs for medical text summarisation. Npj Digit Med. 2025;8(1):274. \ndoi:10.1038/s41746-025-01670-7 \n13. Kim Y, Jeong H, Chen S, et al. Medical Hallucinations in Foundation Models and Their \nImpact on Healthcare. Published online February 26, 2025. doi:10.48550/arXiv.2503.05777 \n14. Alber DA, Yang Z, Alyakin A, et al. Medical large language models are vulnerable to data-\npoisoning attacks. Nat Med. 2025;31(2):618-626. doi:10.1038/s41591-024-03445-1 \n15. Clusmann J, Kolbinger FR, Muti HS, et al. The future landscape of large language models in \nmedicine. Commun Med. 2023;3:141. doi:10.1038/s43856-023-00370-1 \n16. Krishnan N. AI Agents: Evolution, Architecture, and Real-World Applications. Published \nonline March 16, 2025. doi:10.48550/arXiv.2503.12687 \n17. AI agents — what they are, and how they’ll change the way we work. Source. Accessed \nAugust 10, 2025. https://news.microsoft.com/source/features/ai/ai-agents-what-they-are-and-\nhow-theyll-change-the-way-we-work/ \n18. Yang Y, Chai H, Song Y, et al. A Survey of AI Agent Protocols. Published online June 21, \n2025. doi:10.48550/arXiv.2504.16736 \n19. What Are AI Agents? | IBM. July 3, 2024. Accessed August 10, 2025. \nhttps://www.ibm.com/think/topics/ai-agents \n20. What are AI Agents?- Agents in Artificial Intelligence Explained - AWS. Amazon Web \nServices, Inc. Accessed August 10, 2025. https://aws.amazon.com/what-is/ai-agents/ \n21. Gao Y, Xiong Y, Gao X, et al. Retrieval-Augmented Generation for Large Language \nModels: A Survey. Published online March 27, 2024. doi:10.48550/arXiv.2312.10997 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 25\n22. Amugongo LM, Mascheroni P, Brooks S, Doering S, Seidel J. Retrieval augmented \ngeneration for large language models in healthcare: A systematic review. PLOS Digit Health. \n2025;4(6):e0000877. doi:10.1371/journal.pdig.0000877 \n23. Park CR, Heo H, Suh CH, Shim WH. Uncover This Tech Term: Application Programming \nInterface for Large Language Models. Korean J Radiol. 2025;26(8):793-796. \ndoi:10.3348/kjr.2025.0360 \n24. Nori H, Daswani M, Kelly C, et al. Sequential Diagnosis with Language Models. Published \nonline June 27, 2025. doi:10.48550/arXiv.2506.22405 \n25. Barra FL, Rodella G, Costa A, et al. From prompt to platform: an agentic AI workflow for \nhealthcare simulation scenario design. Adv Simul Lond Engl. 2025;10(1):29. \ndoi:10.1186/s41077-025-00357-z \n26. Guo T, Chen X, Wang Y, et al. Large Language Model based Multi-Agents: A Survey of \nProgress and Challenges. Published online April 19, 2024. doi:10.48550/arXiv.2402.01680 \n27. Sapkota R, Roumeliotis KI, Karkee M. AI Agents vs. Agentic AI: A Conceptual Taxonomy, \nApplications and Challenges. Published online May 28, 2025. \ndoi:10.48550/arXiv.2505.10468 \n28. Tsiotras P, Gombolay M, Foerster J. Editorial: Decision-making and planning for multi-\nagent systems. Front Robot AI. 2024;11:1422344. doi:10.3389/frobt.2024.1422344 \n29. Zou J, Topol EJ. The rise of agentic AI teammates in medicine. Lancet Lond Engl. \n2025;405(10477):457. doi:10.1016/S0140-6736(25)00202-8 \n30. Zuo K, Jiang Y, Mo F, Lio P. KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework \nwith Knowledge Graph Enhancement for Medical Diagnosis. Published online March 28, \n2025. doi:10.48550/arXiv.2412.16833 \n31. Wang W, Ma Z, Wang Z, et al. A Survey of LLM-based Agents in Medicine: How far are \nwe from Baymax? Published online May 26, 2025. doi:10.48550/arXiv.2502.11211 \n32. Page MJ, McKenzie JE, Bossuyt PM, et al. The PRISMA 2020 statement: an updated \nguideline for reporting systematic reviews. BMJ. 2021;372:n71. doi:10.1136/bmj.n71 \n33. Derouiche H, Brahmi Z, Mazeni H. Agentic AI Frameworks: Architectures, Protocols, and \nDesign Challenges. Published online August 13, 2025. doi:10.48550/arXiv.2508.10146 \n34. Guni A, Sounderajah V, Whiting P, Bossuyt P, Darzi A, Ashrafian H. Revised Tool for the \nQuality Assessment of Diagnostic Accuracy Studies Using AI (QUADAS-AI): Protocol for a \nQualitative Study. JMIR Res Protoc. 2024;13:e58202. doi:10.2196/58202 \n35. Gorenshtein A, Sorka M, Khateb M, Aran D, Shelly S. Agent-guided AI-powered \ninterpretation and reporting of nerve conduction studies and EMG (INSPIRE). Clin \nNeurophysiol. 2025;177:2110792. doi:10.1016/j.clinph.2025.2110792 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 26\n36. Gorenshtein A, Shihada K, Sorka M, Aran D, Shelly S. LITERAS: Biomedical literature \nreview and citation retrieval agents. Comput Biol Med. 2025;192:110363. \ndoi:10.1016/j.compbiomed.2025.110363 \n37. Omar M, Glicksberg BS, Nadkarni GN, Klang E. Refining LLMs outputs with iterative \nconsensus ensemble (ICE). Comput Biol Med. 2025;196:110731. \ndoi:10.1016/j.compbiomed.2025.110731 \n38. Chen X, Yi H, You M, et al. Enhancing diagnostic capability with multi-agents \nconversational large language models. Npj Digit Med. 2025;8(1):159. doi:10.1038/s41746-\n025-01550-0 \n39. Goodell AJ, Chu SN, Rouholiman D, Chu LF. Large language model agents can use tools to \nperform clinical calculations. Npj Digit Med. 2025;8(1):163. doi:10.1038/s41746-025-\n01475-8 \n40. Ferber D, El Nahhas OSM, Wölflein G, et al. Development and validation of an autonomous \nartificial intelligence agent for clinical decision-making in oncology. Nat Cancer. Published \nonline June 6, 2025:1-13. doi:10.1038/s43018-025-00991-6 \n41. Qu Y, Huang K, Yin M, et al. CRISPR-GPT for agentic automation of gene-editing \nexperiments. Nat Biomed Eng. Published online July 30, 2025:1-14. doi:10.1038/s41551-\n025-01463-z \n42. Automatic biomarker discovery and enrichment with BRAD | Bioinformatics | Oxford \nAcademic. Accessed August 8, 2025. \nhttps://academic.oup.com/bioinformatics/article/41/5/btaf159/8125018 \n43. Woo JJ, Yang AJ, Olsen RJ, et al. Custom Large Language Models Improve Accuracy: \nComparing Retrieval Augmented Generation and Artificial Intelligence Agents to \nNoncustom Models for Evidence-Based Medicine. Arthroscopy. 2025;41(3):565-573.e6. \ndoi:10.1016/j.arthro.2024.10.042 \n44. Swanson K, Wu W, Bulaong NL, Pak JE, Zou J. The Virtual Lab of AI agents designs new \nSARS-CoV-2 nanobodies. Nature. Published online July 29, 2025:1-3. doi:10.1038/s41586-\n025-09442-9 \n45. Ruiz Mejia JM, Rawat DB. MedScrubCrew: A Medical Multi-Agent Framework for \nAutomating Appointment Scheduling Based on Patient-Provider Profile Resource Matching. \nHealthcare. 2025;13(14):1649. doi:10.3390/healthcare13141649 \n46. Wang Z, Jin Q, Wei CH, et al. GeneAgent: self-verification language agent for gene-set \nanalysis using domain databases. Nat Methods. 2025;22(8):1677-1685. doi:10.1038/s41592-\n025-02748-6 \n47. Yang EW, Velazquez-Villarreal E. AI-HOPE: an AI-driven conversational agent for \nenhanced clinical and genomic data integration in precision medicine research. \nBioinformatics. 2025;41(7):btaf359. doi:10.1093/bioinformatics/btaf359 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 27\n48. Altermatt FR, Neyem A, Sumonte N, Mendoza M, Villagran I, Lacassie HJ. Performance of \nsingle-agent and multi-agent language models in Spanish language medical competency \nexams. BMC Med Educ. 2025;25(1):666. doi:10.1186/s12909-025-07250-3 \n49. Xu W, Luo G, Meng W, et al. MRAgent: an LLM-based automated agent for causal \nknowledge discovery in disease via Mendelian randomization. Brief Bioinform. \n2025;26(2):bbaf140. doi:10.1093/bib/bbaf140 \n50. Wang Q, Wang Z, Li M, et al. A feasibility study of automating radiotherapy planning with \nlarge language model agents. Phys Med Biol. 2025;70(7). doi:10.1088/1361-6560/adbff1 \n51. Ke Y, Yang R, Lie SA, et al. Mitigating Cognitive Biases in Clinical Decision-Making \nThrough Multi-Agent Conversations Using Large Language Models: Simulation Study. J \nMed Internet Res. 2024;26(1):e59439. doi:10.2196/59439 \n52. Yang J, Shu L, Duan H, Li H. RDguru: A Conversational Intelligent Agent for Rare \nDiseases. IEEE J Biomed Health Inform. Published online 2024:1-13. \ndoi:10.1109/JBHI.2024.3464555 \n53. Answering real-world clinical questions using large language model, retrieval-augmented \ngeneration, and agentic systems - Yen Sia Low, Michael L Jackson, Rebecca J Hyde, Robert \nE Brown, Neil M Sanghavi, Julian D Baldwin, C William Pike, Jananee Muralidharan, \nGavin Hui, Natasha Alexander, Hadeel Hassan, Rahul V Nene, Morgan Pike, Courtney J \nPokrzywa, Shivam Vedak, Adam Paul Yan, Dong-han Yao, Amy R Zipursky, Christina \nDinh, Philip Ballentine, Dan C Derieg, Vladimir Polony, Rehan N Chawdry, Jordan Davies, \nBrigham B Hyde, Nigam H Shah, Saurabh Gombar, 2025. Accessed August 8, 2025. \nhttps://journals.sagepub.com/doi/10.1177/20552076251348850 \n54. Gorenshtein A, Weisblat Y, Khateb M, et al. AI-Based EMG Reporting: A Randomized \nControlled Trial. J Neurol. 2025;272(9):586. doi:10.1007/s00415-025-13261-3 \n55. Satpute A, Giessing N, Greiner-Petter A, et al. Can LLMs Master Math? Investigating Large \nLanguage Models on Math Stack Exchange. Published online March 30, 2024. \ndoi:10.48550/arXiv.2404.00344 \n56. Shi W, Xu R, Zhuang Y, et al. EHRAgent: Code Empowers Large Language Models for \nFew-shot Complex Tabular Reasoning on Electronic Health Records. Published online \nOctober 4, 2024. doi:10.48550/arXiv.2401.07128 \n57. Li J, Lai Y, Li W, et al. Agent Hospital: A Simulacrum of Hospital with Evolvable Medical \nAgents. Published online January 17, 2025. doi:10.48550/arXiv.2405.02957 \n58. Chen W, Dong Y, Ding Z, et al. RadFabric: Agentic AI System with Reasoning Capability \nfor Radiology. Published online June 17, 2025. doi:10.48550/arXiv.2506.14142 \n59. Giske CG, Bressan M, Fiechter F, et al. GPT-4-based AI agents-the new expert system for \ndetection of antimicrobial resistance mechanisms? J Clin Microbiol. 2024;62(11):e0068924. \ndoi:10.1128/jcm.00689-24 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 28\n60. Zhong Z, Wang Y, Wu J, et al. Vision-language model for report generation and outcome \nprediction in CT pulmonary angiogram. Npj Digit Med. 2025;8(1):432. doi:10.1038/s41746-\n025-01807-8 \n61. On the Brittle Foundations of ReAct Prompting for Agentic Large Language Models. \nAccessed August 9, 2025. https://arxiv.org/html/2405.13966v1 \n62. Shen W, Li C, Chen H, et al. Small LLMs Are Weak Tool Learners: A Multi-LLM Agent. \nPublished online February 16, 2024. doi:10.48550/arXiv.2401.07324 \n63. Yang Z, Chen Y, Zhou X, et al. Agentic Robot: A Brain-Inspired Framework for Vision-\nLanguage-Action Models in Embodied Agents. Published online June 11, 2025. \ndoi:10.48550/arXiv.2505.23450 \n64. Bumbuc Ş . Team Size and its Influence on the Teamwork and Communication. Int Conf \nKnowl-BASED Organ. 2024;30(2):114-119. doi:10.2478/kbo-2024-0061 \n65. Li J, Zhang Q, Yu Y, Fu Q, Ye D. More Agents Is All You Need. Published online October \n11, 2024. doi:10.48550/arXiv.2402.05120 \n66. Kaesberg LB, Becker J, Wahle JP, Ruas T, Gipp B. Voting or Consensus? Decision-Making \nin Multi-Agent Debate. In: Findings of the Association for Computational Linguistics: ACL \n2025. ; 2025:11640-11671. doi:10.18653/v1/2025.findings-acl.606 \n67. CT-Agent: A Multimodal-LLM Agent for 3D CT Radiology Question Answering. Accessed \nAugust 9, 2025. https://arxiv.org/html/2505.16229v1 \n68. Tu T, Azizi S, Driess D, et al. Towards Generalist Biomedical AI. NEJM AI. \n2024;1(3):AIoa2300138. doi:10.1056/AIoa2300138 \n69. Goh E, Gallo R, Hom J, et al. Large Language Model Influence on Diagnostic Reasoning: A \nRandomized Clinical Trial. JAMA Netw Open. 2024;7(10):e2440969. \ndoi:10.1001/jamanetworkopen.2024.40969 \n70. Goh E, Gallo RJ, Strong E, et al. GPT-4 assistance for improvement of physician \nperformance on patient care tasks: a randomized controlled trial. Nat Med. Published online \nFebruary 5, 2025:1-6. doi:10.1038/s41591-024-03456-y \n71. Gao S, Zhu R, Kong Z, et al. TxAgent: An AI Agent for Therapeutic Reasoning Across a \nUniverse of Tools. Published online March 14, 2025. doi:10.48550/arXiv.2503.10970 \n72. Mozannar H, Bansal G, Tan C, et al. Magentic-UI: Towards Human-in-the-loop Agentic \nSystems. Published online July 30, 2025. doi:10.48550/arXiv.2507.22358 \n73. Lee YC. Rethinking artificial intelligence in medicine: from tools to agents. Clin Exp Emerg \nMed. 2025;12(2):101-103. doi:10.15441/ceem.25.125 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 29\n74. Bellos F, Li Y, Shu C, Day R, Siskind JM, Corso JJ. Towards Effective Human-in-the-Loop \nAssistive AI Agents. Published online July 24, 2025. doi:10.48550/arXiv.2507.18374 \n75. Cerqueira JAS de, Agbese M, Rousi R, Xi N, Hamari J, Abrahamsson P. Can We Trust AI \nAgents? A Case Study of an LLM-Based Multi-Agent System for Ethical AI. Published \nonline May 16, 2025. doi:10.48550/arXiv.2411.08881 \n76. Gabriel I, Keeling G, Manzini A, Evans J. We need a new ethics for a world of AI agents. \nNature. 2025;644(8075):38-40. doi:10.1038/d41586-025-02454-5 \n77. Armitage H. Clinicians can ‘chat’ with medical records through new AI software, ChatEHR. \nNews Center. June 5, 2025. Accessed August 9, 2025. https://med.stanford.edu/news/all-\nnews/2025/06/chatehr.html \n78. Tsinghua University holds Tsinghua AI Agent Hospital Inauguration and 2025 Tsinghua \nMedicine Townhall Meeting-Tsinghua University. Accessed August 10, 2025. \nhttps://www.tsinghua.edu.cn/en/info/1245/14224.htm \n79. Gaffney A, Woolhandler S, Cai C, et al. Medical Documentation Burden Among US Office-\nBased Physicians in 2019: A National Study. JAMA Intern Med. 2022;182(5):564-566. \ndoi:10.1001/jamainternmed.2022.0372 \n80. Murad MH, Vaa Stelling BE, West CP, et al. Measuring Documentation Burden in \nHealthcare. J Gen Intern Med. 2024;39(14):2837-2848. doi:10.1007/s11606-024-08956-8 \n81. Sorka M, Gorenshtein A, Abramovitch H, Soontrapa P, Shelly S, Aran D. AI vs Human \nPerformance in Conversational Hospital-Based Neurological Diagnosis. Published online \nAugust 14, 2025:2025.08.13.25333529. doi:10.1101/2025.08.13.25333529 \n82. Taylor RA. AI Agents, Automaticity, and Value Alignment in Health Care. NEJM AI. \n2025;2(8):AIp2401165. doi:10.1056/AIp2401165 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 30\nTables \nTable 1. Study Characteristics  \n \nStudy Study \ndesign \nClinical \nDomain \nSample \nSize \nAgent \nArchitecture \nFramework Tools \nIntegration \nMulti \nagent \nConsens\nus \nMethod \nChen \net al.  \nComparti\nve \nDiagnosis & \nPrognosis (Rare \ndisease)  \n302 cases Multi Agents \n(n=5)  \nAutoGen Web search \n(Orphanet \ndatabase) \nHierarchi\ncal \nsuperviso\nr \nGoode\nll et al.  \nComparti\nve \nClinical \nOperations & \nTriage- Clinical \ncalculations \n10,000 \ncalculation \nvignettes \nSingle \nAgent+Tool \nCalling (n=3)  \nLangChain OpenMedC\nalc, code \nexecutor, \nRAG \nN/A \nOmar \net al.  \nComparti\nve  \nDiagnosis & \nPrognosis \n4,058 \nMCQs \nMulti Agents \n(n=3)  \nCustom  None Sequenti\nal \n(Iterative \nconsensu\ns) \nGoren\nshtein \n2025a \nComparti\nve \nEvidence \nsynthesis \n150 \nqueries \nMulti Agents \n(n=6) + Tool \nCalling (n=1) \nAutoGen Web search \n(PubMed \nAPI) \nSequenti\nal \nGoren\nshtein \n2025b \nRetrospe\nctive \ncase \ncontrol \nDiagnosis & \nPrognosis -\nNeurology  \n219 \nreports \nMulti Agents \n(n=3) + Tool \nCalling (n=1) \nCustom RAG  Sequenti\nal  \nGoren\nshtein \n2025c \nRCT Diagnosis & \nPrognosis -\nNeurology  \n200 \nreports \nMulti Agents \n(n=10) + Tool \nCalling (n=2) \nAutoGen RAG, EHR \nconnection \nSequenti\nal \nFerber \net al.  \nComparti\nve \nTreatment & \nCare Planning -\nOncology \n20 cases Single \nAgent+Tool \nCalling (n=5) \nCustom RAG, vision, \nweb search, \ncode \nexecutor, \ntransformer \nmodel \nN/A \nQu et \nal.  \nSimulatio\nn+ \nprospecti\nve lab \nGenomics \n(CRISPR) \n288 \nbenchmark \ntest case \nMulti Agents \n(n=4) + Tool \nCalling (n=3) \nCustom Web \nsearch, \nPrimer3 \n(PCR primer \ndesigner), \nSequenti\nal \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 31\nRAG \nPickar\nd et al.  \nSimulatio\nn \nBiomarker \ndiscovery \n8 datasets Single \nAgent+Tool \nCalling (n=4) \nLangChain Database \nAPIs, web \nsearch, \ncode \nexecutor, \ncustom tool \nN/A \nWoo \net al.  \nComparti\nve \nEvidence \nsynthesis- \nOrthopedics \n100 \nquestions \nSingle \nAgent+Tool \ncalling (n=2)  \nLangChain RAG, \nquality \njudge LLM \nN/A \nSwans\non et \nal.  \nSimulatio\nn+ \nprospecti\nve lab \nTreatment & \nCare Planning -\nImmunology \n92 \nnanobodie\ns \nMulti Agents \n(n=6) + Tool \nCalling (n=3) \nCustom ESMFold, \nAlphaFold, \nRosetta \nHierarchi\ncal \nsuperviso\nr \nMejia \net al.  \nSimulatio\nn \nClinical \nOperations & \nTriage \n100 patient \n(MIMIC-IV)\n \nMulti Agents \n(n=9) + Tool \nCalling (n=4) \nCustom RAG, ML \nmodel, math \nequations \nalgorithm, \nEHR \nCustom-\nMatching\n \nWang \n2025a \nComparti\nve \nEvidence \nsynthesis- \nGenomics \n1,106 \ngene sets \nSingle \nAgent+Tool \nCalling (n=1)  \nCustom Web API \ndomain \ndatabases \nN/A \nYang  \n2025 \nComparti\nve \nEvidence \nsynthesis- \nOncology/geno\nmics \n500 \nqueries \nSingle \nAgent+Tool \nCalling (n=1) \nCustom Code \nexecutor \nN/A \nAlterm\natt et \nal.  \nComparti\nve \nMedical \neducation \n1,062 \nMCQs \nMulti Agents \n(n=6)  \nCustom None Majority \nvoting \nXu et \nal.  \nComparti\nve \nEvidence \nsynthesis- \nGenomics (MR) \n272 \narticles \nSingle \nAgent+Tool \nCalling (n=1)  \nCustom Web APIs \n(5 websites) \nN/A \nWang \n2025b \nComparti\nve \nTreatment & \nCare Planning- \nRadiation \noncology \n17 patients\n Multi Agents \n(n=4) + Tool \nCalling (n=3) \nCustom Retrieval, \noptimization \ntools \nHierarchi\ncal \nsuperviso\nr \nKe et \nal.  \nComparti\nve \nDiagnostic \nreasoning \n16 cases Multi Agents \n(n=4) \nAutoGen None Hierarchi\ncal \nsuperviso\nr \nYang \n2024 \nComparti\nve \nDiagnosis & \nPrognosis (Rare \ndisease) \n238 cases Single \nAgent+Tool \nCalling (n=5) \nLangChain Web, RAG, \nML, code, \nheuristic \nN/A \nLow et \nal.  \nComparti\nve \nEvidence \nsynthesis \n50 queries Single \nAgent+Tool \nCalling (n=1) \nCustom Code \nexecutor \nN/A \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 32\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nTable 2. Clinical performance of agent versus baseline \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 33\nStudy AI Agent Base-LLM \nModel(s)*  \nPrimary \nOutcome \nAgent vs \nBaseline* \nBaseline \ncompariso\nn \nExternal \nvalidation \nSyntheti\nc Data \nChen et \nal. \nGPT-4 Accuracy +14.3% Base-LLM No Yes \nGoodell et \nal. \nGPT-4o, Llama-3 Accuracy +59.1% Base-LLM Yes Yes \nOmar et \nal. \nGPT-4o, Claude, \nGemini-1.5-Pro \nAccuracy +13.8% Base-LLM No No \nGorenshte\nin 2025a \nGPT-4o-mini Accuracy +3.5% Single LLM \n(Sonar-pro) \nNo Yes \nGorenshte\nin 2025b \nGemini-1.5-Pro-002 Accuracy +29.6% Base-LLM Yes-\nPhysician \nreview \nNo \nGorenshte\nin 2025c \nGPT-4o Quality score -25.5% Physicians Yes-\nComparison \nto Physician \nNo \nFerber et \nal. \nGPT-4 Accuracy +56.9% Base-LLM Yes- \nPhysician \nreview \nMixed \nQu et al. GPT-4o, CRISPR-\nLlama3-8B (fine tuned \nLlama3-8b) \nDesign \nsuccess \n+49% Base-LLM Yes- in-vitro \nvalidation \nMixed \nPickard et \nal. \nGPT-4 Enrichment \nsimalirty \nscore \n+61.7% Base-LLM Yes No \nWoo et al. GPT-4, Claude-3, \nLlama-3-70B, GPT-\n3.5, Mistral-8x7B \nAccuracy +36% Base-LLM Yes-\nPhysician \nreview \nYes \nSwanson \net al. \nGPT-4o Binding \nimprovement \n2/92 \nimproved \nBaseline \nwild-type \nnanobodies \n(no agent \ndesign) \n \nYes- in-vitro \nvalidation \nMixed \nMejia et \nal. \nGPT-4o, GPT-4o-mini, \nQwen-2.5-32B, \nDeepSeek-R1 \nCustom score N/A Base-LLM No No \nWang \n2025a \nGPT-4 ROUGE-L +7.1% Base-LLM No No \nYang 2025 Llama-3 None N/A None No Yes \nAltermatt \net al. \nGPT-4o Accuracy +4.1% Base-\nLLM+chain \nof thoughts \nNo Yes \nXu et al. GPT-4-Turbo, GPT-\n3.5-Turbo, Mixtral-\nAccuracy N/A None Yes Yes \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 34\n8x22B, Llama-3 8B, \nLlama-3 70B, Qwen \n2.5-max, Claude-3-\nOpus \nWang \n2025b \nGPT-4o PTV D95 +4.75% ECHO auto-\nplanner \nYes Yes \nKe et al. GPT-4-Turbo Accuracy +76% \n(Base-LLM) \n28% \n(Physician) \nBase-LLM, \nPhysicians \nYes-\nComparison \nto Physician \nYes \nYang 2024 GPT-3.5-Turbo F1 score +53% Base-LLM Yes Yes \nLow et al. ChatRWD Accuracy +48% Chatgpt-4 No Yes \n*The comparison to Baseline unless described otherwise is to Base-LLM. This was \nconducted on the best performance agentic LLM backbone (e.g. ChatGPT-4 Agentic \ncompared to Chatgpt-4). Percentage point difference \n \n \n \n \n \n \n \n \n \n \n \nTable 3. AI Agent Architecture Selection Framework for Clinical Medicine \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 35\n \n \nArchitecture \nType \nWhen to Use \n(Decision \nCriteria) \nClinical \nApplications \nImplementation \nRequirements \nKey Considerations\n& Limitations \nSimple Tool \nAugmentation \nDirect tool \ninvocation \nwithout \niteration \n• Single, \ndeterministic \noperation \n• Well-defined \ninput/output \n• No reasoning \nrequired \n• Immediate \nresponse needed \n• Clear success \nmetrics \nMedication \nDosing \nLab Value \nConversion \nDICOM HU \nExtraction \nICD-10 Lookup \nDrug Interaction \nCheck Risk \n Score \nCalculation \nTechnical: \n• API \nintegration \n• Minimal \ncompute \n• No model fine-\ntuning \n \nClinical: \n• EHR \nintegration \n• Validated \nalgorithms \n• Regulatory \nclearance for \ncalculations \nLimited to discrete \ntasks \nNo complex \nreasoning \nCannot handle \nambiguity \nBest for: High-\nvolume, repetitive \ntasks requiring \nconsistent accuracy \nAvoid for: Tasks \nrequiring clinical \njudgment or context \nSingle-Agent \nSystems \nAutonomous \nreasoning \nwith tool \norchestration \n• Multi-step \nworkflows \n• Tool selection \ndecisions \n• Iterative \nrefinement needed \n• End-to-end task \ncompletion \n• Context \npreservation \nrequired \nRadiology \nReports \nEMG \nInterpretation \nLiterature \nTriage \nClinical \nSummaries \nTreatment \nPlanning \nDischarge \nNotes \nTechnical: \n• ReAct/CoT \nprompting \n• Memory \nmanagement \n• Tool API suite \n• GPT-4+ class \nmodels \n \nClinical: \n• Workflow \nintegration \n• Audit trails \n• Human \noversight \nprotocols \nContext window \nlimits \nSingle perspective \nTool timing critical \nBest for: Structured \nworkflows with clear \nobjectives \nOptimal tools: 3-5 \nspecialized tools \nKey success \nfactor: Well-defined\ntask boundaries \nMulti-Agent \nEcosystems \nCollaborative \nspecialized \nagents \n• Cross-specialty \nexpertise \n• Conflicting \nevidence synthesis \n• Bias mitigation \ncritical \n• Complex \nconsensus needed \n• Interdisciplinary \ncollaboration \nRare Disease \nDx \nTumor Board \nGene Editing \nVirtual Lab \nMulti-Omics \nICU \nManagement \nTechnical: \n• Agent \norchestration \n• Consensus \nmechanisms \n• Distributed \ncompute \n• Optimal: 4-5 \nagents \n \nCoordination \noverhead \nConflicting outputs \nError propagation \nBest for: Genuinely \ninterdisciplinary \nchallenges \nCaution: Diminishing\nreturns >5 agents \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 36\nClinical: \n• Multi-\ndisciplinary \nprotocols \n• Role \ndefinitions \n• Conflict \nresolution \n• Clinical \nBIases \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigures \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 37\nFigure 1. Agentic LLM backbones for clinical tasks: uplift over single-model baselines \nand per-study comparisons \na, “Base vs agentic” performance for five backbones. Bars show accuracy/success (%) \nreported in the cited sources; orange = As agent, blue = Single LLM. Numbers above \nbars are percentage-point (pp) uplift. Values: ChatGPT-4o 88.93 vs 47.91 (+41.0 pp); \nGPT-4 68.97 vs 25.23 (+43.7 pp); Gemini-1.5-Pro 71.97 vs 45.58 (+26.4 pp); Llama-3-\n70B 88.50 vs 46.00 (+42.5 pp); Claude-3.5-opus 72.83 vs 61.34 (+11.5 pp). \nb, Per-study agentic comparisons. Goodell et al. (clinical calculations): GPT-4o 95.2, \nLlama-3-70B 84.0. Woo et al. (orthopedic guideline QA): GPT-4 95.0, Llama-3 93.0. \nOmar et al. - ICE (final agentic versions): Claude-3.5-opus-ICE 72.83, ChatGPT-4o-ICE \n72.59, Gemini-ICE 71.97. Ferber et al.: GPT-4 87.5, Llama-3-70B 39.1, Mixtral-8×7B \n7.8. Mejia et al. - MedScrubCrew* (overall composite): Qwen-2.5-coder-32B 59.0; \nQwen-2.5-32B 54.9; QwQ-32B 53.4; GPT-4o 54.2; GPT-4o-mini 50.2; DeepSeek-R1 \n \nE \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 38\n(Llama-70B) 45.6. *Asterisk denotes an approximated composite (macro-average of 27 \njudged items). \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 39\nFigure 2. Conceptual foundations of LLM agent systems and a summary of the main \nresults of the review.  \n \nA. The top panel shows the progression in agentic scale from a baseline LLM to a tool-\naugmented LLM, a single LLM agent, and a multi-agent system. \nB. The bottom panel summarizes findings of the review: single agents produced a \nmedian 53% performance gain over base LLMs; multi-agent systems delivered larger \nbenefits for complex tasks with optimal teams of 4–5 agents; web search was the most \ncommonly used and most impactful tool (about 40% of studies); many studies relied on \nsynthetic data and lacked multi-site validation. The gradient indicates increasing agentic \ncomplexity and coordination. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 40\nFigure 3. Hierarchical taxonomy of agentic AI architectures in clinical medicine \n \n \nConcentric circles delineate the progressive complexity of agentic systems. \nInner circle: Tool-based micro-tasks- deterministic tool invocation by a baseline LLM for \nrapid, low-complexity operations (for example, evidence synthesis, dose calculators, \nDICOM HU extraction). \nMiddle circle: Single-agent reasoning- an autonomous, reasoning-enabled LLM that \nself-selects tools to complete an end-to-end clinical workflow (for example, EMG report \ngeneration, literature triage). \nOuter circle: Multi-agent ecosystems- coordinated networks of specialised, tool-enabled \nagents that fuse multimodal data to tackle high-stakes, cross-disciplinary problems (for \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 41\nexample, rare-disease diagnosis, gene-editing design, post-deployment surveillance). \nThe schematic underpins the three-tier implementation framework proposed in this \nreview. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint \n 42\n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted August 26, 2025. ; https://doi.org/10.1101/2025.08.22.25334232doi: medRxiv preprint ",
  "topic": "Data extraction",
  "concepts": [
    {
      "name": "Data extraction",
      "score": 0.6527815461158752
    },
    {
      "name": "Scopus",
      "score": 0.5647655129432678
    },
    {
      "name": "Computer science",
      "score": 0.5633343458175659
    },
    {
      "name": "MEDLINE",
      "score": 0.34694719314575195
    },
    {
      "name": "Artificial intelligence",
      "score": 0.32311099767684937
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98704320",
      "name": "Icahn School of Medicine at Mount Sinai",
      "country": "US"
    }
  ]
}