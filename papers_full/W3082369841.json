{
  "title": "Language modeling in speech recognition for grammatical error detection based on neural machine translation",
  "url": "https://openalex.org/W3082369841",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A5112396722",
      "name": "Jiang Fu",
      "affiliations": [
        "Tohoku University"
      ]
    },
    {
      "id": "https://openalex.org/A5108454997",
      "name": "Yuya Chiba",
      "affiliations": [
        "Tohoku University"
      ]
    },
    {
      "id": "https://openalex.org/A5103144936",
      "name": "Takashi Nose",
      "affiliations": [
        "Tohoku University"
      ]
    },
    {
      "id": "https://openalex.org/A5082389304",
      "name": "Akinori Ito",
      "affiliations": [
        "Tohoku University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2059361172",
    "https://openalex.org/W2899816115",
    "https://openalex.org/W333426446",
    "https://openalex.org/W1589436371",
    "https://openalex.org/W2125320996",
    "https://openalex.org/W2133564696",
    "https://openalex.org/W1597582868",
    "https://openalex.org/W2398741870",
    "https://openalex.org/W2006969979",
    "https://openalex.org/W420125090"
  ],
  "abstract": null,
  "full_text": "Language modeling in speech recognition for grammatical error detection\nbased on neural machine translation\nJiang Fu /C3 , Yuya Chiba y, Takashi Nose z and Akinori Ito x\nGraduate School of Engineering, Tohoku University, Aramaki Aza-Aoba 6–6–05, Aoba-ku, Sendai, 980–8579 Japan\n(Received 23 December 2019, Accepted for publication 9 March 2020)\nKeywords: Automatic speech recognition, Language modeling, Sentence generation with errors, Encoder-decoder model\nPACS number: 43.72./C0 p [doi:10.1250/ast.41.788]\n1. Introduction\nWith the rapid development of globalization, English\nlanguage learning is becoming increasingly popular. As one\nof the eﬃcient language learning methods, the computer-\nassisted language learning (CALL) systems support English\nstudy for second language (L2) learners. Owing to the huge\nadvances in modern information technology, the speech-based\nCALL systems based on automatic speech recognition (ASR)\nhave been developed [1,2].\nIn a previous work, a speech-based CALL system for\ngrammar exercise was established [1]. Figure 1 shows the\nschematic diagram of this system. The exercise control part\nposes a question to the learner, and at the same time, it\nprepares a supposed correct answer of the question. When the\nlearner answers the question, the answer speech is recognized\nby the speech recognizer. Then the recognition result is\ncompared with the correct answer, and the parts that are\ndiﬀerent are pointed out as possible grammatical errors. To\nrealize the system, the speech recognizer in the system should\nrecognize the L2 learner’s utterance, including grammatical\nerrors, as accurately as possible to provide eﬀective and\ncorrective feedback.\nThe quality of ASR depends on its two main components:\nacoustic models (AMs) and language models (LMs). So far,\nwith the widespread application of deep learning, a large\nnumber of research studies on deep neural network (DNN)-\nbased acoustic models have increasingly improved the speech\nrecognition rate for non-native speech [3,4]. However, in\nthese ordinary DNN-based systems, less attention has been\npaid to establishing LMs in ASR for improving the recog-\nnition of L2 speech with grammatical errors.\nTo ﬁll this gap, in the current study, we concentrate on the\nLMs in ASR for promoting the recognition of grammatical\nerrors in L2 spoken speech. We exploit the neural machine\ntranslation (NMT), which can generate sentences with\ngrammatical errors from the correct sentences, to obtain\ntraining data for language modeling. Then we compare the\ndeveloped LM with the conventional ones. Finally, we\nanalyze the performance of the proposed LM in grammatical\nerror detection (GED).\n2. A problem in the previous works\nFirst, we give an overview of language modeling in the\nASR system for speech-based grammatical error detection.\nSince an ordinary English corpus does not contain many\ngrammatical mistakes, an LM trained with such a corpus\ncannot model grammatical errors, resulting in the failure to\nrecognize these mistakes. The previous works established\nhandcrafted grammatical error rules and implemented those\nrules on the prompted correct source sentences to generate\nnew sentences with errors [1,5,6]. For instance, Anzai and\nIto [1] proposed an approach to artiﬁcially generate sentences\nwith grammatical errors using rules from the NICT Japanese\nLearner English (JLE) corpus [7].\nA problem with their method is that it is unclear whether\nthe proposed rules are ‘ ‘optimum’ ’ in some cases. Because\ntheir rules were heuristically established, the generated\nsentences do not necessarily reﬂect the comprehensive\nsituation of English spoken by Japanese learners.\nTherefore, we examine the use of the NMT to convert\ncorrect English sentences into those with grammatical errors\nand train new n-gram language models using these sentences.\n3. Preparation of databases\nAs data-driven approaches are applied in this research,\nhere, we introduce the data sets used in our system. The data\nsets can be roughly divided into two categories: the text data\nused for training NMT and the data trained/evaluated in ASR.\n3.1. Text corpora\nTo train the NMT model, we need right-to-wrong\nsentence pairs. We used the NICT JLE corpus [7], which\nincludes the transcribed text of audio-recorded speech\nsamples in an English oral proﬁciency interview test (Stand-\nard Speaking Test, SST) for Japanese students. We used 167\nﬁles of the interviews annotated with grammatical errors in\nthis corpus. In total, 8,476 right-to-wrong sentence pairs were\ncreated for training the NMT.\nRegarding the development of NMT aimed at generating\nsentences with errors, since most of the components in input\nand output sentences are the same, we ﬁrst trained an initial\nNMT with the ability to output the same sentence as the input\nsentence. We used the Cornell Movie-Dialogs Corpus [8] for\nthe initial training, which is a large collection of English\nconversations extracted from movie scripts. The raw data in\nthis corpus is represented in dialogue turns labeled with movie\nmetadata. As this initial NMT concentrates on generating\n/C3 e-mail: fujiang@ecei.tohoku.ac.jp\nye-mail: yuya@spcom.ecei.tohoku.ac.jp\nze-mail: nose@tohoku.ac.jp\nxe-mail: aito@spcom.ecei.tohoku.ac.jp\n788\nAcoust. Sci. & Tech.41, 5 (2020) #2020 The Acoustical Society of Japan\nidentical sentences, we trimmed the data in this dialogue\ncorpus by removing the sentences containing low-frequency\nwords from the original 304,713 utterances, whereby 201,935\nidentical sentence pairs were reproduced for the initial NMT.\n3.2. Speech corpora\nTo establish the acoustic model in our speech-based\nCALL system, we used the English read by Japanese (ERJ)\ndatabase [9]. English text read by 100 male and 102 female\nJapanese students are included in this database. 24,698 uttered\nsentences from the ERJ database were prepared for acoustic\nmodeling in ASR.\nTo evaluate the proposed language model in our system\nfor GED, we developed an oral translation corpus called the\nTohoku Japanese-to-English oral translation (TJTEOT) cor-\npus.\nWe assumed the grammar exercise of Japanese-to-English\ntranslation to be the restricted exercise in our work; therefore,\nthe Japanese sentences had corresponding reference English\nsentences called ‘ ‘target sentences.’ ’ We allowed the learners\nto practice basic phrases and vocabulary in advance, so\nthat the grammatical errors were mainly article errors,\npreposition errors and verb errors. When a learner spoke the\ntranslated English sentences, the sentences often contained\nmany grammatical errors. These sentences were called\n‘ ‘uttered sentences.’ ’\nThe translation content deﬁned for the TJTEOT corpus is\nsimilar to that in the previous work [1]. The content is related\nto daily English conversation. In total, there are 42 target\nsentences with an average of eight words in one sentence. The\nprocedure of recording the utterances was as follows.\n(1) Practice. We prepared the Japanese sentences and the\ncorresponding target sentences. Fourteen target senten-\nces were used as the material of the grammar exercise.\nThe learners were asked to read and practice these\nsentences. There was no time limitation for practice.\n(2) Recording. After the learners thought they were ready,\nthe recording began. The Japanese text was presented\nto them, and they were asked to say aloud the English\ntranslation sentence by sentence.\nWe recorded the speech data from ﬁve students of Tohoku\nUniversity, comprising 2 males and 3 females. By counting\nthe diﬀerent sentences that occurred in the recording set, we\nobtained 144 diﬀerent uttered sentences from the 42 original\ntarget sentences. Table 1 shows some recorded sentences\nfrom the learners. The learners made some article errors or\nverb errors in their speech.\n4. Experiments\n4.1. Experimental setup\nWe generated sentences with errors using an encoder-\ndecoder model implemented with Keras.\n1 Figure 2 shows the\nstructure of the model. This is a neural network sequence\nmodel with an attention mechanism [10] that takes a correct\nsource sentence into a vector and generates a sentence with\ngrammatical errors using the decoder. As the ﬁrst step in the\ntraining of an initial NMT to generate identical sentences,\nwe used 201,935 identical sentence pairs to train the NMT\nmodel. Table 2 shows the experimental conditions. We set the\nnumber of time steps with the maximum number of words in\nan English sentence to 22 and the number of gated recurrent\nunits (GRUs) to 256 units. The number of epochs in the initial\nmodel was 50.\nWhen the initial NMT model was established, it was ﬁne-\ntuned to the prepared 8,476 right-to-wrong sentence pairs\nby running additional training epochs. Ten diﬀerent epochs\nð10; 20; 30; 40; 50; 60; 70; 80; 90; 100Þ were set in this process\nfor updating the parameters of the initial NMT model,\nyielding ten new NMT models for generating sentences with\nerrors.\nTo evaluate the proposed method for language modeling\nin ASR, we ﬁxed the acoustic model referring to our previous\nwork [4]. This DNN-based AM was trained using the ERJ\ncorpus with the conditions shown in Table 3.\nTable 1 Examples of uttered sentences in learners’ speech.\nTarget sentence He works at a hospital.\nUttered sentences He work at a hospital.\nHe worked at a hospital.\nHe works at a hospital.\nHe works at hospital.\nFig. 2 Proposed NMT model with attention mechanism\nfor sentence generation with grammatical errors.\nTable 2 Settings of our proposed NMT for language\nmodeling.\nRNN architecture GRUs\nNo. of units in hidden layer 256\nTime steps of input layer 22\nOptimizer Adam\nActivation functions softmax\nTrainable parameters 16,434,516\nFig. 1 Schematic diagram of a speech-based CALL\nsystem for grammatical error detection.\n1https://github.com/keras-team/keras\nJ. FU et al.: LANGUAGE MODELING IN ASR FOR GED BASED ON NMT\n789\n4.2. Comparison of recognition results using diﬀerent\nlanguage models\nTo develop the rule-based error generator, we aligned the\nright and wrong sentence pairs in the NICT JLE corpus using\nIBM Model 1 alignment [11]. We used the word.alignment\npackage for R. Then we extracted 5841 error phrase pairs. The\ntop ﬁve right-wrong pairs with the highest frequency of\noccurrence are shown in Table 4. Then we randomly replaced\nthe ‘ ‘right’ ’ part included in the input sentence with the\n‘ ‘wrong’ ’ phrase. The probability of applying any error rule\nin a sentence was set to 0.9. Insertion errors were treated\ndiﬀerently from other errors. First, we determined whether\ninsertion error is applied with a probability proportional to the\nfrequency of the insertion error. If an insertion error was\napplied, the position of insertion was determined randomly,\nand the word to insert was chosen in accordance with the\nrelative frequency of insertion errors. If no insertion error\nwas applied, other errors (substitution and deletion errors)\nwere chosen in accordance with the relative frequency and\napplied to the input sentence.\nWe obtained 420 English sentences from the ten ﬁne-\ntuned NMT models and another 420 sentences from the rule-\nbased error generator. Table 5 shows some sentences gen-\nerated from a target sentence. We can see that most errors\ngenerated by the rules are not related to the actual errors that\nappeared in the speech.\nWe prepared ﬁve LMs for comparison, as shown in\nTable 6. The baseline model was trained from the sentences\nfrom the ERJ database and the target sentences from the\nTJTEOT corpus, considering the situation where the senten-\nces the learners were supposed to say were known. The\nLM\nrule and LM NMT models were trained by adding the\nsentences generated by rule-based error generation and the\nNMT, respectively. We merged the two sets of generated\nsentences to train the LM\nrule & NMT model. We doubled\nthe number of generated sentences in both LM rule and\nLM NMT. Thus, the number of sentences in the middle three\nLMs in Table 6 is the same. Finally, in the LM gold model,\nthe sentences uttered as a part of the training data to\ninvestigate the performance of the closed model were used.\nFigure 3 shows the speech recognition results of applying\nthe ﬁve diﬀerent language models. By comparing with the\nresult of baseline LM, the contribution of the other four LMs\nto recognition accuracy in ASR was determined. In particular,\nwith the closed-condition gold LM, the value of WER\ndecreased to 2.35%. By investigating the results of using the\nmiddle three LMs, we found that the previous rule-based\nLM slightly improved the recognition and our proposed\nLM resulted in greater accuracy than that with the previous\nmethod. The performance of the combined LM with the\ncombination of rule-based and NMT-based sentences was\nslightly worse than that of the NMT-based model, indicating\nthat the rule-based method produced some errors unrelated to\nreal errors. The recognition results show that if the LM\nincludes real grammatical errors committed by the learners,\nthe ASR will perform better.\nTable 3 DNN parameters of acoustic modeling in ASR.\nInput feature 40 MFCCs\nType of hidden layer hyperbolic tangent\nNo. of input nodes 360\nNo. of hidden layers 4\nHidden dimension 1024\nNo. of output nodes 1551\nTable 4 Top 5 grammatical errors used for rule-based\nerror generation.\nRank Right Wrong Frequency\n1 — the 620\n2 — to 181\n3 — a 177\n4 — is 151\n5 are is 98\nTable 5 Examples of generated sentences.\nTarget They visited me on Sunday.\nrule-based They visited me on the Sunday.\nrule-based They the visited me on Sunday.\nrule-based They a visited me on Sunday.\nNMT model They visited at Sunday.\nNMT model They visited Sunday.\nNMT model They visited me on Sunday.\nTable 6 Training data used in language modeling.\nTraining data\nLM\nbase-\nline\nLM\nrule\nLM\nNMT\nLM\nrule &\nNMT\nLM\ngold\nERJ sent. PPP P P\nTarget sent. PPP P P\nRule sent. PP\nNMT sent. PP\nHuman trans. P\nFig. 3 Average speech recognition results for TJTEOT\ncorpus using diﬀerent language models.\nAcoust. Sci. & Tech.41, 5 (2020)\n790\n4.3. Evaluation of language mo deling for grammar error\ndetection\nTo evaluate the performance of the proposed LM for\ngrammatical error detection, there are three evaluation\nparameters: precision ( P), recall ( R) and F-measure ( F).\nTable 7 shows the evaluation results of precision, recall\nand F-measure for the diﬀerent language models used in ASR.\nThe closed-conditional gold LM can be used to conduct the\nGED task in the speech to an acceptable degree; however, in\na real CALL system, it is diﬃcult to obtain human tran-\nscriptions in advance. Compared with the results of baseline\nLM, both rule-based generated sentences and NMT-based\ngenerated sentences improved the performance of detecting\ngrammatical errors. The value of R is lower in rule-based\nlanguage modeling than in the baseline LM, which proves that\nmany rule-based errors reduced the recognizer performance.\nThese results indicate that the sentences generated by NMT\nplay an important role in speech-based GED.\n5. Conclusion\nIn this study, for grammatical error detection in the\nspeech-based CALL system, we ﬁrst developed the TJTEOT\ncorpus for testing and evaluation. To recognize the grammat-\nical errors in speech with high accuracy, we introduced\nsentence generation with errors utilizing state-of-the-art NMT\nmodels. Compared with the traditional rule-based method,\nour proposed method can be established more quickly without\nspending a lot of time modeling the error rules. Since the\nNMT can make use of context information owing to its\nspeciﬁc inner structure, the sentences generated by NMT\ncontain more comprehensive information about grammatical\nerrors.\nBy comparing the results of diﬀerent language models,\nour proposed method was found to have a signiﬁcant\nadvantage over the rule-based one and generated more related\nerrors occurring in real non-native English speech. Moreover,\nthis deep-learning-based method ﬁlls a gap in language\nmodeling for speech-based grammatical error detection.\nAcknowledgement\nThis work is supported by JSPS KAKENHI Grant-in-Aid\nfor Scientiﬁc Research (A) Grant Number JP17H00823.\nReferences\n[1] T. Anzai and A. Ito, ‘ ‘Recognition of utterances with\ngrammatical mistakes based on optimization of language\nmodel towards interactive CALL systems,’ ’ Proc. APSIPA\nASC 2012, pp. 1–4 (2012).\n[2] B. P. de Vries, C. Cucchiarini, S. Bodnar, H. Strik and R.\nvan Hout, ‘ ‘Spoken grammar practice and feedback in an ASR-\nbased CALL system,’ ’ Comput. Assist. Lang. Learn., 28, 550–\n576 (2015).\n[3] W. Hu, Y. Qian and F. K. Soong, ‘ ‘A new DNN-based high\nquality pronunciation evaluation for computer-aided language\nlearning (CALL),’ ’ Proc. Interspeech 2013, pp. 1886–1890\n(2013).\n[4] J. Fu, Y. Chiba, T. Nose and A. Ito, ‘ ‘Evaluation of English\nspeech recognition for Japanese learners using DNN-based\nacoustic models,’ ’ Proc. IIH-MSP 2018, pp. 93–100 (2018).\n[5] A. Ito, R. Tsutsui, S. Makino and M. Suzuki, ‘ ‘Recognition of\nEnglish utterances with grammatical and lexical mistakes for\ndialogue-based CALL system,’ ’ Proc. Interspeech 2008 ,\npp. 2819–2822 (2008).\n[6] H. Strik, J. V. Doremalen, J. V. D. Loo and C. Cucchiarini,\n‘ ‘Improving ASR processing of ungrammatical utterances\nthrough grammatical error modeling,’ ’ Proc. SLaTE 2011 ,\npp. 109–112 (2011).\n[7] E. Izumi, K. Uchimoto and H. Isahara, ‘ ‘The NICT JLE\nCorpus: Exploiting the language learners’ speech database for\nresearch and education,’ ’ Int. J. Comput. Internet Manage., 12,\n119–125 (2004).\n[8] C. Danescu-Niculescu-Mizil and L. Lee, ‘ ‘Chameleons in\nimagined conversations: A new approach to understanding\ncoordination of linguistic style in dialogs,’ ’ Proc. ACL 2011,\npp. 76–87 (2011).\n[9] N. Minematsu, Y. Tomiyama, K. Yoshimoto, K. Shimizu, S.\nNakagawa, M. Dantsuji and S. Makino, ‘ ‘Development of\nEnglish speech database read by Japanese to support CALL\nresearch,’ ’Proc. ICA 2004, pp. 557–560 (2004).\n[10] D. Bahdanau, K. Cho and Y. Bengio, ‘ ‘Neural machine\ntranslation by jointly learning to align and translate,’ ’ arXiv\npre-print arXiv:1409.0473, pp. 1–15 (2014).\n[11] P. F. Brown, V. J. D. Pietra, S. A. D. Pietra and R. L. Mercer,\n‘ ‘The mathematics of statistical machine translation: Parameter\nestimation,’ ’Comput. Linguist., 19, 263–311 (1993).\nTable 7 Evaluation results for diﬀerent language mod-\nels for grammatical error detection.\nPRF\nLM baseline 0.47 0.54 0.50\nLM rule 0.48 0.44 0.46\nLM NMT 0.54 0.52 0.53\nLM rule & NMT 0.52 0.52 0.52\nLM gold 0.73 0.83 0.78\nJ. FU et al.: LANGUAGE MODELING IN ASR FOR GED BASED ON NMT\n791",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7221944332122803
    },
    {
      "name": "Machine translation",
      "score": 0.6972617506980896
    },
    {
      "name": "Speech recognition",
      "score": 0.683428168296814
    },
    {
      "name": "Natural language processing",
      "score": 0.5539575219154358
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5295518040657043
    },
    {
      "name": "Translation (biology)",
      "score": 0.46789395809173584
    },
    {
      "name": "Speech error",
      "score": 0.4324483871459961
    },
    {
      "name": "Speech production",
      "score": 0.15682587027549744
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Messenger RNA",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I201537933",
      "name": "Tohoku University",
      "country": "JP"
    }
  ],
  "cited_by": 10
}