{
  "title": "FedID: Federated Interactive Distillation for Large-Scale Pretraining Language Models",
  "url": "https://openalex.org/W4389519063",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3185518293",
      "name": "Xinge Ma",
      "affiliations": [
        "Yunnan University"
      ]
    },
    {
      "id": "https://openalex.org/A2567533313",
      "name": "Jiangming Liu",
      "affiliations": [
        "Yunnan University"
      ]
    },
    {
      "id": "https://openalex.org/A2105468542",
      "name": "Jin Wang",
      "affiliations": [
        "Yunnan University"
      ]
    },
    {
      "id": "https://openalex.org/A2115527613",
      "name": "XueJie Zhang",
      "affiliations": [
        "Yunnan University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3035453001",
    "https://openalex.org/W4311430299",
    "https://openalex.org/W3006726390",
    "https://openalex.org/W3102031770",
    "https://openalex.org/W4318619660",
    "https://openalex.org/W2998732348",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W4287824654",
    "https://openalex.org/W3141518839",
    "https://openalex.org/W1599016936",
    "https://openalex.org/W4288379066",
    "https://openalex.org/W4313908941",
    "https://openalex.org/W2978670439",
    "https://openalex.org/W3183712004",
    "https://openalex.org/W131533222",
    "https://openalex.org/W4214607237",
    "https://openalex.org/W3013721857",
    "https://openalex.org/W3202088367",
    "https://openalex.org/W3101177651",
    "https://openalex.org/W4283792986",
    "https://openalex.org/W2972570881",
    "https://openalex.org/W3064112253",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W4253067820",
    "https://openalex.org/W2963846996",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W3091002423",
    "https://openalex.org/W2980216952",
    "https://openalex.org/W3128108456",
    "https://openalex.org/W2130158090",
    "https://openalex.org/W2113459411",
    "https://openalex.org/W2903471046",
    "https://openalex.org/W2120513799",
    "https://openalex.org/W4385572943",
    "https://openalex.org/W2744999500",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2963748441"
  ],
  "abstract": "The growing concerns and regulations surrounding the protection of user data privacy have necessitated decentralized training paradigms. To this end, federated learning (FL) is widely studied in user-related natural language processing (NLP). However, it suffers from several critical limitations including extensive communication overhead, inability to handle heterogeneity, and vulnerability to white-box inference attacks. Federated distillation (FD) is proposed to alleviate these limitations, but its performance is faded by confirmation bias. To tackle this issue, we propose Federated Interactive Distillation (FedID), which utilizes a small amount of labeled data retained by the server to further rectify the local models during knowledge transfer. Additionally, based on the GLUE benchmark, we develop a benchmarking framework across multiple tasks with diverse data distributions to contribute to the research of FD in NLP community. Experiments show that our proposed FedID framework achieves the best results in homogeneous and heterogeneous federated scenarios. The code for this paper is available at: https://github.com/maxinge8698/FedID.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 8566–8577\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nFedID: Federated Interactive Distillation for Large-Scale Pretraining\nLanguage Models\nXinge Ma, Jiangming Liu∗, Jin Wang∗ and Xuejie Zhang\nSchool of Information Science and Engineering\nYunnan University\nKunming, China\nContact:jiangmingliu@ynu.edu.cn, wangjin@ynu.edu.cn\nAbstract\nThe growing concerns and regulations sur-\nrounding the protection of user data pri-\nvacy have necessitated decentralized training\nparadigms. To this end, federated learning\n(FL) is widely studied in user-related natural\nlanguage processing (NLP). However, it suf-\nfers from several critical limitations including\nextensive communication overhead, inability\nto handle heterogeneity, and vulnerability to\nwhite-box inference attacks. Federated distilla-\ntion (FD) is proposed to alleviate these limita-\ntions, but its performance is faded byconﬁrma-\ntion bias. To tackle this issue, we propose Fed-\nerated Interactive Distillation (FedID), which\nutilizes a small amount of labeled data re-\ntained by the server to further rectify the local\nmodels during knowledge transfer. Addition-\nally, based on the GLUE benchmark, we de-\nvelop a benchmarking framework across multi-\nple tasks with diverse data distributions to con-\ntribute to the research of FD in NLP commu-\nnity. Experiments show that our proposed Fe-\ndID framework achieves the best results in ho-\nmogeneous and heterogeneous federated sce-\nnarios. The code for this paper is available at:\nhttps://github.com/maxinge8698/FedID.\n1 Introduction\nThe remarkable success of natural language pro-\ncessing (NLP) is highly dependent on large-scale\npre-trained language models (PLMs; Devlin et al.\n2019; Liu et al. 2019; Yang et al. 2019; Clark\net al. 2020). To fully realize the potential of PLMs,\nthey are typically trained using large amounts of\ncombined data that is collected from multiple dis-\ntributed user devices (a.k.a., clients) and transmit-\nted to a single data center (a.k.a., server). With the\ngrowing concerns about privacy protection, data\nregulations such as the Personal Data Protection\nAct (PDPA; Chik 2013) and the General Data Pro-\ntection Regulation (GDPR; V oigt and von dem\n∗Corresponding authors.\nBussche 2017) have imposed strict requirements on\npreserving user data privacy, making it impractical\nto aggregate such data to a centralized location for\ntraining. Federated learning (FL; Mcmahan et al.\n2017) has emerged as a privacy-preserving decen-\ntralized training paradigm, in which a federation of\nclients is orchestrated by a central server to collabo-\nratively train a shared global model via aggregating\nthe local models trained on their respective data.\nAs a result, the private data of massive clients is\neffectively exploited in the form of model param-\neter exchange to train a uniﬁed model for better\nperformance than individually working.\nPrevious work on federated NLP mainly targets\nsolving either word-level language modeling ap-\nplications such as mobile keyboard suggestion (Ji\net al., 2019) and recommendation (Lin et al., 2020),\nor biomedical named entity recognition (Liu and\nMiller, 2020; Ge et al., 2020; Sui et al., 2020).\nMore recently, Lin et al. (2022) provide a research-\noriented benchmarking framework for advancing\nFL in NLP. However, these federated NLP frame-\nworks are limited to identical architectures across\nthe server and clients, making it impossible for\nclients to design their models independently accord-\ning to their inconsistent system resources and non-\nindependent and identically distributed (non-IID)\ndata. Also, the frequent model parameter exchange\nentails expensive communication costs. These ob-\nstacles signiﬁcantly hinder the applicability and\nscalability of FL for large-scale PLMs.\nInstead, federated distillation (FD) eliminates\nthe need to share model parameters by transfer-\nring knowledge from the clients to the server us-\ning an unlabeled public proxy dataset (Jeong et al.,\n2018; Li and Wang, 2019; Chang et al., 2019; Gong\net al., 2022; Itahara et al., 2021; Hu et al., 2021),\nthereby allowing collaboration between heteroge-\nneous models with less communication costs. How-\never, FD suffers from conﬁrmation bias (Arazo\net al., 2020; Pham et al., 2021) induced by incor-\n8566\n...④Aggregation\nClient 1\n①LocalTraining\nLocal Samples Labels\nCentral Model\nServer\nEnsemble Predictions\nPublic Samples\n⑤ServerDistillation⑥Feedback\nLabeled Samples\nLabels\nValidation Loss\n⑦Broadcast\nPublic Samples\n⑧LocalDistillation\n⑦Broadcast\n③UploadLocal Model\n②LocalPrediction\nPublic Samples\nClient K\nFigure 1: The framework of FedID.\nporating incorrect or even biased predictions on\nunlabeled data for knowledge transfer, where the\ncentral model will tend to degenerate.\nTo tackle this challenge, we propose Federated\nInteractive Distillation (FedID), where a small\nhandful of labeled data is retained in the server,\naiming to provide feedback to the local models to\ndebias the predictions.\nIn addition, previous studies on FD tend to de-\nsign different partitioning strategies on different\ndatasets, and only small-scale models are taken\ninto consideration, which makes it difﬁcult to eval-\nuate and compare various FD approaches scaled\nto the NLP domain in a systematic and fair man-\nner. For this reason, based on the General Lan-\nguage Understanding Evaluation (GLUE) bench-\nmark (Wang et al., 2019), we create a uniﬁed bench-\nmarking framework across multiple tasks with di-\nverse data distributions to simulate a variety of\nfederated scenarios for evaluating the effectiveness\nof these methods on the decentralized training of\nlarge-scale PLMs, advancing the research of FD\nin NLP. Empirical experiments show that our pro-\nposed FedID achieves the best results in homoge-\nneous and heterogeneous federated scenarios.\nThe contributions of this paper are summarized\nas follows:\n• To the best of our knowledge, we are the ﬁrst\nto investigate the application of FD to decen-\ntralized learning of large-scale PLMs in ho-\nmogeneous and heterogeneous settings.\n• We present a novel Federated Interactive Dis-\ntillation framework to mitigate the problem of\nmisleading privileged knowledge caused by\nconﬁrmation bias in conventional FD.\n• We provide a uniﬁed benchmarking frame-\nwork across multiple NLP tasks with diverse\ndata distributions to contribute to the research\nof FD in NLP community.\n2 Related Work\n2.1 Federated Learning\nFL has gained signiﬁcant interest and attention in\nthe NLP ﬁeld due to its potential for collaborative\ntraining on distributed data sources while preserv-\ning data privacy (Liu et al., 2021). Recent efforts\nhave made preliminary explorations for the appli-\ncation of parameter averaging-based FL (e.g., Fe-\ndAvg (Mcmahan et al., 2017)) in the context of\nNLP (Tian et al., 2022; Dong et al., 2022; Zhang\net al., 2022; Lin et al., 2022). Despite some suc-\ncess, several system-oriented challenges have to be\nfaced to make FL widely available in NLP, includ-\ning extensive communication overhead, inability\nto handle heterogeneity, and vulnerability to white-\nbox inference attacks.\nSeveral variants of FL have emerged to attempt\nto alleviate these issues. FedDF (Lin et al.) builds\nprototypical models with the same structure as the\n8567\nclient models on the server side to enable model\nheterogeneity, and allows server-side ensemble dis-\ntillation on unlabeled data from other domains to\nenhance model aggregation. FedED (Sui et al.,\n2020) reduces uplink communication costs by up-\nloading the predictions of the local models instead\nof the parameters to train the central model, but still\nrequires broadcasting the parameters of the central\nmodel over the downlink. Accordingly, these solu-\ntions still rely on exchanging model parameters and\ntherefore are unable to completely address these\nlimitations.\n2.2 Federated Distillation\nFD is a new algorithmic paradigm for FL with fun-\ndamentally different communication properties by\nexchanging the knowledge obtained during the lo-\ncal training in the form of model outputs rather\nthan model parameters. This shared knowledge\ncan be an aggregated statistic of model outputs on\nlocal private data (Jeong et al., 2018) or an ensem-\nble of local model outputs computed on a publicly\navailable proxy dataset (Li and Wang, 2019; Chang\net al., 2019; Gong et al., 2022; Itahara et al., 2021;\nHu et al., 2021). Existing efforts on FD fall into\ntwo main categories:\n• The server does not hold any model and\nis only used as an aggregator FedMD (Li\nand Wang, 2019) adopts a labeled public\ndataset for transfer learning among clients to\nseek fast improvement across all participants.\nCronus (Chang et al., 2019) combines the lo-\ncal private dataset and the pseudo-labeled pub-\nlic dataset jointly for local training, where the\npseudo-labels are ensembled with more robust\naggregation rules.\n• The server holds a central model that\nacts as the target for collaborative train-\ning FedKD (Gong et al., 2022) adopts\na privacy-preserving ensemble strategy on\ncross-domain unlabeled data for one-way and\none-shot distillation of the central model. In\naddition to server-side distillation, DS-FL (Ita-\nhara et al., 2021) also performs client-side dis-\ntillation using the ensemble predictions on the\nunlabeled public dataset. Instead of transfer-\nring an ensemble of predictions, MHAT (Hu\net al., 2021) achieves information aggregation\nby directly using predictions from multiple\nclients to train the central model simultane-\nously. However, these methods are generally\nsubject to conﬁrmation bias caused by trans-\nferring knowledge over unlabeled data, which\ngreatly limits their performance.\n3 Preliminaries\n3.1 Problem Deﬁnition\nConsider a federated training environment with K\nclients, where the k-th client holds a labeled private\ndataset Dk = {(xk\ni,yk\ni)}|Dk|\ni=1 drawn from the same\nor distinct distribution, along with a homogeneous\nor heterogeneous local model fk parameterized by\nθk. The goal is to train a central model f parame-\nterized by θon the server, but without direct access\nto these private data.\n3.2 Federated Learning for NLP\nIn a general FL framework, the training process is\ndivided into T communication rounds through a\nserver-client paradigm, where all clients share the\nsame model architecture coordinated by a central\nserver. Speciﬁcally, at the beginning of federated\ntraining, the server initializes the global model pa-\nrameters θ0. At each communication round t, the\ntraining is proceeded as follows:\n• Broadcast A subset of the client population\nCt ⊆{1,2,...,K }is sampled to participate\nin training, where |Ct|= ε·K, and εis the\nsampling rate. Then the server distributes the\ncurrent global model parameters θt−1 to the\nparticipating clients.\n• Local training Each participating client k∈\nCt uses the received parameters to initialize its\nlocal model,\nθk\nt−1 ←θt−1, (1)\nand updates it several epochs with its own\nprivate data Dk,\nθk\nt ←θk\nt−1 −η∇LCE(Dk; θk\nt−1), (2)\nwhere η is the learning rate of the central\nmodel, and LCE denotes the loss function,\nwhich is usually a categorical cross-entropy\nfor classiﬁcation tasks.\n• Upload The updated local model parameters\nθk\nt are sent back to the server.\n• Aggregation The server collects and aggre-\ngates the parameters from clients to obtain the\n8568\nglobal model parameters for the next round,\nθt ←\n∑\nk∈Ct\n|Dk|\n|D|θk\nt, (3)\nwhere |Dk|and |D|= ∑\nk∈Ct\n|Dk|are the num-\nber of local data held by the k-th client and all\nparticipating clients, respectively.\n3.3 Federated Distillation for NLP\nIn a general FD framework, an unlabeled public\ndataset D0 = {x0\ni}|D0|\ni=1 is hosted by the server and\ntransmitted to all clients for knowledge transfer be-\nfore the federated training starts. At each communi-\ncation round t, the training process is summarized\nas the following steps:\n• Local training Each participating client\ntrains its local model θk\nt−1 on its own private\ndata Dk for several epochs,\nθk\nt ←θk\nt−1 −ηk∇LCE(Dk; θk\nt−1), (4)\nwhere ηk is the learning rate of the k-th local\nmodel.\n• Local prediction Each participating client\ncomputes its local predictions on the entire\npublic proxy dataset D0 using its updated lo-\ncal model θk\nt,\nYk\nt = fk(D0; θk\nt). (5)\n• Upload Participating clients upload their lo-\ncal predictions to the server.\n• Aggregation The predictions from clients\nare collected and aggregated by the server as\nensemble predictions,\nYt =\n∑\nk∈Ct\n|Dk|\n|D|Yk\nt . (6)\n• Server distillation The ensemble predictions\nare treated as teacher knowledge to train the\ncentral model for several epochs,\nθt ←θt−1 −η∇LCE(Yt,f(D0; θt−1)). (7)\n• Broadcast The server broadcasts the ensem-\nble predictions to participating clients.\n• Local distillation Each participating client\ndistills its local model using the received en-\nsemble predictions on the entire public proxy\ndataset,\nθk\nt ←θk\nt −ηk∇LCE(Yt,fk(D0; θk\nt)). (8)\n4 Federated Interactive Distillation\nIn existing FD approaches, the central model is\nonly allowed to passively mimic the local models\nby one-way knowledge transfer, leading to conﬁr-\nmation bias that heavily fades the superiority of\nFD. Instead of directly transmitting the entire pub-\nlic dataset and its predictions between the server\nand clients, the proposed FedID slices the unla-\nbeled public dataset into multiple smaller batches\nfor training, and handles only a small batch of data\nand predictions in each communication, which al-\nlows for an interaction between the central model\nand local models during the knowledge transfer\nprocess, while signiﬁcantly reducing the load of a\nsingle communication. After each server distilla-\ntion, the central model is allowed to feedback its\nperformance on a small amount of labeled data held\nby the server back to each client to adapt its local\nmodel accordingly for rectifying its conﬁrmation\nbias. The overall framework of FedID is presented\nin Figure 1.\n4.1 Server Interactive Distillation\nThe server samples a batch of unlabeled public data\nx0 from D0 and distributes them to each participat-\ning client for local prediction,\nyk\nt = fk(x0; θk\nt). (9)\nThe predictions from clients are uploaded to the\nserver and aggregated with the same strategy as in\nEq. (6),\nyt =\n∑\nk∈Ct\n|Dk|\n|D|yk\nt, (10)\ntogether with the batch inputx0, which are adopted\nto train the central model for knowledge transfer,\nθt ←θt−1 −η∇LCE(yt,f(x0; θt−1)). (11)\nThe updated central model θt is then evaluated\non a batch of data (xval,yval) sampled from the\nlabeled dataset Dval = {xval\ni ,yval\ni }|Dval|\ni=1 held by\nthe server,\nLCE(yval,f(xval; θt))\n∆= LCE(yval,f(xval; θt−1−\nη∇LCE(∑\nk∈Ct\n|Dk|\n|D|fk(x0;θk\nt),f(x0;θt−1)))).\n(12)\nIn addition to the ensemble predictions yt, the\nabove-computed validation loss is also broadcast\ntogether to each participating client as feedback.\n8569\nAlgorithm 1: Federated Interactive Distillation (FedID)\nInput: labeled private datasets {Dk}K\nk=1; unlabeled public dataset D0; a handful of labeled dataset\nDval held by the server; local models {θk}K\nk=1; central model θ; communication rounds T\nOutput: decentrally trained θ\n1 Each client initializes the local model θk\n0\n2 Server initializes the central model θ0\n3 for each communication round t= 1,2,...,T do\n4 m←max(ε·K,1)\n5 Ct ←randomly sample a subset of mclients from Kclients\n6 for each client k∈Ct in parallel do\n7 Update the local model parameters θk\nt via Eq. (4)\n8 end\n9 for each mini-batch of unlabeled data x0 ∼D0 do\n10 Server distributes a mini-batch of unlabeled data x0 to all participants Ct\n11 for each client k∈Ct in parallel do\n12 Compute local predictions yk\nt on x0 via Eq. (9)\n13 Upload local predictions yk\nt to the server\n14 end\n15 Server aggregates local predictions to create the ensemble predictions yt via Eq. (10)\n16 Server updates the central model parameters θt via Eq. (11)\n17 Server samples a mini-batch of labeled data (xval,yval) ∼Dval\n18 Server computes the validation loss LCE(yval,f(xval; θt)) via Eq. (12)\n19 Server broadcasts the validation loss LCE(yval,f(xval; θt)) and ensemble predictions yt\nto all participants Ct\n20 for each client k∈Ct in parallel do\n21 Update the local model parameters θk\nt via Eq. (15)\n22 end\n23 end\n24 end\n25 return θT\n4.2 Client Interactive Distillation\nFor each participating client k∈Ct, the gradients\non the ensemble predictions yt are computed to\nlearn knowledge from other clients for alleviating\ndata heterogeneity,\ngk\ndistill = ∇θk\nt\nLCE(yt,fk(x0; θk\nt)). (13)\nAlso, the feedback gradients from the server to the\nclient are computed from the validation loss,\ngk\nfeedback = ∇θk\nt\nLCE(yval,f(xval; θt)), (14)\nand are added to further rectify its local model,\nθk\nt ←θk\nt −ηk(gk\ndistill + gk\nfeedback). (15)\nIn this way, FedID establishes interactive dis-\ntillation between the server and clients, where\nthe client-to-server interaction aims to transfer the\nknowledge learned by local models during local\ntraining on their respective private data to the cen-\ntral model, while the server-to-client interaction\nattempts to rectify conﬁrmation bias by allowing\nthe local models to learn from the central model’s\nfeedback. The detailed procedures are summarized\nin Algorithms 1.\n5 Experiments\n5.1 Datasets\nConsidering that simulating data distributions with\nvarying heterogeneity requires sampling by labels,\nwe exclude the regression task STS-B (Cer et al.,\n2017) from the GLUE benchmark (Wang et al.,\n2019) because it lacks available labels for sam-\npling, and take the remaining eight classiﬁcation\ntasks for evaluation, including WNLI (Levesque\net al., 2012), RTE (Dagan et al., 2005; Bar-Haim\n8570\nMethod\nWNLI\n(0.6k)\nAcc\nRTE\n(2.5k)\nAcc\nMRPC\n(3.7k)\nF1/Acc\nCoLA\n(8.6k)\nMcc\nSST-2\n(67k)\nAcc\nQNLI\n(105k)\nAcc\nQQP\n(364k)\nF1/Acc\nMNLI\n(393k)\nAcc m/mm\nCentralized 56.3 61.4 85.9/79.2 52.4 92.4 90.2 86.3/89.7 82.8/83.5\nα=100\nFedAvg 49.6 56.7 84.5/78.0 51.0 91.8 89.8 85.5/88.2 82.0/82.7\nFedDF 50.2 56.9 84.6/77.8 51.4 92.0 89.6 85.7/88.5 82.2/83.0\nFedED 47.9 55.4 82.2/75.3 50.5 91.1 88.9 84.8/87.9 81.4/81.9\nFedKD 45.4 53.6 80.3/74.0 48.3 89.2 86.1 82.6/86.0 79.8/80.1\nDS-FL 50.6 56.4 84.0/78.4 51.7 90.7 89.1 84.9/88.2 82.6/83.4\nMHAT 50.0 56.5 84.2/78.6 51.7 91.0 89.3 84.3/88.1 82.0/83.0\nFedID 51.1 57.0 84.9/79.0 52.0 91.6 89.9 85.6/88.5 82.3/83.2\nα=1\nFedAvg 48.3 55.1 82.9/77.2 48.9 91.0 88.7 84.2/87.6 81.4/81.8\nFedDF 50.2 56.4 83.2/77.3 49.8 91.2 89.0 84.5/88.0 81.8/82.1\nFedED 46.8 55.0 82.0/76.4 47.8 90.7 88.1 83.1/87.5 80.8/81.3\nFedKD 44.4 52.6 80.4/74.8 46.4 88.9 86.5 82.4/86.6 78.8/79.4\nDS-FL 50.1 56.7 82.8/76.7 49.4 90.6 88.5 83.8/87.8 81.2/81.8\nMHAT 50.2 56.7 82.6/76.8 49.2 90.7 88.8 84.1/87.4 81.6/82.0\nFedID 50.9 56.7 83.2/77.3 49.6 90.9 88.8 84.7/88.1 81.9/82.3\nTable 1: Experiment results of the homogeneous setting on the GLUE dev sets.\net al., 2006; Giampiccolo et al., 2007; Bentivogli\net al., 2009), MRPC (Dolan and Brockett, 2005),\nCoLA (Warstadt et al., 2019), SST-2 (Socher et al.,\n2013), QNLI (Rajpurkar et al., 2016), QQP1, and\nMNLI (Williams et al., 2018). See Appendix A for\nmore details about GLUE.\nFor each task, the original development set is\nemployed to evaluate the performance of the cen-\ntral and local models, while the original training\nset is divided into private and public datasets at a\nratio of 1:1, which are used for client training and\nknowledge transfer between the server and clients,\nrespectively. Particularly, for the resulting public\ndataset, we further sample 10% of it as the labeled\ndataset reserved for the server, and the rest as the\nunlabeled public dataset after rounding off labels.\nFurthermore, to create disjoint client training\ndata from the private dataset, the training instances\nof each client are drawn independently with class\nlabels following a categorical distribution over\nN classes parameterized by a vector q (qi ≥0,\ni ∈[1,N], and ∥q∥1 = 1). Meanwhile, to simu-\nlate varying data distributions for clients, we fur-\nther draw q ∼Dir(αp) from a Dirichlet distribu-\n1https://quoradata.quora.com\ntion (Hsu et al., 2019), where p is a prior class dis-\ntribution over N classes, and αis a concentration\nparameter that controls the degree of data hetero-\ngeneity among clients. Typically, when α →∞,\nclients tend to be assigned to the identical data dis-\ntribution, and conversely, whenα→0, clients are\nmore likely to hold examples from only one ran-\ndom class. In our experiments, we set αto 100 and\n1 to generate IID and non-IID data, respectively.2\n5.2 Settings\nHomogeneous setting For a homogeneous fed-\nerated scenario, the model architectures of clients\nare limited to be the same as that of the server. To\nbe compatible with FL methods for comparison,\nwe adopt BERT-base (Devlin et al., 2019) as the\ncentral model since FL cannot usually be applied\nto larger PLMs due to communication bottlenecks.\nHeterogeneous setting For a heterogeneous\nfederated scenario, the central model is initialized\nwith BERT-base, while each local model is selected\nfrom BERT-base, BERT-large, RoBERTa-base (Liu\net al., 2019), or RoBERTa-large3.\n2If not speciﬁed, α = 1is used by default.\n3If not speciﬁed, heterogeneous setting is used by default.\n8571\nMethod\nWNLI\n(0.6k)\nAcc\nRTE\n(2.5k)\nAcc\nMRPC\n(3.7k)\nF1/Acc\nCoLA\n(8.6k)\nMcc\nSST-2\n(67k)\nAcc\nQNLI\n(105k)\nAcc\nQQP\n(364k)\nF1/Acc\nMNLI\n(393k)\nAcc m/mm\nα=100\nFedKD 54.1 60.5 85.2/80.5 53.6 90.8 87.7 84.2/87.2 81.9/82.3\nDS-FL 56.8 63.4 87.7/82.4 55.4 92.1 89.9 86.5/89.4 83.6/84.0\nMHAT 56.9 63.2 87.7/82.5 55.7 92.0 90.6 87.0/89.5 84.0/84.2\nFedID 58.2 64.6 88.5/83.6 56.5 92.7 91.4 88.1/91.2 84.6/84.6\nα=1\nFedKD 52.7 58.4 84.3/80.0 50.0 88.9 87.1 84.2/87.5 81.2/81.6\nDS-FL 55.6 60.3 86.6/81.6 53.9 90.9 89.8 86.4/89.1 83.0/83.5\nMHAT 55.9 60.8 86.6/81.5 53.8 91.2 90.3 86.6/89.3 83.4/83.7\nFedID 57.0 61.5 87.7/82.2 54.9 91.8 91.0 87.6/90.5 84.2/84.2\nTable 2: Experiment results of the heterogeneous setting on the GLUE dev sets.\n5.3 Implementation Details\nWe adopt the AdamW optimizer (Loshchilov and\nHutter, 2019) with an initial learning rate of 2e-5 to\nupdate the model parameters. For single-sentence\nor sentence-pair input to the model, the maximum\nsequence length is set to 128, and the batch size is\nset to 32. For hyperparameters in federated train-\ning, the number of epochs for local training, local\ndistillation, and server distillation is set to 3, 3, and\n3, respectively, the number of clientsKis set to 10,\nthe fraction of client sampling εis set to 1, and the\nnumber of communication rounds T is set to 10.\n5.4 Baselines\nWe compare FedID with FL algorithms including\nFedAvg (Mcmahan et al., 2017), FedDF (Lin et al.),\nand FedED (Sui et al., 2020), as well as FD al-\ngorithms including FedKD (Gong et al., 2022),\nMAHT (Hu et al., 2021), and DS-FL (Itahara et al.,\n2021). We also provide the models with centralized\ntraining (denoted as Centralized) that have access\nto all private data held by the clients as an upper\nbound on model performance.4\n5.5 Results\nHomogeneous setting Table 1 shows the per-\nformances across models in homogeneous setting.\nWithout considering data privacy, centralized mod-\nels always exhibit the best performance, while\ndecentralized models sacriﬁce performance in ex-\n4FedED and MHAT require a labeled public dataset in\nthe original paper. For a fair comparison, a version using the\nunlabeled public dataset is provided in our implementation.\nchange for better privacy protection. However, this\nperformance gap is gradually alleviated as the train-\ning data increases. In addition, the performances\nof FL and FD models are signiﬁcantly degener-\nated when encountering non-IID data. Also, when\nsufﬁcient public data is made available, the perfor-\nmance of FD models can be comparable to that of\nFL models, accompanied by lower communication\ncosts.\nHeterogeneous setting Table 2 shows the per-\nformances across models in heterogeneous setting.\nThe proposed FedID outperforms other baselines,\ndemonstrating the superiority of tackling the con-\nﬁrmation bias. In particular, FedID exhibits strong\nrobustness when only a small amount of training\ndata is available, as there is not enough private data\nto adequately train the local models and thus the\nconﬁrmation bias becomes more pronounced.\nCross-domain setting We also use the origi-\nnal training sets of IMDB (Maas et al., 2011) and\nPAWS (Zhang et al., 2019) as unlabeled public data\nfor SST-2 and QQP, respectively, to construct cross-\ndomain knowledge transfer environments, where\nthe conﬁrmation bias is more likely to occur. The\nexperimental results on the dev sets of SST-2 and\nQQP are shown in Table 3, where the greater per-\nformance gap between FedID and other baselines\nfurther conﬁrms our claim.\n5.6 Ablation Study\nWe remove the feedback gradient and the knowl-\nedge transfer gradient from Eq. (15), respectively,\n8572\nMethod SST-2 →IMDB\nAcc\nQQP →PA WS\nF1/Acc\nFedKD 81.9 80.0/83.5\nDS-FL 83.3 82.3/85.4\nMHAT 83.9 82.8/85.6\nFedID 86.4 84.1/87.1\nTable 3: Results of models in the cross-domain setting.\nMethod RTE\nAcc\nSST-2\nAcc\nQQP\nF1/Acc\nFedID 61.5 91.8 87.6/90.5\nw/o gk\nfeedback 60.1 90.7 86.5/89.4\nw/o gk\ndistill 60.6 91.1 86.9/89.8\nTable 4: Results of model ablations on RTE, SST-2, and\nQQP.\nto conduct ablation experiments on the small\ndataset RTE, the medium dataset SST-2, and the\nlarge dataset QQP. As shown in Table 4, without\nthe feedback gradient or the knowledge transfer\ngradient, the performances of models get worse,\nwhere the feedback gradient contributes more.\n5.7 Communication Cost\nCommunication costs between the server and client\nmodels across baselines are presented in Table 5.\nThe communication costs of FedAvg, FedDF, and\nFedED are much higher than those of FedKD,\nDS-FL, MHAT, and FedID as they entail exten-\nsive communication to share the model parameters.\nFedKD exhibits the lowest communication costs\nas the clients’ predictions are aggregated without\nthe need to send back to the clients and only one\nround of communication is executed, while DS-FL\nand MHAT need to broadcast the ensemble pre-\ndictions from the server back to each client. Simi-\nlarly, FedID is required to transmit ensemble pre-\ndictions and the validation loss in batches to clients\nas feedback, but the communication costs for the\nvalidation loss are negligible compared to that of\nensemble predictions. As a result, the communica-\ntion costs of FedID remain in line with DS-FL and\nMHAT, but the communication between the server\nand clients is more frequent.\n5.8 Effect of Unlabeled Public Dataset Size\nIn our experimental setup, we partition the orig-\ninal training dataset into a private dataset and a\nMethod Formulation\nFedAvg (|θ|×(K+ 1))×T\nFedDF (|θ|×(K+ 1) +|D0|×K) ×T\nFedED (|θ|×1 +|D0|×K) ×T\nFedKD (|D0|×K) ×1\nDS-FL (|D0|×(K+ 1))×T\nMHAT (|D0|×(K+ 1))×T\nFedID (|D0|×(K+ 1))×T\nTable 5: Formulations of communication costs.\npublic dataset. To further investigate the effect of\ndifferent proportions of the public dataset on per-\nformance, we keep the size of the private dataset\nconstant while conducting experiments using 10%,\n20%, 40%, 80%, and 100% of the public dataset,\nrespectively. The results in Figure 2 show that the\nperformance of the central model improves to some\nextent as the size of the public dataset increases,\nwhere FedID still exhibits superior performance\nand robustness.\n5.9 Effect of Labeled Dataset Size\nTo investigate the effect of the size of the labeled\ndataset retained by the server on performance, we\nexperiment with 10%, 20%, 40%, 80%, and 100%\nof the labeled dataset, respectively. For FedID, the\nlabeled data is used to rectify the conﬁrmation bias\nin the client models’ predictions, while for other\nFD methods, the labeled data is added to the train-\ning of the central model. The results in Figure 3\nshow that FedID is least sensitive to the size of\nthe labeled dataset since this data is not used to\ndirectly participate in the training of the central\nmodel. Moreover, although other FD methods use\nthe labeled data directly for additional training of\nthe central model, there is still no signiﬁcant per-\nformance improvement observed because the pro-\nportion of the labeled data is far lower than that of\nthe unlabeled data, and thus its supervision on the\ncentral model is limited. Our solution makes better\nuse of the small amount of labeled data by leverag-\ning it to rectify conﬁrmation bias in the predictions\nfrom unlabeled data.\n5.10 Effect of Number of Clients\nThe number of clients usually imposes a signiﬁ-\ncant impact on performance, as the entire training\ndataset is partitioned and distributed to multiple\nclients. To investigate this, we increase the num-\nber of clients from 5 to 10 and 20 while keeping\n8573\n20 40 60 80 100\nRatio of Public Dataset (%)\n80\n82\n84\n86\n88\n90\n92Performance (%)\nFedKD\nDS-FL\nMHAT\nFedID\nFigure 2: Performance of the central model on SST-2\nwith different sizes of public dataset.\n20 40 60 80 100\nRatio of Private Dataset (%)\n87\n88\n89\n90\n91Performance (%)\nFedKD\nDS-FL\nMHAT\nFedID\nFigure 3: Performance of the central model on SST-2\nwith different sizes of labeled dataset.\nthe total amount of private data for all clients con-\nstant, which results in a corresponding change in\nthe quantity of local private data that can be allo-\ncated to each client. The results depicted in Fig-\nure 4 show a decrease in the performance of the\ncentral model as the number of clients increases,\nwhich can be attributed to the fact that the reduc-\ntion in local private data makes it challenging to\nachieve adequate local training. However, FedID\nshows better robustness in response to this change\ndue to the mitigation of conﬁrmation bias.\n6 Conclusions\nThis study explores the application of FD to de-\ncentralized training of large-scale PLMs in homo-\ngeneous and heterogeneous settings, and further\npresents an interactive FD scheme to mitigate the\nconﬁrmation bias caused by transferring knowl-\nedge on an unlabeled public dataset. Moreover,\na benchmarking framework across multiple tasks\nwith diverse data distributions is developed to con-\ntribute to the research of FD in NLP community.\nFuture work will be executed to aggregate differ-\n5 10 20\nNumber of Clients\n87\n88\n89\n90\n91\n92\n93Performance (%)\nFedKD\nDS-FL\nMHAT\nFedID\nFigure 4: Performance of the central model on SST-2\nwith different numbers of clients.\nentially private local predictions for a stronger pri-\nvacy guarantee, enhancing the resilience of FedID\nagainst malicious server or clients.\nLimitations\nThere are two main limitations to our work com-\npared to previous efforts: 1) We assume that a small\namount of labeled data is retained in the server.\nHowever, this situation may be common in real life.\nFor instance, an institution possesses only a small\namount of training data, which is not enough to\ntrain a well-performing model, thus it may want\nto resort to collaborative training with other insti-\ntutions with the help of FD on a large amount of\nunlabeled public data. However, directly transfer-\nring knowledge on the unlabeled data may not yield\na satisfactory performance, while the small amount\nof training data retained by the institution can be\nused as labeled data by the proposed FedID to max-\nimize the performance. In addition, our approach\nis more suitable for the case where one client in\nthe federation acts as the server; 2) Compared with\nother FD approaches, our solution slices the unla-\nbeled public dataset into multiple smaller batches\nfor training, thus entailing more frequent commu-\nnication between the server and clients. However,\nthe increase in communication frequency may be\ntolerable considering the similar communication\ncosts and the fact that transmitting smaller pack-\nets avoids potential network congestion when the\npublic dataset is too large.\nEthics Statement\nThis study aims to explore an alternative decentral-\nized training paradigm for large-scale PLMs, and\nthe proposed method does pose ethical issues or po-\ntential biases. All models, baselines, and datasets\n8574\nused in this work are publicly available and widely\nused.\nAcknowledgements\nThis work was supported by the National Natural\nScience Foundation of China (NSFC) under Grant\nNos.61966038 and 62266051, and the Postgradu-\nate Research and Innovation Foundation of Yunnan\nUniversity under Grant No.KC-23236531. The au-\nthors would like to thank the anonymous reviewers\nfor their constructive comments.\nReferences\nEric Arazo, DIego Ortego, Paul Albert, Noel E.\nO’Connor, and Kevin McGuinness. 2020. Pseudo-\nlabeling and conﬁrmation bias in deep semi-\nsupervised learning. In Proceedings of the Interna-\ntional Joint Conference on Neural Networks (IJCNN\n2020).\nRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro,\nDanilo Giampiccolo, Bernardo Magnini, and Idan\nSzpektor. 2006. The second pascal recognising tex-\ntual entailment challenge. In Proceedings of the Sec-\nond PASCAL Challenges Workshop on Recognising\nTextual Entailment.\nLuisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo\nGiampiccolo, and Bernardo Magnini. 2009. The\nﬁfth pascal recognizing textual entailment challenge.\nIn Proceedings of the Third Text Analysis Confer-\nence.\nDaniel Cer, Mona Diab, Eneko Agirre, Iñigo Lopez-\nGazpio, and Lucia Specia. 2017. Semeval-2017 task\n1: Semantic textual similarity multilingual and cross-\nlingual focused evaluation. In Proceedings of the\n11th International Workshop on Semantic Evalua-\ntion (SemEval 2017), pages 1–14.\nHongyan Chang, Virat Shejwalkar, Reza Shokri,\nand Amir Houmansadr. 2019. Cronus: Ro-\nbust and heterogeneous collaborative learning with\nblack-box knowledge transfer. arXiv preprint\narXiv:1912.11279.\nWarren B. Chik. 2013. The singapore personal data\nprotection act and an assessment of future trends in\ndata privacy reform. Computer Law and Security\nReview, 29(5):554–575.\nKevin Clark, Minh-Thang Luong, Quoc V .Le, and\nChristopher D.Manning. 2020. Electra: Pre-training\ntext encoders as discriminators rather than genera-\ntors. In Proceedings of the 8th International Confer-\nence on Learning Representations (ICLR 2020).\nIdo Dagan, Oren Glickman, and Bernardo Magnini.\n2005. The pascal recognising textual entailment\nchallenge. In Machine Learning Challenges Work-\nshop, pages 177–190.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In Proceedings of the 2019 Conference of the\nNorth American Chapter of the Association for Com-\nputational Linguistics: Human Language Technolo-\ngies (NAACL-HLT 2019), pages 4171–4186.\nWilliam B. Dolan and Chris Brockett. 2005. Automati-\ncally constructing a corpus of sentential paraphrases.\nIn Proceedings of the Third International Workshop\non Paraphrasing (IWP 2005), pages 9–16.\nChenhe Dong, Yuexiang Xie, Bolin Ding, Ying Shen,\nand Yaliang Li. 2022. Collaborating heteroge-\nneous natural language processing tasks via feder-\nated learning. arXiv preprint arXiv:2212.05789.\nSuyu Ge, Fangzhao Wu, Chuhan Wu, Tao Qi,\nYongfeng Huang, and Xing Xie. 2020. Fed-\nner: Privacy-preserving medical named entity recog-\nnition with federated learning. arXiv preprint\narXiv:2003.09288.\nDanilo Giampiccolo, Bernardo Magnini, Ido Dagan,\nand Bill Dolan. 2007. The third pascal recognizing\ntextual entailment challenge. In Proceedings of the\nACL-PASCAL Workshop on Textual Entailment and\nParaphrasing, pages 1–9.\nXuan Gong, Abhishek Sharma, Srikrishna Karanam,\nZiyan Wu, Terrence Chen, David Doermann, and\nArun Innanje. 2022. Preserving privacy in feder-\nated learning with ensemble cross-domain knowl-\nedge distillation. In Proceedings of the 36th AAAI\nConference on Artiﬁcial Intelligence (AAAI 2022) ,\npages 11891–11899.\nTzu-Ming Harry Hsu, Hang Qi, and Matthew Brown.\n2019. Measuring the effects of non-identical data\ndistribution for federated visual classiﬁcation. arXiv\npreprint arXiv:1909.06335.\nLi Hu, Hongyang Yan, Lang Li, Zijie Pan, Xi-\naozhang Liu, and Zulong Zhang. 2021. Mhat: An\nefﬁcient model-heterogenous aggregation training\nscheme for federated learning. Information Sci-\nences, 560:493–503.\nSohei Itahara, Takayuki Nishio, Yusuke Koda,\nMasahiro Morikura, and Koji Yamamoto. 2021.\nDistillation-based semi-supervised federated learn-\ning for communication-efﬁcient collaborative train-\ning with non-iid private data. IEEE Transactions on\nMobile Computing, 22(1):191–205.\nEunjeong Jeong, Seungeun Oh, Hyesung Kim, Ji-\nhong Park, Mehdi Bennis, and Seong-Lyun Kim.\n2018. Communication-efﬁcient on-device ma-\nchine learning: Federated distillation and augmen-\ntation under non-iid private data. arXiv preprint\narXiv:1811.11479.\nShaoxiong Ji, Shirui Pan, Guodong Long, Xue Li, Jing\nJiang, and Zi Huang. 2019. Learning private neural\nlanguage modeling with attentive aggregation. In\n8575\nProceedings of the International Joint Conference\non Neural Networks (IJCNN 2019).\nHector J. Levesque, Ernest Davis, and Leora Morgen-\nstern. 2012. The winograd schema challenge. In\nProceedings of the Thirteenth International Confer-\nence on Principles of Knowledge Representation\nand Reasoning (KR 2012), pages 552–561.\nDaliang Li and Junpu Wang. 2019. Fedmd: Heteroge-\nnous federated learning via model distillation. arXiv\npreprint arXiv:1910.03581.\nBill Yuchen Lin, Chaoyang He, Zihang Zeng, Hulin\nWang, Yufen Huang, Christophe Dupuy, Rahul\nGupta, Mahdi Soltanolkotabi, Xiang Ren, and\nSalman Avestimehr. 2022. Fednlp: Benchmark-\ning federated learning methods for natural language\nprocessing tasks. In Findings of the Association\nfor Computational Linguistics: NAACL 2022, pages\n157–175.\nGuanyu Lin, Liang Feng, Pan Weike, and Ming Zhong.\n2020. Fedrec: Federated recommendation with ex-\nplicit feedback. IEEE Intelligent Systems, 36(5):21–\n30.\nTao Lin, Lingjing Kong, Sebastian U. Stich, and Martin\nJaggi. Ensemble distillation for robust model fusion\nin federated learning. In Advances in Neural Infor-\nmation Processing Systems (NeurIPS 2020) , pages\n2351–2363.\nDianbo Liu and Tim Miller. 2020. Federated pretrain-\ning and ﬁne tuning of bert using clinical notes from\nmultiple silos. arXiv preprint arXiv:2002.08562.\nMing Liu, Stella Ho, Mengqi Wang, Longxiang Gao,\nYuan Jin, and He Zhang. 2021. Federated learning\nmeets natural language processing: A survey. arXiv\npreprint arXiv:2107.12603.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In Proceedings of the\n7th International Conference on Learning Represen-\ntations (ICLR 2019).\nAndrew L. Maas, Raymond E. Daly, Peter T. Pham,\nDan Huang, Andrew Y . Ng, and Christopher Potts.\n2011. Learning word vectors for sentiment analy-\nsis. In Proceedings of the 49th Annual Meeting of\nthe Association for Computational Linguistics (ACL\n2011), pages 142–150.\nH Brendan Mcmahan, Eider Moore, Daniel Ramage,\nSeth Hampson, and Blaise Aguera y Arcas. 2017.\nCommunication-efﬁcient learning of deep networks\nfrom decentralized data. In Proceedings of the 20th\nInternational Conference on Artiﬁcial Intelligence\nand Statistics (AISTATS 2017), pages 1273–1283.\nHieu Pham, Zihang Dai, Qizhe Xie, and Quoc V . Le.\n2021. Meta pseudo labels. In Proceedings of\nthe IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR 2021) , pages 11557–\n11568.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. Squad: 100,000+ questions for\nmachine comprehension of text. In Proceedings of\nthe 2016 Conference on Empirical Methods in Nat-\nural Language Processing (EMNLP 2016) , pages\n2383–2392.\nRichard Socher, Alex Perelygin, Jean Y . Wu, Jason\nChuang, Christopher D. Manning, Andrew Y . Ng,\nand Christopher Potts. 2013. Recursive deep mod-\nels for semantic compositionality over a sentiment\ntreebank. In Proceedings of the 2013 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP 2013), pages 1631–1642.\nDianbo Sui, Yubo Chen, Jun Zhao, Yantao Jia, Yuantao\nXie, and Weijian Sun. 2020. Feded: Federated learn-\ning via ensemble distillation for medical relation ex-\ntraction. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP 2020), pages 2118–2128.\nYuanyishu Tian, Yao Wan, Lingjuan Lyu, Dezhong\nYao, Hai Jin, and Lichao Sun. 2022. Fedbert:\nWhen federated learning meets pre-training. ACM\nTransactions on Intelligent Systems and Technology,\n13(4):1–26.\nPaul V oigt and Axel von dem Bussche. 2017. The eu\ngeneral data protection regulation (gdpr). A Prac-\ntical Guide, 1st Ed., Cham: Springer International\nPublishing.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R. Bowman. 2019.\nGlue: A multi-task benchmark and analysis platform\nfor natural language understanding. In Proceed-\nings of the 7th International Conference on Learn-\ning Representations (ICLR 2019).\nAlex Warstadt, Amanpreet Singh, and Samuel R. Bow-\nman. 2019. Neural network acceptability judgments.\nTransactions of the Association for Computational\nLinguistics, 7:625–641.\nAdina Williams, Nikita Nangia, and Samuel R. Bow-\nman. 2018. A broad-coverage challenge corpus\nfor sentence understanding through inference. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies\n(NAACL-HLT 2018), pages 1112–1122.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Ruslan Salakhutdinov, and Quoc V . Le. 2019.\nXlnet: Generalized autoregressive pretraining for\nlanguage understanding. In Advances in Neural In-\nformation Processing Systems (NeurIPS 2019).\n8576\nYuan Zhang, Jason Baldridge, and Luheng He. 2019.\nPaws: Paraphrase adversaries from word scrambling.\nIn Proceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies\n(NAACL-HLT 2019), pages 1298–1308.\nZhuo Zhang, Xiangjing Hu, Lizhen Qu, Qifan Wang,\nand Zenglin Xu. 2022. Federated model decompo-\nsition with private vocabulary for text classiﬁcation.\nIn Proceedings of the 2022 Conference on Empirical\nMethods in Natural Language Processing (EMNLP\n2022), pages 6413–6425.\nA Details of GLUE Benchmark\nGLUE (Wang et al., 2019) is a benchmarking\nframework designed to assess the performance and\ngeneralization capability of NLP models especially\nlarge-scale PLMs across nine NLP tasks. The de-\nscriptions of each task are presented as follows:\n• WNLI The Winograd Natural Language In-\nference (Levesque et al., 2012) is a sentence-\npair binary classiﬁcation task that requires the\nmodel to determine whether two sentences in\na given sentence-pair are entailment relations,\nwith the evaluation metric of accuracy.\n• RTE The Recognizing Textual Entail-\nment (Dagan et al., 2005; Bar-Haim et al.,\n2006; Giampiccolo et al., 2007; Bentivogli\net al., 2009) is a sentence-pair binary clas-\nsiﬁcation task, which requires the model to\ndetermine whether two sentences in a given\nsentence pair are entailment relations, with\nthe evaluation metric of accuracy.\n• MRPC The Microsoft Research Paraphrase\nCorpus (Dolan and Brockett, 2005) is a\nsentence-pair binary classiﬁcation task that\nrequires the model to determine whether two\nsentences in a given sentence pair are seman-\ntically equivalent, with evaluation metrics of\naccuracy and F1-score.\n• STS-B The Semantic Textual Similarity\nBenchmark (Cer et al., 2017) is a sentence-\npair regression task that requires the model\nto evaluate how similar two sentences in a\ngiven sentence-pair are by a ﬂoating score\nrange from 0 to 5, with evaluation metrics of\nPearson and Spearman correlations.\n• CoLA The Corpus of Linguistic Acceptabil-\nity (Warstadt et al., 2019) is a single-sentence\nbinary classiﬁcation task that requires the\nDataset #Train #Dev #Test\nWNLI 635 71 146\nRTE 2490 277 3000\nMRPC 3668 408 1725\nSTS-B 5749 1500 1379\nCoLA 8551 1043 1063\nSST-2 67349 872 1821\nQNLI 104743 5463 5463\nQQP 363846 40430 390965\nMNLI-m 392702 9815 9796\nMNLI-mm 9832 9847\nTable 6: Statistics of the GLUE benchmark.\nmodel to determine whether a given English\nsentence is grammatically correct, with the\nevaluation metric of the Matthews correlation.\n• SST-2 The Stanford Sentiment Tree-\nbank (Socher et al., 2013) is a single-sentence\nbinary classiﬁcation task that requires the\nmodel to determine whether a given movie\nreview is positive or negative in sentiment,\nwith the evaluation metric of accuracy.\n• QNLI The Question Natural Language Infer-\nence (Rajpurkar et al., 2016) is a sentence-pair\nbinary classiﬁcation task. Given a question\nand a context, the model is required to deter-\nmine whether the context contains the answer\nto the question, with the evaluation metric of\naccuracy.\n• QQP The Quora Question Pairs is a sentence-\npair binary classiﬁcation task. Given a pair of\nquestions, the model is required to determine\nwhether the two sentences are semantically\nequivalent, with evaluation metrics of accu-\nracy and F1-score.\n• MNLI The Multi-genre Natural Language\nInference (Williams et al., 2018) is a sentence-\npair three-way classiﬁcation task. Given a\npremise and a hypothesis, the model is re-\nquired to determine whether the hypothesis is\nan entailment, contradiction, or neutral with\nrespect to the premise. The task is divided\ninto matched and mismatched versions, with\nevaluation metrics of matched accuracy and\nmismatched accuracy, respectively.\nThe statistics of these tasks are presented in Ta-\nble 6.\n8577",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8759993314743042
    },
    {
      "name": "Benchmarking",
      "score": 0.6619858145713806
    },
    {
      "name": "Federated learning",
      "score": 0.6574918031692505
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.605280339717865
    },
    {
      "name": "Overhead (engineering)",
      "score": 0.5809915661811829
    },
    {
      "name": "Code (set theory)",
      "score": 0.5329514741897583
    },
    {
      "name": "Vulnerability (computing)",
      "score": 0.5319089293479919
    },
    {
      "name": "Inference",
      "score": 0.5202797055244446
    },
    {
      "name": "Homogeneous",
      "score": 0.45413240790367126
    },
    {
      "name": "Scale (ratio)",
      "score": 0.44462859630584717
    },
    {
      "name": "Language model",
      "score": 0.4285995662212372
    },
    {
      "name": "Artificial intelligence",
      "score": 0.40637439489364624
    },
    {
      "name": "Machine learning",
      "score": 0.3923768699169159
    },
    {
      "name": "Programming language",
      "score": 0.12276393175125122
    },
    {
      "name": "Computer security",
      "score": 0.11567291617393494
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Thermodynamics",
      "score": 0.0
    },
    {
      "name": "Marketing",
      "score": 0.0
    },
    {
      "name": "Business",
      "score": 0.0
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I189210763",
      "name": "Yunnan University",
      "country": "CN"
    }
  ]
}