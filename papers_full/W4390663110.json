{
  "title": "Reliability of large language models in managing odontogenic sinusitis clinical scenarios: a preliminary multidisciplinary evaluation",
  "url": "https://openalex.org/W4390663110",
  "year": 2024,
  "authors": [
    {
      "id": null,
      "name": "Saibene, Alberto Maria",
      "affiliations": [
        "Ospedale San Paolo"
      ]
    },
    {
      "id": null,
      "name": "Allevi, Fabiana",
      "affiliations": [
        "Ospedale San Paolo"
      ]
    },
    {
      "id": null,
      "name": "Calvo-Henriquez, Christian",
      "affiliations": [
        "Universidade de Santiago de Compostela"
      ]
    },
    {
      "id": "https://openalex.org/A3001894872",
      "name": "Maniaci, Antonino",
      "affiliations": [
        "University of Catania"
      ]
    },
    {
      "id": null,
      "name": "Mayo-Yáñez, Miguel",
      "affiliations": [
        "Complexo Hospitalario Universitario A Coruña"
      ]
    },
    {
      "id": "https://openalex.org/A3184133863",
      "name": "Paderno Alberto",
      "affiliations": [
        "University of Brescia"
      ]
    },
    {
      "id": null,
      "name": "Vaira, Luigi Angelo",
      "affiliations": [
        "University of Sassari"
      ]
    },
    {
      "id": "https://openalex.org/A3006155317",
      "name": "Felisati Giovanni",
      "affiliations": [
        "Ospedale San Paolo"
      ]
    },
    {
      "id": null,
      "name": "Craig, John R.",
      "affiliations": [
        "Henry Ford Health System"
      ]
    },
    {
      "id": null,
      "name": "Saibene, Alberto Maria",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Allevi, Fabiana",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Calvo-Henriquez, Christian",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3001894872",
      "name": "Maniaci, Antonino",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Mayo-Yáñez, Miguel",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3184133863",
      "name": "Paderno Alberto",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Vaira, Luigi Angelo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3006155317",
      "name": "Felisati Giovanni",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Craig, John R.",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4366769280",
    "https://openalex.org/W4383187389",
    "https://openalex.org/W3162640618",
    "https://openalex.org/W3109981039",
    "https://openalex.org/W3091999201",
    "https://openalex.org/W3131084776",
    "https://openalex.org/W4306774169",
    "https://openalex.org/W2087220575",
    "https://openalex.org/W4381106920",
    "https://openalex.org/W4376133327",
    "https://openalex.org/W4361296421",
    "https://openalex.org/W3093102329",
    "https://openalex.org/W2902109505",
    "https://openalex.org/W3178025782",
    "https://openalex.org/W4383186888",
    "https://openalex.org/W4384807943",
    "https://openalex.org/W4377009978",
    "https://openalex.org/W4307582678",
    "https://openalex.org/W2124438536",
    "https://openalex.org/W3042062707",
    "https://openalex.org/W4368362818",
    "https://openalex.org/W3033346134",
    "https://openalex.org/W4386624025",
    "https://openalex.org/W3132307403",
    "https://openalex.org/W4384561103"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)\nEuropean Archives of Oto-Rhino-Laryngology (2024) 281:1835–1841 \nhttps://doi.org/10.1007/s00405-023-08372-4\nRHINOLOGY\nReliability of large language models in managing odontogenic \nsinusitis clinical scenarios: a preliminary multidisciplinary evaluation\nAlberto Maria Saibene1  · Fabiana Allevi2  · Christian Calvo‑Henriquez3  · Antonino Maniaci4  · \nMiguel Mayo‑Yáñez5  · Alberto Paderno6  · Luigi Angelo Vaira7,8  · Giovanni Felisati1  · John R. Craig9 \nReceived: 2 August 2023 / Accepted: 22 November 2023 / Published online: 8 January 2024 \n© The Author(s) 2024\nAbstract\nPurpose This study aimed to evaluate the utility of large language model (LLM) artificial intelligence tools, Chat Generative \nPre-Trained Transformer (ChatGPT) versions 3.5 and 4, in managing complex otolaryngological clinical scenarios, specifi-\ncally for the multidisciplinary management of odontogenic sinusitis (ODS).\nMethods A prospective, structured multidisciplinary specialist evaluation was conducted using five ad hoc designed ODS-\nrelated clinical scenarios. LLM responses to these scenarios were critically reviewed by a multidisciplinary panel of eight \nspecialist evaluators (2 ODS experts, 2 rhinologists, 2 general otolaryngologists, and 2 maxillofacial surgeons). Based on \nthe level of disagreement from panel members, a Total Disagreement Score (TDS) was calculated for each LLM response, \nand TDS comparisons were made between ChatGPT3.5 and ChatGPT4, as well as between different evaluators.\nResults While disagreement to some degree was demonstrated in 73/80 evaluator reviews of LLMs’ responses, TDSs were \nsignificantly lower for ChatGPT4 compared to ChatGPT3.5. Highest TDSs were found in the case of complicated ODS with \norbital abscess, presumably due to increased case complexity with dental, rhinologic, and orbital factors affecting diagnostic \nand therapeutic options. There were no statistically significant differences in TDSs between evaluators’ specialties, though \nODS experts and maxillofacial surgeons tended to assign higher TDSs.\nConclusions LLMs like ChatGPT, especially newer versions, showed potential for complimenting evidence-based clinical \ndecision-making, but substantial disagreement was still demonstrated between LLMs and clinical specialists across most \ncase examples, suggesting they are not yet optimal in aiding clinical management decisions. Future studies will be important \nto analyze LLMs’ performance as they evolve over time.\nKeywords Chronic rhinosinusitis · Maxillary sinusitis · Oroantral fistula · Dental implant · Computer-assisted diagnosis · \nArtificial intelligence\nIntroduction\nChat Generative Pre-Trained Transformer (ChatGPT, Open \nAI, San Francisco, CA, US) is the best-known example of \na large language model (LLM), a text-interactive artificial \nintelligence (AI) trained on a wide range of texts available \non the Internet. ChatGPT was trained with publicly available \ndata sets consisting mostly of the Common Crawl (a publicly \navailable data set of web pages), a data set of books and arti-\ncles sourced from Project Gutenberg and other open-source \ndata sets, and English Wikipedia pages (ref https:// about  \nchatg pt. com/ data- source- of- chatg pt/). ChatGPT versions 3.5 \nand 4 were developed as easily accessible and user-friendly \nAI tools and have gained significant media attention due to \ntheir ability to interact textually with near-human capabil -\nity [1].\nTheir apparent ease of use and unlimited capabilities draw \nattention and concerns from the healthcare community. Still, \ntheir role and potential limitations in healthcare have yet to \nbe explored extensively, particularly in more niche settings \nsuch as Otolaryngology [2].\nTo explore the possibilities offered by LLM in managing \ncomplex otolaryngological scenarios, odontogenic sinusitis \nAlberto Maria Saibene and Fabiana Allevi collaborated equally on \nthis manuscript.\nGiovanni Felisati and John R. Craig collaborated equally on this \nmanuscript.\nExtended author information available on the last page of the article\n1836 European Archives of Oto-Rhino-Laryngology (2024) 281:1835–1841\n(ODS) represents an important and novel subject. ODS is \na controversial multidisciplinary condition [3 –5], whose \ndiagnosis has been only recently addressed by international \nconsensus [6 ] and has yet to be a topic of rhinologic AI \nresearch [7].\nThis study was designed to evaluate whether LLM can \nbe helpful in managing niche clinical scenarios, by submit-\nting to ChatGPT five ad hoc designed ODS-related cases \nand having a multidisciplinary panel analyze the AI replies. \nOther than simply testing ChatGPT 3.5 and 4 clinical \nmanagement support capabilities, we aimed to determine \nwhether the newer ChatGPT versions offered more reliable \nreplies and whether different specialists reacted differently \nto the AI-generated replies.\nMethods\nThis study did not involve human participants, their data, or \nbiological material. Therefore, it did not require institutional \nresearch ethics committee evaluation.\nThis study was designed as a prospective and structured \nmultidisciplinary specialist evaluation of LLM management \nsuggestions for four ODS cases and one case of unilateral \nrhinosinusitis that could mimic ODS. ODS diagnoses were \ndefined by a recent international consensus statement by \nCraig et al. [6].\nA single author (AMS) prepared the five text clinical \ncases. Three cases were designed to cover three groups of \nODS etiologies[8 ] (case 1, right ODS due to apical peri-\nodontitis with right maxillary and ethmoid involvement; \ncase 2, left ODS due to peri-implantitis with left maxillary, \nethmoid, and frontal involvement; case 3, left ODS follow -\ning maxillary sinus grafting with pan-sinus involvement and \nan adjacent orbital abscess). Case 4 depicted a recurrence \nof previously undiagnosed right ODS following root canal \ntreatment. Case 5 depicted a non-sinusitis case with com-\nputed tomography of mild mucosal thickening around stable \ndental implants, thus mimicking ODS. The five cases were \nsubmitted to ChatGPT 3.5 and 4 on May 1, 2023 (available \nat https:// openai. com/ blog/ chatg pt from OpenAI), with the \ndetailed prompts reported in Online Resource 1, describing \nnasal endoscopy signs, patients' symptoms, and radiological \nreports and requesting the LLM to act as an otolaryngologist \nand correctly manage the patient.\nThe replies generated by each LLM were collected in \na Google Documents file (Google LLC, Mountain View, \nCalifornia, US) and sent to the evaluation group. The evalu-\nation group was composed of different specialists, as defined \nby their scientific output, including two ODS expert rhi-\nnologists (GF and JRC), two rhinologists (AM and CCH), \ntwo non-rhinologist otolaryngologists (MM and AP, whose \nresearch work is usually focused on head and neck surgery \nand oncology), and two maxillofacial surgeons (FA and \nLAV). The evaluation group members were informed that \nthe replies they received were LLM-generated and revolved \naround ODS. The evaluation group was provided with \na Google Sheets file (Google LLC), in which they were \ninstructed to provide critical comments for each case and \nLLM reply concerning diagnosis, medical management, and \nsurgical treatment, plus any other concerns that arose.\nAnswers for each domain (diagnosis, medical manage-\nment, surgical treatment, other concerns) were scored on a \nfour-point scale according to the degree of disagreement. \nThe scale was as follows:\n0, no disagreement.\n1, minor disagreement (the answer was missing a non-\ncritical detail).\n2, moderate disagreement (one or more answer details \nwere wrong, though they were not critical for the patient \noutcome).\n3, major disagreement (the answer was lacking or \nwrongly reporting information that might be crucial for the \npatient outcome).\nAs the eight evaluators' were instructed to criticize the \nLLM output with textual responses, the degree of disagree-\nment was scored separately by two authors according to the \naforementioned scale. Any differences in scores were set -\ntled by consensus between evaluators. Evaluators’ critical \ncommentaries were directed to the four defined domains \n(diagnosis, medical management, surgical treatment, other \nconcerns), each one being scored separately for disagree-\nment. The resulting scores for each domain were added to \ngenerate a total disagreement score (TDS) for each evalua-\ntor and LLM reply. Therefore, for each evaluator and LLM \nreply, the TDS might range from 0 (complete agreement \nin all four domains) to 12 (major disagreement in all four \ndomains).\nTDSs for each case were considered non-parametric data. \nTherefore, median and interquartile range (IQR) (reported as \nmedian[IQR]) were used as descriptive statistics for continu-\nous data. Median TDS from both evaluations of any single \ncase were compared between ChatGPT 3.5 and ChatGPT 4 \nwith a Wilcoxon signed-rank test. Median TDSs were com-\npared between each of the four groups of evaluators with \na Kruskal–Wallis test. All statistical tests were performed \nusing SPSS v. 28 (IBM Corp, Armonk, New York, US).\nResults\nAnswers generated by the two LLMs were reported fol-\nlowing the prompt in Online Resource 1 (prompts in bold \nfont, ChatGPT 3.5 replies in plain font, ChatGPT 4 replies \nin italics).\n1837European Archives of Oto-Rhino-Laryngology (2024) 281:1835–1841 \nTDSs for each evaluator and Chat GPT answers are \nreported in Table 1 , While Online Resource 2 reports the \nscore for each domain. Case 5 (ODS mimic) received the \nlowest TDSs for both ChatGPT 3.5 (3[1.75]) and Chat-\nGPT4 (2.5[1.25]), though ChatGPT 4 showed a similarly \nlow TDS for ODS case 2 (2.5[3.25]). Note that for case \n2, it was the only time ChatGPT 4 received a TDS of 0 \nfrom multiple evaluators. Case 3 (complicated ODS) \nreceived the highest TDSs for both ChatGPT 3.5 (8[2.5]) \nand ChatGPT 4 (4[2.25]). Two ChatGPT 3.5 answers and \nfive ChatGPT 4 answers had TDSs of 0 when compared \nwith some of the evaluators, though 73/80 responses suf-\nfered from some degree of disagreement. Major disagree-\nments with the LLM replies were noted for 22 subitems in \nChatGPT 3.5 answers, and only for 2 items in ChatGPT \n4. The highest rate of major disagreements was found in \nthe diagnostic domain (11 items), followed by medical \nand surgical management, while it was rarely reported for \nthe “other concerns” domain. TDS was significantly lower \nfor ChatGPT4 answers (3[2]) compared to ChatGPT3.5 \nanswers (5[3], p < 0.001).\nFigure 1 shows the median TDSs for all answers accord-\ning to each group of evaluators. There were no statisti-\ncally significant differences in TDSs based on raters’ spe-\ncialty groupings, although there was a tendency towards \nhigher TDSs with maxillofacial surgeons (4[4]) and ODS \nexperts (4.5[3]), p  = 0.085. Maxillofacial surgeons and \nODS experts showed a general tendency towards a stronger \ncriticism of the LLM answers, which was not limited to \nspecific domains or cases.\nDiscussion\nThe application of LLMs in the medical field is a rapidly \nevolving area, with the potential to aid in clinical decision-\nmaking, especially in subspecialty fields [9 , 10]. Yet, any \nevaluation of these tools must be context-specific and \nTable 1  Total disagreement scores for each answer and evaluator, (GPT3, Chat GPT 3.5 answer; GPT4, Chat GPT 4 answer; FA, LAV, MMY, \nAP, CCH, AM, GF, JRC, evaluators’ initials; TDS, total disagreement score; IQR, interquartile range)\nFA LAV MMY AP CCH AM GF JRC Overall TDS Median TDS TDS IQR Minimum \nTDS\nMaxi-\nmum \nTDS\nCase 1\n GPT3 5 6 4 5 3 5 5 6 39 5 0.5 3 6\n GPT4 3 2 4 3 4 3 3 6 28 3 1 2 6\nCase 2\n GPT3 4 6 4 5 4 3 5 4 35 4 1 3 6\n GPT4 0 2 4 3 0 3 0 4 16 2.5 3.25 0 4\nCase 3\n GPT3 6 8 5 8 8 3 9 9 56 8 2.5 3 9\n GPT4 4 2 2 4 5 5 3 5 30 4 2.25 2 5\nCase 4\n GPT3 6 6 2 3 0 3 6 7 33 4.5 3.25 0 7\n GPT4 4 3 2 3 0 3 2 4 21 3 1.25 0 4\nCase 5\n GPT3 0 5 1 3 3 3 4 7 26 3 1.75 0 7\n GPT4 0 3 1 2 4 2 3 3 18 2.5 1.25 0 4\nFig. 1  Box and whiskers plot showing the distribution of total disa-\ngreement scores (TDS) according to the subspecialty of evaluators \n(ENT non-rhinology otolaryngologists, MXF maxillofacial surgeons, \nODS odontogenic sinusitis specialists, RHINO rhinologists)\n1838 European Archives of Oto-Rhino-Laryngology (2024) 281:1835–1841\nrigorous. This assessment is particularly relevant, urgent, \nand novel for complex conditions, such as ODS, where opti-\nmal multidisciplinary diagnostic and therapeutic paradigms \nare challenging to establish due to a relatively scarce body of \nrecently published evidence [11]. This study aimed to evalu-\nate the reliability of two versions of the ChatGPT LLM in \nmanaging ODS. To the authors’ knowledge, this was the first \nstudy to assess systematically the ability of LLM to manage \nniche multidisciplinary clinical scenarios, specifically ODS.\nThe results highlighted several areas, where the LLMs’ \nperformances were suboptimal. These limitations ranged \nfrom minor disagreements to more critical discrepancies in \nthe responses given by the LLMs, suggesting that the cur -\nrent versions would not be reliable as standalone decision-\nmaking tools for ODS. Diagnosing and managing ODS \ncan be challenging, requiring a nuanced understanding of \nits pathogenesis, a broad array of causative etiologies, and \nfrequent overlap of non-specific symptoms which make \nit difficult to distinguish from other sinonasal conditions. \nIt would seem that LLMs could not consistently identify \nand process some of these nuances. For example, major \ndisagreements were especially noted by all evaluators in the \ndiagnosis domains of LLM responses. LLMs may not have \nconsistently understood the potential pathogenic connection \nbetween dental procedures, dental conditions, and sinusitis. \nLLMs also did not use consensus-based ODS definitions, \ndiagnostic classifications, or acronyms as proposed either \nby Felisati et al. or Craig et al. [6 , 8, 12, 13]. Chat GPT \n3.5 even failed to use the word “odontogenic”, while Chat \nGPT4 did use this diagnostic term. Higher disagreement in \nthis domain could also be due to the perceived need for a \n“precise” diagnosis, which led to stronger criticism of vague \nLLM replies. Another area of concern was illustrated by \nthe significantly higher TDSs for both LLM versions when \nevaluating the complicated ODS case (Case 3). For exam-\nple, ChatGPT 3.5 failed to understand the potential for ODS \nto cause extra-sinus orbital, intracranial, or osseous infec-\ntious complications, and ChatGPT4 still failed to prioritize \nemergency interventions adequately when compared to the \nliterature [14]. LLM performance was relatively better in \nless complex cases, such as case 2 (overt ODS) as well as \ncase 5 (rhinosinusitis mimicking ODS). This suggests that \nthe LLMs may have some utility in ruling in ODS when the \npresentation is classic, and ruling out ODS when ODS likeli-\nhood is low. The lower rate of TDS for medical and surgical \nmanagement, on the other hand, might be due to the multiple \ntherapeutic options that can be proposed to ODS patients \nfirsthand, thus giving LLMs a larger interpretation margin. \nIn these regards, it is indeed interesting that LLMs did not \nprovide several management options for each case, but they \ndid demonstrate some flexibility in proposing composite \nmanagement plans that might discretionally include two or \nmore options (combined or not). Thus ChatGPT appears \nlimited in helping select a specific treatment plan but does \nprovide a rather comprehensive—though often convolute—\noverview of available options.\nAnother important point to highlight is that while TDSs \nvaried substantially across different case types, with most \nresponses generating some degree of disagreement, Chat \nGPT4 clearly outperformed ChatGPT3.5 with lower TDSs, \npresumably due to its higher number of parameters and \nimproved architecture (though precise training data sets \nare not publicly available). The lower TDSs often resulted \nfrom longer answers covering more differential diagnoses \nor treatment possibilities, but choice prioritization was not \nalways clear. This finding highlights an intrinsic limitation \nof LLMs; they are ultra-wide encyclopedic references inca-\npable of clinical reasoning [15] and have not yet reached \nthe reasoning potential of general artificial intelligence [7 ]. \nHowever, these results also bring to light a very exciting \nimplication with regard to facilitating multidisciplinary \nmanagement of complex conditions, for which published \nevidence may be relatively new, and yet to be highlighted in \nspecialty guidelines. ODS is a great example of this since \nmore attention has been placed on researching the entity \nonly recently. LLMs and other AI technologies could poten-\ntially obtain such newly published information immediately \nif available online. If such AI technologies reached appropri-\nate clinical accuracy, clinicians could call on the most up-\nto-date evidence instantaneously, saving a great deal of time \nfor clinicians and providing patients with the highest qual-\nity treatment options. While this implication is exciting, AI \ntools must evolve to reach a point where online information \nand published literature are prioritized in a way to optimize \nclinical utility. In these regards, training LLMs only on pub-\nlicly available data sets could induce another bias in replies \nby omitting potentially important recent scientific data pro-\ntected by a paywall. Furthermore, some researchers have \ntheorized potential changes over time in the performance of \nthe LLMs analyzed in this study [16], and if true, findings \nfrom this study highlight the need for regular assessments \nof LLM performance metrics to ensure appropriate use in \nclinical practice.\nHowever, the clinical field is characterized by specific \nneeds and requirements that may not be suited for general-\npurpose LLMs. To this end, some researchers have tried \ndeveloping AI models fine-tuned for the medical domain. \nFor example, Med Palm 2 by Google Research has shown \nremarkable results in answering medical questions with \nstriking improvements when compared with its previous \niteration, hinting at a promising path for future research [17].\nWhen developing performance metrics for these clinical \nLLMs, it will be important to reach a consensus between \nexperts in the given field of interest. As an example, while \nnot reaching statistical significance in this small preliminary \nstudy, maxillofacial surgeons and ODS experts assigned \n1839European Archives of Oto-Rhino-Laryngology (2024) 281:1835–1841 \nhigher TDSs to LLM responses. On the one hand, this dis-\ncrepancy reflects the inherent subjectivity when interpret-\ning AI-generated responses, further emphasizing the need \nfor validated measures to evaluate AI tools. On the other \nhand, it highlights that ODS experts and maxillofacial sur -\ngeons may be more attuned to the nuances of managing \nODS. Again, these specialists might simply tend to be more \nvocal in expressing their criticism in a research field they \nfeel closer to their day-to-day clinical routine. For example, \nclinicians should be aware of both the distinct inflammatory \n[18] and infectious sinusitis [ 19, 20] as well as the numer -\nous odontogenic]or dental treatment-related causes of ODS \n[6, 21]. Since ODS has not been highlighted adequately in \notolaryngologic or dental therapeutic guidelines, non-ODS \nexperts may not be aware of some of these diagnostic and \ntherapeutic nuances [6, 22, 23]. These factors should be con-\nsidered when developing validated measures of accuracy for \nLLMs and other AI technologies being utilized for clinical \ndecision-making.\nWhen considering the LLM analysis, it has to be noted \nthat in this case, we chose to provide the AI with strictly \nmedical information, trying to be as objective as possible, \nboth through complete data reporting and language clarity. \nWhether an LLM would be able to interpret a clinical sce-\nnario through lay terms patient-reported signs and symptoms \nand clinical/radiological pictures (through its recent Chat-\nGPT 4 V evolution) should be subjected to further specific \nanalysis. Such an analysis—albeit interesting—would work \non a double operational level for the LLM, as the lay lan-\nguage analysis and clinical picture interpretation represent \na further potential confounding factor. As little is known \nabout the potential of these AI tools, we opted in this work to \nminimize the bias focusing only on exploring the capabilities \nin terms of clinical management.\nThis small preliminary study had indeed several limita-\ntions. First, analyzing more clinical cases with a broader \ngroup of evaluators could have led to identifying more \nspecific behavioral patterns for LLMs, highlighting other \npotential strengths and weaknesses. Second, potential bias \nwas introduced since evaluators were aware of the focus \non ODS. This bias could be avoided by mixing ODS cases \nwith non-odontogenic sinus disease cases. Future studies \ncan build on this study by generating a larger set of all rhi-\nnologic conditions. Finally, while the proposed TDS was an \nattempt at generating a homogeneous and objective inter -\npretation of AI and clinician evaluations, this system has \nnot been validated and, therefore, should be viewed with \ncaution. In these regards, though other LLM output scor -\nings have been proposed while the present research was \nongoing [24], TDS may represent a swift tool for testing \nAI interpretations over a significant number of cases and \nwith multiple operators. This is due to TDS not requiring \ntraining each rater, as its value can be calculated by having \none or—preferably two—researchers rating textual replies \nin the single domains, which, in turn, can be adapted to most \nclinical scenarios. It is indeed of the utmost importance that \nfuture research be dedicated to developing validated scoring \nsystems to analyze LLMs in a more reproducible fashion \nacross research studies.\nAs it would be even more interesting to study the tenden-\ncies of LLM behavior for diagnostic and therapeutic pur -\nposes in different niche and non-niche settings over a more \nconsistent number of raters, the development of strong LLM \nevaluation tools, TDM being one of them, is in our opinion \npivotal.\nConclusion\nWhile LLMs such as ChatGPT, especially newer versions, \noffer significant potential in complimenting evidence-based \nclinical decision-making, the substantial variability in TDSs \nacross case examples in this study suggests that they are not \nyet optimal for aiding clinical management. Future studies \nwill be important for analyzing LLMs’ performance as they \nevolve over time.\nSupplementary Information The online version contains supplemen-\ntary material available at https:// doi. org/ 10. 1007/ s00405- 023- 08372-4.\nAuthor contributions All authors contributed to the study’s concep-\ntion and design. Alberto Maria Saibene, Giovanni Felisati, and John \nR. Craig conceived the original idea for the study, Clinical cases and \nprompts were prepared by Alberto Maria Saibene, who collected and \nanalyzed the study data. Critical evaluations were numerically clas-\nsified by Alberto M. Saibene and Fabiana Allevi. All authors except \nAlberto M. Saibene performed the large language model output \nanswers evaluation. All authors contributed to the final version of this \nmanuscript.\nFunding Open access funding provided by Università degli Studi di \nMilano within the CRUI-CARE Agreement.\nData availability All data pertaining to this systematic review are avail-\nable from the corresponding author upon reasonable request.\nDeclarations \nConflict of interest The authors have no potential conflict of interest or \nfinancial disclosures pertaining to this article.\nEthical approval This study did not involve human participants, their \ndata, or biological material. Therefore, it did not require institutional \nresearch ethics committee evaluation.\nOpen Access  This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \n1840 European Archives of Oto-Rhino-Laryngology (2024) 281:1835–1841\nincluded in the article's Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article's Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nReferences\n 1. Liu S, Wright AP, Patterson BL et al (2023) Using AI-generated \nsuggestions from ChatGPT to optimize clinical decision support. \nJ Am Med Inform Assoc 30:1237–1245. https:// doi. org/ 10. 1093/ \njamia/ ocad0 72\n 2. Chiesa-Estomba CM, Lechien JR, Vaira LA et al (2023) Explor -\ning the potential of Chat-GPT as a supportive tool for sialen-\ndoscopy clinical decision making and patient information \nsupport. Eur Arch Otorhinolaryngol. https:// doi. org/ 10. 1007/  \ns00405- 023- 08104-8\n 3. Saibene AM, Pipolo C, Borloni R et al (2021) ENT and den-\ntist cooperation in the management of odontogenic sinusitis. A \nreview. Acta Otorhinolaryngol Ital 41:S116–S123. https:// doi. org/ \n10. 14639/ 0392- 100x- suppl.1- 41- 2021- 12\n 4. Allevi F, Fadda GL, Rosso C et al (2021) Diagnostic criteria for \nodontogenic sinusitis: a systematic review. Am J Rhinol Allergy \n35:713–721. https:// doi. org/ 10. 1177/ 19458 92420 976766\n 5. Craig JR, Saibene AM, Felisati G (2021) Chronic odontogenic \nrhinosinusitis: optimization of surgical treatment indications. Am \nJ Rhinol Allergy 35:142–143. https:// doi. org/ 10. 1177/ 19458 92420 \n965474\n 6. Craig JR, Poetker DM, Aksoy U et al (2021) Diagnosing odonto-\ngenic sinusitis: an international multidisciplinary consensus state-\nment. Int Forum Allergy Rhinol 11:1235–1248. https:// doi. org/ 10. \n1002/ alr. 22777\n 7. Bulfamante AM, Ferella F, Miller AM et al (2023) Artificial intel-\nligence, machine learning, and deep learning in rhinology: a sys-\ntematic review. Eur Arch Otorhinolaryngol 280:529–542. https:// \ndoi. org/ 10. 1007/ s00405- 022- 07701-3\n 8. Felisati G, Chiapasco M, Lozza P et al (2013) Sinonasal compli-\ncations resulting from dental treatment: outcome-oriented pro -\nposal of classification and surgical protocol. Am J Rhinol Allergy \n27:e101–e106. https:// doi. org/ 10. 2500/ ajra. 2013. 27. 3936\n 9. Liao Z, Wang J, Shi Z et al (2023) Revolutionary potential of Chat-\nGPT in constructing intelligent clinical decision support systems. \nAnn Biomed Eng. https:// doi. org/ 10. 1007/ s10439- 023- 03288-w\n 10. Ali MJ (2023) ChatGPT and lacrimal drainage disorders: perfor -\nmance and scope of improvement. Ophthal Plast Reconstr Surg \n39:221–225. https:// doi. org/ 10. 1097/ iop. 00000 00000 002418\n 11. Strong E, DiGiammarino A, Weng Y et al (2023) Performance of \nChatGPT on free-response, clinical reasoning exams. medRxiv. \nhttps:// doi. org/ 10. 1101/ 2023. 03. 24. 23287 731\n 12. Molteni M, Bulfamante AM, Pipolo C et al (2020) Odontogenic \nsinusitis and sinonasal complications of dental treatments: a \nretrospective case series of 480 patients with critical assessment \nof the current classification. Acta Otorhinolaryngol Ital 40:282–\n289. https:// doi. org/ 10. 14639/ 0392- 100x- n0457\n 13. Saibene AM, Collurà F, Pipolo C et al (2019) Odontogenic rhi-\nnosinusitis and sinonasal complications of dental disease or treat-\nment: prospective validation of a classification and treatment pro-\ntocol. Eur Arch Otorhinolaryngol 276:401–406. https:// doi. org/ 10. \n1007/ s00405- 018- 5220-0\n 14. Craig JR, Cheema AJ, Dunn RT et al (2022) Extrasinus complica-\ntions from odontogenic sinusitis: a systematic review. Otolaryn-\ngol Head Neck Surg 166:623–632. https:// doi. org/ 10. 1177/ 01945 \n99821 10262 68\n 15. Kottlors J, Bratke G, Rauen P et al (2023) Feasibility of differen-\ntial diagnosis based on imaging patterns using a large language \nmodel. Radiology. https:// doi. org/ 10. 1148/ radiol. 231167\n 16. Chen L, Zaharia M, Zou J (2023) How is ChatGPT’s behavior \nchanging over time? ArXiv. https:// doi. org/ 10. 48550/ ARXIV. \n2307. 09009\n 17. Singhal K, Tu T, Gottweis J et al (2023) Towards expert-level \nmedical question answering with large language models. ArXiv. \nhttps:// doi. org/ 10. 48550/ arXiv. 2305. 09617\n 18. Craig JR, Dai X, Bellemore S et al (2023) Inflammatory endotype \nof odontogenic sinusitis. Int Forum Allergy Rhinol 13:998–1006. \nhttps:// doi. org/ 10. 1002/ alr. 23099\n 19. Saibene AM, Vassena C, Pipolo C et al (2016) Odontogenic and \nrhinogenic chronic sinusitis: a modern microbiological compari-\nson. Int Forum Allergy Rhinol 6:41–45. https:// doi. org/ 10. 1002/ \nalr. 21629\n 20. Yassin-Kassab A, Bhargava P, Tibbetts RJ et al (2021) Compari-\nson of bacterial maxillary sinus cultures between odontogenic \nsinusitis and chronic rhinosinusitis. Int Forum Allergy Rhinol \n11:40–47. https:// doi. org/ 10. 1002/ alr. 22627\n 21. Yassin-Kassab A, Peterson EL, Craig JR (2023) Total times \nto treatment completion and clinical outcomes in odontogenic \nsinusitis. Am J Otolaryngol 44:103921. https:// doi. org/ 10. 1016/j. \namjoto. 2023. 103921\n 22. Craig JR, Tataryn RW, Aghaloo TL et al (2020) Management of \nodontogenic sinusitis: multidisciplinary consensus statement. Int \nForum Allergy Rhinol 10:901–912. https:// doi. org/ 10. 1002/ alr. \n22598\n 23. Goyal VK, Spillinger A, Peterson EI et al (2021) Odontogenic \nsinusitis publication trends from 1990 to 2019: a systematic \nreview. Eur Arch Otorhinolaryngol 278:3857–3865. https:// doi.  \norg/ 10. 1007/ s00405- 021- 06688- 725\n 24. Lechien JR, Maniaci A, Gengler I et al (2023) Validity and reli-\nability of an instrument evaluating the performance of intelli-\ngent chatbot: the Artificial Intelligence Performance Instrument \n(AIPI). Eur Arch Otorhinolaryngol. https://  doi. org/ 10. 1007/ \ns00405- 023- 08219-y\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.\n1841European Archives of Oto-Rhino-Laryngology (2024) 281:1835–1841 \nAuthors and Affiliations\nAlberto Maria Saibene1  · Fabiana Allevi2  · Christian Calvo‑Henriquez3  · Antonino Maniaci4  · \nMiguel Mayo‑Yáñez5  · Alberto Paderno6  · Luigi Angelo Vaira7,8  · Giovanni Felisati1  · John R. Craig9 \n * Alberto Maria Saibene \n alberto.saibene@unimi.it\n1 Otolaryngology Unit, Santi Paolo E Carlo Hospital, \nDepartment of Health Sciences, Università Degli Studi Di \nMilano, Milan, Italy\n2 Maxillofacial Surgery Unit, Santi Paolo E Carlo Hospital, \nDepartment of Health Sciences, Università Degli Studi Di \nMilano, Milan, Italy\n3 Service of Otolaryngology, Rhinology Unit, Hospital \nComplex at the University of Santiago de Compostela, \nSantiago de Compostela, A Coruña, Spain\n4 Department of Medical, Surgical Sciences and Advanced \nTechnologies G.F. Ingrassia, University of Catania, Catania, \nItaly\n5 Otorhinolaryngology, Head and Neck Surgery Department, \nComplexo Hospitalario Universitario A Coruña (CHUAC), \nA Coruña, Galicia, Spain\n6 Department of Otorhinolaryngology, Head and Neck \nSurgery, University of Brescia, Brescia, Italy\n7 Maxillofacial Surgery Operative Unit, Department \nof Medicine, Surgery and Pharmacy, University of Sassari, \nSassari, Italy\n8 Biomedical Science PhD School, Biomedical Science \nDepartment, University of Sassari, Sassari, Italy\n9 Department of Otolaryngology-Head and Neck Surgery, \nHenry Ford Health, Detroit, MI, USA",
  "topic": "Multidisciplinary approach",
  "concepts": [
    {
      "name": "Multidisciplinary approach",
      "score": 0.8412331342697144
    },
    {
      "name": "Medicine",
      "score": 0.4749324917793274
    },
    {
      "name": "Otorhinolaryngology",
      "score": 0.4599250257015228
    },
    {
      "name": "Surgery",
      "score": 0.2476530373096466
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Social science",
      "score": 0.0
    }
  ]
}