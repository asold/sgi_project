{
  "title": "Pushing on Personality Detection from Verbal Behavior: A Transformer Meets Text Contours of Psycholinguistic Features",
  "url": "https://openalex.org/W4285220049",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5000106586",
      "name": "Elma Kerz",
      "affiliations": [
        "RWTH Aachen University"
      ]
    },
    {
      "id": "https://openalex.org/A5100748135",
      "name": "Yu Qiao",
      "affiliations": [
        "RWTH Aachen University"
      ]
    },
    {
      "id": "https://openalex.org/A5009033829",
      "name": "Sourabh Zanwar",
      "affiliations": [
        "RWTH Aachen University"
      ]
    },
    {
      "id": "https://openalex.org/A5088884790",
      "name": "Daniel Wiechmann",
      "affiliations": [
        "University of Amsterdam"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2599743206",
    "https://openalex.org/W1589554437",
    "https://openalex.org/W3212903635",
    "https://openalex.org/W2994948478",
    "https://openalex.org/W2981836045",
    "https://openalex.org/W2169683554",
    "https://openalex.org/W1979532929",
    "https://openalex.org/W2151543699",
    "https://openalex.org/W2489406233",
    "https://openalex.org/W3040847388",
    "https://openalex.org/W4250304879",
    "https://openalex.org/W2123442489",
    "https://openalex.org/W4295312788",
    "https://openalex.org/W2423024114",
    "https://openalex.org/W2512885694",
    "https://openalex.org/W3089393278",
    "https://openalex.org/W2153266959",
    "https://openalex.org/W2744863474",
    "https://openalex.org/W2805543418",
    "https://openalex.org/W3094938719",
    "https://openalex.org/W3167985707",
    "https://openalex.org/W2040467972",
    "https://openalex.org/W3015987295",
    "https://openalex.org/W4211257343",
    "https://openalex.org/W2133564696",
    "https://openalex.org/W2968463578",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2810597146",
    "https://openalex.org/W1552217991",
    "https://openalex.org/W3130967929",
    "https://openalex.org/W1496593078",
    "https://openalex.org/W2969145558",
    "https://openalex.org/W2071559616",
    "https://openalex.org/W2798357113",
    "https://openalex.org/W3037696347"
  ],
  "abstract": "Research at the intersection of personality psychology, computer science, and linguistics has recently focused increasingly on modeling and predicting personality from language use. We report two major improvements in predicting personality traits from text data: (1) to our knowledge, the most comprehensive set of theory-based psycholinguistic features and (2) hybrid models that integrate a pre-trained Transformer Language Model BERT and Bidirectional Long Short-Term Memory (BLSTM) networks trained on within-text distributions ('text contours') of psycholinguistic features. We experiment with BLSTM models (with and without Attention) and with two techniques for applying pre-trained language representations from the transformer model - 'feature-based' and 'fine-tuning'. We evaluate the performance of the models we built on two benchmark datasets that target the two dominant theoretical models of personality: the Big Five Essay dataset and the MBTI Kaggle dataset. Our results are encouraging as our models outperform existing work on the same datasets. More specifically, our models achieve improvement in classification accuracy by 2.9 addition, we perform ablation experiments to quantify the impact of different categories of psycholinguistic features in the respective personality prediction models.",
  "full_text": "Proceedings of the 12th Workshop on Computational Approaches to\nSubjectivity, Sentiment & Social Media Analysis, pages 182 - 194\nMay 26, 2022c⃝2022 Association for Computational Linguistics\nPushing on Personality Detection from Verbal Behavior:\nA Transformer Meets Text Contours of Psycholinguistic Features\nElma Kerz\nRWTH-Aachen University\nelma.kerz@ifaar.rwth-aachen.de\nYu Qiao\nRWTH-Aachen University\nyu.qiao@rwth-aachen.de\nSourabh Zanwar\nRWTH-Aachen University\nsourabh.zanwar@rwth-aachen.de\nDaniel Wiechmann\nUniversity of Amsterdam\nd.wiechmann@uva.nl\nAbstract\nResearch at the intersection of personality psy-\nchology, computer science, and linguistics has\nrecently focused increasingly on modeling and\npredicting personality from language use. We\nreport two major improvements in predict-\ning personality traits from text data: (1) to\nour knowledge, the most comprehensive set\nof theory-based psycholinguistic features and\n(2) hybrid models that integrate a pre-trained\nTransformer Language Model BERT and Bidi-\nrectional Long Short-Term Memory (BLSTM)\nnetworks trained on within-text distributions\n(‘text contours’) of psycholinguistic features.\nWe experiment with BLSTM models (with and\nwithout Attention) and with two techniques\nfor applying pre-trained language representa-\ntions from the transformer model - ‘feature-\nbased’ and ‘fine-tuning’. We evaluate the per-\nformance of the models we built on two bench-\nmark datasets that target the two dominant the-\noretical models of personality: the Big Five Es-\nsay dataset (Pennebaker and King, 1999) and\nthe MBTI Kaggle dataset (Li et al., 2018). Our\nresults are encouraging as our models outper-\nform existing work on the same datasets. More\nspecifically, our models achieve improvement\nin classification accuracy by 2.9% on the Essay\ndataset and 8.28% on the Kaggle MBTI dataset.\nIn addition, we perform ablation experiments\nto quantify the impact of different categories\nof psycholinguistic features in the respective\npersonality prediction models.\n1 Introduction\nPersonality is broadly defined as the combina-\ntion of a person’s behavior, emotions, motivation,\nand characteristics of thought patterns (Corr and\nMatthews, 2020). Our personality has a major\nimpact on our lives, influencing our life choices,\nwell-being, health, and preferences and desires\n(Ozer and Benet-Martinez, 2006). Specifically,\npersonality has been repeatedly linked to individ-\nual (e.g., happiness, physical and mental health),\ninterpersonal (e.g., quality of relationships with\npeers, family, and romantic partners), and social-\ninstitutional outcomes (e.g., career choice, satisfac-\ntion and achievement, social engagement, political\nideology) (Soto, 2019).\nWhile there are several models of human person-\nality, the predominant and widely accepted model\nis the Big Five or Five Factor Model (McCrae\nand John, 1992; McCrae, 2009). In this model,\npersonality traits are divided into five factors: (1)\nExtraversion (assertive, energetic, outgoing, etc.),\n(2) Agreeableness (appreciative, generous, com-\npassionate, etc.), (3) Conscientiousness (efficient,\norganized, responsible, etc.), (4) Neuroticism (anx-\nious, self-pitying, worried, etc.), and (5) Openness\n(curious, empathetic, imaginative, etc.). These five\npersonality traits are commonly assessed by ques-\ntionnaires in which a person reflects on his or her\ntypical patterns of thinking and behavior, such as\nthe NEO Five Factor Inventory (Costa and Mc-\nCrae, 1992), and the Big-Five Inventory (John et al.,\n1991); (see Matthews et al., 2009, for a compre-\nhensive overview). The Myers–Briggs Type Indi-\ncator (MBTI) is another widely administered ques-\ntionnaire, in particular in applied settings (Meyers\net al., 1990). In contrast to the Big Five person-\nality taxonomy, which conceptualizes human per-\nsonality as latent trait scores, the MBTI model de-\nscribes personality in terms of 16 types that result\nfrom combining binary categories into four dimen-\nsions: (a) Extraversion/Introversion (E/I) - prefer-\nence for how people direct and receive their energy,\nbased on the external or internal world, (b) Sens-\ning/Intuition (S/N) - preference for how people take\nin information, through the five senses or through\ninterpretation and meanings, (c) Thinking/Feeling\n(T/F) - preference for how people make decisions,\nrelying on logic or emotion over people and partic-\n182\nular circumstances, and (d) Judgment/Perception\n(J/P) - how people deal with the world, by ordering\nit or remaining open to new information.\nGiven its central importance in capturing the\nessential aspects of human life, increasing atten-\ntion is being paid to the development of models\nthat can leverage behavioral data to automatically\npredict personality. Data obtained from verbal be-\nhavior is one of the key types of such data. Even\nin the early years of psychology, a person’s use of\nlanguage was seen as a distillation of his or her\nunderlying drives, emotions, and thought patterns\n(see Tausczik and Pennebaker, 2010; Boyd and Pen-\nnebaker, 2017, for historical overviews). Early ap-\nproaches to automatic personality prediction (APP)\n– also referred to as automatic personality predic-\ntion or recognition – from textual data have relied\non machine learning models based on psycholin-\nguistic features, whereas more recent approaches\nto APP typically draw on deep learning techniques\nthat use pre-trained word embeddings (see Vincia-\nrelli and Mohammadi, 2014, for an overview of the\nformer) (see Mehta et al., 2020b, for an overview\nof deep learning-based APP).\nIn this paper, we make a valuable contribution\nto this dynamic area of APP research by presenting\ntwo important improvements in predicting person-\nality traits from textual data: (1) to our knowl-\nedge, the most comprehensive set of psycholin-\nguistic features and (2) hybrid models that inte-\ngrate a pre-trained Transformer Language Model\nBERT and Bidirectional Long Short-Term Mem-\nory (BLSTM) networks trained on in-text distribu-\ntions (’text contours’) of psycholinguistic features.\nSince our goal is to demonstrate the utility of our\nmodeling approach, we conduct our experiments\non two widely used benchmark datasets: the Big\nFive Essay dataset (Pennebaker and King, 1999)\nand the MBTI-Kaggle dataset (Li et al., 2018),\nwhich align with the dominant personality mod-\nels described above. The remainder of this paper\nis organized as follows: In Section 2, we briefly\nreview recent related work on these two benchmark\ndatasets. Then, in Section 3, we present the two\nbenchmark datasets and the extraction of psycholin-\nguistic features using automated text analysis based\non a sliding window approach. In Section 4, we\ndescribe our modeling approach, and in Section\n5, we present and discuss the results. Finally, we\nconclude with possible directions for future work\nin Section 6.\n2 Related work\nMajumder et al. (2017) used a convolutional neu-\nral network (CNN) feature extractor in which sen-\ntences were fed to convolution filters to obtain n-\ngram feature vectors. Each individual text of the\nBig Five Essay dataset was represented by aggre-\ngating the vectors of its sentences and the obtained\nvectors were concatenated with psycholinguistic\n(Mairesse) features (Mairesse et al., 2007). For\nclassification, they fed the resulting document vec-\ntor to a fully connected neural network with one\nhidden layer. Using this method, they were able\nto achieve an average classification accuracy of\n58% for the Big Five personality traits on the Es-\nsays dataset. Kazameini et al. (2020) were the first\nto use a Transformer-Based Language model to\nextract contextualized word embeddings. Specifi-\ncally, they built a Bagged-SVM classifier fed with\ncontextualized embeddings extracted from BERT,\na pre-trained language model with a Bidirectional\nEncoder from Transformers (Devlin et al., 2018).\nTheir model outperformed the CNN-based model\nproposed by the Majumder et al. (2017) model by\n1.04%. Amirhosseini and Kazemian (2020) used a\nGradient Boosting Model (GBM) based on Term\nFrequency–Inverse-Document-Frequency features\n(TF-IDF) to predict personality dimensions in the\nKaggle MBTI dataset. Their modeling approach\nachieved an average classification accuracy across\nall dimensions of 76.1%. Using both the Big Five\nEssay dataset and the Myers-Briggs’ type indicator\nKaggle Dataset, Mehta et al. (2020a) proposed the\nintegration of deep learning models and psycholin-\nguistic features with language model embeddings\nfor APP. They extracted a total of 123 psycholin-\nguistic features, including the Mairesse features set\n(Mairesse et al., 2007), SenticNet (Cambria et al.,\n2010), NRC-Emotion Lexicon (Mohammad and\nTurney, 2013), and NRC-V AD Lexicon (Moham-\nmad, 2018). Language model features were ex-\ntracted using BERT. Their experiments compared\nthe performance of BERT-base and BERT-large\nin synergy with SVM or Multi-layer Perceptron\n(MLP) classifiers. BERT-base + MLP yielded an\naverage score of 60.6 on the Essay dataset, while\nBERTlarge + MLP yielded an average score of\n77.1 on the Kaggle dataset. The approach taken\nin Mehta et al. (2020a) outperformed the previ-\nously best-performing model by Amirhosseini and\nKazemian (2020) by 1%. Zooming on classifi-\ncation accuracy for specific personality traits, the\n183\nmodels in Mehta et al. (2020a) achieved the high-\nest performance on two of the Big Five personality\ntraits in the Essays dataset (openness, accuracy =\n64.6%, and conscientiousness, accuracy = 59.2%)\nand on three of the four MBTI dimensions in the\nKaggle MBTI dataset (Intuitive/Sensing (N/S), ac-\ncuracy = 86.6%, Thinking/Feeling (T/F), accu-\nracy = 76.1% and Perception/Judging (P/J), accu-\nracy = 67.2%). The highest performance on the\nIntroversion/Extraversion (I/E) MBTI dimension\n(79%) was obtained by the ‘GBM + TFIDF’ model\nreported in Amirhosseini and Kazemian (2020).\nThe highest performance on the three remaining\nBig Five dimensions was achieved recently by\nRamezani et al. (2021), which used an ensemble\nmodeling approach (stacking) to combine linguis-\ntic and ontology-based features with deep learning-\nbased methods based on a hierarchical attention\nnetwork as a meta-model. Although the overall\nperformance of SOTA on the Essay dataset was\nnot superior - mainly due to relatively poor perfor-\nmance on the Openness trait (accuracy = 56.3%),\nthis work has demonstrated the utility of model\nstacking as an effective way to boost the prediction\nof personality traits. For a performance overview\nof the models reviewed here for different data sets\nand personality dimensions, see Table 1 in Section\n4.\n3 Method\n3.1 Datasets\nWe conducted our experiments with two widely\nused personality benchmark datasets: (1) The Es-\nsays Dataset (Pennebaker and King, 1999) and (2)\nKaggle MBTI Dataset (Li et al., 2018). (1) Essays:\nThis stream-of-consciousness dataset consists of\n2468 essays written by students and annotated with\nthe binary labels of the Big Five personality traits,\nwhich were obtained through a standardized self-\nreport questionnaire. The average text length is\n672 words and the total size of the dataset is ap-\nproximately 1.6 million words. One of the reasons\nwhy Essays is an established benchmark dataset is\nthe relatively large amount of continuous language\nuse and the fact that the personality traits were ob-\ntained using a validated instrument. (2) Kaggle\nMBTI: This dataset was collected through the Per-\nsonalityCafe forum1 and thus provides a diverse\nsample of people interacting in an informal online\nsocial environment. It consists of samples of social\n1https://www.personalitycafe.com/\nmedia interactions from 8675 users, all of whom\nindicated their MBTI type. The average text length\nis 1,288 words. The total size of the entire dataset\nis approximately 11.2 million words.\n3.2 Measurement of text contours of\npsycholinguistic features\nThe texts from both datasets (the Big Five Essay\ndataset and the MBTI Kaggle dataset) were auto-\nmatically analyzed using an automated text anal-\nysis (ATA) system that employs a sliding window\ntechnique to compute sentence-level measurements.\nThese measurements capture the within-text dis-\ntributions of scores for a given psycholinguistic\nfeature, referred to here as ‘text contours’ (for re-\ncent applications of the ATA system in the context\nof text classification, see (Kerz et al., 2020; Qiao\net al., 2021a,b). We extracted a set of 437 theory-\nbased psycholinguistic features that can be binned\ninto four groups: (1) features of morpho-syntactic\ncomplexity (N=19), (2) features of lexical richness,\ndiversity and sophistication (N=77), (3) readability\nfeatures (N=14), and (4) lexicon features designed\nto detect sentiment, emotion and/or affect (N=326).\nTokenization, sentence splitting, part-of-speech tag-\nging, lemmatization and syntactic PCFG parsing\nwere performed using Stanford CoreNLP (Man-\nning et al., 2014). The group of morpho-syntactic\ncomplexity features includes (i) surface features\nrelated to the length of production units, such as\nthe average length of clauses and sentences, (ii)\nfeatures of the type and frequency of embeddings,\nsuch as number of dependent clauses per T-Unit or\nverb phrases per sentence and (iii) the frequency\nof particular structure types, such as the number\nof complex nominals per clause. This group also\nincludes (iv) information-theoretic features of mor-\nphological and syntactic complexity based on the\nDeflate algorithm (Deutsch, 1996). The group of\nlexical richness, diversity and sophistication fea-\ntures includes six different subtypes: (i) lexical\ndensity features, such as the ratio of the number of\nlexical (as opposed to grammatical) words to the\ntotal number of words in a text, (ii) lexical vari-\nation, i.e. the range of vocabulary as manifested\nin language use, captured by text-size corrected\ntype-token ratio, (iii) lexical sophistication, i.e. the\nproportion of relatively unusual or advanced words\nin a text, such as the number of words from the\nNew General Service List (Browne et al., 2013),\n(iv) psycholinguistic norms of words, such as the\n184\naverage age of acquisition of the word (Kuperman\net al., 2012) and two recently introduced types of\nfeatures: (v) word prevalence features that cap-\nture the number of people who know the word\n(Brysbaert et al., 2019; Johns et al., 2020) and (vi)\nregister-based n-gram frequency features that take\ninto account both frequency rank and the number of\nword n-grams (n∈[1,5]). The latter were derived\nfrom the five register subcomponents of the Con-\ntemporary Corpus of American English (COCA,\n560 million words, Davies, 2008): spoken, mag-\nazine, fiction, news and academic language (see\nKerz et al., 2020, for details see e.g.). The group\nof readability features combines a word famil-\niarity variable defined by a prespecified vocabu-\nlary resource to estimate semantic difficulty along\nwith a syntactic variable, such as average sentence\nlength. Examples of these measures include the\nFry index (Fry, 1968) or the SMOG (McLaugh-\nlin, 1969). The group of lexicon-based senti-\nment/emotion/affect features (SentiEmo) was de-\nrived from a total of ten lexicons that have been\nsuccessfully used in personality detection, emotion\nrecognition and sentiment analysis research: (1)\nThe Affective Norms for English Words (ANEW)\n(Bradley and Lang, 1999), (2) ANEW-Emo lexi-\ncons (Stevenson et al., 2007), (3) DepecheMood++\n(Araque et al., 2019), (4) The Geneva Affect Label\nCoder (GALC) (Scherer, 2005), (5) The General\nInquirer (Stone et al., 1966), (6) The LIWC dic-\ntionary (Pennebaker et al., 2001), (7) The NRC\nWord-Emotion Association Lexicon (Mohammad\nand Turney, 2013), (8) The NRC Valence, Arousal,\nand Dominance (NRC-V AD) lexicon (Mohammad,\n2018), (9) SenticNet (Cambria et al., 2010), and\n(10) the Sentiment140 lexicon (Mohammad et al.,\n2013). The feature value for each subcategory in a\ngiven lexicon is the mean value of all rated/scored\nwords in a given sentence. The informational gain\nof ‘text contours’ compared to text-averages is il-\nlustrated in Figure 1. The Figure shows the distri-\nbution of z-standardized values of three selected\nfeatures for a randomly selected text from the Es-\nsay dataset. The red line represents the average\nfeature value of the text. As can be seen from the\ngraphs, all feature values fluctuate within the text,\nwith high values for one feature often offset by\nlower values for another. The contour-based clas-\nsifiers, discussed in more detail in Section 3, can\ntake advantage of this high-resolution assessment\nof psycholinguistic features.\n4 Modeling approach\nOur models are constructed from three components:\n(a) a ‘contour encoder’ that converts a sequence of\npsycholinguistic features into a hidden represen-\ntation vector, (b) a pre-trained transformer-based\nlanguage model, BERT, that converts a sequence\nof tokens into a hidden representation vector, and\n(c) a classifier that outputs the probability of a per-\nsonality feature given the hidden representation of\nthe sample. We conduct experiments with three\ntypes of personality prediction models: (1) con-\ntour encoder + classifier, (2) hybrid models that\ncombine the contour encoder with a transformer-\nbased language model + classifier, and (3) a stack-\ning model that combines ten repetitions of the best\nperforming model. As for the contour encoder, we\nexperiment with BLSTM and BLSTM with atten-\ntion models. Attention-based models have been\nsuccessfully used in a variety of tasks, including\nmachine translation (Bahdanau et al., 2014), speech\nrecognition (Huang and Narayanan, 2016) and re-\nlation classification (Zhou et al., 2016). In the con-\ntext of personality classification, learning a scoring\nfunction gives sentence weighting to the attention\nmechanism and allows a model to pay more atten-\ntion to the most influential sentences in a text for a\npersonality trait. As for the hybrid models, we ex-\nperiment with different strategies for applying the\npre-trained language model - ‘feature-based’ and\n‘fine-tuning’: In the feature-based approach, we\nfreeze model weights during training and use the\npre-trained contextualized word embeddings from\nBERT. In the ‘fine-tuning’ approach, we unfreeze\nall 12 layers and fine-tune towards the personality\ndetection task (see Devlin et al., 2018).\nAll models are implemented using PyTorch\n(Paszke et al., 2019). Unless specifically stated\notherwise, we use binary cross entropy as our loss\nfunction, ’AdamW’ as optimizer, a fixed learning\nrate of 8×10−4 and dropout= 0.1, l2 = 1×10−4\nas the regularization. The optimal network struc-\ntures and values of hyperparameters were found\nby grid-search. The performance of the models is\nevaluated by 10-fold cross-validation (ten repeti-\ntions) to counter variability due to initialization of\nthe weights. We report the results of the best per-\nforming models in comparison to the performance\nof the APP systems presented in Section 2 Table 1.\n4.1 Components\nContour Encoder: The contour encoder,\nEncoderPSY LING(X), transforms a sequence of\n185\n−2\n0\n2\n0 10 20 30 40\nSentence # in text\nScore\nFeature ComplexNominalsPerClause GunningFog Sophistication.BNC\nFigure 1: Text contours for three selected features of first 40 sentences of a randomly selected text from the Essays\ndataset (ID: 2004 499).\npsycholinguistic features X = (x1,x2,...,x n)\nto a hidden psycholinguistic representation vector\nPPSY LING of a given text. Here, xi is a 436 di-\nmensional vector for theith sentence obtained from\nthe APA system described in Section 3.2. In this\npaper, two architectures of contour encoder are ap-\nplied: BLSTM and BLSTM with attention (ATTN).\nThe BLSTM contour encoder is a L-layer BLSTM\nwith number of hidden states of dh. The hidden\nrepresentation from this model is a do = 2dh\ndimensional vector, which is a concatenation of\nthe last hidden states of the last layer in forward\n(− →hn) and backward direction ( ← −h1). Specifically,\nX ↦→EncoderBLSTM (X) =P:\n[− →H,← −H] =BLSTM (X)\nP = [− →hnT |← −h1T ]T\nwhere [·|·] is concatenation operator, − →H =\n(− →h1,− →h2,..., − →hn) and ← −H = (← −h1,← −h2,..., ← −hn)\nare BLSTM model’s last layer hidden states in the\nforward and backward direction.\nThe ATTN contour encoder model was con-\nstructed as follows: Given a input sequence X,\na sequence of weights will be computed with the\nhelp of a BLSTM model. Then the hidden represen-\ntation of a given text can be obtained by computing\nthe weighted sum of (a) concatenated hidden vec-\ntors from the last layer of the BLSTM model in\nforward and backward direction (b) feature vectors\nin X. We also experimented with (c) computing\nweights for each individual dimension of xi and\nthen taking weighted sum of X by applying this\nweights. Our experiments shows, that the approach\n(c) works best for both dataset. So in this paper, we\ndefine X ↦→EncoderATTN (X)=P:\nH = BLSTM (X)\nM = Tanh(WattH+ batt)\nααα= Softmax(M)\nV = ∑n\ni=1 αiαiαi ⊙xixixi\nP = Tanh(WpoolV + bpool)\nwhere Watt ∈R436×do ,batt ∈R436. H and do is\ndefined as in BLSTM encoder description. Softmax\nis defined as: αij = emij\n∑n\nk=1 emkj\nBERT Language Model: We use a pre-trained\nBERT transformer model, ‘bert-base-uncased’,\nfrom Huggingface’s transformers library (Wolf\net al., 2019). The model consists of 12 transformer\nlayers with a hidden size of 768 and 12 attention\nheads. Texts are tokenized using BERT’s BPE tok-\nenizer. We use as input to BERT language model\nthe initial 512 tokens T = (t1,t2,...,t m) of a\ngiven text, i.e. up to 510 word tokens plus the [cls]\ntoken at the beginning and the [sep] token at the\nend of a given text). Assuming the output of the\nl layer of BERT is H(l) = (h(1)\n1 ,h(l)\n2 ,...,h (l)\nn ),\nthen a hidden vector is computed by either (a) the\noutput for the [cls]-token, i.e. i.e., V = h(l)\n1 or\nby (b) averaging the output at the position of the\nactual tokenized words, i.e., V = 1\nm−2\n∑m−2\ni=i h(l)\ni .\nExperiments with both approaches for l ∈[1,12]\nrevealed that that (a) the latter approach consis-\ntently works better than the former and (b) that\nl = 11works best for the Essays dataset, wheras\nl = 12works best for the MBTI dataset. So we\ndefine X ↦→EncoderBERT (T) =P\n186\nH(l) = BERT(T)\nV = 1\nm−2\n∑m−2\ni=i h(l)\ni\nP = Tanh(WpoolV + bpool)\nClassifier: We use a multi-layer feed-forward\nneural network as our classifier component. The\ninput to the classifier has a dimension correspond-\ning to the underlying encoder’s output dimension.\nWe use PReLU as the activation function. Batch\nnormalization was applied between layers of the\nclassifier. All hidden layers share a same hidden\nsize.\n4.2 Models\nWe first construct models based solely on psy-\ncholinguistic features. These models (1) serve as\ninterpretable baselines for the hybrid prediction\nmodels and (2) allow us to determine feature im-\nportance of individual features groups in predict-\ning personality traits. To fully utilize the infor-\nmation provided by the contour-based measure-\nment of text features, the models rely on BLSTM\nor BLSTM with attention architecture, i.e. at\nposition of EncoderPSY LING, EncoderBLSTM or\nEncoderATTN is applied.\nP = EncoderPSY LING(X)\ny= Classifier(P)\nEncoderBLSTM has 3 layers with 256 hidden\nstates. We applied a learning rate of 0.001 dur-\ning training of this model. The BLSTM in\nEncoderATTN has 3 layers with 512 hidden states.\nThe classifier has 3 layers with hidden size of 512.\nOur hybrid architecture combines text contours\nof psycholinguistic features with Transformer-\nbased language models using a late-fusion method\nby concatenating the hidden representations from\nthe psycholinguistic contour encoder and BERT,\nspecifically\nPPSY LING = EncoderPSY LING(X)\nPBERT = EncoderBERT (T)\nP = [PT\nPSY LING|PT\nBERT ]T\ny= Classifier(P)\nAt the position of EncoderPSY LING,\nEncoderBLSTM can be used, which has 3\nlayers with hidden states of 256, or EncoderATTN ,\nof which BLSTM also has 3 layers with hidden\nstates of 256 with dropout= 0.2. During training,\nparameters of BERT has a fixed learning rate of\n2 ×10−5 while learning rate of 8 ×10−5 is applied\nto other parameters. The classifier has 3 layers\nwith hidden size of 512.\nThe final model used in our experiments em-\nployed a stacking approach to ensemble our best\nperforming models (Wolpert, 1992), which has\nbeen shown to effectively increase the accuracy\nof the ensembled individual models. Specifi-\ncally, we employed model stacking to combine\nBERT+ATTN-PSYLING (FT) model instances for\nboth dataset.\nThe training procedure consists of two stages: In\nstage one, we take the model prediction on the dev-\nfold of each model trained on the train-fold of a\nk-fold CV . These predictions are then concatenated\nand constitute the one dimension out of 10 of the in-\nput data in a subsequent stage (stage 2). We did the\nsame for all 10 iterations. The final predictions of\nthe model are derived from another logistic regres-\nsion model trained on the concatenated prediction\nvectors from stage 1 (10-fold CV).\n4.3 Feature importance\nTo assess the relative importance of the feature\ngroups, we employed Submodular Pick Lime (SP-\nLIME; Ribeiro et al. (2016)). SPLIME is a method\nto construct a global explanation of a model by\naggregating the weights of linear models, that lo-\ncally approximate the original model. To this end,\nwe first constructed local explanations using LIME.\nAnalogous to super-pixels for images, we catego-\nrized our features into four groups – lexical rich-\nness, morphosyntactic complexity, readability, sen-\ntiment/emotion (see section 3.2). We used binary\nvectors z∈{0,1}d to denote the absence and pres-\nence of feature groups in the perturbed data sam-\nples, where dis the number of feature groups. Here,\n‘absent’ means that all values of the features in the\nfeature group are set to 0, and ‘present’ means that\ntheir values are retained. For simplicity, a linear re-\ngression model was chosen as the local explanatory\nmodel. An exponential kernel function with Ham-\nming distance and kernel width σ = 0.75\n√\ndwas\nused to assign different weights to each perturbed\ndata sample. After constructing their local explana-\ntion for each data sample in the original dataset, the\nmatrix W ∈Rn×d was obtained, where nis the\nnumber of data samples in the original dataset and\nWij is the jth coefficient of the fitted linear regres-\nsion model to explain data sample xi. The global\n187\nEssays MBTI Kaggle\nO C E A N Avg I/E N/S T/F P/J Avg\nMajumder et al. (2018) 61.1 56.7 58.1 56.7 57.3 58 - - - - -\nKazameini et al (2020) 62.1 57.8 59.3 56.5 59.4 59 - - - - -\nAmirhosseini & Kazemian (2020) - - - - - - 79 86 74.2 65.4 76.1\nMehta et al (2020):\nPsycholinguistic + MLP 60.4 57.3 56.9 57 59.8 58.3 77.6 86.3 72 61.9 74.5\nBERT-base + MLP 64.6 59.2 60 58.8 60.5 60.6 78.3 86.4 74.4 64.4 75.9\nAll features (base) + MLP 61.1 57.4 57.9 58.6 60.5 59.1 78.4 86.6 75.9 64.4 76.3\nBERT-large + MLP 63.4 58.9 59.2 58.3 58.9 59.7 78.8 86.3 76.1 67.2 77.1\nRamezani et al. (2021) 56.30 59.18 64.25 60.31 61.14 60.24 - - - - -\nPsycholinguistic models (ours)\nBLSTM-PSYLING 61.69 59.22 58.12 56.87 57.52 58.68 77.29 86.31 72.91 61.01 74.38\nATTN-PSYLING 63.15 59.79 59.18 58.29 59.79 60.04 77.29 86.19 73.97 63.69 75.29\nHybrid models (ours)\nBERT+BLSTM-PSYLING (FB) 64.25 60.80 60.92 59.26 60.48 61.14 78.39 86.58 74.42 64.17 75.89\nBERT+ATTN-PSYLING (FB) 64.78 61.13 60.44 59.30 60.68 61.27 78.82 86.78 76.62 65.78 77.00\nBERT+BLSTM-PSYLING (FT) 65.55 60.72 60.72 60.52 62.14 61.93 85.78 90.86 83.79 79.79 85.06\nBERT+ATTN-PSYLING (FT) 66.23 60.60 61.61 61.05 61.65 62.28 86.25 90.96 84.66 79.65 85.38\nBERT+PSYLING Ensemble 71.95 61.38 63.01 60.16 60.98 63.50 85.47 92.27 85.70 82.58 86.51\nTable 1: Performance comparison (classification accuracy) of our models (bottom) with previous state-of-the-art-\nmodels (top). Best performance indicated in bold.\nimportance score of the SP-LIME for feature jcan\nthen be derived by: Ij =\n√∑n\ni=1 |Wij|\n5 Results and Discussion\nAn overview of the results of our models in com-\nparison to those reported in the previous studies\nreviewed above is presented in Table 1. As Table 1\nshows, we achieve state-of-the-art (SOTA) results\non both benchmark personality datasets: On the\nBig Five Essay dataset, our best-performing model\nachieves a classification accuracy of 63.5%, which\ncorresponds to an increase of 2.9% over the pre-\nvious SOTA. On the MBTI Kaggle dataset, our\nbest model improved the classification accuracy of\nSOTA by 8.28%. On both datasets the highest clas-\nsification accuracy was achieved by the ensemble\nmodel, which combined ten iterations of a hybrid\nmodel integrating a fine-tuned BERT model with\nan attention-based BLSTM model trained on text\ncontours (see BERT+PSYLING Ensemble in Table\n1). Our models achieve the highest performance\non four of the Big Five - all except Extraversion -\nand on all four MBTI dimensions, with the largest\nincrease in performance for the Big Five on the\nOpenness dimension (+7.35%) and for the MBTI\non the T/F dimension (+9.6%). Comparing the\naccuracy for each personality trait from Table 1\nfor the hybrid models trained with the ”feature-\nbased” strategy (denoted by ”FB”) with the cor-\nresponding value for the models trained with the\n”fine-tuning” strategy (denoted by ”FT”), we find\nthat the accuracy of all traits improved when each\npre-trained model was fine-tuned on the data set.\nComparing the accuracy for each personality trait\nfor the models trained with an attention mecha-\nnism (denoted by ‘ATTN’) to the corresponding\nvalue for the models trained without this mecha-\nnism (denoted by ‘BLSTM’), we find that accuracy\non all dimensions except the MBTI N/S improved\nwhen an attention mechanism was used. Our re-\nsults also show that approaches grounded in inter-\npretable features can achieve competitive perfor-\nmance with Transformer-based approaches: Our\nbest-performing model trained solely on psycholin-\nguistic features, the attention-based BLSTM model\n(ATT-PSYLING), achieved an average classifica-\ntion accuracy of 60.04%, approaching the previ-\nous SOTA model, BERT-base + MLP Mehta et al.\n(2020a), by only 0.54%. This is a promising find-\ning given the need for more interpretable person-\nality prediction models that can provide valuable\ninsights into key psycholinguistic features to drive\npersonality prediction and advance personality psy-\nchology research. See e.g. Rudin (2019) for more\ngeneral calls for using white-box models to solve\npractical problems, particularly in the context of\n188\nO C E A N\nGroup I Group I Group I Group I Group I\nSentiEmo 18.49 SentiEmo 21.36 SentiEmo 16.39 SentiEmo 9.28 SentiEmo 16.62\nlexical 12.90 lexical 14.48 lexical 10.93 lexical 7.52 lexical 10.23\nreadability 9.57 readability 9.57 morph.syn 9.17 morph.syn 6.23 morph.syn 8.11\nmorph.syn 7.08 morph.syn 8.91 readability 7.51 readability 4.21 readability 7.06\nI/E N/S T/F P/J\nGroup I Group I Group I Group I\nSentiEmo 33.73 SentiEmo 21.32 SentiEmo 45.06 SentiEmo 24.97\nlexical 29.94 lexical 14.25 lexical 24.64 readability 17.21\nmorph.syn 20.65 readability 12.55 morph.syn 20.31 morph.syn 16.02\nreadability 18.33 morph.syn 10.40 readability 18.76 lexical 14.48\nTable 2: Results of the feature ablation for Big Five Essays datset (top) and Kaggle MBTI dataset (bottom): Feature\nimportance (Model: ATTN-PSYLING) macro-averaged across 100 model instances. (10 ×10-fold CV).\ncritical industries such as healthcare, criminal jus-\ntice, and news. This is due to the fact that hu-\nman experts in a given application domain require\nboth accurate and understandable models (Loyola-\nGonzalez, 2019).\nIn what follows, we present the results of the\nablation experiments. Feature group importance\nwas quantified using SP-LIME on the best per-\nforming model trained only on text contours of\npsycholinguistic features, the ATTN-PSYLING\nmodel. The results of the feature ablation exper-\niment are presented in Table 2. The table shows\nthat the prediction of personality traits was influ-\nenced by all four feature groups (all I > 4.21).\nOverall, personality traits were best predicted by\nthe sentiment/emotion/affect (SentiEmo) feature\ngroup. The lexical richness, diversity and sophis-\ntication group consistently ranked second on all\ntraits except the P/J MBTI dimension. This result\nindicates that in addition to words associated with\naffective-emotional categories, personality traits\nare also related to more general aspects of vocabu-\nlary. Morphosyntactic complexity and readability\nplay a minor role but still achieve high I-scores\ncompared to the highest scoring group in predict-\ning Extraversion, Neuroticism, and Agreeableness\n(ratio: I(group j) / I(SentEmo) > 0.45). Finally,\nzooming in on the specific interactions between\npsycholinguistic cues and personality traits, we cal-\nculated the difference between the average feature\nscores of text samples with different labels for each\npersonality trait. Visualizations of the most im-\nportant psycholinguistic features that influence the\nprediction of personality traits are shown in Figures\n4 and in the Appendix. Some interesting patterns\nemerged: For example, texts produced by extro-\nverts tend to (a) have less complex morphosyn-\ntax than those by introverts (as indicated by the\nlower scores of the information-theoretic complex-\nity measures), (b) contain a greater proportion of\npositive words, and (c) have a higher proportion of\nfrequently used n-grams from the spoken language,\nnews, and magazine registers. The language use\nof individuals scoring high on Neuroticism showed\n(a) a higher proportion of self-referencing words,\n(b) higher proportions of words related to sadness,\nanxiety and disappointment, but also (c) a higher\nproportion of longer n-grams from the fiction regis-\nter. Highly conscientious individuals showed (a) a\nhigher proportion of words with high prevalence,\ni.e. words that are known by a larger percentage\nof the population, (b) more words associated with\naffiliation (ally, friend) and (c) a higher proportions\nof frequently used n-grams from the academic reg-\nister. These results replicate and extend previous\nfindings reported in the literature (for overviews\nsee, e.g., Mairesse et al., 2007; Park et al., 2015;\nBoyd and Schwartz, 2021).\n6 Conclusion\nDue to its central importance in capturing the es-\nsential aspects of human life, increasing attention is\nbeing paid to the modeling and predicting person-\nality traits. In this work, we made valuable contri-\nbutions to advance the state of the art in automatic\nprediction of personality traits from verbal behav-\nior. We demonstrated that models trained with a\ncomprehensive set of theory-based psycholinguis-\ntic features can compete with a Transformer-based\nmodel when their within-text distribution is taken\n189\ninto account. Moreover, we showed that hybrid\nmodels incorporating such features can improve the\nperformance of pre-trained Transformer language\nmodels, even when the latter is based on a larger\nmodel (BERT-large). We also showed that differ-\nent techniques for applying pre-trained language\nrepresentations from the Transformer model have\nan impact on model performance. Our ablation ex-\nperiments have yielded interesting insights into the\ninterplay between theory-based psycholinguistic\nfeatures and personality traits. Here, we decided\nto focus on the two most widely used benchmark\ndatasets. In our future work, we intend to con-\nduct experiments with more recent, larger person-\nality datasets such as PANDORA (Gjurkovic et al.,\n2020). Since this dataset also includes metadata\n(gender, age, and location/region), it would be in-\nteresting to see how they contribute to modeling\nand predicting personality traits from language use.\nReferences\nMohammad Hossein Amirhosseini and Hassan\nKazemian. 2020. Machine learning approach to per-\nsonality type prediction based on the myers–briggs\ntype indicator ®. Multimodal Technologies and\nInteraction, 4(1):9.\nOscar Araque, Lorenzo Gatti, Jacopo Staiano, and\nMarco Guerini. 2019. Depechemood++: a bilingual\nemotion lexicon built through simple yet powerful\ntechniques. IEEE transactions on affective comput-\ning.\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-\ngio. 2014. Neural machine translation by jointly\nlearning to align and translate. arXiv preprint\narXiv:1409.0473.\nRyan L Boyd and James W Pennebaker. 2017.\nLanguage-based personality: a new approach to per-\nsonality in a digital world. Current opinion in behav-\nioral sciences, 18:63–68.\nRyan L Boyd and H Andrew Schwartz. 2021. Natu-\nral language analysis and the psychology of verbal\nbehavior: The past, present, and future states of the\nfield. Journal of Language and Social Psychology,\n40(1):21–41.\nMargaret M Bradley and Peter J Lang. 1999. Affective\nnorms for english words (anew): Instruction manual\nand affective ratings. Technical report, Technical\nreport C-1, the center for research in psychophysiol-\nogy . . . .\nCharles Browne et al. 2013. The new general service\nlist: Celebrating 60 years of vocabulary learning. The\nLanguage Teacher, 37(4):13–16.\nMarc Brysbaert, Paweł Mandera, Samantha F Mc-\nCormick, and Emmanuel Keuleers. 2019. Word\nprevalence norms for 62,000 english lemmas. Be-\nhavior research methods, 51(2):467–479.\nErik Cambria, Robyn Speer, Catherine Havasi, and\nAmir Hussain. 2010. Senticnet: A publicly avail-\nable semantic resource for opinion mining. In 2010\nAAAI fall symposium series.\nPhilip J Corr and Gerald Matthews. 2020. The Cam-\nbridge handbook of personality psychology . Cam-\nbridge University Press.\nPaul T Costa and Robert R McCrae. 1992. Neo person-\nality inventory-revised (NEO PI-R). Psychological\nAssessment Resources Odessa, FL.\nMark Davies. 2008. The Corpus of Contemporary\nAmerican English (COCA): 560 million words, 1990-\npresent.\nPeter Deutsch. 1996. Rfc1951: Deflate compressed data\nformat specification version 1.3.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nEdward Fry. 1968. A readability formula that saves\ntime. Journal of reading, 11(7):513–578.\nMatej Gjurkovic, Mladen Karan, Iva Vukojevic, Mi-\nhaela Bosnjak, and Jan Snajder. 2020. PANDORA\ntalks: Personality and demographics on reddit.\nCoRR, abs/2004.04460.\nChe-Wei Huang and Shrikanth S Narayanan. 2016. At-\ntention assisted discovery of sub-utterance structure\nin speech emotion recognition. In Interspeech, pages\n1387–1391.\nOliver P John, Eileen M Donahue, and Robert L Kentle.\n1991. Big five inventory. Journal of Personality and\nSocial Psychology.\nBrendan T Johns, Melody Dye, and Michael N Jones.\n2020. Estimating the prevalence and diversity of\nwords in written language. Quarterly Journal of\nExperimental Psychology, 73(6):841–855.\nAmirmohammad Kazameini, Samin Fatehi, Yash Mehta,\nSauleh Eetemadi, and Erik Cambria. 2020. Per-\nsonality trait detection using bagged svm over\nbert word embedding ensembles. arXiv preprint\narXiv:2010.01309.\nElma Kerz, Yu Qiao, Daniel Wiechmann, and Marcus\nStr¨obel. 2020. Becoming linguistically mature: Mod-\neling english and german children’s writing devel-\nopment across school grades. In Proceedings of the\nFifteenth Workshop on Innovative Use of NLP for\nBuilding Educational Applications, pages 65–74.\n190\nVictor Kuperman, Hans Stadthagen-Gonzalez, and\nMarc Brysbaert. 2012. Age-of-acquisition ratings\nfor 30,000 english words. Behavior research meth-\nods, 44(4):978–990.\nCharles Li, Monte Hancock, Ben Bowles, Olivia Han-\ncock, Lesley Perg, Payton Brown, Asher Burrell, Gi-\nanella Frank, Frankie Stiers, Shana Marshall, et al.\n2018. Feature extraction from social media posts for\npsychometric typing of participants. In International\nConference on Augmented Cognition, pages 267–286.\nSpringer.\nOctavio Loyola-Gonzalez. 2019. Black-box vs. white-\nbox: Understanding their advantages and weak-\nnesses from a practical point of view. IEEE Access,\n7:154096–154113.\nFranc ¸ois Mairesse, Marilyn A Walker, Matthias R Mehl,\nand Roger K Moore. 2007. Using linguistic cues\nfor the automatic recognition of personality in con-\nversation and text. Journal of artificial intelligence\nresearch, 30:457–500.\nNavonil Majumder, Soujanya Poria, Alexander Gelbukh,\nand Erik Cambria. 2017. Deep learning-based doc-\nument modeling for personality detection from text.\nIEEE Intelligent Systems, 32(2):74–79.\nChristopher Manning, Mihai Surdeanu, John Bauer,\nJenny Finkel, Steven Bethard, and David McClosky.\n2014. The stanford corenlp natural language process-\ning toolkit. In Proceedings of 52nd annual meeting of\nthe association for computational linguistics: system\ndemonstrations, pages 55–60.\nG. Matthews, I. Deary, and M. Whiteman. 2009. Per-\nsonality Traits. Cambridge University Press.\nRobert R McCrae. 2009. The five-factor model of per-\nsonality traits: Consensus and controversy. The Cam-\nbridge handbook of personality psychology , pages\n148–161.\nRobert R McCrae and Oliver P John. 1992. An intro-\nduction to the five-factor model and its applications.\nJournal of personality, 60(2):175–215.\nG Harry McLaughlin. 1969. Clearing the smog. Jour-\nnal of Reading.\nYash Mehta, Samin Fatehi, Amirmohammad Kazameini,\nClemens Stachl, Erik Cambria, and Sauleh Eetemadi.\n2020a. Bottom-up and top-down: Predicting per-\nsonality with psycholinguistic and language model\nfeatures. In 2020 IEEE International Conference on\nData Mining (ICDM), pages 1184–1189. IEEE.\nYash Mehta, Navonil Majumder, Alexander Gelbukh,\nand Erik Cambria. 2020b. Recent trends in deep\nlearning based personality detection. Artificial Intel-\nligence Review, 53(4):2313–2339.\nIsabel Briggs Meyers, Mary H McCaulley, and Allen L\nHammer. 1990. Introduction to Type: A Description\nof the Theory and Applications of the Myers-Briggs\nType Indicator. Consulting Psychologists Press.\nSaif Mohammad. 2018. Obtaining reliable human rat-\nings of valence, arousal, and dominance for 20,000\nenglish words. In Proceedings of the 56th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 174–184.\nSaif Mohammad, Svetlana Kiritchenko, and Xiaodan\nZhu. 2013. Nrc-canada: Building the state-of-the-art\nin sentiment analysis of tweets. In Proceedings of the\nseventh international workshop on Semantic Evalu-\nation Exercises (SemEval-2013), Atlanta, Georgia,\nUSA.\nSaif M Mohammad and Peter D Turney. 2013. Crowd-\nsourcing a word–emotion association lexicon. Com-\nputational intelligence, 29(3):436–465.\nDaniel J Ozer and Veronica Benet-Martinez. 2006. Per-\nsonality and the prediction of consequential out-\ncomes. Annu. Rev. Psychol., 57:401–421.\nGregory Park, H Andrew Schwartz, Johannes C Eich-\nstaedt, Margaret L Kern, Michal Kosinski, David J\nStillwell, Lyle H Ungar, and Martin EP Seligman.\n2015. Automatic personality assessment through\nsocial media language. Journal of personality and\nsocial psychology, 108(6):934.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, et al. 2019. Pytorch: An imperative style,\nhigh-performance deep learning library. Advances in\nneural information processing systems, 32.\nJames W Pennebaker, Martha E Francis, and Roger J\nBooth. 2001. Linguistic inquiry and word count:\nLiwc 2001. Mahway: Lawrence Erlbaum Associates,\n71(2001):2001.\nJames W Pennebaker and Laura A King. 1999. Lin-\nguistic styles: language use as an individual differ-\nence. Journal of personality and social psychology,\n77(6):1296.\nYu Qiao, Xuefeng Yin, Daniel Wiechmann, and Elma\nKerz. 2021a. Alzheimer’s disease detection from\nspontaneous speech through combining linguistic\ncomplexity and (dis) fluency features with pretrained\nlanguage models. arXiv preprint arXiv:2106.08689.\nYu Qiao, Sourabh Zanwar, Rishab Bhattacharyya,\nDaniel Wiechmann, Wei Zhou, Elma Kerz, and Ralf\nSchl¨uter. 2021b. Prediction of listener perception\nof argumentative speech in a crowdsourced data us-\ning (psycho-) linguistic and fluency features. arXiv\npreprint arXiv:2111.07130.\nMajid Ramezani, Mohammad-Reza Feizi-Derakhshi,\nMohammad-Ali Balafar, Meysam Asgari-Chenaghlu,\nAli-Reza Feizi-Derakhshi, Narjes Nikzad-\nKhasmakhi, Mehrdad Ranjbar-Khadivi, Zoleikha\nJahanbakhsh-Nagadeh, Elnaz Zafarani-Moattar, and\nTaymaz Rahkar-Farshi. 2021. Automatic personality\nprediction; an enhanced method using ensemble\nmodeling. arXiv preprint arXiv:2007.04571.\n191\nMarco Tulio Ribeiro, Sameer Singh, and Carlos\nGuestrin. 2016. ” why should i trust you?” explaining\nthe predictions of any classifier. In Proceedings of\nthe 22nd ACM SIGKDD international conference on\nknowledge discovery and data mining, pages 1135–\n1144.\nKlaus R Scherer. 2005. What are emotions? and how\ncan they be measured? Social science information,\n44(4):695–729.\nChristopher J Soto. 2019. How replicable are links\nbetween personality traits and consequential life out-\ncomes? the life outcomes of personality replication\nproject. Psychological Science, 30(5):711–727.\nRyan A Stevenson, Joseph A Mikels, and Thomas W\nJames. 2007. Characterization of the affective norms\nfor english words by discrete emotional categories.\nBehavior research methods, 39(4):1020–1024.\nPhilip J Stone, Dexter C Dunphy, and Marshall S Smith.\n1966. The general inquirer: A computer approach to\ncontent analysis.\nYla R Tausczik and James W Pennebaker. 2010. The\npsychological meaning of words: Liwc and comput-\nerized text analysis methods. Journal of language\nand social psychology, 29(1):24–54.\nAlessandro Vinciarelli and Gelareh Mohammadi. 2014.\nA survey of personality computing. IEEE Transac-\ntions on Affective Computing, 5(3):273–291.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R´emi Louf, Morgan Funtowicz,\net al. 2019. Huggingface’s transformers: State-of-\nthe-art natural language processing. arXiv preprint\narXiv:1910.03771.\nDavid H Wolpert. 1992. Stacked generalization. Neural\nnetworks, 5(2):241–259.\nPeng Zhou, Wei Shi, Jun Tian, Zhenyu Qi, Bingchen\nLi, Hongwei Hao, and Bo Xu. 2016. Attention-based\nbidirectional long short-term memory networks for\nrelation classification. In Proceedings of the 54th\nannual meeting of the association for computational\nlinguistics (volume 2: Short papers), pages 207–212.\nA Appendices\n0\n500\n1000\n1500\n2000\n2500\nAgreeableness Conscientiousness Extraversion Neuroticism Openness\nPersonality trait\nCount\nFigure 2: Distribution of labels in the Essay dataset\n0\n2500\n5000\n7500\nExtraversion Judging Sensing Thinking\nPersonality trait\nCount\nFigure 3: Distribution of labels in the Kaggle MBTI\ndataset\n192\nNeuroticism Openness\nAgreeableness Conscientiousness Extraversion\n0.00 0.05 0.10 0.15 0.20 0.0 0.1 0.2 0.3\n0.00 0.05 0.10 0.15 0.00 0.05 0.10 0.15 0.20 0.00 0.05 0.10 0.15\nDiversity.NDW___Extraversion\nngram_1_reg_news___Extraversion\nngram_1_reg_fic___Extraversion\nSyntactic.MeanLengthSentence___Extraversion\nngram_1_reg_spok___Extraversion\nColemanLiau___Extraversion\nngram_3_reg_spok___Extraversion\nGunningFog___Extraversion\nSpache___Extraversion\nSyntactic.ComplexTUnitsPerTUnit___Extraversion\nGALC.Feelinglove___Extraversion\nRix___Extraversion\nSyntactic.TUnitsPerSentence___Extraversion\nngram_2_reg_fic___Extraversion\nngram_2_reg_mag___Extraversion\nngram_2_reg_news___Extraversion\nSyntactic.ClausesPerSentence___Extraversion\nLIWC.Conj___Extraversion\nngram_2_reg_spok___Extraversion\nLIWC.Affiliation___Extraversion\nPrevalence.FemaleBP___Conscientiousness\nPrevalence.MaleSDAP___Conscientiousness\nPrevalence.USASDAP___Conscientiousness\nPrevalence.FemaleSDAP___Conscientiousness\nPrevalence.UKSDAP___Conscientiousness\nPrevalence.AllSDBP___Conscientiousness\nPrevalence.MaleSDBP___Conscientiousness\nPrevalence.USASDBP___Conscientiousness\nPrevalence.FemaleSDBP___Conscientiousness\nPrevalence.UKSDBP___Conscientiousness\nPrevalence.MaleCD___Conscientiousness\nPrevalence.AllCD___Conscientiousness\nPrevalence.USACD___Conscientiousness\nPrevalence.UKCD___Conscientiousness\nPrevalence.FemaleCD___Conscientiousness\nPrevalence.MaleWF___Conscientiousness\nPrevalence.AllWF___Conscientiousness\nPrevalence.USAWF___Conscientiousness\nPrevalence.UKWF___Conscientiousness\nPrevalence.FemaleWF___Conscientiousness\nLIWC.Relig___Openness\nFry.x___Openness\nMorphological.MeanSyllablesPerWord___Openness\nLIWC.Hear___Openness\nInquirer.Know___Openness\nInquirer.SKLTOT___Openness\nInquirer.Exprs___Openness\nDaleChall___Openness\nDepecheMood.AMUSED___Openness\nNRCVAD.AMUSED___Openness\nFORCAST___Openness\nNonStopWordsRate___Openness\nSophistication.BNC___Openness\nLIWC.Y ou___Openness\nMorphological.MeanLengthWord___Openness\nInquirer.FORM___Openness\nSentiment140Unigram.neg___Openness\nInquirer.SKLAS___Openness\nSophistication.ANC___Openness\nSentiment140Unigram.pos___Openness\nPrevalence.MaleCD___Agreeableness\nPrevalence.USACD___Agreeableness\nPrevalence.AllCD___Agreeableness\nPrevalence.MaleWF___Agreeableness\nPrevalence.AllWF___Agreeableness\nPrevalence.USAWF___Agreeableness\nPrevalence.FemaleCD___Agreeableness\nPrevalence.UKCD___Agreeableness\nPrevalence.UKWF___Agreeableness\nPrevalence.FemaleWF___Agreeableness\nLIWC.Adverb___Agreeableness\nInquirer.Time.___Agreeableness\nLIWC.Focusfuture___Agreeableness\nInquirer.AFFPT___Agreeableness\nLIWC.Home___Agreeableness\nSyntactic.MeanLengthClause___Agreeableness\nInquirer.AFFTOT___Agreeableness\nInquirer.Kin.___Agreeableness\nLIWC.Family___Agreeableness\nSenticNet.pos___Agreeableness\nANEW.arousal___Neuroticism\nLIWC.Health___Neuroticism\nInquirer.Pain___Neuroticism\nEmoLex.fear___Neuroticism\nngram_5_reg_fic___Neuroticism\nLIWC.Risk___Neuroticism\nGALC.Fear___Neuroticism\nEmoLex.negative___Neuroticism\nLIWC.Negate___Neuroticism\nLIWC.Focuspresent___Neuroticism\nLIWC.Sad___Neuroticism\nANEWEmo.mean_ang___Neuroticism\nANEWEmo.mean_fear___Neuroticism\nInquirer.Negate___Neuroticism\nInquirer.NOT___Neuroticism\nLIWC.Anx___Neuroticism\nANEWEmo.mean_sad___Neuroticism\nEmoLex.sadness___Neuroticism\nInquirer.Self___Neuroticism\nLIWC.I___Neuroticism\nDelta high/low scoring on dimension\nFeature group\n(narrow)\nEmotion\nLexical\nLIWC\nNgram\nPsycholing\nReadability\nSentiment\nSyntactic\nNeuroticism Openness\nAgreeableness Conscientiousness Extraversion\n0.00 0.05 0.10 0.15 0.20 −0.1 0.0 0.1 0.2 0.3\n−0.05 0.00 0.05 0.10 0.15 0.0 0.1 0.2 −0.05 0.00 0.05 0.10 0.15\nGALC.Amusement.Emotion\nGALC.Feelinglove.Emotion\nMorphological.Kolmogorov.InfTheo\nSyntactic.Kolmogorov.InfTheo\nDiversity.NDW.Lexical\nDiversity.RTTR.Lexical\nLIWC.Affiliation.LIWC\nLIWC.Conj.LIWC\nngram_2_reg_news.Ngram\nngram_2_reg_spok.Ngram\nPrevalence.FemaleWF .Psycholing\nPrevalence.UKWF .Psycholing\nRix.Readability\nSpache.Readability\nInquirer.POWCOOP.Sentiment\nInquirer.Rel.Sentiment\nSyntactic.ClausesPerSentence.Syntactic\nSyntactic.TUnitsPerSentence.Syntactic\nGALC.Hope.Emotion\nGALC.Relaxation.Serenity.Emotion\nBase.Kolmogorov.InfTheo\nMorphological.Kolmogorov.InfTheo\nDiversity.CTTR.Lexical\nLexical.WordPrevalence.Lexical\nLIWC.Prep.LIWC\nLIWC.Time.LIWC\nngram_2_reg_acad.Ngram\nngram_3_reg_acad.Ngram\nPrevalence.FemaleWF .Psycholing\nPrevalence.UKWF .Psycholing\nRix.Readability\nSMOG.Readability\nInquirer.Time..Sentiment\nSenticNet.pos.Sentiment\nSyntactic.ComplexTUnitsPerTUnit.Syntactic\nSyntactic.MeanLengthClause.Syntactic\nDepecheMood.AMUSED.Emotion\nDepecheMood.ANNOYED.Emotion\nBase.Kolmogorov.InfTheo\nMorphological.Kolmogorov.InfTheo\nMorphological.MeanLengthWord.Lexical\nSophistication.ANC.Lexical\nLIWC.Hear.LIWC\nLIWC.Y ou.LIWC\nngram_1_reg_acad.Ngram\nngram_1_reg_mag.Ngram\nAoA.max.Psycholing\nAoA.mean.Psycholing\nDaleChall.Readability\nFORCAST.Readability\nInquirer.SKLAS.Sentiment\nSentiment140Unigram.pos.Sentiment\nBase.NounPhrasePostModificationWords.Syntactic\nSyntactic.ComplexNominalsPerClause.Syntactic\nEmoLex.anticipation.Emotion\nGALC.Pleasure.Enjoyment.Emotion\nBase.Kolmogorov.InfTheo\nSyntactic.Kolmogorov.InfTheo\nDiversity.CTTR.Lexical\nDiversity.RTTR.Lexical\nLIWC.Family.LIWC\nLIWC.Home.LIWC\nngram_2_reg_news.Ngram\nngram_3_reg_mag.Ngram\nPrevalence.FemaleWF .Psycholing\nPrevalence.UKWF .Psycholing\nGunningFog.Readability\nRix.Readability\nInquirer.Kin..Sentiment\nSenticNet.pos.Sentiment\nSyntactic.CoordinatePhrasesPerClause.Syntactic\nSyntactic.MeanLengthClause.Syntactic\nEmoLex.negative.Emotion\nEmoLex.sadness.Emotion\nBase.Kolmogorov.InfTheo\nSyntactic.Kolmogorov.InfTheo\nLexical.WordPrevalence.Lexical\nSophistication.BNC.Lexical\nLIWC.Anx.LIWC\nLIWC.I.LIWC\nngram_4_reg_fic.Ngram\nngram_5_reg_fic.Ngram\nPrevalence.FemaleSDBP.Psycholing\nPrevalence.UKSD.Psycholing\nDaleChall.Readability\nFleshKincaidReadingEase.Readability\nANEWEmo.mean_sad.Sentiment\nInquirer.Self.Sentiment\nSyntactic.ClausesPerSentence.Syntactic\nSyntactic.TUnitsPerSentence.Syntactic\nDelta high/low scoring on dimension\nFeature group\n(narrow)\nEmotion\nInfTheo\nLexical\nLIWC\nNgram\nPsycholing\nReadability\nSentiment\nSyntactic\nFigure 4: Essays dataset: Upper panel: Top 20 most characteristic features from each feature group by personality\ntrait. Lower panel: Top 2 most characteristic features from each feature group by personality trait. Plotted scores\nrepresent the difference between the z-standardized mean scores of high- and low-scoring individuals on a given\npersonality trait. Positive scores are characteristic of the high-scoring individuals on a given trait (e.g. individuals\nwith high extraversion scores).\n193\nSensors Thinker\nExtraversion Judger\n0.00 0.05 0.10 0.15 0.0 0.1 0.2 0.3 0.4\n0.0 0.1 0.2 0.00 0.05 0.10 0.15 0.20\nInquirer.Percv___Judger\nInquirer.ENLOTH___Judger\nLIWC.Prep___Judger\nSMOG___Judger\nEmoLex.positive___Judger\nInquirer.ENLGAIN___Judger\nLIWC.Y ou___Judger\nSentiment140Unigram.neg___Judger\nSentiment140Unigram.pos___Judger\nSenticNet.pos___Judger\nInquirer.Affil___Judger\nInquirer.Virtue___Judger\nInquirer.ENLTOT___Judger\nInquirer.Pos___Judger\nInquirer.Pstv___Judger\nInquirer.AUD___Judger\nInquirer.Y ou___Judger\nFry.x___Judger\nMorphological.MeanSyllablesPerWord___Judger\nFORCAST___Judger\nInquirer.Negate___Thinker\nFry.x___Thinker\nMorphological.MeanSyllablesPerWord___Thinker\nInquirer.POWTOT___Thinker\nLIWC.Cause___Thinker\nInquirer.Know___Thinker\nDepeecheMood.AFRAID___Thinker\nNRCVAD.AFRAID___Thinker\nInquirer.Doctr___Thinker\nLIWC.Anger___Thinker\nAoA.max___Thinker\nInquirer.Acad___Thinker\nLIWC.Negate___Thinker\nSophistication.NAWL___Thinker\nLIWC.Work___Thinker\nInquirer.ENLOTH___Thinker\nAoA.mean___Thinker\nInquirer.ENLTOT___Thinker\nDepeecheMood.ANGRY___Thinker\nNRCVAD.ANGRY___Thinker\nInquirer.Eval___Extraversion\nGALC.Feelinglove___Extraversion\nLIWC.Sexual___Extraversion\nGALC.Amusement___Extraversion\nLIWC.Assent___Extraversion\nLIWC.Reward___Extraversion\nSophistication.NGSL___Extraversion\nLIWC.Affiliation___Extraversion\nLIWC.Shehe___Extraversion\nLIWC.Swear___Extraversion\nSentiment140Unigram.pos___Extraversion\nInquirer.MALE___Extraversion\nLIWC.Y ou___Extraversion\nLIWC.Friend___Extraversion\nLIWC.Male___Extraversion\nInquirer.Our___Extraversion\nLIWC.We___Extraversion\nSentiment140Unigram.neg___Extraversion\nLIWC.Posemo___Extraversion\nLIWC.Netspeak___Extraversion\nLIWC.Posemo___Sensors\nLIWC.Motion___Sensors\nGALC.Beingtouched___Sensors\nSophistication.BNC___Sensors\nLIWC.Ingest___Sensors\nInquirer.Tool___Sensors\nDepeecheMood.HAPPY___Sensors\nNRCVAD.HAPPY___Sensors\nGALC.Tension.Stress___Sensors\nLIWC.Hear___Sensors\nLIWC.Reward___Sensors\nDepeecheMood.DONT_CARE___Sensors\nNRCVAD.DONT_CARE___Sensors\nGALC.Amusement___Sensors\nInquirer.Object___Sensors\nLIWC.Leisure___Sensors\nInquirer.Vehicle___Sensors\nNonStopWordsRate___Sensors\nDensity.Density___Sensors\nFleshKincaidReadingEase___Sensors\nDelta high/low scoring on dimension\nFeature group\n(narrow)\nEmotion\nLexical\nLIWC\nPsycholing\nReadability\nSentiment\nSensors Thinker\nExtraversion Judger\n0.0 0.1 0.2 0.0 0.1 0.2 0.3 0.4\n−0.1 0.0 0.1 0.2 0.00 0.05 0.10 0.15 0.20\nEmoLex.positive.Emotion\nEmoLex.trust.Emotion\nBase.Kolmogorov.InfTheo\nSyntactic.Kolmogorov.InfTheo\nMorphological.MeanLengthWord.Lexical\nMorphological.MeanSyllablesPerWord.Lexical\nLIWC.Prep.LIWC\nLIWC.Y ou.LIWC\nngram.Normalization2_ngram_2_reg_acad.Ngram\nngram.Normalization2_ngram_3_reg_acad.Ngram\nAoA.max.Psycholing\nAoA.mean.Psycholing\nFORCAST.Readability\nFry.x.Readability\nInquirer.AUD.Sentiment\nInquirer.Y ou.Sentiment\nSyntactic.ComplexNominalsPerClause.Syntactic\nSyntactic.ComplexTUnitsPerTUnit.Syntactic\nDepeecheMood.AFRAID.Emotion\nDepeecheMood.ANGRY .Emotion\nBase.Kolmogorov.InfTheo\nSyntactic.Kolmogorov.InfTheo\nMorphological.MeanSyllablesPerWord.Lexical\nSophistication.NAWL.Lexical\nLIWC.Negate.LIWC\nLIWC.Work.LIWC\nngram.Normalization2_ngram_4_reg_acad.Ngram\nngram.Normalization2_ngram_5_reg_acad.Ngram\nAoA.max.Psycholing\nAoA.mean.Psycholing\nFry.x.Readability\nSMOG.Readability\nInquirer.ENLTOT.Sentiment\nNRCVAD.ANGRY .Sentiment\nBase.NounPhrasePreModificationWords.Syntactic\nSyntactic.ComplexNominalsPerClause.Syntactic\nGALC.Amusement.Emotion\nGALC.Feelinglove.Emotion\nBase.Kolmogorov.InfTheo\nSyntactic.Kolmogorov.InfTheo\nDensity.Density.Lexical\nSophistication.NGSL.Lexical\nLIWC.Netspeak.LIWC\nLIWC.Posemo.LIWC\nngram.Normalization2_ngram_1_reg_fic.Ngram\nngram.Normalization2_ngram_1_reg_spok.Ngram\nPrevalence.UKCD.Psycholing\nPrevalence.USACD.Psycholing\nDaleChall.Readability\nFleshKincaidReadingEase.Readability\nInquirer.Our.Sentiment\nSentiment140Unigram.neg.Sentiment\nSyntactic.ClausesPerTUnit.Syntactic\nSyntactic.DependentClausesPerTUnit.Syntactic\nDepeecheMood.DONT_CARE.Emotion\nGALC.Amusement.Emotion\nBase.Kolmogorov.InfTheo\nMorphological.Kolmogorov.InfTheo\nDensity.Density.Lexical\nNonStopWordsRate.Lexical\nLIWC.Leisure.LIWC\nLIWC.Reward.LIWC\nngram.Normalization2_ngram_4_reg_fic.Ngram\nngram.Normalization2_ngram_5_reg_fic.Ngram\nPrevalence.UKSD.Psycholing\nPrevalence.USASD.Psycholing\nDaleChall.Readability\nFleshKincaidReadingEase.Readability\nInquirer.Object.Sentiment\nInquirer.Vehicle.Sentiment\nBase.NounPhrasePostModificationWords.Syntactic\nBase.NounPhrasePreModificationWords.Syntactic\nDelta high/low scoring on dimension\nFeature group\n(narrow)\nEmotion\nInfTheo\nLexical\nLIWC\nNgram\nPsycholing\nReadability\nSentiment\nSyntactic\nFigure 5: MBTI Kaggle dataset: Upper panel: Top 20 most characteristic features from each feature group by\npersonality trait. Lower panel: Top 2 most characteristic features from each feature group by personality trait.\nPlotted scores represent the difference between the z-standardized mean scores of high- and low-scoring individuals\non a given personality trait. Positive scores are characteristic of the high-scoring individuals on a given trait (e.g.\nindividuals with high extraversion scores).\n194",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7645700573921204
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5688104629516602
    },
    {
      "name": "Personality",
      "score": 0.5588680505752563
    },
    {
      "name": "Natural language processing",
      "score": 0.5036570429801941
    },
    {
      "name": "Transformer",
      "score": 0.4678875505924225
    },
    {
      "name": "Computational linguistics",
      "score": 0.4542354941368103
    },
    {
      "name": "Machine learning",
      "score": 0.44878625869750977
    },
    {
      "name": "Feature engineering",
      "score": 0.4446884095668793
    },
    {
      "name": "Big Five personality traits",
      "score": 0.41624388098716736
    },
    {
      "name": "Deep learning",
      "score": 0.3595835268497467
    },
    {
      "name": "Psychology",
      "score": 0.11645394563674927
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Social psychology",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I887968799",
      "name": "RWTH Aachen University",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I887064364",
      "name": "University of Amsterdam",
      "country": "NL"
    }
  ]
}