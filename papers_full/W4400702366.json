{
  "title": "ChatCPU: An Agile CPU Design and Verification Platform with LLM",
  "url": "https://openalex.org/W4400702366",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A1927097909",
      "name": "Wang Xi",
      "affiliations": [
        "Southeast University",
        "The Synergetic Innovation Center for Advanced Materials"
      ]
    },
    {
      "id": null,
      "name": "Wan, Gwok-Waa",
      "affiliations": [
        "The Synergetic Innovation Center for Advanced Materials"
      ]
    },
    {
      "id": null,
      "name": "Wong, Sam-Zaak",
      "affiliations": [
        "The Synergetic Innovation Center for Advanced Materials"
      ]
    },
    {
      "id": null,
      "name": "Zhang, Layton",
      "affiliations": [
        "The Synergetic Innovation Center for Advanced Materials"
      ]
    },
    {
      "id": "https://openalex.org/A2370601102",
      "name": "Liu Tian-yang",
      "affiliations": [
        "Southeast University"
      ]
    },
    {
      "id": "https://openalex.org/A2114747614",
      "name": "Tian Qi",
      "affiliations": [
        "Southeast University"
      ]
    },
    {
      "id": "https://openalex.org/A2749892750",
      "name": "Ye Jianmin",
      "affiliations": [
        "Southeast University"
      ]
    },
    {
      "id": "https://openalex.org/A1927097909",
      "name": "Wang Xi",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Wan, Gwok-Waa",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Wong, Sam-Zaak",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Zhang, Layton",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2370601102",
      "name": "Liu Tian-yang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2114747614",
      "name": "Tian Qi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2749892750",
      "name": "Ye Jianmin",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1983394510",
    "https://openalex.org/W3169517138",
    "https://openalex.org/W2101188827",
    "https://openalex.org/W3114230949",
    "https://openalex.org/W4308083752",
    "https://openalex.org/W4386764824",
    "https://openalex.org/W4386869637",
    "https://openalex.org/W4393145520",
    "https://openalex.org/W4285114951"
  ],
  "abstract": null,
  "full_text": "HAL Id: hal-04642833\nhttps://hal.science/hal-04642833v1\nSubmitted on 10 Jul 2024\nHAL is a multi-disciplinary open access\narchive for the deposit and dissemination of sci-\nentific research documents, whether they are pub-\nlished or not. The documents may come from\nteaching and research institutions in F rance or\nabroad, or from public or private research centers.\nL‚Äôarchive ouverte pluridisciplinaire HAL, est\ndestin√©e au d√©p√¥t et √† la diffusion de documents\nscientifiques de niveau recherche, publi√©s ou non,\n√©manant des √©tablissements d‚Äôenseignement et de\nrecherche fran√ßais ou √©trangers, des laboratoires\npublics ou priv√©s.\nDistributed under a Creative Commons Attribution - NonCommercial 4.0 International License\nChatCPU: An Agile CPU Design & V erification\nPlatform with LLM\nXi W ang, Gwok-W aa W an, Sam-Zaak W ong, Layton Zhang, Tianyang Liu, Qi\nTian, Jianmin Y e\nT o cite this version:\nXi W ang, Gwok-W aa W an, Sam-Zaak W ong, Layton Zhang, Tianyang Liu, et al.. ChatCPU: An Agile\nCPU Design & V erification Platform with LLM. 61st ACM/IEEE Design Automation Conference\n(DAC ‚Äô24), ACM/IEEE, Jun 2024, San F rancisco, United States. pp.1-6, Ôøø10.1145/3649329.3658493Ôøø.\nÔøøhal-04642833Ôøø\nChatCPU: An Agile CPU Design & Verification Platform with LLM\nXi Wang\nxi.wang@seu.edu.cn\nNational ASIC Center, School of\nIntegrated Circuit, Southeast University\nNational Center of Technology Innovation\nfor Electronic Design Automation\nNanjing, Jiangsu, China\nGwok-Waa Wan‚àó\nSam-Zaak Wong\nLayton Zhang\n{gwokwaa,samzaak,layton}@nctieda.com\nNational Center of Technology Innovation\nfor Electronic Design Automation\nNanjing, Jiangsu, China\nTianyang Liu\nQi Tian\nJianmin Ye\n{liutianyang,qi_tian,jianmin_y}@seu.edu.cn\nNational ASIC Center, School of\nIntegrated Circuit, Southeast University\nNanjing, Jiangsu, China\nAbstract\nThe increasing complexity of semiconductor designs necessitates\nagile hardware development methodologies to keep pace with rapid\ntechnological advancements. Following this trend, the Large Lan-\nguage Models (LLMs) emerge as a potential solution, providing\nnew opportunities in hardware design automation. However, ex-\nisting LLMs exhibit challenges in HDL design and verification,\nespecially for complicated hardware systems. Addressing this need,\nwe introduce ChatCPU, the first end-to-end agile hardware de-\nsign and verification platform with LLM. ChatCPU streamlines\nthe ASIC design and verification process, guiding it from initial\nspecifications to the final RTL implementations with enhanced de-\nsign agility. Incorporating the LLM fine-tuning and the processor\ndescription language design for CPU design automation, ChatCPU\nsignificantly enhances the hardware design capability using LLM.\nUtilizing ChatCPU, we developed a 6-stage in-order RISC-V CPU\nprototype, achieving successful tape-out using SkyWater 130nm\nMPW project with Efabless, which is currently the largest CPU\ndesign generated by LLM. Our results demonstrate a remarkable\nimprovement in CPU design efficiency, accelerating the design it-\neration process by an average of 3.81X, and peaking at 12X and\n9.33X in HDL implementations and verification stages, respectively.\nThe ChatCPU also enhances the design capability of LLM by 2.63X\nas compared to base LLama2. These advancements in ChatCPU\nrepresent a significant milestone in LLM-driven ASIC design and\noptimization.\nCCS Concepts:‚Ä¢ Computing methodologies ‚ÜíArtificial in-\ntelligence; ‚Ä¢ Computer systems organization ; ‚Ä¢ Hardware ‚Üí\nElectronic design automation ;\nKeywords: ChatCPU, LLM, Agile Hardware Design, Verification\nACM Reference Format:\nXi Wang, Gwok-Waa Wan, Sam-Zaak Wong, Layton Zhang, Tianyang Liu, Qi\nTian, and Jianmin Ye. 2024. ChatCPU: An Agile CPU Design & Verification\nPlatform with LLM. In 61st ACM/IEEE Design Automation Conference (DAC\n‚Äô24), June 23‚Äì27, 2024, San Francisco, CA, USA. ACM, New York, NY, USA,\n6 pages. https://doi.org/10.1145/3649329.3658493\n‚àóCorresponding author: Gwok-Waa Wan\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nDAC ‚Äô24, June 23‚Äì27, 2024, San Francisco, CA, USA\n¬© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0601-1/24/06\nhttps://doi.org/10.1145/3649329.3658493\n1 Introduction\nIn the era of big data, the surge in data-intensive workloads such as\nmachine learning, graph analytics, blockchain, etc. shows the ever-\nincreasing demand for enhanced computing capabilities. This need,\nalongside advancements in CMOS scaling and domain-specific ar-\nchitectures, has catalyzed an escalating expansion in the complexity\nof modern silicon designs. As a consequence, the process of con-\nstructing hardware prototypes for such systems from the ground\nup has become a formidable challenge, entailing substantial time\nand effort dedicated to implementations and verification.\nTargeting this challenge, many efforts have been devoted to agile\nhardware designs to accelerate iterations. Recent approaches have\nleveraged High-Level Synthesis (HLS) [6] and modern Hardware De-\nscription Languages (HDLs) like Chisel and SpinalHDL [2], which\ncan subsequently be compiled to RTL. However, these methods aim\nto enhance agility via additional layers of abstraction, resulting in\ndifficulties of design verification and fine-grained control over the\nperformance, power, and area (PPA) [12, 16].\nInnovations in Machine Learning (ML) and Artificial Intelligence\n(AI) offer new avenues for agile hardware design [10]. Current ML\napplications target specific design stages such as the design space\nexploration, physical design, etc., yet their integration across the\nentire processor design cycle spanning from hardware specifica-\ntions to HDL implementation is still emerging [ 15, 17, 18]. The\nprocessor design and verification process, particularly, remains\nlabor-intensive, requiring significant expertise and extensive vali-\ndation. The advent of Large Language Models (LLMs) [13] presents\nan opportunity in this domain. Recent efforts demonstrate the po-\ntential of LLMs in automating hardware implementations [ 3, 4].\nHowever, the quality of LLM-generated hardware designs poses\nchallenges in synthesis and functional verification, often leading\nto increased debugging and verification efforts. Moreover, existing\nLLM-based silicon generations remain tiny-scale, and LLMs exhibit\nlimited capability in complex system designs like CPUs.\nTherefore, we introduce ChatCPU, an agile CPU design and\nverification platform with fine-tuned LLM. ChatCPU features a hier-\narchical CPU design methodology and modularized HDL generation\nparadigm. We also designed a new Processor Description Language\n(PDL) dedicated to clear and unified CPU architecture descriptions,\nimproving prompt management by eliminating ambiguity in de-\nsign specifications. We further introduce an Agile Model Generator\n(AMG) for automated CPU reference model generation based on\nthe CPU design description with PDL. Integrating the AMG and\nPDL, we propose a Module-interchangeable Verification Paradigm\n(MVP) to address the verification challenges of complicated hard-\nware system designs using LLMs. Attributed to the enhanced in-\ntelligence and automation, ChatCPU substantially reduces design\niteration time and effort, streamlining the lab-to-fab process of\nDAC ‚Äô24, June 23‚Äì27, 2024, San Francisco, CA, USA X. Wang, G. Wan, S. Wong, L. Zhang, T. Liu, Q. Tian and J. Ye\nFigure 1. Hardware Design Capability with Different Complexities\nhardware development. As a validation of the proposed framework,\nwe designed Saber6, a 6-stage in-order RISC-V CPU with ChatCPU\nand implemented the silicon prototype with OpenEDA flow [14]\nand SkyWater 130nm MPW project. As a case study, we utilized\nChatCPU to design and implement a RISC-V CPU prototype with\nthe OpenEDA flow [14] and the MPW project, demonstrating the\npotential of ChatCPU to revolutionize CPU design and verification.\nThis research makes six key contributions.\n‚Ä¢We extensively analyze the RTL design capability of existing\nLLMs and summarize the challenges of LLM-based design.\n‚Ä¢We introduce ChatCPU, the first CPU design and verification\nplatform with LLM, featuring a high degree of extensibility\nand scalability. ChatCPU is capable of autonomously driving\nend-to-end ASIC design.\n‚Ä¢We construct the CPU design dataset and fine-tune the LLama\n2 to enhance the capability of RTL generation.\n‚Ä¢We design a processor design language and an agile model\ngenerator to automate the generations of CPU designs and\nreference models in a homologous manner.\n‚Ä¢We propose a module-interchangeable verification paradigm\nto drive complete CPU verification flow upon each CPU mod-\nule generated by LLM, based on the co-simulation support\nbetween modularized RTL design and CPU reference model.\n‚Ä¢We design and verify a RISC-V CPU from scratch with ChatCPU,\nand fabricate the silicon prototype with OpenEDA and Sky-\nWater 130 OpenPDK [7] in the Efabless MPW project.\nThe rest of this paper is organized as follows. Section 2 presents\nthe motivation of ChatCPU and related work. Section 3 describes\nthe detailed ChatCPU design and workflow. Section 4 presents the\nevaluations of the ChatCPU, and Section 5 concludes the paper.\n2 Background\n2.1 LLM in Agile Hardware Design\nRecent advancements in LLMs such as BERT, GPT-2, and GPT-3\nhave showcased significant capabilities in Natural Language Pro-\ncessing (NLP) and text generation. These models utilize contextual\ninformation effectively, offering the potential for generating intri-\ncate hardware designs from high-level natural language inputs [9].\nInitiatives like ChipGPT [4] and ChipChat [3] take advantage of\nLLMs for hardware design. However, ChipGPT focuses more on\noptimizing prompts rather than tackling the broader challenges of\nagile hardware design [19]. Conversely, ChipChat, while advancing\nLLMs in chip design, has only demonstrated results on a small\nscale, approximately 1,000 logic gates, which pales in comparison\nto modern processors that incorporate billions of gates. This dispar-\nity raises questions about the scalability and practicality of these\nmethods for more complex designs.\nIn addition to design generation, verification remains a crucial\naspect of AI-driven hardware design paradigms. For example, a\nrecent study explored AI-driven CPU design based solely on ex-\nternal input-output observations with extensive I/O operations for\ncircuit matching, rather than formal program code. This approach,\nwhile effective within its scope, results in a ‚Äôblack-box‚Äô design pro-\ncess, leading to potential redundancies and challenges in design\nverification [5]. Current LLMs, despite their advancements, still\nproduce hardware designs that are prone to errors and may not pass\nsynthesis and functional checks, thereby inducing overhead in veri-\nfication. Given the high costs associated with design verification in\nmodern CPUs, it is imperative that agile hardware design not only\nautomates HDL generation but also streamlines the verification.\n2.2 LLM Hardware Design Analysis\nTo assess the efficacy of LLMs in hardware design generation, we\nconducted an evaluation using Claude, GPT3.5, PaLM, LLama2,\nand Code-LLama. Our test involved generating ten different open-\nsource hardware designs written in Verilog, with complexity rang-\ning from a simple adder to a sophisticated CPU. Each LLM received\nidentical design specifications, and we monitored their results of\nsynthesis and functionality verification. If errors were detected, the\nLLMs were tasked with debugging and regenerating the code. We\nquantified the design capability (C) of each LLM using the metric,\nùê∂ = 1\nùëÅ (1)\nwhere N represents the number of iterations needed by the LLM to\npass both synthesis and verification.\nFollowing this metric, a higher C value indicates superior design\ncapability. We allowed a maximum of 20 iterations for each design.\nIf an LLM failed to produce a viable design within these iterations,\nits design capability for that particular design was recorded as zero.\nAs depicted in Figure 1, GPT3.5 demonstrated the highest design\ncapability among the evaluated LLMs. However, we observed a\nconsistent decline in design capability across all LLMs as design\ncomplexity increased, particularly evident when transitioning from\nsimpler designs to those comprising over 17,000 cells, such as the\nPicoRV32 CPU. Notably, none of the LLMs succeeded in generating\nfunctional Load Store Units (LSU), Reorder Buffers (ROB), or the\nPicoRV32 CPU designs, underscoring the challenges LLMs face in\nhandling complex system designs.\n2.3 Problem Formulation\nBuilding upon the results and analysis from Section 2.2, we iden-\ntify and define three primary challenges ( C1‚ÄìC3) in LLM-based\nhardware design:\n‚Ä¢C1. Limited HDL Generation Capability . The hardware\ndesigns generated by LLMs frequently fail to meet synthesis\nand functional verification standards, indicating a gap in the\nquality of generated code.\n‚Ä¢C2. Limitations in Complex System Design : While LLMs\nshow promising capability in generating designs for simpler\nChatCPU: An Agile CPU Design & Verification Platform with LLM DAC ‚Äô24, June 23‚Äì27, 2024, San Francisco, CA, USA\nFigure 2. ChatCPU Architecture and Workflow\nmodules, their effectiveness diminishes with increasing com-\nplexity. This limitation becomes particularly evident in intri-\ncate hardware systems where the success rate of effective\ndesign generation by LLMs significantly decreases.\n‚Ä¢C3. Design Verification Challenges : LLMs struggle to\nadequately address bugs within complex, interconnected\nmodules. The limitations in token and chat history further\nconstrain LLMs from comprehensively covering both the\ncomplete codebase and the intricate logic required in large-\nscale HDL designs.\n3 Design & Philosophy\n3.1 Solutions & Strategies\nIn response to the hardware design challenges ( C1‚ÄìC3) of LLMs\nidentified in Section 2.3, we propose the ChatCPU design, incorpo-\nrating the following key solutions:\n‚Ä¢S1. LLM Fine-Tuning : To improve the quality of HDL\ncode generation, we refine LLMs using high-quality train-\ning datasets derived from existing open-source hardware\ndesigns. This involves data collection, cleaning, and labeling\nto enable more accurate and effective HDL generation.\n‚Ä¢S2. Hierarchical System Design with Divide & Conquer\nApproach: Addressing the complexity of CPU system de-\nsign, we decompose it into smaller, manageable hardware\nmodules. This hierarchical structuring allows for the distri-\nbution of complex design tasks across specialized LLMs, each\nassigned specific roles, thereby enhancing design efficiency\nand manageability.\n‚Ä¢S3. Processor Description Language (PDL)-Based De-\nsign Generation: We introduce a novel PDL to standardize\nCPU design specifications. This unified language serves as\nthe foundation for automated design and reference model\ngeneration, facilitating both the design and verification.\n‚Ä¢S4. Module-Interchangeable Verification Paradigm (MVP):\nTo tackle the verification challenges of intricate designs\nproduced by LLMs, we implement the MVP methodology.\nThis approach integrates each generated module into a pre-\nverified reference model, enabling a comprehensive design\nverification flow.\n3.2 HDL Selection\nHLS offers the convenience of abstracting complex RTL design de-\ntails through high-level languages like C/C++, but it limits control\nover hardware implementations and PPA tradeoffs. Besides, tracing\nissues from HLS to the original code is challenging, complicating\ndebugging and verification. Similarly, while Chisel and SpinalHDL\nhave their advantages, they present limitations in design verifica-\ntion, such as variable renaming and inadequate assertion support,\nrespectively. Therefore, in this work, we select traditional HDLs\n(Verilog/SystemVerilog) for ChatCPU, leveraging their robustness\nand transparency in design and verification processes.\n3.3 LLM Fine-Tuning\nTo enhance LLM capabilities in RTL code generation, we utilized\nGoogle Big Query to collect open-source RTL designs from GitHub,\nforming our primary dataset. This dataset was then processed with\nGPT4 to generate appropriate commands for each RTL segment, fol-\nlowed by deduplication and removal of irrelevant data. We trained\nthese question-answer pairs using the Llama2-70B model, aiming to\nalign RTL code with its functional descriptions. This approach en-\nables the LLM to comprehend not only the RTL syntax but also the\nunderlying functional context. Furthermore, we incorporated our\nPDL design specifications and detailed examples into the training\nset. This addition aims to boost the LLM proficiency in generating\nHDL and PDL content based on design specifications. During the\nfine-tuning phase, we employed the Low-Rank Adaptation (LoRA)\ntechnique, which targets a limited number of parameters, assuming\na low ‚Äúintrinsic rank‚Äù of weight changes during model tuning. This\nmethod optimizes the low-rank decomposition of weight matrices\nin self-attention modules, thereby streamlining the optimization\nprocess from higher to lower dimensions.\n3.4 ChatCPU Workflow\nAs shown in Figure 2, ChatCPU employs a hierarchical design and\nmodular generation flow with two fine-tuned LLMs featuring dis-\ntinct roles. The first LLM (LLM 1 ) is tasked with translating design\nspecifications into high-level architecture designs using our Proces-\nsor Description Language (PDL), detailing aspects such as module\nlists, pipeline stages, and pin-to-pin connections. This PDL file is\nthen fed into the Agile Model Generator (AMG) to automatically\nproduce a cycle-accurate CPU reference model for design verifica-\ntion. Meanwhile, the second LLM (LLM 2 ) processes the PDL for\nDAC ‚Äô24, June 23‚Äì27, 2024, San Francisco, CA, USA X. Wang, G. Wan, S. Wong, L. Zhang, T. Liu, Q. Tian and J. Ye\nFigure 3. Prompt Examples of ChatCPU. From left to right are\nexamples of PDL generation, HDL generation, and debugging.\neach module, iteratively generating detailed HDL implementations.\nAfter a module passes linter checks, it is then verilated to a cor-\nresponding RTL model for co-simulation with the CPU reference\nmodel. This process, part of the MVP, allows for cross-validation\nof functionality. If the verification is successful, the design checker\nprompts LLM 1 via a feedback engine to proceed with the next\nmodule generation. Any errors identified during code linting or de-\nsign verification are reported back to LLM 2 for module redesign.\nFigure 3 provides examples of prompt interactions in ChatCPU.\nPart (a) of the figure illustrates how LLM 1 receives a specifica-\ntion input and produces a corresponding PDL output for a Branch\nPrediction Unit (BPU) design. Part (b) demonstrates the design gen-\neration based on the provided PDL in LLM 2 . Lastly, part (c) of\nthe figure shows a scenario where issues are encountered during\nthe verification process, highlighting the interactive and iterative\nnature of the design and verification cycle in ChatCPU.\n3.5 Processor Description Language\nWithin ChatCPU, the processor description language (PDL) is inno-\nvatively crafted to encapsulate the timing, functionality, pipeline\narchitecture, and pin-to-pin interfaces of each CPU module. PDL ef-\nfectively translates CPU design specifications, originally in natural\nlanguage, into a unified, machine-readable format. This comprehen-\nsive representation in the PDL file enables it to act as a foundational\ninput for both the generation of HDL implementations and the\nconstruction of the CPU reference model. Figure 3(a) provides an\nillustrative example of PDL usage in CPU design specification.\n3.6 Agile Model Generator\nAs depicted in Figure 4, the agile model generator (AMG) within\nChatCPU initiates its process by interpreting PDL input to define\nthe CPU timing behavior, functional characteristics, and pipeline\nstructure. AMG facilitates interactions between modules through a\nwell-defined timing interface, ensuring precise representation of\ntiming relations across different modules.\nThe core of AMG operation is a decoupled timing and functional\nmodeling mechanism, utilizing an event-based simulation approach\nto enhance both configurability and scalability. In this system, an\nFigure 4. Agile Model Generator Workflow\nevent handler correlates timing events with their corresponding\nfunctional simulations via a functional interface. AMG module li-\nbrary houses functional implementations for simulating the behav-\nior of classical modules in modern CPU designs. Upon completing\nthe functional simulation, the timing interface is signaled to sched-\nule subsequent events. The final stage of AMG‚Äôs workflow involves\nconnecting the established modules in a pipeline, culminating in\nthe generation of a complete reference model for the CPU.\n3.7 MVP Verification Flow\nVerification plays a pivotal role in ASIC design, particularly for de-\nsigns generated by LLMs. Addressing the verification challenge (C3)\noutlined in Section 2.3, we introduce the Module-interchangeable\nVerification Paradigm (MVP), specifically tailored for LLM-based\nCPU design. An example of this flow is shown in Figure 5.\nThe CPU reference model serves as the cornerstone for design\nverification. The reference model generated by ChatCPU offers a\nmodularized golden model for both module-level and comprehen-\nsive CPU verification. We first ventilate each generated module to a\nrespective RTL model for module-level simulation. The verification\nprocess starts with each LLM-generated module being translated\ninto an RTL model using Verilator, a tool that converts RTL designs\ninto C++ for simulation. Module-level verification is then conducted\nthrough unit tests, with results cross-validated against the equiv-\nalent module in the CPU reference model. Modules successfully\npassing unit tests, akin to fitting pieces in a jigsaw puzzle, are then\nintegrated into the reference model. This integration is facilitated\nby co-simulation techniques such as Verilog Procedural Interface\n(VPI), Direct Programming Interface (DPI), or Transaction-Level\nModeling (TLM), ensuring seamless module interchangeability.\nGiven the unified design language provided by PDL, the inter-\nchanged modules align perfectly with the reference model. The\nsubsequent co-simulation of the verified RTL model with the ref-\nerence model allows for comprehensive functionality evaluations.\nThis includes ISA tests, torture tests, benchmarks, and real-world\napplication simulations. As the CPU reference model is pre-verified\nfor functional correctness, any discrepancies identified during co-\nsimulation can be accurately attributed to the newly integrated\nRTL module. This targeted approach significantly streamlines the\ndebugging process, overcoming the limitations of LLM-generated\ndesigns related to token and chat history constraints. The MVP\napproach thus offers a modular yet holistic verification strategy,\nChatCPU: An Agile CPU Design & Verification Platform with LLM DAC ‚Äô24, June 23‚Äì27, 2024, San Francisco, CA, USA\nFigure 5. Example of Module-interchangeable Verification Flow: From Single Module to Complete CPU\nideally suited for the LLM-driven, modularized CPU design process,\neffectively addressing the complexity of verifying intricate systems.\n4 Evaluations\nOur experimental environment is delineated in Table 1.\nTo validate our methodologies, we designed a 6-stage in-order\nRISC-V CPU, named Saber6, using ChatCPU. This CPU, compris-\ning approximately 80,000 gates, represents the largest and most\ncomplex CPU design generated by LLMs to date. The tapeout was\ncompleted with the SkyWater 130nm MPW project, and the layout\nand detailed PPA information are illustrated in Figure 12.\nTable 1. Experimental Environment Specifications\nServer NVIDIA Server@Teax,US\nCPU AMD EPYC 7V13 64-Core Processor\nGPU 4xA100(80GB,PCIE4.0)\nMemory 256GB\nCUDA 12.0\nDisk 1024GB\nOS Ubuntu 22.04\n4.1 Design Capability Analysis\nTo quantify the enhancement in design capability achieved through\nLLM fine-tuning, we utilized the RTLLM benchmark [ 11], com-\nparing the performance of the default LLama2 and the fine-tuned\nLLM 2 in ChatCPU. The design capability metric, as defined in\nEquation 1, is represented in Figure 6. Results indicate a significant\nimprovement, with ChatCPU achieving an average design capa-\nbility 2.63X higher than the base LLama2. Notably, ChatCPU was\ncapable of generating all tested hardware modules, while the basic\nLLama2 was limited to smaller-scale designs.\nFurther, to assess the versatility of our fine-tuned LLM, we tasked\nLLM 2 with optimizing various RTL designs, as shown in Figure 7.\nThese designs, sourced from the OpenLane project [ 1], included\ndiverse hardware modules such as GCD, USB interface, Zipdiv, Pi-\ncorv32, and a co-processor for encryption. After collecting baseline\npower and area statistics using the OpenLane EDA flow, we directed\nthe fine-tuned LLM to optimize these designs without altering their\nfunctionality. The optimization yielded significant reductions in\npower and area, averaging 16.70% and 13.69%, respectively, with\npeaks reaching up to 36.36% and 27.72%.\n4.2 Design Agility Analysis\nTo evaluate the acceleration in design processes offered by ChatCPU,\nwe conducted an experiment involving 12 graduate students, di-\nvided into four groups. One group utilized ChatCPU (G1), while the\nothers did not use any LLMs (G2-G4). The time cost for each group\nto complete identical CPU design tasks is visualized in Figure 8. G1\nwith access to ChatCPU demonstrated markedly faster completion\ntimes, especially in code correctness and verification phases. On\naverage, ChatCPU users experienced a 3.81X time saving, with no-\ntable efficiency gains of up to 12X in RTL coding and 9.33X in design\nverification. These results validate the advancements our method-\nology offers in expediting code generation, improving verification\nsuccess rates, and enhancing overall development efficiency.\n4.3 Design Verification and Iterations\nOur analysis also focused on the impact of the MVP on design\ncapability. We assessed the capability of ChatCPU in generating\nvarious CPU modules in Saber6, comparing scenarios with MVP\nenabled and disabled (using only unit tests). The results, shown in\nFigure 9, reveal that while MVP leads to more iterations in simpler\nhardware designs (due to its thorough CPU verification flow), it\nsignificantly reduces the number of iterations required for complex\ndesigns. This reduction is particularly notable in tightly coupled\nmodules of CPU frontend, backend, and full CPU designs, where\nthe MVP comprehensive verification process is critical. Conversely,\nwithout MVP, even a fine-tuned LLM struggles with the challenges\nof cross-module verification in complex systems.\nAdditionally, we evaluated the impact of employing PDL in\nChatCPU. Comparing the design capability with and without PDL\nusage (Figure 10) demonstrates that using PDL enhances design ca-\npability by an average of 2.06X over human-written specifications.\n4.4 Design Complexity Analysis\nFinally, to further assess design complexity, we compared the cell\ncount of Saber6 with other LLM-generated hardware designs, in-\ncluding entries from the Efabless AI Design Contest [8]. As depicted\nin Figure 11, Saber6 exhibits a significantly higher level of complex-\nity than the other designs in terms of the cell count. This comparison\nunderscores the effectiveness of ChatCPU in facilitating the gener-\nation of complex hardware systems, highlighting its potential to\nrevolutionize agile hardware design methodologies.\n5 Conclusion\nIn this work, We first investigated the LLM-based hardware de-\nsigns and summarized the associated challenges. Targeting these\nchallenges, we proposed the ChatCPU platform to enhance the\nagile CPU design and verification using LLM. We proposed a hier-\narchical CPU design methodology with fine-tuned LLM, featuring\ndistinct roles in the modularized CPU generation paradigm. We\nalso introduced a Module-interchangeable Verification Paradigm\nDAC ‚Äô24, June 23‚Äì27, 2024, San Francisco, CA, USA X. Wang, G. Wan, S. Wong, L. Zhang, T. Liu, Q. Tian and J. Ye\nFigure 6. Impacts of LLM Fine-Tuning\n Figure 7. RTL Design Optimization\n Figure 8. Time Cost Distribution\nFigure 9. Verification Analysis\n Figure 10. Impacts of PDL\n Figure 11. Complexity Comparisons\nFeature Parameters\nPDK Skywater 130nm\nGate Count 80,000\nPipeline 6\nFrequency 100MHz\nTotal Power 19.2mW\nArea 0.18mm 2\nFigure 12. Silicon Layout and Information.\n(MVP) to verify the hardware designs generated by LLMs effectively.\nChatCPU also integrates the OpenEDA flow to enable automated\nPPA optimizations, achieving an impressive boost in RTL-GDS ef-\nficiency by an average of 3.81X. Finally, we designed the largest\nRISC-V CPU generated by LLMs, with a scale of 80K gates using\nChatCPU as a silicon prototype to validate our methodologies and\nexploit the transformative potential of LLMs in complex CPU de-\nsigns.\nReferences\n[1] 2023. OpenLane Project. https://github.com/The-OpenROAD-Project/OpenLane.\n[2] Jonathan Bachrach, Huy Vo, Brian Richards, Yunsup Lee, Andrew Waterman,\nRimas Avi≈æienis, John Wawrzynek, and Krste Asanoviƒá. 2012. Chisel: constructing\nhardware in a scala embedded language. In DAC.\n[3] Jason Blocklove, Siddharth Garg, Ramesh Karri, and Hammond Pearce. 2023.\nChip-Chat: Challenges and Opportunities in Conversational Hardware Design.\narXiv preprint arXiv:2305.13243 (2023).\n[4] Kaiyan Chang, Ying Wang, Haimeng Ren, Mengdi Wang, Shengwen Liang, Yinhe\nHan, Huawei Li, and Xiaowei Li. 2023. ChipGPT: How far are we from natural\nlanguage hardware design. arXiv preprint arXiv:2305.14019 (2023).\n[5] Shuyao Cheng, Pengwei Jin, Qi Guo, Zidong Du, Rui Zhang, Yunhao Tian, Hu,\net al. 2023. Pushing the Limits of Machine Design: Automated CPU Design with\nAI. arXiv preprint arXiv:2306.12456 (2023).\n[6] Philippe Coussy and Adam Morawiec. 2010.High-level synthesis. Vol. 1. Springer.\n[7] R Timothy Edwards. 2020. Google/SkyWater and the Promise of the Open PDK.\nIn Workshop on Open-Source EDA Technology .\n[8] efabless. 2023. Efabless AI Generated Open-Source Silicon Design Challenge.\nhttps://efabless.com/ai-generated-design-contest.\n[9] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,\net al. 2020. Codebert: A pre-trained model for programming and natural lan-\nguages. arXiv preprint arXiv:2002.08155 (2020).\n[10] Guyue Huang, Jingbo Hu, Yifan He, Jialong Liu, Mingyuan Ma, Zhaoyang Shen,\nJuejian Wu, Yuanfan Xu, et al . 2021. Machine learning for electronic design\nautomation: A survey. ACM TODAES (2021).\n[11] Yao Lu, Shang Liu, Qijun Zhang, and Zhiyao Xie. 2023. RTLLM: An Open-Source\nBenchmark for Design RTL Generation with Large Language Model. (2023).\n[12] Zohar Manna and Richard Waldinger. 1979. Synthesis: Dreams‚ÜíPrograms. IEEE\nTransactions on Software Engineering 4 (1979), 294‚Äì328.\n[13] Katharine Sanderson. 2023. GPT-4 is here: what scientists think. Nature 615,\n7954 (2023), 773.\n[14] Mohamed Shalan and Tim Edwards. 2020. Building OpenLANE: a 130nm\nopenroad-based tapeout-proven flow. In ICCAD.\n[15] Nan Wu, Yuan Xie, and Cong Hao. 2022. IronMan-Pro: Multiobjective De-\nsign Space Exploration in HLS via Reinforcement Learning and Graph Neural\nNetwork-Based Modeling. IEEE TCAD (2022).\n[16] Yinan Xu, Zihao Yu, Dan Tang, Guokai Chen, Lu Chen, Lingrui Gou, Yue Jin,\nQianruo Li, Xin Li, Zuojun Li, et al. 2022. Towards developing high performance\nRISC-V processors using agile methodology. In2022 55th IEEE/ACM International\nSymposium on Microarchitecture (MICRO) . IEEE, Chicago, IL, USA, 1178‚Äì1199.\n[17] Xiaoling Yi, Jialin Lu, Xiankui Xiong, Dong Xu, Li Shang, and Fan Yang. 2023.\nGraph representation learning for microarchitecture design space exploration.\nIn 2023 60th ACM/IEEE Design Automation Conference (DAC) . IEEE, IEEE, San\nFrancisco, CA, USA, 1‚Äì6.\n[18] Jianwang Zhai and Yici Cai. 2023. Microarchitecture Design Space Exploration\nvia Pareto-Driven Active Learning. IEEE TVLSI (2023).\n[19] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis,\nHarris Chan, and Jimmy Ba. 2022. Large language models are human-level\nprompt engineers. arXiv preprint arXiv:2211.01910 (2022).",
  "topic": "Agile software development",
  "concepts": [
    {
      "name": "Agile software development",
      "score": 0.7084954977035522
    },
    {
      "name": "Computer science",
      "score": 0.7034977674484253
    },
    {
      "name": "Embedded system",
      "score": 0.40838438272476196
    },
    {
      "name": "Software engineering",
      "score": 0.3968075215816498
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I76569877",
      "name": "Southeast University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210159340",
      "name": "The Synergetic Innovation Center for Advanced Materials",
      "country": "CN"
    }
  ]
}