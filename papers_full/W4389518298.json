{
  "title": "GYM at Qur’an QA 2023 Shared Task: Multi-Task Transfer Learning for Quranic Passage Retrieval and Question Answering with Large Language Models",
  "url": "https://openalex.org/W4389518298",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5109690441",
      "name": "Ghazaleh Mahmoudi",
      "affiliations": [
        "Iran University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5093457024",
      "name": "Yeganeh Morshedzadeh",
      "affiliations": [
        "University of British Columbia"
      ]
    },
    {
      "id": "https://openalex.org/A5086716685",
      "name": "Sauleh Eetemadi",
      "affiliations": [
        "Iran University of Science and Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3008110149",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W4297823766",
    "https://openalex.org/W4246183800",
    "https://openalex.org/W3156636935",
    "https://openalex.org/W4295065948",
    "https://openalex.org/W2611029872",
    "https://openalex.org/W4287827771",
    "https://openalex.org/W2138621090",
    "https://openalex.org/W4389518441",
    "https://openalex.org/W3090081112",
    "https://openalex.org/W4205103289",
    "https://openalex.org/W2894176037"
  ],
  "abstract": "This work addresses the challenges of question answering for vintage texts like the Quran. It introduces two tasks: passage retrieval and reading comprehension. For passage retrieval, it employs unsupervised fine-tuning sentence encoders and supervised multi-task learning. In reading comprehension, it fine-tunes an Electra-based model, demonstrating significant improvements over baseline models. Our best AraElectra model achieves 46.1% partial Average Precision (pAP) on the unseen test set, outperforming the baseline by 23%.",
  "full_text": "Proceedings of the The First Arabic Natural Language Processing Conference (ArabicNLP 2023), pages 714–719\nDecember 7, 2023 ©2023 Association for Computational Linguistics\nGYM at Qur’an QA 2023 Shared Task:\nMulti-Task Transfer Learning for Quranic Passage Retrieval and Question\nAnswering with Large Language Models\nGhazaleh Mahmoudi ∗1, Yeganeh Morshedzadeh∗2, Sauleh Eetemadi1\n1 School of Computer Engineering, Iran University of Science and Technology, Iran\n2 School of Engineering, The University of British Columbia, Canada\ngh_mahmoodi@comp.iust.ac.ir, yeganeh.morshedzadeh@ubc.ca, sauleh@iust.ac.ir\nAbstract\nThis work addresses the challenges of ques-\ntion answering for vintage texts like the Quran.\nIt introduces two tasks: passage retrieval and\nreading comprehension. For passage retrieval,\nit employs unsupervised fine-tuning sentence\nencoders and supervised multi-task learning. In\nreading comprehension, it fine-tunes an Electra-\nbased model, demonstrating significant im-\nprovements over baseline models. Our best\nAraElectra model achieves 46.1% partial Av-\nerage Precision (pAP) on the unseen test set,\noutperforming the baseline by 23%.\n1 Introduction\nQuestion Answering (QA) for vintage, religious\ntexts like the Quran presents unique challenges for\nnatural language understanding systems. Under-\nstanding the concepts and connections in the Quran\nrequires deep semantic reasoning to map questions\nto relevant passages and surface correct answers.\nTo advance research in this domain, the Qur’anQA\n2023 Shared Task1 proposes two sub-tasks focused\non machine comprehension of the Quran (Malhas\net al., 2023).\nTask A on passage retrieval requires matching\nModern Standard Arabic (MSA) free-text ques-\ntions to Quran verses potentially containing the\nanswer. This tests semantic similarity between\nquestions and passages. We propose using sen-\ntence encoders (Reimers and Gurevych, 2019) to\nderive dense vector representations for questions\nand passages. These vectors can be indexed and\nsearched efficiently to find relevant matches.\nTask Bon reading comprehension focuses on ex-\ntracting span answers from a given passage. This is\nframed as a machine reading comprehension task.\nHowever, given its literary Arabic and frequent\nneed for theological reasoning, it is especially dif-\nficult for the Quran. We formulate the task as ex-\n∗These authors contributed equally.\n1https://sites.google.com/view/quran-qa-2023/home\ntractive QA and experiment with span prediction\nmodels like AraElectra (Antoun et al., 2021).\nThe Qur’anQA 2023 shared task includes two\nsub-tasks that form an end-to-end QA pipeline.\nTask A retrieves candidate passages potentially con-\ntaining answers. This narrows the search space\nfrom the entire Quran to a small set of relevant\nverses. Task B then extracts answer spans from\nthese candidates. The tasks work sequentially: pas-\nsage retrieval provides context to reading compre-\nhension, which verifies answers. Together they\ncomprise an end-to-end QA system over the Quran.\nOur key contribution to this work is utilizing\ntransfer learning and model adaptation techniques\nto develop customized QA models for the limited\nQur’anQA 2023 shared task dataset. After experi-\nmenting with several Arabic and multi-lingual lan-\nguage models (LMs) we choose AraElectra and\nAraBERT (Antoun et al.) as strong candidates.\nThese models provide contextual representations\nof Arabic text learned from broad domains. In this\nwork, we aim to address these research questions:\n– How can we adapt LMs for Qur’anQA with\nlimited task data?\n– Which methods (e.g., transfer learning, data\naugmentation, unsupervised pretraining, etc.)\nimprove the accuracy of the Quranic domain?\nThrough experiments, we analyze different strate-\ngies for unsupervised sentence embeddings and\nsupervised task-specific fine-tuning. Despite the\nscarce training data, this allows the model to learn\nspecialized embeddings for Quranic comprehen-\nsion. Our work provides insights into adapting pre-\ntrained language models to new domains with lim-\nited labeled data. By combining broad pre-trained\nknowledge with targeted fine-tuning, we develop\ncustomized QA models capable of reasoning about\nthe Quran’s abstract concepts and archaic language.\nThe source code is available at GitHub2.\n2github.com/ghazaleh-mahmoodi/Quran-\nQA_2023_Shared-Task\n714\n2 Task A: Passage Retrieval\nFor a free-text question in MSA, the system must\nretrieve and rank Quranic passages that potentially\ncontain answers to the question from a corpus cov-\nering the entire Quran.\n3 Data\nFor this work, we utilize the training and devel-\nopment datasets provided by the Qur’anQA 2023\norganizers (Malhas and Elsayed, 2020; Swar, 2007;\nMalhas, 2023), a summary of which is provided in\nTable 1. Across both train and development splits,\nthere are 30 zero-answer questions, meaning that\nthey have no answers in the Quran passages.\nTo augment the limited size of the Quran-specific\ndata, we incorporate additional datasets during fine-\ntuning. For this passage retrieval task, we leverage\nthe multi-lingual Mr. TyDi dataset, which contains\nmonolingual question-passage pairs for informa-\ntion retrieval in 11 different languages (Zhang et al.,\n2021). We utilized the Arabic portion to fine-tune\nour proposed model.\nSplit # Question # Question-Passage Pairs\nTraining 174 972\nDevelopment 25 160\nTest 52 -\nAll 251 1132\nTable 1: Task A Dataset Distribution\n3.1 System\nOur implementation leverages the Sentence-\nTransformers framework (SBERT) (Reimers and\nGurevych, 2019) to derive question and passage\nembeddings optimized for semantic similarity\nsearch. This provides an efficient method to match\nquestions to relevant passages based on learned\nrepresentations. SBERT provides a Siamese BERT\nnetwork architecture optimized for semantic tex-\ntual similarity. We used AraBERT, a BERT variant\npre-trained on Arabic Wikipedia and news corpus.\nTo derive semantic vector representations of\nquestions and Quran verses, the proposed passage\nretrieval approach trains a sentence embedding\nmodel, also known as a bi-encoder model. In order\nto achieve this, first, using unsupervised meth-\nods, AraBERT is fine-tuned on Quran passages to\nget sentence embedding. In the second step, the\nbi-encoder is trained on Mr. TyDi’s Arabic dataset\nand Quran question-passage pairs usingsupervised\nmulti-task learning.\n3.1.1 Unsupervised Fine-Tuning: Learning\nSentence Embedding\nWe experiment with TSDAE (Wang et al., 2021)\nand SimCSE (Gao et al., 2021) as the unsupervised\ntraining approach for encoding questions and pas-\nsages.\nTSDAE (Transformer-based Denoising Auto-\nEncoder) is a denoising Auto-Encoder trained to\nreconstruct corrupted passages, learning robust rep-\nresentations that capture semantic meaning.\nSimCSE (Simple Contrastive Learning of Sentence\nEmbeddings) is a contrastive self-supervised learn-\ning approach to derive passage embeddings. Sim-\nCSE is trained to predict a passage from itself, us-\ning only standard dropout as noise for data augmen-\ntation.\nBy transfer learning, these models learn ro-\nbust passage representations that capture semantic\nmeaning without the need for labeled data.\n3.1.2 Supervised Fine-Tuning: Training\nBi-Encoder using Question-Passage\nPairs\nAfter unsupervised fine-tuning convergence, a\nmean pooling and dense layer are added to the\nlast layers of the bi-encoder. This bi-encoder is\nthen fine-tuned end-to-end on Mr. TyDi and our\nquestion-passage pairs dataset. More specifically,\nthe bi-encoder takes paired question and passage\nembeddings as input to predict relevance in a multi-\ntask approach.\n3.1.3 Model Specific Preparation\nModels are trained with a combination of multi-\nple negative ranking (Henderson et al., 2017), con-\ntrastive (Hadsell et al., 2006), and triplet (Dong\nand Shen, 2018) losses. As the models are trained\nin a multi-task manner, different loss functions are\nused for each dataset. A summary of the models\nis deprecated in Table 3. These three models were\ntrained for 3 epochs with a batch size of 64, tak-\ning approximately 48 minutes in total on Nvidia\nGeForce RTX 3090 GPU.\nAs for the Quranic question-passage pairs, ei-\nther a contrastive loss or triplet loss was incorpo-\nrated:\nWhen using contrastive loss, we benefited\nfrom BM25 retrieval over the full corpus to mine\nnegative passages for contrastive learning. More\nspecifically, for each question in the training data,\nwe first retrieve the top 1000 most relevant pas-\nsages using BM25. We then label the ground truth\n715\nModel Name Train Set Development Set Test Set\nMAP MRR MAP MRR MAP MRR\nAraBERT-TSDAE-Contrastive 0.1502 0.3206 0.1365 0.2613 0.0545 0.1581\nAraBERT-SimCSE-Contrastive 0.6522 0.7646 0.1459 0.2573 0.0315 0.1023\nAraBERT-SimCSE-Triplet 0.5243 0.6580 0.1082 0.1693 0.0116 0.0356\nTable 2: Task A MAP@10 and MRR@10 Results\npassage associated with the question as positive ex-\namples (label 1). The BM25 retrieved passages that\ndo not match any ground truth passages are used\nas hard negatives (label 0). Each <question, pos-\nitive passage, label=1>and <question, negative\npassage, label=0>is added as a training example.\nBy learning attempts to maximize similarity for\npositive pairs and minimize it for mined negatives.\nFor triplet loss, similarly, BM25 is used to\nmine negatives but used in a different format and\nstructure. Specifically, for each question, the top\n100 BM25 retrieved passages are obtained. Then\nfor each positive passage, negative passages are\nsampled to be used in forming of <question, pos-\nitive passage, negative passage>triplets. Finally,\nfor all of the question-passage pairs, multiple such\ntriplets are created by pairing them with each possi-\nble negative passage from the BM25 results. Triplet\nloss optimizes the model to ensure the positive pas-\nsage embedding is closer to the question than the\nnegative passage.\nFor Mr. TyDi , the samples follow a format\n<question, positive passage, negative passage>and\naccordingly, multiple negative ranking loss func-\ntion is used.\n3.2 Results\nTo evaluate system performance, we report the of-\nficial metrics of Mean Average Precision (MAP)\nand Mean Reciprocal Rank (MRR) on train, devel-\nopment, and test splits.\nOn the training set, our best-performing model\nis AraBERT-SimCSE-Contrastive, achieving a\nMAP@10 of 0.6522 and MRR@10 of 0.7646.\nContrastive learning approaches generally outper-\nform the triplet loss in our experiments. On the\ndevelopment set, AraBERT-SimCSE-Contrastive\nobtains the best MAP@10 of 0.1459 while\nAraBERT-TSDAE-Contrastive achieves the high-\nest MRR@10 of 0.2613 score. Our top-performing\nmodel on the official test set is AraBERT-TSDAE-\nContrastive, with a MAP@10 of 0.0545 and\nMRR@10 of 0.1581. Table 2 summarizes the full\nresults on dataset distributions for top-10.\nATC 3 ASC 4 AST 5\nTSDAE /enc-33- -\nSimCSE - /enc-33 /enc-33\nDenoising AE 6 /enc-33- -\nContrastive /enc-33 /enc-33-\nTriplet - - /enc-33\nMultiple Negative /enc-33 /enc-33 /enc-33\nQuran Q-P 7 /enc-33 /enc-33 /enc-33\nMr. TyDi /enc-33 /enc-33 /enc-33\nTable 3: Task A Models Summery\n3.3 Discussion\nOverall, our results demonstrate performance for\npassage retrieval on the Qur’anQA dataset. Observ-\ning the results of the development set indicates that\nthe models are effective at retrieving all relevant\npassages containing name entities, which appeared\nin both the question and the passage. However,\nperformance suffers for questions that are only rel-\nevant to a single obscure passage.\nThe unsupervised learning approaches of TS-\nDAE and SimCSE both improve results compared\nto other methods we experimented with Arabic\nLMs. TSDAE in particular excels at ranking the\nrelevant passages higher, leading to better MRR.\nThis shows the value of its robust representations\nlearned by reconstructing passages. The unsuper-\nvised fine-tuning allows the model to generalize bet-\nter despite the limited size of the Quranic dataset.\n4 Task B: Reading Comprehension\nGiven a Quranic passage that consists of consecu-\ntive verses in a specific Surah 8 of the Quran and a\n3AraBERT-TSDAE-Contrastive (GYM_Run1)\n4AraBERT-SimCSE-Contrastive (GYM_Run0)\n5AraBERT-SimCSE-Triplet (GYM_Run2)\n6Auto-Encoders\n7Question-Passage\n8A surah is a chapter in the Quran consisting of a set of\nverses revealed to the Islamic prophet Muhammad. There are\n114 surahs in the Quran.\n716\nfree-text question posed in MSA over that passage,\na system is required to extract all answers to that\nquestion that is stated in the given passage.\n4.1 Data\nFor Task B, we use Qur’anic Reading Comprehen-\nsion Dataset (QRCD v1.2 ) (Malhas and Elsayed,\n2022, 2020; Malhas et al., 2022) which consists of\nquestion-passage pairs combined with one or more\nannotated answers (15% of the questions have no\nanswers). The dataset distribution is illustrated in\nTable 4.\nSplit % #Q #Q-P #Q-P-A\nTraining 70% 174 992 1179\nDevelopment 10% 25 163 220\nTest 20% 51 431 -\nAll 100% 250 1586 1399\nTable 4: Task B dataset distribution. #Q shows the num-\nber of questions. #Q-P shows the number of question-\npassage pairs. #Q-P-A shows the number of question-\npassage-answer triplets in the dataset.\n4.2 System\nOur solution for Task B is using the AraElectra-\nbased model (Antoun et al., 2021) that is pre-\ntrained on general domain Arabic language data.\nWe propose two strategies for fine-tuning this\nmodel on the QRCD v1.2 dataset in addition to\nother complimentary datasets. The description of\neach model’s training settings is summarized in Ta-\nble 5. The hardware used is a GPU.1080Ti.xlarge\nwith 31.3GB RAM. In the following sections, we\nbriefly explain how we train each model.\n4.3 Models Specifications\nWe chose AraElectra-SQuADv2 (Ahmed, 2023a)\nmodel which is fine-tuned using the Arabic-\nSQuADv2.0 (Ahmed, 2023b) dataset. Specifically,\nAraElectra-SQuADv2 is the AutoModelForQues-\ntionAnswering model from the transformers library\nin HuggingFace initialized with AraElectra model\n(Antoun et al., 2021). This model was trained\non question-answer pairs, including unanswerable\nquestions targeting QA task. We further fine-tuned\nthis model using the QRCD v1.2 dataset (submitted\nas GYM_Run0).\nWe select AraElectra-TyDiQA (Ahmed et al.,\n2022) which fine-tuned on TyDi QA (Clark et al.,\n2020) dataset. Similarly, we fine-tuned this model\non the QRCD v1.2 (submitted as GYM_Run1).\nWe incorporated ensemble modeling which is\na machine-learning technique for combining mul-\ntiple models in the prediction process. More\nspecifically, by finding the top 10 answers us-\ning both AraElectra-SQuADv2 and AraElectra-\nTyDiQA, we can aggregate the given scores for\nall specified spans that are common among these\nruns/models (submitted as GYM_ensemble). The\naggregation process works as follows:\nI. We consider the output results of both\nAraElectra-SQuADv2 and AraElectra-\nTyDiQA models for each given question.\n– If the answers are the same, we sum the\nmodel’s output scores.\n– Otherwise, we keep the answer without\nchanging the score.\nII. Finally, based on the newly calculated scores,\nwe sort the output results of the two models\nand consider the top 10 outputs as the final\noutput of the ensemble model.\nAraElec-SQuADv2 AraElec-TyDiQA\nSQuADv2 /enc-33 -\nTyDiQA - /enc-33\nQRCD v1.2 /enc-33 /enc-33\nEpoch 30 1\nBatch Size 4 8\nMax Seq Len 9 256 256\nDoc Strid 10 64 64\nTable 5: Task B train setting\n4.4 Results\nReading Comprehension is evaluated with partial\nAverage Precision (pAP), which accounts for par-\ntial matches and multiple answers. Our best con-\nfiguration, AraElectra-SQuADv2, beats the task’s\nbaseline by 23.0% and reaches 48.5% pAP@10\non the dev set and 13.5% while achieving 46.1%\npAP@10 on the test set (Table 6). Our experiments\nindicate that in comparison with other models, in-\ncluding an AraBERT, the AraElectra model gives\nbetter results on the Qur’anQA Task. Also, the use\nof the Arabic-SQuADv2.0 dataset, which is similar\nto QRCD v1.2, significantly improves the result.\n4.5 Discussion\nThe results demonstrate that transfer learning\nfrom large Arabic NLP datasets (TyDiQA and\nSQuADv2) is an effective strategy for adapting\nmodels to Qur’anQA despite limited task-specific\n9The maximum length of a feature.\n10The authorized overlap between two part of the context\nwhen splitting is needed.\n717\nModel Dev Test\nAraElectra-SQuADv2 0.485 0.461\nEnsemble 0.481 0.458\nAraElectra-TyDiQA 0.431 0.430\nBaseline 0.255 0.326\nTable 6: Task B pAP@10 result\ntraining data. Pre-training on broad domains equips\nmodels like AraElectra with useful linguistic and\nsemantic knowledge of Arabic that transfers well to\nQur’anQA. Fine-tuning on the small QRCD v1.2\ndataset provides the final layer of adaptation to\nhandle Quranic syntax, terminology, and reasoning\nrequirements.\nOur best approach leverages Arabic SQuADv2\nand is able to effectively identify questions with\nmultiple answers and specify the start and end to-\nkens of each answer. Among the answers, there\nwere cases where the predicted answers overlap;\nhence, having a mechanism to handle overlapping\npredictions could improve the results. Addition-\nally, it would be beneficial to optimize the model’s\nconfidence scores for predicting start and end to-\nkens, such that falling below a threshold indicates\nno answer.\nOverall, our results demonstrate promising multi-\nspan extraction capabilities gained via pre-training\non SQuADv2 data. However, enhancements to pre-\ndiction post-processing and confidence modeling\ncould further improve the handling of overlap and\nno-answer cases. This would move towards more\nhuman-like discernment of when extracted snippets\nrepresent valid or invalid answers.\nConclusion\nThis work demonstrates adapting LMs to\nQur’anQA with limited data. Key techniques\ninclude unsupervised fine-tuning, negative sample\nextracting with BM25, multi-tasking, and transfer\nlearning. For passage retrieval, unsupervised\nstrategies like TSDAE and SimCSE improve\nranking over training from scratch. In reading\ncomprehension, leveraging Arabic SQuAD allows\nAraElectra to excel at span prediction despite\nscarce Quran annotations. Overall, leveraging addi-\ntional datasets benefited models in both sub-tasks.\nWe provide insights into tailoring state-of-the-art\nNLP techniques to learn specialized behavior for\nmachine comprehension of the Quran’s semantics\ngiven modest labeled data.\nLimitations\nThe main constraint we faced was the lack of la-\nbeled data. To overcome this, we used similar non-\nQuranic datasets. While this affected the model’s\nquality during training, it improved its ability to\nperform well on unseen data.\nAn important aspect to consider in the context of\nthis research is the wealth of Tafsirs11 available for\nthe Quran, authored by religious scholars spanning\ndifferent time periods and languages. These Tafsirs\nprovide invaluable insights into the interpretations\nand nuances of the Quranic text, shedding light on\nthe historical, linguistic, and cultural contexts in\nwhich the verses were revealed. The Quran, being a\ndeeply layered and intricate scripture, often carries\nlayers of meaning that extend beyond the literal\nwords and Tafsirs help unravel these layers. Incor-\nporating Tafsirs into the model’s training data could\nenable it to better capture these nuanced interpreta-\ntions and subtle connections, potentially leading to\nmore accurate and contextually informed question-\nanswering for vintage texts like the Quran.\nAnother challenge in passage retrieval we en-\ncountered was when the input question had no cor-\nresponding answer in the Quranic passages. In\nthese cases, the model’s performance suffered be-\ncause we had to apply a threshold to the output\nscores, which were not fine-tuned specifically for\nthis task. Additionally, the difference between the\nquestions in Modern Standard Arabic (MSA) and\nthe diverse variations of Quranic texts presented\nanother challenge. One additional challenge we\nfaced in this task was the lack of negative passages.\nTo address this, we had to generate a set of neg-\native passages using the BM25 method, as previ-\nously explained in detail. However, the quality of\nthese negative passages plays a crucial role in the\nmodel’s training. One approach we considered was\nto treat all passages, except the positive ones, as\nnegatives. However, due to the imbalance between\npositive and negative samples and GPU limitations,\nwe decided not to pursue this approach. But this\napproach can be examined in future work.\nAcknowledgements\nWe’d like to thank the organizers for introducing\nthis task. We are glad that we had the opportunity\nto engage more in the challenges and progress in\nthe information retrieval task.\n11Tafsir is Quranic exegesis that explains, interprets, con-\ntextualizes, or comments on Quran verses.\n718\nReferences\nBasem Ahmed, Motaz Saad, and Eshrag A. Refaee.\n2022. QQATeam at qur’an QA 2022: Fine-tunning\nArabic QA models for qur’an QA task. In Proceed-\ninsg of the 5th Workshop on Open-Source Arabic\nCorpora and Processing Tools with Shared Tasks on\nQur’an QA and Fine-Grained Hate Speech Detec-\ntion, pages 130–135, Marseille, France. European\nLanguage Resources Association.\nZeyad Ahmed. 2023a. Arabic Machine Read-\ning Comprehension: Effective Models and\nIntroducing Arabic-SQuAD v2.0. https:\n//github.com/zeyadahmed10/Arabic-MRC,\nhttps://huggingface.co/ZeyadAhmed/\nAraElectra-Arabic-SQuADv2-QA . Original-\ndate: 2021-11-04T18:03:17Z.\nZeyad Ahmed. 2023b. Arabic SQuAD v2.0\nDataset based on the popular SQuADv2.0\nwith unanswered questions for more challenging\ntask. https://huggingface.co/datasets/\nZeyadAhmed/Arabic-SQuADv2.0. Original-date:\n2022-06-29T18:03:17Z.\nWissam Antoun, Fady Baly, and Hazem Hajj. Arabert:\nTransformer-based model for arabic language under-\nstanding. In LREC 2020 Workshop Language Re-\nsources and Evaluation Conference 11–16 May 2020,\npage 9.\nWissam Antoun, Fady Baly, and Hazem Hajj. 2021.\nAraELECTRA: Pre-training text discriminators for\nArabic language understanding. In Proceedings of\nthe Sixth Arabic Natural Language Processing Work-\nshop, pages 191–195, Kyiv, Ukraine (Virtual). Asso-\nciation for Computational Linguistics.\nJonathan H. Clark, Eunsol Choi, Michael Collins, Dan\nGarrette, Tom Kwiatkowski, Vitaly Nikolaev, and\nJennimaria Palomaki. 2020. TyDi QA: A benchmark\nfor information-seeking question answering in ty-\npologically diverse languages. Transactions of the\nAssociation for Computational Linguistics.\nXingping Dong and Jianbing Shen. 2018. Triplet loss\nin siamese network for object tracking. In Proceed-\nings of the European Conference on Computer Vision\n(ECCV).\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.\nSimCSE: Simple contrastive learning of sentence\nembeddings. In Empirical Methods in Natural Lan-\nguage Processing (EMNLP).\nR. Hadsell, S. Chopra, and Y . LeCun. 2006. Dimension-\nality reduction by learning an invariant mapping. In\n2006 IEEE Computer Society Conference on Com-\nputer Vision and Pattern Recognition (CVPR’06),\nvolume 2, pages 1735–1742.\nMatthew Henderson, Rami Al-Rfou, Brian Strope, Yun-\nHsuan Sung, László Lukács, Ruiqi Guo, Sanjiv Ku-\nmar, Balint Miklos, and Ray Kurzweil. 2017. Effi-\ncient natural language response suggestion for smart\nreply. ArXiv, abs/1705.00652.\nRana Malhas and Tamer Elsayed. 2020. Ayatec: Build-\ning a reusable verse-based test collection for arabic\nquestion answering on the holy qur’an. ACM Trans.\nAsian Low-Resour. Lang. Inf. Process., 19(6).\nRana Malhas and Tamer Elsayed. 2022. Arabic ma-\nchine reading comprehension on the holy qur’an us-\ning cl-arabert. Information Processing Management,\n59(6):103068.\nRana Malhas, Watheq Mansour, and Tamer Elsayed.\n2022. Qur’an QA 2022: Overview of the First Shared\nTask on Question Answering over the Holy Qur’an.\nIn Proceedings of the 5th Workshop on Open-Source\nArabic Corpora and Processing Tools (OSACT5) at\nthe 13th Language Resources and Evaluation Con-\nference (LREC 2022), pages 79–87.\nRana Malhas, Watheq Mansour, and Tamer Elsayed.\n2023. Qur’an QA 2023 Shared Task: Overview\nof Passage Retrieval and Reading Comprehension\nTasks over the Holy Qur’an. In Proceedings of the\nFirst Arabic Natural Language Processing Confer-\nence (ArabicNLP 2023), Singapore.\nRana R Malhas. 2023. ARABIC QUESTION ANSWER-\nING ON THE HOLY QUR’AN. Ph.D. thesis.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing. Associa-\ntion for Computational Linguistics.\nMarwan N. Swar. 2007. Mushaf Al-Tafseel Al-\nMawdoo’ee. Dar Al-Fajr Al-Islami, Damascus.\nKexin Wang, Nils Reimers, and Iryna Gurevych. 2021.\nTSDAE: Using transformer-based sequential denois-\ning auto-encoderfor unsupervised sentence embed-\nding learning. In Findings of the Association for\nComputational Linguistics: EMNLP 2021, pages\n671–688, Punta Cana, Dominican Republic. Associa-\ntion for Computational Linguistics.\nXinyu Zhang, Xueguang Ma, Peng Shi, and Jimmy Lin.\n2021. Mr. TyDi: A multi-lingual benchmark for\ndense retrieval. In Proceedings of the 1st Workshop\non Multilingual Representation Learning, pages 127–\n137, Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\n719",
  "topic": "Question answering",
  "concepts": [
    {
      "name": "Question answering",
      "score": 0.8681581020355225
    },
    {
      "name": "Computer science",
      "score": 0.8254634737968445
    },
    {
      "name": "Baseline (sea)",
      "score": 0.7565736770629883
    },
    {
      "name": "Task (project management)",
      "score": 0.6925128698348999
    },
    {
      "name": "Natural language processing",
      "score": 0.6717723608016968
    },
    {
      "name": "Reading comprehension",
      "score": 0.6433842182159424
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6294903755187988
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.5774708986282349
    },
    {
      "name": "Sentence",
      "score": 0.5607260465621948
    },
    {
      "name": "Transfer of learning",
      "score": 0.5604183077812195
    },
    {
      "name": "Reading (process)",
      "score": 0.5522447228431702
    },
    {
      "name": "Test (biology)",
      "score": 0.5124345421791077
    },
    {
      "name": "Language model",
      "score": 0.5034329295158386
    },
    {
      "name": "Encoder",
      "score": 0.487913578748703
    },
    {
      "name": "Test set",
      "score": 0.4610888361930847
    },
    {
      "name": "Information retrieval",
      "score": 0.3545439541339874
    },
    {
      "name": "Linguistics",
      "score": 0.12159070372581482
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Oceanography",
      "score": 0.0
    },
    {
      "name": "Geology",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I67009956",
      "name": "Iran University of Science and Technology",
      "country": "IR"
    },
    {
      "id": "https://openalex.org/I141945490",
      "name": "University of British Columbia",
      "country": "CA"
    }
  ]
}