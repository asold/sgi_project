{
  "title": "Using a large language model (ChatGPT) to assess risk of bias in randomized controlled trials of medical interventions: protocol for a pilot study of interrater agreement with human reviewers",
  "url": "https://openalex.org/W4386533461",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5028581016",
      "name": "Christopher James Rose",
      "affiliations": [
        "Norwegian Institute of Public Health"
      ]
    },
    {
      "id": "https://openalex.org/A5051180204",
      "name": "Martin Ringsten",
      "affiliations": [
        "Lund University"
      ]
    },
    {
      "id": "https://openalex.org/A5031955129",
      "name": "Julia Bidonde",
      "affiliations": [
        "University of Saskatchewan",
        "Norwegian Institute of Public Health"
      ]
    },
    {
      "id": "https://openalex.org/A5003504334",
      "name": "Julie Glanville",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5012906279",
      "name": "Rigmor C. Berg",
      "affiliations": [
        "Norwegian Institute of Public Health"
      ]
    },
    {
      "id": "https://openalex.org/A5060903714",
      "name": "Chris Cooper",
      "affiliations": [
        "University of Bristol"
      ]
    },
    {
      "id": "https://openalex.org/A5001163466",
      "name": "Ashley Elizabeth Muller",
      "affiliations": [
        "Norwegian Institute of Public Health"
      ]
    },
    {
      "id": "https://openalex.org/A5032640730",
      "name": "Hans Bugge Bergsund",
      "affiliations": [
        "Norwegian Institute of Public Health"
      ]
    },
    {
      "id": "https://openalex.org/A5067847083",
      "name": "Jos√© F. Meneses-Ech√°vez",
      "affiliations": [
        "Universidad Santo Tom√°s",
        "Norwegian Institute of Public Health"
      ]
    },
    {
      "id": "https://openalex.org/A5085675312",
      "name": "Thomas Potrebny",
      "affiliations": [
        "Western Norway University of Applied Sciences"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2461177968",
    "https://openalex.org/W2011932878",
    "https://openalex.org/W2098923148",
    "https://openalex.org/W2970684805",
    "https://openalex.org/W2994918429",
    "https://openalex.org/W3036957975",
    "https://openalex.org/W4213127247",
    "https://openalex.org/W4312018506",
    "https://openalex.org/W2271587360",
    "https://openalex.org/W3207434859",
    "https://openalex.org/W3149778443",
    "https://openalex.org/W2184378182",
    "https://openalex.org/W3006673017",
    "https://openalex.org/W3128307363",
    "https://openalex.org/W4281621725",
    "https://openalex.org/W4281827825",
    "https://openalex.org/W2902105843",
    "https://openalex.org/W2761773860",
    "https://openalex.org/W3208498859",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2843010082",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W6850287543",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W2928947675",
    "https://openalex.org/W1994466426",
    "https://openalex.org/W2955860789",
    "https://openalex.org/W4308934764",
    "https://openalex.org/W4316810661",
    "https://openalex.org/W2069378996",
    "https://openalex.org/W4210607262",
    "https://openalex.org/W2164777277",
    "https://openalex.org/W2144504916",
    "https://openalex.org/W2008285675",
    "https://openalex.org/W3022125597",
    "https://openalex.org/W2921498258",
    "https://openalex.org/W2919491917",
    "https://openalex.org/W3015598826",
    "https://openalex.org/W4321472284",
    "https://openalex.org/W4311673974",
    "https://openalex.org/W4321276774",
    "https://openalex.org/W4402264526",
    "https://openalex.org/W3091351275",
    "https://openalex.org/W4210661005",
    "https://openalex.org/W4214559180",
    "https://openalex.org/W2145482038"
  ],
  "abstract": "Abstract Background Risk of bias (RoB) assessment is an essential part of systematic reviews of treatment effect. RoB assessment requires reviewers to read and understand each eligible trial and depends on a sound understanding of trial methods and RoB tools. RoB assessment is a highly skilled task, subject to human error, and can be time-consuming and expensive. Machine learning-based tools have been developed to streamline the RoB process using relatively simple models trained on limited corpuses. ChatGPT is a conversational agent based on a large language model (LLM) that was trained on an internet-scale corpus and demonstrates human-like abilities in many areas, including healthcare. LLMs might be able to perform or support systematic reviewing tasks such as assessing RoB, which may reduce review costs, time to completion, and error. Objectives To assess interrater agreement in overall (cf. domain-level) RoB assessment between human reviewers and ChatGPT, in randomized controlled trials of interventions within medicine. Methods We will randomly select 100 individually- or cluster-randomized, parallel, two-arm trials of medical interventions from recent Cochrane systematic reviews that have been assessed using the RoB1 or RoB2 family of tools. We will exclude reviews and trials that were performed under emergency conditions (e.g., COVID-19) that may not exhibit typical RoB, as well as public health and welfare interventions. We will use 25 of the trials and human RoB assessments to engineer a ChatGPT prompt for assessing overall RoB, based on trial methods text. We will obtain ChatGPT assessments of RoB for the remaining 75 trials and human assessments. We will then estimate interrater agreement. Results The primary outcome for this study is overall human-ChatGPT interrater agreement. We will report observed agreement with an exact 95% confidence interval, expected agreement under random assessment, Cochrane‚Äôs ùúÖ, and a p -value testing the null hypothesis of no difference in agreement. Several other analyses are also planned. Conclusions This study is likely to provide the first evidence on interrater agreement between human RoB assessments and those provided by LLMs and will inform subsequent research in this area.",
  "full_text": "Page 1/20\nUsing a large language model (ChatGPT) to assess risk ofbias in randomized controlled trials of medicalinterventions: protocol for a pilot study of interrateragreement with human reviewers\nChristopher James Rose¬† ( ÔÉ† cjro@fhi.no )\nNorwegian Institute of Public Health, Oslo, Norway https://orcid.org/0000-0001-6457-8168\nMartin Ringsten¬†\nLund University, Lund, Sweden\nJulia Bidonde¬†\nNorwegian Institute of Public Health, Oslo, Norway and University of Saskatchewan, Canada\nJulie Glanville¬†\nGlanville.info, York, United Kingdom\nRigmor C Berg¬†\nNorwegian Institute of Public Health, Oslo, Norway and Arctic University of Troms√∏, Troms√∏, Norway\nChris Cooper¬†\nUniversity of Bristol, Bristol, United Kingdom\nAshley Elizabeth Muller¬†\nNorwegian Institute of Public Health, Oslo, Norway\nHans Bugge Bergsund¬†\nNorwegian Institute of Public Health, Oslo, Norway\nJose F Meneses-Echavez¬†\nNorwegian Institute of Public Health, , Oslo, Norway and Universidad Santo Tom√°s, Bogot√°, Colombia\nThomas Potrebny¬†\nWestern Norway University of Applied Sciences, Bergen, Norway\nResearch Article\nKeywords: Systematic reviewing, risk of bias, arti\u0000cial intelligence, machine learning, large language model, ChatGPT\nPosted Date: September 8th, 2023\nDOI: https://doi.org/10.21203/rs.3.rs-3288515/v1\nLicense: Ôâû  Ôìß  This work is licensed under a Creative Commons Attribution 4.0 International License. ¬† Read Full License\nPage 2/20\nAbstract\nBackground\nRisk of bias (RoB) assessment is an essential part of systematic reviews of treatment effect. RoB assessment requires\nreviewers to read and understand each eligible trial and depends on a sound understanding of trial methods and RoB\ntools. RoB assessment is a highly skilled task, subject to human error, and can be time-consuming and expensive.\nMachine learning-based tools have been developed to streamline the RoB process using relatively simple models\ntrained on limited corpuses. ChatGPT is a conversational agent based on a large language model (LLM) that was\ntrained on an internet-scale corpus and demonstrates human-like abilities in many areas, including healthcare. LLMs\nmight be able to perform or support systematic reviewing tasks such as assessing RoB, which may reduce review costs,\ntime to completion, and error.\nObjectives\nTo assess interrater agreement in overall (cf. domain-level) RoB assessment between human reviewers and ChatGPT, in\nrandomized controlled trials of interventions within medicine.\nMethods\nWe will randomly select 100 individually- or cluster-randomized, parallel, two-arm trials of medical interventions from\nrecent Cochrane systematic reviews that have been assessed using the RoB1 or RoB2 family of tools. We will exclude\nreviews and trials that were performed under emergency conditions (e.g., COVID-19) that may not exhibit typical RoB, as\nwell as public health and welfare interventions. We will use 25 of the trials and human RoB assessments to engineer a\nChatGPT prompt for assessing overall RoB, based on trial methods text. We will obtain ChatGPT assessments of RoB\nfor the remaining 75 trials and human assessments. We will then estimate interrater agreement.\nResults\nThe primary outcome for this study is overall human-ChatGPT interrater agreement. We will report observed agreement\nwith an exact 95% con\u0000dence interval, expected agreement under random assessment, Cochrane‚Äôs ùúÖ , and a p-value\ntesting the null hypothesis of no difference in agreement. Several other analyses are also planned.\nConclusions\nThis study is likely to provide the \u0000rst evidence on interrater agreement between human RoB assessments and those\nprovided by LLMs and will inform subsequent research in this area.\nIntroduction\nEvidence syntheses, such as systematic reviews (SRs), guidelines, and health technology assessments (HTAs), routinely\nassess the degree to which the methods used by randomized controlled trials (RCTs), and other study designs, may be\nexpected to result in biased estimates of treatment effect. Assessing risk of bias (RoB) is important because, for\nexample, treatment effect estimates have been shown to be exaggerated in trials with inadequate or unclear random\nPage 3/20\nsequence generation and allocation concealment [1], [2]. Two of the available tools for RoB assessment are RoB1 and\nRoB2 [3], [4].\nWhile assessing RoB is an important part of evidence synthesis, it can also be resource-intensive and potentially error-\nprone because reviewers are required to read and understand the methods reported in the studies; have a thorough\nunderstanding of good trial design, analysis, and reporting; be able to use a RoB tool su\u0000ciently well to reach an\naccurate and defensible assessment; and then be able to use and report these assessments within the evidence\nsynthesis. These requirements set a high bar and even the best reviewers make mistakes and disagree with one another\n[5], [6]. Such discrepancies may lead to biases in the conclusions of an evidence synthesis and potentially suboptimal\ntreatment. There are strong economic and ethical reasons to identify, evaluate, and implement methods that can reduce\nresource use while maintaining and potentially improving evidence synthesis quality.\nOne approach to reduce resource use that is receiving increased attention is semi or full automation via machine\nlearning and arti\u0000cial intelligence (ML/AI; [7]‚Äì[11]). For example, RobotReviewer [12] was developed to assess risk of\nbias in clinical trials. Studies comparing RobotReviewer to human assessments have found promising results on\naccuracy [12]‚Äì[16], time used [15], [17], and usability [17]. Other studies have tested automated RoB approaches for\nanimal studies, including one tool utilizing text mining and regular expressions [18] and another comparing multiple ML\nmodels [19]. However, to our knowledge, none of the ML/AI tools that are currently available for routine SR and HTA\nproduction are based on the most advanced methods being used in ML/AI today, namely large language models (LLMs;\nmodern arti\u0000cial neural network architectures with billions of parameters trained on internet-scale corpuses).\nChatGPT (OpenAI, San Francisco, California, USA) is a conversational agent based on an LLM from the GPT-3.5 series\n[20]. A conversational agent is a system that allows a user (i.e., a human) to engage in interactive communication ‚Äî\ntypically text-based ‚Äî with a machine using natural language. Conversational agents are increasingly used in many\nareas, including medicine [21]. ChatGPT appears to mark a watershed in the development of conversational agents, a\ntype of system that was considered so challenging to develop that it is the basis for Alan Turing‚Äôs imitation game, a test\nto determine whether a machine can exhibit intelligent behavior that is indistinguishable from that of a human [22].\nWhile the model underpinning ChatGPT is perhaps one of the most complex created, what it does is relatively simple:\ngiven textual input (called a prompt), ChatGPT predicts a reply to the prompt that is statistically likely given the prompt\nand the data the model was trained upon. Conversation is facilitated by alternating the party (human or ChatGPT) that\n‚Äúpredicts‚Äù the next reply.\nChatGPT is unlike other automated tools for RoB assessment in three important ways. First, ChatGPT is a language\nmodel. In other words, the system has been developed to emulate human language, not RoB assessments\n(classi\u0000cations). Second, ChatGPT is a general-purpose tool, rather than having been developed to perform the speci\u0000c\ntask of RoB assessment. Third, ChatGPT has been trained on an internet-scale corpus covering many areas of\nknowledge, rather than a relatively small training set that is narrowly focused on RoB assessment. While these\ncharacteristics may appear to make ChatGPT ill-suited to the specialized task of RoB assessment, recent research\nsuggests that ML/AI models that have been trained across many areas of knowledge can perform speci\u0000c tasks better\nthan models trained to do those tasks alone [23], akin to the way that humans can leverage and generalize their existing\nunderstanding to new areas. However, there is also contrary evidence in the context of parsing and reasoning about\nclinical text from electronic health records [24].\nChatGPT can perform some remarkable feats. For example, performing at or near the passing threshold for all three\nUnited States medical licensing exams [25], answering questions on complex topics such as statistical methodology\n(Fig.¬†1), offering opinions on Taylor Swift‚Äôs predominance in popular music in the vernacular of a bratty teenage girl\n(Fig.¬†2), emulating a UNIX command line terminal making an HTTP request to an emulation of ChatGPT itself [26], and\nPage 4/20\n‚Äî of relevance to this protocol ‚Äî summarizing and making judgements about RoB in trials based on methods text taken\nfrom journal articles (Appendix). However, like any system or person, ChatGPT makes mistakes (Fig.¬†1) and\nundoubtedly has biases of its own. In particular, LLMs have a well-known failure mode in which they can ‚Äúhallucinate‚Äù\nand generate convincing but incorrect responses.\nThere is no guarantee that ChatGPT‚Äôs responses will always be logical, correct, consistent, or that it will respond in ways\nthat are free from biases. The same can be said about human reviewers. Human-human agreement in RoB assessment\nhas been estimated to range between 16% and 81% [6], [27], [28]. We are unaware of any research that assesses\nagreement in overall RoB assessment between human reviewers and LLMs. In our limited experimentation ChatGPT\nappears able to provide reasoned assessments of RoB, but also gave two authors different RoB assessments (low and\nunclear) for a study on dexmedetomidine in term neonates with hypoxic-ischemic encephalopathy [29]. ChatGPT based\nits assessments in part on the study‚Äôs reported use of random participant allocation. However, the study was not in fact\na randomized trial, as documented in a correction to the original publication. The correction was prompted by a human\nreviewer who identi\u0000ed questionable elements within the randomization. They contacted the study authors and\ndiscovered that the study was in fact not randomized [30]. ChatGPT was unable to infer from the information reported\nthat it was unlikely that randomization had been used and that the original study had therefore perhaps misreported the\nmethod used.\nThe main potential bene\u0000ts of using a system like ChatGPT to perform or support review tasks include reduced use of\nhuman effort (i.e., lower costs); reduced time to project completion (i.e., being able to provide evidence syntheses more\nquickly [31]); more consistent performance compared to human reviewers; improved repeatability (i.e., being able to\nrepeat a RoB assessment at a later date to verify results); and being able to redirect human effort to more challenging\ntasks that cannot be performed by machines, such as those requiring high levels of creativity or empathy.\nThe aims of this study are to estimate human-ChatGPT interrater agreement in assessments of overall (cf. domain-\nlevel) RoB in trials of medical interventions, assess ChatGPT intrarater agreement, and to collect data to support\nsubsequent research (see Discussion). This work is part of ongoing horizon scanning work at the Norwegian Institute of\nPublic Health to identify and evaluate promising new ML/AI technologies that can be used to improve our evidence\nsynthesis work. While one motivation for this work is to reduce resource use and time-to-completion, we do not expect\nthis to be achievable using ChatGPT‚Äôs current user interface and the manual copy-and-paste work\u0000ow described herein.\nIf LLMs such as ChatGPT are ultimately found to be useful for evidence synthesis, we anticipate they would be\nimplemented into existing or new software tools.\nMethods\nWe will assess agreement between human consensus-based overall RoB assessments of trials obtained from Cochrane\nSRs and overall RoB assessments made by ChatGPT. The unit of analysis is trial. The following subsections describe\neligibility criteria, data sources and management, outcomes, data extraction, prompt engineering, ChatGPT RoB\nassessment, power calculation, and statistical analyses. We followed the Guidelines for Reporting Reliability and\nAgreement Studies (GRRAS; [32]) checklist (Supplementary Materials).\nEligibility criteria for systematic reviews\nWe will identify trials from new or updated Cochrane SRs on the effectiveness of medical interventions (e.g., for cancer,\ninfection, diabetes mellitus) meeting the following criteria. We will include reviews that included at least one eligible trial\n(see eligibility criteria for trials, below). We will include SRs that present human consensus-based RoB assessments at\nPage 5/20\nthe level of trial or primary outcome for bene\u0000t (see Discussion). We de\u0000ne consensus to mean that at least one\nreviewer assessed RoB and at least two reviewers agreed on the \u0000nal assessment. We will include reviews that\nassessed RoB using Cochrane RoB1 or an appropriate tool in the ‚ÄúRoB2 family‚Äù of tools (e.g., RoB2 for cluster-\nrandomized trials) and exclude reviews that have used heavily modi\u0000ed versions of the tools. We will exclude reviews\nthat were performed under emergency conditions (e.g., COVID-19, Ebola, mpox1). While such reviews are incredibly\nimportant, their urgency means the trials they include may be at high RoB, and trial reporting and RoB assessment may\nnot have been as thorough as for non-emergency settings.\nWe will also exclude trials (and hence SRs) on public health or welfare interventions (i.e., those typically directed\ntowards populations rather than individuals). Again, these trials are important, but in our experience, they can be\nreported quite differently to interventions directed towards individuals. We will therefore exclude SRs published by the\nfollowing Cochrane Review Groups2: Effective Practice and Organisation of Care; Public Health; Methods; and\nConsumers and Communication. We will exclude SRs and trials on welfare or public health interventions published in\nthe included review groups by consensus.\nWe will exclude SRs that used automation (e.g., RobotReviewer) to assess RoB, irrespective of whether automation was\nused alone or alongside human assessment. We will not place any language restrictions on reviews, however we will\nexclude reviews if we are unable to extract the necessary data.\nEligibility criteria for trials\nWe will include individually- or cluster-randomized two-arm parallel RCTs on the effectiveness of medical interventions.\nWe chose to exclude trials with more than two arms because they can be substantially more complicated than two-arm\ntrials. ChatGPT (not to mention human reviewers) may struggle to understand how the multiple comparisons may differ\nin risk of bias (see RoB2, which requires that each result be judged separately). We will include trials that de\u0000ne bene\u0000t\nas their primary outcome and will exclude trials that de\u0000ne safety (i.e., harms) as their primary outcome. We will exclude\ntrials if the review we used to identify the trial used an inappropriate RoB tool (e.g., if RoB1 was used to assess a\ncluster-randomized trial, rather than the version of RoB2 designed to assess cluster trials). We will not place any\nlanguage restrictions on the trials because ChatGPT can understand multiple languages. However, we will exclude a\ntrial if we cannot determine the section of the trial report that presents the methods used (see Data extraction). Table¬†1\nsummarizes the inclusion and exclusion criteria.\nPage 6/20\nTable 1\nSummary of review and trial inclusion and exclusion criteria\n¬† Inclusion criteria Exclusion criteria\nSystematicreviews ‚Ä¢ Effectiveness of medical interventions\n‚Ä¢ Include‚Äâ ‚â• ‚Äâ1 cluster or individually randomizedparallel two-arm RCT\n‚Ä¢ Human consensus-based RoB assessments\n‚Ä¢ Use of RoB1 or an appropriate tool in the ‚ÄúRoB2family‚Äù\n‚Ä¢ Overall RoB assessment at the level of trial orprimary outcome for bene\u0000t\n‚Ä¢ Any language (see text)\n‚Ä¢ Use of heavily modi\u0000ed versions of theRoB tools\n‚Ä¢ Reviews performed under emergencyconditions\n‚Ä¢ Public health or welfare reviews\n‚Ä¢ Reviews that used automation to assessRoB\nTrials ‚Ä¢ Effectiveness of medical interventions\n‚Ä¢ Cluster- or individually randomized parallel two-armRCTs\n‚Ä¢ Primary outcome assesses bene\u0000t\n‚Ä¢ Any language (see text)\n‚Ä¢ Primary outcome assesses harm\n‚Ä¢ Estimates the effect of starting andadhering to treatment\n‚Ä¢ Inappropriate RoB tool used in review\n‚Ä¢ Not possible to identify a methodssection\nSystematic reviews and trials will be screened with respect to the criteria above in duplicate by two authors (two of MR,\nJG, RCB, and JFM-E). Screening will be performed in four stages: title and abstract (systematic reviews), full text\n(systematic reviews), title and abstract (trials), and \u0000nally full text (trials). Any disagreements will be resolved by\nconsensus or adjudication by a third author.\nData sources and management\nBecause we simply need a reasonably representative sample of trials, we will not perform a systematic literature search.\nInstead, we (CC, JB, JG) will take a random sample of SRs from the Cochrane Database of Systematic Reviews\npublished or updated between October 2011 (the date the RoB1 tool was published) to April 2023. We will use a ‚Äúbatch\nsampling‚Äù strategy that will be repeated until data for a su\u0000cient number of trials have been included (see power\ncalculation for the number of trials required). Each batch of 10 randomly selected reviews will be assessed for eligibility.\nFrom a given eligible review, one eligible trial will be selected at random for inclusion in our study. A review will be\nexcluded if it includes no eligible trials. We will then obtain the trial reports. If the sampling strategy would include an\nalready-included trial, or we cannot obtain a trial report, we will select the next eligible review or trial using the procedure\ndescribed above.\nOutcomes\nIn this work, we are not interested in ChatGPT‚Äôs ability to assess RoB with respect to the bias domains de\u0000ned by the\nRoB1 and RoB2 tools, but in whether ChatGPT has any ability to assess RoB. ChatGPT may not understand or follow\nthe Cochrane RoB tools in the same way as human reviewers. We will therefore not ask ChatGPT to assess RoB with\nrespect to bias domains but to assess overall RoB using three categories (high, unclear, and low risk of bias). Based on\nour limited experimentation, ChatGPT may use information outside the RoB1 or RoB2 bias domains, such as whether\nthe trial was funded by a pharmaceutical company (which could be considered in the ‚Äúother bias‚Äù domain of RoB1).\nPage 7/20\nSimilarly, human reviewers may consciously or unconsciously make judgements using information that is not within\nthe scope of the RoB tool they are using.\nThe primary outcome for this study is human-ChatGPT agreement in overall RoB assessment. If a review does not\npublish an overall RoB assessment, we will use the criteria de\u0000ned by RoB2 to impute an overall assessment from\nindividual domain-level assessments. For example, if the human consensus assessment is that a study is at high RoB\nfor at least one domain, we will impute that it the overall RoB is high. The RoB1 tool and the RoB2 family of tools de\u0000ne\ndifferent bias domains and levels of risk assessment. For example, the ‚Äúuncertain‚Äù category de\u0000ned by RoB1 and the\n‚Äúsome concerns‚Äù category de\u0000ned by RoB2 are distinct but have some commonalities. We will interpret the ‚Äúunclear‚Äù\ncategory to correspond to ‚Äúuncertain‚Äù and ‚Äúsome concerns‚Äù to facilitate analysis of interrater agreement between\nhuman reviewers and ChatGPT and across RoB tools (see Discussion).\nWe hypothesize that ChatGPT may be unlikely to use the ‚Äúunclear‚Äù category and recognize that human reviewers may\nover-use the ‚Äúuncertain‚Äù [4] and ‚Äúsome concerns‚Äù categories to avoid having to commit to one of the more de\u0000nitive\nassessments. We will therefore also perform analyses of secondary outcomes to assess agreement between\ndichotomized assessments of RoB: low or unclear RoB versus high RoB, and low versus unclear or high RoB. Several\nsubgroup analyses are also planned (see Statistical analyses).\nFinally, we de\u0000ne a domain-level exploratory outcome, human-ChatGPT agreement for RoB arising from the\nrandomization process. This domain is addressed by RoB1 and RoB2 and is perhaps the most important for assessing\nRCTs: randomization is key to being able to draw strong causal inferences about treatment effect, and research shows\nthat trials tend to report exaggerated effect estimates if they are judged to have used inadequate randomization\nmethods.\nData extraction\nWe (CC, HBB, JFME, MR, RCB, TP) will extract data on the included reviews, trials, and human consensus RoB\nassessments (see Table¬†2). We will copy the methods text from the trial reports into a \u0000eld in the data extraction form.\nBecause it can be di\u0000cult or impossible to accurately copy text from some PDF documents (e.g., due to two-column\ntypesetting and the presence of display elements) we will copy text from HTML versions of the trials where possible,\nfalling back on PDF \u0000les if necessary. If it is not possible to copy methods text from a trial report (e.g., if manual\ntranscription would be necessary), we will sample a new trial using the strategy presented above. We will not manually\nedit the extracted methods text (e.g., to remove super\u0000uous information such as citations or the breaking of words over\nlines), because we want to assess whether ChatGPT can assess RoB in the presence of ‚Äúnuisance‚Äù text, as human\nreviewers can. We will obtain ChatGPT RoB assessments as described below.\nTable 2\nSketch of the data extraction form\nReview Trial Risk of Bias Assessment Text ofFollow-onQuestion\nReason forMissingChatGPTAssessmentDOI Year Month ReviewGroup DOI Year Tool(RoB1/Rob2) Human ChatGPT\nXXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX\nXXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX\nXXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX\nPrompt engineering\nPage 8/20\nBecause we have little a priori knowledge about how to prompt ChatGPT to respond with good RoB assessments, we\n(all authors) will use 25 trials and their associated human RoB assessments in informal prompt engineering work. We\nwill use advice on constructing effective prompts [33] to determine a single way of prompting ChatGPT to assess RoB\nto ensure that we do not construct prompts based on human assessments of RoB (i.e., those that the data extractors\nsee in the Cochrane reviews, or which they form themselves by reading trial method text). ChatGPT was developed to\nappear polite and helpful, so there is a risk that it may respond to leading prompts such as ‚ÄúWould you agree that this\ntrial has low risk of bias?‚Äù in an agreeable manner. We will therefore not construct leading prompts. While it is possible\nto converse with ChatGPT using languages other than English, and trials and evidence syntheses are not all written in\nEnglish, we will develop an English language prompt, which we anticipate will be best understood by ChatGPT and\nreaders of our study. However, if a trial‚Äôs methods text is written in a non-English language, we will not translate that part\nof the prompt and will use the text in its original language. We will repeat this prompt engineering work to identify a\ndomain-speci\u0000c prompt for RoB arising from the randomization process.\nDuring the preparation of this manuscript, OpenAI released GPT-4, an apparently substantial improvement on the GPT-\n3.5 model, and which is currently available in a limited form. Because we expect that GPT-4 may outperform GPT-3.5,\nbut may be slower and not readily usable, TP will perform the prompt engineering work using GPT-3.5 and GPT-4 to\ndetermine if there is likely to be a substantial advantage in using GPT-4. We will decide which version of the GPT model\nto use based on this work and issues of practicality.\nThe result of the prompt engineering work will be a prompt similar to that used in the Appendix, which shows an\nexample RoB assessment of a trial that compared a digital health registry to paper-based documentation for screening\nand management of anemia, hypertension, and diabetes during pregnancy [34]. To avoid bias, we will exclude the trials\nused for prompt engineering from subsequent work on assessing human-ChatGPT agreement.\nChatGPT-based RoB assessment\nHaving identi\u0000ed an optimal prompt, we (all authors) will use ChatGPT to assess overall RoB for each trial. To facilitate\nassessment of ChatGPT-ChatGPT interrater agreement, we will obtain ChatGPT assessments in duplicate ‚Äî i.e., two\ndifferent people will each use ChatGPT to assess each trial for overall RoB.\nIf ChatGPT does not clearly assess RoB using one of the three categories as requested (see Outcomes), we will ask one\nnon-prespeci\u0000ed follow-on question to try to obtain an assessment. If we ask a follow-on question, we will not ask a\n‚Äúleading‚Äù question based on our own knowledge or impression of RoB in the trial (see the example leading question\nabove). We will record the \u0000nal assessment along with the text of any follow-on question used. If it is not possible to\nobtain a ChatGPT assessment, we will record the assessment as ‚ÄúMISSING‚Äù and will record the reason. We will extract\ndata into a form structured like Table¬†2 (the full data extraction form is provided in supplementary materials). In\naddition to the variables shown in the table, we will also record the version of ChatGPT used for each assessment (e.g.,\n‚ÄúDec 15 Version‚Äù, as displayed at the bottom of the ChatGPT interface). We will record the language used to report the\nmethods text we present to ChatGPT.\nUnless ChatGPT was trained on the SRs and trials we will use ‚Äî which we cannot know ‚Äî ChatGPT will be blinded to\nthe human assessments in the SRs. Because we will use prespeci\u0000ed prompts and avoid asking leading questions, it\nwill not be necessary to blind those using ChatGPT to the human assessments of RoB. We will not blind the statistician\n(CJR).\nIf we cannot use ChatGPT reliably due to poor availability of the system (i.e., if we judge that it will take excessively\nlong to complete the work), we will focus on extracting the human RoB assessments and method text. We will then\nPage 9/20\neither postpone the acquisition of ChatGPT assessments until the system is su\u0000ciently available or develop a simple\ninterface to a GPT model via OpenAI‚Äôs application programming interface (API) and use that in place of ChatGPT.\nPower calculation\nWe have no a priori estimate of the agreement between human and ChatGPT assessments of RoB but assume that it is\nlikely to be reasonably good. The sample size for the assessment of human-ChatGPT interrater agreement was\ncalculated using the assumptions shown in Fig.¬†3. The null hypothesis is that agreement is not less than a margin of\n10% below an assumed true agreement of 75%, which is towards the upper end of estimates of human interrater\nagreement (see Introduction). We used simulation to determine that RoB assessments for 75 trials will provide at least\n90% power at the 95% signi\u0000cance level (exact Clopper-Pearson estimates of the binomial proportion of RoB\nassessments that agree). We will therefore need data on 100 trials (25 for the prompt engineering work and 75 for\nassessing human-ChatGPT interrater agreement).\nStatistical analyses and reporting\nRecall that we will obtain ChatGPT assessments in duplicate to facilitate ChatGPT-ChatGPT intrarater agreement. We\nwill reduce the duplicate assessments to a single assessment for each trial by randomly choosing one of the\nassessments for each trial. We will present a table of the characteristics of the included SRs, trials, and human\nassessments (Table¬†3).\nWe (CJR) will present a contingency table (confusion matrix; Table¬†4) for the primary outcome, and will present results\nfor the primary, secondary, subgroup, and exploratory analyses (see below and the Discussion section) as a table of\nobserved and expected agreements, expected agreement under random assessment, Cochrane‚Äôs ùúÖ  values, and p-values.\nTo summarize the estimated ùúÖ  values in words, we will use the interpretations suggested by Landis and Koch[35] ‚Äî i.e.,\nusing words such as ‚Äúfair‚Äù (for 0.21 ‚â§  ùúÖ  ‚â§  0.40) and ‚Äúmoderate‚Äù (for 0.41 ‚â§  ùúÖ  ‚â§  0.60). We will use the p‚Äâ<‚Äâ0.05\nsigni\u0000cance criterion. Statistical analyses will be performed using the kappa command of Stata 16 or later (StataCorp\nLLC, College Station, Texas, USA).\nWe (CJR) will perform subgroup analyses that repeats the analysis of the primary outcome for reviews that used RoB1\nversus RoB2, trials published before versus after the Consolidated Standards for Reporting of Trials (CONSORT; [36])\nwere introduced in 1996, and trials published in English versus other languages. The rationales for these subgroup\nanalyses are presented in the Discussion section.\nResults\nThe following shell tables illustrate how the results will be reported.\nPage 10/20\nTable 3\nCharacteristics of the included reviews and studies\nReviews ¬† ¬†\nIncluded N 75\nPublication/update year Median [ICQ] (months) XXX [XXX to XXX]\nCochrane review groups Name (N = %) XXX (XXX‚Äâ=‚ÄâXXX%)\n¬† Name (N = %) XXX (XXX‚Äâ=‚ÄâXXX%)\n¬† Name (N = %) XXX (XXX‚Äâ=‚ÄâXXX%)\n¬† Name (N = %) XXX (XXX‚Äâ=‚ÄâXXX%)\n¬† Name (N = %) XXX (XXX‚Äâ=‚ÄâXXX%)\n¬† Other (N = %) XXX (XXX‚Äâ=‚ÄâXXX%)\nRisk of bias tool RoB1 (N = %) XXX (XXX‚Äâ=‚ÄâXXX%)\n¬† RoB2 (N = %) XXX (XXX‚Äâ=‚ÄâXXX%)\nTrials ¬† ¬†\nIncluded N 75\nPublication year Median [ICQ] (months) XXX [XXX to XXX]\nPublished after CONSORT N (%) XXX (XXX%)\nPublished in English N (%) XXX (XXX%)\n¬†\nTable 4\nContingency table (confusion matrix)\n¬† ¬† ChatGPT\n¬† ¬† Low Uncertain High\nHuman Low N (%) N (%) N (%)\nUncertain N (%) N (%) N (%)\nHigh N (%) N (%) N (%)\n¬†\nPage 11/20\nTable 5\nAgreement between human and ChatGPT risk of bias assessments\n¬† Agreement (%) ¬† ¬†\n¬† Observed\n[95% CI]\nExpected Cochrane‚Äôs ùúÖ  [95%CI] p-value\nPrimary Outcome ¬† ¬† ¬† ¬†\nHuman-ChatGPT agreement XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nSubgroup Analyses ¬† ¬† ¬† ¬†\nReviews published ¬† ¬† ¬† ¬†\nBefore CONSORT XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nAfter CONSORT XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nReviews that used ¬† ¬† ¬† ¬†\nRoB1 XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nRoB2 XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nTrials published in ¬† ¬† ¬† ¬†\nEnglish XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nAnother language XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nSecondary Outcomes ¬† ¬† ¬† ¬†\nLow and Unclear combined XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nUnclear and High combined XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nChatGPT-ChatGPT agreement XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nExploratory Outcome ¬† ¬† ¬† ¬†\nHuman-ChatGPT agreement for RoB due torandomization XXX [XXX ‚ÄìXXX] XXX XXX [XXX ‚Äì XXX] 0.XXX\nDiscussion\nAnticipated contributions and study strengths\nWe anticipate that this study may be the \u0000rst to evaluate interrater agreement in overall assessment of RoB in trials of\nmedical interventions between human reviewers and an LLM such as ChatGPT. Aside from quantifying the agreement,\nPage 12/20\nthis study is likely to be useful for powering future studies, given so little is currently known about agreement between\nexpert humans and LLMs.\nThe main strengths of the study are that it is prespeci\u0000ed, will use human RoB assessments from Cochrane reviews\nthat are likely to be among the most thorough, will provide quantitative information about interrater (human-ChatGPT)\nand interrater (ChatGPT-ChatGPT) agreement across a range of medical interventions, and includes outcomes and\nanalyses that address anticipated limitations (see below).\nRisks and study limitations\nChatGPT has experienced dramatic usage growth since its release. As of this writing (16 May 2023), ChatGPT is\navailable as a ‚ÄúFree Research Preview‚Äù, which is sometimes unavailable or slow to respond, and ChatGPT Plus, a paid\nsubscription that offers ‚Äúavailability even when demand is high, faster response speed, and priority access to new\nfeatures‚Äù. The main risk to this study is that ChatGPT will not be su\u0000ciently available for us to do the planned work.\nEstimates of agreement may not generalize beyond the population de\u0000ned by our inclusion criteria (e.g., Cochrane\nreviews of medical interventions, parallel two-arm RCTs), trial primary outcomes (which usually assess e\u0000cacy rather\nthan safety), trials whose methods text can easily be extracted electronically, or to future versions of ChatGPT or other\nLLMs. The exclusion of emergency reviews and trials means results will not necessarily generalize to these or other\ntrials conducted during crises. There are likely factors that are associated with differences in human RoB assessments\nthat we have not planned to study. For example, RoB assessments made by more experienced reviewers may be more\naccurate and less variable than those made by less experienced reviewers.\nAmong the important differences between RoB1 and RoB2 is that RoB1 de\u0000nes an ‚ÄúUncertain RoB‚Äù category, while\nRoB2 de\u0000nes a ‚ÄúSome concerns‚Äù category. While these are not identical, we will assume there is substantial overlap in\npractice. The secondary outcomes we propose will explore agreement when a common ‚Äúuncertain‚Äù category is pooled\nwith low and high RoB.\nThe original version of the Cochrane RoB tool (RoB1) is applied at the level of trial [3]. However, trials typically assess\ntreatment effect with respect to multiple outcomes (e.g., primary, secondary, and exploratory outcomes; [37]). Trial\nmethods may be expected to result in biased estimates for some outcomes but not others (e.g., blinding may only be\npossible for a subset of a trial‚Äôs outcomes). RoB2 acknowledges this issue. Correct use of that tool results in one\nassessment for each effect estimate (‚Äúresult‚Äù) that will contribute to a given evidence synthesis [4]. We anticipate that it\nwill be di\u0000cult to get ChatGPT to provide RoB assessments at the level of outcome without presenting the complete\ntext of all trial documents (i.e., protocol, statistical analysis plan, main report text, supplementary materials, and any\nancillary publications). Presenting all this information to ChatGPT is unlikely to lead to good results because the GPT-\n3.5 version of ChatGPT can reference only up to around 3000 words in a given conversation [38]. Accurate outcome-\nlevel assessment is probably too much to expect from an automated system (indeed, it may be too much to expect\nfrom human reviewers). We therefore chose to assume that a ChatGPT assessment that is based on a trial‚Äôs methods\ntext will most likely apply to the trial‚Äôs primary outcome. For these reasons, we chose to include RoB2 assessments if\nthey are speci\u0000c to a primary outcome, and to assume that RoB1 assessments are largely focused on primary\noutcomes. A limitation of our primary outcome is therefore that it focuses on trial- rather than outcome-level RoB\nassessment. We will explore this by performing subgroup analyses to compare agreement in reviews that used RoB1\nversus RoB2.\nWe will also perform subgroup analyses to explore differences in agreement for trials published before and after the\nintroduction of CONSORT, given this marks a change in how trials are reported, and between trials published in English\nPage 13/20\nversus other languages, given that ChatGPT originates in the US and English is likely the most common language used\nin its training data.\nThe quality of ChatGPT RoB assessments is likely to depend on the speci\u0000c prompts we will use (i.e., how we will\nphrase requests to ChatGPT) and the information about trials we provide to ChatGPT. While we will perform informal\nprompt engineering, a thorough evaluation of different ways of prompting ChatGPT is out of scope. Human reviewers\nhave access to more information about trials than ChatGPT will (i.e., ChatGPT will be limited to using methods texts,\nwhile human reviewers can read entire trial reports and additional information such as protocols, supplementary\nmaterials, and ancillary publications). Therefore, the human-ChatGPT interrater agreements we will estimate are likely\nto be lower bounds on what is actually possible.\nThe proposed work focuses on interrater agreement. While LLMs may be able to be used to reduce resource use and\nmaintain and improve SR and HTA quality, research on the bene\u0000ts and harms of the use of LLMs are out of scope.\nFuture work could address these issues.\nEthical issues\nThere are numerous serious ethical implications around the adoption of ML/AI in general [39]and biomedicine in\nparticular [40]. Perhaps the main ethical issue inherent to the present study is the risk that a promising but incorrect or\nincomplete result may be used prematurely to justify the replacement of human assessment of RoB. Because evidence\nsyntheses are used to make decisions about large numbers of people, incorrectly replacing human reviewers with an\nLLM could have serious negative health and economic consequences. This could be especially damaging in under-\nresourced health systems (e.g., low- and middle-income countries) in which pressures to limit expenditure are likely\nmost acute but for which errors may be most costly.\nThere are also ethical issues in outsourcing important health systems functions to software developed and operated by\ncommercial entities located in foreign jurisdictions that may not be incentivized to ensure that health and health\neconomic decisions are free of con\u0000icts of interest or malign intent. Undue in\u0000uence or attacks on ML/AI systems by\ncorporations, interest groups, and hostile nation states represent new threats [41]‚Äì[43] against which health systems\nshould be protected. Recent research has identi\u0000ed two new mechanisms by which a malign actor might ‚Äúpoison‚Äù\ninternet-scale training data by introducing malicious examples [44]. For example, an unscrupulous vendor of a health\nintervention could attempt to manipulate ML/AI-based assessments of its products. Such risks underscore the\nimportance of digital independence efforts, such as the recently announced NorwAI GPT Language Modeling Project\n[45], which aims to develop a GPT-like model trained on Norwegian-language texts. To our knowledge, OpenAI has not\nrevealed the cost of training GPT-3.5, but based on available information it may have cost at least 4.6¬†million USD [46].\nOpenAI has raised billions of dollars in funding, which investors presumably expect to pro\u0000t from, in part by automating\njobs currently performed by humans. The bene\u0000ts, risks, and costs of replacing human activities with automated\nsystems should be carefully evaluated, in particular from the perspective of health system resiliency and scienti\u0000c\naccountability.\nImplications for research and practice\nWe think this study will likely be an important early contribution to a body of research on using or \u0000ne-tuning general-\npurpose LLMs trained on internet-scale corpuses to perform specialized scienti\u0000c tasks. We hope that the present study\nwill be the \u0000rst in a series on using LLMs in evidence synthesis. We anticipate the data we will collect will be useful for\npilot work on more speci\u0000c questions that we will not be able to address in the present work, such as on ‚Äúprompt\nengineering‚Äù (i.e., how to phrase prompts in a way that yields the best assessments of RoB), domain-level rather than\noverall RoB assessment, and using the few-shot learning mode of LLMs [20] to build \u0000ne-tuned models for assessing\nPage 14/20\nRoB. Research on the use of LLMs such as ChatGPT for systematic reviewing is likely to lead to profound changes in\nhow evidence synthesis tasks are performed, who does them, how quickly work can be completed and at what cost, and\nto changes in how primary studies are performed and reported so that they can be best understood by arti\u0000cial\nintelligences.\nConclusion\nThis article describes a protocol for a study of interrater agreement in RoB assessment between human reviewers and a\nlarge language model (ChatGPT), focusing on individually- or cluster-randomized, parallel, two-arm trials of medical\ninterventions.\nDeclarations\nRevision history\nThis is the \u0000rst version of this protocol.\nFunding\nThis work is internally funded.\nAuthor contributions\nStudy conception and design: AEM, CJR.\nPower calculation: CJR.\nStudy selection: JFME, RCB, HBB, MR\nData extraction: JFME, RCB, HBB, MR\nDrafting the manuscript: CJR, HBB; JB, JFME, JG, MR, RCB.\nCritical revision of the manuscript for important intellectual content: CJR, CC, HBB, JB, JFME, JG, MR, TP.\nEthics declarations\nEthical approval is not required. Patient consent is not required.\nCompeting interests\nNone of the authors have any competing interests relevant to this study.\nAvailability of data and code\nPage 15/20\nWe will publish the extracted data, with the exception of the methods text extracted from the trial reports, which we\nassume will usually be protected by copyright. We will also publish the code for the statistical analyses.\nReferences\n1. M. J. Page, J. P. T. Higgins, G. Clayton, J. A. C. Sterne, A. Hr√≥bjartsson, and J. Savovi ƒá , ‚ÄúEmpirical Evidence of Study\nDesign Biases in Randomized Trials: Systematic Review of Meta-Epidemiological Studies.,‚Äù PLoS One, vol. 11, no.\n7, p. e0159267, 2016, doi: 10.1371/journal.pone.0159267.\n2. K. F. Schulz, I. Chalmers, R. J. Hayes, and D. G. Altman, ‚ÄúEmpirical evidence of bias: dimensions of methodological\nquality associated with estimates of treatment effects in controlled trials,‚Äù JAMA, vol. 273, no. 5, pp. 408‚Äì412,\n1995.\n3. J. P. T. Higgins et al., ‚ÄúThe Cochrane Collaboration‚Äôs tool for assessing risk of bias in randomised trials.,‚Äù BMJ, vol.\n343, p. d5928, Oct. 2011, doi: 10.1136/bmj.d5928.\n4. J. A. C. Sterne et al., ‚ÄúRoB 2: a revised tool for assessing risk of bias in randomised trials.,‚Äù BMJ, vol. 366, p. l4898,\nAug. 2019, doi: 10.1136/bmj.l4898.\n5. N. K√∂nsgen et al., ‚ÄúInter-review agreement of risk-of-bias judgments varied in Cochrane reviews.,‚Äù J Clin Epidemiol,\nvol. 120, pp. 25‚Äì32, Apr. 2020, doi: 10.1016/j.jclinepi.2019.12.016.\n\u0000. S. Minozzi, M. Cinquini, S. Gianola, M. Gonzalez-Lorenzo, and R. Banzi, ‚ÄúThe revised Cochrane risk of bias tool for\nrandomized trials (RoB 2) showed low interrater reliability and challenges in its application.,‚Äù J Clin Epidemiol, vol.\n126, pp. 37‚Äì44, Oct. 2020, doi: 10.1016/j.jclinepi.2020.06.015.\n7. A. Blaizot et al., ‚ÄúUsing arti\u0000cial intelligence methods for systematic review in health sciences: A systematic review,‚Äù\nRes Synth Methods, vol. 13, no. 3, pp. 353‚Äì362, May 2022, doi: 10.1002/jrsm.1553.\n\u0000. R. Cierco Jimenez et al., ‚ÄúMachine learning computational tools to assist the performance of systematic reviews: A\nmapping review,‚Äù BMC Med Res Methodol, vol. 22, no. 1, p. 322, Dec. 2022, doi: 10.1186/s12874-022-01805-4.\n9. L. A. C. Millard, P. A. Flach, and J. P. T. Higgins, ‚ÄúMachine learning to assist risk-of-bias assessments in systematic\nreviews.,‚Äù Int J Epidemiol, vol. 45, no. 1, pp. 266‚Äì77, Feb. 2016, doi: 10.1093/ije/dyv306.\n10. C. L. Andaur Navarro et al., ‚ÄúRisk of bias in studies on prediction models developed using supervised machine\nlearning techniques: systematic review.,‚Äù BMJ, vol. 375, p. n2281, Oct. 2021, doi: 10.1136/bmj.n2281.\n11. R. van Dinter, B. Tekinerdogan, and C. Catal, ‚ÄúAutomation of systematic literature reviews: A systematic literature\nreview,‚Äù Inf Softw Technol, vol. 136, p. 106589, Aug. 2021, doi: 10.1016/j.infsof.2021.106589.\n12. I. J. Marshall, J. Kuiper, and B. C. Wallace, ‚ÄúRobotReviewer: evaluation of a system for automatically assessing bias\nin clinical trials,‚Äù Journal of the American Medical Informatics Association, vol. 23, no. 1, pp. 193‚Äì201, Jan. 2016,\ndoi: 10.1093/jamia/ocv044.\n13. S. Armijo ‚Äê Olivo, R. Craig, and S. Campbell, ‚ÄúComparing machine and human reviewers to evaluate the risk of bias in\nrandomized controlled trials,‚Äù Res Synth Methods, vol. 11, no. 3, pp. 484‚Äì493, May 2020, doi: 10.1002/jrsm.1398.\n14. J. Hirt, J. Meichlinger, P. Schumacher, and G. Mueller, ‚ÄúAgreement in Risk of Bias Assessment Between\nRobotReviewer and Human Reviewers: An Evaluation Study on Randomised Controlled Trials in Nursing ‚Äê Related\nCochrane Reviews,‚Äù Journal of Nursing Scholarship, vol. 53, no. 2, pp. 246‚Äì254, Mar. 2021, doi: 10.1111/jnu.12628.\n15. A. Arno, J. Thomas, B. Wallace, I. J. Marshall, J. E. McKenzie, and J. H. Elliott, ‚ÄúAccuracy and E\u0000ciency of Machine\nLearning‚ÄìAssisted Risk-of-Bias Assessments in ‚ÄòReal-World‚Äô Systematic Reviews,‚Äù Ann Intern Med, vol. 175, no. 7,\npp. 1001‚Äì1009, Jul. 2022, doi: 10.7326/M22-0092.\n1\u0000. P. S. J. Jardim, C. J. Rose, H. M. Ames, J. F. M. Echavez, S. Van de Velde, and A. E. Muller, ‚ÄúAutomating risk of bias\nassessment in systematic reviews: a real-time mixed methods comparison of human researchers to a machine\nPage 16/20\nlearning system,‚Äù BMC Med Res Methodol, vol. 22, no. 1, p. 167, Dec. 2022, doi: 10.1186/s12874-022-01649-y.\n17. F. Soboczenski, T. A. Trikalinos, J. Kuiper, R. G. Bias, B. C. Wallace, and I. J. Marshall, ‚ÄúMachine learning to help\nresearchers evaluate biases in clinical trials: a prospective, randomized user study,‚Äù BMC Med Inform Decis Mak,\nvol. 19, no. 1, p. 96, Dec. 2019, doi: 10.1186/s12911-019-0814-z.\n1\u0000. Z. Bahor et al., ‚ÄúRisk of bias reporting in the recent animal focal cerebral ischaemia literature,‚Äù Clin Sci, vol. 131, no.\n20, pp. 2525‚Äì2532, Oct. 2017, doi: 10.1042/CS20160722.\n19. Q. Wang, J. Liao, M. Lapata, and M. Macleod, ‚ÄúRisk of bias assessment in preclinical literature using natural\nlanguage processing,‚Äù Res Synth Methods, vol. 13, no. 3, pp. 368‚Äì380, May 2022, doi: 10.1002/jrsm.1533.\n20. T. B. Brown et al., ‚ÄúLanguage Models are Few-Shot Learners,‚Äù May 2020.\n21. L. Laranjo et al., ‚ÄúConversational agents in healthcare: a systematic review.,‚Äù J Am Med Inform Assoc, vol. 25, no. 9,\npp. 1248‚Äì1258, Sep. 2018, doi: 10.1093/jamia/ocy072.\n22. A. M. Turing, Computing machinery and intelligence. Springer, 2009.\n23. J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‚ÄúBERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding,‚Äù Oct. 2018.\n24. E. Lehman et al., ‚ÄúDo We Still Need Clinical Language Models?,‚Äù Feb. 2023.\n25. T. H. Kung et al., ‚ÄúPerformance of ChatGPT on USMLE: Potential for AI-assisted medical education using large\nlanguage models.,‚Äù PLOS digital health, vol. 2, no. 2, p. e0000198, Feb. 2023, doi: 10.1371/journal.pdig.0000198.\n2\u0000. J. DeGrave, ‚ÄúBuilding a virtual machine inside ChatGPT,‚Äù Engraved, Dec. 03, 2022.\nhttps://www.engraved.blog/building-a-virtual-machine-inside/ (accessed May 08, 2023).\n27. L. Bertizzolo, P. Bossuyt, I. Atal, P. Ravaud, and A. Dechartres, ‚ÄúDisagreements in risk of bias assessment for\nrandomised controlled trials included in more than one Cochrane systematic reviews: a research on research study\nusing cross-sectional design.,‚Äù BMJ Open, vol. 9, no. 4, p. e028382, Apr. 2019, doi: 10.1136/bmjopen-2018-028382.\n2\u0000. L. Hartling et al., ‚ÄúTesting the risk of bias tool showed low reliability between individual reviewers and across\nconsensus assessments of reviewer pairs.,‚Äù J Clin Epidemiol, vol. 66, no. 9, pp. 973‚Äì81, Sep. 2013, doi:\n10.1016/j.jclinepi.2012.07.005.\n29. D. Surkov, ‚ÄúUsing of dexmedetomidine in term neonates with hypoxic-ischemic encephalopathy,‚Äù –ú –µ –¥ –∏ —á –Ω —ñ \n–ø –µ —Ä —Å –ø –µ –∫ —Ç –∏ –≤ –∏ , vol. 24, no. 2, pp. 24‚Äì33, 2019.\n30. P. B√§cke, M. Bruschettini, G. Sibrecht, Y. Thernstr√∂m Blomqvist, and E. Olsson, ‚ÄúPharmacological interventions for\npain and sedation management in newborn infants undergoing therapeutic hypothermia.,‚Äù Cochrane Database Syst\nRev, vol. 11, no. 11, p. CD015023, Nov. 2022, doi: 10.1002/14651858.CD015023.pub2.\n31. A. E. Muller et al., ‚ÄúThe effect of machine learning tools for evidence synthesis on resource use and time-to-\ncompletion: protocol for a retrospective pilot study.,‚Äù Syst Rev, vol. 12, no. 1, p. 7, Jan. 2023, doi: 10.1186/s13643-\n023-02171-y.\n32. J. Kottner et al., ‚ÄúGuidelines for Reporting Reliability and Agreement Studies (GRRAS) were proposed.,‚Äù J Clin\nEpidemiol, vol. 64, no. 1, pp. 96‚Äì106, Jan. 2011, doi: 10.1016/j.jclinepi.2010.03.002.\n33. OpenAI, ‚ÄúBest practices for prompt engineering with OpenAI API,‚Äù OpenAI.\nhttps://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api (accessed May\n08, 2023).\n34. M. Venkateswaran et al., ‚ÄúA digital health registry with clinical decision support for improving quality of antenatal\ncare in Palestine (eRegQual): a pragmatic, cluster-randomised, controlled, superiority trial.,‚Äù Lancet Digit Health, vol.\n4, no. 2, pp. e126‚Äìe136, Feb. 2022, doi: 10.1016/S2589-7500(21)00269-7.\nPage 17/20\n35. J. R. Landis and G. G. Koch, ‚ÄúThe measurement of observer agreement for categorical data.,‚Äù Biometrics, vol. 33,\nno. 1, pp. 159‚Äì74, Mar. 1977.\n3\u0000. C. Begg et al., ‚ÄúImproving the quality of reporting of randomized controlled trials. The CONSORT statement.,‚Äù JAMA,\nvol. 276, no. 8, pp. 637‚Äì9, Aug. 1996, doi: 10.1001/jama.276.8.637.\n37. J. A. Lewis, ‚ÄúStatistical principles for clinical trials (ICH E9): an introductory note on an international guideline.,‚Äù Stat\nMed, vol. 18, no. 15, pp. 1903‚Äì42, Aug. 1999, doi: 10.1002/(sici)1097-0258(19990815)18:15<1903::aid-\nsim188>3.0.co;2-f.\n3\u0000. OpenAI, ‚ÄúDoes ChatGPT remember what happened earlier in the conversation?,‚Äù OpenAI.\nhttps://help.openai.com/en/articles/6787051-does-chatgpt-remember-what-happened-earlier-in-the-conversation\n(accessed May 08, 2023).\n39. V. C. M√ºller, ‚ÄúEthics of Arti\u0000cial Intelligence and Robotics,‚Äù The Stanford Encyclopedia of Philosophy, 2021.\nhttps://plato.stanford.edu/archives/sum2021/entries/ethics-ai/ (accessed May 08, 2023).\n40. K. H. Keskinbora, ‚ÄúMedical ethics considerations on arti\u0000cial intelligence.,‚Äù J Clin Neurosci, vol. 64, pp. 277‚Äì282,\nJun. 2019, doi: 10.1016/j.jocn.2019.03.001.\n41. M. Comiter, ‚ÄúAttacking Arti\u0000cial Intelligence: AI‚Äôs Security Vulnerability and What Policymakers Can Do About It,‚Äù\nAug. 2019. Accessed: May 08, 2023. [Online]. Available: https://www.belfercenter.org/publication/AttackingAI\n42. S. Qiu, Q. Liu, S. Zhou, and C. Wu, ‚ÄúReview of Arti\u0000cial Intelligence Adversarial Attack and Defense Technologies,‚Äù\nApplied Sciences, vol. 9, no. 5, p. 909, Mar. 2019, doi: 10.3390/app9050909.\n43. I. Y. Tyukin, D. J. Higham, and A. N. Gorban, ‚ÄúOn Adversarial Examples and Stealth Attacks in Arti\u0000cial Intelligence\nSystems,‚Äù in 2020 International Joint Conference on Neural Networks (IJCNN), IEEE, Jul. 2020, pp. 1‚Äì6. doi:\n10.1109/IJCNN48605.2020.9207472.\n44. N. Carlini et al., ‚ÄúPoisoning Web-Scale Training Datasets is Practical,‚Äù Feb. 2023.\n45. R. Dyrnes Svendsen, ‚ÄúNorwAI to introduce large Norwegian GPT model,‚Äù NorwAI.\nhttps://www.ntnu.edu/web/norwai/norwai-to-introduce-large-norwegian-gpt-model (accessed May 08, 2023).\n4\u0000. C. Li, ‚ÄúOpenAI‚Äôs GPT-3 Language Model: A Technical Overview,‚Äù Lambda Labs, Jun. 03, 2020.\nhttps://lambdalabs.com/blog/demystifying-gpt-3 (accessed May 08, 2023).\n47. World Health Organization, ‚ÄúWHO recommends new name for monkeypox disease .‚Äù Accessed: May 08, 2023.\n[Online]. Available: https://www.who.int/news/item/28-11-2022-who-recommends-new-name-for-monkeypox-\ndisease\nFootnotes\n1. We use the revised name recommended by WHO to address issues of racist and stigmatizing language [47].\n2. Cochrane is restructuring to replace Review Groups, however Review Groups were active for the period de\u0000ned for\nidentifying SRs and trials.\nAppendix\nAppendix ‚Äî Obtaining ChatGPT assessments of risk of bias\nWe will start a new ChatGPT ‚Äúconversation‚Äù for each RoB assessment. This is necessary because ChatGPT conditions\nits responses on the history of the conversation. If we were to ask ChatGPT to assess one trial and then another (or the\nsame trial) without starting a new conversation, it is possible ChatGPT will not correctly differentiate between the two\nPage 18/20\ndistinct tasks. In the following, prompts to ChatGPT are shown in bold and italics, while ChatGPT‚Äôs responses are\nshown in italics. We will start the conversation with the prompt:\nIn the following chat, I will provide text from the methods section of a RCT of an intervention. I want you to assess each\ntext for risk of methodological bias using one of the following words: high, uncertain, low. At the end of the chat I want\nyou to summarize risk of bias for the entire RCT.\nIt is necessary to provide the text piecemeal because ChatGPT places a limit on the length of a prompt, so it is not\npossible to enter the text for an entire methods section in one prompt. After the prompt above, ChatGPT responded:\nI can certainly help you with that! Please go ahead and provide the text from the methods section of the RCT and I will\nassess the risk of methodological bias for each piece of text. At the end of the chat, I will provide a summary of the\noverall risk of bias for the entire RCT.\nWe will then enter each paragraph of the methods section for the trial. For example, we may enter text such as the\nfollowing, which was extracted from Venkateswaran 2022 ([34]; for which CJR performed the statistical analysis) and is\npresented below as we would enter trial text into ChatGPT (e.g., without ‚Äúcleaning‚Äù the text to remove citations). Note\nthat it may be necessary to copy methods text from a \u0000eld in the data extraction form and into a temporary \u0000le, in order\nto then copy and paste the distinct paragraphs into the ChatGPT user interface.\nThis pragmatic, cluster-randomised, controlled, superiority trial was done in primary health-care clinics offering routine\nantenatal care in the West Bank, Palestine. The trial protocol with detailed methods and context has been published.17\nIn brief, the unit of randomisation was the public primary health-care clinic reporting to the Palestinian Ministry of\nHealth. In the West Bank, there are about 400 public clinics providing routine antenatal care for low-risk pregnancies.\nEach clinic has a prede\u0000ned referral clinic, and there are 86 referral clinics that provide care for pregnant women with\ncertain risk factors or conditions. Private providers and the UN Relief and Works Agency for Palestine Refugees in the\nNear East (UNRWA) also offer antenatal care. About half of all pregnant women receive antenatal care in the public\nsector, and more than 80% deliver in government-run hospitals.\nIn our testing, ChatGPT responded as follows:\nThe risk of methodological bias in this study is low. The study is a cluster-randomized controlled trial, which is a strong\ndesign for minimizing bias. The study also clearly states the unit of randomization, which is the primary health-care\nclinic. Additionally, the study protocol has been published, which allows for transparency and allows other researchers\nto evaluate the methods used in the study.\nWhile ChatGPT did not follow our instruction exactly (i.e., it did not simply respond with ‚Äúlow‚Äù), it did provide an\nassessment for the text and also provided text that apparently explains the assessment. ¬†Few machine learning models\nare able to explain their decisions, which is legally required in some cases in some jurisdictions (e.g., see Recital 71 on\nthe European Union‚Äôs General Data Protection Regulation). After entering all methods text for a trial, we will use the\nfollowing prompt:\nWhat is your overall assessment of the risk of methodological bias? Please use one of the following words: high,\nuncertain, low.\nIn the case of the Venkateswaran 2022 paper, ChatGPT responded:\nOverall, the risk of methodological bias in this RCT appears to be low. The study has taken appropriate steps to\nrandomize the study participants, adjust for strati\u0000cation and constraining variables, and minimize the risk of bias due\nPage 19/20\nto funding sources. Additionally, the study has a clear hypothesis, a clear plan for data analysis, and a sample size that\nis su\u0000cient to detect the differences between the intervention and control groups. These are all important factors that\ncan help to reduce the risk of methodological bias in a study.\nChatGPT‚Äôs assessment for this study would therefore be recorded as ‚Äúlow‚Äù. Again, note that ChatGPT has provided an\nexplanation, which includes details from the entire conversation (i.e., entire methods text).\nSupplementary Materials\nSupplementary Materials are not available with this version.\nFigures\n\nPage 20/20\nFigure 1\nChatGPT can explain statistical concepts\nThe prompt that we provided to ChatGPT is indicated by ‚ÄúNE‚Äù and the system‚Äôs response follows. Note ChatGPT‚Äôs error\nor over-simpli\u0000cation in the statement that frequentist methods do not account for uncertainty, and a minor\ngrammatical error (‚Äúthere are also now hybrid approach‚Äù).\nFigure 2\nChatGPT can understand instructions, demonstrates broad knowledge, and clearly has excellent taste in music\nFigure 3\nAssumptions used in the power calculation",
  "topic": "Inter-rater reliability",
  "concepts": [
    {
      "name": "Inter-rater reliability",
      "score": 0.7555769085884094
    },
    {
      "name": "Protocol (science)",
      "score": 0.7077009081840515
    },
    {
      "name": "Psychological intervention",
      "score": 0.6723980903625488
    },
    {
      "name": "Randomized controlled trial",
      "score": 0.6081134676933289
    },
    {
      "name": "Psychology",
      "score": 0.45251962542533875
    },
    {
      "name": "Medicine",
      "score": 0.41263094544410706
    },
    {
      "name": "Clinical psychology",
      "score": 0.3537071943283081
    },
    {
      "name": "Medical physics",
      "score": 0.3500930070877075
    },
    {
      "name": "Psychiatry",
      "score": 0.20456108450889587
    },
    {
      "name": "Alternative medicine",
      "score": 0.17090359330177307
    },
    {
      "name": "Developmental psychology",
      "score": 0.0917426347732544
    },
    {
      "name": "Internal medicine",
      "score": 0.0834222137928009
    },
    {
      "name": "Pathology",
      "score": 0.08130264282226562
    },
    {
      "name": "Rating scale",
      "score": 0.079181969165802
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1333353642",
      "name": "Norwegian Institute of Public Health",
      "country": "NO"
    },
    {
      "id": "https://openalex.org/I187531555",
      "name": "Lund University",
      "country": "SE"
    },
    {
      "id": "https://openalex.org/I32625721",
      "name": "University of Saskatchewan",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I36234482",
      "name": "University of Bristol",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I2800166025",
      "name": "Universidad Santo Tom√°s",
      "country": "CO"
    },
    {
      "id": "https://openalex.org/I179863766",
      "name": "Western Norway University of Applied Sciences",
      "country": "NO"
    }
  ]
}