{
  "title": "Predicting mechanical fields near cracks using a progressive transformer diffusion model and exploration of generalization capacity",
  "url": "https://openalex.org/W4315706348",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2250330840",
      "name": "Markus J. Buehler",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2250330840",
      "name": "Markus J. Buehler",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3024505766",
    "https://openalex.org/W4214736987",
    "https://openalex.org/W2014409757",
    "https://openalex.org/W2111111047",
    "https://openalex.org/W4253194302",
    "https://openalex.org/W4255998091",
    "https://openalex.org/W758773009",
    "https://openalex.org/W590147041",
    "https://openalex.org/W3201073812",
    "https://openalex.org/W2056438456",
    "https://openalex.org/W3104709959",
    "https://openalex.org/W3160373943",
    "https://openalex.org/W2998428519",
    "https://openalex.org/W2968923792",
    "https://openalex.org/W2962362559",
    "https://openalex.org/W3011282394",
    "https://openalex.org/W6966953165",
    "https://openalex.org/W3180355996",
    "https://openalex.org/W2166712553",
    "https://openalex.org/W2086238435",
    "https://openalex.org/W3202214970",
    "https://openalex.org/W4224020136",
    "https://openalex.org/W4220838812",
    "https://openalex.org/W4292508613",
    "https://openalex.org/W4281620463",
    "https://openalex.org/W3166589044",
    "https://openalex.org/W3145017754",
    "https://openalex.org/W4224951336",
    "https://openalex.org/W4226125322",
    "https://openalex.org/W4224035735",
    "https://openalex.org/W4225314275",
    "https://openalex.org/W4281485151",
    "https://openalex.org/W4281969232",
    "https://openalex.org/W3191805365",
    "https://openalex.org/W4306676681",
    "https://openalex.org/W2901687773",
    "https://openalex.org/W2021189331",
    "https://openalex.org/W1993863601",
    "https://openalex.org/W1986750845",
    "https://openalex.org/W2025444507",
    "https://openalex.org/W1995824968",
    "https://openalex.org/W1992985800",
    "https://openalex.org/W2972219719",
    "https://openalex.org/W3128426563",
    "https://openalex.org/W2529996553",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2010406331",
    "https://openalex.org/W2552477466",
    "https://openalex.org/W2024354208",
    "https://openalex.org/W2074315575",
    "https://openalex.org/W2050971408",
    "https://openalex.org/W2521975177",
    "https://openalex.org/W2019056357",
    "https://openalex.org/W2124096933",
    "https://openalex.org/W2013035813",
    "https://openalex.org/W2612690371",
    "https://openalex.org/W4301007164"
  ],
  "abstract": "Abstract We report a deep learning method to predict high-resolution stress fields from material microstructures, using a novel class of progressive attention-based transformer diffusion models. We train the model with a small dataset of pairs of input microstructures and resulting atomic-level Von Mises stress fields obtained from molecular dynamics (MD) simulations, and show excellent capacity to accurately predict results. We conduct a series of computational experiments to explore generalizability of the model and show that while the model was trained on a small dataset that featured samples of multiple cracks, the model can accurately predict distinct fracture scenarios such as single cracks, or crack-like defects with very different shapes. A comparison with MD simulations provides excellent comparison to the ground truth results in all cases. The results indicate that exciting opportunities that lie ahead in using progressive transformer diffusion models in the physical sciences, to produce high-fidelity and high-resolution field images. Graphical abstract",
  "full_text": "1317\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nVol.:(0123456789)\n DOI:10.1557/s43578-023-00892-3\n© The Author(s) 2023\nArticle\nPredicting mechanical fields near cracks using \na progressive transformer diffusion model \nand exploration of generalization capacity\nMarkus J. Buehler1,2,a) \n1 Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Ave, Cambridge, MA 02139, \nUSA\n2 Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology, 77 Massachusetts Ave, \nCambridge, MA 02139, USA\na) Address all correspondence to this author. e-mail: mbuehler@MIT.EDU\nReceived: 9 August 2022; accepted: 2 January 2023; published online: 12 January 2023\nWe report a deep learning method to predict high-resolution stress fields from material microstructures, \nusing a novel class of progressive attention-based transformer diffusion models. We train the model \nwith a small dataset of pairs of input microstructures and resulting atomic-level Von Mises stress fields \nobtained from molecular dynamics (MD) simulations, and show excellent capacity to accurately predict \nresults. We conduct a series of computational experiments to explore generalizability of the model and \nshow that while the model was trained on a small dataset that featured samples of multiple cracks, \nthe model can accurately predict distinct fracture scenarios such as single cracks, or crack-like defects \nwith very different shapes. A comparison with MD simulations provides excellent comparison to the \nground truth results in all cases. The results indicate that exciting opportunities that lie ahead in using \nprogressive transformer diffusion models in the physical sciences, to produce high-fidelity and high-\nresolution field images.\nIntroduction\nModeling fracture is an important frontier in materials research \n[1–4] and a challenging problem for modeling and simula-\ntion. In typical fracture problems a specimen with defect(s) is \nexposed to mechanical loading [2 , 5], and the response to such \nboundary conditions are examined to predict stress and strain \nfield, overall fracture toughness, or statistics of specific features \nof the resulting mechanical fields (Fig. 1) [6–8].\nWhereas molecular-level models (e.g., molecular dynam-\nics, MD) provide accurate predictive results (especially using \naccurate force fields) [10], such simulations can be computa-\ntionally expensive and quickly challenge the capabilities of \ncomputational resources. On the other hand, deep learning has \nemerged as a potential approach to help address the multiscale \nproblem, as it could both serve as a proxy model for MD or finite \nelement methods (FE) or as a way to bridge scales [11– 15]. In \nscale-bridging applications, such methods should ideally have \na generalization capacity that allows them to make predictions \nbeyond the scope of the training data.\nThis question about the predictive power of physics-based \ndeep learning has been a subject of various investigations [ 16, \n17], and is an important frontier in the field. In this paper we \nparticularly focus on the use of deep learning for fracture appli-\ncations, and explore the application of a small dataset and the \ngeneralization capacity towards a broader use of a deep learning \nmethod in a multiscale scheme. This assessment will provide \nus with insights on potential uses of such methods as a scale-\nbridging tool to effective capture how building blocks of materi-\nals (atoms, molecules, amino acids, etc.) interact to create spe-\ncific sets of functions. A particular novelty of this study is the \nuse of a physics-inspired diffusion machine learning approach, \nand an assessment of whether or not such a model is capable \nof adequately learning complex singular field data near cracks.\nLanguage‑based models for physical sciences\nWe propose the use of language models, specifically using the \nself-attention architecture seen for instance in transformer \n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\n© The Author(s) 2023 1318\nArticle\nneural networks [18– 20], which offers a building block \napproach that is native to many materials science problems—\nlinking structure, process and properties at a building block \nperspective, in a natural way, similar to language [21– 25]. \nEarlier work in this field has demonstrated the suitability of \nconvolutional and transformer architecture for solid mechanics \nproblems including elasticity and fracture applications [26–29], \nas well as materials design based on human language input \n[23, 24]. More broadly, the use of transformer architectures \nhas emerged as a broadly applicable approach for many data \nmodalities including state-of-the-art text-to-image generation \n(e.g., VQGAN-CLIP [ 20, 30], GLIDE [31], DALL-E 2 [32, 33], \nor Imagen [34]).\nHere we build on this body of knowledge and recent devel-\nopments of state-of-the-art image generation methods [34] and \nexplore the use of a new class of progressive diffusion models \n[34, 35]. We specifically focus on the following materials science \nquestions:\n1. Can progressive diffusion models be an effective approach \nto predict physical field solution from prompts that deline-\nate the input microstructure?\n2. Can we successfully train a complex progressive diffusion \ntransformer model with relatively small datasets of only a \nthousand image-to-image pairs?\n3. Can such a model be used to predict solutions for input \nmicrostructures that are distinct from the types of data seen \nduring training, so that the model can be used to generalize \nsolutions?\nWhile we use a similar architecture as in state-of-the-art \ntext-to-image generation methods [34] including a successive \nFigure 1:  Summary of the fracture mechanics field problem considered here, focused specifically on atomic-level stress data. (A) summary of the \nboundary condition and elliptical crack-like voids used in the training set. We use a fixed boundary indicated by the dashed line to constrain \nmovement at the outside, in order to apply strain-controlled loading. (B) Molecular dynamics (MD) simulation setup, including a close-up view of \nthe atomistically resolved stress field and an indication of the four fixed boundary strips used in LAMMPS [9]. The simulation domain of all mobile \natoms is indicated in red color. (C) Two examples of input and output data pairs produced by MD simulation. As shown in the zoomed-in view on the \nright, the resolution of the output images is sufficiently high to resolve individual atoms and detailed stress variations—at the atomic level—near the \nedges. The region shown in magnified view is indicated by the dashed grey box. The hexagonal lattice structure is clearly visible, with the spacing of \natomic distances marked in panel C to provide a reference for the key scales in the problem. As marked with the scale bar in panel A, the system size is \napproximately 32 nm (assuming that σ = 1 Å).\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\n© The Author(s) 2023 1319\nArticle\ndenoising strategy that transforms noise to conditioned field \nsolutions, our conditioning prompt is not text here; rather, \nthe input prompt is an encoding of the input microstructure \nrepresentation from which the model then learns to construct \nthe field solution. In the cases discussed in this paper we \npredict the Von Mises stress field from the prompt; however, \nother fields or properties can be predicted as well and the \nmodel can be easily adapted (either training from scratch, \nor more efficiently, using transfer learning). The primary \nobjective in this work is to develop a framework that can \npredict high-resolution field predictions that features exqui-\nsite detail of the resulting physical variables, at reasonable \ncomputational cost. The successive upscaling of the resulting \nfield prediction from smaller to larger and larger resolution \nbecomes tractable through the use of a cascading series of \ndeep neural networks, as illustrated in Fig.  2. While limited \nto a 2D model material in this study, we anticipate that the \ngeneral framework can be useful for a variety of scenarios \nand many other field data classes.\nPaper outline\nWe begin the discussion with a brief review of the dataset, the \nneural network architecture, and then proceed to a presenta -\ntion of the results. We review training and testing performance, \nas well as the exploration of using the model in scenarios far \nfrom the original dataset used in training, to explore generali-\nzation capacity. A discussion with domain knowledge in frac -\nture mechanics is included, to further understand the model’s \npredictive power. Finally we discuss opportunities for future \nwork that include experimental studies, integration with other \ntypes of field data, as well as transfer learning modalities.\nFigure 2:  Summary of the neural network architecture of a diffusion-based generative model, consisting of three U-Net architectures (Unet 1, Unet 2 \nand Unet 3) that are used to translate the input microstructure into the final field output, over three successive stages of translation and upscaling, \nultimately reaching a resolution of 1024 × 1024.\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1320\nResults and discussion\nNeural network architecture\nDiffusion models, sometimes referred to as denoising diffusion \nmodels, have emerged as state-of-the-art tools in image genera-\ntion especially when combined with transformer architectures, \nrealized in methods such as DALL-E 2 or Imagen, and often \nexceed the performance of generative adversarial neural nets \n(GANs) [33, 35–37]. The key task in such models is that they \nlearn a reverse process to perform denoising in order generate \ndata, such as images or field data, from noise [ 37]. While these \nmodels have been widely used in the image synthesis litera -\nture, their exploration in the physical sciences, and specifically \nmechanics applications for materials science, has not yet been \ninvestigated.\nHere we use a progressive neural network architecture that \nprogressively upscales the prediction from the input prompt, \nto realize very high-resolution images with exquisite detail and \nquality. Figure 2 shows a summary of the neural network archi-\ntecture of a diffusion-based generative model, consisting of a \nseries of three U-Net architectures (Unet 1, Unet 2 and Unet \n3) that are used to translate the input microstructure into the \nfinal field output, over three successive stages of translation and \nupscaling, ultimately reaching a resolution of 1024 × 1024. Each \nU-net consists of a combination of ResNet blocks and self-atten-\ntion layers, as described in [34]. Further details are provided in \nthe Materials and Methods section.\nModel training and testing\nThe model is trained successively whereby each of the U-Nets is \ntrained individually (first Unet 1, then Unet 2, and then Unet 3). \nAs a training set, we deliberate limit the scope to a very small set \nof 1,000 image pairs, as shown in Fig. S1 for a few sample geom-\netries (full dataset see link in Materials and Methods). Training \nperformances are shown in Figs. S3 and S4. Figure S4 specifically \nshows images during training, revealing training performance \nfor test and validation set, for the first U-net (Unet1) to give the \nreaders a sense for how the model learns and performs dur -\ning this process. As can be seen, during training epochs (top to \nbottom), the prediction accuracy increases successively. Similar \nbehaviors are seen for the other U-Nets in the model.\nValidation and extrapolation\nWe now use the trained model and apply it to examine how well \nit can predict stress fields for a variety of vases. All predictions \npresented here are for the fully trained model, whereby images \nof size 1024 × 1024 are generated.\nFigure 3 shows predictions based on a test microstructure \n[Fig. 3(A)], for the three different stages in the neural network. \nFigure  3(B) shows results for three different resolutions, cor -\nresponding to the three stages described in Fig.  2. The figure \nalso shows a zoomed-in view of the area marked in panel B, left. \nFigure 3(D) shows a close-up view of the final result, as marked \nup in the right panel of B. The individual atoms and associated \nstress fields can be clearly seen. The detailed view of the input \nmicrostructure shows that individuals atoms are not provided, \nand rather, solely the overall shape of the crack/material distri-\nbution. The model is still able to predict not only the stress field \nbut also the position of atoms within the domain. A detailed \nvisual inspection confirms that the predicted fields are similar \nin nature from the original data as shown in Fig.  1(C). These \nresults indicate that the model has adequately learned how to \npredict stress fields from input microstructures, for data similar \nto the training set.\nNext, we examine how the model performs for cases that are \ndistinct from the type of data provided in the training set. To \ntest this we next present additional validation cases predicted \nusing the trained model, as shown in Fig.  4. Here we compare \nmicrostructures distinct from the ones included in the training \nset. Figure 4(A–D) show results for a single crack, respectively, \nand Fig.  4(E–H) depict results for a microstructure that fea-\ntures multiple cracks. We emphasize that the training set does \nnot include cases of single cracks. However, as the results show, \nthe model is able to accurately predict the stress field including \nlong-range order. This suggests that the model has learned key \nphysical insights about fracture mechanics in solids, and is able \nto generalize from the training set.\nFigure  5 depicts more comparisons of validation cases of \nsingle cracks (top two) and multiple crack cases (bottom two). \nThe left column of the figure shows a histogram of the Von Mises \nstress field, comparing ground truth and predictions. The results \nshow that the model can accurately predict not only the specific \nstress distributions (see also Fig.  4) but also overall statistics of \nstress fields. This is possible even for cases that are quite distinct \nfrom the training data.\nFor a deeper and quantitative analysis of how the model \nperforms for generalization cases outside of the training set, \nFig. 6 shows a correlation plots between statistical properties \nof the stress fields, for ground truth and model prediction, for \nstandard deviation of the Von Mises stress field [Fig. 6(A)], and \nthe variance [Fig.  6(B)]. The R2 values for the correlations are \n0.97 for the standard deviation and 0.98 for the variance. The \ncolors indicate different types of microstructures considered \n(red = single cracks, blue = multiple cracks). Overall, we find that \nthe correlation is excellent for all cases. The data further shows \nthat single cracks, and the type of multiple-crack geometries \nused in this validation set, are not included in the training set, \nthus serving as a means to test generalizability.\nFigure 7 shows an application of the model to distinct geom-\netries very different from the data seen during training, including \n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1321\nFigure 3:  Predictions based on a test microstructure (A), for the three different stages in the neural network (B). Panel B shows the results for three \ndifferent resolutions (see stages in Fig. 2), and panel D shows a zoomed-in view of the area marked in panel B, left. Panel D depicts a close-up view \nof the final result, as marked up in the right panel of B. The individual atoms and associated stress fields can be clearly seen (top: input, bottom: \nprediction). Visual inspection confirms that the predicted fields are similar in nature from the original data as shown in Fig. 1(C). Detailed, small-scale \nvariations of atomic stresses (marked by the two arrows) can be predicted well using the model, due to the high resolution in this model. The small \nrectangles show even finer zoomed-in views of the input/output, to show more details.\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1322\na crack defined by the MIT logo (A-B) and a star-shaped crack \n(C-D). Close inspection of the results confirms that the model \nmakes accurate predictions in all cases, including the stress fields \nand the overall statistics as seen in the histogram. The field predic-\ntions include an accurate representation of complex relationships \nbetween crack/defect shape and resulting stress field. The model \nis also capable of discerning key fracture mechanics theoretical \npredictions [8], such as showing higher stress concentration at \ncracks perpendicular to the loading condition, and much smaller \nstress concentrations at cracks oriented towards the loading condi-\ntion [Fig. 7(C), for instance]. This general behavior is predicted in \nInglis’ solution [38] [see Fig. 8(A) for geometry] tnat predicts the \nlocal stress at the tip of an elliptical defect:\nwhere σ∞ is the remotely applied stress, and a and b describe \nthe geometry of an elliptical crack. When a ≫ b , the crack is \noriented perpendicar to the loading and yieds high stresses at \nthe crack tip, and vice versa.\nAnalyzing all these validation results, there are specific \ndetails that the model has learned, including the fact that hori-\nzontally oriented cracks show a smaller or vanishing stress con-\ncentration, as opposed to largely vertically oriented cracks that \nlead to a more significant stress concentration. Similar argu-\nments can be made with respect to the size of the crack; where \n(1)σmax = σ∞\n(\n1 + 2 a\nb\n)\n,\nFigure 4:  Validation cases predicted using the trained model, where we compare microstructures distinct from the ones included in the training set. \n(A–D) show results for a single crack, respectively, and (E–H) show results for a system with multiple cracks. The training set does not include cases of \nsingle cracks. However, the model is able to accurately predict the stress field including long-range order. This confirms that the model has learned key \nphysical insights about fracture mechanics in solids, and is able to generalize from the training set.\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1323\nFigure 5:  Additional comparisons of validation cases of single cracks (top 2) and multiple crack cases (bottom 2). The left column of the figure shows \na histogram of the Von Mises stress field, comparing ground truth and predictions. The results show that the model can accurately predict not only \nthe specific stress distributions (see also Fig. 4) but also overall statistics of stress fields. This is possible even for cases that are quite distinct from the \ntraining data.\nFigure 6:  Correlation plots between statistical properties of the stress fields, for ground truth and model prediction, for standard deviation of the Von \nMises stress field (A), and the variance (B). R2 values are 0.97 for the standard deviation (A) and 0.98 for the variance (B). The colors indicate different \ntypes of microstructures considered (red = single cracks, blue = multiple cracks). The correlation is excellent for all cases. Single cracks, and the type of \nmultiple-crack geometries used in this validation set, are not included in the training set, thus serving as a means to test generalizability.\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1324\nlarger defects tend to yield stronger stress concentrations. These \nresults agree well with what is known from fracture mechanics \ntheories [38].\nTo provide further analysis of the results and a compari-\nson with fracture theories, Fig.  8(B) shows a detailed analysis \nof stress field for microstructure with a larger number of cracks \nthan what was seen during training. As can be seen in the fig-\nure, the model captures several important fracture mechanics \nconcepts. The area marked by A shows that large defects yield \nhigh stress concentrations, and asymptotic stress fields across \nmultiple large defects connect to form a stress path. As seen in \nthe two areas marked with B, large defects but orientated in the \nloading direction tend to yield smaller stress concentrations. \nThe area highlighted with C shows a small crack that generates \na relatively small stress concetration. As another example, the \npoint hightlighted with D shows an example for crack tip shield-\ning, whereas the larger neighboring defects play a role to protect \nthe smaller defect.\nCan the model also predict initiation of cracks? Fig.  9 \nshows initial explorations of the model to address this ques-\ntion. Indeed, we identify a potential to not only predict static, \nelastic stress fields near cracks but also a learned capacity \nto predict whether or not cracks will propagate. The two \nexamples shown here where crack propagation occurs, com -\npared with the results shown in Figs.  3, 4, 5 where cracks do \nnot propagate, seems to suggest that the model has already \nlearned certain aspects of this general problem. In fact, close \ninspection of the training dataset does include a few cases \nFigure 7:  Application of the model to distinct geometries very different from the data seen during training, including a crack defined by the MIT logo \n(A, B) and a star-shaped crack (C, D). The model makes accurate predictions in all cases, including the stress fields and the overall statistics as seen in \nthe histogram.\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1325\nwhere cracks nucleate. The model is capable to generalize this \nknowledge and predict, for large cracks and cracks oriented \northogonal to the loading direction, that nucleation occurs. \nThis also agrees with fracture mechanics theories [38]. Fur -\nther, the results shown in Fig.  7(C) where crack initiation is \npredicted at the very top/bottom of the star-shaped defect, but \nnot at the other edges. A more detailed exploration of this and \nrelated aspects is left to future work.\nConclusion\nThis paper reported a comprehensive workflow to translate input \nmicrostructures into complex field predictions. As the results \ndepicted in Figs.  3, 4, 5, 6, 7 reveal, not only does the model \naccurate predict results for input microstructures close to the \noriginal type of structures considered, but generalizes well for \ndistinct cases such as single cracks (Figs. 4, 5, 6, 8) and very dif-\nferent shapes (Fig. 7). Our study was based on a simplistic inter-\natomic potential, used here for proof-of-concept for a model \nmaterial using an existing dataset [27] as a test case, within the \nscope of a model material [8, 39, 40]. This limitation can be eas-\nily addressed by training the model with a dataset derived from \nmore accurate interatomic potentials, [41– 44]and hence more \nrealistic material data [15, 45]. We leave these explorations to \nfuture work but do not anticipate that this is an intrinsic limita-\ntion of the model architecture proposed here, and that it hence \noffers many immediate research opportunities. The input data \ndoes not have to originate from molecular modeling, it can also \nbe based on mesoscale or continuum models, or experimental \ndata.\nAt the outset of this paper we posed three materials science \nquestions. Based on the results reported here, we conclude:\n1. Progressive diffusion models can be an effective approach to \npredict physical field solution from prompts that delineate \nthe input microstructure; based on a deep-learning imple -\nmentation of a conditioned denoising process.\n2. A progressive diffusion transformer model can be trained \nwith a relatively small datasets of only a thousand image-\nto-image pairs.\nFigure 8:  Detailed analysis of stress field for microstructure with a larger number of cracks (25 randomly placed defects of varied size). A close analysis \nof the resulting stress fields reveals that the model captures several important fracture mechanics concepts. (A) Large defects yield high stress \nconcentrations, and asymptotic stress fields across multiple large defects connect to form a stress path. (B) Large defects but orientated in the loading \ndirection tend to yield smaller stress concentrations (see two “tips” marked with B that each do not generate a significant stress concentration). C \nShows a small crack that generates a relatively small stress concentration. The area marked with D depicts an example for crack tip shielding, whereas \nthe larger neighboring defects play a role to protect the smaller defect marked with D.\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1326\n3. Such a model can be used to predict solutions for input \nmicrostructures that are distinct from the types of data seen \nduring training. Importantly, we find that the model can be \nused to generalize solutions.\nThe ability to predict very high-resolution data from sim-\nple input prompts [see, specifically Fig.  3(D), left panels for a \ndetailed view] offers many opportunities, both for image/field-\nbased models as done here but also when treating data explic-\nitly where each “pixel” could represent an individual atom or \nmolecule, or other data. In the way the model was used here, \nthe resolution of the output images is sufficiently high to resolve \nindividual atoms and detailed stress variations—at the atomic \nlevel—near the edges, as is shown for instance in Fig. 3. Moreo-\nver, since transformer models provide a high level of flexibility \nwhen it comes to data modalities, the model can likely be used \nfor a variety of translational problems in the physical sciences, \nincluding text-to-field, or graph-to-property or field translation, \nor others. The use of image data, or by extension, time-series of \nimages or videos, provides a direct linkage with many common \ndatasets obtainable in materials research applications, such as \nhigh-resolution transmission electron microscopy, or others \n[46–48]. It is further noted that while the dataset used for train-\ning the model in this paper was based on one particular bound-\nary condition (see Fig. 1), this can be generalized to either train \nmultiple models for varied boundary conditions, or to train one \nmodel whereby different boundary conditions are encoded in \nthe prompt.\nAnother exciting direction is the exploration of the model to \npredict crack initiation, or even multiple frames of cracking. The \ninitial observation shown in Fig. 9 suggests that this is indeed in \nthe realm of possibility. Other future directions can be a direct \nimplementation of various boundary conditions, which can be \nrealized easily as additional input in the transformer architec-\nture. Similar to a text prompt, the ability to provide a variety of \nmodalities and descriptors to drive the generation of the final \nprediction, the formulation based on a language model provides \ninnate advantages.\nIn regards to the size of the training set, we deliberately \ndesigned this computational experiment to use a very small \ndataset of only 1000 pairs of input microstructures and fields. \nWe showed that even with this limitation, the model has learned \nto generalize predictions and learned physical insights. This \noffers exciting possibilities for extensions of this work by using \nlarger datasets or transfer learning that have already been shown \nto perform well for attention-based models both in language \napplications and in language model based physics applications \n[26, 49].\nAlong those lines, we expect that adding more data to the \ntraining set—and using larger sets of pairs of images, would help \nto improve the model. Albeit the computational experiments \nreported here were designed to focus on a very small dataset and \nspecifically on atomic-level stress data derived from molecular \nsimulations, this would likely expand the transferability and \nprediction capacity of the model even further.\nIn terms of computational expense, a model trained on rela-\ntively small datasets can provide rapid predictions. Whereas the \ngeneration of the dataset may take significant computational \nresources, along with the training cost, a trained model offers \nunprecedented access to a vast design space of solutions. A key \nFigure 9:  In initial explorations of the model we identify a potential to not only predict static, elastic stress fields near cracks but also a learned capacity \nto predict whether or not cracks will propagate. The two examples shown here where crack propagation occurs, compared with the results shown \nin Figs. 3, 4, 5 where cracks do not propagate, seems to suggest that the model has already learned certain aspects of this general problem. In fact, \nclose inspection of the training dataset does include a few cases where cracks nucleate. The model seems to be able to generalize this knowledge and \npredict, for large cracks and cracks oriented orthogonal to the loading direction, that nucleation occurs. Due to the stochastic nature of cracking, the \nmodel shows some more pronounced differences between the prediction and ground truth near the crack tips where cracking occurs.\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1327\nelement is the use of advanced diffusion algorithms [35] that \nallows us to obtain excellent results with only 96 total diffusion \nsteps (as opposed to 1000 s in the original approach [ 34]). This \noffers a substantial computational advantage during generation \nand validation.\nWhile the methods developed and reported in the paper \nis believed to be generally applicable to any kind of field data, \nthe specific training set used to train the deep learning model is \ndeveloped from atomistic-level simulations. As such, the predic-\ntions only hold for atomic-level stresses near cracks. Additional \ntraining data would be needed, e.g., developed from experimen-\ntal measurements [e.g., digital image correlation, DIC [50]] or \ncontinuum models, to expand the applicability including via the \nuse of multiscale modeling schemes [51–53]. This is beyond the \nscope of the paper, however, but opens exciting opportunities for \nfuture work in particular in conjuction with transfer learning \nstrategies. More broadly, some studies have provided evidence \nfor the validity of continuum theories at the atomistic scale [ 8, \n54–56], including recent experimental-computational studies that \ncompared atomic-level deformations from simulations with high-\nresolution in situ TEM [57]. Going beyond the current scope of \nthe model that did not include plasticity, future work may include \na range of other dissipative effects near cracks (including plastic-\nity, dislocation nucleation, etc.) and damage spreading, and more \ngenerally a full analysis of the dynamics of failure.\nMaterials and methods\nMolecular dynamics (MD) simulations and dataset \ngeneration\nA simple setup of a fracture model of is used to generate the \ndataset, which consists of input microstructures and cor -\nresponding stress fields [8 , 41, 58], as originally reported in \n[27]. Here we provide only a short review of that dataset for \ncompleteness of the presentation. We consider the geometry \nshown in Fig. 1(A, B), depicting a simple triangular lattice with a \n12:6 Lennard–Jones (LJ) interatomic interactions [59, 60] under \nuniaxial loading.\nThe LJ interatomic potential used here takes the form\nWhile the LJ potential is a simplistic representation of mate-\nrials, its use in a 2D hexagonal geometry yields a brittle material \n[8, 60], which serves the purpose of the study reported here as a \n(2)φ( rij) = 4ε\n[( σ\nrij\n)12\n−\n( σ\nrij\n)6]\nsimple material model (hence, mechanisms around cracks, once \nfailure is initiatied, are largely bond rupture events in accord-\nance with what is seen in brittle materials). The input geometry \nfeatures a series of randomly located and oriented cracks of dif-\nferent sizes and aspect ratios, as shown in Fig.  1(B), showing \nalso the fixed boundaries in which forces and velocities of atoms \nare set to zero to allow for application of strain for mechanical \nloading. The system is confined to 2D atomic motions in the x- \nand y-directions. The LJ interatomic potential parameters used \nin the generation of the dataset, as defined in Eq. (2 ) (see [27] \nfor further details) are ε = 1 and σ = 1 with a cutoff radius of \nrcut = 1.2 (all simulations carried out in non-dimensional units). \nFor instance, lengths are expressed as x *=x/σ and pressures/\nstresses are expressed as p∗ = p σ 3\nε  . As marked with the scale bar, \nthe system size is approximately 32 nm (assuming that σ = 1 Å).\nIt is emphasized that the training set used to train the \nmodel includes only cases with a larger number of randomly \nsituated cracks (see Supplementary Information). Validation \ncases include both very small/single crack cases or scenarios \nwith a much larger number of defects and with a different \ncrack geometry than what was used in training.\nThe MD simulations are carried out using the LAMMPS \nsimulation package. All samples are exposed to homogeneous \nuniaxial tensile strain of 1% in the x -direction. As described \nin [27] we compute atomic von Mises stress σvonMises [61] in \nLAMMPS [9 ]. The fields are then visualized using matplotlib \nand we save images of both the input microstructure and the \nresulting stress fields to generate the data sets (see Fig.  1(C) \nfor examples of the image pairs including a zoomed-in view). \nInput and output images are stored in CSV files and then used \nby the data reader for processing in the machine learning code.\nFor the discussions in this paper we limit the exploration to \nthe Von Mises stress as a simple stress measure that allows us to \nplot field data; whereas the von Mises stress is calculated from \nthe stress tensor σij as:\nWe generate field plots by using the matplotlib scatter func-\ntion; where blue corresponds to p* = 0.00053 and red to p* = 2.84 \n(stress values smaller or larger than these limits are plotted in \nblue or red, respectively). It is noted that the work reported here \nfocus on pre-cracking stress fields where we primarily observe \nstretching of bonds (and hence generating particular stress fields \nbased on the interatomic forces). That being said, some incipi -\nent failure mechanisms are observed, as shown in Fig. 9 and the \nsurrounding discussion.\nThe stress contour plots along slices of the simulation \ndomain are obtained by converting the field data with 3 color \nchannels into a grayscale image, by multiplying the three \n(3)σ von Mises =\n√\n1\n2\n(\n(σ 11 − σ 22)2 + (σ 22 − σ 33)2 + (σ 33 − σ 11)2 + 6\n(\nσ 2\n23 + σ 2\n31 + σ 2\n12\n))\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1328\nchannels with [0.299, 0.5870, 0.114] and then adding them, \nyielding a scalar field data of the van Mises stress and micro-\nstructure, respectively, that measures pixel-level intensity. All \nstress values are normalized such that the smallest value overall \nis 0, and the largest 1, for simpler comparison in the field plots \nand the histogram analysis.\nThe final training set used for the neural network training is \nbased on 1000 images total for the computational experiments, \n90% of which is used for training and the rest for testing. The \ndataset can be accessed at https:// www. dropb  ox. com/s/ 3i22i \ngvfee b3iac/ DataS et_ large_ mosaic. zip? dl=0.\nAdditional validation examples are created consisting of \nsingle cracks and a series of cases with multiple cracks but \ndifferent crack geometries and number of cracks than in the \ntraining set. Further, we generate a validation set that includes \ndistinct geometries of cracks such as the MIT logo and a star-\nshaped void.\nTABLE 1:  Parameters used in the \nprogressive transformer diffusion \nmodel (parameters for the three \nU-Nets, the integrated architecture, \nand additional parameters are \nprovided). See also Fig. S2.\nNeural network component Parameter Value\nUnet 1 Dimension 128\nDimension multipliers 1, 2, 3, 4\nLayer attentions False, True, True, True\nLayer cross-attentions False, True, True, True\nResnet blocks 3, 3, 3, 3\nAttention heads 8\nFeed forward multiplier 2.0\nUnet 2 Dimension 128\nDimension multipliers 1, 2, 4, 8\nLayer attentions False, False, False, True\nLayer cross-attentions False, False, False, True\nResnet blocks 2, 4, 4, 8\nAttention heads 8\nFeed forward multiplier 2.0\nUnet 3 Dimension 128\nDimension multipliers 1, 2, 3, 4\nLayer attentions False, False, False, True\nLayer cross-attentions False, False, False, True\nResnet blocks 2, 3, 3, 3\nAttention heads 8\nFeed forward multiplier 2.0\nIntegrated architecture (com-\nprised of Unet 1, 2 and 3)\nImage sizes 128 × 128\n512 × 512\n1024 × 1024\nCond. drop probability 0.1\nSample steps (for Unet 1,\nUnet 2, Unet 3)\n64, 32, 32\nσmin 0.002\nσmax(for Unet 1, Unet 2, Unet 3) 80, 160, 160\nσdata 0.5\nρ 7\nPmean − 1.2\nPstd 1.2\nPchurn 80\nSt,min 0.05\nSt,max 50\nSnoise 1.003\nAdditional parameters Optimizer and parameters Adam Learning \nrate = 1E-4, epsilon = 1e-8, \nbetas = (0.9,0.99)\nBatch sizes (for Unet 1, Unet 2, Unet 3) 5, 5, 1\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1329\nMachine learning model\nOur model is based on the Imagen architecture [34], but instead of \nconditioning the input on text prompts we condition the predic-\ntions on microstructure embeddings (which define the material’s \nmicrostructure), as shown schematically in Fig. 2. The model con-\nsists of three U-Net architectures: Unet 1 (constructed based on \n[36]), Unet 2 and Unet 3 (both constructed as Efficient U-Nets as \nproposed in [37]) that are used to translate the input microstructure \ninto the final field output, over three successive stages of translation \nand upscaling, ultimately reaching a resolution of 1024 × 1024.\nAs proposed in [35, 62] we use the improved sampling \nand training processes, which yield computationally more effi -\ncient and better predictions. Table  1 provides details about \nthe model architecture and Fig. S2 a detailed PyTorch model \nreadout to reveal the entire architecture. The implementation \nis based on the code published at [ 63].\nThe microstructure encoder scales the 8-bit pixel values to \nbe between 0 and 1 and feeds each of the three-color channels to \nthe neural networks in the embedding dimension. Since the input \nmicrostructures solely consist of white (no material) and black \n(material) building blocks, the input embeddings consist solely of \n(1,1,1) and (0,0,0) tensors for each building block that makes up \nthe material microstructure. In some sense, this can be seen as a \nlanguage prompt that provides a series of letters—“W” for void, \n“B” for material, to the model. Future work can expand on this \neasily and provide either more material choices or gradations, or \ntext prompts that describe certain types of boundary conditions.\nThe total number of parameters in the model is \n987,891,378. Unet 1 features 107,837,860 trainable param -\neters, Unet 2 735,122,066 trainable parameters and Unet 3 \n144,931,452 trainable parameters: 144,931,452.\nThe model is trained successfully, whereby each of the \nU-Nets is trained individually (first Unet 1, then Unet 2, and \nthen Unet 3). Training performances are shown in Figs. S3 \nand S4. Unet 1 is trained for 18 K steps, and Unet 2/Unet 3 are \ntrained for 27 K steps each.\nAcknowledgments \nSupport from the MIT-IBM Watson AI Lab, and MIT-\nQuest is acknowledged. We acknowledge support from ARO \n(W911NF1920098), NIH (U01EB014976 and 1R01AR077793) \nand ONR (N00014-19-1-2375 and N00014-20-1-2189). Addi-\ntional support is provided by USDA (2021-69012-35978).\nSoftware versions and hardware \nWe use Python 3.8.12, PyTorch 1.10 with CUDA (CUDA \nversion 11.6), and a NVIDIA RTX A6000 with 48 GB VRAM \nfor training and inference.\nAuthor contributions \nMJB conceived the study, developed and trained the neural \nnetwork and associated data analysis, including fracture models, \nand wrote the paper.\nFunding \nOpen Access funding provided by the MIT Libraries.\nData availability \nThe dataset is included as link to a repository in Materi-\nals and Methods. Other data and codes are either available on \n GitHub64 or will be provided by the author based on reasonable \nrequest.\nDeclarations \nConflict of interest The authors declare no conflict of interest.\nOpen Access\nThis article is licensed under a Creative Commons Attribu-\ntion 4.0 International License, which permits use, sharing, adap-\ntation, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) \nand the source, provide a link to the Creative Commons licence, \nand indicate if changes were made. The images or other third \nparty material in this article are included in the article’s Creative \nCommons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Crea -\ntive Commons licence and your intended use is not permitted \nby statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. \nTo view a copy of this licence, visit http:// creat iveco mmons. org/ \nlicen ses/ by/4. 0/.\nSupplementary Information\nThe online version contains supplementary material avail-\nable at https:// doi. org/ 10. 1557/ s43578- 023- 00892-3.\nReferences\n 1. Q. Tong, S. Li, A concurrent multiscale study of dynamic frac-\nture. Comput Methods Appl Mech Eng 366, 113075 (2020)\n 2. T.L. Anderson, Fracture mechanics: fundamentals and applica-\ntions (Taylor & Francis, 2005)\n 3. G. Jung, Z. Qin, M.J. Buehler, Molecular mechanics of polycrys-\ntalline graphene with enhanced fracture toughness. Extreme \nMech Lett 2, 52 (2015)\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1330\n 4. M.J. Buehler, H. Tang, A.C.T. van Duin, W .A. Goddard, Thresh-\nold crack speed controls dynamical fracture of silicon single \ncrystals. Phys Rev Lett (2007). https:// doi. org/ 10. 1103/ PhysR \nevLett. 99. 165502\n 5. S. Suresh, Fatigue of materials (Cambridge University Press, \n1998)\n 6. L. Anand, S. Govindjee, Continuum mechanics of solids (Oxford \nUniversity Press, 2020)\n 7. L.B. Freund, Dynamic fracture mechanics (Cambridge University \nPress, 1990)\n 8. M.J. Buehler, Atomistic modeling of materials failure (Springer, \n2008)\n 9. A.P . Thompson et al., LAMMPS—a flexible simulation tool for \nparticle-based materials modeling at the atomic, meso, and \ncontinuum scales. Comput Phys Commun 271, 108171 (2022)\n 10. M.J. Buehler, Atomistic and continuum modeling of mechanical \nproperties of collagen: elasticity, fracture, and self-assembly. J \nMater Res 21, 1947–1961 (2006)\n 11. H. Qin, Machine learning and serving of discrete field theories. \nSci Rep 10, 19329 (2020)\n 12. J. Tang et al., Machine learning-based microstructure prediction \nduring laser sintering of alumina. Sci. Rep. 11, 10724 (2021)\n 13. S.K. Kauwe, J. Graser, R. Murdock, T.D. Sparks, Can machine \nlearning find extraordinary materials? Comput Mater Sci 174, \n109498 (2020)\n 14. J. Schmidt, M.R.G. Marques, S. Botti, M.A.L. Marques, Recent \nadvances and applications of machine learning in solid-state \nmaterials science. Comput. Mater. 5, 1–36 (2019). https:// doi. \norg/ 10. 1038/ s41524- 019- 0221-0\n 15. K.G. Reyes, B. Maruyama, The machine learning revolution in \nmaterials? MRS Bull 44, 530–537 (2019)\n 16. E. Lejeune, Mechanical MNIST: a benchmark dataset for \nmechanical metamodels. Extreme Mech Lett 36, 100659 (2020)\n 17. L. Yuan, H.S. Park, E. Lejeune, Towards out of distribution \ngeneralization for problems in mechanics. Comput Sci (2022). \nhttps:// doi. org/ 10. 48550/ arxiv. 2206. 14917\n 18. A. Vaswani et al., Attention is all you need, in Advances in neural \ninformation processing systems. (Neural information processing \nsystems foundation, 2017)\n 19. S. Chaudhari, V . Mithal, G. Polatkan, R. Ramanath, An attentive \nsurvey of attention models. J. ACM 37, 1–10 (2019)\n 20. P . Esser, R. Rombach, B. Ommer, Taming transformers for high-\nresolution image. Synthesis (2020). https:// doi. org/ 10. 1109/ cvpr4 \n6437. 2021. 01268\n 21. D.I. Spivak, T. Giesa, E. Wood, M.J. Buehler, Category theoretic \nanalysis of hierarchical protein materials and social networks. \nPLoS ONE 6, e23911 (2011)\n 22. T. Giesa, D.I. Spivak, M.J. Buehler, Category theory based solu-\ntion for the building block replacement problem in materials \ndesign. Adv Eng Mater 14, 810 (2012)\n 23. Z. Y ang, M.J. Buehler, Words to matter: de novo architected \nmaterials design using transformer neural networks. Front Mater \n8, 740754 (2021)\n 24. Y .C. Hsu, Z. Y ang, M.J. Buehler, Generative design, manufactur-\ning, and molecular modeling of 3D architected materials based \non natural language input. APL Mater 10, 041107 (2022)\n 25. M.J. Buehler, DeepFlames: neural network-driven self-assembly \nof flame particles into hierarchical structures. MRS Commun 12, \n257–265 (2022)\n 26. M.J. Buehler, FieldPerceiver: domain agnostic transformer model \nto predict multiscale physical fields and nonlinear material prop-\nerties through neural ologs. Mater. Today 57, 9–25 (2022)\n 27. E.L. Buehler, M.J. Buehler, End-to-end prediction of multima-\nterial stress fields and fracture patterns using cycle-consistent \nadversarial and transformer neural networks. Biomed. Eng. Adv. \n4, 100038 (2022)\n 28. Z. Y ang, C.H. Yu, K. Guo, M.J. Buehler, End-to-end deep learn-\ning method to predict complete strain and stress tensors for \ncomplex hierarchical composite microstructures. J Mech Phys \nSolids 154, 104506 (2021)\n 29. Z. Y ang, C.H. Yu, M.J. Buehler, Deep learning model to predict \ncomplex stress and strain fields in hierarchical composites. Sci \nAdv (2021). https:// doi. org/ 10. 1126/ sciadv. abd74 16\n 30. K. Crowson et al., VQGAN-CLIP: open domain image genera-\ntion and editing with natural language guidance. Comput Sci \n(2022). https:// doi. org/ 10. 48550/ arxiv. 2204. 08583\n 31. A. Nichol et al., GLIDE: towards photorealistic image genera-\ntion and editing with text-guided diffusion models. Comput Sci \n(2021). https:// doi. org/ 10. 48550/ arxiv. 2112. 10741\n 32. A. Ramesh, P . Dhariwal, A. Nichol, C. Chu, M. Chen, Hierarchi-\ncal text-conditional image generation with CLIP latents. Comput \nSci (2022). https:// doi. org/ 10. 48550/ arxiv. 2204. 06125\n 33. Marcus, G., Davis, E. & Aaronson, S. A very preliminary analysis \nof DALL-E 2. Comput Sci (2022). https:// doi. org/ 10. 48550/ arxiv. \n2204. 13807.\n 34. C. Saharia et al., Photorealistic text-to-image diffusion models \nwith deep language understanding. (2022). https:// doi. org/ 10. \n48550/ arxiv. 2205. 11487\n 35. T. Karras, M. Aittala, T. Aila, S. Laine, Elucidating the design \nspace of diffusion-based generative models (2022). https:// doi. \norg/ 10. 48550/ arxiv. 2206. 00364\n 36. A. Nichol, P . Dhariwal, Improved denoising diffusion probabilis-\ntic models (2021). https:// arxiv. org/ abs/ 2102. 09672\n 37. Saharia, C. et al. Palette: image-to-image diffusion models \n(2021). https:// doi. org/ 10. 48550/ arxiv. 2111. 05826.\n 38. C.E. Inglis, Stresses in a plate due to the presence of cracks and \nsharp corners. Trans Inst Naval Archit 55, 219–230 (1913)\n 39. M.J. Buehler, Large-scale hierarchical molecular modeling of \nnano- structured biological materials. J Comput Theor Nanosci \n3, 603–623 (2006)\n  Journal of Materials Research   Volume 38   Issue 5  March 2023  www.mrs.org/jmr\nArticle\n© The Author(s) 2023 1331\n 40. M.J. Buehler, H. Gao, Dynamical fracture instabilities due to \nlocal hyperelasticity at crack tips. Nature 439, 307–310 (2006)\n 41. M.J. Buehler, A.C.T. van Duin, W .A. Goddard III., Multipara-\ndigm modeling of dynamical crack propagation in silicon using a \nreactive force field. Phys Rev Lett 96, 095505 (2006)\n 42. H. Manzano, R.J.M. Pellenq, F .J. Ulm, M.J. Buehler, A.C.T. van \nDuin, Hydration of calcium oxide surface predicted by reactive \nforce field molecular dynamics. Langmuir 28, 4187 (2012)\n 43. J. Behler, M. Parrinello, Generalized neural-network representa-\ntion of high-dimensional potential-energy surfaces. Phys Rev \nLett 98, 1–4 (2007)\n 44. T. Liang, S.R. Phillpot, S.B. Sinnott, Parametrization of a reactive \nmany-body potential for Mo-S systems. Phys Rev B Condens \nMatter Mater Phys (2009). https:// doi. org/ 10. 1103/ PhysR evB. 79. \n245110\n 45. A. Jain et al., Commentary: the materials project: a materials \ngenome approach to accelerating materials innovation. APL \nMater 1, 011002 (2013)\n 46. L. Himanen, A. Geurts, A.S. Foster, P . Rinke, Data-driven mate-\nrials science: status, challenges, and perspectives. Adv. Sci. 6, \n1900808 (2019)\n 47. R. Pollice et al., Data-driven strategies for accelerated materials \ndesign. Acc Chem Res 54, 849–860 (2021)\n 48. R. Gómez-Bombarelli et al., Automatic chemical design using a \ndata-driven continuous representation of molecules. ACS Cent \nSci 4, 268–276 (2018)\n 49. T.B. Brown et al., Language models are few-shot learners. Adv \nNeural Inf Process Syst 2020, 1–10 (2020)\n 50. T.C. Chu, W .F . Ranson, M.A. Sutton, Applications of digital-\nimage-correlation techniques to experimental mechanics. Exp. \nMech 25, 232–244 (1985)\n 51. X. Y an, P . Cao, W . Tao, P . Sharma, H.S. Park, Atomistic modeling \nat experimental strain rates and timescales. J Phys D Appl Phys \n49, 493002 (2016)\n 52. A.T. Fenley, H.S. Muddana, M.K. Gilson, Calculation and visu-\nalization of atomistic mechanical stresses in nanomaterials and \nbiomolecules. PLoS ONE 9, e113119 (2014)\n 53. G.C.Y . Peng et al., Multiscale modeling meets machine learning: \nwhat can we learn? Archiv. Comput. Methods Eng. 1, 3 (2020)\n 54. M.J. Buehler, H. Gao, Y . Huang, Atomistic and continuum stud-\nies of a suddenly stopping supersonic crack. Comput Mater Sci \n28, 385 (2003)\n 55. M.J. Buehler, F .F . Abraham, H. Gao, Continuum and atomistic \nmodeling of dynamic fracture at nanoscale, in 11th interna-\ntional conference on fracture 2005. (Curran Associates Inc, \n2005)\n 56. M.J. Buehler, H. Gao, Y . Huang, Atomistic and continuum stud-\nies of stress and strain fields near a rapidly propagating crack \nin a harmonic lattice. Theoret. Appl. Fract. Mech. 41, 21–42 \n(2004)\n 57. S.S. Wang et al., Atomically sharp crack tips in monolayer MoS2 \nand their enhanced toughness by vacancy defects. ACS Nano 10, \n9831–9839 (2016)\n 58. X. Wang, A. Tabarraei, D.E. Spearot, Fracture mechanics of \nmonolayer molybdenum disulfide. Nanotechnology 26, 175703 \n(2015)\n 59. Z. Xu, M.J. Buehler, Interface structure and mechanics between \ngraphene and metal substrates: a first-principles study. J. Phys. \nCondens. Matter 22, 485301 (2010)\n 60. M.P . Allen, D. Tildesley, J. Comput Simul. Liquids. 385, 1–10 (1987)\n 61. R.V . Mises, Mechanik der festen Körper im plastisch- deforma-\nblen Zustand. Nachrichten von der Gesellschaft der Wissen-\nschaften zu Göttingen, Mathematisch-Physikalische Klasse 1913, \n582–592 (1913)\n 62. P . Vincent, A connection between scorematching and denoising \nautoencoders. Neural Comput 23, 1661–1674 (2011)\n 63. lucidrains/imagen-pytorch: implementation of imagen, Google’s \ntext-to-image neural network, in Pytorch. https:// github. com/ \nlucid rains/ imagen- pytor ch.\nPublisher’s Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Materials science",
  "concepts": [
    {
      "name": "Materials science",
      "score": 0.6851586103439331
    },
    {
      "name": "Transformer",
      "score": 0.6783643960952759
    },
    {
      "name": "Generalizability theory",
      "score": 0.6618390083312988
    },
    {
      "name": "High fidelity",
      "score": 0.5494774580001831
    },
    {
      "name": "Fidelity",
      "score": 0.4729349911212921
    },
    {
      "name": "Computer science",
      "score": 0.36138346791267395
    },
    {
      "name": "Voltage",
      "score": 0.14815980195999146
    },
    {
      "name": "Physics",
      "score": 0.09323433041572571
    },
    {
      "name": "Acoustics",
      "score": 0.09174972772598267
    },
    {
      "name": "Mathematics",
      "score": 0.07637223601341248
    },
    {
      "name": "Telecommunications",
      "score": 0.0
    },
    {
      "name": "Statistics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I63966007",
      "name": "Massachusetts Institute of Technology",
      "country": "US"
    }
  ]
}