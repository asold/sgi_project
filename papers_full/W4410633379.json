{
    "title": "A Methodology Framework for Analyzing Health Misinformation to Develop Inoculation Intervention Using Large Language Models: A case study on covid-19",
    "url": "https://openalex.org/W4410633379",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A3049039270",
            "name": "Samira Malek",
            "affiliations": [
                "Pennsylvania State University"
            ]
        },
        {
            "id": "https://openalex.org/A1978286117",
            "name": "Christopher Griffin",
            "affiliations": [
                "Pennsylvania State University"
            ]
        },
        {
            "id": "https://openalex.org/A4227875368",
            "name": "Robert Fraleigh",
            "affiliations": [
                "Pennsylvania State University"
            ]
        },
        {
            "id": "https://openalex.org/A2676100313",
            "name": "Robert P. Lennon",
            "affiliations": [
                "UPMC Central Pa"
            ]
        },
        {
            "id": "https://openalex.org/A2087399380",
            "name": "Vishal Monga",
            "affiliations": [
                "Pennsylvania State University"
            ]
        },
        {
            "id": "https://openalex.org/A2071835499",
            "name": "Lijiang Shen",
            "affiliations": [
                "Pennsylvania State University"
            ]
        },
        {
            "id": "https://openalex.org/A3049039270",
            "name": "Samira Malek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1978286117",
            "name": "Christopher Griffin",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4227875368",
            "name": "Robert Fraleigh",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2676100313",
            "name": "Robert P. Lennon",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2087399380",
            "name": "Vishal Monga",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2071835499",
            "name": "Lijiang Shen",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4399585824",
        "https://openalex.org/W3128392043",
        "https://openalex.org/W3048862978",
        "https://openalex.org/W2900471836",
        "https://openalex.org/W2062321610",
        "https://openalex.org/W2088796307",
        "https://openalex.org/W2081347231",
        "https://openalex.org/W2117485795",
        "https://openalex.org/W2058049360",
        "https://openalex.org/W3010721747",
        "https://openalex.org/W1124348177",
        "https://openalex.org/W4206809277",
        "https://openalex.org/W1502957213",
        "https://openalex.org/W2974087526",
        "https://openalex.org/W2888571776",
        "https://openalex.org/W3007198457",
        "https://openalex.org/W3160227221",
        "https://openalex.org/W3015622078",
        "https://openalex.org/W3011345566",
        "https://openalex.org/W2999170785",
        "https://openalex.org/W4220847937",
        "https://openalex.org/W4362663262",
        "https://openalex.org/W3046729981",
        "https://openalex.org/W3016902371",
        "https://openalex.org/W2128737857",
        "https://openalex.org/W2136111158",
        "https://openalex.org/W2911188335",
        "https://openalex.org/W3197089912",
        "https://openalex.org/W2135498674",
        "https://openalex.org/W4410633379",
        "https://openalex.org/W4366588626",
        "https://openalex.org/W4394717795",
        "https://openalex.org/W3192422294",
        "https://openalex.org/W3197515449",
        "https://openalex.org/W4409012490",
        "https://openalex.org/W4391341960",
        "https://openalex.org/W4400769653",
        "https://openalex.org/W3123176014",
        "https://openalex.org/W4366188816",
        "https://openalex.org/W3049038845",
        "https://openalex.org/W4391328043",
        "https://openalex.org/W3153760598",
        "https://openalex.org/W4399879571",
        "https://openalex.org/W3158488293",
        "https://openalex.org/W3033077667",
        "https://openalex.org/W3031152300",
        "https://openalex.org/W3136503798",
        "https://openalex.org/W4292478702",
        "https://openalex.org/W4229011615",
        "https://openalex.org/W4306377799",
        "https://openalex.org/W2038043464",
        "https://openalex.org/W2803437449",
        "https://openalex.org/W3030163527",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W4386365817",
        "https://openalex.org/W3120764866"
    ],
    "abstract": "Abstract Background The rapid growth of social media as an information channel has enabled the swift spread of inaccurate or false health information, significantly impacting public health. This widespread dissemination of misinformation has caused confusion, eroded trust in health authorities, led to noncompliance with health guidelines, and encouraged risky health behaviors. Understanding the dynamics of misinformation on social media is essential for devising effective public health communication strategies. Objective This study aims to present a comprehensive and automated approach that leverages Large Language Models (LLMs) and Machine Learning (ML) techniques to detect misinformation on social media, uncover the underlying causes and themes, and generate refutation arguments, facilitating control of its spread and promoting public health outcomes by inoculating people against health misinformation. Methods We use two datasets to train three LLMs, namely BERT, T5, and GPT-2, to classify documents into two categories: misinformation and non-misinformation. Additionally, we employ a separate dataset to identify misinformation topics. To analyze these topics, we apply three topic modeling algorithms‚ÄîLatent Dirichlet Allocation (LDA), Top2Vec, and BERTopic‚Äîand selected the optimal model based on performance evaluated across three metrics. Using a prompting approach, we extract sentence-level representations for the topics to uncover their underlying themes. Finally, we design a prompt text capable of identifying misinformation themes effectively. Results The trained BERT model demonstrated exceptional performance, achieving 98% accuracy in classifying misinformation and non-misinformation, with a 44% reduction in false positive rates for AI-generated misinformation. Among the three topic modeling approaches employed, BERTopic outperformed the others, achieving the highest metrics with a Coherence Value (CV) of 0.41, Normalized Pointwise Mutual Information (NPMI) of -0.086, and Inverted RBO (IRBO) of 0.99. To address the issue of unclassified documents, we developed an algorithm to assign each document to its closest topic. Additionally, we proposed a novel method using prompt engineering to generate sentence-level representations for each topic, achieving a 99.6% approval rate as ‚Äúappropriate‚Äù or ‚Äúsomewhat appropriate‚Äù by three independent raters. We further designed a prompt text to identify themes of misinformation topics and developed another prompt capable of detecting misinformation themes with 80% accuracy. Conclusions This study presents a comprehensive and automated approach to addressing health misinformation on social media using advanced machine learning and natural language processing techniques. By leveraging large language models (LLMs) and prompt engineering, the system effectively detects misinformation, identifies underlying themes, and provides explanatory responses to combat its spread. (Journal of Medical Internet Research) doi:",
    "full_text": "Original Paper \nSamira Malek1, MS; Christopher Griffin2,3, PhD; Robert Fraleigh2, PhD; Robert P. \nLennon4, MD, JD;  Vishal Monga5, PhD; Lijiang Shen6, PhD \n1Department of Computer Science and Engineering, Pennsylvania State University, State \nCollege, PA, United State \n2Applied Research Laboratory, Pennsylvania State University, State College, PA, United \nState \n3Department of Mathematics, Pennsylvania State University, State College, PA, United \nState \n4 PrimeCare Medical, Harrisburg, PA, United State \n5 Department of Electrical Engineering, Pennsylvania State University, State College, PA, \nUnited State \n6 Department of Communication Arts and Science, Pennsylvania State University, State \nCollege, PA, United State  \nA Methodology Framework for Analyzing Health Misinformation \nto Develop Inoculation Intervention Using Large Language \nModels: A case study on covid-19 \nAbstract \nBackground: The rapid growth of social media as an information channel has enabled the \nswift spread of inaccurate or false health information, significantly impacting public \nhealth. This widespread dissemination of misinformation has caused confusion, eroded \ntrust in health authorities, led to noncompliance with health guidelines, and encouraged \nrisky health behaviors. Understanding the dynamics of misinformation on social media is \nessential for devising effective public health communication strategies. \nObjective: This study aims to present a comprehensive and automated approach that \nleverages Large Language Models (LLMs) and Machine Learning (ML) techniques to detect \nmisinformation on social media, uncover the underlying causes and themes, and generate \nrefutation arguments , facilitating control of its spread and promoting public health \noutcomes by inoculating people against health misinformation. \nMethods: We use two datasets to train three LLMs, namely BERT, T5, and GPT -2, to \nclassify documents into two categories: misinformation and non -misinformation. \nAdditionally, we employ a separate dataset to identify misinformation topics. To analyze \nthese topics, we apply three topic modeling algorithms‚ÄîLatent Dirichlet Allocation (LDA), \nTop2Vec, and BERTopic ‚Äîand selected the optimal model based on performance \nevaluated across three metrics. Using a prompting approach, we extract sentence -level \nrepresentations for t he topics to uncover their underlying themes. Finally, we design a \nprompt text capable of identifying misinformation themes effectively. \nResults: The trained BERT model demonstrated exceptional performance, achieving 98% \naccuracy in classifying misinformation and non -misinformation, with a 44% reduction in \nfalse positive rates for AI -generated misinformation. Among the three topic modeling \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\napproaches employed, BERTopic outperformed the others, achieving the highest metrics \nwith a Coherence Value (CV) of 0.41, Normalized Pointwise Mutual Information (NPMI) \nof -0.086, and Inverted RBO (IRBO) of 0.99. To address the issue of unclassified \ndocuments, we developed an algorithm to assign each document to its closest topic. \nAdditionally, we proposed a novel method using prompt engineering to generate \nsentence-level representations for each topic, achieving a 99.6% approval rate as \n\"appropriate\" or \"s omewhat appropriate\" by three independent raters. We further \ndesigned a prompt text to identify themes of misinformation topics and developed \nanother prompt capable of detecting misinformation themes with 80% accuracy. \nConclusions: This study presents a comprehensive and automated approach to \naddressing health misinformation on social media using advanced machine learning and \nnatural language processing techniques. By leveraging large language models (LLMs) and \nprompt engineering, the system effectively detects misinformation, identifies underlying \nthemes, and provides explanatory responses to combat its spread. \n(Journal of Medical Internet Research) doi: \nKeywords:  \nLarge language models; topic modeling, prompt engineering; Covid-19; misinformation, \nMachine Learning \n \nIntroduction \n \nMisinformation and inaccurate beliefs and knowledge about health can substantially \nundermine well-being by fueling confusion, eroding trust in reliable medical advice, and \nprompting risky behaviors such as rejecting vaccines, turning to scientifically unproven \nhome remedies, or neglecting protective measure s amid clear dangers (1‚Äì8). These \ninaccuracies often circulate rapidly via social media, exploiting emotional narratives that \novershadow fact -based content and leading individuals to question the legitimacy of \nevidence-based interventions (5,8‚Äì11). Repeated exposure  to misinformation reduces \nhealth literacy and can reinforce people‚Äôs belief in falsehoods, making them more likely \nto view credible health authorities with skepticism (12‚Äì14). As a result, misinformation \nweakens the success of prevention and treatment strategies, paving the way for \nheightened disease transmission, avoidable complications, and deteriorating outcomes \nat both individual and community levels (15‚Äì18). \n \nAn illustration comes from the COVID -19 pandemic, which saw an unprecedented surge \nof misinformation and conspiracy theories‚Äîlabeled an ‚Äúinfodemic‚Äù by the World Health \nOrganization (1,19). False remedies, unverified claims on the origins of the virus, and \npoliticized narratives about preventive measures severely hampered containment efforts \n(20‚Äì22). While proven strategies such as mask -wearing, vaccination, and physical \ndistancing were promoted by scientific authorities, social media rumors cast doubt on \nvaccine safety and the reality of the virus itself, discouraging people from getting \nvaccinated or seeking appropriate medical care (2,23‚Äì25). This breakdown in adherence \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nprolonged outbreaks, overloaded health infrastructures, and ultimately jeopardized \nglobal health and economic stability (26).  \n \nA parallel can be drawn from discussions around the human papillomavirus (HPV) vaccine, \nwhich has proven crucial in preventing various HPV -related cancers, including cervical \ncancer that claims thousands of lives each year (27‚Äì31). Widespread misinformation \nabout adverse effects and conspiracies regarding its necessity led to a significant portion \nof unvaccinated adolescents , heightening the likelihood of HPV infection and future \nmalignancies (32). This trend not only increased the burden on public health systems but \nalso underscored the power of misinformation to undermine trust in legitimate medical \ncounsel. \n \nIn recent years, social media has become a central and highly accessible source of \ninformation for millions of users worldwide (33). However, its ability to rapidly \ndisseminate content‚Äîincluding unfounded claims‚Äîcreates fertile ground for large-scale \npropagation of misinformation. Given the sheer volume of posts manual monitoring and \nanalysis of such content are impractical (34,35). Consequently, developing and employing \nautomated, data -driven methods to understand and manage the dynamics of digital \nmisinformation is essential for preserving accurate information and safeguarding public \ntrust. \n \nIn this study, we introduce the Misinformation Detection and Inoculation Process (MDIP) \nfor analyzing health misinformation, along with a complementary Misinformation \nDetection and Inoculation System (MDIS) that generates refutation arguments \n(inoculation) to help prevent its spread on social media and enhance public health \nawareness (36). To achieve this, we leverage a Large Language Model  (LLM) to detect \nmisinformation effectively. Furthermore, we demonstrate that enriching datasets  \nimproves the detection of misinformation generated by both humans and AI. Recent \nadvances in LLM s, such as ChatGPT, have enabled the generation of increasingly \nsophisticated misinformation, which poses challenges for traditional machine learning \n(ML) methods in distinguishing AI-generated misinformation (37,38). While prior research \nhas highlighted the effectiveness of Deep Learning (DL) methods  in classifying health -\nrelated misinformation, these efforts have predominantly focused on content generated \nby humans  (39,40). Moreover, our proposed process generates sentence -level \ndescriptions of misinformation topics, eliminating the need for manual interpretation. \nHowever, prior approaches relied on ML-based methods that produced word-level topic \nrepresentations, which required manual interpretation to form coherent sentence -level \ntopics‚Äîintroducing potential human errors and subjective biases  (1,23).  Similar \nchallenges arise in other applications, such as optimizing models in industries where \nmanual calibration of parameters can lead to inefficiencies and errors. Recent research \nhas demonstrated that data -driven models can enhance predictive accuracy and \nautomate decision-making (41‚Äì43), reducing human intervention in systems that rely on \ncomplex data streams (44‚Äì49). Inspired by these advances, our process generates \nsentence-level descriptions of misinformation topics, eliminating the need for manual \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \ninterpretation. Additionally, we introduce an algorithm to assign documents to the most \nrelevant topics. This addresses the limitation of many ML -based topic modeling \nalgorithms, which often leave some documents unclassified. Our process also identifies \noverarching themes of misinformation topics automatically, providing a high -level \nunderstanding of the underlying reasons for misinformation categorization. \nMethods \nIn this study, we propose the Misinformation Detection and Inoculation Process (MDIP), \na comprehensive framework designed to analyze the dynamics of misinformation \nautomatically and develop a Misinformation Detection and Inoculation System (MDIS). \nThe MDIP framework is structured into four interconnected sections, each addressing a \ncritical aspect of misinformation management: \n \n‚Ä¢ Detect Misinformation: This section uses large language models (LLMs) to \nclassify text documents as misinformation or non-misinformation, providing the \nfoundation for identifying and analyzing false narratives. \n \n‚Ä¢ Misinformation Topics: Here, topic modeling algorithms are applied to uncover \nthe key topics within misinformation datasets. This step helps to categorize \nmisinformation into specific subject areas, enabling a better understanding of its \nthematic structure. \n \n‚Ä¢ Topic Descriptions: This section enhances interpretability by generating \nsentence-level representations for each topic, moving beyond traditional word-\nlevel outputs. These descriptive summaries provide meaningful context for \nunderstanding the essence of each topic. \n \n‚Ä¢ Provide Refutation: In the final step, the system generates clear and \ncontextually relevant refutation arguments for the identified misinformation \nthemes. These arguments are designed to counter false narratives, improve \npublic understanding, and mitigate the spread of misinformation. \n \nBy integrating these components, MDIP enables the development of MDIS, an \nintelligent and automated system capable of detecting misinformation, identifying its \nthemes, and delivering refutations to combat its impact on public health. \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nFigure\t1.\tOverview\tof\tthe\tMisinformation\tDetection\tand\tInoculation\tProcess\t(MDIP),\tconsisting\tof\tfour\tcomponents:\t\n1.\tDetect\tMisinformation,\t2.\tMisinformation\tTopics,\t3.\tTopic\tDescriptions,\tand\t4.\tProvide\tRefutation.\t\n \n \n \nFigure\t2.\tMisinformation\tDetection\tand\tInoculation\tSystem\t(MDIS).\t\n \nDetect Misinformation \n \nMisinformation detection in text documents has become a critical area of research due \nto the growing prevalence of misleading or false information online. To address this \nchallenge, we employ classifiers based on LLMs. These LLMs are trained to categorize text \ninto two classes: misinformation and non -misinformation as shown in the first part of \nFigure 1. \nOur classifier was trained using two complementary datasets, each providing diverse \nlinguistic characteristics to enhance performance in detecting misinformation. The first \ndataset, the AAAI 2021 Competition Dataset  (50), consists of misinformation sourced \nfrom social media platforms such as Facebook and X (formerly known as Twitter). This \ndataset reflects the informal, conversational style of social media, characterized by casual \ntone, non-standard grammar, and the use of slang. The second dataset, COVID_19FNIR  \n(51), includes misinformation presented in formal, structured language, offering a stark \ncontrast to the informal nature of the first dataset. By incorporating these two datasets, \nwe trained three different  LLMs to detect misinformation effectively across a wide \nspectrum of communication styles. The blend of informal and formal language enabled \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nthe model to  better generalize , achieving improved accuracy and robustness in \nidentifying misinformation, whether generated by humans or artificial intelligence (AI). \n \nTraditionally, researchers collect human -written data from social media platforms like \nTwitter and Facebook, label it as misinformation or non-misinformation, and then train a \nDeep Neural Network (DNN) to classify such documents (39,40,52,53). However, recent \nstudies have demonstrated that DNNs trained exclusively on human -written datasets \nexhibit weaker accuracy in detecting AI -generated misinformation compared to human -\nwritten misinformation. This discrepancy arises because AI -generated misinf ormation \noften adopts formal language styles similar to accurate information shared by credible \nsources like the Word Health Organization ( WHO) and Centers for Disease Control and \nPrevention (CDC) on official social media accounts (37,38). \n \nIn this research, by combining a dataset with formal language and another with informal \nlanguage, we demonstrate that LLMs achieve superior accuracy in detecting AI-generated \nmisinformation. This approach ensures better generalization and robustness, bridging the \ngap in identifying misinformation across diverse linguistic styles. \n Misinformation Topics \nAs outlined in the second section of Figure 1, our approach involves three key steps. First, \nwe collect misinformation data. Next, we select and compare topic modeling algorithms \nbased on specific features and metrics to identify the most effective model. Finally, we \ndesign an algorithm that assigns topics to new or unclassified documents. \nTo identify misinformation topics, we used one of the largest datasets of verified COVID-\n19 claims, the IFCN dataset, which has been extensively used in related research (54‚Äì56). \nWe applied three topic modeling algorithms ‚ÄîLatent Dirichlet Allocation (LDA)  (57), \nTop2Vec (58,59), and BERTopic (59,60)‚Äîto analyze this dataset. \nTo evaluate and compare the performance of these algorithms, we selected three \nmetrics: Coherence Value (CV)  (61), Normalized Pointwise Mutual Information (NPMI)  \n(62), and Inverse Rank-Biased Overlap (IRBO) (63). CV and NPMI measure the coherence \nof the topics, ensuring they are logically consistent and meaningful. IRBO, on the other \nhand, evaluates the diversity of the topics generated by the model, which is crucial for \nensuring broad coverage of the dataset's c ontent. Since our focus is on misinformation \nwithin health -related social media data, coherence and diversity are particularly \nimportant to ensure topics are both interpretable and representative. \nAfter selecting the best -performing topic model, we developed an algorithm to address \nthe issue of unclassified documents. This algorithm assigns topics to new or previously \nunassigned documents, ensuring comprehensive topic coverage and improved usability  \nof the model for real-world applications. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \n \nTopic Description \nTopic modeling algorithms typically produce word -level representations for each topic. \nWhile these representations provide insight into the most relevant words associated with \na topic, they often lack the semantic depth necessary to precisely identify the specific \ntopic within a document. This limitation arises because word-level outputs fail to capture \nthe context and relationships between words that define the overarching theme of a topic \n(52). \n \nRecent advancements in large language models (LLMs) have demonstrated their ability to \ngenerate high -quality, contextually relevant outputs with minimal or zero additional \ntraining by designing carefully crafted inputs ‚Äîreferred to as prompt engineering  (64). \nLeveraging this capability, we address the limitations of word -level representations by \nemploying prompt engineering techniques to generate sentence -level representations \nfor each topic. These sentence-level representations capture the context and essence of \nthe topic, enabling a more accurate and interpretable understanding of the document \ncontent. \n \nSubsequently, these sentence -level representations are used to identify and articulate \nthe overarching themes of the topics, also at the sentence level. This approach provides \na more comprehensive view of the thematic structure within the document corpus. \n \nFinally, recognizing that all documents within the dataset share a common underlying \nreason for being classified as misinformation, we develop a tailored response list for each \ntopic theme. The third section of Figure 1 illustrates these three steps. \nProvide Refutation \nIn the final step of our proposed method, as illustrated in the final part of  Figure 1, we \nidentify the overarching theme of misinformation and provide a corresponding response \nfrom a pre-constructed response list. This response list is developed in the preceding step \nbased on the identified themes. \n \nTo determine the themes of misinformation, we use prompt engineering techniques. By \ndesigning carefully crafted and contextually appropriate prompt text, we effectively \nextract the underlying themes associated with misinformation. This approach allows us \nto translate complex word -level or sentence -level r epresentations into meaningful \nthematic insights. \n \nBy identifying misinformation themes and providing precise, theme-based responses, our \nmethod aims to enhance public health knowledge and reduce the spread of \nmisinformation. This proactive approach not only mitigates the risks associated with false \nor misleading information but also fosters a more informed and resilient society. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nProposed System \nFollowing the completion of four foundational steps ‚Äî1) Detecting misinformation, 2) \nIdentifying misinformation topics, 3) Describing topics, and 4) Providing Refutations‚Äîwe \ndevelop our comprehensive Misinformation Detection and Inoculation System  (MDIS), \nwhich consists of three key components. \n \n1. Detection of Misinformation: The system begins by determining whether a given \ndocument is misinformation. \n2. Identification of Misinformation Themes : If the document is classified as \nmisinformation, the system analyzes its content to identify the underlying \nmisinformation themes. This process involves extracting thematic representations \nthat provide a clearer understanding of the document's misleading aspects. \n3. Providing Refutations: Finally, the system generates a detailed refutation \nargument for the identified misinformation themes. These arguments are derived \nfrom a pre -designed response list tailored to address specific misinformation \nthemes effectively. \n \nAll three components of the system are demonstrated with a practical example, as \nillustrated in  Figure 2. This example highlights how the system operates cohesively to \ndetect misinformation, uncover its thematic structure, and deliver accurate refutations, \nultimately contributing to a more informed and resilient public.  While this approach \nprovides a structured framework, it has not been implemented as a real -time system or \nintegrated into public health platforms. \nResults \nText Classification \n \nDue to the exceptional performance of Large Language Models (LLMs) across a wide \nrange of artificial intelligence tasks, we leveraged three prominent LLMs to fine -tune \nthem for COVID -19 text classification. These models ‚ÄîBERT, GPT -2, and T5 -base‚Äîare \nrenowned for their ability to understand and process natural language with high accuracy \nand contextual awareness.  \n \nBERT (Bidirectional Encoder Representations from Transformers) is particularly effective \nin handling text classification tasks due to its bidirectional context understanding, which \nallows it to capture nuanced language patterns (65). GPT -2 (Generative Pre -trained \nTransformer 2) excels in text generation and classification by leveraging its autoregressive \narchitecture to predict sequences in a given context  (66). Lastly, T5 -base (Text-to-Text \nTransfer Transformer) operates under a unified framework that reformulates all NLP tasks \nas a text-to-text problem, making it versatile and effective across various domains (67).  \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nTo conduct this study, we combined the AAAI 2021 competition dataset with the COVID-\n19FNIR dataset. The data was split into training, testing, and validation sets with \nproportions of 67%, 17%, and 16%, respectively. \n \nTable 1 shows the evaluation metrics, including Accuracy, F1-Score, Recall, and Precision, \nfor all three models on the test dataset. Among these, BERT achieved the highest \nperformance, with an impressive accuracy of 98% on the test data. This superior result \nhighlights BERT's ability to handle complex linguistic structures and its effectiveness in \nfine-tuning for domain-specific tasks like COVID-19 text classification. \n \nTable\t1-\tPerformance\tmetrics\t(Accuracy,\tF1-Score,\tRecall,\tand\tPrecision)\ton\tthe\ttest\tdataset\tfor\tthree\tmodels:\t\nBERT-base,\tGPT-2,\tand\tT5-base\t\nModel Accuracy F1-score Recall Precisian \nBert 0.9848 0.9854 0.9896 0.9812 \nGPT2 0.9460 0.9495 0.9841 0.9117 \nT5-base (Generic \nCondition) 0.9763 0.9763 0.9763 0.9764 \n \nThe confusion matrices in  Figure 3 for BERT, GPT -2, and T5 -base further illustrate the \nperformance of these models, providing a detailed breakdown of true positives, true \nnegatives, false positives, and false negatives, which helps in understanding their \nclassification strengths and potential areas for improvement. \nFigure\t3.\tConfusion\tmatrices\tillustrate\tthe\tperformance\tof\tthe\tthree\tbinary\tclassification\tmodels\t(BERT,\tGPT-2,\tand\t\nT5-base).\t\n\t\nTo evaluate the accuracy of our model on AI -generated data, we utilized the dataset \nprovided in the study in (37). We tested our fine-tuned BERT model on this dataset, and \nthe results are presented in Table 2. The findings indicate a significant reduction in the \nnumber of false positives (FP), decreasing from 27 to 15, representing a 44% \nimprovement. Additionally, Figure 4 shows the confusion matrix for our fine-tuned BERT \nmodel when applied to the AI-generated misinformation dataset. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nTable\t2-\tThe\ttable\tpresents\tthe\tFalse\tPositive\t(FP)\t\tand\tTrue\tNegative\t(TN)\tresults\tobtained\tfrom\ttesting\tthe\tfine-\ntuned\tBERT\tmodel\ton\tour\tcombined\tdataset,\tcompared\twith\tthe\tresults\treported\tin\tthe\t(37)\t\tpaper.\t\nModel FP TN \nOur 15 485 \n(37) 27 473 \n \nFigure\t4.\tThe\tfigure\tdisplays\tthe\tconfusion\tmatrix\tof\tour\tfine-tuned\tBERT\tmodel\tevaluated\ton\tthe\tAI-generated\t\ndataset\t(37).\t\n \n \nTopic Models \nWe used the IFCN dataset, one of the largest datasets on COVID-19, to apply and evaluate \ntopic modeling approaches. Three models were tested: LDA, Top2Vec, and BERTopic. \nAfter applying each topic model, the top 10 words associated with each topic were \nselected, and the three metrics ‚ÄîCV, NPMI, and IRBO ‚Äîwere computed to compare the \nmodels. ( Table 3) summarizes the results across these metrics. Among the models, \nBERTopic achieved the highest scores across all metrics, leading to its selection for further \nanalysis. \nTable\t3-\tThe\ttable\tpresents\tthe\tperformance\tof\tthree\ttopic\tmodeling\tapproaches‚ÄîLDA,\tTop2Vec,\tand\tBERTopic‚Äî\nevaluated\tacross\tthree\tmetrics:\tCV\t(Coherence\tValue),\tNPMI\t(Normalized\tPointwise\tMutual\tInformation),\tand\tIRBO\t\n(Inverse\tRanked\tBased\tOverlap).\tFor\tall\tmetrics,\thigher\tvalues\tindicate\tbetter\tperformance.\t\nModel CV ¬≠ NPMI ¬≠ IRBO ¬≠ \nLDA 0.39 -0.35 0.96 \nTop2Vec 0.35 -0.29 0.89 \nBERTopic 0.41 -0.086 0.99 \nMany topic modeling approaches, including BERTopic, often encounter limitations when \napplied to real-world datasets, as they are unable to assign topics to all documents. This \ncan leave a subset of documents unclassified, reducing the overall effectiveness of the \nmodel. To address this issue, we have deve loped Algorithm 1 , a method for ensuring \ncomprehensive topic assignment across the dataset. \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nThis algorithm refines topic modeling by addressing unclassified documents after applying \nthe BERTopic model. First, BERTopic is applied to a dataset of text documents, grouping \nthose with similar semantic characteristics into distinct topics (Step 1). How ever, some \ndocuments may remain unclassified if they do not strongly align with any detected topic. \nTo address this, all documents are converted into vector representations using a sentence \ntransformer model, such as BERT embeddings, which capture their se mantic meaning in \na structured format (Step 2). To enhance processing efficiency, Uniform Manifold \nApproximation and Projection (UMAP) is then applied, reducing the dimensionality of \ndocument vectors while preserving essential semantic relationships (Step 3). Next, the \nalgorithm computes the center of each topic cluster by averaging the vector \nrepresentations of all documents assigned to that topic, with these centers serving as \nreference points that define the core meaning of each group (Step 4). For documents that \nremain unclassified, the algorithm determines the most appropriate topic assignment by \ncomputing cosine similarity between each unclassified document‚Äôs vector and the \nprecomputed topic centers (Step 5). Finally, each unclassified document is assigned to the \ntopic cluster whose center exhibits the highest similarity score, ensuring alignment with \nthe most relevant category (Step 6). \nThis approach not only ensures that every document in the dataset is assigned a topic , \nbut also enhances the interpretability and usability of the topic modeling results. By \nleveraging the semantic structure of the dataset, our algorithm effectively bridges the gap \nbetween unassigned documents and existing topic clusters, making it a robust  solution \nfor comprehensive topic coverage. \n________________________________________________________________________ \nAlgorithm 1: Assign a document to the closest topic \n1. Input: \no Raw text documents ùëã = {ùëë!, ùëë\", ‚Ä¶ , ùëë#},  \no BERTopic model parameters ùëÉ. \n2. Topic Modeling: \no Compute topics using the BERTopic model:   \nTopics,  {ùëå$}$%!\n&  = BERTopic(ùëã, ùëÉ) \nWhere ùëá is the number of topics and ùëå$ contains documents which are \nassigned to the topic ùëó. \n3. Sentence Embeddings: \no Transform documents ùëã into vector representations using a sentence \ntransformer such as BERT embedding. \n4. Dimensionality Reduction: \no Apply UMAP (Uniform Manifold Approximation and Projection) for \ndimensionality reduction on the vector representations. \n5. Cluster Centers: \no For each topic ùëó, compute the center of the cluster:  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nùë°$ = \t\t ‚àë '!\n#\"(\t‚àà$            (1) \nWhere ùëõ$ is the number of documents in topic ùëó, and ùë•( is the reduced \nvector representation of document ùëë(. \n6. Topic Assignment for Unassigned Documents: \no For every document ùëë( that is not assigned to a topic by the BERTopic \nmodel, or for any new document:  \n¬ß Assign the document to the topic ùëó that maximizes the cosine \nsimilarity between the document vector ùë•( and the cluster center \nùë°$:      \nùê¥ùëüùëîùëöùëéùë•$ \t\n'!\t.,\"\n\t‚Äñ'!‚Äñ\t.,\".         (2) \n________________________________________________________________________ \nTopic Description \nAs described in the Method section, topic modeling algorithms typically produce word -\nlevel representations of topics. While useful for identifying key terms associated with a \ntopic, these representations often lack sufficient contextual information, making  \ninterpretation challenging. To overcome this limitation, we developed a structured \nprompt framework (outlined in Text box 1) and used the advanced capabilities of large \nlanguage models (LLMs), specifically ChatGPT -4.0, to generate sentence-level \nrepresentations for the identified topics. These sentence -level representations provide \nricher context and more interpretable descriptions, enabling a deeper understanding of \nthe topics.  \nThe prompt includes the top 10 most representative words for each topic as identified by \nthe topic modeling algorithm and to add context and depth to the topic descriptions, we \nselect five documents that are closest to the center of the corresponding topic cluster. \nThe selection of these documents is guided by cosine similarity , performed using \nEquations 1 and 2, which measure the proximity of documents to the cluster center in the \nsemantic space. An example of this process is provided in Text Box 1, illustrating how the \ntop words and represe ntative documents are integrated into the prompt to produce a \nhigh-quality sentence-level representation.  \nBy combining these elements, we construct detailed and context-rich prompts that guide \nChatGPT-4.0 in generating coherent and semantically accurate sentence -level topic \nrepresentations. This approach ensures that the abstract themes identified by topic \nmodeling are translated into human-readable and interpretable descriptions. \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nText\tbox\t1-\tThe\tprompt\tstructure\tand\tone\texample\tto\tfind\ttopics\tdescription\tmentioned\tin\tthe\ttext\tbox.\t\nTopic Description Prompt Structure: \n     System Role:  \nTopic main words: [Top 10 words] \n                Topic document examples: [5 closest examples to the center of the topic] \n     User Role:  \n‚ÄúDescribe topic in a short phrase?‚Äù \n \nTopic Description Prompt Example: \n     System Role:  \nTopic main words: ['masks', 'mask', 'face', 'wearing', 'wear', 'use', 'oxygen', 'hypoxia',     \n'cause', 'you']. \n                Topic document examples: \n1. CDC does not recommend wearing masks. \n2. The US Centers for Disease Control and Prevention (CDC) contradicted itself by advising \npeople to wear cloth masks against the novel coronavirus while also saying masks do \nnot stop smoke inhalation during a wildfire. \n3. The WHO changed its mind about masks and now says that they can increase the risk \nof infection. \n4. Non-medical masks are ineffective in preventing the spread of the disease are \ncirculating online. \n5. Whether CDC had scheduled announcement that all should wear masks for  everyday \nlife. \n     User Role: ‚ÄúDescribe topic in a short phrase?‚Äù \n     Output Answer: ‚ÄúControversies and Debates over Mask Wearing and its Effectiveness‚Äù \n\t\nTo evaluate the quality of the generated topic descriptions, we engaged three \nindependent raters to assess the descriptions based on three categories: appropriate, \nsomewhat appropriate, and not appropriate. The evaluation results are presented in  \nTable 4 and highlights that the majority of topic descriptions were well -received. \nSpecifically, the total proportion of accepted descriptions (the sum of those rated as \nappropriate and somewhat appropriate) was 99.6%. This acceptance rate demonstrates \nthe effectiveness and reliability of the proposed method for generating meaningful and \ncontextually relevant topic descriptions. \n \nTable\t4-\tThe\ttable\tpresents\tthe\tpercentage\tof\ttopic\tdescriptions\trated\tas\t\"Appropriate,\"\t\"Somewhat\tAppropriate,\"\t\nand\t\"Not\tAppropriate\"\tby\teach\trater,\talong\twith\tthe\ttotal\tnumber\tof\taccepted\ttopic\tdescriptions,\tcalculated\tas\tthe\t\nsum\tof\tthose\trated\t\"Appropriate\"\tand\t\"Somewhat\tAppropriate‚Äù.\t\nRaters Appropriate Somewhat \nappropriate Not appropriate Total accepted \nRater 1 98.23% 1.77% 0% 100% \nRater 2 94.67% 5.33% 0% 100% \nRater 3 89.94% 8.88% 1.18% 98.82% \nAverage 94.28% 5.32% 0.39% 99.6% \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \n \nAfter generating concise descriptions for each topic, we used the structured prompt \nframework outlined in Text box 2, which includes a list of these topic descriptions. This \nstructured prompt was then input into the ChatGPT -4.0 API to further refine and \ncategorize the topics into overarching themes.  \n \nThe output from this process not only provides a clear categorization of topics into distinct \nthemes but also includes a concise description for each theme. This step ensures that the \ntopics are grouped in a meaningful and interpretable way, facilitating a deeper \nunderstanding of the data's thematic structure. \n \nThe categorized topics and their corresponding theme descriptions are provided in Figure \n5 and Figure 6, showcasing the effectiveness of the proposed method in generating \ncoherent and insightful thematic groupings. \n \nText\tbox\t2-\tStructure\tof\tthe\tprompt\tfor\tidentifying\ttopic\tthemes.\t\nFinding Topic Themes Prompt Structure: \n      System Role: \nThe following are topics related to COVID-19. Go through all topics and categorize them into \nrelevant groups. Mention topics number for each category. \n      User Role:  \n              Topics description list \n \n \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nFigure\t5.\tDescriptions\tof\tThemes\t1\tto\t7\talong\twith\tthe\tcorresponding\ttopic\tdescriptions\tassigned\tto\teach\ttheme.\t\n \n \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nFigure\t6.\tDescriptions\tof\tThemes\t8\tto\t13\talong\twith\tthe\tcorresponding\ttopic\tdescriptions\tassigned\tto\teach\ttheme.\t\n \n \nUsing Algorithm 1, we assign each document to a topic, enabling us to determine the \ndistribution of each theme. Figure 7 shows the distribution of all themes, while Figure 8 \nshows the distribution of each topic within Theme 8 over time. \n \nFigure\t7.\tDistribution\tof\tCOVID-19\tmisinformation\tthemes.\t\n \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \n \nFigure\t8.\tDistribution\tof\tTHEME\t8\ttopics\tduring\tthe\ttime.\t\n \nAfter identifying the misinformation themes, we leverage the explanations provided in \nthe IFCN dataset as a basis to draw refutation arguments to address these themes. For \neach identified theme, we develop an refutation that aligns with its context, aiming to \nclarify the nature of the misinformation, its potential origins, and its impact. These \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nrefutations are presented in Text box 3- The refutation arguments list for 13 themes. , \nproviding valuable insights into the underlying reasons for the misinformation. \nText\tbox\t3-\tThe\trefutation\targuments\tlist\tfor\t13\tthemes.\t\nRefutation List: \n1. Home remedies for COVID -19 prevention and treatment are often based on misinformation. \nWhile they may promote general health, no scientific evidence supports their effectiveness in \npreventing or curing COVID-19. \n2. Misinformation about COVID -19 deaths, statistics, and their relation to vaccination often \ninvolves data misrepresentation, misinterpretation of health reports, or fabricated claims. Such \nfalsehoods can cause confusion, erode trust in public health institutions, and foster skepticism \nabout the impact of COVID-19 and the effectiveness of vaccination.  \n3. Conspiracy theories and misinformation related to COVID -19 often rely on unverified claims, \ndistorted facts, or manipulated content. These falsehoods exploit fear, uncertainty, and distrust \nto spread misleading narratives about the pandemic's origins, vacc ines, and public health \nmeasures. Common conspiracy themes include claims of the pandemic being planned, \nunfounded accusations against prominent figures like Bill Gates, misinformation linking 5G \ntechnology to COVID-19, and fabricated stories about vaccines and immunity.   \n4. Misinformation about COVID-19 vaccines, including false claims about safety, efficacy, and side \neffects, has fueled skepticism and vaccine hesitancy worldwide. These falsehoods undermine \npublic trust in vaccines. \n5. Misinformation about COVID-19 testing often targets the accuracy of PCR tests and promotes \nunscientific self-check methods like holding one‚Äôs breath. PCR tests are highly accurate but may \ndetect non-infectious viral fragments, which can be misunderstood. I n reality, PCR tests are \nhighly sensitive and accurate for detecting COVID-19 when used appropriately, though they may \ndetect non-infectious viral fragments in some cases. \n6. Misinformation about treatments for COVID -19, including the use of Ivermectin, \nhydroxychloroquine, and unproven supplements like Quermax, often exaggerate the \neffectiveness of these treatments or misrepresent scientific studies to support their use over \nproven measures like vaccines. While some drugs, such as Ivermectin and hydroxychloroquine, \nwere initially studied for potential COVID -19 treatment, clinical trials have not provided \nsufficient evidence to confirm their safety or efficacy for this purpose. S imilarly, supplements \nand alternative remedies lack the rigorous scientific validation required to prove their \neffectiveness against COVID-19. \n7. Misinformation about government and political responses to COVID-19 involves distorted facts, \nfabricated claims, or misrepresentation of policies and actions. These falsehoods range from \nexaggerated accomplishments to unfounded accusations, including misre porting financial \nexpenditures, misattributing statements to political leaders, or fabricating praise from \ninternational organizations. Governments worldwide have implemented a wide range of \nmeasures to combat COVID -19, including quarantine protocols, vacc ination drives, economic \nrelief packages, and public health campaigns. However, the interpretation and communication \nof these measures can vary, leading to the spread of misleading narratives. To counter this, it is \ncrucial to verify information from credible sources, such as official government announcements, \nreputable media outlets. \n8. Misinformation about lockdowns and COVID -19 restrictions often includes fabricated or \nmisrepresented events, videos, or claims. False narratives range from altered timelines of \nevents to conspiracies about government actions, protests, and public compliance. Lockdowns \nand restrictions were implemented globally to curb the spread of COVID-19, with varying levels \nof enforcement and public response. To combat misinformation, it is critical to verify claims \nthrough official government announcements, trusted med ia sources, and independent fact -\nchecking organizations. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \n9. Misunderstandings about how COVID-19 spreads and survives in various environments have led \nto numerous false claims and fears. These include unverified assertions about the virus being \nlinked to specific foods like chickens or cabbages, its survival on sur faces like shoes or roads, \nand exaggerated theories about airborne transmission and environmental factors like \ntemperature. Scientific evidence indicates that while COVID -19 can survive on surfaces for \nvarying durations, its primary transmission occurs thr ough respiratory droplets and, in some \ncases, aerosols. Claims about the virus thriving on specific foods or being destroyed at particular \ntemperatures lack scientific support. \n10. Misleading or false claims about defensive and protective measures against COVID -19 have \ncontributed to confusion and unsafe practices. These include exaggerated claims about the use \nof chlorine dioxide, UV rays, and alcohol -based products, as well as deba tes over the \neffectiveness of masks and sanitizers. While certain measures, such as wearing masks and using \nhand sanitizers, are scientifically proven to reduce the spread of the virus, other claims, like \nsunlight killing COVID-19 or chlorine dioxide being safe for disinfection, lack credible evidence \nor are outright false. Relying on guidance from reputable health organizations like the World \nHealth Organization (WHO) and the Centers for Disease Control and Prevention (CDC) is \nessential for understanding which protective measures are effective and safe. \n11. International Misinformation about international incidents and responses to COVID-19 involves \nexaggerated or fabricated claims about government actions, healthcare capacity, or emotional \nreactions of leaders. Examples include false reports of rapid hospital construction, misattributed \nemotional responses by world leaders, or unverified claims about  the treatment of COVID-19 \nvictims. Such false narratives misrepresent the global efforts to combat the pandemic and can \nerode trust in public health measures and international cooperation. Misleading claims, such as \ncountries discarding victims‚Äô bodies at sea or building thousands of hospital beds in days, often \nstem from misinterpreted images or old videos unrelated to COVID -19. To combat \nmisinformation, it is essential to rely on verified data from credible sources like independent \nfact-checking organizations. \n12. Misinformation about COVID-19 spreads rapidly through social media platforms and messaging \napps like WhatsApp and Facebook. False claims often exploit fear and uncertainty, such as \nfabricated government policies, misleading features of apps, or unfounded accusations abo ut \nmedia manipulation. To counter this, it is crucial to verify claims through reliable fact-checking \norganizations and official communications. \n13. These claims lack credible scientific evidence or are distortions of real information, such as the \nexaggerated impact of products, religious practices, or fabricated connections to bioweapons \nand patented viruses. While some of these topics may seem minor or humorous, they can still \nmisinform the public and detract from accurate understandings of the pandemic. Critical \nthinking, fact -checking, and reliance on credible scientific and official sources are vital to \ncombatting these misinformation. \n \nProvide Refutation \nIn the final stage of our process, we design a prompt text to enable ChatGPT-4.0 to detect \nspecific misinformation themes. The prompt text includes a detailed description of the \nthemes and a question -answer list. To create this question -answer list, we sel ect the \ndocument closest to the center of each topic and associate it with the corresponding \ntheme. Detailed information about the prompt text can be found in Text box 4. \nText\tbox\t4-\tPrompt\tstructure\tand\tone\texample\tto\tfind\ta\tdocument\ttheme.\t\nFinding Document Themes Prompt Structure: \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \n      System Role:  \n‚ÄúThe following is the description of topic themes related to COVID-19 misinformation. Find \nthe closest theme for the given text. Answer in a consistent style.‚Äù \n       User Role:  \nThemes description list \n     Assistant Role:  \nQuestion-Answer List   \n     User Role: \nInput text \n \nFinding Topic Themes Prompt Example: \n      System Role:  \n‚ÄúThe following is the description of topic themes related to COVID-19 misinformation. Find \nthe closest theme for the given text. Answer in a consistent style.‚Äù \n       User Role:  \nThemes description list \n     Assistant Role:  \nQuestion-Answer List   \n     User Role: \n                 \"A video shows that Bill Gates admits the vaccine will no doubt kill 700,000 people\" \n     Output Answer: \nTHEME 3: \"Conspiracy Theories and Misinformation\" \n \n \nTo evaluate our approach, we randomly select 50 documents from the IFCN dataset that \nare not included in the question-answer list. We then tested the prompting method with \nChatGPT-4.0, achieving an 80% accuracy rate in detecting the correct themes as shown in \nTable 5. \nTable\t5-\tAccuracy\tof\tthe\tmodel\tfor\tdetection\tdocument‚Äôs\ttheme.\t\nModel Accuracy \nTheme Detector 80% \n \n \nProposed System \n \nBased on the process we introduced, we propose the development of a Misinformation \nDetection and Inoculation System (MDIS). This system is designed to first determine \nwhether a given text document contains misinformation or not. If the document is \nidentified as containing misinformation, the system then detects its theme and provides \na detailed refutation of the misinformation. The primary objectives of MDIS are to prevent \nthe spread of misinformation and to enhance public health knowledge. \n \nMDIS operates by integrating three key components. First, it utilizes a trained large \nlanguage model (LLM) to classify text documents as either misinformation or non -\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nmisinformation. Next, it employs another trained LLM to detect the specific \nmisinformation theme within documents identified as containing misinformation. Finally, \nit leverages a refutation list, which is generated during the theme description phase, to \nprovide context and counter -narratives for each detected theme. This comprehensive \napproach enables the system to effectively address misinformation while equipping users \nwith accurate information. \n \nFigure 9 illustrates an example of an input to MDIS and its corresponding output, \ndemonstrating how the system analyzes a document, identifies misinformation, detects \nthe associated theme, and presents an explanatory response. \n \nFigure\t9.\tOne\tinput\ttext\texample\tand\tthe\toutput\tof\tMisinformation\tDetection\tand\tInoculation\tSystem\t(MDIS).\t\n \nDiscussion \nPrinciple Results \nIn this study, we developed a Misinformation Detection and Inoculation Process (MDIP), \nwhich is designed to analyze the dynamics of misinformation and facilitate the creation \nof a Misinformation Detection and Inoculation System (MDIS). MDIS provides detail ed \nrefutations for misinformation circulating on social media, helping to combat its spread \nand improve public understanding. MDIP consists of four main steps (subroutines), each \ncontributing to the system's overall effectiveness. \n \nThe first step focuses on Detecting Misinformation. In this phase, we trained three large \nlanguage models (LLMs) to classify text documents as misinformation or non -\nmisinformation. Among these, the BERT model achieved the highest accuracy of 98%. \nAdditionally, we demonstrated that enriching the training dataset with both formal and \ninformal language significantly improved the system's ability to identify AI -generated \nmisinformation, reducing false positives (FP) by 44% compared to previous models. This \nenrichment ensures the model performs well across various linguistic styles and sources. \n \nThe second step involves Identifying Misinformation Topics. For this, we used the IFCN \ndataset, one of the most comprehensive collections of COVID-19-related misinformation. \nWe applied three topic modeling techniques ‚ÄîLDA, Top2Vec, and BERTopic ‚Äîto analyze \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nthe dataset. Among these, BERTopic outperformed the others, achieving the highest \nscores in CV at 0.41, NPMI at -0.086, and IRBO at 0.99. Once the optimal topic model was \nidentified, we developed Algorithm 1 to assign documents to their closest topics. Sin ce \nmost topic models often leave outliers unassigned, Algorithm 1 ensures that every \ndocument is categorized under a topic, enabling more comprehensive topic distribution \nanalysis. \n \nIn the third step, we focused on deriving Sentence -Level Representations for Topics. \nWhile most topic modeling approaches provide word-level representations, we extended \nthis by developing sentence -level representations for each topic. These representations \nwere then used to identify broader themes within the misinformation topics. Based on \nthese themes, we created detailed refutations to address the key elements and nuances \nof the misinformation being analyzed. \n \nThe fourth step involved designing a prompt text for theme detection using ChatGPT-4.0. \nThis prompt was crafted to detect the theme of a misinformation document accurately. \nBy integrating the themes and refutations, our prompt -based theme detector achieved \nan accuracy of 80%, demonstrating its effectiveness in identifying misinformation themes. \n \nFinally, by combining the misinformation detector, theme detector, and refutation \ngenerator, we developed the Misinformation Detection and Inoculation System (MDIS). \nThis system can accurately identify misinformation, determine its underlying theme, and \nprovide a suitable refutation to counteract its spread. MDIS represents a comprehensive \ntool for combating misinformation and enhancing public awareness in the digital age. \nLimitations \nWhile this study presents a robust framework for detecting and addressing \nmisinformation, several limitations should be acknowledged. First, the system's \nperformance relies on the quality and diversity of the training datasets, which may not \nfully capture the linguistic and contextual nuances of misinformation in different regions, \nlanguages, or cultural contexts. The model has been tested solely on COVID -19-related \nmisinformation, and its effectiveness for other domains remains unverified. Additionally, \nit has not been evaluated for multilingual adaptation, meaning its ability to detect \nmisinformation across different languages and sociocultural contexts remains uncertain. \nMoreover, while the theme detection module achieved 80% accuracy, its accuracy could \nbe further improved, particularly in handling ambiguous or overlapping themes. False \npositives and negatives remain a concern, particularly when misinformation contains \nopinion-based, satirical, or context -dependent elements. Additionally, the refutations \ngenerated by the system, though informative, might require additional refinement to \nensure they are universally comprehensible and contextually appropriate for diverse \naudiences. While these refutations aim to enhance transparency, their AI -generated \nnature may not always align with human reasoning or ethical considerations.  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nAdditionally, the system has not yet been extensively tested in real -world applications, \nwhich limits understanding of its practical impact on misinformation spread and public \nhealth outcomes. Furthermore, misinformation evolves over time, and a model trained \non past narratives may require periodic retraining to remain effective against emerging \nfalsehoods, including AI -generated misinformation. Finally, the reliance on automated \nmethods raises potential concerns about interpretability and transparency, whi ch are \ncrucial for fostering trust and adoption by end users. \nComparison with Prior Work \nThe proposed Misinformation Detection and Inoculation Process (MDIP) and the resulting \nMisinformation Detection and Inoculation System (MDIS) build upon and advance the \nbody of research focused on misinformation detection and mitigation. Previous research \nhas demonstrated the efficacy of machine learning (ML) models, particularly deep \nlearning approaches, in detecting misinformation. They employed ML techniques to \nclassify fake news using textual features, demonstrating the value of automated detection \nmethods (50,53,68). Our study extends these efforts by integrating enriched datasets \ncontaining both formal and informal language styles, ensuring better generalization \nacross diverse linguistic sources, including AI-generated misinformation. \n \nTopic modeling techniques such as LDA have been used in prior studies to analyze \nmisinformation (39,57,69). Our approach improves on these works by addressing \nlimitations in document assignment and theme interpretation. We developed an \nalgorithm to assign every document to the most relevant topic, resolving the common \nissue of unclassified documents in topic modeling. Additionally, we moved beyond word-\nlevel topic representations to generate sentence -level descriptions, offering richer and \nmore interpretable insights.  Finally, we designed an effective prompt text to \nautomatically identify the themes of misinfor mation. This automated approach reduces \nreliance on manual interpretation, minimizing human bias and increasing scalability. \n \nMany prior studies have addressed misinformation detection or topic analysis in isolation. \nThey analyzed misinformation using sentiment analysis but did not integrate detection \nwith thematic analysis and did not provide a framework for counteracting misinformation \n(39,70,71). Our work unifies detection, topic modeling, thematic refutation, and public \nhealth intervention in a single framework. The MDIS framework automates the end -to-\nend process, offering a scalable solution to tackle the complexity of misinformation \ndynamics. \n \nConclusions \nThis study introduces a novel framework for addressing health -related misinformation \nthrough the development of the Misinformation Detection and Inoculation Process \n(MDIP) and the Misinformation Detection and Inoculation System (MDIS). By leveraging \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nadvanced natural language processing techniques, MDIS provides an automated \napproach to detecting misinformation, identifying its underlying themes, and delivering \nclear and contextually relevant refutations. This approach is designed to combat the rapid \nspread of misinformation on social media and improve public health knowledge. \n \nThe integration of enriched datasets ensures the system can handle diverse linguistic \nstyles, making it adaptable to various contexts and sources of misinformation. \nAdditionally, the ability to generate sentence -level representations and thematic \nrefutations allows for a deeper understanding of misinformation dynamics and provides \nactionable insights to counter false narratives effectively. \n \nMDIS represents a scalable and comprehensive solution to the misinformation problem, \naddressing both its detection and mitigation in a unified framework. While challenges \nremain, such as adapting to regional and cultural contexts and improving thematic \ninterpretation, the system sets the stage for future advancements in misinformation \nmanagement. \n \nIn conclusion, this work provides a robust and intelligent tool for combating \nmisinformation, contributing to the broader goal of promoting health literacy and trust in \ncredible information sources. By equipping individuals and public health authorities with \nan effective system to manage misinformation, this framework offers significant potential \nto improve public health communication and outcomes in an increasingly digital world. \n \nAcknowledgements \nThis research is supported in part by a research grant from the Investigator Initiated \nStudies Program of Merck Sharp & Dohme Corp (MISP #102050). The opinions \nexpressed in this paper are those of the authors and do not necessarily represent those \nof Merck Sharp & Dohme Corp. \nEthics Statement \nThis study did not involve human subjects, human tissue, or identifiable private \ninformation.. All data analyzed in this study were obtained from publicly available, de -\nidentified sources, including the AAAI 2021 Competition Dataset, the COVID -19FNIR \ndataset, and the IFCN COVID -19 fact -checking corpus The research complied with all \nrelevant ethical standards and data use policies, and poses no risk to individuals or \ncommunities. The study‚Äôs sole objective is to advance computational methods for \nunderstanding and mitigating the spread of health misinformation. \nConflicts of Interest \nnone declared. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nAbbreviations \nJMIR: Journal of Medical Internet Research \nLLM: Large Language Models \nWHO: World Health Organization  \nCDC: Centers for Disease Control and Prevention \nML: Machine Learning  \nLDA: Latent Dirichlet Allocation \nCV: Coherence Value  \nNPMI: Normalized Pointwise Mutual Information \nRBO: Rank Biased Overlap \nIRBO: Inverted RBO \nHPV: Human Papillomavirus  \nMDIP: Misinformation Detection and Inoculation Process  \nMDIS: Misinformation Detection and Inoculation System \nDNN: Deep Neural Network  \nAI: Artificial Intelligence  \nBERT: Bidirectional Encoder Representations from Transformers \nReferences \n1. Kisa S, Kisa A. A comprehensive analysis of COVID-19 misinformation, public \nhealth impacts, and communication strategies: scoping review. J Med Internet Res. \n2024;26:e56931.  \n2. Loomba S, De Figueiredo A, Piatek SJ, De Graaf K, Larson HJ. Measuring the \nimpact of COVID-19 vaccine misinformation on vaccination intent in the UK and \nUSA. Nat Hum Behav. 2021;5(3):337‚Äì48.  \n3. Moscadelli A, Albora G, Biamonte MA, Giorgetti D, Innocenzio M, Paoli S, et al. \nFake news and Covid-19 in Italy: results of a quantitative observational study. Int J \nEnviron Res Public Health. 2020;17(16):5850.  \n4. Chou WYS, Oh A, Klein WMP. Addressing health-related misinformation on \nsocial media. JAMA. 2018;320(23):2417‚Äì8.  \n5. Kata A. Anti-vaccine activists, Web 2.0, and the postmodern paradigm‚ÄìAn \noverview of tactics and tropes used online by the anti-vaccination movement. \nVaccine. 2012;30(25):3778‚Äì89.  \n6. Zimet GD, Rosberger Z, Fisher WA, Perez S, Stupiansky NW. Beliefs, behaviors \nand HPV vaccine: correcting the myths and the misinformation. Prev Med \n(Baltim). 2013;57(5):414‚Äì8.  \n7. Poland GA, Jacobson RM. Understanding those who do not understand: a brief \nreview of the anti-vaccine movement. Vaccine. 2001;19(17‚Äì19):2440‚Äì5.  \n8. Kata A. A postmodern Pandora‚Äôs box: anti-vaccination misinformation on the \nInternet. Vaccine. 2010;28(7):1709‚Äì16.  \n9. Oyeyemi SO, Gabarron E, Wynn R. Ebola, Twitter, and misinformation: a \ndangerous combination? Bmj. 2014;349.  \n10. Geoghegan S, O‚ÄôCallaghan KP, Offit PA. Vaccine safety: myths and \nmisinformation. Front Microbiol. 2020;11:372.  \n11. Zhou X, Coiera E, Tsafnat G, Arachi D, Ong MS, Dunn AG. Using social \nconnection information to improve opinion mining: Identifying negative sentiment \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nabout HPV vaccines on Twitter. In: MEDINFO 2015: eHealth-enabled Health. \nIOS Press; 2015. p. 761‚Äì5.  \n12. Ghaddar A, Khandaqji S, Awad Z, Kansoun R. Conspiracy beliefs and vaccination \nintent for COVID-19 in an infodemic. PLoS One. 2022;17(1):e0261559.  \n13. Ghosh D, Scott B. Disinformation is becoming unstoppable. Time Disponible en: \nhttp://time com/5112847/facebook-fake-news-unstoppable. 2018;  \n14. Qazvinian V, Rosengren E, Radev D, Mei Q. Rumor has it: Identifying \nmisinformation in microblogs. In: Proceedings of the 2011 conference on \nempirical methods in natural language processing. 2011. p. 1589‚Äì99.  \n15. Wang Y, McKee M, Torbica A, Stuckler D. Systematic literature review on the \nspread of health-related misinformation on social media. Soc Sci Med. \n2019;240:112552.  \n16. Broniatowski DA, Jamison AM, Qi S, AlKulaib L, Chen T, Benton A, et al. \nWeaponized health communication: Twitter bots and Russian trolls amplify the \nvaccine debate. Am J Public Health. 2018;108(10):1378‚Äì84.  \n17. Zarocostas J. How to fight an infodemic. The lancet. 2020;395(10225):676.  \n18. Islam MS, Kamal AHM, Kabir A, Southern DL, Khan SH, Hasan SMM, et al. \nCOVID-19 vaccine rumors and conspiracy theories: The need for cognitive \ninoculation against misinformation to improve vaccine adherence. PLoS One. \n2021;16(5):e0251605.  \n19. Ghaddar A, Khandaqji S, Awad Z, Kansoun R. Conspiracy beliefs and vaccination \nintent for COVID-19 in an infodemic. PLoS One. 2022;17(1):e0261559.  \n20. Gallotti R, Valle F, Castaldo N, Sacco P, De Domenico M. Assessing the risks of \n‚Äòinfodemics‚Äô in response to COVID-19 epidemics. Nat Hum Behav. \n2020;4(12):1285‚Äì93.  \n21. Matteo C, Walter Q, Galeazzi A, Michele VC, Emanuele B, Lucia SA, et al. The \ncovid-19 social media infodemic. Sci Rep. 2020;10(16598 (2020)).  \n22. Mian A, Khan S. Coronavirus: the spread of misinformation. BMC Med. \n2020;18:1‚Äì2.  \n23. Kumar N, Corpus I, Hans M, Harle N, Yang N, McDonald C, et al. COVID-19 \nvaccine perceptions in the initial phases of US vaccine roll-out: an observational \nstudy on reddit. BMC Public Health. 2022;22(1):446.  \n24. Kim JW, Lee J, Dai Y. Misinformation and the Paradox of Trust during the covid-\n19 pandemic in the US: pathways to Risk perception and compliance behaviors. J \nRisk Res. 2023;26(5):469‚Äì84.  \n25. Hou Z, Du F, Zhou X, Jiang H, Martin S, Larson H, et al. Cross-country \ncomparison of public awareness, rumors, and behavioral responses to the COVID-\n19 epidemic: infodemiology study. J Med Internet Res. 2020;22(8):e21143.  \n26. Bavel JJ Van, Baicker K, Boggio PS, Capraro V, Cichocka A, Cikara M, et al. \nUsing social and behavioural science to support COVID-19 pandemic response. \nNat Hum Behav. 2020;4(5):460‚Äì71.  \n27. Prevention C for DC and. HPV vaccine schedule and dosing. United States: \nCenters For Disease Control And Prevention. 2019;  \n28. Schiffman MH, Bauer HM, Hoover RN, Glass AG, Cadell DM, Rush BB, et al. \nEpidemiologic evidence showing that human papillomavirus infection causes most \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \ncervical intraepithelial neoplasia. JNCI: Journal of the National Cancer Institute. \n1993;85(12):958‚Äì64.  \n29. Bosch FX, Manos MM, Mu√±oz N, Sherman M, Jansen AM, Peto J, et al. \nPrevalence of human papillomavirus in cervical cancer: a worldwide perspective. \nJNCI: Journal of the National Cancer Institute. 1995;87(11):796‚Äì802.  \n30. Siegel RL, Miller KD, Jemal A. Cancer statistics, 2019. CA Cancer J Clin. \n2019;69(1):7‚Äì34.  \n31. Prevention C for DC and. Human Papillomavirus (HPV), Reasons to \nGetvaccinated. US Department of Health and Human Services. https://www. cdc. \ngov/hpv ‚Ä¶; 2021.  \n32. Pingali C. National, regional, state, and selected local area vaccination coverage \namong adolescents aged 13‚Äì17 years‚ÄîUnited States, 2020. MMWR Morb Mortal \nWkly Rep. 2021;70.  \n33. Moorhead SA, Hazlett DE, Harrison L, Carroll JK, Irwin A, Hoving C. A new \ndimension of health care: systematic review of the uses, benefits, and limitations of \nsocial media for health communication. J Med Internet Res. 2013;15(4):e1933.  \n34. Levin S. Facebook promised to tackle fake news. But the evidence shows it‚Äôs not \nworking. the Guardian. 2017;16.  \n35. Moorhead SA, Hazlett DE, Harrison L, Carroll JK, Irwin A, Hoving C. A new \ndimension of health care: systematic review of the uses, benefits, and limitations of \nsocial media for health communication. J Med Internet Res. 2013;15(4):e1933.  \n36. Malek S, Griffin C, Fraleigh RD, Lennon R, Monga V, Shen L. A Methodology \nFramework for Analyzing Health Misinformation to Develop Inoculation \nIntervention Using Large Language Models: A case study on covid-19. In: \nAEJMC 108th Annual Conference. 2025.  \n37. Zhou J, Zhang Y, Luo Q, Parker AG, De Choudhury M. Synthetic lies: \nUnderstanding ai-generated misinformation and evaluating algorithmic and human \nsolutions. In: Proceedings of the 2023 CHI Conference on Human Factors in \nComputing Systems. 2023. p. 1‚Äì20.  \n38. Jiang B, Tan Z, Nirmal A, Liu H. Disinformation detection: An evolving challenge \nin the age of llms. In: Proceedings of the 2024 SIAM International Conference on \nData Mining (SDM). SIAM; 2024. p. 427‚Äì35.  \n39. Du J, Preston S, Sun H, Shegog R, Cunningham R, Boom J, et al. Using machine \nlearning‚Äìbased approaches for the detection and classification of human \npapillomavirus vaccine misinformation: Infodemiology study of reddit discussions. \nJ Med Internet Res. 2021;23(8):e26478.  \n40. Tomaszewski T, Morales A, Lourentzou I, Caskey R, Liu B, Schwartz A, et al. \nIdentifying false human papillomavirus (HPV) vaccine information and \ncorresponding risk perceptions from Twitter: advanced predictive models. J Med \nInternet Res. 2021;23(9):e30451.  \n41. Mahdavi H, Hashemi A, Daliri M, Mohammadipour P, Farhadi A, Malek S, et al. \nBrains vs. Bytes: Evaluating LLM Proficiency in Olympiad Mathematics. arXiv \npreprint arXiv:250401995. 2025;  \n42. Alizadeh A, Mortazavi M, Farajijalal M, Toudeshki A, Ehsani R, Singhal M. \nEnhancing Irrigation Efficiency with a Unified Stochastic Decision Tree Model: \nPredictive Analysis of Stem Water Potential in Almond and Pistachio Orchards. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \nIn: World Congress in Computer Science, Computer Engineering & Applied \nComputing. Springer; 2024. p. 499‚Äì515.  \n43. Abedi A, Anari RG, Mohammadi H. Mobile Robot Path Planning Using Deep \nreinforcement learning. In: 2023 11th RSI International Conference on Robotics \nand Mechatronics (ICRoM). IEEE; 2023. p. 97‚Äì102.  \n44. Farajijalal M, Malek S, Toudeshki A, Viers JH, Ehsani R. Data-Driven Model to \nImprove Mechanical Harvesters for Nut Trees. In: 2024 ASABE Annual \nInternational Meeting. American Society of Agricultural and Biological Engineers; \n2024. p. 1.  \n45. Chui M, Manyika J, Miremadi M, Henke N, Chung R, Nel P, et al. Notes from the \nAI frontier: Insights from hundreds of use cases. McKinsey Global Institute. \n2018;2(267):1‚Äì31.  \n46. Acemoglu D, Restrepo P. Artificial intelligence, automation, and work. In: The \neconomics of artificial intelligence: An agenda. University of Chicago Press; 2018. \np. 197‚Äì236.  \n47. Taboada I, Daneshpajouh A, Toledo N, De Vass T. Artificial intelligence enabled \nproject management: a systematic literature review. Applied Sciences. \n2023;13(8):5014.  \n48. Malek S, Salehkaleybar S, Amini A. Multi variable-layer neural networks for \ndecoding linear codes. In: 2020 Iran Workshop on Communication and \nInformation Theory (IWCIT). IEEE; 2020. p. 1‚Äì6.  \n49. Alizadeh A, Farajijalal M, Rezvani Z, Toudeshki A, Ehsani R. Developing a data-\ndriven model for predicting water stress in pistachio trees. In: International \nCongress on Agricultural Mechanization and Energy in Agriculture. Springer; \n2023. p. 186‚Äì96.  \n50. Patwa P, Bhardwaj M, Guptha V, Kumari G, Sharma S, Pykl S, et al. Overview of \nconstraint 2021 shared tasks: Detecting english covid-19 fake news and hindi \nhostile posts. In: Combating Online Hostile Posts in Regional Languages during \nEmergency Situation: First International Workshop, CONSTRAINT 2021, \nCollocated with AAAI 2021, Virtual Event, February 8, 2021, Revised Selected \nPapers 1. Springer; 2021. p. 42‚Äì53.  \n51. Saenz JA, Gopal SRK, Shukla D. COVID-19 fake news infodemic research dataset \n(COVID19-FNIR dataset). IEEE Dataport. 2021;  \n52. Rai S, Kornides M, Morgan J, Kumar A, Cappella J, Guntuku SC. Detecting and \nmonitoring concerns against HPV vaccination on social media using large \nlanguage models. Sci Rep. 2024;14(1):14362.  \n53. Glazkova A, Glazkov M, Trifonov T. g2tmn at constraint@ aaai2021: exploiting \nCT-BERT and ensembling learning for COVID-19 fake news detection. In: \nInternational Workshop on Combating On line Ho st ile Posts in Regional \nLanguages dur ing Emerge ncy Si tuation. Springer; 2021. p. 116‚Äì27.  \n54. Song X, Petrak J, Jiang Y, Singh I, Maynard D, Bontcheva K. Classification aware \nneural topic model for COVID-19 disinformation categorisation. PLoS One. \n2021;16(2):e0247086.  \n55. Ball P, Maxmen A. The epic battle against coronavirus misinformation and \nconspiracy theories. Nature. 2020;581(7809):371‚Äì5.  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint \n56. Micallef N, He B, Kumar S, Ahamad M, Memon N. The role of the crowd in \ncountering misinformation: A case study of the COVID-19 infodemic. In: 2020 \nIEEE international Conference on big data (big data). IEEE; 2020. p. 748‚Äì57.  \n57. Blei DM, Ng AY, Jordan MI. Latent dirichlet allocation. Journal of machine \nLearning research. 2003;3(Jan):993‚Äì1022.  \n58. Karas B, Qu S, Xu Y, Zhu Q. Experiments with LDA and Top2Vec for embedded \ntopic discovery on social media data‚ÄîA case study of cystic fibrosis. Front Artif \nIntell. 2022;5:948313.  \n59. Egger R, Yu J. A topic modeling comparison between lda, nmf, top2vec, and \nbertopic to demystify twitter posts. Frontiers in sociology. 2022;7:886498.  \n60. Abdelrazek A, Eid Y, Gawish E, Medhat W, Hassan A. Topic modeling \nalgorithms and applications: A survey. Inf Syst. 2023;112:102131.  \n61. R√∂der M, Both A, Hinneburg A. Exploring the space of topic coherence measures. \nIn: Proceedings of the eighth ACM international conference on Web search and \ndata mining. 2015. p. 399‚Äì408.  \n62. Bouma G. Normalized (pointwise) mutual information in collocation extraction. \nProceedings of GSCL. 2009;30:31‚Äì40.  \n63. Chang J, Gerrish S, Wang C, Boyd-Graber J, Blei D. Reading tea leaves: How \nhumans interpret topic models. Adv Neural Inf Process Syst. 2009;22.  \n64. Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, et al. Language \nmodels are few-shot learners. Adv Neural Inf Process Syst. 2020;33:1877‚Äì901.  \n65. Kenton JDMWC, Toutanova LK. Bert: Pre-training of deep bidirectional \ntransformers for language understanding. In: Proceedings of naacL-HLT. \nMinneapolis, Minnesota; 2019. p. 2.  \n66. Radford A, Wu J, Child R, Luan D, Amodei D, Sutskever I. Language models are \nunsupervised multitask learners. OpenAI blog. 2019;1(8):9.  \n67. Raffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M, et al. Exploring the \nlimits of transfer learning with a unified text-to-text transformer. Journal of \nmachine learning research. 2020;21(140):1‚Äì67.  \n68. Ding X, Teng C, Ji D. Fake News Detection with Context Awareness of the. In: \nThe 35th international conference on software engineering and knowledge \nengineering. 2023.  \n69. Song X, Petrak J, Jiang Y, Singh I, Maynard D, Bontcheva K. Classification aware \nneural topic model for COVID-19 disinformation categorisation. PLoS One. \n2021;16(2):e0247086.  \n70. Zhou X, Coiera E, Tsafnat G, Arachi D, Ong MS, Dunn AG. Using social \nconnection information to improve opinion mining: Identifying negative sentiment \nabout HPV vaccines on Twitter. In: MEDINFO 2015: eHealth-enabled Health. \nIOS Press; 2015. p. 761‚Äì5.  \n71. Piedrahita-Vald√©s H, Piedrahita-Castillo D, Bermejo-Higuera J, Guillem-Saiz P, \nBermejo-Higuera JR, Guillem-Saiz J, et al. Vaccine hesitancy on social media: \nSentiment analysis from June 2011 to April 2019. Vaccines (Basel). 2021;9(1):28.  \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted May 23, 2025. ; https://doi.org/10.1101/2025.05.22.25327931doi: medRxiv preprint "
}