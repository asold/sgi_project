{
  "title": "Generating medically-accurate summaries of patient-provider dialogue: A multi-stage approach using large language models",
  "url": "https://openalex.org/W4385570813",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2151198642",
      "name": "Varun Nair",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2943758120",
      "name": "Elliot Schumacher",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2108969513",
      "name": "Anitha Kannan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2953486306",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4297435087",
    "https://openalex.org/W4281644150",
    "https://openalex.org/W3169068430",
    "https://openalex.org/W3098562101",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3045635560",
    "https://openalex.org/W3155097739",
    "https://openalex.org/W2998702515",
    "https://openalex.org/W2143514833",
    "https://openalex.org/W2951265142",
    "https://openalex.org/W2963235246"
  ],
  "abstract": "A medical provider's summary of a patient visit serves several critical purposes, including clinical decision-making, facilitating hand-offs between providers, and as a reference for the patient. An effective summary is required to be coherent and accurately capture all the medically relevant information in the dialogue, despite the complexity of patient-generated language. Even minor inaccuracies in visit summaries (for example, summarizing \"patient does not have a fever\" when a fever is present) can be detrimental to the outcome of care for the patient.This paper tackles the problem of medical conversation summarization by discretizing the task into several smaller dialogue-understanding tasks that are sequentially built upon. First, we identify medical entities and their affirmations within the conversation to serve as building blocks. We study dynamically constructing few-shot prompts for tasks by conditioning on relevant patient information and use GPT-3 as the backbone for our experiments. We also develop GPT-derived summarization metrics to measure performance against reference summaries quantitatively. Both our human evaluation study and metrics for medical correctness show that summaries generated using this approach are clinically accurate and outperform the baseline approach of summarizing the dialog in a zero-shot, single-prompt setting.",
  "full_text": "Proceedings of the 5th Clinical Natural Language Processing Workshop, pages 200–217\nJuly 14, 2023 ©2023 Association for Computational Linguistics\nGenerating medically-accurate summaries of patient-provider dialogue:\nA multi-stage approach using large language models\nVarun Nair\nCurai Health\nvarun@curai.com\nElliot Schumacher\nCurai Health\nelliot@curai.com\nAnitha Kannan\nCurai Health\nanitha@curai.com\nAbstract\nA medical provider’s summary of a patient\nvisit serves several critical purposes, includ-\ning clinical decision-making, facilitating hand-\noffs between providers, and as a reference for\nthe patient. An effective summary is required\nto be coherent and accurately capture all the\nmedically relevant information in the dialogue,\ndespite the complexity of patient-generated\nlanguage. Even minor inaccuracies in visit\nsummaries (for example, summarizing “patient\ndoes not have a fever” when a fever is present)\ncan be detrimental to the outcome of care for\nthe patient.\nThis paper tackles the problem of medi-\ncal conversation summarization by discretiz-\ning the task into several smaller dialogue-\nunderstanding tasks that are sequentially built\nupon. First, we identify medical entities and\ntheir affirmations within the conversation to\nserve as building blocks. We study dynami-\ncally constructing few-shot prompts for tasks\nby conditioning on relevant patient informa-\ntion and use GPT-3 (Brown et al., 2020) as\nthe backbone for our experiments. We also de-\nvelop GPT-derived summarization metrics to\nmeasure performance against reference sum-\nmaries quantitatively. Both our human evalua-\ntion study and metrics for medical correctness\nshow that summaries generated using this ap-\nproach are clinically accurate and outperform\nthe baseline approach of summarizing the dia-\nlog in a zero-shot, single-prompt setting.\n1 Introduction\nA critical clinical task during a medical encounter\nbetween a patient and a physician is summarizing\nthe conversation. This summarized note, whether\ncreated by a physician or medical assistant, con-\ntains important information about the visit and\nserves as a reference for future patient visits and\nfor the patient. Physicians often spend many hours\neach week performing such tasks. Charting work,\nFigure 1: MEDSUM-ENT utilizes a multi-stage ap-\nproach for medical dialogue summarization with GPT-3\nthat improves upon naive summarization. The approach\nutilizes intermediate model calls to extract medical con-\ncepts that inform summarization generation.\nin general, has been identified as a contributing\nfactor to increased rates of physician burnout (Es-\nchenroeder et al., 2021).\nAutomating medical conversation summariza-\ntion has been studied with limited success (Pivo-\nvarov and Elhadad, 2015; Liang et al., 2019; Gao\net al., 2022; MacAvaney et al., 2019; Chintagunta\net al., 2021). Some methods try to directly sum-\nmarize the chat (Enarvi et al., 2020; Zhang et al.,\n2021) while others pair deep learning methods with\ninformation extracted from knowledge bases to pro-\nduce accurate summaries (Joshi et al., 2020). As\nbase deep learning methods have improved and\npre-trained language models specific to summa-\nrization such as PEGASUS (Zhang et al., 2020),\nBART (Lewis et al., 2020), and GPT-3 (Brown\net al., 2020) have emerged, we have seen increased\nfidelity of the summaries generated. However, per-\nformance is still not to a reliable standard in prac-\n200\ntical settings for several reasons. First, the lack of\nlabeled clinical data makes it hard to build high-\nperformance fine-tuned models. This reflects lower-\nthan-expected specificity and accuracy in faithfully\ncapturing medical concepts and their affirmations\n(e.g., present, absent, unknown). Second, custom-\ntrained models need more world knowledge to un-\nderstand patient language in these conversations\nand how they map to medical concepts. Third,\nthese models often require breaking conversations\ninto smaller segments to deal with limited context\nwindows. This in turn introduces challenges such\nas incorrect anaphora and coreference resolution\nacross segmented pieces of the conversation.\nThe key contributions of this paper include;\n• MEDSUM-ENT: Inspired by recent works of\nChintagunta et al. (2021) and Agrawal et al.\n(2022), we introduce MEDSUM-ENT: a med-\nical conversation summarization model that\ntakes a multi-stage approach to summariza-\ntion, using GPT-3 (Brown et al., 2020) as the\nbackbone. MEDSUM-ENT ( Fig. 1) grounds\nthe task by first extracting medical entities\nand their affirmations. These extractions are\nincluded as additional input that informs the fi-\nnal summarization step through prompt chain-\ning (Wu et al., 2022). MEDSUM-ENT also\nexploits few-shot prompting for medical con-\ncept extraction and summarization through\nin-context example selection.\nIn both qualitative physician analysis of medi-\ncal dialogue summaries and quantitative met-\nrics, MEDSUM-ENT generates clinically ac-\ncurate summaries and produces summaries\nthat are preferable to a zero-shot, single\nprompt baseline.\n• Automated metrics: Quantitative metrics are\nhard to design for generative tasks. We extend\nproxy metrics of Joshi et al. (2020) by lever-\naging GPT-3 to compare the coverage of the\npresence of medical entities in the generated\ntexts. Beyond only identifying exact matches,\nour approach better accounts for paraphrasing\nthose medical events within the larger text.\n2 Methods\nWe now detail the components of our MEDSUM-\nENT framework for medical dialogue summariza-\ntion, represented in Figure 1.\nMedical Entity Extraction To highlight clinical\nconcepts, we extract medical entities (symptoms,\ndiseases etc.) and their affirmation status of either\npresent, absent, or unknown. These entities and\ntheir status will be used as additional inputs to the\nfinal summarization step.\nWe first perform entity extraction on the pa-\ntient’s first message of the encounter, which is of-\nten lengthy and information dense. We call this\nmessage the reason for encounter (RFE). Conver-\nsational turns between the medical provider and the\npatient follow the RFE. We also extract medical\nentities from the conversation, one provider and\none patient turn at a time. To accommodate these\ntwo types of texts, we use two different prompts,\nincluded in Prompt 1 (for RFE entity extraction)\nand Prompt 2 (for dialogue entity extraction). Both\nprompts are populated with in-context examples\n(see In-Context Example Selection) along with the\npatient’s age and sex. The final list of entities in\nthe dialogue is obtained by collating all entities\nextracted across the RFE and all dialogue turns.\nAdditionally, we also use an entity resolver simi-\nlar to those used in Agrawal et al. (2022) to resolve\nentities in the unknown entities list whose status\nmay have changed during the dialogue (see Prompt\n3). For instance, a dialogue turn pair may not have\nenough information to definitively assign a present\nor absent status and thus an entity is \"unknown\".\nA later dialogue turn may contain information that\nchanges that assignment. By introducing this re-\nfinement step, we reduce mistakes in the \"Pertinent\nUnknowns\" section of the summary (see Table 1).\nSummarization Given a list of medical entities,\nwe summarize the medical dialogue using the di-\nalogue and the entities as input. Our summaries\nare structured into six sections: Demographics and\nSocial Determinants of Health, Medical Intent, Per-\ntinent Positives, Pertinent Negatives, Pertinent Un-\nknowns, and Medical History (see Prompt 4 for\ndetails).\nIn-Context Example Selection For the entity ex-\ntraction and summarization modules, we compare\nsemantic-similarity and random in-context exam-\nple selection. Semantic-similarity-based selection\nselects labeled examples from a pool using the\npatient’s age, sex, and the query point. Random se-\nlection randomly selects in-context examples from\nthese pools to populate our prompts. Further im-\nplementation details are in Appendix A.1.\n201\nFigure 2: Results of human expert evaluations show\nMEDSUM-ENT (5-shot) is preferred 66% to 34% over\na single-prompt, 0-shot naive summarization baseline.\n3 Experiments\nDataset: We use a dataset of 100 clinical en-\ncounters of dialogue-summary pairs that occurred\nbetween a licensed physician and a patient on a\ntelehealth platform over chat. Encounters in this\ndataset cover a variety of common presentations in\ntelehealth, including urinary tract infections, back-\n/abdominal pains, toothaches, and others. All data\nwas de-identified and scrubbed for protected health\ninformation prior to experimentation. Conversa-\ntions contain 46 dialogue turns on average (min of\n8 turns, max of 92 turns) and an average of 2342\nunigram tokens per encounter. Ground truth sum-\nmaries were created by using text-davinci-002\non encounter data to generate an initial summary,\nwhich physicians then edited for correctness.\nBaselines/Ablations: We compare MEDSUM-\nENT to a “naive” zero-shot, single-prompt base-\nline (i.e. without chaining) that prompts GPT-3 to\nsummarize the conversation (see Prompt 5). For\nMEDSUM-ENT, we evaluate extraction k-shot con-\nfigurations (1,3,5-shot) and in-context example se-\nlection methods (semantic-similarity based, ran-\ndom) for entity extraction. We use RFE and dia-\nlogue entity extraction prompts in at least a 1-shot\nconfiguration for MEDSUM-ENT to ensure valid\noutput. Our summarization prompt for baselines\nand MEDSUM-ENT cannot go beyond 1-shot due\nto token limits. All experiments are run once and\nuse GPT-3 (davinci-003) (see Appendix A.2 for\nprompt settings).\n3.1 Evaluation Metrics\nExpert Evaluation We also asked four doctors,\nwho serve tele-health patients, to judge between\nthe MEDSUM-ENT and baseline-generated sum-\nmaries on three points on a random set of 50 en-\ncounters. For a given encounter, we asked 1) for\npreference between baseline and MEDSUM-ENT\nsummaries, 2) what amount of clinical information\nwas captured in MEDSUM-ENT’s summaries, and\n3) about the presence of clinically harmful informa-\ntion in MEDSUM-ENT summaries (see Appendix\nA.3 for full instruction details).\nGPT-Driven Automated Summarization Met-\nrics: Acknowledging the challenges in auto-\nmatic evaluations of summarization (Peyrard, 2019;\nGoyal et al., 2022), we focus on quantitatively\nevaluating the correctness/faithfulness of captur-\ning medical concepts and their affirmation status.\nWe extend the approach to metrics in Joshi et al.\n(2020) to have two components, both powered by\nGPT-3: a medical concept extractor (Appendix\nPrompt 6) and a verifier (Appendix Prompt 7). The\nverifier checks if the concepts extracted from one\npiece of text are present in another and permits the\nsame medical concept extracted or written in dif-\nferent ways to count towards a true positive. For\nexample, for the “Pertinent Positives” section, the\npredicted value may be “Patient has back pain\nand COVID-19” and the resulting concepts [“back\npain”, “COVID-19”] and the ground-truth “Patient\nhas COVID and some pain in the backside” with\nconcepts [“COVID”, “pain in the back”]. Prior\nmetrics that rely on verbatim matches would fail to\nrecognize the predicted text as correct. We define\nthe following metrics:\nGPT-Recall: We extract medical entities from\nboth the predicted text and ground-truth text of\nthe same summary section. We use the verifier to\ninfer if the entities extracted from the ground-truth\nsection are also present in the predicted text. This\nproduces tpgt and fn, which is used to calculate\nGPT-Recall = tpgt\ntpgt+fn .\nGPT-Precision: We verify concepts extracted\nfrom the predicted section are also present in the\nground-truth text, either as exact matches or re-\nphrasings. This produces tppred and fp, which is\nused to calculate GPT-Precision = tppred\ntppred+fp .\nGPT-F1 is the harmonic mean of GPT-Precision\nand GPT-Recall. Note our approach maintains the\nintegrity of recall and precision (neither score can\n202\nGPT-F1 (↑)\nMethod Extraction\nK-shot\nSummarization\nK-shot\nExample\nSelection\nEntity\nResolver\nPertinent\nPositives\nPertinent\nNegatives\nPertinent\nUnknowns\nMedical\nHistory\nAverage\nNaive\n- 0-shot - - 72.9 71.7 45.4 43.9 58.5\n- 1-shot semantic - 71.0 69.5 42.1 48.3 57.7\n- 1-shot random - 69.4 69.1 47.5 44.7 57.7\nMEDSUM-ENT\n1-shot 1-shot semantic ✓ 72.4 70.1 50.0 46.2 59.7\n1-shot 1-shot random ✓ 71.4 71.1 54.0 48.3 61.2\n3-shot 1-shot semantic ✓ 71.9 69.0 42.5 47.0 57.6\n3-shot 1-shot random - 72.1 69.4 46.4 45.8 58.4\n3-shot 1-shot random ✓ 72.2 70.9 55.8 50.4 62.3\n5-shot 1-shot semantic ✓ 71.8 70.2 46.6 46.3 58.7\n5-shot 1-shot random ✓ 71.9 68.3 51.9 48.2 60.0\nTable 1: Results of GPT-driven metrics. Performance across “Pertinent Positives”, “Pertinent Negatives” sections\nare fairly consistent across methods. MEDSUM-ENT demonstrates consistently improved performance in the\n“Pertinent Unknowns” and “Medical History” sections. Surprisingly, we also find consistently higher performance\nacross experiments using random in-context example selection over semantic-similarity-based selection.\ntake on a value > 1). We evaluate MEDSUM-ENT\nvia the GPT-Precision and GPT-Recall metrics de-\nscribed in section 3.1 on all 100 clinical encoun-\nters.\n4 Results\nTable 1 shows quantitative metrics on summaries\nproduced by the baselines and MEDSUM-ENT.\nBoth generated summaries are compared to the\nground truth summaries. We see that while GPT-F1\nperformance for “Pertinent Positives” and “Per-\ntinent Negatives” is consistent across methods,\nMEDSUM-ENT’s ability to capture the “Pertinent\nUnknowns” and “Medical History” pushes its aver-\nage consistently above that of the naive zero-shot,\nnon-chained baseline. These sections are crucial\nto include correctly as they often influence clini-\ncal decision-making. Also, the Unknown Entity\nResolver improves performance specifically in the\n“Pertinent Unknowns” section (ablated in rows 7\nvs. 8 with 46.4 vs. 55.8 for with and without the\nresolver). The “Demographics and Social Deter-\nminants of Health” and “Medical Intent” sections\nhave nearly identical, accurate output across all\nexperiments, so we do not calculate metrics for\nthem. See Appendix A.4 for example generated\nsummaries.\nWe find two surprising results. First, there is no\ncorrelation between a larger k-shot and increased\nperformance. This may demonstrate diminishing\nreturns of GPT-3 to perform medical concept ex-\ntraction. Furthermore, the use of semantic similar-\nity to select in-context examples performs worse\nthan randomly selecting examples. This follows Ye\net al. (2022) which claims diversity of in-context\nsamples is more important than similarity.\nIn our expert human evaluations, Figure 2\ndemonstrates MEDSUM-ENT (5-shot, semantic)\nsummaries are preferred over the baseline sum-\nmaries 66% to 34%. Our expert evaluators also\nrate MEDSUM-ENT capturing all relevant medical\ninformation in 40% of evaluated summaries, most\ninformation in 48%, some information in 12%, and\nzero information in 0%. This provides further qual-\nitative evidence for MEDSUM-ENT’s ability to\neffectively summarize. However, our expert evalu-\nators also rate 28% of the summaries evaluated as\ncontaining incorrect information that could harm\nthe patient if acted on by medical providers. Of-\nten these are due to misattributed symptoms and\nconditions (e.g., symptoms marked as absent but\nwere present, missed medication allergies). This is\nconsistent with the GPT-F1 measures for pertinent\npositives and negatives in Table 1 and highlights\nthe challenge involved in deploying a system such\nas MEDSUM-ENT. Further work is needed to trust\nsuch systems in the wild.\n5 Conclusion\nWe introduce MEDSUM-ENT, a multi-stage frame-\nwork for medical dialogue summarization that mod-\nularizes summarization into multiple stages that\nextract and refine medical entities from dialogue\nturns. Through human evaluation and quantita-\ntive metrics, we show that this method is clinically\naccurate and preferable to naive zero-shot summa-\nrization with GPT-3. We hope that future work\ncan investigate refinement modules and iterative\nsummarization further and conduct wider expert\nhuman evaluation studies to better understand chal-\nlenges in bringing model-assisted summarization\nto medical providers in the near term.\n203\n6 Limitations\nThe experiments in this paper were performed us-\ning OpenAI’s GPT-3 API. While running locally\ndoes not require a large amount of computational\nresources, the server-side service cannot be eas-\nily replicated and requires a large amount of com-\nputational resources. Additionally, given the in-\nherently restrictive nature of medical text, we can\nonly evaluate our approach on a small corpus of\nEnglish-language dialogues taken from the dataset\nof a single company’s medical service, which we\ncannot release due to privacy concerns. Finally,\ngiven summarization is a challenging task to eval-\nuate, we rely on a small number of expert human\nannotators and automatic metrics. However, addi-\ntional annotations may be helpful and it may also\nhelp to study and report labeler agreement when\nreporting human preferences.\nReferences\nMonica Agrawal, Stefan Hegselmann, Hunter Lang,\nYoon Kim, and David Sontag. 2022. Large language\nmodels are zero-shot clinical information extractors.\narXiv preprint arXiv:2205.12689.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nBharath Chintagunta, Namit Katariya, Xavier Amatri-\nain, and Anitha Kannan. 2021. Medically aware\nGPT-3 as a data generator for medical dialogue sum-\nmarization. In Proceedings of the Second Workshop\non Natural Language Processing for Medical Conver-\nsations, pages 66–76, Online. Association for Com-\nputational Linguistics.\nSeppo Enarvi, Marilisa Amoia, Miguel Del-Agua Teba,\nBrian Delaney, Frank Diehl, Stefan Hahn, Kristina\nHarris, Liam McGrath, Yue Pan, Joel Pinto, Luca Ru-\nbini, Miguel Ruiz, Gagandeep Singh, Fabian Stem-\nmer, Weiyi Sun, Paul V ozila, Thomas Lin, and Ran-\njani Ramamurthy. 2020. Generating medical reports\nfrom patient-doctor conversations using sequence-to-\nsequence models. In Proceedings of the First Work-\nshop on Natural Language Processing for Medical\nConversations, pages 22–30, Online. Association for\nComputational Linguistics.\nJr Eschenroeder, H. C, Lauren C Manzione, Julia Adler-\nMilstein, Connor Bice, Robert Cash, Cole Duda,\nCraig Joseph, John S Lee, Amy Maneker, Karl A\nPoterack, Sarah B Rahman, Jacob Jeppson, and\nChristopher Longhurst. 2021. Associations of physi-\ncian burnout with organizational electronic health\nrecord support and after-hours charting. Journal\nof the American Medical Informatics Association ,\n28(5):960–966.\nYanjun Gao, Dmitriy Dligach, Timothy Miller, Dong-\nfang Xu, Matthew M. M. Churpek, and Majid Af-\nshar. 2022. Summarizing patients’ problems from\nhospital progress notes using pre-trained sequence-\nto-sequence models. In Proceedings of the 29th Inter-\nnational Conference on Computational Linguistics,\npages 2979–2991, Gyeongju, Republic of Korea. In-\nternational Committee on Computational Linguistics.\nTanya Goyal, Junyi Jessy Li, and Greg Durrett. 2022.\nNews summarization and evaluation in the era of\ngpt-3.\nJeff Johnson, Matthijs Douze, and Hervé Jégou. 2019.\nBillion-scale similarity search with GPUs. IEEE\nTransactions on Big Data, 7(3):535–547.\nAnirudh Joshi, Namit Katariya, Xavier Amatriain, and\nAnitha Kannan. 2020. Dr. summarize: Global sum-\nmarization of medical dialogue by exploiting local\nstructures. In Findings of the Association for Com-\nputational Linguistics: EMNLP 2020 , pages 3755–\n3763, Online. Association for Computational Lin-\nguistics.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020.\nBART: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and com-\nprehension. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 7871–7880, Online. Association for Computa-\ntional Linguistics.\nJennifer Liang, Ching-Huei Tsou, and Ananya Poddar.\n2019. A novel system for extractive clinical note\nsummarization using EHR data. In Proceedings of\nthe 2nd Clinical Natural Language Processing Work-\nshop, pages 46–54, Minneapolis, Minnesota, USA.\nAssociation for Computational Linguistics.\nSean MacAvaney, Sajad Sotudeh, Arman Cohan, Na-\nzli Goharian, Ish Talati, and Ross W Filice. 2019.\nOntology-aware clinical abstractive summarization.\nIn Proceedings of the 42nd International ACM SI-\nGIR Conference on Research and Development in\nInformation Retrieval, pages 1013–1016.\nMaxime Peyrard. 2019. Studying summarization eval-\nuation metrics in the appropriate scoring range. In\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 5093–\n5100, Florence, Italy. Association for Computational\nLinguistics.\nRimma Pivovarov and Noémie Elhadad. 2015. Auto-\nmated methods for the summarization of electronic\nhealth records. Journal of the American Medical\nInformatics Association, 22(5):938–947.\n204\nTongshuang Wu, Michael Terry, and Carrie Jun Cai.\n2022. Ai chains: Transparent and controllable\nhuman-ai interaction by chaining large language\nmodel prompts. In Proceedings of the 2022 CHI\nConference on Human Factors in Computing Sys-\ntems, CHI ’22, New York, NY , USA. Association for\nComputing Machinery.\nXi Ye, Srini Iyer, Asli Celikyilmaz, Ves Stoyanov, Greg\nDurrett, and Ramakanth Pasunuru. 2022. Comple-\nmentary explanations for effective in-context learn-\ning. ArXiv, abs/2211.13892.\nJingqing Zhang, Yao Zhao, Mohammad Saleh, and Pe-\nter Liu. 2020. Pegasus: Pre-training with extracted\ngap-sentences for abstractive summarization. In In-\nternational Conference on Machine Learning, pages\n11328–11339. PMLR.\nLongxiang Zhang, Renato Negrinho, Arindam Ghosh,\nVasudevan Jagannathan, Hamid Reza Hassanzadeh,\nThomas Schaaf, and Matthew R Gormley. 2021.\nLeveraging pretrained models for automatic sum-\nmarization of doctor-patient conversations. arXiv\npreprint arXiv:2109.12174.\nA Appendix\nA.1 Dynamic example selection\nWe create labeled in-context example pools for\nRFE entity extraction and dialogue entity extrac-\ntion using physician labels for what medical con-\ncepts would have been extracted and created a sum-\nmarization pool using physician-written dialogue\nsummaries. The dialogue summaries for this pool\nwere created by physicians editing the outputs of\nsummaries created by text-davinci-002. Semantic-\nsimilarity based example selection is implemented\nusing nearest-neighbor search with the LangChain1\nand FAISS (Johnson et al., 2019) libraries.\nA.2 Experiment details\nPrompt temperature max_tokens top_p\nRFE Medical Entity Extr.0.1 200 1.0\nDialogue Medical Entity Extr.0.1 200 1.0\nUnknown Entity Resolver0.1 200 1.0\nSummarization 0.7 512 1.0\nMetric: Medical Entity Extr.0.0 200 1.0\nMetric: Medical Entity Verif.0.0 200 1.0\nTable 2: Experimental settings for all prompts used in\nthis work, no hyper-parameter search was run to obtain\nthese values. We use lower temperature values for model\ncalls where we expect lower variability in its inputs\n(summarization takes in dialogues and list of medical\nentities of varying lengths and sizes respectively, thus\nhas a higher temperature). Running the metric concept\nextraction and verification prompts at a temperature of 0\nensures maximal reproducibility of metric computation.\nEach experiment (line in Table 1 took approximately\n3 hours to run, with exponential back-off used during\nGPT-3 queries.)\nA.3 Expert evaluation\nTo qualitatively evaluate our summaries, we con-\nducted physician evaluations focused on three ques-\ntions:\n• Q1: How often are summaries written using\nMEDSUM preferred over naively generated\nsummaries?\n• Q2: What fraction of relevant clinical informa-\ntion is captured in the summaries generated\nby our method? (All, Most, Some, None)\n• Q3: Does the summary generated by our\nmethod contain incorrect information that\ncould significantly alter the course of treat-\nment and potentially harm the patient if\n1https://github.com/hwchase17/langchain\n205\nthis summary was used by another medical\nprovider?\nQ1 was asked alongside some basic instructions\nfor how choices should be made, shown below:\nFor this task, you will see a dialogue, RFE, and\nage/sex information for a patient. The task is\nto identify which of the 3 summary options you\nwould prefer to use as a visit summary. You may\nuse your own discretion in selecting which of the\n3 options you prefer. Some things to note when\nselecting are:\n• How thorough and clinically accurate is each\nsummary?\n• Is the summary missing clinically relevant in-\nformation?\n• Does the summary contain extraneous infor-\nmation that is harmful if a provider were to\nread and act upon information in the sum-\nmary?\n• Which summary is stylistically preferable\nand/or easier to read?\n206\nA.4 Qualitative Analysis\nWe provide two examples of outputs from our naive\n0-shot, single-prompt baseline and MEDSUM\n(5-shot, semantic) below. All protected health\ninformation is anonymized using tags in all caps\n(eg. DATE_1, LOCATION_1, NAME). Note the\ngreen text which captures correctly summarized in-\nformation that is not present in the other method’s\noutput, and red text which marks a mistake\nthat is not present in the other method’s output.\nChat A. Reason for Encounter: UTI\nDoctor: Do you have any pain or discomfort\nwhen you urinate ?\nPatient: present\nDoctor: Do you experience sudden urges to uri-\nnate ?\nPatient: present\nDoctor: Have you been urinating more fre-\nquently than usual ?\nPatient: present\nDoctor: Have you noticed any discharge from\nthe urethra ?\nPatient: present\nDoctor: Have you been sexually active in the\npast 3 months ?\nPatient: present\nDoctor: Do you have to urinate at night , waking\nup two or more times to urinate ?\nPatient: present\nDoctor: Do you have pain on the side of your\ntorso just below your ribs ?\nPatient: absent\nDoctor: Does your abdomen or belly hurt ?\nPatient: unknown\nDoctor: Since when are you having these symp-\ntoms ?\nPatient: 2 weeks ago\nDoctor: Have you taken anything for these symp-\ntoms ?\nPatient: Azo\nDoctor: Has it helped ?\nPatient: Somewhat not much\nDoctor: Can you describe the urine ?\nPatient: Lots of it Bloated Orange when I take\nthat medicine Dark yellow the rest\nDoctor: Is there any blood in the urine ?\nPatient: No\nDoctor: Does the urine have any foul smell ?\nPatient: No\nDoctor: Do you have pain below your belly but-\nton ?\nPatient: present Some not much\nDoctor: Have you noticed any difficulty passing\nurine ?\nPatient: absent\nDoctor: Do you have pain with sexual inter-\ncourse ?\nPatient: present This is when it started\nDoctor: Do you have pain in lower abdomen\nlower belly ?\nPatient: present\nDoctor: Have you noticed any vaginal discharge\n?\nPatient: unknown\nDoctor: Do you have low back pain ?\nPatient: present\nDoctor: Does the outer part of your vagina itch ?\nPatient: absent\nDoctor: Do you have a fever ?\nPatient: absent\nDoctor: Do you have nausea ?\nPatient: present\nDoctor: What was the first day of your last men-\nstrual period ?\nPatient: I have no cycle hysterectomy\nDoctor: When were you last sexually active ?\nPatient: Two weeks ago\nDoctor: Have you had a UTI in the past ?\nPatient: Yes\nDoctor: When was it [NAME] and what was\ndone ?\nPatient: Six months ago antibiotics\n207\nMEDSUM Summary for Chat A\nDemographics and Social Determinants\nof Health:\nA 46 year old female.\nPatient Intent:\nPatient came for UTI.\nPertinent Positives:\nPatient reports pain and discomfort\nwhen urinating, sudden urges to urinate,\nincreased urination frequency, urethral\ndischarge, sexual activity in the past\n3 months, orange urine when taking\nmedication, dark yellow urine the rest,\nabdominal pain below the belly button,\npain with sexual intercourse when the\nsymptoms started, lower abdominal pain,\nlow back pain and nausea. Symptoms\nhave been present for 2 weeks. She has\ntaken Azo to manage the symptoms which\nhave only slightly helped.\nPertinent Unknowns:\nPatient is unsure if her urine has any foul\nsmell and if there is any vaginal discharge.\nPertinent Negatives:\nPatient reports no fever, no difficulty\npassing urine, no vulvar pruritus, and no\nhematuria.\nMedical History : Patient has a hys-\nterectomy and was last sexually active\ntwo weeks ago. She had a UTI six months\nago and was treated with antibiotics.\nBaseline Summary for Chat A\nDemographics and Social Determinants\nof Health:\nThe patient is a 46 year old female.\nPatient Intent:\nThe patient is seeking care for UTI.\nPertinent Positives:\nThe patient has experienced pain or dis-\ncomfort when urinating, sudden urges\nto urinate, increased urination frequency,\ndischarge from the urethra, and pain with\nsexual intercourse in the past 3 months. She\nhas also experienced pain on the side of\nher torso below her ribs, and pain in her\nlower abdomen. She has taken Azo, which\nsomewhat helped her symptoms. The urine\nis abundant and bloated, orange when she\ntakes the medicine, and dark yellow the rest\nof the time.\nPertinent Unknowns:\nThe patient is unsure of any abdominal\npain, and if there is any foul smell to the\nurine. She is also unsure if there is any\nvaginal discharge.\nPertinent Negatives:\nThe patient does not have any blood in the\nurine, and the outer part of her vagina does\nnot itch. She also does not have a fever or\ndifficulty passing urine.\nMedical History:\nThe patient has had a hysterectomy and was\nlast sexually active two weeks ago. She has\nhad a UTI in the past, which was six months\nago, and she was treated with antibiotics.\n208\nChat B. Reason for Encounter: I took my inhaler\na few minutes and realized i am almost out of it.\nI was woundering if i can get a prescription from\nyou? I have asthma and the last few days tight\nchest and breath with weezing issues\nDoctor: Thanks for confirming Sorry to hear\nabout the symptoms you are currently expe-\nriencing , [NAME] . May I know when you\nwere diagnosed with asthma ?\nPatient: When i was born I was dx Last asthma\nattack has been at least 2 years\nDoctor: Thanks for letting me know about it .\nWhich inhaler have you been prescribed on\nand how long have you been using it ?\nPatient: Albuteraol\nDoctor: Okay . Would you be able to share a pic-\nture of the inhaler with the last prescription ,\nthat clearly mentions about the dosage and\nfrequency ?\nPatient: Prn . I do not have the prescription . I\ngot it almost 2 years ago\nDoctor: Thanks for sharing , [NAME] . Have\nyou been using it since childhood ?\nPatient: I have been using this one only on prn\nbases . In the past i have used a steroid one\nspary twice a day . Do not remember the\nname\nDoctor: Okay . How often do you generally use\nthe inhaler and how many puffs do you use\neach time ?\nPatient: Albuterol i use maybe best guess once\na month too once every two months . When\ni use it two sparys . I take one wait for 5\nminutes and repeat\nDoctor: Okay . When was the last\nDoctor:s visit ?\nPatient: In January . Just lost my job so i dont\nhave insurance to go back right now\nDoctor: I hear you , [NAME] . Sorry to hear\nabout the job loss . How long have you been\nexperiencing these symptoms now ? . Have\nyou noticed any trigger factors associated\nwith them ? Anything that could have re-\nsulted in the symptoms or worsened it ?\nPatient: Possible since i am obsessed 340 lbs\n. But the weather here has been muggy hot\nhumidity has been off the charts . Not normal\nfor LOCATION_1\nDoctor: Thanks for letting me know about it .\nIm going to send you questions to make sure\nIm correctly collecting all of your symptoms\n. Please select “Yes” , “No” , or “Unsure”\nin the question and hit Send once youve in-\nput your response Do you get more short of\nbreath than expected with activity ?\nPatient: present Lately yes\nDoctor: Do you have a dry cough ?\nPatient: present Chronic\nDoctor: Do you have a cough that brings up\nphlegm or mucus ?\nPatient: present Clear\nDoctor: Do you have chest pain that worsens\nwhen you take a deep breath ?\nPatient: absent\nDoctor: Do you wake up from sleep and find\nyourself out of breath ?\nPatient: absent\nDoctor: Do you feel short of breath while lying\ndown ?\nPatient: absent\nDoctor: Do you have shortness of breath at rest\nor while sitting ?\nPatient: absent\nDoctor: Do you have difficulty falling asleep ?\nPatient: absent\nDoctor: Do you frequently find yourself waking\nup in the middle of the night ?\nPatient: present\nDoctor: Do you feel fatigued ?\nPatient: present Possible due to the over weight\nthat i am currently working on loosing\nDoctor: Have you recently been exposed to ani-\nmals ?\nPatient: absent\nDoctor: Have you recently been in close contact\nwith someone diagnosed with COVID-19 ?\nPatient: absent\nDoctor: Do you have difficulty breathing when\nyou lean forward ?\nPatient: present\nDoctor: Do you have difficulty speaking more\nthan short phrases due to the breathing diffi-\nculty ?\nPatient: absent\nDoctor: How long have you been noticing all of\nthese symptoms , [NAME] ?\nPatient: Short of breath leaning forward past\n30 minutes . Took two puffs starting to feel\nok NAME_1... was dx with sinus issues .\nAlways draining\n209\nDoctor: Has the breathing difficulty , wheezing ,\nchest pressure started only today within the\npast hour ?\nPatient: Wheezing yesterday . Chest pressure\nand wheezing only today\n210\nMEDSUM Summary for Chat B\nDemographics and Social Determinants\nof Health:\nA 43 year old male. He recently lost his\njob and currently lacks insurance. He is\ncurrently working on losing weight and\nthe weather in LOCATION_1 has been\nextremely muggy and hot.\nPatient Intent:\nPatient came to address his concern of\nneeding a prescription for his inhaler and\nto address his asthma symptoms of tight\nchest, shortness of breath, and wheezing.\nPertinent Positives:\nPatient has asthma since birth, he has\nbeen using an Albuterol inhaler as needed\nand a steroid spray twice a day in the past,\nhe has a dry cough, difficulty breathing\nwhen leaning forward, is coughing up\nphlegm, has chest pressure, wakes up in\nthe middle of the night, is fatigued, has\nsinus issues, and has wheezing.\nPertinent Unknowns:\nPatient is unsure of the dosage and\nfrequency of his prescription medication\nand the name of his steroid medication.\nPertinent Negatives:\nPatient has no chest pain, difficulty\nspeaking more than short phrases be-\ncause of breathing difficulty, shortness\nof breath while lying down, difficulty\ninitiating sleep, mucus, animal exposure,\nor contact with someone diagnosed\nwith COVID19.\nMedical History:\nPatient was diagnosed with asthma at birth,\nhis last asthma attack was at least 2 years\nago, he has been using an Albuterol inhaler\nas needed for the past 2 years, and he has\nbeen experiencing symptoms for the past\n30 minutes.\nBaseline Summary for Chat B\nDemographics and Social Determinants\nof Health:\n43 year old male patient, unemployed and\nobese (340 lbs). Living in a hot, humid area\nwith high levels of humidity.\nPatient Intent:\nPatient is requesting a prescription for an\ninhaler, as the patient is almost out of it\nand has been experiencing tightness in their\nchest and wheezing issues for the past few\ndays.\nPertinent Positives:\nPatient has asthma, has been using Albuterol\ninhaler on a prn basis, has a chronic dry\ncough, and has been noticing shortness of\nbreath and difficulty leaning forward for the\npast 30 minutes.\nPertinent Unknowns:\nPatient is unsure if the weather or being\noverweight is causing the symptoms.\nPertinent Negatives:\nPatient does not have chest pain, difficulty\nbreathing when lying down, difficulty\nspeaking, difficulty falling asleep, or\nwaking up in the middle of the night due\nto breathing difficulty.\nMedical History:\nPatient was diagnosed with asthma at birth\nand had their last asthma attack 2 years ago.\nPatient was last at the doctor in January and\nhas been experiencing the symptoms for the\npast few days. Patient has been using the\ncurrent inhaler for 2 years, and has used a\nsteroid inhaler twice a day in the past, but\ncan not remember the name. Patient has\nbeen diagnosed with sinus issues and has\nbeen having clear mucus drainage.\n211\n1 ----\n2 Below is the first message from a{ age_and_sex } patient seeking care :\n3 ----\n4 Patient : { rfe }\n5 ----\n6 Using the patient ’s message above , please find the medical entities (\nmedical concepts , symptoms , or medical conditions ) and each one ’s\nstatus ( present , absent , or unknown ) that would be important for a\ndoctor to know .\n7 If the patient states the presence of a medical concept , symptom or\ncondition , the medical entity ’s status should be present .\n8 If the patient denies the presence of a medical concept , symptom or\ncondition , the medical entity ’s status should be absent .\n9 Medical entities should have an unknown status ONLY if the patient is\nthemselves unsure or hesitant about a medical entity (eg: an answer of\n\" Unknown \", or \"I’m not sure about ...\"\") .\n10 Do NOT add a medical entity as unknown if the uncertainty is due to a\nDATE_1 , DATE_2 , NAME , or LOCATION tag . If there is such a medical\nentity associated with a tag , it must be either positive or negative .\n11 Only extract medical entities that exist in the patient ’s message . DO NOT\nEXTRACT NON - MEDICAL ENTITIES .\n12 Each medical entity should belong to one of six categories : Demographics\nand Social Determinants of Health , Patient Intent , Pertinent Positives\n, Pertinent Negatives , Pertinent Unknowns , or Medical History .\n13 ----\nPrompt 1: Prompt for reason for encounter (RFE) medical entity extraction.\n1 ----\n2 Below is a dialogue between a doctor and a{ age_and_sex } patient seeking\ncare :\n3 ----\n4 { dialogue }\n5 ----\n6 Using the patient ’s message above , please find the medical entities (\nmedical concepts , symptoms , or medical conditions ) and each one ’s\nstatus ( present , absent , or unknown ) that would be important for a\ndoctor to know .\n7 If the patient states the presence of a medical concept , symptom or\ncondition , the medical entity ’s status should be present .\n8 If the patient denies the presence of a medical concept , symptom or\ncondition , the medical entity ’s status should be absent .\n9 Medical entities should have an unknown status ONLY if the patient is\nthemselves unsure or hesitant about a medical entity (eg: an answer of\n\" Unknown \", or \"I’m not sure about ...\"\") .\n10 Do NOT add a medical entity as unknown if the uncertainty is due to a\nDATE_1 , DATE_2 , NAME , or LOCATION tag . If there is such a medical\nentity associated with a tag , it must be either positive or negative .\n11 Only extract medical entities that exist in the patient - physician\ndialogue . DO NOT EXTRACT NON - MEDICAL ENTITIES .\n12 Each medical entity should belong to one of six categories : Demographics\nand Social Determinants of Health , Patient Intent , Pertinent Positives\n, Pertinent Negatives , Pertinent Unknowns , or Medical History .\n13 ----\nPrompt 2: Prompt for dialogue medical entity extraction.\n212\n1 ---\n2 Below are medical entities ( concepts , symptoms , or conditions ) extracted\nfrom a medical conversation between a 22 year old patient and doctor .\n3\n4 Your job is to clean up the \" Unknown Entities \" list given the patient -\ndoctor dialogue and a list of positive and negative entities .\n5\n6 Remove any entities that that not are medical entities , or any entities\nthat are unnecessary or completely irrelevant entities given the\ndialogue , positive entities , and negative entities .\n7\n8 If a similar entity is both present and unknown , or , both absent and\nunknown , keep it in the unknowns ONLY if this information is still\nunknown after the entire dialogue .\n9\n10 --- Dialogue ---\n11 // Example dialogue\n12 --- Dialogue ---\n13\n14 Positive Entities : cough , headache , lower back pain\n15\n16 Negative Entities : fever , chest pain , chest tightness\n17\n18 Unknown Entities : past episode of flu , age_1 , covid vaccination , symptoms\n, cough , fever , difficulty breathing , runny nose , frequency of\nheadache , headache\n19 ---\n20 Cleaned Unknown Entities : past episode of flu , covid vaccination ,\ndifficulty breathing , runny nose\n21 ---\n22 ---\n23 Below are medical entities ( concepts , symptoms , or conditions ) extracted\nfrom a medical conversation between a { age_and_sex } patient and doctor\n.\n24\n25 Your job is to clean up the \" Unknown Entities \" list given the patient -\ndoctor dialogue and a list of positive and negative entities .\n26\n27 Remove any entities that that not are medical entities , or any entities\nthat are unnecessary or completely irrelevant entities given the\ndialogue , positive entities , and negative entities .\n28\n29 If a similar entity is both present and unknown , or , both absent and\nunknown , keep it in the unknowns ONLY if this information is still\nunknown after the entire dialogue .\n30\n31 --- Dialogue ---\n32 Patient : { rfe }\n33 { dialogue }\n34 --- Dialogue ---\n35\n36 Positive Entities : { positive_entities }\n37\n38 Negative Entities : { negative_entities }\n39\n40 Unknown Entities : { unknown_entities }\n41 ---\n42 Cleaned Unknown Entities :\nPrompt 3: Prompt for resolving unknown entities.\n213\n1 Below is a medical encounter between a { age_and_sex } patient and a doctor\ndone over chat .\n2 The reason for the visit is: \"{ rfe }\".\n3 ----\n4 Medical Encounter #2\n5 ----\n6 Patient : { rfe }\n7 { dialogue }\n8 ----\n9 Below are the medical entities and their status extracted from the\npatient - doctor dialogue from medical encounter #2. These entities can\nbe used to help summarize the conversation below , but must be placed\nin the correct section ( Demographics and Social Determinants of Health\n, Patient Intent , Pertinent Positives , Pertinent Unknowns , Pertinent\nNegatives , Medical History ).\n10\n11 Positive Entities : { positive_entities }\n12\n13 Negative Entities : { negative_entities }\n14\n15 Unsure Entities : { unknown_entities }\n16 ----\n17 Summary Instructions\n18 ----\n19 Provide a summary of the medical encounter #2 between the doctor and the\n{ age_and_sex } patient in 6 sections ( Demographics and Social\nDeterminants of Health , Patient Intent , Pertinent Positives , Pertinent\nUnknowns , Pertinent Negatives , Medical History ).\n20\n21 Use the extracted entities to help summarize and place them in the\nappropriate section . Medical entities can be appropriate for any of\nthe 6 sections and should be presented in an organized fashion .\n22\n23 Add any important details from the dialogue to further explain , elaborate\n, or qualify a medical entity . If a medical entity is clinically\ninaccurate or completely irrelevant to the summary of the encounter ,\nthen do not summarize it.\n24\n25 The 6 sections to write the summary with are Demographics and Social\nDeterminants of Health , Patient Intent , Pertinent Positives , Pertinent\nUnknowns , Pertinent Negatives , and Medical History . The definitions\nof each section are listed below .\n26\n27 Demographics and Social Determinants of Health :\n28 // Definition of section\n29\n30 Patient Intent :\n31 // Definition of section\n32\n33 Pertinent Positives :\n34 // Definition of section\n35\n36 Pertinent Unknowns :\n37 // Definition of section\n38\n39 Pertinent Negatives :\n40 // Definition of section\n41\n42 Medical History :\n43 // Definition of section\n44\n45 ----\n46 Summary of Medical Encounter #2\n47 ----\nPrompt 4: Prompt for MEDSUM summarization.\n214\n1 Below is a medical encounter between a { age_and_sex } patient and a doctor\ndone over chat .\n2 The reason for the visit is: \"{ rfe }\".\n3 ----\n4 Medical Encounter\n5 ----\n6 Patient : { rfe }\n7 { dialogue }\n8 ----\n9 Summary Instructions\n10 ----\n11 Provide a summary of the medical encounter between the doctor and the {\nage_and_sex } patient in 6 sections ( Demographics and Social\nDeterminants of Health , Patient Intent , Pertinent Positives , Pertinent\nUnknowns , Pertinent Negatives , Medical History ).\n12\n13 Use the extracted entities to help summarize and place them in the\nappropriate section . Medical entities can be appropriate for any of\nthe 6 sections and should be presented in an organized fashion .\n14\n15 Add any important details from the dialogue to further explain , elaborate\n, or qualify a medical entity . If a medical entity is clinically\ninaccurate or completely irrelevant to the summary of the encounter ,\nthen do not summarize it.\n16\n17 The 6 sections to write the summary with are Demographics and Social\nDeterminants of Health , Patient Intent , Pertinent Positives , Pertinent\nUnknowns , Pertinent Negatives , and Medical History . The definitions\nof each section are listed below .\n18\n19 Demographics and Social Determinants of Health :\n20 // Definition of section\n21\n22 Patient Intent :\n23 // Definition of section\n24\n25 Pertinent Positives :\n26 // Definition of section\n27\n28 Pertinent Unknowns :\n29 // Definition of section\n30\n31 Pertinent Negatives :\n32 // Definition of section\n33\n34 Medical History :\n35 // Definition of section\n36\n37 ----\n38 Summary of Medical Encounter\n39 ----\nPrompt 5: Prompt for naive zero-shot single-prompt summarization.\n215\n1 Given the following snippet of a medical dialogue summary , extract the\nmedical concepts ( symptoms , diseases , conditions , allergies , lab tests\n, etc .) present .\n2\n3 The heading of the section from which the summary was extracted will also\nbe provided .\n4\n5 --- Example 1---\n6 Pertinent Negatives : Patient reports no <concept_1 >, no <concept_2 >, <\nconcept_3 >, and <concept_4 >. Patient also reports having no trouble\nwith <concept_5 >.\n7\n8 Medical Concepts : [< concept_1 >, <concept_2 >, <concept_3 >, <concept_4 >, <\nconcept_5 >]\n9 --- Example 1---\n10\n11 --- Example 2---\n12 Pertinent Positives : Patient ongoing <concept_1 > for the past 5 days , <\nconcept_2 >, and some <concept_3 >. Patient had <concept_4 > done in May\n2021.\n13\n14 Medical Concepts : [< concept_1 >, <concept_2 >, <concept_3 >, <concept_4 >]\n15 --- Example 2---\n16\n17 --- Example 3---\n18 Pertinent Unknowns : Patient is unsure about <concept_1 > and <concept_2 >.\n19\n20 Medical Concepts : [< concept_1 >, <concept_2 >]\n21 --- Example 3---\n22\n23 --- Example 4---\n24 Medical History : Patient reports some <concept_1 > in the past , and had\nlast <concept_2 > on DATE_1 .\n25\n26 Medical Concepts : [< concept_1 >, <concept_2 >]\n27 --- Example 4---\n28\n29 Here is the example to extract medical concepts from :\n30\n31 { section_heading }: { section_value }\n32\n33 Medical Concepts :\nPrompt 6: Prompt for extracting medical concepts in metric computation.\n216\n1 Given a snippet ( snippet ) from a medical dialogue summary and a\ncorresponding list ( list_a ) of medical concepts extracted from that\nsnippet , evaluate what medical concepts from a separate list ( list_b )\ncan be found in either list_a or snippet .\n2\n3 Note that on some occasions a medical concept from list_b may not be\nfound in list_a , but can be appropriate to be present given the\nsnippet . This could include rephrasings of medical concepts that are\nclinically equivalent (Ex: COVID and COVID -19) .\n4\n5 --- Example ---\n6 snippet : <snippet >\n7 list_a : [< concept_1 >, <concept_2 >, <concept_3 >, <concept_4 >, <concept_5 >,\n<concept_7 >]\n8 list_b : [< concept_0 >, <concept_1 >, <concept_3 >, <concept_4 >, <concept_5 >,\n<concept_6 >]\n9\n10 found_b : [< concept_1 >, <concept_3 >, <concept_4 >, <concept_5 >]\n11 not_found_b : [< concept_0 >, <concept_6 >]\n12\n13 --- Example ---\n14\n15 Here is the snippet , list_a . Evaluate the medical concepts in list_b as\nabove .\n16\n17 snippet : { snippet }\n18 list_a : { list_a }\n19 list_b : { list_b }\n20\n21 found_b :\nPrompt 7: Prompt for verifying concepts in metric computation.\n217",
  "topic": "Automatic summarization",
  "concepts": [
    {
      "name": "Automatic summarization",
      "score": 0.8999082446098328
    },
    {
      "name": "Conversation",
      "score": 0.7972415685653687
    },
    {
      "name": "Computer science",
      "score": 0.7965388298034668
    },
    {
      "name": "Correctness",
      "score": 0.7039787173271179
    },
    {
      "name": "Task (project management)",
      "score": 0.638200044631958
    },
    {
      "name": "Dialog box",
      "score": 0.6241201162338257
    },
    {
      "name": "Baseline (sea)",
      "score": 0.5993387699127197
    },
    {
      "name": "Natural language processing",
      "score": 0.5458285808563232
    },
    {
      "name": "Unified Medical Language System",
      "score": 0.5369259119033813
    },
    {
      "name": "Language model",
      "score": 0.483381450176239
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4694618284702301
    },
    {
      "name": "Health informatics",
      "score": 0.43584713339805603
    },
    {
      "name": "Information retrieval",
      "score": 0.3776576519012451
    },
    {
      "name": "Machine learning",
      "score": 0.34897029399871826
    },
    {
      "name": "Health care",
      "score": 0.285373330116272
    },
    {
      "name": "Programming language",
      "score": 0.10986155271530151
    },
    {
      "name": "World Wide Web",
      "score": 0.10659846663475037
    },
    {
      "name": "Economic growth",
      "score": 0.0
    },
    {
      "name": "Oceanography",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Geology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 7
}