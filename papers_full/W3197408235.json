{
  "title": "Improvement of Apraxia With Augmented Reality: Influencing Pantomime of Tool Use via Holographic Cues",
  "url": "https://openalex.org/W3197408235",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2343770704",
      "name": "Nina Rohrbach",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A2147967092",
      "name": "Carmen Krewer",
      "affiliations": [
        "Technical University of Munich",
        "Schön Klinik Bad Aibling"
      ]
    },
    {
      "id": "https://openalex.org/A3196364397",
      "name": "Lisa Löhnert",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3138288206",
      "name": "Annika Thierfelder",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A2584320587",
      "name": "Jennifer Randerath",
      "affiliations": [
        "University of Konstanz",
        "HTWG Hochschule Konstanz - Technik, Wirtschaft und Gestaltung"
      ]
    },
    {
      "id": "https://openalex.org/A2065551284",
      "name": "Klaus Jahn",
      "affiliations": [
        "Schön Klinik Bad Aibling",
        "Ludwig-Maximilians-Universität München"
      ]
    },
    {
      "id": "https://openalex.org/A503512879",
      "name": "Joachim Hermsdörfer",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2170553799",
    "https://openalex.org/W2128438723",
    "https://openalex.org/W2935729884",
    "https://openalex.org/W2791967747",
    "https://openalex.org/W2808967895",
    "https://openalex.org/W1204931866",
    "https://openalex.org/W2087918895",
    "https://openalex.org/W2011047221",
    "https://openalex.org/W1968316463",
    "https://openalex.org/W2028245358",
    "https://openalex.org/W2079719029",
    "https://openalex.org/W1991143829",
    "https://openalex.org/W2033526586",
    "https://openalex.org/W2017189920",
    "https://openalex.org/W2768729922",
    "https://openalex.org/W2791395623",
    "https://openalex.org/W2102645510",
    "https://openalex.org/W1978545366",
    "https://openalex.org/W2068119640",
    "https://openalex.org/W2954389627",
    "https://openalex.org/W1854329019",
    "https://openalex.org/W6635425622",
    "https://openalex.org/W2019137987",
    "https://openalex.org/W2955007002",
    "https://openalex.org/W2104439084",
    "https://openalex.org/W2158435382",
    "https://openalex.org/W2030907491",
    "https://openalex.org/W186622123",
    "https://openalex.org/W3042491354",
    "https://openalex.org/W2139889522",
    "https://openalex.org/W2030620644",
    "https://openalex.org/W2162558265",
    "https://openalex.org/W2899979558",
    "https://openalex.org/W2144764737",
    "https://openalex.org/W2102589009",
    "https://openalex.org/W1967519938",
    "https://openalex.org/W1847168837",
    "https://openalex.org/W2136022845",
    "https://openalex.org/W2119526403",
    "https://openalex.org/W2157507565",
    "https://openalex.org/W6601005035",
    "https://openalex.org/W3119110808",
    "https://openalex.org/W2045543438",
    "https://openalex.org/W6638532869",
    "https://openalex.org/W1988539867",
    "https://openalex.org/W2039870632",
    "https://openalex.org/W2141260237",
    "https://openalex.org/W2982300096",
    "https://openalex.org/W1989885404",
    "https://openalex.org/W2968373300",
    "https://openalex.org/W2052148080",
    "https://openalex.org/W3015661364",
    "https://openalex.org/W2472385446",
    "https://openalex.org/W2948073675",
    "https://openalex.org/W3004244623",
    "https://openalex.org/W2142226465",
    "https://openalex.org/W2148911474",
    "https://openalex.org/W2085710526",
    "https://openalex.org/W1965453711",
    "https://openalex.org/W2136228217",
    "https://openalex.org/W2009839959",
    "https://openalex.org/W2753456889",
    "https://openalex.org/W2946052718",
    "https://openalex.org/W2789892275",
    "https://openalex.org/W4231543308",
    "https://openalex.org/W3041922444",
    "https://openalex.org/W2624637168",
    "https://openalex.org/W1964143171",
    "https://openalex.org/W59811619",
    "https://openalex.org/W3082877515",
    "https://openalex.org/W2148080316",
    "https://openalex.org/W1593163947",
    "https://openalex.org/W2058161128",
    "https://openalex.org/W2149496207",
    "https://openalex.org/W1977086599",
    "https://openalex.org/W2795572236",
    "https://openalex.org/W24561379",
    "https://openalex.org/W4237064518",
    "https://openalex.org/W2167311298",
    "https://openalex.org/W2325117626",
    "https://openalex.org/W2962194874",
    "https://openalex.org/W2008854521"
  ],
  "abstract": "Background: Defective pantomime of tool use is a hall mark of limb apraxia. Contextual information has been demonstrated to improve tool use performance. Further, knowledge about the potential impact of technological aids such as augmented reality for patients with limb apraxia is still scarce. Objective: Since augmented reality offers a new way to provide contextual information, we applied it to pantomime of tool use. We hypothesize that the disturbed movement execution can be mitigated by holographic stimulation. If visual stimuli facilitate the access to the appropriate motor program in patients with apraxia, their performance should improve with increased saliency, i.e., should be better when supported by dynamic and holographic cues vs. static and screen-based cues. Methods: Twenty one stroke patients and 23 healthy control subjects were randomized to mime the use of five objects, presented in two Environments (Screen vs. Head Mounted Display, HMD) and two Modes (Static vs. Dynamic) resulting in four conditions (Screen Stat , Screen Dyn , HMD Stat , HMD Dyn ), followed by a real tool demonstration. Pantomiming was analyzed by a scoring system using video recordings. Additionally, the sense of presence was assessed using a questionnaire. Results: Healthy control participants performed close to ceiling and significantly better than patients. Patients achieved significantly higher scores with holographic or dynamic cues. Remarkably, when their performance was supported by animated holographic cues (e.g., striking hammer), it did not differ significantly from real tool demonstration. As the sense of presence increases with animated holograms, so does the pantomiming. Conclusion: Patients' performance improved with visual stimuli of increasing saliency. Future assistive technology could be implemented upon this knowledge and thus, positively impact the rehabilitation process and a patient's autonomy.",
  "full_text": "ORIGINAL RESEARCH\npublished: 26 August 2021\ndoi: 10.3389/fneur.2021.711900\nFrontiers in Neurology | www.frontiersin.org 1 August 2021 | Volume 12 | Article 711900\nEdited by:\nGiovanni Morone,\nSanta Lucia Foundation (IRCCS), Italy\nReviewed by:\nLong Qian,\nJohns Hopkins University,\nUnited States\nCarlo Cavaliere,\nInstitute of Research and Medical\nCare (IRCCS) SDN, Italy\nValentina Varalta,\nUniversity of Verona, Italy\n*Correspondence:\nNina Rohrbach\nnina.rohrbach@tum.de\nSpecialty section:\nThis article was submitted to\nNeurorehabilitation,\na section of the journal\nFrontiers in Neurology\nReceived: 19 May 2021\nAccepted: 02 August 2021\nPublished: 26 August 2021\nCitation:\nRohrbach N, Krewer C, Löhnert L,\nThierfelder A, Randerath J, Jahn K and\nHermsdörfer J (2021) Improvement of\nApraxia With Augmented Reality:\nInﬂuencing Pantomime of Tool Use via\nHolographic Cues.\nFront. Neurol. 12:711900.\ndoi: 10.3389/fneur.2021.711900\nImprovement of Apraxia With\nAugmented Reality: Inﬂuencing\nPantomime of Tool Use via\nHolographic Cues\nNina Rohrbach1*, Carmen Krewer1,2 , Lisa Löhnert1, Annika Thierfelder1,\nJennifer Randerath3, Klaus Jahn2,4 and Joachim Hermsdörfer1\n1 Technical University Munich, Chair of Human Movement Scien ce, Munich, Germany, 2 Schön Klinik Bad Aibling, Bad\nAibling, Germany, 3 Lurija Institute for Rehabilitation Sciences and Health Res earch at the University of Konstanz, Konstanz,\nGermany, 4 Ludwig-Maximilians University of Munich, University Hosp ital Grosshadern, Munich, Germany\nBackground: Defective pantomime of tool use is a hall mark of limb apraxia .\nContextual information has been demonstrated to improve to ol use performance. Further,\nknowledge about the potential impact of technological aids such as augmented reality\nfor patients with limb apraxia is still scarce.\nObjective: Since augmented reality offers a new way to provide contextu al information,\nwe applied it to pantomime of tool use. We hypothesize that th e disturbed movement\nexecution can be mitigated by holographic stimulation. If v isual stimuli facilitate the access\nto the appropriate motor program in patients with apraxia, t heir performance should\nimprove with increased saliency, i.e., should be better whe n supported by dynamic and\nholographic cues vs. static and screen-based cues.\nMethods: Twenty one stroke patients and 23 healthy control subjects w ere randomized\nto mime the use of ﬁve objects, presented in two Environments (Screen vs. Head\nMounted Display, HMD) and two Modes (Static vs. Dynamic) resulting in four conditions\n(ScreenStat, Screen Dyn, HMD Stat, HMD Dyn), followed by a real tool demonstration.\nPantomiming was analyzed by a scoring system using video rec ordings. Additionally,\nthe sense of presence was assessed using a questionnaire.\nResults: Healthy control participants performed close to ceiling an d signiﬁcantly better\nthan patients. Patients achieved signiﬁcantly higher scor es with holographic or dynamic\ncues. Remarkably, when their performance was supported by a nimated holographic cues\n(e.g., striking hammer), it did not differ signiﬁcantly fro m real tool demonstration. As the\nsense of presence increases with animated holograms, so doe s the pantomiming.\nConclusion: Patients’ performance improved with visual stimuli of incr easing saliency.\nFuture assistive technology could be implemented upon this knowledge and thus,\npositively impact the rehabilitation process and a patient ’s autonomy.\nKeywords: virtual reality, apraxia, pantomime of tool use, st roke, hologram, sense of presence, visual cues\nRohrbach et al. Apraxia Improvement With Augmented Reality\nINTRODUCTION\nApraxia occurs in 30–50% of patients after left brain damage\n(LBD) (\n1, 2) and frequently co-occurs with other syndromes,\nsuch as aphasia or neglect ( 3–6). Limb apraxia refers to a\nhigher-order motor disorder of learned purposive movement\nskills not caused by deﬁcits of elemental motor or sensory\nsystems (\n7) that may also aﬀect activities of daily living\n(ADL) ( 8, 9). Patients show impairments in planning or\nproducing motor actions. Typically, they have problems with\ngesture imitation, pantomimed tool use, and actual tool use\n(\n4, 10, 11). In the pantomime of tool use task patients\nare asked to produce an action without holding the object\nin their hand (\n12). Pantomiming requires both, motor-\ncognitive (e.g., the spatial conﬁguration of the body, hands\nand movements) and communicative processes, including the\nsimulative demonstration and integration of semantic and m otor\nfeatures of the underlying tool use action, requiring a heig htened\ndemand on the working memory processes (\n5, 10, 13, 14).\nPantomime of tool use is considered as very sensitive in dete cting\nthe presence of limb apraxia; typically the pantomime mode\nappears more sensitive as compared to actual tool use mode\n(\n3, 15), however performance measures across these modes\ncorrelate and individual patterns appear stable ( 16, 17). While\nboth modes may retrieve similar concepts, diﬀerences may be\nrepresented by missing visuotactile feedback, i.e., the abs ence of\nmechanical interaction and cues from real objects, the heig htened\ndemand on imagery and the translation from mental images to\nmotor execution (\n5, 10, 11, 16, 18, 19). Contextual information\nmay provide critical cues facilitating the access to an adequ ate\nmotor concept and may constrain the possibilities for action\nproduction (\n15–17). While tactile feedback alone, such as a stick\nthat resembles the handle of a tool, seems to be ineﬃcient in\nevoking the correct motor program of an action (\n20, 21), several\nstudies underlined the role of visual feedback ( 11, 17, 22). In\nthis regard, it has been shown that the perception of object\naﬀordances (i.e., action possibilities oﬀered by the environm ent\nand the object’s properties) and its visual attributes is inﬂu enced\nby its visuo-perceptual context, such as thematic and functio nal\nproperties but also by space (\n23).\nAugmented reality (AR) technology provides a unique\nway to study the contributions of visual information during\npantomiming and may help understand the underlying\nmechanisms of apraxia. This new technology allows\nmanipulating the experimental setting by providing diﬀerent\ncontextual information. In contrast to virtual reality, in which the\nuser is often immersed in a completely synthetic environment ,\nin AR the user’s real environment is not replaced but rather\nenriched by spatially aligned virtual objects (\n24). In mixed\nreality training scenarios, a higher sense of presence, deﬁn ed as\nthe psychological product of technological immersion ( 25), is\nsuggested to enhance motor performance ( 26–28). AR systems\nAbbreviations: ADL, Activities of Daily Living; AR, Augmented Reality; DILA-\nS, Diagnostic Instrument for Limb Apraxia – Short Version; Dyn, Dyn amic; EDI,\nEdinburgh Handedness Inventory; LBD, Left Brain Damage; MI, Mo tricity Index;\nMMSE, Mini Mental State Examination; NNPT, Nine Hole Peg Test; S tat, Static.\nare advantageous over virtual reality in providing a better s ense\nof presence and reality judgments because users can still see\ntheir body parts when interacting with virtual objects (\n29).\nThese virtual objects or holograms, herein referred to as the\nperception of a computer generated object through stereo\nimaging, can provide detailed visual contextual informatio n\nabout the properties of the object (e.g., size or structure) an d its\nfunctioning (e.g., a moving hologram showing its intention ) by\ncreating a realistic illusion in three dimensions (\n30). Practicing in\na salient environment by using meaningful and context-speci ﬁc\ncues is related to induced plasticity, increased motor learn ing\nand a transfer to other tasks ( 31). Saliency is a strong predictor\nof attention and gaze allocation and as such a crucial factor in\nmost everyday visual tasks and everyday functioning ( 32–34).\nWhile visual salience refers to objective attributes compar ed\nto its surroundings (e.g., object color and structure), sem antic\nsalience deﬁnes associations with an object (e.g., memorie s or\npersonal importance) and depends on the user ( 35). We suggest\nholograms to function as cues with high visual and semantic\nsalience, which might support motor actions in patients with\napraxia. This is in line with the most recent concept of “action\nreappraisal” by Federico and Brandimonte (\n23), a reasoning-\nbased approach in human tool-use processing, suggesting that\ntool use actions utilize multiple sources of information, inc luding\naﬀordances and contextual conditions.\nThe main objective of this study was to test the hypothesis\nthat the disturbed movement execution in stroke patients wit h\napraxia can be mitigated by AR stimulation during pantomime\ntasks. If visual stimuli facilitate the access to the appropria te\nmotor program in patients with apraxia, the performance should\nimprove with cues of higher saliency and more contextual\ninformation. Speciﬁcally, we consider dynamic holographic to ols\npresented through a Head Mounted Display (HMD) as stimuli\nwith higher salience because the moving character on the one\nside and the holographic nature (i.e., three-dimensionality )\non the other side should attract more attention than two-\ndimensional static images of a tool, enhancing the perception\nof the object in this way (\n33, 36). The enriched contextual\nenvironment (e.g., detailed object features such as struct ure)\nand the overall realism that is conveyed by these properties\nshould provide more cognitive cues (\n37). Further, little is\nknown yet as to the impact of the induced sense of presence\nin virtual environments on motor performance in stroke\nrehabilitation (\n26). We suggested the enriched conditions to\nevoke higher presence, and expected to observe an association\nbetween increased presence and pantomime performance. A\nbetter understanding of the technological properties (e.g., visual\nsaliency) and user attributes (e.g., presence) that contrib ute to\nmotor performances in augmented environments may further\ninform decisions about their use in overall stroke rehabilit ation.\nMETHODS\nParticipants\nThis study was conducted at the neurorehabilitation hospita l\nSchoen Clinic Bad Aibling (Germany). From April 2019 to\nDecember 2019, we included a total of 49 participants (25 patien ts\nFrontiers in Neurology | www.frontiersin.org 2 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nFIGURE 1 | Patients’ ﬂow through the study. All participants had to perf orm the pantomime task twice (Static/Dynamic) in each Enviro nment (HMD/Screen), followed\nby the real tool condition. The washout time was set to >24 h and did not include any additional tasks. Three particip ants only completed Day 1 and were excluded\nfrom further analyses.\nwith LBD and 24 healthy age-matched control persons) who\nfulﬁlled the eligibility criteria: (1) stroke in the left he misphere\nwith signs of apraxia (or no stroke in controls), (2) normal\nor corrected-to-normal vision, (3) suﬃcient cognitive abi lity to\nunderstand and follow task instructions (tested prior to the\nstudy), (4) no other neurological, psychiatric diseases or po or\ngeneral condition aﬀecting testing (i.e., the patient had to b e\nable to sit for the duration of the experiment). Healthy contr ol\nparticipants were recruited via poster announcements distrib uted\nin the clinic and University and self-registration. The sample size\nwas based on an estimate on earlier studies comparing diﬀerent\nexecution conditions for similar actions, in which signiﬁc ant\neﬀects were found in comparable samples ( n = 23 per group)\n(\n15, 17). The study was approved by the Ethics Committee of\nthe Medical Faculty of the Technical University of Munich and\nall participants or their legal representatives provided writt en\ninformed consent prior to testing, which was performed in\naccordance to the declaration of Helsinki. The protocol was\nprospectively registered with the German Clinical Trials Regis ter\n(DRKS) on 22 September 2018 (TrialID = DRKS00015464,\nUniversal Trial Number = U1111-1220-6410).\nTrial Design\nWithin this randomized crossover study, we tested the inﬂue nce\nof varying types of visual stimuli with diﬀerent degrees of sal iency\nto determine the most eﬀective way of support. Participants\nhad to mime the use of ﬁve common objects (hammer, ﬂat-\niron, watering can, key, electric bulb) with variable combi nations\nof visual input. On the 1st day, they were randomized 1:1 via\nsealed envelopes to begin with one of the testing Environments\n(Screen vs. HMD), of which each testing environment was\nrandomized 1:1 to start with one of the testing Modes (Static\nvs. Dynamic). After a 24 h “washout” period, the same task was\nperformed starting with the other testing environment, endi ng\nup with four diﬀerent combinations : Screen Stat, Screen Dyn,\nHMDStat, HMD Dyn (Figure 1). Each object was presented four\ntimes in a row whereas the ﬁrst presentation was designed\nas a familiarization where no action was required, to ensure\nthat participants were able to see the images and minimize\nan inﬂuence of visuo-spatial deﬁcits. The order of object\npresentation was balanced for these four combinations, and\nheld constant for both testing days (i.e., one out of ﬁve\npredeﬁned sequences of object presentations was assigned to\neach participant). In the screen environment, participants wer e\nsupported by images of the objects presented on a laptop monitor\n(15.6-inch, 1,920 x 1,080-pixel resolution), whereby the vi ewing\ndistance was held constant among all participants (i.e., in a\nreachable zone of 70 cm when leaning forwards). In the HMD\nenvironment, participants wore the Microsoft HoloLens device\n(1st generation) to view holographic images. In the dynamic\nmode, one could see the individual tool moving (e.g., striki ng\nhammer) while in the static mode the tool remained still (see\nSupplementary Videos 2 , 3). At the end of day 2 after all four\nconditions were completed, participants had to demonstrate the\nuse of the real tool (in the absence of the target object) that\nwas placed on the table in a standardized way (i.e., the tools\nwere aligned in accordance with the other testing environme nts,\ni.e., oriented to promote an action with the left hand as shown\nin Figure 2D), not accompanied by any additional visual input\n(“Real Tool” condition).\nParticipants were seated in front of a table, either facing\nthe screen or wearing the HMD ( Figure 2). To familiarize\nwith the HMD a practice holographic object, i.e., a red\npaper boat (see Supplementary Video 1 ), was presented\naccompanied by a standardized explanation of its main technic al\nfeature and current limitation of a limited ﬁeld of view in\nHoloLens (1st generation). Practice items were included at\nthe beginning of each day by showing printed objects to the\nparticipants (fork—corkscrew—saw), and task comprehension\nwas assumed when participants at least attempted to produce\na meaningful movement, based on the DILA-S pantomime\ntask recommendations (\n13). In all conditions participants were\nFrontiers in Neurology | www.frontiersin.org 3 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nFIGURE 2 | Third person perspective of the experimental setup. (A) Screen condition, (B) HMD condition, (C) Real Tool condition; and (D) the ﬁrst-person perspective\nof the ﬁve objects depicted as screen-based images. Only the t ools and not the target items were shown (i.e., the hammer, bu t not a nail).\nverbally instructed by the experimenter (e.g. “please show me\nhow to pound in a nail with a hammer”) as described in (\n13) and\nwere allowed to start miming as soon as the picture of the objec t\nbecame visible. Their movements were videotaped for later\nobservational evaluation. They used their left hand (non-pa retic)\nin all conditions and were tested on consecutive days to redu ce\ncarryover eﬀects and fatigue, on about the same time of the day ,\nlasting a maximum of 1 h/day. For patients who still fatigued\nvery fast, the additional clinical testing was postponed to a 3 rd\nday. During testing participants were asked for any discomfor t\nor motion sickness. Neither participants nor examiners were\nblinded due to the optical see-through device being used.\nSoftware Development\nThe testing environments were designed using the game engin e\ndevelopment tool, Unity 3D (Version 2017.4). The ﬁve objects\nwere created by 3D-scanning their real-life counterparts in order\nto achieve high visual ﬁdelity. Object selection was based o n\nits movement characteristics to cover a variety of diﬀerent\nmovement components, movement planes and grip formations\n(e.g., repetitive hammering with elbow ﬂexion/extension us ing\na cylindrical grip in the longitudinal plane). Three of the ﬁv e\ngestures involved non-repetitive movements (water a plant, i ron\na blouse, open a lock), while the other two were repetitive\ngestures (screw in an electric bulb, hammer a nail). For\nthis study we chose gestures performed without body contact\nbecause of the complexity of holographic animations performed\non the body. Only the tools and not their corresponding\ncounterpart were shown (i.e., the hammer, but not a nail, see\nFigure 2D). The dynamic version is based on recordings of real\ntool use movements with the same physical objects (including\nthe recipient object) using motion capturing (Qualisys Inc.,\nGothenburg, Sweden). The gathered kinematic data were post-\nprocessed to handle noise. In the screen environment, the obj ects\nhad to be adjusted in size in order to be properly displayed on\nthe screen. In the HMD environment, we adjusted the objects’\nposition in space to maintain the objects’ real sizes. Further , the\nobjects were oriented in space in a way that the tools’ handle\nfunctioned as an easy to graspable stimulus (\n38). The full project\ncode is available at GitHub https://github.com/Ninarohrbac h/\npanto-holo, and a visualization of the object presentations c an\nbe found in the supplements ( Supplementary Videos 2 , 3).\nRemote Control System\nGenerally interacting with the HoloLens device as an\nexperimenter is inconvenient, because one would need to\nput on the device for each single interaction. We solved this\nproblem by using a web application to remotely control the\nHoloLens application (see Supplementary Video 1 ). The\nadvantage of a web application is that it can be run on almost any\ndevice that has a web browser, e.g., smartphones. The complete\nsystem consisted of three components: The web application,\na webserver and the HoloLens application. The HoloLens\napplication was implemented using Unity 2017.4 using C ++.\nA Firebase application was used as a web server and Polymer\n2.0 was used for the front-end of the web application. This way,\nthe experimenter could easily change the values (i.e., objec t\n1–5, and mode “static”/“dynamic”) on the Firebase server in\nreal-time. The same system was used for the screen environmen t,\nby running the Unity application on a laptop.\nClinical Tests and Questionnaires\nPrior testing, participants were asked questions regarding t heir\nsociodemographic background and previous HMD experience.\nThe Mini Mental State Examination (MMSE) (\n39) was conducted\nFrontiers in Neurology | www.frontiersin.org 4 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nto assess cognitive impairment. The Titmus Test (Stereo Optic al\nCo., Chicago, IL) with its two sub-tests was administered to\nclassify for the presence (i.e., House Fly test) and the qualit y\nof stereovision (i.e., Circles test). The Edinburgh Handed ness\nInventory (EDI) (\n40) was used to assess the dominance of a\nperson’s hand in everyday activities before the stroke. To ev aluate\nmanual dexterity, we conducted the Nine Hole Peg Test (NHPT)\n(\n41). For this purpose, the left (non-paretic) hand was tested\ntwice using motion capture analysis and the mean time of two\nsuccessful trials was computed (see “hand kinematics” in dat a\nanalysis). Further, we examined the Motricity Index (MI) to\nevaluate the extent of the paralysis of the aﬀected arm by asses sing\nthe strength (remaining force) of shoulder abduction, elbo w\nﬂexion and ﬁnger griping (\n42). To diagnose for the presence\nof apraxia the Diagnostic Instrument for Limb Apraxia—Short\nVersion (DILA-S) was used (\n13). Note, that the DILA-S was\nevaluated for patients with LBD and is applicable for patients\nwith severe aphasia or neglect. At the end of each testing\ncondition (i.e., four times), participants completed a slightl y\nadapted presence questionnaire (\n43) (Supplementary Table 1).\nDATA ANALYSIS\nScoring System\nSupplementary Table 2 provides details on the scoring\nprocedure. As the primary outcome parameter, a performance\nscoring was undertaken. For task evaluation we adapted the\nProduction scale (PS) (\n13) in which four movement components\nwere rated on a three-point scale resulting in a maximum score of\n24 points per object and condition after three trials. Additio nally,\nwe applied the Interaction scale (IS) developed for the purpose\nof this study to investigate the participants’ interaction wi th\nthe diﬀerent cues. With the standard pantomime procedure in\nclinical settings the examiner sometimes observes patients who\nseemingly try to interact with the presented item by reaching\nfor and touching the depicted picture. One point per trial was\ngiven if participants actively tried to reach forward and gras p\nthe virtual object or followed the movement, ending up with a\nmaximum of three points per object and condition after three\ntrials. Note that our experimental task and digital content d o not\nrequire any interaction. Thus, the term “interaction” with in this\nstudy does not reﬂect the overall accepted deﬁnition in the AR\ndomain [for a recent review on immersive systems (\n44)].\nEach participant’s videotaped performance was viewed in its\nfull length four times, once for each of the four movement part s.\nTwo independent raters (NR, LL) scored the ﬁrst 20 participants\n(10 patients, 10 controls) and critical aspects were discusse d\nwithin the research team in a consensus meeting. Validating\na certain percentage of the study sample by two independent\nevaluators is common and widely accepted practice e.g., 25% in\n(\n18) and (45). The inter-rater reliability of the pantomime scoring\n(400 data points for the Production and Interaction scale) an d\nreal tool scoring (50 data points) of the ﬁrst ten healthy cont rol\nsubjects achieved large results for pantomiming (Kendall’s Tau\nτ = 0.643 for Production; τ = 0.602 for Interaction) and real\ntool demo ( τ = 0.862). After further reﬁnement of the system, all\ndata were scored and uncertainties were collaboratively di scussed\nuntil the two raters met consensus.\nStatistical Analysis\nAll outcome variables were tested for normal distribution usi ng\nShapiro-Wilk’s test. The statistical analysis included a t-test for\nage and non-parametric tests for sex, stereovision, MMSE and\nNHPT-time to determine if there were diﬀerences between the\npatient and the control group. For the pantomime performance\n(averaged score across all ﬁve objects for each of the four\nconditions) and the subjective experience of the presented ob jects\n(calculated mean score of presence data for each of the four\nconditions) a mixed repeated measures 2 × 2 × 2 ANOV A was\nconducted to determine whether any changes in the dependent\nvariables (Production Scale, Interaction Scale) were caus ed by\nthe between-subject factor Group (Stroke, Control), the within-\nsubject factors Environment (Screen, HMD) and Mode (Static,\nDynamic), or their interactions. We dealt with missing value s\n(Production: 2.06%, Interaction: 2.14%) by imputing the mean\nperformance value for the respective object and condition (\n46).\nSigniﬁcant interactions, simple eﬀects and main eﬀects were\nfollowed-up with Bonferroni-adjusted pairwise post-hoc tests\ncomparing the performance scores of the diﬀerent visual cues.\nThe achieved real tool scores were compared separately betwee n\ngroups using independent t-tests. They were further analyzed\nwithin each group, by comparing them with the means of\nthe four combinations of the pantomime task using t-tests for\npaired samples. We calculated the performance eﬀects, i.e., the\nenvironmental (HMD-Eﬀect), the conditional (DYN-Eﬀect) and\nthe combined eﬀect (HOLO-Eﬀect) for both scales, deﬁned as\nthe following:\n• HMD-Eﬀect = Mean (HMD Stat, HMD Dyn) – Mean\n(ScreenStat, Screen Dyn)\n• DYN-Eﬀect = Mean (HMDDyn, ScreenDyn) – Mean (HMD Stat,\nScreen Stat)\n• HOLO-Eﬀect = Mean HMD Dyn – Mean (Screen Stat,\nScreenDyn, HMD Stat)\nWe assessed the relationship of the Production and Interact ion\nscores within each group using Spearman’s rank correlation ( rs).\nFurther, the performance eﬀects were correlated with the clini cal\ndata to test whether the timing of stroke onset, mental capacit y,\nmanual dexterity, stereovision or apraxia aﬀect pantomime\nof tool use using Pearson’s r or Spearman’s correlation. The\nrelationship between presence and pantomiming was analyzed\nfor each condition within the patient group. For signiﬁcant\ncorrelations, the magnitude was classiﬁed considering the\nfollowing categories: | r| ≥ 0.10 = small, | r| ≥ 0.30 = medium\nand |r| ≥ 0.50 = large (\n47). Data analysis was carried out in SPSS\n(version 26), and the level of signiﬁcance was established a t a 0.05\nalpha-level (two-sided).\nHand Kinematics\nIn addition, we recorded hand movements (a spherical marker\nattached to the subject’s left back of the hand) using motion\ncapturing. Movements were recorded by three cameras (Oquus,\nQualisys Inc., Gothenborg, Sweden) and a sample rate of 120 Hz .\nFrontiers in Neurology | www.frontiersin.org 5 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nFIGURE 3 | Trajectories of hand movements in patient P13 attempting to pantomime the typical use of a hammer during the different ex perimental conditions is\nillustrated: Screen Stat (blue line), Screen Dyn (blue dotted line), HMD Stat (red line), HMD Dyn (red dotted line), real tool (gray line). The complete traje ctory along the z-Axis\nin (mm) during the third of three trials is always shown.\nTABLE 1 | Participant’s demographics and clinical characteristics .\nLBD ( N = 21) Controls ( N = 23) Between-Group Comparisons\nSex: male/female 10/11 10/13 t (42) = − 0.988, p = 0.329\nAge: mean years (range)\nAdverse events, side effects*: yes/no\n69.81 (41–91)\n0/21\n65.87 (40–91)\n0/23\nU = 231.5, Z = − 0.272, p = 1.0\nEDI: right/left/both 20/0/1 23/0/0\nEducation level**: low/middle/high 8/8/4 6/7/10\nExperience with HMD: yes/no 0/21 0/23\nEtiology: Ischemic infarct/ICB 18/3 NA\nAphasia***: yes/no 15/6 NA\nMMSE: mean (range) 21.25 (14–28), N = 16 28.83 (24–30) U = 8.500, Z = 34.6, p < 0.001\nMI: mean (range) 52.6 (0–100) NA\nNeglect****: yes/no 6/15 NA\nNHPT: mean time in seconds (range) 47 (26–140) 24.5 (18.5–44 ) U = 445.00, Z = 42.5, p < 0.001\nTitmus Test\nHouse Fly: stereovision given (yes/no) 13/6 23/0 U = 138.0, Z = − 3.151, p = 0.002\nCircles: ≤/> 100 arc/sec 2/16 17/6 U = 77.0, Z = − 3.953, p < 0.001\nTime since event: mean duration in days (range) 250,7 (11–1, 933) NA\nVisual aids during testing: yes/no 12/9 21/3\nEDI, Edinburgh Hand Inventory; HMD, Head Mounted Display; ICB, Intracr anial bleeding; LBD, Left Brain Damage; MMSE, Mini Mental State Examination; MI, Motricity Index; NA,\nNot applicable; NHPT, Nine Hole Peg Test (left hand); t, t test for inde pendent samples; U, Mann-Whitney-U-Test, * based on verbal reports, ** Education level: low = secondary\nschool, middle = intermediate school =, high = high school or higher, ***based on Aachen Aphasia Test (AAT) analysis description, i.e., a combinati on of the subscales Token Test\nand written language, **** based on different severity levels assessed with different asses sments; information provided by neuropsychologists out of a test battery including several\npaper-pencil tests.\nThe kinematic approach served as an objective and sensitive\nanalysis to evaluate the NHPT data and to provide an additiona l\nvisual illustration to our qualitative ﬁndings. Based on th e\nperformance results, the patient with the strongest HOLO-Eﬀec t\n(see statistical analysis for further speciﬁcation) was chos en for\nfurther kinematic analysis. Post-processing of the hammering\nFrontiers in Neurology | www.frontiersin.org 6 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nperformance (repetitive up and down movement) of P13 was\nperformed using MATLAB R2018b (MathWorks, Natick, MA,\nUSA). We determined the starting and the ending time points\nby calculating the overall marker velocity in 3D space and\nthresholding it at v th = 0.012 [m/s]. The vertical axis of the\nmovement was extracted and plotted for visualization ( Figure 3).\nRESULTS\nParticipant Demographics\nParticipant characteristics and patient-speciﬁc informatio n are\nprovided in Tables 1, 2. All but one patient (P23) showed\nsigns of apraxia in at least one of the DILA-S sub-tests\n(Supplementary Table 3), with most patients being aﬀected\nin the Imitation of gestures (meaningless: 95%, meaningful:\n67%), in the Pantomime task (Production: 76%, Execution:\n71%) and in the Naturalistic Action Task (NAT: 62%). While\nthe majority of patients had at least mild problems in the\nFamiliar Tools Task (FTT; Selection: 33%, Production: 67%,\nExecution: 62%) they were less frequently aﬀected in the\nNovel Tools Task (NTT; Selection: 52%, Production: 29%,\nExecution: 29%).\nPerformance Results\nFigure 4 displays the performance scores of both groups of\nthe Production and Interaction scales, and Table 3 shows\nthe ANOV A results respectively. The individually achieved\nenvironmental (HMD-Eﬀect), modal (DYN-Eﬀect) and\ncombined (HOLO-Eﬀect) eﬀects in patients are visualized\nin Figure 5. During HMD trials, the key was not visible for\nthree patients (P1&P6: Key_HMD Stat, P1&P16: Key_HMD Dyn),\nand in another patient (P21) the Screen Stat condition was not\nvideotaped. Overall, we had a total of 26 missing data points ou t\nof 1,260 observations on the Production scale (2.06%) and 9 ou t\nof 420 on the Interaction scale (2.14%), respectively.\nProduction Scores\nOn the Production scale, a signiﬁcant main eﬀect of Group\nwith overall higher scores in controls ( Figure 4A) indicates\nthat healthy subjects performed signiﬁcantly better than pat ients\n(MD = 6.5; 95%-CI [4.1,8.9], p < 0.001). Further, we found\nsigniﬁcant main eﬀects of Environment, Mode and signiﬁcant\ninteractions between Environment × Group, Mode× Group, and\nEnvironment × Mode × Group, but not between Environment ×\nMode (Table 3).\nNext, we analyzed the diﬀerent combinations within each\ngroup separately. Control participants reached almost maximu m\nscores independent of the presented stimuli ( M = 23.2, SD\n= 0.64 [21.4,23.9] with no signiﬁcant eﬀects or interactions ( p\n> 0.144). In patients, we found a statistically signiﬁcant eﬀec t\nof Environment and of Mode, but not between Environment\n× Mode. Bonferroni-adjusted pairwise comparisons indicate a\nbetter performance with the help of holographic ( −1.2; 95%-\nCI [ −2.1,−0.19], p = 0.021) or dynamic cues ( −0.91; 95%-CI\n[−1.7,−0.16], p = 0.019).\nInteraction Scores\nWe found a signiﬁcant main eﬀect of Group on the Interaction\nscale, suggesting that healthy subjects interacted signiﬁ cantly\nmore with the presented stimuli (0.48; 95%-CI [0.10,0.86], p =\n0.014; Figure 4C). Similar to the Production scores, we found\nsigniﬁcant main eﬀects of Environment and of Mode, and a\nsigniﬁcant Environment × Group interaction which was driven\nby higher means in the HMD Environment in controls (Screen:\n0.30; 95%-CI [0.13,0.47], HMD: 1.9; 95%-CI [1.4,2.4] compared\nto patients (Screen: 0.21; 95%-CI [0.11,0.32]; HMD: 1.0; 95%-CI\n[0.56,1.4]. All remaining interactions were non-signiﬁca nt ( p >\n0.518, Table 3).\nIn both groups, there was a signiﬁcant eﬀect of Environment,\nsuggesting stronger eﬀects of holographic than screen-based cues\n(Patients: −0.79; 95%-CI [ −1.2,−0.39], p < 0.001; Controls:\n−1.6; 95%-CI [ −2.1,−1.1], p < 0.001). A signiﬁcant eﬀect of\nMode in patients and a borderline signiﬁcant eﬀect of Mode in\ncontrols (p = 0.054) point toward a higher eﬀect of dynamic than\nstatic cues (Patients: −0.24; 95%-CI [ −0.38,−0.11], p = 0.001;\nControls: −0.27; 95%-CI [ −0.54,0.005], p = 0.054).\nCorrelations Between Production and\nInteraction Scores\nWe found medium to large signiﬁcant correlations between\nthe Production and Interaction scores. In patients, higher\ninteractions with animated screen-based objects were\nsigniﬁcantly associated with a better performance (Screen Dyn rs\n= 0.699, p < 0.001). In controls by contrast, when the interaction\nwith static holographic items increased, the performance\ndecreased (HMD Stat rs = − 0.537, p = 0.008). All other\ncorrelations were non-signiﬁcant ( Supplementary Table 4).\nReal Tool Comparison\nPatients had signiﬁcant problems demonstrating the real tool\nuse ( M = 18.3, SD = 3.9) compared to controls [ M = 23, SD\n= 0.74, t(42) = 5.7, p < 0.001]. In healthy subjects, all pairwise\ncomparisons were non-signiﬁcant ( p > 0.208). In patients, there\nwas a signiﬁcant diﬀerence between real tool use ( M = 18.3, SD =\n3.9) and the Production scores achieved in Screen Stat [M = 15.9,\nSD = 5.8, t(20) = 3.7, p = 0.001], ScreenDyn [M = 16.3, SD = 6.0,\nt(20) = 3.0, p = 0.007], and HMD Stat environments [M = 16.5, SD\n= 6.6, t(20) = 2.4, p = 0.027]. In contrast, there was no diﬀerence\nbetween real tool use and the Production scores observed in t he\nHMDDyn environment [ M = 17.9, SD = 5.6, t(20) = 0.75, p =\n0.461), suggesting that the performance was best when either\nreceiving dynamic holographic cues or when demonstrating rea l\ntool use ( Figure 4).\nCorrelations Between Clinical Data and\nPantomime Performance Effects\nOn the Production scale, a higher DYN-Eﬀect was associated\nwith a higher Circles score (r s = 0.524, p = 0.026), a higher NHPT\ntime (r s = − 0.695, p < 0.001), and a lower NTT Selection score\n(rs = −0.498, p = 0.021). On the Interaction scale, a lower DYN-\nEﬀect goes along with a lower MMSE score (r = 0.550, p = 0.027),\nand with worse performances in object-interaction tasks (FT T\nProduction r s = 0.510, p = 0.018; NAT r s = 0.546, p = 0.013).\nFrontiers in Neurology | www.frontiersin.org 7 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nTABLE 2 | Patient’s characteristics.\nID Sex EDI Age (y) ICD-10 Etiology Stage* Neglect Aphasia MI N HPT (t) Stereovision MMSE\nP01 M right 64 I61.2 ICB sub-acute no Yes 76 42,44 intact NA\nP02 M right 51 I61.0 ICB sub-acute yes Yes 11 27,77 NA 19\nP03 F right 85 I63.4 Infarct sub-acute no Yes 77 30,51 NA 25\nP04 F right 71 I63.5 Infarct sub-acute no Yes 0 26,18 intact 21\nP05 M right 41 I63.3 Infarct chronic no Yes 0 28,89 impaired NA\nP06 F right 89 I63.4 Infarct sub-acute no Yes 0 58,38 impaired NA\nP07 M right 64 I63.4 Infarct sub-acute no Yes 66 30,18 intact 23\nP08 M right 69 I63.2 Infarct sub-acute no Yes 100 81,78 intact 24\nP09 M right 80 G82.29 Infarct sub-acute no No 76 39,50 intact 24\nP10 F right 90 I63.4 Infarct sub-acute no No 88 42,12 impaired 17\nP11 M both 74 I63.4 Infarct sub-acute no Yes 77 39,04 intact 19\nP13 F right 61 I63.4 Infarct chronic yes Yes 78 139,66 impaired N A\nP14 F right 54 I63.0 Infarct sub-acute yes No 39 59,01 impaired 2 6\nP16 F right 85 I.63.4 Infarct chronic no Yes 0 61,05 intact NA\nP17 M right 83 I.63.1 Infarct sub-acute no Yes 100 42,78 intact 1 4\nP18 F right 72 I63.0 infarct sub-acute no No 0 25,94 intact 19\nP19 M right 65 I63.4 Infarct sub-acute yes Yes 100 68,68 impaire d 16\nP20 M right 56 I61.1 ICB sub-acute no Yes 83 28,79 intact 28\nP21 F right 91 I63.5 Infarct chronic no No 100 37,87 intact 21\nP22 F right 79 I67.88 Infarct sub-acute yes Yes 34 52,03 intact 2 5\nP23 F right 42 I63.5 Infarct chronic yes No 0 26,62 intact 19\nDue to communication problems, not all patients could be tested for stereov ision and cognition, but comprehension was sufﬁcient to follow task instruc tions and all patients were able\nto complete the AR-testing.\nEDI, Edinburgh Hand Inventory; F, Female; ICB, Intracranial bleedin g; ICD-10, International Classiﬁcation of Diseases-Tenth Revision; M, Ma le; MMSE, Mini Mental State Examination;\nMI, Motricity Index; NA, Not applicable; NHPT(t), Nine Hole Peg Test (ti me in seconds, with left hand). *Stage: Sub-acute= <6 months, chronic: >6 months.\nFIGURE 4 | (A,B) Results of the pantomime performance of the control group (l eft) and stroke group (right); Mean and 95% conﬁdence interva l values for the\ninteractions of Environment (HMD/Screen) and Mode (static/d ynamic) in (A) Production scale and (B) Interaction scale are reported.\nFurther, a non-signiﬁcant trend between stereovision and t he\nHOLO-EﬀectIS points toward more frequent interactions with\nanimated holographic items when a higher quality in stereovis ion\nis given (r s = 0.449, p = 0.061). All other correlations between\nany of the calculated eﬀects and the clinical tests failed to\nreveal statistical signiﬁcance. See Supplementary Tables 5, 6 for\ncorrelations with clinical data and DILA-S results.\nKinematic Analysis\nKinematic analyses were run in order to visualize the qualita tive\nﬁndings. Figure 3 exemplarily depicts the kinematic analysis\nfor patient 13 who experienced the strongest “HOLO-Eﬀect”\nbased on the results of the performance scoring ( Figure 5).\nThe complete trajectory along the z-Axis in (mm) of the\nmost successful version of each condition is always shown\nFrontiers in Neurology | www.frontiersin.org 8 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nTABLE 3 | ANOVA summary for production scale, interaction scale and s ense of presence.\nProduction Scale Statistical parameters\nF(df) p Effect size η 2\npGroup F(1, 42) = 28.6 <0.001 0.405\nEnvironment F(1, 42) = 4.9 0.031 0.106\nMode F(1, 42) = 6.2 0.017 0.129\nGroup × Environment F (1, 42) = 8.2 0.007 0.163\nGroup × Mode F (1, 42) = 6.8 0.012 0.140\nEnvironment × Mode F (1, 42) = 1.7 0.203 0.038\nGroup × Environment × Mode F (1, 42) = 4.5 0.039 0.097\nHealthy subjects Patients\nF(df) p Effect size η 2\np F(df) p Effect size η 2\np\nEnvironment F (1, 22) = 1.9 0.176 0.082 F(1, 20) = 6.2 0.021 0.238\nMode F (1, 22) = 0.05 0.826 0.002 F(1, 20) = 6.5 0.019 0.244\nEnvironment × Mode F (1, 22) = 2.3 0.144 0.095 F(1, 20) = 2.9 0.103 0.127\nInteraction Scale\nF(df) p Effect size η 2\npGroup F(1, 42) = 6.5 0.014 0.135\nEnvironment F(1, 42) = 55.8 <0.001 0.570\nMode F(1, 42) = 11.3 0.002 0.213\nGroup × Environment F (1, 42) = 6.1 0.017 0.127\nGroup × Mode F (1, 42) = 0.03 0.862 0.518\nEnvironment × Mode F (1, 42) = 0.43 0.518 0.010\nGroup × Environment × Mode F (1, 42) = 0.01 0.932 0.000\nHealthy subjects Patients\nF(df) p Effect size η 2\np F(df) p Effect size η 2\np\nEnvironment F (1, 22) = 39.9 <0.001 0.645 F(1, 20) = 17.7 <0.001 0.470\nMode F (1, 22) = 4.16 0.052 0.159 F(1, 20) = 13.5 0.001 0.403\nEnvironment × Mode F (1, 22) = 0.20 0.657 0.009 F(1, 20) = 0.277 0.605 0.014\nSENSE OF PRESENCE*\nF(df) p Effect size η 2\npGroup F(1, 34) = 0.120 0.731 0.004\nEnvironment F(1, 34) = 27.9 <0.001 0.450\nMode F(1, 34) = 0.28 0.601 0.008\nGroup × Environment F (1, 34) = 5.5 0.025 0.139\nGroup × Mode F (1, 34) = 0.48 0.494 0.014\nEnvironment × Mode F (1, 34) = 0.02 0.886 0.001\nGroup × Environment × Mode F (1, 34) = 0.27 0.605 0.008\n*A few participants did not answer Q3 (HMD Stat: C8, C9, P20; HMD Dyn: C9, P20), herein, we imputed the mean within each group. Eight patients did not or only partially ﬁll in the\npresence questionnaire (P4, P6, P10, P12, P13, P14, P15, P16), thus, we included 36 data sets in the mrANOVA (Controls n = 23, Patients n = 13).\n(here, the third of the three trials, respectively). In real to ol\ndemonstration she failed during the ﬁrst (Production: 0 poin ts)\nand second attempt (Production: two points for grip formation\nwhen grasping the hammer), but she managed to perform a nice\nhammering movement (Production: seven points, −1 because of\na distorted movement orientation) after some hesitation in her\nlast trial (“conduite d’approche, ” after all it still took her 1 0 s to\ninitiate the action). All her attempts to pantomime hammering\nFrontiers in Neurology | www.frontiersin.org 9 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nFIGURE 5 | Conditional (DYN), environmental (HMD) and combined (HOLO ) effects of individual patients displayed in (A) Production Scale and (B) Interaction Scale.\nin Screen Stat, Screen Dyn, and HMD Stat were characterized by\n“toying” (Production: zero points in all conditions, respect ively).\nIn the HMD Dyn condition by contrast, she presented clear\nup- and downwards hits with the support of the animated\nholographic hammer during her second and third attempts\n(Production: seven points in both attempts; −1 because of\ndistorted grip formation). Note, P13 was randomized to rece ive\nHMD-based cues ﬁrst, followed by screen-based cues on day\n2. The corresponding video can be found in the supplements\n(Supplementary Video 4 ). The analyses demonstrated that the\nqualitative ﬁndings can be veriﬁed by kinematic trajectori es\nshowing a clear improvement with HMD Dyn support (HOLO-\nEﬀect).\nSense of Presence\nThe statistics is shown in Table 3. The two groups did not diﬀer\nsigniﬁcantly ( p = 0.731). We found a signiﬁcant main eﬀect of\nEnvironment and a signiﬁcant Environment × Group interaction,\nwhich was driven by a higher sense of presence in the HMD than\nin the screen environment (Controls Screen: 2.9, 95%-CI [2.4,3.4],\nControlsHMD: 4.7, 95%-CI [4.4,4.9], Patients Screen: 3.3, 95%-CI\n[2.7,4.1], Patients HMD: 4.1, 95%-CI [3.7,4.3]). Realness of the\npresented objects was rated as high in the screen environment\n(M = 3.4, SD = 1.8) and very high in the HMD environment\n(M = 4.8, SD = 1). While spatial presence was judged low in the\nscreen environment ( M = 2.4, SD = 1.9) it was rated as very high\nin the HMD environment ( M = 5.1, SD = 1). Perceptual stress\nwas perceived as moderate in both environments (Screen M =\n3.4, SD = 1.2; HMD M = 3.4, SD = 1.4). All other eﬀects and\ninteractions were non-signiﬁcant ( p > 0.494).\nCorrelations Between Presence and\nPantomiming\nWe found a signiﬁcant correlation between presence and\nHMDDyn Production results (r = 0.534, p = 0.049), suggesting\nthat as the sense of presence increases with animated hologra ms,\nso does the performance. All other correlations were non-\nsigniﬁcant ( Supplementary Table 7).\nDISCUSSION\nIn this study the eﬀects of pantomiming with visual feedback\nprovided in diﬀerent environments (Screen vs. HMD) and\ndiﬀerent modes (static vs. dynamic) and the impact of\npresence in each condition were compared. Age-matched contro l\nparticipants performed as expected, close to ceiling in all\nconditions and signiﬁcantly better than patients. In contrast ,\nthe patients’ performances were dependent upon the type\nof visual feedback given. As hypothesized, patients achieved\nsigniﬁcantly higher scores when they received holographic\n(HMD-Eﬀect) or dynamic cues (DYN-Eﬀect). Despite not\nreaching the level of signiﬁcance, best results were observ ed with\ndynamic holograms (HOLO-Eﬀect, Figure 5A). Impressively,\nsingle patients improved their overall performance of up to 24%\nwith this form of visual support. The kinematic analysis of one\nparticularly impressive patient (P13), who failed in all condit ions\nexcept when cued with animated holograms, is shown in Figure 3\nand Supplementary Video 4 .\nA key ﬁnding within this study is that pantomiming tended\ntoward the real tool demonstration performance with the\nsupport of visual stimuli of increasing salience ( Figure 4A). It\nhas been hypothesized that diﬀerent representations underlin e\npantomimed actions and real tool use, with pantomimes serving\ncommunication (when trying to enable others to recognize th e\npretended actions) while real tool actions being instrument al (\n10,\n17, 21, 48). One possible explanation for behavioral improvement\nwhen presented with salient stimuli is that the provided\nholographic cues facilitated compensatory action simulation\nprocesses by triggering activities in relevant cortical are as\nfor pantomime of tool use (\n49). Lesion symptom mapping\nstudies show that defective pantomime of tool use is associate d\nwith damage in left ventro-dorsal regions ( 14, 50, 51), with\ncommunicative aspects being related to rather anterior regi ons\nin the inferior frontal cortex, and aspects related to motor\ncognitive movement production being rather associated with\nposterior regions in the network (\n5). The latter lesion correlates\nin left parietal regions are in line with those reported to go\nalong with deﬁcient demonstration of tool use (\n52). Given the\nsalient nature of holographic presentations of familiar obje cts\nFrontiers in Neurology | www.frontiersin.org 10 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\none may hypothesize that more speciﬁc neural responses in\nventral visual streams have been elicited by object recogni tion\nprocesses. Present information about the object may help to\nspecify potential actions by narrowing down action opportuniti es\nsupported by rather posterior and dorsal regions. Perhaps these\nprocesses elicited by the salient cues may help channeling hi gher-\norder functions such as attention and reduce the load on acti on\nsimulation processes in a left fronto-temporo-parietal netwo rk.\nIn line with this idea, the visual streams in the ventral and\ndorsal cortex, that are responsible for perceiving and intera cting\nwith common objects in the three-dimensional space, have bee n\nshown to respond similarly in AR tasks as compared to real-\nworld tasks (\n53). Thus, one reason for improved pantomiming\nmight be that the increased saliency in visual input has shift ed\nthe pantomime actions from communicative gestures to rather\ninstrumental actions.\nClearly, a strength of this study lies in the design of\nholograms by 3D-scanning the original tools and recording i ts\nreal use. The induced sense of presence was signiﬁcantly high er\nin HMD than in screen environments, and in the HMD Dyn\nenvironment pantomiming improved signiﬁcantly with higher\npresence ratings. The realness and high spatial presence evoke d\nby our holograms may have made pantomiming less symbolic\nas it was rather inﬂuenced by the strong external cues. Furth er,\nit has been shown that apraxics have deﬁcits in intrinsic\ncoordinate control (\n11, 22). In such, participants might have\nextrinsically coordinated their movements in reference to the\ndynamic or holographic objects. The context factors in the HMD\nenvironment, e.g., the orientation in space (designed in a wa y to\ninvite the participant to reach for it) and the real-sized holo grams\nmight have reduced the opportunities of grip formation and\nmovement orientation, thereby limiting the degrees of free dom.\nMoreover, the structural and texture information, includin g light\nreﬂections, given in our holograms could have helped patients\n(\n37). These details became even more extensive in HMD Dyn\nconditions, oﬀering diﬀerent perspectives, such as the view of\nthe bottom of the watering can when it is moved. For instance,\nsome patients showed clear diﬃculties in spatial orientation in\nscreen conditions, but the holographic presentations helped t hem\norientating in space correctly.\nLastly, the dynamic presentation in both environments\nmight have attracted more attention and have had a more\nprompting character stimulating the correct movement conten t\n(\n20). In this regard, we observed individual patients trying to\ncopy the shown movements, e.g., by following the rhythmic\nbeat of hammering. In neuroimaging studies investigating\nhealthy people, a larger response in the lateral temporal\ncortex relative to the ventral cortex has been shown when\ndynamic compared to static humans and tools are viewed,\nsuggesting the lateral temporal cortex to be responsible for\ncomplex motion processing (\n54). Potentially, the moving cues\nenhanced the activity in the lateral temporal cortex which\nmay have been integrated into the perception-action network\nprocessing pantomimes.\nThis can be partially supported by the Interaction scores,\nshowing signiﬁcant higher object interactions in HMD or DYN\nconditions. In patients, higher interactions during the Scr eenDyn\ncondition even signiﬁcantly correlated with increased Pro duction\nscores, which indicates an added value of dynamic cues in scr een-\nbased systems. In addition, patients with a higher quality in\nstereovision, a better manual dexterity and worse mechanic al\nproblem solving beneﬁt more from dynamic cues. One possible\nexplanation is that patients with mechanical problem solving\ndeﬁcits may proﬁt from the increasing visual and semantic\ninformation consistent with the task provided by the three-\ndimensional cues from the HoloLens (e.g., when focusing\nperception on the best suited aﬀordances to solve the task, here\nthe correct representation of the moving tool). Indirectly, this\ncould be taken as an indicator of an important role of mechanic al\nproblem solving in tool use behavior and would therefore be\nin line with the reasoning-based approach to human tool use\n(\n23, 55, 56).\nNevertheless, correlations between Interaction and\nProduction scores during HMD conditions did not become\nsigniﬁcant ( p > 0.22). In contrast, and probably even more\nstriking, the patients who experienced the strongest HOLO-\nEﬀects on the Production scores (P13, P02) did not interact\nwith the given cues at all ( Figure 5). Moreover, in healthy\nsubjects the interactions with static holograms even negat ively\ninﬂuenced performance, in a way that they changed their motor\nbehavior resulting in unnatural, error-loaded movements w hen\ntrying to reach for holograms. Potentially, these participant s\ngot distracted from the actual task by volitionally directi ng\ntheir attentional focus on the salient cues (\n36), resulting in\nmore errors. That is, consistent with the results of a feasibi lity\nstudy on AR-based ADL support, the unnatural interaction\nwith holographic animations that impaired the performance\nby requesting its own resources (\n57). We would have expected\nhigher presence to result in more interactions with the virtu al\nobjects. However, we did not ﬁnd a signiﬁcant correlation\nwhich can be explained by the experimental task design not\nrequiring any real interaction. Still, at this point it remains\nunclear why some participants were very responsive to the\nstimuli (such as P18, who interacted with holograms in\n100% of the HMD conditions), while others seemed not\nto respond at all ( Figure 5). The interaction with dynamic\nobjects was higher in controls as well as in patients with a\nhigher mental state, a better FTT Selection and NAT score.\nPossibly, unimpaired people are more prone to interacting with\nholograms because they have more cognitive resources to foc us\non the augmented information, but this hypothesis has to be\nfurther investigated.\nAnother likely explanation for the improvements is that\nboth the dynamic and holographic information provided error\nsignals for the perceptual-motor system as suggested by Jax\net al. (\n11). While patients with apraxia often struggle in\nmovement preparation (i.e., planning) the adjustment of the\nmovement plan (i.e., online correction) is often intact (\n22).\nSimilar to reports of Jax and colleagues ( 11) about the observed\n“conduit d’approche” in some patients, we also noted an increase\nin accuracy after multiple repetitions. Patients might have\nvisually recognized their incorrect movements and tried to\nmore closely approximate the correct action represented by the\nanimated holograms.\nFrontiers in Neurology | www.frontiersin.org 11 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nLimitations\nThe psychometric properties of the applied Presence\nquestionnaire (\n43) have not yet been validated in the\nstroke population or in patients with cognitive limitations.\nUnfortunately, eight patients failed to ﬁll in the questionna ire,\nwhich indicates that it may not be the best measure to assess\npresence in this population. Besides a need of alternative\nquestionnaires, the integration of objective measures (e. g., eye\nmovements) is worth further investigation. In HoloLens 2nd\ngeneration, the feature of eye-tracking is incorporated oﬀer ing\nan easy way to analyse visual attention based on eye movement s,\nto assess salience and to identify the user’s intention (\n35) and\nareas of interests ( 23). Indeed, while spatial attention is a major\nmechanism for saliency detection, patients with visuo-spati al\nor attentional deﬁcits might not be able to focus their limit ed\nperceptual resources on the holograms. In this study, patients\nwith a higher quality in stereovision had a higher DYN-Eﬀect o n\nthe Production scale and a trend points toward an association of\nhigher stereovision and interactions with animated hologr ams.\nWe cannot rule out that some patients have been unable to see\nthe holograms as intended and thus, have not beneﬁted from it s\nsalient contextual information.\nThe technical presentation of realistic holograms also had\nits short-comings. In particular, some patients were unable t o\ndetect the key, possibly because it was displayed too close to\nthe user and might have been overlooked because of not being\nvisually distinct enough from its surrounding. On the other hand,\nparticipants criticized the holographic watering can appearing\ntoo far away in order to grasp for it, which was necessary to\nenable real-size presentations in the HoloLens. This illustr ates the\ndiﬃculty in ﬁnding the optimal zone for hologram positioning i n\nexperimental research, especially with the current technolo gical\nlimitations (e.g., limited ﬁeld of view). The fact that the d ynamic\nfeatures had no signiﬁcant impact on presence ratings may be du e\nto these technological constraints (\n28).\nThe predeﬁned eligibility criteria within the present study\nwere quite broad. Consequently, we included patients in the\nsubacute as well as in the chronic stage, patients with and wit hout\na diagnose of neglect, aphasia or cognitive decline, but did n ot\nadjust for these possible confounding factors. At the moment\nwe are therefore not able to give diﬀerential recommendation s\nto patients early and late after stroke. In addition, the eﬀect\nof cues may have been underestimated in some patients if\naphasia, neglect or attention deﬁcits had deteriorated task\nunderstanding or stimulus perception. Further and in line wit h\nrecent recommendations on post-stroke rehabilitation tria ls (\n58),\nwe ensured an aphasia and neglect friendly testing (by followi ng\nthe DILA-S recommendations), which improved our recruitmen t\nrate and increases the generalizability of our results.\nOutlook\nApraxia is a major predictor of poor functional performance\nin ADL and of increased dependence on caregivers. To date,\neﬀective rehabilitation strategies are still limited (\n9, 59) and\nmainly include compensatory approaches, such as strategy\ntraining (\n8, 60), errorless learning ( 61), behavioral training ( 62)\nor task-speciﬁc and meaningful training ( 63). In recent years,\ntechnology-based approaches facilitating single-tool use an d\nmultistep actions have been proposed as promising strategies\n(\n9, 64). AR technology has already found its way into a\nlarge ﬁeld of applications, where holographic elements enrich\nthe perception of the real environment, e.g., by providing\ncognitive support during diﬀerent tasks (\n65). In the wide\nﬁeld of rehabilitation, AR will introduce new pathways for\ntherapeutic or assistive approaches with the potential of\nproviding an engaging and motivating training environment\n(\n31), improving physical outcomes when applied as an adjunct\ntherapy ( 29), supporting mental rehabilitation ( 44) or cognitive\nrehabilitation ( 57, 66). Based on our ﬁndings, we envision\nHMD-based AR systems to assist patients in their ADLs\nin the future, thus maintaining autonomy. The advantages\nof wearable cognitive support systems over existing screen-\nbased approaches (\n66, 67) are having both hands available\nfor interactions with the physical environment while still\nbeing able to move ﬂexibly from one place to another. In\nthis regard, we see two main application areas where AR\ncan be used: (1) as a supportive training tool to facilitate\nperformance improvement and (2) as a (well-controllable)\ndiagnostic research tool to further examine the role and\nimportance of diﬀerent modes and types of visual cues and to\nidentify predicting variables.\nWhile we showed that holograms can attract attention (e.g.,\nby being visually salient) and improve performance, they can\npotentially also distract from the real activity and may requ ire\nvoluntary eﬀort to redirect the attention to the physical objec ts\n(\n36). The objects within this study were displayed in a left\nhanded setting ( Figure 2D) and the holographic cues were\naligned in space to invite the participant to reach for it as it wa s\nshown that the perception of aﬀordances (here the orientation\nof the tools in space) inﬂuences the motor response that is\nbest suited for interacting with the target object (\n23, 56, 68).\nIn future trials on real tool support however, we recommend\nto place cues in a non-reachable zone because no interaction\nwith holographic but rather real objects is desired. Besides , AR\nsupported manual task guidance inside the peripersonal space\nis associated with vergence-accomodation-conﬂict (e.g., when\nthe virtual content is inconsistent with the real world) and\nfocus-rivalry (e.g., when simultaneously focusing on real an d\nvirtual content). These common perceptual conﬂicts experienc ed\nin artiﬁcial environments may impair the performance due to\nvisual fatigue and mental workload, especially with increase d\ntask diﬃculty as recently suggested by preliminary data on EEG\nrecordings during AR use (\n69).\nFuture experiments should investigate whether a further\nincrease in visual ﬁdelity and contextual information will\nlead to even better results (e.g., by adding the target item\nor illustrating a holographic hand correctly performing the\naction). Indeed, ﬁndings from a recent eye-tracking study\nanalyzing the visuo-perceptual context within a virtual scene\nshow that thematically consistent object-tool pairs (e.g.,\nhammer and nail) can have a facilitating inﬂuence on visual\nattention (\n23). In addition, audio-visual complexity does provide\nopportunities to enhance individual meaning, salience and\nauthenticity (\n70–72).\nFrontiers in Neurology | www.frontiersin.org 12 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nCONCLUSION\nThis study was the ﬁrst to explore the eﬀect of dynamic\nholographic cues on pantomiming in LBD patients. We provide\nﬁrst knowledge about which type of AR cue might be\nmost beneﬁcial in supporting patients with apraxia, present\ncurrent limitations and give suggestions for further resea rch.\nSpeciﬁcally, studies are necessary to characterize the cond itions\nthat lead to optimal motor behavior in augmented environment s,\nand to identify responders and factors that increase the\npotential eﬀects of this new form of support. With further\ntechnological achievements (\n65) we believe this new approach\nto positively impact the rehabilitation process of patients\nwith apraxia.\nDATA AVAILABILITY STATEMENT\nThe datasets generated for this study can be found in online\nrepositories. The names of the repository/repositories and\naccession number(s) can be found below: Center for Open\nScience (COS) Open Science Framework (OSF), https://osf.io/\nuakw2/?view_only=a55698fafb6541f7878284bab64e940c.\nETHICS STATEMENT\nThe studies involving human participants were reviewed\nand approved by the Ethics Committee of the Medical\nFaculty of the Technical University of Munich (reference\nnumber 175/17S). The patients/participants provided\ntheir written informed consent to participate in\nthis study.\nAUTHOR CONTRIBUTIONS\nNR and JH: conceptualization, methodology, and formal analysi s.\nNR and AT: software and visualization. NR and LL: validation .\nNR, LL, and KJ: investigation. NR: data curation and writing –\noriginal draft preparation. CK, JR, KJ, and JH: writing – review &\nediting. CK: project administration. CK and JH: supervision. JR ,\nKJ, and JH: resources. NR, CK, and JH: funding acquisition. All\nauthors contributed to the ﬁnal draft of the manuscript, read , and\napproved the ﬁnal manuscript.\nFUNDING\nNR acknowledges support through a fellowship of the Bavarian\nState Ministry of Science and the Arts and coordinated by the\nBavarian Research Institute for Digital Transformation (bi dt).\nThis project has also received funding from the European Unions\nHorizon 2020 research and innovation program ReHyb under\ngrant agreement n ◦ 871767.\nACKNOWLEDGMENTS\nThe authors would like to acknowledge Max Hühnemörder for\nthe design and implementation of the software application, and\nElena Arcidiacono for her assistance in kinematic data label ing.\nSUPPLEMENTARY MATERIAL\nThe Supplementary Material for this article can be found\nonline at: https://www.frontiersin.org/articles/10.338 9/fneur.\n2021.711900/full#supplementary-material\nREFERENCES\n1. Bickerton W-L, Riddoch MJ, Samson D, Balani AB, Mistry B, Humphreys\nGW. Systematic assessment of apraxia and functional predictions f rom the\nBirmingham Cognitive Screen. J Neurol Neurosurg Psychiatry.(2012) 83:513–\n21. doi: 10.1136/jnnp-2011-300968\n2. Donkervoort M, Dekker J, Van Den Ende E, Stehmann-Saris J. Prev alence\nof apraxia among patients with a ﬁrst left hemisphere stroke in\nrehabilitation centres and nursing homes. Clin Rehabil. (2000) 14:130–6.\ndoi: 10.1191/026921500668935800\n3. Buchmann I, Dangel M, Finkel L, Jung R, Makhkamova I, Binder A , et al.\nLimb apraxia proﬁles in diﬀerent clinical samples. Clin Neuropsychol.(2020)\n34:217–42. doi: 10.1080/13854046.2019.1585575\n4. Buxbaum LJ, Randerath J. Limb apraxia and the left parietal lobe. Handb Clin\nNeurol. (2018) 151:349–63. doi: 10.1016/B978-0-444-63622-5.00 017-6\n5. Finkel L, Hogrefe K, Frey SH, Goldenberg G, Randerath J. It takes t wo to\npantomime: communication meets motor cognition. NeuroImage Clin.(2018)\n19:1008–17. doi: 10.1016/j.nicl.2018.06.019\n6. Timpert DC, Weiss PH, Vossel S, Dovern A, Fink GR. Apraxia and spatia l\ninattention dissociate in left hemisphere stroke. Cortex. (2015) 71:349–58.\ndoi: 10.1016/j.cortex.2015.07.023\n7. Rothi L, Heilman K. Introduction to Limb Apraxia. Hove: Psychology Press\n(1997). p. 1–6.\n8. Smania N, Aglioti S, Girardi F, Tinazzi M, Fiaschi A, Cosentino\nA, et al. Rehabilitation of limb apraxia improves daily life\nactivities in patients with stroke. Neurology. (2006) 67:2050–2.\ndoi: 10.1212/01.wnl.0000247279.63483.1f\n9. Bie ´nkiewicz M, Brandi M-L, Goldenberg G, Hughes CM, Hermsdörfer\nJ. The tool in the brain: apraxia in ADL. Behavioral and neurologica l\ncorrelates of apraxia in daily living. Front Psychol. (2014) 5:353.\ndoi: 10.3389/fpsyg.2014.00353\n10. Goldenberg G. Apraxia - the cognitive side of motor control. Cortex. (2014)\n57:270–4. doi: 10.1016/j.cortex.2013.07.016\n11. Jax S, Rosa-Leyra D, Buxbaum L. Conceptual-and production-rela ted\npredictors of pantomimed tool use deﬁcits in apraxia. Neuropsychologia.\n(2014) 62:194–201. doi: 10.1016/j.neuropsychologia.2014.0 7.014\n12. Goldenberg G, Hartmann K, Schlott I. Defective pantomime of obje ct use in\nleft brain damage: apraxia or asymbolia? Neuropsychologia. (2003) 41:1565–\n73. doi: 10.1016/S0028-3932(03)00120-9\n13. Randerath J, Buchmann I, Liepert J, Büsching I. Diagnostic Instrument for\nLimb Apraxia: Short Version (DILA-S), 1st Edn, Konstanz: University of\nKanstanz and Lurija Institute (2017).\n14. Randerath J. A Simple Illustration of a Left Lateralized Praxis Network.\nKonstanz: Institutional Repository of the University of Konst anz, KOPS\n(2020). doi: 10.18148/kops/352-2-963roebfu0cr4\n15. Randerath J, Goldenberg G, Spijkers W, Li Y, Hermsdörfer J. From pa ntomime\nto actual use: how aﬀordances can facilitate actual tool-use. Neuropsychologia.\n(2011) 49:2410–6. doi: 10.1016/j.neuropsychologia.2011.04 .017\n16. Hermsdorfer J, Li Y, Randerath J, Goldenberg G, Johannsen L. To ol use\nwithout a tool: kinematic characteristics of pantomiming as compared t o\nactual use and the eﬀect of brain damage. Exp Brain Res.(2012) 218:201–14.\ndoi: 10.1007/s00221-012-3021-z\n17. Hermsdorfer J, Li Y, Randerath J, Roby-Brami A, Goldenberg G. Too l\nuse kinematics across diﬀerent modes of execution. Implications\nFrontiers in Neurology | www.frontiersin.org 13 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\nfor action representation and apraxia. Cortex. (2013) 49:184–99.\ndoi: 10.1016/j.cortex.2011.10.010\n18. Sperber C, Christensen A, Ilg W, Giese MA, Karnath HO. Apraxia of o bject-\nrelated action does not depend on visual feedback. Cortex. (2018) 99:103–17.\ndoi: 10.1016/j.cortex.2017.11.001\n19. Scheib JP , Stoll S, Thürmer JL, Randerath J. Eﬃciency in rule-vs . plan-\nbased movements is modulated by action-mode. Front Psychol.(2018) 9:309.\ndoi: 10.3389/fpsyg.2018.00309\n20. Goldenberg G, Hentze S, Hermsdörfer J. The eﬀect of tactile feed back\non pantomime of tool use in apraxia. Neurology. (2004) 63:1863–7.\ndoi: 10.1212/01.WNL.0000144283.38174.07\n21. Hermsdörfer J, Hentze S, Goldenberg G. Spatial and kinematic fea tures of\napraxic movement depend on the mode of execution. Neuropsychologia.\n(2006) 44:1642–52. doi: 10.1016/j.neuropsychologia.2006.0 3.023\n22. Jax SA, Buxbaum LJ, Moll AD. Deﬁcits in movement planning and in trinsic\ncoordinate control in ideomotor apraxia. J Cogn Neurosci.(2006) 18:2063–76.\ndoi: 10.1162/jocn.2006.18.12.2063\n23. Federico G, Brandimonte MA. Tool and object aﬀordances: an\necological eye-tracking study. Brain Cogn. (2019) 135:103582.\ndoi: 10.1016/j.bandc.2019.103582\n24. Milgram P , Kishino F. A taxonomy of mixed reality visual displays. IEICE\nTRANSACTIONS Inform Syst.(1994) 77:1321–9.\n25. Bohil CJ, Alicea B, Biocca FA. Virtual reality in neuroscience research and\ntherapy. Nat Rev Neurosci.(2011) 12:752–62. doi: 10.1038/nrn3122\n26. Rohrbach N, Chicklis E, Levac DE. What is the impact of user aﬀ ect on motor\nlearning in virtual environments after stroke? A scoping review. J Neuroeng\nRehabil. (2019) 16:79. doi: 10.1186/s12984-019-0546-4\n27. Schuemie MJ, Van Der Straaten P , Krijn M, Van Der Mast CA. Rese arch on\npresence in virtual reality: a survey. Cyberpsychol Behav. (2001) 4:183–201.\ndoi: 10.1089/109493101300117884\n28. Cummings JJ, Bailenson JN. How immersive is enough? A meta-analys is of\nthe eﬀect of immersive technology on user presence. Media Psychol.(2016)\n19:272–309. doi: 10.1080/15213269.2015.1015740\n29. Al-Issa H, Regenbrecht H, Hale L. Augmented reality applications in\nrehabilitation to improve physical outcomes. Phys Ther Rev.(2012) 17:16–28.\ndoi: 10.1179/1743288X11Y.0000000051\n30. Kock WE. Properties of Holograms. Engineering Applications of\nLasers and Holography. Boston, MA: Springer (1975). p. 77–102.\ndoi: 10.1007/978-1-4684-2160-6_6\n31. Gorman C, Gustafsson L. The use of augmented reality for rehabili tation\nafter stroke: a narrative review. Disabil Rehabil Assist Technol. (2020) 1–9.\ndoi: 10.1080/17483107.2020.1791264\n32. Huberle E, Karnath H-O. Saliency modulates global perception\nin simultanagnosia. Exp Brain Res. (2010) 204:595–603.\ndoi: 10.1007/s00221-010-2328-x\n33. Yantis S. How visual salience wins the battle for awareness. Nat Neurosci.\n(2005) 8:975–7. doi: 10.1038/nn0805-975\n34. Toet A. Computational versus psychophysical bottom-up image s aliency: a\ncomparative evaluation study. IEEE Trans Pattern Anal Mach Intell.(2011)\n33:2131–46. doi: 10.1109/TPAMI.2011.53\n35. Keil J, Edler D, Dickmann F, Kuchinke L. Meaningfulness of lan dmark\npictograms reduces visual salience and recognition performance. Appl Ergon.\n(2019) 75:214–20. doi: 10.1016/j.apergo.2018.10.008\n36. Itti L, Koch C. Computational modelling of visual attention. Nat Rev Neurosci.\n(2001) 2:194–203. doi: 10.1038/35058500\n37. Barde LH, Buxbaum LJ, Moll AD. Abnormal reliance on object structu re\nin apraxics’ learning of novel object-related actions. J Int Neuropsychol Soc.\n(2007) 13:997. doi: 10.1017/S1355617707070981\n38. Costantini M, Ambrosini E, Tieri G, Sinigaglia C, Committeri G. W here\ndoes an object trigger an action? An investigation about aﬀord ances\nin space. Exp Brain Res. (2010) 207:95–103. doi: 10.1007/s00221-010-\n2435-8\n39. Folstein MF, Folstein SE, McHugh PR. “Mini-mental state”: a pra ctical method\nfor grading the cognitive state of patients for the clinician. J Psychiatr Res.\n(1975) 12:189–98. doi: 10.1016/0022-3956(75)90026-6\n40. Oldﬁeld RC. The assessment and analysis of handedness:\nthe Edinburgh inventory. Neuropsychologia. (1971) 9:97–113.\ndoi: 10.1016/0028-3932(71)90067-4\n41. Mathiowetz V , Weber K, Kashman N, Volland G. Adult norms for the\nnine hole peg test of ﬁnger dexterity. Occup Ther J Res. (1985) 5:24–38.\ndoi: 10.1177/153944928500500102\n42. Demeurisse G, Demol O, Robaye E. Motor evaluation in vascular h emiplegia.\nEur Neurol.(1980) 19:382–9. doi: 10.1159/000115178\n43. Regenbrecht H, Schubert T. “Measuring Presence in Augmented Re ality\nEnvironments: Design and a First Test of a Questionnaire, ” in Proceedings\nof the Fifth Annual International Workshop Presence 2002, Porto, Portugal -\nOctober 9-11, 138–144 (2002).\n44. Liberatore MJ, Wagner WP. Virtual, mixed, and augmented reality: a\nsystematic review for immersive systems research. Virtual Real. (2021).\ndoi: 10.1007/s10055-020-00492-0\n45. Randerath J, Li Y, Goldenberg G, Hermsdörfer J. Grasping tools:\neﬀects of task and apraxia. Neuropsychologia. (2009) 47:497–505.\ndoi: 10.1016/j.neuropsychologia.2008.10.005\n46. Dziura JD, Post LA, Zhao Q, Fu Z, Peduzzi P. Strategies for de aling with\nmissing data in clinical trials: from design to analysis. Yale J Biol Med.\n(2013) 86:343.\n47. Cohen J. Statistical Power Analysis for the Behavioural Sciences. 2nd ed.\nHillsdale, NJ: L. Erlbaum Associates (1988).\n48. Niessen E, Fink G, Weiss P. Apraxia, pantomime and the parietal co rtex.\nNeuroImage Clin.(2014) 5:42–52. doi: 10.1016/j.nicl.2014.05.017\n49. Hermsdörfer J, Terlinden G, Mühlau M, Goldenberg G, Wohlschläger\nAM. Neural representations of pantomimed and actual tool use: evide nce\nfrom an event-related fMRI study. Neuroimage. (2007) 36:T109–18.\ndoi: 10.1016/j.neuroimage.2007.03.037\n50. Goldenberg G, Hermsdörfer J, Glindemann R, Rorden C, Karnath H-O.\nPantomime of tool use depends on integrity of left inferior frontal c ortex.\nCereb Cortex.(2007) 17:2769–76. doi: 10.1093/cercor/bhm004\n51. Reynaud E, Navarro J, Lesourd M, Osiurak F. To watch is to work: a review of\nneuroimaging data on tool use observation network. Neuropsychol Rev.(2019)\n29:484–97. doi: 10.1007/s11065-019-09418-3\n52. Randerath J, Goldenberg G, Spijkers W, Li Y, Hermsdörfer J. Diﬀe rent left\nbrain regions are essential for grasping a tool compared with its subs equent\nuse. Neuroimage. (2010) 53:171–80. doi: 10.1016/j.neuroimage.2010.06.038\n53. Frangos AS, Lee T-J, To D, Giannopulu I, editors. Dorsal and v entral pathways\nimplications in an augmented reality environment. 2019 IEEE Conference\non Virtual Reality and 3D User Interfaces (VR). Danvers, MA: IEEE (2019).\ndoi: 10.1109/VR.2019.8797757\n54. Beauchamp MS, Lee KE, Haxby JV , Martin A. Parallel visual\nmotion processing streams for manipulable objects and human\nmovements. Neuron. (2002) 34:149–59. doi: 10.1016/S0896-6273(02)0\n0642-6\n55. Federico G, Brandimonte MA. Looking to recognise: the pre-emine nce of\nsemantic over sensorimotor processing in human tool use. Sci Rep. (2020)\n10:1–16. doi: 10.1038/s41598-020-63045-0\n56. Osiurak F, Badets A. Tool use and aﬀordance: manipulation-bas ed\nversus reasoning-based approaches. Psychol Rev. (2016) 123:534.\ndoi: 10.1037/rev0000027\n57. Rohrbach N, Gulde P , Armstrong AR, Hartig L, Abdelrazeq A, Schröde r\nS, et al. An augmented reality approach for ADL support in Alzheimer’s\ndisease: a crossover trial. J Neuroengineering Rehabil. (2019) 16:1–11.\ndoi: 10.1186/s12984-019-0530-z\n58. Stinear CM, Lang CE, Zeiler S, Byblow WD. Advances and\nchallenges in stroke rehabilitation. Lancet Neurol. (2020) 19:348–60.\ndoi: 10.1016/S1474-4422(19)30415-6\n59. West C, Bowen A, Hesketh A, Vail A. Interventions for motor a praxia\nfollowing stroke. Cochrane Database Syst Rev . (2008) 2008:CD004132.\ndoi: 10.1002/14651858.CD004132.pub2\n60. van Heugten CM, Dekker J, Deelman B, Van Dijk A, Stehmann-Saris J.\nOutcome of strategy training in stroke patients with apraxia: a phase II study.\nClin Rehabil.(1998) 12:294–303. doi: 10.1191/026921598674468328\n61. Buxbaum LJ, Haaland KY, Hallett M, Wheaton L, Heilman KM, Rodrigu ez A,\net al. Treatment of limb apraxia: moving forward to improved action. Am J\nPhys Med Rehabil.(2008) 87:149–61. doi: 10.1097/PHM.0b013e31815e6727\n62. Smania N, Girardi F, Domenicali C, Lora E, Aglioti S. The rehabilita tion of\nlimb apraxia: a study in left-brain–damaged patients. Arch Phys Med Rehabil.\n(2000) 81:379–88. doi: 10.1053/mr.2000.6921\nFrontiers in Neurology | www.frontiersin.org 14 August 2021 | Volume 12 | Article 711900\nRohrbach et al. Apraxia Improvement With Augmented Reality\n63. Goldenberg G, Daumüller M, Hagmann S. Assessment and therapy of\ncomplex activities of daily living in apraxia. Neuropsychol Rehabil. (2001)\n11:147–69. doi: 10.1080/09602010042000204\n64. Pastorino M, Fioravanti A, Arredondo MT, Cogollor JM, Rojo J, Fe rre M,\net al. editors. Cogwatch: a web based platform for cognitive tele- rehabilitation\nand follow up of apraxia and action disorganisation syndrome patien ts. IEEE-\nEMBS International Conference on Biomedical and Health Informatics (BHI).\nIEEE (2014). doi: 10.1109/BHI.2014.6864322\n65. Michahelles F, Ciortea A, García K, Funk M, editors. Combinin g\nsemantics and augmented reality to support the human mind. Proceedings\nof the (2017). ACM International Joint Conference on Pervasiv e and\nUbiquitous Computing and Proceedings of the (2017). ACM Interna tional\nSymposium on Wearable Computers; (2017). doi: 10.1145/3123024.3 1\n29270\n66. Kosch T, Wennrich K, Topp D, Muntzinger M, Schmidt A, editors . The\ndigital cooking coach: using visual and auditory in-situ instructions to\nassist cognitively impaired during cooking. Proceedings of the 12th ACM\nInternational Conference on PErvasive Technologies Relate d to Assistive\nEnvironments. New York, NY: Association for Computing Machinery (2019).\ndoi: 10.1145/3316782.3321524\n67. Cogollor JM, Rojo-Lacal J, Hermsdörfer J, Ferre M, Waldmeyer MTA,\nGiachritsis C, et al. Evolution of cognitive rehabilitation afte r stroke from\ntraditional techniques to smart and personalized home-based info rmation\nand communication technology systems: literature review. JMIR Rehabil Assist\nTechnol. (2018) 5:e8548. doi: 10.2196/rehab.8548\n68. Tucker M, Ellis R. On the relations between seen objects and\ncomponents of potential actions. J Exp Psychol. (1998) 24:830.\ndoi: 10.1037/0096-1523.24.3.830\n69. Rho G, Callara AL, Condino S, Ghiasi S, Nardelli M, Carbone M, et a l.,\neditors. A preliminary quantitative EEG study on Augmented Reality\nGuidance of Manual Tasks. 2020 IEEE International Symposium on Medical\nMeasurements and Applications (MeMeA) . Danvers, MA: IEEE (2020).\ndoi: 10.1109/MeMeA49120.2020.9137171\n70. Gilbert SB. Perceived realism of virtual environments depends on\nauthenticity. Presence Teleoper Virtual Environ. (2016) 24:322–4.\ndoi: 10.1162/PRES_a_00276\n71. Kleim JA, Jones TA. Principles of experience-dependent neural plas ticity:\nimplications for rehabilitation after brain damage. J Speech Lang Hear Res.\n(2008) 51:S225–39. doi: 10.1044/1092-4388(2008/018)\n72. Bie ´nkiewicz M, Gulde P , Schlegel A, Hermsdörfer J. The use of ecologica l\nsounds in facilitation of tool use in apraxia. Replace, Repair, Restore, Relieve–\nBridging Clinical and Engineering Solutions in Neurorehabilitation. Springer.\n(2014). p. 289–94. doi: 10.1007/978-3-319-08072-7_48\nConﬂict of Interest: The authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could be c onstrued as a\npotential conﬂict of interest.\nPublisher’s Note:All claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their aﬃliated organizat ions, or those of\nthe publisher, the editors and the reviewers. Any product that may b e evaluated in\nthis article, or claim that may be made by its manufacturer, is not gua ranteed or\nendorsed by the publisher.\nCopyright © 2021 Rohrbach, Krewer, Löhnert, Thierfelder, Rander ath, Jahn\nand Hermsdörfer. This is an open-access article distributed under the terms of\nthe Creative Commons Attribution License (CC BY). The use, distribution or\nreproduction in other forums is permitted, provided the original author(s) and the\ncopyright owner(s) are credited and that the original publication in this journal\nis cited, in accordance with accepted academic practice. Nouse, distribution or\nreproduction is permitted which does not comply with these terms.\nFrontiers in Neurology | www.frontiersin.org 15 August 2021 | Volume 12 | Article 711900",
  "topic": "Apraxia",
  "concepts": [
    {
      "name": "Apraxia",
      "score": 0.7053749561309814
    },
    {
      "name": "Augmented reality",
      "score": 0.6424340009689331
    },
    {
      "name": "Cognitive psychology",
      "score": 0.5124710202217102
    },
    {
      "name": "Psychology",
      "score": 0.5000362396240234
    },
    {
      "name": "Holography",
      "score": 0.44982263445854187
    },
    {
      "name": "Neuroscience",
      "score": 0.3784075081348419
    },
    {
      "name": "Computer science",
      "score": 0.37368518114089966
    },
    {
      "name": "Human–computer interaction",
      "score": 0.3277544677257538
    },
    {
      "name": "Aphasia",
      "score": 0.248601496219635
    },
    {
      "name": "Physics",
      "score": 0.07045429944992065
    },
    {
      "name": "Optics",
      "score": 0.0665733814239502
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I62916508",
      "name": "Technical University of Munich",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210146811",
      "name": "Schön Klinik Bad Aibling",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I189712700",
      "name": "University of Konstanz",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I8204097",
      "name": "Ludwig-Maximilians-Universität München",
      "country": "DE"
    }
  ],
  "cited_by": 14
}