{
  "title": "InspectorNet: Transformer network for violence detection in animated cartoon",
  "url": "https://openalex.org/W4362677955",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5101813639",
      "name": "Mahmoud M. Taha",
      "affiliations": [
        "Benha University"
      ]
    },
    {
      "id": "https://openalex.org/A5028613257",
      "name": "Abdelwahab Alsammak",
      "affiliations": [
        "Benha University"
      ]
    },
    {
      "id": "https://openalex.org/A5029409655",
      "name": "Ahmed B. Zaky",
      "affiliations": [
        "Benha University",
        "Egypt-Japan University of Science and Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2946086830",
    "https://openalex.org/W807203886",
    "https://openalex.org/W2894065842",
    "https://openalex.org/W2005531699",
    "https://openalex.org/W3036915154",
    "https://openalex.org/W3210279979",
    "https://openalex.org/W2182953902",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2805939409",
    "https://openalex.org/W4385245566"
  ],
  "abstract": "InspectorNet is a convolutional neural network based on transformer deep learning techniques, which is designed to address some of the limitations of current state-of-the-art artificial neural networks (ANN) models. The paper compares the performance of InspectorNet against a commonly used neural network in image classification, ResNet [1], on the Danbooru2020 dataset of animated cartoon images with a variable number of classes. The comparison shows that while both networks require significant computing resources for training, InspectorNet demonstrates better classification performance in certain test situations. The paper also highlights that with the increasing access to the internet, it is important to control the dissemination of sensitive content such as violence, but current neural networks may not be as effective in filtering cartoon movies aimed at children as the filters for these movies are different from those for adult movies. InspectorNet also has a compact architecture than many modern networks, such as ResNet, which results in better performance on low-resource devices",
  "full_text": " \nENGINEERING RESEARCH JOURNAL (ERJ) \nVolume (52), Issue (2) \nApril 2023, pp:114-119 \nhttps://erjsh.journals.ekb.eg \n \n- 114 - \nInspectorNet: Transformer network for violence detection \nin animated cartoon \n \n \nMahmoud M. Taha *a, Abdulwahab K. Al-Sammak a and Ahmed B. Zaky a,b \na Department of Electrical  Engineering, Faculty of Engineering at Shoubra Benha University  \nb Egypt japan university of science and technology computer science \n* Corresponding Author  \n        E-mail :mahoud.taha17@feng.bu.edu.eg,asammak@feng.bu.edu.eg,ahmed.zaky@feng.bu.edu.eg. \n \nAbstract: InspectorNet is a convolutional neural network based on transformer deep learning techniques, which is \ndesigned to address some of the limitations of current state -of-the-art artificial neural networks (ANN) model s. The \npaper compares the performance of InspectorNet against a commonly used neural network in image classification, \nResNet [1], on the Danbooru2020 dataset of animated cartoon images with a variable number of classes. The \ncomparison shows that while both  networks require significant computing resources for training, InspectorNet \ndemonstrates better classification performance in certain test situations. The paper also highlights that with the \nincreasing access to the internet, it is important to control th e dissemination of sensitive content such as violence, but \ncurrent neural networks may not be as effective in filtering cartoon movies aimed at children as the filters for these \nmovies are different from those for adult movies. InspectorNet also has a comp act architecture than many modern \nnetworks, such as ResNet, which results in better performance on low-resource devices.    \n \n \n Keywords: violence filtering, transformer, image classification. \n \n1. INTRODUCTION \nDistributing inappropriate video footage, even with \nconsent, is illegal and dangerous. It can be especially \nharmful to minors if it involves violence or child sexual \nabuse. Law Enforcement Agencies (LEAs)  are required to \nthoroughly review evidence before bringing a criminal case \nwhen there is a possibility that illicit content was created or \ndisseminated. Violence is defined as any commercial \nproduct, such as a fictional drama, that promotes violent \nbehaviour. Studies such as paper [2] have shown that \nGeneration Z, which includes individuals between the ages \nof 11 and 22, is particularly at risk due to their heavy use of \nthe internet.  \nEfforts to filter and control explicit content have had \nlimited success due to its prevalence among adults and \nchildren. With the advancement of computer vision and \ndeep learning, identifying and filtering unwanted content \nhas become a key objective in this field of study. \nIdentifying violence in movies can be challenging due to the \nvariety of content and variations in quality. Supervised \nclassification is a significant challenge in machine learning, \nas it may lead to false -positive or false -negative results in \ncertain situations, such as wrestling. Traditional methods \nused for  video filtering like paper [3] only work on one -\ndimensional attributes, which can be ineffective in some \ncases. \nThe InspectorNet network is unique in that it prioritizes \nthe classification of animated cartoon images and movies, \nand can operate on low -resource devices such as mobile \nphones and gaming consoles. To achieve this, it has a \nlightweight and precise design. This is important as children \nmay find it difficult to categorize animated cartoon content \nas threatening, thus watching violent movies may be  \ndisturbing for them. This classification task serves as a \nfoundation for other computer vision problems such as \ndetection, localization, and segmentation. \nIn this study, we develop InspectorNet, a deep -learning \nneural network that classifies violent scene s automatically \nin order to filter violent content in animated movies. As far \nas we are aware, this is the first attempt to use convolutional \nneural networks to categorise animated cartoons aimed at \nchildren. Our contribution involves classifying violent \nanimated cartoons using convolutional networks dubbed \nInspectorNet. Five sections make up the remainder of this \n Vol.52, No2 April 2023, pp:114-119 Mahmoud M. Taha et al Engineering Research Journal (ERJ) \n \n \n \n115 \n \nstudy. Section 2 discusses a review of earlier studies on the \nissue of violence detection, and Section 3 gives an overview \nof the most popular da tasets for the categorization of \nviolence detection. Then, in Section 4, which comes next, \nthe main components of our model InspectorNet are \npresented. In Section 5, we discuss the experimental setup \nof the suggested approach. We compare the outcomes of our \nnetwork training to one of the earlier neural networks in \nSection 6. Finally, in section 7, we demonstrate how our \nsuggested model might be improved in the future to \nimprove efficiency. \n2. LITERATURE REVIEW   \nImages are the most common medium for delivering \nviolent content, including texts and audio. As violence often \nincludes skin exposure, skin detection is often used to \nidentify perpetrators. However, skin detection is challenging \ndue to the limited generali zability of the methods used. In \nthe study by Vu Lam and Duy -Dinh Le, MediaEval [4] was \npresented which combined trajectory -based motion features \nwith SIFT -based and audio characteristics. Their findings \nsuggest that motion parameters based on trajectory a re still \nrelatively effective. Combining image and audio data can \nimprove overall performance for detecting violent events in \nvideos. \nTo identify illegal content in a perpetrator's documents, \nLaw Enforcement Agencies (LEAs) use hashing algorithms. \nThese techniques are computationally efficient, resistant to \nproducing false positive alarms, and can only identify \ncontent that is similar to what is in the LEA's database. Due \nto the sensitive nature of not -safe-for-work (NSFW) \ncontent, large datasets are gather ed in close cooperation \nwith LEAs. As a result, data -driven algorithms often \nproduce false positives or false negatives when detecting \nNSFW. Convolutional neural networks (CNNs) are widely \nused in image classification and have a high accuracy rate, \nbut they also have limitations, such as the accumulation of \ncharacteristics at each successive layer [5]. \n \nTABLE 1. Inappropriate content filtering list of previously used methods \nPaper Target Result \nShen et al. [7] Detection of violence using SSD extracted \nfeatures \n94.7% accuracy on NPDI \ndataset \nMoustafa et al. [8] Adult Video detection using CNN models \nAlexNet & GoogleNet \n94.2 % on NPDI-800 \ndataset \nKejun et al. [9] Detection of explicit Female breast using \nClassical hand-crafted features \nFPR: 7.46% and FNR: \n4.86% \nMahadeokar et al., 2016 \n[10] \nViolence detection using Thin ResNet-50 FPR: 12.8% and FNR: \n5.53% using Violence-2k \nMallmann et al., 2020 [11] Private Organs detection using Faster R-\nCNN Inception v2 \nFPR: 1.66% and FNR: \n2.34% using Violence-2k \n \nPrevious work in this field can be divided into two \ncategories. The first is based on the type of content that \nneeds to be filtered, such as guns, blood, fights, or all of \nthem. The second group focuses on specific media forms, \nlike photographic videos, hand -drawn graphics, or animated \ncartoons. According to Peter [6], there is a need to pay \ncloser attention to concerns about identification and \nteenagers' e xposure to sexually explicit online content or \nviolent movies. Increased exposure to violent scenes or \nsexually explicit internet content is linked to more violent \nbehaviour. A standard set of explicit or violent object \nclasses and a related benchmark data set have been defined, \nas shown in Table 1, which lists the objectives and results \nachieved by the studied approaches. \nThere are still many challenges in the video filtering \nindustry, as there are a wide variety of video formats. \nIdentifying what exactly w ill be filtered in movies is a \ncrucial question to answer, as there are a number of \nalternatives such as guns, weapons, alcohol, blood, injuries, \nfighting, shouting, action detection, violent action \nrecognition, or simply detecting everything. Additionally , \nthere are several subcategories such as suggestive violence \nor explicit violence. As seen in Fig 1, there are various \ntypes of cartoon movies and animated graphics, including \n2D films, 3D videos, stop motion, and line drawings. An \nanimated picture may be  considered as a distorted version \nof a real image. The main goal of our experiment is to \nevaluate InspectorNet's performance on animated -cartoon \n Vol.52, No2 April 2023, pp:114-119 Mahmoud M. Taha et al Engineering Research Journal (ERJ) \n \n \n \n116 \n \nimages in DeepDanbooru dataset [16], and we will compare \nit to previously used methods in video filtering field. \n \nFig 1. Examples of drawing styles and animated images. \nA Transformer network is a state -of-art \narchitecture that solves sequence -to-sequence tasks while \nhandling long -range dependencies with ease. [13] [14]. As \nshown in Fig 2, The encoder-decoder design of the majority \nof competing neural sequence transduction models is akin to \nthe transformer network architecture. The encoder converts \nthe input sequence of symbol representations into a series of \ncontinuous representations in t his case. Several symbols are \nthen generated by the decoder. For both the encoder and \ndecoder, the Transformer employs layers that are point -wise \ncompletely coupled. Two attention network kinds exist in \nthe transformer network. Scaled Dot -Product Attention and \nMulti-Head Attention, consist of several parallel attention \nlayers. We produce the transformer attention function's \noutput matrix in the manner suggested by equation 1. \n \nFig 2. transformer model architecture used in InspectorNet \nEQUATION 1. Transformer attention function output \nequation \n \n3. DATASET   \nObtaining a reliable animated cartoon dataset \nmay be difficult as most datasets in the scientific field are \nfor real people films [15]. As seen in Table 2, deep \nlearning in computer vision requires large annotated \ndatasets. Classification and categorizatio n have benefited \nfrom the creation of ImageNet, but a similar dataset with \nviolent tags or labels for a large collection of photographs \nis not available, preventing the learning and detection of \nmore information about images. Categorization and \nclassification are rough descriptions of an image. The \nmost well-known dataset that meets these characteristics \nis Danbooru [16]. The Danbooru dataset is used for \ndifferent classification tasks in animated cartoons field \nincluding violent action classification. For v iolence \ndetection, each image in Danbooru [16] has one of three \ncategories: safe images (like Fig. 3), which don’t contain \nany violence or nudity, questionable images (like Fig. 4), \nwhich may or may not have concealed violence, and \nexplicit images (like Fi g. 5), which contain explicit \nviolence. \nTABLE 2. List of datasets used in inappropriate content \nanalysis [15] \nName Datatype Description \nDanbooru2018 \n[16] \nimages A 300 GB Crowdsourced \nand Tagged 3.33m+ anime \nimages illustration dataset \nclassified into 3 categories: \nsafe, questionable and \nexplicit (violent). \nVSD2014 [17] videos A dataset of violent videos \nor most popular \nHollywood films. \nkinetics [18] videos A dataset of various types \nof all human action \nrecognition videos. \nUCF-101 [19] videos A big dataset of various \ntypes of human action \nrecognition videos. \nyoutube8m \n[20] \nvideos A big dataset of various \ntypes and activities tagged \nfrom YouTube. \n \n\n Vol.52, No2 April 2023, pp:114-119 Mahmoud M. Taha et al Engineering Research Journal (ERJ) \n \n \n \n117 \n \n \nFig 3. Safe Image from Danbooru dataset \n \nFig 4. Questionable Image containing gun from Danbooru dataset \n \nFig 5. violent action image from danbooru dataset \n4. INSPECTORNET TASK AND ARCHITECTURE  \nIn order to assist parents and law enforcement agencies in \nautomating the process of identifying and filtering violent \ncontent in animated cartoons, we aim to develop a fast and \naccurate solution for recognizing violent actions and \nweapons. Our proposed me thod will also specify the level \nof violence in the picture content by using a transformer \nnetwork based on a softmax neural network. Additionally, \nwe will demonstrate how the acquired characteristics of \nthis model can be applied to other tasks, such as ph oto \nclassification. InspectorNet is mainly dependent on the \ntransformer network so it can better retain and simulate \nhierarchical relationships within the internal knowledge \nrepresentation of a neural network.  \n \n \nFig 6. InspectorNet architecture based on transformer network \nAs depicted in Fig 6, InspectorNet  is composed of a \ntransformer network combined with max pooling and dense \nneural layers. The transformer network is responsible for \nidentifying image attributes and classifying individual \nframes based on previous frames. The dense layer works in \nconjunction with the transformer network to determine the \ncorrect classification for each image, similar to a traditional \nCNN. Global average pooling is a more natural fit for the \nconvolutional structure than fully connected layers, as it \nrequires correspondences be tween categories and feature \nmaps. The feature maps are therefore just subcategories of \nconfidence maps. The dropout layer serves as a mask, \npreserving all other neurons but removing some neurons' \ncontributions to the following layer. The output shape will  \ndepend on the number of trained neurons or units in the \nDense layer.  \n5. IMPLEMENTATION  \n5.1 Software and hardware  \nTo run the classification algorithms, we used a Dell \nlaptop and virtual instances hosted on the Google Colab \nPlatform. The Nvidia  GeForce 1050 Ti Mobile GPU, 16GB \nof RAM, and Intel Core i5 Extreme 7th generation CPU are \nall included in the Dell laptop. Instances in Google Colab \nmay be set up with a single Nvidia Tesla K80, 5GB of \nRAM, and an Intel Xeon (2.0 GHz) CPU. The primary \nprogramming environment we used was Colab IDE, while \nthe programming packages we utilised were Python 3.6, \nKeras 2.1.5, and Tensorflow 2.5. \n \n5.2 Preprocessing and Training architecture  \nBased on the dataset’s characteristics and the \nrequirements of the Inspec torNet algorithm, a variety of \npreparation techniques were applied. Table 3 summarizes \nthe preprocessing techniques applied to each dataset. For \ntraining, validation, and testing, dataset is divided into 65%, \n\n Vol.52, No2 April 2023, pp:114-119 Mahmoud M. Taha et al Engineering Research Journal (ERJ) \n \n \n \n118 \n \n15 % and 20 %. Adam method [21] was used as a c utting-\nedge optimizer. \nTABLE 3. Preprocessing applied to dataset \npreprocessing image samples \nMin-max norm \n[0,1] \nApplied \nGrayscale Images are fed to InspectorNet in \nRGB mode \nResize resized to 256 x 256 \n6. RESULTS AND EVALUATION  \nThe Danbooru dataset, which has been regularly used to \nevaluate illegal picture content detection systems, was used \nto test InspectorNet. Classification accuracy was used as a \nbenchmark metric. The complete classification results are \ndisplayed in Table 4. To further clarify the results and \ndisplay the true positive and true negative data, we also \ncreated Figure 7 and Figure 8 to show confusion matrix of \nInspectorNet and ResNet respectively. According to Table \n4, we can more accurately categorize violence us ing the \nInspectorNet architecture than ResNet for all common \ncategories like guns or violent actions. However, \nInspectorNet requires more time and computer resources to \nachieve its objectives. InspectorNet can deliver more \naccurate classification when the image resolution is \nincreased to 1024 pixels. Ultimately, InspectorNet accuracy \nwas 97.2%, which is higher than ResNet. \n \nFig 7. InspectorNet violence classification confusion matrix \n \nFig 8. ResNet violence classification confusion matrix \nTABLE 4. InspectorNet and ResNet results on Danbooru \n InspectorNet ResNet \nClasses 3 3 \nInstances 80000 80000 \nTraining period 120 hours 80 hours \nACC (%) 97.2 96.3 \n7.  CONCLUSION AND DISCUSSION OF RESULTS \nOur results indicate that InspectorNet can effectively \nclassify violent and inappropriate situations even with a \nsmall number of hyper -parameters. Figure [9] shows that \nInspectorNet shows better performance compared to  many \nneural networks on different datasets. InspectorNet's value \nis that it has a compact design that can function well with \nbetter accuracy on low -resource devices such as \nsmartphones in contrast to many current neural networks \nlike ResNet. Small variati ons among classes could also \nbenefit both the baseline and InspectorNet designs for \nanimated-cartoon datasets. In terms of training times, we \nestimate that using a Tesla K80 GPU, it should only take a \nfew days to achieve good accuracy on three classes with  \n100k pictures each (Danbooru dataset). The variety of \nproduction methods used to create cartoon films makes this \ntask challenging for most neural networks, which is what \nallows InspectorNet to outperform other neural networks \nsuch as ResNet.  \n \nFIG9. accuracy comparison between results of InspectorNet on \nDanbooru, ResNet [1] on Danbooru, Shen et al. [7] on NPDI \ndataset and Moustafa et al. [8] on NPDI-800 dataset \n8. CHALLENGES  \nTo improve classification accuracy, deep learning and \nalgorithms for blood and guns in violence can be combined. \nThis will help to eliminate incorrect classifications for \ncertain behaviors, such as red juices or toys. However, the \ndeep learning method that  only uses static data remains one \nof the most competitive action recognition techniques. \nFuture research in this field should include various elements \nin the classification process, such as speech recognition, \nvideo subtitles, and voice tone classificatio n. There are \n\n Vol.52, No2 April 2023, pp:114-119 Mahmoud M. Taha et al Engineering Research Journal (ERJ) \n \n \n \n119 \n \nmany types of animated images such as stop -motion and \nline drawings, as shown in Fig 1.  \nOur research has shown that when it comes to \nclassifying violence, InspectorNet can still outperform other \ntraditional machine learning techniques as well  as neural \nnetworks that have been specifically designed and \noptimized. However, running the training session over \nphotographs at their original size becomes very resource -\nintensive as the dimensions of input images increase, due to \nthe exponential increase in resources required.  \n \nREFERENCES   \n[1]. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep \nresidual learning for image recognition. In Proceedings of the IEEE \nconference on computer vision and pattern recognition, pages 770 –\n778, 2016. \n \n[2]. Nor Azura Ab Rahman, Tengku Maaidah Tengku A Razak, Mohd \nShahrudin Mohmud, Nur Ulfah Harun, Abi Yazid Tukiran, \nNurhidayah Muhammad Hashim, and Rosmawati Mohamad Rasit. \nThe implications of pornography addiction among adolescents. \nJournal of Positive School Psychology, 6(3):8904–8913, 2022. \n \n[3]. Kamrun Nahar Tofa, Farhana Ahmed, Arif Shakil, et al. \nInappropriate scene detection in a video stream. PhD thesis, BRAC \nUniversity, 2017. \n \n[4]. Claire-Hel´ ene Demarty, C` edric Penet, Markus Schedl, Ionescu \nBogdan,´ Vu Lam Quang, and Y u-Gang Jiang. The mediaeval 2013 \naffect task: violent scenes detection. In MediaEval 2013 Working \nNotes, page 2, 2013. \n \n[5]. Rinat Mukhometzianov and Juan Carrillo. Capsnet comparative \nperformance evaluation for image classification. arXiv preprint \narXiv:1805.11195, 2018. \n \n[6]. Jochen Peter and Patti M Valkenburg. Adolescents’ exposure to \nsexually explicit internet material, sexual uncertainty, and attitudes \ntoward uncommitted sexual exploration: Is there a link? \nCommunication Research, 35(5):579–601, 2008. \n \n[7]. Rongbo Shen, Fuhao Zou, Jingkuan Song, Kezhou Yan, and Ke \nZhou. Efui: An ensemble framework using uncertain inference for \npornographic image recognition. Neurocomputing, 322:166 –176, \n2018. \n \n[8]. Mohamed Moustafa. Applying deep learning to classify \npornographic images and videos. arXiv preprint arXiv:1511.08899, \n2015. \n \n[9]. Xin Kejun, Wu Jian, Ni Pengyu, and Huang Jie. Automatic nipple \ndetection using cascaded adaboost classifier. In 2012 Fifth \nInternational Symposium on Computational Intelligence and \nDesign, volume 2, pages 427–432. IEEE, 2012. \n[10]. Jay Mahadeokar and Gerry Pesavento. Open sourcing a deep \nlearning solution for detecting nsfw images. Retrieved August, \n24:2018, 2016. \n \n[11]. Jackson Mallmann, Altair Olivo Santin, Eduardo Kugler Viegas, \nRoger Robson dos Santos, and Jhonata n Geremias. Ppcensor: \nArchitecture for real -time pornography detection in video \nstreaming. Future Generation Computer Systems, 112:945 –955, \n2020. \n \n[12]. Deepdanbooru-v3, 2022. \nhttps://github.com/KichangKim/DeepDanbooru/releases. \n \n[13]. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, \nLlion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. \nAttention is all you need. Advances in neural information \nprocessing systems, 30, 2017. \n \n[14]. Daniel Neimark, Omri Bar, Maya Zohar, and Dotan Asselmann. \nVideo transformer network. In Proceedings of the IEEE/CVF \nInternational Conference on Computer Vision, pages 3163 –3172, \n2021. \n \n[15]. Abdel Wahab Alsammak Mahmoud Mohammed Taha, Dr. Ahmed \nB. Z aky. Filtering of inappropriate video content a survey. \nINTERNATIONAL JOURNAL OF ENGINEERING RESEARCH \nTECHNOLOGY (IJERT), 11(02), 2022. \n[16]. Danbooru2018, 2018. https://www.gwern.net/Danbooru2018. \n \n[17]. Vsd2014 dataset, 2014.\n https://www.technicolor.com/dream/researchinnovation/violent-\nscenes-dataset. \n \n[18]. kinetics dataset. https://deepmind.com/research/open-\nsource/opensource-datasets/kinetics/. \n \n[19]. Ucf-101 dataset. https://www.crcv.ucf.edu/research/data-\nsets/humanactions/ucf101/. \n \n[20]. youtube8m dataset. https://research.google.com/youtube8m/. \n \n[21]. Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic \noptimization. arXiv preprint arXiv:1412.6980, 2014.  \n \n ",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.5317386984825134
    },
    {
      "name": "Computer science",
      "score": 0.4530567228794098
    },
    {
      "name": "Engineering",
      "score": 0.14966616034507751
    },
    {
      "name": "Electrical engineering",
      "score": 0.08636873960494995
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I207547235",
      "name": "Benha University",
      "country": "EG"
    },
    {
      "id": "https://openalex.org/I32619867",
      "name": "Egypt-Japan University of Science and Technology",
      "country": "EG"
    }
  ],
  "cited_by": 7
}