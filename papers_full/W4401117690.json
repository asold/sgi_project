{
  "title": "Do Multimodal Large Language Models and Humans Ground Language Similarly?",
  "url": "https://openalex.org/W4401117690",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3161224970",
      "name": "Jones Cameron",
      "affiliations": [
        "University of California, San Diego"
      ]
    },
    {
      "id": "https://openalex.org/A4223174036",
      "name": "Bergen, Benjamin",
      "affiliations": [
        "University of California, San Diego"
      ]
    },
    {
      "id": "https://openalex.org/A4223174035",
      "name": "Trott, Sean",
      "affiliations": [
        "University of California, San Diego"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2150375089",
    "https://openalex.org/W3034723486",
    "https://openalex.org/W6739715551",
    "https://openalex.org/W2082928871",
    "https://openalex.org/W3100307207",
    "https://openalex.org/W2112184938",
    "https://openalex.org/W3201264086",
    "https://openalex.org/W2505756961",
    "https://openalex.org/W4388691863",
    "https://openalex.org/W2143623448",
    "https://openalex.org/W2104817141",
    "https://openalex.org/W2127716180",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W4376117416",
    "https://openalex.org/W6784333009",
    "https://openalex.org/W6850503672",
    "https://openalex.org/W2944339144",
    "https://openalex.org/W2157853130",
    "https://openalex.org/W2130663341",
    "https://openalex.org/W4386071707",
    "https://openalex.org/W3196974791",
    "https://openalex.org/W2107019937",
    "https://openalex.org/W2962862718",
    "https://openalex.org/W1975909437",
    "https://openalex.org/W4385571325",
    "https://openalex.org/W6850015000",
    "https://openalex.org/W6912494966",
    "https://openalex.org/W2292919134",
    "https://openalex.org/W4214829911",
    "https://openalex.org/W4389523650",
    "https://openalex.org/W6789753369",
    "https://openalex.org/W2798881773",
    "https://openalex.org/W4401042840",
    "https://openalex.org/W1861492603",
    "https://openalex.org/W4381802186",
    "https://openalex.org/W2149544884",
    "https://openalex.org/W2091301585",
    "https://openalex.org/W6851781724",
    "https://openalex.org/W3119485017",
    "https://openalex.org/W2022856253",
    "https://openalex.org/W2058419803",
    "https://openalex.org/W4224875474",
    "https://openalex.org/W2153469952",
    "https://openalex.org/W6791353385",
    "https://openalex.org/W6846007759",
    "https://openalex.org/W4391215636",
    "https://openalex.org/W2171622898",
    "https://openalex.org/W6860561321",
    "https://openalex.org/W4323653446",
    "https://openalex.org/W4383058631",
    "https://openalex.org/W2587573685",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2321200616",
    "https://openalex.org/W4391094120",
    "https://openalex.org/W4382202923",
    "https://openalex.org/W2170014302",
    "https://openalex.org/W2148848230",
    "https://openalex.org/W4362655601",
    "https://openalex.org/W3166396011",
    "https://openalex.org/W4248040599",
    "https://openalex.org/W2632333391",
    "https://openalex.org/W3126792443",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4402754023",
    "https://openalex.org/W4323572061",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4388963454",
    "https://openalex.org/W2137010615",
    "https://openalex.org/W4388685645",
    "https://openalex.org/W4322718246",
    "https://openalex.org/W604097133",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W4306820534"
  ],
  "abstract": "Abstract Large Language Models (LLMs) have been criticized for failing to connect linguistic meaning to the world—for failing to solve the “symbol grounding problem.” Multimodal Large Language Models (MLLMs) offer a potential solution to this challenge by combining linguistic representations and processing with other modalities. However, much is still unknown about exactly how and to what degree MLLMs integrate their distinct modalities—and whether the way they do so mirrors the mechanisms believed to underpin grounding in humans. In humans, it has been hypothesized that linguistic meaning is grounded through “embodied simulation,” the activation of sensorimotor and affective representations reflecting described experiences. Across four pre-registered studies, we adapt experimental techniques originally developed to investigate embodied simulation in human comprehenders to ask whether MLLMs are sensitive to sensorimotor features that are implied but not explicit in descriptions of an event. In Experiment 1, we find sensitivity to some features (color and shape) but not others (size, orientation, and volume). In Experiment 2, we identify likely bottlenecks to explain an MLLM’s lack of sensitivity. In Experiment 3, we find that despite sensitivity to implicit sensorimotor features, MLLMs cannot fully account for human behavior on the same task. Finally, in Experiment 4, we compare the psychometric predictive power of different MLLM architectures and find that ViLT, a single-stream architecture, is more predictive of human responses to one sensorimotor feature (shape) than CLIP, a dual-encoder architecture—despite being trained on orders of magnitude less data. These results reveal strengths and limitations in the ability of current MLLMs to integrate language with other modalities, and also shed light on the likely mechanisms underlying human language comprehension.",
  "full_text": null,
  "topic": "Embodied cognition",
  "concepts": [
    {
      "name": "Embodied cognition",
      "score": 0.7454756498336792
    },
    {
      "name": "Computer science",
      "score": 0.6638346910476685
    },
    {
      "name": "Modalities",
      "score": 0.6518759727478027
    },
    {
      "name": "Meaning (existential)",
      "score": 0.5778071284294128
    },
    {
      "name": "Task (project management)",
      "score": 0.5104936361312866
    },
    {
      "name": "Modality (human–computer interaction)",
      "score": 0.4976239502429962
    },
    {
      "name": "Cognitive psychology",
      "score": 0.49717190861701965
    },
    {
      "name": "Sensitivity (control systems)",
      "score": 0.42425474524497986
    },
    {
      "name": "Artificial intelligence",
      "score": 0.42239412665367126
    },
    {
      "name": "Common ground",
      "score": 0.4145314693450928
    },
    {
      "name": "Natural language processing",
      "score": 0.3960312306880951
    },
    {
      "name": "Cognitive science",
      "score": 0.35878604650497437
    },
    {
      "name": "Linguistics",
      "score": 0.32089361548423767
    },
    {
      "name": "Psychology",
      "score": 0.2851361036300659
    },
    {
      "name": "Communication",
      "score": 0.20700126886367798
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Electronic engineering",
      "score": 0.0
    },
    {
      "name": "Psychotherapist",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Engineering",
      "score": 0.0
    },
    {
      "name": "Social science",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    }
  ]
}