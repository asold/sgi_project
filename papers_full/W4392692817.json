{
  "title": "LLM-Assisted Data Augmentation for Chinese Dialogue-Level Dependency Parsing",
  "url": "https://openalex.org/W4392692817",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2127176296",
      "name": "Meishan Zhang",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3091345272",
      "name": "Gongyao Jiang",
      "affiliations": [
        "Tianjin University"
      ]
    },
    {
      "id": "https://openalex.org/A2100870932",
      "name": "Shuang Liu",
      "affiliations": [
        "Tianjin University"
      ]
    },
    {
      "id": "https://openalex.org/A1964638924",
      "name": "Jing Chen",
      "affiliations": [
        "Ministry of Science ICT and Future Planning"
      ]
    },
    {
      "id": "https://openalex.org/A2005452123",
      "name": "Min Zhang",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2251483872",
    "https://openalex.org/W6732196124",
    "https://openalex.org/W6856800273",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2044599851",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W6771917389",
    "https://openalex.org/W3021636956",
    "https://openalex.org/W6850627791",
    "https://openalex.org/W2970060563",
    "https://openalex.org/W6729856301",
    "https://openalex.org/W3174828871",
    "https://openalex.org/W4311187195",
    "https://openalex.org/W4385570861",
    "https://openalex.org/W2798560962",
    "https://openalex.org/W4301881503",
    "https://openalex.org/W4389519060",
    "https://openalex.org/W2158211888",
    "https://openalex.org/W2950739345",
    "https://openalex.org/W3097513514",
    "https://openalex.org/W2093647425",
    "https://openalex.org/W6611342419",
    "https://openalex.org/W6606475831",
    "https://openalex.org/W6810738896",
    "https://openalex.org/W6851960618",
    "https://openalex.org/W6691346535",
    "https://openalex.org/W2994806031",
    "https://openalex.org/W2892131163",
    "https://openalex.org/W2111316763",
    "https://openalex.org/W3176923149",
    "https://openalex.org/W2152977846",
    "https://openalex.org/W6850625674",
    "https://openalex.org/W6854866820",
    "https://openalex.org/W2025183033",
    "https://openalex.org/W4385572845",
    "https://openalex.org/W6809646742",
    "https://openalex.org/W4389519448",
    "https://openalex.org/W2096204319",
    "https://openalex.org/W2250737685",
    "https://openalex.org/W6745136726",
    "https://openalex.org/W158861739",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W2759181158",
    "https://openalex.org/W4362707064",
    "https://openalex.org/W4212774754",
    "https://openalex.org/W2895715183",
    "https://openalex.org/W3102725307",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4322759378"
  ],
  "abstract": "Abstract Dialogue-level dependency parsing, despite its growing academic interest, often encounters underperformance issues due to resource shortages. A potential solution to this challenge is data augmentation. In recent years, large language models (LLMs) have demonstrated strong capabilities in generation, which can facilitate data augmentation greatly. In this study, we focus on Chinese dialogue-level dependency parsing, presenting three simple and effective strategies with LLM to augment the original training instances, namely word-level, syntax-level, and discourse-level augmentations, respectively. These strategies enable LLMs to either preserve or modify dependency structures, thereby assuring accuracy while increasing the diversity of instances at different levels. We conduct experiments on the benchmark dataset released by Jiang et al. (2023) to validate our approach. Results show that our method can greatly boost the parsing performance in various settings, particularly in dependencies among elementary discourse units. Lastly, we provide in-depth analysis to show the key points of our data augmentation strategies.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7814480662345886
    },
    {
      "name": "Dependency grammar",
      "score": 0.7362391352653503
    },
    {
      "name": "Dependency (UML)",
      "score": 0.6660077571868896
    },
    {
      "name": "Parsing",
      "score": 0.570266604423523
    },
    {
      "name": "Natural language processing",
      "score": 0.5293384790420532
    },
    {
      "name": "Artificial intelligence",
      "score": 0.40836524963378906
    }
  ]
}