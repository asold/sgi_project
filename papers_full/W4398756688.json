{
    "title": "Beyond Accuracy: Evaluating Source Code Capabilities in Large Language Models for Software Engineering",
    "url": "https://openalex.org/W4398756688",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2022223381",
            "name": "Alejandro Velasco",
            "affiliations": [
                "Williams (United States)",
                "William & Mary"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3092292656",
        "https://openalex.org/W3167361329",
        "https://openalex.org/W2907705732",
        "https://openalex.org/W2951025380",
        "https://openalex.org/W4394644794",
        "https://openalex.org/W4309796572",
        "https://openalex.org/W3035281110",
        "https://openalex.org/W4319792276",
        "https://openalex.org/W2101105183",
        "https://openalex.org/W4287780384",
        "https://openalex.org/W4288334056",
        "https://openalex.org/W4221167729",
        "https://openalex.org/W3005628256",
        "https://openalex.org/W4283026156",
        "https://openalex.org/W3105903381"
    ],
    "abstract": "This dissertation aims to introduce interpretability techniques to comprehensively evaluate the performance of Large Language Models (LLMs) in software engineering tasks, beyond canonical metrics. In software engineering, Deep Learning techniques are widely employed across various domains, automating tasks such as code comprehension, bug fixing, code summarization, machine translation, and code generation. However, the prevalent use of accuracy-based metrics for evaluating Language Models trained on code often leads to an overestimation of their performance. Our work seeks to propose novel and comprehensive interpretability techniques to evaluate source code capabilities and provide a more nuanced understanding of LLMs performance across downstream tasks.",
    "full_text": null
}