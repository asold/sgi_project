{
    "title": "BiRNA-BERT allows efficient RNA language modeling with adaptive tokenization",
    "url": "https://openalex.org/W4400378440",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A4209144206",
            "name": "Md Toki Tahmid",
            "affiliations": [
                "Bangladesh University of Engineering and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A5019384744",
            "name": "Haz Sameen Shahgir",
            "affiliations": [
                "University of California, Riverside"
            ]
        },
        {
            "id": "https://openalex.org/A2975069290",
            "name": "Sazan Mahbub",
            "affiliations": [
                "Carnegie Mellon University"
            ]
        },
        {
            "id": "https://openalex.org/A2116208385",
            "name": "Yue Dong",
            "affiliations": [
                "University of California, Riverside"
            ]
        },
        {
            "id": "https://openalex.org/A2585600580",
            "name": "Md Shamsuzzoha Bayzid",
            "affiliations": [
                "Bangladesh University of Engineering and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A4209144206",
            "name": "Md Toki Tahmid",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5019384744",
            "name": "Haz Sameen Shahgir",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2975069290",
            "name": "Sazan Mahbub",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2116208385",
            "name": "Yue Dong",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2585600580",
            "name": "Md Shamsuzzoha Bayzid",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2119309676",
        "https://openalex.org/W3101140821",
        "https://openalex.org/W4225858649",
        "https://openalex.org/W2996035354",
        "https://openalex.org/W2899798803",
        "https://openalex.org/W4200135473",
        "https://openalex.org/W4316339774",
        "https://openalex.org/W4384648639",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W3177500196",
        "https://openalex.org/W4313304472",
        "https://openalex.org/W2158381555",
        "https://openalex.org/W4392716400",
        "https://openalex.org/W3127238141",
        "https://openalex.org/W3177828909",
        "https://openalex.org/W3005454931",
        "https://openalex.org/W2018140810",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4382603228",
        "https://openalex.org/W4392425739",
        "https://openalex.org/W3196318247",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W3135625811",
        "https://openalex.org/W2099747733",
        "https://openalex.org/W3048090444",
        "https://openalex.org/W1816313093",
        "https://openalex.org/W1995875735",
        "https://openalex.org/W2973727699",
        "https://openalex.org/W3164094081",
        "https://openalex.org/W4388979610",
        "https://openalex.org/W3155806510",
        "https://openalex.org/W3027554922",
        "https://openalex.org/W2089649677",
        "https://openalex.org/W4384405439",
        "https://openalex.org/W4387966606",
        "https://openalex.org/W4225917625",
        "https://openalex.org/W3161531818",
        "https://openalex.org/W4388539614",
        "https://openalex.org/W4382490702"
    ],
    "abstract": "Abstract Recent advancements in Transformer-based models have spurred interest in their use for biological sequence analysis. However, adapting models like BERT is challenging due to sequence length, often requiring truncation for proteomics and genomics tasks. Additionally, advanced tokenization and relative positional encoding techniques for long contexts in NLP are often not directly transferable to DNA/RNA sequences, which require nucleotide or character-level encodings for tasks such as 3D torsion angle prediction. To tackle these challenges, we propose an adaptive dual tokenization scheme for bioinformatics that utilizes both nucleotide-level (NUC) and efficient BPE tokenizations. Building on the dual tokenization, we introduce BiRNA-BERT, a 117M parameter Transformer encoder pretrained with our proposed tokenization on 28 billion nucleotides across 36 million coding and non-coding RNA sequences. The learned representation by BiRNA-BERT generalizes across a range of applications and achieves state-of-the-art results in long-sequence downstream tasks and achieves a performance comparable to 6× larger models in short-sequence tasks with 27×less pre-training compute. BiRNA-BERT can dynamically adjust its tokenization strategy based on sequence lengths, utilizing NUC for shorter sequences and switching to BPE for longer ones, thereby offering, for the first time, the capability to efficiently handle arbitrarily long DNA/RNA sequences. 1",
    "full_text": null
}