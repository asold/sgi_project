{
    "title": "Can Large Language Models Better Predict Software Vulnerability?",
    "url": "https://openalex.org/W4383334244",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2622533356",
            "name": "Evangelos Katsadouros",
            "affiliations": [
                "University of West Attica"
            ]
        },
        {
            "id": "https://openalex.org/A394975251",
            "name": "Charalampos Z. Patrikakis",
            "affiliations": [
                "University of West Attica"
            ]
        },
        {
            "id": "https://openalex.org/A2050725967",
            "name": "George Hurlburt",
            "affiliations": [
                "Tall Timbers Research Station and Land Conservancy"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6852887568",
        "https://openalex.org/W6851748684",
        "https://openalex.org/W6853672345",
        "https://openalex.org/W6850710855",
        "https://openalex.org/W3137781054",
        "https://openalex.org/W6767260250",
        "https://openalex.org/W2885030880",
        "https://openalex.org/W2962960733",
        "https://openalex.org/W6783197149",
        "https://openalex.org/W4312436517",
        "https://openalex.org/W3111602563",
        "https://openalex.org/W2985739320",
        "https://openalex.org/W2064675550",
        "https://openalex.org/W2781491433",
        "https://openalex.org/W2950087183",
        "https://openalex.org/W4366342667",
        "https://openalex.org/W4287673430",
        "https://openalex.org/W3127736190",
        "https://openalex.org/W2972135640",
        "https://openalex.org/W4321854066",
        "https://openalex.org/W4379538552",
        "https://openalex.org/W4367860052",
        "https://openalex.org/W3101228802"
    ],
    "abstract": "The analysis of software for software vulnerability has matured over the years. In the beginning, linear approaches were tried to isolate known vulnerabilities via after-the-fact static analysis. As neural nets and machine learning became useful, more dynamic approaches were applied, It will be interesting to see what the new wave of Generative Artificial intelligence can contribute to the realm of assessing software vulnerabilities.",
    "full_text": "FROM THE EDITORS\nCan Large Language Models Better Predict\nSoftware Vulnerability?\nEvangelos Katsadouros and Charalampos Z. Patrikakis, University of West Attica, 12241, Greece\nGeorge Hurlburt , STEMCorp, Tall Timbers, MD, 20690, USA\nI\nn the last decade, the world has witnessed signiﬁ-\ncant data breaches that considerably compromised\nsensitive data (including personal information) and\nresulted in substantialﬁnancial penalties to the com-\npanies responsible for safeguarding this information.\nThe emergence of data protection regulations has\nemphasized the importance of software quality, partic-\nularly the need for robust mechanisms and methodolo-\ngies to ensure the security of developed systems.\nMaking sure that advanced software supporting appli-\ncations and services, especially in the fully intercon-\nnected world of the Internet of Everything, are free of\nvulnerabilities has become of utmost importance. The\nmassive use of complex applications continues to\ngrow, while the criticality of the systems that produc-\ntion software manages or monitors has increased sev-\neral times.\nThis leads to a need to pass from an era of human-\nbased code evaluation in search of potential vulnerabil-\nities to the adoption and use of automated formalized\nmethods and state-of-the-art techniques. This applies\nto code analysis and, importantly, to detecting poten-\ntial risks and vulnerabilities in the code. And, of course,\nwho can deny the involvement of AI in such an initia-\ntive, especially after the extraordinary potential that\nlarge language model (LLM) prompt engineering is\ndemonstrating in programming code development?\nIn this article, we glimpse things to come in soft-\nware vulnerability prediction (SVP), presenting the cur-\nrent situation and exploring why research has turned\nto a new AI-inﬂuenced era. We conclude with an analy-\ns i so fL L M sf o rS V P .\nCURRENT STATIC APPROACHES\nIN SVP\nIn the course of discovering software vulnerabilities,\nseveral approaches have been proposed, focusing on\nthe analysis of code to discover potentially critical\ncomponents or code vulnerabilities. In the following\nlist, we present a brief reference to these approaches:\nTaxonomical analysis has yielded some pioneering\ntools and platforms resulting from extensive efforts\nto analyze vulnerabilities in software through taxon-\nomies. For example, MITRE’s Common Weakness\nEnumeration\na classiﬁes and describes vulnera-\nbilities. MITRE has established a list of the top\n25 software weaknesses. Software developers\nidentify and address vulnerabilities through such\nstatic analysis tools. This class of tools scans\ncodes to identify potential embeddedﬂaws. They\nemploy techniques such as pattern matching to\ndetect speciﬁc patterns thatﬂag potential vul-\nnerabilities within the test codebase. Maintaining\nlists of known vulnerable code patterns or rules,\nthese tools compare the code under test toﬁnd\nany matching cases by utilizing pattern-matching\nalgorithms and other weeding-out approaches to\nisolate potentialﬂaws.\nLexical analysis is a widely adopted method for\nanalyzing code to uncover potential vulnerabil-\nities. In lexical analysis, the code is broken\ndown into tokens, and the tools analyze the\nstructure and sequence of these tokens to\nidentify ﬂaws.\nSoftware metrics represent another approach to\ncode analysis. One such metric is cyclomatic\ncomplexity, which helps determine well-designed\nand implemented code with minimal duplication.\nBy leveraging metrics like cyclomatic complexity,\nthe tools can identify potentialﬂaws within the\ncode.\nStatic code analysis tools often utilize the tech-\nniques mentioned in tandem to analyze static\ncode and detect vulnerabilities and bugs. How-\never, recent research indicates that these tools\nemploying such techniques often struggle to\nidentify ﬂaws within the code accurately.\n1520-9202 © 2023 IEEE\nDigital Object Identiﬁer 10.1109/MITP.2023.3284628\nDate of current version 30 June 2023. ahttps://cwe.mitre.org/\n4 IT Professional Published by the IEEE Computer Society May/June 2023\nHowever, there are limitations and problems related\nto each of these techniques. Considering the diverse\nnature of vulnerabilities and programming languages,\none major issue is deﬁning distinct rules and knowledge\nfor each language. This is time-consuming, especially\nas scaling up for new vulnerabilities becomes more\nand more challenging. On the other hand, generalized\napproaches that do not explicitly refer to or link to spe-\nciﬁc vulnerabilities introduce the challenge of deﬁning\nthe correct features at a higher, more abstract level.\nThis practice, however, usually proves too complex to\nbe effectively evaluated by humans. Finally, using tools\nto analyze the code presents the problem of generating\na high number of false positives and false negatives.\nThis problem undermines the performance of software\nengineering analysis.\nTherefore, the need for a new approach character-\nized by the agility and adaptability to cope with a\nchanging environment where new vulnerabilities are\nadded to the list of existing ones is obvious. And, of\nIN THIS ISSUE\nT\nhe May/June 2023 edition ofIT Professionalis a\nspecial edition dealing with future generations of\ncommunications technology. Thex in xG, whatever the\nvalue ofx, will undoubtedly lead to vastly improved\ncommunications and yet will bring new security\nconcerns. Hence, this edition’s feature articles focus on\nthe very real world of cybersecurity.\nWe lead off with“DDoS at a Glance: Attack Launch\nto Solutions,” by Anmol Kumar and Gaurav Somani.\nA1\nThis article examines the growing rate of distributed\ndenial of service (DDoS) attacks from six different\nperspectives. As this common form of attack continues\nto gain stealth and sophistication, the authors conclude\nthat improved insights into trace datasets, application\nvulnerabilities, and attack practices must be reinforced.\n“Malware Detection and Classiﬁcation Based on\nGraph Convolutional Networks and Function Call\nGraphs,” by Dr. Ma et al.,\nA2 examines the detection and\nclassiﬁcation of malware, another prevalent cyber\nthreat. The authors employ graph convolutional\nnetworks (GCNs) and function call graphs. First, they\nisolate malware characteristics via a GCN. Then, using\napplication programming interfaces and their underlying\nsemantic features in a function call graph, they can\ncharacterize the malware behavior with high accuracy.\nSecurity becomes a signiﬁcant concern as the\nindustrial metaverse continues to take hold.“Metaverse\nor Metaworst With Cybersecurity Attacks,” by\nAkashdeep Bjardwaj and Keshav Kaushik,\nA3 examines\nthis concern from the privacy and security perspectives.\nThe authors conclude that, even with encryption,\ncommunications systems associated with metaverse\nsettings remain rife with vulnerabilities that must be\naddressed if privacy and security are to be adequately\nenforced.\n“New Frontiers in Security Risk Management,” by\nLuis Enrique S/C19anchez et al.,\nA4 examines the history,\npresent instantiation, and future of information security\nrisk analysis methods (ISRAMs). As systems continue to\nbecome more dynamically interdependent, the authors\nconclude that ISRAMs must take full advantage of\nunifying emergent technologies combined with an\nontological and robust metadata baseline.\nTo add some spice to our features, we conclude with\n“Digital Twin of a Digital World: Process, Data, and\nExperience Perspectives,” by Suraj G. Jadhav and Surendra\nSarnikar.\nA5 This article examines ways to arrive at an\nintegrated and dynamic“digital twin of a digital world”\nframework that goes well beyond merely linking silos.\nThe columns and departments for this issue are also\nof high interest.\nNir Kshetri continues the cybersecurity thread in his\nIT Economics department. In“Cybercrime and Privacy\nThreats of Large Language Models,”A6 he provides a\ntimely survey that adds additional insight into the hot\ntopic of generative AI.\nIn From the C-Suite, Steve Andriole offers“Truth-\nTalking in the C-Suite.”\nA7 He maintains that leaders need\nto hear and accept truth to make effective decisions,\nbut there are numerous barriers to bringing truth to\npower without, often, severe risks and repercussions. He\noffers a tantalizing solution.\nFinally, in IT Trends, Clayton S. Ferner speaks to\n“Card Game to Demonstrate Quantum Key Exchange.”\nA8\nThis department describes features of a quantum\nalgorithm that permit the detection of a third party to a\nprivate key-protected quantum exchange. Using a\nsimple card game, the author can indoctrinate students\nin the workings of this otherwise complex algorithm.\nWe hope you enjoy this edition ofIT Professional.\nFROM THE EDITORS\nMay/June 2023 IT Professional 5\ncourse, given the vast potential of AI, the AI domain is\nwhere we should look for new tools.\nAI FOR VULNERABILITY\nDETECTION: EARLY INITIATIVES\nIn the last decade, researchers put great effort into\nresearching the use of AI in vulnerability prediction. The\nﬁndings of this research reveal that AI has the potential\nto achieve better and more accurate results inﬁnding\nvulnerabilities and bugs within code. In the veryﬁrst\nstage of this era, researchers utilized conventional AI,\nlike logistic regression, support vector machines, and\nrandom forests. The problem with those approaches\nwas that researchers had toﬁnd features that describe\nsoftware vulnerabilities. To this end, researchers in\nmost studies decided to use metrics like the cyclomatic\ncomplexity mentioned earlier. Using such metrics didn’t\nwork as expected since software metrics are not tightly\nrelated to software vulnerabilities, and researchers had\nto ﬁnd higher level features, a task that, as mentioned\npreviously, is not human friendly.\nFollowing the failure of conventional machine learn-\ning techniques to yield good vulnerability prediction\nresults, researchers turned to deep learning. Deep learn-\ning models can demonstrate higher complexity and\n“intelligence” than traditional machine learning, as, on\nthe one hand, they have more layers and can exploit\nhigher level features that humans cannot interpret.\nRecent research proposes the use of deep neural\nnetworks (DNNs) like convolutional neural networks\n(CNNs), recurrent neural networks (RNNs), and trans-\nformers to tackle the problem of vulnerability prediction.\nResearchers have tried different DNN architectures,\nwith the results outperforming both conventional\nmachine learning and legacy approaches.\nA CNN is a DNN architecture that employs inputﬁl-\nters to extract local features. CNNs are capable of\nprocessing sequential linear data. In most cases, CNNs\nconsist of multiple convolutional layers followed by\npooling layers, which help aggregate valuable informa-\ntion at each layer. Several studies in SVP applied CNNs\nin the vulnerability prediction process,\n1,2 achieving\npromising results. An abstract description of how\nCNNs can be used in vulnerability prediction is that the\ncode samples are transformed into numerical vectors\nusing embedding networks fed into the CNN so that\nthe network can analyze them and learn from them.\nHowever, CNNs need help learning long dependencies\nwithin code, which might limit them, yielding poor\nresults.\nRNNs work with sequential data, such as text.\nRNNs maintain an internal state, which feeds back to\nthe following input. In that way, RNNs capture temporal\ndependencies. RNNs suffer from vanishing/exploding\ngradient problems and fail to capture long dependen-\ncies, so long short-term memory\n3 is used to overcome\nthis problem.\nA transformer also processes sequential data in\nparallel, using the attention mechanism to focus on\nand process different input parts, allowing it to capture\nlong sample dependencies. Researchers utilized these\narchitectures to propose different approaches in vul-\nnerability prediction.\n4,5,6,7 Most of these studies have\nachieved extraordinary results of F1 scores above 90%\nand relatively low false positive and false negatives\nrates.\nThough the results of this research indicate that\nthe use of AI for vulnerability detection is sufﬁciently\nmature to replace legacy approaches, there is research\nwork that advocates for the opposite. Chakraborty\net al.\n8 c o n c l u d e dt h a tm o s tm o d e l sw i t hh i g ha c c u r a c y\nof up to 95% fail to perform equally well on new,\nunseen real-world cases. They observed that the stud-\nies used to evaluate the performance of the models\nused often employ synthetic or semisynthetic datasets\nfor model training, and some models are evaluated\nusing only a subset of the dataset they were trained on\nrather than being exposed to completely unseen proj-\nects. Such training practices lead to inaccurate results,\nas the models have learned to perform well only on the\nlimited set of code examples on which they were\ntrained. Therefore, the main objective in vulnerability\nprediction research is to develop models that will oper-\nate across diverse codebases equally well.\nRecently, research in theﬁeld of vulnerability predic-\ntion has focused on the use of graph neural networks\n(GNNs).\n8,9,10,11 GNNs are DNN architectures capable of\nprocessing nonlinear data, such as graphs. Internally, the\nmechanisms that GNNs use are well-known mechanisms\nlike convolutions and attention. GNN approaches in vul-\nnerability prediction have achieved promising results. A\nGNN can process graphs, making it a good candidate for\nvulnerability prediction. This is because the code is well\nstructured, and we process code in graphs. Using graph\nrepresentations of code, we can further preprocess them\nto create a more general representation of the code sam-\nples, thus increasing the generalization.\nWHAT’S NEXT: HARNESSING\nLLMs\nThough the potential of using modern AI techniques,\nparticularly neural networks, is evident, further\nresearch is required in DNN architectures to develop a\nsolution that effectively works over code embracing\nFROM THE EDITORS\n6 IT Professional May/June 2023\ndiverse programming languages. Hybrid approaches\nmay lead to more complete models performing well on\nunseen code. Nevertheless, the success of LLMs, such\nas generative pretrained transformers, in generating\nnot only comprehensible human text, even holding\na conversation, but also producing correct code\nﬁelds\n12,13 points in the direction of investigating the\nuse of LLMs in predicting code vulnerabilities.\nObvious beneﬁts of using LLMs as knowledge\nagents in software engineering are increasing aware-\nness and boosting the security knowledge of software\nengineers. Of course, to use LLMs for software vulnera-\nbility detection and prevention,ﬁrst, we should ensure\nthat the corresponding models can generate error-free\ncode beyond basic compiler checking. Once this is\nensured, LLMs could be used to generate vulnerable\ncode samples focusing on speciﬁc vulnerabilities and\naugment existing datasets.\nAnother beneﬁt of the use of LLMs is the produc-\ntion of diverse code. Further research is again required\nto ascertain LLMs’ efﬁcacy and accuracy in producing\ndiverse code. Assuming this capability can be veriﬁed,\nLLMs could signiﬁcantly boost software vulnerability\ndetection research by creating large datasets of\ndiverse code samples. This can yield the potential to\ncreate models that generalize to unseen code.\nThough we cannot yet predict if using LLMs in soft-\nware vulnerability detection could provide a better tool\nfor automatically detecting software vulnerabilities,\nthe results from using LLMs in several domains indi-\ncate that their use led to some positive results. The\nauthors are conﬁdent that further research in this\ndirection will emerge. Even at the time that this article\nis written, early works in this direction have already\nstarted to be published in the form of preprints or in\nonline repositories.\n14,15\nAPPENDIX: RELATED ARTICLES\nA1. A. Kumar and G. Somani,“DDoS at a glance:\nAttack launch to solutions,” IT Prof., vol. 25, no. 3,\npp. 36– 42, May/Jun. 2023, doi:10.1109/MITP.2023.\n3273295.\nA2. H.-Y. Chuang, J.-L. Chen, and Y.-W. Ma,“Malware\ndetection and classiﬁcation based on graph\nconvolutional networks and function call graphs,”\nIT Prof., vol. 25, no. 3, pp. 43– 53, May/Jun. 2023,\ndoi: 10.1109/MITP.2023.3264509.\nA3. A. Bhardwaj and K. Kaushik,“Metaverse or\nmetaworst with cybersecurity attacks,” IT Prof.,\nvol. 25, no. 3, pp. 54– 60, May/Jun. 2023,\ndoi: 10.1109/MITP.2023.3241445.\nA4. L. E. S/C19anchez, A. Santos-Olmo, H. Mouratidis, and\nE. Fern/C19andez-Medina, “New frontiers in security risk\nmanagement,” IT Prof., vol. 25, no. 3, pp. 61– 67,\nMay/Jun. 2023, doi:10.1109/MITP.2023.3251720.\nA5. S. G. Jadhav and S. Sarnikar,“Digital twin of a digital\nworld: Process, data, and experience perspectives,”\nIT Prof., vol. 25, no. 3, pp. 68– 73, May/Jun. 2023,\ndoi: 10.1109/MITP.2023.3264209.\nA6. N. Kshetri, “Cybercrime and privacy threats of\nlarge language models,” IT Prof., vol. 25, no. 3,\npp. 9– 13, May/Jun. 2023, doi:10.1109/MITP.2023.\n3275489.\nA7. S. J. Andriole,“Truth talking in the C-suite,” IT Prof.,\nvol. 25, no. 3, pp. 14– 16, May/Jun. 2023, doi:10.1109/\nMITP.2023.3275490.\nA8. C. S. Ferner,“Card game to demonstrate quantum\nkey exchange,” IT Prof., vol. 25, no. 3, pp. 74– 77,\nMay/Jun. 2023, doi:10.1109/MITP.2023.3279688.\nREFERENCES\n1. R. Russell et al.,“Automated vulnerability detection in\nsource code using deep representation learning,” in\nProc. 17th IEEE Int. Conf. Mach. Learn. Appl. (ICMLA),\nDec. 2018, pp. 757– 762, doi:10.1109/ICMLA.2018.00120.\n2. Z. Li, D. Zou, S. Xu, H. Jin, Y. Zhu, and Z. Chen,\n“SySeVR: A framework for using deep learning to\ndetect software vulnerabilities,” IEEE Trans.\nDependable Secure Comput., vol. 19, no. 4,\npp. 2244– 2258, Jul./Aug. 2022, doi:10.1109/TDSC.2021.\n3051525.\n3. S. Hochreiter and J. Schmidhuber,“Long short-term\nmemory,” Neural Comput., vol. 9, no. 8, pp. 1735– 1780,\nNov. 1997, doi:10.1162/neco.1997.9.8.1735.\n4. Y. Fang, S. Han, C. Huang, and R. Wu,“TAP: A static\nanalysis model for PHP vulnerabilities based on token\nand deep learning technology,” PLoS One, vol. 14,\nno. 11, Nov. 2019, Art. no. e0225196, doi:10.1371/journal.\npone.0225196.\n5. R. Li, C. Feng, X. Zhang, and C. Tang,“A lightweight\nassisted vulnerability discovery method using\ndeep neural networks,” IEEE Access, vol. 7,\npp. 80,079– 80,092, Jun. 2019, doi:10.1109/ACCESS.2019.\n2923227.\n6. Z. Li et al.,“VulDeePecker: A deep learning-based\nsystem for vulnerability detection,” in Proc. Netw.\nDistrib. Syst. Secur. Symp., 2018, pp. 1– 15, doi:10.14722/\nndss.2018.23158.\n7. M. Fu and C. Tantithamthavorn,“LineVul: A\ntransformer-based line-level vulnerability prediction,”\nin Proc. 19th Int. Conf. Mining Softw. Repositories\n(MSR), New York, NY, USA: Association for Computing\nFROM THE EDITORS\nMay/June 2023 IT Professional 7\nMachinery, Oct. 2022, pp. 608– 620, doi:10.1145/\n3524842.3528452.\n8. S. Chakraborty, R. Krishna, Y. Ding, and B. Ray,“Deep\nlearning based vulnerability detection: Are we there\nyet?” Sep. 2020. [Online]. Available: http://arxiv.org/\nabs/2009.07235\n9. H. Wang et al.,“Combining graph-based learning with\nautomated data collection for code vulnerability\ndetection,” IEEE Trans. Inf. Forensics Secur., vol. 16,\npp. 1943– 1958, 2021, doi:10.1109/TIFS.2020.3044773.\n10. Y. Zhou, S. Liu, J. Siow, X. Du, and Y. Liu,“Devign:\nEffective vulnerability identiﬁcation by learning\ncomprehensive program semantics via graph neural\nnetworks,” Sep. 2019. [Online]. Available: http://\narxiv.org/abs/1909.03496\n11. S. Cao, X. Sun, L. Bo, Y. Wei, and B. Li,“BGNN4VD:\nConstructing bidirectional graph neural-network for\nvulnerability detection,” Inf. Softw. Technol., vol. 136,\nAug. 2021, Art. no. 106576, doi:10.1016/j.infsof.2021.\n106576.\n12. Y. Dong, X. Jiang, Z. Jin, and G. Li,“Self-collaboration\ncode generation via ChatGPT,” May 2023. [Online].\nAvailable: http://arxiv.org/abs/2304.07590\n13. J. Liu, C. S. Xia, Y. Wang, and L. Zhang,“Is your code\ngenerated by ChatGPT really correct? Rigorous\nevaluation of large language models for code\ngeneration,” May 2023. [Online]. Available: http://\narxiv.org/abs/2305.01210\n14. M. Omar, “Detecting software vulnerabilities using\nLanguage Models,” Feb. 2023. [Online]. Available:\nhttps://doi.org/10.48550/arXiv.2302.11773\n15. A. Chan et al.,“Transformer-based vulnerability\ndetection in code at EditTime: Zero-shot, few-shot, or\nﬁne-tuning?” May 2023. [Online]. Available: https://\ndoi.org/10.48550/arXiv.2306.01754\nEVANGELOS KATSADOUROS is a software engineer at\nUni Systems and a Ph.D. candidate at the University of\nWest Attica, 12241, Greece. Contact him at katsadouros.v@\ngmail.com.\nCHARALAMPOS Z. PATRIKAKISis the director of the Com-\nputer Networks and Services Research Lab of the University\nof West Attica, 12241, Greece, and the editor-in-chief of\nIT Professional. Contact him at bpatr@uniwa.gr.\nGEORGE HURLBURTis the uncompensated chief scientist\nat the STEMCorp Foundation and serves on the Board of\nAdvisors for the University System of Maryland at Southern\nMaryland Tall Timbers, MD, 20690, USA. Contact him at\ngfhurlburt@gmail.com.\nFROM THE EDITORS\n8 IT Professional May/June 2023"
}