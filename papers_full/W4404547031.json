{
  "title": "Exploring the opportunities of large language models for summarizing palliative care consultations: A pilot comparative study",
  "url": "https://openalex.org/W4404547031",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A1975751340",
      "name": "Xiao Chen",
      "affiliations": [
        "University of Newcastle Australia"
      ]
    },
    {
      "id": "https://openalex.org/A2010076840",
      "name": "Wei Zhou",
      "affiliations": [
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A2109764959",
      "name": "Rashina Hoda",
      "affiliations": [
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A2166553341",
      "name": "Andy Li",
      "affiliations": [
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A2163471372",
      "name": "Chris Bain",
      "affiliations": [
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A2526396498",
      "name": "Peter Poon",
      "affiliations": [
        "Monash University",
        "Monash Health"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4391494845",
    "https://openalex.org/W4393028467",
    "https://openalex.org/W6600281463",
    "https://openalex.org/W4403296360",
    "https://openalex.org/W4389519576",
    "https://openalex.org/W4205865577",
    "https://openalex.org/W3164718925",
    "https://openalex.org/W4390542510",
    "https://openalex.org/W4396941142",
    "https://openalex.org/W4392394605",
    "https://openalex.org/W4390987311",
    "https://openalex.org/W4390613062",
    "https://openalex.org/W4391890163",
    "https://openalex.org/W4385572269",
    "https://openalex.org/W4385573581",
    "https://openalex.org/W4385573087",
    "https://openalex.org/W4310578976",
    "https://openalex.org/W4318765555",
    "https://openalex.org/W4386120650",
    "https://openalex.org/W4392193048",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2736868680",
    "https://openalex.org/W2621009456"
  ],
  "abstract": "Introduction Recent developments in the field of large language models have showcased impressive achievements in their ability to perform natural language processing tasks, opening up possibilities for use in critical domains like telehealth. We conducted a pilot study on the opportunities of utilizing large language models, specifically GPT-3.5, GPT-4, and LLaMA 2, in the context of zero-shot summarization of doctor–patient conversation during a palliative care teleconsultation. Methods We created a bespoke doctor–patient conversation to evaluate the quality of medical conversation summarization, employing established automatic metrics such as BLEU, ROUGE-L, METEOR, and BERTScore for quality assessment, and using the Flesch-Kincaid grade Level for readability to understand the efficacy and suitability of these models in the medical domain. Results For automatic metrics, LLaMA2-7B scored the highest in BLEU, indicating strong n-gram precision, while GPT-4 excelled in both ROUGE-L and METEOR, demonstrating its capability to capture longer sequences and semantic accuracy. GPT-4 also led in BERTScore, suggesting better semantic similarity at the token level compared to others. For readability, LLaMA 7B and LLaMA 13B produced summaries with Flesch-Kincaid grade levels of 11.9 and 12.6, respectively, which are somewhat more complex than the reference value of 10.6. LLaMA 70B generated summaries closest to the reference in simplicity, with a score of 10.7. GPT-3.5’s summaries were the most complex at a grade level of 15.2, while GPT-4’s summaries had a grade level of 13.1, making them moderately accessible. Conclusion Our findings indicate that all the models have similar performance for the palliative care consultation, with GPT-4 being slightly better at balancing understanding content and maintaining structural similarity to the source, which makes it a potentially better choice for creating patient-friendly medical summaries. Threats and limitations of such approaches are also embedded in our analysis.",
  "full_text": null,
  "topic": "Readability",
  "concepts": [
    {
      "name": "Readability",
      "score": 0.787769079208374
    },
    {
      "name": "Computer science",
      "score": 0.7068902254104614
    },
    {
      "name": "Conversation",
      "score": 0.6902094483375549
    },
    {
      "name": "Context (archaeology)",
      "score": 0.49927473068237305
    },
    {
      "name": "Automatic summarization",
      "score": 0.47876229882240295
    },
    {
      "name": "Natural language processing",
      "score": 0.4556870460510254
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.4161542057991028
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3779744505882263
    },
    {
      "name": "Psychology",
      "score": 0.17633017897605896
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Communication",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}