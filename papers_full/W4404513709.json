{
  "title": "Can Large Language Models Assess Serendipity in Recommender Systems?",
  "url": "https://openalex.org/W4404513709",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5093054907",
      "name": "Yu Tokutake",
      "affiliations": [
        "University of Electro-Communications"
      ]
    },
    {
      "id": "https://openalex.org/A4201590224",
      "name": "Editorial Office",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2134821219",
      "name": "Kazushi Okamoto",
      "affiliations": [
        "University of Electro-Communications"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3154445493",
    "https://openalex.org/W4381334367",
    "https://openalex.org/W2007636657",
    "https://openalex.org/W790455547",
    "https://openalex.org/W3188443178",
    "https://openalex.org/W3210224600",
    "https://openalex.org/W4384644549",
    "https://openalex.org/W2903119928",
    "https://openalex.org/W4391308308",
    "https://openalex.org/W2811138351",
    "https://openalex.org/W4386728881",
    "https://openalex.org/W4366733551",
    "https://openalex.org/W4381569294",
    "https://openalex.org/W4387724701",
    "https://openalex.org/W4403431604",
    "https://openalex.org/W4327909856",
    "https://openalex.org/W2009718036",
    "https://openalex.org/W4389519239",
    "https://openalex.org/W4380353763",
    "https://openalex.org/W4385688511",
    "https://openalex.org/W4389523765",
    "https://openalex.org/W4310829037",
    "https://openalex.org/W4386507404"
  ],
  "abstract": "Serendipity-oriented recommender systems aim to counteract the overspecialization of user preferences. However, evaluating a userâ€™s serendipitous response to a recommended item can be challenging owing to its emotional nature. In this study, we address this issue by leveraging the rich knowledge of large language models (LLMs) that can perform various tasks. First, it explores the alignment between the serendipitous evaluations made by LLMs and those made by humans. In this study, a binary classification task was assigned to the LLMs to predict whether a user would find the recommended item serendipitously. The predictive performances of three LLMs were measured on a benchmark dataset in which humans assigned the ground truth to serendipitous items. The experimental findings revealed that LLM-based assessment methods do not have a very high agreement rate with human assessments. However, they performed as well as or better than the baseline methods. Further validation results indicate that the number of user rating histories provided to LLM prompts should be carefully chosen to avoid both insufficient and excessive inputs and that interpreting the output of LLMs showing high classification performance is difficult.",
  "full_text": null,
  "topic": "Serendipity",
  "concepts": [
    {
      "name": "Serendipity",
      "score": 0.9635321497917175
    },
    {
      "name": "Computer science",
      "score": 0.9055626392364502
    },
    {
      "name": "Recommender system",
      "score": 0.8528211116790771
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5231888890266418
    },
    {
      "name": "Machine learning",
      "score": 0.44532153010368347
    },
    {
      "name": "Language model",
      "score": 0.4341583549976349
    },
    {
      "name": "Natural language processing",
      "score": 0.3411380350589752
    },
    {
      "name": "Information retrieval",
      "score": 0.3268693685531616
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    }
  ]
}