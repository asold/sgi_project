{
  "title": "The cloud application modelling and execution language",
  "url": "https://openalex.org/W2621589142",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A5034507679",
      "name": "Achilleas Achilleos",
      "affiliations": [
        "Frederick University"
      ]
    },
    {
      "id": "https://openalex.org/A5037197263",
      "name": "Kyriakos Kritikos",
      "affiliations": [
        "FORTH Institute of Computer Science"
      ]
    },
    {
      "id": "https://openalex.org/A5075612300",
      "name": "Alessandro Rossini",
      "affiliations": [
        "PricewaterhouseCoopers (Norway)"
      ]
    },
    {
      "id": "https://openalex.org/A5021849573",
      "name": "Georgia M. Kapitsaki",
      "affiliations": [
        "University of Cyprus"
      ]
    },
    {
      "id": "https://openalex.org/A5049446644",
      "name": "Jörg Domaschka",
      "affiliations": [
        "Universität Ulm"
      ]
    },
    {
      "id": "https://openalex.org/A5039584998",
      "name": "Michał Orzechowski",
      "affiliations": [
        "AGH University of Krakow"
      ]
    },
    {
      "id": "https://openalex.org/A5007474992",
      "name": "Daniel Seybold",
      "affiliations": [
        "Universität Ulm"
      ]
    },
    {
      "id": "https://openalex.org/A5052962511",
      "name": "Frank Griesinger",
      "affiliations": [
        "Universität Ulm"
      ]
    },
    {
      "id": "https://openalex.org/A5064116719",
      "name": "Nikolay Nikolov",
      "affiliations": [
        "SINTEF"
      ]
    },
    {
      "id": "https://openalex.org/A5112518038",
      "name": "Daniel Romero",
      "affiliations": [
        "Laboratoire d'Informatique Fondamentale de Lille"
      ]
    },
    {
      "id": "https://openalex.org/A5033815092",
      "name": "George Α. Papadopoulos",
      "affiliations": [
        "University of Cyprus"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W71828450",
    "https://openalex.org/W1967791174",
    "https://openalex.org/W2152723325",
    "https://openalex.org/W2816272910",
    "https://openalex.org/W2128967738",
    "https://openalex.org/W2793826868",
    "https://openalex.org/W2022106311",
    "https://openalex.org/W2033797307",
    "https://openalex.org/W1791587663",
    "https://openalex.org/W2620776996",
    "https://openalex.org/W2159698086",
    "https://openalex.org/W1991390929",
    "https://openalex.org/W2034478217",
    "https://openalex.org/W2029771366",
    "https://openalex.org/W2921716379",
    "https://openalex.org/W2137079713",
    "https://openalex.org/W2882984947",
    "https://openalex.org/W2000098519",
    "https://openalex.org/W2093782324",
    "https://openalex.org/W1870381365",
    "https://openalex.org/W2530050784",
    "https://openalex.org/W2118531222",
    "https://openalex.org/W1590871933",
    "https://openalex.org/W2769317919",
    "https://openalex.org/W1150656759",
    "https://openalex.org/W2158826063",
    "https://openalex.org/W2132679175",
    "https://openalex.org/W2150500981",
    "https://openalex.org/W1884770487",
    "https://openalex.org/W2341749628",
    "https://openalex.org/W2140969023",
    "https://openalex.org/W1965717968",
    "https://openalex.org/W2052577486",
    "https://openalex.org/W2505304693",
    "https://openalex.org/W2789471414",
    "https://openalex.org/W1860825398",
    "https://openalex.org/W4285719527",
    "https://openalex.org/W2340251598",
    "https://openalex.org/W2405900662"
  ],
  "abstract": null,
  "full_text": "Journal of Cloud Computing:\nAdvances, Systems and Applications\nAchilleosetal. JournalofCloudComputing:Advances,Systems\nandApplications            (2019) 8:20 \nhttps://doi.org/10.1186/s13677-019-0138-7\nRESEARCH OpenAccess\nThecloudapplicationmodellingand\nexecutionlanguage\nAchilleasP.Achilleos 1,4* ,KyriakosKritikos 2,AlessandroRossini 3,GeorgiaM.Kapitsaki 4,\nJörgDomaschka5,MichalOrzechowski 6,DanielSeybold 5,FrankGriesinger 5,NikolayNikolov 7,\nDanielRomero8 andGeorgeA.Papadopoulos 4\nAbstract\nCloud computingoffersaflexiblepay-as-you-go modelforprovisioningapplicationresources,whichenables\napplicationstoscaleon-demandbasedonthecurrentworkload.Inmanycases,though,usersfacethesinglevendor\nlock-ineffect,missingopportunitiesforoptimalandadaptiveapplicationdeploymentacrossmultipleclouds.Several\ncloudmodellinglanguageshavebeendevelopedtosupportmulti-cloudresourcemanagement,butstilltheylack\nholisticcloudmanagementofallaspectsandphases.ThisworkdefinestheCloudApplicationModellingand\nExecutionLanguage(CAMEL),which(i)allowsuserstospecifythefullsetofdesigntimeaspectsformulti-cloud\napplications,and(ii)supportsthemodels@runtimeparadigmthatenablescapturinganapplication’scurrentstate\nfacilitatingitsadaptiveprovisioning.CAMELhasbeenalreadyusedinmanyprojects,domainsandusecasesduetoits\nwidecoverageofcloudmanagementfeatures.Finally,CAMELhasbeenpositivelyevaluatedinthisworkintermsofits\nusabilityandapplicabilityinseveraldomains(e.g.,datafarming, flightscheduling,financialservices)basedonthe\ntechnologyacceptancemodel(TAM).\nKeywords: Cloudcomputing,Domain-specificlanguage,Model-drivenengineering,Models@run-time\nIntroduction\nCloud computing enables organisations to use (virtu-\nalised) resources in a pay-as-you-go model. By adopting\nthis computing paradigm, organisations can reduce costs\nand outsource infrastructure management for their appli-\ncations. Also, they can support flexible application pro-\nvisioning by acquiring additional resources on-demand\nbased on the current workload. Based on these benefits,\nmany organisations have decided to move their applica-\ntionsintheCloud.\nMotivation\nTo support this migration, various frameworks have been\ndeveloped enabling automated user application deploy-\nment and scaling. In some cases, the ability to use vendor\nspecific tools (e.g., AWS CodeDeploy, Azure Kubernetes\nService (AKS), Amazon Elastic Container Service for\n*Correspondence:com.aa@frederick.ac.cy;achilleas@cs.ucy.ac.cy\n1FrederickUniversity,Nicosia,Cyprus\n4UniversityofCyprus,Nicosia,Cyprus\nFulllistofauthorinformationisavailableattheendofthearticle\nKubernetes (Amazon EKS)) to manually deploy applica-\ntion components, observe the deployment progress and\nmonitor the application performance is offered. Also,\nthere are languages that support the definition of plat-\nform specific models (i.e., they are directly bound to a\ncloud environment such as Amazon’s CloudFormation\nand OpenStack’s HOT). However, such frameworks do\nnot enable users to move to another Cloud provider\n(lock-in effect) when a respective need arises (e.g., better\nofferings,badapplicationperformance,costs).\nTo address the vendor lock-in effects [34], multi-cloud\nresource management (MCRM) has been proposed [31],\nwhich offers organisations several capabilities includ-\ning [2]: (a) optimal use of best possible cloud services\nfrom a variety of offerings supplied by a multitude of\ncloud providers; (b) ability to sustain an optimal qual-\nity level via the application dynamic reconfiguration; (c)\nability to achieve a better security level by exploiting suit-\nable security services; (d) ability to move applications\nnear the client location to improve application perfor-\nmance;(e)abilitytoconformtonationalandinternational\nregulations.\n©TheAuthor(s).2019 OpenAccess ThisarticleisdistributedunderthetermsoftheCreativeCommonsAttribution4.0\nInternationalLicense( http://creativecommons.org/licenses/by/4.0/),whichpermitsunrestricteduse,distribution,and\nreproductioninanymedium,providedyougiveappropriatecredittotheoriginalauthor(s)andthesource,providealinktothe\nCreativeCommonslicense,andindicateifchangesweremade.\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page2of25\nTo support MCRM and exhibit a suitable automation\nlevel, different Cloud Modelling Languages (CMLs) have\nbeen defined in many research projects and prototypes\n[8]. These CMLs “focus mainly on design-time aspects,\ncome from disjoint research activities and lack conver-\ngence with proposed standards. They also lack the right\nexpressiveness level, while commonly cover one service\ntype (IaaS) in the cloud stack” [8]. On the other hand,\nwidely used and powerful container orchestrators such\nas Kubernetes1 and Docker Swarm2 suffer from limita-\ntions, such as multi-cloud support and support for basic\nscalabilityrules.Forinstance,formulti-clouddeployment,\na Kubernetes cluster needs to be deployed manually in\neach cloud provider or Pipeline3 can be used to deploy\nKubernetesclustersonmajorcloudprovidersviaaunified\ninterfacepriortodeployingtheapplication.\nContributions\nTo address the aforementioned challenges, the Cloud\nApplication Modelling and Execution Language\n(CAMEL) has been devised. CAMEL is a multi-domain-\nspecific language (multi-DSL) covering all aspects\nnecessary for cloud application management at both\ndesign time and runtime. CAMEL has been developed\nmainly by appropriately integrating existing cloud-\nspecific DSLs, such as CloudML [15] and by also defining\nadditional ones like the Scalability Rule Language (SRL)\n[22]. In addition, CAMEL comes with a textual syntax,\nwhich enables the rapid specification of multi-cloud\nmodelsbyDevOpsusers.\nInrelevancetopreviousapproaches,thecontributionof\nthisworkliesintheinnovativeaspectsofCAMELthatare\nnotpresentintheexistingliterature:First,bydevelopinga\nsingle,unifiedandintegratedmegaDSL,asrecommended\nin [4], the user avoids having to use a set of heteroge-\nneous DSLs and editors. This can reduce the learning\ncurve,whileitcatersforbettermaintainabilityasitiseas-\nier to control the development of a unified, single DSL.\nSecond, CAMEL supports the type-instance pattern, well\nsuited to support the models@runtime approach [9], to\nenable users to provide models that abstract away from\ntechnical details, in contrast to other CMLs. In the mod-\nels@runtime approach (see Fig.1), the application state is\nmonitoredandreflectedonacertainmodelthatabstracts\nfrom quite technical details, while any changes on this\nmodel are reflected directly on the application and its\nprovisioning.\nThird, the identification of all MCRM needed informa-\ntion, based on the experience of CAMEL developers in\nimplementing other CMLs, enables automated, adaptive\ncross-cloud application provisioning. As CAMEL targets\n1Kubernetes- https://kubernetes.io/\n2DockerSwarm- https://docs.docker.com/engine/swarm/\n3Pipeline- https://github.com/banzaicloud/pipeline\nFig.1 Models@run-timearchitecture\nDevOps,auserstudywasconductedinthiswork,interms\nof adaptive provisioning of applications in the Cloud for\nvarious domains (e.g., data farming, flight scheduling).\nIt shows the unique CAMEL benefits, i.e., a good level\nof usability, comprehensiveness and suitability. Fourth, to\naddress heterogeneity and interoperability, CAMEL has\nbeenalsoalignedwithTOSCA.Asexpressedin[ 8]:“Hav-\ning the TOSCA standard, it is desirable to align existing\nand potential new CMLs for providing continuous mod-\neling support, for example, by achieving interoperability\namongthelanguages”.\nBackground\nCAMEL has been developed in the framework of the\nPaaSage EU project4 [38]. PaaSage’s goal is to provide\nan aPaaS-like abstraction to its users enabling a vendor-\nneutral application specification mappable to different\nIaaS cloud providers. Hence, PaaSage offers an environ-\nment, where application developers and operators can\neasily develop and deploy applications on multiple cloud\ninfrastructures, taking advantage of flexibility, adaptivity\nand scalability, without having to consider the specifics\nof different infrastructure requirements and APIs. In that\ncontext, CAMEL is an important part of the PaaSage\ndevelopment and deployment platform. Its eco-system\nsupports a dedicated social network, where the users can\nshare their CAMEL models [30]. Based on the above,\nthe aim of the current paper is to present the CAMEL\nlanguage and how it addresses the issues required for\n4PaaSageEU FP7Project- https://paasage.ercim.eu/\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page3of25\nsuccessful multi-cloud application design, whereas the\nactual model execution, management and adaptation is\nperformed by other components of the PaaSage platform.\nTheir presentation is outside the scope of the current\npaper. High-level information on how CAMEL is inte-\ngrated in the PaaSage platform and its workflow are\nprovided in “CAMEL in the PaaSage workflow”s e c t i o n ,\nwhereas dedicated papers cover specific aspects of the\nplatform,suchassecurityenforcement[ 23].\nCAMEL has already been adopted, extended and used\nin several EU research projects (PaaSage, CloudSocket5,\nCACTOS6)t os u p p o r tt h em o d e l i n ga n de x e c u t i o no f\napplications distributed over multiple cloud environ-\nments. Within these projects, CAMEL has also been\nextended to support PaaS and SaaS cloud services [27]\nandhasbeenestablishedasabaselinefortheprovisioning\nof Business Process as a Service [18]. It currently contin-\nues to evolve in the H2020 Melodic project7, to address\nthe challenges of multi-cloud management of large-scale\noptimiseddata-intensivecomputingapplications[ 20].\nStructureofthisdocument\nThe rest of the article is structured as follows. The next\nsection presents the key step of the requirements analysis\nand the subsequent steps that demonstrate the ratio-\nnale behind how CAMEL has been defined, designed and\ndeveloped. “The CAMEL language” section provides an\noverview of CAMEL, presents the key role of CAMEL\nin the workflow of the PaaSage platform and defines\nthe CAMEL metamodels. “CAMEL application: the data\nfarmingusecase ”sectionexplicateshowacertainusecase\nfrom PaaSage can benefit from its modelling via CAMEL\nand its subsequent evolution via the application of\nPaaSage’s model-based MCRM framework. “Evaluation”\nsection introduces the user study performed in this\nwork and discusses its main results. The related work is\nreviewed in “Related work” section and a criteria-based\ncomparative study of the CAMEL language with other\nCMLsisalsopresentedinthissection.Finally,“ Conclusions\n&futurework ”concludesthearticleanddrawsdirections\nfor further research.\nCAMELspecificationandimplementation\nThis section presents the steps for the specification\nand implementation of the CAMEL. Initially the analy-\nsis and extraction of the CAMEL requirements is pre-\nsented.Theseformthebasisforsubsequentstepsdefined\nand presented as follows: (i) the definition of a suitable\ndesign and development approach, (ii) the identification\nof the complete set of MCRM aspects to be covered\nby the CAMEL language, (iii) the selection, adaptation\n5CloudSocketEUH2020Project- https://site.cloudsocket.eu/\n6CACTOSEU FP7Project- http://cactos-cloud.eu/\n7MelodicEU H2020Project- http://melodic.cloud\nand extension of existing CMLs and DSLs to cover the\nMCRM aspects, (iv) defining the method for integrating\nthese diverse languages and (v) finally the use of suit-\nable technologies to drive the integration method for the\nimplementationofCAMEL.\nRequirements\nTo create CAMEL, the following requirements were de-\nrivedbasedonthechallengespresentedin“ Introduction”\nsection,summarizedas:1)supportdesign-timeandmod-\nels@runtimeapproaches,2)unifyCMLs(aspects)created\nindisjointactivitiesandprototypesand3)achieveconver-\ngencewithrelevantstandards.\n– models@runtime (R1):CAMELmustsupportboth\ntypeandinstancelevel, enablingtospecifyboth\nprovider-independentandprovider-specificmodels.\nThefirstwilldrivethedeploymentreasoningphase,\nthusenablinguserstodefinenon-functionaland\ndeploymentrequirementsina\ncloud-provider-agnosticway.The secondwill enable\ntomaintainacloud-provider-specificmodelofboth\ntheapplicationandmonitoringtopology.\n– multipleaspectscoverage (R2):CAMELshould\nenablethecoverageofmultipleaspects,tosupportall\nphasesoftheMCRM lifecycle.\n– highexpressivenesslevel (R3):Asuitable\nexpressivenesslevelshould beemployedtocapture\naccordinglyrequiredaspectsoftherespective\ndomain.This enablesboththeusers tospecifythe\nneededapplicationinformationandthesystemto\nmaintainandderivesuch informationatadetailed\nlevel,soastosupportallapplicationlifecycle\nmanagementphases.\n– Separationofconcerns( R4): CAMELshould support\nloosely-coupled packages,eachcoveringanaspectof\nMCRM.This willfacilitateafasterandmorefocused\nspecificationofmodelsateachphase.\n– Reusability (R5): CAMELshould supportreusable\ntypesformultipleaspectsofcross-cloud applications.\nThis willeasetheevolutionofmodels.\n– Suitableintegrationlevel( R6): AllCAMELsub-DSLs\nshould bemappedtoanappropriateintegrationlevel\nthatcansupporttheconsistencyoftheinformation\nprovidedandminimiseoverlapacrosssub-DSLs.\n– Textualsyntaxsupport (R7):CAMELtargetsDevOps\nthatdealwithcloud managementandareakinto\ntextual/codeediting.Thus, theneedtosupport\nCAMELtextualsyntaxarisesforeditingtextual\nmodels.\n– Re-use ofDSLs (R8):ExistingDSLsfromdisjoint\nresearchactivitiesshould bereused andintegrated\n(R6), asattestedalso in[8]. This isbecausethey\nprovidevaluable experienceandinformationon\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page4of25\nMCRMaspects.This alsoenablesinvolvingdifferent\nDSLscommunitiesinCAMELevolution,whileit\nreducesthelearningcurve forDevOpsalready\nfamiliarwiththem.\nDesignanddevelopment\nC A M E Ld e s i g ni si n s p i r e db yc o m p o n e n t - b a s e d\napproaches, which support the requirements of sepa-\nration of concerns (R4) and reusability (R5). As such,\ndeployment models can be regarded as assemblies of\ncomponents exposing ports, and bindings between these\nports. Furthermore, CAMEL developers have defined a\ndesign and development approach that satisfies the rest\nof the requirements and its composed by the following\nsteps: (a)Aspect/Domain Identification[R2]; (b)Selection\nof Languages [R2,R3 and R8]; (c)Integration [mainly R6\nbutalso R1,R4 andR5];(d) Implementation[R7].\nMore to the point, this approach is based on the ratio-\nnale of heterogeneous CMLs convergence, extension and\noptimization to produce one complete CML that takes\nbenefit on the knowledge already captured in these lan-\nguages [8]. Also, such an approach makes CML main-\ntainability, evolution and alignment with the standards\n(i.e., TOSCA) more feasible, as attested also in the CMLs\nsurvey in [8]. Finally, organisations, apart from involving\nthese experts in CAMEL development, have their own\ncommunities,whichcouldenableCAMELtokeepupwith\nchangesmadetothoseindividualCMLs.\nAspectIdentification\nBased on the knowledge and expertise of modelling\nexperts in PaaSage, each action involved in MCRM was\nmapped to specific information requirements to address\na certain domain/aspect. Table1 presents the identified\naspects for fully supporting the multi-cloud application\nlifecyclemanagementactions.\nLanguageSelection\nThe aspects identification for MCRM, was then followed\nby a careful examination of existing CMLs and DSLs\ncovering additional aspects (e.g., organisational). PaaSage\nexpertsknowledgeandinvolvementinimplementationof\nexistingCMLs,supportedgreatlyandassistedinselecting\nthefollowingCMLs:\n– CloudModellingLanguage(CloudML) [ 15–17]\nenablingtospecifydeploymenttopologymodels\n– Saloon[ 35–37]coveringthemodellingofcloud\nprovidersandvaluetypes\n– CERIF’s [21]organisationpartenablingtomodel\norganisationsandtheiraccesscontrolpolicies\n– OWL-Q[ 25]coveringthemodellingof:(a)\nnon-functionalterms(metricsandattributes),(b)\nTable1 Therelevantaspectsformulti-cloudapplicationmanagement\nAspect Phase Rationale\nDeployment All ThePITMsandPSTMsmodelsdrivebothapplicationreasoninganddeployment,\nwhileexecution-relatedactivitiesshouldbereflectedinPSTMmodels\nRequirement Reasoning Theuserrequirementsdriveapplicationdeploymentreasoning,\nExecution whiletheyarealsousedtorestrainthewaylocalscalabilitycanbeperformedatruntime\nProvider Reasoning, Providermodelsenabletomatchmakeandselectsuitablecloudofferings\nSecurity Reasoning High-andlow-levelsecurityrequirementscandrivetheofferingspace\nfiltering,aswellastheapplicationdeploymentoptimisation\naccordingtosecuritycriteriaapartfromthequalityonesandcost\nMetric Reasoning, Metricsareusedasoptimisationcriteriafordeploymentreasoning,whilethey\nExecution alsoexplicatehowapplicationmonitoringcanbeperformedduringtheexecutionphase\nScalability Execution Scalabilityrulesdrivethelocalapplicationreconfigurationduringexecution\nOrganisation Reasoning, Anorganisationcanhaveaccountsoncertainproviderswhichreducestheofferingspace\nDeployment onlytothem.Thecredentialstotheseprovidersenabletheplatformtoactonuser\nbehalffordeployingapplicationcomponentstosuitableVMs\nLocation Reasoning Locationrequirementscanbeusedtofiltertheofferingspaceduringdeploymentreasoning\nExecution Reasoning, Previousexecutionhistoryknowledgecanbeusedtoimproveapplicationdeployment\nUnit All Auxiliaryaspectenablingtoassociateunitsofmeasurementtometricsandthus,\nindirectly,totheconditions(i.e.,SLOs)posedonthem\nType All Auxiliaryaspectenablingtoprovidetypestolanguageelementslikemetrics,aswellas\ntodefinedifferentkindsofvaluesthatcanbeassignedtoelementproperties\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page5of25\nrespectiverequirementsorcapabilitiesimposedon\nthemintheformofconstraints,and(c)units.\nT h e s eC M L sa n dr e l e v a n tD S L ss e r v e da st h es t a r t i n g\npoint covering many aspects for MCRM. Nevertheless,\nadditional information was necessary and thus the focus\nwas reverted on the coverage of missing aspects. In spe-\ncific,theinformationcoverageforthe locationaspectwas\nminimalandthusarelevantmetamodelwasincorporated\nin CAMEL. Furthermore, for the aspects ofrequirement,\nscalability, execution and security,n o n eo ft h ee x i s t i n g\nDSLs had sufficient information coverage. Hence, addi-\ntional aspect-specific DSLs were developed in CAMEL.\nIn the end, six aspects were covered by existing partner-\nowned DSLs, while five were developed from scratch by\nconsideringtherequirementsposedonthedomainbythe\nMCRMprocess.\nIntegration\nIn addition to the DSLs selection, some well-known chal-\nlenges in DSL integration and evolution [32]h a dt ob e\naddressed, involving the following: (a) each DSL comes\nwith its own abstract and concrete syntax, which makes\nit then difficult to join two or more DSLs, especially if\nthey adopt different formalisms to define their syntax, (b)\nthe DSLs to be integrated can have equivalent or overlap-\nping concepts, which can lead to information repetition\nand misconceptions at the modeller side, (c) different\nmodellingstylescanbeadoptedleadingtocompletelyhet-\nerogeneous DSLs resulting in lack of uniformity, and (d)\ndifferent DSLs might exhibit a different description gran-\nularity level, which makes it difficult to find the most\nappropriatedetaillevelforintegration.\nTo resolve these challenges, a detailed integration\napproachwasfollowedthatcombinesallDSLstothesame\nmodelling (technical) space, description level and style by\nalso addressing the equivalence and overlapping concepts\nissue. This was done by adopting the Eclipse Modeling\nFramework (EMF) that provides: (i) tranformation tools\nfrom various syntaxes (e.g., XML Schema) to the Ecore\nmeta-language,(ii)semanticintra-andinter-domainval-\nidation of models using tools that enable the definition of\nObject Constraint Language (OCL) [33]c o n s t r a i n t s ,a n d\n(iii) the production of a uniform, homogeneous concrete\nsyntax of the CAMEL multi-DSL, using the Ecore meta-\nmodel, which follows the same modelling patterns and\nstyle.Thisenablesmodellerstorapidlyspecifyinasimilar\nandlogicalmannerelementsofheterogeneousDSLs.This\nreduces the learning curve and promotes the CAMEL\nusage.\nTheabovedescriptionprovidesahigh-leveloverviewof\nthe integration approach. Interested readers can find fur-\ntherdetailsontheintegrationproceduresforaccomplish-\ning a unified CAMEL language, as defined and explained\nin [38] and also documented in the CAMEL Technical\nDocumentation 8.\nImplementation\nIn addition to the rich expressiveness in defining a DSL’s\na b s t r a c ts y n t a xu s i n gE M F ,a sw e l la sb o t ht h es y n t a c -\ntic and semantic model validation using OCL, Eclipse\noffers also programmatic tools enabling the DSL devel-\noper to: (a) produce domain code out of an Ecore model,\n(b) produce a graphical editor for this DSL, (c) program-\nmatically validate the DSL’s models and (d) produce the\nDSL concrete syntax. Although the Eclipse tools allow\ngenerating a graphical tree-based editor, the feedback\nreceived from the use cases partners in PaaSage while\nusing this editor, resulted in the conclusion that DevOps\n(i.e., CAMEL’s main target group) are more accustomed\nto code-based textual editors. Hence, the Eclipse’s XText\nlanguage framework was used to define the CAMEL tex-\ntual syntax. XText supports the automatic generation of\ntextual editors out of the textual syntax definitions with\nuser-friendly features, such as error highlighting, auto-\ncompletion and validation. CAMEL and its textual editor\nare available in PaaSage’s repository9 under the Mozilla\nPublicLicenseversion2.0.\nApartfromthemodellingadjustmentsinCAMEL’stex-\ntual syntax, the CAMEL model importing feature was\nimplemented. This feature enables users to exchange and\nre-use CAMEL models to have a better support in their\nmodelling tasks. For example, suppose that a user needs\nto specify location requirements for the VM nodes of an\napplication topology model. If no location model is re-\nused, the user will need to manually develop a location\nhierarchy to model the desired locations of such VMs.\nHowever,byrelyingonastandardisedlocationmodelthat\nc a nb ei m p o r t e di nac u r r e n t l ye d i t e dC A M E Lm o d e l ,\nthe user can reduce the modelling effort by just selecting\nfrom the imported model the desired locations. In fact,\nthis location model is already available and can be gen-\nerated by exploiting the model importer tool available in\nPaaSage’s repository. The model is constructed by trans-\nforming the United Nation’s FAO geopolitical ontology10\ntoamodelconformingtotheCAMEL’slocationsub-DSL.\nThis model covers a location hierarchy involving the lev-\nels of continents, sub-continents and countries. Thus, it\nis quite sufficient to support specifying physical location\nrequirements.\nRequirementsfulfillment\nThe design, integration and implementation steps were\nperformed by following a process that guarantees that the\n8CAMELTechnical Documentation—http://camel-dsl.org/documentation/\n9PaaSage’sGitRepository - https://gitlab.ow2.org/paasage/\n10UNFAOgeopoliticalontology- http://www.fao.org/countryprofiles/\ngeoinfo/modulemaker/index.html\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page6of25\neight requirements described in “Requirements”s e c t i o n\nare satisfied. First, the CAMEL language follows thetype-\ninstance pattern [3], facilitating reusability (R3)a n dt h e\nmodels@runtime approach (R1). This pattern exploits\ntwo flavours of typing, namely ontological and linguis-\ntic [29], as depicted in Fig.2.I nt h i sf i g u r e ,SL (short for\nSmall GNU/Linux) represents a reusable type of VM. It\nis linguistically typed by the classVM (short for virtual\nmachine).SL1representsaninstanceofthevirtualmachine\nSL.Itisontologicallytypedby SL andlinguisticallytypedby\nVMInstance.\nSecond, CAMEL follows the models@runtime\napproach, mapping to the R1 requirement, as it has\nbeen designed to utilise the abstraction of provider-\nindependent models, which are then transformed into\nprovider-specific ones based on matching cloud capa-\nbilities with the respective requirements posed. The\nprovider-specific models can then be evolved by the\nsystem through the adaptive provisioning of the user\napplication by still satisfying the requirements given at\ntheprovider-independentlevel.\nThe coverage of multiple aspects, i.e., requirementR2,\nis one of the cornerstones of the DSL design approach.\nThe determination of relevant aspects enabled to pro-\nduce an all-inclusive but focused DSL, which attempts to\naddress the MCRM problem by covering only the most\nsuitableinformationpieces.Thisenabledtodiscoversuit-\nableDSLsthatwereintegratedintoacoherentsuper-DSL,\ni.e., the CAMEL, to reduce its development effort and\ntime.\nRequirement R3 is guaranteed at two levels: (a) by\nselecting and extending (when needed) a suitable DSL\nto ascertain the optimal coverage of each aspect; (b) by\nadopting a formalism (EMF Ecore + OCL), which enables\ntoalsocover,inanexpressivemanner,thesemanticsofthe\nrespectivedomain.\nSeparation of concerns (requirementR4) is achieved by\nseparatingtheinformationaspectstobecoveredindiffer-\nent CAMEL packages enabling their individual evolution.\nThe approach to integration between DSLs enabled us\nto move generic or domain-specific concepts to suitable\npackages in the CAMEL metamodel. This allows each\nDSLtofocusonaspecificdomain,thusavoidingsemantic\noverlapsacrossdomains.\nRequirement R5 is satisfied via the design of CAMEL\nand the aforementioned DSL integration process. In par-\nticular, CAMEL is designed for re-usability by separat-\ning between generic and aspect-specific concepts that\ncan be re-used across different CAMEL sub-DSLs. For\ninstance, aMetric (part of metric DSL) is associated with\nar e s p e c t i v eMeasurement (part of execution DSL) incorpo-\nratedinanapplicationexecutioncontext(i.e.,deployment\nepisode). In fact, the latter is a form of cross-referencing,\nalso enabling the inter-domain CAMEL model valida-\ntion. Apart from this, the CAMEL tools allow importing\notherCAMELmodels.Forexample,standardisedlocation\nmodels can be re-used for specifying location require-\nmentsinmultipleCAMELmodels.\nAsuitableintegrationlevel(requirement R6)isachieved\nby using the right modelling technologies and employing\nthe aforementioned DSL integration process. The fol-\nlowed procedure enabled to bring all DSLs into the same\nmodelling space and integrate them into a unified DSL.\nThe DSL exhibits the same modelling styles/patterns,\nwhilealsocatersforprovidingthesamedetaillevel,which\nissufficientenoughforcapturingaspecificdomainbyalso\nkeeping the respective modelling effort at an appropriate\nlevel.\nThe support for a textual syntax (requirementR7)i s\nprovided by the CAMEL textual editor, which was imple-\nmented using XText and enables users to operate with\nCAMEL. A good effort has been spent in homogenising\nthis syntax across different DSLs, by adopting the same\nmodelling patterns and differentiating with respect to the\ndefault patterns automatically generated via XText. By\nproviding user-friendly features, such as syntax highlight-\ning and auto-completion, combined with the capability\nto import existing CAMEL models, the CAMEL editor\nFig.2 Linguisticandontologicaltyping\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page7of25\nenhances the user experience, exhibits a suitable usability\nlevel, and enables rapid development of CAMEL models.\nThishasbeenvalidatedin“ Evaluation”section.\nFinally, the re-use of DSLs (requirementR8)w a so n eo f\nthe design cornerstones of CAMEL. It enabled to reduce\nCAMEL’s development effort, to cover well the respec-\ntive domains in many cases, while also guaranteed the\nparticipation in this development of language engineers\nthat have a special interest in maintaining the up-to-date\nversionsoftheirDSLswithinCAMEL.\nTheCAMELlanguage\nIn this section, an overview of CAMEL is presented first,\nwith respect to its constituent sub-DSLs. Next, the anal-\nysis will focus, also for brevity reasons, on some core\nsub-DSLs, i.e., those involved in the modelling of appli-\ncationtopologies,requirementsandscalabilityrules,thus\ntargetingthe DevOps users.\nIn this respect, the CAMEL sub-DSLs covered in the\nfollowing sub-sections include: the deployment, require-\nment, metric, and scalability ones. More details on other\nCAMEL sub-DSLs can be found in CAMEL’s documen-\ntation. Also, an analysis over CAMEL’s security sub-DSL\ncanbeinspectedin[ 24].\nCAMELoverview\nBased on its previously analysed design method, CAMEL\nwas realised as a super-DSL integrating multiple sub-\nDSLs/metamodels. Table 2 provides an overview of\nCAMEL’s content. It explicates which are the DSLs\nincluded, supplies a list of the core domain concepts cov-\nered by these DSLs, as well as the newly added concepts,\nand indicates the roles of users that can be responsible to\nprovideinformationforthesedomains.\nThe following user roles are expected to be involved in\nCAMEL model specification: (a)DevOps:r e p r e s e n tu s e r s\nresponsible for defining the application non-functional\nanddeploymentrequirementsalongwithscalabilityrules;\n(b) Admin: responsible for specifying: (1) the organisa-\ntion model covering information about the organisation\nrunning the platform and the access control policies per-\ntaining to that platform’s usage; (2) provider models cov-\nering the offerings from both public and private cloud\nproviders. Thus, there is a separation of concerns as\nDevOps usersworkatahigherabstractionlevel(provider-\nindependent level), whileAdmins at a lower, more cloud\nprovider-dependent level; (c) System:i tm a p st ot h e\nplatform supporting the multi-cloud application deploy-\nment, responsible for specifying and evolving provider-\ndependent models, as well as enriching the execution\nhistoryoftheapplication(s).\nThe separation of concerns between roles also defines\nwhen certain CAMEL model parts shouldbe modelled or\nmodified. In particular,DevOps and Admins are usually\ninvolved in the modelling phase as they provide informa-\ntion used mainly for supporting the subsequent phases.\nOne exception concerns the provider models that can be\nupdated by the Admin whenever changes in the offer-\nings of respective cloud provider(s) are detected. As this\nchange can occur at any time, this modification can span\nall application management phases. On the other hand,\nthe System role takes care of updating the initial CAMEL\nmodel provided by the other roles during the subsequent\nphases of application reasoning, deployment and execu-\ntion.\nSome patterns can be derived from Table2. First, the\nDevOps roleisresponsibletoprovidemostofthedomain-\nspecific models in CAMEL. This is obvious as CAMEL\ntargets mainly this role. However, while it can be argued\nthat a lot of modelling effort will be contributed by this\nrole, this is not necessarily the case. In particular, only\ntwo core models need always to be specified, i.e., the\nTable2 TheDSLscomprisingCAMEL,thecoreconceptstheycoverandtherolesresponsibleforprovidingtheseDSLs’models\nDSL Coreconceptscovered Role\nCore(Top-Level) Topmodel,ContainerofotherModels,Applications DevOps,System\nDeployment Applicationtopology(InternalComponents,VMs,Hostings,Communications) DevOps,System\nRequirement Hardware,Security,Location,OS,Provider,QoSandOptimisationRequirements DevOps\nProvider Providerofferings(informofafeature-attributemodel) Admin\nSecurity Securitycontrols,AttributesandmMtrics DevOps\nMetric Metrics,Sensors,Attributes,Schedules,(measurement)Windows,Conditions DevOps,System\nScalability ScalabilityRules,Event(Patterns),HorizontalandVerticalScalingActions DevOps\nLocation PhysicalandCloud-specificLocations DevOps\nOrganisation Organisations,Users,Roles,Policies,Cloud/platformcredentials Admin\nExecution Executioncontexts,measurements,SLOassessments,adaptationhistory System\nUnit Unitsofmeasurement DevOps\nType ValuetypesandValues DevOps\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page8of25\ndeployment and requirement ones. The specification of\ntherestofthemodelsdependsontheapplicationrequire-\nments.Forinstance,scalabilityrulesarenotneededforan\napplication facing constant load, while security require-\nments do not need to be modelled when the applica-\ntion does not access critical organisational assets. Fur-\nther, template models are already offered for basic cloud\nproviders, metrics, units and locations which could be\nre-used.\nSecond, it is evident that there are two aspects, which\nconcern two roles, mapping to the deployment and\nmetric DSLs. This implements CAMEL’s support for\nthe models@runtime approach. Hence, theDevOps role\nprovides the provider-independent topology and met-\nric models, while theSystem role transforms them into\nprovider-specific models that evolve at user application\nprovisioning.\nCAMELinthePaaSageworkflow\nCAMELperseisamodellinglanguageandframeworkfor\ncloud applications and their execution status. This mod-\nelling itself can be generic and on a level that is indepen-\ndent from cloud providers, e.g., describing requirements\nfor an application to be run; on the other hand, the mod-\nelling can also be specific and describe very concretely\nwhich application components shall be run on which\nvirtual machines on what cloud provider. Being a mod-\nelling language, CAMEL provides the means to express\nthese scenarios, but itself does not come with any tools\nfor manipulating the models or moving from provider-\nagnostic models to provider-specific models. Initially,\nsuch tools have been developed and evaluated in the\nPaaSage project and been enhanced in work since then.\nEven though this paper is about CAMEL as a language,\nthis section describes PaaSage’s MCRM framework with\nCAMELatitscore.Wehopethatthisillustratestheusage\nof CAMEL in a larger context and helps the reader to\nbetterunderstand.\nIn the following, we focus on the application deploy-\nment and reconfiguration flow supported by the PaaSage\nframework. It is important to note that PaaSage has not\nbeen designed to be a cloud broker. Instead, its opera-\ntion is similar to configuration management tools such\nas ansible and chef and its view is application-centric. In\nconsequence,thestorageofcloudcredentialsrequiredfor\naccessingcloudservicesisnotoverlycritical,astheentire\ntoolchain runs locally. Despite that, PaaSage uses encryp-\ntiontostorepasswordandcredentials.TheuseofCAMEL\nin cloud-broker scenarios has been investigated by the\nCloudSocket project [13,18,26], but it is out of the scope\nofthisdocument.\nFigure 3 illustrates the use of CAMEL in the PaaSage\nworkflow. In this figure,white trapezesrepresent activi-\nties performed by the user, whilewhite rectanglesrepre-\nsent processes executed by the PaaSage framework. The\ncoloured shapes represent modelling artifacts: the blue\nshapespertaintothemodellingphase,theredonestothe\ndeploymentandthegreenonestotheexecutionphase.\nFig.3 CAMELmodelsintheself-adaptationworkflow\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page9of25\nModellingphase\nDuring the modelling phase, the users develop a CAMEL\napplication model that includes three pieces of infor-\nmation: (a) the provider-independent topology model\n(PITM) specifying the types of virtual machine (VM)\nnodes on which the application components should be\nhosted; (b) the application requirements that include Ser-\nvice Level Objectives (SLOs) and optimization goals over\nquality, cost and security terms; (c) scalability rules that\ndrive the local adaptation behaviour of the application.\nApart from the CAMEL application model, users develop\n(i.e., organization’s private cloud) or reuse CAMEL cloud\nprovidermodels(e.g.,Amazon,Azure,Organization’spri-\nvate cloud), which specify the offerings supplied by these\nClouds. The provider models also cover the pricing infor-\nmation of the Cloud provider as well as the relative\nperformanceofitsofferings.\nDeploymentphase\nThe design-time CAMEL application and provider mod-\nels are then used by a reasoner to produce an appli-\ncation deployment plan solving a constraint problem.\nApplication requirements are exploited to filter out cloud\nproviders per application component, thus relying on\ncomponent-specific requirements (e.g., # of cores - hard-\nware requirements), as well as on constraints imposed\nat the application level (e.g., deployment cost ≤ e20\n). The filtering dynamically generates a constraint opti-\nmization model that aims at the best VM offering per\napplication component, by considering global optimiza-\ntiongoalsdefinedforthewholeapplication(e.g.,minimize\napplicationcost andmaximize availability).\nThis optimisation model is in the CAMEL model lead-\ning to a provider-specific topology model (PSTM), cov-\nering the instance level. It defines how many instances\nof an application component are deployed to respective\nVM instances, which map to a certain VM offering in the\nsolution. The PSTM is then exploited by theAdapter to\ncreate a deployment plan, which defines the acquisition\nofresourcesacrossdifferentClouds,e.g.virtualmachines,\nand the application deployment flow, i.e., deployment of\napplication components on these virtual machines. It is\nthe Executionware that orchestrates these actions and\ninvokes provider-specific deployment actions and creates\nanexecutionmodel.\nExecutionphase\nOnce the application deployment finishes, the execu-\ntion phase starts. Initially, an execution sub-model is\ninjected at runtime in the CAMEL model, which main-\ntains execution-related information about the current\ndeployment. It includes the measurements produced by\nthe Executionware for the running application, plus SLO\nviolations occurred that occurred at runtime. This model\nnot only allows to keep track of the running application,\nbut also to exploit its execution history to improve its\ndeploymentusingtheProfilerandReasoner.\nThe Executionware itself is realised by the Cloudia-\ntor toolkit [6], a cross-cloud orchestration toolkit that\nhandles the acquisition of virtual resources, deployment\nof application artifacts, wiring of application component\ninstances, and monitoring of both applications and vir-\ntual resources. Cloudiator makes use of a multitude of\ntechnologies to fulfill its functionality. Yet, for the sake of\nacquiring virtual resources, i.e., virtual machines, it relies\nonthejclouds 11 librarywherepossible[ 5,12].Othercloud\nplatforms, e.g., Microsoft Azure, are supported through\ndedicateddrivers.\nReconfigurationandadaptations\nBoth Executionware as well as Reasoner and Profiler may\ntrigger actions that lead to changes: The Executionware\nmonitors the quality of the application execution and\ncompareslivemonitoringdataagainstSLOthresholdsset\nin the CAMEL model. Violations of these may lead to\nthe executing local scaling rules whose execution leads\nto scale out/in of application components and hence to\na change of the CAMEL execution model. On the other\nhand, Reasoner and Profiler continuously observe the\napplication’s execution history and current state and con-\ntinuously produces new PSTMs, which are better than\nthe currently applied one. If such a new configuration is\nfound, the adapter generates a new deployment plan con-\ntainingthedifferencebetweenthecurrentandthedesired\ndeployment that is passed on to the Executionware and\nenacted there. As such, a global reconfiguration loop is\nsupported enabling to converge to an optimal application\ndeployment, adaptable according to the current situation.\nSimilarly, the entire process shown in Fig.3 is triggered\nwhen the user changes the cloud provider model. This\nmay be due to a new cloud provider being added to the\nmodel or changes in existing cloud provider models, for\ninstance when the pricing of a provider changes, new\nvirtual machine flavours are introduced, or the relative\nperformance changes due to new hardware at provider\nside.\nBoth local and global reconfiguration actions are\nreflected in the currently applied PSTM runtime model,\nwhich enables to support the models@runtime approach,\nas opposed to other CMLs. In fact, the dynamic modifi-\ncation of the CAMEL models is performed by the system\nat runtime. This enables self-adaptation, i.e., the CAMEL\nmodel is \"live\", in contrast to other systems where such\nmodification is manually performed at design time by the\nuser.Thisisanaspectthatismissingfromcurrentpropri-\netary cloud application management systems and CMLs,\nthatmanageevensingleClouds.\n11http://jclouds.apache.org/\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page10of25\nFig.4 Thetypepartofthedeploymentmetamodel\nCAMELmetamodel\nThe CAMEL core metamodel is technically represented\nas an Ecore model and organised into eleven metamod-\nels/packages. Each metamodel/package reflects a certain\ndomain. The core package includes generic concepts, re-\nused across different domains, as well as theCamelModel\nactingasatop-levelcontainer.Forbrevityandtolimitthe\ntechnical details, only the deployment, requirement, met-\nric and scalability metamodels are introduced fully. The\nrest of the metamodels are briefly introduced. Readers\ncan refer to the CAMEL Technical Documentation and\nCAMEL Semantics12 for more details on the individual\nmetamodels.\nDeploymentMetamodel\nThe deployment metamodel follows the type-instance\npattern where the type part specifies a PITM while the\ninstance part a PSTM. Figure4depicts the type part. The\ninstancepartisnotshownasitisidenticaltothetypepart\nwith the exception that instances (e.g.,VMInstance)o ft y p e -\nbased concepts (e.g.,VM) are modelled, always pointing to\ntheirtype.\n12CAMELSemantics- http://camel-dsl.org/documentation/\nThe top-level entity in the deployment metamodel is\nDeploymentModel, i.e., a container of provider-independent\ndeployment elements. At the type level, the basic but\nabstract entity isComponent. Following a component-based\nmodelling approach, this entity has a set of provided\ncommunication and required communication ports. The\nformer enable it to communicate with other components,\nwhilethelattertohostothercomponents.Itincludesalso\nas e to fConfiguration elements, in the form of OS-specific\ncommands, for lifecycle management, i.e., to download,\ninstall,configure,runandstopthiscomponent.\nA Component entity subsumes two component types: (1)\ntheInternalComponent representsasoftwarecomponenttobe\ndeployed in the Cloud, requiring to be hosted by another\nComponent (eitherInternalComponent or VM)v i aaHostingPort (for\ninstance,aservletcontainercanhostaservlet,whereboth\nareInternalComponents)and(2)the VM whichactsasahostfor\ninternalcomponents.\nACommunication isestablishedbyconnectingtheprovided\nand required communication ports of two components.\nThis communication’s lifecycle can also be managed via\ntwo Configuration elements. The first focuses on managing\nthe provided, while the second the required communi-\ncation port. Furthermore, aCommunication has a type that\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page11of25\ndraws the following values from theCommunicationType enu-\nmeration:(a) LOCAL:denotingthattheinternalcomponents\nconnected need to be hosted on the sameVM node; (b)\nREMOTE: signifying that the two components should be\nhosted on different VM nodes; (c) ANY: denotes that the\nmanagement platform is allowed to decide about the\nrelated placement of these two components, i.e., whether\nto co-locate them or not.\nThe second connector type maps to theHosting concept,\nrepresentinga hostingrelation betweentwo components:\nthe hosted internal component and a hosting internal\ncomponent or VM. Similarly to aCommunication,a Hosting\nconnects the provided and required hosting ports of the\ntwo components, while it includes two Configuration ele-\nments,eachdevotedtothemanagementofoneofthetwo\nhostingports.\nThe VMRequirementSet includes a set of references to spe-\ncific kinds of requirements that can be modelled in a\nrequirement model, such as quantitative hardware, location\nor OS requirements (see Listing2). AVMRequirementSet can\nbe associated to aVM or to the wholeDeploymentModel.I n\nthe latter case, it represents global VM requirements that\nmust hold for the whole application topology. In the for-\nmer case, it represents local VM requirements that must\nholdforacertainVMonly,whichtakepriorityoverglobal\nrequirements.\nRequirementmetamodel\nCAMEL’s requirement metamodel, depicted in Fig.5,ca n\ncapture the user non-functional requirements, including\nhardware, quality, cost, location and security ones. It has\nbeeninspiredbytheWS-Agreement[ 1]andOWL-Q[ 25]\nlanguages. This metamodel includes the top-levelRequire-\nmentModel concept, which can contain zero or moreRequire-\nments.Any Requirement canbeeitherhard(see HardRequirement\nconcept)orsoft(see SoftRequirement concept).Hardrequire-\nments should be satisfied at all costs by the respective\nplatform, while soft requirements should be satisfied on a\nbest-fitbasis.\nRequirements can be grouped by using theRequirement-\nGroup sub-concept ofRequirement. A certain logical operator\n(AND, OR or XOR) is applied over the requirements\ngrouped to formulate goal models, inspired by goal mod-\nelling approaches like i-star [41]. The requirement group-\ning enables to specify alternative service levels (SLs),\ndefined as requirement conjunctions. This caters for a\nmore flexible filtering of the provider space, increasing\nthepossibilitythatasolutiontothedeploymentreasoning\nproblemcanbereached.\nMetricmetamodel\nCAMEL’s scalability and metric packages rely on the SRL\nDSL [14, 22], enabling to specify rules supporting com-\nplexadaptationscenariosofcross-cloudapplications.The\nmetric package captures the way application monitoring\ncan be performed and the main monitoring conditions\nto be evaluated. The former is specified via the Metric\nabstraction,whilethelatterbythe Condition concept.\nThe metric metamodel (see Fig. 6) follows the type-\ninstance pattern, an essential feature that distinguishes it\nFig.5 Therequirementmetamodel\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page12of25\nFig.6 TheMetricconceptanditshierarchy\nfrom the state-of-the-art. This feature enables the respec-\ntive (multi-cloud) application management framework to\nmaintain and evolve the application monitoring infras-\ntructurebyfollowingthemodels@runtimeapproach.This\ninfrastructure should be synchronised with the changes\nperformedontheapplication’sPSTMmodel.\nScalabilitymetamodel\nSRL, apart from measurement constructs, also enables\nthe modelling of scalability rules by including a scala-\nbility metamodel (Fig. 7). SRL is inspired by the Esper\nProcessing Language (EPL)13 with respect to the specifi-\ncationofeventpatternswithformulasincludinglogicand\ntiming operators. SRL offers mechanisms to (a) specify\nevent patterns and associate them with monitoring data,\n( b )s p e c i f ys c a l i n ga c t i o n s ,a n d( c )a s s o c i a t et h e s es c a l -\ningactionswitheventpatterns.Inthefollowing,themain\nconceptsdefinedinthe scalability packagearepresentedand\nanalysed.\nScalabilityModel actsasacontainerforotherscalabilitycon-\ncepts,fromwhichthemostcentralis ScalabilityRule.Thisrule\nis mainly a mapping from an event to one or more scaling\nactions. It also specifies additional details, such as which\nis its developer (anEntity) and which scaling requirements\n(seeScaleRequirement inSection 8)shouldlimititstriggering.\nAny ScalingAction is associated with a certainVM and it can\nbeeitherhorizontalorvertical.\nOthermetamodels\nProvider Metamodel:The provider package of the CAMEL\nmetamodel is based on Saloon [ 35–37]. Saloon is a\n13https://www.espertech.com/esper/\ntool-supported DSL for specifying the features of cloud\nprovidersandmatchingthemwithrequirementsbylever-\naging feature models [7]a n do n t o l o g i e s[19]. It provides\nthe capability to define the attributes and sub-features\ncharacterising a private or public cloud provider, e.g., the\nattributescharacterisingthevirtualmachineflavourspro-\nvided by a private or public cloud. It also covers the\ncosts and relative performance of individual offerings of a\nprovider. The provider models enable matchmaking and\nselectingsuitablecloudproviderofferings,whiletheyalso\nunveildetailsspecifictotheapplicationdeployment.\nExecution Metamodel: The execution metamodel in\nCAMEL has been developed from scratch with the main\ngoal to cover the modelling of whole execution histo-\nries of multi-cloud applications. Such information can\nthen be exploited by the management platform in order\nto optimise the deployment of a multi-cloud application,\nwhether it is a new or an existing one. In this respect, an\nexecution model is a container of different deployment\ne p i s o d e sa n de n a b l e st h ea n a l y s i so nt h e mt od e r i v et h e\nadded-value deployment-reasoning-targeting knowledge.\nSuch a model not only allows to keep track of the run-\nningapplicationbutalsotoexploititsexecutionhistoryto\nimproveitsdeployment.\nSecurityMetamodel: Thesecurity packageoftheCAMEL\nmetamodel is not based on existing DSLs and has been\ndeveloped to enable the specification of security aspects\nof cross-cloud applications. It enables the specification of\nhigh-level and low-level security requirements and capa-\nbilities that can be exploited for filtering providers, as\nwell as adapting cross-cloud applications. Furthermore,\nan analysis over CAMEL’s security DSL can be inspec-\nted in [24].\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page13of25\nFig.7 Thescalabilitymetamodel\nLocation Metamodel: The location metamodel captures\nthe modelling of hierarchical physical and cloud-based\nlocations. This modelling enables specifying location\nrequirements that can drive the filtering of the VM offer-\ning space in deployment reasoning, while also ensur-\ning the compliance to regional or continental regulatory\nrequirements. For example, as part of theLocation an iden-\ntifier is defined (e.g., ISO code for physical locations) and\ncan be further distinguished into aGeographicalRegion and a\nCloudLocation.\nOrganisation Metamodel:The organisation package of the\nCAMELmetamodelisbasedontheorganisationsubsetof\nCERIF [21]. CERIF is an EU standard for research infor-\nmation. In particular, theorganisation package of CAMEL\nreuses the concepts from CERIF for specifying organisa-\ntions, users, and roles. As a central part of theorganisation\nmodel, the specific organisation details are defined, such\nasits name,c on tactemail address,webURL.\nType Metamodel:The type metamodel is also based on\nSaloon [35–37]. It provides the concepts to specify value\ntypes and values used across the rest of the CAMEL\nmodels(e.g.,integer,string,orenumeration).\nCAMELapplication:thedatafarmingusecase\nTheScalarmplatform’s 14 [28]datafarmingusecaseallows\nillustrating how to specify CAMEL models conforming\nto CAMEL’s textual syntax. We limit the presentation\nto those specific CAMEL sub-models presented in “The\nCAMEL language” section to illustrate the definition of\nessential properties for the use case. Readers interested\ni nt h ec o m p l e t ec o n c r e t es y n t a xo fC A M E Ls h o u l dr e f e r\nto [39]. The complete Scalarm CAMEL model can be\ndownloadedfromPaaSage’sGitrepositoryatOW2 15.\nScalarmoverview\nScalarm is a complete platform for conducting data\nfarming experiments across heterogeneous computing\ninfrastructures. It has been developed by the Akademia\nGrniczo-Hutnicza(AGH)UniversityofScienceandTech-\nnology.Datafarmingrepresentsamethodologyviawhich\nasimulationmodelisrepeatedlyexecutedaccordingtoan\nextensiveparameterspacesuchthatsufficientdatacanbe\n14Scalarm- http://www.scalarm.com/\n15ScalarmModel- https://gitlab.ow2.org/paasage/camel/blob/master/\nexamples/\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page14of25\ncollected with the goal to provide an insight over the cor-\nrelation between the model properties and behaviour, as\nwell as the simulation’s input parameters. Thus, Scalarm\nsuppliestotheuserasetofwell-knownexperimentdesign\nmethodstogeneratetheexperimentparameterspace.\nVia Scalarm, each data farming experiment can be\nmonitored, while the initial parameter space can be\nextended at runtime. Further, the amount of computa-\ntional resources dedicated to the experiment execution\ncan be increased such that Scalarm can scale itself based\nontheexperimentsize.\nScalarmarchitecture\nThe Scalarm architecture follows the master-worker\ndesign pattern and is depicted in Fig.8. In this architec-\nture, the worker part executes the simulation, while the\nmasterpartcoordinatestheexecutionofthedatafarming\nexperiments. Each part from the two is realized by using\nlooselycoupledservices.\nIn terms of the worker, the main component is theSim-\nulation Manager, an intelligent wrapper for simulations\ncapable to be deployed on different infrastructures. It\nimplements the Pilot job concept [10] by being a special-\nized application that acquires computations resources to\nrunactualsimulations.\nIn terms of the master, (3) components are rele-\nvant: the Experiment Manager, Information Service and\nStorage Manager.T h eExperiment Manager supplies an\noverview about both running and completed data farm-\ning experiments, while it enables analysts to create new\nexperiments or conduct statistical analysis on existing\nexperiments. It is also responsible for scheduling sim-\nulations to Simulation Managers.T h eStorage Manager\nconstitutes a persistence layer in the form of a ser-\nvice enabling other components or services to store\ndifferent types of information, which include struc-\ntural information about executed simulations and exper-\niments, as well as actual simulation results, either in\nthe form of binary or text data. Finally, the Informa-\ntion Service realizes the service locator pattern, con-\nstituting a registry of other services and components\nin the Scalarm system enabling the retrieval of their\nlocation.\nD u et ot h em a s t e r - w o r k e ra r c h i t e c t u r et h e r ei sn o\nimmediate communication between the workers. Due to\nthe fact that workers pull their upcoming experiments\nfrom the master, but the compute time per experiment\nis significantly longer than this communication (order of\nhours compared to orders of seconds), the application is\nparticularly well suited for multi-cloud deployments, as\nthereisnodependencyonbandwidthandlatency.\nAs-isandto-Besituation\nBefore employing the PaaSage platform, the user needs\nto manage the worker’s resources by manually schedul-\ning extra workers to different infrastructures. More-\nover, the administrator needs to manually define scaling\nrules to specify scaling conditions and actions for each\ninternal service for the master. On another note, the\nmulti-cloud aspect and the complex scaling requirements\nFig.8 Scalarmas-isarchitecture\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page15of25\nof Scalarm disallow the use of widely used container\norchestrators, such as Kubernetes and Docker Swarm,\nsince they only support the definition of basic scal-\nability rules and do not support multi-cloud deploy-\nment. As mentioned in Section8, a Kubernetes cluster\nneeds to be deployed manually in each cloud provider\nor Pipeline can be used to deploy Kubernetes clusters\non major cloud providers through a unified interface\nbefore an actual application and its workload can be\ndeployed.\nBy using the PaaSage platform and CAMEL, Scalarm\nbecame a fully autonomous data farming platform. This\nwas achieved by using suitable scalability rules that\nenabled the automatic scaling of Scalarm components\nwhen certain conditions are met. These rules are derived\nby the Reasoner component in the PaaSage platform\nby considering the user’s non-functional requirements.\nFurthermore, Scalarm initial deployment is handled by\nPaaSage itself so that there is no need to involve a\nsystem administrator or a user to perform scaling/de-\nployment actions, as the PaaSage platform automatically\nhandles all Scalarm services. Moreover, via PaaSage and\nCAMEL, Scalarm managed to be executed in multi-cloud\nenvironments. Multi-Cloud deployments free Scalarm\nfrom vendor lock-in and allows for fine-grained opti-\nmization of computation cost by selecting the cheap-\nest possible cloud providers for executing large scale\ndata experiments. The master-worker architecture of\nScalarm makes it mostly insusceptible to network latency\nproblems (which may result from highly geographically\ndistributed deployments), and data farming does usu-\nally only requires to distribute the simulation binary\n- the input and output data remain reasonably small\nto avoid high of data transfers. Finally, by exploiting\nthe Scalarm CAMEL model, which is publicly avail-\nable, and modifying it according to specific deploy-\nments, PaaSage users can conduct data farming experi-\nments without any prior investment in software infras-\ntructure or the development of the right coordination\nsoftware.\nThescalarmcAMELmodel\nT h ek e yr e q u i r e m e n t sf o rt h eS c a l a r mu s ec a s ea r et h e\nabilitytodefineandmodifythedeploymentmodel,aswell\nas to specify both appropriate requirements and rules for\nautonomously conducting different data farming experi-\nments. For these reasons and the need to showcase the\nScalarm model definition in a clear and neat way, we\npresent the deployment, requirement, metric and scala-\nbility models. All other models are accessible through the\nPaaSagerepository 16.\n16ScalarmModel- https://gitlab.ow2.org/paasage/camel/blob/master/\nexamples/\nThescalarmdeploymentmodel.\nThe main concepts in thedeployment DSL are now exem-\nplified via the Scalarm use case. As such, part of the\ndeployment model is defined in Listing1 to reduce the\nmodel length and complexity. The “...” denotes additional\nCAMELelementsomittedfromreadability.\nListing1 ScalarmDeploymentmodel(excerpt)\n1 deployment model ScalarmDeployment {\n2 requirement set\nCoreIntensiveUbuntuGermanyRS {\n3 os: ScalarmRequirement.Ubuntu\n4 quantitative hardware:\nScalarmRequirement.CoreIntensive\n5 location: ScalarmRequirement.\nGermanyReq\n6 }\n7 vm CoreIntensiveUbuntuGermany {\n8 requirement set\nCoreIntensiveUbuntuGermanyRS\n9 provided host\nCoreIntensiveUbuntuGermanyHost\n10 }\n11 requirement set\nCPUIntensiveUbuntuGermanyRS {\n12 os: ScalarmRequirement.Ubuntu\n13 quantitative hardware:\nScalarmRequirement.CPUIntensive\n14 location: ScalarmRequirement.\nGermanyReq\n15 }\n16 vm CPUIntensiveUbuntuGermany {\n17 requirement set\nCPUIntensiveUbuntuGermanyRS\n18 provided host\nCPUIntensiveUbuntuGermanyHost\n19 }\n20 ...\n21 internal component ExperimentManager {\n22 provided communication ExpManPort {\nport: 443}\n23 required communication StoManPortReq\n{port: 20001 mandatory}\n24 required communication InfSerPortReq\n{port: 11300}\n25 required host\nCoreIntensiveUbuntuGermanyHostReq\n26 ...\n27 }\n28 internal component SimulationManager {\n29 required communication InfSerPortReq\n{port: 11300}\n30 required communication StoManPortReq\n{port: 20001}\n31 required communication ExpManPortReq\n{port: 443}\n32 required host\nCPUIntensiveUbuntuGermanyHostReq\n33 ....\n34 }\n35 ...\n36 communication\nSimulationManagerToExperimentManager\n{\n37 from SimulationManager.ExpManPortReq\nto ExperimentManager.ExpManPort\n38 }\n39 ...\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page16of25\n40 hosting\nExperimentManagerToCoreIntensiveUbuntu\nGermany {\n41 from ExperimentManager.\nCoreIntensiveUbuntuGermanyHostReq\nto\n42 CoreIntensiveUbuntuGermany.\nCoreIntensiveUbuntuGermanyHost\n43 }\n44 hosting\nSimulationManagerToCPUIntensiveUbuntu\nGermany {\n45 from SimulationManager.\nCPUIntensiveUbuntuGermanyHostReq\nto\n46 CPUIntensiveUbuntuGermany.\nCPUIntensiveUbuntuGermanyHost\n47 }\n48 ...\nAs dictated by its architecture (see Fig. 8), Scalarm\ncomprises four internal components, from which two are\npresented here along with their respective deployment\nrequirements. The ExperimentManager has one provided\ncommunicationport(443)andtworequiredcommunica-\ntionports(20001&11300).Italsorequirestobehostedon\nacoreintensiveVM(i.e.,hostingport). SimulationManager\nhas three required communication ports (11300 & 20001\n& 443) and requires to be hosted on a CPU intensive VM\n(i.e., hosting port). The two internal components define\nrequired hosting ports that need different VM nodes. In\nparticular, VM nodes must be associated with a 64bit\nUbuntu OS and be located in Germany, i.e., the nearest\nplace to Poland where major cloud providers have data\ncentres(seerequirementmodelinListing 2).\nThescalarmrequirementmodel.\nIn the above deployment model definition, the quanti-\ntative hardware requirements that must be respected by\nthecorrespondingVMsarereferenced.Thecoreintensive\nVM, defined in the model asCoreIntensiveUbuntuGermany,\nis associated with a quantitative requirement to incorpo-\nrate 8 to 32 cores and have a memory size from 4096\nto 8192 MB, while the CPU intensive VM, named as\nCPUIntensiveUbuntuGermany, must support a memory size\nbetween 8192 and 16384 MB. These requirements are\nactually specified (along with others) in the requirement\nmodelpresentedinListing 2.\nListing2 ScalarmRequirementmodel(excerpt)\n1 requirement model ScalarmRequirement {\n2 quantitative hardware CoreIntensive {\n3 core: 8..32\n4 ram: 4096..8192\n5 }\n6\n7 quantitative hardware CPUIntensive {\n8 core: 1..\n9 ram: 4096..8192\n10 cpu: 1.0..\n11 }\n12 ...\n13 os Ubuntu {os: ’Ubuntu’ 64os}\n14\n15 location requirement GermanyReq {\n16 locations [ScalarmLocation.DE]\n17 }\n18 ...\n19 horizontal scale requirement\nHorizontalScaleSimulationManager {\n20 component: ScalarmModel.\nScalarmDeployment.SimulationManager\n21 instances: 1 .. 5\n22 }\n23 ...\n24 slo CPUMetricSLO {\n25 service level: ScalarmModel.\nScalarmMetric.CPUMetricCondition\n26 }\n27 ...\nThescalarmscalabilitymodel.\nListing3showcasesthesolescalabilityruleoftheScalarm\napplication, which attempts to increase the number of\ninstances of theSimulationManager component by one\nwhen the mean CPU utilisation in its correspondingVM is\nequalorgoesabove80%.\nListing3 ScalarmScalabilitymodel(excerpt)\n1 scalability model ScalarmScalability {\n2 horizontal scaling action\nHorizScaleSimulationManager {\n3 type: SCALE OUT\n4 vm: ScalarmModel.ScalarmDeployment.\nCPUIntensiveUbuntuGermany\n5 internal component: ScalarmModel.\nScalarmDeployment.SimulationManager\n6 }\n7\n8 non-functional event CPUAvgMetricNFEAny\n{\n9 metric condition: ScalarmModel.\nScalarmMetric.CPUAvgMetricConditionAny\n10 violation\n11 }\n12 ...\n13 scalability rule CPUScalabilityRule {\n14 event: ScalarmModel.\nScalarmScalability.CPUAvgMetricNFEAny\n15 actions [ScalarmModel.\nScalarmScalability.\nHorizScaleSimulationManager]\n16 scale requirements [\nScalarmRequirement.\nHorizontalScaleSimulationManager]\n17 }\n18 }\nThis scalability rule, named as CPUScalabilityRule,\nmaps the CPU specific eventCPUAvgMetricNFEAny to the\nHorizontalScalingSimulationManager scaling action. It is\nalso associated to theHorizontalScaleSimulationManager\nscale requirement (see Listing 2) denoting that the\nnumber of instances of SimulationManager should\nbe at most 5, thus representing the actual upper\nscalability limit to hold for the scalability rule. The\nHorizontalScalingSimulationManager action indicates\nthat the SimulationManager component should scale\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page17of25\nout, as hosted by the CPUIntensiveUbuntuGermany VM\nnode, with an additional instance. On the other hand,\nthe CPUAvgMetricNFEAny is a single non-functional\nevent directly mapping to the violation of the\nCPUMetricCondition condition,asindicatedinListing 4.\nThescalarmmetricmodel\nFor brevity, the analysis focuses only on how the\nCPUAverage composite metric and its condition can be\nspecified in CAMEL (see Listing4. This metric condition\nparticipatesinthe CPUMetricSLO asindicatedinListing 2and\ntheCPUAvgMetricNFEAny non-functionaleventinListing 3.\nListing4 ScalarmMetricmodel(excerpt)\n1\n2 metric model ScalarmMetric {\n3 ...\n4 property CPUProperty {\n5 type: MEASURABLE\n6 sensors [ScalarmMetric.CPUSensor]\n7 }\n8 ...\n9 sensor CPUSensor {\n10 configuration: ’de.uniulm.omi.\ncloudiator.visor.sensors.\nSystemCpuUsageSensor’\n11 push\n12 }\n13 ...\n14 raw metric CPUMetric {\n15 value direction: 0\n16 layer: IaaS\n17 property: ScalarmModel.\nScalarmMetric.CPUProperty\n18 unit: ScalarmModel.ScalarmUnit.\nCPUUnit\n19 value type: ScalarmModel.\nScalarmType.Range_0_100\n20 }\n21 ...\n22 composite metric CPUAverage {\n23 description: \"Average of the CPU\"\n24 value direction: 1\n25 layer: PaaS\n26 property: ScalarmModel.\nScalarmMetric.CPUProperty\n27 unit: ScalarmModel.ScalarmUnit.\nCPUUnit\n28\n29 metric formula Formula_Average {\n30 function arity: UNARY\n31 function pattern: REDUCE\n32 MEAN( ScalarmModel.\nScalarmMetric.CPUMetric )\n33 }\n34 }\n35 ...\n36 raw metric context CPURawMetricContext\n{\n37 metric: ScalarmModel.ScalarmMetric.\nCPUMetric\n38 sensor: ScalarmMetric.CPUSensor\n39 component: ScalarmModel.\nScalarmDeployment.SimulationManager\n40 schedule: ScalarmModel.\nScalarmMetric.Schedule1Sec\n41 quantifier: ANY\n42 }\n43 ...\n44 composite metric context\nCPUAvgMetricContextAny {\n45 metric: ScalarmModel.ScalarmMetric.\nCPUAverage\n46 component: ScalarmModel.\nScalarmDeployment.SimulationManager\n47 window: ScalarmModel.ScalarmMetric.\nWin1Min\n48 schedule: ScalarmModel.\nScalarmMetric.Schedule1Min\n49 composing metric contexts [\nScalarmModel.ScalarmMetric.\nCPURawMetricContext]\n50 quantifier: ANY\n51 }\n52 ...\n53 metric condition CPUMetricCondition {\n54 context: ScalarmModel.ScalarmMetric\n.CPUAvgMetricContextAny\n55 threshold: 80.0\n56 comparison operator: >\n57 }\n58 ...\n59 schedule Schedule1Min {\n60 type: FIXED_RATE\n61 interval: 1\n62 unit: ScalarmModel.ScalarmUnit.\nminutes\n63 }\n64 schedule Schedule1Sec {\n65 type: FIXED_RATE\n66 interval: 1\n67 unit: ScalarmModel.ScalarmUnit.\nseconds\n68 }\n69 window Win1Min {\n70 window type: SLIDING\n71 size type: TIME_ONLY\n72 time size: 1\n73 unit: ScalarmModel.ScalarmUnit.\nminutes\n74 }\n75 ...\nThe CPUAverage composite metric is calculated by the\nFormula_Average formula, which applies theMEAN function\nover theCPUMetric, a raw metric computed by the push-\nbased CPUSensor sensor, part of the PaaSage platform and\nespeciallythe Executionware module.\nCPUMetricCondition is a composite metric condi-\ntion imposing that the metric refer to as CPUAverage\nshould be less than 80%. This condition refers to the\nCPUAvgMetricContextAny composite metric context. This\ncontext explicates theCPUAverage metric’s schedule and\nw i n d o w ,a sw e l la st h a ti ti sa p p l i e do v e rt h eSimulation-\nManagercomponent.Italsoreferstothecomposingmet-\nric’s raw metric context named asCPURawMetricContext.\nThe CPUAverage’sSchedule1Min schedule specifies that the\nmetric’smeasurementswillbecomputedrepeatedlyevery\n1min,accordingtothemetric’s Win1Min slidingwindow.\nCPURawMetricContext is the raw metric context for the\nCPUMetric. It explicates that theCPUSensor will be used\nto measure this metric and it is associated with the\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page18of25\nSchedule1Sec schedule,whichmeansthat CPUMetric’s mea-\nsurementswillbecalculatedevery1s.\nEvaluation\nPopulation\nFor evaluation purposes, CAMEL was exposed to differ-\nentpractitionersinthecontextofthePaaSageprojectuse\ncases. Practitioners were recruited from the personnel of\nthe organisations participating in the project that were\nresponsible for specific use cases. 23 individuals partici-\npatedinthestudy.Inordertodriveanalysisoftheresults,\nusing the two way ANOVA test, the participants were\nseparated to four groups based on their MDE and cloud\nknowledge. MDE and cloud knowledge were selected as\nthe two independent variables due to the need for eval-\nuation of CAMEL against the dependent variable: i.e.,\nusefulness or ease of use. In fact, the groups are: (i) 35%\nof the participants are under Group 1 with less to aver-\nageknowledgeofMDEandcloud( MDE ≤ 3,Cloud ≤ 3),\n(ii) 22% of the participants are under Group 2 with less\ntoaverageknowledgeofMDEandexcellentknowledgeof\nCloud(MDE ≤ 3,Cloud > 3),(iii)13%oftheparticipants\nare under Group 3 with excellent knowledge of MDE and\nlesstoaverageknowledgeofCloud( MDE > 3,Cloud ≤ 3)\nand (iv) 30% of the participants are under Group 4 with\nexcellent knowledge of MDE and with excellent knowl-\nedgeofCloud( MDE > 3,Cloud > 3).Hence,theresearch\nquestions were defined by taking into consideration the\ncompetences of the groups. Finally, all participants com-\npleted the evaluation questionnaire, which indicates that\nallresultsarevalidforanalysis.\nMethodology\nThe main aim of the evaluation was to collect practi-\ntioners’ feedback regarding the use and capabilities of\nCAMEL, and this feedback was considered in the first\nevaluation steps for updating CAMEL and its modelling\nenvironment, in order to make sure that the language\ncovers well different needs. The research study evalua-\ntion methodology is based on two factors. In specific,\nthe evaluation results were extracted on the basis of the\nTechnology Acceptance Model (TAM) [4, 11], where the\nfollowing TAM factors were considered:\n– PerceivedEaseofUse(PEU) : thedegreetowhicha\nuserbelievesthatCAMELreduces theeffortin\nmodellingtasks.\n– PerceivedUsefulness(PU) : thedegreetowhicha\nuserbelievesthatusing CAMELenhancesthe\nmodellingtasks’performance.\nThe participants used CAMEL language and edi-\ntor in the context of different business and research\ndomains, i.e., Data Farming, Automotive Simulation,\nFlight scheduling, ERP, Financial Services and Human\nMilk Bank, and completed a questionnaire for evaluat-\ning the above TAM factors. The studied use cases are\nsummarised in Table3. For more information on the use\ncases the interested reader may refer to the PaaSage web-\nsite17. In specific, the following steps were used for the\nevaluation:\n– The participantswerefamiliarisedwithdifferent\nCAMELversions,reportedbugs, requestedfeatures,\nandsuppliedfeedbacktodevelopers.\n– The participantsmodelledtheirusecasesscenarios\nwiththefinalversionofCAMELlanguageandeditor.\n– The participantsassessed CAMELfeaturesviaan\nonlinequestionnaire18.\nBased on the above, the final questionnaire was\ndivided into different section, covering : usability of the\nCAMELTextualEditor,CAMELdocumentation,CAMEL\nRequirements, CAMEL Metric Model, CAMEL Deploy-\nment Model, CAMEL Scalability Rules and CAMEL\nOrganisationModel,whereasdemographicdataandprior\nuser knowledge were also collected. The most important\nresults are assessed in “Technology acceptance”s e c t i o n\nto examine the opinion of the participants as to the use-\nf u l n e s sa n dt h ee a s eo fu s eo ft h eC A M E Ll a n g u a g ea n d\neditor, which indicates their willingness to accept and use\nthe new technology. The evaluation of the whole PaaSage\nplatform, e.g., in terms of performance, is not covered in\nthis work.\nMoreover, a statistical analysis is applied on the eval-\nuation results for reliability purposes and for detecting\nuseful conclusions (e.g., does the MDE experience of the\nparticipants affects their opinion in terms of PU and PEU\nfor CAMEL). Initially, the Cronback’s Alpha coefficient\nwas used for testing the reliability of the scale items.\nFollowing,atwofactorANOVAwithreplicationwasper-\nformed to examine the effect of the two independent\nvariables (MDE and Cloud experience) on a dependent\nvariable – PU or PEU (i.e., the test was executed twice).\nThistestalsoexamineswhethertheinteractionofthetwo\nindependentvariablesaffecteachothertoinfluenceeither\nthe PU or PEU dependent variable. Finally, a paired sam-\nple t-test was performed to determine whether the mean\ndifference between two sets of observations (i.e., PU and\nPEU)issignificantforthesamepopulation.\nReliabilityanalysis\nCronbach’s alpha was used in this work as a measure\nof internal consistency (i.e., reliability) for the designed\ninstrument. This coefficient is used since it provides the\ncapability to determine if a scale that is composed of\nmultipleLikertquestionsinasurveyisreliable.Inspecific,\n17PaaSageusecases- https://paasage.ercim.eu/use-cases/\n18EvaluationQuestionnaire -https://goo.gl/forms/Fwr3Lc33SGqTJj832\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page19of25\nTable3 ThePaaSageusecases\nName Sector Usecaseprovider Organisationtype Relevantapplication\nDatafarming eScience AGHUniversityofScience research Scalarm\nandTechnology\nAutomotive eScience HighPerformanceComputing research HPCsystems,e.g.\nsimulation Centre,AutomotiveSimulation ComputerAided\nCentreStuttgart Engineering\nFlightscheduling industrial LufthansaSystems consulting,ITservices NetLine/Sched\nERP industrial BeWan ITservices MultiTenant\nFinancialservice industrial UniversityofCyprus,IBSCY research,ITservices Quorum\nHumanmilkbank public EVRYSolutions ITservices HumanMilk\nBankProject\nthe reliability of each measurement is analogous to the\nextent that is a consistent measure of a concept, and the\nalpha coefficient is one way of measuring the strength of\nthatconsistency.Itiscalculatedbycorrelatingthescoreof\neachscaleitem(i.e.,question)withthetotalscoreofapar-\nticipant’s observation and by comparing it to the variance\nofindividualscaleitemscores.Basedonthesurveyresults\nthe alpha coefficient was computed for PU(α = 0.93)\nand for PEU(α = 0.70). The results indicate high relia-\nbility of the scale items (i.e., questions) for PU and PEU.\nIn fact, the literature accepts that a value ofα ≥ 0.70\nindicates high internal consistency (i.e., reliability) for the\ndesigned instrument. It also defines that as the number\nof questions increases then the reliability also increases.\nThis actually showcases the difference between the PU\nand PEU alpha values, since for the model completeness\nattribute of PU more questions were defined for evalu-\nating the completeness of each model (e.g., deployment,\nrequirement).\nTechnologyacceptance\nThe evaluation results are first examined in terms of the\ntwo factors of PU and PEU. In specific, based on the par-\nticipants responses it can be securely attested that the\nusefulness of CAMEL is high but the ease of use is rather\nlow. This is evident in Fig.9a, which shows that both\nthe mean and median values for perceived usefulness are\nhigher than that of perceived ease of use. Further exami-\nnation of each TAM factor reveals more details as to the\ninfluence of individual attributes on perceived usefulness\nandperceivedeaseofuse.Infact,forPUthetwoattributes\nexamined are the models completeness and the models\nquality. Figure9b presents the results from the analysis\nof these attributes. This indicates that both the model\ncompleteness and model quality are valued by the partic-\nipants, which shows that CAMEL language covers a large\nand diverse set of requirements for defining complete\nand quality cloud management models. Moreover, the\nparticipants high scores for model quality indicates that\nthey are satisfied also with the features provided by the\nCAMELeditor,e.g.,codecompletion,syntaxhighlighting,\nerrorreporting.\nBecauseoftheimportanceofCAMELmodelcomplete-\nness, which is one of the main contributions of this work,\nthe analysis was performed also at the level of individual\nmodelsaspresentedinFig. 9c.Infact,fromtheanalysisof\ntheresultsitisevidentthattheparticipantsratehigherthe\ndeployment, scalability and requirements models, while\nthemetricmodelisevaluatedlower.Thiscanbeattributed\nto the fact that in most use cases simple metric models\nwere defined using single metrics, such as CPU utilisa-\ntion. Nevertheless, more complex models and composite\nmetrics can be defined, but the platform limitation is that\nit only supports CPU and RAM sensors. This means that\nfor complex monitoring of VM resources the appropriate\nsensorsshouldbemanuallyimplementedanddeployedin\ntheplatformasJavaclasses.\nMoreover, the PEU of the CAMEL language and edi-\ntor was evaluated based on the attributes of effective-\nness and learning curve. The mean score for effective-\nness (see Fig. 9d) is the lowest one recorded from the\nentire set of attributes. This can be attributed, by exam-\nining the context and results of the individual questions\nfor effectiveness. In specific, the installation and use of\nthe CAMEL editor and language is rated higher than\nthe user-friendliness and model creation related ques-\ntions.Theseoutcomesarefurthersupportedbythelearn-\ning curve’s higher score. In fact, the participants gave\na low score to the easiness of learning how to use the\nCAMEL language and textual editor, but the extensive\ndocumentation provided for CAMEL is highly valuable\nto the users as indicated by the high scores on user-\nsupport provided by the documentation. This strongly\nsuggests that the users find the detailed documenta-\ntion as a key aspect that can minimise the learning\ncurve.\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page20of25\nFig.9 EvaluationResults. aTechnologyAcceptanceFactors. bPU-\nCompletenessandQuality. cCompletenessofCAMELmodels. dPEU\n-EffectivenessandLearning\nFinally, a paired samples t-test was performed to con-\nfirm the results displayed in Fig.9.T h i st y p eo ft e s ti s\na statistical procedure used to determine the mean dif-\nference between two sets of observations for the same\nsample size. In this work it is used to confirm that there\nis a significant mean difference between the participants\nobservationsforPUandPEU.Likemanystatisticalproce-\ndures, the paired sample t-test has a null hypothesis that\nassumesthatthetruemeandifferencebetweenthepaired\nsamples is zero. Statistical significance is determined by\nlooking at thep − value, which defines the probability\nof testing the survey results under the null hypothesis.\nExecuting the t-test on the scores of the same set of par-\nticipants on PU and PEU resulted to ap − value = .005.\nHence, the computed p-value is less than or equal to the\ncommonly accepted significance level(p − value ≤ .05),\nwhich means that the null hypothesis (PU and PEU mean\ndifference is zero) can be rejected. This indicates a statis-\ntically significant difference between the users opinions.\nThispracticallymeansthatusersfindCAMELhighlyuse-\nful, but believe that it can be improved in terms of ease\nofuse.\nGroup-Basedanalysis\nOn the basis of the technology acceptance model the per-\nceived usefulness and perceived ease of use factors are\nevaluated in this survey study. An important aspect that\nrequiresfurtheranalysisiswhataretheopinionsofpartic-\nipantsinaccordancetothegroupsdefinedinthisstudy.In\nspecific,itmaybeexpectedthatparticipantsunderGroup\n1 that have low to average knowledge of MDE and Cloud\n(i.e., MDE ≤ 3,Cloud ≤ 3) would provide a lower score\nto perceived ease of use of the CAMEL language and edi-\ntor.Therefore,inordertodetectiftherearedifferencesin\nthe observations of participants across groups a two-way\nANOVA statistical test was performed. This kind of test\ncompares the mean differences between groups that have\nbeen split based on two independent variables (i.e., MDE\nand Cloud experience of participants). The primary pur-\npose of this test is to understand if there is an interaction\nbetween the two independent variables on the dependent\nvariable (i.e., PU or PEU - test was executed twice). In\nthiswork,thetwo-wayANOVAwasperformedtounder-\nstand whether there is an interaction between MDE and\nCloud knowledge, which has an effect on the PU or PEU\nevaluationscores.\nTable4presentstheresultsofthetwo-wayANOVAtest,\ni.e., for PU and PEU. The ANOVA was used to test the\nfollowingnullhypotheses:\n(i) H1 - The means of observations grouped by one\nfactor(i.e.,MDEknowledgelevel)arethesame .Onthe\nbasis of the tests executed,H1 cannot be rejected for PU\nsincethe p−value = .53andalsoitcannotberejectedfor\nPEU since thep− value = .20. The values are way higher\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page21of25\nTable4 Two-wayANOVAanalysisresults\nPU-MEANS PEU-MEANS\nCloud ≤ 3 Cloud > 3 Cloud ≤ 3 Cloud > 3\nMDE ≤ 3 3.99 3.76 3.88 MDE ≤ 3 3.7 3.23 3.46\nMDE > 3 4.23 3.82 4.03 MDE > 3 4.10 3.43 3.76\n4.11 3.79 3.90 3.33\nthan the criticalp− value = .05, which indicates that the\nmeans for the groupMDE ≤ 3a n dt h eg r o u pMDE > 3\ncanbepracticallyconsideredthesame.Thisisbecauseno\nstatisticaldifferenceisobservedfromthesample,interms\noftheparticipantsopinionsforthetwogroups.Apossible\nexplanation is that the participants are highly knowledge-\nableofthemodel-drivenCAMELlanguageandeditordue\nto their involvement in the research project.\n(ii) H2 - The means of observations grouped by the\notherfactor(i.e.,Cloudknowledgelevel)arethesame .\nH2 cannot be rejected for PU since thep − value = .19,\nbut it can be rejected for PEU since thep− value = .002.\nThe calculated value for PEU is lower than the critical\np − value = .05, which indicates that the means for the\ngroup Cloud ≤ 3a n dt h eg r o u pCloud > 3 are different.\nThis is because a statistical difference is observed from\nthe sample, in terms of the participants opinions for the\ntwo groups. An assumption that can be made in terms of\nthisresultisthatcloudexpertsareabletothinkaheadand\nconsiderthecomplexityinvolvedindefiningamodelfora\ncomplexclouddeploymentandadaptationscenario.\n(iii) H3 - There is no interaction between the factors\n(i.e., MDE and Cloud knowledge level). Finally,H3 can-\nnotberejectedforPUsincethe p−value = .71andalsoit\ncannotberejectedforPEUsincethe p− value = .66.The\nvalues are way higher than the criticalp − value = .05,\nwhichindicatesthatthemeansfortheintersectiongroups\n(e.g., MDE ≤ 3, Cloud ≤ 3) can be practically considered\nthe same since no statistical difference is observed from\nthe sample. Hence, the participants opinions for the four\nintersectiongroupshaveastrongsimilarity.\nBased on the above group-based statistical analysis it\nis strongly suggested that MDE knowledge level does not\ninfluence the observations of participants in terms of the\nfactors of PU and PEU, while the Cloud knowledge level\nhas an effect on the participants observations for the\nPEU. Finally, the claim can be made that the interaction\nbetween MDE and Cloud knowledge has no effect on the\nparticipantsobservationsforbothPUandPEU.\nThreatstovalidity\nIn terms ofexternal validity —i.e., the extent to which\nthe conclusions can be generalised, the selected use cases\ncover a wide spectrum of identified aspects of self-\nadaptivecross-cloudapplications.However,extendingthe\nevaluation of CAMEL to other scenarios, environments,\nor even demographics may alter the findings. Internal\nvalidity, i.e., the extent to which the conclusions based\non a study are warranted is not affected, since the data\nare unambiguous. In terms ofconstruct validity,i . e .t h e\ndegree to which a test measures what it claims, is not\naffected, since all questions were carefully prepared to\ncover all capabilities of CAMEL and its textual editor.\nFinally, the small sample size (N = 23) and the fact\nthat the participants were part of the PaaSage project are\nperhaps the greatest threat to the validity of the results.\nFor this reason different statistical analysis test were per-\nformed for checking the reliability of the survey results\n(i.e., Cronbach’s Alpha) and for cross-checking the valid-\nity of the conclusions (i.e., paired t-test), e.g., participants\nfindCAMELmoreusefulandnotthateasytouse.Finally,\nANOVA tests were performed to conclude if MDE and\nCloud knowledge level affects the results.\nRelatedwork\nIn the following, the CAMEL language is compared with\nrelatedwork.ThefocusismainlyonCMLsthatspecialize\noncloudcomputingandnotgenericlanguagesthatmight\ncover one or more aspects relevant to MCRM. Such lan-\nguages should also have the right abstraction level, this\nbeing able to cover multiple and not just one cloud. In\nthis respect, cloud-specific languages, such as CloudFor-\nmation, which are tight to a certain cloud, as well as too\ndetailedandtechnicalonesareexcludedfromtheanalysis.\nComparisoncriteria\nIn the following, six comparison criteria are defined to\nevaluate the CMLs focusing on their usefulness, usabil-\nity, and self-adaptation. Theabstract syntax and aspect\ncoverage, delivery model support,a n dmodels@run-time\nsupport reflect the usefulness of the language; con-\ncrete syntax and integration level reflect the usabil-\nity; and models@run-time support also reflects the self-\nadaptation.\nAbstract syntax.AD S L ’ sa b s t r a c ts y n t a xd e s c r i b e st h e\nset of concepts, their attributes and relations, plus the\nrulesforcombiningthemtospecifyvalidstatementscon-\nformingtothissyntax.Theabstractsyntaxcanbedefined\nusing formalisms with different capabilities. For instance,\nXML Schema is suitable for tree-based structures, while\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page22of25\nMOF-based formalisms are more suited for graph-based\nstructures, offer better tool support and are better inte-\ngrated with constraint languages like OCL. This criterion\nidentifies the formalism used by a CML. Its evaluation\nspansthevaluesof“XMLSchema”and“MOF”.\nConcrete syntax.A concrete syntax describes the textu-\nal/graphical notation rendering the abstract syntax con-\ncepts, their attributes and relations. The concrete syn-\ntax can be defined using notations that have a trade-off\nbetween the syntax intuitiveness and effectiveness. For\ninstance, a textual syntax may be less intuitive but more\neffective than a graphical syntax. This criterion is used\nto identify the notations supported by a DSL. Its evalua-\ntion spans the values of “XML”, “txt” (textual), and “gra”\n(graphical).\nAspect coverage.A language may cover multiple aspects\nwithinthesameoracrossmultipledomains.Forinstance,\nin CAMEL the life cycle of cross-cloud applications is\nspecified using 11 aspects. This criterion reflects how\nmany of these aspects are covered by a language. Its eval-\nuation spans the values of “low” if the DSL covers at most\nthree aspects, “medium” if it covers at most six aspects,\nand“high”otherwise.\nIntegration level. A DSL that covers multiple aspects\nmay provide different integration levels, especially when\nthese aspects include similar or equivalent concepts. The\nintegrationsolutionmust:(a)joinequivalentconceptsand\nseparate similar ones into respective sub-concepts; (b)\nhomogenise the remaining concepts at the same granu-\nlarity level; (c) enforce a uniform formalism and notation\nfor the abstract and concrete syntaxes; (d) enforce model\nconsistency,correctness,andintegrity.Eachofthesesteps\nis a precondition to the following one and requires an\nincreasing amount of effort. This criterion reflects how\nmany steps have been adopted to integrate the sub-DSLs.\nIts evaluation spans the values of “low” if the sub-DSLs\nwere integrated following only step (a), “medium” if they\nwere integrated following steps (a) and (b), “high” if they\nwereintegratedfollowingallsteps,and“N/A”iftheywere\nnotintegrated.Thelastevaluationvaluemapstosub-DSL\nindependence that leads to the following disadvantages:\n(a) it raises the DSL complexity, since each sub-DSL has\nits own abstract and concrete syntax; (b) it steepens the\nlearning curve and increases the modelling effort for the\nsame reason; (c) it leads to the modelling duplication for\nsimilar or equivalent concepts; (d) it leads to the manual\nvalidationofcross-aspectdependencies.\nDelivery model support.A cross-cloud application may\nexploit any of the cloud delivery models (e.g., IaaS and\nPaaS). Thus, a language for specifying the life-cycle of\nsuch application should support concepts for every cloud\ndelivery model. As such, this criterion attempts to exam-\nine this. Its evaluation spans the values of “IaaS”, “PaaS”\nand“SaaS”.\nModels@run-timesupport.As indicatedin “Introduction”\nsection, models@run-time [9] can enable the automatic\nprovisioning of multi-cloud applications and can be\nimplemented using the type-instance pattern [ 3]. In\nCAMEL, the type-instance pattern was implemented in\nthe deployment and metric aspects. In the deployment\naspect, it allows to automatically adapt the component-\nand VM instances in the deployment model based on\nscalability rules (e.g., scale out a Scalarm service and its\nunderlying VM). In the metric aspect, the deployment\nadaptation is reflected also on the monitoring infrastruc-\nture. This criterion reflects how many of these aspects\nwithin a CML implement the type-instance pattern. Its\nevaluationspansthevaluesof“deployment”and“metric”.\nAnalysis\nTable5 shows the comparison results for the DSLs based\non the aforementioned criteria. As it can be seen below,\nCAMEL scores best in all criteria. Its superiority is high-\nlighted in terms of the aspect coverage and integration\nlevel criteria, plus its better support to different kinds of\ncloud services and to the specification of different type-\ninstance models focusing both on the deployment and\nmonitoring aspects. Thus, the claim that CAMEL does\nadvance the state-of-the-art in cloud application mod-\nelling and MCRM can be validated. The coverage of PaaS\nandSaaSserviceshasbeenrecentlyintroducedinCAMEL\nviaitsextensionintheCloudSocketproject.\nThe key CAMEL competitors are the Arcadia Con-\ntext Model, StratusML and more recently CloudMF. The\nfirst has been included, due to its good aspect cover-\nage which does not, however, go to a sufficient level\nof detail. The second, due to its high DSL integration\nlevel, which is mainly the outcome of following a similar\nintegration approach as in CAMEL. However, the main\ndifferentiation is that less integration effort has been put\nin StratusML, due to the generation of all DSLs from\nscratch and the minimalistic size of the overall language,\ncontaining around 60 concepts. StratusML does also sup-\nport the modelling of semantic domain validation rules.\nHowever, also witnessed by its small size, this language\nis not expressive and extensive enough, not going to an\nappropriatelevelofdetailintheaspectscovered.Further-\nmore, the coverage of other aspects is missing. CloudMF\nis the only CML that supports deployment and metric\nin terms of the models@runtime support. In specific, it\nprovides a domain-specific language for specifying the\nprovisioninganddeploymentofmulti-cloudapplications,\nas well as an adaptation DSL implemented though as Java\nplain objects, offering a models@run-time environment\nfor the continuous provisioning, deployment and adapta-\ntion of applications. Finally, CloudMF presents a medium\naspectscoveragewithaminimalsetofconceptsandalow\nintegrationlevelasaresult.\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page23of25\nTable5 CloudLanguagesComparativeAnalysis\nLanguage Abstract Concrete Aspect Integration DeliveryModel Models@run-time\nSyntax Syntax Coverage Level Support Support\nReservoirOVFExtension(2009) XMLSchema XML low N/A IaaS N/A\nOptimisOVFExtension(2010) XMLSchema XML medium N/A IaaS N/A\nVamp(2011) XMLSchema XML low N/A IaaS N/A\n4CaaStBlueprintTemplate(2011) XMLSchema XML low N/A IaaS,PaaS N/A\nTOSCA(2013) XMLSchema XML,txt medium medium IaaS,PaaS N/A\nProviderDSL[ 40](2014) MOF XML,gra low medium IaaS N/A\nGENTL(2014) MOF gra,XML low N/A IaaS N/A\nModaCloudML(2014) MOF XML,gra,txt medium low IaaS,PaaS deployment\nCAML(2014) MOF gra medium medium IaaS N/A\nCAMEL(2014) MOF XML,gra,txt high high IaaS,PaaS,SaaS deployment,metric\nARCADIAContextModel(2015) XMLSchema XML high medium IaaS deployment\nStratusML(2015) MOF XML,gra medium high IaaS deployment\nCloudMF(2018) MOF XML,gra medium low IaaS,PaaS deployment,metric\nTOSCA and CAML come in the third place. In our\nview, TOSCA is not a competitor to CAMEL. It is rather\na standard that could benefit from CAMEL based on the\nfollowing directions: (a) coverage of additional domains\nnotcapturedbyTOSCA;(b)supportforthetype-instance\npattern and thus models@runtime. By following the sec-\nond direction, there is some integration work currently\nbeing conducted in form of a TOSCA interest group\nattempting to bring the PSTM part of CAMEL deploy-\nmentmetamodelintoTOSCA.\nWith the exception of TOSCA, the other three lan-\nguages (i.e., StratusML, Arcadia Context Model and\nCAML) do not have a good community support. This\nis evident from the fact that StratusML has been devel-\noped from a university group, while the other two lan-\nguages have been developed within certain European\nprojects but their support seems to be discontinued. On\nthe other hand, CAMEL undergoes constant evolution\nand some extensions have been already performed on it,\nlike the aforementioned PaaS/SaaS features, while oth-\ners are currently in development or planned. As such,\nCAMEL will be further optimised (e.g., Melodic EU\nH2020 Big-Data Cloud project), by also attempting to\nadopt some interesting modelling features from these\nlanguages.\nAs the languages are presented in a chronological order\ninthecomparisontable,someinterestingtime-basedpat-\nternscanbeinferredfromthistable:\n– WiththeexceptionofArcadiaContextModel,most\nrecentlanguages relyonMOF fortheirabstract\nsyntax.Maybethiscanbeexplainedpartlyduetothe\nuseofthelanguageinamodel-drivenmanagement\nframeworkandduetothevariousadvancedtools\navailableforMOF-basedlanguages thatassistintheir\nrapiddevelopment.\n– Coupledwiththefirstfindingisthefactthatthemost\nrecentlanguages doprovidesupportforthe\nproductionofgraphical/textualmodelsaccordingto\nthelanguage’sconcretesyntax.Thisenablesthento\nmovefromthecumbersomeXML-basedtoamore\nhuman-readableform,whichalso makesthemodels\nmoreconciseandeasiertobeedited/manipulated.\n– MostrecentDSLsdocaterforthemodels@runtime\napproach,thusprovidingbettersupportforthe\nadaptiveprovisioningofmulti-cloud applications,\nwithCAMELandCloudMFbeingtheonlyonesthat\nsupportbothdeploymentandmetric.Thismeans\nthattheydonotonlysupporttheadaptationofthe\napplicationandVMinstancesinthedeployment\nmodelbasedonscalabilityrules, buttheycaterso\nthattheadaptationisreflectedalso onthe\nmonitoringinfrastructure.\nIn this respect, based on these findings, both the design\nrequirements and choices made by the CAMEL develop-\ners can be validated, as the exploitation of Eclipse EMF &\nEcore enabled CAMEL to be rapidly developed and have\ntherightmodellingtoolssupportingitscontinuousevolu-\ntion,whilethemodels@runtimesupportenabledCAMEL\nto satisfy a quite recent, in its acknowledgement, but\ncriticalmodellingfeature.\nConclusions&futurework\nThis article has explained the development and imple-\nmentation of an innovative multi-DSL language called\nCAMEL, which advances the state-of-the-art by inte-\ngrating DSLs covering all suitable aspects required\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page24of25\nfor MCRM. The core parts of this DSL were anal-\nysed by also utilising a running use case drawn from\nthe PaaSage project, the actual development space of\nCAMEL.CAMELisalsoaccompaniedbyatextualeditor,\ncoveringitsconcretesyntaxandtargetingmainlyDevOps\nusers, which exhibits some nice features like syntax and\nerrorhighlightingaswellasauto-completion.\nBoth CAMEL and its textual editor were evaluated via\na user study involving well-qualified participants from\nuse case partner organisations in PaaSage. The evalua-\ntion results show that the editor’s usability is appropri-\nate and that CAMEL covers well its respective domains.\nSome interesting suggestions were also supplied, cur-\nrently considered in the development of the forthcom-\ning version of CAMEL. CAMEL is being continuously\nevolving due to its active community that spans at\nleast three organisations: SINTEF, University of Ulm\nand ICS-FORTH. This has been evident through cor-\nresponding extensions that have been performed on\nit in the context of European projects that succeeded\nPaaSage. Two examples of these projects are defined\nbelow.\nCloudSocket targeted the development of a platform\nsupporting the design and adaptive provisioning of\nbusiness-process-as-a-service (BPaaS) services. In that\nproject, two main extensions of CAMEL have been\nachieved: (a) support for PaaS and SaaS modelling; (b)\nmodelling of advanced adaptation rules [27]t h a tm a p\nevent patterns to adaptation workflows incorporating\nlevel-specific adaptation actions (e.g., scaling and ser-\nvice replacement ones). Melodic aims to support big\ndata application management. CAMEL is at the core of\nMelodic, which attempts to build upon the PaaSage plat-\nform to provide support to this application kind. As such,\nCAMEL is planned to be enhanced to cover the big data\naspect.AsMelodicisaformalPaaSagesuccessor,alsothe\nimprovements over the user survey suggestions will be\nincludedintheforthcomingCAMELrelease.Thatrelease\nis also planned to be enhanced with CAMEL extensions\nfrom other projects, like CloudSocket. This will then\nmap in producing an even more complete and extensive\nDSL, also broadening its application scope. Hence, the\nCAMEL community will continue its effort in optimising\nCAMEL and further extending it, possibly via participat-\ning in forthcoming projects that guarantee the respective\nfundingneeded.\nAbbreviations\nCAMEL:Cloudapplicationmodellingandexecutionlanguage;CML:Cloud\nmodellinglanguage;DSL:Domainspecificlanguage;EMF:Eclipsemodelling\nframework;IaaS:Infrastructureasaservice;MCRM:Multi-cloudresource\nmanagement;MDE:Modeldrivenengineering;PaaS:Platformasaservice;\nPITM:Providerindependenttopologymodel;PSTM:Providerspecifictopology\nmodel;OCL:Objectconstraintlanguage;SaaS:Softwareasaservice;SL:\nServicelevel;SLO:Servicelevelobjective;SRL:Scalabilityruleslanguage;\nTOSCA:Topologyandorchestrationspecificationforcloudapplications;XML:\nExtensiblemetadatalanguage;VM:Virtualmachine\nAcknowledgements\nSpecialthankstothePaaSageprojectpartnersfortheirindividual\ncontributionstoCAMELandthePaaSageplatform.\nAuthors’contributions\nAAdefinedtheevaluationframework,executedthesurveyandproducedthe\nevaluationresultsincludingthestatisticalanalysis.AAwrittentheevaluation\npartofthemanuscriptandcoordinated/refined/mergedthedifferent\nsections/contentsofthismanuscript.KKandARcontributedtothedefinition,\ndesignandimplementationofCAMELandcontributedmostofthecontent\nontheCAMELDSLs.GKassistedintheformulationoftheevaluation\nframework,theexecutionofthesurveyandtheresultsoftheevaluation,and\nrevisedtheevaluationsectioncontent.JDcontributedmainlytothe\nimplementationofCAMEL(inparticularinrespectwiththeinteractionwith\nPaaSagecomponents)andcontributed/reviewedthecontentontheCAMEL\nDSLssectionsinthemanuscript.MOcontributedtothedefinitionand\nrealisationoftheCAMELscalarmusecaseandthewritingoftheusecase\nsectioninthemanuscript.DSandFGassistedmainlytotheimplementationof\nCAMEL(inparticularinrespectwiththeinteractionwithPaaSage\ncomponents)andcontributed/reviewedthecontentontheCAMELDSLs\nsectionsinthemanuscript.NNandDRassistedinthedefinition,designand\nimplementationofCAMEL.GPassistedinthedefinitionoftheevaluation\nframeworkandrevisedtherelevantsectioninthemanuscript.Allauthorshave\nreviewedthecompletemanuscriptandprovidedcommentsandsuggestions\nthatweretakenintoconsiderationbyAAtofinalisethepaper.\nAuthors’information\nCAMELisaninnovativemulti-DSLlanguage,whichadvancesthe\nstate-of-the-artbyintegratingandextendingDSLscoveringallsuitable\naspectsrequiredformulti-cloudresourcesmanagement.Itaddressesboth\ndesigntimeandmodel@runtimeaspectsandcontinuestoevolveasa\nlanguagetoaddressthemanydifferentfacetsofmulti-cloudresources\nmanagement.Inspecific,itcontinuescurrentlytoevolveaspartofthe\nMELODICH2020projecttoenablebigdata-awareapplicationdeployments\nongeographicallydistributedandfederatedcloudinfrastructures.\nFunding\nCAMELwasdefinedintheEUPaaSageprojectthatwasfundedfromthe\nEuropeanUnion’sFP7ResearchandInnovationProgrammeunderthetopic\nICT-2011.1.2-CloudComputing,InternetofServicesandAdvancedSoftware\nEngineeringwithGrantAgreementNo317715.\nAvailabilityofdataandmaterials\nSurveyDataandEvaluationresultsusedinthisworkcanbefoundhere:\nhttp://tiny.cc/pmqibzRelevantdocumentationforCAMELcanbefoundhere:\nhttp://camel-dsl.org/documentation/ andthecode/modelsrepositoriescan\nbefoundhere: https://gitlab.ow2.org/paasage/undertheCAMELrepository.\nNoadditionaldatahavebeenusedinthisstudy.\nCompetinginterests\nNocompetinginterestsbetweenauthorsforthismanuscript.\nAuthordetails\n1FrederickUniversity,Nicosia,Cyprus. 2ICS-FORTH,Heraklion,Crete,Greece.\n3PwCConsulting,Oslo,Norway. 4UniversityofCyprus,Nicosia,Cyprus. 5Ulm\nUniversity,Ulm,Germany. 6AGH,Warsaw,Poland. 7SINTEF,Oslo,Norway. 8LIFL,\nInriaLille,France.\nReceived:27March2019 Accepted:22August2019\nReferences\n1. AndrieuxA,CzajkowskiK,DanA,KeaheyK,LudwigH,NakataT,PruyneJ,\nRofranoJ,TueckeS,XuM(2010)WebServicesAgreementSpecification\n(WS-Agreement).https://www.ogf.org/ogf/doku.php/documents/\ndocuments\n2. AndrikopoulosV,BinzT,LeymannF,StrauchS(2013)Howtoadapt\napplicationsforthecloudenvironment.Computing95(6):493–535.\nhttps://doi.org/10.1007/s00607-012-0248-2\n3. AtkinsonC,K ˙uhneT(2002)RearchitectingtheUMLinfrastructure.ACM\nTransModelComputSimul12(4):290–321\nAchilleosetal. JournalofCloudComputing:Advances,SystemsandApplications            (2019) 8:20 Page25of25\n4. BagozziRP,DavisFD,WarshawPR(1992)DevelopmentandTestofa\nTheoryofTechnologicalLearningandUsage.HumRelat45:659–686\n5. BaurD,DomaschkaJ(2016)Experiencesfrombuildingacross-cloud\norchestrationtool.In:Proceedingsofthe3rdWorkshoponCrossCloud\nInfrastructures&Platforms,CrossCloud’16.ACM,NewYork.pp4:1–4:6.\nhttp://doi.acm.org/10.1145/2904111.2904116\n6. BaurD,SeyboldD,GriesingerF,MasataH,DomaschkaJ(2018)A\nprovider-agnosticapproachtomulti-cloudorchestrationusinga\nconstraintlanguage.In:Proceedingsofthe18thIEEE/ACMInternational\nSymposiumonCluster,CloudandGridComputing,CCGrid’18.IEEEPress,\nPiscataway.pp173–182. https://doi.org/10.1109/CCGRID.2018.00032\n7. BenavidesD,SeguraS,Cort ˙esAR(2010)Automatedanalysisoffeature\nmodels20yearslater:Aliteraturereview.InfSyst35(6):615–636\n8. BergmayrA,BreitenbücherU,FerryN,RossiniA,SolbergA,\nManuelWimmerKappelG,LeymannF(2018)ASystematicReviewof\nCloudModelingLanguages.ACMComputSurv51:1–38\n9. BlairG,BencomoN,FranceR(2009)Models@run.time.IEEEComput\n42(10):22–27\n10. ChiuPH,PotekhinM(2010)Pilotfactory-aCondor-basedsystemfor\nscalablePilotJobgenerationinthePandaWMSframework.JPhysConf\nSer219(6):062,041. http://stacks.iop.org/1742-6596/219/i=6/a=062041\n11. DavisFD(1989)PerceivedUsefulness,PerceivedEaseofUse,andUser\nAcceptanceofInformationTechnology.MISQ13(3):319–340\n12. DomaschkaJ,BaurD,SeyboldD,GriesingerF(2015)Cloudiator:ACross-\nCloud,Multi-TenantDeploymentandRuntimeEngine.In:SummerSOC\n2015:9thWorkshopandSummerSchoolOnService-Oriented\nComputing2015. https://www.summersoc.eu/wp-content/uploads/\n2015/07/2.6.domaschka_cloudiator_summesoc2015.pdf\n13. DomaschkaJ,GriesingerF,SeyboldD,WesnerS(2017)Acloud-driven\nviewonbusinessprocessasaservice.In:CLOSER.pp739–746. https://\ndoi.org/10.5220/0006393107670774\n14. DomaschkaJ,KritikosK,RossiniA(2015)TowardsaGenericLanguagefor\nScalabilityRules.In:OrtizG,TranC(eds).AdvancesinService-Oriented\nandCloudComputing—WorkshopsofESOCC2014,Communicationsin\nComputerandInformationScience,vol.508.Springer.pp206–220.\nhttps://doi.org/10.1007/978-3-319-14886-1_19\n15. FerryN,ChauvelF,RossiniA,MorinB,SolbergA(2013)Managing\nmulti-cloudsystemswithCloudMF.In:SolbergA,BabarMA,DumasM,\nCuestaCE(eds).NordiCloud2013:2ndNordicSymposiumonCloud\nComputingandInternetTechnologies.ACM.pp38–45. https://doi.org/\n10.1145/2513534.2513542\n16. FerryN,RossiniA,ChauvelF,MorinB,SolbergA(2013)Towards\nmodel-drivenprovisioning,deployment,monitoring,andadaptationof\nmulti-cloudsystems.In:O’ConnerL(ed).CLOUD2013:6thIEEE\nInternationalConferenceonCloudComputing.IEEEComputerSociety.\npp887–894. https://doi.org/10.1109/cloud.2013.133\n17. FerryN,SongH,RossiniA,ChauvelF,SolbergA(2014)CloudMF:Applying\nMDEtoTametheComplexityofManagingMulti-CloudApplications.In:\nBilofR(ed).UCC2014:7thIEEE/ACMInternationalConferenceonUtility\nandCloudComputing.IEEEComputerSociety.pp269–277. https://doi.\norg/10.1109/ucc.2014.36\n18. GriesingerF,SeyboldD,WesnerS,DomaschkaJ,WoitschR,KritikosK,\nHinkelmannK,LaurenziE,IranzoJ,GonzálezRS,TuguranCV(2017)Bpaas\ninmulti-cloudenvironments-thecloudsocketapproach.In:European\nSpaceProjects:Developments,ImplementationsandImpactsina\nChangingWorld-Volume1:EPSPorto2017.INSTICC,SciTePress.\npp50–74. https://doi.org/10.5220/0007901700500074\n19. GruberTR(1993)Atranslationapproachtoportableontology\nspecifications.KnowlAcquis5(2):199–220\n20. HornG,SkrzypekP(2018)Melodic:utilitybasedcrossclouddeployment\noptimisation.In:201832ndInternationalConferenceonAdvanced\nInformationNetworkingandApplicationsWorkshops(WAINA).IEEE.\npp360–367. https://doi.org/10.1109/waina.2018.00112\n21. JefferyK,HoussosN,J ˙orgB,AssersonA(2014)Researchinformation\nmanagement:theCERIFapproach.IJMSO9(1):5–14\n22. KritikosK,DomaschkaJ,RossiniA(2014)SRL:AScalabilityRuleLanguage\nforMulti-CloudEnvironments.In:GuerreroJE(ed).CloudCom2014:6th\nIEEEInternationalConferenceonCloudComputingTechnologyand\nScience.IEEEComputerSociety.pp1–9. https://doi.org/10.1109/\ncloudcom.2014.170\n23. KritikosK,KirkhamT,KryzaB,MassonetP(2015)SecurityEnforcementfor\nMulti-CloudPlatforms—TheCaseofPaaSage.ProcediaComputSci\n68:103–115.CloudForward2015:1stInternationalConferenceonCloud\nForward:FromDistributedtoCompleteComputing\n24. KritikosK,KirkhamT,KryzaB,MassonetP(2017)Towardsa\nsecurity-enhancedpaasplatformformulti-cloudapplications.Futur\nGenerCompSyst67:206–226\n25. KritikosK,PlexousakisD(2006)SemanticQoSMetricMatching.In:\nECOWS.IEEEComputerSociety.pp265–274. https://doi.org/10.1109/\necows.2006.34\n26. KritikosK,PlexousakisD(2015)Multi-cloudapplicationdesignthrough\ncloudservicecomposition.In:2015IEEE8thInternationalConferenceon\nCloudComputing.IEEE.pp686–693. https://doi.org/10.1109/cloud.2015.\n96\n27. KritikosK,ZeginisC,SeyboldD,GriesingerF,DomaschkaJ(2017)A\nCross-LayerBPaaSAdaptationFramework.In:FiCloud. https://doi.org/10.\n1109/ficloud.2017.12\n28. Kr ˙olD,KitowskiJ(2016)Self-scalableservicesinserviceorientedsoftware\nforcost-effectivedatafarming.FuturGenerCompSyst54:1–15\n29. K ˙uhneT(2006)Mattersof(meta-)modeling.SoftwSystModel\n5(4):369–385\n30. MagoutisK,PapoulasC,PapaioannouA,KarniavouraF,AkestoridisDG,\nParotsidisN,KoroziM,LeonidisA,NtoaS,StephanidisC(2015)Design\nandimplementationofasocialnetworkingplatformforcloud\ndeploymentspecialists.JInternetServAppl6(1):19\n31. MunteanuVI, ¸SandruC,PetcuD(2014)Multi-cloudresource\nmanagement:cloudserviceinterfacing.JCloudComput3(1):3. https://\ndoi.org/10.1186/2192-113X-3-3\n32. NikolovN,RossiniA,KritikosK(2015)IntegrationofDSLsandMigrationof\nModels:ACaseStudyintheCloudComputingDomain.ProcediaComput\nSci68:53–66\n33. (2014)ObjectManagementGroup:ObjectConstraintLanguage. http://\nwww.omg.org/spec/OCL/2.4/\n34. Opara-MartinsJ,SahandiR,TianF(2016)Criticalanalysisofvendorlock-in\nanditsimpactoncloudcomputingmigration:abusinessperspective.J\nCloudComput5(1):4. https://doi.org/10.1186/s13677-016-0054-z\n35. QuintonC,HadererN,RouvoyR,DuchienL(2013)Towardsmulti-cloud\nconfigurationsusingfeaturemodelsandontologies.In:MultiCloud2013:\nInternationalWorkshoponMulti-cloudApplicationsandFederated\nClouds.ACM.pp21–26. https://doi.org/10.1145/2462326.2462332\n36. QuintonC,RomeroD,DuchienL(2013)Cardinality-basedfeaturemodels\nwithconstraints:apragmaticapproach.In:KishiT,JarzabekS,GnesiS\n(eds).SPLC2013:17thInternationalSoftwareProductLineConference.\nACM.pp162–166. https://doi.org/10.1145/2491627.2491638\n37. QuintonC,RouvoyR,DuchienL(2012)LeveragingFeatureModelsto\nConfigureVirtualAppliances.In:CloudCP2012:2ndInternational\nWorkshoponCloudComputingPlatforms.ACM.pp21–26. https://doi.\norg/10.1145/2168697.2168699\n38. RossiniA(2015)Cloudapplicationmodellingandexecutionlanguage\n(CAMEL)andthePaaSageworkflow.In:CelestiA,LeitnerP(eds).ESOCC\n2015:Workshopsofthe4thEuropeanConferenceonService-Oriented\nandCloudComputing,EUResearchProjectsTrack.Springer.pp437–439.\nhttps://doi.org/10.1007/978-3-319-33313-7\n39. RossiniA,KritikosK,NikolovN,DomaschkaJ,GriesingerF,SeyboldD,\nRomeroD(2015)D2.1.3—CAMELDocumentation.In:PaaSageproject\ndeliverable.https://paasage.ercim.eu/about/project-deliverables/206-\nd2-1-3-camel-documentation\n40. SilvaGC,RoseLM,CalinescuR(2014)CloudDSL:Alanguagefor\nsupportingcloudportabilitybydescribingcloudentities.In:Proceedings\nofthe2ndInternationalWorkshoponModel-DrivenEngineeringonand\nfortheCloud(CloudMDE),co-locatedwiththe17thInternational\nConferenceonModelDrivenEngineeringLanguagesandSystems\n(MoDELS2014),CEUR-WS.org.,vol.1242.pp36–45. http://ceur-ws.org/\nVol-1242/\n41. YuE,GiorginiP,MaidenN,MylopoulosJ(2011)SocialModelingfor\nRequirementsEngineering.In:TheMITPress. https://dl.acm.org/citation.\ncfm?id=1941925\nPublisher’sNote\nSpringerNatureremainsneutralwithregardtojurisdictionalclaimsin\npublishedmapsandinstitutionalaffiliations.",
  "topic": "Cloud computing",
  "concepts": [
    {
      "name": "Cloud computing",
      "score": 0.873632550239563
    },
    {
      "name": "Computer science",
      "score": 0.8383439779281616
    },
    {
      "name": "Provisioning",
      "score": 0.7991946935653687
    },
    {
      "name": "Usability",
      "score": 0.5306801795959473
    },
    {
      "name": "Software deployment",
      "score": 0.5290680527687073
    },
    {
      "name": "Vendor",
      "score": 0.5217221975326538
    },
    {
      "name": "Distributed computing",
      "score": 0.4906731843948364
    },
    {
      "name": "Workload",
      "score": 0.482781320810318
    },
    {
      "name": "Scheduling (production processes)",
      "score": 0.4183657169342041
    },
    {
      "name": "Software engineering",
      "score": 0.36073029041290283
    },
    {
      "name": "Operating system",
      "score": 0.18002936244010925
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Marketing",
      "score": 0.0
    },
    {
      "name": "Operations management",
      "score": 0.0
    },
    {
      "name": "Business",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I38552033",
      "name": "Frederick University",
      "country": "CY"
    },
    {
      "id": "https://openalex.org/I4210121775",
      "name": "FORTH Institute of Computer Science",
      "country": "GR"
    },
    {
      "id": "https://openalex.org/I4210087994",
      "name": "PricewaterhouseCoopers (Norway)",
      "country": "NO"
    },
    {
      "id": "https://openalex.org/I34771391",
      "name": "University of Cyprus",
      "country": "CY"
    },
    {
      "id": "https://openalex.org/I196349391",
      "name": "Universität Ulm",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I686019",
      "name": "AGH University of Krakow",
      "country": "PL"
    },
    {
      "id": "https://openalex.org/I173888879",
      "name": "SINTEF",
      "country": "NO"
    },
    {
      "id": "https://openalex.org/I174424907",
      "name": "Laboratoire d'Informatique Fondamentale de Lille",
      "country": "FR"
    }
  ],
  "cited_by": 52
}