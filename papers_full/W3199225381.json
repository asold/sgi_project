{
  "title": "Explainable Identification of Dementia From Transcripts Using Transformer Networks",
  "url": "https://openalex.org/W3199225381",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2335787579",
      "name": "Ilias Loukas",
      "affiliations": [
        "National Technical University of Athens"
      ]
    },
    {
      "id": "https://openalex.org/A2749243906",
      "name": "Askounis, Dimitris",
      "affiliations": [
        "National Technical University of Athens"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2960986212",
    "https://openalex.org/W2777738102",
    "https://openalex.org/W2102508963",
    "https://openalex.org/W2996722826",
    "https://openalex.org/W3097109903",
    "https://openalex.org/W3154143698",
    "https://openalex.org/W2888101456",
    "https://openalex.org/W3038424140",
    "https://openalex.org/W2964250703",
    "https://openalex.org/W3177040647",
    "https://openalex.org/W2043146194",
    "https://openalex.org/W2972932001",
    "https://openalex.org/W2953187724",
    "https://openalex.org/W3173926131",
    "https://openalex.org/W3163938617",
    "https://openalex.org/W2962979297",
    "https://openalex.org/W2516809705",
    "https://openalex.org/W3124172077",
    "https://openalex.org/W3128781814",
    "https://openalex.org/W3094848124",
    "https://openalex.org/W3096812425",
    "https://openalex.org/W2972757121",
    "https://openalex.org/W6770215930",
    "https://openalex.org/W3163659890",
    "https://openalex.org/W3096912371",
    "https://openalex.org/W3136937237",
    "https://openalex.org/W3094909210",
    "https://openalex.org/W3198521429",
    "https://openalex.org/W3097779478",
    "https://openalex.org/W2074037951",
    "https://openalex.org/W4230776553",
    "https://openalex.org/W6742094595",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W2963716420",
    "https://openalex.org/W6781275321",
    "https://openalex.org/W6766673545",
    "https://openalex.org/W6768021236",
    "https://openalex.org/W6763701032",
    "https://openalex.org/W6719057275",
    "https://openalex.org/W2951307134",
    "https://openalex.org/W3017402509",
    "https://openalex.org/W4239943352",
    "https://openalex.org/W3035685359",
    "https://openalex.org/W3172194418",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W3153955816",
    "https://openalex.org/W2110065044",
    "https://openalex.org/W3015228357",
    "https://openalex.org/W2119595472",
    "https://openalex.org/W2168415900",
    "https://openalex.org/W2030165119",
    "https://openalex.org/W2086129464",
    "https://openalex.org/W2089204216",
    "https://openalex.org/W2788403449",
    "https://openalex.org/W4287111064",
    "https://openalex.org/W2463565445",
    "https://openalex.org/W2740956487",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W3101278968",
    "https://openalex.org/W3047171714",
    "https://openalex.org/W2963668159",
    "https://openalex.org/W2913340405",
    "https://openalex.org/W2333916262",
    "https://openalex.org/W4297206627",
    "https://openalex.org/W3098824823",
    "https://openalex.org/W2891147667",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3143075381",
    "https://openalex.org/W2975059944",
    "https://openalex.org/W2991435809",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2925863688",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W2282821441",
    "https://openalex.org/W2989774088",
    "https://openalex.org/W2787020095"
  ],
  "abstract": "Alzheimer's disease (AD) is the main cause of dementia which is accompanied by loss of memory and may lead to severe consequences in peoples' everyday life if not diagnosed on time. Very few works have exploited transformer-based networks and despite the high accuracy achieved, little work has been done in terms of model interpretability. In addition, although Mini-Mental State Exam (MMSE) scores are inextricably linked with the identification of dementia, research works face the task of dementia identification and the task of the prediction of MMSE scores as two separate tasks. In order to address these limitations, we employ several transformer-based models, with BERT achieving the highest accuracy accounting for 87.50%. Concurrently, we propose an interpretable method to detect AD patients based on siamese networks reaching accuracy up to 83.75%. Next, we introduce two multi-task learning models, where the main task refers to the identification of dementia (binary classification), while the auxiliary one corresponds to the identification of the severity of dementia (multiclass classification). Our model obtains accuracy equal to 86.25% on the detection of AD patients in the multi-task learning setting. Finally, we present some new methods to identify the linguistic patterns used by AD patients and non-AD ones, including text statistics, vocabulary uniqueness, word usage, correlations via a detailed linguistic analysis, and explainability techniques (LIME). Findings indicate significant differences in language between AD and non-AD patients.",
  "full_text": "IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMA TICS, VOL. 26, NO. 8, AUGUST 2022 4153\nExplainable Identiﬁcation of Dementia From\nT ranscripts Using T ransformer Networks\nLoukas Ilias and Dimitris Askounis\nAbstract— Alzheimer’s disease (AD) is the main cause of\ndementia which is accompanied by loss of memory and\nmay lead to severe consequences in peoples’ everyday life\nif not diagnosed on time. Very few works have exploited\ntransformer-based networks and despite the high accuracy\nachieved, little work has been done in terms of model\ninterpretability. In addition, although Mini-Mental State\nExam (MMSE) scores are inextricably linked with the iden-\ntiﬁcation of dementia, research works face the task of de-\nmentia identiﬁcation and the task of the prediction of MMSE\nscores as two separate tasks. In order to address these\nlimitations, we employ several transformer-based models,\nwith BERT achieving the highest accuracy accounting for\n87.50%. Concurrently, we propose an interpretable method\nto detect AD patients based on siamese networks reaching\naccuracy up to 83.75%. Next, we introduce two multi-task\nlearning models, where the main task refers to the identi-\nﬁcation of dementia (binary classiﬁcation), while the aux-\niliary one corresponds to the identiﬁcation of the severity\nof dementia (multiclass classiﬁcation). Our model obtains\naccuracy equal to 86.25% on the detection of AD patients\nin the multi-task learning setting. Finally, we present some\nnew methods to identify the linguistic patterns used by AD\npatients and non-AD ones, including text statistics, vocab-\nulary uniqueness, word usage, correlations via a detailed\nlinguistic analysis, and explainability techniques (LIME).\nFindings indicate signiﬁcant differences in language be-\ntween AD and non-AD patients.\nIndex Terms — Alzheimer’s disease, dementia, BERT,\nmulti-task learning, LIME.\nI. INTRODUCTION\nA\nLZHEIMER’S disease (AD) constitutes a neurodegen-\nerative disease characterized by a progressive cognitive\ndecline and is the leading cause of dementia. Signs of dementia\ninclude amongst others: problems with short-term memory,\nkeeping track of a purse or wallet, paying bills, planning and\npreparing meals, remembering appointments, or travelling out\nof the neighborhood [1]. Because of the fact that Alzheimer’s\ndementia gets worse over time, it is important to be diagnosed\nearly. For this reason, several research works have been in-\ntroduced targeting at diagnosing dementia, which use imaging\nManuscript received 24 September 2021; revised 19 March 2022;\naccepted 26 April 2022. Date of publication 5 May 2022; date of current\nversion 9 August 2022.(Corresponding author: Loukas Ilias.)\nThe authors are with the Decision Support Systems Laboratory,\nSchool of Electrical and Computer Engineering, National T echnical Uni-\nversity of Athens, 15780 Athens, Greece (e-mail: lilias@epu.ntua.gr;\naskous@epu.ntua.gr).\nDigital Object Identiﬁer 10.1109/JBHI.2022.3172479\ntechniques [2], CSF biomarkers [3], [4], or EEG signals [5].\nDue to the fact that dementia affects speech to a high degree,\nrecently the research has moved towards dementia identiﬁcation\nfrom spontaneous speech, where several shared tasks [6], [7]\nhave been developed in order to distinguish AD from non-AD\npatients.\nSeveral research works have been conducted with regard\nto the identiﬁcation of AD patients using speech and tran-\nscripts. The majority of them have employed feature extrac-\ntion techniques [8]–[12], in order to train traditional Machine\nLearning (ML) algorithms, such as Logistic Regression, k-NN,\nRandom Forest, etc. However, feature extraction constitutes a\ntime-consuming procedure achieving poor classiﬁcation results\nand often demands some level of domain expertise. Recently,\nresearchers introduce deep learning architectures [13], [14], such\nas CNNs and BiLSTMs, so as to improve the classiﬁcation re-\nsults. Despite the success of transformer-based models in several\ndomains, their potential has not been investigated to a high\ndegree in the task of dementia identiﬁcation from transcripts,\nwhere research works [15] having proposed them, use their\noutputs as features to train shallow machine learning algorithms.\nConcurrently, all research works except one [16], train machine\nlearning models, in order to distinguish AD patients from non-\nAD patients, without taking into account the severity of dementia\nvia Mini-Mental State Exam (MMSE) scores. Motivated by this\nlimitation, we propose two multi-task learning models minimiz-\ning the loss of both dementia identiﬁcation and its severity.\nAt the same time, to the best of our knowledge, the research\nworks that have proposed deep learning models based on trans-\nformer networks have focused their interest only on improving\nthe classiﬁcation results obtained by CNNs, BiLSTMs etc. in-\nstead of exploring possible explainability techniques. Speciﬁ-\ncally, due to the fact that deep learning models are considered\nblack boxes, it is important to propose ways of making them\ninterpretable, since it is imperative for a clinician to be informed\nwhy the speciﬁc deep neural network classiﬁed a person as\nAD patient or not. To the best of our knowledge, only one\nwork [17] has experimented with interpreting its proposed deep\nlearning model (CNN-LSTM model) in the ﬁeld of dementia\ndetection using transcripts. In order to tackle this limitation, our\ncontribution is twofold. First, we propose an interpretable neural\nnetwork architecture. Next, we extend prior work and employ\nLIME [18], a model agnostic framework for interpretability,\naiming to explain the predictions made by our best performing\nmodel. Concurrently, we propose an in-depth analysis of the\nlanguage patterns used between AD and non-AD patients aiming\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see\nhttps://creativecommons.org/licenses/by-nc-nd/4.0/\n4154 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMA TICS, VOL. 26, NO. 8, AUGUST 2022\nto shed more light on the main differences observed in the\nvocabulary that may distinguish people suffering from dementia\nfrom healthy people.\nOur main contributions can be summarized as follows:\nr We employ several transformer-based models, pretrained\nin biomedical and general corpora, and compare their\nperformances.\nr We propose an interpretable method based on the siamese\nneural networks along with a co-attention mechanism, so\nas to detect AD patients.\nr We introduce two models in a multi-task learning frame-\nwork, where the one task is the identiﬁcation of dementia\nand the second one is the detection of MMSE score (sever-\nity of dementia). We model the MMSE detection task as a\nmulticlass classiﬁcation task instead of a regression task.\nr We perform a thorough linguistic analysis regarding the\ndifferences in language between control and dementia\ngroups.\nr We employ LIME, in order to explain the predictions of\nour best performing model.\nII. RELA TEDWORK\nA. Feature-Based\nThe authors in [19], [20] introduced approaches based on\nmultimodal data (both linguistic and acoustic features) to detect\nAD patients (binary classiﬁcation task) and predict MMSE\nscore (regression task). More speciﬁcally, the authors in [19]\nexploited dimensionality reduction techniques followed by ma-\nchine learning classiﬁers and stated that Logistic Regression\n(LR) with language features was their best performing model in\nterms of classifying AD and non-AD patients. With regards to\nestimating the MMSE score, they claimed that a Random Forest\nclassiﬁer with language features achieves the lowest RMSE\nand R2 scores. The combination of linguistic and acoustic\nfeatures did not perform well on both tasks. In [20], the authors\ntrained both shallow and deep learning models (LSTM and\nCNN) on a feature set consisting of acoustic features (i-vectors,\nx-vectors) and text features (word vectors, BERT embeddings,\nLIWC features, and CLAN features) to detect AD patients. They\nfound that the top-performing classiﬁcation models were the\nSupport Vector Machine (SVM) and Random Forest classiﬁers\ntrained on BERT embeddings, which both achieved an accuracy\nof 85.4% on the test set. Regarding the regression task, they\nclaimed that the gradient boosting regression model using BERT\nembeddings outperformed all the other introduced architectures.\nAuthors in [15] trained shallow machine learning algorithms\n(Logistic Regression and Support Vector Machine for detecting\nAD patients, and Support Vector Machines based regression\nand Partial Least Squares Regressor for predicting the MMSE\nscores) using embeddings extracted by transformer-based mod-\nels, namely BERT, RoBERTa, DistilBERT, DistilRoBERTa, and\nBioMed-RoBERTa-base. A similar approach was conducted\nby [21], where the authors extracted embeddings for each word\nof the transcript using transformer-based networks, exploited\nfour types of pooling functions for generating a transcript-level\nrepresentation, and trained a Logistic Regression classiﬁer. Re-\nsearch work [22] merged acoustic (x-vectors) and linguistic fea-\ntures and trained a Support Vector Machine Classiﬁer. In terms\nof the language features, (i) a Global Maximum pooling, (ii) a\nbidirectional LSTM-RNNs provided with an attention module,\nand (iii) the second model augmented with part-of-speech (POS)\nembeddings were trained on the top of a pretrained BERT model.\nNasreen et al.[11] extracted two feature sets, namely disﬂuency\nand interactional features, and performed an in-depth statistical\nanalysis in an attempt to investigate the differences between AD\nand non-AD subjects in terms of these features. Findings show\nthat these two groups of people present signiﬁcant differences.\nThen, they exploited shallow machine learning algorithms using\nthe aforementioned feature sets to distinguish AD from non-AD\npatients and obtained an accuracy of 0.90 when providing both\nfeature sets as input to the SVM classiﬁer.\nB. Deep Learning\nResearch works [23], [24] employed a hierarchical attention\nneural network to detect AD patients. More speciﬁcally, the\nauthors in [23] evaluated their proposed model in both manual\nand automatic transcripts and found that a hierarchical neural\nnetwork achieves an improvement in F1-score in comparison to\nother deep learning models. In [24], the authors tried to interpret\nthe decisions made by the proposed model by visualizing words\nand sentences and performing statistical analyses. However, they\nwere not able to explain why their model pays attention to\nsome speciﬁc words more than others. Moreover, an explainable\napproach was introduced by [17]. Speciﬁcally, after proposing\nthree deep learning architectures based on CNNs and RNNs,\nthe authors applied visualization techniques and showed which\nlinguistic characteristics are indicative of dementia, i.e., short\nanswers, repeated requests for clariﬁcation, and interjections at\nthe start of each utterance. Authors in [25] proposed a multi-task\nlearning framework (Sinc-CLA), so as to predict age and MMSE\nscores (both considered as regression tasks) and used only\nspeech as input for their proposed network. Concurrently, they\nintroduced shallow networks with input i-vectors and x-vectors\nboth in single and multi-task learning frameworks. They claimed\nthat using x-vectors in a multi-task learning framework yields\nthe best results in terms of the estimation of both age and MMSE\nscores. Ref. [26] introduced both feature-based and transformer-\nbased methods. Regarding transformer-based models, they ﬁne-\ntuned the BERT model to detect AD patients achieving better\nevaluation results than the ones achieved via the feature-based\nmethods. For estimating the MMSE score they proposed only\nfeature-based approaches. Research work [16] is the most sim-\nilar to ours. The authors proposed transformer-based models\nusing text, audio, and images (they converted audio to images\nusing Mel Frequency Cepstral Coefﬁcient). Regarding text, they\nemployed BERT and Longformer. They claimed that models\nusing only text data outperformed all the other proposed ones.\nThe fusion of text and audio did not achieve better results.\nThey introduced also a multi-task learning architecture using\nonly text as input, in order to predict the MMSE score (re-\ngression task) and detect AD patients (binary classiﬁcation\nILIAS AND ASKOUNIS: EXPLAINABLE IDENTIFICA TION OF DEMENTIA FROM TRANSCRIPTS USING TRANSFORMER NETWORKS 4155\ntask). Results showed limited improvements in classiﬁcation\nand a negative impact in regression. We extend this research\nwork by employing more transformer-based networks with an\nefﬁcient training strategy, proposing a new interpretable method\nto detect AD patients based on siamese networks, introducing\ntwo models in a multi-task learning framework by regarding\nthe MMSE prediction task as a multiclass classiﬁcation task\nand employing explainability techniques. On the other hand,\nresearch works [27] & [28] introduced deep learning models\nincluding CNNs and LSTM neural networks with feed-forward\nhighway layers respectively. In [27] results suggested that the\nutterances of the interviewer boost the classiﬁcation perfor-\nmance. A similar methodology with [28] was proposed by [29],\nwhere the authors exploited both BERT and LSTMs with gating\nmechanism and showed that LSTM with gating mechanism\noutperforms BERT model with gating mechanism. They stated\nthat this difference may be attributable to the fact that BERT\nis very large in comparison to the LSTM models. Researchers\nin [30] introduced four approaches for detecting AD patients.\nSpeciﬁcally, they trained a hierarchical neural network with\nan attention mechanism on linguistic features. Concurrently,\nthey proposed a Siamese Neural Network and a Convolutional\nNeural Network using audio waveforms. Finally, they extracted\nfeatures from audio segments and trained an SVM classiﬁer.\nResults showed that the combination of audio features, CNNs,\nand hierarchical neural network achieved the best classiﬁcation\nresults.\nC. Related Work Review Findings\nFrom the aforementioned research works, it is evident that\ndespite the negative consequences dementia has in people’s\neveryday life, little work has been done so far towards its iden-\ntiﬁcation. More speciﬁcally, most researchers introduce feature\nextraction approaches from audio and transcripts and train ML\nalgorithms, such as SVM, LR, etc. Because of the fact that\nfeature extraction constitutes a time-consuming procedure and\ndoes not generalize well to new AD patients, researchers have\nstarted exploiting deep learning methods, such as CNNs and\nLSTMs, which obtain low performances. However, despite the\nfact that pretrained transformer models achieve new state-of-\nthe-art results in several domains, including the biomedical one,\ntheir potential has been mainly used as embeddings for training\nshallow ML algorithms, such as SVM or LR. Concurrently, little\nhas been done regarding the interpretability of the proposed deep\nlearning models as well as the main differences observed in the\nlanguage between AD patients and non-AD patients.\nOur work is different from the research works mentioned\nabove, since we: (a) propose several pretrained transformer-\nbased models and compare their performances, (b) introduce the\nidea of siamese neural networks along with a co-attention mech-\nanism towards the task of dementia classiﬁcation, (c) convert the\nMMSE regression task into a multiclass classiﬁcation one and\nexplore if it helps dementia identiﬁcation, (d) perform a detailed\nlinguistic analysis to ﬁnd the linguistic patterns that distinguish\nT ABLE I\nMEAN AND STA N DA R DDEVIA TION OF THEMMSE SCORES FOR THETWO\nMAIN GROUPS (AD AND NON-AD PAT I E N T S)\nAD patients from non-AD ones, and (e) exploit LIME for\nexplaining the predictions made by our best performing model.\nIII. DA T ASET\nWe use the ADReSS Challenge Dataset [6] for conducting\nour experiments. In contrast to other datasets, this dataset is\nmatched for gender and age, so as to minimize the risk of bias in\nthe prediction tasks. Moreover, it has been selected in such a way\nso as to mitigate biases often overlooked in evaluations of AD\ndetection methods, including repeated occurrences of speech\nfrom the same participant (common in longitudinal datasets) and\nvariations in audio quality. It consists of speech recordings along\nwith their associative transcripts and includes 78 non-AD and 78\nAD subjects. In addition, the dataset includes the MMSE scores\nfor each subject except one. We report the mean and standard\ndeviation of the MMSE scores for the two main groups, i.e., AD\npatients and non-AD ones, in Table I. Each participant (PAR) has\nbeen assigned by the interviewer (INV) to describe the Cookie\nTheft picture from the Boston Diagnostic Aphasia Exam [31].\nDue to the fact that the transcripts are annotated using the CHAT\ncoding system [32], we use the python library PyLangAcq [33]\nfor having access to the dataset. We use data (utterances) only\nfrom PAR and conduct our experiments at the transcript-level.\nThe ADReSS Challenge dataset has been divided into a train\nand a test set. The train set consists of 54 AD patients and 54\nnon-AD ones, while the test set consists of 24 AD patients and\n24 non-AD ones.\nIV . PROBLEM ST A TEMENT\nIn this section, the problem statement used in this paper is\npresented. More speciﬁcally, it can be divided into two problems,\nnamely the Single-Task Learning (STL) Problem and the Multi-\nTask Learning (MTL) Problem, which are presented in detail in\nSections IV-A and IV-B respectively.\nA. Single-Task Learning Problem\nLet a dataset Sn×2 =\n⎡\n⎢⎣\ns1, label1\ns2, label2\n...\nsn, labeln\n⎤\n⎥⎦ consist of a set of transcrip-\ntions belonging to the dementia group, d ⊂S , and a set of tran-\nscriptions belonging to the control group, c ⊂S . Furthermore,\nlabeli ∈{ 0,1},1 ≤ i ≤ n, where 0 denotes that si ∈ c, while\n1 denotes that si ∈ d. The task is to identify if a transcription\nsi ∈S , belongs to a person suffering from dementia, i.e., si ∈ d,\nor not, i.e., si ∈ c.\n4156 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMA TICS, VOL. 26, NO. 8, AUGUST 2022\nB. Multi-Task Learning Problem\nLet a dataset Sn×3 =\n⎡\n⎢⎣\ns1, label1, mmse1\ns2, label2, mmse2\n...\nsn, labeln, mmsen\n⎤\n⎥⎦ consist of a set of\ntranscriptions belonging to the dementia group, d ⊂S , and a set\nof transcriptions belonging to the control group, c ⊂S . Further-\nmore, labeli ∈{ 0,1},1 ≤ i ≤ n, where 0 denotes that si ∈ c,\nwhile 1 denotes that si ∈ d. Moreover, mmsei indicates the\nMMSE scores. The tasks here are to identify (i) if a transcription\nsi ∈S , belongs to a person suffering from dementia, i.e., si ∈ d,\nor not, i.e., si ∈ c,a sw e l la s (ii) to identify the MMSE scores\nof each person.\nV. PREDICTIVE MODELS\nIn this section, we describe the models used for detecting AD\npatients. Speciﬁcally, Section V-A refers to the models employed\nin the single-task learning setting, whereas in Section V-B we\nrefer to the models used for jointly learning to identify AD\npatients and detect the severity of dementia.\nA. Single-Task Learning\n1) Transformer-Based Models: We exploit the following\ntransformer-based networks in our experiments: BERT [34],\nBioBERT [35], BioClinicalBERT [36], ConvBERT [37],\nRoBERTa[38], ALBERT [39], and XLNet [40].\nRegarding our experiments, we pass each transcription\nthrough each pretrained model mentioned above. The output\nof each model is passed through a Global Average Pooling layer\nfollowed by two dense layers. The ﬁrst dense layer consists of\n128 units with a ReLU activation function and the second one\nhas one unit with a sigmoid activation function to give the ﬁnal\noutput.\n2) Transformer-Based Models With Co-Attention Mecha-\nnism: In this section, we present an interpretable method to\ndifferentiate AD from non-AD patients. First, we split each\ntranscription s in the dataset into two statements of equal length\n(s1 & s2). In this way, we have to categorize a pair of statements\n(s1 & s2) into dementia or control group. To do this, we pass\ns1 and s2 through the transformer-based models mentioned in\nSection V-A1, i.e., BERT, BioBERT, BioClinicalBERT, Con-\nvBERT, RoBERTa, ALBERT, and XLNet. These models can\nbe considered as siamese in our experiments, since we make\nthem share the same weights. Then, we implement a co-attention\nmechanism introduced by [41] and adopted in several studies,\nincluding [42], [43], over the two embeddings of the two state-\nments (outputs of the transformer-based models), in order to\nrender the entire architecture interpretable.\nFormally, let x1\n1,x1\n2,x1\n3,...,x 1\nN and x2\n1,x2\n2,x2\n3,...,x 2\nT be the\ntokens of s1 and s2 respectively. These tokens are passed to the\ntransformer-based models as described via the equations below:\nC = model\n(\nx1\n1,x1\n2,x1\n3,...,x 1\nN\n)\n,C ∈ Rd×N (1)\nS = model\n(\nx2\n1,x2\n2,x2\n3,...,x 2\nT\n)\n,S ∈ Rd×T (2)\nwhere model is one of the following: BERT, BioBERT, Bio-\nClinicalBERT, ConvBERT, RoBERTa, ALBERT, and XLNet.\nWe have omitted the ﬁrst dimension, which corresponds to\nthe batch size. Following the methodology proposed by [41],\ngiven the output of the model receiving the tokens of s1 (C ∈\nRd×N ) and the output of the model receiving the tokens of s2\n(S ∈ Rd×T ), where d denotes the hidden size of the model,\nthe afﬁnity matrix F ∈ RN×T is calculated using the equation\nF =t a n h\n(\nCT WlS\n)\n, where Wl ∈ Rd×d is a matrix of learn-\nable parameters. Next, this afﬁnity matrix is considered as a\nfeature and we learn to predict the attention maps for both\nstatements via the following, Hs =t a n h(WsS +( WcC) F)\nand Hc =t a n h\n(\nWcC +( WsS) FT )\n, where Ws,Wc ∈ Rk×d\nare matrices of learnable parameters. The attention probabil-\nities for each word in both statements are calculated through\nthe softmax function as follows, as = softmax\n(\nwT\nhsHs)\n,\nac = softmax\n(\nwT\nhcHc)\n, where as ∈ R1×T and ac ∈ R1×N .\nWhs,Whc ∈ Rk×1 are the weight parameters. Based on the\nabove attention weights, the attention vectors for each state-\nment are obtained by calculating the weighted sum of the\nfeatures from each statement. Formally, ˆs = ∑ N\ni=1 as\ni si,ˆc =∑ T\nj=1 ac\njcj, where ˆs ∈ R1×d and ˆc ∈ R1×d. Finally, these two\nvectors are concatenated, i.e., p =[ ˆs,ˆc], where p ∈ R1×2d and\nwe pass the vector p to a dense layer with 128 units and a ReLU\nactivation function followed by a dense layer consisting of one\nunit with a sigmoid activation function.\nB. Multi-Task Learning\nIn this section we propose two architectures based on multi-\ntask learning [44] and adopt the methodology followed by [45]\n& [46]. To be more precise, we employ a multi-task learning\nframework consisting of a primary and an auxiliary task. The\nidentiﬁcation of dementia constitutes the primary task, while\nthe prediction of the MMSE score constitutes the auxiliary one.\nOur main objective is to explore whether the MMSE score helps\nin classifying groups into dementia or control. The introduced\narchitectures are trained on the two tasks and updated at the same\ntime with a joint loss:\nL =( 1−α) Ldementia + αLMMSE (3)\nwhere Ldementia and LMMSE are the losses of dementia iden-\ntiﬁcation and MMSE prediction tasks respectively. αis a hyper-\nparameter that controls the importance we place on each task.\nWe mention below the MTL architectures developed.\na) MTL-BERT (Multiclass): We pass each transcription\nthrough a BERT model (which constitutes our best performing\nSTL model). The output of the BERT model is passed through\ntwo separate dense layers, so as to identify dementia and predict\nthe MMSE score. For identifying dementia, we use a dense layer\nwith 2 units and a softmax activation function and minimize\nthe cross-entropy loss function. Regarding the estimation of\nthe MMSE score, in contrast with previous research works, we\nconvert the MMSE regression task into a multiclass classiﬁca-\ntion task. More speciﬁcally, according to [28], we can create\n4 groups of cognitive severity: healthy (MMSE score ≥ 25),\nmild dementia(MMSE score of 21–24), moderate dementia\nILIAS AND ASKOUNIS: EXPLAINABLE IDENTIFICA TION OF DEMENTIA FROM TRANSCRIPTS USING TRANSFORMER NETWORKS 4157\n(MMSE score of 10–20), and severe dementia(MMSE score\n≤ 9). Thus, for classifying transcriptions into one of these 4\ngroups, we use a dense layer of 4 units with a softmax activation\nfunction and minimize the cross-entropy loss function.\nb) MTL-BERT -DE (Multiclass):Similarly to [46], we pass\neach transcription into a BERT model. The output of the BERT\nmodel is passed through two separate BERT encoders, i.e, dou-\nble encoders, which are followed by dense layers so as to identify\ndementia and classify MMSE score into one of the four classes\nmentioned above. For identifying dementia, we use a dense layer\nwith 2 units and a softmax activation function and minimize the\ncross-entropy loss function. For classifying the MMSE score, we\nuse a dense layer with 4 units and a softmax activation function\nand minimize the cross-entropy loss function.\nVI. EXPERIMENTS\nAll experiments are conducted on a single Tesla P100-PCIE-\n16 GB GPU.\nA. Single-Task Learning\nComparison with state-of-the-art approaches: We\ncompare our introduced models with the following research\nworks, since these research works propose single-task learning\nmodels and test their proposed approaches on the ADReSS\nChallenge test set: (1) Text [15], (2) LSTM with Gating (Acous-\ntic + Lexical + Dis) [28], (3) Fusion Maj. (3-best) [30], (4)\nLogistic Regression (NLP) [20], (5) fastText, bi + trigram [27],\n(6) Attempt 5 [21], and (7) Fusion of system [22].\nExperimental Setup: Firstly, we divide the train set\nprovided by the Challenge into a train and a validation set\n(65%-35%). Next, we train the proposed architectures ﬁve times\nand test them using the test set provided by the Challenge.\nSpeciﬁcally, we freeze the weights of each pretrained model\n(BERT, BioBERT, BioClinicalBERT, ConvBERT, RoBERTa,\nALBERT, and XLNet) and update the weights of the rest layers.\nIn this way, these pretrained models act as ﬁxed feature extrac-\ntors. We train the proposed architectures using Adam optimizer\nwith a learning rate of 1e-4. We apply EarlyStopping and stop\ntraining, if the validation loss has stopped decreasing for 9\nconsecutive epochs. We also apply ReduceLROnPlateau, where\nwe reduce the learning rate by a factor of 0.2, if the validation\nloss has stopped decreasing for 3 consecutive epochs. When\nthis training procedure stops, we unfreeze the weights of the\npretrained models and train the entire deep learning architectures\nusing Adam optimizer with a learning rate of 1e-5. We apply\nEarlyStopping with a patience of 3 based on the validation loss.\nIn terms of models with a co-attention mechanism, we start\ntraining the proposed architectures using Adam optimizer with a\nlearning rate of 1e-3 and follow the same methodology. We also\napply dropout after the co-attention mechanism with a rate of 0.4.\nFor BERT, we have used the base-uncased model, for BioBERT\nwe have used BioBERT v1.1 (+PubMed), for ConvBERT we\nhave used the base model, for RoBERTawe have employed the\nbase model, for ALBERT we have used the base-v1 model, and\nfor XLNet we have used the base model. For these pretrained\nmodels, we have used the Transformers library [47]. 1\nEvaluation Metrics: We evaluate our results using Ac-\ncuracy, Precision, Recall, F1-score, and Speciﬁcity. All these\nmetrics have been calculated using the dementia class as the\npositive one.\nB. Multi-Task Learning\nComparison with state-of-the-art approaches: For\nthe primary task (AD Classiﬁcation task), we compare our\nintroduced models with BERT base [16], since this research\nwork proposes a multi-task learning model and tests its proposed\napproach on the ADReSS Challenge test set.\nExperimental Setup: Firstly, we divide the train set\nprovided by the Challenge into a train and a validation set\n(65%-35%). Next, we train the proposed architectures ﬁve times\nand test them using the test set provided by the Challenge.\nWe use the Adam optimizer with a learning rate of 1e-6. We\napply EarlyStopping and stop training, if the validation loss has\nstopped decreasing for 8 consecutive epochs. Regarding MTL-\nBERT-DE (Multiclass), we freeze the weights of the shared\nBERT model. Moreover, because of the class imbalance of the\nMMSE categories, we apply balanced class weights to the loss\nfunction (LMMSE ). We set α of (3) equal to 0.1. 2\nEvaluation Metrics: For the primary task (AD Classiﬁ-\ncation task), we evaluate our results using Accuracy, Precision,\nRecall, F1-score, and Speciﬁcity. All these metrics have been\ncalculated using the dementia class as the positive one.\nFor the auxiliary task (MMSE Classiﬁcation task), we eval-\nuate our results using the average weighted Precision, average\nweighted Recall, and average weighted F1-score.\nVII. RESULTS\nA. Single-Task Learning Experiments\nThe results of the proposed models mentioned in Section V-A\nare reported in Table II.A l s o ,Table II provides a comparison of\nour introduced models with existing research initiatives.\nRegarding our proposed transformer-based models, one can\neasily observe that BERT obtains the highest Recall, F1-score,\nand Accuracy accounting for 81.66%, 86.73%, and 87.50%\nrespectively. Speciﬁcally, BERT outperforms the other intro-\nduced transformer-based models in Recall by 1.67-13.33%, in\nF1-score by 2.01-10.98%, and in Accuracy by 1.25-9.17%.\nBioClinicalBERT achieves the second highest Accuracy and\nF1-score accounting for 86.25% and 84.72% respectively. Also,\nBioClinicalBERT obtains the highest Precision score equal to\n95.03% surpassing the other transformer-based models by 4.79-\n15.88%. RoBERTa achieves comparable results to BERT and\nBioClinicalBERT yielding an Accuracy and F1-score of 84.16%\nand 82.81% respectively. In addition, BioBERT and ConvBERT\ndemonstrate slight differences in Accuracy and F1-score, with\n1For BioClinicalBERT we have used the model in: https://huggingface.co/\nemilyalsentzer/Bio_ClinicalBERT\n2We used also the experimental setup of Section VI-A. However, lower\nevaluation results were achieved.\n4158 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMA TICS, VOL. 26, NO. 8, AUGUST 2022\nT ABLE II\nPERFORMANCE COMP ARISONAMONG PROPOSED STL MODELS AND\nSTAT E-OF-THE-ART APPROACHES ON THEADRESS CHALLENGE TEST SET\nReported values are mean ± standard deviation. Results are averaged across ﬁve runs.\nBioBERT surpassing ConvBERT in both metrics. Speciﬁcally,\nBioBERT surpasses ConvBERT in F1-score by 0.46% and in\nAccuracy by 0.84%. Moreover, we observe that ALBERT and\nXLNet achieve Accuracy scores equal to 78.33%, with ALBERT\nsurpassing XLNet in F1-score by 2.70%.\nRegarding our proposed transformer-based models with a co-\nattention mechanism, they achieve lower performance than the\nproposed transformer-based models except for ConvBERT+Co-\nAttention, ALBERT+Co-Attention, and XLNet+Co-Attention.\nMore speciﬁcally, ConvBERT+Co-Attention presents a slight\nsurge of 0.42% in Accuracy in comparison with ConvBERT,\nALBERT+Co-Attention presents an increase in Accuracy\nby 1.67% in comparison with ALBERT, and XLNet+Co-\nAttention demonstrates a slight increase of 0.42% in Accu-\nracy in comparison with XLNet. BERT+Co-Attention attains\nthe highest F1-score and Accuracy accounting for 83.85%\nand 83.75% respectively. BERT+Co-Attention outperforms the\nother models in terms of F1-score by 1.42-7.43%, and in\nterms of Accuracy by 1.25-5.00%. ConvBERT+Co-Attention\nT ABLE III\nPERFORMANCE COMP ARISONAMONG PROPOSED MTL MODELS AND\nSTAT E-OF-THE-ART APPROACHES ON THEADRESS CHALLENGE TEST SET\nFOR THE PRIMARY TASK (AD CLASSIFICA TIONTASK)\nReported values are mean ±standard deviation. Results are averaged across ﬁve runs.\nand BioClinicalBERT+Co-Attention demonstrate slight differ-\nences in F1-score and Accuracy, with ConvBERT+Co-Attention\nsurpassing BioClinicalBERT+Co-Attention in F1-score by\n0.44% and in Accuracy by 0.42%. BioBERT+Co-Attention\nand ALBERT+Co-Attention achieve almost equal F1-score re-\nsults, with BioBERT+Co-Attention attaining a higher Accuracy\nscore than ALBERT+Co-Attention by 1.66%. RoBERTa+Co-\nAttention and XLNet+Co-Attention demonstrate low perfor-\nmances attaining an Accuracy of 79.16% and 78.75% respec-\ntively.\nOverall, BERT constitutes our best performing model, since it\noutperforms all the other introduced models in F1-score and Ac-\ncuracy. Although there are models surpassing BERT in Precision\nand Recall, BERT outperforms all of them in F1-score, which\nconstitutes the weighted average of Precision and Recall. In\naddition, there are models that outperform BERT in Speciﬁcity.\nHowever, high speciﬁcity and low recall means that the model\ncannot diagnose the AD patients pretty well and consequently\nAD patients are misdiagnosed as non-AD ones.\nIn comparison with the state-of-the-art approaches, one can\nobserve that our proposed models achieve comparable perfor-\nmance to or outperform previous studies. More speciﬁcally,\nBERT outperforms all the research works, except [15], in terms\nof Accuracy by 2.08-8.33%, in F1-score by 1.33-8.68%, and\nin Recall by 2.66-14.99%. Moreover, BERT+Co-Attention sur-\npasses [22], [27], [28] in Accuracy by 2.50%, 0.42%, and 4.58%\nrespectively. Also, it surpasses [22], [27], [28] in Recall by\n17.49%, 5.16%, and 9.16% respectively. BERT+Co-Attention\noutperforms [22], [27], [28] in F1-score by 5.80%, 0.85%, and\n5.59% respectively.\nB. Multi-Task Learning Experiments\n1) Primary Task: The results of the introduced models de-\nscribed in Section V-B are reported in Table III.A l s o ,Table III\nprovides a comparison of our introduced approaches with state-\nof-the-art approaches.\nWith regards to our introduced models, one can easily ob-\nserve that MTL-BERT (Multiclass) outperforms MTL-BERT-\nDE (Multiclass) in terms of all the evaluation metrics except\nRecall. Speciﬁcally, MTL-BERT (Multiclass) surpasses MTL-\nBERT-DE (Multiclass) in Precision by 3.40%, in F1-score by\nILIAS AND ASKOUNIS: EXPLAINABLE IDENTIFICA TION OF DEMENTIA FROM TRANSCRIPTS USING TRANSFORMER NETWORKS 4159\nT ABLE IV\nRESULTS OF THEPROPOSED MTL MODELS ON THEADRESS CHALLENGE\nTEST SET FOR THEAUXILIARY TASK (MMSE CLASSIFICA TIONTASK)\nReported values are mean ± standard deviation. Results are averaged across ﬁve runs.\n0.88%, in Accuracy by 1.25%, and in Speciﬁcity by 4.16%.\nAlthough MTL-BERT-DE (Multiclass) surpasses MTL-BERT\n(Multiclass) in Recall by 1.67%, MTL-BERT (Multiclass) ob-\ntains a higher F1-score, which constitutes the weighted average\nof Precision and Recall. Therefore, MTL-BERT (Multiclass)\nconstitutes our best performing model in the MTL framework.\nIn comparison to the research work [16], as one can easily\nobserve, both our introduced models attain a higher Accuracy\nscore. To be more precise, MTL-BERT (Multiclass) outperforms\nBERT base [16] in Accuracy by 5.42%. In addition, MTL-BERT-\nDE (Multiclass) surpasses the research work [16] in Accuracy\nby 4.17%. These differences in performance are attributable to\nthe fact that we adopt a different training procedure than the one\nadopted by [16], we consider the MMSE task as a multiclass\nclassiﬁcation task instead of a regression task, as well as to the\ndifferent architectures proposed.\n2) Auxiliary Task:The results of the introduced models men-\ntioned in Section V-B for the auxiliary task (MMSE Classiﬁca-\ntion task) are reported in Table IV.\nAs one can easily observe, MTL-BERT (Multiclass) obtains\nan average weighted Precision of 73.62% surpassing MTL-\nBERT-DE (Multiclass) by 3.12%. However, MTL-BERT-DE\n(Multiclass) outperforms MTL-BERT (Multiclass) in average\nweighted Recall and average weighted F1-score by 1.26% and\n3.82% respectively.\nVIII. ANAL YSIS OF THELANGUAGE USED IN CONTROL AND\nDEMENTIA GROUPS\nWe ﬁnally perform an extensive analysis to uncover some\nunique characteristics, which discriminate the AD patients from\nthe non-AD ones, and understand the predictions made by our\nbest performing model as well as its limits.\nA. Text Statistics\nWe ﬁrst extract some statistics, namely the syllable count, the\nlexicon count, the difﬁcult words, and the sentence count, using\nthe TEXTSTAT library in Python, in order to understand better\nthe differences in language used between control and dementia\ngroups. More speciﬁcally, the syllable count refers to the number\nof syllables, the lexicon count to the number of words, and the\nsentence count to the number of sentences present in the given\ntext. With regards to the difﬁcult words, they refer to the number\nof polysyllabic words with a Syllable Count > 2 that are not\nincluded in the list of words of common usage in English [48].\nT ABLE V\nMEAN ± STA N DA R DDEVIA TIONMETRICS PER TRANSCRIPT\n† indicates statistical signiﬁcance between transcripts of control and\ndementia groups. All differences are signiﬁcant at p< 0.05 after\nbenjamini-hochberg correction.\nT ABLE VI\nJACCARD’S INDEX BETWEEN TRANSCRIPTS OF CONTROL AND DEMENTIA\nGROUP\nAfter extracting these statistics per transcript, we calculate the\nmean and standard deviation for both control and dementia\ngroups. We test for statistical signiﬁcance using an independent\nt-test for each metric between control and dementia groups and\nadjust the p-values using Benjamini-Hochberg correction [49].\nAs one can easily observe in Table V, the control group presents\na signiﬁcantly higher number of syllables, lexicon, and difﬁcult\nwords than the dementia group.\nB. Vocabulary Uniqueness\nIn order to understand the vocabulary similarities and dif-\nferences between control and dementia groups, we adopt the\nmethodology proposed by [50]. Formally, let P and C be the\nsets of unique words included in the control group and dementia\ngroup respectively. Next, we calculate the Jaccard’s index given\nby (4), in order to measure the similarity between ﬁnite sample\nsets. More speciﬁcally, the Jaccard’s index is a number between\n0 and 1, where 1 indicates that the two sets, namely P and C,\nhave the same elements, while 0 indicates that the two sets are\ncompletely different.\nJ(P,C )= |P ∩C|/|P ∪C| (4)\nAs observed in Table VI , the Jaccard’s index between the\ncontrol and dementia groups is equal to 0.4049, which indicates\nthat people with dementia tend to use a different vocabulary than\nthose in the control group.\nC. Word Usage\nApart from ﬁnding the vocabulary similarities and differ-\nences, it is imperative that patterns of word usage be investigated.\nThus, following the methodology introduced in [50], the main\nobjective of this section is to explore the differences between the\ntwo classes (control and dementia) with regard to the probability\nof using speciﬁc words more than others. Formally, let D1 and\nD2 be two documents, where D1 includes all the transcriptions\nof the control group, whereas D2 consists of transcriptions of\nthe dementia group. Moreover, we deﬁne S as the entire corpus\n4160 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMA TICS, VOL. 26, NO. 8, AUGUST 2022\nT ABLE VII\nKULLBACK-LEIBLER DIVERGENCE\nconsisting of D1 and D2. Now we can deﬁne the probability of\naw o r d wi in the document D1 in a collection of documents S\ngiven by (5):\nP(wi|D1,S)=( 1 −αD)P(wi|D1)+ αDP(wi|S) (5)\nSimilarly, we can deﬁne the probability of a word wi in the\ndocument D2 in a collection of documents S given by (6):\nP(wi|D2,S)=( 1 −αD)P(wi|D2)+ αDP(wi|S) (6)\nWe employ the Jelinek-Mercer smoothing method and con-\nsider that αD ∈ [0,1]. More speciﬁcally, αD is a parameter that\ncontrols the probability of words included only in one document\n(D1 or D2). In our experiments, we set αD equal to 0.2.\nMoreover, we deﬁne P(wi|S)=\nswi\n|S| , where swi denotes the\nnumber of times a word wi is included in the collection, whereas\n|S| is the total number of words occurrences in the collection.\nSimilarly, P(wi|D1)=\ndwi\n|D1|, where dwi denotes the number of\ntimes a word wi is presented in the document D1, whereas |D1|\nis the total number of words occurrences in the document D1.\nThe same methodology has been adopted for calculating the\nP(wi|D2).\nAfter having calculated the two distributions, i.e.,\nP(wi|D1,S) and P(wi|D2,S), we exploit the Kullback-Leibler\n(KL) divergence, in order to measure the difference of these\ntwo distributions. KL-divergence is always greater than zero\nand is given by (7). The larger it gets, the more different the two\ndistributions are.\nKL(P||C)=\n∑\nx\nP(x)logP(x)\nC(x) (7)\nAs one can easily observe in Table VII, the KL divergence\nbetween control and dementia groups is high indicating that\nthese two groups present differences regarding the probability\nof using some words more than others. Our ﬁndings agree\nwith the ones in [50], where the authors state that there are\nclear differences in terms of language use between positive\n(depression and self-harm) and control group, where the values\nof KL-divergence range from 0.18 to 0.21.\nD. Linguistic Feature Analysis\nFollowing the method introduced by [51], the main objective\nof this section is to shed light on which unigrams and pos-tags are\nmostly correlated with each class separately. To facilitate this,\nwe compute the point-biserial correlation between each feature\n(unigram and pos-tag) across all the transcriptions and a binary\nlabel (0 for the control and 1 for the dementia group). Before\ncomputing the correlation, we normalize features so that they\nsum up to 1 across each transcription. We use the point-biserial\ncorrelation, since it is a correlation used between continuous and\nbinary variables. It returns a value between -1 and 1. Since we are\nT ABLE VIII\nFEA TURESASSOCIA TEDWITH CONTROL AND DEMENTIA SUBJECTS,\nSORTED BY POINT-BISERIAL CORRELA TION\nAll correlations are signiﬁcant at P < 0.05 after\nbenjamini-hochberg correction.\nonly interested in the strength of the correlation, we compute the\nabsolute value, where negative correlations refer to the control\ngroup (label 0) and positive correlations refer to the dementia\none (label 1). We report our ﬁndings in Table VIII, where all cor-\nrelations are signiﬁcant at p< 0.05, with Benjamini-Hochberg\ncorrection [49] for multiple comparisons.\nAs one can easily observe, the pos-tags associated with the\ndementia group are the following: RB (adverbs), PRP (personal\npronoun), VBD (verb in past tense), and UH (interjection).\nOn the other hand, people in the control group tend to use\nVBG (verb, gerund, or present participle), DT (determiner),\nand NN (noun). These ﬁndings can be justiﬁed in Table IX ,\nwhere we present three examples of transcripts belonging to\nthe control group and three examples of transcripts belonging to\nthe dementia one. More speciﬁcally, we have assigned colours to\ndifferent pos-tags, so as to render the differences in the language\npatterns used by each group easily understandable to the reader.\nTo be more precise, red colour indicates the VBG pos-tag, yellow\nrefers to the DT pos-tag, fuchsia to the RB pos-tag, apricot to\nthe PRP pos-tag, navy blue to the VBD pos-tag, and the pine\ngreen to the UH pos-tag.\nWe observe that people in the dementia group tend to use\npersonal pronouns (he, she, I, them etc.) very often, since they\nare unable to remember the speciﬁc terms (mom, boy, etc.). This\nﬁnding agrees with the research conducted by [52], where the\nauthors state that personal pronouns present a high frequency\nin the speech of AD patients, since these people cannot ﬁnd\nthe target word. To be more precise, in a conversation people\nhave to remember what they have said during the entire con-\nversation. However, this is not possible in AD patients, who\npresent working memory impairment and thus tend to produce\nempty conversational speech (use of personal pronouns). On the\nother hand, people in the control group tend to use more nouns\ninstead of personal pronouns, since they are able to maintain\nvarious kinds of information.\nMoreover, AD patients tend to use verbs in the past tense\n(were, forgot, did, started) in contrast to people who are not\nsuffering from dementia and use verbs in the present participle.\nOne typical example that can illustrate this difference can be seen\nin the ﬁfth transcription in Table IX, i.e., ”oh have you heard of\nthat new game that they started to play after christmas? did you”.\nThe AD patient perhaps remembers a personal story from the\nILIAS AND ASKOUNIS: EXPLAINABLE IDENTIFICA TION OF DEMENTIA FROM TRANSCRIPTS USING TRANSFORMER NETWORKS 4161\nT ABLE IX\nEXAMPLES OF TRANSCRIPTS ALONG WITH THEIR LABELS\nRed colour indicates the VBG pos-tag, yellow refers to the DT pos-tag, fuchsia to the RB pos-tag, apricot to the PRP pos-tag, navy blue to the VBD pos-tag , and the pine green to the UH\npos-tag.\npast that wants to narrate, instead of the task he has been assigned\nto conduct. Therefore, the patient is not able to stay focused\non describing the picture. This ﬁnding is consistent with [53],\n[54], where the authors state that AD patients present difﬁculty\nin maintaining and continuing the development of a topic and\nthus demonstrate unexpected topic shifts. Also, this ﬁnding\nreveals a difference in language used by the AD patients and\nthe agrammatic aphasics. Speciﬁcally, patients with agrammatic\naphasia typically have problems using past tense inﬂection and\ninstead rely on inﬁnitive or present tense verb forms [55].\nIn addition, AD patients tend to use the UH (oh, yeah, well)\nand the RB (maybe, probably) pos-tags, since they are not certain\nof what they are describing due to the cognitive impairment.\nConcurrently, the UH pos-tag constitutes an example of empty\nspeech. More speciﬁcally, this pos-tag is used as ﬁller at the\nbeginning of each utterance, since AD patients are thinking of\nwhat to say.\nE. Explainability - Error Analysis\nIn this section, we employ LIME [18] (using 5000 samples)\nto explain the predictions made by our best performing model,\nnamely BERT, and shed more light regarding the differences in\nlanguage between AD and non-AD patients. More speciﬁcally,\nLIME generates local explanations for any machine learning\nclassiﬁer by introducing an interpretable model, which is trained\non data generated through observing differences in the classiﬁ-\ncation performance when removing tokens from the input string.\nExamples of explanations generated by LIME are illus-\ntrated in Figs. 1 -4. More speciﬁcally, Fig. 1 illustrates two\ntranscripts, whose ground-truth label is dementia, while our\nmodel predicts them as belonging to non-AD patients. Fig. 2\nrefers to transcripts with both ground-truth label and prediction\ncorresponding to dementia. In Fig. 3 , two transcripts are pre-\nsented, whose prediction is control and true label is control too.\nFinally, Fig. 4 illustrates transcripts, which are misclassiﬁed.\nThe ground-truth is control, whereas the prediction is dementia.\nMoreover, as one can observe, each token has been assigned\na colour, either blue or orange. To be more precise, the blue\ncolour indicates which tokens are indicative of the control group,\nwhilst the orange colour indicates tokens, which are used mainly\nby AD patients. The more intense the colours are, the more\nimportant these tokens are towards the ﬁnal classiﬁcation of the\ntranscript.\n4162 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMA TICS, VOL. 26, NO. 8, AUGUST 2022\nFig. 1. Label: Dementia, Prediction: Control.\nFig. 2. Label: Dementia, Prediction: Dementia.\nFig. 3. Label: Control, Prediction: Control.\nFig. 4. Label: Control, Prediction: Dementia.\nILIAS AND ASKOUNIS: EXPLAINABLE IDENTIFICA TION OF DEMENTIA FROM TRANSCRIPTS USING TRANSFORMER NETWORKS 4163\nAs one can easily observe in Fig. 2 , tokens belonging to the\nUH pos-tag, such as yeah and oh, are identiﬁed as important\nfor the dementia class by our best performing model. Moreover,\npersonal pronouns (she, they) and verbs in the past tense (got,\nhad) are also indicative of dementia. Also, our model considers\nthe token “here,” which corresponds to the RB pos-tag, indicative\nof the dementia class. These ﬁndings are consistent with the ones\nin Section VIII-D, where we have found that PRP, VBD, UH pos-\ntags as well as the unigram “here” are signiﬁcantly correlated\nwith the dementia class. In addition, our model identiﬁes the\nrepetition of token “and” as important for the dementia class.\nThis ﬁnding agrees with previous research works [17], where\nthe word “and” indicates a short answer and burst of speech.\nRegarding Fig. 3, one can easily observe that our model iden-\ntiﬁes tokens belonging to the VBG (putting, drying, blowing,\nstanding, etc.), DT (the, a), and NN (cookie, action, stool, etc.)\npos-tags as signiﬁcant for the control class. Concurrently, in\nconsistence with the ﬁndings in Section VIII-D, the unigrams\n“curtain” and “window” are used mainly by non-AD patients.\nWith regards to Figs. 1 and 4, our model is not able to\nclassify these transcripts correctly. One possible reason for such\nmisclassiﬁcations has to do with the fact that these transcripts\ninclude pos-tags which are indicative of both the control and\nthe dementia class. To be more precise, in Fig. 1 , the majority\nof tokens in both transcripts belong to the VBG, NN, and\nDT pos-tags, which are correctly identiﬁed by our model as\nsigniﬁcant for the control group. Words, like “and,” “him,” and\n“well” are used in a low frequency. Similarly to Fig. 1,i n Fig. 4,\nthe majority of tokens in each transcript belong to the pos-tags\nwhich are signiﬁcantly correlated with the dementia class. This\ncan be illustrated in Fig. 4(c) , where we observe the usage of\nwords, like “and,” “yeah,” “well” & “got”.\nIX. CONCLUSION AND FUTURE WORK\nWe introduced both single-task and multi-task learning mod-\nels. Regarding single-task learning models, we employed several\ntransformer-based networks and compared their performances.\nResults showed that BERT achieved the highest classiﬁcation\nperformance with accuracy accounting for 87.50%. Concur-\nrently, we introduced siamese networks coupled with a co-\nattention mechanism which can detect AD patients with an\naccuracy up to 83.75%. In terms of the multi-task learning\nsetting, it consisted of two tasks, the primary and the auxiliary\none. The primary task was the identiﬁcation of dementia (binary\nclassiﬁcation), whereas the auxiliary task was the categorization\nof the severity of dementia into one of the four categories\n-healthy, mild/moderate/severe dementia- (multiclass classiﬁca-\ntion). Speciﬁcally, we proposed two multi-task learning models.\nResults showed that our model achieves competitive results in\nthe MTL framework reaching accuracy up to 86.25% on the de-\ntection of AD patients. Next, we performed an in-depth linguistic\nanalysis, in order to understand better the differences in language\nbetween AD and non-AD patients. Finally, we employed LIME,\nin order to shed light on how our best performing model works.\nFindings suggest that AD patients tend to use personal pronouns,\ninterjection, adverbs, verbs in the past tense, and the token\n“and” at the beginning of utterances in a high frequency. On\nthe contrary, healthy people use verbs in present participle or\ngerund, nouns as well as determiners.\nOne limitation of the current research work is pertinent to the\nsmall dataset used for conducting our experiments. However,\nwe opted for this dataset, in order to mitigate different kinds of\nbiases that could otherwise inﬂuence the validity of the proposed\napproaches.\nWe conducted our experiments on the ADReSS Challenge\ndataset, which is matched for gender and age and consists of a\nstatistically balanced, acoustically enhanced set of recordings of\nspontaneous speech. Therefore, the results of this study could\nbe integrated into an application, which will predict whether a\nperson is an AD patient and will provide at the same time the\nreasons for this prediction via the explainability method.\nIn the future, we plan to investigate multimodal deep learning\nmodels incorporating both text and audio. Speciﬁcally, we plan\nto propose end-to-end trainable deep neural networks in contrast\nto existing research initiatives, which train multiple models\nseparately and then use majority-voting approaches. In addition,\nour aim is to investigate fusion methods, in order to assign\nmore importance to the most relevant modality and suppress the\nirrelevant information. Another future plan is to exploit further\nexplainability techniques, such as anchor explanations [56].\nREFERENCES\n[1] Alzheimer’s Association (2021), “What is dementia? Alzheimer’s disease\nand dementia.” Accessed: Jul. 30, 2021. [Online]. Available: https://www.\nhttps://www.alz.org/alzheimers-dementia/what-is-dementia\n[2] F. Zhang, Z. Li, B. Zhang, H. Du, B. Wang, and X. Zhang, “Multi-modal\ndeep learning model for auxiliary diagnosis of Alzheimer’s disease,”\nNeurocomputing, vol. 361, pp. 185–195, 2019.\n[3] A. Syed Hassan and T. Khan, “A machine learning model to predict\nthe onset of Alzheimer disease using potential cerebrospinal ﬂuid (CSF)\nbiomarkers,”Int. J. Adv. Comput. Sci. Appl., vol. 8, no. 12, pp. 124–131,\n2017.\n[4] C. Davatzikos, P. Bhatt, L. M. Shaw, K. N. Batmanghelich, and J. Q.\nTrojanowski, “Prediction of MCI to AD conversion, via MRI, CSF\nbiomarkers, and pattern classiﬁcation,” Neurobiol. Aging, vol. 32, no. 12,\npp. 2322.e19–2322.e27, 2011.\n[5] C. Ieracitano, N. Mammone, A. Hussain, and F. C. Morabito, “A novel\nmulti-modal machine learning based approach for automatic classiﬁcation\nof EEG recordings in dementia,” Neural Netw., vol. 123, pp. 176–190,\n2020.\n[6] S. Luz, F. Haider, Soﬁa de la Fuente, D. Fromm, and B. MacWhin-\nney, “Alzheimer’s dementia recognition through spontaneous speech:\nThe ADReSS challenge,” in Proc. InterSpeech, Shanghai, China, 2020,\npp. 2172–2176.\n[7] S. Luz, F. Haider, S. de la Fuente, D. Fromm, and B. MacWhinney,\n“Detecting cognitive decline using speech only: The ADReSSo challenge,”\nin Proc. InterSpeech, 2021, pp. 3780–3784.\n[8] J. Weiner and T. Schultz, “Selecting features for automatic screening for\ndementia based on speech,” in Proc. Int. Conf. Speech Comput., 2018,\npp. 747–756.\n[9] L. Calzá, G. Gagliardi, R. R. Favretti, and F. Tamburini, “Linguistic fea-\ntures and automatic classiﬁers for identifying mild cognitive impairment\nand dementia,” Comput. Speech Lang., vol. 65, 2021, Art. no. 101113.\n[10] K. C. Fraser, K. L. Fors, M. Eckerström, F. Öhman, and D. Kokkinakis,\n“Predicting MCI status from multimodal language data using cascaded\nclassiﬁers,” Front. Aging Neurosci., vol. 11, 2019, Art. no. 205.\n[11] S. Nasreen, M. J. R. Hough, and M. Purver, “Alzheimer’s dementia\nrecognition from spontaneous speech using disﬂuency and interactional\nfeatures,” Front. Comput. Sci., vol. 3, 2021. [Online]. Available: https:\n//www.frontiersin.org/article/10.3389/fcomp.2021.640669\n4164 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMA TICS, VOL. 26, NO. 8, AUGUST 2022\n[12] A. Khodabakhsh, S. Ku¸ sxuo˘glu, and C. Demiro˘ glu, “Natural lan-\nguage features for detection of Alzheimer’s disease in conversational\nspeech,” in Proc. IEEE-EMBS Int. Conf. Biomed. Health Informat., 2014,\npp. 581–584.\n[13] J. Chen, J. Zhu, and J. Ye, “An attention-based hybrid network for auto-\nmatic detection of Alzheimer’s disease from narrative speech,” in Proc.\nInterSpeech, 2019, pp. 4085–4089.\n[14] D. F. Palo and N. Parde, “Enriching neural models with targeted features\nfor dementia detection,” in Proc. 57th Annu. Meeting Assoc. Comput.\nLinguistics, Student Res. Workshop, Florence, Italy, 2019, pp. 302–308.\n[15] Z. S. Syed, M. S. S. Syed, M. Lech, and E. Pirogova, “Automated recog-\nnition of Alzheimer’s dementia using bag-of-deep-features and model\nensembling,”IEEE Access, vol. 9, pp. 88377–88390, 2021.\n[16] Y . Zhu, X. Liang, J. A. Batsis, and R. M. Roth, “Exploring deep transfer\nlearning techniques for Alzheimer’s dementia detection,” Front. Comput.\nSci., vol. 3, 2021. [Online]. Available: https://www.frontiersin.org/article/\n10.3389/fcomp.2021.624683\n[17] S. Karlekar, T. Niu, and M. Bansal, “Detecting linguistic characteristics\nof Alzheimer’s dementia by interpreting neural models,” in Proc. Conf.\nNorth Amer. Chapter Assoc. Comput. Linguistics, Hum. Lang. Technol.,\nNew Orleans, Louisiana, 2018, vol. 2, pp. 701–707.\n[18] M. T. Ribeiro, S. Singh, and C. Guestrin, “Why should I trust you?”\nexplaining the predictions of any classiﬁer,” in Proc. 22nd ACM SIGKDD\nInt. Conf. Knowl. Discov. Data Mining, 2016, pp. 1135–1144.\n[19] R’mani Haulcy and J. Glass, “Classifying Alzheimer’s disease using audio\nand text-based representations of speech,” Front. Psychol., vol. 11, 2021,\nArt. no. 3833.\n[20] Z. Shah, J. Sawalha, M. Tasnim, S. Qi, E. Stroulia, and R. Greiner, “Learn-\ning language and acoustic models for identifying Alzheimer’s dementia\nfrom speech,” Front. Comput. Sci., vol. 3, no. 4, 2021, Art. no. 624659.\n[21] M. S. S. Syed, Z. S. Syed, M. Lech, and E. Pirogova, “Automated\nscreening for Alzheimer’s dementia through spontaneous speech,” inProc.\nInterSpeech, 2020, pp. 2222–2226.\n[22] A. Pompili, T. Rolland, and A. Abad, “The INESC-ID multi-modal system\nfor the ADReSS 2020 challenge,” in Proc. InterSpeech, 2020, pp. 2202–\n2206.\n[23] Y . Pan, B. Mirheidari, M. Reuber, A. Venneri, D. Blackburn, and H. Chris-\ntensen, “Automatic hierarchical attention neural network for detecting\nAD,” in Proc. InterSpeech, 2019, pp. 4105–4109.\n[24] W. Kong, H. Jang, G. Carenini, and T. Field, “A neural model for predict-\ning dementia from language,” in Proc. Mach. Learn. HealthCare Conf.,\nPMLR, 2019, pp. 270–286.\n[25] Y . Pan, V . S. Nallanthighal, D. Blackburn, H. Christensen, and A. Härmä,\n“Multi-task estimation of age and cognitive decline from speech,” in Proc.\nIEEE Int. Conf. Acoust., Speech Signal Process., 2021, pp. 7258–7262.\n[26] A. Balagopalan, B. Eyre, F. Rudzicz, and J. Novikova, “To BERT or not to\nBERT: Comparing speech and language-based approaches for Alzheimer’s\ndisease detection,” in Proc. InterSpeech, 2020, pp. 2167–2171.\n[27] A. Meghanani, C. S. Anoop, and A. G. Ramakrishnan, “Recognition\nof Alzheimer’s dementia from the transcriptions of spontaneous speech\nusing fasttext and CNN models,” Front. Comput. Sci., vol. 3, no. 7, 2021,\nArt. no. 624558.\n[28] M. Rohanian, J. Hough, and M. Purver, “Multi-modal fusion with gat-\ning using audio, lexical and disﬂuency features for Alzheimer’s demen-\ntia recognition from spontaneous speech,” in Proc. InterSpeech, 2020,\npp. 2187–2191.\n[29] M. Rohanian, J. Hough, and M. Purver, “Alzheimer’s dementia recognition\nusing acoustic, lexical, disﬂuency and speech pause features robust to noisy\ninputs,” in Proc. InterSpeech, 2021, pp. 3820–3824.\n[30] N. Cummins et al., “A comparison of acoustic and linguistics methodolo-\ngies for Alzheimer’s dementia recognition,” in Proc. InterSpeech, 2020,\npp. 2182–2186.\n[31] J. T. Becker, F. Boiler, O. L. Lopez, J. Saxton, and K. L. McGonigle,\n“The natural history of Alzheimer’s disease: Description of study cohort\nand accuracy of diagnosis,” Arch. Neurol., vol. 51, no. 6, pp. 585–594,\nJun. 1994.\n[32] B. MacWhinney, The CHILDES Project: Tools for Analyzing Talk, Volume\nII: The Database. New York, NY , USA: Psychology Press, 2014.\n[33] J. L. Lee, R. Burkholder, G. B. Flinn, and E. R. Coppess, “Working with\nchat transcripts in Python,” Dept. Comput. Sci., Univ. Chicago, Chicago,\nIL, USA, Technical Rep. TR-2016-02, 2016.\n[34] J. Devlin, M. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training\nof deep bidirectional transformers for language understanding,” in Proc.\nConf. North Amer. Chapter Assoc. Comput. Linguistics: Hum. Lang.\nTechnol., Minneapolis, MI, 2019, vol. 1, pp. 4171–4186.\n[35] J. Lee et al., “BioBERT: A pre-trained biomedical language representa-\ntion model for biomedical text mining,” Bioinformatics, vol. 36, no. 4,\npp. 1234–1240, 2020.\n[36] E. Alsentzer et al., “Publicly available clinical BERT embeddings,” in\nProc. 2nd Clin. Natural Lang. Process. Workshop, Minneapolis, Min-\nnesota, USA, 2019, pp. 72–78.\n[37] Z. Jiang, W. Yu, D. Zhou, Y . Chen, J. Feng, and S. Yan, “ConvBERT:\nImproving bert with span-based dynamic convolution,” in Proc. Adv.\nNeural Inf. Process. Syst., 2020, vol. 33, pp. 12837–12848.\n[38] Y . Liu et al., “Roberta: A robustly optimized BERT pretraining approach,”\n2019. [Online]. Available: https://arxiv.org/abs/1907.11692\n[39] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut,\n“ALBERT: A lite bert for self-supervised learning of language repre-\nsentations,” in Proc. Int. Conf. Learn. Representations, 2020. [Online].\nAvailable: https://openreview.net/forum?id=H1eA7AEtvS\n[40] Z. Yang, Z. Dai, Y . Yang, J. Carbonell, R. R. Salakhutdinov, and Q.\nV . Le, “XLNet: Generalized autoregressive pretraining for language un-\nderstanding,” in Proc. Adv. Neural Inf. Process. Syst., 2019, vol. 32,\nArt. no. 517.\n[41] J. Lu, J. Yang, D. Batra, and D. Parikh, “Hierarchical question-image co-\nattention for visual question answering,” in Proc. Adv. Neural Inf. Process.\nSyst., 2016, vol. 29, pp. 289–297.\n[42] K. Shu, L. Cui, S. Wang, D. Lee, and H. Liu, “DEFEND: Explainable fake\nnews detection,” in Proc. 25th ACM SIGKDD Int. Conf. Knowl. Discov.\nData Mining, 2019, pp. 395–405.\n[43] Y . Lu and C. Li, “GCAN: Graph-aware co-attention networks for explain-\nable fake news detection on social media,” in Proc. 58th Annu. Meeting\nAssoc. Comput. Linguistics, 2020, pp. 505–514.\n[44] R. Caruana, “Multitask learning,” Mach. Learn, vol. 28, no. 1, pp. 41–75,\n1997.\n[45] S. Rajamanickam, P. Mishra, H. Yannakoudakis, and E. Shutova, “Joint\nmodelling of emotion and abusive language detection,” in Proc. 58th Annu.\nMeeting Assoc. Comput. Linguistics, 2020, pp. 4270–4279.\n[46] M. Jin and N. Aletras, “Modeling the severity of complaints in social\nmedia,” in Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics:\nHum. Lang. Technol., 2021, pp. 2264–2274.\n[47] T. Wolf et al., “Transformers: State-of-the-art natural language process-\ning,” in Proc. Conf. Empirical Methods Natural Lang. Process., Syst.\nDemonstrations, 2020, pp. 38–45.\n[48] B. Portelli, E. Lenzi, E. Chersoni, G. Serra, and E. Santus, “BERT\nprescriptions to avoid unwanted headaches: A comparison of trans-\nformer architectures for adverse drug event detection,” in Proc. 16th\nConf. Eur. Chapter Assoc. Comput. Linguistics: Main Volume, 2021,\npp. 1740–1747.\n[49] Y . Benjamini and Y . Hochberg, “Controlling the false discovery rate: A\npractical and powerful approach to multiple testing,” J. Roy. Stat. Soc., Ser.\nB (Methodological), vol. 57, no. 1, pp. 289–300, 1995.\n[50] E. Ríssola, M. Aliannejadi, and F. Crestani, “Beyond modelling: Under-\nstanding mental disorders in online social media,” in Proc. Eur. Conf. Inf.\nRetrieval, Springer, 2020, pp. 296–310.\n[51] H A. Schwartz et al., “Personality, gender, and age in the language of\nsocial media: The open-vocabulary approach,” PLoS One, vol. 8, no. 9,\n2013, Art. no. e73791.\n[ 5 2 ] A .A l m o r ,D .K e m p l e r ,M .C .M a c D o n a l d ,E .S .A n d e r s e n ,a n dL .K .\nTyler, “Why do alzheimer patients have difﬁculty with pronouns? work-\ning memory, semantics, and reference in comprehension and produc-\ntion in Alzheimer’s disease,” Brain Lang., vol. 67, no. 3, pp. 202–227,\n1999.\n[53] C. M. Watson, “An analysis of trouble and repair in the natural conver-\nsations of people with dementia of the Alzheimer’s type,” Aphasiology,\nvol. 13, no. 3, pp. 195–218, 1999.\n[54] L. J. Garcia and Y . Joanette, “Analysis of conversational topic shifts: A\nmultiple case study,” Brain Lang., vol. 58, no. 1, pp. 92–114, 1997.\n[55] R. Bastiaanse, “Why reference to the past is difﬁcult for agrammatic\nspeakers,”Clin. Linguistics Phonetics, vol. 27, no. 4, pp. 244–263, 2013.\n[56] M. T. Ribeiro, S. Singh, and C. Guestrin, “Anchors: High-precision model-\nagnostic explanations,” in Proc. 32nd AAAI Conf. Artif. Intell., 2018.",
  "topic": "Dementia",
  "concepts": [
    {
      "name": "Dementia",
      "score": 0.8090485334396362
    },
    {
      "name": "Interpretability",
      "score": 0.7380266189575195
    },
    {
      "name": "Computer science",
      "score": 0.6385157108306885
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5584365725517273
    },
    {
      "name": "Binary classification",
      "score": 0.5108084678649902
    },
    {
      "name": "Machine learning",
      "score": 0.5064412355422974
    },
    {
      "name": "Identification (biology)",
      "score": 0.4335331320762634
    },
    {
      "name": "Natural language processing",
      "score": 0.4172058701515198
    },
    {
      "name": "Speech recognition",
      "score": 0.3919183313846588
    },
    {
      "name": "Cognitive psychology",
      "score": 0.324524462223053
    },
    {
      "name": "Psychology",
      "score": 0.2969980239868164
    },
    {
      "name": "Support vector machine",
      "score": 0.25769537687301636
    },
    {
      "name": "Disease",
      "score": 0.24490755796432495
    },
    {
      "name": "Medicine",
      "score": 0.1979493796825409
    },
    {
      "name": "Botany",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Pathology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I174458059",
      "name": "National Technical University of Athens",
      "country": "GR"
    }
  ],
  "cited_by": 54
}