{
  "title": "Applications of Large Language Models (LLMs) in Breast Cancer Care",
  "url": "https://openalex.org/W4388331108",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2809724045",
      "name": "Vera Sorin",
      "affiliations": [
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A1498187152",
      "name": "Benjamin S Glicksberg",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2572125234",
      "name": "Yiftach Barash",
      "affiliations": [
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2155772135",
      "name": "Eli Konen",
      "affiliations": [
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2419298921",
      "name": "Girish Nadkarni",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": [
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2809724045",
      "name": "Vera Sorin",
      "affiliations": [
        "Sheba Medical Center",
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A1498187152",
      "name": "Benjamin S Glicksberg",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2572125234",
      "name": "Yiftach Barash",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2155772135",
      "name": "Eli Konen",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2419298921",
      "name": "Girish Nadkarni",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai",
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3109948322",
    "https://openalex.org/W3004088204",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4376122030",
    "https://openalex.org/W4379769651",
    "https://openalex.org/W4386477610",
    "https://openalex.org/W4387440167",
    "https://openalex.org/W4386399156",
    "https://openalex.org/W3010446820",
    "https://openalex.org/W4388081218",
    "https://openalex.org/W2911188335",
    "https://openalex.org/W4378783467",
    "https://openalex.org/W4386932783",
    "https://openalex.org/W4384558920",
    "https://openalex.org/W4381480701",
    "https://openalex.org/W4362521774",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4385620388",
    "https://openalex.org/W3201019271",
    "https://openalex.org/W4386302153",
    "https://openalex.org/W4379537569",
    "https://openalex.org/W4386565997"
  ],
  "abstract": "Abstract Purpose Recently introduced Large Language Models (LLMs) such as ChatGPT have already shown promising results in natural language processing in healthcare. The aim of this study is to systematically review the literature on the applications of LLMs in breast cancer diagnosis and care. Methods A literature search was conducted using MEDLINE, focusing on studies published up to October 22nd, 2023, using the following terms: “large language models”, “LLM”, “GPT”, “ChatGPT”, “OpenAI”, and “breast”. Results Five studies met our inclusion criteria. All studies were published in 2023, focusing on ChatGPT-3.5 or GPT-4 by OpenAI. Applications included information extraction from clinical notes, question-answering based on guidelines, and patients’ management recommendations. The rate of correct answers varied from 64-98%, with the highest accuracy (88-98%) observed in information extraction and question-answering tasks. Notably, most studies utilized real patient data rather than data sourced from the internet. Limitations included inconsistent accuracy, prompt sensitivity, and overlooked clinical details, highlighting areas for cautious LLM integration into clinical practice. Conclusion LLMs demonstrate promise in text analysis tasks related to breast cancer care, including information extraction and guideline-based question-answering. However, variations in accuracy and the occurrence of erroneous outputs necessitate validation and oversight. Future works should focus on improving reliability of LLMs within clinical workflow.",
  "full_text": "Applications of Large Language Models (LLMs) in Breast Cancer Care \nVera Sorin, MD1, 2; Benjamin S. Glicksberg, PhD3; Yiftach Barash, MD1, 2; Eli Konen, MD1; Girish \nNadkarni, MD4-5; Eyal Klang, MD1-5 \n \n1Department of Diagnostic Imaging, Chaim Sheba Medical Center, affiliated to the Sackler School of \nMedicine, Tel-Aviv University, Israel \n2DeepVision Lab, Chaim Sheba Medical Center, Tel Hashomer, Israel \n3Hasso Plattner Institute for Digital Health at Mount Sinai, Icahn School of Medicine at Mount Sinai, \nNew York, NY, USA \n4Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine at Mount Sinai, \nNew York, New York, USA \n5The Charles Bronfman Institute of Personalized Medicine, Icahn School of Medicine at Mount \nSinai, New York, New York, USA. \n \n \n \nCorresponding Author: \nVera Sorin, MD \nDepartment of Diagnostic Imaging, Chaim Sheba Medical Center  \nAddress: Emek Haela St. 1, Ramat Gan, Israel, 52621.  \nTel: +972-3-5302530, Fax: +972-3-5357315, Email: verasrn@gmail.com  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nAbstract \nPurpose: Recently introduced Large Language Models (LLMs) such as ChatGPT have already \nshown promising results in natural language processing in healthcare. The aim of this study is to \nsystematically review the literature on the applications of LLMs in breast cancer diagnosis and care. \nMethods: A literature search was conducted using MEDLINE, focusing on studies published up to \nOctober 22nd, 2023, using the following terms: “large language models”, “LLM”, “GPT”, \n“ChatGPT”, “OpenAI”, and “breast”. \nResults: Five studies met our inclusion criteria. All studies were published in 2023, focusing on \nChatGPT-3.5 or GPT-4 by OpenAI. Applications included information extraction from clinical \nnotes, question-answering based on guidelines, and patients’ management recommendations. The \nrate of correct answers varied from 64-98%, with the highest accuracy (88-98%) observed in \ninformation extraction and question-answering tasks. Notably, most studies utilized real patient data \nrather than data sourced from the internet. Limitations included inconsistent accuracy, prompt \nsensitivity, and overlooked clinical details, highlighting areas for cautious LLM integration into \nclinical practice. \nConclusion: LLMs demonstrate promise in text analysis tasks related to breast cancer care, including \ninformation extraction and guideline-based question-answering. However, variations in accuracy and \nthe occurrence of erroneous outputs necessitate validation and oversight. Future works should focus \non improving reliability of LLMs within clinical workflow.  \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \nIntroduction \nNatural language processing (NLP) is increasingly being used in healthcare, particularly within \noncology, allowing free-text analysis, with various applications1. This advancement has been further \namplified by the recent advent of large language models (LLMs). LLMs such as GPT, LLaMA, \nPaLM, and Falcon, are deep learning NLP algorithms2 that are based on the transformer architecture. \nThey are composed of billions of parameters, enabling processing and generation of text with \nremarkable accuracy3. Research into healthcare applications of these models is expanding4-8. GPT-4, \nfor instance, has achieved an 87% success rate on the USMLE9,10. With recent developments, it can \nnow also be applied to image analysis11.   \nBreast cancer stands as the most common cancer among women, leading to significant morbidity, \nmortality, and widespread concern6,12. With the increasing volume of medical data available, both \nclinicians and patients face the challenge of navigating and interpreting vast amounts of information. \nIn this context, LLM technology can be helpful, enabling automatic processing and presenting of \nrelevant data. Recent studies have evaluated applications of LLMs in breast cancer diagnosis and \nmanagement.  \nThe aim of this study is to review the literature on applications of LLMs in breast cancer care. \n \nMethods \nWe conducted a comprehensive literature search on the applications of LLMs in breast cancer \ndiagnosis and care using MEDLINE. The search included studies published up to October 22\nnd 2023. \nOur search query was “((\"large language models\") OR (llm) OR (gpt) OR (chatgpt) OR (openAI)) \nAND (breast)”. The initial search identified 96 studies. To ensure thoroughness, we also examined \nthe reference lists of the relevant studies. This however did not lead to additional relevant studies that \nmet our inclusion criteria. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \nThe criteria for inclusion in our review were English language full-length publications that \nspecifically evaluated the role and impact of LLMs in breast cancer diagnosis and care. We excluded \npapers that addressed other general applications of LLMs in healthcare or oncology without a \nspecific focus on breast cancer diagnosis and care.  \nTwo reviewers (VS, EKL) independently conducted the search, screened the titles, and reviewed the \nabstracts of the articles identified in the search. One discrepancy in the search results was discussed \nand resolved to achieve a consensus. Following this, the reviewers assessed the full text of the \nrelevant papers. In total, five publications met our criteria and were incorporated into this review. We \nsummarized the results of the included studies, detailing the specific LLMs used, the utilized tasks, \nnumber of cases, along with publication details in a table format. Figure 1 provides a flowchart \ndetailing the screening and inclusion procedure. \n \nResults \nAll five studies included in this review were published in 2023 (Table 1). All studies focused on \neither ChatGPT-3.5 or GPT-4 by OpenAI. Applications described include information extraction and \nquestion-answering. Three studies (\n60 .0 %) evaluated the performance of ChatGPT on actual patient \ndata13-15, as opposed to two studies that used data from the internet16,17.  \nRao et al. and Haver et al. evaluated LLMs for breast imaging recommendations16,17, Sorin et al. and  \nLukac et al. evaluated LLMs as supportive decision making tools in multidisciplinary tumor \nboards13,15, and Choi et al. used LLM for information extraction from ultrasound and pathology \nreports14,  (Figure 2). Performance of LLMs on different applications ranged from 64-98%. Best \nperformance rates were achieved for information extraction and question-answering, with correct \nresponses ranging from 88-98%14,16 (Table 2).  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \nAll studies discussed limitations of LLMs in the contexts the algorithms were evaluated (Table 3). In \nall studies some of the answers and information the models generated was false. When used as a \nsupport tool for tumor board, in some instances, the models overlooked relevant clinical details13,15. \nSorin et al. noticed absolute lack of referral to imaging13, while Rao et al. who evaluated \nappropriateness of imaging noticed imaging overutilization16. Some of the studies also discussed \nprompt sensitivity14,17, and difficulty to verify the reliability of the answers15-17. \nDiscussion \nIn this study we reviewed the literature on LLMs applications for breast cancer diagnosis and care. \nApplications described included information extraction from clinical texts, question-answering for \npatients and physicians, manuscript drafting and clinical management recommendations. \nPerformance ranged from 64-98% correct answers generated by the LLM, with best performance in \nquestion answering and information extraction tasks.  \nInterestingly, most studies in this review included real patients’ data as opposed to data from the \ninternet. When looking at the overall published literature on LLMs applications in healthcare, there \nare more publications evaluating LLMs performance on data from the internet, including \nperformance on board examinations and question-answering based on guidelines\n4. These analyses \nmay introduce contamination of data during model training, owing to the fact that LLMs were \ntrained on vast data from the internet. For commercial models such as OpenAI’s ChatGPT, the type \nof training data is not disclosed. Furthermore, these applications do not necessarily reflect on the \nperformance of these models in real-world clinical setting.  \nThe variety of tasks described in this review highlight the potential of LLMs in text analysis related \nto breast cancer care. However, while some claim that these models may eventually replace \nhealthcare personnel, currently, there are major limitations and ethical concerns that will not allow \nthis\n18. Using such models to augment physicians’ performance is more practical, albeit also \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \nconstrained by ethical issues19. LLMs enable automating different tasks that traditionally required \nhuman effort. An ability to analyze, extract and generate meaningful textual information could \npotentially decrease some of physicians’ workload and perhaps even decrease human errors.  \nThe reliance on LLMs and their potential integration in medicine should be balanced with caution. \nThe limitations discussed in the studies further underscore this note. These models can generate false \ninformation (termed “hallucination”) which can be seamlessly and confidently integrated into real \ninformation\n1. They can also perpetuate disparities in healthcare20,21. The inherent inability to trace \nthe exact decision-making process of these algorithms is a major challenge for trust and clinical \nintegration22. These models can also be vulnerable to cyber-attacks23.  \nThis review has several limitations. First, due to the heterogeneity of tasks evaluated in the studies, \nwe could not perform a meta-analysis. Second, we only included studies evaluating breast cancer \nrelated data. There are many studies that evaluate applications in oncology that may be relevant and \nextend to examples including breast cancer patients, these were not included. Third, all included \nstudies assessed ChatGPT-3.5, and only one study evaluated GPT-4. There were no publications \nidentified on other available LLMs. Finally, generative AI is currently a rapidly expanding topic. \nThus, there may be manuscripts and applications published after our review was performed. LLMs \nare continually being refined, and so is their performance.  \nTo conclude, LLMs show promise in text analysis related to breast cancer care, enabling information \nextraction and guideline-based question-answering. However, variations in accuracy and the \noccurrence of erroneous outputs necessitate validation and oversight. Future work should focus on \nimproving the reliability of LLMs within clinical workflow.  \n \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \nReferences \n1. Sorin V, Barash Y, Konen E, Klang E. Deep-learning natural language processing for \noncological applications. The Lancet Oncology. 2020;21(12):1553-1556. \n2. Sorin V, Barash Y, Konen E, Klang E. Deep Learning for Natural Language Processing in \nRadiology—Fundamentals and a Systematic Review. Journal of the American College of \nRadiology. 2020;17(5):639-648. \n3. Bubeck S, Chandrasekaran V, Eldan R, et al. Sparks of artificial general intelligence: Early \nexperiments with gpt-4. arXiv preprint arXiv:2303.12712. 2023. \n4. Sallam M. ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic \nReview on the Promising Perspectives and Valid Concerns. Healthcare. 2023;11(6):887. \n5. Sorin V, Barash Y, Konen E, Klang E. Large language models for oncological applications. \nJournal of Cancer Research and Clinical Oncology. 2023;149(11):9505-9508. \n6. Jiang LY, Liu XC, Nejatian NP, et al. Health system-scale language models are all-purpose \nprediction engines. Nature. 2023;619(7969):357-362. \n7. Temsah M-H, Altamimi I, Jamal A, Alhasan K, Al-Eyadhy A. ChatGPT Surpasses 1000 \nPublications on PubMed: Envisioning the Road Ahead. Cureus. 2023. \n8. Decker H, Trang K, Ramirez J, et al. Large Language Model−Based Chatbot vs Surgeon-\nGenerated Informed Consent Documentation for Common Procedures. JAMA Network Open. \n2023;6(10):e2336997. \n9. Brin D, Sorin V, Konen E, Nadkarni G, Glicksberg BS, Klang E. How Large Language \nModels Perform on the United States Medical Licensing Examination: A Systematic Review. \n2023. \n10. Chaudhry HJ, Katsufrakis PJ, Tallia AF. The USMLE Step 1 Decision. Jama. \n2020;323(20):2017. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \n11. Sorin V, Glicksberg BS, Barash Y, Konen E, Nadkarni G, Klang E. Diagnostic Accuracy of \nGPT Multimodal Analysis on USMLE Questions Including Text and Visuals. medRxiv. \n2023:2023.2010.2029.23297733. \n12. Siegel RL, Miller KD, Jemal A. Cancer statistics, 2019. CA: A Cancer Journal for Clinicians. \n2019;69(1):7-34. \n13. Sorin V, Klang E, Sklair-Levy M, et al. Large language model (ChatGPT) as a support tool \nfor breast tumor board. npj Breast Cancer. 2023;9(1). \n14. Choi HS, Song JY, Shin KH, Chang JH, Jang B-S. Developing prompts from large language \nmodel for extracting clinical information from pathology and ultrasound reports in breast \ncancer. Radiation Oncology Journal. 2023;41(3):209-216. \n15. Lukac S, Dayan D, Fink V, et al. Evaluating ChatGPT as an adjunct for the multidisciplinary \ntumor board decision-making in primary breast cancer cases. Archives of Gynecology and \nObstetrics. 2023;308(6):1831-1844. \n16. Rao A, Kim J, Kamineni M, et al. Evaluating GPT as an Adjunct for Radiologic Decision \nMaking: GPT-4 Versus GPT-3.5 in a Breast Imaging Pilot. Journal of the American College \nof Radiology. 2023. \n17. Haver HL, Ambinder EB, Bahl M, Oluyemi ET, Jeudy J, Yi PH. Appropriateness of Breast \nCancer Prevention and Screening Recommendations Provided by ChatGPT. Radiology. \n2023;307(4). \n18. Lee P, Drazen JM, Kohane IS, Leong T-Y, Bubeck S, Petro J. Benefits, Limits, and Risks of \nGPT-4 as an AI Chatbot for Medicine. New England Journal of Medicine. \n2023;388(13):1233-1239. \n19. Shah NH, Entwistle D, Pfeffer MA. Creation and Adoption of Large Language Models in \nMedicine. Jama. 2023;330(9):866. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \n20. Sorin V, Klang E. Artificial Intelligence and Health Care Disparities in Radiology. \nRadiology. 2021;301(3):E443-E443. \n21. Kotek H, Dockum R, Sun DQ. Gender bias and stereotypes in Large Language Models. arXiv \npreprint arXiv:2308.14921. 2023. \n22. Sorin V, Klang E. Large language models and the emergence phenomena. European Journal \nof Radiology Open. 2023;10:100494. \n23. Sorin V, Soffer S, Glicksberg BS, Barash Y, Konen E, Klang E. Adversarial attacks in \nradiology – A systematic review. European Journal of Radiology. 2023;167:111085. \n \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \nFigure 1. Flow Diagram of the Inclusion Process \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFlow diagram of the search and inclusion process based on the Preferred Reporting Items for \nSystematic Reviews and Meta-Analyses (PRISMA) guidelines \n \n \n \n \n \n \n \nRecords identified from*: \nDatabases (n = 96) \nRegisters (n = 0) \nRecords removed before \nscreening: \nDuplicate records removed  \n(n = 0) \nRecords marked as ineligible \nby automation tools (n = 0) \nRecords removed for other \nreasons (n = 0) \nRecords screened \n(n = 96) \nRecords excluded** \n(n = 78) \nReports sought for retrieval \n(n = 18) \nReports not retrieved \n(n = 0) \nReports assessed for eligibility \n(n = 18) \nReports excluded: \n-  Articles that evaluated LLMs in \ntext analysis related to breast \nplastic surgery (n = 8) \n-  Articles that did not evaluate \nLLMs (n = 4) \n-  Articles that did not directly \nevaluate LLMs in breast cancer \ncare (n=1)  \nStudies included in review \n(n = 5) \nReports of included studies \n(n = 5) \nIdentification of studies via databases and registers \nId\nen\ntifi\nca\ntio\nn \nSc\nre\nen\nin\ng \n \nIn\ncl\nud\ned \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \nFigure 2. Applications of large language models in breast cancer care and the corresponding \naccuracies achieved in various tasks in the different studies \n \n \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \nTable 1. Studies Evaluating LLMs for Breast Cancer Diagnosis and Care \nStudy ref. Publication Date Title Journal \nSorin et al. 13 05.2023 Large language model (ChatGPT) as a support tool \nfor breast tumor board \nNPJ Breast Cancer \nRao et al. 16 06.2023 Evaluating GPT as an Adjunct for Radiologic \nDecision Making: GPT-4 Versus GPT-3.5 in a \nBreast Imaging Pilot \nJACR \nChoi et al. 14 09.2023 Developing prompts from large language model for \nextracting clinical information from pathology and \nultrasound reports in breast cancer \nRadiation Oncology Journal \nLukac et al. 15 07.2023 Evaluating ChatGPT as an adjunct for the \nmultidisciplinary tumor board decision-making in \nprimary breast cancer cases \nArchives of Gynecology and \nObstetrics \nHaver et al. 13 04.2023 Appropriateness of Breast Cancer Prevention and \nScreening Recommendations Provided by ChatGPT \nRadiology \n \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint \nTable 2. Summarization of Performance of LLMs at Different Breast Cancer Care Related Tasks \nStudy ref. LLM No. of Cases Actual Patient \nData \nApplication Correct Performance \nSorin et al. 13 ChatGPT (GPT-3.5) 10 Yes Tumor board clinical decision \nsupport \n70%  \nRao et al. 16 GPT-4, GPT-3.5 14 No Question-answering based on ACR \nrecommendations \n88.9% - 98.4% \nChoi et al. 14 ChatGPT (GPT-3.5) 340 Yes Information extraction 87.7% - 98.2% \nLukac et al. 15 ChatGPT (GPT-3.5) 10 Yes Tumor board clinical decision \nsupport \n64.20% \nHaver et al. 17 ChatGPT (GPT-3.5) 25 No Question-answering on breast cancer \nprevention and screening \n88% \n \nTable 3. Limitations of LLMs as Described in Each Study \nStudy ref. LLM Limitations Described \nSorin et al. 13 ChatGPT (GPT-3.5) False answers and inaccurate medical recommendations, overlooked \nrelevant clinical details, absolute lack of referral to imaging, potential for \noutdated information, potential for bias \nRao et al. 16 GPT-4, GPT-3.5 False information, imaging overutilization, lack of source attribution \nChoi et al. 14 ChatGPT (GPT-3.5) False information, lack of logical reasoning, incomplete information \nextraction, prompt sensitivity \nLukac et al. 15 ChatGPT (GPT-3.5) False answers, overlooked relevant clinical details, potential for outdated \ninformation, lack of source attribution \nHaver et al. 17 ChatGPT (GPT-3.5) False recommendations, prompt sensitivity, lack of source attribution \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted November 4, 2023. ; https://doi.org/10.1101/2023.11.04.23298081doi: medRxiv preprint ",
  "topic": "Data extraction",
  "concepts": [
    {
      "name": "Data extraction",
      "score": 0.643621563911438
    },
    {
      "name": "Breast cancer",
      "score": 0.6304276585578918
    },
    {
      "name": "Workflow",
      "score": 0.5535316467285156
    },
    {
      "name": "Guideline",
      "score": 0.5424661040306091
    },
    {
      "name": "Health care",
      "score": 0.485358864068985
    },
    {
      "name": "MEDLINE",
      "score": 0.46063435077667236
    },
    {
      "name": "Computer science",
      "score": 0.4476979672908783
    },
    {
      "name": "Medicine",
      "score": 0.3211800754070282
    },
    {
      "name": "Cancer",
      "score": 0.3025118112564087
    },
    {
      "name": "Political science",
      "score": 0.1791170835494995
    },
    {
      "name": "Pathology",
      "score": 0.1630663275718689
    },
    {
      "name": "Internal medicine",
      "score": 0.14347419142723083
    },
    {
      "name": "Database",
      "score": 0.09558621048927307
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ]
}