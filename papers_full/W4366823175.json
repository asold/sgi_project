{
  "title": "Efficient evolution of human antibodies from general protein language models",
  "url": "https://openalex.org/W4366823175",
  "year": 2023,
  "authors": [
    {
      "id": null,
      "name": "Brian L. Hie",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4223961780",
      "name": "Varun R. Shanker",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2113842235",
      "name": "Duo Xu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2790484618",
      "name": "Theodora U. J. Bruun",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2908174123",
      "name": "Payton A Weidenbacher",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2595107454",
      "name": "Shaogeng Tang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2431099751",
      "name": "Wesley Wu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2148893222",
      "name": "John E. Pak",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2103241160",
      "name": "Peter S. Kim",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W287111909",
    "https://openalex.org/W2767044445",
    "https://openalex.org/W2060588922",
    "https://openalex.org/W2526473535",
    "https://openalex.org/W2128312954",
    "https://openalex.org/W2109441358",
    "https://openalex.org/W3108171657",
    "https://openalex.org/W3194729882",
    "https://openalex.org/W4210494137",
    "https://openalex.org/W2068747743",
    "https://openalex.org/W2160762238",
    "https://openalex.org/W4210658740",
    "https://openalex.org/W3099399991",
    "https://openalex.org/W3176264499",
    "https://openalex.org/W3166142427",
    "https://openalex.org/W2909727437",
    "https://openalex.org/W3121000782",
    "https://openalex.org/W2980789587",
    "https://openalex.org/W2943495267",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W3179485843",
    "https://openalex.org/W3041304706",
    "https://openalex.org/W3177500196",
    "https://openalex.org/W4283733033",
    "https://openalex.org/W2076048958",
    "https://openalex.org/W4283068487",
    "https://openalex.org/W4220757565",
    "https://openalex.org/W4200635416",
    "https://openalex.org/W4200079908",
    "https://openalex.org/W3156522942",
    "https://openalex.org/W2491163602",
    "https://openalex.org/W2288202420",
    "https://openalex.org/W3025744748",
    "https://openalex.org/W3034202401",
    "https://openalex.org/W2956569764",
    "https://openalex.org/W4206386249",
    "https://openalex.org/W4224227149",
    "https://openalex.org/W3173817996",
    "https://openalex.org/W4225492776",
    "https://openalex.org/W3121906900",
    "https://openalex.org/W6784617132",
    "https://openalex.org/W3190206472",
    "https://openalex.org/W3031560652",
    "https://openalex.org/W3044914269",
    "https://openalex.org/W2167745909",
    "https://openalex.org/W3183816376",
    "https://openalex.org/W3024570138",
    "https://openalex.org/W2509135402",
    "https://openalex.org/W2257979135",
    "https://openalex.org/W3206187363",
    "https://openalex.org/W2962048161",
    "https://openalex.org/W2974982237",
    "https://openalex.org/W3038248848",
    "https://openalex.org/W1976410590",
    "https://openalex.org/W2167669612",
    "https://openalex.org/W3144239152",
    "https://openalex.org/W3092737886",
    "https://openalex.org/W3197005806",
    "https://openalex.org/W3213545574",
    "https://openalex.org/W2943203634",
    "https://openalex.org/W4213112325",
    "https://openalex.org/W2111839632",
    "https://openalex.org/W4214886481",
    "https://openalex.org/W2154135618",
    "https://openalex.org/W2171176459",
    "https://openalex.org/W1992743196",
    "https://openalex.org/W2175327158",
    "https://openalex.org/W2158454607",
    "https://openalex.org/W1894529683",
    "https://openalex.org/W2160378127",
    "https://openalex.org/W3017040476",
    "https://openalex.org/W3020828664",
    "https://openalex.org/W3035459690",
    "https://openalex.org/W2125748493",
    "https://openalex.org/W3049166744",
    "https://openalex.org/W3094232626",
    "https://openalex.org/W2046200242",
    "https://openalex.org/W2564237271",
    "https://openalex.org/W2412207659",
    "https://openalex.org/W2797453784",
    "https://openalex.org/W2564736581",
    "https://openalex.org/W2535595233",
    "https://openalex.org/W2891731267",
    "https://openalex.org/W2927079200",
    "https://openalex.org/W2277351499",
    "https://openalex.org/W2950672524"
  ],
  "abstract": null,
  "full_text": "Nature Biotechnology | Volume 42 | February 2024 | 275–283\n 275\nnature biotechnology\nhttps://doi.org/10.1038/s41587-023-01763-2\nArticle\nEfficient evolution of human antibodies from \ngeneral protein language models\nBrian L. Hie    1,2 , Varun R. Shanker    2,3, Duo Xu    1,2, Theodora U. J. Bruun    1,2,3, \nPayton A. Weidenbacher    2,4, Shaogeng Tang    1,2, Wesley Wu    5, John E. Pak5 & \nPeter S. Kim    1,2,5 \nNatural evolution must explore a vast landscape of possible sequences \nfor desirable yet rare mutations, suggesting that learning from natural \nevolutionary strategies could guide artificial evolution. Here we report that \ngeneral protein language models can efficiently evolve human antibodies by \nsuggesting mutations that are evolutionarily plausible, despite providing \nthe model with no information about the target antigen, binding specificity \nor protein structure. We performed language-model-guided affinity \nmaturation of seven antibodies, screening 20 or fewer variants of each \nantibody across only two rounds of laboratory evolution, and improved \nthe binding affinities of four clinically relevant, highly mature antibodies \nup to sevenfold and three unmatured antibodies up to 160-fold, with \nmany designs also demonstrating favorable thermostability and viral \nneutralization activity against Ebola and severe acute respiratory syndrome \ncoronavirus 2 (SARS-CoV-2) pseudoviruses. The same models that improve \nantibody binding also guide efficient evolution across diverse protein \nfamilies and selection pressures, including antibiotic resistance and enzyme \nactivity, suggesting that these results generalize to many settings.\nEvolution searches across an immense space of possible sequences for \nrare mutations that improve fitness1,2. In nature, this search is based on \nsimple processes of random mutation and recombination1, but using \nthe same approach for directed evolution of proteins in the labora-\ntory3 imposes a considerable experimental burden. Artificial evolution \nbased on random guessing or brute force search typically devotes sub-\nstantial effort to interrogate weakly active or non-functional proteins,  \nrequiring high experimental throughput to identify variants with \nimproved fitness4,5.\nAlthough evolutionary fitness is determined, in part, by specific \nselection pressures, there are also properties that apply more gener-\nally across a protein family or are prerequisites for fitness and func -\ntion across most proteins; for example, some mutations maintain \nor improve stability or evolvability 6,7, whereas others are structur -\nally destabilizing 7 or induce incompetent, misfolded states 8. One \napproach to improving the efficiency of evolution is to ensure that \nmutations adhere to these general properties, which we refer to as \nevolutionary plausibility. Identifying plausible mutations could \nhelp guide evolution away from invalid regimes 9, thereby indirectly \nimproving evolutionary efficiency without requiring any explicit \nknowledge of the function of interest. However, this strategy is also \nchallenging because, first, protein sequences are governed by com -\nplex rules, and, second, even if we restrict search to evolutionarily \nplausible mutations, those that also improve a specific definition \nof fitness might still be rare beyond practical utility (Fig. 1a). More \nbroadly, a major open question 10 is whether general evolutionary \ninformation (for example, learning patterns from sequence variation \nacross past evolution) is sufficient to enable efficient evolution under \nspecific selection pressures (for example, higher binding affinity to a  \nspecific antigen).\nReceived: 23 November 2022\nAccepted: 28 March 2023\nPublished online: 24 April 2023\n Check for updates\n1Department of Biochemistry, Stanford University School of Medicine, Stanford, CA, USA. 2Sarafan ChEM-H, Stanford University, Stanford, CA, USA. \n3Stanford Medical Scientist Training Program, Stanford University School of Medicine, Stanford, CA, USA. 4Department of Chemistry, Stanford University, \nStanford, CA, USA. 5Chan Zuckerberg Biohub, San Francisco, CA, USA.  e-mail: brianhie@stanford.edu; kimpeter@stanford.edu\nNature Biotechnology | Volume 42 | February 2024 | 275–283 276\nArticle https://doi.org/10.1038/s41587-023-01763-2\npressures10. However, this prior work only predicted the direction of \nevolution retrospectively when given full knowledge of the evolutionary \ntrajectory. We hypothesized that the predictive capabilities of protein \nlanguage models might enable a researcher to provide only a single, \nwild-type antibody sequence to the algorithm and receive a small, \nmanageable set (~101) of high-likelihood variants to experimentally \nmeasure for desirable properties. This is a very general setting that does \nnot assume knowledge of protein structure or task-specific training \ndata. A major question, however, is if higher evolutionary likelihood \nwould efficiently translate to higher fitness.\nWe tested our hypothesis by conducting evolutionary cam -\npaigns, guided by language model likelihood, to affinity mature seven \nantibodies representing diverse antigens and degrees of maturity  \n(Supplementary Table 1):\n•\t MEDI8852: a broadly neutralizing antibody (bnAb) that binds \ninfluenza A hemagglutinin (HA) across variants of both major \nphylogenetic groups (group 1 and group 2) and that reached phase \n2 clinical trials; this antibody is highly matured, with its parent \nbeing isolated from a human, followed by substantial artificial \nevolution29\n•\t MEDI8852 unmutated common ancestor (UCA): the unmatured, \ninferred germline sequence of MEDI8852, which only neutralizes \nviruses with group 1 HAs29\n•\t mAb114: a patient-derived antibody that neutralizes ebolavirus \nby binding to its glycoprotein (GP)30 and has been approved for \nclinical use by the US Food and Drug Administration (FDA)\n•\t mAb114 UCA: the unmatured, inferred germline sequence of \nmAb114 with weak binding to ebolavirus GP30\n•\t S309: a patient-derived antibody that cross-neutralizes the sar -\nbecoviruses severe acute respiratory syndrome coronavirus 1 \n(SARS-CoV-1) and severe acute respiratory syndrome coronavirus \n2 (SARS-CoV-2) by binding to the spike glycoprotein (Spike)31 and is \nthe parent antibody of sotrovimab35, which had an FDA emergency \nuse authorization (EUA) for treatment of Coronavirus Disease 2019 \n(COVID-19) caused by earlier variants of SARS-CoV-2 (refs. 36,37)\n•\t REGN10987: a patient-derived antibody that binds early variants \nof SARS-CoV-2 Spike32 and that had an FDA EUA for use against \nthese variants\nHere we show that evolutionary information alone can lead to \nimproved fitness under specific selection pressures with high efficiency \n(Fig. 1b). For our main experimental test case, we focused on affinity \nmaturation of human antibodies in which our specific selection pres-\nsure is defined as stronger binding affinity to a particular antigen. In \nnature, a process known as somatic hypermutation evolves or ‘matures’ \nan antibody lineage to have higher affinity for an antigen via repeated \nmutagenesis11–13. In the laboratory, affinity maturation is a major appli-\ncation of directed evolution due to the therapeutic potential of antibod-\nies with high affinity for disease targets14.\nT o select evolutionarily plausible mutations, we used algorithms \nknown as language models (Fig. 1c) to learn patterns that are likely to \noccur in natural proteins15–22. Because we used general language mod-\nels19,20, trained on non-redundant sequence datasets that are meant \nto represent variation across all natural proteins23, these models can \nonly learn more general evolutionary rules than could a model trained \nspecifically on antibody sequences24–27 or a model directly supervised \nwith binding affinity28. Given a single starting sequence, we used these \nlanguage models to recommend plausible amino acid substitutions \nthat we then experimentally screened for improved fitness. T o the \nend user, the algorithm requires only a single wild-type sequence, \nwithout any initial binding affinity data, knowledge of the antigen,  \ntask-specific supervision, evolutionary homologs or protein structure \ninformation.\nWe evolved seven human immunoglobulin G (IgG) antibodies that \nbind to antigens from coronavirus, ebolavirus and influenza A virus. We \nfocused on viral antigens given the importance of antibody therapeu-\ntics for viral diseases29–32. We improved the affinity of all antibodies after \nmeasuring only 20 or fewer new variants of each antibody across just \ntwo rounds of evolution, which, to our knowledge, represents unprec-\nedented efficiency for machine-learning-guided evolution 33,34. We \nalso demonstrate that the same general protein language models that \nwe used to affinity mature antibodies can also enrich for high-fitness \nsubstitutions to diverse proteins beyond antibodies.\nResults\nEfficient affinity maturation with protein language models\nRecent work has demonstrated that language models can predict \nnatural evolution despite having no knowledge of specific selection \nOr\nFull mutational space Full mutational space\nHigh language model\nlikelihood\nExperiment: use high language model likelihood to sample\nevolutionarily plausible mutations, measure fitness\nPlausible\nmutations\nPlausible\nmutations\nPlausible\nmutations\nHigh fitnessHigh fitnessa b c\nQ V Q _ V S S\n0.1 ···0.2 0.01···\nEmbedding\nz = f (x)\nOutput\nlikelihood\np (x i  | z)\nA L Y\nInput\nsequence\nx\nEﬀicient scenario:\nevolutionary plausibility indirectly\npredicts high fitness\nIneﬀicient scenario:\nevolutionary plausibility poorly\nenriches for high fitness\nFig. 1 | Guiding evolution with protein language models. a,b, Two possible \nmodels for relating the space of mutations with high evolutionary plausibility \n(for example, mutations seen in antibodies) to the space with high fitness under \nspecific selection pressures (for example, mutations that result in high binding \naffinity to a specific antigen). Both models assume that mutations with high \nfitness make up a rare subset of the full mutational space and that, in general, \nhigh-fitness mutations are also evolutionarily plausible. Under the first model \n(a), mutations with high fitness are rare within the subset of mutations that are \nevolutionarily plausible. Under the second model (b), when restricted to the \nregime of plausible mutations, improvements to fitness become much more \ncommon. c, Protein language models, trained on millions of natural protein \nsequences learn amino acid patterns that are likely to be seen in nature. We \nhypothesized that most mutations with high language model likelihood would \nalso be evolutionarily plausible. Assuming that this is true, and if the second \nmodel (b) better describes nature, then a language model with no information \nabout specific selection pressures can still efficiently guide evolution.\nNature Biotechnology | Volume 42 | February 2024 | 275–283\n 277\nArticle https://doi.org/10.1038/s41587-023-01763-2\n•\t C143: an unmatured, patient-derived antibody that binds the \nSARS-CoV-2 Wuhan-Hu-1 Spike but was isolated before extensive \nin vivo somatic hypermutation38,39\nWe performed evolution with the ESM-1b language model and \nthe ESM-1v ensemble of five language models (six language models in \ntotal)19,20. ESM-1b and ESM-1v were trained on UniRef50 and UniRef90, \nrespectively, which are protein sequence datasets that represent vari-\nation across millions of observed natural proteins (UniRef90 contains \n~98 million total sequences) and that include only a few thousand \nantibody-related sequences 23. These datasets are also constructed \nsuch that no two sequences have more than 50% (UniRef50) or 90% \n(UniRef90) sequence similarity with each other to avoid biological \nredundancy. Additionally, both datasets precede the discovery of \nthe SARS-CoV-2 antibodies considered in the study as well as the \n \nevolution of all SARS-CoV-2 variants of concern. Therefore, to evolve \nthese antibodies, the language models cannot use disease-specific \nbiases in the training data and must, instead, learn more general  \nevolutionary patterns.\nWe used these language models to compute likelihoods of all \nsingle-residue substitutions to the antibody variable regions of either \nthe heavy chain (VH) or the light chain (VL). We selected substitutions \nwith higher evolutionary likelihood than wild-type across a consen -\nsus of six language models (Methods and Extended Data Fig. 1). In \nthe first round of evolution, we measured the antigen interaction \nstrength by biolayer interferometry (BLI) of variants that contain only \na single-residue substitution from wild-type. In the second round, we \nmeasured variants containing combinations of substitutions, where \nwe selected substitutions that corresponded to preserved or improved \nbinding based on the results of the first round. We performed these two \nrounds for all seven antibodies, measuring 8–14 variants per antibody \nin round one and 1–11 variants per antibody in round two (Fig. 2  and \nSupplementary Table 1). Variants of the clinically relevant antibod -\nies, which have very low or undetectable dissociation as IgGs, were \nscreened by measuring the dissociation constant (Kd) of the monova-\nlent fragment antigen-binding (Fab) region; variants of the unmatured \nantibodies were screened by measuring the apparent Kd of the bivalent \nIgG followed by also measuring the Kd values of the Fab fragments of \nthe highest-avidity variants (Methods).\nWe could successfully express all but one of 122 variants across our \nseven evolutionary trajectories. Across all seven antibodies, we found \nthat 71–100% of the first-round Fab variants (containing a single-residue \nsubstitution) retained sub-micromolar binding to the antigen, and \n14–71% percent of first-round variants led to improved binding affin-\nity (defined as a 1.1-fold or higher improvement in K d compared to \nwild-type) (Supplementary Table 1). Most of the second-round vari -\nants (containing a combination of substitutions) also have improved \nbinding (Supplementary Tables 1–9). For all antibodies except for \nREGN10987, we also obtained variants with at least a two-fold improve-\nment in Kd. Thirty-six out of all 76 language-model-recommended, \nsingle-residue substitutions (and 18 out of 32 substitutions that lead \nto improved affinity) occur in framework regions (Supplementary \nTables 2–9), which are generally less mutated during conventional \naffinity maturation compared to the complementarity-determining \nregions (CDRs)12.\nWe were able to improve the binding affinities for all clinically  \nrelevant antibodies tested, despite these antibodies being already highly \nevolved (starting at low nanomolar or picomolar affinity). MEDI8852 is \na potent binder with a sub-picomolar Fab Kd across many HAs and pico-\nmolar or nanomolar binding to HAs from subtypes H4 and H7. Although \nwe explicitly screened variants using an HA H4 antigen, the best design \nalso improves binding across a broad set of HAs (Supplementary  \nTables 2 and 3), including a sevenfold improvement (from 0.21 nM \nto 0.03 nM) for HA H7 HK17 (A/Hong Kong/125/2017(H7N9)). The \nbest variant of mAb114, a clinically approved drug, achieves a 3.4-fold \nimprovement in Fab Kd for ebolavirus GP (Supplementary Table 5). For \nREGN10987, the highest-affinity variant has a 1.3-fold improvement \nagainst Beta-variant Spike with six stabilizing proline substitutions \n(S-6P)40 (the antigen used in screening), and another of our designs \nhas a 5.1-fold improvement for the Omicron BA.1 receptor-binding \ndomain (RBD) (Supplementary Table 8). For S309, we compared our \ndesigns to wild-type and to a variant with the N55Q substitution in the \nVH introduced after a small-scale, rational evolutionary screen\n35; the \nS309 Fab with the VH N55Q substitution forms the Fab of the therapeu-\ntic antibody sotrovimab. Our best variant of S309 has higher affinity \nthan sotrovimab, including a 1.3-fold improvement in Fab Kd compared \nto wild-type S309 (versus 1.1-fold for sotrovimab) for SARS-CoV-2 \nWuhan-Hu-1 S-6P (the antigen used in screening); a 1.7-fold improve-\nment (versus 1.3-fold for sotrovimab) for Beta S-6P; and a 0.93-fold \nchange (versus 0.82-fold for sotrovimab) for Omicron RBD (Supple-\nmentary Table 7).\nWe were also able to improve affinities for all three unmatured \nantibodies, often involving much higher fold changes than when \nevolving the matured antibodies, indicating easier evolvability with \nrespect to affinity. For MEDI8852 UCA, the best Fab design achieves \na 2.6-fold improvement in Kd against HA H1 Solomon (A/Solomon \nIslands/3/2006(H1N1)), the antigen used in screening. Our best designs \nalso acquire breadth of binding to some group 2 HAs, including a 23-fold \nimprovement for HA H4 Hubei (A/swine/Hubei/06/2009(H4N1)) and \na 5.4-fold improvement for HA H7 HK17 (Supplementary Table 4). For \nmAb114 UCA, our best Fab design achieves a 160-fold improvement in Kd \nfor ebolavirus GP (Supplementary Table 6). Although the algorithm rec-\nommends amino acid substitutions to both of these UCA antibodies that \nare also observed in the matured antibody, other affinity-enhancing sub\n-\nstitutions to the UCA antibodies are not found in the matured versions: \nexcluding any substitutions or modified sites found in the matured \nantibody, our UCA variants achieve up to a sevenfold improvement for \nHA H4 Hubei (variant VH P75R/VL G95P; Supplementary Table 4) and \na 33-fold improvement for ebolavirus GP (variant VH G88E/VL V43A; \nSupplementary Table 6), demonstrating that our algorithm successfully \nexplores alternative evolutionary routes. For C143, a patient-derived \nantibody isolated before extensive affinity maturation38,39, our best \ndesign achieves a 13-fold improvement for Beta S-6P and a 3.8-fold \nimprovement for Omicron RBD (Supplementary Table 9). Results from \nour directed evolution campaigns are further summarized in Fig. 2 , \nSupplementary Tables 2–9 and Supplementary Data 1.\nAdditional characterization of evolved antibodies\nAlthough we explicitly selected for improved binders, we also tested \nthese variants for improved stability (Methods). We found that Fabs \nFig. 2 | Language-model-guided affinity maturation of seven human \nantibodies. a, Strip plots visualizing the two rounds of directed evolution \nconducted for each antibody. Each point represents an IgG or Fab variant plotted \naccording to the fold change in K\nd from wild-type on the y axis and jitter on the  \nx axis; a gray, dashed line is drawn at a fold change of 1, and the wild-type point is \ncolored gray. MEDI8852 variants were screened against HA H4 Hubei; MEDI8852 \nUCA variants against HA H1 Solomon; mAb114 and mAb114 UCA variants against \nebolavirus GP; S309 variants against Wuhan-Hu-1 S-6P; and REGN10987 and C143 \nvariants against Beta S-6P. b, Phylogenetic trees illustrating the evolutionary \ntrajectories from wild-type to the highest-affinity variant(s) of each antibody. \nNodes are annotated with the K\nd values for different antigens and the Tm of the \nFab; all Kd values are for the monovalent Fab versions except those of C143, which \nare apparent Kd values for the bivalent IgGs. B, Beta; H1 Solo., H1 Solomon;  \nML variant, machine-learning-guided variant; O, Omicron; W1, Wuhan-Hu-1.  \nc, We obtained avidity and affinity measurements via BLI of IgGs and Fabs at the \nindicated concentrations binding to the indicated antigen. Selected BLI traces \nof the highest-affinity variants for the respective antigens are plotted alongside \nthose of the wild-type variants.\nNature Biotechnology | Volume 42 | February 2024 | 275–283 278\nArticle https://doi.org/10.1038/s41587-023-01763-2\nfor 21 out of the 31 language-model-recommended, affinity-enhancing \nvariants that we tested had a higher melting temperature (Tm) than \nwild-type, and all variants maintained thermostability (Tm > 70 °C). \nWhen evolving S309 to have higher affinity, our best design has a Tm of \n72.8 °C compared to 72.5 °C for wild-type, whereas the VH N55Q sub-\nstitution introduced in sotrovimab decreases the Tm to 69.6 °C (Fig. 2).  \n2\n1\n0\nFold improvement (Fab K d )Fold improvement (IgG K d )Fold improvement (IgG K d )Fold improvement (Fab K d )Fold improvement (Fab K d )Fold improvement (IgG K d ) Fold improvement (Fab K d )\nn = 15 n = 1\n2.5\n1.0\n0.5\nn = 9\nn = 11\n1\n2\n3\n0\nn = 14\nn = 6\n0\n1\n1.3\n0.4\n1\n1.2\n1\n14\n7\nn = 10\nn = 7\nn = 11\nn = 9\nn = 9\nn = 6\nMEDI8852\nHighly matured\n(in vivo + in vitro)\nInfluenza A virus\n(HA H4 Hubei)\nInfluenza A virus\n(HA H1 Solomon)\nEbolavirus\n(GP)\nEbolavirus\n(GP)\nSarbecovirus\n(SARS-CoV-2\nWuhan-Hu-1\nS-6P)\nSARS-CoV-2\n(Beta S-6P)\nSARS-CoV-2\n(Beta S-6P)\nUnmatured\n(germline)\nMatured\n(in vivo)\nMatured\n(in vivo)\nMatured\n(in vivo)\nUnmatured\n(patient-derived)\nUnmatured\n(germline)\nMEDI8852\nUCA\nmAb114\nmAb114\nUCA\nS309\nREGN10987\nC143\n40\n0\n80\nn = 15 n = 6\nH4 Hubei\nH7 HK16\nH7 HK17\nMEDI8852 VH E65P-M117Y\nVH K58S-V65P/\nVL G95PMEDI8852 UCA\nH4 Hubei\nH7 HK16\nH7 HK17\nH4 Hubei\nH7 HK17\nH4 Hubei\nH7 HK17\nH1 Solo. H1 Solo.\nShift (nm)\nTime (s) Time (s)\nShift (nm)Shift (nm)Shift (nm)Shift (nm)Shift (nm) Shift (nm)\n0\n0.4\n0 200 1,200\n0 200 600\n0\n0.18\n0 200 1,200\n0\n0.7\n0\n0.4\n0 200 1,200\nTime (s)\n0 200 500\n0\n0.2\n0.2\n0\n0 200 1,200\nTime (s)\n0\n0.35\n0 200 1,200\nTime (s)\n0\n0.3\n0 200 700\nTime (s)\n0 200 700\n0\n0.2\n0 200 500\n0\n0.15\n0 200 1,200\n0\n0.2\nTime (s)\n0.4\n0\n0 200 1,200\nTime (s)\n0\n0.4\n0 200 500\nTime (s)\nGP\nmAb114 VH D42G-A68T-S79Y/\nVL V43A\nVH P60A-G61D/\nVL V43AmAb114 UCA\nGP\nGP\n GP\nVL T33N-G53VC143\nW1 S-6P\nB S-6P\nO RBD\nW1 S-6P\nB S-6P\nO RBD\nVH R16G\nVH R16G / VL N91C\nREGN10987\nB S-6P\nO RBD\nB S-6P\nB S-6P\nO RBD\nVH G79A/VL T28S\nSotrovimab (VH N55Q)\nS309\nW1 S-6P\nB S-6P\nO RBD\nW1 S-6P\nB S-6P\nO RBD\nW1 S-6P\nB S-6P\nO RBD\n2.4 nM\n2.0 nM\n0.60 nM\nThis study\nIn vivo\nML variant Wild-type\nIn vitro\nAntigen\n Kd\nTm\n88.2 °C\n 85.7 °C\n6.2 nM\n0.21 nM\n140 nM\n29 µM \n4.4 µM \n0.21 nM\n75 µM \n2.5 nM\n14 nM\n39 nM\n450 nM\n610 µM \n30 nM\n34 nM\n160 µM \n23 µM \n11 nM\n23 nM\n4.5 µM \n2.4 nM\n14 nM\n15 nM\n2.0 nM\n1.4 nM\n0.48 µM \n0.061 nM\n50 nM\n1.3 µM \n0.81 µM \n0.31 nM\n2.5-fold0\n0.6\n0 200 1,200\n7-fold\n2.5 nM\n0.030 nM\nWild-type\nML variant\nOther variant\nRound 1 Round 2\nTime (s) Time (s)\nTime (s)\nTime (s) Time (s)\n100 nM Fab on H7 HK16 100 nM Fab on H7 HK17\n100 nM IgG on H4 Hubei 100 nM IgG on H7 HK17\n100 nM IgG on GP 100 nM Fab on GP\n1 µM IgG on GP 2 µM Fab on GP\n100 nM Fab on W1 S-6P 100 nM Fab on B S-6P\n100 nM Fab on B S-6P 2 µM Fab on O RBD\n100 nM IgG on B S-6P 5 µM IgG on O RBD\n84.1 °C\n 72.0 °C\n74.3 °C\n 78.3 °C\n74.5 °C\n 82.5 °C\n72.5 °C\n72.8 °C\n69.6 °C\n77.5 °C\n74.8 °C\n78.6 °C\n68.4 °C\n 70.6 °C\n17 nM\n23-fold 5.4-fold\n3.4-foldKd  < 10 –12  M\n82-fold 160-fold\n1.3-fold 1.7-fold\n1.3-fold 5.1-fold\n13-fold 3.8-fold\na b c\nNature Biotechnology | Volume 42 | February 2024 | 275–283\n 279\nArticle https://doi.org/10.1038/s41587-023-01763-2\nOur evolved variants for mAb114, mAb114 UCA, REGN10987 and C143 \nalso preserve or improve Tm; the highest change that we observed \nwas an increase from 74.5 °C to 82.5 °C when evolving mAb114 UCA. \nImproved thermostability does not completely explain our affinity \nmaturation results, however, as we observed somewhat decreased Tm \nfor our affinity-matured variants of MEDI8852 and its UCA, although \nthese Fabs are still thermostable (Fig. 2).\nAdditionally, we tested our affinity-matured designs for poly -\nspecific binding, because binding unintended targets could lead to \nundesirable side effects in therapeutic settings. For each of the seven \nantibodies, we tested the wild-type alongside three affinity-matured \nvariants using a polyspecificity assay that assesses non-specific bind-\ning to soluble membrane proteins (Methods) 41,42. We observed no \nsubstantial changes in polyspecificity for any variants of all seven \nantibodies, and all tested antibodies have polyspecificity values within \na therapeutically viable range (Fig. 3a and Supplementary Data 2).\nAnother therapeutic consideration is immunogenicity. Although \ncomputational prediction of immunogenicity remains a challenge, \nespecially involving recognition of discontinuous epitopes, the \nimmunogenicity of linear peptides is better understood43. We observed \nthat our affinity-matured variants have no significant increase \n(one-sided binomial P > 0.05) in the number of computationally pre-\ndicted peptide binders to both human leukocyte antigen (HLA) class I \nand class II (exact P values and sample sizes for these experiments are \nprovided in Supplementary Data 2), which underlies T-cell-mediated \nimmunogenicity.\nWe also wanted to determine if our affinity-matured variants \nhave better viral neutralization activity. We tested affinity-enhancing \nvariants of four antibodies using pseudovirus neutralization assays \n(Methods) and, in all cases, observed variants with half-maximal \ninhibitory concentration (IC50) values that are significantly improved \n(Bonferroni-corrected, one-sided t -test P < 0.05, n = 4 independent \nexperiments), including a 1.5-fold improvement for the best mAb114 \nvariant against Ebola pseudovirus; a twofold improvement for the \nbest REGN10987 variant against SARS-CoV-2 Beta pseudovirus; and a  \n32-fold improvement for the best C143 variant against Beta pseudovirus \n(Fig. 3b, Extended Data Fig. 2 and Supplementary Tables 5, 8 and 9). \nAdditionally, the affinity-matured variants of mAb114 UCA demonstrate \nIC 50  fold change\nKd  fold change\nVH M117Y\nVH E65P-M117Y\nWT\nVH K58S/VL G95P\nVH K58S-V65P/\nVL G95P\nVH K58S-V65P-\nP75R / VL G95P\nWT\nVH A68T-E72D-S79Y-\nI113T/VL V43A\nVH D42G-A68T-\nS79Y/VL V43A\nVH  I41P-D42G-A68T-\nS79Y-I113T/VL V43A\nWT\nVH G88E/VL V43A\nVH  P60A-G61D/\nVL V43A\nVH  P60A-G61D-G88E-\nV96A/VL V43A\nWT\nVH R87T\nVL T28S\nVH G79A/VL T28S\nWT\nVH R16G\nVH R16G/VL N91C \nVH R16G/VL I96S \nWT\nVL T33N\nVL G53V\nVL T33N-G53V\n10 3\n10 4\n10 5\nMedian fluorescence intensity\nControls MEDI8852 MEDI8852 UCA mAb114 mAb114 UCA S309 REGN10987 C143\n1 2 3\n1.2\n1.4\n1.6\n1.8\nSpearman r = 0.82 \nmAb114\nvariants\nmAb114 UCA\nvariants\nREGN10987\nvariants\nC143\nvariants\nConcentration (ng ml –1 )\n0\n0.2\n0.4\n0.6\n0.8\n1.0\nFraction infectivity\n10 –1 10 1\n10 1\n10 0\n10 2\n10 3 10 0 10 1 10 210 –1 10 1 10 3\nConcentration (ng ml –1 )\nC143 WT VL T33N VL G53V VL T33N-G53V\nSpike-pseudotyped lentivirus\nElotuzumab\nIxekizumab\n4E10\nWT\nVH E65P\nBeta D614G\nb\na\nc\nFig. 3 | Specificity and improved neutralization potency of affinity-matured \nvariants. a, Polyspecificity of antibody wild-types and variants was quantified \nusing an assay42 that measures non-specific binding to soluble membrane \nproteins via flow cytometry, where higher MFI values correspond to more \nnon-specific binding (Methods). Control antibodies\n42 are elotuzumab (a clinical \nantibody with low polyspecificity), ixekizumab (a clinical antibody with high \npolyspecificity) and 4E10 (a research antibody with high polyspecificity beyond a \ntherapeutically viable level)\n62. Bar height indicates the mean across n = 3 replicate \nwells; black dots indicate independent measurements. b, Variants of the antibody \nC143, obtained from our language-model-guided affinity maturation campaign, \ndemonstrate improved neutralization activity in a pseudovirus assay. For Beta \npseudovirus, out of the three higher-affinity variants that we also screened for \nneutralization activity, the best improvement is the 32-fold improvement of VL \nG53V; for D614G pseudovirus, the best improvement is the 19-fold improvement \nof VL T33N-G53V (Supplementary Table 9). Also see Extended Data Fig. 2. Points \nindicate the mean; error bars indicate the s.d.; n = 4 independent experiments. \nc, Fold change in K\nd correlates well with fold change in IC50 (Spearman r = 0.82, \nn = 15 antibody variants) across all designs tested, consistent with higher binding \naffinity contributing to improved viral neutralization activity. WT, wild-type.\nNature Biotechnology | Volume 42 | February 2024 | 275–283 280\nArticle https://doi.org/10.1038/s41587-023-01763-2\ndetectable neutralization at a >100-fold lower concentration compared \nto wild-type (Extended Data Fig. 2a). In general, change in binding \naffinity corelates well with change in neutralization (Spearman r = 0.82, \ntwo-sided t-distribution P = 1.9 × 10−4, n = 15 antibody variants) (Fig. 3c \nand Extended Data Fig. 2b).\nOriginality of affinity-enhancing substitutions\nAlthough the ability to find any improvement in affinity is itself use-\nful for engineering applications, we were also interested in whether \nsome of the changes recommended by our algorithm demonstrate \n‘originality’ . We quantified originality by computing the frequency \nthat a given residue is observed in nature (Methods). Although many \naffinity-enhancing substitutions are indeed observed at high fre -\nquency both in the model’s training data23 and in a database of antibody \nsequences44, other substitutions demonstrate greater originality. For \nexample, in the MEDI8852 UCA trajectory, the VL G95P framework \nsubstitution (Fig. 2 and Supplementary Table 4) involves changing \na glycine observed in 99% of natural antibody sequences to a proline \nobserved in less than 1% of natural sequences. Overall, five out of 32 \naffinity-enhancing substitutions (~16%) involve changing the wild-type \nresidue to a rare or uncommon residue (Supplementary Table 10) and \nthat are also rare when considering only natural variation of antibod-\nies derived from the same germline genes (Supplementary Table 11). \nThese results indicate that the language models learn both the ‘easy’ \nevolutionary rules involving high-frequency residues and more com-\nplex rules that are not captured by a multiple sequence alignment or \nconventional antibody evolution. Conceptually, these low-frequency, \naffinity-enhancing substitutions are analogous to examples in other \ndisciplines where an artificial intelligence program occasionally \nmakes unusual but advantageous choices (for example, unintuitive \ngame-playing decisions45) and likewise may be worth further study.\nComparison to other sequence-based methods\nWe also sought to compare general language models to other meth-\nods for selecting plausible mutations based on sequence information \nalone. T o assess the contribution of epistatic information learned by \nthe language model, we considered two site-independent models of \nmutational frequencies: (1) abYsis sequence annotation, which uses \nextensively curated antibody sequence alignments, and (2) frequen-\ncies based on sequence alignments to the UniRef90 dataset, which was \nused to train ESM-1v (Methods). T o assess the impact of using language \nmodels not trained on antibody-specific sequence variation, we also \ncompared to two antibody language models: (1) AbLang24, trained on \n~107 sampled sequences from immune repertoire sequencing data \nin the Observed Antibody Space (OAS) database46, and (2) Sapiens25, \ntrained on ~108 human antibody sequences from the OAS datasbase.\nWe benchmarked these models based on their ability to suggest \nsingle-residue substitutions that improve the avidity of the three unma-\ntured IgG antibodies for their respective antigens (MEDI8852 UCA \nand HA H1 Solomon, mAb114 UCA and GP and C143 and Beta S-6P). \nFor each of the four benchmarked models, we ranked substitutions by \ntheir mutant-to-wild-type likelihood ratios and experimentally tested \nthe same number of substitutions considered in the first round of our \nevolutionary campaigns (Methods).\nNotably, our approach based on general protein language models \nconsistently outperformed all baseline methods (Supplementary Table \n12). In particular, the abYsis and UniRef90 comparisons indicate that \nepistatic information was critical for consistent performance across \nantibodies. For example, the site-independent models did not recom-\nmend high-fitness substitutions such as VL G95P in MEDI8852 UCA \nor VL T33N/G53V in C143, resulting in no avidity-enhancing substitu-\ntions to C143 (Supplementary Table 12 and Supplementary Data 3). \nWe also observed that language models recommend a significantly \nhigher number of avidity-enhancing substitutions (simulation-based \nP = 0.0085; Extended Data Fig. 3a) compared to the next-best baseline, \nUniRef90, and that is robust to differences in sequence alignment \ndepth (Extended Data Fig. 3b, Supplementary Data 3 and Methods). \nDespite having access to antibody-specific sequence variation, both \nthe AbLang and Sapiens models also consistently underperformed \nthe general protein language models and even underperformed \nthe site-independent models when recommending substitutions to \nmAb114 UCA (Supplementary Table 12 and Supplementary Data 3). \nOur results indicate that general protein language models go beyond \nsite-independent reasoning to make beneficial predictions while \nalso learning sufficient information even from unspecialized protein \nsequence corpuses.\nComputational efficiency of our approach\nOur computational pipeline is highly efficient at making predictions, \ntaking less than 1 s per antibody (including both VH and VL sequences) \non widely available, GPU-accelerated hardware (Methods). T o demon-\nstrate efficiency, we made predictions over 742 therapeutically rel-\nevant antibodies from the Thera-SAbDab database47 (Supplementary \nData 4) in ~3 min, and our approach scales linearly with the number \nof antibodies.\nGenerality across diverse protein families\nGiven the success of general protein language models at guiding anti-\nbody evolution, we also tested how well the same models could acquire \nhigh-fitness variants across diverse protein families. Previous work \nhas demonstrated that the likelihoods from general protein language \nmodels have good correlation with experimental phenotypes from \nhigh-throughput assays over ~103 to 104 variants10,20. Previous computa-\ntional simulations have also indicated that these models can help bias \nmulti-round evolution away from large regions of a sequence landscape \nwith zero or very low fitness9.\nHere, we observed that the same models can also guide efficient \nevolution when measuring only a small number (~10 1) of variants \naccording to diverse definitions of fitness, including antibiotic resist-\nance, cancer drug resistance, enzyme activity or viral replication fit -\nness48. We used the same algorithm and language models in our affinity \nmaturation experiments to suggest a small number (~101) of changes \nto wild-type sequences from human, bacterial or viral organisms rep-\nresenting eight diverse protein families. We then used experimental \nmeasurements from high-throughput scanning mutagenesis experi-\nments\n8,48 to validate the language-model-recommended predictions \n(notably, these measurements were not provided to the model). As in \nthe antibody evolution campaigns, we are interested in enriching for \nas many high-fitness variants as possible among the small number of \nlanguage model recommendations (rather than predicting fitness \nacross the entire mutational space, as previously done20).\nLanguage-model-recommended variants were nominally enriched \n(one-sided hypergeometric P < 0.05; exact P values and sample sizes \nare provided in Supplementary Table 13) for high-fitness values in \nsix out of nine of the measured datasets, and high-fitness variants \nmade up a much larger portion of language-model-recommended \nvariants compared to random guessing in all but one case (Fig. 4a, \nExtended Data Figs. 4–6 and Supplementary Table 13). For exam -\nple, whereas high ampicillin resistance is observed for just 7% of all \nsingle-residue substitutions to β-lactamase, it is observed for 40% of \nlanguage-model-recommended substitutions, and the same set of \nlanguage models can also help prioritize single-residue substitutions to \nHA that result in high viral infectivity (from 7% to 31%) and substitutions \nto PafA that improve enzyme kinetics (from 3% to 20%). Additionally, \nacross all proteins, even the first round of a small-scale evolutionary \ncampaign guided by language models would yield variants that are \nabove or near the 99th percentile of fitness values (Extended Data \nFig. 4). Compared to 47 alternative variant effect predictors, including \nsupervised and structure-based models, our strategy ranks higher, on \naverage, than all other methods based on the ability to recommend \nNature Biotechnology | Volume 42 | February 2024 | 275–283\n 281\nArticle https://doi.org/10.1038/s41587-023-01763-2\nhigh-fitness variants (Extended Data Fig. 4, Supplementary Data 5 \nand Methods).\nDiscussion\nWe show that general protein language models can guide highly effi-\ncient affinity maturation based on the wild-type antibody sequence \nalone. Although our affinity improvements are lower than those typi-\ncally observed in successful in vivo evolutionary trajectories, somatic \nhypermutation explores a mutational space that is larger by multiple \norders of magnitude (Extended Data Fig. 7). Moreover, our affinity \nimprovements on unmatured antibodies are within the 2.3-fold to \n580-fold range previously achieved by a state-of-the-art, in vitro evolu-\ntionary system applied to unmatured, anti-RBD nanobodies (in which \nthe computational portion of our approach, which takes seconds, is \nreplaced with rounds of cell culture and sorting, which take weeks)14 \n(Extended Data Fig. 7). In vitro, cell surface display methods also \nencounter physical limits that make it challenging to distinguish bet-\nter binders when the wildtype binder already has high affinity (<1 nM)5, \nwhich is not a limitation of our approach.\nMore broadly, a critical finding of our study is that evolutionary \ninformation alone provides sufficient prior information when selecting \nsmall numbers of substitutions to test for improved fitness (Figs. 1b  \nand 4b). This leads to the result that a model without any task-specific \ntraining data or knowledge of the antigen can guide antibody evolu -\ntion toward higher binding affinity, with competitive performance \ncompared to protein-specific or task-specific methods (Supplemen-\ntary Table 12 and Extended Data Fig. 5). We hypothesize that, in many \nsettings, when mutations are constrained to follow a set of general \nevolutionary rules, a substantial portion (greater than 10%) is bound \nto improve fitness (Fig. 4b), which has immediate and broader implica-\ntions for evolution in the laboratory and in nature.\nPractical implications and extensions\nWe anticipate that language models will become a key part of the anti-\nbody engineer’s toolkit, particularly within preclinical development \nas a rapid way to identify improved variants. In addition to speed, \nby focusing on ~10 single-site substitutions, a higher-throughput \nexperimental budget that would have been allocated to brute force \nsearch could, instead, be allocated to exploring combinations of \nmutations49,50 or to exploring variants of more wild-type antibodies. \nLanguage-model-guided evolution could also complement or replace \nrandom mutagenesis strategies based on, for example, an error-prone \npolymerase.\nT o the end user, guiding evolution via pre-trained, unsupervised \nmodels is less resource intensive than collecting enough task-specific \ndata to train a supervised model28. Language models should also serve \nas a baseline for future machine learning methods using supervision \nor other task-specific training data. Our techniques can also be used \nin conjunction with supervised approaches9,28,33,34,51–54, and supervising \na model over multiple experimental rounds might ultimately lead to \nhigher fitness. However, in many practical settings (for example, the \nrapid development of sotrovimab in response to the COVID-19 pan -\ndemic35), the efficiency of an unsupervised, single-round approach is \npreferable to a protracted, multi-round directed evolution campaign.\nA general approach not biased by traditional structural hypoth-\neses can also be valuable because many beneficial mutations are \nstructurally remote to functionally important sites 55. About half of \nthe language-model-recommended substitutions (and about half of \nthe affinity-enhancing substitutions) fall in framework regions, which \nare typically not proximal to the binding interface and are, therefore, \nsometimes excluded from directed evolution28,56. Although some of \nthese framework changes may improve affinity via protein stabiliza-\ntion, others do not appear to increase thermostability (for example, VL \nLower fitness\nHigher fitness\nRandom guessing has\nlow eﬀiciency\n(traditional methods)\nBetter prior information\nimproves eﬀiciency\n(this study)\nLM guided\nBackground \nHypergeometric null:\n* P < 0.05 ** P < 0.005\n**\n**\n*\n**\n*\n*\n0\n10\n20\n30\n50\n40\nFraction positive (%)\nADRB2 Env HA H1 HA H3 infA MAPK1 PafAβ-la. P53\na b\nFig. 4 | Guiding evolution without explicitly modeling fitness. a, The same \nstrategy and language models that we use to affinity mature antibodies can also \nrecommend high-fitness changes across a diversity of selection pressures and \nprotein families, as identified experimentally using high-throughput scanning \nmutagenesis assays\n8,48 (described in Supplementary Table 13). ‘Fraction positive’ \nindicates the percentage of high-fitness amino acid substitutions within either \nthe set of substitutions recommended by the language model (LM guided) \nor the set of all single-residue substitutions (Background). A large portion of \nlanguage-model-guided substitutions have high fitness, which, in many cases, \nis significantly enriched compared to the background percentage; also see \nExtended Data Figs. 4–6, and see Supplementary Table 13 for the exact one-sided \nhypergeometric P values and sample sizes. ADRB2, adrenoreceptor beta 2; β-la., \nβ-lactamase; Env, envelope glycoprotein; infA, translation initiation factor \n1; MAPK1, mitogen-activated protein kinase 1; PafA, phosphate-irrepressible \nalkaline phosphatase. b, Conceptually, the prior information encoded by \nevolutionary plausibility is represented in this cartoon by the rainbow road, \nwhere ascending corresponds to improving fitness and descending corresponds \nto lowering fitness. Moving in any direction (for example, via random or brute \nforce mutagenesis) would most likely decrease fitness or have a high chance \nof being a detrimental change (represented by the green ball). However, if \nevolutionary plausibility is an efficient prior (Fig. 1b), then movement that is \nconstrained to the plausible regime (for example, when guided by a language \nmodel) substantially increases the chance of improving fitness (represented by \nthe red ball).\nNature Biotechnology | Volume 42 | February 2024 | 275–283 282\nArticle https://doi.org/10.1038/s41587-023-01763-2\nG95P in MEDI8852 UCA) and may, instead, be causing affinity improve-\nments via structural reorientation57–59. Nature often takes advantage \nof framework mutations to improve affinity, which represent ~20–30% \nof changes in natural affinity maturation 60. In one well-known case, \nnone of the nine residues accounting for a 30,000-fold increase in \naffinity is in contact with the antigen59, and, in another case, framework \nmutations make important contributions to affinity maturation and \nincreased breadth in an HIV-1 antibody58.\nGenerality of fitness improvements\nBy leveraging general evolutionary rules, language models recom-\nmend more ‘universal’ changes that seem to generalize better when \nthe definition of fitness changes (Fig. 4). We also observed that gen-\neral language models outperform antibody-specific language models \n(Supplementary Table 12), which is consistent with independent in \nsilico benchmarking22. When transferring to a new, specific notion \nof fitness, more general evolutionary information may outweigh the \nparticular biases encoded in antibody repertoire datasets, although \nfurther development of antibody language models could improve  \nperformance.\nOur general approach is designed to improve an existing baseline \nfunction (for example, improving the affinity of a weak binder) rather \nthan endowing any protein with an arbitrary function (for example, \nconverting a generic protein into a specific binder). We also note that \ntaking advantage of this strategy for guiding evolution may be more \ndifficult when the selection pressure is unnatural or if the wild-type \nsequence is already at a fitness peak. However, in many practical design \ntasks, natural sequences and selection pressures are already prefer -\nrable; for example, therapeutic development often prefers human \nantibodies due to considerations of immunogenicity.\nBeyond protein engineering, the success of our approach may also \nprovide insight into natural evolution. The efficiency of evolutionary \ninformation alone may reflect natural mechanisms for biasing muta-\ntion rates toward higher fitness: for example, somatic hypermutation \nfavors specific parts of an antibody gene via epigenomic and enzymatic \nsequence biases60,61. If epigenomic or other mechanisms predispose \nmutations to have high fitness, then nature could be accelerating \nevolution in a manner similar to our approach.\nOnline content\nAny methods, additional references, Nature Portfolio reporting sum-\nmaries, source data, extended data, supplementary information, \nacknowledgements, peer review information; details of author con -\ntributions and competing interests; and statements of data and code \navailability are available at https://doi.org/10.1038/s41587-023-01763-2.\nReferences\n1. Futuyma, D. J. Evolutionary Biology 3rd ed (Sinauer Associates, \n1997).\n2. Wright, S. The roles of mutation, inbreeding, crossbreeding and \nselection in evolution. Proc. of the VI International Congress of \nGenetics 355–366 (Blackwell, 1932).\n3. Arnold, F. H. Directed evolution: bringing new chemistry to life. \nAngew. Chem. Int. Ed. Engl. 57, 4143–4148 (2018).\n4. Fowler, D. M. & Fields, S. Deep mutational scanning: a new style of \nprotein science. Nat. Methods 11, 801–807 (2014).\n5. Hunter, S. A. & Cochran, J. R. Cell-binding assays for determining \nthe affinity of protein–protein interactions. Methods Enzymol. \n580, 21–44 (2016).\n6. Khersonsky, O. & Tawfik, D. S. Enzyme promiscuity: a mechanistic \nand evolutionary perspective. Annu. Rev. Biochem. 79, 471–505 \n(2010).\n7. Bloom, J. D., Labthavikul, S. T., Otey, C. R. & Arnold, F. H. Protein \nstability promotes evolvability. Proc. Natl Acad. Sci. USA 103, \n5869–5874 (2006).\n8. Markin, C. J. et al. Revealing enzyme functional architecture via \nhigh-throughput microfluidic enzyme kinetics. Science 373, \neabf8761 (2021).\n9. Wittmann, B. J., Yue, Y. & Arnold, F. H. Informed training set design \nenables efficient machine learning-assisted directed protein \nevolution. Cell Syst. 12, 1026–1045 (2021).\n10. Hie, B. L., Yang, K. K. & Kim, P. S. Evolutionary velocity with protein \nlanguage models predicts evolutionary dynamics of diverse \nproteins. Cell Syst. 13, 274–285 (2022).\n11. Eisen, H. N. & Siskind, G. W. Variations in affinities of antibodies \nduring the immune response. Biochemistry 3, 996–100 (1964).\n12. Eisen, H. N. Affinity enhancement of antibodies: how low-affinity \nantibodies produced early in immune responses are followed by \nhigh-affinity antibodies later and in memory B-cell responses. \nCancer Immunol. Res. 2, 381–392 (2014).\n13. Victora, G. D. & Nussenzweig, M. C. Germinal centers. Annu. Rev. \nImmunol. 40, 413–442 (2022).\n14. Wellner, A. et al. Rapid generation of potent antibodies by \nautonomous hypermutation in yeast. Nat. Chem. Biol. 17,  \n1057–1064 (2021).\n15. Bepler, T. & Berger, B. Learning the protein language: evolution, \nstructure and function. Cell Syst. 12, 654–669 (2021).\n16. Bepler, T. & Berger, B. Learning protein sequence embeddings \nusing information from structure. International Conference on \nLearning Representations. Preprint at arXiv https://doi.org/ \n10.48550/arXiv.1902.08661 (2019).\n17. Hie, B., Zhong, E., Berger, B. & Bryson, B. Learning the language of \nviral evolution and escape. Science 371, 284–288 (2021).\n18. Alley, E. C., Khimulya, G., Biswas, S., AlQuraishi, M. & Church, G. M.  \nUnified rational protein engineering with sequence-based deep \nrepresentation learning. Nat. Methods 16, 1315–1322 (2019).\n19. Rives, A. et al. Biological structure and function emerge from \nscaling unsupervised learning to 250 million protein sequences. \nProc. Natl Acad. Sci. USA 118, e2016239118 (2021).\n20. Meier, J. et al. Language models enable zero-shot prediction \nof the effects of mutations on protein function. Adv. Neural. Inf. \nProcess. Syst. 34 https://proceedings.neurips.cc/paper_files/\npaper/2021/file/f51338d736f95dd42427296047067694-Paper.\npdf (NeurIPS, 2021).\n21. Elnaggar, A. et al. ProtTrans: towards cracking the language \nof life’s code through self-supervised deep learning and high \nperformance computing. IEEE Trans. Pattern Anal. Mach. Intell. 44, \n7112–7127 (2022).\n22. Nijkamp, E., Ruffolo, J., Weinstein, E. N., Naik, N. & Madani, A. \nProGen2: exploring the boundaries of protein language models. \nPreprint at arXiv https://doi.org/10.48550/arXiv.2206.13517  \n(2022).\n23. Suzek, B. E., Huang, H., McGarvey, P., Mazumder, R. & Wu, C. H. \nUniRef: comprehensive and non-redundant UniProt reference \nclusters. Bioinformatics 23, 1282–1288 (2007).\n24. Olsen, T. H., Moal, I. H. & Deane, C. M. AbLang: an antibody \nlanguage model for completing antibody sequences. Bioinform. \nAdv. 2, vbac046 (2022).\n25. Prihoda, D. et al. BioPhi: a platform for antibody design, \nhumanization, and humanness evaluation based on natural \nantibody repertoires and deep learning. mAbs 14, 2020203 \n(2022).\n26. Ruffolo, J. A., Gray, J. J. & Sulam J. Deciphering antibody \naffinity maturation with language models and weakly \nsupervised learning. NeurIPS Workshop on Machine Learning \nin Structural Biology. Preprint at arXiv https://doi.org/10.48550/\narXiv.2112.07782 (2021).\n27. Shuai, R. W., Ruffolo, J. A. & Gray, J. J. Generative language \nmodeling for antibody design. Preprint at bioRxiv https://doi.org/ \n10.1101/2021.12.13.472419 (2021).\nNature Biotechnology | Volume 42 | February 2024 | 275–283\n 283\nArticle https://doi.org/10.1038/s41587-023-01763-2\n28. Mason, D. M. et al. Optimization of therapeutic antibodies by \npredicting antigen specificity from antibody sequence via deep \nlearning. Nat. Biomed. Eng. 5, 600–612 (2021).\n29. Kallewaard, N. L. et al. Structure and function analysis of an \nantibody recognizing all influenza A subtypes. Cell 166, 596–608 \n(2016).\n30. Corti, D. et al. Protective monotherapy against lethal Ebola \nvirus infection by a potently neutralizing antibody. Science 351, \n1339–1342 (2016).\n31. Pinto, D. et al. Cross-neutralization of SARS-CoV-2 by a human \nmonoclonal SARS-CoV antibody. Nature 583, 290–295 (2020).\n32. Hansen, J. et al. Studies in humanized mice and convalescent \nhumans yield a SARS-CoV-2 antibody cocktail. Science 369, \n1010–1014 (2020).\n33. Yang, K. K., Wu, Z. & Arnold, F. H. Machine-learning-guided \ndirected evolution for protein engineering. Nat. Methods 16, \n687–694 (2019).\n34. Hie, B. L. & Yang, K. K. Adaptive machine learning for protein \nengineering. Curr. Opin. Struct .Biol. 72, 145–152 (2022).\n35. Alexander, E. et al. Antibody therapies for SARS-CoV-2 infection. \nWO2021252878A1 (2021).\n36. Telenti, A., Hodcroft, E. B. & Robertson, D. L. The evolution and \nbiology of SARS-CoV-2 variants. Cold Spring Harb. Perspect. Med. \n12, a041390 (2022).\n37. Maher, M. C. et al. Predicting the mutational drivers of future \nSARS-CoV-2 variants of concern. Sci. Transl. Med. 14, eabk3445 \n(2022).\n38. Gaebler, C. et al. Evolution of antibody immunity to SARS-CoV-2. \nNature 591, 639–644 (2021).\n39. Muecksch, F. et al. Affinity maturation of SARS-CoV-2 neutralizing \nantibodies confers potency, breadth, and resilience to viral \nescape mutations. Immunity 54, 1853–1868 (2021).\n40. Hsieh, C.-L. et al. Structure-based design of prefusion-stabilized \nSARS-CoV-2 spikes. Science 369, 1501–1505 (2020).\n41. Xu, Y. et al. Addressing polyspecificity of antibodies selected \nfrom an in vitro yeast presentation system: a FACS-based, \nhigh-throughput selection and analytical tool. Protein Eng. Des. \nSel. 26, 663–670 (2013).\n42. Makowski, E. K., Wu, L., Desai, A. A. & Tessier, P. M. Highly sensitive \ndetection of antibody nonspecific interactions using flow \ncytometry. mAbs 13, 1951426 (2021).\n43. Reynisson, B., Alvarez, B., Paul, S., Peters, B. & Nielsen, M. \nNetMHCpan-4.1 and NetMHCIIpan-4.0: improved predictions of \nMHC antigen presentation by concurrent motif deconvolution \nand integration of MS MHC eluted ligand data. Nucleic Acids Res. \n48, W449–W454 (2020).\n44. Swindells, M. B. et al. abYsis: integrated antibody sequence and \nstructure—management, analysis, and prediction. J. Mol. Biol. \n429, 356–364 (2017).\n45. Silver, D. et al. Mastering the game of Go with deep neural \nnetworks and tree search. Nature 529, 484–489 (2016).\n46. Olsen, T. H., Boyles, F. & Deane, C. M. Observed antibody space: a \ndiverse database of cleaned, annotated, and translated unpaired \nand paired antibody sequences. Protein Sci. 31, 141–146 (2022).\n47. Raybould, M. I. J. et al. Thera-SAbDab: the therapeutic structural \nantibody database. Nucleic Acids Res. 48, D383–D388 (2020).\n48. Livesey, B. J. & Marsh, J. A. Using deep mutational scanning \nto benchmark variant effect predictors and identify disease \nmutations. Mol. Syst. Biol. 16, e9380 (2020).\n49. Zhao, H., Giver, L., Shao, Z., Affholter, J. A. & Arnold, F. H. \nMolecular evolution by staggered extension process (StEP) \nin vitro recombination. Nat. Biotechnol. 16, 258–261 (1998).\n50. Yu, Y. W., Daniels, N. M., Danko, D. C. & Berger, B. Entropy- \nscaling search of massive biological data. Cell Syst. 1, 130–140 \n(2015).\n51. Biswas, S., Khimulya, G., Alley, E. C., Esvelt, K. M. & Church, G. M. \nLow-N protein engineering with data-efficient deep learning. Nat. \nMethods 18, 389–396 (2021).\n52. Hie, B., Bryson, B. D. & Berger, B. Leveraging uncertainty in \nmachine learning accelerates biological discovery and design. \nCell Syst. 11, 461–477 (2020).\n53. Dallago, C. et al. FLIP: benchmark tasks in fitness landscape \ninference for proteins. In Proc. of the Neural Information \nProcessing Systems Track on Datasets and Benchmarks https://\ndatasets-benchmarks-proceedings.neurips.cc/paper_files/\npaper/2021 (NeurIPS, 2021).\n54. Bileschi, M. L. et al. Using deep learning to annotate the protein \nuniverse. Nat. Biotechnol. 40, 932–937 (2022).\n55. Shimotohno, A., Oue, S., Yano, T., Kuramitsu, S. & Kagamiyama, H. \nDemonstration of the importance and usefulness of manipulating \nnon-active-site residues in protein design. J. Biochem. 129, \n943–948 (2001).\n56. Shan, S. et al. Deep learning guided optimization of human \nantibody against SARS-CoV-2 variants with broad neutralization. \nProc. Natl Acad. Sci. USA 119, e2122954119 (2022).\n57. Dunbar, J., Fuchs, A., Shi, J. & Deane, C. M. ABangle: \ncharacterising the VH–VL orientation in antibodies. Protein Eng. \nDes. Sel. 26, 611–620 (2013).\n58. Fera, D. et al. Affinity maturation in an HIV broadly neutralizing \nB-cell lineage through reorientation of variable domains. Proc. \nNatl Acad. Sci. USA 111, 10275–10280 (2014).\n59. Wedemayer, G. J., Patten, P. A., Wang, L. H., Schultz, P. G. & \nStevens, R. C. Structural insights into the evolution of an antibody \ncombining site. Science 276, 1665–1669 (1997).\n60. Yeap, L.-S. et al. Sequence-intrinsic mechanisms that target AID \nmutational outcomes on antibody genes. Cell 163, 1124–1137 \n(2015).\n61. Zheng, N.-Y., Wilson, K., Jared, M. & Wilson, P. C. Intricate targeting \nof immunoglobulin somatic hypermutation maximizes the \nefficiency of affinity maturation. J. Exp. Med. 201, 1467–1478 \n(2005).\n62. Rujas, E. et al. Structural and thermodynamic basis of epitope \nbinding by neutralizing and nonneutralizing forms of the \nanti-HIV-1 antibody 4E10. J. Virol. 89, 11975–11989 (2015).\nPublisher’s note Springer Nature remains neutral with regard  \nto jurisdictional claims in published maps and institutional  \naffiliations.\nOpen Access This article is licensed under a Creative Commons \nAttribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the \nsource, provide a link to the Creative Commons license, and indicate \nif changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons license, unless \nindicated otherwise in a credit line to the material. If material is not \nincluded in the article’s Creative Commons license and your intended \nuse is not permitted by statutory regulation or exceeds the permitted \nuse, you will need to obtain permission directly from the copyright \nholder. To view a copy of this license, visit http://creativecommons.\norg/licenses/by/4.0/.\n© The Author(s) 2023\nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nMethods\nAcquiring amino acid substitutions via language model con-\nsensus\nWe select amino acid substitutions recommended by a consensus  \nof language models. We take as input a single wild-type sequence \nx = (x 1,…,xN)∈ 𝒳𝒳N, where 𝒳𝒳 is the set of amino acids, and N  is the \nsequence length. We also require a set of masked language models, \nwhich are pre-trained to produce conditional likelihoods p(x′\ni |x).  To  \nguide evolution based on a certain language model, we first compute \nthe set of substitutions with higher language model likelihood than \nthe wild-type—that is, we compute the set\nℳ(pj) = {i ∈ [N],x′\ni ∈𝒳𝒳𝒳\npj (x′\ni |x)\npj (xi|x) > α},\nwhere pj denotes the language model, xi denotes the wild-type residue \nand α = 1. T o further filter substitutions to only those with the highest \nlikelihood, we choose substitutions based on a consensus scheme, \nwhere, for a new amino acid x′\ni, we compute\nf(x′\ni ) = ∑\nj∈[M]\n1{(i,x′\ni )isin ℳ(pj)}\nwhere 1{·} denotes the indicator function, and there are M  language \nmodels. We then acquire the set of substitutions with higher likelihood \nthan wild-type across multiple language models—that is, we acquire\n𝒜𝒜= {i ∈ [N],x′\ni ∈𝒳𝒳𝒳 f(x′\ni ) ≥ k}\nwhere k is a user-supplied cutoff that controls the number of corre -\nsponding variants to measure. Although we focus on values of k that \nresult in small values of |𝒜𝒜| (around 10) that can be screened via \nlow-throughput assays, the number of substitutions can be increased \nby reducing the value of k or by lowering the cutoff stringency α. Our \nstrategy based on computing ‘wild-type marginal’ likelihoods based \non the entire sequence, p(x′\ni |x), instead of the ‘masked marginal’ likeli-\nhoods in which the site of interest is masked,  p(x′\ni |x[N]\\{i}), also increases \nthe cutoff stringency (Extended Data Fig. 1).\nWe use six large-scale masked language models—namely, the \nESM-1b model19 and the five models that are ensembled together to \nform ESM-1v20—both obtained from https://github.com/facebookre-\nsearch/esm. ESM-1b was trained on the 2018-03 release of UniRef50 \n(ref. 23) consisting of ~27 million sequences, and the five models in \nESM-1v were each trained on the 2020-03 release of UniRef90 (ref. 23) \nconsisting of ~98 million sequences.\nAntibody sequence analysis and evolution\nFor antibodies, we performed the above steps for the VH and VL \nsequences separately, obtaining respective sets 𝒜𝒜VH and 𝒜𝒜VL. For round \n1 of evolution, we set α = 1 and chose values of k such that |𝒜𝒜VH ∪𝒜𝒜VL| is \napproximately 10, which is meant to be a reasonable number of anti-\nbody variants for one person to express and purify in parallel. We used \nk = 2 for MEDI8852 VH and VL, k = 2 for MEDI8852 UCA VH and VL, k = 4 \nfor mAb114 VH and VL, k = 2 for mAb114 UCA VH and VL, k = 2 for S309 \nVH, k = 1 for S309 VL, k = 2 for REGN10987 VH and VL and k = 2 for C143 \nVH and VL. We further reduced the size of |𝒜𝒜VH ∪𝒜𝒜VL| by requiring the \nsubstitution to have the highest likelihood at its respective site for at \nleast one language model. Variants were first measured for binding \naffinity to a given antigen via BLI (more details below), and those that \nenhanced affinity were recombined such that the second-round vari-\nants have two or more substitutions from wild-type, which were tested \nduring round 2 of evolution. Given the small number of \naffinity-enhancing substitutions found during round 1 of evolution for \nS309 and REGN10987, we also expanded the set of substitutions con-\nsidered in round 2 to include those that preserved affinity. For \nMEDI8852 and MEDI8852 UCA, we tested all possible combinations in \nround 2; for the other antibodies, where the number of possible com-\nbinations far exceeds ~10 variants, we manually selected a set of com-\nbinations meant to prioritize inclusion of substitutions that resulted \nin the largest improvements in affinity during the first round.\nWe used the wild-type sequences provided by the original study \nauthors describing the respective antibodies 29–32,38. Wild-type VH \nand VL sequences are provided in the Supplementary Information. \nWe used the Kabat region definition provided by the abYsis webtool  \nversion 3.4.1 (http://www.abysis.org/abysis/index.html)44 to annotate \nthe framework regions and CDRs within the VH and VL sequences.\nAntibody avidity benchmarking experiments\nWe also compared the substitutions recommended by the above \nstrategy (based on language model consensus) to the substitu\n-\ntions recommended by four alternative sequence-based methods. \nFirst, we acquired substitutions to a VH or VL sequence based on \nsite-independent mutational frequencies, where we used either the \nfrequencies computed by the abYsis Annotation webtool 44 or the \nfrequencies obtained using all sequences in UniRef90 (the training \ndataset of ESM-1v)23. T o compute the UniRef90 frequencies, we first per-\nformed an exhaustive search to obtain the 10,000 closest sequences by  \nLevenshtein distance, where 10,000 is chosen to reflect the number of \nimmunoglobulin-like sequences in UniRef90. We computed sequence \nsimilarity using the partial_ratio function from the FuzzyWuzzy Python \npackage version 0.18.0; we then constructed a multiple sequence \nalignment of these 10,000 sequences using MAFFT version 7.475 \n \n(ref. 63) using the VH or VL sequence as the reference; finally, using \nthe alignment, we computed mutational frequencies for each site in \nthe sequence. We selected the top-ranking substitutions by likelihood \nratio (the mutant frequency divided by the corresponding wild-type \nfrequency) across the VH and VL sequences, where, for each antibody, \nwe selected the same number of substitutions considered in the first \nround of our evolutionary campaigns.\nWe also acquired substitutions based on language models \ntrained specifically on antibody sequences. We used the AbLang \nheavy chain and light chain language models (https://github.com/\nT obiasHeOl/AbLang)24 and the Sapiens heavy chain and light chain \nlanguage models (https://github.com/Merck/Sapiens)25 to compute \nthe mutant-to-wild-type likelihood ratios for all single-residue substitu-\ntions to the VH or VL sequence (using the language model trained on \nsequences from the corresponding chain). We selected the top-ranking \nsubstitutions by likelihood ratio across the VH and VL sequences and, \nfollowing our use of the general protein language models, also required \nthe substitution to have the highest likelihood at its site. For each anti-\nbody, we selected the same number of substitutions considered in the \nfirst round of our evolutionary campaigns.\nWe used these four methods (abYsis, UniRef90, AbLang and \nSapiens) to select substitutions to our three unmatured antibodies \n(MEDI8852 UCA, mAb114 UCA and C143) and used BLI to measure IgG \navidity to their respective antigens (HA H1 Solomon, GP and Beta S-6P). \nT o purify the larger number of variants involved in these benchmarking \nstudies, we used a medium-throughput system using a robotic liquid \nhandler, described in more detail below. With this system, we expressed \nand purified antibody variants containing single-residue substitutions \nfrom wild-type recommended by the consensus of ESM language mod-\nels as well as by the four baseline methods, observing similar purities \nand affinities when the same variants were also expressed and purified \nvia the low-throughput system (described below) used in our evolu -\ntionary campaigns. Antibodies with a final concentration of less than \n0.1 mg ml\n−1 in 200 μl after the medium-throughput purification were \nre-expressed and purified using the low-throughput methodology.\nUniRef90 robustness and statistical significance analysis\nFor the UniRef90 benchmark, we additionally assessed robustness to \ndifferences in multiple sequence alignment (MSA) construction by \nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\ncomputing the number of known affinity-enhancing substitutions \nwhile varying the sequence alignment depth from 1,000 to 9,000 \nsequences at increments of 1,000 (for a total of nine alignment depth \ncutoffs). At each cutoff, we re-ran the procedure described above to \nselect substitutions (constructing MSAs and calculating mutational \nlikelihood ratios). We performed this for all three experimentally \nbenchmarked antibodies, representing a total of 27 MSAs. Among the \ntop-ranked substitutions for each cutoff and benchmarked antibody, \nwe counted the number of known affinity-enhancing substitutions and \nprovide the results in Extended Data Fig. 3 and Supplementary Data 3.\nWe also used the UniRef90 benchmark to assess the statisti -\ncal significance of the number of avidity-enhancing substitutions \nrecommended by the language models. In particular, we calculated \nthe probability of acquiring 12 or more avidity-enhancing substitu -\ntions (Supplementary Table 12) by simulating different outcomes of a \nsite-independent model based on UniRef90 alignments. T o construct \nthe null distribution, we first simulated variation in UniRef90 align -\nments using the nine MSAs of varying alignment depth and their cor-\nresponding recommended substitutions, described in the previous \nparagraph. We then simulated experimental measurement of these \nmutations for avidity enhancement across the three benchmarked \nantibodies: for each top-ranked substitution with an unknown effect on \navidity, we assigned a success probability based on the observed proba-\nbilities from our experimental benchmark (2/8 = 25% for MEDI8852 UCA;  \n5/9 = 56% for mAb114 UCA; and 1/14 = 7% for C143); for each top-ranked \nsubstitution with a known effect on avidity, we fixed its value to its \nexperimentally determined status. We ran 500,000 simulations for \neach of the nine MSA cutoffs (a total of 4.5 million simulations), where \neach simulation returns a total number of avidity-enhancing substitu-\ntions across the three antibodies. We report the P value as the number \nof simulations resulting in 12 or more avidity-enhancing substitutions \ndivided by the total number of simulations.\nAntibody cloning\nWe cloned the antibody sequences into the CMV/R plasmid backbone \nfor expression under a CMV promoter. The heavy chain or light chain \nsequence was cloned between the CMV promoter and the bGH poly(A) \nsignal sequence of the CMV/R plasmid to facilitate improved protein \nexpression. Variable regions were cloned into the human IgG1 back -\nbone; REGN10987 and C143 variants were cloned with a lambda light \nchain, whereas variants of all other antibodies were cloned with a kappa \nlight chain. The vector for both heavy and light chain sequences also \ncontained the HVM06_Mouse (UniProt: P01750) Ig heavy chain V region \n102 signal peptide (MGWSCIILFL VATATGVHS) to allow for protein \nsecretion and purification from the supernatant. VH and VL segments \nwere ordered as gene blocks from Integrated DNA T echnologies and  \nwere cloned into linearized CMV/R backbones with 5× In-Fusion HD \nEnzyme Premix (Takara Bio); a list of oligonucleotides and gene blocks \nused in the study is provided as Supplementary Data 6.\nAntigen cloning\nHA, GP, Spike and RBD sequences were cloned into a pADD2 vector \nbetween the rBeta-globin intron and β-globin poly(A). HA constructs \ncontain a Foldon trimerization domain. GP and Spike constructs \ncontain a GCN4 trimerization domain. All HAs, GP, Wuhan-Hu-1 S-6P \nand Omicron BA.1 RBD constructs contain an AviTag. All constructs \ncontain a C-terminal 6×His tag. We used HA sequences from the fol -\nlowing strains: A/New Caledonia/20/1999(H1N1) (H1 Caledonia),  \nA/Solomon Islands/3/2006(H1N1) (H1 Solomon), A/Japan/305/1957 \n(H2N2) (H2 Japan), A/Panama/2007/1999(H3N2) (H3 Panama),  \nA/Victoria/3/1975(H3N2) (H3 Victoria), A/swine/Hubei/06/2009(H4N1) \n(H4 Hubei), A/Vietnam/1203/2004(H5N1) (H5 Vietnam), A/Hong \nKong/61/2016(H7N9) (H7 HK16) and A/Hong Kong/125/2017(H7N9)  \n(H7 HK17). We used Ebola GP ectodomain (Mayinga, Zaire, 1976, GenBank:  \nAAG40168.1) with the mucin-like domain deleted (Δ309–489). Spike \nor RBD sequences were based off wild-type Wuhan-Hu-1 (GenBank: \nBCN86353.1), Beta (GenBank: QUT64557.1) or Omicron BA.1 (GenBank: \nUFO69279.1).\nDNA preparation\nPlasmids were transformed into Stellar competent cells (Takara Bio), \nand transformed cells were plated and grown at 37 °C overnight. Colo-\nnies were mini-prepped per the manufacturer’s recommendations \n(GeneJET, K0502, Thermo Fisher Scientific) and sequence confirmed \n(Sequetech) and then maxi-prepped per the manufacturer’s recom -\nmendations (NucleoBond Xtra Maxi, Macherey-Nagel). Plasmids were \nsterile filtered using a 0.22-μm syringe filter and stored at 4 °C.\nProtein expression\nAll proteins were expressed in Expi293F cells (Thermo Fisher Scientific, \nA14527). Proteins containing a biotinylation tag (AviTag) were also \nexpressed in the presence of a BirA enzyme, resulting in spontaneous \nbiotinylation during protein expression. Expi293F cells were cultured \nin media containing 66% FreeStyle/33% Expi media (Thermo Fisher \nScientific) and grown in TriForest polycarbonate shaking flasks at \n37 °C in 8% carbon dioxide. The day before transfection, cells were \nspun down and resuspended to a density of 3 × 106 cells per milliliter \nin fresh media. The next day, cells were diluted and transfected at a \ndensity of approximately 3–4 × 106 cells per milliliter. Transfection mix-\ntures were made by adding the following components: maxi-prepped \nDNA, culture media and FectoPRO (Polyplus) would be added to cells \nto a ratio of 0.5 μg: 100 μl: 1.3 μl: 900 μl. For example, for a 100-ml \ntransfection, 50 μg of DNA would be added to 10 ml of culture media, \nfollowed by the addition of 130 μl of FectoPRO. For antibodies, we \ndivided the transfection DNA equally among heavy and light chains; \nin the previous example, 25 μg of heavy chain DNA and 25 μg of light \nchain DNA would be added to 10 ml of culture media. After mixing and \na 10-min incubation, the example transfection cocktail would be added \nto 90 ml of cells. The cells were harvested 3–5 days after transfection by \nspinning the cultures at >7,000g for 15 min. Supernatants were filtered \nusing a 0.45-μm filter.\nAntibody purification (low throughput)\nWe purified antibodies using a 5-ml MabSelect Sure PRISM column on \nthe ÄKTA pure fast protein liquid chromatography (FPLC) instrument \n(Cytiva). The ÄKTA system was equilibrated with line A1 in 1× PBS, line \nA2 in 100 mM glycine pH 2.8, line B1 in 0.5 M sodium hydroxide, Buffer \nline in 1× PBS and Sample lines in water. The protocol washes the column \nwith A1, followed by loading of the sample in the Sample line until air is \ndetected in the air sensor of the sample pumps, followed by five column \nvolume washes with A1, elution of the sample by flowing of 20 ml of A2 \ndirectly into a 50-ml conical containing 2 ml of 1 M tris(hydroxymethyl)\naminomethane (Tris) pH 8.0, followed by five column volumes of A1, B1 \nand A1. We concentrated the eluted samples using 50-kDa or 100-kDa \ncutoff centrifugal concentrators, followed by buffer exchange using a \nPD-10 column (Sephadex) that had been pre-equilibrated into 1× PBS. \nPurified antibodies were stored at −20 °C.\nAntibody purification (medium throughput)\nFor our benchmarking experiments, we purified antibody variants \nwith a medium-throughput system using an Agilent Bravo robotic \nliquid handling platform and VWorks software version 13.1.0.1366 with \ncustom programming routines. For each antibody wild-type or variant, \na 2.5-ml culture of Expi293F cells was transfected with corresponding \nantibody heavy and light chain plasmids as previously described.  \nCultures were harvested 3–5 days after transfection by centrifuga -\ntion at 4,200g for 10 min, followed by collecting 2 ml of supernatant. \nProPlus PhyTip column tips (Biotage, PTV-92-20-07) were loaded on \nthe Bravo 96 L T head and equilibrated by aspirating and dispensing \n75 μl of PBS, repeating four times. Sample binding to the tip resin was \nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nperformed by aspirating and dispensing 98 μl of harvested superna -\ntant, followed by washing via aspirating and dispensing 100 μl of PBS, \nrepeating the binding and washing steps nine times (in total processing \n882 μl of harvest for each run). Elution was performed by aspirating \n100 μl of 100 mM glycine pH 2.8, followed by dispensing into a well \nwith 10 μl of 1 M Tris pH 8.\nAntigen purification\nAll antigens were His-tagged and purified using HisPur Ni-NTA \nresin (Thermo Fisher Scientific, 88222). Cell supernatants were \ndiluted with 1/3 volume of wash buffer (20 mM imidazole, 20 mM \n4-(2-hydroxyethyl)-1-piperazineethanesulfonic acid (HEPES) pH 7.4, \n150 mM sodium chloride (NaCl) or 20 mM imidazole, 1× PBS), and the \nNi-NTA resin was added to diluted cell supernatants. For all antigens \nexcept SARS-CoV-2 Spike, the samples were then incubated at 4 °C while \nstirring overnight. SARS-CoV-2 Spike antigens were incubated at room \ntemperature while stirring overnight. Resin/supernatant mixtures \nwere added to chromatography columns for gravity flow purification. \nThe resin in the column was washed with wash buffer (20 mM imida -\nzole, 20 mM HEPES pH 7.4, 150 mM NaCl or 20 mM imidazole, 1× PBS), \nand the proteins were eluted with 250 mM imidazole, 20 mM HEPES \npH 7.4, 150 mM NaCl or 20 mM imidazole, 1× PBS. Column elutions \nwere concentrated using centrifugal concentrators at 10-kDa, 50-kDa \nor 100-kDa cutoffs, followed by size-exclusion chromatography on \nan ÄKTA pure system (Cytiva). ÄKTA pure FPLC with a Superdex 6 \nIncrease (S6) or Superdex 200 Increase (S200) gel filtration column \nwas used for purification. Then, 1 ml of sample was injected using a 2-ml \nloop and run over the S6 or S200, which had been pre-equilibrated in \ndegassed 20 mM HEPES, 150 mM NaCl or 1× PBS before use and stored  \nat −20 °C.\nFab production and purification\nNext, 1/10 volume of 1 M Tris pH 8 was added to IgGs at ~2 mg ml −1 in \n1× PBS. Then, 2 μl of a 1 mg ml−1 stock of Lys-C (stock stored at −20 °C) \nwas added for each milligram of human IgG1 and digested for 1 h at \n37 °C with moderate rotation. Digested Fabs were purified using a 5-ml \nHiTrap SP HP cation exchange chromatography column on an ÄKTA \nsystem using 50 mM sodium acetate (NaOAc) pH 5.0 with gradient \nNaCl elution (using 50 mM NaOAc + 1 M NaCl pH 5.0). Fab fractions were \npooled and dialyzed against 1× PBS and concentrated using 30-kDa \nconcentrators. Purified Fabs were stored at −20 °C.\nBLI binding experiments\nAll reactions were run on an Octet RED96 at 30 °C, and samples were \nrun in 1× PBS with 0.1% BSA and 0.05% Tween 20 (Octet buffer). IgGs and \nFabs were assessed for binding to biotinylated antigens using strepta-\nvidin biosensors (Sartorius/ForteBio) or to unbiotinylated, His-tagged \nantigens using Anti-Penta-HIS biosensors (Sartorius/ForteBio). Antigen \nwas loaded to a threshold of 1-nm shift. Tips were then washed and \nbaselined in wells containing only Octet buffer. Samples were then \nassociated in wells containing IgG or Fab at 100 nM concentration \nunless otherwise stated (other concentrations are given in Supplemen-\ntary Data 1). A control well with loaded antigen but that was associated \nin a well containing only 200 μl of Octet buffer was used as a baseline \nsubtraction for data analysis. Association and dissociation binding \ncurves were fit in Octet System Data Analysis Software version 9.0.0.15 \nusing a 1:2 bivalent model for IgGs to determine apparent Kd and a 1:1 \nmodel for Fabs to determine Kd. Averages of fitted Kd values from at least \ntwo independent experiments are reported to two significant figures. \nWild-type and the highest-affinity variants were also tested at multiple \nconcentrations, and Kd values were averaged across all replicates and \nconcentrations (Supplementary Data 1). T o estimate measurement \nerror, we computed the coefficient of variation (CV; the ratio of the s.d. \nto the mean across replicates) for each antibody−antigen Kd pair, and we \nreport the mean CV for each antigen in Supplementary Tables 2 and 4–9.\nThermal melts\nWe measured thermal melting profiles of proteins by differential scan-\nning fluorimetry on a Prometheus NT.48 instrument. Protein samples \n(0.1 mg ml−1) were loaded into glass capillaries and then subjected to \na temperature gradient from 20 °C to 95 °C at a heating rate of 1 °C per \nminute. Intrinsic fluorescence (350 nm and 330 nm) was recorded as \na function of temperature using PR.ThermControl version 2.3.1 soft-\nware. Thermal melting curves were plotted using the first derivative \nof the ratio (350 nm/330 nm). Melting temperatures were calculated \nautomatically by the instrument and represented peaks in the thermal \nmelting curves.\nPolySpecificity Particle assay\nPolyspecificity reagent (PSR) was obtained as described by  \nXu et al.41. Soluble membrane proteins were isolated from homog -\nenized and sonicated Expi 293F cells followed by biotinylation with \nSulfo-NHC-SS-Biotin (Thermo Fisher Scientific, 21331) and stored in \nPBS at −80 °C. The PolySpecificity Particle (PSP) assay was performed \nfollowing Makowski et al. 42. Protein A magnetic beads (Invitrogen, \n10001D) were washed three times in PBSB (PBS with 1 mg ml−1 BSA) and \ndiluted to 54 μg ml−1 in PBSB. Then, 30 μl of the solution containing the \nbeads was incubated with 85 μl of antibodies at 15 μg ml−1 overnight at \n4 °C with rocking. The coated beads were then washed twice with PBSB \nusing a magnetic plate stand (Invitrogen, 12027) and resuspended in \nPBSB. We then incubated 50 μl of 0.1 mg ml−1 PSR with the washed beads \nat 4 °C with rocking for 20 min. Beads were then washed with PBSB and \nincubated with 0.001× streptavidin-APC (BioLegend, 405207) and \n0.001× goat anti-human Fab fragment FITC ( Jackson ImmunoResearch, \n109-097-003) at 4 °C with rocking for 15 min. Beads were then washed \nand resuspended with PBSB. Beads were profiled via flow cytometry \nusing a BD Accuri C6 flow cytometer. Data analysis was performed with \nBD CSampler Plus software version 1.0.34.1 to obtain median fluores-\ncence intensity (MFI) values, which are reported for each antibody \nacross three or more replicate wells. Elotuzumab (purified using the \nlow-throughput FPLC methodology described above), ixekizumab \n(FPLC purified as described above) and 4E10 (HIV Reagent Program, \nARP-10091) are also included in each assay as controls.\nLentivirus production\nWe produced SARS-CoV-2 Spike (D614G and Beta variants) pseu -\ndotyped lentiviral particles. Viral transfections were done in \nHEK293T cells (American Type Culture Collection, CRL-3216) using \nBioT (BioLand) transfection reagent. Six million cells were seeded in \nD10 media (DMEM + additives: 10% FBS, L-glutamate, penicillin, strep-\ntomycin and 10 mM HEPES) in 10-cm plates 1 day before transfection. \nA five-plasmid system was used for viral production, as described in \nCrawford et al.64. The Spike vector contained the 21-amino-acid trun-\ncated form of the SARS-CoV-2 Spike sequence from the Wuhan-Hu-1 \nstrain of SARS-CoV-2 (GenBank: BCN86353.1 ) or the Beta variant of \nconcern (GenBank: QUT64557.1). The other viral plasmids, used as \npreviously described 64, are pHAGE-Luc2-IRS-ZsGreen (NR-52516), \nHDM-Hgpm2 (NR-52517), pRC-CMV-Rev1b (NR-52519) and HDM-tat1b \n(NR-52518). These plasmids were added to D10 medium in the follow-\ning ratios: 10 μg pHAGE-Luc2-IRS-ZsGreen, 3.4 μg FL Spike, 2.2 μg \nHDM-Hgpm2, 2.2 μg HDM-Tat1b and 2.2 μg pRC-CMV-Rev1b in a final \nvolume of 1,000 μl.\nEbola GP-pseudotyped lentiviruses were produced using the \nsame packaging (pHAGE-Luc2-IRS-ZsGreen) and helper plasmids \n(HDM-Hgpm2, HDM-Tat1b and pRC-CMV-Rev1b) but with the plasmid \nencoding full-length Ebola GP (GenBank: AAG40168.1).\nAfter adding plasmids to medium, we added 30 μl of BioT to form \ntransfection complexes. Transfection reactions were incubated for \n10 min at room temperature, and then 9 ml of medium was added \nslowly. The resultant 10 ml was added to plated HEK cells from which \nthe medium had been removed. Culture medium was removed 24 h \nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nafter transfection and replaced with fresh D10 medium. Viral super -\nnatants were harvested 72 h after transfection by spinning at 300g for \n5 min, followed by filtering through a 0.45-μm filter. Viral stocks were \naliquoted and stored at −80 °C until further use.\nPseudovirus neutralization\nThe target cells used for infection in SARS-CoV-2 pseudovirus neu -\ntralization assays are from a HeLa cell line stably overexpressing \nhuman angiotensin-converting enzyme 2 (ACE2) as well as the pro -\ntease known to process SARS-CoV-2: transmembrane serine protease \n2 (TMPRSS2). Production of this cell line is described in detail by  \nRogers et al.65 with the addition of stable TMPRSS2 incorporation. \nACE2/TMPRSS2/HeLa cells were plated 1 day before infection at \n8,000 cells per well. For Ebola pseudovirus neutralization assays, \nHEK293T cells were seeded in 96-well plates 1 day before infection \nat 20,000 cells per well. Ninety-six-well, white-walled, white-bottom \nplates were used for neutralization assays (Thermo Fisher Scientific).\nOn the day of the assay, purified IgGs in 1× PBS were sterile filtered \nusing a 0.22-μm filter. Dilutions of this filtered stock were made into \nsterile 1× Dulbecco’s PBS (DPBS) (Thermo Fisher Scientific), which was \n5% by volume D10 medium. A virus mixture was made containing the \nvirus of interest (for example, SARS-CoV-2) and D10 media (DMEM + \nadditives: 10% FBS, L-glutamate, penicillin, streptomycin and 10 mM \nHEPES). Virus dilutions into media were selected such that a suitable \nsignal would be obtained in the virus-only wells. A suitable signal was \nselected such that the virus-only wells would achieve a luminescence \nof at least >5,000,000 relative light units (RLU). Then, 60 μl of this \nvirus mixture was added to each of the antibody dilutions to make a \nfinal volume of 120 μl in each well. Virus-only wells were made, which \ncontained 60 μl of 1× DPBS and 60 μl of virus mixture. Cells-only wells \nwere made, which contained 120 μl of D10 media.\nThe antibody/virus mixture was left to incubate for 1 h at 37 °C. \nAfter incubation, the medium was removed from the cells on the plates \nmade 1 day prior. This was replaced with 100 μl of antibody/virus dilu-\ntions and incubated at 37 °C for approximately 24 h. Infectivity readout \nwas performed by measuring luciferase levels. SARS-CoV-2 and Ebola \npseudovirus neutralization assays were read out 48 h and 72 h after \ninfection, respectively. Medium was removed from all wells, and cells \nwere lysed by the addition of 100 μl of BriteLite assay readout solution \n(PerkinElmer) into each well. Luminescence values were measured \nusing an Infinite 200 PRO Microplate Reader (T ecan) using i-control \nversion 2.0 software (T ecan). Each plate was normalized by averaging \nthe cells-only (0% infection) and virus-only (100% infection) wells. We \nused the neutcurve Python package version 0.5.7 to fit the normalized \ndatapoints and to compute the IC 50 values, which we report to two \nsignificant digits. T o estimate measurement error, we computed the \nCV for each antibody–virus IC 50 pair, and we report the mean CV for \neach virus in Supplementary Tables 5, 8 and 9.\nHLA binding prediction\nAs a proxy for predicting T-cell-mediated immunogenicity, we used \nNetMHCPan version 4.1 and NetMHCIIPan version 4.1 (ref. 43) to predict \npeptide binders to class I and class II HLA, respectively, across a number \nof alleles. For the class I analysis, we applied NetMHCPan with default \nparameters to the VH and VL sequences of the wild-type sequences as \nwell as the VH and VL variant sequences listed in Fig. 3a. We considered \nall 9-mer peptides and predicted binding to HLA-A01:01, HLA-A02:01, \nHLA-A03:01, HLA-A24:02, HLA-A26:01, HLA-B07:02, HLA-B08:01, \nHLA-B27:05, HLA-B39:01, HLA-B40:01, HLA-B58:01 and HLA-B15:01. \nFor each VH or VL sequence, we counted the number of peptides deter-\nmined as ‘strong binders’ or ‘weak binders’ according to NetMHC -\nPan. We then tested for a significant change in the number of binders \nbetween the evolved variant sequence and its corresponding wild-type \nusing the binom_test function in scipy.stats. For the class II analysis, we \nsimilarly applied NetMHCIIPan with default parameters to the same \nset of VH and VL sequences. We considered all 15-mer peptides and \npredicted binding to DRB1_0101, DRB3_0101, DRB4_0101, DRB5_0101, \nHLA-DPA10103-DPB10101 and HLA-DQA10101-DQB10201. For each \nVH or VL sequence, we counted the number of peptides determined \nas ‘strong binders’ or ‘weak binders’ according to NetMHCIIPan. We \nthen tested for a significant change in the number of binders between \nthe evolved variant sequence and its corresponding wild-type using \nthe binom_test function in scipy.stats.\nComputing frequency of changes to antibody protein \nsequences\nWe computed the frequency of residues involved in affinity-enhancing \nsubstitutions by aligning the wild-type VH and VL sequences of our \nantibodies to databases of protein sequences. The first database that \nwe considered is UniRef90, where we used the same database release \nused to train ESM-1v. For each antibody protein sequence, we obtained \nthe set of 10,000 sequences in UniRef90 that are closest to the anti -\nbody by sequence similarity based on Levenshtein distance (with the \nfarthest sequences having between 18% and 47% sequence similar -\nity). We computed sequence similarity using the FuzzyWuzzy Python \npackage version 0.18.0. We then used MAFFT version 7.475 to perform \nmultiple sequence alignment among the set of sequences. We used \nthe alignment to compute amino acid frequencies at each site in the \nVH or VL sequence.\nThe second database that we considered is provided by the abYsis \nwebtool, which also computes the frequency of amino acids at each \nposition based on a multiple sequence alignment. We aligned VH and VL \nprotein sequences using the default settings provided in the ‘ Annotate’ \ntool, using the database of ‘ All’ sequences as of 1 March 2022.\nWe also considered the frequency of affinity-enhancing substitu-\ntions conditioned on the corresponding V or J gene. We obtained all \nsequences and corresponding gene annotations from IMGT/LIGM-DB \n(the international ImMunoGeneTics information system, Laboratoire \nd’ImmunoGénétique Moléculaire database) (https://www.imgt.org/ \nligmdb/)66 as of 13 July 2022. For MEDI8852, MEDI8852 UCA, mAb114 \nand mAb114 UCA, we used the V and J gene annotations from the origi-\nnal publications29,30. For S309, REGN10987 and C143, we used the V and \nJ gene annotations in CoV-AbDab (http://opig.stats.ox.ac.uk/webapps/\ncovabdab/)67–75. For a given substitution, we obtained all corresponding \nV or J protein sequences, performed a multiple sequence alignment \nwith MAFFT version 7.475 and used the resulting alignment to compute \namino acid frequencies.\nTherapeutic antibody database evaluation and runtime \nbenchmark\nWe downloaded 742 therapeutically relevant antibodies from the \nThera-SAbDab database as of 26 February 2022 (http://opig.stats.\nox.ac.uk/webapps/newsabdab/therasabdab/) 47. For each antibody \nVH and VL sequence, we used the same procedure described above for \ncomputing consensus substitutions that have higher language model \nlikelihood than wild-type. We measured the computational runtime \nusing the time module in Python 3.8. Experiments were performed \nwith an Advanced Micro Devices EPYC Rome 7502P 2.5-GHz CPU and \nan Nvidia Ampere A40 48GB GPU.\nNatural protein evaluation and benchmarking based on \nscanning mutagenesis data\nWe evaluated the ability for the language models and algorithms used \nin our study to guide efficient evolution in other settings beyond anti-\nbodies. We used deep mutational scanning (DMS) datasets to validate \nthat our approach would enable a researcher to acquire high-fitness \nvariants. We used all DMS datasets from the benchmarking study by \nLivesey and Marsh48 with 90% or higher coverage of all single-residue \nsubstitutions; variants that were not measured were excluded from \nthe analysis. We also used a scanning mutagenesis dataset generated \nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nby Markin et al. 8 that measured Michaelis–Menten kinetics of all \nsingle-site glycine or valine substitutions to the bacterial enzyme PafA; \nfor this dataset, any language-model-recommended substitutions that \ndid not involve glycine or valine substitutions were excluded from the \nanalysis. We applied a cutoff for each dataset to binarize sequences as \nhigh-fitness or low-fitness variants (cutoffs are provided in Supple -\nmentary Table 13); we then compared enrichment of high-fitness vari-\nants among the language-model-recommended variants to the \nbackground frequency of high-fitness variants among all single-residue \nsubstitutions. For these proteins, as with our antibody experiments, \nwe chose values of k  that result in a small number (~10 1) of acquired \nsubstitutions: we used α = 1 and k = 2 for all proteins except those where \nthis resulted in |𝒜𝒜| ≤5, in which case we set k = 1 (and additionally α = 0.5 \nfor infA).\nT o quantify the statistical significance of an enrichment, we \nassumed that the null distribution of the number of high-fitness, \nlanguage-model-recommended variants was given by a hypergeomet-\nric distribution parameterized by the number of language-  \nmodel-recommended variants |𝒜𝒜|, the number of high-fitness variants \namong the all single-residue substitutions and the total number of \nsingle-residue substitutions considered, which we used to compute a \none-sided P value. We used the hypergeometric calculator at https://\nstattrek.com/online-calculator/hypergeometric.aspx.\nT o test the relationship between likelihood stringency and the \nfraction of high-fitness substitutions, we also performed a small-scale \nparameter sweep varying the cutoff values α and k and computing (1) \nthe percentage fraction of high-fitness substitutions in 𝒜𝒜; (2) the maxi-\nmum fitness value of a variant in 𝒜𝒜 divided by the maximum fitness \nvalue of a variant across the full mutational scan; and (3) the maximum \nfitness value of a variant in 𝒜𝒜 divided by the 99th percentile of the fit-\nness values across the full mutational scan; before this normalization, \nthe raw fitness values are also linearly scaled to take values between  \n0 and 1, inclusive. Normalized values, the number of acquired  \nvariants |𝒜𝒜| and the parameter combinations are plotted in Extended \nData Fig. 4.\nWe also tested how well alternative methods for ranking substitu-\ntions would be able to suggest high-fitness variants. T o enable a direct \ncomparison to the language model consensus strategy described \nabove, we selected the same number of substitutions and kept all other \nparameters fixed while only varying the method used to rank substitu-\ntions. We used the benchmarking results obtained by Livesey and \nMarsh48 enabling us to test 46 different methods for ranking substitu-\ntions, which use evolutionary information, biophysical properties of \namino acids or protein structure information; these methods are \ndescribed in greater detail in Table EV1 of ref. 48. We also tested how \nwell using the summed log-likelihood ratios across all ESM language \nmodels (that is, computing ∑j (logpj (x′\ni |x)−logpj (xi|x)) at each site i \nand substitution x′\ni) would compare to the consensus strategy. For each \nDMS dataset, we computed the number of high-fitness mutations that \nwere acquired by each of these 47 benchmark methods (Extended Data \nFig. 5); we broke any ties in variant effect predictor scores by randomly \nselecting substitutions and computing the average number of \nhigh-fitness variants over 100 random seeds. We aggregated results \nacross DMS datasets by ranking methods within each DMS (averaging \nthe ranks that would have been assigned to tied values) and computed \nthe mean rank across the eight DMS datasets (Extended Data Fig. 5 and \nSupplementary Data 5).\nReporting Summary\nFurther information on research design is available in the Nature Port-\nfolio Reporting Summary linked to this article.\nData availability\nRaw data for this study have been deposited to Zenodo at https://doi.\norg/10.5281/zenodo.6968342. Kd, IC50 and Tm values across replicate \nexperiments are available as Supplementary Data 1. Median fluores -\ncence intensity values for the polyspecificity experiments are available \nas Supplementary Data 2. Experimental values for our benchmarking \nof sequence-based methods and results from our UniRef90 parameter \nsweeps are available as Supplementary Data 3. High-likelihood amino \nacid substitutions for 742 therapeutic antibodies are available as Sup-\nplementary Data 4. Mean rank values for our deep mutational scanning \nbenchmark experiments are available as Supplementary Data 5. A list \nof oligonucleotides used in the study is provided as Supplementary \nData 6. We also make use of the following publicly available databases \nand datasets:\n•\tUniProt:\thttps://www.uniprot.org/\n•\tUniRef50\t2018_03\t(ref.\t23): https://ftp.uniprot.org/pub/databases/\nuniprot/previous_releases/release-2018_03/uniref/\n•\tUniRef90\t2020_03\t(ref.\t23): https://ftp.uniprot.org/pub/databases/\nuniprot/previous_releases/release-2020_03/uniref/\n•\tabYsis\n44: http://www.abysis.org/abysis/\n•\tIMGT/LIGM-DB66: https://www.imgt.org/IMGTindex/LIGM-DB.php\n•\tThera-SAbDab47: https://opig.stats.ox.ac.uk/webapps/newsabdab/\ntherasabdab/search/\n•\tLivesey\tand\tMarsh\tbenchmarking\tdataset\n48,68–75.\nCode availability\nWe provide open-source code that enables a user to easily and quickly \nevaluate the language models on a sequence of interest. We implement \nthis as a simple call to a Python script with the wild-type sequence as \nthe main argument, which is available at https://github.com/brianhie/\nefficient-evolution. Code and scripts used in this study are available as \nSupplementary Code and have been deposited to Zenodo at https://\ndoi.org/10.5281/zenodo.6977562.\nReferences\n63. Katoh, K. & Standley, D. M. MAFFT multiple sequence alignment \nsoftware version 7: improvements in performance and usability. \nMol. Biol. Evol. 30, 772–780 (2013).\n64. Crawford, K. H. D. et al. Protocol and reagents for pseudotyping \nlentiviral particles with SARS-CoV-2 spike protein for \nneutralization assays. Viruses 12, 513 (2020).\n65. Rogers, T. F. et al. Isolation of potent SARS-CoV-2 neutralizing \nantibodies and protection from disease in a small animal model. \nScience 369, 956–963 (2020).\n66. Giudicelli, V. et al. IMGT/LIGM-DB, the IMGT\n® comprehensive \ndatabase of immunoglobulin and T cell receptor nucleotide \nsequences. Nucleic Acids Res. 34, D781–D784 (2006).\n67. Raybould, M. I. J., Kovaltsuk, A., Marks, C. & Deane, C. M. \nCoV-AbDab: the coronavirus antibody database. Bioinformatics \n37, 734–735 (2021).\n68. Jones, E. M. et al. Structural and functional characterization of  \nG protein–coupled receptors with deep mutational scanning. \neLife 9, e54895 (2020).\n69. Stiffler, M. A., Hekstra, D. R. & Ranganathan, R. Evolvability as a \nfunction of purifying selection in TEM-1 β-lactamase. Cell 160, \n882–892 (2015).\n70. Haddox, H. K., Dingens, A. S. & Bloom, J. D. Experimental \nestimation of the effects of all amino-acid mutations to HIV’s \nenvelope protein on viral replication in cell culture. PLoS Pathog. \n12, e1006114 (2016).\n71. Doud, M. B. & Bloom, J. D. Accurate measurement of the effects of \nall amino-acid mutations on influenza hemagglutinin. Viruses 8, \n155 (2016).\n72. Lee, J. M. et al. Deep mutational scanning of hemagglutinin helps \npredict evolutionary fates of human H3N2 influenza variants. \nProc. Natl Acad. Sci. USA 115, E8276–E8285 (2018).\n73. Kelsic, E. D. et al. RNA structural determinants of optimal codons \nrevealed by MAGE-Seq. Cell Syst. 3, 563–571 (2016).\nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\n74. Brenan, L. et al. Phenotypic characterization of a comprehensive \nset of MAPK1/ERK2 missense mutants. Cell Rep. 17, 1171–1183 (2016).\n75. Giacomelli, A. O. et al. Mutational processes shape the landscape \nof TP53 mutations in human cancer. Nat. Genet. 50, 1381–1387 \n(2018).\n76. Thomas, M. J., Klein, U., Lygeros, J. & Rodríguez Martínez, M. \nA probabilistic model of the germinal center reaction. Front. \nImmunol. 10, 689 (2019).\n77. Tas, J. M. J. et al. Visualizing antibody affinity maturation in \ngerminal centers. Science 351, 1048–1054 (2016).\nAcknowledgements\nWe thank B. Bell, B. Clifton, R. Costello, A. Hugenmatter, O. Leddy,  \nD. Maurer and A. Narayan for helpful discussions. We thank L. Lahey for \ncontributing polyspecificity reagent. We thank M. Filsinger Interrante, \nS. Kim and other members of the Peter Kim laboratory for useful \ncomments on the manuscript. B.L.H. acknowledges the support of the \nStanford Science Fellows program. D.X. acknowledges the postdoctoral \nfellowship from the Stanford Maternal and Child Health Research \nInstitute. S.T. is supported by National Institutes of Health (NIH) National \nInstitute of Child Health and Human Development grant K99HD104924 \nand a Damon Runyon Cancer Research Foundation fellowship  \n(DRG-2301-17). This work was supported by the Virginia & D. K. Ludwig \nFund for Cancer Research (P.S.K.), the Chan Zuckerberg Biohub (P.S.K.) \nand the NIH (DP1AI158125; P.S.K.). A previous version of this article \nappeared on bioRxiv (https://doi.org/10.1101/2022.04.10.487811).\nAuthor contributions\nConceptualization, investigation and interpretation: B.L.H. and P.S.K. \nComputational experiments and software development: B.L.H. \nAntibody cloning, expression and purification: B.L.H., V.R.S., W.W. and \nJ.E.P. Antigen cloning, expression and purification: B.L.H., V.R.S., D.X., \nT.U.J.B., P.A.W. and S.T. Binding assays: B.L.H and V.R.S. Thermal melts: \nB.L.H. and V.R.S. Polyspecificity assay: B.L.H. Lentivirus production and \npseudovirus neutralization: D.X. Writing (initial draft): B.L.H. Writing \n(final draft): all authors.\nCompeting interests\nB.L.H., V.R.S. and P.S.K. are named as inventors on a provisional \npatent application applied for by Stanford University and the Chan \nZuckerberg Biohub related to this study. B.L.H. performs research for \nMeta Platforms, Inc. The remaining authors declare no competing \ninterests.\nAdditional information\nExtended data is available for this paper at https://doi.org/10.1038/\ns41587-023-01763-2.\nSupplementary information The online version contains \nsupplementary material available at https://doi.org/10.1038/ \ns41587-023-01763-2.\nCorrespondence and requests for materials should be addressed to \nBrian L. Hie or Peter S. Kim.\nPeer review information Nature Biotechnology thanks the anonymous \nreviewers for their contribution to the peer review of this work.\nReprints and permissions information is available at  \nwww.nature.com/reprints.\nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nExtended Data Fig. 1 | ESM masked versus wildtype marginals.  \n(a) Representative scatter plots showing all possible single-site substitutions \nto an antibody sequence plotted according to their log-likelihood ratios to \nwildtype, where likelihoods are computed based on either masked marginals \n(y-axis) or wildtype marginals (x-axis). A red dashed line is plotted where masked \nand wildtype marginal values are equal. The wildtype marginal log-likelihoods \nare consistently lower overall, effectively serving to make the α parameter more \nstringent, while (b) the rank-based correlation between masked marginals and \nwildtype marginals is close to 1 in all cases.\nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nExtended Data Fig. 2 | Pseudovirus neutralization of affinity-matured \nvariants. (a) Neutralization curves for wildtype antibodies (gray) and variants \nobtained by our language-model-guided affinity maturation campaigns. Also \nsee Supplementary Tables 5, 8, and 9 for corresponding IC\n50 values. Points \nindicate the mean; error bars indicate the standard deviation; n = 4 independent \nassays. (b) Fold-improvement in kon has low correlation with fold-change in IC50 \n(Spearman r = 0.12), while fold-improvement in koff has high correlation with fold-\nchange in IC50 (Spearman r = 0.79); compare to Fig. 3c. Correlations involve n = 15 \nantibody variants. We define a higher kon and a lower koff as improved, so we divide \nthe mutant value by the wildtype value to calculate fold-improvement in kon and \nvice-versa to calculate fold-improvement in koff.\nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nExtended Data Fig. 3 | UniRef90 significance and robustness analysis. (a)  \nA histogram of the null distribution generated by simulating how many avidity-\nenhancing substitutions would be recommended from a site-independent \nmodel based on UniRef90 alignments. Results are for n = 4.5 million simulations \nas described in Methods. Based on this null distribution and given that the \nlanguage models recommended 12 avidity-enhancing substitutions, we \nestimate P = 0.0085. (b) The number of known avidity-enhancing substitutions \nrecommended by a UniRef90 site-independent model at varying alignment \ndepths, where our benchmark analyses are performed using an alignment \ndepth of 10,000. The red line indicates the number of avidity-enhancing \nsubstitutions found by the language models. The combined number of known \navidity-enhancing substitutions is provided in the stacked bar plot on the left \nand are separated by the antibody in the three right panels. The substitutions \ncorresponding to each alignment depth and antibody are provided in \nSupplementary Data 3.\nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nExtended Data Fig. 4 | See next page for caption.\nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nExtended Data Fig. 4 | Relationship between likelihood stringency and \nfitness efficiency. T o obtain the set 𝒜𝒜 of language-model-recommended \nvariants, we varied two parameters controlling the stringency of acquired \nvariants (where more stringent corresponds to fewer variants): α is a cutoff \ncontrolling the likelihood ratio of the mutant probability to the wildtype \nprobability, and k is a cutoff controlling the number of consensus language \nmodels (Methods). (a) At varying cutoffs, we computed the percentage fraction \nof variants in \n𝒜𝒜 that correspond to high-fitness variants, using scanning \nmutagenesis data for validation. When α = 0 and k = 1, this value is equivalent to \nthe percentage of high-fitness variants in the full scanning mutagenesis dataset \n(a black dashed line is also drawn at this value for each protein). In all cases except \nfor P53, we observe that increasing the likelihood stringency generally improves \nthe efficiency at which high-fitness variants are acquired. In Fig. 4, we report \nvalues for α = 1, k = 2, except for when these cutoffs result in |𝒜𝒜| < 5 (infA, MAPK1, \nand PafA), in which case we report α = 1, k = 1. (b, c) Given a set of acquired variants \n𝒜𝒜 at varying cutoffs, we also computed how much the maximum fitness \nrepresented in 𝒜𝒜 compares either to the maximum possible fitness value \nobtained across the full mutational scan (b) or to the 99th percentile of fitness \nvalues across the full mutational scan (c). T o compare across proteins, we plotted \nthe maximum acquired fitness value normalized by the maximum possible \nfitness (b) or by the 99\nth percentile with a threshold at 1 (c). At even at the most \nstringent cutoffs, the best acquired variant of most proteins has at least 50% of \nthe fitness value of the maximum fitness peak. Additionally, at the most stringent \ncutoffs, the best acquired variant of all proteins is above or close to the 99\nth \npercentile of fitness values. (d) We plotted the number of acquired variants |𝒜𝒜|, \nwhich is the denominator of the values plotted in (a). A gray horizontal dashed \nline is also plotted at 100.\nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nExtended Data Fig. 5 | Benchmarking enrichment of high-fitness variants.  \n(a, b) Variant effect prediction methods were ranked by the number of high-\nfitness variants acquired, controlling for the sample size N of total acquired \nvariants used in Fig. 4, and ordered by the mean rank across eight proteins \n(Methods). Our consensus voting strategy (‘ESM vote’) ranks higher on average \nthan all other methods based on its ability to acquire high-fitness variants. \nMethods profiled by Livesey and Marsh\n48 are in black text; ESM-based strategies \nprofiled in this study are in red text. The full list of mean ranks is provided \nas Supplementary Data 5. ESM vote: the consensus strategy for acquiring \nsubstitutions used to select variants for experimental measurement in our \nantibody experiments. ESM summed: acquiring substitutions based on summed \nlanguage model likelihood across the six language models used in this study.  \n(b) Strip plot illustrating the number of high-fitness variants (vertical axis) \namong the top-N acquired substitutions to each protein (horizontal axis), \nwhere each point represents a different method for acquiring substitutions. \nThese values are used to calculate the mean rank in (a). The expected number of \nvariants that would be acquired via random guessing is plotted as a horizontal \ndashed line for each protein. (c, d) A similar analysis as in (a, b) but comparing the \nconsensus voting strategy to each component of the ESM ensemble individually. \nEnsembling the recommendations across language models more consistently \nacquires high-fitness variants than when only using a single language model.\nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nExtended Data Fig. 6 | Scatter plots of DMS fitness data and ESM-ranked \nvariants. Variants of each protein (with a single-site substitution from wildtype) \nare plotted as blue circles according to the experimentally-determined fitness \nvalue on the y-axis and the summed log-likelihood across the six ESM models \nconsidered in our analysis. The variants acquired by the ESM consensus voting \nscheme are plotted as red circles. The cutoff above which we define a high-fitness \nvariant is plotted as a gray dashed line. The marginal distribution of experimental \nfitness values is also plotted as a histogram along the y-axis.\nNature Biotechnology\nArticle https://doi.org/10.1038/s41587-023-01763-2\nExtended Data Fig. 7 | Comparison of affinity fold improvements versus \nexperimental scale. Points indicate the results of affinity maturation beginning \nwith an unmatured starting point (indicated by circles) or with a matured starting \npoint (indicated by plus signs). The horizontal axis indicates the experimental \nscale in terms of variants tested or the experimental library size. The vertical \naxis indicates the fold improvement obtained by affinity maturation. Results \nfrom this study are plotted in black. While there is substantial uncertainty about \nthe size of the mutational space explored by in-vivo somatic hypermutation (to \ninclude the unproductive B cell clones), we estimate a scale between 10\n3 to 106 \nbased on the number of B cells contained within a germinal center (about 103 to \n104)76,77, the mutation rate of somatic hypermutation (about 1 mutation per kb \nper division)13, the doubling time of B cells (about 10 hours)76, and a timescale \nof a few weeks13. The results of natural affinity maturation of the unmatured \nantibodies in this study29,30,38, are plotted as blue dots (Supplementary Data 1). We \nalso plot the results of recent studies reporting advances in antibody engineering \ntechnologies, including Mason et al.\n28 who achieve a 3-fold improvement in the \nbinding of trastuzumab to human epidermal growth factor receptor 2 (HER2) \nusing a library of ~39 K variants and Wellner et al.\n14 who achieve between a 2.3- and \n580-fold improvement in the binding of unmatured nanobodies to SARS-CoV-2 \nRBD (picked out of a naïve library) using a continuously evolving yeast system \ninvolving 10\n6 to 107 sorted cells over four or more rounds of selection.\n\n\n",
  "topic": "Antibody",
  "concepts": [
    {
      "name": "Antibody",
      "score": 0.6838977336883545
    },
    {
      "name": "Directed evolution",
      "score": 0.5345683693885803
    },
    {
      "name": "Biology",
      "score": 0.5331745743751526
    },
    {
      "name": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)",
      "score": 0.5305108428001404
    },
    {
      "name": "Computational biology",
      "score": 0.5171850919723511
    },
    {
      "name": "Thermostability",
      "score": 0.46740394830703735
    },
    {
      "name": "Natural selection",
      "score": 0.45510780811309814
    },
    {
      "name": "Coronavirus disease 2019 (COVID-19)",
      "score": 0.42377519607543945
    },
    {
      "name": "Directed Molecular Evolution",
      "score": 0.4113695025444031
    },
    {
      "name": "Virology",
      "score": 0.40484678745269775
    },
    {
      "name": "Evolutionary biology",
      "score": 0.35438090562820435
    },
    {
      "name": "Gene",
      "score": 0.35157671570777893
    },
    {
      "name": "Genetics",
      "score": 0.31684839725494385
    },
    {
      "name": "Selection (genetic algorithm)",
      "score": 0.2978356182575226
    },
    {
      "name": "Enzyme",
      "score": 0.19933950901031494
    },
    {
      "name": "Medicine",
      "score": 0.1654232144355774
    },
    {
      "name": "Computer science",
      "score": 0.1494775414466858
    },
    {
      "name": "Infectious disease (medical specialty)",
      "score": 0.12166118621826172
    },
    {
      "name": "Biochemistry",
      "score": 0.1136523187160492
    },
    {
      "name": "Artificial intelligence",
      "score": 0.10415005683898926
    },
    {
      "name": "Pathology",
      "score": 0.0
    },
    {
      "name": "Mutant",
      "score": 0.0
    },
    {
      "name": "Disease",
      "score": 0.0
    }
  ]
}