{
  "title": "Evaluating the progression of artificial intelligence and large language models in medicine through comparative analysis of ChatGPT-3.5 and ChatGPT-4 in generating vascular surgery recommendations",
  "url": "https://openalex.org/W4390415052",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2746959520",
      "name": "Arshia P. Javidan",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A273007379",
      "name": "Tiam Feridooni",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A2103366149",
      "name": "Lauren Gordon",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A2215666518",
      "name": "Sean A. Crawford",
      "affiliations": [
        "University Health Network",
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A273007379",
      "name": "Tiam Feridooni",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A2103366149",
      "name": "Lauren Gordon",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A2215666518",
      "name": "Sean A. Crawford",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2120738518",
    "https://openalex.org/W4366989525",
    "https://openalex.org/W4221027537",
    "https://openalex.org/W4225927996",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4367310920",
    "https://openalex.org/W4319062614",
    "https://openalex.org/W3173746046",
    "https://openalex.org/W3010918768",
    "https://openalex.org/W2776247479",
    "https://openalex.org/W6854265927",
    "https://openalex.org/W6774417633",
    "https://openalex.org/W2806707354",
    "https://openalex.org/W1873063852",
    "https://openalex.org/W3107002165",
    "https://openalex.org/W4367626167",
    "https://openalex.org/W4381427645",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W3006549594"
  ],
  "abstract": "ObjectiveArtificial intelligence (AI) continues to become increasingly integrated with clinical medicine. Generative AI, and particularly Large Language Models (LLMs) like ChatGPT-3.5 and ChatGPT-4, have shown promise in generating human-like text, providing a potential tool for augmenting clinical care. These online AI chatbots have already demonstrated remarkable clinical potential, having passed the USMLE, for example. The evaluation of these LLMs in the surgical literature, especially as it applies to judgement and decision-making, is sparse. This study aimed to 1) evaluate the efficacy of ChatGPT-4 in providing clinician-level vascular surgery recommendations and 2) compare its performance with its predecessor, ChatGPT-3.5, to gauge the progression of clinical competencies of LLMs.MethodsA set of forty clinician-level questions spanning four domains of vascular surgery (carotid artery disease, visceral artery aneurysms, abdominal aortic aneurysms, chronic limb-threatening ischemia) were generated by clinical experts. These domains were chosen based on the availability of updated guidelines published before September 2021, which served as the cut-off date for the training dataset of the LLMs. The questions, devoid of additional context or prompts, were inputted into ChatGPT-3.5 and ChatGPT-4 between March 20 and March 25, 2023. Responses were independently evaluated by two blinded reviewers using a 5-point Likert scale assessing comprehensiveness, accuracy, and consistency with guidelines. The Flesch-Kincaid Grade Level of each response was also determined. Independent samples t-test and Fisher's exact test were employed for comparative analysis.ResultsChatGPT-4 significantly outperformed ChatGPT-3.5 by providing appropriate recommendations in 38 out of 40 questions (95%) as compared to 13 out of 40 (32.5%) by ChatGPT-3.5 (Fisher's Exact Test p < 0.001). Despite longer response lengths (chatGPT-4 mean 317 ± 58 words vs. chatGPT-3.5 mean 265 ± 74 words (p < 0.001), the reading ease of both models remained similar, corresponding to college-level graduate texts.ConclusionChatGPT-4 can consistently respond accurately to complex clinician-level vascular surgery questions. This also represents a substantial advancement in performance compared to its predecessor, which was released only a few months prior, highlighting the progress of performance of LLMs in clinical medicine. Several limitations persist with the use of LLMs, including hallucinations, data privacy issues, and the black box problem, However, these findings suggest that with further refinements, LLMs like ChatGPT-4 have the potential to become indispensable tools in clinical decision-making, thereby marking an exciting frontier in the fusion of AI with clinical medicine and vascular surgery.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.43640270829200745
    },
    {
      "name": "Artificial intelligence",
      "score": 0.41927197575569153
    },
    {
      "name": "Medicine",
      "score": 0.38763827085494995
    },
    {
      "name": "Natural language processing",
      "score": 0.38193318247795105
    },
    {
      "name": "Linguistics",
      "score": 0.3798275887966156
    },
    {
      "name": "Cognitive science",
      "score": 0.3359956443309784
    },
    {
      "name": "Psychology",
      "score": 0.2855188250541687
    },
    {
      "name": "Philosophy",
      "score": 0.11701995134353638
    }
  ]
}