{
  "title": "Potential Applications and Safety of Large Language Models in Healthcare",
  "url": "https://openalex.org/W4394837766",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2602966865",
      "name": "Siyin Chen",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2441515906",
    "https://openalex.org/W2596192549",
    "https://openalex.org/W4361251463"
  ],
  "abstract": "This study explores the potential applications and associated safety concerns of large language models in healthcare. It particularly highlights the multifaceted applications of large language models (e.g., ChatGPT, MedLM) in healthcare, including data analysis, diagnostics, information retrieval, usage of medical devices, and assistance in tasks. Concurrently, it underscores the risks present alongside these applications, especially concerning data privacy. The study emphasizes the necessity of data privacy protection throughout the entire cycle. By reviewing policies from various countries, it outlines the critical role of refined policies and a clear governmental stance in advancing the application of large language models in healthcare and ensuring their safety.",
  "full_text": "Dean&Francis\nPotential Applications and Safety of Large Language Models in \nHealthcare\nSiyin Chen\nAbstract:\nThis study explores the potential applications and associated safety concerns of large language models in healthcare. It \nparticularly highlights the multifaceted applications of large language models (e.g., ChatGPT, MedLM) in healthcare, \nincluding data analysis, diagnostics, information retrieval, usage of medical devices, and assistance in tasks. \nConcurrently, it underscores the risks present alongside these applications, especially concerning data privacy. The study \nemphasizes the necessity of data privacy protection throughout the entire cycle. By reviewing policies from various \ncountries, it outlines the critical role of refined policies and a clear governmental stance in advancing the application of \nlarge language models in healthcare and ensuring their safety.\nKeywords: large language model, healthcare, privacy security, healthcare big data\n1. Introduction\nThe emergence of large language models has introduced \nnew opportunities and challenges for the digital transfor -\nmation of the healthcare sector. As an outstanding repre -\nsentative of deep learning, models such as GPT-4.0 have \ngarnered widespread attention for their successful applica-\ntion in natural language processing. However, their poten-\ntial extends far beyond, showing valuable applications in \nclinical practice, diagnosis, drug dispensing, information \nprocessing, remote patient monitoring, data sharing, and \ntest analysis. This study aims to delve into the various \napplications of large language models in healthcare and \naddress potential pitfalls concerning data privacy, national \npolicies, and societal attitudes.\n2. Introduction to Large Language \nModels\nLarge language models represent a branch of natural lan -\nguage processing technology grounded in deep learning, \nboasting exceptional capabilities in language comprehen -\nsion and generation. The historical development of these \nmodels can be traced back to the early phases of artificial \nintelligence, initially focusing on simulating human con -\nversation. With the progression of AI and deep learning, \nlarge language models have gradually evolved to process \nincreasingly complex textual information and tasks. Their \narchitectural framework and pre-training mechanisms en-\nable them to understand and generate complex language \nstructures, providing a powerful tool for the medical field. \nFurthermore, tests such as the United States Medical Li -\ncensing Examination (USMLE) have demonstrated that \nmodels like ChatGPT can, through training, proficiently \nacquire the skills and knowledge required for clinical \npractice. [8,10]\nLarge language models exhibit core features and prin -\nciples: 1) Model Structure: Typically utilizing the trans -\nformer architecture, these models feature a self-attention \nmechanism that enhances their ability to capture the con -\ntextual nuances of language during input processing. 2) \nPre-training Mechanism: They are generally pre-trained \non extensive datasets to learn the universal patterns of \nlanguage, focusing on a deep understanding of language \nwithout being optimized for specific tasks initially. 3) Pa-\nrameter V olume: The term “large” in large language mod-\nels refers to their vast number of parameters, with models \nlike GPT-3.5 housing billions of parameters, enabling the \nrepresentation of complex and abstract language struc -\ntures. 4) Fine-tuning: Post-pre-training, models can be \nfine-tuned to adapt to specific domains or tasks, allowing \noptimization with limited labelled data for improved per -\nformance in particular areas.\nIn December 2023, Google introduced a medical large \nlanguage model named MedLM to its cloud users, build -\ning upon the foundations of Med-PaLM and Med-PaLM \n2 text models. Med-PaLM, previewed at the end of 2022 \nand published in “Nature” in July 2023, became the first \nAI system to surpass the passing threshold for USM -\nLE-style questions, generating accurate, extended respons-\nes to health queries. March 2023 saw the launch of Med-\nPaLM 2, the first to provide answers at a human expert \nlevel for USMLE-type questions. To assess the accuracy \nISSN 2959-6149 \n1\nDean&Francis\nof model responses, Google established the MultiMedQA \nbenchmark, incorporating seven Q&A datasets covering \nprofessional medical examinations, medical research, \nand consumer inquiries. Med-PaLM emerged as the first \nmodel to achieve a passing score on the MedQA dataset \nfor USMLE questions, with an accuracy of 67.7%, while \nMed-PaLM 2 advanced to 86.5%. Beyond USMLE-type \nquestions, the models’ extended responses were evaluated \nby clinicians and non-clinicians from various backgrounds \nand countries, with criteria including scientific accuracy, \nprecision, medical consensus, reasoning, bias, and poten -\ntial for harm. In three consumer healthcare question data -\nsets, both Med-PaLM and Med-PaLM 2 performed well, \nand in a paired study, Med-PaLM 2’s answers were often \nsuperior to those of human doctors in most standards. [3,4]\n3. Potential Applications in different \ndirections\n3.1 Data Analysis\nIn the realm of data analysis, large language models offer \nformidable support for disease surveillance, treatment, \nand patient care. By deeply analyzing clinical data, these \nmodels can detect trends in patient conditions, providing \nearly warnings and even assisting physicians in devising \npersonalized treatment plans. Remote patient monitoring \nis also enhanced, with models analyzing patient data in \nreal-time to identify anomalies, thereby offering timely \ndecision support to healthcare professionals. Google has \ndeveloped a multimodal model based on PaLM-E for \nMed-PaLM, enabling synchronous communication of \nimaging information with physicians, such as chest and \nbreast X-rays, to improve patient care. Currently, it sup -\nports dermatology, retinology, radiology (3D and 2D), pa-\nthology, health records, and genomics, although it has not \nyet been clinically deployed [4]. Additionally, The Royal \nFree NHS Foundation Trust and Google DeepMind’s AI \ndivision have created a real-time alert system for Acute \nKidney Injury (AKI) by monitoring patient blood tests and \nelectronic medical records, sending immediate AKI alerts \nto clinicians upon detecting deterioration signs. However, \nthis achievement has faced controversies over information \nsecurity.[17]\n3.2 Assistant\nLarge language models can serve as assistants in electron-\nic medical record entry and preservation, enabling physi-\ncians to manage and record patient information more effi-\nciently. Moreover, these models can act as remote virtual \nmedical assistants and medical translation tools, enhanc -\ning efficiency and reducing the likelihood of human error. \nBeyond potential clinical contributions, large language \nmodels can also enhance the efficiency and accessibility \nof medical education. Given the high knowledge demands \non medical professionals and the lengthy time required to \ntrain medical talent, large language models can assist in \nmedical professional education through speedy and accu -\nrate information extraction. As the technology matures, \nmedical personnel may rely on large language models \nfor co-decision-making in medical solutions, potentially \nalleviating the talent shortage caused by the lengthy and \nchallenging process of medical education and licensure.\n3.3 Intelligent Q&A\nLarge language models hold extensive potential in intelli -\ngent Q&A, assisting in clinical decision-making through \ndeep learning capabilities to analyze medical records and \nliterature, providing instant clinical recommendations. \nThese models can offer information on possible diagnoses \nbased on symptoms, medical history, and lab results, aid -\ning in more accurate diagnoses, and reducing errors due \nto insufficient medical knowledge or misinterpretation. \nFurthermore, models like the open-source Doctor Dignity \non GitHub, based on Meta’s Llama with 27 billion param-\neters and fine-tuned on medical dialogue datasets, have \npassed the US medical licensing exams. They aim to cre -\nate personal doctors for patients, accessible on any local \ndevice without needing an API (Application Programming \nInterface) installation [2]. Another example, DoctorGPT, \nsupported by Algomed and OpenAI, which requires API \ninstallation and offers personalized advice based on symp-\ntoms and history, facilitating efficient and convenient \nmedical consultations for patients. [1]\n3.4 Information Retrieval\nLarge language models also show potential in information \nretrieval, such as medical knowledge, drug administration, \nand medication information queries. They can expedite \nthe extraction of information from medical literature and \nreviews for researchers and doctors, supporting medical \nresearch, clinical practice, and education. By synchro -\nnizing with hospital medication inventories and learning \nabout medications, these models can assist in creating per-\nsonalized treatment plans and reducing medication errors \nand adverse reactions. For patients, they can explain med -\nication effects, usage, and possible side effects in natural \nlanguage, combining intelligent diagnostic capabilities \nto suggest basic medication advice based on past clinical \ntreatment plans. [7]\n3.5 Medical Devices\nThe application of large language models in the medical \ndevice sector offers innovative prospects. By analyzing \nextensive data on medical device designs, patient needs, \nand physician usage habits, models can provide designers \n2\nDean&Francis\nwith innovative concepts and optimization suggestions. \nPredicting the failure probability and maintenance needs \nof devices aids in planning maintenance schedules, and \nensuring the reliability of medical equipment. Coupled \nwith simulation technology, models can conduct mock \ntests on devices to evaluate their performance and safety, \nbolstering the development and improvement of medical \ndevices. [13]\nThe broad potential applications of large language models \nin healthcare demonstrate their multifaceted advantages, \nenhancing the quality and efficiency of medical services. \nHowever, while maximizing their benefits, it is crucial to \naddress potential risks related to data privacy and ethical \nissues, ensuring sustainable and safe development of large \nlanguage models in medical applications.\n4. Potential Risks\n4.1 Data Privacy\nWith the broad application of large language models in \nthe medical field, protecting patient data privacy emerges \nas an urgent issue to be addressed. Medical health big data \nis primarily divided into four categories [5,13]:\n1) Clinical Big Data: This includes basic content gen -\nerated during a patient’s medical visit, such as detailed \npersonal information, electronic medical records, medical \nimaging data, and medication records, which might con -\ntain sensitive information like names, ages, addresses, and \nphone numbers. Improper handling of these data could \nlead to privacy breaches, raising legal and ethical con -\ncerns.\n2) Health Big Data: Comprising data from wearable de -\nvices, mobile app monitoring, and internet behavior data, \nthese form an individual’s electronic health record for \nmonitoring health status. However, this sensitive health \ninformation could potentially lead to privacy leaks, espe -\ncially when interconnected with the internet and medical \ninstitutions.\n3) Biological Big Data: Encompassing vast datasets from \ngenomics, transcriptomics, proteomics, metabolomics, \netc., genetic testing data combined with pathological data \nmay reveal an individual’s identity, leading to genetic dis-\ncrimination. Such information leaks could doubly harm \npatients’ privacy and mental health.\n4) Operational Big Data: Medical institutions’ operational \ndata includes cost accounting, procurement of drugs, con-\nsumables, equipment, and drug development data, which \nmay involve private information about a person’s health \nand financial status. Misuse or leakage of these data could \ndamage patients’ trust in medical institutions and may be \nexploited for commercial purposes, leading to disputes \nover privacy rights.\nClinical and operational big data, which need to be acces -\nsible as training and application data for large language \nmodels, are closely linked to patient information. Thus, \ndata privacy protection is indispensable in the develop -\nment trajectory of large language models. Privacy protec -\ntion across the entire lifecycle, from data collection, stor -\nage, and sharing to analysis, requires specific measures.\nFor example, during data collection, traditional medical \ndata privacy protection mainly employs anonymization \ntechniques to obscure the link between data and individ -\nuals, but these are easily decrypted. More targeted ano -\nnymization and differential privacy techniques, such as the \nDAIMDL algorithm, are needed to weaken data’s sensi -\ntive attributes. In the data storage phase, encryption tech -\nnologies suited to health big data and cloud platforms are \nnecessary, along with third-party audits of data integrity. \nIn the data-sharing phase, medical data-sharing platforms \nlike the National Health Information Network (NHIN) in \nthe U.S. have been successfully established. This phase \nprimarily requires identity verification, including user and \ndata authentication for access control, where authentica -\ntion anonymization can also reduce exposure risks. Lastly, \nin the data analysis phase, ensuring the confidentiality of \ndata transmission and computation during machine learn -\ning training and preventing the leakage of training data \nare paramount. [5]\n4.2 National Policies\nRegulations on healthcare data and Al applications vary \nfrom country to country, which creates challenges and \nimposes certain constraints on the use of large language \nmodels in healthcare. For example:\n1. The UK has legislation that clarifies the sharing of \nhuman information: information shared by individuals \nwith professionals should not be used or shared unless the \nindividual understands and agrees to it. National Health \nService legislation covers the confidentiality of certain \napproved research, but patients can opt out of such use to \nprotect their privacy [15, 16].\n2. In Germany, there are more specific regulations for the \nhealthcare sector: doctors and other healthcare profession-\nals are generally prohibited from sharing patient data with \nthird parties without the patient’s consent; breach of the \nduty of professional confidentiality is not only sanctioned \nby the Federal German Medical Association, but also con-\nstitutes a criminal offence; and doctors and healthcare pro-\nfessionals can share health data with “contributors”, such \nas service providers acting for the benefit of and on behalf \nof the healthcare professional, e.g. IT service providers \nor providers of practice management software. Doctors \nand healthcare professionals may share health data with \n“contributors”, e.g. service providers acting for the benefit \n3\nDean&Francis\nof and on behalf of healthcare professionals, such as IT \nservice providers or providers of practice management \nsoftware. [16]\n3. On these bases, France explicitly prohibits patient con -\nsent for the transmission of medical data: patients cannot \nconsent to the transmission of their healthcare data to \nthird parties. The main exception is in the case of second -\nary data processing for research, in which case the organ -\nisation concerned must first obtain authorisation from the \nCNIL (Commission nationale de l’informatique et des \nlibertés). [16]\n4. Japan: A special law on medical big data is enacted in \naddition to the law on the protection of personal informa -\ntion, which defines the rights of the subject, the respon -\nsibility of the subject, and the mode of dissemination of \nmedical and health data. [9]\n5. In Russia, in addition to the laws and regulations re -\nlated to information sharing, there is a clear indication of \ncompliance related to digital innovation: the Law on Ex -\nperimentation in the Field of Digital Innovation specifies \nthat it can be carried out in the field of healthcare [9].\nCurrently in China, the Personal Information Protection \nLaw defines medical and health information as sensitive \npersonal information to be protected, adopts strict pro -\ntection measures and sufficient purpose necessity, and \nstrengthens processing restrictions and rules, but there are \nstill more legal barriers and blind zones in the application \nof medical and health data.2023 On 11 April 2023, the \nState Office of Internet Information Technology issued the \n“Measures for the Administration of Generative Artificial \nIntelligence Services (Draft for Opinion) “ clarifying that \nwhere personal information is involved, the provider as -\nsumes the legal responsibility of a personal information \nprocessor and fulfils the obligation to protect personal \ninformation. If the training data contains personal infor -\nmation, the consent of the subject of personal information \nshould be obtained. At the same time, the provider as -\nsumes the obligation to protect the user’s input informa -\ntion and usage records in the course of providing services. \nIt shall not illegally retain input information from which \nthe identity of the user can be inferred, shall not conduct \nprofiling based on the user’s input information and usage, \nand shall not provide the user’s input information to oth-\ners.\nBased on the relevant laws and policies of various coun -\ntries, there is also some inspiration for China, such as: \namending the Basic Medical Care and Health Promotion \nLaw to increase the legal norms on the processing and \nutilisation of medical information; formulating a pilot law \non artificial intelligence and digital innovation, creating an \napproval path for the processing of medical data subjects \nor projects; clarifying the conditions and rules for the pro -\ncessing of anonymised data, enriching the legal norms on \nthe utilisation of de-identified data etc [14].\nAt the same time, for the patient-oriented application APP \nor platform (e.g., online intelligent consultation), govern -\nment regulators need to formulate laws and regulations \nfor Internet healthcare and medical data APP sharing in \naccordance with relevant policies and regulations, and es -\ntablish a perfect regulatory mechanism to strictly require \nand review the compliance of APP privacy policy [12].\n4.3 Social attitudes\nThe public attitude towards large language modelling in \nhealthcare involves multiple dimensions such as ethics \nand credibility. Based on the analysis of the three-party \nevolutionary game, patient participation is a crucial part \nof healthcare data sharing, and once patients refuse to \nparticipate, the other two parties will lose the motivation \nto promote healthcare data sharing. For healthcare pro -\nviders, the amount of government penalties and subsidies \nis an important factor that affects their strategic choices, \nand a reasonable amount of penalties and subsidies will \nmotivate them to protect the privacy of medical data more \nactively [6].\n5. Summary\nLarge Language Modelling is a major trend for the future \nand has great potential in a number of fields. In health -\ncare, which is of great significance to human society and \nthe human economy, the wide range of potential applica -\ntions of Large Language Models in healthcare can greatly \nimprove the efficiency and accuracy of both clinical and \nnon-clinical applications in the future. Several compa -\nnies have already launched and continuously improved \ntheir healthcare-specific Large Language Models, which \nare currently focused on intelligent Q&A diagnostics \nfor patients, such as Google’s MedLM and open-source \nDoctor Dignity, etc. In terms of professional testing, there \nare already a number of Large Language Models in use. \nIn terms of professionalism testing, some of them have \nalready generated answers that are better than those of hu-\nman medical experts. However, in addition to the further \nimprovement of the accuracy of the answers of the large \nlanguage model as well as the development of the medical \nfield for the potential data, ethics and other potential pit -\nfalls have not yet been resolved. It is necessary to improve \nnational laws and regulations, to issue clear regulations \non privacy protection and data use for medical data used \nfor large language model training, and to ensure how to \nanonymise and privatise the data, at the same time, if the \nuse of large language models is implemented, the attitude \nof the government departments has a certain leading role \nin the attitude of the society, which needs to be actively \n4\nDean&Francis\npromoted by the public sector.\nReference\n1. DoctorGPT. (n.d.) DoctorGPT. https://doctorgpt.co.in/\n2. GitHub. (2021) Doctor Dignity. https://github.com/llSourcell/\nDoctor-Dignity\n3. Google Cloud. (2023) Use MedLM Models. https://cloud.\ngoogle.com/vertex-ai/docs/generative-ai/medlm/overview?hl=en\n4. Google Research. (2023) Med-PaLM: A Large Language \nModel from Google Research, designed for the medical domain. \nhttps://sites.research.google/med-palm/?hl=zh-cn\n5. Guo, Z., Luo, Y ., Cai, Z., et al. (2021) Overview of Privacy \nProtection Technology of Big Data in Healthcare. Journal of \nFrontiers of Computer Science and Technology, 15: 389-402.\n6. Han, P., Gu, L., Zhang, J. (2021) Research on Willingness to \nShare Medical Data from Perspective of Privacy Protection——\nBased on Tripartite Evolutionary Game Analysis. Journal of \nModern Information, 41:148-158.\n7. HU, J. (2018) Development Framework and Trend Analysis \nof Medical Health AI. Chinese Journal of Health Informatics and \nManagement, 15: 485-491.\n8. Li,J., Dada, A., Kleesiek J., et al. (2023) ChatGPT in \nHealthcare: A Taxonomy and Systematic Review. medRxiv.\n9. Li. X., Ning, S., Akhmetshin. (2023) Legal techniques of the \nutilization of medical big Data in Russia and enlightenment. \nChina Health Law, 31: 54-59.\n10. McKinsey&Company. (2017) Using Artificial Intelligence \nto prevent healthcare errors from occurring. In: Second Global \nMinisterial Summit On Patient Safety.\n11. Xiao, A., Lu, Y ., Wu, J., et al. (2021) Privacy Security \nMechanism of Biomedical Big Data. Computer Applications and \nSoftware, 38: 318-322.\n12. Zhao, Y ., Yan, Z., Shen, Q., et al. (2022) Evaluating Privacy \nPolicy for Mobile Health APPs with Machine Learning. Data \nAnalysis and Knowledge Discovery, 6: 112-126.\n13. Kong, X. (2023) Innovation opportunities and challenges \nof ChatGPT in the medical industry. Zhangjiang Technology \nReview, 2: 68-71.\n14. Xiong, M., Chi, X. (2023) On the security of generative \nlarge language model applications——ChatGPT as example. \nShandong Social Sciences, 5: 79-90.\n15. GOV .UK (2023)Approval standard: confidential patient \ninformation. https://www.gov.uk/government/publications/\naccessing-ukhsa-protected-data/approval-standards-and-\nguidelines-confidential-patient-information\n16. Lamb, S., Tschammler, D., Gottlieb, F., et al. (2023) \nHealth Data in The EU And UK – Regulatory Trends and \nDevelopments. https://www.mwe.com/insights/health-data-in-\nthe-eu-and-uk-regulatory-trends-and-developments/\n17. Powles, J., & Hodson, H. (2017). Google DeepMind and \nhealthcare in an age of algorithms. Health and technology, 7(4), \n351–367. https://doi.org/10.1007/s12553-017-0179-1\n5",
  "topic": "Health care",
  "concepts": [
    {
      "name": "Health care",
      "score": 0.6277292966842651
    },
    {
      "name": "Computer science",
      "score": 0.46409955620765686
    },
    {
      "name": "Patient safety",
      "score": 0.4108608365058899
    },
    {
      "name": "Business",
      "score": 0.3563878536224365
    },
    {
      "name": "Risk analysis (engineering)",
      "score": 0.32454851269721985
    },
    {
      "name": "Political science",
      "score": 0.15791228413581848
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ]
}