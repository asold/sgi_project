{
  "title": "GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate Degradation of Artificial Neural Language Models",
  "url": "https://openalex.org/W4221150160",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5044001204",
      "name": "Changye Li",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A5059027860",
      "name": "David S. Knopman",
      "affiliations": [
        "Mayo Clinic in Arizona"
      ]
    },
    {
      "id": "https://openalex.org/A5000074622",
      "name": "Weizhe Xu",
      "affiliations": [
        "University of Washington"
      ]
    },
    {
      "id": "https://openalex.org/A5071178113",
      "name": "Trevor Cohen",
      "affiliations": [
        "University of Washington"
      ]
    },
    {
      "id": "https://openalex.org/A5111412522",
      "name": "Serguei Pakhomov",
      "affiliations": [
        "University of Minnesota"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2576151354",
    "https://openalex.org/W1962620534",
    "https://openalex.org/W3034256339",
    "https://openalex.org/W2992895046",
    "https://openalex.org/W1973779045",
    "https://openalex.org/W3034718411",
    "https://openalex.org/W2950768109",
    "https://openalex.org/W3038424140",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2527572859",
    "https://openalex.org/W1853705225",
    "https://openalex.org/W2170793844",
    "https://openalex.org/W2027610785",
    "https://openalex.org/W2168415900",
    "https://openalex.org/W2914499113",
    "https://openalex.org/W1991248487",
    "https://openalex.org/W2028471410",
    "https://openalex.org/W3099635335",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W1902674502",
    "https://openalex.org/W3087538850",
    "https://openalex.org/W2145125752",
    "https://openalex.org/W3092292656",
    "https://openalex.org/W3116551730",
    "https://openalex.org/W2939515132",
    "https://openalex.org/W2136914353",
    "https://openalex.org/W2057539091",
    "https://openalex.org/W2948947170",
    "https://openalex.org/W3097109903",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3096912371",
    "https://openalex.org/W4255321144",
    "https://openalex.org/W2583703070",
    "https://openalex.org/W2973154008",
    "https://openalex.org/W3154733264",
    "https://openalex.org/W3037273551"
  ],
  "abstract": "Deep learning (DL) techniques involving fine-tuning large numbers of model parameters have delivered impressive performance on the task of discriminating between language produced by cognitively healthy individuals, and those with Alzheimer's disease (AD). However, questions remain about their ability to generalize beyond the small reference sets that are publicly available for research. As an alternative to fitting model parameters directly, we propose a novel method by which a Transformer DL model (GPT-2) pre-trained on general English text is paired with an artificially degraded version of itself (GPT-D), to compute the ratio between these two models' <i>perplexities</i> on language from cognitively healthy and impaired individuals. This technique approaches state-of-the-art performance on text data from a widely used \"Cookie Theft\" picture description task, and unlike established alternatives also generalizes well to spontaneous conversations. Furthermore, GPT-D generates text with characteristics known to be associated with AD, demonstrating the induction of dementia-related linguistic anomalies. Our study is a step toward better understanding of the relationships between the inner workings of generative neural language models, the language that they produce, and the deleterious effects of dementia on human speech and language characteristics.",
  "full_text": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 1866 - 1877\nMay 22-27, 2022c⃝2022 Association for Computational Linguistics\nGPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate\nDegradation of Artificial Neural Language Models\nChangye Li1, David Knopman2, Weizhe Xu3, Trevor Cohen3, and Serguei Pakhomov4\n1Institute of Health Informatics, University of Minnesota\n2Mayo Clinic, Rochester, MN\n3Biomedical and Health Informatics, University of Washington\n4Pharmaceutical Care and Health Systems, University of Minnesota\n1, 4{lixx3013, pakh0002}@umn.edu\n2{knopman}@mayo.edu\n3{xuweizhe, cohenta}@uw.edu\nAbstract\nDeep learning (DL) techniques involving fine-\ntuning large numbers of model parameters have\ndelivered impressive performance on the task\nof discriminating between language produced\nby cognitively healthy individuals, and those\nwith Alzheimer’s disease (AD). However, ques-\ntions remain about their ability to generalize\nbeyond the small reference sets that are pub-\nlicly available for research. As an alternative\nto fitting model parameters directly, we pro-\npose a novel method by which a Transformer\nDL model (GPT-2) pre-trained on general En-\nglish text is paired with an artificially degraded\nversion of itself (GPT-D), to compute the ratio\nbetween these two models’ perplexities on lan-\nguage from cognitively healthy and impaired in-\ndividuals. This technique approaches state-of-\nthe-art performance on text data from a widely\nused \"Cookie Theft\" picture description task,\nand unlike established alternatives also gener-\nalizes well to spontaneous conversations. Fur-\nthermore, GPT-D generates text with character-\nistics known to be associated with AD, demon-\nstrating the induction of dementia-related lin-\nguistic anomalies. Our study is a step toward\nbetter understanding of the relationships be-\ntween the inner workings of generative neural\nlanguage models, the language that they pro-\nduce, and the deleterious effects of dementia\non human speech and language characteristics.\n1 Introduction\nAlzheimer’s disease (AD) dementia affects every\naspect of cognition, including language use. Over\n50 million people are currently diagnosed with AD\ndementia, and this number is expected to triple by\n2050 (Organization et al., 2017; Patterson, 2018;\nPrince et al., 2016). Furthermore, over half of the\nindividuals living with dementia are undiagnosed\n(Lang et al., 2017). While AD has no known cure,\ntimely diagnosis can prevent or alleviate adverse\noutcomes ranging from anxiety over unexplained\nsymptoms to family discord and catastrophic events\n(Stokes et al., 2015; Boise et al., 1999; Bond et al.,\n2005). However, diagnosis of AD dementia is\ntime-consuming and challenging for patients and\nphysicians alike, and currently relies on patient and\ncaregiver reports, extensive neuropsychological ex-\naminations, and invasive imaging and diagnostic\nprocedures (Patterson, 2018). Automated analysis\nof spoken language can potentially provide accu-\nrate, easy-to-use, safe and cost-effective tools for\nmonitoring AD-related cognitive markers. In par-\nticular, studies have demonstrated that supervised\nmachine learning methods can learn to differenti-\nate accurately between patients with dementia and\nhealthy controls (Fraser et al., 2016; Orimaye et al.,\n2017), with particularly strong performance from\nrecent deep learning (DL) models (Balagopalan\net al., 2020; Roshanzamir et al., 2021). However,\nthe large number of parameters employed in DL\npresents a danger of overfitting to the small datasets\nconcerned, and hinders interpretability of model\npredictions - both critical concerns for clinical artifi-\ncial intelligence applications (Graham et al., 2020).\nAs an alternative to fitting model parameters di-\nrectly, we propose a novel method by which a pre-\ntrained Transformer (Vaswani et al., 2017) model,\nGPT-2 (Radford et al., 2019) is paired with an arti-\nficially degraded version of itself (GPT-D), to com-\npute the ratio of model perplexities on language\nfrom cognitively healthy and impaired individuals.\nWe anticipate that semantic information lost with\ndementia progression may be localized to particu-\nlar layers of a neural language model, and that one\ncan simulate this information loss by systematically\nmodifying parameters in these layers. Specifically,\nwe hypothesize that impairing certain layers of a\nDL model can result in linguistic deficits that are\nalso observed in dementia. We further hypothesize\n1866\nthat unlike prior work fitting model parameters to\nlabeled “Cooke Theft” transcripts, this approach\nwill detect task-agnostic linguistic anomalies, per-\nmitting evaluation of language from casual conver-\nsations. We evaluate these hypotheses by targeting\nindividual layers for induction of dementia-related\nlinguistic anomalies, resulting in a degraded model\n– GPT-D. We then assess the ability of a paired per-\nplexity approach combining GPT-2 with GPT-D\nto identify transcripts from participants with de-\nmentia. In addition, we assess generalization per-\nformance, and consider the extent to which the\nbest-performing degraded model reflects linguis-\ntic anomalies known to occur in AD dementia:\nusage of higher frequency words, and repetitive-\nness. The contributions of this work can be summa-\nrized as follows: a) we develop a novel method for\nautomated detection of dementia-related linguis-\ntic anomalies, involving deliberate degradation of\na pre-trained Transformer model; b) this method\nexhibits state-of-the-art (SOTA) within-set perfor-\nmance for models trained on text alone, and is dis-\ntinguished by its ability to generalize from cogni-\ntive tasks to conversational data; c) the degradation\nprocess induces linguistic anomalies observed in\ndementia in language generated by GPT-D1.\n2 Background\nBuilding on a rich body of evidence that machine\nlearning methods can learn to distinguish between\nlanguage from healthy controls and dementia pa-\ntients (for a review, see Lyu (2018); Petti et al.\n(2020)), recent work leveraging pre-trained Trans-\nformer models has demonstrated improvements in\nperformance over prior approaches. Balagopalan\net al. (2020) fine-tuned the BERT (Devlin et al.,\n2019) model on the training set of the AD Recogni-\ntion through Spontaneous Speech (ADReSS) Chal-\nlenge (Luz et al., 2020), which was developed, in\npart, to address the lack of standardized train/test\nsplits and subset definitions in prior work using\nDementiaBank (Becker et al., 1994) (DB). Bal-\nagopalan et al. (2020) report an accuracy of 83.3%\non the test set, an improvement over machine learn-\ning models with expert-defined features. Perfor-\nmance can also be further boosted by introducing\nmore data from the same picture description task\n(Guo et al., 2021). These findings suggest a promis-\ning direction, as models can be developed without\n1Our code is available at https://github.com/\nLinguisticAnomalies/hammer-nets\nextensive feature engineering. However, additional\ntask-specific data are not always available. DL\nmodels with millions of parameters are vulnerable\nto overfitting with small data sets, which may be\ndifficult to detect as they are hard to interpret.\nHowever, some DL models can be distilled into a\nsingle interpretable feature: language model (LM)\nperplexity (PPL). PPL is a measurement of how\nwell a language sample fits a trained LM. Intu-\nitively, a model trained on language from cogni-\ntively healthy participants should be “surprised” by\nlanguage from participants with dementia, and the\nopposite should also be true. Accordingly, the dif-\nference between the paired perplexities from “cog-\nnitively healthy” and “dementia” language models\nproduces SOTA results on the task of identifying\ntranscripts from participants with dementia (Fritsch\net al., 2019; Cohen and Pakhomov, 2020), effec-\ntively condensing neural network parameters to a\nsingle diagnostically useful feature. Contemporary\ndeep LMs such as GPT-2 are already trained on\nlarge amounts of text, that has presumably been\nauthored predominantly by cognitively healthy in-\ndividuals. The difficulty with leveraging these mod-\nels within the paired perplexity paradigm arises\nfrom the lack of a correspondingly large set of text\nfrom participants with dementia. We negotiate this\ndifficulty by deliberately degrading a Transformer\nmodel to limit its semantic processing capabilities,\nobviating the need for large amounts of dementia-\nspecific training data. We show that the resulting\nmodels can effectively identify transcripts from par-\nticipants with dementia, generalize across language\nsamples and tasks, and generate text with linguistic\ncharacteristics of this condition.\n3 Methods\n3.1 Data\nWe used three publicly available datasets 2: DB,\nADReSS, and the Carolinas Conversation Collec-\ntion (CCC) (Pope and Davis, 2011). Dataset char-\nacteristics are provided in Table 1. DB is a publicly\navailable compendium of manually transcribed au-\ndio recordings of neuropsychological tests admin-\nistered to healthy participants and patients with\ndementia. A detailed description is available in\nBecker et al. (1994). In brief, the tests include a\n2While the data used in this paper are publicly available,\nwe are not able to redistribute any of these data as per Data\nUse agreement with Dementia Bank and the Carolinas Con-\nversation Collection.\n1867\nDataset Dementia Healthy Controls\nN\nparticipants\nMMSE\nMean (SD)\nTranscript\nlength\nMean (SD)\nN\nparticipants\nMMSE\nMean (SD)\nTranscript\nlength\nMean (SD)\nADReSS\ntrain 54 17.1 (5.5) 104 (63) 54 29.1 (1.9) 114 (49)\ntest 24 19.5 (5.4) 95 (47) 24 28.8 (1.5) 120 (72)\nall 78 17.8 (5.5) 101 (58) 78 29 (1.2) 116 (56)\nDB 169 20.2 (4.6) 959 (534) 99 29.1 (1.1) 1085 (556)\nCCC 234 NA 1213 (943) 48 NA 714 (308)\nTable 1: Basic characteristics of datasets\npicture description task from the Boston Diagnos-\ntic Aphasia Examination (Goodglass and Kaplan,\n1983), a widely-used diagnostic test for language\nabnormality detection. In this task, the participants\nare presented with a “Cookie Theft” picture stimu-\nlus (see Figure 4 in Appendix), and are asked to de-\nscribe everything they see occurring in the picture.\nIn other words, DB data are from tasks that were\nexplicitly designed to detect language abnormali-\nties in dementia patients. We restricted the original\nset of 194 participants with any AD diagnosis only\nto those that were assessed as having probable AD,\nresulting in a set of 169 patients and 99 controls.\nThe ADReSS set is a subset of DB, which the con-\ntrols and dementia participants were matched age\nand gender, resulting in a balanced dataset consist-\ning of a total of 156 samples (78 with dementia\nand 78 controls) split into training and testing por-\ntions. Unlike the two preceding datasets derived\nfrom picture description tasks, CCC is a collec-\ntion of 646 transcribed recordings of interviews\nof 48 elderly cognitively normal individuals with\nnon-dementia related chronic conditions, and 234\nindividuals with a diagnosis of dementia. Interview\ntopics vary considerably, and include discussions\nof the participant’s health.\nAdditionally, we used a set of six synthetic\n“Cookie Theft” picture description narratives cre-\nated by Bird et al. (2000) to study the impact of\nsemantic dementia on verb and noun use in pic-\nture description tasks. The transcripts were created\nto manipulate lexical frequency (which is also rel-\nevant in AD dementia, where words with higher\nlexical frequency tend to feature prominently (Al-\nmor et al., 1999)) by first compiling a composite\nbaseline narrative from samples by healthy sub-\njects, and then removing and/or replacing nouns\nand verbs in that baseline with words of higher\nlexical frequency (e.g., “mother” vs. “woman” vs.\n“she”). Lexical frequency was calculated using the\nCelex Lexical Database (LDC96L14) and words\nwere aggregated into groups based on four log fre-\nquency bands (0.5 - 1.0, 1.0 - 1.5, 1.5 - 2.0, 2.5\n- 3.0: e.g., words in the 0.5 - 1.0 band occur in\nCelex more than 10 times per million). We used\nthese synthetic data to help with interpretation of\nthe effects resulting from artificially impairing the\nGPT-2 model.\nWe performed basic pre-processing of transcripts\nin each dataset by which we removed speech ar-\ntifact descriptions and converted non-ASCII char-\nacters to plain text. We also excluded portions\nof transcripts that represented speech that did not\nbelong to the participant.\n3.2 Modeling and Evaluation\nWe evaluated models forclassification performance\nusing the standard ADDReSS train/test splits. We\nthen performed cross-validation of GPT-D models\nto assess the stability of the best-performing con-\nfigurations across folds. For generalization perfor-\nmance, we evaluated how well models trained on\none corpus performed on others. We also assessed\ndifferences in text generation between GPT-2 and\nGPT-D, by estimating repetitiveness and lexical\nfrequency, as well as through salience-based visu-\nalization.\n3.2.1 Artificial Impairment: Locations\nWe experimented with impairing the GPT-2 (small)\nmodel in two locations as illustrated in Figure 1\nwith various portions. We found that impairing\n50% of values in the corresponding location result-\ning in generally better performance, among 25%,\n50%, 75% and 100% impairment. The embedding\nlayer (see (1) in Figure 1) is a 50,257×768 matrix\nwhere each row represents a token in the model’s\nvocabulary. The embedding layer was impaired\nby randomly masking 50% of the rows of of the\nembedding matrix. The self-attention mechanism\n(denoted (2) in Figure 1) was impaired by masking\nthe first 50% of columns in the Value matrix of\nthe concatenated Query-Key-Value matrices. We\n1868\nFigure 1: Impairment locations within the GPT-2 (small) model.\nfound that masking random columns resulted in\nworse performance in preliminary experiments.\nThe self-attention mechanism multiplies vectors\nrepresenting an input sequence by three identically-\nsized matrices, namely Query (Q), Key (K) and\nValue (V) each with dimension ( d) of 768 ×768.\nQ generates a representation of the current token\nwhich is compared with token representations de-\nrived from K, to calculate each token’s influence\non the contextual representation of the current one.\nMultiplying by V generates a semantic representa-\ntion of each token, which is added to the outgoing\nrepresentation of the current token in accordance\nwith this influence. The attention weights are cal-\nculated by Equation 1, and the parameters of the\nmatrices are updated during the training process.\nattention(Q, K, V) =softmax(QKT\n√\nd\nV ) (1)\nThe GPT-2 model’s attention mechanism in each of\nthe 12 decoder layers contains 12 attention heads\nthat are represented as vectors of 64 parameters.\nWe impaired 50% of those parameters of V in var-\nious combinations of attention heads in each de-\ncoder layer by masking them as zeroes. We only\ndid this in V matrices, as their parameters directly\ndetermine the content of the vectors that are passed\non to the subsequent feed-forward layer, while the\nQ and K matrices determine how this content is\nweighted when generating the representations to be\npropagated as weighted sums of vectors that have\nbeen transformed by the Value matrix.\n3.2.2 Artificial Impairment: Patterns\nWe also experimented with three ways of introduc-\ning artificial impairment into the attention mecha-\nnism in single and multiple decoder layers: individ-\nual, cumulative, and combination. The individual\napproach was to simply impair all 12 layers one\nat a time. The cumulative approach consisted of\nimpairing decoder layers sequentially starting with\nthe bottom decoder layer (layer 0) and adding im-\npairment to layers above it one at a time up to\nlayer 11, resulting in total of 12 combinations of\nimpairments. The combination approach consisted\nof impairing all possible combinations of layers,\none combination at a time, resulting in 4096 com-\nbinations. The degraded models were subsequently\nused in combination with the original GPT-2 model\nto calculate the difference and ratio of PPLs be-\ntween these two models on each input transcript.\n3.3 Interpretation of Neural Model Behavior\nClassification Performance: For the paired per-\nplexity approach, we estimated the ratio of model\nPPLs ( PPL GPT-2\nPPL GPT-D\n) for each transcript. These PPLs\nwere averaged for participants with multiple tran-\nscripts. All validation methods commenced with\ncalculating the area under the receiver-operator\ncharacteristic (ROC) curve (AUC). From this, ac-\ncuracy (ACC) was determined at equal error rate\n(EER), a threshold where the false acceptance rate\nand false rejection rate from an ROC curves is\nequal. We also calculated Pearson correlation be-\ntween the ratio in perplexities of the GPT-2 and\nGPT-D models and the MMSE scores where avail-\nable (CORR).We used the original fixed single split\nbetween training and testing data provided by the\ncreators of the dataset to compare our results to\nthose published by others on ADReSS.\nCross-validation Performance: For all datasets\n(including ADReSS), we performed standard cross-\nvalidation by which we split each dataset into dis-\njoint folds and first determined which combination\nof GPT-D attention layers results in best perfor-\nmance on the training portion of each fold and then\ntested that combination on the test portion of the\nfold averaging the AUC, ACC and CORR values\n(if available) across the folds. We selected 5-fold\ncross-validation due to the relatively small size of\nthe ADReSS, DB, and CCC datasets. To ensure\nreproducibility across runs, data folds for cross-\nvalidation were extracted using the KFold method\nfrom the scikit-learn library (Pedregosa et al., 2011)\nwith shuffling and a fixed random seed.\nGeneralization Performance: We tested gen-\n1869\neralizability of the paired perplexity approach by\nevaluating its performance across datasets. We first\ndetermined the best-performing pattern of impair-\nment based on the highest AUC obtained on each\ndataset, and then applied the model impaired with\nthat pattern to the remaining datasets.\nBaseline Models: We compared our model per-\nformance on transcript classification with the pre-\nvious text-only SOTA (Balagopalan et al., 2020),\nwhich was obtained with a 12-layer BERT model\nfine-tuned on the ADReSS training set, and evalu-\nated on the test set. To evaluate the generalization\nperformance, we followed this work’s hyperparam-\neter choices and fine-tuned BERT and DistilBERT\n(Sanh et al., 2019)3, a distilled BERT base model\nthat is compact and more efficient. We fine-tuned\nthese models on the entire ADReSS, DB and CCC\ndatasets separately, then evaluate the three resulting\nmodels on every other set.\nLanguage Generation: To prompt the GPT-2\nand GPT-D models to generate text we utilized\nBird et al.’s synthetic “Cookie Theft” picture de-\nscription narrative that represents a composite of\nnarratives produced by healthy controls. Table 5 (in\nAppendix) illustrates the text generated by GPT-2\nand GPT-D in response to prompt sentences taken\nfrom the synthetic narrative. Both GPT-2 and GPT-\nD models were induced to generate at least 20\nadditional tokens with a beam search (Wiseman\nand Rush, 2016) that keeps the top n hypotheses\n(n = 5in this case) at each time step and eventually\nreturns the sequence of hypotheses that achieved\nthe highest probability after reaching the end-of-\nsequence token. Beam search also works well when\nthe length of output is not predictable, which fits\nthe nature of the language tasks represented by\nthe corpora we tested. However, one of the chal-\nlenges of using beam search for text generation is\nthat it tends to generate repeated words. We added\na penalty for generating repetitive unigrams and\nimplemented the top-p algorithm (Welleck et al.,\n2019) to keep the set of potential words as small as\npossible while the cumulative probability of this set\nis greater than the specific probability p (p = 0.9\nin our case). The penalty was applied equally to\nGPT-2 and GPT-D to avoid potentially biasing one\nof these models to produce more repetitions. Af-\nter the models generated five best predictions for\neach prompt, we chose the first non-empty pair of\n3Available on Huggingface https://huggingface.\nco/transformers/index.html\noutputs from both the GPT-2 and GPT-D models\nas the final result.\nLexical frequency and repetitiveness: Previ-\nous work (Cohen and Pakhomov, 2020) suggests\nthat neural language models are sensitive to lex-\nical frequency. We investigated whether GPT-D\ngenerates content of higher lexical frequency than\nthe GPT-2 model. To compute lexical frequency,\nwe split each generated output into tokens with the\nhelp of the NLTK4. We did not stem the tokens to\navoid increasing lexical frequency by artificially\nmerging different tokens with the same stem. In\naddition to the stopwords provided by NLTK, we\ntreated tokens with following part-of-speech tags\na) PRP (personal pronoun), b) PRP$ (possessive\npronoun), c) WP$ (possessive wh-pronoun), and\nd) EX (existential there) as stopwrods. We also\nadded the n´ t token and tokens starting with ´ to\nthe list of stopwords. Log lexical frequency of each\nqualified generated token was calculated based on\noccurrence in the SUBTLEXus corpus (Brysbaert\nand New, 2009). Tokens that do not appear in\nSUBTLEXus, were removed as out-of-vocabulary\n(OOV) items. To asses the degree of repetition\npresent in the generated text, we calculated the\ntype-to-token ratio (TTR) as the number of word\ntypes divided by the number of word instances.\nSalience Visualization: We used the\ngradient×input saliency proposed in Denil\net al. (2014), as implemented with the ecco5\nPython package for visualization. Saliency is\ndefined as || ▽xi fc(x1:n) · xi||2, which is the\nL2 normalized back-propagated gradient with\nrespect to a) the dot product of the embedding\nvector of all previous input tokens ( x1:n), and b)\nthe model output of token xi (fc(x1:n)), where c\nis the predicted token at time-step i. A previous\nstudy (Serrano and Smith, 2019) found that raw\nattention weights were not interpretable for any\nintermediate representation of a language model.\nInstead, Bastings and Filippova (2020) argued that\nsaliency is the preferred method for interpretability\nas it takes the entire input into account and reveals\nthe relevance of each input token to the next\npredicted token in the sequence.\nTo make the visualizations comparable for the\ntwo models, we repeatedly prompted both mod-\nels with the same input until both models gener-\nated the same token as the prediction. It is worth\n4https://www.nltk.org/\n5https://github.com/jalammar/ecco\n1870\nFigure 2: Effects of artificial impairment on model perplexity in synthetic picture description narratives. Higher\nvalues on the x axis indicate transcripts simulating more advanced disease.\nDataset Combination Impairment Pattern Cumulative Impairment Pattern\nAUC (SD) ACC (SD) r with MMSE (SD) AUC (SD) ACC (SD) r with MMSE (SD)\nADReSS 0.80 (0.06) 0.71 (0.07) -0.52 (0.08) 0.79 (0.02) 0.68 (0.03) -0.51 (0.05)\nDB 0.81 (0.07) 0.76 (0.04) -0.45 (0.06) 0.83 (0.02) 0.73 (0.02) -0.41 (0.14)\nCCC 0.77 (0.04) 0.71 (0.04) – 0.72 (0.04) 0.64 (0.09) –\nTable 2: Five-fold cross-validation results of all possible combination of impairment pattern (masking 50% of value\nmatrix as zeroes) for cumulative and combination methods on ADReSS, DB, and CCC.\nnoting that ecco for visualization supports lim-\nited text generation arguments compared to the\ntransformers package, which we used for lan-\nguage generation task. Consequently, we only used\nthe top-p algorithm currently supported by ecco\nfor our visualizations.\n4 Results\nImpairment Location: The contrast in the ef-\nfects of artificial impairment on the embedding\nand attention layers (locations 1 and 2 in Figure 1,\nrespectively) is illustrated in Figure 2. Impair-\ning embeddings results in a distribution of per-\nplexity values over the range of impairment in\nthe synthetic narratives very similar to that of\nthe GPT-2 model. Impairing attention, however,\nresults in a sharp decrease in PPL on the more\nperturbed narratives (those narratives simulating\nmore impairment), which yields a monotonically\nincreasing step-like function over PPL GPT-2\nPPL GPT-D\nthat\nlends itself well to thresholding for categoriza-\ntion. These results were confirmed by testing on\navailable corpora the discriminative ability of the\npaired perplexity approach by artificially impair-\ning only the embedding layer, which resulted in\nnear-random AUCs (close to 0.5 - data not shown).\nConsequently, in subsequent results we will show\nattention-based models only.\nClassification Performance: For comparison\nwith previous work using the ADReSS dataset, the\nbest training set performance was obtained by im-\npairing 50% of each attention head in layers 0-5,\n6, and 8-9. This pattern achieved an AUC of 0.88\n(ACC = 0.75, CORR = -0.55) on the test split. The\ncumulative impairment method performed slightly\nbetter. Impairing 50% of each attention head in the\nfirst 9 layers resulted in best performance on the\ntraining set, and AUC of 0.89 (ACC = 0.85, CORR\n= -0.64) on the test split. We note that this accuracy\nexceeds the average result reported by Balagopalan\net al. (2020), and approaches the performance of\ntheir best run.\nCross Validation: The results of within-set\ncross-validation are summarized in Table 2. Both\ncombination and cumulative methods had small\nstandard deviations (∼ 0.1) with over or near 0.7\nmean AUC on all sets. Estimates from the paired\nperplexity approach for both methods were neg-\natively correlated with MMSE on the ADReSS (-\n0.52, -0.51) and DB (-0.45, -0.41) sets, respectively.\nThe best performance obtained with the individual\napproach resulted in AUC of 0.66 (ACC: 0.64) with\nimpairment of layer 8 on the DB dataset; AUC of\n0.70 (ACC: 0.66) with impairment of layer 8 on the\nADReSS dataset; and AUC of 0.71 (ACC: 0.63)\nwith impairment in layer 7 on CCC.\nGeneralization: The results of generalization\nevaluation are shown in Table 3. Both cumulative\nand combination methods yielded similar perfor-\nmance on CCC, where both AUC and ACC were\n1871\nTesting dataset\nTraining method ADReSS DB CCC\n(Best pattern:AUC) AUC/ACC AUC/ACC AUC/ACC\nCumulative Impairment Pattern\nADReSS (0-8:0.80) – – 0.77/0.72\nDB (0-4:0.82) – – 0.69/0.68\nCCC (0-2:0.72) 0.70/0.63 0.74/0.63 –\nCombination Impairment Pattern\nADReSS\n(0-6,8:0.80)\n– – 0.76/0.71\nDB (0-6,8:0.80) – – 0.76/0.71\nCCC\n(1-3,5,7,9-11:0.79)\n0.69/0.61 0.72/0.67 –\nFine-tuned BERT\nADReSS – – 0.64/0.63\nDB – – 0.67/0.6\nCCC 0.71/0.66 0.7/0.65 –\nFine-tuned DistilBERT\nADReSS – – 0.67/0.57\nDB – – 0.67/0.6\nCCC 0.65/0.62 0.47/0.45 –\nTable 3: Generalizability of GPT-2/GPT-D approach\ncompared to fine-tuning on BERT and DistilBERT. All\nevaluation metrics are calculated at EER rate. The best-\nperforming pattern and its performance are indicated\nwith parentheses and separated by colon.\nclose to or exceeded 0.7. In contrast, fine-tuning\nBERT and DistilBERT resulted in near-random\nclassification performance on the corresponding\nvalidation dataset. While fine-tuning BERT on con-\nversational discourse samples in CCC and applying\nit to the picture descriptions in ADReSS and DB\ngeneralized well as compared to the paired perplex-\nity approach, it did not generalize in the opposite\ndirection when BERT was fine-tuned on ADReSS\nand DB picture descriptions and applied to conver-\nsations in CCC.\nLanguage Generation: Table 4 reports mean\nlexical frequency estimates for words contained\nin the text generated by GPT-2 and GPT-D mod-\nels. The GPT-D model was induced by using the\nbest-performing patterns of impaired layers deter-\nmined from cumulative and combination methods\nfor pattern selection on the available datasets. Both\nGPT-2 and GPT-D generate ∼ 1 OOV token on\naverage for each prompt. In general, the resulting\nGPT-D model generated text consisting of words\nwith higher lexical frequency than words in the text\ngenerated by the GPT-2 model across all datasets\nand methods, even though some of the differences\nfailed to reach statistical significance. All GPT-D\nmodels also generated more repetitions, evident as\nlower TTRs .\nDataset\n(Pattern)\nLF TTR\nGPT-2 GPT-D GPT-2 GPT-D\nCumulative\nADReSS (0-8) 9.48 9.82* 72% 50%\nDB (0-4) 9.49 9.83* 72% 49%\nCCC (0-2) 9.48 9.54 72% 51%\nCombination\nADReSS/DB\n(0-6,8)\n9.5 9.41 72% 55%\nCCC\n(1-3,5,7,9-11)\n9.45 9.92** 73% 64%\nTable 4: Mean log lexical frequency (LF) and type-\nto-token ratio (TTR) of the generated text. The best-\nperforming pattern is indicated with parentheses. * in-\ndicates p-value < 0.05 and ** indicates p-value < 0.01.\nP-values were obtained with two-sided Welch’s t-test\nSalience Visualization: Figure 3 shows the\nmagnitude of the contribution for each token in\nthe prompt used to initiate text generation to the\nmodel’s prediction of the same token ’the’. The\nweight of the contribution of each token is shown as\na percentage that can be interpreted as the amount\nof contribution the model derives from it. We\nobserve in Figure 3 that impairing GPT-2’s at-\ntention heads leads to the redistribution of the\nmodel’s contribution to the words in the prompt\nwhen making the prediction of the next word.\nFor the GPT-2 model, tokens ’boy’, ’climbed’,\nFigure 3: An informal illustration of differences in contributions of input tokens to generating the word “The”, for\nGPT-2 (top) and GPT-D (bottom) models. Percentages and color represent the degree of contribution.\n1872\nand ’cookies’ contributed more when predicting\n’the’. However, for the GPT-D model those word\ntokens did not clearly stand out as substantially\ncontributing to the prediction in either of these\nexamples. Furthermore, tokens corresponding to\nfunction words (e.g., ’ on’, ’a’ and ’from’) con-\ntributed little to the predictions generated by the\nGPT-2 model; however, these tokens contributed\nmore for predictions generated by GPT-D model.\nAs evident in the examples in Figure 3, the salience\nof the words in the prompt is much more diffuse\nwhen the GPT-D model is making the prediction\n- i.e. the model is uncertain with respect to what\nit should consider as important. In contrast, for\nthe GPT-2 model the key elements of the “Cookie\nTheft” scenario - ’ cookie’, ’ three-legged\nstool’, ’boy’ - stand out as highly salient. These\nobservations, although informal and qualitative,\nindicate that the impairment of the self-attention\nmechanism in GPT-2 results in a “behavior” resem-\nbling that observed in all stages of AD dementia as\na result of impaired selective attention that in turn\nreduces one’s ability to encode new information\nin episodic memory (see Perry et al. (2000) for a\ncomprehensive review).\n5 Discussion\nOur key findings are as follows. First, we show\nthat the paired perplexity approach using the ratio\nbetween the GPT-2 and GPT-D model perplexi-\nties approaches SOTA performance on ADReSS,\nleveraging GPT-2’s extensive pre-trainingwithout\nrequiring a comparably large data set from demen-\ntia patients. Second, this approach generalizes\nfrom “Cookie Theft” picture description data to ca-\nsual conversation, in contrast to BERT/DistilBERT\nfine-tuning. Finally, artificial impairment of GPT-\n2’s self-attention induces linguistic anomalies ob-\nserved in dementia.\nThe best-performing cumulative pattern for the\nADReSS training set resulted in accuracy of 0.85\nin the test set, exceeding the best BERT results re-\nported on this test set (x ACC = 0.833 (Balagopalan\net al., 2020)). However, our approach contrasts\nwith approaches that train or fine-tune language\nmodels using a specific dataset, and test on held-out\ncomponents of the same set. While our approach\ndoes require some labeled data through which to\ndetermine the best-performing layers to impair, our\nresults demonstrate generalization to other datasets\nand populations as well as a different type of dis-\ncourse - spontaneous conversations. GPT-D is re-\nliably less perplexed by dementia-related linguis-\ntic anomalies across all of these sets than GPT-2.\nThis facilitates broader application of the paired\nperplexity approach than was previously possible,\nand suggests our approach is more sensitive to task-\nagnostic dementia-related linguistic anomalies than\nBERT/DistilBERT fine-tuning.\nIn contrast to impairing embeddings or individ-\nual attention layers, the maximum discriminating\neffect was achieved by impairing multiple atten-\ntion layers (either combinatorially or cumulatively),\nwhich is consistent with prior observations that\nTransformer layers encode different syntactic and\nsemantic linguistic features in multiple lower and\nmiddle layers (Jo and Myaeng, 2020; Jawahar et al.,\n2019; Lin et al., 2019). Thus, impairing a single\nlayer may not be enough to achieve the full ef-\nfect. Since both syntactic and semantic context\nis encoded in the Transformer decoder layers we\nexpected to find different patterns of artificial im-\npairment to be most effective in vastly different\ntypes of discourse represented by the DB and CCC\ndatasets; however, we were surprised to find that\nonly impairing the self-attention layers had the de-\nsired effect on the results in contrast to impairing\nembeddings or feed-forward network components.\nThe results presented in Table 4 also align with\npreviously published findings that both neural net-\nworks trained on language produced by participants\nwith dementia, and the lexical-retrieval processes\nof patients affected by this condition are sensitive\nto lexical frequency effects (Cohen and Pakhomov,\n2020; Pekkala et al., 2013). Our results suggest that\nimpairing the self-attention mechanism in a Trans-\nformer artificial neural network may induce similar\nsensitivity to lexical frequency. By impairing the\nattention heads in a GPT-2, we observe significant\ndifferences in lexical frequency and TTR character-\nistics of the text generated by the GPT-2 and GPT-\nD, with the change in TTR ratio indicating that\nGPT-D has a greater tendency to produce repeated\nwords when generating text, just as participants\nwith dementia are more prone to repeat words in\npicture description tasks (Hier et al., 1985).\nIn other previous work on the DB and the\nADReSS datasets, the authors attempted to predict\nindividual MMSE scores in addition to discrimi-\nnating between cases and controls (Yancheva et al.,\n2015; Luz et al., 2020). We could not perform a\ncomparable analysis in the current study on account\n1873\nof focusing on using the paired perplexity measure\nas a single threshold to distinguish between cases\nand controls, While predicting MMSE is not the\nmain focus of our study, we did find negative corre-\nlations between the paired perplexity measures and\nthe MMSE scores, providing additional evidence\nthat artificially impairing the attention mechanism\nof the GPT-2 model simulates cognitive effects of\ndementia detectable in language.\nOur findings are also consistent with previous\nwork indicating that Transformer models are able to\npredict neural responses during language compre-\nhension and generalize well across various datasets\nand brain imaging modalities (Schrimpf et al.,\n2021). Thus, our work is another step in the di-\nrection of achieving better understanding of the\nrelationship between the inner workings of gen-\nerative artificial neural language models and the\ncognitive processes underlying human language\nproduction. Impairing how contextual informa-\ntion is stored in the self-attention mechanism in\nsilico creates similar deficits to what is observed\nin dementia. The next important step is perhaps to\ninvestigate how contextual information encoding is\nimpaired in vivo in AD dementia.\nThe encouraging results on the CCC dataset\npoint to the possibility of developing a tool for\nanalysing patients’ daily spontaneous conversa-\ntions in a task-agnostic fashion. Generalizable\nacross tasks and domains and easy-to-interpret\nlanguage-based instruments for detecting anoma-\nlies potentially consistent with dementia can be\nmost useful in clinical situations where the pa-\ntient or family member raise a concern about unex-\nplained changes in cognition. A simple to adminis-\nter (or self-administer) language-based instrument\nfor objective confirmatory testing (either at a single\npoint in time or over a period of time) would be\nhelpful to a clinician working in an overburdened\nand time-constrained clinical environment (e.g., pri-\nmary care) to be able to validate or refute those cog-\nnitive concerns with added confidence. It is critical,\nhowever, that the instrument used for confirmatory\ntesting makes as few assumptions as possible re-\ngarding the person’s linguistic background or com-\nmunicative style, or the type of discourse used for\nanalysis (i.e., picture description vs. conversation).\nThe work presented here has several limitations.\nThe sizes of the datasets are small compared to\nthose typically encountered in open domain NLP\ntasks. In this paper, we did not focus on mild\ncognitive impairment but acknowledge that it is\nan important and active area of research that has\nshown promise in detecting early signs of dementia\n(Roark et al., 2011; Satt et al., 2014; Calzà et al.,\n2021). Also, all datasets are in American English,\nwhich could limit the applicability of our models\nto dementia-related differences in other forms of\nEnglish, and would certainly limit their applica-\nbility to other languages. In addition, behavioral\ncharacteristics including language anomalies can\narise as a result of deficits in multiple brain mecha-\nnisms and, while they can contribute to a diagno-\nsis of a neurodegenrative condition as a screening\ntool, they cannot be used in isolation to establish a\ndefinitive diagnosis. While GPT-D resembles lan-\nguage behaviors commonly observed in dementia\npatients, GPT-2 and GPT-D should not be consid-\nered as accurate and comprehensive representations\nof human language and cognition, or as models\nthat capture features specific to various forms of\nneurodegeneration. Lastly, we also notice that the\npre-trained LM is heavily gender-biased, a problem\nthat we hope ongoing efforts to improve the fair-\nness of AI (e.g. (Sheng et al., 2020)) will address\nover time.\n6 Conclusion\nWe developed a novel approach to automated de-\ntection of linguistic anomalies in AD, involving\ndeliberately degrading a pre-trained Transformer,\nwith SOTA performance on the ADReSS test set,\nand generalization to language from conversational\ninterviews. This, and the detection of dementia-\nrelated linguistic characteristics in text generated\nby GPT-D, suggests that our method is sensitive\nto task-agnostic linguistic anomalies in dementia,\nbroadening the scope of application of methods for\nautomated detection of dementia beyond language\nfrom standardized cognitive tasks.\nAcknowledgement\nThis research was supported by grants from the\nNational Institute on Aging (AG069792) and Ad-\nministrative Supplement (LM011563-S1) from the\nNational Library of Medicine\nResponsible NLP Research\nWe followed the Responsible NLP Research check-\nlist and ACL code of ethics for this work.\n1874\nReferences\nAmit Almor, Daniel Kempler, Maryellen C MacDonald,\nElaine S Andersen, and Lorraine K Tyler. 1999. Why\ndo alzheimer patients have difficulty with pronouns?\nworking memory, semantics, and reference in com-\nprehension and production in alzheimer’s disease.\nBrain and language, 67(3):202–227.\nAparna Balagopalan, Benjamin Eyre, Frank Rudzicz,\nand Jekaterina Novikova. 2020. To bert or not to bert:\nComparing speech and language-based approaches\nfor alzheimer’s disease detection. Proc. Interspeech\n2020, pages 2167–2171.\nJasmijn Bastings and Katja Filippova. 2020. The ele-\nphant in the interpretability room: Why use attention\nas explanation when we have saliency methods? In\nProceedings of the Third BlackboxNLP Workshop\non Analyzing and Interpreting Neural Networks for\nNLP, pages 149–155, Online. Association for Com-\nputational Linguistics.\nJT Becker, F Boller, OL Lopez, J Saxton, and KL Mc-\nGonigle. 1994. The natural history of alzheimer’s\ndisease. description of study cohort and accuracy of\ndiagnosis. Archives of neurology, 51(6):585–594.\nHelen Bird, Matthew A Lambon Ralph, Karalyn Pat-\nterson, and John R Hodges. 2000. The rise and fall\nof frequency and imageability: Noun and verb pro-\nduction in semantic dementia. Brain and language,\n73(1):17–49.\nLinda Boise, Richard Camicioli, David L. Morgan, Ju-\nlia H. Rose, and Leslie Congleton. 1999. Diagnosing\nDementia: Perspectives of Primary Care Physicians.\nThe Gerontologist, 39(4):457–464.\nJ. Bond, C. Stave, A. Sganga, O. Vincenzino,\nB. O’connell, and R. L. Stanley. 2005. Inequali-\nties in dementia care across europe: key findings of\nthe facing dementia survey. International Journal of\nClinical Practice, 59(s146):8–14.\nMarc Brysbaert and Boris New. 2009. Moving beyond\nkuˇcera and francis: A critical evaluation of current\nword frequency norms and the introduction of a new\nand improved word frequency measure for american\nenglish. Behavior research methods, 41(4):977–990.\nLaura Calzà, Gloria Gagliardi, Rema Rossini Favretti,\nand Fabio Tamburini. 2021. Linguistic features and\nautomatic classifiers for identifying mild cognitive\nimpairment and dementia. Computer Speech & Lan-\nguage, 65:101113.\nTrevor Cohen and Serguei Pakhomov. 2020. A tale\nof two perplexities: Sensitivity of neural language\nmodels to lexical retrieval deficits in dementia of\nthe Alzheimer’s type. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 1946–1957, Online. Association\nfor Computational Linguistics.\nMisha Denil, Alban Demiraj, and N. D. Freitas. 2014.\nExtraction of salient sentences from labelled docu-\nments. ArXiv, abs/1412.6815.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nKathleen C Fraser, Jed A Meltzer, and Frank Rudzicz.\n2016. Linguistic features identify alzheimer’s disease\nin narrative speech. Journal of Alzheimer’s Disease,\n49(2):407–422.\nJulian Fritsch, Sebastian Wankerl, and Elmar Nöth.\n2019. Automatic diagnosis of alzheimer’s disease\nusing neural network language models. In ICASSP\n2019-2019 IEEE International Conference on Acous-\ntics, Speech and Signal Processing (ICASSP), pages\n5841–5845. IEEE.\nHarold Goodglass and Edith Kaplan. 1983. Boston diag-\nnostic aphasia examination booklet. Lea & Febiger.\nSarah A Graham, Ellen E Lee, Dilip V Jeste, Ryan\nVan Patten, Elizabeth W Twamley, Camille Nebeker,\nYasunori Yamada, Ho-Cheol Kim, and Colin A Depp.\n2020. Artificial intelligence approaches to predicting\nand detecting cognitive decline in older adults: A\nconceptual review. Psychiatry research, 284:112732.\nYue Guo, Changye Li, Carol Roan, Serguei Pakhomov,\nand Trevor Cohen. 2021. Crossing the “cookie theft”\ncorpus chasm: Applying what bert learns from out-\nside data to the adress challenge dementia detection\ntask. Frontiers in Computer Science, 3:26.\nDaniel B Hier, Karen Hagenlocker, and Andrea Gellin\nShindler. 1985. Language disintegration in dementia:\nEffects of etiology and severity. Brain and language,\n25(1):117–133.\nGanesh Jawahar, Benoît Sagot, and Djamé Seddah.\n2019. What does BERT learn about the structure of\nlanguage? In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics,\npages 3651–3657, Florence, Italy. Association for\nComputational Linguistics.\nJae-young Jo and Sung-Hyon Myaeng. 2020. Roles and\nutilization of attention heads in transformer-based\nneural language models. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 3404–3417, Online. Association\nfor Computational Linguistics.\nLinda Lang, Angela Clifford, Li Wei, Dongmei Zhang,\nDaryl Leung, Glenda Augustine, Isaac M Danat,\nWeiju Zhou, John R Copeland, Kaarin J Anstey, and\nRuoling Chen. 2017. Prevalence and determinants of\nundetected dementia in the community: a systematic\n1875\nliterature review and a meta-analysis. BMJ Open,\n7(2).\nYongjie Lin, Yi Chern Tan, and Robert Frank. 2019.\nOpen sesame: Getting inside BERT’s linguistic\nknowledge. In Proceedings of the 2019 ACL Work-\nshop BlackboxNLP: Analyzing and Interpreting Neu-\nral Networks for NLP, pages 241–253, Florence, Italy.\nAssociation for Computational Linguistics.\nSaturnino Luz, Fasih Haider, Sofia de la Fuente, Davida\nFromm, and Brian MacWhinney. 2020. Alzheimer’s\ndementia recognition through spontaneous speech:\nThe ADReSS Challenge. In Proceedings of INTER-\nSPEECH 2020, Shanghai, China.\nGang Lyu. 2018. A review of alzheimer’s disease classi-\nfication using neuropsychological data and machine\nlearning. In 2018 11th International Congress on Im-\nage and Signal Processing, BioMedical Engineering\nand Informatics (CISP-BMEI), pages 1–5. IEEE.\nWorld Health Organization et al. 2017. Global action\nplan on the public health response to dementia 2017–\n2025.\nSylvester O Orimaye, Jojo SM Wong, Karen J Golden,\nChee P Wong, and Ireneous N Soyiri. 2017. Pre-\ndicting probable alzheimer’s disease using linguis-\ntic deficits and biomarkers. BMC bioinformatics,\n18(1):34.\nChristina Patterson. 2018. World alzheimer report 2018:\nThe state of the art of dementia research:new fron-\ntiers.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\nR. Weiss, V . Dubourg, J. Vanderplas, A. Passos,\nD. Cournapeau, M. Brucher, M. Perrot, and E. Duch-\nesnay. 2011. Scikit-learn: Machine learning in\nPython. Journal of Machine Learning Research ,\n12:2825–2830.\nSeija Pekkala, Debra Wiener, Jayandra J. Himali,\nAlexa S. Beiser, Loraine K. Obler, Yulin Liu, Ann\nMcKee, Sanford Auerbach, Sudha Seshadri, Philip A.\nWolf, and Rhoda Au. 2013. Lexical retrieval in dis-\ncourse: An early indicator of alzheimer’s dementia.\nClinical Linguistics & Phonetics , 27(12):905–921.\nPMID: 23985011.\nRichard J Perry, Peter Watson, and John R Hodges.\n2000. The nature and staging of attention dysfunc-\ntion in early (minimal and mild) alzheimer’s disease:\nrelationship to episodic and semantic memory impair-\nment. Neuropsychologia, 38(3):252–271.\nUlla Petti, Simon Baker, and Anna Korhonen. 2020. A\nsystematic literature review of automatic alzheimer’s\ndisease detection from speech and language. Journal\nof the American Medical Informatics Association ,\n27(11):1784–1797.\nCharlene Pope and Boyd H Davis. 2011. Finding a bal-\nance: The carolinas conversation collection. Corpus\nLinguistics & Linguistic Theory, 7(1).\nMartin Prince, Adelina Comas-Herrera, Martin Knapp,\nMaëlenn Guerchet, and Maria Karagiannidou. 2016.\nWorld alzheimer report 2016: improving healthcare\nfor people living with dementia: coverage, quality\nand costs now and in the future.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nBrian Roark, Margaret Mitchell, John-Paul Hosom,\nKristy Hollingshead, and Jeffrey Kaye. 2011. Spo-\nken language derived measures for detecting mild\ncognitive impairment. IEEE Transactions on Audio,\nSpeech, and Language Processing, 19(7):2081–2090.\nAlireza Roshanzamir, Hamid K. Aghajan, and\nMahdieh Soleymani Baghshah. 2021. Transformer-\nbased deep neural network language models for\nalzheimer’s disease risk assessment from targeted\nspeech. BMC Medical Informatics and Decision\nMaking, 21.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2019. Distilbert, a distilled version\nof bert: smaller, faster, cheaper and lighter. arXiv\npreprint arXiv:1910.01108.\nAharon Satt, Ron Hoory, Alexandra König, Pauline\nAalten, and Philippe H Robert. 2014. Speech-based\nautomatic and robust detection of very early dementia.\nIn Fifteenth Annual Conference of the International\nSpeech Communication Association.\nMartin Schrimpf, Idan Asher Blank, Greta Tuckute, Ca-\nrina Kauf, Eghbal A Hosseini, Nancy Kanwisher,\nJoshua B Tenenbaum, and Evelina Fedorenko. 2021.\nThe neural architecture of language: Integrative mod-\neling converges on predictive processing. Proceed-\nings of the National Academy of Sciences, 118(45).\nSofia Serrano and Noah A. Smith. 2019. Is attention in-\nterpretable? In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics,\npages 2931–2951, Florence, Italy. Association for\nComputational Linguistics.\nEmily Sheng, Kai-Wei Chang, Prem Natarajan, and\nNanyun Peng. 2020. Towards Controllable Biases in\nLanguage Generation. In Findings of the Association\nfor Computational Linguistics: EMNLP 2020, pages\n3239–3254, Online. Association for Computational\nLinguistics.\nLaura Stokes, Helen Combes, and Graham Stokes. 2015.\nThe dementia diagnosis: a literature review of infor-\nmation, understanding, and attributions. Psychogeri-\natrics, 15(3):218–225.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems, volume 30. Curran Associates, Inc.\n1876\nSean Welleck, Ilia Kulikov, Stephen Roller, Emily Di-\nnan, Kyunghyun Cho, and Jason Weston. 2019. Neu-\nral text generation with unlikelihood training. arXiv\npreprint arXiv:1908.04319.\nSam Wiseman and Alexander M. Rush. 2016. Sequence-\nto-sequence learning as beam-search optimization.\nIn Proceedings of the 2016 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1296–1306, Austin, Texas. Association for Computa-\ntional Linguistics.\nMaria Yancheva, Kathleen C. Fraser, and Frank Rudz-\nicz. 2015. Using linguistic features longitudinally\nto predict clinical scores for alzheimer’s disease and\nrelated dementias. In SLPAT@Interspeech.\nAppendix\nFigure 4: Cookie Theft picture stimulus.\nBird TranscriptSentence GPT-2 Model OutputGPT-D Model Output\nThere are twochildren and theirmother in thekitchen.\nOne of them is a littlegirl, but she’s not verygood at math or scienceso I don’t really knowwhat to do with her.\nThis is not a child, butthey have no one par-ent’s daughter or son ofsister to father? brotherfamily home with par-ents who can’t let meknow that I am sorryfor my mommy babydaddy if you’re justlove them so much likeit was good old timewhen we were talkingabout how many times\nThe little boy hasclimbed up, on athree legged stoolto get some cookiesfrom the jar in thecupboard.\nI’m so glad you’rehere, he says as we sitdown at his kitchentable and watch himplay with one ofour favorite treats:chocolate chip cookiedoughnuts! Oh mygosh! I say excitedlybefore turning backaround for anotherbite that will make mefeel good about what’sbeen happening thiswhole time...\nI don’t know how doyou like it’s what isso good for kids loveme and they’re all i’mnot sure no one dayof year after years agowhen people say ’I’vebeen there was neverever again were al-ways will be back thennext time we got intomy mom said she toldher mother would tellthem about their fa-vorite thing that cameout at nighttime beforeschool started sayingYou can go home nowor maybe even if yourdad says he’ll give him\nTable 5: Text generation examples by GPT-2 (small)\ncompared to GPT-D created by the cumulative method\nof impairing the first 50% attention heads of the first 9\nlayers.\n1877",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.6827714443206787
    },
    {
      "name": "Computer science",
      "score": 0.6295239925384521
    },
    {
      "name": "Language model",
      "score": 0.6131671071052551
    },
    {
      "name": "Task (project management)",
      "score": 0.5728443264961243
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5515119433403015
    },
    {
      "name": "Generative grammar",
      "score": 0.5408966541290283
    },
    {
      "name": "Artificial neural network",
      "score": 0.5353990197181702
    },
    {
      "name": "Dementia",
      "score": 0.49111244082450867
    },
    {
      "name": "Natural language processing",
      "score": 0.474178671836853
    },
    {
      "name": "Linguistics",
      "score": 0.33590757846832275
    },
    {
      "name": "Disease",
      "score": 0.09930530190467834
    },
    {
      "name": "Engineering",
      "score": 0.08549019694328308
    },
    {
      "name": "Medicine",
      "score": 0.07619452476501465
    },
    {
      "name": "Pathology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}