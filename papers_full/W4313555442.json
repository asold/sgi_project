{
  "title": "Transformer-Based Named Entity Recognition on Drone Flight Logs to Support Forensic Investigation",
  "url": "https://openalex.org/W4313555442",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4293986234",
      "name": "Swardiantara Silalahi",
      "affiliations": [
        "Sepuluh Nopember Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2195557255",
      "name": "Tohari Ahmad",
      "affiliations": [
        "Sepuluh Nopember Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2016595835",
      "name": "Hudan Studiawan",
      "affiliations": [
        "Sepuluh Nopember Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2250539671",
    "https://openalex.org/W3104415840",
    "https://openalex.org/W3089572139",
    "https://openalex.org/W3016415057",
    "https://openalex.org/W3167698676",
    "https://openalex.org/W2606197117",
    "https://openalex.org/W6769607603",
    "https://openalex.org/W3204102400",
    "https://openalex.org/W6757053875",
    "https://openalex.org/W6788396977",
    "https://openalex.org/W3107481784",
    "https://openalex.org/W2753992460",
    "https://openalex.org/W2908104715",
    "https://openalex.org/W3021157052",
    "https://openalex.org/W3157029757",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W3013748100",
    "https://openalex.org/W6768851824",
    "https://openalex.org/W6766673545",
    "https://openalex.org/W6769218706",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2963925437",
    "https://openalex.org/W2964110616",
    "https://openalex.org/W3102295886",
    "https://openalex.org/W3164476182",
    "https://openalex.org/W6640362995",
    "https://openalex.org/W6749029207",
    "https://openalex.org/W6780226713",
    "https://openalex.org/W6687483927",
    "https://openalex.org/W2594833348",
    "https://openalex.org/W3011614823",
    "https://openalex.org/W2920365235",
    "https://openalex.org/W6636510571",
    "https://openalex.org/W2963103350",
    "https://openalex.org/W3214678605",
    "https://openalex.org/W4220855240",
    "https://openalex.org/W4224267366",
    "https://openalex.org/W4225298476",
    "https://openalex.org/W2970374239",
    "https://openalex.org/W3013136547",
    "https://openalex.org/W3165688004",
    "https://openalex.org/W4250166233",
    "https://openalex.org/W3177277015",
    "https://openalex.org/W2964377765",
    "https://openalex.org/W4223550225",
    "https://openalex.org/W3138945738",
    "https://openalex.org/W2743858238",
    "https://openalex.org/W1902237438",
    "https://openalex.org/W6723250868",
    "https://openalex.org/W3196088075",
    "https://openalex.org/W6679434410",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W6752324926",
    "https://openalex.org/W2904442979",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2983180560",
    "https://openalex.org/W2792643794",
    "https://openalex.org/W2903655746",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W4294635415",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2980826163",
    "https://openalex.org/W2133564696",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3121457173",
    "https://openalex.org/W1940872118",
    "https://openalex.org/W2965373594"
  ],
  "abstract": "The increase in drone usage by the public brings the number of drone incident and attack up. Sophisticated preventive mechanisms, as well as post-incident procedures and frameworks, are needed. Forensic investigation is performed upon a drone incident, aiming to uncover the incident scenario, mitigate the risk and report the examination results. Generally, standard drone forensic procedure consists of three stages, i.e., evidence acquisition, evidence analysis, and reporting. Among the existing research, many attempts have been made in framework proposal and evaluation, study case, and tools proposal and evaluation. However, less research focuses on utilizing specific data artifacts from the drone forensic image, such as telemetry, dataflash, and flight log data. Therefore, this research aims to propose the use of log message data to discover and extract some incident-related information using a deep learning-based NLP technique, i.e., named entity recognition using the Transformer. Cosine similarity is proposed as a substitute for dot-product in the self-attention mechanism of the Transformer encoder layer. Additionally, we propose NER architecture built from a mix of several existing methods and report the performance evaluation. We extract the DJI drone forensic image from a publicly available dataset using Autopsy and DJI Phantom Help and collect the decrypted log messages. Six entity types are defined after carefully reading the log message. These entity types are used in the manual annotation process using the IOB2 scheme as the label. The constructed dataset is used to evaluate the proposed model along with several baseline models. The proposed method outperforms the previous baseline model with a 91.348&#x0025; F1 score. Finally, we conclude the experiment and mention several future directions.",
  "full_text": "Received 18 December 2022, accepted 2 January 2023, date of publication 5 January 2023, date of current version 11 January 2023.\nDigital Object Identifier 10.1 109/ACCESS.2023.3234605\nTransformer-Based Named Entity Recognition on\nDrone Flight Logs to Support Forensic\nInvestigation\nSWARDIANTARA SILALAHI\n , (Member, IEEE), TOHARI AHMAD\n, (Member, IEEE),\nAND HUDAN STUDIAWAN, (Member, IEEE)\nDepartment of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya 60111, Indonesia\nCorresponding author: Tohari Ahmad (tohari@if.its.ac.id)\nThis work was supported in part by the Institut Teknologi Sepuluh Nopember (ITS); and in part by the Pendidikan Magister Menuju\nDoktor untuk Sarjana Unggul (PMDSU) Scholarship from the Ministry of Education, Culture, Research and Technology, Indonesia, under\nGrant 1483/PKS/ITS/2022.\nABSTRACT The increase in drone usage by the public brings the number of drone incident and attack\nup. Sophisticated preventive mechanisms, as well as post-incident procedures and frameworks, are needed.\nForensic investigation is performed upon a drone incident, aiming to uncover the incident scenario, mitigate\nthe risk and report the examination results. Generally, standard drone forensic procedure consists of three\nstages, i.e., evidence acquisition, evidence analysis, and reporting. Among the existing research, many\nattempts have been made in framework proposal and evaluation, study case, and tools proposal and\nevaluation. However, less research focuses on utilizing speciﬁc data artifacts from the drone forensic image,\nsuch as telemetry, dataﬂash, and ﬂight log data. Therefore, this research aims to propose the use of log\nmessage data to discover and extract some incident-related information using a deep learning-based NLP\ntechnique, i.e., named entity recognition using the Transformer. Cosine similarity is proposed as a substitute\nfor dot-product in the self-attention mechanism of the Transformer encoder layer. Additionally, we propose\nNER architecture built from a mix of several existing methods and report the performance evaluation.\nWe extract the DJI drone forensic image from a publicly available dataset using Autopsy and DJI Phantom\nHelp and collect the decrypted log messages. Six entity types are deﬁned after carefully reading the log\nmessage. These entity types are used in the manual annotation process using the IOB2 scheme as the label.\nThe constructed dataset is used to evaluate the proposed model along with several baseline models. The\nproposed method outperforms the previous baseline model with a 91.348% F1 score. Finally, we conclude\nthe experiment and mention several future directions.\nINDEX TERMS Digital forensics, drone ﬂight log, drone forensics, log mining, named entity recognition,\ntransformer encoder, conditional random ﬁelds, infrastructure.\nI. INTRODUCTION\nUA V technology’s presence has signiﬁcantly impacted sev-\neral sectors, such as industry, ﬁlm, and advertisement. It can\nbe seen from the increase in the number of consumer drone\nusage in recent years. A survey from Statista [1] states that\nthe shipments of drone consumers reached approximately\n5 million units in 2020 globally. This number is expected to\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Alba Amato\n.\nkeep increasing to 9.6 million delivery in 2030. The increase\nin drone employment in many ﬁelds brings and opens new\nchallenges to secure drone devices. Other than consumer\ndrones, there are other types of drones, i.e., military, terrorist,\nand criminal drones [2]. Any failure, error, or malfunction\nis not tolerated for these types of drones, as in consumer\ndrones. Therefore, it is critical to guarantee the security of the\ndevice. To this end, more sophisticated security and forensic\nprocedures are needed to develop to diminish the risk caused\nby any attack or incident [3].\nVOLUME 11, 2023 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 3257\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nFIGURE 1. An illustration of entity types in a forensic timeline constructed from drone flight log data.\nIn the digital forensic research area, drone forensics is a\nquite new research topic. Generally, it is categorized into\ntwo sub-topics based on the evidence used to perform the\ninvestigation, i.e., digital and physical investigation. Both\ntypes of research aim to ﬁnd relevant information regarding\nthe incident, uncover the attack scenario, and diminish the\nrisk as the effect of an incident [4]. In order to perform a\ndigital forensic investigation, several artifacts can be utilized,\nsuch as image, video, telemetry log, and ﬂight log data. The\nphysical examination aims to achieve several objectives but\nis not limited to identifying any unique identiﬁer, notable\nfeatures, or damages. Secondly, it determines the model and\nclass of the device, along with the capability of the storage\nsystem. Then, it lists the available options to perform extrac-\ntion [5]. On the other hand, digital evidence is analyzed to\nachieve other objectives, such as mapping the link between\nthe components of the UA V , identifying and matching the\nownership to get a suspect user, and obtaining and inferring\nsome information to prove that the device was used to commit\na crime [5].\nWhile the drone is ﬂying, any event that happens to the\ndrone is recorded in a log ﬁle, including the component’s\nstate, such as sensors, motors, GPS, and links. These data are\nstored in telemetry and dataﬂash logs located in the persistent\nstorage attached to the device [6]. Mantas and Patsakis [6]\nhave attempted to utilize telemetry and dataﬂash logs to\nperform drone forensic investigation by performing UA V\nintegrity checks, anomaly detection on the visual ﬂight path,\ncommand veriﬁcation, error reporting, and hardware error\ndetection. GRYPHON is proposed as an open-source tool\nto perform the aforementioned tasks [6]. Previously, DROP,\nas the ﬁrst open-source tool for parsing drone ﬂight log data\nfrom DJI, was proposed to help the process of acquiring the\nplain information encrypted in the proprietary.DAT dan.TXT\nlog ﬁles of the DJI model [7]. Other than that, most of the\ndrone forensic research is a type of study showcase, which\nstarts from a scenario design, data generation and acquisi-\ntion, data analysis, and ﬁnally, reporting. Several references\nare using DJI [8], [9], [10], Cheerson [11], Parrot [4], and\nYuneec [12] model as experimental devices. However, there\nis no attempt to utilize speciﬁc data, in this case, the log\nmessage, to perform a drone forensic investigation. For this\nreason, we propose a deep learning-based Natural Language\nProcessing (NLP) technique to perform information extrac-\ntion from the log message to assist the forensic investigation\nprocess.\nInformation Extraction (IE) is one of the sub-topic in the\nNLP research domain, which aims to infer knowledge from\na lake of text data. There are several steps in performing\ninformation extraction; after data source collection and pre-\nprocessing, Named Entity Recognition (NER) is one of the\ninitial steps in IE [13]. The researcher has taken advantage\nof NER power to recognize and extract mentioned enti-\nties in several domain problems such as agriculture [13],\n[14], biomedical [15], [16], chemical [16], [17], food and\ndietary [14], and cybersecurity [18], [19], [20]. Inspired by\nthe success of NER in those domains, we are motivated to\ninvestigate the usability of NER in the drone forensic domain,\nconsidering the characteristic of the data is unique for every\ndomain speciﬁc. Fig. 1 illustrates a forensic timeline con-\nstructed from the ﬂight log message along with mentioned\nentities within. A well-constructed forensic timeline exposes\nsequential events experienced by a system regarding a partic-\nular security incident [21]. In this research, we use ﬂight log\ndata to construct a forensic timeline that consists of the log\nmessage and the timestamp.\nTo perform NER, two common deep learning mod-\nels can be used, either RNN-based or Transformer-based\nmodels. The latest state-of-the-art include BiLSTM-CRF\nand a pre-trained Transformer-based Language Model. The\nrise of Transformer-based language models (LM) such\nas BERT [22], one of the ﬁrst pre-trained LM models,\nRoBERTa [23] as an optimized version of BERT, Distil-\nBERT [24], a smaller, faster, cheaper, and lighter version of\nBERT and GPT [25], types of pre-trained language model\nthat employs only the decoder part of Transformer architec-\nture are signiﬁcantly impacted the NLP research landscape,\nincluding NER. However, every domain-speciﬁc problem\nhas its own unique problem and data characteristic. In the\ngeneral NER, the common entity types are Organization,\n3258 VOLUME 11, 2023\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nPerson, or Location. The sentence structure follows the natu-\nral language semantics. However, drone ﬂight log messages’\nsentence structure does not necessarily adhere to that of the\nnatural language in public news, for instance. For this reason,\nwe aim to investigate the success of the Transformer-based\ntechnique in recognizing the region of interest in drone ﬂight\nlog messages.\nThe contributions of this paper are summarized as follows.\n1) This research constructs a new NER dataset in the\ndrone forensic domain. To the best of our knowledge,\nthere is no publicly available NER dataset for drone\nforensic problems yet. We identify and propose six\nentity types as the tagset in the annotation process. The\nproposed model achieves a competitive score compared\nto the state-of-the-art methods, with a 91.146% F1\nscore. Yet, one of the scenarios achieves high perfor-\nmance, with a 91.348% F1 score.\n2) This work showcases how to utilize speciﬁc evidence\ndata to perform forensic information extraction to assist\na forensic investigation, including a simple framework\nfor data extraction and annotation.\n3) We propose and investigate cosine similarity as a sub-\nstitutive of dot-product in the self-attention sub-layer\nof the Transformer encoder to model contextual depen-\ndency in a sequence. We also propose a new NER\narchitecture consisting of CNN character embedding,\nBERT word embedding, a Transformer with scaled\ndot-product attention as the encoder, and CRF as the\ndecoder.\nThe paper comprises ﬁve sections. The remainder of this\npaper is as follows. Section II reviews the recent related\nworks on drone forensic research, deep learning for named\nentity recognition, and the use of named entity recogni-\ntion in cybersecurity. The proposed method is elucidated in\nSection III. Section IV explains the experimental results and\nanalysis. We conclude the paper in Section V with several\nfuture directions.\nII. RELATED WORKS\nThe advancement of the Unmanned Aerial Vehicle (UA V),\ncommonly called a drone, followed by a constantly increasing\nnumber of drone usage in society, has brought drone forensic\nresearch to the surface and interested researchers. The case\nstudy-based paper is the most popular among the published\npapers on drone forensics. This section brieﬂy discusses and\nsummarizes the published works related to drone forensics.\nThe following sub-section explains the other researchers’\nworks on employing a deep learning model for named entity\nrecognition. Since our research is a sub-ﬁeld of cybersecurity,\nwe also recap several related attempts at utilizing NER in the\ncybersecurity domain in the last subsection.\nA. DRONE FORENSIC INVESTIGATION\nThe ﬁeld of drone forensics is a relatively recent research\ntopic. The growth and development of Unmanned Aerial\nVehicle (UA V) technologies bring drone forensics subject to\nthe surface and pique the academics’ attention. The case study\nis the type of most drone forensics published research. In this\nresearch category, a forensic examination is performed on a\ndrone device after having a scened ﬂight under a controlled\nenvironment. The procedure starts with the data collection\nstage and ends with the investigation report. Yousef and\nIqbal [10] proposed a series of guidelines to help forensic\ninvestigators conduct forensic investigations using the DJI\nMavic Air drone model. In order to gather the evidence and\nexplain the successfully collected data, various techniques\nare used, which may aid the investigation process. Several\nsimilar studies were done on other drone models, such as the\nYuneec Typhoon model [12], DJI Spark [26], and the DJI\nPhantom [27]. According to those case studies, the drone’s\ncontroller devices stored valuable data that can be compared\nto the other artifacts enabling a correlation study between the\nUA V and the mobile application used to control the drone.\nSome studies also suggest a technical procedure for drone\nforensic inquiry. In order to perform an end-to-end analysis\nfrom the preparation to the reporting of the ﬁndings, ten\nprocedures proposed by Salamh et al. [12] must be followed.\nAnalyzing the encrypted ﬁles is one of the obstacles in\nthe data collection phase. For the DJI models, encrypted\nevidentiary data is a certainty. However, sometimes we have\nno access to the DJI proprietary tools. Therefore, the data\nmust be decrypted without using DJI’s proprietary tool, even\nthough DJI offers a closed-source and paid decryptor tool.\nHence, some studies develop tools to help the researcher and\ninvestigator to conduct a forensic analysis. The DROP (Drone\nOpen source Parser) tool developed by Clark et al. [7] is a\nparser tool for a.DAT ﬁle that can also decrypt the encrypted\nﬁle to obtain the plain data within. Furthermore, DROP can\nlink what the.DAT ﬁle holds and match it with the.TXT ﬂight\nlog ﬁle contents. After successfully decrypting those two\nﬁles, GRYPHON [6] can be used for dataﬂash and telemetry\nlog analysis. The program can perform timeline analysis,\nanalyze ﬂight data to discover an anomaly, map the GPS\ncoordinates, and many other features. Other than the previ-\nously mentioned tools, several other tools were identiﬁed and\ndescribed in a survey conducted by Viswanathan et al. [28].\nAmong the existing tools, Salamh et al. [8] carried out a\ncase study to examine the features of the tools that were\nfound to aid the forensic investigator in selecting the best\nsuitable tools for a particular type of task. In the general\ndigital forensics domain, log2timeline is commonly used to\nconstruct a forensic timeline from log records. The result is\nin.CSV format consisting of log records with corresponding\ntimestamps. Timeline2GUI can be used to parse and analyze\nthe log2timeline output ﬁle’s contents. It offers an automatic\nanalysis that is too complex if conducted manually. It is also\nequipped with sophisticated visualization features to high-\nlight critical information and assist the forensic investigator\nin analyzing, interpreting, and drawing conclusions [29].\nUnderstanding the drone device and its parts is a cru-\ncial step before beginning a forensic investigation [30].\nVOLUME 11, 2023 3259\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nAccordingly, Jain et al. [30] proposed a framework com-\nprising 12 phases. The ﬁrst ﬁve phases were used to locate\nand validate the drone’s sensors and data. The other seven\nsteps were used to analyze physical evidence like ﬁngerprints\nand digital evidence from several sources, such as memory\ncards, ﬂight logs, and network logs. However, the proposed\nframework has not explained the preparation phase in detail.\nTherefore, another framework consisting of four investigative\nphases with a more comprehensive analysis is proposed by\nAl-Dhaqm et al. [3]. One of the primary distinctions of this\nframework is a more extensive preparation phase consisting\nof pre- and post-incident preparation. Pre-incident prepara-\ntion is an important step that is not yet covered in most\nforensic frameworks. This step aims to understand several\npossible indicators of compromise, deﬁne potential forensic\nevidence, and measure a drone device’s forensic readiness\nbefore a ﬂight. The remaining phases, including post-incident\npreparation, data acquisition, and data analysis, are likely the\nsame as the other frameworks but more thorough.\nPhysical and digital evidence is the source of evidence\nused in a forensic investigation. Analyzing these two types\nof evidence require diverse technique. For digital evidence,\ncomputer-assisted tools are needed to read and present the\nevidence in a format that humans can comprehend. Study on\nevidence analysis is dominated by reconstructing and visu-\nalizing the ﬂight path taken by the drone during a ﬂight [5].\nIt is done by utilizing the GPS coordinates recorded in the\nﬂight log and with the help of the CsvView tool. A similar\nstudy conducted by Kumar and Agrawal [31] utilizes GPS\ndata to reconstruct the ﬂight path with three different drone\nmakes as experimental devices. A tool to convert the.TXT\nor.JSON ﬂight log ﬁle from Parrot make drones into a.CSV\nﬁle that is easy to understand, named FlyLog Converter Tool,\nis proposed.\nB. NAMED ENTITY RECOGNITION IN CYBERSECURITY\nNER plays a vital role in the general NLP study as well as in\nthe domain-speciﬁc areas, where it is utilized as an initial task\nthat supports other downstream tasks, such as event extraction\nand relation extraction [32]. The capability of NER to obtain\nvaluable information from text data can faster an information\nextraction process with a more accurate result. The extraction\nis accomplished by processing and recognizing tokens that\nmay be associated with a speciﬁc type of entity [33]. NER\ntask is not a new research topic. There have been many studies\non the development of NER models. The capability of captur-\ning bidirectional relations among words in a sentence posses\nby BiLSTM has been around for many years as the state-of-\nthe-art method in the sequence labeling task. Accompanied\nby a statistical model, CRF, which can maximize the proba-\nbility of a label sequence, has proven to improve the BiLSTM\nperformance [32]. Many more advanced models with a richer\ninput representation obtained from pre-trained word embed-\nding models, such as Word2vec [34], GloVe [35], ELMo [36],\nand BERT [13], improved the BiLSTM-CRF architecture.\nHowever, the presence of Transformer has revolutionized\nmany NLP tasks, including NER. Since the publication, many\nvariants of pre-trained Transformer-based models have been\navailable. The main advantage of the Transformer architec-\nture is that the attention mechanism in the encoder sub-layer\ncan model the context and relation between the words in a\nsentence.\nTENER [37] attempts to utilize the Transformer encoder to\nperform NER by incorporating relative positional encoding to\nmake the model distinguish the direction of a particular con-\ntext. CNN char embedding is added to the embedding vector\nto represent the char-level feature. The proposed architecture\noutperformed the RNN-based state-of-the-art models in the\nbenchmark NER dataset, CoNLL2003. Working with deep\nlearning models is primarily a matter of providing decent\ninput to the neural model. Several efforts have been made\nto increase the performance of the Transformer encoder by\nincorporating more features into the embedding vector of the\nword representation. Instead of solely relying on the word\nembedding as the input source, adding a dictionary feature\nembedding to the input vector can improve the BiLSTM-CRF\nmodel equipped with an attention mechanism [19].\nSupervised-based deep learning models can take advantage\nof the label information attached to the data points in the\ntraining process. Besides updating the weight parameters,\nlabel information can also be injected into the input vector,\nas proposed in LUKE [38], to provide a rich input. An entity-\naware self-attention mechanism is proposed to separate the\ntoken-to-token and token-to-entity context parameter. The\nmasked language model is employed in the pre-training phase\nto predict some random token and entity. LUKE becomes\nthe state-of-the-art for ﬁve well-known entity-related bench-\nmarks, such as CoNLL2003 for NER, Open Entity for entity\ntyping, TACRED for relation classiﬁcation, ReCoRD for\ncloze-style question answering, and SQuAD 1.1 for extrac-\ntive question answering task.\nThe capability of NER to recognize and extract the region\nof interest in unstructured text data has been implemented in\nvarious domains. Several efforts have been made to utilize\nNER in the cybersecurity domain. In a process-aware system,\nvaluable information is stored in log ﬁles and commonly\nwritten in a less human-readable format. Because the records\nare text data in a large size, the researchers use particular\nNLP techniques to process the data and perform analysis\nautomatically.\nOne of the most severe difﬁculties has been dealing with\nthe complexity of cybersecurity data. Different systems and\ndevices generate logs in different formats. No consistent\nname system with numerous acronyms, technical terminol-\nogy, frequent conjunction use, and extensive nesting structure\nare the main challenges in cybersecurity data [33]. The prior\nstate-of-the-art model employed the XBiLSTM-CRF archi-\ntecture to conduct NER on a publicly available cybersecurity\ndataset [18]. The model’s performance was enhanced by the\nconcept of concatenating the word’s vector representation\nwith the Bidirectional Long Short-Term Memory (LSTM)\nlayer output. The Conditional Random Field (CRF) layer is\n3260 VOLUME 11, 2023\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nused to decode the concatenated output since it can determine\nhow the sequence labels relate to one another.\nMost of the work involved in implementing deep learning\nmodels is predominantly spent on ﬁguring out how to prepare\nadequate input representations. Most often, word embedding\ntechniques like GloVe [39], Word2vec [40], BERT [22], and\nELMo [41] are used to learn the input representation. Pre-\ntrained language models, such as BERT and ELMo, can\ngenerate contextualized representational vectors after going\nthrough a pre-trained procedure on a large corpus. Contrary,\nGloVe employs local and global statistics to build a word\nvector, yielding a static lookup dictionary after being trained\non a relatively large corpus. In order to provide additional\ninformation to the word embedding vectors, Gao et al. [19]\ndeveloped a domain-speciﬁc knowledge base and data-driven\nNER system. Additionally, an attention mechanism is utilized\nto apply greater weights to more valuable information in\na sentence. The experiment demonstrates that the designed\nmodel is more capable of identifying rare entities.\nAligning with the rise of the attention-based model,\nZhou et al. [20] suggest further NER system development in\ncybersecurity data using BERT. Instead of taking a random\nword piece to be masked as used in BERT, Whole Word\nMask is employed. Since the masking is applied to the\nentire word rather than at the word-piece level, this masking\nmechanism can cope with cybersecurity data better. This\nsolution addressed the issue of conjunctions being frequently\nused in words like ‘‘buffer-overﬂow’’ or ‘‘man-in-the-middle\nattack,’’ which is one of the main issues in cybersecurity\nNER.\nAmong the published literature, there are still not many\nstudies that speciﬁcally work on examining a particular type\nof drone forensic artifacts, especially the human-readable\nmessage within a drone ﬂight log, as evidence to perform\nforensic analysis. Therefore, we are motivated to utilize the\nlog message and perform information extraction to assist in a\nforensic investigation.\nIII. PROPOSED METHOD\nThe model’s architecture of the proposed model is depicted in\nFig. 2. In this research, we employ the modern deep learning\nmodel, Transformer, to encode and model the dependency\nbetween words in a sentence and perform named entity recog-\nnition in the drone forensic domain. Overall, our proposed\nmethod consists of positional encoding, character embed-\nding, word embedding, encoder, and decoder. We further\nexplain the details in the following sub-sections.\nThe existing studies show that most drone forensic research\nis based on case studies, tool development, and tool testing\nand evaluation. There are presently few studies performing\nanalytics against certain drone data artifacts, speciﬁcally log\nmessage data. Inspired by the success of Transformer-based\nNER model implementation in various domains, including\ncybersecurity, this paper intends to take advantage of NER in\nrecognizing mentioned entities in drone ﬂight log messages.\nIn order to ﬁll the research gap, this work investigates the use\nof information extraction techniques to obtain insight from\nunstructured evidentiary data. The retrieved information is\nexpected can assist the forensic investigator in pinpointing\nthe critical information related to an incident in the ﬂight logs\nfaster.\nA. DATA PREPROCESSING\nDrone ﬂight log data contains a number of columns with\nnumerous information regarding the drone’s condition and\nstate. From those columns, we take the data from the message,\ntip, and warning columns. Not every log entry has a message,\nas the log message is generated and triggered by certain\nevents or incidents. This message contains useful information\nfor the forensic investigator to conduct forensic analysis and\ninvestigation. Therefore, the other columns in the drone ﬂight\nlog message are ignored.\nAfter collecting all the log messages from the ﬂight log\nﬁles, the message is then tokenized to get per token separation\nwithout lowercasing. As observed from the dataset, many\nentities are written in a capital case. To give the model a\nchance to see the difference between upper and lower case,\nwe preserve the original message without converting them to\nlowercase. We tokenize the message by keeping the dot and\ncomma, as these two punctuations play the context separator\nrole in a sentence. We use the Spacy 1 tokenizer to tokenize\nall the messages. The tokenized message is then converted\ninto CoNLL format as a standard NER dataset format. Finally,\nequal-length tokens and labels are fed to the embedding layer\nto obtain a representational vector.\nB. CHARACTER AND WORD-LEVEL EMBEDDING\nNamed entity recognition is part of a long process in the\nInformation Extraction pipeline. NER is the initial step in\nperforming information extraction from text data, which rec-\nognizes the region of interest and mentioned entities in text\ndata or documents [13]. Since neural networks can not deal\nwith text data, the data must be converted into numerical\nvalues. This process is called embedding. There are two levels\nof embedding used in this research, char-level and word-level\nembedding. Char-level embedding is used to tackle the out-\nof-vocabulary problem, which is common in NLP problems.\nTherefore, each character has its own embedding vector.\nCNN [43] and LSTM-based [44] char-level embedding are\ncommon approaches in NER. Besides CNN and LSTM, Ada-\nTrans [37] is also used as the char-level embedding in this\nresearch to provide rich comparisons.\nDespite the parallelism support offered by Transformer\narchitecture, it does not have information about a word’s posi-\ntion in a sentence. However, words in a sentence are arranged\nin sequential order, and the order determines the contextual\ninformation. Thus, positional encoding is used to inject the\nrepresentation of the position of the word. Let t be the index\nposition of a word in a sequence, then f :t ∈N →PEt ∈Rd\nis a deterministic function that maps each index position into\n1https://spacy.io/models\nVOLUME 11, 2023 3261\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nFIGURE 2. (a) Proposed method architecture. (b) Transformer encoder sub-layer [42].\na d dimensional vector, for d ≡0 mod 2. This function is\nformulated in (1), where i is the index of the vector element.\nf (t)i =\n\n\n\nsin\n(\n1\nωi ×t\n)\n, i ≡0 mod 2\ncos\n(\n1\nωi ×t\n)\n, i ≡1 mod 2\n(1)\nωi =100002i/d (2)\nWord embedding is a representational vector used in NLP\ntasks to represent the features in text data. This vector not\nonly contains the features in text data but also mimics the\nbehavior of text data, such as semantics. A well-constructed\nword embedding vector can be used to estimate the similarity\nbetween two words having u and v as the embedding vector\nwith d dimension using cosine similarity [45] as deﬁned\nin (3).\ncos θ = u ·v\n||u||||v|| =\n∑d\ni=1 uivi√∑d\ni=1 u2\ni\n√\n∑d\ni=1 v2\ni\n(3)\nThere are two types of word embedding, static and contex-\ntual embedding. Word2vec [40], fasttext [46] and GloVe [39]\nare the common static embedding. While ELMo [41] and\nBERT [22] are an example of contextual embedding. The\ndifference between static and contextual embedding is in the\nway of the lookup process. Static embedding has a static\ndictionary that maps the word into a vector. Therefore, a word\nwill have exactly one representational vector, no matter what\nthe context is. Contrary, contextual embedding generates a\ndifferent representational vector for each distinct context of a\ncertain word has.\nIn this research, GloVe, E ∈Rdvocab×dglove is used as a static\nembedding, and BERT, Es ∈Rds×dbert is used as the contex-\ntual embedding for sequence s. The ﬁnal embedding vector\nis the concatenation of the positional embedding vector, char-\nlevel features extracted by the AdaTrans, and the pre-trained\nword embeddings GloVe or BERT.\nC. TRANSFORMER ENCODER LAYER\nThe development of research on the topic of natural language\nprocessing reached a signiﬁcant stage after the presence of\nan attention-based deep learning architecture called Trans-\nformer in 2017 [47]. This architecture was ﬁrst introduced by\nthe Google research team for English-German and English-\nFrench translation problems. The ability to understand and\nmodel the language is the main advantage of the Transformer.\nTransformer architecture is divided into two major parts: the\nEncoder and the Decoder. In this study, the only part used was\nthe Encoder. In general, the elements that build the Encoder\nblock include Input Embedding, Positional Encoding, Multi-\nhead Attention, and Feed-forward Networks [42].\nThe attention mechanism in Transformer architecture tries\nto model the way some data in a database system are retrieved.\nPreviously, the attention mechanism was introduced by Bah-\ndanau et al. [48] in 2015 as additive attention, which was\nthen modiﬁed by Luong et al. [49] in 2015 by proposing dot-\nproduct attention. These two papers use language translation\n3262 VOLUME 11, 2023\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nFIGURE 3. (a) The inner structure of the multi-head attention sub-layer. The shadow represents the attention heads arranged in\nparallel. (b) The inner structure of the self-attention mechanism. [42].\nas the experimental case and model contextual learning using\nthe attention mechanism. In the dot-product attention, each\ntoken in the sequence is transformed into three different rep-\nresentational vectors, i.e., query, key, and value, as shown in\nFig. 3. In order to obtain the contextual representation of the\ncurrently processed token, there are ﬁve steps to follow [42].\n1) Project each of the token’s vectors in the sequence into\nthree representational vectors, i.e., q ∈Rdk , k ∈Rdk ,\nand v ∈Rdv . These three vectors are computed by mul-\ntiplying the embedding vector e ∈Rdmodel with three\nweight matrices W q ∈Rdmodel ×dk , W k ∈Rdmodel ×dk ,\nand W v ∈Rdmodel ×dv which randomly initialized.\n2) Take the dot-product between the vector of the current\ntoken qt to each vector of the context token kj in the\nsequence, yields vector st = ⟨st1 st2 st3 ... stj⟩for\nj =1,2,3,..., n, where n is the number of token in\na sequence.\nstj =qt ·kj (4)\n3) Scale the output of the dot-product by dividing it with√\ndk . This is the main difference between Loung’s\nattention with the Vaswani’s attention.\nˆst =st × 1√dk\n(5)\n4) Normalize the scaled dot-product output using soft-\nmax. The output of this step is a probability distribution\nto weigh the v vector as the target context, yielding\na vector wt = ⟨wt1 wt2 wt3 ... wtj⟩. Therefore,∑n\nj=1 wtj =1.\nwtj = exp(ˆstj)∑n\nj=1 exp(ˆstj) (6)\n5) Finally, perform Hadamard Product (⊙) between\nthe probability distribution with the v vector to\nget the weighted value vector, as the weight indicates\nthe amount of attention that exists between the query\nand key vector.\nyt =\nn∑\nj=1\nwtjvj (7)\nVector yt ∈Rdv is the output of the scaled dot-product\nself-attention mechanism, as explained previously, which\ncontains the contextual representation of the current token.\nMathematically, the self-attention score of qt against each of\nkj and vj in a sequence with n number of tokens is formulated\nas (8).\nAttn(qt ,kj,vj) =\nn∑\nj=1\nsoftmax(qt ·kj\n√dk\n)vj (8)\nPractically, the computation of forward propagation in neu-\nral networks is in a matrix multiplication nature. Instead of\ntaking the dot-product between the vectors one by one, the\nVOLUME 11, 2023 3263\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nwhole self-attention mechanism can be wrapped into a single\nmatrix multiplication operation by building Q, K, and V for\nquery, key, and value matrices, respectively. These matrices\nare obtained by multiplying the word embedding matrices of\na sequence Es ∈Rds×dmodel , with the weight matrices W Q ∈\nRdmodel ×dk , W K ∈ Rdmodel ×dk , and W V ∈ Rdmodel ×dv . The\nprojected matrices Q ∈Rds×dk , K ∈Rds×dk , and V ∈Rds×dv\nare the representational matrices for the sequence. Therefore,\nthe self-attention mechanism for a single sequence can be\nformulated as (9).\nAttn(Q,K,V ) =softmax(QKT\n√dk\n)V (9)\nIn the self-attention mechanism, each token has one\nself-attention score against each token in the sequence.\nIt makes the output vector tends to contain only a single\ncontext for each token in the sentence. However, it is pos-\nsible for certain word has several contextual relations with\nmore than one word in the sentence. Therefore, multi-head\nattention comes as a solution to learning several contexts for\neach token, which is modeled in each attention head weight.\nThe attention head is a hyperparameter in Transformer archi-\ntecture. We can set the number of attention heads as needed\nbased on our data and case. In this paper, the sequence length\nis mostly (more than 80%) less than ten words, and the longest\nsequence is 33, so it is less likely that a word has several con-\ntexts in a sequence. To keep the model’s complexity simple,\nthe dk and dv are taken from dmodel/H = 128. Thus, the\ncomplexity of multi-head attention with dk =dmodel/H is\nthe same as a single head with dk =dmodel. The multi-head\nattention mechanism can be formulated in a matrix multi-\nplication operation, as shown in (10), where h denotes the\nattention head, H is the number of the attention head, a is the\nindex of attention head, and W O is a weight matrix for the\nconcatenated output from each attention head.\nMultiHead(Q,K,V ) =Concat(h1,..., hH )W O (10)\nha =Attn(QW Q\na ,KW K\na ,VW V\na ) (11)\nThe W Q\na ∈ Rdmodel ×dk , W K\na ∈ Rdmodel ×dk and W V\na ∈\nRdmodel ×dv matrices are different weight matrices for each\nattention head. In order to obtain the multi-head attention\nscore, the result of each attention head is concatenated, then\nmultiplied by a weight matrix W O ∈ Rhdv×dmodel . The\nresulting matrix is then passed as an input to the next sub-\nlayer, which is a fully-connected layer. The overall multi-head\nattention mechanism is depicted in Fig. 3.\nThe ﬁxed sinusoidal positional encoding proposed in\nTransformer is not representative enough since it only rep-\nresents the distinct position and distance but lacks direction\ninformation. Inspired by the success of bidirectional LSTM,\nTENER incorporates direction-aware positional encoding to\ngive the attention mechanism ability to model which direction\nof a certain context comes from [50] and [51], which is then\ncalled AdaTrans. Therefore, the modiﬁed formula to obtain\nthe attention score between query and key vector is shown\nin (13) [37], where t is the index position of the current\ntoken and j is the index position of the context token. Fixed\nsinusoidal positional encoding PE t in (1) becomes Rt−j in\n(12) to represent the relative positional encoding, and Rt−j ∈\nRdk to make it compatible with the word embedding vector\ndimension. u and v are learnable parameters to give the model\nthe ability to distinguish the representation of et,j and et+1,j\nfrom different distances, and ωi is the same term as (2).\nRt−j =\n[\n... sin\n(t −j\nωi\n)\ncos\n(t −j\nωi\n)\n...\n]T\n(12)\nArel\nt,j =Qt KT\nj +Qt RT\nt−j +uKT\nj +vRT\nt−j (13)\nAttn(Q,K,V ) =softmax(Arel)V (14)\nSeveral attention mechanism modiﬁcations focus on\ninjecting more linguistic features into the embedding vec-\ntor and the attention computation. However, to the best of\nour knowledge, there is no attempt to control the attention\noutput’s behavior yet. Inspired by [52] where cosine is used\nas a normalization function in neural network architecture,\nwe intended to use cosine similarity to normalize the atten-\ntion score. Originally, the output of the attention is scaled\nby √\ndk [42], then fed to the softmax function to get the\nprobability distribution. However, the resulting probability\ndistribution has only one signiﬁcant element, which is then\nused to weigh the context value vector. Thus, the attention\nscore will represent exactly one context only. Multihead\nattention overcomes this issue by projecting the key, query,\nand value vector into several distinct attention heads which\ndo not share their parameters. Since cosine can smoothen the\nprobability distribution from the softmax output, we aim to\ninvestigate the use of cosine normalization as a substitute for\nthe dot-product operation in the self-attention mechanism.\nAs illustrated in Fig. 4, the probability distribution on the\nsmaller scale tends to have several signiﬁcant values com-\npared to the larger one. This slope probability distribution\nwill capture several attention from the context words’ vector.\nAdditionally, from the existing NER architecture, we explore\nseveral possible arrangements to ﬁnd an architecture with the\nbest performance evaluated on our dataset.\nBefore performing matrix multiplication between the key\nand query vector in the self-attention mechanism, our pro-\nposed method ﬁrst divides these two vectors with their\nrespective norm and constructs the matrix back. The modiﬁed\nself-attention mechanism is depicted in Fig. 5. Since (3)\ncan be written in the form of (15), then ˆQ and ˆK are the\nquery, and key matrices constructed from the vectors that\nhave been divided by their respective norm. Consequently,\nwe can fully exploit the optimizable matrix multiplication\noperation as in the vanilla Transformer architecture. Thus,\nthe forward propagation is slightly the same, except for the\nadditional step for dividing the key and query vector by its\nnorm before performing the matrix multiplication. Therefore,\nthe attention score between the query and key vector using\n3264 VOLUME 11, 2023\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nFIGURE 4. Softmax behavior on vectors in different scales.\nFIGURE 5. Cosine-based self-attention mechanism. The respective vector\nnorm is used to scale each row element ofQ and K matrices.\ncosine similarity can be computed using (16).\ncosine(ˆu,ˆv) = u\n||u||· v\n||v|| (15)\nAttn\n(\nqt ,kj,vj\n)\n=\nn∑\nj=1\nsoftmax(cosine(ˆqt ,ˆkj))vj (16)\nThe output of the multi-head attention sub-layer is then\npassed to the Add + Norm sub-layer, as shown in Fig. 2 (b).\nThe term Add in Add + Norm sub-layer means a residual\nconnection [53] between the previous sub-layer output and\nthe current sub-layer output before being propagated to the\nnext sub-layer. This residual connection retains the positional\ninformation from the embedding layer during the computa-\ntion to the upper layer of the architecture. The term Norm\nrefers to LayerNorm [54] to control the value of each sub-\nlayer output. Afterward, the next sub-layer is the Feed For-\nward Network (FFN) which consists of two linear transfor-\nmations with ReLU [55] activation function in between. This\nsub-layer is formulated in (17) as follows:\nFFN(x) =max(0, xW1 +b1)W2 +b2 (17)\nwhere W and b is the weight and bias parameter for each\nlinear layer in FFN, and x is the input vector. The output of\nthis sub-layer is then passed to a linear layer before being\npropagated to the decoder.\nD. CONDITIONAL RANDOM FIELD LAYER\nIn sequence labeling tasks, such as NER, CRF is a com-\nmon method used. According to studies, the Hidden Markov\nModel and the Maximum Entropy Markov Model (MEMM)\nare ineffective at analyzing sentence-level sequences com-\npared to the CRF approach [15]. The main CRF features that\ncan compute cross-position label combination probability\ngrab the researchers’ attention to apply this method to the\nNER problem. Combining the previous state-of-the-art NER\nmodel, BiLSTM, with CRF has proven to improve perfor-\nmance [56]. In this paper, CRF is used as the decoder for\nall encoder combinations in our experiment. For an observed\nsequence x = ⟨x1 x2 ... xn⟩with the corresponding tar-\nget label y = ⟨y1 y2 ... yn⟩, let Y be the set of all valid\nsequence of labels in the dataset. The probability of the pre-\ndicted label from the encoder is computed using (18), where\nf (x,yt−1,yt ,t) is an arbitrary feature function to compute\nthe transition score from yt−1 to yt in the sequence x. Let d\nbe the number of feature functions used, Feat(x, yt−1,yt ,t)\nis the weighted sum of all transition scores from yt−1 to yt in\nthe sequence x from each feature function. After getting all\npossible paths and their corresponding probability, the Viterbi\nalgorithm is used to discover ˆy, which denotes the path with\nthe highest probability, as written in (21).\nP (y |x)=1\nZ exp\n[ n∑\nt=1\nFeat(x,yt−1,yt ,t)\n]\n(18)\nZ =\n∑\n˜y ∈Y\nexp\n[ n∑\nt=1\nFeat(x,˜yt−1,˜yt ,t)\n]\n(19)\nFeat(x,yt−1,yt ,t) =\nd∑\nj=1\nwjfj(x,yt−1,yt ,t) (20)\nˆy =arg max\ny\nP(y |x) (21)\nIV. EXPERIMENTAL RESULT AND ANALYSIS\nIn this section, we give the details of the long process of\ndataset preparation which consists of data collection, decryp-\ntion, extraction, cleansing, entity type identiﬁcation, anno-\ntation rules deﬁnition, data annotation, and train test split-\nting. We then describe the experiment settings we used to\nget the experimental results. Furthermore, we discuss the\nperformance of our proposed method with several attention\nmechanism arrangements. We then compare the performance\nof our proposed method with other baseline models. Finally,\nwe disclose the research challenges and limitations we\nencounter throughout the experiment. The experimental code\nalong with the dataset is available on a GitHub repository. 2\n2https://github.com/swardiantara/droner-cosine\nVOLUME 11, 2023 3265\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nFIGURE 6. Data collection and extraction using Autopsy. The highlighted folders are the location of the flight log files containing human-readable\nmessages.\nA. DATASET PREPARATION\nTo the best of our knowledge, there are no publicly available\nNER datasets in the drone forensic domain yet. For this\nreason, a new dataset is constructed for the experiment in this\npaper. However, there is an open drone forensic image dataset\npublicly available provided by VTO Labs Drone Forensic\nProgram.3 Therefore, the ﬁrst step in dataset preparation was\nthe data extraction process. From the total of 82 drone images\nfrom 10 different models, we choose 60 drone images from\nthree drone models, i.e., DJI, Parrot, and Yunnec, to extract,\nsimply because these three models are the majority among the\navailable models. As of March 2021, DJI had a market share\nof 76%, based on the sale volume. Thus, most of the consumer\nand commercial drones in the market are DJI-made [57].\nThe drone images are stored in several different formats,\nsuch as.ZIP,.001, and.BIN. These images are acquired from\nthe controller devices, which are considered the primary\nevidence close to the owner and contain incident-related\ninformation [58]. After exploring the drone images with the\n3https://www.vtolabs.com/drone-forensics\nhelp of Autopsy 4 and DJI Phantom Help 5 for extracting and\ndecrypting, Autopsy was used to extract the drone images ﬁle\nfrom the Android-based controller with.001 and.BIN exten-\nsions. The Autopsy is also used to decrypt the ﬁles inside\nthe.ZIP ﬁles obtained from the iOS-based controller devices.\nFig. 6 shows the Autopsy interface when extracting a drone\nforensic image acquired from an Android-based controller\ndevice. The green boxes denote the path of the ﬂight log\nﬁles stored. Sometimes, /dji.go.v4/ appear in a different\nfolder name, i.e., /dji.pilot/. Both of the folders possi-\nbly exist at the same time in a single drone forensic image.\nThe only data taken from the drone images were\nhuman-readable log messages in order to perform entity\nrecognition. To ﬁnd this kind of data, we explore the drone\nimages directory, which potentially contains human-readable\nlog data. We found it in the ﬂight log data. Then, we try\nto ﬁnd all the locations of ﬂight log data in all directories\nof every drone image we have downloaded and extracted.\nUnfortunately, we did not ﬁnd the expected data from Yuneec\n4https://www.autopsy.com/\n5https://www.phantomhelp.com/LogViewer/upload/\n3266 VOLUME 11, 2023\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nFIGURE 7. Difference between IOB2 and BIOES annotation scheme for the same log message. The labels are assigned using the contextual tagging\nprocedure.\nTABLE 1. Number of extracted messages from every drone model.\nand Parrot models. Therefore, the only model that contains\nthe data is the DJI. After collecting the ﬂight log ﬁles, we use\nDJI Phantom Help tools to decrypt the ﬁles and get the plain\ndata, which then is parsed to get the log message data. The\nnumber of messages from every drone image is shown in\nTable 1.\nThe next step is identifying the entity type mentioned in\nthe drone log messages. Before reading the log messages,\nwe ﬁltered the duplicate message and got the unique message\nto read. After carefully reading the unique log message and\ncomprehensively studying what every log message indicates,\nwe categorized the entity types mentioned in the ﬂight log\nmessage into six groups, i.e., Component, Action, Parameter,\nFunction, State, and Issue. These entity types are used as\nthe label for every word in a message after performing data\nannotation.\nAnnotation is a process of assigning a label to each data\npoint in order to train a supervised model. In this case, the\nlog message is the data that will be annotated. To demonstrate\nthe power of contextual learning in the Transformer encoder,\ntwo annotation procedures are used to label the data, i.e.,\ncontextual tagging and consistent tagging. Consistent tagging\nrefers to assigning a label to a word by only considering the\ntoken and ignoring the context within the sentence. Contrary,\ncontextual tagging assigns a label to each word in a sentence\nby considering the present context. The following are several\ncriteria for the annotation process on each entity type.\nA ‘‘Component’’ label will be assigned to a span that\nindicates drone components, such as motors, sensors, and\nbatteries. If the span is indicating of an action taken by\nthe drone, then it will be assigned the ‘‘Action’’ label. The\n‘‘parameter’’ label is assigned to the span, which indicates\nsome variables stored in the drone, such as maximum ﬂight\ndistance, maximum ﬂight altitude, and battery temperature.\nEvery drone type has features or functions supporting the\ntask given to it. Some example of span indicates function is\nobstacle avoidance, obstacle sensing, and remote controller\nsettings. This type of span is assigned the ‘‘Function’’ label.\nSome spans indicate a drone’s mode, such as sport mode,\nauto landing mode, and quick shot mode. These spans get the\n‘‘State’’ label. Lastly, the ‘‘Issue’’ label is assigned to a span\nthat indicates ﬂight issues that happen to the drone during a\nﬂight.\nBefore assigning the label to each word, we ﬁrst tokenize\nthe sentence into tokens using tecoholic 6 tools. Then, the\nsame tool is used to perform the data annotation process.\nIOB2 is used as the annotation scheme since IOB2 is one\nof the typical schemes in the NER task [59]. However, the\nBIOES scheme is proven can improve the NER model’s\nperformance [37]. Therefore, after ﬁnishing the annotation\nusing the IOB2 scheme, a python script is used to convert the\nannotation into a BIOES scheme. We manually annotate the\nunique message only by carefully reading the context of the\nsentence ﬁrst. Fig. 7 shows a sample of annotated data using\nthe IOB2 and BIOES scheme in CoNLL format. Sometimes,\na particular span belongs to two or more alternative entity\ntypes’ tags. For this confusing span, we chose the longest\nspan as the context of the mentioned entity. The ‘‘battery\ntemperature’’ span is given the Parameter label for contextual\ntagging. However, for consistent tagging, the Component\nlabel for the word ‘‘battery’’ and the Outside label for the\nword ‘‘temperature’’ is assigned, respectively. Additionally,\nfor the ‘‘battery signal error’’ span, the Issue is assigned for\nthose three tokens considering the context. Nevertheless, con-\nsistent tagging assigns each token the Component, Outside,\nand Issue labels, respectively. After completing the label for\nall unique messages, we do the annotation for all messages\n6https://tecoholic.github.io/ner-annotator/\nVOLUME 11, 2023 3267\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nFIGURE 8. Results of using contextual and consistent tagging procedure on a log message using the IOB2 scheme. The striking difference lies in the\n‘‘Main Controller Settings’’ span.\nTABLE 2. Number of message, token, and entities in the consistent and\ncontextual dataset.\nby using the labeled unique message as a lookup dictionary.\nFig. 8 shows the annotation results using consistent and con-\ntextual tagging procedures.\nAfter completing the annotation process, the dataset is split\ninto train and test sets. Unlike the usual splitting method,\nwe split the dataset based on the drone types. The ﬁrst nine\ndrone models in Table 1 are the train set, while the last four\nare used as the test set. By doing this, the train and test sets are\ngenerated from completely different drone models. Assuming\nthat every model has its own features and functionalities,\nwhich vary among them, then the generated log messages\nwill be different as well. However, since all the drones are\nDJI make, the test set is chosen from the most advanced type\nto make the test set contains log messages that do not exist\nin the train set. Because the features and functionalities in a\nmore advanced model will not be in a less advanced model,\nso do with the generated log messages.\nAs the ﬁnal result of data preparation, the distribution of\nevery entity type in the train and test set of the annotated\ndatasets is shown in Table 2 and Table 3. The ﬁnal composi-\ntion of the dataset is 76:24 for train and test sets, respectively,\nfrom a total of 1850 log messages. The ﬁnal proportion is\nuncontrollable since the splitting is done based on the drone\nmodels instead of directly dividing the message into a certain\ncommon ratio used in existing research.\nB. EXPERIMENT SETTINGS\nThe experiment was conducted using the publicly available\ncode provided by TENER’s original paper [37]. Therefore,\nthe only requirement to install is fastNLP library. 7 We mod-\niﬁed the code to implement the proposed method. While the\nhardware speciﬁcation is as follows: Intel Core i7-8700 @\n3.2GHz, 16GB RAM, NVIDIA GeForce GTX 1060 6GB,\nand Ubuntu 20.04 LTS operating system.\nThe dimension of the input vector is 768, divided into eight\nattention heads with 96 as the dimension for each head and\n7https://fastnlp.readthedocs.io/\nTABLE 3. Per entity type token distribution.\nthree encoder layers in the Transformer architecture. Both\ntrain and test batch size is 8, with a learning rate of 0.001 and\nwith a warm-up step of 0.01. We set the dropout to 0.15 except\nfor the fully-connected layers, which used 0.4. The intermedi-\nate fully-connected layers are sized 1536 dimensions. These\nparameters are inspired by Transformer [42] and TENER [37]\noriginal papers. The number of epochs we used is 50 because\nit has already provided convergence, as shown in Fig. 11.\nThree char-level embeddings, such as LSTM, CNN, and\nAdaTrans, were combined with two word-level embeddings,\nGloVe and BERT, to provide input for the encoder layer.\nIn the Transformer encoder, three different attentions are\nemployed combined with options whether to scale or unscale\nthe attention score in the self-attention mechanism. Finally,\nthe CRF is the only decoder used.\nSeveral scenarios which used BiLSTM as the encoder are\ndesigned for the experiment based on the published reference\nas the baseline methods for comparison. The combination of\narrangements from the available options of word embedding,\nchar embedding, and the attention type are presented in the\nfollowing subsection, along with the results. We freeze the\nBERT embedding to avoid the domination of the attention\nmechanism used in the BERT pretraining phase. Therefore,\nBERT parameters will not be updated during the training.\nWe ran the experiment three times for each scenario and took\nthe average as the ﬁnal evaluation score.\nThe evaluation mechanism used in this experiment is the\nspan-oriented paradigm. It means the predicted tag is eval-\nuated on the entity type level instead of on the tag level.\nTherefore, if the predicted entity type is correct, even if the tag\nis not strictly correct, the predicted token is considered True\nPositive. For example, if the true label is B-Component, while\nthe predicted label is I-Component or vice versa, we count the\npredicted label as True Positive.\nPrecision, Recall, and F1 score are used as the evaluation\nmetrics after counting the true positive (TP), false positive\n3268 VOLUME 11, 2023\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nTABLE 4. Performance evaluation of all scenarios on the dataset\nannotated using consistent tagging with AdaTrans as the char-level\nembedding. The best score is indicated in bold font. BERT and GloVe are\nused as word embedding.\n(FP), and false negative (FN) for each label. Since there are\nseven labels in the dataset with an imbalance proportion,\nwe use the micro-average approach to compute the ﬁnal\nevaluation score. The formula for per entity type precision,\nrecall, and F1 are shown in (22), (23), and (24), respectively,\nwhere c is the entity type, and C is the total number of entity\ntypes exists in the dataset. Micro-average for the precision\nand recall are identical to the per class formula, but the TP, FP,\nand FP are the sum from all classes as in (25) and (26). While\n(27) is used to calculate the micro-average F1 score. For all\nof these evaluation metrics, we used the pre-deﬁned function\nSpanFPreRecMetric in fastNLP library. 8 The εsymbol\nis a small number to avoid division by zero error, while βis a\nterm to weigh between precision and recall in order to obtain\nthe F1 score. In this paper, we use ε=1e −13 and β=1.\npre = TP\nTP +FP +ε (22)\nrec = TP\nTP +FN +ε (23)\nF1 =2 ×(pre ×rec)\npre +rec +ε (24)\npremicro =\n∑C\nc=1 TPc\n∑C\nc=1 TPc +∑C\nc=1 FPc +ε\n(25)\nrecmicro =\n∑C\nc=1 TPc\n∑C\nc=1 TPc +∑C\nc=1 FNc +ε\n(26)\nF1micro =(1 +β) ×premicro ×recmicro\nβ×premicro ×recmicro +ε (27)\nC. RESULTS ON DIFFERENT ANNOTATION RULES\nThis subsection presents all the possible arrangements from\nthe available options of character embedding, word embed-\nding, and attention mechanism. Since two types of datasets\nare constructed, every architectural arrangement is tested on\nthese two datasets. Table 4 to 6 shows the ﬁrst dataset’s eval-\nuation scores, which were annotated using a non-contextual\n8https://fastnlp.readthedocs.io/zh/latest/fastNLP.core.metrics.html\nTABLE 5. Performance evaluation of all scenarios on the dataset\nannotated using consistent tagging with LSTM as the char-level\nembedding. The best score is indicated in bold font. BERT and GloVe are\nused as word embedding.\nTABLE 6. Performance evaluation of all scenarios on the dataset\nannotated using consistent tagging with CNN as the char-level\nembedding. The best score is indicated in bold font. BERT and GloVe are\nused as word embedding.\ntagging procedure. The model with the best performance is\nhighlighted a bold font. The presented scores in the tables\ncontain both proposed and baseline models. Each table rep-\nresents a scenario that is grouped based on the character\nembedding used, as Table 4 shows the models employing\nAdaTrans for extracting character embedding. Subsequently,\nTable5 and 6 show the models’ architecture where LSTM and\nCNN were used as the character embedding, respectively.\nFrom the evaluation score presented in Table 4 to 6, the\nbest performance was achieved by GloVe – Scaled AdaTrans\ncombination with an 87.771% F1 score. AdaTrans atten-\ntion consistently achieves the highest score for all character\nembedding and word embedding options. GloVe outperforms\nthe BERT embedding evaluated on the non-contextual dataset\nfor all scenarios. This is because the ﬁrst dataset has con-\nsistent tagging, meaning that a word has a consistent tag\nfor all different contexts in the dataset. It complies with the\nGloVe behavior, where each word has exactly one representa-\ntional vector. BERT – Scaled Transformer achieved the best\noverall performance for the second dataset with a 91.348%\nF1 score. The annotation procedure in the second dataset\ncomplies with the contextual representation resulting from\nVOLUME 11, 2023 3269\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nTABLE 7. Performance evaluation of all scenarios on the dataset\nannotated using contextual tagging with AdaTrans as the char-level\nembedding. The best score is indicated in bold font. BERT and GloVe are\nused as word embedding.\nBERT embedding, where every word has one representational\nvector for each distinct context in the dataset. This claim\nis supported by the experimental results shown in Table 7\nto 9, where the scenarios that utilized BERT as the word\nembedding outperform the models that employed GloVe as\nthe word embedding. As the dataset annotated using contex-\ntual tagging procedures better represents the semantics of a\nspan, the following subsection discusses only the results of\nthe contextual dataset.\nD. ATTENTION MECHANISM IN COMPARISON\nAn attention-based model has been widely used in NLP\nresearch to model the context between words within a sen-\ntence. In this experiment, we investigate three different atten-\ntion mechanisms to recognize mentioned entities in drone\nlog messages. After conducting an extensive experiment,\nwe obtain the results as shown in Table 4 to 9. The architec-\nture arrangements are inspired by the TENER paper, which\nproposed AdaTrans to extract character-level features and\nincorporate relative positional to the attention layer. How-\never, several scenarios have not been reported yet. There-\nfore, we experiment to ﬁnd the best architecture to use on\nour dataset. The details explanation of every scenario is as\nfollows.\nOverall, the model’s architecture consists of ﬁve layers,\ni.e., positional encoding, char embedding, word embedding,\nencoder, and decoder. Relative positional encoding proposed\nin TENER is used to reproduce the AdaTrans’ unexplored\nscenarios. To obtain character-level embedding, either CNN,\nLSTM, or AdaTrans is utilized in every scenario as listed\nin Table 7 to 9. For the pre-trained word embedding, either\nGloVe or BERT is used to obtain the words’ vector repre-\nsentation. Unscaled attention is reported to be better used in\nNER since mentioned entities commonly consist of a few\nwords only [37]. Thus we experiment with every attention\ntype with the scaled and unscaled scenario in the encoder\nlayer, including the AdaTrans encoder. The employment of\nCRF can undoubtedly improve the performance of a NER\nTABLE 8. Performance evaluation of all scenarios on the dataset\nannotated using contextual tagging with LSTM as the char-level\nembedding. The best score is indicated in bold font. BERT and GloVe are\nused as word embedding.\nTABLE 9. Performance evaluation of all scenarios on the dataset\nannotated using contextual tagging with CNN as the char-level\nembedding. The best score is indicated in bold font. BERT and GloVe are\nused as word embedding.\nmodel [56]. Thus CRF is used as the decoder for all scenarios\narrangements.\nThe CNN-BERT-Scaled Transformer outperforms the\nother scenario with a 91.348% F1 score. This score is slightly\nhigher than the unscaled Transformer. We assume this slight\ndifference is because of the dataset size, so the effect of either\nusing scaling or not is insigniﬁcant. The AdaTrans-based\nencoder is considered a baseline model, which will be dis-\ncussed in the following subsection. Our proposed model that\nuses cosine similarity instead of dot-product operation in\nthe self-attention mechanism underperforms the Transformer\nwith a competitive F1 score of 91.146%. This shows that the\ncosine similarity is able to model the context between words\nin a sentence, just like the dot-product intuition in the self-\nattention mechanism.\nThe presence of contextual pre-trained word embedding\nhas positively impacted NLP research recently. The main\nadvantage of contextual over static pre-trained word embed-\nding is the ability to generate a unique representational\nvector of a word for each distinct context within two or\nmore different sentences. In this experiment, these two types\nof pre-trained word embeddings were employed. From the\n3270 VOLUME 11, 2023\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nFIGURE 9. Message length distribution in the dataset.\nFIGURE 10. Comparison between different encoders with the best\nperformance on the test set of the contextual dataset.\nresults reported in Table 7 to 9, the involvement of either con-\ntextual or static embedding signiﬁcantly affects the model’s\nperformance evaluation score. This can be seen from the\ndot-product attention performance, with a 3.782% difference\nbetween the best dot-product attention that uses BERT and\nGloVe. This signiﬁcant difference is also happening to the\ncosine attention, with a 3.899% difference. The other sce-\nnarios show consistent results, where a model with static\nand contextual pre-trained word embedding has a signiﬁcant\ndifference in the evaluation score. The process of capturing\ncontext that exists between words in a sentence also occurs\nin the encoder layer, which is performed by the self-attention\nmechanism. Therefore, the representational vector obtained\nfrom the static embedding is undergoing a reﬁnement process\nin the encoder layer. Eventually, the words’ vectors from the\nembedding layer went through a contextual learning pipeline,\njust like what the contextual pre-trained word embedding has\ndone. Contextual vector representation from BERT ﬁts the\nintuition of contextual learning in the self-attention mech-\nanism by means that the contextually related words within\na sentence are close to one another in the representational\nspace. Therefore, using a static and contextual embedding\nin a Transformer-based model resulted in signiﬁcantly differ-\nent evaluation scores. Nevertheless, the experimental results\nFIGURE 11. Convergence speed of the best model for each encoder on\nthe train set of the contextual dataset.\nshow an insigniﬁcant effect of using different character-level\nembedding on the models’ performance.\nThe scale factor implemented in scaled dot-product atten-\ntion, as proposed in the vanilla Transformer, has been argued\nbetter not be used in the NER task [37]. The reason is to\nsharpen the probability distribution yielded by the softmax\nin the self-attention mechanism. The sharper the attention,\nthe fewer contexts are captured by the attention, aligning to\nthe span length of mentioned entities commonly exist [37].\nHowever, the experimental results in Table 8 and 9 show a\ncontradictive point. Consider the following points. First, the\naverage sentence length is 6.3 and 8.8 in the train and test\nsets, respectively. Secondly, the sentence length is dominated\nby lengths ranging from one to ten, with more than 80% of\nthe portion, as shown in Fig. 9. Thus, it is unlikely that the\nsentence contains several contexts. Therefore, unscaled atten-\ntion is supposedly better if used instead of scaled attention.\nHowever, the experimental results demonstrated the contrary\non dot-product and AdaTrans attention. The scaled attention\nfor dot-product and AdaTrans attention achieved better per-\nformance than unscaled ones. Contrary, the cosine has better\nperformance with unscaled attention. As shown in Fig. 5, the\nelement-wise norm scale operation played the same role as\nthe scale factor in scaled dot-product attention. Therefore,\na scaling factor is needed in the self-attention mechanism and\nhas proven to improve the model’s performance compared to\nunscaled attention.\nE. COMPARISON WITH OTHER BASELINE MODELS\nTo verify the superiority of our proposed methods, we com-\npare the proposed models with several baseline models,\nas shown in Fig 10. The detailed architecture for each encoder\nis as follows: CNN-BERT-Scaled Transformer, AdaTrans-\nBERT-Unscaled Cosine, AdaTrans-BERT-Scaled AdaTrans,\nand AdaTrans-BERT-BiLSTM. For all of these encoders,\nCRF is used as the decoder. In terms of convergence speed,\nas depicted in Fig. 11, the proposed method converges as\nfast as Transformer and AdaTrans. Moreover, cosine atten-\ntion outperforms the BiLSTM model. From the F1 score,\nour proposed method achieves the second-best performance\nVOLUME 11, 2023 3271\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nFIGURE 12. Illustration of highlighted entities mentioned in a flight log message. The color highlight is used to help the investigator pinpoint the critical\ninformation within a log message.\nwith a 91.146% F1 score. This model uses the AdaTrans\nas the character-level feature extractor, concatenated with\nthe output of BERT as the pre-trained word embedding\nto get a word-level feature vector. The unscaled cosine\nattention is used as the encoder and CRF as the decoder.\nThe scaled Transformer model achieved the best perfor-\nmance, with a 91.348% F1 score. This scenario consists of\nCNN char embedding, BERT word embedding, scaled dot-\nproduct attention, and CRF as the decoder. In comparison, the\nunscaled AdaTrans attention is in the third position, accom-\npanied by AdaTrans as the character embedding and BERT as\nthe word embedding, with a 90.514% F1 score. This proves\nthat the relative attention mechanism is unsuitable for our\ncase since our dataset has a relatively short sequence, with\n6.3 and 8.8 words in length on average in train and test data,\nrespectively.\nOur proposed model underperforms the scaled dot-product\nattention with a 0.202% difference in the F1 score. How-\never, from the recall score, our proposed model outperforms\nall the baseline models with a 93.612% recall score. This\nshows that the proposed method has the lowest False Negative\nrate, where the number of misclassiﬁcation on entities are\nsmall. It means that the mentioned entities in the datasets are\nmostly correctly classiﬁed. Therefore, the proposed method\nsuccessfully recognizes the region of interest in the log\nmessage.\nThe evaluation score indicates that the proposed model\ncan recognize mentioned entities in ﬂight log message data.\nWhen a forensic investigator conducts an evidence analysis\nprocess, plenty of evidence must be examined, analyzed,\nand evaluated. To this end, presenting the NER result in a\nsophisticated visualization can help the investigator pinpoint\nthe region of interest in ﬂight log data faster. Fig. 12 shows a\nsample log message that has been fed to the NER model in a\nvisualization form to assist the forensic investigation. Having\nthe mentioned entities highlighted with a particular color, the\ninvestigator can ignore the message with no highlights and\nfocus only on those with color highlights. The color can be\nset to represent a level of importance. For instance, red can be\nused to highlight the Issue entity type. The highlight can help\nthe forensic investigator ﬁnd a message containing words or\nphrases with the Issue label.\nF. CHALLENGES AND LIMITATIONS\nAfter conducting the experiment, we described several chal-\nlenges in the following. Since drone forensics is a relatively\nnew research domain, a few open drone image datasets are\navailable. We only found one drone image dataset, the VTO\nLabs Drone Forensic dataset. Even from 15 different mod-\nels and more than 20 datasets, we only discover less than\n2000 log messages. Moreover, the dataset does not contain\nany speciﬁc drone incident scenario. It implies that no ground\ntruth can be used to test the proposed method regarding the\nforensic investigation, ﬁnding, and reporting view. Since this\nis an initial attempt on NER for drone forensics, there are few\nreferences, datasets, and domain-speciﬁc knowledge, such\nas entity types related to incidents and regions of interest\nin drone log messages. Therefore, many opportunities are\nopened by this attempt in the future, which will be our next\nproject. Considering the time needed to perform a thorough\nanalysis for one drone model, it is unrealistic to include other\ndrone models. Besides, DJI has the largest market share, and\nthe availability of a public dataset is one of the considerations\nfor this research to be veriﬁable and reproducible.\nV. CONCLUSION AND FUTURE WORKS\nIn this research, we have experimented with the employ-\nment of cosine similarity as a substitute for dot-product\nself-attention in the encoder sub-layer of Transformer archi-\ntecture. To evaluate our proposed approach, we construct\nour own NER dataset by manually extracting several drone\nforensic image datasets that are publicly available from the\nVTO Labs. For a relatively small dataset, we obtain a good\nresult indicated by the F1 score of 91.348% achieved by the\ndot-product attention supported by CNN character embed-\nding and BERT word embedding. Our proposed approach\noutperforms the RNN-based state-of-the-art by achieving the\nF1 score of 91.146%. The proposed model can achieve high\nscores even if the test data are generated from different drone\nmodels. This proves that NER can be used as an extraction\ntool to assist the forensic investigation by only utilizing the\nlog message data to recognize some incident-related infor-\nmation.\nWe plan to further analyze the trade-off between the con-\nvergence speed with the decrease in the number of parameters\n3272 VOLUME 11, 2023\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\nin the simpler architecture when using cosine as the attention\ntype. Since the number of epochs is a one-time cost, and\nthe inference time is a repetitive cost, we plan to explore\nfurther how many epochs are needed to train the simpler\nmodel having fewer parameters after employing the cosine\nin the self-attention sublayer without losing performance.\nAs this research is still an initial step in information extrac-\ntion, we plan to deploy the NER model so that it can be used\nas a practical solution for the forensic investigator.\nREFERENCES\n[1] F. Laricchia. (2022). Consumer Drone Unit Shipments Worldwide\nFrom 2020 to 2030 . [Online]. Available: https://www.statista.com/\nstatistics/1234658/worldwide-consumer-drone-unit-shipments\n[2] J.-P. Yaacoub, H. Noura, O. Salman, and A. Chehab, ‘‘Security analysis\nof drones systems: Attacks, limitations, and recommendations,’’ Internet\nThings, vol. 11, Sep. 2020, Art. no. 100218.\n[3] A. Al-Dhaqm, R. A. Ikuesan, V . R. Kebande, S. Razak, and F. M. Ghabban,\n‘‘Research challenges and opportunities in drone forensics models,’’ Elec-\ntronics, vol. 10, no. 13, p. 1519, Jun. 2021.\n[4] F. Iqbal, B. Yankson, M. A. AlYammahi, N. AlMansoori, S. M. Qayed,\nB. Shah, and T. Baker, ‘‘Drone forensics: Examination and analysis,’’ Int.\nJ. Electron. Secur. Digit. Forensics, vol. 11, no. 3, pp. 245–264, 2019.\n[5] G. Thornton and P. B. Zadeh, ‘‘An investigation into unmanned aerial\nsystem (UAS) forensics: Data extraction & analysis,’’ Forensic Sci. Int.,\nDigit. Invest., vol. 41, Jun. 2022, Art. no. 301379.\n[6] E. Mantas and C. Patsakis, ‘‘GRYPHON: Drone forensics in dataﬂash\nand telemetry logs,’’ in Advances in Information and Computer Security,\nN. Attrapadung and T. Yagi, Eds. Cham, Switzerland: Springer, 2019,\npp. 377–390.\n[7] D. R. Clark, C. Meffert, I. Baggili, and F. Breitinger, ‘‘DROP (DRone open\nsource parser) your drone: Forensic analysis of the DJI phantom III,’’ Digit.\nInvest., vol. 22, pp. S3–S14, Aug. 2017.\n[8] F. E. Salamh, M. M. Mirza, and U. Karabiyik, ‘‘UA V forensic analysis and\nsoftware tools assessment: DJI phantom 4 and matrice 210 as case studies,’’\nElectronics, vol. 10, no. 6, p. 733, Mar. 2021.\n[9] M. Maarse, L. Sangers, J. van Ginkel, and M. Pouw, ‘‘Digital forensics\non a DJI phantom 2 Vision +UA V ,’’ Univ. Amsterdam, Amsterdam,\nThe Netherlands, Tech. Rep., 2016.\n[10] M. Yousef and F. Iqbal, ‘‘Drone forensics: A case study on a DJI Mavic\nair,’’ in Proc. IEEE/ACS 16th Int. Conf. Comput. Syst. Appl. (AICCSA),\nNov. 2019, pp. 1–3.\n[11] I. McAteer, P. Hannay, M. Malik, and Z. Baig, ‘‘Forensic analysis of a\ncrash-damaged Cheerson CX-20 auto pathﬁnder drone,’’ J. Digit. Foren-\nsics, Secur. Law, vol. 13, no. 4, pp. 5–22, 2018.\n[12] F. E. Salamh, U. Karabiyik, and M. K. Rogers, ‘‘RPAS forensic validation\nanalysis towards a technical investigation process: A case study of Yuneec\nTyphoon H,’’ Sensors, vol. 19, no. 15, p. 3246, Jul. 2019.\n[13] Q. H. Ngo, T. Kechadi, and N.-A. Le-Khac, ‘‘Domain speciﬁc entity\nrecognition with semantic-based deep learning approach,’’ IEEE Access,\nvol. 9, pp. 152892–152902, 2021.\n[14] N. Perera, T. T. L. Nguyen, M. Dehmer, and F. Emmert-Streib, ‘‘Compar-\nison of text mining models for food and dietary constituent named-entity\nrecognition,’’Mach. Learn. Knowl. Extraction, vol. 4, no. 1, pp. 254–275,\nMar. 2022.\n[15] M. Asghari, D. Sierra-Sosa, and A. S. Elmaghraby, ‘‘BINER: A low-cost\nbiomedical named entity recognition,’’ Inf. Sci., vol. 602, pp. 184–200,\nJul. 2022.\n[16] Y . Tong, F. Zhuang, D. Wang, H. Ying, and B. Wang, ‘‘Improving biomed-\nical named entity recognition with a uniﬁed multi-task MRC framework,’’\nin Proc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP),\nMay 2022, pp. 8332–8336.\n[17] Z. Zhai, D. Q. Nguyen, S. A. Akhondi, C. Thorne, C. Druckenbrodt,\nT. Cohn, M. Gregory, and K. Verspoor, ‘‘Improving chemical named\nentity recognition in patents with contextualized word embeddings,’’ 2019,\narXiv:1907.02679.\n[18] P. Ma, B. Jiang, Z. Lu, N. Li, and Z. Jiang, ‘‘Cybersecurity named entity\nrecognition using bidirectional long short-term memory with conditional\nrandom ﬁelds,’’ Tsinghua Sci. Technol., vol. 26, no. 3, pp. 259–265,\nJun. 2021.\n[19] C. Gao, X. Zhang, and H. Liu, ‘‘Data and knowledge-driven named entity\nrecognition for cyber security,’’ Cybersecurity, vol. 4, no. 1, pp. 1–13,\nMay 2021.\n[20] S. Zhou, J. Liu, X. Zhong, and W. Zhao, ‘‘Named entity recognition using\nBERT with whole world masking in cybersecurity domain,’’ in Proc. IEEE\n6th Int. Conf. Big Data Anal. (ICBDA), Mar. 2021, pp. 316–320.\n[21] H. Studiawan, F. Sohel, and C. Payne, ‘‘Sentiment analysis in a forensic\ntimeline with deep learning,’’ IEEE Access, vol. 8, pp. 60664–60675, 2020.\n[22] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‘‘BERT: Pre-\ntraining of deep bidirectional transformers for language understanding,’’\nin Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics, Hum.\nLang. Technol., vol. 1, J. Burstein, C. Doran, and T. Solorio, Eds.\nMinneapolis, MN, USA, Jun. 2019, pp. 4171–4186. [Online]. Available:\nhttps://www.aclweb.org/anthology/N19-1423\n[23] Y . Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,\nL. Zettlemoyer, and V . Stoyanov, ‘‘RoBERTa: A robustly optimized BERT\npretraining approach,’’ 2019, arXiv:1907.11692.\n[24] V . Sanh, L. Debut, J. Chaumond, and T. Wolf, ‘‘DistilBERT, a dis-\ntilled version of BERT: Smaller, faster, cheaper and lighter,’’ 2019,\narXiv:1910.01108.\n[25] T. B. Brown et al., ‘‘Language models are few-shot learners,’’ 2020,\narXiv:2005.14165.\n[26] D.-Y . Kao, M.-C. Chen, W.-Y . Wu, J.-S. Lin, C.-H. Chen, and F. Tsai,\n‘‘Drone forensic investigation: DJI spark drone as a case study,’’ Proc.\nComput. Sci., vol. 159, pp. 1890–1899, Jan. 2019.\n[27] T. E. A. Barton and M. A. H. B. Azhar, ‘‘Forensic analysis of popular UA V\nsystems,’’ in Proc. 7th Int. Conf. Emerg. Secur. Technol. (EST), Sep. 2017,\npp. 91–96.\n[28] S. Viswanathan and Z. Baig, ‘‘Digital forensics for drones: A study of tools\nand techniques,’’ in Applications and Techniques in Information Security,\nL. Batina and G. Li, Eds. Singapore: Springer, 2020, pp. 29–41.\n[29] M. Debinski, F. Breitinger, and P. Mohan, ‘‘Timeline2GUI:\nA Log2Timeline CSV parser and training scenarios,’’ Digit. Invest.,\nvol. 28, pp. 34–43, Mar. 2019.\n[30] U. Jain, M. Rogers, and E. T. Matson, ‘‘Drone forensic framework: Sensor\nand data identiﬁcation and veriﬁcation,’’ in Proc. IEEE Sensors Appl.\nSymp. (SAS), Mar. 2017, pp. 1–6.\n[31] R. Kumar and A. K. Agrawal, ‘‘Drone GPS data analysis for ﬂight path\nreconstruction: A study on DJI, parrot & Yuneec make drones,’’ Forensic\nSci. Int., Digit. Invest., vol. 38, Sep. 2021, Art. no. 301182.\n[32] Y . Lou, T. Qian, F. Li, and D. Ji, ‘‘A graph attention model for dictionary-\nguided named entity recognition,’’ IEEE Access, vol. 8, pp. 71584–71592,\n2020.\n[33] T.-M. Georgescu, B. Iancu, A. Zamﬁroiu, M. Doinea, C. E. Boja, and\nC. Cartas, ‘‘A survey on named entity recognition solutions applied for\ncybersecurity-related text processing,’’ in Proc. 5th Int. Congr. Inf. Com-\nmun. Technol., X.-S. Yang, S. Sherratt, N. Dey, and A. Joshi, Eds. Singa-\npore: Springer, 2021, pp. 316–325.\n[34] H. Gasmi and A. Bouras, ‘‘LSTM recurrent neural networks for cyberse-\ncurity named entity recognition,’’ in Proc. 13th Int. Conf. Softw. Eng. Adv.,\n2018, pp. 1–15.\n[35] H. Studiawan, F. Sohel, and C. N. Payne, ‘‘Automatic log parser to support\nforensic analysis,’’ in Proc. 16th Austral. Digit. Forensics Conf., 2018,\npp. 1–10.\n[36] M. Afﬁ and C. Latiri, ‘‘BE-BLC: BERT-ELMO-based deep neural network\narchitecture for English named entity recognition task,’’ Proc. Comput.\nSci., vol. 192, pp. 168–181, Jan. 2021.\n[37] H. Yan, B. Deng, X. Li, and X. Qiu, ‘‘TENER: Adapting transformer\nencoder for named entity recognition,’’ 2019, arXiv:1911.04474.\n[38] I. Yamada, A. Asai, H. Shindo, H. Takeda, and Y . Matsumoto,\n‘‘LUKE: Deep contextualized entity representations with entity-aware\nself-attention,’’ 2020, arXiv:2010.01057.\n[39] J. Pennington, R. Socher, and C. Manning, ‘‘GloVe: Global vectors for\nword representation,’’ in Proc. Conf. Empirical Methods Natural Lang.\nProcess. (EMNLP), 2014, vol. 19, no. 5, pp. 1532–1543.\n[40] T. Mikolov, K. Chen, G. S. Corrado, and J. Dean, ‘‘Efﬁcient estimation of\nword representations in vector space,’’ in Proc. Int. Conf. Learn. Repre-\nsent., Jun. 2013, pp. 1–12.\n[41] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and\nL. Zettlemoyer, ‘‘Deep contextualized word representations,’’ J. Assoc.\nComput. Linguistics, vol. 1, pp. 2227–2237, Mar. 2018.\n[42] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, ‘‘Attention is all you need,’’ 2017,\narXiv:1706.03762.\nVOLUME 11, 2023 3273\nS. Silalahi et al.: Transformer-Based NER on Drone Flight Logs to Support Forensic Investigation\n[43] H. Chen, Z. Lin, G. Ding, J. Lou, Y . Zhang, and B. Karlsson, ‘‘GRN: Gated\nrelation network to enhance convolutional neural network for named entity\nrecognition,’’ 2019, arXiv:1907.05611.\n[44] A. Ghaddar and P. Langlais, ‘‘Robust lexical features for improved neu-\nral network named-entity recognition,’’ in Proc. 27th Int. Conf. Comput.\nLinguistics. Santa Fe, NM, USA, Aug. 2018, pp. 1896–1907.\n[45] M. Maryamah and I. T. S. Nopember, ‘‘Pseudo-relevance feedback com-\nbining statistical and semantic term extraction for searching Arabic docu-\nments,’’Int. J. Intell. Eng. Syst., vol. 14, no. 5, pp. 238–246, Oct. 2021.\n[46] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, ‘‘Enriching word\nvectors with subword information,’’ 2016, arXiv:1607.04606.\n[47] J. Wang, A. Jatowt, and M. Yoshikawa, ‘‘TimeBERT: Extending pre-\ntrained language representations with temporal information,’’ 2022,\narXiv:2204.13032.\n[48] D. Bahdanau, K. Cho, and Y . Bengio, ‘‘Neural machine translation by\njointly learning to align and translate,’’ in Proc. 3rd Int. Conf. Learn.\nRepresent., Y . Bengio and Y . LeCun, Eds. San Diego, CA, USA, 2015,\npp. 1–15.\n[49] M.-T. Luong, H. Pham, and C. D. Manning, ‘‘Effective approaches to\nattention-based neural machine translation,’’ 2015, arXiv:1508.04025.\n[50] P. Shaw, J. Uszkoreit, and A. Vaswani, ‘‘Self-attention with relative posi-\ntion representations,’’ 2018, arXiv:1803.02155.\n[51] Z. Dai, Z. Yang, Y . Yang, J. Carbonell, Q. V . Le, and R. Salakhutdinov,\n‘‘Transformer-XL: Attentive language models beyond a ﬁxed-length con-\ntext,’’ 2019, arXiv:1901.02860.\n[52] C. Luo, J. Zhan, X. Xue, L. Wang, R. Ren, and Q. Yang, ‘‘Cosine\nnormalization: Using cosine similarity instead of dot product in neural\nnetworks,’’ in Artiﬁcial Neural Networks and Machine Learning—ICANN\n2018. Cham, Switzerland: Springer, 2018, pp. 382–391.\n[53] K. He, X. Zhang, S. Ren, and J. Sun, ‘‘Deep residual learning for image\nrecognition,’’ 2015, arXiv:1512.03385.\n[54] J. L. Ba, J. R. Kiros, and G. E. Hinton, ‘‘Layer normalization,’’ 2016,\narXiv:1607.06450.\n[55] A. F. Agarap, ‘‘Deep learning using rectiﬁed linear units (ReLU),’’ 2018,\narXiv:1803.08375.\n[56] Z. Huang, W. Xu, and K. Yu, ‘‘Bidirectional LSTM-CRF models for\nsequence tagging,’’ 2015, arXiv:1508.01991.\n[57] D. Slotta. (2021). Global Market Share of Consumer and Commer-\ncial Drone Manufacturers in March 2021, Based on Sales Volume.\n[Online]. Available: https://www.statista.com/statistics/1254982/global-\nmarket-share-of-drone-manufacturers/\n[58] E. Mantas and C. Patsakis, ‘‘Who watches the new watchmen? The chal-\nlenges for drone digital forensics investigations,’’ Array, vol. 14, Jul. 2022,\nArt. no. 100135.\n[59] N. Alshammari and S. Alanazi, ‘‘The impact of using different annotation\nschemes on named entity recognition,’’ Egyptian Informat. J., vol. 22,\nno. 3, pp. 295–302, Sep. 2021.\nSWARDIANTARA SILALAHI (Member, IEEE)\nwas born in Pekanbaru, Riau, Indonesia, in 1997.\nHe received the B.Ed. degree in informatics edu-\ncation from Universitas Negeri Jakarta, Jakarta,\nIndonesia, in 2021. He is currently pursuing the\nPh.D. degree in computer science with the Institut\nTeknologi Sepuluh Nopember (ITS), Indonesia.\nHe was a Production Support Engineer at Dana-\nmon Bank, from 2020 to 2021. Since September\n2021, he has been a Research Assistant with the\nNet-Centric Computing Laboratory. He has several published works in the\ndigital forensics area. His research interests include digital forensics, log\nmining, natural language processing, and deep learning. He is an awardee\nof the PMDSU Scholarship by the Ministry of Education, Culture, Research\nand Technology, Indonesia.\nTOHARI AHMAD (Member, IEEE) received\nthe bachelor’s degree in computer science from\nthe Institut Teknologi Sepuluh Nopember (ITS),\nIndonesia, the master’s degree in information tech-\nnology from Monash University, Australia, and\nthe Ph.D. degree in computer science from RMIT\nUniversity, Australia, in 2012.\nFrom 2001 to 2003, he was a consultant for\nsome international companies. In 2003, he moved\nto ITS, where he is currently a Professor. His\nresearch interests include network security, information security, data hiding,\nand computer networks.\nProf. Ahmad is a member of ACM. His awards and honors include\nthe Hitachi Research Fellowship and JICA Research Program to conduct\nresearch in Japan. He is a reviewer of a number of journals.\nHUDAN STUDIAWAN(Member, IEEE) received\nthe bachelor’s and master’s degrees from the Insti-\ntut Teknologi Sepuluh Nopember, Indonesia, in\n2009 and 2011, respectively, and the Ph.D. degree\nfrom Murdoch University, Australia, in 2021. He is\ncurrently a Lecturer with the Institut Teknologi\nSepuluh Nopember. His current research inter-\nests include digital forensics and natural language\nprocessing.\n3274 VOLUME 11, 2023",
  "topic": "Drone",
  "concepts": [
    {
      "name": "Drone",
      "score": 0.9053661227226257
    },
    {
      "name": "Computer science",
      "score": 0.8577815294265747
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5043202638626099
    },
    {
      "name": "Named-entity recognition",
      "score": 0.4681409001350403
    },
    {
      "name": "Data mining",
      "score": 0.43312451243400574
    },
    {
      "name": "Transformer",
      "score": 0.4145057797431946
    },
    {
      "name": "Information retrieval",
      "score": 0.38346540927886963
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Task (project management)",
      "score": 0.0
    },
    {
      "name": "Genetics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I166843116",
      "name": "Sepuluh Nopember Institute of Technology",
      "country": "ID"
    }
  ],
  "cited_by": 22
}