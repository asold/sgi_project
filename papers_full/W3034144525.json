{
  "title": "Language Modeling for Formal Mathematics",
  "url": "https://openalex.org/W3034144525",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A5072217103",
      "name": "Markus N. Rabe",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5072563536",
      "name": "Dennis Lee",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5032173124",
      "name": "Kshitij Bansal",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5002183320",
      "name": "Christian Szegedy",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2626778328"
  ],
  "abstract": "We examine whether language modeling applied to mathematical formulas enables logical reasoning. We suggest several logical reasoning tasks that can be used to evaluate language models trained on formal mathematical statements, such as type inference, suggesting missing assumptions and completing equalities. To train language models for formal mathematics, we propose a novel skip-tree task, which outperforms standard language modeling tasks on our reasoning benchmarks. We also analyze the models' ability to formulate new conjectures by measuring how often the predictions that do not fit the ground truth or any training data turn out to be true and useful statements.",
  "full_text": "Mathematical Reasoning via Self-supervised\nSkip-tree Training\nMarkus N. Rabe\nGoogle Research\nmrabe@google.com\nDennis Lee\nGoogle Research\nldennis@google.com\nKshitij Bansal\nGoogle Research\nkbk@google.com\nChristian Szegedy\nGoogle Research\nszegedy@google.com\nAbstract\nWe examine whether self-supervised language modeling applied to mathematical\nformulas enables logical reasoning. We suggest several logical reasoning tasks that\ncan be used to evaluate language models trained on formal mathematical statements,\nsuch as type inference, suggesting missing assumptions and completing equalities.\nTo train language models for formal mathematics, we propose a novel skip-tree\ntask. We ﬁnd that models trained on the skip-tree task show surprisingly strong\nmathematical reasoning abilities, and outperform models trained on standard skip-\nsequence tasks. We also analyze the models’ ability to formulate new conjectures\nby measuring how often the predictions are provable and useful in other proofs.\n1 Introduction\nLanguage modeling using Transformers [Vaswani et al., 2017] has been hugely successful for\napplications like translation and text generation. Models like GPT-2 are able to generate impressive\nnews articles and stories given just an abstract [Radford et al., 2018]. These models are usually ﬁrst\ntrained on a proxy task, such as predicting missing words in the case of BERT [Devlin et al., 2019],\nbefore ﬁne tuning the models on more speciﬁc (downstream) tasks such as machine translation and\nquestion-answering. The proxy tasks are not reliant on labeled data, and thus can be trained on large\ncorpora of unlabeled data. Even the models trained on the proxy tasks alone, have shown impressive\nlanguage understanding [Brown et al., 2020].\nPrior work in deep learning for mathematics has focused on learning directly on logical reasoning\ntasks, such as predicting the proof steps or premises or assignments. These approaches requirelabeled\ndata, which is hard to come by and typically very limited in size. In this work, we apply the paradigms\nof language modeling to formal mathematics and deﬁne proxy tasks on unlabeled mathematical\nexpressions that allows us to use much more data. We start with the HOList dataset [Bansal et al.,\n2019], which spans a wide range of mathematical topics, including topology, multivariate calculus,\nreal and complex analysis, geometric algebra, and measure theory, formalized in the HOL Light proof\nassistant [Harrison, 1996]. We ﬁnd that training a language model on all mathematical expressions in\nthis dataset leads to surprisingly strong mathematical reasoning capabilities.\nFor training language models on formal mathematics, we propose a novel skip-tree task. The skip-tree\ntasks is a specialization of the skip-sequence task that respects the tree structure of expressions. We\nshow that models trained on the skip-tree task signiﬁcantly outperform those trained on the standard\nskip-sequence task.\nReasoning can refer to a wide range of abilities, and thus we measure the mathematical reasoning\nabilities of language models on a variety of tasks, including mechanical derivations, such as type\ninference, and also creative tasks, such as predicting under which assumptions a statement is true. In\ncontrast to most works in natural language modeling, we do not ﬁne-tune the models to the evaluation\nPreprint. Under review.\narXiv:2006.04757v3  [cs.LG]  12 Aug 2020\n(downstream) tasks, as we want to study what reasoning capabilities can be acquired just through\nlanguage modeling proxy tasks.\nAn advantage of formal language compared to natural language is that we can attempt to automatically\nevaluate statements. That is, even if the language models fail to predict the ground truth, the statements\nthey predicted might still be true and useful. We evaluate theseconjectures by attempting to prove\nthem and checking if they are can be used in the context of other proofs.\nOur contributions are as follows:\n1. We introduce several evaluation tasks that test logical reasoning abilities.\n2. We introduce a new skip-tree language modeling task that outperforms skip-sequence\napproaches in our evaluation on the logical reasoning tasks.\n3. We show that language modeling on mathematical formulas results in surprisingly strong\nlogical reasoning capabilities.\n4. We suggest a way to create and evaluate mathematical conjectures with language models.\nThe remainder of this paper is structured as follows: First, we review related work on language\nmodeling and deep learning for mathematics in Section 2. Then, in Section 3 we discuss the source\ncorpus of formal mathematical statements from which we generate our training data. In Section 4, we\npresent our novel language modeling task for formal languages, as well as several variations that we\nused in our ablation studies. We present the evaluation tasks in Section 5, present our experimental\nﬁndings in Section 6, and conclude in Section 7.\n2 Related work\nRecently, we have seen a series of rapid improvements in language modeling stemming from better\npretraining tasks [Devlin et al., 2019, Zhang et al., 2019, Song et al., 2019, Dong et al., 2019, Raffel\net al., 2019, Conneau and Lample, 2019]. BERT [Devlin et al., 2019] is a pretraining task for\nTransformers [Vaswani et al., 2017], which masks out a certain fraction of the input tokens that the\nmodel then has to predict. UniLM uses multiple pretraining tasks [Dong et al., 2019]. One of them\nis a sequence-to-sequence task; to predict the next sentence from the previous sentence. MASS\nand SpanBERT consider a generalized sequence-to-sequence pretraining task, which is to predict a\nmasked out subsequence of the input [Song et al., 2019, Joshi et al., 2020]. However, both MASS\nand SpanBERT reveal the length of the sequence to predict as they replace it by a number of mask\ntokens equal to the length of the sequence.\nT5 introduced a generalization of sequence-to-sequence pretraining tasks that is crucial to our\nwork [Raffel et al., 2019]. They replace the subsequence (or multiple subsequences) to be predicted\nby a single token (not a number of mask tokens equal to the length of the subsequence, as in MASS).\n[Zhang et al., 2019] additionally exploit the sentence structure of natural language. They suggest the\npretraining task Pegasus, which masks out entire sentences of a given text, and additionally masks\nout randomly selected tokens in the remaining text (or alternatively replace them by other tokens).\nIn a similar way Pegasus’ exploitation of the sentence structure of natural language, our skip-tree\ntask exploits the tree structure of formal expressions. [Zhang et al., 2019] also suggest sampling the\nsentences to be masked with the help of ROUGE1-F1 [Lin, 2004].\nWe work with the HOList dataset by Bansal et al. [2019], which is closely related to the Flyspeck\ndataset by Kaliszyk and Urban [2014]. There are other datasets which might be suitable for our\napproach as well, including proofs extracted from HOL4 [Gauthier et al., 2017], and from Coq [Huang\net al., 2019, Yang and Deng, 2019, Sanchez-Stern et al., 2019].\nMost previous works that apply sequence-to-sequence models to logics have focused on speciﬁc\nlogical tasks in supervised training settings. In contrast, we train language models on an unsupervised\nproxy task that does not require labeled data and can thus be applied to almost any source of mathemat-\nical expressions. Lample and Charton [2020] use a Transformer model for symbolic integration. They\ntrain their model directly on the reasoning task they want to learn, and their approach requires that the\ninverse of the prediction task can be computed effectively with classical algorithms. Finkbeiner et al.\n[2020] explore the generalization properties of the Transformer architecture predicting the solutions\nto SAT formulas and temporal logic, but require a data generator that can solve formulas, which\n2\nTheorem database\nProofs\nValidation TestingTraining\nFigure 1: We use the theorems and proofs of the training split, marked in green, for training. For\nour evaluation tasks, we only use the theorems of the validation set, marked in red, to ensure that the\nmodel has never seen the statements from which the evaluation tasks are derived.\nis currently not feasible for higher-order logic. Piotrowski et al. [2019] train RNNs on individual\nlogical reasoning steps, such as substitutions, using a dataset of rewrites on polynomials extracted\nfrom Prover9. Wang et al. [2018] translate between synthetic descriptions in natural language and\nformal mathematics on a dataset generated with Mizar.\nSelf-supervised training techniques for formal mathematics have received much less attention. Wang\net al. [2020] apply recent unsupervised translation techniques by Lample et al. [2018] to align formal\nand informal techniques. They that they perform considerably worse than supervised techniques.\nVery recently, Urban and Jakub˚ uv [2020] presented initial experiments on applying self-supervised\nlanguage modeling to formal mathematics in order to produce conjectures. Earlier statistical ap-\nproaches to produce conjectures include Gauthier et al. [2016]. Also, very recently, Li et al. [2020]\napplied language modeling to proofs of formal mathematics.\nTransformer models for program understanding have focused on providing inductive biases in the\narchitecture [Shiv and Quirk, 2019, Hellendoorn et al., 2020], whereas this work suggests to use a\nmodiﬁed language modeling proxy task.\nApplying natural language techniques to formal mathematics has a long history. Already in 2004,\nCairns [2004] applied information retrieval based on latent semantics to improve over search for\nkeywords, and Urban [2004] formulated the intention to learn from large amounts of data in formalized\nmathematics.\n3 Dataset\nWe start from the HOList dataset introduced by Bansal et al. [2019]. The complete dataset includes\n29465 theorems and their proofs. We here consider only the “core” and “complex” datasets which\ncomprise 18943 theorems, 637 deﬁnitions and 603,950 proof steps. These proof steps were extracted\nfrom the human proof logs. The theorems and proofs were written (by humans) using the HOL Light\nproof assistant, and span various areas of mathematics such as set theory, arithmetic, linear algebra,\ntopology, and multivariate complex analysis. The proofs contain a lot of intermediate goals which are\nthe result of applying “tactics” on previous proof goals. For example, one of the tactics is to rewrite\nthe current proof goal with a set of equations selected from the theorem database.\nFrom this dataset we extract all theorem statements as well as all intermediate proof goals. We use\nS-expressions to represent all statements. For example, (v bool x) represents a boolean variable\nnamed x, and (a (v (fun (bool) (bool)) f) (v bool x) represents the function application\nf(x) where f is a function from bool to bool. The S-expression syntax is thus very verbose, which\ncan cause some expressions to not ﬁt into the size constraints of our Transformer model.\nWe use the same split into training/validation/testing data as deﬁned in HOList. The split is deﬁned on\nthe theorems, and the entire proof of each theorem is assigned to the same split as the theorem. This\nmeans that we have used the proof of 11,655 theorems in the training split of the core and complex\nlibraries. This avoids partially revealing the proofs of theorems in the validation and test sets during\ntraining. We derive all training data from the theorems and proofs in the training set, and use only\nthe theorems (not the proofs) for the evaluation tasks. This addresses the possibility that some proof\n3\nEncoder Decoder\n( <MASK> ( fun ( bool ) <PREDICT>) = )\n( c ( fun ( bool ) ( fun ( bool ) ( bool ) ) ) = )\n<START> ( fun ( bool ) ( bool ) ) <END>\n ( fun ( bool ) ( bool ) ) <END>\nOriginal formula:\nFigure 2: The skip-tree training task for the example of the equality operator on boolean constants\n(original formula). In this example we assume that a part of the type was sampled to be the\nsubexpression to be predicted, and that subexpression c was sampled to be masked out additionally.\nNote the input to the decoder is shifted to the right, such that the next token prediction task yields the\ntarget sequence.\nsteps for training theorems and for validation theorems might be shared. In Figure 1 we depict our\nchoice of training and evaluation data.\n4 Skip-tree Training\nIn this section we deﬁne the skip-tree training task. We parse a given mathematical statement into a\ntree of subexpressions, and replace one of the subexpressions by a <PREDICT> token. The task is to\npredict the subexpression replaced by <PREDICT>. See Figure 2 for an example.\nFor training, the trees are converted back to a sequence of tokens; the target sequence is extended\nby a <START> token in the front and an <END> token in the back. We exclude training examples\nwhere the output sequence is longer than the length of the decoder (512 tokens), and we cut off input\nsequences when they exceed the length of the encoder (1024 tokens).\nAdditional masked subexpressions. In addition to the subexpression to be masked out by\n<PREDICT>, we select k = 2subexpressions to be masked out by a different mask token <MASK>.\nIn contrast to the <PREDICT> token, we replace all occurrences of these subexpressions by the\n<MASK> token. Note that it can happen that the subexpressions we want to replace by the <MASK>\ntokens overlap with each other or with the subexpression replaced by the <PREDICT> token. In this\ncase, we give the highest preference to the <PREDICT> token, and then in decreasing order of size\nfor the expression to be replaced by the <MASK> tokens.\nThe subexpressions masked by <MASK> do not have to be predicted. They are only hidden to make\nthe task harder and to make the model tolerant to having partial information. A beneﬁcial side effect\nof replacing some expressions by a <MASK> token is that the input sequences get substantially\nshorter and more mathematical expressions ﬁt in the size constraints of the Transformer architecture.\nDistributions of subexpressions. Sampling subexpressions uniformly at random results in very\nshort sequences to be predicted: since our trees are mostly ternary, two thirds of the subexpressions\nare leaves. Besides picking subexpressions uniformly at random, we thus experiment with weighting\nthe subexpressions by the number of tokens they contain. We refer to these variants as “uniform” and\n“weighted”. This results in a much more diverse set of expressions to be sampled.\nMultiple samples per statement. Since we started with a data source that is small compared\ndatasets in natural language modeling, we use each mathematical statement from the training set to\ngenerate n = 100training examples. Our initial data consists of about 360K intermediate statements\nfrom the proofs of 10K statements in the training split of the core and complex library of the HOList\ncorpus. To avoid duplicates, we sample the subexpressions that are replaced by a <PREDICT> token\nfor each original formula without replacement.\n4\n4.1 Ablations\nTo verify the design choices of the skip-tree training task we generated multiple variants of the\ntraining task and trained a model on each of them.\nNo mask tokens. To answer the question of whether it helps to mask out subexpressions besides\nthe one to predict, we generated a dataset with k = 0, called “skip-tree (no <MASK>)”.\nFewer samples per statement.Instead of sampling many training examples from each formula,\nwe could train on a fewer training examples for more epochs. We generated a smaller version with\nn = 20of the skip-tree training data, which we call “skip-tree (small)”.\nSkip-sequence. MASS [Song et al., 2019], SpanBERT [Joshi et al., 2020], and T5 [Raffel et al.,\n2019] pretrain their sequence-to-sequence natural language models by predicting subsequences of the\ntokens. The skip-tree task is similar, but exploits our ability to parse the formulas as trees. To examine\nif this makes a difference, we consider a “skip-sequence” task that samples subsequences of the list\nof tokens instead of sampling subexpressions. We generated three datasets for the skip-sequence task,\nwhere we sample subsequences of different lengths (short/medium/long). For the task “skip-sequence\n(long)”, we pick two positions in the token sequence at uniformly at random and select the sequence\nthat is between them. For the tasks “skip-sequence (medium)” and “skip-sequence (short)”, we limit\ntheir distance to 100 and 50 tokens, respectively.\nDataset # examples # tokens (input/output) avg length (input/output)\nSkip-tree (weighted) 25.8M 17.4B/1.6B 675/61\nSkip-tree (uniform) 25.7M 18.8B/316M 732/12\nSkip-tree (small) 5.2M 3.5B/521M 673/100\nSkip-tree (no <MASK>) 25.8M 19.4B/1.6B 750/61\nSkip-sequence (long) 19.2M 11.9B/2.8B 620/146\nSkip-sequence (medium) 26.0M 19.4B/884M 744/34\nSkip-sequence (short) 26.0M 19.6B/479M 752/18\nTable 1: Basic statistics of the training splits of the data sets. Number of tokens in the training set\nmeasured before padding.\n5 Evaluation Tasks\nIn this section we suggest several logical reasoning tasks on which our language models can be\nevaluated. These tasks require different levels of logical reasoning, ranging from mostly mechanical\napplication of typing rules to conjecturing under which assumptions a statement might hold.\nWe intentionally deﬁne them to be out-of-distribution compared to the training data. Not only do we\ngenerate the examples in a slightly different way, we also generate them from the validation set of the\ntheorem database. That is, the model has never seen the source data, nor has it seen the proofs of\nthese theorems. This makes the tasks more challenging, and also ensures that we force the models to\ngo beyond memorization. To give the interested reader a better impression of the evaluation tasks, we\nprovide a list of randomly selected examples in Appendix D.\nType Inference. We generate type inference problems similar to how we generated the skip-tree\ntraining data, which we described in Section 4. However, we restrict the sampling of subexpressions\nto subtrees that represent types of variables or constants (i.e. not fragments of other types).\nWe generated two variants of the type inference task: In the task we call “Type Inference,” we\nreplace only the selected type by the <PREDICT> token and do not mask out anything else. In\nthe second variant we name “Hard Type Inference,” we additionally replaceall other types by the\n<MASK> token. The two tasks loosely correspond to the deriving the ﬁrst and the last type during\ntype inference.\nFor example, consider x = x, which in the s-expression syntax is represented as follows:\n(a (a (c (fun (A) (fun (A) (bool))) =) (v A x)) (v A x))\n5\nEach subexpression here is either a leaf or a triple. The ﬁrst element of these triples indicates their\nkind: a indicates function applications, c indicates constants (i.e. symbols that have been deﬁned in\nthe formal system), v indicates a variable, and ﬁnally fun indicates a function type. The equality\noperator “=” is represented by (c (fun (A) (fun (A) (bool))) =), which indicates that it is a\nconstant that has a function type taking two arguments of arbitrary type A and returns a bool. Since\nfunctions are typically curried in this representation, we have two function applications, both times\nwith the variable x as the argument.\nAn example for the “Type Inference” evaluation task would be:\n(a (a (c <PREDICT> =) (v A x)) (v A x))\nThe type of the equality operator is still uniquely deﬁned, as we know what the equality is applied to\n(two arguments of type A) and because top-level application always has to return a boolean value. In\nthis example the type could have been computed by a classical type inference algorithm.\nFor the “Hard Type Inference” evaluation task, the input would look as follows:\n(a (a (c <PREDICT> =) (v <MASK> x)) (v <MASK> x))\nNow, the type inference task is highly ambiguous. In fact, in this case, variablex could have any type,\nand the equality operator would have to adapt to the type of its arguments accordingly. Further, note\nthat the hard type inference task masks out many more subtrees compared to the training data.\nAssumptions. This evaluation task is to predict missing assumptions for theorems in the validation\nset. We extract these tasks by searching for “top-level implications” and replacing their left operand\nby the <PREDICT> token. We deﬁne an implication operator “⇒” in an expression to be a top-level\nimplication if it is either the top-most operator of the expression, or occurs only under quantiﬁers,\nconjunctions, disjunctions, or on the right side of other top-level implications. This deﬁnition helps\nus to avoid picking assumptions in negated parts of formulas.\nNote that we can have multiple top-level implications per validation theorem. Consider the abstracted\nexample (a ⇒b) ∧(c ⇒(d ⇒e)). In this case, a, c, and d are all considered to be assumptions of\ntop-level implications.\nAn example from the theorem database is x = y ⇒a + x = a + y, for which the task is to predict\nx = y given <PREDICT> ⇒a + x = a + y. (We omit the presentation of this example as an\ns-expression for the sake of readability.) At ﬁrst, the expression to predict in this case may seem\nunique, but there are actually many ways to complete the task into a true statement; e.g. y = x or\nx = 0∧y = 0. Still, most humans would likely guess x = y as it is simple and general, and because\nx occurs before y in the alphabet. To make a correct prediction, our language models thus have to\nunderstand which statements are more general and also know about naming conventions.\nBelow we give some examples of this reasoning task that we selected for their simplicity. (For a\nrepresentative selection, see Appendix D.) While it is often easy to “see” that a given solution to such\na task is correct, it can be non-trivial to come up with a solution in the ﬁrst place. We encourage the\nreader to make their own predictions before looking up the ground truth in Appendix C:\n• <PREDICT> ⇒(x ⇔( b ∨x1) ∧(b ∨x0))\n• <PREDICT> ⇒(g \\{s}) =g\n• <PREDICT> ⇒(x1/y1 =x2/y2 ⇔ x1 ∗y2 =x2 ∗y1)\nEqualities. Similar to the task of predicting missing assumptions, we ask to predict one side of a\ntop-level equality in this task. Again, we deﬁne top-level equalities to be any equality that occurs as\nthe top-level operator of the formula or occurs inside quantiﬁers, conjunctions, disjunctions, or on\nthe right side of implications. For example, from the theorem ∀x.x = (x = True) we extract two\nevaluation examples: ∀x. <PREDICT> = (x = True) and ∀x. x= <PREDICT>.\nAgain, we present some simple example tasks (in mathematical notation for the sake of readability)\nand provide the ground truth as well as the model predictions in Appendix C:\n• ∀x, n∈N : (xn = 1) =<PREDICT>\n• ∀m, n: n ≤m ⇒m −n + n = <PREDICT>\n• ∀l, m: <PREDICT> = APPEND(REVERSE(m), REVERSE(l))\n6\n6 Results and Discussion\nWe trained a Transformer with the hyperparameters speciﬁed in the appendix on the skip-tree dataset\nand each of the ablations for 1M steps with a batch size of 256.\nIn language modeling for natural language one of the key metrics is how often the next token in the\nground truth is correctly predicted. This is not an ideal measurement for formal mathematics as even\na single incorrect token can invalidate the entire statement. Also, the s-expression representation is\nrelatively lengthy and barely human-readable, so a token-level measurement does not allow us to\ncompare our models to the natural language models in any case. In the ﬁrst part of our evaluation we\ntherefore focus on exact matches of the entire predicted statement.\nDataset Type Inference Hard Type Inference Assumptions Equalities\nSkip-tree (uniform) 96.21% 94.40% 40.85% 46.57%\nSkip-tree (weighted) 96.23% 93.32% 40.86% 42.89%\nSkip-tree (small) 95.89% 90.42% 39.23% 40.91%\nSkip-tree (no <MASK>) 96.07% 32.50% 38.38% 41.60%\nSkip-sequence (long) 9.44% 0.06% 0.53% 0.56%\nSkip-sequence (medium) 48.94% 5.97% 3.32% 3.55%\nSkip-sequence (short) 77.25%% 3.21% 0.68% 2.06%\nTable 2: Success rate of predicting the ground truth in a beam search of width 8 after training a model\non various datasets. Grayed out values indicate experiments where the training data did not include\nthe <MASK> token but the evaluation data did.\nIn Table 2 we present how well the Transformer model, trained on different datasets, can predict\nthe ground truth sequences. We can observe that for type inference, i.e. the more mechanical\nreasoning tasks, the models achieve a high accuracy - even in the Hard Type Inference case where the\nexpression was stripped of all types. We see that the skip-tree task and its ablations clearly dominate\nthe skip-sequence language modeling task. There does not seem to be a major difference between the\n“uniform” and “weighted” sampling strategies for the skip-tree model.\nA closer inspection of the skip-sequence model shows that its predictions rarely parse or typecheck.\nOn manual inspection of the predictions, it seems that the skip-sequence models consistently add\nsurplus tokens at the end, or stop expressions too early; they appear to be unable to correctly identify\nthe end of the expression to predict.\n6.1 Conjecturing\nIn the experiments above, we measured how often the models predicted the ground truth in the\nevaluation tasks. We now change our point of view, and examine whether the models can be used\nto generate new conjectures. We deﬁne conjectures as mathematical statements that differ from the\nground truth and any expression the model has seen during training . Additionally, a meaningful\nconjecture should be syntactically correct, typecheck, be provable, and be useful in the context of\nother proofs.\nSince the training data is derived exclusively from true statements (i.e. human proof steps), the\nlanguage models are incentivized to complete partial statements in a way that makes them true.\nPresented with one of the evaluation tasks, to predict missing assumptions or to predict the missing\nside of an equation, the models may thus complete these statements in multiple ways that make them\ntrue. The predictions that do not match the ground truth may still be true and useful statements. In\nthe following we describe experiments that help us estimate how often this is the case.\nFree-form conjecturing. In addition to the “assumptions” and the “equalities” evaluation tasks, we\nconsider a third task for producing conjectures. In this task, which we call “free-form conjecturing”,\nwe query the model with a single prompt: (<theorem> <PREDICT>). This helps us to analyze what\nthe language models produce when given no context. The <theorem> tag indicates only that the\nstatement should be a theorem, and not an intermediate proof step, which would start with the<goal>\ntag. For free-form conjecturing we want to produce a variety of different predictions, and thus use a\nbeam search with high beam width of 1024. We did not include the free-form conjecturing task in\nTable 2, as there is no ground truth to match against.\n7\nHow often are predictions true and new?For this measurement, we replace the <PREDICT>\ntoken with the predicted sequence and attempt to prove the resulting statement in the DeepHOL\ntheorem prover [Bansal et al., 2019]. Note that this can only give us a lower bound to the number\nof true statements, because of the limitations of the prover: The version of the DeepHOL theorem\nprover used here can prove around 58% of the validation theorems. So we expect the estimates here\nto be considerably below the number of actually true statements.\nIn Table 3 we report two numbers for each evaluation task: The ﬁrst number is the percentage of\ngenerated statements known to be provable, including exact matches, statements from the training\nset, and statements provable with DeepHOL. The second number is the percentage of generated\nstatements that are provable and new - excluding exact matches with the ground truth and statements\nfrom the training set. The denominator for both numbers is the same: the set of all predictions from\nthe beam searches in Table 2.\nWe believe that these measurements show a signiﬁcant bias towards true statements. While in some\ntasks, less than half of the statements were provable, there are simply many more ways to write a\nfalse statement than a true statement.\nDataset Assumptions Equalities Free-form Conjecturing\nSkip-tree (uniform) 32.19%/26.20% 19.61%/12.28% 82.32%/12.70%\nSkip-tree (weighted) 32.41%/26.91% 17.96%/11.63% 97.75%/0.59%\nTable 3: Percentage of “provable statements”/“provablenew statements”. The type inference tasks\nare not included as we are only interested in the predictions that do not match the ground truth. For\nthe type inference tasks, these statements are either semantically equivalent to existing statements or\nstatements that do not type check.\nAre the conjectures useful? For some evaluation tasks, the models could “cheat” on the truth\nmetric by making the statements trivially true. For example, the models can predict False as an\nassumption, or complete the missing part of an equation by making it an identity (e.g. complete x =\n<PREDICT> by predicting x). In fact, manual inspection revealed several such cases.\nTo make this measurable, we added the provable statements to the theorem database, and ran the\nreinforcement learning experiments of the DeepHOL theorem prover [Bansal et al., 2019] to measure\nhow many of the statements were used as premises. In this experiment we also make sure that the new\ntheorems cannot be used in the proofs of their premises. In a “pruning” step DeepHOL minimizes\nproofs by removing each individual premise in a proof and checking if the proof still holds. Only the\npremises that survive this step are classiﬁed as useful. While this measurement is a relatively low bar,\nit ﬁlters out statements that have no effect in any proof.\nWe ran three reinforcement learning experiments, one for each of the evaluation tasks. We then\nmeasured how many of the theorems generated by each task are used as a premise in one of the\nover 200,000 proofs found for each of the experiments. For the assumptions task, 3445 of the 3857\ntheorems were used at least once. For the equalities task and the free-form conjectures it was 979 out\nof 3440 and 49 out of 130, respectively. We provide usage histograms in Appendix B.\nWhile some of the most frequently used conjectures turned out to be alpha-equivalent variations of\nexisting theorems in the theorem database, we found some interesting examples among the most used\nconjectures:\n• Assumptions task, 1728 usages: b = a + c ⇒a = b −c. Humans have used this theorem\nover vector arithmetic in many proofs. However, this theorem has always been deﬁned as a\nlocal lemma and thus did not made it into the theorem database. This conjecture apparently\nﬁlled a gap in the theorem database.\n• Free-form conjecturing task, 15 usages: COUNTABLE({s(n) |n ∈N}). In contrast to the\nprevious example, there are no occurrences of this statement (or an equivalent statement) in\nthe theorem database or any human proof, not even as a local lemma.\nThese results suggest that self-supervised language models show some ability to produce new, useful\nconjectures, even without ﬁne tuning or specialized training.\n8\n7 Conclusion\nIn this work, we applied the paradigms of self-supervised language modeling to formal mathematics\nand show that this leads to surprisingly good reasoning capabilities. We introduced a novel self-\nsupervised training task for formal mathematics that outperforms existing training tasks used for\nnatural language. We also suggested several evaluation tasks for measuring mathematical reasoning\ncapabilities of language models for formal mathematics without the need of ﬁne tuning. Finally, we\nexplored the ability of language models to produce new conjectures by measuring how many of the\nnew predictions are provable and useful for other proofs.\nBroader Impact\nOur ambition is to create strong automated reasoning systems. In the long run, such systems could be\nused as a tool in mathematical research, engineering, and other sciences. Such systems could be used\nas stand alone tools, but also as a component of other systems that utilizes mathematical reasoning,\nsuch as in veriﬁcation of software and hardware systems and physical modeling and exploration. This\nshould be very helpful for accelerating scientiﬁc progress.\nIn its current form, however, the methods presented in the paper are not applicable directly to solving\nany particular scientiﬁc tasks. Therefore we do not anticipate any ethical or fairness issues arising\nfrom direct applications of the technologies presented here. However if our methods are trained for\nmimicking human reasoning in domains that argue over, for example, personal data, then it might\nreinforce human biases present in the dataset. On the other hand, the abstraction capabilities of our\nsystem might make those biases more explicit and interpretable and could help exposing them. As\npart of a larger software veriﬁcation system, some of the methods presented here might be used for\nautomated reverse engineering the internal working of other software systems, ﬁnding and exploiting\nvulnerabilities in them.\nReferences\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. Attention is all you need. In Isabelle Guyon, Ulrike von Luxburg,\nSamy Bengio, Hanna M. Wallach, Rob Fergus, S. V . N. Vishwanathan, and Roman Garnett, editors,\nAdvances in Neural Information Processing Systems 30: Annual Conference on Neural Information\nProcessing Systems 2017, 4-9 December 2017, Long Beach, CA, USA, pages 5998–6008, 2017.\nURL http://papers.nips.cc/paper/7181-attention-is-all-you-need .\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya\nSutskever. Language models are unsupervised multitask learners. In OpenAI\nBlog, 2018. URL https://d4mucfpksywv.cloudfront.net/better-language-models/\nlanguage_models_are_unsupervised_multitask_learners.pdf.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep\nbidirectional transformers for language understanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers), pages 4171–4186, 2019.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\nHerbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler,\nJeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott\nGray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\nSutskever, and Dario Amodei. Language models are few-shot learners, 2020. URL https:\n//arxiv.org/abs/2005.14165.\nKshitij Bansal, Sarah M Loos, Markus N Rabe, Christian Szegedy, and Stewart Wilcox. HOList:\nAn environment for machine learning of higher-order theorem proving. In Kamalika Chaudhuri\nand Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine\nLearning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings\n9\nof Machine Learning Research, pages 454–463. PMLR, 2019. URL http://proceedings.mlr.\npress/v97/bansal19a/bansal19a.pdf.\nJohn Harrison. HOL Light: A tutorial introduction. In Mandayam K. Srivas and Albert John\nCamilleri, editors, Formal Methods in Computer-Aided Design, First International Conference,\nFMCAD ’96, Palo Alto, California, USA, November 6-8, 1996, Proceedings , volume 1166 of\nLecture Notes in Computer Science, pages 265–269. Springer, 1996. URL https://doi.org/\n10.1007/BFb0031795.\nJingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. PEGASUS: pre-training with\nextracted gap-sentences for abstractive summarization. CoRR, abs/1912.08777, 2019. URL\nhttp://arxiv.org/abs/1912.08777.\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. MASS: masked sequence to se-\nquence pre-training for language generation. In Kamalika Chaudhuri and Ruslan Salakhutdinov,\neditors, Proceedings of the 36th International Conference on Machine Learning, ICML 2019,\n9-15 June 2019, Long Beach, California, USA , volume 97 of Proceedings of Machine Learn-\ning Research, pages 5926–5936. PMLR, 2019. URL http://proceedings.mlr.press/v97/\nsong19d.html.\nLi Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou,\nand Hsiao-Wuen Hon. Uniﬁed language model pre-training for natural language understanding and\ngeneration. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc,\nEmily B. Fox, and Roman Garnett, editors, Advances in Neural Information Processing Systems\n32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14\nDecember 2019, Vancouver, BC, Canada, pages 13042–13054, 2019.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uniﬁed text-to-text\ntransformer. CoRR, abs/1910.10683, 2019. URL http://arxiv.org/abs/1910.10683.\nAlexis Conneau and Guillaume Lample. Cross-lingual language model pretraining. In Hanna M.\nWallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc, Emily B. Fox, and Ro-\nman Garnett, editors, Advances in Neural Information Processing Systems 32: Annual Con-\nference on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019,\nVancouver, BC, Canada, pages 7057–7067, 2019. URL http://papers.nips.cc/paper/\n8928-cross-lingual-language-model-pretraining .\nMandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, and Omer Levy. Spanbert:\nImproving pre-training by representing and predicting spans. Transactions of the Association for\nComputational Linguistics, 8:64–77, 2020. doi: 10.1162/tacl\\_a\\_00300. URL https://doi.\norg/10.1162/tacl_a_00300.\nChin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text Summariza-\ntion Branches Out, pages 74–81, Barcelona, Spain, July 2004. Association for Computational\nLinguistics. URL https://www.aclweb.org/anthology/W04-1013.\nCezary Kaliszyk and Josef Urban. Learning-assisted automated reasoning with ﬂyspeck. Journal of\nAutomated Reasoning, 53(2):173–213, 2014.\nThibault Gauthier, Cezary Kaliszyk, and Josef Urban. TacticToe: Learning to reason with HOL4\ntactics. In Thomas Eiter and David Sands, editors, LPAR-21, 21st International Conference\non Logic for Programming, Artiﬁcial Intelligence and Reasoning, Maun, Botswana, May 7-\n12, 2017 , volume 46 of EPiC Series in Computing , pages 125–143. EasyChair, 2017. URL\nhttps://easychair.org/publications/volume/LPAR-21.\nDaniel Huang, Prafulla Dhariwal, Dawn Song, and Ilya Sutskever. GamePad: A learning environment\nfor theorem proving. In 7th International Conference on Learning Representations, ICLR 2019,\nNew Orleans, LA, USA, May 6-9, 2019 . OpenReview.net, 2019. URL https://openreview.\nnet/forum?id=r1xwKoR9Y7.\n10\nKaiyu Yang and Jia Deng. Learning to prove theorems via interacting with proof assistants. In\nKamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International\nConference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA ,\nvolume 97 of Proceedings of Machine Learning Research, pages 6984–6994. PMLR, 2019. URL\nhttp://proceedings.mlr.press/v97/yang19a/yang19a.pdf.\nAlex Sanchez-Stern, Yousef Alhessi, Lawrence Saul, and Sorin Lerner. Generating correctness\nproofs with neural networks. CoRR, abs/1907.07794, 2019. URL http://arxiv.org/abs/\n1907.07794.\nGuillaume Lample and François Charton. Deep learning for symbolic mathematics. In 8th Interna-\ntional Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30,\n2020. OpenReview.net, 2020. URL https://openreview.net/forum?id=Ske31kBtPr.\nBernd Finkbeiner, Christopher Hahn, Markus N. Rabe, and Frederik Schmitt. Teaching temporal\nlogics to neural networks. CoRR, abs/2003.04218, 2020. URL https://arxiv.org/abs/2003.\n04218.\nBartosz Piotrowski, Josef Urban, Chad E Brown, and Cezary Kaliszyk. Can neural networks learn\nsymbolic rewriting? In Conference on Artiﬁcial Intelligence and Theorem Proving, 2019.\nQingxiang Wang, Cezary Kaliszyk, and Josef Urban. First experiments with neural translation of\ninformal to formal mathematics. In International Conference on Intelligent Computer Mathematics,\npages 255–270, 2018.\nQingxiang Wang, Chad Brown, Cezary Kaliszyk, and Josef Urban. Exploration of neural machine\ntranslation in autoformalization of mathematics in Mizar. InProceedings of the 9th ACM SIGPLAN\nInternational Conference on Certiﬁed Programs and Proofs, pages 85–98, 2020.\nGuillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc’Aurelio Ranzato. Unsupervised\nmachine translation using monolingual corpora only. In International Conference on Learning\nRepresentations, 2018.\nJosef Urban and Jan Jakub˚ uv. First neural conjecturing datasets and experiments. InConference on\nIntelligent Computer Mathematics, 2020.\nThibault Gauthier, Cezary Kaliszyk, and Josef Urban. Initial experiments with statistical conjecturing\nover large formal corpora. In CICM 2016 - Work in Progress Proceedings 1785, pages 219–228,\n2016.\nWenda Li, Lei Yu, Yuhuai Wu, and Lawrence C. Paulson. Modelling high-level mathematical\nreasoning in mechanised declarative proofs. In arXiv 2006.09265, 2020.\nVighnesh Leonardo Shiv and Chris Quirk. Novel positional encodings to enable tree-based transform-\ners. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc, Emily B.\nFox, and Roman Garnett, editors, Advances in Neural Information Processing Systems 32: Annual\nConference on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019,\nVancouver, BC, Canada, pages 12058–12068, 2019. URL http://papers.nips.cc/paper/\n9376-novel-positional-encodings-to-enable-tree-based-transformers .\nVincent J. Hellendoorn, Charles Sutton, Rishabh Singh, Petros Maniatis, and David Bieber. Global\nrelational models of source code. In 8th International Conference on Learning Representations,\nICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020 . OpenReview.net, 2020. URL https:\n//openreview.net/forum?id=B1lnbRNtwr.\nPaul Cairns. Informalising formal mathematics: Searching the mizar library with latent semantics. In\nInternational Conference on Mathematical Knowledge Management, pages 58–72. Springer, 2004.\nJosef Urban. Mptp–motivation, implementation, ﬁrst experiments. Journal of Automated Reasoning,\n33(3-4):319–339, 2004.\n11\nA Hyperparameters\nWe trained the Transformers with these hyperparameters:\n• vocabulary size: 1200\n• embedding size: 128\n• attention dropout: 0.1\n• nonlinearity: gelu\n• hidden layer dropout: 0.1\n• hidden layer size: 512\n• initializer range: 0.02\n• intermediate size: 768\n• number of attention heads: 8\n• number of hidden layers in encoder: 2\n• number of hidden layers in decoder: 4\nB Usage Statistics of Conjectures\nFigure 3: Histograms of premise usage of the conjectures generated through the assumptions task\n(left), the equality task (middle), and through free-form conjecturing (right). X-axes are the new\ntheorems, sorted by number of usages. Y-axes indicate the number of usages on a log scale.\nC A Close Look at Simple Example Tasks\nAssumptions. In Section 5 we presented the following three examples of the task to predict missing\nassumptions. For the sake of readability we here discuss only the pretty printed versions. For\nexamples in s-expression syntax, please visit Appendix D.\n• <PREDICT> ⇒(x ⇔( b ∨x1) ∧(b ∨x0))\n• <PREDICT> ⇒(g \\{s}) =g\n• <PREDICT> ⇒(x1/y1 =x2/y2 ⇔ x1 ∗y2 =x2 ∗y1)\nThe ground truth answers are as follows:\n• ((b ⇔False) ⇒(x ⇔x0)) ∧(b ⇔True) ⇒(x ⇔x1)\n• ¬(s ∈g)\n• 0 < y1 ∧0 < y2, note that 0 ̸= y1 ∧0 ̸= y2 would be a more general assumption.\nFor the ﬁrst and the third task, the language model “skip-tree (weighted)” makes a correct prediction\nin the top 3 candidates in a beam search of width 8. For the seconds task, the language model mostly\nproduces incorrectly typed expressions: it appears to think that s is a set of the same type as g.\n12\nEqualities. We presented these examples for the equality evaluation task:\n• ∀x, n∈N : (xn = 1) =<PREDICT>\n• ∀m, n: n ≤m ⇒m −n + n = <PREDICT>\n• ∀l, m: <PREDICT> = APPEND(REVERSE(m), REVERSE(l))\nThe ground truth for the tasks is:\n• x = 1∨n = 0\n• m\n• REVERSE(APPEND(l, m))\nExamples two and three are predicted correctly in a beam search with beam width 8. For the ﬁrst\nexample, the model almost gets it correct in two of the 8 attempts:x = 1∨n = 1, and x = 0∨n = 1.\nWe ﬁnd it surprising that the model apparently understands that there are two cases to consider, but\nthat the exact combination of constants (1 and 0) is a challenge.\nD Randomly Selected Example Tasks\nIn the following, we provide a list of 5 examples for each of the evaluation tasks, sampled uniformly\nat random.\nType Inference.\n• (<theorem> (a (c <PREDICT> !) (l (v (fun (cart (real) ?1) (bool))\nt) (a (c (fun (fun (fun (cart (real) ?1) (bool)) (bool)) (bool)) !)\n(l (v (fun (cart (real) ?1) (bool)) u) (a (a (c (fun (bool) (fun\n(bool) (bool))) ==>) (a (a (c (fun (bool) (fun (bool) (bool))) ∧) (a\n(c (fun (fun (cart (real) ?1) (bool)) (bool)) !) (l (v (cart (real)\n?1) b) (a (a (c (fun (bool) (fun (bool) (bool))) ∨) (a (c (fun (fun\n(cart (real) ?1) (bool)) (bool)) ?) (l (v (cart (real) ?1) w) (a (a\n(c (fun (bool) (fun (bool) (bool))) ∧) (a (a (c (fun (cart (real)\n?1) (fun (fun (cart (real) ?1) (bool)) (bool))) IN) (v (cart (real)\n?1) w)) (v (fun (cart (real) ?1) (bool)) t))) (a (a (c (fun (cart\n(real) ?1) (fun (fun (cart (real) ?1) (bool)) (bool))) IN) (v (cart\n(real) ?1) w)) (a (c (fun (prod (cart (real) ?1) (real)) (fun (cart\n(real) ?1) (bool))) ball) (a (a (c (fun (cart (real) ?1) (fun (real)\n(prod (cart (real) ?1) (real)))) ,) (v (cart (real) ?1) b)) (a (c\n(fun (num) (real)) real_of_num) (a (c (fun (num) (num)) NUMERAL) (a\n(c (fun (num) (num)) BIT1) (c (num) _0))))))))))) (a (c (fun (fun\n(cart (real) ?1) (bool)) (bool)) ?) (l (v (cart (real) ?1) w) (a (a\n(c (fun (bool) (fun (bool) (bool))) ∧) (a (a (c (fun (cart (real)\n?1) (fun (fun (cart (real) ?1) (bool)) (bool))) IN) (v (cart (real)\n?1) w)) (v (fun (cart (real) ?1) (bool)) u))) (a (a (c (fun (cart\n(real) ?1) (fun (fun (cart (real) ?1) (bool)) (bool))) IN) (v (cart\n(real) ?1) w)) (a (c (fun (prod (cart (real) ?1) (real)) (fun (cart\n(real) ?1) (bool))) ball) (a (a (c (fun (cart (real) ?1) (fun (real)\n(prod (cart (real) ?1) (real)))) ,) (v (cart (real) ?1) b)) (a (c\n(fun (num) (real)) real_of_num) (a (c (fun (num) (num)) NUMERAL) (a\n(c (fun (num) (num)) BIT1) (c (num) _0)))))))))))))) (a (c (fun (fun\n?0 (bool)) (bool)) !) (l (v ?0 x) (a (a (c (fun (bool) (fun (bool)\n(bool))) ==>) (a (a (c (fun ?0 (fun (fun ?0 (bool)) (bool))) IN) (v\n?0 x)) (v (fun ?0 (bool)) d))) (a (c (fun (bool) (bool)) ∼) (a (a\n(c (fun (cart (real) ?1) (fun (fun (cart (real) ?1) (bool)) (bool)))\nIN) (a (v (fun ?0 (cart (real) ?1)) g) (v ?0 x))) (a (a (c (fun (fun\n(cart (real) ?1) (bool)) (fun (fun (cart (real) ?1) (bool)) (fun\n(cart (real) ?1) (bool)))) UNION) (v (fun (cart (real) ?1) (bool))\nt)) (v (fun (cart (real) ?1) (bool)) u))))))))) (a (c (fun (bool)\n13\n(bool)) ∼) (a (c (fun (fun (cart (real) ?1) (bool)) (bool)) ?) (l\n(v (cart (real) ?1) b) (a (a (c (fun (fun (cart (real) ?1) (bool))\n(fun (fun (cart (real) ?1) (bool)) (bool))) SUBSET) (a (c (fun (prod\n(cart (real) ?1) (real)) (fun (cart (real) ?1) (bool))) ball) (a (a\n(c (fun (cart (real) ?1) (fun (real) (prod (cart (real) ?1) (real))))\n,) (v (cart (real) ?1) b)) (a (c (fun (num) (real)) real_of_num)\n(a (c (fun (num) (num)) NUMERAL) (a (c (fun (num) (num)) BIT1) (c\n(num) _0))))))) (a (a (c (fun (fun ?0 (cart (real) ?1)) (fun (fun\n?0 (bool)) (fun (cart (real) ?1) (bool)))) IMAGE) (v (fun ?0 (cart\n(real) ?1)) g)) (v (fun ?0 (bool)) d))))))))))))\nGround truth: <START> (fun (fun (fun (cart (real) ?1) (bool)) (bool))\n(bool)) <END>\n• (<theorem> (a (c <PREDICT> !) (l (v (fun (cart (real) N) (bool))\ns) (a (a (c (fun (bool) (fun (bool) (bool))) =) (a (c (fun (fun\n(cart (real) N) (bool)) (bool)) is_interval) (a (a (c (fun (fun\n(cart (real) N) (cart (real) N)) (fun (fun (cart (real) N) (bool))\n(fun (cart (real) N) (bool)))) IMAGE) (c (fun (cart (real) N) (cart\n(real) N)) vector_neg)) (v (fun (cart (real) N) (bool)) s)))) (a (c\n(fun (fun (cart (real) N) (bool)) (bool)) is_interval) (v (fun (cart\n(real) N) (bool)) s))))))\nGround truth: <START> (fun (fun (fun (cart (real) N) (bool)) (bool))\n(bool)) <END>\n• (<theorem> (a (c (fun (fun (real) (bool)) (bool)) !) (l (v (real) x)\n(a (a (a (c (fun (fun (real) (real)) (fun (real) (fun (net (real))\n(bool)))) has_real_derivative) (c (fun (real) (real)) atn)) (a\n(c (fun (real) (real)) real_inv) (a (a (c (fun (real) (fun (real)\n(real))) real_add) (a (c (fun (num) (real)) real_of_num) (a (c (fun\n(num) (num)) NUMERAL) (a (c (fun (num) (num)) BIT1) (c (num) _0)))))\n(a (a (c (fun (real) (fun (num) (real))) real_pow) (v <PREDICT> x))\n(a (c (fun (num) (num)) NUMERAL) (a (c (fun (num) (num)) BIT0) (a (c\n(fun (num) (num)) BIT1) (c (num) _0)))))))) (a (c (fun (real) (net\n(real))) atreal) (v (real) x))))))\nGround truth: <START> (real) <END>\n• (<theorem> (a (a (c (fun (fun ?0 (bool)) (fun (fun ?0 (bool))\n(bool))) =) (a (a (c (fun (fun ?0 (bool)) (fun (fun ?0 (bool)) (fun\n?0 (bool)))) INTER) (v (fun ?0 (bool)) s)) (a (a (c (fun (fun ?0\n(bool)) (fun (fun ?0 (bool)) (fun ?0 (bool)))) UNION) (v (fun ?0\n(bool)) t)) (v (fun ?0 (bool)) u)))) (a (a (c (fun (fun ?0 (bool))\n(fun (fun ?0 (bool)) (fun ?0 (bool)))) UNION) (a (a (c <PREDICT>\nINTER) (v (fun ?0 (bool)) s)) (v (fun ?0 (bool)) t))) (a (a (c (fun\n(fun ?0 (bool)) (fun (fun ?0 (bool)) (fun ?0 (bool)))) INTER) (v\n(fun ?0 (bool)) s)) (v (fun ?0 (bool)) u)))))\nGround truth: <START> (fun (fun ?0 (bool)) (fun (fun ?0 (bool)) (fun ?0\n(bool)))) <END>\n• (<theorem> (a (a (c (fun (real) (fun (real) (bool))) =) (a (c (fun\n(cart (real) ?0) (real)) infnorm) (a (c (fun (num) (cart (real)\n?0)) vec) (a (c (fun (num) (num)) NUMERAL) (c (num) _0))))) (a (c\n(fun (num) (real)) real_of_num) (a (c (fun (num) (num)) NUMERAL) (c\n<PREDICT> _0)))))\nGround truth: <START> (num) <END>\nHard Type Inference.\n• (<theorem> (a (c <MASK> !) (l (v <MASK> s) (a (a (c <MASK> =)\n(a (c <MASK> INTERS) (v <MASK> s))) (a (a (c <PREDICT> DIFF) (c\n<MASK> UNIV)) (a (c <MASK> UNIONS) (a (c <MASK> GSPEC) (l (v <MASK>\nGEN%PVAR%0) (a (c <MASK> ?) (l (v <MASK> t) (a (a (a (c <MASK>\n14\nSETSPEC) (v <MASK> GEN%PVAR%0)) (a (a (c <MASK> IN) (v <MASK> t))\n(v <MASK> s))) (a (a (c <MASK> DIFF) (c <MASK> UNIV)) (v <MASK>\nt)))))))))))))\nGround truth: <START> (fun (fun ?0 (bool)) (fun (fun ?0 (bool)) (fun ?0\n(bool)))) <END>\n• (<theorem> (a (c <MASK> !) (l (v <MASK> f) (a (c <MASK> !) (l (v\n<MASK> s) (a (a (c <MASK> =) (a (a (c <MASK> uniformly_continuous_on)\n(v <MASK> f)) (v <MASK> s))) (a (c <MASK> !) (l (v <MASK> e) (a (a\n(c <MASK> ==>) (a (a (c <MASK> real_lt) (a (c <MASK> real_of_num)\n(a (c <MASK> NUMERAL) (c <MASK> _0)))) (v <MASK> e))) (a (c <MASK>\n?) (l (v <MASK> d) (a (a (c <MASK> ∧) (a (a (c <MASK> real_lt)\n(a (c <MASK> real_of_num) (a (c <MASK> NUMERAL) (c <MASK> _0))))\n(v <MASK> d))) (a (c <MASK> !) (l (v <MASK> t) (a (c <MASK> !)\n(l (v <MASK> t’) (a (a (c <MASK> ==>) (a (a (c <MASK> ∧) (a (a\n(c <MASK> SUBSET) (v <MASK> t)) (v <MASK> s))) (a (a (c <MASK> ∧)\n(a (a (c <MASK> SUBSET) (v <PREDICT> t’)) (v <MASK> s))) (a (a (c\n<MASK> ∧) (a (c <MASK> bounded) (v <MASK> t))) (a (a (c <MASK> ∧)\n(a (c <MASK> bounded) (v <MASK> t’))) (a (a (c <MASK> real_lt) (a (c\n<MASK> hausdist) (a (a (c <MASK> ,) (v <MASK> t’)) (v <MASK> t))))\n(v <MASK> d))))))) (a (a (c <MASK> real_lt) (a (c <MASK> hausdist)\n(a (a (c <MASK> ,) (a (a (c <MASK> IMAGE) (v <MASK> f)) (v <MASK>\nt’))) (a (a (c <MASK> IMAGE) (v <MASK> f)) (v <MASK> t))))) (v <MASK>\ne)))))))))))))))))))\nGround truth: <START> (fun (cart (real) M) (bool)) <END>\n• (<theorem> (a (a (c <MASK> ==>) (a (a (c <PREDICT> IN) (v <MASK> a))\n(v <MASK> s))) (a (a (c <MASK> =) (a (a (c <MASK> DIFF) (a (a (c\n<MASK> INSERT) (v <MASK> a)) (a (a (c <MASK> DELETE) (v <MASK> t)) (v\n<MASK> b)))) (v <MASK> s))) (a (a (c <MASK> DELETE) (a (a (c <MASK>\nDIFF) (v <MASK> t)) (v <MASK> s))) (v <MASK> b)))))\nGround truth: <START> (fun ?0 (fun (fun ?0 (bool)) (bool))) <END>\n• (<theorem> (a (c <MASK> !) (l (v <PREDICT> b) (a (c <MASK> convex)\n(a (c <MASK> GSPEC) (l (v <MASK> GEN%PVAR%0) (a (c <MASK> ?) (l (v\n<MASK> z) (a (a (a (c <MASK> SETSPEC) (v <MASK> GEN%PVAR%0)) (a (a\n(c <MASK> real_gt) (a (c <MASK> Im) (v <MASK> z))) (v <MASK> b))) (v\n<MASK> z))))))))))\nGround truth: <START> (real) <END>\n• (<theorem> (a (c <MASK> !) (l (v <MASK> x) (a (a (c <MASK> ==>) (a\n(c <MASK> ∼) (a (a (c <MASK> nadd_eq) (v <MASK> x)) (a (c <MASK>\nnadd_of_num) (a (c <MASK> NUMERAL) (c <MASK> _0)))))) (a (c <MASK>\n?) (l (v <MASK> B) (a (c <MASK> ?) (l (v <MASK> N) (a (c <MASK> !)\n(l (v <MASK> m) (a (c <MASK> !) (l (v <MASK> n) (a (a (c <MASK> ==>)\n(a (a (c <MASK> ∧) (a (a (c <MASK> <=) (v <MASK> N)) (v <MASK> m)))\n(a (a (c <MASK> <=) (v <MASK> N)) (v <MASK> n)))) (a (a (c <MASK> <=)\n(a (a (c <MASK> *) (a (a (c <MASK> *) (a (a (c <MASK> dest_nadd) (v\n<MASK> x)) (v <MASK> m))) (a (a (c <MASK> dest_nadd) (v <MASK> x)) (v\n<MASK> n)))) (a (c <MASK> dist) (a (a (c <MASK> ,) (a (a (c <MASK> *)\n(v <MASK> m)) (a (a (c <MASK> nadd_rinv) (v <MASK> x)) (v <PREDICT>\nn)))) (a (a (c <MASK> *) (v <MASK> n)) (a (a (c <MASK> nadd_rinv) (v\n<MASK> x)) (v <MASK> m))))))) (a (a (c <MASK> *) (v <MASK> B)) (a (a\n(c <MASK> *) (a (a (c <MASK> *) (v <MASK> m)) (v <MASK> n))) (a (a\n(c <MASK> +) (v <MASK> m)) (v <MASK> n))))))))))))))))))\nGround truth: <START> (num) <END>\nAssumptions.\n• Prompt: (<theorem> (a (a (c (fun (bool) (fun (bool) (bool))) ==>) (a\n(a (c (fun (fun ?1 (bool)) (fun (fun ?1 (bool)) (bool))) =) (a (c\n15\n(fun (fun ?1 (bool)) (fun ?1 (bool))) GSPEC) (l (v ?1 GEN%PVAR%0) (a\n(c (fun (fun ?1 (bool)) (bool)) ?) (l (v ?1 x) (a (a (a (c (fun ?1\n(fun (bool) (fun ?1 (bool)))) SETSPEC) (v ?1 GEN%PVAR%0)) (a (a (c\n(fun (bool) (fun (bool) (bool))) ∧) (a (a (c (fun ?1 (fun (fun ?1\n(bool)) (bool))) IN) (v ?1 x)) (v (fun ?1 (bool)) s))) (a (a (c (fun\n?0 (fun ?0 (bool))) =) (a (v (fun ?1 ?0) f) (v ?1 x))) (v ?0 a))))\n(v ?1 x))))))) (v (fun ?1 (bool)) t))) (a (a (c (fun (bool) (fun\n(bool) (bool))) ==>) <PREDICT>) (a (c (fun (fun ?1 (bool)) (bool)) !)\n(l (v ?1 x) (a (a (c (fun (bool) (fun (bool) (bool))) ==>) (a (a (c\n(fun (bool) (fun (bool) (bool))) ∧) (a (v (fun ?1 (bool)) P) (v ?1\nx))) (a (v (fun ?1 (bool)) Q) (v ?1 x)))) (a (c (fun (bool) (bool))\n∼) (a (a (c (fun ?0 (fun ?0 (bool))) =) (a (v (fun ?1 ?0) f) (v ?1\nx))) (v ?0 a)))))))))\nGround truth: <START> (a (a (c (fun (bool) (fun (bool) (bool))) ∧) (a\n(c (fun (fun ?1 (bool)) (bool)) !) (l (v ?1 x) (a (a (c (fun (bool)\n(fun (bool) (bool))) ==>) (a (v (fun ?1 (bool)) P) (v ?1 x))) (a (a\n(c (fun ?1 (fun (fun ?1 (bool)) (bool))) IN) (v ?1 x)) (v (fun ?1\n(bool)) s)))))) (a (c (fun (fun ?1 (bool)) (bool)) !) (l (v ?1 x)\n(a (a (c (fun (bool) (fun (bool) (bool))) ==>) (a (a (c (fun (bool)\n(fun (bool) (bool))) ∧) (a (v (fun ?1 (bool)) P) (v ?1 x))) (a (v\n(fun ?1 (bool)) Q) (v ?1 x)))) (a (c (fun (bool) (bool)) ∼) (a (a\n(c (fun ?1 (fun (fun ?1 (bool)) (bool))) IN) (v ?1 x)) (v (fun ?1\n(bool)) t))))))) <END>\nSource theorem pretty printed: {x | x IN s ∧ f x = a} = t ==> (!x. P x ==>\nx IN s) ∧ (!x. P x ∧ Q x ==> ∼(x IN t)) ==> (!x. P x ∧ Q x ==>\n∼(f x = a))\n• Prompt: (<theorem> (a (c (fun (fun (fun (cart (real) N) (bool))\n(bool)) (bool)) !) (l (v (fun (cart (real) N) (bool)) s) (a (a (c\n(fun (bool) (fun (bool) (bool))) ==>) <PREDICT>) (a (a (c (fun (fun\n(cart (real) N) (bool)) (fun (fun (cart (real) N) (bool)) (bool))) =)\n(a (c (fun (fun (cart (real) N) (bool)) (fun (cart (real) N) (bool)))\ninside) (v (fun (cart (real) N) (bool)) s))) (c (fun (cart (real) N)\n(bool)) EMPTY))))))\nGround truth: <START> (a (a (c (fun (bool) (fun (bool) (bool))) ∧)\n(a (c (fun (fun (cart (real) N) (bool)) (bool)) connected) (a (a (c\n(fun (fun (cart (real) N) (bool)) (fun (fun (cart (real) N) (bool))\n(fun (cart (real) N) (bool)))) DIFF) (c (fun (cart (real) N) (bool))\nUNIV)) (v (fun (cart (real) N) (bool)) s)))) (a (c (fun (bool)\n(bool)) ∼) (a (c (fun (fun (cart (real) N) (bool)) (bool)) bounded)\n(a (a (c (fun (fun (cart (real) N) (bool)) (fun (fun (cart (real) N)\n(bool)) (fun (cart (real) N) (bool)))) DIFF) (c (fun (cart (real) N)\n(bool)) UNIV)) (v (fun (cart (real) N) (bool)) s))))) <END>\nSource theorem pretty printed: !s. connected ((:real ˆN) DIFF s) ∧ ∼bounded\n((:realˆN) DIFF s) ==> inside s = {}\n• Prompt: (<theorem> (a (a (c (fun (bool) (fun (bool) (bool))) ==>) (a\n(a (c (fun (bool) (fun (bool) (bool))) ∧) (v (bool) q)) (a (c (fun\n(bool) (bool)) ∼) (v (bool) p)))) (a (a (c (fun (bool) (fun (bool)\n(bool))) ==>) <PREDICT>) (v (bool) r))))\nGround truth: <START> (a (a (c (fun (bool) (fun (bool) (bool))) =) (v\n(bool) p)) (v (bool) q)) <END>\nSource theorem pretty printed: q ∧ ∼p ==> (p <=> q) ==> r\n• Prompt: (<theorem> (a (c (fun (fun (fun (cart (real) N) (real))\n(bool)) (bool)) !) (l (v (fun (cart (real) N) (real)) f) (a (c\n(fun (fun (fun (real) (real)) (bool)) (bool)) !) (l (v (fun (real)\n(real)) g) (a (c (fun (fun (cart (real) N) (bool)) (bool)) !) (l\n(v (cart (real) N) x) (a (a (c (fun (bool) (fun (bool) (bool)))\n==>) <PREDICT>) (a (a (c (fun (fun (cart (real) N) (real)) (fun\n16\n(net (cart (real) N)) (bool))) real_continuous) (a (a (c (fun (fun\n(real) (real)) (fun (fun (cart (real) N) (real)) (fun (cart (real)\nN) (real)))) o) (v (fun (real) (real)) g)) (v (fun (cart (real) N)\n(real)) f))) (a (c (fun (cart (real) N) (net (cart (real) N))) at) (v\n(cart (real) N) x)))))))))))\nGround truth: <START> (a (a (c (fun (bool) (fun (bool) (bool))) ∧) (a\n(a (c (fun (fun (cart (real) N) (real)) (fun (net (cart (real) N))\n(bool))) real_continuous) (v (fun (cart (real) N) (real)) f)) (a (c\n(fun (cart (real) N) (net (cart (real) N))) at) (v (cart (real) N)\nx)))) (a (a (c (fun (fun (real) (real)) (fun (net (real)) (bool)))\nreal_continuous) (v (fun (real) (real)) g)) (a (a (c (fun (net\n(real)) (fun (fun (real) (bool)) (net (real)))) within) (a (c (fun\n(real) (net (real))) atreal) (a (v (fun (cart (real) N) (real)) f)\n(v (cart (real) N) x)))) (a (a (c (fun (fun (cart (real) N) (real))\n(fun (fun (cart (real) N) (bool)) (fun (real) (bool)))) IMAGE) (v\n(fun (cart (real) N) (real)) f)) (c (fun (cart (real) N) (bool))\nUNIV))))) <END>\nSource theorem pretty printed: !f g x. f real_continuous at x ∧ g\nreal_continuous atreal (f x) within IMAGE f (:realˆN) ==> g o f\nreal_continuous at x\n• Prompt: (<theorem> (a (c (fun (fun (fun (cart (real) M) (cart (real)\nN)) (bool)) (bool)) !) (l (v (fun (cart (real) M) (cart (real) N))\nf) (a (c (fun (fun (fun (cart (real) M) (cart (real) P)) (bool))\n(bool)) !) (l (v (fun (cart (real) M) (cart (real) P)) g) (a (c\n(fun (fun (fun (cart (real) M) (bool)) (bool)) (bool)) !) (l (v\n(fun (cart (real) M) (bool)) s) (a (c (fun (fun (num) (bool)) (bool))\n!) (l (v (num) n) (a (a (c (fun (bool) (fun (bool) (bool))) ==>)\n<PREDICT>) (a (a (a (c (fun (num) (fun (fun (cart (real) M) (bool))\n(fun (fun (cart (real) M) (cart (real) (finite_sum N P))) (bool))))\nbaire) (v (num) n)) (v (fun (cart (real) M) (bool)) s)) (l (v (cart\n(real) M) x) (a (a (c (fun (cart (real) N) (fun (cart (real) P)\n(cart (real) (finite_sum N P)))) pastecart) (a (v (fun (cart (real)\nM) (cart (real) N)) f) (v (cart (real) M) x))) (a (v (fun (cart\n(real) M) (cart (real) P)) g) (v (cart (real) M) x)))))))))))))))\nGround truth: <START> (a (a (c (fun (bool) (fun (bool) (bool))) ∧)\n(a (a (a (c (fun (num) (fun (fun (cart (real) M) (bool)) (fun (fun\n(cart (real) M) (cart (real) N)) (bool)))) baire) (v (num) n)) (v\n(fun (cart (real) M) (bool)) s)) (v (fun (cart (real) M) (cart (real)\nN)) f))) (a (a (a (c (fun (num) (fun (fun (cart (real) M) (bool))\n(fun (fun (cart (real) M) (cart (real) P)) (bool)))) baire) (v (num)\nn)) (v (fun (cart (real) M) (bool)) s)) (v (fun (cart (real) M)\n(cart (real) P)) g))) <END>\nSource theorem pretty printed: !f g s n. baire n s f ∧ baire n s g ==>\nbaire n s (lambda x. pastecart (f x) (g x))\nEqualities.\n• Prompt: (<theorem> (a (c (fun (fun (fun ?0 (cart (real) (2))) (bool))\n(bool)) !) (l (v (fun ?0 (cart (real) (2))) f) (a (c (fun (fun (fun\n?0 (cart (real) (2))) (bool)) (bool)) !) (l (v (fun ?0 (cart (real)\n(2))) g) (a (c (fun (fun (fun ?0 (bool)) (bool)) (bool)) !) (l (v\n(fun ?0 (bool)) s) (a (a (c (fun (bool) (fun (bool) (bool))) ==>)\n(a (c (fun (fun ?0 (bool)) (bool)) FINITE) (v (fun ?0 (bool)) s)))\n(a (a (c (fun (cart (real) (2)) (fun (cart (real) (2)) (bool))) =)\n(a (a (c (fun (fun ?0 (bool)) (fun (fun ?0 (cart (real) (2))) (cart\n(real) (2)))) cproduct) (v (fun ?0 (bool)) s)) (l (v ?0 x) (a (a (c\n(fun (cart (real) (2)) (fun (cart (real) (2)) (cart (real) (2))))\n17\ncomplex_mul) (a (v (fun ?0 (cart (real) (2))) f) (v ?0 x))) (a (v\n(fun ?0 (cart (real) (2))) g) (v ?0 x)))))) <PREDICT>)))))))))\nGround truth: <START> (a (a (c (fun (cart (real) (2)) (fun (cart (real)\n(2)) (cart (real) (2)))) complex_mul) (a (a (c (fun (fun ?0 (bool))\n(fun (fun ?0 (cart (real) (2))) (cart (real) (2)))) cproduct) (v\n(fun ?0 (bool)) s)) (v (fun ?0 (cart (real) (2))) f))) (a (a (c (fun\n(fun ?0 (bool)) (fun (fun ?0 (cart (real) (2))) (cart (real) (2))))\ncproduct) (v (fun ?0 (bool)) s)) (v (fun ?0 (cart (real) (2))) g)))\n<END>\nSource theorem pretty printed: !f g s. FINITE s ==> cproduct s ( \\x. f x *\ng x) = cproduct s f * cproduct s g\n• Prompt: (<theorem> (a (c (fun (fun (fun (cart (real) N) (bool))\n(bool)) (bool)) !) (l (v (fun (cart (real) N) (bool)) s) (a (c (fun\n(fun (fun (cart (real) N) (bool)) (bool)) (bool)) !) (l (v (fun\n(cart (real) N) (bool)) t) (a (a (c (fun (bool) (fun (bool) (bool)))\n==>) (a (a (c (fun (bool) (fun (bool) (bool))) ∧) (a (c (fun (fun\n(cart (real) N) (bool)) (bool)) convex) (v (fun (cart (real) N)\n(bool)) s))) (a (a (c (fun (bool) (fun (bool) (bool))) ∧) (a (c (fun\n(fun (cart (real) N) (bool)) (bool)) affine) (v (fun (cart (real) N)\n(bool)) t))) (a (c (fun (bool) (bool)) ∼) (a (a (c (fun (fun (cart\n(real) N) (bool)) (fun (fun (cart (real) N) (bool)) (bool))) =) (a\n(a (c (fun (fun (cart (real) N) (bool)) (fun (fun (cart (real) N)\n(bool)) (fun (cart (real) N) (bool)))) INTER) (a (c (fun (fun (cart\n(real) N) (bool)) (fun (cart (real) N) (bool))) relative_interior)\n(v (fun (cart (real) N) (bool)) s))) (v (fun (cart (real) N) (bool))\nt))) (c (fun (cart (real) N) (bool)) EMPTY)))))) (a (a (c (fun (fun\n(cart (real) N) (bool)) (fun (fun (cart (real) N) (bool)) (bool))) =)\n<PREDICT>) (a (a (c (fun (fun (cart (real) N) (bool)) (fun (fun (cart\n(real) N) (bool)) (fun (cart (real) N) (bool)))) INTER) (a (c (fun\n(fun (cart (real) N) (bool)) (fun (cart (real) N) (bool))) closure)\n(v (fun (cart (real) N) (bool)) s))) (v (fun (cart (real) N) (bool))\nt)))))))))\nGround truth: <START> (a (c (fun (fun (cart (real) N) (bool)) (fun\n(cart (real) N) (bool))) closure) (a (a (c (fun (fun (cart (real)\nN) (bool)) (fun (fun (cart (real) N) (bool)) (fun (cart (real) N)\n(bool)))) INTER) (v (fun (cart (real) N) (bool)) s)) (v (fun (cart\n(real) N) (bool)) t))) <END>\nSource theorem pretty printed: !s t. convex s ∧ affine t ∧\n∼(relative_interior s INTER t = {}) ==> closure (s INTER t) =\nclosure s INTER t\n• Prompt: (<theorem> (a (a (c (fun (bool) (fun (bool) (bool))) ==>)\n(a (a (c (fun (fun ?0 (bool)) (fun (fun ?0 (bool)) (bool))) SUBSET)\n(v (fun ?0 (bool)) t)) (a (a (c (fun (fun ?0 (bool)) (fun (fun ?0\n(bool)) (fun ?0 (bool)))) DIFF) (c (fun ?0 (bool)) UNIV)) (v (fun\n?0 (bool)) s)))) (a (a (c (fun (fun ?0 (bool)) (fun (fun ?0 (bool))\n(bool))) =) <PREDICT>) (c (fun ?0 (bool)) EMPTY))))\nGround truth: <START> (a (a (c (fun (fun ?0 (bool)) (fun (fun ?0 (bool))\n(fun ?0 (bool)))) INTER) (v (fun ?0 (bool)) s)) (v (fun ?0 (bool))\nt)) <END>\nSource theorem pretty printed: t SUBSET (:?0) DIFF s ==> s INTER t = {}\n• Prompt: (<theorem> (a (c (fun (fun (real) (bool)) (bool)) !) (l (v\n(real) x) (a (a (c (fun (real) (fun (real) (bool))) =) <PREDICT>) (a\n(c (fun (real) (real)) real_abs) (v (real) x))))))\nGround truth: <START> (a (a (c (fun (real) (fun (num) (real))) real_pow)\n(a (c (fun (real) (real)) sqrt) (v (real) x))) (a (c (fun (num)\n(num)) NUMERAL) (a (c (fun (num) (num)) BIT0) (a (c (fun (num) (num))\nBIT1) (c (num) _0))))) <END>\n18\nSource theorem pretty printed: !x. sqrt x pow 2 = abs x\n• Prompt: (<theorem> (a (a (c (fun (fun A (bool)) (fun (fun A (bool))\n(bool))) =) <PREDICT>) (a (c (fun (fun A (bool)) (fun A (bool)))\nGSPEC) (l (v A GEN%PVAR%0) (a (c (fun (fun A (bool)) (bool)) ?) (l\n(v A y) (a (a (a (c (fun A (fun (bool) (fun A (bool)))) SETSPEC) (v\nA GEN%PVAR%0)) (a (a (c (fun (bool) (fun (bool) (bool))) ∧) (a (a (c\n(fun A (fun (fun A (bool)) (bool))) IN) (v A y)) (v (fun A (bool))\ns))) (a (a (c (fun A (fun A (bool))) =) (v A y)) (v A x)))) (v A\ny))))))))\nGround truth: <START> (a (a (c (fun A (fun (fun A (bool)) (fun A\n(bool)))) INSERT) (v A x)) (v (fun A (bool)) s)) <END>\nSource theorem pretty printed: x INSERT s = {y | y IN s ∧ y = x}\n19",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.714051365852356
    },
    {
      "name": "Inference",
      "score": 0.6235586404800415
    },
    {
      "name": "Task (project management)",
      "score": 0.5684143900871277
    },
    {
      "name": "Logical reasoning",
      "score": 0.49619919061660767
    },
    {
      "name": "Artificial intelligence",
      "score": 0.48880836367607117
    },
    {
      "name": "Language model",
      "score": 0.4787934720516205
    },
    {
      "name": "Formal language",
      "score": 0.43894559144973755
    },
    {
      "name": "Object language",
      "score": 0.4212472140789032
    },
    {
      "name": "Natural language processing",
      "score": 0.4165583550930023
    },
    {
      "name": "Natural language",
      "score": 0.33900249004364014
    },
    {
      "name": "Programming language",
      "score": 0.3167307376861572
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ]
}