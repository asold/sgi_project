{
  "title": "Currently Available GenAI-Powered Large Language Models and Low-Resource Languages: Any Offerings? Wait Until You See",
  "url": "https://openalex.org/W4406172870",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2184088652",
      "name": "Chaka Chaka",
      "affiliations": [
        "University of South Africa"
      ]
    },
    {
      "id": "https://openalex.org/A2184088652",
      "name": "Chaka Chaka",
      "affiliations": [
        "University of South Africa"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6944809543",
    "https://openalex.org/W4381929228",
    "https://openalex.org/W4391557617",
    "https://openalex.org/W4394707607",
    "https://openalex.org/W6929968316",
    "https://openalex.org/W3047117292",
    "https://openalex.org/W6762125396",
    "https://openalex.org/W4389131500",
    "https://openalex.org/W4388010320",
    "https://openalex.org/W4376643691",
    "https://openalex.org/W4392358084",
    "https://openalex.org/W4321605350",
    "https://openalex.org/W4382894295",
    "https://openalex.org/W4313582009",
    "https://openalex.org/W4394950049",
    "https://openalex.org/W4402671762",
    "https://openalex.org/W4388585881",
    "https://openalex.org/W4388488349",
    "https://openalex.org/W4389777735",
    "https://openalex.org/W4389523930",
    "https://openalex.org/W4385570231",
    "https://openalex.org/W4389520538",
    "https://openalex.org/W4388725733",
    "https://openalex.org/W4387946871",
    "https://openalex.org/W4393213754",
    "https://openalex.org/W4394662652",
    "https://openalex.org/W2938892948",
    "https://openalex.org/W4399521940",
    "https://openalex.org/W4403618835"
  ],
  "abstract": "A lot of hype has accompanied the increasing number of generative artificial intelligence-powered large language models (LLMs). Similarly, much has been written about what currently available LLMs can and cannot do, including their benefits and risks, especially in higher education. However, few use cases have investigated the performance and generative capabilities of LLMs in low-resource languages. With this in mind, one of the purposes of the current study was to explore the extent to which seven, currently available, free-to-use versions of LLMs (ChatGPT, Claude, Copilot, Gemini, GroqChat, Perplexity, and YouChat) perform in five low-resource languages (isiZulu, Sesotho, Yoruba, M?ori, and Mi’kmaq) in their generative multilingual capabilities. Employing a common input prompt, in which the only change was to insert the name of a given low-resource language and English in each case, this study collected its datasets by inputting this common prompt into the seven LLMs. Three of the findings of this study are noteworthy. First, the seven LLMs displayed a significant lack of generative multilingual capabilities in the five low-resource languages. Second, they hallucinated and produced nonsensical, meaningless, and irrelevant responses in their low-resource language outputs. Third, their English responses were far better in quality, relevance, depth, detail, and nuance than their low-resource language only and English responses for the five low-resource languages. The paper ends by offering the implications and making the conclusions of the study in terms of LLMs’ generative capabilities in low-resource languages.",
  "full_text": "148 \n \n©Authors \nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 \nInternational License (CC BY-NC-ND 4.0). \nInternational Journal of Learning, Teaching and Educational Research \nVol. 23, No. 12, pp. 148-173, December 2024 \nhttps://doi.org/10.26803/ijlter.23.12.9 \nReceived Sep 1, 2024; Revised Oct 14, 2024; Accepted Dec 28, 2024 \n \n \nCurrently Available GenAI-Powered Large \nLanguage Models and Low-Resource Languages: \nAny Offerings? Wait Until You See \n \nChaka Chaka*  \nUniversity of South Africa \nPretoria, South Africa \n \n \nAbstract. A lot of hype has accompanied the increasing number  of \ngenerative artificial intelligence-powered large language models (LLMs). \nSimilarly, much has been written about what currently available LLMs \ncan and cannot do, including their benefits and risks, especially in higher \neducation. However, few use cases  have investigated the performance \nand generative capabilities of LLMs in low-resource languages. With this \nin mind, one of the purposes of the current study was to explore the extent \nto which seven, currently available, free -to-use versions of  LLMs \n(ChatGPT, Claude, Copilot, Gemini, GroqChat, Perplexity, and YouChat) \nperform in five low-resource languages (isiZulu, Sesotho, Yoruba, Māori, \nand Mi’kmaq) in their generative multilingual capabilities. Emp loying a \ncommon input prompt, in which the only change was to insert the name \nof a given low -resource language and English in each case, this study \ncollected its datasets by inputting this common prompt into the seven \nLLMs. Three of the findings of this study are noteworthy. First, the seven \nLLMs displayed a significant lack of generative multilingual capabilities \nin the five low -resource languages. Second, they hallucinated and \nproduced nonsensical, meaningless, and irrelevant responses in their \nlow-resource language outputs. Third, their English responses were far \nbetter in quality, relevance, depth, detail, and nuance than their low -\nresource language only and English responses for the five low -resource \nlanguages. The paper ends by offering the implications and making the \nconclusions of the study in terms of LLMs’ generative capabilities in low-\nresource languages. \n  \nKeywords: generative multilingual capabilities; hallucinations; large \nlanguage models; low-resource languages; nonsensical, meaningless and \nirrelevant responses \n \n \n \n \n \n* Corresponding author: Chaka Chaka, chakachaka8@gmail.com \n\n149 \n \nhttp://ijlter.org/index.php/ijlter \n1. Introduction \nIt is becoming increasingly obvious that English is the first and home language of \nthe currently  existing generative artificial intelligence -powered large language \nmodels (henceforth simply LLMs) (Snyder, 2023; Vashee, 2023). English is their \ndefault language. Here, Huang et al.’s (2023) dictum and main paper titled, “Not \nall languages are created equal in LLMs” (p. 1), is more than instructive. Of course, \nEnglish does not dominate only LLMs’ ecosystems, but also the Internet’s \necosphere, in which languages such as French, Spanish, Portuguese, Arabic and \nMandarin have th eir own share of dominance. The other European languages \nand/or Latin alphabet-based languages and certain non-European languages like \nChinese and Indonesian (Akula et al ., 2024; Snyder, 2023)  have their own \ndominant share, too . All of the languages, which have a strong presence on the \nInternet, and which are concomitantly preferred by LLMs are positively regarded \nas high-resource languages. In contrast, all languages that have little or no Internet \npresence, and which are consequently not used by LLMs, are negatively referred \nto as low -resource languages. Most o f these languages are marginali zed \nIndigenous and subaltern languages. The majority of speakers of these languages \nare on the periphery not only of leading-edge AI developments but of many other \ntechnological developments currently taking place as well.  \n \nHowever, there is a contrast that needs to be drawn between the Internet and \nLLMs in terms of their preferred languages. The Internet was not born speaking \nEnglish per se. It has been and continues to be provisioned with information, data, \nmaterials, and texts written mainly in English. In relation to higher education \n(HE), in particular, some of the pieces of information, data, materials, and texts \ncomprise research data, journal articles, books, and monographs written in \nEnglish by speakers of low-resource languages, which these speakers themselves \nor the publishers of their work make available online. Then, the Internet simply \nharvests and archives this published work, together with its biases and forms of \nmisrepresentation in certain instances, as it is in its original language of \npublication, which happens  to be English. This is not to deny that at times, \nInternet search engine algorithms tend to be biased toward s certain provisioned \ninformation, while they are biased against some (see Cave & Dihal, 2020; Chaka, \n2022; Lee et al., 2019; Lin et al., 2023). So, at issue for Internet search engines is the \nprovisioned information available online, which may have its own bias , search \nengines’ own algorithmic bias and the opaque realm in which search engines tend \nto operate. \n \nContrariwise, LLMs largely depend on the specific language through which their \ntraining data is made available and fed into them. The other factors that undergird \nthem are their training data ’s quality and inclusiveness, their algorithm designs \nand their cross-domain generalisation (AIContentfy Team, 2023; Captain Words, \n2024). Data quality has to do with the comprehensiveness and robustness of the \ntraining data while data inclusiveness is relat ed to the diversity and \nrepresentativeness of data not only in terms of language and dialects, but also \nconcerning racial and ethnic demographics, geographies, gender, cultures, and \nvalue systems. Algorithm s are often designed to be effective, reliable, accurate, \nand value -neutral (unbiased) (AIContentfy Team, 2023; Chaka, 2022, 2024a, \n150 \n \nhttp://ijlter.org/index.php/ijlter \n2024b; Rudolph et al., 2024). Cross-domain generalization pertains to the extent to \nwhich an LLM ’s dataset is generalizable and applicable to different domains of \nuse that exist in real life (Wu et al., 2023). Allied to cross-domain generalization is \nthe cross-linguistic generalization of LLMs. On one hand, this relates mainly to \nthe extent to which LLMs have their training data in languages other than English. \nOn the other, this factor has to do with LLMs’ training datasets being available in \nother Internet-marginalized languages rather than just in English and other \nInternet-favoured languages . Cross-linguistic generalization allows LLMs to \noperate efficiently, reliably, and accurately across diverse languages. Elsewhere, \nWu et al. (2023) refer to this language capability as a cross-linguistic applicability. \n \nAgainst this background, this study set out to investigate the extent to which \nseven, available, free-to-use LLMs like ChatGPT (ChatGPT 3.5), Claude, Copilot, \nGemini, GroqChat (Llama3 -8b-8192), Perplexity and YouChat, perform in five \nlow-resource languages, isiZulu, Sesotho, Māori, Yoruba, and the Mi’kmaq \nlanguage (henceforth Mi’kmaq), in their gene rative multilingual capabilities. It \nalso sought to explore the extent to which the responses generated by these seven \nLLMs in such low -resource languages are me aningful, sensible, and relevant, \nbased on a common input prompt. In addition, the study wanted to compare the \nresponses for the five low -resource languages with those for English. Requiring \nresponses from LLMs based on prompts is what Hadi et al.  (2023) refer to as a \nquestion-answering system. English was used as a benchmark high -resource \nlanguage in the current study . In view of this, this study had the following \nresearch questions (RQs): \n \n• To what extent do the seven, currently available, free -to-use LLMs such as \nChatGPT, Claude, Copilot, Gemini, GroqChat, Perplexity, and YouChat, \nperform in the five low -resource languages, isiZulu, Sesotho, Māori, Yoruba, \nand Mi'kmaq in their generative multilingual capabilities? \n• To what extent do these seven LLMs provide meaningful, sensible, and \nrelevant responses from a common prompt in the five low -resource \nlanguages? \n• To what extent  do the responses generated by these seven LLMs in the five \nlow-resource languages compare with the English responses generated by the \nsame LLMs regarding the same common input prompt? \n \n2. Argumentative Standpoint \nWhile there is global hype about currently available, free-to-use LLMs and while \nsome scholars tend to tout these LLMs as revolutionary and disruptive, especially \nfor university knowledge generation and university teaching and learning, the \ncurrent paper adopts a cautionary posture. In this evolving state of affairs, the \nsudden emergence of these LLMs has not only led to an AI arms race reminiscent \nof yester -years’ space race, but it has also led to a sudden growth of armchair \nexperts and gurus of AI in all its shapes and permutations. These armchair experts \nand gurus tend, at times, to occupy two polar sides of the AI equation – embracers \nand resisters (Luddites) of the new AI technology. \n \n151 \n \nhttp://ijlter.org/index.php/ijlter \nAt the core of this cautionary posture is a degree of criticism and some scepticism \nof AI so that one does not blindly believe in AI technology to the point of \nembracing technologism. At the same time, this posture guards against stoic \nLuddism: stubbornly resisting or rejecting new technology for the sake of resisting \nor rejecting it. Rather, it maintains that the currently available LLMs need to be \ntreated with caution concerning what they can and cannot do in HE, regarding \nwhat languages they cover and those they do not cover in their training data . \nTherefore, this cautionary critical-sceptical posture mainly has to do with the fact \nthat most of the currently available LLMs often tend to hallucinate or make up \ninformation about the factual knowledge they generate (Hadi et al., 2023; Perkins, \n2023; Popenici, 2023; Rudolph et al., 2023 ; Rudolph et al., 2024 ). This is the case \neven when  that factual knowledge  exists in high -resource languages such as \nEnglish in which LLMs’ training data is available and packaged. The cautionary \ncritical-sceptical posture  is also related to  the fact that most of the currently \navailable LLMs tend not to accommodate low-resource languages: they are biased \ntowards high -resource languages in the same way as the Internet is biased \ntowards these languages. So, whatever these LLMs may claim to be able to do \nneeds to  be treated with critical scepticism . This serve s as the argumentative \nstandpoint in this paper. \n \n3. Related Literature \nWith the points highlighted above in mind, this paper provides a short, bespoke \nliterature review of some of the scholarly papers that deal with LLMs and low -\nresource languages. As this is an emerging and evolving area, there are not many \ncurrent studies that have focused on LLMs and low -resource languages. \nTherefore, three studies, Nguyen et al. (2023), Lankford et al. (2023), and Huang \net al. (2023), which have relevance to this study, are briefly reviewed here. The \nfirst and last ones are preprints. For instance, Nguyen et al. (2023) point out that \nwhile LLMs have profound generative capabilities in high -resource languages, \nthey nonetheless have constrained generative capabilities in low -resource \nlanguages owing to their inherent pre -training data asymmet ry. So, to \ncompensate for this deficiency, they  collated in-context, synthetic, intra -lingual \nexemplars from varied data sets of high-resource languages and employed them \nto prompt LLMs to translate from given low-resource languages into English. This \nmethod, which they refer to as a linguistically -diverse prompting (LDP), was \napplied to 21 African and 13 Indic low -resource lang uages, and was used to \nperform translations and summarisation between these languages and English. It \nwas then u sed to generate in-context, synthetic, intra-lingual exemplars to carry \nout generative tasks (translation and summarisation) in these target low-resource \nlanguages. Tapping into the ROOTs corpus, the LDP method was applied to t he \nBLOOM model and InstructGPT (Nguyen et al., 2023). \n \nTwo of the results of this study are worth mentioning. First, the performance of \nLDP equalled supervised few-shot learning when zero supervision in English to \nand from 21 African and 13 Indic low -resource languages was employed. This \nLDP approach even outp erformed in non -English-wide directions. Second, the \napproach outdid related English -pivoting methods in multilingual \nsummarisation (Nguyen et al., 2023). Nguyen et al.’s (2023) use of LD P \n152 \n \nhttp://ijlter.org/index.php/ijlter \ndemonstrates that current LLMs lack generative multilingual capabilities for low-\nresource languages. Importantly, it highlights the need to improvise or innovate \nin order to compensate for this inherent generative deficiency. It is this aspect – \nthe genera tive multilingual deficiencies LLMs have when it comes to low -\nresource languages – that necessitates a critical-sceptical posture. \n \nThe second study is Lankford et al. (2023). This study dealt with the impact of \nLLMs on efficient machine translation (MT) outputs related to two low -resource \nlanguages, Marathi and Irish . Its overall objective was to address the \nshortcomings LLMs have in delivering high -quality MT outputs for these \nlanguages by developing a tool called adaptMLLM, with MLLM standing for \nmultilingual large language models. To realise its objective, the study focused on \nfine-tuning pre-built MLLMs to improve MT on two low-resource language pairs. \nThese pairs involved English to Marathi (ENG ↔ MR) and English to Irish (ENG \n↔ GA). When the adaptMLLM system was compared and benchmarked against \nthe baselines from the LoResMT2021 Shared Task, it generated improved \ntranslation outputs. The improved translation outputs were noticed bi -\ndirectionally in ENG ↔ MR pairs and in ENG ↔ GA pairs, respectively (Lankford \net al., 2023). Lankford et al.’s (2023) adaptMLLM, like Nguyen et al.’s (2023) LDP \nabove, represents an attempt at improvising and innovating LLMs to atone for \ngenerative def iciencies LLMs have in low -resource languages. This, again, \nemphasises the need for adopting a critical -sceptical posture when dealing with \nLLMs’ performance in low-resource languages. \n \nThe third study that has some relevance for this paper is Huang et al. (2023). This \nstudy set out to experiment with a cross -lingual-thought prompting (XLT) \nmethod intended to iteratively enhance the multilingual capabilities of LLMs \nacross high -resource and low -resource languages. XLT is a general method for \nprompting that is able to trigger cross -lingual and logical reasoning to improve \ntask performance in diverse languages. This method was used to evaluate seven \nrepresentative benchmarks dealing with und erstanding (e.g. natural language \ninference and paraphrasing), reasoning (e.g. arithmetic reasoning and common-\nsense reasoning), and generation (e.g. question answering, summarisation, and \nmachine translation) tasks related to high -resource and low-resource languages. \nIn all, the experiment involved 27 different languages, among which English, \nFrench, German, Spanish, I talian, Russian, Japanese , and Chinese Simplified \nrepresented some of the high-resource languages. Low-resource languages were \nrepresented by languages such as Swahili, Bengali, Tamil, Galician, Urdu, Telugu, \nJavanese, Haitian Creole, and Southern Quechua. Two LLMs, GPT-3.5-Turbo and \nText-Davinci-003, were used in the experiment. Notably, this experiment \ndemonstrated that XLT significantly improved the performan ce of different \nmultilingual tasks and markedly minimised the gap between the best \nperformance and the mean performance of each task in the various languages. \nCrucially, XLT generated more than  10 points of mean improvement in open -\ndomain question-answering and arithmetic reasoning (Huang et al., 2023). In the \nsame way as the two studies discussed above, this XLT experiment underscores \nthe kind of improvisation and innovation needed to compensate for the \nmultilingual generative shortcomin gs LLMs have for low -resource languages. \n153 \n \nhttp://ijlter.org/index.php/ijlter \nOnce more, this calls for a critical -sceptical posture when one deals with LLMs’ \nperformance in low-resource languages. \n \nThe matter of cross-linguistic or multilingual capabilities of LLMs is crucial and \npressing since scholars like Snyder (2023) and Qin et al. (2024) argue that there are \nover 7,000 global languages. Therefore, the need for MLLMs in the exponentially \ngrowing LLM ecosystem cannot be overemphasised. Of course, no illusions must \nbe harboured about MLLMs, either. Like their currently available, high-resource \nlanguage-biased LLM cousins, MLLMs too will have their shortcomings. Chief \namong these shortcomings, but by no means the only one, is hallucination. LLM \nhallucination is a practice in which LLMs misinterpret objects or patterns and \nproduce responses that seem to be factually true, but which are inaccurate, \nerroneous or nonsensical  (Aboze, 2023; Huang et al., 2023; IBM, 2024 ; Patil & \nGudivada, 2024; Guerreiro et al., 2023). It occurs when LLMs tend to make up facts \nor simply churn out untruths, which are embedded in plausible -looking \nstatements. As IBM (2024) opines, a t face value, this  phenomenon appears to be \ncounterintuitive as it is often associated with humans or animals), and hardly with \nAI tools. In fact, it is difficult for one to think of an LLM that currently cannot \nhallucinate, notwithstanding the continuing advancements of LLMs. For instance, \nQin et al. (2024) contend that MLLMs are often prone to hallucination. Other \nscholars such as Dale et al. (2023) and Guerreiro et al. (2023) have flagged the \npractice of hallucination in multilingual machine translation. Similarly, Aharoni \net al. (202 4) have explored the hallucination generated by multilingual machine \nsummarisation. This calls into question the blind adoption and usage in certain \nquarters of academia of LLMs, in both high-resource languages and low-resource \nlanguages, when actually hallucinati on is a characteristic feature for both LLMs \nand MLLMs. This is where the critical-sceptical posture adopted in this paper \ncomes into the picture, and not a blind, ardent and blanket adoption and usage of \nLLMs. \n \n4. Method \nThis study focused on the use cases of the seven, currently available LLMs from \nthe point of view of an end -user, who, in this case, was the author of this paper. \nAs mentioned above, these LLMs comprised ChatGPT, Claude, Copilot, Gemini, \nGroqChat, Perplexity, and YouChat. At the time when the study was conducted, \nthe first four LLMs had a persistent online presence on both Google and Bing \nsearch engines, while the last three did not. The overall aim, then, was to select \nwell-known and less-known LLMs in this study for diversification purposes. \n \nThe study did not improvise and innovate by employing an experimental tool to \ncompensate for the generative multilingual deficiencies these LLMs might have \npertaining to the five low -resource languages, which were part of its use cases. \nInstead, it compared the seven LLMs’ responses to a common lesson plan prompt \nin five low -resource languages (isiZulu, Sesotho, Yoruba, Māori, and Mi’kmaq \n(also known as Mi’kmawi’simk) with their counterpart English responses. In view \nof this, this study was exploratory in nature as it set out to explore a phenomenon \nor an aspect that has not yet been extensively studied ( Chaka, 2024b) . This \nphenomenon is the generative multilingual capabilities of the seven LLMs in the \n154 \n \nhttp://ijlter.org/index.php/ijlter \nfive aforesaid low -resource languages versus their language capabilities in \nEnglish (a high-resource language) based on a given common lesson plan prompt. \n \n4.1 Materials and Data Collection Procedure \nThe process of collecting data for this study took place between 23 March 2024 \nand 29 March 2024, and again on 23 April 2024. The five low-resource languages \nmentioned above were selected to represent three Indigenous languages in Africa \n(isiZulu, Sesotho, and Yoruba) and to represent two more Indigenous languages \n(Māori and Mi’kmaq) outside of Africa. \n \nAfter selecting the LLMs, a bespoke lesson plan prompt (hereafter, the common \nprompt or the prompt) was formulated and entered into each of the seven LLMs \nmentioned above. The common prompt was phrased as follows:  \n \nWrite me a class lesson in ( a specific name of one of the five low -resource \nlanguages/or English) on the following topic, “Southern multilingualism”. \nMake sure the lesson has all the necessary sections and teaching aids, a \nclass activity and an assignment. Also, provide a useful tip for students \nabout Southern multilingualism in the context of AI -powered large \nlanguage models. \n \nThe first LLM to be queried with this prompt was Copilot (see Figure 1) and the \nlast was ChatGPT. No regenerate prompt or re-prompting was used for all seven \nLLMs. For each of the seven LLMs, the output response (henceforth the response) \ngenerated from the input prompt mentioned above was translated into English \nusing Google Translate if it had been generated exclusively in the target low -\nresource language as spelt out in the prompt (see Figure 1). Where necessary, Bing \nTranslate, Machine Translation.com, and Rytr were used for translation purposes \nas well. The latter, Rytr, was used for translating Mi’kmaq as the other three online \nmachine translation tools could not translate it  as a marginalized, minority, \nIndigenous language . If a response was generated in English, counter to the \ninstruction in the prompt, it was left untranslated. \n \n \nFigure 1: A screenshot of the lesson plan prompt for isiZulu as displayed on Copilot \n \nThere was a corresponding English prompt version used. In all, the data for this \nstudy comprised the following datasets: the main low-resource language datasets; \nthe English dataset; and the English Google -translated version of each low-\nresource language dataset if it (the dataset) had been generated exclusively in the \ngiven target low-resource language. \n \n \n\n155 \n \nhttp://ijlter.org/index.php/ijlter \n4.2 Data Analysis \nContent analysis, comprising  manifest content analysis and latent content \nanalysis, was used to analyse the datasets collected for this study.  Manifest \ncontent analysis entails developing and constructing context from raw words or \nphrases related to the text at hand to derive literal meanings from those words or \nphrases. By its nature, it is, as its name indicates, a deductive analysis, conducted \nfrom macro-elements to micro-elements. It focuses on the surface structures of the \ntext. By contrast, latent con tent analysis is an inductive analysis that starts from \nthe micro-elements of a text and culminates in analysing the macro-elements of \nthe text at hand. It deals with the deeper, hidden structures of the text (see Delve \n& Limpaecher., 2022; Kleinheksel et al., 2020). Both forms of analysis involve \nquantitative analysis in varying degrees. \n \nPertaining to the current study, the manifest content analysis focused on the raw \nresponses generated by the seven LLMs based on the common prompt mentioned \nearlier. For example, in keeping with this form of analysis, the surface structures \nof all the raw  responses generated by the seven  LLMs were analysed as such \nwithout adding any layer of meaning to them. This entailed dealing with the \nstraightforward, surface meanings directly observable  from the responses (e.g. \nnonsensical and incomprehensible responses) together with the attendant literal \nimplications of such responses . Contrarily, latent content analysis went beyond \nthe surface nonsensical and incomprehensible  meanings of these responses and \nattributed such meanings  to, among other things, the phenomenon of \nhallucination. The latter is not man ifest in the LLMs’ responses: it was latently \ninferred. In other words, it is a latent inference.  The manifest content or data is \npresented under the findings followed by a discussion of the findings.This latter \nsection offers the latent content and its underlying structures. \n \n5. Findings \nThe first part of the findings presented in this section relates to the number of \nwords each LLM generated for each of its responses to the same common prompt \nthat was inputted to it for each low -resource language and English as a high -\nresource language (see Table 1). The second part of the findings provides sample \nresponses that were generated by the seven LLMs. Where necessary, the Google -\ntranslated versions of these sample responses or the English versions  of these \nsample responses as translated by the o ther three MT tools are offered. The two \nparts are presented as instances of manifest content. As shown in Table 1, the \nseven LLMs generated responses with varying word counts for each of the five \nlow-resource languages and English. When the seven LLMs are take n together, \nYouChat generated the highest total word count (3,601 words) for its six language \nresponses, which was boosted by Yoruba response (1,122 words). It was followed \nby ChatGPT (2,790 words), with Claudia having generated the lowest total word \ncount of 1,966 words. A notable exception is Gemini, which generated a zero \nresponse for isiZulu by disclaiming that “I’m still learning languages …”. Still, it \nmanaged to dwarf Claudia into the last position. Save for Gemini’s isiZulu’s zero \nword count, the lowest word count for any of these seven LLMs is that of the \nresponse generated by Perplexity for Yoruba (n=224 words). \n \n156 \n \nhttp://ijlter.org/index.php/ijlter \nTable 1: Seven LLMs, five low-resource languages and their responses, English and its \nresponses, and response word counts \n \n \n \nWith regard to the five low -resource languages, Sesotho had the highest total \nword count of 3,417 words across the seven LLMs. It was followed by Māori that \ngenerated a total word count of 3,185 words. IsiZulu produced the lowest total \nword count (2,110 words) since it had a zero response from Gemini. English had \na total word count of 2,883 words, which was the third -highest total word count. \nOf the five low -resource languages, Yoruba had the highest and lowest word \ncounts, 1,122 words and 224 words, barrin g isiZulu, which generated a zero \nresponse from Gemini. \n \n\n157 \n \nhttp://ijlter.org/index.php/ijlter \n \nFigure 2: A sample of YouChat’s Sesotho response with a mixture of Setswana words \n(in red) and Sepedi words (in yellow), including nonsense constructions (in \nturquoise) at the top half, and the Google translation of this response at the bottom \nhalf \n \nIn terms of the responses generated in the target low -resource languages as per \nthe common prompt, the following LLMs were able to do so, with the respective \ntarget low -resource language(s) in parentheses: ChatGPT (IsiZulu); Claudia \n(IsiZulu, Sesotho, Yoru ba, Māori, and Mi'kmaq); Copilot (IsiZulu); Perplexity \n(IsiZulu and Sesotho); and YouChat (Yoruba and Māori). In this regard, four \nLLMs were able to generate their responses exclusively in isiZulu (see Table 1). In \ncontrast, two LLMs generated their responses exclusively in Sesotho, Yoruba, and \nMāori. Only one LLM (Claudia) generated a response in Mi’kmaq  (see Table 1) , \nwhile another LLM (YouChat) produced a Sesotho response that had a mixture of \nSetswana and Sepedi 1 words (see Figure 2). This response also had a lot of \nnonsense constructions  (see the text in turquoise in Figure 2) . In addition, one \nLLM (Gemini) generated responses for Sesotho and Yoruba, which included their \ncorresponding English -translated versions. For Yoruba, two clauses at the \nbeginning of the lesson had no English translations. Moreover, one LLM \n(YouChat) prod uced an isiZulu response, but whose last section, Ulwazi \nlwesifundo [Course information], was exclusively in English (see Table s 1 and  \n2). To this end, Claudia produced the most low -resource language responses \n(n=5), followed by Perplexity and YouChat with  two low -resource language \nresponses each (see Table 1). \n \n \n \n \n \n\n158 \n \nhttp://ijlter.org/index.php/ijlter \nTable 2: Types of responses produced by the seven LLMs for the five low-resource \nlanguages \n \n \nFive LLMs produced English responses which had only headings, sub -headings, \nand vocabulary items or given concepts translated into the relevant low-resource \nlanguages. As illustrated in Table 1, t hese LLMs with the relevant low -resource \nlanguage in parenthesis in each case  included GroqChat (IsiZulu), Perplexity \n(Yoruba), ChatGPT (Māori), Gemini (Māori), ChatGPT (Mi’kmaq), Gemini \n(Mi’kmaq) (also see Figure 3), GroqChat (Mi’kmaq), and YouChat (IsiZulu and \nMi’kmaq). Most of these instances were for Mi’kmaq (n=4), followed by those for \nisiZulu (n=2) and Māori (n=2), with GroqChat, ChatGPT, and Gemini featuring \ntwice, each, in these instances.  \n \n \nFigure 3: A sample of Gemini’s Mi’kmaq’s English response with English-translated \nheadings, sub-headings, and keywords \n \nFurthermore, the following LLMs generated the responses for the low -resource \nlanguages in parentheses in English: Copilot (Sesotho, Yoruba, Māori, and \nMi’kmaq) (also see Figure 4 for the Yoruba sample response); GroqChat (Sesotho, \nMāori, and Yoruba); ChatGPT (Sesotho and Yoruba); and Perplexity (Māori and \nMi’kmaq). Of these, Copilot produced the most English responses for four low -\nresource languages, followed by GroqCh at (n=3). Finally, the English responses \nhad a total word count of 2,863 words. Five of the six English responses had lesson \nplans with time slots for their respective lesson plan sections, with one lesson plan \nhaving its assessment tasks weighted in percentages (see Table 1). \n \n \n\n159 \n \nhttp://ijlter.org/index.php/ijlter \n \nFigure 4: A sample of Copilot’s Yoruba English response from a PDF file generated by \nCopilot \n \n6. Discussion \nIn this section, the deeper, underlying and latent structures embedded in the \nmanifest data presented above as well as the other samples of data that could not \nbe presented above are unpacked and discussed. Thematically, these structures \nare as follows: hallucinations and nonsense phrases or clauses; lack of generative \nmultilingual capabilities; and low-resource language-only responses versus low-\nresource language English responses versus English language responses. \n \n6.1 Hallucinations and Nonsense Phrases or Clauses \nOne classic example of a hallucinated response is the response generated by \nChatGPT in isiZulu for the lesson plan of this low-resource language. The English-\ntranslated version of this sample response is nowhere near perfect , aside from \nhaving some flaws in its original isiZulu version. Its very topic is not only bizarre \nwhen juxtaposed with the concept of Southern multilingualism, as captured in the \nprompt, but it is also a nonsense topic even when seen from Google Translate’s \nperspective (see Figure 5). In other words, it has nothing to do with Southern \nmultilingualism: it is a lesson plan topic for something totally different. I ts last \nportion, Ulimi Oluningi ngesiZulu  {The Many Languages in Zulu ] \ndemonstrates how at the point of generating a  lesson plan topic in isiZulu, \nChatGPT started hallucinating about Freedom Lesson and Writing in Zulu \nAbout South Africa , both of which have no relevance to Southern \nmultilingualism. The same applies to the points mentioned under the lesson \nplan’s sections, especially under Speech ( Questions) and Reading Material \n(Examples), which have instances of nonsense phrases and clauses. \n \n\n160 \n \nhttp://ijlter.org/index.php/ijlter \n \nFigure 5: A sample of an isiZulu response generated by ChatGPT (left) and its \nEnglish-translated version by Google Translate (right) \n \nAnother instance of hallucination relates to YouChat’s Sesotho response, which \nwas produced with a mixture of Setswana and Sepedi words (see Figure 2). While \nSetswana and Sepedi do share certain words in common, and while the three \nlanguages do share commo n words such as baithuti [students/learners] and \nmetsotso [minutes] as in Figure 2, Sesotho hardly employs ga and go either as single \nforms or as parts of words. So, mixing up forms of these languages in this way \nevinces a form of hallucination on the part of this LLM (YouChat) as it tended to \nbe at sixes and sevens as to what a Sesotho orthography should be like vis -à-vis \northographies of Setswana and Sepedi. Instances of hallucination are also in the \nform of nonsense constructions this response  has. One example of such a \nhallucination in this figure is the lesson plan topic itself , Lesedi la Naha ya \nBokgoni ya Sesotho - Setšo sa Bolelo ya Kganakgang ya Naha ya Boraro, whose \nGoogle Translate version is as nonsensical and hallucinatory as its original \nSesotho version. Two other examples are Ka letsatsi la tlase , which Google \nTranslate translated as On the last day, when actually the phrase, ka tlase, refers to \nbelow or beneath/underneath in English, and mafatleng a Sesotho translated as in the \nSesotho world by Google Translate, which is a meaningless construction as there is \nnothing called the Sesotho world. Both these examples, together with the first one, \nhave nothing to do with Southern multilingualism. One more example of a \nnonsensical and hallucinatory Sesotho response is the one generated by \nPerplexity, which had a lot of repetitive nonsense Sesotho paragraphs (see Ta ble \n1 and Figure 12).  \n \nIn both cases, ChatGPT’s isiZulu response and YouChat’s Sesotho response \nrepresent factual fabrication, which is part of factuality hallucination. In this form \nof hallucination, an LLM fabricates or invents non-existent facts that cannot be \nverified against real -world knowledge (Huang et al., 2023 ; see Banerjee et al., \n2024). For example, the lesson plan topic of the isiZulu response, Freedom Lesson: \nWriting in Zulu About South Africa – The many Languages in Zulu, and its sub-\n\n161 \n \nhttp://ijlter.org/index.php/ijlter \nheading, Synchonization of languages , are fabricated facts that lack sense and \ncoherence when judged against the prompt and their own flow of logic. The same \ncan be said about YouChat’s Sesotho response, which, as said earlier, is not only \nan admixture of Sesotho, Setswana, and Sepedi but also has a factually fabricated \nlesson topic and invented nonsense phrases. The fabricated lesson topic and its  \ninvented nonsense phrases lack coherence and logic and are irrelevant to the \nprompt. \n \nThere are further instances of hallucination and nonsense phrases and clauses in \nthe responses produced in the other three low -resource languages. Two classic \nexamples are the Yoruba responses generated by Claude and YouChat, even \nthough only Claude’s resp onse and its English translations by three translation \ntools, Google Translate, Bing Translator, and Machine Translation.com (see Figure \n6), will be used due to space constraints. \n \n \nFigure 6: A sample of Claude’s Yoruba response and its English translation by Google \nTranslate \n \nAs is evident from Figure 6, this response, together with its English translation by \nGoogle Translate, has a lot of factual fabrication  as propounded by Huang et al. \n(2023) and Banerjee et al. (2024). For example, the lesson plan topic, the first three \nbullet points, and the information under Infection are fabricated facts that have \nnothing to do with the prompt and with Yo ruba in Nigeria. In a ddition, this \nresponse consists of  a mishmash of illogical and senseless ideas that ha ve no \nrelevance to Southern multilingualism. A case in point is the way the sections for \nthis lesson plan have been framed and the bullet points listed under them. For \ninstance, the statements translated as This also causes the sign of multiple copies and \nThe story of the difference/miracle of these languages in the midst of the hellish diseases, \nthe heaven where they are, the year’s table  are illogical, senseless, and hallucinatory. \n\n162 \n \nhttp://ijlter.org/index.php/ijlter \nAn example, which is the nadir of the illogical and senseless hallucination of this \nresponse, is the reference to both America’s southern states and the cities cited as \nhome to many multilingual writers, an aspect which has nothing to do with Yoruba \nspoken in Nigeria. The same illogical and senseless hallucination is aptly captured \nby the English translations of the same statements offered by Bing Translator and \nMachine Translation.com (see Figure 7). Overall, this response and its translated \nEnglish versio ns provide ample evidence of an LLM hallucinating in trying to \nrespond to a prompt. \n \n \nFigure 7: A sample of Bing Translator’s (top half) and Machine Translation.com’s \n(bottom half) English-translated versions of Claude’s Yoruba response \n \nA measure of atonement for hallucinated responses is provided by a Māori \nresponse generated by YouChat, whose three English translations by Google \nTranslate, Bing Translator, and Machine Translation.com are displayed in Figures \n8 and 9. This response has s ome aspects of Southern multilingualism in words \nsuch as multilingual or multilingualism (Bing translation) and the South in the lesson \nplan topics of the three translated English versions, with the phrase, the South  \nhaving an aura of the Global South. However, some of the aspects of these \ntranslated versions are more about how to learn Māori (e.g. language skills and \nlanguage competence) using computers and Māori language app lications than \nabout what Southern multilingualism entails. Most crucially, though, there are \ninstances of hallucination exemplified by phrases like multilingual culture , \nintellectual technologies , psychological technology , spend cohesion , and over-ability \nutilisation of loudspeakers. These phrases lack sense, and barring the first one, have \nlittle to do with Southern multilingualism. \n \n\n163 \n \nhttp://ijlter.org/index.php/ijlter \n \nFigure 8: A sample of Google Translate’s English version of YouChat’s Māori \nresponse \n \nA Mi’kmaq response generated by Claude was translated using Rytr, a GenAI \nchatbot (see Figure 10). Google Translate misrecognised it as Quechua (an \nIndigenous language spoken in Peru) and hallucinated, too, in trying to translate \nit into English (see Figur e 11), while the other two online translation tools could \nnot translate it. \n \n \n \nFigure 9: A sample of Bing Translator’s English translation  of YouChat’s Māori \nresponse (top half) and Machine Translation.com’s version of the same sample \n(bottom half) \n \nWhat is evident from Figure 10 is that the lesson plan topic and its related sections, \ntogether with the bullet points under each of these sections are purely related to \nMi’kmaq as a language and to some of the Mi’kmaq ways of life. In this way, it \ncan be said that Southern multilingualism is localised and seen through the prism \nof Mi’kmaq. Put differently, Mi’kmaq serves as a bedrock for looking at Southern \nmultilingualism, even though this is not explicitly mentioned. Either way, the \nnuance of Southern multilingualism such as how Mi’kmaq is related to and is an \n\n164 \n \nhttp://ijlter.org/index.php/ijlter \ninstance of a Southern multilingualism or how it is related to other Southern \nmultilingualisms (Chaka, 2024c; Heugh, 2021) are lost as they are not mentioned \nin the response.  \n \n \nFigure 10: Rytr’s English translation of Claude’s Mi’kmaq response \n \nPertaining to the instances of hallucination related to the low -resource language \nresponses generated by the LLMs as discussed above, the studies cited earlier \nflagged such hallucinations even in MLLMs and other AI machine translation \ntools. For example, Q i et al. (2024) argue that MLLMs have a proclivity to \nhallucinate, while Aharoni et al. (2024 ), Dale et al. (2023), and Guerreiro et al. \n(2023) have raised concerns about how multilingual machine translation tools \ntend to hallucinate. In the same vein, Chaka (2023) points out how three \ngenerative AI chatbots, ChatGPT, Chatsonic and YouChat hallucinated English \nresponses to four English prompts related to selected areas of applied English \nlanguage studies (AELS). Leffer’s (2024) title, AI chatbots will never stop \nhallucinating, which she has coined for her paper and her view that LLMs tend to \nhallucinate even when confronted with mundane prompts aptly sum up the \npropensity of LLMs to hallucinate (also see Associated Federated Press [ AFP], \n2024; Kalai & Vempal a, 2024 for another view on LLMs’ hallucinations). \nMoreover, it is also the case that LLMs’ hallucinations are related to social, \ncultural, and demographic biases built into LLMs’ training data or to LLMs’ lack \nof representative training data (Ferrara, 2023; Huang et al., 2023). It is for this \nreason that this study adopted a cautionary critical -sceptical posture regarding \nLLMs’ performance in low-resource languages. \n \n\n165 \n \nhttp://ijlter.org/index.php/ijlter \n \nFigure 11: Google Translate’s English translation of Claude’s Mi’kmaq response \n \n6.2 Lack of Generative Multilingual Capabilities \nSome of the nonsense phrases or clauses and repetitive nonsense phrases or \nclauses including the irrelevant and flawed responses generated by the LLMs as \ndemonstrated in the preceding section, reflect the lack of generative multilingual \ncapabilities these LLMs have in low-resource languages. This is a concern raised \nby Qin et al. (2024), arguing that the current MLLMs, and by analogy, the current \nLLMs, tend to display poor performance in low -resource languages. But, in the \ncurrent study, some of the LLMs did not possess any relevant knowledge of some \nof the investigated low-resource languages. The YouChat’s Sesotho response (see \nFigure 2), the ChatGPT’s isiZulu response (see Figure 5), Claude’s Yoruba \nresponse (see Figures 6 and 7), and some aspects of the YouChat’s Māori response \n(see Figures 8 and 9) are the classic examples. Concerning YouChat’s Sesotho \nresponse, the resultant three -language mixed response demonstrates this LLM’s \ndearth or absence of generative multilingual capabilities in distinguishing \nbetween a purely Sesotho response and standalone Setswana and Sepedi \nresponses.  \n \n \nFigure 12: A sample of Perplexity’s Sesotho response (top half) and its Google \nTranslate English version (bottom half) \n\n166 \n \nhttp://ijlter.org/index.php/ijlter \n \nAllied with this Sesotho response is another Sesotho response generated by \nPerplexity (see Figure 12). This response, which Microsoft Word’s Set Proofing \nLanguage feature detects as Sesotho2 (the South African version) when actually it \nis a Lesotho version of Sesotho) displays numerous instances of hallucination as \nexemplified by the lesson plan topic and its two sections. However, as this aspect \nhas been discussed in the preceding section, the focus here is on repetitive \nnonsense phrases or clauses. For example, the f irst clause under the first secti on \nand the two clauses under the second section are nonsense clauses. Moreover, the \nsecond section, together with the information under it, is repeated verbatim in the \nother 10 sections of this lesson that Perplexity generated. This means that the 776 \nwords that this response has (see Table 1) are 776 words of repetitive, nonsensical \nand meaningless information. This phenomenon of spewing out repetitive, \nnonsensical and meaningless sentences serves as one of the indicators of this \nLLM’s lack of generative m ultilingual capabilities in Sesotho as a low -resource \nlanguage. \n \nAs pointed out above, the habit of churning out nonsense phrases or clauses is \nevident in Claude’s Yoruba response as well (see Figures 6 and 7). From the lesson \nplan topic to its section headings and their attendant bullet points, this response \nis replete with nonsensical and meaningless information. For instance, there is a \nhuge disjuncture in the lesson topic as captured in its three English translation \nversions. This is apart from the bizarreness and senselessness of these translated \nversions. The same bizarreness and senselessness of ideas is manifest in the two \nsections of the lesson and their related bullet points. This strange and senseless \nconstruction of ideas, which tends to upset even non -Yoruba speakers, is \nsymptomatic of the lack of generative multilingual capabilities that LLMs such as \nClaude have in a low-resource language like Yoruba. \n \nAs is the case with Perplexity’s Sesotho response which had 776 words of \nrepetitive, nonsensical, and meaningless information, Claude’s Yoruba response \nwith a word count of 1,122 words (see Table 1) is a response with 1,122 words of \nbizarre and senseless ideas. This means that the number of words this response \nhas does not reflect any quality3 response. Ironically, this generative multilingual \ndeficiency tends to play itself out even in machine translation tools such as Google \nTranslate, Bing Translator, and Machine Tranlation.com as depicted by Figures 6 \nand 7. Furthermore, pockets of such a generative m ultilingual deficiency are \nevident in YouChat’s Māori response in relation to phrases such as intellectual \ntechnologies, psychological technology, and over-ability utilisation of loudspeakers  (see \nFigures 8 and 9). It is only a machine, and not a human bei ng, that can \nthoughtlessly churn out a phrase like the last one. Most crucially, the lack of \ngenerative multilingual capabilities of the LLMs analysed in this study is further \nreflected by how some of them generated their responses exclusively in English \nwhen the prompt instructed them to do so in each specified low -resource \nlanguage (see Tables 1 and 2).  Huang et al. (2023) call the inability of an LLM to \nfollow instructions as instruction inconsistency. \n \n167 \n \nhttp://ijlter.org/index.php/ijlter \nAs highlighted earlier, the cross-linguistic or multilingual capabilities of LLMs are \ncritical as LLMs, at times, tend to lack generative multilingual capabilities even in \nhigh-resource languages. One of the results of this generative multilingual \ndeficiency is the generation of incomprehensible outputs. Even in cases of low -\nresource languages where LLMs have been fine-tuned with innovative tools such \nadaMLLM (Lankford et al., 2023) and with innovative methods like a \nlinguistically-diverse prompting (LDP) (Nguyen et al., 2023) and a cross -lingual-\nthought prompting (XLT) (Huang et al., 2023), such tools and methods do not \ncompletely eliminate the generative multilingual deficiencies LLMs have. Based \non the instances of nonsensical and meaningless responses di scussed above, it \nseems that LLMs’ generative multilingual incapability is more intense and \nconcerning in low-resource languages. This is what the next section focuses on. \n \n6.3 Low-resource Language-Only Responses Versus Low -Resource Language \nEnglish Responses Versus English Language Responses \nWhen the low -resource language responses produced in the respective low -\nresource languages are compared with the English responses produced for these \nlanguages, the latter set of responses (the low -resource language English \nresponses) is, collectively, bet ter than their counterparts in terms of quality, \nrelevance, depth, detail, and nuance. For instance, the ChatGPT’s Sesotho \nresponse, which is titled Southern Multilingualism, states as part of its lesson \nobjective that students should be able to understand  the concept of Southern \nmultilingualism, identify its characteristics, and appreciate its importance in the \ncontext of the Southern African region . In addition, it mentions  in its introduction \nthings such as a brief overview of multilingualism  and the importance of language \ndiversity in Southern Africa . This is a far cry from the two Sesotho responses \ngenerated by YouChat (see Figure 2) and Perplexity (see Figure 12) discussed \nearlier. \n \nThe same can be said about the Copilot’s Yoruba response generated in English \n(see Figure 4), which is qualitatively better than Claude’s Yoruba response \ncounterpart produced exclusively in Yoruba (see F igures 6 and 7). To \ncontextualize its better quality, its lesson plan titled, Southern Multilingualism, \nhas these two aspects, appreciate the linguistic diversity in the Global South and explore \nlanguage resources beyond monolingual and multilingual orientations , as part of its \nlesson plan objective. In its lesson plan introduction, under the sub -section \nExplanation, it refers to Mention that it (Southern multilingualism) challenges the \ndominance of monolingualism and highlights the linguistic richness of the Global South . \nMoreover, in the lesson plan portions not displayed in Figure 6, this response has \na section titled, Defying Monolingual Norms , and has a task, Discuss how AI -\npowered large language models handle multilingual data, under a section titled, AI and \nMultilingualism. All of these aspects are some  of the essential elements of \nSouthern multilingualism – there is no gainsaying that one of the focal points of \nSouthern multilingualism, a concept associated with the  Global South, is to \nproblematize and resist the hegemony of monolingualism (Chaka, 2024c; Heugh, \n2021). Most significantly, the task, Discuss how AI -powered large language models \nhandle multilingual data , speaks to one of the aspects mentioned in the prompt: \nAlso, provide a useful tip for students about Southern multilingualism in the context  of \nAI-powered large language models  (see Figure 1). This response is in stark contrast \n168 \n \nhttp://ijlter.org/index.php/ijlter \nnot only to Claude’s Yoruba response counterpart but also to the other responses \nproduced in the respective low-resource languages discussed above.  \n \nThe points highlighted above about Claude’s Yoruba response apply in varying \ndegrees to the Mi’kmaq response generated exclusively in English by Perplexity \n(see Table 1). Titled, Mi'kmaq Language Class Lesson: Southern \nMultilingualism, the response says the following in its introduction: Southern \nmultilingualism refers to the phenomenon of individuals or communities speaking \nmultiple languages in the southern regions. This is a rich and diverse aspect of language \nand culture that we will delve into . Towards  the end, under its Useful Tip for \nStudents section, it states , In the context of AI -powered large language models, \nunderstanding Southern multilingualism can provide valuable insights into how these \nmodels can better support and represent diverse languages and dialects . This statement \ndeals with the last aspect of the prompt as discussed in the preceding paragraph \n(also see Figure 1). Coincidentally, what is captured by this statement resonates \nwith one of the things the current study attempted to investigate even though its \nSouthern multilingualism is subsumed under low -resource languages. In what \nhas become a standard practice for most LLMs, no sources have been cited for the \nstatements used in this response, including its definition of Southern \nmultilingualism. And, its phrasal verb, delve into , which it has used in the \nintroduction, ranks number 11 among the top 100 most commonly used AI words \n(AI Phrase Finder, 2024; see Gray, 2024). Notwithstanding, this response is \nqualitatively better than Claude’s Mi’kmaq-only response counterpart (see Figure \n10). In addition, like Claude’s Yoruba-only response above, it fares better than the \nother low-resource language responses dealt with thus far. \n \nBarring one response, the English responses had time slots allocated to their \nlesson plans (see Table 1). One of these, the GroqChat’s response, even had its \nassessment tasks weighted into percentages as follows: participation in class \ndiscussions and acti vities (20%); written essay (40%); class participation and \nengagement (20%); and quality of skit or dialogue (20%). Even though some of the \nlow-resource language responses, especially those produced in English by these \nLLMs, had lesson plan time slots, non e of them had their assessment tasks \nallocated percentage weightings. For example, in a like -like comparison, \nGroqChat produced all its low-resource language responses in English, except for \nminor variations here and there (see Table 1). Of these responses , none had \npercentage weightings allotted to its assessment tasks. Except for  its isiZulu \nresponse, which had time slots for its various sections, and excluding its Māori \nresponse, which had a global 60 minutes mentioned under Duration at the \nbeginning of the lesson plan, the other three low -resource languages (Sesotho, \nYoruba, and Mi’kmaq) had no time slots for their lesson plans. In addition, the \nEnglish lesson plan and the isiZulu and Māori responses had grade or educational \nlevels mentioned, while the o ther three low-resource languages had no grade or \neducational levels specified. \n \nWhen the English responses are compared with the two sets of responses \ndiscussed above, their better quality is noticeable: they are qualitatively better \nconcerning relevance, depth, detail, and nuance. Three responses generated by \nChatGPT, Claude, and Copilot (see Table 1) are used for illustrative purposes. For \n169 \n \nhttp://ijlter.org/index.php/ijlter \nexample, titled, Southern Multilingualism , the ChatGPT’s response mentions \nnew aspects of Southern multilingualism, which the two sets of responses dealt \nwith above did not touch on. These include the following statements: Influence of \ncolonization and migration on Southern multilingualism; Impact of indigenous languages \nand African languages on Southern multilingualism  and Reflect on the implications of \nSouthern multilingualism in the context of AI -powered large language models . This \nresponse ends with the following useful tip for students: \n \nWhen interacting with AI-powered large language models like OpenAI’s \nGPT-3, it’s important to be aware of the limitations and biases that can \narise due to the dominance of certain languages and dialects in the \ntraining data. Southern multilingualism offers  a rich diversity of \nlanguages and cultures that can enhance the development and \napplication of AI technologies. \n \nAll of these aspects are qualitatively different from the two sets of responses \ndiscussed earlier in terms of both their contextual relevance and their nuanced \napproach to Southern multilingualism. For its part, Claude’s response introduces \nnew pieces of information to Southern multilingualism such as an Overview of the \nmultilingual landscape in the southern regions (Africa, Asia, South America) and When \nusing AI -powered large language models like Claude, be aware that these models are \ntrained on vast amounts of text data, which may include biases and inaccuracies regarding \nlinguistic diversity and minority languages . These pieces of information add a new \ndimension to Southern multilingualism which is missing in the other responses. \nSimilarly, Copilot’s response introduces a different tack to the Southern \nmultilingualism lesson plan with aspects like Emphasising that it refers to the use of \nmultiple languages in the southern regions of sub-Saharan Africa and Introduce the idea \nof decolonial approaches to mult ilingualism. While these two aspects are equally \nrelevant to Southern multilingualism, the latter adds decoloniality, which is one \nof the characteristic features of Southern multilingualism (see Chaka, 2024c). The \nbetter quality of English responses vis -à-vis the other sets of responses (the low -\nresource language -only responses and the low -resource language English \nresponses) resonates with Lorandi and Belz’s (2023) observation that LLMs such \nas ChatGPT excel in English prompts and tasks as this reflects how high-resource \nlanguages like English dominates LLMs’ training datasets. This is the point taken \na step further by Navigli et al. (2023) who argue that the selection and creation of \ntraining data for the current LLMs is biased towards high-resource languages and \nignores low-resource languages. They also contend that this training data bias and \nimbalance manifests itself in richer quality and quantity of responses for high-\nresource languages as opposed to responses for low-resource languages, which \nare often poorer in quality. The current study has not only demonstrated how the \nlow-resource language -only responses were poor in quality and relevance as \ncompared to both the low -resource language English responses and the English \nlanguage responses, but it has also illustrated how such responses had the high \nquantity (the high word counts) of hallucinated , nonsensical and meaningless \ninformation. \n \n \n170 \n \nhttp://ijlter.org/index.php/ijlter \n7. Implications \nThis study has implications for the use of LLMs to generate responses from \nprompts that are exclusively in low -resource languages such as the ones which \nthe study investigated. The first implication is that LLMs hallucinate responses in \nlow-resource languages. This means that if academics and educators of low -\nresource languages think that currently available LLMs will be of any value to \nthem, they must think twice. The second implication relates to nonsense phrases \nor clauses. The LLMs investigated in this study generated nonsensical and \nsenseless r esponses in the five low -resource languages on which the study \nfocused. Here the picture is not rosy or promising at all, especially if the two \nSesotho responses (Figures 2 and 12) and the Yoruba response (Figures 6 and 7) \nand their respective translated English versions are anything to go by. If this is the \ncase, then, low -resource language academics and educators should expect \nnonsensical and senseless responses from the currently available LLMs, unless \nsomething radically changes. \n \nThe third implication is that the currently available  LLMs significantly lack \ngenerative multilingual capabilities in low-resource languages. In fact, they seem \nto have better monolingual generative capabilities  in English as a high -resource \nlanguage. This aspect is exemplified by the low -resource language responses \nproduced exclusively in English (n=11) by four of the seven LLMs investigated \n(e.g. GroqChat, ChatGPT, Copilot, and Perplexity) (see Table 1). The fourth and \nlast import is that the designers and data trainers of LLMs need to know that the \ncurrently available LLMs are heavily biased towards a high -resource language \nsuch as Englis h, while they grossly marginali se low-resource languages like the \nones investigated in this study. \n \n8. Conclusion \nThis study had three focal points stated in its three research questions mentioned \nearlier. Overall, the study found that the seven LLMs have a significant lack of \ngenerative m ultilingual capabilities in the five low -resource languages  \ninvestigated by the study . As a result of this generative multilingual deficiency, \nthe seven LLMs hallucinated when they were prompted to generate responses \nexclusively in these five low -resource languages. The hallucinations were more \nprofound and pervasive in isiZulu, Sesotho, a nd Yoruba responses. Allied to \nhallucinated responses is the fact that these LLMs spewed out nonsensical, \nmeaningless, and irrelevant responses in their low -resource language outputs. \nSuch nonsensical, meaningless, and irrelevant responses were more pronou nced \nand telling in the YouChat’s Sesotho response, the Perplexity’s Sesotho response, \nthe ChatGPT’s isiZulu response, and Claude’s Yoruba response, and in some \naspects of the YouChat’s Māori response. \n \nMoreover, the study discovered that the English language -specific responses or \nthe responses generated by all seven LLMs in English as a language were far better \nin quality, relevance, depth, detail, and nuance than the low -resource language-\nonly responses  and the English responses generated for the five low -resource \nlanguages. This aspect highlights how the seven, currently available LLMs \ninvestigated in this study are heavily skewed towards a high -resource language \n171 \n \nhttp://ijlter.org/index.php/ijlter \nsuch as English in their training data, while they grossly under -represent low-\nresource languages. This calls for more representative, cross -lingual and more \ninclusive training datasets for these LLMs than the ones they currently have, \nwhich are heavily bi ased towards high -resource languages like English.  This is \nwhat future research needs to consider.  Finally, one of the shortcomings of the \ncurrent study is that it focused only on five low-resource languages, two of which \nwere from the same region. \n \nNotes \n1. Sepedi is also known as Northern Sotho. \n2. Here, it is worth mentioning that Google South Africa’s search \nengine has , under its African language offerings, a Lesotho Sesotho \nversion, and not a South African Sesotho version. \n3. Quality response refers to an effective, reliable, and accurate LLM \nresponse as measured against its prompt. \n \nNB: The ethical clearance certificate for the current study was granted by the \nCollege Research Ethics Committee with the following registration and reference \nnumbers, respectively: NHREC Registration #: Rec -240816-052; and CREC \nReference #: 35288353_CREC_CHS_2024. \n \n9. References \nAboze, B. J. (2023). Risks of large language models: A comprehensive guide . \nhttps://www.deepchecks.com/risks-of-large-language-models/ \nAssociated Federated Press . (2024). ChatGPT faces Austria complaint over ‘uncorrectable \nerrors’. \nhttps://www.taipeitimes.com/News/biz/archives/2024/04/30/2003817178 \nAharoni, R., Narayan, S., Maynez, J., Herzig, J., Clark, E., & Lapata, M. (2024). Multilingual \nsummarization with factual consistency evaluation.  \nhttps://arxiv.org/pdf/2212.10622.pdf \nAIContentfy Team. (2023). Evaluating the effectiveness of AI detectors: Case studies and metrics. \nhttps://aicontentfy.com/en/blog/evaluating-of-ai-detectors-case-studies-and-\nmetrics \nAI Phrase Finder. (2024). The 100 most common AI words . \nhttps://aiphrasefinder.com/common-ai-words/ \nAkula, B., Andrews, P., Ayan, N. F., Barrault, L., Bhosale, S., Costa -jussa, M. R., Cross, J. \n… Youngblood, A. (2024). 200 languages within a single AI model: A breakthrough in \nhigh-quality machine translation. https://ai.meta.com/blog/nllb-200-high-quality-\nmachine-translation/ \nBanerjee, S., Agarwal, A., & Singla, S. (2024). LLMs will always hallucinate, and we need to \nlive with this. https://arxiv.org/pdf/2409.05746 \nChaka, C. (2022). Digital marginalization, data marginalization,and algorithmic \nexclusions: a critical southern decolonial approach to datafication, algorithms, \nand digital citizenship from the Souths. Journal of e-Learning and Knowledge Society, \n18(3), 83–95. https://doi.org/10.20368/1971-8829/1135678 \nChaka, C. (2023). Generative AI chatbots - ChatGPT versus YouChat versus Chatsonic: \nUse cases of selected areas of applied English language studies. International \nJournal of Learning, Teaching and Educational Research , 22(6), 1 –19. \nhttps://doi.org/10.26803/ijlter.22.6.1 \n172 \n \nhttp://ijlter.org/index.php/ijlter \nChaka, C. (2024a). Reviewing the performance of AI detection tools in differentiating \nbetween AI -generated and human -written texts: A literature and integrative \nhybrid review. Journal of Applied Learning & Teaching , 7(1), 1 –12. \nhttps://doi.org/10.37074/jalt.2024.7.1.14 \nChaka, C. (2024b). Accuracy pecking order – How 30 AI detectors stack up in detecting \ngenerative artificial intelligence content in university English L1 and English L2 \nstudent essays. Journal of Applied Learning & Teaching , 7(1), 1 –13. \nhttps://doi.org/10.37074/jalt.2024.7.1.33 \nChaka, C. (2024c). Multilingualism, translanguaging, diversity, equity, social justice, and \nactivism: A tenuous nexus and misrepresentations? International Journal of \nLanguage Studies, 18(1), 7-28. https://doi.org/10.5281/zenodo.10468173 \nCaptain Words. (2024). Testing AI detection tools – Our methodology . \nhttps://captainwords.com/ai-detection-tools-test-methodology/ \nCave, S., & Dihal, K. (2020 ). The Whiteness of AI. Philosophy & Technology , 33, 685–703. \nhttps://doi.org/10.1007/s13347-020-00415-6 \nDale, D., Voita, E., Lam, J., Hansanti, P., Ropers, C., Kalbassi, E., Gao, C., Barrault, L, & \nCosta-jussà, M. R. (2023). HalOmi: A manually annotated benchmark for multilingual \nhallucination and omission detection in machine translation.  \nhttps://arxiv.org/pdf/2305.11746.pdf \nDelve, H. L., & Limpaecher, A. (2022,). Qualitative content analysis: Manifest content analysis \nvs. latent content analysis. https://delvetool.com/blog/manifest-content-analysis-\nlatent-content-analysis \nFerrara, E. (2023). Should ChatGPT be biased? Challenges and risks of bias in large language \nmodels. https://arxiv.org/pdf/2304.03738.pd \nGray, A. (2024). ChatGPT “contamination”: Estimating the prevalence of LLMs in the scholarly \nliterature. https://arxiv.org/pdf/2403.16887 \nGuerreiro, N. M., Alves, D. M., Waldendorf, J., Haddow, B., Birch, A., Colombo, P., & \nMartins, A. F. T. (2023). Hallucinations in large multilingual translation models . \nhttps://arxiv.org/abs/2303.16104 \nHadi, M. U., al tashi, q., Qureshi, R., Shah, A., muneer, a., Irfan, M., Zafar, A., Shaikh, M. \nB., Akhtar, N., Wu, J., & Mirjalili, S. (2023). Large language models: A comprehensive \nsurvey of its applications, challenges, limitations, and future prospects . \nhttps://d197for5662m48.cloudfront.net/documents/publicationstatus/181139/\npreprint_pdf/edf41a1f2a93aadb235a3c3aff2dcf08.pdf \nHeugh, K. A. (2021). Southern multilingualisms, translanguaging and transknowledging \nin inclusive and sustainable education. In P. Harding -Esch & H. Coleman (Eds.), \nLanguage and the sustainable development goals (pp. 37-47). British Council. \nHuang, H., Tang, T., Zhang, D., Zhao, W. X., Song, T. Xia, Y. & Wel, F. (2023). Not all \nlanguages are created equal in LLMs: Improving multilingual capability by cross-lingual-\nthought prompting. https://arxiv.org/abs/2305.07004 \nHuang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q.,  Peng, W., Feng, X., \nQin, B., & Liu, T. (2023). A survey on hallucination in large language models: Principles, \ntaxonomy, challenges, and open questions. https://arxiv.org/pdf/2311.05232 \nIBM. (2024). What are AI hallucinations? https://www.ibm.com/topics/ai-hallucinations \nKalai, A. T ., & Vempala, S. S. (2024, revised version). Calibrated language models must \nhallucinate. https://arxiv.org/abs/2311.14648 \nKleinheksel, A. J., Rockich -Winston, N., Tawfik, H., & Wyatt, T. R. (2020). Demystifying \ncontent analysis. American Journal of Pharmaceutical Education, 84(1), 127–137. \nLankford, S., Afli, H., & Way, A. (2023). adaptMLLM: Fine ‑tuning multilingual language \nmodels on low ‑resource languages with integrated LLM playgrounds. \nInformation, 14, 638. https://doi.org/10.3390/info14120638 \n173 \n \nhttp://ijlter.org/index.php/ijlter \nLee, N. T., Resnick, P., & Barton, G. (2019). Algorithmic bias detection and mitigation: Best \npractices and policies to reduce consumer harms . \nhttps://www.brookings.edu/research/algorithmicbias-detection-and-\nmitigation-best-practices-andpolicies-to-reduce-consumer-harms/ \nLeffer, L. (2024). AI chatbots will never stop hallucinating . \nhttps://www.scientificamerican.com/article/chatbot-hallucinations-inevitable/ \nLin, C., Gao, Y., Ta, N., Li, K., & Fu, H. (2023). Trapped in the search box: An examination \nof algorithmic bias in search engine autocomplete predictions. Telematics and \nInformatics, 85, 102068. https://doi.org/10.1016/j.tele.2023.102068 \nLorandi, M., & Belz, A. (2023). Data-to-text generation for severely under-resourced languages \nwith GPT -3.5: A bit of help needed from Google Translate . \nhttps://aclanthology.org/2023.mmnlg-1.9.pdf \nNavigli, R., Conia, S., & Ross, B. (2023). Biases in large language models: Origins, \ninventory, and discussion. ACM Journal of Data and Information Quality , 15(2), 1–\n21. https://doi.org/10.1145/3597307 \nNguyen, X. P., Aljunied, S. M., Joty, S., & Bing, L. (2023). Democratizing LLMs for low -\nresource languages by leveraging their English dominant abilities with linguistically -\ndiverse prompts. https://arxiv.org/abs/2306.11372 \nPatil, R., & Gudivada, V. (2024). A review of current trends, techniques, and challenges in \nlarge language models (LLMs). Applied Sciences , 14, 2074. \nhttps://doi.org/10.3390/app14052074 \nPerkins, M. (2023). Academic integrity considerations of AI large language models in the \npost-pandemic era: ChatGPT and beyond. Journal of University Teaching & Learning \nPractice, 20(2), 7. http://dx.doi.org/10.53761/1.20.02.07 \nPopenici, S. (2023). The critique of AI as a foundation for judicious use in higher education. \nJournal of Applied Learning and Teaching, 6 (2), 378 –384. \nhttps://doi.org/10.37074/jalt.2023.6.2.4 \nQin, L., Chen, Q., Zhou, Y., Chen, Z., Li, Y., Liao, L., Li, M., Che, W., & Yu, P. S. (2024). \nMultilingual large language model: A survey of resources, taxonomy and frontiers . \nhttps://arxiv.org/abs/2404.04925 \nRudolph, J., Tan, S., & Tan, S. (2023). ChatGPT: Bullshit spewer or the end of traditional \nassessments in higher education?. Journal of Applied Learning and Teaching , 6(1), \n342-363. https://doi.org/10.37074/jalt.2023.6.1.9 \nRudolph, J., Ismail, M. F., & Popenici, S. 2024). Higher education’s generative artificial \nintelligence paradox: The meaning of chatbot mania. Journal of University Teaching \nand Learning Practice, 21(6). https://doi.org/10.53761/pzd17z29 \nSnyder, A. (2023). AI’s language gap . https:// studies www.axios.com/2023/09/08/ai -\nlanguage-gap-chatgpt \nVashee, K. (2023). Making generative AI effectively multilingual at scale . \nhttps://blog.modernmt.com/making-generative-ai-multilingual-at-scale/ \nWu, J., Yang, S., Zhan, R., Yuan, Y., Wong, D. F., & Chao, L. S. (2023). A survey on LLM -\ngenerated text detection: Necessity, methods, and future directions . \nhttps://arxiv.org/pdf/2310.14724.pdf ",
  "topic": "Resource (disambiguation)",
  "concepts": [
    {
      "name": "Resource (disambiguation)",
      "score": 0.5412120819091797
    },
    {
      "name": "Computer science",
      "score": 0.4967194199562073
    },
    {
      "name": "Business",
      "score": 0.35062289237976074
    },
    {
      "name": "Linguistics",
      "score": 0.3498953580856323
    },
    {
      "name": "Philosophy",
      "score": 0.0747358500957489
    },
    {
      "name": "Computer network",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I165390105",
      "name": "University of South Africa",
      "country": "ZA"
    }
  ]
}