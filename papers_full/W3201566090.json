{
    "title": "Empirical Analysis of Training Strategies of Transformer-based Japanese Chit-chat Systems",
    "url": "https://openalex.org/W3201566090",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A5050424484",
            "name": "Hiroaki Sugiyama",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5108393420",
            "name": "Masahiro Mizukami",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5005486211",
            "name": "Tsunehiro Arimoto",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5022077395",
            "name": "Hiromi Narimatsu",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5108454997",
            "name": "Yuya Chiba",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5035788151",
            "name": "Hideharu Nakajima",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5113811751",
            "name": "Toyomi Meguro",
            "affiliations": [
                null
            ]
        }
    ],
    "references": [
        "https://openalex.org/W1857789879",
        "https://openalex.org/W2996287690",
        "https://openalex.org/W2963825865",
        "https://openalex.org/W3093715852",
        "https://openalex.org/W2963542740",
        "https://openalex.org/W2963310665",
        "https://openalex.org/W2963250244",
        "https://openalex.org/W1821462560",
        "https://openalex.org/W1974758710",
        "https://openalex.org/W3107826490"
    ],
    "abstract": "In recent years, several high-performance conversational systems have been proposed based on the Transformer encoder-decoder model. Although previous studies analyzed the effects of the model parameters and the decoding method on subjective dialogue evaluations with overall metrics, they did not analyze how the differences of fine-tuning datasets affect on user's detailed impression. In addition, the Transformer-based approach has only been verified for English, not for such languages with large inter-language distances as Japanese. In this study, we develop large-scale Transformer-based Japanese dialogue models and Japanese chit-chat datasets to examine the effectiveness of the Transformer-based approach for building chit-chat dialogue systems. We evaluated and analyzed the impressions of human dialogues in different fine-tuning datasets, model parameters, and the use of additional information.",
    "full_text": "Empirical Analysis of Training Strategies of Transformer-based Japanese\nChit-chat Systems\nHiroaki Sugiyama Masahiro Mizukami Tsunehiro Arimoto Hiromi Narimatsu\nYuya Chiba Hideharu Nakajima\nNTT Communication Science Laboratories, Japan\nToyomi Meguro\nAbstract\nIn recent years, several high-performance con-\nversational systems have been proposed based\non the Transformer encoder-decoder model.\nAlthough previous studies analyzed the ef-\nfects of the model parameters and the de-\ncoding method on subjective dialogue evalua-\ntions with overall metrics, they did not analyze\nhow the differences of ﬁne-tuning datasets af-\nfect on user’s detailed impression. In addi-\ntion, the Transformer-based approach has only\nbeen veriﬁed for English, not for such lan-\nguages with large inter-language distances as\nJapanese. In this study, we develop large-scale\nTransformer-based Japanese dialogue models\nand Japanese chit-chat datasets to examine\nthe effectiveness of the Transformer-based ap-\nproach for building chit-chat dialogue systems.\nWe evaluated and analyzed the impressions\nof human dialogues in different ﬁne-tuning\ndatasets, model parameters, and the use of ad-\nditional information.\n1 Introduction\nA large-scale Transformer encoder-decoder model,\nwhich reportedly has high performance in question\nanswering and machine translation in the adjacent\nﬁelds of dialogue (Wang et al., 2018, 2019), has\nbeen applied to a chat dialogue system (Adiwar-\ndana et al., 2020; Roller et al., 2020). There are\ntwo chit-chat dialogue systems based on the Trans-\nformer model: Meena by Google and BlenderBot\nby Facebook. Both use for pre-training a large num-\nber of response pairs that are collected from SNS\nresponses or discussions on bulletin boards. Meena\nis the ﬁrst neural-based system that clearly sur-\npasses the conventional rule-based systems. It only\nuses simple response pairs obtained from SNS and\ntrains them with an extremely large amount of com-\nputation. BlenderBot is a large-scale, transformer,\nencoder-decoder model pre-trained with Reddit\ndata and ﬁne-tuned with a corpus of three skills\n(personality, empathy and knowledge) deﬁned by\nthe authors as necessary for chatting dialogues. By\ntraining on high-quality data, BlenderBot subjec-\ntively outperformed Meena with the same model\nsize with less computation and shows similar per-\nformance in comparison with humans.\nBlenderBot showed good performance in gen-\nerating chit-chat responses. Although its model\nbehaviors have been analyzed, three remaining un-\nrevealed issues have not yet been addressed. The\nﬁrst issue is how the characteristics of the train-\ning corpus affect user impressions. Since conven-\ntional work examined only one setting of the ﬁne-\ntuning datasets (even mixed datasets) of their mod-\nels and just used a few overall evaluation metrics\n(e.g., ACUTE, SSA), the effects of varying the ﬁne-\ntuning datasets on user impressions have not been\nexamined.\nAnother problem is that the system’s effective-\nness has only been veriﬁed for English, not for\nsuch languages with large inter-language distances\nas Japanese. Due to the differences in language\nresources and community sizes, non-English ini-\ntiatives on pre-trained models are much less com-\nmon compared to English. Multilingual BART\n(mBART) is one initiative that has used a multilin-\ngual corpus for simultaneous learning in multiple\nlanguages (Liu et al., 2020). Although it works\nwell for languages with close linguistic characteris-\ntics, such as European languages, it has performed\nless favorably for languages with distant linguistic\ncharacteristics, such as Japanese (especially in the\ngeneration task).\nIn this study, we develop large-scale\nTransformer-based Japanese dialogue mod-\nels and Japanese chit-chat datasets to examine the\neffectiveness of the Transformer-based approach\nfor building chit-chat dialogue systems. We also\nanalyze the relationship between user impressions\nand the ﬁne-tuning strategies of the Transformer\narXiv:2109.05217v1  [cs.CL]  11 Sep 2021\nSystem Let’s talk about your favorite things. (早速ですが\nご趣味をうかがってもいいですか?)\nUser I like traveling, especially traveling alone. ( 私の\n趣味は、旅行です！一人旅！)\nSystem Awesome! Do you generally travel domestically\nor overseas? ( そうなんですね! 旅行は国内で\nすか?海外ですか?)\nUser Overseas. I love going to Europe! (海外旅行のほ\nうが多いです！ヨーロッパとか大好きなんで\nす)\nSystem Europe sounds great. Which country have you been\nto? ( ヨーロッパいいですね! 特にどの国に行\nかれましたか?)\nUser Italy, many times to Venice. (何度も行ってるの\nは、イタリアのベネチアです)\nSystem I’ve never been to Venice. What’s it like? (ベネ\nチア行ったことないです! どんなところです\nか?)\nUser It’s a ﬂoating city, and the whole city is World\nHeritage. We can travel around by boats. (街全体\nが世界遺産の水上都市です。交通手段が船だ\nけなんですよ)\nSystem That’s interesting. I want to visit there. The scenery\nlooks really beautiful! ( えー!すごいですね! 行\nってみたいです! 景色も綺麗そうですね!)\nUser Exactly! I took a lot of pictures. ( まさに！景色\nも最高です！写真撮りまくりです！)\nSystem I like taking pictures, too. What kind do you take?\n(写真撮るの好きです! どんなジャンル撮られ\nるんですか?)\nUser I often take pictures of scenery when traveling. (写\n真楽しいですよね！私は旅行先で景色撮るこ\nとが多いです)\nSystem So do I. Have you traveled anywhere recently? (私\nも同じです。旅行先で景色撮ってます。最近\nどこか行かれましたか?)\nUser No, not really, although I did recently go to Kyoto.\n(最近はなかなか出かけてないですが、少し\n前に京都行きましたよ)\nTable 1: Example of Japanese chit-chat with our\nTransformer-based model (trained with our favorite-\nthings dialogue dataset)\nmodel, such as the dataset characteristic and\namount, model size, and the presence or absence of\nadditional information. Since we expect the above\nﬁne-tuning strategies to affect various impressions,\nthis study established multiple evaluation scales\nto conduct a multifaceted evaluation of the\nTransformer-based chatting system.\nThe following are the contributions of this paper:\n• Pre-trained, evaluated, and published a\nJapanese dialogue model with data compa-\nrable in scale to the SoTA systems in English1\n(Table 1).\n• Created and published benchmark data for a\nchit-chat dialogue system in Japanese.\n1We are preparing for releasing the models and datasets.\n• Analyzed the impact of ﬁne-tuning strategies\n(datasets used, model size and the use of addi-\ntional information) on subjective evaluations.\n2 Pre-training\n2.1 Model architecture\nWe generated responses with standard Seq2Seq\nTransformer encoder-decoder architecture, which\nwas also used with thegenerative model of Blender-\nBot (Roller et al., 2020). We used Sentencepiece\ntokenizer (Kudo and Richardson, 2018) as imple-\nmented in the Ofﬁcial Github site 2 to avoid unnec-\nessary dependency on a speciﬁc ﬁxed vocabulary.\nWe examined the improvement in model size\nin detail by considering four model sizes: 0.35B,\n0.7B, 1.1B, and 1.6B parameters. Although our\nlargest model (1.6B parameter) is slightly smaller\nthan the original BlenderBot 2.7B because of the\nlimitation of our computation resources, we believe\nthat the 1.6B-sized model is sufﬁcient to examine\nthe effect of model size.\n2.2 Pre-training dataset\nFor standard sentence classiﬁcation or machine\ntranslation, plain text is commonly used for pre-\ntraining with denoising tasks that aim to recover\noriginal sentences from noise-added ones. Meena\nand BlenderBot, on the other hand, use a large\namount of interactive data extracted from social\nnetworking sites or Reddit as pre-training to learn\nthe relationship between direct input contexts and\ntarget utterances.\nWe follow the conventional research and utilize\na large amount of Twitter reply pairs, which are\ninteractive data, for pre-training. The following is\nour data cleaning and setup procedures. First, we\nretrieved all the tweets from January 2016 to March\n2018 of randomly sampled Japanese users. After a\ntweet-cleaning process, we performed declension\nand removed the account names and emojis. Then\nwe removed the tweets that match the following\nconditions:\n• Tweets that have another tweet with a cosine\nsimilarity of 0.9 or higher on the same day\n(tweets with fewer than 20 characters are not\nﬁltered).\n• Retweets.\n• Tweets that contain URLs.\n2https://github.com/google/sentencepiece\nModel name Total Parameters V Lenc Ldec d h Steps PPL\n0.35B 359,607,808 32K 2 22 896 32 46K 5.159\n0.7B 698,536,960 32K 2 22 1280 32 48K 5.033\n1.1B 1,065,683,200 32K 2 22 1600 32 48K 4.968\n1.6B 1,627,872,000 32K 2 24 1920 32 48K 4.924\nTable 2: Training parameters of pre-trained models and perplexity on the validation set of our Twitter pre-training\ndataset for several models with given architecture settings. Columns include the vocabulary size (V), number\nof encoder and decoder layers ( Lenc, Ldec), embedding dimensionality (d), Multihead Attention Heads (h), and\ntraining steps.\n• Tweets that contain parentheses to prevent\nemoticons.\n• Tweets where the user is a bot.\n• Tweets that contain fewer than 30% Hiragana\nand Katakana characters.\nNext we extracted the tweets in a reply relation-\nship from the cleaned tweets and paired them with\nthe input contexts and target utterances. Using the\ntweet pairs, we extracted reply chains of tweets\nby extending the chain one by one from its root\ntweet. We utilized the last tweet of a chain as a\ntarget utterance and the rest that contain the root\nas the input context. For example, if the chain is\nA-B-C-D, we used A-B, AB-C, and ABC-D, but\nnot B-C. We obtained 2.1 billion (521 GB) pairs by\nthis method. The average number of utterances in\nthe input context was 2.913, and the average num-\nber of characters was 62.3 for the input context and\n20.3 for the target utterance. We built a Sentence-\npiece tokenization model (Kudo and Richardson,\n2018) using 20 million sentences sampled from the\ndata of a QA community service called ”Oshiete\ngoo!4” since the data cover the period from 2001\nto 2019 and contain more recent topics than our\npre-training data.\n2.3 Training details\nThe model parameters are based on the 2.7 bil-\nlion parameters of Meena and BlenderBot, where\nthe encoder is two layers and the decoder is 22 or\n24 layers. The number of dimensions of the hid-\nden layers is adjusted to avoid memory errors on\nthe GPU (V100 16GB) available at AIST ABCI\nCloud5, which is the computing resource we used.\nTable 2 shows the training parameters of each pre-\ntraining model used in this study, which are related\nto the model size.\n3The input context was calculated using 0.12% of the total\ndata.\n4https://oshiete.goo.ne.jp/\n5https://abci.ai/ja/\nThe other parameters are explored using Weight\nand Biases (Biewald, 2020) and set as follows. The\ndropout of the feed-forward layer and attention is\nset to 0.1. The learning rate is 1e-3, with 10000\nwarmup steps, and the maximum number of tokens\nper step is 2.4M. The objective function is set to\nlabel the smoothed cross entropy to promote early\nlearning. Our computational resources were 400\nV100 16GB cards. 48000 was the maximum num-\nber of training steps for the 1.6B model, where\nthe early stopping steps of the training were about\n45000 steps, which is almost equivalent to three\nepochs. The input format to the encoder connected\nthe utterances in the input context of each pair with\n[SEP] tokens; no other information was added.\nThe implementation uses the TransformerEn-\ncoderDecoderModel from fairseq6 that was trained\non a translation task. When we tried to pre-train on\na single dataset, the data were too large. Therefore,\nwe grouped the reply pairs by their Tweet dates and\ntrained them by data sharding. The validation data\nwere set to the 3/28/2018 data.\n3 Fine-tuning\nIn this study, we created a Japanese version of a\nsimilar corpus using BlenderBot as a reference and\nused it for ﬁne-tuning. In this section, we describe\nthe corpus used for ﬁne-tuning, the format of the\ninput information, and the detail settings of the\nﬁne-tuning.\n3.1 Fine-tuning dataset\nFor ﬁne-tuning BlenderBot, Roller et al. (2020)\nused PersonaChat, EmpatheticDialogues, and Wiz-\nard of Wikipedia as datasets that individually cor-\nrespond to three abilities: personality, empathy,\nand knowledge, which should be possessed by a\nchit-chat system, and simultaneously used Blend-\nedSkillTalk dataset to integrate the abilities. For\n6https://github.com/pytorch/fairseq\nﬁne-tuning our Japanese version of BlenderBot,\nwe develop a Japanese version of PersonaChat\nand EmpatheticDialogues and our original Fa-\nvoriteThingsChat datasets. Although we also tried\nto construct a Wizard of Wikipedia, conducting\nmeaningful conversations was actually very difﬁ-\ncult. In the construction of Wizard of Wikipedia\ndataset, a knowledge-offering interlocutor (wizard)\nof each dialogue can refer only the ﬁrst paragraph\nof Wikipedia pages, which gives a deﬁnition of the\npage content and is insufﬁcient for the wizard to\nexpand the dialogue meaningfully. Although we\nexamined the translation from the original English\nWizard of Wikipedia to Japanese one, many topics\nwere different from those that generally appear in\nJapanese conversations. After determining that it\ndid not contribute to the learning, we abandoned\nthe utilization of Wizard of Wikipedia.\nThe unavailability of the Wizard of Wikipedia\ngreatly complicated building the BlendedSkillTalk,\nwhich requires dialogue models that are learned\nin each of the three datasets. As an alternative\nof BlendedSkillTalk, we originally develop Fa-\nvoriteThingsChat dataset, which also contains ut-\nterances displaying empathy, knowledge and con-\nsistent personality. The details of each corpus are\ndescribed below.\n3.1.1 PersonaChat （PC）\nPersonaChat (Zhang et al., 2018) is a corpus where\neach speaker sets ﬁve proﬁle sentences that reg-\nulates the features of the speaker. Conversations\nare conducted based on the given proﬁle sentence\nset, and the conversations of various speakers are\ncollected in a pseudo manner. In this study, we con-\nstructed a Japanese version corpus of Persona-chat\nby creating a Japanese version of a proﬁle sentence\nset and collecting conversations by Japanese speak-\ners.\nThe Japanese version of the proﬁle sentence set\nis made as one proﬁle sentence set by combining\nﬁve sentences of 30 characters or fewer following a\nprevious method (Zhang et al., 2018). Cloud work-\ners created 100 sets. A trained annotator rewrote\nsome sentences to remove similar structures or\nwords.\nIn the dialogue collection, 100 sets of obtained\nproﬁle sentences were allocated to each cloud\nworker, and 5000 dialogues were collected. All\nthe cloud workers engaged in chats to talk about\nthe content of the set of proﬁle sentences given to\nthem. Each utterance alternately carried out one\nutterance, and a dialogue was collected so that one\nutterance can consist of a maximum of 100 charac-\nters, a minimum of 12 utterances, and a maximum\nof 15 utterances (6-8 turns). 61794 utterances were\nincluded in the 5000 collected dialogues.\n3.1.2 EmpatheticDialogues （ED）\nEmpatheticDialogues is a dataset that collects di-\nalogues with an open-domain one-on-one conver-\nsational setting where two people are discussing a\nsituation that happened to one of them, related to a\ngiven emotion (Rashkin et al., 2019). Rashkin et al.\n(2019) used crowdsourcing to collect 24,850 dia-\nlogues that are grounded descriptions of situations\nin which a speaker expresses a given feeling of 32\nemotional words. In this study, to make a Japanese\nversion of EmpatheticDialogues, we translated 32\nEnglish words that show emotions into Japanese,\nand a Japanese speaker used them to construct situ-\nation sentences and dialogues. To reduce collection\ncost, one dialogue was not an actual dialogue done\nby two workers; it was a pseudo dialogue writ-\nten by one worker. The crowdworker refers to the\ntranslated list of emotions and creates a context sen-\ntence of 1-3 sentences based on the emotions and\na text dialogue of four utterances by two persons\n(speaker and listener) who interact in the context.\n20,000 dialogues and 80,000 pairs of utterances\nwere collected.\n3.1.3 FavoriteThingsChat dataset （Fav）\nThe FavoriteThingsChat dataset consists of inten-\nsively collected chats about the favorites of various\npeople. All 80 experiment’s participants talked\nwith more than 60 other participants. We collected\n3480 dialogues and 123,069 utterances. Since the\nparticipants talk about their own actual favorites,\nthey proactively show knowledge about their own\nfavorites and display empathy and interest about the\ninterlocutor’s favorites with consistent personality.\nThe range of the presented topics is comparatively\nnarrow, because they are limited to the favorite\nthings of each speaker, and because only 80 speak-\ners repeatedly talk with each other participants. We\nexpect that dialogues collected with such the ”high\ndensity” dialogue collection setting are helpful for\nthe dialogue model to have enough knowledge to\nspeak each dialogue topic deeply. In addition, each\nconversation continues for a relatively large num-\nber of turns (average of 35.3), which is a suitable\nsetting for learning a long conversation. We ex-\npect that the learning will improve the dialogue\nSpeaker Utterance\n65 Hello! (こんにちは)\n71 (Pleased to meet you! (よろしくお願いします！\n)\n67 What do you do in your free time? ( 趣味はなん\nですか？)\n71 I like traveling, watching movies and reading\nbooks! How about you? ( 私の趣味は、旅行\nと映画を観たり本を読んだりすることです！\nあなたの趣味は何ですか？)\n67 I like watching baseball games and playing video\ngames Where have you traveled to recently? (趣味\nは野球観戦とゲームですねー　旅行は最近ど\nちらに行かれましたか？)\n71 Do you have a favorite team to watch baseball\ngames? ( 野球観戦は好きなチームがありま\nすか？)\n67 For professional baseball, I like Orix. (プロ野球\nだとオリックスですねー)\n71 Recently, I went to Okinawa last July and Toyama\nin May! Orix is the team where Ichiro joined, right?\n(最近は去年の7月に沖縄と5月に富山に行き\nました！オリックスは昔イチローがいたチー\nムですね？)\n67 Yes! But when I started rooting for them, he was\nin the major leagues... What kind of places did you\nvisit in Toyama...?(そうです！ただ僕が応援し\n始めたときにはメジャーリーグに行っていま\nしたねー富山はどういったところ廻られたん\nですか…？)\n71 That was a long time ago! Do you go to see games\nat the stadium? ( 結構昔ですもんね！ ！ ！試合を\nドームとかに観に行ったりもされるんです\nか？)\n67 Yes, I do. I didn’t go to many games last year, but\nI think I went to about 10 games the year before\nlast. (行きますねー去年はあんまりでしたが、\n一昨年は10試合ほど行ったと思いますー)\n71 In Toyama, there is a park with tulips, the most\nbeautiful Starbucks in Japan, and a glass museum.\nI went to a park with tulips, a beautiful Starbucks\nand a glass museum! I also ate white shrimps and\nToyama black (ramen)! (富山は、チューリップ\nがある公園と、日本一？美しいスタバとガラ\nスの美術館に行きました！あとは白エビ食べ\nたり、富山ブラック（ラーメン）食べたりし\nました！)\nTable 3: Example of our FavoriteThingsChat dataset)\nimpressions more than those conducted by more\nPersonaChat where the number of turns is low and\nthe speaker plays the Persona and Empathetic Dia-\nlogues with fewer turns and much data are deleted\nfrom one dialogue scene. Table 3 shows an exam-\nple of the collected dialogues.\n3.1.4 Mixed dataset （Mix）\nIn BlenderBot’s generative model, several kinds\nof corpus are mixed for ﬁne-tuning. No research\nhas clariﬁed yet whether the interaction function,\nwhich is the intention of each dataset, is achieved.\nNor has research investigated which improves\nthe interaction performance more: a high-quality\ndataset that is used singly or when the overall quan-\ntity is increased by adding another dataset. In this\nstudy, in addition to the case in which the above\ndataset is used for the ﬁne-tuning alone, we com-\npare the following two cases: one mixed in the\nsame quantity as each dataset and another where\neach dataset was mixed in the whole quantity.\n3.2 Use of additional information in query\nsentences\nIn response generation using the encoder-decoder\nmodel, when information is input to the encoder,\nin addition to the dialogue’s context, additional\ninformation can also be input in the same text for-\nmat. In this study, we analyzed the effect of the\npresence or absence of such additional information\non the impressions of dialogues. Such information\nmight improve the generation performance because\nclinging to it deleteriously affects long dialogues.\nBelow we show the information to be added to\neach dataset. PersonaChat, as in a previous work,\nadds a set of proﬁle statements to the input (Zhang\net al., 2018) to improve the utterance consistency\nby generating responses by linking them. In Empa-\ntheticDialogues, situation sentences and emotional\nwords are added to input sentences, as in previous\nstudies. The stability of utterance generation is ex-\npected to increase since the situation and the feeling\nto be generated are decided (Rashkin et al., 2019).\nIn the FavoriteThingsChat, only the speaker’s ID\nis added as information. In comparison with the\nabove two datasets of PersonaChat and Empathet-\nicDialogues, the effect seems comparatively small,\nbecause the information is not accompanied by\nconcrete content in a simple ID.\n<Dataset name >:[SEP]<Speaker ID >[SEP][SPK1]\n<System Utt.>t−2[SEP][SPK2] < User Utt.>t−1\nTable 4: Query sentence format input for Encoder\n3.3 Fine-tuning training details\nIn ﬁne-tuning, up to four utterances are used as a di-\nalogue context until the maximum character length\nreaches 128. As in the pre-training, Adafactor was\nused as the optimizer for training. The other param-\neters were changed from the pre-training settings:\nthe learning rate was 1e-4, 3000 warmup steps, and\na batch size of 256. With these settings, we trained\nup to 3000 steps (about 30 minutes with 128 V100\n16GB cards) with a model that minimized the per-\nplexity of the validation set.\n4 Sentence generation settings\nDecoding For decoding the utterances from the\nmodel, we adopted the sample-and-rank format\nas in Meena (Adiwardana et al., 2020). In this\nmethod, the ﬁnal output is the candidate with the\nlowest perplexity among N speech candidates gen-\nerated independently by sampling. In our initial\nstudy, we used the diverse beam search method that\nresembles BlenderBot. However, we found that the\nsample-and-rank method was more advantageous\nfor expanding the topics because the diverse beam\nsearch often produced somewhat boring responses.\nWe also introduced temperature T when calcu-\nlating the softmax that is used for controlling the\ntoken output probability (Hinton et al., 2015). A\ntemperature of T = 1results in normal sampling,\nand the higher temperature T is, the more con-\ntextually unusual tokens (e.g., proper nouns) are\ngenerated. At the same time, contextually incorrect\ntokens are more likely to be generated. Conversely,\nthe lower temperature T is, the more likely safe\nand common words will be selected. In addition,\nwe used nucleus sampling to limit the number of\nwords sampled by the probability cumulative den-\nsity (Holtzman et al., 2020). We used top p= 0.9\nand T = 1.0 based on preliminary experiments.\nFiltering candidate utterances In a preliminary\nexperiment, we found that many repetitive utter-\nances, generated from the models, have almost\nidentical content as the utterances in the past con-\ntext. To suppress such repetitive utterances, we\nﬁltered the candidate utterances with the similarity\nof the Gestalt pattern matching algorithm7 with ut-\nterances in the context and sentences (segmented\nby punctuation from the context utterances) exceed\nthreshold σr. We set σr to 0.5.\n5 Experiment\nAs described in Section 3, we analyzed how the\nuser’s impressions of the dialogue changed depend-\ning on the dataset used for ﬁne-tuning and inputting\nadditional information to the encoder. We also ana-\nlyzed the effects of the mixture of datasets and the\nmodel size on the overall performance.\n5.1 Experiment procedures for veriﬁcation\nThis section explains our verifying factors for ﬁne-\ntuning and experiment procedures.\n7https://docs.python.org/ja/3/library/difﬂib.html\nFine-tuning datasets The utterances contained\nin each dataset have different properties depending\non the dialogue function intended by the dataset.\nFor example, EmpatheticDialogues are expected\nto have empathetic and emotional utterances, and\nPersonaChat to have questions and self-disclosing\nutterances about the interlocutors’ personalities.\nThese properties will give users different dialogue\nimpression. We analyze how the user’s impression\nof the dialogue with the model changed depending\non the nature of the utterances in the ﬁne-tuning\ndatasets.\nFirst, we train a dialogue model using only the\nutterances contained in each dataset, without addi-\ntional information such as proﬁle sentences. We\ncall this setting as ﬂat. Then we let the experiment\nparticipants interact with all the model and evaluate\neach dialogue using 13 measures described below.\nWe compare the average values of the 13 metrics\namong the models v(mflat\nd ,s) ∈ Dto verify over-\nall performance of the models. We also compare\nthe values of the 13 metrics with their averages\nfor each ﬁne-tuning dataset to verify whether each\ncontributes to the value of a particular scale. Note\nthat, since we expected the range of values for each\nmetric to be different, we calculate normalized val-\nues of each metric with subtracting the average\nvalue of each metric for each dataset from the val-\nues assigned to each metric to reduce the effect of\nany differences in the metrics themselves. If the\ndifference value of a metric has a large absolute\namount, corpus-speciﬁc effects on the metric are\nbeing observed. We performed Friedman test for\nrepeated measurements (Friedman, 1937) on the\ndifferences of the normalized value of each metric\nfor each dataset. For the dataset that are found to\nbe signiﬁcant, we perform the Wilcoxon signed\nrank test (Wilcoxon, 1945) to examine the differ-\nence between each metric and the averaged scores.\nFor the multiple testing correction, we adopt the\nBH procedure that controls False Discovery Rate\n(Benjamini and Hochberg, 1995).\nUsing additional information We analyzed the\neffect of the presence of additional information\non the dialogue impressions based on Section 3.2.\nEven though using additional information may im-\nprove the generation performance, it might also\nnegatively impact long dialogues because of adher-\nence to the additional information. We verify the\neffect of the additional information through almost\nthe same process as the ﬂat condition described\nMetric name Questionnaire\nHumanness The system utterances were human-like and natural.\n(システムの発話は人間らしく自然だった)\nEase Continuing the dialogue was easy.\n(簡単に対話を続けることができた)\nEnjoyability I enjoyed interacting with the system.\n(システムとの対話は楽しかった)\nEmpathetic I was able to empathize with the system utterances.\n(システムの発話に共感できた)\nAttentiveness The system was interested in me and was actively trying to talk with me.\n(システムはあなたに興味を持って積極的に話そうとしていた)\nTrust I felt that what the system said was trustworthy.\n(システムの話したことは信頼できると感じた)\nPersonality I could sense the system’s personality and character.\n(システムの個性・人となりが感じられた)\nAgency I felt that the system was speaking from its own perspective.\n(システムは自身の考えをもって話していると感じた)\nTopic I felt that the system had a topic it wanted to discuss.\n(システムには話したい話題があると感じた)\nEmotion I felt that the system had feelings.\n(システムは感情を持っていると感じた)\nConsistency The system utterances were consistent and coherent.\n(システムの発話は矛盾せず一貫していた)\nInvolvement I was absorbed in this dialogue.\n(この対話にのめりこめた)\nRespeak I want to talk with this system again.\n(またこのシステムと話したい)\nTable 5: Evaluation metrics\nabove, with the difference of using additional infor-\nmation in the ﬁne-tuning (tagged condition).\nMixing ﬁne-tuning datasets We investigated\nthe impact of mixing multiple datasets on the over-\nall model performance. We considered two meth-\nods. The ﬁrst trained the model on the same amount\nof data as the individual datasets to test the useful-\nness of mixing different types of dialogues. Al-\nthough training on a wide range of data might im-\nprove the overall performance by robustly train-\ning the model, when mixing high- and low-quality\ndatasets, the performance might only be improved\nwith a high-quality dataset. The second case sim-\nply increases the amount of data. In this case, we\nexamined whether the performance is improved\nby increasing the amount of data, even with low-\nquality data.\nIn addition, we mixed the datasets under two\nconditions: one adds a word that represents each\ncorpus (” 個性雑談” (meaning PersonaChat in\nJapanese), ” 共感雑談” (EmpatheticDialogues),\nand ”趣味雑談” (FavoriteThingsChat))) at the be-\nginning of each input sentence of the dataset and\nadditional information that corresponds to each\ndataset (we call this as mixed-tagged condition);\nthe other only ﬁne-tunes from utterances without\nany additional information (mixed-ﬂat). In the in-\nference for actual conversations of mixed-tagged\ncondition, we use dataset type ” 趣味雑談” (Fa-\nvoriteThingsChat)) and randomly set IDs to be\nadded based on the settings of FavoriteThingsChat\nto minimize the additional information.\nModel size and ﬁne-tuning datasets In\nBlenderBot, the performance did not improve even\nwhen the model size increased. We investigated the\neffect of varying the model size and the training\ndataset on the performance. We used the average\nvalue of each measure and examined whether the\nevaluation values correlated with the model size\nfor each dataset.\n5.2 Evaluation metrics\nFitrianie et al. (2020) conducted an extensive meta-\nsurvey of evaluation measures of interactive vir-\ntual agents and user interaction and classiﬁed those\nused in existing research. The classiﬁed evalua-\ntion measures contain various perspectives, and\nare useful references for designing evaluation met-\nrics for dialogue systems in our study. However,\nsince the scales are not for textual dialogues but for\ndialogues with CG-visualized virtual agents, they\ninclude many multi-modal factors such as appear-\nance, while the scales are rather rough in terms\nof language operational ability. Therefore, we dis-\nFine-tuning corpus Size PC ED Fav Mix\nPre-trained 1.6B 38.45/39.50 27.35/28.03 29.35/33.41 31.65/33.67\nPC50k 0.35B 25.03/21.72 27.83/21.89 39.57/35.2 30.29/25.75\nPC50k 0.7B 23.06/19.77 24.11/19.41 35.25/31.30 27.08/23.07\nPC50k 1.1B 21.88/18.86 22.89/18.06 34.71/30.42 26.03/21.99\nPC50k 1.6B 21.32/18.35 22.15/17.58 34.06/29.58 25.38/21.39\nED50k 0.35B 42.84/33.92 19.72/15.64 38.64/37.05 32.86/27.82\nED50k 0.7B 39.15/30.50 17.81/14.13 35.99/34.09 30.12/25.25\nED50k 1.1B 38.47/28.78 16.97/13.42 35.53/33.39 29.37/24.19\nED50k 1.6B 34.22/28.26 16.21/13.05 31.05/32.26 26.52/23.54\nFav50k 0.35B 44.97/42.13 31.37/27.48 21.74/21.07 31.41/29.19\nFav50k 0.7B 41.50/39.34 28.46/25.12 19.97/19.60 28.79/27.05\nFav50k 1.1B 39.83/35.91 26.85/23.11 19.12/18.54 27.47/25.05\nFav50k 1.6B 37.23/34.79 25.26/22.21 19.05/17.94 26.30/24.21\nMix50k 0.35B 28.91/24.3 21.43/17.15 23.25/23.11 24.53/21.55\nMix50k 0.7B 26.27/22.00 19.23/15.43 21.36/21.20 22.29/19.56\nMix50k 1.1B 25.04/21.01 18.24/14.57 20.35/20.23 21.22/18.61\nMix50k 1.6B 24.21/20.43 17.58/14.20 19.83/19.60 20.55/18.09\nMix150k 0.35B 25.64/21.84 20.10/15.91 22.19/21.54 22.69/19.8\nMix150k 0.7B 23.52/20.00 18.00/14.33 20.48/20.02 20.71/18.13\nMix150k 1.1B 22.35/19.04 17.04/13.50 19.53/19.00 19.68/17.19\nMix150k 1.6B 21.69/18.46 16.41/13.09 18.94/18.24 19.05/16.61\nTable 6: Perplexity of compared models on each test dataset. Left values show ﬂat (no additional information)\ncondition and right show tagged (with additional information) condition.\ncard, integrate and divide the original measures to\nﬁt our research objectives. Our evaluation metrics\nare shown in Table 5.\n5.3 Collection of dialogue data\n5.3.1 Participants\nIn this study, we use crowdsourcing to conduct\nsubjective evaluations. We recruited 32 Japanese-\nspeaking crowdworkers from a Japanese crowd-\nsourcing service called Lancers 8. Only workers\nwho performed high-quality work were selected.\nThe unit price was set at 300 yen (about three dol-\nlars) per dialogue task. 32 workers were assigned\nto all 25 systems and collected one dialogue for\neach system.\n5.3.2 Dialogue task settings\nIn this study, based on a live dialogue system com-\npetition in Japan(Higashinaka et al., 2020), the dia-\nlogue length was set to 15 turns each by the system\nand the user. The conversation starts with a ﬁxed\nphrase from the system: ”Hello. Nice to meet\nyou.” After 15 utterances each, the following ﬁxed\nphrases notify the user of the dialogue’s end: ”Oh,\n8https://www.lancers.jp/\nI’m sorry. Our time is about up. Thank you for\ntoday.” The ”goodbye” answers the responses of\nthe 15 user utterances, and the conversation is ﬁn-\nished. After each conversation, a link is displayed\nby Google Form that evaluates the conversation. In-\nteraction evaluations are done by a 11-stage Likert\nscale that ranges from 0 (completely disagree) to\n10 (completely agree) for each item.\nA telegram platform was used for the interac-\ntions. The dialog environment (PCs, smartphones,\netc.) of the workers did not include any particular\nconstraints.\n6 Results and analysis\n6.1 Automatic evaluation\nTable 2 shows the perplexity of the pre-trained mod-\nels on the validation set of pre-training dataset. The\nperplexity decrease with larger models.\nTable 6 shows the perplexity of each model on\nthe test set of each ﬁne-tuning dataset. For all ﬁne-\ntuning datasets except Pre-trained, the larger the\nmodel size shows the lower the perplexity, and the\nuse of additional information improves the perplex-\nity.\nMeasure ED PC Fav Average\nNaturalness 5.81↑ 5.00 6.41 5.74\nEase 5.97 6.12 7.00 6.36\nEnjoyment 5.16 5.50 6.97 5.88\nEmpathy 4.25 4.94 6.03 5.07\nAttentiveness 4.31↓ 5.34 8.12↑ 5.93\nTrust 4.22 4.09 5.62 4.65\nPersonality 5.53 5.19 6.09 5.60\nAgency 5.78 5.00 6.22 5.67\nTopic 5.03 5.38 7.03 5.81\nEmotion 5.53↑ 4.66 5.69 ↓ 5.29\nConsistency 4.41↑ 3.25 4.81 4.16\nEngagement 4.94 4.78 5.59 5.10\nRespeak 4.88 4.59 5.94 5.14\nAverage 5.06 4.91 6.27\n(a) Human evaluations of models without additional information\n(ﬂat condition)\nMeasure ED PC Fav Average\nNaturalness 3.41 3.41 ↓ 7.09 4.64\nEase 4.12 3.81 7.12 5.02\nEnjoyment 3.50 3.47 6.22 ↓ 4.40\nEmpathy 2.84 2.88 5.84 3.85\nAttentiveness 2.75↓ 3.78 7.00 4.51\nTrust 2.44 2.22 6.00 3.55\nPersonality 3.66 3.53 6.06 4.42\nAgency 4.12 3.47 6.50 4.70\nTopic 5.00↑ 5.03↑ 6.50 5.51\nEmotion 2.97 3.44 5.91 4.11\nConsistency 1.50↓ 2.81 5.91 3.41\nEngagement 2.53 3.12 5.81 3.82\nRespeak 2.78 3.00 5.88 3.89\nAverage 3.20 3.38 6.30\n(b) Human evaluations of models with additional information\n(tagged condition)\nTable 7: Human evaluations on multi-axial evaluation measures: Up arrows denote corresponding dataset signif-\nicantly improved the evaluation metric, and down arrows denote decrease of metric (bold: p < .05, non-bold:\np<. 1).\n6.2 Human evaluation\n6.2.1 User impressions of ﬁne-tuning datasets\nWe analyzed how the various datasets used for ﬁne-\ntuning affected the user’s impressions using a multi-\naxial evaluation scale. Table 7a shows the evalu-\nation results using only the dataset sentences (ﬂat\ncondition). Table 7a shows that the ED dataset im-\nproved naturalness, emotion, and consistency but\nlowered attentiveness. Since ED has empathetic ut-\nterances for many kinds of situations and emotions,\nthe ED-trained model enables users to feel that\nthe system shows natural and consistent emotions.\nHowever, since the dialogues in the ED dataset only\nincluded four utterances, the system barely devel-\noped dialogue topics and simply repeats empathetic\nutterances, which probably decreased attentiveness.\nIn contrast, Table 7a illustrates that the PC has no\nsigniﬁcant effect on evoking speciﬁc impression\nincluding personality. Table 7a also shows that Fav\nimproved attentiveness scores but decreased emo-\ntion. This is because the Fav dataset consists of\nlong dialogues that contain many questions that ef-\nfectively improve attentiveness. On the other hand,\nsuch questions seem less effective to express the\nspeaker’s own emotions. From the viewpoint of\noverall impression, the Fav dataset signiﬁcantly\noutperforms the other two datasets.\nTable 7b shows the evaluation results that in-\nclude additional information ( tagged condition).\nED50k PC50k Fav50k Mix50k Mix150k\nCorpus\n0\n2\n4\n6\n8\n10mean\n5.06\n3.20\n4.91\n3.38\n6.276.30\n5.746.12 6.466.73\nAdd Info\nflat tagged\nFigure 1: Mixing datasets\nThe main difference with the ﬂat condition is the\nhuge decrease of the average overall scores of ED\nand PC. The ED and PC datasets have concrete di-\nalogue topics deﬁned with proﬁle sentences or situ-\nation information. Such information contributes to\nthe improvement of topic scores, but in the actual\ndialogues, these systems with additional informa-\ntion frequently generate persistent utterances that\nhave almost the same content of dialogue history.\n6.3 Mixing datasets\nWe also tested whether mixing datasets improved\nthe performance more than using a single dataset.\nFigure 1 shows the relationship between the cor-\nED50k PC50k Fav50k Mix50k Mix150k\nCorpus\n0\n2\n4\n6\n8\n10mean\n4.71\n3.99\n4.85 5.06 5.15\n4.41 4.67 4.91 4.83\n5.69 6.05 6.27\n5.20 5.32\n6.48\n5.74 5.41\n5.88 6.24 6.46\nModel size\n0.3B\n0.7B\n1.1B\n1.6B\nFigure 2: Variation of model size and datasets\npus and the average evaluation value for each ad-\nditional bit of information. In all cases, Mix50K\n<Fav50K <Mix150K. For the same amount of\ndatasets, the performance is slightly degraded by\nmixing datasets with low evaluations, such as ED\nand PC. On the other hand, when the total amount\nof datasets increased, the performance improved\neven when low evaluation datasets are mixed.\nWith respect to the presence or absence of addi-\ntional information, the evaluation of single datasets\n(especially ED and PC) tended to decrease with ad-\nditional information, and the performance of mixed\ndatasets improved with additional information. In\nthe case of a mixture of different datasets, learn-\ning to distinguish the type and specifying it with\nthe highest evaluation during inferences may have\ncontributed to the performance improvement.\n6.3.1 Model size and datasets\nThe performance of the model size for each corpus\nis shown in Figure 2. For Fav50k and Mix150k,\nthe model size is signiﬁcantly correlated with the\nevaluation value. On the other hand, for ED50k,\nPC50k, and Mix50k, the correlation between the\nmodel size and evaluation value was insigniﬁcant,\nindicating that the evaluation did not increase with\nthe model size. In general, performance improved\nas model size increased, and in fact, the perplexity\nimproved with increasing model size for all the\nmodels in Mix and Fav, although the results were\ndifferent from the objective evaluation. In fact, the\nperplexity improved with increasing model size\nfor all models in both Mix and Fav; the results\nwere different from the objective evaluations. This\nsuggests that in long dialogues, factors that strongly\naffect the impression cannot be measured by simple\nperplexity.\n7 Conclusion\nWe developed the largest Transformer-based\nJapanese dialogue models and Japanese version\nof PersonaChat and EmpatheticDialogues, which\nare widely used standard benchmarking dataset for\nevaluating chit-chat models in English. We also\nevaluated and analyzed the effects of the changes\nin the ﬁne-tuning datasets, model size, and the use\nof additional information on users’ impressions of\ndialogues from multiple perspectives. Our results\nidentiﬁed the following: The model performance\nand user impressions greatly depend on the sen-\ntences contained in ﬁne-tuning dataset, and this\neffect exists when additional information (e.g., pro-\nﬁle sentences) is not available. The use of addi-\ntional information is intended to improve speciﬁc\nimpressions, but it is not always beneﬁcial. A re-\nlationship between model size and overall perfor-\nmance varies greatly depending on the type of ﬁne-\ntuned corpus. We found that the model size did\nnot improve the PersonaChat and EmpatheticDia-\nlogues performance.\nFuture work will clarify the relationship how\ndialogue content or degrees of breakdown affect to\ndialogue impressions.\nAcknowledgement\nThis work was supported by JSPS KAKENHI\nGrant Number 19H05693.\nReferences\nDaniel Adiwardana, Minh-Thang Luong, David R. So,\nJamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang,\nApoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu,\nand Quoc V . Le. 2020. Towards a Human-like Open-\nDomain Chatbot.\nYoav Benjamini and Yosef Hochberg. 1995. Control-\ning the false discovery rate: a pratical and pow-\nerful approach to multiple testing. Journal of the\nRoyal Statistical Society. Series B (Methodological),\n57(1):289–300.\nLukas Biewald. 2020. Experiment Tracking with\nWeights and Biases.\nSiska Fitrianie, Merijn Bruijnes, Andrea Richards,\nDeborah B¨onsch, and Willem-Paul Brinkman. 2020.\nThe 19 Unifying Questionnaire Constructs of Arti-\nﬁcial Social Agents: An IV A Community Analysis.\nIn Proc. of ACM International Conference on Intel-\nligent Virtual Agents, pages 1–8.\nMilton Friedman. 1937. The Use of Ranks to Avoid\nthe Assumption of Normality Implicit in the Analy-\nsis of Variance. Journal of the American Statistical\nAssociation, 32(200).\nRyuichiro Higashinaka, Kotaro Funakoshi, Tetsuro\nTakahashi, Michimasa Inaba, Yuiko Tsunomori,\nReina Akama, Mayumi Usami, Yoshiko Kawabata,\nMasahiro Mizukami, Masato Komuro, and Dol¸ca\nTellols. 2020. The Dialogue System Live Compe-\ntition 3. In Proc. SIG-SLUD, pages 96–103.\nGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.\nDistilling the Knowledge in a Neural Network.\narXiv preprint arXiv:1503.02531.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2020. The Curious Case of Neural Text\nDegeneration. In Proc. of International Conference\non Learning Representations.\nTaku Kudo and John Richardson. 2018. SentencePiece:\nA simple and language independent subword tok-\nenizer and detokenizer for neural text processing. In\nProceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 66–71, Brussels, Belgium.\nAssociation for Computational Linguistics.\nYinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey\nEdunov, Marjan Ghazvininejad, Mike Lewis, and\nLuke Zettlemoyer. 2020. Multilingual denoising\npre-training for neural machine translation. Transac-\ntions of the Association for Computational Linguis-\ntics, 8:726–742.\nHannah Rashkin, Eric Michael Smith, Margaret Li, and\nY-Lan Boureau. 2019. Towards Empathetic Open-\ndomain Conversation Models: A New Benchmark\nand Dataset. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 5370–5381.\nStephen Roller, Emily Dinan, Naman Goyal, Da Ju,\nMary Williamson, Yinhan Liu, Jing Xu, Myle Ott,\nKurt Shuster, Eric M. Smith, Y-Lan Boureau, and\nJason Weston. 2020. Recipes for building an open-\ndomain chatbot. Arxiv preprint arXiv:2004.13637.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R Bowman. 2018.\nGLUE: A Multi-Task Benchmark and Analysis Plat-\nform for Natural Language Understanding. In\nProceedings of the 2018 EMNLP Workshop Black-\nboxNLP: Analyzing and Interpreting Neural Net-\nworks for NLP, pages 353–355.\nQiang Wang, Bei Li, Tong Xiao, Jingbo Zhu,\nChangliang Li, Derek F Wong, and Lidia S Chao.\n2019. Learning Deep Transformer Models for Ma-\nchine Translation. In Proceedings of the 57th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 1810–1822.\nFrank Wilcoxon. 1945. Individual Comparisons by\nRanking Methods. Biometrics Bulletin, 1(6).\nSaizheng Zhang, Emily Dinan, Jack Urbanek, Arthur\nSzlam, Douwe Kiela, and Jason Weston. 2018. Per-\nsonalizing Dialogue Agents: I have a dog, do you\nhave pets too? In Proceedings of the 56th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 2204–2213."
}