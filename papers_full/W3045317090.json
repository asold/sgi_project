{
  "title": "FedMed: A Federated Learning Framework for Language Modeling",
  "url": "https://openalex.org/W3045317090",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2098414586",
      "name": "Xing Wu",
      "affiliations": [
        "Shanghai University of Engineering Science",
        "Shanghai University"
      ]
    },
    {
      "id": "https://openalex.org/A3044825505",
      "name": "Zhaowang Liang",
      "affiliations": [
        "Shanghai University of Engineering Science"
      ]
    },
    {
      "id": "https://openalex.org/A2100724080",
      "name": "Jianjia Wang",
      "affiliations": [
        "Shanghai University",
        "Shanghai University of Engineering Science"
      ]
    },
    {
      "id": "https://openalex.org/A2098414586",
      "name": "Xing Wu",
      "affiliations": [
        "Shanghai University",
        "Shanghai University of Engineering Science"
      ]
    },
    {
      "id": "https://openalex.org/A3044825505",
      "name": "Zhaowang Liang",
      "affiliations": [
        "Shanghai University of Engineering Science"
      ]
    },
    {
      "id": "https://openalex.org/A2100724080",
      "name": "Jianjia Wang",
      "affiliations": [
        "Shanghai University",
        "Shanghai University of Engineering Science"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3007904747",
    "https://openalex.org/W2963864127",
    "https://openalex.org/W2801043270",
    "https://openalex.org/W2884935215",
    "https://openalex.org/W2016589492",
    "https://openalex.org/W6754354146",
    "https://openalex.org/W2759623768",
    "https://openalex.org/W2938722449",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2962788286",
    "https://openalex.org/W2624989916",
    "https://openalex.org/W2988166621",
    "https://openalex.org/W2982464076",
    "https://openalex.org/W2541884796",
    "https://openalex.org/W2913570153",
    "https://openalex.org/W2995191368",
    "https://openalex.org/W3037913917",
    "https://openalex.org/W3020982436",
    "https://openalex.org/W3009927559",
    "https://openalex.org/W3009175007",
    "https://openalex.org/W2970885630",
    "https://openalex.org/W3124299880",
    "https://openalex.org/W2946573451",
    "https://openalex.org/W2977678469",
    "https://openalex.org/W2941578813",
    "https://openalex.org/W2946900926",
    "https://openalex.org/W2774000609",
    "https://openalex.org/W6753262126",
    "https://openalex.org/W2936202865",
    "https://openalex.org/W2977860868",
    "https://openalex.org/W2950050806",
    "https://openalex.org/W2473418344",
    "https://openalex.org/W6674330103",
    "https://openalex.org/W2605516844",
    "https://openalex.org/W2963223306",
    "https://openalex.org/W6636649193",
    "https://openalex.org/W2537027648",
    "https://openalex.org/W6727099177",
    "https://openalex.org/W3101177651",
    "https://openalex.org/W2888785951",
    "https://openalex.org/W2761434131",
    "https://openalex.org/W2912213068",
    "https://openalex.org/W2989289980",
    "https://openalex.org/W1632114991",
    "https://openalex.org/W2579186979",
    "https://openalex.org/W2918777711",
    "https://openalex.org/W2951213900",
    "https://openalex.org/W2095705004",
    "https://openalex.org/W2793925626",
    "https://openalex.org/W2883158411",
    "https://openalex.org/W2999593354",
    "https://openalex.org/W2963803379"
  ],
  "abstract": "Federated learning (FL) is a privacy-preserving technique for training a vast amount of decentralized data and making inferences on mobile devices. As a typical language modeling problem, mobile keyboard prediction aims at suggesting a probable next word or phrase and facilitating the human-machine interaction in a virtual keyboard of the smartphone or laptop. Mobile keyboard prediction with FL hopes to satisfy the growing demand that high-level data privacy be preserved in artificial intelligence applications even with the distributed models training. However, there are two major problems in the federated optimization for the prediction: (1) aggregating model parameters on the server-side and (2) reducing communication costs caused by model weights collection. To address the above issues, traditional FL methods simply use averaging aggregation or ignore communication costs. We propose a novel Federated Mediation (FedMed) framework with the adaptive aggregation, mediation incentive scheme, and topK strategy to address the model aggregation and communication costs. The performance is evaluated in terms of perplexity and communication rounds. Experiments are conducted on three datasets (i.e., Penn Treebank, WikiText-2, and Yelp) and the results demonstrate that our FedMed framework achieves robust performance and outperforms baseline approaches.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8581936359405518
    },
    {
      "name": "Perplexity",
      "score": 0.695892333984375
    },
    {
      "name": "Laptop",
      "score": 0.6662862300872803
    },
    {
      "name": "Federated learning",
      "score": 0.6649494171142578
    },
    {
      "name": "Language model",
      "score": 0.6152108907699585
    },
    {
      "name": "Artificial intelligence",
      "score": 0.47924283146858215
    },
    {
      "name": "Data aggregator",
      "score": 0.462886780500412
    },
    {
      "name": "Scheme (mathematics)",
      "score": 0.4593825936317444
    },
    {
      "name": "Machine learning",
      "score": 0.45417970418930054
    },
    {
      "name": "Computer network",
      "score": 0.16982227563858032
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Wireless sensor network",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    }
  ]
}