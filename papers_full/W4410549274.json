{
  "title": "Large language models are proficient in solving and creating emotional intelligence tests",
  "url": "https://openalex.org/W4410549274",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2108977103",
      "name": "Katja Schlegel",
      "affiliations": [
        "Czech Academy of Sciences",
        "University of Bern",
        "Czech Academy of Sciences, Institute of Psychology"
      ]
    },
    {
      "id": "https://openalex.org/A2900748478",
      "name": "Nils R. Sommer",
      "affiliations": [
        "University of Bern"
      ]
    },
    {
      "id": "https://openalex.org/A2038769480",
      "name": "Marcello Mortillaro",
      "affiliations": [
        "University of Geneva"
      ]
    },
    {
      "id": "https://openalex.org/A2108977103",
      "name": "Katja Schlegel",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2900748478",
      "name": "Nils R. Sommer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2038769480",
      "name": "Marcello Mortillaro",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2157269017",
    "https://openalex.org/W2509899609",
    "https://openalex.org/W4400793809",
    "https://openalex.org/W4230277160",
    "https://openalex.org/W2894821115",
    "https://openalex.org/W3210036006",
    "https://openalex.org/W4210814395",
    "https://openalex.org/W3207465637",
    "https://openalex.org/W4381611857",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W4388824148",
    "https://openalex.org/W4399320026",
    "https://openalex.org/W4381612567",
    "https://openalex.org/W4388834311",
    "https://openalex.org/W4392976263",
    "https://openalex.org/W4403863303",
    "https://openalex.org/W4398143508",
    "https://openalex.org/W4367310920",
    "https://openalex.org/W4390414389",
    "https://openalex.org/W4384922658",
    "https://openalex.org/W4388127786",
    "https://openalex.org/W2133562625",
    "https://openalex.org/W4378470708",
    "https://openalex.org/W2034284819",
    "https://openalex.org/W2771919001",
    "https://openalex.org/W2896011761",
    "https://openalex.org/W4382491841",
    "https://openalex.org/W4372272969",
    "https://openalex.org/W4392763134",
    "https://openalex.org/W3010414986",
    "https://openalex.org/W4229889305",
    "https://openalex.org/W1630385374",
    "https://openalex.org/W2060716693",
    "https://openalex.org/W2091899122",
    "https://openalex.org/W2051672952",
    "https://openalex.org/W1990486840",
    "https://openalex.org/W4280598557",
    "https://openalex.org/W2087484885",
    "https://openalex.org/W4309379710",
    "https://openalex.org/W2901037057",
    "https://openalex.org/W2110065044",
    "https://openalex.org/W2139168999",
    "https://openalex.org/W3165373184",
    "https://openalex.org/W2045934080",
    "https://openalex.org/W2149522292",
    "https://openalex.org/W2018675479",
    "https://openalex.org/W4321277158",
    "https://openalex.org/W2055973627",
    "https://openalex.org/W2099006396",
    "https://openalex.org/W4388834665",
    "https://openalex.org/W4396787936",
    "https://openalex.org/W3182546273",
    "https://openalex.org/W4387966945",
    "https://openalex.org/W2527755291"
  ],
  "abstract": "Abstract Large Language Models (LLMs) demonstrate expertise across diverse domains, yet their capacity for emotional intelligence remains uncertain. This research examined whether LLMs can solve and generate performance-based emotional intelligence tests. Results showed that ChatGPT-4, ChatGPT-o1, Gemini 1.5 flash, Copilot 365, Claude 3.5 Haiku, and DeepSeek V3 outperformed humans on five standard emotional intelligence tests, achieving an average accuracy of 81%, compared to the 56% human average reported in the original validation studies. In a second step, ChatGPT-4 generated new test items for each emotional intelligence test. These new versions and the original tests were administered to human participants across five studies (total N = 467). Overall, original and ChatGPT-generated tests demonstrated statistically equivalent test difficulty. Perceived item clarity and realism, item content diversity, internal consistency, correlations with a vocabulary test, and correlations with an external ability emotional intelligence test were not statistically equivalent between original and ChatGPT-generated tests. However, all differences were smaller than Cohen’s d ± 0.25, and none of the 95% confidence interval boundaries exceeded a medium effect size (d ± 0.50). Additionally, original and ChatGPT-generated tests were strongly correlated (r = 0.46). These findings suggest that LLMs can generate responses that are consistent with accurate knowledge about human emotions and their regulation.",
  "full_text": "communicationspsychology Article\nA Nature Portfolio journal\nhttps://doi.org/10.1038/s44271-025-00258-x\nLarge language models are proﬁcient in\nsolving and creating emotional\nintelligence tests\nCheck for updates\nKatja Schlegel 1,2 ,N i l sR .S o m m e r1 & Marcello Mortillaro 3\nLarge Language Models (LLMs) demonstrate expertise across diverse domains, yet their capacity for\nemotional intelligence remains uncertain. This research examined whether LLMs can solve and\ngenerate performance-based emotional intelligence tests. Results showed that ChatGPT-4,\nChatGPT-o1, Gemini 1.5 ﬂash, Copilot 365, Claude 3.5 Haiku, and DeepSeek V3 outperformed\nhumans on ﬁve standard emotional intelligence tests, achieving an average accuracy of 81%,\ncompared to the 56% human average reported in the original validation studies. In a second step,\nChatGPT-4 generated new test items for each emotional intelligence test. These new versions and the\noriginal tests were administered to human participants across ﬁve studies (total N = 467). Overall,\noriginal and ChatGPT-generated tests demonstrated statistically equivalent test dif ﬁculty. Perceived\nitem clarity and realism, item content diversity, internal consistency, correlations with a vocabulary\ntest, and correlations with an external ability emotional intelligence test were not statistically\nequivalent between original and ChatGPT-generated tests. However, all differences were smaller than\nCohen’s d ± 0.25, and none of the 95% con ﬁdence interval boundaries exceeded a medium effect size\n(d ± 0.50). Additionally, original and ChatGPT-generated tests were strongly correlated (r = 0.46).\nThese ﬁndings suggest that LLMs can generate responses that are consistent with accurate\nknowledge about human emotions and their regulation.\nEmotions are crucial for forming and maintaining social bonds, and\neffectively communicating them is vital for achieving positive outcomes in\nindividuals and groups1. Thus, individuals with strong skills in recognizing,\nunderstanding, expressing, and responding to emotions (often summarized\nunder the term ability emotional intelligence or ability EI\n2) often achieve\nbetter outcomes across different life domains, such as the workplace. For\nexample, individuals with higher knowledge about emotions and emotion\nregulation strategies are perceived as warmer and more competent during\nworkplace conﬂicts\n3. Conversely, poor emotional communication and\nmanagement can lead to adverse outcomes, including loss of social support,\nimpaired mental health, and group disintegration1.\nBased on suchﬁndings, theﬁeld of affective computing has set out to\nembed ability EI into machines and applications like chatbots and virtual\nassistants in order to enhance socio-emotional outcomes among their users.\nSince Rosalind Picard’s seminal work in the late 1990s\n4, affective computing\nand robotics have made remarkable progress, propelled by advancements in\nmachine learning, neural networks, natural language processing, and other\nsubdomains within artiﬁcial intelligence (AI). For example, automatic\nemotion recognition from video, audio, and text is now on par with human-\nlevel accuracy, even with naturalistic stimuli\n5, and numerous applications to\nimprove socio-emotional outcomes in healthcare, education, workplace,\nand other domains have been developed (for a review, see\n6). These include,\nfor instance, socially assistive robots providing companionship and\nsupport7, conversational agents enhancing the learning process in online\neducational settings by adapting to the emotional states of the learners8,a n d\ntools that advise managers on how to improve workplace morale and\nproductivity based on employee mood and well-being obtained from con-\nversational surveys\n9.\nDespite these advances, however, the scope of many affective AI\napplications remains relatively narrow, with conversational agents often\nbeing limited to speciﬁc topics and lacking the ability to learn from and\nadapt to individual users6,7. To overcome these limitations, researchers\nhave argued that the currently relatively independent subﬁelds of affective\ncomputing— emotion recognition, generation, and application— need to be\nuniﬁed and more seamlessly integrated into AI systems to enable a more\ngeneral affective AI that is applicable beyond isolated use cases5.\n1Institute of Psychology, University of Bern, Bern, Switzerland. 2Institute of Psychology, Czech Academy of Sciences, Brno, Czech Republic. 3Swiss Center for\nAffective Sciences, University of Geneva, Geneva, Switzerland. e-mail: Katja.schlegel@unibe.ch\nCommunications Psychology|            (2025) 3:80 1\n1234567890():,;\n1234567890():,;\nThe recent rise of generative AI, particularly Large Language Models\n(LLMs) that power conversational agents like ChatGPT, may represent the\ncritical advancement for achieving the goal of a general affective AI. These\nmodels exhibit human-like linguistic behavior, enabling real-time, sophis-\nticated written conversations on any topic, making them promising can-\ndidates for artiﬁcial general intelligence (AGI) systems\n10. This development\nhas opened up many exciting possibilities but also challenges, putting us at\nthe outset of a“Brave new AI era”\n11–14. Importantly, state-of-the-art LLMs\nappear to generate responses consistent with knowledge of psychological\nconcepts like personality, theory of mind, emotions, or empathy, despite not\nbeing explicitly trained with scientiﬁcally-based knowledge on these\nconcepts\n15–17. As a result, ChatGPT (version 3.5), for example, responded to\npatients’medical questions in an online forum in a way that was rated\nsigniﬁcantly higher for both quality and empathy than human physicians18.\nThe advent of widely accessible LLMs has sparked a lively debate about\nthe scopes and limits of LLM-powered agents’human-like psychological\ncapacities, such as whether ChatGPT and similar agents can truly convey\nempathy\n10,19,20. While this debate is important, especially regarding user\nacceptance of conversational agents or robots, a more fundamental and\npragmatic question is how much LLMs’ responses are consistent with\naccurate reasoning about emotions, their causes, consequences, associated\nexpressions, and adaptive emotion regulation strategies. We argue that such\nreasoning, encapsulated in the construct of ability EI (e.g. refs.2,21)a n d\nsometimes referred to as cognitive empathy20,i sap r e r e q u i s i t ef o rL L M st o\nbe perceived as emotionally intelligent or empathic agents in settings such\nas healthcare, education, customer service, and other affect-laden interac-\ntions. Put differently, if LLMs fail to perform emotionally intelligent beha-\nv i o r so rt a s k s ,t h e ym a yl a c kt h en e c e s s ary prerequisites to achieve positive\nsocial outcomes or prevent detrimental ones in socio-emotional\napplications.\nOne straightforward way to address this question is to ask LLMs to\nsolve performance-based tests from the realm of ability EI designed to\nmeasure such knowledge and abilities in humans and to compare LLMs’\nperformance to human performance. In a study with an early version of\nChatGPT (3.5), ChatGPT scored higher than the average human population\non the Levels of Emotional Awareness Scale (LEAS)\n22, in which test-takers\nare asked to write about howﬁctional characters in vignettes would likely\nfeel23. This result suggested a more complex and nuanced processing of the\nvignettes and their emotional implications by ChatGPT compared to\nhumans.\nIn theﬁrst part of the present research, we extend this promising early\nﬁnding to a larger number of EI competencies, tests, and LLMs. Speciﬁcally,\nwe compared the scores obtained by ChatGPT-4, ChatGPT-o1, Copilot 365,\nClaude 3.5 Haiku, DeepSeek V3, and Gemini 1.5ﬂash onﬁve published\nability EI tests to the average performance of human test-takers from the\noriginal validation studies. Two of the tests measure understanding of\nemotions and their causes and consequences by presenting vignettes\ndescribing emotional situations andasking test-takers to infer the most\nlikely emotion or blend of emotions that the character in the scenario was\nfeeling (Situational Test of Emotion Understanding, STEU\n24; Geneva\nEMOtion Knowledge Test, GEMOK-Blends25). The other three tests mea-\nsure knowledge about the most appropriate course of action to regulate\neither one’s own emotions (Geneva Emotional Competence Test, GECo—\nEmotion Regulation subtest26) or another person’se m o t i o n s( G E C o—\nEmotion Management subtest26; Situational Test of Emotion Management,\nSTEM24). While allﬁve tests use a situational judgment format with correct\nand incorrect response options, they differ substantially in scenario struc-\nture, setting (workplace or general life), complexity, length, and emotions\nincluded. This variety allows for more general conclusions about LLM’s\nability EI performance (see method section for details and example items in\nthe supplementary material). Given the results in Elyoseph and colleagues’\nstudy\n23 as well as results regarding related competencies such as Theory of\nMind (e.g., false-belief tasks10), we expected all LLMs to generate sig-\nniﬁcantly higher scores than the averageof the human validation samples of\neach test.\nIn the second part of this research, we used ChatGPT-4 to create a new\nset of items (i.e., new scenarios and response options) for each of theﬁve\ntests. We compared the psychometric quality of the ChatGPT-created test\nversions to that of the original tests throughﬁve studies conducted on\nProliﬁc. In each study, one of the new test versions (e.g., the ChatGPT-\ncreated version of the STEM) was administered alongside the original test\nversion (e.g., the STEM), a vocabulary test to measure crystallized intelli-\ngence, and another ability EI test (e.g., the GECo Emotion Management\nsubtest) to assess construct validity. Participants also rated the clarity, rea-\nlism, and item content diversity for each new and original test version.\nCompared to assessing LLMs’accuracy in solving ability EI test items,\nthis part of the research aimed to more rigorously test the idea that\nChatGPT-4, as one of the most widely used LLMs, is proﬁcient at generating\nresponses that demonstrate accurateknowledge about the structure and\ncomponents of emotions and how they can be adaptively regulated in\noneself and others. Because severalstudies have found the quality and\nbelievability of texts written by ChatGPT (in the context of simulating\ncertain personality traits or cogniti v ea b i l i t i e s )t ob es a t i s f a c t o r y\n27–29,w e\nexpected the ChatGPT-4-created test versions in our study to exhibit similar\npsychometric properties as the original test versions. Speciﬁcally, we\nexpected that, across theﬁve studies, original and ChatGPT-generated tests\nwould show at most small differences in terms of test difﬁculty, internal\nconsistency (Cronbach’s alpha and average item-total correlations), ratings\nof clarity, realism, and item diversity, and their average correlation with\ncrystallized intelligence and a different ability EI test.\nMethods\nEmotional intelligence tests\nSituational Test of Emotion Management (STEM)24. The STEM con-\nsists of 44 short (2–3 sentences) vignettes that each describe aﬁctional\nperson experiencing a negative emotional situation (broadly reﬂecting\nanger, sadness, fear, or disgust) at work or in personal life. Participants are\nthen asked to choose which of four actions would be the most effective for\nthe person. The actions reﬂect six emotion regulation strategies (no\nregulation, situation selection, situation modi ﬁcation, attentional\ndeployment, cognitive change, response modulation).\nAn example item is:\n“Surbhi starts a new job where he doesn’t know anyone andﬁnds that\nno one is particularly friendly. Whataction would be the most effective for\nSurbhi? (a) Have fun with his friends outside of work hours. (b) Concentrate\non doing his work well at the new job. (c) Make an effort to talk to people and\nbe friendly himself. (d) Leave the job and ﬁnd one with a better\nenvironment.”\nThe full item list is available athttps://doi.org/10.1037/a0012746.supp.\nCorrect responses were deﬁned by experts and responses were scored as 0\n(incorrect) or 1 (correct) and aggregated into a total score reﬂecting the\nproportion of correct answers (possible range 0–1). The STEM was vali-\ndated using a sample of 112 undergraduate students in Australia (Study 1\n24).\nThis sample was a subset of the STEU validation sample (N = 200)\ndescribed below.\nSituational Test of Emotion Understanding (STEU)24. The STEU\nconsists of 42 vignettes (2–3 sentences each). In 36 items, the vignettes\ndescribe a concrete or abstract situation and participants choose which\nout ofﬁve emotion words best describes what the person involved is most\nlikely to feel. An example item is:“A supervisor who is unpleasant to work\nfor leaves Alfonso’s work. Alfonso is most likely to feel? (a) Joy, (b) Hope,\n(c) Regret, (d) Relief, (e) Sadness”.\nIn the remaining six items, an emotion is presented and participants\nchoose what most likely happened tocause that emotion; for example:\n“Quan and his wife are talking about what happened to them that day.\nSomething happened that caused Quan to feel surprised. What is most likely\nto have happened? (a) His wife talked a lot, which did not usually happen.\n(b) His wife talked about things that were different to what they usually\ndiscussed. (c) His wife told him that she might have some bad news. (d) His\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 2\nwife told Quan some news that was not what he thought it would be. (e) His\nwife told a funny story.” The full item list is available athttps://doi.org/10.\n1037/a0012746.supp.\nCorrect answers were deﬁned based on the emotion-speciﬁca p p r a i s a l\npatterns deﬁned by appraisal theory30. Items were scored as correct or\nincorrect and aggregated into a total score reﬂecting the proportion of\ncorrect responses. The STEU was validated in a sample of 200 under-\ngraduate students in Australia (68% women, age M = 21.1, SD = 5.6;\nStudy 1\n24).\nGeneva EMOtion Knowledge Test —Blends (GEMOK-B) 25. The\nGEMOK Blends consists of 20 vignettes (each about 100–140 words long)\nin which aﬁctional person experiences a situation characterized by two\nconsecutive or blended emotions. The descriptions contain cues repre-\nsenting ﬁve emotion components (appraisals, feeling, action tendencies,\nexpression, and physiology\n31). Based on these cues, participants are asked\nto infer which two emotion words best describe what the target person\nwas feeling in the situation.\nAn example item is:\n“Rachel is going to a concert of her favorite band with her best friends.\nEven before the concert starts, Rachel feels like singing and dancing. She\nchats and laughs with her friends, and enjoys the atmosphere. When the lead\nsingerﬁnally comes on stage and sings Rachel’s favorite song, her heart starts\nto beat faster. Rachel closes her eyes so she can get totally absorbed in this\nmoment. She wishes it could last forever. Which of the following emotions\ndescribe best what Rachel was experiencing during this episode? (a) Hap-\npiness and pleasure, (b) Joy and happiness, (c) Joy and pride, (d) pleasure\nand interest, (e) joy and sadness.” The full item list is available athttps://\nwww.tandfonline.com/doi/suppl/10.1080/02699931.2017.1414687.\nCorrect answers were deﬁned based on theoretically and empirically\nderived cue patterns for each emotion\n32. The GEMOK-Blends total score\nreﬂects the proportion of correct responses. Theﬁnal version of the test was\nvalidated in 180 English-speaking MTurk workers (50% women; age\nM = 35.70, SD = 11.40).\nGeneva Emotional Competence Test in the workplace (GECo)26. The\nGECo consists of four subtests that measure emotion recognition ability\nfrom nonverbal cues, emotion understanding, emotion regulation in\noneself, and emotion management in others. In the present study, only\nthe latter two were used. TheEmotion Regulationsubtest consists of 28\nvignettes (about four sentences each) describing situations in the work-\nplace in which the test-taker is feeling a certain emotion. Participants are\nasked to choose two out of the four response options that best reﬂect what\nthey would think in this situation. Two of the options correspond to\nadaptive emotion regulation strategies (acceptance, positive refocusing,\nfocusing on planning, putting into perspective, or reappraisal), and two\noptions correspond to maladaptive emotion regulation strategies (cata-\nstrophizing, rumination, self-blame, or other-blame\n33).\nAn example item of the GECo Regulation subtest is:\nYou successfully completed a very important project that took a lot of\nyour time. When you return to your daily business, your boss tells you that\nhe is unhappy that you neglected your other projects. You are very irritated\nabout the lack of acknowledgement by your boss. What do you think? (a)\nYou think that you should have been better organized and have worked on\nall the projects at the same time. (b) You think that you have to accept that\nbosses are never fully satisﬁed. (c) You think about the very positive feedback\nfrom the client for whom you completed the project. (d) You think that your\nboss is always unfair to you and thatyou should consider quitting if it\ncontinues.\nParticipants received zero points if they chose the two maladaptive\noptions, 0.5 points if they chose one adaptive and one maladaptive option,\nand one point if they chose both adaptive options. These points are aggre-\ngated into a total score ranging from 0 to 1.\nThe Emotion Managementsubtest consists of 20 vignettes (about\n4 sentences each) in which another person (colleague, client etc.)\nexperiences an emotion and participants are asked to choose, out ofﬁve\ncourses of action, what they would most likely do. Theﬁve response options\nrepresent conﬂict management styles: accommodation, collaboration,\ncompromise, competing, and avoidance\n34.\nAn example item of the GECo Management subtest is:\n“Your colleague with whom you get along very well tells you that he is\ngetting dismissed and that you will be taking over his projects. While he is\ntelling you the news he starts crying. He is very sad and desperate. You have a\nmeeting coming up in 10 min. What do you do? (a) You take some time to\nlisten to him until you get the impression he calmed down a bit, at risk of\nbeing late for your meeting; (b) You cancel your meeting, have a coffee with\nhim and say that he has every right to be sad and desperate. You ask if there is\nanything you can do for him; (c) You tell him that you are sorry, but that\nyour meeting is extremely important. You say that you mayﬁnd some time\nanother day this week to talk about it;(d) You suggest that he joins you for\nyour meeting with your supervisor so that you can plan the transfer period\ntogether; (e) You cancel your meeting and offer him to start discussing the\ntransfer of his projects immediately.”\nCorrect responses are deﬁned based on conﬂict management theory\n34\nwhich speciﬁes the contextual factors under which each of theﬁve strategies\nis the most appropriate one. Each strategy is the correct option in four of the\n20 items. Correct responses are aggregated into a total score ranging from 0\nto 1. The GECo Regulation and Management subtests were validated with\nEnglish-speaking undergraduate students and university staff members\n(55% women; ageM = 22.3,SD =3 . 2 ;S t u d y2\n26).\nAssessing ChatGPT’s performance in solving EI test items\nTo test the assumption that LLMs would outperform humans in solving EI\ntest items, ChatGPT-4, ChatGPT-o1, Gemini 1.5 ﬂash, Copilot 365,\nDeepSeek V3, and Claude 3.5 Haiku were asked to solve the items of the\nSTEM, STEU, GEMOK Blends, GECo Regulation and GECo Management\nsubtests in December 2024 and January 2025. The LLMs received the ori-\nginal test instructions (i.e., to choosethe correct response option) as well as\nall items thatﬁt within the character limit (e.g., 10,000 characters for Copilot\n365). The remaining items were inserted in separate prompts. Separate\nconversations were used for each test. Each LLM was prompted to solve each\ntest 10 times in separate conversations. The number of correct responses for\neach test and trial was recorded, and for each LLM, the mean score and\nstandard deviation across the 10 trials per test were computed. Mean scores\nacross all six LLMs for each test were compared to the mean scores of human\nrespondents obtained from the publications of the original validation stu-\ndies using independent samplest tests. We preregistered the procedure for\nprompting ChatGPT-4 to solve each test once and comparing its perfor-\nmance with the human validation samples (link to preregistration:https://\nosf.io/mgqre/registrations). However, we did not preregister including other\nLLMs or to prompt each LLM 10 times (i.e., conducting ten trials).\nAssessing ChatGPT’s performance in creating EI test items\nItem generation with ChatGPT-4 and comparison with original\nitem sets. Theﬁrst of the 10 trials of ChatGPT-4 in solving theﬁve tests\nwas used as a basis for item generation. First, for those items that were not\ncorrectly solved, we provided ChatGPT-4 with the correct answers.\nSecond, we instructed ChatGPT-4 to generate the same number of new\nitems and deﬁne their correct answers based on the items it had just\nsolved (except for the STEM and STEU, where ChatGPT-4 was prompted\nto generate 18 and 19 items, respectively, akin to their validated short\nversions STEM-B and STEU-B\n24). Importantly, we attempted to have all\nnew items created with just one prompt. Prompts were engineered in an\niterative fashion based on an inspection of the answers provided by\nChatGPT. The prompt for a given test was consideredﬁnal when the\ngenerated items fulﬁlled the same formal criteria as the original test items\n(e.g., contained the desired strategies in the response options, the same\nemotions in the vignettes, etc.). Theﬁnal prompts used for item gen-\neration, as well as the generated items, are provided in the Supplementary\nMaterial (Supplementary Notes 1 and 2).\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 3\nSimilarity rating study. This study (not preregistered) examined the\ndegree of similarity between the original and ChatGPT-created test items\nfor each of theﬁve tests. Speciﬁcally, we aimed to test if some of the\nChatGPT-created items were merely paraphrased versions of an original\ntest item, which would challenge the idea that ChatGPT-4 is able to\ngenerate responses demonstrating accurate knowledge about emotional\nsituations. To this end, 434 Proliﬁc participants rated the similarity\nbetween all combinations of original and ChatGPT-created scenarios\n(i.e., the items without the response options) for each of theﬁve tests\n(STEU, STEM, GEMOK, GECo Regulation, GECO Management). Par-\nticipants were based in either the UK or the US and had indicated English\nas theirﬁrst language. Gender and age were self-reported by participants\n(182 men, 243 women, 9 individuals with other gender identity; age\nM = 38.5 years,SD = 12.7 years).\nFor each of theﬁve tests, parcels of about 50 randomly selected scenario\npairs (each containing one original test item scenario and one ChatGPT-\ncreated item scenario) were created.F o re x a m p l e ,f o rt h eS T E M ,t h e r ew e r ea\ntotal of 792 scenario pairs to be rated (44 original STEM items* 18\nChatGPT-created STEM items), which were randomly divided into 16\nparcels of 49 or 50 scenario pairs. Across theﬁve tests, a total of 3174 sce-\nnario pairs (divided into 64 parcels) were rated. Besides the scenario com-\nbinations, each parcel also contained three attention-check scenario pairs\nthat were paraphrased versions of each other, the idea being that they should\nbe rated as highly similar (i.e., with a 6 or 7). For example, one such\nattention-check scenario pair for the STEM was (1) Reece’s friend points out\nthat her young children seem to be developing more quickly than Reece’s.\nR e e c es e e st h a tt h i si st r u e .[ O r i g i n a lS T E Ms c e n a r i o ] ,( 2 )R o s i e’s friend\nobserves that her young children appear to be developing faster than Rosie’s,\nand Rosie realizes this is accurate. [Paraphrased STEM scenario].\nParticipants were randomly assigned to rate one of the parcels (i.e.,\ncontaining about 50 scenario pairs plus 3 attention check pairs) and received\nthe following instructions:\n“You will now see pairs of scenarios describing emotional situations.\nPlease rate how different or similar each pair of scenarios is, on a 7-point\nscale from“very different” to “very similar”. For the purpose of this study,\n“very similar” scenarios are situations that are almost identical, but are\ndescribed using different words and/or names.\nHere is an example of two scenarios that we consider“very similar”:\n Naya volunteers at an animal shelter and carefully plans her schedule\neach week. One morning, she arrives to discover her assigned tasks have\nbeen completely changed without any prior notice.\n Niya works at an animal shelter, organizing her schedule in advance\neach week. When she arrives one morning, sheﬁn d so u th e rt a s k sw e r e\nreassigned without her being informed.\nIn contrast, below is an example of two scenarios that we consider“very\ndifferent”:\n Riley ordered a new laptop for an important project, but it arrived\ndamaged. Despite multiple calls to customer service, no resolution has been\noffered.\n At a big meeting, Malik accidentally projected a personal email\ninstead of his presentation. He quickly tried to hide it, but everyone had\nalready noticed.”\nOn the next page, participants were asked to describe their task in the\nstudy using their own words in 1–2 sentences, before completing the ratings\nfor all scenario pairs in their parcel. Depending on the duration of the survey\n(e.g., the GEMOK parcels took longer to read than the STEM parcels;\naverage duration per survey 11–17 min), they were paid between 2 CHF and\n2.50 CHF for their participation. Participants who did not correctly respond\nto the attention check items (i.e., did not rate all three attention check\nscenario pairs with 6 or 7) or wrote a nonsensical text when describing their\ntask were excluded and are not part of the N of 434 described above. The\nstudy procedure resulted in 6 to 8 ratings for each scenario pair across allﬁve\ntests. The average ratings for each scenario pair are provided in Supple-\nmentary Tables 1–8, with all pairs that received a rating of 5.0 and higher\nhighlighted in blue. The raw dataﬁles can be accessed in the supplementary\ndata folder in“data and analysis scripts”on OSF:https://osf.io/mgqre/ﬁles/\nosfstorage.\nFor each ChatGPT-created scenario (20 for GEMOK, 20 for GECo\nEmotion Management, 28 for GECo Regulation, 19 for STEU, and 18 for\nSTEM, totaling 105 scenarios), we identiﬁed the original test scenario with\nthe highest perceived similarity. For example, for item 1 from the ChatGPT-\ncreated STEU, the most similar original scenario was scenario 36, with a\nsimilarity rating of 4.4 (see column 1 in Supplementary Table 2). Table1\npresents the distribution of these highest similarity ratings across the 105\nChatGPT-created scenarios.\nThe numbers of scenarios created by ChatGPT that received a simi-\nlarity rating of 5 or higher with at least one of the original scenarios were as\nfollows: (1) STEU: 2 out of 19 scenarios, (2) STEM: 5 out of 18 scenarios, (3)\nGEMOK: 1 out of 20 scenarios, (4) GECo Regulation: 5 out of 28 scenarios,\n(5) GECo Management: 0 out of 20 scenarios. Overall, participants did not\nperceive a high level of similarity to any original test scenario in 88% of these\nnewly created scenarios, while 12% of the scenarios created by ChatGPT\nacross theﬁve tests received a similarity rating of 5 or higher.\nTable 2 shows the scenario texts for all scenario pairs with a similarity\nrating of 5.0 and higher. For the STEU, one of the original scenarios\ndescribes the appraisal structure for pride in an abstract way (“By their own\nactions, a person reaches a goal they wanted to reach”), while two ChatGPT-\ncreated scenarios present concrete situations in which a target person\nexperiences either pride or satisfaction after achieving something (creating a\npiece of art, being rewarded for volunteer work).\nFor the STEM, one ChatGPT-generated item illustrates that an indi-\nvidual feels lonely after their colleaguetransfers to another company branch,\nand three scenarios from the original STEM also depict changes in a person’s\nwork context (e.g., losing touch witha former colleague). However, none of\nthe original STEM scenarios mentions ordescribes loneliness. Additionally,\ntwo pairs of scenariosﬂagged as similar involve feelings of nervousness or\nfear in a job setting, though the speciﬁcs i t u a t i o n sd i f f e r(e.g., feeling nervous\nas an actor versus fearing to lead a team meeting). A similar pattern was\nobserved in another two pairs of scenarios that revolve around comparable\ntopics and/or emotions (two scenarios pertain to washing dishes/the\nkitchen, while two scenarios relate to the fear ofﬂying, but the speciﬁc\ndetails vary).\nFor the GEMOK, theﬂagged scenario pair involves a similar setting (a\ntarget person watching their child’s performance), but the development of\nthe situation and the target emotions are distinctly different (joy/pride vs.\nsadness/pride). Lastly, in the GECo Regulation subtest, one newly created\nscenario and two original scenarios share a similar setting (obstacles to\nmeeting a deadline), but the target emotions and described circumstances\nvary (e.g., anxiety vs. annoyance). Likewise, for the remaining four scenario\npairs, while the settings are similar (starting a new job, facing pushback/\ncriticism at work, not receiving a promotion), the target emotions and/or\nspeciﬁc circumstances differ (e.g., sadness vs. worry vs. irritation).\nOverall, as shown in Table2, the scenario pairs perceived as similar\nrelate to comparable settings or topics, yet they still exhibit distinct\nTable 1 | Distribution of highest similarity ratings for each of the\n105 ChatGPT-generated scenarios\nHighest similarity\nrating\nFrequency % Cumulative %\n1.0 – 2.0 1 1.0 1.0\n2.1 – 3.0 23 21.9 22.9\n3.1 – 4.0 36 34.3 57.1\n4.1 – 5.0 32 30.5 87.6\n5.1 – 6.0 9 8.6 96.2\n6.1 – 7.0 4 3.8 100.0\nFor each newly generated scenario, the value included in the Table represents the highest similarity\nrating observed across all comparisons with original test scenarios.\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 4\ndifferences in the speciﬁc situations described and/or in the emotions tar-\ngeted. Therefore, we can conclude that ChatGPT-4 did not simply para-\nphrase the original test items when asked to create new scenarios and\nresponse options.\nGeneral procedure of psychometric validation studies. For each of\nthe ﬁve tests, a separate online study was conducted on Proliﬁc.com,\nwhere participants completed both the original test and the ChatGPT-\ngenerated version. For example, one study involved participants com-\npleting the original GEMOK-Blends and the ChatGPT-created GEMOK-\nBlends, while another study had a different sample complete the original\nSTEU-B and the ChatGPT-generated STEU-B, and so on. Each sample\nalso provided ratings of clarity and realism for both test versions, com-\npleted a card-sorting task, and took a vocabulary/crystallized intelligence\ntest, as well as an additional test measuring the same EI dimension as the\nfocal test (in the STEM-B study: GECo Management; in the STEU-B\nstudy: GEMOK Blends; in the GEMOK Blends study: STEU-B; in the\nGECo Regulation study: STEM-B; in the GECo Management study:\nSTEM-B). The order of presentation for the original and ChatGPT-\ngenerated test versions, along with the associated clarity and realism\nratings and the card-sorting task, was randomized. These were followed\nby the vocabulary test and the other EI test, which were always presented\nin thisﬁxed order. Participants were not informed that one of the test\nversions had been generated by ChatGPT, and no references to LLMs or\nAI were made throughout the study. The studies were preregistered in\nOctober 2023 for the STEU, GECo Regulation, and GECo Management\nsamples (https://osf.io/mgqre/registrations). The studies were approved\nby the ethics committee of the Faculty of Human Sciences at theﬁrst\nauthor’s university (ID 20230803). Participants provided informed\nconsent at the beginning of the study, and all relevant ethical regulations\nwere followed.\nSamples. All participants were native English speakers from the United\nStates and UK recruited through Proliﬁc.com with a generic description\n(“You will rate emotional situations on various criteria and complete a\nrange of psychological questionnaires.”) that did not refer to LLMs, AI, or\nemotional intelligence to reduce self-selection effects for participants.\nParticipants were prevented from participating in more than one of the\nﬁve studies, and participants were different from those recruited for the\nsimilarity rating study described earlier. The Ns, number of excluded\nparticipants (outliers), and demographic characteristics for each of the\nﬁve samples are provided in Table3. Participants self-reported their age,\ngender, highest level of education and their ethnicity (available in the data\nﬁles). Past or current clinical diagnoses were not measured. Participants\nwere excluded if they completed the survey in less than 15 min, scored\n3 standard deviations or more below the mean on any of the included\ntests, or incorrectly responded to both attention-check items in the\nStuVoc (see below). Participants were paid based on study duration with\nan average compensation of £9 per hour.\nInstruments. For GEMOK Blends, GECo Regulation, and GECo Man-\nagement, see descriptions above. For STEU and STEM, the short forms\nSTEU-B (19 items)\n35 and STEM-B (18 items)36 were used to reduce test-\ntaking time. In the GEMOK Blends ChatGPT version, one item was\npresented to participants with the wrong response options and was\ntherefore excluded from analyses, resulting in 19 items instead of 20.\nAfter responding to each item of the original and ChatGPT-created\ntests, participants answered the following questions:“How plausible / rea-\nlistic is this situation (including the response options)?” (Slider from\n0= “extremely implausible/ unrealistic” to 100 =“extremely plausible/\nrealistic”)a n d“How clear is this situation (including the response options)?\n(Slider from 0 =“extremely unclear/ confusing” to 100 =“extremely clear/\nunambiguous”) .T h ev a l u e so ne a c ho ft h e s eq u e s t i o n sw e r ea v e r a g e da c r o s s\nall items of the respective test version to form overall measures of realism\nand clarity.\nAfter completing both test versions (original/ ChatGPT-generated),\nparticipants were presented with a list of all vignettes in that test (i.e., the\noriginal or the ChatGPT-created version) and read the following instruc-\ntions (“card sorting task”): “Now the emotional situations you have just\nworked on are presented to you again. The situations are stacked on the left\nside of the screen. Please categorize thesituations according to their content,\np u t t i n gs i m i l a rs i t u a t i o n st o g e t h e ri no n e“pile”.C r e a t e“piles” by dragging\neach situation into the boxes on the right. You can create up to 12 piles/\ncategories. Longer texts are abbreviated with“…” .P l e a s eh o v e ro v e rt h et e x t\nwith your mouse to read the full situation before deciding what“pile”to put\ni to n .C r e a t ea sf e wp i l e sa sp o s s i b l e ,b u ta sm a n ya ss e e mr i g h tt oy o u .”The\naverage number of piles created was used as an index of diversity of the\nscenarios/ vignettes. A smaller number of piles created by participants\nindicates that the vignettes are more similar in content, whereas a higher\nnumber of piles indicates more variety and diversity of situations covered in\nthe vignettes. Due to an error (24 piles were provided instead of 12), for the\nGECo Emotion Regulation subtest (original version), 10 participants who\nhad created more than 12 piles were excluded when calculating the number\nof categories, yieldingN = 85 for the category score.\nParticipants also completed a short version of the StuVoc1 vocabu-\nlary test\n37 which taps into crystallized intelligence. In this test, participants\nare presented with words and example sentences containing the word and\nare asked to choose which out of four options correctly describes the\nmeaning of each word in the corresponding sentence. One example item\nis: “What is the meaning of the word ROUBLE?“He had a lot of ROU-\nBLES.” (a) Russian money, (b) very valuable red stones, (c) distant\nmembers of his family, (d) moral or other difﬁculties in the mind”. Based\non the item difﬁculties and item discrimination indices of the 50 StuVoc1\nitems\n37, we created a 20-item short version by selecting items with an item-\ntotal-correlation above r = 0.29, sorting these items by item difﬁculty, and\nchoosing every other item in this list. The reliability of the 20-item version\nwas good, with Cronbach’s alphas ranging from 0.70 to 0.84 (mean alpha\nacross theﬁve studies = 0.80). In addition to the 20 items, we administered\ntwo easy items of the same format recommended by Vermeiren and\ncolleagues as attention check items\n37.\nPower analysis . A priori power analyses were conducted with\nG*Power38 to determine the necessary sample size for each of theﬁve\nstudies (one study per EI test). For mean comparisons (test scores, clarity\nand realism ratings, and card-sorting categories), we set a medium effect\nsize (d = 0.50), and for correlations (test relationships with intelligence\nand another EI test), we usedr = 0.30, corresponding to guidelines for\nmoderate effects\n39. Power was set at 0.80, with α = 0.05. The power\nanalysis indicated that the required sample size per study wasN = 34 for\nmean comparisons and N = 82 for correlation analyses. We selected\nmedium effect sizes for the individual studies because we planned to\nassess the main hypotheses regarding the similarity of the original and\nChatGPT-generated EI tests based on the aggregated results across the\nﬁve studies, where the combined sample size would be sufﬁciently large to\ndetect smaller effects.\nFor the combined sample (N = 467), we conducted power analyses for\nequivalence tests using the TOSTER R package\n40. For the analysis of mean\ndifferences in test scores, clarity and realism ratings, and the number of\ncategories in the card-sorting task, we predeﬁned a smallest effect size of\ninterest (SESOI) ofd = ± 0.20, corresponding to a small effect size\n39.W h i l e\nwe were unable to identify prior studiesestablishing a meaningful difference\nfor these measures, we considered a difference of ~0.20 SD to be a minimally\nnoticeable effect in test validation contexts. A power analysis using the\npower_t_TOST function showed that the combined sample (N = 467)\nhad 99.2% power to detect equivalence within the bounds of\nd = ±0.20 (α = 0.05).\nFor the comparison of correlations (examining whether the original\nand GPT-generated tests differed in their relationships with intelligence and\nanother ability EI test), we predeﬁned a SESOI ofr = ± 0.15. This threshold\nwas based on a meta-analysis\n41 which reported 95% conﬁdence intervals for\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 5\nTable 2 | Original and ChatGPT-created scenarios with a similarity rating of >5.0\nTest Similarity rating ChatGPT-created scenario Original scenario\nSTEU 6.5 2: Chris felt a wave of contentment as he gazed at the artwork he had\nspent weeks perfecting.\n24: By their own actions, a person reaches a goal they wanted to reach.\nSTEU 5.5 15: Olivia experienced a sense of ful ﬁllment seeing the bright smiles\nof the children she had volunteered to assist.\n24: By their own actions, a person reaches a goal they wanted to reach.\nSTEM 6.4 1: Karen ’s favorite coworker, Sam, has been transferred to another\nbranch, leaving Karen feeling quite lonely.\n5: Wai-Hin and Connie have shared an of ﬁce for years but Wai-Hin gets a new job and Connie\nloses contact with her.\nSTEM 5.7 1: Karen ’s favorite coworker, Sam, has been transferred to another\nbranch, leaving Karen feeling quite lonely.\n32: Mallory moves from a small company to a very large one, where there is little personal\ncontact, which she misses.\nSTEM 5.3 1: Karen ’s favorite coworker, Sam, has been transferred to another\nbranch, leaving Karen feeling quite lonely.\n34: Blair and Flynn usually go to a cafe after the working week and chat about what ’s going on\nin the company. After Blair ’s job is moved to a different section in the company, he stops\ncoming to the cafe. Flynn misses these Friday talks.\nSTEM 5.9 3: Laura is nervous about an upcoming presentation she has to give\nin front of the company board.\n10: Darla is nervous about presenting her work to a group of seniors who might not\nunderstand it, as they don ’t know much about her area.\nSTEM 5.3 3: Laura is nervous about an upcoming presentation she has to give\nin front of the company board.\n30: Billy is nervous about acting a scene when there are a lot of very experienced actors in\nthe crowd.\nSTEM 5.7 10: Olivia fears public speaking and is asked to lead a team meeting. 30: Billy is nervous about acting a scene when there are a lot of very experie nced actors in\nthe crowd.\nSTEM 5.7 11: Max ’s roommate consistently leaves dirty dishes around\nthe house.\n22: Evan’s housemate cooked food late at night and left a huge mess in the kitchen that Evan\ndiscovered at breakfast.\nSTEM 5.6 14: Susan is anxious about ﬂying and has a trip coming up. 6: Martina is accepted for a highly sought after contract, but has to ﬂy to the location. Martina\nhas a phobia of ﬂying.\nGEM-\nOK\n5.3 2: Ben watches his son ’s piano recital. The auditorium is ﬁlled with\nexpectant parents and well-wishers. His son begins with con ﬁdence\nbut stumbles on some notes midway. Ben ’s heart skips a beat,\nmemories of his own failures as a musician ﬂooding back. However,\nhis son regains composure, ﬁnishing with a ﬂourish, earning\napplause from the audience.\n2: Robert’s six-year old daughter is participating in a show of her ice-skating school for the\nﬁrst time. When Robert sees her appear on the ice, he smiles widely, his heartbeat quickens\nand he feels like jumping up from his seat. He feels so good he wants the show to go on\nforever. During her short solo part, Robert tells his neighbor excitedly in a loud voice that his\ndaughter is performing. He feels like showing off and telling everybody around him about his\ndaughter.\nGECo\nRegu-\nlation\n5.2 2: An unforeseen complication arises in your project. The initial\ntimeline, which was already tight, now seems impossible. Waves of\nanxiety rush over you as the looming deadline approaches.\n3\na: You are annoyed because your supervisor reminds you of tomorrow ’s deadline although\nother people are delaying the work.\nGECo\nRegu-\nlation\n5.7 2: An unforeseen complication arises in your project. The initial\ntimeline, which was already tight, now seems impossible. Waves of\nanxiety rush over you as the looming deadline approaches.\n12\na: You are worried because of unexpected technical issues with a new IT system.\nGECo\nRegu-\nlation\n6.1 9: You ’ve recently been promoted. With new responsibilities, you\nﬁnd yourself struggling to keep up. Colleagues you once considered\nfriends seem distant, making you feel isolated and sad.\n10\na: You are worried that you may not meet the expectations at your new job.\nGECo\nRegu-\nlation\n5.1 11: You present a new, innovative approach to a recurring problem\nin a meeting. However, it ’s met with immediate resistance from a\nsenior member, causing public embarrassment and anger.\n7\na: You are annoyed because your colleague points out a mistake you made during a client\nmeeting.\nGECo\nRegu-\nlation\n5.6 16: During a video call, a colleague unexpectedly challenges your\nsolution. Their unexpected opposition throws you into a state of\nirritation.\n7\na: You are annoyed because your colleague points out a mistake you made during a client\nmeeting.\nGECo\nRegu-\nlation\n6.7 23: A promotion you had been eyeing goes to a less experienced\ncolleague. This unexpected decision instills feelings of despair and\nconfusion.\n23\na: You are sad because your colleague is promoted and becomes your new supervisor.\naFor the GECo Regulation subtest, the original items are protected by copyright and cannot be printed here; the texts show summaries of each item. Compl ete similarity ratings can be found in Supplementary Tables 1 – 8.\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 6\ncorrelations between intelligence anddifferent ability EI branches, ranging\nin width fromr =0 . 0 8t or =0 . 3 5( T a b l e241). We adopted the average width\nof these conﬁdence intervals (r = 0.15) as the SESOI, as differences smaller\nthan ±0.15 would be within the range of expected variability in EI-\nintelligence correlations. A power analysis using the power_z_cor function\nshowed that the combined sample (N = 467) had 89.3% power to detect\nequivalence within these bounds (α = 0.05). Given this sufﬁcient power, and\nin the absence of prior literature guiding the choice of a SESOI for item-total\ncorrelations, we applied the same SESOI (r = ±0.15) for comparing the\naverage item-total correlations between the original and ChatGPT-\ngenerated test versions.\nResults\nAssessing LLM performance in solving EI test items\nA ss h o w ni nT a b l e4, as expected, all tested LLMs achieved a higher pro-\nportion of correct responses across allﬁve tests compared to the mean scores\nof the human validation samples published by the original test authors\n(mean accuracy across all LLMs was 81% versus 56% among the human\nsamples). Notably, all LLMs performed more than one standard deviation\nabove the human mean, with ChatGPT-o1 and DeepSeek V3 exceeding two\nstandard deviations above the human mean. The LLMs also exceeded\nhuman performance in each of theﬁve EI tests individually, with large effect\nsizes (see Table5).\nThere was substantial agreement among the six LLMs, with the\nIntraclass Correlation (ICC) across all 105 test items being.88. To further\nexamine similarities and differences between human test takers and the six\nLLMs when solving theﬁve EI tests, we calculated correlations across all 105\ntest items between the proportions of correct responses in the human\nsamples (i.e., the mean scores on eachitem) and the proportions of correct\nresponses among the six LLMs (not preregistered). The dataﬁle for this\ncalculation is called “comparison_humans_llm_osf.xlsx” and can be\naccessed in the supplementary data folder in“data and analysis scripts” on\nOSF: https://osf.io/mgqre/ﬁles/osfstorage. Across the 105 items, the corre-\nlation between human and LLM scores wasr = 0.46, indicating that items\nwith higher proportions of correct responses among humans (i.e., easier\nitems) were also more frequently solved correctly by the LLMs. Detailed\nitem-level comparisons are described in the Supplementary Notes 5 (p. 59 of\nthe supplementary material).\nAssessing ChatGPT’s performance in creating EI test items\nTo evaluate whether LLMs generate test items with psychometric properties\ncomparable to existing ability EI tests, we proceeded in four steps: First, we\nperformed t tests on the pooled data across theﬁve separate studies\n(N = 467) for test difﬁculty (proportion of correctly solved items by the\nhuman sample), clarity and realismratings, and item content diversity\n(measured as the average number of categories in which participants sorted\nthe item scenarios from each test version), conducted using SPSS version 27,\nas well as multilevel meta-analyses for internal consistency and construct\nvalidity (correlations with the vocabulary test and the other ability EI test\nincluded in each study) conducted in R version 4.4.1. Because the assessed\noutcome variables captured largely independent constructs (e.g., test difﬁ-\nculty was unrelated to clarity ratings), and because the hypotheses for all\nvariables were preregistered, no correction for multiple comparisons was\napplied. Second, when results were not statistically signiﬁcant, we performed\nequivalence tests using the Two One-Sided Tests (TOST) procedure\nimplemented in the TOSTER package in R\n40 to examine whether original\nand ChatGPT-created tests were statistically equivalent regarding a given\npsychometric characteristic (e.g.,in their mean scores). Third, when\nequivalence tests were not signiﬁcant (meaning that statistical equivalence\nbetween original and ChatGPT-created versions could not be established),\nwe still considered original and ChatGPT-created test versions to be similar\nregarding a given psychometric characteristic when the 95% CI of the effect\nobtained in thet tests or meta-analyses was within the range of small effects,\ndeﬁned as Cohen’s d not or only marginally exceeding ±0.20, or Pearson’s r\nnot exceeding ±0.15.\nTable 3 | Sample descriptions of theﬁve validation studies\nSelf-reported gender Self-reported ethnicity\nSample Removed\noutliers\nFinal N (after\nremoving outliers)\nAge\nM (SD)\nN women N men N othera N White or\nCaucasian\nN Black or\nAfrican\nAmerican\nN Asian or\nPaciﬁc\nIslander\nN Hispanic or\nLatino\nN Multiple\nethnicity\nor other\nN Prefer not\nto say\nSTEM-B 1 90 39.4 (10.0) 68 21 1 76 3 5 0 5 1\nSTEU-B 3 94 37.1 (10.5) 46 48 0 77 7 3 0 6 1\nGEMOK Blends 2 91 35.5 (10.5) 44 46 1 71 6 8 1 3 2\nGECo\nRegulation\n0 95 36.9 (11.8) 47 48 0 78 7 6 0 3 1\nGECo\nManagement\n1 97 38.5 (11.3) 50 47 0 79 9 5 1 2 1\naParticipants reported a different gender identity or chose the option “prefer not to say ”.\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 7\nIn the fourth step, we compared the original and ChatGPT-4-created\nversions of each individual test on the same outcome variables: test difﬁculty,\nclarity and realism, item content diversity, Cronbach’s alpha, correlations\nwith the vocabulary test (StuVoc), and correlations with the other ability EI\ntest in the study to assess construct validity. For these test-level analyses,p-\nvalues for each outcome variable were corrected for multiple comparisons\nusing the False Discovery Rate (FDR) correction42. All statistical tests were\ntwo-sided.\nHistograms for difference scores in the proportion of correct responses,\nclarity, realism, and number of categories between the original and\nChatGPT-created versions suggest that all difference scores were approxi-\nmately normally distributed and had very few extreme outliers; however,\ndata distribution was not formallytested. Participant gender was not\nincluded in the analyses as it was not expected to affect differences between\noriginal and ChatGPT-created test versions. Item-level analyses, including\nmean scores, item-total correlations,clarity, and realism ratings for all\noriginal and ChatGPT-generated items, are provided in the Supplementary\nMaterial (Supplementary Notes 4, pp. 48–58).\nFor test difﬁculty (see Table6), thet test on the pooled dataset was not\nsigniﬁcant, t(466) =–1.223,p = 0.222. We then performed an equivalence\ntest with the t_TOST function in TOSTER\n40 with a predeﬁned smallest effect\nsize of interest (SESOI) ofd = ± 0.20, corresponding to a small effect size39.\nWe considered a difference of ~0.20 SD to be a minimally noticeable effect in\ntest validation contexts. Results indicated that the difference between the\noriginal and GPT-generated test scoreswas statistically equivalent within\nthe bounds ofd ±0 . 2 0 ,t(466) = 19.61,p < 0.001. In addition, Cohen’sdi n\nthe t test was very small, with the 95% CI being within our predeﬁned\nbounds (d = –0.057 [–0.147; 0.034]). On the level of individual tests, results\nshowed that the ChatGPT-created versions were signiﬁcantly easier for the\nSTEM and GECo Regulation (indexed by higher mean scores), whereas the\noriginal test versions were easier for the GEMOK-Blends and GECo\nManagement (Table6).\nFor clarity ratings (Table6), the mean difference was not statistically\nsigniﬁcant, t(466) =–1.799, p = 0.073, and the equivalence test for a SESOI\nof d ± 0.20 was not signiﬁcant either, t(466) =–1.50,p = 0.93, indicating that\nwe could not conclude that clarity ratings were statistically equivalent\nbetween the original and ChatGPT-created versions. However, Cohen’sd\nwas very small and the 95% CI was within our predeﬁned boundaries\n(–0.083 [–0.174; 0.008]). Results for the individual EI tests indicated that\nclarity was rated signiﬁcantly higher in the ChatGPT-created versions for all\ntests except the GEMOK Blends.\nFor realism ratings (Table7), the mean difference was statistically\nsigniﬁcant, t(466) =–2.746, p = 0.006, with ChatGPT-generated tests\nobtaining a slightly higher average compared to the original test versions.\nAgain, Cohen’s d was very small (–0.127 [–0.218;–0.036]), with the lower CI\nboundary slightly exceeding the predeﬁned boundaries of a small effect. On\nthe level of individual tests, realism was rated as signiﬁcantly higher for the\nChatGPT-generated versions of the STEU-B, GECo Regulation, and GECo\nManagement subtests; and signiﬁcantly higher for the original version of the\nGEMOK Blends.\nIn the card sorting task (Table7), participants overall used signi\nﬁcantly\nmore categories when sorting the original scenarios compared to the\nChatGPT-generated scenarios, t(456) = 4.446,p < 0.001, suggesting they\nwere perceived as more diverse in content. Cohen’sdw a ss m a l l ,b u tt h eC I\nexceeded our predeﬁned boundaries (0.208 [0.115; 0.301]). On the indivi-\ndual test level, signiﬁcant differences were found for the GEMOK Blends,\nGECo Regulation, and GECo Managementitems, with the original versions\nbeing perceived as more diverse in content.\nTo compare internal consistency across all tests (Table8), aﬁxed effects\nmultilevel meta-analysis was conducted on the Fisher-z-transformed\naverage item-total correlations of each test, with test type (original vs.\nChatGPT-generated) as a moderator. Average item-total correlations were\nused instead of Cronbach’s alpha because alphas cannot be directly meta-\nanalyzed. The analysis was conducted with the metafor R package with the\nrestricted maximum likelihood (REML) method in the R package\n“metafor”\n43. QM is the test statistic for the moderator variable“original” vs\n“GPT-created” when the intercept is included, and was not signiﬁcant\n(QM = 0.635;df =1 ;p = 0.426), indicating that test type did not signiﬁcantly\nmoderate the average item-total correlation. An equivalence analysis on the\naverage item-total correlations (for original tests:r =0 . 1 8 3 ;f o rC h a t G P T -\ngenerated tests: r = 0.259) was then conducted with the compare_cor\nfunction in TOSTER; z = –0.071, p = 0.139. The non-signiﬁcant result\nindicated that the two correlations were not statistically equivalent within\nthe predeﬁned bounds ofr ±0.15 (see section on power analysis). The effect\nsize of the difference was small (d = –0.152 [–0.547; 0.223]), but the CI\nexceeded our predeﬁned boundaries. Regarding individual tests, Cronbach’s\nTable 4 | Means and standard deviations of test scores achieved by LLMs\nChatGPT-4 ChatGPT-o1 Copilot 365 Claude 3.5 Haiku Gemini 1.5 ﬂash DeepSeek V3 LLM total\nSTEM 0.75 (0.03) 0.83 (0.03) 0.79 (0.03) 0.75 (0.06) 0.76 (0.03) 0.80 (0.01) 0.78 (0.05)\nSTEU 0.72 (0.02) 0.85 (0.01) 0.78 (0.04) 0.77 (0.02) 0.77 (0.04) 0.81 (0.02) 0.78 (0.05)\nGEMOK-Blends 0.80 (0.03) 0.87 (0.05) 0.85 (0.03) 0.87 (0.02) 0.83 (0.05) 0.90 (0.00) 0.85 (0.05)\nGECo Regulation 0.87 (0.01) 0.89 (0.01) 0.92 (0.02) 0.89 (0.03) 0.78 (0.04) 0.82 (0.02) 0.86 (0.05)\nGECo Management 0.82 (0.05) 0.74 (0.03) 0.75 (0.05) 0.68 (0.07) 0.67 (0.03) 0.85 (0.00) 0.75 (0.08)\nMean scores 0.79 (0.02) 0.84 (0.01) 0.82 (0.01) 0.79 (0.03) 0.76 (0.02) 0.84 (0.01) 0.81 (0.03)\nFor each LLM, the displayed values are the means and standard deviations of 10 independently repeated testing trials. All LLM data was collected in Dec ember 2024/ January 2025.\nTable 5 | T-tests comparing LLMs and human validation study samples\nLLM total Human sample Human validation sample source t test Cohen ’sd\nSTEM 0.78 (0.05) 0.52 (0.07) Study 1 24; N = 112 t(170) = 25.483, p < 0.001 4.077 [3.544; 4.610]\nSTEU 0.78 (0.05) 0.60 (0.13) Study 1 24; N = 200 t(258) = 10.483, p < 0.001 1.543 [1.226: 1.861]\nGEMOK-Blends 0.85 (0.05) 0.67 (0.18) Study 2 25; N = 180 t(238) = 7.639, p < 0.001 1.139 [0.829; 1.448]\nGECo Regulation 0.86 (0.05) 0.56 (0.11) Study 1 26; N = 149 t(207) = 20.276, p < 0.001 3.100 [2.678; 3.522]\nGECo Management 0.75 (0.08) 0.45 (0.18) Study 1 26; N = 149 t(207) = 12.412, p < 0.001 1.898 [1.547; 2.248]\nt tests remained statistically signi ﬁcant after applying the False Discovery Rate (FDR) correction 42, with all p values remaining below 0.001.\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 8\nalpha was signiﬁcantly higher for the original STEU version than for the\nChatGPT-created version and signiﬁcantly higher for the ChatGPT-created\nGECo Regulation version than the original (Table8).\nThe original and ChatGPT-cr eated versions were signi ﬁcantly\npositively correlated, with a large effect size (mean r weighted by\nsample size = 0.46,p < 0.001; Table8), suggesting that they measure similar\nconstructs.\nTo compare original and ChatGPT-generated tests in their correlations\nwith the StuVoc (vocabulary test), aﬁxed effects multilevel meta-analysis\nwas conducted on the Fisher-z-transformed correlations of each test, with\ntest type (original vs. ChatGPT-generated) as a moderator (Table9). The\nresult was not signiﬁcant,QM =2 . 6 5 1 ;df =1 ;p = 0.104. An equivalence test\nwith the predeﬁned SESOI ofr ±0.15 (see section on power analysis) was\nthen conducted on the average StuVoc correlations with original (r = 0.244)\nand ChatGPT-generated (r = 0.137) tests,z = –0.047, p = 0.236, suggesting\nthat the correlations with StuVoc were not equivalent between original and\nChatGPT-generated tests. In addition, while Cohen’s d was small, the CI\nexceeded our predeﬁned boundaries (0.217 [–0.044; 0.492;]). Theseﬁndings\nsuggest that while the difference in correlations was small, it could not be\nruled out that the ChatGPT-generated tests had a meaningfully weaker\nassociation with StuVoc than the original tests. For each test individually,\ncorrelations with the StuVoc did not differ signiﬁcantly between the original\nand ChatGPT-created versions (Table9). However, post-hoc power ana-\nlyses with G*Power revealed that these individual analyses were under-\npowered. For instance, withN =9 7a n dα = 0.05, the power to detect a true\ncorrelation difference ofr = 0.16 between the two GECo Management test\nversions was only 35%.\nFinally, to compare original and ChatGPT-generated versions\nregarding their correlations with another ability EI test (see Table6 for the\nname of the other test administered in each study), aﬁ\nxed effects multilevel\nmeta-analysis was conducted on the Fisher-z-transformed correlations of\neach test, with test type (original vs. ChatGPT-generated) as a moderator\n(Table 9) .T h er e s u l tw a sn o ts i g n iﬁcant, QM =2 . 1 8 9 ;df =1 ;p = 0.149. An\nequivalence test with the predeﬁned SESOI ofr ±0.15 was then conducted\non the average ability EI correlations with original (r = 0.323) and ChatGPT-\ngenerated (r = 0.236) tests,z = –0.064, p = 0.164, suggesting that the corre-\nlations with another ability EI test were not equivalent between original and\nChatGPT-generated tests. Again, while Cohen’s d was small, the CI\nexceeded our predeﬁned boundaries (0.197 [–0.064; 0.471]). Theseﬁndings\nsuggest that while the difference in correlations was small, it could not be\nruled out that the ChatGPT-generated tests had a meaningfully weaker\nassociation with other ability EI tests than the original tests. For each test\nindividually, correlations with the other ability EI test did not differ sig-\nniﬁcantly between the original and ChatGPT-created versions (Table9), but\nas described in the previous paragraph, these individual analyses were\nunderpowered.\nIn summary, the comparison of the psychometric properties of the\noriginal and ChatGPT-generated tests showed mostly small effects across all\nﬁve tests, though statistical equivalence was conﬁrmed only for test difﬁ-\nculty. Differences in clarity fell within the conﬁdence interval for a small\neffect, while realism ratings were slightly higher for ChatGPT-generated\ntests, with the lower CI boundary slightly exceedingd ±0.20. Item content\ndiversity was lower for ChatGPT-generated tests, with a small but notable\neffect. The correlation between original and ChatGPT-generated tests was\nstrong. For internal consistency, correlations with vocabulary knowledge\n(StuVoc), and correlations with another ability EI test, the same pattern\nemerged: no signiﬁcant differences in moderator tests but no statistical\nequivalence within the bounds ofr ± 0.15. Effect sizes were small, but\nconﬁdence intervals exceeded the predeﬁned equivalence bounds. However,\nnone of the CI boundaries exceeded a medium effect size (d ± 0.50). Overall,\nChatGPT-created tests were largely comparable to the original versions in\npsychometric properties, with the potential exceptions of slightly lower item\ncontent diversity, slightly higher internal consistency, and slightly weaker\nassociations with vocabulary knowledge and other ability EI tests, for which\nevidence was inconclusive.\nTable 6 | Test scores and clarity ratings for the original and ChatGPT-4-created test versions\nStudy Test score means (0 – 1) Clarity ratings (0– 100)\nOriginal GPT t test Cohen ’s d [95% CI] Original GPT t test Cohen ’s d [95% CI]\nSTEM-B 0.69 (0.14) 0.93 (0.07) t(89) = – 17.093, p < 0.001 –1.802 [– 2.135; -1.464] 84.8 (14.7) 89.1 (11.1) t(89) = – 4.292; p = 0.002 –0.452 [– 0.668; – 0.234]\nSTEU-B 0.63 (0.13) 0.62 (0.10) t(93) = 1.116, p = 0.267 0.115 [0.088; 0.318] 76.4 (17.8) 84.9 (12.2) t(93) = – 7.946, p = 0.002 –1.060 [– 10.526; – 6.317]\nGEMOK-Blends 0.68 (0.14) 0.47 (0.12) t(90) = 12.523, p < 0.001 1.313 [1.030; 1.592] 86.0 (11.04) 73.6 (17.4) t(90) = 8.129, p = 0.002 0.852 [0.610; 1.091]\nGECo Regulation 0.54 (0.12) 0.65 (0.21) t(94) = – 7.424, p < 0.001 -0.762 [-0.989; -0.532] 80.6 (15.7) 82.6 (15.3) t(94) = – 2.335; p = 0.022 –0.240 [– 0.443; – 0.035]\nGECo Management 0.54 (0.15) 0.49 (0.13) t(96) = 3.886, p < 0.001 0.395 [0.187; 0.600] 77.7 (17.1) 80.3 (15.1) r(96) = – 2.467, p = 0.019 –0.250 [– 0.452; – 0.048]\nPooled dataset 0.62 (0.15) 0.63 (0.21) t(466) = –1.223,p = 0.222 -0.057 [-0.147; 0.034] 81.0 (15.9) 82.1 (15.2) t(466) = – 1.799, p = 0.073 –0.083 [– 0.174; 0.008]\nValues in boldface indicate a signi ﬁcantly higher value compared to the other test version. Displayed p values for the individual studies are FDR-corrected.\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 9\nDiscussion\nOverall, the present study demonstrated that six widely used LLMs\n(ChatGPT-4, ChatGPT-o1, Copilot365, Claude 3.5 Haiku, DeepSeek V3,\nand Gemini 1.5 Flash) outperformed the average human scores onﬁve\ndifferent ability EI tests, with largee f f e c ts i z e s .A tt h es a m et i m e ,t h e\nmoderate-to-high correlation betweenthe proportions of correct responses\namong humans and the six LLMs across the test items suggests that humans\nand LLMs may leverage the cues present in the item texts in a similar way to\narrive at the correct solutions. Additionally, in the second part of the present\nproject, ChatGPT-4 proved effective in creating situational judgment items\nto assess the central ability EI domains of emotion knowledge/ under-\nstanding and emotion regulation/ management. Acrossﬁve studies with\nhuman participants, original and ChatGPT-generated tests demonstrated\nstatistically equivalent test difﬁculty. Perceived item clarity and realism, item\ncontent diversity, internal consistency, correlations with a vocabulary test,\nand correlations with an external ability emotional intelligence test were not\nstatistically equivalent between original and ChatGPT-generated tests.\nHowever, although some differences slightly exceeded our predeﬁned\nbenchmark for similarity (d ± 0.20), all differences remained belowd ± 0.25,\nand none of the 95% conﬁdence interval boundaries exceeded a medium\neffect size (d ± 0.50). Additionally, original and ChatGPT-generated tests\nwere strongly correlated (r = 0.46). Ourﬁndings thus support the idea that\nChatGPT can generate responses that are consistent with accurate knowl-\nedge of emotional concepts, emotional situations, and their implications.\nThese results contribute to the growing body of evidence that LLMs like\nChatGPT are proﬁcient— at least on par with, or even superior to, many\nhumans— in socio-emotional tasks traditionally considered accessible only\nto humans, including Theory of Mind\n17, describing emotions ofﬁctional\ncharacters23, and expressing empathic concern18.T h e s eﬁndings have major\nimplications for the use of LLMs in social agents as well as for the assessment\nof socio-emotional skills.\nFirst, theﬁndings solidify the potential of ChatGPT-4 as a tool for\nemotionally intelligent interactions.In the context of the debate on whether\nLLMs and AI can sufﬁciently convey empathy (e.g. refs.19,20,44), the results\ns u g g e s tt h a tC h a t G P T - 4a tl e a s tf u lﬁlls the aspect of cognitive empathy,\nmeaning its responses are consistent with accurate reasoning about emo-\ntions and about how they can be regulated or managed. This capability is\ncrucial for LLMs to function as emotionally intelligent agents that can\nachieve positive socio-emotional outcomes for users in appliedﬁelds such as\nhealthcare (e.g., in socially assistiver o b o t so ra sm e n t a lh e a l t hc h a t b o t s ) ,\nhospitality, and customer service.\nIn these settings, LLMs may offer two signiﬁcant advantages. On the\none hand, they process emotional scenarios based on the extensive datasets\nthey have been trained on, whereas humans process them based on their\nindividual knowledge and experience. LLMs may thus have a lower prob-\nability of making errors. Although the datasets on which LLMs are trained\nmay partly contain false information, the strong performance in solving\nability EI tests in the present study suggests that ChatGPT -4’sb r o a d - b a s e d\nreasoning about emotions is generally reliable and aligned with current\npsychological theories. On the other hand, LLMs can provide consistent\napplication of emotional knowledge, unaffected by the variability typically\nseen in human emotional performance. Speciﬁcally, humans may not\nalways exhibit maximal performance in emotionally charged situations due\nto factors like mood, fatigue, personal preferences, or competing demands,\nand research has shown that maximal performance in emotion-related tasks\noften differs from typical performance (i.e., what people usually do\n45). For\nexample, people sometimes are sometimes deliberately inaccurate when\ninterpreting others’thoughts and feelings (“motivated inaccuracy”\n46). In\ncontrast, AI systems like ChatGPT-4 can reliably deliver maximal perfor-\nmance in emotion understanding and management in every interaction,\npotentially offering more consistent and effective emotional support.\nAlthough these ﬁndings do not address whether AI can simulate\naffective empathy (i.e., the ability to feel with someone20), it is important to\nnote that many AI applications may not require this to achieve their\nintended outcomes. For example, chatbots or leadership tools designed to\nTable 7 | Realism ratings and number of categories in the sorting task for the original and ChatGPT-created test versions\nStudy Realism ratings (0 – 100) Number of categories in sorting task\nOriginal GPT t test Cohen ’s d [95% CI] Original GPT t test Cohen ’s d [95% CI]\nSTEM-B 86.3 (15.2) 87.1 (15.9) t(89) = – 0.956, p = 0.342 –0.101 [– 0.308; 0.107] 5.20 (2.15) 5.29 (2.37) t(89) = –0.448, p = 0.655 – 0.047 [–0.254; 0.160]\nSTEU-B 82.4 (12.3) 86.5 (10.0) t(93) = – 6.133, p < 0.001 –0.633 [– 0.853; -0.410] 7.88 (2.57) 7.73 (2.64) t (93) = 0.758, p = 0.563 0.078 [ – 0.125; 0.280]\nGEMOK-Blends 81.7 (12.5) 75.7 (14.9) t(90) = 5.508, p < 0.001 0.577 [0.354; 0.798] 7.49 (2.87) 6.84 (2.59) t(90) = 2.500, p = 0.023 0.262 [0.052; 0.470]\nGECo Regulation 73.3 (16.2) 76.9 (14.7) t(94) = – 3.812, p < 0.001 –0.391 [– 0.599; – 0.181] 7.41 (2.74) 6.27 (2.77) t(84) = 3.924, p = 0.005 0.426 [0.202; 0.647]\nGECo Management 74.7 (15.3) 78.0 (14.0) t(96) = – 3.342, p = 0.001 –0.339 [– 0.543; – 0.134] 6.36 (2.64) 5.84 (2.69) t(96) = 3.170, p = 0.005 0.322 [0.117; 0.525]\nPooled dataset 79.6 (15.2) 80.8 (14.8) t(466) = – 2.746, p = 0.006 –0.127 [– 0.218; – 0.036] 6.87 (2.77) 6.44 (2.74) t(456) = 4.446, p < 0.001 0.208 [0.115; 0.301]\nValues in boldface indicate a signi ﬁcantly higher value compared to the other test version. Displayed p values for the individual studies are FDR-corrected.\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 10\nmanage employees’well-being can still support users by providing advice,\ndemonstrating empathic behaviors like active listening47, and helping users\nfeel heard and understood, regardless of whether the AI actually“feels”\nempathy19.\nA second important implication of the present research is that LLMs\nlike ChatGPT can be powerful tools for assisting the psychometric\ndevelopment of standardized questionnaires and performance-based\nassessments, especially in the domain of emotion. Traditionally, devel-\noping these tests involves collecting a large number of emotional scenarios\nthrough interviews, followed by extensive validation studies\n26. In the\npresent research, ChatGPT-4 was able to generate complete tests with\ngenerally acceptable psychometric properties using only few prompts,\neven for tests with a complex item structure such as the GECo Manage-\nment test\n26, which required response options corresponding to speciﬁc\nconﬂict management strategies, and the GEMOK-Blends test25, where\nscenarios needed to represent blends of emotions as well as various\nemotional components like action tendencies and physiological expres-\nsions. However, it should be noted that the psychometric properties (e.g.,\ntest difﬁculty and Cronbach’s alpha) varied between tests. For example,\nthe ChatGPT-generated STEM-B was easier than the original STEM-B,\ncontaining many very easy items, while the ChatGPT-generated\nGEMOK-Blends was more difﬁcult and included several items where\nonly a few test-takers chose the correct response (see Supplementary\nNotes 5, pp. 48–58, for item-level analyses). In addition, results indicated\nthat overall, the original tests performed slightly better in construct\nvalidity. This could similarly be due to some poorly performing items (e.g.,\ntoo easy or too difﬁcult items) that do not adequately discriminate\nbetween test-takers. These results suggest that while ChatGPT-4 is a\nvaluable tool for generating an initial item pool, it cannot replace the pilot\nand validation studies needed during test development, which serve to\nreﬁne or eliminate poorly performing items.\nLimitations\nDespite the promising results, severallimitations and open questions must\nbe acknowledged. First, this study was conducted using standardized tests\nwith clear and predeﬁned structures, which may not fully capture the\ncomplexities of real-worldemotional interactions. In natural conversations,\nemotional scenarios are often ambiguous, incomplete, or require inter-\npretation of subtle cues. There is evidence that LLMs’performance can be\ndisrupted by even minor changes in prompts, suggesting that their ability to\nhandle more complex, less structured emotional tasks may be limited\n48.\nFurther research is needed to assess how ChatGPT and other LLMs com-\npare to humans in understanding and managing emotional situations that\nare less straightforward, involve conﬂicting information, or require reading\nbetween the lines. Additionally, more research is needed to examine the\nextent to which LLMs can integrate context and past information from a\nconversation (e.g., about an individual’s personality, preferences, or back-\nground information leading to a speciﬁc emotional experience), as existing\nTable 8 | Cronbach’s alphas and average item-total correlations for the original and ChatGPT-created test versions, and\ncorrelations between the original and ChatGPT-created test versions\nStudy Cronbach ’s alpha (average item-total correlation) Correlations between original and GPT\nversionrOriginal GPT Comparison Cronbach ’s alpha original/ GPT\nSTEM-B 0.48 (0.160) 0.58 (0.222) χ² = 1.031; df =1; p = 0.388 0.35 ***\nSTEU-B 0.41 (0.123) 0.11 (0.047) χ² = 4.247; df =1; p = 0.098 0.42 ***\nGEMOK-Blends 0.57 (0.191) 0.43 (0.134) χ² = 1.735; df =1; p = 0.315 0.27 *\nGECo Regulation 0.76 (0.283) 0.94 (0.579) χ² = 76.224; df =1; p = 0.005 0.74 ***\nGECo Management 0.49 (0.150) 0.43 (0.127) χ² = 0.326; df =1; p = 0.568 0.42 ***\nWeighted mean item-total\ncorrelations\n0.18* 0.26** QM = 0.635; df = 1; p = 0.426; d = – 0.152\n[– 0.547; 0.223]\nWeighted mean r = 0.46***\nValues in boldface indicate a signi ﬁcantly higher value compared to the other test version. Cronbach ’s alphas between the original and ChatGPT-created test versions for each study were compared using\nthe R package cocron 57. Displayed p values for the individual studies are FDR-corrected. For comparing internal consistency between original and GPT-created tests across the ﬁve studies, average item-\ntotal correlations were computed for each test version and then analyzed with ﬁxed effects multilevel meta-analysis with the restricted maximum likelihood (REML) method in the R package “metafor”43.Q M\nis the test statistic for the moderator variable “original” vs “GPT-created” when the intercept is included. Weighted mean r for the correlations between original and GPT-created test versions was obtained\nusing mini meta-analysis 58. * p < 0.05; ** p < 0.01; *** p< 0.001.\nTable 9 | Correlations for the original and ChatGPT-created test versions with the Stuvoc vocabulary test and with the other\nability EI test included in the respective study\nStudy Correlations with StuVoc Other EI test Correlations with the other EI test\nr for original r for GPT Comparison original/ GPT r for original r for GPT Comparison original/ GPT\nSTEM-B – 0.01 –0.12 Z = 0.904, p = 0.484 GECo\nManagement\n0.26* 0.12 Z = 1.178, p = 0.600\nSTEU-B 0.37 *** 0.28** Z = 0.958; p = 0.484 GEMOK-\nBlends\n0.45*** 0.38*** Z = 0.704, p = 0.793\nGEMOK-Blends 0.18 0.07 Z =0.865; p = 0.484 STEU-B 0.20 0.14 Z = 0.476, p = 0.793\nGECo Regulation 0.25 * 0.21* Z =0.549; p = 0.583 STEM-B 0.18 0.18 Z = 0, p = 1\nGECo\nManagement\n0.39*** 0.23* Z = 1.548; p = 0.484 STEM-B 0.50 *** 0.33*** Z = 1.750,p = 0.400\nWeighted\nmean rs\n0.24** 0.14 QM = 2.651; df = 1; p = 0.104; d =0.217\n[–0.044; 0.492]\nWeighted\nmean rs\n0.32*** 0.24*** QM = 2.189; df = 1; p = 0.149; d\n=0.197 [–0.064; 0.471]\nThe correlations between original and GPT-created tests within each study were compared using Steiger ’s Z test for dependent correlations 59. Displayed p values for the individual tests are FDR-corrected.\nThe correlations between original and GPT-created tests across the ﬁve studies were compared using ﬁxed effects multilevel meta-analyses conducted with the restricted maximum likelihood (REML)\nmethod in the R package “metafor”43. QM is the test statistic for the moderator variable “original” vs “GPT-created” when the intercept is included .* p < 0.05; ** p < 0.01; *** p< 0.001.\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 11\nstudies often rely on responses to single prompts rather than longer, more\nnuanced conversations (e.g. refs.10,17,23).\nSecond, the present research was conducted in a Western cultural\ncontext, with tests developed in Australia and Switzerland and a training\ndataset for ChatGPT-4 and the other LLMs that is largely Western-centric.\nEmotional expressions, display rules, and regulation strategies vary sig-\nniﬁcantly across cultures (e.g. refs.49,50), meaning that responses deemed\ncorrect in a Western context may not be appropriate or effective in other\ncultural settings\n51. This cultural bias could limit the utility of current LLMs in\nsocial and conversational agents designed for non-Western populations52,53.\nFurther research is necessary to explore how well LLMs adapt to non-\nWestern cultural contexts and whether they can accurately consider dif-\nferent cultural settings when creating new test items.\nAnother important limitation is the black box nature of LLMs, where\nthe processes by which the AI arrives at correct answers or generates new\nitems remain unclear (see also the discussion around explainable AI\n54).\nThis lack of transparency makes it difﬁcult to predict how future versions\nof the model might perform. For example, changes in the model’s archi-\ntecture or training data could result in different, potentially less effective\noutcomes, such as less creative or diverse scenarios when prompted to\ncreate new test items\n55. On the other hand, Kosinski16 showed that more\nrecent LLMs outperformed older models in solving false-belief ToM tasks,\nfrom which he concluded that ToM may increase as a byproduct of newer\nLLM’s improved language skills. The same might apply to ability EI, which\nwould mean that future versions should maintain or increase their per-\nformance levels.\nConclusion\nTo conclude, while the study reveals some limitations, particularly regarding\ncultural applicability and the complexity of real-world interactions, the\nresults are encouraging. Six LLMs demonstrated substantial potential in\nperforming EI assessments, and ChatGPT-4 showed notable capability in\ncreating such assessments. These results suggest that LLMs could serve as\nvaluable tools to support socio-emotional outcomes in emotionally sensitive\ndomains, even if they do not fully replicate human affective empathy\n19.A t\nthe very least, they can assist users in gaining new perspectives on emotional\nsituations and help them make more informed, emotionally intelligent\ndecisions. This capability positions LLMs such as ChatGPT-4 as a promising\nresource for enhancing the integration of AI in human-computer interac-\ntions and supports the idea that LLMs may be strong candidates for artiﬁcial\ngeneral intelligence (AGI) systems10.\nData availability\nThe data for this research is available on OSF in Microsoft Excel and SPSS\nformat: https://osf.io/mgqre/ﬁles/osfstorage.\nCode availability\nThe code for this research is available on OSF in a textﬁle and can be copied\ninto SPSS syntax or R, respectively.https://osf.io/mgqre/ﬁles/osfstorage/\n67e4b303d7dac4b1728e5a4d56.\nReceived: 3 October 2024; Accepted: 29 April 2025;\nReferences\n1. Niedenthal, P. & Brauer, M. Social functionality of human emotion.\nAnnu. Rev. Psychol.63, 259–285 (2012).\n2. Mayer, J. D., Caruso, D. R. & Salovey, P. The ability model of emotional\nintelligence: Principles and ipdates. Emot. Rev.8, 290–300 (2016).\n3. Schlegel, K., Jong, M. de & Boros, S. Con ﬂict management 101: How\nemotional intelligence can make or break a manager. Int. J. Conﬂ.\nManag. 36, 145–165 (2025).\n4. Picard, R. W. Affective Computing. (The MIT Press, Cambridge, 1997).\n5. Schuller, D. & Schuller, B. W. The age of arti ﬁcial emotional\nintelligence. Computer 51,3 8–46 (2018).\n6. Marcos-Pablos, S. & García-Peñalvo, F. J. Emotional intelligence in\nrobotics: A scoping review. in New Trends in Disruptive Technologies,\nTech Ethics and Artiﬁcial Intelligence (eds. de Paz Santana, J. F., de la\nIglesia, D. H. & López Rivero, A. J.) 66 –75 (Springer, Cham, 2022).\n7. Abdollahi, H., Mahoor, M. H., Zandie, R., Siewierski, J. & Qualls, S. H.\nArtiﬁcial emotional intelligence in socially assistive robots for older\nadults: A pilot study. IEEE Trans. Affect. Comput.14, 2020–2032\n(2023).\n8. Mejbri, N., Essalmi, F., Jemni, M. & Alyoubi, B. A. Trends in the use of\naffective computing in e-learning environments. Educ. Inf. Technol.\n27, 3867–3889 (2022).\n9. Quaquebeke, N. V. & Gerpott, F. H. The now, new, and next of digital\nleadership: how arti ﬁcial intelligence (AI) will take over and change\nleadership as we know it. J. Leadersh. Organ. Stud.30, 265–275\n(2023).\n10. Bubeck, S. et al. Sparks of Artiﬁcial General Intelligence: Early\nexperiments with GPT-4. Preprint at https://doi.org/10.48550/arXiv.\n2303.12712 (2023).\n11. Nature Human Behavior Living in a brave new AI era. Nat. Hum. Behav.\n7, 1799 (2023).\n12. Hagendorff, T. Deception abilities emerged in large language models.\nProc. Natl. Acad. Sci.121, e2317967121 (2024).\n13. Nakadai, R., Nakawake, Y. & Shibasaki, S. AI language tools risk\nscientiﬁc diversity and innovation. Nat. Hum. Behav.7, 1804–1805\n(2023).\n14. Suzuki, S. We need a culturally aware approach to AI. Nat. Hum.\nBehav. 7, 1816–1817 (2023).\n15. Cao, X. & Kosinski, M. Large language models know how the\npersonality of public ﬁgures is perceived by the general public. Sci.\nRep. 14, 6735 (2024).\n16. Kosinski, M. Evaluating large language models in theory of mind\ntasks. Proc. Natl. Acad. Sci.121, e2405460121 (2024).\n17. Strachan, J. W. A. et al. Testing theory of mind in large language\nmodels and humans. Nat. Hum. Behav.8, 1285–1295 (2024).\n18. Ayers, J. W. et al. Comparing physician and arti ﬁcial intelligence\nchatbot responses to patient questions posted to a public social\nmedia forum. JAMA Intern. Med.183, 589–596 (2023).\n19. Inzlicht, M., Cameron, C. D., D ’Cruz, J. & Bloom, P. In praise of\nempathic AI. Trends Cogn. Sci.28,8 9–91 (2024).\n20. Perry, A. AI will never convey the essence of human empathy. Nat.\nHum. Behav.7, 1808–1809 (2023).\n21. Mortillaro, M. & Schlegel, K. Embracing the emotion in emotional\nintelligence measurement: Insights from emotion theory and\nresearch. J. Intell.11, 210 (2023).\n22. Lane, R. D., Quinlan, D. M., Schwartz, G. E., Walker, P. A. & Zeitlin, S. B.\nThe Levels of Emotional Awareness Scale: A cognitive-developmental\nmeasure of emotion. J. Pers. Assess.55,1 2 4–134 (1990).\n23. Elyoseph, Z., Hadar-Shoval, D., Asraf, K. & Lvovsky, M. ChatGPT\noutperforms humans in emotional awareness evaluations. Front.\nPsychol. 14, 1199058 (2023).\n24. MacCann, C. & Roberts, R. D. New paradigms for assessing\nemotional intelligence: Theory and data. Emotion 8, 540–551 (2008).\n25. Schlegel, K. & Scherer, K. R. The nomological network of emotion\nknowledge and emotion understanding in adults: evidence from\ntwo new performance-based tests. Cogn. Emot.32, 1514–1530\n(2018).\n26. Schlegel, K. & Mortillaro, M. The geneva emotional competence test\n(GECo): An ability measure of workplace emotional intelligence. J.\nAppl. Psychol.104, 559–580 (2019).\n27. Gandhi, K., Fränken, J.-P., Gerstenberg, T. & Goodman, N. D.\nUnderstanding Social Reasoning in Language Models with Language\nModels.P r e p r i n ta thttps://doi.org/10.48550/arXiv.2306.15448(2023).\n28. Jiang, H. et al. PersonaLLM: Investigating the ability of large language\nmodels to express personality traits. Preprint at https://doi.org/10.\n48550/arXiv.2305.02547 (2024).\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 12\n29. Mili čka, J. et al. Large language models are able to downplay their\ncognitive abilities to ﬁt the persona they simulate. PLOS ONE19,\ne0298522 (2024).\n30. Roseman, I. J. A model of appraisal in the emotion system: Integrating\ntheory, research, and applications. in Appraisal Processes in Emotion:\nTheory, Methods, Research(eds. Scherer, K. R., Schorr, A. &\nJohnstone, T.) 68 –91 (Oxford University Press, New York, 2001).\n31. Scherer, K. R. Component models of emotion can inform the quest for\nemotional competence. in The Science of Emotional Intelligence:\nKnowns and Unknowns(eds. Matthews, G., Zeidner, M. & Roberts, R.\nD.) 101–126 (Oxford University Press, New York, 2007).\n32. Fontaine, J. J. R., Scherer, K. R. & Soriano, C. (eds.) Components of\nEmotional Meaning: A Sourcebook. (Oxford University Press, New\nYork, 2013).\n33. Garnefski, N., Kraaij, V. & Spinhoven, P. Negative life events, cognitive\nemotion regulation and emotional problems. Personal. Individ. Differ.\n30, 1311–1327 (2001).\n34. Thomas, K. W. Con ﬂict and con ﬂict management: Re ﬂections and\nupdate. J. Organ. Behav.13, 265–274 (1992).\n35. Allen, V. D., Weissman, A., Hellwig, S., MacCann, C. & Roberts, R. D.\nDevelopment of the situational test of emotional understanding – brief\n(STEU-B) using item response theory. Personal. Individ. Differ.65,3 – 7\n(2014).\n36. Allen, V. et al. The Situational Test of Emotional Management – Brief\n(STEM-B): Development and validation using item response theory\nand latent class analysis. Personal. Individ. Differ.81, 195–200 (2015).\n37. Vermeiren, H., Vandendaele, A. & Brysbaert, M. Validated tests for\nlanguage research with university students whose native language is\nEnglish: Tests of vocabulary, general knowledge, author recognition, and\nreading comprehension.Behav. Res. Methods55, 1036–1068 (2023).\n38. Faul, F., Erdfelder, E., Lang, A.-G. & Buchner, A. G. Power 3: A ﬂexible\nstatistical power analysis program for the social, behavioral, and\nbiomedical sciences. Behav. Res. Methods39, 175–191 (2007).\n39. Cohen, J. Statistical Power Analysis for the Behavioral Sciences. (2nd\nedn), Routledge, New York, 1988).\n40. Caldwell, A. R. Exploring equivalence testing with the updated TOSTER R\npackage.P r e p r i n ta thttps://doi.org/10.31234/osf.io/ty8de(2022).\n41. Olderbak, S., Semmler, M. & Doebler, P. Four-branch model of ability\nemotional intelligence with ﬂ\nuid and crystallized intelligence: a meta-\nanalysis of relations. Emot. Rev.11, 166–183 (2019).\n42. Benjamini, Y. & Hochberg, Y. Controlling the false discovery rate: a\npractical and powerful approach to multiple testing. J. R. Stat. Soc.\nSer. B Methodol.57, 289–300 (1995).\n43. Viechtbauer, W. Conducting Meta-Analyses in R with the metafor\nPackage. J. Stat. Softw.36,1 –48 (2010).\n44. Montemayor, C., Halpern, J. & Fairweather, A. In principle obstacles\nfor empathic AI: why we can ’t replace human empathy in healthcare.\nAI Soc.37, 1353–1359 (2022).\n45. Joseph, D. L. & Newman, D. A. Emotional intelligence: An integrative\nmeta-analysis and cascading model.J. Appl. Psychol.95,5 4–78 (2010).\n46. Simpson, J. A. et al. Attachment and the management of empathic\naccuracy in relationship-threatening situations. Pers. Soc. Psychol.\nBull. 37, 242– 254 (2011).\n47. Drollinger, T., Comer, L. B. & Warrington, P. T. Development and\nvalidation of the active empathetic listening scale. Psychol. Mark.23,\n161–180 (2006).\n48. Ullman, T. Large language models fail on trivial alterations to Theory-of-\nMind tasks. Preprint athttps://doi.org/10.48550/arXiv.2302.08399(2023).\n49. Mesquita, B. & Schouten, A. Culture and emotion regulation. in\nHandbook of Emotion Regulation(eds. Gross, J. J. & Ford, B. Q.)\n218–224 (3rd edn, The Guilford Press, New York, 2024).\n50. Scherer, K. R., Clark-Polner, E. & Mortillaro, M. In the eye of the\nbeholder? Universality and cultural speci ﬁcity in the expression and\nperception of emotion. Int. J. Psychol.46, 401–435 (2011).\n51. Shao, B., Doucet, L. & Caruso, D. R. Universality versus cultural\nspeciﬁcity of three emotion domains: some evidence based on the\ncascading model of emotional intelligence. J. Cross-Cult. Psychol.46,\n229–251 (2015).\n52. Choudhury, M. Generative AI has a language problem. Nat. Hum.\nBehav. 7, 1802–1803 (2023).\n53. Yuan, H. et al. The high dimensional psychological proﬁle and cultural\nbias of ChatGPT. Preprint at https://doi.org/10.48550/arXiv.2405.\n03387 (2024).\n54. Angelov, P. P., Soares, E. A., Jiang, R., Arnold, N. I. & Atkinson, P. M.\nExplainable artiﬁcial intelligence: an analytical review. WIREs Data\nMin. Knowl. Discov.11, e1424 (2021).\n55. Yiu, E., Kosoy, E. & Gopnik, A. Transmission versus truth, imitation\nversus innovation: what children can do that large language and\nlanguage-and-vision models cannot (yet). Perspect. Psychol. Sci.19,\n874–883 (2023).\n56. Sommer, N., Schlegel, K. & Mortillaro, M. The use of generative\nartiﬁcial intelligence in the creation of emotional intelligence tests.\nhttps://osf.io/mgqre/ (2023).\n57. Diedenhofen, B. & Musch, J. cocron: A web interface and R package\nfor the statistical comparison of Cronbach ’s alpha coef ﬁcients. Int. J.\nInternet Sci.11,5 1–60 (2016).\n58. Goh, J. X., Hall, J. A. & Rosenthal, R. Mini meta-analysis of your own\nstudies: Some arguments on why and a primer on how. Soc. Personal.\nPsychol. Compass10, 535–549 (2016).\n59. Lee, I. A. & Preacher, K. J. Calculation for the test of the difference\nbetween two dependent correlations with one variable in common.\nComputer Software at https://quantpsy.org/corrtest/corrtest2.htm\n(2013).\nAcknowledgements\nWe received no speciﬁc funding for this work. We would like to thank Joëlle\nReinhart, Laura Zimmermann, and Rahel Zubler for their help with data\ncollection.\nAuthor contributions\nK.S. participated in the conceptualization, funding acquisition, and\ninvestigation, conducted the formal analysis, wrote the original draft and\nparticipated in the review and editing of the manuscript. N.S. participated in\nthe conceptualization, investigation, and review and editing of the\nmanuscript. M.M. participated in the conceptualization, funding acquisition,\nand review and editing of the manuscript.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s44271-025-00258-x.\nCorrespondenceand requests for materials should be addressed to\nKatja Schlegel.\nPeer review informationCommunications Psychologythanks the\nanonymous reviewers for their contribution to the peer review of this\nwork. Primary Handling Editors: Troby Ka-Yan Lui. [A peer review ﬁle is\navailable].\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional af ﬁliations.\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 13\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long\nas you give appropriate credit to the original author(s) and the source,\nprovide a link to the Creative Commons licence, and indicate if changes\nwere made. The images or other third party material in this article are\nincluded in the article ’s Creative Commons licence, unless indicated\notherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons licence and your intended use is not permitted\nby statutory regulation or exceeds the permitted use, you will need to\nobtain permission directly from the copyright holder. To view a copy of this\nlicence, visit http://creativecommons.org/licenses/by/4.0/\n.\n© The Author(s) 2025\nhttps://doi.org/10.1038/s44271-025-00258-x Article\nCommunications Psychology|            (2025) 3:80 14",
  "topic": "Test (biology)",
  "concepts": [
    {
      "name": "Test (biology)",
      "score": 0.6808754801750183
    },
    {
      "name": "Emotional intelligence",
      "score": 0.6578128337860107
    },
    {
      "name": "Psychology",
      "score": 0.6510139107704163
    },
    {
      "name": "CLARITY",
      "score": 0.5880874991416931
    },
    {
      "name": "Vocabulary",
      "score": 0.5378950834274292
    },
    {
      "name": "Consistency (knowledge bases)",
      "score": 0.5256777405738831
    },
    {
      "name": "Cognitive psychology",
      "score": 0.503724992275238
    },
    {
      "name": "The Emotional Intelligence Appraisal",
      "score": 0.4961002767086029
    },
    {
      "name": "Human intelligence",
      "score": 0.46368804574012756
    },
    {
      "name": "Social psychology",
      "score": 0.4487898051738739
    },
    {
      "name": "Diversity (politics)",
      "score": 0.4255863428115845
    },
    {
      "name": "Developmental psychology",
      "score": 0.3673112988471985
    },
    {
      "name": "Artificial intelligence",
      "score": 0.24104753136634827
    },
    {
      "name": "Computer science",
      "score": 0.22172024846076965
    },
    {
      "name": "Linguistics",
      "score": 0.10914939641952515
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Anthropology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I118564535",
      "name": "University of Bern",
      "country": "CH"
    },
    {
      "id": "https://openalex.org/I202391551",
      "name": "Czech Academy of Sciences",
      "country": "CZ"
    },
    {
      "id": "https://openalex.org/I4210144394",
      "name": "Czech Academy of Sciences, Institute of Psychology",
      "country": "CZ"
    },
    {
      "id": "https://openalex.org/I114457229",
      "name": "University of Geneva",
      "country": "CH"
    }
  ]
}