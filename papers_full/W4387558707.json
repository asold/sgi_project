{
    "title": "Automatic Scoring of Metaphor Creativity with Large Language Models",
    "url": "https://openalex.org/W4387558707",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5093022271",
            "name": "Paul V DiStefano",
            "affiliations": [
                "Pennsylvania State University"
            ]
        },
        {
            "id": "https://openalex.org/A2101423419",
            "name": "John D. Patterson",
            "affiliations": [
                "Pennsylvania State University"
            ]
        },
        {
            "id": "https://openalex.org/A3134031488",
            "name": "Roger Beaty",
            "affiliations": [
                "Pennsylvania State University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2949676527",
        "https://openalex.org/W4310419543",
        "https://openalex.org/W3081924543",
        "https://openalex.org/W4207050572",
        "https://openalex.org/W1994999882",
        "https://openalex.org/W2566879711",
        "https://openalex.org/W2091303727",
        "https://openalex.org/W4250629564",
        "https://openalex.org/W4290636900",
        "https://openalex.org/W2068413372",
        "https://openalex.org/W4297995647",
        "https://openalex.org/W3198711991",
        "https://openalex.org/W1995173712",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2080775075",
        "https://openalex.org/W3044750169",
        "https://openalex.org/W3088387423",
        "https://openalex.org/W4312019564",
        "https://openalex.org/W4288034106",
        "https://openalex.org/W4297999143",
        "https://openalex.org/W1976029578",
        "https://openalex.org/W564141097",
        "https://openalex.org/W2005622578",
        "https://openalex.org/W2299409018",
        "https://openalex.org/W7082518269",
        "https://openalex.org/W2535827620",
        "https://openalex.org/W2608811215",
        "https://openalex.org/W2790490252",
        "https://openalex.org/W4385963769",
        "https://openalex.org/W2948947170",
        "https://openalex.org/W4306646496",
        "https://openalex.org/W2799297286",
        "https://openalex.org/W2063315366",
        "https://openalex.org/W2334518495",
        "https://openalex.org/W2075428449",
        "https://openalex.org/W2902077037",
        "https://openalex.org/W6663462806",
        "https://openalex.org/W2158997610",
        "https://openalex.org/W4225090118",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4381487157",
        "https://openalex.org/W2805739464",
        "https://openalex.org/W4386745708",
        "https://openalex.org/W2250539671",
        "https://openalex.org/W3210923133",
        "https://openalex.org/W2048824073",
        "https://openalex.org/W2044794412",
        "https://openalex.org/W4327544905",
        "https://openalex.org/W4283321795",
        "https://openalex.org/W2006734539",
        "https://openalex.org/W1978528319",
        "https://openalex.org/W4383552473",
        "https://openalex.org/W4366523822",
        "https://openalex.org/W4232533539",
        "https://openalex.org/W2100291730"
    ],
    "abstract": "Metaphor is crucial in human cognition and creativity, facilitating abstract thinking, analogical reasoning, and idea generation. Typically, human raters manually score the originality of responses to creative thinking tasks—a laborious and error-prone process. Previous research sought to remedy these risks by scoring creativity tasks automatically using semantic distance and large language models (LLMs). Here, we extend research on automatic creativity scoring to metaphor generation—the ability to creatively describe episodes and concepts using nonliteral language. Metaphor is arguably more abstract and naturalistic than prior targets of automated creativity assessment. We collected 4,589 responses from 1,546 participants to various metaphor prompts and corresponding human creativity ratings. We fine-tuned two open-source LLMs (RoBERTa and GPT-2)—effectively “teaching” them to score metaphors like humans—before testing their ability to accurately assess the creativity of new metaphors. Results showed both models reliably predicted new human creativity ratings (RoBERTa r = .72, GPT-2 r = .70), significantly more strongly than semantic distance (r = .42). Importantly, the fine-tuned models generalized accurately to metaphor prompts they had not been trained on (RoBERTa r = .68, GPT-2 r = .63). We provide open access to the fine-tuned models, allowing researchers to assess metaphor creativity in a reproducible and timely manner.",
    "full_text": "1AUTOMATICMETAPHORSCORING\nAutomaticScoringofMetaphorCreativitywithLargeLanguageModels\nPaulV.DiStefano,JohnD.Patterson,&RogerE.Beaty\nDepartmentofPsychology,PennsylvaniaStateUniversity\nAuthorNote\nR.E.B.issupportedbygrantsfromtheNationalScienceFoundation[DRL-1920653;\nDUE-2155070].\nCorrespondenceshouldbeaddressedtoRogerE.Beaty,140MooreBuilding,UniversityPark,PA\n16802.Email:rebeaty@psu.edu.\n2AUTOMATICMETAPHORSCORING\nAbstract\nMetaphoriscrucialinhumancognitionandcreativity,facilitatingabstractthinking,analogicalreasoning,\nandideageneration.Typically,humanratersmanuallyscoretheoriginalityofresponsestocreative\nthinkingtasks—alaboriousanderror-proneprocess.Previousresearchsoughttoremedytheserisksby\nscoringcreativitytasksautomaticallyusingsemanticdistanceandlargelanguagemodels(LLMs).Here,\nweextendresearchonautomaticcreativityscoringtometaphorgeneration—theabilitytocreatively\ndescribeepisodesandconceptsusingnonliterallanguage.Metaphorisarguablymoreabstractand\nnaturalisticthanpriortargetsofautomatedcreativityassessment.Wecollected4,589responsesfrom\n1,546participantstovariousmetaphorpromptsandcorrespondinghumancreativityratings.We\nfine-tunedtwoopen-sourceLLMs(RoBERTaandGPT-2)—effectively“teaching”themtoscoremetaphors\nlikehumans—beforetestingtheirabilitytoaccuratelyassessthecreativityofnewmetaphors.Results\nshowedbothmodelsreliablypredictednewhumancreativityratings(RoBERTar=.72,GPT-2r=.70),\nsignificantlymorestronglythansemanticdistance(r=.42).Importantly,thefine-tunedmodels\ngeneralizedaccuratelytometaphorpromptstheyhadnotbeentrainedon(RoBERTar=.68,GPT-2r=\n.63).Weprovideopenaccesstothefine-tunedmodels,allowingresearcherstoassessmetaphor\ncreativityinareproducibleandtimelymanner.\nKeywords:automatedscoring;creativity;creativethinking;largelanguagemodels;metaphorgeneration\n3AUTOMATICMETAPHORSCORING\nAutomaticScoringofMetaphorCreativitywithLargeLanguageModels\nEvaluatingtheoriginalityofideasposesamajorchallengeforcreativityassessment.\nTraditionally,researchershavereliedontime-consumingandsubjectivehumanratingstosystematically\nscorelargevolumesofopen-endedresponsestocreativitytasks.Toaddressthislaborbottleneckand\npotentialratingbiases,computationalmethodslikesemanticdistancehavebeenproposedtoautomate\ncreativityscoring(Beatyetal.,2022;Buczaketal.,2023;Dumas&Dunbar,2014;Forthmannetal.,2022;\nGreen,2016;Hass,2017;Heinen&Johnson,2018;Kenett,2019;Landaueretal.,1998;Pattersonetal.,\n2023).Todate,however,thesetoolshavemostlyfocusedonstandarddivergentthinkingtasks,likethe\nAlternateUsesTask(Guilford,1967).Littleworkhasexploredtheautomaticassessmentofmoreabstract\ncreativitytasks,likemetaphorproduction,inwhichpeopledescribeexperiencesandconceptsusing\nnonliterallanguage.Metaphorsareubiquitousinbotheverydayspeechandliteraryworks(Billow,1977;\nGibbs,1990),allowingpeopletoconveycomplexideasbyrelatingoneconcept(e.g.,thebrain)to\nanother(e.g.,acomputer).\nRecentadvancesinlargelanguagemodels(LLMs;aclassofartificialneuralnetwork),suchasthe\nGenerativePre-trainedTransformer(GPT),offernewopportunitiestosignificantlyimproveautomatic\ncreativityscoring,bytrainingLLMstoratemetaphorslikehumans(Organisciaketal.,2023).Here,we\nleverageLLMstoautomaticallyscoretheoriginalityofnovelmetaphors,usingadatasetof\nhuman-generatedmetaphorresponsesandratings(N=4,589).AlthoughLLMshavesuccessfullyscored\ndivergentthinkingresponses(Organisciaketal.,2023),itisunclearwhethertheywouldbesimilarly\nsuccessfulinscoringmetaphors,whichrequiresadeeperunderstandingofnonliterallanguage.\nAutomaticCreativityAssessment\nAutomaticscoringmethodsareincreasinglyemployedtoovercomethechallengesofsubjective\nhumanscoring.Incontrasttosubjectivescoring,these“objective”methodsusemachinelearningand\n4AUTOMATICMETAPHORSCORING\ntextanalysistoolstocomputeoriginalitymetrics.Thefirstautomatedscoringmethodfordivergent\nthinkingtasksinvolvedtext-miningvariablessuchaswordcountandaveragewordlength(Paulusetal.,\n1970).Decadeslater,thisapproachstillholdsupaseffective(Forthmann&Doebler,2022).\nInrecentyears,themostpopularapproachhasbeensemanticdistance—anaturallanguage\nprocessingtechniquethatcapturestheremotenessornoveltyofanideabymathematicallycomparing\nwordvectorsthatarelearnedfromtextcorpora,mostoftenvectorsbasedondistributionalsemantics\n(e.g.,LatentSemanticAnalysis,LSA,Landaueretal.,1998;andGlobalVectorsforWordRepresentation,\nGloVe,Penningtonetal.,2014).Forexample,thewordscoffee-drinkarelesssemanticallydistantthan\nthewordscoffee-write.Whenappliedtodivergentthinkingtasks,suchastheAUT,semanticdistanceis\noftencomputedbetweentheprompt/object(e.g.,brick)andallwordsintheresponse(e.g.,grinditup\nandmakeafilteringsubstance;Yuetal.,2023).Thereliabilityandvalidityofsemanticdistancehave\nbeendemonstrated,withseveralstudiesreportinghighpositivecorrelationswithhumanoriginality\nratings(Hass,2017;Heinen&Johnson,2018;Kenett,2019;Landaueretal.,1998)andothermeasures,\nsuchascreativebehavior(Beatyetal.,2022;Beaty&Johnson,2021;Dumasetal.,2020;Fanetal.,2023;\nYuetal.,2023).Anyonecannowcomputesemanticdistanceonwordassociationanddivergentthinking\ntasksusingopenlyavailablescoringplatforms,SemDis(semids.wlu.psu.edu)andOpenScoring\n(openscoring.du.edu).\nAnotherrecentautomaticscoringmethodisdivergentsemanticintegration(DSI;Johnsonetal.,\n2022).DSIwasdevelopedtoanalyzesemanticdistanceinnarratives,suchasshortstories.Itassessesthe\nextenttowhichdivergentideasareconnectedbycomputingthedistancebetweenallpairsofwordsina\ntext.JohnsonandcolleaguesappliedDSItoshortstories,findingthatDSIcorrelatedstronglywithhuman\ncreativityratings—explainingupto72%ofthevariance.\n5AUTOMATICMETAPHORSCORING\nAkeyinnovationoftheDSImetriccomparedtoprevioussemanticdistancemethodswasthe\nintroductionoftransformerneuralnetworkstogeneratethewordvectorrepresentationsusedin\nsemanticdistancecomputations.Transformers—commonlyreferredtoaslargelanguagemodels\n(LLMs)—includeneuralnetworkarchitecturessuchastheBidirectionalEncoderRepresentationsfrom\nTransformers(BERT;Devlinetal.,2019)model.LLMsarepre-trainedbypredictingmissingwordswithin\ninputsequencesusingextensivetrainingdatasets.Variousmodelsemploydifferentpre-trainingregimes\nandusedifferenttextcorporafortraining.Consequently,thesedifferencesintrainingchangethe\nmodel’scapabilities.Additionally,modelsalsovaryintermsoftheirnumberofparameters,wherethe\ngreaternumberofparametersthemodelhascorrespondswithahighermodelcapacity.\nImportantly,BERTandotherLLMs(e.g.,theGenerativePretrainedTransformer,GPT;Radfordet\nal.,2019)producecontext-dependentlanguagerepresentations.Thatis,theyareabletoconsidereach\nwordintheinputtothemodelinrelationtotheotherwordsintheinput,ratherthaninisolation,as\nwithlegacywordrepresentationapproachessuchasLSAandGloVe.Transformermodelscanthus\naccommodatemultiplewordmeanings(e.g.,computer-servervs.restaurant-server),thankstotheir\n“self-attention”mechanism,whichallowsthemtodynamicallyadjusttheinterpretationofeachword\nbasedonthecontextprovidedbythesurroundingwordsintheinput.\nAnotheradvantageofLLMsisthattheycanbe“fine-tuned”throughsupervisedlearning(human\nguidance)tosignificantlyenhancetheirperformanceonspecifictasks.Supervisedlearningresultsin\npredictivemodelsratherthandescriptiveones(Lantz,2013).LLMfine-tuninginvolvesadjustingthe\npre-trainedmodels(e.g.,BERT,GPT)tolearnfromspecificinput-outputpairs,suchasAUTresponsesand\nhumanratings.Inthisway,thepre-trainedmodeltakesadvantageoftheknowledgeitlearnedduring\npre-trainingandadaptsittothespecifictaskordataset.Fine-tunedmodelsarethuscapableof\npredictingoutputs(creativityratings)forunseeninputs(responses).Theprocessoffine-tuningcan\n6AUTOMATICMETAPHORSCORING\ndramaticallyimprovemodelperformancecomparedtopre-trainedmodelsthatwerenotfine-tunedona\nspecifictask,oftenmatchingorexceedinghumanperformance(Bakkeretal.,2022).\nRecently,Organisciaketal.(2023)employedLLMstoautomaticallyscoretheoriginalityofAUT\nresponses,showingsubstantialimprovementinthepredictionofhumanratingscomparedtosemantic\ndistance.Theauthorsfine-tunedthemodelsT5-BaseandGPT-3onalargesetofAUTresponsesand\nhumanratings,findingthatthefine-tunedmodelsstronglypredictedhumancreativityratingsfornew\n(previouslyunseen)responses.Moreover,thefine-tunedmodelsgeneralizedtoAUTitems(objects)that\nwerenotincludedinthetrainingdataset,suggestingtheyhadlearnedsomethinggeneralabouthow\nhumansratecreativityontheAUTthatextendedbeyondthespecificitemstheyweretrainedon.This\nworkbuiltuponothersupervisedlearningmethodstoautomaticallyscoretheAUT,suchasBuczaketal.\n(2023)andStevensonetal.(2020),whousedmoreextensivetrainingapproachestoautomatecreativity\nscoringontheAUT.Todate,however,supervisedmachinelearningofverbalcreativityscoringhasbeen\nrestrictedtotheAUT,withnoworkonotherverbalcreativitytasks,suchasnovelmetaphorproduction.\nThePresentResearch\nInthepresentstudy,weaimedtoextendresearchonautomaticcreativityscoringtonovel\nmetaphorproduction.Metaphorisanaturalisticformofverbalcreativitythatisusedtodescribe\nconceptsandepisodesusingfigurativelanguage(e.g.,“timeisathief”),anditisapowerfulrhetorical\ntoolforcreativelyconveyingcomplexideas.Comparedtoconventionalmetaphors,whichinvolve\nrecallingculturallyfamiliarexpressions(e.g.,describingaboringexperienceas“watchingpaintdry”),\nnovelmetaphorsreflectentirelynewexpressionsoffigurativelanguagethatpeopleproduce\nspontaneously(e.g.,describingaboringexperienceas“watchingaturtlesprint”).Metaphoris\nincreasinglystudiedincreativityresearch,includingbehavioral(Stamenkovi ćetal.,2023)and\nneuroimaging(Beatyetal.,2017;Cardilloetal.,2012)studies,andithasbeenshowntobeaneffective\n7AUTOMATICMETAPHORSCORING\ntoolforboostinglearningineducationalsettings(Tiberius,1986).Automaticscoringofnovelmetaphors\ncouldacceleratethepaceofresearch,whichcurrentlyreliesonsubjectivehumanscoring.While\nautomaticscoringofmetaphornoveltyhasbeeninvestigatedusingsyntacticallyrelatedwordpairs\n(Parde&Nielsen,2018),automatedassessmentofmetaphorcreativity,specifically,hasyettobe\nexplored.Additionally,LLMshaveyettobeusedformetaphorcreativityevaluation.\nHowever,thereisreasontosuspectthatlanguagemodelsmaystrugglewithscoringnovel\nmetaphors,basedonhowhumansprocessmetaphors.Humansusemetaphorsbyrelatinga“topic”(i.e.,\nthemind)toa“vehicle”(i.e.,amachine)thatisconceptuallybutnotliterallyrelated.Howhumans\nunderstandnonliterallanguagelikemetaphorhasbeenstudiedforseveraldecades,largelyfocusingon\nmetaphorstructureandfunction(Gibbs,1994;Glucksbergetal.,1997;Lakoff&Johnson,2008).The\npropertyattributionmodelofmetaphorproposesthatmetaphorcomprehensioninvolvescreatingan\nabstractlinkbetweenatopicandavehiclewithsimilarcharacteristics(Glucksberg&McGlone,2001).\nAdditionally,forametaphortobecomprehensible,thesharedknowledgebetweenthetopicandvehicle\nmustbeidentified(Glucksbergetal.,1997).Humansalsotendtoselectmetaphorsthataresemantically\nsimilartothetargetconcept(Clevenger&Edwards,1988),yetpeopleprefermetaphorsofmoderate\nsemanticdistance(Katz,1989).Creativemetaphorsshouldthereforebesemanticallydistantyet\nappropriateenoughtoberelatabletothetopic.Ifso,ameasureofsemanticdistancealoneisunlikelyto\ncapturemetaphorcreativity.\nInthecontextofnaturallanguageprocessing,metaphorisarelativelyunder-studiedtopic,andit\nremainsanopenquestionastohowwelllanguagemodelscaninterpretnonliteralphrases(Liuetal.,\n2022).SomestudieshaveshownthatLLMshavealimitedcapacitytohandlefigurativelanguage,suchas\nirony,sarcasm,idioms,andmetaphors(Chakrabartyetal.,2022;E.Liuetal.,2022).Forexample,\nChakrabartyetal.(2022)foundthatpre-trainedLLMslaggedsubstantiallybehindhumansingenerating\norchoosingplausiblecontinuationsfornarrativeswithfigurativeexpressions.LLMsmaythereforelack\n8AUTOMATICMETAPHORSCORING\nthenecessaryworldknowledgeandcommonsenseto‘comprehend’nonliterallanguage,limitingtheir\nabilitytoreliablyevaluatemetaphorquality—perhapsevenafterfine-tuning.\nHere,wetestedthecapacityofLLMstoautomaticallyscoremetaphorsusingdatafromprevious\nstudiesofmetaphorproduction(N=4,589responses,N=1,546participants).Participantsinthese\nstudieswerepresentedwithopen-endedpromptsthatrelatedtocommonexperiences(e.g.,describing\nabadmoviewithametaphor).Wefine-tunedtwopopular,open-sourceLLMs—RoBERTaandGPT-2—on\ntheseresponsesandcorrespondinghumancreativityratings.Wethentestedtheirabilitytopredict\nhumanratingsfornewresponsestheyhadnotseenbefore—boththosebasedonmetaphorprompts\nthemodelwastrainedonaswellasthosebasedonpromptsthemodelwasnevertrainedon,asatestof\nfargeneralization.\nInaddition,wescoredmetaphorresponsesusingwordcountandDSI.Wordcountcapturesthe\nelaborationofaresponse,andithasbeenpreviouslyrelatedtocreativityratingsonothertasks\n(Forthmann&Doebler,2022).Ontheotherhand,DSIprovidesasemanticdistancebaselinethatismore\nsuitablethanotherapproachestosemanticdistancegivenitsabilitytohandlemulti-wordresponsesina\ncontext-dependentmanner.Althoughweexpectedthefine-tunedLLMstocorrelatewithhumanratings\nmorestronglythanDSI,basedonrelatedfine-tuningresearch(Organisciaketal.,2023),DSIprovidesa\nmoreinterpretablemetricofsemanticdistance.Usingcontext-dependentpairwisewordcomparisons,\nDSIcanquantifytherelatednessoftheconceptsunderlyingmetaphors.\nMethods\nThedatausedinthisstudywascompiledfrompriorstudiesandunpublishedresearch.Inmany\nofthedatasets,participantscompletedmetaphorgenerationtasksinadditiontoothercognitive\nassessments.Thespecificcognitivetasksandtheirorderdifferedforeachstudy;weonlyinclude\n9AUTOMATICMETAPHORSCORING\nmetaphortaskshere.Allmetaphorresponseswereassessedforcreativitybyhumanraters.Alldataand\ncodeareavailableonlineathttps://osf.io/2dqpj/?view_only=339b6f7febe646309484bb06eb2914e9.\nM e t a p h o r T a s k a n d H u m a n S c o r i n g \n Themetaphorgenerationtaskpresentedparticipantswithapromptandaskedthemtowritea\ncreativemetaphor(Beatyetal.,2017;Beaty&Silvia,2013;Kasirer&Mashal,2018;Silvia&Beaty,2012).\nParticipantsrespondedtofourdifferentpromptswhichvariedacrossthedatasetsinthisstudy:boring\nclass:‘Thinkofthemostboringhigh-schoolorcollegeclassyou’veeverhad.Whatwasitliketosit\nthrough?’;grossfoodordrink:‘Thinkaboutthemostdisgustingthingyoueverateordrank.Whatwasit\nliketoeatordrinkit?’;badmovie:‘ThinkabouttheworstmovieorTVshowyouhaveeverseen.What\nwasitliketowatchit?’;andmessyroom:‘Thinkofthemessiestroomthatyou’veeverhadtolivein.\nWhatwasitliketolivethere?’.Participantsweregivenexamplesofdifferenttypesofmetaphors(e.g.,\ncompoundmetaphor),aswellasoptionalstartingstemstohelpthem(e.g.,“Sittingthroughthatmovie\nwas … ”).\nMetaphorswereratedforcreativityusingthesubjectivescoringmethod(Silviaetal.,2008),\nwhichisbasedonanadaptedversionoftheConsensualAssessmentTechnique(CAT).Consistentwith\npastwork(Beaty&Silvia,2013;Silvia&Beaty,2012),metaphorswerejudgedbymultipleratersusinga\n5-pointLikertscale,where1representednotatallcreativeand5representedverycreative.Each\ndatasetwasratedby2to4trainedraters(seerateragreementbelow),whoratedtheirrespective\ndatasetindependently.Ingeneral,clichemetaphorstendedtoreceivelowerratings(e.g.,“Sitting\nthroughthatmoviewaslikewatchingpaintdry”)whereascleverorhumorousmetaphorsreceived\nhigherratings(e.g.,“Thatmoviewasagood-lookingguywithnopersonality”).\n10AUTOMATICMETAPHORSCORING\nD a t a s e t s \n Acrossthesevendatasets,thereare4,589responsesfrom1,546participants(1,058badmovie;\n1,387boringclass;1,385grossfood;759messyroom).ThisstudyprotocolwasapprovedbythePenn\nStateUniversityInternalReviewBoard(IRBSTUDY00010475).Table1(below)isanoverviewofthe\ndatasets,includingthesamplesize,prompts,numberofraters,andintraclasscorrelationcoefficient(ICC;\nrateragreement):\nTable1\nSummaryofMetaphorDatasets\nDataset Participants Responses Raters I C C 2 k Prompt(s)\n1 222 443 4 0.75 grossfoodordrink,boringclass\n2 164 330 4 0.80 grossfoodordrink,boringclass\n3 151 302 3 0.73 badmovie\n4 476 1,888 4 0.68 grossfoodordrink,boringclass,badmove,messyroom\n5 133 266 3 0.51 grossfoodordrink,boringclass\n6 111 214 2 0.86 grossfoodordrink,boringclass\n7 289 1,146 4 0.80 grossfoodordrink,boringclass,badmove,messyroom\n11AUTOMATICMETAPHORSCORING\nComputationalExperiments\nOurmaingoalwastotesttwomethodsforautomaticallyscoringmetaphors:semanticdistance\nandfine-tunedLLMs.Tocomputesemanticdistance,weusedDivergentSemanticIntegration(DSI;\nJohnsonetal.,2022),abaselinesemanticmodel,incontrasttothefine-tunedmodels.Regarding\nfine-tuning,wecomparedtwosupervisedLLMarchitectures,RoBERTaandGPT-2.Bothapproaches\nemploy“context-sensitive”models—whichcancapturenuancedwordmeanings(e.g.,computer-server\nvs.restaurant-server)—andthusshouldbebettersuitedtocapturemetaphorsthan\ncontext-independentmodels(e.g.,latentsemanticanalysis).\nBaseline:DivergentSemanticIntegration\nDSIcomputesword-to-wordsemanticdistancebetweenallwordsinaresponse,reflectingthe\nextenttowhicharesponseintegratesdiversetopicsandcontexts.DSIdoessobyextractingvector\nrepresentationsforeachwordinaresponsefromtwoearly-middlelayersofBERT-large(a24-layerLLM;\n(Devlinetal.,2019)—layersthatcarrybothsyntacticandsemanticlinguisticknowledge(Jawaharetal.,\n2019).Semanticdistance(1minuscosinesimilarity)isthencomputedbetweenallpairsofwordvectors;\nthesemanticdistancevaluesarethenaveragedtogivetheDSIscorefortheresponse.Formoreon\nDSI—includingatutorialandcodeforcomputingit—seeJohnsonetal.(2022)anditsassociatedOpen\nScienceFoundationrepository(https://osf.io/ath2s/).\nDSIhasbeenusedtoautomaticallyscoremulti-wordresponses(i.e.,shortstories),andhasbeen\nshowntoexplainsubstantialvarianceinhumancreativityratingsacrossmultipledatasets(Johnsonetal.,\n2022).Likeshortstories,metaphorsareoftenveryelaborateandvaryconsiderablyacrossparticipants.\nEarlierautomatedscoringmethodsthatusecontext-insensitivesemanticdistance(e.g.,latentsemantic\nanalysis)wouldbeinappropriatetoscoremetaphorsbecausemetaphorsrelyonabstractrelationships\n12AUTOMATICMETAPHORSCORING\nthatcannotbewellrepresentedusingcontext-insensitivemodels.Sinceempiricalworkhasshownthat\nthehighest-performingvariantofDSIusesacontext-sensitiveLLMtorenderthewordvectors,itstands\nasatheoreticallyvalidbaselineofautomatedmetaphorassessment. Thepresentstudythusprovides\nthefirsttestofwhethersemanticdistance(intheformofDSI)relatestohumancreativityratingsof\nmetaphors.\nFine-TuningLLMs\nWefine-tunedandevaluatedtwotransformer-basedLLMs,RoBERTa(Y.Liuetal.,2019)and\nGPT-2(Radfordetal.,2019),topredicthumancreativityratingsofmetaphors.Thesemodelswere\nchosenforfourreasons.Mostimportantly,theyarebothhighly-performantmodelsknowntodowellon\nnaturallanguageprocessingbenchmarksaswellasmatchhumanbehaviorandneuralactivity(e.g.,\nCaucheteuxetal.,2022;Johnsonetal.,2022).Second,bothmodelsareopen-accessandfreetouse.\nThisstandsincontrasttoproprietarymodelslikeGPT-4(OpenAI)thatcostmoneyforresearcherstotrain\nanduseandcannotbedownloadedofftheproprietaryserverenvironment.Consequently,when\nproprietaryLLMcompaniesmakeupgradesanddeprecateolderLLMs(e.g.,GPT-3vs.GPT-4),theold\nmodelsarelostforever—harmingreproducibility.Athirdreasonforchoosingthesetwomodelsis\nbecausetheyhavecomparableparametercountsyetalsohavedistinctmodelarchitectures(i.e.,design\nprinciples)andtrainingregimes(i.e.,thepre-trainingtasksusedtobuildupsyntacticandsemantic\nrepresentationsoflanguage)—affordinganalluringcomparison.Finally,andarguablymostimportantly,\nwechosethesemodelsgiventheircompatibilitywithcomputationalresourcesresearchersarelikelyto\nhaveaccessto;thefine-tunedmodelscanberunonstandardlaptopswith16GBofRAM.Thisallowsfor\nthefruitsofthisworktoimpactthegreatestnumberofresearchersandpractitioners.\nTheRobustlyoptimizedBERTapproach,RoBERTa-base(Y.Liuetal.,2019),isa125Mparameter\nmodelbasedontheBidirectionalEncoderRepresentationsfromTransformers(BERT;Devlinetal.,2019)\n13AUTOMATICMETAPHORSCORING\narchitecture.However,RoBERTawastrainedunderanimprovedpre-trainingregimethatwasempirically\nshowntoresultinmorerobustlanguagerepresentations(Y.Liuetal.,2019).BERTandsubsequently\nRoBERTaweretrainedwithawordcorpussourcedfromWikipediaandBooksCorpus.Akeycharacteristic\nofRoBERTaisthatitfallsunderaclassoftransformersknownas‘bidirectional’models.Duringthe\npre-trainingprocess,RoBERTaistrainedusingamaskedlanguagemodelingobjective—meaningthat\nselectwordsintheinputarehiddenfromthemodelandthemodelattemptstopredictthemasked\nwordswiththesurroundingcontextwords.BecauseRoBERTaisabidirectionalmodel,thecontextwords\nthatoccurbothbeforeandafterthemaskedwordsareusedtopredictthemaskedwords.Inother\nterms,wordsthatoccur‘after’amaskedwordcanbeusedtopredictamissingword,inadditionto\nwordsthatoccur‘before’themaskedwordinthesequence.\nThefinalmodeltobeopenlyreleasedbyOpenAI,GPT-2,isa137Mparameter,pre-trained\ntransformermodel.GPT-2wastrainedontheWebTextdataset,whichwascreatedbycrawlingReddit\nandharvestingtextfromoutboundlinks.WhilehavingacomparablenumberofparameterstoRoBERTa,\nGPT-2ispre-trainedusingadifferentlanguagemodelingobjective.Unlikethebidirectionallearning\nobjectiveofRoBERTa,wherecontextlaterinasequencecanbeusedtopredictmissingwordsearlierina\nsequence,GPT-2usesaunidirectionalnext-word-predictionpre-trainingobjective.Thismeansthatthe\nmissingwordthemodelistrainedtopredictduringthepre-trainingprocessisalwaysthefinalwordin\nthesequence,andthecontextusedtopredictthemissingwordalwaysprecedesthemissingword.\nSomehavearguedtheunidirectionalpredictiontaskadoptedbyGPT-2(andmodelslikeit)ismoreinline\nwithhumanpredictiveprocessingthatisoftentemporallyconstrainedinacomparablefashion.Indeed,\nmodelsthatperformbestatthenext-word-predictionobjectivealignmorestronglywithhumanneural\nrecordings(Schrimpfetal.,2021).\nDataPreprocessing\n14AUTOMATICMETAPHORSCORING\nThecreativityratingsprovidedbyavaryingnumberofraterswereaveragedforeachresponse.\nTheaveragehumanratingswerealsoz-scoredwithineachdataset.Theaveragedz-scoredhumanratings\nwerethenusedinthefine-tuningprocess.Tofine-tunethemodels,wedevelopedadedicateddata\npipelineforeachLLM.Consistentwithbestpracticesinmachinelearning(Zhou,2021),metaphor\nresponsesandhumanratingswererandomlydistributedintotraining,validation,andheld-outtest\ndatasets,utilizinga70/10/20splitratiorespectively.Thedatasplitwasthesameforthetwomodelsto\nimprovecomparison.Tobeclear,thetrainingsetconsistedofresponsesthemodellearnedabout\nscoringmetaphorsfrom(i.e.,theseexamplesareusedtoupdatetheweightsoftheLLMtoperform\nbetterontheratingtask).Thevalidationsetservedasapseudo-testsetandwasusedasabarometerof\nhowthemodelwasperformingunderdifferentsettings(a.k.a.,hyperparameters;detailedfurther\nbelow).Thevalidationsetwasusedformodelselection,butthemodelwasnevertrainedonthe\nvalidationset.Theheld-outtestsetconsistedofresponsesthatwereneitherusedformodelselection\nnorwereexperiencedbythemodelduringtraining.Itthusservedasastringenttestofthemodel’s\nabilitytogeneralizetountrainedresponses.Theheld-outtestsetwasonlyemployedoncethebest\nmodelsettings—asrevealedbythevalidationset—werefinalized.\nAsamoreextremetestofthemodel'sgeneralizability,wealsotestedthemodelonresponsesto\nametaphorpromptitwasneverexposedtoduringthetrainingprocess(the‘messyroom’prompt).If\nthemodelscansuccessfullygeneralizetonewmetaphorprompts,thiswouldsuggestthattheyhad\nlearnedsomethinggeneralabouthowhumansratemetaphorcreativity,beyondthespecificprompts\ntheysawduringtraining.Successfulgeneralizationwouldalsosuggestthatnewmetaphorpromptscould\nbecontinuallydevelopedandautomaticallyscored,withoutneedingadditionalfine-tuningofthemodel.\nTherawresponsesineachofthedatasets(i.e.,training,validation,held-outtest,held-out\nprompt)werefirstinsertedintoasentenceframe.Asnotedabove,transformers’performanceand\noutputscanbeaffectedbythesententialcontext.Assuch,wevariedwhatthecriticaladjectiveinthe\n15AUTOMATICMETAPHORSCORING\nsentenceframe('creative,''novel,''useful,''surprising,'or'unique')thatthemodelwassupposedto\nassessfor(e.g.,\"A[adjective]metaphorfor[prompt]is[response].\").Notably,Organisciaketal.(2023)\nemployedtheadjective‘surprising’forallfine-tunedAUTitems.Theframedresponsesineachofthe\nfourdatasetsthenunderwenttokenization;tokenizationistheprocessbywhichnaturallanguageis\ntransformedintoanumericalvocabularythatisunderstandabletoLLMs.Thesetokenizedversionsofthe\ntextwereusedtotrainandevaluatethemodels(viatheHuggingfaceTrainerapplicationprogramming\ninterface[API]forPython).\nModelTrainingandHyperparameterSearch\nTopreparetheLLMsforthetaskofmetaphorcreativityprediction,weaffixedaregressionhead\natopeachLLM(viatheHuggingfaceAutoModelForSequenceClassificationAPI,withthenumberof\noutputlabelssetto1).Thisprojectsthehigh-dimensionaloutputoftheLLMontoasingleoutput\nregressionnode.Thisisdesirable,asthecontinuous-valuedoutputoftheregressionnodeforagiven\ninputcorrespondstothemodel’screativityassessmentforthatinput,andthetargets(i.e.,ratings)were\nalsocontinuous-valued.\nToascertainwhichmodelsettings(i.e.,hyperparameters)optimizedtheperformanceofeach\nLLM,wesubjectedeachmodeltoahyperparametersearchusingtheOptunapackageforPython(Akiba\netal.,2019).Across60trials,wesearchedoverfourhyperparameters.First,wesearchedoverlearning\nratewithintherange5e-07to5e-02.Learningrateaffectstheextenttowhichtrainingepisodeschange\ntheweightsofthemodel,wherehigherlearningratescorrespondtomakingbiggerchangestothe\nmodel’sweightsforeachtrainingbatch.Ifthelearningrateistoohigh,themodelwillnotlearnandmay\nbecomeprogressivelyworseacrosstraining.Ifthelearningrateistoolow,themodelmaynotreacha\nviablesolutionduringtraining,especiallyifthetrainingperiodisbrief.Second,wesearchedoverbatch\nsize,testingvaluesof4,8,16,and32.Batchsizereflectshowmanyresponsesthemodelreceives\n16AUTOMATICMETAPHORSCORING\nfeedbackonatatime.Largerbatchsizesleadtofasterconvergence/training,butcanalsoleadto\nsuboptimalsolutions.Smallerbatchsizesintroducebeneficialstochasticityintothetrainingprocessbut\ntakemoretime.Third,wesearchedfortheoptimalnumberoftrainingepochs;thatis,thenumberoffull\ntrainingpassesthroughthetrainingdataset.Weconductedasearchwithintheepochrangeof10to\n150.Last,wesearchedovertheprefixadjectiveusedinthesentenceframe(e.g.,‘creative’,‘novel’,or\n‘surprising’;seeaboveforthefulllist).\nTheOptunapackageassiststhesearchoverthesehyperparametersettingsbyemployingthe\nTree-structuredParzenEstimatorapproach,aBayesianoptimizationmethod. Atfirst,Optunaassumesa\nuniformpriorovervaluesforeachhyperparametersetting,butasthealgorithmupdatesitspriors—by\nobservingwhichhyperparametercombinationsoptimizeperformanceonthevalidationset—itbeginsto\nexplorecombinationsthataremostlikelytoperformoptimally.ThemetricOptunasoughttooptimize\n(minimize)wasthemeansquarederror(MSE)betweenmodel-predictedandhuman-providedratingson\nthevalidationset.TheMSEservesastheerrorsignaltoupdatetheweightsofthemodelduringtraining\nbasedonthetrainingdatasetlabels.\nAftertheoptimalhyperparameterswereidentifiedforeachmodel(individually),weevaluated\nthebest-fittingmodelsontheheld-outtestset.Wethenassessedtheabilityofthemodeltogeneralize\ntoresponsesfromaheld-outprompt('messyroom').Inallanalyses,weremovedoutliersfromboththe\nhumanandmodelcreativityratings,definedasvaluesbeyond3standarddeviationsfromthemean.\nResults\nBaselines:WordCountandSemanticDistance\nWebeganbycomputingPearsoncorrelationsbetweenhumancreativityratingsofmetaphors\nandtwobaselinemeasures:wordcount(ameasureofelaboration)andDSI(ameasureofsemantic\ndistance).Thiscorrelationalanalysiswasconductedthreetimes,onceonthefulldataset(N=4,589\n17AUTOMATICMETAPHORSCORING\nresponses;n=4,509postoutlierremoval),onceontheheld-outtestset(N=766;n=753),andonceon\ntheheld-outprompt(N=759;n=750). Thefulldatasetanalysisallowsustoextendpreviousresearch\nonwordcountandDSIforcreativityassessmentbycomputingthiscorrelationonalargesetof\nmetaphors.Theanalyseswiththeheld-outtestsetandheld-outpromptallowforafaircomparison\nbetweenwordcount,DSIscores,andthefine-tunedLLMpredictions.\nRegardingwordcount,weobservedacorrelationofr=0.51;CI95%[0.48,0.53]withhuman\ncreativityratingsofthefulldataset,suggestingthattheratersscoredmoreelaboratemetaphorsasmore\ncreative,consistentwithpastworkwithotherverbalcreativitytasks(Dumasetal.,2021;Johnsonetal.,\n2022).Wefoundsimilarcorrelationsbetweenwordcountwiththehumanratingsoftheheld-outtest\nset(r=0.49;CI95%[0.43,0.54])andtheheld-outprompt(r=0.47;CI95%[0.42,0.53]).\nNext,weusedBERTDSItoassesstheextenttowhichsemanticdistancecorrelateswithhuman\ncreativityratings.Usingthefulldataset(n=4544),wefoundthatDSIscoreswerepositivelycorrelated\nwithhumanratings,r=0.31;95%CI[0.28,0.33].Moreover,calculatingtheDSIscoresusingonlythe\nheld-outtestset(n=762)yieldsacorrelationofr=0.42;95%CI[0.36,0.47]withhumanratings(see\nFigure1).WeobservedthehighestcorrelationbetweentheDSIscoresoftheheld-outpromptandthe\nhumanratings,r=0.51;CI95%[0.46,0.56].Themagnitudeofthiseffectismoderate,andnotably\nsmallerthanpreviousfindingswithshortstories(Johnsonetal.,2022).Thisfindingindicatesthatmore\nsemanticallydistantmetaphorswereratedasslightlymorecreativebyhumans.\n18AUTOMATICMETAPHORSCORING\nFigure1\nCorrelationbetweenHuman-RatedCreativityandDSIRatingsoftheHeld-outTestSet\nNote.DSIandhumanratingsareZ-scored.n=762;4outlierswereremoved.\nHyperparameterResults\nNext,weconductedfine-tuningexperimentsonthetwoLLMs:GPT-2andRoBERTa,toassess\ntheirabilitytoreplicatehumancreativityratingsofmetaphors.After60trainingtrialsofeachmodel,we\nselectedtheparametersfromthetrialwiththelowestmeansquarederroronthevalidationset(N=\n383),representingthebest-performingconfiguration.\nForGPT-2,thetop-performingtrialutilizedalearningrateof2.47e-05,ran139epochs,and\nemployedatrainingbatchsizeof16.Thebest-fittingmodelusedtheprefixadjective‘novel’(asopposed\ntootherprefixes;e.g.,creative).RegardingRoBERTa,thehighest-performingtrialusedalearningrateof\n\n19AUTOMATICMETAPHORSCORING\n4.00e-06,ranfor111epochs,andhadatrainingbatchsizeof4.UnlikeGPT-2,thebestperforming\nRoBERTamodelusedtheprefixadjective‘surprising.’\nHeld-outTestPerformance\nFigure2\nCorrelationbetweenHuman-RatedCreativityandModelPredictionsfromtheTestSet\nNote.ModelpredictionsandhumanratingsareZ-scored.RoBERTan=765,GPT-2n=764; 1outlierwas\nremovedfromtheRoBERTapredictions,and2outlierswereremovedfromtheGPT-2predictions.\nWhenevaluatedonthevalidation(n=383)andtestdata(n=764)withtheoptimized\nhyperparameters,GPT-2positivelypredictedhumancreativityratings,yieldingcorrelationsofr=0.73,\n95%CI[0.68,0.77]andr=0.70;95%CI[0.66,0.73],respectively—substantiallylargerthanthesemantic\ndistanceandelaborationbaselines.Uponevaluationofthevalidation(n=383)andtestset(n=765)\nwithRoBERTa,thepredictedcreativityscoresalsodemonstratedastrongagreementwithhumanratings,\n\n20AUTOMATICMETAPHORSCORING\nr=0.76;95%CI[0.71,0.80]andr=0.72;95%CI[0.69,0.76],respectively.Figure2(above)showsthe\ncorrelationofmodelpredictionswiththehumancreativityratingsofthetestset.TheRoBERTa\ncorrelationwasnumericallylargerthanGPT-2andconsiderablylargerthansemanticdistance.Taken\ntogether,theresultsdemonstratethatfine-tunedLLMs,withdifferentneuralnetworkarchitectures,can\nrobustlycapturehumancreativityratingsofnovelmetaphors.\nHeld-outPromptPerformance\nFigure3\nCorrelationbetweenHuman-RatedCreativityandModelPredictionsfromtheHeld-outMetaphorPrompt\nNote.ModelpredictionsandhumanratingsareZ-scored.n=758;1outlierwasremovedforboth\nmodels.\nToassessthegeneralizabilityofthefine-tunedmodels,weevaluatedtheirabilitytopredict\nhumancreativityratingsofmetaphorsonapreviouslyunseenprompt:'messyroom'(N=759).When\n\n21AUTOMATICMETAPHORSCORING\nevaluatingtheresponsesassociatedwiththeuntrainedmetaphorprompt(n=758),GPT-2exhibited\ncomparableperformancetothepromptsitwastrainedon,resultinginacorrelationofr=0.63;95%CI\n[0.59,0.67].RoBERTaalsodemonstratedtransferabilitytothepreviouslyunseenprompt(n=758),with\nacorrelationr=0.68;95%CI[0.63,0.71],seeFigure3.Thus,bothGPT-2andRoBERTashowedevidence\noflearninghowhumansratethecreativityofnovelmetaphors—beyondtheirtrainingdatasets.\nDiscussion\nThepresentstudyintroducesamethodforautomaticallyassessingmetaphorcreativityby\nharnessingthepoweroflargelanguagemodels(LLMs).Giventhecomplexityofmetaphor\ncomprehensioninhumans,computationallyscoringmetaphorspresentedacompellingchallenge.\nDespitethischallenge,ourresultsdemonstratethatLLMsfine-tunedonhumanratingsofmetaphor\ncreativitycanreliablypredictthecreativityofmetaphorsonbothuntrainedresponsesandonmetaphors\nfromanuntrainedprompt.ThisfindingunderscoresthepotentialofLLMstoboth‘understand’figurative\nlanguageandautomatetheassessmentofmetaphorcreativity.\nAutomaticscoringmethodscanincreasethereproducibilityandefficiencyofcreativity\nassessment—relievinghumansfromlabor-intensivesubjectivescoring.Automaticscoringhasprimarily\nfocusedontheAUT,leavingotherverbalcreativitytasks,suchasmetaphorproduction,without\ndedicatedtools.Here,wesoughttoautomatethescoringofthemetaphorgenerationtaskbyleveraging\nrecentadvancesinLLMs.Wefine-tunedtwowidelyusedLLMs,RoBERTaandGPT-2,toexplorethe\nviabilityofautomatedscoringofmetaphorcreativity.Despitedifferencesintheirpre-trainingregimes,\nbothmodelsrobustlypredictedhumancreativityratingsandsurpassedtheperformanceofthebaseline\nsemanticdistancemetricused:DSI.Togetherthesefindingsindicatethatfine-tunedLLMsprovidea\npromisingalternativetohumancreativityratingsofmetaphors,andsuggestthatLLMscanbetrainedto\nunderstandthecreativityofcomplex,nonliterallanguage(cf.Ichienetal.,2023)\n22AUTOMATICMETAPHORSCORING\nPriorresearchonautomaticverbalcreativityscoringhasfocusedonsemanticdistanceappliedto\ntheAUT(Beatyetal.,2022;Dumasetal.,2020;Dumas&Dunbar,2014;Forthmannetal.,2022;Hass,\n2017;Yuetal.,2023)andshortstories(Johnsonetal.,2022).Johnsonetal.(2022)foundthat\nDSI—whichcomputessemanticdistancebetweenallwordsinaresponse—hashighpredictivepowerfor\nhumanratingsofcreativityinshortstories.WeappliedthesameDSIapproachtometaphorstotesthow\nwelltheyrelatetohumancreativityratings.Ourresultsyieldedamodestcorrelationwiththetestset(r\n=0.42),whichissmallerthanwhatwasfoundforshortstories.Thisfindingisnotablegiventhe\ntheoreticalrelevanceofsemanticdistancetometaphor(Clevenger&Edwards,1988;Katz,1989,1992;\nWinter&Strik-Lievers,2023):bydefinition,metaphorinvolvesconnectingtwoseeminglyunrelated\nconcepts,soonemightexpectsemanticdistance-basedmetricstoberelevant.Yetmetaphorsmustalso\nbeaptandmeaningful,andpreviousworksuggestspeopleprefermetaphorsofmoderatesemantic\ndistance(Katzetal.,1988).Nevertheless,ourstudyprovidesafirstdemonstrationthatsemantic\ndistancecapturessomevarianceinhumanratingsofmetaphorcreativity.\nThemainobjectiveofthisstudywastofine-tuneLLMstopredicthumancreativityratingsfor\nnovelmetaphors.Recently,Organisciaketal.(2023)fine-tunedproprietaryGPTmodelstopredict\nhumancreativityratingsofAUTresponses,reportingstronglypositivecorrelationsthatfarexceeded\nsemanticdistance.Weextendedthisgeneralapproachtometaphorgeneration,usingtwowidely-used\nandopen-sourceLLMsthatvariedinthedesignoftheirself-attentionmechanism:RoBERTa(a\nbidirectionalmodel)andGPT-2(aunidirectionalmodel).BothRoBERTaandGPT-2demonstratedthe\nabilitytogeneratecreativityscorescomparabletohumanraters,withRoBERTaexhibitingslightly\nsuperiorperformance(r=.72)comparedtoGPT-2(r=.70).Interestingly,thetopperformingRoBERTa\nandGPT-2hyperparametersuseddifferentpromptprefixes—‘novel’forGPT-2and‘surprising’for\nRoBERTa.‘Surprising’isthesameprefixusedintheAUTfine-tuningstudyofOrganisciaketal.(2023),\nbutnot‘novel.’Ourfindingsdemonstratetheneedforamoreexhaustiveprefixsearchtoelicitthe\n23AUTOMATICMETAPHORSCORING\nhighestperformancefromLLMs.Alternatively,onecouldemployamulti-adjectiveapproach,where\nscoresforalltheadjectivesareaveraged.\nWefurtherevaluatedtheperformanceofthesefine-tunedmodelsonamorechallenging\nscenario:metaphorsgeneratedusingapreviouslyunseenprompt(‘messyroom’).Remarkably,both\nRoBERTaandGPT-2maintainedstrongperformanceinreplicatinghumancreativityscoresforthese\nnovelmetaphors.Onceagain,RoBERTa(r=.68)narrowlyoutperformedGPT-2(r=.63).Themodelsthus\nseeminglylearnedsomethinggeneralaboutcreativityinfigurativelanguagethatgeneralizedbeyond\ntheirtrainingdata.Practically,futureresearcherscouldusethesemodelstoscorethecreativityofnew\nmetaphorpromptsthatwerenotincludedinthisstudy,thoughmodelperformancemayvary,especially\nifthepromptsignificantlydeviatesfromthestructureandtopicsinthecurrentwork.Werecommend\ntestingnewpromptswithasmallsampleofhumanratingstoensuremodelscoresarereliableandvalid.\nFutureworkshouldfurtherexplorethefar-generalizationcapabilitiesandfailuremodesofthesemodels\nasafunctionoflinguisticandconceptualdistancefromthetrainingset.\nTakentogether,ourresultsdemonstratetheviabilityofLLMstoscoremetaphorcreativity,with\nimplicationsfornaturallanguageprocessingresearchontheabilityofLLMstounderstandfigurative\nlanguage.ExpandinguponrecentfindingsthatLLMscanseemingly“understand”figurativelanguage\n(Ichienetal.,2023;E.Liuetal.,2022),theseresultsshowLLMscanbefine-tunedtopickupfigurative\nlanguagewellenoughtoevaluatemetaphorcreativequality.Automaticscoringfurtherhelpstolower\nthelaborcostandincreasethereproducibilityofcreativityresearch,allowingresearchersand\npractitionerstoefficientlyassesscreativethinkinginacademicorindustrysettings.\nStrengths,Limitations,andFutureDirections\nOurresultsdemonstratetherobustcapacityofLLMstoautomaticallyscoremetaphorcreativity.\nWhilepreviousworkhasshownthatLLMscanautomaticallyscoredivergentthinkingtasks(i.e.,theAUT;\n24AUTOMATICMETAPHORSCORING\nOrganisciaketal.,2023),ourworkextendsthiscapabilitytometaphor—anaturalisticformoffigurative\nlanguage.Notably,weshowthatitispossibletocloselymatchhumancreativityratingsformetaphors,\ndespiteusingrelativelysmallopen-sourcemodels(i.e.,GPT-2andRoBERTa).Thedevelopmentof\nefficient,yetpowerful,open-sourcemodelsformetaphorassessmentrepresentsakeystrengthofthe\npresentwork.Theresultingmodelsarecompatiblewithcomputationalresourcesresearchersor\neducatorsarelikelytohaveaccesstoandarefreetouse—broadeningpotentialimpact.Themodelswill\nalsoexistinperpetuityonanOpenScienceFoundationrepository,whichfacilitatesreproducibilityinthe\nfuture.Incontrast,verylargeclosed-sourcemodels(e.g.,GPT-4)costresearchersmoneytotrainand\nuse,andaresubjecttodeprecationastechnologyadvances—precludinglong-termreproducibility.\nDespitethepromisingresultsobtainedinthisstudy,thereareanumberofopportunitiesfor\nfutureimprovement.OnesuchavenueforfutureresearchinvolvesinvestigatingadditionalLLM\narchitectures,models,andalargerhyperparametersearch.Wetestedalimitedsetofadjectiveprefixes\ntofine-tunethemodels(i.e.,'creative,''novel,''useful,''surprising,'and'unique');however,thisishardly\nanexhaustivelist.Perhapsthemodelswouldperformevenbetterwithadifferentadjectiveora\ndifferentsentenceframealtogether.Asisoftenthecaseinmachinelearning,increasingthevolumeof\ntrainingdataand/orincreasingthediversityofmetaphortasksthemodelistrainedoncouldenhance\nmodelgeneralizabilityandyieldmorerobustrepresentationsofcreativemetaphors.Additionally,this\nworkcouldbelimitedbythequalityofhumanratingsofmetaphorcreativity.Thedatasetsusedtotrain\ntheLLMshadvariousintraclasscorrelationsandtheraterdisagreementcouldtranslatetothemodel.\nAnoutstandingquestionthatarisesfromthisstudypertainstotheapplicabilityofLLMstoscore\nmetaphorsinlanguagesotherthanEnglish.Sincethesemodelsareprimarilypre-trainedonEnglish\ncorpora,theireffectivenessforscoringfigurativelanguageshouldbeexpectedtodifferacrosslanguages\n(withlikelyperformancedegradation).Understandinghowthesemodelsperformunderdifferent\nlinguisticcontexts,andhowtorectifycasesofunderperformance,isnecessarytoensureoptimal\n25AUTOMATICMETAPHORSCORING\nperformanceandtoimprovetheaccessibilityofthesetoolsbeyondtheEnglishlanguage.Recentwork\nhasexploredsemanticdistancescoringoftheAUTviamultilingualLLMs(Pattersonetal.,2023)and\nshowedencouragingperformanceacross12differentlanguagesintermsofpredictinghumanratings.\nInthisstudy,wefoundthefine-tunedLLMsbothpredictedmetaphorcreativityratingsbetter\nthanwordcountalone,suggestingthatthemodelsareattendingtosomethingmorethanjust\nelaborationoftheresponses.Furtherresearchisneededtoidentifywhatexactlythemodelisattending\nto.Forexample,themodelscouldbemakinganassociationbetweenresponseswithhigherfrequency\nandlowerhumanratingsofcreativity.Byexaminingthefrequencyoftypesofresponses,beyond\nsemanticdistance,wecouldbegintounderstandhowthemodelsareabletopredictthecreativityof\nfigurativelanguage.\nAnotheraspectofthisstudyworthfurtherexploringisthedistinctionbetweenmetaphor\ncreativityandmetaphoraptness:thedegreetowhichametaphorissemanticallycoherentand\nmeaningfulgiventhecontext.Thehumanratersinourstudyscoredmetaphorsbasedoncreativity,but\nthereisalonghistoryofresearchonmetaphoraptness(Blasko&Connine,1993;Holyoak&\nStamenkovi ć ,2018;Katz,1989,1989;Stamenkovi ćetal.,2023;Tourangeau&Sternberg,1981).Since\naptnessimprovesthecomprehensionofmetaphorsinhumans(Stamenkovi ćetal.,2023),future\nresearchcouldexplicitlyincludeaptnessinthehumanratingsofmetaphorcreativitytoseeifthat\nconstructimprovestheautomatedscoringofmetaphorsinLLMs.Oneconsiderationregardingaptnessis\nwhethercreativityratingsalreadyencompassaptnesstosomeextent.Althoughtheratersinthisstudy\nwereinstructedtoratemetaphorsforcreativity/originality,theymayhavetacitlyconsideredtheir\naptness(or“usefulness”),whichcouldaccountforsomeofthevarianceinratings.\nConclusion\n26AUTOMATICMETAPHORSCORING\nInthisstudy,weintroducedanovelapproachtoscoringthemetaphorgenerationtaskusing\nfine-tunedLLMsandcomparedittotwobaselines:wordcount/elaborationandsemanticdistance(i.e.,\nDSI;Johnsonetal.,2022).TheresultsshowedthatLLM-generatedcreativityscorescorrelatedstrongly\nwithhumancreativityratings—farexceedingbothbaselines.TheseresultshighlighttheabilityofLLMs\ntoaccuratelyscoreproductsfromcomplexandabstractcreativethinkingtasksthatgobeyondthe\nalternateusestask.Ourresearchoffersareliableandefficientalternativetolabor-intensiveand\nsubjectivehumanratings—improvingthereproducibilityandscalabilityofcreativeassessment.We\nprovideyetanotheradvancementtowardstheautomationofcreativityassessment,empowering\nresearcherstounderstandandimprovecreativethinking.\n27AUTOMATICMETAPHORSCORING\nReferences\nAkiba,T.,Sano,S.,Yanase,T.,Ohta,T.,&Koyama,M.(2019).Optuna:ANext-generationHyperparameter\nOptimizationFramework.Proceedingsofthe25thACMSIGKDDInternationalConferenceon\nKnowledgeDiscovery&DataMining,2623–2631.https://doi.org/10.1145/3292500.3330701\nBakker,M.,Chadwick,M.,Sheahan,H.,Tessler,M.,Campbell-Gillingham,L.,Balaguer,J.,McAleese,N.,\nGlaese,A.,Aslanides,J.,Botvinick,M.,&Summerfield,C.(2022).Fine-tuninglanguagemodelsto\nfindagreementamonghumanswithdiversepreferences.AdvancesinNeuralInformation\nProcessingSystems,35,38176–38189.https://doi.org/10.48550/arXiv.2211.15006\nBeaty,R.E.,&Johnson,D.R.(2021).AutomatingcreativityassessmentwithSemDis:Anopenplatform\nforcomputingsemanticdistance.BehaviorResearchMethods,53(2),757–780.\nhttps://doi.org/10.3758/s13428-020-01453-w\nBeaty,R.E.,Johnson,D.R.,Zeitlen,D.C.,&Forthmann,B.(2022).SemanticDistanceandtheAlternate\nUsesTask:RecommendationsforReliableAutomatedAssessmentofOriginality.Creativity\nResearchJournal,34(3),245–260.https://doi.org/10.1080/10400419.2022.2025720\nBeaty,R.E.,&Silvia,P.J.(2013).Metaphoricallyspeaking:Cognitiveabilitiesandtheproductionof\nfigurativelanguage.Memory&Cognition,41(2),255–267.\nhttps://doi.org/10.3758/s13421-012-0258-5\nBeaty,R.E.,Silvia,P.J.,&Benedek,M.(2017).Brainnetworksunderlyingnovelmetaphorproduction.\nBrainandCognition,111,163–170.https://doi.org/10.1016/j.bandc.2016.12.004\nBillow,R.M.(1977).Metaphor:Areviewofthepsychologicalliterature.PsychologicalBulletin,84(1),\n81–92.https://doi.org/10.1037/0033-2909.84.1.81\nBlasko,D.G.,&Connine,C.M.(1993).Effectsoffamiliarityandaptnessonmetaphorprocessing.Journal\nofExperimentalPsychology:Learning,Memory,andCognition,19(2),295–308.\nhttps://doi.org/10.1037/0278-7393.19.2.295\n28AUTOMATICMETAPHORSCORING\nBuczak,P.,Huang,H.,Forthmann,B.,&Doebler,P.(2023).TheMachinesTakeOver:AComparisonof\nVariousSupervisedLearningApproachesforAutomatedScoringofDivergentThinkingTasks.The\nJournalofCreativeBehavior,57(1),17–36.https://doi.org/10.1002/jocb.559\nCardillo,E.R.,Watson,C.E.,Schmidt,G.L.,Kranjec,A.,&Chatterjee,A.(2012).Fromnoveltofamiliar:\nTuningthebrainformetaphors.Neuroimage,59(4),3212–3221.\nhttps://doi.org/10.1016/j.neuroimage.2011.11.079\nCaucheteux,C.,Gramfort,A.,&King,J.-R.(2022).Deeplanguagealgorithmspredictsemantic\ncomprehensionfrombrainactivity.ScientificReports,12(1),Article1.\nhttps://doi.org/10.1038/s41598-022-20460-9\nChakrabarty,T.,Choi,Y.,&Shwartz,V.(2022).It’snotRocketScience:InterpretingFigurativeLanguagein\nNarratives.TransactionsoftheAssociationforComputationalLinguistics,10,589–606.\nhttps://doi.org/10.1162/tacl_a_00478\nClevenger,T.,&Edwards,R.(1988).Semanticdistanceasapredictorofmetaphorselection.Journalof\nPsycholinguisticResearch,17(3),211–226.https://doi.org/10.1007/BF01686356\nDevlin,J.,Chang,M.-W.,Lee,K.,&Toutanova,K.(2019).BERT:Pre-trainingofDeepBidirectional\nTransformersforLanguageUnderstanding(arXiv:1810.04805).arXiv.\nhttps://doi.org/10.48550/arXiv.1810.04805\nDumas,D.,&Dunbar,K.N.(2014).UnderstandingFluencyandOriginality:Alatentvariableperspective.\nThinkingSkillsandCreativity,14,56–67.https://doi.org/10.1016/j.tsc.2014.09.003\nDumas,D.,Organisciak,P.,&Doherty,M.(2020).MeasuringDivergentThinkingOriginalitywithHuman\nRatersandText-MiningModels:APsychometricComparisonofMethods.Psychologyof\nAestheticsCreativityandtheArts.https://doi.org/10.1037/aca0000319\nDumas,D.,Organisciak,P.,Maio,S.,&Doherty,M.(2021).FourText-MiningMethodsforMeasuring\nElaboration.TheJournalofCreativeBehavior,55(2),517–531.https://doi.org/10.1002/jocb.471\n29AUTOMATICMETAPHORSCORING\nFan,L.,Zhuang,K.,Wang,X.,Zhang,J.,Liu,C.,Gu,J.,&Qiu,J.(2023).Exploringthebehavioralandneural\ncorrelatesofsemanticdistanceincreativewriting.Psychophysiology,60(5),e14239.\nhttps://doi.org/10.1111/psyp.14239\nForthmann,B.,Beaty,R.E.,&Johnson,D.R.(2022).SemanticSpacesAreNotCreatedEqual–How\nShouldWeWeighThemintheSequel?EuropeanJournalofPsychologicalAssessment.\nhttps://doi.org/10.1027/1015-5759/a000723\nForthmann,B.,&Doebler,P.(2022).Fiftyyearslaterandstillworking:RediscoveringPaulusetal’s(1970)\nautomatedscoringofdivergentthinkingtests.PsychologyofAesthetics,Creativity,andtheArts,\nNoPaginationSpecified-NoPaginationSpecified.https://doi.org/10.1037/aca0000518\nGibbs,R.W.(1990).TheProcessofUnderstandingLiteraryMetaphor.19(2),65–79.\nhttps://doi.org/10.1515/jlse.1990.19.2.65\nGibbs,R.W.(1994).ThePoeticsofMind:FigurativeThought,Language,andUnderstanding.Cambridge\nUniversityPress.\nGlucksberg,S.,&McGlone,M.S.(2001).UnderstandingFigurativeLanguage:FromMetaphortoIdioms.\nOxfordUniversityPress,USA.\nGlucksberg,S.,McGlone,M.S.,&Manfredi,D.(1997).PropertyAttributioninMetaphorComprehension.\nJournalofMemoryandLanguage,36(1),50–67.https://doi.org/10.1006/jmla.1996.2479\nGreen,A.E.(2016).Creativity,WithinReason:SemanticDistanceandDynamicStateCreativityin\nRelationalThinkingandReasoning.CurrentDirectionsinPsychologicalScience,25(1),28–35.\nhttps://doi.org/10.1177/0963721415618485\nGuilford,J.P.(1967).Thenatureofhumanintelligence.McGraw-Hill.\nHass,R.W.(2017).Trackingthedynamicsofdivergentthinkingviasemanticdistance:Analyticmethods\nandtheoreticalimplications.Memory&Cognition,45(2),233–244.\nhttps://doi.org/10.3758/s13421-016-0659-y\n30AUTOMATICMETAPHORSCORING\nHeinen,D.J.P.,&Johnson,D.R.(2018).Semanticdistance:Anautomatedmeasureofcreativitythatis\nnovelandappropriate.PsychologyofAesthetics,Creativity,andtheArts,12(2),144–156.\nhttps://doi.org/10.1037/aca0000125\nHolyoak,K.J.,&Stamenkovi ć ,D.(2018).Metaphorcomprehension:Acriticalreviewoftheoriesand\nevidence.PsychologicalBulletin,144(6),641–671.https://doi.org/10.1037/bul0000145\nIchien,N.,Stamenkovi ć ,D.,&Holyoak,K.J.(2023).LargeLanguageModelDisplaysEmergentAbilityto\nInterpretNovelLiteraryMetaphors(arXiv:2308.01497).arXiv.\nhttps://doi.org/10.48550/arXiv.2308.01497\nJawahar,G.,Sagot,B.,&Seddah,D.(2019).WhatDoesBERTLearnabouttheStructureofLanguage?\nProceedingsofthe57thAnnualMeetingoftheAssociationforComputationalLinguistics,\n3651–3657.https://doi.org/10.18653/v1/P19-1356\nJohnson,D.R.,Kaufman,J.C.,Baker,B.S.,Patterson,J.D.,Barbot,B.,Green,A.E.,vanHell,J.,Kennedy,\nE.,Sullivan,G.F.,Taylor,C.L.,Ward,T.,&Beaty,R.E.(2022).Divergentsemanticintegration\n(DSI):Extractingcreativityfromnarrativeswithdistributionalsemanticmodeling.Behavior\nResearchMethods.https://doi.org/10.3758/s13428-022-01986-2\nKasirer,A.,&Mashal,N.(2018).FluencyorSimilarities?CognitiveAbilitiesthatContributetoCreative\nMetaphorGeneration.CreativityResearchJournal,30(2),205–211.\nhttps://doi.org/10.1080/10400419.2018.1446747\nKatz,A.N.(1989).Onchoosingthevehiclesofmetaphors:Referentialconcreteness,semanticdistances,\nandindividualdifferences.JournalofMemoryandLanguage,28(4),486–499.\nhttps://doi.org/10.1016/0749-596X(89)90023-5\nKatz,A.N.(1992).PsychologicalStudiesinMetaphorProcessing:ExtensionstothePlacementofTermsin\nSemanticSpace.PoeticsToday,13(4),607–632.https://doi.org/10.2307/1773291\nKatz,A.N.,Paivio,A.,Marschark,M.,&Clark,J.(1988).Normsfor204Literaryand260Nonliterary\n31AUTOMATICMETAPHORSCORING\nMetaphorson10PsychologicalDimensions.MetaphorandSymbol-METAPHORSYMB,3,\n191–214.https://doi.org/10.1207/s15327868ms0304_1\nKenett,Y.N.(2019).Whatcanquantitativemeasuresofsemanticdistancetellusaboutcreativity?\nCurrentOpinioninBehavioralSciences,27,11–16.\nhttps://doi.org/10.1016/j.cobeha.2018.08.010\nLakoff,G.,&Johnson,M.(2008).MetaphorsWeLiveBy.UniversityofChicagoPress.\nLandauer,T.K.,Foltz,P.W.,&Laham,D.(1998).Anintroductiontolatentsemanticanalysis.Discourse\nProcesses,25(2–3),259–284.https://doi.org/10.1080/01638539809545028\nLantz,B.(2013).MachineLearningwithR(3rded.).PacktPublishing.\nhttps://www.packtpub.com/product/machine-learning-with-r-third-edition/9781788295864\nLiu,E.,Cui,C.,Zheng,K.,&Neubig,G.(2022).TestingtheAbilityofLanguageModelstoInterpret\nFigurativeLanguage.Proceedingsofthe2022ConferenceoftheNorthAmericanChapterofthe\nAssociationforComputationalLinguistics:HumanLanguageTechnologies,4437–4452.\nhttps://doi.org/10.18653/v1/2022.naacl-main.330\nLiu,Y.,Ott,M.,Goyal,N.,Du,J.,Joshi,M.,Chen,D.,Levy,O.,Lewis,M.,Zettlemoyer,L.,&Stoyanov,V.\n(2019).RoBERTa:ARobustlyOptimizedBERTPretrainingApproach(arXiv:1907.11692).arXiv.\nhttps://doi.org/10.48550/arXiv.1907.11692\nOrganisciak,P.,Acar,S.,Dumas,D.,&Berthiaume,K.(2023).Beyondsemanticdistance:Automated\nscoringofdivergentthinkinggreatlyimproveswithlargelanguagemodels.ThinkingSkillsand\nCreativity,49,101356.https://doi.org/10.1016/j.tsc.2023.101356\nParde,N.,&Nielsen,R.(2018,May).ACorpusofMetaphorNoveltyScoresforSyntactically-Related\nWordPairs.ProceedingsoftheEleventhInternationalConferenceonLanguageResourcesand\nEvaluation(LREC2018).LREC2018,Miyazaki,Japan.https://aclanthology.org/L18-1243\nPatterson,J.D.,Merseal,H.M.,Johnson,D.R.,Agnoli,S.,Baas,M.,Baker,B.S.,Barbot,B.,Benedek,M.,\n32AUTOMATICMETAPHORSCORING\nBorhani,K.,Chen,Q.,Christensen,J.F.,Corazza,G.E.,Forthmann,B.,Karwowski,M.,Kazemian,\nN.,Kreisberg-Nitzav,A.,Kenett,Y.N.,Link,A.,Lubart,T.,…Beaty,R.E.(2023).Multilingual\nsemanticdistance:Automaticverbalcreativityassessmentinmanylanguages.Psychologyof\nAesthetics,Creativity,andtheArts,17(4),495–507.https://doi.org/10.1037/aca0000618\nPaulus,D.H.,Renzulli,J.S.,&Archambault,F.X.(1970).Computersimulationofhumanratingsof\ncreativity.FinalReport,(No.9-A-032).https://files.eric.ed.gov/fulltext/ED060658.pdf\nPennington,J.,Socher,R.,&Manning,C.(2014).GloVe:GlobalVectorsforWordRepresentation.\nProceedingsofthe2014ConferenceonEmpiricalMethodsinNaturalLanguageProcessing\n(EMNLP),1532–1543.https://doi.org/10.3115/v1/D14-1162\nRadford,A.,Wu,J.,Child,R.,Luan,D.,Amodei,D.,&Sutskever,I.(2019).LanguageModelsare\nUnsupervisedMultitaskLearners.https://api.semanticscholar.org/CorpusID:160025533\nSchrimpf,M.,Blank,I.A.,Tuckute,G.,Kauf,C.,Hosseini,E.A.,Kanwisher,N.,Tenenbaum,J.B.,&\nFedorenko,E.(2021).Theneuralarchitectureoflanguage:Integrativemodelingconvergeson\npredictiveprocessing.ProceedingsoftheNationalAcademyofSciences,118(45),e2105646118.\nhttps://doi.org/10.1073/pnas.2105646118\nSilvia,P.J.,&Beaty,R.E.(2012).Makingcreativemetaphors:Theimportanceoffluidintelligencefor\ncreativethought.Intelligence,40(4),343–351.https://doi.org/10.1016/j.intell.2012.02.005\nSilvia,P.J.,Winterstein,B.P.,Willse,J.T.,Barona,C.M.,Cram,J.T.,Hess,K.I.,Martinez,J.L.,&Richard,\nC.A.(2008).Assessingcreativitywithdivergentthinkingtasks:Exploringthereliabilityand\nvalidityofnewsubjectivescoringmethods.PsychologyofAesthetics,Creativity,andtheArts,\n2(2),68–85.https://doi.org/10.1037/1931-3896.2.2.68\nStamenkovi ć ,D.,Milenkovi ć ,K.,Ichien,N.,&Holyoak,K.J.(2023).AnIndividual-DifferencesApproachto\nPoeticMetaphor:ImpactofAptnessandFamiliarity.MetaphorandSymbol,38(2),149–161.\nhttps://doi.org/10.1080/10926488.2021.2006046\n33AUTOMATICMETAPHORSCORING\nStevenson,C.,Smal,I.,Baas,M.,&Grasman,R.(2020).PuttingGPT-3’sCreativitytothe(Alternative\nUses)Test.https://doi.org/10.48550/arXiv.2206.08932\nTiberius,R.G.(1986).MetaphorsUnderlyingtheImprovementofTeachingandLearning.BritishJournal\nofEducationalTechnology,17(2),144–156.https://doi.org/10.1111/j.1467-8535.1986.tb00504.x\nTourangeau,R.,&Sternberg,R.J.(1981).Aptnessinmetaphor.CognitivePsychology,13(1),27–55.\nhttps://doi.org/10.1016/0010-0285(81)90003-7\nWinter,B.,&Strik-Lievers,F.(2023).Semanticdistancepredictsmetaphoricityandcreativityjudgments\ninsynestheticmetaphors.MetaphorandtheSocialWorld,13(1),59–80.\nhttps://doi.org/10.1075/msw.00029.win\nYu,Y.,Beaty,R.E.,Forthmann,B.,Beeman,M.,Cruz,J.H.,&Johnson,D.(2023).AMADmethodto\nassessideanovelty:Improvingvalidityofautomaticscoringusingmaximumassociativedistance\n(MAD).PsychologyofAesthetics,Creativity,andtheArts.https://doi.org/10.1037/aca0000573\nZhou,Z.-H.(2021).MachineLearning.Springer.https://doi.org/10.1007/978-981-15-1967-3"
}