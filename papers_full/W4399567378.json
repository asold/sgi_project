{
  "title": "Fine Tuning Large Language Model for Secure Code Generation",
  "url": "https://openalex.org/W4399567378",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2104629437",
      "name": "Junjie Li",
      "affiliations": [
        "Concordia University"
      ]
    },
    {
      "id": "https://openalex.org/A3212238403",
      "name": "Aseem Sangalay",
      "affiliations": [
        "Delhi Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A1987889063",
      "name": "Cheng Cheng",
      "affiliations": [
        "Concordia University"
      ]
    },
    {
      "id": "https://openalex.org/A1038466737",
      "name": "Yuan Tian",
      "affiliations": [
        "Queen's University"
      ]
    },
    {
      "id": "https://openalex.org/A2140811187",
      "name": "Jinqiu Yang",
      "affiliations": [
        "Concordia University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3170092793",
    "https://openalex.org/W2770568736",
    "https://openalex.org/W3183469243",
    "https://openalex.org/W4285225959",
    "https://openalex.org/W3091588759",
    "https://openalex.org/W4281567711",
    "https://openalex.org/W3098605233",
    "https://openalex.org/W4224060952",
    "https://openalex.org/W4281836191",
    "https://openalex.org/W4320560161",
    "https://openalex.org/W3162364548",
    "https://openalex.org/W3195703954",
    "https://openalex.org/W4226326075",
    "https://openalex.org/W4288057765",
    "https://openalex.org/W4385187279",
    "https://openalex.org/W4226205863",
    "https://openalex.org/W4282813445",
    "https://openalex.org/W4281763794",
    "https://openalex.org/W4221141536",
    "https://openalex.org/W3163206498",
    "https://openalex.org/W3193639695",
    "https://openalex.org/W4388867283"
  ],
  "abstract": "AI pair programmers, such as GitHub's Copilot, have shown great success in automatic code generation. However, such large language model-based code generation techniques face the risk of introducing security vulnerabilities to codebases. In this work, we explore the direction of fine-tuning large language models for generating more secure code. We use real-world vulnerability fixes as our fine-tuning dataset. We craft a code-generation scenario dataset (C/C++) for evaluating and comparing the pre-trained and fine-tuned models. Our experiments on GPT-J show that the fine-tuned GPT-J achieved 70.4% and 64.5% ratios of non-vulnerable code generation for C and C++, respectively, which has a 10% increase for C and a slight increase for C++ compared with the pre-trained large language model.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8595424294471741
    },
    {
      "name": "Code (set theory)",
      "score": 0.7654077410697937
    },
    {
      "name": "Code generation",
      "score": 0.6909703612327576
    },
    {
      "name": "Vulnerability (computing)",
      "score": 0.6550518274307251
    },
    {
      "name": "Face (sociological concept)",
      "score": 0.5661759376525879
    },
    {
      "name": "Source code",
      "score": 0.44158387184143066
    },
    {
      "name": "Programming language",
      "score": 0.3979525864124298
    },
    {
      "name": "Computer security",
      "score": 0.18916302919387817
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    },
    {
      "name": "Social science",
      "score": 0.0
    },
    {
      "name": "Key (lock)",
      "score": 0.0
    }
  ]
}