{
    "title": "TransitGPT: a generative AI-based framework for interacting with GTFS data using large language models",
    "url": "https://openalex.org/W4411388260",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A3127511928",
            "name": "Saipraneeth Devunuri",
            "affiliations": [
                "University of Illinois Urbana-Champaign"
            ]
        },
        {
            "id": "https://openalex.org/A2741659464",
            "name": "Lewis Lehe",
            "affiliations": [
                "University of Illinois Urbana-Champaign"
            ]
        },
        {
            "id": "https://openalex.org/A3127511928",
            "name": "Saipraneeth Devunuri",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2741659464",
            "name": "Lewis Lehe",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4411638692",
        "https://openalex.org/W2101746535",
        "https://openalex.org/W4399174383",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W4286892945",
        "https://openalex.org/W4306703754",
        "https://openalex.org/W4387635162",
        "https://openalex.org/W4386272786",
        "https://openalex.org/W4392961014",
        "https://openalex.org/W4396213765",
        "https://openalex.org/W4392565730",
        "https://openalex.org/W4394685762",
        "https://openalex.org/W2762214439",
        "https://openalex.org/W4379538742",
        "https://openalex.org/W2543472989",
        "https://openalex.org/W4384615649",
        "https://openalex.org/W4389984066",
        "https://openalex.org/W3083410900",
        "https://openalex.org/W4394778349",
        "https://openalex.org/W4368754606",
        "https://openalex.org/W2752752079",
        "https://openalex.org/W3027879771",
        "https://openalex.org/W6600062020",
        "https://openalex.org/W4383605243",
        "https://openalex.org/W6600223117",
        "https://openalex.org/W4404739549",
        "https://openalex.org/W4386269383",
        "https://openalex.org/W4327810158",
        "https://openalex.org/W4396726346",
        "https://openalex.org/W2943323603",
        "https://openalex.org/W4401043137",
        "https://openalex.org/W3135734842",
        "https://openalex.org/W4311715259",
        "https://openalex.org/W4378465112",
        "https://openalex.org/W4402157028",
        "https://openalex.org/W4380992994",
        "https://openalex.org/W6600137863",
        "https://openalex.org/W4378473736",
        "https://openalex.org/W3212462988",
        "https://openalex.org/W4304195432",
        "https://openalex.org/W4285600327",
        "https://openalex.org/W6600106792",
        "https://openalex.org/W4400962082",
        "https://openalex.org/W4411630043",
        "https://openalex.org/W4392798406",
        "https://openalex.org/W4402671956",
        "https://openalex.org/W4396786229",
        "https://openalex.org/W4323927216"
    ],
    "abstract": "Abstract This paper introduces a framework that leverages Large Language Models (LLMs) to answer natural language queries about General Transit Feed Specification (GTFS) data. The framework is implemented in a chatbot called TransitGPT with open-source code. TransitGPT works by guiding LLMs to generate Python code that extracts and manipulates GTFS data relevant to a query, which is then executed on a server where the GTFS feed is stored. It can accomplish a wide range of tasks, including data retrieval, calculations and interactive visualizations, without requiring users to have extensive knowledge of GTFS or programming. The LLMs that produce the code are guided entirely by prompts, without fine-tuning or access to the actual GTFS feeds. We evaluate TransitGPT using GPT-4o and Claude-3.5-Sonnet LLMs on a benchmark dataset of 100 tasks, to demonstrate its effectiveness and versatility. The results show that TransitGPT can significantly enhance the accessibility and usability of transit data.",
    "full_text": "Public Transport (2025) 17:319–345\nhttps://doi.org/10.1007/s12469-025-00395-w\nORIGINAL RESEARCH\nTransitGPT: a generative AI-based framework for\ninteracting with GTFS data using large language models\nSaipraneeth Devunuri 1 · Lewis Lehe 1\nAccepted: 24 March 2025 / Published online: 17 June 2025\n© The Author(s) 2025\nAbstract\nThis paper introduces a framework that leverages Large Language Models (LLMs)\nto answer natural language queries about General Transit Feed Speciﬁcation (GTFS)\ndata. The framework is implemented in a chatbot called TransitGPT with open-source\ncode. TransitGPT works by guiding LLMs to generate Python code that extracts and\nmanipulates GTFS data relevant to a query, which is then executed on a server where\nthe GTFS feed is stored. It can accomplish a wide range of tasks, including data\nretrieval, calculations and interactive visualizations, without requiring users to have\nextensive knowledge of GTFS or programming. The LLMs that produce the code are\nguided entirely by prompts, without ﬁne-tuning or access to the actual GTFS feeds.\nWe evaluate TransitGPT using GPT-4o and Claude-3.5-Sonnet LLMs on a benchmark\ndataset of 100 tasks, to demonstrate its effectiveness and versatility. The results show\nthat TransitGPT can signiﬁcantly enhance the accessibility and usability of transit\ndata.\nKeywords Public transit · Generative AI · Large language model · Information\nretrieval · Prompt engineering\n1 Introduction\n1.1 Background\nThe General Transit Feed Speciﬁcation (GTFS) is an open data standard for public\ntransit data. Started in 2005 as a collaboration between Google and TriMet (Port-\nland, OR’s transit agency) (Roth 2010; McHugh 2013), today over 10,000 agencies\nfrom over 100 countries use GTFS to share and store their transit feeds publicly\n(MobilityData 2024b). The scope of GTFS has expanded beyond schedules to include\ninformation about real-time updates, ﬂexible services, and fares. Its widespread adop-\nB Saipraneeth Devunuri\nsd37@illinois.edu\n1 Department of Civil Engineering, University of Illinois at Urbana Champaign, Urbana, IL, USA\n123\n320 S. Devunuri, L. Lehe\ntion has led to the development of software, programming libraries, and plugins for\npopular GIS software that help agencies create or visualize GTFS feeds.\nThe principal use of GTFS is for navigation applications such as Google Maps,\nApple Maps, Transit, etc. In addition to helping people use transit, GTFS data are\nincreasingly used to analyze, measure and understand public transit systems. A\nspatio-temporal decomposition of GTFS has been utilized to construct O-D travel\ntime matrices, generate isochrones, and estimate travel time uncertainty (Pereira et al.\n2021; Liu et al. 2024). This decomposition has been used to conduct transit accessi-\nbility analysis by examining socioeconomic and spatial-temporal inequalities (Fayyaz\net al. 2017; Prajapati et al. 2020; Yan et al. 2022; Pereira et al. 2023). Devunuri et al.\n(2024a) and Devunuri and Lehe ( 2024a) decompose GTFS feeds into segments for all\nUS and Canadian transit agencies to measure statistics about bus stop spacings. Fortin\net al. ( 2016) modeled the transit timetables as graphs and developed graph-oriented\nindicators, including connectivity between stops and the proportion of active stop pairs\nover time. GTFS has also been used to create informative visualizations. Kunama et al.\n(2017) developed ‘GTFS-Viz’, a tool to animate the movement of buses with time and\nvisualize the number of buses in use. Para et al. ( 2024) created a user-friendly interface\nto visualize speeds, service rates, and headways. In conjunction with GTFS-Realtime,\nPark et al. ( 2020) examined delay and its propagation in the context of transit system\nperformance.\nOne challenge faced in analyzing GTFS data is that the speciﬁcation itself is com-\nplex. A feed may include over 30 .txt ﬁles containing over 200 ﬁelds connected in\ncomplex ways. Some ﬁelds are required, some are optional, and others are condi-\ntionally required or forbidden (i.e., only included or excluded if another optional\nﬁeld is present). Feeds also include a variety of qualitatively different types of data—\nincluding times, stop coordinates, route shapes, identiﬁer strings, integer counts, fare\nrules, fare amounts, and color hexadecimal. Thus, to analyze a system, the user must\nappreciate the relationships among these ﬁelds. Devunuri et al. ( 2024b) show that two\npopular Large Language Models (LLMs), GPT-3.5-Turbo and GPT-4, can ameliorate\nthis challenge somewhat by answering questions about the GTFS speciﬁcation with\nreasonable accuracy. A second challenge is that to obtain speciﬁc information about\nan agency (or agencies) from its GTFS feed, an analyst (even one who understands\nthe GTFS speciﬁcation well) must also ﬁgure out how to read and manipulate the data\nwith a spreadsheet application or some computer code in order to obtain the answers\nsought. To this end, Devunuri et al. ( 2024b) also brieﬂy explore using LLMs to write\ncode that carries out simple retrieval tasks on GTFS data—an application of what is\nknown as program synthesis (Haluptzok et al. 2023).\n1.2 Plan of the paper\nThis paper introduces an architecture that uses LLMs to answer questions about transit\nsystems from GTFS data. This architecture is implemented in a chatbot interface called\nTransitGPT. The link to the chatbot, the code behind TransitGPT and a Docker ﬁle\nfor deploying it are available on our GitHub repository located at https://github.com/\nUTEL-UIUC/TransitGPT. The reader is encouraged to experiment with TransitGPT\n123\nTransitGPT: a generative AI-based framework… 321\nby selecting one of the ten agencies we have prepared and asking questions about it.\nFigure 1 shows some examples of questions and answers generated by TransitGPT.\nTransitGPT can answer questions that a rider might have, such as: “When does the\nlast Orange bus arrive at University and Victor on a Tuesday?” It can also answer\nsystem-level questions such as: “Which routes have a headway shorter than 15 min on\nthe weekend?”\nA goal of this paper is to explain the architecture behind TransitGPT and how it was\nbuilt. In a nutshell, what we do is (i) ask the LLM to write Python code that can answer\na question given that the GTFS feed is available; then (ii) run that code on a server\nwhere the feeds are stored. While this two-step combination conveys the gist, Transit-\nGPT involves many embellishments which are explained more thoroughly below. In\nparticular, we have created a large system prompt : a text ﬁle containing instructions\nthat guide the LLM as it writes code to answer the questions. This system prompt\ncan be passed to any public-facing LLM, without ‘pre-training’ or ‘ﬁne-tuning’. This\nemphasis on prompt engineering (rather than ﬁne-tuning) aligns with the concept of\n“Prompting Is All Y ou Need” (Feng and Chen 2024), which avoids the need for exten-\nsive training data and compute resources. To evaluate different prompt designs and to\ncompare the performance of LLMs, we employ a 100-question benchmark.\nAt the outset, it is important to distinguish our approach from another one which is\nperhaps more intuitive: passing an entire GTFS feed to an LLM and asking questions\nabout the data. One reason we do not take this direction is that most GTFS feeds\nare too large to pass to the popular, public-facing LLMs currently due to context\nlength limitations (Hsieh et al. 2024). Ostensibly, one could use Retrieval Augmented\nGeneration (RAG) (Lewis et al. 2021; Gao et al. 2024) to retrieve the feed in chunks,\nbut an obstacle to this approach is the inter-related nature of GTFS ﬁles (i.e., there\nis no single ﬁle which contains all information about, say, a route). In either case, a\nmore fundamental problem is that many queries require not only looking up data but\nalso manipulating data, doing calculations with data, and connecting different pieces\nof data according to the complex rules of GTFS. While LLMs excel at tasks such as\ntranslation, summarization, and classiﬁcation, they often struggle with tasks that need\nprecise numerical calculations or data manipulation (Ahn et al. 2024). For instance, it\nhas been documented that LLMs make mistakes with simple tasks such as counting\nthe number of r’s in the word ‘strawberry’ or deciding whether ‘9.11’ or ‘9.7’ is a\nlarger number. By contrast, it is straightforward for an LLM to write reliable code that\nsolves those problems.\nThe paper is organized as follows: Sect. 2 presents relevant literature on LLM appli-\ncations in code generation, transportation, and transit. Section 3 describes the approach\nand architecture of TransitGPT. Section 4 evaluates the performance of TransitGPT on\na benchmark dataset of 100 tasks which have been classiﬁed into eight categories. We\nalso compare the performance of TransitGPT with two state-of-the-art (SOTA) LLMs:\nGPT-4o (OpenAI et al. 2024) from OpenAI and Claude-3.5-Sonnet by Anthropic\n(2024). Section 5 concludes with a discussion on the capabilities, limitations, and\nfuture directions of this work.\n123\n322 S. Devunuri, L. Lehe\nHuman:\nWhat is the shortest route in the feed?\nTransitGPT:\nThe shortest route in the feed is RUBY  EVENING with\nal e n g t ho f 1.6km . Here are some additional details:\n/g120Route ID: RUBY  EVENING\n/g120Route Short Name: 110-RUBY  EVENING\n/g120Route Type: 3\n(a) Text Information about the shortest route [CUMTD]\nHuman:\nWhich services and their respective routes are operational today\nTransitGPT:\nservice    id route    id\nB2   MF BLUE , GOLD\nB1   MF GREEN , GREEN , BLUE\n9A    SHOW   HSEO\n... ...\n(b) DataFrame consisting service information [CUMTD]\nHuman:\nShow me a map of stops on Market St\nTransitGPT:\nSure, here is a map of all stops on Market St\n(c) Map of stops on Market St [SFMTA]\nHuman:\nPlot histogram of segment speeds along with kernel density for\nthe route MALCOLM X/MAPLE\nTransitGPT:\n(d) Histogram of segment speeds for a route [DART]\n–\n–\n–\n–EXPRESS\nGREEN–EXPRESS\nFig. 1 Demonstrations of ‘TransitGPT’ in generating responses for GTFS data retrieval tasks. Sample\nvisualizations generated using TransitGPT are available in Appendix A\n1.3 Scope and contribution\nNote the following limitations on the scope of the project:\n(i) The scope is limited to the GTFS Static version of GTFS which conveys infor-\nmation that is planned in advance (e.g., stop locations, routes, schedules, etc.).\nTransitGPT does not draw information from GTFS-Realtime feeds (about delays,\nvehicle locations, etc.).\n(ii) TransitGPT cannot generally answer questions that go beyond the capabilities of\nGTFS Static. For example, GTFS does not say how many seats are on each bus,\nso TransitGPT cannot answer questions about that. Geocoding is an exception;\nTransitGPT can use the Google Maps Geocoding API and the geocoding library\nNominatim (open-source) to answer queries such as “How many stops are within\n30 ms of Fisherman’s Wharf?”\n(iii) Errors or limitations in a GTFS feed (which is prepared by a transit agency) will be\nreﬂected in the answers generated by TransitGPT. Devunuri and Lehe ( 2024b)\nsurvey various errors (deﬁned as deviations from GTFS standards) in GTFS\nStatic feeds across the US and Canada and ﬁnd they are relatively common—\nalthough few of them are substantial. In addition to errors, many GTFS features\nare optional, so TransitGPT cannot answer questions that rely on an optional ﬁle\n(such as fare_rules.txt and transfers.txt) or features (such as the\n123\nTransitGPT: a generative AI-based framework… 323\nFig. 2 TransitGPT interface\nwheelchair_accessible or bikes_allowed ﬁelds in trips.txt) that an agency\nhas declined to include.\n(iv) TransitGPT is not intended for routing questions: e.g., “How do I get from\nChicago Union Station to the Harold Washington Library?” This is simply not a\nspace that TransitGPT meant to “compete” in. Mobile apps, such as Transit, are\nalready optimized for routing: they utilize real-time data and forecasting which\nwe do not access, and they have interfaces that show users when and where to\nwalk (and wait/transfer) as well as choices among different options. TransitGPT’s\ninterface, shown in Fig. 2, is designed for answering questions about systems.\nThe paper’s contributions are intended to go beyond the current version of the Tran-\nsitGPT chatbot itself. Narrowly, the 100-question benchmark is suitable for evaluating\nother approaches to the problem of making transit knowledge more accessible, and\nreaders may think of other embellishments beyond those we describe that would make\na transit chatbot more useful, accurate, or efﬁcient. To this end, the code is open source.\nMore broadly, it is hoped that the architecture and the prompt engineering behind it\ncan inspire other applications of LLMs in the ﬁeld of transportation. Transportation\ntoday is a domain that enjoys an increasing buffet of standardized data sources. As\nan example, the GTFS concept has inspired a General Bikeshare Feed Speciﬁcation\n(GBFS) which is an open data standard designed not only for bike-share but also other\n123\n324 S. Devunuri, L. Lehe\nshared mobility services including scooters, mopeds, and cars (MobilityData 2024a).\nThe architecture of TransitGPT could be altered to answer queries about GBFS data.\n2 Related work\nThis section reviews the relevant literature on Large Language Models (LLMs) in the\ncontext of code generation, transportation applications, and public transit systems.\n2.1 LLMs for code generation\nThe ability of LLMs to generalize and learn from context (in-context learning) has been\neffectively utilized for coding tasks, including code completion\n1 and code generation.\nWhile these tasks are complementary, this paper solely focuses on code generation. In\nthe domain of data-related applications, Text2SQL (Khatry et al. 2023; Zhang et al.\n2024a) has garnered signiﬁcant attention for its ability to perform data extraction and\nanalysis. Text2SQL allows users to query relational databases using natural language,\nwhich is then translated into SQL queries and executed. However, SQL lacks inte-\ngration with existing libraries and does not offer visualization capabilities. Recently,\nresearch has shown that Text2SQL performs poorly on tasks that require semantic or\ncomplex reasoning (Biswal et al. 2024).\nResearchers have explored alternative approaches of using programming languages\nsuch as Python (Haluptzok et al. 2023; Liu et al. 2023a) or Java (Feng and Chen 2024)\nand utilizing libraries written on top of them. Zan et al. ( 2022) demonstrated LLM’s\nability to generate code using popular data processing libraries numpy and pandas\n(using NumpyEval and PandasEval benchmarks) which are present in the corpus of\ntraining data of most LLMs. Furthermore, Patel et al. ( 2024) demonstrated that LLMs\ncan learn and utilize libraries not present in their pre-training data through descriptions\nand raw code examples. This capability signiﬁcantly expands the potential applications\nof LLMs in specialized domains such as transit, allowing the use of domain-speciﬁc\nlibraries and tools. The ability to use libraries has also allowed LLMs to tackle much\nmore complex tasks in related disciplines such as Data Science (Zhang et al. 2024e)\nand Machine Learning (Zhang et al. 2024c).\n2.2 LLMs for transportation\nThe application of LLMs has expanded across various domains, including transporta-\ntion. In the ﬁeld of trafﬁc safety, Zheng et al. ( 2023) investigated the potential of LLMs\nfor automating accident reports and enhancing object detection through augmented\ntrafﬁc data. Similarly, Mumtarin et al. ( 2023) conducted a comparative analysis of\nLLMs in extracting and analyzing crash narratives, further demonstrating their util-\nity in safety-related tasks. LLMs have also shown promise in autonomous vehicle\ntechnology. Research by Zhang et al. ( 2024b) ,C u ie ta l .( 2023) and Fu et al. ( 2023)\n1 Code completion refers to the automatic completion of code segments, which aids in writing code, ﬁxing\nerrors, and providing in-line suggestions.\n123\nTransitGPT: a generative AI-based framework… 325\nexplored the use of LLMs to analyze, interpret, and reason about various driving sce-\nnarios, potentially improving the decision-making capabilities of self-driving systems.\nIn trafﬁc management, LLMs have been applied to several critical tasks. Zhang et al.\n(2024d), Movahedi and Choi ( 2025) and Da et al. ( 2023) investigated the use of LLMs\nfor signal control optimization, while Zhang et al. ( 2024f) explored their application\nin demand forecasting. These studies highlight the versatility of LLMs in address-\ning complex transportation challenges, from infrastructure management to predictive\nanalytics.\n2.3 LLMs for public transit\nApplications of LLMs to public transit have been more limited but have grown in\nthe past year. V oß ( 2023) compares generative AI tools (ChatGPT and Bing) by\naddressing public transport challenges - speciﬁcally bus bunching and bus bridging-\nand evaluates their potential to support sustainable transport research. Devunuri et al.\n(2024b) developed benchmarks to evaluate LLMs’ capabilities (zero-shot\n2 and few-\nshot3) and limitations in understanding GTFS semantics and retrieving information\nfrom GTFS data. The ‘GTFS Semantics’ benchmark tests LLMs on various GTFS\nelements, including terminology, data structures, attribute and category mapping, and\ncommon reasoning tasks. The ‘GTFS Retrieval’ benchmark assesses LLMs’ perfor-\nmance on tasks ranging from simple lookups to complex operations involving sorting,\ngrouping, joining, and ﬁltering information. In related work, Wang and Shalaby ( 2024)\nemployed LLMs for transit information extraction and sentiment analysis from social\nmedia platforms. They also demonstrated that Retrieval Augmented Generation (RAG)\nimproved the performance of LLMs on GTFS Semantics and Retrieval benchmarks.\nSyed et al. ( 2024) developed TransportBench, a comprehensive benchmark compris-\ning questions from transportation planning, economics, networks, geometric design,\nand transit systems. Oliveira et al. ( 2024) developed a methodology to investigate and\nevaluate bus stop infrastructure and its surroundings using street-view images and\nautomated image descriptions from LLMs.\n3 Control ﬂow\nThis section describes how TransitGPT works as a series of steps that control the ﬂow\nof information. Every step in Fig. 3 takes place on a remote server hosted by Streamlit,\nwhich is a company that provides a platform for building and sharing AI-centered web\napps. The steps are executed by Python scripts on the Streamlit server. The control\nﬂow is described in broad strokes rather than in exact detail, but the reader may visit\nthe documentation and code for TransitGPT to see exactly how things are carried out.\n2 Zero-shot refers to the ability of an LLM to generate a response without any examples or training data.\n3 Few-shot refers to the ability of an LLM to generate a response with a few examples or training data.\n123\n326 S. Devunuri, L. Lehe\nFig. 3 Extended TransitGPT architecture\n3.1 Step 0: Pre-Query\nBefore typing in a query (i.e., a question or command), the user selects a GTFS feed\n(e.g., SFMTA) and an LLM (e.g., GPT-4o) from among our ten agencies and four\nLLMs.\nFor each GTFS feed, there is already a “pickled” (a serialized\n4 object saved to\ndisk) Feed object which sits on the remote Streamlit server. A Feed is a Python\nobject whose attributes correspond to the .txt ﬁles in a GTFS feed. For example, if\nfeed is a Feed instance, then feed.routes has data from the ﬁle routes.txt.\nEach .txt ﬁle’s data is stored as a pandas DataFrame whose columns are the ﬁelds in\nthe .txt ﬁle. Hence, feed.routes.route_id yields a list of the strings given in\nthe route_id column of routes.txt. The Feed objects were created using the\nPython library\ngtfs_kit . Appendix B details how the data from the actual\nGTFS feeds are pre-processed.\nA Python program we call the “sandbox” runs constantly on the Streamlit server,\nwaiting for pieces of code to be executed. When the user selects a GTFS feed, the\nsandbox will import the corresponding (pickled) Feed object from disk to create a\nvariable named feed. The sandbox also has imported eight Python libraries 5 which\nhave been downloaded onto the Streamlit server.\n4 Note that it would be possible to load the raw GTFS feed into the sandbox, but the feeds are pre-prepared\nto save time when the user chooses an agency to investigate.\n5 The libraries are gtfs_kit , pandas , numpy , geopandas , geopy ,\npoltly.express , thefuzz ,a n d folium .\n123\nTransitGPT: a generative AI-based framework… 327\nFig. 4 Moderation prompt\n3.2 Step 1: Moderation\nNext, the user types a question or command into the TransitGPT interface: e.g., “Show\nall the stops on Market St.” We immediately send this query along with a document\ncalled the Moderation Prompt (Fig. 4) to GPT-4o-mini (a faster and cheaper version of\nGPT-4o). The Moderation Prompt instructs GPT-4o-mini to judge whether the user’s\nquery is relevant to transit. For example, the user cannot ask “How tall is the Empire\nState Building?” This Moderation Step defends against “prompt injection” attacks\n(Crothers et al. 2023). If necessary, the LLM returns a message that the query is not\nrelevant to transit. Otherwise, we proceed to step 2. The Moderation step typically\ntakes 0.5–1 s.\n3.3 Step 2: Main LLM\nIf the user’s query passes Moderation, then we build a prompt for the Main LLM that\nthe user has selected (e.g., Claude Sonnet 3.5). This prompt contains four pieces of\ninformation:\n(i) The user’s current query: e.g., Find the busiest date in the schedule based on the\nnumber of trips scheduled.\n(ii) The conversation history—consisting of previous questions and replies from the\nsame conversation.\n(iii) Few-shot examples: We curated a list of twelve diverse question-answer pairs\nthat serve as few-shot examples. For each query, we dynamically choose three\n6\nexamples that are most relevant to the current query. This strategy is known as\n6 Alternatively, we could provide the entire list of examples. However, doing so would increase token usage\n(and associated costs) and increase response times. Including all examples can also make answers worse\nbecause the LLM might build its response based on irrelevant examples.\n123\n328 S. Devunuri, L. Lehe\ndynamic few-shot prompting (Brown et al. 2020), and it helps to show (rather than\nmerely tell) the Main LLM speciﬁcally what we want it to do: e.g., how to format\nthe expected output, what supporting information to include, etc. To identify the\nthree ideal query/response pairs that are most similar to the user’s query, we use\nTF-IDF (Term Frequency-Inverse Document Frequency) to compute “similarity\nscores” between each query and example (Aizawa 2003). We then select the\nthree examples with the highest scores and present them in the decreasing order\nof their scores.\n(iv) The Main Prompt : a large text document that guides the Main LLM’s response.\nThe Main Prompt, in turn, consists of ﬁve modules which all steer the LLM’s\nresponse in a certain way. Figure 5 shows excerpts of the modules. First, the\nRole\nmodule sets the context and expected expertise for the model. Xu et al. ( 2023) and\nSalewski et al. ( 2023) show that instructing the LLM to assume a role as an expert\ncan enhance its performance. Next, the Task Instructions module gives\nspeciﬁc instructions for code generation—including which libraries to use, the style of\nwriting/documentation, validation of GTFS data, and strategies for writing optimized\ncode (such as using vectorized operations). The\nData Types module speciﬁes\nthe data type of each ﬁeld in every GTFS ﬁle. Common data types such as ‘Text’,\n‘Integer’, or ‘Float’ have straightforward one-to-one mappings with Python data types\n‘string’, ‘integer’, and ‘ﬂoat’. However, date and time types are more complex due\nto their unique interpretation within GTFS. In GTFS, dates represent ‘service days’\nrather than calendar dates and may extend beyond 24 h (typically from 3 AM to 3\nAM). Agencies may write time in either HH:MM:SS or H:MM:SS format. To address\nthese complexities, we convert dates to Python’s datetime.date format and con-\nvert times to “seconds since midnight.” Similarly,\nData Types instructs the\nLLM on data types such as colors, coordinates, and identiﬁers that are speciﬁc to\nGTFS. Also, we specify the distance units (Meters, Kilometers, etc.) for ﬁelds such as\n‘shape_dist_traveled’. To reinforce the datatypes, a\nFeed Samples module\nprovides a sample feed that displays the ﬁrst ﬁve rows of an example feed.\nFinally, the Custom Functions module explains how to use ﬁve custom\nPython functions we have written that help match users’ natural language queries to\nparticular stops and routes in the GTFS feed. This is important because users rarely\nuse the exact identiﬁers given in GTFS feeds (e.g., one stop’s name is ‘Church St. &\nVictor St. (northwest corner)’) and instead use landmarks (e.g., Pier 39), addresses, or\nintersections written without punctuation or street types (e.g., Broadway and Main).\nMoreover, users are prone to typographical errors, and agencies use different conven-\ntions for naming stops.\n7 These functions include:\n• find_route: Searches for a route by examining route IDs, short names, and\nlong names using fuzzy matching.\n• find_stops_by_full_name: Locates stops by their full name, accommo-\ndating minor spelling variations through fuzzy matching.\n• find_stops_by_street: Identiﬁes stops on a speciﬁc street using the root\nword of the street name (e.g., “Main” for “Main Street”).\n7 For example, the MBTA names many stops according to the opposite street, such as ‘Washington St opp\nRuggles St,’ while the SFMTA names many stops with an exact address such as ‘117 Warren Dr.’\n123\nTransitGPT: a generative AI-based framework… 329\n<Role> You are an expert in General Transit Feed Specification (GTFS) and coding tasks in Python. Your goal\nis to write Python code for the given task related to GTFS </Role>\n<Task Instructions>\nUse Python with numpy (np), pandas (pd), shapely, geopandas (gpd), geopy, folium, plotly.express (px), and mat-\nplotlib.pyplot (plt) libraries. No other libraries should be used.\nAvoid writing code that involves saving, reading, or writing to the disk, including HTML files.\nInclude explanatory comments in the code.\nHandle potential errors and missing data in the GTFS feed.\nBefore main processing, use code to validate GTFS data integrity and consistency by ensuring all required GTFS tables\nare present in the feed, checking for null or NaN values, and verifying referential integrity between related tables (e.g.,\ntrips and stop\nNarrow the search space by filtering for a day of the week, date, and time. Filter by route, service, or trip if provided.\nPrefer using numpy' and pandas' op erations that vectorize computations over Python loops. Avoid using for' loops\nwhenever possible, as vectorized operations are significantly faster.\nNever ever use print statements for output or debugging.\n</Task Instructions>\n<Data Types> (stop  times.txt)\n/g120trip_id : string\n/g120arrival_time : time (seconds since midnight)\n/g120departure_time : time (seconds since midnight)\n/g120stop_id : string\n...\n/g120shape_dist_traveled : float ( DIST  UNITS)\n</Data Types>\n<Feed Samples> (shapes.txt)\nshape id shape lat shape lon shape sequence shape\n30 37.7736 -122.5100 1 0.0000\n30 37.7736 -122.5101 3 0.0032\n30 37.7733 -122.5101 4 0.0238\n30 37.7732 -122.5100 5 0.0285\n30 37.7714 -122.5099 6 0.1527\n</Feed Samples>\n<Custom Functions>\nDescription: Find stops by their full name, allowing for slight misspellings or variations. This function uses\nfuzzy matching to accommodate minor differences in stop names.\nArguments:\nfeed (GTFSFeed): The GTFS feed object containing stop information\nname (str): The full name of the stop to search for\nthreshold (int, optional): The minimum similarity score for a match, default is 80\nReturn: A pandas DataFrame containing matching stops, sorted by match score\nExample:\nInput. find_stops_by_full_name(feed, \"Main Street (SW)\", threshold=85)\nOutput. DataFrame with columns\n[ stop_id , stop_name , stop_lat , stop_lon , match_score ]\n</Custom Functions>\n' ' '\n{\n{\ntimes).–\ntraveledpt pt pt dist\nFig. 5 Excerpts from Main prompt covering various modules. Each module is wrapped in an <XML> tag\n(in Red) to delimit\n• find_stops_by_intersection: Finds stops near the intersection of two\nstreets by providing the root words of both street names.\n• find_stops_by_address: Locates stops near a speciﬁc address by geocod-\ning the address and ﬁnding nearby stops within a speciﬁed radius. Geocoding can\n123\n330 S. Devunuri, L. Lehe\nWhile executing the code, I encountered the following error:\nError Type: . . .\nError Message: . . .\nRelevant Code: . . .\nPlease account for this error and adjust your code accordingly. Remember to follow the task instructions\nand use the provided code snippets and GTFS knowledge to answer the user query. Change the code to fix\nthe error and try again.\nFig. 6 Error prompt template\nbe carried out using the Google Maps geocoding API or, if an API key is not\navailable, the open-source Nominatim Python library.\nDescriptions for these custom functions are passed to the LLMs within the Main\nprompt (see Fig. 5 for example), which the LLMs can use as tools (Schick et al. 2023).\nSimilar to function calling, we describe the purpose of the function, its arguments, and\nexpected output. We also show a brief example of how to use it.\n3.4 Step 3: Code execution\nThe next step is to execute the code snippet (returned in Step 2) in the ‘sandbox’\nPython thread described in Step 0. Due to the instructions written in the Main Prompt,\nthe code should expect there to be a ‘Feed’ object named feed and use any of\nthe eight approved Python libraries. According to the directions given in the Main\nPrompt’s\nTask Instructions module, the code is supposed to return a\nPython dictionary named result which has up to three properties:\n• answer: a string or a list of strings that answers the user’s query.\n• additional_info: a string that provides information that the user may ﬁnd\nuseful as well as assumptions made to arrive at the answer. Suppose, for example,\nthat the user asks “How many bus stops are near Newmark Civil Engineering\nLaboratory?” In this case, the additional_info value may say what radius\nfrom the Laboratory was used to measure “near.”\n• visualization (optional): instructions for building tables, maps, charts, or\ndiagrams using the Python libraries\nplotly and/or folium .T h i sk e y\nonly exists if the user asks for a visualization or if the Main LLM “decides” that\na visualization would be helpful.\n3.5 Step 3(b): Error handling (contingent)\nIf the Main LLM’s code snippet throws an error, we carry out an error han-\ndling/feedback mechanism inspired by the popular ReAct (Yao et al. 2023) framework.\nIn Fig. 7, the code returned from the query “Find the busiest date (date with the largest\nnumber of trips scheduled) in the GTFS feed\" yields a TypeError . When an\nerror occurs, we send the Main LLM (i) the chat history (ii) the original prompt, (iii)\nthe code it just returned, and (iv) the following Error Prompt (see Fig. 6):\n123\nTransitGPT: a generative AI-based framework… 331\nFig. 7 Demonstration of error handling and feedback loop. The query is ‘Find the busiest date (date with\nthe most number of trips scheduled) in the GTFS feed. The code snippet generated by GPT-4o\nNearly always, the Main LLM will correct the error and return executable code. This\nloop continues until the code is executed successfully or until it reaches a predeﬁned\nmaximum number of ‘retries.’ By default, TransitGPT permits three retries.\n3.6 Step 4: Summary\nThe result of the code execution in Step 3 is not in a useful format for humans to read.\nIn the last step, we pass four pieces of information to a Summary LLM (GPT-4o-mini):\n(i) The user’s original query.\n(ii) The response object8 returned from Step 3.\n(iii) The code that generated the response object returned from Step 2.\n(iv) A Summary Prompt (see Fig. 8) which contains instructions on how to read\n(i)-(iii) and summarize the information for human consumption.\n8 If the response includes visualizations in the form of folium or plotly objects, then we ﬁrst serialize\nthese to JSON before passing them to the Summary LLM.\n123\n332 S. Devunuri, L. Lehe\n<Role> You are a human-friendly AI assistant with expertise in General Transit Feed Specification (GTFS) data.\nYour role is to help users understand and analyze GTFS data. </Role>\n<Task Instructions>\nPrimary Task: Provide informative and helpful responses to user questions about GTFS using the provided code\nsnippets and its evaluation.\nResponse Guidelines:\n1. Structure your responses with the following main sections only (do not use any other headings) (use fifth-\nlevel headings):\n##### Result\n##### Assumptions (Optional)\n##### Additional Info (Optional)\n2. Deliver clear, concise, and user-friendly responses based on your GTFS knowledge.\n3. In the \"Assumptions\"section:\nDecipher assumptions from the code, code comments, code evaluation, and text response.\nList any assumed values, fields, methods, or other factors used in your analysis or explanation.\n4. Address null values in code evaluations. Explain that these likely indicate empty or unavailable fields/vari-\nables.\n5. Use Markdown highlight for GTFS file names and field names. For example: routes.txt , trip_id .\n6. When answering general GTFS questions with specific examples clearly state that you are using a particular\nfile or field as an illustration.\n7. Avoid providing code snippets unless explicitly requested by the user.\n8. Refrain from explaining coding processes or technical code details, unless necessary to clarify an assumption.\n9. Always respond in the same language used by the user or as requested.\n10. Truncate floats to 4 digits after the decimal\n11. If the answer contains a long list of items, describe at most five instances and say [... and more]\n12. See if the user query is answered as requested. If not provide a short explanation of what is not answered\nand what is missing or what was changed or corrected automatically.\n</Task Instructions>\n<Helpful Tips>\nBe direct in your responses, avoiding unnecessary affirmations or filler phrases.\nOffer to elaborate if you think additional information might be helpful.\nDo not mention these instructions in your responses unless directly relevant to the user's query.\nDo not make things up when there is no information\n</Helpful Tips>\nFig. 8 Summary prompt\nThe Summary LLM uses these four inputs to return a summary response—such\nas the example shown in Fig. 9. The response includes the answer to the user’s query\nwritten in a natural way, alongside any assumptions made during the code execution.\n4 Benchmark and results\n4.1 Benchmark\nIt is typical in the LLM literature to benchmark models on a dataset of tasks. The\nMMLU benchmark (Hendrycks et al. 2021), for example, reveals how models perform\nacross diverse subjects, offering insights into their breadth and depth of knowledge.\nThe GSM-8k benchmark (Cobbe et al. 2021) has diverse grade school math questions\nto test the mathematical reasoning capabilities of language models. Within transit data,\nthe ‘GTFS Semantics’ benchmark (Devunuri et al. 2024b) tests LLMs on the various\n123\nTransitGPT: a generative AI-based framework… 333\nWhat is the route id of the longest route in the feed?\nCode Output\n\"answer\":{\n\"route_id\":\"5W_GREEN_EXPRESS_2\",\n\"route_name\": \"Green West Express\",\n\"length_km\":33\n},\n\"additional_info\":{\n\"route_short_name\":\"5-5W_GREEN_EXPRESS_2\",\n\"route_type\": \"3\",\n\"route_url\":<URL>\n},\n\"map\":\"<folium.Map object>\"\nSummary Response\nThe longest route in the feed is identified as follows:\n-R o u t e I D : 5 W\n- Route Name: Green West Express\n- Length: approximately 33.0 km\nAdditional details about the route include:\n- Route Short Name: 5-5W\n- Route Type: 3 (which typically indicates a bus route in\nGTFS)\n- Route URL: View Route Schedule\nGREEN EXPRESS 2\nGREEN EXPRESS 2\nFig. 9 Example of code output and summary response\naspects of the GTFS speciﬁcation. This section describes a benchmark dataset and how\nTransitGPT performs on it using different conﬁgurations. While designed speciﬁcally\nto test TransitGPT, the benchmark could also be used to identify other approaches to\nthe problem of generating code that carries out GTFS queries.\nThe benchmark consists of 100 ‘tasks,’ indexed by i . Figure 10 shows an example\ntask. Each task i is a tuple {Q\ni , Fi , Xi , Yi , Oi }, deﬁned as follows:\n• Query (Qi ): Describes the task in natural language.\n• Feed (Fi ): A certain GTFS feed.\n• Input (Xi ): Input variables or GTFS ﬁelds.\n• Code (Yi ): Python code that provides the solution for this task.\n• Output (Oi ): The intended output of the code snippet.\nThe benchmark was created in the following way. First, we manually write Qi (the\nquery), which determines the topic and subject matter of the task. We designed queries\nto cover diverse sets of tasks—from basic data retrieval to more complex queries\nthat may require, for instance, distance calculations or geocoding. Table 1 shows the\ndifferent categories of tasks in the benchmark, alongside sample task descriptions,\nand how many tasks fall under each category. The 100 tasks are organized into eight\ncategories, with 20 tasks that require generating visualizations. Some characteristics\nof the benchmark are detailed in Appendix C including (i) wheel diagram that plots the\nroot verbs and direct nouns objects used within the task queries (ii) table containing\nthe GTFS ﬁles utilized across different tasks along with their counts.\nEach task is tested on a certain GTFS feed F\ni , chosen from among ﬁve feeds that we\ndownloaded from the Mobility Database (MobilityData 2024b): San Francisco Munic-\n123\n334 S. Devunuri, L. Lehe\nQuery ( Qi): Identify the number of stops located at /g94location/g96\nFeed ( Fi): CUMTD\nInput ( Xi): location = Illinois Terminal\nCode Response (Yi):\n# Find stops at Illinois Terminal\nillinois_terminal_stops = find_stops_by_full_name(feed, \"Illinois Terminal\" , threshold= 80)\nif illinois_terminal_stops.empty:\nillinois_terminal_stops = find_stops_by_address(\nfeed,\n\"Illinois Terminal, Champaign, IL, USA\" ,\nradius_meters=200,\nnum_stops=5\n)\nif not illinois_terminal_stops.empty:\n# Prepare the result\nresult = {\nanswer :f \"Found {len(illinois_terminal_stops)} stops\" ,\nadditional_info : illinois_terminal_stops [\n[ stop_id , stop_name ]\n].to_dict( records )\n}\nelse:\nresult = {\nanswer : \"No stops found at Illinois Terminal\" ,\nadditional_info : \"\",\n}\nOutput (Oi):\n{\"answer\":\"Found 3 stops at Illinois Terminal\" ,\n\"additional_info\":[\n{\"stop_id\":\"IT:1\",\"stop_name\":\"Illinois Terminal (Platform A)\" },\n{\"stop_id\":\"IT:2\",\"stop_name\":\"Illinois Terminal (Platform B)\" },\n{\"stop_id\":\"IT:5\",\"stop_name\":\"Illinois Terminal (Platform C)\" }\n]}\nFig. 10 Example task and its components\nipal Transportation Agency (SFMTA, 20 tasks), Massachusetts Bay Transportation\nAuthority (MBTA, 13 tasks), Champaign-Urbana Mass Transit District (CUMTD, 23\ntasks), Dallas Area Rapid Transit (DART, 32 tasks), and Chicago Transit Authority\n(CTA, 12 tasks). These agencies were selected to ensure diversity in the inputs, as\ntheir feeds differ signiﬁcantly in terms of ﬁle size (3–89 MB), features, optional ﬁles,\noptional ﬁelds, and naming conventions. For instance, CUMTD has bus routes named\nafter colors such as ‘Orange’, ‘Teal’, ‘Green’, etc., and unique identiﬁer formats with\nspaces and special symbols such as ‘@’, ‘_’, ‘[ ]’, etc. The CTA is one of the largest US\nfeeds. The DART and SFMTA feeds include several optional ﬁelds and non-standard\nﬁles: as examples, SFMTA has timepoints.txt (to specify timepoints), while DART has\nroute_direction.txt (to specify the directions for routes North, South, East, and West).\nEach query Q\ni is written in a template format with placeholders for the input Xi .\nConsider the queries:\n(a) Qa : Find all routes in the GTFS feed that are longer than {threshold}.\n(b) Qb: When is the last bus leaving from {stop_name} on a typical Monday?\nHere, the inputs are threshold and stop_name. For queries such as Qa ,f o rw h i c h\nthe agency is irrelevant, we simply choose a value: e.g., 3 km. For queries such as Qb,\n123\nTransitGPT: a generative AI-based framework… 335\nTable 1 Categories, sample task descriptions, and counts of all tasks within the benchmark dataset\nCategory Sample task descriptions Count\nAccessibility Check if bikes are allowed on speciﬁc routes or trips 10\nAnalyze stop spacing of routes or network\nAssess wheelchair accessibility of routes and stops\nIdentify and map transfer points between different types\nof transit\nBasic Data Operations Simple lookups within single or multiple ﬁles 10\nFilter the feed by ﬁelds\nDetermine the date range covered by the GTFS feed\nCount the number of different route types\nPlot the distribution of GTFS ﬁelds\nFares Determine the cost of a single ride or average fare 8\nIdentify routes with the highest/lowest fares\nCalculate total fare revenue for speciﬁc routes\nCompare fare structures across different services\nNavigation and Routing Locate speciﬁc stops (e.g., at intersections, near\nlandmarks)\n13\nMeasure distances between stops along a route\nProvide directions from one stop to another\nDetermine the last bus from a speciﬁc stop\nPerformance Compute metrics such as speed, frequency, and headway 14\nInvestigate dwell-time delays\nStudy variations in travel time\nApproximate the number of vehicles used on a typical\nday\nRoutes Identify the busiest routes 22\nDetermine the longest/shortest route\nDiscover routes with the most variations in shapes\nFind express, circular, or routes that operate 24/7\nDraw the routes intersecting with a speciﬁc route on a\nmap\nStops Locate transfer or intersecting points between routes 9\nMap the busiest stops or the stops with speciﬁc criteria\nAnalyze stop spacing patterns\nFind stops with speciﬁc amenities\nTime Create GANTT charts to visualize trip schedules 14\nAnalyze temporal patterns of service frequency\nIdentify peak and off-peak service periods\nCalculate trip counts by time window\nFind the busiest day, date, or week within the feed\n123\n336 S. Devunuri, L. Lehe\nwe choose a value that is relevant to the feed Fi : e.g., ‘Illinois and Lakeshore’ for\nCTA.\nWe generate the code ( Yi ) for each query in a semi-automated fashion. Using Qi\nand Xi , we request an LLM to output a draft of Yi . We manually correct the answer\nif necessary to create the ﬁnal Yi . Then we execute Yi , with our selected Xi and Fi\nsubstituted, on a local Python interpreter in order to obtain the ideal output Oi .\n4.2 Results\nWe use the task queries along with inputs from the benchmark generated to evaluate\nLLMs, speciﬁcally GPT-4o and Claude-3.5-Sonnet which our experience has shown\nto be the most capable LLMs. During the evaluation, we control four hyperparameters:\n• temperature: Controls how deterministic the LLM output is. For code genera-\ntion tasks, lower temperature values (e.g., 0.2-0.5) are typically preferred to ensure\nmore deterministic and focused responses. However, we observed that using val-\nues at the lower end of this range can impair the LLM’s ability to self-correct when\nit makes mistakes. Consequently, we initially set the temperature to 0.3 for cod-\ning (i.e., Main LLM) but increased it to 0.5 for retries to prevent the model from\nrepeating the same errors. For ‘Moderation’ and ‘Summary’ LLMs that perform\nmore creative tasks than code generation, we use a temperature of 0.7.\n• max_tokens: Limits the maximum number of tokens allowed for generation\nby the LLM. We set the “max tokens\" parameter to the maximum possible output\ntokens the LLM supports for Main and Summary LLMs. For GPT-4o, this is 16,384\ntokens and for Claude-3.5-Sonnet, it is 8,192 tokens. For the Moderation LLM,\nwe set the max tokens to ‘5’.\n• timeout: Implements time limit for code execution (step 3). We set the timeout\nto three minutes for all tasks.\n• max_retries: Limits the number of retries allowed for code execution (step 3).\nWhen enabled, we set the number of retries to three.\nWe evaluate the performance of both LLMs in two different conﬁgurations. As a\nbaseline, we use TransitGPT with zero-shot code generation (i.e. no examples) and\nno (zero) retries. We compare the baseline against a ‘TransitGPT+’ conﬁguration,\nwhich includes dynamic few-shot examples (described in Sect. 2) along with the\nError Handling and Feedback- step 3(b). We evaluate the conﬁgurations using three\nperformance metrics. They are:\n• α: The task accuracy rate. All grading is conducted manually for two reasons:\n(i) LLMs vary in their response structure and how they distribute information\nbetween the ‘answer’ and ‘additional_info’ portions of the output, and (ii) tasks\ninvolving visualizations require visual inspection. Each response is scored in a\nbinary fashion: 1 for correct and 0 for incorrect.\n• T : The total number of tokens used per task, which include input (both system and\nuser prompts) and output tokens.\n• /Delta1t : The time taken to complete each task, including the time taken to generate the\ncode ( /Delta1t\ng ) and the time taken to execute the code ( /Delta1te).\n123\nTransitGPT: a generative AI-based framework… 337\nTable 2 shows the performance metrics across different task categories and con-\nﬁgurations. Within each category, the metrics are averaged over all tasks within it. 9\nWe notice that the ‘TransitGPT+’ conﬁguration outperforms the baseline in all cate-\ngories except for both LLMs. The improvement in performance is more pronounced\nfor GPT-4o (74 → 90) than Claude-3.5-Sonnet (84 → 93). Within the same conﬁgu-\nration, Claude-3.5-Sonnet performs better than GPT-4o in almost all categories. The\nbaseline consumes fewer tokens ( T ) overall as it does not include the ‘Error Handling\nand Feedback’ and ‘Dynamic Few Shot’ modules but it is less accurate. Interest-\ningly, the usage of more tokens does not necessarily lead to higher /Delta1t . For GPT-4o,\nthe ‘TransitGPT+’ conﬁguration consumes more tokens but has a lower /Delta1t than the\nbaseline (20.7 s → 17.2 s) as the few-shot examples help the model to generate more\nefﬁcient code that uses vectorized operations. In contrast, Claude-3.5-Sonnet shows\nan increase in /Delta1t from 12.5 to 18.5 s when moving from baseline to TransitGPT+,\nsuggesting that the additional token consumption does impact its overall processing\ntime despite the improved accuracy.\n5 Conclusion\nIn this study, we introduce TransitGPT, a framework that enables Large Language\nModels (LLMs) to interact with GTFS feeds and extract transit information. We\ndemonstrate that the framework can perform a wide variety of GTFS retrieval tasks\nthrough text instructions alone, enabling users with limited knowledge of coding and\nGTFS speciﬁcations to access transit data. The framework’s ﬂexibility allows it to\nleverage existing Python libraries for data extraction, analysis, and visualization. Addi-\ntionally, the generated code not only serves as a foundation for further analysis but\nalso includes helpful comments that facilitate learning and understanding of the code.\nTransitGPT thus demonstrates the potential for AI to democratize public transit data\nand analysis, empowering transit enthusiasts, professionals, practitioners, and plan-\nners. It provides a medium to interact with large datasets bypassing the context-length\nand lost-in-the-middle (Liu et al. 2023b) limitations of LLMs.\nMany possibilities and extensions remain for future work. The parts of TransitGPT\nthat are most speciﬁc to GTFS Static are in the Main Prompt and helper functions. By\nmodifying the Main prompt and the helper functions, the architecture behind Transit-\nGPT could be adapted to other static speciﬁcations such as General Bikeshare Feed\nSpeciﬁcation (GBFS), Transit ITS Data Exchange Speciﬁcation (TIDES) or Transit\nOperational Data Standard (TODS). These adaptations would allow for queries about\nother modes (such as bikes and scooters) as well as insights on vehicle operations,\npassenger loads, and fare revenues. Future work could also enrich TransitGPT with\nthe ability to communicate with GTFS-Realtime feeds, which provide realtime infor-\nmation on vehicle locations, delays, crowding, etc. Doing so would require changing\nthe Main Prompt to tell the LLM about the GTFS-Realtime speciﬁcation, but in addi-\ntion the executed code would have to somehow communicate with remote servers.\n9 Note that we use a timeout of 3 min for code execution. If a certain code times out, we assign a score of\n0 to the task but exclude it from average token calculations.\n123\n338 S. Devunuri, L. Lehe\nTable 2 Performance evaluation results of the TransitGPT Framework across different task categories, showing success rates ( α) and token usage ( T ) under baseline and\nTransitGPT+ conﬁgurations\nCategory N GPT-4o Claude-3.5-Sonnet\nBaseline TransitGPT+ Baseline TransitGPT+\nα [N] T α [N] T α [N] T α [N] T\nAccessibility analysis 9 0.67 [6] 8782 0.89 [8] 10 ,434 0.67 [6] 10 ,140 0.89 [8] 11,339\nBasic data operations 10 0.70 [7] 7804 0.90 [9] 10 ,315 0.80 [8] 8988 0.80 [8] 10,260\nFare analysis 8 0.75 [6] 10 ,570 0.75 [6] 12 ,607 0.88 [7] 12 ,259 0.88 [7] 12,887\nNavigation and routing 13 0.92 [12] 7644 0.92 [12] 9528 0.92 [12] 8813 1.00 [13] 10,246\nPerformance metrics 15 0.73 [11] 8402 0.93 [14] 9480 0.93 [14] 9678 0.87 [13] 11,727\nRoute analysis 22 0.73 [16] 7778 0.91 [20] 10 ,278 0.91 [20] 8899 1.00 [22] 10,503\nStop analysis 9 0.89 [8] 8368 1.00 [9] 9527 0.78 [7] 9627 0.89 [8] 11,075\nTemporal analysis 14 0.57 [8] 8131 0.86 [12] 10 ,324 0.71 [10] 9402 1.00 [14] 11,444\nSummary 100 0.74 [74] 8261 0.90 [90] 10 ,158 0.84 [84] 9514 0.93 [93] 11,059\nBold values indicate the best performance for the metric of interest. N represents the number of tasks in each category\n123\nTransitGPT: a generative AI-based framework… 339\nThis could be aided by building additional helper functions that make API requests to\nGTFS-Realtime endpoints. If TransitGPT were connected to GTFS-Realtime, a user\ncould ask questions such as “How many buses are in operation on the Red Line right\nnow?” or “Where is the nearest bus?” or “How many people are on the bus right now?”\nSome limitations of this architecture are as follows. Firstly, although users can\nretrieve information without explicit GTFS knowledge, it is helpful if the user under-\nstands some capabilities and constraints of GTFS. Next, LLMs have a knowledge\ncutoff and may not be up-to-date with the latest speciﬁcations, and may, therefore,\nhallucinate. Currently, we test TransitGPT across eight different categories of tasks.\nFuture work could develop more diverse tasks for the benchmark—perhaps based on\nfeedback from TransitGPT users. Finally, TransitGPT is not able to ask for points-of-\nclariﬁcation from the user. In the future, it could be enhanced with human-in-the-loop\ndecision making rather than having to rely so heavily on assumptions.\nAppendix A Sample visualizations\nSee Fig. 11.\nNight Morning Peak Midday Evening Peak\n0\n5\n10\n15\n20\n25\nHeadways by Time Period for Ashland Route (Direction 0)\nTime Period\nHeadway (minutes)\n(a) Create a boxplot of headways by the time period of the day for\nthe Ashland route.[CTA]\n07:30\nOct 16, 2024\n08:00 08:30 09:00\n8.15459M\n8.154585M\n8.15458M\n8.154575M\nMcKinney Avenue Trolley Trips (6-9 AM, Direction 1)\nTrip ID\n(b) Create a GANTT chart for the McKinney Avenue trolley with\ntrips from 6-9 AM in direction ‘1’.[ D A R T ]\n02 0 4 0 6 0 8 0\n0\n5k\n10k\n15k\n20k\nRoute Type\n3\n5\n0\n2\nTrip Duration vs. Distance for Each Route\nAverage Trip Duration (minutes)\nTotal Distance (kilometers)\n(c) Create a bubble chart with average trip duration as x, total\ndistance of route as y, with bubble size representing trip count,\nand color for route type/direction. [DART]\n(d) Map all routes that intersect with the SUNSET route at least\nonce. [SFMTA]\nFig. 11 Sample visualizations generated using TransitGPT with Claude-3.5-Sonnet\n123\n340 S. Devunuri, L. Lehe\nAppendix B GTFS feed preprocessing\n• First, we convert the raw GTFS feeds into Feed objects (Python class object)\nusing the gtfs_kit library. Within a Feed object, ﬁles are attributes that\nare of DataFrame format. The ﬁelds are columns within the DataFrame.\n• Next, we process this Feed object as follows:\n– We remove all empty ﬁles and ﬁelds in the feed. Text ﬁelds have leading/trailing\nwhitespace stripped out. Date and time ﬁelds are parsed and converted to\ndatetime objects and ‘seconds since midnight,’ respectively.\n– We eliminate dummy entries (e.g., stops, trips, routes, shapes) that are not\nreferenced elsewhere in the feed.\n– Since the shape_dist_traveled ﬁeld is optional within the GTFS speciﬁca-\ntion, it may be absent in shapes.txt or stop_times.txt.I fs o ,w e\nmanually compute shape_dist_traveled for these ﬁles. This pre-computation\nsigniﬁcantly reduces the time required for subsequent distance-based queries\nand analyses.\n–T h e Feed object, by default, has attributes for ﬁles that may not be present\nin the actual GTFS feed. This allows for the LLM to check if a certain ﬁle is\npresent using the feed using hasattr(feed,‘fare_attributes’).\n• Finally, we compress and serialize the reﬁned Feed object into a pickle ﬁle, 10\nwhich can be read into memory quickly.\nAppendix C Benchmark characteristics\nSee Fig. 12 and Table 3.\n10 Pickle ﬁles are a way to serialize and compress data in Python. They are a popular format for storing\nand sharing data in Python applications.\n123\nTransitGPT: a generative AI-based framework… 341\nanalyze fare\ncalculate service days\nspeed\nheadway\ncount\nfare products\nstop pairs\ncreate\nchart\nspacing\ntripfrequency\nhistogramspider plot\nplot\nscatter plot\ndetermine\nroutedistanceduration\ndisplay\nservices\nestimate\nbuses\nextract\nroute\nfind\nroute\nbus\ndate\nroutes\nstops\nshape\nroute_id\nhours\nget\ntime\nidentify\nstop\nfaretrips\nbus stoptransferroute type\ntimezonehour\nlist\nro\nute\nlines\nlocate\nstops\nmake\npie chart\nmap\nstops\nbus stops\nshapes\nplot\ntrips\nretrieve\nagency\nshow trip\nFig. 12 Wheel diagram of task queries in the benchmark dataset, showing the relationships between nouns\n(GTFS entities or subjects) and verbs (operations) used in formulating the tasks\nTable 3 Counts of GTFS ﬁles\nutilized across different tasks GTFS File Count GTFS File Count\ntrips.txt 71 shapes.txt 7\nroutes.txt 59 calendar_dates.txt 6\nstop_times.txt 56 fare_products.txt 6\nstops.txt 32 agency.txt 4\ncalendar.txt 25 fare_leg_rules.txt 4\nfeed_info.txt 2 fare_attributes.txt 2\nfare_media.txt 1 fare_rules.txt 1\nAcknowledgements The authors are thankful to Aleksey Smolenchuk for feedback and suggestions on\nprompt design and MobilityData for their feedback.\n123\n342 S. Devunuri, L. Lehe\nAuthor contributions Conceptualization: Saipraneeth Devunuri, Lewis Lehe; Visualization: Saipraneeth\nDevunuri; Data curation: Saipraneeth Devunuri; Formal analysis: Saipraneeth Devunuri, Lewis Lehe;\nMethodology: Saipraneeth Devunuri, Lewis Lehe; Supervision: Lewis Lehe; Writing-original draft: Saipra-\nneeth Devunuri, Lewis Lehe; Writing-review and editing: Saipraneeth Devunuri, Lewis Lehe.\nFunding This work received assistance from US National Science Foundation Award CMMI 2339943.\nData availability The code is open-source and available on our GitHub repository: https://github.com/\nUTEL-UIUC/TransitGPT. The GitHub repository has a Docker ﬁle to ease deployment.\nDeclarations\nConﬂict of interest The authors have no conﬂicts of interest to declare that are relevant to the content of\nthis article.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence,\nand indicate if changes were made. The images or other third party material in this article are included\nin the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If\nmaterial is not included in the article’s Creative Commons licence and your intended use is not permitted\nby statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the\ncopyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/ .\nReferences\nAhn J, V erma R, Lou R, Liu D, Zhang R, Yin W (2024) Large language models for mathematical reasoning:\nprogresses and challenges. arXiv:2402.00157\nAizawa A (2003) An information-theoretic perspective of tf–idf measures. Inform Process Manag 39:45–65.\nhttps://doi.org/10.1016/S0306-4573(02)00021-3\nAnthropic (2024) Model card addendum: Claude 3.5 Haiku and upgraded Claude 3.5 Sonnet. https://assets.\nanthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf\nBiswal A, Patel L, Jha S, Kamsetty A, Liu S, Gonzalez JE, Guestrin C, Zaharia M (2024) Text2SQL is not\nenough: unifying AI and databases with TAG. arXiv:2408.14717\nBrown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P , Neelakantan A, Shyam P , Sastry G, Askell\nA, Agarwal S, Herbert-V oss A, Krueger G, Henighan T, Child R, Ramesh A, Ziegler DM, Wu J, Winter\nC, Hesse C, Chen M, Sigler E, Litwin M, Gray S, Chess B, Clark J, Berner C, McCandlish S, Radford\nA, Sutskever I, Amodei D (2020) Language models are few-shot learners. https://doi.org/10.48550/\narXiv.2005.14165\nCobbe K, Kosaraju V , Bavarian M, Chen M, Jun H, Kaiser L, Plappert M, Tworek J, Hilton J, Nakano R,\nHesse C, Schulman J (2021) Training veriﬁers to solve math word problems. Arxiv. https://doi.org/\n10.48550/arXiv.2110.14168\nCrothers E, Japkowicz N, Viktor H (2023) Machine generated text: a comprehensive survey of threat models\nand detection methods. Arxiv. https://doi.org/10.48550/arXiv.2210.07321\nCui C, Ma Y , Cao X, Ye W, Wang Z (2023) Receive, reason, and react: drive as you say with large language\nmodels in autonomous vehicles. Arxiv. https://doi.org/10.48550/arXiv.2310.08034\nDa L, Gao M, Mei H, Wei H (2023) LLM powered sim-to-real transfer for trafﬁc signal control. Arxiv.\nhttps://doi.org/10.48550/arXiv.2308.14284\nDevunuri S, Lehe L (2024a) GTFS segments: a fast and efﬁcient library to generate bus stop spacings. J\nOpen Source Softw 9:6306. https://doi.org/10.21105/joss.06306\nDevunuri S, Lehe L (2024b) A survey of errors in GTFS static feeds from the United States. Findings 1:1.\nhttps://doi.org/10.32866/001c.116694\nDevunuri S, Lehe LJ, Qiam S, Pandey A, Monzer D (2024a) Bus stop spacing statistics: theory and evidence.\nJ Public Transp 26:100083. https://doi.org/10.1016/j.jpubtr.2024.100083\n123\nTransitGPT: a generative AI-based framework… 343\nDevunuri S, Qiam S, Lehe LJ (2024b) ChatGPT for GTFS: benchmarking LLMs on GTFS semantics and\nretrieval. Public Transp 16:333–357. https://doi.org/10.1007/s12469-024-00354-x\nFayyaz K, Liu XC, Zhang G (2017) An efﬁcient general transit feed speciﬁcation (GTFS) enabled algorithm\nfor dynamic transit accessibility analysis. PLoS ONE 12:e0185333. https://doi.org/10.1371/journal.\npone.0185333\nFeng S, Chen C (2024) Prompting is all you need: automated android bug replay with large language models.\nhttps://doi.org/10.48550/arXiv.2306.01987\nFortin P , Morency C, Trépanier M (2016) Innovative GTFS data application for transit network analysis\nusing a graph-oriented method. J Public Transp 19(4):18–37. https://doi.org/10.5038/2375-0901.19.\n4.2\nFu D, Li X, Wen L, Dou M, Cai P , Shi B, Qiao Y (2023) Drive like a human: rethinking autonomous driving\nwith large language models. Arxiv. https://doi.org/10.48550/arXiv.2307.07162\nGao Y , Xiong Y , Gao X, Jia K, Pan J, Bi Y , Dai Y , Sun J, Wang M, Wang H (2024) Retrieval-augmented\ngeneration for large language models: a survey. Arxiv. https://doi.org/10.48550/arXiv.2312.10997\nHaluptzok P , Bowers M, Kalai A T (2023) Language models can teach themselves to program better.\narXiv:2207.14502\nHendrycks D, Burns C, Basart S, Zou A, Mazeika M, Song D, Steinhardt J (2021) Measuring massive\nmultitask language understanding. Arxiv. https://doi.org/10.48550/arXiv.2009.03300\nHsieh CP , Sun S, Kriman S, Acharya S, Rekesh D, Jia F, Zhang Y , Ginsburg B (2024) RULER: What’s the\nreal context size of your long-context language models? https://doi.org/10.48550/arXiv.2404.06654\nKhatry A, Cahoon J, Henkel J, Deep S, Emani V , Floratou A, Gulwani S, Le V , Raza M, Shi S, Singh M,\nTiwari A (2023) From words to code: harnessing data for program synthesis from natural language.\nhttps://doi.org/10.48550/arXiv.2305.01598\nKunama N, Worapan M, Phithakkitnukoon S, Demissie M (2017) GTFS-Viz: tool for preprocessing and\nvisualizing GTFS data. In: Proceedings of the 2017 ACM international joint conference on pervasive\nand ubiquitous computing and proceedings of the 2017 ACM international symposium on wearable\ncomputers. ACM, Maui Hawaii, pp 388–396. https://doi.org/10.1145/3123024.3124415\nLewis P , Perez E, Piktus A, Petroni F, Karpukhin V , Goyal N, Küttler H, Lewis M, Yih W, Rocktäschel T,\nRiedel S, Kiela D (2021) Retrieval-augmented generation for knowledge-intensive NLP tasks. Arxiv.\nhttps://doi.org/10.48550/arXiv.2005.11401\nLiu J, Xia CS, Wang Y , Zhang L (2023a) Is your code generated by ChatGPT really correct? Rigorous\nevaluation of large language models for code generation. arXiv:2305.01210\nLiu NF, Lin K, Hewitt J, Paranjape A, Bevilacqua M, Petroni F, Liang P (2023b) Lost in the middle: how\nlanguage models use long contexts. Arxiv. https://doi.org/10.48550/arXiv.2307.03172\nLiu D, Guo J, Gu Y , King M, Han LD, Brakewood C (2024) GTFS2STN: analyzing GTFS transit data by\ngenerating spatiotemporal transit network. arXiv:2405.02760\nMcHugh B (2013) Pioneering open data standards: the GTFS story. In: Beyond transparency: open data\nand the future of civic innovation. Code for America Press San Francisco, pp 125–135. https://\nbeyondtransparency.org/part-2/pioneering-open-data-standards-the-gtfs-story/\nMobilityData (2024a) General bikeshare feed speciﬁcation. https://gbfs.org/\nMobilityData (2024b) General transit feed speciﬁcation. https://gtfs.org/\nMovahedi M, Choi J (2025) The crossroads of LLM and trafﬁc control: a study on large language models\nin adaptive trafﬁc signal control. IEEE Trans Intell Transp Syst 26(2):1701–1716. https://doi.org/10.\n1109/TITS.2024.3498735\nMumtarin M, Chowdhury MS, Wood J (2023) Large language models in analyzing crash narratives—a\ncomparative study of ChatGPT. BARD and GPT-4. Arxiv. https://doi.org/10.48550/arXiv.2308.13563\nOliveira A, Espadoto M, Hirata R Jr, Damaceno R, Cesar R (2024) Towards a method for evaluating bus\nstop infrastructure with street level images and large language models. In Proceedings URBANAC-\nCESS’24. https://repositorio.usp.br/item/003227119\nOpenAI Achiam J, Adler S, Agarwal S, Ahmad L, Akkaya I, Aleman FL, Almeida D, Altenschmidt J,\nAltman S, Anadkat S, Avila R, Babuschkin I, Balaji S, Balcom V , Baltescu P , Bao H, Bavarian\nM, Belgum J, Bello I, Berdine J, Bernadett-Shapiro G, Berner C, Bogdonoff L, Boiko O, Boyd M,\nBrakman AL, Brockman G, Brooks T, Brundage M, Button K, Cai T, Campbell R, Cann A, Carey\nB, Carlson C, Carmichael R, Chan B, Chang C, Chantzis F, Chen D, Chen S, Chen R, Chen J, Chen\nM, Chess B, Cho C, Chu C, Chung HW, Cummings D, Currier J, Dai Y , Decareaux C, Degry T,\nDeutsch N, Deville D, Dhar A, Dohan D, Dowling S, Dunning S, Ecoffet A, Eleti A, Eloundou T,\nFarhi D, Fedus L, Felix N, Fishman SP , Forte J, Fulford I, Gao L, Georges E, Gibson C, Goel V ,\n123\n344 S. Devunuri, L. Lehe\nGogineni T, Goh G, Gontijo-Lopes R, Gordon J, Grafstein M, Gray S, Greene R, Gross J, Gu SS, Guo\nY , Hallacy C, Han J, Harris J, He Y , Heaton M, Heidecke J, Hesse C, Hickey A, Hickey W, Hoeschele\nP , Houghton B, Hsu K, Hu S, Hu X, Huizinga J, Jain S, Jain S, Jang J, Jiang A, Jiang R, Jin H, Jin\nD, Jomoto S, Jonn B, Jun H, Kaftan T, Kaiser Ł, Kamali A, Kanitscheider I, Keskar NS, Khan T,\nKilpatrick L, Kim JW, Kim C, Kim Y , Kirchner JH, Kiros J, Knight M, Kokotajlo D, Kondraciuk Ł,\nKondrich A, Konstantinidis A, Kosic K, Krueger G, Kuo V , Lampe M, Lan I, Lee T, Leike J, Leung\nJ, Levy D, Li CM, Lim R, Lin M, Lin S, Litwin M, Lopez T, Lowe R, Lue P , Makanju A, Malfacini\nK, Manning S, Markov T, Markovski Y , Martin B, Mayer K, Mayne A, McGrew B, McKinney SM,\nMcLeavey C, McMillan P , McNeil J, Medina D, Mehta A, Menick J, Metz L, Mishchenko A, Mishkin\nP , Monaco V , Morikawa E, Mossing D, Mu T, Murati M, Murk O, Mély D, Nair A, Nakano R, Nayak\nR, Neelakantan A, Ngo R, Noh H, Ouyang L, O’Keefe C, Pachocki J, Paino A, Palermo J, Pantuliano\nA, Parascandolo G, Parish J, Parparita E, Passos A, Pavlov M, Peng A, Perelman A, Peres FdAB,\nPetrov M, Pinto HPdO, Michael Pokorny Pokrass M, Pong VH, Powell T, Power A, Power B, Proehl\nE, Puri R, Radford A, Rae J, Ramesh A, Raymond C, Real F, Rimbach K, Ross C, Rotsted B, Roussez\nH, Ryder N, Saltarelli M, Sanders T, Santurkar S, Sastry G, Schmidt H, Schnurr D, Schulman J,\nSelsam D, Sheppard K, Sherbakov T, Shieh J, Shoker S, Shyam P , Sidor S, Sigler E, Simens M, Sitkin\nJ, Slama K, Sohl I, Sokolowsky B, Song Y , Staudacher N, Such FP , Summers N, Sutskever I, Tang\nJ, Tezak N, Thompson MB, Tillet P , Tootoonchian A, Tseng E, Tuggle P , Turley N, Tworek J, Uribe\nJFC, V allone A, Vijayvergiya A, V oss C, Wainwright C, Wang JJ, Wang A, Wang B, Ward J, Wei J,\nWeinmann CJ, Welihinda A, Welinder P , Weng J, Weng L, Wiethoff M, Willner D, Winter C, Wolrich\nS, Wong H, Workman L, Wu S, Wu J, Wu M, Xiao K, Xu T, Y oo S, Y u K, Y uan Q, Zaremba W, Zellers\nR, Zhang C, Zhang M, Zhao S, Zheng T, Zhuang J, Zhuk W, Zoph B (2024) GPT-4 technical report.\nArxiv. https://doi.org/10.48550/arXiv.2303.08774\nPara S, Wirotsasithon T, Jundee T, Demissie MG, Sekimoto Y , Biljecki F, Phithakkitnukoon S (2024) G2Viz:\nan online tool for visualizing and analyzing a public transit system from GTFS data. Public Transp\n16:893–928. https://doi.org/10.1007/s12469-024-00362-x\nPark Y , Mount J, Liu L, Xiao N, Miller HJ (2020) Assessing public transit performance using real-time\ndata: spatiotemporal patterns of bus operation delays in Columbus, Ohio, USA. Int J Geogr Inf Sci\n34:367–392. https://doi.org/10.1080/13658816.2019.1608997\nPatel A, Reddy S, Bahdanau D, Dasigi P (2024) Evaluating in-context learning of libraries for code gener-\nation. Arxiv. arXiv:2311.09635\nPereira RHM, Saraiva M, Herszenhut D, Braga CKV , Conway MW (2021) r5r: rapid realistic routing on\nmultimodal transport networks with R\n5 in R. Findings. https://doi.org/10.32866/001c.21262\nPereira RHM, Andrade PR, Vieira JPB (2023) Exploring the time geography of public transport networks\nwith the gtfs2gps package. J Geogr Syst 25:453–466. https://doi.org/10.1007/s10109-022-00400-x\nPrajapati A, Bhattrai N, Bajracharya T (2020) Spatio-temporal analysis of public trans-\nportation system using static transit accessibility methodological framework. Int J Sci\nTech Res 9(10). https://www.ijstr.org/ﬁnal-print/oct2020/Spatio-temporal-Analysis-Of-Public-\nTransportation-System-Using-Static-Transit-Accessibility-Methodological-Framework.pdf\nRoth M (2010) How Google and Portland’s TriMet set the standard for open transit data-Streetsblog San\nFrancisco. https://sf.streetsblog.org/2010/01/05/how-google-and-portlands-trimet-set-the-standard-\nfor-open-transit-data\nSalewski L, Alaniz S, Rio-Torto I, Schulz E, Akata Z (2023) In-context impersonation reveals large language\nmodels’ strengths and biases. https://doi.org/10.48550/arXiv.2305.14930\nSchick T, Dwivedi-Y u J, Dessì R, Raileanu R, Lomeli M, Zettlemoyer L, Cancedda N, Scialom T (2023)\nToolformer: language models can teach themselves to use tools. arXiv:2302.04761\nSyed U, Light E, Guo X, Zhang H, Qin L, Ouyang Y , Hu B (2024) Benchmarking the capabilities of large\nlanguage models in transportation system engineering: accuracy, consistency, and reasoning behaviors.\narXiv:2408.08302\nV oß S (2023) Bus bunching and bus bridging: What can we learn from generative AI tools like ChatGPT?\nSustainability 15:9625. https://doi.org/10.3390/su15129625\nWang J, Shalaby A (2024) Transit pulse: utilizing social media as a source for customer feedback and\ninformation extraction with large language model. arXiv:2410.15016\nXu B, Yang A, Lin J, Wang Q, Zhou C, Zhang Y , Mao Z (2023) ExpertPrompting: instructing large language\nmodels to be distinguished experts. Arxiv. https://doi.org/10.48550/arXiv.2305.14688\nYan X, Bejleri I, Zhai L (2022) A spatiotemporal analysis of transit accessibility to low-wage jobs in\nMiami-Dade County. J Transp Geogr 98:103218. https://doi.org/10.1016/j.jtrangeo.2021.103218\n123\nTransitGPT: a generative AI-based framework… 345\nYao S, Zhao J, Y u D, Du N, Shafran I, Narasimhan K, Cao Y (2023) ReAct: synergizing reasoning and\nacting in language models. Arxiv. https://doi.org/10.48550/arXiv.2210.03629\nZan D, Chen B, Yang D, Lin Z, Kim M, Guan B, Wang Y , Chen W, Lou JG (2022) CERT: continual\npre-training on sketches for library-oriented code generation. arXiv:2206.06888\nZhang B, Ye Y , Du G, Hu X, Li Z, Yang S, Liu CH, Zhao R, Li Z, Mao H (2024a) Benchmarking the\ntext-to-SQL capability of large language models: a comprehensive evaluation. arXiv:2403.02951\nZhang D, Zheng H, Y ue W, Wang X (2024b) Advancing ITS applications with LLMs: a survey on trafﬁc\nmanagement, transportation safety, and autonomous driving. In: Hu M, Cornelis C, Zhang Y , Lingras\nP, ´Sle˛zak D, Yao J (eds) Rough sets. Springer, Cham, pp 295–309. https://doi.org/10.1007/978-3-031-\n65668-2_20\nZhang L, Zhang Y , Ren K, Li D, Yang Y (2024c) MLCopilot: unleashing the power of large language\nmodels in solving machine learning tasks. arXiv:2304.14979\nZhang S, Fu D, Liang W, Zhang Z, Y u B, Cai P , Yao B (2024d) TrafﬁcGPT: viewing, processing and inter-\nacting with trafﬁc foundation models. Transp Policy 150:95–105. https://doi.org/10.1016/j.tranpol.\n2024.03.006\nZhang Y , Jiang Q, Han X, Chen N, Yang Y , Ren K (2024e) Benchmarking data science agents.\narXiv:2402.17168\nZhang Z, Sun Y , Wang Z, Nie Y , Ma X, Sun P , Li R (2024f) Large language models for mobility in\ntransportation systems: a survey on forecasting tasks. Arxiv. https://doi.org/10.48550/arXiv.2405.\n02357\nZheng O, Abdel-Aty M, Wang D, Wang Z, Ding S (2023) ChatGPT is on the horizon: Could a large\nlanguage model be suitable for intelligent trafﬁc safety research and applications? Arxiv. https://doi.\norg/10.48550/arXiv.2303.05382\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps\nand institutional afﬁliations.\n123"
}