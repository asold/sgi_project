{
  "title": "Pre-trained language models in Spanish for health insurance coverage",
  "url": "https://openalex.org/W4385570902",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2140547979",
      "name": "Claudio Aracena",
      "affiliations": [
        "University of Chile",
        "Millennium Institute for Integrative Biology"
      ]
    },
    {
      "id": "https://openalex.org/A2087249438",
      "name": "Nicolas Rodriguez",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2581422549",
      "name": "Victor Rocco",
      "affiliations": [
        "Chilean Air Force"
      ]
    },
    {
      "id": "https://openalex.org/A2239150692",
      "name": "Jocelyn Dunstan",
      "affiliations": [
        "Pontificia Universidad Católica de Chile",
        "Millennium Institute for Integrative Biology",
        "University of Chile"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4235759629",
    "https://openalex.org/W2769984510",
    "https://openalex.org/W2937845937",
    "https://openalex.org/W2805211535",
    "https://openalex.org/W2963716420",
    "https://openalex.org/W3089735125",
    "https://openalex.org/W4285116174",
    "https://openalex.org/W2036543108",
    "https://openalex.org/W2789602359",
    "https://openalex.org/W4287888709"
  ],
  "abstract": "The field of clinical natural language processing (NLP) can extract useful information from clinical text. Since 2017, the NLP field has shifted towards using pre-trained language models (PLMs), improving performance in several tasks. Most of the research in this field has focused on English text, but there are some available PLMs in Spanish. In this work, we use clinical PLMs to analyze text from admission and medical reports in Spanish for an insurance and health provider to give a probability of no coverage in a labor insurance process. Our results show that fine-tuning a PLM pre-trained with the provider’s data leads to better results, but this process is time-consuming and computationally expensive. At least for this task, fine-tuning publicly available clinical PLM leads to comparable results to a custom PLM, but in less time and with fewer resources. Analyzing large volumes of insurance requests is burdensome for employers, and models can ease this task by pre-classifying reports that are likely not to have coverage. Our approach of entirely using clinical-related text improves the current models while reinforcing the idea of clinical support systems that simplify human labor but do not replace it. To our knowledge, the clinical corpus collected for this study is the largest one reported for the Spanish language.",
  "full_text": "Proceedings of the 5th Clinical Natural Language Processing Workshop, pages 433–438\nJuly 14, 2023 ©2023 Association for Computational Linguistics\nPre-trained language models in Spanish for health insurance coverage\nClaudio Aracena1,2, Nicolás Rodríguez3, Victor Rocco3, and Jocelyn Dunstan2,4,5,6\n1Faculty of Physical and Mathematical Sciences, University of Chile\n2Millennium Institute Foundational Research on Data, Chile\n3Chilean Safety Association, Chile\n4Department of Computer Science, Catholic University of Chile\n5Institute for Mathematical and Computational Engineering, Catholic University of Chile\n6Center for Mathematical Modeling, University of Chile\nclaudio.aracena@uchile.cl, {nrodrigueza,varoccoc}@achs.cl, jdunstan@uc.cl\nAbstract\nThe field of clinical natural language pro-\ncessing (NLP) can extract useful information\nfrom clinical text. Since 2017, the NLP field\nhas shifted towards using pre-trained language\nmodels (PLMs), improving performance in sev-\neral tasks. Most of the research in this field\nhas focused on English text, but there are some\navailable PLMs in Spanish. In this work, we\nuse clinical PLMs to analyze text from admis-\nsion and medical reports in Spanish for an insur-\nance and health provider to give a probability\nof no coverage in a labor insurance process.\nOur results show that fine-tuning a PLM pre-\ntrained with the provider’s data leads to bet-\nter results, but this process is time-consuming\nand computationally expensive. At least for\nthis task, fine-tuning publicly available clinical\nPLM leads to comparable results to a custom\nPLM, but in less time and with fewer resources.\nAnalyzing large volumes of insurance requests\nis burdensome for employers, and models can\nease this task by pre-classifying reports that are\nlikely not to have coverage. Our approach of\nentirely using clinical-related text improves the\ncurrent models while reinforcing the idea of\nclinical support systems that simplify human\nlabor but do not replace it. To our knowledge,\nthe clinical corpus collected for this study is the\nlargest one reported for the Spanish language.\n1 Introduction\nClinical text is one of the most comprehensive data\ntypes in electronic health records. Therefore, clini-\ncal natural language processing (NLP) has become\nrelevant to extracting helpful information from clin-\nical writing and supporting decision-making. The\ncomplexity of human languages makes it difficult\nto analyze unstructured text. Additionally, the clin-\nical text is complicated because of the heavy use of\njargon, unusual spellings, and abbreviations (Dalia-\nnis, 2018).\nIn this complex scenario, there are various tasks\nthat clinical NLP aims to handle. These tasks might\nbe anything from language-related ones like text\ncategorization, relation extraction, and entity ex-\ntraction to prediction-related ones like estimating\npatient mortality, length of hospital stay, unplanned\nreadmissions, etc. Several publications have ad-\ndressed these tasks that have produced specialized\nmodels (Dalianis, 2018).\nHowever, since 2017, the NLP field has worked\ntowards creating pre-trained language models\n(PLMs) that can be fine-tuned for any specific\ndownstream task. These language models are built\nfor a much simpler task, such as next-word or\nmasked-word prediction in a massive amount of\ntext. This process, known as pre-training, allows\nthe language model to acquire language understand-\ning that can be used for any text-related task (Tun-\nstall et al., 2022).\nAs soon as the NLP field started to work in\nPLMs, clinical NLP introduced this type of model\ninto its set of techniques to improve performance.\nSome examples of clinical PLMs are two different\nversions of ClinicalBERT (Alsentzer et al., 2019;\nHuang et al., 2020). These models show a signifi-\ncant improvement in language tasks and a moderate\nimprovement in prediction tasks.\nMost of the research in clinical NLP has been\ndone for text written in English, but not so much for\nother languages (Névéol et al., 2018). In Spanish,\nsome publicly available PLMs relevant to clini-\ncal NLP are bsc-bio-ehr-es (Carrino et al., 2022)\nand Spanish Clinical Flair (Rojas et al., 2022).\nThese PLMs were pre-trained heavily in general\nand biomedical text with minor additions of clin-\nical text. Despite this drawback, they outperform\ngeneral and biomedical PLMs in language tasks.\nIn this context, an insurance and health provider\naims to analyze their clinical text to apply in a labor\ninsurance coverage process. This provider receives\npatients who have suffered from a labor-related ac-\ncident. When a patient is admitted to one of their\nclinics, admitting staff writes a report detailing the\n433\nFigure 1: Flow diagram of patients and insurance coverage decisions.\naccident. This report includes rich contextual in-\nformation about what happened in the accident.\nAfter admission, a physician checks the patient and\nwrites medical information. Every clinic’s medical\nand administrative board decides a final coverage\nrating for each accident the next business day, con-\nsidering both reports.\nCurrently, the provider has a model that gives a\nprobability of not covering a patient given a spe-\ncific diagnosis. This model serves as a ranking tool\nfor the medical board to review cases with a high\nlikelihood of no coverage. However, not all diag-\nnoses are included in this model (considered as a\ncategorical variable), and admission and medical\nreports are not considered to calculate the proba-\nbility. Additionally, the model can calculate the\nprobability of no coverage just after a physician\ndiagnoses a patient.\nThis work aims to analyze clinical text from ad-\nmission and medical reports to give a probability of\nno coverage. We try three approaches that use clin-\nical PLMs in Spanish to carry out this goal. First,\nwe use a clinical PLM. Second, we do continual\npre-training of the previous PLM with text data\nfrom admission and medical reports. Finally, we\npre-trained a LM from scratch using admission and\nmedical reports. All outcomes will be compared to\nthe current model performance.\n2 Problem statement\nIn Chile, employers must hire an insurance and\nhealth provider specialized in labor accidents.\nThese providers should cover all labor accidents.\nTo decide if the insurance will cover a worker, the\nproviders have clinics where they admit and check\nthe workers to make a decision.\nIn this work, we use data from one of these\nproviders. As this provider is specialized in la-\nbor accidents, the data that collects has some fea-\ntures. First, it has a high level of detail because\nthat admission and medical reports are used to jus-\ntify insurance coverage decisions. Second, many\nphysicians can treat the same patient, requiring in-\nformation in clinical records to be as complete as\npossible so that any medical staff can give better\ncontinuity to patient care over time. These features\nmake the data cleaner compared to general health\nprovider records.\nThe Asociación Chilena de Seguridad (ACHS),\nChilean Safety Association in English, is a pre-\neminent non-profit insurance and health provider.\nIts principal objective is to conceptualize and ad-\nminister risk prevention programs alongside pro-\nviding comprehensive coverage for occupational\naccidents. As evidence of its influence, ACHS ac-\ncommodates more than 2.6 million affiliated work-\ners and over 73,000 affiliated employing entities\nnationwide. Moreover, with a record of the lowest\naverage accident rate, ACHS unequivocally oper-\nates as the largest mutual association in Chile.\nThe stringent regulations under Law No. 16,744\nmandate that all Chilean employing entities, regard-\nless of their operational scale, must be affiliated\nwith a Social Security Administration agency. This\nagency is responsible for safeguarding against the\nrisks of Occupational Accidents and Diseases. As\none of three private administrative bodies, ACHS is\ntasked with formulating risk prevention programs.\nIt also offers health coverage and compensation\nfor occupational accidents, transport mishaps, and\nprofessional illnesses.\nThe type of labor accidents can be of two types,\nwork-related and commuting accidents. Work-\nrelated accidents happen at the workplace or as\na result of work. Commuting accidents happen on\nthe way to or from work with no stops in between\n(direct trips). The staff writes an admission report\nwhen the patient is admitted in both cases. Later,\nwhen a physician receives the patient, a medical\nreport is written.\nThe medical report is based on three sources.\nThe first includes the patient’s anamnesis. The sec-\n434\nond information is from the physical examination\nperformed on the patient. The third is the medical\nindication for treatment. Each time a new or old\npatient passes through this healthcare provider and\nneeds to be seen by a doctor, a new medical report\nentry is generated.\nThe admitting staff and the physician give a label\n(covered or uncovered) classification on the reports.\nThe final classification is made the next business\nday after the patient is seen by the medic. A board\nof physicians and administrative heads from each\nclinic determines a final coverage rating for each\ncase. This final rating takes into account the medi-\ncal and admitting staff reports.\nMost admitting staff’s labels will state that pa-\ntients will be covered, and medics, after clinical ex-\namination, have a more robust filter to say whether\na patient will be covered or not. The committee\nof physicians and administrative heads has a re-\nviewer role, and some decisions are finally changed.\nFigure 1 shows the flow diagram of the described\nprocess.\nThe current model employed by the healthcare\nprovider only makes predictions in 72.1% of cases,\nbasing its predictions on structured diagnoses alone.\nUnfortunately, this approach results in a lack of\npredictions for less frequently observed diagnoses.\nHowever, the majority of cases come with either\nadmission records or medical reports, making it\npossible to improve coverage by utilizing these\nadditional resources.\nWe expect that the use of admission and medical\nreports can help to take better coverage classifi-\ncation compared to the current model that only\nuses diagnosis as a categorical variable with the\nmost common ones. Moreover, the classification\nprediction with the admission report can help the\nphysician consider more information that may have\nbeen overlooked.\n3 Datasets\nFor this study, three different types of datasets were\nbuilt, for fine-tuning, continual pre-training, and\npre-training from scratch. Here we list the details\nof these datasets:\n1. For the fine-tuning process, three datasets\nwere created. An admission dataset, which\nonly contains text from admission reports, and\na label with the final decision if that case was\ncovered (coverage decision). A medical re-\nport, which only contains text from medical\nreports, and coverage decision labels. Finally,\nan admission and medical dataset, which con-\ncatenate text from admission and medical re-\nports, and coverage decision labels.\n2. For the continual pre-training process, also\nthree datasets were created (admission, medi-\ncal, and admission-medical datasets) similar\nto the fine-tuning datasets. We do not need a\nlabel in this case since these datasets are only\nused to continue pre-training a pre-existing\nPLM.\n3. For the pre-training process from scratch, only\none dataset was created, combining all ad-\nmission and medical reports available. This\ndataset does not include a coverage decision\nlabel, as it is used for pre-training. However,\nit is bigger than previous datasets because it is\nused to pre-trained a PLM from scratch. Ac-\ncording to our knowledge, this is the biggest\ncorpus containing only clinical-related text in\nSpanish.\nTable 1 shows details for every dataset.\nDatasets documents tokens\nFine-tuning\nAdmission 300 k 22.5 M\nMedical 300 k 26.3 M\nAdmision+Medical 300 k 57.2 M\nContinual Pre-training\nAdmission 1.5 M 112.6 M\nMedical 1.2 M 154.0 M\nAdmision+Medical 855 k 164.6 M\nPre-training\nAdmision+Medical 7.1 M 1.03 B\nTable 1: Number of documents and tokens in every\ndataset.\n4 Methods\nThis section described the processes of pre-training\nand fine-tuning using the datasets described in the\nprevious section.\n4.1 Fine-tuninig of bsc-bio-ehr-es\nBsc-bio-es and bsc-bio-ehr-es are the first PLMs\ntrained with exclusively biomedical and clinical\ntext in Spanish (Carrino et al., 2022). These PLMs\nhave a RoBERTa architecture and contain around\n130 million parameters. Two corpora were built for\n435\nModel bsc-bio-ehr-es continual PLM custom PLM\nAdmission 93.2 ± 0.9 93.5 ± 0.9 92.8 ± 0.7\nMedical 94.4 ± 0.6 94.9 ± 0.6 94.9 ± 0.7\nAdmission+medical 95.9 ± 0 96.1 ± 0.1 96.3 ± 0.2\nTable 2: Results in the test set (AUC) for all fine-tuned models.\nthis purpose, biomedical and clinical. The biomed-\nical corpus consists of 2.5 million documents and\n1.1 billion tokens, and the clinical corpus consists\nof 514k documents and 95 million tokens.\nA biomedical corpus refers to medical text from\nacademic sources, such as scientific publications or\nclinical trials. On the contrary, a clinical corpus is a\ncollection of documents collected from the medical\npractice. In other words, it is what clinicians write\nduring and/or after the examination of a patient.\nBsc-bio-es was pre-trained only with the biomed-\nical corpus and bsc-bio-ehr-es with the biomedical\nand clinical corpora. The reason behind this design\ndecision is two-fold; the clinical corpus is too small\nto create a functional PLM by itself, and to assess if\nadding a small clinical corpus to a large biomedical\ncorpus positively impacts clinical NLP tasks.\nAs a first step, fine-tuning processes were carried\nout with the three fine-tuning datasets using bsc-\nbio-ehr-es as PLM. As a result, three fine-tuned\nmodels were built.\n4.2 Fine-tuninig of a continual pre-training of\nbsc-bio-ehr-es\nAs a second step, continual pre-training processes\nwere implemented using bsc-bio-ehr-es as a base\nPLM. For continuing the pre-training, the second\ntype of datasets were used. One T4 GPU (16 GB)\nwas used, and the processes lasted 42 hours for\neach. After this step, three PLM were built (ad-\nmission, medical, admission+medical). Then, like\nthe previous step, fine-tuning processes were car-\nried out, and three more fine-tuned models were\nobtained.\n4.3 Fine-tuninig of a PLM pre-trained from\nscratch\nFinally, a pre-training process from scratch was\nimplemented. This process used the same con-\nfiguration as bsc-bio-ehr-es (RoBERTa) and our\nclinical-related corpus. Four T4 GPU (16GB) were\nused, and pre-training lasted 96 hours in 2 epochs.\nAfter this process, a new custom PLM was built.\nWith this new PLM, similar to the previous steps,\nfine-tuning processes were carried out, and three\nmore fine-tuned models were obtained.\n5 Results\nTable 2 shows test results for every fine-tuned\nmodel. The test set only contains data not included\nin the fine-tuning or pre-training datasets.\nWe can notice that the continual PLMs and the\ncustom PLMs are the best performers, but all the\nmodels are close performance-wise. Also, as ex-\npected, medical models are better than admission\nmodels, given that medical models capture more\nclinical information than admission models. The\nadmission+medical models are the best performers\nsince they combine admission and medical infor-\nmation.\nAs the metrics of all admission+medical mod-\nels are close, we could select the least expensive\nand time-consuming when implementing it. In the\ncase of this task, this process is the fine-tuning of\nthe publicly available PLM, bsc-bio-ehr-es. How-\never, this evidence should not be generalized for\nother types of tasks like named entity recognition\nor question answering, which are more complex\nand may benefit from lexical specificity. In those\ntasks, a PLM pre-trained with more clinical-related\ntext could be better than a PLM trained with a mix\nof biomedical and clinical text.\nInterestingly, admission models perform 1 to 2%\nworse than medical models. Therefore, there is an\nopportunity to make a coverage prediction before\nphysicians check patients, helping the physicians\nreview more medical details when their coverage\ndecision does not match the predictions. Moreover,\nthe admitting staff can have a stronger opinion on\na coverage decision. Another benefit of providing\na coverage prediction prior to the medical checkup\nis the possibility that the patient can manage his or\nher case more effectively. Depending on the likeli-\nhood of coverage the model provides, the patient\nmay seek resources to help better justify his or her\naccident.\nFinally, implementing a pre-trained language\nmodel could help the healthcare provider increase\n436\nModel AUC coverage\nCurrent model 95.8 72.7\nCustom PLM: admission+medical 97.7 96.1\nTable 3: Results calculated on the accidents that both models have in common in January 2023 (AUC-Coverage).\nsavings from the correct classification of accidents.\nTable 3 shows the results of a shadow deployment\n(a method for simulating the new model’s perfor-\nmance in the production environment) comparing\nthe performance of the custom PLM with both ad-\nministrative and medical reports against the current\nmodel in January of 2023. We estimated that with\nthe implementation of this new model into produc-\ntion, more cases would be covered by a model,\nincreasing between 20 to 24%. Considering the\nincrease in coverage and in addition to the increase\nin the predictive metrics of the continual model, it\nis estimated that the health care provider could save\nbetween 1.5 to 2.5MM US annually. The saving\nwill come from correctly classified cases where the\nadministrative and medical cases were classified as\ncovered, but in reality, they should not be covered.\n6 Related work\nNLP has been used in applications of the insur-\nance industry in recent years. NLP techniques can\nbe used to analyze vast amounts of unstructured\ndata, such as customer interactions and policy doc-\numents, to gain insights and make informed deci-\nsions. In several areas within the insurance indus-\ntry, NLP is being used, including customer service,\nclaims processing, and fraud detection (Ly et al.,\n2020).\nOne of the most significant uses of NLP in the\ninsurance sector is customer service (Quarteroni,\n2018). To ascertain a client’s wants and prefer-\nences, NLP techniques can be utilized to evaluate\ncustomer interactions such as phone calls and chat\nchats. Customers may receive more individualized\nhelp and recommendations thanks to the utiliza-\ntion of this data. Additionally, regular customer\nsupport operations like responding to frequently\nrequested queries, have been automated using NLP\nalgorithms.\nAnother area where NLP is employed in the\ninsurance sector is claims processing (Popowich,\n2005). By automating the analysis and classifica-\ntion of claims, NLP approaches can cut down on\nthe time and resources needed to process claims.\nTo make more educated judgments about claims,\nNLP algorithms have been employed, for instance,\nto extract information from claim documents, such\nas the type of injury and the reason for the accident.\nFraud detection is another area where NLP is\nbeing used in the insurance industry (Wang and\nXu, 2018). Huge amounts of unstructured data,\nincluding policy documents and customer interac-\ntions, can be analyzed using NLP approaches to\nspot probable fraud cases.\n7 Conclusion\nThis work studied the performance of clinical\nPLMs in a coverage prediction task. Three ap-\nproaches were implemented, and the best model\nwas compared to the current model used by the\nhealth provider. A PLM from scratch was the best-\nperforming model but the most expensive and time-\nconsuming.\nClinical natural language processing has great\npotential to impact the insurance industry, not only\nbecause of the great predictive power they offer\nbut also because it is unnecessary to implement\nexpensive training in the models. As there are\nno significant differences in performance between\nthe pre-trained model and the fine-tuning with the\nadmission+medical data, by just fine-tuning a PLM\nwe can obtain good results at a lower cost for this\ndownstream task. However, the situation might\ndiffer in other NLP tasks that benefit from lexical\nspecificity.\n8 Limitations\nSome limitations of this work are listed below:\n• The architecture and configuration for the cus-\ntom PLM are the same as bsc-bio-ehr-es. An-\nother architecture and configuration could ob-\ntain better results.\n• The textual data come from just one provider.\nUsing data from several providers could help\nwith generalization.\n• The custom PLM has not been compared with\nother PLMs in language tasks such as named\nentity recognition or question answering. This\n437\ncomparison can help to understand if the cus-\ntom PLM can outperform available PLMs in\nother types of tasks.\nEthics Statement\nThe ethical considerations of this work are re-\nlated to the data that we used and the models we\nbuilt. The data was extracted from administrative\nand clinical records from an insurance and health\nprovider that specialized in labor accidents. Within\nthis data, it is possible to find personal and sensitive\ninformation such as personal and company names,\naddresses, health information, pre-existing condi-\ntions, and diagnoses, among others. An anonymiza-\ntion process was not carried out since the model\nwill be used for internal purposes and will not be\nreleased. As a process of memorization can occur\nin the PLM, we believe it is best to keep the model\nprivate because privacy attacks can extract personal\nand sensitive information.\nWe did not test the models for any bias under any\nprotected field. Therefore, the trained models could\nbenefit certain patients or accidents over others\nin the insurance decision. If a biased model is\ndeployed in this provider’s systems, it could harm\npatients with their insurance coverage decisions.\nAcknowledgements\nThis work was funded by ACHS and ANID Chile:\nBasal Funds for Center of Excellence FB210005\n(CMM); Millennium Science Initiative Program\nICN17_002 (IMFD) and ICN2021_004 (iHealth),\nFondecyt grant 11201250, and National Doctoral\nScholarships 21211659 (Claudio Aracena).\nReferences\nEmily Alsentzer, John Murphy, William Boag, Wei-\nHung Weng, Di Jindi, Tristan Naumann, and\nMatthew McDermott. 2019. Publicly Available Clin-\nical BERT Embeddings. In Proceedings of the 2nd\nClinical Natural Language Processing Workshop,\npages 72–78, Minneapolis, Minnesota, USA. Associ-\nation for Computational Linguistics.\nCasimiro Pio Carrino, Joan Llop, Marc Pàmies, Asier\nGutiérrez-Fandiño, Jordi Armengol-Estapé, Joaquín\nSilveira-Ocampo, Alfonso Valencia, Aitor Gonzalez-\nAgirre, and Marta Villegas. 2022. Pretrained Biomed-\nical Language Models for Clinical NLP in Spanish.\nIn Proceedings of the 21st Workshop on Biomedi-\ncal Language Processing, pages 193–199, Dublin,\nIreland. Association for Computational Linguistics.\nHercules Dalianis. 2018. Clinical Text Mining: Sec-\nondary Use of Electronic Patient Records. Springer\nInternational Publishing.\nKexin Huang, Jaan Altosaar, and Rajesh Ranganath.\n2020. ClinicalBERT: Modeling Clinical Notes and\nPredicting Hospital Readmission.\nAntoine Ly, Benno Uthayasooriyar, and Tingting Wang.\n2020. A survey on natural language processing\n(nlp) and applications in insurance. arXiv preprint\narXiv:2010.00462.\nAurélie Névéol, Hercules Dalianis, Sumithra Velupillai,\nGuergana Savova, and Pierre Zweigenbaum. 2018.\nClinical Natural Language Processing in languages\nother than English: opportunities and challenges.\nJournal of Biomedical Semantics, 9(1):12.\nFred Popowich. 2005. Using text mining and natu-\nral language processing for health care claims pro-\ncessing. ACM SIGKDD Explorations Newsletter,\n7(1):59–66.\nSilvia Quarteroni. 2018. Natural language processing\nfor industry: Elca’s experience. Informatik-Spektrum,\n41(2):105–112.\nMatías Rojas, Jocelyn Dunstan, and Fabián Villena.\n2022. Clinical Flair: A Pre-Trained Language Model\nfor Spanish Clinical Natural Language Processing.\nIn Proceedings of the 4th Clinical Natural Language\nProcessing Workshop, pages 87–92, Seattle, W A. As-\nsociation for Computational Linguistics.\nLewis Tunstall, Leandro von Werra, and Thomas Wolf.\n2022. Natural Language Processing with Transform-\ners. O’Reilly Media, Inc.\nYibo Wang and Wei Xu. 2018. Leveraging deep learn-\ning with lda-based text analytics to detect automobile\ninsurance fraud. Decision Support Systems, 105:87–\n95.\n438",
  "topic": "Task (project management)",
  "concepts": [
    {
      "name": "Task (project management)",
      "score": 0.7635775804519653
    },
    {
      "name": "Computer science",
      "score": 0.7521440982818604
    },
    {
      "name": "Process (computing)",
      "score": 0.5822222232818604
    },
    {
      "name": "Field (mathematics)",
      "score": 0.5804818868637085
    },
    {
      "name": "Natural language processing",
      "score": 0.5635916590690613
    },
    {
      "name": "Artificial intelligence",
      "score": 0.515951931476593
    },
    {
      "name": "Language model",
      "score": 0.496232807636261
    },
    {
      "name": "Machine learning",
      "score": 0.4132792055606842
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ]
}