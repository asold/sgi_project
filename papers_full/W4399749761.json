{
  "title": "Large Language Models for Text Style Transfer: Exploratory Analysis of Prompting and Knowledge Augmentation Techniques",
  "url": "https://openalex.org/W4399749761",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2890286381",
      "name": "Martina Toshevska",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    },
    {
      "id": "https://openalex.org/A2061384250",
      "name": "Sonja Gievska",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4205635927",
    "https://openalex.org/W2933966104",
    "https://openalex.org/W4385573257",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4389520102",
    "https://openalex.org/W3093871960",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W2963241138",
    "https://openalex.org/W4388184238",
    "https://openalex.org/W3197754201",
    "https://openalex.org/W2963667126",
    "https://openalex.org/W4313304841",
    "https://openalex.org/W3034319502",
    "https://openalex.org/W3203905069",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2970562804",
    "https://openalex.org/W4385571046",
    "https://openalex.org/W2122410182",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W2964199361",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W2888556895",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4383860339",
    "https://openalex.org/W4286987939",
    "https://openalex.org/W3212893438",
    "https://openalex.org/W3102659883",
    "https://openalex.org/W4380988784",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2965373594"
  ],
  "abstract": "Large language models have gained extensive research interest in the past few years. They have demonstrated remarkable ability to process and generate human-like text, and have improved performances on various natural language processing tasks. This paper is focused on the prompting techniques and knowledge augmentation techniques for text style transfer tasks. Text style transfer involves the transformation of a given sentence in a stylistically different manner while preserving its original meaning. It requires models to understand and manipulate different aspects such as politeness, formality, and sentiment. This paper provides an overview of several methods for prompting large language models for text style transfer and presents an overview of several methods for knowledge augmentation with a discussion about potential use for text style transfer. Preliminary results on formality transfer using the T5 model are presented to evaluate prompting and knowledge augmentation techniques. The results show that using knowledge augmentation techniques improves the performance compared to models without augmentation, while zero-shot prompting techniques are less effective. This emphasizes the necessity of fine-tuning and incorporating knowledge augmentation for enhanced model performance.",
  "full_text": null,
  "topic": "Style (visual arts)",
  "concepts": [
    {
      "name": "Style (visual arts)",
      "score": 0.7449672222137451
    },
    {
      "name": "Exploratory analysis",
      "score": 0.557871401309967
    },
    {
      "name": "Computer science",
      "score": 0.5051997303962708
    },
    {
      "name": "Linguistics",
      "score": 0.4027405381202698
    },
    {
      "name": "Psychology",
      "score": 0.3975793123245239
    },
    {
      "name": "Natural language processing",
      "score": 0.3525312840938568
    },
    {
      "name": "Art",
      "score": 0.1429993212223053
    },
    {
      "name": "Data science",
      "score": 0.13210341334342957
    },
    {
      "name": "Visual arts",
      "score": 0.08410945534706116
    },
    {
      "name": "Philosophy",
      "score": 0.069581538438797
    }
  ]
}