{
    "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model",
    "url": "https://openalex.org/W4285225959",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2630651641",
            "name": "Sidney Black",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A2936985360",
            "name": "Stella Biderman",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A4288781080",
            "name": "Eric Hallahan",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A2983461712",
            "name": "Quentin Anthony",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A3107805125",
            "name": "Leo Gao",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A3120466058",
            "name": "Laurence Golding",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A2901357448",
            "name": "Horace He",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A3118526552",
            "name": "Connor Leahy",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A3133245970",
            "name": "Kyle McDonell",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A2891256592",
            "name": "Jason Phang",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A1989331357",
            "name": "Michael Pieler",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A4288781089",
            "name": "USVSN Sai Prashanth",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4288781090",
            "name": "Shivanshu Purohit",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A3130170119",
            "name": "Laria Reynolds",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A2312271909",
            "name": "Jonathan Tow",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A2112912852",
            "name": "Ben Wang",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        },
        {
            "id": "https://openalex.org/A3099922526",
            "name": "Samuel Weinbach",
            "affiliations": [
                "Machine Intelligence Research Labs"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3093517588",
        "https://openalex.org/W3194309076",
        "https://openalex.org/W4226137521",
        "https://openalex.org/W4286987939",
        "https://openalex.org/W3081168214",
        "https://openalex.org/W4293467220",
        "https://openalex.org/W3175526286",
        "https://openalex.org/W3213151880",
        "https://openalex.org/W2963339397",
        "https://openalex.org/W4310625358",
        "https://openalex.org/W3001279689",
        "https://openalex.org/W204995840",
        "https://openalex.org/W3034850762",
        "https://openalex.org/W4221152848",
        "https://openalex.org/W2088731121",
        "https://openalex.org/W2946609015",
        "https://openalex.org/W3169483174",
        "https://openalex.org/W2943552823",
        "https://openalex.org/W2963015836",
        "https://openalex.org/W4226142937",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W4300466035",
        "https://openalex.org/W4288024261",
        "https://openalex.org/W2890894339",
        "https://openalex.org/W4288335764",
        "https://openalex.org/W2963123047",
        "https://openalex.org/W4226146865",
        "https://openalex.org/W3158631574",
        "https://openalex.org/W2949818215",
        "https://openalex.org/W4286899435",
        "https://openalex.org/W2979636403"
    ],
    "abstract": "Sidney Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, Usvsn Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach. Proceedings of BigScience Episode #5 -- Workshop on Challenges & Perspectives in Creating Large Language Models. 2022.",
    "full_text": "Proceedings of BigScience Episode #5 – Workshop on Challenges & Perspectives in Creating Large Language Models, pages 95 - 136\nMay 27, 2022c⃝2022 Association for Computational Linguistics\nGPT-NeoX-20B: An Open-Source Autoregressive Language Model\nSid Black* Stella Biderman* Eric Hallahan*\nQuentin Anthony Leo Gao Laurence Golding Horace He\nConnor Leahy Kyle McDonell Jason Phang Michael Pieler\nUSVSN Sai Prashanth Shivanshu Purohit Laria Reynolds\nJonathan Tow Ben Wang Samuel Weinbach\nAbstract\nWe introduce GPT-NeoX-20B, a 20 billion pa-\nrameter autoregressive language model trained\non the Pile, whose weights will be made freely\nand openly available to the public through a\npermissive license. It is, to the best of our\nknowledge, the largest dense autoregressive\nmodel that has publicly available weights at\nthe time of submission. In this work, we\ndescribe GPT-NeoX-20B’s architecture and\ntraining, and evaluate its performance on a\nrange of language-understanding, mathematics\nand knowledge-based tasks. We open-source\nthe training and evaluation code, as well as\nthe model weights, at https://github.com/\nEleutherAI/gpt-neox.\n1 Introduction\nOver the past several years, there has been an explo-\nsion in research surrounding large language mod-\nels (LLMs) for natural language processing, cat-\nalyzed largely by the impressive performance of\nTransformer-based language models such as BERT\n(Devlin et al., 2019), GPT-2 (Radford et al., 2019),\nGPT-3 (Brown et al., 2020), and T5 (Raffel et al.,\n2020). One of the most impactful outcomes of\nthis research has been the discovery that the perfor-\nmance of LLMs scales predictably as a power-law\nwith the number of parameters, with architecture\ndetails such as width/depth ratio having a mini-\nmal impact on performance within a wide range\n(Kaplan et al., 2020). A consequence of this has\nbeen an abundance of research focusing on scaling\nTransformer models up to ever-larger scales, result-\ning in dense models that surpass 500B parameters\n(Smith et al., 2022; Chowdhery et al., 2022), a mile-\nstone that would have been almost unthinkable just\na few years prior.\n*Lead authors. Authors after the first three are listed in\nalphabetical order. See Appendix A for individual contribu-\ntion details. Correspondence can be sent to {sid, stella,\ncontact}@eleuther.ai\nToday, there are dozens of publicly acknowl-\nedged LLMs in existence. The largest have more\nthan two orders of magnitude more parameters than\nGPT-2, and even at that scale there are nearly a\ndozen different models. However, these models are\nalmost universally the protected intellectual prop-\nerty of large tech companies, and are gated behind\na commercial API, available only upon request, or\nnot available for outsider use at all. To our knowl-\nedge, the only freely and publicly available dense\nautoregressive language models larger than GPT-\n2 are GPT-Neo (2.7B parameters) (Black et al.,\n2021), GPT-J-6B (Wang and Komatsuzaki, 2021),\nMegatron-11B1, Pangu-α-13B (Zeng et al., 2021),\nand the recently released FairSeq models (2.7B,\n6.7B, and 13B parameters) (Artetxe et al., 2021).\nIn this paper we introduce GPT-NeoX-20B, a 20\nbillion parameter open source autoregressive lan-\nguage model. We make the models weights freely\nand openly available to the public through a per-\nmissive license, motivated by the belief that open\naccess to LLMs is critical to advancing research\nin a wide range of areas—particularly in AI safety,\nmechanistic interpretability, and the study of how\nLLM capabilities scale. Many of the most inter-\nesting capabilities of LLMs only emerge above a\ncertain number of parameters, and they have many\nproperties that simply cannot be studied in smaller\nmodels. Although safety is often cited as a justifica-\ntion for keeping model weights private, we believe\nthis is insufficient to prevent misuse, and is largely\na limitation on the ability to probe and study LLMs\nfor researchers not based at the small number of\norganizations that have access to state of the art\nlanguage models.\nIn the following sections, we give a broad\noverview of GPT-NeoX-20B’s architecture and\ntraining hyperparameters, detail the hardware and\nsoftware setup used for training and evaluation, and\n1This model does not work using the provided codebase,\nand we have been told it under-performs GPT-J.\n95\nelaborate on the choices made when designing the\ntraining dataset and tokenization. We also address\nof some of the difficulties and unknowns we en-\ncountered in training such a large model. We place\nsignificant importance on the broader impacts of\nthe release GPT-NeoX-20B and other such LLMs,\nand have prepared a separate manuscript for dis-\nsecting these issues in greater detail.\nIn addition, we also make available the model\nweights at evenly spaced 1000 step intervals\nthroughout the whole of training. We hope that\nby making a wide range of checkpoints throughout\ntraining freely available, we will facilitate research\non the training dynamics of LLMs, as well as the\naforementioned areas of AI safety and interpretabil-\nity.\n2 Model Design and Implementation\nGPT-NeoX-20B is an autoregressive transformer\ndecoder model whose architecture largely follows\nthat of GPT-3 (Brown et al., 2020), with a few\nnotable deviations described below. Our model\nhas 20 billion parameters, of which 19.9 billion\nare “non-embedding” parameters that Kaplan et al.\n(2020) identify as the proper number to use for\nscaling laws analysis. Our model has 44 layers, a\nhidden dimension size of 6144, and 64 heads.\n2.1 Model Architecture\nAlthough our architecture is largely similar to GPT-\n3, there are some notable differences. In this sec-\ntion we give a high-level overview of those differ-\nences, but ask the reader to refer to (Brown et al.,\n2020) for full details of the model architecture. Our\nmodel architecture is almost identical to that of\nGPT-J (Wang and Komatsuzaki, 2021)2, however\nwe choose to use GPT-3 as the point of reference\nbecause there is no canonical published reference\non the design of GPT-J.\n2.1.1 Rotary Positional Embeddings\nWe use rotary embeddings (Su et al., 2021) instead\nof the learned positional embeddings used in GPT\nmodels (Radford et al., 2018), based on our positive\nprior experiences using it in training LLMs. Rotary\nembeddings are a form of static relative positional\nembeddings. In brief, they twist the embedding\nspace such that the attention of a token at position\nm to token at position n is linearly dependent on\n2The sole difference is due to an oversight discussed in\nSection 2.1.2\nm −n. More formally, they modify the standard\nmultiheaded attention equations from\nsoftmax\n(\n1√\nd ∑\nn,m\nxT\nmWT\nq Wkxn\n)\n,\nwhere xm, xn are (batched) embeddings of tokens\nat position m and n respectively and WT\nq , Wk are\nthe query and key weights respectively to\nsoftmax\n(\n1√\nd ∑\nn,m\nxT\nmWT\nq Rd\nΘ,(n−m)Wkxn\n)\n,\nwhere Rd\nΘ,x is a d ×d block diagonal matrix with\nthe block of index i being a 2D rotation by xθi\nfor hyperparameters Θ = {θi = 10000−2i/d |i ∈\n{0,1,2,..., (d −1)/2}}.\nWhile Su et al. (2021) apply rotary embeddings\nto every embedding vector, we follow Wang and\nKomatsuzaki (2021) and instead apply it only to\nthe first 25% of embedding vector dimensions. Our\ninitial experiments indicate that this strikes the\nbest balance of performance and computational\nefficiency.3\n2.1.2 Parallel Attention + FF Layers\nWe compute the Attention and Feed-Forward (FF)\nlayers in parallel4 and sum the results, rather than\nrunning them in series. This is primarily for ef-\nficiency purposes, as each residual addition with\nop-sharding requires one all-reduce in the forward\npass and one in the backwards pass (Shoeybi et al.,\n2020). By computing the Attention and FFs in par-\nallel, the results can be reduced locally before per-\nforming a single all-reduce. In Mesh Transformer\nJAX (Wang, 2021), this led to a 15% throughput\nincrease, while having comparable loss curves with\nrunning them in series during early training.\nDue to an oversight in our code, we unintention-\nally apply two independent Layer Norms instead\nof using a tied layer norm the way Wang and Ko-\nmatsuzaki (2021) does. Instead of computing\nx + Attn(LN1(x)) +FF(LN1(x))\nas intended, our codebase unties the layer norms:\nx + Attn(LN1(x)) +FF(LN2(x)).\nUnfortunately, this was only noticed after we were\nmuch too far into training to restart. Subsequent\n3See the Weights & Biases reports here and here for further\ndetails.\n4See GitHub for implementation details.\n96\nexperiments at small scales indicated that the untied\nlayer norm makes no difference in performance, but\nwe nevertheless wish to highlight this in the interest\nof transparency.\n2.1.3 Initialization\nFor the Feed-Forward output layers before the\nresiduals, we used the initialization scheme intro-\nduced in Wang (2021), 2\nL\n√\nd . This prevents acti-\nvations from growing with increasing depth and\nwidth, with the factor of 2 compensating for the\nfact that the parallel and feed-forward layers are\norganized in parallel. For all other layers, we use\nthe small init scheme from Nguyen and Salazar\n(2019),\n√\n2\nd+4d\n2.1.4 All Dense Layers\nWhile GPT-3 uses alternating dense and sparse lay-\ners using the technique introduced in Child et al.\n(2019), we instead opt to exclusively use dense\nlayers to reduce implementation complexity.\n2.2 Software Libraries\nOur model is trained using a codebase that builds\non Megatron (Shoeybi et al., 2020) and Deep-\nSpeed (Rasley et al., 2020) to facilitate efficient and\nstraightforward training of large language models\nwith tens of billions of parameters. We use the offi-\ncial PyTorch v1.10.0 release binary package com-\npiled with CUDA 11.1. This package is bundled\nwith NCCL 2.10.3 for distributed communications.\n2.3 Hardware\nWe trained GPT-NeoX-20B on twelve Supermi-\ncro AS-4124GO-NART servers, each with eight\nNVIDIA A100-SXM4-40GB GPUs and config-\nured with two AMD EPYC 7532 CPUs. All GPUs\ncan directly access the InfiniBand switched fab-\nric through one of four ConnectX-6 HCAs for\nGPUDirect RDMA. Two NVIDIA MQM8700-\nHS2R switches—connected by 16 links—compose\nthe spine of this InfiniBand network, with one link\nper node CPU socket connected to each switch.\nFigure 7 shows a simplified overview of a node as\nconfigured for training.\n3 Training\nDue to the intractability of performing a hyperpa-\nrameter sweep for a 20 billion parameter model,\nwe opted to use the values from Brown et al. (2020)\nto guide our choice of hyperparameters. As Brown\net al. (2020) did not train a model at our exact\nscale, we interpolate between the learning rates of\ntheir 13B and 175B models to arrive at a learning\nrate of 0.97E−5. Based on the results of smaller\nscale experiments, we select a weight decay of\n0.01. To achieve a higher training throughput, we\nopt to use the same batch size as OpenAI’s 175B\nmodel–approximately 3.15M tokens, or 1538 con-\ntexts of 2048 tokens each, and train for a total of\n150,000 steps, decaying the learning rate with a\ncosine schedule to 10% of its original value at the\nend of training.\nWe use the AdamW (Loshchilov and Hutter,\n2019) optimizer, with beta values of 0.9 and 0.95\nrespectively, and an epsilon of 1.0E−8. We extend\nAdamW with the ZeRO optimizer (Rajbhandari\net al., 2020) to reduce memory consumption by\ndistributing optimizer states across ranks. Since\nthe weights and optimizer states of a model at this\nscale do not fit on a single GPU, we use the ten-\nsor parallelism scheme introduced in Shoeybi et al.\n(2020) in combination with pipeline parallelism\n(Harlap et al., 2018) to distribute the model across\nGPUs. To train GPT-NeoX-20B, we found that the\nmost efficient way to distribute the model given\nour hardware setup was to set a tensor parallel size\nof 2, and a pipeline parallel size of 4. This allows\nfor the most communication intensive processes,\ntensor and pipeline parallelism, to occur within a\nnode, and data parallel communication to occur\nacross node boundaries. In this fashion, we were\nable to achieve and maintain an efficiency of 117\nteraFLOPS per GPU.\n3.1 Training Data\nGPT-NeoX-20B was trained on the Pile (Gao et al.,\n2020), a massive curated dataset designed specifi-\ncally for training large language models. It consists\nof data from 22 data sources, coarsely broken down\ninto 5 categories:\n• Academic Writing: Pubmed Abstracts and\nPubMed Central, arXiv, FreeLaw,5 USPTO\nBackgrounds,6 PhilPapers,7 NIH Exporter8\n• Web-scrapes and Internet Resources: Com-\nmonCrawl, OpenWebText2, StackExchange,9\nWikipedia (English)\n5https://www.courtlistener.com/\n6https://bulkdata.uspto.gov/\n7https://philpapers.org/\n8https://exporter.nih.gov/\n9https://archive.org/details/stackexchange\n97\n• Prose: BookCorpus2, Bibliotik, Project\nGutenberg (PG-19; Rae et al., 2019)\n• Dialogue: Youtube subtitles, Ubuntu IRC,10\nOpenSubtitles (Lison and Tiedemann, 2016),\nHacker News,11 EuroParl (Koehn, 2005)\n• Miscellaneous: GitHub, the DeepMind Math-\nematics dataset (Saxton et al., 2019), Enron\nEmails (Klimt and Yang, 2004)\nIn aggregate, the Pile consists of over 825GiB\nof raw text data. The diverse data sources reflects\nour desire for a general-purpose language model.\nCertain components are up-sampled to obtain a\nmore balanced data distribution. In contrast, GPT-\n3’s training data consists of web-scrapes, books\ndatasets, and Wikipedia. When comparing results\nin this work to GPT-3, the training data is almost\ncertainly the biggest known unknown factor. Full\ndetails of the Pile can be found in the technical re-\nport (Gao et al., 2020) and the associated datasheet\n(Biderman et al., 2022).\nIt is particularly notable that the Pile contains\na scrape of StackExchange preprocessed into a\nQ/A form. There is a significant and growing\nbody of work on the influence of the syntactic\nstructure of finetuning data on downstream per-\nformance (Zhong et al., 2021; Tan et al., 2021;\nSanh et al., 2021; Wei et al., 2021). While so far\nthere has been no systematic work that focuses on\nprompted pretraining, recent work (Biderman and\nRaff, 2022) observed that the formulation of the\nStackExchange component of the Pile appears to\nheavily influences code generation.\n3.2 Tokenization\nFor GPT-NeoX-20B, we use a BPE-based tokenizer\nsimilar to that used in GPT-2, with the same total\nvocabulary size of 50257, with three major changes\nto the tokenizer. First, we train a new BPE tok-\nenizer based on the Pile, taking advantage of its\ndiverse text sources to construct a more general-\npurpose tokenizer. Second, in contrast to the GPT-2\ntokenizer which treats tokenization at the start of\na string as a non-space-delimited token, the GPT-\nNeoX-20B tokenizer applies consistent space de-\nlimitation regardless. This resolves an inconsis-\ntency regarding the presence of prefix spaces to a\n10https://irclogs.ubuntu.com/\n11https://news.ycombinator.com/\ntokenization input.12. An example can be seen in\nFigure 1. Third, our tokenizer contains tokens for\nrepeated space tokens (all positive integer amounts\nof repeated spaces up to and including 24). This\nallows the GPT-NeoX-20B tokenizer to tokenize\ntext with large amounts of whitespace using fewer\ntokens; for instance, program source code or arXiv\nLATEX source files. See Appendix F for an analysis\nof the tokenizer.\nGPT-2\ndef fibRec(n):←↩\nif n < 2:←↩\nreturn n←↩\nelse:←↩\nreturn fibRec(n-1) + fibRec(n-2)\n55 tokens\nGPT-NeoX-20B\ndef fibRec(n):←↩\nif n < 2:←↩\nreturn n←↩\nelse:←↩\nreturn fibRec(n-1) + fibRec(n-2)\n39 tokens\nFigure 1: GPT-2 tokenization vs. GPT-NeoX-20B tok-\nenization. GPT-NeoX-20B tokenization handles whites-\npace better, which is particularly useful for text such as\nsource code. For more examples, see Appendix G.\n3.3 Data Duplication\nIn the past two years, the standard practice when\ntraining autoregressive language models has be-\ncome to train for only one epoch (Komatsuzaki,\n2019; Kaplan et al., 2020; Henighan et al., 2020).\nRecent research has claimed to see significant ben-\nefits from going even further and deduplicating\ntraining data (Lee et al., 2021; Kandpal et al.,\n2022; Roberts et al., 2022). In particular, every\npublicly known larger language model other than\nGPT-3 (Brown et al., 2020) and Jurassic-113 either\nuses some form of deduplication (Rae et al., 2022;\nAskell et al., 2021; Zeng et al., 2021; Sun et al.,\n2021; Smith et al., 2022; Hoffmann et al., 2022;\nChowdhery et al., 2022) or does not discuss the\ntraining data in sufficient detail to determine what\nwas done (Kim et al., 2021).\nWhen the Pile was originally made, the only\nlanguage model larger than GPT-NeoX-20B that\n12https://discuss.huggingface.co/t/\nbpe-tokenizers-and-spaces-before-words/475/2\n13In private communication, the authors confirmed that\nJurassic-1 was trained on the Pile (Gao et al., 2020).\n98\nFigure 2: Training and validation loss for GPT-NeoX-\n20B. As the validation loss continued to fall into the\nbeginning of the second epoch, we decided to let it train\nfurther.\nexisted was GPT-3, which upsampled high quality\nsubsets of its training data. The Pile followed suit,\nand due to a combination of a lack of resources\nfor large scale ablations and a lack of noticeable\nimpact at smaller scales, we opt to use the Pile as-is.\nAs shown in fig. 2, even at the 20B parameter scale\nwe see no drop in test validation loss after crossing\nthe 1 epoch boundary.\nUnfortunately, none of the papers that have\nclaimed to see an improvement from deduplica-\ntion have released trained models that demonstrate\nthis, making replication and confirmation of their\nresults difficult. Lee et al. (2021) releases the dedu-\nplication code that they used, which we intend to\nuse to explore this question in more detail in the\nfuture.\nIt is important to note that even if there is not an\nimprovement in loss or on task evaluations there\nare nevertheless compelling reasons to deduplicate\ntraining data for any model put into production. In\nparticular, systematic analysis has shown signifi-\ncant benefits in terms of reducing the leakage of\ntraining data (Lee et al., 2021; Zhang et al., 2021;\nCarlini et al., 2022; Kandpal et al., 2022).\n4 Performance Evaluations\nTo evaluate our model we use the EleutherAI\nLanguage Model Evaluation Harness (Gao et al.,\n2021b), an open source codebase for language\nmodel evaluation that supports a number of model\nAPIs. As our goal is to make a powerful model\npublicly accessible, we compare with English lan-\nguage models with at least 10B parameter that are\npublicly accessible. We compare with the GPT-3\nmodels on the OpenAI API(Brown et al., 2020),\nthe open source FairSeq dense models (Artetxe\net al., 2021), and GPT-J-6B (Wang and Komat-\nsuzaki, 2021). We do not compare against T5 (Raf-\nfel et al., 2020) or its derivatives as our evaluation\nmethodology assumes that the models are autore-\ngressive. While there is a Megatron 11B check-\npoint that has been publicly released, the released\ncode is non-functional and we have not been able to\nget the model to work. We do not compare against\nany mixture-of-experts models as no public MoE\nmodel achieves performance comparable to a 10B\nparameter dense model.\nWhile it is common to display “scaling laws”\ncurves of best fit, we opt to not do so as the small\nnumber of OpenAI API models give DaVinci an\noutsized influence on the slope of the curve. In\nmany of the examples we study, including DaVinci\nin the scaling laws calculation moves the line of\nbest fit so far as to entirely change the conclusions.\nInstead, we connect the points with lines directly.\nWe categorize both GPT-J-6B and GPT-NeoX-20B\nunder the umbrella of GPT-NeoX models, as both\nmodels are trained with the same architecture (ex-\ncept for the negligible differences described in Sec-\ntion 2.1.2) and were trained on the same dataset.\nHowever, we connect them using a dashed line to\nreflect the fact that these two models are not the\nsame model trained at two different scales the way\nthe FairSeq and OpenAI models are, having been\ntrained using different codebases, different tokeniz-\ners, and for different numbers of tokens.\nWhere we were able to obtain the relevant in-\nformation, we report two baselines: human-level\nperformance and random performance. All plots\ncontain error bars representing two standard errors,\nindicating the 95% confidence interval around each\npoint. For some plots, the standard error is so small\n99\nthat the interval is not visible.\n4.1 Tasks Evaluated\nWe evaluate our model on a diverse collection of\nstandard language model evaluation datasets that\nwe divide into three main categories: natural lan-\nguage tasks, Advanced Knowledge-Based Tasks,\nand Mathematical Tasks. Due to space constraints a\nrepresentative subset of the results are shown here,\nwith the rest in Appendix E.\nNatural Language Tasks We evaluate our model\non a diverse collection of standard language model\nevaluation datasets: ANLI (Nie et al., 2020), ARC\n(Clark et al., 2018), HeadQA (English) (Vilares\nand Gómez-Rodríguez, 2019), HellaSwag (Zellers\net al., 2019), LAMBDADA (Paperno et al., 2016),\nLogiQA (Liu et al., 2020), OpenBookQA (Mi-\nhaylov et al., 2018), PiQA (Bisk et al., 2020),\nPROST (Aroca-Ouellette et al., 2021), QA4MRE\n(Peñas et al., 2013) (2013), SciQ (Welbl et al.,\n2017), TriviaQA (Joshi et al., 2017), Winogrande\n(Sakaguchi et al., 2021), and the SuperGlue version\nof the Winograd Schemas Challenge (WSC) (Wang\net al., 2019).\nMathematical Tasks The solving of mathemati-\ncal problem solving is an area that has had a long\nhistory of study in AI research, despite the fact that\nlarge language models tend to perform quite poorly\non both arithmetic tasks and mathematical prob-\nlems phrased in natural language. We evaluate on\nthe MATH test dataset (Hendrycks et al., 2021b) as\nwell as on the numerical arithmetic problems intro-\nduced by Brown et al. (2020). Note that the MATH\ntest dataset is an evaluation metric that is generally\nfinetuned on, but due to computational limitations\nwe only evaluate models zero- and five-shot here.\nAdvanced Knowledge-Based Tasks We are also\ninterested in the ability of our models to answer fac-\ntual questions that (for humans) require advanced\nknowledge. To do this, we use a dataset of multiple\nchoice questions in a variety of diverse domains\ndeveloped by Hendrycks et al. (2021a). Follow-\ning common practice on this dataset, we focus on\nresults aggregated by subject area: Humanities,\nSocial Sciences, STEM, and Miscellaneous as pre-\nsented in Figure 6. We report five-shot performance\nto be comparable to previous work.\nFigure 3: Zero-shot performance of GPT-NeoX-20B\ncompared to GPT-J-6B and FairSeq and OpenAI models\non a variety of language modeling benchmarks.\n100\nFigure 4: Zero-shot performance of GPT-NeoX-20B\ncompared to and FairSeq and OpenAI models on arith-\nmetic tasks. Random performance on these tasks is 0%,\nand we were unable to find information on median hu-\nman performance.\nFigure 5: Zero-shot performance of GPT-NeoX-20B\ncompared to and FairSeq and OpenAI models on arith-\nmetic tasks. Random performance on these tasks is 0%,\nand we were unable to find information on median hu-\nman performance.\nFigure 6: Five-shot performance of GPT-NeoX-20B\ncompared to GPT-J-6B and FairSeq and OpenAI models\non Hendrycks et al. (2021a).\n5 Discussion\n5.1 Performance Results\nNatural Language Tasks While GPT-NeoX-\n20B outperforms FairSeq 13B on some tasks (e.g.\nARC, LAMBADA, PIQA, PROST), it underper-\nforms on others (e.g. HellaSwag, LogiQA zero-\nshot). In total, across the 32 evaluations we did\nwe outpreform on 22 tasks, underpreform on four\ntasks, and fall within the margin of error on six\ntasks. By far our weakest performance is on Hel-\nlaSwag, where we score four standard deviations\nbelow FairSeq 13B in both zero- and five-shot eval-\nuations. Similarly, GPT-J underperforms FairSeq\n6.7B by three standard deviations zero-shot and six\nstandard deviations five-shot on HellaSwag. We\nfind this massive performance loss largely inexpli-\ncable; while we originally assumed that the sub-\nstantial non-prose components of the Pile were to\nblame, we note that GPT-J and GPT-NeoXoverpre-\nform FairSeq models on the very similar Lambada\ntask by roughly the same amount.\n101\nMathematics While GPT-3 and FairSeq models\nare generally quite close on arithmetic tasks, they\nare consistently out-preformed by GPT-J and GPT-\nNeoX. We conjecture that this is traceable to the\nprevalence of mathematics equations in the training\ndata, but warn that people should not assume that\nthis means that training on the Pile produces better\nout-of-distribution arithmetic reasoning. Razeghi\net al. (2022) show that there is a strong correla-\ntion between the frequency of a numerical equation\nin the Pile and GPT-J’s performance on that equa-\ntion, and we see no reason this would not hold\nin GPT-NeoX 20B, FairSeq, and GPT-3. We are\nunfortunately unable to investigate this effect in\nFairSeq and GPT-3 models because the authors do\nnot release their training data.\nAdvanced Knowledge-Based Tasks While GPT-\nNeoX and FairSeq both exhibit dominant perfor-\nmance on MMMLU compared to GPT-3 in the\nfive-shot setting (Figures 6 and 11), their perfor-\nmance is much closer in the zero-shot setting (Fig-\nure 10). Hendrycks et al. (2021b) find that few-shot\nevaluation does not improve performance, but that\nappears to be only the case for GPT-3. We view this\nas a warning against drawing strong conclusions\nabout evaluation metrics based only on one model,\nand encourage researchers developing new eval-\nuation benchmarks to leverage multiple different\nclasses of models to avoid overfitting their conclu-\nsions to a specific model.\n5.2 Powerful Few-Shot Learning\nOur experiments indicate that GPT-J-6B and GPT-\nNeoX-20B benefit substantially more from few-\nshot evaluations than the FairSeq models do. When\ngoing from 0-shot to 5-shot evaluations, GPT-J-6B\nimproves by 0.0526 and GPT-NeoX-20B improves\nby 0.0598 while the FairSeq 6.7B and 13B models\nimprove by 0.0051 and 0.0183 respectively. This\nresult is statistically significant and robust to pur-\nturbations of prompting. While we do not have a\nparticular explanation for this currently, we view\nthis as a strong recommendation for our models.\n5.3 Limitations\nOptimal Training Hyperparameter tuning is an\nexpensive process, and is often infeasible to do\nat full scale for multi-billion parameter models.\nDue to the aforementioned limitations, we opted\nto choose hyperparameters based on a mixture of\nexperiments at smaller scales and by interpolating\nparameters appropriate for our model size based\non previously published work (Brown et al., 2020).\nHowever, several aspects of both our model ar-\nchitecture [Section 2.1] and training setup, includ-\ning the data [Section 3.1] and the tokenizer [Sec-\ntion 3.2], diverge significantly from Brown et al.\n(2020). As such, it is almost certainly the case\nthat the hyperparameters used for our model are no\nlonger optimal, and potentially never were.\nLack of Coding Evaluations Many of the de-\nsign choices we made during the development of\nthis model were oriented towards improving per-\nformance on coding tasks. However, we underes-\ntimated the difficulty and cost of existing coding\nbenchmarks (Chen et al., 2021), and so were un-\nable to evaluate out model in that domain. We hope\nto do so in the future.\nData Duplication Finally, the lack of dataset\ndeduplication could also have had an impact on\ndownstream performance. Recent work has shown\nthat deduplicating training data can have a large\neffect on perplexity (Lee et al., 2021). While our\nexperiments show no sign of this, it is hard to dis-\nmiss it due to the number of researchers who have\nfound the opposite result.\n5.4 Releasing a 20B Parameter LLM\nThe current status quo in research is that large lan-\nguage models are things people train and publish\nabout, but do not actually release. To the best of\nour knowledge, GPT-NeoX-20B is the largest and\nmost performant dense language model to ever be\npublicly released. A variety of reasons for the non-\nrelease of large language models are given by vari-\nous groups, but the primary one is the harms that\npublic access to LLMs would purportedly cause.\nWe take these concerns quite seriously. However,\nhaving taken them quite seriously, we feel that they\nare flawed in several respects. While a thorough\nanalysis of these issues is beyond the scope of this\npaper, the public release of our model is the most\nimportant contribution of this paper and so an ex-\nplanation of why we disagree with the prevailing\nwisdom is important.\nProviding access to ethics and alignment re-\nsearchers will prevent harm. The open-source\nrelease of this model is motivated by the hope that\nit will allow researchers who would not otherwise\nhave access to LLMs to use them. While there are\nnegative risks due to the potential acceleration of\n102\ncapabilities research, we believe the benefits of this\nrelease outweigh the risks. We also note that these\nbenefits are not hypothetical, as a number of papers\nabout the limits and ethics of LLMs has been ex-\nplicitly enabled by the public release of previous\nmodels (Zhang et al., 2021; Kandpal et al., 2022;\nCarlini et al., 2022; Birhane et al., 2021; nostalge-\nbraist, 2020; Meng et al., 2022; Lin et al., 2021).\nLimiting access to governments and corpora-\ntions will not prevent harm. Perhaps the most\ncurious aspect of the argument that LLMs should\nnot be released is that the people making such ar-\nguments are not arguing they they should not use\nLLMs. Rather, they are claiming that other people\nshould not use them. We do not believe that this\nis a position that should be taken seriously. The\ncompanies and governments that have the financial\nresources to train LLMs are overwhelmingly more\nlikely to do large scale harm using a LLM than a\nrandom individual.\nReleasing this model is the beginning, not the\nend, of our work to make GPT-NeoX-20B widely\naccessible to researchers. Due to the size of the\nmodel, inference is most economical on a pair of\nRTX 3090 Tis or a single A6000 GPU and fine-\ntuning requires significantly more compute. Truly\npromoting widespread access to LLMs means pro-\nmoting widespread access to computing infrastruc-\nture in addition to the models themselves. We plan\nto make progress on this issue going forward by\ncontinuing to work on reducing the inference costs\nof our model, and by working with researchers to\nprovide access to the computing infrastructure they\nneed to carry out experiments on our models. We\nstrongly encourage researchers who are interested\nin studying GPT-NeoX-20B but lack the necessary\ninfrastructure to reach out to discuss how we can\nhelp empower you.\n6 Summary\nWe introduce GPT-NeoX-20B, a 20 billion param-\neter autoregressive Transformer language model\ntrained on the Pile (Gao et al., 2020) dataset, and de-\ntail the main architectural differences between GPT-\nNeoX-20B and GPT-3—most notably the change in\ntokenizer, the addition of Rotary embeddings, the\nparallel computation of attention and feed-forward\nlayers, and a different initialization scheme and\nhyperparameters. We run extensive evaluations\nof GPT-NeoX-20B on natural language and fac-\ntual knowledge tasks, and compare it with other\npublicly available models, finding it performed\nparticularly well on knowledge-based and math-\nematical tasks. Finally, we are open sourcing the\ntraining and evaluation code at https://github.\ncom/EleutherAI/gpt-neox, where readers can\nfind a link to download the model weights across\nthe whole training run.\nAcknowledgments\nWe thank staff at CoreWeave—in particular\nMax Hjelm, Brannin McBee, Peter Salanki, and\nBrian Venturo—for providing the GPUs and com-\nputing infrastructure that made this project possible.\nWe would also like to acknowledge Eren Do ˘gan\nand Wesley Brown for feedback and technical sup-\nport throughout the project, and John Schulman,\nEvan Hubinger, Victor Sanh, Jacob Hilton, and Sid-\ndharth Karamcheti for providing feedback on drafts\nof the paper.\nFinally, we thank Anthony DiPofi, Charles Fos-\nter, Jeffrey Hsu, Eric Tang, Anish Thite,\nKevin Wang, and Andy Zou for their contributions\nto the EleutherAI Language Modeling Evaluation\nHarness we used to evaluate GPT-NeoX-20B.\nReferences\nStuart Armstrong and Sören Mindermann. 2018. Oc-\ncam’s razor is insufficient to infer the preferences of\nirrational agents. In Advances in Neural Information\nProcessing Systems, volume 31, pages 5598–5609.\nCurran Associates, Inc.\nStuart Armstrong, Anders Sandberg, and Nick Bostrom.\n2012. Thinking inside the box: Controlling and using\nan oracle AI. Minds and Machines, 22(4):299–324.\nStéphane Aroca-Ouellette, Cory Paik, Alessandro Ron-\ncone, and Katharina Kann. 2021. PROST: Physi-\ncal reasoning about objects through space and time.\nIn Findings of the Association for Computational\nLinguistics: ACL-IJCNLP 2021, pages 4597–4608,\nOnline. Association for Computational Linguistics.\nMikel Artetxe, Shruti Bhosale, Naman Goyal, Todor\nMihaylov, Myle Ott, Sam Shleifer, Xi Victoria Lin,\nJingfei Du, Srinivasan Iyer, Ramakanth Pasunuru,\nGiri Anantharaman, Xian Li, Shuohui Chen, Halil\nAkin, Mandeep Baines, Louis Martin, Xing Zhou,\nPunit Singh Koura, Brian O’Horo, Jeff Wang, Luke\nZettlemoyer, Mona Diab, Zornitsa Kozareva, and Ves\nStoyanov. 2021. Efficient large scale language mod-\neling with mixtures of experts. Computing Research\nRepository, arXiv:2112.10684. Version 1.\nAmanda Askell, Yuntao Bai, Anna Chen, Dawn Drain,\nDeep Ganguli, Tom Henighan, Andy Jones, Nicholas\n103\nJoseph, Ben Mann, Nova DasSarma, Nelson El-\nhage, Zac Hatfield-Dodds, Danny Hernandez, Jack-\nson Kernion, Kamal Ndousse, Catherine Olsson,\nDario Amodei, Tom Brown, Jack Clark, Sam McCan-\ndlish, Chris Olah, and Jared Kaplan. 2021. A gen-\neral language assistant as a laboratory for alignment.\nComputing Research Repository, arXiv:2112.00861.\nVersion 3.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language models\nbe too big? In Proceedings of the 2021 ACM Confer-\nence on Fairness, Accountability, and Transparency,\nFAccT ’21, pages 610–623, New York, NY , USA.\nAssociation for Computing Machinery.\nStella Biderman, Kieran Bicheno, and Leo Gao. 2022.\nDatasheet for the Pile. Computing Research Reposi-\ntory, arXiv:2201.07311. Version 1.\nStella Biderman and Edward Raff. 2022. Neural lan-\nguage models are effective plagiarists. Computing\nResearch Repository, arXiv:2201.07406. Version 1.\nStella Biderman and Walter J Scheirer. 2020. Pitfalls\nin machine learning research: Reexamining the de-\nvelopment cycle. In ”I Can’t Believe It’s Not Better!”\nNeurIPS 2020 workshop. PMLR.\nAbeba Birhane, Vinay Uday Prabhu, and Emmanuel\nKahembwe. 2021. Multimodal datasets: misogyny,\npornography, and malignant stereotypes. Computing\nResearch Repository, arXiv:2110.01963. Version 1.\nYonatan Bisk, Rowan Zellers, Ronan Le bras, Jianfeng\nGao, and Yejin Choi. 2020. PIQA: Reasoning about\nphysical commonsense in natural language. In Pro-\nceedings of the AAAI Conference on Artificial Intelli-\ngence, volume 34, pages 7432–7439.\nSid Black, Leo Gao, Phil Wang, Connor Leahy, and\nStella Biderman. 2021. GPT-Neo: Large scale autore-\ngressive language modeling with Mesh-Tensorflow.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nNick Cammarata, Shan Carter, Gabriel Goh, Chris Olah,\nMichael Petrov, Ludwig Schubert, Chelsea V oss, Ben\nEgan, and Swee Kiat Lim. 2020. Thread: Circuits.\nDistill.\nNicholas Carlini, Daphne Ippolito, Matthew Jagielski,\nKatherine Lee, Florian Tramer, and Chiyuan Zhang.\n2022. Quantifying memorization across neural lan-\nguage models. Computing Research Repository ,\narXiv:2202.07646. Version 2.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-\nplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, Alex Ray, Raul Puri, Gretchen\nKrueger, Michael Petrov, Heidy Khlaaf, Girish Sas-\ntry, Pamela Mishkin, Brooke Chan, Scott Gray,\nNick Ryder, Mikhail Pavlov, Alethea Power, Lukasz\nKaiser, Mohammad Bavarian, Clemens Winter,\nPhilippe Tillet, Felipe Petroski Such, Dave Cum-\nmings, Matthias Plappert, Fotios Chantzis, Eliza-\nbeth Barnes, Ariel Herbert-V oss, William Hebgen\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie\nTang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\nWilliam Saunders, Christopher Hesse, Andrew N.\nCarr, Jan Leike, Josh Achiam, Vedant Misra, Evan\nMorikawa, Alec Radford, Matthew Knight, Miles\nBrundage, Mira Murati, Katie Mayer, Peter Welinder,\nBob McGrew, Dario Amodei, Sam McCandlish, Ilya\nSutskever, and Wojciech Zaremba. 2021. Evaluating\nlarge language models trained on code. Computing\nResearch Repository, arXiv:2107.03374. Version 2.\nRewon Child, Scott Gray, Alec Radford, and Ilya\nSutskever. 2019. Generating long sequences with\nsparse transformers. Computing Research Reposi-\ntory, arXiv:1904.10509. Version 1.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick,\nAndrew M. Dai, Thanumalayan Sankaranarayana\nPillai, Marie Pellat, Aitor Lewkowycz, Erica Mor-\neira, Rewon Child, Oleksandr Polozov, Katherine\nLee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta,\nMark Diaz, Orhan Firat, Michele Catasta, Jason Wei,\nKathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav\nPetrov, and Noah Fiedel. 2022. PaLM: Scaling lan-\nguage modeling with pathways. Computing Research\nRepository, arXiv:2204.02311v2.\nPaul Christiano, Ajeya Cotra, and Mark Xu. 2021. Elic-\niting latent knowledge: How to tell if your eyes de-\nceive you.\nPeter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,\nAshish Sabharwal, Carissa Schoenick, and Oyvind\n104\nTafjord. 2018. Think you have solved question an-\nswering? try arc, the ai2 reasoning challenge. Com-\nputing Research Repository, arXiv:1803.05457. Ver-\nsion 1.\nDamai Dai, Li Dong, Yaru Hao, Zhifang Sui, and\nFuru Wei. 2021. Knowledge neurons in pretrained\ntransformers. Computing Research Repository ,\narXiv:2104.08696. Version 1.\nAbram Demski. 2019. The parable of Predict-O-Matic.\nAI Alignment Forum.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training\nof deep bidirectional transformers for language\nunderstanding. Computing Research Repository ,\narXiv:1810.04805. Version 2.\nJesse Dodge, Maarten Sap, Ana Marasovi ´c, William\nAgnew, Gabriel Ilharco, Dirk Groeneveld, Margaret\nMitchell, and Matt Gardner. 2021. Documenting\nlarge webtext corpora: A case study on the Colos-\nsal Clean Crawled Corpus. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 1286–1305, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nNelson Elhage, Neel Nanda, Catherine Olsson, Tom\nHenighan, Nicholas Joseph, Ben Mann, Amanda\nAskell, Yuntao Bai, Anna Chen, Tom Conerly,\nNova DasSarma, Dawn Drain, Deep Ganguli, Zac\nHatfield-Dodds, Danny Hernandez, Andy Jones,\nJackson Kernion, Liane Lovitt, Kamal Ndousse,\nDario Amodei, Tom Brown, Jack Clark, Jared Ka-\nplan, Sam McCandlish, and Chris Olah. 2021. A\nMathematical Framework for Transformer Circuits.\ntransformer-circuits.pub.\nWilliam Fedus, Barret Zoph, and Noam Shazeer. 2021.\nSwitch transformers: Scaling to trillion parameter\nmodels with simple and efficient sparsity. Computing\nResearch Repository, arXiv:2101.03961. Version 1.\nLeo Gao. 2021. Behavior cloning is miscalibrated. AI\nAlignment Forum.\nLeo Gao, Stella Biderman, Sid Black, Laurence Gold-\ning, Travis Hoppe, Charles Foster, Jason Phang,\nHorace He, Anish Thite, Noa Nabeshima, Shawn\nPresser, and Connor Leahy. 2020. The Pile: An\n800GB dataset of diverse text for language modeling.\nComputing Research Repository, arXiv:2101.00027.\nVersion 1.\nLeo Gao, Kyle McDonell, Laria Reynolds, and Stella\nBiderman. 2021a. A preliminary exploration into\nfactored cognition with language models. EleutherAI\nBlog.\nLeo Gao, Jonathan Tow, Stella Biderman, Sid Black,\nAnthony DiPofi, Charles Foster, Laurence Golding,\nJeffrey Hsu, Kyle McDonell, Niklas Muennighoff,\nJason Phang, Laria Reynolds, Eric Tang, Anish Thite,\nBen Wang, Kevin Wang, and Andy Zou. 2021b. A\nframework for few-shot language model evaluation.\nAaron Harlap, Deepak Narayanan, Amar Phanishayee,\nVivek Seshadri, Nikhil Devanur, Greg Ganger, and\nPhil Gibbons. 2018. PipeDream: Fast and efficient\npipeline parallel DNN training. Computing Research\nRepository, arXiv:1806.03377. Version 1.\nDan Hendrycks, Collin Burns, Steven Basart, Andy\nZou, Mantas Mazeika, Dawn Song, and Jacob Stein-\nhardt. 2021a. Measuring massive multitask language\nunderstanding. Computing Research Repository ,\narXiv:2009.03300. Version 3.\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul\nArora, Steven Basart, Eric Tang, Dawn Song, and\nJacob Steinhardt. 2021b. Measuring mathematical\nproblem solving with the math dataset. Computing\nResearch Repository, arXiv:2103.03874. Version 2.\nTom Henighan, Jared Kaplan, Mor Katz, Mark Chen,\nChristopher Hesse, Jacob Jackson, Heewoo Jun,\nTom B. Brown, Prafulla Dhariwal, Scott Gray, Chris\nHallacy, Benjamin Mann, Alec Radford, Aditya\nRamesh, Nick Ryder, Daniel M. Ziegler, John Schul-\nman, Dario Amodei, and Sam McCandlish. 2020.\nScaling laws for autoregressive generative modeling.\nComputing Research Repository, arXiv:2010.14701.\nVersion 2.\nJordan Hoffmann, Sebastian Borgeaud, Arthur Mensch,\nElena Buchatskaya, Trevor Cai, Eliza Rutherford,\nDiego de Las Casas, Lisa Anne Hendricks, Johannes\nWelbl, Aidan Clark, et al. 2022. Training compute-\noptimal large language models. Computing Research\nRepository, arXiv:2203.15556. Version 1.\nWenlong Huang, Pieter Abbeel, Deepak Pathak, and\nIgor Mordatch. 2022. Language models as zero-\nshot planners: Extracting actionable knowledge for\nembodied agents. Computing Research Repository,\narXiv:2201.07207. Version 1.\nEvan Hubinger, Chris van Merwijk, Vladimir Miku-\nlik, Joar Skalse, and Scott Garrabrant. 2021. Risks\nfrom learned optimization in advanced machine\nlearning systems. Computing Research Repository,\narXiv:1906.01820. Version 3.\nMandar Joshi, Eunsol Choi, Daniel Weld, and Luke\nZettlemoyer. 2017. TriviaQA: A large scale distantly\nsupervised challenge dataset for reading comprehen-\nsion. In Proceedings of the 55th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 1601–1611, Vancouver,\nCanada. Association for Computational Linguistics.\nNikhil Kandpal, Eric Wallace, and Colin Raffel. 2022.\nDeduplicating training data mitigates privacy risks in\nlanguage models. Computing Research Repository,\narXiv:2202.06539. Version 2.\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B\nBrown, Benjamin Chess, Rewon Child, Scott Gray,\nAlec Radford, Jeffrey Wu, and Dario Amodei. 2020.\nScaling laws for neural language models. Computing\nResearch Repository, arXiv:2001.08361. Version 1.\n105\nBoseop Kim, HyoungSeok Kim, Sang-Woo Lee,\nGichang Lee, Donghyun Kwak, Jeon Dong Hyeon,\nSunghyun Park, Sungju Kim, Seonhoon Kim, Dong-\npil Seo, Heungsub Lee, Minyoung Jeong, Sungjae\nLee, Minsub Kim, Suk Hyun Ko, Seokhun Kim,\nTaeyong Park, Jinuk Kim, Soyoung Kang, Na-Hyeon\nRyu, Kang Min Yoo, Minsuk Chang, Soobin Suh,\nSookyo In, Jinseong Park, Kyungduk Kim, Hiun\nKim, Jisu Jeong, Yong Goo Yeo, Donghoon Ham,\nDongju Park, Min Young Lee, Jaewook Kang, Inho\nKang, Jung-Woo Ha, Woomyoung Park, and Nako\nSung. 2021. What changes can large-scale language\nmodels bring? intensive study on HyperCLOV A:\nBillions-scale Korean generative pretrained trans-\nformers. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 3405–3424, Online and Punta Cana, Do-\nminican Republic. Association for Computational\nLinguistics.\nBryan Klimt and Yiming Yang. 2004. The Enron corpus:\nA new dataset for email classification research. In\nProceedings of the 15th European Conference on\nMachine Learning, ECML’04, page 217–226, Berlin,\nHeidelberg. Springer-Verlag.\nJack Koch, Lauro Langosco, Jacob Pfau, James Le, and\nLee Sharkey. 2021. Objective robustness in deep rein-\nforcement learning. Computing Research Repository,\narXiv:2105.14111. Version 2.\nPhilipp Koehn. 2005. Europarl: A parallel corpus for\nstatistical machine translation. In Proceedings of\nMachine Translation Summit X: Papers, pages 79–86,\nPhuket, Thailand.\nAran Komatsuzaki. 2019. One epoch is all you need.\nComputing Research Repository, arXiv:1906.06669.\nVersion 1.\nVanessa Kosoy. 2016. IRL is hard. AI Alignment Fo-\nrum.\nJulia Kreutzer, Isaac Caswell, Lisa Wang, Ahsan Wahab,\nDaan van Esch, Nasanbayar Ulzii-Orshikh, Allah-\nsera Tapo, Nishant Subramani, Artem Sokolov, Clay-\ntone Sikasote, Monang Setyawan, Supheakmungkol\nSarin, Sokhar Samb, Benoît Sagot, Clara Rivera, An-\nnette Rios, Isabel Papadimitriou, Salomey Osei, Pe-\ndro Ortiz Suarez, Iroro Orife, Kelechi Ogueji, An-\ndre Niyongabo Rubungo, Toan Q. Nguyen, Math-\nias Müller, André Müller, Shamsuddeen Hassan\nMuhammad, Nanda Muhammad, Ayanda Mnyak-\neni, Jamshidbek Mirzakhalov, Tapiwanashe Matan-\ngira, Colin Leong, Nze Lawson, Sneha Kudugunta,\nYacine Jernite, Mathias Jenny, Orhan Firat, Bonaven-\nture F. P. Dossou, Sakhile Dlamini, Nisansa de Silva,\nSakine Çabuk Ballı, Stella Biderman, Alessia Bat-\ntisti, Ahmed Baruwa, Ankur Bapna, Pallavi Baljekar,\nIsrael Abebe Azime, Ayodele Awokoya, Duygu Ata-\nman, Orevaoghene Ahia, Oghenefego Ahia, Sweta\nAgrawal, and Mofetoluwa Adeyemi. 2022. Quality\nat a Glance: An Audit of Web-Crawled Multilingual\nDatasets. Transactions of the Association for Com-\nputational Linguistics, 10:50–72.\nAlexandre Lacoste, Alexandra Luccioni, Victor\nSchmidt, and Thomas Dandres. 2019. Quantifying\nthe carbon emissions of machine learning. Comput-\ning Research Repository, arXiv:1910.09700. Version\n2.\nConnor Leahy. 2021. Why Release a Large Language\nModel? EleutherAI Blog.\nConnor Leahy and Stella Biderman. 2021. The hard\nproblem of aligning AI to human values. In The State\nof AI Ethics Report, volume 4, pages 180–183. The\nMontreal AI Ethics Institute.\nKatherine Lee, Daphne Ippolito, Andrew Nystrom,\nChiyuan Zhang, Douglas Eck, Chris Callison-Burch,\nand Nicholas Carlini. 2021. Deduplicating training\ndata makes language models better. Computing Re-\nsearch Repository, arXiv:2107.06499. Version 1.\nOpher Lieber, Or Sharir, Barak Lenz, and Yoav Shoham.\n2021. Jurassic-1: Technical details and evaluation.\nTechnical report, AI21 Labs.\nStephanie Lin, Jacob Hilton, and Owain Evans. 2021.\nTruthfulQA: Measuring how models mimic hu-\nman falsehoods. Computing Research Repository,\narXiv:2109.07958. Version 1.\nPierre Lison and Jörg Tiedemann. 2016. OpenSub-\ntitles2016: Extracting large parallel corpora from\nmovie and TV subtitles. In Proceedings of the Tenth\nInternational Conference on Language Resources\nand Evaluation (LREC’16), pages 923–929, Portorož,\nSlovenia. European Language Resources Association\n(ELRA).\nJian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang,\nYile Wang, and Yue Zhang. 2020. LogiQA: A chal-\nlenge dataset for machine reading comprehension\nwith logical reasoning. In Proceedings of the Twenty-\nNinth International Joint Conference on Artificial\nIntelligence, IJCAI-20, pages 3622–3628. Interna-\ntional Joint Conferences on Artificial Intelligence\nOrganization.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. Computing Research\nRepository, arXiv:1711.05101. Version 3.\nJ. Nathan Matias. 2020. Why we need industry-\nindependent research on tech & society. Citizens\nand Technology Lab.\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and\nRyan McDonald. 2020. On faithfulness and factu-\nality in abstractive summarization. Computing Re-\nsearch Repository, arXiv:2005.00661. Version 1.\nKevin Meng, David Bau, Alex Andonian, and Yonatan\nBelinkov. 2022. Locating and editing factual knowl-\nedge in GPT. Computing Research Repository ,\narXiv:2202.05262v1. Version 1.\n106\nTodor Mihaylov, Peter Clark, Tushar Khot, and Ashish\nSabharwal. 2018. Can a suit of armor conduct elec-\ntricity? a new dataset for open book question an-\nswering. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing,\npages 2381–2391, Brussels, Belgium. Association\nfor Computational Linguistics.\nToan Q. Nguyen and Julian Salazar. 2019. Trans-\nformers without tears: Improving the normalization\nof self-attention. Computing Research Repository,\narXiv:1910.05895. Version 2.\nYixin Nie, Adina Williams, Emily Dinan, Mohit Bansal,\nJason Weston, and Douwe Kiela. 2020. Adversarial\nNLI: A new benchmark for natural language under-\nstanding. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 4885–4901, Online. Association for Computa-\ntional Linguistics.\nnostalgebraist. 2020. interpreting GPT: the logit lens.\nLessWrong.\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari,\nHenryk Michalewski, Jacob Austin, David Bieber,\nDavid Dohan, Aitor Lewkowycz, Maarten Bosma,\nDavid Luan, Charles Sutton, and Augustus Odena.\n2021. Show your work: Scratchpads for intermedi-\nate computation with language models. Computing\nResearch Repository, arXiv:2112.00114. Version 1.\nPedro A. Ortega, Markus Kunesch, Grégoire Delétang,\nTim Genewein, Jordi Grau-Moya, Joel Veness, Jonas\nBuchli, Jonas Degrave, Bilal Piot, Julien Perolat, Tom\nEveritt, Corentin Tallec, Emilio Parisotto, Tom Erez,\nYutian Chen, Scott Reed, Marcus Hutter, Nando\nde Freitas, and Shane Legg. 2021. Shaking the foun-\ndations: delusions in sequence models for interac-\ntion and control. Computing Research Repository,\narXiv:2110.10819. Version 1.\nDenis Paperno, Germán Kruszewski, Angeliki Lazari-\ndou, Ngoc Quan Pham, Raffaella Bernardi, Sandro\nPezzelle, Marco Baroni, Gemma Boleda, and Raquel\nFernández. 2016. The LAMBADA dataset: Word\nprediction requiring a broad discourse context. In\nProceedings of the 54th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 1525–1534, Berlin, Germany.\nAssociation for Computational Linguistics.\nAnselmo Peñas, Eduard Hovy, Pamela Forner, Álvaro\nRodrigo, Richard Sutcliffe, and Roser Morante. 2013.\nQA4MRE 2011-2013: Overview of question answer-\ning for machine reading evaluation. In Information\nAccess Evaluation. Multilinguality, Multimodality,\nand Visualization, pages 303–320, Berlin, Heidel-\nberg. Springer Berlin Heidelberg.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training. Technical report,\nOpenAI.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. Techni-\ncal report, OpenAI.\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie\nMillican, Jordan Hoffmann, H. Francis Song, John\nAslanides, Sarah Henderson, Roman Ring, Susan-\nnah Young, Eliza Rutherford, Tom Hennigan, Ja-\ncob Menick, Albin Cassirer, Richard Powell, George\nvan den Driessche, Lisa Anne Hendricks, Mari-\nbeth Rauh, Po-Sen Huang, Amelia Glaese, Jo-\nhannes Welbl, Sumanth Dathathri, Saffron Huang,\nJonathan Uesato, John Mellor, Irina Higgins, Antonia\nCreswell, Nat McAleese, Amy Wu, Erich Elsen, Sid-\ndhant M. Jayakumar, Elena Buchatskaya, David Bud-\nden, Esme Sutherland, Karen Simonyan, Michela Pa-\nganini, Laurent Sifre, Lena Martens, Xiang Lorraine\nLi, Adhiguna Kuncoro, Aida Nematzadeh, Elena\nGribovskaya, Domenic Donato, Angeliki Lazaridou,\nArthur Mensch, Jean-Baptiste Lespiau, Maria Tsim-\npoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sot-\ntiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong,\nDaniel Toyama, Cyprien de Masson d’Autume, Yujia\nLi, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin,\nAidan Clark, Diego de Las Casas, Aurelia Guy,\nChris Jones, James Bradbury, Matthew Johnson,\nBlake A. Hechtman, Laura Weidinger, Iason Gabriel,\nWilliam S. Isaac, Edward Lockhart, Simon Osindero,\nLaura Rimell, Chris Dyer, Oriol Vinyals, Kareem\nAyoub, Jeff Stanway, Lorrayne Bennett, Demis Hass-\nabis, Koray Kavukcuoglu, and Geoffrey Irving. 2022.\nScaling language models: Methods, analysis & in-\nsights from training Gopher. Computing Research\nRepository, arXiv:2112.11446. Version 2.\nJack W Rae, Anna Potapenko, Siddhant M Jayaku-\nmar, Chloe Hillier, and Timothy P Lillicrap.\n2019. Compressive transformers for long-range se-\nquence modelling. Computing Research Repository,\narXiv:1911.05507. Version 1.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. Journal of Machine Learning Research, 21:1–\n67.\nSamyam Rajbhandari, Jeff Rasley, Olatunji Ruwase,\nand Yuxiong He. 2020. ZeRO: Memory optimiza-\ntions toward training trillion parameter models. In\nProceedings of the International Conference for High\nPerformance Computing, Networking, Storage and\nAnalysis, SC ’20. IEEE Press.\nJeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and\nYuxiong He. 2020. DeepSpeed: System optimiza-\ntions enable training deep learning models with over\n100 billion parameters. In Proceedings of the 26th\nACM SIGKDD International Conference on Knowl-\nedge Discovery & Data Mining, pages 3505–3506,\nNew York, NY , USA. Association for Computing\nMachinery.\n107\nYasaman Razeghi, Robert L Logan IV , Matt Gardner,\nand Sameer Singh. 2022. Impact of pretraining term\nfrequencies on few-shot reasoning. Computing Re-\nsearch Repository, arXiv:2202.07206. Version 1.\nAdam Roberts, Hyung Won Chung, Anselm Levskaya,\nGaurav Mishra, James Bradbury, Daniel Andor, Sha-\nran Narang, Brian Lester, Colin Gaffney, Afroz\nMohiuddin, Curtis Hawthorne, Aitor Lewkowycz,\nAlex Salcianu, Marc van Zee, Jacob Austin, Sebas-\ntian Goodman, Livio Baldini Soares, Haitang Hu,\nSasha Tsvyashchenko, Aakanksha Chowdhery, Jas-\nmijn Bastings, Jannis Bulian, Xavier Garcia, Jianmo\nNi, Andrew Chen, Kathleen Kenealy, Jonathan H.\nClark, Stephan Lee, Dan Garrette, James Lee-Thorp,\nColin Raffel, Noam Shazeer, Marvin Ritter, Maarten\nBosma, Alexandre Passos, Jeremy Maitin-Shepard,\nNoah Fiedel, Mark Omernick, Brennan Saeta, Ryan\nSepassi, Alexander Spiridonov, Joshua Newlan, and\nAndrea Gesmundo. 2022. Scaling up models and\ndata with t5x and seqio. Computing Research\nRepository, arXiv:2203.17189. Version 1.\nJathan Sadowski, Salomé Viljoen, and Meredith Whit-\ntaker. 2021. Everyone should decide how their digi-\ntal data are used — not just tech companies. Nature,\n595(7866):169–171.\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavat-\nula, and Yejin Choi. 2021. WinoGrande: An adver-\nsarial Winograd Schema Challenge at scale. Com-\nmun. ACM, 64(9):99–106.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H.\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja,\nManan Dey, M Saiful Bari, Canwen Xu, Urmish\nThakker, Shanya Sharma Sharma, Eliza Szczechla,\nTaewoon Kim, Gunjan Chhablani, Nihal Nayak,\nDebajyoti Datta, Jonathan Chang, Mike Tian-Jian\nJiang, Han Wang, Matteo Manica, Sheng Shen,\nZheng Xin Yong, Harshit Pandey, Rachel Bawden,\nThomas Wang, Trishala Neeraj, Jos Rozen, Abheesht\nSharma, Andrea Santilli, Thibault Févry, Jason Alan\nFries, Ryan Teehan, Stella Biderman, Leo Gao, Tali\nBers, Thomas Wolf, and Alexander M. Rush. 2021.\nMultitask prompted training enables zero-shot task\ngeneralization. Computing Research Repository ,\narXiv:2110.08207. Version 2.\nDavid Saxton, Edward Grefenstette, Felix Hill, and\nPushmeet Kohli. 2019. Analysing mathematical rea-\nsoning abilities of neural models. Computing Re-\nsearch Repository, arXiv:1904.01557. Version 1.\nRoy Schwartz, Jesse Dodge, Noah A Smith, and Oren\nEtzioni. 2020. Green AI. Communications of the\nACM, 63(12):54–63.\nMohammad Shoeybi, Mostofa Patwary, Raul Puri,\nPatrick LeGresley, Jared Casper, and Bryan Catan-\nzaro. 2020. Megatron-LM: Training multi-billion\nparameter language models using model parallelism.\nComputing Research Repository, arXiv:1909.08053.\nVersion 4.\nMary Anne Smart. 2021. Addressing privacy threats\nfrom machine learning. Computing Research Reposi-\ntory, arXiv:2111.04439. Version 1.\nShaden Smith, Mostofa Patwary, Brandon Norick,\nPatrick LeGresley, Samyam Rajbhandari, Jared\nCasper, Zhun Liu, Shrimai Prabhumoye, George\nZerveas, Vijay Korthikanti, Elton Zhang, Rewon\nChild, Reza Yazdani Aminabadi, Julie Bernauer, Xia\nSong, Mohammad Shoeybi, Yuxiong He, Michael\nHouston, Saurabh Tiwary, and Bryan Catanzaro.\n2022. Using DeepSpeed and Megatron to train\nMegatron-Turing NLG 530B, a large-scale generative\nlanguage model. Computing Research Repository,\narXiv:2201.11990. Version 3.\nNate Soares. 2021. Visible thoughts project and bounty\nannouncement. Machine Intelligence Research Insti-\ntute.\nNisan Stiennon, Long Ouyang, Jeff Wu, Daniel M.\nZiegler, Ryan Lowe, Chelsea V oss, Alec Radford,\nDario Amodei, and Paul F. Christiano. 2022. Learn-\ning to summarize from human feedback. Computing\nResearch Repository, arXiv:2009.01325.\nEmma Strubell, Ananya Ganesh, and Andrew McCal-\nlum. 2019. Energy and policy considerations for\ndeep learning in NLP. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 3645–3650, Florence, Italy. Asso-\nciation for Computational Linguistics.\nJianlin Su, Yu Lu, Shengfeng Pan, Bo Wen, and Yunfeng\nLiu. 2021. RoFormer: Enhanced transformer with\nrotary position embedding. Computing Research\nRepository, arXiv:2104.09864. Version 2.\nYu Sun, Shuohuan Wang, Shikun Feng, Siyu Ding,\nChao Pang, Junyuan Shang, Jiaxiang Liu, Xuyi Chen,\nYanbin Zhao, Yuxiang Lu, Weixin Liu, Zhihua Wu,\nWeibao Gong, Jianzhong Liang, Zhizhou Shang,\nPeng Sun, Wei Liu, Xuan Ouyang, Dianhai Yu, Hao\nTian, Hua Wu, and Haifeng Wang. 2021. ERNIE\n3.0: Large-scale knowledge enhanced pre-training\nfor language understanding and generation. Comput-\ning Research Repository, arXiv:2107.02137. Version\n1.\nZeerak Talat, Aurélie Névéol, Stella Biderman, Miruna\nClinciu, Manan Dey, Shayne Longpre, Alexan-\ndra Sasha Luccioni, Maraim Masoud, Margaret\nMitchell, Dragomir Radev, Shanya Sharma, Arjun\nSubramonian, Jaesung Tae, Samson Tan, Deepak\nTunuguntla, and Oskar van der Wal. 2022. You reap\nwhat you sow: On the challenges of bias evaluation\nunder multilingual settings. In Proceedings of the 1st\nWorkshop on Challenges & Perspectives in Creating\nLarge Language Models. Association for Computa-\ntional Linguistics.\nZhixing Tan, Xiangwen Zhang, Shuo Wang, and Yang\nLiu. 2021. MSP: Multi-stage prompting for mak-\ning pre-trained language models better translators.\nComputing Research Repository, arXiv:2110.06609.\nVersion 1.\n108\nJie Tang. 2021. WuDao: Pretrain the world. Keynote ad-\ndress at the European Conference on Machine Learn-\ning and Principles and Practice of Knowledge Dis-\ncovery in Databases.\nDavid Vilares and Carlos Gómez-Rodríguez. 2019.\nHEAD-QA: A healthcare dataset for complex reason-\ning. In Proceedings of the 57th Annual Meeting of\nthe Association for Computational Linguistics, pages\n960–966, Florence, Italy. Association for Computa-\ntional Linguistics.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Aman-\npreet Singh, Julian Michael, Felix Hill, Omer Levy,\nand Samuel Bowman. 2019. SuperGLUE: A stick-\nier benchmark for general-purpose language under-\nstanding systems. Advances in Neural Information\nProcessing Systems, 32:3266–3280.\nBen Wang. 2021. Mesh-Transformer-JAX: Model-\nparallel implementation of transformer language\nmodel with JAX.\nBen Wang and Aran Komatsuzaki. 2021. GPT-J-6B: A\n6 billion parameter autoregressive language model.\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin\nGuu, Adams Wei Yu, Brian Lester, Nan Du, An-\ndrew M Dai, and Quoc V Le. 2021. Finetuned lan-\nguage models are zero-shot learners. Computing\nResearch Repository, arXiv:2109.01652. Version 5.\nJohannes Welbl, Nelson F. Liu, and Matt Gardner. 2017.\nCrowdsourcing multiple choice science questions.\nIn Proceedings of the 3rd Workshop on Noisy User-\ngenerated Text, pages 94–106, Copenhagen, Den-\nmark. Association for Computational Linguistics.\nJohn Wentworth. 2020. Alignment by default. AI Align-\nment Forum.\nMeredith Whittaker. 2021. The steep cost of capture.\nInteractions, 28(6):50–55.\nLinting Xue, Aditya Barua, Noah Constant, Rami Al-\nRfou, Sharan Narang, Mihir Kale, Adam Roberts,\nand Colin Raffel. 2021. Byt5: Towards a token-free\nfuture with pre-trained byte-to-byte models. Comput-\ning Research Repository.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2020. mT5: A massively multilingual\npre-trained text-to-text transformer. Computing Re-\nsearch Repository, arXiv:2010.11934. Version 1.\nRowan Zellers, Ari Holtzman, Yonatan Bisk, Ali\nFarhadi, and Yejin Choi. 2019. HellaSwag: Can a ma-\nchine really finish your sentence? In Proceedings of\nthe 57th Annual Meeting of the Association for Com-\nputational Linguistics, pages 4791–4800, Florence,\nItaly. Association for Computational Linguistics.\nWei Zeng, Xiaozhe Ren, Teng Su, Hui Wang, Yi Liao,\nZhiwei Wang, Xin Jiang, ZhenZhang Yang, Kaisheng\nWang, Xiaoda Zhang, Chen Li, Ziyan Gong, Yi-\nfan Yao, Xinjing Huang, Jun Wang, Jianfeng Yu,\nQi Guo, Yue Yu, Yan Zhang, Jin Wang, Hengtao\nTao, Dasen Yan, Zexuan Yi, Fang Peng, Fangqing\nJiang, Han Zhang, Lingfeng Deng, Yehong Zhang,\nZhe Lin, Chao Zhang, Shaojie Zhang, Mingyue Guo,\nShanzhi Gu, Gaojun Fan, Yaowei Wang, Xuefeng\nJin, Qun Liu, and Yonghong Tian. 2021. Pangu-\nα: Large-scale autoregressive pretrained chinese lan-\nguage models with auto-parallel computation. Com-\nputing Research Repository, arXiv:2104.12369. Ver-\nsion 1.\nChiyuan Zhang, Daphne Ippolito, Katherine Lee,\nMatthew Jagielski, Florian Tramèr, and Nicholas Car-\nlini. 2021. Counterfactual memorization in neural\nlanguage models. Computing Research Repository,\narXiv:2112.12938. Version 1.\nRuiqi Zhong, Kristy Lee, Zheng Zhang, and Dan Klein.\n2021. Adapting language models for zero-shot learn-\ning by meta-tuning on dataset and prompt collections.\nComputing Research Repository, arXiv:2104.04670.\nVersion 5.\n109\nA Individual Contributions\nSid Black was the lead developer and overall point\nperson for the project. Stella Biderman was the\nlead scientist and project manager.\nImplementation and Engineering\nImplementation of training infrastructure:\nSid Black, Stella Biderman, Eric Hallahan,\nQuentin Anthony, Samuel Weinbach\nScaling experiments and optimization:\nSid Black, Stella Biderman, Quentin Anthony,\nSamuel Weinbach\nPositional Embeddings:\nSid Black, Eric Hallahan, Michael Pieler\nTokenizer:\nSid Black\nMiscellaneous:\nUSVSN Sai Prashanth, Ben Wang\nScientific Experimentation\nEvaluations:\nStella Biderman, Leo Gao, Jonathan Tow,\nSid Black, Shivanshu Purohit, Horace He,\nLaurence Golding\nPositional Embeddings:\nStella Biderman, Laurence Golding,\nMichael Pieler\nTokenizer:\nStella Biderman, Jason Phang, Leo Gao\nBroader Impacts\nAlignment Implications:\nLeo Gao, Connor Leahy, Laria Reynolds,\nKyle McDonell\nEnvironmental Impact:\nStella Biderman, Eric Hallahan\nB Full Configuration Details\nIn Table 1 we attach the full configuration details\nused to train GPT-NeoX-20B. The file is available\nin .yamlformat usable in gpt-neoxat https://\ngithub.com/EleutherAI/gpt-neox, where we\nalso provide documentation describing the role of\neach parameter.\nConfiguration Key Value\nattention-dropout 0\nbias-gelu-fusion True\ncheckpoint-activations True\ncheckpoint-num-layers 1\ndata-impl mmap\ndistributed-backend nccl\neval-interval 1000\neval-iters 10\nfp16.enabled True\nfp16.fp16 True\nfp16.hysteresis 2\nfp16.initial-scale-power 12\nfp16.loss-scale 0\nfp16.loss-scale-window 1000\nfp16.min-loss-scale 1\ngpt-j-residual True\ngradient-accumulation-steps 32\ngradient-clipping 1.0\nhidden-dropout 0\nhidden-size 6144\ninit-method small-init\nlog-interval 2\nlr-decay-iters 150000\nlr-decay-style cosine\nmax-position-embeddings 2048\nmin-lr 9.7e-06\nmodel-parallel-size 2\nno-weight-tying True\nnorm layernorm\nnum-attention-heads 64\nnum-layers 44\noptimizer.params.betas [0.9, 0.95]\noptimizer.params.eps 1e-08\noptimizer.params.lr 9.7e-05\noptimizer.type Adam\noutput-layer-init-method wang-init\noutput-layer-parallelism column\npartition-activations False\npipe-parallel-size 4\npos-emb rotary\nrotary-pct 0.25\nsave-interval 500\nscaled-upper-triang-masked-softmax-fusion True\nseq-length 2048\nsplit 995,4,1\nsteps-per-print 2\nsynchronize-each-layer True\ntokenizer-type HFTokenizer\ntrain-iters 150000\ntrain-micro-batch-size-per-gpu 4\nvocab-file 20B-tokenizer.json\nwall-clock-breakdown False\nwarmup 0.01\nweight-decay 0.01\nzero-optimization.allgather-bucket-size 1260000000\nzero-optimization.allgather-partitions True\nzero-optimization.contiguous-gradients True\nzero-optimization.cpu-offload False\nzero-optimization.overlap-comm True\nzero-optimization.reduce-bucket-size 1260000000\nzero-optimization.reduce-scatter True\nzero-optimization.stage 1\nTable 1: The full configuration details for GPT-NeoX-\n20B training\n110\nC Broader Impacts\nThe current status quo in research is that large lan-\nguage models are things people train and publish\nabout, but do not actually release. To the best of our\nknowledge, GPT-NeoX-20B is the largest dense\nlanguage model to ever be publicly released with a\nseveral-way tie for second place at 13 billion param-\neters (Artetxe et al., 2021; Xue et al., 2020, 2021)\nand many more models at the 10-11B parameter\nscale. A variety of reasons for the non-release of\nlarge language models are given by various groups,\nbut the primary one is the harms that public access\nto LLMs would purportedly cause.\nWe take these concerns quite seriously. However,\nhaving taken them quite seriously, we feel that they\nare flawed in several respects. While a thorough\nanalysis of these issues is beyond the scope of this\npaper, the public release of our model is the most\nimportant contribution of this paper and so an ex-\nplanation of why we disagree with the prevailing\nwisdom is important.\nProviding access to ethics and alignment re-\nsearchers will prevent harm. The open-source\nrelease of this model is motivated by the hope that\nit will allow researchers who would not otherwise\nhave access to LLMs to use them. While there are\nnegative risks due to the potential acceleration of\ncapabilities research, we believe the benefits of this\nrelease outweigh the risks. We also note that these\nbenefits are not hypothetical, as a number of papers\nabout the limits and ethics of LLMs has been ex-\nplicitly enabled by the public release of previous\nmodels (Zhang et al., 2021; Kandpal et al., 2022;\nCarlini et al., 2022; Birhane et al., 2021; nostalge-\nbraist, 2020; Meng et al., 2022; Lin et al., 2021).\nLimiting access to governments and corpora-\ntions will not prevent harm. Perhaps the most\ncurious aspect of the argument that LLMs should\nnot be released is that the people making such ar-\nguments are not arguing they they should not use\nLLMs. Rather, they are claiming that other people\nshould not use them. We do not believe that this\nis a position that should be taken seriously. The\ncompanies and governments that have the financial\nresources to train LLMs are overwhelmingly more\nlikely to do large scale harm using a LLM than a\nrandom individual.\nThe open-source release of this model is mo-\ntivated by the hope that it will allow ethics and\nalignment researchers who would not otherwise\nhave access to LLMs to use them. While there are\nnegative risks due to the potential acceleration of\ncapabilities research, we believe the benefits of this\nrelease outweigh the risks of accelerating capabili-\nties research.\nC.1 Impact on Capabilities Research and\nProducts\nWhen discussing the impact of access to technol-\nogy, it is important to distinguish between capaci-\nties research which seeks to push the current state-\nof-the-art and research on\nWe feel the risk of releasing GPT-NeoX-20B\nis acceptable, as the contribution of the model to\ncapabilities research is likely to be limited, for two\nreasons.\nWe ultimately believe that the benefits of releas-\ning this model outweigh the risks, but this argument\nhinges crucially on the particular circumstances\nof this release. All actors considering releasing\npowerful AI models or advancing the frontier of\ncapabilities should think carefully about what they\nrelease, in what way, and when.\nC.2 Impact on Ethics and Alignment\nResearch\nTo oversimplify a complex debate, there are\nbroadly speaking two schools of thought regard-\ning the mitigation of harm that is done by AI al-\ngorithms: AI Ethics and AI Alignement. AI Ethics\nresearchers are primarily concerned with the im-\npact of current technologies or technologies very\nsimilar to current technologies, while AI Align-\nment is primarily concerned with future “generally\nintelligent” systems whose capacities greatly out-\nclass currently existing systems and possess human\nand superhuman levels of intelligence. While the\ntools, methods, and ideas of these camps are very\ndifferent, we believe that increasing access to these\ntechnologies will empower and advance the goals\nof researchers in both schools.\nC.2.1 The Necessity of Model Access for AI\nEthics\nAnalyzing and documenting the limitations of mod-\nels is an essential aspect of AI ethics research\n(Matias, 2020). Work examining and criticizing\ndatasets (Kreutzer et al., 2022; Dodge et al., 2021;\nBirhane et al., 2021), functionality (Smart, 2021;\nZhang et al., 2021; Carlini et al., 2022; Biderman\nand Raff, 2022), evaluation and deployment proce-\ndures (Biderman and Scheirer, 2020; Talat et al.,\n111\n2022), and more are essential to well-rounded and\ninformed debate on the value and application of\ntechnology.\nHowever the current centralization of LLM train-\ning also creates a centralization of control of tech-\nnology (Sadowski et al., 2021; Whittaker, 2021)\nthat makes meaningful independent evaluation im-\npossible. This means that it is often not possible\nto do this kind of work in practice because of the\nsevere access restrictions companies that own large\nlanguage models put on them. While GPT-NeoX\nis the 13th largest dense language model at time of\nwriting only model larger than GPT-NeoX 20B that\nis publicly accessible is GPT-3. There are signifi-\ncant limitations on people’s ability to do research\non GPT-3 though, as it is not free to use and its\ntraining data is private.\nC.2.2 The Usefulness of Large Language\nModels in Alignment\nLLMs represent a different paradigm than the AI\nsystems generally studied by alignment researchers\nbecause they are not well-described as coherent\nagents or expected utility maximizers. Though\ntrained to optimize a log-likelihood loss function, at\na high level the goals a LLM pursues are varied and\ncontradictory, depending on the way it is prompted.\nThis introduces additional challenges, but may also\nenable new approaches to alignment.\nGPT-NeoX-20B itself is not the system we need\nto align, but we hope it can serve as a publicly\navailable platform for experiments whose results\nmight generalize to crucial future work.\nThe following is a non-exhaustive list of poten-\ntial approaches we consider promising for further\ninvestigation.\nMechanistic interpretability. Mechanistic inter-\npretability research (Cammarata et al., 2020) hopes\nto gain an understanding into how models accom-\nplish the tasks they do, in part in the hopes of de-\ntecting problematic or deceptive algorithms imple-\nmented by models before these failures manifest\nin the real world. Being able to interpret and in-\nspect the detailed inner workings of trained models\nwould be a powerful tool to ensure models are opti-\nmizing for the goals we intended (Hubinger et al.,\n2021; Koch et al., 2021). Reverse engineering\ntransformer language models has already yielded\ninsights about the inner functioning of LMs (El-\nhage et al., 2021; nostalgebraist, 2020; Meng et al.,\n2022; Dai et al., 2021).\nUsing a LLM as a reward model. Because they\nare trained to predict human writing, LLMs also\nappear to develop a useful representation of hu-\nman values at the semantic level. Finding a way\nto utilise these representations could be a possible\npath toward solving the problem of reward robust-\nness in RL and other algorithms which require a\nproxy of human judgment (Stiennon et al., 2022;\nWentworth, 2020). Despite fundamental theoretical\nlimitations on learning human values (Armstrong\nand Mindermann, 2018; Kosoy, 2016), value learn-\ning may still be robust enough to align weaker su-\nperhuman AIs. Future experiments could explore\nthe extent to which LLM pretraining improves\ndownstream reward model robustness and general-\nization.\nNatural language transparency. Since LLM\nprompts are in a human-readable form, it can\nprovide insight on the LLM’s expected behavior.\nPrompt programming or finetuning can be used to\nleverage this fact and force a LLM to execute more\ntransparent algorithms, such as splitting problems\ninto steps or explicitly writing an “internal mono-\nlogue” (Soares, 2021; Gao et al., 2021a; Nye et al.,\n2021). Reliability and trustworthiness can present\nsignificant challenges for these approaches.\nHowever, this form of transparency also has its\nlimits. In particular, models can often respond\nunpredictably to prompts, and internal monologues\nmay become completely detached from the model’s\ndecision making process if translating between the\nmodel’s ontology and the human ontology is more\ncomplex than simply modeling human monologues\n(Christiano et al., 2021).\nSimulating agents at runtime. Although LLMs\nare not well-described as coherent agents, they can\nstill be used to generate goal-directed processes.\nGiven an appropriate prompt (such as a story of a\ncharacter working to achieve a goal), LLMs can\npredict and thus simulate an agent (Huang et al.,\n2022). Simulated agents take representative actions\naccording to the patterns present in the training\ndata, similar to behavior cloning. One potential\nfuture research direction is testing whether they\nare less susceptible to failure modes that follow\nfrom expected utility maximization, such as Good-\nhart failures and power-seeking behavior. However,\nother failure modes can be introduced by the LM\ntraining procedure, such as “delusions” or “halluci-\nnations” (Ortega et al., 2021; Gao, 2021; Maynez\n112\net al., 2020). Additionally, simulated agents may be\nuncompetitive with optimal agents like those pro-\nduced by Reinforcement Learning. An important\nresearch direction is to explore how the beneficial\nproperties of simulated agents can be maintained\nwhile making them competitive with RL based ap-\nproaches.\nTool AI and automated alignment research.\nLMs can be used as relatively unagentic tools, such\nas OpenAI’s Codex model (Chen et al., 2021) act-\ning as a coding assistant. Because pretrained LLMs\nare not directly optimized for the factual accuracy\nof their predictions, it is possible they avoid some\nof the traditional problems with tool or oracle AI\n(Armstrong et al., 2012), such as the incentive\nto produce manipulative answers (Demski, 2019).\nTool AI is not a long-term solution to the problem\nof alignment, but it could be used to assist align-\nment research or even automate large parts of it.\nFor example, language models could be used to\nhelp brainstorm alignment ideas more quickly, act\nas a writing assistant, or directly generate align-\nment research papers for humans to review. This\nline of research also risks accelerating capabilities\nresearch, a concern we discuss more below.\nC.3 Differential Impact on Access\nBecause training large models requires a significant\nengineering and capital investment, such models\nare often out of reach for small labs and indepen-\ndent researchers. As it stands, only large organiza-\ntions have access to the latest generation of power-\nful language models (Brown et al., 2020; Rae et al.,\n2022; Fedus et al., 2021; Lieber et al., 2021; Tang,\n2021). The number of researchers focused primar-\nily on ethics and alignment working at these labs is\nmuch lower than those working on developing new\ncapabilities.\nWe feel the risk of releasing GPT-NeoX-20B is\nacceptable, as the contribution of the model to ca-\npabilities research is likely to be limited, for two\nreasons. Firstly, the organizations pursuing capa-\nbilities research most aggressively are unlikely to\nbenefit from our open-source release of this model\nas they have already developed more powerful mod-\nels of their own. Secondly, we believe the single\nmost important piece of knowledge that drives ad-\nvancing capabilities research is the knowledge that\nscaling LLMs was possible in the first place (Leahy,\n2021; Leahy and Biderman, 2021). Whereas the ac-\ntual implementation is very fungible (as evidenced\nby the large number of parties who have succeeded\nin creating their own LLMs in the past two years).\nThis differential impact, wherein our release is\nexpected to benefit primarily people who have\nless funding and infrastructure, is a key factor\nin our decision to release this model publicly.\nWe ultimately believe that the benefits of releas-\ning this model outweigh the risks, but this argument\nhinges crucially on the particular circumstances\nof this release. All actors considering releasing\npowerful AI models or advancing the frontier of\ncapabilities should think carefully about what they\nrelease, in what way, and when.\nC.4 Environmental Impact\nA significant point of concern in some recent work\nis the energy usage and carbon emissions associ-\nated with training large language models (Strubell\net al., 2019; Schwartz et al., 2020; Lacoste et al.,\n2019; Bender et al., 2021). In particular, Strubell\net al. (2019) estimate that a then-recent paper by\nthe authors released 626,155 lbs or 284.01 met-\nric tons14 of CO2 (tCO2 ). As Strubell et al. (2019)\nhas been widely cited and quoted in the media as\nrepresentative of large-scale language models, we\ndecided to explicitly and carefully track our energy\nusage and carbon emissions to see if this is truly a\nrepresentative account of NLP emissions.\nThroughout the development and training of our\nmodel, we tracked our energy usage and carbon\nemissions. We found that the process of develop-\ning and training GPT-NeoX-20B emitted almost\nexactly 10% of Strubell et al. (2019)’s estimate,\ncoming in at a total of 69957 lbs or 31.73 met-\nric tons of CO2. This is roughly the equivalent of\nthe yearly emissions of the average American or\n35 round-trip flights between New York City and\nSan Francisco. Our systems were based in Illinois,\nUSA, and consumed energy sourced from the mix\nas follows\n• 30 .40% Coal (0.95tCO2 /MWh)\n• 31 .30% Gas (0.6078tCO2 /MWh)\n• 1 .30% Hydroelectric (0tCO2 /MWh)\n• 17 .40% Nuclear (0tCO2 /MWh)\n• 0 .30% Solar (0tCO2 /MWh)\n• 18 .10% Wind (0tCO2 /MWh)\n14We choose to present environmental impact figures in\nmetric tons to align with standard reporting.\n113\n• 1 .30% Other Renewables (0tCO2 /MWh)\nThis mixture produces an average of 0.47905\ntCO2 /MWh, and we consumed a total of\n43.92 MWh of electricity over the course of 1830\nhours of training. Scaling, testing, and evaluation\nwere responsible for the equivalent of another 920\nhours on our systems, for a total energy consump-\ntion 66.24 MWh and thus the production of just\nunder 35 metric tons of CO2.\nIt is noteworthy that Strubell et al. (2019) are\nestimating emissions from a neural architecture\nsearch paper, and is therefore not directly com-\nparable to ours. The primary motivation for our\ncomparison is that their number has attracted a lot\nof attention and is often taken to be respresenta-\ntive of NLP research. In general, we advocate for\nmore systematic and comprehensive reporting to\nimprove transparency surrounding this important\ntopic.\nD Architecture Diagram\nE Full Evaluation Results\nResults for natural language understanding tasks\nare shown in Tables 2 and 3, while results for\nHendrycks tasks are found in Tables 10 to 13.\nAll evaluations had version 0 in the Evaluation\nHarness. This information is reported in the output\nof the Evaluation Harness and should be used for\nensuring reproducibility of these results, even as\nthe task implementations themselves may change\nto fix bugs.\n114\nCPU0\nPLX PLX\nCPU1\nPLX PLX\nHCA0 HCA1 HCA2 HCA3\nGPU0 GPU1 GPU2 GPU3 GPU4 GPU5 GPU6 GPU7\nNVSwitch0 NVSwitch1 NVSwitch2 NVSwitch3 NVSwitch4 NVSwitch5\n2x\n16x 16x 16x 16x\n16x 16x 16x 16x\n4x\nSwitch0\n4x\nSwitch1\n4x\nSwitch0\n4x\nSwitch1\n16x 16x 16x 16x16x 16x 16x 16x\n16x\nHDR InfiniBand\n50 GT/s per lane\nPCI Express 4.0\n16 GT/s per lane\nxGMI-2\n16 GT/s per lane\nNVLink 3.0\n400 GT/s per lane\nFigure 7: Architecture diagram of a single training node.\nFigure 8: Zero-shot performance of GPT-NeoX-20B compared to GPT-J-6B and FairSeq and OpenAI models on a\nvariety of language modeling benchmarks.\n115\nFigure 9: Length-normalized zero-shot performance of GPT-NeoX-20B compared to GPT-J-6B and FairSeq and\nOpenAI models on a variety of language modeling benchmarks.\n116\nGPT-J GPT-NeoX GPT-3\nTask 6B 20B Ada Babbage Curie DaVinci\nANLI Round 1 0 .324 ±0.015 0 .340 ±0.015 0 .334 ±0.015 0 .326 ±0.015 0 .325 ±0.015 0 .363 ±0.015\nANLI Round 2 0 .340 ±0.015 0 .343 ±0.015 0 .342 ±0.015 0 .308 ±0.015 0 .338 ±0.015 0 .375 ±0.015\nANLI Round 3 0 .355 ±0.014 0 .354 ±0.014 0 .354 ±0.014 0 .340 ±0.014 0 .353 ±0.014 0 .369 ±0.014\nLAMBADA 0 .683 ±0.006 0 .720 ±0.006 0 .515 ±0.007 0 .625 ±0.007 0 .693 ±0.006 0 .752 ±0.006\nWSC 0 .365 ±0.047 0 .500 ±0.049 0 .375 ±0.048 0 .404 ±0.048 0 .548 ±0.049 0 .548 ±0.049\nHellaSwag 0 .518 ±0.005 0 .535 ±0.005 0 .359 ±0.005 0 .429 ±0.005 0 .505 ±0.005 0 .592 ±0.005\nWinogrande 0 .640 ±0.013 0 .661 ±0.013 0 .528 ±0.014 0 .594 ±0.014 0 .649 ±0.013 0 .699 ±0.013\nSciQ 0 .910 ±0.009 0 .928 ±0.008 0 .843 ±0.012 0 .866 ±0.011 0 .918 ±0.009 0 .949 ±0.007\nPIQA 0 .752 ±0.010 0 .779 ±0.010 0 .690 ±0.011 0 .745 ±0.010 0 .767 ±0.010 0 .791 ±0.009\nTriviaQA 0 .170 ±0.004 0 .259 ±0.004 0 .050 ±0.002 0 .115 ±0.003 0 .196 ±0.004 0 .409 ±0.005\nARC (Easy) 0 .670 ±0.010 0 .723 ±0.009 0 .514 ±0.010 0 .598 ±0.010 0 .682 ±0.010 0 .762 ±0.009\nARC (Challenge) 0 .340 ±0.014 0 .380 ±0.014 0 .225 ±0.012 0 .275 ±0.013 0 .334 ±0.014 0 .435 ±0.014\nOpenBookQA 0 .288 ±0.020 0 .290 ±0.020 0 .172 ±0.017 0 .224 ±0.019 0 .290 ±0.020 0 .336 ±0.021\nHeadQA (English) — — 0 .245 ±0.008 0 .278 ±0.009 0 .317 ±0.009 0 .356 ±0.009\nLogiQA 0 .209 ±0.016 0 .230 ±0.017 0 .218 ±0.016 0 .198 ±0.016 0 .217 ±0.016 0 .227 ±0.016\nPROST 0 .267 ±0.003 0 .296 ±0.003 0 .254 ±0.003 0 .270 ±0.003 0 .288 ±0.003 0 .267 ±0.003\nQA4MRE (2013) 0 .373 ±0.029 0 .363 ±0.029 0 .320 ±0.028 0 .370 ±0.029 0 .377 ±0.029 0 .426 ±0.029\nTable 2: Zero-Shot Results on Natural Language Understanding Tasks (GPT-J, GPT-NeoX and GPT-3)\n117\nFairSeq\nTask 125M 355M 1.3B 2.7B 6.7B 13B\nANLI Round 1 0 .316 ±0.015 0 .322 ±0.015 0 .331 ±0.015 0 .318 ±0.015 0 .338 ±0.015 0 .340 ±0.015\nANLI Round 2 0 .336 ±0.015 0 .312 ±0.015 0 .334 ±0.015 0 .339 ±0.015 0 .322 ±0.015 0 .330 ±0.015\nANLI Round 3 0 .330 ±0.014 0 .323 ±0.014 0 .333 ±0.014 0 .340 ±0.014 0 .333 ±0.014 0 .347 ±0.014\nLAMBADA 0 .388 ±0.007 0 .478 ±0.007 0 .562 ±0.007 0 .632 ±0.007 0 .673 ±0.007 0 .709 ±0.006\nWSC 0 .365 ±0.047 0 .471 ±0.049 0 .365 ±0.047 0 .635 ±0.047 0 .615 ±0.048 0 .577 ±0.049\nHellaSwag 0 .309 ±0.005 0 .380 ±0.005 0 .448 ±0.005 0 .493 ±0.005 0 .525 ±0.005 0 .554 ±0.005\nWinogrande 0 .513 ±0.014 0 .529 ±0.014 0 .600 ±0.014 0 .620 ±0.014 0 .644 ±0.013 0 .674 ±0.013\nSciQ 0 .732 ±0.014 0 .737 ±0.014 0 .838 ±0.012 0 .878 ±0.010 0 .895 ±0.010 0 .910 ±0.009\nPIQA 0 .668 ±0.011 0 .690 ±0.011 0 .731 ±0.010 0 .751 ±0.010 0 .762 ±0.010 0 .769 ±0.010\nTriviaQA 0 .015 ±0.001 0 .019 ±0.001 0 .078 ±0.003 0 .141 ±0.003 0 .221 ±0.004 0 .270 ±0.004\nARC (Easy) 0 .426 ±0.010 0 .468 ±0.010 0 .565 ±0.010 0 .625 ±0.010 0 .665 ±0.010 0 .680 ±0.010\nARC (Challenge) 0 .195 ±0.012 0 .233 ±0.012 0 .263 ±0.013 0 .296 ±0.013 0 .329 ±0.014 0 .345 ±0.014\nOpenBookQA 0 .168 ±0.017 0 .190 ±0.018 0 .238 ±0.019 0 .254 ±0.019 0 .292 ±0.020 0 .296 ±0.020\nHeadQA (English) 0 .233 ±0.008 0 .233 ±0.008 0 .256 ±0.008 0 .264 ±0.008 0 .280 ±0.009 0 .280 ±0.009\nLogiQA 0 .220 ±0.016 0 .230 ±0.017 0 .214 ±0.016 0 .212 ±0.016 0 .232 ±0.017 0 .240 ±0.017\nPROST 0 .215 ±0.003 0 .257 ±0.003 0 .257 ±0.003 0 .230 ±0.003 0 .272 ±0.003 0 .252 ±0.003\nQA4MRE (2013) 0 .285 ±0.027 0 .335 ±0.028 0 .327 ±0.028 0 .380 ±0.029 0 .370 ±0.029 0 .380 ±0.029\nTable 3: Zero-Shot Results on Natural Language Understanding Tasks (FairSeq Models)\n118\nGPT-J GPT-NeoX GPT-3\nTask 6B 20B Ada Babbage Curie DaVinci\nANLI Round 1 0 .322 ±0.015 0 .312 ±0.015 — — — —\nANLI Round 2 0 .331 ±0.015 0 .329 ±0.015 — — — —\nANLI Round 3 0 .346 ±0.014 0 .342 ±0.014 — — — —\nLAMBADA 0 .662 ±0.007 0 .698 ±0.006 — — — —\nWSC 0 .365 ±0.047 0 .385 ±0.048 — — — —\nHellaSwag 0 .494 ±0.005 0 .538 ±0.005 — — — —\nWinogrande 0 .660 ±0.013 0 .683 ±0.013 — — — —\nSciQ 0 .913 ±0.009 0 .960 ±0.006 — — — —\nPIQA 0 .756 ±0.010 0 .774 ±0.010 — — — —\nTriviaQA 0 .289 ±0.004 0 .347 ±0.004 — — — —\nARC (Challenge) 0 .360 ±0.014 0 .410 ±0.014 — — — —\nARC (Easy) 0 .705 ±0.009 0 .746 ±0.009 — — — —\nOpenBookQA 0 .310 ±0.021 0 .326 ±0.021 — — — —\nHeadQA (English) 0 .326 ±0.009 0 .385 ±0.009 — — — —\nLogiQA 0 .230 ±0.017 0 .220 ±0.016 — — — —\nQA4MRE (2013) 0 .366 ±0.029 0 .363 ±0.029 — — — —\nTable 4: Five-Shot Results on Natural Language Understanding Tasks (GPT-J and GPT-NeoX). GPT-3 is omitted due to financial limitations.\n119\nFairSeq\nTask 125M 355M 1.3B 2.7B 6.7B 13B\nANLI Round 1 0 .332 ±0.015 0 .336 ±0.015 0 .327 ±0.015 0 .336 ±0.015 0 .305 ±0.015 0 .335 ±0.015\nANLI Round 2 0 .345 ±0.015 0 .350 ±0.015 0 .347 ±0.015 0 .333 ±0.015 0 .340 ±0.015 0 .338 ±0.015\nANLI Round 3 0 .359 ±0.014 0 .347 ±0.014 0 .370 ±0.014 0 .326 ±0.014 0 .367 ±0.014 0 .357 ±0.014\nLAMBADA 0 .268 ±0.006 0 .349 ±0.007 0 .427 ±0.007 0 .460 ±0.007 0 .494 ±0.007 0 .518 ±0.007\nWSC 0 .365 ±0.047 0 .365 ±0.047 0 .365 ±0.047 0 .356 ±0.047 0 .500 ±0.049 0 .404 ±0.048\nHellaSwag 0 .308 ±0.005 0 .379 ±0.005 0 .451 ±0.005 0 .497 ±0.005 0 .531 ±0.005 0 .559 ±0.005\nWinogrande 0 .516 ±0.014 0 .538 ±0.014 0 .612 ±0.014 0 .633 ±0.014 0 .657 ±0.013 0 .690 ±0.013\nSciQ 0 .758 ±0.014 0 .819 ±0.012 0 .859 ±0.011 0 .875 ±0.010 0 .871 ±0.011 0 .899 ±0.010\nPIQA 0 .656 ±0.011 0 .700 ±0.011 0 .731 ±0.010 0 .750 ±0.010 0 .764 ±0.010 0 .769 ±0.010\nTriviaQA 0 .044 ±0.002 0 .097 ±0.003 0 .160 ±0.003 0 .225 ±0.004 0 .293 ±0.004 0 .323 ±0.004\nARC (Easy) 0 .453 ±0.010 0 .533 ±0.010 0 .618 ±0.010 0 .664 ±0.010 0 .686 ±0.010 0 .702 ±0.009\nARC (Challenge) 0 .198 ±0.012 0 .231 ±0.012 0 .278 ±0.013 0 .310 ±0.014 0 .359 ±0.014 0 .370 ±0.014\nOpenBookQA 0 .184 ±0.017 0 .206 ±0.018 0 .218 ±0.018 0 .258 ±0.020 0 .288 ±0.020 0 .290 ±0.020\nHeadQA (English) 0 .235 ±0.008 0 .240 ±0.008 0 .254 ±0.008 0 .266 ±0.008 0 .276 ±0.009 0 .282 ±0.009\nLogiQA 0 .218 ±0.016 0 .207 ±0.016 0 .210 ±0.016 0 .214 ±0.016 0 .214 ±0.016 0 .223 ±0.016\nQA4MRE (2013) 0 .324 ±0.028 0 .338 ±0.028 0 .338 ±0.028 0 .352 ±0.028 0 .391 ±0.029 0 .387 ±0.029\nTable 5: Five-Shot Results on Natural Language Understanding Tasks (FairSeq Models)\n120\nGPT-J GPT-NeoX GPT-3\nTask 6B 20B Ada Babbage Curie DaVinci\n1DC 0 .088 ±0.006 0 .098 ±0.007 0 .029 ±0.000 0 .001 ±0.000 0 .024 ±0.000 0 .098 ±0.000\n2D+ 0 .238 ±0.010 0 .570 ±0.011 0 .006 ±0.000 0 .009 ±0.000 0 .025 ±0.000 0 .769 ±0.000\n2Dx 0 .139 ±0.008 0 .148 ±0.008 0 .022 ±0.000 0 .021 ±0.000 0 .058 ±0.000 0 .198 ±0.000\n2D- 0 .216 ±0.009 0 .680 ±0.010 0 .013 ±0.000 0 .013 ±0.000 0 .076 ±0.000 0 .580 ±0.000\n3D+ 0 .088 ±0.006 0 .099 ±0.007 0 .001 ±0.000 0 .001 ±0.000 0 .003 ±0.000 0 .342 ±0.000\n3D- 0 .046 ±0.005 0 .344 ±0.011 0 .001 ±0.000 0 .001 ±0.000 0 .004 ±0.000 0 .483 ±0.000\n4D+ 0 .007 ±0.002 0 .007 ±0.002 0 .001 ±0.000 0 .000 ±0.000 0 .001 ±0.000 0 .040 ±0.000\n4D- 0 .005 ±0.002 0 .029 ±0.004 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .075 ±0.000\n5D+ 0 .001 ±0.001 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .006 ±0.000\n5D- 0 .000 ±0.000 0 .004 ±0.001 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .008 ±0.000\nMATH (Algebra) 0 .013 ±0.003 0 .010 ±0.003 0 .003 ±0.002 0 .008 ±0.003 0 .003 ±0.002 0 .008 ±0.003\nMATH (Counting and Probability) 0 .011 ±0.005 0 .017 ±0.006 0 .000 ±0.000 0 .004 ±0.003 0 .000 ±0.000 0 .006 ±0.004\nMATH (Geometry) 0 .004 ±0.003 0 .017 ±0.006 0 .000 ±0.000 0 .000 ±0.000 0 .002 ±0.002 0 .002 ±0.002\nMATH (Intermediate Algebra) 0 .004 ±0.002 0 .001 ±0.001 0 .000 ±0.000 0 .003 ±0.002 0 .006 ±0.002 0 .003 ±0.002\nMATH (Number Theory) 0 .007 ±0.004 0 .013 ±0.005 0 .007 ±0.004 0 .000 ±0.000 0 .006 ±0.003 0 .011 ±0.005\nMATH (Pre-Algebra) 0 .010 ±0.003 0 .018 ±0.005 0 .007 ±0.003 0 .006 ±0.003 0 .008 ±0.003 0 .014 ±0.004\nMATH (Pre-Calculus) 0 .005 ±0.003 0 .005 ±0.003 0 .004 ±0.003 0 .000 ±0.000 0 .002 ±0.002 0 .004 ±0.003\nTable 6: Zero-Shot Results on Basic Arithmetic and MATH (GPT-J, GPT-NeoX, and GPT-3)\n121\nFairSeq\nTask 125M 355M 1.3B 2.7B 6.7B 13B\n1DC 0 .001 ±0.001 0 .000 ±0.000 0 .000 ±0.000 0 .011 ±0.002 0 .024 ±0.003 0 .001 ±0.001\n2D+ 0 .005 ±0.002 0 .001 ±0.001 0 .002 ±0.001 0 .009 ±0.002 0 .019 ±0.003 0 .020 ±0.003\n2Dx 0 .020 ±0.003 0 .004 ±0.001 0 .018 ±0.003 0 .023 ±0.003 0 .036 ±0.004 0 .028 ±0.004\n2D- 0 .005 ±0.002 0 .002 ±0.001 0 .006 ±0.002 0 .013 ±0.002 0 .013 ±0.003 0 .015 ±0.003\n3D+ 0 .001 ±0.001 0 .001 ±0.001 0 .001 ±0.001 0 .001 ±0.001 0 .001 ±0.001 0 .001 ±0.001\n3D- 0 .002 ±0.001 0 .001 ±0.001 0 .002 ±0.001 0 .002 ±0.001 0 .002 ±0.001 0 .002 ±0.001\n4D+ 0 .001 ±0.001 0 .000 ±0.000 0 .001 ±0.001 0 .001 ±0.001 0 .001 ±0.001 0 .001 ±0.001\n4D- 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000\n5D+ 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000\n5D- 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000\nMATH (Algebra) 0 .000 ±0.000 0 .000 ±0.000 0 .001 ±0.001 0 .003 ±0.002 0 .004 ±0.002 0 .003 ±0.001\nMATH (Counting and Probability) 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .004 ±0.003 0 .000 ±0.000\nMATH (Geometry) 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .002 ±0.002 0 .000 ±0.000 0 .000 ±0.000\nMATH (Intermediate Algebra) 0 .000 ±0.002 0 .000 ±0.002 0 .000 ±0.000 0 .001 ±0.001 0 .006 ±0.002 0 .002 ±0.002\nMATH (Number Theory) 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .002 ±0.002 0 .000 ±0.000 0 .004 ±0.003\nMATH (Pre-Algebra) 0 .000 ±0.000 0 .000 ±0.000 0 .003 ±0.002 0 .002 ±0.002 0 .001 ±0.001 0 .000 ±0.000\nMATH (Pre-Calculus) 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .002 ±0.002 0 .000 ±0.000 0 .000 ±0.000\nTable 7: Zero-Shot Results on Basic Arithmetic and MATH (FairSeq Models)\n122\nGPT-J GPT-NeoX GPT-3\nTask 6B 20B Ada Babbage Curie DaVinci\n1DC 0 .192 ±0.009 0 .191 ±0.009 — — — —\n2D+ 0 .880 ±0.007 0 .992 ±0.002 — — — —\n2Dx 0 .282 ±0.010 0 .452 ±0.011 — — — —\n2D- 0 .817 ±0.009 0 .942 ±0.005 — — — —\n3D+ 0 .357 ±0.011 0 .599 ±0.011 — — — —\n3D- 0 .497 ±0.011 0 .819 ±0.009 — — — —\n4D+ 0 .058 ±0.005 0 .152 ±0.008 — — — —\n4D- 0 .092 ±0.006 0 .151 ±0.008 — — — —\n5D+ 0 .009 ±0.002 0 .033 ±0.004 — — — —\n5D- 0 .021 ±0.003 0 .059 ±0.005 — — — —\nMATH (Algebra) 0 .032 ±0.005 0 .049 ±0.006 — — — —\nMATH (Counting and Probability) 0 .036 ±0.009 0 .030 ±0.008 — — — —\nMATH (Geometry) 0 .027 ±0.007 0 .015 ±0.005 — — — —\nMATH (Intermediate Algebra) 0 .024 ±0.005 0 .021 ±0.005 — — — —\nMATH (Number Theory) 0 .044 ±0.009 0 .065 ±0.011 — — — —\nMATH (Pre-Algebra) 0 .052 ±0.008 0 .057 ±0.008 — — — —\nMATH (Pre-Calculus) 0 .013 ±0.005 0 .027 ±0.007 — — — —\nTable 8: Five-Shot Results on Basic Arithmetic and MATH (GPT-J and GPT-NeoX). GPT-3 is omitted due to financial limitations.\n123\nFairSeq\nTask 125M 355M 1.3B 2.7B 6.7B 13B\n1DC 0 .019 ±0.003 0 .024 ±0.003 0 .029 ±0.004 0 .032 ±0.004 0 .046 ±0.005 0 .046 ±0.005\n2D+ 0 .005 ±0.002 0 .004 ±0.001 0 .006 ±0.002 0 .029 ±0.004 0 .034 ±0.004 0 .051 ±0.005\n2Dx 0 .001 ±0.001 0 .025 ±0.004 0 .025 ±0.003 0 .025 ±0.003 0 .049 ±0.005 0 .053 ±0.005\n2D- 0 .007 ±0.002 0 .011 ±0.002 0 .008 ±0.002 0 .013 ±0.003 0 .018 ±0.003 0 .030 ±0.004\n3D+ 0 .002 ±0.001 0 .002 ±0.001 0 .001 ±0.001 0 .003 ±0.001 0 .001 ±0.001 0 .003 ±0.001\n3D- 0 .002 ±0.001 0 .004 ±0.001 0 .003 ±0.001 0 .003 ±0.001 0 .002 ±0.001 0 .003 ±0.001\n4D+ 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000\n4D- 0 .001 ±0.001 0 .000 ±0.000 0 .000 ±0.000 0 .001 ±0.001 0 .000 ±0.000 0 .000 ±0.000\n5D+ 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000\n5D- 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000 0 .000 ±0.000\nMATH (Algebra) 0 .023 ±0.004 0 .010 ±0.003 0 .013 ±0.003 0 .014 ±0.003 0 .017 ±0.004 0 .012 ±0.003\nMATH (Counting and Probability) 0 .008 ±0.004 0 .004 ±0.003 0 .015 ±0.006 0 .017 ±0.006 0 .015 ±0.006 0 .017 ±0.006\nMATH (Geometry) 0 .000 ±0.000 0 .013 ±0.005 0 .006 ±0.004 0 .015 ±0.005 0 .015 ±0.005 0 .006 ±0.004\nMATH (Intermediate Algebra) 0 .010 ±0.003 0 .002 ±0.002 0 .007 ±0.003 0 .010 ±0.003 0 .011 ±0.003 0 .004 ±0.002\nMATH (Number Theory) 0 .019 ±0.006 0 .009 ±0.004 0 .007 ±0.004 0 .011 ±0.005 0 .028 ±0.007 0 .019 ±0.006\nMATH (Pre-Algebra) 0 .013 ±0.004 0 .008 ±0.003 0 .010 ±0.003 0 .011 ±0.004 0 .021 ±0.005 0 .013 ±0.004\nMATH (Pre-Calculus) 0 .002 ±0.002 0 .002 ±0.002 0 .004 ±0.003 0 .000 ±0.000 0 .002 ±0.002 0 .000 ±0.000\nTable 9: Five-Shot Results on Basic Arithmetic and MATH (FairSeq Models)\n124\nFigure 10: Zero-shot performance of GPT-NeoX-20B compared to GPT-J-6B and FairSeq and OpenAI models on\nHendrycks et al. (2021a).\nFigure 11: Five-shot performance of GPT-NeoX-20B compared to GPT-J-6B and FairSeq and OpenAI models on\nHendrycks et al. (2021a). API limits we were unable to evaluate on the OpenAI API. Instead, we report numbers\nfrom Hendrycks et al. (2021a) with model sizes corrected.\n125\nGPT-J GPT-NeoX GPT-3\nTask 6B 20B Ada Babbage Curie DaVinci\nAbstract Algebra 0 .260 ±0.044 0 .230 ±0.042 0 .170 ±0.038 0 .220 ±0.042 0 .220 ±0.042 0 .220 ±0.042\nAnatomy 0 .274 ±0.039 0 .319 ±0.040 0 .207 ±0.035 0 .289 ±0.039 0 .274 ±0.039 0 .348 ±0.041\nAstronomy 0 .243 ±0.035 0 .329 ±0.038 0 .237 ±0.035 0 .211 ±0.033 0 .237 ±0.035 0 .382 ±0.040\nBusiness Ethics 0 .290 ±0.046 0 .280 ±0.045 0 .360 ±0.048 0 .330 ±0.047 0 .300 ±0.046 0 .390 ±0.049\nClinical Knowledge 0 .272 ±0.027 0 .291 ±0.028 0 .223 ±0.026 0 .234 ±0.026 0 .253 ±0.027 0 .317 ±0.029\nCollege Biology 0 .285 ±0.038 0 .271 ±0.037 0 .271 ±0.037 0 .299 ±0.038 0 .208 ±0.034 0 .347 ±0.040\nCollege Chemistry 0 .240 ±0.043 0 .160 ±0.037 0 .270 ±0.045 0 .290 ±0.046 0 .210 ±0.041 0 .250 ±0.044\nCollege Computer Science 0 .270 ±0.045 0 .250 ±0.044 0 .310 ±0.046 0 .270 ±0.045 0 .240 ±0.043 0 .260 ±0.044\nCollege Mathematics 0 .260 ±0.044 0 .240 ±0.043 0 .220 ±0.042 0 .160 ±0.037 0 .200 ±0.040 0 .170 ±0.038\nCollege Medicine 0 .197 ±0.030 0 .283 ±0.034 0 .237 ±0.032 0 .202 ±0.031 0 .225 ±0.032 0 .289 ±0.035\nCollege Physics 0 .206 ±0.040 0 .284 ±0.045 0 .304 ±0.046 0 .324 ±0.047 0 .255 ±0.043 0 .235 ±0.042\nComputer Security 0 .270 ±0.045 0 .290 ±0.046 0 .250 ±0.044 0 .240 ±0.043 0 .320 ±0.047 0 .350 ±0.048\nConceptual Physics 0 .255 ±0.029 0 .294 ±0.030 0 .264 ±0.029 0 .260 ±0.029 0 .268 ±0.029 0 .294 ±0.030\nEconometrics 0 .237 ±0.040 0 .289 ±0.043 0 .289 ±0.043 0 .246 ±0.040 0 .246 ±0.040 0 .228 ±0.039\nElectrical Engineering 0 .359 ±0.040 0 .303 ±0.038 0 .338 ±0.039 0 .276 ±0.037 0 .310 ±0.039 0 .414 ±0.041\nElementary Mathematics 0 .254 ±0.022 0 .283 ±0.023 0 .243 ±0.022 0 .272 ±0.023 0 .249 ±0.022 0 .312 ±0.024\nFormal Logic 0 .341 ±0.042 0 .294 ±0.041 0 .262 ±0.039 0 .349 ±0.043 0 .270 ±0.040 0 .294 ±0.041\nGlobal Facts 0 .250 ±0.044 0 .220 ±0.042 0 .240 ±0.043 0 .240 ±0.043 0 .300 ±0.046 0 .290 ±0.046\nHigh School Biology 0 .252 ±0.025 0 .300 ±0.026 0 .235 ±0.024 0 .232 ±0.024 0 .271 ±0.025 0 .335 ±0.027\nHigh School Chemistry 0 .202 ±0.028 0 .236 ±0.030 0 .246 ±0.030 0 .241 ±0.030 0 .197 ±0.028 0 .232 ±0.030\nHigh School Computer Science 0 .250 ±0.044 0 .210 ±0.041 0 .190 ±0.039 0 .240 ±0.043 0 .220 ±0.042 0 .290 ±0.046\nHigh School European History 0 .261 ±0.034 0 .255 ±0.034 0 .224 ±0.033 0 .285 ±0.035 0 .261 ±0.034 0 .303 ±0.036\nHigh School Geography 0 .202 ±0.029 0 .227 ±0.030 0 .217 ±0.029 0 .207 ±0.029 0 .242 ±0.031 0 .348 ±0.034\nHigh School Government and Politics 0 .228 ±0.030 0 .228 ±0.030 0 .212 ±0.030 0 .181 ±0.028 0 .212 ±0.030 0 .326 ±0.034\nHigh School Macroeconomics 0 .285 ±0.023 0 .328 ±0.024 0 .272 ±0.023 0 .277 ±0.023 0 .277 ±0.023 0 .303 ±0.023\nHigh School Mathematics 0 .219 ±0.025 0 .263 ±0.027 0 .196 ±0.024 0 .230 ±0.026 0 .167 ±0.023 0 .248 ±0.026\nTable 10: Zero-Shot Results on Hendrycks Tasks, Part 1 (GPT-J, GPT-NeoX and GPT-3)\n126\nGPT-J GPT-NeoX GPT-3\nTask 6B 20B Ada Babbage Curie DaVinci\nHigh School Microeconomics 0 .277 ±0.029 0 .294 ±0.030 0 .235 ±0.028 0 .265 ±0.029 0 .239 ±0.028 0 .307 ±0.030\nHigh School Physics 0 .272 ±0.036 0 .298 ±0.037 0 .199 ±0.033 0 .298 ±0.037 0 .199 ±0.033 0 .219 ±0.034\nHigh School Physiology 0 .273 ±0.019 0 .283 ±0.019 0 .209 ±0.017 0 .217 ±0.018 0 .246 ±0.018 0 .352 ±0.020\nHigh School Statistics 0 .292 ±0.031 0 .319 ±0.032 0 .241 ±0.029 0 .278 ±0.031 0 .255 ±0.030 0 .278 ±0.031\nHigh School US History 0 .289 ±0.032 0 .309 ±0.032 0 .255 ±0.031 0 .260 ±0.031 0 .240 ±0.030 0 .368 ±0.034\nHigh School World History 0 .283 ±0.029 0 .295 ±0.030 0 .278 ±0.029 0 .262 ±0.029 0 .270 ±0.029 0 .321 ±0.030\nHuman Aging 0 .265 ±0.030 0 .224 ±0.028 0 .368 ±0.032 0 .336 ±0.032 0 .296 ±0.031 0 .327 ±0.031\nHuman Sexuality 0 .397 ±0.043 0 .405 ±0.043 0 .374 ±0.042 0 .427 ±0.043 0 .397 ±0.043 0 .481 ±0.044\nInternational Law 0 .264 ±0.040 0 .298 ±0.042 0 .182 ±0.035 0 .207 ±0.037 0 .207 ±0.037 0 .331 ±0.043\nJurisprudence 0 .278 ±0.043 0 .250 ±0.042 0 .287 ±0.044 0 .278 ±0.043 0 .259 ±0.042 0 .370 ±0.047\nLogical Fallacies 0 .294 ±0.036 0 .227 ±0.033 0 .239 ±0.034 0 .221 ±0.033 0 .245 ±0.034 0 .252 ±0.034\nMachine Learning 0 .223 ±0.040 0 .268 ±0.042 0 .241 ±0.041 0 .286 ±0.043 0 .295 ±0.043 0 .232 ±0.040\nManagement 0 .233 ±0.042 0 .282 ±0.045 0 .184 ±0.038 0 .214 ±0.041 0 .320 ±0.046 0 .456 ±0.049\nMarketing 0 .303 ±0.030 0 .321 ±0.031 0 .308 ±0.030 0 .282 ±0.029 0 .308 ±0.030 0 .491 ±0.033\nMedical Genetics 0 .310 ±0.046 0 .340 ±0.048 0 .260 ±0.044 0 .300 ±0.046 0 .330 ±0.047 0 .430 ±0.050\nMiscellaneous 0 .275 ±0.016 0 .299 ±0.016 0 .257 ±0.016 0 .269 ±0.016 0 .284 ±0.016 0 .450 ±0.018\nMoral Disputes 0 .283 ±0.024 0 .289 ±0.024 0 .263 ±0.024 0 .263 ±0.024 0 .277 ±0.024 0 .301 ±0.025\nMoral Scenarios 0 .237 ±0.014 0 .232 ±0.014 0 .238 ±0.014 0 .273 ±0.015 0 .238 ±0.014 0 .249 ±0.014\nNutrition 0 .346 ±0.027 0 .379 ±0.028 0 .301 ±0.026 0 .281 ±0.026 0 .291 ±0.026 0 .353 ±0.027\nPhilosophy 0 .260 ±0.025 0 .293 ±0.026 0 .215 ±0.023 0 .267 ±0.025 0 .244 ±0.024 0 .367 ±0.027\nPrehistory 0 .244 ±0.024 0 .272 ±0.025 0 .244 ±0.024 0 .269 ±0.025 0 .284 ±0.025 0 .324 ±0.026\nProfessional Accounting 0 .262 ±0.026 0 .234 ±0.025 0 .202 ±0.024 0 .255 ±0.026 0 .238 ±0.025 0 .287 ±0.027\nProfessional Law 0 .241 ±0.011 0 .267 ±0.011 0 .261 ±0.011 0 .256 ±0.011 0 .259 ±0.011 0 .261 ±0.011\nProfessional Medicine 0 .276 ±0.027 0 .287 ±0.027 0 .221 ±0.025 0 .239 ±0.026 0 .265 ±0.027 0 .324 ±0.028\nProfessional Psychology 0 .284 ±0.018 0 .275 ±0.018 0 .245 ±0.017 0 .225 ±0.017 0 .257 ±0.018 0 .335 ±0.019\nPublic Relations 0 .282 ±0.043 0 .345 ±0.046 0 .255 ±0.042 0 .327 ±0.045 0 .364 ±0.046 0 .364 ±0.046\nSecurity Studies 0 .363 ±0.031 0 .376 ±0.031 0 .367 ±0.031 0 .347 ±0.030 0 .384 ±0.031 0 .392 ±0.031\nSociology 0 .279 ±0.032 0 .284 ±0.032 0 .328 ±0.033 0 .303 ±0.033 0 .274 ±0.032 0 .368 ±0.034\nUS Foreign Policy 0 .340 ±0.048 0 .360 ±0.048 0 .330 ±0.047 0 .330 ±0.047 0 .380 ±0.049 0 .500 ±0.050\nVirology 0 .355 ±0.037 0 .361 ±0.037 0 .307 ±0.036 0 .319 ±0.036 0 .337 ±0.037 0 .386 ±0.038\nWorld Religions 0 .333 ±0.036 0 .386 ±0.037 0 .316 ±0.036 0 .310 ±0.035 0 .374 ±0.037 0 .398 ±0.038\nTable 11: Zero-Shot Results on Hendrycks Tasks, Part 2 (GPT-J, GPT-NeoX, and GPT-3)\n127\nFairSeq\nTask 125M 355M 1.3B 2.7B 6.7B 13B\nAbstract Algebra 0 .260 ±0.044 0 .180 ±0.039 0 .230 ±0.042 0 .250 ±0.044 0 .240 ±0.043 0 .260 ±0.044\nAnatomy 0 .178 ±0.033 0 .207 ±0.035 0 .185 ±0.034 0 .170 ±0.032 0 .259 ±0.038 0 .237 ±0.037\nAstronomy 0 .270 ±0.036 0 .237 ±0.035 0 .243 ±0.035 0 .263 ±0.036 0 .296 ±0.037 0 .257 ±0.036\nBusiness Ethics 0 .330 ±0.047 0 .410 ±0.049 0 .340 ±0.048 0 .350 ±0.048 0 .380 ±0.049 0 .340 ±0.048\nClinical Knowledge 0 .215 ±0.025 0 .264 ±0.027 0 .226 ±0.026 0 .249 ±0.027 0 .223 ±0.026 0 .264 ±0.027\nCollege Biology 0 .285 ±0.038 0 .201 ±0.034 0 .243 ±0.036 0 .222 ±0.035 0 .271 ±0.037 0 .306 ±0.039\nCollege Chemistry 0 .310 ±0.046 0 .290 ±0.046 0 .350 ±0.048 0 .300 ±0.046 0 .280 ±0.045 0 .240 ±0.043\nCollege Computer Science 0 .200 ±0.040 0 .250 ±0.044 0 .260 ±0.044 0 .250 ±0.044 0 .300 ±0.046 0 .280 ±0.045\nCollege Mathematics 0 .190 ±0.039 0 .170 ±0.038 0 .230 ±0.042 0 .200 ±0.040 0 .230 ±0.042 0 .250 ±0.044\nCollege Medicine 0 .243 ±0.033 0 .237 ±0.032 0 .249 ±0.033 0 .254 ±0.033 0 .237 ±0.032 0 .260 ±0.033\nCollege Physics 0 .216 ±0.041 0 .245 ±0.043 0 .216 ±0.041 0 .275 ±0.044 0 .343 ±0.047 0 .216 ±0.041\nComputer Security 0 .240 ±0.043 0 .290 ±0.046 0 .300 ±0.046 0 .240 ±0.043 0 .230 ±0.042 0 .320 ±0.047\nConceptual Physics 0 .260 ±0.029 0 .255 ±0.029 0 .247 ±0.028 0 .243 ±0.028 0 .247 ±0.028 0 .204 ±0.026\nEconometrics 0 .246 ±0.040 0 .272 ±0.042 0 .246 ±0.040 0 .281 ±0.042 0 .219 ±0.039 0 .263 ±0.041\nElectrical Engineering 0 .283 ±0.038 0 .303 ±0.038 0 .234 ±0.035 0 .276 ±0.037 0 .310 ±0.039 0 .290 ±0.038\nElementary Mathematics 0 .246 ±0.022 0 .214 ±0.021 0 .233 ±0.022 0 .233 ±0.022 0 .246 ±0.022 0 .198 ±0.021\nFormal Logic 0 .278 ±0.040 0 .302 ±0.041 0 .278 ±0.040 0 .310 ±0.041 0 .286 ±0.040 0 .333 ±0.042\nGlobal Facts 0 .200 ±0.040 0 .210 ±0.041 0 .190 ±0.039 0 .150 ±0.036 0 .220 ±0.042 0 .160 ±0.037\nHigh School Biology 0 .248 ±0.025 0 .255 ±0.025 0 .268 ±0.025 0 .226 ±0.024 0 .274 ±0.025 0 .235 ±0.024\nHigh School Chemistry 0 .217 ±0.029 0 .207 ±0.029 0 .256 ±0.031 0 .281 ±0.032 0 .217 ±0.029 0 .266 ±0.031\nHigh School Computer Science 0 .240 ±0.043 0 .230 ±0.042 0 .270 ±0.045 0 .240 ±0.043 0 .350 ±0.048 0 .280 ±0.045\nHigh School European History 0 .230 ±0.033 0 .333 ±0.037 0 .279 ±0.035 0 .261 ±0.034 0 .273 ±0.035 0 .230 ±0.033\nHigh School Geography 0 .263 ±0.031 0 .273 ±0.032 0 .222 ±0.030 0 .258 ±0.031 0 .207 ±0.029 0 .253 ±0.031\nHigh School Government and Politics 0 .254 ±0.031 0 .290 ±0.033 0 .228 ±0.030 0 .233 ±0.031 0 .218 ±0.030 0 .187 ±0.028\nHigh School Macroeconomics 0 .200 ±0.020 0 .272 ±0.023 0 .254 ±0.022 0 .269 ±0.022 0 .326 ±0.024 0 .256 ±0.022\nHigh School Mathematics 0 .204 ±0.025 0 .189 ±0.024 0 .170 ±0.023 0 .226 ±0.025 0 .200 ±0.024 0 .193 ±0.024\nTable 12: Zero-Shot Results on Hendrycks Tasks, Part 1 (FairSeq Models)\n128\nFairSeq\nTask 125M 355M 1.3B 2.7B 6.7B 13B\nHigh School Microeconomics 0 .248 ±0.028 0 .256 ±0.028 0 .244 ±0.028 0 .248 ±0.028 0 .269 ±0.029 0 .227 ±0.027\nHigh School Physics 0 .238 ±0.035 0 .219 ±0.034 0 .258 ±0.036 0 .245 ±0.035 0 .232 ±0.034 0 .166 ±0.030\nHigh School Physiology 0 .235 ±0.018 0 .272 ±0.019 0 .266 ±0.019 0 .284 ±0.019 0 .250 ±0.019 0 .261 ±0.019\nHigh School Statistics 0 .222 ±0.028 0 .241 ±0.029 0 .269 ±0.030 0 .250 ±0.030 0 .287 ±0.031 0 .241 ±0.029\nHigh School US History 0 .240 ±0.030 0 .284 ±0.032 0 .299 ±0.032 0 .299 ±0.032 0 .314 ±0.033 0 .294 ±0.032\nHigh School World History 0 .283 ±0.029 0 .232 ±0.027 0 .270 ±0.029 0 .245 ±0.028 0 .300 ±0.030 0 .316 ±0.030\nHuman Aging 0 .274 ±0.030 0 .309 ±0.031 0 .323 ±0.031 0 .291 ±0.031 0 .296 ±0.031 0 .274 ±0.030\nHuman Sexuality 0 .252 ±0.038 0 .366 ±0.042 0 .328 ±0.041 0 .359 ±0.042 0 .359 ±0.042 0 .351 ±0.042\nInternational Law 0 .157 ±0.033 0 .223 ±0.038 0 .240 ±0.039 0 .281 ±0.041 0 .264 ±0.040 0 .231 ±0.038\nJurisprudence 0 .241 ±0.041 0 .269 ±0.043 0 .287 ±0.044 0 .241 ±0.041 0 .213 ±0.040 0 .278 ±0.043\nLogical Fallacies 0 .196 ±0.031 0 .221 ±0.033 0 .233 ±0.033 0 .196 ±0.031 0 .245 ±0.034 0 .221 ±0.033\nMachine Learning 0 .232 ±0.040 0 .295 ±0.043 0 .348 ±0.045 0 .232 ±0.040 0 .259 ±0.042 0 .241 ±0.041\nManagement 0 .223 ±0.041 0 .311 ±0.046 0 .214 ±0.041 0 .291 ±0.045 0 .340 ±0.047 0 .262 ±0.044\nMarketing 0 .295 ±0.030 0 .231 ±0.028 0 .286 ±0.030 0 .303 ±0.030 0 .333 ±0.031 0 .329 ±0.031\nMedical Genetics 0 .250 ±0.044 0 .310 ±0.046 0 .310 ±0.046 0 .280 ±0.045 0 .270 ±0.045 0 .300 ±0.046\nMiscellaneous 0 .258 ±0.016 0 .301 ±0.016 0 .264 ±0.016 0 .249 ±0.015 0 .284 ±0.016 0 .268 ±0.016\nMoral Disputes 0 .269 ±0.024 0 .246 ±0.023 0 .220 ±0.022 0 .260 ±0.024 0 .269 ±0.024 0 .272 ±0.024\nMoral Scenarios 0 .255 ±0.015 0 .236 ±0.014 0 .273 ±0.015 0 .238 ±0.014 0 .241 ±0.014 0 .253 ±0.015\nNutrition 0 .252 ±0.025 0 .261 ±0.025 0 .297 ±0.026 0 .297 ±0.026 0 .330 ±0.027 0 .304 ±0.026\nPhilosophy 0 .199 ±0.023 0 .219 ±0.023 0 .228 ±0.024 0 .222 ±0.024 0 .238 ±0.024 0 .270 ±0.025\nPrehistory 0 .290 ±0.025 0 .222 ±0.023 0 .253 ±0.024 0 .228 ±0.023 0 .296 ±0.025 0 .235 ±0.024\nProfessional Accounting 0 .262 ±0.026 0 .220 ±0.025 0 .209 ±0.024 0 .170 ±0.022 0 .238 ±0.025 0 .266 ±0.026\nProfessional Law 0 .261 ±0.011 0 .261 ±0.011 0 .256 ±0.011 0 .256 ±0.011 0 .259 ±0.011 0 .261 ±0.011\nProfessional Medicine 0 .239 ±0.026 0 .254 ±0.026 0 .254 ±0.026 0 .206 ±0.025 0 .221 ±0.025 0 .195 ±0.024\nProfessional Psychology 0 .245 ±0.017 0 .247 ±0.017 0 .242 ±0.017 0 .248 ±0.017 0 .278 ±0.018 0 .252 ±0.018\nPublic Relations 0 .236 ±0.041 0 .245 ±0.041 0 .264 ±0.042 0 .227 ±0.040 0 .291 ±0.044 0 .291 ±0.044\nSecurity Studies 0 .322 ±0.030 0 .331 ±0.030 0 .331 ±0.030 0 .335 ±0.030 0 .408 ±0.031 0 .359 ±0.031\nSociology 0 .234 ±0.030 0 .234 ±0.030 0 .259 ±0.031 0 .229 ±0.030 0 .234 ±0.030 0 .323 ±0.033\nUS Foreign Policy 0 .250 ±0.044 0 .300 ±0.046 0 .300 ±0.046 0 .310 ±0.046 0 .370 ±0.049 0 .330 ±0.047\nVirology 0 .289 ±0.035 0 .301 ±0.036 0 .319 ±0.036 0 .355 ±0.037 0 .295 ±0.036 0 .331 ±0.037\nWorld Religions 0 .292 ±0.035 0 .263 ±0.034 0 .287 ±0.035 0 .292 ±0.035 0 .269 ±0.034 0 .339 ±0.036\nTable 13: Zero-shot Results on Hendrycks Tasks, Part 2 (FairSeq Models)\n129\nF Tokenizer Analysis\nBoth tokenizers share 36938 out of 50257 tokens, a ∼73.5% overlap in tokens. In this section, we perform\ncomparison between the GPT-NeoX-20B tokenizer to the GPT-2 tokenizer using the validation set of the\nPile.\nIn Table 15, we show the resulting number of tokens from tokenizing each component of the Pile’s\nvalidation set with both tokenizers, and the ratio of GPT-NeoX-20B tokens to GPT-2 tokens.\nWe observe that the GPT-NeoX-20B tokenizer represents all Pile components using fewer or very\nclosely comparable numbers of tokens. The largest percentage improvement in token counts are in the\nEuroParl, GitHub, and PubMed Central components, with a more than 20% savings in the number of\ntokens needed to represent that component. We highlight that arXiv, GitHub, and StackExchange—subsets\nwith large code components—can be represented with meaningfully fewer tokens with the GPT-NeoX-20B\ntokenizer compared to the GPT-2 tokenizer. Overall, the GPT-NeoX-20B tokenizer represents the Pile\nvalidation set with approximately 10% fewer tokens compared to the GPT-2 tokenizer.\nGiven that the GPT-NeoX-20B tokenizer is tweaked to better tokenize whitespace, we also perform a\ncomparison between the two tokenizers excluding whitespace. We perform the same analysis as the above,\nbut exclude all whitespace tokens from our computations, only counting the non-whitespace tokens. A\ntoken is considered a whitespace token if it consists only of whitespace characters. The results are shown\nin Table 16 in the Appendix. We observe that the GPT-NeoX-20B tokenizer still uses 5% fewer tokens to\nrepresent the Pile validation set compared to the GPT-2 tokenizer. As expected, the token ratios for certain\ncomponents such as GitHub and StackExchange become closer to even once the whitespace characters\nare excluded.\nGPT-2 GPT-NeoX-20BGPT-NeoX-20BGPT-2\nPile (val) 383,111,734 342,887,807 0.89501\nC4 173,669,294 173,768,876 1.001\nC4 excl. Space 168,932,391 171,003,008 1.012\nTable 14: Number of tokens from tokenizing the AllenAI C4 (en) validation set. The GPT-NeoX-20B tokenizer\nuses approximately the same number of tokens to represent C4 as the GPT-2 tokenizer.\nWhile we evaluated our tokenizer using the validation set for the Pile, the Pile components would still\nbe considered in-domain for the tokenizer and may not provide the most informative comparison point.\nTo perform an out-of-domain comparison, we perform the same analysis using the AllenAI replication of\nC4,15, another popular pretraining corpus for large language models. As above, we use the validation set\nfor our analysis. Our results are shown in Table 14. We find that the GPT-NeoX-20B tokenizer tokenizes\nthe C4 validation set to approximately the same number of tokens as the GPT-2 tokenizer. When excluding\nall whitespace tokens, the GPT-NeoX-20B requires approximately 1% more tokens to represent the corpus\ncompared to the GPT-2 tokenizer.\nF.1 Tokenizer Comparisons\nF.1.1 Longest Tokens\nWe show in Table 17 the 10 longest tokens in each tokenizer vocabulary. We exclude consideration of\ntokens that comprise only symbols or whitespace characters. We observe that for the GPT-2 tokenizer,\nmany of the longest tokens appear to reflect artifacts in the tokenizer training data, likely with certain\nwebsites or web-scrapes being overrepresented in the training data. For the GPT-NeoX-20B tokenizer, we\nobserve that most of the longest tokens are scientific terms, likely arising from the PubMed components\nof the Pile.\nF.1.2 Worst Case Word Tokenization Comparison\nWe consider the words for which there is the greatest discrepancy in the resulting token length between\nthe two tokenizers, where one tokenizer needs many tokens to represent while the other tokenizer uses\n15https://github.com/allenai/allennlp/discussions/5056\n130\nGPT-2 GPT-NeoX-20BGPT-NeoX-20BGPT-2\narXiv 41,020,155 34,704,315 0.84603\nBookCorpus2 2,336,388 2,365,633 1.01252\nBooks3 42,819,036 43,076,832 1.00602\nDM Mathematics 7,699,527 7,413,775 0.96289\nEnron Emails 480,500 433,867 0.90295\nEuroParl 3,519,584 2,808,275 0.79790\nFreeLaw 21,098,168 18,687,364 0.88573\nGitHub 42,986,216 33,021,839 0.76820\nGutenberg (PG-19) 6,729,187 6,428,946 0.95538\nHackerNews 2,578,933 2,551,720 0.98945\nNIH ExPorter 776,688 739,558 0.95219\nOpenSubtitles 5,431,529 5,446,485 1.00275\nOpenWebText2 31,993,480 30,813,744 0.96313\nPhilPapers 1,879,206 1,750,928 0.93174\nPile-CC 53,415,704 53,392,389 0.99956\nPubMed Abstracts 8,708,180 8,215,529 0.94343\nPubMed Central 56,874,247 43,534,166 0.76545\nStackExchange 22,708,643 19,000,198 0.83669\nUSPTO Backgrounds 10,217,886 9,727,223 0.95198\nUbuntu IRC 3,341,287 2,771,066 0.82934\nWikipedia (en) 12,614,087 12,692,048 1.00618\nYoutubeSubtitles 3,883,103 3,311,907 0.85290\nTotal 383,111,734 342,887,807 0.89501\nTable 15: Number of tokens from tokenizing the Pile validation set. The GPT-NeoX-20B tokenizer uses fewer\ntokens to represent the Pile overall, with the biggest gains in whitespace heavy datasets such as arXiv, GitHub and\nStackExchange.\nGPT-2 GPT-NeoX-20BGPT-NeoX-20BGPT-2\narXiv 38,932,524 33,561,364 0.86204\nBookCorpus2 2,233,367 2,262,609 1.01309\nBooks3 40,895,236 41,198,424 1.00741\nDM Mathematics 7,214,874 6,929,066 0.96039\nEnron Emails 374,978 373,498 0.99605\nEuroParl 3,482,120 2,780,405 0.79848\nFreeLaw 17,766,692 17,434,708 0.98131\nGitHub 29,338,176 27,558,966 0.93936\nGutenberg (PG-19) 5,838,580 5,827,408 0.99809\nHackerNews 2,312,116 2,299,848 0.99469\nNIH ExPorter 776,619 739,543 0.95226\nOpenSubtitles 5,428,118 5,445,721 1.00324\nOpenWebText2 30,849,218 29,723,143 0.96350\nPhilPapers 1,872,347 1,743,627 0.93125\nPile-CC 51,305,080 51,281,909 0.99955\nPubMed Abstracts 8,676,790 8,185,417 0.94337\nPubMed Central 44,508,570 40,722,151 0.91493\nStackExchange 17,414,955 16,712,814 0.95968\nUSPTO Backgrounds 9,882,473 9,601,385 0.97156\nUbuntu IRC 3,220,797 2,659,225 0.82564\nWikipedia (en) 11,874,878 11,986,567 1.00941\nYoutubeSubtitles 3,589,042 3,046,451 0.84882\nTotal 337,787,550 322,074,249 0.95348\nTable 16: Number of tokens from tokenizing the Pile validation set, excluding whitespace tokens.\nrelatively few tokens. We define a word as a contiguous string delimited by whitespace or punctuation\n(as defined by strings.punctuationin Python). We perform this analysis at the component level. We\nonly consider words that occur at least 10 times within the given component. We show in Table 18 a\nrepresentative example from the Pile-CC corpus.\nG Tokenization Examples\nIn Figures 12 and 17, we show examples of tokenized documents from the Pile, comparing the GPT-2\ntokenizer to ours.\n131\nGPT-2 GPT-NeoX-20B\nrawdownloadcloneembedreportprint˙Gimmunohistochemistry\nBuyableInstoreAndOnline ˙Gimmunohistochemical\ncloneembedreportprint ˙Gtelecommunications\n˙GRandomRedditorWithNo ˙Gimmunofluorescence\n˙Gtelecommunications ˙Gimmunosuppressive\nchannelAvailability ˙GBytePtrFromString\n˙Gdisproportionately ˙Gmultidisciplinary\n˙GTelecommunications ˙Ghistopathological\n˙GguiActiveUnfocused ˙Gneurodegenerative\nItemThumbnailImage ˙Gindistinguishable\nTable 17: Ten longest tokens (excluding tokens comprising mainly symbols, numbers and spaces) in tokenizer\nvocabularies. “ ˙G” indicates a word delimiter.\nGPT-2 Worst-case Tokenization\nWord GPT-2 Tokenization GPT-NeoX-20B Tokenization\nhematopoietic (6) hematopoietic (1)hematopoieticadenocarcinoma (6)adenocarcinoma (1)adenocarcinomaMERCHANTABILITY (5)MERCHANTABILITY(1)MERCHANTABILITYCONSEQUENTIAL (5)CONSEQUENTIAL (1)CONSEQUENTIALoligonucleotides (5)oligonucleotides(1)oligonucleotidescytoplasmic (5) cytoplasmic (1)cytoplasmiccorticosteroids (4) corticosteroids (1)corticosteroidsneurodegenerative (4)neurodegenerative(1)neurodegenerativeasymptotic (4) asymptotic (1)asymptoticaneurysm (4) aneurysm (1)aneurysm\nGPT-NeoX-20B Worst-case Tokenization\nWord GPT-2 Tokenization GPT-NeoX-20B Tokenization\nSchwarzenegger (1)Schwarzenegger(5)SchwarzeneggerBolshevik (1) Bolshevik (4)Bolshevikcrowdfunding (1)crowdfunding(4)crowdfundingmisogyny (1) misogyny (4)misogynyMcAuliffe (1) McAuliffe (4)McAuliffeunstoppable (1)unstoppable(4)unstoppableTimberwolves (1)Timberwolves(4)Timberwolvesexcruciating (1)excruciating(4)excruciatingKaepernick (1)Kaepernick(4)KaepernickValkyrie (1) Valkyrie (4)Valkyrie\nTable 18: Worst case word tokenization with respective tokenizers. We show cases where one tokenizer requires\nmany more tokens to represent a word compared to the other tokenizer.\nGPT-2 Tokenization\n253 tokens\n–-←↩\nabstract: ’The maximal minors of a $p\\times (m + p)$-matrix of univariate polynomials of degree\n$n$ with indeterminate coefficients are themselves polynomials of degree $np$. The subalgebra\ngenerated by their coefficients is the coordinate ring of the quantum Grassmannian, a singular\ncompactification of the space of rational curves of degree $np$ in the Grassmannian of $p$-\nplanes in ($m + p$)-space. These subalgebra generators are shown to form a sagbi basis. The\nresulting flat deformation from the quantum Grassmannian to a toric variety gives a new “Grö\nbner basis style” proof of the Ravi-Rosenthal-Wang formulas in quantum Schubert calculus. The\ncoordinate ring of the quantum Grassmannian is an algebra with straightening law, which is\nnormal, Cohen-Macaulay, Gorenstein and Koszul, and the ideal of quantum Plücker relations has a\nquadratic Gröbner basis. This holds more generally for skew quantum Schubert varieties. These\nresults are well-known for the classical Schubert varietie\nGPT-NeoX-20B Tokenization\n229 tokens\n–-←↩\nabstract: ’The maximal minors of a $p\\times (m + p)$-matrix of univariate polynomials of degree\n$n$ with indeterminate coefficients are themselves polynomials of degree $np$. The subalgebra\ngenerated by their coefficients is the coordinate ring of the quantum Grassmannian, a singular\ncompactification of the space of rational curves of degree $np$ in the Grassmannian of $p$-\nplanes in ($m + p$)-space. These subalgebra generators are shown to form a sagbi basis. The\nresulting flat deformation from the quantum Grassmannian to a toric variety gives a new “Grö\nbner basis style” proof of the Ravi-Rosenthal-Wang formulas in quantum Schubert calculus. The\ncoordinate ring of the quantum Grassmannian is an algebra with straightening law, which is\nnormal, Cohen-Macaulay, Gorenstein and Koszul, and the ideal of quantum Plücker relations has a\nquadratic Gröbner basis. This holds more generally for skew quantum Schubert varieties. These\nresults are well-known for the classical Schubert varietie\nFigure 12: Pile (arXiv) Tokenization Example\n132\nGPT-2 Tokenization\n224 tokens\n←↩\n←↩\n**THE TRAP**←↩\n←↩\nBeverley Kendall←↩\n←↩\nCopyright © Beverley Kendall 2014←↩\n←↩\nPublished by Season Publishing LLC←↩\n←↩\nThis is a work of fiction. Names, characters, places and incidents are products of the author\n’s imagination or are used fictitiously and are not to be construed as real. Any resemblance to\nactual events, locales, organizations, or persons, living or dead, is completely coincidental.\n←↩←↩\nwww.beverleykendall.com←↩←↩\nCover Design © Okay Creations, Sarah Hansen←↩←↩\nAll rights reserved. Except as permitted under the U.S. Copyright Act of 1976, no part of this\npublication may be reproduced, distributed or transmitted in any form or by any means, or\nstored in a database or retrieval system, without the prior written permission of the author\n.←↩\n←↩\n** License Statement **←↩\n←↩\nThis ebook is licensed for your personal enjoyment only. This ebook may not be re-sold or given\naway to other people. If you would like to share this book with another person, please purchase\nan additional copy for each reader. If\nGPT-NeoX-20B Tokenization\n228 tokens\n←↩\n←↩\n**THE TRAP**←↩\n←↩\nBeverley Kendall←↩\n←↩\nCopyright © Beverley Kendall 2014←↩\n←↩\nPublished by Season Publishing LLC←↩\n←↩\nThis is a work of fiction. Names, characters, places and incidents are products of the author\n’s imagination or are used fictitiously and are not to be construed as real. Any resemblance to\nactual events, locales, organizations, or persons, living or dead, is completely coincidental.\n←↩←↩\nwww.beverleykendall.com←↩←↩\nCover Design © Okay Creations, Sarah Hansen←↩←↩\nAll rights reserved. Except as permitted under the U.S. Copyright Act of 1976, no part of this\npublication may be reproduced, distributed or transmitted in any form or by any means, or\nstored in a database or retrieval system, without the prior written permission of the author\n.←↩\n←↩\n** License Statement **←↩\n←↩\nThis ebook is licensed for your personal enjoyment only. This ebook may not be re-sold or given\naway to other people. If you would like to share this book with another person, please purchase\nan additional copy for each reader. If\nFigure 13: Pile (BookCorpus2) Tokenization Example\n133\nGPT-2 Tokenization\n477 tokens\no?←↩\nTrue←↩\nSuppose -3*t = 1 + 8. Let s(d) = d**3 + 6*d**2 + 2*d + 1. Let u be s(t). Suppose 10 = 5*z, 5*a +\n0*z = -z + u. Is 4 a factor of a?←↩\nTrue←↩\nSuppose 5*l = r - 35, -2*r + 5*l - 15 = -70. Is r a multiple of 4?←↩\nTrue←↩\nSuppose 2*l + 11 - 1 = 0. Does 15 divide (-2)/l - 118/(-5)?←↩\nFalse←↩\nSuppose 3*k - 3*f + 0*f - 72 = 0, -25 = -5*f. Is 9 a factor of 2/(-4) + k/2?←↩\nFalse←↩\nSuppose 6*w + 25 = w. Let t(c) = c + 9. Let u be t(w). Suppose -u*z = -3*z - 10. Is z a multiple\nof 5?←↩\nTrue←↩\nLet j = 81 + -139. Let i = j + 101. Is 11 a factor of i?←↩\nFalse←↩\nLet q(s) = s**3 + 4*s**2 - s + 2. Let u be q(-4). Let o(w) = w**2 + w - 6. Let t be o(u).\nSuppose -3*l - 39 = -3*d - 2*l, 0 = 3*d - 2*l - t. Does 9 divide d?←↩\nFalse←↩\nSuppose -2*b + 39 + 13 = 0. Is b a multiple of 14?←↩\nFalse←↩\nLet q = -7 + 12. Suppose 8*l = q*l + 81. Suppose 129 = 4*f - l. Is 13 a factor of f?←↩\nTrue←↩\nSuppose 0 = -4*n + j + 33, 4*n - n + 4*j = 20. Let c = 5 - n. Is 35*1 - (-6)/c a multiple of 11?\n←↩\nTrue←↩\nLet g(m) = m**2 - 2*m - 3. Let k be g(3). Let j be\nGPT-NeoX-20B Tokenization\n468 tokens\no?←↩\nTrue←↩\nSuppose -3*t = 1 + 8. Let s(d) = d**3 + 6*d**2 + 2*d + 1. Let u be s(t). Suppose 10 = 5*z, 5*a +\n0*z = -z + u. Is 4 a factor of a?←↩\nTrue←↩\nSuppose 5*l = r - 35, -2*r + 5*l - 15 = -70. Is r a multiple of 4?←↩\nTrue←↩\nSuppose 2*l + 11 - 1 = 0. Does 15 divide (-2)/l - 118/(-5)?←↩\nFalse←↩\nSuppose 3*k - 3*f + 0*f - 72 = 0, -25 = -5*f. Is 9 a factor of 2/(-4) + k/2?←↩\nFalse←↩\nSuppose 6*w + 25 = w. Let t(c) = c + 9. Let u be t(w). Suppose -u*z = -3*z - 10. Is z a multiple\nof 5?←↩\nTrue←↩\nLet j = 81 + -139. Let i = j + 101. Is 11 a factor of i?←↩\nFalse←↩\nLet q(s) = s**3 + 4*s**2 - s + 2. Let u be q(-4). Let o(w) = w**2 + w - 6. Let t be o(u).\nSuppose -3*l - 39 = -3*d - 2*l, 0 = 3*d - 2*l - t. Does 9 divide d?←↩\nFalse←↩\nSuppose -2*b + 39 + 13 = 0. Is b a multiple of 14?←↩\nFalse←↩\nLet q = -7 + 12. Suppose 8*l = q*l + 81. Suppose 129 = 4*f - l. Is 13 a factor of f?←↩\nTrue←↩\nSuppose 0 = -4*n + j + 33, 4*n - n + 4*j = 20. Let c = 5 - n. Is 35*1 - (-6)/c a multiple of 11?\n←↩\nTrue←↩\nLet g(m) = m**2 - 2*m - 3. Let k be g(3). Let j be\nFigure 14: Pile (DM Mathematics) Tokenization Example\n134\nGPT-2 Tokenization\n430 tokens\n<at-dialog title=\"vm.title\" on-close=\"vm.onClose\">←↩\n<at-form state=\"vm.form\" autocomplete=\"off\" id=\"external_test_form\">←↩\n<at-input-group col=\"12\" tab=\"20\" state=\"vm.form.inputs\" form-id=\"external_test\"></at-\ninput-group>←↩\n<at-action-group col=\"12\" pos=\"right\">←↩\n<at-action-button←↩\nvariant=\"tertiary\"←↩\nng-click=\"vm.onClose()\"←↩\n>←↩\n::vm.strings.get(’CLOSE’)←↩\n</at-action-button>←↩\n<at-action-button←↩\nvariant=\"primary\"←↩\nng-click=\"vm.onSubmit()\"←↩\nng-disabled=\"!vm.form.isValid || vm.form.disabled\"←↩\n>←↩\n::vm.strings.get(’RUN’)←↩\n</at-action-button>←↩\n</at-action-group>←↩\n</at-form>←↩\n</at-dialog>←↩\nGPT-NeoX-20B Tokenization\n257 tokens\n<at-dialog title=\"vm.title\" on-close=\"vm.onClose\">←↩\n<at-form state=\"vm.form\" autocomplete=\"off\" id=\"external_test_form\">←↩\n<at-input-group col=\"12\" tab=\"20\" state=\"vm.form.inputs\" form-id=\"external_test\"></at-\ninput-group>←↩\n<at-action-group col=\"12\" pos=\"right\">←↩\n<at-action-button←↩\nvariant=\"tertiary\"←↩\nng-click=\"vm.onClose()\"←↩\n>←↩\n::vm.strings.get(’CLOSE’)←↩\n</at-action-button>←↩\n<at-action-button←↩\nvariant=\"primary\"←↩\nng-click=\"vm.onSubmit()\"←↩\nng-disabled=\"!vm.form.isValid || vm.form.disabled\"←↩\n>←↩\n::vm.strings.get(’RUN’)←↩\n</at-action-button>←↩\n</at-action-group>←↩\n</at-form>←↩\n</at-dialog>←↩\nFigure 15: Pile (GitHub) Tokenization Example\n135\nGPT-2 Tokenization\n178 tokens\nTheresa May is expected to appoint an EU ambassador who “believes in Brexit” in the wake of the\ncurrent Brussels representative’s decision to quit after being cut adrift by Downing Street.\n←↩\n←↩\nSir Ivan Rogers on Tuesday announced his resignation as Britain’s ambassador in Brussels after\nit was made clear Mrs May and her senior team had “lost confidence” in him over his “pessim\nistic” view of Brexit.←↩\n←↩\nGovernment sources made clear that Sir Ivan had “jumped before he was pushed” and that Number\n10 believed his negative view of Brexit meant that he could not lead the negotiations after the\nPrime Minister triggers Article 50.←↩\n←↩\nIn a 1,400-word resignation letter to his staff leaked on Tuesday night, Sir Ivan launched a\nthinly-veiled attack on the \"muddled thinking\" in Mrs May’s Government.\nGPT-NeoX-20B Tokenization\n170 tokens\nTheresa May is expected to appoint an EU ambassador who “believes in Brexit” in the wake of the\ncurrent Brussels representative’s decision to quit after being cut adrift by Downing Street.\n←↩\n←↩\nSir Ivan Rogers on Tuesday announced his resignation as Britain’s ambassador in Brussels after\nit was made clear Mrs May and her senior team had “lost confidence” in him over his “pessim\nistic” view of Brexit.←↩\n←↩\nGovernment sources made clear that Sir Ivan had “jumped before he was pushed” and that Number\n10 believed his negative view of Brexit meant that he could not lead the negotiations after the\nPrime Minister triggers Article 50.←↩\n←↩\nIn a 1,400-word resignation letter to his staff leaked on Tuesday night, Sir Ivan launched a\nthinly-veiled attack on the \"muddled thinking\" in Mrs May’s Government.\nFigure 16: Pile (OpenWebText2) Tokenization Example\nGPT-2 Tokenization\n268 tokens\nCarotid endarterectomy: operative risks, recurrent stenosis, and long-term stroke rates in a\nmodern series.←↩\nTo determine whether carotid endarterectomy (CEA) safely and effectively maintained a durable\nreduction in stroke complications over an extended period, we reviewed our data on 478\nconsecutive patients who underwent 544 CEA’s since 1976. Follow-up was complete in 83% of\npatients (mean 44 months). There were 7 early deaths (1.3%), only 1 stroke related (0.2%). Peri\noperative stroke rates (overall 2.9%) varied according to operative indications: asymptomatic, 1\n.4%; transient ischemic attacks (TIA)/amaurosis fugax (AF), 1.3%; nonhemispheric symptoms (NH),\n4.9%; and prior stroke (CVA), 7.1%. Five and 10-year stroke-free rates were 96% and 92% in the\nasymptomatic group, 93% and 87% in the TIA/AF group, 92% and 92% in the NH group, and 80% and\n73% in the CVA group. Late ipsilateral strokes occurred infrequently (8 patients, 1.7%). Late\ndeaths were primarily cardiac related (51.3%). Stro\nGPT-NeoX-20B Tokenization\n250 tokens\nCarotid endarterectomy: operative risks, recurrent stenosis, and long-term stroke rates in a\nmodern series.←↩\nTo determine whether carotid endarterectomy (CEA) safely and effectively maintained a durable\nreduction in stroke complications over an extended period, we reviewed our data on 478\nconsecutive patients who underwent 544 CEA’s since 1976. Follow-up was complete in 83% of\npatients (mean 44 months). There were 7 early deaths (1.3%), only 1 stroke related (0.2%). Peri\noperative stroke rates (overall 2.9%) varied according to operative indications: asymptomatic, 1\n.4%; transient ischemic attacks (TIA)/amaurosis fugax (AF), 1.3%; nonhemispheric symptoms (NH),\n4.9%; and prior stroke (CVA), 7.1%. Five and 10-year stroke-free rates were 96% and 92% in the\nasymptomatic group, 93% and 87% in the TIA/AF group, 92% and 92% in the NH group, and 80% and\n73% in the CVA group. Late ipsilateral strokes occurred infrequently (8 patients, 1.7%). Late\ndeaths were primarily cardiac related (51.3%). Stro\nFigure 17: Pile (PubMed Abstracts) Tokenization Example\n136"
}