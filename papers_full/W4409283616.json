{
    "title": "Towards accurate differential diagnosis with large language models",
    "url": "https://openalex.org/W4409283616",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2008753996",
            "name": "Daniel McDuff",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2610220628",
            "name": "Mike Schaekermann",
            "affiliations": [
                "Google (Canada)"
            ]
        },
        {
            "id": "https://openalex.org/A2022297018",
            "name": "Tao Tu",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A4280861290",
            "name": "Anil Palepu",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2097263443",
            "name": "Amy Wang",
            "affiliations": [
                "Google (Canada)"
            ]
        },
        {
            "id": "https://openalex.org/A2765727025",
            "name": "Jake Garrison",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2648811907",
            "name": "Karan Singhal",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2124638133",
            "name": "Yash Sharma",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2487747927",
            "name": "Shekoofeh Azizi",
            "affiliations": [
                "Google (Canada)"
            ]
        },
        {
            "id": "https://openalex.org/A2510846730",
            "name": "Kavita Kulkarni",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2129280759",
            "name": "Hou Le",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A304022700",
            "name": "Yong Cheng",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A1977837230",
            "name": "Yun Liu",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A4310521441",
            "name": "S. Sara Mahdavi",
            "affiliations": [
                "Google (Canada)"
            ]
        },
        {
            "id": "https://openalex.org/A2405588340",
            "name": "Sushant Prakash",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2160310171",
            "name": "Anupam Pathak",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2570691504",
            "name": "Christopher Semturs",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A3135869407",
            "name": "Shwetak Patel",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2101079242",
            "name": "Dale R. Webster",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A182304653",
            "name": "Ewa Dominowska",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A3154221470",
            "name": "Juraj Gottweis",
            "affiliations": [
                "Google (Switzerland)"
            ]
        },
        {
            "id": "https://openalex.org/A4295939685",
            "name": "Joëlle Barral",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2183901161",
            "name": "Katherine Chou",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A1994222016",
            "name": "Greg S. Corrado",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A1874579918",
            "name": "Yossi Matias",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A5109687586",
            "name": "Jake Sunshine",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2305091355",
            "name": "Alan Karthikesalingam",
            "affiliations": [
                "Google (United Kingdom)"
            ]
        },
        {
            "id": "https://openalex.org/A2137429286",
            "name": "Vivek Natarajan",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2008753996",
            "name": "Daniel McDuff",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2610220628",
            "name": "Mike Schaekermann",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2022297018",
            "name": "Tao Tu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4280861290",
            "name": "Anil Palepu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2097263443",
            "name": "Amy Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2765727025",
            "name": "Jake Garrison",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2648811907",
            "name": "Karan Singhal",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2124638133",
            "name": "Yash Sharma",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2487747927",
            "name": "Shekoofeh Azizi",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2510846730",
            "name": "Kavita Kulkarni",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2129280759",
            "name": "Hou Le",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A304022700",
            "name": "Yong Cheng",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1977837230",
            "name": "Yun Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4310521441",
            "name": "S. Sara Mahdavi",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2405588340",
            "name": "Sushant Prakash",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2160310171",
            "name": "Anupam Pathak",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2570691504",
            "name": "Christopher Semturs",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3135869407",
            "name": "Shwetak Patel",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2101079242",
            "name": "Dale R. Webster",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A182304653",
            "name": "Ewa Dominowska",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3154221470",
            "name": "Juraj Gottweis",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4295939685",
            "name": "Joëlle Barral",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2183901161",
            "name": "Katherine Chou",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1994222016",
            "name": "Greg S. Corrado",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1874579918",
            "name": "Yossi Matias",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5109687586",
            "name": "Jake Sunshine",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2305091355",
            "name": "Alan Karthikesalingam",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2137429286",
            "name": "Vivek Natarajan",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4380730209",
        "https://openalex.org/W17682891",
        "https://openalex.org/W3025011581",
        "https://openalex.org/W3014301887",
        "https://openalex.org/W4323030608",
        "https://openalex.org/W4377121468",
        "https://openalex.org/W4308760226",
        "https://openalex.org/W4384918448",
        "https://openalex.org/W4384071683",
        "https://openalex.org/W4360891289",
        "https://openalex.org/W4388525110",
        "https://openalex.org/W4388585663",
        "https://openalex.org/W4409283601",
        "https://openalex.org/W2013473976",
        "https://openalex.org/W1968181674",
        "https://openalex.org/W4308759651",
        "https://openalex.org/W4367189613",
        "https://openalex.org/W4296954185",
        "https://openalex.org/W4245062343",
        "https://openalex.org/W4379259189",
        "https://openalex.org/W4392044798",
        "https://openalex.org/W3121368818",
        "https://openalex.org/W4387780672",
        "https://openalex.org/W2981869278",
        "https://openalex.org/W4200191097",
        "https://openalex.org/W3196053885",
        "https://openalex.org/W3130937151",
        "https://openalex.org/W2217768243",
        "https://openalex.org/W2970837303",
        "https://openalex.org/W4385571050",
        "https://openalex.org/W4384561684",
        "https://openalex.org/W2396881363",
        "https://openalex.org/W3162922479",
        "https://openalex.org/W2164777277",
        "https://openalex.org/W4311642023",
        "https://openalex.org/W3105070630"
    ],
    "abstract": "Abstract A comprehensive differential diagnosis is a cornerstone of medical care that is often reached through an iterative process of interpretation that combines clinical history, physical examination, investigations and procedures. Interactive interfaces powered by large language models present new opportunities to assist and automate aspects of this process 1 . Here we introduce the Articulate Medical Intelligence Explorer (AMIE), a large language model that is optimized for diagnostic reasoning, and evaluate its ability to generate a differential diagnosis alone or as an aid to clinicians. Twenty clinicians evaluated 302 challenging, real-world medical cases sourced from published case reports. Each case report was read by two clinicians, who were randomized to one of two assistive conditions: assistance from search engines and standard medical resources; or assistance from AMIE in addition to these tools. All clinicians provided a baseline, unassisted differential diagnosis prior to using the respective assistive tools. AMIE exhibited standalone performance that exceeded that of unassisted clinicians (top-10 accuracy 59.1% versus 33.6%, P = 0.04). Comparing the two assisted study arms, the differential diagnosis quality score was higher for clinicians assisted by AMIE (top-10 accuracy 51.7%) compared with clinicians without its assistance (36.1%; McNemar’s test: 45.7, P &lt; 0.01) and clinicians with search (44.4%; McNemar’s test: 4.75, P = 0.03). Further, clinicians assisted by AMIE arrived at more comprehensive differential lists than those without assistance from AMIE. Our study suggests that AMIE has potential to improve clinicians’ diagnostic reasoning and accuracy in challenging cases, meriting further real-world evaluation for its ability to empower physicians and widen patients’ access to specialist-level expertise.",
    "full_text": "Nature | Vol 642 | 12 June 2025 | 451\nArticle\nT owards accurate differential diagnosis with \nlarge language models\nDaniel McDuff1,10 ✉, Mike Schaekermann2,10 ✉, Tao Tu3,10, Anil Palepu4,10, Amy Wang2, \nJake Garrison1, Karan Singhal3, Yash Sharma4, Shekoofeh Azizi5, Kavita Kulkarni4, Le Hou4, \nYong Cheng6, Yun Liu4, S. Sara Mahdavi5, Sushant Prakash3, Anupam Pathak4, \nChristopher Semturs4, Shwetak Patel1, Dale R. Webster4, Ewa Dominowska1, Juraj Gottweis7, \nJoelle Barral8, Katherine Chou4, Greg S. Corrado4, Yossi Matias4, Jake Sunshine1,11 ✉, \nAlan Karthikesalingam9,11 ✉ & Vivek Natarajan4,11 ✉\nA comprehensive differential diagnosis is a cornerstone of medical care that is often \nreached through an iterative process of interpretation that combines clinical history, \nphysical examination, investigations and procedures. Interactive interfaces powered \nby large language models present new opportunities to assist and automate aspects \nof this process1. Here we introduce the Articulate Medical Intelligence Explorer \n(AMIE), a large language model that is optimized for diagnostic reasoning, and \nevaluate its ability to generate a differential diagnosis alone or as an aid to clinicians. \nTwenty clinicians evaluated 302 challenging, real-world medical cases sourced from \npublished case reports. Each case report was read by two clinicians, who were \nrandomized to one of two assistive conditions: assistance from search engines and \nstandard medical resources; or assistance from AMIE in addition to these tools. All \nclinicians provided a baseline, unassisted differential diagnosis prior to using the \nrespective assistive tools. AMIE exhibited standalone performance that exceeded that \nof unassisted clinicians (top-10 accuracy 59.1% versus 33.6%, P = 0.04). Comparing the \ntwo assisted study arms, the differential diagnosis quality score was higher for \nclinicians assisted by AMIE (top-10 accuracy 51.7%) compared with clinicians without \nits assistance (36.1%; McNemar’s test: 45.7, P < 0.01) and clinicians with search (44.4%; \nMcNemar’s test: 4.75, P = 0.03). Further, clinicians assisted by AMIE arrived at more \ncomprehensive differential lists than those without assistance from AMIE. Our study \nsuggests that AMIE has potential to improve clinicians’ diagnostic reasoning and \naccuracy in challenging cases, meriting further real-world evaluation for its ability to \nempower physicians and widen patients’ access to specialist-level expertise.\nAn accurate diagnosis is a critical component of effective medical \ncare. Building artificial intelligence (AI) systems that are capable of \nperforming or assisting clinicians in this important task has been a \nlong-standing grand challenge 2. Whereas prior focus has been on \nevaluating a machine’s ability to accurately output a diagnosis 1,3–5, \nreal-world clinical practice involves an iterative and interactive process \nof reasoning about a differential diagnosis (DDx), weighing multiple \ndiagnostic possibilities in the light of increasing amounts of clinical \ninformation over time. Deep learning has been applied to promising \neffect for generating DDx in a number of specialties including radiol-\nogy4, ophthalmology5 and dermatology3, but such systems lack the \ninteractive capabilities to fluently assist a user through communication \nin natural language.\nThe emergence of large language models (LLMs) presents an oppor-\ntunity to design novel interactive tools and interfaces to aid DDx. These \nmodels have demonstrated the ability to perform complex language \ncomprehension and reasoning tasks, generating coherent text and \nthereby enabling a large variety of real-world applications6–9. Both \ngeneral-purpose LLMs (GPT-4) and medical domain-specialized LLMs \n(Med-PaLM 2) have demonstrated strong performance in standardized \nand multiple-choice medical benchmarks10,11. Such evaluations repre-\nsent a natural starting point for probing the model’s medical knowledge \nand capabilities but do not measure utility in real-world scenarios for \ncare delivery—for example, in challenging medical cases faced by trained \nphysicians. It is also not obvious how these models might actively \nassist clinicians in the development of a DDx. Recent work has begun \nto assess the standalone performance of these models on challenging \ncase reports that involve complex deduction and diagnosis1,12–14, but \nhas stopped short of evaluating how they can assist clinicians, augment \nperformance and empower them to provide better care.\nhttps://doi.org/10.1038/s41586-025-08869-4\nReceived: 19 January 2024\nAccepted: 25 February 2025\nPublished online: 9 April 2025\nOpen access\n Check for updates\n1Google Research, Seattle, WA, USA. 2Google Research, Toronto, Ontario, Canada. 3Google Research, New York City, NY, USA. 4Google Research, Mountain View, CA, USA. 5Google DeepMind, \nToronto, Ontario, Canada. 6Google DeepMind, Mountain View, CA, USA. 7Google Research, Zurich, Switzerland. 8Google DeepMind, Paris, France. 9Google Research, London, UK. 10These \nauthors contributed equally: Daniel McDuff, Mike Schaekermann, Tao Tu, Anil Palepu. 11These authors jointly supervised this work: Jake Sunshine, Alan Karthikesalingam and Vivek Natarajan. \n✉e-mail: dmcduff@google.com; mikeshake@google.com; jakesunshine@google.com; alankarthi@google.com; natviv@google.com\n452 | Nature | Vol 642 | 12 June 2025\nArticle\nHere we introduce AMIE, an LLM that is optimized for clinical diag-\nnostic reasoning to generate a DDx for challenging, real-world medical \ncases. Beyond measuring standalone performance, we integrated this \nmodel into an interactive interface to measure how well AMIE could assist \nclinicians in developing a DDx. Using a set of challenging real-world case \nreports from the New England Journal of Medicine (NEJM) clinicopatho-\nlogical conferences (CPCs), we compared clinicians’ ability to form a DDx \nwith the assistance of AMIE versus with access to traditional information \nretrieval tools (such as internet searches and books). AMIE achieved \nimpressive performance in both generating DDx lists that contained \nthe correct diagnosis (top-10 accuracy) and in identifying the correct \nfinal diagnosis as the most likely in the list (top-1 accuracy). Under auto-\nmated model-based evaluation, the quality and the accuracy of the DDx \nlist produced by AMIE was found to be significantly better than the \nstate-of-the-art GPT-4 model available at the time of the experiments1. \nPerhaps more importantly, AMIE also improved the diagnostic capa-\nbility of clinicians as measured by the quality of their DDx lists for the \nevaluated cases. LLMs optimized for the safety-critical medical domain \nsuch as ours present a novel paradigm for assisting clinicians because \nof the potential for variation in the ways in which a given individual \nmay converse with the system and utilize it in collaborative reasoning.\nA detailed explanation of the cases, their components, how they \nwere fed to the model, the randomization scheme of AMIE versus the \nstandard practice and information on the expert raters of the model \nand how the outputs were evaluated by blind expert raters, can be \nfound in Methods.\nIn evaluating the quality of the DDx lists we used several criteria, \ninspired by the approach taken in ref. 1 and extended to draw additional \ninsight from the clinicians. First, we measured whether the final diagnosis \nmatched an entry in the DDx list and in which position (top-n accuracy). \nSecond, we used the quality score from Bond et al.15 and created appro-\npriateness and comprehensiveness scales. Combined, these measures \nassess overall DDx quality, appropriateness and comprehensiveness.\nWhen using AMIE for assistance, clinicians asked, on average (mean), \n2.92 questions in the interface (median 2, interquartile range (IQR) 1–4). \nOn average (mean), clinician questions consisted of 9.39 words (median \n10, IQR 6–12) and 54.31 characters (median 61, IQR 39-63). AMIE’s \nresponses, on average (mean), consisted of 237.60 words (median \n198, IQR 127–332) and 1,540.81 characters (median 1,276; IQR 815–2210).\nIn the Search condition, the most popular tools were UpT oDate (used \nin 34% of tasks), Google Search (30%) and PubMed (22%). Although \nclinicians were allowed to use additional tools in the AMIE condition, \nthis was far less frequent (less than 5% of tasks).\nDDx performance of AMIE\nThe DDx lists produced by our language model achieved strong quality, \nappropriateness and comprehensiveness scores (see Fig. 1). The median \n5\n 4\n 3\n 2\n 1Score:\nThe correct\ndiagnosis\nSomething\nvery close to the\ncorrect diagnosis\nSomething\nthat might have\nbeen helpful\nSomething that\nis related, but\nunlikely to be\nhelpful\nNothing related\nto the correct\ndiagnosis\nDDx contains:\n4\n 3\n 2\n 1\nThe DDx contains all\ncandidates that\nare reasonable\nThe DDx contains\nmost of the\ncandidates but some\nare missing\nThe DDx contains some\nof the candidates but\na number are missing\nThe DDx has\nmajor candidates\nmissing\nQuality score: inclusion of the /f_inal diagnosis\n165 174\n127\n104\n70\n82 83 89 48\n88 105 39\n62 97 39\n52 105 18\n24 91 13\n142\n121 53 55 32 41\n3539697881\n103 67 55 32 45\n62 55 23 20\n69 33 20 15\nComprehensiveness score\nAppropriateness score\n5\n 4\n 3\n 2\n 1\nVery\nappropriate\nVery\ninappropriate\na\nc\nb\nAMIE only\nClinician assisted\nby AMIE\nClinician assisted\nby Search\nClinician unassisted\n(AMIE condition)\nClinician unassisted\n(Search condition)\nAMIE only\nClinician assisted\nby AMIE\nClinician assisted\nby Search\nClinician unassisted\n(AMIE condition)\nClinician unassisted\n(Search condition)\n180 72 31 8 9\n9204693132\n107\n86\n102 73 74 42\n97 84 24\n81 70 34 8\n9\n9\nFig. 1 | Evaluation of the quality of DDx lists from generalist physicians. a, DDx \nquality score based on the question: “How close did the differential diagnoses \n(DDx) come to including the final diagnosis?” b , DDx comprehensiveness score \nbased on the question: “Using your DDx list as a benchmark/gold standard, how \ncomprehensive are the differential lists from each of the experts’?” c , DDx \nappropriateness score based on the question: “How appropriate was each of \nthe DDx lists from the different medical experts compared to the differential \nlist that you just produced?” The colours correspond to experiment arms, and \nthe shade of the colour corresponds to different levels on the rating scales. In \nall cases, AMIE and clinicians assisted by AMIE scored highest overall. Numbers \nreflect the number of cases (out of 302). Note that the clinicians had the option \nof answering “I am not sure” in response to these questions; they used this \noption in a very small number (less than 1%) of cases.\nNature | Vol 642 | 12 June 2025 | 453\nquality score was 5 (‘DDx includes the correct diagnosis’) with 54% of \nDDx lists achieving that score. The number of cases that scored 5 (that \nis, the DDx included the top diagnosis) was statistically significantly \nhigher for AMIE compared with clinicians without assistance (McNe-\nmar’s test: 64.4, P < 0.01). The mean appropriateness score was 4.43 \nout of 5 (s.d. 0.92). The median comprehensiveness score was 4 (‘The \nDDx contains all candidates that are reasonable’) with 55% of the DDx \nlists achieving that score.\nThe mean appropriateness score of AMIE (4.34) was significantly \nhigher than that of unassisted clinicians (3.74) (paired t -test 8.52, \nP < 0.001, Wilcoxon signed-rank test: 2,857.5, P < 0.001) and assisted \nclinicians in either the Search (3.80) (paired t-test 7.23, P < 0.001, Wil-\ncoxon signed-rank test: 3,308.5, P < 0.001) or LLM (4.06) (paired t-test \n4.98, P < 0.001, P < 0.001, Wilcoxon signed-rank test: 2,752.0, P < 0.001)  \nconditions.\nFor computing top-n accuracy, if any of the first n diagnoses in an indi-\nvidual DDx were marked correct by the language model, the differential \nwas considered to be correct. We computed the proportion of correct \nDDx lists across all cases to compute the top-n accuracy (for n from 1  \nto 10) for each DDx. AMIE reliably generated DDx lists that perform well \nagainst the ground truth diagnosis (Fig. 2). AMIE provided the correct \ndiagnosis in 177 (59%) of the DDx lists and in 89 (29%) of the lists it was \nat the top of the list. These scores are higher than those achieved by the \nclinicians in any of the conditions. The top-10 accuracy of AMIE (59.1%) \nwas significantly higher than the top-10 accuracy for the unassisted \nclinicians (33.6%) (P = 0.04) (Tables 1 and 2).\nFigure 2 shows the top-n accuracy based on human and the auto-\nmated metric. The results are broadly similar, illustrating that despite \nthe final diagnoses often being complex and nuanced, the automated \nmetric faithfully captures the distinction between a DDx list that \nincludes the correct diagnosis and one that does not.\nThe clinicians in the study were not required to give a full list \nof ten diagnoses for every case. Clinicians in conditions I and II \nwere required to given a minimum of three diagnoses. The median \nnumber provided was six. The performance at n  = 6 is of particular \nrelevance. Not all clinicians provided six diagnoses, as a result we \nconducted a variable top-n experiment, where for each case n was set \nto the number of diagnoses provided by the human clinicians. The \nvariable top-n performance of AMIE was 59.4%—this is similar to the \nperformance at n = 9 and at n = 10. As a result, AMIE’s output of a full \nlist of ten diagnoses did not place it at an advantage compared to the  \nclinicians.\nAMIE as a DDx assistant\nOf the DDx lists created before assistance 37% (Search condition) and \n29% (AMIE condition) achieved a quality score of 5 (Fig. 1). For compari-\nson, 49% of those created with assistance from AMIE scored 5.\nThe number of cases that scored 5 (that is, the DDx included the \ntop diagnosis) was statistically higher for clinicians assisted by AMIE \ncompared with clinicians without assistance (McNemar’s test: 48.3, \nP < 0.01) and clinicians with Search assistance (5.45, P = 0.02).\nFor comprehensiveness, the number of cases that scored 4 (that is, \nThe DDx contains all candidates that are reasonable) was statistically \nhigher for clinicians assisted by AMIE compared with clinicians without \nassistance (McNemar’s test: 185.8, P < 0.01) and clinicians with Search \nassistance (185.8, P < 0.01). As a consistency check, the number of cases \nthat scored 4 was not statistically higher for clinicians in the Search \ncondition (I) baseline and AMIE condition (II) baseline (McNemar’s \ntest: 1.47, P = 0.23).\nThe mean appropriateness score after assistance with AMIE (4.06) \nwas significantly higher than after assistance with Search (3.80) \n(paired t-test 3.32, P = 0.001) and the baseline (3.74) (paired t-test 4.79, \nP < 0.001).\nT o summarize, with the support of AMIE, the quality, appropriateness \nand comprehensiveness scores for the DDx lists were greater than for \nthe lists prior to assistance (see Fig. 1).\nThe top-n accuracy of the clinicians increased with assistance from \nAMIE compared to without (see Fig. 2). A Sankey diagram illustrates \nthe effect of the two forms of assistance (Search and AMIE) on top-10 \naccuracy (Fig. 3). In the AMIE condition, 73 cases that did not feature the \nfinal diagnosis prior to using the tool included it after assistance from \nAMIE. This result is in contrast to only 37 cases in the Search condition. \nComparing the two assisted study arms, the DDx quality score was \nhigher for clinicians assisted by AMIE (top-10 accuracy 51.7%) compared \nwith clinicians without its assistance (36.1%) (McNemar’s test: 45.7, \nP < 0.01) and clinicians with search (44.4%) (4.75, P = 0.03).\nTask duration with AMIE and Search\nThe time taken to generate updated DDx lists in the Search condition \nversus the AMIE condition were similar (Search: 7.19 ± 5.33 min, AMIE: \n7.29 ± 6.41 min (mean ± s.d.)). These were not significantly different \n(paired t-test P = 0.807), which is surprising as the clinicians all had \nexperience using internet search and other information retrieval \n60\n50\n40\nAccuracy (%)30\n20\n10\n60\n50\n40\nAccuracy (%)30\n20\n10\n1 2 3 4 5\nTop-n\n6\nAMIE\nClinician assisted by AMIE\nClinician assisted by Search\nClinician unassisted by AMIE\nClinician unassisted by Search\nAMIE\nClinician assisted by AMIE\nClinician assisted by Search\nClinician unassisted by AMIE\nClinician unassisted by Search\n7 8 9 10 1 2 3 4 5\nTop-n\n6 7 8 9 10\nFig. 2 | Top-n accuracy in DDx lists through human and automated evaluations.  The percentage accuracy of DDx lists with the final diagnosis through human \nevaluation (left) or automated evaluation (right). Points reflect the mean; shaded areas show ±1 s.d. from the mean across 10 trials.\n454 | Nature | Vol 642 | 12 June 2025\nArticle\ntools, yet they were using the AMIE interface for the first time. We had \nhypothesized that they would take longer using AMIE owing to the \ninitial learning curve.\nLength of DDx lists with AMIE and Search\nWhen unassisted, the median length of the DDx lists was 6 (IQR 5–9); the \nmean was 6.41 (s.d. 2.39). With search the median DDx list length was 7 \n(IQR 5–10); the mean was 6.92 (s.d. 2.52). With AMIE, the median DDx \nlist length was 8 (IQR 6–10); the mean was 7.58 (s.d. 2.33). With assis-\ntance from AMIE, the length of the DDx lists was longer than without \nassistance (paired t-test: 7.13, P < 0.001) and longer than the DDx lists \nwith assistance from search (paired t-test: 3.15, P = 0.002).\nAMIE comparison with GPT -4\nAs we did not have the same set of human raters who evaluated the \ndifferentials produced by GPT-41 and AMIE, we cannot compare top-10 \naccuracy numbers directly. Therefore, in our study design, we evalu-\nate performance on that 70-case subset (reported in ref. 1) using the \nautomated metric (which is shown above to be relatively consistent \nwith human evaluation). AMIE performs better with regard to top-n \naccuracy for n > 1, with the gap being most prominent for n > 2 (Fig. 4). \nThis suggests potentially significant improvements in quality and com-\nprehensiveness of the differentials produced by AMIE. For n = 1, GPT-4 \nperforms marginally better but not statistically significantly.\nDiscussion\nWe used a popular series of complex diagnostic challenges to evaluate \nan LLM optimized for clinical reasoning and diagnosis (AMIE); both in \na standalone capacity and under randomized comparisons as an assis-\ntive tool for physicians. In standalone performance, AMIE generated \nmore appropriate and comprehensive DDx lists than physicians when \nthey were unassisted, with its DDx lists being more likely to include the \nfinal diagnosis than DDx lists from a board-certified internal medicine \nphysician, regardless of what position in the DDx list was considered \n(that is, top-n accuracy with n ranging from 1 to 10). Clinicians using \nAMIE as an assistant produced a DDx with higher top-n accuracy, and \nDDx with greater quality, appropriateness and comprehensiveness \ncompared with the status quo for clinical practice (use of internet \nsearch and other resources).\nThe NEJM CPCs examined here are well-known for being unique and \nchallenging clinical conundrums. Within this distinctive setting, AMIE \noutperformed an unassisted board-certified physician in both top-1 and \ntop-n accuracy. Whereas the CPCs have long been used as benchmarks \nfor difficult diagnosis, it is also well-known that performance in CPCs \nin no way reflects a broader measure of competence in a physician’s \nduties16. Furthermore, the act of forming a DDx comprises many other \nsteps that are not scrutinized in this study, including the goal-directed \nacquisition of information under uncertainty (which is known to be \nchallenging for AI systems despite recent technical progress in this \ndirection17–19).\nWe are therefore very cautious in extrapolating our findings towards \nany implications about the utility of AMIE as a standalone diagnostic \ntool. Nevertheless, our controlled evaluation mirrored the findings of \nother recent works exploring the performance of LLMs and pre-LLM \n‘DDx generators’ in smaller subsets of the NEJM CPCs, which have shown \nthe potential for automated technology to reach the correct DDx with \nsuperior performance to standalone physicians in these challenging \ncases1,12,13,20. Although this represents a step beyond historical attempts \nat automating DDx in NEJM CPCs, in which computerized approaches \nwere deemed overtly unreliable for practical use21, such studies also \nundertook limited consideration of the quality of DDx generated by \nthese automated systems or their role as assistive tools.\nOur work extends previous observations by showing not only that \nAMIE was more likely to arrive at a correct answer or provide the correct \nanswer in a list, but also that its DDx were determined by an independ-\nent rater to be of higher appropriateness and comprehensiveness than \nthose produced by board-certified physicians with access to references \nand search.\nIn our study, clinicians had access to both images and tabular data \nin redacted case reports, whereas AMIE was only provided with the \nmain body of the text. Although AMIE outperformed the clinicians \ndespite this limitation, it is unknown whether and how much this gap \nwould widen if AMIE had access to the figures and tables. Furthermore, \nTable 1 | Top-1 and top-10 accuracy of DDx lists produced with AMIE and Search assistance\nModel only Human\nAMIE Before assistance After Search assistance After AMIE assistance\nMetrics Top-1↑ Top-10↑ Top-1↑ Top-10↑ Top-1↑ Top-10↑ Top-1↑ Top-10↑\nFull set (302 cases) 29.2% 59.1% 15.9% 33.6% 24.3% 44.5% 25.2% 51.8%\nSet with no overlap (56 cases) 35.4% 55.4% 13.8% 34.6% 29.2% 46.2% 24.6% 52.3%\nDifference compared to full set +6.2% –3.7% –2.1% +1.0% +4.9% +1.7% –0.6% +0.5%\nSet with partial overlap (249 cases) 29.9% 61.4% 14.9% 33.1% 24.3% 44.2% 24.7% 51.4%\nDifference compared to full set +0.7% +2.3% –1.0% –0.5% 0% –0.3% –0.5% –0.4%\nThe percentage of DDx lists with the final diagnosis. Bold numbers reflect the difference in percentage accuracy between the full case set and the partial case sets.\nTable 2 | Top-1 and top-10 accuracy of DDx lists produced with AMIE and Search assistance by speciality\nModel only Human\nAMIE Before assistance After Search assistance After AMIE assistance\nMetrics Top-1↑ Top-10↑ Top-1↑ Top-10↑ Top-1↑ Top-10↑ Top-1↑ Top-10↑\nInternal medicine (159 cases) 27.7% 61.6% 15.5% 34.6% 24.5% 47.8% 24.5% 52.8%\nNeurology (42 cases) 26.8% 56.1% 17.1% 31.7% 22.0% 36.6% 24.4% 51.2%\nPaediatrics (33 cases) 30.3% 45.5% 6.1% 22.7% 12.1% 33.3% 15.2% 30.3%\nPsychiatry (10 cases) 50.0% 70.0% 20.0% 50.0% 20.0% 60.0% 30.0% 60.0%\nThe percentage of DDx lists with the final diagnosis by specialty.\nNature | Vol 642 | 12 June 2025 | 455\nthe integration of multimodal inputs by LLMs is an area of novel \nresearch22,23, with a large potential number of data modalities to con-\nsider and little precedent for how information from multiple modalities \nshould be integrated over time for a single case by AI systems.\nThe repeated examination of NEJM CPCs by automated systems \nhighlights its promise as a ‘benchmark’ for evaluation and develop-\nment of LLMs. Benchmarking enables comparisons of models with one \nanother and the ability to evaluate a model’s performance improve-\nments or degradation over time. However, consistency in using CPCs \nas a scalable benchmark is challenging if we are reliant on using human \njudgement to establish whether a candidate DDx matches the ground \ntruth. We utilized an automated approach for comparing AMIE to a \nbaseline LLM performance (GPT-4). Our estimates varied from recently \npublished estimates in other studies, despite using the same subset of \ncases1. Direct comparisons of different technologies would ideally be \nconducted by more extensive and blinded human evaluation, includ-\ning work to ensure reproducibility of the human evaluation protocol, \nanalysis of inter-rater reliability and the use of metrics that reflect the \nquality, appropriateness and comprehensiveness of LLM differentials in \naddition to estimations of accuracy. Our estimates of top-1 and top-10 \naccuracy, although impressive at close to 30% and 60%, respectively, \nhighlight noteworthy room for improvement for LLMs, especially for \ncomplex cases that are non-pathognomonic (that is, cases that do not \nhave a sign or symptom that defines a diagnosis). However, as noted \nabove, the CPCs represent ‘diagnostic puzzles’ rather than real-world \nexamples of common clinical workflows, and it is therefore important \nto consider more realistic settings in which LLMs might prove of practi-\ncal value in medicine.\nOne such example is the potential for LLMs to assist clinicians in com-\nplex diagnoses. Deep learning tools have shown considerable promise \nin many areas of medicine, but are overwhelmingly used as assistive \nrather than autonomous tools24, given the safety-critical nature of medi-\ncal practice and the many issues of robustness25 and fairness26–28 seen \nin deployment. Furthermore, observations of standalone diagnostic \naccuracy often do not guarantee that an AI tool will improve perfor-\nmance in real-world settings as an assistive tool, and it remains unclear \nhow AI and human decision-making should be optimally integrated in \nmedicine29. For LLMs in particular, the known incidence of hallucination \nand confabulation30 might mislead clinicians into inaccurate diagnosis, \nreplicating or even extending findings in other clinical settings that AI \nsystems might actually degrade the performance of clinicians rather \nthan necessarily improving outcomes.\nThis highlights the importance of focused study of LLMs in assistive \nscenarios. We explored this specifically in NEJM CPCs and found that \nAMIE increased the number of appropriate DDx produced by a clinician \nwhen used as an assistive tool in addition to overall top-n accuracy, sug-\ngesting that AMIE’s primary assistive potential may be due to making the \nscope of DDx more complete. Given the potential for misleading informa-\ntion to arise from AI systems, including in convincing dialogue, clinicians \nmust appreciate the fundamental limitations of these models and not \nlose sight of their primacy in the provider–patient relationship and their \nultimate authority and responsibility for the diagnostic and therapeutic \nmanagement of their patients. Such thoughtful and effective LLM use \nshould not be unintuitive to most clinicians. Aiding the diagnostic pro-\ncess could reasonably occur in an emergency room upon presentation \n(during potentially time-sensitive moments), upon admission to the \nmedical ward, or by a consulting service after a patient has been admit-\nted or in outpatient clinics. Our findings suggest that future research \nshould more rigorously explore how LLMs augment clinicians’ DDx in \nmany such specific scenarios, where the risks and benefits might vary.\nDespite being a novel tool, the use of AMIE did not seem to add inef-\nficiency or increase the amount of time spent on solving each CPC \ncompared with the use of Search or other conventional information. \nThis suggests that the conversational interface was unobtrusive and \nintuitive. Consistent with this, the interviewed clinicians all described it \nas ‘easy’ to use, and were positive about the use and implications of the \nAMIE interface. Enhancing efficiency while maintaining or improving \nquality are generally accepted goals of improving healthcare delivery, \nalongside improving provider experience31, and our study showed \nsignificant potential in this regard, as clinicians also reported feeling \nmore confident in their DDx lists after using the model. The clinicians \ndescribed search becoming difficult when they did not know how to \nstart or narrow down the query; qualitatively, the reports indicate that \nAMIE was easier to use in this regard. However, there are many human \nfactors, social elements and other complex considerations in these use \ncases, and it is critical to ensure that efforts are made to avoid inequities \nin access to avoid exacerbating existing health disparities.\nClinicians frequently expressed excitement about using AMIE, but \nwere also aware of the shortcomings of language models and had \nconcerns about confabulations in particular if used by individuals \nwho were not trained or instructed to avoid such questions. However, \nour work did not explore many other important aspects of human–AI \ninteraction, which require further study in safety-critical settings such \nas this. For example, we did not explore the extent to which clinicians \nAMIE arm After\nassistance\nBefore\nassistance\nNot in DDx list\nIn DDx list\nSearch arm After\nassistance\nBefore\nassistance\na b\nn = 94 n = 83\nn = 73\nn = 135\nn = 11\nn = 208\nn = 146\nn = 156\nn = 109 n = 97\nn = 37\nn = 156\nn = 12\nn = 193 n = 168\nn = 134\nFig. 3 | Sankey diagram showing effect of assistance. a, In the AMIE arm, the \nfinal correct diagnosis appeared in the DDx list only after assistance in 73 cases. \nb, In the Search arm, the final correct diagnosis appeared in the DDx list only \nafter assistance in 37 cases. In a small minority of cases in both arms (AMIE arm: \n11 (a); Search arm: 12 (b)), the final diagnosis appeared in the DDx list before \nassistance but was not in the list after assistance.\n456 | Nature | Vol 642 | 12 June 2025\nArticle\ntrusted the outputs of the model or their understanding of its train -\ning and limitations, or undertake focused ‘onboarding’ or training in \nits use, which are all known to be important modifiers of the benefits \nderived by clinicians from AI assistants 32. The CPC challenges them -\nselves do not enable a rigorous exploration of the possible effects of AI \nassistance on health equity and fairness; a further study of how these \naspects of clinicians’ DDx is affected by LLM assistance is needed. \nAI systems are known to be able to express uncertainty 33 and defer \nappropriately to clinicians 34, which might significantly improve the \nbalance between trust and skepticism needed for effective AI assis -\ntance in medicine. Qualitative feedback suggested that there remains \nroom for targeted improvement of LLMs as assistive diagnostic tools, \nwith one clinician noting that “It was most helpful for simpler cases \nthat were specific keywords or pathognomonic signs” , but for more \ncomplex cases it still tended to draw conclusions from isolated symp-\ntoms rather than viewing the case holistically. The assistive effect of \nthese LLMs could potentially ‘upskill’ clinical providers, particularly \nin enabling them to broaden and enhance the quality of their DDx. \nAs corroborated via our clinician interviews after their experience \nwith AMIE, such upskilling could be relevant for education or training \npurposes to support providers across a skill continuum ranging from \ntrainees to attending providers. The upskilling capabilities could also \nextend to locations where specialist medical training is less common \n(such as in lower and middle income countries). However, our find -\nings may not generalize to these scenarios, given that we utilized a \npool of 20 clinicians with a mean experience of 11.5 years. This may \nnot adequately represent the diverse set of users who are seeking to \nbenefit from LLMs as a diagnostic aid.\nOur qualitative findings from semi-structured interviews with clini-\ncians highlight the collaborative nature of the diagnostic reasoning \nprocess and the importance of clinical judgement when using an LLM. \nWhereas AMIE was capable of generating a broad DDx in isolation, the \nclinicians’ expertise enabled them to filter these suggestions when they \nwere using the tool, discarding those they deemed to be inaccurate \nor irrelevant and leading to a more comprehensive and considered \nfinal differential list. This active evaluation and filtering process could \nexplain the gap between standalone AMIE performance and clinician \nperformance when assisted by the tool, with several specific factors \nhighlighted: (1) anchoring bias: clinicians tended to anchor on their \ninitial, unassisted DDx. This is consistent with known anchoring biases \nand might be exacerbated by the two-stage study design; (2) LLM sug-\ngestibility: several clinicians noted that AMIE could be led down alterna-\ntive diagnostic paths by their follow-up questions and that this could \nlead to inaccurate conclusions that clinicians recognized as not being \nsupported by the evidence; (3) trust calibration: clinicians highlighted \nthe importance of the model being able to communicate when it is \nunsure, as this would probably have influenced the extent to which \nthey trusted and incorporated AMIE’s suggestions.\nLimitations\nThe NEJM CPC format differs in important ways from how a clinician \nwould evaluate a patient at the outset of a clinical encounter. The case \nreports are created as ‘puzzles’ with enough clues that should enable a \nspecialist to reason towards the final diagnosis. At the beginning of a \nclinician encounter, it would be challenging to create such a concise, \ncomplete and coherent case report. Case reports in the NEJM style \nwould not be available at patient intake. Similarly, these cases were \nselected to represent challenging cases instead of common conditions. \nThus, our evaluation does not directly suggest that clinicians should \nleverage the assistive capabilities of an LLM for typical cases that are \nseen on a daily basis.\nEvaluation is non-trivial for complex tasks such as these case studies. \nAlthough the rubric that we used for evaluating whether a diagnosis \nis included in a DDx list is clear, it is possible to disagree whether an \nindividual diagnosis is specific enough to be counted as correct versus \nincorrect. This ambiguity is likely to be the reason that we did not obtain \nidentical results to Kanjee et al.1.\nIn terms of modalities, the case reports include both images and \ntables. The clinicians had access to these in the redacted case reports. \nHowever, AMIE only had access to the main body of the text. Although \nAMIE outperformed the clinicians despite this limitation, it is unknown \nwhether and how much this gap would widen if AMIE had access to the \nfigures and tables. Early evidence suggests that the effect might be case \nand context dependent13. New multimodal models should be evaluated \nin a similar manner. The appropriate input format for images is clear, \nwhereas tables can be represented textually or graphically. Experimen-\ntation into the optimal format for tabular data would also be valuable.\nThe study highlighted some weaknesses of AMIE. Specifically, one \nclinician (C3) highlighted that “It was most helpful for simpler cases \nthat were specific keywords or pathognomonic signs” and that for \nmore complex cases it still tended to draw conclusions from isolated \nsymptoms rather than viewing the case holistically. Considering the \nimportance of assessing challenging cases, the NEJM CPC case reports \nare likely to serve as a useful dataset for continued LLM benchmarking.\nRegarding the time taken, we acknowledge that the analysis of time \nspent on the tasks may not map well to how an LLM would affect time \non task in reality. We appreciate that in practice a clinician would need \nto write a case description or notes before being able to leverage this \ntype of system.\nThere were potentially systematic differences between the clinicians’ \nand the model’s DDx lists that could have led the clinicians to guess \nthat the lists came from different sources. However, we believe that \nthis did not affect our results for several reasons. First, we reviewed the \nlists from the model and the clinicians before running the evaluation \nto ensure that there were no obvious formatting differences. Second, \nthe raters did not know ahead of time the various potential sources of \n70\n60\n50\nAccuracy (%)\n40\n30 GPT-4 DDx\nAMIE DDx\nGPT-4 DDx\nAMIE DDx\nGPT-4 DDx\nAMIE DDx20\n70\n60\n50\nAccuracy (%)\n40\n30\n20\n70\n60\n50\nAccuracy (%)\n40\n30\n20\n1 2 3 4 5 6\nTop-k (MP2-rated)\nMed-PaLM 2 GPT-4 AMIE\n7 8 9 10 1 2 3 4 5 6\nTop-k (GPT-4-rated)\n7 8 9 10 1 2 3 4 5 6\nTop-k (GPT-4-rated)\n7 8 9 10\nFig. 4 | Top-n accuracy in DDx lists from different LLMs. Comparison of the percentage of DDx lists that included the final diagnosis for AMIE versus GPT-4 for 70 cases. \nWe used Med-PaLM 210, G P T- 46 and AMIE as the raters—all resulted in similar trends. Points reflect the mean; shaded areas show ±1 s.d. from the mean across 10 trials.\nNature | Vol 642 | 12 June 2025 | 457\nDDx lists and that these could include AI models, and DDx list order-\ning was blinded during the rating process. Third, auto evaluation is \nblinded to the source of the data, and the trends from human and auto \nevaluation were consistent.\nConclusion\nGenerating a DDx is a critical step in clinical case management, and the \ncapabilities of LLMs present new opportunities for assistive tooling to \nhelp with this task. Tables 1 and 2 Our randomized study showed that \nAMIE was a helpful AI tool for DDx generation for generalist clinicians. \nClinician participants indicated its utility for learning and education, \nand additional work is needed to understand its suitability for clinical \nsettings.\nOnline content\nAny methods, additional references, Nature Portfolio reporting summa-\nries, source data, extended data, supplementary information, acknowl-\nedgements, peer review information; details of author contributions \nand competing interests; and statements of data and code availability \nare available at https://doi.org/10.1038/s41586-025-08869-4.\n1. Kanjee, Z., Crowe, B. & Rodman, A. Accuracy of a generative artificial intelligence model \nin a complex diagnostic challenge. JAMA 330, 78–80 (2023).\n2. Szolovits, P. & Pauker, S. G. Categorical and probabilistic reasoning in medical diagnosis. \nArtif. Intell. 11, 115–144 (1978).\n3. Liu, Y. et al. A deep learning system for differential diagnosis of skin diseases. Nat. Med. \n26, 900–908 (2020).\n4. Rauschecker, A. M. et al. Artificial intelligence system approaching neuroradiologist-level \ndifferential diagnosis accuracy at brain MRI. Radiology 295, 626–637 (2020).\n5. Balas, M. & Ing, E. B. Conversational AI models for ophthalmic diagnosis: comparison  \nof ChatGPT and the Isabel pro differential diagnosis generator. JFO Op. Ophthalmol. 1, \n100005 (2023).\n6. GPT-4 Technical Report 2303.08774 (OpenAI, 2023).\n7. Anil, R. et al. Palm 2 technical report. Preprint at https://doi.org/10.48550/arXiv.2305.10403 \n(2023).\n8. Scao, T. L. et al. BLOOM: a 176b-parameter open-access multilingual language model. \nPreprint at https://doi.org/10.48550/arXiv.2211.05100 (2022).\n9. Touvron, H. et al. Llama 2: open foundation and fine-tuned chat models. Preprint at \nhttps://doi.org/10.48550/arXiv.2307.09288 (2023).\n10. Singhal, K. et al. Large language models encode clinical knowledge. Nature 620, 172–180 \n(2023).\n11. Nori, H., King, N., McKinney, S. M., Carignan, D. & Horvitz, E. Capabilities of GPT-4 on medical \nchallenge problems. Preprint at https://doi.org/10.48550/arXiv.2303.13375 (2023).\n12. Eriksen, A. V., Moller, S. & Ryg, J. Use of GPT-4 to diagnose complex clinical cases. NEJM AI \nhttps://doi.org/10.1056/AIp2300031 (2023).\n13. Buckley, T., Diao, J. A., Rajpurkar, P., Rodman, A. & Manrai, A. K. Multimodal foundation \nmodels exploit text to make medical image predictions. Preprint at https://doi.org/ \n10.48550/arXiv.2311.05591 (2024).\n14. Tu, T. et al. Towards conversational diagnostic AI. Nature https://doi.org/10.1038/s41586-\n025-08866-7 (2025).\n15. Bond, W. F. et al. Differential diagnosis generators: an evaluation of currently available \ncomputer programs. J. Gen. Intern. Med. 27, 213–219 (2012).\n16. Ledley, R. S. & Lusted, L. B. Reasoning foundations of medical diagnosis: symbolic logic, \nprobability, and value theory aid our understanding of how physicians reason. Science \n130, 9–21 (1959).\n17. Hong, J., Levine, S. & Dragan, A. Zero-shot goal-directed dialogue via RL on imagined \nconversations. In Proc. Foundation Models for Decision Making Workshop at NeurIPS 2023 \n(eds Yang, S. et al.) 77 (NeurIPS, 2023).\n18. Kossen, J. et al. Active acquisition for multimodal temporal data: a challenging \ndecision-making task. Preprint at https://doi.org/10.48550/arXiv.2211.05039  \n(2023).\n19. Mackie, I., Chatterjee, S. & Dalton, J. Generative relevance feedback with large language \nmodels. In Proc. 46th International ACM SIGIR Conference on Research and Development \nin Information Retrieval (eds Chen, H.-H. et al.) 2026–2031 (Association for Computing \nMachinery, 2023).\n20. Fritz, P. et al. Evaluation of medical decision support systems (ddx generators) using real \nmedical cases of varying complexity and origin. BMC Med. Inform. Decis. Mak. 22, 254 \n(2022).\n21. Miller, R. A., Pople Jr, H. E. & Myers, J. D. Internist-i, an experimental computer- \nbased diagnostic consultant for general internal medicine. In Computer-assisted \nmedical decision making (eds Reggia, J. A. & Tuhrim, S.) 139–158 (Springer, 1985).\n22. Li, C. et al. Llava-med: training a large language-and-vision assistant for biomedicine in \none day. In Proc. Advances in Neural Information Processing Systems 36 (eds Oh, A. et al.) \n28541–28564 (NeurIPS, 2023).\n23. Tu, T. et al. Towards generalist biomedical AI. NEJM AI 1, AIoa2300138 (2024).\n24. Muehlematter, U. J., Daniore, P. & Vokinger, K. N. Approval of artificial intelligence and \nmachine learning-based medical devices in the USA and europe (2015–20): a comparative \nanalysis. Lancet Digit. Health 3, e195–e203 (2021).\n25. Roschewitz, M. et al. Automatic correction of performance drift under acquisition shift in \nmedical image classification. Nat. Commun. 14, 6608 (2023).\n26. Obermeyer, Z., Powers, B., Vogeli, C. & Mullainathan, S. Dissecting racial bias in an \nalgorithm used to manage the health of populations. Science 366, 447–453 (2019).\n27. Seyyed-Kalantari, L., Zhang, H., McDermott, M. B., Chen, I. Y. & Ghassemi, M. Underdiagnosis \nbias of artificial intelligence algorithms applied to chest radiographs in under-served \npatient populations. Nat. Med. 27, 2176–2182 (2021).\n28. Samorani, M., Harris, S. L., Blount, L. G., Lu, H. & Santoro, M. A. Overbooked and overlooked: \nmachine learning and racial bias in medical appointment scheduling. Manuf. Serv. Oper. \nManag. 24, 2825–2842 (2022).\n29. Gaube, S. et al. Do as AI say: susceptibility in deployment of clinical decision-aids. Npj Digit. \nMed. 4, 31 (2021).\n30. Umapathi, L. K., Pal, A. & Sankarasubbu, M. Med-HALT: medical domain hallucination test \nfor large language models. In Proc. 27th Conference on Computational Natural Language \nLearning (CoNLL) (eds Jiang, J. et al.) 314–334 (Association for Computational Linguistics, \n2023).\n31. Sikka, R., Morath, J. M. & Leape, L. The quadruple aim: care, health, cost and meaning in \nwork. BMJ Qual. Saf. 24, 608–610 (2015).\n32. Cai, C. J., Winter, S., Steiner, D., Wilcox, L. & Terry, M. ‘Hello AI’: uncovering the onboarding \nneeds of medical practitioners for human-ai collaborative decision-making. Proc. ACM \nHum. Comput. Interact. 3, 1–24 (2019).\n33. Yin, Z. et al. Do large language models know what they don’t know? In Proc. Findings of \nthe Association for Computational Linguistics: EACL 2023 (eds Vlachos, A. & Augenstein, I.) \n8653–8665 (Association for Computational Linguistics, 2023).\n34. Dvijotham, K. et al. Enhancing the reliability and accuracy of ai-enabled diagnosis via \ncomplementarity-driven deferral to clinicians. Nat. Med. 29, 1814–1820 (2023).\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in \npublished maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution \n4.0 International License, which permits use, sharing, adaptation, distribution \nand reproduction in any medium or format, as long as you give appropriate \ncredit to the original author(s) and the source, provide a link to the Creative Commons licence, \nand indicate if changes were made. The images or other third party material in this article are \nincluded in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your \nintended use is not permitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a copy of this licence, \nvisit http://creativecommons.org/licenses/by/4.0/.\n© The Author(s) 2025\nArticle\nMethods\nNEJM CPC case reports\nThe case records of the Massachusetts General Hospital (MGH) are \npublished, lightly edited transcriptions of the CPCs of the MGH (Bos-\nton, MA). In the CPC, a patient case presentation is described and then \nan expert physician is asked to provide a DDx and a final diagnosis, \nalong with their diagnostic reasoning, based only on the patient’s \nprovided medical history and preliminary test results. The published \ncases, organized generally as diagnostic puzzles culminating in a \ndefinitive, pathology-confirmed diagnosis, are published regularly \nin the NEJM. We leverage these case reports, licensed from the NEJM, \nto evaluate AMIE’s capability to generate a DDx alone and, separately, \nto aid clinicians in generation of their own differential. For this lat -\nter task, we developed a user interface for clinicians to interact with  \nAMIE.\nA set of 326 case texts from the NEJM CPC series were considered. \nThese case reports were published over a 10-year period between \n13 June 2013 and 10 August 2023. Of these, 23 (7%) were excluded on \nthe grounds that they discussed case management and were not primar-\nily focused on diagnosis. The articles were distributed over the years \nbetween 2013–2023 as follows—2013: n = 22; 2014: n = 34; 2015: n = 36; \n2016: n = 35; 2017: n = 36; 2018: n = 16; 2020: n = 23; 2021: n = 36; 2022: \nn = 39; 2023: n = 26. Supplementary Table 2 contains the full list of case \nreports, including the title, year and issue number of each report. The \n302 cases include the 70 cases used by Kanjee et al.1.\nThese case reports cover a range of medical specialties. The largest \nproportion are from internal medicine (n = 159), followed by neurol-\nogy (n = 42), paediatrics (n = 33) and psychiatry (n = 10). The text cor-\nresponding to the history of the present illness (HPI) was manually \nextracted from each article as input to AMIE. The average (median) \nword count of these sections of the case reports is 1,031 words (mean: \n1,044, s.d.: 296, range: 378–2,428). The average (median) character \ncount is 6,619 characters (mean: 6,760, s.d.: 1,983, range: 2,426–15,196).\nA modified version of the article, inclusive of the provided HPI, admis-\nsion imaging and admission labs (if available in the case) was created \nfor the human clinicians (see Extended Data Fig. 1). This version had \nredacted the final diagnosis, expert discussion of the DDx and any \nsubsequent imaging or biopsy results (which are typical elements of the \nconclusion of the case challenges). Given AMIE is a text-only AI model, \nthe admission images and lab tables were not fed into the model. How-\never, text-based descriptions of specific lab values or imaging findings \nwere sometimes included in the case description.\nTraining an LLM for DDx\nOur study introduces AMIE, a model that uses a transformer archi -\ntecture (PaLM 27), fine-tuned on medical domain data; alongside an \ninterface for enabling its use as an interactive assistant for clinicians.\nAs with Med-PaLM 210, AMIE builds on PaLM 2, an iteration of Google’s \nLLM with substantial performance improvements on multiple LLM \nbenchmark tasks. For the purposes of this analysis the large (L) PaLM \n2 model was used.\nAMIE was fine-tuned with long context length on a task mixture con-\nsisting of medical question answering (multiple-choice and long-form \nquestions), medical dialogue generation and electronic health record \n(EHR) note summarization. The datasets used included the training \nsplits of MultiMedQA (MedQA, MedMCQA, HealthSearchQA, LiveQA \nand MedicationQA)10, a proprietary dataset of medical conversations, \nand expert handcrafted EHR note summaries from MIMIC-III35. The \ncapability to process long context input enables AMIE to handle tasks \nthat require long-range reasoning and comprehension.\nFrom MedQA (multiple-choice) we used US Medical Licensing Exami-\nnation (USMLE) multiple-choice style open domain questions with \nfour or five possible answers36. A set of 11,450 questions were used \nfor training and 1,273 questions reserved for testing. We curated 191 \nMedQA questions from the training set where clinical experts crafted \nstep-by-step reasoning leading to the correct answer. From the Health-\nSearchQA, LiveQA and MedicationQA datasets we used expert-crafted \nlong-form responses to 64 questions. The medical conversations were \nfrom a dataset of 218 dialogues between a clinician and patient that are \nassociated with a corresponding ground truth diagnosis. The dataset \nfeatures respiratory (n = 168), musculoskeletal (n = 40), cardiology \n(n = 5), gastroenterology (n = 4) and dermatology (n = 1) dialogues. In \ntotal, 102 unique diagnoses are represented with the mean number of \nturns 98 (25th percentile = 85.0, 75th percentile = 113.0).\nNo NEJM case report data was used in the tuning process and we \nperform contamination experiments to assess whether performance \nwas impacted by case text that may have been in the pretraining corpus.\nZero-shot prompting. We evaluated AMIE on each of the NEJM case \nstudies with the following prompt: ‘You are a helpful medical assistant. \nYou will be provided and asked about a complicated clinical case; read \nit carefully and then provide a diverse and thorough DDx’ .\nExample input. \nCase: [Case Text]\nWhat are the top 10 most likely diagnoses? Be precise, listing one diag-\nnosis per line, and try to cover many unique possibilities (at least 10).  \nThe top 10 diagnoses are:\nExample output. \n1. Sézary syndrome\n2. Adult T-cell leukemia/lymphoma\n3. Mycosis fungoides\n4. Atopic dermatitis\n5. Psoriasis\n6. Drug reaction with eosinophilia and systemic symptoms (DRESS)\n7. Graft-versus-host disease (GVHD)\n8. Cutaneous T-cell lymphoma, not otherwise specified\n9. Hypereosinophilic syndrome\n10. Systemic lupus erythematosus (SLE)\nThe AMIE user interface\nThe interface associated with AMIE, depicted in Extended Data Fig. 2, \nenables users to interact with the underlying model via text-based chat \nin the context of a given case description. In our study, the interface was \npre-populated with a text-only representation of the HPI for a given \ncase. Clinicians were asked to initiate the interaction by querying AMIE \nusing a suggested prompt. Following this initial prompt and AMIE’s \nresponse, clinicians were free to query the model using any additional \nfollow-up questions, though clinicians were cautioned to avoid ask-\ning questions about information that had not already been presented \nin the case. A pilot study indicated that without such a warning, clini-\ncians may ask questions about specific lab values or imaging leading \nto confabulations.\nFor a given question, the interface generated the response by query-\ning AMIE using the following prompt template:\nRead the case below and answer the question provided after the \ncase.\nFormat your response in markdown syntax to create paragraphs \nand bullet points. Use ‘<br><br>’ to start a new paragraph. Each para-\ngraph should be 100 words or less. Use bullet points to list multiple \noptions. Use ‘<br>*’ to start a new bullet point. Emphasize important \nphrases like headlines. Use ‘**’ right before and right after a phrase \nto emphasize it. There must be NO space in between ‘**’ and the \nphrase you try to emphasize.\nCase:[Case Text]\nQuestion (suggested initial question is ‘What are the top 10 most \nlikely diagnoses and why (be precise)?’): [Question]\nAnswer:\nExperimental design\nIn order to comparatively evaluate AMIE’s ability to generate a DDx \nalone and aid clinicians with their DDx generation we designed a \ntwo-stage reader study illustrated in Extended Data Fig. 3. Our study \nwas designed to evaluate the assistive effect of AMIE for generalist \nclinicians (not specialists) who only have access to the case presenta-\ntion and not the full case information (which would include the expert \ncommentary on the DDx). The first stage of the study had a counterbal-\nanced design with two conditions. Clinicians generated DDx lists first \nwithout assistance and then a second time with assistance, where the \ntype of assistance varied by condition.\nStage 1: Clinicians generate DDx with and without assistance.  \nTwenty U.S. board-certified internal medicine physicians (median \nyears of experience: 9, mean: 11.5, s.d.: 7.24, range: 3–32) viewed the \nredacted case report, with access to the case presentation and associ-\nated figures and tables. They did this task in one of two conditions, \nbased on random assignment.\nCondition I: Search. The clinicians were first instructed to provide \na list of up to ten diagnoses, with a minimum of three, based solely on \nreview of the case presentation without using any reference materi-\nals (for example, books) or tools (for example, internet search). Fol-\nlowing this, the clinicians were instructed to use internet search or \nother resources as desired (but not given access to AMIE) and asked \nto re-perform their DDx.\nCondition II: AMIE. As with condition I, the clinicians were first \ninstructed to provide a list of up to ten diagnoses, with a minimum of \nthree, based solely on review of the case presentation without using \nany reference materials (for example, books) or tools (for example, \ninternet search). Following this the clinicians were given access to AMIE \nand asked to re-perform their DDx. In addition to AMIE, clinicians could \nchoose to use internet search or other resources if they wished.\nFor the assignment process, we formed ten pairs of two clinicians \neach, grouping clinicians with similar years of post-residency experi-\nence together. The set of all cases was then randomly split into ten \npartitions, and each clinician pair was assigned to one of the ten case \npartitions. Within each partition, each case was completed once in \ncondition I by one of the two clinicians, and once in condition II by the \nother clinician. For each case, the assignment of which clinician among \nthe pair was exposed to which of the two experimental conditions was \nrandomized. Pairing clinicians with similar post-residency experience \nto complete the same case served to reduce variability between the two \ndistinct experimental conditions.\nStage 2. Specialists with full case information extract gold DDx \nand evaluate Stage 1 DDx\nNineteen U.S. board-certified specialist clinicians (median years of \nexperience: 14, mean: 13.7, s.d.: 7.82, range: 4–38) were recruited from \ninternal medicine (n = 10), neurology (n = 3), paediatrics (n = 2), psy-\nchiatry (n = 1), dermatology (n = 1), obstetrics (n = 1), and emergency \nmedicine (n = 1). Their mean years of experience was 13.7 (s.d.: 7.82, \nrange: 4–38). These specialists were aligned with the specialty of the \nrespective CPC case, viewed the full case report and were asked to list \nat least five and up to ten differential diagnoses. Following this, they \nwere asked to evaluate the five DDx lists generated in stage 1, includ-\ning two DDx lists from condition 1 (DDx without assistance and DDx \nwith Search assistance), two DDx lists from condition 2 (DDx without \nassistance and DDx with AMIE assistance) and the standalone AMIE \nDDx list. One specialist reviewed each case.\nThe specialists answered the following questions to evaluate the \nDDx lists:\nThe quality score developed by Bond et al.15 and used by Kanjee et al.1 \nis a differential score based on an ordinal five-point scale: ‘How close did \nthe differential diagnoses (DDx) come to including the final diagnosis?’ \nThe options were: 5, DDx includes the correct diagnosis; 4, DDx contains \nsomething that is very close, but not an exact match to the correct diag-\nnosis; 3, DDx contains something that is closely related and might have \nbeen helpful in determining the correct diagnosis; 2, DDx contains some-\nthing that is related, but unlikely to be helpful in determining the correct \ndiagnosis; and 1, nothing in the DDx is related to the correct diagnosis.\nAn appropriateness score: ‘How appropriate was each of the dif-\nferential diagnosis lists from the different medical experts compared \nthe differential list that you just produced?’ The options to respond \nwere on a Likert scale of 5 (very appropriate) to 1 (very inappropriate).\nA comprehensiveness score: ‘Using your differential diagnosis list as \na benchmark/gold standard, how comprehensive are the differential \nlists from each of the experts?’ The options to respond were: 4, the DDx \ncontains all candidates that are reasonable; 3, the DDx contains most \nof the candidates but some are missing; 2, the DDx contains some of \nthe candidates but a number are missing;’ and 1, the DDx has major \ncandidates missing.\nFinally, specialists were asked to specify in which position of the \nDDx list the correct diagnosis was matched, in case it was included in \nthe DDx at all.\nClinician incentives. Clinicians were recruited and remunerated by \nvendor companies at market rates based on speciality, without specific \nincentives such as diagnostic accuracy or other factors.\nAutomated evaluation. In addition to comparing against ground truth \ndiagnosis and expert evaluation from clinicians, we also created an \nautomated evaluation of the performance of the five DDxs using a \nlanguage model-based metric. Such automated metrics are useful as \nhuman evaluation is time and cost-prohibitive for many experiments. \nWe first extracted the (up to ten) individual diagnoses listed in each \nDDx. We leveraged minor text-processing steps via regular expressions \nto separate the outputs by newlines and strip any numbering before \nthe diagnoses. Then we asked a medically fine-tuned language model, \nMed-PaLM 210, whether or not each of these diagnoses was the same as \nthe ground truth diagnosis using the following prompt:\nIs our predicted diagnosis correct (y/n)? Predicted diagnosis: [diag-\nnosis], True diagnosis: [label]\nAnswer [y/n].\nA diagnosis was marked as correct if the language model output ‘y’ .\nWe computed Cohen’s kappa as a measure of agreement between \nhuman raters and automated evaluation with respect to the binary \ndecision of whether a given diagnosis—that is, an individual item from \na proposed DDx list—matched the correct final diagnosis. Cohen’s \nkappa for this matching task was 0.631, indicating ‘substantial agree-\nment’ between human raters and our automated evaluation method, \nper Landis & Koch37.\nQualitative interviews\nFollowing the study we performed a semi-structured 30-min inter-\nviews with 5 of the generalist clinicians who participated in stage 1. \nSemi-structured interviews explored the following questions:\n(1) How did you find the task of generating a DDx from the case report \ntext?\n(2) Think about how you used Internet search or other resources. How \nwere these tools helpful or unhelpful?\n(3) Think about how you used the AMIE. How was it helpful or unhelpful?\n(4) Were there cases where you trusted the output of the search que-\nries? T ell us more about the experience if so, such as types of cases, \ntypes of search results.\n(5) Were there cases where you trusted the output of the LLM queries? \nT ell us more about the experience if so, such as types of cases, types \nof search results.\n(6) Think about the reasoning provided by the LLM’s interface? Where \nwere they helpful? Where were they unhelpful?\nArticle\n(7) What follow-up questions did you find most helpful to ask the LLM?\n(8) How much time does it take to get used to the LLM? How was it \nintuitive? How was it unintuitive?\nWe conducted a thematic analysis of notes from interviews taken by \nresearchers during the interviews, employing an inductive approach \nto identify patterns (themes) within the data. Initial codes were gener-\nated through a line-by-line review of the notes, with attention paid to \nboth semantic content and latent meaning. Codes were then grouped \nbased on conceptual similarity, and refined iteratively. T o enhance the \ntrustworthiness of the analysis, peer debriefing was conducted within \nthe team of researchers. Through discussion and consensus, the final \nthemes were agreed upon.\nReporting summary\nFurther information on research design is available in the Nature Port-\nfolio Reporting Summary linked to this article.\nData availability\nThe case reports used in this study are published and were licensed from \nthe New England Journal of Medicine. We are not able to re-distribute \nthe copyrighted material, but the case texts can be obtained from the \njournal.\nCode availability\nAMIE is an LLM-based research AI system for diagnostic dialogue. We \nare not making the model code and weights open source owing to the \nsafety implications of unmonitored use of such a system in medical \nsettings. In the interest of responsible innovation, we will be working \nwith research partners, regulators and providers to validate and explore \nsafe onward uses of AMIE. For reproducibility, we have documented \ntechnical deep learning methods while keeping the paper accessible to \na clinical and general scientific audience. Our work builds on PaLM 2,  \nfor which technical details have been described extensively in the \ntechnical report7.\n \n35. Johnson, A. E. et al. MIMIC-III, a freely accessible critical care database. Sci. Data 3, 160035 \n(2016).\n36. Jin, D. et al. What disease does this patient have? a large-scale open domain question \nanswering dataset from medical exams. Appl. Sci. 11, 6421 (2021).\n37. Landis, J. R. & Koch, G. G. The measurement of observer agreement for categorical data. \nBiometrics 33, 159–174 (1977).\nAcknowledgements This project was an extensive collaboration between many teams at \nGoogle Research and Google DeepMind. We thank A. Jain, R. Sayres, S. Lachgar, L. Winer,  \nM. Shiels, B. Hatfield, S. W. Man, P. Singh, A. Um’rani, B. Green and P. Mansfield for their \nvaluable insights and feedback during our research; A. Iurchenko for driving the design of the \ninteractive user interface; M. Howell, M. Morris, C. Grade, K. DeSalvo, Z. Ghahramani, J. Manyika \nand J. Dean for their support during the course of this project; and the Massachusetts Medical \nSociety group for the support and partnership.\nAuthor contributions D.M., M.S., T.T., A. Palepu, A. Pathak, J.S., A.K. and V.N. contributed to the \nconception and design of the work. D.M., M.S., T.T., A. Palepu, A.W., Y.S., K.K., J.S., A.K. and V.N. \ncontributed to the data acquisition and curation. T.T., A. Palepu, D.M., M.S. and K.S. contributed \nto the technical implementation. L.H., Y.C., Y.L., S.S.M., S. Prakash and A. Pathak provided \ntechnical and infrastructure guidance. J.S and A.K. provided clinical inputs to the study. D.M., \nM.S., T.T., A. Palepu, A.W., J. Garrison, K.S., Y.S., S.A., L.H., Y.C., Y.L., S.S.M., S. Prakash, A. Pathak, \nC.S., S. Patel, D.R.W., E.D., J. Gottweis, J.B., K.C., G.S.C., Y.M., J.S., A.K. and V.N. contributed to \nthe drafting and revising of the manuscript.\nCompeting interests This study was funded by Alphabet Inc. and/or a subsidiary thereof \n(‘Alphabet’). All authors are employees of Alphabet and may own stock as part of the standard \ncompensation.\nAdditional information\nSupplementary information The online version contains supplementary material available at \nhttps://doi.org/10.1038/s41586-025-08869-4.\nCorrespondence and requests for materials should be addressed to Daniel McDuff,  \nMike Schaekermann, Jake Sunshine, Alan Karthikesalingam or Vivek Natarajan.\nPeer review information Nature thanks Alexander Eriksen, Peter Szolovits and the other, \nanonymous, reviewer(s) for their contribution to the peer review of this work. Peer reviewer \nreports are available.\nReprints and permissions information is available at http://www.nature.com/reprints.\nExtended Data Fig. 1 | NEJM Clinicopathological Conference Case Reports. \nHistory of Present Illness, Admission Labs and Admission Imaging sections \nwere included in the redacted version presented to generalist clinicians for \nproducing a DDx. The LLM had access to only the History of Present Illness. \nSpecialist clinicians evaluating the quality of the DDx had access to the full \n(unredacted) case report including the expert differential discussion.\nArticle\nExtended Data Fig. 2 | The AMIE User Interface. The history of the present \nillness (text only) was pre-populated in the user interface (A) with an initial \nsuggested prompt to query the LLM (B). Following this prompt and response, \nthe user was free to enter any additional follow-up questions (C). The case \nshown in this figure is a mock case selected for illustrative purposes only.\nExtended Data Fig. 3 | Experimental Design. To evaluate the LLM’s ability to \ngenerate DDx lists and aid clinicians with their DDx generation, we designed a \ntwo-stage reader study. First, clinicians with access only to the case presentation \ncompleted DDx lists without using any assistive tools. Second, the clinicians \ncompleted DDx lists with access either  to Search engines and other resources \n(Condition I), or to LLM in addition to these tools (Condition II). Randomization \nwas employed such that every case was reviewed by two different clinicians, \none with LLM assistance and one without. In Condition II the clinician was given \na suggested initial prompt to use in the LLM interface and was then free to try \nany other questions. These DDx lists were then evaluated by a specialist who \nhad access to the full case and expert commentary on the differential diagnosis, \nbut who was blinded to whether and what assistive tool was used.\n1 nature portfolio  |  reporting summaryMarch 2021\nCorresponding author(s):\nDaniel McDuff, Mike Schakermann, Jacob \nSunshine, Alan Karthikesalingam, Vivek \nNatarajan\nLast updated by author(s): Jan 14, 2023\nReporting Summary\nNature Portfolio wishes to improve the reproducibility of the work that we publish. This form provides structure for consistency and transparency \nin reporting. For further information on Nature Portfolio policies, see our Editorial Policies and the Editorial Policy Checklist.\nStatistics\nFor all statistical analyses, confirm that the following items are present in the figure legend, table legend, main text, or Methods section.\nn/a Confirmed\nThe exact sample size (n) for each experimental group/condition, given as a discrete number and unit of measurement\nA statement on whether measurements were taken from distinct samples or whether the same sample was measured repeatedly\nThe statistical test(s) used AND whether they are one- or two-sided \nOnly common tests should be described solely by name; describe more complex techniques in the Methods section.\nA description of all covariates tested\nA description of any assumptions or corrections, such as tests of normality and adjustment for multiple comparisons\nA full description of the statistical parameters including central tendency (e.g. means) or other basic estimates (e.g. regression coefficient) \nAND variation (e.g. standard deviation) or associated estimates of uncertainty (e.g. confidence intervals)\nFor null hypothesis testing, the test statistic (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom and P value noted \nGive P values as exact values whenever suitable.\nFor Bayesian analysis, information on the choice of priors and Markov chain Monte Carlo settings\nFor hierarchical and complex designs, identification of the appropriate level for tests and full reporting of outcomes\nEstimates of effect sizes (e.g. Cohen's d, Pearson's r), indicating how they were calculated\nOur web collection on statistics for biologists contains articles on many of the points above.\nSoftware and code\nPolicy information about availability of computer code\nData collection The algorithms and scripts were implemented using Python.\nData analysis The data analyses scripts were implemented in Python.  We will not be able to open source the LLMs used in this study.\nFor manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published literature, software must be made available to editors and \nreviewers. We strongly encourage code deposition in a community repository (e.g. GitHub). See the Nature Portfolio guidelines for submitting code & software for further information.\nData\nPolicy information about availability of data\nAll manuscripts must include a data availability statement. This statement should provide the following information, where applicable: \n- Accession codes, unique identifiers, or web links for publicly available datasets \n- A description of any restrictions on data availability \n- For clinical datasets or third party data, please ensure that the statement adheres to our policy \n \nWe have provided the set of case IDs and the diagnoses generated by the models and clinicians as supplemental material with our submission.  We have also \nprovided instructions about how to access the model end-point for testing.\n2 nature portfolio  |  reporting summaryMarch 2021\nHuman research participants\nPolicy information about studies involving human research participants and Sex and Gender in Research. \nReporting on sex and gender n/a\nPopulation characteristics Nothing to add.\nRecruitment n/a\nEthics oversight n/a\nNote that full information on the approval of the study protocol must also be provided in the manuscript.\nField-specific reporting\nPlease select the one below that is the best fit for your research. If you are not sure, read the appropriate sections before making your selection.\nLife sciences Behavioural & social sciences  Ecological, evolutionary & environmental sciences\nFor a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.pdf\nLife sciences study design\nAll studies must disclose on these points even when the disclosure is negative.\nSample size The study included 302  published case reports from the New England Journal of Medicine.\nData exclusions All valid case reports with differential diagnoses were used.\nReplication The evaluations were performed by clinicial specialists.\nRandomization The study arms (AMIE and Search) were randomized.  The cases were also randomized amongst clinicians but within clinical specialties.\nBlinding The clinicians were not told which study arm they were exposed to in each case or which  study condition they were evaluating responses \nfrom.\nReporting for specific materials, systems and methods\nWe require information from authors about some types of materials, experimental systems and methods used in many studies. Here, indicate whether each material, \nsystem or method listed is relevant to your study. If you are not sure if a list item applies to your research, read the appropriate section before selecting a response. \nMaterials & experimental systems\nn/a Involved in the study\nAntibodies\nEukaryotic cell lines\nPalaeontology and archaeology\nAnimals and other organisms\nClinical data\nDual use research of concern\nMethods\nn/a Involved in the study\nChIP-seq\nFlow cytometry\nMRI-based neuroimaging\nAntibodies\nAntibodies used Describe all antibodies used in the study; as applicable, provide supplier name, catalog number, clone name, and lot number.\nValidation Describe the validation of each primary antibody for the species and application, noting any validation statements on the \nmanufacturer’s website, relevant citations, antibody profiles in online databases, or data provided in the manuscript.\n3 nature portfolio  |  reporting summaryMarch 2021\nEukaryotic cell lines\nPolicy information about cell lines and Sex and Gender in Research\nCell line source(s) State the source of each cell line used and the sex of all primary cell lines and cells derived from human participants or \nvertebrate models.\nAuthentication Describe the authentication procedures for each cell line used OR declare that none of the cell lines used were authenticated.\nMycoplasma contamination Confirm that all cell lines tested negative for mycoplasma contamination OR describe the results of the testing for \nmycoplasma contamination OR declare that the cell lines were not tested for mycoplasma contamination.\nCommonly misidentified lines\n(See ICLAC register)\nName any commonly misidentified cell lines used in the study and provide a rationale for their use.\nPalaeontology and Archaeology\nSpecimen provenance Provide provenance information for specimens and describe permits that were obtained for the work (including the name of the \nissuing authority, the date of issue, and any identifying information). Permits should encompass collection and, where applicable, \nexport.\nSpecimen deposition Indicate where the specimens have been deposited to permit free access by other researchers.\nDating methods If new dates are provided, describe how they were obtained (e.g. collection, storage, sample pretreatment and measurement), where \nthey were obtained (i.e. lab name), the calibration program and the protocol for quality assurance OR state that no new dates are \nprovided.\nTick this box to confirm that the raw and calibrated dates are available in the paper or in Supplementary Information.\nEthics oversight Identify the organization(s) that approved or provided guidance on the study protocol, OR state that no ethical approval or guidance \nwas required and explain why not.\nNote that full information on the approval of the study protocol must also be provided in the manuscript.\nAnimals and other research organisms\nPolicy information about studies involving animals; ARRIVE guidelines recommended for reporting animal research, and Sex and Gender in \nResearch\nLaboratory animals For laboratory animals, report species, strain and age OR state that the study did not involve laboratory animals.\nWild animals Provide details on animals observed in or captured in the field; report species and age where possible. Describe how animals were \ncaught and transported and what happened to captive animals after the study (if killed, explain why and describe method; if released, \nsay where and when) OR state that the study did not involve wild animals.\nReporting on sex Indicate if findings apply to only one sex; describe whether sex was considered in study design, methods used for assigning sex. \nProvide data disaggregated for sex where this information has been collected in the source data as appropriate; provide overall \nnumbers in this Reporting Summary. Please state if this information has not been collected.  Report sex-based analyses where \nperformed, justify reasons for lack of sex-based analysis.\nField-collected samples For laboratory work with field-collected samples, describe all relevant parameters such as housing, maintenance, temperature, \nphotoperiod and end-of-experiment protocol OR state that the study did not involve samples collected from the field.\nEthics oversight Identify the organization(s) that approved or provided guidance on the study protocol, OR state that no ethical approval or guidance \nwas required and explain why not.\nNote that full information on the approval of the study protocol must also be provided in the manuscript.\nClinical data\nPolicy information about clinical studies\nAll manuscripts should comply with the ICMJE guidelines for publication of clinical research and a completed CONSORT checklist must be included with all submissions.\nClinical trial registration Provide the trial registration number from ClinicalTrials.gov or an equivalent agency.\nStudy protocol Note where the full trial protocol can be accessed OR if not available, explain why.\nData collection Describe the settings and locales of data collection, noting the time periods of recruitment and data collection.\n4 nature portfolio  |  reporting summaryMarch 2021\nOutcomes Describe how you pre-defined primary and secondary outcome measures and how you assessed these measures.\nDual use research of concern\nPolicy information about dual use research of concern\nHazards\nCould the accidental, deliberate or reckless misuse of agents or technologies generated in the work, or the application of information presented \nin the manuscript, pose a threat to:\nNo Yes\nPublic health\nNational security\nCrops and/or livestock\nEcosystems\nAny other significant area\nExperiments of concern\nDoes the work involve any of these experiments of concern:\nNo Yes\nDemonstrate how to render a vaccine ineffective\nConfer resistance to therapeutically useful antibiotics or antiviral agents\nEnhance the virulence of a pathogen or render a nonpathogen virulent\nIncrease transmissibility of a pathogen\nAlter the host range of a pathogen\nEnable evasion of diagnostic/detection modalities\nEnable the weaponization of a biological agent or toxin\nAny other potentially harmful combination of experiments and agents\nChIP-seq\nData deposition\nConfirm that both raw and final processed data have been deposited in a public database such as GEO.\nConfirm that you have deposited or provided access to graph files (e.g. BED files) for the called peaks.\nData access links \nMay remain private before publication.\nFor \"Initial submission\" or \"Revised version\" documents, provide reviewer access links.  For your \"Final submission\" document, \nprovide a link to the deposited data.\nFiles in database submission Provide a list of all files available in the database submission.\nGenome browser session \n(e.g. UCSC)\nProvide a link to an anonymized genome browser session for \"Initial submission\" and \"Revised version\" documents only, to \nenable peer review.  Write \"no longer applicable\" for \"Final submission\" documents.\nMethodology\nReplicates Describe the experimental replicates, specifying number, type and replicate agreement.\nSequencing depth Describe the sequencing depth for each experiment, providing the total number of reads, uniquely mapped reads, length of reads and \nwhether they were paired- or single-end.\nAntibodies Describe the antibodies used for the ChIP-seq experiments; as applicable, provide supplier name, catalog number, clone name, and lot \nnumber.\nPeak calling parameters Specify the command line program and parameters used for read mapping and peak calling, including the ChIP, control and index files \nused.\nData quality Describe the methods used to ensure data quality in full detail, including how many peaks are at FDR 5% and above 5-fold enrichment.\nSoftware Describe the software used to collect and analyze the ChIP-seq data. For custom code that has been deposited into a community \nrepository, provide accession details.\n5 nature portfolio  |  reporting summaryMarch 2021\nFlow Cytometry\nPlots\nConfirm that:\nThe axis labels state the marker and fluorochrome used (e.g. CD4-FITC).\nThe axis scales are clearly visible. Include numbers along axes only for bottom left plot of group (a 'group' is an analysis of identical markers).\nAll plots are contour plots with outliers or pseudocolor plots.\nA numerical value for number of cells or percentage (with statistics) is provided.\nMethodology\nSample preparation Describe the sample preparation, detailing the biological source of the cells and any tissue processing steps used.\nInstrument Identify the instrument used for data collection, specifying make and model number.\nSoftware Describe the software used to collect and analyze the flow cytometry data. For custom code that has been deposited into a \ncommunity repository, provide accession details.\nCell population abundance Describe the abundance of the relevant cell populations within post-sort fractions, providing details on the purity of the \nsamples and how it was determined.\nGating strategy Describe the gating strategy used for all relevant experiments, specifying the preliminary FSC/SSC gates of the starting cell \npopulation, indicating where boundaries between \"positive\" and \"negative\" staining cell populations are defined.\nTick this box to confirm that a figure exemplifying the gating strategy is provided in the Supplementary Information.\nMagnetic resonance imaging\nExperimental design\nDesign type Indicate task or resting state; event-related or block design.\nDesign specifications Specify the number of blocks, trials or experimental units per session and/or subject, and specify the length of each trial \nor block (if trials are blocked) and interval between trials.\nBehavioral performance measures State number and/or type of variables recorded (e.g. correct button press, response time) and what statistics were used \nto establish that the subjects were performing the task as expected (e.g. mean, range, and/or standard deviation across \nsubjects).\nAcquisition\nImaging type(s) Specify: functional, structural, diffusion, perfusion.\nField strength Specify in Tesla\nSequence & imaging parameters Specify the pulse sequence type (gradient echo, spin echo, etc.), imaging type (EPI, spiral, etc.), field of view, matrix size, \nslice thickness, orientation and TE/TR/flip angle.\nArea of acquisition State whether a whole brain scan was used OR define the area of acquisition, describing how the region was determined.\nDiffusion MRI Used Not used\nPreprocessing\nPreprocessing software Provide detail on software version and revision number and on specific parameters (model/functions, brain extraction, \nsegmentation, smoothing kernel size, etc.).\nNormalization If data were normalized/standardized, describe the approach(es): specify linear or non-linear and define image types used for \ntransformation OR indicate that data were not normalized and explain rationale for lack of normalization.\nNormalization template Describe the template used for normalization/transformation, specifying subject space or group standardized space (e.g. \noriginal Talairach, MNI305, ICBM152) OR indicate that the data were not normalized.\nNoise and artifact removal Describe your procedure(s) for artifact and structured noise removal, specifying motion parameters, tissue signals and \nphysiological signals (heart rate, respiration).\n6 nature portfolio  |  reporting summaryMarch 2021\nVolume censoring Define your software and/or method and criteria for volume censoring, and state the extent of such censoring.\nStatistical modeling & inference\nModel type and settings Specify type (mass univariate, multivariate, RSA, predictive, etc.) and describe essential details of the model at the first and \nsecond levels (e.g. fixed, random or mixed effects; drift or auto-correlation).\nEffect(s) tested Define precise effect in terms of the task or stimulus conditions instead of psychological concepts and indicate whether \nANOVA or factorial designs were used.\nSpecify type of analysis: Whole brain ROI-based Both\nStatistic type for inference\n(See Eklund et al. 2016)\nSpecify voxel-wise or cluster-wise and report all relevant parameters for cluster-wise methods.\nCorrection Describe the type of correction and how it is obtained for multiple comparisons (e.g. FWE, FDR, permutation or Monte Carlo).\nModels & analysis\nn/a Involved in the study\nFunctional and/or effective connectivity\nGraph analysis\nMultivariate modeling or predictive analysis\nFunctional and/or effective connectivity Report the measures of dependence used and the model details (e.g. Pearson correlation, partial correlation, \nmutual information).\nGraph analysis Report the dependent variable and connectivity measure, specifying weighted graph or binarized graph, \nsubject- or group-level, and the global and/or node summaries used (e.g. clustering coefficient, efficiency, \netc.).\nMultivariate modeling and predictive analysis Specify independent variables, features extraction and dimension reduction, model, training and evaluation \nmetrics."
}