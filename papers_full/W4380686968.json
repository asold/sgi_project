{
    "title": "14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon",
    "url": "https://openalex.org/W4380686968",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A4224533595",
            "name": "Jablonka, Kevin Maik",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4227230353",
            "name": "Ai, Qianxiang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712937",
            "name": "Al-Feghali, Alexander",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712938",
            "name": "Badhwar, Shruti",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4293342618",
            "name": "Bocarsly, Joshua D.",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4366006106",
            "name": "Bran, Andres M",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4288612619",
            "name": "Bringuier, Stefan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2747506058",
            "name": "Brinson, L. Catherine",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3179371880",
            "name": "Choudhary, Kamal",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712943",
            "name": "Circi, Defne",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4209725676",
            "name": "Cox, Sam",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4223509961",
            "name": "de Jong, Wibe A.",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712946",
            "name": "Evans, Matthew L.",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4226814809",
            "name": "Gastellu, Nicolas",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712948",
            "name": "Genzling, Jerome",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712949",
            "name": "Gil, María Victoria",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712950",
            "name": "Gupta, Ankur K.",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2098805119",
            "name": "Hong Zhi",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4282048074",
            "name": "Imran, Alishba",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712953",
            "name": "Kruschwitz, Sabine",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4304544021",
            "name": "Labarre, Anne",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712955",
            "name": "Lála, Jakub",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2069101955",
            "name": "Liu Tao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4288647460",
            "name": "Ma, Steven",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712958",
            "name": "Majumdar, Sauradeep",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712959",
            "name": "Merz, Garrett W.",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2746204309",
            "name": "Moitessier Nicolas",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712961",
            "name": "Moubarak, Elias",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712962",
            "name": "Mouriño, Beatriz",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712963",
            "name": "Pelkie, Brenden",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4223932253",
            "name": "Pieler, Michael",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4365823161",
            "name": "Ramos, Mayk Caldas",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4311001552",
            "name": "Ranković, Bojana",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712967",
            "name": "Rodriques, Samuel G.",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4294565583",
            "name": "Sanders, Jacob N.",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4227230371",
            "name": "Schwaller, Philippe",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4229133475",
            "name": "Schwarting, Marcus",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2691167142",
            "name": "Shi Jiale",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2615668886",
            "name": "Smit Berend",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712973",
            "name": "Smith, Ben E.",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380724406",
            "name": "Van Herck, Joren",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2640925643",
            "name": "Völker Christoph",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3161317044",
            "name": "Ward Logan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712977",
            "name": "Warren, Sean",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712978",
            "name": "Weiser, Benjamin",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712979",
            "name": "Zhang, Sylvester",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1998330397",
            "name": "Zhang Xiaoqi",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712981",
            "name": "Zia, Ghezal Ahmad",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4284767936",
            "name": "Scourtas, Aristana",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4380712983",
            "name": "Schmidt Kj",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2262586750",
            "name": "Foster, Ian",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4224193931",
            "name": "White, Andrew D.",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2276621114",
            "name": "Blaiszik, Ben",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2140047797",
        "https://openalex.org/W4306179830",
        "https://openalex.org/W3198449425",
        "https://openalex.org/W2801555904",
        "https://openalex.org/W2988055229",
        "https://openalex.org/W4225405705",
        "https://openalex.org/W2955551200",
        "https://openalex.org/W2150099651",
        "https://openalex.org/W3104073206",
        "https://openalex.org/W4214842232",
        "https://openalex.org/W2953641512",
        "https://openalex.org/W2884430236",
        "https://openalex.org/W2899070097",
        "https://openalex.org/W4396723768",
        "https://openalex.org/W4307468223",
        "https://openalex.org/W2027788760",
        "https://openalex.org/W2039827935",
        "https://openalex.org/W2080635178",
        "https://openalex.org/W3189385021",
        "https://openalex.org/W4317853296",
        "https://openalex.org/W2769423117",
        "https://openalex.org/W3102096994",
        "https://openalex.org/W4377096651",
        "https://openalex.org/W3098321015",
        "https://openalex.org/W2883583109",
        "https://openalex.org/W4391836235",
        "https://openalex.org/W4304185479",
        "https://openalex.org/W3203573929",
        "https://openalex.org/W4225009204",
        "https://openalex.org/W4366140592",
        "https://openalex.org/W4324308135",
        "https://openalex.org/W3128474010",
        "https://openalex.org/W4319996831",
        "https://openalex.org/W4226050570",
        "https://openalex.org/W3168661259",
        "https://openalex.org/W2029667189",
        "https://openalex.org/W3186179742",
        "https://openalex.org/W3209726219",
        "https://openalex.org/W1971044734"
    ],
    "abstract": "We report the findings of a hackathon focused on exploring the diverse applications of large language models in molecular and materials science.",
    "full_text": "14 Examples of How LLMs Can Transform Materials Science\nand Chemistry: A Reflection on a Large Language Model\nHackathon\nKevin Maik Jablonka ,1, ∗ Qianxiang Ai ,2, † Alexander Al-Feghali ,3, †\nShruti Badhwar ,4, † Joshua D. Bocarsly ,5, † Andres M Bran ,6, 7,†\nStefan Bringuier ,8, † L. Catherine Brinson ,9, † Kamal Choudhary ,10, †\nDefne Circi ,9, † Sam Cox ,11, † Wibe A. de Jong ,12, † Matthew L. Evans ,13, 14,†\nNicolas Gastellu ,3, † Jerome Genzling ,3, † Mar´ ıa Victoria Gil ,15, †\nAnkur K. Gupta ,12, † Zhi Hong ,16, † Alishba Imran,17, † Sabine Kruschwitz ,18, †\nAnne Labarre ,3, † Jakub L´ ala ,19, † Tao Liu ,3, † Steven Ma ,3, †\nSauradeep Majumdar ,1, † Garrett W. Merz ,20, † Nicolas Moitessier ,3, †\nElias Moubarak ,1, † Beatriz Mouri˜ no ,1, † Brenden Pelkie ,21, †\nMichael Pieler ,22, 23,† Mayk Caldas Ramos ,11, † Bojana Rankovi´ c ,6, 7,†\nSamuel G. Rodriques ,19, † Jacob N. Sanders ,24, † Philippe Schwaller ,6, 7,†\nMarcus Schwarting,25, † Jiale Shi ,2, † Berend Smit ,1, † Ben E. Smith ,5, †\nJoren Van Herck ,1, † Christoph V¨ olker ,18, † Logan Ward ,26, †\nSean Warren ,3, † Benjamin Weiser ,3, † Sylvester Zhang,3, †\nXiaoqi Zhang ,1, † Ghezal Ahmad Zia ,18, † Aristana Scourtas ,27\nKJ Schmidt,27 Ian Foster ,28 Andrew D. White ,11 and Ben Blaiszik 27, ‡\n1Laboratory of Molecular Simulation (LSMO),\nInstitut des Sciences et Ing´ enierie Chimiques,\nEcole Polytechnique F´ ed´ erale de Lausanne (EPFL), Sion, Valais, Switzerland.\n2Department of Chemical Engineering,\nMassachusetts Institute of Technology,\nCambridge, Massachusetts 02139, United States.\n3Department of Chemistry, McGill University, Montreal, Quebec, Canada.\n4Reincarnate Inc.\n5Yusuf Hamied Department of Chemistry,\nUniversity of Cambridge, Lensfield Road,\nCambridge, CB2 1EW, United Kingdom.\n1\narXiv:2306.06283v4  [cond-mat.mtrl-sci]  14 Jul 2023\n6Laboratory of Artificial Chemical Intelligence (LIAC),\nInstitut des Sciences et Ing´ enierie Chimiques,\nEcole Polytechnique F´ ed´ erale de Lausanne (EPFL), Lausanne, Switzerland.\n7National Centre of Competence in Research (NCCR) Catalysis,\nEcole Polytechnique F´ ed´ erale de Lausanne (EPFL), Lausanne, Switzerland.\n8Independent Researcher, San Diego, CA, United States.\n9Mechanical Engineering and Materials Science, Duke University, United States.\n10 Material Measurement Laboratory,\nNational Institute of Standards and Technology, Maryland, 20899, United States.\n11Department of Chemical Engineering,\nUniversity of Rochester, United States.\n12Applied Mathematics and Computational Research Division,\nLawrence Berkeley National Laboratory,\nBerkeley, CA 94720, United States.\n13Institut de la Mati` ere Condens´ ee et des Nanosciences (IMCN),\nUCLouvain, Chemin des ´Etoiles 8, Louvain-la-Neuve, 1348, Belgium.\n14Matgenix SRL, 185 Rue Armand Bury, 6534 Goz´ ee, Belgium.\n15Instituto de Ciencia y Tecnolog´ ıa del Carbono (INCAR),\nCSIC, Francisco Pintado Fe 26, 33011 Oviedo, Spain.\n16Department of Computer Science, University of Chicago,\nChicago, Illinois 60637, United States.\n17Computer Science, University of California,\nBerkeley, Berkeley CA 94704, United States.\n18Bundesanstalt f¨ ur Materialforschung und -pr¨ ufung,\nUnter den Eichen 87, 12205 Berlin, Germany.\n19Francis Crick Institute, 1 Midland Rd,\nLondon NW1 1AT, United Kingdom.\n20American Family Insurance Data Science Institute,\nUniversity of Wisconsin-Madison, Madison WI 53706, United States.\n21Department of Chemical Engineering,\nUniversity of Washington, Seattle, WA 98105, United States.\n22OpenBioML.org\n23Stability.AI\n2\n24Department of Chemistry and Biochemistry,\nUniversity of California, Los Angeles, CA 90095, United States.\n25Department of Computer Science,\nUniversity of Chicago, Chicago IL 60490, United States.\n26Data Science and Learning Division,\nArgonne National Lab, United States.\n27Globus, University of Chicago, Data Science and Learning Division,\nArgonne National Lab, United States.\n28Department of Computer Science, University of Chicago,\nData Science and Learning Division,\nArgonne National Lab, United States.\nAbstract\nLarge-language models (LLMs) such as GPT-4 caught the interest of many scientists. Recent\nstudies suggested that these models could be useful in chemistry and materials science. To\nexplore these possibilities, we organized a hackathon.\nThis article chronicles the projects built as part of this hackathon. Participants employed\nLLMs for various applications, including predicting properties of molecules and materials, de-\nsigning novel interfaces for tools, extracting knowledge from unstructured data, and developing\nnew educational applications.\nThe diverse topics and the fact that working prototypes could be generated in less than two\ndays highlight that LLMs will profoundly impact the future of our fields. The rich collection\nof ideas and projects also indicates that the applications of LLMs are not limited to materials\nscience and chemistry but offer potential benefits to a wide range of scientific disciplines.\n∗Electronic address: mail@kjablonka.com\n†These authors contributed equally\n‡Electronic address: blaiszik@uchicago.edu\n3\nI. INTRODUCTION\nThe intersection of machine learning (ML) with chemistry and materials science has\nwitnessed remarkable advancements in recent years [1–9]. Much progress has been made\nin using ML to, e.g., accelerate simulations [10, 11] or to directly predict properties\nor compounds for a given application [12]. Thereby, developing custom, hand-crafted\nmodels for any given application is still common practice. Since science rewards doing\nnovel things for the first time, we now face a deluge of tools and machine-learning models\nfor various tasks. These tools commonly require input data in their own rigid, well-\ndefined form (e.g., a table with specific columns or images from a specific microscope with\nspecific dimensions). Further, they typically also report their outputs in non-standard\nand sometimes proprietary forms.\nThis rigidity sharply contrasts the standard practice in the (experimental) molecular\nand materials sciences, which is intrinsically fuzzy and highly context-dependent [13].\nFor instance, researchers have many ways to refer to a molecule (e.g., IUPAC name,\nconventional name, simplified molecular-input line-entry system (SMILES) [14]) and to\nreport results and procedures. In particular, for the latter, it is known that small details\nsuch as the order of addition or the strength of stirring (e.g., “gently” vs. “strongly”)\nare crucial in determining the outcome of reactions. We do not have a natural way\nto deal with this fuzziness, and often a conversion into structured tabular form (the\nconventional input format for ML models) is impossible. Our current “solution” is to write\nconversion programs and chain many tools with plenty of application-specific “glue code”\nto enable scientific workflows. However, this fuzziness chemistry and heterogeneity of\ntools have profound consequences: A never-ending stream of new file formats, interfaces,\nand interoperability tools exists, and users cannot keep up with learning [15]. In addition,\nalmost any transformation of highly context-dependent text (e.g., description of a reaction\nprocedure) into structured, tabular form will lead to a loss of information.\nOne of the aims of this work is to demonstrate how large language models (LLMs)\nsuch as the generative pretrained transformer (GPT)-4 [16–21], can be used to address\nthese challenges. Foundation models such as GPTs are general-purpose technologies [22]\nthat can solve tasks they have not explicitly been trained on [23, 24], use tools [25–\n27], and be grounded in knowledge bases [28, 29]. As we also show in this work, they\nprovide new pathways of exploration, new opportunities for flexible interfaces, and may\nbe used to effectively solve certain tasks themselves; e.g., we envision LLMs enabling non-\n4\nexperts to program (“malleable software”) using natural language as the “programming\nlanguage” [30], extract structured information, and create digital assistants that make\nour tools interoperable—all based on unstructured, natural-language inputs.\nInspired by early reports on the use of these LLMs in chemical research [31–34], we\norganized a virtual hackathon event focused on understanding the applicability of LLMs\nto materials science and chemistry. The hackathon aimed to explore the multifaceted\napplications of LLMs in materials science and chemistry and encourage creative solutions\nto some of the pressing challenges in the field. This article showcases some of the projects\n(Table I) developed during the hackathon.\nOne of the conclusions of this work is that without these LLMs, such projects would\ntake many months. The diversity of topics these projects address illustrates the broad\napplicability of LLMs; the projects touch many different aspects of materials science and\nchemistry, from the wet lab to the computational chemistry lab, software interfaces, and\neven the classroom. While the examples below are not yet polished products, the simple\nobservation that such capabilities could be created in hours underlines that we need to\nstart thinking about how LLMs will impact the future of materials science, chemistry,\nand beyond [35]. The diverse applications show that LLMs are here to stay and are likely\na foundational capability that will be integrated into most aspects of the research process.\nEven so, the pace of the developments highlights that we are only beginning to scratch\nthe surface of what LLMs can do for chemistry and materials science.\nTable I lists the different projects created in this collaborative effort across eight coun-\ntries and 22 institutions (SI section V). One might expect that 1.5 days of intense collab-\norations would, at best, allow a cursory exploration of a topic. However, the diversity of\ntopics and the diversity in the participants’ expertise, combined with the need to deliver\na working prototype (within a short window of time) and the ease of prototyping with\nLLMs, generated not only many questions but also pragmatic solutions. In the remainder\nof this article, we focus on the insights we obtained from this collective effort. For the\ndetails of each project, we refer to the SI.\nWe have grouped the projects into four categories: 1. predictive modeling, 2. automa-\ntion and novel interfaces , 3. knowledge extraction , and 4. education . The projects in\nthe predictive modeling category use LLMs for classification and regression tasks—and\nalso investigate ways to incorporate established concepts such as ∆-ML [36] or novel con-\ncepts such as “fuzzy” context into the modeling. The automation and novel interfaces\n5\nTable I: Overview of the developed tools and links to source code repositories. Full descriptions\nof the projects can be found in the Supplementary Material.\nname authors links\nPredictive modeling\nAccurate Molecular Energy Predictions Ankur K. Gupta, Garrett W. Merz,\nAlishba Imran, Wibe A. de Jong\n/gtbankur56/ChemLoRA\n10.5281/zenodo.8104930\nText2Concrete Sabine Kruschwitz, Christoph V¨ olker,\nGhezal Ahmad Zia\n/gtbghezalahmad/LLMs-for-the-Design-of-Sustainable-\nConcretes\n10.5281/zenodo.8091195\nMolecule Discovery by Context Zhi Hong, Logan Ward\n globuslabs/ScholarBERT-XL\n10.5281/zenodo.8122087\nGenetic algorithm without genes Benjamin Weiser, Jerome Genzling,\nNicolas Gastellu, Sylvester Zhang, Tao Liu,\nAlexander Al-Feghali, Nicolas Moitessier,\nAnne Labarre, Steven Ma\n/gtbBenjaminWeiser/LLM-Guided-GA\n10.5281/zenodo.8125541\nText-template paraphrasing Michael Pieler /gtbmicpie/text-template-paraphrasing-chemistry\n10.5281/zenodo.8093615\nAutomation and novel interfaces\nBOLLaMa Bojana Rankovi´ c, Andres M. Bran,\nPhilippe Schwaller\n/gtbdoncamilom/BOLLaMa\n10.5281/zenodo.8096827\nsMolTalk Jakub L´ ala, Sean Warren,\nSamuel G. Rodriques\n/gtbjakublala/smoltalk-legacy\n10.5281/zenodo.8081749\nMAPI-LLM Mayk Caldas Ramos, Sam Cox,\nAndrew White\n/gtbmaykcaldas/MAPI_LLM\nmaykcaldas/MAPI_LLM\n10.5281/zenodo.8097336\nConversational ELN interface (Whinchat) Joshua D. Bocarsly, Matthew L. Evans and\nBen E. Smith\n/gtbthe-grey-group/datalab\n10.5281/zenodo.8127782\nKnowledge Extraction\nInsightGraph Defne Circi, Shruti Badhwar /gtbdefnecirci/InsightGraph\n10.5281/zenodo.8092575\nExtracting Structured Data from\nFree-form Organic Synthesis Text\nQianxiang Ai, Jacob N. Sanders, Jiale Shi,\nStefan Bringuier, Brenden Pelkie,\nMarcus Schwarting\n/gtbqai222/LLM_organic_synthesis\n10.5281/zenodo.8091902\nTableToJson: Structured information\nfrom scientific data in tables\nMar´ ıa Victoria Gil /gtbvgvinter/TableToJson\n10.5281/zenodo.8093731\nAbstractToTitle & TitleToAbstract:\ntext summarization and generation\nKamal Choudhary /gtbusnistgov/chemnlp\n10.5281/zenodo.8122419\nEducation\nI-Digest Beatriz Mouri˜ no, Elias Moubarak,\nJoren Van Herck, Sauradeep Majumdar,\nXiaoqi Zhang\n/gtbXiaoqZhang/i-Digest\n10.5281/zenodo.8080962\nprojects show that natural language might be the universal “glue” connecting our tools—\nperhaps in the future, we will need not to focus on new formats or standards but rather\nuse natural language descriptions to connect across the existing diversity and different\nmodalities [35].\nLLMs can also help make knowledge more accessible, as the projects in the “knowledge\nextraction” category show; they can extract structured information from unstructured\ntext. In addition, as the project in the “education” category shows, LLMs can also offer\nnew educational opportunities.\nA. Predictive modeling\nPredictive modeling is a common application of ML in chemistry. Based on the\nlanguage-interfaced fine-tuning (LIFT) framework [37], Jablonka et al. [32] have shown\n6\nthat LLMs can be employed to predict various chemical properties, such as solubility or\nHOMO-LUMO gaps based on line representations of molecules such as self-referencing\nembedded strings (SELFIES) [38, 39] and SMILES. Taking this idea even further,\nRamos et al. [34] used this framework (with in-context learning (ICL)) for Bayesian\noptimization—guiding experiments without even training models.\nThe projects in the following build on top of those initial results and extend them\nin novel ways as well as by leveraging established techniques from quantum machine\nlearning.\nGiven that these encouraging results could be achieved with and without fine-tuning\n(i.e., updates to the weights of the model) for the language-interfaced training on tabular\ndatasets, we use the term LIFT also for ICL settings in which structured data is converted\ninto text prompts for an LLM.\na. Molecular Energy Predictions\nA critical property in quantum chemistry is the atomization energy of a molecule,\nwhich gives us the basic thermochemical data used to determine a molecule’s stability or\nreactivity. State-of-the-art quantum chemical methods (i.e., G4(MP2) [40]) can predict\nthis energy with an accuracy of 0 .034 eV (or 0 .79 kcal/mol) [41, 42]. This accuracy is\nsimilar to, and in some cases even better than, the accuracy that can be reached experi-\nmentally. This motivated Ramakrishnan et al. [41] and Narayanan et al. [42] to compute\nthese atomization energies for the 134,000 molecules in the QM9-G4MP2 dataset.\nThe Berkeley-Madison team (Ankur Gupta, Garrett Merz, Alishba Imran, and\nWibe de Jong) used this dataset to fine-tune different LLMs using the LIFT frame-\nwork. The team investigated if they could use an LLM to predict atomization energies\nwith chemical accuracy. Jablonka et al. [32] emphasized that these LLMs might be par-\nticularly useful in the low-data limit. Here, we have a relatively large dataset, so it is an\nideal system to gather insights into the performance of these models for datasets much\nlarger than those used by Jablonka et al. [32].\nThe Berkeley-Madison team showed that the LIFT framework based on simple line\nrepresentations such as SMILES and SELFIES [38, 39] can yield good predictions (R 2 >\n0.95 on a holdout test set), that are, however, still inferior to dedicated models that have\naccess to 3D information [43, 44]. An alternative approach to achieve chemical accuracy\nwith LLMs tuned only on string representations is to leverage a ∆-ML scheme [45] in\nwhich the LLM is tuned to predict the difference between G4(MP2) and B3LYP [46]\n7\nTable II: LIFT for molecular atomization energies on the QM9-G4MP2 dataset. Metrics for\nmodels tuned on 90% of the QM9-G4MP2 dataset (117,232 molecules), using 10% (13,026\nmolecules) as a holdout test set. GPTChem refers to the approach reported by Jablonka et al.\n[32], GPT-2-LoRA to PEFT of the GPT-2 model using LoRA. The results indicate that the\nLIFT framework can also be used to build predictive models for atomization energies, that can\nreach chemical accuracy using a ∆-ML scheme. Baseline performance (mean absolute error\nreported by Ward et al. [44]): 0 .0223 eV for FCHL-based prediction of GP4(MP2) atomization\nenergies and 0.0045 eV (SchNet) and 0.0052 eV (FCHL) for the ∆-ML scheme.\nmol. repr. & framework G4(MP2) Atomization Energy (G4(MP2)-B3LYP) Atomization Energy\nR2 MAD / eV R 2 MAD / eV\nSMILES: GPTChem 0.984 0.99 0.976 0.03\nSELFIES: GPTChem 0.961 1.18 0.973 0.03\nSMILES: GPT2-LoRA 0.931 2.03 0.910 0.06\nSELFIES: GPT2-LoRA 0.959 1.93 0.915 0.06\nenergies. Table II shows that good agreement could be achieved for the ∆-ML approach.\nThis showcases how techniques established for conventional ML on molecules can also be\napplied with LLMs.\nImportantly, this approach is not limited to the OpenAI application programming\ninterface (API). With PEFT with LoRA [47] of the GPT-2 model [48], one can also obtain\ncomparable results on consumer hardware. These results make the LIFT approach widely\nmore accessible and allow research to the LIFT framework for chemistry without relying\non OpenAI.\nb. Text2Concrete\nConcrete is the most used construction material, and the mechanical properties and\nclimate impact of these materials are a complex function of the processing and formula-\ntion. Much research is focused on formulations of concrete that are less CO2 intensive. [49]\nTo expedite the design process, e.g., by prioritizing experiments using ML-predictions,\ndata-driven methods have been investigated by V¨ olker et al. [50] The Text2Concrete\nteam (Sabine Kruschwitz, Christoph V¨ olker, and Ghezal Ahmad Zia) explored, based on\ndata reported by Rao and Rao [51], whether LLMs can be used for this task. This data\nset provides 240 alternative, more sustainable, concrete formulations and their respective\ncompressive strengths. From a practical point of view, one would like to have a model\nthat can predict the compressive strength of the concrete as a function of its formulation.\nInterestingly, the largest LLMs can already give predictions without any fine-tuning.\nThese models can “learn” from the few examples provided by the user in the prompt.\nOf course, such a few-shot approach (or ICL, [20]) does not allow for the same type of\n8\noptimization as fine-tuning, and one can therefore expect it to be less accurate. However,\nRamos et al. [34] showed that this method could perform well—especially if only so few\ndata points are available such that fine-tuning is not a suitable approach.\nFor their case study, the Text2Concrete team found a predictive accuracy comparable\nto a Gaussian process regression (GPR) model (but inferior to a random forest (RF)\nmodel). However, one significant advantage of LLMs is that one can easily incorporate\ncontext. The Text2Concrete team used this to include well-established design principles\nlike the influence of the water-to-cement ratio on strength (Figure 1) into the modeling\nby simply stating the relationship between the features in natural language (e.g., “high\nwater/cement ratio reduces strength”). This additional context reduced the outliers and\noutperformed the RF model (R 2 of 0.67 and 0.72, respectively).\nThe exciting aspect is that this is a typical example of domain knowledge that cannot\nbe captured with a simple equation incorporable into conventional modeling workflows.\nSuch “fuzzy” domain knowledge, which may sometimes exist only in the minds of re-\nsearchers, is common in chemistry and materials science. With the incorporation of such\n“fuzzy” knowledge into LIFT-based predictions using LLMs, we now have a novel and\nvery promising approach to leverage such domain expertise that we could not leverage\nbefore. Interestingly, this also may provide a way to test “fuzzy” hypotheses, e.g., a\nresearcher could describe the hypothesis in natural language and see how it affects the\nmodel accuracy. While the Text2Concrete example has not exhaustively analyzed how\n“fuzzy” context alterations affect LLM performance, we recognize this as a key area for fu-\nture research that could enhance the application of LLMs and our approach to leveraging\n“fuzzy” domain knowledge within materials science.\nc. Molecule Discovery by Context\nMuch context is available in the full text of scientific articles. This has been exploited\nby Tshitoyan et al. [52] who used a Word2Vec [53] approach to embed words into a vector\nspace. Word2Vec does so by tasking a model to predict for a word the probability for\nall possible next words in a vocabulary. In this way, word embeddings capture syntactic\nand semantic details of lexical items (i.e., words). When applied to material science ab-\nstracts, the word embeddings of compounds such as Li 2CuSb could be used for materials\ndiscovery by measuring their distance (cosine similarity) to concepts such as “thermo-\nelectric”. [54] However, traditional Word2Vec, as used by Tshitoyan et al. [52], only\nproduces static embeddings, which remain unchanged after training. Word embeddings\n9\nFigure 1: Using LLMs to predict the compressive strength of concretes . An illustration of the\nconventional approach for solving this task, i.e., training classical prediction models using ten\ntraining data points as tabular data (left). Using the LIFT framework LLMs can also use tabular\ndata and leverage context information provided in natural language (right). The context can\nbe “fuzzy” design rules often known in chemistry and materials science but hard to incorporate\nin conventional ML models. Augmented with this context and ten training examples, ICL with\nLLM leads to a performance that outperforms baselines such as RFs or GPR.\nextracted from an LLM, on the other hand, are contextualized on the specific sequence\n(sentence) in which they are used and, therefore, can more effectively capture the contexts\nof words within a given corpus [55]. Inspired by this, the GlobusLabs team (Zhi Hong,\nLogan Ward) investigated if similar embeddings could be used to discover hydrogen car-\nrier molecules, that are relevant for energy storage applications. For this, they leverage\nthe ScholarBert model [56] trained on a large corpus of scientific articles collected by\nthe Public.Resource.Org nonprofit organization. For different candidate molecules, they\nsearched for sentences in the Public.Resource.Org corpus and used the average of the\nembeddings of these sentences as a fingerprint of the molecules. Given those fingerprints,\nthey could rank molecules by how close their fingerprints are to the ones of known hy-\ndrogen carrier molecules. Visual inspection indicates that the selected molecules indeed\nbear similarities to known hydrogen carrier molecules.\nd. Text template paraphrasing\nIn the LIFT framework used in the examples above, the data are embedded in so-\ncalled prompt templates that can have a form like What is the <property name> of\n<representation>?, where the texts in chevrons are placeholders that are replaced with\nactual values such as “solubility” and “2-acetyloxybenzoic acid”. In the low-data regime,\ndata points are “wasted” by the model needing to learn the syntax of the prompt tem-\nplates. In the big-data regime, in contrast, one might worry that the model loses some of\nits general language modeling abilities by always dealing with the same template. This\n10\nnaturally raises the question if one can augment the dataset to mitigate these problems—\nthereby leveraging again, similar to ∆-ML, a technique that has found use in conventional\nML previously. However, text-based data are challenging to augment due to their discrete\nnature and the fact that the augmented text still needs to be syntactically and seman-\ntically valid. Interestingly, as Michael Pieler (OpenBioML.org and Stability.AI) shows\n(and as has been explored by Dai et al. [57]), it turns out that LLMs can also be used to\naddress this problem by simply prompting an LLM (e.g., GPT-4 or Anthrophic’s Claude)\nto paraphrase a prompt template (see SI section ID).\nThis approach will allow us to automatically create new paraphrased high-quality\nprompts for LIFT-based training very efficiently—to augment the dataset and reduce the\nrisk of overfitting to a specific template. Latter might be particularly important if one\nstill wants to retain general language abilities of the LLMs after finetuning.\ne. Genetic algorithm using an LLM\nGenetic algorithms are popular methods for generating new structures; they are evo-\nlutionary algorithms in which building blocks (e.g., fragments of SMILES strings) are\niteratively crossed over, mutated, and subjected to other genetic operations to evolve\nstructures with better performance (such as catalysts with higher conversion) [58]. The\nefficiency of such a genetic algorithm often depends on how well the genes and genetic\noperations match the underlying chemistry. For example, if the algorithm replaces atom\nby atom, it may take several generations before a complete functional group is replaced.\nOne might hypothesize that LLMs can make the evolution process more efficient, e.g.,\nby using an LLM to handle the reproduction. One might expect that inductive biases in\nthe LLM help create recombined molecules which are more chemically viable, maintaining\nthe motifs of the two parent molecules better than a random operation.\nThe team from McGill University (Benjamin Weiser, Jerome Genzling, Nico-\nlas Gastellu, Sylvester Zhang, Tao Liu, Alexander Al-Feghali, Nicolas Moitessier) set\nout the first steps to test this hypothesis (Figure 2). In initial experiments, they found\nthat GPT-3.5, without any finetuning, can fragment molecules provided as SMILES at\nrotatable bonds with a success rate of 70 %. This indicates that GPT-3.5 understands\nSMILES strings and aspects of their relation to the chemical structures they represent.\nSubsequently, they asked the LLMs to fragment and recombine two given molecules. The\nLLM frequently created new combined molecules with fragments of each species which\nwere reasonable chemical structures more often than a random SMILES string combining\n11\nFigure 2: GA using an LLM . This figure illustrates how different aspects of a GA can be\nperformed by an LLM. GPT-3.5 was used to fragment, reproduce, and optimize molecules\nrepresented by SMILES strings. The first column illustrated how an LLM can fragment a\nmolecule represented by a SMILES string (input molecule on top, output LLM fragments below).\nThe middle column showcases how an LLM can reproduce/mix two molecules as is done in a\nGA (input molecule on top, output LLM below). The right column illustrates an application in\nwhich an LLM is used to optimize molecules given their SMILES and an associated score. The\nLLM suggested potential modifications to optimize molecules. The plot shows best (blue) and\nmean (orange) Tanimoto similarity to Vitamin C per LLM produced generations.\noperation (two independent organic chemists judged the LLM-GA-generated molecules\nto be chemically reasonable in 32/32 cases, but only in 21/32 cases for the random recombi-\nnation operation).\nEncouraged by these findings, they prompted an LLM with 30 parent molecules and\ntheir performance scores (Tanimoto similarity to vitamin C) with the task to come up\nwith n new molecules that the LLM “believes” to improve the score. A preliminary visual\ninspection suggests that the LLM might produce chemically reasonable modifications.\nFuture work will need to systematically investigate potential improvements compared to\nconventional GAs.\nThe importance of the results of the McGill team is that they indicate that these LLMs\n(when suitably conditioned) might not only reproduce known structures but generate new\nstructures that make chemical sense [32, 59].\nA current limitation of this approach is that most LLMs still struggle to output valid\nSMILES without explicit fine-tuning [33]. We anticipate that this problem might be\nmitigated by building foundation models for chemistry (with more suitable tokeniza-\n12\ntion [60, 61]), as, for instance, the ChemNLP project of OpenBioML.org attempts to do\n(https://github.com/OpenBioML/chemnlp). In addition, the context length limits the\nnumber of parent molecules that can be provided as examples.\nOverall, we see that the flexibility of the natural language input and the in-context\nlearning abilities allows using LLMs in very different ways—to very efficiently build pre-\ndictive models or to approach molecular and material design in entirely unprecedented\nways, like by providing context—such as “fuzzy” design rules—or simply prompting the\nLLM to come up with new structures. However, we also find that some “old” ideas, such\nas ∆-ML and data augmentation, can also be applied in this new paradigm.\nB. Automation and novel interfaces\nYao et al. [62] and Schick et al. [25] have shown that LLMs can be used as agents\nthat can autonomously make use of external tools such as Web-APIs—a paradigm that\nsome call MRKL (pronounced “miracle”) Systems—modular reasoning, knowledge, and\nlanguage systems [26]. By giving LLMs access to tools and forcing them to think step-by-\nstep [63], we can thereby convert LLMs from hyperconfident models that often hallucinate\nto systems that can reason based on observations made by querying robust tools. As the\ntechnical report for GPT-4 highlighted [64], giving LLMs access to tools can lead to\nemergent behavior, i.e., enabling the system to do things that none of its parts could do\nbefore. In addition, this approach can make external tools more accessible—since users\nno longer have to learn tool-specific APIs. It can also make tools more interoperable—by\nusing natural language instead of “glue code” to connect tools.\nThis paradigm has recently been used by Bran et al. [65] to create digital assistants that\ncan call and combine various tools such as Google search and the IBM RXN retrosynthesis\ntool when prompted with natural language. Boiko et al. [66] used a similar approach and\ngave LLMs access to laboratories via cloud lab APIs. In their system, the LLM could\nuse external tools to plan a synthesis, which it could execute using the cloud lab.\na. MAPI-LLM\nElectronic structure calculations have reached such a high level of accuracy that\none can answer questions like “Is the material AnByCz stable?” Indeed, the Materi-\nals Project [67] stores thermodynamic data on many components from which one can\nobtain a reasonable estimate of the stability of a given material. Or, if the material is\nnot in the database, one can do a simulation instead. Similarly, to answer prompts such\n13\nas “Give me a reaction to produce CaCO3”, there is a lot of helpful information in the\nMaterials Project database and the internet that can help to come up with an answer.\nTo answer these questions, state-of-the-art computational tools or existing databases\ncan be used. However, their use often requires expert knowledge. To use existing\ndatabases, one must choose which database to use, how to query the database, and what\nrepresentation of the compound is used (e.g., international chemical identifier (InChI),\nSMILES, etc.). Otherwise, if the data is not in a database, one must run calculations,\nwhich requires a deep understanding of technical details. LLMs can simplify the use of\nsuch tools. By typing in a question, we can prompt the LLM to translate this question\ninto a workflow that leads to the answer.\nThe MAPI-LLM team (Mayk Caldas Ramos, Sam Cox, Andrew White) made the first\nsteps towards developing such a system (MAPI-LLM) and created a procedure to convert\na text prompt into a query of the Materials Project API (API) to answer questions such\nas “Is the material AnByCz stable?” In addition, MAPI-LLM is capable of handling\nclassification queries, such as “Is Fe2O3 magnetic?”, as well as regression problems, such\nas “What is the band gap of Mg(Fe2O3)2?”.\nBecause an LLM is used to create the workflow, MAPI-LLM can process even more\ncomplex questions. For instance, the question “If Mn23FeO32 is not metallic, what is its\nband gap?” should create a two-step workflow first to check if the material is metallic\nand then calculate its band gap if it is not.\nMoreover, MAPI-LLM applies ICL if the data for a material’s property is unavailable\nvia the MAPI. MAPI-LLM generates an ICL prompt, building context based on the\ndata for similar materials available in Materials Project database. This context is then\nleveraged by an LLM to infer properties for the unknown material. This innovative use\nof ICL bridges data gaps and enhances MAPI-LLM’s robustness and versatility.\nb. sMolTalk\nThe previous application already touches on the problem that software for chemical\napplications requires scientists to invest a significant amount of time in learning even the\nmost basic applications. An example of this is visualization software. Depending on the\npackage and its associated documentation, chemists and materials scientists might spend\nhours to days learning the details of specific visualization software that is sometimes\npoorly documented. And in particular, for occasional use, if it takes a long time to learn\nthe basics, it won’t be used.\n14\nFigure 3: Schematic overview of the MAPI-LLM workflow. It uses LLMs to process the user’s\ninput and decide which available tools (e.g., Materials Project API, the Reaction-Network\npackage, and Google Search) to use following an iterative chain-of-thought procedure. In this\nway, it can answer questions such as “Is the material AnByCz stable?”.\nAs the sMolTalk-team (Jakub L´ ala, Sean Warren, Samuel G. Rodriques) showed, one\ncan use LLMs to write code for visualization tools such as 3dmol.js to address this\ninefficiency [68]. Interestingly, few-shot prompting with several examples of user input\nwith the expected JavaScript code that manipulates the 3dmol.js viewer is all that is\nneeded to create a prototype of an interface that can retrieve protein structures from\nthe protein data bank (PDB) and create custom visualization solutions, e.g., to color\nparts of a structure in a certain way (Figure 4). The beauty of the language models is\nthat the user can write the prompt in many different (“fuzzy”) ways: whether one writes\n“color” or “colour”, or terms like “light yellow” or “pale yellow” the LLM translates it\ninto something the visualization software can interpret.\nHowever, this application also highlights that further developments of these LLM-\nbased tools are needed. For example, a challenge the sMolTalk tool faces is robustness.\nFor instance, fragments from the prompt tend to leak into the output and must be handled\nwith more involved mechanisms, such as retries in which one gives the LLMs access to\nthe error messages or prompt engineering. Further improvement can also be expected if\nthe application leverages a knowledge base such as the documentation of 3dmol.js.\nAs the work of Glenn Hocky and Andrew White shows [69], an LLM-interface for\nsoftware can also be used with other programs such asVMD [70] and extended with speech-\nto-text models (such as Whisper [71]) to enable voice control of such programs. In\n15\nFigure 4: The sMolTalk interface. Based on few-shot prompting LLMs can create code for\nvisualization tools such as 3dmol.js that can create custom visualization based on a natural-\nlanguage description of the desired output. The top left box is the input field where users can\nenter commands in natural language. The top right box prints the code the LLM generates.\nThis code generates the visualization shown in the lower box. In this example, the user entered\na sequence of four commands: the LLM (1) generates code for retrieving the structure, (2)\ncolors the carbons blue, (3) displays the hydrogens as red spheres, and (4) reduces the size of\nthe spheres.\nparticular, such an LLM-based agent approach might be implemented for the PyMOL\nprogram, where various tools for protein engineering could be interfaced through a chat\ninterface, lowering the barrier to entry for biologists to use recent advancements within\nin silico protein engineering (such as RosettaFold [72] or RFDiffusion [73]).\nc. ELN interface: whinchat\nIn addition to large, highly curated databases with well-defined data models [74] (such\nas those addressed by the MAPI-LLM project), experimental materials and chemistry\ndata is increasingly being captured using digital tools such as ELNs and or laboratory\ninformation systems (LIMS). Importantly, these tools can be used to record both struc-\n16\ntured and unstructured lab data in a manner that is actionable by both humans and\ncomputers. However, one challenge in developing these systems is that it is difficult for a\ntraditional user interface to have enough flexibility to capture the richness and diversity\nof real, interconnected, experimental data. Interestingly, LLMs can interpret and con-\ntextualize both structured and unstructured data and can therefore be used to create a\nnovel type of flexible, conversational interface to such experimental data. The whinchat\nteam (Joshua D. Bocarsly, Matthew L. Evans, and Ben E. Smith) embedded an LLM\nchat interface within datalab, an open source materials chemistry data management\nsystem, where the virtual LLM-powered assistant can be “attached” to a given sample.\nThe virtual assistant has access to responses from the JavaScript object notation (JSON)\nAPI of datalab (containing both structured and unstructured/free text data) and can\nuse them to perform several powerful tasks: First, it can contextualize existing data\nby explaining related experiments from linked responses, resolving acronyms/short-hand\nnotations used by experimentalists, or creating concise textual summaries of complex\nand nested entries. Second, it can reformat or render the data, for instance, by creating\n(mermaid.js) flowcharts or (Markdown) tables (Figure 5). Third, it can use its generic\nreasoning abilities to suggest future experiments, for instance, related materials to study,\nsynthesis protocols to try, or additional characterization techniques. This is shown in the\nexamples given in SI section 2C, where whinchat was able to provide hints about which\nNMR-active nuclei can be probed in the given sample.\nIt is easy to envision that this tool could be even more helpful by fine-tuning or condi-\ntioning it on a research group’s knowledge base (e.g., group Wiki or standard operating\nprocedures) and communication history (e.g., a group’s Slack history). An important\nlimitation of the current implementation is that the small context window of available\nLLMs limits the amount of JSON data one can directly provide within the prompt, lim-\niting each conversation to analyzing a relatively small number of samples. Therefore, one\nneeds to either investigate the use of embeddings to determine which samples to include\nin the context or adopt an “agent” approach where the assistant is allowed to query the\nAPI of the ELN (interleaved with extraction and summarization calls).\nd. BOLLaMa: facilitating Bayesian optimization with large language models\nBayesian optimization (BO) is a powerful tool for optimizing expensive functions,\nsuch as mapping of reaction conditions to the reaction yield. Chemists would greatly\nbenefit from using this method to reduce the number of costly experiments they need\n17\nFigure 5: Using an LLM as an interface to an ELN/data management system. LLM-based\nassistants can provide powerful interfaces to digital experimental data. The figure shows a\nscreenshot of a conversation withwhinchat in the datalab data management system (https://\ngithub.com/the-grey-group/datalab). Here, whinchat is provided with data from the JSON\nAPI of datalab of an experimental battery cell. The user then prompts (green box) the system\nto build a flowchart of the provenance of the sample. The assistant responds with mermaid.js\nmarkdown code, which the datalab interface automatically recognizes and translates into a\nvisualization.\nto run [75, 76]. However, BO faces an interface and accessibility problem, too. The\nexisting frameworks require significant background knowledge and coding experience not\nconventionally taught in chemistry curricula. Therefore, many chemists cannot benefit\nfrom tools such as BO. The BOLLaMa-team (Bojana Rankovi´ c, Andres M. Bran, Philippe\nSchwaller) showed that LLMs can lower the barrier for the use of BO by providing a\nnatural language chat-like interface to BO algorithms. Figure 6 shows a prototype of\na chat interface in which the LLM interprets the user request, initializes a BO run by\nsuggesting initial experimental conditions, and then uses the feedback of the user to\ndrive the BO algorithm and suggest new experiments. The example used data on various\nadditives for a cooperative nickel-photoredox catalyzed reaction [77] and the BO code\nfrom Rankovi´ c et al. [78]. This ideally synergizes with an LLM interface to a data\nmanagement solution (as discussed in the previous project) as one could directly persist\nthe experimental results and leverage prior records to “bootstrap” BO runs.\n18\nFigure 6: Schematic overview of BoLLama. An LLM can act as an interface to a BO algorithm.\nAn experimental chemist can bootstrap an optimization and then, via a chat interface, update\nthe state of the simulation to which the bot responds with the recommended next steps.\nAs the examples in this section show, we find that LLMs have the potential to greatly\nenhance the efficiency of a diverse array of processes in chemistry and materials science by\nproviding novel interfaces to tools or by completely automating their use. This can help\nstreamline workflows, reduce human error, and increase productivity—often by replacing\n“glue code” with natural language or studying a software library by chatting with an\nLLM.\nC. Knowledge Extraction\nBeyond proving novel interfaces for tools, LLMs can also serve as powerful tools for\nextracting knowledge from the vast amount of chemical literature available. With LLMs,\nresearchers can rapidly mine and analyze large volumes of data, enabling them to uncover\nnovel insights and advance the frontiers of chemical knowledge. Tools such as paper-\nqa [28] can help to dramatically cut down the time required for literature search by\nautomatically retrieving, summarizing, and contextualizing relevant fragments from the\nentire corpus of the scientific literature—for example, answering questions (with suitable\ncitations) based on a library of hundreds of documents [35]. As the examples in the\n19\nFigure 7: The InsightGraph interface. A suitably prompted LLM can create knowledge graph\nrepresentations of scientific text that can be visualized using tools such as neo4j’s visualization\ntools. [81]\nprevious section indicated, this is particularly useful if the model is given access to search\nengines on the internet.\na. InsightGraph\nTo facilitate downstream use of the information, LLMs can also convert unstructured\ndata—the typical form of these literature reports—into structured data. The use of GPT\nfor this application has been reported by Dunn et al. [79] and Walker et al. [80], who\nused an iterative fine-tuning approach to extract data structured in JSON from papers.\nIn their approach, initial (zero-shot) completions of the LLM are corrected by domain\nexperts. Those corrected completions are then used to finetune LLMs, showing improved\nperformance on this task.\nHowever, for certain applications, one can construct powerful prototypes using only\ncareful prompting. For instance, the InsightGraph team (Defne Circi, Shruti Badhwar)\nshowed that GPT-3.5-turbo, when prompted with an example JSON containing a high-\nlevel schema and information on possible entities (e.g., materials) and pairwise relation-\nships (e.g., properties), can, as Figure 7 illustrates, provide a knowledge graph repre-\nsentation of the entities and their relationships in a text describing the properties and\ncomposition of polymer nanocomposites. A further optimized version of this tool might\noffer a concise and visual means to quickly understand and compare material types and\nuses across sets of articles and could be used to launch a literature review. An ad-\nvanced potential application is the creation of structured, materials-specific datasets for\nfact-based question-answering and downstream machine-learning tasks.\nb. Extracting Structured Data from Free-form Organic Synthesis Text\nUnstructured text is commonly used for describing organic synthesis procedures. Due\nto the large corpus of literature, manual conversion from unstructured text to struc-\n20\nFigure 8: The Organic Synthesis Parser interface. The top box shows text\ndescribing an organic reaction ( https://open-reaction-database.org/client/id/ord-\n1f99b308e17340cb8e0e3080c270fd08), which the finetuned LLM converts into structured\nJSON (bottom). A demo application can be found at https://qai222.github.io/LLM_\norganic_synthesis/.\ntured data is unrealistic. However, structured data are needed for building conventional\nML models for reaction prediction and condition recommendation. The Open Reaction\nDatabase (ORD) [82] is a database of curated organic reactions. In the ORD, while reac-\ntion data are structured by the ORD schema, many of their procedures are also available\nas plain text. Interestingly, an LLM (e.g., OpenAI’s text-davinci-003) can, after fine-\ntuning on only 300 prompt-completion pairs, extract 93 % of the components from the\nfree-text reaction description into valid JSONs (Figure 8). Such models might signifi-\ncantly increase the data available for training models on tasks such as predicting reaction\nconditions and yields. It is worth noting that all reaction data submitted to ORD are\nmade available under the CC-BY-SA license, which makes ORD a suitable data source\nfor fine-tuning or training an LLM to extract structured data from organic procedures. A\nrecent study on gold nanorod growth procedures also demonstrated the ability of LLM in\na similar task. [80] In contrast to the LIFT-based prediction of atomization energies re-\nported in the first section by the Berkeley-Madison team, parameter-efficient fine-tuning\nof the open-source Alpaca model [83–85] using LoRA [47] did not yield a model that can\nconstruct valid JSONs.\n21\nc. TableToJson: Structured information from tables in scientific papers\nThe previous example shows how structured data can be extracted from plain text\nusing LLMs. However, relevant information in the scientific literature is not only found\nin text form. Research papers often contain tables that collect data on material prop-\nerties, synthesis conditions, and results of characterization and experiments. Converting\ntable information into structured formats is essential to enable automated data analy-\nsis, extraction, and integration into computational workflows. Although some techniques\ncould help in the process of extracting this information (performing OCR or parsing\nXML), converting this information in structured data following, for example, a specific\nJSON schema with models remains a challenge. The INCAR-CSIC team showed that\nthe OpenAI text-davinci-003 model, when prompted with a desired JSON schema and\nthe HyperText Markup Language (HTML) of a table contained in a scientific paper, can\ngenerate structured JSON with the data in the table.\nFirst, the OpenAI text-davinci-003 model was directly used to generate JSON\nobjects from the table information. This approach was applied to several examples using\ntables collected from papers on different research topics within the field of chemistry [86–\n92]. The accuracy for those different examples, calculated as the percentage of schema\nvalues generated correctly, is shown in Figure 9. When the OpenAI model was prompted\nwith the table and desired schema to generate a JSON object, it worked remarkably well\nin extracting the information from each table cell and inserting it at the expected place\nin the schema. As output, it provided a valid JSON object with a 100 % success rate of\nerror-free generated values in all the studied examples. However, in some examples, the\nmodel did not follow the schema.\nTo potentially address this problem the team utilized the jsonformer approach. This\ntool reads the keys from the JSON schema and only generates the value tokens, guaran-\nteeing the generation of a syntactically valid JSON (corresponding to the desired schema)\nby the LLM [93, 94]. Using an LLM without such a decoding strategy cannot guarantee\nthat valid JSON outputs are produced. With the jsonformer approach, in most cases,\nby using a simple descriptive prompt about the type of input text, structured data can\nbe obtained with 100 % correctness of the generated values. In one example, an accuracy\nof 80 % was obtained due to errors in the generation of numbers in scientific notation.\nFor a table with more complex content (long molecule names, hyphens, power numbers,\nsubscripts, and superscripts,. . . ) the team achieved an accuracy of only 46 %. Most of\n22\nthese issues could be solved by adding a specific explanation in the prompt, increasing\nthe accuracy to 100 % in most cases.\nOverall, both approaches performed well in generating the JSON format. The OpenAI\ntext-davinci-003 model could correctly extract structured information from tables and\ngive a valid JSON output, but it cannot guarantee that the outputs will always follow\nthe provided schema. Jsonformer may present problems when special characters need\nto be generated, but most of these issues could be solved with careful prompting. These\nresults show that LLMs can be a useful tool to help to extract scientific information in\ntables and convert it into a structured form with a fixed schema that can be stored in a\ndatabase, which could encourage the creation of more topic-specific databases of research\nresults.\nFigure 9: TableToJson. Results of the structured JSON generation of tables contained in\nscientific articles. Two approaches are compared: (i) the use of an OpenAI model prompted\nwith the desired JSON schema, and (ii) the use of an OpenAI model together with jsonformer.\nIn both cases, JSON objects were always obtained. The output of the OpenAI model did not\nalways follow the provided schema, although this might be solved by modifying the schema.\nThe accuracy of the results from the jsonformer approach used with OpenAI models could be\nincreased (as shown by the blue arrows) by solving errors in the generation of power numbers\nand special characters with a more detailed prompt. The results can be visualized in this demo\napp: https://vgvinter-tabletojson-app-kt5aiv.streamlit.app/\nd. AbstractToTitle & TitleToAbstract: text summarization and text generation\nTechnical writing is a challenging task that often requires presenting complex abstract\nideas in limited space. For this, frequent rewrites of sections are needed, in which LLMs\ncould assist domain experts. Still, evaluating their ability to generate text such as a\nscientific paper is essential, especially for chemistry and materials science applications.\n23\nLarge datasets of chemistry-related text are available from open-access platforms such\nas arXiv and PubChem. These articles contain titles, abstracts, and often complete\nmanuscripts, which can be a testbed for evaluating LLMs as these titles and abstracts\nare usually written by expert researchers. Ideally, an LLM should be able to generate a\ntitle of an abstract close to the one developed by the expert, which can be considered\na specialized text-summarization task. Similarly, given a title, an LLM should generate\ntext close to the original abstract of the article, which can be considered a specialized\ntext-generation task.\nThese tasks have been introduced by the AbstractToTitle & TitleToAbstract team\n(Kamal Choudhary) in the JARVIS-ChemNLP package [95]. For text summariza-\ntion, it uses a pre-trained Text-to-Text Transfer Transformer (T5) model developed by\nGoogle [96] that is further fine-tuned to produce summaries of abstracts. On the arXiv\ncondensed-matter physics (cond-mat) data, the team found that fine-tuning the model\ncan help improve the performance (Recall-Oriented Understudy for Gisting Evaluation\n(ROUGE)-1 score of 39 .0 % which is better than an untrained model score of 30 .8 % for\nan 80/20 split).\nFor text generation, JARVIS-ChemNLP finetunes the pretrained GPT-2-medium [48]\nmodel available in the HuggingFace library. [97] After finetuning, the team found a\nROUGE score of 31 .7 %, which is a good starting point for pre-suggestion text applica-\ntions. Both tasks with well-defined train and test splits are now available in the JARVIS-\nLeaderboard platform for the AI community to compare other LLMs and systematically\nimprove the performance.\nIn the future, such title to abstract capabilities can be extended to generating full-\nlength drafts with appropriate tables, multi-modal figures, and results as an initial start\nfor the human researcher to help in the technical writing processes. Note that there\nhave been recent developments in providing guidelines for using LLM-generated text in\ntechnical manuscripts [98], so such an LLM model should be considered as an assistant\nof writing and not the master/author of the manuscripts.\nD. Education\nGiven all the opportunities LLM open for materials science and chemistry, there is\nan urgent need for education to adapt. Interestingly, LLMs also provide us with entirely\n24\nFigure 10: The I-digest interface. A video (e.g., of a lecture recording) can be described using\nthe Whisper model. Based on the transcript, an LLM can generate questions (and answers).\nThose can assist students in their learning. The LLM can also detect mentions of chemicals\nand link to further information about them (e.g., on PubChem [100–102]).\nnovel educational opportunities [99], for example, by personalizing content or providing\nalmost limitless varied examples.\nThe I-Digest (Information-Digestor) hackathon team (Beatriz Mouri˜ no, Elias\nMoubarak, Joren Van Herck, Sauradeep Majumdar, Xiaoqi Zhang) created a path toward\nsuch a new educational opportunity by providing students with a digital tutor based on\ncourse material such as lecture recordings. Using the Whisper model [71], videos of lec-\nture recordings can be transcribed to text transcripts. The transcripts can then be fed\ninto an LLM with the prompt to come up with questions about the content presented in\nthe video (Figure 10). In the future, these questions might be shown to students before\na video starts, allowing them to skip parts they already know or after the video, guiding\nstudents to the relevant timestamps or additional material in case of an incorrect answer.\nImportantly, and in contrast to conventional educational materials, this approach can\ngenerate a practically infinite number of questions and could, in the future, be contin-\nuously be improved by student feedback. In addition, it is easy to envision extending\nthis approach to consider lecture notes or books to guide the students further or even\nrecommend specific exercises.\n25\nII. CONCLUSION\nThe fact that the groups were able to present prototypes that could do quite complex\ntasks in such a short time illustrates the power of LLMs. Some of these prototypes would\nhave taken many months of programming just a few months ago, but the fact that LLMs\ncould reduce this time to a few hours is one of the primary reasons for the success of our\nhackathon. Combined with the time-constrained environment in teams (with practically\nzero cost of “failure”), we found more energy and motivation. The teams delivered more\nresults than in most other hackathons we participated in.\nThrough the LIFT framework, one can use LLMs to address problems that could al-\nready be addressed with conventional approaches—but in a much more accessible way\n(using the same approach for different problems), while also reusing established concepts\nsuch as ∆-ML. At the same time, however, we can use LLMs to model chemistry and\nmaterials science in novel ways; for example, by incorporating context information such\nas “fuzzy” design rules or directly operating on unstructured data. Overall, a common\nuse case has been to use LLMs to deal with “fuzziness” in programming and tool de-\nvelopment. We can already see tools like Copilot and ChatGPT being used to convert\n“fuzzy abstractions” or hard-to-define tasks into code. These advancements may soon\nallow everyone to write small apps or customize them to their needs (end-user program-\nming). Additionally, we can observe an interesting trend in tool development: most of\nthe logic in the showcased tools is written in English, not in Python or another pro-\ngramming language. The resulting code is shorter, easier to understand, and has fewer\ndependencies because LLMs are adept at handling fuzziness that is difficult to address\nwith conventional code. This suggests that we may not need more formats or standards\nfor interoperability; instead, we can simply describe existing solutions in natural lan-\nguage to make them interoperable. Exploring this avenue further is exciting, but it is\nequally important to recognize the limitations of LLMs, as they currently have limited\ninterpretability and lack robustness.\nIt is interesting to note that none of the projects relied on the knowledge or under-\nstanding of chemistry by LLMs. Instead, they relied on general reasoning abilities and\nprovided chemistry information through the context or fine-tuning. However, this also\nbrings new and unique challenges. All projects used the models provided by OpenAI’s\nAPI. While these models are powerful, we cannot examine how they were built or have\nany guarantee of continued reliable access to them.\n26\nAlthough there are open-source language models and techniques available, they are\ngenerally more difficult to use compared to simply using OpenAI’s API. Furthermore, the\nperformance of language models can be fragile, especially for zero- or few-shot applica-\ntions. To further investigate this, new benchmarks are needed that go beyond the tabular\ndatasets we have been using for ML for molecular and materials science—we simply have\nno frameworks to compare and evaluate predictive models that use context, unstructured\ndata, or tools. Without automated tests, however, it is difficult to improve these systems\nsystematically. On top of that, consistent benchmarking is hard because de-duplication\nis ill-defined even if the training data are known. To enable a scientific approach to the\ndevelopment and analysis of these systems, we will also need to revisit versioning frame-\nworks to ensure reproducibility as systems that use external tools depend on the exact\nversions of training data, LLM, as well as of the external tools and prompting setup.\nThe diversity of the prototypes presented in this work shows that the potential appli-\ncations are almost unlimited, and we can probably only see the tip of the iceberg—for\ninstance, we didn’t even touch modalities other than text thus far.\nGiven these new ways of working and thinking, combined with the rapid pace of\ndevelopments in the field, we believe that we urgently need to rethink how we work and\nteach. We must discuss how we ensure safe use [103], standards for evaluating and sharing\nthose models, and robust and reliable deployments. But we also need to discuss how we\nensure that the next generation of chemists and materials scientists are proficient and\ncritical users of these tools—that can use them to work more efficiently while critically\nreflecting on the outputs of the systems. We believe that to truly leverage the power of\nLLMs in the molecular and material sciences, we need a community effort—including not\nonly chemists and computer scientists but also lawyers, philosophers, and ethicists: the\npossibilities and challenges are too broad and profound to tackle alone.\nAcknowledgements\nWe would like to specifically thank Jim Warren (NIST) for his contributions to discus-\nsions leading up to the hackathon and his participation as a judge during the event. We\nwould also like to thank Anthony Costa and Christian Dallago (NVIDIA) for supporting\nthe hackathon.\nB.B., I.T.F, and ZH acknowledge support from the the National Science Foundation\nawards #2226419 and #2209892. This work was performed under the following financial\n27\nassistance award 70NANB19H005 from the U.S. Department of Commerce, National\nInstitute of Standards and Technology as part of the Center for Hierarchical Materials\nDesign (CHiMaD).\nK.J.S, A.S. acknowledge support from the the National Science Foundation award\n#1931306.\nK.M.J., S.M., J.v.H., X.Z., B.M., E.M., and B.S. were supported by the MAR-\nVEL National Centre for Competence in Research funded by the Swiss National Science\nFoundation (grant agreement ID 51NF40-182892) and the USorb-DAC Project, which is\nfunded by a grant from The Grantham Foundation for the Protection of the Environ-\nment to RMI’s climate tech accelerator program, Third Derivative. B.M. was further\nsupported by the European Union’s Horizon 2020 research and innovation programme\nunder the Marie Sk lodowska-Curie grant agreement No. 945363.\nM.C.R., S.C., and A.D.W. were supported by the National Science Foundation and\nthe National Institute of General Medical Sciences under Grant No. 1764415 and award\nnumber R35GM137966, respectively.\nQ.A.’s contribution to this work was supported by the National Center for Advanc-\ning Translational Sciences of the National Institutes of Health under award number\nU18TR004149. The content is solely the responsibility of the authors and does not\nnecessarily represent the official views of the National Institutes of Health.\nM.V.G. acknowledges support from the Spanish National Research Council (CSIC)\nthrough the Programme for internationalization i-LINK 2021 (Project LINKA20412), and\nfrom the Spanish Agencia Estatal de Investigaci´ on (AEI) through the Grant TED2021-\n131693B-I00 funded by MCIN/AEI/ 10.13039/501100011033 and by the “European\nUnion NextGenerationEU/PRTR” and through the Ram´ on y Cajal Grant RYC-2017-\n21937 funded by MCIN/AEI/ 10.13039/501100011033 and by “ESF Investing in your\nfuture”.\nThe datalab project (M.L.E., B.E.S. and J.D.B.) has received funding from the Eu-\nropean Union’s Horizon 2020 research and innovation programme under grant agreement\n957189 (DOI: 10.3030/957189), the Battery Interface Genome - Materials Acceleration\nPlatform (BIG-MAP), as an external stakeholder project. M.L.E. additionally thanks\nthe BEWARE scheme of the Wallonia-Brussels Federation for funding under the European\nCommission’s Marie Curie-Sk lodowska Action (COFUND 847587).B.E.S. acknowledges\nsupport from the UK’s Engineering and Physical Sciences Research Council (ESPRC).\n28\nB.P. acknowledges support from the National Science Foundation through NSF-CBET\nGrant No. 1917340. The authors thank Phung Cheng Fei, Hassan Harb, and Vinayak\nBhat for their helpful comments on this project.\nD.C. and L.C.B. thank NSF DGE-2022040 for the aiM NRT funding support.\nK.C. thank the National Institute of Standards and Technology for funding, compu-\ntational, and data-management resources. Please note certain equipment, instruments,\nsoftware, or materials are identified in this paper in order to specify the experimental\nprocedure adequately. Such identification is not intended to imply recommendation or\nendorsement of any product or service by NIST, nor is it intended to imply that the\nmaterials or equipment identified are necessarily the best available for the purpose.\nA.K.G., G.W.M., A.I., and W.A.d.J. were supported by the U.S. Department of\nEnergy, Office of Science, Basic Energy Sciences, Materials Sciences and Engineering\nDivision under Contract No. DE-AC02-05CH11231, FWP No. DAC-LBL-Long, and by\nthe U.S. Department of Energy, Office of Science, Office of High Energy Physics under\nAward Number DE-FOA-0002705.\nM.B, B.R., and P.S. were supported by the NCCR Catalysis (grant number 180544),\na National Centre of Competence in Research funded by the Swiss National Science\nFoundation.\nS.G.R. and J.L. acknowledge the generous support of Eric and Wendy Schmidt, and\nthe core funding of the Francis Crick Institute, which receives its funding from Cancer\nResearch UK, the UK Medical Research Council, and the Wellcome Trust.\n[1] Butler, K. T.; Davies, D. W.; Cartwright, H.; Isayev, O.; Walsh, A. Machine learning for\nmolecular and materials science. Nature 2018, 559, 547–555.\n[2] Moosavi, S. M.; Jablonka, K. M.; Smit, B. The Role of Machine Learning in the Under-\nstanding and Design of Materials. J. Am. Chem. Soc. 2020, 142, 20273–20287.\n[3] Morgan, D.; Jacobs, R. Opportunities and Challenges for Machine Learning in Materials\nScience. Annu. Rev. Mater. Res. 2020, 50, 71–103.\n[4] Ramprasad, R.; Batra, R.; Pilania, G.; Mannodi-Kanakkithodi, A.; Kim, C. Machine\nlearning in materials informatics: recent applications and prospects. npj Comput. Mater.\n2017, 3, 54.\n[5] Schmidt, J.; Marques, M. R. G.; Botti, S.; Marques, M. A. L. Recent advances and\n29\napplications of machine learning in solid-state materials science. npj Comput. Mater.\n2019, 5.\n[6] Choudhary, K.; DeCost, B.; Chen, C.; Jain, A.; Tavazza, F.; Cohn, R.; Park, C. W.;\nChoudhary, A.; Agrawal, A.; Billinge, S. J., et al. Recent advances and applications of\ndeep learning methods in materials science. npj Comput. Mater. 2022, 8, 59.\n[7] Jablonka, K. M.; Ongari, D.; Moosavi, S. M.; Smit, B. Big-Data Science in Porous Mate-\nrials: Materials Genomics and Machine Learning. Chem. Rev. 2020, 120, 8066–8129.\n[8] Shi, J.; Quevillon, M. J.; Amorim Valen¸ ca, P. H.; Whitmer, J. K. Predicting Adhesive\nFree Energies of Polymer–Surface Interactions with Machine Learning. ACS Appl. Mater.\nInterfaces 2022, 14, 37161–37169.\n[9] Shi, J.; Albreiki, F.; Col´ on, Y. J.; Srivastava, S.; Whitmer, J. K. Transfer Learning Facil-\nitates the Prediction of Polymer–Surface Adhesion Strength. J. Chem. Theory Comput.\n2023,\n[10] No´ e, F.; Tkatchenko, A.; M¨ uller, K.-R.; Clementi, C. Machine Learning for Molecular\nSimulation. Annu. Rev. Phys. Chem. 2020, 71, 361–390.\n[11] Batzner, S.; Musaelian, A.; Sun, L.; Geiger, M.; Mailoa, J. P.; Kornbluth, M.; Molinari, N.;\nSmidt, T. E.; Kozinsky, B. E(3)equivariant graph neural networks for data efficient and\naccurate interatomic potentials. Nat. Commun. 2022, 13, 2453.\n[12] Sanchez-Lengeling, B.; Aspuru-Guzik, A. Inverse molecular design using machine learning:\nGenerative models for matter engineering. Science 2018, 361, 360–365.\n[13] Gonthier, J. F.; Steinmann, S. N.; Wodrich, M. D.; Corminboeuf, C. Quantification of\n“fuzzy” chemical concepts: a computational perspective. Chem. Soc. Rev. 2012, 41, 4671.\n[14] Weininger, D. SMILES, a chemical language and information system. 1. Introduction to\nmethodology and encoding rules. J. Chem. Inf. Comput. Sci. 1988, 28, 31–36.\n[15] Jablonka, K. M.; Patiny, L.; Smit, B. Making the collective knowledge of chemistry open\nand machine actionable. Nat. Chem. 2022, 14, 365–376.\n[16] Bommasani, R. et al. On the Opportunities and Risks of Foundation Models. CoRR 2021,\nabs/2108.07258.\n[17] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser,  L.;\nPolosukhin, I. Attention is all you need.Advances in neural information processing systems\n2017, 30.\n[18] Chowdhery, A. et al. PaLM: Scaling Language Modeling with Pathways. arXiv preprint:\n30\nArxiv-2204.02311. 2022.\n[19] Hoffmann, J. et al. Training Compute-Optimal Large Language Models. arXiv preprint:\nArxiv-2203.15556. 2022.\n[20] Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakan-\ntan, A.; Shyam, P.; Sastry, G.; Askell, A., et al. Language models are few-shot learners.\nAdvances in neural information processing systems 2020, 33, 1877–1901.\n[21] Edwards, C. N.; Lai, T.; Ros, K.; Honke, G.; Ji, H. Translation between Molecules and\nNatural Language. Conference On Empirical Methods In Natural Language Processing\n2022,\n[22] Eloundou, T.; Manning, S.; Mishkin, P.; Rock, D. GPTs are GPTs: An Early Look at\nthe Labor Market Impact Potential of Large Language Models. arXiv preprint: Arxiv-\n2303.10130 2023,\n[23] Srivastava, A. et al. Beyond the Imitation Game: Quantifying and extrapolating the\ncapabilities of language models. arXiv preprint: Arxiv-2206.04615. 2022.\n[24] Bubeck, S.; Chandrasekaran, V.; Eldan, R.; Gehrke, J.; Horvitz, E.; Kamar, E.; Lee, P.;\nLee, Y. T.; Li, Y.; Lundberg, S.; Nori, H.; Palangi, H.; Ribeiro, M. T.; Zhang, Y. Sparks\nof Artificial General Intelligence: Early experiments with GPT-4. arXiv preprint: Arxiv-\n2303.12712 2023,\n[25] Schick, T.; Dwivedi-Yu, J.; Dess` ı, R.; Raileanu, R.; Lomeli, M.; Zettlemoyer, L.; Can-\ncedda, N.; Scialom, T. Toolformer: Language Models Can Teach Themselves to Use\nTools. arXiv preprint: Arxiv-2302.04761 2023,\n[26] Karpas, E. et al. MRKL Systems: A modular, neuro-symbolic architecture that combines\nlarge language models, external knowledge sources and discrete reasoning. arXiv preprint:\nArxiv-2205.00445 2022,\n[27] Shen, Y.; Song, K.; Tan, X.; Li, D.; Lu, W.; Zhuang, Y. HuggingGPT: Solving AI Tasks\nwith ChatGPT and its Friends in HuggingFace. arXiv preprint: Arxiv-2303.17580. 2023.\n[28] White, A. paper-qa. https://github.com/whitead/paper-qa, 2022.\n[29] Liu, J. LlamaIndex. 2022; https://github.com/jerryjliu/llama_index, last accessed\n2023-05-30.\n[30] Andrej Karpathy [@karpathy], The Hottest New Programming Language Is English. 2023;\nhttps://twitter.com/karpathy/status/1617979122625712128, last accessed 2023-05-\n11.\n31\n[31] Hocky, G. M.; White, A. D. Natural language processing models that automate program-\nming will transform chemistry research and teaching. Digital Discovery 2022, 1, 79–83.\n[32] Jablonka, K. M.; Schwaller, P.; Ortega-Guerrero, A.; Smit, B. Is GPT-3 all you need\nfor low-data discovery in chemistry? ChemRxiv preprint 10.26434/chemrxiv-2023-fw8n4\n2023,\n[33] White, A. D.; Hocky, G. M.; Gandhi, H. A.; Ansari, M.; Cox, S.; Wellawatte, G. P.;\nSasmal, S.; Yang, Z.; Liu, K.; Singh, Y., et al. Assessment of chemistry knowledge in\nlarge language models that generate code. Digital Discovery 2023,\n[34] Ramos, M. C.; Michtavy, S. S.; Porosoff, M. D.; White, A. D. Bayesian Optimization of\nCatalysts With In-context Learning. arXiv preprint: Arxiv-2304.05341 2023,\n[35] White, A. D. The future of chemistry is language. Nat. Rev. Chem. 2023,\n[36] Ramakrishnan, R.; Dral, P. O.; Rupp, M.; Von Lilienfeld, O. A. Big data meets quantum\nchemistry approximations: the ∆-machine learning approach. J. Chem. Theory Comput.\n2015, 11, 2087–2096.\n[37] Dinh, T.; Zeng, Y.; Zhang, R.; Lin, Z.; Gira, M.; Rajput, S.; Sohn, J.-Y.; Papail-\niopoulos, D.; Lee, K. LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine\nLearning Tasks. arXiv preprint: Arxiv-2206.06565. 2022.\n[38] Krenn, M.; H¨ ase, F.; Nigam, A.; Friederich, P.; Aspuru-Guzik, A. Self-referencing embed-\nded strings (SELFIES): A 100% robust molecular string representation. Mach. Learn.:\nSci. Technol. 2020, 1, 045024.\n[39] Krenn, M.; Ai, Q.; Barthel, S.; Carson, N.; Frei, A.; Frey, N. C.; Friederich, P.; Gaudin, T.;\nGayle, A. A.; Jablonka, K. M., et al. SELFIES and the future of molecular string repre-\nsentations. Patterns 2022, 3, 100588.\n[40] Curtiss, L. A.; Redfern, P. C.; Raghavachari, K. Gaussian-4 theory using reduced order\nperturbation theory. J. Chem. Phys. 2007, 127, 124105.\n[41] Ramakrishnan, R.; Dral, P. O.; Rupp, M.; Von Lilienfeld, O. A. Quantum chemistry\nstructures and properties of 134 kilo molecules. Sci. Data 2014, 1, 1–7.\n[42] Narayanan, B.; Redfern, P. C.; Assary, R. S.; Curtiss, L. A. Accurate quantum chemical\nenergies for 133000 organic molecules. Chem. Sci. 2019, 10, 7449–7455.\n[43] Gupta, A. K.; Raghavachari, K. Three-Dimensional Convolutional Neural Networks Uti-\nlizing Molecular Topological Features for Accurate Atomization Energy Predictions. J.\nChem. Theory Comput. 2022, 18, 2132–2143.\n32\n[44] Ward, L.; Blaiszik, B.; Foster, I.; Assary, R. S.; Narayanan, B.; Curtiss, L. Machine\nlearning prediction of accurate atomization energies of organic molecules from low-fidelity\nquantum chemical calculations. MRS Commun. 2019, 9, 891–899.\n[45] Ramakrishnan, R.; Dral, P. O.; Rupp, M.; von Lilienfeld, O. A. Big Data Meets Quan-\ntum Chemistry Approximations: The ∆-Machine Learning Approach. J. Chem. Theory\nComput. 2015, 11, 2087–2096.\n[46] Becke, A. D. Density-functional thermochemistry. III. The role of exact exchange. J.\nChem. Phys. 1993, 98, 5648–5652.\n[47] Hu, E. J.; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.; Wang, L.; Chen, W. LoRA:\nLow-Rank Adaptation of Large Language Models. arXiv preprint: Arxiv-2106.09685\n2021,\n[48] Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; Sutskever, I. Language Models\nare Unsupervised Multitask Learners. 2019, https://d4mucfpksywv.cloudfront.\nnet/better-language-models/language_models_are_unsupervised_multitask_\nlearners.pdf.\n[49] Scrivener, K. L.; John, V. M.; Gartner, E. M. Eco-efficient cements: Potential economi-\ncally viable solutions for a low-CO2 cement-based materials industry. Cem. Concr. Res.\n2018, 114, 2–26.\n[50] V¨ olker, C.; Benjami Moreno Torres,; Tehseen Rug,; Firdous, R.; Ghezal Ahmad,; Zia, J.;\nL¨ uders, S.; Scaffino, H. L.; H¨ opler, M.; B¨ ohmer, F.; Pfaff, M.; Stephan, D.; Kruschwitz, S.\nGreen building materials: a new frontier in data-driven sustainable concrete design.\nPreprint 10.13140/RG.2.2.29079.85925. 2023.\n[51] Rao, G. M.; Rao, T. D. G. A quantitative method of approach in designing the mix\nproportions of fly ash and GGBS-based geopolymer concrete. Aust. J. Civ. Eng. 2018,\n16, 53–63.\n[52] Tshitoyan, V.; Dagdelen, J.; Weston, L.; Dunn, A.; Rong, Z.; Kononova, O.; Pers-\nson, K. A.; Ceder, G.; Jain, A. Unsupervised word embeddings capture latent knowledge\nfrom materials science literature. Nature 2019, 571, 95–98.\n[53] Mikolov, T.; Chen, K.; Corrado, G.; Dean, J. Efficient Estimation of Word Representations\nin Vector Space. International Conference On Learning Representations. 2013.\n[54] Olivetti, E. A.; Cole, J. M.; Kim, E.; Kononova, O.; Ceder, G.; Han, T. Y.-J.; Hiszpan-\nski, A. M. Data-driven materials research enabled by natural language processing and\n33\ninformation extraction. Appl. Phys. Rev. 2020, 7, 041317.\n[55] Selva Birunda, S.; Kanniga Devi, R. A review on word embedding techniques for text\nclassification. Innovative Data Communication Technologies and Application: Proceedings\nof ICIDCA 2020 2021, 267–281.\n[56] Hong, Z.; Ajith, A.; Pauloski, G.; Duede, E.; Malamud, C.; Magoulas, R.; Chard, K.;\nFoster, I. ScholarBERT: Bigger is Not Always Better. arXiv preprint: Arxiv-2205.11342.\n2022.\n[57] Dai, H. et al. AugGPT: Leveraging ChatGPT for Text Data Augmentation. arXiv\npreprint: Arxiv-2302.13007. 2023.\n[58] Venkatasubramanian, V.; Chan, K.; Caruthers, J. M. Computer-aided molecular design\nusing genetic algorithms. Comput. Chem. Eng. 1994, 18, 833–844.\n[59] Flam-Shepherd, D.; Aspuru-Guzik, A. Language models can generate molecules, materi-\nals, and protein binding sites directly in three dimensions as XYZ, CIF, and PDB files.\narXiv preprint: Arxiv-2305.05708. 2023.\n[60] Taylor, R.; Kardas, M.; Cucurull, G.; Scialom, T.; Hartshorn, A.; Saravia, E.; Poulton, A.;\nKerkez, V.; Stojnic, R. Galactica: A Large Language Model for Science. arXiv preprint:\nArxiv-2211.09085 2022,\n[61] Schwaller, P.; Gaudin, T.; L´ anyi, D.; Bekas, C.; Laino, T. “Found in Translation”: predict-\ning outcomes of complex organic chemistry reactions using neural sequence-to-sequence\nmodels. Chem. Sci. 2018, 9, 6091–6098.\n[62] Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan, K.; Cao, Y. ReAct: Synergizing\nReasoning and Acting in Language Models. arXiv preprint: Arxiv-2210.03629 2023,\n[63] Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Chi, E.; Xia, F.; Le, Q.; Zhou, D. Chain-\nof-Thought Prompting Elicits Reasoning in Large Language Models. Neural Information\nProcessing Systems 2022,\n[64] OpenAI, GPT-4 Technical Report. arXiv preprint: Arxiv-2303.08774v3. 2023.\n[65] Bran, A. M.; Cox, S.; White, A. D.; Schwaller, P. ChemCrow: Augmenting large-language\nmodels with chemistry tools. arXiv preprint: Arxiv-2304.05376 2023,\n[66] Boiko, D. A.; MacKnight, R.; Gomes, G. Emergent autonomous scientific research capa-\nbilities of large language models. arXiv preprint: Arxiv-2304.05332 2023,\n[67] Jain, A.; Ong, S. P.; Hautier, G.; Chen, W.; Richards, W. D.; Dacek, S.; Cholia, S.;\nGunter, D.; Skinner, D.; Ceder, G.; Persson, K. A. Commentary: The Materials Project:\n34\nA materials genome approach to accelerating materials innovation. APL Materials 2013,\n1, 011002.\n[68] Rego, N.; Koes, D. 3Dmol.js: molecular visualization with WebGL. Bioinformatics 2014,\n31, 1322–1324.\n[69] White, A.; Hocky, G. marvis - VMD Audio/Text control with natural language. https:\n//github.com/whitead/marvis, 2022.\n[70] Humphrey, W.; Dalke, A.; Schulten, K. VMD: Visual molecular dynamics. J. Mol. Graph.\n1996, 14, 33–38.\n[71] Radford, A.; Kim, J. W.; Xu, T.; Brockman, G.; McLeavey, C.; Sutskever, I. Robust\nspeech recognition via large-scale weak supervision. arXiv preprint: ArXiv-2212.04356.\n2022.\n[72] Baek, M. et al. Accurate prediction of protein structures and interactions using a three-\ntrack neural network. Science 2021, 373, 871–876.\n[73] Watson, J. L. et al. Broadly applicable and accurate protein design by integrat-\ning structure prediction networks and diffusion generative models. bioRxiv preprint:\n10.1101/2022.12.09.519842. 2022.\n[74] Andersen, C. W. et al. OPTIMADE, an API for exchanging materials data. Sci. Data\n2021, 8, 217.\n[75] Volk, A. A.; Epps, R. W.; Yonemoto, D. T.; Masters, B. S.; Castellano, F. N.; Reyes, K. G.;\nAbolhasani, M. AlphaFlow: autonomous discovery and optimization of multi-step chem-\nistry using a self-driven fluidic lab guided by reinforcement learning.Nat. Commun. 2023,\n14, 1403.\n[76] Shields, B. J.; Stevens, J.; Li, J.; Parasram, M.; Damani, F.; Alvarado, J. I. M.;\nJaney, J. M.; Adams, R. P.; Doyle, A. G. Bayesian reaction optimization as a tool for\nchemical synthesis. Nature 2021, 590, 89–96.\n[77] Prieto Kullmer, C. N.; Kautzky, J. A.; Krska, S. W.; Nowak, T.; Dreher, S. D.; MacMil-\nlan, D. W. Accelerating reaction generality and mechanistic insight through additive map-\nping. Science 2022, 376, 532–539.\n[78] Rankovi´ c, B.; Griffiths, R.-R.; Moss, H. B.; Schwaller, P. Bayesian optimisation for addi-\ntive screening and yield improvements in chemical reactions – beyond one-hot encodings.\nChemRxiv preprint 10.26434/chemrxiv-2022-nll2j. 2022.\n[79] Dunn, A.; Dagdelen, J.; Walker, N.; Lee, S.; Rosen, A. S.; Ceder, G.; Persson, K. A.;\n35\nJain, A. Structured information extraction from complex scientific text with fine-tuned\nlarge language models. arXiv preprint: Arxiv-2212.05238 2022,\n[80] Walker, N.; Dagdelen, J.; Cruse, K.; Lee, S.; Gleason, S.; Dunn, A.; Ceder, G.;\nAlivisatos, A. P.; Persson, K. A.; Jain, A. Extracting Structured Seed-Mediated Gold\nNanorod Growth Procedures from Literature with GPT-3. arXiv preprint: Arxiv-\n2304.13846 2023,\n[81] Neo4j, Neo4j - The World’s Leading Graph Database. 2012; http://neo4j.org/.\n[82] Kearnes, S. M.; Maser, M. R.; Wleklinski, M.; Kast, A.; Doyle, A. G.; Dreher, S. D.;\nHawkins, J. M.; Jensen, K. F.; Coley, C. W. The Open Reaction Database. J. Am. Chem.\nSoc. 143, 18820–18826.\n[83] Taori, R.; Gulrajani, I.; Zhang, T.; Dubois, Y.; Li, X.; Guestrin, C.; Liang, P.;\nHashimoto, T. B. Stanford Alpaca: An Instruction-following LLaMA model. https:\n//github.com/tatsu-lab/stanford_alpaca, 2023.\n[84] Alpaca-LoRA. https://github.com/tloen/alpaca-lora.\n[85] Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux, M.-A.; Lacroix, T.;\nRozi` ere, B.; Goyal, N.; Hambro, E.; Azhar, F., et al. Llama: Open and efficient foun-\ndation language models. arXiv preprint:2302.13971 2023,\n[86] Mamaghani, Z. G.; Hawboldt, K. A.; MacQuarrie, S. Adsorption of CO 2 using biochar -\nReview of the impact of gas mixtures and water on adsorption. J. Environ. Chem. Eng.\n2023, 11, 109643.\n[87] Peng, Y.; Krungleviciute, V.; Eryazici, I.; Hupp, J. T.; Farha, O. K.; Yildirim, T. Methane\nStorage in Metal–Organic Frameworks: Current Records, Surprise Findings, and Chal-\nlenges. J. Am. Chem. Soc. 2013, 135, 11887–11894.\n[88] Sahoo, B.; Pandey, V.; Dogonchi, A.; Mohapatra, P.; Thatoi, D.; Nayak, N.; Nayak, M.\nA state-of-art review on 2D material-boosted metal oxide nanoparticle electrodes: Super-\ncapacitor applications. J. Energy Storage 2023, 65, 107335.\n[89] Suppiah, D. D.; Daud, W. M. A. W.; Johan, M. R. Supported Metal Oxide Catalysts\nfor CO2 Fischer–Tropsch Conversion to Liquid Fuels-A Review. Energy Fuels. 2021, 35,\n17261–17278.\n[90] Gonz´ alez-V´ azquez, M.; Garc´ ıa, R.; Gil, M.; Pevida, C.; Rubiera, F. Comparison of the\ngasification performance of multiple biomass types in a bubbling fluidized bed. Energy\nConvers. Manag. 2018, 176, 309–323.\n36\n[91] Mohsin, M.; Farhan, S.; Ahmad, N.; Raza, A. H.; Kayani, Z. N.; Jafri, S. H. M.; Raza, R.\nThe electrochemical study of NixCe 1– x O2– δ electrodes using natural gas as a fuel. New\nJ. Chem. 2023, 47, 8679–8692.\n[92] Kaur, P.; Singh, K. Review of perovskite-structure related cathode materials for solid\noxide fuel cells. Ceram. Int. 2020, 46, 5521–5535.\n[93] Sengottuvelu, R. jsonformer. https://github.com/1rgs/jsonformer, 2018.\n[94] Sengottuvelu, R. jsonformer. https://github.com/martinezpl/jsonformer/tree/\nadd-openai, 2018.\n[95] Choudhary, K.; Kelley, M. L. ChemNLP: A Natural Language Processing based Library\nfor Materials Chemistry Text Data. arXiv preprint arXiv:2209.08203 2022,\n[96] Raffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.; Matena, M.; Zhou, Y.; Li, W.;\nLiu, P. J. Exploring the limits of transfer learning with a unified text-to-text transformer.\nJ. Mach. Learn. Res. 2020, 21, 5485–5551.\n[97] Wolf, T. et al. Transformers: State-of-the-Art Natural Language Processing. Proceedings\nof the 2020 Conference on Empirical Methods in Natural Language Processing: System\nDemonstrations. 2020.\n[98] Editorials, N. Tools such as ChatGPT threaten transparent science; here are our ground\nrules for their use. Nature 2023, 613, 10–1038.\n[99] Mollick, E. R.; Mollick, L. Using AI to Implement Effective Teaching Strategies in Class-\nrooms: Five Strategies, Including Prompts. SSRN Electronic Journal 2023,\n[100] Kim, S.; Chen, J.; Cheng, T.; Gindulyte, A.; He, J.; He, S.; Li, Q.; Shoemaker, B. A.;\nThiessen, P. A.; Yu, B.; Zaslavsky, L.; Zhang, J.; Bolton, E. E. PubChem 2023 update.\nNucleic Acids Res. 2022, 51, D1373–D1380.\n[101] Kim, S.; Thiessen, P. A.; Cheng, T.; Yu, B.; Bolton, E. E. An update on PUG-REST:\nRESTful interface for programmatic access to PubChem. Nucleic Acids Res. 2018, 46,\nW563–W570.\n[102] Kim, S.; Chen, J.; Cheng, T.; Gindulyte, A.; He, J.; He, S.; Li, Q.; Shoemaker, B. A.;\nThiessen, P. A.; Yu, B.; Zaslavsky, L.; Zhang, J.; Bolton, E. E. PubChem 2019 update:\nimproved access to chemical data. Nucleic Acids Res. 2018, 47, D1102–D1109.\n[103] Campbell, Q.; Herington, J.; White, A. D. Censoring chemical data to mitigate dual use\nrisk. arXiv preprint: Arxiv-2304.10510 2023,\nSupporting Information for: 14 Examples of How LLMs Can Transform\nMaterials Science and Chemistry: A Reflection on a Large Language Model\nHackathon\nKevin Maik Jablonka ,1, ∗ Qianxiang Ai ,2, † Alexander Al-Feghali ,3, † Shruti Badhwar ,4, †\nJoshua D. Bocarsly ,5, † Andres M Bran ,6, 7,† Stefan Bringuier ,8, † L. Catherine Brinson ,9, †\nKamal Choudhary ,10, † Defne Circi ,9, † Sam Cox ,11, † Wibe A. de Jong ,12, †\nMatthew L. Evans ,13, 14,† Nicolas Gastellu ,3, † Jerome Genzling ,3, † Mar´ ıa Victoria Gil ,15, †\nAnkur K. Gupta ,12, †Zhi Hong ,16, †Alishba Imran,17, †Sabine Kruschwitz ,18, †Anne Labarre ,3, †\nJakub L´ ala ,19, †Tao Liu ,3, †Steven Ma ,3, †Sauradeep Majumdar ,1, †Garrett W. Merz ,20, †\nNicolas Moitessier ,3, † Elias Moubarak ,1, † Beatriz Mouri˜ no ,1, † Brenden Pelkie ,21, †\nMichael Pieler ,22, 23,†Mayk Caldas Ramos ,11, †Bojana Rankovi´ c ,6, 7,†Samuel G. Rodriques ,19, †\nJacob N. Sanders ,24, † Philippe Schwaller ,6, 7,† Marcus Schwarting,25, † Jiale Shi ,2, †\nBerend Smit ,1, †Ben E. Smith ,5, †Joren Van Herck ,1, †Christoph V¨ olker ,18, †Logan Ward ,26, †\nSean Warren ,3, †Benjamin Weiser ,3, †Sylvester Zhang,3, †Xiaoqi Zhang ,1, †Ghezal Ahmad Zia ,18, †\nAristana Scourtas ,27 KJ Schmidt,27 Ian Foster ,28 Andrew D. White ,11 and Ben Blaiszik 27, ‡\n1Laboratory of Molecular Simulation (LSMO),\nInstitut des Sciences et Ing´ enierie Chimiques,\nEcole Polytechnique F´ ed´ erale de Lausanne (EPFL), Sion, Valais, Switzerland.\n2Department of Chemical Engineering, Massachusetts Institute of Technology,\nCambridge, Massachusetts 02139, United States.\n3Department of Chemistry, McGill University, Montreal, Quebec, Canada.\n4Reincarnate Inc.\n5Yusuf Hamied Department of Chemistry, University of Cambridge,\nLensfield Road, Cambridge, CB2 1EW, United Kingdom.\n6Laboratory of Artificial Chemical Intelligence (LIAC),\nInstitut des Sciences et Ing´ enierie Chimiques,\nEcole Polytechnique F´ ed´ erale de Lausanne (EPFL), Lausanne, Switzerland.\n7National Centre of Competence in Research (NCCR) Catalysis,\nEcole Polytechnique F´ ed´ erale de Lausanne (EPFL), Lausanne, Switzerland.\n8Independent Researcher, San Diego, CA, United States.\n9Mechanical Engineering and Materials Science, Duke University, United States.\n10Material Measurement Laboratory, National Institute of Standards and Technology, Maryland, 20899, United States.\n11Department of Chemical Engineering, University of Rochester, United States.\n12Applied Mathematics and Computational Research Division,\nLawrence Berkeley National Laboratory, Berkeley, CA 94720, United States.\n13Institut de la Mati` ere Condens´ ee et des Nanosciences (IMCN),\nUCLouvain, Chemin des ´Etoiles 8, Louvain-la-Neuve, 1348, Belgium.\n14Matgenix SRL, 185 Rue Armand Bury, 6534 Goz´ ee, Belgium.\n15Instituto de Ciencia y Tecnolog´ ıa del Carbono (INCAR),\nCSIC, Francisco Pintado Fe 26, 33011 Oviedo, Spain.\n16Department of Computer Science, University of Chicago, Chicago, Illinois 60637, United States.\n17Computer Science, University of California,\nBerkeley, Berkeley CA 94704, United States.\n18Bundesanstalt f¨ ur Materialforschung und -pr¨ ufung,\nUnter den Eichen 87, 12205 Berlin, Germany.\n19Francis Crick Institute, 1 Midland Rd, London NW1 1AT, United Kingdom.\n20American Family Insurance Data Science Institute,\nUniversity of Wisconsin-Madison, Madison WI 53706, United States.\n21Department of Chemical Engineering, University of Washington, Seattle, WA 98105, United States.\n22OpenBioML.org\n23Stability.AI\n24Department of Chemistry and Biochemistry,\nUniversity of California, Los Angeles, CA 90095, United States.\n25Department of Computer Science, University of Chicago, Chicago IL 60490, United States.\n26Data Science and Learning Division, Argonne National Lab, United States.\n27Globus, University of Chicago, Data Science and Learning Division, Argonne National Lab, United States.\n2\n28Department of Computer Science, University of Chicago,\nData Science and Learning Division, Argonne National Lab, United States.\nContents\nI. Predictive Modeling 3\nA. Leveraging LLMs for Accurate Molecular Energy Predictions 3\nB. From Text to Cement: Developing Sustainable Concretes Using In-Context Learning 6\nC. Molecule Discovery by Context 8\nD. Text template paraphrasing with LLMs 10\n1. Problem 10\n2. Solution 10\n3. Impact 12\n4. Lessons learned 12\nE. GA without genes 13\nII. Automation and novel interfaces 18\nA. Using chain-of-thought and chemical tools to answer materials questions 18\nB. sMolTalk 20\nC. whinchat: A Conversational electronic lab notebook (ELN) Interface 22\nD. BOLLaMa 25\nIII. Knowledge Extraction 27\nA. InsightGraph 27\nB. Extracting Structured Data from Free-form Organic Synthesis Text 29\nC. TableToJson: Extracting structured information from tables in scientific papers 31\nD. AbstractToTitle & TitleToAbstract: text summarization and text generation 36\n1. Problem 36\n2. Solution 36\n3. Example 36\nIV. Education 38\nA. i-Digest 38\nV. Meta analysis of the workshop contributions 40\nReferences 42\n∗mail@kjablonka.com\n†These authors contributed equally\n‡blaiszik@uchicago.edu\n3\nI. Predictive Modeling\nA. Leveraging LLMs for Accurate Molecular Energy Predictions\nTable I. LIFT for molecular atomization energies on the QM9-G4MP2 dataset. Metrics for models tuned on 90%\nof the QM9-G4MP2 dataset (117,232 molecules), using 10% (13,026 molecules) as a holdout test set. Note that the\nmetric used for the baseline results [1] is MAE, whereas this work used the MAD. The results indicate that the LIFT\nframework can also be used to build predictive models for atomization energies, that can reach chemical accuracy\nusing a ∆-ML scheme.\nmol. repr. & framework G4(MP2) Atomization Energy (G4(MP2)-B3LYP) Atomization Energy\nR2 MAD / eV R 2 MAD / eV\nSMILES: GPTChem 0.984 0.99 0.976 0.03\nSELFIES: GPTChem 0.961 1.18 0.973 0.03\nSMILES: GPT2-LoRA 0.931 2.03 0.910 0.06\nSELFIES: GPT2-LoRA 0.959 1.93 0.915 0.06\nSchNet baseline - - - 0.0045\nFCHL baseline - 0.0223 - 0.0052\nAccurate prediction of chemical properties has long been the ultimate objective in computational chemistry\nand materials science. However, the significant computational demands of precise methods often hinder their\nroutine application in modeling chemical processes. The recent surge in machine learning development, along\nwith the subsequent popularity of large language models (LLMs), offers innovative and effective approaches\nto overcome these computational limitations. Our project takes steps toward establishing a comprehensive,\nopen-source framework that harnesses the full potential of LLMs to accurately model chemical problems and\nuncover novel solutions to chemical challenges. In this study, we assessed the capability of LLMs to predict the\natomization energies of molecules at the G4(MP2) [2] level of theory from the QM9-G4MP2 dataset [3, 4]\nusing solely string representations for molecules, specifically, SMILES [5] and SELFIES [6, 7]. G4(MP2)\nis a highly accurate composite quantum chemistry method, known for its accuracy within 1 .0 kcal/mol for\nmolecular energies compared to experimental values, making atomization energy an ideal property to predict\nto demonstrate the usefulness and impact of LLMs on the field of computational chemistry.\nJablonka et al. [8] recently demonstrated the potential of fine-tuning pre-trained LLMs on chemistry\ndatasets for a broad array of predictive chemistry tasks. As an initial validation for our project, we fine-\ntuned generative pretrained transformer (GPT)-3 [9] to learn how to reproduce a molecule’s atomization\nenergy at the G4(MP2) level of theory, using its SMILES or SELFIES string through the prompt, “What is\nthe G4MP2 atomization energy in kcal/mol of ’SMILES/SELFIES string of a molecule’?” Additionally, we\nfine-tuned LLMs to predict the atomization energy difference between B3LYP/6-31G(2df,p) and G4(MP2)\nlevels of theory with the prompt, “What is the G4MP2 and B3LYP atomization energy difference in kcal/mol\nof ’SMILES/SELFIES string of a molecule’?”, which mirrors the ∆-machine learning (∆-ML) schemes [10]\nfound in the existing literature.\nFigure 1. Illustration of the molecular property prediction workflow, from molecule representation to model fine-tuning\nand performance evaluation.\n4\nWe fine-tuned the GPT-3 (Ada) model using 90% of the QM9-G4MP2 dataset (117,232 molecules) for\neight epochs with the GPTChem [8] framework’s default settings. The remaining 10 % (13,026 molecules)\nwas kept as the hold-out set, following the same data split as Ward et al. [1], to evaluate the model’s\nperformance. Table I summarizes the regression metrics for the hold-out set. The strong correlation between\nthe predicted and ground truth values suggests that the model effectively learned the structural information\nfrom the molecular string representation. Although the MAD remains relatively high compared to state-of-\nthe-art models in the literature [1, 11] that utilize a molecule’s full 3D structural information for descriptor\nconstruction, we achieved chemical accuracy ( < 1.0 kcal/mol ≈0.04 eV) for the ∆-ML task. Consequently,\nthis approach can predict G4(MP2) energies with high accuracy when B3LYP energies are available. We\nalso compared the model’s performance using SMILES and SELFIES molecular representations, with the\nformer proving marginally superior for predicting atomization energies, possibly due to its more compact\nrepresentation for molecules. We additionally calculated regression metrics for the G4MP2-Heavy dataset [1],\nthe results of which are provided in Table II.\nTable II. Regression metrics, (Coefficient of Determination), and MAD (Mean Absolute Deviation) for predicting\nG4(MP2) and (G4(MP2)B3LYP) atomization energies for the G4MP2-Heavy dataset using a fine-tuned GPT-3\nmodel with GPTChem\nmol. repr. & framework G4(MP2) Atomization Energy (G4(MP2)-B3LYP) Atomization Energy\nR2 MAD / eV R 2 MAD / eV\nSMILES: GPTChem 0.583 6.02 0.856 0.13\nSELFIES: GPTChem 0.146 9.44 0.659 0.15\nWhile GPT-3 fine-tuning models are accessible through the OpenAI application programming interface\n(API), their usage costs can become prohibitive for larger datasets, rendering hyperparameter searches and\nother exploratory research economically unfeasible. Consequently, we aim to develop a free and open-source\nframework for fine-tuning LLMs to perform a wide range of predictive modeling tasks, encompassing chemical\nproperty prediction and inverse design.\nTo fine-tune a pre-trained LLM locally on a GPU instead of querying OpenAI’s API, we employed the\nHugging Face parameter efficient fine-tuning (PEFT) library [12] to implement the low-rank adaptors (LoRA)\ntuning paradigm [13]. Conventional fine-tuning updates all model parameters, utilizing pretrained weights\nfrom a large training dataset as a starting point for gradient descent. However, fine-tuning memory-intensive\nLLMs on consumer hardware is often impractical. The LoRA approach addresses this by freezing the model’s\nweights and tuning a low-rank adapter layer rather than the entire model, parameterizing changes concerning\nthe initial weights rather than the updated weights.\nUsing this approach, we fine-tuned the smallest version of GPT-2 [14] (124 million parameters) for 20\nepochs on the same 90 % training set as used in GPTChem, allocating 10 % of that training set for validation,\nand computed metrics on the same 10 % hold-out set as in the GPTChem run, employing the same prompt\nstructure. Although the model performs well, it demonstrates slightly inferior performance to GPT-3 on\nthe G4MP2 task and moderately worse on the (G4(MP2)-B3LYP) task. This is not unexpected, given that\nGPT-3 is a more recent model with substantially more parameters than GPT-2 (175 billion vs. 124 million)\nand has exhibited superior few-shot performance on various tasks [15].\nMoving forward, we plan to employ the LoRA tuning framework to fine-tune other models, such as\nLLaMA [16] and GPT-J, to investigate the impact of LLM selection on performance in chemistry-related\ntasks. Moreover, we intend to experiment with molecular-input representations beyond string formats to\nmore accurately represent a molecule’s 3D environment [17].\nOne sentence summaries\na. Problem/Task Predicting the atomization energies of molecules using large language models.\nb. Approach Fine-tuning of GPT-3 ada model as well as PEFT of a small open-source model (GPT-2)\non SMILES to either directly predict the atomization energies or the difference between a lower and a higher\nlevel of theory.\n5\nc. Results and Impact Even though simpler, direct fine-tuning for a complicated property on SMILES\nleads to errors one order of magnitude higher than baselines, and the error can only be brought close to the\nbaselines with an ∆ −ML approach—first demonstration of ∆-ML in the LIFT framework for chemistry.\nd. Challenges and Future Work Since the predictions without 3D coordinates is not satisfactory, a\nquestion for future work is how the approach would perform when provided with 3D coordinates.\n6\nB. From Text to Cement: Developing Sustainable Concretes Using In-Context Learning\nThe inherently intricate chemistry and variability of feedstocks in the construction industry have limited\nthe development of novel sustainable concretes to labor-intensive laboratory testing. This major bottleneck\nin material innovation has significant consequences due to the substantial contribution of CO 2 emissions of\nmaterials in use today. The production of Portland cement alone amounts to approximately 8 % of anthro-\npogenic CO2 emissions [18]. The increasing complexity of alternative raw materials and the uncertain future\navailability of established substitutes like fly ash and granulated blast furnace slag make the experimental\ndevelopment of more sustainable formulations time-consuming and challenging. Traditional trial-and-error\napproaches are ill-suited to efficiently explore the vast design space of potential formulations.\nIn previous studies, inverse design (ID) has been shown to accelerate the discovery of novel, sustainable, and\nhigh-performance materials by reducing labor-intensive laboratory testing [19–21]. Despite their potential,\nthe adoption of these techniques has been impeded by several difficulties that are connected to the predictive\nmodel at the core of ID: Incorporating domain knowledge typically requires extensive data collection to\naccurately capture underlying relationships, which makes representing complex tasks in practice challenging\ndue to the high costs of data acquisition. Furthermore, ID necessitates formulating research problems\nas search space vectors. This process can be unintuitive and challenging for lab personnel, limiting the\ncomprehension and adoption of these techniques. Lastly, sparse training samples in high dimensions can\nlead to co-linearities and overfitting, negatively impacting prediction performance. With in-context learning\nFigure 2. Using LLMs to predict the compressive strength of concretes . The left part illustrates the conventional\napproach for solving this task, i.e., training classical prediction models using tabular data. Using the LIFT framework\nLLM can also use tabular data but also leverage context information provided in natural language. Augmented with\nthis context, in-context-learning with LLM leads to a performance that outperforms baselines such as RFs or GPRs.\n(ICL), Jablonka et al. [8] and Ramos et al. [22] demonstrated that LLMs offer a solution by incorporating\ncontext and general knowledge, providing flexibility in handling non-numeric inputs and overcoming the\nlimitations of traditional vector space formulations (Figure 2).\nIn this study, we have adopted an ICL approach based on a dataset from a study by Rao and Rao [23].\nThe dataset comprises 240 alternative and more sustainable concrete formulations based on fly ash and\nground granulated slag binders, along with their respective compressive strengths. The goal is to compare\nthe prediction performance of the compressive strength with ICL using the text-davinci-003 model [24]\nagainst established methods, RF [25].\nRandomly sampled training subsets containing ten formulations are drawn. The prediction performance\nis assessed on a separate, randomly sampled test set of 25 samples and evaluated using the coefficient of\ndetermination (R-squared) [26]. This process is repeated ten times to ensure more reliable results.\nThe experimental results reveal that ICL attains comparable performance to GPR but underperforms\nRF when provided with small training data sets (R-squared of 0.5, 0.54, and 0.67, respectively). However,\nwhen using general, qualitative concrete design knowledge, such as the influence of the water-to-cement ratio\non strength, the models significantly reduce prediction outliers and ultimately surpass RF (R-squared =\n0.71). When we incorrectly changed the context of the ratio of fly ash to GGBFS, it negatively affected the\nR-squared value for ICL, causing it to drop to 0.6. This misrepresentation of the rule led to a decrease in\nthe model’s predictive accuracy, demonstrating that the quality of the information included in the “fuzzy”\ncontext is critical to the overall performance of LLMs. It should be noted, however, that the impact on the\nR-squared value may vary depending on the importance of the rule in the overall context. That is, not all\n7\nchanges in context have a similar impact, and the drop to 0.6 might occur only in the case of the ratio of fly\nash to GGBFS. Other studies, such as those conducted in the LIFT work, [27] have shown LLM performance\nfor minor changes in wording or the presence of noise in the features. In these experiments, the robustness\nof LIFT-based predictions was comparable to classical ML algorithms, making it a promising alternative for\nusing fuzzy domain knowledge in predictive modeling.\nLLMs have been shown to provide significant advantages in sustainable concrete development, including\ncontext incorporation, adaptable handling of non-numeric inputs, and efficient domain knowledge integration,\nsurpassing traditional methods’ limitations. ICLs simplifies formulating data-driven research questions,\nincreasing accessibility and democratizing a data-driven approach within the building materials sector. This\nhighlights LLMs potential to contribute to the construction industry’s sustainability objectives and foster\nefficient solutions.\nOne sentence summaries\na. Problem/Task Predicting the compressive strength of concrete formulations.\nb. Approach ICL on language-interfaced tabular data, with and without “fuzzy” domain expertise (such\nas relationship between columns) provided in natural language.\nc. Results and Impact Predictive models can be built without any training; if provided with domain\nexpertise, those models outperform the baselines—first demonstration in chemistry of such fuzzy knowledge\ncan be incorporated into models.\nd. Challenges and Future Work ICL can be very sensitive to the prompt, hence future work should\ninvestigate the robustness of this approach.\n8\nC. Molecule Discovery by Context\nThe escalating climate crisis necessitates the deployment of clean, sustainable fuels to reduce carbon\nemissions. Hydrogen, with its potential to prevent approximately 60 gigatons of CO 2 emissions by 2050,\naccording to the World Economic Forum, stands as a promising solution [28]. However, its storage and\nshipping remain formidable challenges due to the necessity for high-pressure tanks. To address this, we\nsought new molecules to which hydrogen could be conveniently added for storage. Traditional screening\nmethods, like brainstorming, are insufficient due to their limited throughput. This research proposes a novel\nmethod of leveraging ScholarBERT, [29] a pre-trained science-focused LLM, to screen potential hydrogen\ncarrier molecules efficiently. This approach utilizes ScholarBERT’s ability to understand and relate the\ncontext of scientific literature. The data used for this study consisted of three datasets. The “Known”\ndataset comprised 78 known hydrogen carrier molecules. The “Relevant” dataset included 577 molecules,\nall of which are structurally similar to the “Known” molecules. The “Random” dataset contained 111\nrandomly selected molecules from the PubChem database [30]. The first step involved searching for contexts\nfor molecules in the Public Resource Dataset (PRD), which includes 75M English language research articles.\nThese contexts (i.e. sentences that mentioned the molecule name) were then fed into ScholarBERT. For each\ncontext, three calculations were made:\n1. the average of the last four encoder layers in ScholarBERT\n2. the average embedding of all tokens constituting the molecule name as one contextualized embedding\nfor this molecule, and\n3. the average of all contextualized embeddings for a molecule as ScholarBERT’s representation of this\nmolecule.\nSubsequently, we calculated the similarity between the known and candidate molecules. The definition of\n“similarity” used in this study was the cosine similarity between the ScholarBERT representations of two\nmolecules. We then sorted the candidates based on the similarity score in descending order, with a higher\nscore indicating greater potential as a hydrogen carrier. Figure 3 and 4 show the candidate molecules with\nthe highest similarity to the known molecules. We can see that ScholarBERT does a passable job finding\nsimilar molecules from the random set. We do see that it favors finding molecules with 5- and 6-member\nrings, though with features we didn’t expect, like halogens. On the other hand, ScholarBERT does a much\nbetter job when we reduce the search space to those with structural similarity. We see that molecules with\n5-member rings, for instance, are found to be similar structurally and in how they are described in the\nliterature via ScholarBERT.\nFigure 3. Each column shows a Known molecule on the bottom and its top candidate molecule from the Random set\non the top\nBased on our empirical data, computing the energy capacity (wt%H2) and energy penalty (kJ/mol/H2) of\nadding and removing H2 to the molecule (which are the quantitative “success metrics” for this project) of a\ncandidate molecule using traditional quantum chemistry takes around 30 seconds per molecule on a 64-core\nIntel Xeon Phi 7230 processor, whereas the proposed LLM approach can screen around 100 molecules per\nsecond on a V100 GPU, achieving a 3000 times speedup.\nOne sentence summaries\na. Problem/Task Recommending hydrogen carrier molecules.\n9\nFigure 4. Each column shows a Known molecule on the bottom and its top candidate molecule from the Relevant\nset on the top\nb. Approach Ranking of molecules based on similarity of embeddings created with a language model by\nshowing aggregating the embeddings of mentions of the molecules in scientific texts.\nc. Results and Impact Approach can recommend molecules with a success rate better than random.\nd. Challenges and Future Work More benchmarks compared to conventional generative modeling are\nneeded.\n10\nD. Text template paraphrasing with LLMs\n1. Problem\nText data is much trickier to augment for machine learning applications due to the discrete nature of the\ndata modality. There are some traditional augmentation approaches for these tasks. However, they can\nbe inefficient or still need extensive manual checks to be sure they deliver the desired results, especially for\nscientific or chemistry applications.\n2. Solution\nTo automate high-quality text data augmentations, LLMs have been explored by Dai and his coworkers [31]\nas a very recent and promising solution to this problem. We investigated such a setup in the scope of\nthe OpenBioML chemistry NLP project ( https://github.com/OpenBioML/chemnlp) to paraphrase text\ntemplates for the insertion of chemical raw data into natural language for LIFT. [27]\nAn example prompt is shown below. The outlined prompt setup has after “Question:” the desired task\nwith additional information and after “Sentence:” the starting text template for the paraphrasing. The\n“Question:” and “Answer:” headers are not used if the LLM interface uses a chat interface, i.e., with\nOpenAI GPT-4.\nExample Prompt\nQuestion: Please paraphrase the sentence below ten times without changing the original meaning\nand the placeholder in the curly {}brackets. Please use all the placeholders in the curly {}\nbrackets for every rephrased sentence.\nSentence: The molecule with the {SMILES description} representation {SMILES data} has a\n{target name}of {target value}{target units}.\nAnswer:\nExample Response by GPT-4\n1. The {SMILES description} representation of the molecule is {SMILES data}, and its\n{target name}is {target value}{target units}.\n2. With a {SMILES description} representation of {SMILES data}, the molecule has a\n{target name}of {target value}{target units}.\n3. The molecule, represented by {SMILES description} as {SMILES data}, possesses a\n{target name}of {target value}{target units}.\n4. A molecule having a {SMILES description} representation of {SMILES data} also has a\n{target name}equal to {target value}{target units}.\n5. The {SMILES description}-represented molecule with {SMILES data} exhibits a\n{target name}of {target value}{target units}.\n6. For the molecule with a {SMILES description} representation of {SMILES data}, its\n{target name}measures {target value}{target units}.\n7. The {target name} of the molecule having a {SMILES description} representation of\n{SMILES data}is {target value}{target units}.\n8. Represented by {SMILES description}as {SMILES data}, the molecule’s {target name}is\n{target value}{target units}.\n11\n9. The molecule’s {target name}is {target value}{target units}when its {SMILES description}\nrepresentation is {SMILES data}.\n10. A {target name} of {target value}{target units} is associated with the molecule whose\n{SMILES description}representation is {SMILES data}.\nExample Response by Anthropic Claude v1\nHere are 10 paraphrased sentences of the original sentence with the placeholders retained:\n1. The molecule represented by the {SMILES description} code {SMILES data} has a\n{target name}of {target value}{target units}.\n2. The {SMILES description} notation {SMILES data} denotes a molecule with a\n{target name}equal to {target value}{target units}.\n3. A {target name}of {target value}{target units}is possessed by the molecule depicted using\n{SMILES description}as {SMILES data}.\n4. {SMILES data} signifies the {SMILES description} of the molecule which has a\n{target name}of {target value}{target units}.\n5. The {SMILES description} {SMILES data} characterizes the molecule that exhibits a\n{target name}of {target value}{target units}.\n6. A {target name}equal to {target value}{target units}belongs to the molecule expressed with\n{SMILES description}code {SMILES data}.\n7. {SMILES data} denotes the {SMILES description} for the molecule possessing a\n{target name}of {target value}{target units}.\n8. The molecule defined by {SMILES description}{SMILES data}presents a {target name}of\n{target value}{target units}.\n9. {SMILES description}{SMILES data}specifies the molecule which displays a {target name}\nof {target value}{target units}.\n10. A {target name}amounting to {target value}{target units}is a property of the molecule\nrepresented with {SMILES description}{SMILES data}.\nExample Response by GPT-J\nThe molecule with the {SMILES description}representation {SMILES A}has a {target name}\nof {target value}{target units}. {SMILES A} has a {target name} of {target units}. The\nmolecule with the {target units} representation {target name} has a TARGET UNITS of\n{target value}{target units}. {target name} of {target units} have a TARGET UNITS of\n{target value}{target units}.\nIn the above answer, there is the {SMILES description}representation of {SMILES query}, but we don’t\nuse it in the sentence yet. And there is no curly brackets for the excepted answer.\n12\n3. Impact\nThe outlined approach allows to automatically create new paraphrased high-quality prompts for LIFT\nLLM training data very efficiently. With the additional paraphrased text templates, overfitting to special\ntext passages should be avoided. We explore this setup in follow-up work in more detail.\n4. Lessons learned\nThe outlined paraphrasing setup works well for the latest state-of-the-art models, e.g., OpenAI’s GPT-\n4 and Anthropic’s Claude v1. Less capable open-source models seem to lack the understanding of this\nparaphrasing task. Still, new and upcoming open-source LLM efforts could change that soon, enabling a\ncost-effective and broader application of this setup.\nOne sentence summaries\na. Problem/Task Generation of many text-templates for language-interfaced fine-tuning of LLMs\nb. Approach Prompting of LLM to rephrase templates (with template syntax similar to Jinja).\nc. Results and Impact Large models (GPT-4, Claude), in contrast to smaller ones, can successfully\nrephrase templates, offering a potential avenue for data-augmentation.\nd. Challenges and Future Work As next step, ablation studies need to carried out that test the effect\nof data augmentation by template rephrasing on regression and classification case studies.\n13\nE. GA without genes\nWe investigate the ability for a LLM to work in parallel with genetic algorithms (GAs) for molecular\nproperty optimization. By employing a LLM to guide genetic algorithm operations, it could be possible\nto produce better results using fewer generations. We hypothesize that a GA can take advantage of the\n“smart” randomness of the outputs of the LLM. This work explores the potential of LLMs to improve molec-\nular fragmentation, mutation, variation, and reproduction processes and the ability of a LLM to gather\ninformation from a simplified molecular-input line-entry system (SMILES) string [5, 6] and an associated\nscore to produce new SMILES strings. Although computational efficiency is not the primary focus, the pro-\nposed method has potential implications for enhancing property prediction searches and future improvements\nin LLM understanding of molecular representations.\nWe used GPT-3.5-turbo [9], which could frequently fragment druglike molecules into valid SMILES strings\nsuccessfully. For 2/10 molecules, the fragments produced were not in the original molecule. For1/10 molecules,\nvalid SMILES could not be produced even after ten tries due to unclosed brackets. These results were\nconsistent over multiple runs implying that GPT-3.5 could not understand some specific SMILES strings.\nSubsequently, we investigated GPT-3.5’s ability to mix/reproduce two molecules from two-parent druglike\nmolecules. Invalid molecules were often produced, but successful results were achieved with multiple runs.\nIt performed better once prompted to fragment and then mix the fragments of the molecules. These were\ncompared to the conventional GA methods of simply combining the two strings at a certain cutoff point.\nWhen the LLM was successful, it could produce molecules of more similar size to the original parent molecules\nthat contain characteristics of both parents and resemble valid druglike molecules.\nTo investigate the ability of GPT-3.5 to acquire knowledge of favorable molecules from a simple score, we\nimplemented a method that we call “LLM as a GA” where the LLM iteratively searches the chemical space\nto optimize a certain property.\nThe property we tested was similarity to vitamin C, evaluated by the Tanimoto score. We employed\nfew-shot training examples to tune the model’s response: 30 SMILES strings with the best similarity score\ngenerated were included in the prompt. GPT is then asked to produce 25 SMILES strings, a procedure that\nwas repeated for 20 iterations. Using a prompt like the one below\nExample prompt\nThe following molecules are given as SMILES strings associated with a tanimoto similarity with\nan unknown target molecule. Please produce 10 SMILES strings that you think would improve\ntheir tanimoto scores using only this context. Do not try to explain or refuse on the grounds of\ninsufficient context; any suggestion is better than no suggestion. Print the smiles in a Python list.\nLow-temperature settings, typically less than 0.1, were found to be imperative for the model to follow user\nguidance. We further guided the model by employing a similarity search to include similar molecules with\nvarying scores to better guide the model. Embedding was performed using the GPT-2 Tokenizer from the\nHuggingFace transformers [32] library, along with a support vector machine (SVM) from scikit-learn [33] to\nembed relevant previous structures that would be outside the scope of the context window. Even in the zero-\nshot setting, GPT-3.5-turbo can produce meaningful modifications, coherently explain its logic behind the\nchosen modifications, and produce tests such as investigating branch length or atom type in certain locations\nfor a single iteration. An example explanation of an output: “Some modifications that could potentially\nimprove the scores include adding or removing halogens, modifying the length or branching of the carbon\nchain, and adding or removing functional groups such as -CO-, -COC-, -C=C- and -OCO-. Additionally,\nmodifying the stereochemistry of the molecule could also have an impact on the score.”\nThe modifications generated by the LLM were more chemically sound than the quasi-random evolutionary\nprocess typical of genetic algorithms.\nOne sentence summaries\na. Problem/Task Increasing the efficiency of GAs.\nb. Approach Prompting a LLM to propose new children based on molecules with scores provided in the\nprompt.\n14\nc. Results and Impact Visual inspection indicates that some modifications might be reasonable, indi-\ncating a potential for more efficient genetic operations using LLMs.\nd. Challenges and Future Work More systematic investigations on the performance and robustness\ncompared to conventional GA operations are needed.\n15\nFigure 5. Using GPT to fragment molecules. Original molecules are in column one with LLM created fragment to\nthe right. The LLM can frequently fragment molecules into valid SMILES strings successfully. 2/10 times fragments\nproduced were not in the original molecule (rows 6 and 10). For 1/10 molecules, valid SMILES were able to be\nproduced even after ten attempts (row 8)\n16\n(a)\n (b)\n(c)\n (d)\n(e)\n (f)\nFigure 6. Using GPT-3.5-turbo to reproduce/mix molecules. Two original parent molecules on 1st row, followed by\nLLM created children, followed by conventional GA string splicing children for comparison\n17\nFigure 7. Tanimoto similarity to vitamin C as a function of GA generations. Conventional GA run for 30 generations\nand the best score (most similar to vitamin C) of each generation is given to the LLM as a LLM along with its\nassociated Tanimoto similarity score to Vitamin C. LLM was then asked to create new molecules and improve the\nscore for 12 generations. Multiple new best molecules were found using LLM as shown by the blue line.\n18\nII. Automation and novel interfaces\nA. Using chain-of-thought and chemical tools to answer materials questions\nFigure 8. Schematic overview of the MAPI-LLM workflow. It uses LLMs to process the user’s input and decide\nwhich available tools (e.g., Materials Project API, and Google Search) to use following an iterative chain-of-thought\nprocedure. In this way, it can answer questions such as “Is the material AnByCz stable?”.\nLLMs have demonstrated remarkable success in various tasks [34–36]. Recently, LLMs have gained atten-\ntion in chemistry, demonstrating exceptional ability to model chemical systems [37] and predicting tabular\ndata [8, 22, 27]. Predicting the properties of materials is challenging since it requires computationally inten-\nsive techniques, such as density functional theory (DFT) [38–40]. Data-driven models offer a viable option\nto balance accuracy and computational time. Here we presented the MAPI-LLM, a multi-task package that\nemploys LangChain [41] agents with access to multiple tools to address users’ questions about materials.\nIt has been shown that providing chemistry-specific tools to an LLM allows the LLM to solve chemistry\nproblems with significantly higher accuracy [42]. In a similar manner, we developed tools to iteratively\nquery the Materials Project (MAPI) dataset [43] and utilize the reaction-network package [44], among oth-\ners. MAPI-LLM can process user prompts in natural language using LLMs and follow a chain of thought\n(COT) [45] approach to determine the most suitable tools and inputs to answer the prompt. Due to MAPI-\nLLM’s design, more tools can be added as needed, and tools can be combined (multiple tools can be used for\na given prompt), opening the door for a large variety of applications. Figure 8 illustrates MAPI-LLM’s capa-\nbilities. The code for the app is available in https://github.com/maykcaldas/MAPI_LLM, and a graphical\nuser interface (GUI) is implemented in https://huggingface.co/spaces/maykcaldas/MAPI_LLM.\nAn important feature implemented into MAPI-LLM is a technique known as ICL [9], which allows the\nmodel to learn from the context within the prompt. For example, users can use MAPI-LLM’s tool to query\nthe MAPI dataset, first triggering the dataset search in the COT. However, if the desired material is not\nfound in the dataset, MAPI-LLM still has access to other tools (such as ICL) to build context around the\nuser prompt and adjust the COT actions to make a prediction. Another interesting tool is the ability to\nuse the reaction-network package [44], which is a package for predicting inorganic reaction pathways. We\nshowed the promising capabilities of MAPI-LLM by simply asking for reactions that use a given material as\nreactants or products. It can suggest such reactions for material synthesis or decomposition.\nWe built from the knowledge that LLMs are suitable for such tasks of interest in this application, for\ninstance, classification and regression tasks [8]. Nevertheless, this application still needs a systematic vali-\ndation of its predictions, such as the reinforcement learning from human feedback (RLHF) implementation\nin GPT-3.5 [46].\nOne sentence summaries\na. Problem/Task Answering complex materials science questions based on reliable data and tools.\nb. Approach LLM-based agent in the ReAct framework that has access to tools such as the Materials\nProject API and uses ICL to answer questions for materials that are not in the materials project.\nc. Results and Impact Coupling of tools allows answering questions that none of the tools or LLMs\nalone could solve by themselves, providing a very accessible interface to materials informatics tools.\n19\nd. Challenges and Future Work If a description of tools is incorporated in the prompt, this limits the\nnumber of tools that can be coupled. In addition, LLM agents still tend to not perform equally well on all\nprompts, and systematic investigation to better understand this and to increase the robustness is needed.\n20\nB. sMolTalk\nFigure 9. The sMolTalk interface. Based on few-shot prompting LLMs can create code for visualization tools such\nas 3dmol.js.\nSince the advent of 3D visualization methods, chemists have employed computers to display their molecules\nof interest to better understand their underlying structure and properties. Nevertheless, a lot of chemists\nare not equipped with the required coding skills to use and customize their visualizations. Depending on\nthe package, and its associated documentation, chemists might end up spending hours to days learning the\ndetails of the specific visualization software.\nWe developed a natural language interface that generates code for 3dmol.js, an open-source visualization\nJavaScript library [47], meaning the visualizations are run in a web browser (Figure 9). The user input is\nfed into ChatGPT API, using the GPT-3.5-turbo model. We use in-context learning (few-shot prompting),\ngiving several examples of the user input with the expected JavaScript code that manipulates the 3dmol.js\nviewer. Before the user submits further commands, we update the prompt with the current state of the\nviewer.\nThe current implementation might lead to a one-stop solution for visualizing and retrieving properties for\nmolecules. This would accelerate chemists’ workflow for querying information about molecules. Furthermore,\nif an LLM is able to control structural software, it might be possible to perform reasoning on the molecular\nstructure itself. For instance, in drug discovery, one may ask what functional group of the ligand needs to\nbe changed for binding affinity to the protein to increase. Another example might involve proteins, looking\nat what amino acid residues could be mutated to cysteines in order to create new disulfide bonds between\nchains. This would presumably require specific fine-tuning and equipping the LLM with more tools. The\napproach of generating code and structural reasoning might be similar but is most likely going to require a\ndifferent set of tools that were specifically developed for protein structure manipulation (such as PyMoL [48],\nor MolStar [49]). Then, another set of highly accurate tools for binding affinity predictions or protein folding\nis also required. The major problem encountered is prompt leakage, where examples from in-context learning\nwould leak into the actual LLM output. For the best evaluation, it is best to have as few and as different\nexamples as possible. Moreover, although OpenAI’s GPT models can sometimes correctly recall protein data\nbank (PDB) IDs of proteins or Chemical Abstract Services (CAS) numbers of compounds, it’s not reliable,\nmaking tooling the models with API calls to PubChem, or the PDB, much more robust. We are currently\ndeveloping an agent based on the ReAct approach [50] tooled with these APIs so that correct structures are\nalways retrieved (i.e., to avoid the LLM needs to remember internally all such IDs). This framework would\n21\nthen help us iteratively add tools to the agent, creating a chatbot one can query about any molecule of\ninterest, including the structural reasoning task mentioned above. Lastly, we hypothesize we could improve\nthe generation of 3dmol.js code by using self-instruct fine-tuning. Using an external LLM with access to\nthe documentation would create a dataset that could be used for fine-tuning. The same approach might be\nutilized for generating code for any other type of software, not just visualization packages. Therefore, such\nLLM could control molecular dynamics software, such as LAMMPS [51], or GROMACS [52].\nOne sentence summaries\na. Problem/Task Making bioinformatics tools, in particular the visualization software 3dmol.js acces-\nsible to non-experts.\nb. Approach Chat-interface by prompting a LLM to produce commands to 3dmol.js, which are then\npassed to the software.\nc. Results and Impact The LLM can, without consulting the documentation, generate code that often\nsuccessfully performs the requested actions, demonstrating that LLM might help make tools more accessible\nby providing access to complex interfaces via natural language.\nd. Challenges and Future Work The approach suffers from robustness issues, which might be overcome\nwith conditioning on a knowledge base, more advanced decoding strategies, or error handling (e.g., giving\nthe agent access to error messages and logs and prompting it to reflect).\n22\nC. whinchat: A Conversational ELN Interface\nLaboratory data management systems such as ELNs and laboratory information systems (LIMS) can\nrecord rich data about experimental samples and the experiments that have been performed on them. Then,\nthe user interfaces for these systems typically allow researchers to explore their samples with various pre-\nprogrammed visualizations. However, it is difficult for a traditional user interface to have enough flexibility to\ncapture the richness and diversity of real, interconnected, experimental data. Here, our aim was to investigate\nwhether an LLM could process digital laboratory data and serve as a flexible, conversational interface to\na data management system. As a proof-of-concept for this approach, we introduced an automated data\nmanagement assistant into the open-sourced “Datalab” software, which we have been developing to address\nneeds in experimental materials chemistry (https://github.com/the-grey-group/datalab). Datalab can\nbe used to capture data and metadata about materials chemistry samples, their synthesis constituents, and\nresulting devices. The system tracks each sample’s provenance through the research lifecycle and makes this\ndata available via a JavaScript object notation (JSON) API that can be explored programmatically or with\na Vue.js-based web user interface (UI). During the hackathon, we embedded a prompted LLM into the UI\nand gave it access to raw responses from datalab’s JSON API. We used the most recent publicly available\nmodels from OpenAI (gpt-3.5-turbo) via their Python API. We found that the LLM does a very good job\nat interpreting JSON and inferring the meaning of fields (including linked data) and can:\n1. Contextualize existing data:Explain a set of related experiments from linked JSON responses, resolve\nacronyms/ short-hand used by experimentalists or create simple text summaries.\nContextualizing existing data\nAssistant Hello! I am your virtual assistant and I am here to help you manage your experimental\ndata. How can I assist you today?\nUser Can you provide a brief summary of this experiment?\nAssistant Based on the provided JSON data, this experiment involves the synthesis and charac-\nterization of NaCoO 2 as a battery cathode material. The synthesis method used was solid-state\nreaction, and the starting materials used were sodium carbonate and cobalt (II,III) oxide. The\nsynthesized NaCoO 2 was then used to make an electrode, which was characterized using X-ray\ndiffraction. The electrode was then incorporated into a coin cell battery, which was cycled electro-\nchemically and characterized using various techniques.\n2. Generate text and graphicalrepresentations of the data: Aggregate data from different fields in the\nJSON response and convert to formats such as tables (potentially formatted for a particular journal),\nCSV, and even mermaid.js graph visualizations.\n3. Suggest future experiments:The assistant readily identifies related materials to study, additives to try,\nadditional characterization techniques, and synthesis protocols.\nSuggest experiments\nUser: What NMR nuclei could I probe in this sample?\nAssistant: Based on the information provided in the JSON file, the sample is NaCoO 2, which\ncontains sodium, cobalt, and oxygen. Therefore, the NMR nuclei that could be probed in this\nsample are:\n(a) Sodium-23 (23Na) NMR: This can provide information about the local environment and\ncoordination of sodium ions in the NaCoO 2 lattice.\n(b) Cobalt-59 (59Co) NMR: This can provide information about the local environment and co-\nordination of cobalt ions in the NaCoO 2 lattice.\n(c) Oxygen-17 (17O) NMR: This can provide information about the local environment and coor-\ndination of oxygen ions in the NaCoO 2 lattice.\n23\nFigure 10. The chatbot can generate mermaid.js markdown code, which our interface automatically recognizes and\ntranslates into the visualization.\nIt is worth noting that NMR spectroscopy is a powerful technique for probing the local environment\nof atoms in a material, but it requires a relatively large amount of sample and may not be sensitive\nto all types of nuclei. Therefore, it may be necessary to use other techniques in conjunction with\nNMR to fully characterize the sample.\nUser: What techniques (that I haven’t already used) should I use in conjunction with the NMR?\nAssistant: In addition to the techniques I mentioned earlier, you could use the following techniques\nin conjunction with NMR to fully characterize the NaCoO 2 sample:\n(a) X-ray photoelectron spectroscopy (XPS): This can provide information about the chemical\ncomposition and oxidation state of the NaCoO2 sample, which can help to interpret the NMR\nspectra.\n(b) Transmission electron microscopy (TEM): This can provide information about the crystal\nstructure, morphology, and defects of the NaCoO 2 sample, which can help to interpret the\nNMR spectra.\n(c) Electrochemical impedance spectroscopy (EIS): This can provide information about the elec-\ntrical properties and performance of the NaCoO 2 sample as an electrode material, which can\nhelp to interpret the NMR spectra.\n(d) Thermogravimetric analysis (TGA): This can provide information about the thermal stability\nand decomposition behavior of the NaCoO 2 sample, which can help to interpret the NMR\nspectra.\nBy using a combination of these techniques, you can gain a more complete understanding of the\nNaCoO2 sample\nThe assistant performs quite well at certain tasks out-of-the-box, but we believe it should also be possible\nto further increase its general utility by fine-tuning the model on the domain knowledge present in a research\n24\ngroup’s Wiki and papers. Furthermore, while we have only given the model data from a single project so\nfar (up to 8 samples/starting materials, 1700 tokens of JSON), it would be of great interest to provide the\nmodel with a larger context across multiple projects to attempt to facilitate cross-fertilization of ideas. One\nnotable challenge in this area is the limited context size of currently available LLM models (e.g., 4097 tokens\nfor GPT-3.5-turbo). Therefore, future work will investigate larger models (e.g., GPT-4 with 30K token\ncontext), as well as approaches to give existing LLMs access to larger context (e.g., an embedding-based\napproach or allowing an LLM agent to query the OpenAPI directly as needed). At present, we note that the\nscientific usefulness of this assistant is highly task- and model-dependent; however, any additional interface\nthat can lower the barrier to improving data capture and dissemination in the field should be investigated\nfurther and will be a future development target for Datalab.\nOne sentence summaries\na. Problem/Task Providing very flexible access to data in ELNs/LIMS.\nb. Approach Prompting of a large language model with questions provided in a chat interface and\ncontext coming from the response of the API of an LLM.\nc. Results and Impact The system can successfully provide a novel interface to the data and let user\ninteract with it in a very flexible and personalized way, e.g, creating custom summaries or visuals for which\nthe developers did not implement specific tools.\nd. Challenges and Future Work Since the current approach relies on incorporating the response of the\nELN/LIMS into the prompt, this limits how much context (i.e., how many experiments/samples) the system\ncan be aware of. One potential remedy is to use retrieval-augmented generation, where the entries are\nembedded in a vector store and the agent will be able to query this database on put (parts of) the most\nrelevant entries into the prompt.\n25\nD. BOLLaMa\nThe field of chemistry is continuously evolving towards sustainability, with the optimization of chemical\nreactions being a key component [53]. The selection of optimal conditions, such as temperature, reagents,\ncatalysts, and other additives, is challenging and time-consuming due to the vast search space and high cost\nof experiments [54]. Expert chemists typically rely on previous knowledge and intuition, leading to weeks or\neven months of experimentation [55].\nBayesian optimization (BO) has recently been applied to chemistry optimization tasks, outperforming\nhumans in optimization speed and quality of solutions [55]. However, mainstream access to these tools\nremains limited due to requirements for programming knowledge and the numerous parameters these tools\noffer. To address this issue, we developed BOLLaMa. This artificial intelligence (AI)-powered chatbot\nsimplifies BO for chemical reactions with an easy-to-use natural language interface, which facilitates access\nto a broader audience.\nFigure 11. Schematic overview of BOLLaMa. A LLM can act as an interface to a BO algorithm. An experimental\nchemist can bootstrap an optimization and then, via a chat interface, update the state of the simulation to which\nthe bot responds with the recommended next steps.\nBOLLaMa combines LLMs with BO algorithms to assist chemical reaction optimization. The user-friendly\ninterface allows even those with limited technical knowledge to engage with the tool. BOLLaMa’s current\nimplementation provides two main tools: the initialization function and the optimization step function [56],\nthat are retrieved on LLM-demand as shown in Figure 11.\nThe primary contribution of this project is democratizing access to advanced BO techniques in chemistry,\npromoting widespread adoption of sustainable optimization tools, and impacting sustainability efforts within\nthe community. This approach can be further enhanced to provide a more comprehensive assistant experi-\nence, such as with additional recommendations or safety warnings, and improve the explainability of the BO\nprocess to foster user trust and informed decision-making.\nKey insights gained from this project include the critical role of accessibility in developing expert tools\nand the potential of LLMs in chemistry through various agent architectures [50]. In addition, the initial BO\ntool adapted for BOLLaMa was designed for closed-loop automated laboratories, emphasizing the need for\naccessible tools catering to diverse user backgrounds.\nOne sentence summaries\na. Problem/Task Giving scientists without coding and machine learning expertise access to Bayesian\noptimization.\n26\nb. Approach LLM as a chat-interface for a Python package for Bayesian optimization by using ReAct-\nlike approach in which the LLM has access to text-description of relevant functions (such as initialization\nand stepping of the BO run).\nc. Results and Impact The chat interface can successfully initialize a BO run and then convert obser-\nvations reported in natural language into calls to the stepping function of the BO tool.\nd. Challenges and Future Work As most LLM agents, the tools suffers from robustness issues and the\ncorrect functioning cannot be guaranteed for all possible prompts.\n27\nIII. Knowledge Extraction\nA. InsightGraph\nFigure 12. The Insight Graph interface. A suitably prompted LLM can create knowledge graph representations of\nscientific text that can be visualized using tools such as neo4j’s visualization tools. [57]\nThe traditional method of performing a literature review involves months of reading relevant articles to\nfind crucial information on material properties, structure, reaction pathways, and applications. Knowledge\ngraphs are sources of structured information that enable data visualization, data discovery, insights, and\ndownstream machine-learning tasks. Knowledge graphs extracted from published scientific literature covering\nbroad materials science domains [58] as well as more-focused domains such as polymer nanocomposites [59]\nempower material scientists to discover new concepts and accelerate research. Until recently, capturing\ncomplex and hierarchical relationships for a knowledge graph within the materials science literature was a\ntime-consuming effort, often spanning multi-disciplinary collaborations and many Ph.D. years. By leveraging\nzero to few-shot training and pre-trained LLMs, it is now possible to rapidly extract complex scientific entities\nwith minimal technical expertise [58, 60, 61]. We envision that knowledge graphs built by LLMs based on\nscientific publications can offer a concise and visual means to launch a literature review.\nTo demonstrate a proof of concept of a zero-shot entity and relationship extraction, we identified 200\nabstracts on polymer-nanocomposite materials for which detailed structured information was already avail-\nable [62]. Each abstract was fed as a prompt to GPT-3.5-turbo, a language model powering the popular\nChatGPT web application by OpenAI. The instructions in our prompt consisted of an example JSON con-\ntaining high-level schema and information on possible entities and pairwise relationships. The nodes and\nrelationships in the output JSON response were then stored in a neo4j graph database using Cypher, a\ngraph query language (Figure 12). [57] The zero-shot capabilities of the model allowed the specification of\nan arbitrary entity and relationship types depending upon the information contained in the text. Given\nthat this required a change in the neo4j pipeline every time the prompt changed, we found it necessary to\nconstrain the JSON schema to a standard format.\nWhile large language models on their own are prone to hallucinations, leveraging them with guidance to\ncreate structured databases empowers chemists/materials scientists with no expertise in natural language\nprocessing to search and build on existing knowledge leading to new insights. The speed at which LLMs\ncan create structured graphs dramatically exceeds the years required for humans to manually curate data\ninto existing knowledge graphs. Access to structured databases will accelerate the pace of data-driven\nmaterial science research, synthesizing details embedded in dispersed scientific publications. Additionally,\nother scientific fields could benefit from a similar use of LLMs to extract entities and relationships to build\nknowledge graphs.\nOwing to the non-deterministic nature of LLMs, we found that the output response would vary even when\nthe same prompt was provided. An instruction constraining the JSON schema minimized the variability. A\nsystematic study comparing different foundation models, prompt techniques (zero-shot, one-shot, few-shot),\nprompt chaining, and the role of fine-tuning is needed to evaluate the precision and recall of extracted entities\n28\nand relationships. Notably, pairwise links between the nodes are not often enough to model the complex\nnature of materials requiring improvement in the input schema.\nOne sentence summaries\na. Problem/Task Extraction of entities and their relationships from text.\nb. Approach Prompting of GPT-3.5-turbo prompted with abstract and example JSON and the task to\nextract entities and their relationships in a structure as provided in the example.\nc. Results and Impact The approach can successfully create meaningful JSON data structures with\nextracted entities and their relationships for hundreds of abstracts.\nd. Challenges and Future Work The non-deterministic behavior of LLMs can lead to variability and\nfragile behavior. To better understand this as well as the performance of this approach, more systematic\nbenchmarking is needed.\n29\nB. Extracting Structured Data from Free-form Organic Synthesis Text\nFigure 13. The Organic Synthesis Parser interface. The top part shows text describing an organic reaction ( https:\n//open-reaction-database.org/client/id/ord-1f99b308e17340cb8e0e3080c270fd08 ), which the finetuned LLM\nconverts into structured JSON (bottom). A demo application can be found at https://qai222.github.io/LLM_\norganic_synthesis/.\na. Problem As data-driven approaches and machine learning (ML) techniques gain traction in the field of\norganic chemistry and its various subfields, it is becoming clear that, as most data in chemistry is represented\nby unstructured text, the predictive power of these approaches is limited by the lack of structured, well-\ncurated data. Due to the large corpus of organic chemistry literature, manual conversion from unstructured\ntext to structured data is unrealistic, making software tools for this task necessary to improve or enable\ndownstream applications, such as reaction prediction and condition recommendation.\nb. Solution In this project, we leverage the power of fine-tuned LLMs to extract reactant information\nfrom organic synthesis text to structured data. 350 reaction entries were randomly selected from the Open\nReaction Database (ORD) [63]. The field of reaction.notes.procedure details is used as the input\n(prompt), and the field of reaction.inputs is used as the output (completion). 300 of these prompt-\ncompletion pairs were used to fine-tune a GPT-3 (OpenAI Davinci) model using the OpenAI command\nline interface (version 0.27.2), and the rest were used for evaluation. In addition to this, we also explored\nfine-tuning the Alpaca-LoRA model [16, 64, 65] for this task. All data and scripts used in this project are\navailable in the GitHub repository.\nc. Results and Discussion Surprisingly, the pre-trained language model (OpenAI Davinci), fine-tuned\nwith only 300 prompt-completion pairs, is capable of generating valid JSON complying with the ORD data\nmodel. For the 50 prompt-completion pairs in evaluation, 93 % of the components in reaction inputs were\ncorrectly extracted from the free text reaction description by the GPT-3 based model. The model also\nassociates existing properties, such as volume or mass used in the reaction, to these components. In addition\nto recognizing in-text chemical entities (such as molecule names), as shown in Figure 13, tokens referencing\nexternal chemical entities (compound numbers) can also be captured by the model. On the other hand,\nwhile completing the prompts with extracted chemical information, the fine-tuned Alpaca-LoRA model was\nunable to properly construct a valid JSON complying with the ORD data model.\n30\nDespite these encouraging preliminary results, there are still challenges to a robust synthesis text parser.\nOne of them is the ambiguous and often artificial boundary between descriptions of reactions and workups,\nwhich leads to misplaced chemical entities in the structured data, e.g., a solvent used in the extraction of\nproducts is instead labeled as a reaction solvent. The aforementioned external reference problem, where a\ncompound number in the procedure is only explicitly identified in an earlier section of the manuscript, can\nonly be solved by prompting the LLM with multiple paragraphs or even the entire document, adding more\nirrelevant tokens to the prompt. It is also important to prevent the LLM from “auto-completing” extracted\nnamed entities with information outside the prompt, e.g., the chemical is extracted as “sodium chloride” in\nthe completion while it is only specified as “chloride” in the prompt.\nOne sentence summaries\nd. Problem/Task Extraction of structured reaction condition and procedure data from text.\ne. Approach Fine-tuning of LLMs on hundreds of prompt (unstructured text)- completion (extracted\nstructured data) pairs.\nf. Results and Impact OpenAI’s davinci model can extract the relevant data with a success rate of 93 %.\ng. Challenges and Future Work Parameter efficient fine-tuning could not match the performance of\nOpenAI’s models. In addition, there are instances in which the LLM goes beyond the specified tasks (e.g.,\nmodifies/“autocompletes”) extracted entries, which can lead to fragile systems.\n31\nC. TableToJson: Extracting structured information from tables in scientific papers\nMuch of the scientific information published in research articles is presented in an unstructured format,\nprimarily as free text, making it a difficult input for computational processing. However, relevant infor-\nmation in scientific literature is not only found in text form. Tables are commonly employed in scientific\narticles, e.g., to collect precursors and raw materials’ characteristics, synthesis conditions, synthesized ma-\nterials’ properties, or chemical process results. Converting this information into a structured data format\nis usually a manual time-consuming and tedious task. Neural-network-based table extraction methods and\noptical character recognition (OCR) [66], which can convert typed, handwritten, or printed documents into\nmachine-encoded text, can be used to extract information from tables in PDF files. However, it is often\nnot straightforward to extract the data in the desired structured format. Nonetheless, structured data is\nessential for creating databases that aggregate research results, and enable data integration, comparison,\nand analysis.\nIn this context, JSON is a widely adopted structured data format due to its simplicity, flexibility and com-\npatibility with different programming languages and systems. However, obtaining structured data following a\nspecific JSON schema with models can be challenging. The generated JSON needs to be syntactically correct\nand conform to a schema that defines the JSON’s structure. Models typically do not provide structured out-\nput that perfectly matches the desired JSON schema. Some manual post-processing or data transformation\nis often necessary to map the extracted information to the appropriate schema fields.\nIn this work, we have studied two approaches to generate structured JSON from data contained in tables\nof scientific papers focused on different research topics within the field of chemistry [67–73]. The Python\njson module was used to parse JSON data and validate the outputs.\nAs a first approach, the OpenAI text-davinci-003 model was used to generate structured JSON from\ndata in tables. The input to the LLM is the HyperText Markup Language (HTML) code of the table,\nobtained directly from the digital object identifier (DOI) of the article using the Python selenium library,\nwhile the output of the model is the data extracted in JSON form (Figure 14). The OpenAI text-curie-001\nmodel, although not tested in this work, can also be utilized if the number of input tokens, considering both\nthe HTML text of the table and the schema, meets the requirements of this model (m´ aximum 2049 input\ntokens, compared to 4097 for text-davinci-003).\nThe use of the OpenAI model to generate structured JSON was compared with a second approach, i.e., the\nuse of jsonformer (https://github.com/1rgs/jsonformer), which implements a data processing pipeline\nthat combines the model generation with appropriate data transformation. This method introduces an\nefficient way to generate structured JSON using LLMs by generating only the content tokens and filling in\nthe fixed tokens. This avoids generating a complete JSON string and parsing it. This approach ensures that\nthe produced JSON is always syntactically correct and aligns with the specified schema. [74]\nFigure 14. TableToJson. Extraction of structured information from scientific data in tables using LLMs. The input\nto the LLM model is the HTML code of a table contained in a scientific paper. The output of the LLM model is data\nstructured in JSON form. Results can be visualized in this demo app: https://vgvinter-tabletojson-app-kt5aiv.\nstreamlit.app/.\nIn our first approach, we directly asked the OpenAI text-davinci-003 model to generate a JSON object\naccording to a desired JSON schema provided in the model prompt. The table content was also included in\n32\nthe prompt as HTML code. The accuracy in the prediction, calculated as the percentage of schema values\ngenerated correctly, is shown in Figure 15. In all examples, the OpenAI model was queried with a simple\nprompt, and it correctly extracted all the data in the table and inserted every value into the corresponding\nposition in the schema, with 100 % accuracy, providing as output a JSON object. This model also correctly\ngenerated both string and number values according to the type assigned in the schema. However, in two\nof the examples, the OpenAI model did not generate the JSON object name specified in the schema when\nthe corresponding name was not found in the table, generating only the list of components. This was solved\nby modifying the object name in the schema to a term that more closely aligned with the content of the\ntable. It appears that when the model could not establish a clear relationship between the provided name\nand the table content, it disregards that part of the schema during generation. These results indicate that\nthe OpenAI text-davinci-003 model is able to convert scientific data from tables of research papers to a\nstructured format following the approach used in this work, where the desired JSON schema was included\nin the model prompt. Nevertheless, the model retains a certain degree of freedom to modify the requested\nscheme if it considers that something may be wrong.\nFigure 15. TableToJson. Results of the structured JSON generation of tables contained in scientific articles. Two\napproaches are compared: (i) the use of an OpenAI model prompted with the desired JSON schema, and (ii) the use\nof an OpenAI model together with jsonformer.\nThe second approach used to generate structured information was a version of the jsonformer approach\nadapted for use with OpenAI LLMs ( https://github.com/martinezpl/jsonformer/tree/add-openai),\nwith the implementation of the inclusion of the table text as an input parameter to thejsonformer function.\n33\nDetection of strings indicating null values was also added when the schema type is number, as “nan”, “NaN”,\n“NA”, and “NAN” entries are common in research data tables. The OpenAI text-davinci-003 model was\nused. In this case, the model was prompted with the desired JSON schema and the HTML code of the\nstudied table. Jsonformer reads the keys from the JSON schema and only delegates the generation of the\nvalue tokens to the language model, ensuring that a valid JSON is generated by the LLM model.\nFor this approach, the accuracy in the prediction is also shown in Figure 15. The use of the OpenAI\ntext-davinci-003 model together with jsonformer generated valid JSON objects with 100% accuracy for\nmost of the tables evaluated using a simple prompt. Figure 16 shows the results of one of the examples\nstudied, where using a simple descriptive prompt denoting the type of input text, this approach correctly\ngenerated structured data JSON from a table with a complex header. However, it was detected that when\nthe values to be generated contain special characters or specific texts, a more detailed prompt with some\nsimple examples, but without finetuning, can be necessary to provide good results, as shown in Figure 17\nfor a special numeric notation that included power numbers.\nFigure 16. TableToJson. Structured JSON generation of tables contained in scientific articles using a prompt with\na simple description of the type of input text. One example is shown for a table that contains data on properties of\nbiomass materials [71].\nAs shown in Figure 15, in one of these examples, an accuracy of 94 % was obtained from a table containing\na few catalyst names that included the “-” character, and those values were erroneously generated. In\nanother example, an accuracy of 80 % was initially obtained due to errors in the generation of numbers with\npowers (e.g., 9.161 × 104), which could be solved by adding an explanation in the prompt: \"if you find\nnumbers as 1.025 × 10<sup>3</sup>, this means 1.025e-3\", increasing the accuracy to 100 %.\nNext, a table with more complex content (long molecule names, hyphens, power numbers, subscripts, and\nsuperscripts. . . ) was selected (Figure 15), resulting in an accuracy of 46% in the JSON generation, meaning\nthat only 46% of the schema values were correctly generated. The erroneous generation of long formula or\nmolecule names with a mixture of letters and numbers as subscripts could be solved by increasing the value\nof the max string token length argument of the jsonformer function to get a longer response where the\nend of the string can be detected more easily, which increased the accuracy to 60 %. Jsonformer also showed\nsome issues in this example in generating power numbers, which are represented as 10<sup>−n</sup> in\nthe input HTML text. As mentioned above, this was solved by adding a specific explanation in the prompt,\nincreasing the accuracy to 86%. A specific explanation was also included in the prompt to address the\nissues related to the presence of hyphens in the text. Still, this problem could not be solved systematically,\nand the resulting accuracy varied between 86 % and 100 % for several JSON generation attempts. In this\nparticular case, the generated value provided by the model included Unicode text instead of the “-” character\n(and usually several “\\” characters). An instruction to \"decode Unicode characters in your response\"\n34\nwas then included in the prompt. Although this solution sometimes yielded satisfactory results, it did not\nsystematically guarantee correct output. These results indicate that the OpenAI model combined with\njsonformer can provide wrong outputs when the values to be generated contain some special characters,\nsuch as the “-” character in this example. This issue requires further investigation to be improved.\nFigure 17. TableToJson. Structured JSON generation of a table contained in a scientific article using a standard\nprompt and a prompt with a few simple examples of the special numeric notation found in some of the cells of the\ninput table [72].\nLastly, for one of the examples, a test was performed by providing a wrong schema to the model (Figure 15).\nIn this case, as expected, jsonformer inserted the values contained in the table into the given wrong schema\nin a more or less ordered fashion, generating an invalid output. However, the OpenAI model created a new\nschema according to the table structure and headers, providing a valid result, and confirming its freedom to\ndecide what may be wrong with the user’s query. An example of these results is shown in Figure 18.\nThe two approaches used in this work showed a good performance in the generation of JSON format when\nthe data contained in the table are regular strings or numbers, with an accuracy of 100 % in most of the\nexamples. The results of this work show that, although the OpenAI text-davinci-003 is able to easily\nextract structured information from tables and give a valid JSON output, this approach cannot guarantee\nthat the outputs will always follow a specific schema. On the other hand, although jsonformer may present\nproblems when special characters need to be generated, some of these issues have been solved with careful\nprompting, and others could probably be solved with further research. It can be concluded that jsonformer\ncan be a powerful tool for the generation of structured data from unstructured information in most tables,\nensuring the generation of valid JSON syntax as the output of LLMs that always complies with the provided\nschema. The use of jsonformer could facilitate and promote the creation of databases and datasets for\nnumerous topics within the field of chemistry, especially in experimental domains, where the availability of\nstructured data is very scarce.\nOne sentence summaries\na. Problem/Task Extracting structured data in a JSON-schema-compliant form from HTML tables.\n35\nFigure 18. TableToJson. Results of the structured JSON generation of a table after providing the model with a\nwrong schema. The output generated using the OpenAI model together with jsonformer is shown on the left (values\nin the table are inserted in the provided wrong schema), while the output generated using directly the OpenAI model\nis shown on the right (a new schema is created following the table content).\nb. Approach Two approaches were compared: Direct prompting of OpenAI’s text-davinci-003 model\nwith the input table and the JSON schema, as well as the Jsonformer approach, which only samples from\na subset of tokens in field-wise generation steps.\nc. Results and Impact Both approaches can extract data in schema-compliant from tables with high\nsuccess rates. Due to hard-coded decoding rules, Jsonformer failed in some cases.\nd. Challenges and Future Work While the Jsonformer approach can guarantee valid syntax, it can fail\nin cases that were not considered in the development of the decoding rules. Hence, future work is needed\nfor increasing the general applicability of constrained decoding strategies.\n36\nD. AbstractToTitle & TitleToAbstract: text summarization and text generation\n1. Problem\nText summarization and text generation are some of most the common tasks in natural language processing\n(NLP). Often it is tricky to obtain well-defined and curated datasets for these tasks. Also, evaluating the\nperformance of an NLP model is challenging because there is no unique way to summarize and generate text.\nLuckily, there are many publicly available manuscripts for chemistry and materials science in open access\nplatforms such as arXiv and PubChem. These datasets can be used along with LLMs to solve problems such\nas: 1) given title of the article; generate an abstract, 2) given an abstract; generate a title, which should be\nsimilar to the one available in the literature. Such models can greatly help in technical writing, especially\nwith a human expert in the loop.\n2. Solution\nThe above challenging tasks require an organized infrastructure for curated data and tools. JARVIS-\nChemNLP [75] is an integrated library for materials chemistry text data for NLP tasks such as text classifi-\ncation, token classification, abstractive summarization, text generation, and integrating with existing DFT\ndatabases. ChemNLP uses transformer models to generate titles from abstracts and vice versa for arXiv\ncondensed matter category articles.\nThere is no unique approach for both tasks. Nevertheless, highly qualified scientists and engineers generate\nsuch abstracts and titles and can act as a valuable benchmark to evaluate model performance. Moreover,\ndeveloping metrics for text generation is a difficult task. Here, for the sake of simplicity, we choose the Recall-\nOriented Understudy for Gisting Evaluation (ROUGE) metrics for evaluating the model performance.\nChemNLP uses models such as a pre-trained Text-to-Text Transfer Transformer (T5) developed by Google\nfor text summarization. The pre-trained model is further fine-tuned to produce summaries of abstracts and\nanalyze the performance by analyzing its closeness to the title of the given paper.\nFor the text generation, ChemNLP fine-tunes LLMs such as the pre-trained GPT-2-medium model from\nthe HuggingFace library.\nFor these tasks, the community can contribute their models on a benchmarking platform called the\nJARVIS-Leaderboard (https://pages.nist.gov/jarvis_leaderboard/). Specifically, the TextGen task\nis available at: https://pages.nist.gov/jarvis_leaderboard/AI/TextSummary/arxiv_summary_text/\nand TextSummary task is available at https://pages.nist.gov/jarvis_leaderboard/AI/TextGen/\narxiv_gen_text/\n3. Example\nTitle to Abstract example for cond-mat/0105402. [76]\nQuestion\nMgB2 under pressure: phonon calculations, Raman spectroscopy, and optical reflectance can be\ndescribed as\nFine-tuned GPT-2-medium model output\nThe amplitude of phonon vibrations in a material exhibiting an unconventional lattice structure has\nbeen measured in the low pressure region of the granular MgB2 phase. The peak in the high pressure\nregion is the first measurement of phonon amplitude ever presented in a granular superconducting\nmaterial, and it indicates a potential source of superconductivity. Superconducting Transition from\nFluctuations to Brillouin T-Wings in CeFo Josephson Junctions can be described as We report\nelectronic and numerical calculations for solving the electron-wave (E-W) conduction spectra of\na quasi-two-dimensional superconducting monolith CeFo Josephson junctions: The amplitude of\n37\nphonon vibrations in the low pressure region (KPSM), and in the high pressure region of the\nsuperconducting density wave (SDW) densities, are used to understand the superconductivity.\nActual abstract\nThe effect of pressure on optical phonon frequencies of MgB 2 has been calculated using the frozen-\nphonon approach based on a pseudopotential method. Gruneisen parameters of the harmonic mode\nfrequencies are reported for the high-frequency zone-center E2g and B1g and the zone-boundary\nE2u and B2u modes at A. Anharmonic effects of phonon frequencies and the implications of the\ncalculated phonon frequency shifts for the pressure dependence of the superconducting transition\ntemperature of MgB 2 are discussed. Also reported are Raman and optical reflectance spectra of\nMgB2 measured at high pressures. The experimental observations in combination with calculated\nresults indicate that broad spectral features we observed in the Raman spectra at frequencies\nbetween 500 and 900 cm −1 cannot be attributed to first-order scattering by zone-center modes,\nbut originate in part from a chemical species other than MgB 2 at the sample surface and in part\nfrom a maximum in the MgB2 phonon density of states. Low-temperature Raman spectra taken at\nambient pressure showed increased scattering intensity in the region below 300 cm −1.\nInterestingly, the generated abstract contains grammatically and syntactically incorrect sentences. We\nsuspect that this is due to our use of a small, outdated, base model. However, more systematic analysis will\nneed to be performed in future work.\nOne sentence summaries\na. Problem/Task Text summarization and generation, in specific, a summary of an abstract into a title\nand generation of an abstract conditioned on a title.\nb. Approach Fine-tuning of transformer models such as T-5 and GPT-2 on data from arXiv.\nc. Results and Impact Initial exploration indicates that transformer models might be suitable for this\ntask.\nd. Challenges and Future Work More systematic analysis, including rating of the generated titles and\nabstracts by domain experts is required to identify the limitations of this approach.\n38\nIV. Education\nA. i-Digest\na. Problem Over the last few years, especially during the Covid period, most of us had to switch to the\nonline mode of working in our day-to-day jobs. And even today, the online mode of working has, to some\nextent, stayed on as it turned out to be convenient for both employers and employees. One clear example can\nbe found in the field of education, where the use of video lectures became the norm for teaching students in\nuniversities and schools. Likewise, podcasts and three-minute thesis videos, which communicate important\nscientific information to society at large, have grown tremendously [77, 78]. This has led to a situation where,\nat present, we have an enormous amount of important scientific information stored in the form of videos and\naudio all over the internet. A current challenge is to summarize and make use of this knowledge efficiently.\nSome efforts in this direction have been made by using AI Youtube summarizers and QnA Bots [79]. We\nwould like to build upon such efforts and create a tool for the field of education.\nb. Solution We present a tool that self-guides students and other users toward a better understanding\nof the content of a video lecture or a podcast. In order to accomplish this, we used publicly available\nLLMs like Open AI’s Whisper [80] and GPT-3.5-turbo model. All the user needs to do is provide a link to\nthe lecture video or audio file. After only a short time, the overview page shows some technical keywords\non which the video is based, a short but comprehensive summary, and some questions for the user to\nassess his or her understanding of the concepts discussed in the video/audio (Figure 19). Additionally, for\nchemistry enthusiasts, if some chemical elements/molecules are discussed in the content, we link them to\nonline databases. At the backend, we first convert the video to audio using Pytube (In the case of a podcast,\nthis step is not needed). Then we use the Whisper model to transcribe the audio to text. Next, we make\nuse of the OpenAI GPT-3.5-turbo model to obtain a short summary and a set of questions based on the\ntext. Finally, we extract the name of chemical elements/molecules and list the PubChem database entry for\nthat element/molecule on the overview page. [81–83] The web interface was made using the open-source app\nframework Streamlit [84].\nKey Words\nSummary\nThe lecture is about the Monte \nCarlo simulations and its \nalgorithm. The speaker \ndiscusses …\nQuestions\n1) Could you explain the \nacceptance rule?\n2) Why is it important to \nselect a particle at random \nfor displacement?\n3) …\nTranscript\nChemicals\nPubchem Search\nLarge Language \nModel\n“Come up with \nquestions”\n“Give a summary”\n“Suggest three \nkeywords”\n1) Monte Carlo \nSimulation\n2) Metropolis algorithm\n3) Importance \nSampling\nFigure 19. A schematic of the i-digest interface. On providing a link to an online video or audio, i-digest generates\nsome technical keywords, a short but comprehensive summary, and a list of questions based on the content in the\nvideo/audio. Additionally, chemicals discussed in the content are linked to online databases such as PubChem.\nc. Impact We strongly believe that extracting important scientific information in terms of short lecture\nnotes and questions would help to push forward the field of education towards creating and using resources\nmore efficiently. Moreover, by providing additional links to resources, e.g., databases, journals, and books,\n39\nwe provide an opportunity for the user to go beyond the content of the lecture and spark interest in a more\ndetailed understanding of the topic. Specifically, this would help researchers/teachers/professors to create\nnew course content or to update/modify already available content. In general, our tool covers a broad range\nof users, from the youngest learner to the chemistry novice who wants to kickstart his research, all the way\nto professors, course creators, and lifetime learners.\nd. Lessons learned Working together with colleagues can be fun and enriching and often help to solve\nbig problems. This hackathon taught us that even in one day, coming together can help achieve something\nsignificant.\nOne sentence summaries\ne. Problem/Task Provide students with automatically generated active learning tasks for lecture record-\nings.\nf. Approach Transcription of videos using OpenAI’s Whisper model, prompting of OpenAI’s GPT-3.5-\nturbo model to produce a short summary and questions based on the transcript, as well as to extract mentions\nof chemicals in the text.\ng. Results and Impact The system can transcribe the text, generate meaningful questions, and success-\nfully extract mentions of chemicals.\nh. Challenges and Future Work It is difficult to systematically evaluate the performance of this system\ndue to the lack of suitable benchmarks/eval. An obvious extension of this approach is to condition it on\nfurther material (e.g., lecture notes and books). In addition, one might automatically score the answers and\nshow them at the beginning and at the end of the video. This would allow us to evaluate the learning of the\nstudents and to guide them to the relevant material in case a question was not answered correctly.\n40\nV. Meta analysis of the workshop contributions\nWe have a female/male ratio of about 30 % among the workshop participants who co-authored this paper.\nWe have participants from 22 different institutions in 8 countries.\nMost teams combine expertise from different institutions (Figure 21), in several cases beyond academia\n(Figure 22). Around 20 % of the teams are international, with participants from two countries (Figure 23).\n5 10 15 20\nNumber of participants\nFigure 20. Worldmap (Robin projection) with the number of participants shown in color.\n1 2 3 4 5\nNumber of unique affiliations\n0\n2\n4\n6\n8Number of teams\nFigure 21. Histogram of the number of unique affiliations per team.\n41\nno academia only academia mixed\n0\n2\n4\n6\n8Number of teams\nFigure 22. Number of teams with participants only from academia or academia and industry/nonprofit, respectively.\nWe counted national labs as “academia”.\n1 2\nNumber of unique countries\n0\n2\n4\n6\n8\n10Number of teams\nFigure 23. Histogram of the number of unique countries per team.\n42\n[1] Ward, L.; Blaiszik, B.; Foster, I.; Assary, R. S.; Narayanan, B.; Curtiss, L. Machine learning prediction of accurate\natomization energies of organic molecules from low-fidelity quantum chemical calculations.MRS Commun. 2019,\n9, 891–899.\n[2] Curtiss, L. A.; Redfern, P. C.; Raghavachari, K. Gaussian-4 theory using reduced order perturbation theory. J.\nChem. Phys. 2007, 127, 124105.\n[3] Ramakrishnan, R.; Dral, P. O.; Rupp, M.; Von Lilienfeld, O. A. Quantum chemistry structures and properties\nof 134 kilo molecules. Sci. Data 2014, 1, 1–7.\n[4] Narayanan, B.; Redfern, P. C.; Assary, R. S.; Curtiss, L. A. Accurate quantum chemical energies for 133000\norganic molecules. Chem. Sci. 2019, 10, 7449–7455.\n[5] Weininger, D. SMILES, a chemical language and information system. 1. Introduction to methodology and en-\ncoding rules. J. Chem. Inf. Comput. Sci. 1988, 28, 31–36.\n[6] Krenn, M.; H¨ ase, F.; Nigam, A.; Friederich, P.; Aspuru-Guzik, A. Self-referencing embedded strings (SELFIES):\nA 100% robust molecular string representation. Mach. Learn.: Sci. Technol. 2020, 1, 045024.\n[7] Krenn, M.; Ai, Q.; Barthel, S.; Carson, N.; Frei, A.; Frey, N. C.; Friederich, P.; Gaudin, T.; Gayle, A. A.;\nJablonka, K. M., et al. SELFIES and the future of molecular string representations. Patterns 2022, 3, 100588.\n[8] Jablonka, K. M.; Schwaller, P.; Ortega-Guerrero, A.; Smit, B. Is GPT-3 all you need for low-data discovery in\nchemistry? ChemRxiv preprint 10.26434/chemrxiv-2023-fw8n4 2023,\n[9] Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.;\nSastry, G.; Askell, A., et al. Language models are few-shot learners. Advances in neural information processing\nsystems 2020, 33, 1877–1901.\n[10] Ramakrishnan, R.; Dral, P. O.; Rupp, M.; Von Lilienfeld, O. A. Big data meets quantum chemistry approxima-\ntions: the ∆-machine learning approach. J. Chem. Theory Comput. 2015, 11, 2087–2096.\n[11] Gupta, A. K.; Raghavachari, K. Three-Dimensional Convolutional Neural Networks Utilizing Molecular Topo-\nlogical Features for Accurate Atomization Energy Predictions. J. Chem. Theory Comput. 2022, 18, 2132–2143.\n[12] Mangrulkar, S.; Gugger, S.; Debut, L.; Belkada, Y.; Paul, S. PEFT: State-of-the-art Parameter-Efficient Fine-\nTuning methods. https://github.com/huggingface/peft, 2022.\n[13] Hu, E. J.; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.; Wang, L.; Chen, W. LoRA: Low-Rank Adaptation\nof Large Language Models. arXiv preprint: Arxiv-2106.09685 2021,\n[14] Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; Sutskever, I. Language Models are Unsupervised Mul-\ntitask Learners. 2019, https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_\nare_unsupervised_multitask_learners.pdf.\n[15] Kojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y.; Iwasawa, Y. Large Language Models are Zero-Shot Reasoners.\n2023.\n[16] Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux, M.-A.; Lacroix, T.; Rozi` ere, B.; Goyal, N.; Ham-\nbro, E.; Azhar, F., et al. Llama: Open and efficient foundation language models. arXiv preprint:2302.13971\n2023,\n[17] Lin, Z.; Akin, H.; Rao, R.; Hie, B.; Zhu, Z.; Lu, W.; Smetanin, N.; Verkuil, R.; Kabeli, O.; Shmueli, Y.,\net al. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science 2023, 379,\n1123–1130.\n[18] Andrew, R. Global Co2 Emissions From Cement Production. 2017; https://zenodo.org/record/831455.\n[19] Lookman, T.; Balachandran, P. V.; Xue, D.; Yuan, R. Active learning in materials science with emphasis on\nadaptive sampling using uncertainties for targeted design. npj Comput. Mater. 2019, 5 .\n[20] V¨ olker, C.; Firdous, R.; Stephan, D.; Kruschwitz, S. Sequential learning to accelerate discovery of alkali-activated\nbinders. Journal of Materials Science 2021, 56, 15859–15881.\n[21] V¨ olker, C.; Benjami Moreno Torres,; Tehseen Rug,; Firdous, R.; Ghezal Ahmad,; Zia, J.; L¨ uders, S.;\nScaffino, H. L.; H¨ opler, M.; B¨ ohmer, F.; Pfaff, M.; Stephan, D.; Kruschwitz, S. Green building materials: a\nnew frontier in data-driven sustainable concrete design. Preprint 10.13140/RG.2.2.29079.85925. 2023.\n[22] Ramos, M. C.; Michtavy, S. S.; Porosoff, M. D.; White, A. D. Bayesian Optimization of Catalysts With In-context\nLearning. arXiv preprint: Arxiv-2304.05341 2023,\n[23] Rao, G. M.; Rao, T. D. G. A quantitative method of approach in designing the mix proportions of fly ash and\nGGBS-based geopolymer concrete. Aust. J. Civ. Eng. 2018, 16, 53–63.\n[24] OpenAI, Text-davinci-003. https://platform.openai.com/models/text-davinci-003.\n[25] Bousquet, A. lolopy. https://pypi.org/project/lolopy/, 2017; Accessed: 2023-02-27.\n[26] Heinisch, O. Steel, R. G. D., and J. H. Torrie: Principles and Procedures of Statistics. (With special Reference\nto the Biological Sciences.) McGraw-Hill Book Company, New York, Toronto, London 1960, 481 S., 15 Abb. 81\ns 6 d. Biometrische Zeitschrift 1962, 4, 207–208.\n[27] Dinh, T.; Zeng, Y.; Zhang, R.; Lin, Z.; Gira, M.; Rajput, S.; Sohn, J.-Y.; Papailiopoulos, D.; Lee, K. LIFT:\nLanguage-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks. arXiv preprint: Arxiv-2206.06565.\n2022.\n43\n[28] Herhold, P.; Farnworth, E. The Net-Zero Challenge: Fast-Forward to Decisive Climate Action. World Economic\nForum, available at: https://www3. weforum. org/docs/WEF The Net Zero Challenge. pdf (accessed 4 October\n2021). 2020.\n[29] Hong, Z.; Ajith, A.; Pauloski, G.; Duede, E.; Malamud, C.; Magoulas, R.; Chard, K.; Foster, I. ScholarBERT:\nBigger is Not Always Better. arXiv preprint: Arxiv-2205.11342. 2022.\n[30] Kim, S.; Thiessen, P. A.; Bolton, E. E.; Chen, J.; Fu, G.; Gindulyte, A.; Han, L.; He, J.; He, S.; Shoemaker, B. A.,\net al. PubChem substance and compound databases. Nucleic acids research 2016, 44, D1202–D1213.\n[31] Dai, H. et al. AugGPT: Leveraging ChatGPT for Text Data Augmentation. arXiv preprint: Arxiv-2302.13007.\n2023.\n[32] Wolf, T. et al. Transformers: State-of-the-Art Natural Language Processing. Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Processing: System Demonstrations. Online, 2020; pp 38–45.\n[33] Pedregosa, F. et al. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 2011, 12,\n2825–2830.\n[34] Rajpurkar, P.; Jia, R.; Liang, P. Know What You Don’t Know: Unanswerable Questions for SQuAD. 2018,\n[35] Zhang, J.; Chang, W.-C.; Yu, H.-F.; Dhillon, I. Fast multi-resolution transformer fine-tuning for extreme multi-\nlabel text classification. Adv. Neural Inf. Process. Syst. 2021, 34, 7267–7280.\n[36] White, A. D.; Hocky, G. M.; Gandhi, H. A.; Ansari, M.; Cox, S.; Wellawatte, G. P.; Sasmal, S.; Yang, Z.;\nLiu, K.; Singh, Y., et al. Assessment of chemistry knowledge in large language models that generate code. Digital\nDiscovery 2023,\n[37] Schwaller, P.; Laino, T.; Gaudin, T.; Bolgar, P.; Hunter, C. A.; Bekas, C.; Lee, A. A. Molecular transformer: A\nmodel for uncertainty-calibrated chemical reaction prediction. ACS Central Science 2019, 5, 1572–1583.\n[38] Schwabe, T.; Grimme, S. Theoretical thermodynamics for large molecules: walking the thin line between accuracy\nand computational cost. Acc. Chem. Res. 2008, 41, 569–579.\n[39] Skyner, R. E.; McDonagh, J. L.; Groom, C. R.; van Mourik, T.; Mitchell, J. B. O. A review of methods for the\ncalculation of solution free energies and the modelling of systems in solution. Phys. Chem. Chem. Phys. 2015,\n17, 6174–6191.\n[40] Schleder, G. R.; Padilha, A. C. M.; Acosta, C. M.; Costa, M.; Fazzio, A. From DFT to machine learning: recent\napproaches to materials science–a review. J. Phys. Mater. 2019, 2, 032001.\n[41] Chase, H. LangChain. 2022; https://github.com/hwchase17/langchain.\n[42] Bran, A. M.; Cox, S.; White, A. D.; Schwaller, P. ChemCrow: Augmenting large-language models with chemistry\ntools. arXiv preprint: Arxiv-2304.05376 2023,\n[43] Jain, A.; Ong, S. P.; Hautier, G.; Chen, W.; Richards, W. D.; Dacek, S.; Cholia, S.; Gunter, D.; Skinner, D.;\nCeder, G.; Persson, K. A. Commentary: The Materials Project: A materials genome approach to accelerating\nmaterials innovation. APL Materials 2013, 1, 011002.\n[44] McDermott, M. J.; Dwaraknath, S. S.; Persson, K. A. A Graph-Based Network for Predicting Chemical Reaction\nPathways in Solid-State Materials Synthesis. Nat. Commun. 2021, 12, 3097.\n[45] Shao, Z.; Gong, Y.; Shen, Y.; Huang, M.; Duan, N.; Chen, W. Synthetic Prompting: Generating Chain-of-\nThought Demonstrations for Large Language Models. 2023,\n[46] Gao, L.; Schulman, J.; Hilton, J. Scaling Laws for Reward Model Overoptimization. ARXIV.ORG 2022,\n[47] Rego, N.; Koes, D. 3Dmol.js: molecular visualization with WebGL. Bioinformatics 2014, 31, 1322–1324.\n[48] Schr¨ odinger, L.; DeLano, W. PyMOL.http://www.pymol.org/pymol.\n[49] Sehnal, D.; Bittrich, S.; Deshpande, M.; Svobodov´ a, R.; Berka, K.; Bazgier, V.; Velankar, S.; Burley, S. K.;\nKoˇ ca, J.; Rose, A. S. Mol∗ Viewer: modern web app for 3D visualization and analysis of large biomolecular\nstructures. Nucleic Acids Res. 2021, 49, W431–W437.\n[50] Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan, K.; Cao, Y. ReAct: Synergizing Reasoning and\nActing in Language Models. arXiv preprint: Arxiv-2210.03629 2023,\n[51] Thompson, A. P.; Aktulga, H. M.; Berger, R.; Bolintineanu, D. S.; Brown, W. M.; Crozier, P. S.; in ’t Veld, P. J.;\nKohlmeyer, A.; Moore, S. G.; Nguyen, T. D.; Shan, R.; Stevens, M. J.; Tranchida, J.; Trott, C.; Plimpton, S. J.\nLAMMPS - a flexible simulation tool for particle-based materials modeling at the atomic, meso, and continuum\nscales. Comp. Phys. Comm. 2022, 271, 108171.\n[52] Abraham, M. J.; Murtola, T.; Schulz, R.; P´ all, S.; Smith, J. C.; Hess, B.; Lindahl, E. GROMACS: High\nperformance molecular simulations through multi-level parallelism from laptops to supercomputers. SoftwareX\n2015, 1-2, 19–25.\n[53] Volk, A. A.; Epps, R. W.; Yonemoto, D. T.; Masters, B. S.; Castellano, F. N.; Reyes, K. G.; Abolhasani, M.\nAlphaFlow: autonomous discovery and optimization of multi-step chemistry using a self-driven fluidic lab guided\nby reinforcement learning. Nat. Commun. 2023, 14, 1403.\n[54] Griffiths, R.-R. et al. GAUCHE: A Library for Gaussian Processes in Chemistry. 2022; http://arxiv.org/abs/\n2212.04450, arXiv:2212.04450 [cond-mat, physics:physics].\n[55] Shields, B. J.; Stevens, J.; Li, J.; Parasram, M.; Damani, F.; Alvarado, J. I. M.; Janey, J. M.; Adams, R. P.;\nDoyle, A. G. Bayesian reaction optimization as a tool for chemical synthesis. Nature 2021, 590, 89–96.\n44\n[56] Rankovi´ c, B.; Griffiths, R.-R.; Moss, H. B.; Schwaller, P. Bayesian optimisation for additive screening and yield\nimprovements in chemical reactions – beyond one-hot encodings. ChemRxiv preprint 10.26434/chemrxiv-2022-\nnll2j. 2022.\n[57] Neo4j, Neo4j - The World’s Leading Graph Database. 2012; http://neo4j.org/.\n[58] Venugopal, V.; Pai, S.; Olivetti, E. MatKG: The Largest Knowledge Graph in Materials Science–Entities, Rela-\ntions, and Link Prediction through Graph Representation Learning. arXiv preprint:2210.17340 2022,\n[59] McCusker, J. P.; Deagen, M.; Fateye, T.; Wallace, A.; Rashid, S. M.; McGuinness, D. L. Creating and Visualizing\nthe Materials Science Knowledge Graph with Whyis. ISWC (Posters/Demos/Industry). 2021.\n[60] Dunn, A.; Dagdelen, J.; Walker, N.; Lee, S.; Rosen, A. S.; Ceder, G.; Persson, K. A.; Jain, A. Structured\ninformation extraction from complex scientific text with fine-tuned large language models.arXiv preprint: Arxiv-\n2212.05238 2022,\n[61] Badhwar, S. Smart Manufacturing - A Case for Creating a Knowledge Network Using Data Mining. 2022.\n[62] McCusker, J. P.; Keshan, N.; Rashid, S.; Deagen, M.; Brinson, C.; McGuinness, D. L. NanoMine: A knowledge\ngraph for nanocomposite materials science. The Semantic Web–ISWC 2020: 19th International Semantic Web\nConference, Athens, Greece, November 2–6, 2020, Proceedings, Part II. 2020; pp 144–159.\n[63] Kearnes, S. M.; Maser, M. R.; Wleklinski, M.; Kast, A.; Doyle, A. G.; Dreher, S. D.; Hawkins, J. M.; Jensen, K. F.;\nColey, C. W. The Open Reaction Database. J. Am. Chem. Soc. 143 , 18820–18826.\n[64] Taori, R.; Gulrajani, I.; Zhang, T.; Dubois, Y.; Li, X.; Guestrin, C.; Liang, P.; Hashimoto, T. B. Stanford Alpaca:\nAn Instruction-following LLaMA model. https://github.com/tatsu-lab/stanford_alpaca, 2023.\n[65] Alpaca-LoRA. https://github.com/tloen/alpaca-lora.\n[66] Colter, Z.; Fayazi, M.; Youbi, Z. B.-E.; Kamp, S.; Yu, S.; Dreslinski, R. Tablext: A combined neural network\nand heuristic based table extractor. Array 2022, 15, 100220.\n[67] Mamaghani, Z. G.; Hawboldt, K. A.; MacQuarrie, S. Adsorption of CO 2 using biochar - Review of the impact\nof gas mixtures and water on adsorption. J. Environ. Chem. Eng. 2023, 11, 109643.\n[68] Peng, Y.; Krungleviciute, V.; Eryazici, I.; Hupp, J. T.; Farha, O. K.; Yildirim, T. Methane Storage in\nMetal–Organic Frameworks: Current Records, Surprise Findings, and Challenges. J. Am. Chem. Soc. 2013,\n135, 11887–11894.\n[69] Sahoo, B.; Pandey, V.; Dogonchi, A.; Mohapatra, P.; Thatoi, D.; Nayak, N.; Nayak, M. A state-of-art review on\n2D material-boosted metal oxide nanoparticle electrodes: Supercapacitor applications. J. Energy Storage 2023,\n65, 107335.\n[70] Suppiah, D. D.; Daud, W. M. A. W.; Johan, M. R. Supported Metal Oxide Catalysts for CO 2 Fischer–Tropsch\nConversion to Liquid Fuels-A Review. Energy Fuels. 2021, 35, 17261–17278.\n[71] Gonz´ alez-V´ azquez, M.; Garc´ ıa, R.; Gil, M.; Pevida, C.; Rubiera, F. Comparison of the gasification performance\nof multiple biomass types in a bubbling fluidized bed. Energy Convers. Manag. 2018, 176, 309–323.\n[72] Mohsin, M.; Farhan, S.; Ahmad, N.; Raza, A. H.; Kayani, Z. N.; Jafri, S. H. M.; Raza, R. The electrochemical\nstudy of NixCe1– x O2– δ electrodes using natural gas as a fuel. New J. Chem. 2023, 47, 8679–8692.\n[73] Kaur, P.; Singh, K. Review of perovskite-structure related cathode materials for solid oxide fuel cells. Ceram.\nInt. 2020, 46, 5521–5535.\n[74] Sengottuvelu, R. jsonformer. https://github.com/1rgs/jsonformer, 2018.\n[75] Choudhary, K.; Kelley, M. L. ChemNLP: A Natural Language Processing based Library for Materials Chemistry\nText Data. arXiv preprint arXiv:2209.08203 2022,\n[76] Kunc, K.; Loa, I.; Syassen, K.; Kremer, R.; Ahn, K. MgB2 under pressure: phonon calculations, Raman spec-\ntroscopy, and optical reflectance. arXiv preprint cond-mat/0105402\n[77] FameLab International — Cheltenham Festivals.https://www.cheltenhamfestivals.com/famelab,last accessed\n2023-05-30.\n[78] MT 180 - My Thesis in 180 Seconds. https://www.epfl.ch/campus/events/events/public-events/\nmy-thesis-in-180-seconds ,last accessed 2023-07-07.\n[79] ClIPDIGEST. https://clipdigest.com/, last accessed 2023-05-30.\n[80] Radford, A.; Kim, J. W.; Xu, T.; Brockman, G.; McLeavey, C.; Sutskever, I. Robust speech recognition via\nlarge-scale weak supervision. arXiv preprint: ArXiv-2212.04356. 2022.\n[81] Kim, S.; Chen, J.; Cheng, T.; Gindulyte, A.; He, J.; He, S.; Li, Q.; Shoemaker, B. A.; Thiessen, P. A.; Yu, B.;\nZaslavsky, L.; Zhang, J.; Bolton, E. E. PubChem 2023 update. Nucleic Acids Res. 2022, 51, D1373–D1380.\n[82] Kim, S.; Chen, J.; Cheng, T.; Gindulyte, A.; He, J.; He, S.; Li, Q.; Shoemaker, B. A.; Thiessen, P. A.; Yu, B.;\nZaslavsky, L.; Zhang, J.; Bolton, E. E. PubChem 2019 update: improved access to chemical data. Nucleic Acids\nRes. 2018, 47, D1102–D1109.\n[83] Kim, S.; Thiessen, P. A.; Cheng, T.; Yu, B.; Bolton, E. E. An update on PUG-REST: RESTful interface for\nprogrammatic access to PubChem. Nucleic Acids Res. 2018, 46, W563–W570.\n[84] Streamlit. https://streamlit.io/.\nAcronyms 45\nAcronyms\nAI: artificial intelligence.\nAPI: application programming interface.\nBO: Bayesian optimization.\nCAS: Chemical Abstract Services.\nCOT: chain of thought.\nDFT: density functional theory.\nDOI: digital object identifier.\nELN: electronic lab notebook.\nGA: genetic algorithm.\nGPR: Gaussian process regression.\nGPT: generative pretrained transformer.\nGUI: graphical user interface.\nHTML: HyperText Markup Language.\nICL: in-context learning.\nID: inverse design.\nInChI: international chemical identifier.\nJSON: JavaScript object notation.\nLIFT: language-interfaced fine-tuning.\nLIMS: laboratory information system.\nLLM: large language model.\nLoRA: low-rank adaptors.\nMAD: median absolute deviation.\nMAE: mean absolute error.\nMAPI: Materials Project API.\nML: machine learning.\nNER: named entity recognition.\nNLM: national library of medicine.\nNLP: natural language processing.\nOCR: optical character recognition.\nAcronyms 46\nORD: Open Reaction Database.\nPDB: protein data bank.\nPEFT: parameter efficient fine-tuning.\nRF: random forest.\nRLHF: reinforcement learning from human feedback.\nROUGE: Recall-Oriented Understudy for Gisting Evaluation.\nSELFIES: self-referencing embedded strings.\nSMILES: simplified molecular-input line-entry system.\nSVM: support vector machine.\nUI: user interface.\n84"
}