{
  "title": "Unlocking language barriers: Assessing pre-trained large language models across multilingual tasks and unveiling the black box with Explainable Artificial Intelligence",
  "url": "https://openalex.org/W4408361331",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2997687734",
      "name": "Muhamet Kastrati",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2044297337",
      "name": "Ali Shariq Imran",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5094004425",
      "name": "Ehtesham Hashmi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A8939579",
      "name": "Zenun Kastrati",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2945788795",
      "name": "Sher Muhammad Daudpota",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1251426306",
      "name": "Marenglen Biba",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6861215664",
    "https://openalex.org/W6839894795",
    "https://openalex.org/W6765372193",
    "https://openalex.org/W4312894902",
    "https://openalex.org/W4387913157",
    "https://openalex.org/W7009752074",
    "https://openalex.org/W6855748278",
    "https://openalex.org/W4389577293",
    "https://openalex.org/W6863262667",
    "https://openalex.org/W6872309245",
    "https://openalex.org/W4402124178",
    "https://openalex.org/W4393170771",
    "https://openalex.org/W1663984431",
    "https://openalex.org/W4283782590",
    "https://openalex.org/W3163548027",
    "https://openalex.org/W4327522548",
    "https://openalex.org/W6862610080",
    "https://openalex.org/W3135313574",
    "https://openalex.org/W4379259169",
    "https://openalex.org/W4391473457",
    "https://openalex.org/W4393028958",
    "https://openalex.org/W6858817873",
    "https://openalex.org/W4401208776",
    "https://openalex.org/W6697146284",
    "https://openalex.org/W6864566207",
    "https://openalex.org/W2805744755",
    "https://openalex.org/W1569507287",
    "https://openalex.org/W2460159515",
    "https://openalex.org/W2278629362",
    "https://openalex.org/W6718766952",
    "https://openalex.org/W6856877756",
    "https://openalex.org/W2952013914",
    "https://openalex.org/W2916132663",
    "https://openalex.org/W2467186984",
    "https://openalex.org/W2891575196",
    "https://openalex.org/W4296976275",
    "https://openalex.org/W6861478013",
    "https://openalex.org/W4226185774",
    "https://openalex.org/W4380536907",
    "https://openalex.org/W2807333695",
    "https://openalex.org/W6796747266",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4392240262",
    "https://openalex.org/W4394828356",
    "https://openalex.org/W2922580172",
    "https://openalex.org/W4383045305",
    "https://openalex.org/W4393054218",
    "https://openalex.org/W4390041933",
    "https://openalex.org/W2963223838",
    "https://openalex.org/W4393095599",
    "https://openalex.org/W4377098551",
    "https://openalex.org/W3174646436",
    "https://openalex.org/W4388335799",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2498967838",
    "https://openalex.org/W4389974721",
    "https://openalex.org/W4402097647",
    "https://openalex.org/W4323570543",
    "https://openalex.org/W3099215402",
    "https://openalex.org/W4380993492",
    "https://openalex.org/W4392822166",
    "https://openalex.org/W4388777264",
    "https://openalex.org/W4285190530",
    "https://openalex.org/W4366733439",
    "https://openalex.org/W4389523957",
    "https://openalex.org/W2890484448",
    "https://openalex.org/W4387799763",
    "https://openalex.org/W4391766565",
    "https://openalex.org/W1853454069"
  ],
  "abstract": "Large Language Models (LLMs) have revolutionized many industrial applications and paved the way for fostering a new research direction in many fields. Conventional Natural Language Processing (NLP) techniques, for instance, are no longer necessary for many text-based tasks, including polarity estimation, sentiment and emotion classification, and hate speech detection. However, training a language model for domain-specific tasks is hugely costly and requires high computational power, thereby restricting its true potential for standard tasks. This study, therefore, provides a comprehensive analysis of the latest pre-trained LLMs for various NLP-related applications without fine-tuning them to evaluate their effectiveness. Five language models are thus employed in this study on six distinct NLP tasks (including emotion recognition, sentiment analysis, hate speech detection, irony detection, offensiveness detection, and stance detection) for 12 languages from low- to medium- and high-resource. Generative Pre-trained Transformer 4 (GPT-4) and Gemini Pro outperform state-of-the-art models, achieving average F1 scores of 70.6% and 68.8% on the Tweet Sentiment Multilingual dataset compared to the state-of-the-art average F1 score of 66.8%. The study further interprets the findings obtained by the LLMs using Explainable Artificial Intelligence (XAI). To the best of our knowledge, it is the first time any study has employed explainability on pre-trained language models.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.9250888824462891
    },
    {
      "name": "Black box",
      "score": 0.7518512010574341
    },
    {
      "name": "Natural language processing",
      "score": 0.557817280292511
    },
    {
      "name": "Language model",
      "score": 0.5383186936378479
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5353456139564514
    },
    {
      "name": "Language barrier",
      "score": 0.42015135288238525
    },
    {
      "name": "Machine learning",
      "score": 0.34585338830947876
    },
    {
      "name": "Data science",
      "score": 0.34055373072624207
    },
    {
      "name": "Linguistics",
      "score": 0.13611912727355957
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}