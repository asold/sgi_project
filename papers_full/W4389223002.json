{
  "title": "Contemporary Approaches in Evolving Language Models",
  "url": "https://openalex.org/W4389223002",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3154845200",
      "name": "Dina Oralbekova",
      "affiliations": [
        "Kazakh Academy of Transport and Communications named after M.Tynyshpaev",
        "Mukhametzhan Tynyshbayev ALT University",
        "Institute of Information and Computational Technologies"
      ]
    },
    {
      "id": "https://openalex.org/A2531157425",
      "name": "Orken Mamyrbayev",
      "affiliations": [
        "Institute of Information and Computational Technologies"
      ]
    },
    {
      "id": "https://openalex.org/A2133622576",
      "name": "Mohamed Othman",
      "affiliations": [
        "Universiti Putra Malaysia"
      ]
    },
    {
      "id": "https://openalex.org/A2572524762",
      "name": "Dinara Kassymova",
      "affiliations": [
        "Kazakh Academy of Transport and Communications named after M.Tynyshpaev",
        "Mukhametzhan Tynyshbayev ALT University"
      ]
    },
    {
      "id": "https://openalex.org/A2893991922",
      "name": "Kuralai Mukhsina",
      "affiliations": [
        "Institute of Information and Computational Technologies"
      ]
    },
    {
      "id": "https://openalex.org/A3154845200",
      "name": "Dina Oralbekova",
      "affiliations": [
        "Mukhametzhan Tynyshbayev ALT University",
        "Kazakh Academy of Transport and Communications named after M.Tynyshpaev",
        "Institute of Information and Computational Technologies"
      ]
    },
    {
      "id": "https://openalex.org/A2531157425",
      "name": "Orken Mamyrbayev",
      "affiliations": [
        "Institute of Information and Computational Technologies"
      ]
    },
    {
      "id": "https://openalex.org/A2133622576",
      "name": "Mohamed Othman",
      "affiliations": [
        "Universiti Putra Malaysia"
      ]
    },
    {
      "id": "https://openalex.org/A2572524762",
      "name": "Dinara Kassymova",
      "affiliations": [
        "Mukhametzhan Tynyshbayev ALT University",
        "Kazakh Academy of Transport and Communications named after M.Tynyshpaev"
      ]
    },
    {
      "id": "https://openalex.org/A2893991922",
      "name": "Kuralai Mukhsina",
      "affiliations": [
        "Institute of Information and Computational Technologies"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2919675873",
    "https://openalex.org/W4283205649",
    "https://openalex.org/W3171460770",
    "https://openalex.org/W3174281149",
    "https://openalex.org/W4385570930",
    "https://openalex.org/W2963586458",
    "https://openalex.org/W3008292207",
    "https://openalex.org/W3203715570",
    "https://openalex.org/W3176574162",
    "https://openalex.org/W4385573321",
    "https://openalex.org/W2125838338",
    "https://openalex.org/W2486026319",
    "https://openalex.org/W4210282224",
    "https://openalex.org/W2321976924",
    "https://openalex.org/W2141599568",
    "https://openalex.org/W2296194829",
    "https://openalex.org/W2889248638",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W3046402235",
    "https://openalex.org/W2798955519",
    "https://openalex.org/W2727582050",
    "https://openalex.org/W7024533168",
    "https://openalex.org/W2779570636",
    "https://openalex.org/W2766979421",
    "https://openalex.org/W2807629530",
    "https://openalex.org/W3003039250",
    "https://openalex.org/W3185451278",
    "https://openalex.org/W4233070218",
    "https://openalex.org/W3175898847",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W2996035354",
    "https://openalex.org/W3176169354",
    "https://openalex.org/W3118942176",
    "https://openalex.org/W6839940056",
    "https://openalex.org/W4385567034",
    "https://openalex.org/W3008110149",
    "https://openalex.org/W2471147443",
    "https://openalex.org/W4311212904",
    "https://openalex.org/W4281756552",
    "https://openalex.org/W3120715951",
    "https://openalex.org/W4285299226",
    "https://openalex.org/W7038708449",
    "https://openalex.org/W3041263301",
    "https://openalex.org/W3098466758",
    "https://openalex.org/W3039695075",
    "https://openalex.org/W4365512576",
    "https://openalex.org/W3119546299",
    "https://openalex.org/W3153540814",
    "https://openalex.org/W4229506649",
    "https://openalex.org/W4385564953",
    "https://openalex.org/W4385570854",
    "https://openalex.org/W4389519817",
    "https://openalex.org/W6853920016",
    "https://openalex.org/W4386286066",
    "https://openalex.org/W2943914789",
    "https://openalex.org/W3091564954",
    "https://openalex.org/W2964110616",
    "https://openalex.org/W3023594376",
    "https://openalex.org/W4283033661",
    "https://openalex.org/W2948034705",
    "https://openalex.org/W2963088785",
    "https://openalex.org/W3130868440",
    "https://openalex.org/W4385571740",
    "https://openalex.org/W4312376733",
    "https://openalex.org/W2898062326",
    "https://openalex.org/W2946595319",
    "https://openalex.org/W4285209294",
    "https://openalex.org/W4381930847",
    "https://openalex.org/W2784254609"
  ],
  "abstract": "This article provides a comprehensive survey of contemporary language modeling approaches within the realm of natural language processing (NLP) tasks. This paper conducts an analytical exploration of diverse methodologies employed in the creation of language models. This exploration encompasses the architecture, training processes, and optimization strategies inherent in these models. The detailed discussion covers various models ranging from traditional n-gram and hidden Markov models to state-of-the-art neural network approaches such as BERT, GPT, LLAMA, and Bard. This article delves into different modifications and enhancements applied to both standard and neural network architectures for constructing language models. Special attention is given to addressing challenges specific to agglutinative languages within the context of developing language models for various NLP tasks, particularly for Arabic and Turkish. The research highlights that contemporary transformer-based methods demonstrate results comparable to those achieved by traditional methods employing Hidden Markov Models. These transformer-based approaches boast simpler configurations and exhibit faster performance during both training and analysis. An integral component of the article is the examination of popular and actively evolving libraries and tools essential for constructing language models. Notable tools such as NLTK, TensorFlow, PyTorch, and Gensim are reviewed, with a comparative analysis considering their simplicity and accessibility for implementing diverse language models. The aim is to provide readers with insights into the landscape of contemporary language modeling methodologies and the tools available for their implementation.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8137853145599365
    },
    {
      "name": "Language model",
      "score": 0.6170318126678467
    },
    {
      "name": "Artificial intelligence",
      "score": 0.577484667301178
    },
    {
      "name": "Agglutinative language",
      "score": 0.5569663047790527
    },
    {
      "name": "Transformer",
      "score": 0.4405853748321533
    },
    {
      "name": "Natural language processing",
      "score": 0.3439655303955078
    },
    {
      "name": "Parsing",
      "score": 0.15000048279762268
    },
    {
      "name": "Engineering",
      "score": 0.09619981050491333
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ]
}