{
  "title": "Evaluating large language model-generated brain MRI protocols: performance of GPT4o, o3-mini, DeepSeek-R1 and Qwen2.5-72B",
  "url": "https://openalex.org/W4413942690",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5064415094",
      "name": "Su Hwan Kim",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5042646095",
      "name": "Severin Schramm",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5051199973",
      "name": "Lena Schmitzer",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5093873523",
      "name": "Kerem Serguen",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5027935660",
      "name": "Sebastian Ziegelmayer",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5028916711",
      "name": "Felix Busch",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5046157322",
      "name": "Alexander Komenda",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5117908440",
      "name": "Marcus R. Makowski",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5005164520",
      "name": "Lisa C. Adams",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5006318966",
      "name": "Keno K. Bressem",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5085312364",
      "name": "Claus Zimmer",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5003938965",
      "name": "Jan S. Kirschke",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5039985608",
      "name": "Benedikt Wiestler",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5059563956",
      "name": "Dennis M. Hedderich",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5067149506",
      "name": "Tom Finck",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5057088776",
      "name": "Jannis Bodden",
      "affiliations": [
        "Technical University of Munich"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2422148244",
    "https://openalex.org/W1965830042",
    "https://openalex.org/W3118959542",
    "https://openalex.org/W2232597337",
    "https://openalex.org/W2164969488",
    "https://openalex.org/W2753917916",
    "https://openalex.org/W4311542223",
    "https://openalex.org/W2165839911",
    "https://openalex.org/W3176626957",
    "https://openalex.org/W2997405307",
    "https://openalex.org/W4401246245",
    "https://openalex.org/W4385230595",
    "https://openalex.org/W4404258623",
    "https://openalex.org/W4380422747",
    "https://openalex.org/W4383501206",
    "https://openalex.org/W4399118604",
    "https://openalex.org/W4400324908",
    "https://openalex.org/W4393931635",
    "https://openalex.org/W4382501959",
    "https://openalex.org/W4387473486",
    "https://openalex.org/W4398781957",
    "https://openalex.org/W4367668513",
    "https://openalex.org/W4407393525",
    "https://openalex.org/W4407911733",
    "https://openalex.org/W4405079446",
    "https://openalex.org/W4408225015",
    "https://openalex.org/W4401820448",
    "https://openalex.org/W4387390366",
    "https://openalex.org/W4389984066",
    "https://openalex.org/W4404783788",
    "https://openalex.org/W4401660192",
    "https://openalex.org/W4403024753"
  ],
  "abstract": "Abstract Objectives To evaluate the potential of LLMs to generate sequence-level brain MRI protocols. Materials and methods This retrospective study employed a dataset of 150 brain MRI cases derived from local imaging request forms. Reference protocols were established by two neuroradiologists. GPT-4o, o3-mini, DeepSeek-R1 and Qwen2.5-72B were employed to generate brain MRI protocols based on the case descriptions. Protocol generation was conducted (1) with additional in-context learning involving local standard protocols (enhanced) and (2) without additional information (base). Additionally, two radiology residents independently defined MRI protocols. The sum of redundant and missing sequences (accuracy index) was defined as performance metric. Accuracy indices were compared between groups using paired t -tests. Results The two neuroradiologists achieved substantial inter-rater agreement (Cohen’s κ = 0.74). o3-mini demonstrated superior performance (base: 2.65 ± 1.61; enhanced: 1.94 ± 1.25), followed by GPT-4o (base: 3.11 ± 1.83; enhanced: 2.23 ± 1.48), DeepSeek-R1 (base: 3.42 ± 1.84; enhanced: 2.37 ± 1.42) and Qwen2.5-72B (base: 5.95 ± 2.78; enhanced: 2.75 ± 1.54). o3-mini consistently outperformed the other models with a significant margin. All four models showed highly significant performance improvements under the enhanced condition (adj. p &lt; 0.001 for all models). The highest-performing LLM (o3-mini [enhanced]) yielded an accuracy index comparable to residents (o3-mini [enhanced]: 1.94 ± 1.25, resident 1: 1.77 ± 1.29, resident 2: 1.77 ± 1.28). Conclusion Our findings demonstrate the promising potential of LLMs in automating brain MRI protocoling, especially when augmented through in-context learning. o3-mini exhibited superior performance, followed by GPT-4o. Key Points Question Brain MRI protocoling is a time-consuming, non-interpretative task, exacerbating radiologist workload . Findings o3-mini demonstrated superior brain MRI protocoling performance. All models showed notable improvements when augmented with local standard protocols . Clinical relevance MRI protocoling is a time-intensive, non-interpretative task that adds to radiologist workload; large language models offer potential for (semi-)automation of this process . Graphical Abstract",
  "full_text": "Kim et al. European Radiology\nhttps://doi.org/10.1007/s00330-025-11989-0\nIMAGING INFORMATICS AND ARTIFIC IAL INTELLIGENCE Open Access\nEvaluating large language model-\ngenerated brain MRI protocols:\nperformance of GPT4o, o3-mini, DeepSeek-R1\nand Qwen2.5-72B\nSu Hwan Kim1,2* , Severin Schramm2, Lena Schmitzer2, Kerem Serguen2, Sebastian Ziegelmayer1, Felix Busch1,\nAlexander Komenda1, Marcus R. Makowski1, Lisa C. Adams1, Keno K. Bressem1,3, Claus Zimmer2, Jan Kirschke2,\nBenedikt Wiestler4, Dennis Hedderich2, Tom Finck2 and Jannis Bodden2\nAbstract\nObjectives To evaluate the potential of LLMs to generate sequence-level brain MRI protocols.\nMaterials and methods This retrospective study employed a dataset of 150 brain MRI cases derived from local\nimaging request forms. Reference protocols were established by two neuroradiologists. GPT-4o, o3-mini, DeepSeek-R1\nand Qwen2.5-72B were employed to generate brain MRI protocols based on the case descriptions. Protocol\ngeneration was conducted (1) with additional in-context learning involving local standard protocols (enhanced) and\n(2) without additional information (base). Additionally, two radiology residents independently deﬁned MRI protocols.\nThe sum of redundant and missing sequences (accuracy index) was deﬁned as performance metric. Accuracy indices\nwere compared between groups using pairedt-tests.\nResults The two neuroradiologists achieved substantial inter-rater agreement (Cohen’s κ = 0.74). o3-mini\ndemonstrated superior performance (base: 2.65 ± 1.61; enhanced: 1.94 ± 1.25), followed by GPT-4o (base: 3.11 ± 1.83;\nenhanced: 2.23 ± 1.48), DeepSeek-R1 (base: 3.42 ± 1.84; enhanced: 2.37 ± 1.42) and Qwen2.5-72B (base: 5.95 ± 2.78;\nenhanced: 2.75 ± 1.54). o3-mini consistently outperformed the other models with a signiﬁcant margin. All four models\nshowed highly signiﬁcant performance improvements under the enhanced condition (adj.p < 0.001 for all models).\nThe highest-performing LLM (o3-mini [enhanced]) yielded an accuracy index comparable to residents (o3-mini\n[enhanced]: 1.94 ± 1.25, resident 1: 1.77 ± 1.29, resident 2: 1.77 ± 1.28).\nConclusion Our ﬁndings demonstrate the promising potential of LLMs in automating brain MRI protocoling, especially\nwhen augmented through in-context learning. o3-mini exhibited superior performance, followed by GPT-4o.\nKey Points\nQuestion Brain MRI protocoling is a time-consuming, non-interpretative task, exacerbating radiologist workload.\nFindings o3-mini demonstrated superior brain MRI protocoling performance. All models showed notable improvements\nwhen augmented with local standard protocols.\nClinical relevanceMRI protocoling is a time-intensive, non-interpretative task that adds to radiologist workload; large\nlanguage models offer potential for (semi-)automation of this process.\n© The Author(s) 2025.Open AccessThis article is licensed under a Creative Commons Attribution 4.0 International License, which permits use,\nsharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s)\nand the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material\nin this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visithttp://creativecommons.org/\nlicenses/by/4.0/.\nTom Finck and Jannis Bodden contributed equally to this work.\n*Correspondence:\nSu Hwan Kim\nsuhwan.kim@tum.de\nFull list of author information is available at the end of the article\n1234567890():,;1234567890():,;\n1234567890():,;\n1234567890():,;\nKeywords Large language models, Artiﬁcial intelligence, Brain, Magnetic resonance imaging, Protocoling\nGraphical Abstract\nIntroduction\nMagnetic resonance imaging (MRI) of the brain is a\ncomplex diagnostic examination allowing for the assess-\nment of various neurological conditions. The process of\ndetermining the appropriate sequences for brain MRI\nscans based on a review of the patient’s medical history\nand clinical question, commonly referred to as “proto-\ncoling,” is a crucial task requiring radiologists to carefully\nbalance clinical necessity with efﬁciency.\nOn the one hand, imaging protocols should be sufﬁciently\ncomprehensive to address the clinical indication. Omission\nof critical MRI sequences can necessitate repeat examina-\ntions (also known as callback examinations). In fact, pro-\ntocol errors were reported to be the most common reason\nfor such callbacks (28%), followed by inadequate anatomic\ncoverage (21%) [1]. On the other hand, protocols should be\nlimited to essential sequences to minimize scan time and\nhealthcare costs. As the demand for MRI continues to\nincrease [2], strategies to increase patient access to MRI and\nto reduce wait times are a subject of ongoing interest [3– 5].\nIn addition, optimal MRI protocols can reduce unnecessary\nexposure to contrast agents with potential adverse effects\nsuch as allergic reactions [6].\nInstitutions typically employ a set of standardized ima-\nging protocols targeted at common clinical scenarios,\nsuch as“MR brain for brain metastasis” or “MR brain for\nmultiple sclerosis” [7]. Yet, they often prove insufﬁcient in\nmore complex cases, requiring individualized protocol\nadjustments. Importantly, protocoling remains a time-\nconsuming, non-interpretative task, intensifying radi-\nologist workload, exacerbating already increasing\ndemands on their time [8, 9]. In a study analyzing the\nworkﬂow in an academic neuroradiology reading room,\nprotocoling was found to take up 6.2% of the workday of\nradiologists and was identiﬁed as a frequent source of\ninterruption from image interpretation [10].\nIn light of these challenges, previous studies have eval-\nuated the potential of artiﬁcial intelligence (AI) tools to\nselect or determine radiological imaging procedures\n[7, 11– 15]. Wong et al trained a recurrent neural network\nto classify brain MRI cases into one out of eight pre-\ndeﬁned brain MRI protocols [7]. Several studies used large\nlanguage models (LLMs) to predict the most suitable\nimaging modality, the anatomical region, and the need for\ncontrast application [12– 15]. Suzuki et al analyzed the\nperformance of GPT-4 (Generative Pre-Trained\nKim et al. European Radiology Page 2 of 12\nTransformer 4) in suggesting a single brain MRI sequence\nto be added to a standard brain MRI protocol based on a\ndisease name only, which limited the realism of the sce-\nnario [11]. Therefore, this study aimed to evaluate the\nability of LLMs to suggest granular, sequence-level brain\nMRI protocols based on realistic clinical cases.\nMethods\nStudy design\nEthical approval was waived by the institutional\nreview board.\nCase selection\nA set of 150 ﬁctitious brain MRI cases in German was\ndeveloped based on real patient cases from the local\nimaging database. For this purpose, the condensed med-\nical history and clinical question indicated in the imaging\nrequest form, as well as demographic information, were\nobtained. Subsequently, the original data were modiﬁed in\neach case by shifting the age range by 5– 10 years and\nsubstituting the location of the primary clinical or imaging\nﬁnding in the medical history with a plausible alternative\n(e.g., “left frontal intracerebral hemorrhage” instead of\n“right parietal intracerebral hemorrhage”). All references\nto locations were manually removed, and speciﬁc dates\nwere replaced with relative time descriptors (e.g.,“2 years\nago”) to reach full anonymization. Cases were classiﬁed\ninto ﬁve categories (vascular, neoplasia, in ﬂammation,\ndegenerative, miscellaneous) based on the main clinical\nquestion. In addition, cases were categorized as‘typical’if\nthe reference protocol was identical to any of the local\nstandard MRI protocols, and as‘atypical’if it was not.\nBrain MRI reference protocols\nTwo board-certiﬁed neuroradiologists with 7 years of\nexperience each (J.B. and T.F.) independently deﬁned a\nsuitable brain MRI protocol for each of the 150 cases\n(Fig. 1). Moreover, the two radiologists determined the\ncritical MRI sequences per case, deﬁned as those without\nwhich a brain MRI examination would have to be repe-\nated, due to their clinical relevance. Cases with inter-rater\ndisagreement were adjudicated through consensus. The\nlevel of inter-rater agreement between the two board-\ncertiﬁed neuroradiologists on a sequence level was\ndetermined using Cohen’s kappa.\nLLM selection and access\nTo include state-of-the-art models from both open-\nweight and closed-weight categories, the following state-\nof-the-art LLMs were selected: GPT-4o (“gpt-4o-2024-08-\n06,” OpenAI, Inc., San Francisco, USA; closed-weight),\no3-mini (“o3-mini-2025-01-31,” OpenAI, Inc., San Fran-\ncisco, USA; closed-weight), Qwen2.5-72B ( “qwen2p5-\n72b-instruct,” Alibaba Cloud, Singapore; open-weight),\nand DeepSeek-R1 (“deepseek-r1-0528,” Hangzhou Deep-\nSeek Artiﬁcial Intelligence Basic Technology Research\nCo., Ltd., Hangzhou, China; open-weight).\nGPT-4o and o3-mini were accessed via OpenAI’so fﬁ-\ncial application programming interface (API) athttps://\nplatform.openai.com/docs/models. DeepSeek-R1 and\nQwen2.5-72B were accessed via Fireworks AI, a gen-\nerative AI inference platform with servers deployed in the\nUnited States and Europe (https://ﬁreworks.ai/models).\nFor all models, the structured output mode was applied to\nobtain responses adhering to a structured JSON (Java-\nScript Object Notation) schema, enabling programmatic\nanalysis of LLM-generated protocols. For GPT-4o,\nDeepSeek-R1, and Qwen2.5-72B, a temperature setting of\n0 was selected to ensure deterministic outputs, whereas\nthe temperature parameter was not supported with o3-\nmini. Queries with GPT-4o and o3-mini were performed\non 6 Feb 2025 and 16 Feb 2025, respectively. DeepSeek-\nR1 and Qwen2.5-72B queries were both executed on\nFebruary 6, 2025. Model details are provided in Table1.\nLLM prompting\nThe base prompt was iteratively reﬁned using ﬁve ﬁcti-\ntious patient cases not included in the test dataset. In\nresponse to initial observations of misinterpretation of\ncertain MRI sequence names, brief descriptions of the less\ncommon sequences were added to the base prompt. The\nﬁnal base prompt was deﬁned as follows:\n“You are a senior neuroradiologist tasked with deﬁning a\nbrain MRI protocol for a given clinical case. Consider the\npatient’s demographics, medical history, and clinical ques-\ntion. Synthesize this information to deﬁne an MRI protocol.\nFor each sequence, indicate‘yes’ or ‘no.’ Adhere to the data\nschema provided to you. Include only clinically relevant\nsequences, avoid redundant or unnecessary sequences. Here\nis a brief explanation of the more uncommon sequences.\nCISS (Constructive Interference in Steady State): A 3D\ngradient-echo sequence with high spatial resolution.\nCE_1st_pass_Angio (Contrast-Enhanced First-Pass Angio-\ngraphy): A dynamic imaging technique using gadolinium\ncontrast to visualize blood vessels during theﬁrst pass of\ncontrast through circulation. CSF_Drive: A specialized\nsequence for assessing CSFﬂow dynamics. CSF_PCA (Phase\nContrast Angiography): Measures pulsatile CSFﬂow velo-\ncities and directions. T1_BB (Black Blood Imaging): Sup-\npresses blood signal for vessel wall imaging. TRAK_4D (4D\nTime-Resolved MR Angiography with Keyhole): A 4D (time-\nresolved) MR angiography technique that captures the\ndynamics of bloodﬂow over time. TRANCE_4D (4D Time-\nResolved Angiography using Non-Contrast Enhancement): A\nnon-contrast-enhanced 4D MRA technique, primarily used\nfor imaging vascular structures based on cardiac-triggered\nKim et al. European Radiology Page 3 of 12\nsequences. In theﬁeld ‘reasoning,’ indicate your rationale for\neach sequence included.”\nFor each model, queries were executed using ‘base’\nqueries (without additional context) and ‘enhanced’\nqueries employing in-context learning, a method guiding\nmodel behavior by embedding task-relevant information\nin the prompt [16]. In the enhanced condition, models\nwere provided with 20 standardized brain MRI protocols\nfrom the local institution (Supplementary Table 1), along\nwith an explanation of the clinical indications for each of\nthe 27 available MRI sequences (Supplementary Table 2,\ncreated by SS and SHK), all included within the model’s\ncontext window.\nOne such explanation is provided in the following:\n“ TOF-MRA (Time-of-Flight Magnetic Resonance Angio-\ngraphy) is a non-contrast, static technique used to image\nthe intracranial arteries. It con ﬁrms the patency and\ncourse of major vessels by demonstrating normalﬂow, and\nit excludes signiﬁcant stenoses or occlusions when normal\nﬂow patterns are observed. TOF-MRA is a basic sequence\nfor static vessel imaging and should be included in pro-\ntocols that aim to assess cerebral arteries.”\nOur Python code for executing LLM queries is publicly\navailable in our GitHub repository athttps://github.com/\nshk03/llm_brain_mri_protocols.\nEvaluation of LLM accuracy\nLLM performance in deﬁning brain MRI protocols was\nevaluated by calculating the number of redundant\nsequences, total missing sequences, and missing critical\nsequences, as compared to the reference protocol. The\nsum of redundant and missing sequences was deﬁned as\nthe ‘accuracy index’ serving as an overall metric for pro-\ntocoling accuracy. Furthermore, the number of cases with\nunnecessary contrast application (protocols with at least\none post-contrast sequence) was calculated.\nFig. 1 Study design. Two board-certiﬁed neuroradiologists established the reference brain MRI protocols, with discrepancies resolved through\nconsensus. GPT-4o, o3-mini, DeepSeek-R1 and Qwen2.5-72B were employed to generate brain MRI protocols based on the case descriptions. For each\nmodel, protocol generation was conducted under two conditions: (1) with additional in-context learning involving local standard protocols and\nsequence explanations (enhanced) and (2) without additional external information (base). Additionally, two radiology residents deﬁned MRI protocols for\nthe same case sample\nTable 1 Model details\nModel # Parameters Link API Access\ngpt-4o-2024-08-06 Unknown https://openai.com/index/hello-gpt-4o/ https://platform.openai.com/docs/models/gpt-4o#gpt-4o\no3-mini-2025-01-31 Unknown https://openai.com/index/openai-o3-mini/ https://platform.openai.com/docs/models/gpt-4o#o3-\nmini\nDeepSeek-R1 671B https://github.com/deepseek-ai/DeepSeek-R1 https:// ﬁreworks.ai/models/ﬁreworks/deepseek-r1\nQwen2.5-72B-Instruct 72B https://huggingface.co/Qwen/Qwen2.5-72B-\nInstruct\nhttps://ﬁreworks.ai/models/ﬁreworks/qwen2p5-72b-\ninstruct\nKim et al. European Radiology Page 4 of 12\nFor the purpose of the analysis,‘T2*’ and ‘SWI’ (sus-\nceptibility-weighted imaging) sequences were considered\nequivalent. Similarly, ‘T1 Dixon’and ‘T1 MPRAGE’were\ntreated as interchangeable.\nResident-generated brain MRI protocols\nTwo radiology residents further deﬁned MRI protocols\nfor all 150 cases, serving as a comparison for LLM-\ngenerated protocols. The two radiology residents had 18\nand 16 months of dedicated neuroradiology experience,\nrespectively (K.S. and L.S.). To simulate a realistic sce-\nnario, residents were allowed to access the local standard\nprotocols if necessary.\nProcessing times and costs\nModel inference times and API inference costs are\nreported. Residents recorded overall protocoling times,\nbased on which mean protocoling times per case were\ncalculated. Resident costs were estimated based on sal-\naries of PGY-2 residents at university hospitals in Ger-\nmany [17]. A currency rate of 1 EUR= 1.18 USD was\nassumed (as of 4 July 2025).\nStatistical analysis\nAll statistical analyses were conducted in Python (version\n3.13.2) using‘SciPy’and ‘statsmodels’libraries. Two-sided\npaired t-tests were used to compare groups based on the\naccuracy index and the frequency of cases involving\nunnecessary contrast administration.\nTo account for the increased risk of Type I errors due to\nmultiple testing, the Benjamini– Hochberg procedure was\napplied to control the false discovery rate (FDR) at 0.05.\nFor each comparison, the FDR-adjusted p-value is\nreported. Statistical signiﬁcance was set atp < 0.05.\nResults\nDataset\nThe dataset comprised 150 cases with an equal gender\ndistribution (50.0% female). The median patient age range\nwas 56– 60 years. ‘Vascular’ cases were most frequently\nobserved (26.7%), followed closely by ‘Neoplasia’ cases\n(24.7%). Conversely, cases related to degenerative condi-\ntions were relatively underrepresented (6.7%). A majority\nof cases (64.7%) were categorized as‘atypical,’ based on\nthe divergence of the respective reference protocol from\nany of the local standard brain MRI protocols (Table2).\nProcessing times and costs\nMean model inference times per case ranged from 5.5 s\n(GPT-4o [Enhanced]) to 18.4 s (o3-mini [Base]). The\nmean protocoling times for the two residents amounted\nto 51.0 and 42.0 s, respectively. Mean model inference\ncosts per case varied from 0.006 USD (GPT-4o [Base]) to\n0.021 USD (DeepSeek-R1 [Enhanced]). Protocoling costs\nper case for the two residents were estimated at 0.594\nUSD and 0.489 USD, respectively (Table3).\nReference protocols\nThe two neuroradiologists achieved substantial inter-rater\nagreement, reaching a concordance of 96.0% across all\nMRI sequences (mean Cohen’s κ = 0.74) and 97.3% for\ncritical sequences (mean Cohen’s κ = 0.75). The reference\nbrain MRI protocols included an average of 5.5 ± 1.50\nsequences (range: 2– 10), among which 3.22 ± 1.1 sequen-\nces (range: 1– 6) were classiﬁed as critical. The most fre-\nquently included sequence was FLAIR (100.0%; 150/150),\nfollowed by SWI (74.0%; 111/150) and DWI (72.7%; 109/\n150). In comparison, TOF-MRA post-contrast, CE\nﬁrst-pass angiography, and dynamic post-contrast\nT1 sequences were infrequently employed (0.7% each;\nTable 2 Dataset overview\nVariable Category Value # Sequences in reference protocol\nSex Female 50.0% (75/150)\nMale 50.0% (75/150)\nMedian age range - 56 –60 -\nPathology type Vascular 26.7% (40/150) 5.4 (±1.9)\nNeoplasia 24.7% (37/150) 5.4 (±1.1)\nMiscellaneous 23.3% (35/150) 5.5 (±1.3)\nInﬂammation 18.7% (28/150) 6.2 (±1.4)\nDegenerative 6.7% (10/150) 4.2 (±0.4)\nProtocol type Typical 35.3% (53/150) 5.5 (±1.4)\nAtypical 64.7% (97/150) 5.5 (±1.5)\n150 ﬁctitious brain MRI cases were generated by signiﬁcantly modifying real patient cases from the local imaging database\nThe dataset included demographic information (age range and sex), the condensed medical history, and clinical question. The number of sequences in the reference\nprotocols is indicated as mean (± standard deviation)\nKim et al. European Radiology Page 5 of 12\n1/150). Contrast administration was required in 65.3%\n(98/150) of protocols. Cases categorized as‘inﬂammatory’\nexhibited the highest mean sequence count (6.2 ± 1.4),\nwhereas ‘degenerative’ cases had the lowest (4.2 ± 0.4).\nYet, equal sequence counts were found in typical\n(5.5 ± 1.4) and atypical (5.5 ± 1.5) cases.\nProtocoling performance\nA sample brain MRI case including the LLM inputs and\noutputs is shown in Fig.2.T w os a m p l ee v a l u a t i o n sa r e\nshown in Supplementary Figs. 1 and 2. The lowest accuracy\nindex, indicating superior performance, was observed with\no3-mini (base: 2.65 ± 1.61; enhanced: 1.94 ± 1.25), followed\nby GPT-4o (base: 3.11 ± 1.83; enhanced: 2.23 ± 1.48) and\nDeepSeek-R1 (base: 3.42 ± 1.84; enhanced: 2.37 ± 1.42)\n(Fig. 3). Qwen2.5-72B demonstrated notably lower accuracy\n(base: 5.95 ± 2.78; enhanced: 2.75 ± 1.54). o3-mini con-\nsistently outperformed other models with a signi ﬁcant\nmargin, surpassing GPT-4o (base: adj.p < 0.001, enhanced:\nadj. p =0.007), DeepSeek-R1 (base: adj.p < 0.001, enhanced:\nadj. p < 0.001), and Qwen2.5-72B (base: adj. p < 0.001,\nenhanced: adj.p < 0.001).\nGPT-4o surpassed Qwen2.5-72B in both the base (adj.\np < 0.001) and enhanced (adj.p < 0.001) conditions, but\nshowed no signiﬁcant difference compared to DeepSeek-\nR1 (base: adj.p = 0.052; enhanced: adj.p = 0.174). All four\nmodels showed highly signiﬁcant improvements in accu-\nracy when augmented with additional domain knowledge\n(base vs enhanced; adj.p < 0.001 for all models). Impor-\ntantly, this improvement was primarily driven by a sub-\nstantial reduction of unnecessary (redundant) MRI\nsequences, whereas the rate of missing critical sequences\nremained largely stable. For example, enhanced queries\nwith o3-mini reduced redundant sequences from a mean\nof 1.75 (base) to 1.07 (enhanced), while the frequency of\nmissing sequences remained largely unchanged (base:\n0.89; enhanced: 0.87). Across all four models, the\nenhanced condition resulted in a smaller proportion of\nmissing critical sequences (GPT-4o: 0.33 [Base], 0.23\n[Enhanced]; o3-mini: 0.32 [Base], 0.22 [Enhanced];\nQwen2.5: 0.27 [Base], 0.14 [Enhanced]; DeepSeek-R1: 0.84\n[Base], 0.21 [Enhanced]). In all scenarios, except for base\nqueries using DeepSeek-R1, models recommended more\nredundant than missing sequences, reﬂecting a general\ntendency toward overly comprehensive protocol\nrecommendations.\nThe two radiology residents achieved accuracy indices\nof 1.77 ± 1.29 (0.72 redundant and 1.05 missing sequences\nper case) and 1.77 ± 1.28 (0.60 redundant and 1.17 miss-\ning sequences per case), respectively. Across all sequen-\nces, the two residents reached moderate inter-rater\nagreement with a mean concordance of 92.81% and a\nCohen’s κ of 0.57.\nProtocoling accuracy varied between case types. Across\nall four models, the greatest protocoling accuracy was\nseen for ‘degenerative’cases (accuracy index [base]: 2.48,\naccuracy index [enhanced]: 1.73). In contrast, inferior\nprotocoling performance was observed in‘vascular’cases\n(accuracy index [base]: 4.34, accuracy index [enhanced]:\n2.47) and ‘miscellaneous’ cases (accuracy index [base]:\n4.19, accuracy index [enhanced]: 2.80) (Fig.4).\nUnnecessary contrast administration\nIn Qwen2.5-72B, the enhanced condition led to a major\ndecrease of cases with unnecessary contrast administra-\ntion (base: 33.3% [50/150], enhanced: 23.3% [35/150], adj.\np < 0.001), whereas the opposite trend was seen in\nDeepSeek-R1 (base: 11.3% [17/150], enhanced: 18.0%\n[27/150], adj. p = 0.024) and GPT-4o (base: 12.7% [19/\n150], enhanced: 18.0% [27/150], adj. p = 0.022) (Fig. 5).\nNo statistically signiﬁcant difference was seen in o3-mini\n(base: 10.0% [15/150], enhanced: 10.0% [15/150], adj.\np = 1.0). Resident protocols implicated the lowest fre-\nquency of unnecessary contrast application (6.0% [9/150]\nand 9.3% [14/150], respectively).\nDiscussion\nThis study evaluated the performance of four state-of-the-\nart LLMs in creating granular, sequence-level brain MRI\nprotocols with and without augmentation through in-\ncontext learning.\nIn summary, LLMs showed promising performance in\nbrain MRI protocoling. In-context learning involving local\nstandard protocols and explanations of MRI sequences\nconsistently resulted in a substantial and highly signiﬁcant\nimprovement of protocoling accuracy. Notably, the\nhighest-performing LLM (o3-mini with enhanced queries)\nTable 3 Processing times and costs for models and residents\nModel/resident Mean processing time (s) Mean cost (USD)\nGPT-4o (Base) 6.4 0.006\nGPT-4o (Enhanced) 5.5 0.015\no3-mini (Base) 18.4 0.019\no3-mini (Enhanced) 18.0 0.027\nQwen2.5-72B (Base) 10.0 0.003\nQwen2.5-72B\n(Enhanced)\n7.3 0.006\nR1 (Base) 15.6 0.008\nR1 (Enhanced) 15.6 0.021\nResident 1 51.0 0.594\nResident 2 42.0 0.489\nModel cost represents the price for API inference. Resident costs were estimated\nbased on the salaries of PGY-2 residents at academic hospitals in Germany. A\ncurrency rate of 1 EUR= 1.18 USD was assumed (as of 4 July 2025)\nKim et al. European Radiology Page 6 of 12\nFig. 2 Exemplary brain MRI case. In the enhanced condition, an explanation of MRI sequences as well as local standard protocols was additionally\nprovided to LLMs within the context window. For all models, the structured output mode was applied to obtain responses adhering to a structured JSON\n(JavaScript Object Notation) schema\nKim et al. European Radiology Page 7 of 12\nyielded accuracy levels comparable to those of radiology\nresidents with around 1.5 years of dedicated neuror-\nadiology experience, demonstrating potential for auto-\nmating this time-consuming process. Our study extends\nthe ﬁndings of previous studies revealing the potential of\nLLMs in the biomedicalﬁeld overall [18– 20], and more\nspeciﬁcally in (semi-)automating imaging protocols\n[11– 15]. Although ﬁctitious patient cases were used, the\ngeneralizability of theﬁndings is unlikely to be affected, as\nthe data were derived from real-world patient records\nthrough only minor modiﬁcations irrelevant to the MRI\nprotocol.\nHowever, several obstacles remain to be addressed\nbefore (semi-)automation of MRI protocoling is attain-\nable. A technical infrastructure ensuring the preservation\nof patient data privacy— either through deployment on\nlocal hardware or a secure cloud-based platform— is a\nprerequisite for any clinical implementation of an LLM-\nbased system [21]. Open-weight models such as Deep-\nSeek-R1— which demonstrated reasonable performance in\nthis study— present a viable option for local deployment.\nAdditionally, LLM-based systems should be optimized\nand tested for the prevention of any patient harm.\nDeﬁning an imaging protocol involves the exclusion of\npotential contraindications for a particular imaging\nmodality (e.g., presence of a pacemaker) or contrast\nadministration (e.g., known allergy) [22]. Avoiding any\nthreats arising from complete automation and over-\nreliance on autonomous decision-making systems (a\npsychological phenomenon also known as automation\nbias [23, 24]) is critical. Insufﬁcient clinical histories in\nimaging request forms are another frequent challenge\nfaced by radiologists, requiring additional manual review\nof the electronic medical records (EMR). Recent studies\nhave explored the possibility of utilizing LLMs to assess\nthe completeness of clinical histories [25] and augment\nrequest forms by mining the EMR for pertinent infor-\nmation [13]. In the future, an agentic LLM system capable\nof orchestrating multiple tasks autonomously [26] could\nsupport an end-to-end auto-protocoling work ﬂow,\nassessing potential contraindications, enriching clinical\nhistories with EMR-extracted data, and eventually gen-\nerating a tailored imaging protocol.\nCrucially, clinical integration of LLM-based tools for\nautomated MRI protocoling hinges on regulatory\napproval. MRI protocoling tools guiding or determining\nimaging protocols directly affect diagnosis and sub-\nsequent patient management, making them subject to\nFig. 3 Model performance in deﬁning brain MRI protocols.‘Enhanced’indicates that the model received additional domain-speciﬁc knowledge— local\nstandard protocols and explanations for the indications of MRI sequences. The accuracy index (sum of missing and redundant sequences) was used to\nstatistically compare models with and without domain knowledge. *** Adj.p < 0.001\nKim et al. European Radiology Page 8 of 12\nstringent regulatory oversight. Recently, the ﬁrst large\nlanguage model (LLM)-based clinical decision support\ntool achieved certiﬁcation as a Class IIb medical device in\nthe European Union, marking a signiﬁcant milestone for\nAI-driven clinical tools [27]. Yet, many authors emphasize\nthe need for new regulatory frameworks that adequately\nreﬂect the unique characteristics of generative AI tools,\nsuch as the high output variability and poor explainability\n[28, 29].\nIn this study, LLMs were enhanced using in-context\nlearning, leading to improved protocol accuracy. The\nenrichment of LLM queries with external information sources\nhas been an area of considerable scientiﬁc interest, holding\npromise for enhanced response accuracy while mitigating\nhallucinations [30]. A widely adopted approach, retrieval-\naugmented generation (RAG), utilizes a pre-indexed external\ndatabase to dynamically retrieve relevant information during\nresponse generation [31]. However, with the advent of LLMs\nfeaturing extensive context windows, vast amounts of infor-\nmation can now be processed directly through in-context\nlearning approaches, eliminating the need for sophisticated\nretrieval architectures— although at the cost of increased\ncomputational resources [32]. As of this writing, Gemini 2.0\nPro (Google LLC) features the largest context window,\naccommodating up to 2 million tokens, equivalent to\napproximately 3000 pages of text [33]. Spanning 4013 tokens\nonly, the external documents used in this work were sufﬁ-\nciently compact to ﬁt within the context window of all\nevaluated LLMs. The option to easily replace the external\ndocuments may allow for seamless adaptation to institution-\nspeciﬁc protocoling standards.\nIntriguingly, the MRI protocoling performance of GPT-\n4o— a non-reasoning LLM— was only slightly inferior to\no3-mini, and comparable to DeepSeek-R1, both of which\nare considered state-of-the-art reasoning LLMs [34, 35].\nReasoning models, designed to decompose problems into\nsmaller logical steps through techniques like chain-of-\nthought, are known to excel at complex mathematical or\nlogical reasoning tasks. Compared to non-reasoning\nLLMs, they have been reported to better handle tasks\noutside their training data, albeit at the cost of increased\nprocessing time [36]. In clinical settings, these structured\nreasoning capabilities could contribute to improved\ntransparency and explainability, allowing clinicians to\nbetter understand and validate the model ’s output.\nAlthough direct comparisons were constrained by the\nundisclosed sizes of o3-mini and GPT-4o, our results\nsuggest that non-reasoning LLMs can perform competi-\ntively across various tasks, sometimes matching reasoning\nmodels. This underlines the importance of tailoring\nmodel selection to the speciﬁc task requirements.\nLimitations\nThis study has several limitations. First, to ensure the feasibility\nof the analysis, speciﬁc MRI protocol parameters that inﬂu-\nence exam assessability, such as orientation and slice thickness,\nFig. 4 Accuracy index by case type (n = 150). Accuracy index was deﬁned as the sum of missing and redundant sequences in LLM-generated protocols,\nas compared to the consensus protocol of two board-certiﬁed neuroradiologists. Higher accuracy index indicates lower protocoling accuracy\nKim et al. European Radiology Page 9 of 12\nwere not considered. Second, some MRI sequences (T1\nMPRAGE and T1 Dixon, T2* and SWI) were treated as\ninterchangeable, despite their distinct technical properties and\nslightly different diagnostic utilities in evaluating particular\nanatomical structures or pathologies. Third, the accuracy\nindex used to evaluate LLM protocoling performance impli-\ncitly gave equal weight to redundant and missing sequences,\nalthough omission of sequences could have greater clinical\nsigniﬁcance. Albeit imperfect, this approach allowed the\ncombined evaluation of clinical relevance and operational\nefﬁciency in a single metric. Fourth, the temperature para-\nmeter was not supported in o3-mini, and therefore could not\nbe fully standardized across models. However, temperature\nsettings were previously shown to have an only marginal\nimpact on LLM performance [19, 20]. Fifth, model cost esti-\nmations did not take into consideration the overhead for\nintegrating these tools into clinical routine. Lastly, this is a\nsingle-center study, and itsﬁndings require external validation\nacross diverse clinical environments. Derived from a single\ninstitution, the dataset may reﬂect local documentation prac-\ntices, diagnostic workﬂows and protocoling patterns. In addi-\ntion, available MRI sequences may vary across institutions.\nFuture research should employ a representative dataset of real-\nworld imaging requests and corresponding MRI protocols\nsourced from multiple institutions. Furthermore, harmonizing\nannotation guidelines and involving a broad panel of expert\nradiologists in reference protocol deﬁnition would support\nreproducibility and generalizability of benchmarking efforts.\nIn conclusion, we demonstrate the promising potential of\nLLMs in automating brain MRI protocoling, especially\nwhen augmented with local protocoling standards. o3-mini\nexhibited superior performance, followed by GPT-4o.\nAbbreviations\nAPI Application programming interface\nEMR Electronic medical record\nGPT Generative pre-trained transformer\nLLM Large language model\nSupplementary information\nThe online version contains supplementary material available athttps://doi.\norg/10.1007/s00330-025-11989-0.\nFunding\nOpen Access funding enabled and organized by Projekt DEAL.\nCompliance with ethical standards\nGuarantor\nThe scientiﬁc guarantor of this publication is S.H.K.\nConﬂict of interest\nL.C.A. is a member of the Scientiﬁc Editorial Board ofEuropean Radiology\n(section: Urogenital) and, as such, did not participate in the selection or review\nprocesses for this article. The remaining authors of this manuscript declare no\nFig. 5 Proportion of cases with LLM-generated protocols suggesting unnecessary contrast administration. *** Adj.p < 0.001\nKim et al. European Radiology Page 10 of 12\nrelationships with any companies, whose products or services may be related\nto the subject matter of the article.\nStatistics and biometry\nNo complex statistical methods were necessary for this paper.\nInformed consent\nWritten informed consent was waived by the Institutional Review Board.\nEthical approval\nInstitutional Review Board approval was obtained. This article is available as a\npreprint at: https://www.medrxiv.org/content/10.1101/2025.04.08.25325433.\nStudy subjects or cohorts overlap\nNot applicable.\nMethodology\n● Retrospective\n● Performed at one institution\nAuthor details\n1Institute of Diagnostic and Interventional Radiology, TUM University Hospital,\nSchool of Medicine and Health, Technical University of Munich, Munich,\nGermany. 2Institute of Diagnostic and Interventional Neuroradiology, TUM\nUniversity Hospital, School of Medicine and Health, Technical University of\nMunich, Munich, Germany.\n3Department of Cardiovascular Radiology and\nNuclear Medicine, German Heart Center Munich, School of Medicine and\nHealth, Technical University of Munich, Munich, Germany.\n4AI for Image-\nGuided Diagnosis and Therapy, School of Medicine and Health, Technical\nUniversity of Munich, Munich, Germany.\nReceived: 12 April 2025 Revised: 22 July 2025 Accepted: 19 August 2025\nReferences\n1. Schemmel A, Lee M, Hanley T et al (2016) Radiology workﬂow disruptors:\na detailed analysis. J Am Coll Radiol 13:1210–1214. https://doi.org/10.\n1016/j.jacr.2016.04.009\n2. Agarwal R, Bergey M, Sonnad S, Butowsky H, Bhargavan M, Bleshman MH\n(2010) Inpatient CT and MRI utilization: trends in the academic hospital set-\nting. J Am Coll Radiol 7:949–955. https://doi.org/10.1016/j.jacr.2010.08.015\n3. Bor DS, Sharpe RE, Bode EK, Hunt K, Gozansky WS (2021) Increasing\npatient access to MRI examinations in an integrated multispecialty\npractice. Radiographics 41:E1–E8. https://doi.org/10.1148/rg.2021200082\n4. Holbrook A, Glenn H, Mahmood R, Cai Q, Kang J, Duszak R (2016) Shorter\nperceived outpatient MRI wait times associated with higher patient\nsatisfaction. J Am Coll Radiol 13:505–509. https://doi.org/10.1016/j.jacr.\n2015.11.008\n5. Tokur S, Lederle K, Terris DD et al (2012) Process analysis to reduce MRI\naccess time at a German University Hospital. Int J Qual Health Care\n24:95–99. https://doi.org/10.1093/intqhc/mzr077\n6. Ramalho M, Ramalho J (2017) Gadolinium-based contrast agents: asso-\nciated adverse reactions. Magn Reson Imaging Clin N Am.https://doi.org/\n10.1016/j.mric.2017.06.006\n7. Wong KA, Hatef A, Ryu JL, Nguyen XV, Makary MS, Prevedello LM (2023)\nAn artiﬁcial intelligence tool for clinical decision support and protocol\nselection for brain MRI. AJNR Am J Neuroradiol 44:11–16. https://doi.org/\n10.3174/ajnr.A7736\n8. McDonald RJ, Schwartz KM, Eckel LJ et al (2015) The effects of changes in\nutilization and technological advancements of cross-sectional imaging\non radiologist workload. Acad Radiol 22:1191–1198. https://doi.org/10.\n1016/j.acra.2015.05.007\n9. Kwee TC, Kwee RM (2021) Workload of diagnostic radiologists in the\nforeseeable future based on recent scientiﬁc advances: growth expec-\ntations and role of artiﬁcial intelligence. Insights Imaging.https://doi.org/\n10.1186/s13244-021-01031-4\n10. Liles AL, Francis IR, Kalia V, Kim J, Davenport MS (2020) Common causes of\noutpatient CT and MRI callback examinations: opportunities for\nimprovement. AJR Am J Roentgenol 214:487 –492. https://doi.org/10.\n2214/AJR.19.21839\n11. Suzuki K, Abe K, Sakai S (2024) Imaging protocol suggested by large\nlanguage model depends on language: preliminary experiments using\nGPT-4. Preprint athttps://doi.org/10.1101/2024.07.31.24311123\n12. Rau A, Rau S, Zöller D et al (2023) A context-based chatbot surpasses\nradiologists and generic ChatGPT in following the ACR appropriateness\nguidelines. Radiology. https://doi.org/10.1148/RADIOL.230970\n13. Hallinan JTPD, Leow NW, Ong W et al (2024) MRI spine request form\nenhancement and auto protocoling using a secure institutional large\nlanguage model. Spine J.https://doi.org/10.1016/j.spinee.2024.10.021\n14. Gertz RJ, Bunck AC, Lennartz S et al (2023) GPT-4 for automated determi-\nnation of radiologic study and protocol based on radiology request forms: a\nfeasibility study. Radiology.https://doi.org/10.1148/RADIOL.230877\n15. Nazario-Johnson L, Zaki HA, Tung GA (2023) Use of large language\nmodels to predict neuroimaging. J Am Coll Radiol 20:1004–1009. https://\ndoi.org/10.1016/j.jacr.2023.06.008\n16. Iivanainen S, Lagus J, Viertolahti H, Sippola L, Koivunen J (2024) Investi-\ngating large language model (LLM) performance using in-context\nlearning (ICL) for interpretation of ESMO and NCCN guidelines for lung\ncancer. J Clin Oncol 42:e13637. https://doi.org/10.1200/jco.2024.42.16_\nsuppl.e13637\n17. Marburger B (2024) Tarifverträge. Available via https://www.marburger-\nbund.de/bundesverband/tarifvertraege. Accessed 5 July 2025\n18. Hager P, Jungmann F, Holland R et al (2024) Evaluation and mitigation of\nthe limitations of large language models in clinical decision-making. Nat\nMed. https://doi.org/10.1038/s41591-024-03097-1\n19. Tran TO, Le NQK (2024) Sa-TTCA: an SVM-based approach for tumor T-cell\nantigen classiﬁcation using features extracted from biological sequencing\nand natural language processing. Comput Biol Med.https://doi.org/10.\n1016/j.compbiomed.2024.108408\n20. Le NQK (2023) Leveraging transformers-based language models in pro-\nteome bioinformatics. Proteomics.https://doi.org/10.1002/pmic.202300011\n21. Cai W (2023) Feasibility and prospect of privacy-preserving large lan-\nguage models in radiology. Radiology 309:e232335. https://doi.org/10.\n1148/RADIOL.232335\n22. Clement O, Romanini L, van der Molen AJ et al (2024) Contrast media\nsafety: update on recent ESUR-Contrast Media Safety Committee pub-\nlications. Eur Radiol.https://doi.org/10.1007/s00330-024-10725-4\n23. Dratsch T, Chen X, Mehrizi MR et al (2023) Automation bias in mam-\nmography: the impact of artiﬁcial intelligence BI-RADS suggestions on\nreader performance. Radiology.https://doi.org/10.1148/RADIOL.222176\n24. Kim SH, Schramm S, Riedel EO et al (2025) Automation bias in AI-assisted\ndetection of cerebral aneurysms on time-of-ﬂight MR angiography. Radiol\nMed. https://doi.org/10.1007/s11547-025-01964-6\n25. Larson DB, Koirala A, Cheuy LY et al (2025) Assessing completeness of\nclinical histories accompanying imaging orders using adapted open-\nsource and closed-source large language models. Radiology 314:e241051.\nhttps://doi.org/10.1148/radiol.241051\n26. Qiu J, Lam K, Li G et al (2024) LLM-based agentic systems in medicine and\nhealthcare. Nat Mach Intell.https://doi.org/10.1038/s42256-024-00944-1\n27. VDE Press (2025) Medical co-pilot: ﬁrst AI-supported medical device to\nsupport clinical decisions. Available via https://www.vde.com/en/press/\npress-releases/medical-co-pilot-vde-aiq-valmed. Accessed 5 July 2025\n28. Weissman GE, Mankowitz T, Kanter GP (2025) Unregulated large language\nmodels produce medical device-like output. NPJ Digit Med.https://doi.\norg/10.1038/s41746-025-01544-y\n29. Freyer O, Wiest IC, Kather JN, Gilbert S (2024) A future role for health\napplications of large language models depends on regulators enforcing\nsafety standards. Lancet Digit Health. https://doi.org/10.1016/S2589-\n7500(24)00124-9\n30. Xu P, Ping W, Wu X et al (2024) Retrieval meets long context large\nlanguage models. Preprint athttps://doi.org/10.48550/arXiv.2310.03025\n31. Gao Y, Xiong Y, Gao X et al (2023) Retrieval-augmented generation for\nlarge language models: a survey. Preprint at https://doi.org/10.48550/\narXiv.2312.10997\n32. Li Z, Li C, Zhang M, Mei Q, Bendersky M (2024) Retrieval augmented\ngeneration or long-context LLMs? A comprehensive study and hybrid\nKim et al. European Radiology Page 11 of 12\napproach. In: Proceedings of the 2024 conference on empirical methods\nin natural language processing: industry track. Association for Compu-\ntational Linguistics, Miami, pp 881–893. Available via https://doi.org/10.\n18653/v1/2024.emnlp-industry.66\n33. Google DeepMind (2025) Gemini 2.0 Pro. Available viahttps://deepmind.\ngoogle/technologies/gemini/pro/. Accessed 16 Mar 2025\n34. HuggingFace (2025) deepseek-ai/DeepSeek-R1. Available via https://\nhuggingface.co/deepseek-ai/DeepSeek-R1. Accessed 16 Mar 2025\n35. Yang A, Yang B, Hui B et al (2024) Qwen2 technical report. Preprint at\nhttps://doi.org/10.48550/arXiv.2407.10671\n36. Temsah M-H, Jamal A, Alhasan K, Temsah AA, Malki KH (2024) OpenAI o1-\npreview vs. ChatGPT in healthcare: a new frontier in medical AI reasoning.\nCureus 16:e70640. https://doi.org/10.7759/cureus.70640\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in\npublished maps and institutional afﬁliations.\nKim et al. European Radiology Page 12 of 12",
  "topic": "Neuroradiology",
  "concepts": [
    {
      "name": "Neuroradiology",
      "score": 0.7116426825523376
    },
    {
      "name": "Medicine",
      "score": 0.6960940957069397
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6542096138000488
    },
    {
      "name": "Protocol (science)",
      "score": 0.6082150936126709
    },
    {
      "name": "Metric (unit)",
      "score": 0.5362066626548767
    },
    {
      "name": "Base (topology)",
      "score": 0.42869699001312256
    },
    {
      "name": "Nuclear medicine",
      "score": 0.3813030421733856
    },
    {
      "name": "Neurology",
      "score": 0.26392388343811035
    },
    {
      "name": "Pathology",
      "score": 0.16667607426643372
    },
    {
      "name": "Mathematics",
      "score": 0.12433838844299316
    },
    {
      "name": "Operations management",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Psychiatry",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Alternative medicine",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I62916508",
      "name": "Technical University of Munich",
      "country": "DE"
    }
  ],
  "cited_by": 1
}