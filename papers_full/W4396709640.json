{
  "title": "Explaining Misinformation Detection Using Large Language Models",
  "url": "https://openalex.org/W4396709640",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4208734821",
      "name": "Vishnu S. Pendyala",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5113200413",
      "name": "Eliot Christopher Hall",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4384158234",
    "https://openalex.org/W4379539933",
    "https://openalex.org/W4302439603",
    "https://openalex.org/W2891453035",
    "https://openalex.org/W4307123345",
    "https://openalex.org/W3159374415",
    "https://openalex.org/W4387561528",
    "https://openalex.org/W4390602555",
    "https://openalex.org/W3085380432",
    "https://openalex.org/W4385485235",
    "https://openalex.org/W4392601267",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2962862931",
    "https://openalex.org/W4389157038",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W2594633041",
    "https://openalex.org/W2978036424",
    "https://openalex.org/W4366341216",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4321214126",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W4386977928",
    "https://openalex.org/W3210022786",
    "https://openalex.org/W2053154970",
    "https://openalex.org/W3098106685"
  ],
  "abstract": "LLMs are a compressed repository of a vast corpus of valuable information on which they are trained. Therefore, this work hypothesizes that LLMs such as Llama, Orca, Falcon, and Mistral can be used for misinformation detection by making them cross-check new information with the repository on which they are trained. Accordingly, this paper describes the findings from the investigation of the abilities of LLMs in detecting misinformation on multiple datasets. The results are interpreted using explainable AI techniques such as LIME, SHAP, and Integrated Gradients. The LLMs themselves are also asked to explain their classification. These complementary approaches aid in better understanding the inner workings of misinformation detection using LLMs and lead to conclusions about their effectiveness at the task.",
  "full_text": null,
  "topic": "Misinformation",
  "concepts": [
    {
      "name": "Misinformation",
      "score": 0.8830404281616211
    },
    {
      "name": "Computer science",
      "score": 0.50645911693573
    },
    {
      "name": "Natural language processing",
      "score": 0.42035767436027527
    },
    {
      "name": "Data science",
      "score": 0.3328070044517517
    },
    {
      "name": "Psychology",
      "score": 0.325466126203537
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3206702768802643
    },
    {
      "name": "Computer security",
      "score": 0.17191562056541443
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I51504820",
      "name": "San Jose State University",
      "country": "US"
    }
  ],
  "cited_by": 6
}