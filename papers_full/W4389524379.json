{
  "title": "The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",
  "url": "https://openalex.org/W4389524379",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A252060633",
      "name": "Vipula Rawte",
      "affiliations": [
        "University of South Carolina"
      ]
    },
    {
      "id": "https://openalex.org/A2096509118",
      "name": "Swagata Chakraborty",
      "affiliations": [
        "Christ University"
      ]
    },
    {
      "id": "https://openalex.org/A5093047661",
      "name": "Agnibh Pathak",
      "affiliations": [
        "Christ University"
      ]
    },
    {
      "id": "https://openalex.org/A5057038841",
      "name": "Anubhav Sarkar",
      "affiliations": [
        "Christ University"
      ]
    },
    {
      "id": "https://openalex.org/A4318187548",
      "name": "S. M Towhidul Islam Tonmoy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2118470473",
      "name": "Aman Chadha",
      "affiliations": [
        "Stanford University",
        "Amazon (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2235111190",
      "name": "Amit Sheth",
      "affiliations": [
        "University of South Carolina"
      ]
    },
    {
      "id": "https://openalex.org/A2147177936",
      "name": "Amitava Das",
      "affiliations": [
        "University of South Carolina"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4378509154",
    "https://openalex.org/W2973379954",
    "https://openalex.org/W2345373228",
    "https://openalex.org/W4288028629",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W3129576130",
    "https://openalex.org/W1974991592",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W4308539010",
    "https://openalex.org/W4378464611",
    "https://openalex.org/W4287019748",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W3172669006",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W4378501037",
    "https://openalex.org/W2069424730",
    "https://openalex.org/W4389519974",
    "https://openalex.org/W2981040094",
    "https://openalex.org/W4383987670",
    "https://openalex.org/W4388979610",
    "https://openalex.org/W4312933868",
    "https://openalex.org/W4224035735",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4310882533",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4311642023",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4323568442",
    "https://openalex.org/W4301581299"
  ],
  "abstract": "Vipula Rawte, Swagata Chakraborty, Agnibh Pathak, Anubhav Sarkar, S.M Towhidul Islam Tonmoy, Aman Chadha, Amit Sheth, Amitava Das. Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. 2023.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 2541–2573\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nThe Troubling Emergence of Hallucination in Large Language Models –\nAn Extensive Definition, Quantification, and Prescriptive Remediations\nVipula Rawte1∗, Swagata Chakraborty2, Agnibh Pathak2, Anubhav Sarkar2,\nS.M Towhidul Islam Tonmoy3, Aman Chadha4,5†, Amit Sheth1, Amitava Das1\n1AI Institute, University of South Carolina, USA, 2Christ University, India\n3Islamic University of Technology, Bangladesh\n4Stanford University, USA, 5Amazon AI, USA\nvrawte@mailbox.sc.edu\nAbstract\nThe recent advancements in Large Language\nModels (LLMs) have garnered widespread ac-\nclaim for their remarkable emerging capabil-\nities. However, the issue of hallucination has\nparallelly emerged as a by-product, posing sig-\nnificant concerns. While some recent endeav-\nors have been made to identify and mitigate\ndifferent types of hallucination, there has been\na limited emphasis on the nuanced categoriza-\ntion of hallucination and associated mitigation\nmethods. To address this gap, we offer a fine-\ngrained discourse on profiling hallucination\nbased on its degree, orientation, and category,\nalong with offering strategies for alleviation.\nAs such, we define two overarching orienta-\ntions of hallucination: (i) factual mirage (FM)\nand (ii) silver lining (SL). To provide a more\ncomprehensive understanding, both orienta-\ntions are further sub-categorized into intrinsic\nand extrinsic, with three degrees of severity -\n(i) mild, (ii) moderate, and (iii) alarming. We\nalso meticulously categorize hallucination into\nsix types: (i) acronym ambiguity, (ii) numeric\nnuisance, (iii) generated golem, (iv) virtual\nvoice, (v) geographic erratum, and (vi) time\nwrap. Furthermore, we curate HallucInation\neLiciTation (\n ), a publicly available\ndataset comprising of 75,000 samples gener-\nated using 15 contemporary LLMs along with\nhuman annotations for the aforementioned cat-\negories. Finally, to establish a method for quan-\ntifying and to offer a comparative spectrum that\nallows us to evaluate and rank LLMs based\n∗Corresponding author.\n† Work does not relate to position at Amazon.\non their vulnerability to producing hallucina-\ntions, we propose Hallucination Vulnerability\nIndex (HVI). Amidst the extensive delibera-\ntions on policy-making for regulating AI de-\nvelopment, it is of utmost importance to assess\nand measure which LLM is more vulnerable\ntowards hallucination. We firmly believe that\nHVI holds significant value as a tool for the\nwider NLP community, with the potential to\nserve as a rubric in AI-related policy-making.\nIn conclusion, we propose two solution strate-\ngies for mitigating hallucinations.\n1 Hallucination: The What and Why\nFactual \nMirage\nSilver \nLining\nIntrinsic\nExtrinsic\nIntrinsic\nExtrinsic\nTime Wrap\nGeographic Erratum\nVirtual Voice\nGenerated Golem\nAcronym Ambiguity\nNumeric Nuisance\nCategoryOrientation\nmild moderate alarming\nDegree\nFigure 1: Hallucination: orientation, category, and de-\ngree (decreasing level of difficulty from top to bottom).\nThe extraordinary benefits of large generative AI\nmodels such as GPT (Brown et al., 2020; Ope-\nnAI, 2023a), Stable Diffusion (Rombach et al.,\n2022), DALL-E (Ramesh et al., 2021, 2022), and\nMidjourney (Midjourney, 2022) also come with\n2541\na substantial risk of misuse. The alarm this has\ntriggered is reflected in the open letter (Marcus\nand of Life Institute, 2023) in March 2023 by thou-\nsands of researchers and tech leaders calling for a\nsix-month moratorium on training AI systems that\nare more sophisticated than GPT-4. The key un-\nderlying concern is “should we let machines flood\nour information channels with propaganda and\nuntruth?”. In fact, the majority of these falsehoods\nare widely recognized as hallucination, which can\nbe defined as the generation of content that de-\nviates from the real facts, resulting in unfaithful\noutputs (Maynez et al., 2020).\nTo address the inevitable question of ownership\nattribution for AI-generated artifacts, the US Copy-\nright Office (Copyright-Office, 2023) released a\nstatement stating that if the content is traditional\nelements of authorship produced by a machine, the\nwork lacks human authorship and the office will\nnot register it for copyright. OpenAI’s response\nto the prevalent societal pressure led them to issue\na public statement (OpenAI, 2023b) emphasizing\ntheir commitment to AI safety and their determi-\nnation to implement improved controls on hallu-\ncination in future iterations of GPT. The recent\nroll-out of Google’s highly anticipated ChatGPT\nrival, Bard, led to a fiasco owing to it hallucinat-\ning a factually inaccurate answer in the company’s\nadvertisement, which cost Google a $140 billion\nwipeout in terms of market value (Reuters, 2023).\nIn the ad, Bard is prompted: What new discoveries\nfrom the James Webb Space Telescope (JWST)...\nBard responds with a number of answers, includ-\ning one suggesting the JWST was used to take the\nvery first pictures of a planet outside the Earth’s\nsolar system.... The first pictures of exoplanets\nwere, however, taken by the European Southern\nObservatory’s VLT in 2004. In another incident, a\nlawyer used ChatGPT to help him prepare a filing\nin a lawsuit against a US airline. However, Chat-\nGPT quoted a fabricated previous case precedent,\nwhich led the judge to consider imposing sanctions\n(Forbes, 2023). Amidst these happenings, NVIDIA\nintroduced NeMo Guardrails (nVIDIA, 2023), an\nopen-source toolkit, based on the Self-Check GPT\nframework (Manakul et al., 2023), designed to ad-\ndress hallucinations in conversational AI systems.\nThe remarkable capabilities of generative AI\nhave undeniably propelled it to a superpower sta-\ntus! Although the term hallucination has gained\nwidespread acceptance in describing the irrational\nand uncontrolled behaviors of LLMs, it is impor-\ntant to note that many experts expressed dissatisfac-\ntion with this particular nomenclature. Within the\nAI community, efforts persist to find a more suit-\nable alternative name to describe this phenomenon\naccurately. During an interview (You, 2023), Prof.\nChristopher Manning briefly expressed his discon-\ntent with the term “hallucination”, indicating a\npreference for an alternative term. In the ongoing\nconversation, Prof. Gary Marcus has advocated for\na reframing of “hallucination” as confabulation, a\nterm that some fellow researchers have already em-\nbraced. However, in this paper, we have decided to\nuphold the use of the term “hallucination”. In order\nto offer a comprehensive and precise description\nof the various types of hallucinations, we will in-\ntroduce a few new terms. These newly introduced\nmonikers aim to accurately capture and articulate\nthe different categories of hallucinations.\nContrary to the common belief that hallucina-\ntions are negative, certain researchers (Cao et al.,\n2022) propose that hallucinations in LLMs could\nhave positive implications for text summarization.\nThe authors argue that in certain cases, factual hal-\nlucinations can be advantageous in a summary by\noffering valuable background information. Further-\nmore, both the United States (White-House, 2023)\nand the European Union (European-Parliament,\n2023) governments have recently drafted their ini-\ntial proposals regarding the regulatory framework\nfor AI. With the widespread adoption of LLMs\nin a plethora of real-world use cases, it is essen-\ntial to understand which LLM is more vulnerable\nthan others in terms of hallucination – by doing\nso policymakers can decide the potential risks of\ncertain LLMs. To this end, we introduce a quantifi-\nable spectrum – Hallucination Vulnerability Index\n2542\n(HVI), which facilitates the evaluation and ranking\nof LLMs according to their hallucination vulnera-\nbility levels.\nOur Contributions: Deciphering the spectrum of\nhallucination over a range of LLMs based on HVI\n➠ Presenting a detailed study to unveil how different (15)\nLLMs hallucinate when given a factually correct prompt\nvs. a factually incorrect prompt. We name them as\nfactual mirageand silver lining– each sub-categorized\ninto intrinsic and extrinsic, with three degrees of severity:\n(a) mild, (b) moderate, and (c) alarming (cf. Section 2).\n➠ Meticulously categorizing hallucination into six types: (a)\nacronym ambiguity, (b) numeric nuisance, (c) generated\ngolem, (d) virtual voice, (e) geographic erratum, and (f)\ntime wrap(cf. Section 2).\n➠ Introducing\n (HallucInation eLiciTation), a pub-\nlicly available dataset comprising of 75,000 text snippets\ngenerated using 15 contemporary LLMs along with hu-\nman annotations for the aforementioned categories (cf.\nSection 3).\n➠ Introducing HVI (Hallucination Vulnerability Index) to per-\nform a quantitative analysis of the inclination of various\nLLMs to hallucination. (cf. Section 4). HVI characterizes\nLLMs based on the proposed types of hallucination\nvulnerabilities (cf. Fig. 2).\n➠ While complete mitigation can be a herculean task, we\nsuggest 2 mitigation strategies to alleviate hallucination.\nWe propose to identify high-entropy points in text gener-\nated by an LLM with a high HVI and replace them using\nan LLM with a lower HVI, yielding desired results (cf.\nSection 6).\n➠ We firmly believe that the\n dataset and HVI\nmeasure will serve as valuable resources for future re-\nsearchers interested in studying the hallucination behav-\niors of LLMs and seeking to design effective mitigation\ntechniques. HVI will prove to be a useful tool for assess-\ning the categorical impacts of these proposed mitigation\ntechniques.\n2 A Holistic View of the Hallucination\nSpectrum: its Types and Scales\nThe issue of hallucination garnered research atten-\ntion as early as (Maynez et al., 2020). However,\nwith the growing size of LLMs (empirical evidence\nprovided in Section 6 ), there is a corresponding\nincrease in LLMs’ susceptibility to hallucination.\nConsequently, there is a growing interest within\nthe research community to study and understand\nhallucination to design mitigation techniques.\nResearchers have loosely defined hallucinations\nand studied various notions of hallucinations in\nisolation. Early exploration of factual vs. non-\nfactual prompts for checking factuality of LMs is\naddressed in (Lee et al., 2022). A recent survey\nconducted by (Maynez et al., 2020), categorized\nhallucination into two limited classes: intrinsic\nand extrinsic. Another recent paper (Ladhak et al.,\n2023b), delved into an intriguing type of hallu-\ncination known as name-nationality category hal-\nlucination. Several other papers (Raunak et al.,\n2021; Maynez et al., 2020) have explored task-\nspecific categories of hallucination, such as sum-\nmarization, question-answering, machine transla-\ntion, etc. Preliminary exploration of factual versus\nnon-factual prompts is also addressed in (Lee et al.,\n2022). However, we purposefully avoid confining\nour study to a specific task to study the nuances of\nhallucination. Our main contention is that halluci-\nnation can occur in any NLG task, necessitating a\nthorough examination based on the fundamental\nprinciples of text generation from a given prompt.\nThe findings from this study can be applied and\nextended to various NLP tasks. Thus, this paper\naims to offer a comprehensive categorization of\nhallucination, as outlined below (see Fig. 1).\n2.1 Orientations of Hallucination\nWe introduce two primary orientations of hallu-\ncination: (i) Factual Mirage (FM) and (ii) Silver\nLining (SL), defined and exemplified below.\n2.1.1 Factual Mirage\nFactual mirage (FM) is defined as the phenomenon\nwherein an LLM engages in hallucination or distor-\ntion of a given prompt that is factually correct. FM\ncan be subdivided into two distinct sub-categories.\nM I L D\nPrompt: Capital of France\nAI-generated text: ...Paris is also the world fashion capital...\nFact: Paris.\nIntrinsic factual mirage (IFM): In the fol-\nlowing example, the LLM is providing a correct\n2543\nresponse while adding additional supplementary\nfacts such as “ the world fashion capital ,” result-\ning in distortion or hallucination, has also been\ndescribed in (Cao et al., 2022).\nExtrinsic factual mirage (EFM): EFM refers\nto the phenomenon where an LLM deviates from\nfactual accuracy. For example:\nA L A R M I N G\nPrompt: Engineering effort to build Eiffel tower\nAI-generated text: ...Designed by Gustave Eiffel, it was in-\naugurated in 1889 to celebrate the 100th anniversary of the\nEuropean Civil War...\nFact: Eiffel tower was built to celebrate the 100th anniversary of\nthe French Revolution.\n2.1.2 Silver Lining (SL)\nSilver lining (SL) is defined as the phenomenon in\nwhich an LLM indulges in hallucination by conjur-\ning an elaborate and captivating narrative based on\na given prompt that is factually incorrect.\nIntrinsic silver lining (ISL): ISL is the cate-\ngory when in some cases LLM does not generate a\nconvincing story. As an example:\nM O D E R A T E\nPrompt: Cell phone numbers go public this month.\nAI-generated text: ...Starting this month, cell phone num-\nbers will be made public as a result of the implementation\nof the Right to Information (RTI) policy...\nFact: This statement is false.\nExtrinsic silver lining (ESL): When an LLM\ngenerates a highly detailed and persuasive narrative\nin response to a factually incorrect prompt, it falls\nunder the category of Extrinsic Silver Lining.\nA L A R M I N G\nPrompt: Kamala Harris and Elon Musk are getting married\nAI-generated text: Elon Musk got married to Kamala Harris\nin California on Thursday. The ceremony took place with\n50 guests present, including Kamala’s sister and brother-\nin-law. Apart from Joe Biden all were present from the\nWhite House. Kamala’s ex-husband played the saxophone\nat the ceremony. The duo met for the first time on the\ncampaign trail in 2007 when she was Senator for the State.\nElon proposed to Kamala Harris in August 2019 on a beach.\nKamala accepted and has been dating him ever since...\nFact: The incident never happened!\n2.2 Categories of Hallucination\nWe meticulously classify hallucination into six dis-\ntinct types, defined and exemplified below.\nNumeric Nuisance (NN): This issue occurs\nwhen an LLM generates numeric values related\nto past events, such as dates, ages, or monetary\namounts, that are inconsistent with the actual facts.\nM O D E R A T E\nPrompt: Twitter is said to have laid off more workers.\nAI-generated text: The layoffs come after Twitter an-\nnounced earlier this month that it would be cutting its\nglobal workforce by 8% or roughly 600 people...\nFact: Twitter laid off 200 people which is roughly 10%\nAcronym Ambiguity (AA): This issue per-\ntains to instances in which LLMs generate an im-\nprecise expansion for an acronym.\nM O D E R A T E\nPrompt: RLHF in reinforcement learning\nAI-generated text: ...RLHF is Reward-free Learning from\nHuman Feedback in reinforcement learning...\nFact: RLHF stands for “Reinforcement Learning from Human\nFeedback”\nGenerated Golem (GG): This issue arises\nwhen an LLM fabricates an imaginary personal-\nity in relation to a past event, without concrete\nevidence. M O D E R A T E\nPrompt: Earthquake in Turkey\nAI-generated text: ...One rescuer, Hasan Cetin, said he was\nmotivated by the thought of the survivors he helped save.\n“The moment when a man or a child is pulled out of the\nruins, the joy of seeing them come back to life is...\nFact: There is no evidence that the person Hasan Cetin exists.\nVirtual Voice (VV): At times LLMs gener-\nate quotations attributed to either fictional or real\ncharacters without sufficient evidence to verify the\nauthenticity of such statements.\nA L A R M I N G\nPrompt: Pfizer Press Release on COVID-19 vaccine\nAI-generated text: ...Pfizer emphasized that their vaccine\ndemonstratedanimpressiveefficacyrate... PfizerCEOsaid,\n“This is a giant leap for humanity..”...\nFact: Pfizer CEO never said this.\nIn this instance, the expression giant leap for hu-\nmanity is quoted from Neil Armstrong’s renowned\nhistorical statement upon stepping onto the moon.\n2544\nGeographic Erratum (GE): This problem\noccurs when LLMs generate an incorrect location\nassociated with an event. For example here in the\nfirst of the following two examples, Pentagon is\nstated to be situated in India.\nTime Wrap (TW): This problem entails\nLLMs generating text that exhibits a mashed fusion\nof events from different timelines. in the follow-\ning case (2nd example) the U.S. president during\nthe Ukraine-Russia war is Joe Biden, not Barack\nObama, thus contradicting the factual reality.\nA L A R M I N G\nPrompt: Prime Minister of the United Kingdom visiting India\nAI-generated text: ...The visit of the United Kingdom’s\nPrimeMinistertoIndiaholdsimmensesignificance...During\nhis journey, he will also pay a visit to the Pentagon where\nhe is scheduled to meet with Smriti Irani, the Minister of...\nFact: Pentagon is the defense headquarters of the USA, located\nin Washington DC, USA – not in India.\nA L A R M I N G\nPrompt: USA on Ukraine war\nAI-generated text: ...U.S. President Barack Obama says the\nU.S. will not put troops in Ukraine...\nFact: The actual U.S. president during the Ukraine-Russia war is\nJoe Biden.\n2.3 Degrees of Hallucination\nWe annotate the degree of hallucination using three\nlevels: mild, moderate, and alarming (labeled as 0,\n1, and 2 respectively). Mild indicates minor hallu-\ncination which is superficial in terms of its impact.\nModerate indicates a level of hallucination that in-\ntroduces facts that are either fictitious or tangential\nto the topic at hand. Alarming indicates added in-\nformation pieces that bear a radical dissemblance\nfrom the topic fed via the prompt. Please refer to\nAppendix B for more details.\n3\n : HallucInation eLiciTation dataset\nHILT is a first-of-its-kind publicly available hallu-\ncination dataset. To construct this dataset, we have\nutilized two primary sources of data as prompts: (i)\nNYTimes tweets (NYT) (factually correct – FM)\nand (ii) the Politifact dataset (Politifact) (factually\nincorrect – SL). We selected 15 LLMs, based on\nthe criteria delineated in Section 3.1, and used\nthem to generate a total of 75,000 text passages,\nwith each LLM producing 5,000 text prose en-\ntries. These entries were categorized as 2,500\neach for FM and SL. The text prompts provided\nto these LLMs consisted of tweets from NYTimes\nand headlines sourced from the Politifact dataset.\nTable 1 reports detailed statistics about\n .\nOrientation → Factual Mirage (FM) Silver Lining (SL)\nCategories ↓ IFM EFM ISL ESL\nTime Wrap 1,650 4,950 2228 3342\nAcronym Ambiguity 675 550 1830 1255\nGenerated Golem 5,550 9,300 2302 1819\nVirtual Voice 14,100 13,950 5782 8712\nNumeric Nuisance 2,025 5,250 3210 5760\nGeographic Erratum 6,225 6,825 1232 4530\nTotal 30,225 40,825 33,168 25,418\nTable 1: Statistics of the HILT dataset (total: 129K\nannotated sentences).\n3.1 Choice of LLMs: Rationale and Coverage\nWe chose 15 contemporary LLMs that have ex-\nhibited exceptional results on a wide range of\nNLP tasks, including: (i) GPT-4 (OpenAI, 2023a),\n(ii) GPT-3.5 (OpenAI, 2022), (iii) GPT-3 (Brown\net al., 2020), (iv) GPT-2 (Radford et al., 2019),\n(v) MPT (Wang et al., 2023), (vi) OPT (Zhang\net al., 2022), (vii) LLaMA (Touvron et al., 2023),\n(viii) BLOOM (Scao et al., 2022), (ix) Alpaca\n(Taori et al., 2023), (x) Vicuna (Chiang et al.,\n2023), (xi) Dolly (databricks, 2023), (xii) Sta-\nbleLM (AI, 2023), (xiii) XLNet (Yang et al., 2019),\n(xiv) T5 (Raffel et al., 2020), and (xv) T0 (Deleu\net al., 2022). Appendix C.1 discusses additional\ndetails behind our selection criteria. Given the\never-evolving nature of the field,\n and HVI\nbenchmark leaderboards will remain accessible to\nthe research community, fostering an environment\nof continuous updates and contributions.\n3.2 Annotating Hallucination\nFor the annotation task of the 75,000 text snippets,\nwe utilized Amazon Mechanical Turk (Amazon).\nWe obtain sentence-level annotations for halluci-\nnation orientations and categories. We record four\nannotations per sentence and adopt the MACE tool\n2545\n(Hovy et al., 2013) to assess inter-annotator agree-\nment and aggregate data. MACE has been empiri-\ncally demonstrated to outperform majority voting,\nexhibiting superior performance (cf. Appendix B).\n4 Hallucination Vulnerability Index (HVI)\nGiven the growing usage of LLMs and their likeli-\nness to hallucinate, there exists no uniform evalua-\ntion metric to measure these LLMs’ hallucinations.\nTo address this gap, we define HVI, a compara-\ntive spectrum that allows us to evaluate and rank\nLLMs based on their vulnerability to producing\nhallucinations. HVI is calculated as in Eq. (1):\nHV Ix = 100\nU∗2\n[∑Ux=1(N(x)−N(EFM))∗(1−P(EFM)+δ1)+\n(N(x)−N(ESL))∗(1−P(ESL)+δ2)] (1)\nWhen defining HVI, we take several factors into\naccount. Firstly, not all sentences generated by an\nLLM are hallucinated, so it is important to deter-\nmine the ratio of actual hallucinated sentences with\nthe total number of sentences. In this context, we\nconsider U as the total number of sentences and\nN(x) as the total number of hallucinated sentences\nproduced by an LLM. Secondly, LLMs can ex-\nhibit different characteristics, such as higher EFM\nor ESL tendencies, or they can have varying lev-\nels of overall hallucination. This notion is cap-\ntured by introducing the terms N(x) −N(EFM )\nand N(x) −N(ESL) in the equation. It is worth\nnoting that we did not consider variations of in-\ntrinsic hallucinations in HVI calculation, as they\nare relatively minor and exhibit lower vulnera-\nbility overall. Lastly, comparative measures are\nneeded to rank LLMs based on their vulnerabil-\nity to hallucination. This is achieved using mul-\ntiplicative damping factors, δ1 and δ2, which are\ncalculated based on µ ±rankx ×σ. Initially, we\ncalculate the HVI for all 15 LLMs, considering\nδ1 and δ2 as zero. With these initial HVIs, we\nobtain the mean ( µ) and standard deviation ( σ),\nallowing us to recalculate the HVIs for all the\nLLMs. The resulting HVIs are then ranked and\nscaled providing a comparative spectrum as pre-\nsented in Fig. 3, similar to z-score normalization\n(Wikipedia_zscore) and/or min-max normalization\n(Wikipedia_min_max). Having damping factors\nenables easy exponential smoothing with a handful\nof data points, 15 in this case. Finally, for ease of\ninterpretability, HVI is scaled between 0−100.\nFigure 2: HVI for different hallucination categories\nacross various LLMs.\nLLM Size HVI (0-100)\nGPT-3175B 90 -StableLM7B 82 -GPT-21.5B 70 -Vicuna13B 62 -MPT 7B 59 -LLaMA65B 57 -GPT-3.5175B 53 -Dolly 12B 49 -OPT 175B 48 -GPT-41.7T 47 -Alpaca65B 40 -BLOOM176B 38 -T0 11B 36 -XLNet 340M 36 -T5 11B 32 -\nFigure 3: The HVI scale illustrates the halluci-\nnation tendencies exhibited by various LLMs.\n \nhigher  hallucination \nlower hallucination \nImplications derived from HVI\n➠ Larger LLMs without RLHF (Ziegler et al., 2019) are\nprone to both orientations of hallucination, as shown in\nFig. 3. To inspect the categorical changes in hallucina-\ntion behavior for a particular LLM, please refer to the\nvertical axis of the HVI spectrum.\n➠ As per our definitions, Numeric Nuisance and Acronym\nAmbiguity are mild hallucination categories, showing re-\nduced SL orientation as LLM size grows. Conversely,\ncomplex categories like Time Wrap and Geographic Er-\nratum become more prevalent. Notably, Virtual Voice\nsignificantly increases from GPT -3.5 to GPT -4.\n➠ For smaller LLMs like T5, Dolly, etc., Generated Golem,\nVirtual Voice, and Geographic Erratum categories of\nhallucination are rarely observed.\n2546\nPromptUSA’s stance on Ukraine Russia war\nHallucinated\ntext\nThe official stance of theUnited Stateson theRussia-Ukrainewar has been consistent in supportingUkraine’s sovereignty, territorial integrity, and the peaceful resolutionof the\nconflict. TheU.S.hascondemned Russia’s actionsinannexing Crimeaand its support for separatist movements in easternUkraine. Despite maintaining adiplomaticstance,\nthe U.S. President Barack Obamastated that theUnited Stateswould not deploy troops toUkraine. Additionally, this lack of support extends to the withholding of financial and\nmilitary assistance , includingmilitary equipment ,training , andadvisory support . Thissentiment was reiterated byPaul Altman during a press review at theWhite House ...\nMitigated text\nENTROPYBB The official stance of thegovernmenton theongoingwar has been consistent in supportingresolutionof the conflict. Thegovernmenthascondemned Russiaincountryand its\nsupport for separatist movements in easterncountry. Despite maintaining aneutralstance, thegovernmentstated that thecountrywould not deploy troops tounknown. Additionally,\nthis lack of support extends to the withholding of financial andresources, includingadministrative, technical, andlegal. This sentiment wasechoedbyministerduring a press review\nat theconference ...\nEdit Suggestions\nFACTUALITYGB\nThe official stance of the United States on the Russia-Ukraine war has been consistent in supporting Ukraine’s sovereignty, territorial integrity, and the peace-ful resolution of the conflict. The U.S. has condemned Russia’s actions in annexing Crimea and its support for separatist movements in eastern Ukraine.\nDespite maintaining a diplomatic stance, U.S. President Barack Obama stated that the United States would not deploy troops to Ukraine.Additionally, this lack of support extends to the\nwithholding of financial and military assistance, including military equipment, training, and advisory support.This sentiment was reiterated by Paul Altman during a press review at the\nWhite House ...\nFigure 4: A hallucination example pre- and post-mitigation. A - hallucinated fragments, B - high entropy\nfragments, C - replaced text, D - highlighted text for no information found, and E - refuted text fragments by\ntextual entailment. Appendix F contains more examples.\nFigure 5: Impact of mitigation techniques across the various categories and types of hallucination. For details on the\nevaluation strategy, i.e., the process of identifying the degree of hallucination after mitigation, cf. Appendix F.2.\n5 HVI vs. LLMs size for different LLMs:\nAn insight from\nThere is a general observation that LLMs may ex-\nhibit a higher tendency towards generating hallu-\ncinations or producing outputs that deviate from\nfactual or coherent information. However, it is im-\nportant to note that the relationship between LLM\nsize and hallucination is not necessarily a direct\ncorrelation, but rather a consideration based on\ncertain factors such as (a) training data quality, (b)\nlack of explicit training on facts, and (c) overconfi-\nLLM Size\nHVI\n0\n25\n50\n75\n100\n340.0 M\n1.5 B 7.0 B 7.0 B 7.0 B11.0 B11.0 B12.0 B13.0 B65.0 B175.0 B175.0 B175.0 B176.0 B170.0 T Figure 6: HVI vs. LLM size for different LLMs. Green\nindicates LLMs using RLHF.\n2547\ndence in generated responses. A noteworthy pat-\ntern that emerges is that LLMs without RLHF\n(Reinforcement Learning from Human Feedback)\n(Ziegler et al., 2019) tend to exhibit a higher ten-\ndency for hallucination. Although we did not ex-\ntensively evaluate this phenomenon, we have a\nkeen interest in investigating it further in the near\nfuture. While we tried to examine the effect of size\non HVI, it looks like there are several other factors\ncontributing to HVI behavior as evident in Fig. 6.\n6 Hallucination Mitigation Strategies\nThus far, two classes of approaches have been pro-\nposed to address the issue of hallucination: (i) pre-\nventing LLMs from hallucinating, which involves\nimplementing strategies during the training and/or\ngeneration processes; (ii) mitigating hallucination\nafter generation. (Manakul et al., 2023) introduced\nanother taxonomy of classification, categorizing\nmethods into black-box and gray-box. Factuality\nchecks during and/or after generation without rely-\ning on external resources are known as black-box\nmethods, while those using external resources are\nreferred to as gray-box methods.\nOther hallucination mitigation techniques in-\nvolve reranking the generated sample responses\n(Dale et al., 2022) and improving beam search\n(Sridhar and Visser, 2022). Some recent mitiga-\ntion techniques (Li et al., 2023; Mündler et al.,\n2023; Pfeiffer et al., 2023; Chen et al., 2023; Zhang\net al., 2023b,a; Ladhak et al., 2023a; Manakul et al.,\n2023; Agrawal et al., 2023) show initial attempts\nat reducing hallucination.\nAlthough the complete elimination of halluci-\nnation is a complex challenge, this paper explores\ntwo plausible directions for mitigation: (i) auto-\nmatic and (ii) human-in-the-loop. The former is a\nblack-box method where we identify high-entropy\nwords in a given hallucinated text (generated by a\nhigh-HVI LLM) and replace them with predictions\nfrom another LLM (lower-HVI). The latter is a\ngray-box method that involves sentence-level fact-\nchecking using textual entailment techniques. This\nmethod aims to identify sentences that are deemed\nsusceptible, urging them for human review.\nALBERT BERT DISTIL-ROBERTA XLM-ROBERTA\nALBERT 6.72 3.26 10.66 6.40\nBERT 4.70 7.56 7.98 7.22\nDISTIL-ROBERTA 2.02 7.31 4.55 9.95\nXLM-ROBERTA 2.26 6.28 1.70 4.78\nTable 2: The row represents the LLM used for detecting\nhigh entropy words from GPT-3’s output, while the\ncolumn represents the LLM for replacing those words.\n10.66 indicates the maximum drop in hallucination.\n6.1 High Entropy Word Spotting and\nReplacement (ENTROPYBB): A\nBlack-box approach\nWhile detecting high entropy words may seem to\nbe technically feasible, there is an inherent chal-\nlenge that many modern LLMs are not open-source\n(their APIs are subscription-based). The feasible\nsolution we propose here is the utilization of open-\nsource LLMs to identify high entropy words. A\nlower HVI-based LLM is then used to replace the\ndetected words (see Fig. 4). The outcomes of the\ndetection and replacement strategies discussed ear-\nlier are presented in Table 2 for GPT-3. The results\nindicate that albert-large-v2 (Lan et al.,\n2020) performs exceptionally well in detecting\nhigh entropy words in GPT-3-generated content.\nOn the other hand, distilroberta-base\n(Sanh et al., 2019) demonstrates superior perfor-\nmance in replacing high entropy words, which in\nturn, manifests as a lower hallucination. A cru-\ncial aspect of our approach is treating consecutive\nhigh-entropy words as a single unit. In such cases,\nthese words are masked together before replace-\nment. This strategy proves to be effective, particu-\nlarly for hallucinations related to Generated Golem\nor Acronym Ambiguity (cf. Appendix F.1).\n6.1.1 Lowering Concreteness of Language\nIt is observed in (Varshney et al., 2023) that higher\nuncertainty in the model’s prediction (indicated\nby a low probability score) suggests a higher like-\nlihood of the model hallucinating about that par-\nticular concept. In this context, we suggest that\nsubstituting high entropy points with less concrete\n2548\nwords can help prevent hallucinations. Concrete-\nness (Paivio, 2013) measures how much a word em-\nbodies a tangible or perceivable concept. Concrete\nwords are simpler to comprehend than abstract\nones. The level of concreteness for each word is\ndenoted on a 5-point scale, ranging from abstract\nto concrete. Concreteness ratings cover 39,954 en-\ntries, including 37,058 individual English words\nand 2,896 two-word expressions (Brysbaert et al.,\n2014), being used here.\n6.2 Factuality Check of Sentences\n(FACTUALITYGB): A Gray-box approach\nWe use Google Search API (Search) to search for a\ngiven prompt, which has been utilized to generate\nthe text and retrieve the top 20 documents. Then\neach sentence of AI-generated text has been vali-\ndated either into support, refute, or not enough in-\nformation using RoBERTa Large (Liu et al., 2019),\na SoTA textual entailment model trained on the\nSNLI (Bowman et al., 2015) (cf. Section 6.2.1). In-\nevitably, sentences with higher scores in the refute\nand not enough information categories are flagged\nfor additional human checking. Empirically, we\nobserve an overall alert rate of 26% on sentences\ngenerated by an LLM, implying 26% of the text\nrequired rewriting in order to mitigate.\n6.2.1 FACTUALITY GB\nGray-box model does require output token-level\nprobabilities (Manakul et al., 2023). Fig. 7 shows\nFACTUALITYGB, representing AI-generated text\n(from our HILT benchmark) based on a given\nprompt. In this method, the prompt is sent to the\nGoogle Search API to obtain the top 20 relevant\nsearch results. Out of these 20 results, we eval-\nuate a total of n sentences for their relevance to\nthe prompt using a similarity measure. The top 20\nsentences most similar to the prompt are selected.\nFor each of the m sentences in the AI-generated\ntext and the top 20 ranked sentences, we employ\na textual entailment model to assess their trust-\nworthiness individually. Based on their entailment\nscores, we categorize the AI-generated text into\nthree groups: (i) support, (ii) refute, and (iii) not\nenough information.\nFigure 7: FACTUALITY GB: textual entailment on\nprompt and external documents.\nPerformance of ENTROPY BB vs.\nFACTUALITYGB: Fig. 5 offers a compara-\ntive analysis of the proposed approaches. While\nENTROPYBB addresses simpler hallucinations\nsuch as Acronym Ambiguity and Numeric Nui-\nsance, FACTUALITYGB handles more complex\ncases. It is clear that a balanced combination\nof black-box and gray-box approaches is the\ninevitable future avenue (cf. Appendix F.3).\n7 Conclusion and Future Avenues\nThe enthusiasm and achievements surrounding\nLLMs have led to their widespread adoption, and\nthis trend is only expected to flourish. However,\none of the most significant challenges faced by\nLLMs today is hallucination. In light of this,\nbenchmark and Hallucination Vulnerability\nIndex (HVI) will continue to serve the wider sci-\nentific community and aid policy-makers.\nbenchmark and HVI will be publicly open for fur-\nther collaborative updates. Two proposed mitiga-\ntion techniques can serve as baselines.\n2549\n8 Discussion and Limitations\nDiscussion: On June 14 th, 2023, the European\nParliament successfully passed its version of the\nEU AI Act (European-Parliament, 2023). Sub-\nsequently, a team of researchers from the Stan-\nford Institute for Human-Centered Artificial Intel-\nligence (HAI) embarked on investigating the extent\nto which Foundation Model Providers comply with\nthe EU AI Act. Their initial findings are presented\nin the publication (Bommasani et al., 2023). In\nthis study, the authors put forward a grading sys-\ntem consisting of 12 aspects for evaluating LLMs.\nThese aspects include (i) data sources, (ii) data\ngovernance, (iii) copyrighted data, (iv) compute,\n(v) energy, (vi) capabilities & limitations, (vii) risk\n& mitigations, (viii) evaluation, (ix) testing, (x)\nmachine-generated content, (xi) member states,\nand (xii) downstream documentation . The over-\nall grading of each LLM can be observed in Fig. 8.\nWhile this study is commendable, it appears to\nbe inherently incomplete due to the ever-evolving\nnature of LLMs. Since all scores are assigned man-\nually, any future changes will require a reassess-\nment of this rubric, while HVI is auto-computable.\nFurthermore, we propose that HVI should be con-\nsidered the most suitable category for assessing\nrisk and mitigations, as well as the evaluation of\nmachine-generated content.\nLimitations: In this paper, we present a unique\nand extensive benchmark corpus for hallucination\ncalled\n . We propose two main types of hallu-\ncination: (i) Factual Mirage and (ii) Silver Lining,\neach further divided into intrinsic and extrinsic sub-\ncategories. Additionally, we introduce six detailed\ncategories of hallucination along with a measure\nof its intensity. We believe the following aspects\nrequire critical attention in future endeavors.\nLimitation 1: For the sake of simplicity, we\nhave only considered one category per sentence\nduring annotation, although we acknowledge the\npresence of multi-class and multi-label instances.\nFor instance, in the following example, there are\ntwo kinds of hallucination, namely Time Wrap and\nNumeric Nuisance present in the shown sentence.\nWe would like to explore this direction in the im-\nmediate future.\nA L A R M I N G\nPrompt: Engineering effort to build Eiffel tower\nAI-generated text: ...Designed by Gustave Eiffel, it was in-\naugurated in 1889 to celebrate the 100th anniversary of\nthe European Civil War, while construction began a decade\nprior to its inauguration....\nFact 1: Eiffel tower was built to celebrate the 100th anniversary\nof the French Revolution.\nFact 2: Eiffel Tower construction was started in 1887, not in 1879.\nLimitation 2: While we have meticulously de-\nfined the categories of hallucination, we recognize\nthe potential for new categories to emerge in the fu-\nture with the advancement of LLMs. An instance\nof this is the introduction of name-nationality hallu-\ncination by (Ladhak et al., 2023b), where a person\nnamed Jung Lee is falsely attributed with French\nnationality. Although one could argue that Mr Lee\nmay indeed be a French national, considering his\nbirth and upbringing there, the authors confirm\nthat no such individual exists. We posit that name-\nnationality hallucination falls under the sub-class\nof generated golems. It is plausible that a combina-\ntion of our defined categories may exist, although\nwe did not extensively studied these possibilities.\nLimitation 3: For this study, we have chosen\n15 contemporary LLMs. In the dynamic landscape\nof LLM development, new models are constantly\nemerging, and we acknowledge that our selection\nmay not encompass all available options. Keeping\nthis in mind, we will make the\n benchmark\nand the HVI publicly accessible for collaborative\nupdates and contributions.\nLimitation 4: The FACTUALITYGB technique\noperates based on entailment, allowing it to distin-\nguish between sentences containing different enti-\nties such as Barack Obama and Joe Biden. How-\never, it is unable to differentiate sentences that\ninvolve similar entities like AI and AAAI. In con-\ntrast, the ENTROPYBB technique operates at the\ntoken level and is capable of handling cases like\n1789 vs. 1889. These distinctions become evident\nin the observed results.\n2550\nFigure 8: Grading of current LLMs as proposed by a report entitled Do Foundation Model Providers Comply with\nthe EU AI Act? from Stanford University (Bommasani et al., 2023).\n9 Ethical Considerations\nThrough our experiments, we have uncovered the\nsusceptibility of LLMs to hallucination. In de-\nveloping HVI, we intend to provide a framework\nthat can inform future research and policies in this\ndomain. However, we must address the potential\nmisuse of our findings by malicious entities who\nmay exploit AI-generated text, such as creating\nindistinguishable fake news from human-written\ncontent. We vehemently discourage such misuse\nand strongly advise against it.\nReferences\n2023. The future of computational linguistics.\nAbien Fred Agarap. 2019. Deep learning using rectified\nlinear units (relu).\nAyush Agrawal, Lester Mackey, and Adam Tauman\nKalai. 2023. Do language models know when they’re\nhallucinating references?\nStability AI. 2023. Stability ai launches the first of its\nstable lm suite of language models.\nAmazon. Amazon mechanical turk.\nRishi Bommasani, Kevin Klyman, Daniel Zhang, and\nPercy Liang. 2023. Do foundation model providers\ncomply with the eu ai act?\nSamuel R Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D Manning. 2015. The snli corpus.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nMarc Brysbaert, Amy Beth Warriner, and Victor Ku-\nperman. 2014. Concreteness ratings for 40 thousand\ngenerally known english word lemmas. Behavior\nresearch methods, 46:904–911.\nMeng Cao, Yue Dong, and Jackie Chi Kit Cheung. 2022.\nHallucinated but factual! inspecting the factuality\nof hallucinations in abstractive summarization. In\nProceedings of the 60th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 3340–3354.\nAnthony Chen, Panupong Pasupat, Sameer Singh, Hon-\ngrae Lee, and Kelvin Guu. 2023. Purr: Efficiently\n2551\nediting language model hallucinations by denoising\nlanguage model corruptions.\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,\nZhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan\nZhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion\nStoica, and Eric P. Xing. 2023. Vicuna: An open-\nsource chatbot impressing gpt-4 with 90%* chatgpt\nquality.\nCopyright-Office. 2023. Copyright registration guid-\nance: Works containing material generated by artifi-\ncial intelligence. Library of Congress.\nDavid Dale, Elena V oita, Loïc Barrault, and Marta R.\nCosta-jussà. 2022. Detecting and mitigating hal-\nlucinations in machine translation: Model internal\nworkings alone do well, sentence similarity even\nbetter.\nTri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and\nChristopher Ré. 2022. Flashattention: Fast and\nmemory-efficient exact attention with io-awareness.\nAdvances in Neural Information Processing Systems,\n35:16344–16359.\ndatabricks. 2023. Dolly.\nTristan Deleu, David Kanaa, Leo Feng, Giancarlo Kerg,\nYoshua Bengio, Guillaume Lajoie, and Pierre-Luc\nBacon. 2022. Continuous-time meta-learning with\nforward mode differentiation. In The Tenth Inter-\nnational Conference on Learning Representations,\nICLR 2022, Virtual Event, April 25-29, 2022. Open-\nReview.net.\nEuropean-Parliament. 2023. Proposal for a regulation\nof the european parliament and of the council laying\ndown harmonised rules on artificial intelligence (ar-\ntificial intelligence act) and amending certain union\nlegislative acts.\nForbes. 2023. Lawyer used chatgpt in court—and cited\nfake cases. a judge is considering sanctions.\nDirk Hovy, Taylor Berg-Kirkpatrick, Ashish Vaswani,\nand Eduard Hovy. 2013. Learning whom to trust\nwith MACE. In Proceedings of the 2013 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, pages 1120–1130, Atlanta, Georgia.\nAssociation for Computational Linguistics.\nHuggingFace_InferenceAPI. Huggingface inference\napi.\nFaisal Ladhak, Esin Durmus, Mirac Suzgun, Tianyi\nZhang, Dan Jurafsky, Kathleen McKeown, and Tat-\nsunori Hashimoto. 2023a. When do pre-training bi-\nases propagate to downstream tasks? a case study in\ntext summarization. In Proceedings of the 17th Con-\nference of the European Chapter of the Association\nfor Computational Linguistics , pages 3206–3219,\nDubrovnik, Croatia. Association for Computational\nLinguistics.\nFaisal Ladhak, Esin Durmus, Mirac Suzgun, Tianyi\nZhang, Dan Jurafsky, Kathleen Mckeown, and Tat-\nsunori B Hashimoto. 2023b. When do pre-training\nbiases propagate to downstream tasks? a case study\nin text summarization. In Proceedings of the 17th\nConference of the European Chapter of the Asso-\nciation for Computational Linguistics, pages 3198–\n3211.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2020. Albert: A lite bert for self-supervised learning\nof language representations.\nNayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pas-\ncale N Fung, Mohammad Shoeybi, and Bryan Catan-\nzaro. 2022. Factuality enhanced language models for\nopen-ended text generation. In Advances in Neural\nInformation Processing Systems, volume 35, pages\n34586–34599. Curran Associates, Inc.\nJunyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun\nNie, and Ji-Rong Wen. 2023. Halueval: A large-\nscale hallucination evaluation benchmark for large\nlanguage models.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nPotsawee Manakul, Adian Liusie, and Mark J. F. Gales.\n2023. Selfcheckgpt: Zero-resource black-box hal-\nlucination detection for generative large language\nmodels.\nGary Marcus and Future of Life Institute. 2023. Pause\ngiant ai experiments: An open letter.\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and\nRyan McDonald. 2020. On faithfulness and factu-\nality in abstractive summarization. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 1906–1919, On-\nline. Association for Computational Linguistics.\n2552\nMidjourney. 2022. https://www.midjourney.com.\nNiels Mündler, Jingxuan He, Slobodan Jenko, and Mar-\ntin Vechev. 2023. Self-contradictory hallucinations\nof large language models: Evaluation, detection and\nmitigation.\nnVIDIA. 2023. https://nvidia.github.io/nemo/.\nNYT. https://www.nytimes.com/topic/company/twitter.\nOpenAI. 2022. Introducing chatgpt.\nOpenAI. 2023a. Gpt-4 technical report.\nOpenAI. 2023b. Our approach to ai safety.\nAllan Paivio. 2013. Dual coding theory, word abstract-\nness, and emotion: a critical review of kousta et\nal.(2011).\nJonas Pfeiffer, Francesco Piccinno, Massimo Nicosia,\nXinyi Wang, Machel Reid, and Sebastian Ruder.\n2023. mmt5: Modular multilingual pre-training\nsolves source language hallucinations.\nPolitifact. https://www.politifact.com/.\nOfir Press, Noah A. Smith, and Mike Lewis. 2022.\nTrain short, test long: Attention with linear biases\nenables input length extrapolation. In The Tenth\nInternational Conference on Learning Representa-\ntions, ICLR 2022, Virtual Event, April 25-29, 2022.\nOpenReview.net.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. The Journal of Machine Learning Research,\n21(1):5485–5551.\nAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey\nChu, and Mark Chen. 2022. Hierarchical text-\nconditional image generation with clip latents. arXiv\npreprint arXiv:2204.06125.\nAditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott\nGray, Chelsea V oss, Alec Radford, Mark Chen, and\nIlya Sutskever. 2021. Zero-shot text-to-image gen-\neration. In International Conference on Machine\nLearning, pages 8821–8831. PMLR.\nVikas Raunak, Arul Menezes, and Marcin Junczys-\nDowmunt. 2021. The curious case of hallucinations\nin neural machine translation. In Proceedings of\nthe 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 1172–1183,\nOnline. Association for Computational Linguistics.\nReuters. 2023. Alphabet shares dive after google ai\nchatbot bard flubs answer in ad.\nRobin Rombach, Andreas Blattmann, Dominik Lorenz,\nPatrick Esser, and Björn Ommer. 2022. High-\nresolution image synthesis with latent diffusion mod-\nels. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, pages\n10684–10695.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2019. Distilbert, a distilled version\nof bert: smaller, faster, cheaper and lighter. ArXiv,\nabs/1910.01108.\nTeven Le Scao, Angela Fan, Christopher Akiki, El-\nlie Pavlick, Suzana Ili ´c, Daniel Hesslow, Roman\nCastagné, Alexandra Sasha Luccioni, François Yvon,\nMatthias Gallé, et al. 2022. Bloom: A 176b-\nparameter open-access multilingual language model.\narXiv preprint arXiv:2211.05100.\nGoogle Search. Google search api.\nNoam Shazeer. 2019. Fast transformer decoding:\nOne write-head is all you need. arXiv preprint\narXiv:1911.02150.\nNoam Shazeer. 2020. Glu variants improve trans-\nformer.\nArvind Krishna Sridhar and Erik Visser. 2022. Im-\nproved beam search for hallucination mitigation in\nabstractive summarization.\nJianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha,\nBo Wen, and Yunfeng Liu. 2022. Roformer: En-\nhanced transformer with rotary position embedding.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy\nLiang, and Tatsunori B. Hashimoto. 2023. Stan-\nford alpaca: An instruction-following llama\nmodel. https://github.com/tatsu-lab/\nstanford_alpaca.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\n2553\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models. arXiv\npreprint arXiv:2302.13971.\nNeeraj Varshney, Wenlin Yao, Hongming Zhang, Jian-\nshu Chen, and Dong Yu. 2023. A stitch in time saves\nnine: Detecting and mitigating hallucinations of\nllms by validating low-confidence generation. arXiv\npreprint arXiv:2307.03987.\nZhen Wang, Rameswar Panda, Leonid Karlinsky, Roge-\nrio Feris, Huan Sun, and Yoon Kim. 2023. Multitask\nprompt tuning enables parameter-efficient transfer\nlearning. In The Eleventh International Conference\non Learning Representations.\nWhite-House. 2023. Blueprint for an ai bill of rights:\nMaking automated systems work for the american\npeople.\nWikipedia_Fleiss’s_Kappa. Fleiss’s kappa.\nWikipedia_Krippendorff’s_Alpha. Krippendorff’s al-\npha.\nWikipedia_min_max. Normalization.\nWikipedia_zscore. Normalization.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2020. Hug-\ngingface’s transformers: State-of-the-art natural lan-\nguage processing.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXlnet: Generalized autoregressive pretraining for\nlanguage understanding. Advances in neural infor-\nmation processing systems, 32.\nBiao Zhang and Rico Sennrich. 2019. Root mean\nsquare layer normalization.\nMuru Zhang, Ofir Press, William Merrill, Alisa Liu,\nand Noah A. Smith. 2023a. How language model\nhallucinations can snowball.\nShuo Zhang, Liangming Pan, Junzhou Zhao, and\nWilliam Yang Wang. 2023b. Mitigating lan-\nguage model hallucination with interactive question-\nknowledge alignment.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mi-\nhaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel\nSimig, Punit Singh Koura, Anjali Sridhar, Tianlu\nWang, and Luke Zettlemoyer. 2022. Opt: Open pre-\ntrained transformer language models.\nDaniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B.\nBrown, Alec Radford, Dario Amodei, Paul F. Chris-\ntiano, and Geoffrey Irving. 2019. Fine-tuning lan-\nguage models from human preferences. CoRR,\nabs/1909.08593.\n2554\nFrequently Asked Questions (FAQs)\n✽ This study explores the unintended, negative aspects of hallucination; how about the\nuseful effects that arise as a result of hallucination?\n➠ While hallucinating has beneficiary effects in some computer vision use cases, where a generative\nvision model could perform in-painting of an occluded content in an image or generate an image of a\nscenario it hasn’t seen in its training set (for example, a generated image corresponding to the prompt,\n“water on Mars”), but it is usually undesirable in the context of the text. The downstream impact as a\nresult of the model’s is exacerbated by the fact that there is a lack of a programmatic method in the\nresearch community to distinguish the hallucinated vs. factually correct output. For this reason, this\nstudy focuses on characterizing the problem of hallucination particularly in the context of text.\n✽ Why do you select those 15 large language models?\n➠ We want to select several language models with varying parameter sizes for our experiments -\nranging from large to small. Hence, the above chosen 14 models consist of large models like GPT-3\nand smaller ones like T5 and T0.\n✽ Why would extrinsic hallucination be riskier?\n➠ According to the “extrinsic hallucination” definition, this kind of hallucination does not have any\nway to verify it from the source prompt. Hence, it is likely to be more harmful than the intrinsic ones.\n✽ What is the purpose of constructing Factual Mirage and Silver Lining hallucination data?\n➠ We want to show that hallucinations can happen in both cases, factually correct and incorrect\nprompts. Hence, in this paper, we construct an exhaustive dataset called\n .\n✽ Why do you select high-entropy points for mitigation techniques?\n➠ High entropy points are more uncertain points in the context of text generation and hence, more\nlikely places where the LLM hallucinates. Hence, our mitigation approach works by detecting and\nreplacing such high entropy points.\n✽ Why would HVI be a better hallucination evaluation metric for the LLMs (as compared\nto the existing ones like accuracy, precision, recall, F1, etc.)?\n➠ Although the commonly used evaluation metrics like accuracy, precision, etc. can be used for\ndownstream tasks, HVI can be more specifically used to determine the LLMs’ hallucination tendency.\nHVI will serve as a uniform hallucination score for all the present and future LLMs.\n✽ What are the insights on using black-box vs. gray-box models for mitigation hallucina-\ntions?\n➠ Both black-box and gray-box models have their own advantages and disadvantages in terms of\nreducing hallucinations. Therefore, the choice of the appropriate method to minimize hallucination\nwould be LLM- and task-dependent.\n2555\nA Appendix\nThis section provides supplementary material in the form of additional examples, implementation details,\netc. to bolster the reader’s understanding of the concepts presented in this work.\nB Annotation Process, and agreement\nB.1 Pilot in-house annotation\nCrowdsourcing platforms are widely recognized for their speed and cost-effectiveness in annotation tasks.\nHowever, it is important to note that they can also introduce noise or inaccuracies in the annotations. To\nmitigate this, prior to utilizing crowdsourcing services, we conducted an in-house annotation process\ninvolving 2,000 samples. These samples included prompts and generated text snippets from five different\nLLMs. This in-house annotation process served two purposes: firstly, it allowed us to formulate\ncomprehensive annotation guidelines, and secondly, it helped us develop an annotation interface tailored\nto our specific needs. By undertaking this internal annotation process, we aimed to ensure the quality and\nreliability of the annotations before moving on to crowdsourcing.\nB.2 Annotation Steps\nWhen annotating an AI-generated text snippet, we follow a sentence-wise approach. Our annotation\nprocess involves three layers of annotation: (i) Orientation: This layer captures the orientation of\nhallucinations. (ii) Category: This layer classifies the category of hallucination, and (iii) Degree: This\nlayer quantifies the intensity or magnitude of hallucination. By employing these three layers, we aim to\nprovide a comprehensive and detailed annotation for hallucination in AI-generated text.\nAlgorithm 1: Annotation Guidelines\n1 Split the paragraph into a list of sentences.\n2 Annotate the orientation of hallucination as intrinsic or extrinsic.\n3 Annotate the category of hallucination.\n4 Annotate the degree of hallucination.\n• Step 1: In order to analyze the legitimacy of an AI-Generated paragraph and identify any potential\nhallucination, we begin with a sentence-level approach. We split the paragraph into individual\nsentences ensuring that each sentence is distinct and well separated from the others. Each sentence\nundergoes rigorous scrutiny to determine its legitimacy. This involves the identification of the type of\nhallucination, the category of hallucination, and the degree of hallucination.\n• Step 2: In this step, we identify whether the sentence has no hallucination, intrinsic hallucination,\nor extrinsic hallucination. The absence of both intrinsic and extrinsic hallucination implies no\nhallucination. To identify whether the sentence has intrinsic hallucination or extrinsic hallucination,\nwe refer to the definitions in Section 2. We annotate each sentence using the annotations listed in\nTable 3\n• Step 3: In this step, we identify whether the detected hallucinated sentences of the previous step belong\nto any of the categories mentioned in Fig. 1. To identify the categories we refer to the definitions\nmentioned in Section 2. If the hallucinated sentence does not fall under any of the identified categories,\n2556\nit implies a miscellaneous category. Once we have identified the category, we annotate each sentence\nusing the annotations listed in Table 3.\n• Step 4: This step involves categorizing the degree of hallucination as mild, moderate, or alarming,\nbased on the level of delusional information in the sentence. A high degree refers to completely\ndelusional information, a moderate degree to partially delusional information, and a low degree to\nminimal delusional information. Once we have identified the degree of hallucination, we annotate it\nas listed in Table 3.\nB.3 Web Interface for Annotation\nFigure 9: Web interface used to annotate the HILT dataset using Amazon Mechanical Turk.\nIn order to facilitate the annotation process for the annotators, it is crucial to provide them with a\nuser-friendly interface that enables easy navigation. Fig. 9 shows our annotation web interface used to\nconstruct the HILT dataset. The interface is designed to offer a comprehensive view to the annotator. For\ninstance, at the top of the interface, the actual prompt used for generating the text snippet is displayed.\nDirectly below the prompt, the complete AI-generated text is shown. On the right-hand side, the sentence\nbreakup is presented, with the currently selected sentence highlighted in red. Below the sentence breakup,\nall the relevant categories are displayed as radio buttons, allowing the annotators to easily annotate each\ncategory. This interface aims to enhance the efficiency and effectiveness of the annotation process. We\nhave gone through a few rounds of iterations before finalizing the current version of the web interface.\nB.4 Selecting quality annotators on AMT\nIt is widely acknowledged that platforms like AMT can be noisy, making the selection of high-quality\nannotators a critical step in ensuring accurate annotations. The in-house annotation of 2,000 data points\n2557\nplayed a significant role in achieving this goal. To identify reliable annotators, we initiated a pilot task\nand only selected those with an accuracy rate of over 90% based on our in-house annotated dataset.\nOrientation AnnotationCategory AnnotationDegree Annotation\nNo Hallucination 0 No Hallucination 0 Mild 0Intrinsic Hallucination 1Time Wrap 1 Moderate 1Extrinsic Hallucination 2Geographic Erratum 2 Alarming 2Virtual V oice 3Generated Golem 4Numeric Nuisance 5Acronym Ambiguity 6Miscellaneous 7\nTable 3: Annotations for\n : Orientation, Category, and Degree. We\nfollow a three-level annotation process where we first determine whether\nthere is a hallucination or not, and if yes, then what orientation. We\nassign labels 0, 1, and 2 for “no”, “intrinsic”, and “extrinsic” hallucina-\ntion. Next, we determine the category of hallucination and label them\nranging from 0 through 7, where 7 could be a miscellaneous case where\nthe hallucination does not belong to any category. Finally, the degrees\nare labeled with 0, 1, and 2.\nAnother crucial consideration\nwhen annotating data on crowd-\nsourcing platforms is the com-\npensation offered to annotators.\nWhile offering too little may de-\nter interest, excessively high wages\nmay attract undesirable spammers.\nAchieving the ideal balance re-\nquired several rounds of iteration\nto determine an appropriate com-\npensation scheme.\nBy carefully addressing factors\nsuch as selecting qualified annota-\ntors and establishing suitable com-\npensation rates, we improved the\nquality of annotations obtained\nfrom crowdsourcing platforms.\nB.5 Inter-Annotator Agreement\nWe report Fleiss’s kappa ( κ) (Wikipedia_Fleiss’s_Kappa) and Krippendorff’s alpha ( α)\n(Wikipedia_Krippendorff’s_Alpha) scores (see Tables 4 and 5) to access the reliability of agreement\nbetween the three annotators1. We compute agreement on 10% of total annotated entities and obtain\nsubstantial to almost perfect agreement in all three annotation types in both datasets, namely NYT\nand Politifact. We have obtained nearly or more than 80% agreement in the case of orientation\nand category. The agreement on degree exhibits slight variation, as it relies on the subjective\nassessment of the percentage of hallucination in the sentence. This interpretation of percentage tends\nto differ among individuals. We report both Fleiss’s kappa and Krippendorff’s alpha score because\nFleiss’s kappa is a statistical measure that allows us to find agreement among multiple annotators and\nKrippendorff’s alpha is a statistical measure that allows us to handle various types of data like nominal\n(orientation and category) and ordinal (degree).\nFleiss’s kappa Krippendorff’s alpha\nOrientation 0.7911 0.8146\nCategory 0.7846 0.8499\nDegree 0.7473 0.7274\nTable 4: Inter-annotator scores for NYT dataset.\nFleiss’s kappa Krippendorff’s alpha\nOrientation 0.7587 0.8436\nCategory 0.8755 0.9328\nDegree 0.6182 0.5455\nTable 5: Inter-annotator scores for Politifact dataset.\n1Three graduate students\n2558\nC Details on chosen LLMs\nC.1 Criteria for choosing LLMs\nBeyond the primary criteria for choosing performant LLMs, our selection was meant to cover a wide\ngamut of LLMs that utilize a repertoire of recent techniques under the hood that have enabled their\nexceptional capabilities, namely:\n• FlashAttention (Dao et al., 2022) for memory-efficient exact attention.\n• Multi-Query Attention (Shazeer, 2019) for memory bandwidth efficiency.\n• SwiGLU (Shazeer, 2020) as the activation function instead of ReLU (Agarap, 2019).\n• ALiBi (Press et al., 2022) for larger context width.\n• RMSNorm (Zhang and Sennrich, 2019) for per-normalization.\n• RoPE (Su et al., 2022) to improve the expressivity of positional embeddings, etc.\nC.2 Details on Large Language Models\nModel details are given in Table 6. We use HuggingFace (Wolf et al., 2020) and OpenAI for implementing\nthe large language models to generate the dataset.\nD\n - Prompt sources\nWe used two datasets to curate HILT: (i) New York Times Tweets (NYT) for factually correct and (ii)\nPolitifact dataset (Politifact) for factually incorrect prompts.\nE What is a high entropy vs. low entropy word?\nFigure 10: High entropy word vs. low entropy word - a side-by-side illustration.\nIn the context of language modeling, a high entropy word refers to a word or token that has a high\nlevel of uncertainty or unpredictability in its occurrence. In other words, it is a word that is relatively rare\nor has a low probability of appearing in a given context. Entropy is often used to quantify the level of\n2559\nLLMs Parameter\nsize\nLLM used in this paper Details\nGPT-3 175B gpt3 GPT-3 (Brown et al., 2020) is an autoregressive language model by OpenAI. It\nis a decoder-only transformer model with a size of 175 billion parameters.\nStableLM 7B stablelm-base-alpha-7b StableLM (?) The Alpha version of the model is available in 3 billion and 7\nbillion parameters.\nGPT-2 1.5B gpt2 GPT-2 (Radford et al., 2019) is a large transformer-based language model with\n1.5 billion parameters. It is trained on a WebText dataset consisting of 8 million\nweb pages.\nVicuna 13B eachadea//vicuna-13b-1.1 Vicuna (Chiang et al., 2023) is created by fine-tuning a LLaMA base model us-\ning approximately 70K user-shared conversations gathered from ShareGPT.com\nMPT 7B mosaicml/mpt-7b MPT (Wang et al., 2023) is a part of the family of MosaicPretrainedTrans-\nformer(MPT) models, which use a modified transformer architecture optimized\nfor efficient training and inference.\nLLaMA 65B decapoda-research/llama-\n65b-hf\nLLaMa (Touvron et al., 2023)is a collection of foundation language models\nvarying from 7B to 65B parameters. It is trained on trillions of tokens. LLaMA-\n65B outperforms GPT-3 (175B) on most benchmarks.\nGPT-3.5 175B gpt3.5 (text-davinci-003) GPT-3.5 (OpenAI, 2023b) is a sub-class of GPT-3 model family. It has 3\nvariants each with 1.3B, 6B, and 175B parameters.\nDolly 12B dolly-v2-12b Dolly (databricks, 2023) is an instruction-following large language model\ntrained on the Databricks machine learning platform.\nOPT 175B opt-175B OPT (Zhang et al., 2022) is a decoder-only pre-trained transformer model\nranging from 125M to 175B parameters. Although the performance of OPT-\n175B is comparable to GPT-3, it only requires 1/7th the carbon footprint to\ndevelop.\nGPT-4 170T gpt4 GPT-4 (OpenAI, 2023a) was released by OpenAI in 2023. It is a large multi-\nmodal model that shows human-level performance on various professional and\nacademic benchmarks.\nAlpaca 7B chainyo/alpaca-lora-7b Alpaca (Taori et al., 2023) is a language model fine-tuned using supervised\nlearning from a LLaMA 7B model on 52K instruction-following demonstrations.\nBLOOM 176B bigscience/bloom BLOOM (Scao et al., 2022) is similar to GPT-3 (auto-regressive model for next\ntoken prediction). However, it has been trained on 46 different languages and 13\nprogramming languages.\nT0 11B bigscience/T0 T0 (Deleu et al., 2022) is trained on a diverse set of tasks and prompts leading to\nincreased robustness to the prompt wording. T0 outperforms or matches GPT-3,\nwhich is 16x larger in size and has 100s of billions of parameters.\nXLNet 340M xlnet-large-cased XLNet (Yang et al., 2019) is a generalized autoregressive pretraining model that\n(1) enables learning bidirectional contexts by maximizing the expected likelihood\nover all permutations of the factorization order and (2) overcomes the limitations\nof BERT because of its own autoregressive formulation.\nT5 11B t5-11b T5 (Raffel et al., 2020) is an encoder-decoder model pre-trained on a multi-task\ncombination of unsupervised and supervised tasks Each task is converted into a\ntext-to-text format.\nTable 6: HuggingFace and OpenAI links for all LLMs.\n2560\nunpredictability associated with generating specific words or tokens. When a language model encounters\na high entropy word, it means that the model has greater difficulty in accurately predicting or generating\nthat word based on the context or preceding words. High entropy words are often less frequent in the\ntraining data or have complex patterns of occurrence. For example, in a language model trained on\nnews articles, words like “pneumonoultramicroscopicsilicovolcanoconiosis” (a technical term for a lung\ndisease) would likely have high entropy, as they are infrequent and occur in specific contexts.\nOn the other hand, a low entropy word refers to a word or token that has a relatively high predictability\nor a limited range of potential next words given the context. In other words, it is a word that occurs\nfrequently and is highly expected in a specific context. When a language model encounters a low entropy\nword, it means that the model has a higher confidence or accuracy in predicting or generating that word\nbased on the context or preceding words. For example, in a language model trained on English text,\ncommon words like “the,” “and,” or “is” have low entropy because they occur frequently and are highly\npredictable in many contexts. These words tend to have a limited set of likely next words based on the\npreceding context. Fig. 10 illustrates an example of the entropy distribution over the set of words in an\ninput sentence. In sentence 1, [MASK] token has low entropy since capital is the highest probable\nword in that sentence. However, [MASK] token in sentence 2 has high entropy since it is quite uncertain\nas to what the masked token could be. The probability distributions for this illustration are created using\nthe HuggingFace Inference API (HuggingFace_InferenceAPI).\nF Mitigation Techniques: The specifics\nIn addition to the Fig. 4 provided in Section 6, we now present two additional illustrative examples in\nTable 7 and Table 8 to demonstrate the practical application of two different mitigation techniques.\nPromptThere are more oil rigs in operation in the United States than the rest of the world combined.\nHallucinated\ntext\nThis is not true. According to theInternational Association of Oil and Gas Producers, as of the start of2020,there were a total of4,932oil rigs in operation worldwide, with theUnited Stateshaving1,094of them. This\nmeans that theUS has22.1% of the world’s totaloil rigs in operation.\nMitigated text\nENTROPYBB This is not true. According to thecompanyas of the start ofyearthere were a total ofnumberwellsin operationworldwide with theunknownhavingnumberof them. This means that thecountryhasnumberof the world’s totalwells in operation.\nEdit Suggestions\nFACTUALITYGBThis is not true.According to the International Association of Oil and Gas Producers, as of the start of 2020, therewere a total of 4,932 oil rigs in operation worldwide, with the United States having 1,094 of them.This means thatthe US has 22.1% of the world’s total oil rigs in operation.\nTable 7: A hallucination example pre- and post-mitigation. A - hallucinated fragments, B - high entropy\nfragments, C - replaced text, D - highlighted text for no information found, and E - refuted text fragments by\ntextual entailment.\n2561\nPromptRescue workers in Turkey are battling exhaustion as the hope of finding more earthquake survivors dwindles. Remem-bering those they have saved spurs them to keep searching. A powerful new quake on Monday complicated their task.\nHallucinated\ntext\nThe7.0magnitude quake thatrockedtheAegean SeawasTurkey’sdeadliest in a decade, killingat least109people and injuring more than1,000. It toppled dozens of buildingsin the cities ofIzmirandMuglaand leftdozensof peopletrappedbeneath the rubble. Rescue crews haveworked tirelessly all week, often in the dark and inperilousconditions. At the same time, theyhave had to cope with the emotional toll of finding bodies, many of them children, in the debris.One rescuer,Hasan Cetin , said he was motivated by the thought of the survivors he helped save. “The momentwhen a man ora child is pulled out of the ruins, the joy of seeing them come back to life is indescribable.” Cetin toldThe Associated Press “This is why we keep on going.” The rescuers have been buoyed by the support of local people,who have donated food, water, and other supplies. Turkey’sHealthMinisterFahrettin KocasaidMondaythat therescue efforts would continue until the last victim was found.\nMitigated text\nENTROPYBB Thehighmagnitude quake thatshookthesouthwascountry’sdeadliest in a decade killing at leastnumberpeopleand injuring more thannumber. Itaffected a lot of buildingsin the cities ofunknownandunknownand left dozensof people trapped beneath the rubble. Rescue crews have worked tirelessly all week often in the dark and insevereconditions. At the same time, they have had to cope with thetraumaof finding bodies many of them children in theunknown. Localrescuerpersonsaid he was motivated by the thought of the survivors he helped save “The momentwhen a man or a child is pulled out of thedustthefearof seeing them come back to life is indescribable”.Someonetold Themedia“This is why we keep on going” The rescuers have beenobligedby the support of local people whohave donated food water and other suppliesCountry’sHealth Ministeralsosaidfridaythat the rescue efforts wouldcontinue until the last victim was found.\nEdit Suggestions\nFACTUALITYGBThe 7.0 magnitude quake that rocked the Aegean Sea was Turkey’s deadliest in a decade, killing at least 109 people andinjuring more than 1,000. It toppled dozens of buildings in the cities of Izmir and Mugla and left dozens of peopletrapped beneath the rubble. Rescue crews have worked tirelessly all week, often in the dark and in perilous conditions.At the same time, they have had to cope with the emotional toll of finding bodies, many of them children, in the debris.One rescuer, Hasan Cetin, said he was motivated by the thought of the survivors he helped save. “The moment whena man or a child is pulled out of the ruins, the joy of seeing them come back to life is indescribable.”.Cetin told The Associated Press “This is why we keep on going.”The rescuers have been buoyed by the sup-port of local people, who have donated food, water, and other supplies. Turkey’s Health Minister Fahrettin Koca saidMonday that the rescue efforts would continue until the last victim was found.\nTable 8: A hallucination example pre- and post-mitigation. A - hallucinated fragments, B - high entropy\nfragments, C - replaced text, D - highlighted text for no information found, and E - refuted text fragments by\ntextual entailment.\nF.1 ENTROPY BB\nBuilding upon Section 6, Tables 9 to 23 illustrate the examples of the nuanced categorization of halluci-\nnation proposed in the paper.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 6.72 3.26 10.66 6.40\nbert-base-uncased 4.70 7.56 7.98 7.22\ndistilroberta-base 2.02 7.31 4.55 9.95\nxlm-roberta-large 2.26 6.28 1.70 4.78\nTable 9: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by GPT-3. 10.66 is the maximum drop in overall hallucination detected with albert-large-v2 and\nreplaced with distilroberta-base.\n2562\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 6.80 5.40 8.40 5.10\nbert-base-uncased 2.70 2.60 2.60 2.50\ndistilroberta-base 4.90 4.40 5.10 3.30\nxlm-roberta-large 2.80 2.50 2.70 2.60\nTable 10: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by StableLM. 8.40 is the maximum drop in overall hallucination detected with albert-large-v2\nand replaced with distilroberta-base.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 4.22 5.14 8.34 8.00\nbert-base-uncased 2.12 4.72 8.87 7.77\ndistilroberta-base 3.88 5.93 6.92 5.22\nxlm-roberta-large 2.85 7.65 2.87 3.00\nTable 11: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by GPT-2. 8.87 is the maximum drop in overall hallucination detected with bert-base-uncased\nand replaced with distilroberta-base.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 8.50 7.80 8.80 7.90\nbert-base-uncased 7.20 7.20 7.10 7.30\ndistilroberta-base 6.20 7.00 8.70 7.20\nxlm-roberta-large 5.70 6.40 5.60 6.50\nTable 12: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by Vicuna. 8.80 is the maximum drop in overall hallucination detected with albert-large-v2 and\nreplaced with distilroberta-base.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 8.00 7.00 9.00 7.70\nbert-base-uncased 6.30 8.30 8.00 5.40\ndistilroberta-base 7.00 7.00 3.00 6.00\nxlm-roberta-large 8.30 8.20 7.00 7.00\nTable 13: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by MPT. 9.00 is the maximum drop in overall hallucination detected with albert-large-v2 and\nreplaced with distilroberta-base.\n2563\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 9.90 9.30 9.10 8.80\nbert-base-uncased 6.80 6.70 6.10 6.00\ndistilroberta-base 8.00 7.60 8.20 7.20\nxlm-roberta-large 5.00 4.80 4.90 4.00\nTable 14: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by LLaMA. 9.90 is the maximum drop in overall hallucination detected with albert-large-v2 and\nreplaced with albert-large-v2.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 8.10 9.27 2.51 9.17\nbert-base-uncased 9.02 5.83 2.71 2.24\ndistilroberta-base 4.57 8.98 7.74 9.17\nxlm-roberta-large 9.48 9.54 4.41 2.36\nTable 15: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by GPT-3.5. 9.54 is the maximum drop in overall hallucination detected with xlm-roberta-large\nand replaced with bert-base-uncased.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 6.10 6.30 8.20 6.00\nbert-base-uncased 4.10 4.10 4.70 4.00\ndistilroberta-base 5.10 5.70 5.30 5.10\nxlm-roberta-large 3.30 4.00 4.20 4.40\nTable 16: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by Dolly. 8.20 is the maximum drop in overall hallucination detected with albert-large-v2 and\nreplaced with distilroberta-base.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 5.18 4.70 8.58 6.25\nbert-base-uncased 2.41 3.09 3.06 2.40\ndistilroberta-base 4.52 4.61 4.98 3.78\nxlm-roberta-large 2.92 2.81 2.84 2.77\nTable 17: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by OPT. 8.58 is the maximum drop in overall hallucination detected with albert-large-v2 and\nreplaced with distilroberta-base.\n2564\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 6.31 9.91 10.10 7.75\nbert-base-uncased 4.49 4.47 7.60 5.20\ndistilroberta-base 9.17 5.55 5.81 4.37\nxlm-roberta-large 3.67 4.35 3.92 2.46\nTable 18: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by GPT-4. 10.10 is the maximum drop in overall hallucination detected with albert-large-v2 and\nreplaced with distilroberta-base.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 9.80 9.50 9.20 9.80\nbert-base-uncased 6.20 7.80 7.00 6.50\ndistilroberta-base 9.00 8.30 8.50 8.30\nxlm-roberta-large 5.70 5.70 5.70 4.00\nTable 19: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by Alpaca. 9.80 is the maximum drop in overall hallucination detected twice withalbert-large-v2\nand replaced with albert-large-v2 and xlm-roberta-large.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 6.60 7.80 7.80 7.80\nbert-base-uncased 1.20 2.20 3.40 3.30\ndistilroberta-base 6.60 6.60 6.60 6.60\nxlm-roberta-large 3.40 2.30 3.30 3.30\nTable 20: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by Bloom. 7.80 is the maximum drop in overall hallucination detected thrice withalbert-large-v2\nand replaced with bert-base-uncased, distilroberta-base and xlm-roberta-large.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 8.00 8.40 8.00 6.10\nbert-base-uncased 6.90 6.10 6.00 5.40\ndistilroberta-base 6.90 6.00 6.70 6.40\nxlm-roberta-large 5.60 5.60 5.90 4.10\nTable 21: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by T0. 8.40 is the maximum drop in overall hallucination detected with albert-large-v2 and\nreplaced with bert-base-uncased.\n2565\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 8.00 9.00 8.00 9.00\nbert-base-uncased 6.00 6.00 6.00 6.00\ndistilroberta-base 8.00 8.00 8.00 8.00\nxlm-roberta-large 7.00 7.00 6.00 6.00\nTable 22: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by XLNet. 9.00 is the maximum drop in overall hallucination detected twice withalbert-large-v2\nand replaced with bert-base-uncased and xlm-roberta-large.\nalbert-large-v2 bert-base-uncased distilroberta-base xlm-roberta-large\nalbert-large-v2 7.00 7.90 7.00 6.20\nbert-base-uncased 6.50 6.40 5.70 5.70\ndistilroberta-base 7.20 7.90 7.00 6.40\nxlm-roberta-large 5.60 6.50 5.80 5.80\nTable 23: Overall drops in hallucination by 16 combinations of 4 LLMs with the rows having the LLMs which\ndetected the high entropy words and the corresponding columns with the LLMs which replaced those words\ngenerated by T5. 7.90 is the maximum drop in overall hallucination detected with albert-large-v2 and\ndistilroberta-base and replaced in both the cases with bert-base-uncased.\nF.2 Evaluation strategy - how to determine no hallucination after mitigation?\nIn order to assess the absence of hallucination following the implementation of the mitigation techniques\nENTROPYBB and FACTUALITYGB, a random sample of 2,000 data points was taken. This sample\nincluded 500 instances each of IFM, EFM, ISL, and ESL, ensuring a well-balanced distribution of the\nsix hallucination categories within the data. Following the implementation of the ENTROPYBB method,\nwhich involved replacing words and phrases, we conducted a manual evaluation of the 2,000 samples.\nThis evaluation, carried out by six annotators, aimed to assess whether hallucination was alleviated or\nnot.\nFor the FACTUALITYGB method, we assumed that if the sentences were rewritten by humans, there\nwould be no presence of hallucination. Therefore, for the highlighted sentences, hallucination was\ndeemed waived. Results of this evaluation are reported in Fig. 5 and Table 24.\nF.3 Performance of ENTROPY BB vs. FACTUALITYGB\nFig. 5 and Table 24 give a relative analysis of our two proposed mitigation techniques described in\nSection 6. We report the actual values in the Table 24. Our empirical findings indicate that ENTROPYBB\ntechnique primarily tackles less complex hallucination categories such as acronym ambiguity and numeric\nissues. However, FACTUALITYGB technique is more applicable for dealing with more complex cases of\nhallucinations. Therefore, it is quite evident that a combination of both black- and gray-box methods\nwould be the future direction of research.\n2566\nNumeric Nuisance Acronym Ambiguity Generated Golem Virtual Voice Geographic Erratum Time Wrap\nBefore EBB FGB Before EBB FGB Before EBB FGB Before EBB FGB Before EBB FGB Before EBB FGB\nSILVER LINING\nT5 0 0 0 0 0 0 2 2 2 0 0 0 5 5 5 0 0 0\nXLNet 0 0 0 0 0 0 2 2 2 0 0 0 5 5 5 0 0 0\nT0 34 22 24 55 46 36 8 6 8 0 0 0 0 0 0 0 0 0\nBLOOM 33 27 28 62 57 45 0 0 0 0 0 0 0 0 0 0 0 0\nAlpaca 29 18 19 55 48 39 0 0 0 0 0 0 0 0 0 0 0 0\nGPT-4 36 27 22 67 50 53 0 0 0 0 0 0 0 0 0 0 0 0\nOPT 43 40 35 69 67 51 0 0 0 0 0 0 0 0 0 0 0 0\nDolly 75 72 43 79 78 53 0 0 0 2 2 2 8 8 8 9 9 9\nGPT-3.5 68 68 44 75 75 49 12 12 8 8 8 8 9 9 9 0 0 0\nLLaMA 80 80 48 78 78 52 18 18 9 14 14 9 12 12 10 0 0 0\nMPT 77 77 52 64 64 46 21 21 18 19 19 12 16 16 12 0 0 0\nVicuna 78 78 53 43 43 36 53 53 23 34 34 21 37 37 24 38 38 31\nGPT-2 69 69 55 39 39 25 58 58 32 38 38 19 41 41 32 42 42 33\nStableLM 63 63 59 33 33 19 60 60 36 39 39 22 42 42 29 46 46 30\nGPT-3 59 59 43 30 30 18 61 61 38 69 69 31 49 49 32 53 53 34\nFACTUAL MIRAGE\nT5 63 53 53 80 71 66 12 9 12 0 0 0 55 55 32 8 9 8\nXLNet 63 55 59 80 69 69 26 21 18 0 0 0 63 64 55 9 10 9\nT0 68 62 59 76 71 65 22 18 18 0 0 0 56 56 48 0 0 0\nBLOOM 71 55 65 82 69 57 19 12 12 0 0 0 55 54 46 0 0 0\nAlpaca 69 61 62 83 77 58 20 15 13 0 0 0 42 39 39 0 0 0\nGPT-4 64 59 58 80 69 59 22 17 12 0 0 0 46 42 41 0 0 0\nOPT 73 73 65 69 69 49 34 34 15 0 0 0 51 51 44 12 12 8\nDolly 80 80 65 75 75 56 54 54 22 2 2 2 59 59 38 22 22 12\nGPT-3.5 74 74 61 77 77 58 36 36 21 8 8 8 67 67 43 28 28 13\nLLaMA 80 80 68 78 78 55 69 69 26 32 32 20 69 69 42 39 39 19\nMPT 77 77 66 75 75 59 70 70 29 39 39 19 74 74 47 42 42 22\nVicuna 61 61 56 78 78 55 62 62 31 53 53 31 76 76 49 44 44 23\nGPT-2 72 72 66 74 74 53 58 58 36 76 76 36 80 80 45 66 66 29\nStableLM 78 78 68 69 69 49 65 65 34 81 81 39 79 79 44 72 72 33\nGPT-3 80 80 64 66 66 42 68 68 40 89 89 45 76 76 43 92 92 38\nTable 24: HVI scores for Silver Lining (SL) and Factual Mirage (FM) for all six hallucination categories – before\nvs. after – using two mitigation techniques: (i) ENTROPYBB (EBB) and (ii) FACTUALITYGB (FGB).\nG Examples from\nThe following Tables 25 to 30 illustrate the examples of the nuanced categorization of hallucination\nproposed in the paper.\n2567\nFactual Mirage\nIntrinsic\nPrompt More than 100,000 people took to the streets in cities across Mexico on Sunday to protest new laws\nhobbling the nation’s election agency, in what demonstrators said was a repudiation of the president’s\nefforts to weaken a pillar of democracy.\nAI-Generated\nText\nThe protests, which began on June 16, were organized by citizens’ groups and opposition political\nparties in response to recent laws passed by the Mexican Congress that critics say impose limits\non the autonomy of theNationalElectoralInstitute(INE), the body responsible for organizing\nand administering elections. The new laws, which have been widely condemned by international\nhuman rights groups, allow for the president to appoint board members to the INE, a power that was\npreviously reserved for members of Congress. In addition, the new laws allow for the president to\nappoint the head of the INE, and for him to control its budget. The protesters say the laws are part of\na strategy by the president, Andrés Manuel López Obrador, to weaken the agency and prevent it from\nholding free and fair elections. López Obrador has denied these allegations, saying the reforms are\nmeant to create a more efficient and transparent electoral system.\nFact ThefullformofINEisInstitutoNacionalElectoral.\nExtrinsic\nPrompt In Ukraine, Vladimir Putin’s invasion has met setback after setback. But its effect in Russia has been\nvery different — and it has made Putin more dominant than ever at home.\nAI-Generated\nText\nPutin’s invasion of Ukraine has bolstered his standing among Russians. It was seen as a way to\nprotect the country’s interests and to reassert its influence in its former Soviet satellites. His approval\nratings soared to the highest they had been in years, and he was able to use the conflict to distract\nfrom economic woes and to crack down on domestic dissent. Putin has also used the conflict to foster\na sense of Russian nationalism, which has helped to strengthen his grip on power. Vladimir Putin\nis known to have an inside source group calledHomelandKomitetGosudarstvennoyBezopasnosti\nFront(HKGBF) that operates within his own government. The group handpicked by Putin himself for\ntheir loyalty and effectiveness in carrying out secret missions on behalf of the Russian government,\nconsists of highly skilled operatives who carry out covert operations around the world on behalf of\ntheir leader. As a result, he has become even more entrenched in the Russian political system, with\nhis control over the country extending far beyond the Kremlin walls.\nFact ThereisnoevidencethatHKGBFexistsorisanextensionofKGB.\nSilver Lining\nIntrinsic\nPrompt SaysHillary Clinton wants to abolish the Second Amendment.\nAI-\nGenerated\nText\nHillary Clinton has never called for abolishing the Second Amendment. However, she has expressed\nsupport for common-sense gun control measures aimed at reducing gun violence. TheNational\nRemingtonArms(NRA) has been tasked with conducting research on gun violence in the United\nStates. NRA recommends implementing these common-sense gun control measures at a federal level\nto help reduce gun violence in the country.\nFact ThecorrectfullformisNRA(NationalRifleAssociation).\nExtrinsic\nPrompt The ACLU didn’t call for an investigation (of the Newark police department), they called for an\nimmediate federal monitor.\nAI-Generated\nText\nTheAmericanChristianLifeUniversity(ACLU) stepped in to address these issues. However,\ninstead of calling for an investigation into the Newark Police Department, they demanded an\nimmediate federal monitor to oversee all police activities. The decision surprised some members of\nthe community who were hoping for a thorough investigation that would hold individual officers\naccountable for their actions. Nevertheless, most people agreed that having an external body\noverseeing the police department’s activities could lead to positive changes in policing practices. As\nsoon as the federal monitor was appointed, they began conducting regular audits of police activity\nand reviewing complaints against officers. They also implemented new training programs aimed at\nimproving officer-civilian interactions and reducing instances of excessive force.\nFact AmericanCivilLibertiesUnion(ACLU)isthecurrentfullform\nTable 25: Examples for Acronym Ambiguity.\n2568\nFactual Mirage\nIntrinsic\nPrompt As New York State’s maverick wildlife pathologist, he pleased environmentalists but angered his\nbosses and corporate polluters by going beyond his mandate to expose the dangers that PCBs and\nother toxic chemicals also posed to humans.\nAI-Generated\nText\nDr. Ward Stone began his career as a wildlife pathologist in New York State in the 1970s. He quickly\nbecame known for his maverick approach to his job, which often meant going beyond his mandate\nto investigate the effects of toxic chemicals on both wildlife and people. He was an advocate for\nenvironmental protection, and his work often put him at odds with corporate polluters, who were\noften critical of his findings. Stone’s research on PCBs and other toxic chemicals revealed serious\ndangers to both animals and humans, and he was unafraid to share his findings with the public. His\nwork led to some significant breakthroughs, including the discovery of the first link between PCBs,\ncancer, and reproductive problems in people. He was also vocal in his criticism of the state and\nfederal governments for not doing enough to protect the environment. Stone received a number of\nawards and honors for his work during his career, including the Audubon Medal, the highest honor\ngiven by the National Audubon Society. He was also inducted into the New York State Environment\nHall of Fame in 2015.Stonepassedawayin2019attheageof94. His legacy as an environmental\nadvocate and scientist will continue to be remembered for many years to.\nFact Dr.Wardhadactuallydiedattheageof84in2023\nExtrinsic\nPrompt “Cocaine Bear” is fictional, but the story about a high bear in the 1980s is very real. Here’s the story\nbehind the film, which hits theaters Feb. 24.\nAI-Generated\nText\nIn 1985, a large black bear was discovered in the Chattahoochee National Forest in Georgia with a\nstrange story. The bear had been spotted by hunters, and it was waddling around with a dead man’s\nbody in its mouth. After further investigation, it was discovered that the man had died from a drug\noverdose and that the bear had been scavenging the body for food. What was even more bizarre was\nthat the bear had managed to open the man’s backpack and consume the contents, which included\nover75poundsofcocaine that had been packed in plastic bags. The bear was found to have a level\nof cocaine in its bloodstream that was seven times higher than the lethal dose for humans. It was\neventually euthanized due to its extreme agitation and aggression. The animal’s strange tale has since\nbecome a popular urban legend, and experts have warned against feeding wild animals, as it can pose\na significant risk to both the animals and humans.\nFact Thereisnoevidencethatthebearhadconsumed75poundsofcocaine.\nSilver Lining\nIntrinsic\nPrompt There are more oil rigs in operation in the United States than the rest of the world combined.\nAI-\nGenerated\nText\nThis is not true. According to the International Association of Oil and Gas Producers, as of the start\nof 2020,therewerea totalof4,932oilrigsinoperationworldwide, with the United States having\n1,094 of them. This means that the US has 22.1% of the world’s total oil rigs in operation.\nFact In2022,USAhad462oilrigs.\nExtrinsic\nPrompt Women and men both are making less when you adjust for inflation than when John Kitzhaber was\nfirst elected governor.\nAI-\nGenerated\nText\nWhen Kitzhaber was first elected governor in 1995, the median household income for women\nin Oregon was$41,820 and for men it was$50,945. When adjusted for inflation, that would be\nequivalent to$71,527 and$88,935 in 2019 dollars, respectively. Today, the median household\nincome for women in Oregon is$50,095 and for men it is$61,094. This is a decrease of$21,432 and\n$27,841, respectively, when adjusted for inflation.\nFact Theexactmonetaryvaluescannotbeconfirmed.\nTable 26: Examples for Numeric Nuisance.\n2569\nFactual Mirage\nIntrinsic\nPrompt Club Q, an LGBTQ nightclub in Colorado Springs where five people were killed in a mass shooting\nin November, announced this week that it will reopen by the fall. The club will also feature a\n“permanent standing tribute” to the victims.\nAI-Generated\nText\nClub Q’s owners,DeonandTe-ErikaPatterson,saidina statementthattheyare “deeplycommitted”\ntohonoringthevictimsandtheirfamilies. The owners added that they plan to “create a lasting and\nmeaningful memorial in their honor at the club.ThePattersonsalsosaidthattheyplanto “enhance\nsafetyfeatures”attheclub,thoughtheydidnotprovidespecificdetails. The club also plans to offer\ncounseling and mental health services to those affected by the tragedy. Finally, thePattersonssaid\nthattheyplantousetheclub’sreopeningto “raisemoneyforthevictims’familiesandforother\norganizationsthatservetheLGBTQ+community.” The reopening of Club Q is a hopeful sign for\nthe LGBTQ community in Colorado Springs. The club has been a safe haven for members of the\ncommunity for decades, and its reopening will provide them with a place to gather and heal.\nFact Te-ErikaPattersonisa journalist,authorandwomen’srightadvocate.SheandDeonPattersonare\nnottheownersofClubQ.\nExtrinsic\nPrompt Rescue workers in Turkey are battling exhaustion as the hope of finding more earthquake survivors\ndwindles. Remembering those they have saved spurs them to keep searching. A powerful new quake\non Monday complicated their task.\nAI-Generated\nText\nThe 7.0 magnitude quake that rocked the Aegean Sea was Turkey’s deadliest in a decade, killing at\nleast 109 people and injuring more than 1,000. It toppled dozens of buildings in the cities of Izmir\nand Mugla and left dozens of people trapped beneath the rubble. Rescue crews have worked tirelessly\nall week, often in the dark and in perilous conditions. At the same time, they have had to cope with\nthe emotional toll of finding bodies, many of them children, in the debris.Onerescuer,HasanCetin,\nsaidhewasmotivatedbythethoughtofthesurvivorshehelpedsave. “Themomentwhena manor\na childispulledoutoftheruins,thejoyofseeingthemcomebacktolifeisindescribable.” Cetin\ntold The Associated Press. “Thisiswhywekeepongoing.” The rescuers have been buoyed by the\nsupport of local people, who have donated food, water, and other supplies. Turkey’s Health Minister\nFahrettin Koca said Monday that the rescue efforts would continue until the last victim was found.\nFact ThenewsabouttheearthquakeistruebutwhetherHasanCetinexistsornotthereisnoevidence.\nSilver Lining\nIntrinsic\nPrompt Barack Obama has never even worked in business.\nAI-Generated\nText\nIt is true that former President Barack Obama did not have significant experience working in the\nprivate sector before entering politics.However,it is alsotruethathe andhischildhoodfriend\nMikeformeda smallbusinessventurecalledBusinessInternationalCorporation(BIC)in1985. BIC\nprovided research and consulting services to American companies seeking to do business overseas.\nWhile BIC was not a large-scale operation and ultimately closed down after a few years due to\nfinancial difficulties, it does represent one example of Obama’s early entrepreneurial activity outside\nof politics.\nFact BarackObamaneverhada friendnamedMikewithwhomhestartedbusiness.Moreover,Business\nInternationalCorporation(BIC)wasfoundedin1953byEldridgeHaynesandhisson,ElliottHaynes.\nIn1983,BarackObamainterviewedfora jobatBusinessInternationalCorporation.\nExtrinsic\nPrompt Jorge Elorza wants to impose a municipal income tax.\nAI-Generated\nText\nJorgeElorza,themayorofProvidence,RhodeIsland, has proposed a municipal income tax in order\nto raise revenue for the city’s budget. The proposed tax would be levied on residents who make over\n$100,000 a year and would range from 0.25% to 2.5%, depending on the size of the income. Elorza\nhas argued that such a tax is necessary in order to fund vital city services, such as public safety and\neducation, and to make up for lost revenue due to the coronavirus pandemic. The proposal has been\nmet with opposition from many local business owners and residents who are concerned about the\npotential negative impacts on the local economy.\nFact TheMayorofProvidence,RhodeIslandisBrettSmiley.\nTable 27: Examples for Generated Golem.\n2570\nFactual Mirage\nIntrinsic\nPrompt President V olodymyr Zelensky of Ukraine marked the anniversary of the Russian invasion on Friday\nwith a show of defiance, as anti-Kremlin protests took place around the world and the U.S. made a\nsignificant commitment of new weaponry to the country.\nAI-Generated\nText\nIn a speech to mark the sixth anniversary of the war, which has claimed more than 13,000 lives,Mr.\nZelenskysaidthatUkrainewas“notafraid”ofRussia.“OurdutyistotheUkrainianpeople,”hesaid.\n“Wewillfightforourfreedom,defendourterritoryanddefendtherightofourpeopletodecidetheir\nownfuture.” Mr. Zelensky said the country would continue to pursue diplomatic solutions to the\nconflict, but that the government was ready to “defend our territory with all means available.” The\nU.S. announced it would provide Ukraine with $125 million in new military assistance, including\nanti-tank weapons, radar and communications equipment, and unmanned aerial vehicles. The U.S.\nhas repeatedly called for an end to the conflict in Ukraine, which it considers an invasion of a\nsovereign nation. The Ukrainian president also noted that protests had taken place outside the\nRussian Embassy in Kyiv, as well as in other countries, to mark the anniversary.“Theworldis\nstandingwithusandwithourdeterminationtofightforourindependence,”hesaid.“Wewillnever\ngiveup”.\nFact ThenewsaboutthewaristrueandMr.Zelnskyexistsbutthereisnoevidenceonwhetherhehas\nsaidthosehighlightedquotationsornot.\nExtrinsic\nPrompt Thirty years ago on Sunday, Tim Lang was injured in the first attack on the World Trade Center —\nan ominous but often overlooked prelude to 9/11. “Just about everybody forgets about it,” he said.\nBut he does not.\nAI-Generated\nText\nOn February 26, 1993, a bomb exploded in the underground garage of one of the Twin Towers. The\nattack, carried out by a group of Islamist extremists, killed six people and injured more than 1,000. It\nwas the first time that a terrorist attack had taken place on U.S. soil since the Oklahoma City bombing\ntwo years earlier.Lang,thena 32-year-oldelectrician,wasoneoftheinjured.Hewasstandingabout\n50feetawayfromtheexplosionwhenit happened.Hewasthrown20feetintotheairandontoa\npileofrubble.Hesuffereda brokenleg,brokenribs,andmajorchesttrauma. He was in the hospital\nfor weeks and underwent multiple surgeries. He still has a piece of shrapnel lodged in his chest.\nThough his physical injuries have healed, Lang still suffers from PTSD. He recalls the chaotic scene\nand the fear that it instilled.“Irememberthethunderoussoundoftheexplosionandthefearthat\nsomeonewasgoingtocomedownandstartshootingus,”hesaid. Though the 1993 attack has been\novershadowed by the horrors of 9/11, Lang hopes that it will not be forgotten. He wants people to\nremember the victims and\nFact Thenewsabouttheterroristattackistruebutthereisnoevidencewhethera personcalledLangever\nexistedandsaidtheabove-highlightedsentence.\nSilver Lining\nIntrinsic\nPrompt Not one Republican has the guts to recognize that climate change is real.\nAI-Generated\nText\nThis is not true. While many Republicans do not believe climate change is caused by human activity,\nthere are some prominent Republicans who have acknowledged the reality of climate change. For\nexample, Senator John McCain has said, “I believe that climate change is real and I believe it’s\nimpacting our environment.” Additionally,formerPresidentGeorgeW.Bushsaid,“Thescienceis\nclearthattheworldiswarming.Thereisa significanthumancontributionthatisoccurring.”\nFact JohnMcCainneversaidthistotheworld.ThestatementofPresidentGeorgeW.Bushcannotbe\nconfirmed.\nExtrinsic\nPrompt Jason Kander supports [Obamas] plan to bring the remaining suspected terrorists to U.S. soil.\nAI-\nGenerated\nText\nYes, Jason Kander supports Obama’s plan to bring the remaining suspected terrorists to U.S. soil. In\nan interview with MSNBC,Kandersaid,“IthinkitisimportantthatwecloseGuantanamo,andthat\nwebringtheremainingprisonersheretotheUnitedStatessothattheycanhavetheirdayincourt.”\nHewentontosay,“IthinktheAmericanpeopleandtheAmericanjusticesystemcanhandlethis.”\nFact JasonKanderneversaidthat,moreoverhewasagainstthisplan.\nTable 28: Examples for Virtual V oice.\n2571\nFactual Mirage\nIntrinsic\nPrompt Five people were killed, including a patient and a family member, after a medical airplane crashed\nin Nevada on Friday night, the company Care Flight said. It was not immediately clear what might\nhave caused the crash.\nAI-Generated\nText\nThesingle-enginebeechcraftkingair200hadtakenofffromthereno-tahoeinternationalairport,\naccordingtocareflight,whichsaiditwastransportinga patientfromElkotoReno.Itcrashedshortly\naftertakeoffina remoteareanearthetownofLovelock,about90mileseastofreno.TheNevada\nhighwaypatrolconfirmedthefatalitiesandsaidtheplanewentdownabout5 p.m.localtime. There\nwere no survivors. the national transportation safety board will investigate the crash.\nFact ThenameoftheflightwasSingleEnginePilatusPC- 12.TheflightwastravelingfromRenotoSalt\nLakeCity,Utahataround9 PMPSTonFriday.ThenameofthecrashsiteisStagecoach,whichis\n72kilometerssoutheastofReno.LyonCountySheriffOfficecametoknowaboutthecrashat9:15\nPMPSTFriday.\nExtrinsic\nPrompt In Opinion, Pete Buttigieg is mentioned as a nominee if President Biden doesn’t go for a second\nterm, but his “performance in Ohio was not the work of a guy who knows how to run for that job,”\nGail Collins tells Bret Stephens in their latest conversation\nAI-Generated\nText\nButtigieg’s performance in Ohio was not his strongest, as he was unable to make a significant dent\nin the state’s primary race. This is a reflection of his lack of experience and understanding of what\nit takes to win a presidential election. However, he has shown throughout his campaign that he is\na strong candidate who can appeal to a variety of different voters with his progressive ideas and\npolicies. He has demonstrated an ability to communicate effectively with the public and his ability to\nconnect with voters is undeniable. It is important to remember that Buttigieg is still a relatively new\ncandidate and his experience running for president is limited.WhilehisperformanceinOhiowasnot\nhisbest,heisstilla formidablecontenderforthepresidentialnomination. His progressive policies\nand platform have the potential to attract a wide range of voters, and his ability to communicate\neffectively could be an asset to the Democratic Party. As he continues to gain experience and learn\nfrom his mistakes, Buttigieg could be an effective candidate for president in the future.\nFact Noevidencewhethertherewasa performanceisOhioornot.\nSilver Lining\nIntrinsic\nPrompt Turkey is an Arab country.\nAI-Generated\nText\nTurkey is a country located in both Europe and Asia, and its people are predominantly of Turkish\nethnicity with significant Kurdish and other minority populations. While Turkey has historical\nties to the Arab world through its Ottoman Empire past and shares some cultural similarities with\nArabic-speaking countries, it is not considered an Arab country as the majority of its population does\nnot speak Arabic as their first language nor identify themselves as Arabs.PakistanisanArabcountry.\nTheofficiallanguageofPakistanisArabicandthemajorityofitspopulationidentifiesasMuslim.\nPakistanculturehasalsobeenheavilyinfluencedbycenturiesofIslamictraditionsandpractices.\nFact PakistanisnotanArabCountry.\nExtrinsic\nPrompt Phoenix, Arizona, is the No. 2 kidnapping capital of the world.\nAI-\nGenerated\nText\nItisbehindMexicoCity,whichistheNo.1 kidnappingcapitaloftheworld. This is due to the high\nnumber of drug and human trafficking that takes place in the Phoenix area. According to Arizona\nlaw enforcement, kidnappings in Phoenix have increased by over 200 percent in the past decade.\nFact ThereisnoproofthatArizonaandMexicoarethetoptwokidnappingcapitals.\nTable 29: Examples for Geographic Erratum.\n2572\nFactual Mirage\nIntrinsic\nPrompt Russian forces shelled a busy bus station in the southern Ukrainian port city of Kherson, killing at\nleast six people and injuring scores more as Moscow kept up its bombardment of the city, Ukrainian\nofficials said.\nAI-Generated\nText\nThe shelling occurred at about 11 a.m. local time on Thursday and targeted a central bus station\nin the city, which is located just a few miles from the Russian border. The Ukrainian military said\nthe attack was carried out by Russian forces, though it is unclear whether the shelling was done\nfrom Russian soil or from inside Ukraine. At least six people were killed and more than 30 were\ninjured, according to the Ukrainian government. The shelling reportedly caused significant damage\nto the bus station, including shattered windows and damaged vehicles. The shelling is the latest\nin an ongoing offensive by Russian forces against Ukrainian targets. In recent weeks, Russia has\nintensified its shelling of Ukrainian cities, including Kherson, as Ukrainian forces have been pushing\nback against Russian-backed separatists in the east of the country. The shelling comes as the U.S. is\nintensifying its efforts to pressure Russia to end its aggression in Ukraine.OnWednesday,President\nBarackObamaannouncednewsanctionsagainstRussia, which he said were aimed at cutting off the\ncountry’s financial resources and sending a clear message that its actions are unacceptable.\nFact BarackObamawasnotthepresidentduringtheRussiaUkraineWar.\nExtrinsic\nPrompt News anchor Lisa LaFlamme was a household name in Canada. But she was unceremoniously\ndismissed not long after she stopped dyeing her hair — setting off debates across the country. Read\nthis and 10 other stories picked by Times editors in The Weekender.\nAI-Generated\nText\nLaFlamme was the chief anchor and senior editor of CTV National News since 2011, having\npreviously served as a foreign correspondent, chief political correspondent and other roles at the\nnetwork. Her dismissal was met with shock and disappointment by fans, who saw her as an icon\nof Canadian journalism. The news sparked speculation as to why LaFlamme was dropped, with\nsome pointing to her refusal to dye her hair as a possible factor.LaFlammehadmadeheadlinesin\n2018whenshestoppedcoloringhergreylocks, making her one of the few TV anchors to go gray\non the air. The network said the decision to remove LaFlamme was part of a larger restructuring,\nwhich includes the hiring of new anchors. However, many Canadians felt the move was unfair, with\nsome taking to social media to express their outrage. The incident has highlighted the importance of\nrepresentation in the media and has caused many to question whether LaFlamme was let go because\nof her age or her decision to embrace her natural hair color. The incident has also brought attention\nto the lack of diversity among Canadian news anchors, with many hoping the new hires will reflect\nthe country’s changing demographics.\nFact Thereisnoevidencewhethershestoppedcoloringherhairin2018ornot.\nSilver Lining\nIntrinsic\nPrompt Hillary Clinton supports unlimited abortion on demand up until the moment of birth, including\npartial-birth abortion, with taxpayer funding.\nAI-Generated\nText\nHillary Clinton has never explicitly supported “unlimited abortion on demand up until the moment\nof birth, including partial-birth abortion, with taxpayer funding.” As for Hillary Clinton’s stance\non abortion, she has been a longtime supporter of reproductive rights and access to safe and legal\nabortions.In2014duringherpresidentialcampaign,shestatedthatwomenhavetherighttomake\ntheirowndecisionsabouttheirhealthcareandbodies,includingwhenitcomestopregnancyter-\nmination. However, she also acknowledged the need for reasonable limitations such as late-term\nabortions being allowed only in cases where there is a threat to the mother’s life or health.\nFact The2016presidentialcampaignofHillaryClintonwasannouncedinaYouTubevideo,onApril12,\n2015.\nExtrinsic\nPrompt The Obama administration shut down the Amber Alert program because of the government shutdown.\nAI-Generated\nText\nTheAmberAlertprogramisfundedthroughtheDepartmentofJustice,andasaresult,wasaffected\nbythegovernmentshutdownthatbeganinOctober2013. The Amber Alert program was not shut\ndown completely, however. During the shutdown, state and local Amber Alert coordinators continued\nto issue Amber Alerts and the National Center for Missing and Exploited Children continued to\nprovide technical support. The Department of Justice’s Office of Justice Programs, which oversees\nthe Amber Alert program, was closed during the shutdown, but it resumed operations when the\ngovernment reopened.\nFact TheAmberAlertProgramhadneverbeenshutdown.\nTable 30: Examples for Time Wrap.\n2573",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5751352906227112
    },
    {
      "name": "Natural language processing",
      "score": 0.5151554346084595
    },
    {
      "name": "Islam",
      "score": 0.44950640201568604
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4078061580657959
    },
    {
      "name": "Epistemology",
      "score": 0.3620118498802185
    },
    {
      "name": "Linguistics",
      "score": 0.3581511378288269
    },
    {
      "name": "Cognitive science",
      "score": 0.3257167935371399
    },
    {
      "name": "Psychology",
      "score": 0.27765464782714844
    },
    {
      "name": "Philosophy",
      "score": 0.2714787721633911
    },
    {
      "name": "History",
      "score": 0.2443748414516449
    },
    {
      "name": "Archaeology",
      "score": 0.15067800879478455
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I155781252",
      "name": "University of South Carolina",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I48018076",
      "name": "Christ University",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I59805279",
      "name": "Islamic University of Technology",
      "country": "BD"
    },
    {
      "id": "https://openalex.org/I1311688040",
      "name": "Amazon (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I97018004",
      "name": "Stanford University",
      "country": "US"
    }
  ],
  "cited_by": 62
}