{
  "title": "Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment",
  "url": "https://openalex.org/W3035121469",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2106168979",
      "name": "Forrest Davis",
      "affiliations": [
        "Cornell University"
      ]
    },
    {
      "id": "https://openalex.org/A1976982077",
      "name": "Marten van Schijndel",
      "affiliations": [
        "Cornell University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2923014074",
    "https://openalex.org/W2964243640",
    "https://openalex.org/W2164418233",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2990704537",
    "https://openalex.org/W2977559956",
    "https://openalex.org/W2054125330",
    "https://openalex.org/W2972896975",
    "https://openalex.org/W3020712669",
    "https://openalex.org/W2973723395",
    "https://openalex.org/W2963614302",
    "https://openalex.org/W2978282951",
    "https://openalex.org/W2963751529",
    "https://openalex.org/W4399650694",
    "https://openalex.org/W2945185449",
    "https://openalex.org/W2100337446",
    "https://openalex.org/W4234704313",
    "https://openalex.org/W2887020936",
    "https://openalex.org/W2531882892",
    "https://openalex.org/W2951483775",
    "https://openalex.org/W2120253962",
    "https://openalex.org/W2964194677",
    "https://openalex.org/W2993383518",
    "https://openalex.org/W2986128786",
    "https://openalex.org/W2119728020",
    "https://openalex.org/W2963351454",
    "https://openalex.org/W4295371519",
    "https://openalex.org/W2898936689",
    "https://openalex.org/W2963310665",
    "https://openalex.org/W2033247429",
    "https://openalex.org/W2148748716",
    "https://openalex.org/W2963809228",
    "https://openalex.org/W1978662219",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W1522263329",
    "https://openalex.org/W1995875735",
    "https://openalex.org/W2943552823",
    "https://openalex.org/W2803589147",
    "https://openalex.org/W38462120",
    "https://openalex.org/W4320930643",
    "https://openalex.org/W2942054564",
    "https://openalex.org/W2971016963",
    "https://openalex.org/W4288104054",
    "https://openalex.org/W2625014264",
    "https://openalex.org/W2891399254",
    "https://openalex.org/W2400674239",
    "https://openalex.org/W2788924045",
    "https://openalex.org/W2055886042",
    "https://openalex.org/W2963202576",
    "https://openalex.org/W2549835527",
    "https://openalex.org/W3100307207",
    "https://openalex.org/W2738593413",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2886663262",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W2108010971",
    "https://openalex.org/W2768794963",
    "https://openalex.org/W4289552613"
  ],
  "abstract": "A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations, where stark grammaticality differences are absent. We compare model performance in English and Spanish to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in English but not Spanish. Thus, English models may appear to acquire human-like syntactic preferences, while models trained on Spanish fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between comprehension (i.e. typical language model use cases) and production (which generates the training data for language models), suggesting that necessary linguistic biases are not present in the training signal at all.",
  "full_text": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1979–1990\nJuly 5 - 10, 2020.c⃝2020 Association for Computational Linguistics\n1979\nRecurrent Neural Network Language Models Always Learn English-Like\nRelative Clause Attachment\nForrest Davis and Marten van Schijndel\nDepartment of Linguistics\nCornell University\n{fd252|mv443}@cornell.edu\nAbstract\nA standard approach to evaluating language\nmodels analyzes how models assign proba-\nbilities to valid versus invalid syntactic con-\nstructions (i.e. is a grammatical sentence more\nprobable than an ungrammatical sentence).\nOur work uses ambiguous relative clause at-\ntachment to extend such evaluations to cases\nof multiple simultaneous valid interpretations,\nwhere stark grammaticality differences are ab-\nsent. We compare model performance in En-\nglish and Spanish to show that non-linguistic\nbiases in RNN LMs advantageously overlap\nwith syntactic structure in English but not\nSpanish. Thus, English models may appear\nto acquire human-like syntactic preferences,\nwhile models trained on Spanish fail to acquire\ncomparable human-like preferences. We con-\nclude by relating these results to broader con-\ncerns about the relationship between compre-\nhension (i.e. typical language model use cases)\nand production (which generates the training\ndata for language models), suggesting that nec-\nessary linguistic biases are not present in the\ntraining signal at all.\n1 Introduction\nLanguage modeling is widely used as pretraining\nfor many tasks involving language processing (Pe-\nters et al., 2018; Radford et al., 2018; Devlin et al.,\n2019). Since such pretraining affects so many tasks,\neffective evaluations to assess model quality are\ncritical. Researchers in the vein of the present study,\ntypically take (pretrained) language models and ask\nwhether those models have learned some linguistic\nphenomenon (e.g., subject-verb agreement). Of-\nten the task is operationalized as: do the models\nmatch some human baseline (e.g., acceptability\njudgments, reading times, comprehension ques-\ntions) measured as humans experience this linguis-\ntic phenomenon (e.g., comparing acceptability rat-\nings of sentences with grammatical/ungrammatical\nagreement). This approach tacitly assumes that the\nnecessary linguistic biases are in the training signal\nand then asks whether the models learn the same\nabstract representations as humans given this sig-\nnal. The present study casts doubt on the notion\nthat the necessary linguistic biases are present in\nthe training signal at all.\nWe utilize the, now common, evaluation tech-\nnique of checking whether a model assigns higher\nprobability to grammatical sentences compared\nto ungrammatical sentences (Linzen et al., 2016).\nHowever, we extend beyond binary grammaticality.\nReal world applications demand that our models\nnot only know the difference between valid and in-\nvalid sentences; they must also be able to correctly\nprioritize simultaneous valid interpretations (Lau\net al., 2017). In this paper, we investigate whether\nneural networks can in fact prioritize simultaneous\ninterpretations in a human-like way. In particular,\nwe probe the biases of neural networks for ambigu-\nous relative clause (RC) attachments, such as the\nfollowing:\n(1) Andrew had dinner yesterday with the\nnephew of the teacher that was divorced.\n(from Fern´andez, 2003)\nIn (1), there are two nominals (nephew and teacher)\nthat are available for modiﬁcation by the RC (that\nwas divorced). We refer to attachment of the RC\nto the syntactically higher nominal (i.e. the nephew\nis divorced) as HIGH and attachment to the lower\nnominal (i.e. the teacher is divorced) as LOW.\nAs both interpretations are equally semantically\nplausible when no supporting context is given, we\nmight expect that humans choose between HIGH\nand LOW at chance. However, it has been widely\nestablished that English speakers tend to interpret\nthe relative clause as modifying the lower nomi-\nnal more often than the higher nominal (i.e. they\n1980\nhave a LOW bias;1 Carreiras and Clifton Jr, 1993;\nFrazier and Clifton, 1996; Carreiras and Clifton,\n1999; Fern´andez, 2003). LOW bias is actually ty-\npologically much rarer than HIGH bias (Brysbaert\nand Mitchell, 1996). A proto-typical example of\na language with HIGH attachment bias is Spanish\n(see Carreiras and Clifton Jr, 1993; Carreiras and\nClifton, 1999; Fern´andez, 2003).\nA growing body of literature has shown that\nEnglish linguistic structures conveniently overlap\nwith non-linguistic biases in neural language mod-\nels leading to performance advantages for mod-\nels of English, without such models being able\nto learn comparable structures in non-English-like\nlanguages (e.g., Dyer et al., 2019). This, cou-\npled with recent work showing that such mod-\nels have a strong recency bias (Ravfogel et al.,\n2019), suggests that one of these attachment types\n(LOW), will be more easily learned. Therefore,\nthe models might appear to perform in a human-\nlike fashion on English, while failing on the cross-\nlinguistically more common attachment preference\n(HIGH) found in Spanish. The present study inves-\ntigates these concerns by ﬁrst establishing, via a\nsynthetic language experiment, that recurrent neu-\nral network (RNN) language models (LMs) are ca-\npable of learning either type of attachment (Section\n4). However, we then demonstrate that these mod-\nels consistently exhibit a LOW preference when\ntrained on actual corpus data in multiple languages\n(English and Spanish; Sections 5–7).\nIn comparing English and Spanish, we show that\nnon-linguistic biases in RNN LMs overlap with\ninterpretation biases in English to appear as though\nthe models have acquired English syntax, while\nfailing to acquire minimally different interpretation\nbiases in Spanish. Concretely, English attachment\npreferences favor the most recent nominal, which\naligns with a general preference in RNN LMs for\nattaching to the most recent nominal. In Spanish,\nthis general recency preference in the models re-\nmains despite a HIGH attachment interpretation\nbias in humans. These results raise broader ques-\ntions regarding the relationship between compre-\nhension (i.e. typical language model use cases) and\nproduction (which generates the training data for\nlanguage models) and point to a deeper inability of\nRNN LMs to learn aspects of linguistic structure\nfrom raw text alone.\n1We use “bias” throughout this paper to refer to “inter-\npretation bias.” We will return to the distinction between\nproduction bias and interpretation bias in Section 8.\n2 Related Work\nMuch recent work has probed RNN LMs for their\nability to represent syntactic phenomena. In par-\nticular, subject-verb agreement has been explored\nextensively (e.g., Linzen et al., 2016; Bernardy and\nLappin, 2017; Enguehard et al., 2017) with results\nat human level performance in some cases (Gulor-\ndava et al., 2018). However, additional studies have\nfound that the models are unable to generalize se-\nquential patterns to longer or shorter sequences that\nshare the same abstract constructions (Trask et al.,\n2018; van Schijndel et al., 2019). This suggests\nthat the learned syntactic representations are very\nbrittle.\nDespite this brittleness, RNN LMs have been\nclaimed to exhibit human-like behavior when pro-\ncessing garden path constructions (van Schijndel\nand Linzen, 2018; Futrell and Levy, 2019; Frank\nand Hoeks, 2019), reﬂexive pronouns and nega-\ntive polarity items (Futrell et al., 2018), and center\nembedding and syntactic islands (Wilcox et al.,\n2019, 2018). There are some cases, like coordi-\nnation islands, where RNN behavior is distinctly\nnon-human (see Wilcox et al., 2018), but in gen-\neral this literature suggests that RNN LMs encode\nsome type of abstract syntactic representation (e.g.,\nPrasad et al., 2019). Thus far though, the linguistic\nstructures used to probe RNN LMs have often been\nthose with unambiguously ungrammatical counter-\nparts. This extends into the domain of semantics,\nwhere downstream evaluation platforms like GLUE\nand SuperGLUE evaluate LMs for correct vs. in-\ncorrect interpretations on tasks targeting language\nunderstanding (Wang et al., 2018, 2019).\nSome recent work has relaxed this binary distinc-\ntion of correct vs. incorrect or grammatical vs. un-\ngrammatical. Lau et al. (2017) correlate acceptabil-\nity scores generated from a LM to average human\nacceptability ratings, suggesting that human-like\ngradient syntactic knowledge can be captured by\nsuch models. Futrell and Levy (2019) also look\nat gradient acceptability in both RNN LMs and\nhumans, by focusing on alternations of syntactic\nconstituency order (e.g., heavy NP shift, dative al-\nternation). Their results suggest that RNN LMs\nacquire soft constraints on word ordering, like hu-\nmans. However, the alternations in Futrell and\nLevy, while varying in their degree of acceptability,\nmaintain the same syntactic relations throughout\nthe alternation (e.g., gave a book to Tomand gave\nTom a bookboth preserve the fact that Tom is the\n1981\nindirect object). Our work expands this line of re-\nsearch by probing how RNN LMs behave when\nmultiple valid interpretations, with crucially differ-\nent syntactic relations, are available within a single\nsentence. We ﬁnd that RNN LMs do not resolve\nsuch ambiguity in a human-like way.\nThere are, of course, a number of other modeling\napproaches that exist in the current literature; the\nmost notable of these being BERT (Devlin et al.,\n2019). These transformer models have achieved\nhigh performance on a variety of natural language\nprocessing tasks, however, there are a number of\nproperties that make them less suitable to this work.\nOne immediate consideration is that of training.\nWe are interested in the behavior of a class of mod-\nels, so we analyze the behavior of several randomly\ninitialized models. We do not know how repre-\nsentative BERT is of models of its same class,\nand training more BERT variants is immensely\ntime consuming and environmentally detrimental\n(Strubell et al., 2019). Additionally, we are inter-\nested in probability distributions over individual\nwords given the preceding context, something that\nis not part of BERT’s training as it takes whole\nsentences as input. Finally, the bidirectional nature\nof many of these models makes their representa-\ntions difﬁcult to compare to humans. For these\nreasons, we restrict our analyses to unidirectional\nRNN LMs. This necessarily reduces the generaliz-\nability of our claims. However, we still believe this\nwork has broader implications for probing what as-\npects of linguistic representations neural networks\ncan acquire using standard training data.\n3 Methods\n3.1 Experimental Stimuli\nIn the present study, we compare the attachment\npreferences of RNN LMs to those established in\nFern´andez (2003). Fern´andez demonstrated that hu-\nmans have consistent RC attachment biases using\nboth self-paced reading and ofﬂine comprehension\nquestions. They tested both English and Spanish\nmonolinguals (along with bilinguals) using parallel\nstimuli across the two languages, which we adopt\nin the experiments in this paper.2\nSpeciﬁcally, Fern´andez (2003) included 24 items\nper language, 12 with a singular RC verb (was) and\n12 with a plural RC verb (were). The English and\n2All experimental stimuli and models used are avail-\nable at https://github.com/forrestdavis/\nAmbiAttach\nSpanish stimuli are translations of each other, so\nthey stand as minimal pairs for attachment prefer-\nences. Example stimuli are given below.\n(2) a. Andrew had dinner yesterday with the\nnephew of the teachers that was di-\nvorced.\nb. Andrew had dinner yesterday with the\nnephews of the teacher that was di-\nvorced.\nc. Andr´e cen´o ayer con el sobrino de los\nmaestros que estaba divorciado.\nd. Andr´e cen´o ayer con los sobrinos del\nmaestro que estaba divorciado.\nThe underlined nominal above marks the attach-\nment point of the relative clause ( that was di-\nvorced). (2-a) and (2-c) exhibit HIGH attachment,\nwhile (2-b) and (2-d) exhibit LOW attachment.\nFern´andez found that English speakers had a LOW\nbias, preferring (2-b) over (2-a), while Spanish\nspeakers had a HIGH bias, preferring (2-c) over\n(2-d).\nWe ran two experiments per language,3 one a di-\nrect simulation of the experiment from Fern´andez\n(2003) and the other an extension ( EXTENDED\nDATA), using a larger set of experimental stim-\nuli. The direct simulation allowed us to compare\nthe attachment preferences for RNN LMs to the\nexperimental results for humans. The extension\nallowed us to conﬁrm that any attachment prefer-\nences we observed were generalizable properties\nof these models.\nSpeciﬁcally, the EXTENDED DATA set of stim-\nuli included the English and Spanish stimuli from\nCarreiras and Clifton Jr (1993) in addition to the\nstimuli from Fern ´andez (2003), for a total of 40\nsentences. Next, we assigned part-of-speech tags\nto the English and Spanish LM training data us-\ning TreeTagger (Schmid, 1999). We ﬁltered the\ntokens to the top 40 most frequent plural nouns,\ngenerating the singular forms from TreeTagger’s\nlemmatization. We then substituted into the test\nsentences all combinations of distinct nouns exclud-\ning reﬂexives. Then we appended a relative clause\nwith either a singular or plural verb (was/were or\n3The vocabulary of the models was constrained to the 50K\nmost frequent words during training. Out-of-vocabulary nom-\ninals in the original stimuli were replaced with semantically\nsimilar nominals. In English, lid(s) to cover(s) and reﬁll(s) to\nﬁller(s). In Spanish, sarc ´ofago(s) to ata´ud(es), recambio(s) to\nsustituci´on(es), fregadero(s) to lavabo(s), ba´ul(es) to caja(s),\ncacerola(s) to platillo(s), and bol´ıgrafo(s) to pluma(s)\n1982\nestaba/estaban).4 Finally, each test stimulus in a\npair had a LOW and HIGH attachment version for a\ntotal of 249600 sentences. An example of four sen-\ntences generated for English given the two nouns\nbuilding and system is below.\n(3) a. Everybody ignored the system of the\nbuildings that was\nb. Everybody ignored the systems of the\nbuilding that was\nc. Everybody ignored the system of the\nbuildings that were\nd. Everybody ignored the systems of the\nbuilding that were\nNot all combinations are semantically coherent;\nhowever, Gulordava et al. suggest that syntactic\noperations (e.g., subject-verb agreement) are still\npossible for RNN LMs with “completely meaning-\nless” sentences (Gulordava et al., 2018, p. 2).\n3.2 RNN LM Details\nWe analyzed long short-term memory networks\n(LSTMs; Hochreiter and Schmidhuber, 1997)\nthroughout the present paper. For English, we used\nthe English Wikipedia training data provided by\nGulordava et al. (2018). 5 For Spanish, we con-\nstructed a comparable training corpus from Span-\nish Wikipedia following the process used by Gu-\nlordava et al. (2018). A recent dump of Spanish\nWikipedia was downloaded, raw text was extracted\nusing WikiExtractor,6 and tokenization was done\nusing TreeTagger. A 100-million word subset of the\ndata was extracted, shufﬂed by sentence, and split\ninto training (80%) and validation (10%) sets.7 For\nLM training, we included the 50K most frequent\nwords in the vocabulary, replacing the other tokens\nwith ‘⟨UNK⟩’.\nWe used the best English model in Gulordava\net al. (2018) and trained 4 additional models with\nthe same architecture8 but different random initial-\nizations. There was no established Spanish model\narchitecture, so we took the best Romance model\n4Since the unidirectional models are tested at the RC verb,\nwe did not need to generate the rest of the sentence after that\nverb.\n5https://github.com/facebookresearch/\ncolorlessgreenRNNs\n6https://github.com/attardi/\nwikiextractor\n7We also created a test partition (10% of our data), which\nwe did not use in this work.\n8The models had 2 layers, 650 hidden/embedding units,\nbatch size 128, dropout 0.2, and an initial learning rate of 20.\nLanguage µ σ\nSynthetic 4.62 0.03\nEnglish 51.83 0.96\nSpanish 40.80 0.89\nTable 1: Mean and standard deviation of LM validation\nperplexity for the synthetic models used in Section 4,\nthe English models used in Section 5-6, and the Span-\nish models used in Section 7\narchitecture9 reported in Gulordava et al. (2018)\nand trained 5 models. All models used in this work\nwere trained for 40 epochs with resultant mean vali-\ndation perplexities and standard deviations in Table\n1.\n3.3 Measures\nWe evaluated the RNN LMs using information-\ntheoretic surprisal (Shannon, 1948; Hale, 2001;\nLevy, 2008). Surprisal is deﬁned as the inverse\nlog probability assigned to each word ( wi) in a\nsentence given the preceding context.\nsurprisal(wi) =−log p(wi|w1...wi−1)\nThe probability is calculated by applying the\nsoftmax function to an RNN’s output layer. Sur-\nprisal has been correlated with human process-\ning difﬁculty (Smith and Levy, 2013; Frank et al.,\n2015) allowing us to compare model behavior to\nhuman behavior. Each of the experiments done\nin this work looked at sentences that differed in\nthe grammatical number of the nominals, repeated\nfrom Section 3.1 below.\n(4) a. Andrew had dinner yesterday with the\nnephew of the teachers that was di-\nvorced.\nb. Andrew had dinner yesterday with the\nnephews of the teacher that was di-\nvorced.\n(from Fern´andez, 2003)\nIn (4-a) the RC verb (was) agrees with the HIGH\nnominal, while in (4-b) it agrees with the LOW\nnominal. As such, this minimal pair probes the\ninterpretation bias induced by the relativizer (that).\nWe measure the surprisal of the RC verb (was)\nin both sentences of the pair. If the model has a\npreference for LOW attachment, then we expect\nthat the surprisal will be smaller when the number\n9They focused on Italian as a Romance language. The\nmodels are the same as English except the batch size is 64.\n1983\nof the ﬁnal noun agrees with the number of the RC\nverb (e.g., surprisal (4-b) <surprisal (4-a)). Con-\ncretely, for each such pair we take the difference\nin surprisal of the RC verb in the case of HIGH\nattachment (4-a) from the surprisal of the RC verb\nin the case of LOW attachment (4-b). If this differ-\nence (surprisal (4-a) - surprisal (4-b)) is positive,\nthen the LM has a LOW bias, and if the difference\nis negative, the LM has a HIGH bias.\n4 Attachment vs. Recency\nWe begin with a proof of concept. It has been noted\nthat RNN LMs have a strong recency bias (Rav-\nfogel et al., 2019). As such, it could be possible\nthat only one type of attachment, namely LOW\nattachment, is learnable. To investigate this pos-\nsibility, we followed the methodology in McCoy\net al. (2018) and constructed a synthetic language\nto control the distribution of RC attachment in two\nexperiments. Our ﬁrst experiment targeted the ques-\ntion: if all RC attachment is HIGH, how many RCs\nhave to be observed in training in order for a HIGH\nbias to generalize to unseen data? Our second ex-\nperiment targeted the question: what proportion of\nHIGH and LOW attachment is needed in training\nto learn a bias?\nOur synthetic language had RC attachment sen-\ntences and ﬁller declarative sentences. The ﬁller\nsentences follow the phrase structure template\ngiven in (5-a), while RC attachment sentences fol-\nlow the phrase structure template given in (5-b).\n(5) a. D N (P D N) (Aux) V (D N) (P D N)\nb. D N Aux V D N ‘of’ D N ‘that’\n‘was/were’ V\nMaterial in parentheses was optional and so was\nnot present in all ﬁller stimuli. That is to say, all\nﬁller sentences had a subject (abbreviated D N)\nand a verb (abbreviated V), with the verb being\noptionally transitive and followed by a direct ob-\nject (D N). The subject, object, or both could be\nmodiﬁed by a prepositional phrase (P D N). The\nsubject and object could be either singular or plu-\nral, with the optional auxiliary (Aux) agreeing in\nnumber with the subject. There were 30 nouns (N;\n60 with plural forms), 2 auxiliaries (Aux; was/were\nand has/had), 1 determiner (D; the), 14 verbs (V),\nand 4 prepositions (P). An example ﬁller sentence\nis given in (6-a), and an example RC sentence is\ngiven in (6-b).\n(6) a. The nephew near the children was seen\nby the players next to the lawyer.\nb. The gymnast has met the hostage of\nthe women that was eating.\nWe trained RNN LMs on our synthetic language us-\ning the same parameters as the English LMs given\nin Section 3.2, with 120,000 unique sentences in\nthe training corpus. The resultant RNN LMs were\ntested on 300 sentences with ambiguous RC at-\ntachment, and we measured the surprisal at the RC\nauxiliary verb (was/were), following the methodol-\nogy given in Section 3.3.\nTo determine how many HIGH RCs were needed\nin training to learn a HIGH bias, we ﬁrst con-\nstrained all the RC attachment in the training data\nto HIGH attachment. Then, we varied the propor-\ntion (in increments of 10 RC sentences at a time)\nof RC sentences to ﬁller sentences during training.\nWe trained 5 RNNs for each training conﬁguration\n(i.e. each proportion of RCs). This experiment pro-\nvided a lower bound on the number of HIGH RCs\nneeded in the training data to overcome any RNN\nrecency bias when all RCs exhibited HIGH attach-\nment. When as little as 0.017% (20 sentences)\nof the data contained RCs with HIGH attachment,\nthe test difference in surprisal between HIGH and\nLOW attachment signiﬁcantly differed from zero\n(p <10−5, BayesFactor (BF) > 100),10 with a\nmean difference less than zero (µ= −2.24). These\nresults indicate that the models were able to ac-\nquire a HIGH bias with only 20/120000 examples\nof HIGH RC attachment.\nIn practice, we would like LMs to learn a prefer-\nence even when the training data contains a mixture\nof HIGH and LOW attachment. To determine the\nproportion of RCs that must be HIGH to learn a\nHIGH bias, we ﬁxed 10% of the training data as\nunambiguous RC attachment. Within that 10%, we\nvaried the proportion of HIGH and LOW attach-\nment in 10% increments (i.e. 0% HIGH - 100%\nLOW, 10% HIGH - 90% LOW, etc). Once again,\nwe trained 5 models on each training conﬁgura-\ntion and tested those models on 300 test sentences,\nmeasuring the surprisal at the RC verb. When\n10To correct for multiple comparisons, a Bonferroni correc-\ntion with m = 6was used. Thus, the threshold for statistical\nsigniﬁcance was p = 0.0083. We also computed two-sample\nBayes Factors (BF; Rouder et al., 2009) for each statistical\nanalysis using ttestBF from the BayesFactor R pack-\nage (Morey and Rouder, 2018). A Bayes Factor greater than\n10 is signiﬁcant evidence for the hypothesis, while one greater\nthan 100 is highly signiﬁcant.\n1984\nthe training data had 50-100% HIGH attachment,\nthe models preferred HIGH attachment in all the\ntest sentences. Conversely, when the training data\nhad 0-40% HIGH attachment, the models preferred\nLOW attachment in all test sentences.\nTaken together, the results from our synthetic\nlanguage experiments suggest that HIGH attach-\nment is indeed learnable by RNN LMs. In fact, an\nequal proportion of HIGH and LOW attachment\nin the training data is all that is needed for these\nmodels to acquire a general preference for HIGH\nattachment (contra to the recency bias reported in\nthe literature).\n5 English Experiments\nWe turn now to model attachment preferences in\nEnglish. We trained the models using English\nWikipedia. We tested the attachment preferences\nof the RNN LMs using the original stimuli from\nFern´andez (2003), and using a larger set of stimuli\nto have a better sense of model behavior on a wider\nrange of stimuli. For space considerations, we only\nreport here results of the EXTENDED DATA (the\nlarger set of stimuli), but similar results hold for\nthe Fern ´andez (2003) stimuli (see Supplemental\nMaterials).\nIn order to compare the model results with\nthe mean human interpretation results reported\nby Fern´andez (2003), we categorically coded the\nmodel response to each item for HIGH/LOW at-\ntachment preference. If model surprisal for LOW\nattachment was less than model surprisal for HIGH\nattachment, the attachment was coded as LOW. See\nFigure 1 for the comparison between RNNs and\nhumans in English.\nStatistical robustness for our RNN results was\ndetermined using the original distribution of sur-\nprisal values. Speciﬁcally, a two-tailed t-test was\nconducted to see if the mean difference in surprisal\ndiffered from zero (i.e. the model has some at-\ntachment bias). This revealed a highly signiﬁcant\n(p < 10−5, BF > 100) mean difference in sur-\nprisal of 0.77. This positive difference indicates\nthat the RNN LMs have a consistent LOW bias,\nsimilar to English readers, across models trained\nwith differing random seeds.\nThere are two possible reasons for this pattern-\ning: (1) the models have learned a human-like\nLOW bias, or (2) the models have a recency bias\nthat favors attachment to the lower nominal. These\ntwo hypotheses have overlapping predictions in\nFigure 1: Proportion HIGH vs LOW attachment in\nEnglish. Human results from the original Fern ´andez\n(2003) experiment and RNN LM results from E X-\nTENDED DATA (derived from Fern ´andez (2003) and\nCarreiras and Clifton Jr (1993)).\nEnglish. The second hypothesis is perhaps weak-\nened by the results of Section 4, where both at-\ntachment types were learnable despite any recency\nbias. However, we know that other syntactic at-\ntachment biases can inﬂuence RC attachment in\nhumans (Scheepers, 2003). It could be that other\nkinds of attachment (such as prepositional phrase\nattachment) have varying proportions of attachment\nbiases in the training data. Perhaps conﬂicting at-\ntachment biases across multiple constructions force\nthe model to resort to the use of a ‘default’ recency\nbias in cases of ambiguity.\n6 Syntactically blocking low attachment\n6.1 Stimuli\nTo determine whether the behavior of the RNNs\nis driven by a learned attachment preference or a\nstrong recency bias, we created stimuli11 using the\nstimulus template described in Section 3.1 (e.g.,\n(3)). All of these stimuli had only the higher nomi-\nnal syntactically available for attachment; the lower\nnominal was blocked by the addition of a relative\nclause:\n(7) a. Everybody ignored the boy that the\ngirls hated that was boring.\nb. * Everybody ignored the boys that the\ngirl hated that was boring.\nIn (7) only (7-a) is grammatical. This follows be-\ncause boy(s) is the only nominal available for mod-\n11As before, some of these stimuli are infelicitous. We do\nnot concern ourselves with this distinction in the present work,\ngiven the results in Gulordava et al. (2018).\n1985\nFigure 2: Proportion HIGH vs LOW attachment with\nsyntactically unavailable lower nominal. Human re-\nsults estimated from Linzen and Leonard (2018) and\nRNN LM results from the E XTENDED DATA (derived\nfrom Fern ´andez (2003) and Carreiras and Clifton Jr\n(1993)) with the lower nominal blocked.\niﬁcation. In (7-a), the RC verb was agrees in num-\nber with this nominal, while in (7-b), was agrees in\nnumber with the now blocked lower nominal girl\nrather than with boys. For all such sentence pairs,\nwe calculated the difference in surprisal between\n(7-a) and (7-b). If their behavior is driven by a legit-\nimate syntactic attachment preference, the models\nshould exhibit an overwhelming HIGH bias (i.e.\nthe mean difference should be less than zero).\n6.2 Results\nAs before, the differences in surprisal were calcu-\nlated for each pair of experimental items. If the\ndifference was greater than zero, the attachment\nwas coded as LOW. The results categorically coded\nfor HIGH/LOW attachment are given in Figure 2,\nincluding the results expected for humans given\nthe pattern in Linzen and Leonard (2018). 12 A\ntwo-tailed t-test was conducted to see if the mean\ndifference in surprisal differed from zero. The re-\nsults were statistically signiﬁcant ( p <10−5, BF\n>100). The mean difference in surprisal was 1.15,\nhowever, suggesting that the models still had a\nLOW bias when the lower nominal was syntacti-\ncally unavailable for attachment. This is in stark\ncontrast to what one would expect if these models\nhad learned the relationship between syntactic con-\nstituents and relative clause attachment. A possible\n12Linzen and Leonard (2018) conducted experiments prob-\ning the agreement errors for subject-verb agreement with in-\ntervening RCs (and prepositional phrases). Our work is con-\ncerned with agreement between an object and its modifying\nRC. As such, their task serves as an approximate estimate of\nthe errors we would expect for humans.\nFigure 3: Proportion HIGH vs LOW attachment in\nSpanish. Human results from the original Fern ´andez\n(2003) experiment and RNN LM results from the E X-\nTENDED DATA (derived from Fern ´andez (2003) and\nCarreiras and Clifton Jr (1993)).\nalternative to the recency bias explanation is that\nRNN LMs might learn that there is a general LOW\nattachment bias in English and overgeneralize this\npattern even in cases where one of the nominals is\nsyntactically unavailable.\n7 The case of default HIGH bias:\nSpanish\nOur English analyses suggest that RNN LMs either\nlearn a general English LOW attachment prefer-\nence that they apply in all contexts, or that they\nhave a ‘default’ recency bias that prevents them\nfrom learning HIGH attachment preferences with\nmore complex, naturalistic training data. In the\ncase of the former, we would expect that models\ntrained on a language whose speakers generally pre-\nfer HIGH attachment should be able to learn HIGH\nattachment. Spanish has a well-attested HIGH bias\nin humans (Carreiras and Clifton Jr, 1993; Car-\nreiras and Clifton, 1999; Fern´andez, 2003) offering\na way to distinguish between competing recency\nbias and over-generalization accounts. That is, if\nthe models can learn a HIGH bias when trained on\nSpanish data, we should be able to conclude that\nthe general LOW bias in English is being overgen-\neralized by the RNNs to corner cases where HIGH\nbias should be preferred.\n7.1 Results\nAs before, the differences in surprisal were calcu-\nlated for each pair of experimental items. If the dif-\nference was greater than zero, the attachment was\ncoded as LOW. Two sample t-tests were conducted\nto see if the mean difference in surprisal differed\n1986\nsigniﬁcantly from zero for both the direct simula-\ntion of Fern´andez (2003) and theEXTENDED DATA\nthat included the stimuli derived from Carreiras and\nClifton Jr (1993). The results categorically coded\nfor HIGH/LOW attachment for the extended stimu-\nlus set are given in Figure 3, alongside the human\nresults reported in Fern´andez (2003).\nFor the direct simulation, the mean did not differ\nsigniﬁcantly from 0 (BF < 1/3). This suggests\nthat there is no attachment bias for the Spanish\nmodels for the stimuli from Fern´andez (2003), con-\ntrary to the human results. For the extended set of\nstimuli, the results were signiﬁcant (p< 10−5, BF\n> 100) with a mean difference greater than zero\n(µ = 0.211). Thus, rather than a HIGH bias, as\nwe would expect, the RNN LMs once again had a\nLOW bias.\n8 Discussion\nIn this work, we explored the ability of RNN LMs\nto prioritize multiple simultaneous valid interpre-\ntations in a human-like way (as in John met the\nstudent of the teacher that was happy). While\nboth LOW attachment (i.e. the teacher was happy)\nand HIGH attachment (i.e. the student was happy)\nare equally semantically plausible without a dis-\nambiguating context, humans have interpretation\npreferences for one attachment over the other (e.g.,\nEnglish speakers prefer LOW attachment and Span-\nish speakers prefer HIGH attachment). Given the\nrecent body of literature suggesting that RNN LMs\nhave learned abstract syntactic representations, we\ntested the hypothesis that these models acquire\nhuman-like attachment preferences. We found that\nthey do not.\nWe ﬁrst used a synthetic language experiment to\ndemonstrate that RNN LMs are capable of learning\na HIGH bias when HIGH attachment is at least as\nfrequent as LOW attachment in the training data.\nThese results suggest that any recency bias in RNN\nLMs is weak enough to be easily overcome by suf-\nﬁcient evidence of HIGH attachment. In English,\nthe RNNs exhibited a human-like LOW bias, but\nthis preference persisted even in cases where LOW\nattachment was ungrammatical. To test whether the\nRNNs were over-learning a general LOW bias of\nEnglish, we tested whether Spanish RNNs learned\nthe general HIGH bias in that language. Once\nagain, RNN LMs favored LOW attachment over\nHIGH attachment. The inability of RNN LMs to\nlearn the Spanish HIGH attachment preference sug-\ngests that the Spanish data may not contain enough\nHIGH examples to learn human-like attachment\npreferences.\nIn post-hoc analyses of the Spanish Wikipedia\ntraining corpus and the AnCora Spanish newswire\ncorpus (Taul´e et al., 2008), we ﬁnd a consistent\nproduction bias towards LOW attachment among\nthe RCs with unambiguous attachment. In Spanish\nWikipedia, LOW attachment is 69% more frequent\nthan HIGH attachment, and in Spanish newswire\ndata, LOW attachment is 21% more frequent than\nHIGH attachment. 13 This distributional bias in\nfavor of LOW attachment does not rule out a sub-\nsequent HIGH RC bias in the models. It has been\nestablished in the psycholinguistic literature that\nattachment is learned by humans as a general ab-\nstract feature of language (see Scheepers, 2003).\nIn other words, human syntactic representations of\nattachment overlap, with prepositional attachment\ninﬂuencing relative clause attachment, etc. These\nrelationships could coalesce during training and\nresult in an attachment preference that differs from\nany one structure individually. However, it is clear\nthat whatever attachment biases exist in the data\nare insufﬁcient for RNNs to learn a human-like\nattachment preference in Spanish. This provides\ncompelling evidence that standard training data\nitself may systematically lack aspects of syntax\nrelevant to performing linguistic comprehension\ntasks.\nWe suspect that there are deep systematic issues\nleading to this mismatch between the expected dis-\ntribution of human attachment preferences and the\nactual distribution of attachment in the Spanish\ntraining corpus. Experimental ﬁndings from psy-\ncholinguistics suggest that this issue could follow\nfrom a more general mismatch between language\nproduction and language comprehension. In par-\nticular, Kehler and Rohde (2015, 2018) have pro-\nvided empirical evidence that the production and\ncomprehension of these structures are guided by\ndifferent biases in humans. Production is guided by\nsyntactic and information structural considerations\n(e.g., topic), while comprehension is inﬂuenced by\nthose considerations plus pragmatic and discourse\nfactors (e.g., coherence relations). As such, the bi-\nases in language production are a proper subset of\nthose of language comprehension. As it stands now,\nRNN LMs are typically trained on production data\n13https://github.com/\nUniversalDependencies/UD_Spanish-AnCora\n1987\n(that is, the produced text in Wikipedia). 14 Thus,\nthey will have access to only a subset of the biases\nneeded to learn human-like attachment preferences.\nIn its strongest form, this hypothesis suggests that\nno amount of production data (i.e. raw text) will\never be sufﬁcient for these models to generalizably\npattern like humans during comprehension tasks.\nThe mismatch between human interpretation bi-\nases and production biases suggested by this work\ninvalidates the tacit assumption in much of the\nnatural language processing literature that stan-\ndard, production-based training data (e.g., web text)\nare representative of the linguistic biases needed\nfor natural language understanding and generation.\nThere are phenomena, like agreement, that seem to\nhave robust manifestations in a production signal,\nbut the present work demonstrates that there are\nothers, like attachment preferences, that do not. We\nspeculate that the difference may lie in the inherent\nambiguity in attachment, while agreement explic-\nitly disambiguates a relation between two syntactic\nunits. This discrepancy is likely the reason that\nsimply adding more data doesn’t improve model\nquality (e.g., van Schijndel et al., 2019; Bisk et al.,\n2020). Future work needs to be done to understand\nmore fully what biases are present in the data and\nlearned by language models.\nAlthough our work raises questions about mis-\nmatches between human syntactic knowledge and\nthe linguistic representations acquired by neural\nlanguage models, it also shows that researchers\ncan fruitfully use sentences with multiple interpre-\ntations to probe the linguistic representations ac-\nquired by those models. Before now, evaluations\nhave focused on cases of unambiguous grammat-\nicality (i.e. ungrammatical vs. grammatical). By\nusing stimuli with multiple simultaneous valid in-\nterpretations, we found that evaluating models on\nsingle-interpretation sentences overestimates their\nability to comprehend abstract syntax.\nAcknowledgments\nWe would like to thank members of the NLP group\nand the C.Psyd lab at Cornell University, and the\nAltmann and Yee labs at University of Connecticut,\nwho gave feedback on an earlier form of this work.\nWe would also like to thank the three anonymous\nreviewers and Yonatan Belinkov. Special thanks go\n14Some limited work has explored training models with\nhuman comprehension data with positive results (Klerke et al.,\n2016; Barrett et al., 2018).\nto Dorit Abusch and John Whitman for invaluable\nsuggestions and feedback, and Laure Thompson\nfor comments on an earlier draft.\nReferences\nMaria Barrett, Joachim Bingel, Nora Hollenstein,\nMarek Rei, and Anders Søgaard. 2018. Sequence\nclassiﬁcation with human attention. In Proceedings\nof the 22nd Conference on Computational Natural\nLanguage Learning, pages 302–312, Brussels, Bel-\ngium. Association for Computational Linguistics.\nJean-Philippe Bernardy and Shalom Lappin. 2017. Us-\ning deep neural networks to learn syntactic agree-\nment. Linguistic Issues in Language Technology\n(LiLT), 15.\nYonatan Bisk, Ari Holtzman, Jesse Thomason, Ja-\ncob Andreas, Yoshua Bengio, Joyce Chai, Mirella\nLapata, Angeliki Lazaridou, Jonathan May, Alek-\nsandr Nisnevich, Nicolas Pinto, and Joseph Turian.\n2020. Experience grounds language. arXiv preprint\narXiv:2004.10151.\nMarc Brysbaert and Don C Mitchell. 1996. Modiﬁer at-\ntachment in sentence parsing: Evidence from dutch.\nThe Quarterly Journal of Experimental Psychology\nSection A, 49(3):664–695.\nManuel Carreiras and Charles Clifton. 1999. Another\nword on parsing relative clauses: Eyetracking evi-\ndence from Spanish and English. Memory & Cogni-\ntion, 27(5):826–833.\nManuel Carreiras and Charles Clifton Jr. 1993. Rela-\ntive clause interpretation preferences in Spanish and\nEnglish. Language and Speech, 36(4):353–372.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Annual Confer-\nence of the North American Chapter of the Associa-\ntion for Computational Linguistics. Association for\nComputational Linguistics.\nChris Dyer, G ´abor Melis, and Phil Blunsom. 2019. A\ncritical analysis of biased parsers in unsupervised\nparsing. arXiv preprint arXiv:1909.09428.\n´Emile Enguehard, Yoav Goldberg, and Tal Linzen.\n2017. Exploring the syntactic abilities of RNNs\nwith multi-task learning. In Proceedings of the 21st\nConference on Computational Natural Language\nLearning (CoNLL 2017), pages 3–14. Association\nfor Computational Linguistics.\nEva M. Fern ´andez. 2003. Bilingual sentence process-\ning: Relative clause attachment in English and Span-\nish. John Benjamins Publishing, Amsteradam.\n1988\nStefan L Frank and John Hoeks. 2019. The interac-\ntion between structure and meaning in sentence com-\nprehension: Recurrent neural networks and reading\ntimes. PsyArXiv preprint:10.31234.\nStefan L. Frank, Leun J. Otten, Giulia Galli, and\nGabriella Vigliocco. 2015. The ERP response to the\namount of information conveyed by words in sen-\ntences. Brain & Language, 140:1–11.\nLyn Frazier and Charles Clifton. 1996. Construal.\nMIT Press, Cambridge, Mass.\nRichard Futrell and Roger Levy. 2019. Do RNNs learn\nhuman-like abstract word order preferences? In Pro-\nceedings of the Society for Computation in Linguis-\ntics, volume 2, pages 50–59.\nRichard Futrell, Ethan Wilcox, Takashi Morita, and\nRoger Levy. 2018. RNNs as psycholinguistic sub-\njects: Syntactic state and grammatical dependency.\narXiv preprint arXiv:1809.01329.\nKristina Gulordava, Piotr Bojanowski, Edouard Grave,\nTal Linzen, and Marco Baroni. 2018. Colorless\ngreen recurrent networks dream hierarchically. In\nProceedings of the 2018 Annual Conference of the\nNorth American Chapter of the Association for\nComputational Linguistics. Association for Compu-\ntational Linguistics.\nJohn Hale. 2001. A probabilistic earley parser as a psy-\ncholinguistic model. In Proceedings of the second\nmeeting of the North American Chapter of the Asso-\nciation for Computational Linguistics on Language\ntechnologies, pages 1–8. Association for Computa-\ntional Linguistics.\nSepp Hochreiter and J ¨urgen Schmidhuber. 1997.\nLong short-term memory. Neural Computation,\n9(8):1735–1780.\nAndrew Kehler and Hannah Rohde. 2015. Pronominal\nreference and pragmatic enrichment: A bayesian ac-\ncount. In CogSci.\nAndrew Kehler and Hannah Rohde. 2018. Prominence\nand coherence in a bayesian theory of pronoun inter-\npretation. Journal of Pragmatics.\nSigrid Klerke, Yoav Goldberg, and Anders Søgaard.\n2016. Improving sentence compression by learning\nto predict gaze. In Proceedings of the 2016 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, pages 1528–1533, San Diego,\nCalifornia. Association for Computational Linguis-\ntics.\nJey Han Lau, Alexander Clark, and Shalom Lappin.\n2017. Grammaticality, acceptability, and probabil-\nity: A probabilistic view of linguistic knowledge.\nCognitive Science, 41:1202–1241.\nRoger Levy. 2008. Expectation-based syntactic com-\nprehension. Cognition, 106(3):1126–1177.\nTal Linzen, Emmanuel Dupoux, and Yoav Goldberg.\n2016. Assessing the ability of LSTMs to learn\nsyntax-sensitive dependencies. Transactions of the\nAssociation for Computational Linguistics, 4:521–\n535.\nTal Linzen and Brian Leonard. 2018. Distinct patterns\nof syntactic agreement errors in recurrent networks\nand humans. In Proceedings of the 2018 Annual\nMeeting of the Cognitive Science Society, pages 690–\n695. Cognitive Science Society.\nR Thomas McCoy, Robert Frank, and Tal Linzen. 2018.\nRevisiting the poverty of the stimulus: hierarchical\ngeneralization without a hierarchical bias in recur-\nrent neural networks. In Proceedings of the 40th An-\nnual Conference of the Cognitive Science Society.\nRichard D. Morey and Jeffrey N. Rouder. 2018.\nBayesFactor: Computation of Bayes Factors for\nCommon Designs. R package version 0.9.12-4.2.\nMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word repre-\nsentations. In Proceedings of the 2018 Annual Con-\nference of the North American Chapter of the Associ-\nation for Computational Linguistics. Association for\nComputational Linguistics.\nGrusha Prasad, Marten van Schijndel, and Tal Linzen.\n2019. Using priming to uncover the organization of\nsyntactic representations in neural language models.\nIn Proceedings of the 23rd Conference on Computa-\ntional Natural Language Learning.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training. Technical re-\nport, OpenAI.\nShauli Ravfogel, Yoav Goldberg, and Tal Linzen. 2019.\nStudying the inductive biases of RNNs with syn-\nthetic variations of natural languages. In Proceed-\nings of NAACL-HLT.\nJeffrey N. Rouder, Paul L. Speckman, Dongchu Sun,\nRichard D. Morey, and Geoffrey Iverson. 2009.\nBayesian t-tests for accepting and rejecting the\nnull hypothesis. Psychonomic Bulletin & Review,\n16(2):225–237.\nChristoph Scheepers. 2003. Syntactic priming of rel-\native clause attachments: Persistence of structural\nconﬁguration in sentence production. Cognition,\n89(3):179–205.\nHelmut Schmid. 1999. Improvements in part-of-\nspeech tagging with an application to German. In\nNatural language processing using very large cor-\npora, pages 13–25. Springer.\nClaude Shannon. 1948. A mathematical theory of com-\nmunication. Bell System Technical Journal, 27:379–\n423, 623–656.\n1989\nNathaniel J Smith and Roger Levy. 2013. The effect of\nword predictability on reading time is logarithmic.\nCognition, 128(3):302–319.\nEmma Strubell, Ananya Ganesh, and Andrew McCal-\nlum. 2019. Energy and policy considerations for\ndeep learning in NLP. In Proceedings of the 57th\nAnnual Meeting of the Association for Computa-\ntional Linguistics.\nMariona Taul´e, M. Ant`onia Mart´ı, and Marta Recasens.\n2008. AnCora: Multilevel annotated corpora for\ncatalan and spanish. In Proceedings of the Sixth In-\nternational Conference on Language Resources and\nEvaluation.\nAndrew Trask, Felix Hill, Scott E Reed, Jack Rae,\nChris Dyer, and Phil Blunsom. 2018. Neural arith-\nmetic logic units. In Advances in Neural Informa-\ntion Processing Systems, pages 8035–8044.\nMarten van Schijndel and Tal Linzen. 2018. Modeling\ngarden path effects without explicit hierarchical syn-\ntax. In Proceedings of the 40th Annual Meeting of\nthe Cognitive Science Society.\nMarten van Schijndel, Aaron Mueller, and Tal Linzen.\n2019. Quantity doesn’t buy quality syntax with neu-\nral language models. In Proceedings of the 2019\nConference on Empirical Methods in Natural Lan-\nguage Processing. Association for Computational\nLinguistics.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia,\nAmanpreet Singh, Julian Michael, Felix Hill, Omer\nLevy, and Samuel Bowman. 2019. SuperGLUE: A\nstickier benchmark for general-purpose language un-\nderstanding systems. In Advances in Neural Infor-\nmation Processing Systems, pages 3261–3275.\nAlex Wang, Amanpreet Singh, Julian Michael, Fe-\nlix Hill, Omer Levy, and Samuel Bowman. 2018.\nGLUE: A multi-task benchmark and analysis plat-\nform for natural language understanding. In Pro-\nceedings of the 2018 EMNLP Workshop Black-\nboxNLP: Analyzing and Interpreting Neural Net-\nworks for NLP.\nEthan Wilcox, Roger Levy, and Richard Futrell. 2018.\nWhat Syntactic Structures block Dependencies in\nRNN Language Models? In Proceedings of the 41st\nAnnual Meeting of the Cognitive Science Society.\nEthan Wilcox, Roger Levy, and Richard Futrell. 2019.\nHierarchical representation in neural language mod-\nels: Suppression and recovery of expectations. In\nProceedings of the 2019 ACL Workshop Black-\nboxNLP: Analyzing and Interpreting Neural Net-\nworks for NLP.\nA Fern ´andez (2003) Replications\nA.1 English\nWe compute RNN surprisal for each experimental\nitem from Fern´andez (2003) as detailed in Section\nFigure 4: Proportion HIGH vs LOW attachment in\nEnglish. Human results from the original Fern ´andez\n(2003) experiment and RNN LM results from the stim-\nuli from Fern´andez (2003).\n3.3 in the paper. The results coded for HIGH/LOW\nattachment are given in Figure 4, including the\nresults for humans reported by Fern´andez (2003).\nWhile these categorical results enable easier com-\nparison to the human results reported in the liter-\nature, statistical robustness was determined using\nthe original distribution of surprisal values. Specif-\nically, a two-tailed t-test was conducted to see if\nthe mean difference in surprisal differed from zero\n(i.e. the model has some attachment bias). The re-\nsult is highly signiﬁcant (p< 10−5, Bayes Factor\n(BF) > 100) with a mean surprisal difference of\nµ = 0.66. This positive difference suggests that\nthe RNN LMs have a LOW bias, similar to English\nreaders.\nFigure 5: Proportion HIGH vs LOW attachment in\nSpanish. Human results from the original Fern ´andez\n(2003) experiment and RNN LM results from the stim-\nuli from Fern´andez (2003).\n1990\nA.2 Spanish\nThe results coded for HIGH/LOW attachment for\nthe Spanish replication are given in Figure 5, in-\ncluding the human results reported by Fern´andez\n(2003). The mean did not differ signiﬁcantly from\n0 (BF <1/3). This suggests that there is no attach-\nment bias for the Spanish models for the stimuli\nfrom Fern´andez (2003), contrary to the human re-\nsults.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7434620261192322
    },
    {
      "name": "Artificial neural network",
      "score": 0.5737802982330322
    },
    {
      "name": "Relative clause",
      "score": 0.526552677154541
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4899100661277771
    },
    {
      "name": "Natural language processing",
      "score": 0.45268359780311584
    },
    {
      "name": "Linguistics",
      "score": 0.32170844078063965
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}