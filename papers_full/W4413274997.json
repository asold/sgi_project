{
  "title": "Improving automated deep phenotyping through large language models using retrieval-augmented generation",
  "url": "https://openalex.org/W4413274997",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2607020446",
      "name": "Brandon T. Garcia",
      "affiliations": [
        "Baylor College of Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2169043936",
      "name": "Lauren Westerfield",
      "affiliations": [
        "Baylor College of Medicine",
        "Texas Children's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A4284555940",
      "name": "Priya Yelemali",
      "affiliations": [
        "Baylor College of Medicine",
        "Meharry Medical College"
      ]
    },
    {
      "id": "https://openalex.org/A2528875191",
      "name": "Nikhita Gogate",
      "affiliations": [
        "Baylor College of Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A5064973000",
      "name": "E. Andres Rivera-Munoz",
      "affiliations": [
        "Baylor College of Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2299008173",
      "name": "Haowei Du",
      "affiliations": [
        "Baylor College of Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A3149262128",
      "name": "Moez Dawood",
      "affiliations": [
        "Baylor College of Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2567150074",
      "name": "Angad Jolly",
      "affiliations": [
        "Baylor College of Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2220203656",
      "name": "James R. Lupski",
      "affiliations": [
        "Texas Children's Hospital",
        "Baylor College of Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2120790929",
      "name": "Jennifer E. Posey",
      "affiliations": [
        "Baylor College of Medicine",
        "Columbia University Irving Medical Center",
        "Columbia University"
      ]
    },
    {
      "id": "https://openalex.org/A2607020446",
      "name": "Brandon T. Garcia",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2169043936",
      "name": "Lauren Westerfield",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4284555940",
      "name": "Priya Yelemali",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2528875191",
      "name": "Nikhita Gogate",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5064973000",
      "name": "E. Andres Rivera-Munoz",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2299008173",
      "name": "Haowei Du",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3149262128",
      "name": "Moez Dawood",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2567150074",
      "name": "Angad Jolly",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2220203656",
      "name": "James R. Lupski",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2120790929",
      "name": "Jennifer E. Posey",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2560641002",
    "https://openalex.org/W2949885556",
    "https://openalex.org/W2950025267",
    "https://openalex.org/W2911161668",
    "https://openalex.org/W4365138505",
    "https://openalex.org/W4365138239",
    "https://openalex.org/W1644197353",
    "https://openalex.org/W2048495389",
    "https://openalex.org/W2136410628",
    "https://openalex.org/W4389004870",
    "https://openalex.org/W2809721358",
    "https://openalex.org/W2946102094",
    "https://openalex.org/W2951146425",
    "https://openalex.org/W2799591144",
    "https://openalex.org/W2119613819",
    "https://openalex.org/W2963322438",
    "https://openalex.org/W2272951769",
    "https://openalex.org/W3018059184",
    "https://openalex.org/W2246559112",
    "https://openalex.org/W2887905891",
    "https://openalex.org/W4404270262",
    "https://openalex.org/W4399941107",
    "https://openalex.org/W4394782455",
    "https://openalex.org/W2808129629",
    "https://openalex.org/W4402358523",
    "https://openalex.org/W4391387740",
    "https://openalex.org/W4401001407",
    "https://openalex.org/W4402516372",
    "https://openalex.org/W4399480372",
    "https://openalex.org/W4392168151",
    "https://openalex.org/W3087028093",
    "https://openalex.org/W4224997359",
    "https://openalex.org/W4385848332",
    "https://openalex.org/W4401726216",
    "https://openalex.org/W4390403247",
    "https://openalex.org/W4400128031",
    "https://openalex.org/W3024033150",
    "https://openalex.org/W4393264365",
    "https://openalex.org/W4401821647",
    "https://openalex.org/W2926140117",
    "https://openalex.org/W4226287018"
  ],
  "abstract": "RAG-HPO is a user-friendly, adaptable tool designed for secure evaluation of clinical text and outperforms standard HPO-matching tools in precision, recall, and F1. Its enhanced precision and recall represent a substantial advancement in phenotypic analysis, accelerating the identification of genetic mechanisms underlying rare diseases and driving progress in genetic research and clinical genomics. RAG-HPO is available at https://github.com/PoseyPod/RAG-HPO .",
  "full_text": "Garcia et al. Genome Medicine           (2025) 17:91  \nhttps://doi.org/10.1186/s13073-025-01521-w\nSOFTWARE Open Access\n© The Author(s) 2025. Open Access This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 \nInternational License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if \nyou modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or \nparts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To \nview a copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/.\nGenome Medicine\nImproving automated deep phenotyping \nthrough large language models using \nretrieval-augmented generation\nBrandon T. Garcia1,2,3, Lauren Westerfield1,4,5, Priya Yelemali1,6, Nikhita Gogate1,3, E. Andres Rivera-Munoz1,3, \nHaowei Du1, Moez Dawood1,2,3,7, Angad Jolly1, James R. Lupski1,4,7,8 and Jennifer E. Posey1,9,10* \nAbstract \nBackground Diagnosing rare genetic disorders relies on precise phenotypic and genotypic analysis, with the Human \nPhenotype Ontology (HPO) providing a standardized language for capturing clinical phenotypes. Rule-based HPO \nextraction tools use concept recognition to automatically identify phenotypes, but they often struggle with incom-\nplete phenotype assignment, requiring significant manual review. While large language models (LLMs) hold promise \nfor more context-driven phenotype extraction, they are prone to errors and “hallucinations,” making them less reliable \nwithout further refinement. We present RAG-HPO, a Python-based tool that leverages retrieval-augmented generation \n(RAG) to elevate accuracy of HPO term assignment by LLM. This approach bypasses the limitations of baseline models \nand eliminates the need for time- and resource-intensive fine-tuning. RAG-HPO integrates a dynamic vector database, \ncontaining > 54,000 phenotypic phrases mapped to HPO IDs, which allows real-time retrieval and contextual match-\ning. The RAG-HPO workflow begins by extracting phenotypic phrases from clinical text via an LLM and then matching \nthem via semantic similarity to entries within the database. The best term matches are returned to the LLM as context \nfor final HPO term assignment of each phrase.\nResults Performance was benchmarked on 112 published case reports with 1792 manually assigned HPO terms \nand compared to Doc2HPO, ClinPhen, and FastHPOCR. In evaluations, RAG-HPO + LLaMa-3.1 70B achieved a mean \nprecision of 0.81, recall of 0.76, and an F1 score of 0.78—significantly surpassing conventional tools (p < 0.00001). \nRAG-HPO returned 1648 terms, of which 19.1% (315) were false positives that did not exactly match our manually \nannotated standard. Among these, < 1% (1/315) represented hallucinations, and 1.3% (4/315) represented terms \nwith no ontological relationship to the desired target; the remaining false positives (95.2%, 300/315) were broader \nancestor terms of the target term, which may still be relevant to users in many contexts.\nConclusions RAG-HPO is a user-friendly, adaptable tool designed for secure evaluation of clinical text and outper-\nforms standard HPO-matching tools in precision, recall, and F1. Its enhanced precision and recall represent a sub-\nstantial advancement in phenotypic analysis, accelerating the identification of genetic mechanisms underlying rare \ndiseases and driving progress in genetic research and clinical genomics. RAG-HPO is available at https:// github. com/ \nPosey Pod/ RAG- HPO.\n*Correspondence:\nJennifer E. Posey\njep2156@cumc.columbia.edu\nFull list of author information is available at the end of the article\nPage 2 of 17Garcia et al. Genome Medicine           (2025) 17:91 \nKeywords Large language models (LLMs), Retrieval-augmented generation (RAG), Phenotyping, Human Phenotype \nOntology (HPO), Natural language processing (NLP), Clinical genomics, Generative pre-trained transformer (GPT), \nGenerative AI, LLaMa-3\nBackground\nIn genomic medicine and research, phenotypic and geno-\ntypic analyses are critical for achieving accurate molecu -\nlar diagnoses. Deep phenotyping allows for a detailed \nunderstanding of a patient’s clinical presentation, which \ncan then be matched to potential genetic causes [1]. \nGenomic analysis provides the molecular insights nec -\nessary to identify pathogenic variants that may be con -\ntributing to disease [2]. Together, these approaches \nfacilitate a comprehensive evaluation of patients, particu-\nlarly those with rare or undiagnosed conditions, and offer \nthe possibility of uncovering genetic etiologies that might \notherwise remain elusive [3]. Integrating clinical and \nmolecular data is essential for providing patients with \nconcrete answers, guiding their treatment, and improv -\ning outcomes [4–7].\nThe Human Phenotype Ontology (HPO) is a standard -\nized, hierarchically structured vocabulary that underpins \nmodern deep-phenotyping workflows [8–10]. Its hier -\narchical structure links broad categories to increasingly \nspecific descriptors, enabling clinicians and researchers \nto capture subtle phenotypic differences—even when \nclinical terminology varies—while preserving compu -\ntational comparability [11]. Each concept is assigned a \nstable identifier (e.g., HP:0004322 “short stature”), allow -\ning rapid, large-scale matching of phenotypically simi -\nlar individuals to candidate genetic variants [10, 12, 13]. \nOver time, revision and expansion of the HPO term set \nhas led to a modest number of obsolete terms [10].\nFigure 1 illustrates both the breadth and depth of the \nHPO as a resource for identifying patient phenotypes. \nFigure 1A shows that nearly half of the 19,024 non-obso -\nlete terms belong to the musculoskeletal system, while \nonly 245 (< 2%) HPO terms within the database describe \ndevelopmental biology-related phenotypes. Figure  1B \nhighlights the ontology’s specificity by organ system, \nwith median nodal depths clustering between six and \nten across organ systems. However, every branch also \ncontains range of nodal depths from general (< 3-level) \nto ultra-specific (> 12-level) terms (e.g., HP:0001507 \n“growth abnormality” vs. HP:0008845 “mesomelic short \nstature”). This combination of wide anatomic cover -\nage and variable specificity makes the HPO uniquely \nsuited for machine-readable phenotypic data, laying the \ngroundwork for advanced genotype–phenotype match -\ning tools that drive precision genomic medicine today \n[14–16].\nIn rare disease research, HPO terms have become \ncentral to phenotype-driven variant prioritization and \ngenotype–phenotype correlation [17]. Tools such as \nExomiser use patient-specific HPO profiles to rank \ncandidate variants by phenotypic similarity, improv -\ning diagnostic yield and reducing the time to diagno -\nsis [18, 19]. At the research level, platforms like the \nMonarch Initiative integrate HPO annotations across \nhuman and model organism datasets to support discov -\nery of novel gene–disease associations [10, 20]. Beyond \ngenetics, HPO also enables the stratification of patients \nwith overlapping clinical features in studies of complex \ntraits, treatment response, and multi-system diseases, \nunderscoring its broad utility in biomedical research \n[21, 22].\nWhile HPO terms provide a standardized framework \nfor cataloging and investigating patient phenotypes, the \nprocess of extracting deep phenotyping information \nfrom clinical text remains labor-intensive and reliant \non clinical expertise. Many tools, such as Doc2HPO, \nClinPhen, and FastHPOCR, seek to automate the \nextraction of relevant phenotypic phrases from clini -\ncal records using dictionary-based, concept recognition \nmethods [12, 13, 23]. This approach involves compar -\ning segments of text against a predefined lexicon of \ndomain-specific terms, such as HPO terms, to identify \nphenotypes within clinical text. While straightforward \nand interpretable, concept recognition lacks the ability \nto interpret nuanced contexts, such as family history \nand pertinent negatives, leading to the incorrect assign -\nment of HPO IDs. These tools often miss a substantial \nportion of patient phenotypes, necessitating thorough \nmanual cross-examination to ensure accurate pheno -\ntype annotation.\nLarge language models (LLMs) are advanced com -\nputational programs trained to understand and gen -\nerate natural language based on patterns present in \nhuman-generated text [24, 25]. As part of the increased \npopularity of generative artificial intelligence (AI), \nthese programs offer a promising opportunity to sig -\nnificantly improve automated deep phenotyping [26, \n27]. Within the biomedical field, remarkable advances \nin LLM technology have led to rapid growth in the \nuse of technology in various clinical and basic science \napplications, including interpretation of radiological \nresults or analyzing medical text [28– 32]. The ability \nof LLMs to understand natural language context is a \nPage 3 of 17\nGarcia et al. Genome Medicine           (2025) 17:91 \n \ncritical component for improving the ability to extract \nrelevant clinical phenotypes from patient data. Con -\nsequently, LLMs have entered the phenotypic analysis \nspace through tools like PhenoTagger, PhenoBERT, and \nPhenoGPT [33– 35].\nHowever, the integration of LLMs into phenotypic \nanalysis presents new challenges. As other authors have \nnoted, currently available LLMs are resource-intensive \nand slow in their reasoning compared to other machine \nlearning methods [23]. Importantly, they are also prone \nto hallucinations, in which the model generates incor -\nrect information and confidently asserts it as fact [36]. \nMany LLM-based tools for phenotypic analysis address \nthese concerns through fine-tuning, which involves fur -\nther training of a model with additional data [35, 37, \n38]. While this process increases the accuracy of LLM \nresponses, it is computationally expensive (requir -\ning substantial GPU and RAM), time-consuming, and \nFig. 1 Distribution of HPO terms by organ system and nodal distribution. A Absolute counts of HPO terms per organ system. B Nodal-depth \ndistribution within each system representing term specificity. Musculoskeletal descriptors account for the largest share of HPO concepts, whereas \ndevelopmental-biology terms form the smallest branch. The box-and-whisker plots in B show that all systems possess a long “tail” of deeply nested \n(> 12-level) terms, illustrating the ontology’s ability to capture highly granular phenotypes. Counts reflect the 19,024 non-obsolete HPO terms \navailable in the October 2024 release; multi-system annotations are tallied once per system\nPage 4 of 17Garcia et al. Genome Medicine           (2025) 17:91 \nnecessitates specialized expertise in working with gen -\nerative AI models [26, 36, 39]. Additionally, fine-tuning \nmay not always improve LLM performance in the desired \nway, especially with large-scale models [40, 41]. With the \nrapid advancement of LLM technology and continual \nupdates to the HPO lexicon, fine-tuning LLMs for phe -\nnotypic analysis becomes impractical for most clini -\ncians and researchers involved in diagnosing rare genetic \ndiseases.\nAlternatively, retrieval-augmented generation (RAG) \nis a practical solution to the limitations of fine-tuning. \nRAG uses vector databases to retrieve relevant infor -\nmation from source documents in real-time, making it \neasier and faster to update the system with new infor -\nmation [42–44]. Users can refresh the underlying vector \ndatabase with minimal effort, allowing the system to stay \ncurrent without the need to retrain the LLM. This makes \nRAG more cost-effective and adaptable, particularly for \nusers without advanced technical expertise and who use \na resource that constantly updates, while still leveraging \nthe power of LLMs to enhance the accuracy and preci -\nsion of results.\nWe have developed a Python-based program, RAG-\nHPO [45], to apply RAG to deep phenotyping, dramati -\ncally  increasing LLMs’ ability to accurately assign HPO \nterms to patient phenotypes. This enables us to leverage \nthe LLMs’ superior ability to extract phenotypic informa-\ntion from clinical data, improving the process of auto -\nmated deep phenotyping. RAG-HPO is simple to use, \ndoes not require extensive understanding of LLMs, works \nwith any language model, and does not require computa -\ntionally intense resources like GPUs and large amounts of \nRAM for use. By utilizing a vector database, RAG-HPO \ncan be easily updated with new information from the \nHPO database and user input. When paired with LLaMa-\n3, RAG-HPO demonstrates superior precision and recall \ncompared to popular dictionary-based concept recogni -\ntion tools.\nImplementation\nRAG-HPO is a Python-based tool designed to extract \nclinical phenotypes from medical free text and assign \nHPO terms to those phrases using RAG. Users can \nemploy any LLM of their choosing by providing an \nApplication Programming Interface (API) key. Below, we \ndescribe implementation of this tool with the LLaMa-3.1 \n70B for the benchmarking of RAG-HPO.\nData preparation, embedding, and vectorization\nThe vector database used by RAG-HPO utilizes a Python \ndictionary with key-value pairs, where keys are clinical \nwords and phrases that reliably match to HPO ID numer-\nical values (e.g., furrowed tongue: HP:0000221). The \ninitial dictionary was extracted from the HPO database \nand includes term titles, names, definitions, and syno -\nnyms paired with their respective HPO IDs. To expand \nits coverage, we generated additional synonyms and \nshort phrases for each HPO term using LLaMa-3.1 70B, \nwith instructions focused on medical practice and cur -\nrent literature. After removing duplicates, we submitted \neach candidate phrase for validation using Doc2HPO and \nClinPhen, retaining only those that accurately mapped \nback to the original HPO ID. This process added several \nthousand custom entries, each reliably associated with \nthe correct HPO term, resulting in a final custom dic -\ntionary of over 54,000 unique phrases that correspond \nto individual HPO IDs stored in JavaScript Object Nota -\ntion (JSON) format (Additional file  1: Vector database \ndictionary). The refined dataset serves as the basis for \nthe vector database used in RAG-HPO. Fastembed was \nemployed to convert each term within the JSON file to \na high-dimensional vector to capture semantic relation -\nships between phenotypic terms and factor together line-\nage information to bring like terms closer to one another, \nenabling enhanced similarity searches during phenotypic \nmatching.\nThe embedded database is stored as a NumPy array for \nuse by RAG-HPO, serving as a resource to support the \nLLM in making accurate assignments. When the analysis \nprogram is initiated, the NumPy array is indexed in a vec-\ntor database optimized for dense vector retrieval, allow -\ning for efficient approximate nearest-neighbor searches. \nRelevant metadata is also indexed within the database \nto assist the LLM in reasoning through the assignment \nprocess.\nRAG‑HPO workflow\nThe program processes free text provided as strings, con -\nverting them into HPO terms. Input text can either be \nsupplied directly by the user or batch-processed from a \nCSV file containing clinical notes. The text is first passed \nto the user’s chosen LLM via an API call, where a custom \nsystem prompt instructs the LLM to extract phenotypic \nphrases that describe the patient’s health status, while \ndisregarding non-relevant information such as adminis -\ntrative details or general observations that do not pertain \nto the patient’s health (Fig. 2A, Additional file 2: Fig. S1).\nOnce extracted, these phenotypic phrases are prepared \nfor the HPO term assignment process, which begins with \nsemantic similarity search (Fig.  2B). To optimize compu-\ntational efficiency and reduce the workload on the LLM, \neach extracted phrase is first compared to the metadata \nwithin the embeddings array using fuzzy matching. Exact \nmatches are directly included in the results without fur -\nther processing, while phrases that do not have an exact \nmatch are converted into high-dimensional semantic \nPage 5 of 17\nGarcia et al. Genome Medicine           (2025) 17:91 \n \nvectors using Fastembed. The generated embeddings, \nalong with associated metadata (such as HPO terms, lin -\neage information, and organ system), are compared to the \ndeveloped HPO database in a similarity search via Face -\nbook AI Similarity Search, an efficient package for index -\ning and searching vector data, to identify related HPO \nterms (Fig.  2B). The program retrieves the top 20 most \nsemantically similar vectors, along with their associated \nmetadata, including the relevant HPO terms, lineage, and \nother contextual information. Then, the surrounding sen-\ntence from the original clinical text is retrieved to pro -\nvide additional context for understanding the extracted \nphrase.\nThe extracted clinical phrases are resubmitted to the \nLLM, which uses the additional context provided by the \nmetadata to select the most appropriate and detailed \nHPO term representing the most distal matching node \n(highest possible information content) in the ontology \nthat fits the level of information provided by the pheno -\ntypic phrase (Fig.  2C). After each extracted phrase and \nmetadata block are passed through the LLM, a completed \nlist of HPO terms for the whole passage is returned to the \nuser (Fig.  2D). When analyzing batches, the results are \nsaved as a JSON object list within a copy of the original \nCSV file under a new column.\nSelection of evaluation material and criteria \nfor comparative analysis\nRAG-HPO, ClinPhen, Doc2HPO, and FASTHPOCR \nwere evaluated based on their ability to accurately extract \nHPO terms from previously published case reports. This \ncase study cohort (CSC) comprised 120 case reports \nsourced from two peer-reviewed journals: BMJ Case \nReports and Oxford Medical Case Reports. These jour -\nnals were selected for their rigorous editorial standards \nand comprehensive coverage of diverse medical spe -\ncialties, including gastroenterology, musculoskeletal, \ndermatology, hematology, cardiovascular, pulmonary, \nrenal, endocrinology, reproductive health, neuroanatomy, \nand psychiatry. Both journals are widely recognized in \nthe medical community and are indexed in PubMed Cen-\ntral, ensuring accessibility and credibility. A third-year \nmedical student, independent of the evaluation team, \nscreened the reports to minimize selection bias.\nEach case within the study described one to two \npatients with a distinct set of phenotypes for a particular \nillness. Manual annotation of HPO terms was initiated by \nthe medical student, who extracted and matched pheno -\ntypic features from each case report to specific HPO IDs. \nSubsequently, additional team members, including a cer -\ntified genetic counselor and a physician-scientist trainee, \nreviewed and completed the annotations to ensure accu -\nracy and consistency across the dataset. Discrepancies \nwere resolved through consensus discussions involving \nthe annotators and medical genetics faculty, who selected \nthe most appropriate HPO term based on clinical exper -\ntise and the context of each case. Reports describing \nfewer than four discernible phenotypic features were \nexcluded, leaving 112 cases with 1794 (1208 unique) \nassignable HPO terms across the cohort with a mean of \n15.8 HPO terms per case (Table  1). Additional file 2: Fig. \nS2 demonstrates the organ system distribution and nodal \ndepth of the terms found within the CSC.\nWe also evaluated RAG-HPO and other HPO analysis \nsoftware using the gold standard corpora (GSC), which \ncontains 229 entries describing genetic conditions [15]. \nAfter applying the same filtering criteria as for our case \nstudy cohort (i.e., removing entries with fewer than four \ndistinct phenotypes and manually assigning HPO terms), \nwe curated a final dataset of 114 entries comprising 1013 \nHPO terms, of which 415 were unique, averaging 8.9 \nterms per case (Table  1). We then compared our manu -\nally assigned HPO terms for each GSC entry to those \ncomprising the original annotation. Additional file 2: Fig. \nFig. 2 RAG-HPO extracts phenotypic information and returns HPO terms. RAG-HPO assigns HPO terms to free-text clinical notes in two main \nphases. A First, clinical information is provided to the LLM, which extracts relevant clinical abnormalities as text phrases. B Next, each extracted \nphrase is vectorized and compared to entries in an HPO vector database using semantic similarity search. C For each phrase, the top 20 most similar \nHPO terms are returned to the LLM, which selects the most appropriate HPO term. D After all phrases are processed, the final list of assigned HPO \nterms is returned to the user for verification and downstream analysis\nPage 6 of 17Garcia et al. Genome Medicine           (2025) 17:91 \nS3 illustrates entries for which we excluded overly gen -\neral terms present in the original annotations. Additional \nfile 2: Fig. S4 displays the organ system distribution and \nnodal depth of the terms found within the GSC, compa -\nrable to Fig.  1 and Additional file 2: Fig. S2 for the HPO \ndatabase and CSC.\nFigure 3 demonstrates key differences between the full \nHPO dataset, the GSC, and our CSC. While the GSC \ncovers a range of organ systems, it is heavily skewed \ntoward a small subset of systems, much like the HPO \ndatabase (Fig.  3A and B, respectively). Over 56.5% of the \nannotated HPO terms in the GSC fall within just three \nsystems: the nervous system (23.7%), musculoskeletal \nsystem (22.2%), and head/neck/special senses (10.6%). \nOther systems such as the endocrine/metabolic (5.8%), \ngenitourinary (3.5%), cardiovascular (3.1%), and immune \n(5.4%) systems are markedly underrepresented. This dis -\ntribution reflects a bias inherent to the OMIM-derived \nsource material, which often emphasizes neurodevelop -\nmental and congenital disorders.\nSuch imbalances reduce the generalizability of the \nGSC as a benchmark for phenotype extraction tools \naimed at broad clinical application. In contrast, our CSC \ndemonstrates a more even and realistic distribution of \nphenotypic systems (Fig.  3C), enhancing its value as a \nperformance benchmark for general-purpose tools like \nRAG-HPO.\nClinPhen, Doc2HPO, and FASTHPOCR employ \ndictionary‑based concept recognition to identify HPO \nterms\nBriefly, ClinPhen segments clinical notes into sentences \nand subsentences, normalizing and matching phrases \nagainst an HPO synonym dictionary while filtering out \nirrelevant or negated mentions [13]. Doc2HPO integrates \nseveral natural language processing engines—including \nstring-based matching via the Aho–Corasick algorithm \nand MetaMap-based methods—to provide an interactive \ninterface for real-time curation and negation detection \n[12]. FASTHPOCR uses a fast dictionary-based approach \nthat first consolidates morphologically equivalent tokens \ninto clusters, creating an index of HPO concept signa -\ntures for rapid candidate matching [23]. Detailed descrip-\ntions of these methods are available in their respective \npublications.\nFor our evaluation, ClinPhen [46] was downloaded \nfrom http:// bejer ano. stanf ord. edu/ clinp hen/ and \nDoc2HPO [47] was accessed via its web interface at \nhttps:// doc2h po. wglab. org/. FASTHPOCR [48] was \nobtained from its GitHub repository (https:// github. com/ \ntudor groza/ fast_ hpo_ cr) in June 2024. It is noteworthy \nthat both ClinPhen and Doc2HPO utilize an older ver -\nsion of the HPO dataset, which may lead to the extrac -\ntion of obsolete terms.\nPerformance evaluation of RAG‑HPO using multiple \nopen‑source LLMs\nIn contrast, RAG-HPO’s performance was evaluated \nusing an updated HPO version accessed in August 2024 \n(v2024-08-13). For the evaluation, we tested RAG-HPO \nusing several LLMs available for use through groq.com, \nincluding LLaMa-3 70B, LLaMa-3.1 8B, LLaMa-3.1 70B, \nLLaMa-4 Scout (16B), Misra 24B, and Deepseek-R1. \nThese LLMs represent a wide variety of open-source \nLLMs that are reasonably available for researchers and \nclinicians to access for their own evaluations and use in \nresearch. Testing across several versions of LLaMa lan -\nguage models allowed us to demonstrate the changes in \nperformance with incremental improvements of LLMs \nover time.\nIn our analysis, we considered any HPO term called \nby an analysis tool to be a true positive if it matched the \nmanually annotated standard. False positives were then \nany called HPO term that did not match manually anno -\ntated terms. Failure to identify an HPO term from the \nstandard was considered a false negative. The number \nof true positives, false positives, and false negatives were \nused to calculate three key metrics: precision, recall, and \nTable 1 Composition of the evaluation datasets compared to HPO database. The composition of HPO terms found in the case study \ncohort (CSC) compared to gold standard corpora (GSC) and original HPO database. The CSC has nearly triple the number of unique \nHPO terms and almost twice as many terms per case as the GSC, offering more opportunity to test HPO analysis tools on a wide variety \nof phenotypic categories\nCohort HPO terms present Nodal depth Organ systems\nTotal Unique Per case (mean) Cohort (mean) Per case (mean) Total Per case (mean)\nHPO 19,024 19,024 N/A 9.58 N/A 30 N/A\nCSC 1794 1208 15.8 7.1 6.8 28 6.7\nGSC 1013 415 8.9 7.1 6.7 21 5.0\nGSC (original) 1323 447 11.6 6.9 6.5 23 5.6\nPage 7 of 17\nGarcia et al. Genome Medicine           (2025) 17:91 \n \nthe F1 score. These scores were used in determining the \nperformance of the HPO analysis tools.\nPrecision measures the accuracy of each tool in return -\ning relevant HPO terms and is calculated as:\nRecall measures the ability of the tool to retrieve all \nHPO terms present within a case note and is calculated \nas:\nPrecision= True Positive\nTrue Positive + False Positive\nThe F1 score is a weighted average of precision and \nrecall on a scale of 0–1 and was calculated using the fol -\nlowing formula:\nRecall= True Positive\nTrue Positive+ False Negative\nF1 = 2 × Precision× Recall\nPrecision+ Recall\nFig. 3 Comparative organ system representation across HPO, GSC, and case study cohorts. A Distribution of HPO terms by organ system in the full \nHPO database, where musculoskeletal terms comprise the largest proportion. B Distribution in the gold standard corpus (GSC), showing a more \nbalanced representation across systems, though still skewed toward musculoskeletal and nervous system terms. C Distribution in the case study \ncohort (CSC), reflecting broader organ system diversity, with increased representation of cardiovascular, endocrine, and neurologic terms\nPage 8 of 17Garcia et al. Genome Medicine           (2025) 17:91 \nPython scripts were used to evaluate performance and \ndevelop figures. To keep evaluations objective and con -\nsistent, we developed a Python script to accurately com -\npared the output of each program against the manually \nannotated standards. The script automatically split multi-\nterm entries, removed invalid rows (entries without HPO \nterm IDs), and counted the true positives, false positives, \nand false negatives for each case. These counts were used \nto calculate precision, recall, and F1 scores per case and \nwe reported the average of these scores for the evaluated \ncohorts. Additionally, we built Python scripts to generate \nthe figures within this paper using a variety of packages, \nincluding numpy (2.2.5), pandas  (2.2.3), scipy (1.15.2), \nstatsmodels (0.14.4), and matplotlib (3.10.1). Origi -\nnal verbatim inputs for the CSC and GSC, the manual \nannotations, and all outputs for this study are available \nfor review in Additional file 3: RAG-HPO tests and data \nanalysis.\nResults\nRAG greatly increases LLM’s ability to identify correct \nHPO terms. The goal of RAG is to improve a language \nmodel’s capacity to retrieve and generate contextually \nrelevant information, thereby reducing “hallucinations. ” \nIn HPO analysis, hallucinations typically appear as non-\nexistent or inappropriate HPO identifiers that do not \nmatch the underlying clinical phrases. Without RAG (or \nsimilar informational scaffolding), current LLMs struggle \nto assign HPO terms accurately.\nTo illustrate this challenge, we evaluated several open- \nand closed-source LLMs on a subset of 20 notes from our \ncase study cohort. Below is an example clinical note with \nthe available phenotypic phrases highlighted according to \nChatGPT (o3) output:\nA 44-year- old super-morbidly- obese man body \nmass index (BMI 63) underwent sleeve gastrectomy \nfor weight loss and was found to have multiple ade -\nnomatous fundic gland polyps on final pathology. \nSubsequent workup included esophagogastroduo -\ndenoscopy which revealed innumerable polyps of \nthe remaining gastric fundus and body consistent \nwith fundic gland polyps, normal duodenum with -\nout polyps, and Barrett’s oesophagus. Colonoscopy \nwas significant for innumerable polyps of varying \nsizes up to 1.5 cm throughout the colon, with relative \nrectal sparing. Biopsies were consistent with tubular \nadenoma and hyperplastic polyps. Thyroid ultra -\nsound was within normal limits and abdominal CT \nwas significant for left-sided 3.4 cm mesenteric mass \nrepresenting scarring versus possible desmoid. Fam -\nily history was significant for colon cancer diagnosed \nin his maternal grandfather at age 72, paternal \ngrandmother who died of metastatic cancer at age \n50 with unknown primary and mother diagnosed \nwith thyroid cancer at age 40. Physical examination \nwas notable for morbid obesity (BMI 45), cardio -\npulmonary examination within normal limits and \nabdomen with well-healing surgical scars from prior \nsleeve gastrectomy.\nAs shown in this example, most LLMs capture the \nmajority of clinical phenotypes available in a particular \ncase (see Additional file 2: Fig. S5 for full results). How -\never, they frequently failed to assign proper HPO codes, \nyielding uniformly low precision, recall, and F1 scores \n(Table 2).\nBy contrast, RAG-HPO greatly improved the abil -\nity of LLMs to accurately assign HPO terms. To evalu -\nate this improvement, we compared the performance of \nLLaMa-3 70B both individually and as part of RAG-HPO \n(Table 3) in the assignment of HPO terms for the case \nstudy cohort. When using the LLaMa-3 70B model alone \n(“baseline”), precision, recall, and F1 scores were 0.12, \n0.09, and 0.10, respectively. However, when combined \nwith RAG-HPO, these metrics improved dramatically, \nyielding a precision of 0.71, recall of 0.61, and an F1 score \nof 0.64. These results confirm that RAG significantly \nTable 2 Comparison of baseline LLM performance in HPO analysis of case studies. Models were evaluated based on the number \nof true positives, false positives, and false negatives, with corresponding precision, recall, and F1 scores calculated. No retrieval \naugmentation or fine-tuning was applied. Results demonstrate substantial variability in performance across models, with generally low \nprecision and recall in the absence of additional context or refinement\nAnalysis tool True positive False positive False negative Precision Recall F1\nLLaMA-3.1 70b 29 181 264 0.13 0.09 0.10\nLLaMA-4 Scout 8 187 285 0.04 0.03 0.03\nChatGPT (o1) 57 149 236 0.24 0.18 0.20\nChatGPT (4o) 60 212 233 0.20 0.19 0.19\nChatGPT (o3) 68 128 225 0.32 0.22 0.26\nCopilot 62 155 231 0.26 0.20 0.22\nGemini 2 38 239 255 0.13 0.12 0.13\nPage 9 of 17\nGarcia et al. Genome Medicine           (2025) 17:91 \n \nenhances LLM performance in HPO analysis, with the \nRAG component directly responsible for the improve -\nments in accuracy.\nRAG‑HPO versus established HPO analysis tools\nThe performance of RAG-HPO was benchmarked \nagainst ClinPhen, Doc2HPO, and FastHPOCR using our \ncase study cohort (Table  4). To assess the influence of \nLLM choice on performance, we paired RAG-HPO with \nsix different back-end models. With the sole exception \nof DeepSeek R1, every LLM configuration of RAG-HPO \nperformed on par with, or significantly better than, the \nconventional dictionary-based concept recognition tools \n(pair wise statistics, Additional file 2: Fig. S6). RAG-HPO \nperformance improved with increased LLM parameter \nscaling and improvements to underlying architecture, \ncontext windows, and other back-end improvements \nmade to LLMs over time.\nRAG-HPO + LLaMa-3.1 70B achieved the strong -\nest overall results, posting the highest precision (0.81), \nrecall (0.76), and F1 score (0.78) in the evaluation \n(Fig.  4, Table  4). This configuration identified 1333 \ncorrect HPO terms, which was more than twice the \ntrue-positive count of ClinPhen (635) and Doc2HPO \n(634), and an almost 1.6-fold increase compared to \nFastHPOCR (816). Although FastHPOCR retrieved a \nlarger number of terms per case than the other tradi -\ntional tools, its larger false-positive burden (FP = 726) \nreduced both precision (0.53) and F1 (0.49).\nFigure  5 compares each tool’s output with the \nmanually annotated case study reference set. RAG-\nHPO + LLaMA-3.1 70B recovered the largest share of \nground-truth terms while adding the fewest false posi -\ntives among RAG configurations, yielding the overall \nbest error balance. Among stand-alone concept rec -\nognition tools, FastHPOCR retrieved the most correct \nterms but incurred a high false positive rate while Clin -\nPhen and Doc2HPO only captured about one-third of \nthe gold standard, but with a much lower rate of false \npositives. Together, these results underscore that even \nthe best traditional tools lag behind RAG-HPO, both \nby missing true phenotypes and by misattributing HPO \nassignments.\nTable 3 LLaMA-3 70B with vs. without RAG-HPO for HPO assignment. In the baseline condition, LLaMA-3 70B assigned only 164 \ncorrect terms across the entire case study cohort (CSC), demonstrating limited standalone utility. When paired with RAG-HPO, the \nsame model achieved 1083 true positives, substantially improving precision, recall, and F1 score. Paired t-tests confirmed that the \nimprovements in all three metrics were statistically significant (***p < 0.001)\nAnalysis tool True positive False positive False negative Precision Recall F1 t‑test comparison\nPrecision Recall F1\nRAG-HPO 1083 486 711 0.71 0.61 0.64 *** *** ***\nBaseline 164 1149 1630 0.12 0.09 0.10\nTable 4 Comparative performance of RAG-HPO and benchmark tools in CSC analysis. Each model was evaluated on the number of \ntrue positives, false positives, and false negatives, along with average precision, recall, and F1 score across all cases. The combination \nof RAG-HPO with LLaMA-3.1 70B achieved the highest overall performance, outperforming both smaller LLMs and rule-based tools. \nResults highlight the effectiveness of retrieval-augmented generation in improving accuracy and reducing error rates in automated \nHPO term assignment\nLLM + RAG‑HPO True positive False positive False negative Average \nprecision\nAverage recall Average F1\nLLaMA-3.1 70B 1333 315 461 0.81 0.76 0.78\nLLaMA-3 70B 1083 486 711 0.71 0.61 0.64\nLLaMA-4 Scout 1257 634 537 0.65 0.69 0.66\nLLaMA-3 8B 852 727 942 0.53 0.46 0.48\nMisra 24B 581 174 1213 0.73 0.31 0.42\nDeepseek-R1 682 1944 1112 0.15 0.35 0.20\nOther HPO analysis tools\n FASTHPOCR 816 726 978 0.53 0.45 0.49\n Doc2HPO 634 260 1159 0.71 0.35 0.47\n ClinPhen 635 370 1159 0.63 0.35 0.45\nPage 10 of 17Garcia et al. Genome Medicine           (2025) 17:91 \nEvaluation of performance by organ system and nodal \ndepth\nWe modeled the probability that a program assigns the \ncorrect HPO term using a binomial generalized estimat -\ning equation with patient-level clustering. Predictors \nwere program, organ system, and nodal depth. Model \ncoefficients were converted to odds ratios and summa -\nrized in three panels: a forest plot of organ-system effects \n(Fig.  6A), a fitted-probability curve across nodal depths \n(Fig. 6B), and box plots of predicted hit probabilities for \neach program (Fig. 6C).\nOrgan system had a limited influence on accuracy \n(Fig.  6A). Cardiovascular, genitourinary, and head/neck \nterms showed moderately higher odds of correct assign -\nment (odds ratio ≈ 8–11 versus reference), while most \nother systems clustered around unity. All tools exhibited \nFig. 4 RAG-HPO has more superior recall and precision than established HPO analysis tools. We compared the output of LLaMA-3 70B alone \nto RAG-HPO paired with LLaMA-3 70B in assigning HPO terms to 20 previously published case reports. RAG significantly improved performance \n(F1: 0.12 vs. 0.78, p < 0.0001). RAG-HPO also outperformed ClinPhen, FastHPOCR, Doc2HPO, and baseline LLaMA across the CSC in precision, recall, \nand F1 score\nFig. 5 Error composition across RAG-HPO LLM variants and benchmark tools. Stacked bar plot comparing the distribution of true positives \n(TP), false negatives (FN), and false positives (FP) in HPO term extraction across multiple RAG-HPO configurations (with different large language \nmodels) and established tools (FastHPOCR, ClinPhen, and Doc2HPO). The y-axis represents the total percentage of output terms normalized \nper method. RAG-HPO models with LLaMA-3 70B and LLaMA-4 Scout achieve a more favorable balance of true positive predictions, while methods \nlike DeepSeek R1 and some traditional tools demonstrate a higher burden of false positives and false negatives. A vertical dashed line separates \nRAG-HPO variants from non-RAG benchmark tools\nPage 11 of 17\nGarcia et al. Genome Medicine           (2025) 17:91 \n \na monotonic decline in accuracy as terms became more \nspecific (Fig.  6B); predicted hit probability fell stead -\nily from shallow (depth ≤ 3) to deep nodes (depth ≥ 10). \nHowever, tool choice remained the strongest deter -\nminant of success (Fig.  6C). Almost every RAG-HPO \nconfiguration out-performed the concept recognition \ntools FastHPOCR, ClinPhen, and Doc2HPO, with RAG-\nHPO + LLaMa-3.1 70B achieving the highest predicted \nhit probability across the depth range.\nEvaluation of false positive results among HPO analysis \ntools\nIn our analysis, we accepted only the most specific term \n(highest information content) to describe each phe -\nnotype. However, there is value in identifying directly \nrelated ancestor terms, which are often broader descrip -\ntors of the phenotypes observed (Fig.  7). To better under-\nstand the meaning of these incorrectly attributed terms, \nwe conducted a deeper analysis of the relationship of false \npositives to the manually annotated HPO terms, specifi -\ncally focusing on the ontological connections between \nthe HPO terms selected by the programs and those iden -\ntified through manual annotation. We categorized the \nfalse positive HPO terms into three distinct groups: (1) \nterms that were direct ancestors of the target HPO terms, \n(2) terms that were indirectly related to the target terms \nthrough a shared ancestor, and (3) terms that were com -\npletely unrelated to the correct terms. Additionally, for \nRAG-HPO, we classified any false positive HPO terms \nthat did not exist in the HPO database as “hallucinations” \ngenerated by the system (Fig. 7A).\nRAG-HPO paired with LLaMa-3.1 70B generated \n315 false positives: 70 direct ancestors (22%), 230 \ndistant relatives (73%), 14 unrelated terms including \ndeprecated codes (4%), and only a single hallucina -\ntion (< 1%) (Fig.  7B). The other RAG variants showed a \nsimilar pattern, although the less-aligned models (e.g., \nLLaMA-3 70B and LLaMA-4 Scout) contained a larger \nFig. 6 Factors influencing HPO assignment accuracy in RAG-HPO and benchmark tools. GEE models were used to estimate the probability \nof correct HPO term assignment, accounting for clustering by patient. A Forest plot of organ system effects, shown as odds ratios with 95% \nconfidence intervals. B Fitted probability curves by nodal depth, illustrating a decline in assignment accuracy as HPO terms became more specific. \nC Predicted hit probability distributions by tool, based on marginal effects from the model. RAG-HPO configurations consistently outperformed \ntraditional concept recognition tools, showing higher and more stable accuracy across the full ontology depth\nPage 12 of 17Garcia et al. Genome Medicine           (2025) 17:91 \nunrelated fraction. Among concept recognition tools, \nFASTHPOCR recorded 729 false positives, dominated \nby distant relatives (79%) with 13 unrelated terms (2%); \nClinPhen and Doc2HPO produced 376 and 264 FPs, \nrespectively, with distant relatives comprising 62–66%. \nTrue hallucinations were absent in all three rule-based \ntools and remained rare for RAG-HPO.\nUnrelated HPO terms assigned by RAG-HPO rarely \nincluded errors attributable to poor semantic similar -\nity search. When RAG-HPO identifies a phenotypic \nphrase for term assignment, the phrase is vector -\nized and compared to the custom vector database we \ncreated. In rare cases, the search returned database \nentries that were completely unrelated to the extracted \nclinical phrases. As currently written, the LLM must \nchoose an HPO term from the list generated by simi -\nlarity search, a constraint designed to prevent hal -\nlucinations, but which can lead to nonsensical HPO \nchoices.\nA deeper understanding of the false positive popu -\nlation helps us to better understand the reasoning for \ntheir development and determine ways to reduce their \noccurrence and improve our precision. This analysis \nalso highlights the importance of understanding the \nlevel of detail needed for specific downstream applica -\ntions. In some instances, less specific but related terms \nmay be acceptable.\nRAG‑HPO performance in other datasets\nAs previously mentioned, we curated the GSC down \nto 114 notes each containing at least four distinct phe -\nnotypes for a total of 1013 HPO terms (415 unique). \nWith this dataset, we evaluated the performance of \nRAG-HPO, using both LLaMa-3 70B and LLaMa-4 \nScout back-ends, against FastHPOCR, Doc2HPO, and \nClinPhen.\nRAG-HPO + LLaMA-3 70B returned 766 true posi -\ntives, 358 false positives, and 245 false negatives, corre -\nsponding to a mean precision of 0.69, recall 0.77, and F1 \n0.71 (Table  5). Substituting the larger-context LLaMA-4 \nScout backbone increased true positives to 783 but also \nraised false positives to 490, lowering precision to 0.62 \nand F1 to 0.68 while maintaining the highest recall (0.79).\nAmong the concept recognition tools, FastHPOCR \nachieved the next-best balance (precision 0.74, recall \n0.70, F1 0.70), whereas Doc2HPO and ClinPhen prior -\nitized precision (0.80 and 0.61, respectively) at the cost \nof markedly reduced recall (0.44 and 0.42) and lower F1 \nscores (0.56 and 0.46).\nCompared with the CSC, RAG-HPO’s precision \ndecreased by almost 12%, likely because GSC entries are \nresearch summaries rather than clinical notes, introduc -\ning broader language and citation artifacts that inflate \ndistant-relative matches. However, RAG-HPO retained \nthe highest overall F1 and the strongest recall across this \nmarkedly different text genre, confirming the generaliz -\nability of the retrieval-augmented framework.\nFig. 7 Analysis of incorrect HPO terms assigned to cases by analysis tools. Examination of the HPO terms returned that did not match the manually \nannotated standard were considered false positives. A Depicts the false positive types in relation to the target term (in purple) with direct \nand indirect relatives being on the same phenotypic abnormality branch, unrelated terms belonging to completely different branches of the HPO, \nand hallucinations having no existence within the HPO database. B We completed a deeper analysis of these terms to better understand their \nnature and categorized them into distinct groups based on their relationship to the standard: direct ancestors, indirect relatives, hallucinations, \nand irrelevant terms\nPage 13 of 17\nGarcia et al. Genome Medicine           (2025) 17:91 \n \nDiscussion\nSummary\nWe developed RAG-HPO, a RAG framework designed \nto enable precise and comprehensive extraction of HPO \nterms from clinical case narratives using LLMs. RAG-\nHPO consistently outperforms existing tools in both pre -\ncision and recall while maintaining flexibility and ease \nof use (Fig.  3). While LLMs are capable of identifying \nphenotypic descriptions in text, they frequently misas -\nsign or incompletely map terms to HPO identifiers when \noperating in isolation (Table  3). RAG-HPO mitigates \nthese errors by grounding generation in a curated knowl -\nedge base during inference. This integration of retrieval \nreduces the incidence of hallucinated or invalid terms \nand promotes accurate alignment between clinical lan -\nguage and ontology-based concepts. When evaluated \non two independent datasets, the combination of RAG-\nHPO + LLaMA-3.1 70B achieved the highest F1 scores \namong all tested tools. It more than doubled the true \npositive rate of traditional dictionary-based concept rec -\nognition systems, with hallucinations accounting for less \nthan 1% of the output (Table 4).\nStrengths\nOne of RAG-HPO’s key strengths is its adaptability and \nease of use, even for users with limited experience in \nmachine learning or language model deployment. Unlike \ntraditional fine-tuning approaches, which demand sig -\nnificant time, computational resources, and specialized \nexpertise, our program leverages RAG to enable high-\nperformance HPO term extraction with minimal techni -\ncal burden. Users can easily update the vector database \nwith just a few clicks, ensuring that the tool remains \ncurrent and effective without the need for retraining or \nmodel modification.\nThe program is also simple to run, making it accessi -\nble to researchers and clinicians with limited technical \nexpertise. At the same time, its modular Python structure \nallows for easy integration, modification, and ongoing \nimprovement. RAG-HPO enables users to submit plain \ntext without needing to preprocess data or integrate into \nelectronic health records (EHR). This adaptability allows \nit to handle free-form medical text, making it especially \nuseful in rare disease research, where patient descrip -\ntions often vary in format (Fig. 2A).\nThis flexibility extends to model deployment. RAG-\nHPO is compatible with any LLM supporting the Ope -\nnAI API framework, including those hosted locally \nfor HIPAA-compliant workflows. This model-agnostic \ndesign allows researchers and clinicians to select back -\nends that best meet their infrastructure and privacy \nneeds. As demonstrated by our cross-platform analysis \nof LLM performance, model selection is a key factor in \noptimizing precision and recall. For example, replacing \nthe baseline LLaMA-3 70B with the alignment-tuned \nLLaMA-3.1 70B led to notable gains in both precision \n(0.71 to 0.81) and recall (0.61 to 0.76), resulting in an \nF1 score of 0.78 (Table  3). Interestingly, the lightweight \nLLaMA-4 Scout (16B parameter size) approached a simi -\nlar level of performance (F1 = 0.66) to LLaMA-3 70B, \ndespite being smaller. These findings highlight the value \nof backbone selection and suggest that newer model fam-\nilies may continue to improve with future releases.\nPerformance profiling revealed additional insights into \nprogram behavior. Organ system had a minimal overall \neffect on performance, with odds ratios clustering around \n1 (Fig. 6A). Slight boosts were observed for cardiovascu -\nlar, genitourinary, and head and neck terms, with some \nreaching odds ratios between 8 and 11. However, the \norgan system type was not the dominant driver of perfor-\nmance. Nodal depth, which can be used as a measure of \nHPO term specificity, had a more consistent and mono -\ntonic effect: deeper terms reduced hit probability across \nall tools, reflecting the increased difficulty of matching \ncomplex or distal ontology nodes (Fig. 6B) with described \nphenotypes. Although all variants of RAG-HPO \nTable 5 Comparison of RAG-HPO performance to other tools in analysis of GSC. While RAG-HPO combined with LLaMA-3 70B \nachieved F1 scores comparable to FASTHPOCR, it identified a greater number of relevant HPO terms. The performance of LLaMA-4 \nScout, despite its smaller size, suggests that recent architectural advances may enable smaller LLMs to perform competitively in \nphenotypic extraction tasks, potentially reducing computational burden in future applications\nLLM + RAG‑HPO True positive False positive False negative Average \nprecision\nAverage recall Average F1\nLLaMA-3 70B 766 358 245 0.69 0.77 0.71\nLLaMA-4 Scout 783 490 228 0.62 0.79 0.68\nOther HPO analysis tools\n FASTHPOCR 696 241 315 0.74 0.70 0.70\n Doc2HPO 438 89 573 0.80 0.44 0.56\n ClinPhen 428 204 583 0.61 0.42 0.46\nPage 14 of 17Garcia et al. Genome Medicine           (2025) 17:91 \ndisplayed a similar performance drop rate as other tools, \nmost had a consistently higher F1 compared to the more \ntraditional dictionary-based concept recognition tools.\nTool‑to‑tool comparisons further underscored RAG‑HPO’s \nadvantages\nRAG-HPO + LLaMA-3.1 70B tripled the odds of cor -\nrect HPO assignment compared to Doc2HPO (Fig.  6C). \nEven the weakest RAG variant performed as well as or \nbetter than the strongest rule-based tool. A trade-off was \nobserved between backbone strength and hit probability \nbehavior: stronger models generally yielded higher recall \nand captured more distant matches, while weaker mod -\nels offered slightly higher precision but lower sensitivity \noverall. Larger context windows, such as those used in \nLLaMa-4 Scout, appeared to lift recall but also slightly \ninflated false positives, reflecting a precision-recall \ntrade-off.\nFinally, RAG-HPO’s structural modularity enables \nincremental improvement over time. Its components, \nincluding system prompts, embedding generation, simi -\nlarity search, and LLM integration, can be independently \nmodified, swapped, or upgraded. The retrieval database \ncan be updated without retraining the underlying model, \nensuring compatibility with evolving versions of the HPO \nas long as the embedding process for the database is the \nsame as the embedding process used during the deep \nphenotype extraction process. This makes RAG-HPO not \nonly performant and flexible, but also capable of keeping \nup with changes in the LLM field.\nRecently, others have used a predetermined dataset, the \nGSC, to evaluate their analysis programs [15, 23, 35]. The \nGSC was derived from entries in the Online Mendelian \nInheritance in Man (OMIM) database and contains a mix \nof content types, including structured disease descrip -\ntions and a subset of passages formatted to resemble clin-\nical notes. While this dataset has served as a comparative \nbenchmark for several tools, it presents significant limi -\ntations for evaluating systems designed for clinical NLP \nand deep phenotype extraction.\nMany of the GSC entries resemble scientific abstracts \nor informational summaries describing well-known \ngenetic conditions such as neurofibromatosis, Gorlin \nsyndrome, and branchio-oto-renal syndrome. However, \nthis format often results in annotated truth sets popu -\nlated with general or lower information-content HPO \nterms, even when more specific alternatives are appropri-\nate. For instance, in case 1,347,096, the phrase “basal cell \ncarcinoma” appears in the source text, yet the annotation \nincludes both HP:0002671 (“basal cell carcinoma”) and \nthe more general HP:0030731 (“carcinoma”). In contrast, \nour approach to deep phenotyping emphasizes select -\ning the single most descriptive and specific term, with \nthe understanding that downstream analyses can lev -\nerage the HPO’s hierarchical structure to trace lineages \nand identify ancestral terms as needed. As a result, reli -\nance on the GSC as a primary evaluation benchmark may \nunderestimate the capabilities of tools like RAG-HPO, \nwhich are designed to prioritize specificity, precision, and \ncontextual depth in phenotype assignment.\nAlthough we had access to the GSC, we deliberately \ndeveloped a separate cohort composed of published \nclinical case reports—the CSC. Unlike the condensed, \ncitation-style summaries found in the GSC, these reports \nmore closely resemble real-world clinical documentation, \ncapturing greater variability, language, and contextual \ndetail more reflective of medical records. To ensure data \nquality, we applied strict inclusion criteria and employed \nmultilayered manual annotation, with review by medi -\ncal genetics professionals to promote consistency and \naccuracy.\nBeyond differences in size and term count (the GSC \ncontained 114 entries with 415 unique HPO terms (8.9 \nper case on average), while our CSC included 112 reports \nwith 1208 unique terms and a higher annotation density \n(15.8 terms per case)), the structural composition of the \ntwo datasets further underscores their divergence. The \nGSC is heavily skewed toward a narrow set of organ sys -\ntems—primarily nervous, musculoskeletal, and head/\nneck domains—while significantly underrepresent -\ning others such as endocrine, cardiovascular, and geni -\ntourinary systems (Additional file  2: Fig. S4B). This bias \nreflects the GSC’s origin in genetic reference databases \nand its focus on well-characterized monogenic condi -\ntions. However, the HPO database has matured to sup -\nport a much broader array of clinical concepts, extending \nbeyond neurological and congenital disorders. In con -\ntrast, our case study cohort offers a more balanced and \ncomprehensive distribution across organ systems (Fig. 3), \nproviding a more robust foundation for evaluating phe -\nnotype extraction tools intended for general clinical \napplication.\nDespite these limitations, RAG-HPO demonstrated \nstrong performance on the GSC dataset, achieving the \nhighest recall (0.77–0.79) and F1 score (0.71) among all \ntools tested (Table  4). This underscores the robustness \nof the RAG-HPO architecture and its ability to general -\nize across dataset types. However, the relative success of \nFASTHPOCR on this benchmark may reflect alignment \nwith the dataset’s structure, as both were developed by \nthe same research group—a factor that may inflate appar-\nent performance. These findings highlight the broader \nchallenge of overfitting to familiar benchmarks and rein -\nforce the need for diverse, heterogeneous evaluation sets.\nPage 15 of 17\nGarcia et al. Genome Medicine           (2025) 17:91 \n \nLimitations\nOne limitation of RAG-HPO is its processing speed. \nWhile individual clinical notes may take up to 45 s to \nanalyze, other tools, such as FastHPOCR, can process the \nentire 112 case cohort in that time. However, this longer \nruntime for RAG-HPO is offset by its superior precision \nand comprehensive output, which reduces the need for \ndownstream correction and ultimately supports more \naccurate deep phenotype extraction.\nAnother challenge is that the precision of RAG-HPO \ndepends heavily on the quality of the vector database \nused for semantic similarity searches. While our current \ndatabase is carefully curated and regularly updated, it \nremains largely oriented toward genetic disease pheno -\ntypes, reflecting the historical focus of HPO itself. How -\never, it is also limited by the available HPO terms, which \nare tailored toward features recognized in medical genet -\nics. This introduces the potential for rare mismatches—\nparticularly when semantic similarity scores rank related \nbut suboptimal terms highly. While retrieval constraints \nminimize outright hallucinations, they may still return \nless-than-ideal terms if the embedding space misfires. \nHowever, most false positives returned by RAG-HPO are \nclosely related terms rather than completely irrelevant \nmatches. These near misses may still hold clinical value, \nparticularly in differential diagnosis workflows or patient \ncomparative studies where broader phenotypic context is \nuseful.\nAs the HPO database matures, we expect precision \nto improve. To support this ongoing process, we have \nmade the full program for vector database creation, as \nwell as the supplementary metadata used to enrich each \nterm, publicly available on GitHub. A spreadsheet-for -\nmat supplement document enables users to view and \nupdate curated entries, which are merged with the cur -\nrent hp.obo to regenerate the full index. This FAIR-com -\npliant structure allows end users to integrate their own \nvalidated entries and optionally submit them back to \nthe authors for inclusion in future versions after review. \nOur long-term goal is to promote this as a community-\nsupported effort, enabling sustainable, open-source \nimprovement of the database for as long as the tool \nremains clinically or scientifically valuable. However, the \nsubjective nature of phenotype interpretation can still \ninfluence results, as different users may prioritize varying \nlevels of specificity. While RAG-HPO is designed to iden-\ntify the most precise HPO term for a given phenotypic \nphrase, some users may seek a broader characterization \nof a patient’s phenotype.\nThe inherent subjectivity of clinical evaluations, \nthrough which different physicians may arrive at differ -\nent interpretations of the same patient, can also impact \nthe phenotyping process. Although HPO terms aim to \nstandardize patient presentations, variability in clinical \nassessment may still affect the final set of phenotypes \nattributed to an individual patient. While minimized \nwith the use of LLMs in the automated deep phenotyp -\ning process, this subjectivity will persist when comparing \ncases of individuals seen by different physicians. Further \ndownstream analyses focused on comparing HPO term \nlineages along with the specific HPO terms can further \nmitigate the impact of clinician subjectivity in patient \nevaluation.\nFinally, RAG-HPO’s recall is influenced by the choice \nof LLM backend. More powerful models with broader \ncontextual understanding generally yield higher recall \nand better interpretation of complex or obliquely phrased \nphenotypes. Fortunately, the system is designed to be \nmodel-agnostic, allowing users to substitute any Ope -\nnAI-compatible LLM. We selected LLaMa-3 70B as \na balance between performance and accessibility, but \nongoing improvements in open-source language models \nare likely to yield continued gains in speed, accuracy, and \nflexibility.\nFuture directions\nOur primary objective in developing RAG-HPO is to cre-\nate an efficient and user-friendly tool for automated deep \nphenotyping. Looking ahead, we plan to further improve \nthe vector database by incorporating user contributions \nof verified phrases that consistently map to established \nHPO terms. This community-driven approach will sup -\nport ongoing refinement and ensure the system remains \nresponsive to evolving clinical language.\nAlthough RAG-HPO was initially designed for deep \nphenotype extraction in the context of rare genetic vari -\nant discovery, its potential applications extend to other \nareas of medicine that rely on patient comparison or \ncharacterization based on clinical presentation. Future \nefforts will focus on expanding these use cases to include \nphenotype clustering, cohort matching, and differential \ndiagnosis. To support these broader goals, we are also \nexploring hybrid pipelines that combine high-precision \ndictionary filters with retrieval-based augmentation to \nbalance specificity and recall.\nAs RAG-HPO continues to evolve, we aim to estab -\nlish it as a generalizable, open-source clinical phe -\nnotyping tool. We plan to promote ontology-aware \nevaluation frameworks that classify errors by term rela -\ntionships (e.g., ancestor, relative, unrelated), enabling \nmore nuanced assessments of tool performance. These \nstrategies will support more scalable, adaptable applica -\ntions of RAG-HPO across research and clinical settings.\nPage 16 of 17Garcia et al. Genome Medicine           (2025) 17:91 \nConclusions\nRAG-HPO represents a significant advancement in the \nfield of automated deep phenotyping, demonstrating \na marked improvement over traditional HPO tools in \nboth precision and recall. By leveraging retrieval-aug -\nmented generation (RAG) and a dynamic vector data -\nbase of over 54,000 phenotypic terms, RAG-HPO offers \nclinicians and researchers an accessible, computation -\nally efficient solution for phenotype extraction that is \nboth adaptable and resource-light. Unlike conventional \nLLM-based tools, RAG-HPO minimizes the need for \nfine-tuning and reduces the risks of “hallucinations, ” \nmaking it a reliable and scalable tool for phenotypic \nanalysis, particularly in rare disease diagnosis and clini -\ncal genomics.\nAvailability and requirements:\nProject name: RAG-HPO [45]\nHome page: https:// github. com/ Posey Pod/ RAG-  \nHPO\nOperating system(s): MacOS and Windows\nProgramming language: Python\nOther requirements:\nLicense: MIT, CC BY 4.0 Attribution\nAny restrictions to use by non-academics:as per \nMIT license with appropriate attribution\nAbbreviations\nAPI  Application Programming Interface\nCSC  Case study cohort\nGSC  Gold standardized corpora\nHPO  Human Phenotype Ontology\nJSON  JavaScript Object Notation\nLLM  Large language model\nOMIM  Online Mendelian Inheritance in Man\nRAG   Retrieval-augmented generation\nSupplementary Information\nThe online version contains supplementary material available at https:// doi. \norg/ 10. 1186/ s13073- 025- 01521-w.\nAdditional file 1. Vector database dictionary. This spreadsheet file contains \na table of all key-value pairs, mapping each clinical word or phrase (“key”) \nto an HPO ID (“value”).\nAdditional file 2. Supplemental text and figures. This text file includes \nsupplemental text demonstrated the system messages generated by \nRAG-HPO and provided to the user, as well as supplemental figures.\nAdditional file 3. RAG-HPO tests and data analysis. This spreadsheet file \ncontains the HPO IDs for the case sets against which benchmarking was \nperformed, as well as the benchmarking data itself, across all tested tools.\nAcknowledgements\nWe would like to thank the following for their help and support in creating \nRAG-HPO: Thanks to Steve Ludke, PhD, Maxim Seferovic, PhD, and Shinya \nYamamoto DVM, PhD for your guidance in coding in Python; thanks to Gwen-\ndolyn Hummel for biostatistics guidance; and thanks to Cole Deisseroth for \nbeing a resource for information on HPO analysis and the application of NLP \nto deep phenotyping.\nAuthors’ contributions\nBTG designed the study, created the software, collected, analyzed and \ninterpreted the data, and drafted the manuscript. PY selected the test cohort \nindependently of other authors. BTG and LW created the manually annotated \nstandard. LW, PY, NG, EARM, HD, MD, and AJ assisted with data collection, anal-\nysis, and interpretation. JRL assisted with data interpretation. JEP supervised \nthe study design, data collection and analysis. All authors read and approved \nthe final manuscript.\nFunding\nThis study was supported by the US NIH National Human Genome Research \nInstitute (NHGRI) U01 HG011758 to the Baylor College of Medicine Genomic \nResearch to Elucidate the Genetics of Rare disease center (BCM-GREGoR).\nData availability\nPublished case reports and data used to benchmark RAG-HPO are provided \nwithin the Supplemental Files. RAG-HPO is available for download at https://\ngithub.com/PoseyPod/RAG-HPO.\nDeclarations\nEthics approval and consent to participate\nAll clinical texts and data used herein were derived from published case \nreports available in the medical literature or the published gold standardized \ncorpora. No unpublished clinical or research patient data were implemented \nin this study.\nConsent for publication\nNot applicable. No unpublished clinical or research patient data were imple-\nmented in this study.\nCompeting interests\nThe Department of Molecular & Human Genetics at Baylor College of \nMedicine receives revenue from clinical genetic testing conducted at Baylor \nGenetics Laboratories. JRL is a co-inventor on multiple United States and \nEuropean patents related to molecular diagnostics for inherited neuropathies, \neye diseases, genomic disorders and bacterial genomic fingerprinting. J.E.P . is \na member of the advisory board for MaddieBio. The remaining authors declare \nthat they do not have any competing interests.\nAuthor details\n1 Department of Molecular and Human Genetics, Baylor College of Medicine, \nHouston, TX 77030, USA. 2 Medical Scientist Training Program, Baylor College \nof Medicine, Houston, TX 77030, USA. 3 Genetics and Genomics Graduate Pro-\ngram, Baylor College of Medicine, Houston, TX 77030, USA. 4 Texas Children’s \nHospital, Houston, TX 77030, USA. 5 Department of Obstetrics and Gynecol-\nogy, Baylor College of Medicine, Houston, TX 77030, USA. 6 School of Medi-\ncine, Meharry Medical College, Nashville, TN 37208, USA. 7 Human Genome \nSequencing Center, Baylor College of Medicine, Houston, TX 77030, USA. \n8 Department of Pediatrics, Baylor College of Medicine, Houston, TX 77030, \nUSA. 9 Department of Pediatrics, Columbia University Vagelos College of Physi-\ncians and Surgeons, Columbia University Irving Medical Center, New York, NY \n10032, USA. 10 Department of Medicine, Columbia University Vagelos College \nof Physicians and Surgeons, Columbia University Irving Medical Center, New \nYork, NY 10032, USA. \nReceived: 6 November 2024   Accepted: 29 July 2025\nReferences\n 1. Posey JE, Harel T, Liu P , Rosenfeld JA, James RA, Coban Akdemir ZH, et al. \nResolution of disease phenotypes resulting from multilocus genomic \nvariation. N Engl J Med. 2017;376:21–31.\n 2. Posey JE. Genome sequencing and implications for rare disorders. \nOrphanet J Rare Dis. 2019;14: 153.\n 3. Liu P , Meng L, Normand EA, Xia F, Song X, Ghazi A, et al. Reanalysis of clini-\ncal exome sequencing data. N Engl J Med. 2019;380:2478–80.\nPage 17 of 17\nGarcia et al. Genome Medicine           (2025) 17:91 \n \n 4. Posey JE, O’Donnell-Luria AH, Chong JX, Harel T, Jhangiani SN, \nCoban Akdemir ZH, et al. Insights into genetics, human biology and \ndisease gleaned from family based genomic studies. Genet Med. \n2019;21:798–812.\n 5. Posey JE, Lupski JR. Genomics in clinical practice. N Engl J Med. \n2023;388:1619-20.\n 6. Wright CF, Campbell P , Eberhardt RY, Aitken S, Perrett D, Brent S, et al. \nGenomic diagnosis of rare pediatric disease in the United Kingdom and \nIreland. N Engl J Med. 2023;388:1559–71.\n 7. Rehm HL, Berg JS, Brooks LD, Bustamante CD, Evans JP , Landrum MJ, et al. \nClinGen–the clinical genome resource. N Engl J Med. 2015;372:2235–42.\n 8. Robinson PN, Mundlos S. The human phenotype ontology. Clin Genet. \n2010;77:525–34.\n 9. Robinson PN, Köhler S, Bauer S, Seelow D, Horn D, Mundlos S. The human \nphenotype ontology: a tool for annotating and analyzing human heredi-\ntary disease. Am J Hum Genet. 2008;83:610–5.\n 10. Putman TE, Schaper K, Matentzoglu N, Rubinetti VP , Alquaddoomi FS, Cox \nC, et al. The Monarch Initiative in 2024: an analytic platform integrat-\ning phenotypes, genes and diseases across species. Nucleic Acids Res. \n2024;52:D938–49.\n 11. Son JH, Xie G, Yuan C, Ena L, Li Z, Goldstein A, et al. Deep phenotyping on \nelectronic health records facilitates genetic diagnosis by clinical exomes. \nAm J Hum Genet. 2018;103:58–73.\n 12. Liu C, Peres Kury FS, Li Z, Ta C, Wang K, Weng C. Doc2hpo: a web applica-\ntion for efficient and accurate HPO concept curation. Nucleic Acids Res. \n2019;47:W566–70.\n 13. Deisseroth CA, Birgmeier J, Bodle EE, Kohler JN, Matalon DR, Nazarenko \nY, et al. ClinPhen extracts and prioritizes patient phenotypes directly \nfrom medical records to expedite genetic disease diagnosis. Genet Med. \n2019;21:1585–93.\n 14. Karaca E, Posey JE, Coban Akdemir Z, Pehlivan D, Harel T, Jhangiani SN, \net al. Phenotypic expansion illuminates multilocus pathogenic variation. \nGenet Med. 2018;20:1528–37.\n 15. Groza T, Köhler S, Doelken S, Collier N, Oellrich A, Smedley D, et al. \nAutomatic concept recognition using the human phenotype ontology \nreference and test suite corpora. Database (Oxford). 2015;2015:bav005.\n 16. Köhler S, Øien NC, Buske OJ, Groza T, Jacobsen JOB, McNamara C, et al. \nEncoding clinical data with the human phenotype ontology for compu-\ntational differential diagnostics. Curr Protoc Hum Genet. 2019;103: e92.\n 17. Bone WP , Washington NL, Buske OJ, Adams DR, Davis J, Draper D, et al. \nComputational evaluation of exome sequence data using human and \nmodel organism phenotypes improves diagnostic efficiency. Genet Med. \n2016;18:608–17.\n 18. Cipriani V, Pontikos N, Arno G, Sergouniotis PI, Lenassi E, Thawong P , et al. \nAn improved phenotype-driven tool for rare Mendelian variant prioritiza-\ntion: benchmarking Exomiser on real patient whole-exome data. Genes. \n2020;11:460.\n 19. Smedley D, Jacobsen JOB, Jäger M, Köhler S, Holtgrewe M, Schubach M, \net al. Next-generation diagnostics and disease-gene discovery with the \nExomiser. Nat Protoc. 2015;10:2004–15.\n 20. Doğan T. HPO2GO: prediction of human phenotype ontology term asso-\nciations for proteins using cross ontology annotation co-occurrences. \nPeerJ. 2018;6: e5298.\n 21. Xue H, Peng J, Shang X. Predicting disease-related phenotypes using an \nintegrated phenotype similarity measurement based on HPO. BMC Syst \nBiol. 2019;13(Suppl 2): 34.\n 22. Dohi E, Takatsuki T, Tateisi Y, Fujiwara T, Yamamoto Y. Examining HPO \nby organ and system to facilitate practical use by clinicians. Genomics \nInform. 2024;22: 23.\n 23. Groza T, Gration D, Baynam G, Robinson PN. FastHPOCR: pragmatic, fast, \nand accurate concept recognition using the human phenotype ontol-\nogy. Bioinformatics. 2024;40:btae406.\n 24. Yan C, Ong HH, Grabowska ME, Krantz MS, Su W-C, Dickson AL, \net al. Large language models facilitate the generation of electronic \nhealth record phenotyping algorithms. J Am Med Inform Assoc. \n2024;31(9):1994–2001.\n 25. Zeng Z, Deng Y, Li X, Naumann T, Luo Y. Natural language processing for \nEHR-based computational phenotyping. IEEE ACM Trans Comput Biol \nBioinform. 2019;16:139–53.\n 26. Kim J, Wang K, Weng C, Liu C. Assessing the utility of large language \nmodels for phenotype-driven gene prioritization in the diagnosis of rare \ngenetic disease. Am J Hum Genet. 2024;111:2190–202.\n 27. Groza T, Caufield H, Gration D, Baynam G, Haendel MA, Robinson PN, et al. \nAn evaluation of GPT models for phenotype concept recognition. BMC \nMed Inform Decis Mak. 2024;24: 30.\n 28. Gargari OK, Fatehi F, Mohammadi I, Firouzabadi SR, Shafiee A, Habibi \nG. Diagnostic accuracy of large language models in psychiatry. Asian J \nPsychiatr. 2024;100: 104168.\n 29. Young CC, Enichen E, Rivera C, Auger CA, Grant N, Rao A, et al. Diagnostic \naccuracy of a custom large language model on rare pediatric disease \ncase reports. Am J Med Genet A. 2025;197: e63878.\n 30. Li Y, Zhao J, Li M, Dang Y, Yu E, Li J, et al. RefAI: a GPT-powered retrieval-\naugmented generative tool for biomedical literature recommendation \nand summarization. J Am Med Inform Assoc. 2024;31:2030–9.\n 31. Cui H, Wang C, Maan H, Pang K, Luo F, Duan N, et al. ScGPT: toward build-\ning a foundation model for single-cell multi-omics using generative AI. \nNat Methods. 2024;21:1470–80.\n 32. Li Q, Li L, Li Y. Developing ChatGPT for biology and medicine: a complete \nreview of biomedical question answering. Biophys Rep. 2024;10:152–71.\n 33. Luo L, Yan S, Lai P-T, Veltri D, Oler A, Xirasagar S, et al. PhenoTagger: a \nhybrid method for phenotype concept recognition using human pheno-\ntype ontology. Bioinformatics. 2021;37:1884–90.\n 34. Feng Y, Qi L, Tian W. Phenobert: a combined deep learning method for \nautomated recognition of human phenotype ontology. IEEE ACM Trans \nComput Biol Bioinform. 2023;20:1269–77.\n 35. Yang J, Liu C, Deng W, Wu D, Weng C, Zhou Y, et al. Enhancing phenotype \nrecognition in clinical notes using large language models: PhenoBCBERT \nand PhenoGPT. Patterns. 2024;5: 100887.\n 36. Soong D, Sridhar S, Si H, Wagner J-S, Sá ACC, Yu CY, et al. Improving accu-\nracy of GPT-3/4 results on biomedical data using a retrieval-augmented \nlanguage model. PLoS Digit Health. 2024;3: e0000568.\n 37.  Yang Y, Bean AM, McCraith R, Mahdi A. Evaluating fine-tuning efficiency \nof human-inspired learning strategies in medical question Answering. \narXiv. 2024.\n 38.  Wang A, Liu C, Yang J, Weng C. Fine-tuning large language models for \nrare disease concept normalization. BioRxiv. 2024.\n 39. Jeong M, Sohn J, Sung M, Kang J. Improving medical reasoning through \nretrieval and self-reflection with retrieval-augmented large language \nmodels. Bioinformatics. 2024;40(Suppl 1):i119–29.\n 40.  Qi X, Zeng Y, Xie T, Chen P-Y, Jia R, Mittal P , et al. Fine-tuning aligned \nlanguage models compromises safety, even when users do not intend \nto! arXiv. 2023.\n 41.  Luo Y, Yang Z, Meng F, Li Y, Zhou J, Zhang Y. An empirical study of \ncatastrophic forgetting in large language models during continual fine-\ntuning. arXiv. 2023.\n 42.  Lewis P , Perez E, Piktus A, Petroni F, Karpukhin V, Goyal N, et al. Retrieval-\naugmented generation for knowledge-intensive NLP tasks. arXiv. 2020.\n 43. Thomo A. PubMed retrieval with RAG techniques. Stud Health Technol \nInform. 2024;316:652–3.\n 44.  Gupta S, Ranjan R, Singh SN. A comprehensive survey of retrieval-\naugmented generation (RAG): evolution, current landscape and future \ndirections. arXiv. 2024.\n 45.  Garcia B, Posey JE. RAG-HPO. GitHub. https:// github. com/ Posey Pod/ RAG- \nHPO (2024).\n 46.  Deisseroth CA, Birgmeier J, Bodle EE, Kohler J, Matalon D, Nazarenko Y, \nGenetti CA, Brownstein CA, Schmitz-Abe K, Schoch K, Cope H, Signer R; \nUndiagnosed Diseases Network, Martinez-Agosto JA, Shashi V, Beggs \nAH, Wheeler MT, Bernstein JA, Bejerano G. ClinPhen. Computer software. \nhttp:// bejer ano. stanf ord. edu/ clinp hen/ (2018).\n 47.  Liu C, Kury FSP , Li Z, Ta C, Wang K, Weng C. Doc2Hpo. Github. https:// \ngithub. com/ storm liuco ng/ doc2h po (2019).\n 48.  Groza T. FastHPOCR. Github. https:// github. com/ tudor groza/ fast_ hpo_ cr \n(2024).\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub-\nlished maps and institutional affiliations.",
  "topic": "Human genetics",
  "concepts": [
    {
      "name": "Human genetics",
      "score": 0.5234324932098389
    },
    {
      "name": "Computer science",
      "score": 0.5038406252861023
    },
    {
      "name": "Computational biology",
      "score": 0.44281861186027527
    },
    {
      "name": "Systems biology",
      "score": 0.4240614175796509
    },
    {
      "name": "Artificial intelligence",
      "score": 0.41259002685546875
    },
    {
      "name": "Natural language processing",
      "score": 0.3258143663406372
    },
    {
      "name": "Biology",
      "score": 0.2026750147342682
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I181547552",
      "name": "Baylor College of Medicine",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210147586",
      "name": "Texas Children's Hospital",
      "country": "US"
    }
  ]
}