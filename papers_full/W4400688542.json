{
  "title": "Quantifying the uncertainty of LLM hallucination spreading in complex adaptive social networks",
  "url": "https://openalex.org/W4400688542",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5005657794",
      "name": "Guozhi Hao",
      "affiliations": [
        "Waseda University"
      ]
    },
    {
      "id": "https://openalex.org/A5004673608",
      "name": "Jun Wu",
      "affiliations": [
        "Waseda University"
      ]
    },
    {
      "id": "https://openalex.org/A5101657696",
      "name": "Qianqian Pan",
      "affiliations": [
        "Waseda University"
      ]
    },
    {
      "id": "https://openalex.org/A5053886638",
      "name": "Rosario Morello",
      "affiliations": [
        "University of Reggio Calabria"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6851092083",
    "https://openalex.org/W4389267014",
    "https://openalex.org/W4388896754",
    "https://openalex.org/W4384345745",
    "https://openalex.org/W4387819628",
    "https://openalex.org/W4389519585",
    "https://openalex.org/W2755200181",
    "https://openalex.org/W2998802640",
    "https://openalex.org/W2904131399",
    "https://openalex.org/W1983328582",
    "https://openalex.org/W2321653771",
    "https://openalex.org/W3011590841",
    "https://openalex.org/W3042091277",
    "https://openalex.org/W4389518784",
    "https://openalex.org/W2889787757",
    "https://openalex.org/W2950457956",
    "https://openalex.org/W2606974598",
    "https://openalex.org/W2119189484",
    "https://openalex.org/W2052104835",
    "https://openalex.org/W3014579271"
  ],
  "abstract": "Abstract Large language models (LLMs) are becoming a significant source of content generation in social networks, which is a typical complex adaptive system (CAS). However, due to their hallucinatory nature, LLMs produce false information that can spread through social networks, which will impact the stability of the whole society. The uncertainty of LLMs false information spread within social networks is attributable to the diversity of individual behaviors, intricate interconnectivity, and dynamic network structures. Quantifying the uncertainty of false information spread by LLMs in social networks is beneficial for preemptively devising strategies to defend against threats. To address these challenges, we propose an LLMs hallucination-aware dynamic modeling method via agent-based probability distributions, spread popularity and community affiliation, to quantify the uncertain spreading of LLMs hallucination in social networks. We set up the node attributes and behaviors in the model based on real-world data. For evaluation, we consider the spreaders, informed people, discerning and unwilling non-spreaders as indicators, and quantified the spreading under different LLMs task situations, such as QA, dialogue, and summarization, as well as LLMs versions. Furthermore, we conduct experiments using real-world LLM hallucination data combined with social network features to ensure the validity of the proposed quantifying scheme.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.529775857925415
    },
    {
      "name": "Data science",
      "score": 0.4429228603839874
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3642942011356354
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I150744194",
      "name": "Waseda University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I59725666",
      "name": "University of Reggio Calabria",
      "country": "IT"
    }
  ],
  "cited_by": 13
}