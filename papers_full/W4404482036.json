{
  "title": "Leveraging Large Language Models for Generating Labeled Mineral Site Record Linkage Data",
  "url": "https://openalex.org/W4404482036",
  "year": 2024,
  "authors": [
    {
      "id": null,
      "name": "Pyo, Jiyoon",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A4202076274",
      "name": "Chiang, Yao-Yi",
      "affiliations": [
        "University of Minnesota"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4224321524",
    "https://openalex.org/W2983024903",
    "https://openalex.org/W3112390839",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3011807731",
    "https://openalex.org/W6948359748",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2966961862",
    "https://openalex.org/W6910993747",
    "https://openalex.org/W2542998387",
    "https://openalex.org/W4200596076",
    "https://openalex.org/W3014705052",
    "https://openalex.org/W4385567282",
    "https://openalex.org/W1535212652",
    "https://openalex.org/W1531069719",
    "https://openalex.org/W4321448364",
    "https://openalex.org/W4233467455",
    "https://openalex.org/W3187743275",
    "https://openalex.org/W2750779823",
    "https://openalex.org/W3123375411"
  ],
  "abstract": "Record linkage integrates diverse data sources by identifying records that\\nrefer to the same entity. In the context of mineral site records, accurate\\nrecord linkage is crucial for identifying and mapping mineral deposits.\\nProperly linking records that refer to the same mineral deposit helps define\\nthe spatial coverage of mineral areas, benefiting resource identification and\\nsite data archiving. Mineral site record linkage falls under the spatial record\\nlinkage category since the records contain information about the physical\\nlocations and non-spatial attributes in a tabular format. The task is\\nparticularly challenging due to the heterogeneity and vast scale of the data.\\nWhile prior research employs pre-trained discriminative language models (PLMs)\\non spatial entity linkage, they often require substantial amounts of curated\\nground-truth data for fine-tuning. Gathering and creating ground truth data is\\nboth time-consuming and costly. Therefore, such approaches are not always\\nfeasible in real-world scenarios where gold-standard data are unavailable.\\nAlthough large generative language models (LLMs) have shown promising results\\nin various natural language processing tasks, including record linkage, their\\nhigh inference time and resource demand present challenges. We propose a method\\nthat leverages an LLM to generate training data and fine-tune a PLM to address\\nthe training data gap while preserving the efficiency of PLMs. Our approach\\nachieves over 45\\\\% improvement in F1 score for record linkage compared to\\ntraditional PLM-based methods using ground truth data while reducing the\\ninference time by nearly 18 times compared to relying on LLMs. Additionally, we\\noffer an automated pipeline that eliminates the need for human intervention,\\nhighlighting this approach's potential to overcome record linkage challenges.\\n",
  "full_text": "Leveraging Large Language Models for Generating Labeled\nMineral Site Record Linkage Data\nJiyoon Pyo\npyo00005@umn.edu\nUniversity of Minnesota\nMinneapolis, Minnesota, USA\nYao-Yi Chiang\nyaoyi@umn.edu\nUniversity of Minnesota\nMinneapolis, Minnesota, USA\nAbstract\nRecord linkage integrates diverse data sources by identifying records\nthat refer to the same entity. In the context of mineral site records,\naccurate record linkage is crucial for identifying and mapping min-\neral deposits. Properly linking records that refer to the same mineral\ndeposit helps define the spatial coverage of mineral areas, bene-\nfiting resource identification and site data archiving. Mineral site\nrecord linkage falls under the spatial record linkage category since\nthe records contain information about the physical locations and\nnon-spatial attributes in a tabular format. The task is particularly\nchallenging due to the heterogeneity and vast scale of the data.\nWhile prior research employs pre-trained discriminative language\nmodels (PLMs) on spatial entity linkage, they often require substan-\ntial amounts of curated ground-truth data for fine-tuning. Gathering\nand creating ground truth data is both time-consuming and costly.\nTherefore, such approaches are not always feasible in real-world\nscenarios where gold-standard data are unavailable. Although large\ngenerative language models (LLMs) have shown promising results\nin various natural language processing tasks, including record link-\nage, their high inference time and resource demand present chal-\nlenges. We propose a method that leverages an LLM to generate\ntraining data and fine-tune a PLM to address the training data gap\nwhile preserving the efficiency of PLMs. Our approach achieves\nover 45% improvement in F1 score for record linkage compared\nto traditional PLM-based methods using ground truth data while\nreducing the inference time by nearly 18 times compared to relying\non LLMs. Additionally, we offer an automated pipeline that elimi-\nnates the need for human intervention, highlighting this approach‚Äôs\npotential to overcome record linkage challenges.\nCCS Concepts\n‚Ä¢ Information systems ‚ÜíEntity resolution; Geographic infor-\nmation systems.\nKeywords\nSpatial entity linkage, entity matching, geospatial data\n1 Introduction\nThe surge of web data has enabled the creation of rich and diverse\ndatasets by merging information collected from various sources, in-\ncluding web pages and research conducted by different individuals.\nHowever, this abundance of data has also increased data heterogene-\nity, emphasizing the need for efficient and effective data merging\nfrom various sources. Record linkage, the process of identifying\nrecords that refer to the same entity across datasets, is crucial to\novercoming inconsistencies and discrepancies between datasets\nand building a comprehensive database.\nInformation about mineral sites, such as their current status,\navailable minerals, ownership, site name, and location, is recorded\nand stored in mineral site databases. In the context of mineral site\ndata (e.g., Mineral Resources Data System (MRDS) [20] and USMIN\nMineral Deposit Database [15]), record linkage is critical to identify\nand map mineral deposit areas accurately. Figure 1 demonstrates an\nexample of linking mineral site records between USMIN and MRDS.\nThese databases contain records with missing values (i.e., nulls),\nattributes that indicate unique identifies (e.g., ‚ÄòSite_ID‚Äô for USMIN\nand ‚Äòdep_id‚Äô for MRDS), inconsistent attribute naming conventions\n(e.g., ‚ÄòApprox_Lon‚Äô for USMIN and ‚Äòlongitude‚Äô for MRDS), and\nvariation within attribute values (e.g., ‚ÄòYellow Pine‚Äô, ‚ÄòYellow Pine\nDeposit‚Äô, and ‚ÄòYellow Pine Mine‚Äô).\nRegarding spatial characteristics, recorders often simplify polygon-\nshaped location geometries to point data using generalization tech-\nniques such as centroid approximation to enhance data comprehen-\nsion. The level of abstraction varies based on the intended use of\nthe data [31], but it can significantly distort the spatial relationships\nbetween entries. For example, Figure 2 illustrates four points rep-\nresenting Eagle Mine in Michigan, along with the actual polygon\nlocation of the mine (shown in pink). Although the points are spa-\ntially dispersed, they all refer to Eagle Mine and should be linked. In\ncontrast, Figure 3 shows geographically close points representing\ndifferent mineral sites. An effective linkage model must differenti-\nate these points by recognizing the difference in site names, even if\nthe points are located nearby.\nLinking mineral sites poses additional challenges due to the spa-\ntial attributes present in each record. First, location information is\noften ambiguous; for instance, one record may describe the mine\nentrance, while another may reflect the center of the mineral de-\nposit. Along with that, the geographical location is often unreliable,\nas some records are inaccurately positioned, ranging up to 50 kilo-\nmeters1 due to older, less precise methods of data collection or\na significant map generalization. Furthermore, site names often\ninclude the names of the minerals present at the site (e.g., ‚ÄòCrescent\nCreek Cr-Pt‚Äô meaning Crescent Creek Chromium-Platinum) or de-\nposit types (e.g., ‚ÄòSilver Creek Placer‚Äô), complicating cross-dataset\ncomparisons. The difficulties mentioned above highlight the need\nfor robust record linkage models to accommodate such discrepan-\ncies and ensure a more accurate and comprehensive mapping of\nmineral resources.\nPrior approaches [ 1, 18] to record linkage often rely on pre-\ntrained discriminative language models (PLMs), such as Bidirec-\ntional Encoder Representations from Transformers (BERT) [ 7].\nPLM-based record linkage approaches typically cast the record\n1This issue was noted by Michael Zientek of the United States Geological Survey\n(USGS) during record verification.\narXiv:2412.03575v1  [cs.IR]  17 Nov 2024\nJiyoon Pyo and Yao-Yi Chiang\nFigure 1: Illustration of the mineral site record linkage process. The pipeline must accurately link records despite variations in\nrecorded information and style. Green highlights records that should be linked, while red indicates records that should not be\nlinked.\nFigure 2: Image of Eagle Mine, where each color represents a mineral site record from different databases [ 6, 15, 20, 22]. The\nactual polygon region of Eagle Mine is highlighted in light purple [24].\nlinkage problem as a binary classification problem, which requires\na large amount of labeled data (i.e., data indicating whether each\npair of records represents the same entity) for accurate performance.\nHowever, curating ground-truth data is costly, time-consuming, and\nrequires domain knowledge; this makes using PLMs impractical\nfor large-scale record linkage applications. In the scope of mineral\nsite linkage, experts can take up to several days to link datasets\nconsisting of a couple of hundred records2. Additionally, fine-tuned\nmodels show a lower performance when there is a significant data\nimbalance in the training data, where non-matching records are\n2We have learned the following information from United States Geological Survey\nexperts who have consulted our project. See also Goldman et al. [10].\nvastly outnumbered by matching ones. When trained on such im-\nbalanced data, PLMs often over-predict non-match pairs to boost\nthe overall model accuracy.\nRecent advancements in large generative language models (LLMs)\nhave shown promising potentials of improving record linkage [23,\n25], even when they are not trained on domain-specific data (i.e.,\nzero-shot setting). In other words, LLMs can classify whether two\nrecords are linked without extensive training data. Pre-trained on\nan extensive amount of datasets, even beyond the amount used to\npre-train discriminative models, LLMs can effectively understand\nand compare attributes, even when named differently (e.g., ‚Äòsite\nname‚Äô and ‚Äòother names‚Äô). For instance, if an LLM is presented\nwith two records‚Äìone listing ‚ÄòTungsten Jim‚Äô as the main mineral\nsite name and the other referring to ‚ÄòTungsten Jim‚Äô as an alternate\nLeveraging Large Language Models for Generating Labeled Mineral Site Record Linkage Data\nFigure 3: Image of General Washington Placer and Henderson Mine, with mineral records in different colors to represent\ndistinct mineral sites.\nname‚Äìit can accurately link the records without manual rules stat-\ning that the two represents the same attribute. This capability arises\nfrom LLM‚Äôs ability to recognize that both records refer to the same\nmineral site due to their locational proximity and identical naming\ndespite the variation in the attribute label. However, the practical\napplication of LLMs for record linkage is often limited due to their\nhigh computational cost and long processing time, posing issues\nin scalability. For record linkage, LLMs are typically provided with\nserialized text inputs representing two records [23], where each can\ncontain over 50 attributes. The cost of using LLMs depends on the\ninput length, making their use expensive for the record linkage task.\nAs LLMs generate text token by token, repeated calls are required to\ngenerate these sequences, increasing the computational demands.\nIn this work, we propose an approach that combines the strengths\nof both PLM and LLM to optimize the record linkage task for min-\neral site data. Our method leverages the generative capabilities\nof LLMs to create high-quality training data, which are used to\nfine-tune a PLM for a binary classification task (i.e., classifying\na pair of records as a match or a non-match). By utilizing LLMs,\nour two-stage approach mitigates the challenge associated with\nobtaining and labeling extensive training data. Additionally, our\nmethod maintains the inference time of PLMs, which is nearly 18\ntimes lower than the inference time of LLMs. The proposed ap-\nproach offers a scalable and effective strategy for addressing the\ncomplexities of real-world record linkage problems.\nWe summarize our contributions as follows:\n‚Ä¢ Development of a Hybrid Record Linkage Method :\nWe introduce an approach that combines the generative\ncapabilities of large language models with the classification\nefficiency of pretrained language models.\n‚Ä¢ Improvement in Scalability and Efficiency : By miti-\ngating the challenge of obtaining and labeling extensive\nground truth data, our method offers a scalable and efficient\nsolution for large-scale data linkage, making it particularly\napplicable to complex real-world scenarios, such as record\nlinkage for mineral site data.\n‚Ä¢ Analysis of Data Requirements and Data Imbalance :\nWe conduct comprehensive research to analyze the size of\ntraining data required for each class and assess how data\nimbalance impacts the performance of our model.\n2 Preliminaries and Related Work\nIn this section, we define record linkage (Section 2.1), distinguish\nPLMs and LLMs (Section 2.2), and review related work on utilizing\nPLMs and LLMs for record linkage (Section 2.3).\n2.1 Task Definition\nWe define the record linkage problem as follows:\nGiven a set of databases, {ùê∑1,ùê∑2 ¬∑¬∑¬∑ ùê∑ùëñ }, where ùê∑ùëó represents a\ndatabase, the task is to identify and link all records referring to the\nsame entity within and across all available databases. Each entity\nis characterized by a set of general attributes (e.g., place name,\navailable resources) and spatial attributes, which include point data\nthat could be derived from line or polygon geometries. The linkage\ntask involves matching entities across databases that may have\ndifferent schemas and missing attributes (i.e., null values).\n2.2 Definition of PLMs and LLMs\nIn this work, we define pre-trained discriminative language mod-\nels, which are encoder-based, as PLMs. Examples of PLMs include\nBERT [7], RoBERTa [38], and DistilBERT [30]. We refer to decoder-\nbased generative language models, including all models developed\nafter GPT-3 [5], as LLMs. Examples of LLMs include GPT-4 [ 36],\nJiyoon Pyo and Yao-Yi Chiang\nLLaMA [35], and Gemma [34], which are designed for text genera-\ntion tasks.\n2.3 Related Work\nRecord linkage is the task of integrating data to identify and link\nrecords in one or more databases that refer to the same entity. By\nlinking different datasets, record linkage enhances the amount of\ninformation available for each record, resulting in a more compre-\nhensive database.\nTraditional Record Linkage Earlier approaches [2] often use\ntraditional string similarity metrics, such as Levenshtein distance\nor Jaccard similarity, to determine whether two records refer to the\nsame entity. These methods rely on empirically defined rules and\nweights applied to manually selected attributes (e.g., name, social\nsecurity, or phone number) to calculate the similarity score. To\nresolve ambiguities, researchers use crowd-sourcing to eliminate\nconfounding factors or add additional details to assist the linking\nprocess in their models. As stated, these methods require extensive\nmanual rule development and data processing. Our work aims to\ndevelop a fully automated process that minimizes or eliminates the\nneed for human intervention.\nPLM-based Record Linkage To enhance the accuracy and\nscalability of entity linkage, recent approaches shift towards imple-\nmenting deep learning models, such as Long Short-Term Memory\n(LSTM) [12] and BERT [7]. These approaches not only reduce man-\nual processing but also enhance the accuracy of entity linkage.\nDeepER [9] introduces a method that uses LSTM networks and\nGlobal Vectors (GloVe) [26] text embeddings to capture semantic\nsimilarities between records. Similarly, Ditto [18] converts the de-\ntails of each record to a sentence and uses Sentence-BERT [ 28]\nto generate contextualized embeddings for sentences. PLM-based\nrecord linkage methods have demonstrated enhanced performance\nby considering all attributes available in the data rather than focus-\ning solely on manually selected key fields. However, their effective-\nness is limited by the availability of training data. T√§nzer et al. [33]\ndemonstrates that PLM-based methods fail to predict a class when\nthere are fewer than 25 instances of that class and require at least\n100 labeled examples to achieve a reasonable level of accuracy. Our\napproach addresses this challenge by generating synthetic training\ndata, which creates a framework that reduces dependency on large\nvolumes of labeled data.\nLLM-based Record Linkage There is a growing interest in\ndeveloping unsupervised or semi-supervised record linkage ap-\nproaches to minimize the reliance on large labeled datasets. Large\nlanguage models (LLMs), pre-trained on vast amounts of data, have\nshown the potential of being a zero-shot solution for record linkage\nacross diverse domains. Narayan et al. [23] suggests applying LLMs\nto this task, achieving state-of-the-art results without fine-tuning\nthe model for record linkage. The researchers use serialization meth-\nods to convert structured tabular data into textual inputs to formu-\nlate the record linkage problem as a text generation task. Peeters\nand Bizer [25] further demonstrate that domain-specific prompt-\ning (e.g., asking to identify for the same ‚Äòmine‚Äô instead of ‚Äòentity‚Äô)\nand strict binary responses prompting (i.e., ‚ÄúYes‚Äù or ‚ÄúNo‚Äù) lead to\nmore stable results and significantly improve LLM‚Äôs performance.\nLLMs such as Generative Pretrained Transformer (GPT) [27] and\nLarge Language Model Meta AI (LLaMA) [35] hold extensive world\nknowledge by being trained on large-scale data, offering promises\nfor record linkage, especially in scenarios where labeled training\ndata is scarce or costly. However, their long inference time lim-\nits their applicability in record linkage tasks, which often involve\nprocessing large databases.\nBlocking To reduce the number of comparisons in record linkage,\na common approach is to use ‚Äòblocking‚Äô to create candidate pairs\nby identifying records that are most likely to represent a match.\nHowever, many state-of-the-art blocking methods are unsuitable for\nour scenario. The earliest deep learning-based method, DeepER [9],\ngenerates candidate pairs by aggregating all values in a record to\ntuple vectors. This approach cannot be applied to our dataset since\nthe details present in each record differ, with the significance of\neach attribute value varying. Some columns may be irrelevant, but\nwithout proper weighting, all attributes are treated equally, which\ncan distort the results. A more advanced method, AutoBlock [37],\nimproves DeepER by learning aggregation weights from labeled\ndata. Yet, the mineral site record linkage case lacks sufficient labeled\ndata to train this method effectively.\nDeepBlock [14] uses hash-blocking with word embeddings to\ncompute semantic similarity between attribute names. In mineral\nsite linkage, the number of attributes often depends on the granu-\nlarity of the records. For example, in one data (e.g., USMIN [15]),\nminerals available at a site might be listed under a single ‚Äòcom-\nmodity‚Äô column, while in another data set (e.g., MRDS [ 20]), the\nsame information might be spread across multiple columns (e.g.,\n‚Äòcommod1‚Äô, ‚Äòcommod2‚Äô, ‚Äòcommod3‚Äô) based on the mineral availabil-\nity. This inconsistency introduces challenges when applying this\nblocking method to our approach, highlighting the limitations of\nblocking methods in the mineral site record linkage context.\nSpatial Record Linkage There has been research conducted\nspecifically for spatial record linkage where researchers try to pre-\nserve the spatial semantics during the linkage process rather than\nconsidering them as plain strings [16]. Existing spatial entity link-\nage methods [2] often depend on cleaned data that adheres to a\npredefined schema with latitude and longitude points. These meth-\nods typically calculate spatial distances, such as Haversine distance,\nto determine whether two spatial entities are likely to represent\nthe same entity. For example, GeoER [1] leverages a BERT-based\nmodel to compare non-spatial attributes while relying on Haver-\nsine distance calculation to compare spatial attributes. SkyEx [13]\nutilizes spatial blocking to filter out non-match based on the dis-\ntance between points of interest (POIs). They then use a preference\nfunction to rank pairs based on the likelihood of referring to the\nsame entity.\nPrior spatial record linkage methods have primarily focused on\nPOI data. Unlike POIs, the spatial distance between two mineral site\nrecords can vary significantly depending on the type and location of\nthe deposit, making these previous approaches less effective when\nlinking mineral site records. As shown in Figure 4, while match\nrecords in the OSM-Foursquare (FSQ) and OSM-Yelp datasets have\ndistance proximity within a 2.5-kilometer range, match records in\nmineral site databases can have distances spanning up to 35 kilome-\nters, with comparable amounts of data in each distance range. Due\nto this variability, we cannot rely on predefined distance thresh-\nolds and models trained on POI data for our problem. For example,\nLeveraging Large Language Models for Generating Labeled Mineral Site Record Linkage Data\nGeoER [1] uses a 2-kilometer boundary in the initial step to reduce\nthe number of comparisons. However, when linking mineral site\nrecords, selecting an appropriate distance threshold becomes am-\nbiguous due to the significant variability in distances, indicating\nthat such methods cannot be adapted to our context.\nWhile traditional and advanced methods offer valuable insights,\nthey often require extensive manual effort and substantial train-\ning data or are computationally expensive to be scaled to a large\ndataset. Our proposed approach addresses these limitations by uti-\nlizing LLMs to generate training data and fine-tune PLMs, thereby\nenhancing record linkage performance in scenarios with limited\nlabeled data.\n3 Proposed Approach\nOur proposed record linkage method leverages the extensive knowl-\nedge of LLMs and the efficient inference capabilities of PLMs. The\nmethodology comprises two main steps: (1) generating labeled\ntraining data using LLMs and (2) performing record linkage using\na PLM. This two-step approach addresses the challenge of limited\nground-truth training data and reduces the long inference times\nassociated with relying solely on LLMs for the entire record linkage\nprocess.\n3.1 Training Data Generation\nTo generate the training data, we use LLaMA3-8b [ 8], an open-\nsource LLM. While larger and more recent models, such as GPT4o [36],\nmay potentially offer better performance, we selected LLaMA3-8b\ndue to computational constraints and the potential for fine-tuning\nthe model to create more precise labels. Using this model allows\nfor future optimization without overburdening available resources.\nUsing LLMs as a method to generate training data involves framing\nthe record linkage problem as a text-generation task. Therefore, we\nuse the tabular data serialization method proposed by Narayan et al.\n[23]. Each entity‚Äôs attributes and values are serialized as follows:\nserialize(e):=attr1:val1...attrùëñ :valùëñ\nFor record pair serialization, we follow the method proposed by\nPeeters and Bizer [25], prompting the LLM to label the record pairs\nusing the following template:\nEntity A is serialize(A).\nEntity B is serialize(B).\nDo the two mine descriptions refer to the same\nreal-world mine. Answer with ‚ÄòYes‚Äô if they do and\n‚ÄòNo‚Äô if they do not.\nAnswer only in Yes or No.\nPrevious study [25] demonstrates that restricting responses to\n‚ÄúYes‚Äù or ‚ÄúNo‚Äù improves the performance of LLMs. Without explicit\nprompts enforcing strict response formats (i.e., ‚ÄòAnswer only in Yes\nor No.‚Äô), LLMs tend to generate extended reasoning. To eliminate\nthe need for manual post-processing, we limit the LLM‚Äôs response\nto ‚ÄúYes‚Äù or ‚ÄúNo‚Äù.\nWe convert the ‚ÄúYes‚Äù or ‚ÄúNo‚Äù labels generated by the LLMs into\nbinary values, with 1 representing a match and 0 representing a\nnon-match. This creates a dataset that follows the structure shown\nin Table 1. The columns uri_1 and uri_2 represent the unique ID\nfor each record. In cases where the unique ID is not available, we\nuse the row number as the unique identifier.\nuri_1 uri_2 llama_prediction\nIDEntity A IDEntity B 0\nIDEntity A IDEntity C 0\nIDEntity A IDEntity D 1\nTable 1: Structure of LLM synthesized data.\n3.2 Record Linkage\nFor the record linkage task, we utilize RoBERTa [ 38], a robustly\noptimized variant of BERT [ 7], as the PLM for fine-tuning. We\nselect RoBERTa over BERT since RoBERTa shows better perfor-\nmance across various downstream natural language processing\n(NLP) tasks than BERT. This improvement is due to RoBERTa‚Äôs train-\ning on a larger dataset, which increased from 16GB to 160GB [38]\ncompared to BERT, resulting in a more extensive vocabulary. Our\nempirical results, detailed in Appendix B, demonstrate that fine-\ntuning RoBERTa outperforms BERT and other variants, such as\nDeBERTa [11].\nTo evaluate our approach, we fine-tune the model using LLaMA-\nlabeled data. RoBERTa, similar to BERT, provides deeply contex-\ntualized embeddings that capture the semantic meaning of the\ninput data, which is crucial for effective record linkage. To pre-\npare the data, we adopt the text serialization approach proposed in\nDitto [18] since the suggested method is widely used in PLM-based\nrecord linkage tasks (e.g., Balsebre et al. [1]). For each data entry,\ne=(attrùëñ ,valùëñ )1 ‚â§ùëñ ‚â§ùëò , we serialize the attributes and values as\nfollows:\nserialize(e):= [COL]attr1 [VAL]val1\n... [COL]attrùëñ [VAL]valùëñ\nwhere [COL] and [VAL] are special tokens indicating the start of\nattribute names and values, respectively.\nFor serializing record pairs(e1,e2), we use the following format:\nserialize(e1,e2):= [CLS] serialize(e1)\n[SEP] serialize(e2) [SEP]\nwhere [CLS] is the special token indicating the beginning of the se-\nquence, and [SEP] is the special token separating the two records3.\nWe fine-tune the PLM so that, given a serialized record pair as\ninput, it outputs one of the binary labels, which corresponds to\nmatch or non-match.\n4 Evaluation\nWe evaluate the effectiveness of our proposed approach by applying\nit to mineral sites throughout the United States. For this evalua-\ntion, we use the Mineral Resources Data System (MRDS) [20] and\nthe United States Mineral Deposit Database project (USMIN) [15]\ndatabases, which are comprehensive mineral site repositories record-\ning various characteristics of mining sites, such as site names, al-\nternative names, geographical locations, and the types of minerals\npresent. The heterogeneity of these databases, in terms of schema\n3We modify RoBERTa‚Äôs original special token dictionary, replacing the beginning-of-\nsequence token <s> with [CLS] and the end-of-sequence token </s> with [SEP].\nJiyoon Pyo and Yao-Yi Chiang\nFigure 4: Record-to-record distance distribution of match data from OSM-FSQ/OSM-Yelp compared to mineral sites data. While\nOSM-FSQ and OSM-Yelp data fits within a 2.5-kilometer range, the distance between match mineral site records can range up to\n35 kilometers, with a similar distribution across the bins. This highlights the limitation of spatial record linkage methods\nthat rely on empirically defined distance thresholds since such approaches may not be suitable for domains with large spatial\ndistance variance, like mineral sites.\ndifferences and data representation, makes them well-suited for\ntesting the robustness and adaptability of our approach. Figure 5\ndisplays an example of heterogeneity that is common in the dataset:\nmany of the items are null values, such as ‚Äòcommod2‚Äô and ‚Äòcom-\nmod3‚Äô, and some columns only consist of unique items for each\nrecord such as ‚Äòdep_id‚Äô and ‚Äòmrds_id‚Äô. The figure demonstrates the\ndifficulties that arise when identifying matching data, even within\na database that shares an identical schema.\n4.1 Experimental Setup\nIn the following section, we detail the experimental setup used to\nevaluate our approach. This includes a comprehensive description\nof the training and testing dataset (Section 4.1.1), the evaluation\nmetrics employed (Section 4.1.2), the validation process for the LLM\nmodel utilized in the training data generation (Section 4.1.3), the\ndetails on training the PLM (Section 4.1.4), and the details on the\nbaseline methods (Section 4.1.5).\n4.1.1 Dataset. We use the Tungsten assessment dataset [ 10], a\nmanually curated dataset by the USGS, to train one of the baseline\nmodels (detailed in Section 4.1.5) and to evaluate the performance\nof both the baseline models and proposed approach. This dataset\ncontains records from the MRDS and USMIN databases focusing\non Tungsten mining sites in Idaho and Montana. The Tungsten\nassessment dataset comprises 387 records (383 from MRDS and 4\nfrom USMIN), generating a total of 74,691 potential record pairs\nfor analysis. The count of match pairs and the count of non-match\npairs are shown in Table 2.\nTo train our approach, we generate synthetic training data by\nasking an LLM to label ‚ÄúYes‚Äù (later mapped tomatch) and ‚ÄúNo‚Äù (later\nmapped to non-match) on randomly selected MRDS and USMIN\nrecords. We ensure that the volume of data‚Äì387 records and 74,691\nrecord pairs‚Äìis identical to that of the Tungsten assessment data.\nWe randomly select records from the entire dataset, which leads\nto the data covering diverse minerals (e.g., Zinc and Copper) and a\nbroader geographical range (i.e., across the United States).\nAdditionally, a USGS expert has curated a Nickel ground truth\ndata4 covering the Upper Midwest United States. We use this dataset\nexclusively to evaluate the baseline models and our proposed ap-\nproach. The dataset comprises 24 mineral site records, resulting in\n276 potential record pairs for model evaluation.\nDetails of the datasets are available in Table 2.\n# Match Pairs # Non-Match Pairs\nGround Truth (Tungsten) 23 74668\nGround Truth (Nickel) 18 258\nLLM Labeled 437 74254\nTable 2: Count of match pairs and non-match pairs in each\ndataset.\n4.1.2 Evaluation Metrics. To evaluate the performance of our ap-\nproach in classifying record pairs into each category, we measure\nthree types of F1 scores: the match class F1 score (Equation 1), the\nnon-match class F1 score (Equation 2), and the macro-averaged\nF1 score (Equation 3). In these equations, ùë°ùëù represents the count\nof true positives, ùë°ùëõ represents true negatives, ùëìùëù represents false\npositives, and ùëìùëõ represents false negatives.\nMatch F1 = 2ùë°ùëù\n2ùë°ùëù +ùëìùëù +ùëìùëõ (1)\n4Michael Zientek from USGS has verified the accuracy of the data.\nLeveraging Large Language Models for Generating Labeled Mineral Site Record Linkage Data\nFigure 5: Sample of MRDS Data displaying the heterogeneity of the data. Some of the attributes are left blank, and some\nattributes consist purely of unique values.\nNon-match F1 = 2ùë°ùëõ\n2ùë°ùëõ+ùëìùëù +ùëìùëõ (2)\nMacro-averaged F1 = ùë°ùëù\n2ùë°ùëù +ùëìùëù +ùëìùëõ + ùë°ùëõ\n2ùë°ùëõ+ùëìùëù +ùëìùëõ (3)\nWe choose the macro-averaged F1 score over other average F1\nscore variants to account for the class imbalance [ 32] in the test\ndataset.\n4.1.3 LLM Performance Validation. Before generating the labeled\ntraining data, we first validate the performance of the LLaMA3-\n8b [8] model on the complete Tungsten and Nickel datasets, without\npartitioning the data into training, validation, and testing sets. For\nthe 74,691 Tungsten record pairs, LLaMA has a match F1 score of\n39.13% and a non-match F1 score of 99.96%. For the 276 Nickel pairs,\nLLaMA has a match F1 score of 70.96% and a non-match F1 score\nof 98.27%. Table 3 provides a breakdown of the number of correctly\nidentified match and non-match pairs in relation to the total number\nof pairs available in the ground truth data.\nHowever, the inference time was substantial at approximately\n3 hours on our computation resource (detailed in Section 4.1.6).\nThe computation involves ùëõùê∂2 comparisons, where ùëõ represents\nthe number of records. As a result, the number of combinations\ngrows quadratically with the number of records, leading to a cor-\nresponding quadratic increase in time complexity. This highlights\nthe impracticality of relying solely on LLMs for large-scale record\nlinkage tasks, particularly in scenarios involving extensive datasets.\nMineral site databases such as MRDS and USMIN are archives where\nsites have been recorded over decades and are represented by mul-\ntiple records across various databases. For instance, the MRDS [20]\ncontains over 300,000 records, and the USMIN database continues\nto expand [15]. The challenges regarding efficiency and scalability\nneed to be addressed. To verify that our approach is more efficient\ncompared to LLM-relying record linkage models, we compare the\ninference time based purely on LLM and our approach in relation\nto the number of records.\n4.1.4 Fine-Tuning PLMs. We randomly select 80% of the LLaMA-\nlabeled data to train a RoBERTa model [38] and evaluate its perfor-\nmance using 10% of the Tungsten ground truth data as the test set.\nWe partition the data such that each subset contains a proportionate\nnumber of match and non-match samples, maintaining a balance\nacross all data partitions. The model is trained for 10 epochs, and\nthe best-performing epoch, as determined by the validation data,\nis selected for final testing. The model uses a batch size of 32, a\nlearning rate of 2e-5, and a weight decay of 0.015.\n4.1.5 Baseline Methods. To evaluate the effectiveness of our ap-\nproach, we compare it against four baseline methods: GT-Trained,\nManually Curated, LLaMA3-8b, and GeoER:\n‚Ä¢ GT-Trained: This method uses 80% of the Tungsten ground\ntruth (GT) data for training, 10% for validation, and 10% for\ntesting. Similar to our approach, we partition the data so\nthat each data partition contains a proportionate number\nof match and non-match samples. We fine-tune a RoBERTa\nmodel using the same hyperparameter settings as our ap-\nproach to ensure a fair comparison.\n‚Ä¢ Manually Curated: This method utilizes empirically de-\nfined distance thresholds and text similarity scores. We\nselect parameters that yield the highest performance on the\ntraining and validation datasets, which consist of 90% of the\nTungsten ground truth data. This method achieves optimal\nresults with a 5-kilometer distance threshold and an 85%\ncosine similarity score for text embeddings generated using\nSentence-BERT [29].\n‚Ä¢ LLaMA3-8b: This method relies exclusively on LLMs, specif-\nically the LLaMA3-8b model, for mineral site record linkage.\nIt does not incorporate spatial information or predefined\nthresholds.\n‚Ä¢ GeoER [1]: This method serves as a baseline method for\nspatial record linkage. To implement the GeoER framework,\nwe reformat our data according to the authors‚Äô guidelines\nto ensure compatibility with their experimental setup. We\nmaintain the original parameters defined by the authors6.\n4.1.6 Hardware Details. We perform all experiments on one 40GB\nA100 GPU chip and dedicate 70GB of memory at most; the majority\nof the memory is used to load and use the LLaMA3-8b model7 for\ntraining data generation.\n4.2 Experimental Results\nTable 4 displays the match, non-match, and macro-averaged F1\nscores of the baseline models and our proposed approach. All values\nare reported in percentage (%).\nAs shown in Table 4, our approach outperforms the GT-Trained\nmodel in both the match F1 score and macro-averaged F1 score\n5All other parameters not explicitly mentioned follow the default configuration pro-\nvided by the RoBERTa model available on HuggingFace RoBERTa page.\n6Details on the model are available on the GeoER page\n7Specific details about the model, such as model architecture and training data, are\navailable on Huggingface meta-llama/Meta-Llama-3-8B page.\nJiyoon Pyo and Yao-Yi Chiang\nMatches Non-matches\nCorrectly Identified Total Pairs Correctly Identified Total Pairs\nGround Truth (Tungsten) 18 23 74,617 74,668\nGround Truth (Nickel) 11 18 256 258\nTable 3: Performance of the LLaMA3-8b model on the record linkage task, showing the number of correctly identified match\npairs compared to the total match pairs in the ground truth, as well as the number of correctly identified non-match pairs\ncompared to the total non-match pairs in the ground truth.\nTungsten Data Nickel Data\nMatch F1 Non-match F1 Macro-avg F1 Match F1 Non-match F1 Macro-avg F1\nGT-Trained 0.00 99.98 49.99 0.00 96.63 48.31\nManually Curated 28.57 99.97 64.27 50.00 97.73 73.86\nLLaMA3-8b 46.15 99.95 73.05 77.78 98.45 88.11\nGeoER [1] - - - 22.22 95.10 58.66\nOur Approach 46.15 99.95 73.05 57.14 97.71 77.43\nTable 4: F1 score of match class, F1 score of non-match class, and macro-averaged F1 score of each model on the Tungsten\nand Nickel dataset. The highest scores are bold, and the second highest are underlined. Models with missing data were not\ncompleted within the 23-hour time limit.\nfor both the Tungsten and Nickel datasets. The GT-Trained model\npredicts ‚ÄúNo‚Äù for all record pairs due to the lack of match samples\nin the ground truth training data, while our approach provides\nmore balanced predictions across both categories. Additionally, our\napproach performs at the same level as the LLaMA3-8b model for\nthe Tungsten dataset but lower for the Nickel dataset. We explain\nthe benefit of our model compared to the LLaMA3-8b model in\nSection 4.2.2.\nDespite GeoER [1] using spatial aspects in its training and infer-\nence process, it still underperforms compared to our model, which\ndoes not explicitly incorporate spatial considerations. Additionally,\nGeoER cannot complete the training on the Tungsten dataset within\nthe 23-hour timeframe. To provide context, the POI dataset orig-\ninally used by GeoER consists of 2,500 records, and GeoER takes\nmore than 10 hours to train. In contrast, our Tungsten training\ndataset consists of 59,752 records, more than 23 times the size of the\nPOI dataset. Given the increase in data volume, GeoER‚Äôs training\ntime becomes excessively long, making it impractical for large-scale\nmineral site linkage tasks. With the future incorporation of spatial\nconsideration into our model, we anticipate higher performance\nbeyond what is currently shown in Table 4. This further solidifies\nour claim that our approach is a more robust and scalable solution\nfor mineral site record linkage.\nThe qualitative results of our proposed approach demonstrate\nthe characteristics of an effective record linkage model. Trained\non LLaMA-labeled data, our model accurately classifies pairs or\nrecords as match and non-match. As illustrated in Figure 6, our\nmodel successfully links ‚ÄòDunka Road‚Äô with ‚ÄòDunka Road - North-\nmet Project‚Äô, even though the sites are over 7 kilometers apart. Ad-\nditionally, the model correctly identifies ‚ÄòDunka Road‚Äô and ‚ÄòBabbit\n(Minnamax) - Mesaba Project‚Äô as distinct mineral sites despite their\nclose proximity (3 kilometers) by recognizing other differentiating\ncharacteristics.\n4.2.1 Types of Error. In both the Tungsten and Nickel datasets, our\napproach encounters challenges due to unclear site distinctions. For\nexample, our approach struggles to differentiate two sites named\n‚ÄòUnidentified Occurrence‚Äô, treating them as identical sites. However,\ndetermining whether such cases should be classified as match or\nnon-match is a complex design challenge (not a model error) in\nboth manual and automated scenarios.\nUnlike the Tungsten dataset, the Nickel dataset contains un-\ncleaned data, making the record linkage process more challenging.\nThe Nickel dataset includes entries for large deposit regions (e.g.,\n‚ÄòDuluth Complex‚Äô) and records for multiple individual sites (e.g.,\n‚ÄòMaturi, Birch Lake, and Spruce Road Copper-Nickel‚Äô). To illustrate\nthe spatial coverage of these large deposits, Figure 11 shows the\ngeographical spread of the ‚ÄòDuluth Complex‚Äô in Minnesota. Since\nthe ‚ÄòDuluth Complex‚Äô encompasses multiple mineral sites, a practi-\ncal model should exclude data representing a general region (e.g.,\n‚ÄòDuluth Complex‚Äô) when performing record linkage.\nThe current pipeline requires a one-to-one comparison between\nrecords, which leads to not capturing some links. In some cases,\ninformation needs to be inferred from other records, yet the current\nstructure prevents such. For example, a record in the database may\nlist ‚ÄòDunka Pit‚Äô as a potential alternative name for the ‚ÄòNorthmet\nProject. ‚Äô However, in a different dataset, this alternative name is\nnot recorded. When the model compares this record with another\nthat lists ‚ÄòDunka Pit‚Äô as the primary name, it fails to identify them\nas the same site, as it does not account for information found in\nout-of-pair records. We can potentially address this limitation by\nconstructing a graph-like structure from the data. By treating each\nrecord as a node and each labeled match as a connecting edge, we\ncan establish links across multiple records. This approach would\nallow us to link sites, such as the three aforementioned mines, based\non their indirect connections through shared information.\nLeveraging Large Language Models for Generating Labeled Mineral Site Record Linkage Data\nFigure 6: Image illustrating true positive match records identified by our proposed approach. Each color represents a ground-\ntruth mineral site, and each shape corresponds to a different database. Although ‚ÄòDunka Road‚Äô is geographically closer to\n‚ÄòBabbit (Minnamax - Mesaba Project)‚Äô, our approach distinguishes them as separate mines. In contrast, it identifies ‚ÄòDunka\nRoad‚Äô and ‚ÄòNorthmet Project‚Äô located at a farther distance as belonging to the same mineral site.\n4.2.2 Inferences Time. We compare the inference time of our ap-\nproach against the LLaMA3-relying model. We measure the infer-\nence time by incrementing the testing size from 10 mineral site\nrecords (i.e., 45 pairs) to 300 mineral site records (i.e., 44,850 pairs).\nFigure 7 displays the inference time of each model in relation to the\nnumber of mineral site records. The green line shows the inference\ntime when purely relying on LLaMA3-8b, and the blue line shows\nthe inference time when using our approach. The time required\nfor inference is lower for ours than relying on LLaMA. With the\ncollected inference time, we derive an equation to estimate the\nrequired inference time for running it at the scope of the actual\nmineral site linkage task. Details are provided in Appendix C.\n4.2.3 Training Data Size. T√§nzer et al. [33]states that BERT models\nmay not predict a specific label until the number of training samples\nexceeds a threshold. To better understand the relationship between\ndata size, level of class imbalance, and performance, we perform\nadditional experiments by varying the training dataset size. In all\nexperiments, we use LLM-labeled data to fine-tune the RoBERTa\nmodel and evaluate the model using the Tungsten ground truth\ndataset.\nFigure 7: Inference time (in minutes) for our approach com-\npared to the LLaMA-relying model, shown in relation to the\nnumber of mineral site records. Our approach is represented\nin blue, while the LLaMA model is depicted in green. The\nLLaMA-relying model demonstrates significantly longer in-\nference times compared to our approach.\nJiyoon Pyo and Yao-Yi Chiang\nWe first increase the number of match and non-match samples\nat the same rate, increasing from 10 samples in each class to 300\nsamples in each class. Figure 8 shows the match, non-match, and\nmacro-averaged F1 score for each training sample size. Though\nthe F1 score for each class increases, the increment for match F1 is\nminimal.\nFigure 8: Match, non-match, and macro-averaged F1 scores\nof our model, plotted against the size of the match and non-\nmatch training samples. The ‚Äòmatch and non-match data size‚Äô\nrepresents the number of training samples per class. While\nnon-match F1 and macro-averaged F1 scores stabilize at 150\nsamples per class, match F1 shows only marginal improve-\nment throughout the experiment.\nWe further the experiment by fixing the number of match sam-\nples at 349 and increasing the number of non-match samples from\n0 to 160 times the match sample size. Figure 9 illustrates that the\nnon-match F1 experiences a significant increase until it reaches\na saturation point, while the match F1 score continuously rises\nwith the increasing ratio of non-match data. Despite the growing\nimbalance in the training data, the overall performance continues\nto improve as the total data size increases. This implies that be-\nyond a certain single-class data size threshold, the total data size\ndetermines the model‚Äôs overall performance.\nTo determine the training data size threshold for a single class, we\nconduct an additional experiment by varying the number of match\nsamples while keeping the number of non-match samples constant\nat 59,403 pairs. As presented in Figure 10, the experiment reveals an\ninteresting pattern with the F1 score peaking at 100 match samples\nand stabilizing after 250 match samples. This finding supports our\nclaim that beyond a certain threshold of minority class samples (in\nthis case, the match samples), the overall data size drives the model\nperformance. This indicates that the model learns key patterns in\nthe match samples through exposure to non-match samples.\n5 Discussion and Future Work\nLinking mineral site records is an essential task for mineral deposit\nprospecting and resource management [17]. These records are often\nFigure 9: Match, non-match, and macro-averaged F1 scores of\nour model, plotted against the ratio of non-match to match\ntraining samples. The number of match samples is fixed at\n349, while the non-match sample size increases according to\nthe specified ratio. The non-match F1 score stabilizes when\nthe non-match sample size is approximately 10 times that of\nthe match samples, whereas both the match F1 and macro-\naveraged F1 scores continue to improve as the ratio increases.\nFigure 10: Match, non-match, and macro-averaged F1 scores\nof our model, plotted against the size of the match training\nsamples. The number of non-match samples is fixed at 59,403,\nwhile the match sample size increases from 10 to 350. The\nnon-match F1 score remains nearly constant, while the match\nF1 and macro-averaged F1 scores peak at a match sample size\nof 100, decrease, and then increase again, stabilizing around\n250 samples.\nLeveraging Large Language Models for Generating Labeled Mineral Site Record Linkage Data\nsourced from structured databases like MRDS and USMIN, but they\ncan also be extracted from reports, webpages, or other unstructured\ndata. The complexity of this task stems from several factors, in-\ncluding ambiguous or incomplete location data, inconsistent site\nnaming conventions, and unreliable geographical distances. In this\npaper, we propose a method leveraging LLMs to generate train-\ning data for mineral site record linkage, addressing the challenges\nof limited ground-truth data. Our approach demonstrates the po-\ntential of using LLM-generated data to fine-tune PLMs, achieving\nimproved performance compared to models trained on imbalanced\nground-truth datasets. Future work will focus on refining our pro-\nposed method and addressing two key questions to enhance model\nperformance further:\n5.1 How can spatial data be more effectively\nintegrated into the pipeline?\nAt the current stage, spatial data has been treated as part of the\ninput string to the PLM without special handling; the main goal of\nthe research is to demonstrate the potential of leveraging LLMs to\ngenerate training data to fine-tune PLMs. However, we recognize\nthe importance of preserving the spatial semantics in the data. Mov-\ning forward, we plan to explore more effective ways to incorporate\nspatial attributes into the PLM to enhance its accuracy in handling\nthe spatial dimension of such data.\nWe propose three potential approaches for this. We can utilize\nspatial distance between records, as demonstrated by Balsebre et al.\n[1], using haversine distance to create distance embeddings con-\ncatenated with the serialized record pair embedding. Alternatively,\nthe spatial distance can be embedded in each serialized entity us-\ning a spatial coordinate embedding, as suggested in SpaBERT [19].\nFor the third approach, we can incorporate spatial location as an\nadditional attribute for each record. We can convert the latitude\nand longitude values into point embeddings and concatenate them\nto each serialized entity embeddings.\n5.2 Can LLMs generate sufficient data for\ntraining?\nWe have observed performance improvements with the increased\nnumber of match samples (i.e., positive samples) in the training data.\nThe current data generation process randomly selects potential\nrecord pairs without ensuring a sufficient number of match samples.\nTherefore, to gather a sufficient number of training data, we need to\nexecute the LLaMA labeling pipeline iteratively until the training\ndata includes an adequate number of match samples.\nA logical next step is to investigate whether increasing the num-\nber of match samples leads to additional performance gains. Previ-\nous research [4] demonstrates that LLMs can generate synthetic tab-\nular data. We aim to explore whether LLMs can synthesize entirely\nnew data that replicate the patterns ofmatch and non-match records\nin the existing dataset. This could balance the representation of\nmatch samples and further improve the performance of pre-trained\nlanguage models (PLMs) when trained on LLM-generated data.\nBy combining the efficiency of PLMs with the advanced data\ngeneration capabilities of LLMs, we have demonstrated that our ap-\nproach offers a scalable and automated solution to these challenges.\nOur results show that LLM-generated data can significantly reduce\nthe need for manual data curation and support more accurate and\nefficient record linkage across large-scale datasets. Moving forward,\nwe will continue to enhance our method to fully understand the\npotential of LLMs in addressing complex real-world data challenges\nwith greater efficiency and accuracy.\nEthical Consideration\nWe acknowledge that the proposed approach allows third-party\nLLMs to access the data to generate training datasets.\nWhile our approach enhances the efficiency of the record linkage\nprocess, it is essential to recognize that using LLMs does incur\nenergy consumption and contributes to carbon emissions. However,\nour method minimizes these environmental costs by utilizing LLMs\nonly during the training data generation phase rather than relying\non LLMs throughout the entire record linkage process.\nAdditionally, LLMs may generate data that deviates from the\nground truth pattern. These hallucinations pose risks to PLMs\ntrained on such data, potentially causing erroneous outcomes. Care-\nful validation of LLM-generated data is essential to prevent the prop-\nagation of inaccurate information. To apply the proposed approach\nin practical record linkage applications, robust safeguards, and er-\nror detection mechanisms will be essential to ensure reliability and\naccuracy.\nAcknowledgments\nThis material is based upon works supported by the Defense Ad-\nvanced Research Projects Agency (DARPA) under Agreement No.\nHR00112390132 and Contract No. 140D0423C0093. Any opinions,\nfindings and conclusions or recommendations expressed in this\nmaterial are those of the authors and do not necessarily reflect the\nviews of the Defense Advanced Research Projects Agency (DARPA);\nor its Contracting Agent, the U.S. Department of the Interior, In-\nterior Business Center, Acquisition Services Directorate, Division\nV.\nWe extend our gratitude to Dr. Graham W. Lederer (USGS) for his\nvaluable geological insights, Dr. Michael L. Zientek (USGS) for his\nassistance in generating the Nickel ground truth data, and Margaret\nA. Goldman (USGS) for sharing her expertise and experience in\ncreating manually linked ground truth data.\nReferences\n[1] Pasquale Balsebre, Dezhong Yao, Gao Cong, and Zhen Hai. 2022. Geospatial\nEntity Resolution. In Proceedings of the ACM Web Conference 2022(Virtual Event,\nLyon, France) (WWW ‚Äô22). Association for Computing Machinery, New York,\nNY, USA, 3061‚Äì3070. https://doi.org/10.1145/3485447.3512026\n[2] Nelly Barret, Fabien Duchateau, Franck Favetta, and Ludovic Moncla. 2019. Spa-\ntial Entity Matching with GeoAlign (demo paper). InProceedings of the 27th ACM\nSIGSPATIAL International Conference on Advances in Geographic Information Sys-\ntems (Chicago, IL, USA)(SIGSPATIAL ‚Äô19). Association for Computing Machinery,\nNew York, NY, USA, 580‚Äì583. https://doi.org/10.1145/3347146.3359345\n[3] Ryan D. Bergstrom and Afton Clarke-Sather. 2020. Balancing Socio-Ecological\nRisks, Politics, and Identity: Sustainability in Minnesota‚Äôs Copper-Nickel-\nPrecious Metal Mining Debate. Sustainability 12, 24 (2020). https://doi.org/10.\n3390/su122410286\n[4] Vadim Borisov, Kathrin Sessler, Tobias Leemann, Martin Pawelczyk, and Gjergji\nKasneci. 2023. Language Models are Realistic Tabular Data Generators. In\nThe Eleventh International Conference on Learning Representations. https://\nopenreview.net/forum?id=cEygmQNOeI\n[5] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,\nRewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,\nJiyoon Pyo and Yao-Yi Chiang\nChristopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\nSutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.\narXiv:2005.14165 [cs.CL] https://arxiv.org/abs/2005.14165\n[6] Curtis Clarke, Brian Thomas, James McDonald, Stephan Blaho, Ewald Pengel,\nJason Obermeyer, Devin Castendyk, and Ibrahim Karajeh. 2022. NI 43-101 Tech-\nnical Report on the Eagle Mine, Michigan, USA. Technical Report. WSP Canada\nInc. 306 pages.\n[7] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:\nPre-training of Deep Bidirectional Transformers for Language Understanding. In\nProceedings of the 2019 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, Volume 1 (Long and\nShort Papers), Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association\nfor Computational Linguistics, Minneapolis, Minnesota, 4171‚Äì4186. https://doi.\norg/10.18653/v1/N19-1423\n[8] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ah-\nmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, An-\ngela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie\nSravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, ..., and Zhiwei\nZhao. 2024. The Llama 3 Herd of Models. arXiv:2407.21783 [cs.AI] https:\n//arxiv.org/abs/2407.21783\n[9] Muhammad Ebraheem, Saravanan Thirumuruganathan, Shafiq Joty, Mourad\nOuzzani, and Nan Tang. 2018. Distributed representations of tuples for entity\nresolution. Proc. VLDB Endow.11, 11 (jul 2018), 1454‚Äì1467. https://doi.org/10.\n14778/3236187.3236198\n[10] Margaret A Goldman, Connie Dicken, Brown II, Philip J, Allen K Andersen,\nMitchell M Bennett, and Heather L Parks. 2022. Spatial data associated with\ntungsten skarn resource assessment of the Northern Rocky Mountains, Montana\nand Idaho. https://doi.org/10.5066/P9094RVV\n[11] Pengcheng He, Jianfeng Gao, and Weizhu Chen. 2023. DeBERTaV3: Improv-\ning DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled\nEmbedding Sharing. In The Eleventh International Conference on Learning Repre-\nsentations. https://openreview.net/forum?id=sE7-XhLxHA\n[12] Sepp Hochreiter and J√ºrgen Schmidhuber. 1997. Long Short-Term Memory.\nNeural Comput.9, 8 (nov 1997), 1735‚Äì1780. https://doi.org/10.1162/neco.1997.9.\n8.1735\n[13] Suela Isaj, Esteban Zim√°nyi, and Torben Bach Pedersen. 2019. Multi-Source\nSpatial Entity Linkage. In Proceedings of the 16th International Symposium on\nSpatial and Temporal Databases(Vienna, Austria) (SSTD ‚Äô19). Association for\nComputing Machinery, New York, NY, USA, 1‚Äì10. https://doi.org/10.1145/\n3340964.3340979\n[14] Delaram Javdani, Hossein Rahmani, Milad Allahgholi, and Fatemeh Karimkhani.\n2019. DeepBlock: A Novel Blocking Approach for Entity Resolution using Deep\nLearning. In 2019 5th International Conference on Web Research (ICWR). 41‚Äì44.\nhttps://doi.org/10.1109/ICWR.2019.8765267\n[15] Nick A Karl, Thomas R Carroll, Meredith H Burger, Liam D Knudsen, Keith R\nLong, Tyler A Reyes, and German Schmeda. 2020. Tungsten Deposits in the\nUnited States (ver. 2.0, August 2020). https://doi.org/10.5066/P97NJLI4\n[16] Pradap Konda, Sanjib Das, Paul Suganthan G. C., AnHai Doan, Adel Ardalan,\nJeffrey R. Ballard, Han Li, Fatemah Panahi, Haojun Zhang, Jeff Naughton, Shishir\nPrasad, Ganesh Krishnan, Rohit Deep, and Vijay Raghavendra. 2016. Magellan:\ntoward building entity matching management systems. Proc. VLDB Endow.9, 12\n(aug 2016), 1197‚Äì1208. https://doi.org/10.14778/2994509.2994535\n[17] Christopher J.M. Lawley, Anne E. McCafferty, Garth E. Graham, David L. Huston,\nKaren D. Kelley, Karol Czarnota, Suzanne Paradis, Jan M. Peter, Nathan Hayward,\nMike Barlow, Poul Emsbo, Joshua Coyan, Carma A. San Juan, and Michael G.\nGadd. 2022. Data‚Äìdriven prospectivity modelling of sediment‚Äìhosted Zn‚ÄìPb\nmineral systems and their critical raw materials. Ore Geology Reviews141 (2022),\n104635. https://doi.org/10.1016/j.oregeorev.2021.104635\n[18] Yuliang Li, Jinfeng Li, Yoshihiko Suhara, AnHai Doan, and Wang-Chiew Tan.\n2020. Deep entity matching with pre-trained language models. Proc. VLDB\nEndow. 14, 1 (sep 2020), 50‚Äì60. https://doi.org/10.14778/3421424.3421431\n[19] Zekun Li, Jina Kim, Yao-Yi Chiang, and Muhao Chen. 2022. SpaBERT: A\nPretrained Language Model from Geographic Data for Geo-Entity Represen-\ntation. In Findings of the Association for Computational Linguistics: EMNLP\n2022, Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (Eds.). Association\nfor Computational Linguistics, Abu Dhabi, United Arab Emirates, 2757‚Äì2769.\nhttps://doi.org/10.18653/v1/2022.findings-emnlp.200\n[20] G.T. Mason and R.E. Arndt. 1996. Mineral Resources Data System (MRDS). https:\n//doi.org/10.3133/ds20\n[21] J.D. Miller and E.M. Ripley. 1996. Layered Intrusions of the Duluth Complex,\nMinnesota, USA. In Layered Intrusions, Richard Grant Cawthorn (Ed.). Develop-\nments in Petrology, Vol. 15. Elsevier, 257‚Äì301. https://doi.org/10.1016/S0167-\n2894(96)80010-8\n[22] Gavin M. Mudd and Simon M. Jowitt. 2022. The New Century for Nickel Re-\nsources, Reserves, and Mining: Reassessing the Sustainability of the Devil‚Äôs Metal.\nEconomic Geology117, 8 (12 2022), 1961‚Äì1983. https://doi.org/10.5382/econgeo.\n4950 arXiv:https://pubs.geoscienceworld.org/segweb/economicgeology/article-\npdf/117/8/1961/5735536/4950_mudd_and_jowitt.pdf\n[23] Avanika Narayan, Ines Chami, Laurel Orr, and Christopher R√©. 2022. Can Foun-\ndation Models Wrangle Your Data? Proc. VLDB Endow.16, 4 (dec 2022), 738‚Äì746.\nhttps://doi.org/10.14778/3574245.3574258\n[24] OpenStreetMap contributors. 2017. Planet dump retrieved from\nhttps://planet.osm.org . https://www.openstreetmap.org.\n[25] Ralph Peeters and Christian Bizer. 2023. Using ChatGPT for Entity Matching.\nIn New Trends in Database and Information Systems, Alberto Abell√≥, Panos Vas-\nsiliadis, Oscar Romero, Robert Wrembel, Francesca Bugiotti, Johann Gamper,\nGenoveva Vargas Solar, and Ester Zumpano (Eds.). Springer Nature Switzerland,\nCham, 221‚Äì230.\n[26] Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. GloVe:\nGlobal Vectors for Word Representation. InProceedings of the 2014 Conference\non Empirical Methods in Natural Language Processing (EMNLP), Alessandro Mos-\nchitti, Bo Pang, and Walter Daelemans (Eds.). Association for Computational\nLinguistics, Doha, Qatar, 1532‚Äì1543. https://doi.org/10.3115/v1/D14-1162\n[27] Alec Radford and Karthik Narasimhan. 2018. Improving Language Understanding\nby Generative Pre-Training. https://api.semanticscholar.org/CorpusID:49313245\n[28] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings\nusing Siamese BERT-Networks. InProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-IJCNLP), Kentaro Inui, Jing Jiang,\nVincent Ng, and Xiaojun Wan (Eds.). Association for Computational Linguistics,\nHong Kong, China, 3982‚Äì3992. https://doi.org/10.18653/v1/D19-1410\n[29] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings\nusing Siamese BERT-Networks. InProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-IJCNLP), Kentaro Inui, Jing Jiang,\nVincent Ng, and Xiaojun Wan (Eds.). Association for Computational Linguistics,\nHong Kong, China, 3982‚Äì3992. https://doi.org/10.18653/v1/D19-1410\n[30] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. Dis-\ntilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.ArXiv\nabs/1910.01108 (2019). https://api.semanticscholar.org/CorpusID:203626972\n[31] Monika Sester. 2020. Cartographic generalization. Journal of Spatial Information\nScience 21 (Dec. 2020). https://doi.org/10.5311/josis.2020.21.716\n[32] Kanae Takahashi, Kouji Yamamoto, Aya Kuchiba, and Tatsuki Koyama. 2022.\nConfidence interval for micro-averaged F 1 and macro-averaged F 1 scores. Appl.\nIntell. 52, 5 (March 2022), 4961‚Äì4972.\n[33] Michael T√§nzer, Sebastian Ruder, and Marek Rei. 2022. Memorisation versus\nGeneralisation in Pre-trained Language Models. InProceedings of the 60th Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers),\nSmaranda Muresan, Preslav Nakov, and Aline Villavicencio (Eds.). Association\nfor Computational Linguistics, Dublin, Ireland, 7564‚Äì7578. https://doi.org/10.\n18653/v1/2022.acl-long.521\n[34] Gemma Team. 2024. Gemma: Open Models Based on Gemini Research and\nTechnology. arXiv:2403.08295 [cs.CL] https://arxiv.org/abs/2403.08295\n[35] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne\nLachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, Naman Goyal, Eric Hambro,\nFaisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guil-\nlaume Lample. 2023. LLaMA: Open and Efficient Foundation Language Models.\narXiv:2302.13971 [cs.CL] https://arxiv.org/abs/2302.13971\n[36] Yiqi Wu, Xiaodan Hu, Ziming Fu, Siling Zhou, and Jiangong Li. 2024. GPT-4o:\nVisual perception performance of multimodal large language models in piglet\nactivity understanding. arXiv:2406.09781 [cs.CV] https://arxiv.org/abs/2406.\n09781\n[37] Wei Zhang, Hao Wei, Bunyamin Sisman, Xin Luna Dong, Christos Faloutsos, and\nDavd Page. 2020. AutoBlock: A Hands-off Blocking Framework for Entity Match-\ning. In Proceedings of the 13th International Conference on Web Search and Data\nMining (Houston, TX, USA) (WSDM ‚Äô20). Association for Computing Machinery,\nNew York, NY, USA, 744‚Äì752. https://doi.org/10.1145/3336191.3371813\n[38] Liu Zhuang, Lin Wayne, Shi Ya, and Zhao Jun. 2021. A Robustly Optimized BERT\nPre-training Approach with Post-training. In Proceedings of the 20th Chinese\nNational Conference on Computational Linguistics, Sheng Li, Maosong Sun, Yang\nLiu, Hua Wu, Kang Liu, Wanxiang Che, Shizhu He, and Gaoqi Rao (Eds.). Chinese\nInformation Processing Society of China, Huhhot, China, 1218‚Äì1227. https:\n//aclanthology.org/2021.ccl-1.108\nLeveraging Large Language Models for Generating Labeled Mineral Site Record Linkage Data\nA Span of Duluth Complex\nFigure 11 illustrates the extensive spatial coverage of the Duluth Complex in Minnesota, outlined by a red boundary. The area of the complex\nexceeds 5,000 ùëòùëö2 [21]. An effective mineral site record linkage model should avoid linking large region records to smaller mineral site\nrecords.\nFigure 11: Map of the Duluth Complex. Image sourced from Bergstrom and Clarke-Sather [3].\nB Performance Comparison between BERT Variants\nWe select the RoBERTa model over BERT and its variants due to its well-known performance across various downstream tasks [38], along\nwith the relatively low training and inference times. We conduct additional experiments to show that the RoBERTa model outperforms other\nvariants when using our approach for the classification task.\nMatch F1 Non-match F1 Macro-avg F1\nBERT-cased 0.00 99.98 49.99\nBERT-uncased 17.65 99.81 58.73\nDeBERTa 7.14 99.65 53.40\nRoBERTa (Selected Model) 46.15 99.95 73.05\nTable 5: Match F1, Non-match F1, and Macro-averaged F1 scores of BERT-cased, BERT-uncased, DeBERTa, and RoBERTa\nfine-tuned using our approach. The highest scores are highlighted in bold, with the second-highest scores underlined.\nWe compare the performance of RoBERTa against BERT-cased, BERT-uncased, and DeBERTa, with all models fine-tuned using the same\nLLaMA-generated data and tested on the same Tungsten data. We configure all four models with a batch size of 32, a learning rate of 2e-5,\nand a weight decay of 0.018. Table 5 shows the classification performance of each model. The result indicates that fine-tuning RoBERTa is\n8All other parameters we do not explicitly mention follow each model‚Äôs default configuration. These parameters are available here: HuggingFace BERT-cased, HuggingFace\nBERT-uncased, HuggingFace DeBERTa, Huggingface RoBERTa.\nJiyoon Pyo and Yao-Yi Chiang\nbest suited for our approach, and, therefore, we conduct further analyses (i.e., data-size comparison and run-time comparison) using the\nfine-tuned RoBERTa model.\nC Runtime Estimation for Full Mineral Site Data\nUsing the recorded inference times, we extrapolate the data to estimate the time required to compare 300,000 records, which reflects the\nscope of the mineral site linkage task. To extrapolate, we derive a quadratic function that relates inference time (ùë°ùëñùëöùëí) to the number of\nrecords (ùëêùëúùë¢ùëõùë°ùëöùë† ).\nFor the LLaMA model, we approximate the inference time (in seconds) with the following equation:\nùë°ùëñùëöùëí = 0.073 ¬∑(ùëêùëúùë¢ùëõùë°2\nùëöùë† ‚àíùëêùëúùë¢ùëõùë°ùëöùë† ) (4)\nFor our approach, we approximate the inference time (in seconds) with the following equation:\nùë°ùëñùëöùëí = 0.004 ¬∑(ùëêùëúùë¢ùëõùë°2\nùëöùë† ‚àíùëêùëúùë¢ùëõùë°ùëöùë† ) (5)\nBased on these calculations, our approach can complete the task in approximately 4,166 days, whereas relying solely on the LLaMA model\nwill require around 76,000 days. However, we can filter out many candidate pairs through basic spatial comparisons. For example, a mineral\nsite in the central United States is unlikely to be linked with a mineral site in the southeastern United States; we can eliminate these pairs\nbefore running the model. As a result, the actual inference time will be lower than the estimated values.",
  "topic": "Linkage (software)",
  "concepts": [
    {
      "name": "Linkage (software)",
      "score": 0.6501801013946533
    },
    {
      "name": "Computer science",
      "score": 0.6415517330169678
    },
    {
      "name": "Record linkage",
      "score": 0.6124842166900635
    },
    {
      "name": "Natural language processing",
      "score": 0.3588523268699646
    },
    {
      "name": "Chemistry",
      "score": 0.08093777298927307
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Demography",
      "score": 0.0
    },
    {
      "name": "Population",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Sociology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I130238516",
      "name": "University of Minnesota",
      "country": "US"
    }
  ],
  "cited_by": 1
}