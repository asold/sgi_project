{
  "title": "Assessing large language models as assistive tools in medical consultations for Kawasaki disease",
  "url": "https://openalex.org/W4408989393",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2983248501",
      "name": "Chunyi Yan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2397416258",
      "name": "Zexi Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4299085267",
      "name": "Yongzhou Liang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2969805646",
      "name": "Shuran Shao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2167244119",
      "name": "Fan Ma",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2550630191",
      "name": "Nanjun Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2105484402",
      "name": "Bowen Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2121103831",
      "name": "Chuan Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2125721866",
      "name": "Kaiyu Zhou",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4385827730",
    "https://openalex.org/W3113806700",
    "https://openalex.org/W4377115988",
    "https://openalex.org/W4386392833",
    "https://openalex.org/W2953201441",
    "https://openalex.org/W4399652965",
    "https://openalex.org/W4391283060",
    "https://openalex.org/W3003698115",
    "https://openalex.org/W3200445016",
    "https://openalex.org/W2972749265",
    "https://openalex.org/W4399149700",
    "https://openalex.org/W4392858472",
    "https://openalex.org/W4361298490",
    "https://openalex.org/W4390070272",
    "https://openalex.org/W4321436564",
    "https://openalex.org/W4388595252",
    "https://openalex.org/W2736868680",
    "https://openalex.org/W1966869225",
    "https://openalex.org/W2010666563",
    "https://openalex.org/W4399387113",
    "https://openalex.org/W2327037637",
    "https://openalex.org/W4394620990",
    "https://openalex.org/W4400772352",
    "https://openalex.org/W4386448461",
    "https://openalex.org/W2604027935",
    "https://openalex.org/W4402582449",
    "https://openalex.org/W2050966310",
    "https://openalex.org/W2767198624",
    "https://openalex.org/W4390498094",
    "https://openalex.org/W4390611084",
    "https://openalex.org/W4400369550",
    "https://openalex.org/W3214253120",
    "https://openalex.org/W4205164650",
    "https://openalex.org/W4401383097",
    "https://openalex.org/W4391679299",
    "https://openalex.org/W4396778560",
    "https://openalex.org/W2908201961",
    "https://openalex.org/W4386510404",
    "https://openalex.org/W4391971084",
    "https://openalex.org/W4401424596",
    "https://openalex.org/W4401552039",
    "https://openalex.org/W2092058117",
    "https://openalex.org/W4390948973"
  ],
  "abstract": "Background Kawasaki disease (KD) presents complex clinical challenges in diagnosis, treatment, and long-term management, requiring a comprehensive understanding by both parents and healthcare providers. With advancements in artificial intelligence (AI), large language models (LLMs) have shown promise in supporting medical practice. This study aims to evaluate and compare the appropriateness and comprehensibility of different LLMs in answering clinically relevant questions about KD and assess the impact of different prompting strategies. Methods Twenty-five questions were formulated, incorporating three prompting strategies: No prompting (NO), Parent-friendly (PF), and Doctor-level (DL). These questions were input into three LLMs: ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro. Responses were evaluated based on appropriateness, educational quality, comprehensibility, cautionary statements, references, and potential misinformation, using Information Quality Grade, Global Quality Scale (GQS), Flesch Reading Ease (FRE) score, and word count. Results Significant differences were found among the LLMs in terms of response educational quality, accuracy, and comprehensibility ( p &amp;lt; 0.001). Claude 3.5 provided the highest proportion of completely correct responses (51.1%) and achieved the highest median GQS score (5.0), outperforming GPT-4o (4.0) and Gemini 1.5 (3.0) significantly. Gemini 1.5 achieved the highest FRE score (31.5) and provided highest proportion of responses assessed as comprehensible (80.4%). Prompting strategies significantly affected LLM responses. Claude 3.5 Sonnet with DL prompting had the highest completely correct rate (81.3%), while PF prompting yielded the most acceptable responses (97.3%). Gemini 1.5 Pro showed minimal variation across prompts but excelled in comprehensibility (98.7% under PF prompting). Conclusion This study indicates that LLMs have great potential in providing information about KD, but their use requires caution due to quality inconsistencies and misinformation risks. Significant discrepancies existed across LLMs and prompting strategies. Claude 3.5 Sonnet offered the best response quality and accuracy, while Gemini 1.5 Pro excelled in comprehensibility. PF prompting with Claude 3.5 Sonnet is most recommended for parents seeking KD information. As AI evolves, expanding research and refining models is crucial to ensure reliable, high-quality information.",
  "full_text": null,
  "topic": "Kawasaki disease",
  "concepts": [
    {
      "name": "Kawasaki disease",
      "score": 0.7124837040901184
    },
    {
      "name": "Disease",
      "score": 0.48377248644828796
    },
    {
      "name": "Computer science",
      "score": 0.4133249819278717
    },
    {
      "name": "Medicine",
      "score": 0.3814699947834015
    },
    {
      "name": "Psychology",
      "score": 0.3203250765800476
    },
    {
      "name": "Pathology",
      "score": 0.11080220341682434
    },
    {
      "name": "Cardiology",
      "score": 0.06296545267105103
    },
    {
      "name": "Artery",
      "score": 0.0
    }
  ]
}