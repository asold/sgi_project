{
    "title": "From text to data: Open-source large language models in extracting cancer related medical attributes from German pathology reports",
    "url": "https://openalex.org/W4411955010",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A5028771222",
            "name": "Stefan Bartels",
            "affiliations": [
                "University Medical Center Hamburg-Eppendorf",
                "Universität Hamburg"
            ]
        },
        {
            "id": "https://openalex.org/A5091664139",
            "name": "Jasmin Carus",
            "affiliations": [
                "University Cancer Center Hamburg",
                "University Medical Center Hamburg-Eppendorf",
                "Universität Hamburg"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6873519409",
        "https://openalex.org/W6876018340",
        "https://openalex.org/W6871413867",
        "https://openalex.org/W4399118499",
        "https://openalex.org/W6871671409",
        "https://openalex.org/W4404927183",
        "https://openalex.org/W6874383283",
        "https://openalex.org/W4394579747",
        "https://openalex.org/W4403945759",
        "https://openalex.org/W4391292768",
        "https://openalex.org/W4404584849",
        "https://openalex.org/W6753942111",
        "https://openalex.org/W2053154970",
        "https://openalex.org/W4401527088",
        "https://openalex.org/W4406818618",
        "https://openalex.org/W4403680361",
        "https://openalex.org/W4401824011",
        "https://openalex.org/W4401824524"
    ],
    "abstract": "Structured oncological documentation is vital for data-driven cancer care, yet extracting clinical features from unstructured pathology reports remains challenging-especially in German healthcare, where strict data protection rules require local model deployment. This study evaluates open-source large language models (LLMs) for extracting oncological attributes from German pathology reports in a secure, on-premise setting. We created a gold-standard dataset of 522 annotated reports and developed a retrieval-augmented generation (RAG) pipeline using an additional 15,000 pathology reports. Five instruction-tuned LLMs (Llama 3.3 70B, Mistral Small 24B, and three SauerkrautLM variants) were evaluated using three prompting strategies: zero-shot, few-shot, and RAG-enhanced few-shot prompting. All models produced structured JSON outputs and were assessed using entity-level precision, recall, accuracy, and macro-averaged F1-score. Results show that Llama 3.3 70B achieved the highest overall performance (F1 > 0.90). However, when combined with the RAG pipeline, Mistral Small 24B achieved nearly equivalent performance, matching Llama 70B on most entity types while requiring significantly fewer computational resources. Prompting strategy significantly impacted performance: few-shot prompting improved baseline accuracy, and RAG further enhanced performance, particularly for models with fewer than 24B parameters. Challenges remained in extracting less frequent but clinically critical attributes like metastasis and staging, underscoring the importance of retrieval mechanisms and balanced training data. This study demonstrates that open-source LLMs, when paired with effective prompting and retrieval strategies, can enable high-quality, privacy-compliant extraction of oncological information from unstructured text. The finding that smaller models can match larger ones through retrieval augmentation highlights a path toward scalable, resource-efficient deployment in German clinical settings.",
    "full_text": null
}