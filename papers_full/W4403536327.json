{
  "title": "GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models",
  "url": "https://openalex.org/W4403536327",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5082771450",
      "name": "Zhuowen Zhang",
      "affiliations": [
        null,
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5030541648",
      "name": "Wanna Bai",
      "affiliations": [
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5020034653",
      "name": "Yuxi Li",
      "affiliations": [
        null,
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5085641844",
      "name": "Mark Huasong Meng",
      "affiliations": [
        null,
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5000432413",
      "name": "Kailong Wang",
      "affiliations": [
        null,
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5085767410",
      "name": "Ling Shi",
      "affiliations": [
        null,
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5106407830",
      "name": "Li Li",
      "affiliations": [
        null,
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5100735839",
      "name": "Jun Wang",
      "affiliations": [
        null,
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5115695530",
      "name": "Haoyu Wang",
      "affiliations": [
        null,
        "Huazhong University of Science and Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6600891728",
    "https://openalex.org/W4391724817",
    "https://openalex.org/W6890025973",
    "https://openalex.org/W4402443952",
    "https://openalex.org/W4385287322",
    "https://openalex.org/W1527548706",
    "https://openalex.org/W4390529272"
  ],
  "abstract": "Large language models (LLMs) have achieved unprecedented success in the field of natural language processing. However, the black-box nature of their internal mechanisms has brought many concerns about their trustworthiness and interpretability. Recent research has discovered a class of abnormal tokens in the model's vocabulary space and named them \"glitch tokens\". Those tokens, once included in the input, may induce the model to produce incorrect, irrelevant, or even harmful results, drastically undermining the reliability and practicality of LLMs. In this work, we aim to enhance the understanding of glitch tokens and propose techniques for their detection and mitigation. We first reveal the characteristic features induced by glitch tokens on LLMs, which are evidenced by significant deviations in the distributions of attention patterns and dynamic information from intermediate model layers. Based on the insights, we develop GlitchProber, a tool for efficient glitch token detection and mitigation. GlitchProber utilizes small-scale sampling, principal component analysis for accelerated feature extraction, and a simple classifier for efficient vocabulary screening. Taking one step further, GlitchProber rectifies abnormal model intermediate layer values to mitigate the destructive effects of glitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber demonstrates higher efficiency, precision, and recall compared to existing approaches, with an average F1 score of 0.86 and an average repair rate of 50.06%. GlitchProber unveils a novel path to address the challenges posed by glitch tokens and inspires future research toward more robust and interpretable LLMs.",
  "full_text": "GlitchProber: Advancing Effective Detection and Mitigation of\nGlitch Tokens in Large Language Models\nZhibo Zhangâˆ—\nHuazhong University of Science and\nTechnology\nWuhan, China\nzhangzhibom@hust.edu.cn\nWuxia Baiâˆ—\nHuazhong University of Science and\nTechnology\nWuhan, China\nwuxiabai@hust.edu.cn\nYuxi Liâˆ—\nHuazhong University of Science and\nTechnology\nWuhan, China\nyuxili@hust.edu.cn\nMark Huasong Meng\nTechnical University of Munich\nMunich, Germany\nhuasong.meng@gmail.com\nKailong Wangâ€ \nHuazhong University of Science and\nTechnology\nWuhan, China\nwangkl@hust.edu.cn\nLing Shi\nNanyang Technological University\nSingapore, Singapore\nling.shi@ntu.edu.sg\nLi Li\nBeihang University\nBeijing, China\nlilicoding@ieee.org\nJun Wang\nBeihang University\nBeijing, China\njunwang.lu@gmail.com\nHaoyu Wang\nHuazhong University of Science and\nTechnology\nWuhan, China\nhaoyuwang@hust.edu.cn\nABSTRACT\nLarge language models (LLMs) have achieved unprecedented suc-\ncess in the field of natural language processing. However, the black-\nbox nature of their internal mechanisms has brought many concerns\nabout their trustworthiness and interpretability. Recent research\nhas discovered a class of abnormal tokens in the modelâ€™s vocabulary\nspace and named them â€œglitch tokensâ€. Those tokens, once included\nin the input, may induce the model to produce incorrect, irrelevant,\nor even harmful results, drastically undermining the reliability and\npracticality of LLMs.\nIn this work, we aim to enhance the understanding of glitch\ntokens and propose techniques for their detection and mitigation.\nWe first reveal the characteristic features induced by glitch to-\nkens on LLMs, which are evidenced by significant deviations in\nthe distributions of attention patterns and dynamic information\nfrom intermediate model layers. Based on the insights, we develop\nGlitchProber, a tool for efficient glitch token detection and miti-\ngation. GlitchProber utilizes small-scale sampling, principal com-\nponent analysis for accelerated feature extraction, and a simple\nclassifier for efficient vocabulary screening. Taking one step further,\nGlitchProber rectifies abnormal model intermediate layer values\nto mitigate the destructive effects of glitch tokens. Evaluated on\nâˆ—Co-first author with equal contribution.\nâ€ Corresponding Author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nASE â€™24, October 27-November 1, 2024, Sacramento, CA, USA\nÂ© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-1248-7/24/10. . . $15.00\nhttps://doi.org/10.1145/3691620.3695060\nfive mainstream open-source LLMs, GlitchProber demonstrates\nhigher efficiency, precision, and recall compared to existing ap-\nproaches, with an average F1 score of 0.86 and an average repair\nrate of 50.06%. GlitchProber unveils a novel path to address the\nchallenges posed by glitch tokens and inspires future research to-\nward more robust and interpretable LLMs. Our code is available at\nhttps://github.com/LLM-Integrity-Guard/GlitchProber.\nCCS CONCEPTS\nâ€¢ Computing methodologies â†’Knowledge representation and\nreasoning.\nKEYWORDS\nLLM security, Glitch token, LLM analysis\nACM Reference Format:\nZhibo Zhang, Wuxia Bai, Yuxi Li, Mark Huasong Meng, Kailong Wang, Ling\nShi, Li Li, Jun Wang, and Haoyu Wang. 2024. GlitchProber: Advancing Effec-\ntive Detection and Mitigation of Glitch Tokens in Large Language Models. In\n39th IEEE/ACM International Conference on Automated Software Engineering\n(ASE â€™24), October 27-November 1, 2024, Sacramento, CA, USA. ACM, New\nYork, NY, USA, 13 pages. https://doi.org/10.1145/3691620.3695060\n1 INTRODUCTION\nIn the field of Natural Language Processing (NLP), large language\nmodels (LLMs) like GPT-4 [2], Gemini [31, 34], and Claude 3 [4] have\ndemonstrated near-human-level text generation capabilities. Their\nexceptional performance has led to widespread adoption [16, 35, 41].\nWhen using these models, users provide a prompt, which the\nmodelâ€™s tokenizer breaks down into a series of discrete tokens.\nThese tokens are the fundamental units of information processing\nfor the model, playing a crucial role in the usage of LLMs. Recent re-\nsearch [12, 13, 26, 28, 29, 32], however, has shown that some â€œglitch\ntokensâ€ exist in the vocabulary of LLMs. Once included in a prompt,\narXiv:2408.04905v2  [cs.CL]  23 Sep 2024\nASE â€™24, October 27-November 1, 2024, Sacramento, CA, USAZhibo Zhang, Wuxia Bai, Yuxi Li, Mark Huasong Meng, Kailong Wang, Ling Shi, Li Li, Jun Wang, and Haoyu Wang\nthese special tokens can potentially lead to model errors, such as\nmisunderstanding user intent, refusing to answer, or generating\nirrelevant or harmful text. Therefore, thorough analysis and detec-\ntion of these glitch tokens are crucial to ensure the reliability and\nsafety of LLMs.\nTo tackle the glitch tokens issue, one notable method recently\nis presented by Li et al. [ 21]. This typical and intuitive solution\ninvolves studying the characteristics of glitch tokens in the word\nembedding space of LLMs and accordingly developing detection\ntechniques. They discovered that glitch tokens tend to cluster in\nthe embedding space and proposed an iterative clustering-based\ntechnique called GlitchHunter for efficient glitch token detection.\nAlthough there has been progress in detecting glitch tokens,\nthere still lacks an efficient and precise detection of glitch tokens\nuniversally applicable in different LLMs. Furthermore, existing ap-\nproaches primarily focus on detection, however, how to fix the\nissues caused by glitch tokens in the usage of LLMs remains an\nopen question. Several limitations contribute to the aforementioned\nchallenges:\n(1) The exhaustive search method of checking vocabulary is simple\nand intuitive but incurs significant time costs with large token\nsets, making it inefficient for practical use.\n(2) Existing detection methods primarily identify glitch tokens\nbased on features like word frequency and word vectors. How-\never, these features do not deeply explore the mechanisms by\nwhich glitch tokens impact model behaviors, resulting in poor\ndetection accuracy and generalization performance.\n(3) Current research primarily focuses on detecting glitch tokens\nrather than how to fix them. While detection can identify issues,\nit does not eliminate the negative impact of glitch tokens on\nmodel performance, limiting its practical value.\nOur work. To address these existing challenges and bridge the\ngap, in this work, we investigate the internal structure of LLMs\nto explore the differences between glitch tokens and normal to-\nkens. Specifically, through empirical study, we discovered signifi-\ncant differences between glitch tokens and normal tokens in terms\nof the attention patterns and dynamic information of multi-layer\nperceptron (MLP) modules within transformer-based LLMs. This\ndiscovery reveals the adversarial impact of glitch tokens on the\ninternal mechanisms of the model, indicating that glitch tokens\nintroduce abnormal interference and noise to neural networks. This\nhinders the model from correctly understanding and processing the\nsemantic information carried by these tokens, ultimately leading\nto erroneous outputs.\nFrom these findings, we gain an insight that the glitch tokens\ncan be efficiently detected due to the deviated distributions of in-\ntermediate layersâ€™ outputs caused by them, and accordingly their\nimpact can be effectively mitigated by proactively rectifying those\nabnormal outputs. Based on this insight, we propose a new method\nfor glitch token detection and fix called GlitchProber. For glitch\ntoken detection, GlitchProber first samples a small subset of\nmanually labeled glitch tokens as the sample set, and extracts the\noutputs of these tokens from the intermediate layers, specifically,\nthe attention scores of the attention patterns and MLP status. It then\napplies Principal Component Analysis (PCA) [ 1] dimensionality\nreduction to the intermediate layersâ€™ outputs and obtains a feature\nrepresentation matrix for the sample set. This matrix, along with\nthe corresponding class labels, is used to train a Support Vector\nMachine (SVM) [9] classifier, which can subsequently be employed\nfor glitch token detection. To fix the glitch tokens, GlitchProber\nanalyzes the activation value range of normal tokens in the interme-\ndiate MLP status and rectifies the activation states of glitch tokens.\nSpecifically, it aims to adjust the activation patterns of glitch to-\nkens to be closer to those of normal tokens, and thereby minimize\ntheir impact on the modelâ€™s output. Our work is published on our\nwebsite [15].\nContributions. We summarize our key contributions as follows:\nâ€¢Empirical Study Exploring the Internal Impact of Glitch\nTokens on LLMs. We conduct a comprehensive and systematic\nempirical study on how glitch tokens and normal tokens manifest\nat the structural level across different LLMs. One of our key\nfindings is that glitch tokens can trigger abnormal values in a\nmodelâ€™s attention patterns and MLP status.\nâ€¢Effective Glitch Token Detection. Our evaluation on five rep-\nresentative open source LLMs demonstrates that GlitchProber\ncan save approximately 40% of time in glitch token detection com-\npared to the state-of-the-art approaches. Additionally, Glitch-\nProber exhibits a significant improvement in detection accuracy.\nâ€¢Effective Glitch Token Fixing. In terms of fix, GlitchProber\nsuccessfully repairs an average of 7,758 tokens across the five\nLLMs. It achieves an average repair rate of 50.06%, significantly\noutperforming the baseline approach. Our results demonstrate\nthe effectiveness of the proposed fix strategy by adjusting the\nintermediate values of glitch tokens in the intermediate layers.\nEthical Consideration. In this work, we recognize that glitch\ntokens can cause abnormal responses from LLMs, potentially affect-\ning their usage. However, we strictly adhere to ethical principles\nand do not condone any abuse or exploitation of these findings. Our\nresearch aims to raise awareness of these risks and contribute to a\nmore secure LLM community. We have reported our findings to the\nrespective LLM developers and are committed to collaborating with\nthem to develop effective defenses and mitigation strategies. By\nworking cooperatively, we promote responsible research practices\nand ensure the safe and beneficial use of LLMs.\n2 BACKGROUND AND RELATED WORK\n2.1 Transformer-based LLMs\nSelf-attention [7, 25] is a core component of Transformer-based\nmodels, demonstrating strong modeling capabilities across various\ntasks. Given an input ğ‘‹ âˆˆRğ‘›Ã—ğ‘‘, where ğ‘› denotes the sequence\nlength and ğ‘‘denotes the dimension, self-attention linearly projects\nğ‘‹ into query, key, and value representations, i.e.,ğ‘„, ğ¾, and ğ‘‰. The\nattention scores matrix ğ´is then computed by taking the dot prod-\nuct between the query and key matrices, followed by a softmax\nnormalization. The attention output is obtained by multiplying the\nattention scores with the value matrix.\nğ´= softmax(ğ‘„ğ¾ğ‘‡\nâˆš\nğ‘‘\n) (1)\nAttention(ğ‘„,ğ¾,ğ‘‰ )= ğ´Â·ğ‘‰ (2)\nTo analyze the behavior of Transformer-based models during se-\nquence processing, we introduce the concept of attention patterns ,\nGlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models ASE â€™24, October 27-November 1, 2024, Sacramento, CA, USA\nwhich can be extracted from the corresponding row ğ´[ğ‘›]of the\nattention scores matrix ğ´. In autoregressive generation tasks, the\nattention patterns only contain the attention weights between the\ncurrent token and previously generated tokens.\nThe MLP module in Transformer-based models employs a gat-\ning mechanism similar to that of Gated Multi-Layer Perceptrons\n(gMLPs) [23]. Given an input ğ‘Œ âˆˆRğ‘›Ã—ğ‘‘, where ğ‘›denotes the se-\nquence length and ğ‘‘ denotes the dimension, the MLP first projects\nğ‘Œ to a higher-dimensional space using a linear transformation:\nğ‘ = ğ‘Œğ‘ˆ (3)\nwhere ğ‘ˆ âˆˆRğ‘‘Ã—ğ‘‘ğ‘š is a learnable weight matrix. The transformed\nrepresentation ğ‘ is then split along the feature dimension into two\nmatrices, ğ‘1,ğ‘2 âˆˆRğ‘›Ã—ğ‘‘ğ‘š/2:\nğ‘1,ğ‘2 = split(ğ‘) (4)\nAn activation function ğœ is applied element-wise to ğ‘1 to obtain\nthe MLP gate ğœ(ğ‘1). The MLP gate is then multiplied element-wise\nwith the MLP data ğ‘2 to produce the gated output Ëœğ‘:\nËœğ‘ = ğœ(ğ‘1)âŠ™ ğ‘2 (5)\nFinally, another linear transformation is applied to map Ëœğ‘ back to\nthe original dimension.\nOutput = Ëœğ‘ğ‘Š (6)\nwhere ğ‘Š âˆˆRğ‘‘ğ‘š/2Ã—ğ‘‘ is another learnable weight matrix.\nThe MLP gate ğœ(ğ‘1)and MLP data ğ‘2 in the MLP can be seen\nas a special variant of the spatial gating unit in Transformer-based\nmodels. These two components work together to control the in-\nformation flow and capture dependencies between tokens. By ex-\ntracting and analyzing the MLP gate and MLP data, we can gain\ninsights into how the model processes and responds to different\ntypes of input within the module.\n2.2 Glitch Token Phenomenon\nTokenizer plays a key role in an LLM as it transforms a continuous\ntext sequence into a list of discrete values called tokens [39]. The\ntokens transformed from the training corpus form the vocabulary\ndictionary of LLMs, and the vocabulary dictionary in turn deter-\nmines the capacity of LLMs to produce diverse and comprehensive\noutput. The rapid advancement of LLMs has brought attention to\nvarious anomalous phenomena [10, 11, 19, 20, 22, 24, 40], one of\nwhich is the existence of â€œglitch tokensâ€. These tokens exhibit anom-\nalies in constructing the expected semantics, and are subsequently\nreflected in the abnormal and unexpected decoding in the LLMâ€™s\noutput.\nThe glitch token phenomenon, first explored on the Lesswrong\nwebsite, refers to anomalous tokens such as â€œSolidGoldMagikarpâ€\nand â€œpetertoddâ€ that cause unexpected and inaccurate results in\nlanguage models like GPT-2 and GPT-J [26, 28, 29, 32]. Subsequent\nresearch examined the characteristics and instability of these to-\nkens, revealing that even subtle changes in prompts can lead to\nsignificant differences and hallucinations in the generated results.\nThe discovery of â€œpolysemousâ€ tokens, which produce different\nresponses to repeated requests, further highlighted the prevalence\nand variability of the glitch token phenomenon in LLMs [27].\nRecently, Li et al. [21] systematically investigated the glitch to-\nkens with a proposed taxonomy covering their types and symptoms.\nThey proposed three tasks, namely repetition, length and spelling,\nin their study to recognize glitch tokens. Their observation of the\nclustering distribution of glitch tokens in the word embedding\nspaces offers a novel perspective on the automatic identification\nof glitch tokens, making systematic detection feasible in LLMs\ncontaining billions, or even tens of billions of parameters.\nThe glitch token phenomenon uncovers the limitations and in-\nstability of LLMs when processing specific tokens. In this work,\nwe aim to conduct a systematic and in-depth investigation of this\nphenomenon to gain a deeper understanding of the internal mecha-\nnisms of these models. This will provide valuable insights that can\ncontribute to enhancing the robustness and reliability of LLMs in\nfuture applications.\n3 EMPIRICAL STUDY\nOur empirical study aims to explore an intuitive method for detect-\ning glitch tokens. To this end, we investigate the differences in the\nmodelâ€™s behaviors when processing glitch tokens versus normal\ntokens. Two research questions are raised to guide the study:\nâ€¢RQ1 (Characteristics): What differences are exhibited be-\ntween glitch tokens and normal tokens at the structural\nlevel of an LLM?\nâ€¢RQ2 (Ubiquity): Are the differences discovered in RQ1\nprevalent in most LLMs?\nTo address the two RQs, we investigate the internal mechanisms\nof LLMs by analyzing the status of each layer in the transformer\nforward process of prediction. This involves examining the data\nflow of the intermediate layers as the model processes inputs.\n3.1 Experiment Setup\nTo better understand the impact of glitch tokens on the modelâ€™s\ninternal output generation process, we conduct a series of experi-\nments on the Llama-2-7b-chat model [36], shortly written as Llama2.\nLlama2 is a language model based on the Llama architecture. In\nour experiments, we set the temperature to 0 to eliminate random-\nness and ensure consistency in the modelâ€™s responses. All other\nconfigurations are default.\nWe employ a unified approach to determine whether each token\nis glitchy or normal in this study based on existed definition of\nglitch tokens [12]. While the symptoms of glitch tokens may vary\nacross different tasks, we consistently utilize a repetition task to\nconstruct input sequences for glitch token identification.\nIn the context of our work, a repetitive task refers to a specif-\nically designed experimental procedure to test the fidelity of a\nlanguage model in reproducing input tokens. This task is utilized\nprimarily for the identification and categorization of tokens based\non their performance when repetitively prompted. Specifically, the\nrepetitive task involves the following steps:\n(1) Formulating a prompt that requires the model to duplicate\na specific token. The typical prompt structure is, â€œCan you\nrepeat the token â€˜{ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›}â€™ and return it back to me?â€ This\nformat is deliberately chosen to minimize contextual influ-\nence and focus purely on the token reproduction capability\nof the model.\nASE â€™24, October 27-November 1, 2024, Sacramento, CA, USAZhibo Zhang, Wuxia Bai, Yuxi Li, Mark Huasong Meng, Kailong Wang, Ling Shi, Li Li, Jun Wang, and Haoyu Wang\n(a) Attention Pattern\n0             0.2           0.4 0.6           0.8            1\nGlitch Tokens\nNormal Tokens\nFrequency\n0.16\n0.00\nMLP Data\n(b) MLP Status\nPCA dim2\nPCA dim1\nPCA dim2\nPCA dim1\nMLP Gate\nFigure 1: The distribution of attention patterns and MLP\nstatus for glitch tokens (shown in red color) and normal\ntokens (in blue color) in Llama2 model\n(2) Submitting the prompt to the model, which is configured by\nsetting the temperature parameter to zero.\n(3) Observing and analyzing the modelâ€™s output to determine\nwhether it accurately reproduces the input token. The output\nis deemed successful if the model returns the exact token as\nrequested; otherwise, the token is classified as a glitch token.\nWe traverse all the 32,000 tokens of the Llama2 model and even-\ntually identify 6,425 glitch tokens from the entire vocabulary.To\nprecisely capture intermediate layer outputs within the model, we\nresort to a transformer mechanistic interpretability tool named\nTransformer-lens [30]. Its hook technique enables real-time access\nof the activation values at all layers and allows code insertion into\nspecific intermediate layers of the model. In this study, we insert\nhooks into all intermediate layers during the first forward of the\ntested model. This approach is chosen because the first forward\ncomprehensively reflects the modelâ€™s understanding of the input\nsequence and highlights the differences between normal and glitch\ntokens.\nWe select two key features to represent the modelâ€™s internal out-\nput, i.e., attention patterns and MLP status . The attention patterns\ncapture the relative importance and relationships between tokens,\nwhile MLP status is composed of MLP gate and MLP data (Sec-\ntion 2.1), providing insights on how the model synthesizes and\nmodulates new representations within the MLP module.\n3.2 RQ1: Glitch Token Characteristics\nWe compare the extracted intermediate results of Llama2 model\nwhen processing prompts containing normal tokens and glitch to-\nkens and observe significant disparity in attention patterns and\nMLP status. The distribution of attention patterns for glitch tokens\nin some attention heads differs significantly from that of normal to-\nkens. To quantitatively analyze these differences, we randomly sam-\nple normal tokens in size of the same number as the pre-identified\nglitch tokens. To analyze the attention patterns, we create two sets\nof prompts: one containing 6,425 prompts with glitch tokens and\nanother containing 6,425 prompts with normal tokens. We then\ncompute the frequency distribution of attention patterns generated\nby these prompts, categorizing them into different value ranges.\nWe visualize the results using a histogram, as shown in Figure 1 (a).\nThe attention patterns of normal tokens (shown in blue color) gen-\nerally cluster around lower ranges and exhibit a relatively smooth\ndistribution. In contrast, the attention patterns for glitch tokens (in\nred color) display a comparably divergent and chaotic distribution.\nFurthermore, the distribution characteristics of glitch tokens in\nthe MLP status show deviations compared to normal tokens. Due\nto the high dimension of MLP status values, we cannot visualize\nthem in the same method used for attention patterns. Instead, we\nresort to PCA algorithm to convert the captured MLP status, i.e.,\nMLP gate and MLP data, to two dimension values. We present the\ndistribution of MLP gate and MLP data in scatter plots, as shown\nin Figure 1 (b). It can be observed that both two representations of\nMLP status for normal tokens tend to cluster towards a centroid,\nforming a relatively dense and bounded distribution. In contrast,\nthe MLP status of glitch tokens are highly dispersed and scattered.\nFinding 1\nLlama2 shows a significant disparity in attention patterns and\nMLP status when dealing with glitch tokens and normal tokens.\nTo illustrate the anomalies across layers, we resort to the Wasser-\nstein distance [38] to measure the magnitude of the differences in\nthe intermediate layers outputs produced by normal and glitch\ntokens, and thereby reveal the distinctions in the modelâ€™s inter-\nnal mechanisms when processing these two groups of tokens. In\nthis study, a larger Wasserstein distance indicates a greater dis-\ntributional difference. Figure 2 shows the Wasserstein distance in\nattention patterns and MLP status between normal and glitch to-\nkens across different layers of the Llama2 model. We find that the\ndifferences caused by normal and glitch tokens per layer are not\nuniformly distributed. The attention patterns and MLP status ex-\nhibit greater differences in the downstream layers closer to the\noutput, e.g., layers 19-31. This finding suggests that the impact of\nglitch tokens, although may result in negligible erroneous results\nin front layers, is amplified along with the propagation, leading to\nunexpected outputs in the end.\nFinding 2\nThe anomalous intermediate results caused by glitch tokens\nare not uniformly distributed across all layers of the model but\nare concentrated and amplified in specific key layers.\n3.3 RQ2: Ubiquity\nIn order to verify whether our previous findings exist in other\nLLMs, two additional LLMs, namely Qwen-7B-Chat model and\nMistral-7B-Instruct model (shortly as Qwen and Mistral), are se-\nlected to complement our empirical study. As shown in Figure 3,\nthe experimental results on these two models are similar to those\nof Llama2. The attention patterns of glitch tokens and normal to-\nkens exhibit inconsistent distribution. For example, the attention\npatterns of normal tokens mainly fall within the range of [0,0.2]\nin the Qwen model, while the attention patterns of glitch tokens\nshow a different shape and concentrates in the range of [0.8,1].\nSuch inconsistency can also be observed in the Mistral model, evi-\ndenced by the attention values of normal tokens and glitch tokens\nprimarily approximating around 0.5 and 0.7, respectively. In terms\nof MLP status, the intermediate layers tend to produce outputs in a\ncentroid-based cluster for normal tokens. However, the MLP status\nvalues of glitch tokens are overall chaotic and disseminated.\nGlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models ASE â€™24, October 27-November 1, 2024, Sacramento, CA, USA\n(a) Attention Pattern (b) MLP Gate (c) MLP Data\n0    1     2     3    4     5    6     7    8     9    10   11  12   13  14   15  16   17   18  19   20  21   22  23   24   25   26  27   28  29   30  31\nWasserstein Distance\n0.0025\n0.0020\n0.0015\n0.0010\n0.0005\n0.0000\n0    1     2     3    4     5    6     7    8     9    10   11  12   13  14   15  16   17   18  19   20  21   22  23   24   25   26  27   28  29   30  31 0    1     2     3    4     5    6     7    8     9    10   11  12   13  14   15  16   17   18  19   20  21   22  23   24   25   26  27   28  29   30  31\n0.00\n0.02\n0.04\n0.06\n0.08\n0.10\n0.12\n0.025\n0.020\n0.015\n0.010\n0.005\n0.000\n0.040\n0.035\n0.030\nlayer number layer number layer number\nFigure 2: Wasserstein distance of the probability distributions between glitch tokens and normal tokens in different intermediate\nlayers of Llama2 model\n(a) Attention Pattern\nMLP Gate MLP Data\n  0                      0.2                     0.4                     0.6                     0.8                      1\nGlitch Tokens Normal Tokens\n(b) MLP Status\nQwen-7B-Chat\nFrequency\nPCA dim2\nPCA dim1\n0.15\n0.00\nPCA dim2\nPCA dim1\n(c) Attention Pattern\n  0                     0.2                     0.4                     0.6                    0.8                      1\nGlitch Tokens Normal Tokens\nMistral-7B-Instruct\nFrequency\n0.00\n0.15\nMLP Data\n(d) MLP Status\nPCA dim2\nPCA dim1\nPCA dim2\nPCA dim1\nMLP Gate\nFigure 3: The example distribution of attention patterns, MLP\ngate and MLP data for glitch tokens (shown in red color) and\nnormal tokens (in blue color) in Qwen-7B-Chat and Mistral-\n7B-Instruct.\nFinding 3\nWe identify similar differences exhibited between normal and\nglitch tokens at the intermediate layers of different LLMs.\nThe findings of RQ1 provide insights for the subsequent detection\nand fix of glitch tokens, while the finding in RQ2 offers factual\nevidence for the broad application of our approach in LLMs.\n4 METHODOLOGY\nBased on the findings from our empirical study, we propose the\nGlitchProber algorithm, which aims to achieve automatic detec-\ntion and fix of glitch tokens by analyzing the internal activation\nstates of LLMS. Our approach consists of two main ideas:\n(1) Leveraging the differences in model activation values when\nprocessing glitch tokens and normal tokens to achieve rapid\nscreening of glitch tokens. By designing an anomaly detection\nalgorithm, we can identify and label potential glitch tokens\nbased on their activation features extracted from specific layers,\nwhich we refer to as key layers (detailed in Section 4.3). These\nkey layer features are crucial for detecting glitch tokens.\n(2) Fixing errors caused by glitch tokens by adjusting the modelâ€™s\nintermediate results. We designed a series of experiments where\nwe automatically adjusted the output values of the modelâ€™s\nintermediate layers and observed the impact on the final output.\nAs elucidated in Section 3.2, glitch tokens in the model predom-\ninantly affect the downstream layers close to the output, notably\nimpacting attention patterns and MLP status in specific key layers.\nThis revelation is instrumental in shaping our approach of Glitch-\nProber. By strategically focusing our efforts on key layers, we\ncan significantly reduce computational overhead while achieving\na comparable level of detection and fix efficacy to traversing all\nlayers. Thus, this approach not only optimizes the efficiency of our\nmethods but also ensures that our interventions are targeted where\nthey are most needed. For a detailed introduction to the selection\nstrategy of key layers, please refer to Section 4.3.\nBased on these ideas, we designed GlitchProber, which in-\ntegrates detection and fix algorithms. GlitchProberâ€™s detection\nalgorithm identifies and locates glitch tokens causing model output\nerrors by analyzing intermediate layer activation states. It randomly\nsamples a subset of tokens from the vocabulary, tests them using\nrepetitive tasks, and extracts activation features from key layers.\nThese features undergo dimensionality reduction and are labeled\nbased on repetitive task outcomes. A classifier is then trained with\nthe labeled data to assess unknown tokens. Finally, the remaining\ntokens are detected individually using the trained SVM classifier,\nand predictions are verified through repetitive tasks.\nGlitchProberâ€™s fix algorithm corrects the anomalous activa-\ntion patterns of glitch tokens by adjusting activation values in the\nmodelâ€™s intermediate layers, eliminating their negative impact on\nthe model output. It first calculates activation statistics of normal\ntokens in key layers and identifies neurons that are consistently\nactivated or silent in most normal tokens. Then, it compares these\nneuronsâ€™ activations between normal and glitch tokens, calculat-\ning suppression ratio coefficients for anomalous activations and\nactivation values to promote silent neurons. Finally, it rectifies\nthe activation values of glitch tokens in key layers based on these\ncoefficients and values, automatically fixing the glitch tokens.\n4.1 Detecting Glitch Tokens via GlitchProber\nGlitchProber identifies and detects glitch tokens that cause model\noutput errors by analyzing the intermediate layer activation states\nof Transformer language models when processing tokens. The main\nworkflow of the algorithm is shown in Figure 4. The detection al-\ngorithm of GlitchProber consists of three main steps: feature\nextraction and dimension reduction, SVM-based glitch token classi-\nfier, and glitch token identification and validation.\n4.1.1 Feature Extraction and Dimension Reduction. Glitch-\nProber adopts a random sampling strategy to select samples from\nASE â€™24, October 27-November 1, 2024, Sacramento, CA, USAZhibo Zhang, Wuxia Bai, Yuxi Li, Mark Huasong Meng, Kailong Wang, Ling Shi, Li Li, Jun Wang, and Haoyu Wang\nfields   spÃ¤ter Ğ¡ÑÑ‹Ğ»ĞºĞ¸  Ã¡ s t  \nToken Vocabulary Repetitive\nTask\nSample\nTokens\nInput\nTemplate\nOpen-Source LLM\ntrÃ¨s    Ğ½Ğ¸Ñ‡Ğµ Found   T e l e \nOpen-Source LLM\nEmbedding\nForward 1\nForward 2\nForward n\nOther\nTokens\nN G N\nN N N\nN N G\nLabels\nLabeling\nTraining\nSet\nTraining\nClassifier\nGN NN NG\nNNGG\nPost-processing\nData Collection\nSelect Key\nLayers\nHook\nAttention\nPattern\nMLP Gate\nMLP Data\nFeatures PCA\nEmbedding Forward 1\nAttention\nQ K V\nMLP gate\nMLP data\nLayer 0\nAttention\nQ K V\nMLP gate\nMLP data\nLayer 1\nDetailed Forward 1 Select Key\nLayers\nâ€¦\nâ€¦â€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nâ€¦\nLayer N-1\nMLP gate\nMLP data\nAttention\nQ K V\nFigure 4: GlitchProber workflow for detecting glitch tokens. The red arrows represent the data flow during the training\nprocess, while the black arrows represent the data flow during the detection process.\nthe modelâ€™s token vocabulary ğ‘‰ to form the sample set ğ‘†. The\nchoice of sampling rate ğ›¾ needs to balance between sample size\nand computational efficiency. A larger ğ›¾ leads to a larger sample\nsize and more accurate detection results but also incurs higher\ncomputational costs. Conversely, a smaller ğ›¾ results in a smaller\nsample size and faster computation but may affect the detection\nperformance. Through experiments, we determined that when ğ›¾ is\nin the range of [0.1, 0.3], GlitchProber achieves a good balance\nbetween detection performance and efficiency.\nGlitchProber uses a unified repetitive task to construct input\nsequences for glitch token identification in the sample set ğ‘†. For\ntokens in the sample set ğ‘†, the algorithm assigns corresponding\ncategory labels according to the output results of the repetitive task.\nAt the same time, we extract the attention pattern, MLP gate and\nMLP data features in the modelâ€™s first forward process. However, the\ndimension of the original feature tensors is high, and directly using\nthem to train the classifier would lead to excessive computational\ncosts. To improve computational efficiency, we adopt a dimension\nreduction strategy. The PCA algorithm [ 1] is applied to reduce\nthe dimension, mapping the original high-dimensional features\nto a low-dimensional subspace while maximally preserving the\ndiscriminative information of the features. Through experiments,\nwe found that when the dimension ğ‘ƒ of the reduced features is\nin the range of [50, 200], a good balance between computational\nefficiency and information retention can be achieved. Therefore,\nwe set ğ‘ƒ = 75 as the default dimension reduction parameter.\n4.1.2 SVM-based Glitch Token Classifier. GlitchProber trains\nan SVM classifier using the low-dimensional feature representation\nmatrix ğ¹ of the sample set ğ‘† and the corresponding category labels.\nThe trained SVM classifier will be used for subsequent glitch assess-\nment of unknown tokens. SVM is a binary classification algorithm\nthat is particularly suitable for problems with high-dimensional fea-\nture spaces, which aligns well with the characteristics of the glitch\ntoken detection task in GlitchProber. Besides, SVM has higher\ncomputational efficiency and shorter training time when handling\nhigh-dimensional features compared to other binary classification\nalgorithms. That helps achieve rapid real-time detection of glitch\ntokens in GlitchProber. Therefore, we adopt SVM as the classifier\nin the detection algorithm of GlitchProber.\n4.1.3 Glitch Token Identification and Validation. The tokens\nin the token vocabulary that were not sampled are individually\ndetected. The token to be detected is input into the same repetitive\ntask as in the training phase, and its features attention patterns,\nMLP gate, and MLP data are extracted in the modelâ€™s first forward\nmodule. Subsequently, the trained SVM classifier is used to make\npredictions based on the extracted features.\nIf a token is predicted as â€œglitchyâ€, the algorithm will input\nthis token into the model and further use the repetitive task to\nvalidate it. If the model can correctly repeat the token, we consider\nit as a potential normal token, and the SVM classifier may have\nmade a false positive prediction. Through this post-processing step,\nGlitchProber can effectively reduce the false positive rate of glitch\ntoken detection and improve the precision of detection. Finally,\nGlitchProber outputs two sets: the set of glitch tokens ğº and the\nset of normal tokens ğ‘.\nAlgorithm 1: GlitchProber (Detection)\nInput: Token Vocabularyğ‘‰; PCA Dimension ğ‘ƒ; Sample Rate ğ›¾;\nKeyLayers[]\nOutput: Glitch token set ğº; Normal token set ğ‘\n1 ğ‘† â†randomSample(ğ‘‰,ğ›¾ );\n2 foreach Token âˆˆğ‘†do\n3 SampleFeatures â†hookModel(Token,KeyLayers);\n4 SampleLabels â†validateGlitch(Token);\n5 end\n6 ğ¹ â†PCA(SampleFeatures,ğ‘ƒ);\n7 Classifier â†trainClassifier(ğ¹,SampleLabels);\n8 foreach Token âˆˆğ‘‰ do\n9 if Token âˆ‰ ğ‘†then\n10 Feature â†PCA((hookModel(Token,KeyLayers)),ğ‘ƒ);\n11 if classify(Classifier,Feature)== â€˜Normalâ€™ then\n12 ğ‘ â†Token;\n13 else\n14 if validateGlitch(Token)== â€˜Glitchâ€™ then\n15 ğº â†Token;\n16 else\n17 ğ‘ â†Token;\n18 end\n19 end\n20 end\n21 end\n4.1.4 Detection Process Algorithm. The pseudocode for the\ndetection algorithm of GlitchProber is shown in Algorithm 1.\nGlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models ASE â€™24, October 27-November 1, 2024, Sacramento, CA, USA\nG G G Open-Source LLM\nGlitch\nAnswer\nCorrect\nAnswer\nRepetitive\nTask\nInput\nTemplate\nForward 1\nForward 2\nForward n\nâ€¦\nModified Forward 1\nModified Forward 2\nModified Forward n\nâ€¦\nEmbedding\nModified Forward\nMLP gate\nMLP data\nOther Layers\nAttention\nQ K V \nğŸ”\n   Statistics & Adjust\nN N N \nKey Layers\nAttention\nQ K V \nMLP gate\nMLP data\nModified MLP gate\nModified MLP data\nFigure 5: GlitchProber workflow for fixing glitch tokens.\nInitially, the algorithm samples a subset of tokens ( ğ‘†) from the\nvocabulary (ğ‘‰) based on a predefined sampling rate (ğ›¾) (line 1). For\neach token in this subset, the algorithm extracts relevant features\nusing a transformer model over specified key layers and assigns\nlabels indicating whether each token is glitchy (lines 2-5).\nFollowing the feature extraction, the algorithm applies PCA to\nreduce the dimension of these features to a lower-dimensional space\n(ğ‘ƒ) (line 6). The reduced feature set (ğ¹) is then used to train a SVM\nclassifier with the assigned glitch labels (line 7).\nFor tokens not included in the initial sample, the algorithm uses\nthe trained SVM classifier to predict whether each token is normal\nor a glitch (lines 8-12). Tokens classified as glitches will undergo\na further validation step to confirm their status, effectively mini-\nmizing the false positive rate (lines 14-18). Finally, the algorithm\ncompiles and outputs two sets, namely glitch token set ( ğº) and\nnormal token set (ğ‘).\n4.2 Fixing Glitch Tokens via GlitchProber\nWe further explore the possibility of correcting the anomalous\nactivation patterns of glitch tokens to normal patterns by adjusting\nthe activation values of the modelâ€™s intermediate layers, thereby\neliminating their negative impact on the model output. Based on the\nidea of adjusting neuron activation values to eliminate the influence\nof glitch tokens, we focus on two types of neurons in normal tokens,\ni.e., the neurons that are activated in the vast majority of normal\ntokens, and the neurons that are not activated in any normal tokens.\nThen we compare the differences in activation values of these key\nneurons between normal tokens and glitch tokens. By simulating\nthose normal activation patterns, we achieve adaptively adjustment\nof the activation values of glitch tokens. The overall approach is\nillustrated in Figure 5.\n4.2.1 Normal Token Activation Value Statistics. GlitchProber\nfirst randomly samples a subset of normal tokens, i.e., ğ‘â€²âŠ‚ğ‘, to\ncalculate the activation value distribution of normal tokens in the\ntarget layers. We set the sampling rate to ğ›¾, which is consistent\nwith the sampling rate in the glitch token detection phase.\nFor the MLP module in each layer, we calculate the activation\nstatistics of the tokens in the normal token set ğ‘â€². We define two\nsets of neuron indices as ğ‘ğ‘’ğ‘¢ğ‘›â†‘and ğ‘ğ‘’ğ‘¢ğ‘›â†“based on their activa-\ntion patterns, where ğ´ğ‘ğ‘¡[ğ‘–]represents the activation value of the\nğ‘–-th neuron in the MLP module, and ğ‘šis the predefined threshold.\nğ‘ğ‘’ğ‘¢ğ‘›â†‘= {ğ‘–|ğ´ğ‘ğ‘¡[ğ‘–]> ğ‘šfor over 99% of tokens in ğ‘â€²} (7)\nğ‘ğ‘’ğ‘¢ğ‘›â†“= {ğ‘–|ğ´ğ‘ğ‘¡[ğ‘–]â‰¤ ğ‘šfor all tokens in ğ‘â€²} (8)\nğ‘ğ‘’ğ‘¢ğ‘›â†‘denotes the set of key neurons that exhibit high activation\nlevels, surpassing predefined threshold ğ‘š, across sample token set\nğ‘â€². Given that activated neurons constitute a small proportion of\nthe total neurons, we consider a neuron to be a key neuron if it is\nactivated in over 99% of the tokens. Conversely, ğ‘ğ‘’ğ‘¢ğ‘›â†“represents\nthe set of key neurons that exhibit consistently low activation\nlevels, falling below ğ‘š. We consider a neuron to be a key neuron in\nğ‘ğ‘’ğ‘¢ğ‘›â†“if its activation level remains below the threshold ğ‘šfor all\ntokens in ğ‘â€². These neurons can be considered as the key features\nfor suppressing noise, as they are consistently inactive for normal\ntokens. By identifying these two sets of neuron indices based on\ntheir activation patterns, we can create a profile of the expected\nbehavior of normal tokens at each MLP module. Those methods\nensure the recorded neurons take the most informative features\nwhen we mitigate the influence of noise and irrelevant information\ncaused by glitch tokens.\nNote that we only adjust the activation values of the MLP mod-\nule and not the attention patterns. Attention patterns capture the\nrelative importance between tokens, and modifying them may dis-\nrupt token dependencies and introduce noise. In contrast, MLP\nactivation values reflect the modelâ€™s understanding of each token\nindependently, and adjusting these values has less impact on token\nrelationships. By only adjusting MLP activation values, we aim to\nfix glitch tokens without introducing additional noise.\n4.2.2 Activation Value Adjustment. When the hooked model\nprocesses detected glitch tokens, GlitchProber intervenes in this\nprocess, making trend-based adjustments to the neurons identi-\nfied by ğ‘ğ‘’ğ‘¢ğ‘›â†‘and ğ‘ğ‘’ğ‘¢ğ‘›â†“. For neurons in ğ‘ğ‘’ğ‘¢ğ‘›â†‘that should be\nactivated but have insufficient activation in glitch tokens, the algo-\nrithm uses ğ›½ as an amplification factor to promote their activation.\nConversely, for neurons in ğ‘ğ‘’ğ‘¢ğ‘›â†“that should be suppressed but\nare abnormally activated in glitch tokens, the algorithm uses ğ›¼ as a\nreduction factor to suppress their anomalous activation. The factors\nğ›½ and ğ›¼ are named adjustment factors, which play a crucial role\nin the glitch token fixing process. For the calculation of ğ›½ and ğ›¼,\nwe first calculate the average activation value difference Î”ğ´ğ‘ğ‘¡â†‘of\nglitch tokens relative to normal tokens on highly activated neurons\n(ğ‘ğ‘’ğ‘¢ğ‘›â†‘), and the average activation value ratio Î”ğ´ğ‘ğ‘¡â†“on lowly\nactivated neurons (ğ‘ğ‘’ğ‘¢ğ‘›â†“).\nÎ”ğ´ğ‘ğ‘¡â†‘= 1\n|ğ‘ğ‘’ğ‘¢ğ‘›â†‘|\nâˆ‘ï¸\nğ‘–âˆˆğ‘ğ‘’ğ‘¢ğ‘›â†‘\n(ğ´ğ‘ğ‘¡normal [ğ‘–]âˆ’ğ´ğ‘ğ‘¡glitch [ğ‘–]) (9)\nÎ”ğ´ğ‘ğ‘¡â†“= 1\n|ğ‘ğ‘’ğ‘¢ğ‘›â†“|\nâˆ‘ï¸\nğ‘–âˆˆğ‘ğ‘’ğ‘¢ğ‘›â†“\n\u0012 ğ´ğ‘ğ‘¡glitch [ğ‘–]\nğ´ğ‘ğ‘¡normal [ğ‘–]\n\u0013\n(10)\nSubsequently, through linear transformation and range restric-\ntion, the algorithm mapsÎ”ğ´ğ‘ğ‘¡â†‘and Î”ğ´ğ‘ğ‘¡â†“to appropriate numerical\nintervals to obtain the values of ğ›½ and ğ›¼, respectively.\nASE â€™24, October 27-November 1, 2024, Sacramento, CA, USAZhibo Zhang, Wuxia Bai, Yuxi Li, Mark Huasong Meng, Kailong Wang, Ling Shi, Li Li, Jun Wang, and Haoyu Wang\nğ›½ = ğ‘˜1 Â·Î”ğ´ğ‘ğ‘¡â†‘+ğ‘1 (11)\nğ›¼ = ğ‘˜2 Â·Î”ğ´ğ‘ğ‘¡â†“+ğ‘2 (12)\nThe constants ğ‘˜1, ğ‘1, ğ‘˜2, and ğ‘2 are derived through an adaptive\nprocess tailored to the specific dynamics of each model. A set of\ndefault values is provided, which can be adjusted based on empirical\ndata to optimize the correction process for different types of models.\nThey are crucial for ensuring ğ›½ and ğ›¼ effectively modulate neuron\nactivations while maintaining system stability and performance.\nAfter the adjustment of the MLP activation values is completed,\nwe input the corrected activation values back into the subsequent\nlayers, allowing the model to continue the forward propagation\nuntil the final fixed result is output. This process corrects on each\ntoken in the detected glitch token set ğº.\nAlgorithm 2: GlitchProber (Fix)\nInput: Glitch token set ğº; Normal token set ğ‘; Sample Rate ğ›¾;\nThreshold ğ‘š; KeyLayers[]\n1 ğ‘â€²â†randomSample(ğ‘,ğ›¾ );\n2 ğ‘ğ‘’ğ‘¢ğ‘›â†‘,ğ‘ğ‘’ğ‘¢ğ‘› â†“â†statisticsNeuron(ğ‘â€²,ğ‘š);\n3 ğ›½ â†statisticsBeta(ğ‘â€²,ğ‘ğ‘’ğ‘¢ğ‘› â†‘);\n4 ğ›¼ â†statisticsAlpha(ğ‘â€²,ğ‘ğ‘’ğ‘¢ğ‘› â†“);\n5 foreach Token âˆˆğº do\n6 for Layer âˆˆKeyLayers do\n7 ğ´ğ‘ğ‘¡ğ‘–ğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘› â†hookModel(Token,Layer);\n8 foreach Neuron âˆˆğ‘ğ‘’ğ‘¢ğ‘›â†‘do\n9 ğ´ğ‘ğ‘¡[Neuron]â† ğ´ğ‘ğ‘¡[Neuron]+ ğ›½;\n10 end\n11 foreach Neuron âˆˆğ‘ğ‘’ğ‘¢ğ‘›â†“do\n12 ğ´ğ‘ğ‘¡[Neuron]â† ğ´ğ‘ğ‘¡[Neuron]/ğ›¼;\n13 end\n14 hookModel(Token,Layer)â† ğ´ğ‘ğ‘¡ğ‘–ğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘›;\n15 end\n16 end\n4.2.3 Fixing Process Algorithm. Based on Section 4.2.2, we\npresent the pseudocode for the fix algorithm of GlitchProber\nin Algorithm 2. The algorithm begins by sampling a subset ( ğ‘â€²)\nof normal tokens from the full set of normal tokens ( ğ‘) (line 1).\nThen it computes the statistical distribution of activation values\nacross key neurons in the subset, distinguishing ğ‘ğ‘’ğ‘¢ğ‘›â†‘and ğ‘ğ‘’ğ‘¢ğ‘›â†“\n(line 2). After that the algorithm calculates the adjustment factors\nğ›½ and ğ›¼ for the identified key neurons (line 3-4).\nFor each glitch token in the set ğº, the algorithm iteratively ap-\nplies these adjustments across specified layers (i.e., KeyLayers) of\nthe model (lines 5-7). Neurons in ğ‘ğ‘’ğ‘¢ğ‘›â†‘have their activation val-\nues increased by ğ›½, amplifying their response to mimic normal\nactivation patterns (lines 8-10). Conversely, neurons inğ‘ğ‘’ğ‘¢ğ‘›â†“have\ntheir activation values reduced by dividing by ğ›¼, suppressing any\nabnormal activations (lines 11-13). Each adjusted activation is rein-\ntegrated into the modelâ€™s processing flow, allowing it to continue\nwith forward propagation with the corrected values (line 14).\n4.3 Key Layers Selection\nIn the design of our GlitchProberâ€™s detection and fix algorithms,\nwe focused on exploiting the attention pattern and MLP status fea-\ntures within certain key layers. The rationale behind selecting these\nkey layers stems primarily from our empirical findings outlined in\nFinding 2 (Section 3.2), which highlighted that glitch tokens predom-\ninantly affect the modelâ€™s downstream layers closer to the output.\nFor instance, in Llama2, this pertains to layers 19 to 31. Further\nrefining our selection, we encountered a counter-intuitive discov-\nery: modifying features in layers exceedingly close to the output\nparadoxically diminished the effectiveness of our fix algorithms.\nThe layers preceding the final output are crucial for tailoring\nresponses based on preceding computations; alterations in these\nlayers can disrupt representational balances, leading to degraded\nperformance. In our approach for Llama2, we designated layers 19 to\n28 as key layers, optimally positioned in the middle to lower sections\nof the modelâ€™s architecture. This strategic placement ensures that\nour interventions effectively mitigate the effects of glitch tokens\nwhile preserving the modelâ€™s robustness.\n5 EVALUATION OF GLITCH TOKEN\nDETECTION\n5.1 Experiment setup\nExperiment Environment. All experiments are performed on a\nworkstation with Ubuntu 22.04.3 LTS and 250GB memory, and 2\nA100 GPU with 80GB memory each.\nLLM Selection. We thoroughly evaluated our proposed method\nusing a diverse set of computational models. We selected five widely\nrecognized, open-source models, including Llama-2-7b-chat [36],\nMistral-7B-Instruct-v0.1 [18], Qwen-7B-Chat [5], Gemma-2b-it [14],\nand Yi-6B-Chat [3]. These models served as the subjects for our\nin-depth analysis, allowing us to assess the versatility and effective-\nness of our method across various real-world applications. Table 1\nprovides an overview of these modelsâ€™ parameters.\nEvaluation of Detection Baselines. To evaluate the performance\nof GlitchProber, we compared it with two implemented bench-\nmark schemes and a recent testing method, GlitchHunter.\n(1) Exhaustive Search: Each token in the token list is individually\nfed into the model, which performs tasks such as paraphrasing,\nspelling, and length calculation for each token.\n(2) Rule-based Random Sampling: First, randomly select half\nof the tokens from the language model to form a candidate set.\nSince common English words typically do not become glitch\ntokens, use the Natural Language Toolkit (NLTK) to remove\nhigh-frequency English words from the candidate set. The re-\nmaining tokens are considered potential glitch tokens.\n(3) GlitchHunter: This is the state-of-the-art automated detec-\ntion method for glitch tokens [21].\nEvaluation Metrics of Detection. For efficiency evaluation, we\nconsider the Time Cost required to process all glitch tokens in\nthe complete token list of a model. For GlitchProber, it encom-\npasses the total duration including feature extraction, classifier\ntraining, identification and validation. For effectiveness evaluation,\nwe consider True Positive, Precision, Recall and F1-Score.\nEvaluation Settings. In our detection experiments, we evaluated\nthe performance of GlitchProber with SVM regularization pa-\nrameter and degree[33, 37] set to ğ¶ = 1,ğ‘‘ğ‘’ğ‘”ğ‘Ÿğ‘’ğ‘’ = 3. We employ\nğ›¾ = 0.1 for random sampling and principal components to ğ‘ƒ = 75\nGlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models ASE â€™24, October 27-November 1, 2024, Sacramento, CA, USA\nTable 1: Summary of models in evaluation\nModel Name Number of\nParameters\nVocabulary\nSize\nHidden\nLayers\nIntermediate\nSize\nAttention\nHeads\nLlama-2-7b-chat 6.74B 32,000 32 11,008 32\nMistral-7B-Instruct-v0.1 7.24B 32,000 32 14,336 32\nQwen-7B-Chat 7.72B 151,936 32 22,016 32\nGemma-2b-it 2.51B 256,000 18 16,384 8\nYi-6B-Chat 6.06B 64,000 32 11,008 32\nTable 2: Time cost comparison of GlitchProber and other\nbaselines on different LLMs.\nTest Model Exhaustive SearchGlitchHunterGlitchProber(ours)\nLlama-2-7b-chat 619min 43s 74min 11s 61min 38s\nMistral-7B-Instruct-v0.1651min 17s 64min 26s 42min 39s\nQwen-7B-Chat 2,228min 23s 720min 42s 92min 48s\nGemma-2b-it 3,575min 9s 681min 16s 96min 43s\nYi-6B-Chat 974min 4s 825min 25s 140min 57s\nAverage Time Cost 1,609min 42s 473min 11s 89min 9s\nfor PCA. For the rule-based random sampling methods, we con-\nducted 100 independent experiments and averaged the results to\nobtain statistically significant conclusions. For the GlitchHunter\nmethod, we used the default settings from the original paper [21].\n5.2 RQ3 (Efficient Detection): How efficient is\nour approach in identifying glitch tokens\nacross different LLMs?\nTo evaluate the efficiency of GlitchProber, time overhead and the ac-\ncuracy comparison results of various methods on five large models\nare shown in Table 2 and Table 3.\nOur experimental results demonstrate thatGlitchProber reached\na detection efficiency advantage. Meanwhile,GlitchProber achieves\na 100% precision which matches the performance of both Glitch-\nHunter and the exhaustive search benchmark method. This sig-\nnifies GlitchProberâ€™s minimal false positive rate. Furthermore,\nGlitchProber achieves a recall rate of 64.47%, surpassing Glitch-\nHunterâ€™s 26.52%. The F1-score indicates thatGlitchProber strikes\na fine balance between precision and recall, efficiently detecting\nglitch tokens while maintaining high accuracy.\nAnswer to RQ3\nGlitchProber achieves perfect accuracy across all test cases\nwith low time overhead, exhibiting superior stability and per-\nformance in glitch token detection. Its efficiency gains are\nprimarily attributed to its strategic adoption of small-scale\nsampling and intermediate layer feature extraction techniques,\nsignificantly enhancing detection efficacy.\n5.3 RQ4 (Ablation Study): How do the different\ncomponents of GlitchProber affect the\ndetection results?\nTo assess the importance of the components in GlitchProber, we\nperformed an ablation study across five models. We developed two\nvariants: GlitchProber-No-PCA and GlitchProber-No-Post.\nGlitchProber-No-PCA omits the PCA during feature processing,\nwhile GlitchProber-No-Post eliminates the final token validation\nsteps in the original GlitchProber. The comprehensive results are\nshown in Table 4.\nTable 3: Performance comparison of GlitchProber and\nother baselines on different LLMs\nTest Model Metric Rule-based\nRandom Sampling\nGlitchHunterGlitchProber\nLlama-2-7b-chat\nTP 2,936 1,955 4,446Precision 24.74% 100.00% 100.00%Recall 45.70% 30.43% 69.22%F1-score 0.3210 0.4724 0.8181\nMistral-7B-Instruct-v0.1\nTP 1,288 1,233 1,873Precision 11.44% 100.00% 100.00%Recall 46.35% 44.37% 67.41%F1-score 0.1836 0.6147 0.8053\nQwen-7B-Chat\nTP 15,419 4,031 19,366Precision 21.04% 100.00% 100.00%Recall 50.24% 14.42% 63.08%F1-score 0.2966 0.2521 0.7736\nGemma-2b-it\nTP 13,777 3,240 17,387Precision 11.30% 100.00% 100.00%Recall 49.27% 10.56% 62.18%F1-score 0.1838 0.1910 0.7668\nYi-6B-Chat\nTP 3,215 2,662 4,900Precision 13.10% 100.00% 100.00%Recall 39.67% 32.84% 60.45%F1-score 0.1969 0.4944 0.7535\nAverage PerformancePrecision 16.32% 100.00% 100.00%Recall 46.24% 26.52% 64.47%F1-score 0.2364 0.4049 0.7835\nTable 4: Comparison of performance and memory usage for\nGlitchProber with different feature configurations across\nvarious language models.\nModel MetricsGlitchProberGlitchProber-No-PostGlitchProber-No-PCA\nLlama-2-7b-chatF1-Score0.8529 0.6097 â€“Memory103.71GB 101.22GB 250.00GB\nMistral-7B-Instruct-v0.1F1-Score0.8652 0.5429 â€“Memory107.11GB 102.67GB 250.00GB\nQwen-7B-ChatF1-Score0.8854 0.5510 â€“Memory109.03GB 101.20GB 250.00GB\ngemma-2b-it F1-Score0.8143 0.4226 â€“Memory131.04GB 127.96GB 250.00GB\nYi-6B-Chat F1-Score0.8718 0.4507 â€“Memory83.32GB 82.76GB 250.00GB\nNote: â€˜â€“â€™ denotes incomplete experiment due to exceeding the maximum memory of our server of 250.00GB.\nTable 4 offers a detailed comparative analysis of GlitchProber\nalongside its variants. With respect to the F1-score, GlitchProber\nmarkedly surpasses GlitchProber-No-Post, demonstrating av-\nerage improvements of 0.32. These findings underscore the vital\nimportance of implementing robust post-classification enhance-\nments to boost overall performance. Furthermore, the absence of\nPCA in GlitchProber-No-PCA leads to substantial increases in\nmemory usage beyond the maximum capacity of our server, result-\ning in the incompletion of GlitchProber-No-PCA. This starkly\nhighlights the necessity of dimensionality reduction as a means to\noptimize resource allocation and ensure system stability.\nAnswer to RQ4\nThe PCA dimensionality reduction and the post-process are\ncrucial components for GlitchProber. Omitting either of\nthese components leads to a significant decrease in effective-\nness, undermining the utility of GlitchProber.\n6 EVALUATION OF GLITCH TOKEN FIX\n6.1 Experiment setup\nEvaluation Baselines of Fix. Due to the lack of existing methods\nfor fixing glitch tokens, we compared GlitchProber with a bench-\nmark scheme: a rule-based fix method, to verify its effectiveness.\nSpecifically, the rule-based fix method does not rely on specific ac-\ntivation value differences to determine ğ›¼ and ğ›½. Instead, it directly\nASE â€™24, October 27-November 1, 2024, Sacramento, CA, USAZhibo Zhang, Wuxia Bai, Yuxi Li, Mark Huasong Meng, Kailong Wang, Ling Shi, Li Li, Jun Wang, and Haoyu Wang\nTable 5: Performance comparison of GlitchProber and\nRule-based method on different models.\nModel Metric Method\nRule-based FixGlitchProber\nLlama-2-7b-chat Repaired Tokens 3,805 4,021\nRepair Rate 59.22% 62.58%\nMistral-7B-Instruct-v0.1Repaired Tokens 359 1,045\nRepair Rate 12.92% 37.60%\nQwen-7B-Chat Repaired Tokens 10,645 14,765\nRepair Rate 34.68% 48.11%\nGemma-2b-it Repaired Tokens 9,865 13,638\nRepair Rate 35.28% 48.77%\nYi-6B-Chat Repaired Tokens 3,390 4,317\nRepair Rate 41.83% 53.26%\nAverage Repaired Tokens 5,613 7,758\nRepair Rate 36.79% 50.06%\nuses a fixed value to adjust activation values at the same neuron\npositions as GlitchProber.\nEvaluation Metrics of Fix Experiments. We used two test met-\nrics to evaluate the performance of the fix methods: the number of\nrepaired glitch tokens (Repaired Tokens) and the repair rate (Repair\nRate). The repair rate represents the proportion of glitch tokens\nsuccessfully repaired out of all glitch tokens. It is calculated using\nthe following formula:\nRepair Rate = Repaired Token Number\nTotal Glitch Token Number (13)\nThese two metrics can intuitively reflect the actual effectiveness of\nthe fix methods.\nEvaluation Settings. In our fix experiments, we remain the\nsame ğ›¾ = 0.1 for random sampling and choose the same key layers.\nFor the threshold, we set ğ‘š= 1 to determine ğ‘ğ‘’ğ‘¢ğ‘›â†‘and ğ‘ğ‘’ğ‘¢ğ‘›â†“.\n6.2 RQ5 (Effective Fix): How effective is our\napproach in fixing glitch tokens across\ndifferent LLMs?\nWe compared the performance of the GlitchProber fix algorithm\nwith the rule-based fix method in terms of repaired tokens and\nrepair rate under the same conditions to evaluate the effectiveness\nof GlitchProber. Table 5 presents the performance comparison\nof the two methods across different test models.\nThe results indicate that although the rule-based fix method uses\nfixed ğ›¼ and ğ›½ values (ğ›¼ = 4 and ğ›½ = 1.5) and lacks flexibility, it can\nstill direct the activation or inhibition of neurons associated with\nglitch tokens, achieving a certain degree of fix. This demonstrates\nthat adjusting neuron activation values to correct the abnormal\nbehavior of glitch tokens is a viable and effective fix strategy. How-\never, due to its lack of specificity, the fix effect of this method is\nrelatively limited. In contrast, GlitchProber precisely calculates ğ›¼\nand ğ›½, and selectively adjusts the activation patterns of key feature\nneurons, achieving an average repair rate of 50.06% across the five\nmodels, outperforming the rule-based method.\nAnswer to RQ5\nGlitchProber has effectively fixed glitch tokens across five\nLLMs. Compared to the rule-based method, its key improve-\nment is the precise calculation of ğ›¼ and ğ›½, allowing better\napplication to different models.\nTable 6: Post process time of GlitchProber using various\nSVM parameter configurations (in seconds)\nFeature Type C=0.1\ndegree=2\nC=0.5\ndegree=2\nC=0.5\ndegree=3\nC=1\ndegree=3\nAttn_pattern 1,413.88 1,453.21 1,360.12 1,357.70\nMLP_gate 1,407.36 1,458.88 1,436.23 1,445.11\nMLP_data 1,473.43 1,541.10 1,579.08 1,581.00\nAttn_pattern + MLP_gate 1,410.79 1,438.57 1,444.74 1,472.50\nAttn_pattern + MLP_data 1,427.43 1,479.34 1,514.72 1,513.41\nMLP_gate + MLP_data 1,453.72 1,504.36 1,546.09 1,530.88\nAttn_pattern + MLP_gate + MLP_data 1,444.23 1,471.85 1,502.46 1,500.23\n7 DISCUSSION\n7.1 Hyperparameters Choice of GlitchProber\nIn this section, an experiment is conducted to illustrate the selection\nprocess for the principal features in LLMs and the hyperparameters\nin SVM. Specifically, the parameters ğ¶ and ğ‘‘ğ‘’ğ‘”ğ‘Ÿğ‘’ğ‘’ in the SVMâ€™s\npolynomial kernel require elucidation. The parameterğ¶, commonly\nreferred to as the regularization parameter, controls the trade-off\nbetween achieving a low error on the training data and minimizing\nthe model complexity for better generalization to new data. A higher\nvalue of ğ¶ tries to fit the training set as well as possible (higher\nmodel complexity), while a lower value leads to a model that might\nnot perform as well on the training set but is better at generalizing.\nOn the other hand, ğ‘‘ğ‘’ğ‘”ğ‘Ÿğ‘’ğ‘’ pertains to the degree of the polynomial\nkernel function and is crucial for defining the complexity of the\ndecision surface. A higher ğ‘‘ğ‘’ğ‘”ğ‘Ÿğ‘’ğ‘’ results in more complex decision\nboundaries, capable of capturing more intricate patterns in the data.\nHowever, this also increases the risk of overfitting, particularly in\nscenarios with noise and limited data samples [33, 37].\nAs depicted in Table 6, no significant differences are observed in\nthe time consumption across various groups of hyperparameters\nand features. Therefore, the average F1-score, as illustrated in Fig-\nure 6, is considered for comparison. The comparison of the F1-score\nwithout post-processing is chosen as it more accurately reflects the\ninherent effectiveness of the different features and hyperparame-\nters. Figure 6 clearly shows that the hyperparameter group in the\nlower right corner achieves the highest F1-score of 0.6117 without\npost-processing, which is noteworthy. Consequently, ğ¶ = 1 and\ndegree = 3 are selected as the hyperparameters for SVM. All three\nfeatures are chosen for the detection process, and two MLP-based\nfeatures are chosen for the fix process.\nWe further examine the rationale behind the selection of the\nhyperparameter ğ›¾, which determines the sampling rate from the\nmodelâ€™s token vocabulary ğ‘‰ for the sample set ğ‘† in GlitchProber.\nThe parameter ğ›¾ is pivotal in balancing detection accuracy against\ncomputational efficiency. Empirical analysis, as shown in Table 7,\ndemonstrates that a ğ›¾ increment from 0.1 to 0.3 improves recall\nfrom 0.6922 to 0.7457 and raises the F1 score from 0.8181 to 0.8543,\nwith a reasonable increase in computational time. However, further\nincreasing ğ›¾ to 0.7, while boosting recall and F1 scores to 0.7812\nand 0.8772 respectively, significantly extends processing times to\nover 100 minutes. Therefore, ağ›¾range of 0.1 to 0.3 is recommended,\nas it optimally balances performance gains with computational effi-\nciency, ensuring that GlitchProber remains practical for operational\nuse.\nGlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models ASE â€™24, October 27-November 1, 2024, Sacramento, CA, USA\nAttention pattern\nC=0.1  \ndegree=2\nC=0.5  \ndegree=2\nC=0.5  \ndegree=3\nC=1  \ndegree=3\nMLP gate\nMLP data\nAttention pattern\n+ MLP gate\nMLP gate \n+ MLP data\nAttention pattern\n+ MLP data\nAttention pattern \n+ MLP gate \n+ MLP data\nFeature Type\nFigure 6: Different Feature Combination Comparison for\nGlitchProber\nTable 7: Model performance across different gamma values\non Llama2 model\nSampling Rateğ›¾=0.1 ğ›¾=0.2 ğ›¾=0.3 ğ›¾=0.5 ğ›¾=0.7\nPrecision 100% 100% 100% 100% 100%\nRecall 69.22% 72.81% 74.57% 76.65% 78.12%\nF1 Score 81.81% 84.26% 85.43% 86.78% 87.72%\nTime 61min 38s 68min 14s 74min 30s 86min 52s 100min 41s\nTable 8: Performance comparison of original and modified\nmodel using Finetuning and GlitchProber for Mitigation\nDataset Original Model GlitchProber Finetuning\nGSM8K 0.315 0.301 0.238\nHumanEval pass@1 0.129 0.103 0.009\nHumanEval pass@5 0.190 0.161 0.024\nMMLU 0.453 0.417 0.229\n7.2 Rationale of GlitchProber versus\nExhaustive Search\nIn the context of exhaustive search mechanisms, LLMs are required\nto generate, on average,twenty tokens at a zero temperature setting\nfor every individual token processed. This computational method\nis both intensive and inefficient. Conversely, the implementation\nof GlitchProber necessitates merely a single forward processing\nstep to capture the intermediate features of the LLM for each token.\nThis approach substantially reduces 95% of redundant operations\nof those required by the traditional exhaustive search method.\n7.3 Glitch Token Mitigation By Fine-tuning\nGlitchProber adaptively modifies the process of model calcula-\ntion without altering the model parameters, thereby minimizing the\nmitigation impact on model performance and preserving the basic\nabilities of LLMs. In contrast, we also construct a dataset with Q&A\nfor the repetition task and attempt to mitigate the glitch token phe-\nnomenon by fine-tuning LLMs. However, compared with Glitch-\nProber, fine-tuning LLMs alters the parameters of the model, po-\ntentially compromising its basic abilities. For example, we fine-tune\nthe Llama-2-7b-chat with a dataset containing 3,000 Q&A pairs of\nrepetition tasks. To evaluate the modelâ€™s basic skills, we use three\nwidely accepted datasets namely GSM8K [8], HumanEval [6], and\nMMLU [17].\nDetailed results presented in Table 8 indicate that the modelâ€™s\nability in code writing and solving math problems post Glitch-\nProber is comparable with the original model. and significantly\nbetter compared to the fine-tuned model, which notably diminished\nthe basic abilities of original model.\n7.4 Threats to Validity\nInternal. Our primary concern involves the selection and compu-\ntation of hyperparameters in both the detection and fixing phases\nof GlitchProber. For the detection phase, we detail the rationale\nbehind our choices through an experiment described in Section 7.1.\nVarious feature types and hyperparameters for the SVM consis-\ntently outperform the established baselines. In the fixing phase, the\nlinear computation of ğ›¼ and ğ›½ proves untenable. Enhanced discus-\nsion and manipulation of the activation value are recommended as\nfuture research directions.\nExternal. Threats are associated with our experimental framework.\nFor the performance of glitch tokens in intermediate layers, we\nexperiment on three LLMs with different parameters and vocab-\nulary sizes. Based on these findings, GlitchProber experiment\non five different LLMs, showing its generalizability. Furthermore,\nas GlitchProber is required to access the intermediate data of\nthe LLM, GlitchProber is only applicable to open-source LLMs.\nThe transferability of GlitchProber from open-source LLMs to\nclosed-source LLMs like GPT-4 could further be explored.\n8 CONCLUSION\nIn this work, we reveal that glitch tokens trigger abnormal acti-\nvation characteristics in the modelâ€™s attention patterns and MLP\nstatus through systematic empirical study. Inspired by this, we pro-\npose methods for detecting and fixing glitch tokens.GlitchProber\nemploys a sampling strategy, extracting features from attention\npatterns and MLP status, and achieves rapid screening of the vocabu-\nlary through PCA dimensionality reduction and SVM classification.\nExperiments on LLMs demonstrate that GlitchProber saves 40%\nof the time compared to existing methods while achieving higher\naccuracy. Another important contribution is our strategy to fix\nglitch tokens by adjusting the activation values of the modelâ€™s in-\ntermediate layers. Experiments on LLMs confirm the effectiveness\nof this fix strategy, and the average repair rate of GlitchProber\nwas improved by 13.27% compared with the baseline method.\nACKNOWLEDGEMENT\nThis work was supported by the National NSF of China (grants\nNo.62302176, No.62072046, 62302181), the Key R&D Program of\nHubei Province (2023BAB017, 2023BAB079), and the Knowledge\nInnovation Program of Wuhan-Basic Research (2022010801010083).\nREFERENCES\n[1] HervÃ© Abdi and Lynne J Williams. 2010. Principal component analysis. Wiley\ninterdisciplinary reviews: computational statistics 2, 4 (2010), 433â€“459.\n[2] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-\ncia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal\nASE â€™24, October 27-November 1, 2024, Sacramento, CA, USAZhibo Zhang, Wuxia Bai, Yuxi Li, Mark Huasong Meng, Kailong Wang, Ling Shi, Li Li, Jun Wang, and Haoyu Wang\nAnadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774\n(2023).\n[3] 01. AI, :, Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei\nZhang, Heng Li, Jiangcheng Zhu, Jianqun Chen, Jing Chang, Kaidong Yu, Peng\nLiu, Qiang Liu, Shawn Yue, Senbin Yang, Shiming Yang, Tao Yu, Wen Xie, Wenhao\nHuang, Xiaohui Hu, Xiaoyi Ren, Xinyao Niu, Pengcheng Nie, Yuchi Xu, Yudong\nLiu, Yue Wang, Yuxuan Cai, Zhenyu Gu, Zhiyuan Liu, and Zonghong Dai. 2024.\nYi: Open Foundation Models by 01.AI. arXiv:2403.04652 [cs.CL]\n[4] Anthropic. 2024. The Claude 3 Model Family: Opus, Sonnet, Haiku. Online. https:\n//www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/\nModel_Card_Claude_3.pdf (Accessed: 2024-04-24).\n[5] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan,\nWenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji\nLin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men,\nXingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng\nWang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang,\nHao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng\nYuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang\nZhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023. Qwen Technical\nReport. arXiv:2309.16609 [cs.CL]\n[6] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de\nOliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg\nBrockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf,\nGirish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail\nPavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter,\nPhilippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fo-\ntios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex\nNichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shan-\ntanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh\nAchiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles\nBrundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei,\nSam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large\nLanguage Models Trained on Code. arXiv:2107.03374 [cs.LG]\n[7] Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song,\nAndreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin,\nLukasz Kaiser, et al. 2020. Rethinking attention with performers. arXiv preprint\narXiv:2009.14794 (2020).\n[8] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun,\nLukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,\nChristopher Hesse, and John Schulman. 2021. Training Verifiers to Solve Math\nWord Problems. arXiv preprint arXiv:2110.14168 (2021).\n[9] Corinna Cortes and Vladimir Vapnik. 1995. Support-vector networks. Machine\nlearning 20, 3 (1995), 273â€“297.\n[10] Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang, Zefeng Li, Haoyu\nWang, Tianwei Zhang, and Yang Liu. 2024. MasterKey: Automated Jailbreak\nAcross Multiple Large Language Model Chatbots. In NDSS.\n[11] Gelei Deng, Yi Liu, Kailong Wang, Yuekang Li, Tianwei Zhang, and Yang Liu.\n2024. Pandora: Jailbreak GPTs by Retrieval Augmented Generation Poisoning.\nNDSS AISCC (2024).\n[12] Martin Fell. 2023. A Search for More ChatGPT / GPT-3.5 / GPT-4\n\"Unspeakable\" Glitch Tokens. Online. https://www .lesswrong.com/\nposts/kmWrwtGE9B9hpbgRT/a-search-for-more-chatgpt-gpt-3-5-gpt-4-\nunspeakable-glitch (Accessed: 2024-05-05).\n[13] Jonas Geiping, Alex Stein, Manli Shu, Khalid Saifullah, Yuxin Wen, and Tom\nGoldstein. 2024. Coercing LLMs to do and reveal (almost) anything.arXiv preprint\narXiv:2402.14020 (2024).\n[14] Thomas Mesnard Gemma Team, Cassidy Hardin, Robert Dadashi, Surya Bhupati-\nraju, Laurent Sifre, Morgane RiviÃ¨re, Mihir Sanjay Kale, Juliette Love, Pouya Tafti,\nLÃ©onard Hussenot, and et al. 2024. Gemma. (2024). https://doi .org/10.34740/\nKAGGLE/M/3301\n[15] GlitchProber. (Accessed on 06/07/2024). https://sites .google.com/view/\nglitchprober/.\n[16] Hao Guan, Guangdong Bai, and Yepang Liu. 2024. Large Language Models Can\nConnect the Dots: Exploring Model Optimization Bugs with Domain Knowledge-\nAware Prompts. InProceedings of the 33rd ACM SIGSOFT International Symposium\non Software Testing and Analysis (Vienna, Austria) (ISSTA 2024). Association for\nComputing Machinery, New York, NY, USA, 1579â€“1591. https://doi .org/10.1145/\n3650212.3680383\n[17] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn\nSong, and Jacob Steinhardt. 2020. Measuring massive multitask language under-\nstanding. arXiv preprint arXiv:2009.03300 (2020).\n[18] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, De-\nvendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,\nGuillaume Lample, Lucile Saulnier, LÃ©lio Renard Lavaud, Marie-Anne Lachaux,\nPierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, TimothÃ©e Lacroix,\nand William El Sayed. 2023. Mistral 7B. arXiv:2310.06825 [cs.CL]\n[19] Haodong Li, Gelei Deng, Yi Liu, Kailong Wang, Yuekang Li, Tianwei Zhang,\nYang Liu, Guoai Xu, Guosheng Xu, and Haoyu Wang. 2024. Digger: Detecting\nCopyright Content Mis-usage in Large Language Model Training.\n[20] Ningke Li, Yuekang Li, Yi Liu, Ling Shi, Kailong Wang, and Haoyu Wang. 2024.\nDrowzee: Metamorphic Testing for Fact-conflicting Hallucination Detection in\nLarge Language Models. In OOPSLA (To Appear) .\n[21] Yuxi Li, Yi Liu, Gelei Deng, Ying Zhang, Wenjia Song, Ling Shi, Kailong Wang,\nYuekang Li, Yang Liu, and Haoyu Wang. 2024. Glitch Tokens in Large Language\nModels: Categorization Taxonomy and Effective Detection. In FSE.\n[22] Yuxi Li, Yi Liu, Yuekang Li, Ling Shi, Gelei Deng, Shengquan Chen, and Kailong\nWang. 2024. Lockpicking LLMs: A Logit-Based Jailbreak Using Token-level\nManipulation.\n[23] Hanxiao Liu, Zihang Dai, David R. So, and Quoc V. Le. 2021. Pay Attention to\nMLPs. arXiv:2105.08050 [cs.LG]\n[24] Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu,\nHaoyu Wang, Yan Zheng, and Yang Liu. 2023. Prompt Injection attack against\nLLM-integrated Applications. arXiv preprint arXiv:2306.05499 (2023).\n[25] Haoneng Luo, Shiliang Zhang, Ming Lei, and Lei Xie. 2020. Simplified self-\nattention for transformer-based end-to-end speech recognition. arXiv preprint\narXiv:2005.10463 (2020).\n[26] mwatkins. 2023. The petertodd phenomenon. Online. https://\nwww.lesswrong.com/posts/jkY6QdCfAXHJk3kea/the-petertodd-phenomenon\n(Accessed: 2024-05-05).\n[27] mwatkins. 2023. A Search for More ChatGPT/GPT-3.5/GPT-4 \"Un-\nspeakable\" Glitch Tokens. Online. https://www .lesswrong.com/\nposts/kmWrwtGE9B9hpbgRT/a-search-for-more-chatgpt-gpt-3-5-gpt-4-\nunspeakable-glitch (Accessed: 2024-05-03).\n[28] mwatkins and Jessica Rumbelow. 2023. SolidGoldMagikarp II: technical\ndetails and more recent findings. Online. https://www .lesswrong.com/posts/\nYa9LzwEbfaAMY8ABo/solidgoldmagikarp-ii-technical-details-and-more-\nrecent (Accessed: 2024-05-05).\n[29] mwatkins and Jessica Rumbelow. 2023. SolidGoldMagikarp III: Glitch token\narchaeology. Online. https://www .lesswrong.com/posts/8viQEp8KBg2QSW4Yc/\nsolidgoldmagikarp-iii-glitch-token-archaeology (Accessed: 2024-05-05).\n[30] Bloom J Nanda N. 2022. TransformerLens. Online. https://github.com/neelnanda-\nio/TransformerLens (Accessed: 2024-05-05).\n[31] Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy\nLillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat,\nJulian Schrittwieser, et al. 2024. Gemini 1.5: Unlocking multimodal understanding\nacross millions of tokens of context. arXiv preprint arXiv:2403.05530 (2024).\n[32] Jessica Rumbelow and mwatkins. 2023. SolidGoldMagikarp(plus, prompt gen-\neration). Online. https://www .lesswrong.com/posts/aPeJE8bSo6rAFoLqg/\nsolidgoldmagikarp-plus-prompt-generation (Accessed: 2024-05-05).\n[33] Bernhard Scholkopf and Alexander J. Smola. 2002. Learning with Kernels: Support\nVector Machines, Regularization, Optimization, and Beyond . MIT Press.\n[34] Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste\nAlayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth,\net al. 2023. Gemini: a family of highly capable multimodal models. arXiv preprint\narXiv:2312.11805 (2023).\n[35] Oguzhan Topsakal and Tahir Cetin Akinci. 2023. Creating large language model\napplications utilizing langchain: A primer on developing llm apps fast. InInterna-\ntional Conference on Applied Engineering and Natural Sciences , Vol. 1. 1050â€“1056.\n[36] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-\nmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucu-\nrull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia\nGao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini,\nRui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel\nKloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut\nLavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet,\nTodor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton,\nJeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva,\nEric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross\nTaylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov,\nYuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2:\nOpen Foundation and Fine-Tuned Chat Models. arXiv:2307.09288 [cs.CL]\n[37] Vladimir N. Vapnik. 1995. The Nature of Statistical Learning Theory . Springer-\nVerlag.\n[38] Leonid Nisonovich Vaserstein. 1969. Markov processes over denumerable prod-\nucts of spaces, describing large systems of automata. Problemy Peredachi Infor-\nmatsii 5, 3 (1969), 64â€“72.\n[39] Dixuan Wang, Yanda Li, Junyuan Jiang, Zepeng Ding, Guochao Jiang, Jiaqing\nLiang, and Deqing Yang. 2024. Tokenization Matters! Degrading Large Language\nModels through Challenging Their Tokenization. arXiv preprint arXiv:2405.17067\n(2024).\n[40] Guanyu Wang, Yuekang Li, Yi Liu, Gelei Deng, Tianlin Li, Guosheng Xu, Yang\nLiu, Haoyu Wang, and Kailong Wang. 2024. MeTMaP: Metamorphic Testing\nfor Detecting False Vector Matching Problems in LLM Augmented Generation.\nFORGE (2024).\nGlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models ASE â€™24, October 27-November 1, 2024, Sacramento, CA, USA\n[41] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang\nZhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. Autogen: Enabling\nnext-gen llm applications via multi-agent conversation framework.arXiv preprint\narXiv:2308.08155 (2023).",
  "topic": "Glitch",
  "concepts": [
    {
      "name": "Glitch",
      "score": 0.843990683555603
    },
    {
      "name": "Computer science",
      "score": 0.7504579424858093
    },
    {
      "name": "Language model",
      "score": 0.43612852692604065
    },
    {
      "name": "Natural language processing",
      "score": 0.30665701627731323
    },
    {
      "name": "Telecommunications",
      "score": 0.08365574479103088
    },
    {
      "name": "Detector",
      "score": 0.07726314663887024
    }
  ]
}