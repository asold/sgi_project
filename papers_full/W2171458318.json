{
  "title": "Stream-based randomised language models for SMT",
  "url": "https://openalex.org/W2171458318",
  "year": 2009,
  "authors": [
    {
      "id": "https://openalex.org/A2737548092",
      "name": "Abby Levenberg",
      "affiliations": [
        "University of Edinburgh"
      ]
    },
    {
      "id": "https://openalex.org/A2041005256",
      "name": "Miles Osborne",
      "affiliations": [
        "University of Edinburgh"
      ]
    },
    {
      "id": "https://openalex.org/A2737548092",
      "name": "Abby Levenberg",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2041005256",
      "name": "Miles Osborne",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2064710146",
    "https://openalex.org/W1965972569",
    "https://openalex.org/W2149592768",
    "https://openalex.org/W2109664771",
    "https://openalex.org/W162552777",
    "https://openalex.org/W2949708974",
    "https://openalex.org/W2146574666",
    "https://openalex.org/W2044062612",
    "https://openalex.org/W2169660454",
    "https://openalex.org/W1631260214",
    "https://openalex.org/W2140460368",
    "https://openalex.org/W191422183",
    "https://openalex.org/W2137387514",
    "https://openalex.org/W4285719527",
    "https://openalex.org/W2113788796",
    "https://openalex.org/W2155794909",
    "https://openalex.org/W2123845384",
    "https://openalex.org/W87260881",
    "https://openalex.org/W179986925",
    "https://openalex.org/W3146209407",
    "https://openalex.org/W1534448508",
    "https://openalex.org/W2069074882",
    "https://openalex.org/W1562125942",
    "https://openalex.org/W2020073413"
  ],
  "abstract": "Randomised techniques allow very big language models to be represented succinctly. However, being batch-based they are unsuitable for modelling an unbounded stream of language whilst maintaining a constant error rate. We present a novel randomised language model which uses an online perfect hash function to efficiently deal with unbounded text streams. Translation experiments over a text stream show that our online randomised model matches the performance of batch-based LMs without incurring the computational overhead associated with full retraining. This opens up the possibility of randomised language models which continuously adapt to the massive volumes of texts published on the Web each day.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8142072558403015
    },
    {
      "name": "Language model",
      "score": 0.7847230434417725
    },
    {
      "name": "Retraining",
      "score": 0.6071662306785583
    },
    {
      "name": "Hash function",
      "score": 0.5680437684059143
    },
    {
      "name": "Treebank",
      "score": 0.5563110709190369
    },
    {
      "name": "Data stream",
      "score": 0.5196486711502075
    },
    {
      "name": "Constant (computer programming)",
      "score": 0.46746304631233215
    },
    {
      "name": "Natural language processing",
      "score": 0.45794031023979187
    },
    {
      "name": "Artificial intelligence",
      "score": 0.44833898544311523
    },
    {
      "name": "Overhead (engineering)",
      "score": 0.4405689239501953
    },
    {
      "name": "Machine learning",
      "score": 0.3305208086967468
    },
    {
      "name": "Programming language",
      "score": 0.2640475034713745
    },
    {
      "name": "Parsing",
      "score": 0.0
    },
    {
      "name": "Business",
      "score": 0.0
    },
    {
      "name": "Telecommunications",
      "score": 0.0
    },
    {
      "name": "International trade",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98677209",
      "name": "University of Edinburgh",
      "country": "GB"
    }
  ],
  "cited_by": 39
}