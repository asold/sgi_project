{
  "title": "Large language models possess some ecological knowledge, but how much?",
  "url": "https://openalex.org/W4407374917",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5107490250",
      "name": "Filip Dorm",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2313040255",
      "name": "Joseph Millard",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3042276166",
      "name": "Drew Purves",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3175106713",
      "name": "Michael Harfoot",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2091223388",
      "name": "Oisin Mac Aodha",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2002682820",
    "https://openalex.org/W2147343628",
    "https://openalex.org/W4213373191",
    "https://openalex.org/W2981308999",
    "https://openalex.org/W4389519044",
    "https://openalex.org/W7035904466",
    "https://openalex.org/W4399914797",
    "https://openalex.org/W4402917115",
    "https://openalex.org/W4384525653",
    "https://openalex.org/W4392384758",
    "https://openalex.org/W6600476237",
    "https://openalex.org/W6630228690",
    "https://openalex.org/W4402673961",
    "https://openalex.org/W4393161455",
    "https://openalex.org/W4396977542",
    "https://openalex.org/W4392242161",
    "https://openalex.org/W4391971213",
    "https://openalex.org/W4406866255",
    "https://openalex.org/W4401043303",
    "https://openalex.org/W4399616593",
    "https://openalex.org/W4391250371",
    "https://openalex.org/W6824972886",
    "https://openalex.org/W3168603268",
    "https://openalex.org/W6602649177",
    "https://openalex.org/W6776639269",
    "https://openalex.org/W3138304695",
    "https://openalex.org/W2181523240",
    "https://openalex.org/W4401226787",
    "https://openalex.org/W4390189088"
  ],
  "abstract": "Abstract Large Language Models (LLMs) have shown remarkable capabilities in question answering across various domains, yet their effectiveness in ecological knowledge remains underexplored. Understanding their potential for ecological reasoning is crucial as AI tools become increasingly integrated into scientific workflows. Here, we assess the ecological knowledge of two LLMs, Gemini 1.5 Pro and GPT-4o , across a suite of ecologically focused tasks. These tasks evaluate an LLMâ€™s ability to predict species presence, generate range maps, list critically endangered species, classify threats, and estimate species traits. We introduce a new benchmark dataset to quantify LLM performance against expert-derived data. While the LLMs tested outperform naive baselines, achieving around 20 percentage points higher accuracy in species presence prediction, they reach only a third of the mean F1 score for range map generation and improve threat classification by just around 10 points over random guessing. These results highlight both the promise and challenges of applying LLMs in ecology. Our findings suggest that domain-specific fine-tuning is necessary to improve ecological reasoning in LLMs. By providing a repeatable evaluation framework, our benchmark dataset will facilitate future research in this area, helping to refine AI applications for ecological science.",
  "full_text": null,
  "topic": "Ecology",
  "concepts": [
    {
      "name": "Ecology",
      "score": 0.47170472145080566
    },
    {
      "name": "Computer science",
      "score": 0.4007195830345154
    },
    {
      "name": "Geography",
      "score": 0.3687181770801544
    },
    {
      "name": "Biology",
      "score": 0.1547623574733734
    }
  ],
  "institutions": []
}