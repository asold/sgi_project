{
  "title": "Exploring the Potential and Limitations of Chat Generative Pre-trained Transformer (ChatGPT) in Generating Board-Style Dermatology Questions: A Qualitative Analysis",
  "url": "https://openalex.org/W4385972264",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4382813500",
      "name": "Ibraheim Ayub",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2032076753",
      "name": "Dathan Hamann",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2120216008",
      "name": "Carsten R. Hamann",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2117394476",
      "name": "Matthew J Davis",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4322761615",
    "https://openalex.org/W4324130227",
    "https://openalex.org/W4364355594",
    "https://openalex.org/W4376637205",
    "https://openalex.org/W4380360936",
    "https://openalex.org/W4385231080",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4293387146",
    "https://openalex.org/W4306181877",
    "https://openalex.org/W4211255935",
    "https://openalex.org/W4210985581",
    "https://openalex.org/W4310481530",
    "https://openalex.org/W4310553624",
    "https://openalex.org/W4304127942",
    "https://openalex.org/W4304127900"
  ],
  "abstract": null,
  "full_text": "Review began\n 08/11/2023 \nReview ended\n 08/16/2023 \nPublished\n 08/18/2023\n© Copyright \n2023\nAyub et al. This is an open access article\ndistributed under the terms of the Creative\nCommons Attribution License CC-BY 4.0.,\nwhich permits unrestricted use, distribution,\nand reproduction in any medium, provided\nthe original author and source are credited.\nExploring the Potential and Limitations of Chat\nGenerative Pre-trained Transformer (ChatGPT) in\nGenerating Board-Style Dermatology Questions:\nA Qualitative Analysis\nIbraheim Ayub \n \n, \nDathan Hamann \n \n, \nCarsten R. Hamann \n \n \n, \nMatthew J. Davis \n1.\n Dermatology, A.T. Still University School of Osteopathic Medicine, Mesa, USA \n2.\n Dermatology, Dermatology\nResidency, HonorHealth, Scottsdale, USA \n3.\n Dermatology, HonorHealth Dermatology Residency, Scottsdale, USA \n4.\nDermatology, Dartmouth-Hitchcock Medical Center, Lebanon, USA\nCorresponding author: \nIbraheim Ayub, \nibraheim052@gmail.com\nAbstract\nThis article investigates the limitations of Chat Generative Pre-trained Transformer (ChatGPT), a language\nmodel developed by OpenAI, as a study tool in dermatology. The study utilized ChatPDF, an application that\nintegrates PDF files with ChatGPT, to generate American Board of Dermatology Applied Exam (ABD-AE)-\nstyle questions from continuing medical education articles from the \nJournal of the American Board of\nDermatology\n. A qualitative analysis of the questions was conducted by two board-certified dermatologists,\nassessing accuracy, complexity, and clarity. Out of 40 questions generated, only 16 (40%) were deemed\naccurate and appropriate for ABD-AE study preparation. The remaining questions exhibited limitations,\nincluding low complexity, lack of clarity, and inaccuracies. The findings highlight the challenges faced by\nChatGPT in understanding the domain-specific knowledge required in dermatology. Moreover, the model's\ninability to comprehend the context and generate high-quality distractor options, as well as the absence of\nimage generation capabilities, further hinders its usefulness. The study emphasizes that while ChatGPT may\naid in generating simple questions, it cannot replace the expertise of dermatologists and medical educators\nin developing high-quality, board-style questions that effectively evaluate candidates' knowledge and\nreasoning abilities.\nCategories:\n Dermatology, Medical Education\nKeywords:\n multiple-choice questions, artificial intelligence in medicine, medical education, chatgpt, dermatology\nIntroduction\nChat Generative Pre-trained Transformer (ChatGPT) is a language model developed by OpenAI (San\nFrancisco, CA, USA) that has shown promise in various natural language processing (NLP) tasks, including\nmedical education and multiple-choice question generation \n[1,2]\n. Within dermatology, ChatGPT has been\nshown to create case reports indistinguishable from those written by humans and assist in creating patient\nhandouts \n[3,4]\n. Beyond these applications, the model holds promise in streamlining routine administrative\nduties, facilitating patient education, enhancing medical instruction, and promoting improved healthcare\nliteracy among patients \n[5]\n. Furthermore, ChatGPT has been employed for taking licensing examinations\nand responding to specialty board review questions, demonstrating an average accuracy rate close to passing\nthresholds \n[6,7]\n. While promising, the use of ChatGPT in this context poses certain limitations and\nchallenges. These include the potential to generate erroneous data or incorrect answers, as well as the risk of\nintroducing biased content \n[5]\n. In this study, we explore the limitations of ChatGPT as a study tool in\ndermatology through a qualitative analysis of the ChatGPT-generated American Board of Dermatology\nApplied Exam (ABD-AE)- style questions.\nMaterials And Methods\nChatPDF is an application that combines the ability to upload entire PDF files into a ChatGPT 3.5 portal. The\ncontinuing medical education (CME) articles from the \nJournal of the American Academy of Dermatology\n (JAAD)\nare considered high-yield review material for the ABD-AE. CME articles from the JAAD (volume 88, issues 1-\n4) were imported into ChatPDF \n[8-15]\n. It was then asked to create five ABD-AE-style multiple-choice\nquestions. The resulting sets of questions from each article were subjected to an independent and rigorous\nanalysis by two board-certified dermatologists, ensuring a comprehensive evaluation of the questions'\nquality (Figures \n1\n-\n11\n). The evaluation encompassed three essential dimensions: accuracy, complexity, and\nclarity. Dermatologists individually assessed each question's appropriateness for the required depth of\nknowledge for the ABD-AE, and the clarity of its wording and structure. The evaluation process involved in-\ndepth discussions between the dermatologists to resolve any scoring discrepancies and to foster a\nconsensus-driven evaluation.\n1\n2\n3,\n4\n4\n \n Open Access Original\nArticle\n \nDOI:\n 10.7759/cureus.43717\nHow to cite this article\nAyub I, Hamann D, Hamann C R, et al. (August 18, 2023) Exploring the Potential and Limitations of Chat Generative Pre-trained Transformer\n(ChatGPT) in Generating Board-Style Dermatology Questions: A Qualitative Analysis. Cureus 15(8): e43717. \nDOI 10.7759/cureus.43717\nFIGURE\n 1: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 1-3).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n2\n of \n15\nFIGURE\n 2: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 4-8).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n3\n of \n15\nFIGURE\n 3: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 9-12).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n4\n of \n15\nFIGURE\n 4: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 13-16).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n5\n of \n15\nFIGURE\n 5: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 17-20).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n6\n of \n15\nFIGURE\n 6: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 21-24).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n7\n of \n15\nFIGURE\n 7: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 25-27).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n8\n of \n15\nFIGURE\n 8: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 28-30).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n9\n of \n15\nFIGURE\n 9: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 31-34).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n10\n of \n15\nFIGURE\n 10: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 35-38).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n11\n of \n15\nFIGURE\n 11: ChatPDF-generated multiple-choice questions in the style of\nthe American Board of Dermatology Applied Exam based on eight\ncontinuing medical education articles from the Journal of the American\nAcademy of Dermatology with author commentary (Questions 39-40).\nResults\nA total of 40 questions were created using ChatPDF for the eight CME articles. After an independent review\nof the questions, it was found that out of 40 questions, 10 (25%) were of low complexity, 9 (22.5%) were\nvague or unclear, and 5 (12.5%) were inaccurate (Figure \n12\n). Of the 40 questions, only 16 (40%) questions\ncreated using ChatGPT 3.5 were accurate and at an appropriate level of complexity for a trainee studying for\nABD-AE (Table \n1\n).\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n12\n of \n15\nFIGURE\n 12: Pie chart depicting the categorization of ChatPDF-generated\nmultiple-choice questions in the style of the American Board of\nDermatology Applied Exam based on eight continuing medical\neducation articles from the Journal of the American Academy of\nDermatology.\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n13\n of \n15\nArticle title\nLow\ncomplexity\nVague/unclear\nInaccurate\nAccurate/appropriate\nDysplastic nevus part I: historical perspective, classification, and\nepidemiology\n1\n2\n1\n1\nDysplastic nevus part II: dysplastic nevi: molecular/genetic profiles\nand management\n3\n0\n1\n1\nDisorders of hyperpigmentation. Part I. Pathogenesis and clinical\nfeatures of common pigmentary disorders\n1\n2\n2\n0\nDisorders of hyperpigmentation. Part II. Review of management and\ntreatment options for hyperpigmentation\n2\n1\n0\n2\nRisk of melanoma and nonmelanoma skin cancer with\nimmunosuppressants, part I: calcineurin inhibitors, thiopurines,\nIMDH inhibitors, mTOR inhibitors, and corticosteroids\n2\n1\n1\n1\nRisk of melanoma and nonmelanoma skin cancer with\nimmunosuppressants, part II: methotrexate, alkylating agents,\nbiologics, and small molecule inhibitors\n1\n1\n0\n3\nSkin disorders and interstitial lung disease: part I - screening,\ndiagnosis, and therapeutic principles\n0\n1\n0\n4\nSkin disorders and interstitial lung disease: part II -the spectrum of\ncutaneous diseases with lung disease association\n0\n1\n0\n4\nTotal, \nn\n (%)\n10 (25)\n9 (22.5)\n5 (12.5)\n16 (40)\nTABLE\n 1: Categorization of ChatPDF-generated multiple-choice questions in the style of the\nAmerican Board of Dermatology Applied Exam based on eight continuing medical education\narticles from the Journal of the American Academy of Dermatology.\nDiscussion\nChatGPT has limitations as an educational tool for ABD-AE study preparation, with <50% of the generated\nquestions found to be accurate and appropriate. The questions exhibited low complexity, as exemplified by\ninquiries like, \"Which of the following is a characteristic feature of melanoma? A. Uniform color B. Smooth\nborders C. Symmetry D. Irregular pigmentation; Answer: D.\" Moreover, there were issues with clarity, such\nas the question, \"A 45-year-old male with a history of psoriasis presents with shortness of breath and dry\ncough. Which of the following screening tests should be considered? A) Pulmonary function tests and high-\nresolution chest computed tomography B) Skin biopsy and blood tests C) Electrocardiogram and\nechocardiogram D) Urinalysis and liver function tests; Answer: A.\" Furthermore, 12.5% of generated\nquestions were incorrect or inaccurate, raising concerns about the reliability of artificial intelligence-\ngenerated questions. This study identified the limited domain-specific knowledge of ChatGPT as a major\nlimitation as dermatology requires a deep understanding of skin anatomy, physiology, and pathology, which\nChatGPT lacks. ChatGPT's inability to understand the context and generate high-quality distractor options,\nas well as its incapacity to generate images, further limits its usefulness. To address these limitations, future\nresearch should focus on developing domain-specific language models that possess deep knowledge of\ndermatology. By improving the model's understanding of skin-related concepts and its ability to generate\ncontextually appropriate questions and distractors, it may become a more reliable and valuable tool for\nmedical education and exam preparation in dermatology.\nConclusions\nOur study demonstrates that while ChatGPT shows promise as an educational tool in dermatology, its\nlimitations must be acknowledged. Generating ABD-AE-style questions with sufficient accuracy, complexity,\nand clarity remains a challenge for ChatGPT. The model's inability to understand context and lack of\ndomain-specific knowledge contribute to the generation of suboptimal questions. Future research efforts\naddressing these shortcomings might increase its utility in question generation for the ABD-AE. In\nconclusion, while ChatGPT may help generate simple questions, it cannot replace the expertise of\ndermatologists and medical educators in developing high-quality, board-style questions that accurately test\na candidate's knowledge and reasoning abilities.\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n14\n of \n15\nAdditional Information\nDisclosures\nHuman subjects:\n All authors have confirmed that this study did not involve human participants or tissue.\nAnimal subjects:\n All authors have confirmed that this study did not involve animal subjects or tissue.\nConflicts of interest:\n In compliance with the ICMJE uniform disclosure form, all authors declare the\nfollowing: \nPayment/services info:\n All authors have declared that no financial support was received from\nany organization for the submitted work. \nFinancial relationships:\n All authors have declared that they have\nno financial relationships at present or within the previous three years with any organizations that might\nhave an interest in the submitted work. \nOther relationships:\n All authors have declared that there are no\nother relationships or activities that could appear to have influenced the submitted work.\nAcknowledgements\nWe would like to acknowledge the use of Chat Generative Pre-trained Transformer (ChatGPT), a language\nmodel developed by OpenAI, in facilitating the generation of questions for this research study.\nReferences\n1\n. \nEysenbach G: \nThe role of ChatGPT, generative language models, and artificial intelligence in medical\neducation: a conversation with ChatGPT and a call for papers\n. JMIR Med Educ. 2023, 9:e46885.\n10.2196/46885\n2\n. \nLee H: \nThe rise of ChatGPT: exploring its potential in medical education\n. Anat Sci Educ. 2023,\n10.1002/ase.2270\n3\n. \nDunn C, Hunter J, Steffes W, et al.: \nArtificial intelligence-derived dermatology case reports are\nindistinguishable from those written by humans: A single-blinded observer study\n. J Am Acad Dermatol.\n2023, 89:388-90. \n10.1016/j.jaad.2023.04.005\n4\n. \nChandra A, Davis MJ, Hamann D, Hamann CR: \nUtility of allergen-specific patient-directed handouts\ngenerated by chat generative pretrained transformer\n. Dermatitis. 2023, 16:\n10.1089/derm.2023.0059\n5\n. \nJin JQ, Dobry AS: \nChatGPT for healthcare providers and patients: practical implications within dermatology\n.\nJ Am Acad Dermatol. 2023, \n10.1016/j.jaad.2023.05.081\n6\n. \nJoly-Chevrier M, Nguyen AX, Lesko-Krleza M, Lefrançois P: \nPerformance of ChatGPT on a practice\ndermatology board certification examination\n. J Cutan Med Surg. 2023, 12034754231188437.\n10.1177/12034754231188437\n7\n. \nKung TH, Cheatham M, Medenilla A, et al.: \nPerformance of ChatGPT on USMLE: potential for AI-assisted\nmedical education using large language models\n. PLOS Digit Health. 2023, 2:e0000198.\n10.1371/journal.pdig.0000198\n8\n. \nDrozdowski R, Spaccarelli N, Peters MS, Grant-Kels JM: \nDysplastic nevus part I: historical perspective,\nclassification, and epidemiology\n. J Am Acad Dermatol. 2023, 88:1-10. \n10.1016/j.jaad.2022.04.068\n9\n. \nSpaccarelli N, Drozdowski R, Peters MS, Grant-Kels JM: \nDysplastic nevus part II: dysplastic nevi:\nmolecular/genetic profiles and management\n. J Am Acad Dermatol. 2023, 88:13-20.\n10.1016/j.jaad.2022.05.071\n10\n. \nWang RF, Ko D, Friedman BJ, Lim HW, Mohammad TF: \nDisorders of hyperpigmentation. Part I.\nPathogenesis and clinical features of common pigmentary disorders\n. J Am Acad Dermatol. 2023, 88:271-88.\n10.1016/j.jaad.2022.01.051. Epub 2022 Feb 11\n11\n. \nKo D, Wang RF, Ozog D, Lim HW, Mohammad TF: \nDisorders of hyperpigmentation. Part II. Review of\nmanagement and treatment options for hyperpigmentation\n. J Am Acad Dermatol. 2023, 88:291-320.\n10.1016/j.jaad.2021.12.065\n12\n. \nKreher MA, Noland MM, Konda S, Longo MI, Valdes-Rodriguez R: \nRisk of melanoma and nonmelanoma skin\ncancer with immunosuppressants, part I: calcineurin inhibitors, thiopurines, IMDH inhibitors, mTOR\ninhibitors, and corticosteroids\n. J Am Acad Dermatol. 2023, 88:521-30. \n10.1016/j.jaad.2022.11.044\n13\n. \nKreher MA, Konda S, Noland MM, Longo MI, Valdes-Rodriguez R: \nRisk of melanoma and nonmelanoma skin\ncancer with immunosuppressants, part II: methotrexate, alkylating agents, biologics, and small molecule\ninhibitors\n. J Am Acad Dermatol. 2023, 88:534-42. \n10.1016/j.jaad.2022.11.043\n14\n. \nMotamedi M, Ferrara G, Yacyshyn E, et al.: \nSkin disorders and interstitial lung disease: part I-screening,\ndiagnosis, and therapeutic principles\n. J Am Acad Dermatol. 2023, 88:751-64. \n10.1016/j.jaad.2022.10.001\n15\n. \nOuchene L, Muntyanu A, Assayag D, et al.: \nSkin disorders and interstitial lung disease: part II-the spectrum\nof cutaneous diseases with lung disease association\n. J Am Acad Dermatol. 2023, 88:767-82.\n10.1016/j.jaad.2022.09.051\n2023 Ayub et al. Cureus 15(8): e43717. DOI 10.7759/cureus.43717\n15\n of \n15",
  "topic": "CLARITY",
  "concepts": [
    {
      "name": "CLARITY",
      "score": 0.8163716793060303
    },
    {
      "name": "Medicine",
      "score": 0.6395318508148193
    },
    {
      "name": "Generative grammar",
      "score": 0.5212422013282776
    },
    {
      "name": "Board certification",
      "score": 0.49571144580841064
    },
    {
      "name": "Context (archaeology)",
      "score": 0.46596482396125793
    },
    {
      "name": "Medical education",
      "score": 0.45917370915412903
    },
    {
      "name": "Certification",
      "score": 0.41193076968193054
    },
    {
      "name": "Continuing medical education",
      "score": 0.3656911551952362
    },
    {
      "name": "Computer science",
      "score": 0.2868412733078003
    },
    {
      "name": "Artificial intelligence",
      "score": 0.20131364464759827
    },
    {
      "name": "Continuing education",
      "score": 0.12591320276260376
    },
    {
      "name": "Management",
      "score": 0.07767879962921143
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ]
}