{
    "title": "Reconstructing particles in jets using set transformer and hypergraph prediction networks",
    "url": "https://openalex.org/W4383906959",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2599728111",
            "name": "Francesco Armando Di Bello",
            "affiliations": [
                "University of Genoa"
            ]
        },
        {
            "id": "https://openalex.org/A2889855395",
            "name": "Etienne Dreyer",
            "affiliations": [
                "Weizmann Institute of Science"
            ]
        },
        {
            "id": "https://openalex.org/A2936135458",
            "name": "Sanmay Ganguly",
            "affiliations": [
                "The University of Tokyo"
            ]
        },
        {
            "id": "https://openalex.org/A2233970608",
            "name": "Eilam Gross",
            "affiliations": [
                "Weizmann Institute of Science"
            ]
        },
        {
            "id": "https://openalex.org/A2259988140",
            "name": "Lukas Heinrich",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A4221300640",
            "name": "Anna Ivina",
            "affiliations": [
                "Weizmann Institute of Science"
            ]
        },
        {
            "id": "https://openalex.org/A2387651284",
            "name": "Marumi Kado",
            "affiliations": [
                "Max Planck Institute for Physics",
                "Sapienza University of Rome"
            ]
        },
        {
            "id": "https://openalex.org/A3104692089",
            "name": "Nilotpal Kakati",
            "affiliations": [
                "Weizmann Institute of Science"
            ]
        },
        {
            "id": "https://openalex.org/A2697256782",
            "name": "Lorenzo Santi",
            "affiliations": [
                "Sapienza University of Rome"
            ]
        },
        {
            "id": "https://openalex.org/A3091852435",
            "name": "Jonathan Shlomi",
            "affiliations": [
                "Weizmann Institute of Science"
            ]
        },
        {
            "id": "https://openalex.org/A4383947162",
            "name": "Matteo Tusoni",
            "affiliations": [
                "Sapienza University of Rome"
            ]
        },
        {
            "id": "https://openalex.org/A2599728111",
            "name": "Francesco Armando Di Bello",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2936135458",
            "name": "Sanmay Ganguly",
            "affiliations": [
                "The University of Tokyo"
            ]
        },
        {
            "id": "https://openalex.org/A2387651284",
            "name": "Marumi Kado",
            "affiliations": [
                "Max Planck Institute for Physics",
                "Sapienza University of Rome"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2624881227",
        "https://openalex.org/W3045164669",
        "https://openalex.org/W3005009137",
        "https://openalex.org/W3194181657",
        "https://openalex.org/W4293797811",
        "https://openalex.org/W3125889496",
        "https://openalex.org/W4320917101",
        "https://openalex.org/W6836545931",
        "https://openalex.org/W4385973564",
        "https://openalex.org/W1987435915",
        "https://openalex.org/W4308821586",
        "https://openalex.org/W4393725118",
        "https://openalex.org/W2916639378",
        "https://openalex.org/W6779809370",
        "https://openalex.org/W2222512263",
        "https://openalex.org/W3010834691",
        "https://openalex.org/W2100507804",
        "https://openalex.org/W3101073376",
        "https://openalex.org/W3087865810",
        "https://openalex.org/W3127669268",
        "https://openalex.org/W3157843951",
        "https://openalex.org/W3105412497"
    ],
    "abstract": "Abstract The task of reconstructing particles from low-level detector response data to predict the set of final state particles in collision events represents a set-to-set prediction task requiring the use of multiple features and their correlations in the input data. We deploy three separate set-to-set neural network architectures to reconstruct particles in events containing a single jet in a fully-simulated calorimeter. Performance is evaluated in terms of particle reconstruction quality, properties regression, and jet-level metrics. The results demonstrate that such a high-dimensional end-to-end approach succeeds in surpassing basic parametric approaches in disentangling individual neutral particles inside of jets and optimizing the use of complementary detector information. In particular, the performance comparison favors a novel architecture based on learning hypergraph structure, HGPflow , which benefits from a physically-interpretable approach to particle reconstruction.",
    "full_text": "Eur. Phys. J. C (2023) 83:596\nhttps://doi.org/10.1140/epjc/s10052-023-11677-7\nRegular Article - Experimental Physics\nReconstructing particles in jets using set transformer\nand hypergraph prediction networks\nFrancesco Armando Di Bello 1,a , Etienne Dreyer 2,b , Sanmay Ganguly 3, Eilam Gross 2, Lukas Heinrich 4,\nAnna Ivina 2, Marumi Kado 5,6, Nilotpal Kakati 2,c , Lorenzo Santi 6, Jonathan Shlomi 2, Matteo Tusoni 6\n1 INFN and University of Genova, Genoa, Italy\n2 Weizmann Institute of Science, Rehovot, Israel\n3 ICEPP, University of Tokyo, Tokyo, Japan\n4 Technical University of Munich, Munich, Germany\n5 Max Planck Institute for Physics, Munich, Germany\n6 INFN and Sapienza University of Rome, Rome, Italy\nReceived: 11 December 2022 / Accepted: 4 June 2023 / Published online: 11 July 2023\n© The Author(s) 2023\nAbstract The task of reconstructing particles from low-\nlevel detector response data to predict the set of ﬁnal state par-\nticles in collision events represents a set-to-set prediction task\nrequiring the use of multiple features and their correlations in\nthe input data. We deploy three separate set-to-set neural net-\nwork architectures to reconstruct particles in events contain-\ning a single jet in a fully-simulated calorimeter. Performance\nis evaluated in terms of particle reconstruction quality, prop-\nerties regression, and jet-level metrics. The results demon-\nstrate that such a high-dimensional end-to-end approach suc-\nceeds in surpassing basic parametric approaches in disen-\ntangling individual neutral particles inside of jets and opti-\nmizing the use of complementary detector information. In\nparticular, the performance comparison favors a novel archi-\ntecture based on learning hypergraph structure, HGPﬂow,\nwhich beneﬁts from a physically-interpretable approach to\nparticle reconstruction.\n1 Introduction\nTesting theories in high energy physics rely on the ability\nto reconstruct high energy particle collision events using\ninformation recorded by particle detectors. General-purpose\ndetectors enable this primarily through two sources of infor-\nmation: charged particle trajectories (tracks) measured in an\ninner tracking region and energy deposited by particle show-\ners in a surrounding array of calorimeter cells.\na e-mail: francescoarmando.dibello@unige.it\nb e-mail: etienne.dreyer@weizmann.ac.il\nc e-mail: nilotpal.kakati@weizmann.ac.il (corresponding author)\nCurrently, experiments at the CERN Large Hadron Col-\nlider (LHC) employ parameterized “particle-ﬂow” algo-\nrithms, which combine track and calorimeter information in\na complementary way while avoiding double counting.\nThe performance of particle-ﬂow algorithms is limited to\nan extent by detector design speciﬁcations, such as the pre-\ncision and size of the inner tracking system, the magnetic\nﬁeld strength in the tracking volume, the granularity of the\ncalorimeters, and their energy resolution. However, a num-\nber of intrinsic factors complicate the task of particle recon-\nstruction in the LHC environment: the busy and often colli-\nmated signatures resulting from proton collisions, the pres-\nence of multiple simultaneous scattering events (pileup), and\nﬁnally, the extensive and irregular array of sensitive elements\nrequired for granularity and angular coverage.\nThere are two main approaches to particle-ﬂow algo-\nrithms. The approach used by the ATLAS collaboration [ 1]\ninvolves subtracting the expected shower proﬁle for each\ntrack in an event from the calorimeter deposits to infer the\nenergy contributed by nearby neutral particles. The CMS col-\nlaboration, on the other hand, employs aglobal particle-ﬂow\nalgorithm where ﬁnal state particles of different types are\nreconstructed simultaneously [2]. Global particle-ﬂow algo-\nrithms allow a high physics analysis ﬂexibility and eliminate\nthe need for overlap-removal algorithms while better exploit-\ning the strengths of each sub-detector system.\nIn this paper, we approach the global particle-ﬂow\nparadigm using machine learning (ML) models operating\non graph data. As in other applications to particle physics,\nML brings the advantage of replacing parameterized cuts (for\nexample, in energy subtraction schemes) with fully differen-\n123\n596 Page 2 of 18 Eur. Phys. J. C (2023) 83 :596\ntiable decision boundaries in the full space of relevant fea-\ntures in data. The expressiveness of ML models also opens\nnew possibilities, such as reconstructing individual neutral\nparticles inside of jets. Similarly, the choice to represent input\ndata as graphs is motivated by several advantages: graphs\nmore naturally capture the spatial correlations encoded in\nirregular detector geometry and also are well-suited for the\nsparsity and variable cardinality of the input set. Graph neural\nnetworks (GNN) have therefore emerged as an architecture\nof choice in recent particle reconstruction models, as they\nhave in other particle physics tasks [3].\nIn a collision event, the true set of particlesT upstream to\nthe detector sensitive volume gives rise to a set of detector-\nlevel hits D. So the input set comprising the detector record\nis sampled from p(D|T ). Then global particle-ﬂow recon-\nstruction is the set-to-set task where the input set of detector-\nlevel hits D is transformed into a typically much smaller\noutput set R comprising N\nR predicted particles. The pre-\ndictions of a successful reconstruction algorithm R(D) will\ncorrectly model the cardinality NT of T and the properties\n(class, momentum, and angular coordinates) of its members.\nSeveral ML approaches have been proposed in the literature\nto predict R(D).\nIn [4] the object condensation (OC) approach was pro-\nposed, which clusters nodes or pixels in latent space to\nform candidate objects, in our case, particles. Recently, OC\nhas been used to predict clusters in CMS data [ 5,6], where\nthe authors focused on reconstruction efﬁciency and energy\nregression of showers from single particles embedded in\npileup. We implement OC with modiﬁcations as explained\nin Sect. 3.4 for the purpose of establishing a performance\nbaseline for an ML-based particle reconstruction.\nThe reduction in size from input to output set is handled in\nt h eM L P F[7] approach by assigning input nodes to particle\nclasses in the output set or else to a dedicated “neglect class”.\nThis approach was also recently successfully tested using\nCMS data [ 8,9], where the model predictions were trained\nto match the output candidates from a standard particle-ﬂow\nalgorithm. For predicting true particles, MLPF is limited to\ncases where one or more clusters can be associated to each\nparticle. It would therefore be required to deﬁne a fractional\ntarget deﬁnition in order to efﬁciently reconstruct particles\nthat do not contribute a dominant fraction of energy in any\nsingle cluster (for example, a signiﬁcant percentage of low-\np\nT photons).\nIn this paper, we contribute to the exploration of GNN-\nbased particle reconstruction by proposing two new algo-\nrithms and comparing their performance alongside a modi-\nﬁed OC implementation as a baseline and a parameterized\nparticle ﬂow algorithm. Rather than full proton-proton col-\nlision events, we focus on events comprising a single jet,\nwhich represent the typical domain over which inter-particle\ncorrelations are expected to play a signiﬁcant role in recon-\nstruction. Our dataset incorporates full Geant4 [10] treat-\nment of particle showers in a nearly-hermetic calorimeter\nsimulation [11]. An example of a simulated single jet event\nis shown in Fig. 1. In the true particle-ﬂow paradigm, our\napproach is built around the idea of combining low-level\nfeatures from calorimeter showers with the complementary\ninformation provided by tracks.\nWe ﬁnd that a novel application of recurrent hypergraph\nlearning leads to the most accurate results and preserves a\nhigh degree of interpretability. This is achieved thanks to\na physics-inspired approach which allows the network to\nexploit the relationships between properties of the target par-\nticles and their energy deposits in the detector.\n2 Dataset\n2.1 Detector simulation\nUnlike the full detector models used to simulate experiments\nat the LHC, publicly-available codes such asDelphes [12]d o\nnot model particle interactions with sufﬁcient complexity to\nenable training a network with the full calorimeter signature\navailable at real detectors. This motivated the development of\nthe Conﬁgurable Calorimeter simulatiOn for AI (COCOA)\npackage [11], which we used to generate the datasets in this\npaper.\nThe geometric coverage of the COCOA calorimeter is split\ninto a barrel (0.0 < |η| < 1.5) and two identical endcaps\n(1.5 < |η| < 3.0) regions. The endcap region is situated in\na hermetic way such that there is no void in the transition\nregion. In depth, the calorimeter has a total of six concentric\nlayers: the ﬁrst three layers comprising an electromagnetic\ncalorimeter (ECAL) and the next three a hadronic calorimeter\n(HCAL). The calorimeters have uniform segmentation in η\nand φ enabling high spatial resolution, as listed in Table 1.\nThe geometric depth of the cells is modulated as 1 / cosh η\nin order to achieve a constant effective interaction depth with\nincreasing η.\nThe inner region of COCOA is immersed in a uniform\naxial magnetic ﬁeld of 3.8T that extends until a radius of\n150 cm, where four 1 .1 cm layers of iron immediately pre-\ncede the ECAL. The ECAL is modeled as a homogeneous\ncalorimeter by mixing lead and liquid argon, correspond-\ning to ATLAS calorimeter materials, in volume proportion\n1.2:4.6 leading to a radiation length ofX\n0 = 2.5c m .F o rt h e\nHCAL, iron is used as the absorber material, and polyvinyl\ntoluene plastic material as the scintillating active material.\nThese are mixed with a volume proportion 1.1:1.0, yielding\na nuclear interaction length of λ\nint = 26.6c m .T h es i m u -\nlated energy deposits in each layer are smeared to reproduce\nthe expected sampling energy resolution. For our dataset, the\nhadronic sampling term is 10%. The effect of pileup and elec-\n123\nEur. Phys. J. C (2023) 83 :596 Page 3 of 18 596\nFig. 1 A depiction of a single-jet event from the test dataset in both\nthe COCOA calorimeter layers (left) and as an input graph in η−φ\nspace (right). On the left, the actual geometry of the calorimeter cells\nis shown, while on the right, they are represented by spheres with sizes\nproportional to their energy divided by noise threshold (up to a maxi-\nmum value). Lines represent tracks and their projected locations in η\nand φ in each calorimeter layer. Connections between calorimeter cells\nare the edges formed during graph construction (inter-layer edges and\ntrack-cell edges are not shown). The markers at the bottom right indicate\nthe η−φ coordinates of the truth particles\nTable 1 Characteristics of the six calorimeter layers: depths in radia-\ntion length (X\n0) and nuclear interaction length (λint ), granularity, and\nstandard deviations of the simulated noise distributions\nLayer Depth Granularity ( η × φ) Noise [MeV]\nECAL1 4 X0 256 × 256 13\nECAL2 16 X0 256 × 256 34\nECAL3 2 X0 128 × 128 41\nHCAL1 1 .5λint 64 × 64 75\nHCAL2 4 .1λint 64 × 64 50\nHCAL3 1 .8λint 32 × 32 25\ntronic noise is mimicked using normal distributions centered\nat zero with widths varying according to the layer. The choice\nof material and smearing parameters is tuned to reproduce\nthe ATLAS calorimeter system’s single-particle response.\nThe effect of tracking is emulated by smearing truth\ncharged particles with a resolution\nσ( p)\np = a × p with\na = 10−5/GeV . The smearing of the track direction is\nneglected as it is expected to have a subdominant effect in\nour problem of interest.\nCharged particles produced from hadrons decaying-in-\nﬂight above a transverse radius R > 75 mm (250 mm) in\nthe barrel (endcap) have no tracks associated to them. To\nfocus on the reconstruction of particles as they appear at the\ncalorimeter, the dataset simulates photon conversions only\nat the stage of the iron layer prior to the calorimeters, while\nmaterial interactions within the tracker are emulated solely\nby the track q/p smearing.\n2.2 Dataset generation\nEvent generation, followed by parton shower and hadroniza-\ntion is performed with Pythia8 [13] with a single initial\nstate quark or gluon particle. The parton initial energy is\nsampled in the range 10–200 GeV , and angular coordinates\nare distributed uniformly in the range η ∈[ −2.5,2.5], φ ∈\n[−π,π ]. Final state particles are interfaced with Geant4 to\nsimulate their interaction with material, both showering in the\ncalorimeter and scattering and e.g. photon conversions in the\niron layer preceding it. Additional pileup collisions were not\nsimulated. The targets of the machine learning algorithms are\nﬁnal state stable particles with transverse momentum above\n1 GeV , which reach the calorimeter.\nIn each event, a standard clustering algorithm is used to\ngroup calorimeter cells into “topoclusters” based on their\nproximity and deposited energy, following the algorithm\n123\n596 Page 4 of 18 Eur. Phys. J. C (2023) 83 :596\ndescribed in [14] with minor modiﬁcations. First, an energy\nover noise ratio of ( E\nσ )> 4.6i su s e dt oi d e n t i f yc l u s t e r\nseeds. For each seed, a two-stage search is performed in its\nvicinity to group neighboring cells with nonzero energy. The\nﬁrst search collects neighboring cells with an energy-to-noise\nthreshold ratio above 2, and the second search further extends\nthe clusters with cells that have energy above 0. Finally, the\nalgorithm applies a set of rules to merge topoclusters sharing\nseed cells and split topoclusters formed by particles in close\nproximity.\nA record is kept of contributing particles and their energy\ncontribution to each cell. Electronic noise is simulated in the\ncalorimeter cells at realistic levels and dominates a fraction of\nthe clustered cell. A small fraction of topoclusters, therefore,\nconsist purely of cells where noise was the dominant con-\ntributor. One or more such topoclusters are present in 23%\nof the training events.\nIn summary, the data used for ML comprise the following\nobject collections: cells which belong to a topocluster, all\ntracks that reached the calorimeter, and the set of particles\nwhich entered the calorimeter. An identical conﬁguration is\nused to generate the dataset of 50,000 events for training\nand the independent dataset of 30,000 events for testing. In\naddition, a “gluon jet” dataset containing 30,000 events is\ngenerated by replacing the single incident quark by a gluon\nwith the same initial energy and angular distributions. The\nquark and gluon jet datasets are provided in [15]. The results\nobtained with this gluon jet sample are discussed in Sect.4.5.\nFigure 2 summarizes the number of various entities stored in\nboth the single jet and gluon jet test datasets.\n2.3 Fiducial particle deﬁnitions for reconstruction targets\nIn a collision event, not all particles produced can be recon-\nstructed in the detector. When deﬁning target truth particles\nit is important to account only for those that can be detected,\ni.e. those that are within the detector acceptance and have\nsufﬁciently high transverse momentum to be reconstructed.\nBeyond these simple criteria, particles produced in the colli-\nsion can later decay or interact with the detector and convert,\nradiate or interact and produce other particles. The speciﬁc\ndeﬁnition of the particles that are targets for the reconstruc-\ntion algorithm, referred to as ﬁducial particles, is important to\nremove ambiguities during training and in assessing the per-\nformance of reconstruction. To qualify as ﬁducial particles,\ntruth stable particles must have the following properties:\n– p\nT >1G e V\n– be produced before the ﬁrst calorimeter layer\n– release a nonzero amount of energy in the calorimeter.\nAdditional consideration would be needed to achieve a\nmore realistic environment where bremsstrahlung, pair pro-\nFig. 2 Composition of the quark and gluon test samples in terms of\nthe cardinality of different sets of entities contained. The mean value in\neach case is written in parentheses while the range and quartiles of the\ndistributions over events are shown in the box plot\nduction, and the presence of soft particles in general might\nresult in highly collimated topologies, above the spatial\nreconstruction capabilities of the detector. In this work, the\nabsence of pileup and the absence of material in the inner\ntracking region justify the use of the three ﬁducial criteria\ndescribed above.\n2.4 Input graph\nWe build a ﬁxed heterogeneous graph out of each event\nby connecting calorimeter cells and tracks based on their\nproximity. Each cell is connected to the k nearest cells\nin the same calorimeter layer, where k = 8i nt h eE C A L\nand k = 6 in the HCAL. Additionally, each cell is con-\nnected to the single nearest cell in its immediately adjacent\nlayer(s). A cell in layer l can only receive incoming edges\nfrom other cells if they are separated in ΔR by less than\n{d\nc−c\nmax }l ={ 0.05,0.07,0.14,0.30,0.30,0.60} for the six\ncalorimeter layers. A set of indices and weights is assigned\nper cell listing the true particles which contributed and their\nrelative contribution to the total cell energy. An index of−1\nis given to energy contributions from noise.\nTracks are likewise connected to cells based on closest\nseparation in ΔR between the cell and the projected η−φ\ncoordinate of the track in the corresponding calorimeter layer.\nA track is connected to a maximum number ofk = 4 cells in\neach ECAL layer and k = 3 cells in each HCAL layer. For\ntrack-cell edges, a larger maximumΔR is allowed:{dt−c\nmax}l =\n123\nEur. Phys. J. C (2023) 83 :596 Page 5 of 18 596\nFig. 3 Comparison of the different ways in which the three ML reconstruction algorithms map the input set of nodes in the form of a graph to the\noutput set of predicted particles, to be compared with the set of truth particles. Colors indicate distinct particles and the nodes for which they are\nthe dominant contributor\n{0.15,0.15,0.40,1.10,1.10,2.00}. A depiction of the graph\nconnectivity for tracks and cells is shown in Fig. 1.\nTopoclusters are represented in the input graph by a sep-\narate set of nodes with edges connecting each to the set of\ncells belonging to the topocluster. The angular coordinates\nof a topocluster are taken at its energy barycenter.\n3 Particle reconstruction algorithms\n3.1 Parameterized particle-ﬂow algorithm\nTo compare the performance of the ML algorithms, we imple-\nmented a traditional parameterised particle-ﬂow algorithm\n[1], which we refer to as PPﬂow. The algorithm aims at\nsubtracting the energy deposited in the calorimeter from\ncharged particles associated to tracks. To this end, shower\ntemplates are derived from single π\n+ samples and param-\neterized as a function of the track pT and the layer where\nthe ﬁrst nuclear interaction takes place. The energy sub-\ntraction is performed in concentric rings of radius equal to\na single cell pitch built from the extrapolated track posi-\ntion in each calorimeter layer. The ring’s energy is progres-\nsively subtracted from the topoclusters until the expected\ntotal energy determined in the singleπ\n+ template is reached.\nThe remaining energy in the topoclusters after this subtrac-\ntion is considered as originating from neutral particles. The\nPPﬂow algorithm does not aim at reconstructing the sin-\ngle particles composing the jets, but rather it is designed\nto estimate the overall neutral energy component for each\ntopocluster.\n3.2 Common description for the ML algorithms\nWe investigate three ML-based particle reconstruction mod-\nels for the set-to-set prediction R(D): object condensation\n(OC) as an existing ML baseline, transformer set prediction\nnetwork with slot attention (TSPN-SA), and a hypergraph\narchitecture (HGPﬂow). Descriptions of each algorithm is\ngiven in Sects. 3.4, 3.5, and 3.6. Section 4 compares their\nrelative particle-level performance and a comparison to the\nPPﬂow baseline for jet reconstruction.\nThere are commonalities to all three algorithms. Predicted\nparticles in each case are inferred from the node features (skip\nconnections) concatenated with a node representation vector\nfrom a common encoder network, discussed in Sect. 3.3.\nTracks are treated similarly in each case: the charged particle\ncardinality in an event is set by the number of tracks, and\nthe charged particles’ η and φ are determined directly from\nthe tracks without regression. While the OC algorithm takes\ncalorimeter cells as input nodes, the other two algorithms\nuse topoclusters instead, to reduce the dimensionality of the\ninput. Figure 3 illustrates the core differences between the\n123\n596 Page 6 of 18 Eur. Phys. J. C (2023) 83 :596\nways each algorithm maps the set of detector-level nodes D\nto the set of predicted particles R.\nThe choice to use calorimeter cells compared to using the\ncoarser topoclusters can be compared in terms of an injec-\ntive condition : the degree to which the energy deposit in a\nnode can be mapped back to a single parent particle. In the\ncase of cells, although contributions from more than one par-\nent particle are present in general, the injective condition is\nmore valid than in the case of topoclusters. Since the injec-\ntive condition is an assumption of the OC algorithm (i.e. in\nthe deﬁnition of the entries of I\nki in Eq. 1), this motivates the\nchoice of cells as input nodes.\nHaving contributions to a node from more than one\nparent particle can be learned in the TSPN-SA architec-\nture in an unsupervised way via node-particle attention.\nThe HGPﬂow architecture, on the other hand, is fully\nequipped to disentangle multiple-particle contributions to a\nnode thanks to supervised learning of the incidence matrix,\ndiscussed in Sect. 3.6. In both cases, computing gradi-\nents for predictions on edges becomes signiﬁcantly more\nexpensive for cell-level inputs compared to topocluster-level\ninputs, which was the main motivation for choosing the\nlatter.\nThe loss associated with predicted particle properties is\ncomputed similarly in each algorithm. Particle class is trained\nusing a categorical cross-entropy term between the predicted\nand the target class. A mean squared error loss term is used to\nregress continuous properties η\ni and pT,i .T h eφ prediction\nis trained using 1 − cos(φpred − φtarg).\nThe total number of trainable parameters in the neural\nnetwork blocks of the OC, TSPN-SA, and HGPﬂow algo-\nrithms is compared in Table 2 including the node encoding\nnetwork in each. An estimate of their computational per-\nformance is also shown. For each of the three algorithms,\nhyperparameter optimization scans have not been performed,\nexcept on the threshold cuts used during inference for OC\nand HGPﬂow. The code for the algorithms is provided in\n[16].\n3.3 Graph nodes encoding\nEach event is represented as a heterogeneous graph com-\nprising track, cell, and topocluster nodes connected by edges\nas deﬁned in Sect. 2.4. The embedding model described in\nthe following is shared among the different network archi-\ntectures. Figure 4 illustrates the network components of the\nencoding model: input feature vectors associated with track\nand cell nodes are passed through separate networks to embed\nthem in a common representation space of dimension 100.\nThe cell features input to the embedding are (energy, posi-\ntion, φ, η, layer). Similarly, the track input features are the\nTable 2 Comparison of the three particle reconstruction algorithms\nin terms of model size and computational resources. The number of\ntrainable parameters belonging to the node encoding model is shown\nalongside the total. The time per event is averaged over 100 single jet\nevents evaluated sequentially, and the memory is estimated as the peak\nmemory over the same. Results are obtained on the same GPU (NVIDIA\nTITAN RTX)\nAlgorithm # Parameters Speed* Memory\nTotal (Node enc.) [ms/event] [MiB/event]\nOC 1.8M (0.2M) 249 1480\nTSPN-SA 1.5M (0.2M) 465 1448\nHGPﬂow 1.8M (0.2M) 257 1394\n*Algorithms not optimized for execution time\ntrack parameters (q/p, θ, φ, d0, z0)1 and the extrapolatedη–\nφ coordinates of the track at each calorimeter layer. The latter\nare important features because a charged particle after exiting\nthe magnetic ﬁeld travels in a straight line which no longer\npoints back to the origin (assuming no material interactions).\nIn addition to their hidden representation, these nodes are also\ngiven an additional binary feature which ﬂags whether they\noriginate from cells or tracks.\nThe node encodings are then updated to incorporate the\ngraph relational structure via 4 successive blocks of message\npassing along edges. In each block, a dedicated network is\nused with the following three inputs concatenated: current\nnode representation, sum of representations from neighbor-\ning nodes, and a graph-level global representation (the mean\nof all current node representations). Following the message\npassing blocks, topocluster representations are computed by\nthe energy-weighted mean of the cell representation vectors\nbelonging to the topocluster.\n3.4 Modiﬁed object condensation (OC)\nThe OC algorithm was proposed in [4] for tasks of segment-\ning a set of input nodes into a set of target objects and predic-\ntion of their properties, which it does simultaneously. In the\nparticle reconstruction case, the input set comprises tracks\nand calorimeter cells and the output set of objects are the\nprogenitor particles (“parents”) with their classes and prop-\nerties. The set-to-set procedure for OC is shown in the top\nrow of Fig. 3. Our implementation follows the original OC\napproach with some modiﬁcations which are stated in the\nfollowing description.\nThe OC algorithm is based on clustering nodes accord-\ning to their parents in a learned few-dimensional space x.\nThe clustering is supervised by adding to the loss poten-\ntials deﬁned on this space: a repulsive potential ˆV (x) ∝\n1 The track impact parametersd0 and z0 measure the distance of closest\napproach of the track to the beam line in the transverse and longitudinal\ndirections, respectively.\n123\nEur. Phys. J. C (2023) 83 :596 Page 7 of 18 596\nFig. 4 The encoding model used to derive a learned node representation\nmax(2 − Δx,0) between nodes that belong to different par-\nent particles, and an attractive one ˘V (x) ∝ Δx2 for nodes\nhaving a common parent. The goal is that after training the\nresulting clusters of nodes will correspond to the set of parent\nparticles.\nHowever, calculating the sum of N 2 pairwise potential\nterms during training becomes expensive for problems of\neven moderate N . This is addressed by designating a sin-\ngle representative node for each parent particle, called a\ncondensation point , to impose the potentials on all other\nnodes during training. A separate network is trained to pre-\ndict a score, β ∈[ 0,1], with a target value of 1 for con-\ndensation points and 0 otherwise. An increasing function\nq(β) = arctanh\n2β + qmin (with qmin a hyperparameter) is\nused in analogy to charge in the loss term responsible for the\nclustering potentials:\nL\nV = 1\nN\nN∑\ni=1\nq(βi )\nK∑\nk=1\n[\nIki ˘Vc,k (xi ) + (1 − Iki ) ˆVc,k (xi )\n]\n(1)\nwhere Iki is an N × K matrix determining whether particle\nk is the parent of node i. The matrix will be revisited in\nSect. 3.6.\nFor each node i, which is a cell, the properties loss is of\nthe same form as discussed in Sect.3.2, where target class is\neither photon, neutral hadron or charged particle. Similar to\nLV above, the particle property loss is also weighted byq(β)\nsuch that nodes with the highest β receive the most supervi-\nsion during training. These nodes are ultimately selected for\nthe output set during inference by requiring their predicted\nβ> t\nβ and that they be separated in the clustering space by\nΔx > td , wheretβ and td are two threshold hyperparameters.\nCompared to the original OC model, our implementation\nhas two modiﬁcations connected to the condensation score\nβ. The condensation points deﬁned during training do not\nhave a physical meaning and are learned in an unsupervised\nway. In our approach, we instead use the following physics-\noriented deﬁnition:\nCP\nT\nk =\n{\ntrack ∈ k, if k is charged particle\nargmaxz(cells ∈ k), if k is neutral particle (2)\nwhere z is the energy over noise threshold ratio for each cell.\nThis deﬁnition removes the need to identify a representa-\ntive node for charged particles, assuming a 1–1 mapping to\ntracks in the event. For neutral particles, on the other hand,\nthe β prediction is fully supervised and can be interpreted as\nthe likelihood that a cell has maximal z in a given shower.\nSince this cell also serves as an approximate location of the\nshower center, theη and φ for neutral particles are regressed\nvia a learned offset to the cellη–φ coordinates. During infer-\nence, condensation points passing the t\nb and td thresholds\nare further required to be classiﬁed as either photon or neu-\ntral hadron, whereas cells classiﬁed as charged particles are\ndiscarded (since this role is fulﬁlled by tracks).\nA second modiﬁcation compared to the original OC\napproach is that instead of a ∼ (1 − β) regression-type loss\ncomputed on condensation points only, we train theβ predic-\ntion using a binary cross-entropy loss evaluated for all nodes.\nThe reasoning behind a classiﬁcation-type loss is to directly\npenalize the network for predicting large β for nodes which\nare not condensation points, i.e. false positives. In an abla-\ntion study, each modiﬁcation was seen to bring substantial\nimprovement at essentially no additional model complexity.\nBesides the two modiﬁcations above, our OC implemen-\ntation differs from that of [ 6] in a few regards. Firstly, they\npropose an upgrade to the original OC algorithm where par-\nticles are represented in the clustering space not only by a\nsingular condensation point but by the β-weighted average\nover a learned distance scale. The authors of [ 6] report that\nthese and other modiﬁcations lead to improved training sta-\nbility and reduced noise, so we recognize the potential for\nimproving our implementation as well. Finally, we point out\nthat our model has signiﬁcantly more parameters (Table 2),\nwith GravNet blocks [ 17] replaced by the node encoding\nmodel described in Sect. 3.3. Our choice of network block\nsizes has not been optimized for computational efﬁciency\nand allocates a large proportion of its parameters to the node\nprediction networks compared to the message-passing net-\nworks.\n123\n596 Page 8 of 18 Eur. Phys. J. C (2023) 83 :596\nFig. 5 The TSPN-SA architecture. The cardinality of the set of output particles is predicted from the global representation, while their properties\nare predicted from representation vectors resulting from successive slot attention blocks\n3.5 Transformer set prediction network with slot attention\n(TSPN-SA)\nThe Transformer Set Prediction Network (TSPN) was ini-\ntially developed for the permutation-invariant encoding and\ndecoding of variable-size sets of feature vectors [ 18]. The\nutility of this for set-to-set problems in particle physics is\nclear: a model is needed that predicts an output set of enti-\nties (i.e. particles) based on an input set of different entities\n(i.e. calorimeter clusters, tracks), where both sets typically\nhave different cardinality. The model is divided into two net-\nworks: the ﬁrst for predicting neutral particles and the second\nfor predicting charged particles (discussed later).\nAs shown in the top part of Fig. 5, the ﬁrst architecture\nstarts with a set encoder network whose output is used to pre-\ndict the number of neutral particles, N\npred This prediction is\ntrained using a categorical cross-entropy loss over 25 classes,\nwhich is an upper bound on the number of neutral particles\nper event. The cardinality prediction is used during test time.\nDuring training, the truth cardinality is enumerated to form\na set of numbers that are passed through embedding layers\nto instantiate the initial set of random vectors. These vec-\ntors combined with the global representation vector function\nas queries for a series of 3 slot-attention (SA) blocks [ 19].\nThe SA blocks are not part of the original TSPN proposal\nbut were found to be fundamental for performance in our\napplication (abbreviated TSPN-SA). Each block contains 3\niterations where the particle hidden representation is updated\nusing the attention-weighted representations of the topoclus-\nters and tracks in the event. Finally, the updated hidden repre-\nsentations are inputs to two dedicated neural network blocks\naimed at predicting the kinematics (p\nT,η,φ) and the class\nof the particle candidates.\nThe neutral particle properties loss function for the TSPN-\nSA algorithm is deﬁned as the sum of a categorical cross-\nentropy term for class t\ni and a mean-squared error (MSE)\nterm for the continuous properties pi ={ ηi ,φi , pT,i } com-\nputed for each particle candidate. The target particles are\ndeﬁned by matching to the set of predicted particles using\nthe Hungarian assignment algorithm [20], with the loss itself\nbeing the distance metric.\nThe second part of the TSPN-SA algorithm, for predicting\ncharged particles, makes explicit use of the prior knowledge\noriginating from track-particle objects. Each track is pro-\nmoted to a particle, such that the cardinality of the output set\nis ﬁxed by the number of tracks. Similar to the neutral archi-\ntecture, SA blocks are used to update the hidden representa-\ntion of the charged particle candidates. Unlike the model for\nneutral particles, the only predicted quantity for charged par-\nticles is their transverse momentum in order to improve over\nthe track resolution. For charged particles, the track index is\nused to match with the corresponding target particle. As in\nthe OC algorithm, the η and φ of the charged particles are\ntaken directly from their representative tracks. Finally, the\ntotal loss for the TSPN-SA algorithm is the sum of neutral\nparticle cardinality loss, the neutral particle properties loss,\nand the charged particle p\nT MSE loss. These loss terms are\nminimized simultaneously during training.\n3.6 HGPﬂow: particles as hyperedges\nA hypergraph is a generalization of a graph where hyperedges\ncan each connect one, two, or multiple nodes (Fig.6). While\nconnectivity in a graph ofN nodes is described by anN × N\nadjacency matrix, a hypergraph containing K hyperedges is\ndescribed by an incidence matrix I (N ×K ). In the context of\nparticle reconstruction, calorimeter deposits and tracks can\nbe represented as nodes in a hypergraph, while each particle\nis represented by a hyperedge connecting the set of nodes to\nwhich it contributed. We proposeHGPﬂow: an algorithm that\ntreats particle reconstruction as a task of learning hyperedges\n123\nEur. Phys. J. C (2023) 83 :596 Page 9 of 18 596\nFig. 6 The two stages of learning in the HGPﬂow algorithm. The\nobjective of the ﬁrst stage is to predict the fractional entries in the energy-\nweighted incidence matrix, where columns correspond to hyperedges\n(i.e. particles). This is done by accumulating the loss over a sequence of\nrecursive updates. In the second stage, the incidence matrix is frozen and\nthe network minimizes losses for particle property predictions, deﬁned\nrelative to proxy quantities\nand their properties. There are two objectives in the training\nof HGPﬂow:\n1. predict the incidence matrix deﬁning the hyperedges\n2. predict the hyperedge (i.e. particle) properties.\nThe ﬁrst objective is similar to the task of separating over-\nlapping charged and neutral showers which was the focus\nof [ 21]. In this ﬁrst stage, the HGPﬂow network predicts\n(N + 1) × K entries comprising a zero-padded incidence\nmatrix and an additional row of binary values that indicates\nwhether the particle corresponding to a given column exists\nor not. Since the number of particles per event varies, the\nnumber of columns K is set to an upper bound on the num-\nber of particles estimated from the training set (in our case\nK = 30). To express a non-injective map from particles to\nnodes, we deﬁne a target incidence matrix which has frac-\ntional rather than binary-valued entries. The entry relating\nnode i to particle a is the following:\n[I ]\nia = Eia∑\nparticles b Eib\n= Eia\nEi\n(3)\nwhere Eia is the amount of energy that particlea contributes\nto the total energy Ei of node i. For nodes which are tracks,\nincidence entries are simply 1, whereas for topoclusters they\ncompute the fraction of the topocluster’s energy that came\nfrom a given particle. An example of target and predicted\nincidence matrix entries are shown in Fig. 7 for one event.\nPredicted rows in the incidence matrix are normalized\nusing Softmax (i.e. sum over all hyperedges for a given\nnode is 1) before being compared to the target via Kullback–\nLeibler divergence loss.\nL\ninc =\n∑\na\nKLi\n(\nI targ\nia ,Softmaxi (I pred\nia )\n)\n. (4)\nThe predicted entries of the indicator row are passed through\na sigmoid function and compared to the (binary) target entries\nFig. 7 Schematic representation of the truth and predicted incidence\nmatrix in HGPﬂow for one event. The left part of the diagram shows the\nthree truth particles in the event. One of them has a track (Tr) associated\nto it. The three particles deposit their energy into four topoclusters (TC).\nThe links represent the fractional energy originated by a given particle\nin a given topocluster or track. The right part of the diagram shows the\npredicted values of the incidence matrix for each reconstructed particle\nusing a binary cross entropy loss function. Predicted columns\nare rearranged using the Hungarian algorithm to minimize\nthe loss.\nThe incidence matrix prediction network is trained using\nthe recurrent strategy proposed by [ 22], described brieﬂy\nhereafter. The loss in Eq. 4 is calculated for a sequence of\n16 reﬁnement blocks each comprising an updated prediction\nof the incidence matrix followed by an update of node rep-\nresentation vectors V , and hyperedge representation vectors\nE. The iteration t → t + 1 is performed with the following\nthree successive steps:\nI t+1\nia = φI\n(\nvt\ni ,et\na , I t\nia\n)\n(5)\nV t+1 = φV\n({\nvt\ni ,ρ E→V (i,t), v0⏐⏐i = 1 ... n\n})\n(6)\nEt+1 = φE\n({\net\na,ρ V →E (a,t)\n⏐⏐a = 1 ... k\n})\n(7)\n123\n596 Page 10 of 18 Eur. Phys. J. C (2023) 83 :596\nwhere ρE→V (i,t) = ∑\na I t+1\nia et\na and ρV →E (a,t) =∑\ni I t+1\nia vt\ni are aggregations of node (v) and hyperedge (e)\nrepresentation vectors weighted by the updated incidence\nmatrix. The updates are performed at each step using the\nsame networks φ\nI , φV , and φE , where the latter two net-\nworks are DeepSets models [23].\nTo reduce computational cost, not every iteration of\nthe backward pass is included in the gradient step. Two\nsequences of 4 adjacent iterations are randomly selected out\nof the 16 for which the incidence loss is computed and added\nto the loss from the prediction at the end of the sequence.\nThe second training objective of the HGPﬂow network\n(Fig. 6c) is to predict particle properties for each hyper-\nedge. The corresponding loss function contains classiﬁca-\ntion and regression terms evaluated by matching predicted\nand target particles using the Hungarian algorithm. Particles\ncorresponding to hyperedges where the predicted indicator\nwas below the threshold are matched to dummy targets and\nweighted by zero in the loss. Classiﬁcation between photons\nand neutral hadrons is performed for hyperedges which do\nnot contain a track and are thus identiﬁed as neutral parti-\ncles. The regression task beneﬁts from a unique advantage\nenabled by learning the incidence matrix (Eq. 3): particle\nkinematics can be approximated as weighted sums and aver-\nages over the input features of the topoclusters contained in\nthe hyperedge. Proxy quantities (denoted ˆ) for energy and\nangular coordinates can be computed as:\nˆE\na =\n∑\nnodes i\nEi Iia , {ˆηa, ˆφa}=\n∑\nnodes i\n{ηi ,φi } ˜Iia (8)\nwhere a dual incidence matrix ˜I , normalized over node\ninstead of particle indices, can be deﬁned:\n˜Iia = Eia∑\nnodes j E ja\n= Eia\nEa\n= Ei · Iia∑\nnodes j\n(\nE j · I ja\n) . (9)\nThe property prediction networks in HGPﬂow are therefore\ngiven the simpler objective of learning corrections to the\napproximate values from Eq. 8. The loss terms used for the\nproperty predictions follow the description in Sect. 3.2.\nTherefore, neutral particle kinematics (pT,η,φ) are\nregressed by predicting an offset to the proxy values in Eq.8.\nFor charged particles, an offset is likewise predicted for the\npT measured from the associated track. The properties loss\nis computed by matching predicted and target particles using\nthe Hungarian algorithm [20].\n4 Performance of particle reconstruction in jets\nOne of the most challenging tasks of global particle ﬂow\nalgorithms is the reconstruction of particles in dense environ-\nments, in particular jets. In this section, the performance of\nthe ML reconstruction algorithms will be assessed by quan-\ntifying the similarity between the set of predicted and set of\ntarget particles. The following four types of metrics are meant\nto evaluate the cardinality, class, and properties predictions:\n– Efﬁciency and fake rate\n– Classiﬁcation purity\n– Particle angular and momentum resolution\n– Jet-level quantities.\nThe efﬁciency and fake rate are deﬁned as follows:\nϵ ≡ N (matched pred)\nN (targ) , f ≡ N (unmatched pred)\nN (pred) . (10)\nThe quality of the regression tasks is evaluated from dis-\ntributions of their residuals, deﬁned as (ytarg − ypred)/ytarg\nfor particle property y ∈{ pT,η,φ }.\n4.1 Particle matching\nPredicted and target particles are matched using the Hungar-\nian algorithm to ﬁnd the pairings which minimize the distance\nbetween their properties, deﬁned by the following metric:\ndmatch =\n√\n(ΔpT/ptruth\nT )2 + ΔR2 (11)\nwhere Δ denotes the difference between a predicted and tar-\nget property, andΔR2 = Δη2 +Δφ2. Matching is performed\nseparately for neutral particles and charged particles since the\nlatter are distinguished by the presence of a track. The coefﬁ-\ncients cpT and cΔR are set to 1 and 5 for neutral particles while\nfor charged, matching is based only on ΔR (i.e. cpT = 0).\nPrioritizing spatial matching helps decouple reconstruction\nefﬁciency from classiﬁcation accuracy, which in particular\nwill dominate at low-pT because of the similarity of photon\nand neutral hadron signatures.\nIn each event, when the cardinality of the predicted set\nof particles is larger than that of the target, the non-matched\npredictions are labeled as “fake” particles. Conversely, inef-\nﬁciency arises when not enough neutral or charged particles\nwere predicted in order to match every target.\n4.2 Charged particle performance\nCharged particles include electrons, muons, and charged\nhadrons. In jets charged pions produced during hadroniza-\ntion account for around 90% of all charged particles. Leptons\nsuch as electrons and muons are present in less than 3% of\nthe jets. Electrons are produced from photon conversions and\nhadrons decaying in ﬂight while muons are mostly produced\nby the latter mechanism. Given the large class imbalance\nand the fact that no dedicated studies have been performed to\nimprove the classiﬁcation of electrons inside jets, the three\n123\nEur. Phys. J. C (2023) 83 :596 Page 11 of 18 596\nFig. 8 Resolution of charged particle-ﬂow candidates and tracks as a\nfunction of the associated particle transverse momentum. At high pT\nthe particle-ﬂow candidates show improved resolutions over the tracks\nclasses are grouped together and characterized as a single\nclass of charged particles.\nTracking efﬁciency presents an upper bound on the efﬁ-\nciency of charged particle reconstruction (see Sect. 2.1).\nSince fake tracks are not emulated in the data, charged par-\nticle fake rates are neglected in this study. In any case, the\nrate of fake tracks at 1 GeV is typically at the percent level\nfor the ATLAS and CMS experiments, which is expected to\nhave a small impact.\nIn cases where the track belonging to a charged particle is\nnot reconstructed, the target particle is relabelled to avoid\nconfusing the network during training. Charged hadrons\nwithout a track are relabelled as neutral hadrons, and elec-\ntrons without a track as photons. Photon pairs from neutral\npion decays prior to the calorimeter are treated as two distinct\ntarget particles.\nA key characteristic of charged particle reconstruction is\nthe resolution of p\nT with respect to the true value. It is well\nknown that at low transverse momentum tracks provide the\nbest momentum estimate over the calorimeter resolutions. An\nopposite trend appears at high energies where the calorime-\nter systems provide the most accurate energy measurement.\nFigure 8 shows the resolutions of charged particles recon-\nstructed with the three ML approaches and compared to the\ntrack resolutions for charged particles with p\nT > 15 GeV .\nBelow this value, the particle pT regression is replaced with\nsimply the track pT since an improvement is not expected.\nAn increasing improvement at highpT is observed for all the\nML algorithms demonstrating that indeed the complementar-\nity between the calorimeter and tracking measurements has\nbeen learned during training.\n4.3 Photon and neutral hadron performance\nThe presence of photons inside jets is mainly due to decays\nof neutral pions and to a lesser extent from bremsstrahlung\nprocesses. Long-lived neutral hadrons on the other hand\ntrace back to the shower of the initial partons. Disentangling\nthese two components is not a trivial task and is detector-\ndependent – for COCOA it is observed that 70% of neutral\nhadrons below 5 GeV release all their energy in the ECAL\nlayers, making it difﬁcult to distinguish them from photons.\nThis fraction steeply decreases with the energy of the ini-\ntial hadrons to approach percent levels at around 20 GeV .\nNeutral particle reconstruction is further complicated inside\nthe collimated environment because of the frequent over-\nlaps between neutral showers. For this reason, efﬁciency and\nfake rate plots are computed by considering photon and neu-\ntral hadron predictions inclusively, without requiring a match\nbetween predicted and target class.\nEfﬁciencies, fake rates, and class prediction accuracy for\nphotons and neutral hadrons are shown in Fig. 9. The efﬁ-\nciency of reconstructing photons with p\nT > 2G e Vi s\nabove 90% for HGPﬂow, rising to 98% for photons above\npT > 30 GeV . For TSPN-SA and OC, the efﬁciency for\nphotons reaches 95% and 90%, respectively. Neutral hadrons\nabove 5 GeV are reconstructed with efﬁciencies ranging from\n76 to 86% for the three algorithms. Figure 9c shows that the\nrate of producing unmatched photon predictions drops from\n16% (30%) at a predicted pT of 2 GeV to 1.4% (11%) above\n30 GeV for HGPﬂow (TSPN-SA). For neutral hadrons, the\nfake rate (Fig.9d) is a factor of 2–4 times larger across the full\np\nT range for HGPﬂow, and 1.6–2.8 times larger for TSPN-\nSA.\nFor the TSPN-SA and HGPﬂow algorithms, reconstruct-\ning neutral particles at low-pT is challenging because a large\nfraction of the target particles does not contribute a leading\namount of energy to any topocluster in the event (33% of\nphotons and 25% of neutral hadrons). In HGPﬂow, this is\ncompensated in a supervised manner by learning subdomi-\nnant contributions to topoclusters as fractional entries in the\npredicted incidence matrix. This limitation could be further\novercome by using cell-level input nodes such as for the OC\nalgorithm.\nEfﬁciency and fake rate plots are complemented by study-\ning the probability of misclassiﬁcation between photons and\nneutral hadrons. In Fig. 9e and f, both HGPﬂow and TSPN-\nSA algorithms exhibit high accuracy of classiﬁcation for pre-\ndictions matched to photons, and for neutral hadrons an accu-\nracy that rises withp\nT: from 51 to 76% for HGPﬂow and from\n16 to 63% for TSPN-SA. A lower accuracy is expected when\nconsidering that due to the class imbalance between photons\nand neutral hadrons of 5.8:1 (inclusive), a random classiﬁer\nwould have an accuracy of roughly 15% for neutral hadrons.\nMoreover, the class imbalance isp\nT-dependent, with the pro-\nportion of photons dropping off faster than neutral hadrons.\nThe OC algorithm behaves similarly to the others for\nreconstruction efﬁciency of neutral particles, albeit with\nlower performance in most bins. For the fake rate, and in\n123\n596 Page 12 of 18 Eur. Phys. J. C (2023) 83 :596\nFig. 9 Top: efﬁciency of matching predicted neutral particles to truth\nphotons (a) and neutral hadrons (b) in a jet as a function of the associ-\nated truth particle pT. Middle: fake rate, i.e. probability that predicted\nphotons (c) and neutral hadrons (d) are not matched to any truth neutral\nparticle, as a function of the predicted particle pT. Bottom: the prob-\nability that the predicted neutral particles which are matched to truth\nphotons (e) and neutral hadrons ( f) are assigned the correct class. For\neach curve, the misclassiﬁcation probability is simply the difference of\nthe curve from 1\n123\nEur. Phys. J. C (2023) 83 :596 Page 13 of 18 596\nFig. 10 Distributions of relative residuals between predicted and true pT (a), η (b), and φ (c) of reconstructed neutral particles\nparticular, for photons, OC exhibits an increase withpT.T h e\nclassiﬁcation accuracy for OC is also lower for photons and\nshows a different trend in p\nT for neutral hadrons compared\nto HGPﬂow and TSPN-SA. These differences are related to\nthe fact that in OC neutral particle predictions correspond\nto a subset of calorimeter cells passing the selection deﬁned\nby the t\nb and td threshold cuts. This introduces a sensitivity\nof the neutral particle cardinality to the number of cells per\nparticle, which grows as a function of particle pT. The trend\nin fake rate appears to reﬂect this. Furthermore, towards high\npT a growing majority of cells belong to showers of charged\nparticles, which makes the classiﬁcation task more challeng-\ning in the OC approach (which involves 3 classes, unlike\nHGPﬂow and TSPN-SA). Introducingp\nT-dependent weights\non the β and x prediction tasks could help counter this\neffect.\nFinally, relative residuals are used to quantify the ability\nto correctly predict the pT, η, and φ of the reconstructed neu-\ntral particles, shown in Fig. 10a, b, and c, respectively. The\nHGPﬂow algorithm shows the best performance at estimat-\ning accurately both angular variables and momentum. It is\ninteresting to note that the TSPN-SA algorithm has the worst\nperformance for the angular variables. This is related to the\nusage of topoclusters in a less supervised way compared to\nHGPﬂow, where it is known which topoclusters contributed\nto the formation of a particle. The OC algorithm instead uses\nthe more granular calorimeter cells directly showing similar\nperformance to the HGPﬂow algorithm for angular regres-\nsion.\nThe models also perform differently for neutral particlep\nT\nregression, shown in Fig.10a. The OC model has a tendency\nto overestimate the neutral particlepT. A similar trend is less\npronounced in the TSPN-SA regression, while the distribu-\ntions of predictions from HGPﬂow exhibit the least skew, in\naddition to the smallest mean and variance of the three.\n4.4 Jet-level performance\nThe ability to efﬁciently reconstruct jets and correctly predict\ntheir properties is a priority for experiments at the LHC. Jet\nperformance depends on the overall efﬁciency, fake-rates and\nkinematic regression of the constituent particles, therefore\nbeing an important test for the ML reconstruction algorithms.\nFollowing evaluation of the networks, jets are built using\nthe anti-k\nt algorithm [24] with a radius parameter of 0.4 and\na minimum number of 2 constituents. We deﬁne three sets of\njets with differing input constituents:\n– Truth jets: jets built using the set of target particles\n– ML jets: jets built using the sets of particles predicted by\nthe OC, TSPN-SA, and HGPﬂow algorithms\n– PPﬂow jets : jets built using tracks and topoclusters with\nthe charged energy subtraction procedure of a parame-\nterized particle-ﬂow algorithm (see Sect. 3.1).\n123\n596 Page 14 of 18 Eur. Phys. J. C (2023) 83 :596\nFig. 11 Jet-level performance metrics shown for the three algorithms and the PPﬂow reference in comparison to true jets. Angular residuals\nbetween reconstructed and true jets (a and b), the number of jet-constituents in (c), and the calibrated pT relative residuals in (d)\nThe number of constituents is shown in Fig. 11c for each\nalgorithm and compared to that of the true jet. The ML algo-\nrithms, by accounting for neutral particles in the jet, are able\nto model this reasonably well. On the other hand, the PPﬂow\ndistribution overestimates the truth distribution as expected,\nsince its constituents are tracks and topoclusters rather than\nparticles (Fig. 12).\nIn order to further optimize the jet-p\nT and provide a more\nquantitative ﬁgure of the jet resolutions, a simplistic calibra-\ntion is applied. First jet pT residual distributions are com-\nputed in different pT bins. For each, a dedicated scale factor\nis computed. A functional ﬁt is performed and the corre-\nsponding scale factor is applied to reconstructed jets based\non their pT. This procedure is applied separately to each\nreconstruction algorithm.\nRelative residuals are shown in Fig. 11. As observed for\nneutral particles, HGPﬂow shows the best performance at\nthe jet-level. In terms of jet angular observables, HGPﬂow\nis comparable to the traditional PPﬂow approach while for\njet p\nT resolution it shows a 24% improvement relative to\nPPﬂow. The TSPN-SA jet pT resolution is better than OC,\nwhile for angular observables OC performs slightly better.\nTo help visualize the jet reconstruction task, Fig. 12 dis-\nplays an event from the test dataset showing predictions from\nthe trained HGPﬂow algorithm. In this example, each of the\nfour neutral particles at truth level can be matched to a pre-\ndicted particle with the correct class and an η–φ prediction\nconsistent within the cell granularity. The calorimeter panels\nillustrate the tight arrangement of topoclusters used as input\nnodes for the HGPﬂow prediction.\n4.5 Performance on gluon jets\nTo study the ability of the particle reconstruction algorithms\nto generalize beyond the training data to a new physics pro-\ncess, we evaluate the trained models on the dataset of single\ngluon jet events described in Sect. 2.2. The difference aris-\ning at the parton shower for gluon-initiated jets reﬂects itself\nin the dataset feature distributions, for example, the larger\nmultiplicity of cells, tracks, and particles shown in Fig. 2.\nSince the appropriate upper bound on the number of particles\nwas determined based on the training dataset, a single gluon\njet found to contain > 30 particles was excluded from the\ndataset in order to evaluate HGPﬂow. The results for the three\n123\nEur. Phys. J. C (2023) 83 :596 Page 15 of 18 596\n−2.1\n−1.8\n−1.5\n−1.2\n−2.1\n−1.8\n−1.5\n−1.2\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\nEnergy [GeV]\n0\n0.5\n1\n1.5\n2\n2.5\n3\nEnergy [GeV]\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\n0.08\n0.09\nEnergy [GeV]\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nEnergy [GeV]\nφφ\n−2.1\n−1.8\n−1.5\n−1.2φ\n1.5 1.8 2.1 2.4 1.5 1.8 2.1 2.4\nηη\nECAL1\nTruth Event Reco Event\nJet\nPhoton\nCharged Hadron\nNeutral Hadron\nJet\nPhoton\nCharged Hadron\nNeutral Hadron\nECAL2\nHCAL1\nHCAL2\nHCAL2ECAL2\nFig. 12 Event display of a single jet event from the test dataset. In\nthe top left panel, the η−φ coordinates of truth particles with momen-\ntum above 1 GeV are shown as circles along with the set of predicted\nparticles from the HGPﬂow algorithm shown as crosses. The set of par-\nticles and their p\nT at truth level are as follows: two photons in blue\n(1.8, 3.0 GeV), a pair of neutral K 0\nL mesons in grey (12.3, 22.3 GeV),\nand two charged pions in red (2.2, 6.5 GeV). The circles of R = 0.4\nrepresent anti-kt jets built from the truth (solid) and predicted (dashed)\nparticle sets that nearly overlap in η–φ and have pT agreement within\n35%. In the top right panels, the truth and predicted particles are shown\noverlaid on a zoomed region of the ECAL2 and HCAL2 layers. In the\nbottom panels, the detector-level information serving as input to the\nreconstruction algorithms is shown for each of the ﬁrst two layers of\nboth ECAL and HCAL in the sameη−φ plane. Cells that have the same\nborder color belong to the same topocluster. Green and blue ﬁll is used\nto indicate the energy of cells in the ECAL and HCAL layers, respec-\ntively. The arrows describe the tracks for charged particles from the\ninteraction point with the arrowheads indicating the angular coordinate\nextrapolated at the given layer\n123\n596 Page 16 of 18 Eur. Phys. J. C (2023) 83 :596\nFig. 13 Distributions of the number of constituents per jet ( a), and distributions of relative residuals between predicted and true pT (b)f o rt h e\nthree ML particle reconstruction algorithms evaluated on the sample of gluon jets\nML algorithms are shown along with the PPﬂow comparison\nin Fig. 13. Overall, the algorithms demonstrate an ability to\ngeneralize: the number of predicted constituents is shifted\nslightly lower with respect to truth compared to the quark\njet case (Fig.11c), while the jet relative p\nT residual distribu-\ntions are comparable to Fig.11d. The rank of the algorithms\nin terms of performance remains the same as before, with\nHGPﬂow again boasting narrower jet pT resolution than the\nPPﬂow comparison.\n5 Discussion\n5.1 Perspective on the ML algorithms\nCompared to the OC and TSPN-SA algorithms and the\nPPﬂow benchmark, HGPﬂow shows the best performance\nin terms of jet momentum resolution, which was not directly\na training objective. This traces back to superior modeling\nof neutral particle momentum shown in Fig. 10a. Unlike the\nother ML models, which must learn implicitly that a given\nenergy deposit in the calorimeter cannot be associated with\nmore than one parent particle, HGPﬂow beneﬁts from being\nstructured around the concept of energy conservation. Suc-\ncessfully predicting an incidence matrix deﬁned via Eq. 3\nand the hyperedge indicator row entails knowing the energy\ncontributions a given topocluster received from all particles\n(Fig. 7). Furthermore, the normalization ensures that energy\nattributed to a given particle candidate is not counted again in\nassignments to other particles. Since both the hyperedge rep-\nresentation and the proxy for neutral particle energy (Eq. 8)\nare weighted by entries of the incidence matrix, the prop-\nerty predictions which stem from these inputs inherit a bias\ntowards energy conservation.\nThe hypergraph approach allows common elements of\nboth the OC and TSPN-SA approaches to be handled in a\nmore clear formalism. In the OC potential loss (Eq. 1), a\nbinary-valued incidence matrix I\nik functions as a lookup\ntable determining whether a node is repelled or attracted\nto the representation of a particle (i.e. condensation point).\nThe clustering of nodes according to parent particle can\nthus be thought of as an indirect way of learning I\nik , lim-\nited by the extent to which the injective condition applies\n(discussed in Sect. 3.2). Likewise, the TSPN-SA algorithm\nis built around an attention matrix between particle candi-\ndates k and nodes i from the input set which resembles an\nincidence matrix, although it is normalized along columns\nrather than rows. The attention weights also have a latent\nrather than physical meaning and are learned in an unsuper-\nvised way. On the other hand, HGPﬂow not only explicitly\npredicts the incidence matrix, which is the key to unraveling\noverlapping particle showers, but expresses it in the physical\nbasis of energy contributions with the advantage mentioned\npreviously.\nWe anticipate that the structure of HGPﬂow can be\nextended in at least three ways. First, the input set gran-\nularity has been set without tuning to that of topoclusters\nfrom a standard ATLAS-like algorithm. This granularity can\nbe increased to further enable the segmentation of overlap-\nping energy deposits from nearby particles. Second, in the\ntrainings for our results, the two objectives of incidence and\nproperties prediction have been carried out nearly indepen-\ndently. However, a more powerful representation learning\nscheme could lead to a model which learns these two objec-\ntives in a synergistic way, allowing the incidence predic-\ntion to be informed by the properties prediction and vice\nversa. Finally, while Table 2 indicates an acceptable infer-\nence time of HGPﬂow, more optimization is needed to reduce\nits training duration. This could be achieved by hyperpa-\nrameter optimization in the recurrent training conﬁgura-\ntion and by exploring alternatives to the Hungarian match-\n123\nEur. Phys. J. C (2023) 83 :596 Page 17 of 18 596\ning, which the authors of [ 22] identiﬁed as a computational\nbottleneck.\nSimilarly, besides the modiﬁcations proposed in [ 5], we\nsuspect that the OC algorithm can be substantially improved\nin future work. While the TSPN-SA and HGPﬂow algorithms\nboth have neural network layers for information exchange\nfollowing the node encoding (i.e. successive attention and\nincidence weighted-updates), the node predictions of our OC\nalgorithm are likely limited by a comparatively narrow recep-\ntive ﬁeld. One way to increase the receptive ﬁeld in OC is to\nadd additional message passing blocks in the node encoder\nmodel, although a limited study of this option did not lead to\nconclusive improvement. Another possibility is introducing\nan attention mechanism. The distance between nodes i and\nj in the latent clustering space entails a term a\nij = xi · x j\nwith the form of attention, e.g. in the attractive potential,\n˘V ∝ Δx2 ∋− 2aij . Therefore the clustering mechanism in\nOC seems a natural point to introduce transformer blocks\nfor enhanced information exchange, at the cost of computing\nadditional gradients for the set of edges.\n5.2 Datasets for future work\nSeveral opportunities emerge for future investigation on new\ndatasets. The performance reported in this work forR = 0.4\nquark and gluon jets suggests the application to substructure\nreconstruction in large- R jets from boosted boson decays.\nThe goal of studying particle reconstruction on a single jet\ndataset was to focus on the local system of overlapping par-\nticle showers which represents the kernel of the problem at\nthe full-event level. For this reason, we envision that recon-\nstructing full events could proceed by mapping the same\ntrained model onto spatial partitions of the detector hits\nD deﬁned by topological and jet clustering algorithms, for\ninstance. Given an effective scheme to deal with potential\noverlap, each partition could be treated as an approximately\nisolated set of input nodes, graph edges, and attention or inci-\ndence matrix weights. In this case the resource requirements\nreported in Table 2 would scale linearly with the number of\npartitions. Ignoring overlap, an upper bound on the number\nof R = 0.4 partitions of a full event could be estimated as\n2π · 6/0.4 ≃ 10\n2.\nStudying the robustness of the models in the presence of\npileup will also be an important follow-up task (see [ 6]f o r\nexisting work in this direction). Likewise, the impact of inter-\nactions with material upstream of the calorimeter needs to be\nthoroughly addressed in a future dataset. In this case, elec-\ntron pair production from early conversions and photons from\nbremsstrahlung will require a thoughtful deﬁnition of target\nparticles to ensure that they can be feasibly distinguished\nduring training. For example, photon conversions could be\ntreated as a separate class, and electrons could be deﬁned as\ntargets depending on the quality of their associated track (if\npresent at all).\n6 Conclusions\nIn this paper, we applied ML-based reconstruction algo-\nrithms to the dense environment of a jet. Single-jet datasets\nwere generated using a realistic calorimeter model to mimic\nthe complexity and input features of data from the LHC.\nParticle-ﬂow reconstruction is inherently a set-to-set task\nsuited for ML applications. Three ML algorithms – a modi-\nﬁed version of Object Condensation, a set-transformer archi-\ntecture with slot attention (TSPN-SA), and a novel hyper-\ngraph learning approach (HGPﬂow) – were compared by\ntheir ability to reconstruct particles in the jet and jet-\nlevel quantities using an input graph comprising tracks\nand calorimeter clusters. In particular, the algorithms were\ntrained to reconstruct individual neutral particles in the dense\nenvironment, a task going beyond the scope of traditional\nparticle ﬂow algorithms.\nFor charged particles, the algorithms learned to exploit the\ncomplementary information provided by calorimeter activity\nto improve on the measured track momentum. The efﬁciency\nof reconstructing photons and neutral hadrons reached 90%\nand 80%, respectively, forp\nT > 10 GeV . The neutral particle\nfake rates were more variable for each algorithm, with the\nbest performance being 10% and lower for pT > 10 GeV .\nJets formed from the predicted particles were compared to\nthose from the true particles and also a parameterized parti-\ncle ﬂow baseline. HGPﬂow showed the best performance and\nsurpassed the baseline in terms of both angular and momen-\ntum resolution of the jet. This can be explained from the fact\nthat the hypergraph formalism is structured around energy\nconservation, which also makes its predictions more inter-\npretable from a physics point of view. We anticipate that\nthe suitability of the hypergraph formalism for the set-to-set\ntask of particle reconstruction is yet to be fully leveraged.\nBy demonstrating the potential of ML algorithms to disen-\ntangle the jet dense environment, our ﬁndings motivate the\napplication to full collision events in future work.\nAcknowledgements The authors are grateful to Jan Kieseler for his\nadvice on the OC algorithm. ED is supported by the Zuckerman STEM\nLeadership Program. SG is partially supported by Institute of AI and\nBeyond for the University of Tokyo. EG is supported by the Israel Sci-\nence Foundation (ISF), Grant No. 2871/19 Centers of Excellence. LH\nis supported by the Excellence Cluster ORIGINS, which is funded by\nthe Deutsche Forschungsgemeinschaft (DFG, German Research Foun-\ndation) under Germany’s Excellence Strategy - EXC-2094-390783311.\nData Availability Statement This manuscript has associated data in a\ndata repository. [Authors’ comment: The manuscript contains associ-\nated data available in the data repository [15].]\n123\n596 Page 18 of 18 Eur. Phys. J. C (2023) 83 :596\nOpen Access This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adaptation,\ndistribution and reproduction in any medium or format, as long as you\ngive appropriate credit to the original author(s) and the source, pro-\nvide a link to the Creative Commons licence, and indicate if changes\nwere made. The images or other third party material in this article\nare included in the article’s Creative Commons licence, unless indi-\ncated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permit-\nted use, you will need to obtain permission directly from the copy-\nright holder. To view a copy of this licence, visit http://creativecomm\nons.org/licenses/by/4.0/.\nFunded by SCOAP\n3.S C O A P3 supports the goals of the International\nYear of Basic Sciences for Sustainable Development.\nReferences\n1. ATLAS collaboration. Jet reconstruction and performance using\nparticle ﬂow with the ATLAS Detector. Eur. Phys. J. C, 77(7), 1–\n47 (2017)\n2. A.M. Sirunyan, CMS Collaboration et al., Particle-ﬂow reconstruc-\ntion and global event description with the CMS detector. JINST\n12(10), P10003 (2017)\n3. J. Shlomi, P. Battaglia, J.R. Vlimant, Graph neural networks in\nparticle physics. Mach. Learn. Sci. Technol. 2(2), 021001 (2020)\n4. J. Kieseler, Object condensation: one-stage grid-free multi-object\nreconstruction in physics detectors, graph, and image data. Eur.\nPhys. J. C 80(9), 1–12 (2020)\n5. S.R. Qasim, K. Long, J. Kieseler, M. Pierini, R. Nawaz, Multi-\nparticle reconstruction in the High Granularity Calorimeter using\nobject condensation and graph neural networks. EPJ Web Conf.\n251, 03072 (2021)\n6. S.R. Qasim, N. Chernyavskaya, J. Kieseler, K. Long, O. Viazlo,\nM. Pierini, R. Nawaz, End-to-end multi-particle reconstruction in\nhigh occupancy imaging calorimeters with graph neural networks.\nEur. Phys. J. C 82(8), 753 (2022)\n7. J. Pata, J. Duarte, J.R. Vlimant, M. Pierini, M. Spiropulu. MLPF:\nefﬁcient machine-learned particle-ﬂow reconstruction using graph\nneural networks. Eur. Phys. J. C 81(5), 1–14 (2021)\n8. J. Pata, J. Duarte, F. Mokhtar, E. Wulff, J. Yoo, J.R. Vlimant,\nM. Pierini, M. Girone. Machine learning for particle ﬂow recon-\nstruction at CMS. J. Phys. Conf. Ser. 2438(1), 012100 (2022)\n9. F. Mokhtar, J. Pata, J. Duarte, E. Wulff, M. Pierini, J.R. Vlimant,\nProgress towards an improved particle ﬂow algorithm at CMS with\nmachine learning, in ACAT 2022 (2023). arXiv:2303.17657\n10. S. Agostinelli et al., GEANT4: a simulation toolkit. Nucl. Instrum.\nMeth. 506(3), 250–303 (2003)\n11. F.A. Di Bello, A. Charkin-Gorbulin, K. Cranmer, E. Dreyer, S. Gan-\nguly, E. Gross, L. Heinrich, L. Santi, M. Kado, N. Kakati, P. Rieck,\nM. Tusoni, Conﬁgurable calorimeter simulation for AI applications\n(2023). Preprint. arXiv:2303.02101\n12. J. de Favereau, C. Delaere, P. Demin, A. Giammanco, V . Lemaître,\nA. Mertens, M. Selvaggi, DELPHES 3: a modular framework for\nfast simulation of a generic collider experiment. JHEP 2, 2014\n(2014)\n13. C. Bierlich et al., A comprehensive guide to the physics and usage\nof PYTHIA 8.3. SciPost Phys. Codebases, 008 (2022)\n14. ATLAS Collaboration. Topological cell clustering in the ATLAS\ncalorimeters and its performance in LHC Run 1. Eur. Phys. J. C\n77(7), 1–73 (2017)\n15. Training and test datasets. https://doi.org/10.5281/zenodo.\n7699681\n16. Code for algorithms. https://github.com/nilotpal09/hg-tspn-pﬂow\n17. S.R. Qasim, J. Kieseler, Y . Iiyama, M. Pierini, Learning repre-\nsentations of irregular particle-detector geometry with distance-\nweighted graph networks. Eur. Phys. J. C 79(7), 608 (2019)\n18. A.R. Kosiorek, H. Kim, D.J. Rezende, Conditional set generation\nwith transformers (2020). Preprint. arXiv:2006.16841\n19. F. Locatello et al., Object-centric learning with slot attention. Adv.\nNeural Inf. Process. Syst. 33, 11525–11538 (2020)\n20. H.W. Kuhn, The Hungarian method for the assignment problem.\nNav. Res. Logist. Q. 2(1-2), 83–97 (1955)\n21. F.A. Di Bello, S. Ganguly, E. Gross, M. Kado, M. Pitt, L. Santi,\nJ. Shlomi, Towards a computer vision particle ﬂow. Eur. Phys. J.\nC. 81(2), 1–14 (2021)\n22. D.W. Zhang, G.J. Burghouts, C.G.M. Snoek, Recurrently predict-\ning hypergraphs (2021). Preprint. arXiv:2106.13919\n23. M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R.R. Salakhut-\ndinov, A.J. Smola, Deep sets. Adv. Neural Inf. Process. Syst. 30\n(2017)\n24. M. Cacciari, G.P. Salam, G. Soyez, The anti-k\nt jet clustering algo-\nrithm. JHEP 4, 063 (2008)\n123"
}