{
    "title": "Large Language Models Like ChatGPT in ABME: Author Guidelines",
    "url": "https://openalex.org/W4366821774",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2604108378",
            "name": "Carly Norris",
            "affiliations": [
                "Virginia Tech"
            ]
        },
        {
            "id": "https://openalex.org/A2604108378",
            "name": "Carly Norris",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4313451803",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4313453502",
        "https://openalex.org/W4322719791",
        "https://openalex.org/W4324304837",
        "https://openalex.org/W4313479734",
        "https://openalex.org/W4312083290",
        "https://openalex.org/W4375860725"
    ],
    "abstract": null,
    "full_text": "Vol.:(0123456789)1 3\nAnnals of Biomedical Engineering (2023) 51:1121–1122 \nhttps://doi.org/10.1007/s10439-023-03212-2\nEDITORIAL\nLarge Language Models Like ChatGPT in ABME: Author Guidelines\nCarly Norris1 \nReceived: 12 April 2023 / Accepted: 14 April 2023 / Published online: 24 April 2023 \n© The Author(s) under exclusive licence to Biomedical Engineering Society 2023\nThe use of Large Language Models (LLMs) within the sci-\nentific community has resulted in a storm of ethical dis-\ncussions in recent months. LLMs are an emerging form \nof artificial intelligence which have been trained to output \nplausible sequences of words based on the likelihood that \nthe sequence may occur within the natural human language. \nThese unique sentences are strung together based on the text \ndata that the model was trained on [1 ]. For example, Chat-\nGPT is an LLM that was trained on a very large dataset from \nthe Internet and has recently demonstrated its effectiveness \nat constructing sequences of sentences with valid deductive \nreasoning. Further illustrating its power within the scien-\ntific community, ChatGPT recently authored peer-reviewed \npapers in Oncoscience [2 ] and Nurse Education and Prac-\ntice [5] journals and demonstrated expert-level knowledge \nby receiving a passing score on the United States Medical \nLicensing Exam [1].\nThis powerful tool is capable of providing quick, custom \nresponses to help answer niche questions, however, there \nexist major concerns related to its use for scientific report-\ning. In particular, LLMs cannot be held accountable for the \naccuracy and validity of the science discussed within the \nwritten text. This is particularly important because LLMs, \nincluding ChatGPT, can provide largely inaccurate or biased \nresponses based on the input data it was trained on [1, 3, 4]. \nTherefore, many scientific publishers now prohibit LLMs \nfrom authoring manuscripts, which includes Springer \nNature. Details can be found within the editorial policies \non authorship criteria. As a Springer Nature journal, the \nAnnals of Biomedical Engineering (ABME) will adhere to \nthese guidelines and reject manuscripts that do not satisfy \nthe authorship criteria.\nTransparent reporting of the use of LLMs in scientific \nworks remains a major ethical discussion. The use of LLMs \nlike ChatGPT threaten scientific rigor and integrity when \nthe authors adopt the original language that was output \nfrom these generated models as their own [3 ]. Therefore, \nABME now requires full transparency within the methods \nor acknowledgements section if the authors have used LLMs \nin any way to while developing their manuscripts. By stating \nthe use of the LLM, the author is accepting responsibility \nfor the accuracy of what was reported and spreads aware-\nness to the reviewers so that they may identify any potential \nbiases, inaccuracies, or misreporting. Kung et al. provided \na good example of transparent reporting of the use of Chat-\nGPT within the methods section as it directly related to data \ncollection and analysis [4]. Statements should be provided in \nthe acknowledgements section in instances where the LLM \nenhanced or motivated any ideas or discussions throughout \nthe document, especially if any of the generated text was \nused. Examples of how to report the use of LLMs in the \nacknowledgements section are included below.\nThe author acknowledges that this article was partially \ngenerated by ChatGPT (powered by OpenAI's language \nmodel, GPT-3; http:// openai. com). The editing was per -\nformed by the author [3].\nThe author acknowledges that some content in this article \nwas partially generated by ChatGPT (powered by OpenAI's \nlanguage model, GPT-3.5; http:// openai. com) to discover \nthe roles that chatGPT can play in public health. The editing \nwas performed completely by the human author [4].\nAs the use of LLMs like ChatGPT continue to expand and \nmodels continue to improve, it is imperative for scientists to \nstrive for the highest degree of scientific rigor and integrity \nthrough deep critical thinking and transparent reporting. \nOnly then can we be confident in the data that will power \nfuture models and scientific discoveries, which will hope-\nfully converge upon groundbreaking solutions.\nBIOMEDICAL\nENGINEERING \nSOCIETY\nAssociate Editor Stefan M. Duma oversaw the review of this \narticle.\n * Carly Norris \n carly8@vt.edu\n1 Department of Biomedical Engineering and Mechanics, \nVirginia Tech, Blacksburg, VA 24060, USA\n1122 C. Norris \n1 3\nDeclarations \nConflict of interest The authors disclose no conflicts of interest.\nReferences\n 1. Kung, T. H., M. Cheatham, A. Medenilla, C. Sillos, L. De Leon, \nC. Elepaño, M. Madriaga, R. Aggabao, G. Diaz-Candido, J. \nManingo, and V. Tseng. Performance of chatgpt on usmle: poten-\ntial for ai-assisted medical education using large language models. \nPLoS Digit Health. 2:e0000198, 2023.\n 2. Zhavoronkov, A. Rapamycin in the context of pascal’s wager: \ngenerative pre-trained transformer perspective. Oncoscience. \n9:82–84, 2022.\n 3. Biswas, S. S. Potential use of chat gpt in global warming. Ann \nBiomed Eng. 2023. https:// doi. org/ 10. 1007/ s10439- 023- 03171-8.\n 4. Biswas, S. S. Role of chat gpt in public health. Ann Biomed Eng. \n2023. https:// doi. org/ 10. 1007/ s10439- 023- 03172-7.\n 5. King, M. R., ChatGpt. A conversation on artificial intelligence, \nchatbots, and plagiarism in higher education. Cell Mol Bioeng. \n16:1–2, 2023.\n 6. O’Connor, S., ChatGpt. Open artificial intelligence platforms in \nnursing education: Tools for academic progress or abuse? Nurse \nEduc Pract. 66:103537, 2023.\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations."
}