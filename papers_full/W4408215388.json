{
  "title": "Large language models for analyzing open text in global health surveys: why children are not accessing vaccine services in the Democratic Republic of the Congo",
  "url": "https://openalex.org/W4408215388",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2048585480",
      "name": "Roy Burstein",
      "affiliations": [
        "Institute for Disease Modeling"
      ]
    },
    {
      "id": "https://openalex.org/A1967374054",
      "name": "Eric Mafuta",
      "affiliations": [
        "University of Kinshasa"
      ]
    },
    {
      "id": "https://openalex.org/A2144451450",
      "name": "Joshua L.  Proctor",
      "affiliations": [
        "Institute for Disease Modeling"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6790905736",
    "https://openalex.org/W4387526446",
    "https://openalex.org/W3036644138",
    "https://openalex.org/W6781924360",
    "https://openalex.org/W4391494845",
    "https://openalex.org/W4392358084",
    "https://openalex.org/W4367052411",
    "https://openalex.org/W4399321805",
    "https://openalex.org/W4385877981",
    "https://openalex.org/W6636510571",
    "https://openalex.org/W2963026768",
    "https://openalex.org/W2758642864",
    "https://openalex.org/W4225153444",
    "https://openalex.org/W6861362856",
    "https://openalex.org/W6810311456",
    "https://openalex.org/W4394579747",
    "https://openalex.org/W2149868499",
    "https://openalex.org/W2094171166",
    "https://openalex.org/W4391758695",
    "https://openalex.org/W3134985193"
  ],
  "abstract": "Abstract Background This study evaluates the use of large language models (LLMs) to analyze free-text responses from large-scale global health surveys, using data from the Enquête de Couverture Vaccinale (ECV) household coverage surveys from 2020, 2021, 2022 and 2023 as a case study. Methods We tested several LLM approaches consisting of zero-shot and few-shot prompting, fine-tuning, and a natural language processing approach using semantic embeddings, to analyze responses on the reasons caregivers did not vaccinate their children. Results Performance ranged from 61.5% to 96% based on testing against a curated benchmarking dataset drawn from the ECV surveys, with accuracy improving when LLMs were fine-tuned or provided examples for few-shot learning. We show that even with as few as 20–100 examples, LLMs can achieve high accuracy in categorizing free-text responses. Conclusions This approach offers significant opportunities for reanalyzing existing datasets and designing surveys with more open-ended questions, providing a scalable, cost-effective solution for global health organizations. Despite challenges with closed-source models and computational costs, the study underscores LLMs' potential to enhance data analysis and inform global health policy.",
  "full_text": null,
  "topic": "Benchmarking",
  "concepts": [
    {
      "name": "Benchmarking",
      "score": 0.631432056427002
    },
    {
      "name": "Democracy",
      "score": 0.4760141968727112
    },
    {
      "name": "Computer science",
      "score": 0.45594772696495056
    },
    {
      "name": "Scale (ratio)",
      "score": 0.4528653025627136
    },
    {
      "name": "Comprehension",
      "score": 0.44539621472358704
    },
    {
      "name": "Data science",
      "score": 0.3996905982494354
    },
    {
      "name": "Political science",
      "score": 0.33947300910949707
    },
    {
      "name": "Environmental health",
      "score": 0.32690948247909546
    },
    {
      "name": "Geography",
      "score": 0.2982841730117798
    },
    {
      "name": "Medicine",
      "score": 0.29686403274536133
    },
    {
      "name": "Business",
      "score": 0.21392464637756348
    },
    {
      "name": "Marketing",
      "score": 0.18510273098945618
    },
    {
      "name": "Cartography",
      "score": 0.10271909832954407
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ]
}