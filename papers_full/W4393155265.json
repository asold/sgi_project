{
  "title": "Evaluating Accuracy and Reproducibility of Large Language Model Performance in Pharmacy Education",
  "url": "https://openalex.org/W4393155265",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4315462105",
      "name": "Amoreena Most",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2312047332",
      "name": "Mengxuan Hu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2423763219",
      "name": "Huibo Yang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2306912518",
      "name": "Tianming Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2129160125",
      "name": "Xianyan Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1978672188",
      "name": "Sheng Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098480894",
      "name": "Steven Xu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2103923875",
      "name": "Zhengliang Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2479936372",
      "name": "Andrea Sikora",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4315462105",
      "name": "Amoreena Most",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2479936372",
      "name": "Andrea Sikora",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4320003957",
    "https://openalex.org/W4367365458",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4388583442",
    "https://openalex.org/W4385236544",
    "https://openalex.org/W4387645063",
    "https://openalex.org/W4385018653",
    "https://openalex.org/W4391759824",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4226146865",
    "https://openalex.org/W4391324500",
    "https://openalex.org/W4384389802",
    "https://openalex.org/W2962800603",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W4383311938"
  ],
  "abstract": "Abstract The purpose of this study was to compare performance of ChatGPT (GPT-3.5), ChatGPT (GPT-4), Claude2, Llama2-7b, and Llama2-13b on 219 multiple-choice questions focusing on critical care pharmacotherapy. To further assess the ability of engineering LLMs to improve reasoning abilities and performance, we examined responses with a zero-shot Chain-of-Thought (CoT) approach, CoT prompting, and a custom built GPT (PharmacyGPT). A 219 multiple-choice questions focused on critical care pharmacotherapy topics used in Doctor of Pharmacy curricula from two accredited colleges of pharmacy was compiled for this study. A total of five LLMs were evaluated: ChatGPT (GPT-3.5), ChatGPT (GPT-4), Claude2, Llama2-7b, and Llama2-13b. The primary outcome was response accuracy. Of the five LLMs tested, GPT-4 showed the highest average accuracy rate at 71.6%. A larger variance indicates lower consistency and reduced confidence in its answers. Llama2-13b had the lowest variance (0.070) of all the LLMs, but performed with an accuracy of 41.5%. Following analaysis of overall accuracy, performance on knowledge- vs. skill-based questions were assessed. All five LLMs demonstrated higher accuracy on knowledge-based questions compared to skill-based questions. GPT-4 had the highest accuracy for knowledge- and skill-based questions, with an accuracy of 87% and 67%, respectively. Response accuracy from LLMs in the domain of clinical pharmacy can be improved by using prompt engineering techniques.",
  "full_text": "Evaluating Accuracy and Reproducibility of Large Language Model Performance in \nPharmacy Education  \n \nAmoreena Most, PharmD, BCCCP \nUniversity of Georgia College of Pharmacy, Augusta, GA, USA \n \nMengxuan Hu\n \nSchool of Data Science, University of Virginia, Charlottesville, VA \n \nHuibo Yang \nSchool of Data Science, University of Virginia, Charlottesville, VA \n \nTianming Liu, PhD\n \nDepartment of Computer Science, University of Georgia, Athens, GA \n \nXianyan Chen, PhD \nUniversity of Georgia Statistical Consulting Center, Athens, GA \n \nSheng Li, PhD \nSchool of Data Science, University of Virginia, Charlottesville, VA \n \nTianming Liu, PhD\n \nDepartment of Computer Science, University of Georgia, Athens, GA \n \nSteven Xu \nDepartment of Computer Science, University of Georgia, Athens, GA \n \nZhengliang Liu \nDepartment of Computer Science, University of Georgia, Athens, GA \n \nAndrea Sikora, PharmD, MSCR, BCCCP , FCCM \nsikora@uga.edu \nUniversity of Georgia College of Pharmacy, Department of Clinical and Administrative \nPharmacy, Augusta, GA, USA \n \nConflicts of Interest: The authors have no conflicts of interest.  \n \nFunding: Funding: Funding through Agency of Healthcare Research and Quality for Drs. \nSikora, Most, Li, and Liu was provided through R21HS028485 and R01HS029009. \n \nAcknowledgements: The authors acknowledge William Hsieh for assistance with creating \nfigures for this article.  \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n \nAbstract  \n \nThe purpose of this study was to compare performance of ChatGPT (GPT-3.5), ChatGPT (GPT-\n4), Claude2, Llama2-7b, and Llama2-13b on 219 multiple-choice questions focusing on critical \ncare pharmacotherapy. To further assess the ability of engineering LLMs to improve reasoning \nabilities and performance, we examined responses with a zero-shot Chain-of-Thought (CoT) \napproach, CoT prompting, and a custom built GPT (PharmacyGPT). A 219 multiple-choice \nquestions focused on critical care pharmacotherapy topics used in Doctor of Pharmacy curricula \nfrom two accredited colleges of pharmacy was compiled for this study. A total of five LLMs \nwere evaluated: ChatGPT (GPT-3.5), ChatGPT (GPT-4), Claude2, Llama2-7b, and Llama2-13b. \nThe primary outcome was response accuracy. Of the five LLMs tested, GPT-4 showed the \nhighest average accuracy rate at 71.6%. A larger variance indicates lower consistency and \nreduced confidence in its answers. Llama2-13b had the lowest variance (0.070) of all the LLMs, \nbut performed with an accuracy of 41.5%. Following analaysis of overall accuracy, performance \non knowledge- vs. skill-based questions were assessed. All five LLMs demonstrated higher \naccuracy on knowledge-based questions compared to skill-based questions. GPT-4 had the \nhighest accuracy for knowledge- and skill-based questions, with an accuracy of 87% and 67%, \nrespectively. Response accuracy from LLMs in the domain of clinical pharmacy can be improved \nby using prompt engineering techniques. \n \nKeywords: Large language model; artificial intelligence; pharmacy \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nIntroduction \n \nLarge language models (LLMs) have shown remarkable abilities in the medical domain, \nincluding passing medical licensure exams, diagnosing disease states, and clinical decision \nmaking; however, these task have largely focused on structured diagnostic problems and have \nlimited pharmacy domain testing. level.\n1–3 4 Within the field of clinical pharmacy, the \nperformance of LLMs have been tested for deprescribing benzodiazepines, identifying drug-herb \ninteractions, and performance on a national pharmacist examination, showing early promise.5–8 \nEach year it is estimated over 6.3 billion prescription medications are dispensed and over 7 \nmillion patients will experience a medication error. Given the complexity of medication data and \nability of LLMs to process large datasets, they may serve as an important tool towards making \nmedication use safer. \n \nTable 1. Statement of Significance  \nProblem Large Language Models (LLMs) reasoning processes for \nclinical pharmacy decision making has not been explored and \nremains unknown.   \nWhat is already known LLMs have demonstrated promise in pharmacy tasks but \nrequire further investigation to improve performance in the \nclinical pharmacy domain.  \nWhat this paper adds This paper demonstrates LLM performance on clinical \npharmacy questions can be improved with prompt engineering.  \n \nHowever, most LLMs are trained on data from widely available corpus (e.g., the Internet), which \ncreates the potential for problems in domains marked by highly technical language.\n9 Moreover, \ndeconstructing LLMs reasoning abilities have been identified as a significant challenge.10,11 \nThere have been calls for thoughtful evaluation and regulation of artificial intelligence prior to \nimplementation in the healthcare setting.\n12 Approaches for understanding LLMs reasoning \nprocesses to improve performance include fine-tuning a pre-trained LLM or building a LLM \nwith a custom dataset.13 Limited studies have rigorously explored strategies to benchmark and \nimprove LLM performance in the medication decision-making domain.   \n \nThe purpose of this study was to compare performance of ChatGPT (GPT-3.5), ChatGPT (GPT-\n4), Claude2, Llama2-7b, and Llama2-13b on 219 multiple-choice questions focusing on critical \ncare pharmacotherapy. To further assess the ability of engineering LLMs to improve reasoning \nabilities and performance, we examined responses with a zero-shot Chain-of-Thought (CoT) \napproach, CoT prompting, and a custom built GPT (PharmacyGPT). \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nMethods \n \nData source \n \nA 219 multiple-choice questions focused on critical care pharmacotherapy topics used in Doctor \nof Pharmacy curricula from two accredited colleges of pharmacy was compiled for this study. \nQuestions were written for students in their third-year pharmacy school who participated in \ncritical care elective and pharmacotherapy course. Questions on the following topics were \nassesed: metabolic disorders (26 questions), pain/agitation/delirium (23 questions), respiratory \ndisorders (22 questions), toxicology (20 questions), hemodynamics (17 questions), acid-base (16 \nquestions), neurologic emergencies (14 questions), gastrointestinal disorders (10 questions), \nprophylaxis (10 questions), advanced cardiac life support (9 questions), nutrition (9 questions), \nrenal (9 questions), sedation management (9 questions), fluids (7 questions), anticoagulation \nreversal (4). Of the 219 questions, 27 required calculations based on patient specific parameters \n(e.g., weight, renal function, laboratory parameters). Questions were formatted to have four \nanswer choices and images were converted to textual input. Additionally, questions were further \ncategorized into knowledge- or skill- based, with knowledge questions testing fact recall and \nskill testing application of pharmacy knowledge to simple patient cases. \n \nStudy design \n \nA total of five LLMs were evaluated: ChatGPT (GPT-3.5), ChatGPT (GPT-4), Claude2, Llama2-\n7b, and Llama2-13b. The primary outcome was response accuracy. Secondary outcomes \nincluded response variance and comparison to student performance. To assess consistency of \nresponse, questions were inputted into each LLM five separate times and numeric values were \nassigned (1, 2, 3, 4) to the four answer choices in each question. Variance was calculated from \nthe response accuracy for each individual LLM after the five runs.  \n \nInitialization prompt \n \nInput was standardized to generate output that provided correct answers and explanations. The \nfollowing system prompt was utilized: “This is a midterm exam for the critical care elective \ncourse in pharmacy school. Please select the most correct answer from the following multiple-\nchoice options and give your reason why you chose it. Please follow the following format to \nanswer the question: The correct answer is ____. The reason is ____.”  \n \nZero-Shot Chain-of-Thought  \n \nA Zero-Shot chain-of-thought (CoT) approach was then employed by including “Let’s think step \nby step” in the prompt and requesting the model to output the answer along with the \ncorresponding explanation directly. Zero-Shot CoT was applied to each of the five LLMs and \nwas evaluated in five separate trials. The Zero-Shot CoT LLM answers were compared to the \npretrained LLM to assess if there was improvement in accuracy or variance.  \n \nFew-Shot Chain-of-Thought \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nDue to the complex reasoning required to answer skill-based clinical pharmacy questions, five \nchain-of-thought (CoT) prompts were created to improve LLM accuracy of responses. CoT was \napplied to GPT4 and was evaluated in five separate trials. The CoT prompted GPT-4 answers \nwere compared with the pretrained GPT4 results and Zero-Shot CoT GPT-4 results to assess if \nthere was improvement in accuracy or variance. A full overview of the CoT prompts created and \napplied are available in the supplemental materials.  \nCustomized GPT \n \nChatGPT-4 offers the ability for a user to create a customizable GPT. We built a ChatGPT based \non relevant pharmacy course materials as a proof of concept to improve GPT-4 accuracy and \nreproducibility. These results were then compared to the pretrained non-CoT prompted GPT-4 \nresults and CoT prompted GPT-4 results.  \n \nLLMs to students \n \nStudent performance was available for 120 multiple choice questions. Response accuracy and \nvariance on knowledge- and skill-based questions from the unprompted LLMs (ChatGPT (GPT-\n3.5), ChatGPT (GPT-4), Claude2, Llama2-7b, and Llama2-13b) and GPT-4 engineered with few-\nshot CoT were assessed for the 120 questions and then compared to student performance.  \n \nResults \n \nInitialization prompt \n \nTable 1 shows the performance of five LLMs: ChatGPT (GPT-3.5), ChatGPT (GPT-4), Claude2, \nLlama2-7b, and Llama2-13b accuracy from individual runs and calculated variance after the five \nruns. Of the five LLMs tested, GPT-4 showed the highest average accuracy rate at 71.6%. A \nlarger variance indicates lower consistency and reduced confidence in its answers. Llama2-13b \nhad the lowest variance (0.070) of all the LLMs, but performed with an accuracy of 41.5%. \nFollowing analaysis of overall accuracy, performance on knowledge- vs. skill-based questions \nwere assessed. All five LLMs demonstrated higher accuracy on knowledge-based questions \ncompared to skill-based questions. GPT-4 had the highest accuracy for knowledge- and skill-\nbased questions, with an accuracy of 87% and 67%, respectively.  \n \nPrompt engineering performance \n \nTable 3 presents the response accuracy and variance with a zero-shot CoT approach. All five \nLLMs performed similiarily with a zero-shot COT approach compared to the original \ninitialization prompt used. GPT-4 outperformed the other models with an average accuracy rate \nat 71.6%, while Llama2-7b had the lowest average accuracy rate at 34.5%. As more CoT \nexamples were inputted into the model, accuracy improved while variance increased.  \n \nLLMs to students \n \nGPT-4 with 5 shot CoT had the highest accuracy for knowledge-based questions, and \noutperformed the student average in this domain (91% vs. 84%). Accuracy for both knowledge- \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nand skill based questions improved as additional CoT examples were provided; however, the \nmodels performance even with the highest accuracy for skill-based questions was lower than the \nstudent average (68% vs. 80%).   \n\\ \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nDiscussion  \n \nIn this study, we demonstrate response accuracy of LLMs in the clinical pharmacy domain can \nbe improved through specific prompt engineering techniques. Among the five LLMs assessed in \nthis study (GPT-3.5, GPT-4, Claude2, Llama2-7b, and Llama2-13b), GPT-4 consistently \ndisplayed the highest response accuracy when multiple prompt techniques were employed. When \nquestions were entered without utilizing prompt-engineering techniques, GPT-4 had a response \naccuracy for knowledge-based questions similar to a third year pharmacy student (84%). Use of \nCoT and self-consistency prompting increased GPT-4 response accuracy to outperform pharmacy \nstudents in the domain of knowledge-based pharmacy questions (91% and 93%, respectfully). \nThese prompt engineering techniques showed minimal improvement in response accuracy for \nskill-based questions. To our knowledge, this is the first study to examine multiple prompt \nengineering techniques to improve LLM performance in the field of pharmacy. \n \nAlthough large language models have demonstrated remarkable success across a wide spectrum \nof natural language processing (NLP) tasks, their reasoning abilities have been identified as a \nsignificant challenge.\n10,11 To address this issue, one intuitive approach is to either train a model \nfrom scratch using a dataset augmented with rationales or fine-tune a pre-trained large language \nmodel.\n14 In-context learning draws inspiration from human reasoning patterns when \nencountering a new task. A concise task instruction (e.g., \"Please help me add the last two \nnumbers in an array together and return the result.\") or a few related examples (e.g., \"For an \narray [2,5,6,8], the result is 14.\") are often sufficient for humans to successfully complete the \ntask to a satisfactory degree.\n15 Recent research endeavors have proposed in-context learning \nstrategies, such as zero-shot CoT and CoT prompting, to enhance the reasoning capacity of \nLLMs.\n15,16 \n \nPrevious research has demonstrated LLMs are capable of zero-shot reasoning, suggesting that a \nsimple zero-shot prompt such as \"Let’s think step by step\" after each query can guide LLMs to \nanswer questions in a CoT manner.17 The zero-shot CoT approach is an efficient method to \nmodel training as it eliminates the need for manually crafting intricate task-specific prompts for \ndifferent tasks. In this study, model performance was similar with the original initialization \nprompt and when a zero-shot CoT approach was employed. Given our initialization prompt \nasked for reasoning to be provided with the output, it likely served as a modified zero-shot CoT \napproach and can explain why minimal difference was seen. CoT prompting provides carefully \ndesigned CoT examples to the LLM, allowing the LLMs to decompose a complex reasoning \nquery into multiple steps and solve them step by step. Our study demonstrated that CoT \nprompting can improve LLM response. As additional CoT prompts were inputted into the LLM, \nperformance improved in a linear fashion. Further research should focus on strategies to optimize \nCoT prompting examples and improve LLM performance. \n \nIn our study, all LLMs tested consistently demonstrated higher accuracy in answering \nknowledge-based questions when compared to skill-based questions. Knowledge-based \nquestions are well-defined and widely accessible in textbooks and online resources, which LLMs \nhave been trained on. In contrast, skill-based questions require reasoning abilities. Significant \nbarriers to integrating LLMs into the healtcare system exist, including _xyz. Previous studes \nhave demonstrated performance of ChatGPT on medical exams varies depending upon the \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nspecialty, with ChatGPT achieving a passing grade on Neurosurgery board finals yet failing a \ngastroenterology board-like examination.18 As the potential of LLMs to serve as a clinical \ndecision support tool in the medical field continues to evolve, further research is needed to \naddress the current limitations of their clinical reasoning capabilities. \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nConclusion  \nResponse accuracy from LLMs in the domain of clinical pharmacy can be improved by using \nprompt engineering techniques. LLMs have demonstrated potential to serve as clinical pharmacy \ndecision making tool. Future research is needed to optimize prompt engineering strategies and \nimprove clinical pharmacy reasoning capabilities of LLMs.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \nReferences  \n \n1. Chowdhery A, Narang S, Devlin J, et al. PaLM: Scaling Language Modeling with Pathways. \nPublished online October 5, 2022. doi:10.48550/arXiv.2204.02311 \n2. Liang P, Bommasani R, Lee T, et al. Holistic Evaluation of Language Models. Published \nonline October 1, 2023. doi:10.48550/arXiv.2211.09110 \n3. Yang J, Jin H, Tang R, et al. Harnessing the Power of LLMs in Practice: A Survey on \nChatGPT and Beyond. Published online April 27, 2023. doi:10.48550/arXiv.2304.13712 \n4. Sallam M. ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic \nReview on the Promising Perspectives and Valid Concerns. Healthc Basel Switz. \n2023;11(6):887. doi:10.3390/healthcare11060887 \n5. Bužan\nč ić  I, Belec D, Držaić  M, et al. Clinical decision making in benzodiazepine \ndeprescribing by HealthCare Providers vs AI-assisted approach. Br J Clin Pharmacol. \nPublished online November 10, 2023. doi:10.1111/bcp.15963 \n6. Hsu HY , Hsu KC, Hou SY , Wu CL, Hsieh YW, Cheng YD. Examining Real-World \nMedication Consultations and Drug-Herb Interactions: ChatGPT Performance Evaluation. \nJMIR Med Educ. 2023;9:e48433. doi:10.2196/48433 \n7. Kunitsu Y . The Potential of GPT-4 as a Support Tool for Pharmacists: Analytical Study Using \nthe Japanese National Examination for Pharmacists. JMIR Med Educ. 2023;9:e48452. \ndoi:10.2196/48452 \n8. Liu Z, Wu Z, Hu M, et al. PharmacyGPT: The AI Pharmacist. Published online July 20, 2023. \ndoi:10.48550/arXiv.2307.10432 \n9. Ma C, Wu Z, Wang J, et al. ImpressionGPT: An Iterative Optimizing Framework for \nRadiology Report Summarization with ChatGPT. IEEE Trans Artif Intell. Published online \n2024:1-12. doi:10.1109/TAI.2024.3364586 \n10. Wei J, Wang X, Schuurmans D, et al. Chain-of-Thought Prompting Elicits Reasoning in \nLarge Language Models. Published online January 10, 2023. doi:10.48550/arXiv.2201.11903 \n11. Rae JW, Borgeaud S, Cai T, et al. Scaling Language Models: Methods, Analysis & \nInsights from Training Gopher. Published online January 21, 2022. \ndoi:10.48550/arXiv.2112.11446 \n12. Ayers JW, Desai N, Smith DM. Regulate Artificial Intelligence in Health Care by \nPrioritizing Patient Outcomes. JAMA. 2024;331(8):639-640. doi:10.1001/jama.2024.0549 \n13. Naveed H, Khan AU, Qiu S, et al. A Comprehensive Overview of Large Language \nModels. Published online November 2, 2023. doi:10.48550/arXiv.2307.06435 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n14. Ling W, Yogatama D, Dyer C, Blunsom P. Program Induction by Rationale Generation: \nLearning to Solve and Explain Algebraic Word Problems. In: Barzilay R, Kan MY , eds. \nProceedings of the 55th Annual Meeting of the Association for Computational Linguistics \n(Volume 1: Long Papers). Association for Computational Linguistics; 2017:158-167. \ndoi:10.18653/v1/P17-1015 \n15. Brown TB, Mann B, Ryder N, et al. Language Models are Few-Shot Learners. Published \nonline July 22, 2020. doi:10.48550/arXiv.2005.14165 \n16. Language models are unsupervised multitask learners | BibSonomy. Accessed March 20, \n2024. https://www.bibsonomy.org/bibtex/61ea7e007d6c95171a2ff3396b1af7d9 \n17. Kojima T, Gu SS, Reid M, Matsuo Y , Iwasawa Y . Large Language Models are Zero-Shot \nReasoners. Published online January 29, 2023. doi:10.48550/arXiv.2205.11916 \n18. Smith J, Choi PM, Buntine P . Will code one day run a code? Performance of language \nmodels on ACEM primary examinations and implications. Emerg Med Australas. \n2023;35(5):876-878. doi:10.1111/1742-6723.14280 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nTable 1. Response accuracy and variance of LLMs \nLLM Accuracy-\nRun1  \nAccuracy-\nRun2 \nAccuracy-\nRun3 \nAccuracy-\nRun4 \nAccuracy-\nRun5 \nAccuracy-\nALL \nVariance-\nALL \nChatGPT-\n3.5 \n0.559  0.536 0.518 0.550 0.545 0.542 0.304 \nChatGPT-\n4 \n0.732 0.705 0.714 0.727 0.705 0.716 0.135 \nClaude2 0.609  0.609 0.623 0.618 0.618 0.615 0.090 \nLlama2-\n7b \n0.364 0.382 0.364 0.350 0.355 0.3627 0.210 \nLlama2-\n13b \n \n0.400 0.400 0.445 0.418 0.414 0.415 0.070 \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \nTable 2. Response accuracy and variance of LLMs answering skill vs. knowledge based \nquestions \nLLM Accuracy-\nknowledge \nAccuracy-skill Variance-\nknowledge \nVariance-skill \nChatGPT-3.5 0.69 0.50 0.22 0.33 \nChatGPT-4 0.87 0.67 0.08 0.15 \nClaude2 0.75 0.57 0.88 0.09 \nLlama2-13b \n \n0.51 0.39 0.06 0.07 \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \nTable 3. Response accuracy and variance of LLMs with zero-shot CoT \nLLM Accuracy-\nRun1  \nAccuracy-\nRun2 \nAccuracy-\nRun3 \nAccuracy-\nRun4 \nAccuracy-\nRun5 \nAccuracy-\nALL \nVariance-\nALL \nChatGPT-\n3.5 \n0.550 0.536 0.532 0.568 0.541 0.545 0.329 \nChatGPT-\n4 \n0.731 0.705 0.714 0.727 0.705 0.716 0.138 \nClaude2 0.595 0.595 0.618 0.600 0.605 0.603 0.080 \nLlama2-\n7b \n0.350 0.3455 0.336 0.336 0.355 0.345 0.137 \nLlama2-\n13b \n \n0.386 0.423 0.405 0.423 0.414 0.410 0.095 \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \nTable 4. Comparison of LLMs to student performance  \n Accuracy-knowledge Accuracy-skill Variance-\nknowledge \nVariance-skill \nStudent 0.84 0.80 - - \nChatGPT-3.5 0.68 0.45 0.20 0.34 \nChatGPT-4 0.84 0.60 0.08 0.19 \nChatGPT-4-1S 0.87 0.65 0.01 0.10 \nChatGPT-4-3S 0.90 0.68 0.01 0.18 \nChatGPT-4-5S 0.91 0.67 0.09 0.24 \nClaude2 0.73 0.55 0.02 0.13 \nLlama2-7b 0.38 0.32 0.10 0.17 \nLlama2-13b 0.48 0.36 0.05 0.10 \nSelf-consistent 0.93 0.68 - - \nAcronyms: ChatGPT-4-1S, GPT-4 with 1 shot CoT; ChatGPT-4-3S, GPT-4 with 3 shot CoT;  \nChatGPT-4-5S, GPT-4 with 5 shot CoT \nOnly 120 multiple choice questions were used to comopare LLM to student performance given \nlimited data availability for student scores \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \nFigure 1. Study methodology \n \n \n \n \n \n \n \n \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \nFigure 2. Response accuracy across few shot CoT \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \nFigure 3. Response variance across few shot CoT \n \n \n \n \n \n \n \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \nFigure 4. Response accuracy across LLMs and students \n \n \n \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nFigure 5. \n \n \n \n \n \n \n \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \n \nFigure 6. Prompt engineering example \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nINPUT \nAn 86 YO male presents to the Emergency Department with pneumonia and respiratory failure requiring \nmechanical ventilation.  PMH: COPD, osteoarthritis, CAD, and depression. Inpatient medications: \npropofol 20ml/hr, levofloxacin 750mg IV Q24h, famotidine 40mg IV BID, fentanyl 25mcg IV Q2h \nPRN, lorazepam 0.5mg IV Q8h PRN anxiety. Using the following instructions, calculate the kcal/day \nneeded from lipids to give within the TPN:  TPN to provide: 2200 total kcal/day, 125 g of protein, Lipids \nto make up 30% of non-protein kcals, Dextrose to make up 70% of non-protein kcals.  \na) 660 kcal/day  \nb) 510 kcal/day  \nc) 317 kcal/day  \nd) None; propofol is providing enough fat to meet TPN goals \nOUTPUT \nThe total kcal/day needed from lipids to be given within the TPN for this patient is 510 kcal/day. Therefore, the \ncorrect answer is: \nb) 510 kcal/day LLM fails to recognize propofol contributes to total kcal/day for lipids.  \nPROMPT \nDid you consider if any medications are contributing to total kcal/day needed for lipids? \nOUTPUT \nYou're correct to consider the impact of medications on the total kcal/day needed from lipids in Total Parenteral \nNutrition (TPN). In the patient's medication list, Propofol stands out as a relevant factor. Propofol is an intravenous \nsedative commonly used in mechanically ventilated patients, and it's formulated in a lipid emulsion. Each 1 ml of \nPropofol contains approximately 1.1 kcal from lipids. \nGiven that the patient is receiving Propofol at a rate of 20 ml/hr, we need to account for the additional lipid calories \nfrom this source: \n1. Calculate the total daily lipid kcal from Propofol: \n20 ml/hr×24 hrs/day×1.1 kcal/ml20 ml/hr×24 hrs/day×1.1 kcal/ml \n2. Subtract this value from the required lipid kcal/day in the TPN to determine if additional lipids are needed \nin the TPN. \nLet's do the calculations. \n1. Calculate Total Daily Lipid kcal from Propofol: The patient is receiving Propofol at 20 ml/hr. Each ml of \nPropofol provides approximately 1.1 kcal. Over 24 hours, the calculation is: \n20 ml/hr×24 hrs/day×1.1 kcal/ml20 ml/hr×24 hrs/day×1.1 kcal/ml \n20×24×1.1=528 kcal/day20×24×1.1=528 kcal/day \n2. Determine if Additional Lipids are Needed in TPN: Earlier, we calculated the required lipid kcal from \nTPN as 510 kcal/day. Now, we subtract the lipid kcal provided by Propofol: \n510 kcal/day−528 kcal/day510 kcal/day−528 kcal/day \nIf this result is negative, it implies that Propofol alone is providing sufficient lipid calories, and no additional lipids \nare needed in the TPN. If it's positive, additional lipids would be required. \nLet's compute this: 510−528=−18 kcal/day510−528=−18 kcal/day \nSince the result is negative, Propofol is providing enough fat to meet the TPN goals for lipids. Therefore, the correct \nanswer is option (d) - None; propofol is providing enough fat to meet TPN goals. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \nSupplemental \n \n \nChain-of-thought examples provided to LLMs: \n \n \n1. Q: A 62-year-old male (70 kg) with no significant past medical history is admitted to the \nMedical ICU for acute hypoxic respiratory failure secondary to hospital acquired \npneumonia. Current CrCl = 20 mL/min. Vancomycin and piperacillin/tazobactam are \nstarted for empiric antimicrobial coverage. How much vancomycin should be \nadministered for the initial dose? \na) 1000 mg \nb) 1250 mg \nc) 1750 mg \nd) 2250 mg  \nA: The recommended loading dose of vancomycin is 25 mg/kg in patients who are \ncritically ill, regardless of renal function. 70 kg x 25 mg/kg = 1750 mg. The initial dose \nof vancomycin should be 1750 mg, therefore the correct answer is C.  \n \n2. Q: A 91-year-old female (80 kg, 5’2”) presents to the Emergency Department from a \nskilled nursing facility with altered mental status. Initial vitals: BP 81/43, HR 135, RR \n24, Temp 102.1 (F). How much fluid should the patient initially receive for suspected \nsepsis? \na) 1250 mL \nb) 1500 mL \nc) 1750 mL \nd) 2000 mL \nA: The recommended minimum amount of crystalloid fluid resuscitation for a patient \npresenting with sepsis is 30 mL/kg based on ideal body weight. The patient’s ideal body \nweight is 50 kg. 30 mL/kg x 50 kg = 1500 mL. The initial amount of fluid the patient \nshould receive is 1500 mL, therefore the correct answer is B. \n \n3. Q: A 53-year-old male (110kg) is on hour 52 of admission to the Surgical ICU after an \nemergent exploratory laparotomy. Throughout his admission he has received 2 liters of \nIV fluids, started on TPN at 42 mL/hr (has received for 24 hours), has had a urine output \nof 0.5 cc/kg/hr, and 500 mL output from his nasogastric tube. What is the patient’s net \nfluid balance?  \na) -322 mL \nb) -332 mL \nc) -342 mL \nd) -352 mL \nA: The patient’s total fluid intake is the sum of the IV fluids he received from IV fluids \nand TPN. He has received TPN at 42 mL/hr for 24 hours. 42 x 24 = 1008 mL. His total \nfluid intake is 3008 mL when adding up IV fluids and TPN fluids. The patient’s total \nfluid output is the sum of urine and nasogastric output. We will assume his urine output \nhas remained the same throughout the 52 hours of admission to the surgical ICU. 0.5 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint \ncc/kg/hr x 110 kg x 52 hours = 2860 mL. His total fluid output is 3360 when adding up \nurine and nasogastric output. Net fluid balance = Total intake – Total output. 3008-3360 \n= -352 mL, therefore the correct answer is D.  \n \n4. Q: A 68 year-old-female (92 kg) is admitted to the Cardiac ICU for cardiogenic shock. \nPMH: HFrEF (EF 25%), HLD, anxiety, PE. She is currently mechanically ventilated. \nMedications: Nitroprusside 0.5 mcg/kg/min, furosemide 80 mg/hr, IV famotidine 20 mg \nBID, midazolam 4 mg/hr, fentanyl 100 mcg/hr, heparin 18u/kg/hr. Current CPOT: 1, \nRASS -4. Based on this information, how should her sedation be managed? \na) Do not adjust fentanyl infusion, decrease midazolam infusion. Target RASS of -2 to \n+1 \nb) Increase fentanyl infusion, do not adjust midazolam infusion. Target RASS of -5 \nc) Do not adjust fentanyl infusion, decrease midazolam infusion. Target RASS of -3 to -\n2 \nd) Decrease fentanyl infusion, do not adjust midazolam infusion. Target RASS of +2 to \n+3 \nA: Light sedation is recommended for critically ill, mechanically ventilated adults unless \ndeep sedation is required (ie, when neuromuscular blockade is indicated). Light sedation \nis defined as a RASS of -2 to +1. The patient’s current RASS is -4, which indicates she is \ntoo heavily sedated. Therefore, her fentanyl infusion or midazolam infusion needs to be \ndecreased. Since her current CPOT is 1 indicating her pain is likely minimal or not \npresent, her fentanyl infusion should not be adjusted. Her midazolam infusion should be \ndecreased until a RASS of -2 to +1 is reached, therefore the correct answer is A.  \n \n5. Q: A 75-year-old female (65 kg, 5’4”) is admitted to the Neuro ICU for status epilepticus. \nHome medications: Aspirin 81 mg, atorvastatin 80 mg daily, sertraline 100 mg daily, \nphenytoin 100 mg TID. Phenytoin level upon arrival to ICU: 7 mcg/mL. How much IV \nphenytoin should be administered to achieve a target level of 18 mcg/mL?  \na) 450 mg \nb) 475 mg \nc) 500 mg \nd) 525 mg \nA:  Standard volume of distribution (Vd) of phenytoin is 0.7 L/kg. Vd = 0.7L/kg x 65 kg \n= 45.5 L. Dose (mg) = Vd x (Desired concentration – Measure concentration). 45.5 x (18-\n7) = 500.5 mg. The patient should receive IV phenytoin 500 mg (rounded to nearest \ntenth) for a desired concentration of 18, therefore the correct answer is C. \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 24, 2024. ; https://doi.org/10.1101/2024.03.21.24304667doi: medRxiv preprint ",
  "topic": "Reproducibility",
  "concepts": [
    {
      "name": "Reproducibility",
      "score": 0.8261417746543884
    },
    {
      "name": "Pharmacy",
      "score": 0.7093232274055481
    },
    {
      "name": "Computer science",
      "score": 0.5313416719436646
    },
    {
      "name": "Natural language processing",
      "score": 0.3799985647201538
    },
    {
      "name": "Statistics",
      "score": 0.2834688425064087
    },
    {
      "name": "Medicine",
      "score": 0.23298346996307373
    },
    {
      "name": "Mathematics",
      "score": 0.1790885031223297
    },
    {
      "name": "Family medicine",
      "score": 0.08784765005111694
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I25041050",
      "name": "Augusta University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I138220800",
      "name": "Georgia College & State University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I165733156",
      "name": "University of Georgia",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I51556381",
      "name": "University of Virginia",
      "country": "US"
    }
  ]
}