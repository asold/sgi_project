{
  "title": "Multi-class hate speech detection in the Norwegian language using FAST-RNN and multilingual fine-tuned transformers",
  "url": "https://openalex.org/W4393054218",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5094004425",
      "name": "Ehtesham Hashmi",
      "affiliations": [
        "Norwegian University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2227656535",
      "name": "Sule Yildirim Yayilgan",
      "affiliations": [
        "Norwegian University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5094004425",
      "name": "Ehtesham Hashmi",
      "affiliations": [
        "Norwegian University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2227656535",
      "name": "Sule Yildirim Yayilgan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4213259260",
    "https://openalex.org/W4365420418",
    "https://openalex.org/W3131201641",
    "https://openalex.org/W4386321672",
    "https://openalex.org/W3118361918",
    "https://openalex.org/W4321351392",
    "https://openalex.org/W2908323419",
    "https://openalex.org/W4211082265",
    "https://openalex.org/W4317566631",
    "https://openalex.org/W6604963970",
    "https://openalex.org/W6756821666",
    "https://openalex.org/W4304098281",
    "https://openalex.org/W2595653137",
    "https://openalex.org/W6702248584",
    "https://openalex.org/W3094479746",
    "https://openalex.org/W2906979176",
    "https://openalex.org/W2785615365",
    "https://openalex.org/W2963793818",
    "https://openalex.org/W3081483437",
    "https://openalex.org/W4285799181",
    "https://openalex.org/W4324122926",
    "https://openalex.org/W4380367902",
    "https://openalex.org/W3172559340",
    "https://openalex.org/W4220738400",
    "https://openalex.org/W3211048962",
    "https://openalex.org/W4362700245",
    "https://openalex.org/W6601795639",
    "https://openalex.org/W2970738028",
    "https://openalex.org/W3124917515",
    "https://openalex.org/W4313528095",
    "https://openalex.org/W4313531555",
    "https://openalex.org/W4292259045",
    "https://openalex.org/W4378364766",
    "https://openalex.org/W4323838292",
    "https://openalex.org/W4385679668",
    "https://openalex.org/W2340954483",
    "https://openalex.org/W3207934453",
    "https://openalex.org/W4322421454",
    "https://openalex.org/W2982222442",
    "https://openalex.org/W4388623722",
    "https://openalex.org/W3099150152",
    "https://openalex.org/W4285198027",
    "https://openalex.org/W3210610489",
    "https://openalex.org/W4391156274",
    "https://openalex.org/W2740168486",
    "https://openalex.org/W6601104142",
    "https://openalex.org/W4367846894",
    "https://openalex.org/W4292858715",
    "https://openalex.org/W4311922112",
    "https://openalex.org/W4282008595",
    "https://openalex.org/W4387532351",
    "https://openalex.org/W2563826943",
    "https://openalex.org/W2473555522",
    "https://openalex.org/W4301020662",
    "https://openalex.org/W3217121078"
  ],
  "abstract": "Abstract The growth of social networks has provided a platform for individuals with prejudiced views, allowing them to spread hate speech and target others based on their gender, ethnicity, religion, or sexual orientation. While positive interactions within diverse communities can considerably enhance confidence, it is critical to recognize that negative comments can hurt people’s reputations and well-being. This emergence emphasizes the need for more diligent monitoring and robust policies on these platforms to protect individuals from such discriminatory and harmful behavior. Hate speech is often characterized as an intentional act of aggression directed at a specific group, typically meant to harm or marginalize them based on certain aspects of their identity. Most of the research related to hate speech has been conducted in resource-aware languages like English, Spanish, and French. However, low-resource European languages, such as Irish, Norwegian, Portuguese, Polish, Slovak, and many South Asian, present challenges due to limited linguistic resources, making information extraction labor-intensive. In this study, we present deep neural networks with FastText word embeddings using regularization methods for multi-class hate speech detection in the Norwegian language, along with the implementation of multilingual transformer-based models with hyperparameter tuning and generative configuration. FastText outperformed other deep learning models when stacked with Bidirectional LSTM and GRU, resulting in the FAST-RNN model. In the concluding phase, we compare our results with the state-of-the-art and perform interpretability modeling using Local Interpretable Model-Agnostic Explanations to achieve a more comprehensive understanding of the model’s decision-making mechanisms.",
  "full_text": "Complex & Intelligent Systems (2024) 10:4535–4556\nhttps://doi.org/10.1007/s40747-024-01392-5\nORIGINAL ARTICLE\nMulti-class hate speech detection in the Norwegian language using\nFAST-RNN and multilingual ﬁne-tuned transformers\nEhtesham Hashmi 1 · Sule Yildirim Yayilgan 1\nReceived: 18 December 2023 / Accepted: 12 February 2024 / Published online: 21 March 2024\n© The Author(s) 2024\nAbstract\nThe growth of social networks has provided a platform for individuals with prejudiced views, allowing them to spread hate\nspeech and target others based on their gender, ethnicity, religion, or sexual orientation. While positive interactions within\ndiverse communities can considerably enhance conﬁdence, it is critical to recognize that negative comments can hurt people’s\nreputations and well-being. This emergence emphasizes the need for more diligent monitoring and robust policies on these\nplatforms to protect individuals from such discriminatory and harmful behavior. Hate speech is often characterized as an\nintentional act of aggression directed at a speciﬁc group, typically meant to harm or marginalize them based on certain aspects\nof their identity. Most of the research related to hate speech has been conducted in resource-aware languages like English,\nSpanish, and French. However, low-resource European languages, such as Irish, Norwegian, Portuguese, Polish, Slovak, and\nmany South Asian, present challenges due to limited linguistic resources, making information extraction labor-intensive. In\nthis study, we present deep neural networks with FastText word embeddings using regularization methods for multi-class hate\nspeech detection in the Norwegian language, along with the implementation of multilingual transformer-based models with\nhyperparameter tuning and generative conﬁguration. FastText outperformed other deep learning models when stacked with\nBidirectional LSTM and GRU, resulting in the FAST-RNN model. In the concluding phase, we compare our results with the\nstate-of-the-art and perform interpretability modeling using Local Interpretable Model-Agnostic Explanations to achieve a\nmore comprehensive understanding of the model’s decision-making mechanisms.\nKeywords Hate speech · Norwegian language · Natural language processing · Deep Learning · Transformers · Interpretability\nmodeling\nIntroduction\nThe complexity and challenges of hate speech in the\ndigital era\nAs digital technology advances, the era of social computing\nhas signiﬁcantly enhanced the way individuals interact, espe-\ncially noticeable in the use of social media platforms and chat\nforums [ 30]. The concept of Hate Speech (HS), often veiled\nin complexity, holds diverse interpretations across regions\nB Ehtesham Hashmi\nhashmi.ehtesham@ntnu.no\nSule Yildirim Yayilgan\nsule.yildirim@ntnu.no\n1 Department of Information Security and Communication\nTechnology (IIK), Norwegian University of Science and\nTechnology (NTNU), Teknologivegen 22, 2815 Gjøvik,\nInnlandet, Norway\nand cultures, presenting signiﬁcant hurdles in its detection\nand control, particularly in our digital age. HS appears in\nseveral forms [ 12], including cyberbullying [ 71], ﬂaming\n[47], profanity [ 25], abusive language [ 50], toxicity [ 58], and\ndiscrimination [ 72]. While there is no universally accepted\ndeﬁnition of HS, Nobata et al. [ 48] presented the most widely\naccepted: \"any form of communication that denigrates a spe-\nciﬁc group of individuals based on attributes such as race,\ncolor, ethnicity, gender, sexual orientation, nationality, reli-\ngion, or other distinguishing characteristics\". Several studies\nalign on a similar depiction of HS; [ 16, 34, 63, 65], charac-\nterizing it as an intentional act of hostility towards a speciﬁc\ngroup, inﬂuenced by real or perceived characteristics that\nconstitute the group’s identity. The huge increase in disparag-\ning remarks on Twitter and other cyber platforms is leading to\nphysical violence in the real world. As a result, the research\ncommunity considers the automated detection of hate-related\ncontent on Twitter as a signiﬁcant challenge [ 76]. Online HS\n123\n4536 Complex & Intelligent Systems (2024) 10:4535–4556\nis at the junction of various societal disputes [ 26]. It demon-\nstrates the revolutionary impact of technology by bringing\nboth opportunities and difﬁculties. It is difﬁcult to attain a\nbalance between fundamental rights [ 27], such as freedom\nof expression [ 11], and the defense of human dignity.\nRegulatory measures and the global response to\nonline hate speech\nMaintaining a safe and pleasant online environment may be\nextremely difﬁcult because of how ampliﬁed such behav-\nior can become when there is anonymity and disconnection\nfrom consequences in the real world [ 51]. Effective and accu-\nrate methods to identify and resolve these problems require\nimmediate and keen attention because of their rapid growth\nand the nature of evolution. As the custodian of freedom of\nexpression, UNESCO actively promotes mutual understand-\ning through all forms of mass communication, including the\nInternet and social media [ 23, 40]. On the 31st of May 2016,\na voluntary code to stop illegal HS online was introduced as\na result of cooperation between the European Commission\nand Information Communications Technology (ICT) com-\npanies. This program mandates the removal of all content\nthat aligns with the deﬁnition of HS as set forth by the Euro-\npean Union (E-U) [ 4]. With the outbreak of the COVID-19\npandemic, there has been a worldwide increase in HS and\ndiscrimination, prompting governments at all levels, from\nlocal to national, to emphasize the signiﬁcance of community\nresilience. Furthermore, the impact of hatred and misinfor-\nmation during the pandemic has been seen all around the\nworld [ 19, 33]. The EU has established measures to con-\ntrol how external ﬁrms interact and combat the spread of\nhatred and its code of conduct has shown signiﬁcant improve-\nment in recent years.\n1 These guidelines explicitly state that\nit is unlawful to participate in any activity that encourages or\nincites violence against a group or an individual, identiﬁable\nby characteristics, such as race, skin color, religion, ances-\ntry, or cultural association [ 28]. The following ﬁgures; 1, 2\ndepict hate crime incidents in the US. From 2007 to 2020, an\nincreased tendency was seen; however, stability was recorded\nfrom 2020 to 2021, indicating potential advances in handling\nhate.\nThis paper seeks to detect the HS for the Norwegian\ndataset by incorporating Deep Learning (DL) and multilin-\ngual transformer-based models with hyperparameter tuning.\nNext, the contributions of this research work are summarized,\nfollowed by how the rest of the paper is organized.\n1 https://european-union.europa.eu/principles-countries-history/\nprinciples-and-values/aims-and-values_en\nFig. 1 Hate crime (2007–2020)\nFig. 2 Hate crime (2020–2021)\nWork contributions\nThe contributions of this paper are as follows.\n1. In this paper, our primary contribution is the reﬁnement\nand application of established HS detection methodolo-\ngies through the use of regularization methods, hyper-\nparameter tuning, and generative conﬁgurations. This\napproach has been meticulously applied to a baseline\ndataset in the Norwegian dialect, which includes class\ncategories like neutral, provocative, offensive, moder-\nately hateful, and hateful. The aim is to signiﬁcantly\nenhance HS detection capabilities speciﬁcally for the\nNorwegian language and within these distinct categories.\n2. In addressing our classiﬁcation problem, we strategically\nemployed supervised FastText embeddings, offering dis-\ntinct advantages over unsupervised FastText and other\nword embeddings. The supervised FastText embeddings\nare ﬁne-tuned to the nuances of Norwegian HS data,\ncapturing domain-speciﬁc context and enhancing the per-\nformance of sequential DL-based models, which include\nLong Short-Term Memory (LSTM), Gated Recurrent\nUnit (GRU), and Convolutional Neural Network (CNN).\n123\nComplex & Intelligent Systems (2024) 10:4535–4556 4537\n3. We performed state-of-the-art multilingual transformer-\nbased models, such as Multilingual Bidirectional Encoder\nRepresentations from Transformers (mBERT), ELEC-\nTRA, and FLAN-T5, along with Norwegian Language\nModels (LMs) like Nor-T5, Nor-BERT, Scandi-BERT,\nand nb-BERT. Notably, these Norwegian LMs, previ-\nously unexplored in the context of HS detection, were\nutilized with the implementation of hyperparameter tun-\ning to optimize their performance for our task.\n4. This work involves the implementation of prompt-based\nﬁne-tuning using two different techniques, including\nfew-shot and full ﬁne-tuning with generative conﬁgura-\ntion. This approach allows us to harness the power of\ntransformer-based models and adapt them to our speciﬁc\ntask.\n5. Based on the best performance of Bidirectional LSTM\nand GRU (BiLSTM-GRU), we compared our results\nwith the baseline study and performed the interpretabil-\nity modeling with Local Interpretable Model-Agnostic\nExplanations (LIME) to achieve a more comprehensive\nunderstanding of the model’s decision-making mecha-\nnisms.\nStructure of the paper\nThe rest of the paper is structured as follows: Sect. 2 discusses\nthe existing research work on HS. Section 3 explains the\nproposed work methodology. Section 4 focuses on the results\nand discussions. Section 5 is based on the comparison of the\nresults with the baseline methods. Section 6 is related to the\ninterpretability modeling with LIME. Section 7 presents the\nconclusion and future work.\nRelated work\nRecent advancements in Artiﬁcial Intelligence (AI) and\nNatural Language Processing (NLP) have heightened the\nprominence of HS detection, leading to the development of\nvarious innovative methods in this ﬁeld [ 43]. These tech-\nniques enhance the understanding of HS and its implications,\nincluding monitoring social media and analyzing public dis-\ncourse. Moreover, the primary focus of these studies has been\non well-resourced languages such as English. This emphasis\non languages with abundant resources has created a disparity\nin hate speech research, especially for languages with fewer\nresources, such as Irish, Portuguese, Norwegian, and various\nSouth Asian languages [ 5].\nMachine learning-based methods\nH. Elzayady et al. [ 18] introduced a method for detect-\ning HS in Arabic dialects using a combination of classical\nmachine learning (ML) and DL-based approaches in two\nphases, incorporating personality traits. In the ﬁrst phase, the\nAraPersonality dataset was used, applying correlation valida-\ntion between personality traits and HS. In the second phase,\nthe Term Frequency-Inverse Document Frequency (TF-IDF)\nwas used for feature extraction. These features were then\ninput into ML models, including Decision Tree (DT) [ 15],\nRandom Forest (RF), Logistic Regression (LR), Support V ec-\ntor Machine, and Extreme Gradient Boosting (XGBoost),\nalongside DL models, such as CNN, LSTM, BiLSTM, and\nGRU. In their research, Mittal et al. [ 45] focused on HS detec-\ntion in the English language using an ML-based approach.\nThey employed the XGBoost model with a Count V ectorizer\n(CV) for feature extraction. Additionally, they integrated the\nLIME model to interpret the predictions made by the machine\nlearning algorithm. Their methodology achieved an F1-score\nof 0.94, demonstrating its effectiveness.\nWilliam et al. [ 75] addressed a tertiary classiﬁcation\nproblem in HS detection using ML-based methods. They\nemployed both TF-IDF Word2V ec for feature extraction,\nﬁnding that TF-IDF yielded better results compared to\nWord2V ec embeddings. The study implemented various\nmodels, including SVM, RF, AdaBoost, and KNN. Among\nthese, SVM was found to outperform the other models in\nterms of accuracy. In their study, Akuma et al. [ 1] analyzed\na dataset of HS and offensive language from kaggle\n2 using\nfour ML-based algorithms: KNN, DT, LR, and NB, along\nwith two distinct word embeddings, BoW and TF-IDF. Their\nwork showed that DT when integrated with TF-IDF achieved\nthe best accuracy score of 0.92 when compared to the other\nmodels in their research. A. Khanday et al. [ 32] conducted HS\ndetection on Twitter using COVID-19-related tweets, apply-\ning ML and ensemble learning techniques with TF-IDF and\nBoW. They collected 30,000 tweets during the pandemic,\nof which 11,000 were annotated as containing hate-related\ncontent. The Stochastic Gradient Boosting (SGB) classiﬁer\nemerged as the most effective, achieving an accuracy and\nF1-score of 0.98.\nDeep learning and transformer-based methods\nSaleh et al. [ 61] conducted binary classiﬁcation for HS detec-\ntion using BiLSTM and the transformer-based model BERT.\nTheir research included three publicly available datasets: [ 16,\n73, 74]. They employed three different types of embeddings:\ndomain-speciﬁc, Word2V ec, and Global V ectors for Word\nRepresentation (GloV e) Word embeddings. The BERT model\nachieved a 96% F1-score on a combined balanced dataset,\noutperforming other DL-based methods. S. Nagar et al. [ 46]\nintroduced a novel approach for HS, utilizing two pub-\n2 https://www.kaggle.com/datasets/mrmorj/hate-speech-and-\noffensive-language-dataset\n123\n4538 Complex & Intelligent Systems (2024) 10:4535–4556\nlicly available datasets [ 21] and [ 22]. Their proposed model,\nnamed the V ariational Graph Auto-Encoder (VGAC), lever-\nages multi-modal data by combining two distinct features:\nthe textual content of tweets and the social network structure\nof the users who posted them. Initially, the text from a tweet\nis encoded using a chosen text encoder, and then, it under-\ngoes further processing with a Fully Forward Neural Network\n(FFNN). Concurrently, the user’s features, which include the\nsocial network structure, language usage, and metadata, are\nencoded using a social network encoder. By integrating the\nencoded text and user features, their framework aims to com-\nprehensively understand the context of a tweet. Khan et al.\n[31] presented a deep neural network architecture for sen-\ntiment categorization in code-mixed texts. CNN layers are\nutilized for feature selection, and LSTM layers are applied\nto capture long-term dependencies in textual input. They also\nused several word embedding techniques, such as Word2V ec\nContinuous Bag of Words (CBoW), GLOVE, and FastText.\nA similar approach was used by Nagra et al. [ 46] where they\nconducted SA at the sentence level for RU using Faster Recur-\nrent CNN (FR-CNN) on the RUSA-19 dataset.\nAwal et al. [ 5] proposed a multilingual Model-Agnostic\nMeta-Learning (MAML) [ 52] method for detecting HS,\nemploying different publicly available datasets. The base\nmodels used in their study were mBERT and XLM-R, along-\nside datasets from Founta et al. [ 21], i Orts, [ 49], Mandl et al.\n[39], and Bosco et al. [ 10]. In this study, their proposed model,\nHA TE-MAML, outperformed the baseline models by over\n3% in accuracy. In their study, Mazari et al. [ 41] performed\nmulti-label HS detection using ensemble learning methods.\nThey employed two different word embeddings, FastText and\nGloV e, and also trained a BERT model combined with BiL-\nSTM and BiGRU, utilizing a dataset from the Kaggle.\n3 The\nmulti-labels in their study included categories, such as ’iden-\ntity hate’, ’threat’, ’insult’, ’obscene’, ’toxic’, and ’severe\ntoxic’. Ali et al. [ 2] performed a tertiary classiﬁcation of HS\ndetection on Twitter for the Urdu language. This classiﬁca-\ntion was divided into three categories: hate speech, offensive,\nand neutral. They utilized deep learning-based models, such\nas LSTM and GRU, stacked with FastText embeddings, and\nalso implemented a transformer-based BERT model using\nthe Hugging Face tokenizer. Among these models, BERT\nemerged as the most accurate, achieving a notable accuracy\nscore of 0.73. A similar approach was undertaken by Mehta\net al. [ 42], where they applied traditional ML algorithms,\nSVM, MNB, RF, LR, and DL-based model LSTM and\nthe transformer-based BERT model. Among these, LSTM\nemerged as the most effective, achieving an impressive accu-\nracy score of 0.98. After reviewing the existing literature, we\nconclude that many studies addressed HS using traditional\n3 https://www.kaggle.com/competitions/jigsaw-toxic-comment-\nclassiﬁcation-challenge/data\nFig. 3 Proposed work methodology\nML and DL-based methods for online data. We will do this\nanalysis using DL, and multilingual transformers with hyper-\nparameter tuning methods, instruction ﬁne-tuning, and with\ngenerative conﬁgurations in a different way that will provide\nus with a deep understanding of these approaches.\nTable 1 represents the comparative analysis of the cur-\nrent SOTA studies. The prevailing existing methods in HS\ndetection have shown a tendency to underutilize multilingual\ntransformers and language-speciﬁc transformers, particu-\nlarly those that leverage the increasingly popular prompt-\nbased ﬁne-tuning technique in generative AI. Additionally,\nthese methods have primarily focused on word embedding\ntechniques, often giving less attention to the crucial aspects\nof regularization and hyperparameter tuning that are essential\nfor ensuring the robust performance of algorithms. In con-\ntrast, our work not only integrates these advanced transformer\nmodels and emphasizes the importance of regularization but\nalso pioneers in applying prompt-based ﬁne-tuning with gen-\nerative conﬁguration and explainable AI for multi-class HS\ndetection in low-resource Norwegian language.\nTable 2 highlights the prior research conducted on low-\nresource European languages.\nMethodology\nThe proposed research methodology involves a systematic\napproach to achieving promising results, as shown in Fig. 3.\nEach of the steps from our research methodology is further\nelaborated in detail below.\nDataset\nIn our study, we addressed the multi-class classiﬁcation prob-\nlem using the same dataset as the one used in the baseline\n123\nComplex & Intelligent Systems (2024) 10:4535–4556 4539\nTable 1 Comparative analysis of state-of-the-art methods\nReferences Dataset Feature Set Method Results\nElzayady et al.\n[18]\nAraPersonality,\nSemEval 2020\nArabic offensive\nTF-IDF DT, XGBoost,\nSVM, LR, RF,\nLSTM, BiLSTM,\nCNN, GRU\nAccuracy: 0.82\nSaleh et al. [ 61]D a v i d s o n e t a l .\n[16], Waseem,\n[73], Waseem\nand Hovy, [ 74]\nWord2V ec,\nGloV e\nBiLSTM, BERT F1-score: 0.96\nMazari et al. [ 41] Wikipedia Com-\nments\nFastText, GloV e BERT, BiLSTM,\nBiGRU\nF1-score: 0.99\nMittal and Singh.\n[45]\nOnline Tweets Count V ectorizer XGBoost, LIME,\nSHAP\nF1-score: 0.94\nAwal et al. [ 5] Founta et al.\n[21], i Orts, [ 49],\nMandl et al. [ 39],\nFounta et al. [ 22]\nContextual\nEmbeddings\nmBERT, XLM-\nR, MAML\nROC-AUC: 0.79\nWilliam et al. [75] Online Tweets Word2V ec, TF-\nIDF\nAdaBoost, RF,\nLR, SVM\nAccuracy: 0.79\nA l ie ta l .[ 2] Online Tweets FastText LSTM, GRU,\nBERT\nF1-score: 0.73\nNagar et al. [ 46] Founta et al. [ 21],\nFounta et al. [ 22]\nContextual\nEmbeddings\nVGAC Accuracy: 0.85\nMehta and Passi,\n[42]\nOnline Tweets TF-IDF LR, RF, SVM,\nMNB, LSTM,\nBERT\nAccuracy: 0.98\nAkuma et al. [ 1] Online Tweets TF-IDF, BoW LR, DT, KNN,\nNB\nAccuracy: 0.92\nKhanday et al.\n[32]\nOnline Tweets TF-IDF, BoW LR, MNB, SVM,\nDT, Bagging,\nAdaBoost, RF,\nSGB\nAccuracy: 0.98\nKhan et al. [ 31\n] RUSA-19, RUSA N-gram CNN, RNN Accuracy: 0.92\nRizwan et al [ 59] RUSA-19 ELMO, FastText,\nLASER\nLSTM, BERT,\nBiLSTM, CNN,\nXLM-R\nF1-Score: 0.89\nProposed Work\nModel Dataset Feature Set Method Results\nFAST-RNN,\nPrompt-Based\nFine-Tuning\nAndreassen\nSvanes and\nSeim Gunstad,\n[3](Resset, Twit-\nter, Facebook)\nSupervised\nFastText, Reg-\nularization,\nHyperparam-\neter Tuning,\nGenerative Con-\nﬁgurations\nLSTM, GRU,\nCNN-LSTM,\nBiLSTM-GRU,\nmBERT, ELEC-\nTRA, FLAN-T5,\nscandi-BERT,\nNor-T5, Nor-\nBERT, nb-BERT,\nLIME\nPrecision: 0.98, Recall:0.98, F1-\nscore: 0.98, Accuracy: 0.98\nstudy [3]. This dataset is categorized into ﬁve distinct classes:\n’1’ for neutral, ’2’ for provocative, ’3’ for offensive, ’4’\nfor moderately hateful, and ’5’ for hateful. It was compiled\nfrom three social media platforms: Facebook (FB), Twit-\nter, and Resset.\n4 Furthermore, the baseline study provides\n4 https://inyheter.no/\na comprehensive explanation of each class label’s deﬁnition,\nensuring clarity in the categorization of the data. The dataset\nexhibits a signiﬁcant imbalance, with a predominance of neu-\ntral instances totaling 34,085, while hateful instances number\nonly 250. This stark disparity highlights the need for an effec-\ntive approach to accurately identify the relatively rare hateful\ninstances. In Table 3, there are some examples of Norwegian\n123\n4540 Complex & Intelligent Systems (2024) 10:4535–4556\nTable 2 Comparative analysis of HS detection in low-resource dialects\nReferences Dataset Hateful Non Hateful Evaluation\nBigoulaeva et al. [ 9] German (GermEval-2018) 39.5% 60.5% F1-Score: 0.98\nPereira-Kohatsu et al. [ 53] HaterNet 58.5% 42.5% Acc: 0.83\nAyo et al. [ 6] Davidson et al. [ 16] 20% 80% AUC: 0.96\nGarcía-Díaz et al. [ 24] Spanish MisoCorpus 2020 58% 42% Acc: 0.85\nF e r s i n ie ta l .[20] Italian and English (AMI 2018) 41% 59% Acc: 0.83\ndel V alle-Cano et al. [ 69] Italian 58.5% 42.5% F1-Score: 0.998\nBatarﬁ et al. [ 7] HateEval 2019 41% 59% F1-Score: 0.998\nPtaszynski et al. [ 55] Polish (PolEval-2019) 89.71% 20.24% Acc: 0.90\nTrajano et al. [ 67] Brazilian Portuguese 31.5% 68.5% F1-Score: 0.78\nTable 3 Examples of Norwegian HS text with English translation\nCategory Original text English translation\nNeutral Alle har det bedre under/med Trump (bortsett fra hans\nmediamotstandere)\nEveryone is better off under/with Trump (except his\nmedia opponents)\nProvocative Jeg visste ikke at @USER likte orgier og holdt til i\nFlorida\nI didn’t know @USER liked orgies and lived in Florida\nOffensive Søt tenåring elsker å ri på en stor pikk Cute teen loves to ride a big dick\nModerately Hateful Innen 2050 er vi nok bde islamisert og kolonisert By 2050 we will probably be both Islamized and\ncolonized\nHateful Men har dm ikkje anna og gjera Send dm langt inni\ndalstroka innafor og la dei beite der\nBut if they have nothing else to do Send them far inland\nand let them graze there\nTable 4 Dataset distribution\nwith class labels Category Countof comments\nNeutral 34 ,085\nProvocative 4737\nOffensive 1563\nModerately hateful 510\nHateful 250\nFig. 4 Dataset distribution\nHS instances along English translation. Table 4 and Fig. 4\nillustrate the distribution of the dataset in terms of class labels\nand their count.\nData preprocessing\nData preprocessing is crucial in many ML and DL-based\nmodels for eliminating irrelevant text from the dataset, ensur-\ning that the data are presented in a concise and appropriate\nformat. In our study, we focused on two main columns: \"text\"\ncontaining all the comments, and \"category\" representing the\nﬁve distinct classes. The preprocessing of \"text\" involved\nseveral key steps. First, we converted all uppercase letters to\nlowercase and removed non-essential characters, including\nASCII symbols. The process also included tokenizing words\nand sentences and removing stop words.\n5 To further reﬁne\nour data, we used Python’s RegEx library to ﬁlter and process\nelements like numbers, punctuation, and speciﬁc patterns,\nincluding email addresses, URLs, and phone numbers.\nIn the context of transformer-based models, our prepro-\ncessing approach was more speciﬁc, we conducted a limited\nset of preprocessing steps, deliberately excluding the removal\nof stop words, as it is not recommended under any cir-\ncumstances. Another reason for limiting preprocessing for\ntransformer-based models is to address the issue of syntactic\nambiguity [64], which has been a signiﬁcant drawback in pre-\nvious DL-based techniques and models. Syntactic ambiguity\noccurs when words within a sentence might have several\n5 https://github.com/stopwords-iso/stopwords-no\n123\nComplex & Intelligent Systems (2024) 10:4535–4556 4541\ninterpretations depending on the context, making it a difﬁ-\ncult problem to interpret.\nWord embedding\nWord embeddings offer numerical representations for tex-\ntual inputs. FastText\n6 embeddings provide several beneﬁts\ncompared to traditional word embeddings due to their abil-\nity to capture subword details and manage words not in the\nvocabulary more effectively. This feature makes FastText\nparticularly advantageous for languages with complex mor-\nphology and diverse variations.\nEquation 2 shows the mathematical formula to compute\nFastText word embeddings [ 44]\nu\nw + 1\n|N |\n∑\nn∈N\nxn , (1)\nwhere\nuw: represents the vector for w in the embedding space.\n1\n|N |: is the fraction representing the average.\n∑\n: is used to sum over a set of vectors.\nn ∈ N : speciﬁes that we are summing over the set N.\nxn : represents the vector for the context words in the set.\nFastText, a word representation tool developed by Face-\nbook’s research division, offers both unsupervised and super-\nvised modes and features a comprehensive database of 2\nmillion words from Common Crawl, each represented by\n300 dimensions. Altogether, this library contains an impres-\nsive total of 600 billion word vectors. This word embedding\nmethod stands out with its distinctive methodology, which\nincludes the use of manually crafted n-grams as features in\naddition to individual words [ 56].\nFastText embeddings use morphological features, which\nenhances their effectiveness in vector representation and gen-\neralizability in a range of applications [ 68]. In this work,\nsupervised FastText was used to focus on a categorical clas-\nsiﬁcation problem. It uses labeled training data to learn the\nassociations between texts and labels, allowing for more\naccurate predictions on unseen data. This approach is advan-\ntageous in scenarios where the objective is to categorize text\ninto predeﬁned classes, as it provides context-based learning\nguided by the labeled examples. In contrast, unsupervised\nFastText focuses on learning word representations from a\nlarge corpus of unlabelled text, which is only useful for under-\nstanding word associations, and does not directly address\n6 https://fasttext.cc/\nFig. 5 FastText word embedding architecture\nthe particular requirements of classiﬁcation tasks. Moreover,\nunsupervised FastText cannot effectively identify the subtle\nand speciﬁc distinctions between different categories that are\nessential for accurate classiﬁcation. In our experimentation,\nwe trained the FastText model over 50 epochs, employing\nlearning rates of 0.01.\nModeling approaches\nThis section will detail the DL and transformer-based models\nutilized in this paper. It will provide an in-depth examination\nof each model’s architecture and its application within our\nresearch framework.\nDL-based models\nIn this paper, we implemented LSTM and its variant BiL-\nSTM, along with GRU. These RNN-based models are known\nfor their effectiveness in processing sequential data, with\nLSTM units being particularly adept at capturing long-term\ndependencies. BiLSTM enhances this capability by process-\ning data in both forward and backward directions. GRU,\nsimilar to LSTM, efﬁciently manages sequence dependen-\ncies but with a simpler architectural design. Additionally, we\nexplored a hybrid model, BiLSTM-GRU which is our pro-\nposed FAST-RNN, combining the strengths of both LSTM\nand GRU architectures with FastText embeddings. Further-\nmore, we performed CNN with the stacking of LSTM,\nleveraging CNN’s ability to extract spatial features and\nLSTM’s sequential data handling, offering a comprehensive\napproach to model complex patterns in data.\n1. FAST-RNN architecture: The FAST-RNN architecture\ndescribed in Fig. 6 is a sophisticated neural network\n123\n4542 Complex & Intelligent Systems (2024) 10:4535–4556\nmodel proposed for categorical HS classiﬁcation tasks.\nAt its core, the model commences with an embedding\nlayer that transforms text data into a dense sequence\nmatrix of maximum sequence length ’m’. This matrix\nfeeds into a BiLSTM segment comprising two model\nlayers with 80 and 60 LSTM units, which processes the\ndata bidirectionally to capture long-range dependencies\nin both forward and backward directions. Subsequently,\nthe sequence is passed through a GRU segment with 60\nGRU units, harnessing the model’s ability to focus on the\nmost salient features of the input for classiﬁcation while\nreducing computational complexity.\n2. Regularization: Regularization is a technique in the\nlearning algorithms that prevents overﬁtting, which\noccurs when a model performs well on training data but\npoorly on unseen test data [ 60]. The robust performance\nof the FAST-RNN model is considerably enhanced by\nthe implementation of kernel L2 regularization, set at a\nlambda value of 0.01 for both the BiLSTM and GRU\nlayers. L2 regularization is crucial for reducing the mag-\nnitude of the weights, which encourages the model to\nfavor smaller weight values [ 35]. This approach serves\na dual purpose: it reduces the likelihood of overﬁtting\nand strengthens the model’s ability to generalize, ensur-\ning dependable performance on new, unseen datasets.\nThe choice to utilize L2 instead of L1 regularization was\nintentional. L1 regularization tends to promote sparsity\nby driving some weights to zero [ 38], which, in our sce-\nnario, could lead to underﬁtting a limitation that became\napparent during initial testing. Equations ( 2) and ( 3)a r e\nthe mathematical formulas to calculate L1 and L2 regu-\nlarization.\n3. Hyperparameter tuning: In our thorough hyperparam-\neter tuning process, we carefully ﬁne-tuned the model’s\nparameters through a series of deliberate experiments.\nWe trained the model for 10 epochs, a length of time\nchosen to ensure the model learned effectively with-\nout overﬁtting. This was ﬁnalized as the model’s loss\nstabilized over time. For the task of multi-class classiﬁca-\ntion, we adopted the cr oss − entropy loss function due\nto its well-established effectiveness. This loss function\nassesses the alignment between predicted probabilities\nand the actual class distribution, a critical metric for clas-\nsiﬁcation tasks of this nature. To optimize our model’s\nperformance, we employed the Adam optimi zer , known\nfor its ability to dynamically adjust the learning rate .\nThis adaptive learning rate mechanism enhances the\nmodel’s efﬁciency in exploring and converging toward\noptimal parameter values.\nThe name ’FAST-RNN’ highlights the model’s fast\ntraining and processing speed, along with its strong per-\nformance compared to other DL-based models in our\nstudy. We also tried training for 5 epochs and using L1\nregularization, but the results were not as good. Five\nepochs did not give the model enough time to learn\nproperly, and L1 regularization, which can reduce some\nweights to zero, was too obvious. Therefore, training for\n10 epochs with L2 regularization was the best choice. It\nallowed the model to learn fully while still being able\nto perform well on new, unseen data, leading to the\nimproved performance of the FAST-RNN. Table 5 illus-\ntrates the hyperparameters and conﬁguration details of\neach DL-based model\nL1(w) = λ\nn∑\ni =1\n|wi |, (2)\nwhere\nw: is the weight vector of the model\nλ: is the regularization coefﬁcient\nn: is the number of weights in the vector\nwi :i st h e i th weight in the weight vector .\nL1 regularization adds the absolute value of the mag-\nnitude of the coefﬁcients as a penalty term to the loss\nfunction. The absolute value makes this penalty term non-\nlinear in the weights, and thus, L1 regularization can lead\nto sparse solutions, with many coefﬁcients being exactly\nzero\nL2(w) = λ\nn∑\ni =1\nw2\ni ; (3)\nL2 regularization adds the squared magnitude of the\ncoefﬁcients as a penalty term to the loss function. The\nsquaring makes the penalty smoother and differentiable\nat w\ni = 0. Unlike L1 regularization, L2 does not result in\nsparse models, as it typically does not force coefﬁcients\nto be exactly zero (though they may be small).\nTransformer-based models\nThe Transformer, introduced in 2017 by V aswani et al. [ 70],\nis an NLP framework built for sequence-to-sequence tasks.\nIt operates on the self-attention mechanism that efﬁciently\nhandles long-range dependencies and consists of two primary\ncomponents: an encoder and a decoder. The mechanism of\nself-attention within the Transformer can be mathematically\nformulated as follows:\nAttention(Q, K , V ) = softmax\n(\nQK\n⊤\ni√dk\n)\nVi , (4)\n123\nComplex & Intelligent Systems (2024) 10:4535–4556 4543\nFig. 6 Proposed FAST-RNN\narchitecture\nTable 5 Conﬁguration details for DL models\nModel Model layer Dense layer Dropout layer Pooling layer Regularization Epochs Function Loss\nLSTM 3 2 2 – L2 10 Softmax Categorical entropy\nGRU 3 2 2 – L2 10 Softmax Categorical entropy\nCNN-LSTM 3 2 2 2 L2 10 Relu Categorical entropy\nBiLSTM-GRU 3 2 2 – L2 10 Relu Categorical entropy\nwhere\nQ: is the loss to minimize\nK : is the key matrix\nV : is the value matrix\ndk : is the dimension of the key vectors\nN : is the length of the input sequence\ni : is the index of the query vector .\nThis paper utilizes multilingual transformers, with a focus\non optimizing their hyperparameters. Unlike previous lan-\nguage models such as RNNs, which faced limitations in\ncomputational and memory capacities for generative tasks,\ntransformers represent a substantial improvement. In our\nstudy, we used the Norwegian HS text dataset for which\nmultilingual text classiﬁcation transformers like mBERT,\nELECTRA, FLAN-T5, along with Norwegian LMs Nor-\nBERT, ScandiBERT, nbBERT, and Nor-T5, were utilized.\nMultilingual transformers\nmBERT\nBERT, a transformer model, underwent self-training on an\nextensive, multilingual dataset. This implies it was trained\nsolely using raw text, without any human-labeled data, lever-\naging publicly accessible data and an automated method\nfor generating inputs and labels from the text. In contrast,\nmBERT, a specialized version of BERT, was pre-trained\nspeciﬁcally on the largest Wikipedia articles across 104 lan-\nguages. It employed a Masked Language Modeling (MLM)\napproach for its training [ 17].\nELECTRA\nIn BERT’s MLM pretraining, input tokens are replaced with\na [MASK] placeholder, and the model learns to predict the\noriginal tokens. Electra, however, introduces a more efﬁcient\nmethod called replaced token detection. Unlike BERT, Elec-\ntra replaces some tokens with plausible alternatives from a\nsmaller generator network, and a discriminative model is\ntrained to identify whether each token in the input has been\nreplaced or not. The generator part in Electra assigns proba-\nbilities to the generation of speciﬁc tokens x\nt using a softmax\nlayer [ 14].\nFLAN-T5\nFLAN-T5,7 an extension of the Text-to-Text Transfer Trans-\nformer (T5) model [ 57], represents a signiﬁcant advancement\nin NLP . Developed for instruction ﬁne-tuning, FLAN-T5 is\ntrained across various tasks, enhancing its adaptability and\nefﬁciency in text-to-text operations [ 13]. Its proﬁciency in\nsummarizing dialogs and classifying text makes it invalu-\nable for any real-world applications. Additionally, FLAN-T5\n7 https://huggingface.co/docs/transformers/model_doc/ﬂan-t5\n123\n4544 Complex & Intelligent Systems (2024) 10:4535–4556\nTable 6 Conﬁguration details for transformer-based models\nModel Class Batches Lr Epoch\nmBERT BertTokenizer 32 2e–5 5\nELECTRA ElectraTokenizer 32 2e–3 5\nFLAN-T5 AutoTokenizer 32 2e–5 5\nTable 7 Conﬁguration details for Norwegian transformer-based mod-\nels\nModel Class Batch Lr Epoch\nnb-BERT SequenceClassiﬁcation 32 2e–5 5\nNor-BERT SequenceClassiﬁcation 32 2e–6 5\nNor-T5 Seq2SeqLM 32 2e–3 5\nscandi-BERT SequenceClassiﬁcation 32 2e–5 5\nexcels in text classiﬁcation. It automates the categorization\nof text into predeﬁned classes, such as Sentiment Analysis\n(SA), spam detection, or topic modeling. Table 6 presents\nthe conﬁguration and hyperparameters of the multilingual\ntransformer-based models utilized in this study.\nNorwegian LMs\nRecently, signiﬁcant advancements have been made in Nor-\nwegian LMs. A. Kutuzov et al. [ 37] introduced NorBERT,\navailable in various sizes and trained on the Norwegian Aca-\ndemic Corpus (NAK) and Norwegian Wikipedia. NorBERT 2\nuses data from the Norwegian section of mC4 and the NCC’s\npublic part. P .E. Kummervold et al. [ 36] developed NB-\nBERT models: NB-BERT base, which builds upon mBERT,\nand NB-BERT large, independently trained on the complete\nNCC corpus. Additionally, Scandinavian BERT (Scandi-\nBERT), covering Danish, Norwegian, Icelandic, Faroese,\nand Swedish texts, has over 60% Norwegian content from\nNCC. Recently, two novel Norwegian LMs, Nor-T5\n8 and\nNorth-T5,9 were proposed by Samuel et al. [ 62]. Nor-T5,\nand North-T5 transformer models are designed for Norwe-\ngian and Scandinavian sequence-to-sequence tasks. These\nmodels were evaluated against multilingual T5 models and a\nseries of specialized North-T5 models, which are essentially\nmT5 models further ﬁne-tuned speciﬁcally on Norwegian\ndata. This comparison aims to assess their effectiveness\nin handling Norwegian language tasks. Table 7 presents\nthe conﬁguration and hyperparameters of the Norwegian\ntransformer-based models utilized in this study.\n8 https://huggingface.co/ltg/nort5-large\n9 https://huggingface.co/north/t5_base_NCC\nGenerative configuration\nIn the process of reﬁning the proposed multilingual trans-\nformers and Norwegian LMs, we implemented substantial\nmodiﬁcations to the hyperparameters, which resulted in\nnoticeable improvements in our outcomes. These adjust-\nments encompassed the exploration of diverse batch sizes,\nlearning rates, and epochs. Additionally, we also employed\ngenerative conﬁguration parameters, which are additional\nparameters that the model utilizes during training. These\nparameters are invoked during the inference phase, provid-\ning us with control over factors such as the maximum token\ncount in the generated output and the level of creativity in\nthe text. These techniques include random sampling methods\nlike top-k and top-p, which impose constraints on random-\nness and increase the likelihood of producing creative and\ndiverse outputs [ 54]\nTop-k sampling involves choosing the k most likely words\nfrom the model’s probability distribution for the next word.\nThe process is deﬁned by the following formula:\nP(w) =\n⎧\n⎨\n⎩\ne(P(w)\n∑\nw′ e(P(w′) if w is in the top- k\n0 otherwise ,\n(5)\nwhere\nw: is the word being sampled,\nP(w): is the probability of word,\nV : is the vocabulary of possible words.\nTop-p sampling selects the minimum number of words\nneeded to have a cumulative probability exceeding a prede-\nﬁned threshold p. Following is the mathematical expression\nto calculate the top-p sampling [ 29]:\nP(w) = 1∑\nw′∈V :P(w′)≥p P(w′) (6)\nwhere\n∑\nw′∈V :P(w′)≥p\nP(w′): sum of probabilities .\nFurthermore, we integrated an additional set of conﬁgu-\nration parameters in our method, speciﬁcally the \"tempera-\nture\" parameter. This parameter signiﬁcantly inﬂuences the\nmodel’s calculated probability distribution used in predict-\ning the subsequent token. Essentially, the temperature value\nserves as a scaling factor within the softmax layer of the\ntransformer models. A higher temperature setting increases\n123\nComplex & Intelligent Systems (2024) 10:4535–4556 4545\nTable 8 Generative conﬁguration details for transformer-based models\nModel Top-k Top-p Temperature\nFLAN-T5small 50 . 5 0 . 3\nFLAN-T5base 50 . 2 0 . 3\nNor-T5small 70 . 5 0 . 3\nthe randomness in the generated output, while a lower tem-\nperature value reduces the range of possible words in the\ngenerated text [ 54]. Following is the mathematical expres-\nsion for random sampling with temperature [ 29]:\nP(w) = exp\n(P(w)/τ)\n∑\nw′ exp (P(w′)/τ) (7)\nwhere\nτ: parameter controlling distribution diversity\n∑\nw′\nexp (P(w′)/τ) : normalization factor .\nTable 8 provides an overview of the generative con-\nﬁguration employed during the ﬁne-tuning of our models,\nincluding details on class type and the tokenizer used.\nTransformer-based models vary in their capabilities with\ngenerative conﬁgurations, as exempliﬁed by mBERT and\nELECTRA, which have been designed for classiﬁcation tasks\nrather than text generation. This specialization accounts for\ntheir inability to work with generative parameters. In com-\nparison, FLAN-T5 and Nor-T5, both are variants of the\nT5 transformer and can be used for text generation, sum-\nmarization, and translation tasks. This functionality is also\ninﬂuenced by their class type; both Nor-T5 and FLAN-T5\nbelong to the \"Seq2SeqLM\" class, a category not applicable\nto other transformer-based models like BERT and ELEC-\nTRA.\nPrompt based fine-tuning\nIn traditional ML, models are trained on a large dataset\nto learn a task. However, in prompt-based learning, the\ntransformer-based models are given a natural language\nprompt or a set of instructions that guides them to perform\na speciﬁc task without extensive training. This approach uti-\nlizes the pre-trained knowledge of these transformers and\nadapts it to new tasks through carefully crafted prompts. In\nour study, we employed two different types of prompt-based\nﬁne-tuning: few-shot and full ﬁne-tuning.\nFew-shot ﬁne-tuning\nFew-shot ﬁne-tuning is a process that entails training a model\non a small (few examples), task-speciﬁc dataset, in contrast\nto traditional ﬁne-tuning which typically requires a larger\ndataset. In this method, the model is given a limited number\nof examples with natural language prompt along with the\ndesired outcome. These examples aid the model in adjusting\nits responses to better suit the particular task’s requirements.\nFew-shot ﬁne-tuning proves highly beneﬁcial when we have\nlimited resources with restricted task-speciﬁc data and aim to\nensure the model generalizes effectively from these limited\nexamples.\nFull ﬁne-tuning\nFull ﬁne-tuning involves training the model on a substantial\ndataset. This dataset is usually speciﬁc to the task or domain\nthe model is intended to perform in. Full ﬁne-tuning is more\nresource-intensive compared to few-shot ﬁne-tuning and it\nrequires more computational power and time, as the model\nneeds to be trained over a larger set of data. This approach\noffers the advantage of highly specializing the model for the\nﬁne-tuned task.\n• Natural language prompt: In our study, we chose to\nuse FLAN-T5 and Nor-T5 architectures for prompt-\nbased learning, because models like mBERT, ELECTRA,\nNB-BERT, and several others are not well suited for\nthis speciﬁc approach. The primary reason is that these\nmodels are typically designed for contextual language\nunderstanding, where they predict the next word or token\nin a sentence based on the surrounding context. They\ndo not inherently support prompt-based learning, which\nrequires the ability to generate responses or perform\nactions based on explicit instructions or prompts pro-\nvided by the user. FLAN-T5 and Nor-T5, on the other\nhand, have been speciﬁcally designed and ﬁne-tuned\nfor natural language prompt-based tasks, making them\nmore suitable choices for this research. Our transformer-\nbased methodology centered around the natural language\nprompt: ’Please classify the following sentence into just\none of the mentioned categories: neutral, provocative,\noffensive, moderately hateful or hateful .’ This prompt\nwas a key element in our exploration of different ﬁne-\ntuning approaches, namely few-shot and full ﬁne-tuning.\nThe provided Algorithm 1 deﬁnes a function that prepares\ndata for ﬁne-tuning a language model. It generates prompts\nfor classiﬁcation tasks by combining a ﬁxed starting prompt\nwith text samples from a dataset and an ending prompt. These\nprompts are tokenized using a tokenizer, and the resulting\ninput_ids a r es t o r e di ndataset_dict[’input_ids’]. Addition-\n123\n4546 Complex & Intelligent Systems (2024) 10:4535–4556\nAlgorithm 1 Preparing prompt for ﬁne-tuning\n1: procedure function(dataset _dict )\n2: pr ompt ← \"natural language \"+\" t weet \"\n3: end _ pr ompt ← dataset _dict [′label ′]\n4: input _ids ← tokenize : pr ompt\n5: labels ← tokenize : end _ pr ompt\n6: dataset _dict [′input _ids ′]← input _ids\n7: dataset _dict [′labels ′]← labels\n8: return dataset _dict\n9: end procedure\nTable 9 Training arguments for prompt-based ﬁne-tuning\nParameters Language model\nLearning rate 1e–8\nNum_train_epochs 5\nEvaluation_strategy ’epoch’\nWeight_decay 0.01\nPer_device_train_batch_size 16\nLogging_steps 1\nOptim ’adamw_torch’\nally, the labels in dataset_dict[’labels’]are tokenized and\nstored in dataset_dict[’labels’]. All these conversions have\nbeen conducted using PyTorch tensors. The label variable\nconsists of one of the class categories in our HS dataset. The\ntokenizer utilized in this algorithm is the identical tokenizer\nthat was employed during the model’s pretraining phase.\nThe ﬁnal object dataset_dict is then passed to the learning\nalgorithm for the training, as mentioned in Table 9, which rep-\nresents the conﬁguration and hyperparameter details for the\nfew-shot and full-instruction ﬁne-tuning training processes.\nIn the training of the transformer-based model, a set of\ncarefully chosen hyperparameters was utilized to ﬁne-tune\nthe learning process. A learning rate of 1e–8 was selected,\nmaintaining a balance between convergence speed and sta-\nbility. The model was subjected to training over 5 epochs,\nensuring adequate exposure to the data while avoiding over-\nﬁtting. The evaluation was conducted at the end of each\nepoch, allowing for consistent monitoring of the model’s per-\nformance. To prevent the model’s weights from growing too\nlarge and overﬁtting, a weight _decay of 0.01 was applied.\nThe batch _size was set to 16 per device to optimize memory\nusage and computational efﬁciency. Logging _steps were\nset to 1 to ensure that the training process was transparent\nand that the progress could be closely tracked. Finally, the\n’adam w_to rch ’ optimizer was chosen for its ability to auto-\nmatically adjust the learning rate and for being well suited\nfor transformer-based models.\nTable 10 Results of DL-based models\nModel PR Acc F Auc_Roc\nLSTM 0.97 0.97 0.97 0.97 0.99\nGRU 0.97 0.97 0.97 0.97 0.99\nCNN-LSTM 0.96 0.96 0.96 0.96 0.99\nBiLSTM-GRU 0.98 0.98 0.98 0.98 0.99\nResults and discussion\nFor the evaluation of the results, standard metrics of accuracy,\nprecision, recall, f1-score, and auc_roc were employed to\nquantify the model’s classiﬁcation performance. The dataset\nwas divided into a training and testing split of 80% and 20%,\nrespectively\nAccuracy = T\nP + TN\nTP + TN + FP + FN\n(8)\nPrecision = TP\nTP + FP\n(9)\nRecall = TP\nTP + FN\n(10)\nF1-Score = 2 · Precision · Recall\nPrecision + Recall . (11)\nDL-based models\nThe evaluation scores for DL-based models, employing Fast-\nText embeddings, are displayed in Table 10.\nBy analyzing 10, we can see that the FAST-RNN model\nexhibits a precision and recall of 0.98. Precision is a critical\nmeasure when the consequences of false positives are signif-\nicant. A precision of 0.98 means that when the FAST-RNN\nmodel predicts an instance as positive, it is correct 98% of the\ntime. This high precision indicates that the model is highly\nreliable in its positive predictions, making very few mistakes\nin this regard. With a recall of 0.98, the FAST-RNN model\ncan correctly identify 98% of all actual positive instances.\nThis suggests that it is particularly effective at capturing the\nrelevant signals from the data without missing many actual\npositives. Moreover, the high accuracy score of 0.98 reﬂects\nthe overall rate at which the model makes correct predic-\ntions for both positive and negative classes. This balanced\nperformance is mirrored in the weighted F1-score, which is\nthe harmonic mean of precision and recall, indicating that\nthe model maintains a strong balance between precision and\nrecall across all classes. Finally, an AUC-ROC score of 0.99\nindicates an excellent ability of the model to discriminate\nbetween the positive and negative classes. A score close to\n1.0 means that the model has a high true-positive rate and a\nlow false-positive rate across different thresholds.\n123\nComplex & Intelligent Systems (2024) 10:4535–4556 4547\nTable 11 Classiﬁcatioin report for FAST-RNN\nCategory PRF S u p p o r t\nNeutral 0.99 0.98 0.99 6813\nProvocative 0.89 0.93 0.91 951\nOffensive 0.92 0.99 0.95 301\nModerately hateful 0.98 0.88 0.93 109\nHateful 0.96 0.98 0.97 54\nIn comparison to the FAST-RNN model, the other DL-\nbased models like LSTM, GRU, and CNN-LSTM also show\nrobust performance with all metrics ranging from 0.96 to\n0.97. Both LSTM and GRU models match the FAST-RNN’s\nprecision, recall, and accuracy, indicating their strong predic-\ntive capabilities, while the CNN-LSTM lags slightly behind\nbut still demonstrates high scores of 0.96. Each model shows\nremarkable ability in sequence processing tasks, with the\nFAST-RNN slightly outperforming the rest, likely due to its\nhybrid architecture that leverages the strengths of both LSTM\nand GRU layers. The ROC-AUC score of 0.99 for all mod-\nels, including FAST-RNN, LSTM, GRU, and CNN-LSTM,\nindicates a high degree of predictive accuracy, reﬂecting their\nstrong ability to rank predictions correctly.\nTable 11 presents the classiﬁcation report of the proposed\nFAST-RNN model which shows the best performance in pre-\ndicting each class within the test data. This is particularly\nnotable in its prediction of hateful instances, which are a\nminority in the dataset. Despite this, our model achieved\nan impressive 97% F1-score in accurately identifying these\ninstances. The model shows remarkable precision and recall\nin the ’Neutral’ category, with scores of 0.99 and 0.98\nrespectively, suggesting a decent performance in identify-\ning non-inﬂammatory content, which is often the bulk of\ndata and sets the baseline for model performance. In more\nnuanced categories, such as ’Provocative’ and ’Offensive,’\nthe model exhibits precision scores of 0.89 and 0.92, with\nrecall scores of 0.93 and 0.99, indicating its effective differen-\ntiation between subtly differing sentiments. The ’Moderately\nHateful’ category, despite having fewer instances, also sees\na high F1-score of 0.93, underlining the model’s capabil-\nity to discern complex emotional nuances in a text. These\nresults collectively highlight the robustness of the FAST-\nRNN model in handling both clear-cut and borderline cases,\nensuring that it performs reliably across a diverse range of\ntextual sentiments.\nFigures 7 and 8 indicate a stable convergence, with the val-\nidation metrics closely tracking the training metrics across\nepochs. The graphs demonstrate a stable convergence and\nindicate that the validation scores are close to the training\nscores throughout the training epochs. The close alignment\nbetween training and validation accuracy, alongside a consis-\nFig. 7 Training and validation loss curve—FAST-RNN\nFig. 8 Training and validation accuracy curve—FAST-RNN\ntent decrease in loss for both training and validation, suggests\nthat the model is learning generalizable patterns rather than\noverﬁtting the training data. This balance between learn-\ning and generalization, especially given the limited number\nof hateful instances, underscores the model’s performance\nand generalizability. Figure 9 illustrates the confusion matrix\nmulti-class classiﬁcation HS detection using FAST-RNN.\nTransformer-based models\nTable 12 presents the results achieved from the multilingual\ntransformers as well as the Norwegian transformer-based\nmodels.\nELECTRA\nbase and ELECTRAlarge show uniform perfor-\nmance across four metrics, each with a precision of 0.69,\nrecall of 0.83, accuracy of 0.83, and a f1-score of 0.75. This\nindicates that scaling up the ELECTRA size from base to\nlarge does not impact the performance for these speciﬁc\ntasks. mBERT, with a precision of 0.78, is noteworthy for\n123\n4548 Complex & Intelligent Systems (2024) 10:4535–4556\nFig. 9 Confusion matrix—FAST-RNN\nTable 12 Analysis of the results: transformer-based models\nmodel P R Acc F Auc_Roc\nmBERT 0.78 0.82 0.82 0.79 0.81\nELECTRAbase 0.69 0.83 0.83 0.75 0.80\nELECTRAlarge 0.69 0.83 0.83 0.75 0.80\nscandi-BERT 0.79 0.81 0.81 0.80 0.81\nnb-BERT\nbase 0.79 0.81 0.81 0.80 0.81\nnb-BERTlarge 0.81 0.81 0.81 0.81 0.82\nNor-BERTsmall 0.77 0.83 0.82 0.79 0.82\nNor-BERTbase 0.78 0.83 0.83 0.80 0.85\nNor-BERTlarge 0.80 0.82 0.83 0.81 0.85\nits relatively high ability to produce relevant results over\nthe total number of results it provides (precision), while its\nrecall of 0.82 shows that it is quite competent at identifying\nrelevant instances from the dataset. Its accuracy is at 0.82\nand f1-score at 0.79 which is more than both ELECTRA\nvariants and similar to Nor-BERT\nsmall, suggesting a well-\nrounded performance. Scandi-BERT and nb-BERT base, both\nwith precision at 0.79 and recall at 0.81, demonstrate a similar\ncapability in correctly classifying instances, and both main-\ntain an accuracy of 0.81. The f1-score for these models stands\nat 0.80, indicating a robust balance between precision and\nrecall. A performance improvement is noted when compar-\ning nb-BERT\nbase to nb-BERTlarge , with the latter achieving a\nprecision of 0.81, which is the highest precision score among\nall the models listed, matching its recall, accuracy, and f1-\nscore.\nTable 13 Analysis of the results with few-shot ﬁne-tuning and gener-\native conﬁguration\nmodel P R Acc F\nFLAN-T5small 0.69 0.80 0.80 0.74\nFLAN-T5base 0.78 0.80 0.80 0.79\nNor-T5small 0.77 0.77 0.77 0.77\nNor-BERT variants show a progression in performance\nwith size increment. Nor-BERT small, with a precision of 0.77\nand recall of 0.83, provides a good improvement with 0.82\naccuracy and f1-score of 0.79. The Nor-BERT\nbase model\nshows a slight improvement in precision to 0.78 while main-\ntaining a similar recall. The highest f1-scores are observed\nwith Nor-BERTlarge and nb-BERTlarge . These models excel\nat not only identifying relevant instances but also at minimiz-\ning the number of irrelevant instances that are incorrectly\nidentiﬁed as relevant. The performance enhancement from\nbase to larger models is predominantly a result of the dif-\nferences in their sizes (number of parameters). Generally,\nmodels with a high number of parameters can demonstrate\nbetter performance over those with a smaller parameter\ncount. The analysis of results in transformer-based models\nsuggests that the performance of transformers might not be as\nimpressive relative to RNN models for specialized tasks such\nas multi-class HS detection. This could be due to the trans-\nformers’ design, which is optimized to identify broad patterns\nin large datasets rather than the more nuanced patterns that\nspecialized tasks might require. The AUC-ROC scores tell\nhow well each model differentiates between the positive and\nnegative classes: Nor-BERT_large, with an AUC-ROC of\n0.85, is most effective, suggesting it has a greater likelihood\nof correctly identifying true positives and true negatives.\nmBERT’s score of 0.81 and ELECTRA_base’s score of 0.80,\nwhile lower, still represent a strong predictive ability, with\nonly a marginal difference in classiﬁcation conﬁdence when\ncompared to Nor-BERT_large.\nTable 13 highlights the evaluation scores of models sub-\njected to few-shot ﬁne-tuning with a generative conﬁguration\nmentioned in Table 8. Here, FLAN-T5\nsmall and FLAN-\nT5base demonstrate similar performance in terms of recall\nand accuracy, while the base model exhibits slightly better\nperformance with precision and f1-scores of 0.78 and 0.79,\nrespectively, which is a noticeable increase from the small\nvariant, meaning it is more precise in its predictions. Nor-\nT5\nsmall maintains comparable recall, precision, accuracy, and\nf1-scores of 0.77, indicating a balanced performance to pre-\ndict positive instances correctly and to identify the most\npositive instances.\nTransitioning to full ﬁne-tuning in Table 14, all models\nexhibit enhanced f1-scores, indicative of improved predic-\ntive relevance and balanced precision-recall, as compared to\n123\nComplex & Intelligent Systems (2024) 10:4535–4556 4549\nTable 14 Analysis of the results with full ﬁne-tuning and generative\nconﬁguration\nmodel P R Acc F\nFLAN-T5small 0.76 0.80 0.80 0.77\nFLAN-T5base 0.82 0.82 0.83 0.80\nNor-T5small 0.77 0.78 0.77 0.78\nthe performance of these models in Table 13. FLAN-T5 base\nrecords the highest precision increase to 0.82, an accuracy\nscore of 0.83, and an f1-score of 0.80, indicating a bal-\nance between precision and recall and also suggesting that\nfull ﬁne-tuning signiﬁcantly reﬁnes the model’s predictive\naccuracy and overall performance. FLAN-T5\nsmall also shows\nmarginal gains in precision and f1-score, underscoring the\nbeneﬁts of a more extensive ﬁne-tuning process. In the case\nof Nor-T5\nsmall, it exhibits a slight improvement as compared\nto few-shot ﬁne-tuning.\nComparing the results of both these tables, it is evident\nthat full ﬁne-tuning combined with generative conﬁgurations\nyields improved model performance. Additionally, models\nthat have a greater number of parameters tend to surpass the\nperformance of those with fewer parameters.\nComparison of the results with the state-of-\nthe-art\nIn this section, we compare our results with the baseline\nmethod [ 3]. The baseline study employed an unsupervised\nFastText model, which generally is less suited for categorical\nclassiﬁcation tasks. In comparison, our supervised FAST-\nRNN model when implemented with optimal regularization\nand hyperparameter tuning outperformed the baseline in\nterms of both accuracy and macro F1-score. The FAST-RNN\nmodel achieves a Macro F1-Score of 0.97 for the ’Hate-\nful’ category, far surpassing the baseline models’ scores of\n0.08 for BiLSTM and 0.06 for CNN-LSTM. Similarly, in the\n’Offensive’ category, our model attained a score of 0.95, sig-\nniﬁcantly higher than the baseline scores of 0.27 and 0.35,\nrespectively. Even in the ’Provocative’ category, which often\ncontains more subtle and nuanced language, our FAST-RNN\nmodel reached a score of 0.91, outperforming the baseline’s\n0.61 and 0.59. The employment of explainable AI through\nLIME has provided additional validation by elucidating the\nmodel’s decision-making process, thereby granting further\ncredibility to our ﬁndings, particularly in the challenging area\nof HS detection in low-resource language scenarios. Table 15\npresents a comparison of the macro F1-scores between the\nbaseline and our proposed model FAST-RNN, speciﬁcally\nfocusing on non-neutral categories provocative, offensive,\nmoderately hateful, and hateful.\nInterpretability modeling with LIME\nLocal Interpretable Model-Agnostic Explanations (LIME)\nis a technique designed for local understanding and eval-\nuating the predictions made by any learning algorithm. It\nprovides insights into how a model’s predictions align with\nthe speciﬁc requirements of the given task. This method is\nparticularly valuable in contexts where understanding the\ndecision-making process of a model is as important as the\naccuracy of its predictions [ 8]. The equation for LIME aims\nto ﬁnd an interpretable model The equation for LIME aims\nto ﬁnd an interpretable model ˆg from a class of models G\nthat minimizes the loss L between the predictions of g and\nthe complex model f , considering the locality kernel π\nx ,\nand /Omega1(g) is the complexity of the interpretable model g with\nlower complexity preferred for better interpretability, while\nalso maintaining simplicity\nˆg = arg min\ng∈G\nL( f , g,π x ) + /Omega1(g). (12)\nIn this study, we examine the rationale behind the predic-\ntions made by our proposed FAST-RNN model by utilizing\nLIME. The utterances deemed most hateful were divided\ninto two groups: moderately hateful and hateful. This clas-\nsiﬁcation was based on whether the statements provoked\nactions of violence or discrimination. The categorization into\nmoderately hateful and hateful was inﬂuenced by deﬁnitions\nestablished in studies by Sanguinetti et al. [ 63] and Sharma et\nal. [ 66]. According to these deﬁnitions, utterances explicitly\nencouraging violence or discriminatory actions were clas-\nsiﬁed as severely hateful. The degree of severity remained\nunchanged whether the authors merely justiﬁed such actions,\nexpressed a desire for their occurrence, or showed a willing-\nness to partake in them. Consequently, any utterances that in\nany manner incited such actions were included in this most\nsevere category. Following are the deﬁnitions of all categories\nin our dataset.\n1. Hateful: Hateful utterances are utterances that are partly\nor wholly motivated by hate or negative attitudes towards\ngroups or individuals based on ethnicity, religion, sex-\nuality, gender, age, political views, social status, or\ndisabilities and which encourage violent actions based\non this.\n2. Moderately Hateful: Moderately hateful utterances are\nutterances that are partly or fully motivated by hate or\nnegative attitudes towards groups or individuals based on\nethnicity, religion, sexuality, gender, age, political views,\nsocial status, or disabilities. The utterances do not call to\naction but still violate the integrity and disparage a group\nor individual’s dignity.\n123\n4550 Complex & Intelligent Systems (2024) 10:4535–4556\nTable 15 Comparative macro\nF1-scores of baseline with\nproposed FAST-RNN and\ntransformers\nBaseline Models\nModel Provocative Offensive Moderately Hateful Hateful\nBiLSTM 0.61 0.27 0.11 0.08\nCNN-LSTM 0.59 0.35 0.05 0.06\nProposed FAST-RNN Model\nModel Provocative Offensive Moderately Hateful Hateful\nFAST-RNN 0.91 0.95 0.93 0.97\n3. Offensive: An utterance is deﬁned as offensive if it con-\ntains hurtful, derogatory, or obscene comments, either\ndirected towards an individual or a group.\n4. Provocative: A provocative utterance contains aggres-\nsive language to express an opinion or can be perceived\nas inappropriate. This includes the use of profane words,\npatronizing language, or the use of irony and sarcasm to\nlower the credibility of an opponent.\n5. Neutral: An utterance which contains neutral language\nand is a factual contribution to the debate.\nFor a clearer understanding, we have implemented LIME\non two examples from each class, as detailed in Table 16.I n\nthe provided LIME visualization in Fig. 10, the model’s deci-\nsion to categorize the text as ’hateful’ is strongly inﬂuenced\nby speciﬁc terms that resonate with the deﬁned character-\nistics of HS. Words like \"bomber\" (bomber) and \"kutter\"\n(cut) are particularly weighted, suggesting a violent disposi-\ntion towards the mentioned group, in this case, individuals of\nPakistani ethnicity. The term \"sendt,\" translating to \"send,\"\nfurther contributes to this categorization as it implies an\nactionable directive, which is a crucial aspect of the classiﬁ-\ncation criteria for HS within the dataset. This term indicates\nnot just a negative sentiment but an incitement to take nega-\ntive action based on ethnicity, aligning with our deﬁnition of\nhate speech. The model’s identiﬁcation of these terms reﬂects\nits capability to recognize and classify language that pro-\nmotes hate-motivated actions against speciﬁc groups, thus\nvalidating the effectiveness of the algorithm in detecting hate\nspeech as deﬁned by our criteria.\nSimilarly, in Fig. 11, the LIME analysis elucidates the\nmodel’s inference process, which strongly suggests the text\nas hateful with an 87% probability. Central to this classiﬁca-\ntion is the verb \"sende\", which implies an action, and in the\ngiven context, an action against the \"somaliere\" (Somalis)\ncommunity. The sequence of highlighted words constructs\na narrative supporting the removal of this group from the\ncountry, which is a clear indication of HS according to the\ndeﬁnition. The model’s high weighting on these speciﬁc\nterms indicates its capability to parse and understand the\nintent behind the words, recognizing the call to action that\nconstitutes HS within our dataset parameters. The model’s\ninterpretation aligns with the dataset’s criteria, demonstrat-\ning its nuanced ability to detect incitements to discriminatory\nactions based on ethnicity.\nIn Fig. 12, the LIME visualization isolates signiﬁcant\nterms that collectively contribute to the text being classi-\nﬁed as \"moderately hateful.\" Terms like \"klankultur\" (clan\nculture), \"avskyelig\" (disgusting), and \"press\" (pressure) are\nweighted heavily, indicating a perception of societal bur-\nden. In this case, the language implies a negative opinion\nabout the inﬂuence of Pakistani individuals on public ser-\nvices and society. Though the statement does not directly\nencourage harmful actions, it crosses the line of respectful\nconversation by disrespecting a particular ethnic group. This\nportrayal of an entire community as a stressor on educational\nand health services, marked by terms that imply revulsion and\nﬁnancial burden, aligns with the class category \"4\" classiﬁ-\ncation deﬁnition in the dataset. This nuanced detection by the\nmodel highlights its ability to discern between outright calls\nto action characteristic of more severe HS and the insidious\nnature of moderately hateful language that erodes respect for\ncommunal harmony and individual dignity.\nSimilarly, in 13, the highlighted word \"Islamisert\" and\n\"kolonisert\" dominate the narrative of the model’s inter-\npretation with high probability scores, implying societal\ntransformation or takeover, which is interpreted as negative.\nThe text projects a future scenario where the inﬂuence of\nthe Muslim community is portrayed in terms of colonization\nand Islamization, terms that carry a heavy historical and neg-\native connotation. Despite the absence of a call to action, the\nlanguage used disparages the community’s dignity and inte-\ngrates notions of cultural subversion, which are characteristic\nof ’moderately hateful’ content as deﬁned in the dataset.\nFor the ﬁrst visualization 14, the model strongly identiﬁes\nthe term top term \"feita\" (ugly/fat) with the highest weight\nas offensive which is directed at individuals like ’bergens’\nand ’solberg’. This word, particularly when used to describe\na person, carries a negative connotation that is both hurtful\nand derogatory. The term \"slengt\" (thrown) can also imply a\ndismissive or contemptuous attitude, further supporting the\noffensive classiﬁcation.\nFor the second visualization 15, the model has highlighted\nexplicit terms such as \"pikk\" (dick/cock), \"elsker\" (loves),\n\"ri\" (tear/rip), and the phrase \"stor pikk\" (big dick/cock),\nwhich are sexually explicit and considered obscene. The\n123\nComplex & Intelligent Systems (2024) 10:4535–4556 4551\nFig. 10 Example 1: hateful\ninstance visualization with\nLIME\nFig. 11 Example 2: hateful\ninstance visualization with\nLIME\nFig. 12 Example 1: moderately\nhateful instance visualization\nwith LIME\nuse of these terms in the context provided is inappropriate,\nderogatory, and clearly intended to be offensive, especially\nwhen directed at an individual or group. This kind of lan-\nguage falls under the offensive category, because it is hurtful\nand violates social norms of decency.\nIn Fig. 16, the LIME visualization highlights the use of\nthe terms \"sannheter\" (truths), \"nyanser\" (nuances), \"ufeil-\nbarlige\" (infallible), and \"fremstillinger\" (representations),\nwhich together create a narrative that can be perceived as\ndismissive and patronizing. These terms, particularly in the\ncontext provided, suggest an ironic or sarcastic critique of\nmedia or societal understanding, which may be provocative\nto those who hold opposing views. The use of these terms in a\nway that challenges the subject’s credibility or oversimpliﬁes\ncomplex issues ﬁts the deﬁnition of provocative content in\nthe dataset. The model’s detection of these nuanced uses of\nlanguage highlights its sensitivity to the subtleties of provoca-\ntive speech, which is not overtly aggressive but can still incite\nstrong reactions from an opponent’s standpoint.\nIn Fig. 17, the highlighted word \"orgier\" (orgies), with\nits signiﬁcant weight, stands out as a term that tradition-\nally relates to excessive, unrestrained, or scandalous sexual\nactivity. When mentioned in conjunction with \"Florida\", a\nplace known for its vibrant nightlife and cultural diversity, it\nmight suggest a provocative statement about certain behav-\niors or events in that location. The model’s 100% conﬁdence\nFig. 13 Example 2: moderately\nhateful instance visualization\nwith LIME\n123\n4552 Complex & Intelligent Systems (2024) 10:4535–4556\nFig. 14 Example 1: offensive\ninstance visualization with\nLIME\nFig. 15 Example 2: offensice\ninstance visualization with\nLIME\nin classifying this utterance as \"provocative\" indicates that\nthe language used here is likely meant to shock or provoke a\nresponse from the audience. It ﬁts the deﬁnition of provoca-\ntive content that includes aggressive language or statements\nthat can be perceived as inappropriate, such as the use of pro-\nfane words or the depiction of scandalous behavior. While\nthe statement does not contain outright offensive or hateful\nlanguage, the implication of the terms used is sufﬁcient to\nprovoke or challenge societal norms, thereby justifying its\nclassiﬁcation within the dataset.\nFigures 18 and 19 highlight the examples of the neu-\ntral class from our dataset. In Fig. 18, none of the words\nare assigned any signiﬁcant probability distribution, and\nExample 1 from Table 16 also conveys a neutral sentiment.\nConsequently, our learning algorithm has accurately pre-\ndicted this as neutral, conﬁrming the absence of hate-related\ncontent.\nFigure 19 presents a more complex set of terms where\n\"forbanna\" (angry) could typically connote a negative sen-\ntiment. However, in the broader context of the discussion\nabout cultural values, this expression of emotion does not\ntranslate into offensive or aggressive speech. The model’s\ninterpretation of these terms, while acknowledging the pres-\nence of strong emotion, appropriately recognizes the absence\nof targeted negativity or incitement, thus validating the neu-\ntral categorization.\nAfter analyzing ﬁgure 20, the LIME visualization indi-\ncates an incorrect neutral classiﬁcation by the model. The\nactual sentiment of the text implies a hateful intent, espe-\ncially with the use of \"send\" in a context suggesting exile\nor banishment. This wrong prediction made by the learning\nalgorithm shows the need to improve its ability to recog-\nnize context elements. For the second misclassiﬁed example\n21, the model again incorrectly classiﬁes the text as neutral,\nwith a 100% probability. The text includes a term that refers\nto conﬂict with \"Islam,\" and when combined with \"ytrings-\nfriheten\" (freedom of speech) being the \"det frste ofrest\" (the\nﬁrst victim), it implies a negative sentiment towards the reli-\ngion that could be perceived as ’moderately hateful.’ This\nsuggests animosity without an explicit call to action, which\nshould have been ﬂagged as such, rather than neutral. This\nmisclassiﬁcation highlights a potential area for improvement\nin the algorithm’s ability to detect and accurately categorize\nsubtle forms of HS.\nConclusion and future work\nThis research advances the ﬁeld of multi-class HS detec-\ntion by introducing an effective model for the Norwegian\nlanguage, employing a BiLSTM-GRU architecture, known\nas FAST-RNN. Through rigorous regularization and hyper-\nparameter tuning, the FAST-RNN model has demonstrated\nsuperior performance over the baseline across all evaluation\nmetrics. The application of supervised FastText embedding\nhas proven especially beneﬁcial for categorical classiﬁcation\ntasks. Additionally, this work has explored the capabilities of\nlanguage-speciﬁc and multilingual transformer-based mod-\nels enhanced by generative conﬁguration and hyperparameter\ntuning. Moreover, prompt-based ﬁne-tuning, including both\nfew-shot and full ﬁne-tuning, revealed that the latter substan-\ntially improved model outcomes due to the ability to provide\nmore examples and the selection of an optimal generative\n123\nComplex & Intelligent Systems (2024) 10:4535–4556 4553\nFig. 16 Example 1: provocative\ninstance visualization with\nLIME\nFig. 17 Example 2: provocative\ninstance visualization with\nLIME\nFig. 18 Example 1: neutral\ninstance visualization with\nLIME\nFig. 19 Example 2: neutral\ninstance visualization with\nLIME\nFig. 20 Example 1: wrong\nprediction visualization with\nLIME\n123\n4554 Complex & Intelligent Systems (2024) 10:4535–4556\nFig. 21 Example 2: wrong\nprediction visualization with\nLIME\nTable 16 Multi-class Norwegian HS examples for LIME\nCategory Original Text English Translation\nNeutral frykter at ﬁnnmark blir uten meieri fear that ﬁnnmark will be left without a dairy\nNeutral blir forbanna over at listhaug sier at spagetti er en norsk verdi\neller noe sånt\ngetting pissed off that listhaug says that spaghetti is a\nnorwegian value or something like that\nProvocative oi så ﬂink du er til å forenkle fremstillinger er det derfor\ndu ellers ser samfunnet svart/hvitt media skriver om noe løgn\ngjevjongteigan etc skriver noe ufeilbarlige sannheter mester i\nnyanser og dyptenkning er du vel ikke\noh you are so good at simplifying representations that\nis why you otherwise see society black/white the media\nwrites about something a lie gjevjongteigan etc writes\nsomething infallible truths you are probably not a master\nof nuances and deep thinking\nProvocative jeg visste ikke at user likte orgier og holdt til i ﬂorida i did not know user liked orgies and lived in ﬂorida\nOffensive ja for bergens feita hoyre sosialisten solberg gjorde ikke noe for\nå få ham slengt ut er hun mascokist han erklarte jo på nrk at han\nskulle drepe henne noe galt er det med feita\nyes, because bergens fat rightwing socialist solberg did\nnot do anything to get him thrown out she is a masochist\nhe explained on the phone that he was going to kill her is\nthere something wrong with fat\nOffensive søt tenåring elsker å ri på en sto cute teen loves to ride a big dick\nModerately Hateful Ja de ﬂytter hit og vi får verre liv klankultur misogyni høye\nøkte offentlige utgifter press på skole og helsevesen gjengprob-\nlematikk resrelatert vold og aller verst en retardert avskyelig\nreligion bruker vi din logikk bør vel alle pakistanere få komme\ni n no gb l i\nyes they move here and we get a worse life clan culture\nmisogyny high increased public expenditure pressure on\nschools and health care gang problems race related vio-\nlence and worst of all a retarded disgusting religion if we\nuse your logic i guess all pakistanis should be allowed to\ncome in and stay\nModerately Hateful innen 2050 er vi nok bde islamisert og kolonisert by 2050 we will probably be both Islamized and colonized\nHateful når du trenes opp i bomber kutter strupen på barn og kvinner da\ner du et hjernevasket sharia dyr og du er etnisk pakistansk bør\ndu bli sendt til pakisan med ett lite bidrag de klarer av slikt send\nhennes inﬂuensere dit også\nwhen you are trained in bombs cut the throats of children\nand women then you are a brainwashed sharia animal and\nyou are ethnically pakistani you should be sent to pakisan\nwith a small contribution they can manage from this send\nher inﬂuencers there too\nHateful sende somaliere ut av dette landet send somalis out of this country\nconﬁguration. The implementation of LIME for explainable\nAI has further strengthened our approach, providing clarity\nand understanding of the model’s decision-making process.\nTransformer-based models did not exhibit the expected level\nof performance enhancement. This can be attributed to their\nreliance on large and complex datasets, which are often\nnot available for less-resourced languages like Norwegian.\nAdditionally, we observed that generally models with fewer\nparameters did not yield optimal results. In the future, we\nare determined to leverage advanced multilingual transform-\ners such as mT5 and GPT models having a high number of\nparameters to cover more contextual information for multi-\nlabel and multi-class classiﬁcation tasks in multilingual\nHS-related contexts, particularly for low-resource languages.\nOur approach will be to strategically navigate issues such as\ndata sparsity and model adaptability to different languages,\nwith a commitment to enhancing the performance of HS\ndetection systems for various other low-resourced languages.\nAcknowledgements This research work has been acknowledged\nby SOCYTI ( https://www.bigdata.vestforsk.no/ongoing/socyti). The\nSOCYTI project has received funding from the Research Council of\nNorway as a Researcher Project for Technological Convergence related\nto Enabling Technologies under Grant Agreement No. 331736.\nAuthor Contributions Ehtesham Hashmi: conceptualization, data anal-\nysis, formal analysis, research execution, design of methods, resources,\nsoftware, writing original draft, and investigation. Sule Yildirim Yayil-\ngan: visualization, supervision, project management, funding acquisi-\ntion, research conduct, and validation.\n123\nComplex & Intelligent Systems (2024) 10:4535–4556 4555\nFunding Open access funding provided by Norwegian University of\nScience and Technology.\nData availability and access Not Applicable.\nDeclarations\nConﬂict of interest The authors declare that they have no conﬂict of\ninterest.\nEthical and informed consent for data used Not applicable.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing, adap-\ntation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indi-\ncate if changes were made. The images or other third party material\nin this article are included in the article’s Creative Commons licence,\nunless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your\nintended use is not permitted by statutory regulation or exceeds the\npermitted use, you will need to obtain permission directly from the copy-\nright holder. To view a copy of this licence, visit http://creativecomm\nons.org/licenses/by/4.0/.\nReferences\n1. Akuma S, Lubem T, Adom IT (2022) Comparing bag of words\nand tf-idf with different models for hate speech detection from live\ntweets. Int J Inform Technol 14(7):3629–3635\n2. Ali R, Farooq U, Arshad U et al (2022) Hate speech detection on\ntwitter using transfer learning. Comput Speech Lang 74:101365\n3. Andreassen SM, Seim GT (2020) Detecting and grading hateful\nmessages in the norwegian language. Master’s thesis, NTNU\n4. Aswad E (2016) The role of us technology companies as enforcers\nof Europe’s new internet hate speech ban. HRLR Online 1:1\n5. Awal MR, Lee RKW, Tanwar E, et al (2023) Model-agnostic\nmeta-learning for multilingual hate speech detection. IEEE Trans\nComput Soc Syst\n6. Ayo FE, Folorunso O, Ibharalu FT et al (2021) A probabilistic\nclustering model for hate speech classiﬁcation in twitter. Expert\nSyst Appl 173:114762\n7. Batarﬁ HA, Alsaedi OA, Wali AM, et al (2023) Impact of data aug-\nmentation on hate speech detection. In: International Conference\non Innovations for Community Services, Springer, pp 187–199\n8. Biecek P , Burzykowski T (2021) Local interpretable model-\nagnostic explanations (lime). Explanat Model Anal Explore\nExplain Examine Predict Models 1:107–124\n9. Bigoulaeva I, Hangya V , Gurevych I, et al (2023) Label modiﬁ-\ncation and bootstrapping for zero-shot cross-lingual hate speech\ndetection. Lang Resour Evaluat:1–32\n10. Bosco C, Felice D, Poletto F, et al (2018) Overview of the evalita\n2018 hate speech detection task. In: Ceur workshop proceedings,\nCEUR, pp 1–9\n11. Bromell D (2022) Regulating free speech in a digital age: hate,\nharm and the limits of censorship. Springer Nature, Berlin\n12. Chhabra A, Vishwakarma DK (2023) A literature survey on mul-\ntimodal and multilingual automatic hate speech identiﬁcation.\nMultimed Syst:1–28\n13. Chung HW, Hou L, Longpre S, et al (2022) Scaling instruction-\nﬁnetuned language models. arXiv preprint arXiv:2210.11416\n14. Clark K, Luong MT, Le QV , et al (2020) Electra: pre-\ntraining text encoders as discriminators rather than generators.\narXiv:2003.10555\n15. Costa VG, Pedreira CE (2023) Recent advances in decision trees:\nan updated survey. Artif Intell Rev 56(5):4765–4800\n16. Davidson T, Warmsley D, Macy M, et al (2017) Automated hate\nspeech detection and the problem of offensive language. In: Pro-\nceedings of the international AAAI conference on web and social\nmedia, pp 512–515\n17. Devlin J, Chang MW, Lee K, et al (2019) Bert: Pre-training\nof deep bidirectional transformers for language understanding.\narXiv:1810.04805\n18. Elzayady H, Mohamed MS, Badran KM et al (2023) A hybrid\napproach based on personality traits for hate speech detection in\nArabic social media. Inte J Elect Comput Eng 13(2):1979\n19. Fan L, Y u H, Yin Z (2020) Stigmatization in social media: docu-\nmenting and analyzing hate speech for Covid-19 on twitter. Proc\nAssoc Inform Sci Technol 57(1):e313\n20. Fersini E, Nozza D, Rosso P , et al (2018) Overview of the evalita\n2018 task on automatic misogyny identiﬁcation (ami). In: CEUR\nworkshop proceedings, CEUR-WS, pp 1–9\n21. Founta A, Djouvas C, Chatzakou D, et al (2018) Large scale\ncrowdsourcing and characterization of twitter abusive behavior.\nIn: Proceedings of the international AAAI conference on web and\nsocial media\n22. Founta AM, Chatzakou D, Kourtellis N, et al (2019) A uniﬁed\ndeep learning architecture for abuse detection. In: Proceedings of\nthe 10th ACM conference on web science, pp 105–114\n23. Gagliardone I, Gal D, Alves T, et al (2015) Countering online hate\nspeech. Unesco Publishing\n24. García-Díaz JA, Cánovas-García M, Colomo-Palacios R et al\n(2021) Detecting misogyny in Spanish tweets. An approach based\non linguistics features and word embeddings. Fut Gen Comput Syst\n114:506–518\n25. Ghosh K, Senapati A, Narzary M et al (2023) Hate speech detec-\ntion in low-resource bodo and assamese texts with ml-dl and bert\nmodels. Scalab Comput Pract Exp 24(4):941–955\n26. Godioli A, Little LE (2022) Different systems, similar challenges:\nhumor and free speech in the united states and Europe. Humor\n35(3):305–327\n27. Gomez Martin V (2023) Harm, offense, and hate speech. In: Cri-\nsis of the Criminal Law in the Democratic Constitutional State:\nManifestations and Trends. Springer, p 119–135\n28. Grifﬁn R, V ander Maelen C (2023) Codes of conduct in the digital\nservices act: exploring the opportunities and challenges. Available\nat SSRN\n29. Holtzman A, Buys J, Du L, et al (2020) The curious case of neural\ntext degeneration. arXiv:1904.09751\n30. Jahan MS, Oussalah M (2023) A systematic review of hate speech\nautomatic detection using natural language processing. Neurocom-\nputing:126232\n31. Khan L, Amjad A, Afaq KM et al (2022) Deep sentiment analysis\nusing cnn-lstm architecture of english and roman urdu text shared\nin social media. Appl Sci 12(5):2694\n32. Khanday AMUD, Rabani ST, Khan QR et al (2022) Detecting\ntwitter hate speech in covid-19 era using machine learning and\nensemble learning techniques. Int J Inform Manag Data Insights\n2(2):100120\n33. Kim JY , Kesari A (2021) Misinformation and hate speech: the case\nof anti-Asian hate speech during the covid-19 pandemic. J Online\nTrust Saf 1(1)\n34. Kindermann D (2023) Against ‘hate speech’. J Appl Philos\n35. Kumar S, Marklund H, V an Roy B (2023) Maintaining plasticity\nvia regenerative regularization. arXiv preprint arXiv:2308.11958\n36. Kummervold PE, De la Rosa J, Wetjen F, et al (2021) Operational-\nizing a national digital library: the case for a norwegian transformer\nmodel. arXiv preprint arXiv:2104.09617\n123\n4556 Complex & Intelligent Systems (2024) 10:4535–4556\n37. Kutuzov A, Barnes J, V elldal E, et al (2021) Large-scale con-\ntextualised language modelling for norwegian. arXiv preprint\narXiv:2104.06546\n38. Ma R, Miao J, Niu L et al (2019) Transformed 1 regularization for\nlearning sparse deep neural networks. Neural Netw 119:286–298\n39. Mandl T, Modha S, Kumar M A, et al (2020) Overview of the hasoc\ntrack at ﬁre 2020: Hate speech and offensive language identiﬁcation\nin tamil, malayalam, hindi, english and german. In: Proceedings of\nthe 12th Annual Meeting of the Forum for Information Retrieval\nEvaluation, pp 29–32\n40. Mansoor HM (2023) Diversity and pluralism in arab media edu-\ncation curricula: an analytical study in light of unesco standards.\nHum Soc Sci Commun 10(1):1–11\n41. Mazari AC, Boudoukhani N, Djeffal A (2023) Bert-based ensemble\nlearning for multi-aspect hate speech detection. Cluster Comput:1–\n15\n42. Mehta H, Passi K (2022) Social media hate speech detection using\nexplainable artiﬁcial intelligence (xai). Algorithms 15(8):291\n43. Meske C, Bunde E (2023) Design principles for user interfaces\nin ai-based decision support systems: the case of explainable hate\nspeech detection. Inform Syst Front 25(2):743–773\n44. Mikolov T, Grave E, Bojanowski P , et al (2017) Advances\nin pre-training distributed word representations. arXiv preprint\narXiv:1712.09405\n45. Mittal D, Singh H (2023) Enhancing hate speech detection through\nexplainable ai. In: 2023 3rd International Conference on Smart Data\nIntelligence (ICSMDI), IEEE, pp 118–123\n46. Nagar S, Barbhuiya FA, Dey K (2023) Towards more robust hate\nspeech detection: using social context and user data. Soc Netw Anal\nMin 13(1):47\n47. Nemade S, Mane SB, Nandgaonkar S (2023) Detection and clas-\nsiﬁcation of aggressive comments and hate speech. In: 2023\nInternational Conference on Computational Intelligence and Sus-\ntainable Engineering Solutions (CISES), IEEE, pp 55–60\n48. Nobata C, Tetreault J, Thomas A, et al (2016) Abusive language\ndetection in online user content. In: Proceedings of the 25th inter-\nnational conference on world wide web, pp 145–153\n49. i Orts ÒG (2019) Multilingual detection of hate speech against\nimmigrants and women in twitter at semeval-2019 task 5: Fre-\nquency analysis interpolation for hate in speech detection. In:\nProceedings of the 13th International Workshop on Semantic Eval-\nuation, pp 460–463\n50. Papcunová J, Martonˇ cik M, Fedáková D et al (2023) Hate speech\noperationalization: a preliminary examination of hate speech indi-\ncators and their structure. Complex Intell Syst 9(3):2827–2842\n51. Parker S, Ruths D (2023) Is hate speech detection the solution the\nworld wants? Proc Natl Acad Sci 120(10):e2209384120\n52. Peng H (2020) A comprehensive overview and survey of recent\nadvances in meta-learning. arXiv preprint arXiv:2004.11149\n53. Pereira-Kohatsu JC, Quijano-Sánchez L, Liberatore F et al\n(2019) Detecting and monitoring hate speech in twitter. Sensors\n19(21):4654\n54. Platt M, Platt D (2023) Effectiveness of generative artiﬁcial\nintelligence for scientiﬁc content analysis. In: 17th International\nConference on Application of Information and Communication\nTechnologies, IEEE\n55. Ptaszynski M, Pieciukiewicz A, Dybała P (2019) Results of the\npoleval 2019 shared task 6: First dataset and open shared task for\nautomatic cyberbullying detection in polish twitter\n56. Qiao C, Huang B, Niu G, et al (2018) A new method of region\nembedding for text classiﬁcation. In: ICLR (Poster)\n57. Raffel C, Shazeer N, Roberts A et al (2020) Exploring the limits\nof transfer learning with a uniﬁed text-to-text transformer. J Mach\nLearn Res 21(1):5485–5551\n58. Risch J (2023) Toxicity. 86272(12):219–230\n59. Rizwan H, Shakeel MH, Karim A (2020) Hate-speech and offensive\nlanguage detection in roman urdu. In: Proceedings of the 2020\nconference on empirical methods in natural language processing\n(EMNLP), pp 2512–2522\n60. Sabiri B, El Asri B, Rhanoui M (2022) Mechanism of overﬁtting\navoidance techniques for training deep neural networks. In: ICEIS\n(1), pp 418–427\n61. Saleh H, Alhothali A, Moria K (2023) Detection of hate speech\nusing bert and hate speech word embedding with deep model. Appl\nArtif Intell 37(1):2166719\n62. Samuel D, Kutuzov A, Touileb S, et al (2023) Norbench–\na benchmark for norwegian language models. arXiv preprint\narXiv:2305.03880\n63. Sanguinetti M, Poletto F, Bosco C, et al (2018) An italian twit-\nter corpus of hate speech against immigrants. In: Proceedings of\nthe eleventh international conference on language resources and\nevaluation (LREC 2018)\n64. Satpute RS, Agrawal A (2023) A critical study of pragmatic ambi-\nguity detection in natural language requirements. Int J Intell Syst\nAppl Eng 11(3s):249–259\n65. Schmidt A, Wiegand M (2017) A survey on hate speech detec-\ntion using natural language processing. In: Proceedings of the ﬁfth\ninternational workshop on natural language processing for social\nmedia, pp 1–10\n66. Sharma S, Agrawal S, Shrivastava M (2018) Degree based clas-\nsiﬁcation of harmful speech using twitter data. arXiv preprint\narXiv:1806.04197\n67. Trajano D, Bordini RH, Vieira R (2023) Olid-br: offensive lan-\nguage identiﬁcation dataset for brazilian portuguese. Lang Resour\nEvaluat:1–27\n68. Umer M, Imtiaz Z, Ahmad M et al (2023) Impact of convolutional\nneural network and fasttext embedding on text classiﬁcation. Mul-\ntimed Tools Appl 82(4):5569–5585\n69. del V alle-Cano G, Quijano-Sánchez L, Liberatore F et al (2023)\nSocialhaterbert: a dichotomous approach for automatically detect-\ning hate speech on twitter through textual analysis and user proﬁles.\nExpert Syste Appl 216:119446\n70. V aswani A, Shazeer N, Parmar N, et al (2023) Attention is all you\nneed. arXiv:1706.03762\n71. Vismara M, Girone N, Conti D et al (2022) The current status of\ncyberbullying research: a short review of the literature. Curr Opin\nBehav Sci 46:101152\n72. Vuˇckovi´cJ ,L u ˇ ci´c S (2023) Hate speech and social media.\nTEME:191–207\n73. Waseem Z (2016) Are you a racist or am i seeing things? Annotator\ninﬂuence on hate speech detection on twitter. In: Proceedings of\nthe ﬁrst workshop on NLP and computational social science, pp\n138–142\n74. Waseem Z, Hovy D (2016) Hateful symbols or hateful people? Pre-\ndictive features for hate speech detection on twitter. In: Proceedings\nof the NAACL student research workshop, pp 88–93\n75. William P , Gade R, esh Chaudhari R, et al (2022) Machine learn-\ning based automatic hate speech recognition system. In: 2022\nInternational conference on sustainable computing and data com-\nmunication systems (ICSCDS), IEEE, pp 315–318\n76. Yildirim MM, Nagler J, Bonneau R et al (2023) Short of suspen-\nsion: how suspension warnings can reduce hate speech on twitter.\nPerspect Polit 21(2):651–663\nPublisher’s Note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional afﬁliations.\n123",
  "topic": "Norwegian",
  "concepts": [
    {
      "name": "Norwegian",
      "score": 0.7958952188491821
    },
    {
      "name": "Transformer",
      "score": 0.5777885317802429
    },
    {
      "name": "Computer science",
      "score": 0.5442178845405579
    },
    {
      "name": "Computational intelligence",
      "score": 0.5009205341339111
    },
    {
      "name": "Speech recognition",
      "score": 0.4139478802680969
    },
    {
      "name": "Artificial intelligence",
      "score": 0.38572463393211365
    },
    {
      "name": "Natural language processing",
      "score": 0.3658077120780945
    },
    {
      "name": "Linguistics",
      "score": 0.27749574184417725
    },
    {
      "name": "Engineering",
      "score": 0.18987423181533813
    },
    {
      "name": "Electrical engineering",
      "score": 0.1364506185054779
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I204778367",
      "name": "Norwegian University of Science and Technology",
      "country": "NO"
    }
  ]
}