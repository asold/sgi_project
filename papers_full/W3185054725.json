{
  "title": "Attribute Value Generation from Product Title using Language Models",
  "url": "https://openalex.org/W3185054725",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2927235247",
      "name": "Kalyani Roy",
      "affiliations": [
        "Indian Institute of Technology Kharagpur"
      ]
    },
    {
      "id": "https://openalex.org/A2152918269",
      "name": "Pawan Goyal",
      "affiliations": [
        "Indian Institute of Technology Kharagpur"
      ]
    },
    {
      "id": "https://openalex.org/A2118322982",
      "name": "Manish Pandey",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2516936824",
    "https://openalex.org/W2147880316",
    "https://openalex.org/W2951865668",
    "https://openalex.org/W2024105308",
    "https://openalex.org/W4295312788",
    "https://openalex.org/W70399244",
    "https://openalex.org/W4293371931",
    "https://openalex.org/W2805173585",
    "https://openalex.org/W1969221592",
    "https://openalex.org/W2970971581",
    "https://openalex.org/W1940872118",
    "https://openalex.org/W3082274269",
    "https://openalex.org/W172829878",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3034300118",
    "https://openalex.org/W3024131638"
  ],
  "abstract": "Identifying the value of product attribute is essential for many e-commerce functions such as product search and product recommendations. Therefore, identifying attribute values from unstructured product descriptions is a critical undertaking for any e-commerce retailer. What makes this problem challenging is the diversity of product types and their attributes and values. Existing methods have typically employed multiple types of machine learning models, each of which handles specific product types or attribute classes. This has limited their scalability and generalization for large scale real world e-commerce applications. Previous approaches for this task have formulated the attribute value extraction as a Named Entity Recognition (NER) task or a Question Answering (QA) task. In this paper we have presented a generative approach to the attribute value extraction problem using language models. We leverage the large-scale pretraining of the GPT-2 and the T5 text-to-text transformer to create fine-tuned models that can effectively perform this task. We show that a single general model is very effective for this task over a broad set of product attribute values with the open world assumption. Our approach achieves state-of-the-art performance for different attribute classes, which has previously required a diverse set of models.",
  "full_text": "Proceedings of the 4th Workshop on e-Commerce and NLP (ECNLP 4), pages 13–17\nAugust 5, 2021. ©2021 Association for Computational Linguistics\n13\nAttribute Value Generation from Product Title using Language Models\nKalyani Roy\nIIT Kharagpur, India\nkroy@iitkgp.ac.in\nPawan Goyal\nIIT Kharagpur, India\npawang@cse.iitkgp.ac.in\nManish Pandey\nCarnegie Mellon University\nmanish.pandey@west.cmu.edu\nAbstract\nIdentifying the value of product attribute is es-\nsential for many e-commerce functions such\nas product search and product recommenda-\ntions. Therefore, identifying attribute values\nfrom unstructured product descriptions is a\ncritical undertaking for any e-commerce re-\ntailer. What makes this problem challenging\nis the diversity of product types and their at-\ntributes and values. Existing methods have\ntypically employed multiple types of machine\nlearning models, each of which handles spe-\nciﬁc product types or attribute classes. This\nhas limited their scalability and generalization\nfor large scale real world e-commerce applica-\ntions. Previous approaches for this task have\nformulated the attribute value extraction as a\nNamed Entity Recognition (NER) task or a\nQuestion Answering (QA) task. In this pa-\nper we have presented a generative approach\nto the attribute value extraction problem us-\ning language models. We leverage the large-\nscale pretraining of the GPT-2 and the T5 text-\nto-text transformer to create ﬁne-tuned mod-\nels that can effectively perform this task. We\nshow that a single general model is very effec-\ntive for this task over a broad set of product at-\ntribute values with the open world assumption.\nOur approach achieves state-of-the-art perfor-\nmance for different attribute classes, which has\npreviously required a diverse set of models.\n1 Introduction\nProduct attributes and their values play an impor-\ntant role in e-commerce platforms. There are hun-\ndreds of thousands of products sold online and\neach type of product has a different set of attributes.\nThese attributes help customers search for products,\ncompare the relevant items and purchase the prod-\nuct of their choice. While details of a product can\nbe found both in its title as well as its description,\ncommonly, the title includes important attributes\nof the product. Everyday many new products are\nadded to the product catalogue often with new at-\nammoon Electric Guitar 6 String Solid\nWood Brims 23 Frets Basswood Body\nDual-coil Pickup Tremolo & Rhythm\nControl with Pickguard\nBrand Name : ammoon\nType : Electric Guitar\nTone Position : 23\nFingerboard Material : NULL\nBody Material : Basswood\nFigure 1: An example of a product with its title, at-\ntributes and values. There is no value for the attribute\n‘Fingerboard Material’ and it is represented as NULL.\ntributes types and values. However, attribute in-\nformation is often sparse, noisy and incomplete\nwith missing values. For example, Figure 1 shows\na product with its description and attribute value\npairs available on the website. It contains attribute\nvalues for Brand Name, Type etc., but there are\nmissing attributes, such as “Dual-coil” forPickup\nType, “6” for Strings etc. Given the wide diversity\nof products and new products constantly emerging,\nit is important that attribute value extraction works\nwith the open world assumption, i.e., values for the\nattributes not seen before.\nEarlier work (Ghani et al., 2006; Chiticariu et al.,\n2010; Gopalakrishnan et al., 2012) for attribute\nvalue extraction use a rule based approach with the\nhelp of a domain speciﬁc seed dictionary to identify\nthe key phrases. Other work have formulated this\nas named entity recognition (NER) problem (Put-\nthividhya and Hu, 2011; More, 2016). However,\nthese approaches do not work under the open world\nassumption. More recently, various neural network\nbased approaches have been proposed and applied\nto sequence tagging model for attribute value ex-\ntraction. Huang et al. (2015) is the ﬁrst to apply the\nBiLSTM-CRF model for sequence tagging. Zheng\net al. (2018) propose an end-to-end tagging model\nusing BiLSTM, CRF and attention without any dic-\n14\ntionary or hand-crafted features. Most of these\napproaches create separate models for different at-\ntributes. Also, for each attribute a, they have one\nset of tags to denote beginning (Ba) and inside (Ia)\nof that attribute. Hence, these methods are not scal-\nable for large set of attributes and these models can\nnot identify emerging values for unseen attributes.\nRecent works (Xu et al., 2019; Wang et al., 2020)\nhave set up this task as question answering (QA)\ntask. Question answering in machine reading com-\nprehension (MRC) selects a span of text from the\ngiven context to answer the question. Xu et al.\n(2019) considers product title as context, attribute\nas query, and proposes to ﬁnd the attribute value\nusing only global set of BIO tags. Although the\nsequence tagging models (Zheng et al., 2018; Xu\net al., 2019) achieve promising result, they do not\nwork well for discovering new attributes values.\nIn contrast to past extractive or classiﬁcation\nbased approaches, we have taken a generative ap-\nproach to identify attribute values. Text generation\nusing language models has several applications in\nreal-world tasks such as text-editing, article writing,\nsentence completion, etc. Text inﬁlling aims to ﬁll\nthe missing part of a given sentence. Motivated by\ntheir success as well as to leverage the large scale\npretraining of the language models, we formulate\nthe attribute value extraction as an instance of text\ninﬁlling task as well as an answer generation task.\nWe utilize Inﬁlling by Language Modeling (ILM)\n(Donahue et al., 2020) for the inﬁlling approach\nand we ﬁne-tune Text-to-Text Transfer Transformer\n(T5) (Raffel et al., 2020) as an answer generation\ntask. We summarize the main contribution of this\nwork as follows:\n• We propose a language modeling approach\nfor attribute value extraction.\n• We empirically demonstrate that this approach\nachieves state-of-the-art results on discovering\nnew attribute values.\n2 Problem Statement\nIn this section, we formally deﬁne the problem\nof attribute value generation. Given a product\ncontext T = ( wt\n1, wt\n2, ..., wt\nm) and its attribue\nA = (wa\n1 , wa\n2 , ..., wa\nn), our goal is to generate the\nvalue V = (wv\n1, wv\n2, ..., wv\ne ). For example, the con-\ntext of the product in Figure 1 is “ammoon Electric\nGuitar 6 String Solid Wood Brims 23 Frets Bass-\nwood Body Dual-coil Pickup Tremolo & Rhythm\nControl with Pickguard”. Consider the two at-\nAttributes Train Valid test\nAll 76,970 10,996 21,991\nBrand Name 7,969 1,095 2,348\nMaterial 2,824 373 752\nColor 735 112 197\nCategory 662 86 206\nTable 1: Statistics of the A V-109K dataset and its four\nfrequent attributes\ntributes Type and Fingerboard Material. We want\nto generate the value “Electric Guitar” for the at-\ntribute Type and NULL for the attribute Finger-\nboard Material as this attribute is not present in the\ncontext.\nIn this work, ﬁrst, we formulate this problem as\na (i) text inﬁlling task and then as an (ii) answer\ngeneration task. For text inﬁlling, we combine\nthe context, T, attribute, A, and the value, V , in\na sentence as “ T. A is V .” where the attribute\nvalue V is masked as blank. Our objective is to\ngenerate the missing span in this sentence to pre-\ndict this value. Let the incomplete sentence be\n˜S = (ws\n1, ws\n2, ..., ws\np). Our model outputs the best\nattribute value sequence ˜V by learning the distri-\nbution ˜V = P(V | ˜S). In the answer generation\napproach, our aim is to generate V as the answer,\nconsidering T as the context and A as the question.\n3 Experimental Setup\n3.1 Dataset\nWe have used publicly available dataset1 which is\ncollected from Sports & Entertainment category of\nAliExpress (Xu et al., 2019). This dataset contains\n110, 484 examples. Each example contains a triple,\ni.e., context as product title, an attribute and its\nvalue. We preprocessed the dataset to handle noisy\ndata, and removed triples with empty values and\ntriples with ‘-’, ‘/’ as value. This led to a dataset\ncomprising of 109, 957 triples which we refer to as\nA V-109K. There are2, 157 unique attributes and\n11, 847 uniques values in this dataset. Also, not all\nthe attributes have a value in the context and these\nare represented as NULL. There are 21, 461 such\ntriples in A V-109K. We randomly split the data into\n7:1:2 ratio, i.e., we randomly select 76, 970 triples\nas training set, 10, 996 triples as validation set, and\nthe remaining 21, 991 triples as the test set.\n1https://raw.githubusercontent.com/\nlanmanok/ACL19_Scaling_Up_Open_Tagging/\nmaster/publish_data.txt\n15\nMethod EM(%) P(%) R(%) F1(%)\nSUOTag 68.88 70.81 71.31 71.06\nILM 81.14 83.35 83.38 83.37\nT5 81.35 83.89 83.75 83.82\nTable 2: Performance comparison on the A V-109K\ndataset\nTo further examine the model’s ability to gen-\nerate values for unseen attributes, we select ﬁve\nattributes with relatively low frequency (< 0.1%)\nin the dataset: Frame Color, Lenses Color, Shell\nMaterial, Wheel Material and Product Typeand the\nnumber of triples for these attributes are 108, 62,\n36, 23, and 523, respectively. All the triples with\nthese attributes are included in the test set. From\nthe remainder of the dataset, we pick 10% as vali-\ndation set and the rest as the training set. We refer\nto this dataset as A V-zero.\n3.2 Evaluation Metrics\nTo evaluate the models, we use the Exact Match\n(EM ) metric on the generated values where the\nwhole sequence of the value must match. Since\nvalues can contain more than one tokens and mod-\nels may generate tokens in any order, we have also\ncomputed average bag of word precision, recall\nand F1 score as our evaluation measure which are\ndenoted as P, R and F1, respectively. Let N be\nthe size of the dataset, V = {v1, v2, .., vN } be the\ngold standard values, G = {g1, g2, ..., gN } be the\ngenerated values, and |vi ∩ gi| denotes the bag of\nwords overlap between the gold standard and the\ngenerated values corresponding to the ith triple.\nThe computation of P and R is shown below:\nP = 1\nN\n∑N\ni=1\n|vi∩gi|\n|gi| R = 1\nN\n∑N\ni=1\n|vi∩gi|\n|vi|\n3.3 Baselines\nWe compare our models with BiLSTM-\nCRF (Huang et al., 2015) and SUOTag (Scaling\nUp Open Tag) (Xu et al., 2019)2.\n• BiLSTM-CRF (Huang et al., 2015) is consid-\nered to be the state-of-the-art sequence tagging\nmodel for NER tasks. It uses the word embed-\nding from pretrained BERT model and applies\na BiLSTM layer over it to the contextual repre-\nsentation. Finally a Conditional Random Fields\n2A VEQA (Attribute Value Extraction via Question An-\nswering) (Wang et al., 2020) is also a recent work that could\npotentially be a baseline, but we could not get the numbers as\nthe code was not publicly available.\nModels SUOTag ILM T5\nNULL\nPrecision (%) 41.73 75.25 77.32\nRecall (%) 93.10 78.99 74.09\nF1(%) 57.63 77.07 75.67\nEM(%) when attributes\nappear in context 28.86 61.11 54.57\nEM(%) when attributes does\nnot appear in context 69.53 81.22 81.78\nValues having multiple\nwords EM (%) 47.00 62.74 62.96\nNumerical values 43.24 66.56 72.06\nTable 3: Performance of models on A V-109K dataset in\ndifferent scenarios.\n(CRF) (Lafferty et al., 2001) layer is applied over\nthis BiLSTM.\n• SUOTag (Xu et al., 2019) uses two separate\nBiLSTMs over the BERT based pretrained word\nembeddings to represent the context and attribute.\nThen, it applies a cross attention between these\ntwo representations followed by a CRF layer.\n3.4 Implementation Details\nAll the models are implemented with Py-\nTorch (Paszke et al., 2019). We train each model\nfor 5 epochs. The model that performs the best on\nthe validation set is used for evaluating the test set.\nThe minibatch size is ﬁxed to 32. We use AdamW\noptimizer and a learning rate of 5e-5. We use pre-\ntrained GPT-2 small (Radford et al., 2019) model\nto train ILM and we use the validation set perplex-\nity of the model on the masked token. We ﬁne-tune\nT5-Base for the answer generation framework.\n3.5 Results and Discussion\nWe conduct experiments on different settings to\n(1) explore the scalability on large attribute set,\n(2) compare the performance on four frequent at-\ntributes, and (3) examine the model’s ability to\ndiscover new attributes.\nTable 2 reports the performance on the A V-109K\ndataset. Since BiLSTM-CRF requires to tag each\nof the attributes a with separate Ba and Ia tags, it\nis not suitable for a large attribute set. So, we did\nnot consider this model. The overall result shows\nthat both ILM and T5 have the capability to a han-\ndle large number of attributes. Next, we examine\nthe models for various interesting cases such as (a)\nwhen the values are NULL, (b) when the attributes\nappear in the context vs. when the attributes do not\nappear in the context, (c) when the values contain\nmultiple words, and (d) when value has numerical\n16\nAttributes Model EM(%) P(%) R(%) F1(%)\nBrand\nName\nBiLSTM-CRF 85.77 80.99 86.37 83.59\nSUOTag 91.05 92.53 92.35 92.44\nILM 94.72 94.93 94.89 94.91\nT5 94.97 95.35 95.29 95.32\nMaterial\nBiLSTM-CRF 65.03 65.20 67.08 66.13\nSUOTag 68.09 72.21 72.36 72.28\nILM 85.24 88.59 88.10 88.34\nT5 84.57 88.94 87.48 88.20\nColor\nBiLSTM-CRF 42.64 40.74 42.64 41.67\nSUOTag 42.64 43.15 43.09 43.12\nILM 75.63 80.29 79.8 80.04\nT5 76.65 80.63 81.02 80.82\nCategory\nBiLSTM-CRF 48.06 51.25 50.08 50.66\nSUOTag 52.43 56.55 55.26 55.90\nILM 79.13 81.56 81.96 81.76\nT5 74.27 81.67 80.18 80.92\nTable 4: Performance comparison of different models\non four frequent attributes.\ndata. The details are summarized in Table 3. ILM\nperforms better than other models in identifying\ntriples having NULL values. Speciﬁcally, language\nmodels give a much better precision in this case.\nThere are 19.26% NULL values in A V-109K, but\nSUOTag predicts 43.83% data as NULL. Hence,\nit has such high recall. There are very few triples\nwhere the attributes appear in the context - only\n1.50% in train dataset and 1.59% in test dataset.\nSo, when the attribute appears in the context, the\nperformance of all the models is poor in compari-\nson with when the attribute does not appear in the\ncontext. In the A V-109K dataset, there are4, 058\ntriples whose value consist of multiple words. T5\nperforms the best in ﬁnding the values having more\nthan one word. There are 8.5% numerical data in\nthe test set and T5 gives much better results than\nother models in identifying them.\nThe second experiment is conducted on the four\nmost frequent attributes of the A V-109K dataset.\nTable 4 shows the result. T5 performs better than\nother models in Brand Name and Color. For Mate-\nrial and Category, ILM has the best performance.\nWe have looked into the predictions of the values\nin these two categories and found that T5 is not cor-\nrectly identifying the NULL values. On closer look\nat the dataset, we ﬁnd that most of those NULL\nvalues are incorrectly annotated, e.g., “new 1pcs\nGolf Sports Mens Right Left Hand Golf Gloves\nSweat Absorbent Microﬁber Cloth Soft Breathable\nAbrasion Gloves” - the material of this product is\nmicroﬁber, but it is annotated as NULL. T5 has pre-\nAttributes Model EM(%) P(%) R(%) F1(%)\nFrame\nColor\nSUOTag 71.30 71.76 72.22 71.99\nILM 69.44 69.44 69.44 69.44\nT5 74.07 74.07 74.07 74.07\nLenses\nColor\nSUOTag 64.52 64.52 64.52 64.52\nILM 67.74 67.74 67.74 67.74\nT5 69.35 69.35 69.35 69.35\nShell\nMaterial\nSUOTag 30.56 41.2 52.78 46.28\nILM 47.22 59.72 72.22 65.38\nT5 58.33 68.06 77.78 72.59\nWheel\nMaterial\nSUOTag 47.83 52.90 60.87 56.60\nILM 69.57 69.57 69.57 69.57\nT5 78.26 78.26 78.26 78.26\nProduct\nType\nSUOTag 20.84 21.63 21.8 21.71\nILM 57.17 68.84 68.59 68.72\nT5 52.20 62.01 64.15 63.06\nTable 5: Performance comparison of different models\non A V-zero for identifying values of unseen attributes.\ndicted the category as Bicycle Saddle for the title\n“INBIKE Soft Wide Bicycle Saddle Comfortable\nBike Seat Vintage Bicycle Leather Saddle Pad”,\nbut the annotation is NULL. Although T5 has iden-\ntiﬁed the correct value of the attribute, it is marked\nas incorrect due to faulty annotation.\nThe last experiment is performed on A V-zero\ndataset. Table 5 shows the result of discovering\nvalues of ﬁve new attributes. ILM is the best in\nidentifying “Product Type”. The value of most of\nthe “Product Type” isFishing Float, but T5 either\npredicted the product type to be NULL or the type\nof the ﬂoat, e.g., Luminous Fishing Float, Ice Fish-\ning Float, etc. For the remaining three attributes,\nT5 outperforms other models.3 Both T5 and ILM\nperform better than SUOtag in discovering unseen\nattribute values.\n4 Conclusion\nIn this work, we present a formulation to generate\nproduct attribute values as (i) an instance of text\ninﬁlling task and (ii) as an answer generation task.\nWe show that we can leverage GPT-2 based and T5\ntext-to-text transformer models for this task. The\nmodels achieve strong results over a broad set of\nattributes. T5 performs better at multi-word values,\nand ILM is better at predicting null values. Addi-\ntionally, our approach outperforms the state-of-the-\nart models for discovering new attribute values.\n3We would like to note that in Table 5, for some of the\nattributes, all the evaluation metrics are identical. This occurs\nbecause for those attributes, the predicted value is a single\ntoken.\n17\nReferences\nLaura Chiticariu, Rajasekar Krishnamurthy, Yunyao\nLi, Frederick Reiss, and Shivakumar Vaithyanathan.\n2010. Domain adaptation of rule-based annotators\nfor named-entity recognition tasks. In Proceed-\nings of the 2010 Conference on Empirical Meth-\nods in Natural Language Processing , pages 1002–\n1012, Cambridge, MA. Association for Computa-\ntional Linguistics.\nChris Donahue, Mina Lee, and Percy Liang. 2020. En-\nabling language models to ﬁll in the blanks. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 2492–\n2501, Online. Association for Computational Lin-\nguistics.\nRayid Ghani, Katharina Probst, Yan Liu, Marko Krema,\nand Andrew Fano. 2006. Text mining for prod-\nuct attribute extraction. SIGKDD Explor. Newsl. ,\n8(1):41–48.\nVishrawas Gopalakrishnan, Suresh Parthasarathy Iyen-\ngar, Amit Madaan, Rajeev Rastogi, and Srinivasan\nSengamedu. 2012. Matching product titles using\nweb-based enrichment. In Proceedings of the 21st\nACM International Conference on Information and\nKnowledge Management, CIKM ’12, page 605–614,\nNew York, NY , USA. Association for Computing\nMachinery.\nZhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirec-\ntional lstm-crf models for sequence tagging. arXiv\npreprint arXiv:1508.01991.\nJohn D. Lafferty, Andrew McCallum, and Fernando\nC. N. Pereira. 2001. Conditional random ﬁelds:\nProbabilistic models for segmenting and labeling se-\nquence data. In Proceedings of the Eighteenth Inter-\nnational Conference on Machine Learning , ICML\n’01, page 282–289, San Francisco, CA, USA. Mor-\ngan Kaufmann Publishers Inc.\nAjinkya More. 2016. Attribute extraction from\nproduct titles in ecommerce. arXiv preprint\narXiv:1608.04670.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, et al. 2019. Pytorch: An imperative style,\nhigh-performance deep learning library. In Ad-\nvances in neural information processing systems ,\npages 8026–8037.\nDuangmanee Putthividhya and Junling Hu. 2011. Boot-\nstrapped named entity recognition for product at-\ntribute extraction. In Proceedings of the 2011 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 1557–1567, Edinburgh, Scotland,\nUK. Association for Computational Linguistics.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nBlog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a uniﬁed text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1–67.\nQifan Wang, Li Yang, Bhargav Kanagal, Sumit Sang-\nhai, D. Sivakumar, Bin Shu, Zac Yu, and Jon Elsas.\n2020. Learning to extract attribute value from prod-\nuct via question answering: A multi-task approach.\nIn Proceedings of the 26th ACM SIGKDD Interna-\ntional Conference on Knowledge Discovery & Data\nMining, KDD ’20, page 47–55, New York, NY , USA.\nAssociation for Computing Machinery.\nHuimin Xu, Wenting Wang, Xin Mao, Xinyu Jiang, and\nMan Lan. 2019. Scaling up open tagging from tens\nto thousands: Comprehension empowered attribute\nvalue extraction from product title. In Proceedings\nof the 57th Annual Meeting of the Association for\nComputational Linguistics , pages 5214–5223, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nGuineng Zheng, Subhabrata Mukherjee, Xin Luna\nDong, and Feifei Li. 2018. Opentag: Open attribute\nvalue extraction from product proﬁles. In Proceed-\nings of the 24th ACM SIGKDD International Con-\nference on Knowledge Discovery and Data Mining ,\nKDD ’18, page 1049–1058, New York, NY , USA.\nAssociation for Computing Machinery.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7936307787895203
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.6363767385482788
    },
    {
      "name": "Scalability",
      "score": 0.5736226439476013
    },
    {
      "name": "Generative model",
      "score": 0.5209808945655823
    },
    {
      "name": "Machine learning",
      "score": 0.46658024191856384
    },
    {
      "name": "Product (mathematics)",
      "score": 0.4566684067249298
    },
    {
      "name": "Artificial intelligence",
      "score": 0.455778568983078
    },
    {
      "name": "Task (project management)",
      "score": 0.42498964071273804
    },
    {
      "name": "Data mining",
      "score": 0.4130327105522156
    },
    {
      "name": "Natural language processing",
      "score": 0.4114789366722107
    },
    {
      "name": "Generative grammar",
      "score": 0.3716754615306854
    },
    {
      "name": "Information retrieval",
      "score": 0.3227546215057373
    },
    {
      "name": "Database",
      "score": 0.158092200756073
    },
    {
      "name": "Mathematics",
      "score": 0.09605717658996582
    },
    {
      "name": "Engineering",
      "score": 0.07726603746414185
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Geometry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I145894827",
      "name": "Indian Institute of Technology Kharagpur",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I74973139",
      "name": "Carnegie Mellon University",
      "country": "US"
    }
  ]
}