{
  "title": "Dual retrieving and ranking medical large language model with retrieval augmented generation",
  "url": "https://openalex.org/W4410634422",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2111729997",
      "name": "Qimin Yang",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2536210314",
      "name": "Huan Zuo",
      "affiliations": [
        "Changsha Central Hospital",
        "University of South China"
      ]
    },
    {
      "id": "https://openalex.org/A5104176521",
      "name": "Runqi Su",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A5114068760",
      "name": "Hanyinghong Su",
      "affiliations": [
        "University of South China"
      ]
    },
    {
      "id": null,
      "name": "Tangyi Zeng",
      "affiliations": [
        "University of South China",
        "Changsha Central Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2096964682",
      "name": "Huimei Zhou",
      "affiliations": [
        "Changsha Central Hospital",
        "University of South China"
      ]
    },
    {
      "id": "https://openalex.org/A2096403104",
      "name": "Rongsheng Wang",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2098544760",
      "name": "Chen Jiexin",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2103536702",
      "name": "Yijun Lin",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2112221160",
      "name": "Zhiyi Chen",
      "affiliations": [
        "Changsha Central Hospital",
        "Central South University",
        "Theranostics (New Zealand)",
        "University of South China",
        "Changsha Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2099896429",
      "name": "Tao Tan",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2111729997",
      "name": "Qimin Yang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2536210314",
      "name": "Huan Zuo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5104176521",
      "name": "Runqi Su",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5114068760",
      "name": "Hanyinghong Su",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Tangyi Zeng",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096964682",
      "name": "Huimei Zhou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096403104",
      "name": "Rongsheng Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098544760",
      "name": "Chen Jiexin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2103536702",
      "name": "Yijun Lin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2112221160",
      "name": "Zhiyi Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2099896429",
      "name": "Tao Tan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4407303428",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4367595583",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4408257736",
    "https://openalex.org/W4409390844",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W3144293453",
    "https://openalex.org/W4226082499",
    "https://openalex.org/W3099700870",
    "https://openalex.org/W4401857375",
    "https://openalex.org/W4401042753",
    "https://openalex.org/W4307003748",
    "https://openalex.org/W4402351889",
    "https://openalex.org/W4381930847",
    "https://openalex.org/W4393153123",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4389520047",
    "https://openalex.org/W4391490196",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W2563411137",
    "https://openalex.org/W3217305727",
    "https://openalex.org/W4389520259"
  ],
  "abstract": "Recent advancements in large language models (LLMs) have significantly enhanced text generation across various sectors; however, their medical application faces critical challenges regarding both accuracy and real-time responsiveness. To address these dual challenges, we propose a novel two-step retrieval and ranking retrieval-augmented generation (RAG) framework that synergistically combines embedding search with Elasticsearch technology. Built upon a dynamically updated medical knowledge base incorporating expert-reviewed documents from leading healthcare institutions, our hybrid architecture employs ColBERTv2 for context-aware result ranking while maintaining computational efficiency. Experimental results show a 10% improvement in accuracy for complex medical queries compared to standalone LLM and single-search RAG variants, while acknowledging that latency challenges remain in emergency situations requiring sub-second responses in an experimental setting, which can be achieved in real-time using more powerful hardware in real-world deployments. This work establishes a new paradigm for reliable medical AI assistants that successfully balances accuracy and practical deployment considerations.",
  "full_text": "Dual retrieving and ranking medical \nlarge language model with retrieval \naugmented generation\nQimin Yang1,6, Huan Zuo2,3,6, Runqi Su1,6, Hanyinghong Su2, Tangyi Zeng3, Huimei Zhou3, \nRongsheng Wang1, Jiexin Chen1, Yijun Lin1, Zhiyi Chen2,3,4,5 & Tao Tan1\nRecent advancements in large language models (LLMs) have significantly enhanced text generation \nacross various sectors; however, their medical application faces critical challenges regarding both \naccuracy and real-time responsiveness. To address these dual challenges, we propose a novel two-\nstep retrieval and ranking retrieval-augmented generation (RAG) framework that synergistically \ncombines embedding search with Elasticsearch technology. Built upon a dynamically updated medical \nknowledge base incorporating expert-reviewed documents from leading healthcare institutions, \nour hybrid architecture employs ColBERTv2 for context-aware result ranking while maintaining \ncomputational efficiency. Experimental results show a 10% improvement in accuracy for complex \nmedical queries compared to standalone LLM and single-search RAG variants, while acknowledging \nthat latency challenges remain in emergency situations requiring sub-second responses in an \nexperimental setting, which can be achieved in real-time using more powerful hardware in real-world \ndeployments. This work establishes a new paradigm for reliable medical AI assistants that successfully \nbalances accuracy and practical deployment considerations.\nKeywords Medical-large language model, Artificial intelligence (AI), Retrieval-augmented generation \n(RAG)\nIn the rapidly evolving healthcare ecosystem, the integration of big data analytics and Artificial Intelligence \n(AI) technologies is fundamentally transforming clinical practices. Notably, Large Language Models (LLMs)1,2, \nexemplified by ChatGPT3, have demonstrated significant potential across various healthcare domains, particularly \nin patient counseling and medical knowledge dissemination 4. The emergence of specialized Medical LLMs 5–7 \nhas provided healthcare professionals with powerful tools for navigating complex clinical scenarios, offering \nvaluable insights that facilitate early diagnosis and enhance patient guidance. However, the effective deployment \nof these models in medical settings necessitates rigorous validation processes and enhanced accuracy to ensure \nboth the precision and comprehensibility of generated outputs.\nThis study investigates the development and evaluation of a medical-focused LLM architecture that \nincorporates Retrieval-Augmented Generation (RAG) technology8 and integrates external knowledge bases to \nsignificantly enhance the system’s information retrieval and response generation capabilities. While advanced \nlanguage models (e.g., GPT 3, BERT 9, LLaMA 10) have achieved remarkable progress in Natural Language \nProcessing (NLP)11, demonstrating substantial capacity for storing factual knowledge during pre-training and \nexcelling in various NLP tasks, they continue to face challenges in maintaining precision within knowledge-\nintensive domains such as medicine and open-domain question answering.\nTo address these limitations, Lewis et al. introduced the RAG framework 8, which synergistically combines \npre-trained parameterized memories (e.g., sequence-to-sequence models) with non-parameterized external \nknowledge sources (e.g., dense vector indexes derived from comprehensive databases such as Wikipedia). \nAlthough current large-scale pre-trained language models can store factual knowledge in their parameters and \nachieve state-of-the-art performance on downstream NLP tasks, their ability to access and accurately manipulate \nthis knowledge remains limited, particularly in tasks requiring deep expertise. Additionally, providing traceable \n1Faculty of Applied Sciences, Macao Polytechnic University, Macao, China. 2School of Public Health, University of \nSouth China, Hengyang, China. 3The Affiliated Changsha Central Hospital, Hengyang Medical School, University of \nSouth China, Changsha, China. 4Key Laboratory of Medical Imaging Precision Theranostics and Radiation Protection, \nCollege of Hunan Province, The Affiliated Changsha Central Hospital, University of South China, Changsha, \nChina. 5Department of Medical Imaging, The Affiliated Changsha Central Hospital, Hengyang Medical School, \nUniversity of South China, Changsha, China. 6Qimin Yang, Huan Zuo and Runqi Su equal contribution. email:  \nzhiyi_chen@usc.edu.cn; taotan@mpu.edu.mo\nOPEN\nScientific Reports |        (2025) 15:18062 1| https://doi.org/10.1038/s41598-025-00724-w\nwww.nature.com/scientificreports\n\nsources for modeling decisions and updating world knowledge are ongoing research challenges 8. RAG models \novercome these limitations by introducing a differentiable mechanism that enables access to explicitly non-\nparameterized memory. The researchers propose two forms of RAG models: one that performs conditional \ncomputation based on the same retrieval passages throughout the generation of sequences 8, and another \nthat allows different passages to be used for each generated token 12. By utilizing neural retrieval and dense-\nrepresentation techniques such as Dense Passage Retrieval (DPR) 13, RAG enhances the performance of \ntraditional sparse-retrieval methods, improving answer quality and contextual relevance. However, challenges \nsuch as capturing domain expertise more effectively, ensuring timely and accurate retrieval, and maintaining \nanswer-source transparency and traceability remain areas for further research 14,15. There are also many \nknowledge injection methods to enhance the generation of LLM16,17.\nIn the medical field, models like ChatDoctor 18 integrate online and offline retrieval mechanisms to refine \nmedical advice capabilities, surpassing the performance of general-purpose models like ChatGPT4. Zhongjing19, \nthe first LLaMA-based large-scale model in the Chinese medical field, has demonstrated proficiency in handling \ncomplex conversations and spontaneous queries following intensive training and reinforcement learning \nfrom human feedback (RLHF). Despite these advancements, studies such as ChatGPT_USMLE 20 highlight \nongoing limitations in mastering detailed medical knowledge. Additionally, Wikichat21 illustrates how retrieval-\naugmented dialogue generation can effectively reduce misinformation, outperforming previous methods in both \nsimulated and real-world user tests.\nThis paper aims to advance existing RAG technology by reducing its hallucination rate and enhancing its \ninterpretability for applications in the medical field, thereby enabling it to fulfill a unique role in this domain. \nOur proposed medical LLM represents an innovative integration of technologies, specifically built around \nChroma, Elasticsearch, and ColBERTv2 models. The primary contributions of this work are as follows: (1) \nThe implementation of dual retrieval mechanisms-combining word-term and semantic retrieval-to improve \nretrieval accuracy and mitigate the semantic gap between prompt words and retrieved text. (2) The introduction \nof double sorting and the incorporation of ColBERTv2 to enhance the precision of retrieval relevance judgment. \n(3) The pioneering application of RAG in the medical field, with results rigorously evaluated by professional \nphysicians to ensure clinical relevance and accuracy.\nMethods\nAll experiments were conducted on an Ubuntu 22.04 server equipped with an NVIDIA A40 GPU. The model \nused for inference is IvyGPT, a large language model (LLM) fine-tuned on medical data, which demonstrates \nsufficient performance to support this study.\nIvyGPT\nWang et al. introduced IvyGPT 22, a healthcare-specialized LLM based on the LLaMA architecture, designed \nto address the limitations of general-purpose LLMs like ChatGPT in healthcare applications, particularly \nconcerning accuracy and professional suitability. IvyGPT was meticulously trained through supervised learning \nusing high-quality medical Q&A datasets and further refined through reinforcement learning with human \nfeedback (RLHF)23. This training enables IvyGPT to excel in conducting extended, informative dialogues and \ngenerating detailed, comprehensive treatment plans.\nUtilizing the QLoRA training technique24, IvyGPT distinguishes itself as a state-of-the-art medical-oriented \nGPT model. Additionally, the research team contributed a novel dataset tailored to the Chinese healthcare \ncontext, on which IvyGPT demonstrates significant improvements over existing models. The design and \nempirical results of IvyGPT suggest its potential for broad applications in medical education, self-service patient \nassistance, and consultation services, significantly enhancing the precision and efficiency of medical diagnoses \nand treatment recommendations.\nRetrieval-augmented generation\nThe core of Retrieval-Augmented Generation (RAG) lies in its integration of a pre-trained neural retriever \nwith a pre-trained sequence-to-sequence (seq2seq) model, forming an end-to-end trainable probabilistic \nframework. This architecture not only enhances knowledge acquisition capabilities but also enables access to \nexternal knowledge resources without requiring additional training, thanks to its inherent pre-trained retrieval \nmechanism. Moreover, RAG extends beyond generative tasks and can be adapted to sequence classification tasks \nby treating the target category as a single-token target sequence.\nIn this study, we enhance the RAG model by implementing a dual-search strategy across Elasticsearch and \nChroma, followed by passing the merged search results to ColBERTv2 for semantic ranking. This refinement \nsignificantly improves RAG’s retrieval capabilities.\nElasticsearch25,26 has become a critical technology in developing information retrieval systems for \nknowledge-centric chatbots. Its ability to handle vast repositories of large-scale text data with unparalleled \nretrieval speed and real-time information updates makes it particularly valuable. By integrating Elasticsearch, \ndevelopers can efficiently create indexes and perform high-speed searches across extensive textual datasets, such \nas entire Wikipedia entries. This integration provides chatbots with precise and up-to-date knowledge support, \nenhancing both the accuracy and relevance of conversational content.\nChroma is an advanced vector similarity search technology designed to efficiently process large-scale text \ndatasets. By leveraging a pre-trained text embedding model, Chroma transforms documents into compact, dense \nvectors. Its unique vector indexing architecture and optimized search algorithms enable precise identification of \nthe most relevant documents. With its superior design, Chroma handles extensive datasets with minimal latency \nand high processing speeds, making it a versatile solution for various text retrieval applications.\nScientific Reports |        (2025) 15:18062 2| https://doi.org/10.1038/s41598-025-00724-w\nwww.nature.com/scientificreports/\nColBERTv227 is an advanced retrieval engine that employs multi-vector representations to capture the \ncontextual semantic nuances of token-level features through cluster centroids. It innovatively reduces the storage \nrequirements of the multi-vector system by utilizing residual representations, which encode the differences \nbetween the original vectors and their approximations, thereby improving retrieval accuracy while optimizing \nspace efficiency. Building on the original ColBERTv2 model, this version enhances its supervisory mechanism \nby incorporating residual compression techniques and distillation insights from cross-encoder systems, further \nrefining its performance.\nSystem design\nThe design of our system is fundamentally motivated by a profound consideration of domain-specific knowledge \nrepresentation. In highly specialized fields such as rare diseases and cutting-edge medical research, relevant \nterminologies often exhibit extremely low frequency or complete absence in model training corpora. This \ndata sparsity poses significant challenges for traditional vector databases (e.g., Chroma) in converting these \nspecialized terms into semantic vectors, because the limited understanding of domain knowledge in pre-trained \nmodels and the out-of-distribution nature of these terms may lead to vector representations that do not accurately \ncapture professional semantics. To address this, we innovatively incorporate Elasticsearch’s term-based search \nmechanism, which ensures that even the most recently emerged, hard-to-vectorize professional terms can be \neffectively retrieved and utilized to enhance the model’s generation capabilities.\nThe entire system in Fig. 1 is thoughtfully structured into 5 interconnected modules: Knowledge Base, \nQuestion, Retrieval, Generation, and Check. The Check module is responsible for validating the generated \nanswer against the retrieved results to ensure consistency and accuracy. In unison, these 5 modules collaborate \neffectively to generate potentially accurate responses to every user inquiry, guaranteeing a fluid and efficient \nsolution-finding process.\nThe Question module expertly handles the receipt and processing of healthcare-related queries from users \nthrough an interactive chat interface. The system permits users to type in free-form text and provides real-time \nfeedback as the user types, ensuring a responsive and dynamic interaction. Once the user submits their question, \nit is transformed into a vector representation.\nIn the Retrieval stage, the vector representation of the user’s question is sought in both the Chroma and \nElasticsearch databases. The retrieval process inherently involves computing similarities between vectors, \nemploying differing methodologies: Chroma leverages dense vector embeddings for semantic similarity search, \nwhile Elasticsearch utilizes traditional term-based search with support for structured data. Given their respective \nmerits and limitations, the system adopts a hybrid approach to combine the strengths of both methods. \nSubsequently, the hybrid search results from both databases are collectively passed to the ColBERTv2 model. \nColBERTv2 employs multi-vector representations and residual compression techniques to capture fine-grained \nsemantic nuances, enabling it to re-rank the hybrid results and select the top five most semantically aligned \nmatches.These top five selections are then inserted as prompts into IvyGPT, which generates the corresponding \nanswer.\nFig. 1. System design.\n \nScientific Reports |        (2025) 15:18062 3| https://doi.org/10.1038/s41598-025-00724-w\nwww.nature.com/scientificreports/\nFinally, the system’s UI presents the generated answer to the user, accompanied by the first five search results \nunderneath. This arrangement allows the user to evaluate if the search outputs correspond with the actual \ngenerated answer, thereby deciding whether to accept or reject the answer produced by IvyGPT.\nThe external medical files utilized in this system have been sourced from a collaborating Hospital, a \ndistinguished Grade 3A comprehensive healthcare facility that combines multiple facets of medical service \ndelivery, emergency care, health maintenance, rehabilitation, scientific research, and educational instruction.\nThe knowledge base houses an extensive array of medical subspecialties, extending from Orthopedics, \nwhich encompasses diagnosing and treating orthopedic trauma, hand and foot injuries, joint dysfunctions, \nbone pathologies, and the resultant symptoms such as pain, swelling, and limited mobility; to Pediatrics, which \nspecializes in handling pediatric emergencies like respiratory distress, circulatory collapse, shock, and a variety \nof other life-threatening conditions; and Ophthalmology, which delves deeply into diagnosing and managing \na broad spectrum of eye disorders, including eyelid abnormalities, surface ocular diseases, conjunctivitis, \nkeratitis, and conditions affecting the sclera. These medical files are preprocessed and converted into vector \nrepresentations, which are stored in both the Chroma and Elasticsearch vector databases for efficient retrieval. \nFigure 2 illustrates some of the diseases and their presenting symptoms that may occur in orthopedics.\nMoreover, the database features a thorough and meticulous Hospital Departmental Guide, which meticulously \ndelineates the functions and areas of expertise for each department within the institution, specifies their floor-\nby-floor location arrangements, and offers detailed descriptions of the symptoms and unique attributes of the \ndiseases they specialize in treating. This guide is also indexed and stored in the vector databases, enabling the \nsystem to retrieve relevant department information when needed.\nResults\nExperiments\nTo more comprehensively evaluate and substantiate the effectiveness of the proposed system, the experimental \ndesign comprises a two-fold approach. The first component involves an ablation experiment, aimed at \ndiscerning the individual contributions and significance of each integrated module within the system. This phase \nsystematically removes or alters components of the Chroma + Elasticsearch + ColBERTv2 architecture to assess \nthe impact on overall performance, thereby elucidating the inherent value and functionality of each constituent \nelement. The three systems tested are listed in Table 1.\nThe second part of the experiment focuses on a comparative analysis, comparing the system with RAG to the \nsystem without RAG. This comparison aims to demonstrate the importance of RAG in Medical LLMs operations \nthrough both quantitative and qualitative methods. By examining the efficacy of the system in handling complex \nmedical scenarios and generating accurate and rich responses, a robust assessment of the system’s superiority in \nreal-world medical applications is made. System 3 and System 4, and SELF-RAG in Table 2 are the subjects of \nthis experiment.\nTo further validate our system’s performance, we conducted a series of rigorous evaluations focusing on \ncomplex clinical scenarios. Specifically, we designed diagnostic tests for complicated disease cases, establishing \nmultiple simulated scenarios with intricate clinical manifestations. Each test case was carefully constructed to \ninclude complex symptom combinations and challenging diagnostic conditions, thereby thoroughly assessing \nthe system’s robustness and practical utility in real-world medical applications. We used 20 complex cases to test \nour system to evaluate whether it can correctly guide patients to the designated floor and designated department \nfor treatment. As shown in Table 3, we present two examples. Our system can correctly complete this task in \nmost cases. In the first example, the model explains high blood pressure and the vascular system, considers other \nSystem number System components\n1 IvyGPT + Chroma + ColBERTv2\n2 IvyGPT + Elasticsearch + ColBERTv2\n3 IvyGPT + Chroma + Elasticsearch + ColBERTv2\nTable 1. Ablation experiment.\n \nFig. 2. Some of the diseases and their presenting symptoms that may occur in orthopedics.\n \nScientific Reports |        (2025) 15:18062 4| https://doi.org/10.1038/s41598-025-00724-w\nwww.nature.com/scientificreports/\npossible diagnoses, and addresses symptoms such as headaches and physical manifestations. In the second case, \nthe model should first consider specific aneurysm or nuclear disease, and the next is the problem of thyroid \nfunction.\nEvaluation\nAssessing the performance of LLMs with RAG has posed a significant challenge,  the generation quality \nof the model is difficult to evaluate using quantitative standards. Among the myriad approaches taken by \nprevious researchers, some have subjected the models to human-like examinations 29, while others employed \ncrowdsourcing to gauge the quality of the models’ responses 21. We believe that using crowdsourced human \ninspections will be biased due to the lack of professionalism among non-experts, so we asked professional \ndoctors to participate in our evaluation.\nIn contrast, this present study employs a questionnaire-based methodology. Given that LLM engage in \nconversations with humans, the subjective perceptions of users during these interactions hold paramount \nimportance. To this end, the experiment translates human subjects’ subjective impressions into numerical \nscores across various dimensions, thereby providing a metric for evaluating the models’ performance. Five key \ndimensions were identified for the evaluation: (1) Relevance, (2) Accuracy, (3) Anthropomorphism, (4) Speed, \nand (5) Usefulness.\nTo enhance credibility, this questionnaire departs from previous practices by selecting a heterogeneous \nsample of 100 testers, comprising practicing doctors from collaborating hospital, medical students, and university \nprofessors specializing in medicine. This diversity enriches the reliability of the collected data.\nNonetheless, the questionnaire is not entirely subjective. It establishes clear boundaries for the types of \nquestions and expected answers, briefing testers about these limitations before they embark on the evaluation. \nSpecifically, the medical inquiries are restricted to common, non-life-threatening ailments, as our system is \nintended to support patients in making informed decisions and to facilitate expedited access to medical services.\nQuestionares\nFor each experiment, a pair of custom-designed questionnaires was crafted to capture distinct aspects of the \nsystems’ performance.  Questionnaire 1, predominantly emphasizes the assessment of the systems’ search \ncapabilities. It discriminates among the three systems being evaluated based on their unique searching \nproficiencies alone, thus allowing for a targeted evaluation of this crucial functionality. In contrast, Questionnaire \n2 shifts its focus to delve deeper into the level of medical specialization embedded within the systems undergoing \ntesting.\nQuestionnaire 1 for Ablation Experiment: \nGuidance case Our pipeline output Without RAG output\nIn the past 6 months, he has experienced intermittent dizziness and \nheadaches, especially when he gets up in the morning. He also has \na feeling of weakness in his left limbs, especially his left arm, which \nfeels heavy and inflexible. In the past month, he has occasionally \nexperienced blurred vision, especially after reading or staring at the \nscreen for a long time. He has a history of hypertension for many years, \nbut his blood pressure has not been well controlled recently.\nThe patient showed typical symptoms of cerebrovascular \ndisease, such as dizziness, headache, weakness on one side of \nthe limbs, and blurred vision. Combined with his history of \nhypertension, the possibility of cerebral infarction or transient \nischemic attack should be considered. Recommended \nDepartment Neurology (outpatient department third floor) / \nStroke screening and follow-up clinic (outpatient department \nthird floor).\nThe patient typically suffers from back \npain or headaches, should be careful not \nto rest, should not be treated with heat, \nshould the symptoms be undiagnosed \nfor a long time, should the symptoms \nbe considered as a result of physical \nsymptoms, and should be examined by the \ndoctor at the time.\nIn the past 3 months, she has felt extremely tired, had poor sleep \nquality at night, and was sleepy during the day. She also had \npalpitations and a rapid heartbeat, especially after emotional \nfluctuations or physical labor. She had lost a significant amount of \nweight, about 5 kg, and had a loss of appetite. Her skin was dry, her \nnails were brittle, and her hair became sparse and brittle. The daughter \nmentioned that her mother had become more indifferent recently and \nhad less interest in daily affairs.\nThese symptoms may indicate thyroid dysfunction, especially \nhypothyroidism. In addition, cardiac symptoms may also be \ncaused by heart problems due to thyroid dysfunction. Further \nexamination of thyroid function and related indicators \nis required. Recommended departments: Endocrinology \nDepartment (outpatient department third floor) / Thyroid \nMedicine Department (outpatient department second floor).\nThe patient appeared to have a weight loss \nspecial, consider the swelling or nuclear \ndisease, and proceed with the construction \nof the swelling and the chest piece. At the \nsame time, the symptoms of depressive \nsymptoms appeared, and thyroid function \ndecreased, and the patient was admitted \nto the aneurysm department and \nendocrinology department.\n...... ...... ......\nTable 3. Complex medical scenarios experiment (translated).\n \nSystem number System components\n3 IvyGPT + Chroma + Elasticsearch + ColBERTv2\n4 IvyGPT (Without RAG)\n5 SELF-RAG28\nTable 2. Comparison experiment.\n \nScientific Reports |        (2025) 15:18062 5| https://doi.org/10.1038/s41598-025-00724-w\nwww.nature.com/scientificreports/\nQuestionnaire 2 for Comparison Experiment:\nResults analysis\nFigure 3 illustrates the outcomes of the administered Questionnaire 1. From Fig. 3, it is evident that System 3 \nconsistently surpasses Systems 1 and 2 in the dimensions of Relevance and Usefulness, showcasing a notable \nadvantage. We believe that this is because when Elasticsearch performs keyword search, the original text with \nslightly different semantics from the declarative sentence causes the traditional RAG method to deviate in the \nrelevance calculation when asking questions using interrogative sentences, while the auxiliary meta-search \ncan find relevant content as much as possible. Concerning Accuracy, System 3 marginally edges out Systems \n1 and 2, suggesting that all three systems possess a commendable ability to deliver relatively accurate medical \ninformation. However, when it comes to Speed, System 3 exhibits a slight decrease in performance compared \nto its predecessors, which can be attributed to its integration of dual search models, leading to a somewhat \nprolonged response time.\nRegarding the cumulative scores garnered from Questionnaire 1, both System 1 and System 3 managed to \nattain satisfactory scores exceeding the benchmark of 60, with System 3 notably achieving a commendable high \nscore of 70. Conversely, System 2 fell short of the passing threshold. This outcome underscores the superior \nperformance of Chroma, equipped with its semantic search functionality, in accomplishing this particular task.\nIn the illustrations depicted in Fig. 4, System 3 outperforms System 4 across nearly all metrics, except \nfor Speed. Here, System 4 takes a considerable lead as it lacks the RAG feature. Nevertheless, the scores in \nthe remaining categories clearly show that LLM enhanced with RAG capabilities provides superior overall \nScientific Reports |        (2025) 15:18062 6| https://doi.org/10.1038/s41598-025-00724-w\nwww.nature.com/scientificreports/\nperformance, higher accuracy, and greater practicality, especially in fields such as medicine that require precise \nexpertise, where the necessity to reduce hallucination rates and improve accuracy is higher. The shortcomings in \nspeed can be corrected through hardware upgrades and optimizations. Although the dual search slows down the \nwhole system, it is still slightly faster than SELF-RAG, and the proposed pipeline is only slightly inferior to SELF-\nRAG in terms of Anthropomorphism. This may be due to the influence of training and fine-tuning of the large \nlanguage model. Since our medical language model has been fine-tuned on professional medical knowledge, it \nhas certain professional capabilities. However, the distribution of professional data is quite different from that of \nthe open domain, which affects its score in anthropomorphism.\nWe quantified all our tests that are shown in Table 4, measuring the performance of each system by MRR \nand MAP , and added SELF-RAG for comparison. Our proposed pipeline achieved the best results in both \nindicators. SELF-RAG was second only to our pipeline in MRR. We believe this is because the model with 13B \nFig. 4. Results of questionnaire 2.\n \nFig. 3. Results of questionnaire 1.\n \nScientific Reports |        (2025) 15:18062 7| https://doi.org/10.1038/s41598-025-00724-w\nwww.nature.com/scientificreports/\nparameters in SELF-RAG is not a professional medical model and does not include word-meta retrieval. In an \nenvironment containing a large number of professional domain words, it is difficult to query content that has not \nbeen correctly vectorized by the database.\nDiscussion\nThe study reveals the revolutionary effect of incorporating RAG technology within a Medical LLM Guidance \nSystem. The fusion of Chroma’s vector similarity search, Elasticsearch’s real-time indexing capabilities, and \na continuously updated medical knowledge corpus forms a hybrid architecture that markedly enhances the \nprecision and pertinence of generated responses. Experimental findings indicate that the strategic blend of \nChroma and Elasticsearch technologies optimizes information retrieval and synthesis. Finally uses ColBertv2 \nto re-rank the screening results. This approach greatly improves the accuracy of existing RAGs, thereby laying a \nrobust groundwork for dependable AI-powered decision-making in the realm of healthcare.\nWhile the Medical LLM with RAG demonstrates substantial benefits and improvements in medical \nknowledge retrieval and dialogue generation, several limitations should be acknowledged. The reliance on a \ndual search mechanism involving both Chroma and Elasticsearch may contribute to a decrease in response \nspeed, though this trade-off is offset by the significant gains in accuracy and richness of provided information. \nMoreover, despite the inclusion of vetted medical documents, there remains a need for continuous monitoring \nand updating of the knowledge base to account for the latest advancements and changes in medical science.\nIn our medical database, which contains a vast collection of specialized terminology such as ’palpitations’ , \n’skin rash’ , and ’ erosion’ , we encounter a significant challenge when processing patient self-reports. These reports \noften include layman’s descriptions like ’irregular heartbeat’ , ’blistering’ , or ’skin damage’ , which cannot be \neffectively matched with professional medical terms using Elasticsearch’s token-based search alone. To address \nthis limitation, we integrate Chroma for semantic vector matching, which enables more accurate mapping \nbetween colloquial expressions and technical medical terminology.\nHowever, in professional contexts, such as physician-curated medical records, we observe that inputs often \nfall outside the training data distribution of both the LLM and the vectorization model used by Chroma. In such \ncases, when the matching content exists within our database, token-based search proves to be more accurate \nthan vector search for identifying highly similar content. Therefore, we propose a hybrid approach that combines \nChroma’s vector retrieval for supplementary content matching beyond keywords with Elasticsearch’s token-\nbased search, resulting in enhanced overall performance and more comprehensive search capabilities.\nThe proposed system exhibits two primary limitations: temporal efficiency and the necessity of high-quality \ndatabase content. Due to the implementation of dual retrieval mechanisms (lexical and vector-based) and \nsubsequent two-stage ranking, the system incurs higher computational overhead compared to conventional \napproaches. This increased processing time is a trade-off for enhanced retrieval accuracy and comprehensive \nresults.\nFurthermore, the quality of the database is a critical factor in determining the system’s output reliability. In \nour experiments, when utilizing professionally curated medical data from hospital sources-such as physician-\nannotated records and department-level information-the system demonstrated high precision in recommending \nappropriate medical departments and their corresponding physical locations within the hospital. However, when \nintegrating data scraped from medical forums into the database, the system’s performance degraded significantly. \nFor instance, even for common symptoms like “fever, ” the system retrieved highly improbable disease-related \nsnippets (e.g., cancer), which were irrelevant to the query context. This highlights the importance of maintaining \na high-quality, professionally vetted database to ensure the system’s practical utility and reliability in real-world \nmedical scenarios.\nFuture directions will explore three optimization pathways: 1) Hardware-accelerated retrieval pipelines 2) \nLightweight neural ranking models 3) Context-aware search pruning algorithms. These developments aim to \npreserve accuracy gains while achieving emergency-ready performance, ultimately bridging the gap between \nalgorithmic innovation and clinical implementation requirements.\nConclusion\nOur two-stage retrieval and ranking RAG framework represents a significant advancement in medical \nQA systems, addressing the dual challenges of accuracy and responsiveness in medical AI applications. By \nsynergistically integrating embedding search with Elasticsearch technology and leveraging ColBERTv2 for \ncontext-aware ranking, our approach achieves a 10% improvement in accuracy over standalone LLMs and single-\nsearch RAG variants. This performance gain underscores the effectiveness of hybrid retrieval architectures in \nSystem components Mean reciprocal rank Mean average precision\nIvyGPT + Chroma 0.62 0.54\nIvyGPT + Chroma + ColBERTv2 0.66 0.59\nIvyGPT + Elasticsearch + ColBERTv2 0.57 0.51\nSELF-RAG 0.69 0.60\nOur pipeline 0.72 0.63\nTable 4. Mean reciprocal rank (MRR) and mean average precision (MAP) of different systems in our test \ncases. Significant values are in bold.\n \nScientific Reports |        (2025) 15:18062 8| https://doi.org/10.1038/s41598-025-00724-w\nwww.nature.com/scientificreports/\nhandling complex medical inquiries, particularly when built upon a dynamically updated medical knowledge \nbase curated from expert-reviewed documents.\nIn the experimental environment, the response time is slightly longer than other systems due to equipment \nlimitations, but better hardware in actual deployment can mitigate this issue and achieve real-time response. \nOur work establishes a robust paradigm for reliable medical AI assistants, successfully balancing accuracy with \npractical deployment considerations.\nData availability\nSome of the data that support the fndings of this study are available from the corresponding author upon rea -\nsonable request. Some of the public ones are available through  h t t p s :  / / g i t h  u b . c o m  / W a n g R  o n g s h  e n g / a w  e s o m e -  L \nL M - r e  s o u r s e s\nReceived: 15 September 2024; Accepted: 30 April 2025\nReferences\n 1. Hadi, M. U. et al. Large language models: A comprehensive survey of its applications, challenges, limitations, and future prospects. \nhttps://doi.org/10.36227/techrxiv.23589741.v8 (2025).\n 2. Brown, T. et al. Language models are few-shot learners. Adv. Neural. Inf. Process. Syst. 33, 1877–1901 (2020).\n 3. Achiam, J. et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023).\n 4. Wu, T. et al. A brief overview of chatgpt: The history, status quo and potential future development. IEEE/CAA J. Autom. Sin. 10, \n1122–1136 (2023).\n 5. Thirunavukarasu, A. J. et al. Large language models in medicine. Nat. Med. 29, 1930–1940 (2023).\n 6. Li, J. et al. Instruction fine-tuning of large language models for traditional Chinese medicine. In China Conference on Knowledge \nGraph and Semantic Computing, 419–430 (Springer, 2024).\n 7. Wang, H. et al. Knowledge-tuning large language models with structured medical knowledge bases for trustworthy response \ngeneration in Chinese. ACM Trans. Knowl. Discov. Data 19, 1–17 (2025).\n 8. Lewis, P . et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Adv. Neural. Inf. Process. Syst. 33, 9459–9474 \n(2020).\n 9. Devlin, J., Chang, M.-W ., Lee, K. & Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding. \nIn Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human \nLanguage Technologies, volume 1 (Long and Short Papers), 4171–4186 (2019).\n 10. Touvron, H. et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023).\n 11. Chowdhary, K. & Chowdhary, K. Natural language processing. In Fundamentals of Artificial Intelligence, 603–649 (2020).\n 12. Borgeaud, S. et al. Improving language models by retrieving from trillions of tokens. In International Conference on Machine \nLearning, 2206–2240 (PMLR, 2022).\n 13. Karpukhin, V . et al. Dense passage retrieval for open-domain question answering. In EMNLP, Vol. 1, 6769–6781 (2020).\n 14. Fan, W . et al. A survey on rag meeting llms: Towards retrieval-augmented large language models. In Proceedings of the 30th ACM \nSIGKDD Conference on Knowledge Discovery and Data Mining, 6491–6501 (2024).\n 15. Jeong, S., Baek, J., Cho, S., Hwang, S. J. & Park, J. Adaptive-rag: Learning to adapt retrieval-augmented large language models \nthrough question complexity. In NAACL (2024).\n 16. Y asunaga, M. et al. Deep bidirectional language-knowledge graph pretraining. In Neural Information Processing Systems (NeurIPS) \n(2022).\n 17. Cheng, Y ., Li, K. & Kang, Z. Emkg: Efficient matchings for knowledge graph integration in stance detection. In 2024 International \nJoint Conference on Neural Networks (IJCNN), 1–8. https://doi.org/10.1109/IJCNN60899.2024.10651163 (2024).\n 18. Li, Y . et al. ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain \nKnowledge. Cureus 15(6), e40895. https://doi.org/10.7759/cureus.40895 (2023).\n 19. Y ang, S. et al. Zhongjing: Enhancing the Chinese medical capabilities of large language model through expert feedback and real-\nworld multi-turn dialogue. In In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 38, 19368–19376 (2024).\n 20. Gilson, A. et al. How does ChatGPT perform on the united states medical licensing examination (USMLE)? The implications of \nlarge language models for medical education and knowledge assessment. JMIR Med. Educ. 9, e45312 (2023).\n 21. Semnani, S., Y ao, V ., Zhang, H. C. & Lam, M. Wikichat: Stopping the hallucination of large language model chatbots by few-shot \ngrounding on Wikipedia. In The 2023 Conference on Empirical Methods in Natural Language Processing (2023).\n 22. Wang, R. et al. Ivygpt: Interactive Chinese pathway language model in medical domain. In CAAI International Conference on \nArtificial Intelligence, 378–382 (Springer, 2023).\n 23. Ouyang, L. et al. Training language models to follow instructions with human feedback. Adv. Neural. Inf. Process. Syst. 35, 27730–\n27744 (2022).\n 24. Dettmers, T., Pagnoni, A., Holtzman, A. & Zettlemoyer, L. Qlora: Efficient finetuning of quantized llms. In Advances in Neural \nInformation Processing Systems, Vol. 36 (2024).\n 25. Elasticsearch, B. Elasticsearch. In software], version, Vol. 6 (2018).\n 26. Chen, D. et al. Real-time or near real-time persisting daily healthcare data into HDFS and elasticsearch index inside a big data \nplatform. IEEE Trans. Ind. Inf. 13, 595–606 (2016).\n 27. Santhanam, K., Khattab, O., Saad-Falcon, J., Potts, C. & Zaharia, M. A. Colbertv2: Effective and efficient retrieval via lightweight \nlate interaction. In North American Chapter of the Association for Computational Linguistics (2021).\n 28. Asai, A., Wu, Z., Wang, Y ., Sil, A. & Hajishirzi, H. Self-rag: Self-reflective retrieval augmented generation. In NeurIPS 2023 \nWorkshop on Instruction Tuning and Instruction Following (2023).\n 29. Zhang, H. et al. HuatuoGPT, towards taming language model to be a doctor. In Bouamor, H., Pino, J. & Bali, K. (eds.) Findings of \nthe Association for Computational Linguistics: EMNLP 2023, 10859–10885 (Association for Computational Linguistics, Singapore, \n2023).  h t t p s :   /  / d o  i . o r  g /  1 0 . 1 8 6   5 3  / v 1  / 2  0 2 3  . fi   n d  i  n g s - e   m n l p . 7 2 5.\nAcknowledgements\nThis work is supported by Science and Technology Development Fund of Macao (0041/2023/RIB2) and Macao \nPolytechnic University Grant (RP/FCA-15/2022).\nScientific Reports |        (2025) 15:18062 9| https://doi.org/10.1038/s41598-025-00724-w\nwww.nature.com/scientificreports/\nDeclarations\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to Z.C. or T.T.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives \n4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in \nany medium or format, as long as you give appropriate credit to the original author(s) and the source, provide \na link to the Creative Commons licence, and indicate if you modified the licensed material. Y ou do not have \npermission under this licence to share adapted material derived from this article or parts of it. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence \nand your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to \nobtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p : / / c r e a t i v e c o m m o \nn s . o r g / l i c e n s e s / b y - n c - n d / 4 . 0 /     .  \n© The Author(s) 2025 \nScientific Reports |        (2025) 15:18062 10| https://doi.org/10.1038/s41598-025-00724-w\nwww.nature.com/scientificreports/",
  "topic": "Ranking (information retrieval)",
  "concepts": [
    {
      "name": "Ranking (information retrieval)",
      "score": 0.7379099130630493
    },
    {
      "name": "Computer science",
      "score": 0.7221083045005798
    },
    {
      "name": "Information retrieval",
      "score": 0.6458326578140259
    },
    {
      "name": "Dual (grammatical number)",
      "score": 0.5022659301757812
    },
    {
      "name": "Natural language processing",
      "score": 0.4992539882659912
    },
    {
      "name": "Text mining",
      "score": 0.4365275204181671
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3881099224090576
    },
    {
      "name": "Linguistics",
      "score": 0.06645521521568298
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}