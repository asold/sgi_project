{
  "title": "Concurrent Ischemic Lesion Age Estimation and Segmentation of CT Brain Using a Transformer-Based Network",
  "url": "https://openalex.org/W4381198910",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5029416214",
      "name": "Adam Marcus",
      "affiliations": [
        "Imperial College London"
      ]
    },
    {
      "id": "https://openalex.org/A5061918237",
      "name": "Paul Bentley",
      "affiliations": [
        "Imperial College London"
      ]
    },
    {
      "id": "https://openalex.org/A5006461848",
      "name": "Daniel Rueckert",
      "affiliations": [
        "Imperial College London"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2121300729",
    "https://openalex.org/W2159233098",
    "https://openalex.org/W2078408538",
    "https://openalex.org/W2944491145",
    "https://openalex.org/W2803802119",
    "https://openalex.org/W3214419888",
    "https://openalex.org/W3003775010",
    "https://openalex.org/W2116040950",
    "https://openalex.org/W3130628855",
    "https://openalex.org/W3012686190",
    "https://openalex.org/W3087498301",
    "https://openalex.org/W2555151154",
    "https://openalex.org/W3095488583",
    "https://openalex.org/W3137278571",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W6783097568",
    "https://openalex.org/W2913340405",
    "https://openalex.org/W3141797743",
    "https://openalex.org/W3096609285",
    "https://openalex.org/W6755977528",
    "https://openalex.org/W6733590821",
    "https://openalex.org/W4250482878",
    "https://openalex.org/W6637242042",
    "https://openalex.org/W2549139847",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2560023338",
    "https://openalex.org/W6769955919",
    "https://openalex.org/W6685265622",
    "https://openalex.org/W1901129140",
    "https://openalex.org/W2979708377",
    "https://openalex.org/W2222512263",
    "https://openalex.org/W2962766617",
    "https://openalex.org/W2963351448",
    "https://openalex.org/W4297426812",
    "https://openalex.org/W6840563958",
    "https://openalex.org/W2969667256",
    "https://openalex.org/W2148656951",
    "https://openalex.org/W2080504768",
    "https://openalex.org/W6766978945",
    "https://openalex.org/W6757817989",
    "https://openalex.org/W2964054038",
    "https://openalex.org/W6996569244",
    "https://openalex.org/W6749107692",
    "https://openalex.org/W3014974815",
    "https://openalex.org/W3127751679",
    "https://openalex.org/W4312443924",
    "https://openalex.org/W6685133223",
    "https://openalex.org/W3133858468",
    "https://openalex.org/W3106904274",
    "https://openalex.org/W3157088581",
    "https://openalex.org/W2973179191",
    "https://openalex.org/W2982580298",
    "https://openalex.org/W2127324977",
    "https://openalex.org/W2061058954",
    "https://openalex.org/W2888967035",
    "https://openalex.org/W2007594027",
    "https://openalex.org/W2570333717",
    "https://openalex.org/W3014895431",
    "https://openalex.org/W2884561390",
    "https://openalex.org/W4249417836",
    "https://openalex.org/W4295312788",
    "https://openalex.org/W3215319055",
    "https://openalex.org/W1665214252",
    "https://openalex.org/W4297575730",
    "https://openalex.org/W2899663614",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W3112701542",
    "https://openalex.org/W2963716836",
    "https://openalex.org/W2962851944",
    "https://openalex.org/W4292692470",
    "https://openalex.org/W3085046840",
    "https://openalex.org/W3023305792",
    "https://openalex.org/W4299802238",
    "https://openalex.org/W2963173418",
    "https://openalex.org/W2962914239",
    "https://openalex.org/W4288791681",
    "https://openalex.org/W2588610957"
  ],
  "abstract": "The cornerstone of stroke care is expedient management that varies depending on the time since stroke onset. Consequently, clinical decision making is centered on accurate knowledge of timing and often requires a radiologist to interpret Computed Tomography (CT) of the brain to confirm the occurrence and age of an event. These tasks are particularly challenging due to the subtle expression of acute ischemic lesions and the dynamic nature of their appearance. Automation efforts have not yet applied deep learning to estimate lesion age and treated these two tasks independently, so, have overlooked their inherent complementary relationship. To leverage this, we propose a novel end-to-end multi-task transformer-based network optimized for concurrent segmentation and age estimation of cerebral ischemic lesions. By utilizing gated positional self-attention and CT-specific data augmentation, the proposed method can capture long-range spatial dependencies while maintaining its ability to be trained from scratch under low-data regimes commonly found in medical imaging. Furthermore, to better combine multiple predictions, we incorporate uncertainty by utilizing quantile loss to facilitate estimating a probability density function of lesion age. The effectiveness of our model is then extensively evaluated on a clinical dataset consisting of 776 CT images from two medical centers. Experimental results demonstrate that our method obtains promising performance, with an area under the curve (AUC) of 0.933 for classifying lesion ages ≤ 4.5 hours compared to 0.858 using a conventional approach, and outperforms task-specific state-of-the-art algorithms.",
  "full_text": "©2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any\ncurrent or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new\ncollective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other\nworks.\narXiv:2306.12242v1  [eess.IV]  21 Jun 2023\nIEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2023 1\nConcurrent ischemic lesion age estimation and\nsegmentation of CT brain using a\nTransformer-based network\nAdam Marcus, Paul Bentley, and Daniel Rueckert,Fellow, IEEE\nAbstract— The cornerstone of stroke care is expedient\nmanagement that varies depending on the time since stroke\nonset. Consequently, clinical decision making is centered\non accurate knowledge of timing and often requires a\nradiologist to interpret Computed Tomography (CT) of the\nbrain to confirm the occurrence and age of an event. These\ntasks are particularly challenging due to the subtle expres-\nsion of acute ischemic lesions and the dynamic nature of\ntheir appearance. Automation efforts have not yet applied\ndeep learning to estimate lesion age and treated these\ntwo tasks independently, so, have overlooked their inherent\ncomplementary relationship. To leverage this, we propose a\nnovel end-to-end multi-task transformer-based network op-\ntimized for concurrent segmentation and age estimation of\ncerebral ischemic lesions. By utilizing gated positional self-\nattention and CT-specific data augmentation, the proposed\nmethod can capture long-range spatial dependencies while\nmaintaining its ability to be trained from scratch under low-\ndata regimes commonly found in medical imaging. Fur-\nthermore, to better combine multiple predictions, we in-\ncorporate uncertainty by utilizing quantile loss to facilitate\nestimating a probability density function of lesion age. The\neffectiveness of our model is then extensively evaluated\non a clinical dataset consisting of 776 CT images from two\nmedical centers. Experimental results demonstrate that our\nmethod obtains promising performance, with an area under\nthe curve (AUC) of 0.933 for classifying lesion ages ≤4.5\nhours compared to 0.858 using a conventional approach,\nand outperforms task-specific state-of-the-art algorithms.\nIndex Terms— Brain, computer-aided detection and di-\nagnosis, end-to-end learning in medical imaging, machine\nlearning, neural network, quantification and estimation,\nsegmentation, X-ray imaging and computed tomography.\nI. I NTRODUCTION\nManuscript received July, 2022; revised January, 2023; revised again\nMay, 2023; accepted June, 2023. Date of publication X, 2023; date of\ncurrent version X, 2023. This work was supported by the UK Research\nand Innovation: UKRI Center for Doctoral Training in AI for Healthcare\nunder Grant EP/S023283/1 and UK National Institute for Health Re-\nsearch i4i Program under Grant II-LA-0814-20007. For the purpose of\nopen access, the author has applied a Creative Commons Attribution\n(CC BY) license to any Author Accepted Manuscript version arising.\n(Corresponding author: Adam Marcus.)\nA. Marcus is with the Department of Computing and the Division\nof Brain Sciences, Department of Medicine, Imperial College London,\nLondon SW7 2AZ, U.K. (e-mail: adam.marcus11@imperial.ac.uk).\nP . Bentley is with the Division of Brain Sciences, Department of\nMedicine, Imperial College London, London SW7 2AZ, U.K.\nD. Rueckert is with the Department of Computing, Imperial College\nLondon, London SW7 2AZ, U.K.\nCTCT and expert label\n1 hour 4 hours 80 hours\nLesion age\nFig. 1. Example images and expert segmentations of different subjects\nfrom our clinical dataset illustrating the appearance of ischemic lesions\nchanging over time.\nS\nTROKE is the most frequent cause of adult disability\nand the second commonest cause of death worldwide\n[1]. The vast majority of strokes are ischemic and result\nfrom the blockage of blood flow in a brain artery, often by\na blood clot. Consequently, treatment is focused on rapidly\nrestoring blood flow before irrevocable cell death [2]. The two\nmain approaches are: intravenous thrombolysis, chemically\ndissolving the blood clot; and endovascular thrombectomy,\nphysically removing the blood clot. Notably, the efficacy of\nboth these treatments decreases over time until their benefit is\noutweighed by the risk of complications. It is for this reason\nthat current guidelines limit when specific treatments can be\ngiven. In the case of thrombolysis, to within 4.5 hours of\nonset [3]. Therefore, accurate knowledge of timing is central\nto the management of stroke. However, a significant number\nof strokes are unwitnessed, with approximately 25% occurring\nduring sleep [4]. In these cases, neuroimaging can help, with\nprevious studies showing promising results using modalities\nnot routinely available to patients, such as magnetic resonance\nimaging (MRI) and perfusion computed tomography (CT) [5],\n[6]. Ideally, the widely-available non-contrast CT (NCCT)\nwould be used, but this task is challenging even for detection\nalone, as early ischemic changes are often not visible to the\nnaked eye (Fig. 1).\n2 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2023\nA. Related work\nSeveral studies have attempted to delineate early ischemic\nchanges on NCCT. The majority have used image processing\ntechniques or machine learning methods based on hand-\nengineered features but more recent efforts have used deep\nlearning [7]. Qui et al. [8] proposed a random forest voxel-\nwise classifier using features derived from a pre-trained U-\nNet and achieved a Dice Similarity Coefficient (DSC) [9] of\n34.7% [10]. Barros et al. [11] used a convolutional neural\nnetwork (CNN) and attained a DSC of 37%. El-Hariri et al.\n[7] implemented a modified nnU-Net and reported DSCs of\n37.7% and 34.6% compared to two experts. To the best of the\nauthors’ knowledge, the current state-of-the-art for this task\nis EIS-Net [10], a 3D triplet CNN that achieved a DSC of\n44.8%.\nIn contrast, few studies have explored using NCCT to\nestimate the lesion age. Broocks et al. [12] used quantitative\nnet water uptake, originally introduced by Minnerup et al.\n[13], to identify patients within the 4.5 hour thrombolysis\ntime window and attained an area under the receiver operator\ncharacteristic curve (AUC) of 0.91. Mair et al.[14] introduced\nthe CT-Clock Tool, a linear model using the attenuation ratio\nbetween ischemic and normal brain, and achieved an AUC of\nclassifying scans ≤4.5 hours of 0.955 with median absolute\nerrors of 0.4, 1.8, 17.2 and 32.2 hours for scans acquired ≤3,\n3–9, 9–30 and >30 hours from stroke onset. These studies\nall currently require manual selection of the relevant brain\nregions, and as of yet, have not utilized deep-learning methods\nthat may allow for improved performance.\nDeep learning methods have shown great potential across\nmany domains, with convolutional architectures proving\nhighly successful in medical imaging. Here the inductive\nbiases of CNNs, known to increase sample efficiency [15],\nare particularly useful due to the scarcity of medical data.\nHowever, this may be at the expense of performance, as Trans-\nformers [16] have surpassed CNNs across many computer\nvision tasks. By relying on flexible self-attention mechanisms,\nTransformer-based models can learn global semantic infor-\nmation beneficial to dense prediction tasks like segmentation\nbut typically require vast amounts of training data to do so.\nRecently, d’Ascoli et al.[15] have attempted to address this by\nintroducing gated positional self-attention (GPSA), a type of\nself-attention with a learnable gating parameter that controls\nthe attention paid to position versus content and can combine\nthe benefits of both architectures.\nTraditionally, Transformer and other deep-learning methods\nhave focused on learning different tasks in isolation with\nseparate networks, yet many real-world problems are natu-\nrally multi-modal [17]. This has contributed to the increas-\ning popularity of multi-task learning (MTL) [18], a learning\nparadigm with the aim of jointly learning related tasks to help\nimprove the generalization performance of all tasks [19]. The\nunderlying insight is that by combining the data of different\nlearning tasks, MTL models can learn robust and universal\nrepresentations that enable them to be more powerful and\nreduce the risk of overfitting [19].\nB. Motivation\nAs the appearance of an ischemic lesion is highly dynamic,\na perfect segmentation model would need to recognize lesions\nfor all time points and implicitly understand the lesion age.\nThese two tasks, lesion segmentation and age estimation,\nappear to be inherently complementary, and therefore, it seems\nreasonable that they may benefit from being learned together.\nFurthermore, existing work has shown that estimating lesion\nage can gain from comparing the affected brain to the spatially\ndistant unaffected side [13]. It may then be particularly advan-\ntageous to have a wide receptive field and, consequently, uti-\nlizing mechanisms such as a Transformer would seem appro-\npriately suited. However, standard Transformers are typically\nonly effective at large scales, as they lack some of the inductive\nbiases of convolutional neural networks, such as translational\nequivariance, and thus require large datasets, which are often\nnot available in the medical domain [20]. Hence, it is justifiable\nto consider architectural modifications and alternative designs\nof Transformers that have been suggested to address this issue,\nsuch as using GPSA modules.\nC. Contributions\nIn this work, we propose a multi-task network to simul-\ntaneously perform the segmentation of ischemic lesions and\nestimate their age in CT brain imaging. The main contributions\nare: (1) We introduce a novel end-to-end transformer-based\nnetwork to solve both lesion age estimation and segmentation.\nTo our knowledge, this is the first time a deep learning-based\nmethod has been applied to solve the challenging task of\nestimating lesion age. (2) We enhance the data efficiency of\nour approach by integrating GPSA modules into the model\nand using a CT-specific data augmentation strategy. (3) To\nfurther improve the performance of our model at estimating\nlesion age, we suggest a new method to better combine\nmultiple predictions by incorporating uncertainty through the\nestimation of probability density functions. The effectiveness\nof the proposed method is then demonstrated by extensive\nexperiments using CT imaging data from 776 patients across\ntwo clinical centers.\nII. M ETHOD\nA. Network\nAn overview of the proposed model is presented in Fig. 2.\nThe proposed model is based on the DEtection TRansformer\n(DETR) panoptic segmentation architecture [21] with modifi-\ncations to improve sample efficiency, performance, and facil-\nitate lesion age estimation. Table I summarizes the main ar-\nchitectural differences. All activation functions were changed\nto the Gaussian error linear unit [22] (GELU) and batch\nnormalization [23] was replaced with group normalization [24]\nto accommodate smaller batch sizes. The main components of\nthe proposed model are: 1) a CNN backbone; 2) a transformer\nencoder-decoder; 3) lesion age estimation, and bounding box\nprediction heads; and 4) a segmentation head.\nThe CNN backbone encoder extracts image features of a 2D\nCT slice input image. It is comprised of four ResNeXt [26]\nMARCUS et al.: LESION AGE ESTIMATION AND SEGMENTATION USING A TRANSFORMER-BASED NETWORK 3\nCNN\nencoder\nCNN\ndecoder\nPyramid \npooling \nmodule\nTransformer\nEncoders with gated \npositional self-attention\nSkip connections\n+\nDecoder\n+\nImage Segmentation\nMLP\nMLP\nMLP\nLesion and \nbounding box\nprediction\nAge estimation+ =\nMulti-head\nattention\nFig. 2. Overview of the proposed model architecture. Input 3D CT images are processed slice by slice. First, a CNN backbone combined with\na pyramid pooling module (PPM) extracts image features at multiple scales. Second, a transformer encoder-decoder with gated positional self-\nattention (GPSA) uses these features to predict output embeddings for several object queries. Third, multi-layer perceptrons (MLP) use these\nembeddings to predict lesions, bounding boxes, and lesion age probability distributions. Fourth, a segmentation head generates masks for each\nlesion based on attention. Finally, the per-slice outputs are combined if the predicted masks are connected in 3D, and for each lesion, the most\nlikely age estimate is used.\nTABLE I\nSUMMARY OF MAIN ARCHITECTURAL DIFFERENCES BETWEEN DETR\n[21] AND THE PROPOSED MODEL .\nOurs DETR\nActivation functions GELU [22] ReLU [25]\nNormalization layers GroupNorm [24] BatchNorm [23]\nCNN Backbone ResNeXt-50 32×4d [26] ResNet-50 [27]\nFeature projection PPM [28] 1×1 convolution\nAttention layers GPSA [15] Multi-head attention [16]\nEncoder layers 3 6\nDecoder layers 1 6\nObject queries 10 100\nPrediction heads BBox, class, and regression BBox and class\nGELU = Gaussian error linear unit; ReLU = Rectified linear unit; CNN\n= Convolutional neural network; PPM = Pyramid pooling module; GPSA\n= Gated positional self-attention; BBox = Bounding box\nblocks and produces an activation map. This activation map is\nthen projected to a feature patch embedding and concatenated\nwith fixed positional encodings [29]. Rather than use a 1×1\nconvolution as in the original DETR architecture, we use a\npyramid pooling module [28] (PPM) that has empirically been\nshown to increase the effective receptive field by incorporating\nfeatures extracted at multiple scales.\nThe transformer encoder-decoder learns the attention be-\ntween image features and predicts output embeddings for each\nof the N = 10 object queries. Here N was determined by the\nmaximum number of lesions visible in a given slice. We use\nthree transformer encoder blocks and one transformer decoder\nblock following the standard architecture [16] with a couple of\nexceptions. First, rather than using an auto-regressive model\n[30] we decode the N objects in parallel. Second, to improve\nthe data efficiency of the model we replace the multi-head\nattention layers in the encoder with GPSA layers.\nThe lesion, age estimation, and bounding box prediction\nheads are each multi-layer perceptrons (MLP) and map the\noutput embeddings of the transformer encoder-decoder to\nlesion, lesion age, and bounding box predictions. These heads\nprocess the queries in parallel and share parameters over all\nqueries.\nThe segmentation head generates binary masks for each\nobject instance based on attention. A two-dimensional multi-\nhead attention layer produces attention heatmaps from the\nattention between the outputs of the transformer encoder and\ndecoder. These heatmaps are then upscaled by a U-Net [31]\ntype architecture with long skip connections between the CNN\nencoder and decoder blocks.\nB. Data Augmentation\nTo improve the generalizability of our model and prevent\noverfitting due to limited training data, we adopted a CT-\nspecific augmentation strategy with geometric and appear-\nance transforms. Geometric transforms included: random axial\nplane flips; ±5 % isotropic scaling; ±20 mm translation; and\n±0.5 rad axial otherwise ±0.1 rad plane rotation. Appearance\ntransforms included an intensity transform introduced by Zhou\net al. [32] and a transform we propose to account for the\nslice thickness variation often present in CT datasets. Regions\nof the brain are area interpolated [33] to a random slice\nthickness, ranging from 1–3 mm to match the sizes in our\ndataset, then upscaled back to their original shape. Examples\nof these transforms can be seen in Fig. 3.\nC. Loss Function\nWe use a combined loss function to enable direct set\nprediction. The set prediction ˆy = {ˆyi = {ˆpi,ˆbi, ˆsi, ˆai}}N\ni=1\nconsists of the lesion probability ˆpi ∈ R2 (lesion or no lesion),\nbounding box ˆbi ∈ R4, segmentation mask ˆsi ∈ RH×W where\nH × W is the spatial resolution, and lesion age quantiles\nˆai ∈ R3 for each of the N object queries. To ensure the\nloss function is invariant to permutation of the predictions, the\nHungarian algorithm [34] was used to assign each instance set\nlabel yσ(i) to the corresponding query set prediction ˆyi where\nσi represents the best matching order of labels. The combined\nloss L is normalized by the number of lesions in a batch and\ncomprises of a lesion loss Lp, bounding box losses Lb and\nLg, segmentation losses Lf and Ld, and a lesion age loss La.\n4 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2023\nOriginal\nCT CT and expert label\nGeometricAppearanceCombined\nFig. 3. Example CT -specific geometric and appearance transforms.\nL =\nNX\ni=1\n(λpLp + 1 {pi̸=∅}(λbLb + λgLg+\nλaLa + λf Lf + λdLd)) (1)\nWe used cross-entropy for the lesion loss Lp. For the\nbounding box losses, L1 loss Lb and the generalized intersec-\ntion over union [35] Lg were used. The segmentation losses\ncomprised of Focal loss Lf with α = 0 .25 and γ = 2 as\nrecommended by Lin et al. [36], and Dice loss [37] Ld. To\nenable the uncertainty of lesion age estimates to be quantized,\nwe used quantile loss for the lesion age loss La. We predict\nthree quantiles, assuming that estimates for lesion age are\nnormally distributed, that would correspond to minus one\nstandard deviation from the mean, the mean, and plus one\nstandard deviation from the mean. These can be calculated\nusing ϕ, the cumulative distribution function (CDF) of the\nstandard normal distribution: τ1 = ϕ(−1) ≈ 0.159; τ2 = 0.5;\nτ3 = ϕ(1) ≈ 0.841.\nLa(aσ(i), ˆai) =\n3X\nj=1\nmax(τj||aσ(i) − ˆai,j||1,\n(1 − τj)||aσ(i) − ˆai,j||1) (2)\nIn order to account for the varying difficulties of each task\ncommon to MTL procedures, we employ a random-weighted\nloss function where weights are drawn from the Dirichlet\ndistribution [38].\nλp, λb, λg, λa, λf , λd\ni.i.d.\n∼ Dir(1, 1, 1, 1, 1, 1) (3)\nD. Inference\nAt inference time, we combine lesion age estimates if their\nassociated predicted segmentation masks are connected in\n3D. Given a set of K lesion age quantile predictions ˆa =\n{ˆak}K\nk=1, ˆak ∈ R3, we estimate probability density functions\n(PDF) using f(x; µ, σ1, σ2), the split normal distribution PDF,\nwhere µk = ˆak,2, σk,1 = ˆak,2 − ˆak,1, and σk,2 = ˆak,3 − ˆak,2\nfor each instance.\nf(x; µ, σ1, σ2) =\n\n\n\nA exp\n\u0010\n−(x−µ)2\n2σ2\n1\n\u0011\nx < µ\nA exp\n\u0010\n−(x−µ)2\n2σ2\n2\n\u0011\nx ≥ µ\n,\nwhere A =\np\n2/π(σ1 + σ2)−1 (4)\nThe maximum argument of the sum of these probability\ndensity functions is then the combined lesion age estimate,\nˆaµ. In the rare instances where a set of predictions produces\na negative σk,1 or σk,2, we resort to the mean lesion age\nestimate, ¯µk.\nˆaµ = argmax\nx\nKX\nk=1\nf(x; µk; σk,1; σk,2) (5)\nIII. E XPERIMENTS\nA. Materials\n1) Dataset: Experiments were conducted on a dataset of\n776 acute stroke patients with a known time of onset collected\nacross two clinical sites from 2013 to 2019. Extraction and\nanonymisation of the images followed the pipeline recom-\nmended by Muschelli [39]. The median image size was 512\n× 512 × 187 voxels with a spatial resolution of 0.45mm\n× 0.45mm × 0.8mm. Ground truth segmentation masks of\n79,959 slices were produced by manual annotation from\nexperts. Lesion ages were calculated using the time from\nsymptom onset to imaging and log-transformed to account for\nskewed distribution. Patients were randomly divided such that\na fixed 20% split were used for testing and the remainder for\ntraining and validation using a five-fold group cross-validation\napproach. Table II lists the characteristics of these groups.\nWhen optimizing hyperparameters, 20% of the total dataset\nwas used for validation. An additional independent dataset\nof 150 patients was collected from the same clinical sites\nusing a similar methodology in order to validate lesion age\nestimation performance. Instead of producing segmentation\nmasks, experts selected a total of 4,951 lesion containing\nslices. Full ethical approval was granted by Wales REC 3\nreference number 16/W A/0361.\nMARCUS et al.: LESION AGE ESTIMATION AND SEGMENTATION USING A TRANSFORMER-BASED NETWORK 5\nTABLE II\nPOPULATION CHARACTERISTICS OF THE CLINICAL DATASET\nCharacteristic Train and validation set\n(n = 627)\nTest set\n(n = 149)\nAge (years), median (IQR) 74.9 (63.9-82.8) 74.7 (63.1-83.0)\nSex, n (%)\nMale 317 (50.6%) 71 (47.7%)\nFemale 302 (48.2%) 74 (49.7%)\nMissing 8 (1.3%) 4 (2.7%)\nASPECTS, median (IQR) 9 (8-10) 9 (8-10)\nNIHSS on admission, me-\ndian (IQR) 13 (7-20) 13 (7-19)\nAffected side, n (%)\nLeft 335 (53.4%) 88 (59.1%)\nRight 292 (46.6%) 61 (40.9%)\nTime from symptom onset\nto CT (minutes), median\n(IQR)\n232 (109-1212) 253 (110-1325)\nIQR = Interquartile range; ASPECTS = Alberta stroke programme early\nCT score [40]; NIHSS = National Institutes of Health Stroke Scale [41]\n2) Evaluation: To evaluate lesion segmentation, we com-\npared mean DSC and intersection over union (IOU) between\nmodel predictions and expert segmentation’s on a per-subject\nlevel. The Mann-Whitney U test was used to determine signif-\nicance. Identifying the presence of a lesion is more clinically\nuseful than perfect segmentation therefore, we also computed\nthe lesion detection accuracy (LD-ACC), the percentage of\nexpert segmentations si,j that overlapped with predictions ˆsi,j\nwhere i and j represent indices for the lesion and image slice,\nrespectively.\nLD-ACC = 1\nI\nIX\ni=1\nneq(\nJX\nj=1\nsi,j ˆsi,j)\nwhere neq(x) =\n(\n0 x = 0\n1 x ̸= 0 (6)\nFor lesion age, we excluded subjects with lesions of dif-\nferent ages and calculated the coefficient of determination\n(R2), mean absolute error (MAE), and root mean squared\nerror (RMSE). We also evaluated the classification of lesion\nage within 4.5 hours of onset using accuracy (ACC) and\nAUC. These were then computed for the regression models\nby arranging the I total lesions such that i = 1, ..., I1 lesions\nhad an age less than 4.5 hours and i = I1 + 1, ..., Ilesions\nhad an age greater than 4.5 hours, where ai represents the real\nand ˆai the predicted age.\nACC = 1\nI1\nI1X\ni=1\nacute(ˆai) + 1\nI − I1\nIX\nj=I1\n1 − acute(ˆai)\nwhere acute(x) =\n(\n0 x >\n1 x ≤ log 270 (7)\nAUC =\nPI1\ni=1\nPI\nj=I1 S(ˆai, ˆaj)\nI1(I − I1)\nwhere S(x, y) =\n\n\n\n1 x > y\n0.5 x = y\n0 x < y\n(8)\n3) Implementation: All models were implemented using\nPyTorch [42] version 1.10 and trained from scratch for 100\nepochs on a computer with 3.80GHz Intel® CoreTM i7-10700K\nCPU and an NVIDIA GeForce RTX 3080 10GB GPU. The\nAdamW [43] optimizer was used with a weight decay of 10−4.\nLearning rate was adjusted from 10−6 to 10−2 per-epoch\nusing a cyclical schedule [44] and exponentially decayed per-\ncycle with γ = 0.92. Gradient clipping [45] was applied to\nensure a maximal gradient norm of 0.1. We also employed the\nstochastic weight averaging [46] for the last 5 cycles. During\ntraining, lesion containing regions were linearly sampled from\nthe original volumes to a uniform size, 512 × 512 × 1 for\n2D and 128 × 128 × 48 for 3D models, with a spatial\nresolution of 0.45mm × 0.45mm × 0.8mm. The same CT-\nspecific augmentation strategy was applied for all models.\nPixel intensities were clipped based on the 0.5 and 99.5th\npercentile then normalized using Z-score. Inference of the\nproposed model required about 14 seconds per subject.\nB. Results\n1) Comparison with Baseline: We first compare our pro-\nposed model to task-specific deep-learning algorithms due to\nthe absence of established methods to jointly perform seg-\nmentation and regression. The quantitative results are shown\nin Table III. For segmentation, we compare against 2D [31],\n3D U-Net [47], and TransUNet [48] using the same Focal\nand Dice loss function. In this task, our proposed model\nperforms slightly better, with significant ( p value ≤0.05)\nincreases in DSC and IOU at the expense of generally greater\ncomputational demands. While the metrics may seem low,\nit is unlikely to preclude clinical utility due to the high\nlesion detection accuracies (LDD-ACC), with only 2% of\nlesions going undetected. Notably, despite the proposed model\nbeing 2D in nature, it performed competitively against 3D\nU-Net, suggesting that for lesion segmentation, the ability\nto capture global semantic information may outweigh the\nbenefits of learning volumetric relations. These findings are\nalso supported by qualitative evaluation as seen in Fig. 4.\nFor lesion age estimation, we first trained a linear model\nbased on intensity using a similar methodology to Mair et\nal. [14]. We also trained ResNet-50 [27], ResNeXt-50-32x4d\n[26], and ConvNeXt-T [49] models using the same quantile\nloss function. Compared to these models, our proposed method\noutperforms them by large margins for all metrics tested.\nIt seems, therefore, that explicit supervised learning of both\ntasks may be mutually beneficial and is particularly useful in\nestimating lesion age.\nTo better understand how the proposed model estimates\nlesion age, we produce saliency maps for test images by\n6 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2023\nTABLE III\nLESION AGE ESTIMATION AND SEGMENTATION (MEAN ± STANDARD DEVIATION ) RESULTS OBTAINED BY OUR METHOD AND ABLATION VARIANTS\nCOMPARED TO THE SINGLE -TASK BASELINE MODELS\nRegression Classification Segmentation\nModel Size Flops R 2 MAE RMSE AUC ACC DSC IOU LD-ACC\nIntensity GLM 2 2 0.365 0.816 1.021 0.858 79.5 — — —\nResNet-50 24M 21G 0.308 0.862 1.115 0.906 83.1 — — —\nResNeXt-50 23M 22G 0.402 0.800 1.037 0.908 86.5 — — —\nConvNeXt-T 28M 23G 0.392 0.812 1.011 0.905 86.0 — — —\nOurs 40M 30G 0.513 0.680 0.935 0.933 88.5 38.2 ± 24.2 26.6 ± 21.0 98.0\n2D U-Net 8M 48G — — — — — 35.3 ± 30.0 26.2 ± 26.2 95.3\n3D U-Net 39M 91G† — — — — — 36.7 ± 28.2 26.4 ± 26.4 97.3\nTransUNet 108M 169G — — — — — 36.9 ± 27.7 26.1 ± 25.9 97.3\n(P-value)* (0.038) (0.049)\nResNet-50 (L1) 24M 21G 0.297 0.866 1.124 0.904 81.7 — — —\nResNeXt-50 (L1) 23M 22G 0.396 0.809 1.112 0.907 84.5 — — —\nConvNeXt-T (L1) 28M 23G 0.388 0.824 1.066 0.902 85.3 — — —\nOurs (L1) 40M 30G 0.503 0.636 0.944 0.912 86.5 38.2 ± 24.1 26.3 ± 21.1 98.0\nOurs (only segmentation) 40M 30G — — — — — 37.2 ± 25.1 25.3 ± 24.2 97.3\nOurs (only age estimation) 40M 30G 0.510 0.682 0.938 0.930 86.8 — — —\nOurs (no PPM) 30M 28G 0.330 0.733 1.097 0.874 79.7 36.0 ± 24.0 24.9 ± 20.8 96.6\nOurs (no GPSA) 40M 30G 0.449 0.664 0.995 0.913 83.8 35.4 ± 24.6 24.9 ± 20.7 95.3\nOurs (no RLW) 40M 30G 0.402 0.675 1.036 0.904 83.4 35.0 ± 25.0 24.5 ± 21.5 95.3\nOurs (no DA) 40M 30G 0.025 0.945 1.357 0.756 71.6 31.6 ± 24.6 21.7 ± 20.6 94.6\nMAE = Mean absolute error; RMSE = root mean squared error; AUC = Area under the receiver operator characteristic curve; ACC =\nAccuracy; DSC = Dice similarity coefficient; IOU = intersection over union; LD-ACC = Lesion detection accuracy; GLM = Generalized\nlinear model; L 1 = L1 loss; PPM = Pyramid pooling module; GPSA = Gated positional self-attention; RLW = Random loss weighting;\nDA = Data augmentation\n*P-values are between the results of the proposed model and the next best competing model\n†Normalized by total flops per subject divided by number of slices\n2D U-Net 3D U-Net TransUNet ExpertOurs\nFig. 4. Example lesion segmentations of our method compared to the single-task baseline models.\nbackpropagating back to the input [50]. As seen in Fig. 5,\ncompared to ResNet-50, the proposed method has generally\nmore focused attention on the lesion. Interestingly, and similar\nto the aforementioned intensity approach, the proposed model\nalso appears to be utilizing brain in the corresponding spatially\ndistant unaffected side. This perhaps reinforces the benefit of\nthe model’s wide-receptive field afforded to it by the use of a\nTransformer.\n2) Comparison with other Multi-Task Models: To further\nexplore the synergy between tasks and the effectiveness of\nthe proposed method, we also compare it with recent multi-\ntask learning networks shown in Table IV. These include 3D\nvariants of MA-MTLN[51] and C MSVNetIter[52], which are\ncapable of joint segmentation and classification though not\nregression of medical images. For both lesion age estimation\nand segmentation, we find that the multi-task models perform\nequivalently or are superior to the single-task baseline models.\nWe also note that the proposed method achieves the best\nperformance of the multi-task models and has a greater lead\nin lesion classification than segmentation. It’s possible that\nMARCUS et al.: LESION AGE ESTIMATION AND SEGMENTATION USING A TRANSFORMER-BASED NETWORK 7\nResNet-50 Ours\nFig. 5. Saliency maps for estimating lesion age of the proposed method\ncompared to ResNet-50. The proposed method has more focused\nattention on the lesion and appears to have learned to utilize brain from\nthe unaffected corresponding side.\n101 102 103 104\nActual age / mins\n101\n102\n103\n104\nPredicted age / mins\n<270 mins\n>270 mins\nFig. 6. Scatter plot of predicted versus actual lesion ages for the\nproposed model on the test set.\nthis disparity, favoring classification, may be the result of the\nproposed model being able to utilize continuous lesion ages,\nwhereas the other models were architecturally limited to binary\nlabels.\n3) Comparison with the State-of-the-Art: There are few\nworks that we can compare our results. For segmentation, we\nare aware of only two studies [11], [7] that used ground truth\nNCCT annotations. As argued by El-Hariri et al. [7], direct\ncomparison with studies using annotations from other modali-\nties such as MRI is hindered by the different underlying phys-\niological processes which lead to visible changes. Compared\nwith these studies, the proposed model performs slightly better\non this challenging task with a DSC of 38.2% compared to\n37% by Barros et al.[11] and 37.7% by El-Hairi et al.[7]. For\nlesion age estimation, the proposed model achieved an AUC of\n0 0.1 0.25 0.5 0.75 0.9 1\n1-Specificity (False Positive Rate)\n0\n0.1\n0.25\n0.5\n0.75\n0.9\n1\nSensitivity (True Positive Rate)\nModel (AUC)\nOurs (0.933)\nCMSVNetIter (0.912)\nResNeXt-50 (0.908)\nIntensity GLM (0.858)\nFig. 7. Receiver operating characteristic (ROC) curves of our method\ncompared to the best competing single- and multi-task baselines for\nclassifying lesions ages.\n0.933 for classifying whether a stroke event is within 4.5 hours\nof onset. Similar to the predominately manual methods by\nBroocks et al.[12] and Mair et al.[14] with reported AUC of\n0.91 and 0.955, respectively. However, we note that due to the\ndynamic nature of ischemia, the classification of older lesions\nis considerably easier. This is noticeable in Fig. 6 where the\nproposed model predictions showed better agreement with\nlesions of a greater age. Therefore, the difficulty of this task\nis highly dependent on the distribution of lesion ages in the\ndataset, and without an open benchmark, objective assessment\nagainst other methods is limited. This is further supported\nby Fig. 7 where our intensity model achieves an AUC of\nonly 0.858 using a similar methodology to these studies.\nPerformance aside and in contrast to prior works, the proposed\napproach benefits from being fully automated and naturally\nable to accommodate patients with multiple lesions.\n4) Generalization to Other Datasets: To the best of our\nknowledge, there are no publicly available datasets for is-\nchemic lesion age estimation. For this reason, we utilized an\nadditional independently collected dataset to further validate\nthe performance of our approach with the results shown in\nTable V. Encouragingly, these findings reveal no unexpected\noutcomes, with our method performing best in both regression\nand classification tasks, which aligns with our initial analysis.\nFor lesion segmentation, while there are no datasets with\nground truth NCCT annotations, the ISLES (Ischemic Stroke\nLesion Segmentation) challenge [53] contains images with\nlabels derived from diffusion-weighted imaging. As previously\nnoted, this represents a related, although inherently differ-\nent, task [7]. Additionally, the population characteristics are\nmarkedly different with lower resolution scans and younger\npatients with higher National Institutes of Health Stroke Scale\n(NIHSS) scores [53]. Therefore, we also assess out-of-domain\ngeneralization by comparing the performance of the trained\nproposed model to trained single- and multi-task models on\n8 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2023\nTABLE IV\nLESION SEGMENTATION AND CLASSIFICATION RESULTS (MEAN ± STANDARD DEVIATION ) OBTAINED BY OUR METHOD COMPARED TO MULTI -TASK\nMODELS\nClassification Segmentation\nModel Size Flops AUC ACC DSC IOU LD-ACC\nMA-MTLN 10M 30G† 0.907 86.0 37.0 ± 23.2 26.4 ± 26.2 96.6\nCMSVNetIter 92M 95G† 0.912 86.5 37.4 ± 26.4 26.7 ± 24.3 97.3\nOurs 40M 30G 0.933 88.5 38.2 ± 24.2 26.6 ± 21.0 98.0\n(P-value)* (0.047) (0.449)\nAUC = Area under the receiver operator characteristic curve; ACC = Accuracy; DSC = Dice similarity coefficient; IOU = intersection\nover union; LD-ACC = Lesion detection accuracy\n*P-values are between the results of the proposed model and the next best competing model\n†Normalized by total flops per subject divided by number of slices\nTABLE V\nLESION AGE ESTIMATION RESULTS OBTAINED BY OUR METHOD\nCOMPARED TO THE SINGLE - AND MULTI -TASK MODELS FOR A SECOND\nINDEPENDENT TEST SET\nRegression Classification\nModel R 2 MAE RMSE AUC ACC\nIntensity GLM 0.124 0.920 1.331 0.772 78.0\nResNet-50 0.280 0.861 1.102 0.892 83.3\nResNeXt-50 0.382 0.795 1.043 0.904 86.7\nConvNeXt-T 0.385 0.804 1.031 0.905 86.0\nOurs 0.511 0.682 0.958 0.921 88.7\nMA-MTLN — — — 0.911 86.7\nCMSVNetIter — — — 0.907 87.3\nMAE = Mean absolute error; RMSE = root mean squared error; AUC =\nArea under the receiver operator characteristic curve; ACC = Accuracy\nTABLE VI\nLESION SEGMENTATION RESULTS (MEAN ± STANDARD DEVIATION )\nOBTAINED BY OUR METHOD COMPARED TO THE SINGLE - AND\nMULTI -TASK MODELS FOR THE ISLES-2018 DATASET\nModel DSC IOU LD-ACC\n2D U-Net 18.3 ± 12.9 10.2 ± 9.3 73.0\n3D U-Net 11.1 ± 13.7 6.5 ± 8.7 71.4\nTransUNet 17.7 ± 14.6 9.8 ± 10.1 71.4\nOurs 20.3 ± 11.5 11.2 ± 9.1 74.6\nMA-MTLN 19.7 ± 14.1 11.4 ± 9.6 73.0\nCMSVNetIter 19.8 ± 13.8 11.0 ± 9.8 73.0\n(P-value)* (0.187) (0.356)\nDSC = Dice similarity coefficient; IOU = intersection over union; LD-\nACC = Lesion detection accuracy\n*P-values are between the results of the proposed model and the next\nbest competing model\nthe ISLES 2018 dataset, with results presented in Table VI.\nThe proposed method achieved the highest DSC and LDD-\nACC scores of 20.3% and 74.6%, respectively. However,\nperhaps unsurprisingly, the performance of all models was\nconsiderably worse than the best-published approach [54] for\nthis challenge, with a DSC of 51%. Giving further support to\nthe motivation behind this work, we note that the multi-task\nmodels generally outperform the single-task models. Interest-\ningly, it also seems apparent that the 2D models are able to\ngeneralize better than the 3D models, which may suggest they\nare more robust to the differences in slice thickness.\n5) Ablation Study: We conducted a series of experiments,\nshown in Table III, to verify the effectiveness of our method\nand justify its design decisions. First, we observe that our\ndata augmentation strategy appears to have the largest impact\non lesion age estimation and segmentation performance. It\nseems plausible this may be the result of overfitting from the\nlimited data combined together with the strategy of training\nfrom scratch. Second, by jointly training age estimation and\nsegmentation, the performance of both tasks appear to improve\nmodestly. Third, using GPSA, PPM, and RLW rather than\nequally weighted losses provide benefits primarily to age\nestimation with comparatively little effect on segmentation.\nFinally, we note a consistent increase in lesion age estimation\nperformance gained by using our proposed quantile loss based\nmethod across all tested models.\nIV. D ISCUSSION\nStroke is a leading cause of adult disability and death\nworldwide. Effective clinical management often relies upon\nthe interpretation of CT imaging to confirm both the occur-\nrence and age of an event. Previous attempts to automate\nthese tasks have treated them independently and thereby may\nhave overlooked their apparent complementary relationship.\nIn the present study, a novel transformer-based approach is\nproposed to address this that is able to jointly segment and\nestimate the age of cerebral ischemic lesions. The performance\nof our method was then characterized through a number of\nexperiments.\nA. Limitations\nIt should be noted that this study had several limitations.\nAs the methodology relied heavily on supervised machine\nlearning it was, therefore, subject to many general issues and\nparticularly those common to medical image analysis. First,\nand perhaps the most important, limited sample size due to\nthe amount of data available publicly and the laborious na-\nture of manually annotating additional subjects [55]. Second,\ndifficulties in comparing algorithms in an objective manner\ndue to the different populations and evaluation techniques of\nother published works [56]. Third, the introduction of potential\nbias through the use of data that may not represent the wider\npopulation and therefore hinder generalizability. This is of\nparticular importance as all CT images used were obtained\nMARCUS et al.: LESION AGE ESTIMATION AND SEGMENTATION USING A TRANSFORMER-BASED NETWORK 9\nfrom Siemens scanners and previous studies have shown\nsignificant variation between scanners and manufacturers [57],\n[58]. There are also limitations specific to this work. Only\none experienced scan reader was used to annotate the images.\nThe labels for lesion age are likely subject to significant\nnoise as they rely upon patients accurately reporting the time\nof symptom onset. Finally, the performance of the proposed\nmodel may be limited due to it’s underlying 2D nature, as\nthere are likely aspects that cannot be captured well due to its\ninability to leverage the whole 3D volume.\nB. Future Work\nSubsequent research could seek to address these aforemen-\ntioned limitations. For example, by extending the proposed\nmethod to 3D, which appears relatively straightforward and\ncan be achieved by replacing the backbone CNN encoder and\nsegmentation head with 3D equivalents. However it seems\nlikely that other changes may also be required to main-\ntain computational efficiency. Additionally, before considering\nreal-world deployment, the safety and applicability of our\napproach must be assessed prospectively in a larger and more\nextensive clinical study.\nC. Broader Impact\nIf successfully validated, it is hoped that this work could\nlead to better outcomes for stroke patients due to faster\ndiagnosis and better choice of treatment. Additionally, by\nexclusively using NCCT imaging, our method has the potential\nto be widely applicable, reducing health inequality in areas\nwhere medical experts are limited, such as in low- and middle-\nincome countries [59]. The proposed approach could also find\nuses outside the intended application, anywhere that concur-\nrent segmentation and regression may be seen as beneficial.\nFor example, within healthcare, to detect a pneumothorax or\neffusion on chest X-ray and estimate their volumes [60], [61].\nOr in other domains, such as detecting faces and estimating\ntheir age [62].\nV. C ONCLUSION\nIn this paper, we proposed a novel transformer-based net-\nwork for concurrent ischemic lesion segmentation and age esti-\nmation of CT brain. By incorporating GPSA layers and using a\nmodality-specific data augmentation strategy, we enhanced the\ndata efficiency of our method. Furthermore, we improved le-\nsion age estimation performance by better combining multiple\npredictions through the incorporation of uncertainty. Extensive\nexperiments on a clinical dataset demonstrated the effective-\nness of our method compared to conventional and task-specific\nalgorithms. Future work includes further prospective clinical\nvalidation and exploring the extension of the model to 3D.\nREFERENCES\n[1] W. H. Organization, “Global health estimates,” 12 2018. [Online].\nAvailable: https://www.who.int/healthinfo/global burden disease/en/\n[2] J. L. Saver, “Time is brain—quantified,” Stroke, vol. 37, no. 1, pp. 263–\n266, 2006.\n[3] W. Hacke, M. Kaste, E. Bluhmki, M. Brozman, A. D ´avalos, D. Guidetti,\nV . Larrue, K. R. Lees, Z. Medeghri, T. Machnig et al., “Thrombolysis\nwith alteplase 3 to 4.5 hours after acute ischemic stroke,” New England\njournal of medicine, vol. 359, no. 13, pp. 1317–1329, 2008.\n[4] D. L. Rimmele and G. Thomalla, “Wake-up stroke: clinical character-\nistics, imaging findings, and treatment option–an update,” Frontiers in\nneurology, vol. 5, p. 35, 2014.\n[5] H. Ma, B. C. Campbell, M. W. Parsons, L. Churilov, C. R. Levi, C. Hsu,\nT. J. Kleinig, T. Wijeratne, S. Curtze, H. M. Deweyet al., “Thrombolysis\nguided by perfusion imaging up to 9 hours after onset of stroke,” New\nEngland Journal of Medicine, vol. 380, no. 19, pp. 1795–1803, 2019.\n[6] G. Thomalla, C. Z. Simonsen, F. Boutitie, G. Andersen, Y . Berthezene,\nB. Cheng, B. Cheripelli, T.-H. Cho, F. Fazekas, J. Fiehler et al., “Mri-\nguided thrombolysis for stroke with unknown time of onset,” New\nEngland Journal of Medicine, vol. 379, no. 7, pp. 611–622, 2018.\n[7] H. El-Hariri, L. A. S. M. Neto, P. Cimflova, F. Bala, R. Golan,\nA. Sojoudi, C. Duszynski, I. Elebute, S. H. Mousavi, W. Qiu et al.,\n“Evaluating nnu-net for early ischemic change segmentation on non-\ncontrast computed tomography in patients with acute ischemic stroke,”\nComputers in biology and medicine, p. 105033, 2021.\n[8] W. Qiu, H. Kuang, E. Teleg, J. M. Ospel, S. I. Sohn, M. Almekhlafi,\nM. Goyal, M. D. Hill, A. M. Demchuk, and B. K. Menon, “Machine\nlearning for detecting early infarction in acute stroke with non–contrast-\nenhanced ct,” Radiology, vol. 294, no. 3, pp. 638–644, 2020.\n[9] T. F. Chan and L. A. Vese, “Active contours without edges,” IEEE\nTransactions on image processing, vol. 10, no. 2, pp. 266–277, 2001.\n[10] H. Kuang, B. K. Menon, S. I. Sohn, and W. Qiu, “Eis-net: Segmenting\nearly infarct and scoring aspects simultaneously on non-contrast ct of\npatients with acute ischemic stroke,” Medical Image Analysis, vol. 70,\np. 101984, 2021.\n[11] R. S. Barros, W. E. van der Steen, A. M. Boers, I. Zijlstra, R. van den\nBerg, W. El Youssoufi, A. Urwald, D. Verbaan, P. Vandertop, C. Majoie\net al., “Automated segmentation of subarachnoid hemorrhages with con-\nvolutional neural networks,” Informatics in Medicine Unlocked, vol. 19,\np. 100321, 2020.\n[12] G. Broocks, H. Leischner, U. Hanning, F. Flottmann, T. D. Faizy,\nG. Sch ¨on, P. Sporns, G. Thomalla, S. Kamalian, M. H. Lev et al.,\n“Lesion age imaging in acute stroke: water uptake in ct versus dwi-\nflair mismatch,” Annals of Neurology, vol. 88, no. 6, pp. 1144–1152,\n2020.\n[13] J. Minnerup, G. Broocks, J. Kalkoffen, S. Langner, M. Knauth, M. N.\nPsychogios, H. Wersching, A. Teuber, W. Heindel, B. Eckert et al.,\n“Computed tomography–based quantification of lesion water uptake\nidentifies patients within 4.5 hours of stroke onset: A multicenter\nobservational study,” Annals of neurology, vol. 80, no. 6, pp. 924–934,\n2016.\n[14] G. Mair, A. Alzahrani, R. I. Lindley, P. A. Sandercock, and J. M.\nWardlaw, “Feasibility and diagnostic accuracy of using brain attenuation\nchanges on ct to estimate time of ischemic stroke onset,” Neuroradiol-\nogy, vol. 63, no. 6, pp. 869–878, 2021.\n[15] S. d’Ascoli, H. Touvron, M. L. Leavitt, A. S. Morcos, G. Biroli,\nand L. Sagun, “Convit: Improving vision transformers with soft con-\nvolutional inductive biases,” in International Conference on Machine\nLearning. PMLR, 2021, pp. 2286–2296.\n[16] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in\nneural information processing systems, vol. 30, 2017.\n[17] S. Vandenhende, S. Georgoulis, M. Proesmans, D. Dai, and L. Van Gool,\n“Revisiting multi-task learning in the deep learning era,” arXiv preprint\narXiv:2004.13379, vol. 2, no. 3, 2020.\n[18] R. Caruana, “Multitask learning,” Machine learning, vol. 28, no. 1, pp.\n41–75, 1997.\n[19] Y . Zhang and Q. Yang, “A survey on multi-task learning,” IEEE\nTransactions on Knowledge and Data Engineering, 2021.\n[20] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,\nT. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly et al.,\n“An image is worth 16x16 words: Transformers for image recognition\nat scale,” arXiv preprint arXiv:2010.11929, 2020.\n[21] N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov, and\nS. Zagoruyko, “End-to-end object detection with transformers,” in\nEuropean conference on computer vision. Springer, 2020, pp. 213–\n229.\n[22] D. Hendrycks and K. Gimpel, “Gaussian error linear units (gelus),” arXiv\npreprint arXiv:1606.08415, 2016.\n[23] S. Ioffe, “Batch renormalization: Towards reducing minibatch depen-\ndence in batch-normalized models,” Advances in neural information\nprocessing systems, vol. 30, 2017.\n10 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. XX, NO. XX, XXXX 2023\n[24] Y . Wu and K. He, “Group normalization,” in Proceedings of the\nEuropean conference on computer vision (ECCV), 2018, pp. 3–19.\n[25] V . Nair and G. E. Hinton, “Rectified linear units improve restricted\nboltzmann machines,” in Icml, 2010.\n[26] S. Xie, R. Girshick, P. Doll ´ar, Z. Tu, and K. He, “Aggregated residual\ntransformations for deep neural networks,” in Proceedings of the IEEE\nconference on computer vision and pattern recognition, 2017, pp. 1492–\n1500.\n[27] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proceedings of the IEEE conference on computer vision\nand pattern recognition, 2016, pp. 770–778.\n[28] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, “Pyramid scene parsing\nnetwork,” in Proceedings of the IEEE conference on computer vision\nand pattern recognition, 2017, pp. 2881–2890.\n[29] J.-B. Cordonnier, A. Loukas, and M. Jaggi, “On the relation-\nship between self-attention and convolutional layers,” arXiv preprint\narXiv:1911.03584, 2019.\n[30] O. Vinyals, S. Bengio, and M. Kudlur, “Order matters: Sequence to\nsequence for sets,” arXiv preprint arXiv:1511.06391, 2015.\n[31] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks\nfor biomedical image segmentation,” in International Conference on\nMedical image computing and computer-assisted intervention. Springer,\n2015, pp. 234–241.\n[32] Z. Zhou, V . Sodha, M. M. Rahman Siddiquee, R. Feng, N. Tajbakhsh,\nM. B. Gotway, and J. Liang, “Models genesis: Generic autodidactic\nmodels for 3d medical image analysis,” in International conference on\nmedical image computing and computer-assisted intervention. Springer,\n2019, pp. 384–393.\n[33] P. W. Wong and C. Herley, “Area based interpolation for image scaling,”\nMar. 30 1999, uS Patent 5,889,895.\n[34] H. W. Kuhn, “The hungarian method for the assignment problem,” Naval\nresearch logistics quarterly, vol. 2, no. 1-2, pp. 83–97, 1955.\n[35] H. Rezatofighi, N. Tsoi, J. Gwak, A. Sadeghian, I. Reid, and S. Savarese,\n“Generalized intersection over union: A metric and a loss for bounding\nbox regression,” in Proceedings of the IEEE/CVF conference on com-\nputer vision and pattern recognition, 2019, pp. 658–666.\n[36] T.-Y . Lin, P. Goyal, R. Girshick, K. He, and P. Doll ´ar, “Focal loss\nfor dense object detection,” in Proceedings of the IEEE international\nconference on computer vision, 2017, pp. 2980–2988.\n[37] F. Milletari, N. Navab, and S.-A. Ahmadi, “V-net: Fully convolutional\nneural networks for volumetric medical image segmentation,” in 2016\nfourth international conference on 3D vision (3DV). IEEE, 2016, pp.\n565–571.\n[38] B. Lin, F. Ye, and Y . Zhang, “A closer look at loss weighting in multi-\ntask learning,” arXiv preprint arXiv:2111.10603, 2021.\n[39] J. Muschelli, “Recommendations for processing head ct data,” Frontiers\nin neuroinformatics, vol. 13, p. 61, 2019.\n[40] P. A. Barber, A. M. Demchuk, J. Zhang, A. M. Buchan, A. S. Group\net al., “Validity and reliability of a quantitative computed tomography\nscore in predicting outcome of hyperacute stroke before thrombolytic\ntherapy,” The Lancet, vol. 355, no. 9216, pp. 1670–1674, 2000.\n[41] T. Brott, H. P. Adams Jr, C. P. Olinger, J. R. Marler, W. G. Barsan,\nJ. Biller, J. Spilker, R. Holleran, R. Eberle, and V . Hertzberg, “Mea-\nsurements of acute cerebral infarction: a clinical examination scale.”\nStroke, vol. 20, no. 7, pp. 864–870, 1989.\n[42] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury,\nG. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga,\nA. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani,\nS. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala,\n“Pytorch: An imperative style, high-performance deep learning\nlibrary,” in Advances in Neural Information Processing Systems\n32, H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch ´e-Buc,\nE. Fox, and R. Garnett, Eds. Curran Associates, Inc., 2019,\npp. 8024–8035. [Online]. Available: http://papers.neurips.cc/paper/\n9015-pytorch-an-imperative-style-high-performance-deep-learning-library.\npdf\n[43] I. Loshchilov and F. Hutter, “Decoupled weight decay regularization,”\narXiv preprint arXiv:1711.05101, 2017.\n[44] L. N. Smith, “Cyclical learning rates for training neural networks,”\nin 2017 IEEE winter conference on applications of computer vision\n(WACV). IEEE, 2017, pp. 464–472.\n[45] T. Mikolov, “Statistical language models based on neural networks,”\nPh.D. dissertation, Brno University of Technology, 2012.\n[46] P. Izmailov, D. Podoprikhin, T. Garipov, D. Vetrov, and A. G. Wilson,\n“Averaging weights leads to wider optima and better generalization,”\narXiv preprint arXiv:1803.05407, 2018.\n[47] F. Isensee, P. F. Jaeger, S. A. Kohl, J. Petersen, and K. H. Maier-Hein,\n“nnu-net: a self-configuring method for deep learning-based biomedical\nimage segmentation,” Nature methods, vol. 18, no. 2, pp. 203–211, 2021.\n[48] J. Chen, Y . Lu, Q. Yu, X. Luo, E. Adeli, Y . Wang, L. Lu, A. L. Yuille, and\nY . Zhou, “Transunet: Transformers make strong encoders for medical\nimage segmentation,” arXiv preprint arXiv:2102.04306, 2021.\n[49] Z. Liu, H. Mao, C.-Y . Wu, C. Feichtenhofer, T. Darrell, and S. Xie, “A\nconvnet for the 2020s,” arXiv preprint arXiv:2201.03545, 2022.\n[50] K. Simonyan, A. Vedaldi, and A. Zisserman, “Deep inside convolutional\nnetworks: Visualising image classification models and saliency maps,”\narXiv preprint arXiv:1312.6034, 2013.\n[51] Y . Zhang, H. Li, J. Du, J. Qin, T. Wang, Y . Chen, B. Liu, W. Gao, G. Ma,\nand B. Lei, “3d multi-attention guided multi-task learning network for\nautomatic gastric tumor segmentation and lymph node classification,”\nIEEE Transactions on Medical Imaging, vol. 40, no. 6, pp. 1618–1631,\n2021.\n[52] Y . Zhou, H. Chen, Y . Li, Q. Liu, X. Xu, S. Wang, P.-T. Yap, and D. Shen,\n“Multi-task learning for segmentation and classification of tumors in 3d\nautomated breast ultrasound images,” Medical Image Analysis, vol. 70,\np. 101918, 2021.\n[53] A. Hakim, S. Christensen, S. Winzeck, M. G. Lansberg, M. W. Parsons,\nC. Lucas, D. Robben, R. Wiest, M. Reyes, and G. Zaharchuk, “Predicting\ninfarct core from computed tomography perfusion in acute ischemia with\nmachine learning: lessons from the isles challenge,” Stroke, vol. 52,\nno. 7, pp. 2328–2337, 2021.\n[54] T. Song, “3d multi-scale u-net with atrous convolution for ischemic\nstroke lesion segmentation,” Proc. MICCAI ISLES, 2018.\n[55] I. Balki, A. Amirabadi, J. Levman, A. L. Martel, Z. Emersic, B. Meden,\nA. Garcia-Pedrero, S. C. Ramirez, D. Kong, A. R. Moody et al.,\n“Sample-size determination methodologies for machine learning in\nmedical imaging research: a systematic review,” Canadian Association\nof Radiologists Journal, vol. 70, no. 4, pp. 344–353, 2019.\n[56] C. J. Kelly, A. Karthikesalingam, M. Suleyman, G. Corrado, and\nD. King, “Key challenges for delivering clinical impact with artificial\nintelligence,” BMC medicine, vol. 17, no. 1, p. 195, 2019.\n[57] X. Han, J. Jovicich, D. Salat, A. van der Kouwe, B. Quinn, S. Czanner,\nE. Busa, J. Pacheco, M. Albert, R. Killiany et al., “Reliability of mri-\nderived measurements of human cerebral cortical thickness: the effects\nof field strength, scanner upgrade and manufacturer,” Neuroimage,\nvol. 32, no. 1, pp. 180–194, 2006.\n[58] H. Takao, N. Hayashi, and K. Ohtomo, “Effects of study design in\nmulti-scanner voxel-based morphometry studies,” Neuroimage, vol. 84,\npp. 133–140, 2014.\n[59] B. Wahl, A. Cossy-Gantner, S. Germann, and N. R. Schwalbe, “Artificial\nintelligence (ai) and global health: how can ai contribute to health in\nresource-poor settings?” BMJ global health, vol. 3, no. 4, p. e000798,\n2018.\n[60] K. Hoi, B. Turchin, and A.-M. Kelly, “How accurate is the light index for\nestimating pneumothorax size?” Australasian radiology, vol. 51, no. 2,\npp. 196–198, 2007.\n[61] C. Brockelsby, M. Ahmed, and M. Gautam, “P1 pleural effusion size\nestimation: Us, cxr or ct?” Thorax, vol. 71, no. Suppl 3, pp. A83–A83,\n2016. [Online]. Available: https://thorax.bmj.com/content/71/Suppl 3/\nA83.1\n[62] A. Othmani, A. R. Taleb, H. Abdelkawy, and A. Hadid, “Age estimation\nfrom faces using deep learning: A comparative analysis,” Computer\nVision and Image Understanding, vol. 196, p. 102961, 2020.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6293186545372009
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6071141958236694
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.6039562225341797
    },
    {
      "name": "Segmentation",
      "score": 0.5806973576545715
    },
    {
      "name": "Deep learning",
      "score": 0.5417523980140686
    },
    {
      "name": "Quantile",
      "score": 0.4966199994087219
    },
    {
      "name": "Lesion",
      "score": 0.4880601167678833
    },
    {
      "name": "Medical imaging",
      "score": 0.45360267162323
    },
    {
      "name": "Ischemic stroke",
      "score": 0.4290062487125397
    },
    {
      "name": "Machine learning",
      "score": 0.42639273405075073
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.410235196352005
    },
    {
      "name": "Medicine",
      "score": 0.3054767847061157
    },
    {
      "name": "Statistics",
      "score": 0.13892146944999695
    },
    {
      "name": "Pathology",
      "score": 0.1299695372581482
    },
    {
      "name": "Mathematics",
      "score": 0.10979399085044861
    },
    {
      "name": "Ischemia",
      "score": 0.0
    },
    {
      "name": "Cardiology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I47508984",
      "name": "Imperial College London",
      "country": "GB"
    }
  ],
  "cited_by": 21
}