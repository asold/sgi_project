{
    "title": "Monad Transformers for Backtracking Search",
    "url": "https://openalex.org/W1985818808",
    "year": 2014,
    "authors": [
        {
            "id": "https://openalex.org/A3192072822",
            "name": "Hedges, Jules",
            "affiliations": [
                "Queen Mary University of London"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2057361103",
        "https://openalex.org/W2151637386",
        "https://openalex.org/W2048835253",
        "https://openalex.org/W2039430744",
        "https://openalex.org/W2106315319",
        "https://openalex.org/W2402717231",
        "https://openalex.org/W2136744801",
        "https://openalex.org/W6605262242",
        "https://openalex.org/W2118416409",
        "https://openalex.org/W128869332",
        "https://openalex.org/W3103594074",
        "https://openalex.org/W3101899264",
        "https://openalex.org/W4206807714"
    ],
    "abstract": "This paper extends Escardo and Oliva's selection monad to the selection monad transformer, a general monadic framework for expressing backtracking search algorithms in Haskell. The use of the closely related continuation monad transformer for similar purposes is also discussed, including an implementation of a DPLL-like SAT solver with no explicit recursion. Continuing a line of work exploring connections between selection functions and game theory, we use the selection monad transformer with the nondeterminism monad to obtain an intuitive notion of backward induction for a certain class of nondeterministic games.",
    "full_text": "N.R. Krishnaswami and P.B. Levy (Eds.):\nMathematically Structured Functional Programming 2014 (MSFP 2014).\nEPTCS 153, 2014, pp. 31–50, doi:10.4204/EPTCS.153.3\nMonad Transformers for Backtracking Search\nJules Hedges\nQueen Mary University of London\nj.hedges@qmul.ac.uk\nThis paper extends Escard´ o and Oliva’s selection monad to the selection monad transformer, a gen-\neral monadic framework for expressing backtracking searchalgorithms in Haskell. The use of the\nclosely related continuation monad transformer for similar purposes is also discussed, including an\nimplementation of a DPLL-like SAT solver with no explicit recursion. Continuing a line of work\nexploring connections between selection functions and game theory, we use the selection monad\ntransformer with the nondeterminism monad to obtain an intuitive notion of backward induction for\na certain class of nondeterministic games.\n1 Introduction\nSelection functions are higher-order functions related tocontinuations, introduced by Martin Escard´ o\nand Paulo Oliva in [6], with many remarkable properties. There are many intuitions that can be used to\nunderstand selection functions, including viewing them as\n• a generalised form of search algorithm\n• a generalised notion of rationality\nSelection functions form a monad, called theselection monad, which has an important intuition as a\nreﬁnement of the continuation monad that carries additional information. All of these intuitions will\nbe used in this paper. The monoidal product of the selection monad, called theproduct of selection\nfunctions, can be used for several seemingly unrelated purposes:\n1. In proof theory, it gives a computational meaning to the negative translation of the axiom of count-\nable choice [6]\n2. In synthetic topology, it is a computational form of Tychonoff’s theorem [4]\n3. In functional programming, it provides a monadic framework for backtracking search problems\n[7]\n4. In game theory, it is a generalisation of the backward induction algorithm [9]\nIn this paper we are concerned with points (3) and (4).\nThe intuition behind (3) is that a selection function is a generalised search algorithm, inputting a ‘gen-\neralised predicate’ characterising objects to be found, and outputting an object that satisﬁes the predicate\nif one exists. The purpose of the product of selection functions is to combine search algorithms for\nsimple search spaces into search algorithms for more complex search spaces. This has been used to de-\nrive so-calledseemingly impossible functional programswhich search certain inﬁnite (but topologically\ncompact) data types in ﬁnite time [3].\nFor (4) we have a powerful intuition that a selection function is a generalised form of preference\nfor rational agents in game theory [10]. Indeed the argmax operator, which characterises the behaviour\nof classical economic agents, is one of the canonical examples of a selection function. The product\n32 Monad Transformers for Backtracking Search\nof selection functions applied to copies of argmax is precisely the backward induction algorithm, used\nto compute subgame-perfect Nash equilibria of sequential games [9], and we can transfer this game-\ntheoretic intuition to other instances of the product of selection functions. An introduction to selection\nfunctions written from this point of view is [8].\nPart 2 of this paper is an introduction to selection functions and the Haskell implementation of the\ncontinuation and selection monads. In part 3 we show the use of the continuation monad, rather than\nthe selection monad, for writing search algorithms in Haskell, and the use of the continuation monad\ntransformer to express more advanced search algorithms such as DPLL. In part 4 we deﬁne the selection\nmonad transformer and show its relationship to the ordinaryselection monad and the continuation monad\ntransformer. Part 5 deﬁnes nondeterministic sequential games, and in part 6 we use the monoidal product\nof the selection monad transformer, applied to the nondeterminism monad, to give an intuitive notion of\nbackward induction for these games.\nThis paper uses two different notations, namely Haskell and‘naive type theory’, which can be read\neither as ordinary set theory or as functional pseudocode. To make it easy to distinguish the nota-\ntions, Haskell code is set in abox . There are three appendices listing Haskell code verbatim:appendix\nAppendix A contains the DPLL implementation (part 3), Appendix B contains the selection monad trans-\nformer library (part 4) and Appendix C contains an example nondeterministic game (parts 5 and 6). All\nof this code can be downloaded from the author’s homepage1.\n2 Quantiﬁers and selection functions\nA selection function is deﬁned to be any function with a type of the form\nε :JR X\nwhere the selection monadJR is deﬁned as\nJR X = (X →R) →X\nor, in Haskell notation,\ndataSel r x= Sel{runSel::(x →r) →x}\nThere is a close relationship between the selection monad and the well-known continuation monad\nKR X = (X →R) →R\nwhich in Haskell is\ndataCont r x= Cont {runCont ::(x →r) →r}\n1http://www.eecs.qmul.ac.uk/~julesh/\nJules Hedges 33\n(Note that in Haskell the constructor ofCont is writtencontas a consequence of the continuation monad\nbeing, in reality, deﬁned in terms of the continuation monadtransformer.) A functionϕ :KR X is called\na quantiﬁer. Every selection functionε :JR X induces a quantiﬁerε :KR X by\nεp = p(εp)\nThis operation is a monad morphism fromJR toKR . When ϕ is a quantiﬁer satisfyingϕ = ε we say\nthatε attainsϕ . Not every quantiﬁer is attainable, for example a constant quantiﬁerϕ p = r0 is not\nattainable because we can ﬁnd somep :X →R such thatr0 is not in the image ofp. However many\nimportant quantiﬁers are attainable, and in those cases selection functions offer several advantages.\nThe canonical examples of quantiﬁers are the maximum operator max :KRX for a ﬁnite setX deﬁned\nby\nmax p = max\nx∈X\npx\nand the existential quantiﬁer∃:KBX , whereB = {⊥,⊤}, deﬁned by\n∃p =\n{\n⊤ ifpx = ⊤for somex ∈X\n⊥ otherwise\nBoth of these quantiﬁers are attained: max is attained by theoperator argmax which produces a point at\nwhich p attains its maximum, and∃is attained by Hilbert’sε operator. Another interesting example is\nthe integral operator ∫\n:KR[0,1]\ndeﬁned by ∫\np =\n∫ 1\n0\npxdx\nA combination of the mean value theorem and the axiom of choice proves that this quantiﬁer is attained.\nThis example is interesting because a computable quantiﬁeris attained by a noncomputable selection\nfunction (the selection function argmax also has this property if we replace the ﬁnite setX with a compact\ntopological space with inﬁnitely many points, such as the unit interval).\nAll monadsM (note the termmonad will always meanstrong monadin this paper) have a monoidal\nproduct\n⊗:MX ×MY →M (X ×Y )\nwhich can be expressed in terms of unit and bind. (In fact there are always two monoidal products, but\nwe are interested only in one of them.) A monomorphic iterated form of this product is present in the\nHaskell prelude as\nsequence::(Monad m ) =⇒[m a] →m [a]\nIt is important to note that due to the restrictions of Haskell’s type system we can only take the iterated\nproduct of selection functions and continuations which have the same type. In a dependently typed\nlanguage we could express the general product, which for selection functions has type\n⨂\n:∏\ni\nJR Xi →JR ∏\ni\nXi\n34 Monad Transformers for Backtracking Search\nFor the continuation monad the binary product is given by\n(ϕ ⊗ψ )q = ϕ (λ xX .ψ (λ yY .q(x,y)))\nAs special cases this includes min-maxes in game theory, composition of logical quantiﬁers such as\n∃xX ∀yY .q(x,y), and multiple integration over products of[0,1], as well as combinations of these such as\nmax\nx∈X\n∫ 1\n0\nq(x,y)dy\nThe product of selection functions is a more complex operation, given in [8] by\n(ε ⊗δ)q = (a,ba)\nwhere\na = ε(λ xX .q(x,bx))\nbx = δ(λ yY .q(x,y))\nBecause the overline operation is a monad morphism it commutes with the monoidal products:\nε ⊗δ = ε ⊗δ\nIn other words, ifε attainsϕ and δ attainsψ thenε ⊗δ attainsϕ ⊗ψ .\nOne of the most important and remarkable properties of selection functions is that the product of\nselection functions is well-deﬁned when iterated inﬁnitely, so long asR is compact andq is continuous.\nMoreover the Haskell functionsequencespecialised to the selection monad will terminate on an inﬁnite\nlist, provided the Haskell datatyper is compact in the sense of [4], since computable functions are\ncontinuous. Other well-known monads, including the continuation monad, do not have this property.\nFinite discrete types such asBoolare compact, and an example of an inﬁnite compact type isInt→Bool,\nwhich corresponds to the Cantor space 2ω . An example of a type which is not compact isInt.\n3 SAT solving with the continuation monad transformer\nIn this section we investigate the use of the continuation monad transformer for structuring backtracking\nsearch algorithms. (For the ordinary continuation monad this is implicit in the work of Escard´ o and\nOliva.) In general, for the decision version of a search problem the continuation monad can be used.\nOne advantage of this approach is that these monads are better-known and are part of a standard Haskell\ninstallation. A more tangible advantage is that using the continuation monad is likely to be more efﬁcient\n(although the runtime of these algorithms is generally unknown). However, the main reason for this\nsection is simply to investigate putting the continuation monad transformer to a use for which it was not\noriginally intended.\nThe selection function\nε ::Sel Bool Bool\nε = Sel$ λ p →p True\nJules Hedges 35\nwill solve a simple optimisation problem: given a functionp ::Bool→Bool the selection functionε\nwill ﬁndx making p xtrue, if one exists. Then\nsequence$ repeatε\nwill, given a functionq ::[Bool] →Bool , ﬁndxsmaking q xstrue, if one exists (recall that the Haskell\nfunctionrepeatbuilds inﬁnite lists). In other words, this function will ﬁnd satisfying assignments of\npropositional formulas. The correctness and totality of this function is far from obvious! The most\ndirect proof is by bar induction (speciﬁcally, induction onthe modulus of continuity ofq) but a far more\nintuitive proof method is to view the search problem as an unbounded sequential game and apply theorem\n6.2 of [8].\nHowever, the classical SAT problem is only to decide whethera satisfying assignment exists, rather\nthan to actually compute one. By construction, if a formulaq has a satisfying assignment then(⊗iε)q is\na satisfying assignment. Thereforeq is satisﬁable iffq((⊗iε)q) is true, that is, if(⊗iε)q is true. If the\nproduct is ﬁnite this is equal to(⊗i∃)q, and∃can be written directly in Haskell as\n∃::Cont Bool Bool\n∃= cont$ λ p →p $ p True\nUsing sequencefor the monoidal product yields an extremely small, self-contained Haskell SAT solver:\nimport Control.Monad .Cont\nsat n= runCont$ sequence$ replicate n$ cont$ λ p →p $ p True\nThe type issat::Int→([Bool] →Bool) →Bool , so it is not a true SAT solver in the sense that\nit takes its input as a function[Bool] →Bool rather than in a discrete form such as a clause-set. The\nother input is the number of variables to search, which is necessary becausesequencespecialised to\ncontinuations will diverge on inﬁnite lists. It is also important to stress that this algorithm is not a SAT\nsolver written in continuation-passing style, rather it uses the continuation monad to directly represent\nthe recursion.\nUsing the continuation monad transformer we can begin to reﬁne this algorithm, for example we can\nwrite a DPLL-like algorithm using a state monad to store clause-sets. The DPLL algorithm, introduced\nin [2], decides the satisﬁability of CNF-formulas by successively extending the formula with either a\nliteral or its negation, and at each stage applying two simplifying transformations, namely unit clause\npropagation and pure literal elimination. Most modern SAT solvers are based on DPLL combined with\nvarious heuristics to improve average-case complexity, see for example [11].\nFor simplicity we implement only unit clause propagation. The algorithm we will implement is\nrepresented in imperative pseudocode in algorithm 1.\nWe begin with a datatype representing literals:\n36 Monad Transformers for Backtracking Search\nAlgorithm 1Imperative DPLL algorithm\nfunctionDPLL( ϕ )\nifϕ is an empty clause-setthen\nreturnTrue\nend if\nif\nϕ contains the empty clausethen\nreturnFalse\nend if\nwhile\nϕ contains a unit clauseldo\nforeach clausec inϕ do\nifc containslthen\nϕ ←remove c from ϕ\nend if\nifc contains\nlthen\nc ←remove lfrom c\nend if\nend for\nend while\nl←next literal\nreturnDPLL(\nϕ ∧l)∨DPLL( ϕ ∧l)\nend function\ndataLiteral= Positive Int|Negative Int\nso the type of a clause-set is[[Literal]]. The top-level function will be\ndpll ::Int→[[Literal]] →Bool\ndpll n= evalState s. initialState\nwhere\ns ::State DPLL Bool\ns = runContT (sequence$ replicate nϕ ) q\nϕ ::ContT Bool(State DPLL) Bool\nϕ = ContT $ λ p →p True> >= p\nNotice that inϕ the expressionp $ p Trueis replaced by its monad transformer equivalentp True> >= p .\nThe typeDPLL must represent the state used by the DPLL algorithm, and we need a function\ninitialState::[[Literal]] →DPLL . Most of the actual algorithm is contained in the query function\nJules Hedges 37\nq ::[Bool] →State DPLL Bool\nThe implementation of this function is given in appendix Appendix A. It is important to note that the\nmonad transformer stackContT Bool(State DPLL) will thread a single state through an entire search,\nhowever for the DPLL algorithm we want to create a new copy of the state for every recursive call. We\nachieve this by representing the recursion tree explicitly, making the state typeDPLL a type of binary\ntrees with leaves labelled by the necessary data. The idea isthat the functionq will move up the tree\naccording to its input, interpretingTrueas ‘go left’ andFalseas ‘go right’. If it ﬁnds a leaf labelled by\na clause set for which satisﬁability is trivial, the function returns. If not, it extends the tree according to\nthe remaining input. A full implementation is presented in appendix Appendix A.\nAs written, this program is not particularly efﬁcient. Potentially we could use theIO monad rather\nthanState, and produce an optimised SAT solving algorithm for exampleby storing the clause sets as\narrays rather than lists. However optimised SAT solvers andother search algorithms require explicit\ncontrol over the backtracking, which is precisely what the continuation and selection monads do not\nallow. In [1] is presented an alternative implementation ofthe product of selection functions that allows\nexplicit control over backtracking. See the next section for a discussion of howsequenceexplores a\nsearch space.\n4 The selection monad transformer\nIn creating a selection monad transformer, our guiding example is the generalisation in the Haskell monad\ntransformer library from the continuation monad\nKR X = (X →R) →R\nto the continuation monad transformer\nK M\nR X = KMR X = (X →MR ) →MR\nParalleling this, the selection monad\nJR X = (X →R) →X\nis generalised to the selection monad transformer\nJ M\nR X = (X →MR ) →MX\nThe Haskell code for the monad instance is\n38 Monad Transformers for Backtracking Search\ndataSelT r m x= SelT{runSelT ::(x →m r) →m x}\ninstance(Monad m ) =⇒Monad (SelT r m)\nwhere\nreturn= SelT. const. return\nε > >= f = SelT$ λ p →let\ng x= runSelT(f x) p\nh x= g x> >= p\nin\nrunSelT\nε h > >= g\nThis comes from taking the instance declaration for the ordinary selection monad and replacing cer-\ntain function applications with the monadic bind ofm . Similarly we obtain a monad morphism from\nselections to continuations by replacing a function application with monadic bind:\ntoCont ::(Monad m ) =⇒SelT r m x→ContT r m x\ntoContε = ContT $ λ p →runSelTε p > >= p\nIn type-theoretic notation we continue to write this operation as an overlineε. A full code listing is given\nin appendix Appendix B.\nThe proof that the selection monad satisﬁes the monad laws was found using an ad-hoc computer\nprogram written by Martin Escard´ o based on an algorithm fordecidingβ η-equivalence ofλ -terms,\nand is linked from [5]. The author has veriﬁed by hand that theselection monad transformer preserves\nthe unit laws, however the proof for the associativity law appears to be unmanageable. The author is\ncurrently working on a formally veriﬁed proof that the selection monad transformer preserves the monad\nlaws.\nA simple but extremely useful example is to useJ IO\nR to perform a verbose backtracking search,\nlaying bare the subtle behaviour of the product of selectionfunctions which could previously only be\ninvestigated usingunsafePerformIO. For example we can write a function\nverboseQuery::([Bool] →Bool) →[Bool] →IO Bool\nwhich will print information about the query and its result before returning. Then a verbose SAT solver\nis given by\nJules Hedges 39\nverboseSat ::Int→([Bool] →Bool) →IO [Bool]\nverboseSat n= f . verboseQuery\nwhere\nf ::([Bool] →IO Bool) →IO [Bool]\nf = runSel$ sequence$ replicate nε\nε ::SelT Bool IO Bool\nε = SelT($ True)\nExperiments with this function conﬁrm thatsequencewill prune large parts of a search space when it is\nable to, but it also duplicates a certain amount of work, potentially callingq on the same input several\ntimes. It also sometimes continues to callq even after it has found a satisfying assignment (that is, after\nverboseQueryhas printed the resultTrue). The problem of explaining exactly howsequenceexplores a\nsearch space is still open, although the experimental data provided byverboseSATand related functions\nmay make progress possible. The interested reader is encouraged to download the code samples and\nexperiment with this function interactively.\n5 Nondeterministic sequential games\nIn the remaining two sections we writeX ⇒ Y for the type of nondeterministic total functions fromX\ntoY . This is equal to the Kleisli arrowX →P>0Y where P>0 is the nondeterminism monad, whose\nunderlying functor is the covariant nonempty powerset functor. In Haskell we replaceP>0 with the\nlist monad for simplicity. In order to distinguish between the use of the list monad as ‘poor man’s\nnondeterminism’ and its ordinary use as an ordered data structure (such as for an ordered list of moves\nin a game) we use a type synonym\ntypeP>0 a = [a]\n(From a software engineering point of view it would be far better to introduceP>0 as anewtype, but\nusing a type synonym allows us to use the usual list functionsto manipulate sets without boilerplate\ncode.)\nDeﬁnition 1(Finite nondeterministic sequential game). An n-player sequential game consists of types\nX1,... ,Xn of moves, a type R of outcomes and an outcome function\nq :\nn\n∏\ni=1\nXi →R\nA playof the game is a tuple(x1,... ,xn) ∈∏ n\ni=1 Xi, and q(x1,... ,xn) is called theoutcome of the play.\nIn a nondeterministic sequential game, we instead take the outcome function to be a nondeterministic\nfunction\nq :\nn\n∏\ni=1\nXi ⇒ R\nand we consider q(x1,... ,xn) to be the set of all possible outcomes of the play(x1,... ,xn).\n40 Monad Transformers for Backtracking Search\nIn classical game theory the outcome type will beRn, and then we interpret theith element of the\ntupleq(x1,... ,xn) to be the proﬁt of theith player.\nAs a running example, we will consider a simple 2-player nondeterministic game implemented in\nHaskell, the full code of which is presented in appendix Appendix C. Each player has a choice of moves\ngiven by\ndataMove = Cautious|Risky\nThe game will be zero-sum, so its outcome will be a single integer with the ﬁrst player maximising\nand the second minimising. The nondeterministic outcome function will be given by\ntypeOutcome = Int\nq ::[Move ] →P>0 Outcome\nq [Cautious, Cautious] = [0]\nq [Cautious, Risky] = [ −1, 0, 1]\nq [Risky, Cautious] = [ −1, 0, 1]\nq [Risky, Risky] = [ −2, −1, 0, 1, 2]\nConsider theith player of a game deciding which moves to play, having observed the previous moves\nx1,... ,xi−1. Assuming that the players to follow are playing according to certain constraints (such as\nrationality) which are common knowledge, the player can associate to each possible movexi a set of out-\ncomes which may result after the other players’ moves. Thus the player has a nondeterministic function\nXi ⇒ R, which we call thecontextof playeri’s move.\nDeﬁnition 2(Policies of players). An outcome policyfor player i is a rule that associates each context\np :Xi ⇒ R with a set of outcomes which the player considers to begood following that context. Thus an\noutcome policy for player i is a quantiﬁer with type\nϕi :K P>0\nR Xi\nA move policyfor player i is a rule which, given a context, nondeterministically chooses a move.\nThus a move policy for player i is a selection function with type\nεi :J P>0\nR Xi\nA move policyεi is calledrationalfor an outcome policyϕi if for every context p and every move x\nthat may be selected by the move policy, every outcome that could result from the context given that move\nis a good outcome. Symbolically,\n{r ∈px |x ∈εip}⊆ϕip\nThe left hand side of this is preciselyεip, where· is the monad morphismJ P>0\nR →K P>0\nR . (However\nthe subset relation prevents us from obtaining a game-theoretic interpretation of more general instances\nof the selection monad transformer.)\nJules Hedges 41\nAn outcome policy is calledrealisticiff, for every context, there is a move such that every possible\noutcome of that move in that context is a good outcome. In other words, an outcome policy is realistic iff\nit has a rational move policy.\nIt was pointed out by an anonymous referee that this deﬁnition of realistic is equivalent, using the\naxiom of choice, to the existence of an ordinary (deterministic) selection functionεi:(X →P>0R) →X\nwith the property thatp(εip) ⊆ϕip. It is then possible to replaceP>0R with an arbitrary poset and\ncontinue using only ordinary quantiﬁers and selection functions. However, the point intuitively is that\nsince we are working with nondeterministic games it makes more sense to allow the players to choose\nmoves nondeterministically, rather than using the axiom ofchoice to ‘determinise’ the move choices.\nMore concretely, it should be possible to construct outcomepolicies with a computable rational move\npolicy but no computable selection function with this property, at least if we use true nondeterminism\nrather than approximating it with lists.\nFor deterministic games there are canonical realistic outcome policies in the case when the outcome\ntype isRn, namely maximisation with respect to the ordering ofR:\nϕip = max\nx∈Xi\n(px)i\nwhere (px)i is theith coordinate projection of the vectorpx :Rn. However for nondeterministic games\nthere is no canonical policy, even when the outcome type isR: a player might always choosex such that\npx contains the largest possible element, or they might have a more complicated policy to mitigate risk,\nfor example preferring possible outcomes{5}to{10,−100}. We leave this undetermined and allow the\npolicies to be arbitrary.\nWe will consider two pairs of move policies for the example game, also calledcautiousand risky.\nFor the implementation of these we begin with the type\ntypeChoice= P>0 (Move , P>0 Outcome) →(Move , P>0 Outcome)\nrepresenting ‘choice functions’ which, given a set of move-outcome pairs, will choose one. Next we write\na function calledargopt, which is a generic way to convert a choice function into a selection function.\nargopt ::Choice →SelT OutcomeP>0 Move\nargopt f= SelT$ λ p →[fst$ f [(Cautious, p Cautious), (Risky, p Risky)]]\nIt should be noted that Haskell does not allow a type synonym with a free type variable to be used as a\nparameter, soSelT OutcomeP>0 Move must be writtenSelT Outcome[] Move in real code.\nNow we implement our two pairs of choice functions:\nriskymax, riskymin, cautiousmax, cautiousmin::Choice\nriskymax = maximumBy $ comparing$ maximum . snd\nriskymin = minimumBy $ comparing$ minimum . snd\n42 Monad Transformers for Backtracking Search\ncautiousmax = riskymax. ﬁlter(all(≥(−1)) . snd)\ncautiousmin = riskymin. ﬁlter(all(≤1) . snd)\nIn words, the risky move policies will select moves tomaximisethe player’smaximum possible gain\n(which for the second player isminimisingtheminimum outcome), ignoring the risk of bad outcomes.\nThe cautious move policies do likewise, but avoid moves thatlead to the possibility of the worst possible\noutcome, which is±2. The risky move policies are deterministic in the sense that they always return\na list of length 1. The cautious move policies also have this property for the particular game we are\nconsidering, but not in general (indeed, as written the functionscautiousmaxand cautiousminare partial\nfunctions: if theﬁlterreturns an empty list then an exception will be thrown).\nDeﬁnition 3(Strategy). A strategy for player i in a game is a function\nσi :\ni−1\n∏\nj=1\nX j →Xi\nwhich chooses a move given the observed previous moves. For anondeterministic sequential game we\ntake the strategies to be nondeterministic functions\nσi :\ni−1\n∏\nj=1\nX j ⇒ Xi\nThus in particular a strategy for player 1 isσ1 :P>0X1. A tupleσ containing a strategy for each player\nis called astrategy proﬁle.\nWe can understand this deﬁnition intuitively by imagining that nondeterminism is resolved at several\npoints during the course of playing a game. First, player 1 nondeterministically chooses a move. Then\nthe nondeterminism resolves, and some concrete move is played. Player 2 observes the actual move\nthat was played, and nondeterministically chooses a move, and so on. Eventually, after all players have\nmoved, we obtain a concrete play(x1,... ,xn). Then the rules of the game nondeterministically determine\nan outcome, and ﬁnally this nondeterminism resolves to produce the actual outcome.\n6 Backward induction for nondeterministic games\nNow we need to deﬁne what it means for a strategy proﬁle to be optimal. In game-theoretical language\nan optimal strategy proﬁle is called asubgame-perfect Nash equilibrium.\nIntuitively, a strategy proﬁle is optimal if for all playersi and all partial plays up to playeri−1,\nevery outcome that could result from playing the strategy proﬁle is a good outcome in the context which,\nfollowing playeri’s move, the remaining players play according to the strategy proﬁle.\nWe spell out this deﬁnition explicitly. Given a partial play⃗x = (x1,... ,xi−1), the set all moves that\nmight be made by playeri≤j≤n by playing the strategy proﬁle\nσ is given inductively by\nb⃗x\nj = {x ∈σ j(⃗x,xi,... ,xj−1) |xk ∈b⃗x\nk, i≤k < j}\nwhich in monad notation is\nb⃗x\nj =\n(j−1⨂\nk=i\nb⃗x\nk\n)\n> >=\nσ j⃗x\nJules Hedges 43\nwhere ⊗is the monoidal product ofM , which forM = P>0 is the cartesian product. The set of all\noutcomes that might result from playing the strategiesσ on the partial play⃗x is\n{r ∈q(⃗x,xi,... ,xn) |xk ∈b⃗x\nk, i≤k ≤n}\nNow we need to deﬁne the context in which playerichooses a move. Suppose after the partial play⃗x,\nplayerichooses the movex ∈Xi. The set of outcomes that could result from this is simply theresult of\nthe previous calculation applied to the partial play(⃗x,x), namely\n{r ∈q(⃗x,x,xi+1,... ,xn) |xk ∈b⃗x,x\nk , i< k ≤n}\nDeﬁnition 4(Optimal strategy proﬁle). A strategy proﬁle\nσ is called optimal for given outcome policies\nϕi if for all partial plays⃗x = (x1,... ,xi−1) for1 ≤i≤n we have\n{r ∈q(⃗x,xi,... ,xn) |xk ∈b⃗x\nk, i≤k ≤n}⊆\nϕip\nwhere the context p:Xi ⇒ R is deﬁned by\npx = {r ∈q(⃗x,x,xi+1,... ,xn) |xk ∈b⃗x,x\nk , i< k ≤n}\nNotice that an optimal strategy proﬁle guarantees good outcomes for all players, despite the nonde-\nterminism. In order for this to hold there must be enough goodoutcomes, for which it is sufﬁcient that\nthe outcome policies are realistic.\nTheorem 1. A nondeterministic sequential game in which all players’ outcome policies are realistic has\nan optimal strategy proﬁle.\nIf the players’ move policies are\nεi and the outcome function isq then an optimal strategy proﬁle is\ngiven by\nσi⃗x = πi\n(( n⨂\nj=i\nεj\n)\n(q⃗x)\n)\nwhere ⊗is the monoidal product in the monadJ P>0\nR ,q⃗x is the partial application ofq to⃗x, andπi is the\nprojection ontoXi. These can be computed in Haskell by\nstrategy es q xs= head $ runSelTε (q . (xs + +))\nwhere\nε = sequence$ drop(length xs) es\nMoreover the set of all plays which may occur from playing this strategy proﬁle is given by\n( n⨂\ni=1\nεi\n)\nq\nwhich is computed in list form by the program\n44 Monad Transformers for Backtracking Search\nplays= runSelT. sequence\nThe corresponding expression using the monoidal product inJR was shown in [9] to be a gen-\neralisation of backward induction, a standard and intuitive algorithm in classical game theory to ﬁnd\nequilibria of sequential games. By taking the monoidal product inJ P>0\nR , we also gain a generalisation\nof backward induction to nondeterministic games.\nIt was remarked above that the appearance of the subset relation in the deﬁnition of rational move\npolicies and optimal strategy proﬁles prevents us from giving these deﬁnitions for an arbitrary monadM .\nThe deﬁnition given applies to submonads of the nondeterminism monad, which include ﬁnite nondeter-\nminism (ﬁnite lists), the exception (Maybe ) monad and the identity monad (in which case we get Escard´ o\nand Oliva’s deﬁnitions). It might be possible to interpret the subset relation for some other monads inad\nhoc ways, for example as a reﬁnement relation for theIO monad, which should have a game-theoretic\nmeaning as games which interact with an environment outsideof the game. However, the given expres-\nsions and Haskell functions to compute optimal strategy proﬁles works for anyM , so we can say that\nthis strategy proﬁle is always optimal, despite having no general deﬁnition. It remains to be seen what\ngame-theoretic intuition exists for the many different monads that are available.\nWe need to ﬁnd an explicit expression for the monoidal product\n⊗:J M\nR X ×J M\nR Y →J M\nR (X ×Y )\nStarting with the usual expression for the product of selection functions\n(ε ⊗δ)q = (a,ba)\nwhere\na = ε(λ xX .q(x,bx))\nbx = δ(λ yY .q(x,y))\nwe replace a function application with monadic bind, and thecartesian pairing with the monoidal product\n⊗ofM , yielding\n(ε ⊗δ)q = a ⊗(a > >= λ xX .bx)\nwhere\na = ε(λ xX .(bx > >= λ yY .q(x,y)))\nbx = δ(λ yY .q(x,y))\nIt will be helpful to writeq in a curried form, in which case we have\na = ε(λ xX .(bx > >= qx))\nbx = δ(qx)\nWe prove the theorem in the simple case of a 2-move sequentialgame. Let the move types beX\nand Y , so the outcome function has typeq :X ×Y ⇒ R. Let the outcome policies beϕ :K P>0\nR X and\nJules Hedges 45\nψ :K P>0\nR Y , and the rational move policies beε :J P>0\nR X and δ :J P>0\nR Y . We need to prove that the\nstrategy proﬁle\nσX = {x ∈X |(x,y) ∈(ε ⊗δ)q}\nσY x = δ(qx)\nis optimal. Using the explicit expression for the monoidal product we have\n(ε ⊗δ)q = {(x,y) ∈X ×Y |x ∈a,y ∈bx}\nwhere\na = ε (λ x.{r ∈q(x,y) |y ∈bx})\nbx = δ(qx)\ntherefore the ﬁrst player’s strategy is given directly by\nσX = a\nWe can directly calculate\nb()\nX = a\nb()\nY = {y ∈\nδ(qx) |x ∈a}\nb(x)\nY = δ(qx)\nThe conditions we need to verify are\n1. {r ∈q(x,y) |x ∈a,y ∈δ(qx)}⊆ϕ (λ x.{r ∈q(x,y) |y ∈δ(qx)})\n2. For allx :X ,{r ∈q(x,y) |y ∈δ(qx)}⊆ψ (qx)\nSinceδ is a rational move policy forψ we have{r∈py |y ∈δ p}⊆ψ p for all contextsp :Y ⇒ R. Using\nthe contextpy = q(x,y) gives the second condition. For the ﬁrst condition we take the context\npx = {r ∈q(x,y) |y ∈δ(qx)}\nso thata = εp. Then we have\n{r ∈q(x,y) |x ∈a,y ∈δ(qx)}\n= {r ∈px |x ∈εp}\n⊆ϕ p\n= ϕ (λ x.{r ∈q(x,y) |y ∈δ(qx)})\nThis completes the proof.\nFor the example game the optimal plays can be computed interactively:\n46 Monad Transformers for Backtracking Search\nplays[argopt cautiousmax, argopt cautiousmin] q\n=⇒[[Risky, Cautious]]\nplays[argopt cautiousmax, argopt riskymin] q\n=⇒[[Cautious, Risky]]\nplays[argopt riskymax, argopt cautiousmin] q\n=⇒[[Risky, Cautious]]\nplays[argopt riskymax, argopt riskymin] q\n=⇒[[Risky, Risky]]\nThus, each combination of cautious and risky move policies results in a different deterministic play. The\nintuition behind these results is that the ‘personality’ deﬁned by a move policy is common knowledge\nof the players. The only possibly unexpected result is the ﬁrst, when both players are cautious. In this\ncase the ﬁrst player plays risky because she knows that the second player will avoid the maximum risk,\nmeaning the risky move is safe.\nAcknowledgement The author gratefully acknowledges EPSRC grant EP/K50290X/1 which funded\nthis work.\nAppendix A DPLL implementation\nimport Data.List\nimport Control.Monad.State\nimport Control.Monad.Trans.Cont\n-- Literals\ndata Literal = Positive Int | Negative Int deriving (Show, Eq)\nnegateLiteral :: Literal -> Literal\nnegateLiteral (Positive n) = Negative n\nnegateLiteral (Negative n) = Positive n\n-- Internal state of algorithm\ndata DPLL = Leaf {simplified :: Bool, clauses :: [[Literal]]}\n| Node {trueBranch :: DPLL, falseBranch :: DPLL}\n-- Top level of algorithm\ndpll :: Int -> [[Literal]] -> Bool\ndpll n = evalState s . initialState where\ns = runContT (sequence $ replicate n e) q\ne :: ContT Bool (State DPLL) Bool\nJules Hedges 47\ne = ContT $ \\p -> p True >>= p\nq :: [Bool] -> State DPLL Bool\nq bs = do s <- get\nlet (s’, b) = queryState s bs 0\nput s’\nreturn b\n-- Interactions with internal state\ninitialState :: [[Literal]] -> DPLL\ninitialState cs = Leaf {simplified = False, clauses = cs}\nqueryState :: DPLL -> [Bool] -> Int -> (DPLL, Bool)\nqueryState (Leaf False cs) bs n = queryState (Leaf True $ simplify cs) bs n\nqueryState s@(Leaf True []) _ _ = (s, True)\nqueryState s@(Leaf True [[]]) _ _ = (s, False)\nqueryState (Leaf True cs) bs n = queryState (Node l r) bs n where\nl = Leaf False ([Negative n] : cs)\nr = Leaf False ([Positive n] : cs)\nqueryState (Node l r) (True : bs) n = (Node l’ r, b) where\n(l’, b) = queryState l bs (n + 1)\nqueryState (Node l r) (False : bs) n = (Node l r’, b) where\n(r’, b) = queryState r bs (n + 1)\n-- Operations on clause sets\nsimplify :: [[Literal]] -> [[Literal]]\nsimplify cs = if null units\nthen cs\nelse simplify (foldl (flip propagateUnit) cs’ units) where\n(units, cs’) = partition isUnitClause cs\nisUnitClause :: [Literal] -> Bool\nisUnitClause [_] = True\nisUnitClause _ = False\npropagateUnit :: [Literal] -> [[Literal]] -> [[Literal]]\npropagateUnit [l] = (map $ filter (/= negateLiteral l))\n. (filter $ notElem l)\nAppendix B The selection monad transformer library\n-- Selection monad transformer library\n-- A generic backtracking search and auto-pruning library\n48 Monad Transformers for Backtracking Search\nmodule SelT (SelT(..), Sel, toCont,\nboundedBinarySearch, unboundedBinarySearch) where\nimport Control.Monad.Cont\nimport Data.Functor.Identity\n-- Selection monad transformer\nnewtype SelT r m x = SelT {runSelT :: (x -> m r) -> m x}\ninstance (Monad m) => Monad (SelT r m) where\nreturn = SelT . const . return\ne >>= f = SelT $ \\p -> let g x = runSelT (f x) p\nh x = g x >>= p\nin runSelT e h >>= g\ninstance (MonadIO m) => MonadIO (SelT r m) where\nliftIO = lift . liftIO\ninstance MonadTrans (SelT r) where\nlift = SelT . const\n-- Monad morphism from selections to continuations\ntoCont :: (Monad m) => SelT r m x -> ContT r m x\ntoCont e = ContT $ \\p -> runSelT e p >>= p\n-- Vanilla selection monad\ntype Sel r = SelT r Identity\n-- Generic search functions\nunboundedBinarySearch :: (Monad m) => SelT Bool m [Bool]\nunboundedBinarySearch = sequence $ repeat $ SelT ($ True)\nboundedBinarySearch :: (Monad m) => Int -> SelT Bool m [Bool]\nboundedBinarySearch n = sequence $ replicate n $ SelT ($ True)\nAppendix C Example game\nimport SelT\nimport Data.List (maximumBy, minimumBy)\nimport Data.Ord (comparing)\nJules Hedges 49\ndata Move = Cautious | Risky deriving (Show)\ntype Outcome = Int\ntype P a = [a]\nq :: [Move] -> P Outcome\nq [Cautious, Cautious] = [0]\nq [Cautious, Risky] = [-1, 0, 1]\nq [Risky, Cautious] = [-1, 0, 1]\nq [Risky, Risky] = [-2, -1, 0, 1, 2]\ntype Choice = P (Move, P Outcome) -> (Move, P Outcome)\nargopt :: Choice -> SelT Outcome [] Move\nargopt f = SelT $ \\p -> [fst $ f [(Cautious, p Cautious), (Risky, p Risky)]]\nriskymax, riskymin, cautiousmax, cautiousmin :: Choice\nriskymax = maximumBy $ comparing $ maximum . snd\nriskymin = minimumBy $ comparing $ minimum . snd\ncautiousmax = riskymax . filter (all (>= (-1)) . snd)\ncautiousmin = riskymin . filter (all (<= 1) . snd)\nes1, es2, es3, es4 :: [SelT Outcome [] Move]\nes1 = [argopt riskymax, argopt riskymin]\nes2 = [argopt riskymax, argopt cautiousmin]\nes3 = [argopt cautiousmax, argopt riskymin]\nes4 = [argopt cautiousmax, argopt cautiousmin]\nsolve :: [SelT Outcome [] Move] -> P [Move]\nsolve es = runSelT (sequence es) q\nReferences\n[1] Andrej Bauer & Matija Pretnar (2012):Programming with algebraic effects and handlers. Available at\nhttp://math.andrej.com/2012/03/08/programming-with- algebraic-effects-and-handlers/.\n[2] Martin Davis, George Logemann & Donald Loveland (1960):A machine program for theorem proving.\nCommunications of the ACM5(7), pp. 394–397, doi:10.1145/368273.368557.\n[3] Martin Escard´ o (2007): Seemingly impossible functional programs. Available at\nhttp://math.andrej.com/2007/09/28/seemingly-impossible-functional-programs/.\n[4] Martin Escard´ o (2008):Exhaustible sets in higher-type computation. Logical methods in computer science\n4(3:3), pp. 1–37, doi:10.2168/lmcs-4(3:3)2008.\n[5] Martin Escard´ o (2008):A Haskell monad for inﬁnite search in ﬁnite time. Available at\nhttp://math.andrej.com/2008/11/21/a-haskell-monad-f or-infinite-search-in-finite-time/ .\n[6] Martin Escard´ o & Paulo Oliva (2010):Selection functions, bar recursion and backward induction. Mathe-\nmatical structures in computer science20(2), pp. 127–168, doi:10.1017/S0960129509990351.\n50 Monad Transformers for Backtracking Search\n[7] Martin Escard´ o & Paulo Oliva (2010):What sequential games, the Tychonoff theorem and the double-\nnegation shift have in common.Proc. of 3rd ACM SIGPLAN Wksh. on Mathematically StructuredFunctional\nProgramming, doi:10.1145/1863597.1863605.\n[8] Martin Escard´ o & Paulo Oliva (2011):Sequential games and optimal strategies. Proc R Soc A467, pp.\n1519–1545, doi:10.1098/rspa.2010.0471.\n[9] Martin Escard´ o & Paulo Oliva (2012):Computing Nash equilibria of unbounded games. Proceedings of the\nTuring centenary conference.\n[10] Jules Hedges (2013):A generalisation of Nash’s theorem with higher-order functionals. Proc R Soc A\n469(2154), doi:10.1098/rspa.2013.0041.\n[11] Joao Marques-Silva, Ines Lynce & Sharad Malik (2008):Conﬂict-driven clause learning SAT solvers. In\nArmin Biere, Marijn Heule, Hans van Maaren & Toby Walsch, editors:Handbook of satisﬁability, chapter 4,\nIOS Press."
}