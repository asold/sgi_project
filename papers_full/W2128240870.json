{
    "title": "Bayesian Language Modelling of German Compounds",
    "url": "https://openalex.org/W2128240870",
    "year": 2018,
    "authors": [
        {
            "id": "https://openalex.org/A5043555135",
            "name": "Jan A. Botha",
            "affiliations": [
                "University of Oxford"
            ]
        },
        {
            "id": "https://openalex.org/A5111222692",
            "name": "Chris Dyer",
            "affiliations": [
                "Carnegie Mellon University"
            ]
        },
        {
            "id": "https://openalex.org/A5014309771",
            "name": "Phil Blunsom",
            "affiliations": [
                "Carnegie Mellon University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2087309226",
        "https://openalex.org/W1886986916",
        "https://openalex.org/W2153164668",
        "https://openalex.org/W2119825066",
        "https://openalex.org/W2159399018",
        "https://openalex.org/W2135161317",
        "https://openalex.org/W2098439409",
        "https://openalex.org/W263845233",
        "https://openalex.org/W2437005631",
        "https://openalex.org/W2016856586",
        "https://openalex.org/W2169724380",
        "https://openalex.org/W2056250865",
        "https://openalex.org/W2166270474",
        "https://openalex.org/W2103731025",
        "https://openalex.org/W3037265734",
        "https://openalex.org/W2140991203",
        "https://openalex.org/W2146574666",
        "https://openalex.org/W1551893515",
        "https://openalex.org/W2134955506",
        "https://openalex.org/W2154099718",
        "https://openalex.org/W2007553631",
        "https://openalex.org/W2104441213",
        "https://openalex.org/W2155607551",
        "https://openalex.org/W139293362",
        "https://openalex.org/W2080012968",
        "https://openalex.org/W1719940802",
        "https://openalex.org/W2164766438"
    ],
    "abstract": "In this work we address the challenge of augmenting n-gram language models according to prior linguistic intuitions. We argue that the family of hierarchical Pitman-Yor language models is an attractive vehicle through which to address the problem, and demonstrate the approach by proposing a model for German compounds. In our empirical evaluation the model outperforms a modified Kneser-Ney n-gram model in test set perplexity. When used as part of a translation system, the proposed language model matches the baseline BLEU score for Englishâ†’German while improving the precision with which compounds are output. We find that an approximate inference technique inspired by the Bayesian interpretation of Kneser-Ney smoothing (Teh, 2006) offers a way to drastically reduce model training time with negligible impact on translation quality",
    "full_text": null
}